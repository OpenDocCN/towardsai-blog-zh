<html>
<head>
<title>This Facebook Architecture Allows NLP Models to Choose Their Own Architecture</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">这种脸书架构允许NLP模型选择自己的架构</h1>
<blockquote>原文：<a href="https://pub.towardsai.net/this-facebook-architecture-allows-nlp-models-to-choose-their-own-architecture-20eabbe276e6?source=collection_archive---------0-----------------------#2021-06-28">https://pub.towardsai.net/this-facebook-architecture-allows-nlp-models-to-choose-their-own-architecture-20eabbe276e6?source=collection_archive---------0-----------------------#2021-06-28</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><h2 id="99d4" class="ir is it bd b dl iu iv iw ix iy iz dk ja translated" aria-label="kicker paragraph"><a class="ae ep" href="https://towardsai.net/p/category/artificial-intelligence" rel="noopener ugc nofollow" target="_blank">人工智能</a></h2><div class=""/><div class=""><h2 id="edca" class="pw-subtitle-paragraph jz jc it bd b ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq dk translated">元嵌入是脸书人工智能研究所使用的一种非常有趣的技术，用于改进NLP模型的架构。</h2></div><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi kr"><img src="../Images/0cb31a6b33b9884fce77d0ba296b7530.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*r6FoBpCUXGKzZvPvKyprbQ.png"/></div></div><figcaption class="ld le gj gh gi lf lg bd b be z dk translated">图片来源:<a class="ae lh" href="https://towardsdatascience.com/visualizing-bias-in-data-using-embedding-projector-649bc65e7487" rel="noopener" target="_blank">https://towards data science . com/visualization-bias-in-data-using-embedding-projector-649 BC 65 e 7487</a></figcaption></figure><blockquote class="li lj lk"><p id="9d3c" class="ll lm ln lo b lp lq kd lr ls lt kg lu lv lw lx ly lz ma mb mc md me mf mg mh im bi translated">我最近创办了一份专注于人工智能的教育时事通讯，已经有超过90，000名订户。《序列》是一份无废话(意思是没有炒作，没有新闻等)的ML导向时事通讯，需要5分钟阅读。目标是让你与机器学习项目、研究论文和概念保持同步。请通过订阅以下内容来尝试一下:</p></blockquote><div class="mi mj gp gr mk ml"><a href="https://thesequence.substack.com/" rel="noopener  ugc nofollow" target="_blank"><div class="mm ab fo"><div class="mn ab mo cl cj mp"><h2 class="bd jd gy z fp mq fr fs mr fu fw jc bi translated">序列</h2><div class="ms l"><h3 class="bd b gy z fp mq fr fs mr fu fw dk translated">订阅人工智能世界中最相关的项目和研究论文。受到85，000多人的信任…</h3></div><div class="mt l"><p class="bd b dl z fp mq fr fs mr fu fw dk translated">thesequence.substack.com</p></div></div><div class="mu l"><div class="mv l mw mx my mu mz lb ml"/></div></div></a></div><p id="750e" class="pw-post-body-paragraph ll lm it lo b lp lq kd lr ls lt kg lu na lw lx ly nb ma mb mc nc me mf mg mh im bi translated">单词嵌入是自然语言处理(NLP)领域中最成熟的技术之一。从概念上讲，单词嵌入是将句子中的短语或单词映射到向量和数字的语言建模方法。任何NLP应用程序的第一步都是确定将要使用什么类型的单词嵌入算法。通常，NLP模型求助于预先训练的单词嵌入算法，如Word2Vec、Glove或FastText。虽然这种方法相对简单，但是它也导致了非常低的效率，因为随着NLP模型的发展，几乎不可能确定什么单词嵌入会执行得更好。如果NLP模型本身能够为给定的上下文选择最佳的单词嵌入会怎么样？<a class="ae lh" href="https://arxiv.org/abs/1804.07983" rel="noopener ugc nofollow" target="_blank">在2018年的一篇论文</a>中，来自脸书人工智能研究实验室(FAIR)的研究人员提出了一种方法，允许NLP模型动态选择一种在给定环境下表现最佳的单词嵌入算法。</p><p id="0dbf" class="pw-post-body-paragraph ll lm it lo b lp lq kd lr ls lt kg lu na lw lx ly nb ma mb mc nc me mf mg mh im bi translated">动态元嵌入是一种将不同的单词嵌入模型组合在集成模型中的技术，并允许NLP算法基于它们的性能来选择使用什么嵌入。脸书的技术，本质上，基于集合的特定行为，将嵌入算法的选择从设计时间延迟到运行时间。</p><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi nd"><img src="../Images/3eb836b28c32964c73596221f2a14e6a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*HXqXbOT47jpGtigKktcV2Q.png"/></div></div></figure><h1 id="8295" class="ne nf it bd ng nh ni nj nk nl nm nn no ki np kj nq kl nr km ns ko nt kp nu nv bi translated">预训练单词嵌入的挑战</h1><p id="fb1b" class="pw-post-body-paragraph ll lm it lo b lp nw kd lr ls nx kg lu na ny lx ly nb nz mb mc nc oa mf mg mh im bi translated">动态元嵌入背后的原理相当简单:在给定的环境下，不同的单词嵌入算法表现不同，那么为什么不将它们结合起来，让网络决定使用哪种嵌入呢？此外，动态元嵌入解决了更传统一代的预训练单词嵌入方法的一些实际挑战。</p><p id="4f55" class="pw-post-body-paragraph ll lm it lo b lp lq kd lr ls lt kg lu na lw lx ly nb ma mb mc nc me mf mg mh im bi translated"><strong class="lo jd">覆盖率:</strong>预训练的单词嵌入算法在遇到不在给定词汇表范围内的单词时会遇到困难。</p><p id="219d" class="pw-post-body-paragraph ll lm it lo b lp lq kd lr ls lt kg lu na lw lx ly nb ma mb mc nc me mf mg mh im bi translated"><strong class="lo jd">特定领域:</strong>监督单词嵌入模型通常在单个领域上训练，当遇到来自其他领域的句子时表现不佳。</p><p id="fa63" class="pw-post-body-paragraph ll lm it lo b lp lq kd lr ls lt kg lu na lw lx ly nb ma mb mc nc me mf mg mh im bi translated"><strong class="lo jd">评估:</strong>在NLP模型中评估单词嵌入算法的性能几乎是不可能的。我们可以清楚地评估NLP模型的性能，但是很难将它与底层单词嵌入的行为联系起来。</p><p id="5974" class="pw-post-body-paragraph ll lm it lo b lp lq kd lr ls lt kg lu na lw lx ly nb ma mb mc nc me mf mg mh im bi translated"><strong class="lo jd">可解释性:</strong>补充上一点，理解为什么一个特定的单词嵌入算法以特定的方式运行是非常困难的。给定一个特定的NLP任务，很难预测哪个单词嵌入算法会执行得更好。</p><h1 id="85f4" class="ne nf it bd ng nh ni nj nk nl nm nn no ki np kj nq kl nr km ns ko nt kp nu nv bi translated">动态元嵌入</h1><p id="7bf8" class="pw-post-body-paragraph ll lm it lo b lp nw kd lr ls nx kg lu na ny lx ly nb nz mb mc nc oa mf mg mh im bi translated">动态元嵌入从给定的单词嵌入算法集合开始。给定由一组tokes <em class="ln"> {t1，t2，…tn} </em>构成的特定句子，动态元嵌入模型将从不同的模型中产生一系列嵌入。随着时间的推移，NLP算法将评估每个嵌入模型的性能，并相应地分配权重，从而获得更好的性能。</p><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi ob"><img src="../Images/7b4e2ab248a9357ac94b20d7cd88bb86.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*ecC9F5Jcr7JIzVqLDhk9CQ.png"/></div></div><figcaption class="ld le gj gh gi lf lg bd b be z dk translated"><strong class="bd ng">图片来源:脸书</strong></figcaption></figure><p id="307f" class="pw-post-body-paragraph ll lm it lo b lp lq kd lr ls lt kg lu na lw lx ly nb ma mb mc nc me mf mg mh im bi translated">GitHub上提供了动态元嵌入的开源实现。基于PyTorch，当前的实现使得将不同的单词嵌入合并到NLP模型中变得非常简单。下面的代码显示了如何使用由FastText和Glove嵌入组成的集成来训练NLP模型。</p><pre class="ks kt ku kv gt oc od oe of aw og bi"><span id="e2c4" class="oh nf it od b gy oi oj l ok ol">python train.py --task snli \<br/>--datasets_root data/datasets --embeds_root data/embeddings --savedir checkpoints \<br/>--embeds fasttext,glove --mixmode proj_sum --attnnet no_dep_softmax \<br/>--nonlin relu --rnn_dim 128 --fc_dim 128 \<br/>--optimizer adam --lr 0.0004 --lr_min 0.00008 --batch_sz 64 --emb_dropout 0.2 --clf_dropout 0.2</span></pre><h1 id="1921" class="ne nf it bd ng nh ni nj nk nl nm nn no ki np kj nq kl nr km ns ko nt kp nu nv bi translated">行动中的动态单词嵌入</h1><p id="875a" class="pw-post-body-paragraph ll lm it lo b lp nw kd lr ls nx kg lu na ny lx ly nb nz mb mc nc oa mf mg mh im bi translated">脸书团队评估了不同NLP场景中的动态元嵌入，如情感分析、图像字幕检索、语言推理和其他几个场景。在每项任务中，使用动态元嵌入的模型能够胜过使用预训练单词嵌入的模型。</p><p id="5657" class="pw-post-body-paragraph ll lm it lo b lp lq kd lr ls lt kg lu na lw lx ly nb ma mb mc nc me mf mg mh im bi translated">除了令人印象深刻的性能结果，动态元嵌入还隐藏了一些关于不同单词嵌入算法性能的有趣见解。下面的图表说明了在给定具体已知单词或低频单词的情况下，动态元嵌入的偏好。我们可以清楚地看到，ImageNet单词嵌入模型对于连续单词是首选的，而Glove在使用低频单词的上下文中是首选的。</p><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi kr"><img src="../Images/a504da6e61fb8b87706e225f5f0b31d6.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*lM21b-pcJtAPG6uQ5fsMGA.png"/></div></div></figure><p id="7e19" class="pw-post-body-paragraph ll lm it lo b lp lq kd lr ls lt kg lu na lw lx ly nb ma mb mc nc me mf mg mh im bi translated">选择单词嵌入算法的任务通常是高度主观的，并且基于领域知识。脸书在动态元嵌入方面的工作表明，单词嵌入模型的选择最好留给神经网络本身。动态元嵌入允许NLP模型为不同的任务选择不同的词嵌入，从而导致更有效和可预测的性能。此外，动态元嵌入产生了更多可解释的NLP模型，更有效的语言分析，并且，值得注意的是，突出了在给定的特定上下文中哪些单词嵌入模型表现得更好。关于动态元嵌入的工作相对来说是新生的，但是它确实显示了极大的希望来改进当前一代的NLP模型。</p></div></div>    
</body>
</html>