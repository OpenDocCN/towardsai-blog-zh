<html>
<head>
<title>Disentangled Representation Learning for Non-Parallel Text Style Transfer</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">非平行文本风格转换的非纠缠表征学习</h1>
<blockquote>原文：<a href="https://pub.towardsai.net/disentangled-representation-learning-for-non-parallel-text-style-transfer-paper-summary-aa862bc46349?source=collection_archive---------0-----------------------#2020-04-10">https://pub.towardsai.net/disentangled-representation-learning-for-non-parallel-text-style-transfer-paper-summary-aa862bc46349?source=collection_archive---------0-----------------------#2020-04-10</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><h2 id="6aaf" class="io ip iq bd b dl ir is it iu iv iw dk ix translated" aria-label="kicker paragraph">论文摘要</h2><div class=""/><div class=""><h2 id="27af" class="pw-subtitle-paragraph jw iz iq bd b jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn dk translated">Vineet John、Lili Mou、Hareesh Bahuleyan、Olga Vechtomova</h2></div><blockquote class="ko kp kq"><p id="b667" class="kr ks kt ku b kv kw ka kx ky kz kd la lb lc ld le lf lg lh li lj lk ll lm ln ij bi translated">解开神经网络的隐藏层让我们对神经网络有更多的控制和理解</p></blockquote><figure class="lp lq lr ls gt lt gh gi paragraph-image"><div role="button" tabindex="0" class="lu lv di lw bf lx"><div class="gh gi lo"><img src="../Images/3cfa6ae33214626d50a73f1b8f214304.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*EWCNKo_ClzhC4MtcYFkBhA.png"/></div></div><figcaption class="ma mb gj gh gi mc md bd b be z dk translated"><a class="ae me" href="https://unsplash.com/@steve_j?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">斯蒂夫·约翰森</a>在<a class="ae me" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上拍照</figcaption></figure><p id="7e62" class="pw-post-body-paragraph kr ks iq ku b kv kw ka kx ky kz kd la mf lc ld le mg lg lh li mh lk ll lm ln ij bi translated">在这篇文章中，我将会以一种简单易懂的方式来解释《非平行文本风格转换的表象学习》[1]中所做的工作，并解释该论文中的一些核心观点。这篇论文发表在ACL 2019上，这是机器学习领域的领先会议之一。</p><p id="2bb8" class="pw-post-body-paragraph kr ks iq ku b kv kw ka kx ky kz kd la mf lc ld le mg lg lh li mh lk ll lm ln ij bi translated">这篇论文的标题中有两个关键部分，我将在开始这篇论文的实际内容之前直观地解释它们中的每一个。这两个组成部分是解开表征学习和非平行文本风格转移。</p><h1 id="302a" class="mi mj iq bd mk ml mm mn mo mp mq mr ms kf mt kg mu ki mv kj mw kl mx km my mz bi translated">解开表征学习</h1><p id="a6c2" class="pw-post-body-paragraph kr ks iq ku b kv na ka kx ky nb kd la mf nc ld le mg nd lh li mh ne ll lm ln ij bi translated">想象一下一个自动编码器，你传入一些数据，然后用一些低维的隐藏层重建数据。这种低维表示通常被称为潜在向量，它学习低维空间中的数据表示，并可用于生成原始输入数据。现在，在正常的自动编码器中，潜在向量包含生成原始数据所需的所有信息，但如果我们想要在潜在向量表示的某些部分中分离输入数据的特定属性，该怎么办呢？例如，如果潜在表示是大小为128的向量，我们希望向量的前120个分量存储关于输入数据内容的信息，后8个分量存储关于样式的信息。请注意，数据的内容和样式可以是任何东西，这取决于我们如何定义它们。我们将在本文的后面部分讨论这两个东西的定义。在这一点上，最重要的是理解解缠是什么意思，为了更好地理解，让我们来看一个我刚才解释的可视化表示。</p><figure class="lp lq lr ls gt lt gh gi paragraph-image"><div class="gh gi nf"><img src="../Images/f265d7c679ebd63f1b7ca86c2cc05af3.png" data-original-src="https://miro.medium.com/v2/resize:fit:590/format:webp/1*vHml1ha0lGhkHOOom0d-Eg.png"/></div><figcaption class="ma mb gj gh gi mc md bd b be z dk translated">Autoencoder把潜在空间分为风格空间和内容空间，如文中所述[1]。来源<a class="ae me" href="https://arxiv.org/pdf/1808.04339.pdf" rel="noopener ugc nofollow" target="_blank">链接</a></figcaption></figure><p id="ee18" class="pw-post-body-paragraph kr ks iq ku b kv kw ka kx ky kz kd la mf lc ld le mg lg lh li mh lk ll lm ln ij bi translated">在上图中，我们看到一个普通的自动编码器，它接受一个输入句子，将其压缩到一个潜在空间，并试图重建原始句子。但是我们也可以看到，潜在向量被分成两个空间:-由s表示的风格空间，其应该捕获句子的风格信息(一种可能的风格可以是句子的情感)，和由c表示的内容空间，其应该捕获句子的内容信息。</p><p id="10d9" class="pw-post-body-paragraph kr ks iq ku b kv kw ka kx ky kz kd la mf lc ld le mg lg lh li mh lk ll lm ln ij bi translated"><strong class="ku ja">关键问题:- </strong>我们在这一点上想要回答的问题是，我们如何训练自动编码器，以便能够在潜在向量表示中分离风格空间和内容空间？</p><p id="905e" class="pw-post-body-paragraph kr ks iq ku b kv kw ka kx ky kz kd la mf lc ld le mg lg lh li mh lk ll lm ln ij bi translated">但在我们进入解决方案之前，让我们快速讨论一下我们的第二个组成部分(非平行文本风格转换)，并了解解开潜在空间将如何有助于文本风格转换。</p><h1 id="20e0" class="mi mj iq bd mk ml mm mn mo mp mq mr ms kf mt kg mu ki mv kj mw kl mx km my mz bi translated">非平行文本风格转移</h1><p id="ae73" class="pw-post-body-paragraph kr ks iq ku b kv na ka kx ky nb kd la mf nc ld le mg nd lh li mh ne ll lm ln ij bi translated">在这一节中，我们看到有两个子组件:-文本风格转移和非平行。我们将分别研究它们。</p><h2 id="42d3" class="ng mj iq bd mk nh ni dn mo nj nk dp ms mf nl nm mu mg nn no mw mh np nq my iw bi translated">文本风格转换</h2><p id="e927" class="pw-post-body-paragraph kr ks iq ku b kv na ka kx ky nb kd la mf nc ld le mg nd lh li mh ne ll lm ln ij bi translated">文本风格转移是指从某个输入文本生成文本，内容与输入文本相同(基本上讲的是与输入文本相同的东西)但风格不同。一个将文本的情感视为风格的明显例子是生成关于一家餐馆的负面评论，而将正面评论作为输入文本，如下所示。</p><blockquote class="ko kp kq"><p id="5ce1" class="kr ks kt ku b kv kw ka kx ky kz kd la lb lc ld le lf lg lh li lj lk ll lm ln ij bi translated">输入文本—食物很棒，服务也很出色(正面)</p><p id="a2d8" class="kr ks kt ku b kv kw ka kx ky kz kd la lb lc ld le lf lg lh li lj lk ll lm ln ij bi translated">输出文本—食物有点糟糕，但员工非常出色(负面)</p></blockquote><h2 id="5ba8" class="ng mj iq bd mk nh ni dn mo nj nk dp ms mf nl nm mu mg nn no mw mh np nq my iw bi translated">非并行数据</h2><p id="cf7c" class="pw-post-body-paragraph kr ks iq ku b kv na ka kx ky nb kd la mf nc ld le mg nd lh li mh ne ll lm ln ij bi translated">该组件指的是文本风格转换系统可访问的数据类型，并且可以被分类为并行数据和非并行数据。</p><p id="9b7c" class="pw-post-body-paragraph kr ks iq ku b kv kw ka kx ky kz kd la mf lc ld le mg lg lh li mh lk ll lm ln ij bi translated">并行数据是指我们可以访问成对的数据，其中某种风格的输入文本直接映射到不同风格的文本，并且可以访问风格转换系统。一个经典的例子是机器翻译系统，它可以访问两种不同语言相互映射的文本。</p><p id="9509" class="pw-post-body-paragraph kr ks iq ku b kv kw ka kx ky kz kd la mf lc ld le mg lg lh li mh lk ll lm ln ij bi translated">非并行数据是指我们只有一个输入文本，但没有从该文本到不同样式的可能文本的映射。</p><p id="d2c0" class="pw-post-body-paragraph kr ks iq ku b kv kw ka kx ky kz kd la mf lc ld le mg lg lh li mh lk ll lm ln ij bi translated">在我们的场景中，我们无法访问并行数据，这是我们甚至希望从属性方面理清潜在空间的主要原因。</p><h2 id="ea6f" class="ng mj iq bd mk nh ni dn mo nj nk dp ms mf nl nm mu mg nn no mw mh np nq my iw bi translated">解缠如何帮助非平行文本风格转换？</h2><p id="757f" class="pw-post-body-paragraph kr ks iq ku b kv na ka kx ky nb kd la mf nc ld le mg nd lh li mh ne ll lm ln ij bi translated">由于我们无法访问从一种风格到另一种风格的成对数据映射，我们需要理清思路，将潜在空间分成内容和风格。如果我们能做到这一点，那么从一个输入文本，现在我们有一个潜在的向量表示，分为内容向量和风格向量。要生成风格转换文本，我们需要做的唯一事情是创建一个与输入文本内容向量相同的新的潜在向量，以及一个基于我们的目标风格的新的风格向量，然后使用这个潜在向量来生成我们的输出文本。</p><p id="7bbb" class="pw-post-body-paragraph kr ks iq ku b kv kw ka kx ky kz kd la mf lc ld le mg lg lh li mh lk ll lm ln ij bi translated">现在，我们已经建立了与问题相关的不同部分，让我们继续进行实际的任务，获得解开的潜在向量表示。</p><h1 id="4b85" class="mi mj iq bd mk ml mm mn mo mp mq mr ms kf mt kg mu ki mv kj mw kl mx km my mz bi translated">方法</h1><p id="b90d" class="pw-post-body-paragraph kr ks iq ku b kv na ka kx ky nb kd la mf nc ld le mg nd lh li mh ne ll lm ln ij bi translated">终于，我们到了。准备好深入研究解决方案，但让我们花点时间快速再看一下关键问题，即— <strong class="ku ja">我们如何训练自动编码器，以便能够在潜在向量表示中分离样式空间和内容空间？</strong></p><p id="13f6" class="pw-post-body-paragraph kr ks iq ku b kv kw ka kx ky kz kd la mf lc ld le mg lg lh li mh lk ll lm ln ij bi translated">以样式空间和内容空间为例，我们希望在最后有两个组件，每个组件都有两个相同的步骤，只是稍有改动。</p><p id="cc58" class="pw-post-body-paragraph kr ks iq ku b kv kw ka kx ky kz kd la mf lc ld le mg lg lh li mh lk ll lm ln ij bi translated">1.<strong class="ku ja">样式空间s中的样式信息</strong> —在样式空间s中实施样式信息(步骤1)，并从内容空间c中移除任何样式信息(步骤2)</p><p id="fe7f" class="pw-post-body-paragraph kr ks iq ku b kv kw ka kx ky kz kd la mf lc ld le mg lg lh li mh lk ll lm ln ij bi translated">2.<strong class="ku ja">内容空间c中的内容信息</strong> —在内容空间c中实施内容信息(步骤1)，并从样式空间s中移除任何内容信息(步骤2)</p><p id="1768" class="pw-post-body-paragraph kr ks iq ku b kv kw ka kx ky kz kd la mf lc ld le mg lg lh li mh lk ll lm ln ij bi translated">我将根据第一个组件描述每一个步骤，然后讨论为执行组件2的步骤所做的更改。</p><h2 id="d7a2" class="ng mj iq bd mk nh ni dn mo nj nk dp ms mf nl nm mu mg nn no mw mh np nq my iw bi translated">步骤1——风格信息的多任务培训</h2><p id="e775" class="pw-post-body-paragraph kr ks iq ku b kv na ka kx ky nb kd la mf nc ld le mg nd lh li mh ne ll lm ln ij bi translated">目标:-确保样式信息包含在样式空间s中。</p><p id="b018" class="pw-post-body-paragraph kr ks iq ku b kv kw ka kx ky kz kd la mf lc ld le mg lg lh li mh lk ll lm ln ij bi translated">在这一步中，我们设计一个神经网络(比如网络A ),它采用潜在表示的风格空间s，并试图预测文本的风格。所以，数学上看起来</p><figure class="lp lq lr ls gt lt gh gi paragraph-image"><div class="gh gi nr"><img src="../Images/f0c11447abc3c2df71cbb204af4998d3.png" data-original-src="https://miro.medium.com/v2/resize:fit:514/format:webp/1*4RlYe81dIiJuqUPOfXBXCw.png"/></div><figcaption class="ma mb gj gh gi mc md bd b be z dk translated">等式1</figcaption></figure><p id="5ea3" class="pw-post-body-paragraph kr ks iq ku b kv kw ka kx ky kz kd la mf lc ld le mg lg lh li mh lk ll lm ln ij bi translated">在训练该网络时，我们一起训练编码器参数，以便它以帮助网络A能够正确预测风格的方式学习潜在表示的风格空间。这整个概念可以概括为给定的损失fn:-</p><figure class="lp lq lr ls gt lt gh gi paragraph-image"><div class="gh gi ns"><img src="../Images/46a843f4fa176970b78a15a25f3673ad.png" data-original-src="https://miro.medium.com/v2/resize:fit:688/format:webp/1*TuB7jSPRKxJEPgOWz_mS6Q.png"/></div><figcaption class="ma mb gj gh gi mc md bd b be z dk translated">等式2</figcaption></figure><p id="cc4c" class="pw-post-body-paragraph kr ks iq ku b kv kw ka kx ky kz kd la mf lc ld le mg lg lh li mh lk ll lm ln ij bi translated">因此，本质上，我们训练编码器参数以最小化等式2，以及自动编码器的正常重建损失，由下式给出</p><figure class="lp lq lr ls gt lt gh gi paragraph-image"><div class="gh gi nt"><img src="../Images/4f169f7cb120700278e4a26ba65d2e81.png" data-original-src="https://miro.medium.com/v2/resize:fit:716/format:webp/1*MqjQha1y0v72EhG_GW8CKA.png"/></div><figcaption class="ma mb gj gh gi mc md bd b be z dk translated">自动编码器重建损失(等式3)</figcaption></figure><p id="777a" class="pw-post-body-paragraph kr ks iq ku b kv kw ka kx ky kz kd la mf lc ld le mg lg lh li mh lk ll lm ln ij bi translated">因此，当我们同时训练自动编码器和网络A时，这是一种多任务训练范例。</p><h2 id="6150" class="ng mj iq bd mk nh ni dn mo nj nk dp ms mf nl nm mu mg nn no mw mh np nq my iw bi translated">第二步——风格信息的对抗性训练</h2><p id="cc20" class="pw-post-body-paragraph kr ks iq ku b kv na ka kx ky nb kd la mf nc ld le mg nd lh li mh ne ll lm ln ij bi translated">目标:-确保内容空间c没有任何样式信息。</p><p id="b3e3" class="pw-post-body-paragraph kr ks iq ku b kv kw ka kx ky kz kd la mf lc ld le mg lg lh li mh lk ll lm ln ij bi translated">类似于步骤1，我们设计一个新的神经网络(我们称之为鉴别器)，它现在预测风格信息，但不是来自风格空间s，而是内容空间c作为输入。数学上，神经网络看起来像:-</p><figure class="lp lq lr ls gt lt gh gi paragraph-image"><div class="gh gi nu"><img src="../Images/e0ff91fd65e49e0308114b318f7e9c86.png" data-original-src="https://miro.medium.com/v2/resize:fit:680/format:webp/1*zX5o8rkXatWbwJU1fmdzNw.png"/></div></figure><p id="41d7" class="pw-post-body-paragraph kr ks iq ku b kv kw ka kx ky kz kd la mf lc ld le mg lg lh li mh lk ll lm ln ij bi translated">注意:-与步骤1相反；我们不一起训练神经网络和编码器参数。</p><p id="46a6" class="pw-post-body-paragraph kr ks iq ku b kv kw ka kx ky kz kd la mf lc ld le mg lg lh li mh lk ll lm ln ij bi translated">一旦鉴别器被训练，编码器将鉴别器视为其对手(因为它不希望鉴别器能够从内容空间推断样式信息)，并训练编码器参数以使鉴别器更难，如以下损失函数所示:-</p><figure class="lp lq lr ls gt lt gh gi paragraph-image"><div class="gh gi nv"><img src="../Images/7da6bb067fbcc1acc6c3eb7a999e7285.png" data-original-src="https://miro.medium.com/v2/resize:fit:500/format:webp/1*J79JMhSx6oOTx4DWnbHwgw.png"/></div></figure><p id="19ca" class="pw-post-body-paragraph kr ks iq ku b kv kw ka kx ky kz kd la mf lc ld le mg lg lh li mh lk ll lm ln ij bi translated">在上面的损失函数中，训练编码器参数，使得学习的内容空间在从内容空间预测风格信息时最大化学习的鉴别器的熵。</p></div><div class="ab cl nw nx hu ny" role="separator"><span class="nz bw bk oa ob oc"/><span class="nz bw bk oa ob oc"/><span class="nz bw bk oa ob"/></div><div class="ij ik il im in"><p id="b988" class="pw-post-body-paragraph kr ks iq ku b kv kw ka kx ky kz kd la mf lc ld le mg lg lh li mh lk ll lm ln ij bi translated">因此，在这一点上，我们有一个潜在的表示，它在空间s中存储了样式信息，而内容空间c没有任何样式信息。</p><p id="c1c8" class="pw-post-body-paragraph kr ks iq ku b kv kw ka kx ky kz kd la mf lc ld le mg lg lh li mh lk ll lm ln ij bi translated">类似地，我们需要一个存储内容信息的内容空间c和一个没有任何内容信息的样式空间s。</p><p id="618e" class="pw-post-body-paragraph kr ks iq ku b kv kw ka kx ky kz kd la mf lc ld le mg lg lh li mh lk ll lm ln ij bi translated">我们遵循早先的两步过程，但是现在我们将输入改变为内容空间(c)而不是样式空间，并且网络试图预测内容信息而不是样式信息。这些变化导致步骤1和2的损失函数如下</p></div><div class="ab cl nw nx hu ny" role="separator"><span class="nz bw bk oa ob oc"/><span class="nz bw bk oa ob oc"/><span class="nz bw bk oa ob"/></div><div class="ij ik il im in"><div class="lp lq lr ls gt ab cb"><figure class="od lt oe of og oh oi paragraph-image"><img src="../Images/34a7f6e12cca83b05afc6b019a55f6bf.png" data-original-src="https://miro.medium.com/v2/resize:fit:476/format:webp/1*S0ob5qgCAZ_CUnBYGTppHA.png"/></figure><figure class="od lt oj of og oh oi paragraph-image"><img src="../Images/c162eb55ec782e73f1d0b2171f888dde.png" data-original-src="https://miro.medium.com/v2/resize:fit:738/format:webp/1*lwYF4RgCH3V3ufkA4Uo1zw.png"/><figcaption class="ma mb gj gh gi mc md bd b be z dk ok di ol om translated">训练内容空间时步骤1的神经网络和损失函数</figcaption></figure></div><figure class="lp lq lr ls gt lt gh gi paragraph-image"><div class="gh gi on"><img src="../Images/c162eb55ec782e73f1d0b2171f888dde.png" data-original-src="https://miro.medium.com/v2/resize:fit:738/format:webp/1*lwYF4RgCH3V3ufkA4Uo1zw.png"/></div></figure></div><div class="ab cl nw nx hu ny" role="separator"><span class="nz bw bk oa ob oc"/><span class="nz bw bk oa ob oc"/><span class="nz bw bk oa ob"/></div><div class="ij ik il im in"><div class="lp lq lr ls gt ab cb"><figure class="od lt oo of og oh oi paragraph-image"><img src="../Images/73ab608bddd8af600f3a85bdbabc44f3.png" data-original-src="https://miro.medium.com/v2/resize:fit:696/format:webp/1*XatCCOXNRKYs0MYX_0k-YA.png"/></figure><figure class="od lt op of og oh oi paragraph-image"><img src="../Images/333cae9300d8a9529d79b2d691f30358.png" data-original-src="https://miro.medium.com/v2/resize:fit:434/format:webp/1*62tbKgn1fkRqjHbCT3k6aw.png"/><figcaption class="ma mb gj gh gi mc md bd b be z dk oq di or om translated">步骤2的鉴别器神经网络和对抗性损失函数</figcaption></figure></div></div><div class="ab cl nw nx hu ny" role="separator"><span class="nz bw bk oa ob oc"/><span class="nz bw bk oa ob oc"/><span class="nz bw bk oa ob"/></div><div class="ij ik il im in"><h1 id="98d5" class="mi mj iq bd mk ml os mn mo mp ot mr ms kf ou kg mu ki ov kj mw kl ow km my mz bi translated">整体培训流程</h1><p id="3e12" class="pw-post-body-paragraph kr ks iq ku b kv na ka kx ky nb kd la mf nc ld le mg nd lh li mh ne ll lm ln ij bi translated">综上所述，我们得到的是由自动编码器重构损失、风格空间的多任务损失、风格空间的对抗性损失、内容空间的多任务损失、内容空间的对抗性损失组成的单一损失函数。数学上，这意味着:-</p><figure class="lp lq lr ls gt lt gh gi paragraph-image"><div class="gh gi ox"><img src="../Images/6369b3563528f0f9a7494317c5ebf39e.png" data-original-src="https://miro.medium.com/v2/resize:fit:760/format:webp/1*drUcuRuMFrI7AyqJatILDg.png"/></div><figcaption class="ma mb gj gh gi mc md bd b be z dk translated">训练自动编码器的总损失</figcaption></figure><h1 id="db0d" class="mi mj iq bd mk ml mm mn mo mp mq mr ms kf mt kg mu ki mv kj mw kl mx km my mz bi translated">如何决定风格和内容？</h1><p id="3821" class="pw-post-body-paragraph kr ks iq ku b kv na ka kx ky nb kd la mf nc ld le mg nd lh li mh ne ll lm ln ij bi translated">现在我们已经提出了培训过程，这是方法论的核心，让我们看看如何定义风格和内容。其实你怎么定义这些问题完全取决于你，但是我来给你看看论文作者是怎么定义这两样东西的。</p><h2 id="1f4c" class="ng mj iq bd mk nh ni dn mo nj nk dp ms mf nl nm mu mg nn no mw mh np nq my iw bi translated">风格</h2><p id="a972" class="pw-post-body-paragraph kr ks iq ku b kv na ka kx ky nb kd la mf nc ld le mg nd lh li mh ne ll lm ln ij bi translated">在本文中，风格被定义为文本的情感，它已经在输入数据中被标注。</p><h2 id="bef7" class="ng mj iq bd mk nh ni dn mo nj nk dp ms mf nl nm mu mg nn no mw mh np nq my iw bi translated">内容</h2><p id="6cee" class="pw-post-body-paragraph kr ks iq ku b kv na ka kx ky nb kd la mf nc ld le mg nd lh li mh ne ll lm ln ij bi translated">这是一个比较棘手的部分，因为对于内容的真正含义没有明确的定义。为此，作者为每个句子提出了一个词袋特征，它计算句子中的内容词的数量与该句子中总词数量的比率。内容词是所有词，不包括停用词和特定于样式的词。</p><h1 id="078c" class="mi mj iq bd mk ml mm mn mo mp mq mr ms kf mt kg mu ki mv kj mw kl mx km my mz bi translated">可视化样式空间和内容空间</h1><p id="6dc6" class="pw-post-body-paragraph kr ks iq ku b kv na ka kx ky nb kd la mf nc ld le mg nd lh li mh ne ll lm ln ij bi translated">一旦我们训练了系统并学习了内容空间和风格空间，确定潜在表示是否被正确地解开的一种方法是绘制内容空间和风格空间的tSNE。论文中提供的tSNE图如下所示。</p><figure class="lp lq lr ls gt lt gh gi paragraph-image"><div class="gh gi oy"><img src="../Images/ba02efc3c3bfb375790c65e8ed8962ec.png" data-original-src="https://miro.medium.com/v2/resize:fit:892/format:webp/1*-E8HNkWERQRg8QSWxdYQqA.png"/></div><figcaption class="ma mb gj gh gi mc md bd b be z dk translated">TSNE情节分为风格空间和内容空间，详见论文[1]。来源<a class="ae me" href="https://arxiv.org/pdf/1808.04339.pdf" rel="noopener ugc nofollow" target="_blank">链接</a></figcaption></figure><p id="f902" class="pw-post-body-paragraph kr ks iq ku b kv kw ka kx ky kz kd la mf lc ld le mg lg lh li mh lk ll lm ln ij bi translated">从图中我们可以看到，正面和负面的情感数据在风格空间中是明显分开的，但在内容空间中却不是这样，这正是我们的目标。</p><p id="25fa" class="pw-post-body-paragraph kr ks iq ku b kv kw ka kx ky kz kd la mf lc ld le mg lg lh li mh lk ll lm ln ij bi translated">图中另一个重要的观察结果是，如果我们使用传统的基于神经网络的确定性自动编码器，潜在空间不像图中数据点之间的大量空白空间那样平滑和连续，而如果我们使用变分自动编码器，我们看到潜在空间是平滑和连续的。</p><h1 id="3311" class="mi mj iq bd mk ml mm mn mo mp mq mr ms kf mt kg mu ki mv kj mw kl mx km my mz bi translated">结论</h1><p id="0d40" class="pw-post-body-paragraph kr ks iq ku b kv na ka kx ky nb kd la mf nc ld le mg nd lh li mh ne ll lm ln ij bi translated">我希望在这篇文章里。我可以提供很好的见解，从潜在的表现形式来看，解开意味着什么，以及它如何用于文本风格的转换。我还在文本风格转换领域的一篇论文中讨论了一种方法。要找到更多关于文本风格转换的论文，你可以点击这个<a class="ae me" href="https://github.com/fuzhenxin/Style-Transfer-in-Text" rel="noopener ugc nofollow" target="_blank">链接</a>。</p><h1 id="26b4" class="mi mj iq bd mk ml mm mn mo mp mq mr ms kf mt kg mu ki mv kj mw kl mx km my mz bi translated">参考</h1><p id="b771" class="pw-post-body-paragraph kr ks iq ku b kv na ka kx ky nb kd la mf nc ld le mg nd lh li mh ne ll lm ln ij bi translated">[1] Vineet John、Lili Mou、Hareesh Bahuleyan和Olga Vechtomova。2018.文本风格转换的非纠缠表征学习。arXiv预印本arXiv:1808.04339。</p></div></div>    
</body>
</html>