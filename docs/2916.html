<html>
<head>
<title>Much More Quickly and Easily Deploy GPT-2 Using Aitextgen</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">使用Aitextgen更快、更轻松地部署GPT-2</h1>
<blockquote>原文：<a href="https://pub.towardsai.net/much-more-quickly-and-easily-deploy-gpt-2-using-aitextgen-bd1af6fadfc7?source=collection_archive---------3-----------------------#2022-07-07">https://pub.towardsai.net/much-more-quickly-and-easily-deploy-gpt-2-using-aitextgen-bd1af6fadfc7?source=collection_archive---------3-----------------------#2022-07-07</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="66dd" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">通过集成PyTorch、拥抱脸变形金刚和使用Aitextgen的GPT-2，更快地解决您的文本生成问题。</h2></div><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ki"><img src="../Images/048292e090e6b581eaf2fb9e5c1097cd.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*yICwe0tckeSO1nc-u4bSaQ.jpeg"/></div></div><figcaption class="ku kv gj gh gi kw kx bd b be z dk translated">来自Pexels的Andrea Piacquadio</figcaption></figure><h1 id="b022" class="kz la it bd lb lc ld le lf lg lh li lj jz lk ka ll kc lm kd ln kf lo kg lp lq bi translated">Aitextgen简介:</h1><p id="9e1c" class="pw-post-body-paragraph lr ls it lt b lu lv ju lw lx ly jx lz ma mb mc md me mf mg mh mi mj mk ml mm im bi translated">Aitextgen是一个工具，允许开发人员训练和部署人工智能模型来生成文本。它利用<a class="ae ky" href="https://pytorch.org/" rel="noopener ugc nofollow" target="_blank"> PyTorch </a>和<a class="ae ky" href="https://github.com/huggingface/transformers" rel="noopener ugc nofollow" target="_blank">拥抱脸变形金刚</a>使用GPT-2生成文本的能力，并可用于在任何类型的文本数据上训练模型。Aitextgen为训练和部署AI模型提供了一个简单的接口，它还包括几个用于监控和优化模型性能的工具。</p><p id="56fa" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">当Aitextgen通过跨神经网络的集成使用训练(如果应用)来生成文本时，它集成了一种称为迁移学习的技术，这种技术允许模型从更大的预训练模型中学习来完成这项任务(文本生成)。</p><p id="e7f2" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">例如，用户可以提供用于训练模型的训练数据集。随后，该模型可用于生成新文本。</p><h2 id="6f8f" class="ms la it bd lb mt mu dn lf mv mw dp lj ma mx my ll me mz na ln mi nb nc lp nd bi translated">Aitextgen在OpenAI的预训练124米/355米/774米GPT-2模型或EleutherAI的125米/355米GPT近地天体模型上进行微调。此外，您可以选择创建自己的GPT-2/GPT近地天体模型。</h2><p id="8995" class="pw-post-body-paragraph lr ls it lt b lu lv ju lw lx ly jx lz ma mb mc md me mf mg mh mi mj mk ml mm im bi translated">Aitextgen决定与变压器集成，这使得用户可以灵活地实施:</p><blockquote class="ne nf ng"><p id="ea32" class="lr ls nh lt b lu mn ju lw lx mo jx lz ni mp mc md nj mq mg mh nk mr mk ml mm im bi translated">“通过Transformers，Aitextgen保持了与基础包的兼容性，允许您将模型用于其他NLP任务，从HuggingFace模型库中下载定制的GPT-2模型，并上传您自己的模型！此外，它使用包含的generate()函数来对生成的文本进行大量控制"[2]。</p></blockquote><h1 id="54e6" class="kz la it bd lb lc ld le lf lg lh li lj jz lk ka ll kc lm kd ln kf lo kg lp lq bi translated">一些高级用例:</h1><p id="b3b3" class="pw-post-body-paragraph lr ls it lt b lu lv ju lw lx ly jx lz ma mb mc md me mf mg mh mi mj mk ml mm im bi translated">1.生成与培训数据相似的文本。GPT-2已经被用于提高其他机器学习模型的性能，例如用于命名实体识别和文本分类的模型。</p><p id="4ec0" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">2.文本分类。通过激活GPT-2，你可以实现机器翻译，问题回答和摘要。此外，GPT-2可用于生成文本，这些文本可用于创建新文档或改进现有文档。此外，GPT-2可用于为其他机器学习模型提供上下文，使它们更加准确。</p><p id="950d" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">3.信息提取。GPT-2已被证明在语言之间的翻译是有效的，因此，可以用来改善机器翻译系统。此外，GPT-2可用于生成新的翻译，这可用于进一步改善机器翻译系统。</p><p id="c8da" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">4.产生正面或负面的评价。</p><p id="27ec" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">5.总结。GPT-2已被证明在摘要文本方面是有效的，因此，可以用来改进文本摘要系统。此外，GPT-2可用于生成新的摘要，这可用于进一步改进文本摘要系统。</p></div><div class="ab cl nl nm hx nn" role="separator"><span class="no bw bk np nq nr"/><span class="no bw bk np nq nr"/><span class="no bw bk np nq"/></div><div class="im in io ip iq"><p id="b119" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">Aitextgen是开源软件，可以在GitHub上使用(参见参考书目下面的链接)。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ns"><img src="../Images/49a90da06451964715fc1f74df789bab.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*t06fFipygMZjHYib6CaaBw.jpeg"/></div></div><figcaption class="ku kv gj gh gi kw kx bd b be z dk translated">来自Pexels的Tara Winstead</figcaption></figure><h1 id="713c" class="kz la it bd lb lc ld le lf lg lh li lj jz lk ka ll kc lm kd ln kf lo kg lp lq bi translated">实施管道:</h1><h2 id="1cba" class="ms la it bd lb mt mu dn lf mv mw dp lj ma mx my ll me mz na ln mi nb nc lp nd bi translated">安装aitextgen:</h2><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="nt nu l"/></div><figcaption class="ku kv gj gh gi kw kx bd b be z dk translated">aitextgen的要点文件</figcaption></figure><h2 id="d267" class="ms la it bd lb mt mu dn lf mv mw dp lj ma mx my ll me mz na ln mi nb nc lp nd bi translated">要在您的计算机上测试aitextgen，您可以从这里开始:</h2><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="nt nu l"/></div></figure><h2 id="9428" class="ms la it bd lb mt mu dn lf mv mw dp lj ma mx my ll me mz na ln mi nb nc lp nd bi translated">如何加载模型:</h2><p id="0203" class="pw-post-body-paragraph lr ls it lt b lu lv ju lw lx ly jx lz ma mb mc md me mf mg mh mi mj mk ml mm im bi translated">以下是生成参数:</p><ul class=""><li id="ac74" class="nv nw it lt b lu mn lx mo ma nx me ny mi nz mm oa ob oc od bi translated"><code class="fe oe of og oh b">n</code>:要生成的文本数量。</li><li id="7c94" class="nv nw it lt b lu oi lx oj ma ok me ol mi om mm oa ob oc od bi translated"><code class="fe oe of og oh b">max_length</code>:生成文本的最大长度。默认情况下，该数字为200。1024是GPT 2号的长度。2048年是GPT尼奥的长度。</li><li id="6aa9" class="nv nw it lt b lu oi lx oj ma ok me ol mi om mm oa ob oc od bi translated"><code class="fe oe of og oh b">prompt</code>:本声明将包含在答复中；这条语句将是整个输出的开始。</li><li id="56d8" class="nv nw it lt b lu oi lx oj ma ok me ol mi om mm oa ob oc od bi translated"><code class="fe oe of og oh b">temperature</code>:控制文字的“疯狂度”(默认值:0.7)</li><li id="726f" class="nv nw it lt b lu oi lx oj ma ok me ol mi om mm oa ob oc od bi translated"><code class="fe oe of og oh b">top_k</code>:如果非零，将采样的令牌限制为前<em class="nh"> k </em>个值。默认值为0。</li><li id="5365" class="nv nw it lt b lu oi lx oj ma ok me ol mi om mm oa ob oc od bi translated"><code class="fe oe of og oh b">num_beams</code>:如果该数字大于1，则执行波束搜索。</li><li id="b38c" class="nv nw it lt b lu oi lx oj ma ok me ol mi om mm oa ob oc od bi translated"><code class="fe oe of og oh b">repetition_penalty</code>:如果该数字大于1.0，则存在重复惩罚。</li></ul><h2 id="7ee2" class="ms la it bd lb mt mu dn lf mv mw dp lj ma mx my ll me mz na ln mi nb nc lp nd bi translated"><strong class="ak">生成函数:</strong></h2><p id="61bd" class="pw-post-body-paragraph lr ls it lt b lu lv ju lw lx ly jx lz ma mb mc md me mf mg mh mi mj mk ml mm im bi translated">首先，您必须确保有一个对象，如aitextgen，带有一个加载的模型和一个标记器。然后:</p><ul class=""><li id="0378" class="nv nw it lt b lu mn lx mo ma nx me ny mi nz mm oa ob oc od bi translated"><code class="fe oe of og oh b">ai.generate()</code>:生成并打印文本。</li><li id="2fed" class="nv nw it lt b lu oi lx oj ma ok me ol mi om mm oa ob oc od bi translated"><code class="fe oe of og oh b">ai.generate_one()</code>:基于生成的文本返回一个字符串。</li><li id="3996" class="nv nw it lt b lu oi lx oj ma ok me ol mi om mm oa ob oc od bi translated"><code class="fe oe of og oh b">ai.generate_samples()</code>:生成多条文本。</li></ul></div><div class="ab cl nl nm hx nn" role="separator"><span class="no bw bk np nq nr"/><span class="no bw bk np nq nr"/><span class="no bw bk np nq"/></div><div class="im in io ip iq"><p id="8757" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">Hugging Face成立于2015年，是一家总部位于纽约市的公司，旨在让人们轻松找到、使用和分享人工智能模型。该公司的旗舰产品是一个预训练的自然语言处理模型的开源库，开发人员可以使用它来轻松地将文本分类、实体识别和机器翻译等功能添加到他们的应用程序中。拥抱脸的使命是让开发者更容易构建使用人工智能的应用程序。</p><p id="c408" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">PyTorch是一种开源的机器学习能力，它提供了灵活性，特别是对于使用GPU和CPU的深度学习。PyTorch为深度学习提供了广泛的工具，包括自动微分、神经网络和丰富的优化器。PyTorch也是发展最快的深度学习平台之一，贡献者社区不断增长。(来源:<a class="ae ky" href="https://pytorch.org/)" rel="noopener ugc nofollow" target="_blank">https://pytorch.org/)</a></p></div><div class="ab cl nl nm hx nn" role="separator"><span class="no bw bk np nq nr"/><span class="no bw bk np nq nr"/><span class="no bw bk np nq"/></div><div class="im in io ip iq"><p id="f3ac" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">创建Aitextgen的主要动机是“让这项技术更容易使用，并准确展示它的前景和局限性”[4]。</p><p id="dde4" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">好了，伙计们。如果你对我的帖子有任何问题或编辑，请联系我。</p></div><div class="ab cl nl nm hx nn" role="separator"><span class="no bw bk np nq nr"/><span class="no bw bk np nq nr"/><span class="no bw bk np nq"/></div><div class="im in io ip iq"><p id="d5f6" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">参考书目:</p><p id="8432" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">1.Github上的aitextgen。https://github.com/minimaxir/aitextgen<a class="ae ky" href="https://github.com/minimaxir/aitextgen" rel="noopener ugc nofollow" target="_blank"/></p><p id="6418" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">2.aitextgen:<a class="ae ky" href="https://docs.aitextgen.io/" rel="noopener ugc nofollow" target="_blank">https://docs . aitextgen . io</a></p><p id="8637" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">3.pytorch.org。</p><p id="0b9a" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">4.<a class="ae ky" href="https://docs.aitextgen.io/ethics/" rel="noopener ugc nofollow" target="_blank">https://docs.aitextgen.io/ethics/</a></p><p id="baa2" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">5.语言模型是一次性学习者。预印本arXiv:2005.14165。</p><p id="fba0" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">6.语言模型是无人监督的多任务学习者。OpenAI博客。<a class="ae ky" href="https://openai.com/blog/better-language-models/" rel="noopener ugc nofollow" target="_blank">https://openai.com/blog/better-language-models/</a></p><p id="4a8a" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">7.评价阅读理解系统的对立例子。arXiv预印本arXiv:1707.07328。</p><p id="38dc" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">8.小队:机器理解文本的10万+题。arXiv预印本arXiv:1606.05250。</p></div></div>    
</body>
</html>