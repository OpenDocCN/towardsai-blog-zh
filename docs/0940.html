<html>
<head>
<title>CVML Annotation — What it is and How to Convert it?</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">CVML注释-它是什么以及如何转换它？</h1>
<blockquote>原文：<a href="https://pub.towardsai.net/cvml-annotation-what-it-is-and-how-to-convert-it-7b818dc30c9f?source=collection_archive---------5-----------------------#2020-09-17">https://pub.towardsai.net/cvml-annotation-what-it-is-and-how-to-convert-it-7b818dc30c9f?source=collection_archive---------5-----------------------#2020-09-17</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><h2 id="d213" class="io ip iq bd b dl ir is it iu iv iw dk ix translated" aria-label="kicker paragraph"><a class="ae ep" href="https://towardsai.net/p/category/computer-vision" rel="noopener ugc nofollow" target="_blank">计算机视觉</a>，<a class="ae ep" href="https://towardsai.net/p/category/machine-learning/deep-learning" rel="noopener ugc nofollow" target="_blank">深度学习</a></h2><div class=""/><div class=""><h2 id="81cd" class="pw-subtitle-paragraph jw iz iq bd b jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn dk translated">这篇文章是关于CMVL注释格式，以及如何将它们转换成其他注释格式。</h2></div><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div role="button" tabindex="0" class="ku kv di kw bf kx"><div class="gh gi ko"><img src="../Images/071eedb34274bb2ad9589456c39ee825.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*aKj5FgsfjdyWhXCT"/></div></div><figcaption class="la lb gj gh gi lc ld bd b be z dk translated">照片由<a class="ae le" href="https://unsplash.com/@lenin33?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">列宁·艾斯特拉达</a>在<a class="ae le" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上拍摄</figcaption></figure><p id="0006" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">2004年1月，<a class="ae le" href="https://www.researchgate.net/profile/Thor_List" rel="noopener ugc nofollow" target="_blank"><strong class="lh ja"/></a>和<a class="ae le" href="https://www.researchgate.net/profile/Robert_Fisher5" rel="noopener ugc nofollow" target="_blank"><strong class="lh ja">Robert b . Fisher</strong></a><strong class="lh ja">发表了一篇名为<a class="ae le" href="https://www.researchgate.net/publication/220927989_CVML_-_An_XML-based_computer_vision_markup_language" rel="noopener ugc nofollow" target="_blank"><strong class="lh ja"><em class="mb">CVML——一种基于XML的计算机视觉标记语言</em></strong></a><strong class="lh ja"><em class="mb"/></strong>的研究论文。介绍一种新的基于XML的注释格式，名为<strong class="lh ja"> CVML。</strong></strong></p><h2 id="bcc4" class="mc md iq bd me mf mg dn mh mi mj dp mk lo ml mm mn ls mo mp mq lw mr ms mt iw bi translated"><strong class="ak">什么是计算机视觉中的标注？</strong></h2><p id="c3df" class="pw-post-body-paragraph lf lg iq lh b li mu ka lk ll mv kd ln lo mw lq lr ls mx lu lv lw my ly lz ma ij bi translated">注记是对影像数据集的标注，因此可用于训练模型。正确标记图像在计算机视觉任务中非常重要，因为模型将使用这些注释进行学习，错误的标记将使模型不太准确，垃圾进垃圾出。</p><p id="3b55" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">如果你正在读这篇文章，那么你有可能在某个地方遇到过CVML。CVML不是时下流行的业态，在COCO和VOC的时代，它似乎已经迷失了。(你看COCO和VOC <a class="ae le" href="https://towardsdatascience.com/coco-data-format-for-object-detection-a4c5eaf518c5" rel="noopener" target="_blank">在这里</a>)。</p><h2 id="ed43" class="mc md iq bd me mf mg dn mh mi mj dp mk lo ml mm mn ls mo mp mq lw mr ms mt iw bi translated">什么是CVML？</h2><p id="733c" class="pw-post-body-paragraph lf lg iq lh b li mu ka lk ll mv kd ln lo mw lq lr ls mx lu lv lw my ly lz ma ij bi translated">CVML是最早尝试创建一种通用注释格式的人之一，这种格式可以让世界各地的研究人员一起工作。它的创造者将其描述为</p><blockquote class="mz na nb"><p id="7b51" class="lf lg mb lh b li lj ka lk ll lm kd ln nc lp lq lr nd lt lu lv ne lx ly lz ma ij bi translated">随着专门为计算机视觉设计的公共数据接口的引入，人们将能够使兼容的项目更容易地一起工作，如果不是作为一个单元，而是作为更大设置中的模块。一个群体的独特能力将会被其他人获得而不会泄露任何秘密。我们已经创建了一种语言，它可以很容易地与现有的代码相结合，还创建了一个库，如果人们愿意的话，可以在所有主要平台上运行。</p><p id="7815" class="lf lg mb lh b li lj ka lk ll lm kd ln nc lp lq lr nd lt lu lv ne lx ly lz ma ij bi translated">这个接口足够简单，所以没有人需要花太多时间来实现它，足够灵活，可以包含许多可能的功能需求，可扩展，所以每个组可以添加他们自己的附加信息源，最后是部分可解析的。这意味着数据中可能有辅助信息，如果不理解或不期望，可以安全地忽略这些信息。</p></blockquote><h2 id="380f" class="mc md iq bd me mf mg dn mh mi mj dp mk lo ml mm mn ls mo mp mq lw mr ms mt iw bi translated">CVML格式</h2><p id="1f3d" class="pw-post-body-paragraph lf lg iq lh b li mu ka lk ll mv kd ln lo mw lq lr ls mx lu lv lw my ly lz ma ij bi translated">作为一种XML格式，每个项目都可以有自己的CVML格式版本。下面给出的转换代码符合以下格式:</p><pre class="kp kq kr ks gt nf ng nh ni aw nj bi"><span id="0253" class="mc md iq ng b gy nk nl l nm nn">&lt;dataset&gt;<br/>&lt;frame number="772" sec="187" ms="717"&gt;<br/>&lt;objectlist&gt;<br/>&lt;object id="0"&gt;<br/>&lt;orientation&gt;90&lt;/orientation&gt;<br/>&lt;box h="15" w="6" xc="501" yc="100"/&gt;<br/>&lt;appearance&gt;appear&lt;/appearance&gt;<br/>&lt;hypothesislist&gt;<br/>&lt;hypothesis evaluation="1.0" id="1" prev="1.0"&gt;<br/>&lt;type evaluation="1.0"&gt;Traffic Light&lt;/type&gt;<br/>&lt;subtype evaluation="1.0"&gt;go&lt;/subtype&gt;<br/>&lt;/hypothesis&gt;<br/>&lt;/hypothesislist&gt;<br/>&lt;/object&gt;<br/>&lt;/objectlist&gt;<br/>&lt;grouplist&gt;&lt;/grouplist&gt;<br/>&lt;/frame&gt;<br/>&lt;/dataset.</span></pre><p id="3d01" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">根据上面的格式，我们将要求边界框使用<code class="fe no np nq ng b">&lt;box h="15" w="6" xc=”501” yc="100"/&gt;</code>。“h”是高度，“w”是宽度，“xc”和“yc”分别是边界框中心在x和y上的坐标。<br/>和<code class="fe no np nq ng b">&lt;subtype evaluation="1.0"&gt;go&lt;/subtype&gt;</code>为标签。因此，在下面给出的转换代码中，我们将h、w、xc、yc和subtype转换为xmin、ymin、xmax、ymax和label。xmin和ymin是边界框的左上角，xmax和ymax是右下角。</p><h2 id="5641" class="mc md iq bd me mf mg dn mh mi mj dp mk lo ml mm mn ls mo mp mq lw mr ms mt iw bi translated"><strong class="ak">将CVML转换成CSV文件</strong></h2><p id="991a" class="pw-post-body-paragraph lf lg iq lh b li mu ka lk ll mv kd ln lo mw lq lr ls mx lu lv lw my ly lz ma ij bi translated">将CVML转化为。csv文件可以很容易地转换成任何流行的格式，如COCO或VOC。</p><p id="443a" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">步骤1:导入必要的库。</p><pre class="kp kq kr ks gt nf ng nh ni aw nj bi"><span id="0919" class="mc md iq ng b gy nk nl l nm nn">import os<br/>import sys<br/>import numpy as np<br/>import pandas as pd<br/>import xmltodict<br/>import json<br/>from tqdm.notebook import tqdm<br/>import collections</span></pre><p id="1899" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">步骤2:加载注释文件</p><pre class="kp kq kr ks gt nf ng nh ni aw nj bi"><span id="ebc2" class="mc md iq ng b gy nk nl l nm nn">img_dir = &lt;image directory&gt;;<br/>annoFile=&lt;annotation file&gt;;<br/>f = open(annoFile, 'r');<br/>my_xml = f.read();<br/>anno = dict(dict(xmltodict.parse(my_xml))["dataset"])</span></pre><p id="ff0d" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">第三步:进入每个文件，找到包围盒的细节，并把它写在熊猫数据框中。</p><pre class="kp kq kr ks gt nf ng nh ni aw nj bi"><span id="e91c" class="mc md iq ng b gy nk nl l nm nn">combined=[]<br/>count=0;<br/>for frame in tqdm(anno['frame']):<br/>    fname=file_content[count].strip()<br/>    count+=1<br/>    label_str = "";<br/>    width=640<br/>    height=480<br/>    if(type(frame["objectlist"]) ==collections.OrderedDict):<br/>        if(type(frame["objectlist"]['object']) == list):<br/>            for j,i in enumerate(frame['objectlist']['object']):<br/>                x1=max(int(i['box']['<a class="ae le" href="http://twitter.com/xc" rel="noopener ugc nofollow" target="_blank">@xc</a>'])-int(i['box']['<a class="ae le" href="http://twitter.com/w" rel="noopener ugc nofollow" target="_blank">@w</a>'])/2,0)<br/>                y1=max(int(i['box']['<a class="ae le" href="http://twitter.com/yc" rel="noopener ugc nofollow" target="_blank">@yc</a>'])-int(i['box']['<a class="ae le" href="http://twitter.com/h" rel="noopener ugc nofollow" target="_blank">@h</a>'])/2,0)<br/>                x2=min(int(i['box']['<a class="ae le" href="http://twitter.com/xc" rel="noopener ugc nofollow" target="_blank">@xc</a>'])+int(i['box']['<a class="ae le" href="http://twitter.com/w" rel="noopener ugc nofollow" target="_blank">@w</a>'])/2,width)<br/>                y2=min(int(i['box']['<a class="ae le" href="http://twitter.com/yc" rel="noopener ugc nofollow" target="_blank">@yc</a>'])+int(i['box']['<a class="ae le" href="http://twitter.com/h" rel="noopener ugc nofollow" target="_blank">@h</a>'])/2,height)<br/>                label=i['hypothesislist']['hypothesis']['subtype']['#text']<br/>                label_str+=str(x1)+" "+str(y1)+" "+str(x2)+" "+str(y2)+" "+label+" "</span><span id="a44a" class="mc md iq ng b gy nr nl l nm nn">else:<br/>            x1=max(0,int(frame["objectlist"]['object']['box']['<a class="ae le" href="http://twitter.com/xc" rel="noopener ugc nofollow" target="_blank">@xc</a>'])-int(frame["objectlist"]['object']['box']['<a class="ae le" href="http://twitter.com/w" rel="noopener ugc nofollow" target="_blank">@w</a>'])/2)<br/>            y1=max(0,int(frame["objectlist"]['object']['box']['<a class="ae le" href="http://twitter.com/yc" rel="noopener ugc nofollow" target="_blank">@yc</a>'])-int(frame["objectlist"]['object']['box']['<a class="ae le" href="http://twitter.com/h" rel="noopener ugc nofollow" target="_blank">@h</a>'])/2)<br/>            x2=min(width,int(frame["objectlist"]['object']['box']['<a class="ae le" href="http://twitter.com/xc" rel="noopener ugc nofollow" target="_blank">@xc</a>'])+int(frame["objectlist"]['object']['box']['<a class="ae le" href="http://twitter.com/w" rel="noopener ugc nofollow" target="_blank">@w</a>'])/2)<br/>            y2=min(height,int(frame["objectlist"]['object']['box']['<a class="ae le" href="http://twitter.com/yc" rel="noopener ugc nofollow" target="_blank">@yc</a>'])+int(frame["objectlist"]['object']['box']['<a class="ae le" href="http://twitter.com/h" rel="noopener ugc nofollow" target="_blank">@h</a>'])/2)<br/>            label=frame["objectlist"]['object']['hypothesislist']['hypothesis']['subtype']['#text']<br/>            label_str += str(x1)+" "+str(y1)+" "+str(x2)+" "+str(y2)+" " + label<br/>        <br/>    combined.append([fname,label_str.strip()])</span></pre><p id="0870" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">步骤4:将数据帧转换成CSV文件。</p><pre class="kp kq kr ks gt nf ng nh ni aw nj bi"><span id="0505" class="mc md iq ng b gy nk nl l nm nn">df = pd.DataFrame(combined, columns = ['ID', 'Label']);<br/>df.to_csv("train_labels.csv", index=False);</span></pre><p id="3f34" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated"><em class="mb">将其转换为CSV文件后，您可以轻松将其转换为其他格式。</em></p><h2 id="1254" class="mc md iq bd me mf mg dn mh mi mj dp mk lo ml mm mn ls mo mp mq lw mr ms mt iw bi translated">将CSV文件转换为COCO</h2><p id="809d" class="pw-post-body-paragraph lf lg iq lh b li mu ka lk ll mv kd ln lo mw lq lr ls mx lu lv lw my ly lz ma ij bi translated">步骤1:导入库</p><pre class="kp kq kr ks gt nf ng nh ni aw nj bi"><span id="5b11" class="mc md iq ng b gy nk nl l nm nn">import os<br/>import numpy as np <br/>import cv2<br/>import dicttoxml<br/>import xml.etree.ElementTree as ET<br/>from xml.dom.minidom import parseString<br/>from tqdm import tqdm<br/>import shutil<br/>import json<br/>import pandas as pd</span></pre><p id="17ff" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">步骤2:加载CSV文件并设置文件目录。</p><pre class="kp kq kr ks gt nf ng nh ni aw nj bi"><span id="e57c" class="mc md iq ng b gy nk nl l nm nn">root = "./";<br/>img_dir = &lt;image directory&gt;;<br/>anno_file = "train_labels.csv";</span><span id="07e2" class="mc md iq ng b gy nr nl l nm nn">dataset_path = root;<br/>images_folder = root + "/" + img_dir;<br/>annotations_path = root + "/annotations/";</span><span id="dca7" class="mc md iq ng b gy nr nl l nm nn">if not os.path.isdir(annotations_path):<br/>    os.mkdir(annotations_path)<br/>    <br/>input_images_folder = images_folder;<br/>input_annotations_path = root + "/" + anno_file;</span><span id="fd8e" class="mc md iq ng b gy nr nl l nm nn">output_dataset_path = root;<br/>output_image_folder = input_images_folder;<br/>output_annotation_folder = annotations_path;</span><span id="57af" class="mc md iq ng b gy nr nl l nm nn">tmp = img_dir.replace("/", "");<br/>output_annotation_file = output_annotation_folder + "/instances_" + tmp + ".json";<br/>output_classes_file = output_annotation_folder + "/classes.txt";</span><span id="9c6c" class="mc md iq ng b gy nr nl l nm nn">if not os.path.isdir(output_annotation_folder):<br/>    os.mkdir(output_annotation_folder);</span><span id="cda4" class="mc md iq ng b gy nr nl l nm nn">df = pd.read_csv(input_annotations_path);<br/>columns = df.columns</span><span id="d3b1" class="mc md iq ng b gy nr nl l nm nn">delimiter = " ";</span></pre><p id="5113" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">步骤3:创建classes.txt文件，该文件将包含注释文件中存在的所有标签类。</p><pre class="kp kq kr ks gt nf ng nh ni aw nj bi"><span id="29c3" class="mc md iq ng b gy nk nl l nm nn">list_dict = [];<br/>anno = [];<br/>for i in range(len(df)):<br/>    img_name = df[columns[0]][i];<br/>    labels = df[columns[1]][i];<br/>    tmp = str(labels).split(delimiter);<br/>    for j in range(len(tmp)//5):<br/>        label = tmp[j*5+4];<br/>        if(label not in anno):<br/>            anno.append(label);<br/>    anno = sorted(anno)<br/>    <br/>for i in tqdm(range(len(anno))):<br/>    tmp = {};<br/>    tmp["supercategory"] = "master";<br/>    tmp["id"] = i;<br/>    tmp["name"] = anno[i];<br/>    list_dict.append(tmp);</span><span id="fad7" class="mc md iq ng b gy nr nl l nm nn">anno_f = open(output_classes_file, 'w');<br/>for i in range(len(anno)):<br/>    anno_f.write(anno[i] + "\n");<br/>anno_f.close();</span></pre><p id="f021" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">第四步:最后将CSV文件转换成COCO格式。</p><pre class="kp kq kr ks gt nf ng nh ni aw nj bi"><span id="9217" class="mc md iq ng b gy nk nl l nm nn">coco_data = {};<br/>coco_data["type"] = "instances";<br/>coco_data["images"] = [];<br/>coco_data["annotations"] = [];<br/>coco_data["categories"] = list_dict;<br/>image_id = 0;<br/>annotation_id = 0;</span><span id="99f6" class="mc md iq ng b gy nr nl l nm nn">for i in tqdm(range(len(df))):<br/>    img_name = df[columns[0]][i];<br/>    labels = df[columns[1]][i];<br/>    tmp = str(labels).split(delimiter);<br/>    image_in_path = input_images_folder + "/" + img_name;<br/>    img = cv2.imread(image_in_path, 1);<br/>    h, w, c = img.shape;</span><span id="0c6c" class="mc md iq ng b gy nr nl l nm nn">images_tmp = {};<br/>    images_tmp["file_name"] = img_name;<br/>    images_tmp["height"] = h;<br/>    images_tmp["width"] = w;<br/>    images_tmp["id"] = image_id;<br/>    coco_data["images"].append(images_tmp);</span><span id="afe6" class="mc md iq ng b gy nr nl l nm nn">for j in range(len(tmp)//5):<br/>        x1 = float(tmp[j*5+0]);<br/>        y1 = float(tmp[j*5+1]);<br/>        x2 = float(tmp[j*5+2]);<br/>        y2 = float(tmp[j*5+3]);<br/>        label = tmp[j*5+4];<br/>        annotations_tmp = {};<br/>        annotations_tmp["id"] = annotation_id;<br/>        annotation_id += 1;<br/>        annotations_tmp["image_id"] = image_id;<br/>        annotations_tmp["segmentation"] = [];<br/>        annotations_tmp["ignore"] = 0;<br/>        annotations_tmp["area"] = (x2-x1)*(y2-y1);<br/>        annotations_tmp["iscrowd"] = 0;<br/>        annotations_tmp["bbox"] = [x1, y1, x2-x1, y2-y1];<br/>        annotations_tmp["category_id"] = anno.index(label);</span><span id="e220" class="mc md iq ng b gy nr nl l nm nn">coco_data["annotations"].append(annotations_tmp)<br/>    image_id += 1;</span><span id="84f2" class="mc md iq ng b gy nr nl l nm nn">outfile =  open(output_annotation_file, 'w');<br/>json_str = json.dumps(coco_data, indent=4);<br/>outfile.write(json_str);<br/>outfile.close();</span></pre><p id="ea89" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">这就是我在这个博客里的全部内容。我希望这能增加你对CVML的了解。欲了解更多详情，请查看这篇研究论文。</p><p id="5bfc" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">也非常感谢阿披实的所有帮助。</p><p id="a86b" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">感谢您的阅读。</p><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div class="gh gi nu"><img src="../Images/3cffcc23a3bdde0ec87c128b6d0ca8af.png" data-original-src="https://miro.medium.com/v2/resize:fit:684/1*x5_q0fLXelcDMZfA4luH7w.gif"/></div></figure><p id="d65d" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">嗨，我是Rohit。我是BTech。来自印度的最后一年学生。我有机器学习和深度学习的知识。我有兴趣在人工智能和人工智能领域工作。我在Tessellate Imaging公司做计算机视觉实习生。在<a class="ae le" href="https://www.linkedin.com/in/rohit96/" rel="noopener ugc nofollow" target="_blank"> LinkedIn </a>上与我联系。</p></div></div>    
</body>
</html>