<html>
<head>
<title>An Overview of Multilabel Classifications</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">多标签分类综述</h1>
<blockquote>原文：<a href="https://pub.towardsai.net/overview-of-multilabel-classifications-3680fe3833d6?source=collection_archive---------1-----------------------#2020-08-11">https://pub.towardsai.net/overview-of-multilabel-classifications-3680fe3833d6?source=collection_archive---------1-----------------------#2020-08-11</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><figure class="ip iq gp gr ir is gh gi paragraph-image"><div role="button" tabindex="0" class="it iu di iv bf iw"><div class="gh gi io"><img src="../Images/cfe548a8fb3354523c4f7db3fc2ed4b8.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*IMQ7jyacFtBIMQbNGvXGTQ.jpeg"/></div></div><figcaption class="iz ja gj gh gi jb jc bd b be z dk translated">欧文·史密斯在<a class="ae jd" href="https://unsplash.com/collections/1918687/ai-and-machine-learning?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上的照片</figcaption></figure><h2 id="66f0" class="je jf jg bd b dl jh ji jj jk jl jm dk jn translated" aria-label="kicker paragraph"><a class="ae ep" href="https://towardsai.net/p/category/machine-learning" rel="noopener ugc nofollow" target="_blank">机器学习</a></h2><div class=""/><div class=""><h2 id="6168" class="pw-subtitle-paragraph km jp jg bd b kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld dk translated">如何将一个实例划分为多个类？</h2></div><p id="a6b1" class="pw-post-body-paragraph le lf jg lg b lh li kq lj lk ll kt lm ln lo lp lq lr ls lt lu lv lw lx ly lz ij bi translated">我们非常熟悉单标签分类问题。我们通常会遇到二元和多元分类。但是，随着机器学习的应用越来越多，我们面临着不同的问题，如电影类型分类、医疗报告分类和根据某些给定主题的文本分类。使用单标签分类器无法解决这些问题，因为一个实例可能同时属于几个类或标签。例如，一部电影可以同时是动作片和冒险片。这就是多标签分类介入的地方。在本文中，我们将介绍一些处理多标签问题的常用方法，在后面的部分中，我们还将介绍一些应用。</p><p id="dca4" class="pw-post-body-paragraph le lf jg lg b lh li kq lj lk ll kt lm ln lo lp lq lr ls lt lu lv lw lx ly lz ij bi translated">在我们进入方法之前，让我们看一下在这样的问题中使用的度量。</p><h2 id="1e5b" class="ma mb jg bd mc md me dn mf mg mh dp mi ln mj mk ml lr mm mn mo lv mp mq mr jm bi translated">韵律学</h2><p id="b38b" class="pw-post-body-paragraph le lf jg lg b lh ms kq lj lk mt kt lm ln mu lp lq lr mv lt lu lv mw lx ly lz ij bi translated">在二分类或多分类中，我们通常使用准确性作为我们的主要评估指标，此外还有F1得分和ROC度量。在多标签分类中，我们需要不同的度量标准，因为当数据集中的一条记录有多个标签时，结果有可能部分正确或完全正确。</p><p id="21b6" class="pw-post-body-paragraph le lf jg lg b lh li kq lj lk ll kt lm ln lo lp lq lr ls lt lu lv lw lx ly lz ij bi translated">根据问题的不同，有3种主要的度量类别:</p><p id="6e23" class="pw-post-body-paragraph le lf jg lg b lh li kq lj lk ll kt lm ln lo lp lq lr ls lt lu lv lw lx ly lz ij bi translated"><strong class="lg jq"> a .评估分区</strong></p><p id="7ac8" class="pw-post-body-paragraph le lf jg lg b lh li kq lj lk ll kt lm ln lo lp lq lr ls lt lu lv lw lx ly lz ij bi translated"><strong class="lg jq"> b .评估排名</strong></p><p id="ea4d" class="pw-post-body-paragraph le lf jg lg b lh li kq lj lk ll kt lm ln lo lp lq lr ls lt lu lv lw lx ly lz ij bi translated"><strong class="lg jq"> c .使用标签层级</strong></p><h2 id="d081" class="ma mb jg bd mc md me dn mf mg mh dp mi ln mj mk ml lr mm mn mo lv mp mq mr jm bi translated">划分</h2><p id="860f" class="pw-post-body-paragraph le lf jg lg b lh ms kq lj lk mt kt lm ln mu lp lq lr mv lt lu lv mw lx ly lz ij bi translated">为了捕获部分正确性，这种策略对实际标签和预测标签之间的平均差异进行处理。我们从数据集中提取样本，并使用模型预测这些样本。我们一次获得一个样本的实际和预测标记的差异，然后找到所有样本的平均差异。这种方法被称为<strong class="lg jq">基于实例的评估</strong>。</p><p id="0f8d" class="pw-post-body-paragraph le lf jg lg b lh li kq lj lk ll kt lm ln lo lp lq lr ls lt lu lv lw lx ly lz ij bi translated">另一种方法是预测所有的测试数据集，并逐标签评估差异，即，将结果的每个标签视为单个向量，并找出特定标签的预测值和实际值之间的差异。一旦我们发现每个标签的不同之处。我们取误差的平均值。这被称为<strong class="lg jq">基于标签的评估</strong>。</p><p id="b013" class="pw-post-body-paragraph le lf jg lg b lh li kq lj lk ll kt lm ln lo lp lq lr ls lt lu lv lw lx ly lz ij bi translated">因此，我们可以说，基于示例的方法是一种行或样本方式来寻找差异，它将样本的所有预测标签视为一个整体，每次寻找一个样本的差异，而基于标签的方法是一种列或标签方式，它将每个标签视为一个整体，即考虑该特定标签的所有样本的值。我们找到了该标签的预测值和实际值之间的差异，并对所有标签进行了平均。</p><p id="b33e" class="pw-post-body-paragraph le lf jg lg b lh li kq lj lk ll kt lm ln lo lp lq lr ls lt lu lv lw lx ly lz ij bi translated">这种基于标签的独立处理每个标签的方法不能解决不同类别标签之间的相关性。</p><h2 id="f704" class="ma mb jg bd mc md me dn mf mg mh dp mi ln mj mk ml lr mm mn mo lv mp mq mr jm bi translated">1.基于示例的指标</h2><ul class=""><li id="34a5" class="mx my jg lg b lh ms lk mt ln mz lr na lv nb lz nc nd ne nf bi translated"><strong class="lg jq">精确匹配率</strong>:这种方法不考虑部分正确，认为它们是不正确的。因此，它将多标签预测表示为单标签预测。主要问题是它没有区分部分正确和完全不正确。在下面的等式中，Y是实际标签向量，Z是样本'<em class="ng"> i </em>'的预测标签，对从1到n个样本的所有'<em class="ng"> i </em>'求和。它只考虑预测和实际标签向量是否完全相同。</li></ul><pre class="nh ni nj nk gt nl nm nn no aw np bi"><span id="4021" class="ma mb jg nm b gy nq nr l ns nt">MR = np.all(y_pred == y_true, axis=1).mean()</span></pre><figure class="nh ni nj nk gt is gh gi paragraph-image"><div class="gh gi nu"><img src="../Images/0e1e42688102de073e15689ed79bc849.png" data-original-src="https://miro.medium.com/v2/resize:fit:1160/0*gvmx7v9o74hHgupi"/></div><figcaption class="iz ja gj gh gi jb jc bd b be z dk translated"><a class="ae jd" href="https://pdfs.semanticscholar.org/6b56/91db1e3a79af5e3c136d2dd322016a687a0b.pdf" rel="noopener ugc nofollow" target="_blank">来源</a></figcaption></figure><ul class=""><li id="437a" class="mx my jg lg b lh li lk ll ln nv lr nw lv nx lz nc nd ne nf bi translated"><strong class="lg jq">0–1损失:</strong>该方法类似于精确匹配率，由下式给出</li></ul><blockquote class="ny nz oa"><p id="ad6d" class="le lf ng lg b lh li kq lj lk ll kt lm ob lo lp lq oc ls lt lu od lw lx ly lz ij bi translated">1-精确匹配比率</p></blockquote><ul class=""><li id="767e" class="mx my jg lg b lh li lk ll ln nv lr nw lv nx lz nc nd ne nf bi translated"><strong class="lg jq">精度:</strong>通常精度由精度= TP / (TP+FP+FN+TN)给出。对于多标签，定义如下:</li></ul><figure class="nh ni nj nk gt is gh gi paragraph-image"><div class="gh gi oe"><img src="../Images/ffdfec1a033c4538eb6b379508ea6dd2.png" data-original-src="https://miro.medium.com/v2/resize:fit:862/0*NNl77ZfKVpWzhN0S"/></div><figcaption class="iz ja gj gh gi jb jc bd b be z dk translated"><a class="ae jd" href="https://pdfs.semanticscholar.org/6b56/91db1e3a79af5e3c136d2dd322016a687a0b.pdf" rel="noopener ugc nofollow" target="_blank">来源</a></figcaption></figure><p id="7709" class="pw-post-body-paragraph le lf jg lg b lh li kq lj lk ll kt lm ln lo lp lq lr ls lt lu lv lw lx ly lz ij bi translated">在等式中，Z是样本I的预测标记向量，Y是实际标记向量。现在，根据定义，如果预测标记和实际标记相同，则结果被称为真阳性。这里，我们取两个向量的交集，因此，得到的向量只有那些标签为1，其中实际向量和预测向量都为真或1。取向量的模值，我们就得到了数值。</p><p id="4675" class="pw-post-body-paragraph le lf jg lg b lh li kq lj lk ll kt lm ln lo lp lq lr ls lt lu lv lw lx ly lz ij bi translated">比方说，(0，0，1，1，0)-&gt;Z是样本的预测向量，而(0，1，1，1，0)-&gt;Y是实际向量，所以mod(Intersection(Y，Z))=2。</p><p id="6934" class="pw-post-body-paragraph le lf jg lg b lh li kq lj lk ll kt lm ln lo lp lq lr ls lt lu lv lw lx ly lz ij bi translated">对于union，mod(Union(Y，Z))=3。该特定样品的总体部分accuracy=⅔ =0.67，因为它正确分类，3个标签中的2个。如果它错误地预测了一个标签，则联合也会增加，即分母增加，从而降低了准确性。然后，我们找到每个样本的分数，并对集合中的所有样本进行平均。</p><pre class="nh ni nj nk gt nl nm nn no aw np bi"><span id="bd30" class="ma mb jg nm b gy nq nr l ns nt">def Accuracy(y_true, y_pred):</span><span id="028f" class="ma mb jg nm b gy of nr l ns nt">temp = 0</span><span id="eaee" class="ma mb jg nm b gy of nr l ns nt">for i in range(y_true.shape[0]):</span><span id="0bd7" class="ma mb jg nm b gy of nr l ns nt">temp += sum(np.logical_and(y_true[i], y_pred[i])) / sum(np.logical_or(y_true[i], y_pred[i]))</span><span id="1a61" class="ma mb jg nm b gy of nr l ns nt">return temp / y_true.shape[0]</span><span id="c1a1" class="ma mb jg nm b gy of nr l ns nt">Accuracy(y_true, y_pred)</span></pre><ul class=""><li id="806f" class="mx my jg lg b lh li lk ll ln nv lr nw lv nx lz nc nd ne nf bi translated"><strong class="lg jq">精度:</strong>根据定义，精度衡量预测为正类的样本中有多少实际上是正的。由TP/(TP+FP)给出。假阳性是将样本错误地分类为真实的模型。分数修改为:</li></ul><figure class="nh ni nj nk gt is gh gi paragraph-image"><div class="gh gi og"><img src="../Images/bddb4d2eb1ddd4145aa7b05740c62afe.png" data-original-src="https://miro.medium.com/v2/resize:fit:838/0*Q1j2AcEP3LVrg7hm"/></div><figcaption class="iz ja gj gh gi jb jc bd b be z dk translated"><a class="ae jd" href="https://pdfs.semanticscholar.org/6b56/91db1e3a79af5e3c136d2dd322016a687a0b.pdf" rel="noopener ugc nofollow" target="_blank">来源</a></figcaption></figure><p id="acc2" class="pw-post-body-paragraph le lf jg lg b lh li kq lj lk ll kt lm ln lo lp lq lr ls lt lu lv lw lx ly lz ij bi translated">分子给出的标签为1，预测值和实际值都为真。所以真正的好处是。分母给出所有标签为1，其预测值为1。所以，它同时包含了TP和FP。因此，对于一个特定的样本，我们获得取值模数，并对所有样本取平均值。</p><p id="f12c" class="pw-post-body-paragraph le lf jg lg b lh li kq lj lk ll kt lm ln lo lp lq lr ls lt lu lv lw lx ly lz ij bi translated">(0，0，1，1，0)-&gt;Z是样本的预测向量，而(0，1，1，1，0)-&gt;Y是实际向量，因此mod(Intersection(Y，Z))=2。</p><p id="e19d" class="pw-post-body-paragraph le lf jg lg b lh li kq lj lk ll kt lm ln lo lp lq lr ls lt lu lv lw lx ly lz ij bi translated">mod((Z))=2。</p><p id="6395" class="pw-post-body-paragraph le lf jg lg b lh li kq lj lk ll kt lm ln lo lp lq lr ls lt lu lv lw lx ly lz ij bi translated">样本的精度=1，因为这里没有假阳性</p><pre class="nh ni nj nk gt nl nm nn no aw np bi"><span id="540e" class="ma mb jg nm b gy nq nr l ns nt">def Precision(y_true, y_pred):</span><span id="1f12" class="ma mb jg nm b gy of nr l ns nt">temp = 0</span><span id="4b23" class="ma mb jg nm b gy of nr l ns nt">for i in range(y_true.shape[0]):</span><span id="bdb6" class="ma mb jg nm b gy of nr l ns nt">if sum(y_true[i]) == 0:</span><span id="2208" class="ma mb jg nm b gy of nr l ns nt">continue</span><span id="fb37" class="ma mb jg nm b gy of nr l ns nt">temp+= sum(np.logical_and(y_true[i], y_pred[i]))/ sum(y_true[i])</span><span id="5657" class="ma mb jg nm b gy of nr l ns nt">return temp/ y_true.shape[0]</span></pre><ul class=""><li id="38a3" class="mx my jg lg b lh li lk ll ln nv lr nw lv nx lz nc nd ne nf bi translated"><strong class="lg jq">召回:</strong>根据定义，召回由TP/TP+FN给出，即它决定了数据集中实际为真的样本中有多少被模型预测为真。修改为:</li></ul><figure class="nh ni nj nk gt is gh gi paragraph-image"><div class="gh gi oh"><img src="../Images/786f078547364ae7a238cad4cc4da07e.png" data-original-src="https://miro.medium.com/v2/resize:fit:766/0*wvatgERJr-9d3I1O"/></div><figcaption class="iz ja gj gh gi jb jc bd b be z dk translated"><a class="ae jd" href="https://pdfs.semanticscholar.org/6b56/91db1e3a79af5e3c136d2dd322016a687a0b.pdf" rel="noopener ugc nofollow" target="_blank">来源</a></figcaption></figure><p id="4999" class="pw-post-body-paragraph le lf jg lg b lh li kq lj lk ll kt lm ln lo lp lq lr ls lt lu lv lw lx ly lz ij bi translated">因此，正如我们所见，分子给出真阳性，分母给出所有标签为1，对于给定的样本，这实际上是真的。</p><p id="9091" class="pw-post-body-paragraph le lf jg lg b lh li kq lj lk ll kt lm ln lo lp lq lr ls lt lu lv lw lx ly lz ij bi translated">(0，0，1，1，0)-&gt;Z是样本的预测向量，而(0，1，1，1，0)-&gt;Y是实际向量，因此mod(Intersection(Y，Z))=2。</p><p id="16b7" class="pw-post-body-paragraph le lf jg lg b lh li kq lj lk ll kt lm ln lo lp lq lr ls lt lu lv lw lx ly lz ij bi translated">mod((Y))=3。</p><p id="d00c" class="pw-post-body-paragraph le lf jg lg b lh li kq lj lk ll kt lm ln lo lp lq lr ls lt lu lv lw lx ly lz ij bi translated">召回=0.67的样本，因为有1个假阴性。我们取所有样本的平均值。</p><pre class="nh ni nj nk gt nl nm nn no aw np bi"><span id="c280" class="ma mb jg nm b gy nq nr l ns nt">def Recall(y_true, y_pred):</span><span id="fb7a" class="ma mb jg nm b gy of nr l ns nt">temp = 0</span><span id="ec10" class="ma mb jg nm b gy of nr l ns nt">for i in range(y_true.shape[0]):</span><span id="33f8" class="ma mb jg nm b gy of nr l ns nt">if sum(y_pred[i]) == 0:</span><span id="84bd" class="ma mb jg nm b gy of nr l ns nt">continue</span><span id="e439" class="ma mb jg nm b gy of nr l ns nt">temp+= sum(np.logical_and(y_true[i], y_pred[i]))/ sum(y_pred[i])</span><span id="520d" class="ma mb jg nm b gy of nr l ns nt">return temp/ y_true.shape[0]</span></pre><ul class=""><li id="e637" class="mx my jg lg b lh li lk ll ln nv lr nw lv nx lz nc nd ne nf bi translated"><strong class="lg jq"> F1得分:</strong>它是精度和召回率的调和平均值。可以这样想，计算一个样本的F1分数，然后对所有样本进行平均。它由下式给出:</li></ul><figure class="nh ni nj nk gt is gh gi paragraph-image"><div class="gh gi oi"><img src="../Images/3fc310cd3a31fbb1a8d7bc0cbd4c8e55.png" data-original-src="https://miro.medium.com/v2/resize:fit:612/0*vOHsUz-okdE5eBpc"/></div><figcaption class="iz ja gj gh gi jb jc bd b be z dk translated"><a class="ae jd" href="https://pdfs.semanticscholar.org/6b56/91db1e3a79af5e3c136d2dd322016a687a0b.pdf" rel="noopener ugc nofollow" target="_blank">来源</a></figcaption></figure><ul class=""><li id="0e4f" class="mx my jg lg b lh li lk ll ln nv lr nw lv nx lz nc nd ne nf bi translated"><strong class="lg jq">汉明损失</strong>:汉明损失试图说明模型对特定样本错误预测的任何标签，也就是说，它同时考虑假阳性和假阴性情况。它在此基础上计算每个样本的分数，然后最终求出所有样本的总和。它由下式给出:</li></ul><figure class="nh ni nj nk gt is gh gi paragraph-image"><div role="button" tabindex="0" class="it iu di iv bf iw"><div class="gh gi oj"><img src="../Images/1ee7bafa2d87179e0c2f73226ee049a4.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*97LamXQLiU5iLmmu"/></div></div><figcaption class="iz ja gj gh gi jb jc bd b be z dk translated"><a class="ae jd" href="https://pdfs.semanticscholar.org/6b56/91db1e3a79af5e3c136d2dd322016a687a0b.pdf" rel="noopener ugc nofollow" target="_blank">来源</a></figcaption></figure><p id="c425" class="pw-post-body-paragraph le lf jg lg b lh li kq lj lk ll kt lm ln lo lp lq lr ls lt lu lv lw lx ly lz ij bi translated">所以，这里k是样本I的类或标签的数量，I是指示函数。首先，对于样本“I ”,该方程迭代1到k中l的所有标签“l”。然后，它试图找到预测值与实际值不匹配的标签“l”。它将所有误差相加，然后除以标签的数量。</p><p id="54b0" class="pw-post-body-paragraph le lf jg lg b lh li kq lj lk ll kt lm ln lo lp lq lr ls lt lu lv lw lx ly lz ij bi translated">(0，0，1，1，1)-&gt;Z是样本的预测向量，而(0，1，1，1，0)-&gt;Y是实际向量。</p><p id="8979" class="pw-post-body-paragraph le lf jg lg b lh li kq lj lk ll kt lm ln lo lp lq lr ls lt lu lv lw lx ly lz ij bi translated">对于给定的样本，对于索引0处的标注分类，它们匹配，因此，误差=0，在第二个索引处发现不匹配，因为l表示Y=1，l表示Z=0。因此，逻辑and为等式中的第二个条件给出1。因此，总的来说，整个样本给出了⅖的汉明损失，因为在5个标签上有2个错配。该分数是所有给定样本的平均值。</p><p id="f0fb" class="pw-post-body-paragraph le lf jg lg b lh li kq lj lk ll kt lm ln lo lp lq lr ls lt lu lv lw lx ly lz ij bi translated">汉明损失=0表示没有错误。</p><pre class="nh ni nj nk gt nl nm nn no aw np bi"><span id="0e6a" class="ma mb jg nm b gy nq nr l ns nt">def Hamming_Loss(y_true, y_pred):</span><span id="a66a" class="ma mb jg nm b gy of nr l ns nt">temp=0</span><span id="c435" class="ma mb jg nm b gy of nr l ns nt">for i in range(y_true.shape[0]):</span><span id="560f" class="ma mb jg nm b gy of nr l ns nt">temp += np.size(y_true[i] == y_pred[i]) — np.count_nonzero(y_true[i] == y_pred[i])</span><span id="0be0" class="ma mb jg nm b gy of nr l ns nt">return temp/(y_true.shape[0] * y_true.shape[1])</span><span id="ae82" class="ma mb jg nm b gy of nr l ns nt">Hamming_Loss(y_true, y_pred)</span></pre><h2 id="af69" class="ma mb jg bd mc md me dn mf mg mh dp mi ln mj mk ml lr mm mn mo lv mp mq mr jm bi translated">2.基于标签的指标</h2><p id="920c" class="pw-post-body-paragraph le lf jg lg b lh ms kq lj lk mt kt lm ln mu lp lq lr mv lt lu lv mw lx ly lz ij bi translated">基于标签分别测量所有标签。如果有k个标签，它认为该评估是对k个不同的二元分类结果的评估。因此，任何测量准确度、精确度、召回率、F1分数的单位或程序都可以用于每个标签，无需任何修改。然后我们取所有标签的平均值。主要有两种方法:</p><ul class=""><li id="f180" class="mx my jg lg b lh li lk ll ln nv lr nw lv nx lz nc nd ne nf bi translated"><strong class="lg jq">宏观平均测度:</strong>按照上述逻辑，即首先计算每个标签的测度。然后我们取所有标签的平均值。它由下式给出:</li></ul><figure class="nh ni nj nk gt is gh gi paragraph-image"><div class="gh gi ok"><img src="../Images/50f4bbf37751165e1896d4cef7164d5b.png" data-original-src="https://miro.medium.com/v2/resize:fit:732/0*BJNfymHH0g9LH52Y"/></div><figcaption class="iz ja gj gh gi jb jc bd b be z dk translated"><a class="ae jd" href="https://pdfs.semanticscholar.org/6b56/91db1e3a79af5e3c136d2dd322016a687a0b.pdf" rel="noopener ugc nofollow" target="_blank">来源</a></figcaption></figure><p id="0192" class="pw-post-body-paragraph le lf jg lg b lh li kq lj lk ll kt lm ln lo lp lq lr ls lt lu lv lw lx ly lz ij bi translated">对于每个标签，计算精确度、召回率和F1分数，然后我们取所有类别或标签(k)的平均值。</p><ul class=""><li id="3e63" class="mx my jg lg b lh li lk ll ln nv lr nw lv nx lz nc nd ne nf bi translated"><strong class="lg jq">微平均测量</strong>:分别取每个标签的真阳性、假阳性、真阴性和假阴性，然后计算精度、召回率和F1值。它由下式给出:</li></ul><figure class="nh ni nj nk gt is gh gi paragraph-image"><div class="gh gi ol"><img src="../Images/1ac1f39399bb2bca37963bd6046858d2.png" data-original-src="https://miro.medium.com/v2/resize:fit:836/0*Hfnbr8BhpWnN8P3E"/></div><figcaption class="iz ja gj gh gi jb jc bd b be z dk translated"><a class="ae jd" href="https://pdfs.semanticscholar.org/6b56/91db1e3a79af5e3c136d2dd322016a687a0b.pdf" rel="noopener ugc nofollow" target="_blank">来源</a></figcaption></figure><figure class="nh ni nj nk gt is gh gi paragraph-image"><div class="gh gi om"><img src="../Images/1eebe6952c1f0d84c0edce102a65fd59.png" data-original-src="https://miro.medium.com/v2/resize:fit:976/0*cbjaTfPzhKWq-qS2"/></div><figcaption class="iz ja gj gh gi jb jc bd b be z dk translated"><a class="ae jd" href="https://pdfs.semanticscholar.org/6b56/91db1e3a79af5e3c136d2dd322016a687a0b.pdf" rel="noopener ugc nofollow" target="_blank">来源</a></figcaption></figure><p id="712d" class="pw-post-body-paragraph le lf jg lg b lh li kq lj lk ll kt lm ln lo lp lq lr ls lt lu lv lw lx ly lz ij bi translated">这里n是样本总数。存在k个类别标签。Y表示实际的输出标签组，Z表示预测的输出标签组。这里的区别是所有标签的总和是外部总和。内部求和对从1到n的所有样本求和。对于第j个标签，子怡是第I个样本的真阳性，依此类推。</p><blockquote class="ny nz oa"><p id="5a24" class="le lf ng lg b lh li kq lj lk ll kt lm ob lo lp lq oc ls lt lu od lw lx ly lz ij bi translated">对于2个标签，微精度由下式给出:(TP1+TP2) / ( TP1+TP2+FP1+FP2)</p><p id="40a5" class="le lf ng lg b lh li kq lj lk ll kt lm ob lo lp lq oc ls lt lu od lw lx ly lz ij bi translated">对于2个标签，微召回率为:(TP1+TP2) / ( TP1+TP2+FN1+FN2)</p></blockquote><h2 id="428b" class="ma mb jg bd mc md me dn mf mg mh dp mi ln mj mk ml lr mm mn mo lv mp mq mr jm bi translated">数据集属性</h2><p id="9f02" class="pw-post-body-paragraph le lf jg lg b lh ms kq lj lk mt kt lm ln mu lp lq lr mv lt lu lv mw lx ly lz ij bi translated">在开始对数据集进行操作之前，我们需要分析数据及其分布。对于多标签，这是基于:</p><ol class=""><li id="ac1d" class="mx my jg lg b lh li lk ll ln nv lr nw lv nx lz on nd ne nf bi translated"><strong class="lg jq">不同标签集(DL) </strong>:由数据集中观察到的不同标签组合的总数给出。它解释了不同标签的分布。</li><li id="b9fc" class="mx my jg lg b lh oo lk op ln oq lr or lv os lz on nd ne nf bi translated"><strong class="lg jq">标签基数(LCard): </strong>它由每个示例的平均标签数给出。它说明了样品和标签的分布。</li></ol><h2 id="facb" class="ma mb jg bd mc md me dn mf mg mh dp mi ln mj mk ml lr mm mn mo lv mp mq mr jm bi translated">多标签学习</h2><p id="676e" class="pw-post-body-paragraph le lf jg lg b lh ms kq lj lk mt kt lm ln mu lp lq lr mv lt lu lv mw lx ly lz ij bi translated">有两种类型的算法来处理多标签分类:</p><ol class=""><li id="f72b" class="mx my jg lg b lh li lk ll ln nv lr nw lv nx lz on nd ne nf bi translated"><strong class="lg jq">简单的问题转化方法</strong></li><li id="15d4" class="mx my jg lg b lh oo lk op ln oq lr or lv os lz on nd ne nf bi translated"><strong class="lg jq">简单算法适配方法</strong></li></ol><h2 id="e419" class="ma mb jg bd mc md me dn mf mg mh dp mi ln mj mk ml lr mm mn mo lv mp mq mr jm bi translated">问题转化方法:</h2><p id="ec12" class="pw-post-body-paragraph le lf jg lg b lh ms kq lj lk mt kt lm ln mu lp lq lr mv lt lu lv mw lx ly lz ij bi translated">该方法将多标签问题转换为单标签问题，然后使用二元分类器和其他可用的方法进行分类。该类别中值得注意的方法有:</p><ul class=""><li id="eb2a" class="mx my jg lg b lh li lk ll ln nv lr nw lv nx lz nc nd ne nf bi translated">有一些简单的转换方法。我们来讨论其中的一些。</li></ul><figure class="nh ni nj nk gt is gh gi paragraph-image"><div class="gh gi ot"><img src="../Images/022f117e2196d8d758f0cfc63e0b0443.png" data-original-src="https://miro.medium.com/v2/resize:fit:1182/format:webp/1*iQXk00lcdzH_i4YYd2HbOQ.png"/></div><figcaption class="iz ja gj gh gi jb jc bd b be z dk translated">数据样本表</figcaption></figure><p id="688c" class="pw-post-body-paragraph le lf jg lg b lh li kq lj lk ll kt lm ln lo lp lq lr ls lt lu lv lw lx ly lz ij bi translated">我们暂时忽略这些特性</p><ul class=""><li id="ef02" class="mx my jg lg b lh li lk ll ln nv lr nw lv nx lz nc nd ne nf bi translated"><strong class="lg jq">复制转换</strong>:为每个有多个标签的样本创建新的样本。因此，它为每个样本复制特征，并考虑每个标签一次。上表修改为:</li></ul><figure class="nh ni nj nk gt is gh gi paragraph-image"><div class="gh gi ou"><img src="../Images/40303fcc32673f23e8dcb29e60fafb57.png" data-original-src="https://miro.medium.com/v2/resize:fit:370/format:webp/1*CHogBxW9STFzixWFyoMZ2Q.png"/></div></figure><ul class=""><li id="9248" class="mx my jg lg b lh li lk ll ln nv lr nw lv nx lz nc nd ne nf bi translated"><strong class="lg jq">称为复制转换:</strong>它类似于复制转换，不同之处在于标签也分配了权重。</li></ul><figure class="nh ni nj nk gt is gh gi paragraph-image"><div class="gh gi ov"><img src="../Images/cd32fab763e06200bca6bf3f4298524d.png" data-original-src="https://miro.medium.com/v2/resize:fit:584/format:webp/1*Wfdt0r7TrgXjh5skVeVgtg.png"/></div></figure><p id="6e0a" class="pw-post-body-paragraph le lf jg lg b lh li kq lj lk ll kt lm ln lo lp lq lr ls lt lu lv lw lx ly lz ij bi translated">权重实际上是1/(样本中值为1的标签数)。</p><ul class=""><li id="81cf" class="mx my jg lg b lh li lk ll ln nv lr nw lv nx lz nc nd ne nf bi translated">下一种方法是从一组标签中选择一个标签，该标签对于特定的样本具有值1。基于选择的过程，有3个选择</li></ul><ol class=""><li id="7c20" class="mx my jg lg b lh li lk ll ln nv lr nw lv nx lz on nd ne nf bi translated">选择最大</li><li id="1c36" class="mx my jg lg b lh oo lk op ln oq lr or lv os lz on nd ne nf bi translated">选择最小值</li><li id="bdaf" class="mx my jg lg b lh oo lk op ln oq lr or lv os lz on nd ne nf bi translated">选择随机</li></ol><ul class=""><li id="41b5" class="mx my jg lg b lh li lk ll ln nv lr nw lv nx lz nc nd ne nf bi translated"><strong class="lg jq">忽略</strong>:忽略多标签数据。因此，这里的最终数据集将只有示例2。</li><li id="9025" class="mx my jg lg b lh oo lk op ln oq lr or lv os lz nc nd ne nf bi translated"><strong class="lg jq"> Label Powerset(LP): </strong>它为不同的标签组合创建新标签。因此，它创建了一个多类分类。对于我们的数据集，它被修改为:</li></ul><figure class="nh ni nj nk gt is gh gi paragraph-image"><div class="gh gi ow"><img src="../Images/c04c0981c85410d8a6d0101aa3d8b1af.png" data-original-src="https://miro.medium.com/v2/resize:fit:1168/format:webp/1*76MVdMMQV7RrRTYHGiIWEw.png"/></div></figure><p id="70a2" class="pw-post-body-paragraph le lf jg lg b lh li kq lj lk ll kt lm ln lo lp lq lr ls lt lu lv lw lx ly lz ij bi translated">其中l5是l2和l3的组合，以此类推。可以创建的标签数量的上限由min( n，2^k)给出，其中n是示例的数量，k是标签的数量。2^k考虑了使用给定的基本k标签可以形成的所有给定的组合。所以，这是最坏的情况，也就是例子的数量，因为如果你只有10个例子，你不可能有2⁴= 16种组合。</p><p id="9351" class="pw-post-body-paragraph le lf jg lg b lh li kq lj lk ll kt lm ln lo lp lq lr ls lt lu lv lw lx ly lz ij bi translated">这种方法的问题是，它创建了高度不平衡的集合，因为一些组合可能出现的次数很少，甚至可能只有一次或两次，所以这些新的级别将被严重低估。</p><p id="0131" class="pw-post-body-paragraph le lf jg lg b lh li kq lj lk ll kt lm ln lo lp lq lr ls lt lu lv lw lx ly lz ij bi translated">为了解决这个问题，使用了一个<strong class="lg jq">修剪问题转换</strong>，它接受一个用户阈值，比如一个标签在一个给定的例子集中必须出现至少4次。如果4次都没有找到标签，则忽略该标签。</p><ul class=""><li id="141d" class="mx my jg lg b lh li lk ll ln nv lr nw lv nx lz nc nd ne nf bi translated"><strong class="lg jq">二元关联:</strong>这种方法最常用。它为每个标签创建k个数据集。因此，它基本上将k类多标记分类转化为k个不相交的二元分类。我们的数据集被修改为:</li></ul><figure class="nh ni nj nk gt is gh gi paragraph-image"><div class="gh gi nu"><img src="../Images/78364b49112b88c7cacd94da1a285e1f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1160/format:webp/1*Gbchv3kS3LEcTm7yttUS6A.png"/></div></figure><p id="b896" class="pw-post-body-paragraph le lf jg lg b lh li kq lj lk ll kt lm ln lo lp lq lr ls lt lu lv lw lx ly lz ij bi translated">在获得每个二元分类的转换结果之后，我们对每个样本的结果进行联合，并获得我们的多类分类的结果。由于基于标签独立性的假设，这种方法受到了批评。它对每个类别使用k个不同的模型，因此每个预测都是相互独立的。</p><ul class=""><li id="ac2d" class="mx my jg lg b lh li lk ll ln nv lr nw lv nx lz nc nd ne nf bi translated"><strong class="lg jq">通过成对比较排序:</strong>它从k个给定标签中创建kC2(组合)数据集。因此，它选择标签Li和标签Lj，这样i &lt; j &lt; k将它们组合在一起形成一个新标签。如果示例至少属于集合中的任一个，但不属于两个集合，则每个数据集保留来自原始集合的示例。</li></ul><figure class="nh ni nj nk gt is gh gi paragraph-image"><div role="button" tabindex="0" class="it iu di iv bf iw"><div class="gh gi ox"><img src="../Images/8984bc05e7f3f84b1af9ac124ed10d88.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*mcgSOlV__V7ZHIWq"/></div></div><figcaption class="iz ja gj gh gi jb jc bd b be z dk translated"><a class="ae jd" href="https://pdfs.semanticscholar.org/6b56/91db1e3a79af5e3c136d2dd322016a687a0b.pdf" rel="noopener ugc nofollow" target="_blank">来源</a></figcaption></figure><h2 id="5ecc" class="ma mb jg bd mc md me dn mf mg mh dp mi ln mj mk ml lr mm mn mo lv mp mq mr jm bi translated">算法适应方法</h2><p id="5bf2" class="pw-post-body-paragraph le lf jg lg b lh ms kq lj lk mt kt lm ln mu lp lq lr mv lt lu lv mw lx ly lz ij bi translated">这些方法试图修改用于单标签分类的常见算法(如支持向量机和决策树)的定义，使其适用于多标签分类。</p><p id="3955" class="pw-post-body-paragraph le lf jg lg b lh li kq lj lk ll kt lm ln lo lp lq lr ls lt lu lv lw lx ly lz ij bi translated">损失函数Log Loss或二进制交叉熵是分类问题中最常用的损失函数，它被修改为:</p><figure class="nh ni nj nk gt is gh gi paragraph-image"><div class="gh gi oy"><img src="../Images/7272e79ce55202b03d63abdf4cfb543d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1170/0*Fp6nSon6fOBD13ct"/></div><figcaption class="iz ja gj gh gi jb jc bd b be z dk translated"><a class="ae jd" href="https://pdfs.semanticscholar.org/6b56/91db1e3a79af5e3c136d2dd322016a687a0b.pdf" rel="noopener ugc nofollow" target="_blank">来源</a></figcaption></figure><p id="ab94" class="pw-post-body-paragraph le lf jg lg b lh li kq lj lk ll kt lm ln lo lp lq lr ls lt lu lv lw lx ly lz ij bi translated"><em class="ng">其中，P(λj ) =类λj的概率。</em>因此，它计算每个标签的损失，类似于它对正常的单标签二进制分类所做的，然后对所有标签的所有损失求和以给出最终损失。</p><p id="c15d" class="pw-post-body-paragraph le lf jg lg b lh li kq lj lk ll kt lm ln lo lp lq lr ls lt lu lv lw lx ly lz ij bi translated">主要有三种方式:</p><ol class=""><li id="b536" class="mx my jg lg b lh li lk ll ln nv lr nw lv nx lz on nd ne nf bi translated"><strong class="lg jq">基于树的提升:</strong>该算法集中于修改在树的梯度提升中使用的AdaBoost算法，以产生多个标签数据的结果。有两种类型的修改:AdaBoost。MH试图通过最小化汉明损失和AdaBoost进行分类。</li></ol><p id="d249" class="pw-post-body-paragraph le lf jg lg b lh li kq lj lk ll kt lm ln lo lp lq lr ls lt lu lv lw lx ly lz ij bi translated">Adaboost算法通常在三个要点上工作，这与随机森林算法不同:</p><ul class=""><li id="9c51" class="mx my jg lg b lh li lk ll ln nv lr nw lv nx lz nc nd ne nf bi translated">Adaboost算法适用于<strong class="lg jq">样本</strong>或弱决策树学习器。它们有一个根，也就是说，它们一次只能使用其中一个特征来预测标签。它们不是我们在随机森林算法中使用的成年树。</li><li id="0ab2" class="mx my jg lg b lh oo lk op ln oq lr or lv os lz nc nd ne nf bi translated">在AdaBoost中，森林中不同的树被赋予不同的权重，即所有的树对最终结果或预测没有相同的发言权或影响力，这与随机森林不同，在随机森林中，所有的树都有相同的权重来决定结果。</li><li id="9d07" class="mx my jg lg b lh oo lk op ln oq lr or lv os lz nc nd ne nf bi translated">Adaboost中的树从以前的错误中学习。所以，它们是相互依赖的，依赖于树木形成的顺序，不像随机森林，树木是相互独立的。</li></ul><p id="e707" class="pw-post-body-paragraph le lf jg lg b lh li kq lj lk ll kt lm ln lo lp lq lr ls lt lu lv lw lx ly lz ij bi translated"><strong class="lg jq"> 2。懒惰学习:</strong>懒惰学习基于K近邻方法。他们可以研究问题转换和算法适应方法。对于问题转化，最常用的懒惰学习方法是BR-KNN。这是一个使用二进制相关性将多标签分类转换为单标签分类，然后应用KNN的过程。</p><p id="db0c" class="pw-post-body-paragraph le lf jg lg b lh li kq lj lk ll kt lm ln lo lp lq lr ls lt lu lv lw lx ly lz ij bi translated"><strong class="lg jq"> 3。神经网络:</strong>神经网络的反向传播算法已经被修改以适应多标签问题。损失函数实际上被修改以考虑跨多个标签的误差。这种方法被称为<em class="ng"> BP-MLL。</em></p><p id="7ba6" class="pw-post-body-paragraph le lf jg lg b lh li kq lj lk ll kt lm ln lo lp lq lr ls lt lu lv lw lx ly lz ij bi translated"><strong class="lg jq"> 4。判别SVM方法:</strong>普通的SVM方法在第一步中使用二进制相关方法来获得k个标签中的每一个标签的二进制分类的结果。然后，它通过k个附加特征扩展数据集，这些特征实际上是第一步中二元分类器的预测。在下一步中，“k”个新的二元分类器，每个k个标签一个。新的分类器在扩展的数据集上训练，以考虑标签的依赖性。还有其他类似<em class="ng"> BandSVM的方法。</em></p><h2 id="c19f" class="ma mb jg bd mc md me dn mf mg mh dp mi ln mj mk ml lr mm mn mo lv mp mq mr jm bi translated">其他可用的方法</h2><ol class=""><li id="9d62" class="mx my jg lg b lh ms lk mt ln mz lr na lv nb lz on nd ne nf bi translated"><strong class="lg jq"> One-Vs-Rest: </strong>这种方法非常类似于二元相关性方法。它将所有k个标签视为互斥的，并为k个标签中的每个标签训练具有相同超参数的不同模型。因此，模型是独立训练的，并且不考虑不同标签之间的相关性。它产生了独立的二进制分类问题。</li><li id="2546" class="mx my jg lg b lh oo lk op ln oq lr or lv os lz on nd ne nf bi translated"><strong class="lg jq">分类器链:</strong>它们考虑了k个标签之间的依赖性或相关性。它为k个标签创建k个二元分类器。第一个二元分类器接受数据集并预测第一个标签。假设预测是C1。对于下一个分类标签，使用第二个二元分类器。对于第二个，我们传递特征集加上C1，即第一个分类器输出的分类器输出。比如说，它给了C2。对于第三个标签分类器，我们馈送，所有特征+C1+C2。因此，对于第n个标签的分类，我们通过实际上是前n-1个类别的预测标签的n-1个特征来扩展特征集。</li></ol><figure class="nh ni nj nk gt is gh gi paragraph-image"><div class="gh gi oz"><img src="../Images/d81c10ed174c6557359f01d718d9426d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1196/0*v3XPziA23tbPzLfi"/></div><figcaption class="iz ja gj gh gi jb jc bd b be z dk translated"><a class="ae jd" href="https://www.researchgate.net/publication/336148903_Multi-Label_Classification_of_Blurbs_with_SVM_Classifier_Chains/figures?lo=1" rel="noopener ugc nofollow" target="_blank">来源</a></figcaption></figure><h2 id="f5e4" class="ma mb jg bd mc md me dn mf mg mh dp mi ln mj mk ml lr mm mn mo lv mp mq mr jm bi translated">应用</h2><p id="2e33" class="pw-post-body-paragraph le lf jg lg b lh ms kq lj lk mt kt lm ln mu lp lq lr mv lt lu lv mw lx ly lz ij bi translated">现在，我们来看看上述算法在python中的应用。</p><p id="737d" class="pw-post-body-paragraph le lf jg lg b lh li kq lj lk ll kt lm ln lo lp lq lr ls lt lu lv lw lx ly lz ij bi translated">对于应用程序，我使用了kaggle的有毒评论分类数据集，此处<a class="ae jd" href="https://www.kaggle.com/c/jigsaw-toxic-comment-classification-challenge" rel="noopener ugc nofollow" target="_blank">可用</a>。这是最常用的数据集之一。我们继续。</p><h2 id="a293" class="ma mb jg bd mc md me dn mf mg mh dp mi ln mj mk ml lr mm mn mo lv mp mq mr jm bi translated">数据可视化</h2><p id="dd91" class="pw-post-body-paragraph le lf jg lg b lh ms kq lj lk mt kt lm ln mu lp lq lr mv lt lu lv mw lx ly lz ij bi translated">在可视化中，数据如下所示:</p><figure class="nh ni nj nk gt is gh gi paragraph-image"><div class="gh gi pa"><img src="../Images/d292db27ff19052139d4ae47cf3ec91f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1226/format:webp/1*Lo3FCMep9F7oN_64pmfnNA.png"/></div></figure><p id="f4a9" class="pw-post-body-paragraph le lf jg lg b lh li kq lj lk ll kt lm ln lo lp lq lr ls lt lu lv lw lx ly lz ij bi translated">它有6个类别，其中每个语句都必须进行分类。这些类别是:</p><pre class="nh ni nj nk gt nl nm nn no aw np bi"><span id="beb8" class="ma mb jg nm b gy nq nr l ns nt">Index(['comment_text', 'toxic', 'severe_toxic', 'obscene', 'threat', 'insult',<br/>       'identity_hate'],<br/>      dtype='object')</span></pre><p id="52e1" class="pw-post-body-paragraph le lf jg lg b lh li kq lj lk ll kt lm ln lo lp lq lr ls lt lu lv lw lx ly lz ij bi translated">尽管如此，这些职业并没有很好的平衡。与其他类别相比,“有毒”类别的出现率非常高。</p><figure class="nh ni nj nk gt is gh gi paragraph-image"><div class="gh gi og"><img src="../Images/a7903dd2b94c1b35752d17772801cf8a.png" data-original-src="https://miro.medium.com/v2/resize:fit:838/format:webp/1*0bGBi3SYMW84CGqmYKfiDg.png"/></div></figure><p id="1f91" class="pw-post-body-paragraph le lf jg lg b lh li kq lj lk ll kt lm ln lo lp lq lr ls lt lu lv lw lx ly lz ij bi translated">现在，这里需要注意的一点是6个标签之间的相关性。</p><figure class="nh ni nj nk gt is gh gi paragraph-image"><div role="button" tabindex="0" class="it iu di iv bf iw"><div class="gh gi pb"><img src="../Images/61fb7bfe877d1a5b773cda8b6a30191d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*qLNWQbghi5YOzFDf6q2PdQ.png"/></div></div></figure><p id="20eb" class="pw-post-body-paragraph le lf jg lg b lh li kq lj lk ll kt lm ln lo lp lq lr ls lt lu lv lw lx ly lz ij bi translated">上图显示了标签之间的相互关系。我们可以观察到‘淫秽’类和‘有毒’类会有很高的相关性。</p><h2 id="5907" class="ma mb jg bd mc md me dn mf mg mh dp mi ln mj mk ml lr mm mn mo lv mp mq mr jm bi translated">数据预处理</h2><p id="c87f" class="pw-post-body-paragraph le lf jg lg b lh ms kq lj lk mt kt lm ln mu lp lq lr mv lt lu lv mw lx ly lz ij bi translated">“comment_text”列将是我们的功能集。</p><pre class="nh ni nj nk gt nl nm nn no aw np bi"><span id="e380" class="ma mb jg nm b gy nq nr l ns nt">0    Explanation\nWhy the edits made under my usern...<br/>1    D'aww! He matches this background colour I'm s...<br/>2    Hey man, I'm really not trying to edit war. It...<br/>3    "\nMore\nI can't make any real suggestions on ...<br/>4    You, sir, are my hero. Any chance you remember...<br/>Name: comment_text, dtype: object</span></pre><p id="76b4" class="pw-post-body-paragraph le lf jg lg b lh li kq lj lk ll kt lm ln lo lp lq lr ls lt lu lv lw lx ly lz ij bi translated">原始文本有几个特殊的字符和缩写，我们需要创建干净的文本来适应一个模型。</p><pre class="nh ni nj nk gt nl nm nn no aw np bi"><span id="7c3b" class="ma mb jg nm b gy nq nr l ns nt">import re<br/>def remove_special_characters(text):<br/>    text=text.lower()<br/>    pattern=r'[^a-zA-Z0-9 ]'<br/>    text = re.sub(r"what's", "what is ", text)<br/>    text = re.sub(r"\'s", " ", text)<br/>    text = re.sub(r"\'ve", " have ", text)<br/>    text = re.sub(r"can't", "cannot ", text)<br/>    text = re.sub(r"n't", " not ", text)<br/>    text = re.sub(r"i'm", "i am ", text)<br/>    text = re.sub(r"\'re", " are ", text)<br/>    text = re.sub(r"\'d", " would ", text)<br/>    text = re.sub(r"\'ll", " will ", text)<br/>    text = re.sub(r"\'scuse", " excuse ", text)<br/>    text = re.sub('\W', ' ', text)<br/>    text = re.sub('\s+', ' ', text)<br/>    text=re.sub(pattern,'',text)<br/>    <br/>    return text<br/>def new_line_r(text):<br/>    pattern=r'\n'<br/>    text=re.sub(pattern,'',text)<br/>    return text<br/>import nltk<br/>from nltk.tokenize import sent_tokenize, word_tokenize <br/>from nltk.corpus import stopwords<br/>def remove_stop(text):<br/>    stop_words = stopwords.words('english')<br/>    cleaned=''<br/>    words=word_tokenize(text) <br/>    for word in words:<br/>        if word not in stop_words:<br/>            cleaned=cleaned+word+' '<br/>    return cleaned</span></pre><p id="9542" class="pw-post-body-paragraph le lf jg lg b lh li kq lj lk ll kt lm ln lo lp lq lr ls lt lu lv lw lx ly lz ij bi translated">上面的代码片段可以用来清理我们的特性集。它从我们输入的句子中删除缩写、特殊字符和停用词。</p><pre class="nh ni nj nk gt nl nm nn no aw np bi"><span id="643b" class="ma mb jg nm b gy nq nr l ns nt">0    explanation edits made username hardcore metal...<br/>1    aww matches background colour seemingly stuck ...<br/>2    hey man really trying edit war guy constantly ...<br/>3    make real suggestions improvement wondered sec...<br/>4                       sir hero chance remember page <br/>Name: cleaned_text, dtype: object</span></pre><p id="9f4b" class="pw-post-body-paragraph le lf jg lg b lh li kq lj lk ll kt lm ln lo lp lq lr ls lt lu lv lw lx ly lz ij bi translated">我们清理过的文本看起来不错。</p><p id="d95d" class="pw-post-body-paragraph le lf jg lg b lh li kq lj lk ll kt lm ln lo lp lq lr ls lt lu lv lw lx ly lz ij bi translated">接下来，我们对文本进行矢量化，并为模型创建训练集和测试集。</p><pre class="nh ni nj nk gt nl nm nn no aw np bi"><span id="bf20" class="ma mb jg nm b gy nq nr l ns nt">X=df_final['cleaned_text']<br/>Y=df_final.drop(['cleaned_text'],axis=1)</span><span id="77bf" class="ma mb jg nm b gy of nr l ns nt">from sklearn.model_selection import train_test_split<br/>X_train, X_test, Y_train, Y_test= train_test_split(X,Y, test_size=0.3)<br/>from sklearn.feature_extraction.text import TfidfVectorizer<br/>vectorizer=TfidfVectorizer(max_features=500,stop_words='english')<br/>vectorizer.fit(X_train)<br/>x_train=vectorizer.transform(X_train)<br/>x_test=vectorizer.transform(X_test)</span></pre><p id="425f" class="pw-post-body-paragraph le lf jg lg b lh li kq lj lk ll kt lm ln lo lp lq lr ls lt lu lv lw lx ly lz ij bi translated">该代码片段创建了所需的集合。</p><h2 id="c58c" class="ma mb jg bd mc md me dn mf mg mh dp mi ln mj mk ml lr mm mn mo lv mp mq mr jm bi translated">模型</h2><p id="4f8c" class="pw-post-body-paragraph le lf jg lg b lh ms kq lj lk mt kt lm ln mu lp lq lr mv lt lu lv mw lx ly lz ij bi translated">首先，让我们为每个标签单独训练一个模型，将每个标签视为一个二元分类，并专门检查准确性，以便获得每个标签性能的基线视图。</p><pre class="nh ni nj nk gt nl nm nn no aw np bi"><span id="0e85" class="ma mb jg nm b gy nq nr l ns nt">from sklearn.linear_model import LogisticRegression<br/>from sklearn.metrics import accuracy_score<br/>labels=Y_train.columns<br/>log_reg=LogisticRegression()<br/>for label in labels:<br/>    y_train_f=Y_train[label]<br/>    y_test_f=Y_test[label]<br/>    log_reg.fit(x_train,y_train_f)<br/>    y_pred=log_reg.predict(x_test)<br/>    acc=accuracy_score(y_test_f,y_pred)<br/>    print("For label {}: accuracy obtained: {}".format(label,acc))</span></pre><p id="66d9" class="pw-post-body-paragraph le lf jg lg b lh li kq lj lk ll kt lm ln lo lp lq lr ls lt lu lv lw lx ly lz ij bi translated">上面的代码片段为我们提供了每个标签的精度。</p><pre class="nh ni nj nk gt nl nm nn no aw np bi"><span id="3a49" class="ma mb jg nm b gy nq nr l ns nt">For label toxic: accuracy obtained: 0.9416569184491979<br/>For label severe_toxic: accuracy obtained: 0.9901403743315508<br/>For label obscene: accuracy obtained: 0.9752882687165776<br/>For label threat: accuracy obtained: 0.997033756684492<br/>For label insult: accuracy obtained: 0.96563753342246<br/>For label identity_hate: accuracy obtained: 0.991769719251337</span></pre><p id="be8c" class="pw-post-body-paragraph le lf jg lg b lh li kq lj lk ll kt lm ln lo lp lq lr ls lt lu lv lw lx ly lz ij bi translated">现在，我们转向多标签分类。</p><h2 id="e5b7" class="ma mb jg bd mc md me dn mf mg mh dp mi ln mj mk ml lr mm mn mo lv mp mq mr jm bi translated">问题转化</h2><h2 id="a595" class="ma mb jg bd mc md me dn mf mg mh dp mi ln mj mk ml lr mm mn mo lv mp mq mr jm bi translated">二元相关性</h2><pre class="nh ni nj nk gt nl nm nn no aw np bi"><span id="1097" class="ma mb jg nm b gy nq nr l ns nt">from skmultilearn.problem_transform import BinaryRelevance<br/>classifier = BinaryRelevance(<br/>    classifier = LogisticRegression(),<br/>)<br/>classifier.fit(x_train, Y_train)<br/>y_pred=classifier.predict(x_test)<br/>acc=accuracy_score(Y_test,y_pred)</span></pre><p id="1ca6" class="pw-post-body-paragraph le lf jg lg b lh li kq lj lk ll kt lm ln lo lp lq lr ls lt lu lv lw lx ly lz ij bi translated">该模型给出了91.11%的准确度分数</p><h2 id="db1f" class="ma mb jg bd mc md me dn mf mg mh dp mi ln mj mk ml lr mm mn mo lv mp mq mr jm bi translated">分类器链</h2><pre class="nh ni nj nk gt nl nm nn no aw np bi"><span id="65fa" class="ma mb jg nm b gy nq nr l ns nt">from skmultilearn.problem_transform import ClassifierChain<br/>from sklearn.linear_model import LogisticRegression<br/>chain_classifier = ClassifierChain(LogisticRegression())<br/>chain_classifier.fit(x_train,Y_train)<br/>y_pred = chain_classifier.predict(x_test)<br/>acc=accuracy_score(Y_test, y_pred)</span></pre><p id="7114" class="pw-post-body-paragraph le lf jg lg b lh li kq lj lk ll kt lm ln lo lp lq lr ls lt lu lv lw lx ly lz ij bi translated">分类器链产生91.26%的准确度</p><h2 id="affe" class="ma mb jg bd mc md me dn mf mg mh dp mi ln mj mk ml lr mm mn mo lv mp mq mr jm bi translated">标签电源集</h2><pre class="nh ni nj nk gt nl nm nn no aw np bi"><span id="cfb1" class="ma mb jg nm b gy nq nr l ns nt">from skmultilearn.problem_transform import LabelPowerset<br/>pw_set_class = LabelPowerset(LogisticRegression())<br/>pw_set_class.fit(x_train,Y_train)<br/>y_pred=pw_set_class.predict(x_test)<br/>acc=accuracy_score(Y_test, y_pred)</span></pre><p id="4000" class="pw-post-body-paragraph le lf jg lg b lh li kq lj lk ll kt lm ln lo lp lq lr ls lt lu lv lw lx ly lz ij bi translated">准确率:91.28%</p><h2 id="61b0" class="ma mb jg bd mc md me dn mf mg mh dp mi ln mj mk ml lr mm mn mo lv mp mq mr jm bi translated">自适应算法</h2><p id="637b" class="pw-post-body-paragraph le lf jg lg b lh ms kq lj lk mt kt lm ln mu lp lq lr mv lt lu lv mw lx ly lz ij bi translated">在这种情况下，我们将看到如何应用<strong class="lg jq">懒惰学习</strong>来处理应用二进制相关KNN分类器的多标签问题。</p><pre class="nh ni nj nk gt nl nm nn no aw np bi"><span id="b514" class="ma mb jg nm b gy nq nr l ns nt">from skmultilearn.adapt import BRkNNaClassifier<br/>lazy_classifier=BRkNNaClassifier()<br/>x_train_a=x_train.toarray()<br/>from scipy.sparse import csr_matrix<br/>y_train_a=csr_matrix(Y_train).toarray()<br/>lazy_classifier.fit(x_train_a, y_train_a)<br/>x_test_a=x_test.toarray()<br/>y_pred=lazy_classifier.predict(x_test_a)</span></pre><h2 id="0342" class="ma mb jg bd mc md me dn mf mg mh dp mi ln mj mk ml lr mm mn mo lv mp mq mr jm bi translated">结论</h2><p id="26b9" class="pw-post-body-paragraph le lf jg lg b lh ms kq lj lk mt kt lm ln mu lp lq lr mv lt lu lv mw lx ly lz ij bi translated">在本文中，我们看到了多标签分类的几种方法</p><p id="5351" class="pw-post-body-paragraph le lf jg lg b lh li kq lj lk ll kt lm ln lo lp lq lr ls lt lu lv lw lx ly lz ij bi translated">这里是Github <a class="ae jd" href="https://github.com/abr-98/Multilabel_Classification_Toxic_Comments" rel="noopener ugc nofollow" target="_blank">链接</a>。</p><p id="4467" class="pw-post-body-paragraph le lf jg lg b lh li kq lj lk ll kt lm ln lo lp lq lr ls lt lu lv lw lx ly lz ij bi translated">希望这篇文章有所帮助。</p><h2 id="9e02" class="ma mb jg bd mc md me dn mf mg mh dp mi ln mj mk ml lr mm mn mo lv mp mq mr jm bi translated">参考</h2><p id="4172" class="pw-post-body-paragraph le lf jg lg b lh ms kq lj lk mt kt lm ln mu lp lq lr mv lt lu lv mw lx ly lz ij bi translated">论文:<a class="ae jd" href="https://pdfs.semanticscholar.org/b3c9/88366e6f80d1cfecbe7f4956e016ac2e498e.pdf" rel="noopener ugc nofollow" target="_blank">https://pdf . semantic scholar . org/b3c 9/88366 E6 f 80 D1 fecbe 7 f 4956 e 016 AC 2 e 498 e . pdf</a></p><p id="18f8" class="pw-post-body-paragraph le lf jg lg b lh li kq lj lk ll kt lm ln lo lp lq lr ls lt lu lv lw lx ly lz ij bi translated">论文:<a class="ae jd" href="https://pdfs.semanticscholar.org/6b56/91db1e3a79af5e3c136d2dd322016a687a0b.pdf" rel="noopener ugc nofollow" target="_blank">https://pdfs . semantic scholar . org/6b 56/91 db 1 E3 a 79 af 5 E3 c 136 D2 DD 322016 a 687 A0 b . pdf</a></p><p id="3be0" class="pw-post-body-paragraph le lf jg lg b lh li kq lj lk ll kt lm ln lo lp lq lr ls lt lu lv lw lx ly lz ij bi translated">指标:<a class="ae jd" href="https://mmuratarat.github.io/2020-01-25/multilabel_classification_metrics.md" rel="noopener ugc nofollow" target="_blank">https://mmuratarat . github . io/2020-01-25/multi label _ classification _ metrics . MD</a></p><p id="7b0b" class="pw-post-body-paragraph le lf jg lg b lh li kq lj lk ll kt lm ln lo lp lq lr ls lt lu lv lw lx ly lz ij bi translated"><a class="ae jd" href="https://arxiv.org/pdf/1912.13405.pdf" rel="noopener ugc nofollow" target="_blank">https://arxiv.org/pdf/1912.13405.pdf</a></p></div></div>    
</body>
</html>