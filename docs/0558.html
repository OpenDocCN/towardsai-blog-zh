<html>
<head>
<title>What’s ‘naive’ about Naive Bayes Classifier?</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">朴素贝叶斯分类器的‘朴素’是什么？</h1>
<blockquote>原文：<a href="https://pub.towardsai.net/whats-naive-about-naive-bayes-classifier-dab83d98dfe0?source=collection_archive---------4-----------------------#2020-06-05">https://pub.towardsai.net/whats-naive-about-naive-bayes-classifier-dab83d98dfe0?source=collection_archive---------4-----------------------#2020-06-05</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><figure class="ip iq gp gr ir is gh gi paragraph-image"><div role="button" tabindex="0" class="it iu di iv bf iw"><div class="gh gi io"><img src="../Images/f6d048c87d699bcbf92d74518807a189.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*_G6_uTQJqUISxd_l1tERrg.jpeg"/></div></div><figcaption class="iz ja gj gh gi jb jc bd b be z dk translated"><a class="ae jd" href="https://www.forestgallery.com/art-insights/naive-art-top-picks/" rel="noopener ugc nofollow" target="_blank">天真的艺术</a></figcaption></figure><h2 id="cec5" class="je jf jg bd b dl jh ji jj jk jl jm dk jn translated" aria-label="kicker paragraph">机器学习</h2><div class=""/><p id="8ec0" class="pw-post-body-paragraph km kn jg ko b kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">朴素贝叶斯分类器是用于分类任务的概率机器学习模型。它可以用来解决任何数量的类的分类问题，并且易于解释。</p><p id="6f27" class="pw-post-body-paragraph km kn jg ko b kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated"><strong class="ko jq">在本文中，我们将讨论朴素贝叶斯分类器背后的数学，分类器的类型，在数据集上的实现，以及它的优点。</strong></p><p id="e4d7" class="pw-post-body-paragraph km kn jg ko b kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">讨论流程如下:</p><ol class=""><li id="a68b" class="lk ll jg ko b kp kq kt ku kx lm lb ln lf lo lj lp lq lr ls bi translated">贝叶斯定理</li><li id="348b" class="lk ll jg ko b kp lt kt lu kx lv lb lw lf lx lj lp lq lr ls bi translated">朴素贝叶斯分类器背后的数学</li><li id="5eb1" class="lk ll jg ko b kp lt kt lu kx lv lb lw lf lx lj lp lq lr ls bi translated">朴素贝叶斯的实现</li><li id="65b9" class="lk ll jg ko b kp lt kt lu kx lv lb lw lf lx lj lp lq lr ls bi translated">朴素贝叶斯的类型</li><li id="6fe9" class="lk ll jg ko b kp lt kt lu kx lv lb lw lf lx lj lp lq lr ls bi translated">朴素贝叶斯的优势</li><li id="3802" class="lk ll jg ko b kp lt kt lu kx lv lb lw lf lx lj lp lq lr ls bi translated">如何改进朴素贝叶斯？</li></ol></div><div class="ab cl ly lz hu ma" role="separator"><span class="mb bw bk mc md me"/><span class="mb bw bk mc md me"/><span class="mb bw bk mc md"/></div><div class="ij ik il im in"><h1 id="9e38" class="mf mg jg bd mh mi mj mk ml mm mn mo mp mq mr ms mt mu mv mw mx my mz na nb nc bi translated">贝叶斯定理:</h1><p id="0888" class="pw-post-body-paragraph km kn jg ko b kp nd kr ks kt ne kv kw kx nf kz la lb ng ld le lf nh lh li lj ij bi translated">朴素贝叶斯源于<strong class="ko jq">统计学</strong>。在了解什么是朴素贝叶斯之前，让我们先看看它的根源。</p><p id="5daf" class="pw-post-body-paragraph km kn jg ko b kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated"><em class="ni">概率</em>是事件发生的几率。从数学上来说，一个事件的概率就是该事件的发生率与所有可能的实验结果的简单比率。</p><p id="8b8a" class="pw-post-body-paragraph km kn jg ko b kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated"><em class="ni">条件概率</em>是在给定另一事件发生的情况下，某一事件发生的概率。</p><figure class="nk nl nm nn gt is gh gi paragraph-image"><div class="gh gi nj"><img src="../Images/df4ce7540ebc31bf13bab11c67de3eae.png" data-original-src="https://miro.medium.com/v2/resize:fit:674/format:webp/1*zYKbCdkVyl3XxlYZCZ0ikg.png"/></div><figcaption class="iz ja gj gh gi jb jc bd b be z dk translated">给定B，A的概率</figcaption></figure><figure class="nk nl nm nn gt is gh gi paragraph-image"><div class="gh gi no"><img src="../Images/23c1c9b4765ba06904ad576e5b910566.png" data-original-src="https://miro.medium.com/v2/resize:fit:644/format:webp/1*3kikmjMBsNEjt4fyfTEuVQ.png"/></div><figcaption class="iz ja gj gh gi jb jc bd b be z dk translated">给定A，B的概率</figcaption></figure><p id="b4ae" class="pw-post-body-paragraph km kn jg ko b kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">结合这两个公式，我们可以很容易地得到，</p><figure class="nk nl nm nn gt is gh gi paragraph-image"><div class="gh gi nj"><img src="../Images/badbb2babaf3dca0fef7ea0f757d92a8.png" data-original-src="https://miro.medium.com/v2/resize:fit:674/format:webp/1*uI11dRXksayRR-s3OpA7dQ.png"/></div><figcaption class="iz ja gj gh gi jb jc bd b be z dk translated">概率A，给定B根据概率B，给定A</figcaption></figure><p id="7092" class="pw-post-body-paragraph km kn jg ko b kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">这就是<strong class="ko jq">贝叶斯定理，</strong>也就是<strong class="ko jq"> </strong>朴素贝叶斯算法的关键。</p></div><div class="ab cl ly lz hu ma" role="separator"><span class="mb bw bk mc md me"/><span class="mb bw bk mc md me"/><span class="mb bw bk mc md"/></div><div class="ij ik il im in"><h1 id="f16e" class="mf mg jg bd mh mi mj mk ml mm mn mo mp mq mr ms mt mu mv mw mx my mz na nb nc bi translated">朴素贝叶斯分类器背后的数学:</h1><p id="a92a" class="pw-post-body-paragraph km kn jg ko b kp nd kr ks kt ne kv kw kx nf kz la lb ng ld le lf nh lh li lj ij bi translated">考虑一个机器学习分类问题。给定一个新的数据点，使用朴素贝叶斯的分类解决方案基于该点在每个类中的概率。</p><p id="d59c" class="pw-post-body-paragraph km kn jg ko b kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">设新点是n维的x，其中每个维分量由x₁,x₂,…xₙ.表示在Cₖ类中，这个n维点“x”的概率由下式给出</p><figure class="nk nl nm nn gt is gh gi paragraph-image"><div class="gh gi np"><img src="../Images/0469154f134a194994c0659e0ae8bc41.png" data-original-src="https://miro.medium.com/v2/resize:fit:668/format:webp/1*TS2DWVFvQ-DZJevX6IsliQ.png"/></div><figcaption class="iz ja gj gh gi jb jc bd b be z dk translated">x成为Cₖ类一部分的概率</figcaption></figure><p id="ff74" class="pw-post-body-paragraph km kn jg ko b kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">P(Cₖ和x)可以表示为，P(Cₖ，x)。而“x”可以用它的n个分量来表示。现在，P (Cₖ和x)被表示为，P(Cₖ,x₁,x₂,…xₙ)</p><p id="ad5f" class="pw-post-body-paragraph km kn jg ko b kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">对我们得到的每个分量应用条件概率，</p><figure class="nk nl nm nn gt is gh gi paragraph-image"><div role="button" tabindex="0" class="it iu di iv bf iw"><div class="gh gi nq"><img src="../Images/b493b90be403d4d14338aff394273946.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*n5l1geMzhcdR9kVMoTyDdA.png"/></div></div></figure><p id="760f" class="pw-post-body-paragraph km kn jg ko b kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">产品中的每一个元素都是一个组件的概率，比如说x₁，给定所有其他特性，x₂,…xₙ和Cₖ.等级</p><p id="5d4c" class="pw-post-body-paragraph km kn jg ko b kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">现在到了Naive Baye分类器的“幼稚”部分。</p><blockquote class="nr"><p id="4f5f" class="ns nt jg bd nu nv nw nx ny nz oa lj dk translated">在Naive Baye的分类器中，假设对于点x，它的每个分量都相互独立于其他分量，并且所有分量对结果都有相同的影响。</p></blockquote><p id="8f4a" class="pw-post-body-paragraph km kn jg ko b kp ob kr ks kt oc kv kw kx od kz la lb oe ld le lf of lh li lj ij bi translated">在这种假设下，产品中的每个元素都变成了，</p><figure class="nk nl nm nn gt is gh gi paragraph-image"><div class="gh gi og"><img src="../Images/b73f1a77b0f4ea746e36b99bf942c33c.png" data-original-src="https://miro.medium.com/v2/resize:fit:824/format:webp/1*hEd1Y3SIxJvsurXKEJPZuA.png"/></div></figure><p id="940b" class="pw-post-body-paragraph km kn jg ko b kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">我们的概率很简单，</p><figure class="nk nl nm nn gt is gh gi paragraph-image"><div class="gh gi oh"><img src="../Images/63dfd76383d89622993bb824e06ee443.png" data-original-src="https://miro.medium.com/v2/resize:fit:950/format:webp/1*oBKbLmCuz9DPi6s29Jw_nw.png"/></div></figure><p id="24e1" class="pw-post-body-paragraph km kn jg ko b kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">点x属于Cₖ类的概率是，</p><figure class="nk nl nm nn gt is gh gi paragraph-image"><div class="gh gi oi"><img src="../Images/e44e49c4539809f741543ec514f160cd.png" data-original-src="https://miro.medium.com/v2/resize:fit:1000/format:webp/1*QbK_xnWwVGsKEFexD6mX9g.png"/></div></figure><p id="c779" class="pw-post-body-paragraph km kn jg ko b kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">其中Z = P(x)</p><p id="5dac" class="pw-post-body-paragraph km kn jg ko b kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">在navies bayes分类器中，我们为所有类别计算x的条件概率，并估计点x属于具有最高P(Cₖ|x).值的Cₖ类别</p></div><div class="ab cl ly lz hu ma" role="separator"><span class="mb bw bk mc md me"/><span class="mb bw bk mc md me"/><span class="mb bw bk mc md"/></div><div class="ij ik il im in"><h1 id="8dba" class="mf mg jg bd mh mi mj mk ml mm mn mo mp mq mr ms mt mu mv mw mx my mz na nb nc bi translated"><strong class="ak">朴素贝叶斯分类器的实现:</strong></h1><p id="678f" class="pw-post-body-paragraph km kn jg ko b kp nd kr ks kt ne kv kw kx nf kz la lb ng ld le lf nh lh li lj ij bi translated">让我们使用Kaggle的<a class="ae jd" href="https://www.kaggle.com/brynja/wineuci" rel="noopener ugc nofollow" target="_blank">葡萄酒分类器</a>问题。</p><h2 id="b3b6" class="oj mg jg bd mh ok ol dn ml om on dp mp kx oo op mt lb oq or mx lf os ot nb jm bi translated">关于数据集:</h2><p id="f26f" class="pw-post-body-paragraph km kn jg ko b kp nd kr ks kt ne kv kw kx nf kz la lb ng ld le lf nh lh li lj ij bi translated">这些数据是对生长在意大利同一地区但来自三个不同品种的葡萄酒进行化学分析的结果。这项分析确定了三种葡萄酒中13种成分的含量。</p><p id="9c92" class="pw-post-body-paragraph km kn jg ko b kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">每个葡萄酒类别的实例数量:</p><ul class=""><li id="17bd" class="lk ll jg ko b kp kq kt ku kx lm lb ln lf lo lj ou lq lr ls bi translated">1级–59级</li><li id="49ba" class="lk ll jg ko b kp lt kt lu kx lv lb lw lf lx lj ou lq lr ls bi translated">2级–71级</li><li id="d9dd" class="lk ll jg ko b kp lt kt lu kx lv lb lw lf lx lj ou lq lr ls bi translated">3级–48级</li></ul><p id="be96" class="pw-post-body-paragraph km kn jg ko b kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">特点:</p><p id="84c5" class="pw-post-body-paragraph km kn jg ko b kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">酒精、苹果酸、灰分、灰分碱度、镁、总酚、类黄酮、非类黄酮酚、原花色素、颜色强度、色调、稀释葡萄酒的OD280/OD315、脯氨酸</p><p id="1709" class="pw-post-body-paragraph km kn jg ko b kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">现在让我们实现朴素贝叶斯分类器，</p><pre class="nk nl nm nn gt ov ow ox oy aw oz bi"><span id="dac2" class="oj mg jg ow b gy pa pb l pc pd">import pandas as pd<br/>features = ['class','alcohol', 'malic_acid', 'ash', 'alcalinity_of_ash', 'magnesium', 'total_phenols', 'flavanoids', 'nonflavanoid_phenols', 'proanthocyanins', 'color_intensity', 'hue', 'od280/od315_of_diluted_wines', 'proline']</span><span id="7315" class="oj mg jg ow b gy pe pb l pc pd">wine_data = pd.read_csv("wine_class.csv",names=features)</span></pre><p id="0867" class="pw-post-body-paragraph km kn jg ko b kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated"><em class="ni">使用pandas将</em>CSV(逗号分隔值)数据加载到数据帧中。</p><pre class="nk nl nm nn gt ov ow ox oy aw oz bi"><span id="dcb9" class="oj mg jg ow b gy pa pb l pc pd">wine_data.head()</span></pre><p id="8b0d" class="pw-post-body-paragraph km kn jg ko b kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">输出:</p><figure class="nk nl nm nn gt is gh gi paragraph-image"><div role="button" tabindex="0" class="it iu di iv bf iw"><div class="gh gi pf"><img src="../Images/f416308dcf3271841a1fa555be1967ec.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Tx-kS13JVtKr4C7vYeAOSA.png"/></div></div></figure><p id="950c" class="pw-post-body-paragraph km kn jg ko b kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">Head()给出了数据帧中的前5个数据点。</p><pre class="nk nl nm nn gt ov ow ox oy aw oz bi"><span id="1559" class="oj mg jg ow b gy pa pb l pc pd">wine_data.shape</span></pre><p id="f1d5" class="pw-post-body-paragraph km kn jg ko b kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">输出:(178，14)</p><p id="b4ce" class="pw-post-body-paragraph km kn jg ko b kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">这意味着葡萄酒数据有178个数据点和14个特征，包括类。</p><pre class="nk nl nm nn gt ov ow ox oy aw oz bi"><span id="36a9" class="oj mg jg ow b gy pa pb l pc pd">wine_target = wine_data['class']<br/>wine_features = wine_data.drop(['class'],axis=1)</span></pre><p id="e037" class="pw-post-body-paragraph km kn jg ko b kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated"><em class="ni">从从属特征中分离出独立特征</em>。</p><pre class="nk nl nm nn gt ov ow ox oy aw oz bi"><span id="5fb2" class="oj mg jg ow b gy pa pb l pc pd">from sklearn.model_selection import train_test_split</span><span id="58bd" class="oj mg jg ow b gy pe pb l pc pd">X_train, X_test, y_train, y_test = train_test_split(wine_features, wine_target, test_size=0.3,random_state=0)</span></pre><p id="c4f1" class="pw-post-body-paragraph km kn jg ko b kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated"><em class="ni">将数据</em>拆分为训练数据和测试数据，其中测试数据占总数据的30%，训练数据占总数据的70%。</p><pre class="nk nl nm nn gt ov ow ox oy aw oz bi"><span id="3e3c" class="oj mg jg ow b gy pa pb l pc pd">#Import Gaussian Naive Bayes model <br/>from sklearn.naive_bayes import GaussianNB <br/> <br/>#Create a Gaussian Classifier <br/>gnb = GaussianNB()</span><span id="fbb3" class="oj mg jg ow b gy pe pb l pc pd">#Train the model using the training sets <br/>gnb.fit(X_train, y_train)</span></pre><p id="f3b9" class="pw-post-body-paragraph km kn jg ko b kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">是的，不管数据大小如何，实现朴素贝叶斯分类器只需要3行代码。</p><p id="5e70" class="pw-post-body-paragraph km kn jg ko b kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">现在我们已经<em class="ni">生成了我们的模型，</em>让我们来测量它的准确性。</p><pre class="nk nl nm nn gt ov ow ox oy aw oz bi"><span id="40bf" class="oj mg jg ow b gy pa pb l pc pd">#Import scikit-learn metrics module for accuracy calculation<br/>from sklearn import metrics</span><span id="303f" class="oj mg jg ow b gy pe pb l pc pd">#Predict the response for test dataset<br/>y_pred = gnb.predict(X_test)</span><span id="4ebb" class="oj mg jg ow b gy pe pb l pc pd"># Model Accuracy, how often is the classifier correct?<br/>print("Accuracy:",metrics.accuracy_score(y_test, y_pred))</span></pre><p id="d3c9" class="pw-post-body-paragraph km kn jg ko b kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">输出:<br/>精度:0.9000000000001</p><p id="8130" class="pw-post-body-paragraph km kn jg ko b kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">我们实现了一个<em class="ni">朴素贝叶斯分类器模型，准确率约为90%。对于葡萄酒分类的问题，精确度是衡量模型性能的合理指标。</em></p></div><div class="ab cl ly lz hu ma" role="separator"><span class="mb bw bk mc md me"/><span class="mb bw bk mc md me"/><span class="mb bw bk mc md"/></div><div class="ij ik il im in"><h1 id="5c09" class="mf mg jg bd mh mi mj mk ml mm mn mo mp mq mr ms mt mu mv mw mx my mz na nb nc bi translated">朴素贝叶斯分类器的类型:</h1><h2 id="be8d" class="oj mg jg bd mh ok ol dn ml om on dp mp kx oo op mt lb oq or mx lf os ot nb jm bi translated">1.高斯朴素贝叶斯</h2><p id="94c5" class="pw-post-body-paragraph km kn jg ko b kp nd kr ks kt ne kv kw kx nf kz la lb ng ld le lf nh lh li lj ij bi translated">当数据是连续的并且假设数据是正态分布时，使用该模型</p><h2 id="cda8" class="oj mg jg bd mh ok ol dn ml om on dp mp kx oo op mt lb oq or mx lf os ot nb jm bi translated"><strong class="ak">②<em class="pg">。伯努利</em> </strong>朴素贝叶斯</h2><p id="f4de" class="pw-post-body-paragraph km kn jg ko b kp nd kr ks kt ne kv kw kx nf kz la lb ng ld le lf nh lh li lj ij bi translated">如果向量是二进制的(即0和1)，这个模型是有用的。一个应用是使用“单词包”模型的文本分类，其中如果单词出现在文档中，1表示<em class="ni">，如果单词没有出现在文档</em>中，0表示<em class="ni"/></p><h2 id="8fb6" class="oj mg jg bd mh ok ol dn ml om on dp mp kx oo op mt lb oq or mx lf os ot nb jm bi translated">3.多元朴素贝叶斯</h2><p id="8ba3" class="pw-post-body-paragraph km kn jg ko b kp nd kr ks kt ne kv kw kx nf kz la lb ng ld le lf nh lh li lj ij bi translated">这个模型类似于Bernoulli Naive Bayes，只是这里的向量表示组件出现的次数。这意味着，如果我们有多个类，这个模型是有用的</p></div><div class="ab cl ly lz hu ma" role="separator"><span class="mb bw bk mc md me"/><span class="mb bw bk mc md me"/><span class="mb bw bk mc md"/></div><div class="ij ik il im in"><h1 id="6e6c" class="mf mg jg bd mh mi mj mk ml mm mn mo mp mq mr ms mt mu mv mw mx my mz na nb nc bi translated">朴素贝叶斯的优势</h1><ol class=""><li id="2678" class="lk ll jg ko b kp nd kt ne kx ph lb pi lf pj lj lp lq lr ls bi translated">这是一种简单、快速、准确的分类方法</li><li id="bea5" class="lk ll jg ko b kp lt kt lu kx lv lb lw lf lx lj lp lq lr ls bi translated">它具有非常低的计算成本</li><li id="72e7" class="lk ll jg ko b kp lt kt lu kx lv lb lw lf lx lj lp lq lr ls bi translated">它可以有效地处理大型数据集</li><li id="417c" class="lk ll jg ko b kp lt kt lu kx lv lb lw lf lx lj lp lq lr ls bi translated">它可用于二元分类或多类分类问题</li><li id="56cc" class="lk ll jg ko b kp lt kt lu kx lv lb lw lf lx lj lp lq lr ls bi translated">当假设成立时，朴素贝叶斯分类器比大多数分类器工作得更好</li></ol><p id="c736" class="pw-post-body-paragraph km kn jg ko b kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">朴素贝叶斯分类器广泛应用于垃圾邮件检测和评论情感分析等文本分类问题。</p></div><div class="ab cl ly lz hu ma" role="separator"><span class="mb bw bk mc md me"/><span class="mb bw bk mc md me"/><span class="mb bw bk mc md"/></div><div class="ij ik il im in"><h1 id="9cae" class="mf mg jg bd mh mi mj mk ml mm mn mo mp mq mr ms mt mu mv mw mx my mz na nb nc bi translated">如何改进朴素贝叶斯？</h1><ul class=""><li id="77ee" class="lk ll jg ko b kp nd kt ne kx ph lb pi lf pj lj ou lq lr ls bi translated">当数据测试数据有一个不同于已训练数据的新类别时，应用“拉普拉斯平滑”</li><li id="ec35" class="lk ll jg ko b kp lt kt lu kx lv lb lw lf lx lj ou lq lr ls bi translated">如果数据不是正态分布，建议将数据更改为正态分布</li><li id="a19f" class="lk ll jg ko b kp lt kt lu kx lv lb lw lf lx lj ou lq lr ls bi translated">移除相关要素，因为它们不会给输出增加任何值</li></ul><p id="37ab" class="pw-post-body-paragraph km kn jg ko b kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">因此，朴素贝叶斯可以有效地用于二元和多类分类问题，而不管数据的大小，并且计算成本低。</p></div><div class="ab cl ly lz hu ma" role="separator"><span class="mb bw bk mc md me"/><span class="mb bw bk mc md me"/><span class="mb bw bk mc md"/></div><div class="ij ik il im in"><p id="b9ae" class="pw-post-body-paragraph km kn jg ko b kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">谢谢你的阅读。我也将在未来写更多初学者友好的帖子。请在<a class="ae jd" href="https://medium.com/@ramyavidiyala" rel="noopener">媒体</a>上关注我，以便了解他们。我欢迎反馈，可以通过Twitter <a class="ae jd" href="https://twitter.com/ramya_vidiyala" rel="noopener ugc nofollow" target="_blank"> ramya_vidiyala </a>和LinkedIn <a class="ae jd" href="https://www.linkedin.com/in/ramya-vidiyala-308ba6139/" rel="noopener ugc nofollow" target="_blank"> RamyaVidiyala </a>联系我。快乐学习！</p></div></div>    
</body>
</html>