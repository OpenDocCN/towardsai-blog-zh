<html>
<head>
<title>Deep learning model to predict mRNA degradation</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">预测mRNA降解的深度学习模型</h1>
<blockquote>原文：<a href="https://pub.towardsai.net/deep-learning-model-to-predict-mrna-degradation-1533a7f32ad4?source=collection_archive---------0-----------------------#2021-09-04">https://pub.towardsai.net/deep-learning-model-to-predict-mrna-degradation-1533a7f32ad4?source=collection_archive---------0-----------------------#2021-09-04</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><h2 id="f46f" class="io ip iq bd b dl ir is it iu iv iw dk ix translated" aria-label="kicker paragraph"><a class="ae ep" href="https://towardsai.net/p/category/machine-learning/deep-learning" rel="noopener ugc nofollow" target="_blank">深度学习</a></h2><div class=""/><p id="e23e" class="pw-post-body-paragraph jw jx iq jy b jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ij bi translated">设计一个深度学习模型，该模型将使用包含3000多个rna分子的Eterna数据集来预测RNA分子每个碱基的降解率。</p><figure class="kv kw kx ky gt kz gh gi paragraph-image"><div role="button" tabindex="0" class="la lb di lc bf ld"><div class="gh gi ku"><img src="../Images/e0b90f9bc193248c8770e9b4e406e510.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*Eu9Kf0PSqTz1IwZF.jpg"/></div></div><figcaption class="lg lh gj gh gi li lj bd b be z dk translated">图片1</figcaption></figure><p id="6bab" class="pw-post-body-paragraph jw jx iq jy b jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ij bi translated">mRNA疫苗处于抗击新冠肺炎疫情病毒的最前沿，但它们也有局限性。信使RNA (mRNA)分子的稳定性问题限制了我们将其包装在一次性注射器中，并使用制冷系统【nih.gov T2】将其分发到世界各地。主要的挑战是设计一种稳定的mRNA疫苗，这种疫苗可以在全球范围内运输，因为一次切割可以使整个疫苗失效。研究人员还发现，mRNA分子往往会快速降解，在这个项目中，我们将设计一个模型来预测降解率，这可以帮助科学家和研究人员在未来设计更稳定的疫苗。目前，为了克服这一问题，我们将这些疫苗冷藏，但这也是有限的，因为这些疫苗在世界上可供更少的人使用。<em class="ll"> OpenVaccine:新冠肺炎mRNA疫苗降解预测</em></p><figure class="kv kw kx ky gt kz gh gi paragraph-image"><div role="button" tabindex="0" class="la lb di lc bf ld"><div class="gh gi lm"><img src="../Images/f191fee23e9ffee959d333f89cd975eb.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*PS_g8vdyoTH5NyRt.png"/></div></div><figcaption class="lg lh gj gh gi li lj bd b be z dk translated">图片2</figcaption></figure><h1 id="4f89" class="ln lo iq bd lp lq lr ls lt lu lv lw lx ly lz ma mb mc md me mf mg mh mi mj mk bi translated">项目目标</h1><p id="9870" class="pw-post-body-paragraph jw jx iq jy b jz ml kb kc kd mm kf kg kh mn kj kk kl mo kn ko kp mp kr ks kt ij bi translated">在这个项目中，我们将探索我们的数据集，然后预处理序列、结构和预测循环类型特征，以便它们可以用于训练我们的深度学习GRU模型。最后预测公共数据集和测试数据集上的退化记录。</p></div><div class="ab cl mq mr hu ms" role="separator"><span class="mt bw bk mu mv mw"/><span class="mt bw bk mu mv mw"/><span class="mt bw bk mu mv"/></div><div class="ij ik il im in"><h1 id="3214" class="ln lo iq bd lp lq mx ls lt lu my lw lx ly mz ma mb mc na me mf mg nb mi mj mk bi translated">做好准备</h1><p id="245d" class="pw-post-body-paragraph jw jx iq jy b jz ml kb kc kd mm kf kg kh mn kj kk kl mo kn ko kp mp kr ks kt ij bi translated">我们将使用<strong class="jy ja"> TensorFlow </strong>作为我们的主库来构建和训练我们的模型，并使用JSON/Pandas来接收数据。为了可视化，我们将使用Plotly和Numpy进行数据操作。</p><pre class="kv kw kx ky gt nc nd ne nf aw ng bi"><span id="4186" class="nh lo iq nd b gy ni nj l nk nl"># Dataframe<br/>import json<br/>import pandas as pd<br/>import numpy as np</span><span id="8767" class="nh lo iq nd b gy nm nj l nk nl"># Visualization<br/>import plotly.express as px</span><span id="b560" class="nh lo iq nd b gy nm nj l nk nl"># Deeplearning<br/>import tensorflow.keras.layers as L<br/>import tensorflow as tf</span><span id="6d7a" class="nh lo iq nd b gy nm nj l nk nl"># Sklearn<br/>from sklearn.model_selection import train_test_split</span><span id="a2c0" class="nh lo iq nd b gy nm nj l nk nl">#Setting seeds<br/>tf.random.set_seed(2021)<br/>np.random.seed(2021)</span></pre><h1 id="6ec2" class="ln lo iq bd lp lq lr ls lt lu lv lw lx ly lz ma mb mc md me mf mg mh mi mj mk bi translated">训练参数</h1><ul class=""><li id="2385" class="nn no iq jy b jz ml kd mm kh np kl nq kp nr kt ns nt nu nv bi translated">目标列:反应性，度毫克pH10，度毫克50C，度pH10，度50C</li><li id="988e" class="nn no iq jy b jz nw kd nx kh ny kl nz kp oa kt ns nt nu nv bi translated">Model_Train:如果要训练一个需要1小时训练的模型，则为True。</li></ul><pre class="kv kw kx ky gt nc nd ne nf aw ng bi"><span id="9f36" class="nh lo iq nd b gy ni nj l nk nl"># This will tell us the columns we are predicting<br/>target_cols = ['reactivity', 'deg_Mg_pH10', 'deg_Mg_50C', 'deg_pH10', 'deg_50C']<br/>Model_Train = True # True if you want to Train model which take 1 hour to train.</span></pre><p id="4ccf" class="pw-post-body-paragraph jw jx iq jy b jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ij bi translated">我们的模型性能度量是<strong class="jy ja"> MCRMSE </strong>(平均列式均方根误差)，它采用所有目标列的真实值的均方根误差。</p><figure class="kv kw kx ky gt kz gh gi paragraph-image"><div role="button" tabindex="0" class="la lb di lc bf ld"><div class="gh gi lm"><img src="../Images/aeb8e98b1e36850ff507d921843f43f3.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*xtGq9Gtp5ZGfO2tm.png"/></div></div></figure><p id="a1d0" class="pw-post-body-paragraph jw jx iq jy b jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ij bi translated">其中，和分别是实际值和预测值。</p><pre class="kv kw kx ky gt nc nd ne nf aw ng bi"><span id="f85c" class="nh lo iq nd b gy ni nj l nk nl">def MCRMSE(y_true, y_pred):## Monte Carlo root mean squared errors <br/>    colwise_mse = tf.reduce_mean(tf.square(y_true - y_pred), axis=1)<br/>    return tf.reduce_mean(tf.sqrt(colwise_mse), axis=1)</span></pre><p id="e63d" class="pw-post-body-paragraph jw jx iq jy b jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ij bi translated">mRNA降解数据可在Kaggle上获得。</p><h1 id="3d3f" class="ln lo iq bd lp lq lr ls lt lu lv lw lx ly lz ma mb mc md me mf mg mh mi mj mk bi translated">列详细说明</h1><ul class=""><li id="01f4" class="nn no iq jy b jz ml kd mm kh np kl nq kp nr kt ns nt nu nv bi translated"><strong class="jy ja"> id </strong> —样本的唯一标识符。</li><li id="a9cd" class="nn no iq jy b jz nw kd nx kh ny kl nz kp oa kt ns nt nu nv bi translated"><strong class="jy ja"> seq_scored </strong> —这应该与反应性、deg_*和<em class="ll">错误</em>栏的长度相匹配。</li><li id="4fd4" class="nn no iq jy b jz nw kd nx kh ny kl nz kp oa kt ns nt nu nv bi translated"><strong class="jy ja">序列长度</strong> —序列的长度。</li><li id="6d1a" class="nn no iq jy b jz nw kd nx kh ny kl nz kp oa kt ns nt nu nv bi translated"><strong class="jy ja">序列</strong> —描述RNA序列，每个样本的A、G、U和C的组合。</li><li id="2d92" class="nn no iq jy b jz nw kd nx kh ny kl nz kp oa kt ns nt nu nv bi translated"><strong class="jy ja">结构</strong> —由(，)和组成的数组。捐献给基地的人物是成对的还是不成对的。</li><li id="701c" class="nn no iq jy b jz nw kd nx kh ny kl nz kp oa kt ns nt nu nv bi translated"><strong class="jy ja">反应性</strong> —这些数字是用于确定RNA样品可能的二级结构的前68个碱基的反应性值。</li><li id="d29c" class="nn no iq jy b jz nw kd nx kh ny kl nz kp oa kt ns nt nu nv bi translated"><strong class="jy ja">deg _ pH10</strong>—pH10在碱基或连接处无镁孵育后降解的可能性。</li><li id="85e7" class="nn no iq jy b jz nw kd nx kh ny kl nz kp oa kt ns nt nu nv bi translated"><strong class="jy ja"> deg_Mg_pH10 </strong> —在碱基或连接处与pH10的镁孵育后降解的可能性。</li><li id="2dcd" class="nn no iq jy b jz nw kd nx kh ny kl nz kp oa kt ns nt nu nv bi translated"><strong class="jy ja"> deg_50C </strong> —底座或连杆在50摄氏度下无镁培养后的降解可能性。</li><li id="6781" class="nn no iq jy b jz nw kd nx kh ny kl nz kp oa kt ns nt nu nv bi translated"><strong class="jy ja"> deg_Mg_50C </strong> —在底座或连杆处与镁在50摄氏度下孵育后降解的可能性。</li><li id="fb0e" class="nn no iq jy b jz nw kd nx kh ny kl nz kp oa kt ns nt nu nv bi translated"><strong class="jy ja"><em class="ll">*</em>_ error _<em class="ll">*</em></strong>—反应性和deg_*栏中获得的实验值的计算误差。</li><li id="4d61" class="nn no iq jy b jz nw kd nx kh ny kl nz kp oa kt ns nt nu nv bi translated"><strong class="jy ja"> predicted_loop_type </strong> —维也纳bpRNA指定的环类型，建议S:成对茎，M:多环，I:内环，B:凸起，H:发夹环，E:悬空端，X:外环</li></ul><h1 id="0ada" class="ln lo iq bd lp lq lr ls lt lu lv lw lx ly lz ma mb mc md me mf mg mh mi mj mk bi translated">观察数据</h1><pre class="kv kw kx ky gt nc nd ne nf aw ng bi"><span id="3fb2" class="nh lo iq nd b gy ni nj l nk nl">data_dir = "stanford-covid-vaccine/"<br/>train = pd.read_json(data_dir + "train.json", lines=True)<br/>test = pd.read_json(data_dir + "test.json", lines=True)<br/>sample_df = pd.read_csv(data_dir + "sample_submission.csv")</span></pre><p id="caf8" class="pw-post-body-paragraph jw jx iq jy b jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ij bi translated">我们有文本格式的序列、结构和预测循环类型。我们将把它们转换成数字符号，以便它们可以用于训练深度学习模型。然后，我们在从反应性_误差到度数_50C的列中有数组，我们将使用它们作为目标。</p><pre class="kv kw kx ky gt nc nd ne nf aw ng bi"><span id="23a3" class="nh lo iq nd b gy ni nj l nk nl">train.head(2)</span><span id="016b" class="nh lo iq nd b gy nm nj l nk nl">print('Train shapes: ', train.shape) print('Test shapes: ', test.shape)</span><span id="ad28" class="nh lo iq nd b gy nm nj l nk nl">Train shapes:  (2400, 19)<br/>Test shapes:  (3634, 7)</span></pre><p id="6823" class="pw-post-body-paragraph jw jx iq jy b jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ij bi translated">测试数据集只有序列、结构、预测循环类型、序列长度、序列得分和id。我们将使用一个测试数据集来预测公共排行榜分数的下降率。</p><h1 id="4295" class="ln lo iq bd lp lq lr ls lt lu lv lw lx ly lz ma mb mc md me mf mg mh mi mj mk bi translated">信噪比分布</h1><p id="fc4f" class="pw-post-body-paragraph jw jx iq jy b jz ml kb kc kd mm kf kg kh mn kj kk kl mo kn ko kp mp kr ks kt ij bi translated">我们可以看到信噪比分布在0到15之间，大多数样本位于0到6之间。我们也有需要摆脱的负面价值观。</p><pre class="kv kw kx ky gt nc nd ne nf aw ng bi"><span id="13c6" class="nh lo iq nd b gy ni nj l nk nl">fig = px.histogram(<br/>    train, <br/>    "signal_to_noise", <br/>    nbins=25, <br/>    title='signal_to_noise distribution', <br/>    width=800,<br/>    height=400<br/>)<br/>fig.show()</span></pre><figure class="kv kw kx ky gt kz gh gi paragraph-image"><div role="button" tabindex="0" class="la lb di lc bf ld"><div class="gh gi ob"><img src="../Images/d50f2b808378b966780685169b8ef076.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*IJeGeXZzhk5lHbcG.png"/></div></div></figure><pre class="kv kw kx ky gt nc nd ne nf aw ng bi"><span id="8e08" class="nh lo iq nd b gy ni nj l nk nl">train = train.query("signal_to_noise &gt;= 1")</span></pre><h1 id="4870" class="ln lo iq bd lp lq lr ls lt lu lv lw lx ly lz ma mb mc md me mf mg mh mi mj mk bi translated">序列测试长度</h1><p id="2ba5" class="pw-post-body-paragraph jw jx iq jy b jz ml kb kc kd mm kf kg kh mn kj kk kl mo kn ko kp mp kr ks kt ij bi translated">在观察序列长度分布后，我们知道我们有两个不同的序列长度，一个在107，另一个在130。</p><pre class="kv kw kx ky gt nc nd ne nf aw ng bi"><span id="076c" class="nh lo iq nd b gy ni nj l nk nl">fig = px.histogram(<br/>    test, <br/>    "seq_length", <br/>    nbins=25, <br/>    title='sequence_length distribution', <br/>    width=800,<br/>    height=400<br/>)<br/>fig.show()</span></pre><figure class="kv kw kx ky gt kz gh gi paragraph-image"><div role="button" tabindex="0" class="la lb di lc bf ld"><div class="gh gi ob"><img src="../Images/42a221c83f4e84f7ff940349483bbdf4.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*9H60kWqCtOlsNd87.png"/></div></div></figure><h1 id="1c71" class="ln lo iq bd lp lq lr ls lt lu lv lw lx ly lz ma mb mc md me mf mg mh mi mj mk bi translated">将测试分为公共和私有数据帧</h1><p id="a9a8" class="pw-post-body-paragraph jw jx iq jy b jz ml kb kc kd mm kf kg kh mn kj kk kl mo kn ko kp mp kr ks kt ij bi translated">让我们根据序列长度分割我们的测试数据集。这样做将提高我们的GRU模型的整体性能。</p><pre class="kv kw kx ky gt nc nd ne nf aw ng bi"><span id="719f" class="nh lo iq nd b gy ni nj l nk nl">public_df = test.query("seq_length == 107")</span><span id="0058" class="nh lo iq nd b gy nm nj l nk nl">private_df = test.query("seq_length == 130")</span></pre><p id="db04" class="pw-post-body-paragraph jw jx iq jy b jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ij bi translated">创建一个字符到整数的字典，我们将使用它来转换我们的RNA序列，结构和预测循环类型为整数。</p><pre class="kv kw kx ky gt nc nd ne nf aw ng bi"><span id="ee3c" class="nh lo iq nd b gy ni nj l nk nl">token2int = {x: i for i, x in enumerate("().ACGUBEHIMSX")}<br/>token2int</span><span id="c7d4" class="nh lo iq nd b gy nm nj l nk nl"><strong class="nd ja">{'(': 0, ')': 1, '.': 2, 'A': 3, 'C': 4, 'G': 5, 'U': 6, 'B': 7, 'E': 8, 'H': 9, 'I': 10, 'M': 11, 'S': 12, 'X': 13}</strong></span></pre><h1 id="97be" class="ln lo iq bd lp lq lr ls lt lu lv lw lx ly lz ma mb mc md me mf mg mh mi mj mk bi translated">将数据帧转换为3D数组</h1><p id="548e" class="pw-post-body-paragraph jw jx iq jy b jz ml kb kc kd mm kf kg kh mn kj kk kl mo kn ko kp mp kr ks kt ij bi translated">下面的函数获取Pandas数据框并将其转换为3D NumPy数组。我们将使用它来转换培训功能和目标。</p><pre class="kv kw kx ky gt nc nd ne nf aw ng bi"><span id="02f5" class="nh lo iq nd b gy ni nj l nk nl">def dataframe_to_array(df):<br/>   return np.transpose(np.array(df.values.tolist()), (0, 2, 1))</span></pre><h1 id="a253" class="ln lo iq bd lp lq lr ls lt lu lv lw lx ly lz ma mb mc md me mf mg mh mi mj mk bi translated">序列的符号化</h1><p id="1cde" class="pw-post-body-paragraph jw jx iq jy b jz ml kb kc kd mm kf kg kh mn kj kk kl mo kn ko kp mp kr ks kt ij bi translated">下面的函数使用我们之前创建的字符串到整数字典，将训练特征转换为包含整数的数组。然后，我们将使用dataframe_to_array将数据集转换为3D NumPy数组。</p><pre class="kv kw kx ky gt nc nd ne nf aw ng bi"><span id="aa87" class="nh lo iq nd b gy ni nj l nk nl">def dataframe_label_encoding(<br/>    df, token2int, cols=["sequence", "structure", "predicted_loop_type"]<br/>):<br/>    return dataframe_to_array(<br/>        df[cols].applymap(lambda seq: [token2int[x] for x in seq])<br/>    ) ## tokenization of Sequence, Structure, Predicted loop</span></pre><h1 id="1b6e" class="ln lo iq bd lp lq lr ls lt lu lv lw lx ly lz ma mb mc md me mf mg mh mi mj mk bi translated">预处理要素和标签</h1><ul class=""><li id="3aaf" class="nn no iq jy b jz ml kd mm kh np kl nq kp nr kt ns nt nu nv bi translated">在我们的培训功能上使用标签认可功能。</li><li id="f596" class="nn no iq jy b jz nw kd nx kh ny kl nz kp oa kt ns nt nu nv bi translated">将目标数据帧转换为3D数组。</li></ul><pre class="kv kw kx ky gt nc nd ne nf aw ng bi"><span id="fed8" class="nh lo iq nd b gy ni nj l nk nl">train_inputs = dataframe_label_encoding(train, token2int) ## Label encoding<br/>train_labels = dataframe_to_array(train[target_cols]) ## dataframe to 3D array to</span></pre><h1 id="09da" class="ln lo iq bd lp lq lr ls lt lu lv lw lx ly lz ma mb mc md me mf mg mh mi mj mk bi translated">培训和验证分离</h1><p id="fb00" class="pw-post-body-paragraph jw jx iq jy b jz ml kb kc kd mm kf kg kh mn kj kk kl mo kn ko kp mp kr ks kt ij bi translated">将我们的训练数据分成训练集和验证集。我们使用信噪比过滤器来平均分配我们的数据集。</p><pre class="kv kw kx ky gt nc nd ne nf aw ng bi"><span id="1ac2" class="nh lo iq nd b gy ni nj l nk nl">x_train, x_val, y_train, y_val = train_test_split(<br/>    train_inputs, train_labels, test_size=0.1, random_state=34, stratify=train.SN_filter<br/>)</span></pre><h1 id="7d57" class="ln lo iq bd lp lq lr ls lt lu lv lw lx ly lz ma mb mc md me mf mg mh mi mj mk bi translated">预处理公共和私有数据帧</h1><p id="2e3d" class="pw-post-body-paragraph jw jx iq jy b jz ml kb kc kd mm kf kg kh mn kj kk kl mo kn ko kp mp kr ks kt ij bi translated">之前，我们根据序列长度将测试数据集分为公共数据集和私有数据集，现在我们将使用dataframe_label_encoding对其进行标记化和整形，使其成为NumPy数组，就像我们对训练数据集所做的一样。</p><pre class="kv kw kx ky gt nc nd ne nf aw ng bi"><span id="cea1" class="nh lo iq nd b gy ni nj l nk nl">public_inputs = dataframe_label_encoding(public_df, token2int)<br/>private_inputs = dataframe_label_encoding(private_df, token2int)</span></pre><h1 id="ec4a" class="ln lo iq bd lp lq lr ls lt lu lv lw lx ly lz ma mb mc md me mf mg mh mi mj mk bi translated">培训/评估模型</h1><h2 id="5edd" class="nh lo iq bd lp oc od dn lt oe of dp lx kh og oh mb kl oi oj mf kp ok ol mj iw bi translated">建立模型</h2><p id="51e4" class="pw-post-body-paragraph jw jx iq jy b jz ml kb kc kd mm kf kg kh mn kj kk kl mo kn ko kp mp kr ks kt ij bi translated">在直接进入深度学习模型之前，我们已经测试了其他梯度增强，如Light GBM和CatBoost。当我们处理这个序列时，我用BiLSTM模型进行了实验，但是与线性激活的三重GRU模型相比，它们的表现都是最差的。</p><p id="3dce" class="pw-post-body-paragraph jw jx iq jy b jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ij bi translated">这个模型受到了最初模型的影响，我惊讶地发现，在不使用数据增强或特征工程的情况下，简单的GRU图层可以产生尽可能好的结果。</p><p id="9d37" class="pw-post-body-paragraph jw jx iq jy b jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ij bi translated">要了解更多关于RNNs、LSTM和GRU的信息，请参见<a class="ae lk" href="https://colah.github.io/posts/2015-08-Understanding-LSTMs/" rel="noopener ugc nofollow" target="_blank">这篇博文</a>。</p><pre class="kv kw kx ky gt nc nd ne nf aw ng bi"><span id="f380" class="nh lo iq nd b gy ni nj l nk nl">def build_model(<br/>    embed_size, # Length of unique tokens <br/>    seq_len=107, # public dataset seq_len<br/>    pred_len=68, # pred_len for public data<br/>    dropout=0.5, # trying best dropout (general)<br/>    sp_dropout=0.2, # Spatial Dropout<br/>    embed_dim=200, # embedding dimension<br/>    hidden_dim=256, # hidden layer units<br/>):<br/>    inputs = L.Input(shape=(seq_len, 3)) <br/>    embed = L.Embedding(input_dim=embed_size, output_dim=embed_dim)(inputs)<br/>    reshaped = tf.reshape(<br/>        embed, shape=(-1, embed.shape[1], embed.shape[2] * embed.shape[3])<br/>    )<br/>    hidden = L.SpatialDropout1D(sp_dropout)(reshaped)<br/>     # 3X BiGRU layers<br/>    hidden = L.Bidirectional(<br/>        L.GRU(<br/>            hidden_dim,<br/>            dropout=dropout,<br/>            return_sequences=True,<br/>            kernel_initializer="orthogonal",<br/>        )<br/>    )(hidden)<br/>    hidden = L.Bidirectional(<br/>        L.GRU(<br/>            hidden_dim,<br/>            dropout=dropout,<br/>            return_sequences=True,<br/>            kernel_initializer="orthogonal",<br/>        )<br/>    )(hidden)<br/>    hidden = L.Bidirectional(<br/>        L.GRU(<br/>            hidden_dim,<br/>            dropout=dropout,<br/>            return_sequences=True,<br/>            kernel_initializer="orthogonal",<br/>        )<br/>    )(hidden)<br/>    # Since we are only making predictions on the first part of each sequence,<br/>    # we have to truncate it<br/>    truncated = hidden[:, :pred_len]<br/>    out = L.Dense(5, activation="linear")(truncated)<br/>    model = tf.keras.Model(inputs=inputs, outputs=out)<br/>    model.compile(optimizer="Adam", loss=MCRMSE) # loss function as of Eval Metric<br/>    return model</span></pre><h1 id="ec1f" class="ln lo iq bd lp lq lr ls lt lu lv lw lx ly lz ma mb mc md me mf mg mh mi mj mk bi translated">建筑模型</h1><p id="051d" class="pw-post-body-paragraph jw jx iq jy b jz ml kb kc kd mm kf kg kh mn kj kk kl mo kn ko kp mp kr ks kt ij bi translated">通过添加嵌入大小(14)来构建我们的模型，我们将使用其他参数的默认值。</p><ul class=""><li id="d428" class="nn no iq jy b jz ka kd ke kh om kl on kp oo kt ns nt nu nv bi translated">序列长度:107</li><li id="d560" class="nn no iq jy b jz nw kd nx kh ny kl nz kp oa kt ns nt nu nv bi translated">预测长度:68</li><li id="9f07" class="nn no iq jy b jz nw kd nx kh ny kl nz kp oa kt ns nt nu nv bi translated">退学率:0.5</li><li id="28c0" class="nn no iq jy b jz nw kd nx kh ny kl nz kp oa kt ns nt nu nv bi translated">空间落差:0.2</li><li id="fd4a" class="nn no iq jy b jz nw kd nx kh ny kl nz kp oa kt ns nt nu nv bi translated">嵌入尺寸:200</li><li id="f73d" class="nn no iq jy b jz nw kd nx kh ny kl nz kp oa kt ns nt nu nv bi translated">隐藏层尺寸:256</li></ul><pre class="kv kw kx ky gt nc nd ne nf aw ng bi"><span id="ff16" class="nh lo iq nd b gy ni nj l nk nl">model = build_model(<br/>    embed_size=len(token2int) ## embed_size = 14<br/>)  ## uniquie token in sequence, structure, predicted_loop_type<br/>model.summary()</span><span id="c4b8" class="nh lo iq nd b gy nm nj l nk nl">Model: "model"<br/>_________________________________________________________________<br/>Layer (type)                 Output Shape              Param #   <br/>=================================================================<br/>input_1 (InputLayer)         [(None, 107, 3)]          0         <br/>_________________________________________________________________<br/>embedding (Embedding)        (None, 107, 3, 200)       2800      <br/>_________________________________________________________________<br/>tf.reshape (TFOpLambda)      (None, 107, 600)          0         <br/>_________________________________________________________________<br/>spatial_dropout1d (SpatialDr (None, 107, 600)          0         <br/>_________________________________________________________________<br/>bidirectional (Bidirectional (None, 107, 512)          1317888   <br/>_________________________________________________________________<br/>bidirectional_1 (Bidirection (None, 107, 512)          1182720   <br/>_________________________________________________________________<br/>bidirectional_2 (Bidirection (None, 107, 512)          1182720   <br/>_________________________________________________________________<br/>tf.__operators__.getitem (Sl (None, 68, 512)           0         <br/>_________________________________________________________________<br/>dense (Dense)                (None, 68, 5)             2565      <br/>=================================================================<br/>Total params: 3,688,693<br/>Trainable params: 3,688,693<br/>Non-trainable params: 0<br/>_________________________________________________________________</span></pre><h1 id="7985" class="ln lo iq bd lp lq lr ls lt lu lv lw lx ly lz ma mb mc md me mf mg mh mi mj mk bi translated">培训模式</h1><p id="6640" class="pw-post-body-paragraph jw jx iq jy b jz ml kb kc kd mm kf kg kh mn kj kk kl mo kn ko kp mp kr ks kt ij bi translated">我们将为40个时期训练我们的模型，并将模型检查点保存在模型文件夹中。我用16、32、64的批量大小进行了实验，到目前为止，64的批量大小产生了更好的结果和更快的收敛。</p><p id="56b5" class="pw-post-body-paragraph jw jx iq jy b jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ij bi translated">正如我们可以观察到的，训练和验证损失(MCRMSE)随着每一次迭代而减少，直到20个时期，并且从那里它们开始发散。在接下来的实验中，我们将把历元的数量限制在20个以内，以获得更快更好的结果。</p><pre class="kv kw kx ky gt nc nd ne nf aw ng bi"><span id="0ec1" class="nh lo iq nd b gy ni nj l nk nl">if Model_Train:    <br/>    history = model.fit(<br/>        x_train,<br/>        y_train,<br/>        validation_data=(x_val, y_val),<br/>        batch_size=64,<br/>        epochs=40,<br/>        verbose=2,<br/>        callbacks=[<br/>            tf.keras.callbacks.ReduceLROnPlateau(patience=5),<br/>            tf.keras.callbacks.ModelCheckpoint("Model/model.h5"),<br/>        ],<br/>    )<br/>Epoch 1/40<br/>30/30 - 69s - loss: 0.4536 - val_loss: 0.3796<br/>Epoch 2/40<br/>30/30 - 57s - loss: 0.3856 - val_loss: 0.3601<br/>Epoch 3/40<br/>30/30 - 57s - loss: 0.3637 - val_loss: 0.3410<br/>Epoch 4/40<br/>30/30 - 57s - loss: 0.3488 - val_loss: 0.3255<br/>Epoch 5/40<br/>30/30 - 57s - loss: 0.3357 - val_loss: 0.3188<br/>Epoch 6/40<br/>30/30 - 57s - loss: 0.3295 - val_loss: 0.3163<br/>Epoch 7/40<br/>30/30 - 57s - loss: 0.3200 - val_loss: 0.3098<br/>Epoch 8/40<br/>30/30 - 57s - loss: 0.3117 - val_loss: 0.2997<br/>Epoch 9/40<br/>30/30 - 57s - loss: 0.3046 - val_loss: 0.2899<br/>Epoch 10/40<br/>30/30 - 57s - loss: 0.2993 - val_loss: 0.2875<br/>Epoch 11/40<br/>30/30 - 57s - loss: 0.2919 - val_loss: 0.2786<br/>Epoch 12/40<br/>30/30 - 57s - loss: 0.2830 - val_loss: 0.2711<br/>Epoch 13/40<br/>30/30 - 57s - loss: 0.2777 - val_loss: 0.2710<br/>Epoch 14/40<br/>30/30 - 57s - loss: 0.2712 - val_loss: 0.2584<br/>Epoch 15/40<br/>30/30 - 57s - loss: 0.2640 - val_loss: 0.2580<br/>Epoch 16/40<br/>30/30 - 57s - loss: 0.2592 - val_loss: 0.2518<br/>Epoch 17/40<br/>30/30 - 57s - loss: 0.2540 - val_loss: 0.2512<br/>Epoch 18/40<br/>30/30 - 57s - loss: 0.2514 - val_loss: 0.2461<br/>Epoch 19/40<br/>30/30 - 57s - loss: 0.2485 - val_loss: 0.2492<br/>Epoch 20/40<br/>30/30 - 57s - loss: 0.2453 - val_loss: 0.2434<br/>Epoch 21/40<br/>30/30 - 57s - loss: 0.2424 - val_loss: 0.2411<br/>Epoch 22/40<br/>30/30 - 57s - loss: 0.2397 - val_loss: 0.2391<br/>Epoch 23/40<br/>30/30 - 57s - loss: 0.2380 - val_loss: 0.2412<br/>Epoch 24/40<br/>30/30 - 57s - loss: 0.2357 - val_loss: 0.2432<br/>Epoch 25/40<br/>30/30 - 57s - loss: 0.2330 - val_loss: 0.2384<br/>Epoch 26/40<br/>30/30 - 57s - loss: 0.2316 - val_loss: 0.2364<br/>Epoch 27/40<br/>30/30 - 57s - loss: 0.2306 - val_loss: 0.2397<br/>Epoch 28/40<br/>30/30 - 57s - loss: 0.2282 - val_loss: 0.2343<br/>Epoch 29/40<br/>30/30 - 57s - loss: 0.2242 - val_loss: 0.2392<br/>Epoch 30/40<br/>30/30 - 57s - loss: 0.2232 - val_loss: 0.2326<br/>Epoch 31/40<br/>30/30 - 57s - loss: 0.2207 - val_loss: 0.2318<br/>Epoch 32/40<br/>30/30 - 57s - loss: 0.2192 - val_loss: 0.2339<br/>Epoch 33/40<br/>30/30 - 57s - loss: 0.2175 - val_loss: 0.2287<br/>Epoch 34/40<br/>30/30 - 57s - loss: 0.2160 - val_loss: 0.2310<br/>Epoch 35/40<br/>30/30 - 57s - loss: 0.2137 - val_loss: 0.2299<br/>Epoch 36/40<br/>30/30 - 57s - loss: 0.2119 - val_loss: 0.2288<br/>Epoch 37/40<br/>30/30 - 57s - loss: 0.2101 - val_loss: 0.2271<br/>Epoch 38/40<br/>30/30 - 57s - loss: 0.2088 - val_loss: 0.2274<br/>Epoch 39/40<br/>30/30 - 57s - loss: 0.2082 - val_loss: 0.2265<br/>Epoch 40/40<br/>30/30 - 57s - loss: 0.2064 - val_loss: 0.2276</span></pre><h1 id="e83a" class="ln lo iq bd lp lq lr ls lt lu lv lw lx ly lz ma mb mc md me mf mg mh mi mj mk bi translated">评估培训历史</h1><p id="3469" class="pw-post-body-paragraph jw jx iq jy b jz ml kb kc kd mm kf kg kh mn kj kk kl mo kn ko kp mp kr ks kt ij bi translated">验证和训练损失都减少了，直到20个时期。验证损失在35年后变得平缓，所以在我看来，我们应该在20和35个时期测试结果。</p><pre class="kv kw kx ky gt nc nd ne nf aw ng bi"><span id="57a9" class="nh lo iq nd b gy ni nj l nk nl">if Model_Train:     <br/>    fig = px.line(<br/>        history.history,<br/>        y=["loss", "val_loss"],<br/>        labels={"index": "epoch", "value": "MCRMSE"},<br/>        title="History",<br/>    )<br/>    fig.show()</span></pre><figure class="kv kw kx ky gt kz gh gi paragraph-image"><div role="button" tabindex="0" class="la lb di lc bf ld"><div class="gh gi op"><img src="../Images/fd27626fefd732009a8b8e5a9775b8a3.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*1Ldf5B2ahA8iK-fk.png"/></div></div></figure><h1 id="f111" class="ln lo iq bd lp lq lr ls lt lu lv lw lx ly lz ma mb mc md me mf mg mh mi mj mk bi translated">加载模型并进行预测</h1><p id="159f" class="pw-post-body-paragraph jw jx iq jy b jz ml kb kc kd mm kf kg kh mn kj kk kl mo kn ko kp mp kr ks kt ij bi translated">测试数据集被分为具有不同序列长度的公共和私有集，因此为了预测不同长度上的降级，我们需要构建两个不同的模型并加载我们保存的检查点。这是可能的，因为RNN模型可以接受不同长度的序列作为输入。人工智能(https://ai . stack exchange . com/questions/2008/how-can-neural-networks-process-with-varying-input-size)</p><p id="ee09" class="pw-post-body-paragraph jw jx iq jy b jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ij bi translated">我们将建立两个具有不同序列和预测长度的独特模型。我们的公共模型包含107个序列长度，而我们的私有模型包含130个序列长度。我们将把我们节省下来的重量加载到两个模型中，以预测mRNA的降解。</p><pre class="kv kw kx ky gt nc nd ne nf aw ng bi"><span id="aeb8" class="nh lo iq nd b gy ni nj l nk nl">model_public = build_model(seq_len=107, pred_len=107, embed_size=len(token2int))<br/>model_private = build_model(seq_len=130, pred_len=130, embed_size=len(token2int))<br/>model_public.load_weights("Model/model.h5")<br/>model_private.load_weights("Model/model.h5")</span></pre><h2 id="5edb" class="nh lo iq bd lp oc od dn lt oe of dp lx kh og oh mb kl oi oj mf kp ok ol mj iw bi translated">预言；预测；预告</h2><p id="6a24" class="pw-post-body-paragraph jw jx iq jy b jz ml kb kc kd mm kf kg kh mn kj kk kl mo kn ko kp mp kr ks kt ij bi translated">我们已经成功地预测了公共和私有数据集。在下一步中，我们将使用test id来组合它们。</p><pre class="kv kw kx ky gt nc nd ne nf aw ng bi"><span id="3790" class="nh lo iq nd b gy ni nj l nk nl">public_preds = model_public.predict(public_inputs)<br/>private_preds = model_private.predict(private_inputs)</span><span id="6cae" class="nh lo iq nd b gy nm nj l nk nl">private_preds.shape</span><span id="eccc" class="nh lo iq nd b gy nm nj l nk nl">(3005, 130, 5)</span></pre><h1 id="12f9" class="ln lo iq bd lp lq lr ls lt lu lv lw lx ly lz ma mb mc md me mf mg mh mi mj mk bi translated">后处理和提交</h1><p id="7085" class="pw-post-body-paragraph jw jx iq jy b jz ml kb kc kd mm kf kg kh mn kj kk kl mo kn ko kp mp kr ks kt ij bi translated"><strong class="jy ja">将三维数字阵列转换成数据帧:</strong></p><ul class=""><li id="1284" class="nn no iq jy b jz ka kd ke kh om kl on kp oo kt ns nt nu nv bi translated">组合私有和公共数据帧。</li><li id="86ee" class="nn no iq jy b jz nw kd nx kh ny kl nz kp oa kt ns nt nu nv bi translated">基于单个预测序列在id前添加一系列整数，例如<code class="fe oq or os nd b">[id_00073f8be_0,id_00073f8be_1,id_00073f8be_2 ..]</code></li><li id="81d0" class="nn no iq jy b jz nw kd nx kh ny kl nz kp oa kt ns nt nu nv bi translated">将所有数据连接成Pandas数据框架并准备提交。</li></ul><pre class="kv kw kx ky gt nc nd ne nf aw ng bi"><span id="3909" class="nh lo iq nd b gy ni nj l nk nl">preds_ls = []<br/>for df, preds in [(public_df, public_preds), (private_df, private_preds)]:<br/>    for i, uid in enumerate(df.id):<br/>        single_pred = preds[i]<br/>        single_df = pd.DataFrame(single_pred, columns=target_cols)<br/>        single_df["id_seqpos"] = [f"{uid}_{x}" for x in range(single_df.shape[0])]<br/>        preds_ls.append(single_df)<br/>preds_df = pd.concat(preds_ls)</span></pre><p id="eb1d" class="pw-post-body-paragraph jw jx iq jy b jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ij bi translated"><code class="fe oq or os nd b">preds_df.head()</code></p><pre class="kv kw kx ky gt nc nd ne nf aw ng bi"><span id="4c86" class="nh lo iq nd b gy ni nj l nk nl">reactivity deg_Mg_pH10 deg_Mg_50C deg_pH10 deg_50C         id_seqpos<br/>0 0.685760 0.703746 0.585288 1.857178 0.808561 id_00073f8be_0<br/>1 2.158555 3.243329 3.443042 4.394709 3.012130 id_00073f8be_1<br/>2 1.432280 0.674404 0.672512 0.662341 0.718279 id_00073f8be_2<br/>3 1.296234 1.306208 1.898748 1.324560 1.827133 id_00073f8be_3<br/>4 0.851104 0.670810 0.971952 0.573919 0.962205 id_00073f8be_4</span></pre><h2 id="028b" class="nh lo iq bd lp oc od dn lt oe of dp lx kh og oh mb kl oi oj mf kp ok ol mj iw bi translated">提交</h2><p id="9af3" class="pw-post-body-paragraph jw jx iq jy b jz ml kb kc kd mm kf kg kh mn kj kk kl mo kn ko kp mp kr ks kt ij bi translated">将样本数据帧与<code class="fe oq or os nd b">id_seqpos</code>上的预测数据帧合并，以避免重复，并确保其遵循提交格式。最后，将我们的数据框保存到。csv文件。</p><pre class="kv kw kx ky gt nc nd ne nf aw ng bi"><span id="646a" class="nh lo iq nd b gy ni nj l nk nl">submission = sample_df[["id_seqpos"]].merge(preds_df, on=["id_seqpos"])<br/>submission.to_csv("Submission/submission.csv", index=False)</span><span id="a9ca" class="nh lo iq nd b gy nm nj l nk nl">submission.head()</span><span id="66e1" class="nh lo iq nd b gy nm nj l nk nl">  id_seqpos reactivity deg_Mg_pH10 deg_Mg_50C deg_pH10 deg_50C<br/>0 id_00073f8be_0 0.685760 0.703746 0.585288 1.857178 0.808561<br/>1 id_00073f8be_1 2.158555 3.243329 3.443042 4.394709 3.012130<br/>2 id_00073f8be_2 1.432280 0.674404 0.672512 0.662341 0.718279<br/>3 id_00073f8be_3 1.296234 1.306208 1.898748 1.324560 1.827133<br/>4 id_00073f8be_4 0.851104 0.670810 0.971952 0.573919 0.962205</span></pre><figure class="kv kw kx ky gt kz gh gi paragraph-image"><div role="button" tabindex="0" class="la lb di lc bf ld"><div class="gh gi ot"><img src="../Images/00cb2030442782051b7b7e8571bf06ce.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*ZFjKw7FLWVLE4DTI.png"/></div></div><figcaption class="lg lh gj gh gi li lj bd b be z dk translated">作者图片| Kaggle排行榜</figcaption></figure></div><div class="ab cl mq mr hu ms" role="separator"><span class="mt bw bk mu mv mw"/><span class="mt bw bk mu mv mw"/><span class="mt bw bk mu mv"/></div><div class="ij ik il im in"><h1 id="9bf5" class="ln lo iq bd lp lq mx ls lt lu my lw lx ly mz ma mb mc na me mf mg nb mi mj mk bi translated">结论</h1><p id="e034" class="pw-post-body-paragraph jw jx iq jy b jz ml kb kc kd mm kf kg kh mn kj kk kl mo kn ko kp mp kr ks kt ij bi translated">这对我来说是一次独特的经历，因为我在单个样本中处理多个数组的JSON文件。在弄清楚如何使用数据后，挑战变得非常简单，Kaggle社区在帮助我实现这一目标方面发挥了更大的作用。本文完全基于模型，除了构建模型之外，我还研究了数据集，并使用数据分析来理解一些常见的模式。我想包括我的其他梯度推进和LSTM模型的实验，但后来我决定提出最好的可能模型。</p><p id="e0dc" class="pw-post-body-paragraph jw jx iq jy b jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ij bi translated">我们使用JSON文件并将其转换成标记化的3D Numpy阵列，然后使用3X GRU模型来预测mRNA的降解率。最后，我们用节省下来的重量为不同长度的RNA序列创建了不同的模型。我会建议你使用我的代码，到处玩，看看你是否能在排行榜上击败我的分数。</p><h1 id="1fec" class="ln lo iq bd lp lq lr ls lt lu lv lw lx ly lz ma mb mc md me mf mg mh mi mj mk bi translated">源代码</h1><div class="ou ov gp gr ow ox"><a href="https://dagshub.com/kingabzpro/mRNA-Vaccine-Degradation-Prediction" rel="noopener  ugc nofollow" target="_blank"><div class="oy ab fo"><div class="oz ab pa cl cj pb"><h2 class="bd ja gy z fp pc fr fs pd fu fw iz bi translated">kingabzpro/mRNA-疫苗-降解-预测</h2><div class="pe l"><h3 class="bd b gy z fp pc fr fs pd fu fw dk translated">我尝试了多种传统模型，包括Light GBM、Catboost和BiLSTM，但结果是…</h3></div><div class="pf l"><p class="bd b dl z fp pc fr fs pd fu fw dk translated">dagshub.com</p></div></div><div class="pg l"><div class="ph l pi pj pk pg pl le ox"/></div></div></a></div><div class="ou ov gp gr ow ox"><a href="https://deepnote.com/project/mRNA-Vaccine-Degradation-Prediction-ZbqWvkGcQXGU3-1fDqb-fQ/%2FmRNA-Vaccine-Degradation-Prediction%2F.dvc%2Fconfig.local" rel="noopener  ugc nofollow" target="_blank"><div class="oy ab fo"><div class="oz ab pa cl cj pb"><h2 class="bd ja gy z fp pc fr fs pd fu fw iz bi translated">mRNA疫苗降解预测</h2><div class="pe l"><h3 class="bd b gy z fp pc fr fs pd fu fw dk translated">面向数据科学家和研究人员的托管笔记本电脑。</h3></div><div class="pf l"><p class="bd b dl z fp pc fr fs pd fu fw dk translated">deepnote.com</p></div></div><div class="pg l"><div class="pm l pi pj pk pg pl le ox"/></div></div></a></div><h1 id="8b02" class="ln lo iq bd lp lq lr ls lt lu lv lw lx ly lz ma mb mc md me mf mg mh mi mj mk bi translated">附加数据</h1><p id="fdbe" class="pw-post-body-paragraph jw jx iq jy b jz ml kb kc kd mm kf kg kh mn kj kk kl mo kn ko kp mp kr ks kt ij bi translated"><strong class="jy ja">RNA疫苗的工作原理及其问题:</strong><a class="ae lk" href="https://www.pbs.org/wgbh/nova/video/rna-coronavirus-vaccine/" rel="noopener ugc nofollow" target="_blank">https://www . PBS . org/wgbh/nova/video/RNA-coronavirus-vaccine/</a></p><p id="1ed7" class="pw-post-body-paragraph jw jx iq jy b jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ij bi translated"><strong class="jy ja">open vaccine挑战赛启动:</strong><a class="ae lk" href="https://scopeblog.stanford.edu/2020/05/20/stanford-biochemist-works-with-gamers-to-develop-covid-19-vaccine/" rel="noopener ugc nofollow" target="_blank">https://scope blog . Stanford . edu/2020/05/20/Stanford-biochemist-works-with-gamers-to-develop-新冠肺炎疫苗/ </a></p><p id="684a" class="pw-post-body-paragraph jw jx iq jy b jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ij bi translated"><strong class="jy ja">大规模免疫接种的不可能性:</strong><a class="ae lk" href="https://www.wsj.com/articles/from-freezer-farms-to-jets-logistics-operators-prepare-for-a-covid-19-vaccine-11598639012" rel="noopener ugc nofollow" target="_blank">https://www . wsj . com/articles/from-freezer-farms-to-jets-logistics-operators-prepare-for-a-新冠肺炎-vaccine-11598639012 </a></p><p id="0a43" class="pw-post-body-paragraph jw jx iq jy b jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ij bi translated"><strong class="jy ja"> Eterna，rna设计众包平台:</strong>【https://eternagame.org T2】</p><h1 id="5f23" class="ln lo iq bd lp lq lr ls lt lu lv lw lx ly lz ma mb mc md me mf mg mh mi mj mk bi translated">参考</h1><ol class=""><li id="caac" class="nn no iq jy b jz ml kd mm kh np kl nq kp nr kt pn nt nu nv bi translated">图片1—<a class="ae lk" href="https://news.harvard.edu/gazette/story/newsplus/harvard-establishes-mrna-immunotherapy-research-collaboration-with-moderna/" rel="noopener ugc nofollow" target="_blank">https://news . Harvard . edu/gazette/story/news plus/Harvard-established-mrna-免疫疗法-研究-协作-与-moderna/ </a></li><li id="d443" class="nn no iq jy b jz nw kd nx kh ny kl nz kp oa kt pn nt nu nv bi translated">图片2-https://news . Harvard . edu/gazette/story/news plus/Harvard-established-mrna-免疫疗法-研究-协作-与-moderna/</li><li id="5afa" class="nn no iq jy b jz nw kd nx kh ny kl nz kp oa kt pn nt nu nv bi translated">数据—<a class="ae lk" href="https://www.kaggle.com/c/stanford-covid-vaccine/data" rel="noopener ugc nofollow" target="_blank">https://www.kaggle.com/c/stanford-covid-vaccine/data</a></li></ol><h1 id="89be" class="ln lo iq bd lp lq lr ls lt lu lv lw lx ly lz ma mb mc md me mf mg mh mi mj mk bi translated">作者</h1><p id="6743" class="pw-post-body-paragraph jw jx iq jy b jz ml kb kc kd mm kf kg kh mn kj kk kl mo kn ko kp mp kr ks kt ij bi translated"><strong class="jy ja"> Abid Ali Awan <br/> </strong>我是一名认证数据科学家专业人士，热爱构建机器学习模型和研究最新的人工智能技术。我目前正在PEC-PITC测试人工智能产品，这些产品后来被批准用于人体试验，例如乳腺癌分类器。</p><p id="9979" class="pw-post-body-paragraph jw jx iq jy b jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ij bi translated"><strong class="jy ja">你可以关注我的</strong><a class="ae lk" href="https://www.linkedin.com/in/1abidaliawan/" rel="noopener ugc nofollow" target="_blank"><strong class="jy ja">LinkedIn</strong></a><strong class="jy ja">，</strong><a class="ae lk" href="https://twitter.com/1abidaliawan" rel="noopener ugc nofollow" target="_blank"><strong class="jy ja">Twitter</strong></a><strong class="jy ja">，以及</strong><a class="ae lk" href="https://www.polywork.com/kingabzpro" rel="noopener ugc nofollow" target="_blank"><strong class="jy ja">Polywork</strong></a><strong class="jy ja">，我每周都会在这里发布我的文章。</strong></p><blockquote class="po pp pq"><p id="61eb" class="jw jx ll jy b jz ka kb kc kd ke kf kg pr ki kj kk ps km kn ko pt kq kr ks kt ij bi translated">本文中显示的媒体不归Analytics Vidhya所有，由作者自行决定使用。</p></blockquote></div><div class="ab cl mq mr hu ms" role="separator"><span class="mt bw bk mu mv mw"/><span class="mt bw bk mu mv mw"/><span class="mt bw bk mu mv"/></div><div class="ij ik il im in"><p id="7a2c" class="pw-post-body-paragraph jw jx iq jy b jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ij bi translated"><em class="ll">原载于2021年9月4日https://www.analyticsvidhya.com</em><a class="ae lk" href="https://www.analyticsvidhya.com/blog/2021/09/deep-learning-model-to-predict-mrna-degradation" rel="noopener ugc nofollow" target="_blank"><em class="ll"/></a><em class="ll">。</em></p></div></div>    
</body>
</html>