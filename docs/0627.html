<html>
<head>
<title>Unsupervised vs. Supervised Learning</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">无监督与有监督学习</h1>
<blockquote>原文：<a href="https://pub.towardsai.net/un-supervised-vs-supervised-learning-c6a83f0b4dfc?source=collection_archive---------3-----------------------#2020-06-26">https://pub.towardsai.net/un-supervised-vs-supervised-learning-c6a83f0b4dfc?source=collection_archive---------3-----------------------#2020-06-26</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><h2 id="2409" class="io ip iq bd b dl ir is it iu iv iw dk ix translated" aria-label="kicker paragraph"><a class="ae ep" href="https://towardsai.net/p/category/machine-learning" rel="noopener ugc nofollow" target="_blank">机器学习</a></h2><div class=""/><p id="1fad" class="pw-post-body-paragraph jw jx iq jy b jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ij bi translated">我刚刚开始涉足数据科学和机器学习，开始接触“监督学习”技术，如“分类器”(来自sklearn kit的Decisiontreeclassifer)，以及非监督学习，包括“聚类”。"</p><p id="5d3a" class="pw-post-body-paragraph jw jx iq jy b jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ij bi translated">在这种情况下，我们使用数据集“<a class="ae ku" href="https://www.kaggle.com/uciml/breast-cancer-wisconsin-data/download" rel="noopener ugc nofollow" target="_blank">乳腺癌—威斯康辛州</a>”，并设定以下目标:</p><p id="cccf" class="pw-post-body-paragraph jw jx iq jy b jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ij bi translated"><strong class="jy ja"> a) </strong>执行聚类(k-means)，使用像剪影评分和WSS(在平方和内)这样的评估方法找到最优的聚类，</p><p id="42bb" class="pw-post-body-paragraph jw jx iq jy b jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ij bi translated"><strong class="jy ja"> b) </strong>执行决策树分类器模型，以及传统的训练与测试样本，并使用ROC/AUC评估模型</p><p id="4999" class="pw-post-body-paragraph jw jx iq jy b jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ij bi translated"><strong class="jy ja"> c) </strong>比较聚类模型输出与决策树分类器模型输出的效率</p><p id="0758" class="pw-post-body-paragraph jw jx iq jy b jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ij bi translated">给我带来惊喜的比较结果是，在没有目标/类别变量的情况下，仅使用聚类的准确性，<strong class="jy ja">接近95 % </strong>与数据集中的实际类别变量匹配，优于监督学习<strong class="jy ja">(使用70: 30 </strong>，训练测试拆分，准确性<strong class="jy ja">为92 % ) </strong>。现在，这是否意味着它将适用于更大的样本，将被验证为更大的数据集？</p><p id="3017" class="pw-post-body-paragraph jw jx iq jy b jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ij bi translated">让我们开始吧— <strong class="jy ja"> <em class="kv">数据洞察:</em> </strong></p><p id="f3b5" class="pw-post-body-paragraph jw jx iq jy b jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ij bi translated">特征是乳腺肿块细针抽吸(FNA)的数字化图像编辑。它们描述了图像中出现的细胞核的特征。</p><p id="e466" class="pw-post-body-paragraph jw jx iq jy b jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ij bi translated">总共569行，32列(包括分类变量，称为诊断，结果为恶性(M)和良性(B)。</p><p id="bd29" class="pw-post-body-paragraph jw jx iq jy b jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ij bi translated">数据处理步骤是:</p><figure class="kx ky kz la gt lb gh gi paragraph-image"><div role="button" tabindex="0" class="lc ld di le bf lf"><div class="gh gi kw"><img src="../Images/c8b354afbd73cbbb3cf10eea2f482908.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*PeqNYMxwyDPJlhZO7fgDBg.jpeg"/></div></div></figure><p id="37c9" class="pw-post-body-paragraph jw jx iq jy b jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ij bi translated">数据集没有任何缺失或重复的值，但在大多数列中有许多异常值，异常值的处理是基于IQR的异常值处理，随后是标准化(zScore ),因为不同要素之间的比例和范围不同。</p><p id="2c0e" class="pw-post-body-paragraph jw jx iq jy b jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ij bi translated">该净化的数据被分成特征和类(目标),然后作为输入提供给K-Means聚类和决策树分类器模型。</p><p id="7b34" class="pw-post-body-paragraph jw jx iq jy b jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ij bi translated"><strong class="jy ja"> K均值聚类</strong>是一种无监督的ML算法，用于识别给定数据集的目标变量的聚类数。让我们忽略原始数据集中的目标变量，只查看特征。让我们假设没有目标变量的潜在聚类的知识。给定这个数据集，看下面的WSS图，从8分开始，WSS得分似乎没有显著变化。所以这个图中的聚类数可能是8。但是考虑到“癌症数据集”的业务场景，拥有8个类桶或目标是没有意义的。</p><figure class="kx ky kz la gt lb gh gi paragraph-image"><div role="button" tabindex="0" class="lc ld di le bf lf"><div class="gh gi li"><img src="../Images/be0eb4e30a14436f9a20e3d8cdb97ace.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*mNbSIegjKTG3i9Rxr7C2mw.png"/></div></div><figcaption class="lj lk gj gh gi ll lm bd b be z dk translated">在平方和(WSS)图内</figcaption></figure><p id="781e" class="pw-post-body-paragraph jw jx iq jy b jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ij bi translated">此外，验证这一点，让我们看看剪影分数。</p><figure class="kx ky kz la gt lb gh gi paragraph-image"><div role="button" tabindex="0" class="lc ld di le bf lf"><div class="gh gi ln"><img src="../Images/39efe869d2c0fbbb03437a976cbeda97.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*BjrulwxA413gRiax6WmUfQ.png"/></div></div><figcaption class="lj lk gj gh gi ll lm bd b be z dk translated">轮廓分数图</figcaption></figure><p id="aa5b" class="pw-post-body-paragraph jw jx iq jy b jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ij bi translated">轮廓分数是对聚类之间的平均距离以及观察值在聚类中聚集的紧密程度的度量。尽管WSS图显示最佳聚类为8，但轮廓得分更为恰当，因为最佳聚类表示“平均得分”，并且根据上述轮廓得分图，最大平均得分位于<strong class="jy ja"> 2个聚类处。</strong></p><p id="c858" class="pw-post-body-paragraph jw jx iq jy b jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ij bi translated"><strong class="jy ja">监督学习—决策树分类器</strong></p><p id="b701" class="pw-post-body-paragraph jw jx iq jy b jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ij bi translated">顾名思义，监督学习模型需要特征和目标变量(类变量)，在这种监督学习方法中，我们将使用决策树根据特征将行分类为二元决策结果1或0。在所考虑的业务场景中，1表示恶性(M)，0表示良性(B)。</p><p id="93b4" class="pw-post-body-paragraph jw jx iq jy b jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ij bi translated">在这种模型方法中，决策树是在最后构建的，它通常具有根节点、分支/子树(在根节点下)，如下所示，分支数量越多，就意味着模型过度拟合，分支数量越少，就意味着拟合不足。最佳方法或分支数量是需要的，并且这种模型的评估机制是多种多样的，我们将使用混淆矩阵和曲线下面积AUC和ROC(受试者操作特征)来验证模型效率。下面描述了一个决策树，</p><figure class="kx ky kz la gt lb gh gi paragraph-image"><div class="gh gi lo"><img src="../Images/839b71cd37d09b454fdbed112ac7eb9b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1180/format:webp/1*WhfIZzfItuXhMlKZuh77XQ.png"/></div><figcaption class="lj lk gj gh gi ll lm bd b be z dk translated">决策图表</figcaption></figure><p id="f541" class="pw-post-body-paragraph jw jx iq jy b jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ij bi translated"><strong class="jy ja">" decision tree classifier "</strong>sk learn . tree模块下的建模</p><p id="c2a4" class="pw-post-body-paragraph jw jx iq jy b jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ij bi translated">dt _ model = decision tree classifier(criteria = ' Gini '，random_state=123)</p><p id="855d" class="pw-post-body-paragraph jw jx iq jy b jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ij bi translated">在调用模型和配件之前，我们使用sklearn将数据集分成训练和测试样本。模型选择模块和库train_test_split。我们在训练和测试之间呈现70:30的分割。</p><p id="9e30" class="pw-post-body-paragraph jw jx iq jy b jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ij bi translated">快速浏览一下参数，我们会使用“基尼”标准，基本上，</p><figure class="kx ky kz la gt lb gh gi paragraph-image"><div class="gh gi lp"><img src="../Images/96f41fa24d288f5e98abb46099705a56.png" data-original-src="https://miro.medium.com/v2/resize:fit:1382/format:webp/1*9TV3LoOx3yvoKOUbRg4pGA.png"/></div><figcaption class="lj lk gj gh gi ll lm bd b be z dk translated">基尼标准</figcaption></figure><figure class="kx ky kz la gt lb gh gi paragraph-image"><div role="button" tabindex="0" class="lc ld di le bf lf"><div class="gh gi lq"><img src="../Images/b0a6e4dca023daf2853ff3dfc0b05e90.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*tFC9EsfvsfcM4pQhZTEOPA.png"/></div></div><figcaption class="lj lk gj gh gi ll lm bd b be z dk translated">模型定型后的决策树视图。</figcaption></figure><p id="b887" class="pw-post-body-paragraph jw jx iq jy b jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ij bi translated">上面生成的决策树描绘了六个分支，对于训练集，决策树分类器模型为每个特征提供了“特征_重要性”。这对于理解每个特征如何影响最终结果以及每个特征的权重至关重要，下图描述了哪些特征具有更强的影响，</p><figure class="kx ky kz la gt lb gh gi paragraph-image"><div role="button" tabindex="0" class="lc ld di le bf lf"><div class="gh gi lr"><img src="../Images/61096026070965a9ec3028c21c5c3342.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*EuPzls-z5n-ffceepvGziQ.png"/></div></div><figcaption class="lj lk gj gh gi ll lm bd b be z dk translated">特征重要性</figcaption></figure><p id="28e7" class="pw-post-body-paragraph jw jx iq jy b jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ij bi translated">如果注意到特征，“凹点_最差”的影响最大，为70.9%，根_节点基本上就是利用这个特征来生成到下一个分支的分裂。</p><p id="c5bd" class="pw-post-body-paragraph jw jx iq jy b jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ij bi translated">让我们来看看训练数据集、测试数据集以及K均值与测试和训练数据集的比较的AUC图。</p><figure class="kx ky kz la gt lb gh gi paragraph-image"><div class="gh gi ls"><img src="../Images/3fa3d3054bf367939c9816f56f79bcaf.png" data-original-src="https://miro.medium.com/v2/resize:fit:906/format:webp/1*RSech29Lpj-IMraGjy4LqQ.png"/></div></figure><figure class="kx ky kz la gt lb gh gi paragraph-image"><div class="gh gi lt"><img src="../Images/be7a6a20b532b1b8534b3df18f346950.png" data-original-src="https://miro.medium.com/v2/resize:fit:856/format:webp/1*_B6d5iSDHarU9_hgr0phUQ.png"/></div></figure><p id="46e6" class="pw-post-body-paragraph jw jx iq jy b jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ij bi translated">如果您注意到，测试数据集的AUC较小，<strong class="jy ja"> @ 0.916，</strong>，而训练数据集在1 时为<strong class="jy ja">，这意味着与实际数据集相比，训练标签、类别变量(诊断)完全匹配。</strong></p><p id="e69b" class="pw-post-body-paragraph jw jx iq jy b jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ij bi translated">当分别比较kMeans结果和训练、测试之间的AUC时，</p><figure class="kx ky kz la gt lb gh gi paragraph-image"><div class="gh gi lu"><img src="../Images/affb22d1b1ca1f489b5555d1cbb4a196.png" data-original-src="https://miro.medium.com/v2/resize:fit:810/format:webp/1*xA-PkseBWLoRSnb_IZzkkQ.png"/></div></figure><figure class="kx ky kz la gt lb gh gi paragraph-image"><div class="gh gi lv"><img src="../Images/a1aa27061cd01b017e957abd4a3576b0.png" data-original-src="https://miro.medium.com/v2/resize:fit:832/format:webp/1*7XHC3T3axZ8DLz1U2lHHmw.png"/></div></figure><p id="6c90" class="pw-post-body-paragraph jw jx iq jy b jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ij bi translated">与训练数据集<strong class="jy ja">相比，Kmeans结果(仅训练样本)的AUC分数为0.925，而对于测试数据集，其为0.908。</strong></p><figure class="kx ky kz la gt lb gh gi paragraph-image"><div class="gh gi lw"><img src="../Images/37800da8cec57a9de2f3671e636c76bc.png" data-original-src="https://miro.medium.com/v2/resize:fit:846/format:webp/1*yBdc3Kl4CFzCsyAf0ERDmg.png"/></div></figure><p id="28a8" class="pw-post-body-paragraph jw jx iq jy b jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ij bi translated">当将kMeans分数与原始数据(诊断)类别标签进行比较时，上述AUC表明kMeans输出和诊断类别(良性-0，恶性-1)之间的高度一致性。AUC值也很高，为<strong class="jy ja"> 0.915。</strong></p><p id="aa0c" class="pw-post-body-paragraph jw jx iq jy b jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ij bi translated">以下是混淆矩阵，针对不同的场景，</p><figure class="kx ky kz la gt lb gh gi paragraph-image"><div class="gh gi lx"><img src="../Images/a5cca1be64f1f2b5c4c70cfafdc828cb.png" data-original-src="https://miro.medium.com/v2/resize:fit:860/format:webp/1*MZXsiRNWzpTfhUQMC71K1w.png"/></div></figure><figure class="kx ky kz la gt lb gh gi paragraph-image"><div class="gh gi ly"><img src="../Images/1d15b1eb8e5b6524095a119da6a8b446.png" data-original-src="https://miro.medium.com/v2/resize:fit:826/format:webp/1*KZzbBVqtqj8_0iv-sFwvrg.png"/></div></figure><figure class="kx ky kz la gt lb gh gi paragraph-image"><div class="gh gi lz"><img src="../Images/33fce497989ed51b02c20aa6a0c5e2c3.png" data-original-src="https://miro.medium.com/v2/resize:fit:874/format:webp/1*aw9t0aUVxxrnBvymAWmBmQ.png"/></div></figure><p id="a5df" class="pw-post-body-paragraph jw jx iq jy b jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ij bi translated"><a class="ae ku" href="http://www.kaggle.com/dataset/db445d1fbfe498ff91c204aafe9beac8b2afee3eaaf32fbaa2ae0832da791f7b" rel="noopener ugc nofollow" target="_blank">合并的最终数据</a>，带有“诊断”原始目标(类别)变量、k均值聚类输出、训练预测、测试预测之间的比较，可从以下网址获得</p><blockquote class="ma mb mc"><p id="6596" class="jw jx kv jy b jz ka kb kc kd ke kf kg md ki kj kk me km kn ko mf kq kr ks kt ij bi translated">总之，<strong class="jy ja"> KMeans聚类提供了相似的准确性和拟合度，即使它是无监督学习，</strong>当与监督学习的决策树分类器相比时。</p></blockquote></div></div>    
</body>
</html>