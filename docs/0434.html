<html>
<head>
<title>From ContE to Entity Type Embeddings in Natural Language Processing</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">自然语言处理中从上下文到实体类型的嵌入</h1>
<blockquote>原文：<a href="https://pub.towardsai.net/from-conte-to-entity-type-embeddings-in-natural-language-processing-19e53db90dd5?source=collection_archive---------0-----------------------#2020-04-26">https://pub.towardsai.net/from-conte-to-entity-type-embeddings-in-natural-language-processing-19e53db90dd5?source=collection_archive---------0-----------------------#2020-04-26</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><figure class="gl gn jr js jt ju gh gi paragraph-image"><div role="button" tabindex="0" class="jv jw di jx bf jy"><div class="gh gi jq"><img src="../Images/31d71bf1eb847c69b39a484c2d1ad25e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*GFJZUqTd8SBo9Ijt"/></div></div><figcaption class="kb kc gj gh gi kd ke bd b be z dk translated">在<a class="ae kf" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上由<a class="ae kf" href="https://unsplash.com/@twinsfisch?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> twinsfisch </a>拍摄的照片</figcaption></figure><p id="fdb4" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">在之前的<a class="ae kf" href="https://medium.com/towards-artificial-intelligence/a-gentle-introduction-to-graph-embeddings-c7b3d1db0fa8" rel="noopener">故事</a>中，TransE (Border et al .，2013)使用了一种翻译机制将主语(s)由谓语(p)转换成宾语(o)。就像word2vec一样，我们可以通过使用“King”+“Man”嵌入来计算“Queen”。</p><figure class="lf lg lh li gt ju gh gi paragraph-image"><div class="gh gi le"><img src="../Images/10b23f1039a3aa924473546b31850e1a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1060/format:webp/0*8AL4GQ1UbYeK48TD.png"/></div><figcaption class="kb kc gj gh gi kd ke bd b be z dk translated">Word2vec示例:国王+女人~=女王(<a class="ae kf" href="https://cfss.uchicago.edu/slides/text-analysis-fundamentals-and-sentiment-analysis/#1" rel="noopener ugc nofollow" target="_blank">来源</a>)</figcaption></figure><p id="90f9" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">Moon等人(2017)考虑上下文关系来解决图形完成。作者不仅考虑三元组(s，p，o ),而且考虑输出关系类型(从s)和输入关系类型(到o)。</p><figure class="lf lg lh li gt ju gh gi paragraph-image"><div class="gh gi lj"><img src="../Images/a4a3aaccd091d5cd85a79c80cf8174ab.png" data-original-src="https://miro.medium.com/v2/resize:fit:1030/format:webp/1*r_jIwcF_NO-4k8_mcf6TuQ.png"/></div><figcaption class="kb kc gj gh gi kd ke bd b be z dk translated">三元组(s，p，o)的上下文关系。(Moon等人，2017年)</figcaption></figure><p id="4e1a" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">当两个实体(“亚历克斯·吉尼斯”和“星球大战”)与“已播放”和“主演”有关系时“Alex Guinness”、“played”和“Star Wars”的组合向量应该类似于“starredIn”的向量。</p><figure class="lf lg lh li gt ju gh gi paragraph-image"><div class="gh gi lk"><img src="../Images/a75c905b48c9f22124e3c3c329595959.png" data-original-src="https://miro.medium.com/v2/resize:fit:872/format:webp/1*x_xplVJDc4nlEYImdR0HkA.png"/></div><figcaption class="kb kc gj gh gi kd ke bd b be z dk translated">学习实体和关系类型向量的框架(Moon等人，2017年)</figcaption></figure><h1 id="bd62" class="ll lm it bd ln lo lp lq lr ls lt lu lv lw lx ly lz ma mb mc md me mf mg mh mi bi translated">ETE</h1><p id="fb69" class="pw-post-body-paragraph kg kh it ki b kj mj kl km kn mk kp kq kr ml kt ku kv mm kx ky kz mn lb lc ld im bi translated">基于ContE (Moon等人，2017)，Moon等人提出了实体类型嵌入(ETE)来学习实体嵌入和实体类型嵌入。假设实体嵌入应该围绕相应的实体类型。例如，香蕉的嵌入(实体)应该类似于水果的嵌入(实体类型)。</p><p id="d063" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">在训练ETE模型之前，每个实体都应该接受ContE的训练(Moon et al. 2017)。换句话说，我们已经有了所有的实体嵌入。在ETE (Moon等人，2017)中训练三元组(实体、谓词、实体类型)时，只有实体类型嵌入将被更新，而实体嵌入和关系嵌入将被冻结。</p><p id="18d6" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">给定由康特康特(Moon等人，2017)训练的实体嵌入(例如，猫王)，E2E (Moon等人，2017)优化对应的正面实体类型嵌入(例如，来自密西西比州的人、摇滚歌手、演员、双胞胎)，以单独最大化相似性值。</p><figure class="lf lg lh li gt ju gh gi paragraph-image"><div class="gh gi mo"><img src="../Images/9704598f82675fce8b6565c51c3f497b.png" data-original-src="https://miro.medium.com/v2/resize:fit:760/format:webp/1*s3IMycSGL21jmQjK5SkQPA.png"/></div><figcaption class="kb kc gj gh gi kd ke bd b be z dk translated">实体类型向量学习框架(Moon等人，2017)</figcaption></figure><h1 id="6e2e" class="ll lm it bd ln lo lp lq lr ls lt lu lv lw lx ly lz ma mb mc md me mf mg mh mi bi translated">拿走</h1><p id="6867" class="pw-post-body-paragraph kg kh it ki b kj mj kl km kn mk kp kq kr ml kt ku kv mm kx ky kz mn lb lc ld im bi translated">从我的角度来看，ETE (Moon等人，2017)的概念类似于<a class="ae kf" href="https://towardsdatascience.com/3-silver-bullets-of-word-embedding-in-nlp-10fa8f50cc5a" rel="noopener" target="_blank"> word2vec </a> (Mikolo等人，2013)除了邻居来自图而不是句子。</p><h1 id="6b75" class="ll lm it bd ln lo lp lq lr ls lt lu lv lw lx ly lz ma mb mc md me mf mg mh mi bi translated">延伸阅读</h1><ul class=""><li id="3949" class="mp mq it ki b kj mj kn mk kr mr kv ms kz mt ld mu mv mw mx bi translated"><a class="ae kf" href="https://github.com/cmoon2/knowledge_graph" rel="noopener ugc nofollow" target="_blank">上下文和ETE知识库</a></li></ul><h1 id="1590" class="ll lm it bd ln lo lp lq lr ls lt lu lv lw lx ly lz ma mb mc md me mf mg mh mi bi translated">关于我</h1><p id="bc02" class="pw-post-body-paragraph kg kh it ki b kj mj kl km kn mk kp kq kr ml kt ku kv mm kx ky kz mn lb lc ld im bi translated">我是湾区的数据科学家。专注于数据科学、人工智能，尤其是NLP和平台相关领域的最新发展。你可以通过<a class="ae kf" href="https://medium.com/@makcedward/" rel="noopener">媒体博客</a>、<a class="ae kf" href="https://www.linkedin.com/in/edwardma1026" rel="noopener ugc nofollow" target="_blank"> LinkedIn </a>或<a class="ae kf" href="https://github.com/makcedward" rel="noopener ugc nofollow" target="_blank"> Github </a>联系我。</p><h1 id="3328" class="ll lm it bd ln lo lp lq lr ls lt lu lv lw lx ly lz ma mb mc md me mf mg mh mi bi translated">参考</h1><ul class=""><li id="e75f" class="mp mq it ki b kj mj kn mk kr mr kv ms kz mt ld mu mv mw mx bi translated">C.Moon、S. Harenberg、J. Slankas和N. F. Samatova。<a class="ae kf" href="http://repository.ittelkom-pwt.ac.id/4358/1/Learning%20Contextual%20Embeddings%20for%20Knowledge%20Graph%20Completion.pdf" rel="noopener ugc nofollow" target="_blank">学习用于知识图完成的上下文嵌入</a>。2017</li><li id="cb72" class="mp mq it ki b kj my kn mz kr na kv nb kz nc ld mu mv mw mx bi translated">C.穆恩、p .琼斯和N. F .萨马托瓦。<a class="ae kf" href="https://persagen.com/files/misc/Moon2017Learning.pdf" rel="noopener ugc nofollow" target="_blank">学习用于知识图完成的实体类型嵌入</a>。2017</li></ul></div></div>    
</body>
</html>