<html>
<head>
<title>From Classification to Ordinal Regression</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">从分类到有序回归</h1>
<blockquote>原文：<a href="https://pub.towardsai.net/from-classification-to-ordinal-regression-c659c074cb88?source=collection_archive---------0-----------------------#2022-09-14">https://pub.towardsai.net/from-classification-to-ordinal-regression-c659c074cb88?source=collection_archive---------0-----------------------#2022-09-14</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><div class=""><h2 id="fe91" class="pw-subtitle-paragraph jn ip iq bd b jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke dk translated">释放标签的潜力</h2></div><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi kf"><img src="../Images/ab4360cd6b1ab9926bd8dd7f1d9dbfaa.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*YOgJsL3sd80myxqxeauosA.jpeg"/></div></div><figcaption class="kr ks gj gh gi kt ku bd b be z dk translated">人工智能生成的(中途):《狮子和大象的混合体，插图，儿童读物》和《狮子脸的大象》</figcaption></figure><blockquote class="kv kw kx"><p id="754d" class="ky kz la lb b lc ld jr le lf lg ju lh li lj lk ll lm ln lo lp lq lr ls lt lu ij bi translated">"狮子更接近长颈鹿还是大象？"</p></blockquote><p id="8fe6" class="pw-post-body-paragraph ky kz iq lb b lc ld jr le lf lg ju lh lv lj lk ll lw ln lo lp lx lr ls lt lu ij bi translated">这是一个没有人问过的问题。永远不会。给狮子、大象和长颈鹿分类是一项简单的分类任务。因此，它可以主要通过交叉熵损失来解决。将某人归类为儿童/成人/老年人的任务是否应该以同样的方式处理？</p><p id="8ca8" class="pw-post-body-paragraph ky kz iq lb b lc ld jr le lf lg ju lh lv lj lk ll lw ln lo lp lx lr ls lt lu ij bi translated">在这篇博文中，我们将概述以下方面的最佳实践方法和论文:<br/> (1)解决有序分类问题。<br/> (2) <strong class="lb ir">粗</strong>分类标签成回归<strong class="lb ir">连续</strong>预测。<br/> (3)如何<strong class="lb ir">选择。</strong> <br/> (4)如何<strong class="lb ir">评价。<br/> </strong>这篇文章中回顾的论文主要关注深度学习模型，但主要概念也适用于其他ML架构。</p><h1 id="6f48" class="ly lz iq bd ma mb mc md me mf mg mh mi jw mj jx mk jz ml ka mm kc mn kd mo mp bi translated">连续世界中的离散标签</h1><blockquote class="mq"><p id="86ea" class="mr ms iq bd mt mu mv mw mx my mz lu dk translated">“世界是连续的，但心灵是离散的。”<br/> - <a class="ae na" href="https://en.wikipedia.org/wiki/David_Mumford" rel="noopener ugc nofollow" target="_blank">大卫·芒福德</a>，ICM 2002</p></blockquote><p id="e45a" class="pw-post-body-paragraph ky kz iq lb b lc nb jr le lf nc ju lh lv nd lk ll lw ne lo lp lx nf ls lt lu ij bi translated">当把现实世界的问题分解成基于ML的解决方案时，我们经常定义类别。然而，实际目标值可能是连续的<strong class="lb ir">或至少是有序的</strong>。这是<strong class="lb ir">在设计<strong class="lb ir">你的ML模型</strong>时要考虑甚至利用</strong>的东西。你是否面临一个分类问题？花点时间去理解你的“类”之间隐藏的关系。</p><p id="59e0" class="pw-post-body-paragraph ky kz iq lb b lc ld jr le lf lg ju lh lv lj lk ll lw ln lo lp lx lr ls lt lu ij bi translated">下面列举一些分类例子:<br/> -网络评分:1–5星。<br/> -医学<a class="ae na" href="https://radiopaedia.org/articles/modified-ct-severity-index" rel="noopener ugc nofollow" target="_blank">诊断指标</a>-1/2/3期。<br/> -人脸姿态估计【1】—45/90/180度。<br/>——年龄估计之类的。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi ng"><img src="../Images/1ebe20be383f84e6282bcb486edd5dcb.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*lgwJLCCeXIeT8DU9zS_pxQ.jpeg"/></div></div><figcaption class="kr ks gj gh gi kt ku bd b be z dk translated">从左到右:<strong class="bd ma">年龄预测</strong>:<a class="ae na" href="https://data.vision.ee.ethz.ch/cvl/rrothe/imdb-wiki/" rel="noopener ugc nofollow" target="_blank">https://data.vision.ee.ethz.ch/cvl/rrothe/imdb-wiki/</a>。图片鸣谢:<a class="ae na" href="https://en.wikipedia.org/wiki/What%27s_My_Age_Again%3F" rel="noopener ugc nofollow" target="_blank"/><strong class="bd ma">预测评级</strong>(ilmakiage . com)<strong class="bd ma">医学</strong> <strong class="bd ma">严重度</strong>dVRS指数，朱等【https://www . aha journals . org/doi/10.1161/stroke aha . 110.591586</figcaption></figure><h1 id="bf0b" class="ly lz iq bd ma mb mc md me mf mg mh mi jw mj jx mk jz ml ka mm kc mn kd mo mp bi translated">了解您的数据</h1><p id="c89a" class="pw-post-body-paragraph ky kz iq lb b lc nh jr le lf ni ju lh lv nj lk ll lw nk lo lp lx nl ls lt lu ij bi translated">在着手设计一个ML解决方案时，一些首要步骤是:<br/> (a)了解您目前有哪些<strong class="lb ir">数据/您可能在合理的时间内获得哪些数据。在某些情况下，您会有与您的数据相关的连续测量。例如，血液测量或关于确切年龄的信息。通常情况下，这些都是不可用的。手工标注细粒度标签是一项极其困难和耗时的任务。因此，在许多情况下，你所拥有的只是粗糙的分类标签。尤其是需要专家意见的时候。</strong></p><p id="e525" class="pw-post-body-paragraph ky kz iq lb b lc ld jr le lf lg ju lh lv lj lk ll lw ln lo lp lx lr ls lt lu ij bi translated">(二)探索领域。请你的<strong class="lb ir">数据领域专家</strong>澄清目标类之间的<strong class="lb ir">关系。他们假设的每一点先验知识或假设。询问他们要求的输出格式。比如:一个介于0到1之间的平滑实数，能比一个失败/通过/优秀的学生成绩预测器更好的产品用途吗？</strong></p><p id="48ba" class="pw-post-body-paragraph ky kz iq lb b lc ld jr le lf lg ju lh lv lj lk ll lw ln lo lp lx lr ls lt lu ij bi translated">如果你的课程确实是独立的，那么这篇博文不适合你！<br/>然而，如果它们是依赖的，问问你自己:<br/> (1)标签有顺序<strong class="lb ir">吗</strong>？<br/> (2)你只关心顺序，还是有些标签比其他标签更接近自己最近的标签？标签间距离的<strong class="lb ir">【步长】是否一致？</strong></p><h1 id="d947" class="ly lz iq bd ma mb mc md me mf mg mh mi jw mj jx mk jz ml ka mm kc mn kd mo mp bi translated">回归救援</h1><p id="fa30" class="pw-post-body-paragraph ky kz iq lb b lc nh jr le lf ni ju lh lv nj lk ll lw nk lo lp lx nl ls lt lu ij bi translated"><strong class="lb ir">逻辑回归<br/> </strong>大多数人都熟悉<a class="ae na" href="http://deeplearning.stanford.edu/tutorial/supervised/LogisticRegression/" rel="noopener ugc nofollow" target="_blank"> <strong class="lb ir">逻辑回归</strong> </a>来区分阶级。虽然目标标签是离散的，但估计的类别置信度是连续的。</p><p id="22ce" class="pw-post-body-paragraph ky kz iq lb b lc ld jr le lf lg ju lh lv lj lk ll lw ln lo lp lx lr ls lt lu ij bi translated">让我们考虑以下情况:错误地将A类分类为B类的后果不如A和c之间的错误严重。一种方法可以是使用带有每种类型错误的风险系数的<strong class="lb ir">加权损失</strong>。</p><p id="2283" class="pw-post-body-paragraph ky kz iq lb b lc ld jr le lf lg ju lh lv lj lk ll lw ln lo lp lx lr ls lt lu ij bi translated"><strong class="lb ir">有序回归<br/> </strong>另一种方法可以是对独热向量标签进行不同的编码，如<a class="ae na" href="https://arxiv.org/pdf/0704.1028.pdf" rel="noopener ugc nofollow" target="_blank"> NNRank </a>的论文【3】中所建议的。举个动手的例子，我推荐<a class="ae na" href="https://towardsdatascience.com/how-to-perform-ordinal-regression-classification-in-pytorch-361a2a095a99" rel="noopener" target="_blank">格鲁伯的帖子</a>和<a class="ae na" href="https://towardsdatascience.com/deep-ordinal-logistic-regression-1afd0645e591" rel="noopener" target="_blank">科特瓦尼的</a>。注意，如果建模为二元分类器集合的集合，则可能出现分类预测的不一致。<a class="ae na" href="https://arxiv.org/pdf/1901.07884.pdf" rel="noopener ugc nofollow" target="_blank">曹等2020 CORAL </a>提出了一种实现秩一致性的解决方案【4】。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi nm"><img src="../Images/587a29a151b000cd3f8442f08f84d5ab.png" data-original-src="https://miro.medium.com/v2/resize:fit:1290/format:webp/1*JnZecHEB-hzRidrDmwLHDw.png"/></div><figcaption class="kr ks gj gh gi kt ku bd b be z dk translated">图来自Cao等人2020<a class="ae na" href="https://arxiv.org/pdf/1901.07884.pdf" rel="noopener ugc nofollow" target="_blank">CORAL</a>【4】:与预期结果(右)相比，聚合二元分类器时的等级不一致(左)</figcaption></figure><h1 id="05cb" class="ly lz iq bd ma mb mc md me mf mg mh mi jw mj jx mk jz ml ka mm kc mn kd mo mp bi translated">线性回归-超越可用标签</h1><p id="34dc" class="pw-post-body-paragraph ky kz iq lb b lc nh jr le lf ni ju lh lv nj lk ll lw nk lo lp lx nl ls lt lu ij bi translated"><strong class="lb ir"> <em class="la">网飞</em> </strong>最近推出了一款<a class="ae na" href="https://about.netflix.com/en/news/two-thumbs-up-even-better-recommendations" rel="noopener ugc nofollow" target="_blank">双拇指竖起</a>。在此基础上，他们将3(不喜欢/无所谓/喜欢)扩展为4类。这是过去“喜欢”类别中更好的区分:喜欢和非常喜欢。想象一下，你有很多过去的粗糙的“喜欢”票，只有几个新的“双拇指”票。评估用户满意度得分(而不是一个类别)可以让您更好地适应新的用户输入。</p><p id="0fa6" class="pw-post-body-paragraph ky kz iq lb b lc ld jr le lf lg ju lh lv lj lk ll lw ln lo lp lx lr ls lt lu ij bi translated"><a class="ae na" href="https://www.nature.com/articles/s41598-020-79007-5" rel="noopener ugc nofollow" target="_blank">秦等BioeNet 2020 </a>展示了一种利用粗标签进行细粒度线性回归的策略【5】。走这条路时要考虑的一件重要事情是评估你的内部阶级秩序。我们将讨论下一步如何做。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi kf"><img src="../Images/fd00462a080d34186d7107beb5e4805f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*FEQoSLZJc62J4KOnkZEsYQ.jpeg"/></div></div><figcaption class="kr ks gj gh gi kt ku bd b be z dk translated">图来自秦等<a class="ae na" href="https://www.nature.com/articles/s41598-020-79007-5" rel="noopener ugc nofollow" target="_blank">生物网</a> 2020:从粗标签学习细粒度估计【5】</figcaption></figure><p id="2c89" class="pw-post-body-paragraph ky kz iq lb b lc ld jr le lf lg ju lh lv lj lk ll lw ln lo lp lx lr ls lt lu ij bi translated">将离散整数目标标签转换成实数的另一个可能的好处是<strong class="lb ir">软标签</strong>的积极效果。如<a class="ae na" href="https://arxiv.org/pdf/1906.02629.pdf" rel="noopener ugc nofollow" target="_blank">谷歌大脑团队(2020) </a>所示，使用软标签不仅<strong class="lb ir">减少了过度自信</strong>，而且<strong class="lb ir">改善了</strong> <a class="ae na" href="http://proceedings.mlr.press/v70/guo17a/guo17a.pdf" rel="noopener ugc nofollow" target="_blank"> <strong class="lb ir">校准</strong> </a>甚至没有温度缩放【6–8】。</p><h1 id="8c80" class="ly lz iq bd ma mb mc md me mf mg mh mi jw mj jx mk jz ml ka mm kc mn kd mo mp bi translated">确保你在正确的方向上</h1><p id="cb30" class="pw-post-body-paragraph ky kz iq lb b lc nh jr le lf ni ju lh lv nj lk ll lw nk lo lp lx nl ls lt lu ij bi translated"><strong class="lb ir">簇的形状和位置<br/> </strong>我非常相信你的DNN嵌入<strong class="lb ir">特征空间</strong>的分析。创建一个<a class="ae na" href="https://towardsdatascience.com/t-sne-clearly-explained-d84c537f53a" rel="noopener" target="_blank"> <strong class="lb ir"> T-SNE </strong> </a>你的测试集特征空间。遵循下图中的插图。在交叉熵损失的情况下，你会期望每个聚类压缩(最小化类内方差)并彼此远离(最大化类内方差)。然而，在有序回归中，你期望在特征空间中看到<strong class="lb ir">中的聚类的正确接近顺序</strong>。例如，对于有MSE损失的线性回归，您不仅会看到正确的顺序，还会看到从一个聚类到下一个聚类的类之间的连续顺序，并且具有<strong class="lb ir">较小的余量</strong>。如果您仍然看到一个明显的空白，这也可能表明您的测试集缺少边界示例。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi nn"><img src="../Images/c88aa81d0fa4976fad0b4c8754d60503.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*E5__CMUfjDY25AHgyezMVQ.jpeg"/></div></div><figcaption class="kr ks gj gh gi kt ku bd b be z dk translated">作者插图</figcaption></figure><p id="1714" class="pw-post-body-paragraph ky kz iq lb b lc ld jr le lf lg ju lh lv lj lk ll lw ln lo lp lx lr ls lt lu ij bi translated">来自同一类别的样本之间的关系如果你能得到一些更细粒度的标签样本，你可以用它们作为测试集，看看你的模型在正确的类内顺序下是否足够概括。例如，假设您正在尝试估计一个人的年龄，但您拥有的大量标记数据都是粗略的标记(0-3/4-14/青少年/20多岁/30多岁等等)。如果您有几个来自相同“年龄组”的人的样本，但具有确切年龄标签的数据(比如4岁、8岁、14岁)，请检查他们在特征空间中的位置是否正确排序，以及输出预测是否如您所预期的那样排序。</p><h1 id="d636" class="ly lz iq bd ma mb mc md me mf mg mh mi jw mj jx mk jz ml ka mm kc mn kd mo mp bi translated">结果</h1><blockquote class="kv kw kx"><p id="3806" class="ky kz la lb b lc ld jr le lf lg ju lh li lj lk ll lm ln lo lp lq lr ls lt lu ij bi translated">思考你的目标类之间的关系。它们可能是从属的或订购的。</p><p id="7253" class="ky kz la lb b lc ld jr le lf lg ju lh li lj lk ll lm ln lo lp lq lr ls lt lu ij bi translated">考虑不同类型的回归，从标签中获得更多。</p><p id="ef26" class="ky kz la lb b lc ld jr le lf lg ju lh li lj lk ll lm ln lo lp lq lr ls lt lu ij bi translated">可视化您的特征空间，并测试预测输出的内部类顺序。</p></blockquote><p id="b45c" class="pw-post-body-paragraph ky kz iq lb b lc ld jr le lf lg ju lh lv lj lk ll lw ln lo lp lx lr ls lt lu ij bi translated">当给定一组可能的小类时，分类方法似乎是一个显而易见的方向，考虑类之间的关系是提高ML的关键，有时可能是成功的关键！</p></div><div class="ab cl no np hu nq" role="separator"><span class="nr bw bk ns nt nu"/><span class="nr bw bk ns nt nu"/><span class="nr bw bk ns nt"/></div><div class="ij ik il im in"><h2 id="56e4" class="nv lz iq bd ma nw nx dn me ny nz dp mi lv oa ob mk lw oc od mm lx oe of mo og bi translated">参考</h2><p id="9fe0" class="pw-post-body-paragraph ky kz iq lb b lc nh jr le lf ni ju lh lv nj lk ll lw nk lo lp lx nl ls lt lu ij bi translated">[1]贝耶，l .，赫尔曼斯，a .和莱贝，b .，2015年10月。<a class="ae na" href="http://strands.acin.tuwien.ac.at/publications/y3/beyer_GCPR_15.pdf" rel="noopener ugc nofollow" target="_blank">双神经元网络:从离散训练标签进行连续头部姿态回归</a>。在<em class="la">德国模式识别会议</em>(第157-168页)。斯普林格，查姆。</p><p id="384f" class="pw-post-body-paragraph ky kz iq lb b lc ld jr le lf lg ju lh lv lj lk ll lw ln lo lp lx lr ls lt lu ij bi translated">[2] Resheff、Yehezkel S .、Amit Mandelbom和Daphna Weinshall。<a class="ae na" href="http://proceedings.mlr.press/v74/resheff17a/resheff17a.pdf" rel="noopener ugc nofollow" target="_blank">用对数双线性损失控制深度学习中的不平衡误差</a>。第一届不平衡领域学习国际研讨会:理论与应用。PMLR，2017。</p><p id="e682" class="pw-post-body-paragraph ky kz iq lb b lc ld jr le lf lg ju lh lv lj lk ll lw ln lo lp lx lr ls lt lu ij bi translated">[3]程，张，王，张，张，2008，6 .<a class="ae na" href="https://arxiv.org/pdf/0704.1028.pdf" rel="noopener ugc nofollow" target="_blank">有序回归的神经网络方法</a>。在<em class="la"> 2008年IEEE国际神经网络联合会议(IEEE世界计算智能大会)</em>(第1279-1284页)。IEEE。</p><p id="f689" class="pw-post-body-paragraph ky kz iq lb b lc ld jr le lf lg ju lh lv lj lk ll lw ln lo lp lx lr ls lt lu ij bi translated">[4]曹，w .，米尔贾利利诉拉什卡，s .，2020年。<a class="ae na" href="https://arxiv.org/pdf/1901.07884.pdf" rel="noopener ugc nofollow" target="_blank">应用于年龄估计的神经网络排序一致有序回归</a>。<em class="la">模式识别字母</em>，<em class="la"> 140 </em>，第325–331页。</p><p id="3239" class="pw-post-body-paragraph ky kz iq lb b lc ld jr le lf lg ju lh lv lj lk ll lw ln lo lp lx lr ls lt lu ij bi translated">[5]秦，张，陈，江，张，余，胡，马，苗，周，2020 .<a class="ae na" href="https://www.nature.com/articles/s41598-020-79007-5" rel="noopener ugc nofollow" target="_blank">通过分布恢复从粗粒度标签学习生理状态的细粒度估计</a>。<em class="la">科学报告</em>，<em class="la"> 10 </em> (1)，第1–10页。</p><p id="92b8" class="pw-post-body-paragraph ky kz iq lb b lc ld jr le lf lg ju lh lv lj lk ll lw ln lo lp lx lr ls lt lu ij bi translated">[6] Müller，r .，Kornblith，s .和Hinton，G.E .，2019。<a class="ae na" href="https://arxiv.org/pdf/1906.02629.pdf" rel="noopener ugc nofollow" target="_blank">标签平滑什么时候有帮助</a>？<em class="la">神经信息处理系统的进展</em>、<em class="la"> 32 </em>。</p><p id="64d1" class="pw-post-body-paragraph ky kz iq lb b lc ld jr le lf lg ju lh lv lj lk ll lw ln lo lp lx lr ls lt lu ij bi translated">[7]郭，c .，普莱斯，g .，孙，y .和温伯格，K.Q .，2017年7月。<a class="ae na" href="http://proceedings.mlr.press/v70/guo17a/guo17a.pdf" rel="noopener ugc nofollow" target="_blank">关于现代神经网络的校准</a>。在<em class="la">机器学习国际会议</em>(第1321–1330页)。PMLR。</p><p id="cb6a" class="pw-post-body-paragraph ky kz iq lb b lc ld jr le lf lg ju lh lv lj lk ll lw ln lo lp lx lr ls lt lu ij bi translated">[8] Minderer，m .，Djolonga，j .，Romijnders，r .，Hubis，f .，Zhai，x .，Houlsby，n .，Tran，d .和Lucic，m .，2021年。<a class="ae na" href="https://proceedings.neurips.cc/paper/2021/file/8420d359404024567b5aefda1231af24-Paper.pdf" rel="noopener ugc nofollow" target="_blank">重温现代神经网络的校准</a>。<em class="la">神经信息处理系统进展</em>，<em class="la"> 34 </em>，第15682–15694页。</p></div></div>    
</body>
</html>