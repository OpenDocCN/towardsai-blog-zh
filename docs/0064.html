<html>
<head>
<title>Multi-Class Text Classification Using PySpark, MLlib &amp; Doc2Vec</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">基于PySpark、MLlib和Doc2Vec的多类文本分类</h1>
<blockquote>原文：<a href="https://pub.towardsai.net/multi-class-text-classification-using-pyspark-mllib-doc2vec-dbfcee5b39f2?source=collection_archive---------1-----------------------#2019-06-01">https://pub.towardsai.net/multi-class-text-classification-using-pyspark-mllib-doc2vec-dbfcee5b39f2?source=collection_archive---------1-----------------------#2019-06-01</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><h2 id="a995" class="ir is it bd b dl iu iv iw ix iy iz dk ja translated" aria-label="kicker paragraph"><a class="ae ep" href="https://towardsai.net/p/category/machine-learning" rel="noopener ugc nofollow" target="_blank">机器学习</a>，<a class="ae ep" href="https://towardsai.net/p/category/programming" rel="noopener ugc nofollow" target="_blank">编程</a>，<a class="ae ep" href="https://towardsai.net/p/category/programming/python" rel="noopener ugc nofollow" target="_blank"> Python </a></h2><div class=""/><div class=""><h2 id="57b3" class="pw-subtitle-paragraph jz jc it bd b ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq dk translated">如何使用Apache Spark MLlib和PySpark解决NLP问题以及如何在Spark MLlib中模拟Doc2Vec</h2></div><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi kr"><img src="../Images/0f5f475670efec7598fc3b09faaaf013.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*SbNl1kfaCz1eBNHMv_xUgQ.jpeg"/></div></div><figcaption class="ld le gj gh gi lf lg bd b be z dk translated">图片来源:新闻— Pixabay</figcaption></figure><p id="14f1" class="pw-post-body-paragraph lh li it lj b lk ll kd lm ln lo kg lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">Apache Spark现在非常流行，可以扩展任何数据处理应用程序。对于机器学习，它也提供了一个名为<a class="ae md" href="https://spark.apache.org/mllib/" rel="noopener ugc nofollow" target="_blank">‘ml lib’</a>的库。这是一种解决ML问题的分布式编程方法。在本文中，我们将看到如何将这个MLlib与PySpark集成，以及使用Doc2Vec和PySpark解决文本分类问题的技术。</p><p id="c32d" class="pw-post-body-paragraph lh li it lj b lk ll kd lm ln lo kg lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">在继续之前，我们需要知道什么是‘doc 2 vec’。它是一个描述文本或文档的NLP模型。它将文本转换成数字特征的向量，以便在任何ML算法中使用。基本上，它是一种特征工程技术。它试图通过随机抽样单词来理解文档的上下文，并用这些单词训练神经网络。神经网络的隐藏层向量成为文档向量，也称为“Doc2Vec”。还有一种叫做“Word2Vec”的技术，也是基于类似的原理。但是它不是处理文档/文本，而是处理单词语料库，并为单词提供向量。有关“Doc2Vec”和“Word2Vec”的更多详细信息，以下资源会有所帮助:</p><ul class=""><li id="1f05" class="me mf it lj b lk ll ln lo lq mg lu mh ly mi mc mj mk ml mm bi translated"><a class="ae md" href="https://rare-technologies.com/doc2vec-tutorial/" rel="noopener ugc nofollow" target="_blank">稀有技术公司的Doc2Vec教程</a></li><li id="46cf" class="me mf it lj b lk mn ln mo lq mp lu mq ly mr mc mj mk ml mm bi translated"><a class="ae md" href="https://cs.stanford.edu/~quocle/paragraph_vector.pdf" rel="noopener ugc nofollow" target="_blank">句子的分布式表示&amp;文档</a></li><li id="7a6a" class="me mf it lj b lk mn ln mo lq mp lu mq ly mr mc mj mk ml mm bi translated"><a class="ae md" href="https://skymind.ai/wiki/word2vec" rel="noopener ugc nofollow" target="_blank">word 2 vec初学者指南</a></li></ul><h1 id="db38" class="ms mt it bd mu mv mw mx my mz na nb nc ki nd kj ne kl nf km ng ko nh kp ni nj bi translated"><strong class="ak">设置PySpark </strong></h1><p id="73ba" class="pw-post-body-paragraph lh li it lj b lk nk kd lm ln nl kg lp lq nm ls lt lu nn lw lx ly no ma mb mc im bi translated">本文需要PySpark本地设置。出于兼容性原因，我们将使用PySpark 2.4.3和Python 2.7，并将为此应用程序设置足够的内存。我们可以通过以下方式实现这一点:</p><figure class="ks kt ku kv gt kw"><div class="bz fp l di"><div class="np nq l"/></div></figure><p id="bc47" class="pw-post-body-paragraph lh li it lj b lk ll kd lm ln lo kg lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">我们现在可以看到那个火花物体了</p><pre class="ks kt ku kv gt nr ns nt nu aw nv bi"><span id="ea3d" class="nw mt it ns b gy nx ny l nz oa">spark</span></pre><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi ob"><img src="../Images/757d192a388194baefb9982ae532b86c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*XNxaVZgd5cdGTaxgLpz5Og.png"/></div></div><figcaption class="ld le gj gh gi lf lg bd b be z dk translated">图1</figcaption></figure><h1 id="4fac" class="ms mt it bd mu mv mw mx my mz na nb nc ki nd kj ne kl nf km ng ko nh kp ni nj bi translated"><strong class="ak">数据探索&amp;问题公式化</strong></h1><p id="1bd7" class="pw-post-body-paragraph lh li it lj b lk nk kd lm ln nl kg lp lq nm ls lt lu nn lw lx ly no ma mb mc im bi translated">我们将使用来自UCI机器学习知识库的句子分类集。这一个包含总共3297个标记的句子，分布在不同的文件中。每个句子都被指定一个特定的类别。显然，这是一个典型的文本分类问题。</p><p id="59a7" class="pw-post-body-paragraph lh li it lj b lk ll kd lm ln lo kg lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">我们先来看看数据集中有什么！</p><figure class="ks kt ku kv gt kw"><div class="bz fp l di"><div class="np nq l"/></div></figure><p id="601b" class="pw-post-body-paragraph lh li it lj b lk ll kd lm ln lo kg lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">记录总数</p><pre class="ks kt ku kv gt nr ns nt nu aw nv bi"><span id="743a" class="nw mt it ns b gy nx ny l nz oa">total_df.count()</span></pre><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div class="gh gi oc"><img src="../Images/386c19961971a7c5b6949932af76cad9.png" data-original-src="https://miro.medium.com/v2/resize:fit:200/format:webp/1*UJMZX0dOricSKBRYdwXN2Q.png"/></div></figure><p id="cd47" class="pw-post-body-paragraph lh li it lj b lk ll kd lm ln lo kg lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">显示数据集</p><pre class="ks kt ku kv gt nr ns nt nu aw nv bi"><span id="84a1" class="nw mt it ns b gy nx ny l nz oa">total_df.show()</span></pre><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi od"><img src="../Images/8eb69d9a2e44a37049dd6deb664a56ef.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Js87b0tKZYp8453Ztxk26Q.png"/></div></div><figcaption class="ld le gj gh gi lf lg bd b be z dk translated">图2</figcaption></figure><p id="86f5" class="pw-post-body-paragraph lh li it lj b lk ll kd lm ln lo kg lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">如我们所见，数据集包含一些不必要的文本，如' # # # abstract # # # ' &amp; ' # # introduction # # # '。这些文本只不过是对那些文件的评论。这个数据集还没有被分成单独的“标签”和“内容”列，这对于分类问题来说是很常见的。因此，这必须被清理&amp;分成适当的列，以便进一步处理。</p><p id="6202" class="pw-post-body-paragraph lh li it lj b lk ll kd lm ln lo kg lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">让我们看看如何做到这一点。</p><figure class="ks kt ku kv gt kw"><div class="bz fp l di"><div class="np nq l"/></div></figure><figure class="ks kt ku kv gt kw"><div class="bz fp l di"><div class="np nq l"/></div></figure><pre class="ks kt ku kv gt nr ns nt nu aw nv bi"><span id="a7fa" class="nw mt it ns b gy nx ny l nz oa">input_df = input_rdd.toDF()<br/>input_df.show()</span></pre><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi oe"><img src="../Images/2fb9f2557e7905f433bdb8a2c1facd17.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*nRy5XAaHHP5JC_aEGg0j8w.png"/></div></div><figcaption class="ld le gj gh gi lf lg bd b be z dk translated">图3</figcaption></figure><p id="a608" class="pw-post-body-paragraph lh li it lj b lk ll kd lm ln lo kg lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">“1”是标签，而“2”是问题的实际文本。现在我们可以使用这个数据集进行进一步的处理和实际的问题解决。</p><p id="a05c" class="pw-post-body-paragraph lh li it lj b lk ll kd lm ln lo kg lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">让我们来看看句子有多少不同的类别，即' _1 '列有多少不同的值</p><pre class="ks kt ku kv gt nr ns nt nu aw nv bi"><span id="05fa" class="nw mt it ns b gy nx ny l nz oa">input_df.groupBy('_1').count().show()</span></pre><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi of"><img src="../Images/1172f2d02e99aff1c325beba587951f9.png" data-original-src="https://miro.medium.com/v2/resize:fit:1156/format:webp/1*dewZcyXKr_TyZjQ-oYZR_A.png"/></div></div><figcaption class="ld le gj gh gi lf lg bd b be z dk translated">图4</figcaption></figure><p id="eb5d" class="pw-post-body-paragraph lh li it lj b lk ll kd lm ln lo kg lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">因此，总共有5个不同的类/类别，这是一个5类文本分类问题。</p><h1 id="07e9" class="ms mt it bd mu mv mw mx my mz na nb nc ki nd kj ne kl nf km ng ko nh kp ni nj bi translated"><strong class="ak">基础文字清理</strong></h1><p id="19c2" class="pw-post-body-paragraph lh li it lj b lk nk kd lm ln nl kg lp lq nm ls lt lu nn lw lx ly no ma mb mc im bi translated">在进入“Doc2Vec”处理之前，基本的文本清理是必要的。典型的文本清理包括以下步骤</p><ol class=""><li id="4223" class="me mf it lj b lk ll ln lo lq mg lu mh ly mi mc og mk ml mm bi translated">转换成小写</li><li id="b574" class="me mf it lj b lk mn ln mo lq mp lu mq ly mr mc og mk ml mm bi translated">删除标点符号</li><li id="335c" class="me mf it lj b lk mn ln mo lq mp lu mq ly mr mc og mk ml mm bi translated">整数、数字的移除</li><li id="6379" class="me mf it lj b lk mn ln mo lq mp lu mq ly mr mc og mk ml mm bi translated">移除多余的空格</li><li id="6cd4" class="me mf it lj b lk mn ln mo lq mp lu mq ly mr mc og mk ml mm bi translated">移除标签(如、<p>等)</p></li><li id="ca56" class="me mf it lj b lk mn ln mo lq mp lu mq ly mr mc og mk ml mm bi translated">删除停用词(如“and”、“to”、“the”等)</li><li id="067f" class="me mf it lj b lk mn ln mo lq mp lu mq ly mr mc og mk ml mm bi translated">词干(将单词转换成词根形式)</li></ol><p id="6e5f" class="pw-post-body-paragraph lh li it lj b lk ll kd lm ln lo kg lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">我们将使用Python ' <strong class="lj jd"> gensim </strong>'库来清理所有文本。</p><figure class="ks kt ku kv gt kw"><div class="bz fp l di"><div class="np nq l"/></div></figure><p id="a8ed" class="pw-post-body-paragraph lh li it lj b lk ll kd lm ln lo kg lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">让我们看看一个特定句子的内容，以及这个“clean_text”函数是如何处理它的</p><pre class="ks kt ku kv gt nr ns nt nu aw nv bi"><span id="57a6" class="nw mt it ns b gy nx ny l nz oa">input_rdd.take(1)[0][1]</span></pre><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi oh"><img src="../Images/84ce17d76ceb6503820bcfa9873be4fc.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*vXVzIm4qi9WxhzThlOwBgg.png"/></div></div><figcaption class="ld le gj gh gi lf lg bd b be z dk translated">图5</figcaption></figure><pre class="ks kt ku kv gt nr ns nt nu aw nv bi"><span id="a2b9" class="nw mt it ns b gy nx ny l nz oa">clean_text(input_rdd.take(1)[0])[1]</span></pre><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi oi"><img src="../Images/749086939a8a038ef8da844870ca3f70.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*9q96jpt68SYDmiCDmHcswQ.png"/></div></div><figcaption class="ld le gj gh gi lf lg bd b be z dk translated">图6</figcaption></figure><p id="752d" class="pw-post-body-paragraph lh li it lj b lk ll kd lm ln lo kg lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">虽然“干净的”句子不再是语法正确的，但它仍然包含了对“Doc2Vec”处理非常重要的上下文</p><p id="cd30" class="pw-post-body-paragraph lh li it lj b lk ll kd lm ln lo kg lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">现在，让我们看看如何在PySpark中使用这个函数来清理所有的句子</p><pre class="ks kt ku kv gt nr ns nt nu aw nv bi"><span id="7014" class="nw mt it ns b gy nx ny l nz oa">cleaned_rdd = input_rdd.map(lambda x : clean_text(x))</span><span id="5df9" class="nw mt it ns b gy oj ny l nz oa">cleaned_df = cleaned_rdd.toDF()<br/>cleaned_df.show()</span></pre><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi ok"><img src="../Images/f21dc382c1b05acf16fc187ecef1e2e6.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*yjj0Fi8S4lHflAFAWS9Edw.png"/></div></div><figcaption class="ld le gj gh gi lf lg bd b be z dk translated">图7</figcaption></figure><h1 id="e189" class="ms mt it bd mu mv mw mx my mz na nb nc ki nd kj ne kl nf km ng ko nh kp ni nj bi translated"><strong class="ak">机器学习管道</strong></h1><p id="6a64" class="pw-post-body-paragraph lh li it lj b lk nk kd lm ln nl kg lp lq nm ls lt lu nn lw lx ly no ma mb mc im bi translated">现在，是做实际工作的时候了。截至目前，Apache Spark没有为‘doc 2 vec’提供任何API。但它提供了一个“Word2Vec”变压器。它基于“跳格”法。根据<a class="ae md" href="https://spark.apache.org/docs/latest/ml-features.html#word2vec" rel="noopener ugc nofollow" target="_blank"> Apache Spark文档</a>:</p><p id="972f" class="pw-post-body-paragraph lh li it lj b lk ll kd lm ln lo kg lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated"><em class="ol"/><code class="fe om on oo ns b"><em class="ol">Word2VecModel</em></code><em class="ol">使用文档中所有单词的平均值将每个文档转换成向量</em></p><p id="2b8d" class="pw-post-body-paragraph lh li it lj b lk ll kd lm ln lo kg lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">比方说，对于我们的用例，一个句子有5个单词。然后，例如，典型的“Word2Vec”将每个单词转换成大小为100的特征向量。在这种情况下,“Doc2Vec”表示将是所有这100个长度向量的平均值，其长度也将是100。这是“Doc2Vec”模型的简化“平均”方案。我们将使用Apache Spark的“Word2Vec”作为我们的“Doc2Vec”模型。</p><p id="ea42" class="pw-post-body-paragraph lh li it lj b lk ll kd lm ln lo kg lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">我们的机器学习管道将由两个阶段组成</p><ol class=""><li id="c39f" class="me mf it lj b lk ll ln lo lq mg lu mh ly mi mc og mk ml mm bi translated">象征主义者</li><li id="9fb7" class="me mf it lj b lk mn ln mo lq mp lu mq ly mr mc og mk ml mm bi translated">“Word2Vec”模型</li></ol><p id="51e7" class="pw-post-body-paragraph lh li it lj b lk ll kd lm ln lo kg lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">为此，我们将使用<a class="ae md" href="https://spark.apache.org/docs/latest/ml-pipeline.html" rel="noopener ugc nofollow" target="_blank"> Apache Spark管道API </a>。</p><figure class="ks kt ku kv gt kw"><div class="bz fp l di"><div class="np nq l"/></div></figure><p id="ccf4" class="pw-post-body-paragraph lh li it lj b lk ll kd lm ln lo kg lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">让我们打印' Doc2Vec '内容</p><pre class="ks kt ku kv gt nr ns nt nu aw nv bi"><span id="0b5a" class="nw mt it ns b gy nx ny l nz oa">doc2vecs_df.show()</span></pre><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi op"><img src="../Images/25e8f6bde0b4032bc929dd8f6be193a3.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*pYjfsUnlqwIPlnlfZFWlQQ.png"/></div></div><figcaption class="ld le gj gh gi lf lg bd b be z dk translated">图8</figcaption></figure><p id="6911" class="pw-post-body-paragraph lh li it lj b lk ll kd lm ln lo kg lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">“特征”列是实际的“Doc2Vec”密集向量。我们使用了300号的“Doc2Vec”。通常，首选大小保持在100到300之间。</p><h1 id="4777" class="ms mt it bd mu mv mw mx my mz na nb nc ki nd kj ne kl nf km ng ko nh kp ni nj bi translated">模型培训和评估</h1><p id="8fa1" class="pw-post-body-paragraph lh li it lj b lk nk kd lm ln nl kg lp lq nm ls lt lu nn lw lx ly no ma mb mc im bi translated">下一步将是把这些“Doc2Vec”特征放入分类器模型。我们将尝试使用random forest &amp; logistic regression模型。</p><p id="7668" class="pw-post-body-paragraph lh li it lj b lk ll kd lm ln lo kg lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">我们需要将数据分成训练集和测试集，并评估模型的准确性</p><pre class="ks kt ku kv gt nr ns nt nu aw nv bi"><span id="629f" class="nw mt it ns b gy nx ny l nz oa">w2v_train_df, w2v_test_df = doc2vecs_df.randomSplit([0.8, 0.2])</span></pre><p id="68ea" class="pw-post-body-paragraph lh li it lj b lk ll kd lm ln lo kg lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated"><strong class="lj jd"> RandomForest模型</strong></p><p id="bbe1" class="pw-post-body-paragraph lh li it lj b lk ll kd lm ln lo kg lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">Spark MLlib不理解典型的分类变量。为此，我们的类标签(列' _1 ')必须转换成索引。<a class="ae md" href="https://spark.apache.org/docs/latest/ml-features.html#stringindexer" rel="noopener ugc nofollow" target="_blank"> StringIndexer </a> ' API为我们做了这些。</p><p id="28e4" class="pw-post-body-paragraph lh li it lj b lk ll kd lm ln lo kg lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">这里，我们也必须构建一个包含以下阶段的管道</p><ol class=""><li id="096b" class="me mf it lj b lk ll ln lo lq mg lu mh ly mi mc og mk ml mm bi translated">StringIndexer(输入= '_1 '，输出= 'label ')</li><li id="a141" class="me mf it lj b lk mn ln mo lq mp lu mq ly mr mc og mk ml mm bi translated">RandomForest分类器(标签列= '标签'，特征列= '特征'。这个“特性”是从“Doc2Vec”转化而来的)</li></ol><figure class="ks kt ku kv gt kw"><div class="bz fp l di"><div class="np nq l"/></div></figure><pre class="ks kt ku kv gt nr ns nt nu aw nv bi"><span id="fdbd" class="nw mt it ns b gy nx ny l nz oa">accuracy = rf_model_evaluator.evaluate(rf_predictions)<br/>print("Accuracy = %g" % (accuracy))</span></pre><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi oq"><img src="../Images/3ab8aaf0861d5e8e2c1a2d0877d45370.png" data-original-src="https://miro.medium.com/v2/resize:fit:816/format:webp/1*FokZ4NgruegUEgSfHUPHew.png"/></div></div><figcaption class="ld le gj gh gi lf lg bd b be z dk translated">图9</figcaption></figure><p id="5997" class="pw-post-body-paragraph lh li it lj b lk ll kd lm ln lo kg lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated"><strong class="lj jd">物流回收模式</strong></p><p id="a595" class="pw-post-body-paragraph lh li it lj b lk ll kd lm ln lo kg lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">对于物流回收，同样的管道阶段也是适用的。</p><figure class="ks kt ku kv gt kw"><div class="bz fp l di"><div class="np nq l"/></div></figure><pre class="ks kt ku kv gt nr ns nt nu aw nv bi"><span id="c09a" class="nw mt it ns b gy nx ny l nz oa">accuracy = lr_model_evaluator.evaluate(lr_predictions)<br/>print("Accuracy = %g" % (accuracy))</span></pre><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div class="gh gi or"><img src="../Images/372b6914e5f35d5d9dbda479185258a4.png" data-original-src="https://miro.medium.com/v2/resize:fit:848/format:webp/1*8SAW2NgSqj6swmt_5aty9Q.png"/></div><figcaption class="ld le gj gh gi lf lg bd b be z dk translated">图10</figcaption></figure><p id="7eec" class="pw-post-body-paragraph lh li it lj b lk ll kd lm ln lo kg lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">我们可以看到，两个分类器的精度大致相同。通过“超参数”调整和改变分类器，可以进一步提高精确度。这超出了本文的范围。这篇文章的读者可以自己尝试一下。</p><p id="ab7f" class="pw-post-body-paragraph lh li it lj b lk ll kd lm ln lo kg lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">这就把我们带到了终点。我们学习了如何通过PySpark使用Spark MLlib，模拟Doc2Vec，构建管道。</p><p id="ce9e" class="pw-post-body-paragraph lh li it lj b lk ll kd lm ln lo kg lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">这篇文章的Jupyter笔记本可以在<a class="ae md" href="https://github.com/avisheknag17/public_ml_models/blob/master/multi_class_text_classification_pyspark/notebook/multi_class_text_classifier_pyspark_2.ipynb" rel="noopener ugc nofollow" target="_blank"> Github </a>上找到。任何反馈都将受到高度赞赏。</p><p id="c4e6" class="pw-post-body-paragraph lh li it lj b lk ll kd lm ln lo kg lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">最近，我写了一本关于ML(<a class="ae md" href="https://twitter.com/bpbonline/status/1256146448346988546" rel="noopener ugc nofollow" target="_blank">https://twitter.com/bpbonline/status/1256146448346988546</a>)的书</p></div></div>    
</body>
</html>