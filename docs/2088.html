<html>
<head>
<title>Centroid Neural Network: An Efficient and Stable Clustering Algorithm</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">质心神经网络:一种高效稳定的聚类算法</h1>
<blockquote>原文：<a href="https://pub.towardsai.net/centroid-neural-network-an-efficient-and-stable-clustering-algorithm-b2fa8cbb2a27?source=collection_archive---------0-----------------------#2021-08-12">https://pub.towardsai.net/centroid-neural-network-an-efficient-and-stable-clustering-algorithm-b2fa8cbb2a27?source=collection_archive---------0-----------------------#2021-08-12</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><h2 id="8d26" class="io ip iq bd b dl ir is it iu iv iw dk ix translated" aria-label="kicker paragraph"><a class="ae ep" href="https://towardsai.net/p/category/machine-learning/deep-learning" rel="noopener ugc nofollow" target="_blank">深度学习</a></h2><div class=""/><div class=""><h2 id="66b0" class="pw-subtitle-paragraph jw iz iq bd b jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn dk translated">让我们提升那些没有被重视的潜力</h2></div><p id="860a" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">通常，聚类是将多维数据集分组到紧密相关的组中。聚类算法的经典代表是K-means聚类和自组织映射(SOM)。您可以很容易地找到大量关于这些算法解释的资源。这一次，让我向大家介绍另一种高效的聚类算法，但似乎没有多少研究者关注:<em class="lk">无监督竞争学习的质心神经网络</em>。请点击<a class="ae ll" href="https://ieeexplore.ieee.org/document/839021" rel="noopener ugc nofollow" target="_blank">此处</a>仔细查看原文。</p><figure class="lm ln lo lp gt lq gh gi paragraph-image"><div class="ab gu cl lr"><img src="../Images/3cc7b1510db1ed338a6a922952f68de1.png" data-original-src="https://miro.medium.com/v2/format:webp/1*nykOoMQpu9GiODUU48Aesg.png"/></div><figcaption class="lu lv gj gh gi lw lx bd b be z dk translated">质心神经网络结果—作者图片(<a class="ae ll" href="https://github.com/tranleanh/centroid-neural-networks" rel="noopener ugc nofollow" target="_blank">来源</a>)</figcaption></figure><p id="17a0" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">现在，让我们开始吧！</p><h1 id="4506" class="ly lz iq bd ma mb mc md me mf mg mh mi kf mj kg mk ki ml kj mm kl mn km mo mp bi translated">质心神经网络</h1><p id="02a0" class="pw-post-body-paragraph ko kp iq kq b kr mq ka kt ku mr kd kw kx ms kz la lb mt ld le lf mu lh li lj ij bi translated">为了避免与卷积神经网络混淆，我想在这篇文章中使用术语“CentNN”。</p><p id="c89c" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">CentNN是一种基于经典k-means聚类算法的无监督竞争学习算法，它在训练数据中估计相关聚类组的质心。CentNN既不需要学习系数的预定时间表，也不需要聚类的总迭代次数。在本文中，对聚类问题和图像压缩问题的仿真结果表明，与传统算法相比，CentNN收敛速度更快，但聚类质量不变，而其他算法的结果可能不稳定，这取决于学习系数的初始值和总迭代次数。</p><figure class="lm ln lo lp gt lq gh gi paragraph-image"><div class="ab gu cl lr"><img src="../Images/2ae305657c641290c7e665cf90fd1fe3.png" data-original-src="https://miro.medium.com/v2/format:webp/1*ZIQ3fK0jgNUOWGg5a1Fb7Q.png"/></div><figcaption class="lu lv gj gh gi lw lx bd b be z dk translated">质心神经网络算法。(图来自<a class="ae ll" href="https://ieeexplore.ieee.org/document/839021" rel="noopener ugc nofollow" target="_blank">纸</a>)</figcaption></figure><p id="9193" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">上图是CentNN算法。如果你在看这些数学方程时感到厌烦，不要担心，我会用一个中学数学的例子让它更容易理解。</p><h1 id="3f50" class="ly lz iq bd ma mb mc md me mf mg mh mi kf mj kg mk ki ml kj mm kl mn km mo mp bi translated">重量更新</h1><p id="3f07" class="pw-post-body-paragraph ko kp iq kq b kr mq ka kt ku mr kd kw kx ms kz la lb mt ld le lf mu lh li lj ij bi translated">算法的核心是权重更新过程:当单个数据点移入或移出时，如何高效地计算一组数据点的质心？</p><p id="6340" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">例如，我们有100个整数，计算平均值非常简单。如果我们多了一个整数会怎么样？我们需要再对所有101个进行平均吗？答案是否定的！</p><p id="e6ee" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">假设我们有N和N+1个数据点，平均值w计算如下:</p><figure class="lm ln lo lp gt lq gh gi paragraph-image"><div class="ab gu cl lr"><img src="../Images/dc5ecc55a63caad817ddc014b754e15c.png" data-original-src="https://miro.medium.com/v2/format:webp/1*R8MedJLo5CXolsnSwBuDIA.png"/></div></figure><p id="e5ca" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">根据上述两个等式:</p><figure class="lm ln lo lp gt lq gh gi paragraph-image"><div class="ab gu cl lr"><img src="../Images/c99ce3ad748d1bbd3f71af034b594513.png" data-original-src="https://miro.medium.com/v2/format:webp/1*6EYC4WoCcBUWk8U9qA33XA.png"/></div></figure><p id="c65c" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">现在，我们可以计算101个整数的平均值，而无需再次对它们进行平均。当我们移出一个整数得到99个整数时，情况类似。</p><p id="c628" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">上面的例子解释了论文中的这些方程:</p><figure class="lm ln lo lp gt lq gh gi paragraph-image"><div class="ab gu cl lr"><img src="../Images/17f84d0057d0c871e76eab1f5ae845a6.png" data-original-src="https://miro.medium.com/v2/format:webp/1*j85U_LxcME2XUy89LZrb-Q.png"/></div><figcaption class="lu lv gj gh gi lw lx bd b be z dk translated">权重更新方程</figcaption></figure><h1 id="8e3f" class="ly lz iq bd ma mb mc md me mf mg mh mi kf mj kg mk ki ml kj mm kl mn km mo mp bi translated">视觉解释示例</h1><p id="37ca" class="pw-post-body-paragraph ko kp iq kq b kr mq ka kt ku mr kd kw kx ms kz la lb mt ld le lf mu lh li lj ij bi translated">给定一个包含30个数据点的数据集，如下图所示，我们的目标是将它们分成3个簇。</p><figure class="lm ln lo lp gt lq gh gi paragraph-image"><div class="ab gu cl lr"><img src="../Images/72d0197e22bc31917f38b9f160ece9ac.png" data-original-src="https://miro.medium.com/v2/format:webp/1*MF7oRVdxQuj9RD7tb1rBZw.png"/></div><figcaption class="lu lv gj gh gi lw lx bd b be z dk translated">作者图片</figcaption></figure><p id="aa21" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated"><strong class="kq ja">纪元0:初始化</strong></p><p id="10fa" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">找到所有数据的1个质心<strong class="kq ja"> <em class="lk"> c </em> </strong>，然后将<strong class="kq ja"> <em class="lk"> c </em> </strong>拆分成2个权重<strong class="kq ja"> <em class="lk"> w1 </em> </strong>、<strong class="kq ja"> <em class="lk"> w2 </em> </strong>和一个小的<strong class="kq ja"><em class="lk">ɛ.</em> </strong></p><p id="46d1" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated"><strong class="kq ja"><em class="lk">w1 = c+ɛ</em></strong>，<strong class="kq ja"><em class="lk">w2 = c—ɛ</em></strong>(如<strong class="kq ja"><em class="lk">【ɛ= 0.05</em></strong>)</p><figure class="lm ln lo lp gt lq gh gi paragraph-image"><div class="ab gu cl lr"><img src="../Images/98fdfa62d1c7bb070a1076d45a0d180f.png" data-original-src="https://miro.medium.com/v2/format:webp/1*kUTFpTJrZ5BRlgklxn1wZw.png"/></div><figcaption class="lu lv gj gh gi lw lx bd b be z dk translated">作者图片</figcaption></figure><p id="5bc1" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">在继续之前，我们先来谈谈“赢家神经元”和“输家神经元”这两个术语。</p><ul class=""><li id="896c" class="mv mw iq kq b kr ks ku kv kx mx lb my lf mz lj na nb nc nd bi translated">赢家神经元:输入一个数据x，赢家神经元是所有权重中最接近x的权重(w)。</li><li id="0a0f" class="mv mw iq kq b kr ne ku nf kx ng lb nh lf ni lj na nb nc nd bi translated">失败者神经元:在时段n输入一个数据x，如果在时段(n-1)中，w是最接近x的权重，但是在时段n中，存在另一个比w更接近x的权重w ’,则w是失败者神经元，而w’是在时段n的数据x的胜利者神经元</li></ul><p id="08f4" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">在<strong class="kq ja"><em class="lk"/></strong>中为每个<strong class="kq ja"> <em class="lk"> x </em> </strong>找到胜出的神经元</p><ul class=""><li id="ef18" class="mv mw iq kq b kr ks ku kv kx mx lb my lf mz lj na nb nc nd bi translated"><strong class="kq ja"> <em class="lk"> x1 </em> </strong>到来，<strong class="kq ja"> <em class="lk"> w1 </em> </strong>胜→更新<strong class="kq ja"> <em class="lk"> w1 </em> </strong></li><li id="adf1" class="mv mw iq kq b kr ne ku nf kx ng lb nh lf ni lj na nb nc nd bi translated"><strong class="kq ja"> <em class="lk"> x2 </em> </strong>到来，<strong class="kq ja"> <em class="lk"> w2 </em> </strong>胜→更新<strong class="kq ja"> <em class="lk"> w2 </em> </strong></li><li id="c0c8" class="mv mw iq kq b kr ne ku nf kx ng lb nh lf ni lj na nb nc nd bi translated"><strong class="kq ja"> <em class="lk"> x3 </em> </strong>来了，<strong class="kq ja"> <em class="lk"> w1 </em> </strong>胜了→更新<strong class="kq ja"> <em class="lk"> w1 </em> </strong></li><li id="0a50" class="mv mw iq kq b kr ne ku nf kx ng lb nh lf ni lj na nb nc nd bi">…</li><li id="b214" class="mv mw iq kq b kr ne ku nf kx ng lb nh lf ni lj na nb nc nd bi translated"><strong class="kq ja"> <em class="lk"> x30 </em> </strong>降临，<strong class="kq ja"> <em class="lk"> w1 </em> </strong>胜→更新<strong class="kq ja"> <em class="lk"> w1 </em> </strong></li></ul><figure class="lm ln lo lp gt lq gh gi paragraph-image"><div class="ab gu cl lr"><img src="../Images/8a7e419eb7b9c5189bc536c83eb73168.png" data-original-src="https://miro.medium.com/v2/format:webp/1*hFLDeUAAwT9h0b5wlDddmw.png"/></div><figcaption class="lu lv gj gh gi lw lx bd b be z dk translated">作者图片</figcaption></figure><p id="7cbf" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">在时间0之后，我们总是有2个质心和聚类数据点的信息。现在，把它放在这里:</p><ul class=""><li id="d1e1" class="mv mw iq kq b kr ks ku kv kx mx lb my lf mz lj na nb nc nd bi translated"><strong class="kq ja"> <em class="lk"> x1 </em> </strong>胜，<strong class="kq ja"> <em class="lk"> w1 </em> </strong>胜</li><li id="d54f" class="mv mw iq kq b kr ne ku nf kx ng lb nh lf ni lj na nb nc nd bi translated"><strong class="kq ja"><em class="lk">x2</em>T101】来了，<strong class="kq ja">T103】w2T105】胜了</strong></strong></li><li id="fc30" class="mv mw iq kq b kr ne ku nf kx ng lb nh lf ni lj na nb nc nd bi translated"><strong class="kq ja"> <em class="lk"> x3 </em> </strong>来了，<strong class="kq ja"> <em class="lk"> w1 </em> </strong>胜了</li><li id="d498" class="mv mw iq kq b kr ne ku nf kx ng lb nh lf ni lj na nb nc nd bi">…</li><li id="c8e8" class="mv mw iq kq b kr ne ku nf kx ng lb nh lf ni lj na nb nc nd bi translated"><strong class="kq ja"> <em class="lk"> x30 </em> </strong>来了，<strong class="kq ja"> <em class="lk"> w1 </em> </strong>胜了</li></ul><p id="d1af" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated"><strong class="kq ja">纪元1: </strong></p><p id="d89f" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">为每个<strong class="kq ja"> <em class="lk"> x </em> </strong>在<strong class="kq ja"> <em class="lk"> X. </em> </strong>中找到胜出的神经元</p><figure class="lm ln lo lp gt lq gh gi paragraph-image"><div class="ab gu cl lr"><img src="../Images/fff951366ae3124e3575d5d64c123d71.png" data-original-src="https://miro.medium.com/v2/format:webp/1*URhOLow3-38TxQnWgZh5nQ.png"/></div><figcaption class="lu lv gj gh gi lw lx bd b be z dk translated">作者图片</figcaption></figure><ul class=""><li id="cbd3" class="mv mw iq kq b kr ks ku kv kx mx lb my lf mz lj na nb nc nd bi translated"><strong class="kq ja"> <em class="lk"> x1 </em> </strong>来了，<strong class="kq ja"> <em class="lk"> w2 </em> </strong>赢了→ <strong class="kq ja"> <em class="lk"> w1 </em> </strong>输了，<strong class="kq ja"> <em class="lk">输了</em> </strong> += 1，<strong class="kq ja"> <em class="lk">更新权重。</em>T19】</strong></li><li id="4b56" class="mv mw iq kq b kr ne ku nf kx ng lb nh lf ni lj na nb nc nd bi translated"><strong class="kq ja"> <em class="lk"> x2 </em> </strong>降临，<strong class="kq ja"> <em class="lk"> w2 </em> </strong>获胜</li><li id="44a2" class="mv mw iq kq b kr ne ku nf kx ng lb nh lf ni lj na nb nc nd bi translated"><strong class="kq ja"> <em class="lk"> x3 </em> </strong>来了，<strong class="kq ja"> <em class="lk"> w1 </em> </strong>胜了</li><li id="6472" class="mv mw iq kq b kr ne ku nf kx ng lb nh lf ni lj na nb nc nd bi">…</li><li id="2186" class="mv mw iq kq b kr ne ku nf kx ng lb nh lf ni lj na nb nc nd bi translated"><strong class="kq ja"> <em class="lk"> x30 </em> </strong>来了，<strong class="kq ja"> <em class="lk"> w1 </em> </strong>胜了</li></ul><p id="9496" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">在时段1之后，我们有1个数据，其聚类被更新，并且失败神经元的数量增加1。通过观察，我们仍然可以意识到x1更接近w2而不是w1，但是在时期0，x1被聚类到w1，现在它被正确地更新。同样，请将信息保存在这里:</p><ul class=""><li id="67af" class="mv mw iq kq b kr ks ku kv kx mx lb my lf mz lj na nb nc nd bi translated"><strong class="kq ja"> <em class="lk"> x1 </em> </strong>来了，<strong class="kq ja"> <em class="lk"> w2 </em> </strong>胜了</li><li id="2f34" class="mv mw iq kq b kr ne ku nf kx ng lb nh lf ni lj na nb nc nd bi translated"><strong class="kq ja"> <em class="lk"> x2 </em> </strong>来了，<strong class="kq ja"> <em class="lk"> w2 </em> </strong>胜了</li><li id="01a1" class="mv mw iq kq b kr ne ku nf kx ng lb nh lf ni lj na nb nc nd bi translated"><strong class="kq ja"> <em class="lk"> x3 </em> </strong>降临，<strong class="kq ja"> <em class="lk"> w1 </em> </strong>获胜</li><li id="ae3a" class="mv mw iq kq b kr ne ku nf kx ng lb nh lf ni lj na nb nc nd bi">…</li><li id="245b" class="mv mw iq kq b kr ne ku nf kx ng lb nh lf ni lj na nb nc nd bi translated"><strong class="kq ja"> <em class="lk"> x30 </em> </strong>来了，<strong class="kq ja"> <em class="lk"> w1 </em> </strong>胜了</li></ul><p id="60a6" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated"><strong class="kq ja">纪元2: </strong></p><p id="d3e5" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">为每个<strong class="kq ja"><em class="lk"/></strong>中的<strong class="kq ja"> <em class="lk"> x </em> </strong>继续寻找获胜神经元</p><figure class="lm ln lo lp gt lq gh gi paragraph-image"><div class="ab gu cl lr"><img src="../Images/bfcc3a303dbd985a28f5516f6e5041a2.png" data-original-src="https://miro.medium.com/v2/format:webp/1*HFHA5fZASji04vY6LQxWGg.png"/></div><figcaption class="lu lv gj gh gi lw lx bd b be z dk translated">作者图片</figcaption></figure><ul class=""><li id="8506" class="mv mw iq kq b kr ks ku kv kx mx lb my lf mz lj na nb nc nd bi translated"><strong class="kq ja"> <em class="lk"> x1 </em> </strong>来了，<strong class="kq ja">T91】w2T93】胜了</strong></li><li id="1b91" class="mv mw iq kq b kr ne ku nf kx ng lb nh lf ni lj na nb nc nd bi translated"><strong class="kq ja"> <em class="lk"> x2 </em> </strong>降临，<strong class="kq ja"> <em class="lk"> w2 </em> </strong>胜</li><li id="46dc" class="mv mw iq kq b kr ne ku nf kx ng lb nh lf ni lj na nb nc nd bi translated"><strong class="kq ja"> <em class="lk"> x3 </em> </strong>到来，<strong class="kq ja"> <em class="lk"> w1 </em> </strong>获胜</li><li id="25cf" class="mv mw iq kq b kr ne ku nf kx ng lb nh lf ni lj na nb nc nd bi">…</li><li id="1473" class="mv mw iq kq b kr ne ku nf kx ng lb nh lf ni lj na nb nc nd bi translated"><strong class="kq ja"> <em class="lk"> x30 </em> </strong>来了，<strong class="kq ja"> <em class="lk"> w1 </em> </strong>胜了</li></ul><p id="df37" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">现在，一切都没有改变。让我们检查集群的数量现在是否达到了期望的数量。答案是还没有。然后我们开始用一个小的<strong class="kq ja"><em class="lk"/></strong>分割误差最大的质心。</p><figure class="lm ln lo lp gt lq gh gi paragraph-image"><div class="ab gu cl lr"><img src="../Images/d03ae9a2fbd701895b4af2f6c964053b.png" data-original-src="https://miro.medium.com/v2/format:webp/1*xT0ko-8kVn6j0cgHLMNEWA.png"/></div><figcaption class="lu lv gj gh gi lw lx bd b be z dk translated">作者图片</figcaption></figure><p id="6015" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">现在从时段1开始执行相同的过程。</p><p id="ba23" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated"><strong class="kq ja">纪元3: </strong></p><figure class="lm ln lo lp gt lq gh gi paragraph-image"><div class="ab gu cl lr"><img src="../Images/a22b4fba35659e132950bb4eac13aa9f.png" data-original-src="https://miro.medium.com/v2/format:webp/1*FxCxVkU2165iDDNYHM05KQ.png"/></div><figcaption class="lu lv gj gh gi lw lx bd b be z dk translated">作者提供的图片</figcaption></figure><figure class="lm ln lo lp gt lq gh gi paragraph-image"><div class="ab gu cl lr"><img src="../Images/7de838d61cf5e94f6ea41f9f9e180189.png" data-original-src="https://miro.medium.com/v2/format:webp/1*ptVJH2fOako3gRZx9sYn9g.png"/></div><figcaption class="lu lv gj gh gi lw lx bd b be z dk translated">作者提供的图片</figcaption></figure><p id="83bc" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated"><strong class="kq ja">纪元4: </strong></p><figure class="lm ln lo lp gt lq gh gi paragraph-image"><div class="ab gu cl lr"><img src="../Images/0332b777356347b1834bb03da31d9f5e.png" data-original-src="https://miro.medium.com/v2/format:webp/1*riysmbxLwXckepyz-cc05Q.png"/></div><figcaption class="lu lv gj gh gi lw lx bd b be z dk translated">作者图片</figcaption></figure><p id="18e6" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated"><strong class="kq ja">纪元5: </strong></p><figure class="lm ln lo lp gt lq gh gi paragraph-image"><div class="ab gu cl lr"><img src="../Images/0332b777356347b1834bb03da31d9f5e.png" data-original-src="https://miro.medium.com/v2/format:webp/1*riysmbxLwXckepyz-cc05Q.png"/></div><figcaption class="lu lv gj gh gi lw lx bd b be z dk translated">作者图片</figcaption></figure><p id="5415" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">现在，什么都没有改变，我们也达到了期望的集群数量。现在，派对时间到了！</p><figure class="lm ln lo lp gt lq gh gi paragraph-image"><div class="ab gu cl lr"><img src="../Images/7950cdda58fe89cf9586c38d5d058a3d.png" data-original-src="https://miro.medium.com/v2/1*niL_51ZQW76Qf2eirGlfLw.gif"/></div><figcaption class="lu lv gj gh gi lw lx bd b be z dk translated">GIF via Tenor[<a class="ae ll" href="https://tenor.com/view/walk-away-walk-away-gif-8390072" rel="noopener ugc nofollow" target="_blank">image-source</a></figcaption></figure><p id="eb95" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">下面是K-Means聚类和CentNN在图像压缩中的结果比较。我们可以看到，在PSNR(峰值信噪比)方面，CentNN优于K均值聚类，PSNR和PSNR分别为47.53和46.35。在本例中，图像大小为128x128，聚类数为48。</p><figure class="lm ln lo lp gt lq gh gi paragraph-image"><div class="ab gu cl lr"><img src="../Images/abfb7bbf75aa5177173c40192e8dbd53.png" data-original-src="https://miro.medium.com/v2/format:webp/1*0XRIgkICGfwW83rNkGxcoA.png"/></div><figcaption class="lu lv gj gh gi lw lx bd b be z dk translated">图像压缩结果-按作者分类的图像</figcaption></figure><h1 id="a880" class="ly lz iq bd ma mb mc md me mf mg mh mi kf mj kg mk ki ml kj mm kl mn km mo mp bi translated">CentNN实现</h1><p id="dc3f" class="pw-post-body-paragraph ko kp iq kq b kr mq ka kt ku mr kd kw kx ms kz la lb mt ld le lf mu lh li lj ij bi translated">你们可以在这里找到我用Python实现的CentNN。如果你觉得它有帮助，请毫不犹豫地给它一颗星。</p><p id="f424" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">顺便说一下，欢迎你访问我的脸书页面，这是关于机器学习的分享:<a class="ae ll" href="https://www.facebook.com/diveintomachinelearning" rel="noopener ugc nofollow" target="_blank">投入机器学习</a>。</p></div><div class="ab cl nj nk hu nl" role="separator"><span class="nm bw bk nn no np"/><span class="nm bw bk nn no np"/><span class="nm bw bk nn no"/></div><div class="ij ik il im in"><p id="3599" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">在这篇文章中，我向大家介绍了质心神经网络(CentNN)，一种有效的聚类算法。CentNN的主要特点是它在每次新数据到来时更新权重，而K-means聚类在每次迭代后更新质心。</p><p id="9740" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">为了避免算法陷入不期望的局部最小解，CentNN从设置组数为2开始，并逐个增加组数，直到达到预定的组数。CentNN算法不像其他无监督算法那样提供收敛到全局最小解的任何保证，但是提供收敛到局部最小值的保证。</p></div></div>    
</body>
</html>