<html>
<head>
<title>Pyspark MLlib | Classification using Pyspark ML</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">Pyspark MLlib |使用Pyspark ML分类</h1>
<blockquote>原文：<a href="https://pub.towardsai.net/pyspark-mllib-classification-using-pyspark-ml-ec7e99e5176f?source=collection_archive---------0-----------------------#2022-08-21">https://pub.towardsai.net/pyspark-mllib-classification-using-pyspark-ml-ec7e99e5176f?source=collection_archive---------0-----------------------#2022-08-21</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><blockquote class="jn jo jp"><p id="b973" class="jq jr js jt b ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko ij bi translated">在前面几节中，我们讨论了RDD、数据帧和Pyspark概念。在本文中，我们将讨论Pyspark MLlib和Spark ML。稍后，我们将通过对数据进行编码、特征提取和使用各种算法开发分类器模型来训练用于汽车评估数据的分类器，并评估结果。</p></blockquote><p id="e03b" class="pw-post-body-paragraph jq jr iq jt b ju jv jw jx jy jz ka kb kp kd ke kf kq kh ki kj kr kl km kn ko ij bi translated">有关Pyspark、Pyspark RDD和DataFrame概念处理缺失值的详细教程，请参考以下链接:</p><div class="ks kt gp gr ku kv"><a href="https://blog.devgenius.io/pyspark-for-beginners-part-1-introduction-638fb16c5092" rel="noopener  ugc nofollow" target="_blank"><div class="kw ab fo"><div class="kx ab ky cl cj kz"><h2 class="bd ir gy z fp la fr fs lb fu fw ip bi translated">Pyspark适合初学者</h2><div class="lc l"><h3 class="bd b gy z fp la fr fs lb fu fw dk translated">PySpark是Apache Spark的Python API。使用PySpark，我们可以在分布式集群上并行运行应用程序…</h3></div><div class="ld l"><p class="bd b dl z fp la fr fs lb fu fw dk translated">blog.devgenius.io</p></div></div><div class="le l"><div class="lf l lg lh li le lj lk kv"/></div></div></a></div><p id="1a89" class="pw-post-body-paragraph jq jr iq jt b ju jv jw jx jy jz ka kb kp kd ke kf kq kh ki kj kr kl km kn ko ij bi translated">Spark MLlib是Spark机器学习库的简称。Pyspark MLlib是Pyspark核心上的一个包装器，使用机器学习算法进行数据分析。它适用于分布式系统，并且是可扩展的。我们可以在PySpark MLlib中找到分类、聚类、线性回归和其他机器学习算法的实现。</p><p id="a516" class="pw-post-body-paragraph jq jr iq jt b ju jv jw jx jy jz ka kb kp kd ke kf kq kh ki kj kr kl km kn ko ij bi translated">MLlib是Spark的可扩展机器学习库，由常见的机器学习算法和实用程序组成，包括分类、回归、聚类、协同过滤和降维，以及底层优化原语。</p><figure class="lm ln lo lp gt lq gh gi paragraph-image"><div role="button" tabindex="0" class="lr ls di lt bf lu"><div class="gh gi ll"><img src="../Images/935d7bacf11cada42275ecede44e6eb7.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*P3Lspcl-oourFFZRkdzhMQ.png"/></div></div><figcaption class="lw lx gj gh gi ly lz bd b be z dk translated">资料来源:Edureka</figcaption></figure><h1 id="5431" class="ma mb iq bd mc md me mf mg mh mi mj mk ml mm mn mo mp mq mr ms mt mu mv mw mx bi translated">使用Pyspark MLlib分类</h1><p id="7227" class="pw-post-body-paragraph jq jr iq jt b ju my jw jx jy mz ka kb kp na ke kf kq nb ki kj kr nc km kn ko ij bi translated">作为本文的一部分，我们将对汽车评估数据集进行分类。该数据集由描述汽车的6个属性和一个目标变量(包含多个类别的car_type)组成。使用的数据集可以在  <strong class="jt ir">这里找到<a class="ae nd" href="https://github.com/muttinenisairohith/Encoding-Categorical-Data/blob/6e7bec3b9cbdc25da1055472c837ef8a10f569ed/data/car_data.csv" rel="noopener ugc nofollow" target="_blank"> <strong class="jt ir">。</strong></a></strong></p><p id="1735" class="pw-post-body-paragraph jq jr iq jt b ju jv jw jx jy jz ka kb kp kd ke kf kq kh ki kj kr kl km kn ko ij bi translated">首先，让我们创建一个sparkSession —</p><pre class="lm ln lo lp gt ne nf ng nh aw ni bi"><span id="6c61" class="nj mb iq nf b gy nk nl l nm nn">from pyspark.sql import SparkSession</span><span id="31f0" class="nj mb iq nf b gy no nl l nm nn">spark = SparkSession.builder.appName("Practice").getOrCreate()<br/>spark</span></pre><figure class="lm ln lo lp gt lq gh gi paragraph-image"><div class="gh gi np"><img src="../Images/9ef285c42e5f611b133f7e28cee45409.png" data-original-src="https://miro.medium.com/v2/resize:fit:936/format:webp/1*uwQQxrleqki6X3FHucEERQ.png"/></div></figure><p id="fcb2" class="pw-post-body-paragraph jq jr iq jt b ju jv jw jx jy jz ka kb kp kd ke kf kq kh ki kj kr kl km kn ko ij bi translated">让我们从CSV文件中加载数据—</p><pre class="lm ln lo lp gt ne nf ng nh aw ni bi"><span id="dbcd" class="nj mb iq nf b gy nk nl l nm nn">df_pyspark = spark.read.csv("car_data.csv",inferSchema=True, header=True)</span><span id="7891" class="nj mb iq nf b gy no nl l nm nn">df_pyspark.show(5)</span></pre><figure class="lm ln lo lp gt lq gh gi paragraph-image"><div class="gh gi nq"><img src="../Images/23a6ee826bf3b84ccf83e44725abeec1.png" data-original-src="https://miro.medium.com/v2/resize:fit:1364/format:webp/1*jZ996kZhtiBALC7bFW5RjA.png"/></div></figure><p id="4465" class="pw-post-body-paragraph jq jr iq jt b ju jv jw jx jy jz ka kb kp kd ke kf kq kh ki kj kr kl km kn ko ij bi translated">对于大多数机器学习算法来说，数字数据是必不可少的——所以让我们来看看这个数据帧的模式。</p><figure class="lm ln lo lp gt lq gh gi paragraph-image"><div class="gh gi nr"><img src="../Images/92f5094c7271979eb881c84412fa0f20.png" data-original-src="https://miro.medium.com/v2/resize:fit:1094/format:webp/1*BNfqx0ACnd2IM5KQnZCoJQ.png"/></div></figure><p id="faeb" class="pw-post-body-paragraph jq jr iq jt b ju jv jw jx jy jz ka kb kp kd ke kf kq kh ki kj kr kl km kn ko ij bi translated">正如我们看到的，我们有字符串列。让我们用Pyspark StringIndexer把它们编码成整数。</p><pre class="lm ln lo lp gt ne nf ng nh aw ni bi"><span id="4f9a" class="nj mb iq nf b gy nk nl l nm nn">from pyspark.ml.feature import StringIndexer</span><span id="6f59" class="nj mb iq nf b gy no nl l nm nn">categoricalColumns = ["buying","maintainence","doors","persons","lug_boot","safety","car_type"]</span><span id="7233" class="nj mb iq nf b gy no nl l nm nn">l = []</span><span id="e1f4" class="nj mb iq nf b gy no nl l nm nn">for categoricalCol in categoricalColumns:</span><span id="fd7f" class="nj mb iq nf b gy no nl l nm nn">    stringIndexer = StringIndexer(inputCol = categoricalCol, outputCol = categoricalCol+"_encoded").fit(df_pyspark)</span><span id="6b87" class="nj mb iq nf b gy no nl l nm nn">    df_pyspark = stringIndexer.transform(df_pyspark)</span><span id="8fda" class="nj mb iq nf b gy no nl l nm nn">    df_pyspark = df_pyspark.withColumn(categoricalCol+"_encoded", df_pyspark[categoricalCol+"_encoded"].cast('int'))</span><span id="8173" class="nj mb iq nf b gy no nl l nm nn">encoded_df =  df_pyspark.select("buying_encoded","doors","maintainence_encoded","persons_encoded","lug_boot_encoded","safety_encoded","car_type_encoded")</span><span id="2a54" class="nj mb iq nf b gy no nl l nm nn">encoded_df.show(5)</span></pre><p id="2d27" class="pw-post-body-paragraph jq jr iq jt b ju jv jw jx jy jz ka kb kp kd ke kf kq kh ki kj kr kl km kn ko ij bi translated">在上面的代码中，我们导入了StringIndexer，并将每个String列转换为数字列。最初，StringIndexer以float格式返回数据，因此在下一步中，我们已经执行了转换，并将float值转换为数值。一旦我们创建了编码数据帧，我们只选择编码值。编码数据帧的输出如下—</p><figure class="lm ln lo lp gt lq gh gi paragraph-image"><div role="button" tabindex="0" class="lr ls di lt bf lu"><div class="gh gi ns"><img src="../Images/8d06bef02ea62a8e4d4f45c326270527.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*ApmFDmiuQTg3va79aMSV5g.png"/></div></div></figure><p id="26f4" class="pw-post-body-paragraph jq jr iq jt b ju jv jw jx jy jz ka kb kp kd ke kf kq kh ki kj kr kl km kn ko ij bi translated">数据准备就绪后，让我们使用Pyspark的VectorAssembler执行特征提取</p><pre class="lm ln lo lp gt ne nf ng nh aw ni bi"><span id="9a36" class="nj mb iq nf b gy nk nl l nm nn">from pyspark.ml.feature import VectorAssembler</span><span id="3e0b" class="nj mb iq nf b gy no nl l nm nn">featureAssembler = VectorAssembler(inputCols=["buying_encoded","doors_encoded","maintainence_encoded","persons_encoded","lug_boot_encoded","safety_encoded"],outputCol="features")</span><span id="030c" class="nj mb iq nf b gy no nl l nm nn">output = featureAssembler.transform(encoded_df)</span><span id="037a" class="nj mb iq nf b gy no nl l nm nn">output.select("features","car_type_encoded").show(5)</span></pre><p id="6a84" class="pw-post-body-paragraph jq jr iq jt b ju jv jw jx jy jz ka kb kp kd ke kf kq kh ki kj kr kl km kn ko ij bi translated">在Pyspark中，与pandas中使用的方法不同，我们使用VectorAssembler将所有独立的列转换成一个特性。创建的特征用于训练。我们包含所需信息的最终数据框架如下:</p><figure class="lm ln lo lp gt lq gh gi paragraph-image"><div class="gh gi nt"><img src="../Images/e68c200b1586bf50c24c14d438b1ecdb.png" data-original-src="https://miro.medium.com/v2/resize:fit:876/format:webp/1*Uwa5pNGg5mJI_hxwztNwPQ.png"/></div></figure><p id="7d07" class="pw-post-body-paragraph jq jr iq jt b ju jv jw jx jy jz ka kb kp kd ke kf kq kh ki kj kr kl km kn ko ij bi translated">让我们把数据分开来进行训练和测试。</p><pre class="lm ln lo lp gt ne nf ng nh aw ni bi"><span id="5f95" class="nj mb iq nf b gy nk nl l nm nn">train, test = output.randomSplit([0.8, 0.2], seed=17)</span></pre><p id="263c" class="pw-post-body-paragraph jq jr iq jt b ju jv jw jx jy jz ka kb kp kd ke kf kq kh ki kj kr kl km kn ko ij bi translated">与scikit-learn中的train_test_split不同，我们使用Pyspark DataFrame中的随机分割来执行分割</p><figure class="lm ln lo lp gt lq gh gi paragraph-image"><div role="button" tabindex="0" class="lr ls di lt bf lu"><div class="gh gi nu"><img src="../Images/541e4fc07ecdb6b3cbf52626bae1f084.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*SvCNAWIdIxa9M6Z8rXKosA.png"/></div></div></figure><p id="84a2" class="pw-post-body-paragraph jq jr iq jt b ju jv jw jx jy jz ka kb kp kd ke kf kq kh ki kj kr kl km kn ko ij bi translated">我们的数据准备好了，就来准备模型吧。</p><p id="91f6" class="pw-post-body-paragraph jq jr iq jt b ju jv jw jx jy jz ka kb kp kd ke kf kq kh ki kj kr kl km kn ko ij bi translated"><strong class="jt ir">逻辑回归</strong></p><pre class="lm ln lo lp gt ne nf ng nh aw ni bi"><span id="f94a" class="nj mb iq nf b gy nk nl l nm nn">from pyspark.ml.classification import LogisticRegression</span><span id="beb1" class="nj mb iq nf b gy no nl l nm nn">lr = LogisticRegression(featuresCol = 'features', labelCol = 'car_type_encoded', maxIter=10)</span><span id="5fce" class="nj mb iq nf b gy no nl l nm nn">lrModel = lr.fit(train)</span></pre><p id="aadf" class="pw-post-body-paragraph jq jr iq jt b ju jv jw jx jy jz ka kb kp kd ke kf kq kh ki kj kr kl km kn ko ij bi translated">我们通过从Pyspark.ml导入逻辑回归创建了一个逻辑回归模型，我们给“features”——features col作为自变量，给“car _ type _ encoded”——label col作为因变量。</p><p id="7504" class="pw-post-body-paragraph jq jr iq jt b ju jv jw jx jy jz ka kb kp kd ke kf kq kh ki kj kr kl km kn ko ij bi translated">让我们用我们的模型来预测测试数据。</p><pre class="lm ln lo lp gt ne nf ng nh aw ni bi"><span id="18cc" class="nj mb iq nf b gy nk nl l nm nn">predictions = lrModel.transform(test)</span><span id="7639" class="nj mb iq nf b gy no nl l nm nn">predictions.show(5)</span></pre><figure class="lm ln lo lp gt lq gh gi paragraph-image"><div role="button" tabindex="0" class="lr ls di lt bf lu"><div class="gh gi nv"><img src="../Images/453a5065713a3e3285ef010935f1db23.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*p-iX-Jx1p2gs9bWgyvLF9A.png"/></div></div></figure><p id="b8df" class="pw-post-body-paragraph jq jr iq jt b ju jv jw jx jy jz ka kb kp kd ke kf kq kh ki kj kr kl km kn ko ij bi translated">这里，我修剪了几列以显示优先级列。正如我们所看到的，我们已经预测了汽车类型。</p><p id="ae75" class="pw-post-body-paragraph jq jr iq jt b ju jv jw jx jy jz ka kb kp kd ke kf kq kh ki kj kr kl km kn ko ij bi translated">我们来评价一下模型。与传统使用的指标不同，Pyspark提供了以下指标—</p><figure class="lm ln lo lp gt lq gh gi paragraph-image"><div class="gh gi nw"><img src="../Images/8f09509c2633f8760a3696408be7891c.png" data-original-src="https://miro.medium.com/v2/resize:fit:714/format:webp/1*b3jPEEpcy8Xs5dpDP_JQtA.png"/></div></figure><p id="aba0" class="pw-post-body-paragraph jq jr iq jt b ju jv jw jx jy jz ka kb kp kd ke kf kq kh ki kj kr kl km kn ko ij bi translated">因为我们有多类数据帧，所以让我们使用多类分类赋值器。</p><pre class="lm ln lo lp gt ne nf ng nh aw ni bi"><span id="fb9a" class="nj mb iq nf b gy nk nl l nm nn">from pyspark.ml.evaluation import MulticlassClassificationEvaluator</span><span id="81a6" class="nj mb iq nf b gy no nl l nm nn">evaluator = MulticlassClassificationEvaluator()</span><span id="5d22" class="nj mb iq nf b gy no nl l nm nn">evaluator.setLabelCol("car_type_encoded")</span><span id="7003" class="nj mb iq nf b gy no nl l nm nn">evaluator.setPredictionCol("prediction")</span><span id="1518" class="nj mb iq nf b gy no nl l nm nn">evaluator.evaluate(predictions)</span></pre><figure class="lm ln lo lp gt lq gh gi paragraph-image"><div role="button" tabindex="0" class="lr ls di lt bf lu"><div class="gh gi nx"><img src="../Images/a33657565d4186ab5daf4472ce93eef2.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*d7YB2F3-rcwhXNCx8MSyIg.png"/></div></div></figure><p id="fa2f" class="pw-post-body-paragraph jq jr iq jt b ju jv jw jx jy jz ka kb kp kd ke kf kq kh ki kj kr kl km kn ko ij bi translated">正如我们所看到的，我们的模型使用逻辑回归表现不佳，因为它包含多个类。所以让我们用决策树来提高性能。</p><p id="144a" class="pw-post-body-paragraph jq jr iq jt b ju jv jw jx jy jz ka kb kp kd ke kf kq kh ki kj kr kl km kn ko ij bi translated"><strong class="jt ir">决策树</strong></p><p id="6322" class="pw-post-body-paragraph jq jr iq jt b ju jv jw jx jy jz ka kb kp kd ke kf kq kh ki kj kr kl km kn ko ij bi translated">决策树被广泛使用，因为它们易于解释，处理分类特征，扩展到多类分类，不需要特征缩放，并且能够捕捉非线性和特征交互。</p><pre class="lm ln lo lp gt ne nf ng nh aw ni bi"><span id="734c" class="nj mb iq nf b gy nk nl l nm nn">from pyspark.ml.classification import DecisionTreeClassifier<br/>from pyspark.ml.evaluation import MulticlassClassificationEvaluator</span><span id="c912" class="nj mb iq nf b gy no nl l nm nn">#Training Model</span><span id="287b" class="nj mb iq nf b gy no nl l nm nn">dt = DecisionTreeClassifier(featuresCol = 'features', labelCol = 'car_type_encoded', maxDepth = 3)<br/>dtModel = dt.fit(train)</span><span id="97ed" class="nj mb iq nf b gy no nl l nm nn">#Prediction</span><span id="d5af" class="nj mb iq nf b gy no nl l nm nn">predictions = dtModel.transform(test)</span><span id="26ab" class="nj mb iq nf b gy no nl l nm nn">#Evaluating the performance</span><span id="6b3b" class="nj mb iq nf b gy no nl l nm nn">evaluator = MulticlassClassificationEvaluator()<br/>evaluator.setLabelCol("car_type_encoded")<br/>evaluator.setPredictionCol("prediction")</span><span id="16cb" class="nj mb iq nf b gy no nl l nm nn">print("Test Area Under ROC: ",evaluator.evaluate(predictions))</span></pre><figure class="lm ln lo lp gt lq gh gi paragraph-image"><div role="button" tabindex="0" class="lr ls di lt bf lu"><div class="gh gi ny"><img src="../Images/0b7993ee7c3d6c16c14265039b9ef42f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*APhHckoiU4HoleLYpRR2RQ.png"/></div></div></figure><p id="d135" class="pw-post-body-paragraph jq jr iq jt b ju jv jw jx jy jz ka kb kp kd ke kf kq kh ki kj kr kl km kn ko ij bi translated">正如我们所知，尽管与逻辑回归模型相比，性能有所提高，但性能仍不令人满意。</p><p id="d9c9" class="pw-post-body-paragraph jq jr iq jt b ju jv jw jx jy jz ka kb kp kd ke kf kq kh ki kj kr kl km kn ko ij bi translated">因此，让我们使用像随机森林这样的集成方法来提高性能。</p><p id="d50c" class="pw-post-body-paragraph jq jr iq jt b ju jv jw jx jy jz ka kb kp kd ke kf kq kh ki kj kr kl km kn ko ij bi translated"><strong class="jt ir">随机森林</strong></p><pre class="lm ln lo lp gt ne nf ng nh aw ni bi"><span id="c11a" class="nj mb iq nf b gy nk nl l nm nn">from pyspark.ml.classification import RandomForestClassifier<br/>from pyspark.ml.evaluation import MulticlassClassificationEvaluator</span><span id="9956" class="nj mb iq nf b gy no nl l nm nn">#Training Model<br/>rf = RandomForestClassifier(featuresCol = 'features', labelCol = 'car_type_encoded', numTrees = 500, maxDepth = 10)<br/>rfModel = rf.fit(train)</span><span id="daff" class="nj mb iq nf b gy no nl l nm nn">#Prediction<br/>predictions = rfModel.transform(test)</span><span id="d8e7" class="nj mb iq nf b gy no nl l nm nn">#Evaluating the performance<br/>evaluator = MulticlassClassificationEvaluator()<br/>evaluator.setLabelCol("car_type_encoded")<br/>evaluator.setPredictionCol("prediction")<br/>print("Test Area Under ROC: ",evaluator.evaluate(predictions))</span></pre><figure class="lm ln lo lp gt lq gh gi paragraph-image"><div role="button" tabindex="0" class="lr ls di lt bf lu"><div class="gh gi nz"><img src="../Images/e87d3c877bcf2923b706590326c04a05.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*ZkSvc2gd_9SKZFDmjNEGtw.png"/></div></div></figure><p id="f7f6" class="pw-post-body-paragraph jq jr iq jt b ju jv jw jx jy jz ka kb kp kd ke kf kq kh ki kj kr kl km kn ko ij bi translated">由于我们使用了超参数numTrees和maxDepth，我们可以看到模型的性能得到了很大的提高，我们得到了很好的结果。</p><p id="d0c9" class="pw-post-body-paragraph jq jr iq jt b ju jv jw jx jy jz ka kb kp kd ke kf kq kh ki kj kr kl km kn ko ij bi translated">在这里，我们使用了最少的方法并获得了期望的性能。或者，我们可以使用pyspark Ml中的许多算法和技术来构建模型。</p><p id="edad" class="pw-post-body-paragraph jq jr iq jt b ju jv jw jx jy jz ka kb kp kd ke kf kq kh ki kj kr kl km kn ko ij bi translated">在本系列文章中，我们已经介绍了使用Pyspark的所有主要概念。</p><p id="9fff" class="pw-post-body-paragraph jq jr iq jt b ju jv jw jx jy jz ka kb kp kd ke kf kq kh ki kj kr kl km kn ko ij bi translated">我期待听到您的宝贵反馈或问题。乐意为您提供帮助…</p><p id="f392" class="pw-post-body-paragraph jq jr iq jt b ju jv jw jx jy jz ka kb kp kd ke kf kq kh ki kj kr kl km kn ko ij bi translated">快乐编码…</p></div></div>    
</body>
</html>