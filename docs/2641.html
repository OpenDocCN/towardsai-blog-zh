<html>
<head>
<title>Understand your Customer Better with Sentiment Analysis</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">通过情感分析更好地了解您的客户</h1>
<blockquote>原文：<a href="https://pub.towardsai.net/understand-your-customer-better-with-sentiment-analysis-9a7de3f106ea?source=collection_archive---------0-----------------------#2022-03-26">https://pub.towardsai.net/understand-your-customer-better-with-sentiment-analysis-9a7de3f106ea?source=collection_archive---------0-----------------------#2022-03-26</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/></div><div class="ab cl jn jo hu jp" role="separator"><span class="jq bw bk jr js jt"/><span class="jq bw bk jr js jt"/><span class="jq bw bk jr js"/></div><div class="ij ik il im in"><figure class="jv jw jx jy gt jz gh gi paragraph-image"><div role="button" tabindex="0" class="ka kb di kc bf kd"><div class="gh gi ju"><img src="../Images/03efdb0bdc51ba75e362b03b6ca1c9c2.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*qn44K8C2-ojteEgbGAgnYA.png"/></div></div><figcaption class="kg kh gj gh gi ki kj bd b be z dk translated">作者图片</figcaption></figure><p id="be63" class="pw-post-body-paragraph kk kl iq km b kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh ij bi translated"><strong class="km ir"> <em class="li">“你最不满意的顾客是你最大的学习来源。”—比尔·盖茨</em>T3</strong></p><p id="db9c" class="pw-post-body-paragraph kk kl iq km b kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh ij bi translated">在这个竞争激烈的商业世界中，公司寻找策略来满足他们的客户群，并可能通过推出优惠或新产品来吸引新客户。跟踪客户是喜欢还是不喜欢某个产品，以及他们对某个产品的反应，以改进服务，从而领先于竞争对手，这已成为不可避免的事情。在这篇博客中，重点将放在NLP用例<strong class="km ir">“情感分析”</strong>上，它根据客户对产品的情感对客户评论进行分类，通过跟踪客户对产品的评论来使企业受益。</p><p id="e1a1" class="pw-post-body-paragraph kk kl iq km b kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh ij bi translated">我们将一步一步地对数据集进行情感分析，该数据集包含对智能手机的评论，数据标签为这些评论的“正面”和“负面”情感。你可以从Kaggle 下载<a class="ae lj" href="https://www.kaggle.com/datasets/PromptCloudHQ/amazon-reviews-unlocked-mobile-phones" rel="noopener ugc nofollow" target="_blank">数据并跟随。我们将介绍Word2Vec算法及其架构的一些基本和初级概念，以便更好地理解NLP在处理文本数据时的工作方式。</a></p><p id="5396" class="pw-post-body-paragraph kk kl iq km b kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh ij bi translated"><strong class="km ir">使用的数据集</strong></p><figure class="jv jw jx jy gt jz gh gi paragraph-image"><div class="gh gi lk"><img src="../Images/53a89f2ee9b6b93a68a2cf22f6b0bc56.png" data-original-src="https://miro.medium.com/v2/resize:fit:1388/format:webp/1*nYtxYvlzD34fgPEx4IOECw.png"/></div></figure><p id="215b" class="pw-post-body-paragraph kk kl iq km b kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh ij bi translated">要执行情感分析，遵循的流程是:</p><figure class="jv jw jx jy gt jz gh gi paragraph-image"><div class="gh gi ll"><img src="../Images/1ed6085163cf80cc3f0cf4ef26fcc0bb.png" data-original-src="https://miro.medium.com/v2/resize:fit:1282/format:webp/1*hRBoOJgeq2mqUzWne0snnQ.png"/></div><figcaption class="kg kh gj gh gi ki kj bd b be z dk translated">作者图片</figcaption></figure><p id="dd9e" class="pw-post-body-paragraph kk kl iq km b kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh ij bi translated"><strong class="km ir"> 1。文本预处理</strong></p><p id="10d6" class="pw-post-body-paragraph kk kl iq km b kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh ij bi translated">需要数据预处理来从文本中移除不必要的信息，这些信息可能导致模型不太准确。文本预处理的步骤如下:</p><p id="7511" class="pw-post-body-paragraph kk kl iq km b kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh ij bi translated"><strong class="km ir">小写</strong> —这是最常见的文本预处理步骤之一，基于问题陈述使用。如果你正在处理用来识别人们情绪的文本，那么这一步可以跳过，因为这样做会导致信息的丢失，比如用大写字母表示愤怒或兴奋。</p><figure class="jv jw jx jy gt jz gh gi paragraph-image"><div class="gh gi lm"><img src="../Images/e2e9e4af9fbd141bef20532442a6b125.png" data-original-src="https://miro.medium.com/v2/resize:fit:1386/format:webp/1*Bxg4ctn-TluimY7U1tj7HQ.png"/></div><figcaption class="kg kh gj gh gi ki kj bd b be z dk translated">将单词转换成小写</figcaption></figure><p id="9b44" class="pw-post-body-paragraph kk kl iq km b kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh ij bi translated"><strong class="km ir">标记化— </strong>标记化是将文本分解成更小的块(句子或单词)，称为标记。这个过程是必需的，因为令牌根据单词序列解释句子的上下文，这对于word2vec模型来说是至关重要的。</p><figure class="jv jw jx jy gt jz gh gi paragraph-image"><div class="gh gi ln"><img src="../Images/cf9d2f4a3a0c490574b19dbf5eec0a12.png" data-original-src="https://miro.medium.com/v2/resize:fit:1372/format:webp/1*UW0FqfDAoANgiT4jPGTXNQ.png"/></div><figcaption class="kg kh gj gh gi ki kj bd b be z dk translated">单词标记化</figcaption></figure><p id="6fb4" class="pw-post-body-paragraph kk kl iq km b kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh ij bi translated"><strong class="km ir">特殊字符删除— </strong>括号、逗号等特殊字符。，不要给文本添加任何值，可以使用Python的字符串库删除它们，该字符串库包含一个预定义的标点符号列表，可用于删除标点符号。</p><figure class="jv jw jx jy gt jz gh gi paragraph-image"><div class="gh gi lo"><img src="../Images/d320cabff5fff6041b506f59fcda583e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1382/format:webp/1*vb00Dv9wn8tbvIJ1lnZfqQ.png"/></div><figcaption class="kg kh gj gh gi ki kj bd b be z dk translated">已删除“.”从句子中</figcaption></figure><p id="9bac" class="pw-post-body-paragraph kk kl iq km b kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh ij bi translated"><strong class="km ir">词汇化— </strong>词汇化移除前缀和后缀，并将单词转换为其基本形式，例如—“变化”和“改变”将转换为“变化”。</p><figure class="jv jw jx jy gt jz gh gi paragraph-image"><div class="gh gi lp"><img src="../Images/52cb142802b4d539cd3ccd729e757fd2.png" data-original-src="https://miro.medium.com/v2/resize:fit:1326/format:webp/1*zLxei8hP3vdw3CofaYoipw.png"/></div></figure><p id="48fc" class="pw-post-body-paragraph kk kl iq km b kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh ij bi translated"><strong class="km ir">停用词移除</strong> —停用词是文本数据中最常用的词，并且不携带关于文本中焦点主题的任何有价值的信息。像my，my，we，our这样的词是停用词，NLTK库包含一个预定义的停用词列表，您可以使用它，也可以根据项目需求创建一个用户定义的停用词列表。例如，在我们的数据集中,“What”可能是一个停用词，但如果我们正在处理一个客户查询数据集，那么“What”将是一个重要的词。</p><figure class="jv jw jx jy gt jz gh gi paragraph-image"><div class="gh gi lq"><img src="../Images/94d0111cd15a385679cb9454750ae1eb.png" data-original-src="https://miro.medium.com/v2/resize:fit:1384/format:webp/1*AWlDoXk72qfYkPGkSgSk5g.png"/></div><figcaption class="kg kh gj gh gi ki kj bd b be z dk translated">停止单词删除</figcaption></figure><p id="0306" class="pw-post-body-paragraph kk kl iq km b kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh ij bi translated"><strong class="km ir"> 2。单词嵌入</strong></p><p id="c60a" class="pw-post-body-paragraph kk kl iq km b kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh ij bi translated">ML模型不直接理解原始文本。因此，需要将文本数据转换为向量，这些向量对单词的上下文含义进行编码，并使相似的单词在维度空间中彼此更接近。例如，像电话、移动电话和手机这样的词在维度空间中会显得彼此更近，而远离像“好”、“好”等这样的不相关的词。将文本转换成向量的过程称为单词嵌入，Word2Vec算法用于产生这些嵌入。</p><p id="2fc1" class="pw-post-body-paragraph kk kl iq km b kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh ij bi translated"><strong class="km ir">工作于Word2Vec </strong></p><blockquote class="lr ls lt"><p id="0280" class="kk kl li km b kn ko kp kq kr ks kt ku lu kw kx ky lv la lb lc lw le lf lg lh ij bi translated"><strong class="km ir"> Word2Vec利用具有单个隐藏层的神经网络来预测文本语料库中每个单词在维度空间中更接近输入单词的概率</strong>。现在，这里的直觉是，相似的单词在相似的上下文中使用，并且它们在维度空间中彼此更接近，因此相似单词的概率应该更大，但是在Word2Vec算法中训练神经网络的目标不是使用产生的神经网络本身，而是学习隐藏层的权重。这些权重是我们的单词向量，它给出了单词在多维空间中的地址。</p></blockquote><p id="f38d" class="pw-post-body-paragraph kk kl iq km b kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh ij bi translated">下面是skip-gram神经网络的视觉图和架构，它将一个单词作为输入，并尝试预测上下文单词。</p><figure class="jv jw jx jy gt jz gh gi paragraph-image"><div role="button" tabindex="0" class="ka kb di kc bf kd"><div class="gh gi lx"><img src="../Images/62f17ed7ed0f0388d361ec0032775a55.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*NMMx9XGP2zqDYzdsC4L_EQ.png"/></div></div></figure><p id="c2fd" class="pw-post-body-paragraph kk kl iq km b kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh ij bi translated">Genism是用于NLP的开源python库，它提供了Word2Vec模型算法，用于从大型文本语料库中学习单词关联。下面是在文本数据上训练word2vec模型的代码。</p><figure class="jv jw jx jy gt jz gh gi paragraph-image"><div class="gh gi ly"><img src="../Images/53b5329b24eb5ba4049b9f10432eaccf.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*dC4jG9S26H1RIrAVkJ-aGg.png"/></div><figcaption class="kg kh gj gh gi ki kj bd b be z dk translated">“电话”这个词有100个向量</figcaption></figure><p id="a93b" class="pw-post-body-paragraph kk kl iq km b kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh ij bi translated">现在，我们有了语料库中每个单词的向量，我们将取一个句子中所有单词向量的平均值，这将得到该评论语句的100维平均数组。</p><figure class="jv jw jx jy gt jz gh gi paragraph-image"><div class="gh gi lz"><img src="../Images/a76a0579962f7e7c24388b133857c5cf.png" data-original-src="https://miro.medium.com/v2/resize:fit:1024/format:webp/1*Lg5JQX6IlWQiNfABpSVFWA.png"/></div></figure><p id="3766" class="pw-post-body-paragraph kk kl iq km b kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh ij bi translated">这个100维的平均数组将代表我们的语句的特征，用于分类模型来预测情感。它存储在‘word 2 vec _ df’中，分类模型利用该‘word 2 vec _ df’来对情感进行分类。</p><figure class="jv jw jx jy gt jz gh gi paragraph-image"><div role="button" tabindex="0" class="ka kb di kc bf kd"><div class="gh gi ju"><img src="../Images/220c79283a9141a12a779b1a1cf5b3d8.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*1t8Ah3d1KMKG4oSVlBe38g.png"/></div></div></figure><p id="933e" class="pw-post-body-paragraph kk kl iq km b kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh ij bi translated"><strong class="km ir"> 3。分类</strong></p><p id="64b6" class="pw-post-body-paragraph kk kl iq km b kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh ij bi translated">一旦我们有了评论的特征，我们就可以在数据上训练一个分类模型来预测情感。采用随机搜索变异系数进行超参数优化，提高了模型的精度。</p><figure class="jv jw jx jy gt jz gh gi paragraph-image"><div class="gh gi lq"><img src="../Images/97f9544a9c6c39ae426a04c3af3d9cd3.png" data-original-src="https://miro.medium.com/v2/resize:fit:1384/format:webp/1*Qd_itiDoJltx2sHgunW_8A.png"/></div></figure><p id="b5ac" class="pw-post-body-paragraph kk kl iq km b kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh ij bi translated">测试集上训练模型的评估</p><p id="ecf5" class="pw-post-body-paragraph kk kl iq km b kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh ij bi translated">生成分类报告和混淆矩阵以查看模型的性能。Gensim word2vec嵌入方法和随机森林分类模型能够对2类文本分类问题产生较高的准确率。在这个问题陈述中选择随机森林的原因是，当我们比较所有评估指标(如精度、召回率和F1)时，它比其他分类算法(支持向量机、逻辑回归)表现得更好。</p><figure class="jv jw jx jy gt jz gh gi paragraph-image"><div class="gh gi ma"><img src="../Images/056bbbb5aa184b26fa8f8f7406b50ed8.png" data-original-src="https://miro.medium.com/v2/resize:fit:1366/format:webp/1*LvLwMHRozBy5vjh45MRHJQ.png"/></div></figure><figure class="jv jw jx jy gt jz gh gi paragraph-image"><div role="button" tabindex="0" class="ka kb di kc bf kd"><div class="gh gi mb"><img src="../Images/0be94e180d8b8a586ac35bafcf14838e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*hlZfcyMJ8nU1oCIHLjSqCQ.png"/></div></div></figure><p id="1b78" class="pw-post-body-paragraph kk kl iq km b kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh ij bi translated"><strong class="km ir">业务用途</strong></p><p id="3126" class="pw-post-body-paragraph kk kl iq km b kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh ij bi translated">假设您的公司最近推出了一种产品，他们想了解产品在市场上的接受情况。该模型将通过利用产品评论并查看有多少人给出了积极的评论以及有多少人不喜欢该产品来帮助您预测情绪。</p><figure class="jv jw jx jy gt jz gh gi paragraph-image"><div role="button" tabindex="0" class="ka kb di kc bf kd"><div class="gh gi mc"><img src="../Images/5bc25ace5d436db7e8973f774c6bb93c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*0XfpMPVXIHvMnQ9tZVGmWg.png"/></div></div></figure><p id="c704" class="pw-post-body-paragraph kk kl iq km b kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh ij bi translated">3000条评论是负面的，你可能想要检查顾客不喜欢该产品的确切原因。你可以通过制造负面评论的文字云来做到这一点</p><figure class="jv jw jx jy gt jz gh gi paragraph-image"><div role="button" tabindex="0" class="ka kb di kc bf kd"><div class="gh gi md"><img src="../Images/3dab48ac5b9971403a7723ff18307aac.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*H5uDSucNfTrPfoo7X_kOmA.png"/></div></div></figure><figure class="jv jw jx jy gt jz gh gi paragraph-image"><div class="gh gi me"><img src="../Images/b75d37d96968524af17141dcb2accda2.png" data-original-src="https://miro.medium.com/v2/resize:fit:1248/format:webp/1*d1vZDGvDWlsHU_uIRZT5bg.png"/></div></figure><p id="0d34" class="pw-post-body-paragraph kk kl iq km b kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh ij bi translated">正如你所看到的，人们对产品的电池、屏幕和卖家都不满意。这些信息有助于改善产品和整体客户体验。</p><p id="b0df" class="pw-post-body-paragraph kk kl iq km b kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh ij bi translated"><strong class="km ir">结论</strong></p><p id="5484" class="pw-post-body-paragraph kk kl iq km b kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh ij bi translated">本博客主要关注面向初学者的NLP情感分析用例，一旦您理解了word2vec算法，最好转向更高级的文本分类技术，如构建神经网络，因为上述方法的缺点是它可能无法很好地执行多类文本分类，因此，可以探索深度学习神经网络来解决这类问题。</p><p id="80d6" class="pw-post-body-paragraph kk kl iq km b kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh ij bi translated"><strong class="km ir">代码链接</strong></p><p id="aa83" class="pw-post-body-paragraph kk kl iq km b kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh ij bi translated">代码可以从<a class="ae lj" href="https://www.kaggle.com/code/simonityagi/a-guide-to-sentiment-analysis-using-word2vec" rel="noopener ugc nofollow" target="_blank">这里引用</a></p><p id="3ae9" class="pw-post-body-paragraph kk kl iq km b kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh ij bi translated"><strong class="km ir">参考文献</strong></p><ol class=""><li id="a222" class="mf mg iq km b kn ko kr ks kv mh kz mi ld mj lh mk ml mm mn bi translated"><a class="ae lj" href="https://kavita-ganesan.com/comparison-between-cbow-skipgram-subword/#.YYqT32BBzIU" rel="noopener ugc nofollow" target="_blank">https://ka vita-ganesan . com/comparison-between-cbow-skip gram-subword/# . yyqt 32 bbziu</a></li></ol><p id="5318" class="pw-post-body-paragraph kk kl iq km b kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh ij bi translated"><a class="ae lj" href="https://machinelearningmastery.com/develop-word-embeddings-python-gensim/" rel="noopener ugc nofollow" target="_blank">https://machine learning mastery . com/develop-word-embeddings-python-gensim/</a></p><p id="a467" class="pw-post-body-paragraph kk kl iq km b kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh ij bi translated">2.skip-gram工作参考—<a class="ae lj" href="https://towardsdatascience.com/word2vec-skip-gram-model-part-1-intuition-78614e4d6e0b%20%0d3" rel="noopener" target="_blank">https://towards data science . com/word 2 vec-skip-gram-model-part-1-intuition-78614 E4 d6e 0 b</a></p></div></div>    
</body>
</html>