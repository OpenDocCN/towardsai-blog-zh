<html>
<head>
<title>Understand CNN Basics with a Keras Example in Python</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">通过Python中的Keras示例了解CNN基础知识</h1>
<blockquote>原文：<a href="https://pub.towardsai.net/understand-cnn-basics-with-a-keras-example-in-python-c1fd6c449935?source=collection_archive---------1-----------------------#2021-06-19">https://pub.towardsai.net/understand-cnn-basics-with-a-keras-example-in-python-c1fd6c449935?source=collection_archive---------1-----------------------#2021-06-19</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><h2 id="3128" class="ir is it bd b dl iu iv iw ix iy iz dk ja translated" aria-label="kicker paragraph"><a class="ae ep" href="https://towardsai.net/p/category/machine-learning/deep-learning" rel="noopener ugc nofollow" target="_blank">深度学习</a></h2><div class=""/><div class=""><h2 id="d5ba" class="pw-subtitle-paragraph jz jc it bd b ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq dk translated">用于图像过程分析的深度神经网络算法</h2></div><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi kr"><img src="../Images/b67b339141b9a2a8d63293dc279b66c3.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*umiIh8jxxXD5UyJF_ImHrA.png"/></div></div><figcaption class="ld le gj gh gi lf lg bd b be z dk translated">图片<a class="ae lh" href="https://indoml.com/2018/03/07/student-notes-convolutional-neural-networks-cnn-introduction/" rel="noopener ugc nofollow" target="_blank">来源</a></figcaption></figure><p id="cbe8" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">在本文中，我们将尝试用Keras框架实现基本的CNN模型。卷积神经网络的好处在于，它通过保留最大限度的信息来减少或最小化图像的维度和参数，从而训练过程变得快速并消耗较少的计算能力。</p><p id="5c1f" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">我们将尝试一步一步地在google colab中实现代码。</p><p id="9a5d" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated"><strong class="lk jd">我们为什么要用CNN？</strong></p><p id="7461" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">使用卷积神经网络的主要考虑是对于图像，以前的算法不太适合大量的图像数据集和保留图像信息。</p><h2 id="b5fb" class="me mf it bd mg mh mi dn mj mk ml dp mm lr mn mo mp lv mq mr ms lz mt mu mv iz bi translated">我们将讨论代码旁边的基本术语，所以让我们开始练习。</h2><p id="9c01" class="pw-post-body-paragraph li lj it lk b ll mw kd ln lo mx kg lq lr my lt lu lv mz lx ly lz na mb mc md im bi translated">我们必须导入某些与Keras相关联的库来实现CNN模型。</p><pre class="ks kt ku kv gt nb nc nd ne aw nf bi"><span id="c5e7" class="me mf it nc b gy ng nh l ni nj"><strong class="nc jd">#basic libraries</strong><br/>import matplotlib.pyplot as plt<br/>from numpy import asarray<br/>import numpy as np<br/>import pandas as pd<br/>import cv2 as cv</span><span id="0080" class="me mf it nc b gy nk nh l ni nj"><strong class="nc jd">#importing Keras libraries</strong><br/>import keras<br/>from keras.models import Sequential<br/>from keras.layers import Dense, Conv2D , MaxPool2D , Activation</span><span id="b19f" class="me mf it nc b gy nk nh l ni nj"><strong class="nc jd">#colab don't support cv2.imshow method, so importing cv2_imshow</strong><br/>from google.colab.patches import cv2_imshow </span><span id="4cda" class="me mf it nc b gy nk nh l ni nj"><strong class="nc jd">#for image pre-processing</strong><br/>from skimage import io</span></pre><p id="3a51" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">如果有些人有keras库，那么在TensorFlow之后安装它，因为keras是在TensorFlow之上工作的。</p><p id="3c89" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">我们在卷积神经网络模型中看到卷积层，有时人们会问你在一个模型中使用了多少层。现在，我们将看到用于制作CNN模型的一层的组件。</p><p id="72b3" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated"><strong class="lk jd">步骤1: </strong>从数据集中获取输入图像。这取决于图像是RGB格式还是灰度格式。对于RGB格式，尺寸为(n x n x 3)，灰度尺寸为(n x n)。</p><p id="0d33" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated"><strong class="lk jd">第二步:</strong>在第一步之后，下一步使用可以在(m×m)维中的过滤器或内核。我们可以使用滤波器的数量来确定来自输入图像的不同信息。</p><p id="f4a3" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated"><strong class="lk jd">步骤3: </strong>该步骤是通过对输入图像使用滤波器来获得维度(a×a)的2D图像。如果我们使用“Y”数量的滤波器，那么我们的输出具有“Y”数量的2D图像，即(a x a x Y)。</p><p id="3014" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">在制作一层CNN模型中使用的基本术语是滤波器、步长、填充和图像的通道数。</p><ul class=""><li id="6af2" class="nl nm it lk b ll lm lo lp lr nn lv no lz np md nq nr ns nt bi translated"><strong class="lk jd">滤波器:</strong>用于与图像相乘，得到2D图像。</li><li id="cadf" class="nl nm it lk b ll nu lo nv lr nw lv nx lz ny md nq nr ns nt bi translated"><strong class="lk jd">步幅:</strong>是一个依赖于一个像素一个像素的滤镜或内核的运动。</li><li id="fb98" class="nl nm it lk b ll nu lo nv lr nw lv nx lz ny md nq nr ns nt bi translated"><strong class="lk jd">填充:</strong>这是输入图像周围“零”值像素的额外尺寸，以保留最大信息。</li><li id="12ae" class="nl nm it lk b ll nu lo nv lr nw lv nx lz ny md nq nr ns nt bi translated"><strong class="lk jd">通道:</strong>它是三通道或单通道图像，即如果输入图像是RGB，则它是“3”通道图像，如果输入图像是灰度，则它是“1”通道图像。</li></ul><div class="nz oa gp gr ob oc"><a rel="noopener  ugc nofollow" target="_blank" href="/step-by-step-basic-understanding-of-neural-networks-with-keras-in-python-94f4afd026e5"><div class="od ab fo"><div class="oe ab of cl cj og"><h2 class="bd jd gy z fp oh fr fs oi fu fw jc bi translated">使用Python中的Keras逐步基本了解神经网络</h2><div class="oj l"><h3 class="bd b gy z fp oh fr fs oi fu fw dk translated">具有定义的神经网络的学习</h3></div><div class="ok l"><p class="bd b dl z fp oh fr fs oi fu fw dk translated">pub.towardsai.net</p></div></div><div class="ol l"><div class="om l on oo op ol oq lb oc"/></div></div></a></div><div class="nz oa gp gr ob oc"><a rel="noopener  ugc nofollow" target="_blank" href="/bitcoin-price-prediction-with-rnn-and-lstm-in-python-f912d57c483e"><div class="od ab fo"><div class="oe ab of cl cj og"><h2 class="bd jd gy z fp oh fr fs oi fu fw jc bi translated">用Python实现RNN和LSTM的比特币价格预测</h2><div class="oj l"><h3 class="bd b gy z fp oh fr fs oi fu fw dk translated">使用深度学习预测比特币价格</h3></div><div class="ok l"><p class="bd b dl z fp oh fr fs oi fu fw dk translated">pub.towardsai.net</p></div></div><div class="ol l"><div class="or l on oo op ol oq lb oc"/></div></div></a></div><pre class="ks kt ku kv gt nb nc nd ne aw nf bi"><span id="417a" class="me mf it nc b gy ng nh l ni nj">#Getting an input from the website with mentioned URL below<br/>urls = ["https://placekitten.com/800/571"]</span><span id="19b1" class="me mf it nc b gy nk nh l ni nj">#reading the image<br/>image = io.imread(url)</span><span id="f1f2" class="me mf it nc b gy nk nh l ni nj">#converting image from BGR to RGB<br/>image_2 = cv.cvtColor(image, cv.COLOR_BGR2RGB)</span><span id="d038" class="me mf it nc b gy nk nh l ni nj">#converting RGB to grayscale image<br/>gray_image = cv.cvtColor(image_2, cv.COLOR_RGB2GRAY)</span><span id="6830" class="me mf it nc b gy nk nh l ni nj">#display the image<br/>cv2_imshow(gray_image)</span></pre><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div class="gh gi os"><img src="../Images/94c24e36a74918b642e7b8dca02a9063.png" data-original-src="https://miro.medium.com/v2/resize:fit:740/format:webp/1*7YzjvlgVCEGI0ClJF2UwSQ.png"/></div><figcaption class="ld le gj gh gi lf lg bd b be z dk translated">输入图像。作者的照片</figcaption></figure><p id="8cc7" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">要检查输入图像的形状</p><pre class="ks kt ku kv gt nb nc nd ne aw nf bi"><span id="05fd" class="me mf it nc b gy ng nh l ni nj">gray_image.shape</span><span id="dac4" class="me mf it nc b gy nk nh l ni nj"><strong class="nc jd">#output:</strong> (571, 800)</span></pre><p id="794f" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">正如我们所知，模型的输入图像是方形的，以使过滤器正常工作。因此，我们需要调整输入图像的大小。</p><pre class="ks kt ku kv gt nb nc nd ne aw nf bi"><span id="58a5" class="me mf it nc b gy ng nh l ni nj">width = 512<br/>height = 512<br/>dim = (width, height)</span><span id="cdaa" class="me mf it nc b gy nk nh l ni nj"># resize image<br/>img = cv2.resize(gray_image, dim, interpolation = cv2.INTER_AREA)</span><span id="1659" class="me mf it nc b gy nk nh l ni nj">img.shape</span><span id="8af3" class="me mf it nc b gy nk nh l ni nj"><strong class="nc jd">#output:</strong> (512, 512)</span></pre><p id="ebea" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">当我们向keras提供图像时，它需要处于完美的维度，这样keras中的过程才能完美地工作。</p><pre class="ks kt ku kv gt nb nc nd ne aw nf bi"><span id="f87f" class="me mf it nc b gy ng nh l ni nj">img_batch = img.reshape(1, img.shape[0], img.shape[1], 1)<br/>img_batch.shape</span><span id="41b1" class="me mf it nc b gy nk nh l ni nj">#output: (1, 512, 512, 1)</span></pre><p id="ba52" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">第一个参数是批量图像的数量，最后一个参数是“1”，这意味着它是一个灰度图像。</p><p id="8c7d" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">现在，我们将在没有激活和最大池的情况下制作我们的卷积神经网络模型。权重将由模型本身随机选择。</p><pre class="ks kt ku kv gt nb nc nd ne aw nf bi"><span id="2a44" class="me mf it nc b gy ng nh l ni nj">model1 = Sequential()</span><span id="7601" class="me mf it nc b gy nk nh l ni nj">model1.add(Conv2D(1, (15,15), padding= 'valid', input_shape =<br/>img_batch.shape[1:]))</span><span id="f080" class="me mf it nc b gy nk nh l ni nj">model1.summary()</span></pre><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div class="gh gi ot"><img src="../Images/a0ed9b6abd4ffcda7ebf0ccc822c9c40.png" data-original-src="https://miro.medium.com/v2/resize:fit:1094/format:webp/1*u_X0bJsSyEYlpTEEgA3L1g.png"/></div><figcaption class="ld le gj gh gi lf lg bd b be z dk translated">模型1的总结。作者的照片</figcaption></figure><p id="99d6" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">这里，我们使用stride的默认值“1 ”,填充为“有效”,这意味着我们不提供任何填充。第一个Conv2D层的第一个参数是“1”，这是我们使用的滤镜数量，第二个参数是滤镜的大小，这里滤镜的尺寸是(15 x 15)。</p><p id="0910" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">CNN模型第一层的总结如上图。使用滤波器后的输出形状是(498×498×1 ),可训练参数是226。</p><p id="3329" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">使用或不使用过滤器、填充和步幅后，获得输出形状的公式如下所示:</p><pre class="ks kt ku kv gt nb nc nd ne aw nf bi"><span id="f8e6" class="me mf it nc b gy ng nh l ni nj">output shape= (input shape+2* padding — filter size)/stride + 1<br/>output shape = (512 + 2*0 - 15)/1 +1 = 498</span><span id="ee56" class="me mf it nc b gy nk nh l ni nj">#the params we get <br/>params = number of filters*(filter size) + number of filters*1<br/>params = 1*(15*15) +1*1 = 226</span></pre><p id="7f75" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">因此，这226个参数将在反向传播过程中被训练。现在，我们将对我们的模型使用预测方法。</p><pre class="ks kt ku kv gt nb nc nd ne aw nf bi"><span id="ab00" class="me mf it nc b gy ng nh l ni nj">conv_img = model1.predict(img_batch)</span></pre><p id="cb99" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">我们将看到使用模型1后的输出图像。</p><pre class="ks kt ku kv gt nb nc nd ne aw nf bi"><span id="f0c4" class="me mf it nc b gy ng nh l ni nj">conv_img_show = conv_img.reshape(conv_img.shape[1],<br/>                                 conv_img.shape[2])</span><span id="15dd" class="me mf it nc b gy nk nh l ni nj">plt.imshow(conv_img_show, cmap = 'gray')<br/>plt.show()</span></pre><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div class="gh gi ou"><img src="../Images/20ed2647cd25a4a86972f98d047900a1.png" data-original-src="https://miro.medium.com/v2/resize:fit:528/format:webp/1*5U56ySJZCO4SRt4RbK138w.png"/></div><figcaption class="ld le gj gh gi lf lg bd b be z dk translated">模型1后的输出图像。作者的照片</figcaption></figure><p id="cea5" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">正如我们在上面的输出图像中看到的，尺寸是(498 x 498)。</p><p id="3f8c" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">现在，我们将看到使用激活函数(即relu和max-pooling)后的输出图像。</p><pre class="ks kt ku kv gt nb nc nd ne aw nf bi"><span id="ed06" class="me mf it nc b gy ng nh l ni nj">model2 = Sequential()</span><span id="43e2" class="me mf it nc b gy nk nh l ni nj">model2.add(Conv2D(1, (15,15), padding= 'valid', input_shape = img_batch.shape[1:]))</span><span id="ae08" class="me mf it nc b gy nk nh l ni nj">model2.add(Activation('relu'))<br/>model2.add(MaxPool2D(pool_size=(2,2)))</span><span id="fb89" class="me mf it nc b gy nk nh l ni nj">model2.summary()</span><span id="29b5" class="me mf it nc b gy nk nh l ni nj">conv_img = model2.predict(img_batch)<br/>conv_img_show = conv_img.reshape(conv_img.shape[1], conv_img.shape[2])</span><span id="c234" class="me mf it nc b gy nk nh l ni nj">plt.imshow(conv_img_show, cmap = 'gray')<br/>plt.show()</span></pre><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi ov"><img src="../Images/fbec9d6b0037735b30e44926be9b0e00.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*BUzjDQTGp_jYKhDM3VNz1Q.png"/></div></div><figcaption class="ld le gj gh gi lf lg bd b be z dk translated">模型2的摘要和输出图像。作者的照片</figcaption></figure><p id="4ae5" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">正如我们在上面的总结中看到的，激活和最大池层是在总结中添加的。这是一个单层卷积神经网络模型。</p><p id="79f8" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">由于最大池操作，输出图像尺寸变小。当内核放置在输入图像上时，最大池内核取图像部分的最大数量。</p><h2 id="d233" class="me mf it bd mg mh mi dn mj mk ml dp mm lr mn mo mp lv mq mr ms lz mt mu mv iz bi translated">结论</h2><p id="fdec" class="pw-post-body-paragraph li lj it lk b ll mw kd ln lo mx kg lq lr my lt lu lv mz lx ly lz na mb mc md im bi translated">这篇文章是关于CNN模型的最基本的观察。要阅读本文，需要先了解与CNN模型实现相关的术语。</p><p id="3661" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">我希望你喜欢这篇文章。通过我的<a class="ae lh" href="https://www.linkedin.com/in/data-scientist-95040a1ab/" rel="noopener ugc nofollow" target="_blank"> LinkedIn </a>和<a class="ae lh" href="https://twitter.com/amitprius" rel="noopener ugc nofollow" target="_blank"> twitter </a>联系我。</p><h1 id="4b7f" class="ow mf it bd mg ox oy oz mj pa pb pc mm ki pd kj mp kl pe km ms ko pf kp mv pg bi translated">推荐文章</h1><p id="68d6" class="pw-post-body-paragraph li lj it lk b ll mw kd ln lo mx kg lq lr my lt lu lv mz lx ly lz na mb mc md im bi translated"><a class="ae lh" href="https://medium.com/towards-artificial-intelligence/nlp-zero-to-hero-with-python-2df6fcebff6e?sk=2231d868766e96b13d1e9d7db6064df1" rel="noopener"> 1。NLP —零到英雄与Python </a> <br/> 2。<a class="ae lh" href="https://medium.com/towards-artificial-intelligence/python-data-structures-data-types-and-objects-244d0a86c3cf?sk=42f4b462499f3fc3a160b21e2c94dba6" rel="noopener"> Python数据结构数据类型和对象</a>T5】3 .<a class="ae lh" rel="noopener ugc nofollow" target="_blank" href="/exception-handling-concepts-in-python-4d5116decac3?source=friends_link&amp;sk=a0ed49d9fdeaa67925eac34ecb55ea30">Python中的异常处理概念</a> <br/> 4。<a class="ae lh" rel="noopener ugc nofollow" target="_blank" href="/deep-learning-88e218b74a14?source=friends_link&amp;sk=540bf9088d31859d50dbddab7524ba35">为什么LSTM在深度学习方面比RNN更有用？</a> <br/> 5。<a class="ae lh" rel="noopener ugc nofollow" target="_blank" href="/neural-networks-the-rise-of-recurrent-neural-networks-df740252da88?source=friends_link&amp;sk=6844935e3de14e478ce00f0b22e419eb">神经网络:递归神经网络的兴起</a> <br/> 6。<a class="ae lh" href="https://medium.com/towards-artificial-intelligence/fully-explained-linear-regression-with-python-fe2b313f32f3?source=friends_link&amp;sk=53c91a2a51347ec2d93f8222c0e06402" rel="noopener">用Python </a> <br/> 7全面讲解了线性回归。<a class="ae lh" href="https://medium.com/towards-artificial-intelligence/fully-explained-logistic-regression-with-python-f4a16413ddcd?source=friends_link&amp;sk=528181f15a44e48ea38fdd9579241a78" rel="noopener">用Python </a> <br/>充分解释了Logistic回归8。<a class="ae lh" rel="noopener ugc nofollow" target="_blank" href="/differences-between-concat-merge-and-join-with-python-1a6541abc08d?source=friends_link&amp;sk=3b37b694fb90db16275059ea752fc16a">concat()、merge()和join()与Python </a> <br/>的区别9。<a class="ae lh" rel="noopener ugc nofollow" target="_blank" href="/data-wrangling-with-python-part-1-969e3cc81d69?source=friends_link&amp;sk=9c3649cf20f31a5c9ead51c50c89ba0b">与Python的数据角力—第一部分</a> <br/> 10。<a class="ae lh" href="https://medium.com/analytics-vidhya/confusion-matrix-in-machine-learning-91b6e2b3f9af?source=friends_link&amp;sk=11c6531da0bab7b504d518d02746d4cc" rel="noopener">机器学习中的混淆矩阵</a></p></div></div>    
</body>
</html>