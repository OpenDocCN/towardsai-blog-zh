<html>
<head>
<title>ELI5: Expectation Maximization Clustering</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">ELI5:期望最大化聚类</h1>
<blockquote>原文：<a href="https://pub.towardsai.net/expectation-maximization-em-clustering-every-data-scientist-should-know-2b47fbd0dbc0?source=collection_archive---------1-----------------------#2022-11-11">https://pub.towardsai.net/expectation-maximization-em-clustering-every-data-scientist-should-know-2b47fbd0dbc0?source=collection_archive---------1-----------------------#2022-11-11</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="af32" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">每个数据科学家都应该知道的聚类技术</h2></div><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ki"><img src="../Images/8b313531cac0251608922a7a6e134f7f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*kuJKi2NCfFINRiqW9D7Mnw.jpeg"/></div></div><figcaption class="ku kv gj gh gi kw kx bd b be z dk translated">图片来源:Unsplash</figcaption></figure><p id="4a9a" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">假设你认识100个人，你根据他们的性格特征给他们打分(1-10)，比如风趣、互动、聪明、勤奋等。现在，你想找一群性格特征相似的人。我们如何做到这一点？</p><p id="ed21" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated"><strong class="la iu">我们执行聚类</strong>！</p><p id="92c6" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">在这篇博客中，我将涉及以下主题:</p><ul class=""><li id="b8e8" class="lu lv it la b lb lc le lf lh lw ll lx lp ly lt lz ma mb mc bi translated"><em class="md">聚类&amp;其类型。</em></li><li id="5050" class="lu lv it la b lb me le mf lh mg ll mh lp mi lt lz ma mb mc bi translated"><em class="md">高斯混合模型背后的直觉(GMM) &amp;期望最大化(EM)。</em></li><li id="1fc5" class="lu lv it la b lb me le mf lh mg ll mh lp mi lt lz ma mb mc bi translated"><em class="md">EM聚类中如何挑选聚类个数？</em></li><li id="719f" class="lu lv it la b lb me le mf lh mg ll mh lp mi lt lz ma mb mc bi translated"><em class="md">什么时候使用EM聚类？</em></li><li id="b2d9" class="lu lv it la b lb me le mf lh mg ll mh lp mi lt lz ma mb mc bi translated"><em class="md">EM的Python实现。</em></li></ul><p id="559b" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">我们开始吧！</p><h2 id="e12d" class="mj mk it bd ml mm mn dn mo mp mq dp mr lh ms mt mu ll mv mw mx lp my mz na nb bi translated">什么是集群？</h2><p id="c2b3" class="pw-post-body-paragraph ky kz it la b lb nc ju ld le nd jx lg lh ne lj lk ll nf ln lo lp ng lr ls lt im bi translated">聚类是将数据点分组在一起的一种方式，使得同一聚类中的数据点彼此之间比不同聚类中的数据点更相似。</p><h2 id="d0ab" class="mj mk it bd ml mm mn dn mo mp mq dp mr lh ms mt mu ll mv mw mx lp my mz na nb bi translated">有两种类型的聚类技术:</h2><ol class=""><li id="b687" class="lu lv it la b lb nc le nd lh nh ll ni lp nj lt nk ma mb mc bi translated">硬聚类:一个数据点只属于一个聚类。集群之间没有重叠。比如- K-means聚类，层次聚类等。</li><li id="3ba0" class="lu lv it la b lb me le mf lh mg ll mh lp mi lt nk ma mb mc bi translated">软聚类:一个数据点可以同时属于多个聚类(带有一些权重/概率)。集群之间有重叠。例如，加权K均值和高斯混合模型(GMM)。</li></ol><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi nl"><img src="../Images/986eedbf0776d99c614dc26ed544a880.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*igSLrzklG6g1LYzPRfJi5Q.jpeg"/></div></div><figcaption class="ku kv gj gh gi kw kx bd b be z dk translated">硬聚类与软聚类(图片由作者提供)</figcaption></figure><h1 id="d6a7" class="nm mk it bd ml nn no np mo nq nr ns mr jz nt ka mu kc nu kd mx kf nv kg na nw bi translated">高斯混合模型(GMM)和期望最大化(EM)算法</h1><ul class=""><li id="56b4" class="lu lv it la b lb nc le nd lh nh ll ni lp nj lt lz ma mb mc bi translated">高斯混合模型(GMM)是进行软聚类的概率方法。每个数据点被分配给具有不同概率的多个聚类。</li><li id="9eb2" class="lu lv it la b lb me le mf lh mg ll mh lp mi lt lz ma mb mc bi translated">由高斯混合模型创建的分类遵循高斯(正态)概率分布。</li><li id="c892" class="lu lv it la b lb me le mf lh mg ll mh lp mi lt lz ma mb mc bi translated">要构建任何分布，我们需要一些基本参数。为了构造高斯分布，我们需要找到分布的均值和方差。这就是期望最大化(EM)算法发挥作用的地方。</li></ul><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi nx"><img src="../Images/704ebafa6bba3dd687d555f4647d800a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*CBw8dcCU2pCErDkryIVyZw.png"/></div></div><figcaption class="ku kv gj gh gi kw kx bd b be z dk translated">基于均值和方差的不同类型的高斯分布(图片来源:维基百科)</figcaption></figure><ul class=""><li id="bd89" class="lu lv it la b lb lc le lf lh lw ll lx lp ly lt lz ma mb mc bi translated">期望最大化(EM)算法是一种寻找概率分布参数(均值/方差)的方法。</li></ul><p id="366b" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">让我们了解一下期望最大化(EM)是如何使用一维表示来构建高斯分布的。</p><h2 id="44b6" class="mj mk it bd ml mm mn dn mo mp mq dp mr lh ms mt mu ll mv mw mx lp my mz na nb bi translated">一维理解</h2><p id="0699" class="pw-post-body-paragraph ky kz it la b lb nc ju ld le nd jx lg lh ne lj lk ll nf ln lo lp ng lr ls lt im bi translated">假设我们想要对一维空间中的数据点执行高斯混合聚类。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ny"><img src="../Images/246d5f7907f1c5105fbfdacb8958383f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Wz3JKEAs7ExNx7lMIFyvuQ.png"/></div></div><figcaption class="ku kv gj gh gi kw kx bd b be z dk translated">一维数据(图片由作者提供)</figcaption></figure><p id="c300" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">为了创建上述数据点的高斯分布，我们需要找到两点:</p><ol class=""><li id="ccf4" class="lu lv it la b lb lc le lf lh lw ll lx lp ly lt nk ma mb mc bi translated">高斯数(我们稍后再看)。</li><li id="9430" class="lu lv it la b lb me le mf lh mg ll mh lp mi lt nk ma mb mc bi translated">每个高斯函数的均值和方差，这样我们就可以构造高斯函数并给它们赋值。</li></ol><p id="c051" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">现在让我们假设这个分布需要2个高斯分布。EM算法执行以下步骤来寻找高斯分布的均值和方差。</p><p id="3449" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated"><strong class="la iu">步骤1: </strong>从随机放置的高斯分布开始——具有随机均值和方差。</p><p id="1518" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">我们已经创建了2个随机高斯(黄色和蓝色)，如下所示。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi nz"><img src="../Images/86f549a8522d84a75fcf8416b6c8073d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*P8hPpzS38xL7qqinogublg.png"/></div></div><figcaption class="ku kv gj gh gi kw kx bd b be z dk translated">初始化随机高斯(图片由作者提供)</figcaption></figure><p id="ec4a" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated"><strong class="la iu">第二步(E步):</strong>找出哪一个点离两个高斯点中的哪一个更近。没有硬任务完成。每个点都有分配给蓝色和黄色分布的概率。</p><p id="f5f4" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">使用以下公式计算将点x分配给具有均值‘μ’和标准偏差’<strong class="la iu">【σ’</strong>的高斯分布的概率:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi oa"><img src="../Images/4159e855cb559cd777f21d0932c06d0c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1126/format:webp/1*KoYMxve0mhWi34cstWxpsg.png"/></div><figcaption class="ku kv gj gh gi kw kx bd b be z dk translated">将数据点x分配给分布y的概率(图片由作者提供)</figcaption></figure><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ob"><img src="../Images/f0814cd2e2ea05d368351c70ce4d1b24.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*mSVnEB60bJTjIo_2vOIIoQ.png"/></div></div><figcaption class="ku kv gj gh gi kw kx bd b be z dk translated">作者图片</figcaption></figure><p id="1636" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">靠近黄色的点很有可能是黄色分布的一部分，而靠近蓝色的点很有可能是蓝色分布的一部分。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi oc"><img src="../Images/5f48d61ccad3d5ea7a0c704efbf452ed.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*MY36IxuszijA7eElxS8g6w.png"/></div></div><figcaption class="ku kv gj gh gi kw kx bd b be z dk translated">分配点给每个高斯(图片由作者提供)</figcaption></figure><p id="2477" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated"><strong class="la iu">第三步(M步):</strong>更新高斯分布的均值和方差，以改进点分配。</p><p id="c7f3" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">使用每个点(y <em class="md"> 1 </em>，y <em class="md"> 2 </em>，…)的概率更新每个分布的平均值和标准偏差。第二步计算的y <em class="md"> n </em>，如下图。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi od"><img src="../Images/b681554d2b161642d56ff483a636cb20.png" data-original-src="https://miro.medium.com/v2/resize:fit:1036/format:webp/1*uYrScQjlipNB2dbpfo6O1w.png"/></div><figcaption class="ku kv gj gh gi kw kx bd b be z dk translated">更新黄色分布的均值和方差(图片由作者提供)</figcaption></figure><p id="07a3" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">类似地,“蓝色”分布的概率、均值和方差也使用上述公式进行更新。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi oe"><img src="../Images/4038c33d04a93b555c463f8498e0a97a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*4y1eykOuqprMP45KRA0fRQ.png"/></div></div><figcaption class="ku kv gj gh gi kw kx bd b be z dk translated">更新的高斯分布(图片由作者提供)</figcaption></figure><p id="e5fd" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated"><strong class="la iu">步骤4: </strong>重复步骤2和3，直到高斯不再更新，从而收敛。</p><p id="567c" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">经过几次迭代后，高斯分布将收敛，如下所示。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi of"><img src="../Images/f46bbbf7900d4057c765eea001d6e52d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*TPCDkOa_LTDFw44LYMT82w.png"/></div></div><figcaption class="ku kv gj gh gi kw kx bd b be z dk translated">最终高斯分布(图片由作者提供)</figcaption></figure><h2 id="f713" class="mj mk it bd ml mm mn dn mo mp mq dp mr lh ms mt mu ll mv mw mx lp my mz na nb bi translated">怎么挑K？</h2><p id="3487" class="pw-post-body-paragraph ky kz it la b lb nc ju ld le nd jx lg lh ne lj lk ll nf ln lo lp ng lr ls lt im bi translated">就像k-means聚类中没有直接的方法找到k一样，高斯混合也没有直接的方法。</p><p id="e20d" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">直觉上，我们希望在假设数据是从高斯混合模型生成的情况下，最大化数据的对数似然。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi og"><img src="../Images/0ca34af714b7b364137ea48ba83a13ac.png" data-original-src="https://miro.medium.com/v2/resize:fit:834/format:webp/1*OQMObX2PmAnxDV6OQ9T0CQ.png"/></div><figcaption class="ku kv gj gh gi kw kx bd b be z dk translated">对数似然性(图片由作者提供)</figcaption></figure><p id="d22d" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">如果高斯数等于数据点数(每个数据点都有自己的高斯数)，对数似然将达到最大值。但是，凭直觉，这并不理想，所以我们必须找出一个停止条件。那么解决办法是什么呢？</p><p id="a133" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">奥卡姆剃刀原则:我们需要在所有模型中选择最‘简单’的模型来拟合我们的数据。我们可以通过最大化BIC和最小化AIC来做到这一点，在这种情况下，它会惩罚具有大量特征(或高斯)的模型，并尝试选择一个简单的模型。</p><h2 id="3ac6" class="mj mk it bd ml mm mn dn mo mp mq dp mr lh ms mt mu ll mv mw mx lp my mz na nb bi translated">什么时候使用高斯混合模型？</h2><ol class=""><li id="adbe" class="lu lv it la b lb nc le nd lh nh ll ni lp nj lt nk ma mb mc bi translated">根据高斯分布生成数据时，识别数据模式和异常。</li><li id="d22b" class="lu lv it la b lb me le mf lh mg ll mh lp mi lt nk ma mb mc bi translated">高斯混合模型可用于生成与原始数据相似的合成数据点，从而有助于数据扩充。</li></ol><h1 id="38af" class="nm mk it bd ml nn no np mo nq nr ns mr jz nt ka mu kc nu kd mx kf nv kg na nw bi translated">使用Python实现期望最大化</h1><p id="cf87" class="pw-post-body-paragraph ky kz it la b lb nc ju ld le nd jx lg lh ne lj lk ll nf ln lo lp ng lr ls lt im bi translated"><strong class="la iu"> <em class="md">导入需要的包</em> </strong></p><pre class="kj kk kl km gt oh oi oj ok aw ol bi"><span id="7c58" class="mj mk it oi b gy om on l oo op"># for matrix inverse<br/><strong class="oi iu">import</strong> <strong class="oi iu">numpy</strong> <strong class="oi iu">as</strong> <strong class="oi iu">np</strong>                              <br/><strong class="oi iu">from</strong> <strong class="oi iu">numpy.linalg</strong> <strong class="oi iu">import</strong> inv                    <em class="md"># for matrix inverse</em><br/><strong class="oi iu">import</strong> <strong class="oi iu">matplotlib.pyplot</strong> <strong class="oi iu">as</strong> <strong class="oi iu">plt</strong>                 <br/><strong class="oi iu">from</strong> <strong class="oi iu">scipy.stats</strong> <strong class="oi iu">import</strong> multivariate_normal     <em class="md"># for generating probability density function </em></span></pre><p id="2a38" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated"><strong class="la iu"> <em class="md">创建输入数据</em> </strong></p><pre class="kj kk kl km gt oh oi oj ok aw ol bi"><span id="47c7" class="mj mk it oi b gy om on l oo op"># consider a random mean and covariance value<br/>m1 = [2,2]     <br/>m2 = [10,10]                                              <br/>cov1 = [[4, 2], [2, 4]]                                      <br/>cov2 = [[2, -1], [-1, 2]]</span><span id="d4fb" class="mj mk it oi b gy oq on l oo op">#Generating 200 samples for each mean and covariance<br/>x = np.random.multivariate_normal(m1, cov1, size=(200,))  <br/>y = np.random.multivariate_normal(m2, cov2, size=(200,))<br/>d = np.concatenate((x, y), axis=0)</span></pre><p id="55a9" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated"><strong class="la iu"> <em class="md">标绘输入数据</em> </strong></p><pre class="kj kk kl km gt oh oi oj ok aw ol bi"><span id="3230" class="mj mk it oi b gy om on l oo op">plt.figure(figsize=(10,10))                                 <br/>plt.scatter(d[:,0], d[:,1], marker='o')     <br/>plt.axis('equal')                                  <br/>plt.xlabel('X-Axis', fontsize=16)              <br/>plt.ylabel('Y-Axis', fontsize=16)                     <br/>plt.title('Ground Truth', fontsize=22)    <br/>plt.grid()            <br/>plt.show()</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi or"><img src="../Images/9a560d2cc9d4e2e73fd22053bf865871.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*hYiJpCSZBxKzfUIu_1eH-Q.png"/></div></div></figure><blockquote class="os ot ou"><p id="a68d" class="ky kz md la b lb lc ju ld le lf jx lg ov li lj lk ow lm ln lo ox lq lr ls lt im bi translated"><strong class="la iu"> <em class="it">第一步:参数的初始猜测</em> </strong></p></blockquote><pre class="kj kk kl km gt oh oi oj ok aw ol bi"><span id="53b4" class="mj mk it oi b gy om on l oo op">m1 = random.choice(d)<br/>m2 = random.choice(d)<br/>cov1 = np.cov(np.transpose(d))<br/>cov2 = np.cov(np.transpose(d))<br/>pi = 0.5</span></pre><p id="6575" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated"><strong class="la iu"> <em class="md">标绘初始状态</em> </strong></p><pre class="kj kk kl km gt oh oi oj ok aw ol bi"><span id="4303" class="mj mk it oi b gy om on l oo op">x1 = np.linspace(-4,11,200)  <br/>x2 = np.linspace(-4,11,200)<br/>X, Y = np.meshgrid(x1,x2) </span><span id="ee76" class="mj mk it oi b gy oq on l oo op">Z1 = multivariate_normal(m1, cov1)  <br/>Z2 = multivariate_normal(m2, cov2)</span><span id="dc0c" class="mj mk it oi b gy oq on l oo op">pos = np.empty(X.shape + (2,))                <em class="md"># a new array of given shape and type, without initializing entries</em><br/>pos[:, :, 0] = X; pos[:, :, 1] = Y   </span><span id="d538" class="mj mk it oi b gy oq on l oo op">plt.figure(figsize=(10,10))                                                          <em class="md"># creating the figure and assigning the size</em><br/>plt.scatter(d[:,0], d[:,1], marker='o')     <br/>plt.contour(X, Y, Z1.pdf(pos), colors="r" ,alpha = 0.5) <br/>plt.contour(X, Y, Z2.pdf(pos), colors="b" ,alpha = 0.5) <br/>plt.axis('equal')                                                                  <em class="md"># making both the axis equal</em><br/>plt.xlabel('X-Axis', fontsize=16)                                                  <em class="md"># X-Axis</em><br/>plt.ylabel('Y-Axis', fontsize=16)                                                  <em class="md"># Y-Axis</em><br/>plt.title('Initial State', fontsize=22)                                            <em class="md"># Title of the plot</em><br/>plt.grid()                                                                         <em class="md"># displaying gridlines</em><br/>plt.show()</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi oy"><img src="../Images/47d53750d656c6e5acd347552523ff5a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*uMzesQ1A7eCmq4w6fk8bUw.png"/></div></div></figure><blockquote class="os ot ou"><p id="d9e4" class="ky kz md la b lb lc ju ld le lf jx lg ov li lj lk ow lm ln lo ox lq lr ls lt im bi translated"><strong class="la iu"> <em class="it">第二步:期望第二步</em> </strong></p></blockquote><pre class="kj kk kl km gt oh oi oj ok aw ol bi"><span id="2ea3" class="mj mk it oi b gy om on l oo op"><em class="md">##Expectation step</em><br/><strong class="oi iu">def</strong> Estep(lis1):<br/>    m1=lis1[0]<br/>    m2=lis1[1]<br/>    cov1=lis1[2]<br/>    cov2=lis1[3]<br/>    pi=lis1[4]<br/>    <br/>    pt2 = multivariate_normal.pdf(d, mean=m2, cov=cov2)<br/>    pt1 = multivariate_normal.pdf(d, mean=m1, cov=cov1)<br/>    w1 = pi * pt2<br/>    w2 = (1-pi) * pt1<br/>    eval1 = w1/(w1+w2)</span><span id="9bc4" class="mj mk it oi b gy oq on l oo op">    <strong class="oi iu">return</strong>(eval1)</span></pre><blockquote class="os ot ou"><p id="5d76" class="ky kz md la b lb lc ju ld le lf jx lg ov li lj lk ow lm ln lo ox lq lr ls lt im bi translated"><strong class="la iu"> <em class="it">第三步:最大化步骤</em> </strong></p></blockquote><pre class="kj kk kl km gt oh oi oj ok aw ol bi"><span id="cedd" class="mj mk it oi b gy om on l oo op"><em class="md">## Maximization step</em><br/><strong class="oi iu">def</strong> Mstep(eval1):<br/>    num_mu1,din_mu1,num_mu2,din_mu2=0,0,0,0</span><span id="c870" class="mj mk it oi b gy oq on l oo op">    <strong class="oi iu">for</strong> i <strong class="oi iu">in</strong> range(0,len(d)):<br/>        num_mu1 += (1-eval1[i]) * d[i]<br/>        din_mu1 += (1-eval1[i])</span><span id="616c" class="mj mk it oi b gy oq on l oo op">        num_mu2 += eval1[i] * d[i]<br/>        din_mu2 += eval1[i]</span><span id="9e9c" class="mj mk it oi b gy oq on l oo op">    mu1 = num_mu1/din_mu1<br/>    mu2 = num_mu2/din_mu2</span><span id="d7ad" class="mj mk it oi b gy oq on l oo op">    num_s1,din_s1,num_s2,din_s2=0,0,0,0<br/>    <strong class="oi iu">for</strong> i <strong class="oi iu">in</strong> range(0,len(d)):</span><span id="9888" class="mj mk it oi b gy oq on l oo op">        q1 = np.matrix(d[i]-mu1)<br/>        num_s1 += (1-eval1[i]) * np.dot(q1.T, q1)<br/>        din_s1 += (1-eval1[i])</span><span id="b08c" class="mj mk it oi b gy oq on l oo op">        q2 = np.matrix(d[i]-mu2)<br/>        num_s2 += eval1[i] * np.dot(q2.T, q2)<br/>        din_s2 += eval1[i]</span><span id="5865" class="mj mk it oi b gy oq on l oo op">    s1 = num_s1/din_s1<br/>    s2 = num_s2/din_s2</span><span id="b853" class="mj mk it oi b gy oq on l oo op">    pi = sum(eval1)/len(d)<br/>    <br/>    lis2=[mu1,mu2,s1,s2,pi]<br/>    <strong class="oi iu">return</strong>(lis2)</span></pre><p id="6b8b" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated"><strong class="la iu"> <em class="md">功能绘制EM算法</em> </strong></p><pre class="kj kk kl km gt oh oi oj ok aw ol bi"><span id="83ec" class="mj mk it oi b gy om on l oo op"><strong class="oi iu">def</strong> plot(lis1):<br/>    mu1=lis1[0]<br/>    mu2=lis1[1]<br/>    s1=lis1[2]<br/>    s2=lis1[3]<br/>    Z1 = multivariate_normal(mu1, s1)  <br/>    Z2 = multivariate_normal(mu2, s2)</span><span id="57aa" class="mj mk it oi b gy oq on l oo op">    pos = np.empty(X.shape + (2,))                <em class="md"># a new array of given shape and type, without initializing entries</em><br/>    pos[:, :, 0] = X; pos[:, :, 1] = Y   </span><span id="9c05" class="mj mk it oi b gy oq on l oo op">    plt.figure(figsize=(10,10))                                                          <em class="md"># creating the figure and assigning the size</em><br/>    plt.scatter(d[:,0], d[:,1], marker='o')     <br/>    plt.contour(X, Y, Z1.pdf(pos), colors="r" ,alpha = 0.5) <br/>    plt.contour(X, Y, Z2.pdf(pos), colors="b" ,alpha = 0.5) <br/>    plt.axis('equal')                                                                  <em class="md"># making both the axis equal</em><br/>    plt.xlabel('X-Axis', fontsize=16)                                                  <em class="md"># X-Axis</em><br/>    plt.ylabel('Y-Axis', fontsize=16)                                                  <em class="md"># Y-Axis</em><br/>    plt.grid()                                                                         <em class="md"># displaying gridlines</em><br/>    plt.show()</span></pre><blockquote class="os ot ou"><p id="9c20" class="ky kz md la b lb lc ju ld le lf jx lg ov li lj lk ow lm ln lo ox lq lr ls lt im bi translated"><strong class="la iu"> <em class="it">第四步:调用函数，重复直到收敛</em> </strong></p></blockquote><pre class="kj kk kl km gt oh oi oj ok aw ol bi"><span id="71c9" class="mj mk it oi b gy om on l oo op">iterations = 20<br/>lis1=[m1,m2,cov1,cov2,pi]<br/>for i in range(0,iterations):<br/>    lis2 = Mstep(Estep(lis1))<br/>    lis1=lis2<br/>    if(i==0 or i == 5 or i == 10 or i == 19):<br/>        plot(lis1)</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi oz"><img src="../Images/db398b5cf739ec8483a98e6143b33c96.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*lclbtwOiDe4bt9yddshqDA.png"/></div></div></figure><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi pa"><img src="../Images/d03a1eee66c8d4bcbb4942a7dd82cc2a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*NXXN490ZdU7Yqcu0lkiOGA.png"/></div></div></figure><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi pb"><img src="../Images/b38a817f2182907537fa500fc356c2cc.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*8KleNO4V2pmgHAB9UX_Rig.png"/></div></div></figure><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi pc"><img src="../Images/f62b9840cb56d19927e958635fd6a55c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*10FMMPNhEMSFwWr8cQkVRw.png"/></div></div></figure><p id="8e80" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">如果你觉得这个博客有用，分享一些掌声:)如果你想让我涵盖任何数据科学主题，请随时发表评论。</p></div><div class="ab cl pd pe hx pf" role="separator"><span class="pg bw bk ph pi pj"/><span class="pg bw bk ph pi pj"/><span class="pg bw bk ph pi"/></div><div class="im in io ip iq"><h1 id="2847" class="nm mk it bd ml nn pk np mo nq pl ns mr jz pm ka mu kc pn kd mx kf po kg na nw bi translated">谢谢大家！</h1><p id="0b7a" class="pw-post-body-paragraph ky kz it la b lb nc ju ld le nd jx lg lh ne lj lk ll nf ln lo lp ng lr ls lt im bi translated">你可以在收件箱里看到我所有的帖子。 <a class="ae pp" href="https://anmol3015.medium.com/subscribe" rel="noopener"> <strong class="la iu"> <em class="md">说到这里</em> </strong> <em class="md">！</em>T45】</a></p><p id="02aa" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated"><em class="md">如果你自己喜欢体验中等，可以考虑通过</em> <a class="ae pp" href="https://anmol3015.medium.com/membership" rel="noopener"> <strong class="la iu"> <em class="md">报名会员</em> </strong> </a> <em class="md">来支持我和其他几千个作家。它每个月只需要5美元，它极大地支持了我们，作家，你可以在媒体上看到所有精彩的故事。</em></p><h2 id="1d64" class="mj mk it bd ml mm mn dn mo mp mq dp mr lh ms mt mu ll mv mw mx lp my mz na nb bi translated"><strong class="ak">参考:</strong></h2><div class="pq pr gp gr ps pt"><a href="https://medium.com/@prateek.shubham.94/expectation-maximization-algorithm-7a4d1b65ca55" rel="noopener follow" target="_blank"><div class="pu ab fo"><div class="pv ab pw cl cj px"><h2 class="bd iu gy z fp py fr fs pz fu fw is bi translated">期望值最大化算法</h2><div class="qa l"><h3 class="bd b gy z fp py fr fs pz fu fw dk translated">K-means方法是硬分配聚类的一个例子，其中每个点只能属于一个聚类…</h3></div><div class="qb l"><p class="bd b dl z fp py fr fs pz fu fw dk translated">medium.com</p></div></div><div class="qc l"><div class="qd l qe qf qg qc qh ks pt"/></div></div></a></div></div></div>    
</body>
</html>