<html>
<head>
<title>7 Classification Algorithms for Machine Learning</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">机器学习的7种分类算法</h1>
<blockquote>原文：<a href="https://pub.towardsai.net/7-classification-algorithms-for-machine-learning-918b8b5cd9a6?source=collection_archive---------0-----------------------#2022-11-25">https://pub.towardsai.net/7-classification-algorithms-for-machine-learning-918b8b5cd9a6?source=collection_archive---------0-----------------------#2022-11-25</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="54d5" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">了解机器学习算法的差异</h2></div><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ki"><img src="../Images/55cd61a27fa2fbbbd45fa6a0b523754b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*SPeUoVObpUp7K6S8"/></div></div><figcaption class="ku kv gj gh gi kw kx bd b be z dk translated">由<a class="ae ky" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上的<a class="ae ky" href="https://unsplash.com/@pietrozj?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Pietro Jeng </a>拍摄</figcaption></figure><p id="076b" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">机器学习模型是一种算法，旨在研究数据并创建解决人类问题的输出。什么是机器学习中的分类算法，每个模型在解决我们的业务问题时有多大用处？</p><h2 id="54f7" class="lv lw it bd lx ly lz dn ma mb mc dp md li me mf mg lm mh mi mj lq mk ml mm mn bi translated"><strong class="ak">监督学习、非监督学习和强化学习之间有什么区别？</strong></h2><p id="3134" class="pw-post-body-paragraph kz la it lb b lc mo ju le lf mp jx lh li mq lk ll lm mr lo lp lq ms ls lt lu im bi translated">机器学习是一个研究领域，人类试图赋予机器从数据中明确学习的能力。这台机器就是我们所说的机器学习模型，我们用它来解决我们的问题。业界有各种形式的机器学习应用；例如，人脸识别机器和垃圾邮件检测就是机器学习模型的应用。</p><p id="6dae" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">知道在每个用例中应用哪个机器学习模型是至关重要的，因为不是所有的模型都适用于每个用例。一个合适的模型将改进我们的模型度量。</p><p id="2f71" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">机器学习是一个很大的领域，其中使用了许多术语。为了清楚地理解什么是分类算法，首先，我们需要谈谈基于人类监督的三种不同的机器学习系统；<strong class="lb iu">有监督的</strong>、<strong class="lb iu">无监督的</strong>、<strong class="lb iu">强化学习。</strong></p><h2 id="5369" class="lv lw it bd lx ly lz dn ma mb mc dp md li me mf mg lm mh mi mj lq mk ml mm mn bi translated"><strong class="ak">监督学习</strong></h2><p id="b575" class="pw-post-body-paragraph kz la it lb b lc mo ju le lf mp jx lh li mq lk ll lm mr lo lp lq ms ls lt lu im bi translated">监督学习是一种机器学习模型，它使用包含所需答案或解决方案的人类训练数据。训练数据已经包含了我们试图解决的问题的答案，机器应该模仿输入数据(预测器)中的模式来产生类似的输出。</p><p id="8259" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">下图显示了监督学习的训练数据示例。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi mt"><img src="../Images/10913adacd92218aac2ef33c312e4852.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*LX5KWJMoUJltOXKu"/></div></div><figcaption class="ku kv gj gh gi kw kx bd b be z dk translated">图一。作者监督学习的训练数据</figcaption></figure><p id="5000" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">监督学习有两个典型的任务；<strong class="lb iu">分类</strong>和<strong class="lb iu">回归</strong>。它们之间有什么区别？本质上，差异来自任务预测结果。</p><p id="1aaa" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">分类算法集中于谨慎的预测结果输出，例如，流失预测(输出是否流失)、心脏病(输出是否受心脏病影响)等。</p><p id="3449" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">相比之下，回归算法侧重于数值预测结果，其中结果不限于某些类别，例如，房价、汽车距离、能源使用等。</p><h2 id="d887" class="lv lw it bd lx ly lz dn ma mb mc dp md li me mf mg lm mh mi mj lq mk ml mm mn bi translated"><strong class="ak">无监督学习</strong></h2><p id="5c11" class="pw-post-body-paragraph kz la it lb b lc mo ju le lf mp jx lh li mq lk ll lm mr lo lp lq ms ls lt lu im bi translated">我们可以把无监督学习想象成从数据中寻找某些统一的变量。顾名思义，无监督学习机器学习系统在学习数据时没有人的监督或指导。相反，人们希望机器能够根据现有数据提出解决方案。</p><p id="fb53" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">无监督学习意味着探索数据并基于算法的学习产生输出。该算法从没有标签(未标记)的训练数据中获取，并产生学习输出。让我们以K-Means算法的无监督学习输出为例。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi mu"><img src="../Images/ec9e627cb7cb0e2ca51d0e45f7a1226c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1150/0*okMZHZCsuXE8T4Yd"/></div><figcaption class="ku kv gj gh gi kw kx bd b be z dk translated">图二。作者使用K-Means的无监督学习结果</figcaption></figure><p id="9119" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">上面的结果是一个<strong class="lb iu">聚类</strong>算法，用于将数据分成一定数量的组。无监督学习的另一个应用是<strong class="lb iu">降维</strong>，它简化了数据，而不会从原始数据中丢失太多信息。</p><h2 id="37fc" class="lv lw it bd lx ly lz dn ma mb mc dp md li me mf mg lm mh mi mj lq mk ml mm mn bi translated"><strong class="ak">强化学习</strong></h2><p id="90e5" class="pw-post-body-paragraph kz la it lb b lc mo ju le lf mp jx lh li mq lk ll lm mr lo lp lq ms ls lt lu im bi translated">强化学习是一种机器学习系统，它通过特定的动作来最大化奖励，从而执行任务。强化学习使用一个代理来观察环境并选择一个状态来行动。这一行动将根据选择产生奖励或惩罚。强化学习将推动算法找到最佳策略，以实现回报最大化。然后，该策略将成为给定环境中的代理。</p><p id="fe1b" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">我们经常在底层数据不多或者通过与环境交互获取数据的时候使用强化学习。强化学习的一个例子是自动驾驶汽车和人工智能象棋。</p></div><div class="ab cl mv mw hx mx" role="separator"><span class="my bw bk mz na nb"/><span class="my bw bk mz na nb"/><span class="my bw bk mz na"/></div><div class="im in io ip iq"><h1 id="166b" class="nc lw it bd lx nd ne nf ma ng nh ni md jz nj ka mg kc nk kd mj kf nl kg mm nm bi translated"><strong class="ak">机器学习中的分类算法</strong></h1><p id="5a7d" class="pw-post-body-paragraph kz la it lb b lc mo ju le lf mp jx lh li mq lk ll lm mr lo lp lq ms ls lt lu im bi translated">我们已经理解了每个机器学习系统的基础，以及不同的问题需要不同的算法。一般来说，行业中的大多数问题都是分类问题，因此进一步了解分类算法将对我们有益。</p><p id="a4cb" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">让我们了解一下七种最常用的分类算法，以及每种算法何时可以使用。</p></div><div class="ab cl mv mw hx mx" role="separator"><span class="my bw bk mz na nb"/><span class="my bw bk mz na nb"/><span class="my bw bk mz na"/></div><div class="im in io ip iq"><h1 id="ddc5" class="nc lw it bd lx nd ne nf ma ng nh ni md jz nj ka mg kc nk kd mj kf nl kg mm nm bi translated">1.逻辑回归</h1><p id="1efb" class="pw-post-body-paragraph kz la it lb b lc mo ju le lf mp jx lh li mq lk ll lm mr lo lp lq ms ls lt lu im bi translated">逻辑回归或Logit回归是一种将数据分为两类的分类算法。术语回归不应被误认为来自监督学习任务的回归，如逻辑回归中的回归，参考<a class="ae ky" href="https://online.stat.psu.edu/stat504/lesson/beyond-logistic-regression-generalized-linear-models-glm" rel="noopener ugc nofollow" target="_blank">广义线性模型</a> (GLM)中的逻辑函数。</p><p id="c428" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">该模型是分类算法中最简单的模型之一，用于许多真实案例，如疾病预测、流失预测、重复预测和许多分类用例。</p><p id="7ada" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">关于方程，GLM是一个广泛的类模型，可以包括许多模型，例如，线性回归，方差分析和逻辑回归。</p><p id="59c2" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">逻辑回归遵循GLM的三个基本组成部分，即:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi nn"><img src="../Images/476353e97aeb0205285550f97c9088b1.png" data-original-src="https://miro.medium.com/v2/resize:fit:878/0*G-66LYeF3QmnjEpT"/></div><figcaption class="ku kv gj gh gi kw kx bd b be z dk translated">图3。作者的GLM基本结构</figcaption></figure><p id="e823" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><strong class="lb iu">随机分量(E(Y)) </strong>:它是Logistic回归模型(响应变量)的概率分布，在这种情况下，是<a class="ae ky" href="https://en.wikipedia.org/wiki/Binomial_distribution" rel="noopener ugc nofollow" target="_blank">二项分布</a>或者准确地说，是成功事件的概率(E(Y) = 1)。</p><p id="aea5" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><strong class="lb iu">系统成分</strong> : <strong class="lb iu"> </strong>它是线性预测因子(+ 1 x1 +2X2 + … + nXn)中的解释变量(X1，x2，…，xn)</p><p id="6ecb" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><strong class="lb iu">连接函数(g()) </strong>:将因变量的期望值(E(Y)))与线性预测值联系起来的函数。使用Logit函数的线性回归，即log(P/1-P)，其中P是成功的概率(E(Y) = 1)。使用Logit函数，结果应该在0到1之间。</p><p id="b8ff" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">上述所有结构将创建一个称为逻辑回归的模型。</p></div><div class="ab cl mv mw hx mx" role="separator"><span class="my bw bk mz na nb"/><span class="my bw bk mz na nb"/><span class="my bw bk mz na"/></div><div class="im in io ip iq"><h1 id="8e62" class="nc lw it bd lx nd ne nf ma ng nh ni md jz nj ka mg kc nk kd mj kf nl kg mm nm bi translated">2.决策图表</h1><p id="da7d" class="pw-post-body-paragraph kz la it lb b lc mo ju le lf mp jx lh li mq lk ll lm mr lo lp lq ms ls lt lu im bi translated">决策树是一种分类模型，其中学习是一种逼近由决策树表示的离散值目标函数的方法。单词树指的是<a class="ae ky" href="https://en.wikipedia.org/wiki/Graph_theory" rel="noopener ugc nofollow" target="_blank">数学图论</a>，定义为两个节点恰好由一条路径连接的无向图。</p><p id="0008" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">简单来说，决策树是一种基于倒置的树结构对数据进行分类的分类模型。决策树将创建一个节点，该节点基于数据学习保持分裂，并且将停止，直到我们已经决定的参数或者不再发生分裂。下图显示了决策树的一个示例。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi no"><img src="../Images/d084a24c78f25df2a6caea7f213155d3.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*2LjUD5SQQsCPMHkq"/></div><figcaption class="ku kv gj gh gi kw kx bd b be z dk translated">图4。作者的决策树示例</figcaption></figure><p id="2379" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">决策树如何决定拆分哪些特征和值？决策的算法很少，但常见的有<a class="ae ky" href="https://towardsdatascience.com/gini-index-vs-information-entropy-7a7e4fed3fcb" rel="noopener" target="_blank">基尼指数、熵和信息增益度量</a>。使用这两种拆分算法的基本思想是基于我们要拆分的值和结果来衡量拆分的好坏。让我们看看下面的图像，以了解算法如何决定哪个分裂点是最好的。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi np"><img src="../Images/6e2b05d1ce5332fe26f961c8fa80b2bd.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*4M14sRuOqPN6Eek2"/></div></div><figcaption class="ku kv gj gh gi kw kx bd b be z dk translated">图5。按作者拆分点决策树</figcaption></figure><p id="05a1" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">上图显示了X1在两个值中的位置，并且信息增益值不同。最佳分裂是当IG较高时，因此X1 = 2是最佳分裂点。我们继续分裂，直到节点只有一个类或我们设置的超参数。</p><p id="ce92" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">决策树是许多数据专家使用的流行模型之一，因为它快速且易于解释。然而，该模型深受<a class="ae ky" href="https://www.ibm.com/cloud/learn/overfitting" rel="noopener ugc nofollow" target="_blank">过拟合</a>问题的困扰。这就是为什么许多模型是以决策树为基础开发的——例如，随机森林。</p></div><div class="ab cl mv mw hx mx" role="separator"><span class="my bw bk mz na nb"/><span class="my bw bk mz na nb"/><span class="my bw bk mz na"/></div><div class="im in io ip iq"><h1 id="f0a2" class="nc lw it bd lx nd ne nf ma ng nh ni md jz nj ka mg kc nk kd mj kf nl kg mm nm bi translated">3.随机森林</h1><p id="c889" class="pw-post-body-paragraph kz la it lb b lc mo ju le lf mp jx lh li mq lk ll lm mr lo lp lq ms ls lt lu im bi translated">随机森林是一种基于决策树的分类算法。随机名称来自算法中引入的随机化，而森林名称来自构建模型的多个决策树。</p><p id="8a6f" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">在我们讨论随机森林之前，我们需要理解<a class="ae ky" href="https://en.wikipedia.org/wiki/Ensemble_learning" rel="noopener ugc nofollow" target="_blank">集合</a>学习概念，因为随机森林模型被归为一类。集成学习是一个概念，其中我们利用多种算法来实现更好的预测结果和性能。例如，我们使用多重决策树算法在随机森林中构建随机森林模型。</p><p id="42dc" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">准确地说，一个随机森林被归类为一个<strong class="lb iu">自举聚集(bagging) </strong>系综。什么是装袋，模型是如何工作的？首先，我们需要理解统计学中的<a class="ae ky" href="https://en.wikipedia.org/wiki/Bootstrapping_(statistics)" rel="noopener ugc nofollow" target="_blank">引导</a>的概念。Bootstraps是一种随机抽样替换的方法；换句话说，我们从同一个数据集创建一个新的数据集，但是允许重复值。让我们看看下图来了解bootstrap。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi nq"><img src="../Images/03edb5cc9be28e4b495d90b285d55065.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*gKxbms9xx2025M6u"/></div></div><figcaption class="ku kv gj gh gi kw kx bd b be z dk translated">图6。作者的引导示例</figcaption></figure><p id="7d0a" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">上图显示了自举是如何工作的。我们将原始数据视为一个池，从那里对数据进行重新采样，每个引导数据集都可以包含相似的值。以上示例显示了两个引导数据，每个数据集有三个样本。</p><p id="999a" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">我们将使用在随机森林模型的引导数据中明确训练的多个决策树。对于我们使用的每一个决策树，我们训练不同的引导数据。因此，如果我们在随机森林中有100棵决策树，我们将在100个不同的引导数据中训练100棵决策树。</p><p id="b87d" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">我们使用bootstrap方法将随机性引入模型并避免过度拟合，因为bootstrap数据将具有与原始数据相似的分布估计，但却不同。这一过程将确保泛化的发生。</p><p id="833a" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">此外，为了避免进一步过度拟合，随机森林算法可以减少创建引导数据时要考虑的要素数量。通常，它是原始数据中所有特征的平方根；因此，如果我们的原始数据有四个特征，我们将在我们的引导数据中使用两个特征。特征选择也是随机进行的，以避免进一步过度拟合。</p><p id="0e0b" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">最后，每个决策树都会有一个概率输出。随机森林的输出将是每个决策树的平均值。下图总结了随机森林算法。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi nr"><img src="../Images/dcb76f7cabc969e825a3bac7279229fe.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*p1MG7qR2ZTxJz5eM"/></div></div><figcaption class="ku kv gj gh gi kw kx bd b be z dk translated">图6。作者的随机森林算法概述</figcaption></figure></div><div class="ab cl mv mw hx mx" role="separator"><span class="my bw bk mz na nb"/><span class="my bw bk mz na nb"/><span class="my bw bk mz na"/></div><div class="im in io ip iq"><h1 id="4c12" class="nc lw it bd lx nd ne nf ma ng nh ni md jz nj ka mg kc nk kd mj kf nl kg mm nm bi translated">4.朴素贝叶斯</h1><p id="3bca" class="pw-post-body-paragraph kz la it lb b lc mo ju le lf mp jx lh li mq lk ll lm mr lo lp lq ms ls lt lu im bi translated">朴素贝叶斯是一种基于<a class="ae ky" href="https://en.wikipedia.org/wiki/Bayes%27_theorem" rel="noopener ugc nofollow" target="_blank">贝叶斯定理</a>的分类算法。与事件概率基于当前数据的<a class="ae ky" href="https://en.wikipedia.org/wiki/Frequentist_probability" rel="noopener ugc nofollow" target="_blank">频率定理</a>不同，贝叶斯定理会基于先前的概率更新概率。</p><p id="f425" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">例如，当天气晴朗时，我们假设下雨的概率是50%,但是随着每一天的发生，我们用每一条可用的信息更新概率。贝叶斯定理概率可以如下图所示。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi ns"><img src="../Images/906eac1ca574bc30702574e8f2879644.png" data-original-src="https://miro.medium.com/v2/resize:fit:550/0*xfmdtSD5YAwT7Lij"/></div><figcaption class="ku kv gj gh gi kw kx bd b be z dk translated">图7。作者的贝叶斯定理方程</figcaption></figure><p id="f436" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">上图展示了贝叶斯定理，其中:</p><ul class=""><li id="1736" class="nt nu it lb b lc ld lf lg li nv lm nw lq nx lu ny nz oa ob bi translated">P(A|B)是后验概率(假设B为真，事件A发生的概率)</li><li id="6050" class="nt nu it lb b lc oc lf od li oe lm of lq og lu ny nz oa ob bi translated">P(B|A)是给定A为真，事件B发生的概率。我们也可以说，给定固定的b，A发生的<a class="ae ky" href="https://en.wikipedia.org/wiki/Likelihood_function" rel="noopener ugc nofollow" target="_blank">可能性</a></li><li id="dac1" class="nt nu it lb b lc oc lf od li oe lm of lq og lu ny nz oa ob bi translated">P(A)和P(B)是先验概率；在没有任何条件或没有证据的情况下，事件A或B发生的可能性有多大。</li></ul><p id="ef0a" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">关于数据集，我们可以如下图所示陈述朴素贝叶斯初始方程。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi nn"><img src="../Images/6348eeb0263f3b9432198fedd6a5aae2.png" data-original-src="https://miro.medium.com/v2/resize:fit:878/0*PI5M2MQMjKQUlFK3"/></div><figcaption class="ku kv gj gh gi kw kx bd b be z dk translated">图8。朴素贝叶斯算法初始方程作者</figcaption></figure><p id="252d" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">让我们以上面的数据集为例，假设X =(宽度= 15，重量= 100，颜色=红色)和y =苹果。因此，我们可以说，假设苹果的宽度为15，重量为100，颜色为红色，朴素贝叶斯分类器P(y|X)是苹果的概率。为了计算概率，通常，朴素贝叶斯算法需要连续数据来离散化或使用概率密度估计。但是对于当前的例子，让我们假设它们是绝对的。</p><p id="9275" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">如果我们将数据中的所有信息放入朴素贝叶斯算法中，结果将如下图所示。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi oh"><img src="../Images/90f595a9316ba996fbcc6984c97e81e1.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*XTInyAINeUZ3lzcg"/></div></div></figure><p id="beb9" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">图9。作者的朴素贝叶斯苹果计算</p><p id="aaa8" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">我们用现有的数据输入信息。对于P(苹果)或之前是苹果标签的出现与所有可用数据的比较，是3 / 5。例如，P(Width = 15 | Apple)的可能性只出现在带有Apple标签的所有3个数据中的1个数据中。</p><p id="6593" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">我们也可以用下面的等式和结果来计算相反的概率(不是苹果，给定数据)。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi oi"><img src="../Images/d885dd0bf6f0b0f2b318ae8a611eceb1.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*Z9QjRzpxoABZ_7M5"/></div></div></figure><p id="3527" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">图10。作者的朴素贝叶斯非苹果计算</p><p id="f204" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">如果我们使用上面的结果，苹果的概率高于非苹果，这意味着数据将有一个苹果输出。通常，这两种情况下的概率都是归一化的，所以我们可以用下面的等式将总概率设为1。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi oj"><img src="../Images/a9011338538c85581323511e7e192235.png" data-original-src="https://miro.medium.com/v2/resize:fit:720/0*h_Q-HDrLMcQrGTOP"/></div><figcaption class="ku kv gj gh gi kw kx bd b be z dk translated">图11。作者的朴素贝叶斯规范化计算</figcaption></figure><p id="f654" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">朴素贝叶斯因其算法简单易行而被广泛使用。训练时间相对于其他的也足够快。该模型在NLP用例中很流行，因为它在许多NLP用例中工作得很好，比如情感分析、垃圾邮件过滤等等。</p></div><div class="ab cl mv mw hx mx" role="separator"><span class="my bw bk mz na nb"/><span class="my bw bk mz na nb"/><span class="my bw bk mz na"/></div><div class="im in io ip iq"><h1 id="a791" class="nc lw it bd lx nd ne nf ma ng nh ni md jz nj ka mg kc nk kd mj kf nl kg mm nm bi translated">5.支持向量机(SVM)</h1><p id="bad1" class="pw-post-body-paragraph kz la it lb b lc mo ju le lf mp jx lh li mq lk ll lm mr lo lp lq ms ls lt lu im bi translated">SVM是一种非常流行的分类算法，因为它必须在特定用例中胜过一些复杂的算法，如数字识别。更简单地说，SVM是一个分类器，用来划分不同的类别。这些数据被称为支持向量，以帮助确定边界。</p><p id="096b" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">这个边界叫做超平面或分割线。它是基于数据集并通过移动超平面来测量最佳余量来计算的。当数据在更高维度或者存在非线性可分数据时，我们将使用<a class="ae ky" href="https://towardsdatascience.com/understanding-support-vector-machine-part-2-kernel-trick-mercers-theorem-e1e6848c6c4d" rel="noopener" target="_blank">核技巧</a>来寻找超平面。</p><p id="171e" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">测量超平面的计算比较棘手，我建议在这里阅读下面的材料<a class="ae ky" href="https://towardsdatascience.com/support-vector-machines-for-classification-fc7c1565e3" rel="noopener" target="_blank">。下面是SVM的图像表示。</a></p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ok"><img src="../Images/bf22330213a96e65494635969d2bae33.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*RHI2GjuWIqaUcHbf"/></div></div><figcaption class="ku kv gj gh gi kw kx bd b be z dk translated">图12。作者从超平面中分离出的SVM像</figcaption></figure></div><div class="ab cl mv mw hx mx" role="separator"><span class="my bw bk mz na nb"/><span class="my bw bk mz na nb"/><span class="my bw bk mz na"/></div><div class="im in io ip iq"><h1 id="010f" class="nc lw it bd lx nd ne nf ma ng nh ni md jz nj ka mg kc nk kd mj kf nl kg mm nm bi translated">6.K-最近邻</h1><p id="af95" class="pw-post-body-paragraph kz la it lb b lc mo ju le lf mp jx lh li mq lk ll lm mr lo lp lq ms ls lt lu im bi translated">K-最近邻或K-NN是一种简单的基于数据距离和<a class="ae ky" href="https://en.wikipedia.org/wiki/Nearest_neighbor_search" rel="noopener ugc nofollow" target="_blank">最近邻</a>优化问题的非参数分类算法。与以前的许多模型不同，K-NN不学习任何参数，如系数，而只使用实际数据作为模型。</p><p id="b786" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">K-NN算法旨在衡量新数据与模型先前学习的训练数据的接近程度。该模型不是学习任何参数，而是分配<em class="ol"> K </em>个最接近的观察值来对新数据进行分类。</p><p id="cb24" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">理解K-NN如何工作的最简单的方法是将模型想象成一个地图，每个新点都被分配到新类，作为使用距离度量(通常是<a class="ae ky" href="https://en.wikipedia.org/wiki/Euclidean_distance" rel="noopener ugc nofollow" target="_blank">欧几里德距离</a>)的<em class="ol"> K的</em>最近数量的观察值的大多数。我们来看看下图。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi om"><img src="../Images/296a44668cee0d9731785e7b9e0208bf.png" data-original-src="https://miro.medium.com/v2/resize:fit:694/0*L4P6fPCUAxkE_v9E"/></div><figcaption class="ku kv gj gh gi kw kx bd b be z dk translated">图13。作者的K-NN模型示例</figcaption></figure><p id="5ac2" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">上图显示了两个不同类别(蓝色和橙色)的实际数据。星星是K-NN试图预测的新数据。如果我们将K设为3，新数据将寻找三个最接近的数据。使用上面的示例，新数据将被分类为蓝色，因为大多数最接近的数据都是蓝色的。但是，如果我们将K增加到5，K-NN会将新数据分类为橙色，因为大多数数据都发生了移动。</p><p id="0845" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">请注意，不要对K使用偶数，因为在出现平局的情况下，分类将是随机预测。找到一个最优的K数也是一个实验，所以尽量用相关的度量来评估机器学习模型。</p></div><div class="ab cl mv mw hx mx" role="separator"><span class="my bw bk mz na nb"/><span class="my bw bk mz na nb"/><span class="my bw bk mz na"/></div><div class="im in io ip iq"><h1 id="3ec7" class="nc lw it bd lx nd ne nf ma ng nh ni md jz nj ka mg kc nk kd mj kf nl kg mm nm bi translated">7.神经网络</h1><p id="8bdb" class="pw-post-body-paragraph kz la it lb b lc mo ju le lf mp jx lh li mq lk ll lm mr lo lp lq ms ls lt lu im bi translated">神经网络是基于人类神经大脑的机器学习模型，该模型是以<a class="ae ky" href="https://www.ibm.com/cloud/learn/deep-learning" rel="noopener ugc nofollow" target="_blank">深度学习方法</a>为核心的机器学习的子集。更详细地说，神经网络通常包含三个节点组件:</p><ul class=""><li id="0cc3" class="nt nu it lb b lc ld lf lg li nv lm nw lq nx lu ny nz oa ob bi translated">输入层(数据进入的地方)</li><li id="bfcb" class="nt nu it lb b lc oc lf od li oe lm of lq og lu ny nz oa ob bi translated">隐蔽层</li><li id="ff45" class="nt nu it lb b lc oc lf od li oe lm of lq og lu ny nz oa ob bi translated">输出层(数据的输出)</li></ul><p id="9a95" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">让我们看看下面的图片，以获得更多的细节。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi on"><img src="../Images/c38d7a0ce421b525e0ed73568c098340.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*hk9mY0ropbeSN1sq"/></div></div><figcaption class="ku kv gj gh gi kw kx bd b be z dk translated">图14。作者的神经网络模型</figcaption></figure><p id="ee5c" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">一般来说，你可以有无限的隐藏层来改进算法。然而，更高的节点意味着更高的计算能力和训练时间。所以，把层数增加太高并不明智。</p><p id="a778" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">神经网络通过计算该层的数据来计算预测。在隐藏层节点中处理数据，其中每个节点由两个函数组成，一个线性函数和一个激活函数。将线性函数视为线性模型，并且<a class="ae ky" href="https://www.educative.io/answers/what-are-activation-functions-in-neural-networks" rel="noopener ugc nofollow" target="_blank">激活函数</a>是将非线性引入模型的函数。为了微调计算，使用了<a class="ae ky" href="https://www.guru99.com/backpropogation-neural-network.html" rel="noopener ugc nofollow" target="_blank">反向传播</a>方法。</p><p id="6015" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">简而言之，输入层中的每个数据都将经过隐藏层，函数将创建一个值输出。</p><p id="28f6" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">神经网络通常用于非结构化数据预测，如图像、文本或音频数据，因为神经网络可以摄取这些数据。这也允许许多用例，例如图像识别、文本识别等。</p></div><div class="ab cl mv mw hx mx" role="separator"><span class="my bw bk mz na nb"/><span class="my bw bk mz na nb"/><span class="my bw bk mz na"/></div><div class="im in io ip iq"><h1 id="750b" class="nc lw it bd lx nd ne nf ma ng nh ni md jz nj ka mg kc nk kd mj kf nl kg mm nm bi translated"><strong class="ak">结论</strong></h1><p id="d9e2" class="pw-post-body-paragraph kz la it lb b lc mo ju le lf mp jx lh li mq lk ll lm mr lo lp lq ms ls lt lu im bi translated">机器学习模型是一种算法，旨在研究数据并创建解决人类问题的输出。机器学习中的分类与谨慎的预测结果输出有关。</p><p id="6c7c" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">我们已经讨论了七种不同的分类算法，它们是:</p><ol class=""><li id="e158" class="nt nu it lb b lc ld lf lg li nv lm nw lq nx lu oo nz oa ob bi translated">逻辑回归</li><li id="55b7" class="nt nu it lb b lc oc lf od li oe lm of lq og lu oo nz oa ob bi translated">决策图表</li><li id="119b" class="nt nu it lb b lc oc lf od li oe lm of lq og lu oo nz oa ob bi translated">随机森林</li><li id="a439" class="nt nu it lb b lc oc lf od li oe lm of lq og lu oo nz oa ob bi translated">朴素贝叶斯</li><li id="e415" class="nt nu it lb b lc oc lf od li oe lm of lq og lu oo nz oa ob bi translated">支持向量机(SVM)</li><li id="2485" class="nt nu it lb b lc oc lf od li oe lm of lq og lu oo nz oa ob bi translated">K-最近邻</li><li id="0345" class="nt nu it lb b lc oc lf od li oe lm of lq og lu oo nz oa ob bi translated">神经网络。</li></ol></div><div class="ab cl mv mw hx mx" role="separator"><span class="my bw bk mz na nb"/><span class="my bw bk mz na nb"/><span class="my bw bk mz na"/></div><div class="im in io ip iq"><blockquote class="op"><p id="b021" class="oq or it bd os ot ou ov ow ox oy lu dk translated">如果您没有订阅为中等会员，请考虑通过<a class="ae ky" href="https://cornelliusyudhawijaya.medium.com/membership" rel="noopener">我的推荐</a>订阅。</p></blockquote></div></div>    
</body>
</html>