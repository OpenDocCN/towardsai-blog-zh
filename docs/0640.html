<html>
<head>
<title>Supporting the Math Behind Supporting Vector Machines!</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">支持向量机背后的数学支持！</h1>
<blockquote>原文：<a href="https://pub.towardsai.net/supporting-the-math-behind-supporting-vector-machines-d46e94b23b9d?source=collection_archive---------3-----------------------#2020-06-30">https://pub.towardsai.net/supporting-the-math-behind-supporting-vector-machines-d46e94b23b9d?source=collection_archive---------3-----------------------#2020-06-30</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><h2 id="22ca" class="ir is it bd b dl iu iv iw ix iy iz dk ja translated" aria-label="kicker paragraph"><a class="ae ep" href="https://towardsai.net/p/category/machine-learning" rel="noopener ugc nofollow" target="_blank">机器学习</a>，<a class="ae ep" href="https://towardsai.net/p/category/mathematics" rel="noopener ugc nofollow" target="_blank">数学</a></h2><div class=""/><div class=""><h2 id="3db9" class="pw-subtitle-paragraph jz jc it bd b ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq dk translated">快速游览SVM构成数学和理论解释以及从零开始实施。</h2></div><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi kr"><img src="../Images/5385face8bd79f4de3563faffd23872e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*HNCWSfzjjMIjIW2VXK_RFg.png"/></div></div></figure><p id="c371" class="pw-post-body-paragraph ld le it lf b lg lh kd li lj lk kg ll lm ln lo lp lq lr ls lt lu lv lw lx ly im bi translated"><strong class="lf jd">支持向量机</strong>是另一种简单的算法，每个机器学习专家都应该拥有它。支持向量机是许多人的首选，因为它产生的数据非常准确，需要较少的计算能力。SVM可用于回归和分类任务。</p><h1 id="422e" class="lz ma it bd mb mc md me mf mg mh mi mj ki mk kj ml kl mm km mn ko mo kp mp mq bi translated">目录</h1><ul class=""><li id="762b" class="mr ms it lf b lg mt lj mu lm mv lq mw lu mx ly my mz na nb bi translated"><em class="nc">支持向量机简介</em></li><li id="60ee" class="mr ms it lf b lg nd lj ne lm nf lq ng lu nh ly my mz na nb bi translated"><em class="nc">SVM是如何工作的？</em></li><li id="97aa" class="mr ms it lf b lg nd lj ne lm nf lq ng lu nh ly my mz na nb bi translated"><em class="nc">处理异常值</em></li><li id="a190" class="mr ms it lf b lg nd lj ne lm nf lq ng lu nh ly my mz na nb bi translated"><em class="nc">佩加索斯</em></li><li id="4a7c" class="mr ms it lf b lg nd lj ne lm nf lq ng lu nh ly my mz na nb bi translated"><em class="nc">非线性分类</em></li><li id="e66e" class="mr ms it lf b lg nd lj ne lm nf lq ng lu nh ly my mz na nb bi translated"><em class="nc">赞成&amp;反对SVM </em></li><li id="dd09" class="mr ms it lf b lg nd lj ne lm nf lq ng lu nh ly my mz na nb bi translated">可视化SVM </li><li id="946f" class="mr ms it lf b lg nd lj ne lm nf lq ng lu nh ly my mz na nb bi translated"><em class="nc">SVM的申请</em></li></ul></div><div class="ab cl ni nj hx nk" role="separator"><span class="nl bw bk nm nn no"/><span class="nl bw bk nm nn no"/><span class="nl bw bk nm nn"/></div><div class="im in io ip iq"><h2 id="f119" class="np ma it bd mb nq nr dn mf ns nt dp mj lm nu nv ml lq nw nx mn lu ny nz mp iz bi translated"><em class="oa">支持</em>向量机简介</h2><p id="da35" class="pw-post-body-paragraph ld le it lf b lg mt kd li lj mu kg ll lm ob lo lp lq oc ls lt lu od lw lx ly im bi translated">支持向量机(SVM)是一个强大的分类器，可以处理线性和非线性数据。</p><blockquote class="oe of og"><p id="d3e3" class="ld le nc lf b lg lh kd li lj lk kg ll oh ln lo lp oi lr ls lt oj lv lw lx ly im bi translated">如果你有一个<strong class="lf jd"> n </strong>维空间，那么超平面的维数将是<strong class="lf jd"> (n-1)。</strong></p></blockquote><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi ok"><img src="../Images/eacfd1008aca39c3a57d0b21a48cfbae.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*h3ltx6mIe5V7Jjot.png"/></div></div></figure><p id="b2f6" class="pw-post-body-paragraph ld le it lf b lg lh kd li lj lk kg ll lm ln lo lp lq lr ls lt lu lv lw lx ly im bi translated">SVM 的<strong class="lf jd">目标是找到一个<strong class="lf jd">最佳超平面</strong>，它能最好地分离我们的数据，从而使空间中最近的点到自身的距离最大化。</strong></p><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div class="gh gi ol"><img src="../Images/01e6d138d318c7aa5b64ff6502aed5ea.png" data-original-src="https://miro.medium.com/v2/resize:fit:600/format:webp/0*LZo6pILXjlIADCZa.png"/></div></figure><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi om"><img src="../Images/9dbcbeab5201bc0634c58401dd1bfe52.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*JDdU1N0REqWrHexo"/></div></div></figure><p id="d83c" class="pw-post-body-paragraph ld le it lf b lg lh kd li lj lk kg ll lm ln lo lp lq lr ls lt lu lv lw lx ly im bi translated">为了简单起见，考虑一条道路，它将左侧、右侧的汽车、建筑物、行人分开，并尽可能形成最宽的车道。那些离街道很近的汽车和建筑是支持向量。</p><p id="1548" class="pw-post-body-paragraph ld le it lf b lg lh kd li lj lk kg ll lm ln lo lp lq lr ls lt lu lv lw lx ly im bi translated">这就是支持向量机的工作原理。</p><h2 id="3adf" class="np ma it bd mb nq nr dn mf ns nt dp mj lm nu nv ml lq nw nx mn lu ny nz mp iz bi translated">SVM是如何运作的？</h2><blockquote class="oe of og"><p id="933f" class="ld le nc lf b lg lh kd li lj lk kg ll oh ln lo lp oi lr ls lt oj lv lw lx ly im bi translated"><strong class="lf jd">目标</strong>:寻找一个最优超平面。</p></blockquote><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi on"><img src="../Images/d41f3de17b20a93ead1740a99e03cc3b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*S9ZLppXS4aNx_fyPPecNLg.png"/></div></div></figure><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi oo"><img src="../Images/ac526e18bb8f37af43250bf37ea7fcd9.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*CxGYFTBI-ieTJ0PSi2qj1g.png"/></div></div></figure><p id="aca5" class="pw-post-body-paragraph ld le it lf b lg lh kd li lj lk kg ll lm ln lo lp lq lr ls lt lu lv lw lx ly im bi translated"><strong class="lf jd">计算点到支持向量的距离</strong></p><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div class="gh gi op"><img src="../Images/6cd5f80f5ee2d87b1ac3523537d97c34.png" data-original-src="https://miro.medium.com/v2/resize:fit:1168/format:webp/1*ZpCyyV18PWwGgcDAvKngQA.png"/></div></figure><p id="9721" class="pw-post-body-paragraph ld le it lf b lg lh kd li lj lk kg ll lm ln lo lp lq lr ls lt lu lv lw lx ly im bi translated">我们想要一个能够以非常有效的方式对点进行分类的超平面，即以精确的方式分配类别。</p><p id="e300" class="pw-post-body-paragraph ld le it lf b lg lh kd li lj lk kg ll lm ln lo lp lq lr ls lt lu lv lw lx ly im bi translated">为了准确地执行，我们需要改变我们的目标。</p><blockquote class="oe of og"><p id="356d" class="ld le nc lf b lg lh kd li lj lk kg ll oh ln lo lp oi lr ls lt oj lv lw lx ly im bi translated"><strong class="lf jd">修改目标:</strong>最大化离超平面的最小距离。</p></blockquote><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi oq"><img src="../Images/5614bca6e4664c06d7eaf6bc304166b6.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*0ZH_xYVkQCh0rDstAMVkzg.png"/></div></div></figure><p id="5c44" class="pw-post-body-paragraph ld le it lf b lg lh kd li lj lk kg ll lm ln lo lp lq lr ls lt lu lv lw lx ly im bi translated">让我们假设一个<strong class="lf jd">最小阈值距离= γ </strong></p><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div class="gh gi or"><img src="../Images/fc06d28ea79f16e35cc7be0264a3e7f2.png" data-original-src="https://miro.medium.com/v2/resize:fit:978/format:webp/1*rr6J0soUIJvLdE_kHwe7oQ.png"/></div></figure><p id="9afe" class="pw-post-body-paragraph ld le it lf b lg lh kd li lj lk kg ll lm ln lo lp lq lr ls lt lu lv lw lx ly im bi translated">现在所有点必须满足以下两个条件:</p><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi os"><img src="../Images/48f994c04d46689336066bfd91d2a41d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*fotebcemDjvEvfjt_7oh_A.png"/></div></div></figure><p id="1de0" class="pw-post-body-paragraph ld le it lf b lg lh kd li lj lk kg ll lm ln lo lp lq lr ls lt lu lv lw lx ly im bi translated">为了实现最小距离，我们需要<strong class="lf jd">最大化“w”。</strong></p><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi ot"><img src="../Images/f28832ac7a0214c5d044783bd234bb26.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*c388Qhr7pdIQd_oW_hjs6w.png"/></div></div></figure><p id="1883" class="pw-post-body-paragraph ld le it lf b lg lh kd li lj lk kg ll lm ln lo lp lq lr ls lt lu lv lw lx ly im bi translated">这个执行有点乏味和麻烦，因此为了降低数学复杂性，我们将重新制定我们的方程。</p><p id="4a62" class="pw-post-body-paragraph ld le it lf b lg lh kd li lj lk kg ll lm ln lo lp lq lr ls lt lu lv lw lx ly im bi translated">因此，我们将以支持向量必须位于超平面上的方式重新归一化我们的数据。</p><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi ou"><img src="../Images/9f0fcadfc810c9e1e46a58d6da1176a9.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*vCjs1pRGDoNGPv62-skmGQ.png"/></div></div></figure><p id="1f75" class="pw-post-body-paragraph ld le it lf b lg lh kd li lj lk kg ll lm ln lo lp lq lr ls lt lu lv lw lx ly im bi translated">所以，为了<strong class="lf jd">最大化“w”，我们需要最大化“D”。</strong></p><blockquote class="ov"><p id="7d8d" class="ow ox it bd oy oz pa pb pc pd pe ly dk translated">d = D1+D2；所以我们也需要最大化D1和D2。</p></blockquote><figure class="pg ph pi pj pk kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi pf"><img src="../Images/a4f3d7f524fcff4b27160cdc169aaac5.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*yntwI1KJbINxRdaBj8F1sA.png"/></div></div></figure><p id="9715" class="pw-post-body-paragraph ld le it lf b lg lh kd li lj lk kg ll lm ln lo lp lq lr ls lt lu lv lw lx ly im bi translated">现在，为了使<strong class="lf jd">增加“D”，我们必须在<strong class="lf jd">最小距离必须为1 </strong>的条件下，重点减少“| | w | |”</strong>。</p><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi pl"><img src="../Images/f7db2378875759c5103087e8ee0a7f7c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*0-hxLOYx2xJqsEIRer7VOg.png"/></div></div></figure><p id="3016" class="pw-post-body-paragraph ld le it lf b lg lh kd li lj lk kg ll lm ln lo lp lq lr ls lt lu lv lw lx ly im bi translated">在我们的新目标中，我们需要减少||w||但是我们需要记住||w||不是自由的，即<strong class="lf jd">它依赖于γ。</strong></p><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi on"><img src="../Images/3dd2718c268f3165bb8ca579cc984473.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*rMBIeDRaewN-Q7IBbbnEtA.png"/></div></div></figure><p id="3fa4" class="pw-post-body-paragraph ld le it lf b lg lh kd li lj lk kg ll lm ln lo lp lq lr ls lt lu lv lw lx ly im bi translated">由于SVM <strong class="lf jd">不能使用梯度下降</strong>，由于约束依赖性，我们需要寻找其他解决方案。</p><p id="829b" class="pw-post-body-paragraph ld le it lf b lg lh kd li lj lk kg ll lm ln lo lp lq lr ls lt lu lv lw lx ly im bi translated">使用以下任何一种方法都可以避免该问题:</p><ul class=""><li id="575a" class="mr ms it lf b lg lh lj lk lm pm lq pn lu po ly my mz na nb bi translated"><em class="nc">二次规划求解器</em></li><li id="6c7a" class="mr ms it lf b lg nd lj ne lm nf lq ng lu nh ly my mz na nb bi translated"><em class="nc">朗格朗密度</em></li><li id="68c9" class="mr ms it lf b lg nd lj ne lm nf lq ng lu nh ly my mz na nb bi translated"><em class="nc">佩加索斯</em></li></ul><h2 id="d4d7" class="np ma it bd mb nq nr dn mf ns nt dp mj lm nu nv ml lq nw nx mn lu ny nz mp iz bi translated">处理异常值</h2><p id="c4fb" class="pw-post-body-paragraph ld le it lf b lg mt kd li lj mu kg ll lm ob lo lp lq oc ls lt lu od lw lx ly im bi translated">有时候对于一些例子<strong class="lf jd"> (x(i)，y(i)) </strong>我们可能会遇到错误<strong class="lf jd"> E(i) </strong>。</p><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi pp"><img src="../Images/77fe537ff832de59ad6c187957d8b9ba.png" data-original-src="https://miro.medium.com/v2/resize:fit:920/format:webp/1*XgXaUNRKkivNtNMyCZvqVA.png"/></div></div></figure><p id="95e1" class="pw-post-body-paragraph ld le it lf b lg lh kd li lj lk kg ll lm ln lo lp lq lr ls lt lu lv lw lx ly im bi translated">误差将完全摧毁我们的目标，因为增加误差将增加损失的成本，但是为了开发一个稳健的模型，我们需要允许一些误差，否则，它将导致<em class="nc">过度拟合</em>。</p><p id="3a04" class="pw-post-body-paragraph ld le it lf b lg lh kd li lj lk kg ll lm ln lo lp lq lr ls lt lu lv lw lx ly im bi translated">但是为了保持尽可能低的误差，我们将引入一个惩罚，当我们的模型错误地分类一个数据点时，它将面临一些<strong class="lf jd">惩罚(c) </strong>，这将帮助我们增加我们的准确性。</p><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi pq"><img src="../Images/7baf6f6b6ffbd06786cde2fad75476d5.png" data-original-src="https://miro.medium.com/v2/resize:fit:908/format:webp/1*CFqpWRShPqRL-JDqIWPL8w.png"/></div></div></figure><blockquote class="ov"><p id="1647" class="ow ox it bd oy oz pr ps pt pu pv ly dk translated">如果E = 0；那就不罚了。</p></blockquote><figure class="pg ph pi pj pk kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi pw"><img src="../Images/11a834128be2486c00beee339325e04c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*h5CNa8qbvxe5QLwuu30_zA.png"/></div></div></figure><blockquote class="ov"><p id="473f" class="ow ox it bd oy oz pr ps pt pu pv ly dk translated">如果c很大；然后是更小的余量但更好的分类(更容易过度拟合)</p><p id="3bc9" class="ow ox it bd oy oz pa pb pc pd pe ly dk translated">如果c=1，即非常低；那么裕度被最大化，但是以错误分类为代价(更好的分类器)</p></blockquote><h2 id="3938" class="np ma it bd mb nq px dn mf ns py dp mj lm pz nv ml lq qa nx mn lu qb nz mp iz bi translated">佩加索斯</h2><p id="43db" class="pw-post-body-paragraph ld le it lf b lg mt kd li lj mu kg ll lm ob lo lp lq oc ls lt lu od lw lx ly im bi translated">为了<strong class="lf jd">克服约束凸优化问题</strong>，我们采用<em class="nc">PEGASOS</em>方法。</p><p id="9697" class="pw-post-body-paragraph ld le it lf b lg lh kd li lj lk kg ll lm ln lo lp lq lr ls lt lu lv lw lx ly im bi translated">我们重新制定我们的方程，以实现约束独立性。</p><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi qc"><img src="../Images/2e5ce4c5beb52bebe706a8673824a770.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*qcK3HuPFiTpvlAAi2Uuq6A.png"/></div></div></figure><p id="e88e" class="pw-post-body-paragraph ld le it lf b lg lh kd li lj lk kg ll lm ln lo lp lq lr ls lt lu lv lw lx ly im bi translated">现在，如果我们从数学上来说，等式上对<em class="nc"> 1 </em>的影响将是<em class="nc">0</em>,因为我们加它一次，相反减去它一次。</p><p id="a87b" class="pw-post-body-paragraph ld le it lf b lg lh kd li lj lk kg ll lm ln lo lp lq lr ls lt lu lv lw lx ly im bi translated">为了简化我们的方程，我们将用t(i)来代替。</p><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi qd"><img src="../Images/5d01422f719ff7ab34a86705ca5e8b78.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*pbWJlyZZEabAakqvTrOtjQ.png"/></div></div></figure><p id="fe01" class="pw-post-body-paragraph ld le it lf b lg lh kd li lj lk kg ll lm ln lo lp lq lr ls lt lu lv lw lx ly im bi translated">上述等式对应于如果点远离超平面，误差将为零，否则遇到的误差将为(1-t(i))。</p><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div class="gh gi qe"><img src="../Images/4a02f31bd47709de1153a16eb46da8df.png" data-original-src="https://miro.medium.com/v2/resize:fit:946/format:webp/1*vbAtrBzhGTpluC9MSDTBOQ.png"/></div></figure><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi on"><img src="../Images/39fac58a5197525e1f05821340ba7b9a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*3hiC8uvo44_6Pn0kvIX3vQ.png"/></div></div></figure><p id="3c6f" class="pw-post-body-paragraph ld le it lf b lg lh kd li lj lk kg ll lm ln lo lp lq lr ls lt lu lv lw lx ly im bi translated">公式化函数在t≥1 时仍<strong class="lf jd">不微分；所以我们要在<strong class="lf jd">子渐变1 </strong> &amp; <strong class="lf jd">子渐变2中划分我们的渐变。</strong></strong></p><p id="0223" class="pw-post-body-paragraph ld le it lf b lg lh kd li lj lk kg ll lm ln lo lp lq lr ls lt lu lv lw lx ly im bi translated">我们需要将<strong class="lf jd">最小化</strong>的最后一个函数是:</p><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi qf"><img src="../Images/fd24fb50f1c9c06bb9621daccd323d14.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*nkf2WO69URqcuB-5WCtSqw.png"/></div></div></figure><p id="a5a3" class="pw-post-body-paragraph ld le it lf b lg lh kd li lj lk kg ll lm ln lo lp lq lr ls lt lu lv lw lx ly im bi translated">现在，因为约束被移除，我们的函数独立于γ。我们可以使用<a class="ae qg" href="https://towardsdatascience.com/gradient-descent-explained-9b953fc0d2c" rel="noopener" target="_blank">梯度下降</a>来减少损失。</p><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi qh"><img src="../Images/7dda4d3e906ffb84770df6169ebc8a19.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*JUKgq0fa93o5d1ns62ugVA.png"/></div></div></figure><h2 id="54f8" class="np ma it bd mb nq nr dn mf ns nt dp mj lm nu nv ml lq nw nx mn lu ny nz mp iz bi translated">使用梯度下降最小化损失</h2><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div class="gh gi qi"><img src="../Images/94b58f8ac13f239d7133e1d9922976fb.png" data-original-src="https://miro.medium.com/v2/resize:fit:1282/format:webp/1*VGM2CDOlausCX7o8vGOSZg.png"/></div><figcaption class="qj qk gj gh gi ql qm bd b be z dk translated">计算损失</figcaption></figure><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi qn"><img src="../Images/c0539346c39d70f65f87152c003f3558.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*GnibrVB5CHlH4AkKgdpUMw.png"/></div></div><figcaption class="qj qk gj gh gi ql qm bd b be z dk translated">为SVM实施梯度下降</figcaption></figure><h2 id="f466" class="np ma it bd mb nq nr dn mf ns nt dp mj lm nu nv ml lq nw nx mn lu ny nz mp iz bi translated">非线性分类</h2><p id="7e37" class="pw-post-body-paragraph ld le it lf b lg mt kd li lj mu kg ll lm ob lo lp lq oc ls lt lu od lw lx ly im bi translated">为了使用支持向量机对非线性数据进行分类，我们需要将数据投影到更高维度，即通过增加其特征将2D数据转换为3D数据。</p><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi qo"><img src="../Images/a2a6df288d217e578f2bb7d29314ea0b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*pwnON2zOaMB_rWkV.png"/></div></div><figcaption class="qj qk gj gh gi ql qm bd b be z dk translated"><a class="ae qg" href="https://www.researchgate.net/figure/Left-Original-3D-data-distributed-along-2D-manifold-Middle-Embedded-coordinates-of_fig1_327107042" rel="noopener ugc nofollow" target="_blank">来源</a></figcaption></figure><blockquote class="oe of og"><p id="a9dd" class="ld le nc lf b lg lh kd li lj lk kg ll oh ln lo lp oi lr ls lt oj lv lw lx ly im bi translated">这种特征的增加在计算上将是昂贵的。</p></blockquote><p id="96cd" class="pw-post-body-paragraph ld le it lf b lg lh kd li lj lk kg ll lm ln lo lp lq lr ls lt lu lv lw lx ly im bi translated">为了转换数据的维度，我们使用内核。</p><ul class=""><li id="4966" class="mr ms it lf b lg lh lj lk lm pm lq pn lu po ly my mz na nb bi translated"><em class="nc">线性内核</em></li><li id="7e72" class="mr ms it lf b lg nd lj ne lm nf lq ng lu nh ly my mz na nb bi translated"><em class="nc"> RBF(径向基)核</em></li></ul><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi ca"><img src="../Images/0acf11a756cd0e179b88a7df4beff46c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*EH40qh86M0ZWPTVP.png"/></div></div></figure><ul class=""><li id="c1ca" class="mr ms it lf b lg lh lj lk lm pm lq pn lu po ly my mz na nb bi translated"><em class="nc">多项式内核</em></li></ul><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div class="gh gi qp"><img src="../Images/a744bb4738cb1ed8353ee5c92a64c1c8.png" data-original-src="https://miro.medium.com/v2/resize:fit:486/format:webp/1*RcAFsaLjcHqof7UpcEHpLw.png"/></div></figure><ul class=""><li id="2331" class="mr ms it lf b lg lh lj lk lm pm lq pn lu po ly my mz na nb bi translated"><em class="nc">s形内核</em></li></ul><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div class="gh gi qq"><img src="../Images/387b51354cb5e8d5ed022a42a37846f3.png" data-original-src="https://miro.medium.com/v2/resize:fit:538/1*xGwa6RsM_x8kQsV12F6Z6A.gif"/></div></figure><p id="53b3" class="pw-post-body-paragraph ld le it lf b lg lh kd li lj lk kg ll lm ln lo lp lq lr ls lt lu lv lw lx ly im bi translated">内核技巧的障碍是为你的模型选择正确的内核，因为我们永远不知道哪个内核最适合我们的模型，代价是什么。</p><p id="dfb5" class="pw-post-body-paragraph ld le it lf b lg lh kd li lj lk kg ll lm ln lo lp lq lr ls lt lu lv lw lx ly im bi translated">因此，为了自动调整我们的超参数，我们将实现<strong class="lf jd"> GridSearch </strong>。</p><p id="6082" class="pw-post-body-paragraph ld le it lf b lg lh kd li lj lk kg ll lm ln lo lp lq lr ls lt lu lv lw lx ly im bi translated">我们将指定参数，即由以关键字为核心的字典和惩罚组成的列表，我们将为每个核心运行我们的模型，并获得最佳的准确性。</p><blockquote class="ov"><p id="a5e7" class="ow ox it bd oy oz pa pb pc pd pe ly dk translated">params = [{'kernel':['linear '，' rbf '，' poly '，' sigmoid']，' c':[0.1，0.2，0.5，1.0，2.0，5.0]}</p></blockquote><p id="a245" class="pw-post-body-paragraph ld le it lf b lg qr kd li lj qs kg ll lm qt lo lp lq qu ls lt lu qv lw lx ly im bi translated">现在，对于每种类型的内核和5种类型的惩罚，我们将存储精度，稍后将选择具有最佳精度的内核和惩罚(c)。</p><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi qw"><img src="../Images/e823d05c81b3eaab50c102a3aa001a51.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*BgCRxaG1jdOGdhk8jMz4Jw.png"/></div></div></figure><p id="46a2" class="pw-post-body-paragraph ld le it lf b lg lh kd li lj lk kg ll lm ln lo lp lq lr ls lt lu lv lw lx ly im bi translated"><em class="nc">接受的参数:</em></p><ul class=""><li id="3813" class="mr ms it lf b lg lh lj lk lm pm lq pn lu po ly my mz na nb bi translated"><strong class="lf jd"> cv </strong>:交叉验证</li><li id="8156" class="mr ms it lf b lg nd lj ne lm nf lq ng lu nh ly my mz na nb bi translated"><strong class="lf jd"> n_jobs </strong>:可用CPU数量</li></ul><h2 id="72e2" class="np ma it bd mb nq nr dn mf ns nt dp mj lm nu nv ml lq nw nx mn lu ny nz mp iz bi translated">支持向量机的利与弊</h2><p id="ae27" class="pw-post-body-paragraph ld le it lf b lg mt kd li lj mu kg ll lm ob lo lp lq oc ls lt lu od lw lx ly im bi translated"><strong class="lf jd">赞成者</strong></p><ul class=""><li id="fc1e" class="mr ms it lf b lg lh lj lk lm pm lq pn lu po ly my mz na nb bi translated">可以轻松处理大型特征空间。</li><li id="42f2" class="mr ms it lf b lg nd lj ne lm nf lq ng lu nh ly my mz na nb bi translated">内核技巧是SVM的真正优势，因为它有助于找到甚至是复杂问题的解决方案。</li><li id="35c7" class="mr ms it lf b lg nd lj ne lm nf lq ng lu nh ly my mz na nb bi translated">适用于线性和非线性数据。</li><li id="c271" class="mr ms it lf b lg nd lj ne lm nf lq ng lu nh ly my mz na nb bi translated">不容易过度拟合。</li><li id="8035" class="mr ms it lf b lg nd lj ne lm nf lq ng lu nh ly my mz na nb bi translated">即使对于非结构化数据也是可靠的。</li></ul><p id="070a" class="pw-post-body-paragraph ld le it lf b lg lh kd li lj lk kg ll lm ln lo lp lq lr ls lt lu lv lw lx ly im bi translated"><strong class="lf jd">缺点</strong></p><ul class=""><li id="635c" class="mr ms it lf b lg lh lj lk lm pm lq pn lu po ly my mz na nb bi translated">对噪音敏感。</li><li id="22bb" class="mr ms it lf b lg nd lj ne lm nf lq ng lu nh ly my mz na nb bi translated">选择一个最佳内核真的很难。</li><li id="be19" class="mr ms it lf b lg nd lj ne lm nf lq ng lu nh ly my mz na nb bi translated">大数据集训练时间长。</li></ul><h2 id="95b8" class="np ma it bd mb nq nr dn mf ns nt dp mj lm nu nv ml lq nw nx mn lu ny nz mp iz bi translated">想象SVM</h2><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi qx"><img src="../Images/2b3209e6b8f4a0b7556dc84e61025ec5.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*IbKkGupv-Qv5na79mbY34w.png"/></div></div></figure><h2 id="93d2" class="np ma it bd mb nq nr dn mf ns nt dp mj lm nu nv ml lq nw nx mn lu ny nz mp iz bi translated">SVM的应用</h2><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi qy"><img src="../Images/3693dc72b8c48ddb5f9565a86d171512.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*U_i0HUb_l5Voifop.jpg"/></div></div><figcaption class="qj qk gj gh gi ql qm bd b be z dk translated">来源:DataFlair</figcaption></figure></div><div class="ab cl ni nj hx nk" role="separator"><span class="nl bw bk nm nn no"/><span class="nl bw bk nm nn no"/><span class="nl bw bk nm nn"/></div><div class="im in io ip iq"><h1 id="9ec5" class="lz ma it bd mb mc qz me mf mg ra mi mj ki rb kj ml kl rc km mn ko rd kp mp mq bi translated">结论</h1><p id="77bb" class="pw-post-body-paragraph ld le it lf b lg mt kd li lj mu kg ll lm ob lo lp lq oc ls lt lu od lw lx ly im bi translated">希望这篇文章能帮助你尽可能好地理解支持向量机(SVM ),并帮助你实际使用它。</p><p id="7b8c" class="pw-post-body-paragraph ld le it lf b lg lh kd li lj lk kg ll lm ln lo lp lq lr ls lt lu lv lw lx ly im bi translated">一如既往，非常感谢您的阅读，如果您觉得这篇文章有用，请分享！</p></div><div class="ab cl ni nj hx nk" role="separator"><span class="nl bw bk nm nn no"/><span class="nl bw bk nm nn no"/><span class="nl bw bk nm nn"/></div><div class="im in io ip iq"><p id="8178" class="pw-post-body-paragraph ld le it lf b lg lh kd li lj lk kg ll lm ln lo lp lq lr ls lt lu lv lw lx ly im bi translated">请随意连接:</p><blockquote class="oe of og"><p id="d1af" class="ld le nc lf b lg lh kd li lj lk kg ll oh ln lo lp oi lr ls lt oj lv lw lx ly im bi translated">加入我在~<a class="ae qg" href="http://www.dakshtrehan.com" rel="noopener ugc nofollow" target="_blank">www.dakshtrehan.com</a></p><p id="5154" class="ld le nc lf b lg lh kd li lj lk kg ll oh ln lo lp oi lr ls lt oj lv lw lx ly im bi translated"><em class="it">LinkedIN ~</em><a class="ae qg" href="https://www.linkedin.com/in/dakshtrehan/" rel="noopener ugc nofollow" target="_blank"><em class="it">https://www.linkedin.com/in/dakshtrehan/</em></a></p><p id="ba0a" class="ld le nc lf b lg lh kd li lj lk kg ll oh ln lo lp oi lr ls lt oj lv lw lx ly im bi translated"><em class="it">Github ~</em><a class="ae qg" href="https://github.com/dakshtrehan" rel="noopener ugc nofollow" target="_blank">T35】https://github.com/dakshtrehan</a></p></blockquote><p id="0e98" class="pw-post-body-paragraph ld le it lf b lg lh kd li lj lk kg ll lm ln lo lp lq lr ls lt lu lv lw lx ly im bi translated">关注更多机器学习/深度学习博客。</p><blockquote class="oe of og"><p id="8b7a" class="ld le nc lf b lg lh kd li lj lk kg ll oh ln lo lp oi lr ls lt oj lv lw lx ly im bi translated"><em class="it">中等~</em><a class="ae qg" href="https://medium.com/@dakshtrehan" rel="noopener"><em class="it">https://medium.com/@dakshtrehan</em>T43】</a></p></blockquote><h1 id="7feb" class="lz ma it bd mb mc md me mf mg mh mi mj ki mk kj ml kl mm km mn ko mo kp mp mq bi translated">想了解更多？</h1><p id="7afe" class="pw-post-body-paragraph ld le it lf b lg mt kd li lj mu kg ll lm ob lo lp lq oc ls lt lu od lw lx ly im bi translated"><a class="ae qg" href="https://towardsdatascience.com/detecting-covid-19-using-deep-learning-262956b6f981" rel="noopener" target="_blank">利用深度学习检测新冠肺炎</a></p><p id="b34f" class="pw-post-body-paragraph ld le it lf b lg lh kd li lj lk kg ll lm ln lo lp lq lr ls lt lu lv lw lx ly im bi translated"><a class="ae qg" href="https://towardsdatascience.com/the-inescapable-ai-algorithm-tiktok-ad4c6fd981b8" rel="noopener" target="_blank">无法逃脱的人工智能算法:抖音</a></p><p id="2b7e" class="pw-post-body-paragraph ld le it lf b lg lh kd li lj lk kg ll lm ln lo lp lq lr ls lt lu lv lw lx ly im bi translated"><a class="ae qg" href="https://medium.com/@dakshtrehan/why-are-you-responsible-for-george-floyds-murder-delhi-communal-riots-4c1edb7acbc5" rel="noopener">为什么你要为乔治·弗洛伊德的谋杀和德里的骚乱负责？</a></p><p id="35b2" class="pw-post-body-paragraph ld le it lf b lg lh kd li lj lk kg ll lm ln lo lp lq lr ls lt lu lv lw lx ly im bi translated"><a class="ae qg" href="https://medium.com/@dakshtrehan/why-random-forest-and-not-decision-tree-6047d94edf61" rel="noopener">为什么随机森林而不是决策树？</a></p><p id="ecc1" class="pw-post-body-paragraph ld le it lf b lg lh kd li lj lk kg ll lm ln lo lp lq lr ls lt lu lv lw lx ly im bi translated"><a class="ae qg" href="https://medium.com/@dakshtrehan/clustering-what-it-is-when-to-use-it-a612bbe95881" rel="noopener">聚类:是什么？什么时候用？</a></p><p id="8e26" class="pw-post-body-paragraph ld le it lf b lg lh kd li lj lk kg ll lm ln lo lp lq lr ls lt lu lv lw lx ly im bi translated"><a class="ae qg" href="https://medium.com/@dakshtrehan/start-off-your-ml-journey-with-k-nearest-neighbors-f72a122f428" rel="noopener">从k个最近邻居开始你的ML之旅</a></p><p id="013b" class="pw-post-body-paragraph ld le it lf b lg lh kd li lj lk kg ll lm ln lo lp lq lr ls lt lu lv lw lx ly im bi translated"><a class="ae qg" href="https://medium.com/swlh/things-you-never-knew-about-naive-bayes-eb84b6ee039a" rel="noopener">朴素贝叶斯解释</a></p><p id="bfe1" class="pw-post-body-paragraph ld le it lf b lg lh kd li lj lk kg ll lm ln lo lp lq lr ls lt lu lv lw lx ly im bi translated"><a class="ae qg" href="https://medium.com/analytics-vidhya/activation-functions-explained-8690ea7bdec9" rel="noopener">激活功能说明</a></p><p id="b7eb" class="pw-post-body-paragraph ld le it lf b lg lh kd li lj lk kg ll lm ln lo lp lq lr ls lt lu lv lw lx ly im bi translated"><a class="ae qg" href="https://towardsdatascience.com/parameters-optimization-explained-876561853de0" rel="noopener" target="_blank">参数优化说明</a></p><p id="6ea7" class="pw-post-body-paragraph ld le it lf b lg lh kd li lj lk kg ll lm ln lo lp lq lr ls lt lu lv lw lx ly im bi translated"><a class="ae qg" href="https://towardsdatascience.com/gradient-descent-explained-9b953fc0d2c" rel="noopener" target="_blank">梯度下降解释</a></p><p id="9199" class="pw-post-body-paragraph ld le it lf b lg lh kd li lj lk kg ll lm ln lo lp lq lr ls lt lu lv lw lx ly im bi translated"><a class="ae qg" href="https://towardsdatascience.com/logistic-regression-explained-ef1d816ea85a" rel="noopener" target="_blank">逻辑回归解释</a></p><p id="556a" class="pw-post-body-paragraph ld le it lf b lg lh kd li lj lk kg ll lm ln lo lp lq lr ls lt lu lv lw lx ly im bi translated"><a class="ae qg" href="https://medium.com/towards-artificial-intelligence/linear-regression-explained-f5cc85ae2c5c" rel="noopener">线性回归解释了</a></p><p id="6438" class="pw-post-body-paragraph ld le it lf b lg lh kd li lj lk kg ll lm ln lo lp lq lr ls lt lu lv lw lx ly im bi translated"><a class="ae qg" href="https://medium.com/datadriveninvestor/determining-perfect-fit-for-your-ml-model-339459eef670" rel="noopener">确定最适合您的ML模型</a></p><blockquote class="oe of og"><p id="77c6" class="ld le nc lf b lg lh kd li lj lk kg ll oh ln lo lp oi lr ls lt oj lv lw lx ly im bi translated"><em class="it">干杯！</em></p></blockquote></div></div>    
</body>
</html>