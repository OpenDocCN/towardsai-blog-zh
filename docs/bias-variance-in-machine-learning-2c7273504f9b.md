# 机器学习中的偏差和方差

> 原文：<https://pub.towardsai.net/bias-variance-in-machine-learning-2c7273504f9b?source=collection_archive---------1----------------------->

## [机器学习](https://towardsai.net/p/category/machine-learning)

![](img/f20f7ee660aba5159736b2278ffaad38.png)

[艾蒂安·吉拉尔代](https://unsplash.com/@etiennegirardet?utm_source=medium&utm_medium=referral)在 [Unsplash](https://unsplash.com?utm_source=medium&utm_medium=referral) 上的照片

**线性回归是一种机器学习算法，用于预测定量目标，借助以线性方式建模的独立变量**，拟合包含预测数据点的直线或平面(或超平面)。首先，让我们认为这是最佳拟合线(为了更好地理解)。因此，通常，来自训练数据的点并不真的只位于最佳拟合线上，这很有意义，因为任何数据都不是完美的。这就是为什么我们首先要做预测，而不仅仅是画一条随机的线。

# 理解偏差

![](img/99f9d0003ca4b29fd3c8c4a205646c86.png)

照片由[大卫·塔利](https://unsplash.com/@davidtalley?utm_source=medium&utm_medium=referral)在 [Unsplash](https://unsplash.com?utm_source=medium&utm_medium=referral) 上拍摄

**线性回归线不能弯曲**以包含所有训练集数据点，因此有时不能捕捉精确的关系。这就是所谓的偏见。**用数学术语来说，线性回归方程中得到的截距，就是偏差。**

**我为什么这么说？**

让我解释一下:这里有一个随机线性回归方程:

> y =截距+斜率 1*x1 +斜率 2*x2

目标(y)在数据集中有一些值，上面的等式计算了这些值的预测值。**如果“截距”本身非常高，并且接近预测的 y 值，那么这将意味着由等式的其他两部分——独立变量(x1 和 x2)——引起的 y 的变化将会更小。**这意味着由 x1 和 x2 解释的差异量会更小，并且最终会导致构建欠拟合模型。**拟合不足的模型具有较低的 R 平方**(目标中的方差，由独立变量解释)。

Underfit 也可以通过**思考如何首先捕捉最佳拟合线/平面来理解。**最佳拟合线/平面捕捉目标和独立变量之间的关系。**如果这种关系被捕捉到非常高的程度，就会导致低偏差，反之亦然。**

既然我们已经了解了什么是偏差，以及高偏差如何导致欠拟合模型，那么对于一个稳健的模型来说，我们需要消除这种欠拟合就变得很清楚了。

**在一个场景中，我们创建一条穿过所有数据点**的曲线，可以展示自变量和因变量之间的现有关系，那么**模型中就不会有偏差。**

# 理解差异

![](img/80bd0df06054398b9fd10eda51feeafa.png)

照片由[尼克·费因斯](https://unsplash.com/@jannerboy62?utm_source=medium&utm_medium=referral)在 [Unsplash](https://unsplash.com?utm_source=medium&utm_medium=referral) 上拍摄

**一个对训练数据过度拟合的模型，会导致一种新的现象叫做“方差”。**是时候考虑几款车型了:

> **模型 1:** 高偏差(无法正确捕捉关系)
> 
> **模型 2:** 低偏差(在很大程度上捕捉关系)

**验证模型时的误差测量:**

> 误差=实际值-预测值

在计算训练数据的误差时(测试数据还没有出现)，我们观察到以下情况:

> **模型 1:** 对训练数据的模型验证显示误差很大
> 
> **模型 2:** 模型对训练数据的验证表明误差很低

现在，让我们引入训练数据，并理解方差。

因此，**如果模型过度拟合训练数据，那么它“理解”和“知道”训练数据到如此高的程度**，以至于我 **t 可能会与测试数据**发生冲突，因此当测试数据被用作该模型的输入时，它将无法捕获关系。从广义上讲，这意味着在训练数据和测试数据之间将有**高的拟合差异(因为训练数据显示了完美的验证，而测试数据无法捕捉到关系)。这种**拟合差异被称为“方差”**，它通常是在模型仅理解训练数据并与给予它的任何新输入进行斗争时产生的。**

在根据测试数据验证上述模型时，我们注意到:

> **模型 1:** 这里也没有正确地捕捉到关系，但是在训练和测试数据之间没有巨大的理解差距，所以方差很低
> 
> **模型 2:** 训练和测试数据之间存在巨大的理解差距，因此方差很大

# 偏差和方差之间的权衡

![](img/39e251e4554d170b67985050cd5e7033.png)

安德烈·诺沃亚在 [Unsplash](https://unsplash.com?utm_source=medium&utm_medium=referral) 上的照片

**现在我们明白了偏差和方差都会给我们的预测模型带来问题。那么，我们如何着手解决这个问题呢？**

在我们继续之前，需要理解几个术语:

> **过度拟合:**低偏差&高可变性——模型非常适合训练数据，但难以处理测试数据，因为它只能很好地理解训练数据
> 
> **欠拟合:**高偏差&低可变性——模型在使用训练数据时无法捕捉到关系，但由于它无论如何都没有捕捉到关系，因此在训练和测试数据之间没有太大的理解差距，所以方差很低

回到解决方案，我们可以做以下工作来尝试在引起的偏差和方差之间建立一个平衡:

# 1.交叉验证

![](img/c55d7363118545afa522f63b07563f95.png)

照片由[梅姆](https://unsplash.com/@picoftasty?utm_source=medium&utm_medium=referral)在 [Unsplash](https://unsplash.com?utm_source=medium&utm_medium=referral) 上拍摄

通常，一个模型建立在训练数据的基础上，并在同样的基础上进行测试，但是还有一件人们更喜欢的事情。**在一部分训练数据上测试模型，这称为验证数据。**

## **那么，什么是交叉验证呢？**

如前所述，模型验证是在部分训练数据上完成的。因此，如果我们继续**从训练数据中选择一组新的数据点来验证每一次迭代**，并对从这些数据集获得的结果进行平均，我们就在进行交叉验证。这是一种**优化的方法，用于理解模型在训练数据上的行为，也是一种理解是否存在过度拟合的方法。**

## **交叉验证的类型:**

> **K-Fold CV:** K 这里表示我们必须将我们的训练集分成的集合的数量，然后这些 **K 个集合将用于模型验证，并且从这些 K 个集合获得的结果将被平均以给出最终结果**，这可能会避免过拟合。
> 
> **留一法 CV:** 留一法 CV 的工作技术类似于 K 折 CV，但由于**使用训练数据中的每个数据点来计算交叉验证结果，因此它将该过程提升到了一个新的水平。**这显然很耗时，但绝对有助于避免过度拟合。
> 
> **正向链接:**在处理**时间序列数据**时，K 倍 CV 和留一 CV 会产生一个问题，因为很有可能**某些年份会出现其他年份没有**的模式，所以使用随机数据集进行交叉验证没有意义。事实上，现有的趋势可能会被忽视，这不是我们想要的。因此，通常，在这种情况下，使用前向链接方法，其中我们形成的每个折叠(用于交叉验证)包含一个**训练集，通过将连续一年的数据添加到先前的训练集**并在**测试集(仅包含训练集中使用的最近一年的连续年份)上验证它来创建。**

# 2.正规化

![](img/7daa8c02129d4adf28e91c8dbb6c6b90.png)

西蒙·伯杰在 [Unsplash](https://unsplash.com?utm_source=medium&utm_medium=referral) 上拍摄的照片

正则化是一种**技术，通过惩罚与我们模型的独立变量相关的β系数**来帮助减少偏差和方差。

我写了一整篇关于**“机器学习中的特征选择”**的文章，其中**更深入地描述了正则化及其类型**。**请随意查看这里:**

[**机器学习中的特征选择**](https://medium.com/towards-artificial-intelligence/feature-selection-in-machine-learning-3b2902852933)

# 结论

没有完美的模型。它必须变得完美，通过积极地利用它的不完美。一旦你能够识别出模型中存在的偏差或可变性，那么你就可以做很多事情来改变它。您也可以尝试功能选择和功能转换。您可以尝试删除一些过度拟合的变量。基于当时可能发生的情况，可以做出决定，如果有可能发生这种情况，模型肯定可以改进。

**感谢您的阅读！快乐学习！**

[**支持我在这里写作😃**](https://www.buymeacoffee.com/shauryalalwani)