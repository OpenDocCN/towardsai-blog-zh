<html>
<head>
<title>Generating Synthetic Sequential Data using GANs</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">使用GANs生成合成序列数据</h1>
<blockquote>原文：<a href="https://pub.towardsai.net/generating-synthetic-sequential-data-using-gans-a1d67a7752ac?source=collection_archive---------0-----------------------#2020-06-29">https://pub.towardsai.net/generating-synthetic-sequential-data-using-gans-a1d67a7752ac?source=collection_archive---------0-----------------------#2020-06-29</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><h2 id="d8b3" class="ir is it bd b dl iu iv iw ix iy iz dk ja translated" aria-label="kicker paragraph"><a class="ae ep" href="https://towardsai.net/p/category/machine-learning/deep-learning" rel="noopener ugc nofollow" target="_blank">深度学习</a></h2><div class=""/><p id="d1e7" class="pw-post-body-paragraph jz ka it kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw im bi translated">时序数据(具有时间依赖性的数据)在商业中非常常见，从信用卡交易到医疗保健记录再到股票市场价格。但隐私法规限制并大大减缓了对研发至关重要的有用数据的访问。这就产生了对具有高度代表性但又完全私密的合成序列数据的需求，至少可以说这是一种挑战。</p><p id="b686" class="pw-post-body-paragraph jz ka it kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw im bi translated">生成合成时间序列和顺序数据比表格数据更具挑战性，表格数据通常将一个人的所有信息存储在一行中。在顺序数据中，信息可以分布在许多行中，如信用卡交易，保持行(事件)和列(变量)之间的相关性是关键。此外，序列的长度是可变的；一些案例可能只包含几笔交易，而其他案例可能包含数千笔交易。</p><p id="1ff3" class="pw-post-body-paragraph jz ka it kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw im bi translated">时序数据和时间序列<a class="ae kx" href="https://pubmed.ncbi.nlm.nih.gov/30535151/" rel="noopener ugc nofollow" target="_blank">的生成模型已经得到了广泛的研究</a>，然而，许多这些努力导致了相对较差的合成数据质量和较低的灵活性。在许多情况下，模型被设计成特定于每个问题，因此需要详细的领域知识。</p><p id="e88a" class="pw-post-body-paragraph jz ka it kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw im bi translated">在本帖中，我们描述并应用了一种最新的强大方法的扩展版本来生成合成序列数据— <a class="ae kx" href="https://github.com/fjxmlzn/DoppelGANger" rel="noopener ugc nofollow" target="_blank">二重身</a>。它是一个基于生成对抗网络(GANs)的框架，具有一些创新，使得复杂序列数据集的合成版本的生成成为可能。</p><p id="7853" class="pw-post-body-paragraph jz ka it kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw im bi translated">我们在这项工作的基础上引入了两项创新:</p><ol class=""><li id="cc8b" class="ky kz it kb b kc kd kg kh kk la ko lb ks lc kw ld le lf lg bi translated">加速GAN收敛和避免模式崩溃的学习策略。</li><li id="8f48" class="ky kz it kb b kc lh kg li kk lj ko lk ks ll kw ld le lf lg bi translated">鉴别器中设计良好的噪声，以在不降低数据质量的情况下使过程有差别地私有，使用修改版本的矩会计策略来提高模型的稳定性。</li></ol></div><div class="ab cl lm ln hx lo" role="separator"><span class="lp bw bk lq lr ls"/><span class="lp bw bk lq lr ls"/><span class="lp bw bk lq lr"/></div><div class="im in io ip iq"><h1 id="763c" class="lt lu it bd lv lw lx ly lz ma mb mc md me mf mg mh mi mj mk ml mm mn mo mp mq bi translated">顺序数据生成的常用方法</h1><p id="a2e5" class="pw-post-body-paragraph jz ka it kb b kc mr ke kf kg ms ki kj kk mt km kn ko mu kq kr ks mv ku kv kw im bi translated">大多数时序数据生成模型使用以下方法之一:</p><p id="668a" class="pw-post-body-paragraph jz ka it kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw im bi translated"><strong class="kb jd">动态平稳过程</strong>通过将时间序列中的每个点表示为添加了一些噪声的确定性过程的总和来工作。这是一种广泛使用的方法，通过像<a class="ae kx" href="https://eranraviv.com/bootstrapping-time-series-r-code/" rel="noopener ugc nofollow" target="_blank">引导</a>这样的技术来建模时间序列。然而，一些长期依赖关系的先验知识，如循环模式，必须纳入约束确定性过程。这使得用复杂的、未知的相关性来建模数据集变得非常困难。</p><p id="b3f5" class="pw-post-body-paragraph jz ka it kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw im bi translated"><strong class="kb jd">马尔可夫模型</strong>是一种通过将系统动态表示为条件概率分布来对分类时间序列建模的流行方法。变体，如<a class="ae kx" href="https://link.springer.com/article/10.1023/A:1007469218079" rel="noopener ugc nofollow" target="_blank">隐马尔可夫模型</a>，也被用于时间序列的分布建模。这种方法的问题是它不能捕捉长期复杂的依赖关系。</p><p id="602a" class="pw-post-body-paragraph jz ka it kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw im bi translated"><strong class="kb jd">自回归(AR)模型</strong>是动态平稳过程，其中序列中的每个点都被表示为前<em class="mw"> n </em>个点的<a class="ae kx" href="https://arxiv.org/abs/1801.07736" rel="noopener ugc nofollow" target="_blank">函数。非线性ar模型(如ARIMA)非常强大。像马尔可夫模型这样的AR模型有一个保真度问题——它们产生的模型过于简单，无法捕捉复杂的时间相关性。</a></p><p id="e1fa" class="pw-post-body-paragraph jz ka it kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw im bi translated"><strong class="kb jd">递归神经网络(RNNs) </strong>最近被用于深度学习中的时间序列建模。像自回归和马尔可夫模型一样，RNNs使用以前时间步长的滑动窗口来确定下一个时间点。rnn还存储一个内部状态变量，该变量捕获时间序列的整个历史。像长短期记忆网络(LTSMs)一样，RNNs在学习时间序列数据的判别模型方面取得了巨大的成功，这些模型预测以样本为条件的标签。然而，rnn不能学习某些简单的时间序列分布。</p><p id="9d42" class="pw-post-body-paragraph jz ka it kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw im bi translated"><strong class="kb jd">基于GAN的方法</strong>或生成式对抗网络模型已经成为一种用于生成或扩充数据集(尤其是图像和视频)的流行技术。然而，gan在网络数据中的保真度较差，网络数据既有复杂的时间相关性，又有混合的离散-连续数据类型。虽然存在基于GAN的时间序列生成技术，例如<a class="ae kx" href="https://github.com/mp2893/medgan" rel="noopener ugc nofollow" target="_blank">医学时间序列</a>，但这种技术在更复杂的数据上失败，这些数据在长序列上表现出较差的自相关得分，同时易于出现模式崩溃。这是由于数据分布是重尾的并且长度可变。这似乎对GANs有很大影响。</p><h1 id="63c1" class="lt lu it bd lv lw mx ly lz ma my mc md me mz mg mh mi na mk ml mm nb mo mp mq bi translated">引入二重身以生成高质量的合成时间序列数据</h1><p id="9bdb" class="pw-post-body-paragraph jz ka it kb b kc mr ke kf kg ms ki kj kk mt km kn ko mu kq kr ks mv ku kv kw im bi translated">在这一节中，我将探索最近的模型来生成合成序列数据<a class="ae kx" href="https://arxiv.org/pdf/1909.13403.pdf" rel="noopener ugc nofollow" target="_blank">分身</a>。我将使用这个基于GANs的模型和一个由递归单元组成的生成器，使用两个数据集生成交易数据的合成版本:银行交易和道路交通。我们使用了二重身模型的修改来解决顺序数据的生成模型的局限性。</p><p id="79ca" class="pw-post-body-paragraph jz ka it kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw im bi translated">传统的生成对抗网络(GANs)由于以下问题而难以对序列数据建模:</p><ul class=""><li id="f5cd" class="ky kz it kb b kc kd kg kh kk la ko lb ks lc kw nc le lf lg bi translated">它们没有捕捉到时态特征和它们相关的(不可变的)属性之间的复杂关系:例如，根据所有者的特征(年龄、收入等)，交易中的信用卡模式是非常不同的。</li><li id="75a9" class="ky kz it kb b kc lh kg li kk lj ko lk ks ll kw nc le lf lg bi translated">时间序列中的长期相关性，如日变化模式:这些相关性在性质上与图像中发现的相关性非常不同，图像具有固定的维度，不需要逐像素生成。</li></ul><p id="1183" class="pw-post-body-paragraph jz ka it kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw im bi translated">二重身融合了一些创新的想法，比如:</p><ul class=""><li id="7b7d" class="ky kz it kb b kc kd kg kh kk la ko lb ks lc kw nc le lf lg bi translated">使用两个网络(多层感知器MLP和递归网络)来捕获时间依赖性</li><li id="f564" class="ky kz it kb b kc lh kg li kk lj ko lk ks ll kw nc le lf lg bi translated">分离属性生成，以更好地捕捉时间序列及其属性(例如，用户的年龄、位置和性别)之间的相关性</li><li id="dac4" class="ky kz it kb b kc lh kg li kk lj ko lk ks ll kw nc le lf lg bi translated">批量生成—生成长序列的小堆栈批量</li><li id="5356" class="ky kz it kb b kc lh kg li kk lj ko lk ks ll kw nc le lf lg bi translated">去耦归一化-将归一化因子添加到约束要素范围的生成器中</li></ul><p id="12a4" class="pw-post-body-paragraph jz ka it kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw im bi translated">DoppelGANger将属性的生成与时间序列解耦，同时在每个时间步将属性提供给时间序列生成器。这与传统方法形成对比，在传统方法中，属性和特征是联合生成的。</p><p id="43c5" class="pw-post-body-paragraph jz ka it kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw im bi translated">DoppelGANger的条件生成架构还提供了更改属性分布和属性条件的灵活性。这也有助于隐藏属性分布，从而增加隐私。</p><p id="746a" class="pw-post-body-paragraph jz ka it kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw im bi translated">二重身模型还具有根据数据属性生成数据特征的优势。</p><figure class="ne nf ng nh gt ni gh gi paragraph-image"><div role="button" tabindex="0" class="nj nk di nl bf nm"><div class="gh gi nd"><img src="../Images/c1e7ff5f0e137b2ef242b7dd08fac032.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*9Ae2jvmXOCwynhuhCnlXtA.png"/></div></div><figcaption class="np nq gj gh gi nr ns bd b be z dk translated"><strong class="bd lv">图1 </strong>:原二重身模型两个发生器模块和两个鉴别器的示意图。信用:【https://arxiv.org/abs/1909.13403】T2。</figcaption></figure><p id="0cd7" class="pw-post-body-paragraph jz ka it kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw im bi translated">这个模型的另一个特点是它如何处理极端事件，这是一个非常具有挑战性的问题。跨样本的序列数据具有广泛的特征值并不罕见，一些产品可能有数千个交易，而另一些只有几个。对于GANs来说，这是有问题的，因为它是模式崩溃的可靠方法——样本将只包含最常见的项目，而忽略罕见的事件。对于图像——几乎所有GANs工作的焦点——这不是问题，因为分布是平滑的。这就是为什么《二重身》的作者提出了一种创新的方法来处理这些情况:<strong class="kb jd">自动规范化</strong>。它包括在训练之前对数据特征进行归一化，并且将最小和最大范围的特征作为两个附加属性添加到每个样本中。</p><p id="355e" class="pw-post-body-paragraph jz ka it kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw im bi translated">在生成的数据中，这两个属性通常会将要素缩放回实际范围。这分三步完成:</p><ol class=""><li id="f921" class="ky kz it kb b kc kd kg kh kk la ko lb ks lc kw ld le lf lg bi translated">使用多层感知器(MLP)生成器生成属性。</li><li id="9d8d" class="ky kz it kb b kc lh kg li kk lj ko lk ks ll kw ld le lf lg bi translated">将生成的属性作为输入，使用另一个MLP生成两个“假”(最大/最小)属性。</li><li id="e719" class="ky kz it kb b kc lh kg li kk lj ko lk ks ll kw ld le lf lg bi translated">将生成的真假属性作为输入，生成要素。</li></ol><h1 id="7df0" class="lt lu it bd lv lw mx ly lz ma my mc md me mz mg mh mi na mk ml mm nb mo mp mq bi translated">在银行交易数据上训练二重身模型</h1><p id="7b9c" class="pw-post-body-paragraph jz ka it kb b kc mr ke kf kg ms ki kj kk mt km kn ko mu kq kr ks mv ku kv kw im bi translated">首先，我们在银行交易数据集上评估了二重身。用于训练的数据是合成的，所以我们知道真实的分布，并且可以在这里 访问<a class="ae kx" href="https://www.dropbox.com/s/yz6por3n3b1o6rn/data.csv?dl=0" rel="noopener ugc nofollow" target="_blank"> <strong class="kb jd">。我们的目的是证明这个模型能够学习数据中的时间依赖性。</strong></a></p><h2 id="01ec" class="nt lu it bd lv nu nv dn lz nw nx dp md kk ny nz mh ko oa ob ml ks oc od mp iz bi translated">如何准备资料？</h2><figure class="ne nf ng nh gt ni gh gi paragraph-image"><div role="button" tabindex="0" class="nj nk di nl bf nm"><div class="gh gi oe"><img src="../Images/0c0246fdb93550ed445842cf2d023e8a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*sYkXXhiEJYXgCjR9pV747w.png"/></div></div><figcaption class="np nq gj gh gi nr ns bd b be z dk translated"><strong class="bd lv">图2 </strong>:作为一组不同长度的属性和特征处理的数据的示意图。</figcaption></figure><p id="76aa" class="pw-post-body-paragraph jz ka it kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw im bi translated">我们假设顺序数据由一组最大长度为Lmax的序列组成—在我们的例子中，我们考虑Lmax <em class="mw"> = </em> 100。每个序列包含一组<strong class="kb jd">属性</strong> <strong class="kb jd"> A </strong>(固定数量)和<strong class="kb jd">特性</strong> <strong class="kb jd"> F </strong>(交易)。在我们的例子中，唯一的属性是初始银行<em class="mw">余额</em>，特征是:交易的<em class="mw">金额</em>(正或负)和另外两个描述交易的类别:<em class="mw">标志</em>和<em class="mw">描述</em>。</p><p id="1fd0" class="pw-post-body-paragraph jz ka it kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw im bi translated">要运行该模型，我们需要三个<a class="ae kx" href="https://cs231n.github.io/python-numpy-tutorial/#:~:text=A%20numpy%20array%20is%20a,the%20array%20along%20each%20dimension." rel="noopener ugc nofollow" target="_blank"> NumPy数组</a>:</p><ol class=""><li id="eb7d" class="ky kz it kb b kc kd kg kh kk la ko lb ks lc kw ld le lf lg bi translated"><strong class="kb jd">数据_特征</strong>:训练特征，<a class="ae kx" href="https://numpy.org/doc/stable/user/basics.types.html" rel="noopener ugc nofollow" target="_blank"> NumPy float32数组格式</a>。大小为[(训练样本数)x(最大长度)x(特征的总尺寸)]。分类特征通过一键编码存储。</li><li id="2995" class="ky kz it kb b kc lh kg li kk lj ko lk ks ll kw ld le lf lg bi translated"><strong class="kb jd"> data_attribute </strong>:训练属性，NumPy float32数组格式。大小为[(训练样本数)x(属性总维数)]。</li><li id="53ce" class="ky kz it kb b kc lh kg li kk lj ko lk ks ll kw ld le lf lg bi translated"><strong class="kb jd"> data_gen_flag </strong>:表示特性激活的标志数组。大小为[(训练样本数)x(最大长度)]。</li></ol><p id="ea25" class="pw-post-body-paragraph jz ka it kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw im bi translated">此外，我们需要一个包含每个变量的数据类型、规范化和基数的类输出对象列表。在这种情况下，它是:</p><pre class="ne nf ng nh gt of og oh oi aw oj bi"><span id="5011" class="nt lu it og b gy ok ol l om on">data_feature_outputs = [<br/>output.Output(type_=OutputType.CONTINUOUS,dim=1,normalization=Normalization.ZERO_ONE,is_gen_flag=False), <br/># time intervals between transactions (Dif)<br/>    output.Output(type_=OutputType.DISCRETE,dim=20,is_gen_flag=False), <br/># binarized Amount<br/>    output.Output(type_=OutputType.DISCRETE,dim=5,is_gen_flag=False),<br/># Flag</span><span id="8648" class="nt lu it og b gy oo ol l om on">output.Output(type_=OutputType.DISCRETE,dim=44,is_gen_flag=False) <br/># Description    <br/>]</span></pre><p id="6ef4" class="pw-post-body-paragraph jz ka it kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw im bi translated">列表的第一个元素是事件之间的时间间隔<em class="mw"> Dif </em>，接着是1-hot编码的交易值(金额)，接着是标志，第四个是交易描述。所有的gen_flags都被设置为False，因为它是一个内部标志，以后会被模型本身修改。</p><p id="f477" class="pw-post-body-paragraph jz ka it kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw im bi translated">该属性被编码为一个连续变量，归一化值在-1和1之间，以说明负余额:</p><pre class="ne nf ng nh gt of og oh oi aw oj bi"><span id="8b1e" class="nt lu it og b gy ok ol l om on">data_attribute_outputs = [output.Output(type_=OutputType.CONTINUOUS,dim=1,normalization=Normalization.MINUSONE_ONE,is_gen_flag=False)]</span></pre><p id="f7d8" class="pw-post-body-paragraph jz ka it kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw im bi translated">此模拟中使用的唯一属性是初始平衡。每一步的余额只需添加相应的交易金额即可更新。</p><p id="1724" class="pw-post-body-paragraph jz ka it kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw im bi translated">我们使用<a class="ae kx" href="http://hazy.com" rel="noopener ugc nofollow" target="_blank">模糊处理器</a>来预处理每个序列，并以正确的格式重塑它。</p><pre class="ne nf ng nh gt of og oh oi aw oj bi"><span id="2eb6" class="nt lu it og b gy ok ol l om on">n_bins = 20<br/>processor_dict = {<br/>            "by_type": {<br/>                  "float": {<br/>                    "processor": "FloatToOneHot", #FloatToBin"<br/>                    "kwargs": {"n_bins": n_bins}<br/>                  },<br/>                  "int": {<br/>                    "processor": "IntToFloat",<br/>                    "kwargs": {"n_bins": n_bins}<br/>                  },<br/>                  "category": {<br/>                    "processor": "CatToOneHot",<br/>          <br/>        },<br/>                 "datetime": {<br/>                    "processor": "DtToFloat",<br/>                  }<br/>                }<br/>        }</span><span id="30b5" class="nt lu it og b gy oo ol l om on">from hazy_trainer.processing import HazyProcessor<br/>processor = HazyProcessor(processor_dict)</span></pre><p id="4e8c" class="pw-post-body-paragraph jz ka it kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw im bi translated">现在我们将读取数据，并使用函数format_data对其进行处理。辅助变量categories_n和categories_cum分别存储变量的基数和基数的累积和。</p><pre class="ne nf ng nh gt of og oh oi aw oj bi"><span id="4e29" class="nt lu it og b gy ok ol l om on">data=pd.read_csv('data.csv',nrows=100000)    # read the data</span><span id="fcb8" class="nt lu it og b gy oo ol l om on">categorical = ['Amount','Flag','Description'] <br/>continuous =['Balance','Dif']<br/>cols = categorical + continuous<br/>processor = HazyProcessor(processor_dict) #call Hazy processor<br/>processor.setup_df(data[cols]) # setup the processor<br/>categories_n = [] # Number of categories in each categorical variable<br/>for cat in categorical:<br/>    categories_n.append(len(processor.column_to_columns[cat]['process']))<br/><br/>categories_cum = list(np.cumsum(categories_n)) # Cumulative sum of number of categorical variables<br/>categories_cum = [x for x in categories_cum] # We take one out because they will be indexes<br/>categories_cum = [0] + categories_cum<br/><br/>def format_data(data, cols, nsequences=1000, Lmax=100, cardinality=70):<br/>''' cols is a list of columns to be processed</span><span id="5cf5" class="nt lu it og b gy oo ol l om on">nsequences  number of sequences to use for training<br/>   Lmax is the maximum sequence length<br/>   Cardinality shape of sequences'''<br/>   idd=list(accenture.Account_id.unique()) # unique account ids<br/>   data.Date = pd.to_datetime(data.Date) # format date<br/>  # dummy to normalize the processors<br/> data['Dif']=np.random.randint(0,30*24*3600,size=accenture.shape[0]) </span><span id="ec99" class="nt lu it og b gy oo ol l om on">   data_all = np.zeros((nsequences,Lmax,Cardinality))<br/>   data_attribut=np.zeros((nsequences))<br/>   data_gen_flag=np.zeros((nsequences,Lmax))<br/>   real_df = pd.DataFrame()<br/>   for i,ids in enumerate(idd[:nsequences]):<br/>      user = data[data.Account_id==ids]<br/>      user=user.sort_values(by='Date')<br/>      user['Dif']=user.Date.diff(1).iloc[1:] <br/>      user['Dif']=user['Dif'].dt.seconds <br/>      user = user[cols]<br/>      real_df=pd.concat([real_df,user])<br/>      processed_df = processor.process_df(user)<br/>      Data_attribut[i] = processed_df['Balance'].values[0]<br/>      processed_array = np.asarray(processed_df.iloc[:,1:)<br/>      data_gen_flag[i,:len(user)]=1<br/>      data_all[i,:len(user),:]=processed_array</span><span id="be58" class="nt lu it og b gy oo ol l om on">return data_all, data_attribut, data_gen_flag</span></pre><p id="82cc" class="pw-post-body-paragraph jz ka it kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw im bi translated"><strong class="kb jd">数据</strong></p><p id="69c7" class="pw-post-body-paragraph jz ka it kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw im bi translated"><a class="ae kx" href="https://www.dropbox.com/s/yz6por3n3b1o6rn/data.csv?dl=0" rel="noopener ugc nofollow" target="_blank">数据</a>包含大约1000万笔银行交易，我们将从中抽取100，000笔交易作为样本，其中包含5，000个不同的账户，每个账户平均有20笔交易。我们考虑以下领域:</p><ul class=""><li id="efaa" class="ky kz it kb b kc kd kg kh kk la ko lb ks lc kw nc le lf lg bi translated">交易日期</li><li id="2687" class="ky kz it kb b kc lh kg li kk lj ko lk ks ll kw nc le lf lg bi translated">交易金额</li><li id="ea3b" class="ky kz it kb b kc lh kg li kk lj ko lk ks ll kw nc le lf lg bi translated">保持平衡</li><li id="4397" class="ky kz it kb b kc lh kg li kk lj ko lk ks ll kw nc le lf lg bi translated">交易标志(5级)</li><li id="1c29" class="ky kz it kb b kc lh kg li kk lj ko lk ks ll kw nc le lf lg bi translated">描述(44级)</li></ul><p id="c409" class="pw-post-body-paragraph jz ka it kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw im bi translated">下面是标题所用的数据:</p><figure class="ne nf ng nh gt ni gh gi paragraph-image"><div role="button" tabindex="0" class="nj nk di nl bf nm"><div class="gh gi op"><img src="../Images/b7ee7151ea16d463c9f7ab494ea166af.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*lHrqJc4aI-uCqj9P1zu3Ug.png"/></div></div><figcaption class="np nq gj gh gi nr ns bd b be z dk translated">表1:银行交易数据示例</figcaption></figure><p id="a3f8" class="pw-post-body-paragraph jz ka it kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw im bi translated">如前所述，时间信息将被建模为两个连续事务之间的时间差(以秒为单位)。</p><figure class="ne nf ng nh gt ni gh gi paragraph-image"><div role="button" tabindex="0" class="nj nk di nl bf nm"><div class="gh gi oq"><img src="../Images/8dfa63f8763aee02537707a33b6c04e4.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*tDeoxpqgxy_eySQ6"/></div></div><figcaption class="np nq gj gh gi nr ns bd b be z dk translated"><strong class="bd lv">图3 </strong>:不同<em class="or">描述</em>的交易柱状图，分离为收入和流出。</figcaption></figure><figure class="ne nf ng nh gt ni gh gi paragraph-image"><div role="button" tabindex="0" class="nj nk di nl bf nm"><div class="gh gi oq"><img src="../Images/4dd539b2d27cb4cff355a8355a9207e1.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*6bCPVK-hso8ZVbuH"/></div></div><figcaption class="np nq gj gh gi nr ns bd b be z dk translated"><strong class="bd lv">图4: </strong>不同时间分布的交易热图。</figcaption></figure><figure class="ne nf ng nh gt ni gh gi paragraph-image"><div role="button" tabindex="0" class="nj nk di nl bf nm"><div class="gh gi oq"><img src="../Images/3cb042e63baf5d1ede01b1c3d37f7835.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*PNlWBRr-tECzp8v3"/></div></div><figcaption class="np nq gj gh gi nr ns bd b be z dk translated"><strong class="bd lv">图五</strong>:交易分布<em class="or">金额</em>。</figcaption></figure><figure class="ne nf ng nh gt ni gh gi paragraph-image"><div role="button" tabindex="0" class="nj nk di nl bf nm"><div class="gh gi oq"><img src="../Images/76435d291f34f2a44c822b9d92186abd.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*QvlbxjSWAsvWUgkY"/></div></div><figcaption class="np nq gj gh gi nr ns bd b be z dk translated"><strong class="bd lv">图6 </strong>:初始<em class="or">余额</em>分配。请注意，由于透支，一些帐户的初始余额为负。</figcaption></figure><figure class="ne nf ng nh gt ni gh gi paragraph-image"><div role="button" tabindex="0" class="nj nk di nl bf nm"><div class="gh gi oq"><img src="../Images/1ac1945833399a6abd7ac48f2737b9dc.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*Bl59B-g-re_Yx8E-"/></div></div><figcaption class="np nq gj gh gi nr ns bd b be z dk translated"><strong class="bd lv">图7 </strong>:一个月的交易笔数——收入和流出。请注意，收入有非常明显的峰值。合成数据必须捕捉这些峰值</figcaption></figure><h1 id="8756" class="lt lu it bd lv lw mx ly lz ma my mc md me mz mg mh mi na mk ml mm nb mo mp mq bi translated">运行代码</h1><p id="3745" class="pw-post-body-paragraph jz ka it kb b kc mr ke kf kg ms ki kj kk mt km kn ko mu kq kr ks mv ku kv kw im bi translated">我们使用以下参数仅运行了100个时期的代码:</p><pre class="ne nf ng nh gt of og oh oi aw oj bi"><span id="12b4" class="nt lu it og b gy ok ol l om on">import sys<br/>import os<br/>sys.path.append("..")<br/>import matplotlib.pyplot as plt<br/><br/>from gan import output<br/>sys.modules["output"] = output<br/><br/>import numpy as np<br/>import pickle<br/>import pandas as pd<br/><br/>from gan.doppelganger import DoppelGANger<br/>from gan.load_data import load_data<br/>from gan.network import DoppelGANgerGenerator, Discriminator, AttrDiscriminator<br/>from gan.output import Output, OutputType, Normalization<br/>import tensorflow as tf<br/>from gan.network import DoppelGANgerGenerator, Discriminator, \<br/>    RNNInitialStateType, AttrDiscriminator<br/>from gan.util import add_gen_flag, normalize_per_sample, \<br/>    renormalize_per_sample<br/><br/>sample_len = 10<br/>epoch = 100<br/>batch_size = 20<br/>d_rounds = 2<br/>g_rounds = 1<br/>d_gp_coe = 10.0<br/>attr_d_gp_coe = 10.0<br/>g_attr_d_coe = 1.0</span></pre><p id="36ea" class="pw-post-body-paragraph jz ka it kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw im bi translated">请注意，生成器由一系列层组成，对于分类输入使用<em class="mw"> softmax </em>激活功能，对于连续变量使用<em class="mw">线性</em>激活功能。发生器和鉴别器都使用具有指定学习速率和动量的<a class="ae kx" href="https://arxiv.org/abs/1412.6980" rel="noopener ugc nofollow" target="_blank"> Adam算法</a>进行优化。</p><p id="e2eb" class="pw-post-body-paragraph jz ka it kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw im bi translated">现在，我们准备好数据来输入网络。real_attribute_mask是一个True/False列表，其长度与属性的数量相同。如果属性为(max-min)/2或(max+min)/2，则为False否则为真。首先，我们实例化生成器和鉴别器:</p><pre class="ne nf ng nh gt of og oh oi aw oj bi"><span id="a4a2" class="nt lu it og b gy ok ol l om on"># create the necessary input arrays<br/>data_all, data_attribut, data_gen_flag = format_data(data,cols)<br/># normalise data<br/>(data_feature, data_attribute, data_attribute_outputs,<br/> real_attribute_mask) = normalize_per_sample(<br/>        data_all, data_attribut, data_feature_outputs,<br/>        data_attribute_outputs)<br/># add generation flag to features<br/>data_feature, data_feature_outputs = add_gen_flag(<br/>    data_feature, data_gen_flag, data_feature_outputs, sample_len)</span><span id="68b0" class="nt lu it og b gy oo ol l om on">generator = DoppelGANgerGenerator(<br/>    feed_back=False,<br/>    noise=True,<br/>    feature_outputs=data_feature_outputs,<br/>    attribute_outputs=data_attribute_outputs,<br/>    real_attribute_mask=real_attribute_mask,<br/>    sample_len=sample_len,<br/>    feature_num_units=100,<br/>    feature_num_layers=2)<br/><br/>discriminator = Discriminator()<br/>attr_discriminator = AttrDiscriminator()</span></pre><p id="6df9" class="pw-post-body-paragraph jz ka it kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw im bi translated">我们使用由两层100个神经元组成的神经网络作为生成器和鉴别器。所有数据都进行了标准化或1-hot编码。然后，我们用以下参数训练模型:</p><pre class="ne nf ng nh gt of og oh oi aw oj bi"><span id="14e4" class="nt lu it og b gy ok ol l om on">checkpoint_dir = "./results/checkpoint"<br/>sample_path = "./results/time"<br/>epoch = 100<br/>batch_size = 50<br/>g_lr = 0.0001<br/>d_lr = 0.0001<br/>vis_freq = 50<br/>vis_num_sample = 5<br/>d_rounds = 3<br/>g_rounds = 1<br/>d_gp_coe = 10.0<br/>attr_d_gp_coe = 10.0<br/>g_attr_d_coe = 1.0<br/>extra_checkpoint_freq = 30<br/>num_packing = 1</span></pre><h1 id="19e1" class="lt lu it bd lv lw mx ly lz ma my mc md me mz mg mh mi na mk ml mm nb mo mp mq bi translated">关于培训的一些注意事项</h1><p id="a9bc" class="pw-post-body-paragraph jz ka it kb b kc mr ke kf kg ms ki kj kk mt km kn ko mu kq kr ks mv ku kv kw im bi translated">如果数据很大，你应该使用更大数量的历元——作者建议400个，但在我们的实验中，我们发现我们可以高达1000个而网络不会退化到模式崩溃。此外，考虑到历元的数量与批次大小有关，较小的批次需要更多的历元和较低的学习率。</p><p id="88ed" class="pw-post-body-paragraph jz ka it kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw im bi translated">对于刚接触神经网络的人来说，批量、随机和小批量梯度下降是机器学习算法的三种主要形式。训练神经网络时，批量大小控制误差梯度估计的准确性。在学习过程中，用户应了解批次大小、速度和稳定性之间的权衡。更大的批量需要更大的学习速率，网络将学习得更快，但也可能不太稳定，由于<a class="ae kx" href="https://medium.com/@jonathan_hui/gan-why-it-is-so-hard-to-train-generative-advisory-networks-819a86b3750b#:~:text=Mode%20collapse%20is%20one%20of%20the%20hardest%20problems%20to%20solve%20in%20GAN.&amp;text=The%20mode%20collapses%20to%20a,to%20detect%20this%20single%20mode." rel="noopener">模式崩溃问题</a>，这对于GANs来说尤其成问题。</p><p id="17d6" class="pw-post-body-paragraph jz ka it kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw im bi translated">根据经验，生成器和鉴别器的学习率应该很小(在10–3到10–5的范围内)并且彼此相似。在我们的例子中，我们使用10–4，而不是默认的10–3。</p><p id="269e" class="pw-post-body-paragraph jz ka it kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw im bi translated">另一个重要参数是发生器和鉴别器上的回合数。Wasserstein GAN (WGAN)需要两个组件才能正常工作:梯度限幅和比发生器更高的鉴频器轮数(d_round)。通常，对于发生器的每一轮，鉴别器的轮数在3到5之间。这里我们用d_round=3，g_round=1。</p><p id="cb03" class="pw-post-body-paragraph jz ka it kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw im bi translated">为了加速训练，我们对生成器使用了一个<a class="ae kx" href="https://arxiv.org/pdf/1506.01186.pdf" rel="noopener ugc nofollow" target="_blank">循环学习率</a>，对鉴别器使用了一个固定的学习率。</p><p id="7bea" class="pw-post-body-paragraph jz ka it kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw im bi translated">目录sample_path存储了在不同检查点收集的一组样本，这对验证非常有用。损失函数的可视化可以使用TensorBoard在您提供的检查点目录上完成。您可以使用参数extra_checkpoint_freq控制检查点的频率。</p><p id="903c" class="pw-post-body-paragraph jz ka it kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw im bi translated">请注意，这可能会占用大量磁盘空间。在MacBook Pro上模拟不到十分钟。</p><pre class="ne nf ng nh gt of og oh oi aw oj bi"><span id="0602" class="nt lu it og b gy ok ol l om on">run_config = tf.ConfigProto()<br/>tf.reset_default_graph() # if you are using spyder <br/>with tf.Session(config=run_config) as sess:<br/>    gan = DoppelGANger(<br/>        sess=sess, <br/>        checkpoint_dir=checkpoint_dir,<br/>        sample_dir=sample_dir,<br/>        time_path=sample_path,<br/>        epoch=epoch,<br/>        batch_size=batch_size,<br/>        data_feature=data_feature,<br/>        data_attribute=data_attribute,<br/>        real_attribute_mask=real_attribute_mask,<br/>        data_gen_flag=data_gen_flag,<br/>        sample_len=sample_len,<br/>        data_feature_outputs=data_feature_outputs,<br/>        data_attribute_outputs=data_attribute_outputs,<br/>        vis_freq=vis_freq,<br/>        vis_num_sample=vis_num_sample,<br/>        generator=generator,<br/>        discriminator=discriminator,<br/>        attr_discriminator=attr_discriminator,<br/>        d_gp_coe=d_gp_coe,<br/>        attr_d_gp_coe=attr_d_gp_coe,<br/>        g_attr_d_coe=g_attr_d_coe,<br/>        d_rounds=d_rounds,<br/>        g_rounds=g_rounds,</span><span id="b838" class="nt lu it og b gy oo ol l om on">g_lr=g_lr,</span><span id="82ac" class="nt lu it og b gy oo ol l om on">d_lr=d_lr,<br/>        num_packing=num_packing,<br/>        extra_checkpoint_freq=extra_checkpoint_freq)<br/>    gan.build()<br/>    gan.train()</span></pre><h1 id="dcd9" class="lt lu it bd lv lw mx ly lz ma my mc md me mz mg mh mi na mk ml mm nb mo mp mq bi translated">合成数据生成</h1><p id="029c" class="pw-post-body-paragraph jz ka it kb b kc mr ke kf kg ms ki kj kk mt km kn ko mu kq kr ks mv ku kv kw im bi translated">模型定型后，您可以使用生成器从噪声中创建合成数据。有两种方法可以做到:</p><ol class=""><li id="9ca3" class="ky kz it kb b kc kd kg kh kk la ko lb ks lc kw ld le lf lg bi translated">纯噪声的无条件生成</li><li id="6ce7" class="ky kz it kb b kc lh kg li kk lj ko lk ks ll kw ld le lf lg bi translated">属性的条件生成</li></ol><p id="0886" class="pw-post-body-paragraph jz ka it kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw im bi translated">在第一种情况下，我们生成属性和特征。在第二个示例中，我们明确指定了我们希望以哪些属性作为要素生成的条件，以便只生成要素。</p><p id="9cfe" class="pw-post-body-paragraph jz ka it kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw im bi translated">下面是从中生成样本的代码:</p><pre class="ne nf ng nh gt of og oh oi aw oj bi"><span id="b7dc" class="nt lu it og b gy ok ol l om on">run_config = tf.ConfigProto()<br/>total_generate_num_sample = 1000<br/>with tf.Session(config=run_config) as sess:<br/>    gan = DoppelGANger(<br/>        sess=sess, <br/>        checkpoint_dir=checkpoint_dir,<br/>        sample_dir=sample_dir,<br/>        time_path=time_path,<br/>        epoch=epoch,<br/>        batch_size=batch_size,<br/>        data_feature=data_feature,<br/>        data_attribute=data_attribute,<br/>        real_attribute_mask=real_attribute_mask,<br/>        data_gen_flag=data_gen_flag,<br/>        sample_len=sample_len,<br/>        data_feature_outputs=data_feature_outputs,<br/>        data_attribute_outputs=data_attribute_outputs,<br/>        vis_freq=vis_freq,<br/>        vis_num_sample=vis_num_sample,<br/>        generator=generator,<br/>        discriminator=discriminator,<br/>        attr_discriminator=attr_discriminator,<br/>        d_gp_coe=d_gp_coe,<br/>        attr_d_gp_coe=attr_d_gp_coe,<br/>        g_attr_d_coe=g_attr_d_coe,<br/>        d_rounds=d_rounds,<br/>        g_rounds=g_rounds,<br/>        num_packing=num_packing,<br/>        extra_checkpoint_freq=extra_checkpoint_freq)<br/><br/># build the network <br/>    gan.build()<br/>    <br/>    length = int(data_feature.shape[1] / sample_len)<br/>    real_attribute_input_noise = gan.gen_attribute_input_noise(<br/>                total_generate_num_sample)<br/>    addi_attribute_input_noise = gan.gen_attribute_input_noise(<br/>                total_generate_num_sample)<br/>    feature_input_noise = gan.gen_feature_input_noise(<br/>                total_generate_num_sample, length)<br/>    input_data = gan.gen_feature_input_data_free(<br/>                total_generate_num_sample)</span><span id="70c3" class="nt lu it og b gy oo ol l om on"># load the weights / change the path accordingly<br/>    gan.load(checkpoint_dir+'/epoch_id-100')<br/><br/># generate features, attributes and lengths<br/>    features, attributes, gen_flags, lengths = gan.sample_from(<br/>        real_attribute_input_noise, addi_attribute_input_noise,<br/>        feature_input_noise, input_data, given_attribute=None,<br/>        return_gen_flag_feature=False)<br/>#denormalise accordingly<br/>    features, attributes = renormalize_per_sample(<br/>        features, attributes, data_feature_outputs,<br/>        data_attribute_outputs, gen_flags,<br/>        num_real_attribute=1)</span></pre><p id="dd45" class="pw-post-body-paragraph jz ka it kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw im bi translated">我们需要一些额外的步骤来将生成的样本处理成序列格式，并返回1-hot编码格式的向量。</p><pre class="ne nf ng nh gt of og oh oi aw oj bi"><span id="fceb" class="nt lu it og b gy ok ol l om on">nfloat = len(continuous)<br/>synth=np.zeros(features.shape[-1])<br/>for i in range(features.shape[0]):<br/>    v = np.concatenate([np.zeros_like(attributes[i]), np.zeros_like(features[i])],axis=-1)<br/>    v[attributes[i].shape] = attributes[i]<br/>    V[attributes[i].shape[0]:attributes[i].shape[0]+1] = feature[i,:,0]<br/><br/>    for j, c in enumerate(categories_cum[:-1]):<br/>        ac = features[:,nfloat+categories_cum[j]-1:          nfloat+categories_cum[j+1]-1]<br/>        a_hot = np.zeros((ac.shape[0], categories_n[j]))    <br/>        a_hot[np.arange(ac.shape[0]),ac.argmax(axis=1)] = 1<br/>        v[:,nfloat+categories_cum[j]:nfloat+categories_cum[j+1]]=a_hot<br/>    v=np.concatenate([np.array([i]*len(ac))[np.newaxis].T,v],axis=1)<br/><br/>    synth = np.vstack([synth,v])<br/>    <br/>df = pd.DataFrame(synth[1:,1:],columns=processed_df.columns)<br/>formated_df = processor.format_df(df)<br/>formated_df['account_id']=synth[:,0] # add account_id</span></pre><p id="af26" class="pw-post-body-paragraph jz ka it kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw im bi translated">下面我们给出了合成(生成)数据和真实数据之间的一些比较。我们可以观察到，总的来说，生成的数据分布与真实分布匹配得相当好——图8和图9。</p><figure class="ne nf ng nh gt ni gh gi paragraph-image"><div role="button" tabindex="0" class="nj nk di nl bf nm"><div class="gh gi os"><img src="../Images/0397dd494613a2530812c327608c7fe9.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*lQIiKYQR-EXAFwjD"/></div></div></figure><figure class="ne nf ng nh gt ni gh gi paragraph-image"><div role="button" tabindex="0" class="nj nk di nl bf nm"><div class="gh gi ot"><img src="../Images/504372081ba0949bd8e7ceeb4b836868.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*paAZI1k5QBlHRxwG"/></div></div></figure><figure class="ne nf ng nh gt ni gh gi paragraph-image"><div role="button" tabindex="0" class="nj nk di nl bf nm"><div class="gh gi ot"><img src="../Images/9a466f60cee8f29a4b863490eea23aaa.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*Ezk2RCzA5a7EKuJD"/></div></div><figcaption class="np nq gj gh gi nr ns bd b be z dk translated"><strong class="bd lv">图8 </strong>:生成数据与实际数据的序列长度直方图(上图)事务之间的时间间隔直方图(中图)和标志直方图(下图)。</figcaption></figure><p id="b64c" class="pw-post-body-paragraph jz ka it kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw im bi translated">唯一的例外是变量<em class="mw">的分布量</em>，如图9所示。这是由于该变量具有非平滑分布的事实。为了解决这个问题，我们将其离散化为20个级别，从而得到更好的匹配。</p><figure class="ne nf ng nh gt ni gh gi paragraph-image"><div role="button" tabindex="0" class="nj nk di nl bf nm"><div class="gh gi ou"><img src="../Images/d082664b58e9ffc5416f11ef9409878f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*8Y0_X1txGA8In9oV"/></div></div></figure><figure class="ne nf ng nh gt ni gh gi paragraph-image"><div role="button" tabindex="0" class="nj nk di nl bf nm"><div class="gh gi ov"><img src="../Images/3af55fca1820fbcbb8dc0831eb8dae44.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*FcGpqLEf3pQLhTKS"/></div></div><figcaption class="np nq gj gh gi nr ns bd b be z dk translated"><strong class="bd lv">图9 </strong>:使用连续编码(上)和二进制独热编码(下)生成的实际数量与。</figcaption></figure><p id="4058" class="pw-post-body-paragraph jz ka it kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw im bi translated">然后，我们使用模糊度量来计算<strong class="kb jd">相似性得分。</strong>该分数是三个分数的平均值:直方图和histogram2D相似性(真实和合成数据直方图重叠的程度)以及列之间的互信息。该分数确定了合成数据保持列间相关性的程度。</p><p id="7f04" class="pw-post-body-paragraph jz ka it kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw im bi translated">当将<em class="mw">数量</em>视为连续变量时，我们得到的相似性得分为<strong class="kb jd"> 0.57 </strong>，当我们将其二进制化为20个箱时，我们得到的相似性得分为<strong class="kb jd"> 0.63 </strong>。相似性得分如下获得:</p><pre class="ne nf ng nh gt of og oh oi aw oj bi"><span id="630c" class="nt lu it og b gy ok ol l om on">from hazy_trainer.evaluation.similarity import Similarity<br/>sim = Similarity(metrics=['hist','hist2d','mi'])<br/>score = sim.score(real_df[cols], formated_df[cols])<br/>print(score['similarity']['score'])</span></pre><p id="3c3f" class="pw-post-body-paragraph jz ka it kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw im bi translated">然而，我们注意到，这个数字并没有真正说明全部情况，因为它没有明确地测量合成数据序列的时间一致性——它独立地处理每一行。</p><figure class="ne nf ng nh gt ni gh gi paragraph-image"><div role="button" tabindex="0" class="nj nk di nl bf nm"><div class="gh gi oq"><img src="../Images/15353070045c6b6403454d5b38c33c94.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*P_17E4mPB6bDDs-7"/></div></div><figcaption class="np nq gj gh gi nr ns bd b be z dk translated"><strong class="bd lv">图10 </strong>:一段时间内模型生成的交易量(资金进出)。</figcaption></figure><p id="edb5" class="pw-post-body-paragraph jz ka it kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw im bi translated">为此，我们使用了一个额外的关键指标:<strong class="kb jd">自相关</strong>，它衡量在时间<em class="mw"> t </em>发生的事件<em class="mw">与在</em>时间<em class="mw">t—∈</em>发生的事件<em class="mw">之间的关系，其中∈是时间延迟。为了衡量这种关系，我们用以下方式进行比较:</em></p><p id="52e6" class="pw-post-body-paragraph jz ka it kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw im bi translated">AC = I = 1T(Areali-Asynthetici)2/I = 1T(Areali)2</p><p id="2228" class="pw-post-body-paragraph jz ka it kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw im bi translated">下面是真实数据和合成数据的总支出(按天累计)的自相关图。我们可以看到两者有非常相似的模式。</p><p id="a0bd" class="pw-post-body-paragraph jz ka it kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw im bi translated">这只适用于数字数据。对于分类，我们可以使用互信息。对于我们的数据，我们得到AC = 0.71</p><figure class="ne nf ng nh gt ni gh gi paragraph-image"><div role="button" tabindex="0" class="nj nk di nl bf nm"><div class="gh gi oq"><img src="../Images/194769b38e6217b4c2ebaf49f596b8b6.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*BIrsglvsyVHuY3bB"/></div></div><figcaption class="np nq gj gh gi nr ns bd b be z dk translated"><strong class="bd lv">图11 </strong>:银行交易数据集真实数据和合成数据的自相关。</figcaption></figure><h1 id="f265" class="lt lu it bd lv lw mx ly lz ma my mc md me mz mg mh mi na mk ml mm nb mo mp mq bi translated">交通数据集</h1><p id="91d3" class="pw-post-body-paragraph jz ka it kb b kc mr ke kf kg ms ki kj kk mt km kn ko mu kq kr ks mv ku kv kw im bi translated">为了证明顺序数据生成器的能力，我们在另一个更具挑战性的数据集上测试了它:地铁州际交通量数据集。这是一个数据集，包含2012年至2018年的每小时交通数据。正如我们在接下来的图中看到的，随着时间的推移，数据相对一致，具有一些每日和每周模式以及较大的每小时可变性。源自发生器的合成数据必须再现所有这些趋势。</p><figure class="ne nf ng nh gt ni gh gi paragraph-image"><div role="button" tabindex="0" class="nj nk di nl bf nm"><div class="gh gi oq"><img src="../Images/3e0388e1b41d7ed4104ee0b2c091584e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*NHUKHZAhRlvGXTcO"/></div></div><figcaption class="np nq gj gh gi nr ns bd b be z dk translated"><strong class="bd lv">图12 </strong>:车流量直方图(每小时车流量)。</figcaption></figure><figure class="ne nf ng nh gt ni gh gi paragraph-image"><div role="button" tabindex="0" class="nj nk di nl bf nm"><div class="gh gi oq"><img src="../Images/f8dac80576f1747066381174e9d22357.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*eW2wgN79SZfG7XUH"/></div></div></figure><figure class="ne nf ng nh gt ni gh gi paragraph-image"><div role="button" tabindex="0" class="nj nk di nl bf nm"><div class="gh gi oq"><img src="../Images/99e982dbd5b74e760b47dcb043909629.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*SrWpAv94sbgVLa3s"/></div></div></figure><figure class="ne nf ng nh gt ni gh gi paragraph-image"><div role="button" tabindex="0" class="nj nk di nl bf nm"><div class="gh gi oq"><img src="../Images/8761fea7530b63ec72c9ecfd049b0e41.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*Uyy-6yll_mfsOUkC"/></div></div></figure><p id="2fbe" class="pw-post-body-paragraph jz ka it kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw im bi translated">日常模式可能相当复杂，如下图所示，包含第一个月(2012年10月)的流量:</p><figure class="ne nf ng nh gt ni gh gi paragraph-image"><div role="button" tabindex="0" class="nj nk di nl bf nm"><div class="gh gi oq"><img src="../Images/fd056e93addea24d3f7fdab5d398ff31.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*YR4nL1odlrUKC4X-"/></div></div><figcaption class="np nq gj gh gi nr ns bd b be z dk translated"><strong class="bd lv">图14</strong>:2012年10月的每小时交通模式。每一滴代表一天。在低流量模式下，周末是可见的。</figcaption></figure><p id="d495" class="pw-post-body-paragraph jz ka it kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw im bi translated">为了生成高质量的合成数据，网络必须预测正确的每日、每周、每月甚至每年的模式，因此长期相关性非常重要。</p><figure class="ne nf ng nh gt ni gh gi paragraph-image"><div role="button" tabindex="0" class="nj nk di nl bf nm"><div class="gh gi oq"><img src="../Images/e8f968341bf9dc76d0acbc302fa7a5ff.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*8DwDNtUyCtSxJwh0"/></div></div></figure><figure class="ne nf ng nh gt ni gh gi paragraph-image"><div role="button" tabindex="0" class="nj nk di nl bf nm"><div class="gh gi oq"><img src="../Images/94e8eee4cba57b1058bdc6adcf29b385.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*5RfGx1Htp0uisW3u"/></div></div></figure><figure class="ne nf ng nh gt ni gh gi paragraph-image"><div role="button" tabindex="0" class="nj nk di nl bf nm"><div class="gh gi oq"><img src="../Images/7cfd38dc55979b66f47b7c934f6046df.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*1r8E82wFtA5-uF8P"/></div></div></figure><figure class="ne nf ng nh gt ni gh gi paragraph-image"><div role="button" tabindex="0" class="nj nk di nl bf nm"><div class="gh gi ow"><img src="../Images/6ad95146fda41a384cdc12981b2941a0.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*UsPomxm_uEvCgLrz"/></div></div><figcaption class="np nq gj gh gi nr ns bd b be z dk translated"><strong class="bd lv">图15 </strong>:数据的更多分布。</figcaption></figure><p id="9427" class="pw-post-body-paragraph jz ka it kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw im bi translated">在自相关方面，我们可以看到平滑的每日相关性，这是有意义的，因为大多数流量具有对称行为。早上的高强度与晚上的高强度相关。</p><figure class="ne nf ng nh gt ni gh gi paragraph-image"><div role="button" tabindex="0" class="nj nk di nl bf nm"><div class="gh gi oq"><img src="../Images/69e5647c2f23d276f4d85a49bcfbe97a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*6DABUGGP2fOWoHZg"/></div></div><figcaption class="np nq gj gh gi nr ns bd b be z dk translated"><strong class="bd lv">图15 </strong>:真实交通数据与生成交通数据的自相关。对于较长的腿，合成数据的自相关开始偏离从真实数据获得的自相关</figcaption></figure><h1 id="ac3f" class="lt lu it bd lv lw mx ly lz ma my mc md me mz mg mh mi na mk ml mm nb mo mp mq bi translated">运行模型</h1><p id="0722" class="pw-post-body-paragraph jz ka it kb b kc mr ke kf kg ms ki kj kk mt km kn ko mu kq kr ks mv ku kv kw im bi translated">在这种情况下，序列长度是固定的。为了准备数据，我们使用每月和每周数据的滑动窗口生成了50，000个序列。这个数据集比前一个数据集大得多，我们希望模型能够平稳运行，不会出现模式崩溃。</p><p id="70ab" class="pw-post-body-paragraph jz ka it kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw im bi translated">在这种情况下，我们也有更多的属性。一些，像<em class="mw">星期几</em>和<em class="mw">月份</em>，是从数据中构建的:</p><ul class=""><li id="91b7" class="ky kz it kb b kc kd kg kh kk la ko lb ks lc kw nc le lf lg bi translated">温度</li><li id="5f9b" class="ky kz it kb b kc lh kg li kk lj ko lk ks ll kw nc le lf lg bi translated">Rain_1h</li><li id="28be" class="ky kz it kb b kc lh kg li kk lj ko lk ks ll kw nc le lf lg bi translated">Snow_1h</li><li id="c1c0" class="ky kz it kb b kc lh kg li kk lj ko lk ks ll kw nc le lf lg bi translated">云_全部</li><li id="0012" class="ky kz it kb b kc lh kg li kk lj ko lk ks ll kw nc le lf lg bi translated">天气_描述</li><li id="79ff" class="ky kz it kb b kc lh kg li kk lj ko lk ks ll kw nc le lf lg bi translated">天气_主要</li><li id="1a73" class="ky kz it kb b kc lh kg li kk lj ko lk ks ll kw nc le lf lg bi translated">假期</li><li id="e58d" class="ky kz it kb b kc lh kg li kk lj ko lk ks ll kw nc le lf lg bi translated">星期几</li><li id="da79" class="ky kz it kb b kc lh kg li kk lj ko lk ks ll kw nc le lf lg bi translated">月</li></ul><p id="ce6c" class="pw-post-body-paragraph jz ka it kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw im bi translated">作为特色，我们只有每小时的<em class="mw">流量</em>。因为我们希望以最高的粒度捕获这个变量，所以所有的数值都被离散到20个箱中，除了交通量被离散到50个箱中。该模型运行了200个时期，批次大小为20，学习速率与之前相同。</p><h1 id="ba93" class="lt lu it bd lv lw mx ly lz ma my mc md me mz mg mh mi na mk ml mm nb mo mp mq bi translated">结果</h1><p id="f848" class="pw-post-body-paragraph jz ka it kb b kc mr ke kf kg ms ki kj kk mt km kn ko mu kq kr ks mv ku kv kw im bi translated">图17包含一个真实的生成样本。我们可以看到，循环模式保持得很好，数据看起来很真实。</p><figure class="ne nf ng nh gt ni gh gi paragraph-image"><div role="button" tabindex="0" class="nj nk di nl bf nm"><div class="gh gi oq"><img src="../Images/002463812cf1831f5e07e3f102a9cac3.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*wJgPeyylYUWT9Phq"/></div></div><figcaption class="np nq gj gh gi nr ns bd b be z dk translated"><strong class="bd lv">图17</strong>:500小时内的真实(上)和生成(下)序列。这个模型是无条件运行的。我们可以看到，合成数据很好地捕捉了每日和每周的模式。</figcaption></figure><p id="dfaa" class="pw-post-body-paragraph jz ka it kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw im bi translated">为了测试生成数据的质量，我们提供了一些指标，见表2:</p><ul class=""><li id="6f84" class="ky kz it kb b kc kd kg kh kk la ko lb ks lc kw nc le lf lg bi translated"><strong class="kb jd">相似度</strong> —通过直方图的重叠和互信息来度量</li><li id="5170" class="ky kz it kb b kc lh kg li kk lj ko lk ks ll kw nc le lf lg bi translated"><strong class="kb jd">自相关</strong>——超过30个时间滞后的真实和合成之间的比率</li><li id="b43a" class="ky kz it kb b kc lh kg li kk lj ko lk ks ll kw nc le lf lg bi translated"><strong class="kb jd">效用</strong> —用真实数据和合成数据训练时预测误差的相对比率来衡量</li></ul><p id="67b1" class="pw-post-body-paragraph jz ka it kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw im bi translated">我们使用LSTM(长短期记忆)模型和自举作为基线。这个<a class="ae kx" href="https://en.wikipedia.org/wiki/Long_short-term_memory" rel="noopener ugc nofollow" target="_blank"> LSTM模型</a>由两层组成，每层100个神经元，使用30小时的滑动窗口。属性通过密集层添加，并连接到网络的最后一个隐藏层。</p><p id="4da2" class="pw-post-body-paragraph jz ka it kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw im bi translated">从表2中可以看出，用每周数据训练的dopper表现相对较好，远远超过了bootstrapping技术。</p><figure class="ne nf ng nh gt ni gh gi paragraph-image"><div role="button" tabindex="0" class="nj nk di nl bf nm"><div class="gh gi ox"><img src="../Images/43988895435ccc020f4ebeb43b912685.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*vLIgsrS8IBZvqOpKj6yTEw.png"/></div></div><figcaption class="np nq gj gh gi nr ns bd b be z dk translated">表2:流量数据集的结果。</figcaption></figure><p id="3e49" class="pw-post-body-paragraph jz ka it kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw im bi translated">我们添加了第三个度量标准，即<strong class="kb jd">顺序互信息</strong> (SMI)。它在包含<em class="mw"> T </em>列的矩阵上评估交互信息，其中每一列对应于之前T、t-1、t-2、… t-T时间步发生的事件，并在属性子集上求平均。</p><p id="06ec" class="pw-post-body-paragraph jz ka it kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw im bi translated">我们应该注意到，模型可以以属性为条件，因此我们可以为特定的天气条件或一周或一月中的某一天生成样本。</p><h1 id="cda3" class="lt lu it bd lv lw mx ly lz ma my mc md me mz mg mh mi na mk ml mm nb mo mp mq bi translated">差分隐私实验</h1><p id="5469" class="pw-post-body-paragraph jz ka it kb b kc mr ke kf kg ms ki kj kk mt km kn ko mu kq kr ks mv ku kv kw im bi translated">在最初的工作中，作者通过向鉴别器添加噪声并剪裁其梯度的众所周知的技术——DPGAN,在模型中引入了差分隐私。</p><p id="2516" class="pw-post-body-paragraph jz ka it kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw im bi translated">然而，他们发现，一旦隐私预算ε变得相对较小——这意味着合成数据变得更安全，它也开始失去质量——通过相对于真实数据的时间一致性来衡量。如果数据的最终用途是提取详细的时间信息，如事件之间的因果关系，这可能是一个大问题。</p><p id="3413" class="pw-post-body-paragraph jz ka it kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw im bi translated">基于<a class="ae kx" href="https://arxiv.org/pdf/1910.02007.pdf" rel="noopener ugc nofollow" target="_blank">最近围绕PPGAN </a>(隐私保护生成对抗网络)的工作，我们对注入鉴别器梯度的噪声进行了一些修改。<a class="ae kx" href="https://arxiv.org/pdf/1607.00133.pdf" rel="noopener ugc nofollow" target="_blank">矩的会计师</a>将隐私损失问题框定为一个随机变量，使用其矩生成函数来控制变量的密度分布。这个性质使得PPGAN模型训练更加稳定。当产生非常长的序列时，与DPGAN的差异尤其显著。</p><p id="9aae" class="pw-post-body-paragraph jz ka it kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw im bi translated">噪声由下式给出:</p><p id="21c8" class="pw-post-body-paragraph jz ka it kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw im bi translated">ɸ=f+N(0,σ2𝜍f2)</p><p id="763e" class="pw-post-body-paragraph jz ka it kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw im bi translated">其中𝞷是对来自两个相邻点<em class="mw"> x </em>和<em class="mw"> x </em>的查询<em class="mw"> f </em>的敏感度:</p><p id="3798" class="pw-post-body-paragraph jz ka it kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw im bi translated">△f = maxf(x)-f(x’)2</p><p id="07a0" class="pw-post-body-paragraph jz ka it kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw im bi translated">该表达式意味着，最具信息性的点(最高灵敏度)会将更多的噪声添加到渐变中，因此不会影响其他点的质量。通过使用这种精心设计的噪声，我们能够在流量数据上保持88%的自相关，直到ε = 1。</p><h1 id="2c39" class="lt lu it bd lv lw mx ly lz ma my mc md me mz mg mh mi na mk ml mm nb mo mp mq bi translated">结论</h1><p id="fda0" class="pw-post-body-paragraph jz ka it kb b kc mr ke kf kg ms ki kj kk mt km kn ko mu kq kr ks mv ku kv kw im bi translated">合成顺序数据生成是一个尚未完全解决的具有挑战性的问题。通过上述测试，我们证明了GANs是解决这一问题的有效方法。<br/>请访问Hazy网站，了解<a class="ae kx" href="https://hazy.com/blog/2020/07/09/how-to-generate-sequential-data" rel="noopener ugc nofollow" target="_blank">合成时序数据</a>的业务用例</p></div></div>    
</body>
</html>