<html>
<head>
<title>Difference between Bag of Words (BOW) and TF-IDF in NLP with Python</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">使用Python的NLP中单词包(BOW)和TF-IDF的区别</h1>
<blockquote>原文：<a href="https://pub.towardsai.net/difference-between-bag-of-words-bow-and-tf-idf-in-nlp-with-python-97d3e75a9fd?source=collection_archive---------0-----------------------#2022-01-06">https://pub.towardsai.net/difference-between-bag-of-words-bow-and-tf-idf-in-nlp-with-python-97d3e75a9fd?source=collection_archive---------0-----------------------#2022-01-06</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><h2 id="e8a2" class="ir is it bd b dl iu iv iw ix iy iz dk ja translated" aria-label="kicker paragraph"><a class="ae ep" href="https://towardsai.net/p/category/nlp" rel="noopener ugc nofollow" target="_blank">自然语言处理</a></h2><div class=""/><div class=""><h2 id="ca98" class="pw-subtitle-paragraph jz jc it bd b ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq dk translated">单词被转换成矢量或数字</h2></div><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi kr"><img src="../Images/2cf6347ca4f6a8fb570361745b2d2799.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*AAHiVLZuW7Dlv-Ad"/></div></div><figcaption class="ld le gj gh gi lf lg bd b be z dk translated"><a class="ae lh" href="https://unsplash.com/@seffen99?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">斯文·布兰德斯马</a>在<a class="ae lh" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上的照片</figcaption></figure><p id="64d1" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">这两个主题可以用作单词嵌入，其中单词被转换成向量或数字，即稀疏矩阵。稀疏矩阵或稀疏阵列是包含更多数量的0和更少数量的1的矩阵，即更多数量的0。</p><p id="5fe2" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">在本文中，我们将研究自然语言处理的两个概念，其中高维的单词被转换为低维的向量或数字，以便于机器学习过程。</p><ul class=""><li id="dcc1" class="me mf it lk b ll lm lo lp lr mg lv mh lz mi md mj mk ml mm bi translated">将单词转换成没有语义信息的数字。</li><li id="9d83" class="me mf it lk b ll mn lo mo lr mp lv mq lz mr md mj mk ml mm bi translated">TF-IDF:它也将单词转换成带有一些加权信息的数字或向量。</li></ul><p id="837f" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">当我们使用机器学习算法时，它们需要输入特定格式的数字，而处理文本有点困难，将文本转换为数字可以挽救生命。</p><blockquote class="ms mt mu"><p id="5e1a" class="li lj mv lk b ll lm kd ln lo lp kg lq mw ls lt lu mx lw lx ly my ma mb mc md im bi translated"><strong class="lk jd"> <em class="it">包单词(BOW)或计数矢量器</em> </strong></p></blockquote><p id="aee5" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">它用于从单词/短语中检索向量或数字形式的信息。这在一定程度上解决了自然语言处理中的分类问题。</p><p id="b595" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">单词包的工作功能是统计单词在短语中的出现次数，而不考虑语义信息，并且不知道单词在短语或文档中的位置。概念的把握和执行是非常容易的。</p><p id="0bf5" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">示例:</p><p id="b3fe" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">你很强壮。</p><p id="ecfa" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">通过使用一个单词包，它转换成矢量，如下所示:</p><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div class="gh gi mz"><img src="../Images/a419b30e044d48f76d42ff217ad5eb15.png" data-original-src="https://miro.medium.com/v2/resize:fit:1276/format:webp/1*0387nkiXgNJNmYfe6G0wTA.png"/></div><figcaption class="ld le gj gh gi lf lg bd b be z dk translated">作者的照片</figcaption></figure><p id="d28a" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">你很勇敢。</p><p id="9cf2" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">通过使用一个单词包，它转换成矢量，如下所示:</p><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div class="gh gi na"><img src="../Images/d248967a264c08093bc2713b106c24e7.png" data-original-src="https://miro.medium.com/v2/resize:fit:1278/format:webp/1*VDbWmT0KECCJQzRAQhWASw.png"/></div><figcaption class="ld le gj gh gi lf lg bd b be z dk translated">作者的照片</figcaption></figure><p id="6fee" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">做一袋字模</p><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div class="gh gi na"><img src="../Images/1521ba4ab90b6aa40861c3caf57caeba.png" data-original-src="https://miro.medium.com/v2/resize:fit:1278/format:webp/1*f_pfHT6pbWBMb9SP5XqPhw.png"/></div><figcaption class="ld le gj gh gi lf lg bd b be z dk translated">作者的照片</figcaption></figure><h2 id="0d13" class="nb nc it bd nd ne nf dn ng nh ni dp nj lr nk nl nm lv nn no np lz nq nr ns iz bi translated"><strong class="ak">单词包的Python示例</strong></h2><pre class="ks kt ku kv gt nt nu nv nw aw nx bi"><span id="3a1d" class="nb nc it nu b gy ny nz l oa ob">#Two sentences to implement BOW<br/>S1="You are very strong"<br/>S2="You are very brave"</span><span id="ed25" class="nb nc it nu b gy oc nz l oa ob">Corpus= [D1,D2]<br/>Corpus</span><span id="e1f8" class="nb nc it nu b gy oc nz l oa ob">#Output:<br/>['You are very strong', 'You are very brave']</span><span id="99b1" class="nb nc it nu b gy oc nz l oa ob">#importing the libraries<br/>import pandas as pd<br/>from sklearn.feature_extraction.text import CountVectorizer</span></pre><p id="541d" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">我们使用一个单词包，即sklearn库中的计数矢量器类，来从句子中提取特征。</p><pre class="ks kt ku kv gt nt nu nv nw aw nx bi"><span id="2016" class="nb nc it nu b gy ny nz l oa ob">#now creating an object of count vectorizer<br/>cv = CountVectorizer()</span></pre><p id="1089" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">它被用来计算这个词在句子中出现的频率。</p><pre class="ks kt ku kv gt nt nu nv nw aw nx bi"><span id="ea77" class="nb nc it nu b gy ny nz l oa ob">#using fit_transform to make the words into sparse array<br/>X = cv.fit_transform(Corpus).toarray()</span><span id="760f" class="nb nc it nu b gy oc nz l oa ob">#getting the features names i.e. words of the document of corpus<br/>print(cv.get_feature_names())</span><span id="4165" class="nb nc it nu b gy oc nz l oa ob">#output:<br/>['are', 'brave', 'strong', 'very', 'you']</span><span id="df5a" class="nb nc it nu b gy oc nz l oa ob">#making a dataframe of bag of words<br/>print("BOW Matrix:-")<br/>pd.DataFrame(X, columns=cv.get_feature_names())</span><span id="e109" class="nb nc it nu b gy oc nz l oa ob">#output:<br/>BOW Matrix:-</span></pre><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div class="gh gi od"><img src="../Images/a3e28b17d42c0f7f21f09d0950c9edf8.png" data-original-src="https://miro.medium.com/v2/resize:fit:466/format:webp/1*M80ZGZyMKN-IzeDIwvpEYA.png"/></div><figcaption class="ld le gj gh gi lf lg bd b be z dk translated">作者的照片</figcaption></figure><p id="611d" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">在一袋单词中，数字被赋予每个单词，并赋予所有单词以重要性。为了克服这一点，我们使用TF-IDF模型。</p><div class="oe of gp gr og oh"><a rel="noopener  ugc nofollow" target="_blank" href="/web-scraping-movie-data-with-beautiful-soup-library-in-python-b51ae9206ea8"><div class="oi ab fo"><div class="oj ab ok cl cj ol"><h2 class="bd jd gy z fp om fr fs on fu fw jc bi translated">用python中漂亮的汤库进行电影数据的Web抓取</h2><div class="oo l"><h3 class="bd b gy z fp om fr fs on fu fw dk translated">从电影网站提取数据</h3></div><div class="op l"><p class="bd b dl z fp om fr fs on fu fw dk translated">pub.towardsai.net</p></div></div><div class="oq l"><div class="or l os ot ou oq ov lb oh"/></div></div></a></div><div class="oe of gp gr og oh"><a href="https://medium.com/pythoneers/forget-html-and-flask-start-using-streamlit-1b394cfe4595" rel="noopener follow" target="_blank"><div class="oi ab fo"><div class="oj ab ok cl cj ol"><h2 class="bd jd gy z fp om fr fs on fu fw jc bi translated">忘记HTML和Flask，开始使用Streamlit</h2><div class="oo l"><h3 class="bd b gy z fp om fr fs on fu fw dk translated">数据科学和机器学习的WebApp框架</h3></div><div class="op l"><p class="bd b dl z fp om fr fs on fu fw dk translated">medium.com</p></div></div><div class="oq l"><div class="ow l os ot ou oq ov lb oh"/></div></div></a></div><blockquote class="ms mt mu"><p id="770d" class="li lj mv lk b ll lm kd ln lo lp kg lq mw ls lt lu mx lw lx ly my ma mb mc md im bi translated"><strong class="lk jd"> <em class="it">词频和逆文档频(TF-IDF) </em> </strong></p></blockquote><p id="721a" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">在该模型中，通过给予不常用词比常用词更高的重要性来收集一些语义信息。</p><p id="e190" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">IDF一词意味着对文档中的生僻字赋予更高的权重。</p><pre class="ks kt ku kv gt nt nu nv nw aw nx bi"><span id="587c" class="nb nc it nu b gy ny nz l oa ob">TF-IDF = TF*IDF</span></pre><p id="34ff" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">示例:</p><p id="4f24" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">你很强壮。</p><p id="766c" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">通过使用一袋单词，它转换成重量，如下所示:</p><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div class="gh gi ox"><img src="../Images/8b3ea65f26620bad4647585be31f90a9.png" data-original-src="https://miro.medium.com/v2/resize:fit:1272/format:webp/1*c1tjUevPqvKiRHRk9710ZQ.png"/></div><figcaption class="ld le gj gh gi lf lg bd b be z dk translated">作者的照片</figcaption></figure><p id="980a" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">根据句子中总单词的出现次数为单词分配权重。</p><p id="2e72" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated"><strong class="lk jd">句子2: </strong>你很勇敢。</p><p id="2b8e" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">通过使用单词包，它转换为如下所示的权重:</p><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div class="gh gi oy"><img src="../Images/a5719a15a625bb893139f473f48e9830.png" data-original-src="https://miro.medium.com/v2/resize:fit:1270/format:webp/1*eXhIUR9uxkor-pVV7cqm7w.png"/></div><figcaption class="ld le gj gh gi lf lg bd b be z dk translated">作者的照片</figcaption></figure><p id="f3be" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">做一袋字模</p><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div class="gh gi oz"><img src="../Images/5553c229141cc2041cae0d14e361c464.png" data-original-src="https://miro.medium.com/v2/resize:fit:1280/format:webp/1*80OclUcoFFkkWUjOXZQq6w.png"/></div><figcaption class="ld le gj gh gi lf lg bd b be z dk translated">作者的照片</figcaption></figure><p id="28d5" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">在上面的例子中，不常用词的权重较大，常用词的权重较小。</p><h2 id="5a16" class="nb nc it bd nd ne nf dn ng nh ni dp nj lr nk nl nm lv nn no np lz nq nr ns iz bi translated"><strong class="ak">TF-IDF中的术语</strong></h2><ul class=""><li id="f89d" class="me mf it lk b ll pa lo pb lr pc lv pd lz pe md mj mk ml mm bi translated">文档频率:文档频率告诉我们一个单词在整个句子集合中出现的频率，这个信息是全局的，不特定于任何一个句子。</li></ul><p id="26c0" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">DF =包含给定术语的文档数量(D)/语料库中的文档总数(D)</p><p id="6190" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">举个例子:我们取上面两个句子，强词出现在一个句子中，两个是语料库中的文档总数。</p><p id="a31c" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">DF = = 0.5</p><p id="342d" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">但是，D大于D，在这种情况下，log(d/D)给出一个负值。为了克服这个负值，研究人员颠倒了对数表达式中的比率。因此，log(D/d)被称为逆文档频率。</p><ul class=""><li id="8179" class="me mf it lk b ll lm lo lp lr mg lv mh lz mi md mj mk ml mm bi translated">在IDF中使用log来抑制比率的影响(压缩数值的标度，以便可以容易地比较大数量和小数量)。</li><li id="c09b" class="me mf it lk b ll mn lo mo lr mp lv mq lz mr md mj mk ml mm bi translated">使用对数函数是因为得分函数是相加的，并且各项是独立的。</li></ul><p id="493f" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">TF中有许多权重方案，如下所示:</p><ul class=""><li id="e4d1" class="me mf it lk b ll lm lo lp lr mg lv mh lz mi md mj mk ml mm bi translated">二进制、原始计数、术语频率、对数归一化等。</li></ul><p id="7af0" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">IDF中有许多重量方案，如下所示:</p><ul class=""><li id="2277" class="me mf it lk b ll lm lo lp lr mg lv mh lz mi md mj mk ml mm bi translated">一元，逆文档频率(IDF)，IDF-平滑，IDF-最大，概率-IDF</li></ul><p id="50da" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">两种类型的TF-IDF方法是TfidfTransformer和TfidfVectorizer</p><ol class=""><li id="aa35" class="me mf it lk b ll lm lo lp lr mg lv mh lz mi md pf mk ml mm bi translated">TfidfTransformer:它接受一包单词作为输入</li><li id="c54f" class="me mf it lk b ll mn lo mo lr mp lv mq lz mr md pf mk ml mm bi translated">tfidf矢量器</li></ol><ul class=""><li id="5256" class="me mf it lk b ll lm lo lp lr mg lv mh lz mi md mj mk ml mm bi translated">它将文档/语料库作为输入</li><li id="6824" class="me mf it lk b ll mn lo mo lr mp lv mq lz mr md mj mk ml mm bi translated">它在sklearn函数中有更多的选项，如标记化、n-grams、停用词等。</li></ul><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div class="gh gi pg"><img src="../Images/0c6870e016357897d1cc0b31faa07448.png" data-original-src="https://miro.medium.com/v2/resize:fit:508/format:webp/1*RxdMbU--xrtVtFGSY4dxVA.png"/></div><figcaption class="ld le gj gh gi lf lg bd b be z dk translated">作者的照片</figcaption></figure><h2 id="0e33" class="nb nc it bd nd ne nf dn ng nh ni dp nj lr nk nl nm lv nn no np lz nq nr ns iz bi translated"><strong class="ak">TF-IDF的Python例子</strong></h2><ul class=""><li id="6247" class="me mf it lk b ll pa lo pb lr pc lv pd lz pe md mj mk ml mm bi translated">使用TF_IDF转换器方法</li></ul><pre class="ks kt ku kv gt nt nu nv nw aw nx bi"><span id="8990" class="nb nc it nu b gy ny nz l oa ob">#import the method from the sklearn library<br/>from sklearn.feature_extraction.text import TfidfTransformer</span><span id="3f5c" class="nb nc it nu b gy oc nz l oa ob">#create object of TfidfTransformer methos and do fit_transform<br/>cv_tfidf = TfidfTransformer(smooth_idf=True,norm=None)</span><span id="c8f6" class="nb nc it nu b gy oc nz l oa ob">X_tfidf = cv_tfidf.fit_transform(X).toarray()<br/>pd.DataFrame(X_tfidf, columns=cv.get_feature_names())</span><span id="ea55" class="nb nc it nu b gy oc nz l oa ob">#output:</span></pre><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div class="gh gi ph"><img src="../Images/821c0417ff3ff20847f14dedeacccff1.png" data-original-src="https://miro.medium.com/v2/resize:fit:520/format:webp/1*1cl1FjWvWIyftdYWw6u2lw.png"/></div><figcaption class="ld le gj gh gi lf lg bd b be z dk translated">作者的照片</figcaption></figure><ul class=""><li id="f0fd" class="me mf it lk b ll lm lo lp lr mg lv mh lz mi md mj mk ml mm bi translated">使用TF_IDF矢量器方法</li></ul><pre class="ks kt ku kv gt nt nu nv nw aw nx bi"><span id="667b" class="nb nc it nu b gy ny nz l oa ob">#import the method from the sklearn library<br/>from sklearn.feature_extraction.text import TfidfVectorizer</span><span id="22ba" class="nb nc it nu b gy oc nz l oa ob">#create object of Tfidf Vectorizer methos and do fit_transform<br/>cv_tfidf = TfidfVectorizer(smooth_idf=False,norm=None)</span><span id="8657" class="nb nc it nu b gy oc nz l oa ob">X_tfidf = cv_tfidf.fit_transform(Corpus).toarray()<br/>pd.DataFrame(X_tfidf, columns=cv_tfidf.get_feature_names())</span><span id="891d" class="nb nc it nu b gy oc nz l oa ob">#output:</span></pre><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div class="gh gi ph"><img src="../Images/821c0417ff3ff20847f14dedeacccff1.png" data-original-src="https://miro.medium.com/v2/resize:fit:520/format:webp/1*1cl1FjWvWIyftdYWw6u2lw.png"/></div><figcaption class="ld le gj gh gi lf lg bd b be z dk translated">作者的照片</figcaption></figure><blockquote class="ms mt mu"><p id="13a7" class="li lj mv lk b ll lm kd ln lo lp kg lq mw ls lt lu mx lw lx ly my ma mb mc md im bi translated"><strong class="lk jd"> <em class="it">结论</em> </strong></p></blockquote><p id="2d4f" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">本文简要介绍了词向量的基本模型。</p><p id="4f30" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">我希望你喜欢这篇文章。通过我的<a class="ae lh" href="https://www.linkedin.com/in/data-scientist-95040a1ab/" rel="noopener ugc nofollow" target="_blank"> LinkedIn </a>和<a class="ae lh" href="https://twitter.com/amitprius" rel="noopener ugc nofollow" target="_blank"> twitter </a>联系我。</p><h1 id="f78e" class="pi nc it bd nd pj pk pl ng pm pn po nj ki pp kj nm kl pq km np ko pr kp ns ps bi translated">推荐文章</h1><pre class="ks kt ku kv gt nt nu nv nw aw nx bi"><span id="c587" class="nb nc it nu b gy ny nz l oa ob">1. <a class="ae lh" href="https://medium.com/towards-artificial-intelligence/nlp-zero-to-hero-with-python-2df6fcebff6e?sk=2231d868766e96b13d1e9d7db6064df1" rel="noopener">NLP — Zero to Hero with Python</a><br/>2. <a class="ae lh" href="https://medium.com/towards-artificial-intelligence/python-data-structures-data-types-and-objects-244d0a86c3cf?sk=42f4b462499f3fc3a160b21e2c94dba6" rel="noopener">Python Data Structures Data-types and Objects</a><br/>3. <a class="ae lh" href="https://medium.com/towards-artificial-intelligence/python-zero-to-hero-with-examples-c7a5dedb968b?source=friends_link&amp;sk=186aff630c2241aca16522241333e3e0" rel="noopener">Python: Zero to Hero with Examples</a><br/>4. <a class="ae lh" href="https://medium.com/towards-artificial-intelligence/fully-explained-svm-classification-with-python-eda124997bcd?source=friends_link&amp;sk=da300d557992d67808746ee706269b2f" rel="noopener">Fully Explained SVM Classification with Python</a><br/>5. <a class="ae lh" href="https://medium.com/towards-artificial-intelligence/fully-explained-k-means-clustering-with-python-e7caa573176a?source=friends_link&amp;sk=9c5c613ceb10f2d203712634f3b6fb28" rel="noopener">Fully Explained K-means Clustering with Python</a><br/>6. <a class="ae lh" href="https://medium.com/towards-artificial-intelligence/fully-explained-linear-regression-with-python-fe2b313f32f3?source=friends_link&amp;sk=53c91a2a51347ec2d93f8222c0e06402" rel="noopener">Fully Explained Linear Regression with Python</a><br/>7. <a class="ae lh" href="https://medium.com/towards-artificial-intelligence/fully-explained-logistic-regression-with-python-f4a16413ddcd?source=friends_link&amp;sk=528181f15a44e48ea38fdd9579241a78" rel="noopener">Fully Explained Logistic Regression with Python</a><br/>8. <a class="ae lh" href="https://medium.com/towards-artificial-intelligence/basic-of-time-series-with-python-a2f7cb451a76?source=friends_link&amp;sk=09d77be2d6b8779973e41ab54ebcf6c5" rel="noopener">Basics of Time Series with Python</a><br/>9. <a class="ae lh" href="https://medium.com/towards-artificial-intelligence/numpy-zero-to-hero-with-python-d135f57d6082?source=friends_link&amp;sk=45c0921423cdcca2f5772f5a5c1568f1" rel="noopener">NumPy: Zero to Hero with Python</a><br/>10.<a class="ae lh" href="https://medium.com/analytics-vidhya/confusion-matrix-in-machine-learning-91b6e2b3f9af?source=friends_link&amp;sk=11c6531da0bab7b504d518d02746d4cc" rel="noopener">Confusion Matrix in Machine Learning</a></span></pre></div></div>    
</body>
</html>