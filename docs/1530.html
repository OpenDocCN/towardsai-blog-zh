<html>
<head>
<title>Speech to Text with Wav2Vec 2.0</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">使用Wav2Vec 2.0进行语音转文本</h1>
<blockquote>原文：<a href="https://pub.towardsai.net/speech-to-text-with-wav2vec-2-0-b21c1e1ad701?source=collection_archive---------1-----------------------#2021-02-13">https://pub.towardsai.net/speech-to-text-with-wav2vec-2-0-b21c1e1ad701?source=collection_archive---------1-----------------------#2021-02-13</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><figure class="is it gp gr iu iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi ir"><img src="../Images/99d0420c25f6f347e3023363a78fc065.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*WT8muwIjafIspee-DrX0sQ.png"/></div></div><figcaption class="jc jd gj gh gi je jf bd b be z dk translated">图片由<a class="ae jg" href="https://pixabay.com/users/temperatesage-13030917/?utm_source=link-attribution&amp;utm_medium=referral&amp;utm_campaign=image&amp;utm_content=4335953" rel="noopener ugc nofollow" target="_blank"> Harmony Lawrence </a>来自<a class="ae jg" href="https://pixabay.com/?utm_source=link-attribution&amp;utm_medium=referral&amp;utm_campaign=image&amp;utm_content=4335953" rel="noopener ugc nofollow" target="_blank"> Pixabay </a></figcaption></figure><h2 id="0442" class="jh ji jj bd b dl jk jl jm jn jo jp dk jq translated" aria-label="kicker paragraph"><a class="ae ep" href="https://towardsai.net/p/category/nlp" rel="noopener ugc nofollow" target="_blank">自然语言处理</a></h2><div class=""/><div class=""><h2 id="27a7" class="pw-subtitle-paragraph kp js jj bd b kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg dk translated">语音转文本</h2></div><p id="a240" class="pw-post-body-paragraph lh li jj lj b lk ll kt lm ln lo kw lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">在我之前的博客中，我解释了如何在谷歌语音识别API的帮助下，使用语音识别库将语音转换为文本。在这篇博客中，我们看到了如何使用脸书Wav2Vec 2.0模型将语音转换成文本。</p><p id="f490" class="pw-post-body-paragraph lh li jj lj b lk ll kt lm ln lo kw lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated"><a class="ae jg" href="https://ai.facebook.com/blog/wav2vec-20-learning-the-structure-of-speech-from-raw-audio" rel="noopener ugc nofollow" target="_blank">脸书</a>最近推出并<a class="ae jg" href="https://ai.facebook.com/blog/wav2vec-20-learning-the-structure-of-speech-from-raw-audio" rel="noopener ugc nofollow" target="_blank">开源了他们的新框架</a>，用于从原始音频数据进行自我监督学习，称为Wav2vec 2.0。脸书的研究人员声称，这个框架只需要10分钟的转录语音数据就可以实现自动语音识别模型。</p><p id="15e2" class="pw-post-body-paragraph lh li jj lj b lk ll kt lm ln lo kw lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">众所周知，变形金刚在自然语言处理中起着主要作用。拥抱脸变形金刚的最新版本是4.30版本，它带有Wav2Vec 2.0。这是变形金刚中包含的第一个自动语音识别语音模型。</p><p id="56a7" class="pw-post-body-paragraph lh li jj lj b lk ll kt lm ln lo kw lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">模型架构超出了这篇博客的范围。详细的Wav2Vec模型架构，请查看<a class="ae jg" href="https://ai.facebook.com/blog/wav2vec-20-learning-the-structure-of-speech-from-raw-audio/" rel="noopener ugc nofollow" target="_blank">此处</a>。</p><p id="26ac" class="pw-post-body-paragraph lh li jj lj b lk ll kt lm ln lo kw lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">让我们看看如何通过一行简单的代码使用拥抱面部变形器将音频文件转换成文本。</p></div><div class="ab cl md me hx mf" role="separator"><span class="mg bw bk mh mi mj"/><span class="mg bw bk mh mi mj"/><span class="mg bw bk mh mi"/></div><div class="im in io ip iq"><h1 id="aa8f" class="mk ml jj bd mm mn mo mp mq mr ms mt mu ky mv kz mw lb mx lc my le mz lf na nb bi translated">安装转换器库</h1><figure class="nc nd ne nf gt iv"><div class="bz fp l di"><div class="ng nh l"/></div></figure><h1 id="e22f" class="mk ml jj bd mm mn ni mp mq mr nj mt mu ky nk kz mw lb nl lc my le nm lf na nb bi translated">导入必要的库</h1><figure class="nc nd ne nf gt iv"><div class="bz fp l di"><div class="ng nh l"/></div></figure><p id="bbc1" class="pw-post-body-paragraph lh li jj lj b lk ll kt lm ln lo kw lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">Wav2Vec2是一种语音模型，它接受与语音信号的原始波形相对应的浮点数组。Wav2Vec2模型使用连接主义时间分类(CTC)进行训练，因此模型输出必须使用wav2 vec 2 tokenizer(<a class="ae jg" href="https://huggingface.co/transformers/model_doc/wav2vec2.html" rel="noopener ugc nofollow" target="_blank">Ref:Hugging Face)</a>进行解码</p><h1 id="71b9" class="mk ml jj bd mm mn ni mp mq mr nj mt mu ky nk kz mw lb nl lc my le nm lf na nb bi translated">读取音频文件</h1><p id="a1a5" class="pw-post-body-paragraph lh li jj lj b lk nn kt lm ln no kw lp lq np ls lt lu nq lw lx ly nr ma mb mc im bi translated">在这个例子中，我使用了连姆·尼森著名的电影《捉迷藏》中的对话音频片段，它说<em class="ns">“我会去找你，我会找到你，我会杀了你”</em></p><figure class="nc nd ne nf gt iv"><div class="bz fp l di"><div class="ng nh l"/></div></figure><p id="5b19" class="pw-post-body-paragraph lh li jj lj b lk ll kt lm ln lo kw lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">请注意，Wav2Vec模型是在16 kHz频率上预先训练的，因此我们确保我们的原始音频文件也以16 kHz的采样率重新采样。我已经使用在线<a class="ae jg" href="https://audio.online-convert.com/convert-to-wav" rel="noopener ugc nofollow" target="_blank">音频工具转换</a>将“拍摄”的音频剪辑重新采样为16kHz。</p><p id="69ca" class="pw-post-body-paragraph lh li jj lj b lk ll kt lm ln lo kw lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">使用librosa库加载音频文件，并提及我的音频剪辑大小为16000 Hz。它将音频剪辑转换成一个数组，并存储在“音频”变量中。</p><figure class="nc nd ne nf gt iv"><div class="bz fp l di"><div class="ng nh l"/></div></figure><figure class="nc nd ne nf gt iv"><div class="bz fp l di"><div class="ng nh l"/></div></figure><figure class="nc nd ne nf gt iv"><div class="bz fp l di"><div class="ng nh l"/></div></figure><h1 id="b31d" class="mk ml jj bd mm mn ni mp mq mr nj mt mu ky nk kz mw lb nl lc my le nm lf na nb bi translated">导入预训练的Wav2Vec模型</h1><figure class="nc nd ne nf gt iv"><div class="bz fp l di"><div class="ng nh l"/></div></figure><p id="c7f1" class="pw-post-body-paragraph lh li jj lj b lk ll kt lm ln lo kw lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">下一步是获取输入值。将音频(数组)传递给tokenizer，我们希望张量转换成PyTorch格式，而不是python整数。提到的return_tensors = "pt "无非就是PyTorch格式。</p><figure class="nc nd ne nf gt iv"><div class="bz fp l di"><div class="ng nh l"/></div></figure><p id="d379" class="pw-post-body-paragraph lh li jj lj b lk ll kt lm ln lo kw lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">获取logit值(非标准化值)</p><figure class="nc nd ne nf gt iv"><div class="bz fp l di"><div class="ng nh l"/></div></figure><p id="8e86" class="pw-post-body-paragraph lh li jj lj b lk ll kt lm ln lo kw lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">将logit值传递给softmax以获得预测值</p><figure class="nc nd ne nf gt iv"><div class="bz fp l di"><div class="ng nh l"/></div></figure><h1 id="4937" class="mk ml jj bd mm mn ni mp mq mr nj mt mu ky nk kz mw lb nl lc my le nm lf na nb bi translated">将音频转换为文本</h1><p id="5967" class="pw-post-body-paragraph lh li jj lj b lk nn kt lm ln no kw lp lq np ls lt lu nq lw lx ly nr ma mb mc im bi translated">最后一步是将预测传递给记号赋予器解码以获得转录</p><figure class="nc nd ne nf gt iv"><div class="bz fp l di"><div class="ng nh l"/></div></figure><figure class="nc nd ne nf gt iv"><div class="bz fp l di"><div class="ng nh l"/></div></figure><p id="a33c" class="pw-post-body-paragraph lh li jj lj b lk ll kt lm ln lo kw lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">它能准确读出我们的音频片段。</p><p id="0fc9" class="pw-post-body-paragraph lh li jj lj b lk ll kt lm ln lo kw lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">在这篇博客中，我们看到了如何使用Wav2Vec pretraining model使用transformers将语音转换为文本。这对NLP项目非常有帮助，尤其是处理音频文本数据。如果你有什么要补充的，欢迎随时留言评论！</p><p id="1b5d" class="pw-post-body-paragraph lh li jj lj b lk ll kt lm ln lo kw lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">你可以在我的<a class="ae jg" href="https://github.com/sdhilip200/speech-to-text" rel="noopener ugc nofollow" target="_blank"> GitHub repo中找到完整的代码和数据。</a></p><p id="70e3" class="pw-post-body-paragraph lh li jj lj b lk ll kt lm ln lo kw lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">感谢阅读。请继续学习，并关注更多内容！</p><h1 id="674e" class="mk ml jj bd mm mn ni mp mq mr nj mt mu ky nk kz mw lb nl lc my le nm lf na nb bi translated">参考</h1><ol class=""><li id="6dc1" class="nt nu jj lj b lk nn ln no lq nv lu nw ly nx mc ny nz oa ob bi translated"><a class="ae jg" href="https://huggingface.co/transformers/model_doc/wav2vec2.html" rel="noopener ugc nofollow" target="_blank">https://huggingface.co/transformers/model_doc/wav2vec2.html</a></li><li id="896b" class="nt nu jj lj b lk oc ln od lq oe lu of ly og mc ny nz oa ob bi translated"><a class="ae jg" href="https://ai.facebook.com/blog/wav2vec-20-learning-the-structure-of-speech-from-raw-audio/" rel="noopener ugc nofollow" target="_blank">https://ai . Facebook . com/blog/wav2 vec-20-从原始音频中学习语音结构/ </a></li></ol></div></div>    
</body>
</html>