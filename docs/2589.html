<html>
<head>
<title>Logistic Regression for Binary Classification: Hands-On with SciKit-Learn</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">二元分类的逻辑回归:SciKit-Learn实践</h1>
<blockquote>原文：<a href="https://pub.towardsai.net/logistic-regression-for-binary-classification-hands-on-with-scikit-learn-a5c06b0f2d60?source=collection_archive---------0-----------------------#2022-03-02">https://pub.towardsai.net/logistic-regression-for-binary-classification-hands-on-with-scikit-learn-a5c06b0f2d60?source=collection_archive---------0-----------------------#2022-03-02</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="f5c7" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">使用Python和Google Colab</h2></div><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ki"><img src="../Images/1db7a0f317276bd588d7d06b6408b97e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*scU0cYZGyHBlBIuc-i3VFw.png"/></div></div></figure><pre class="kj kk kl km gt ku kv kw kx aw ky bi"><span id="01f7" class="kz la it kv b gy lb lc l ld le"><strong class="kv iu"><em class="lf">Table of contents:</em></strong></span><span id="abff" class="kz la it kv b gy lg lc l ld le"><em class="lf">1. Introduction<br/>2. What type of problems can be solved with Logistic Regression<br/>3. Mathematical Interpretation<br/>4. The C parameter<br/>5. Hands-On:</em><strong class="kv iu"><br/>  </strong> -Import Libraries<strong class="kv iu"><br/>   </strong>-Create Data<br/>   -Exploratory data analysis<br/>   -Splitting data into train and test data sets<br/>   -Build and evaluate the model<br/>   -Finding the best C value<br/>   -Build a visualisation for the model</span></pre><p id="3711" class="pw-post-body-paragraph lh li it lj b lk ll ju lm ln lo jx lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">当主题是机器学习时，逻辑回归是你会读到、听到的第一批算法之一。逻辑回归类似于多元回归，但有一个二元(因变量)输出变量和连续或分类预测变量。当因变量为二元(1或0)时，我们不能使用线性回归。</p><p id="e1f4" class="pw-post-body-paragraph lh li it lj b lk ll ju lm ln lo jx lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">逻辑回归中的输出通过出现的概率来表示，而在简单回归中，获得的是数值。因此，逻辑回归本身就是一种确定二元变量预测值出现概率的方法。</p><h2 id="6511" class="kz la it bd md me mf dn mg mh mi dp mj lq mk ml mm lu mn mo mp ly mq mr ms mt bi translated">逻辑回归可以解决什么类型的问题？</h2><p id="da7a" class="pw-post-body-paragraph lh li it lj b lk mu ju lm ln mv jx lp lq mw ls lt lu mx lw lx ly my ma mb mc im bi translated">逻辑回归用于解决二元或多类分类任务。在本文中，我们将只讨论二元分类。用于分类目的逻辑回归的一个好例子是用于检测疾病，其中几个变量用于预测二元结果(疾病的存在或不存在)。预测变量可以是分类的、连续的或顺序的。</p><h2 id="383a" class="kz la it bd md me mf dn mg mh mi dp mj lq mk ml mm lu mn mo mp ly mq mr ms mt bi translated">数学解释</h2><p id="34e7" class="pw-post-body-paragraph lh li it lj b lk mu ju lm ln mv jx lp lq mw ls lt lu mx lw lx ly my ma mb mc im bi translated">逻辑回归的一般表达式是:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi mz"><img src="../Images/97883ed3759c933b3e8b05b843a5b19f.png" data-original-src="https://miro.medium.com/v2/resize:fit:480/format:webp/1*WIoQGVc3kx8iSGmBI8oAPw.png"/></div></figure><p id="3b78" class="pw-post-body-paragraph lh li it lj b lk ll ju lm ln lo jx lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">图形表示是:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi na"><img src="../Images/13b97abf14f586ffd096cc7404cbfce1.png" data-original-src="https://miro.medium.com/v2/resize:fit:1262/format:webp/1*b4WMCxR_2Xds2Zxgv14V0g.png"/></div></figure><p id="22fe" class="pw-post-body-paragraph lh li it lj b lk ll ju lm ln lo jx lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">可以看到，函数范围在0到1之间。当我们将模型拟合到逻辑函数时，我们将使用数据参数的系数来改变<em class="lf"> x </em>值，并得到我们的结果更接近1或0的概率。您还可以通过图形检查注意到，对于<em class="lf"> x &lt; 0，</em><em class="lf">y</em>值<em class="lf"> </em>将更接近0，对于<em class="lf"> x &gt; 0 </em>，<em class="lf"> y </em>值将更接近1。所以，基本上如果你知道<em class="lf"> x </em>是正值还是负值，你就知道对象属于哪一类，而不需要计算<em class="lf"> y. </em>然而，如果你想知道预测的强度，你仍然需要知道y的值。</p><p id="e4ee" class="pw-post-body-paragraph lh li it lj b lk ll ju lm ln lo jx lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">例如:</p><p id="410e" class="pw-post-body-paragraph lh li it lj b lk ll ju lm ln lo jx lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">用<em class="lf"> x = 3: </em></p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi nb"><img src="../Images/a2b6b525aeb77211c79a5e22f4f9a777.png" data-original-src="https://miro.medium.com/v2/resize:fit:506/format:webp/1*ZZBx1rO6ZQ6d6jvWDzxDTA.png"/></div></figure><p id="28b0" class="pw-post-body-paragraph lh li it lj b lk ll ju lm ln lo jx lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">我们将获得:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi nc"><img src="../Images/83c3d36436bf3a53e2fc2e14c072ee3c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1118/format:webp/1*7ivASpcqEVxaNEf_yJN_tQ.png"/></div></figure><p id="9b6e" class="pw-post-body-paragraph lh li it lj b lk ll ju lm ln lo jx lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">这意味着该对象很有可能属于类别1。相比之下，如果x= -4，那么它有很大概率在0类。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi nd"><img src="../Images/0ee3b40dcad68421cf853b69df670c68.png" data-original-src="https://miro.medium.com/v2/resize:fit:838/format:webp/1*C2BQFOY_Ea7O_kvGnAXSKQ.png"/></div></figure><blockquote class="ne nf ng"><p id="0d6f" class="lh li lf lj b lk ll ju lm ln lo jx lp nh lr ls lt ni lv lw lx nj lz ma mb mc im bi translated"><strong class="lj iu">但是模型中x是如何计算的呢？</strong></p></blockquote><p id="a90a" class="pw-post-body-paragraph lh li it lj b lk ll ju lm ln lo jx lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">为了拟合我们的模型，这意味着计算模型的x值，假设预测变量和结果的概率(y=1或y=0)之间存在线性关系。这样，<em class="lf"> x </em>将使用线性回归技术拟合，截距为<em class="lf"> m </em>，预测变量的系数值为<em class="lf"> B1 </em>、<em class="lf"> B2 </em>、<em class="lf"> B3 </em>...</p><blockquote class="nk"><p id="43a3" class="nl nm it bd nn no np nq nr ns nt mc dk translated">我在以前的出版物中解释过线性回归，你可以在这里找到<a class="ae nu" href="https://medium.com/p/467d0df39cc9" rel="noopener"><strong class="ak"/></a><a class="ae nu" href="https://medium.com/p/2315b9a26348" rel="noopener"><strong class="ak">这里</strong> </a>。</p></blockquote><h2 id="3177" class="kz la it bd md me nv dn mg mh nw dp mj lq nx ml mm lu ny mo mp ly nz mr ms mt bi translated">C参数:</h2><p id="9f3c" class="pw-post-body-paragraph lh li it lj b lk mu ju lm ln mv jx lp lq mw ls lt lu mx lw lx ly my ma mb mc im bi translated">逻辑回归中的<strong class="lj iu"> <em class="lf"> C </em> </strong>值是控制正则化的用户可调参数。简单来说，C  的较高<strong class="lj iu"> <em class="lf">值将指示我们的模型尽可能地适合训练集，而<strong class="lj iu"> <em class="lf">较低的C值</em> </strong>将有利于系数更接近于零的简单模型。</em></strong></p><h2 id="dedb" class="kz la it bd md me mf dn mg mh mi dp mj lq mk ml mm lu mn mo mp ly mq mr ms mt bi translated">动手操作:</h2><p id="9141" class="pw-post-body-paragraph lh li it lj b lk mu ju lm ln mv jx lp lq mw ls lt lu mx lw lx ly my ma mb mc im bi translated">现在我们将使用SciKit-Learn和Python来全面实现和评估一个逻辑回归模型。我们还将学习如何调整模型参数，以控制模型的复杂性、过拟合和/或欠拟合。</p><p id="0b59" class="pw-post-body-paragraph lh li it lj b lk ll ju lm ln lo jx lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated"><strong class="lj iu">导入必要的库:</strong></p><pre class="kj kk kl km gt ku kv kw kx aw ky bi"><span id="2e6e" class="kz la it kv b gy lb lc l ld le">#Import Libraries:</span><span id="8af5" class="kz la it kv b gy lg lc l ld le">from random import random<br/>from random import randint<br/>import numpy as np<br/>import pandas as pd<br/>import matplotlib.pyplot as plt<br/>import seaborn as sns</span><span id="7b73" class="kz la it kv b gy lg lc l ld le">from sklearn.model_selection import train_test_split<br/>from sklearn.linear_model import LogisticRegression</span><span id="c1fb" class="kz la it kv b gy lg lc l ld le">from mlxtend.plotting import plot_decision_regions</span></pre><p id="abb6" class="pw-post-body-paragraph lh li it lj b lk ll ju lm ln lo jx lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated"><strong class="lj iu">创建数据:</strong></p><p id="083f" class="pw-post-body-paragraph lh li it lj b lk ll ju lm ln lo jx lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">我们将通过构建一个用作示例的数据集来为此案例研究创建数据。我将变量命名为肺功能(FEV1和BD)和肺部炎症(FeNO)的参数，结果变量命名为疾病存在与否，在这种情况下为哮喘。但是请记住，这不是真实的数据，是为这个例子人工创建的数据，并且基于我在这个领域的专家知识。如果使用的是自己的数据，可以直接跳到步骤“探索性数据分析”。</p><pre class="kj kk kl km gt ku kv kw kx aw ky bi"><span id="5a64" class="kz la it kv b gy lb lc l ld le">#Fabricating variables:</span><span id="f7bc" class="kz la it kv b gy lg lc l ld le">#Creating values for FeNO with 3 classes:<br/>FeNO_0 = np.random.normal(15,20, 100)<br/>FeNO_1 = np.random.normal(35,20, 100)<br/>FeNO_2 = np.random.normal(65, 20, 100)</span><span id="9b01" class="kz la it kv b gy lg lc l ld le">#Creating values for FEV1 with 3 classes:<br/>FEV1_0 = np.random.normal(4.50, 1, 100)<br/>FEV1_1 = np.random.uniform(3.75, 1.2, 100)<br/>FEV1_2 = np.random.uniform(2.35, 1.2, 100)</span><span id="fc90" class="kz la it kv b gy lg lc l ld le">#Creating values for Broncho Dilation with 3 classes:<br/>BD_0 = np.random.normal(150,49, 100)<br/>BD_1 = np.random.uniform(250,50,100)<br/>BD_2 = np.random.uniform(350, 50, 100)</span><span id="75b8" class="kz la it kv b gy lg lc l ld le">#Creating labels variable with two classes (1)Disease (0)No disease:<br/>not_asthma = np.zeros((150,), dtype=int)<br/>asthma = np.ones((150,), dtype=int</span></pre><p id="d40e" class="pw-post-body-paragraph lh li it lj b lk ll ju lm ln lo jx lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">现在，我们将把之前创建的值连接成三个预测变量和一个结果变量:</p><pre class="kj kk kl km gt ku kv kw kx aw ky bi"><span id="eeda" class="kz la it kv b gy lb lc l ld le">#Concatenate classes into one variable:</span><span id="220b" class="kz la it kv b gy lg lc l ld le">FeNO = np.concatenate([FeNO_0, FeNO_1, FeNO_2])<br/>FEV1 = np.concatenate([FEV1_0, FEV1_1, FEV1_2])<br/>BD = np.concatenate([BD_0, BD_1, BD_2])<br/>dx = np.concatenate([not_asthma, asthma])</span></pre><p id="2d01" class="pw-post-body-paragraph lh li it lj b lk ll ju lm ln lo jx lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">下一步是创建一个数据帧，并将变量添加到数据帧中:</p><pre class="kj kk kl km gt ku kv kw kx aw ky bi"><span id="d8b6" class="kz la it kv b gy lb lc l ld le">#Create DataFrame:<br/>df = pd.DataFrame()</span><span id="d8e6" class="kz la it kv b gy lg lc l ld le">#Add variables to DataFrame:<br/>df['FeNO'] = FeNO.tolist()<br/>df['FEV1'] = FEV1.tolist()<br/>df['BD'] = BD.tolist()<br/>df['dx'] = dx.tolist()</span></pre><p id="d3c6" class="pw-post-body-paragraph lh li it lj b lk ll ju lm ln lo jx lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">我们可以通过简单地输入“<strong class="lj iu"> df </strong>”来查看我们的数据帧，以检查是否一切正常。可以看出，我们的数据框架有4列(三个预测变量和一个结果变量)，300行。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi oa"><img src="../Images/cace8ec7d953f34f8234a1d537276209.png" data-original-src="https://miro.medium.com/v2/resize:fit:880/format:webp/1*r8k-f0fNuUiy2XQttg9XDw.png"/></div></figure><p id="7609" class="pw-post-body-paragraph lh li it lj b lk ll ju lm ln lo jx lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated"><strong class="lj iu">探索性数据分析:</strong></p><p id="0119" class="pw-post-body-paragraph lh li it lj b lk ll ju lm ln lo jx lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">这是一个简单的探索性数据分析(EDA ),只是为了了解我们的变量如何表现，以及它们如何相互关联并与结果(疾病存在或不存在)关联。首先，我们将看到我们的变量是如何根据疾病的存在与否而分布的:</p><pre class="kj kk kl km gt ku kv kw kx aw ky bi"><span id="aede" class="kz la it kv b gy lb lc l ld le">#Exploring dataset:</span><span id="2fb3" class="kz la it kv b gy lg lc l ld le">sns.pairplot(df, kind="scatter", hue="dx")<br/>plt.show()</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi ob"><img src="../Images/bc458ce21445696030cb4ad2e7196f97.png" data-original-src="https://miro.medium.com/v2/resize:fit:1160/format:webp/1*cSIRa2rjEBwkvhJfjymKrQ.png"/></div></figure><p id="2a83" class="pw-post-body-paragraph lh li it lj b lk ll ju lm ln lo jx lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">我们可以检查不同参数区分疾病存在/不存在的能力。参数“BD”显示了区分两个类别的最差能力，我们可以看到更高的重叠值。</p><pre class="kj kk kl km gt ku kv kw kx aw ky bi"><span id="7cb7" class="kz la it kv b gy lb lc l ld le">sns.boxplot( x=df["dx"], y=df["FEV1"] )</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi oc"><img src="../Images/fc19f2f8f6de50d9fc2ebb95e881c6bc.png" data-original-src="https://miro.medium.com/v2/resize:fit:752/format:webp/1*oJPdqXlM_D7HjsoX_KO55Q.png"/></div></figure><pre class="kj kk kl km gt ku kv kw kx aw ky bi"><span id="fb61" class="kz la it kv b gy lb lc l ld le">sns.boxplot( x=df["dx"], y=df["FeNO"] )</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi od"><img src="../Images/d5e3bab0ebe5e382d81fe412444ce4ca.png" data-original-src="https://miro.medium.com/v2/resize:fit:782/format:webp/1*37nBUAJeKvKnoUQ9-lH-zw.png"/></div></figure><pre class="kj kk kl km gt ku kv kw kx aw ky bi"><span id="f539" class="kz la it kv b gy lb lc l ld le">sns.boxplot( x=df["dx"], y=df["BD"] )</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi oe"><img src="../Images/e06375b142b1ec8fafc0cca03a3cd632.png" data-original-src="https://miro.medium.com/v2/resize:fit:778/format:webp/1*uzQD2iHIDuY6YlobdFWMcw.png"/></div></figure><p id="b358" class="pw-post-body-paragraph lh li it lj b lk ll ju lm ln lo jx lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">然后我们可以检查不同参数之间的相关性。在有哮喘的情况下，相关性总是更强，而在没有疾病的情况下，相关性就不那么显著了。</p><pre class="kj kk kl km gt ku kv kw kx aw ky bi"><span id="5d9f" class="kz la it kv b gy lb lc l ld le">sns.lmplot(x="FEV1", y="FeNO", data=df, fit_reg=True, hue='dx', legend=True)</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi of"><img src="../Images/9d495c7b9322d75e5c8086dde7aa7fd9.png" data-original-src="https://miro.medium.com/v2/resize:fit:788/format:webp/1*9qVlPkCojojcQY8nUZq9Qg.png"/></div></figure><p id="29b0" class="pw-post-body-paragraph lh li it lj b lk ll ju lm ln lo jx lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">当疾病存在时，我们看到FEV1和FeNO之间有更强的相关性，并且这种相关性是负的(由负斜率可见)，这意味着对于较高的FeNO值，我们将发现较低的FEV1值。</p><pre class="kj kk kl km gt ku kv kw kx aw ky bi"><span id="0f57" class="kz la it kv b gy lb lc l ld le">sns.lmplot(x="FEV1", y="BD", data=df, fit_reg=True, hue='dx', legend=True)</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi of"><img src="../Images/221d68e62c2d42781cb44c11b685c5d3.png" data-original-src="https://miro.medium.com/v2/resize:fit:788/format:webp/1*za9FAf5RG4CDeREV2DzMuQ.png"/></div></figure><p id="db93" class="pw-post-body-paragraph lh li it lj b lk ll ju lm ln lo jx lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">当检查FEV1和BD之间的相关性时，我们发现当存在哮喘诊断时，可以看到负相关性。这样，FEV1值越低，支气管扩张值越高。</p><pre class="kj kk kl km gt ku kv kw kx aw ky bi"><span id="2a06" class="kz la it kv b gy lb lc l ld le">sns.lmplot(x="FeNO", y="BD", data=df, fit_reg=True, hue='dx', legend=True)</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi of"><img src="../Images/dbd6b489a55e222b7bb522f94ad02c98.png" data-original-src="https://miro.medium.com/v2/resize:fit:788/format:webp/1*0VESoy7lUVlmfgIIPGrjfw.png"/></div></figure><p id="c9ad" class="pw-post-body-paragraph lh li it lj b lk ll ju lm ln lo jx lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">最后，FeNO和BD之间的相关性表明，当存在哮喘时，较高的FeNO值与较高的BD值相关(正相关)。</p><p id="7b1c" class="pw-post-body-paragraph lh li it lj b lk ll ju lm ln lo jx lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated"><strong class="lj iu">将数据分成训练和测试数据集:</strong></p><p id="a333" class="pw-post-body-paragraph lh li it lj b lk ll ju lm ln lo jx lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">我们将使用80%的数据来构建模型，剩下的20%用于测试模型。但是首先，我们将创建我们的<strong class="lj iu"> <em class="lf"> X </em> </strong>和<strong class="lj iu"> <em class="lf"> y </em> </strong>变量，其中<strong class="lj iu"> <em class="lf"> X </em> </strong>表示带有预测值的数据集，而<strong class="lj iu"> <em class="lf"> y </em> </strong>表示带有结果的值的数组。</p><pre class="kj kk kl km gt ku kv kw kx aw ky bi"><span id="135b" class="kz la it kv b gy lb lc l ld le">#Creating X and y:<br/>X = df.drop('dx', axis=1)<br/>y = df['dx']</span><span id="ccd2" class="kz la it kv b gy lg lc l ld le">#Data split into train and test:<br/>X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20)</span></pre><p id="e75a" class="pw-post-body-paragraph lh li it lj b lk ll ju lm ln lo jx lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated"><strong class="lj iu">建立并评估模型:</strong></p><pre class="kj kk kl km gt ku kv kw kx aw ky bi"><span id="b8ed" class="kz la it kv b gy lb lc l ld le">#Fit the model:<br/>logisticregression = LogisticRegression().fit(X_train, y_train)</span><span id="5399" class="kz la it kv b gy lg lc l ld le">#Evaluate the model:<br/>print("training set score: %f" % logisticregression.score(X_train, y_train))print("test set score: %f" % logisticregression.score(X_test, y_test))</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi og"><img src="../Images/46b336a3469e74c55f6ed31a00883630.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*wvfwXvkNd5deQHflOG8szg.png"/></div></div></figure><p id="c60f" class="pw-post-body-paragraph lh li it lj b lk ll ju lm ln lo jx lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">正如我们所看到的，我们的模型在训练集上表现稍好，这可能表明我们过度拟合了。幸运的是，我们可以使用<strong class="lj iu"> <em class="lf"> C </em> </strong>值来调整模型，并尝试找到一个在模型复杂性、过拟合和欠拟合之间权衡折衷的最佳模型。</p><p id="05ec" class="pw-post-body-paragraph lh li it lj b lk ll ju lm ln lo jx lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">让我们看看如果我们设置<strong class="lj iu"> <em class="lf"> C=100 </em> </strong>会发生什么:</p><pre class="kj kk kl km gt ku kv kw kx aw ky bi"><span id="7eff" class="kz la it kv b gy lb lc l ld le">#C=100<br/>logisticregression100 = LogisticRegression(C=100).fit(X_train, y_train)</span><span id="7d6e" class="kz la it kv b gy lg lc l ld le">print("training set score: %f" % logisticregression100.score(X_train, y_train))<br/>print("test set score: %f" % <br/>logisticregression100.score(X_test, y_test))</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi oh"><img src="../Images/b077d8e9b4a55462dc53dd8349bdafd6.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*wpqSqr9k2JoouJVKUX8lRw.png"/></div></div></figure><p id="154a" class="pw-post-body-paragraph lh li it lj b lk ll ju lm ln lo jx lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">设置<strong class="lj iu"> <em class="lf"> C=100 </em> </strong>对训练集得分影响很小，对测试集得分没有影响，也就是说对模型没有改善。</p><p id="c3a4" class="pw-post-body-paragraph lh li it lj b lk ll ju lm ln lo jx lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">设定<strong class="lj iu"> <em class="lf"> C=0.01 </em> </strong>:</p><pre class="kj kk kl km gt ku kv kw kx aw ky bi"><span id="57e0" class="kz la it kv b gy lb lc l ld le">#C=0.01<br/>logisticregression001 = LogisticRegression(C=0.01).fit(X_train, y_train)</span><span id="d459" class="kz la it kv b gy lg lc l ld le">print("training set score: %f" % logisticregression001.score(X_train, y_train))<br/>print("test set score: %f" % <br/>logisticregression001.score(X_test, y_test))</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi oi"><img src="../Images/cb29af895720ad8664276f9880b0aa8c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*u0C0LVN8imVLf88AH9cHwA.png"/></div></div></figure><p id="0f60" class="pw-post-body-paragraph lh li it lj b lk ll ju lm ln lo jx lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">设置<strong class="lj iu"> <em class="lf"> C=0.01 </em> </strong>会降低训练集分数和测试集分数，这意味着它不是该参数的好值。</p><p id="c08c" class="pw-post-body-paragraph lh li it lj b lk ll ju lm ln lo jx lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated"><strong class="lj iu">寻找最佳的<em class="lf"> C </em>值:</strong></p><p id="cdb6" class="pw-post-body-paragraph lh li it lj b lk ll ju lm ln lo jx lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">为了找到最佳的<strong class="lj iu"> <em class="lf"> C </em> </strong>值，我们应该使用比试错法更复杂的方法。一种方法是对训练集和测试集在不同的<strong class="lj iu"> <em class="lf"> C </em> </strong>值绘制几个准确度分数。</p><pre class="kj kk kl km gt ku kv kw kx aw ky bi"><span id="6931" class="kz la it kv b gy lb lc l ld le">training_accuracy = []<br/>test_accuracy = []</span><span id="676d" class="kz la it kv b gy lg lc l ld le"># try c values from 0.001 to 100:<br/>c_settings = np.arange(0.001, 100, 0.1)</span><span id="372b" class="kz la it kv b gy lg lc l ld le">for i in c_settings:<br/>    # build the model<br/>    clf = LogisticRegression(C=i)<br/>    clf.fit(X_train, y_train)<br/>    # record training set accuracy<br/>    training_accuracy.append(clf.score(X_train, y_train))<br/>    # record generalization accuracy<br/>    test_accuracy.append(clf.score(X_test, y_test))</span><span id="f3f0" class="kz la it kv b gy lg lc l ld le">plt.plot(c_settings, training_accuracy, label="training accuracy")<br/>plt.plot(c_settings, test_accuracy, label="test accuracy")<br/>plt.legend()</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi oj"><img src="../Images/651f728d9422dbced9eefff855d607ec.png" data-original-src="https://miro.medium.com/v2/resize:fit:756/format:webp/1*rcymtSRoTiqyh_RJBKaSaQ.png"/></div></figure><p id="3ea8" class="pw-post-body-paragraph lh li it lj b lk ll ju lm ln lo jx lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">在图中我们可以看到，大约在<strong class="lj iu"> <em class="lf"> C </em> </strong>值为10之后，训练和测试精度值更加接近。在该图中并不完全清楚，因此我们可以绘制一个更小的区间:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi oj"><img src="../Images/35d12f581804c9deb376e529b34a6b40.png" data-original-src="https://miro.medium.com/v2/resize:fit:756/format:webp/1*qMyFDWkxMqywiiOtAMgihw.png"/></div></figure><p id="4567" class="pw-post-body-paragraph lh li it lj b lk ll ju lm ln lo jx lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">现在很容易看出，在<strong class="lj iu"> <em class="lf"> C=12 </em> </strong>时训练和测试精度值更接近，这意味着这是我们的最优<strong class="lj iu"> <em class="lf"> C </em> </strong>值。我们可以检查一下:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi oh"><img src="../Images/ac9fa521bcf9c5650653a7ccacda8b86.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*1ANb4utXMj5itQIRHAlA9w.png"/></div></div></figure><p id="d640" class="pw-post-body-paragraph lh li it lj b lk ll ju lm ln lo jx lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated"><strong class="lj iu">建立模型的可视化:</strong></p><p id="3022" class="pw-post-body-paragraph lh li it lj b lk ll ju lm ln lo jx lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">最后，我们可以通过构建一个包含决策区域的图表来可视化我们的模型性能。为此，我们需要csv格式的数据帧:</p><pre class="kj kk kl km gt ku kv kw kx aw ky bi"><span id="f380" class="kz la it kv b gy lb lc l ld le">df.to_csv('data.csv', index = False)<br/>data = pd.read_csv('data.csv')</span></pre><p id="cf2d" class="pw-post-body-paragraph lh li it lj b lk ll ju lm ln lo jx lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">然后，我们使用两个主要变量为该图构建一个函数(我们知道，一旦BD具有更大的类重叠，我们将使用FEV1和FeNO):</p><pre class="kj kk kl km gt ku kv kw kx aw ky bi"><span id="a64c" class="kz la it kv b gy lb lc l ld le">def logisticReg_comparison(data,c):<br/>    x = data[['FEV1','FeNO',]].values<br/>    y = data['dx'].astype(int).values<br/>    LogReg = LogisticRegression(C=c)<br/>    LogReg.fit(x,y)<br/>    print(LogReg.score(x,y))<br/>    #Plot decision region:<br/>    plot_decision_regions(x,y, clf=LogReg, legend=2)<br/>    #Adding axes annotations:<br/>    plt.xlabel('X_train')<br/>    plt.ylabel('y_train')<br/>    plt.title('LogReg with C='+str(c))<br/>    plt.show()</span><span id="a7e5" class="kz la it kv b gy lg lc l ld le">logisticReg_comparison(data,12)</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi ok"><img src="../Images/22426acaaf58107ebfd9be18408763e7.png" data-original-src="https://miro.medium.com/v2/resize:fit:784/format:webp/1*TC6vUpCD3wwnFdIg707IeA.png"/></div></figure><p id="4105" class="pw-post-body-paragraph lh li it lj b lk ll ju lm ln lo jx lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">感谢您的阅读！如果您有任何更正或建议，请告诉我，不要忘记订阅以接收关于我未来出版物的通知。</p><p id="6253" class="pw-post-body-paragraph lh li it lj b lk ll ju lm ln lo jx lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">如果:你喜欢这篇文章，别忘了关注我，这样你就能收到关于新出版物的所有更新。</p><p id="81d2" class="pw-post-body-paragraph lh li it lj b lk ll ju lm ln lo jx lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated"><strong class="lj iu">其他如果:</strong>你想了解更多，你可以通过<a class="ae nu" href="https://cdanielaam.medium.com/membership" rel="noopener">我的推荐链接</a>订阅媒体会员。它不会花你更多的钱，但会支付我一杯咖啡。</p><p id="a24d" class="pw-post-body-paragraph lh li it lj b lk ll ju lm ln lo jx lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated"><strong class="lj iu">其他:</strong>谢谢！</p></div></div>    
</body>
</html>