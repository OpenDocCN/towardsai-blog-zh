<html>
<head>
<title>Diving Deep into Deep Learning</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">深入钻研深度学习</h1>
<blockquote>原文：<a href="https://pub.towardsai.net/diving-deep-into-deep-learning-f34497c18f11?source=collection_archive---------2-----------------------#2020-07-17">https://pub.towardsai.net/diving-deep-into-deep-learning-f34497c18f11?source=collection_archive---------2-----------------------#2020-07-17</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><h2 id="b4e6" class="io ip iq bd b dl ir is it iu iv iw dk ix translated" aria-label="kicker paragraph"><a class="ae ep" href="https://towardsai.net/p/category/machine-learning/deep-learning" rel="noopener ugc nofollow" target="_blank">深度学习</a>，<a class="ae ep" href="https://towardsai.net/p/category/data-science" rel="noopener ugc nofollow" target="_blank">数据科学</a></h2><div class=""/><div class=""><h2 id="7a01" class="pw-subtitle-paragraph jw iz iq bd b jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn dk translated">深度学习的非传统指南</h2></div><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div role="button" tabindex="0" class="ku kv di kw bf kx"><div class="gh gi ko"><img src="../Images/31211495eccfbf6c293d49ea19fa0fd0.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*2f0fReAwNoehyhJXvAtw_g.png"/></div></div></figure><p id="74e9" class="pw-post-body-paragraph la lb iq lc b ld le ka lf lg lh kd li lj lk ll lm ln lo lp lq lr ls lt lu lv ij bi translated">我们生活在一个不断被深度学习算法包围的世界，不管是出于好的还是坏的原因。从网飞推荐系统到特斯拉的自动驾驶汽车，深度学习正在离开我们的生活。这种古怪而简单的技术只需要4-5年的训练就可以颠覆整个一千年的人类文明。</p><p id="598d" class="pw-post-body-paragraph la lb iq lc b ld le ka lf lg lh kd li lj lk ll lm ln lo lp lq lr ls lt lu lv ij bi translated">你提出这篇文章可能是因为深度学习认为你应该看看。</p><p id="d4d4" class="pw-post-body-paragraph la lb iq lc b ld le ka lf lg lh kd li lj lk ll lm ln lo lp lq lr ls lt lu lv ij bi translated">现在让我们开始吧！</p><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div role="button" tabindex="0" class="ku kv di kw bf kx"><div class="gh gi lw"><img src="../Images/21f56396bd6778116bc92d0d8ccd8f6b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*94zPKMZunh2DrKqs"/></div></div><figcaption class="lx ly gj gh gi lz ma bd b be z dk translated">照片由<a class="ae mb" href="https://unsplash.com/@arstyy?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">奥斯汀·尼尔</a>在<a class="ae mb" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>拍摄</figcaption></figure><h1 id="7e27" class="mc md iq bd me mf mg mh mi mj mk ml mm kf mn kg mo ki mp kj mq kl mr km ms mt bi translated">什么是深度学习？</h1><p id="2eb8" class="pw-post-body-paragraph la lb iq lc b ld mu ka lf lg mv kd li lj mw ll lm ln mx lp lq lr my lt lu lv ij bi translated">深度学习是机器学习算法的延伸，它教会计算机做人类自然继承的事情，即通过例子学习。</p><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div role="button" tabindex="0" class="ku kv di kw bf kx"><div class="gh gi mz"><img src="../Images/2c362c837c31c164a673e0d61ea9fc70.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*K4AJocuUh558idRj.png"/></div></div><figcaption class="lx ly gj gh gi lz ma bd b be z dk translated">人工智能vs机器学习vs深度学习，<a class="ae mb" href="https://www.wikiwand.com/en/Deep_learning" rel="noopener ugc nofollow" target="_blank">来源</a></figcaption></figure><h2 id="3954" class="na md iq bd me nb nc dn mi nd ne dp mm lj nf ng mo ln nh ni mq lr nj nk ms iw bi translated">和机器学习有什么不同？</h2><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div role="button" tabindex="0" class="ku kv di kw bf kx"><div class="gh gi nl"><img src="../Images/4a9fc1dd0aeba320cea330fb0c85f7cc.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*HZHraBtwpvbL1JwA"/></div></div><figcaption class="lx ly gj gh gi lz ma bd b be z dk translated">ML vs DL，<a class="ae mb" href="https://semiengineering.com/deep-learning-spreads/" rel="noopener ugc nofollow" target="_blank">来源</a></figcaption></figure><p id="9469" class="pw-post-body-paragraph la lb iq lc b ld le ka lf lg lh kd li lj lk ll lm ln lo lp lq lr ls lt lu lv ij bi translated">区分机器学习和深度学习的主要因素是数据表示和输出。机器学习算法是为特定任务开发的，而深度学习更多的是基于矩阵不同层的数据表示，其中每一层都利用了前一层提供的输出。</p><h2 id="1a4d" class="na md iq bd me nb nc dn mi nd ne dp mm lj nf ng mo ln nh ni mq lr nj nk ms iw bi translated">深度学习背后的直觉</h2><p id="d5e4" class="pw-post-body-paragraph la lb iq lc b ld mu ka lf lg mv kd li lj mw ll lm ln mx lp lq lr my lt lu lv ij bi translated">深度学习的唯一灵感就是模仿人脑。它模仿了人类大脑过滤相关信息的方式。</p><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div role="button" tabindex="0" class="ku kv di kw bf kx"><div class="gh gi nm"><img src="../Images/218d55391f71427ad237bc301cdc37b2.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*YaDfcYnlPeXPJb-n"/></div></div><figcaption class="lx ly gj gh gi lz ma bd b be z dk translated">Robina Weermeijer 在<a class="ae mb" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上拍摄的照片</figcaption></figure><p id="85a8" class="pw-post-body-paragraph la lb iq lc b ld le ka lf lg lh kd li lj lk ll lm ln lo lp lq lr ls lt lu lv ij bi translated">我们的大脑由数十亿个生物神经元组成，这些神经元进一步连接到数千个生物神经元，以便共享和过滤信息。<strong class="lc ja">深度学习是一种以适合我们机器的方式重建这种安排的方法。</strong></p><blockquote class="nn no np"><p id="e644" class="la lb nq lc b ld le ka lf lg lh kd li nr lk ll lm ns lo lp lq nt ls lt lu lv ij bi translated"><strong class="lc ja">利用深度学习，我们尝试开发一种人工神经网络。</strong></p></blockquote><p id="784c" class="pw-post-body-paragraph la lb iq lc b ld le ka lf lg lh kd li lj lk ll lm ln lo lp lq lr ls lt lu lv ij bi translated">在我们的大脑中，我们有<em class="nq">树突、轴突、细胞体、</em>和<em class="nq">突触间隙。信号在突触的帮助下从轴突(一个神经元的尾部)传递到树突(另一个神经元的头部)。</em></p><p id="9cca" class="pw-post-body-paragraph la lb iq lc b ld le ka lf lg lh kd li lj lk ll lm ln lo lp lq lr ls lt lu lv ij bi translated">一旦树突收到信号，细胞体进行一些处理，然后将信号发送回轴突，修改后的信号再次发送到另一个神经元，这个过程一遍又一遍地重复。</p><p id="993b" class="pw-post-body-paragraph la lb iq lc b ld le ka lf lg lh kd li lj lk ll lm ln lo lp lq lr ls lt lu lv ij bi translated">为了在人工神经网络中重现魔力，我们引入了<em class="nq">输入、权重、输出</em>和<em class="nq">激活</em>。单个神经元对我们来说毫无用处，但当我们得到一堆神经元时，你可以重现这种魔力。人工神经网络纯粹模仿自然大脑的工作。我们将加权输入馈送到神经层，一些处理发生在产生输出的相同位置，该输出被进一步馈送到下一层，这递归地发生，直到我们到达最后一层。</p><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div class="gh gi nu"><img src="../Images/bc57137d230b6bb2565f1836012dd54b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1204/0*7czY-Vzd_EHGDweR"/></div><figcaption class="lx ly gj gh gi lz ma bd b be z dk translated">大脑vs人工神经网络，<a class="ae mb" href="https://www.quora.com/What-is-the-differences-between-artificial-neural-network-computer-science-and-biological-neural-network" rel="noopener ugc nofollow" target="_blank">来源</a></figcaption></figure><h2 id="c195" class="na md iq bd me nb nc dn mi nd ne dp mm lj nf ng mo ln nh ni mq lr nj nk ms iw bi translated">神经元的魔力</h2><p id="34cb" class="pw-post-body-paragraph la lb iq lc b ld mu ka lf lg mv kd li lj mw ll lm ln mx lp lq lr my lt lu lv ij bi translated">输入节点显示数字信息。投入越高，决策因素中包含的投入就越多。</p><p id="f4f5" class="pw-post-body-paragraph la lb iq lc b ld le ka lf lg lh kd li lj lk ll lm ln lo lp lq lr ls lt lu lv ij bi translated">基于它的权重，计算激活值并传递给下一个节点。每个节点接收加权和，并基于传递函数对其进行修改。这个过程一遍又一遍地重复，直到我们到达输出层。</p></div><div class="ab cl nv nw hu nx" role="separator"><span class="ny bw bk nz oa ob"/><span class="ny bw bk nz oa ob"/><span class="ny bw bk nz oa"/></div><div class="ij ik il im in"><h1 id="33dc" class="mc md iq bd me mf oc mh mi mj od ml mm kf oe kg mo ki of kj mq kl og km ms mt bi translated">神经网络是如何工作的？</h1><p id="b3ec" class="pw-post-body-paragraph la lb iq lc b ld mu ka lf lg mv kd li lj mw ll lm ln mx lp lq lr my lt lu lv ij bi translated">神经网络是用于分类和预测的多层神经元网络。</p><p id="6833" class="pw-post-body-paragraph la lb iq lc b ld le ka lf lg lh kd li lj lk ll lm ln lo lp lq lr ls lt lu lv ij bi translated">它构成三种类型的层wiz <em class="nq">输入层，隐藏层</em> &amp; <em class="nq">输出层。</em></p><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div class="ab gu cl oh"><img src="../Images/187c8c089aec316be6197d5c93b26395.png" data-original-src="https://miro.medium.com/v2/format:webp/1*FBXS211lj7zWEQZRAmDedQ.png"/></div><figcaption class="lx ly gj gh gi lz ma bd b be z dk translated"><a class="ae mb" href="https://www.kdnuggets.com/2017/10/7-types-artificial-neural-networks-natural-language-processing.html" rel="noopener ugc nofollow" target="_blank">神经网络结构，来源</a></figcaption></figure><p id="f23c" class="pw-post-body-paragraph la lb iq lc b ld le ka lf lg lh kd li lj lk ll lm ln lo lp lq lr ls lt lu lv ij bi translated">输入层接受0到1之间的数字，该数字作为输入层(层1)的激活。</p><p id="cba0" class="pw-post-body-paragraph la lb iq lc b ld le ka lf lg lh kd li lj lk ll lm ln lo lp lq lr ls lt lu lv ij bi translated">在多类分类的情况下，输出图层由属于每个类的概率组成。具有最大概率的类被视为该特定输入的输出。</p><p id="d31c" class="pw-post-body-paragraph la lb iq lc b ld le ka lf lg lh kd li lj lk ll lm ln lo lp lq lr ls lt lu lv ij bi translated">在隐藏层中，我们使用不同的激活函数来计算激活，例如<a class="ae mb" href="https://medium.com/analytics-vidhya/activation-functions-explained-8690ea7bdec9" rel="noopener"> TanH、Sigmoid、ReLu </a>。</p><h2 id="437d" class="na md iq bd me nb nc dn mi nd ne dp mm lj nf ng mo ln nh ni mq lr nj nk ms iw bi translated">神经网络的工作</h2><p id="5a0e" class="pw-post-body-paragraph la lb iq lc b ld mu ka lf lg mv kd li lj mw ll lm ln mx lp lq lr my lt lu lv ij bi translated">一个神经元的输入是前一层所有神经元的加权输出之和。每个输入是当前神经元的权重相关和输入的产物。如果在前一层中有5个神经元，则当前层中的每个神经元将具有5个不同的权重。</p><p id="f03a" class="pw-post-body-paragraph la lb iq lc b ld le ka lf lg lh kd li lj lk ll lm ln lo lp lq lr ls lt lu lv ij bi translated">为每个神经元计算一个加权和，然后在挤压成sigmoid函数之前将其加到bias上。</p><p id="a91d" class="pw-post-body-paragraph la lb iq lc b ld le ka lf lg lh kd li lj lk ll lm ln lo lp lq lr ls lt lu lv ij bi translated">因此，简而言之，神经元的激活可以被认为是来自前一层的权重和当前输入以及偏置的乘积之和。</p><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div role="button" tabindex="0" class="ku kv di kw bf kx"><div class="gh gi oi"><img src="../Images/dec85f82ae660623674c24ff33dc3ff1.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*9BGViSZJsDV8Wow9.png"/></div></div><figcaption class="lx ly gj gh gi lz ma bd b be z dk translated">激活功能，<a class="ae mb" href="https://www.datacamp.com/community/tutorials/neural-network-models-r" rel="noopener ugc nofollow" target="_blank">来源</a></figcaption></figure><p id="6fa2" class="pw-post-body-paragraph la lb iq lc b ld le ka lf lg lh kd li lj lk ll lm ln lo lp lq lr ls lt lu lv ij bi translated">激活功能将输入信号解码为输出信号。它在0到1的范围内映射输出值。这是一种表示细胞内潜在放电频率的方法。任何神经元的激活功能越多，其放电能力就越强。</p><h2 id="f8ba" class="na md iq bd me nb nc dn mi nd ne dp mm lj nf ng mo ln nh ni mq lr nj nk ms iw bi translated">我们如何选择隐藏层？</h2><p id="86bc" class="pw-post-body-paragraph la lb iq lc b ld mu ka lf lg mv kd li lj mw ll lm ln mx lp lq lr my lt lu lv ij bi translated">你的模型中隐藏层的数量是一个超参数，即它必须由你来选择。</p><blockquote class="nn no np"><p id="6387" class="la lb nq lc b ld le ka lf lg lh kd li nr lk ll lm ns lo lp lq nt ls lt lu lv ij bi translated">隐藏层数越多== &gt;复杂模型== &gt;过度拟合</p></blockquote><p id="8b88" class="pw-post-body-paragraph la lb iq lc b ld le ka lf lg lh kd li lj lk ll lm ln lo lp lq lr ls lt lu lv ij bi translated">假设，我们想建立一个手写数字识别系统。我们输入一些图像，并期望图像中的数字作为我们的输出。</p><p id="e654" class="pw-post-body-paragraph la lb iq lc b ld le ka lf lg lh kd li lj lk ll lm ln lo lp lq lr ls lt lu lv ij bi translated">当我们看到一个橙子时，我们的大脑是如何识别它的？它识别其形状像圆形，但我们有几个圆形的水果和物体，接下来它分析其颜色和结构如果它是橙色和粗糙表面的东西，那么我们可以将其归类为橙色水果，但如果它是橙色和光滑的表面，我们可以认为它可能是一个橙色的球。</p><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div role="button" tabindex="0" class="ku kv di kw bf kx"><div class="gh gi oj"><img src="../Images/eeb878d26c2e3996bb3a9d1a471a74fb.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*uY7Nk_-sC6VDoiz5"/></div></div><figcaption class="lx ly gj gh gi lz ma bd b be z dk translated">安妮·普雷布尔在<a class="ae mb" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>拍摄的照片</figcaption></figure><p id="a5e1" class="pw-post-body-paragraph la lb iq lc b ld le ka lf lg lh kd li lj lk ll lm ln lo lp lq lr ls lt lu lv ij bi translated">模仿我们的自然神经网络，人工神经网络试图遵循<em class="nq">划分&amp;征服方法</em>，即它会将问题划分为进一步的子问题，或者更具体地说，它会将数字划分为进一步的形状以对数字进行分类。</p><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div role="button" tabindex="0" class="ku kv di kw bf kx"><div class="gh gi ok"><img src="../Images/48d9caab43098bd520366649d8b8a250.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*vM22LC_FewnKuWLIqp7L9w.png"/></div></div><figcaption class="lx ly gj gh gi lz ma bd b be z dk translated">将数字分成更多的子部分，<a class="ae mb" href="https://www.youtube.com/watch?v=aircAruvnKk" rel="noopener ugc nofollow" target="_blank">来源:3Blue1Brown </a></figcaption></figure><p id="4fcd" class="pw-post-body-paragraph la lb iq lc b ld le ka lf lg lh kd li lj lk ll lm ln lo lp lq lr ls lt lu lv ij bi translated">每个子部分被期望被每个隐藏层识别。我们可以假设，第一个要识别的隐藏层(-)，下一个要识别的隐藏层(|)，两个子部分相加可以是7也可以是4。第三个隐藏层将第一个和第二个隐藏层的输出相加，并尝试得出每个类别的概率，即10个类别(0到9)，具有最大概率的类别将被视为输出。</p><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div class="gh gi ol"><img src="../Images/1b1183dbe5805edf3ca2f55d96b076df.png" data-original-src="https://miro.medium.com/v2/resize:fit:840/0*7K_R6eDOLShbFuLj.gif"/></div><figcaption class="lx ly gj gh gi lz ma bd b be z dk translated">神经网络工作，<a class="ae mb" href="https://gfycat.com/discover/neural-networks-gifs" rel="noopener ugc nofollow" target="_blank">来源</a></figcaption></figure></div><div class="ab cl nv nw hu nx" role="separator"><span class="ny bw bk nz oa ob"/><span class="ny bw bk nz oa ob"/><span class="ny bw bk nz oa"/></div><div class="ij ik il im in"><h1 id="84e3" class="mc md iq bd me mf oc mh mi mj od ml mm kf oe kg mo ki of kj mq kl og km ms mt bi translated">神经网络是如何学习的？</h1><p id="55a7" class="pw-post-body-paragraph la lb iq lc b ld mu ka lf lg mv kd li lj mw ll lm ln mx lp lq lr my lt lu lv ij bi translated">一旦我们的模型训练好了，就该扔一些看不见的数据给它，分析它的性能(代价函数)。</p><p id="9e36" class="pw-post-body-paragraph la lb iq lc b ld le ka lf lg lh kd li lj lk ll lm ln lo lp lq lr ls lt lu lv ij bi translated">计算其性能的方法是使用均方误差(MSE ),其中我们计算真实值和预测值之差的平方。</p><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div class="gh gi nu"><img src="../Images/eaa4b5e4491295b19f7f4cce21bd3014.png" data-original-src="https://miro.medium.com/v2/resize:fit:1204/format:webp/0*EEfarJKGH8Vlnx_0.png"/></div><figcaption class="lx ly gj gh gi lz ma bd b be z dk translated">成本函数，<a class="ae mb" href="https://www.programcreek.com/2016/07/neural-network-backpropagation-derivation/" rel="noopener ugc nofollow" target="_blank">来源</a></figcaption></figure><p id="b0e6" class="pw-post-body-paragraph la lb iq lc b ld le ka lf lg lh kd li lj lk ll lm ln lo lp lq lr ls lt lu lv ij bi translated">一旦定义了成本函数，我们就可以检查我们的网络有多糟糕。基于成本函数，我们可以指导我们的模型进行一些调整和即兴创作。</p><p id="72ba" class="pw-post-body-paragraph la lb iq lc b ld le ka lf lg lh kd li lj lk ll lm ln lo lp lq lr ls lt lu lv ij bi translated"><strong class="lc ja">所谓即兴创作，我们指的是学习正确的权重和偏好。</strong></p><p id="e72b" class="pw-post-body-paragraph la lb iq lc b ld le ka lf lg lh kd li lj lk ll lm ln lo lp lq lr ls lt lu lv ij bi translated">为了降低损失，我们使用<a class="ae mb" href="https://towardsdatascience.com/gradient-descent-explained-9b953fc0d2c" rel="noopener" target="_blank">梯度下降</a>。梯度下降背后的思想是使我们的损失达到全局最小值。</p><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div role="button" tabindex="0" class="ku kv di kw bf kx"><div class="gh gi om"><img src="../Images/7fb5686eee47d088b2c4cdaed8b8bfce.png" data-original-src="https://miro.medium.com/v2/resize:fit:1240/format:webp/1*Mhh2yNwibLRsngbho5ZKwg.png"/></div></div><figcaption class="lx ly gj gh gi lz ma bd b be z dk translated">梯度下降算法，<a class="ae mb" href="https://wingshore.wordpress.com/2014/11/19/linear-regression-in-one-variable-gradient-descent-contd/" rel="noopener ugc nofollow" target="_blank">源码</a></figcaption></figure><h2 id="5fc5" class="na md iq bd me nb nc dn mi nd ne dp mm lj nf ng mo ln nh ni mq lr nj nk ms iw bi translated">实施梯度下降的步骤</h2><ol class=""><li id="1d6c" class="on oo iq lc b ld mu lg mv lj op ln oq lr or lv os ot ou ov bi translated">随机初始化值。</li><li id="7759" class="on oo iq lc b ld ow lg ox lj oy ln oz lr pa lv os ot ou ov bi translated">更新值。</li></ol><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div class="gh gi pb"><img src="../Images/ffd726fadafc6264921fdedfa2f86e9d.png" data-original-src="https://miro.medium.com/v2/resize:fit:836/format:webp/0*H_Rura6vExygdtCL.png"/></div></figure><p id="cd36" class="pw-post-body-paragraph la lb iq lc b ld le ka lf lg lh kd li lj lk ll lm ln lo lp lq lr ls lt lu lv ij bi translated">3.重复直到斜率=0</p></div><div class="ab cl nv nw hu nx" role="separator"><span class="ny bw bk nz oa ob"/><span class="ny bw bk nz oa ob"/><span class="ny bw bk nz oa"/></div><div class="ij ik il im in"><h1 id="9fac" class="mc md iq bd me mf oc mh mi mj od ml mm kf oe kg mo ki of kj mq kl og km ms mt bi translated">反向传播</h1><p id="ba82" class="pw-post-body-paragraph la lb iq lc b ld mu ka lf lg mv kd li lj mw ll lm ln mx lp lq lr my lt lu lv ij bi translated">反向传播算法可能是神经网络的组成部分。它利用一种叫做<em class="nq">链规则</em>的方法来有效地训练我们的网络。</p><p id="ed4f" class="pw-post-body-paragraph la lb iq lc b ld le ka lf lg lh kd li lj lk ll lm ln lo lp lq lr ls lt lu lv ij bi translated">现在，在这一点上，我们很清楚，我们的模型肯定是做错了什么，我们需要检查，但是，这实际上是不可能检查每一个神经元。但是，我们挽救模型的唯一可能的方法就是逆行。</p><p id="1b47" class="pw-post-body-paragraph la lb iq lc b ld le ka lf lg lh kd li lj lk ll lm ln lo lp lq lr ls lt lu lv ij bi translated">如果所有主要的权重增加，不相关的权重减少，我们将得到非常精确的输出。</p><blockquote class="nn no np"><p id="38c7" class="la lb nq lc b ld le ka lf lg lh kd li nr lk ll lm ns lo lp lq nt ls lt lu lv ij bi translated">根据赫比恩理论，“一起放电的神经元，连在一起。”</p></blockquote><p id="619f" class="pw-post-body-paragraph la lb iq lc b ld le ka lf lg lh kd li lj lk ll lm ln lo lp lq lr ls lt lu lv ij bi translated">神经网络特别依赖于权重、激活和偏差。为了开发一个有弹性和有效的模型，我们必须改变它们。</p><h2 id="f524" class="na md iq bd me nb nc dn mi nd ne dp mm lj nf ng mo ln nh ni mq lr nj nk ms iw bi translated">反向传播的步骤</h2><ul class=""><li id="4dfd" class="on oo iq lc b ld mu lg mv lj op ln oq lr or lv pc ot ou ov bi translated">我们计算输出的某些损失，并试图找出是谁造成了这种低效率。</li><li id="4447" class="on oo iq lc b ld ow lg ox lj oy ln oz lr pa lv pc ot ou ov bi translated">为此，我们将回溯整个网络。</li><li id="5f48" class="on oo iq lc b ld ow lg ox lj oy ln oz lr pa lv pc ot ou ov bi translated">假设，我们发现第二层(w3h2+b2)对我们的损失负有责任，我们会努力改变它。但是如果我们仔细考虑我们的网络，w3和b2是独立的实体，但是h2依赖于w2、b1和h1，h1进一步依赖于我们的输入，即x1、x2、x3……，xn。但是由于我们无法控制输入，我们将尝试修改w1和b1。</li></ul><p id="4b51" class="pw-post-body-paragraph la lb iq lc b ld le ka lf lg lh kd li lj lk ll lm ln lo lp lq lr ls lt lu lv ij bi translated">为了计算我们的变化，我们将使用链式法则。</p><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div role="button" tabindex="0" class="ku kv di kw bf kx"><div class="gh gi pd"><img src="../Images/1aa50f240ee6f475b3697c6e0d086aea.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*btMLCnuJtjxKNUvV.png"/></div></div><figcaption class="lx ly gj gh gi lz ma bd b be z dk translated">反向传播中的链式法则，<a class="ae mb" href="https://dzone.com/articles/the-very-basic-introduction-to-feed-forward-neural" rel="noopener ugc nofollow" target="_blank">来源</a></figcaption></figure></div><div class="ab cl nv nw hu nx" role="separator"><span class="ny bw bk nz oa ob"/><span class="ny bw bk nz oa ob"/><span class="ny bw bk nz oa"/></div><div class="ij ik il im in"><h1 id="ab65" class="mc md iq bd me mf oc mh mi mj od ml mm kf oe kg mo ki of kj mq kl og km ms mt bi translated">结论</h1><p id="8324" class="pw-post-body-paragraph la lb iq lc b ld mu ka lf lg mv kd li lj mw ll lm ln mx lp lq lr my lt lu lv ij bi translated">希望这篇文章能帮助你以最好的方式理解深度学习和反向传播，并帮助你实践它。</p><p id="68f1" class="pw-post-body-paragraph la lb iq lc b ld le ka lf lg lh kd li lj lk ll lm ln lo lp lq lr ls lt lu lv ij bi translated">一如既往，非常感谢您的阅读，如果您觉得这篇文章有用，请分享！</p></div><div class="ab cl nv nw hu nx" role="separator"><span class="ny bw bk nz oa ob"/><span class="ny bw bk nz oa ob"/><span class="ny bw bk nz oa"/></div><div class="ij ik il im in"><p id="7714" class="pw-post-body-paragraph la lb iq lc b ld le ka lf lg lh kd li lj lk ll lm ln lo lp lq lr ls lt lu lv ij bi translated">请随意连接:</p><blockquote class="nn no np"><p id="57ca" class="la lb nq lc b ld le ka lf lg lh kd li nr lk ll lm ns lo lp lq nt ls lt lu lv ij bi translated"><em class="iq">领英~</em><a class="ae mb" href="https://www.linkedin.com/in/dakshtrehan/" rel="noopener ugc nofollow" target="_blank">T3】https://www.linkedin.com/in/dakshtrehan/T5】</a></p><p id="365a" class="la lb nq lc b ld le ka lf lg lh kd li nr lk ll lm ns lo lp lq nt ls lt lu lv ij bi translated"><em class="iq">insta gram ~</em><a class="ae mb" href="https://www.instagram.com/_daksh_trehan_/" rel="noopener ugc nofollow" target="_blank"><em class="iq">https://www.instagram.com/_daksh_trehan_/</em></a></p><p id="ad5e" class="la lb nq lc b ld le ka lf lg lh kd li nr lk ll lm ns lo lp lq nt ls lt lu lv ij bi translated"><em class="iq">Github ~</em><a class="ae mb" href="https://github.com/dakshtrehan" rel="noopener ugc nofollow" target="_blank">T15】https://github.com/dakshtrehan</a></p></blockquote><p id="a819" class="pw-post-body-paragraph la lb iq lc b ld le ka lf lg lh kd li lj lk ll lm ln lo lp lq lr ls lt lu lv ij bi translated">关注更多机器学习/深度学习博客。</p><blockquote class="nn no np"><p id="06dd" class="la lb nq lc b ld le ka lf lg lh kd li nr lk ll lm ns lo lp lq nt ls lt lu lv ij bi translated"><em class="iq">中等~</em><a class="ae mb" href="https://medium.com/@dakshtrehan" rel="noopener">【https://medium.com/@dakshtrehan】T21</a></p></blockquote><h1 id="44b7" class="mc md iq bd me mf mg mh mi mj mk ml mm kf mn kg mo ki mp kj mq kl mr km ms mt bi translated">想了解更多？</h1><p id="9668" class="pw-post-body-paragraph la lb iq lc b ld mu ka lf lg mv kd li lj mw ll lm ln mx lp lq lr my lt lu lv ij bi translated"><a class="ae mb" href="https://towardsdatascience.com/detecting-covid-19-using-deep-learning-262956b6f981" rel="noopener" target="_blank">利用深度学习检测新冠肺炎</a></p><p id="edb6" class="pw-post-body-paragraph la lb iq lc b ld le ka lf lg lh kd li lj lk ll lm ln lo lp lq lr ls lt lu lv ij bi translated"><a class="ae mb" href="https://towardsdatascience.com/the-inescapable-ai-algorithm-tiktok-ad4c6fd981b8" rel="noopener" target="_blank">无法逃脱的人工智能算法:抖音</a></p><p id="442b" class="pw-post-body-paragraph la lb iq lc b ld le ka lf lg lh kd li lj lk ll lm ln lo lp lq lr ls lt lu lv ij bi translated"><a class="ae mb" href="https://medium.com/towards-artificial-intelligence/an-insiders-guide-to-cartoonization-using-machine-learning-ce3648adfe8" rel="noopener">使用机器学习的卡通化内幕指南</a></p><p id="c90b" class="pw-post-body-paragraph la lb iq lc b ld le ka lf lg lh kd li lj lk ll lm ln lo lp lq lr ls lt lu lv ij bi translated">为什么你要为乔治·弗洛伊德的谋杀和德里的骚乱负责？</p><p id="a190" class="pw-post-body-paragraph la lb iq lc b ld le ka lf lg lh kd li lj lk ll lm ln lo lp lq lr ls lt lu lv ij bi translated"><a class="ae mb" href="https://medium.com/towards-artificial-intelligence/why-choose-random-forest-and-not-decision-trees-a28278daa5d" rel="noopener">为什么选择随机森林而不是决策树</a></p><p id="b181" class="pw-post-body-paragraph la lb iq lc b ld le ka lf lg lh kd li lj lk ll lm ln lo lp lq lr ls lt lu lv ij bi translated"><a class="ae mb" href="https://medium.com/@dakshtrehan/clustering-what-it-is-when-to-use-it-a612bbe95881" rel="noopener">聚类:它是什么？什么时候用？</a></p><p id="5656" class="pw-post-body-paragraph la lb iq lc b ld le ka lf lg lh kd li lj lk ll lm ln lo lp lq lr ls lt lu lv ij bi translated"><a class="ae mb" href="https://medium.com/@dakshtrehan/start-off-your-ml-journey-with-k-nearest-neighbors-f72a122f428" rel="noopener">从k个最近邻居开始你的ML之旅</a></p><p id="e557" class="pw-post-body-paragraph la lb iq lc b ld le ka lf lg lh kd li lj lk ll lm ln lo lp lq lr ls lt lu lv ij bi translated"><a class="ae mb" href="https://medium.com/swlh/things-you-never-knew-about-naive-bayes-eb84b6ee039a" rel="noopener">朴素贝叶斯解释</a></p><p id="bf85" class="pw-post-body-paragraph la lb iq lc b ld le ka lf lg lh kd li lj lk ll lm ln lo lp lq lr ls lt lu lv ij bi translated"><a class="ae mb" href="https://medium.com/analytics-vidhya/activation-functions-explained-8690ea7bdec9" rel="noopener">激活功能说明</a></p><p id="3d03" class="pw-post-body-paragraph la lb iq lc b ld le ka lf lg lh kd li lj lk ll lm ln lo lp lq lr ls lt lu lv ij bi translated"><a class="ae mb" href="https://towardsdatascience.com/parameters-optimization-explained-876561853de0" rel="noopener" target="_blank">参数优化解释</a></p><p id="53d9" class="pw-post-body-paragraph la lb iq lc b ld le ka lf lg lh kd li lj lk ll lm ln lo lp lq lr ls lt lu lv ij bi translated"><a class="ae mb" href="https://towardsdatascience.com/gradient-descent-explained-9b953fc0d2c" rel="noopener" target="_blank">梯度下降解释</a></p><p id="b28c" class="pw-post-body-paragraph la lb iq lc b ld le ka lf lg lh kd li lj lk ll lm ln lo lp lq lr ls lt lu lv ij bi translated"><a class="ae mb" href="https://towardsdatascience.com/logistic-regression-explained-ef1d816ea85a" rel="noopener" target="_blank">逻辑回归解释</a></p><p id="1093" class="pw-post-body-paragraph la lb iq lc b ld le ka lf lg lh kd li lj lk ll lm ln lo lp lq lr ls lt lu lv ij bi translated"><a class="ae mb" href="https://medium.com/towards-artificial-intelligence/linear-regression-explained-f5cc85ae2c5c" rel="noopener">线性回归解释</a></p><p id="820f" class="pw-post-body-paragraph la lb iq lc b ld le ka lf lg lh kd li lj lk ll lm ln lo lp lq lr ls lt lu lv ij bi translated"><a class="ae mb" href="https://medium.com/datadriveninvestor/determining-perfect-fit-for-your-ml-model-339459eef670" rel="noopener">确定最适合您的ML模型</a></p><blockquote class="nn no np"><p id="0361" class="la lb nq lc b ld le ka lf lg lh kd li nr lk ll lm ns lo lp lq nt ls lt lu lv ij bi translated"><em class="iq">干杯！</em></p></blockquote></div></div>    
</body>
</html>