<html>
<head>
<title>A Journey Into the Fabulous Applications of Transformers — Part 1</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">变压器神奇应用之旅——第一部分</h1>
<blockquote>原文：<a href="https://pub.towardsai.net/a-journey-into-the-fabulous-applications-of-transformers-part-1-630cc80e3ce6?source=collection_archive---------1-----------------------#2022-12-14">https://pub.towardsai.net/a-journey-into-the-fabulous-applications-of-transformers-part-1-630cc80e3ce6?source=collection_archive---------1-----------------------#2022-12-14</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><div class=""><h2 id="fbaf" class="pw-subtitle-paragraph jn ip iq bd b jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke dk translated">演示重点是使用Python的NLP，拥抱脸。</h2></div><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi kf"><img src="../Images/c6218183058cf80fe8c9b52c31ccbb95.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*dQwyt3MtbZUl5tvW"/></div></div><figcaption class="kr ks gj gh gi kt ku bd b be z dk translated">阿瑟尼·托古列夫在<a class="ae kv" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上的照片</figcaption></figure><p id="cac4" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi ls translated">变形金刚的出现对人工智能产生了巨大的影响，尤其是在自然语言处理领域。</p><blockquote class="mb"><p id="bbc4" class="mc md iq bd me mf mg mh mi mj mk lr dk translated">变形金刚为人们期待已久的自然语言处理迁移学习的成功铺平了道路。</p></blockquote><p id="8e87" class="pw-post-body-paragraph kw kx iq ky b kz ml jr lb lc mm ju le lf mn lh li lj mo ll lm ln mp lp lq lr ij bi translated">因此，许多大型语言模型应运而生，现在我们能够在这些尖端模型之上构建有益的应用程序。</p><p id="6e5c" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">一个<a class="ae kv" href="https://arxiv.org/pdf/1706.03762.pdf" rel="noopener ugc nofollow" target="_blank">转换器</a>用更简单的语言来说就是一个两端都有<a class="ae kv" href="https://machinelearningmastery.com/the-transformer-attention-mechanism/" rel="noopener ugc nofollow" target="_blank">自关注</a>机制的编码器-解码器架构。编码器模块接收输入并将其转换为数字形式，解码器模块接收该数字形式并将其转换为文本。为了将本文局限于变压器的特定应用，我们将不深入研究其架构。请浏览<em class="mq">参考章节</em>中的链接，了解变压器的架构、发展和基本原理。</p><h1 id="c4c6" class="mr ms iq bd mt mu mv mw mx my mz na nb jw nc jx nd jz ne ka nf kc ng kd nh ni bi translated">为什么是变形金刚？</h1><p id="cdb0" class="pw-post-body-paragraph kw kx iq ky b kz nj jr lb lc nk ju le lf nl lh li lj nm ll lm ln nn lp lq lr ij bi translated">变形金刚通过启用从预训练模型中提取的特征的可用性，帮助在NLP中成功建立<strong class="ky ir"/><a class="ae kv" href="https://towardsdatascience.com/a-gentle-introduction-to-transfer-learning-in-nlp-b71e87241d66" rel="noopener" target="_blank"><strong class="ky ir">迁移学习</strong></a><strong class="ky ir"/>。</p><blockquote class="no np nq"><p id="b108" class="kw kx mq ky b kz la jr lb lc ld ju le nr lg lh li ns lk ll lm nt lo lp lq lr ij bi translated">这个想法是利用一个经过海量文本数据预处理的模型(也称为<a class="ae kv" href="https://www.kdnuggets.com/2022/09/john-snow-top-open-source-large-language-models.html" rel="noopener ugc nofollow" target="_blank">大型语言模型</a>)，根据我们自己的目的对其进行微调。随着大量时间和费用的节省，对大量训练数据的需求也大大减少，因为我们使用的是一个已经预先训练好的模型。</p></blockquote><p id="bdcb" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">这反过来又引发了对变压器的广泛研究，并带来了许多NLP预训练模型的存在。这些模型使得许多应用程序的实现成为可能，并使自然语言处理中的迁移学习得以发展。</p><h1 id="2479" class="mr ms iq bd mt mu mv mw mx my mz na nb jw nc jx nd jz ne ka nf kc ng kd nh ni bi translated">拥抱脸</h1><p id="c2d2" class="pw-post-body-paragraph kw kx iq ky b kz nj jr lb lc nk ju le lf nl lh li lj nm ll lm ln nn lp lq lr ij bi translated"><a class="ae kv" href="https://huggingface.co/" rel="noopener ugc nofollow" target="_blank">拥抱脸</a>是一个由人工智能爱好者建立的图书馆，在这里无数的模型被建立并与社区共享。拥抱脸由<a class="ae kv" href="https://huggingface.co/models" rel="noopener ugc nofollow" target="_blank">预训练模型</a>组成，用于计算机视觉、自然语言处理、音频处理、表格数据、强化学习和多模态应用等领域。使用API(应用程序编程接口)可以很容易地访问所有模型</p><blockquote class="no np nq"><p id="9268" class="kw kx mq ky b kz la jr lb lc ld ju le nr lg lh li ns lk ll lm nt lo lp lq lr ij bi translated">本文的目的是利用NLP领域，并通过演示代码和解释来探索可能的应用。</p></blockquote><p id="cce4" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">要使用任何拥抱脸模型，第一步是安装如下的<code class="fe nu nv nw nx b">transformers</code>库。</p><pre class="kg kh ki kj gt ny nx nz bn oa ob bi"><span id="bbab" class="oc ms iq nx b be od oe l of og">pip install transformers</span></pre><p id="fe25" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">下一步是利用<code class="fe nu nv nw nx b">pipeline</code>，它有助于隐藏模型实现背后的所有复杂步骤，并为模型提供一个简单易用的API。对于下面提到的每个主要应用程序，我们将看到代码和解释。拥抱脸<strong class="ky ir">中有许多模式可用于每个领域的每个任务</strong>。因为这篇文章是关于应用程序的感知，我们将利用库本身设置的默认模型。此外，考虑到本文是关于这些可能性的介绍，关于模型的细节可以从每一节给出的链接中查阅。</p><h1 id="5ae9" class="mr ms iq bd mt mu mv mw mx my mz na nb jw nc jx nd jz ne ka nf kc ng kd nh ni bi translated">应用程序</h1><p id="273d" class="pw-post-body-paragraph kw kx iq ky b kz nj jr lb lc nk ju le lf nl lh li lj nm ll lm ln nn lp lq lr ij bi translated">在本文讨论的所有应用程序中，我们都将遵循这些步骤。</p><blockquote class="no np nq"><p id="925b" class="kw kx mq ky b kz la jr lb lc ld ju le nr lg lh li ns lk ll lm nt lo lp lq lr ij bi translated">1.进口<code class="fe nu nv nw nx b">pipeline</code></p><p id="5806" class="kw kx mq ky b kz la jr lb lc ld ju le nr lg lh li ns lk ll lm nt lo lp lq lr ij bi translated">2.通过实例化<code class="fe nu nv nw nx b">pipeline.</code>来调用相应任务的模型。在该步骤中，下载任务的默认模型的模型权重。</p><p id="7c78" class="kw kx mq ky b kz la jr lb lc ld ju le nr lg lh li ns lk ll lm nt lo lp lq lr ij bi translated">3.通过给出所需的输入来利用该模型。</p><p id="f0b4" class="kw kx mq ky b kz la jr lb lc ld ju le nr lg lh li ns lk ll lm nt lo lp lq lr ij bi translated">4.查看结果并尝试不同的输入。</p></blockquote><p id="cbf0" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">所有应用程序的代码和输出都在这个<a class="ae kv" href="https://github.com/dharini-projects/NLP_Applications_with_Transformers" rel="noopener ugc nofollow" target="_blank"> GitHub库</a>中给出，还有一个Google Colab链接。</p><p id="ac64" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">本文中讨论的应用有</p><blockquote class="no np nq"><p id="b3c4" class="kw kx mq ky b kz la jr lb lc ld ju le nr lg lh li ns lk ll lm nt lo lp lq lr ij bi translated"><a class="ae kv" href="#af17" rel="noopener ugc nofollow"> 1。文本分类</a></p><p id="fa8f" class="kw kx mq ky b kz la jr lb lc ld ju le nr lg lh li ns lk ll lm nt lo lp lq lr ij bi translated"><a class="ae kv" href="#f630" rel="noopener ugc nofollow"> 2。文本摘要</a></p><p id="9309" class="kw kx mq ky b kz la jr lb lc ld ju le nr lg lh li ns lk ll lm nt lo lp lq lr ij bi translated"><a class="ae kv" href="#0a57" rel="noopener ugc nofollow"> 3。问题解答</a></p><p id="307d" class="kw kx mq ky b kz la jr lb lc ld ju le nr lg lh li ns lk ll lm nt lo lp lq lr ij bi translated"><a class="ae kv" href="#2dc3" rel="noopener ugc nofollow"> 4。文本生成</a></p><p id="e66a" class="kw kx mq ky b kz la jr lb lc ld ju le nr lg lh li ns lk ll lm nt lo lp lq lr ij bi translated"><a class="ae kv" href="#af1d" rel="noopener ugc nofollow"> 5。命名实体识别</a></p></blockquote><h2 id="af17" class="oh ms iq bd mt oi oj dn mx ok ol dp nb lf om on nd lj oo op nf ln oq or nh os bi translated">1.文本分类</h2><p id="3cc1" class="pw-post-body-paragraph kw kx iq ky b kz nj jr lb lc nk ju le lf nl lh li lj nm ll lm ln nn lp lq lr ij bi translated">分类是将给定文本放入任何一个已知类别的过程。让我们开始导入所需的库，如下所示。</p><p id="ca26" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">下一步是初始化一个名为<code class="fe nu nv nw nx b">text_classifier</code>的变量，它表示在<code class="fe nu nv nw nx b">text-classification</code>类别中被调用的模型。我们知道，模型是由<code class="fe nu nv nw nx b">pipeline</code>函数使用任务名调用的。由于没有给出具体的模型名称，因此将下载默认模型(<code class="fe nu nv nw nx b">distilbert-base-uncased-finetuned-sst-2-english</code>)，这可以在下面的输出中看到。</p><pre class="kg kh ki kj gt ny nx nz bn oa ob bi"><span id="7513" class="oc ms iq nx b be od oe l of og">from transformers import pipeline<br/>text_classifier = pipeline("text-classification")<br/><br/>Output:<br/>No model was supplied, defaulted to distilbert-base-uncased-finetuned-sst-2-english and revision af0f99b (https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english).<br/>Using a pipeline without specifying a model name and revision in production is not recommended.<br/>Downloading: 100%<br/>629/629 [00:00&lt;00:00, 24.4kB/s]<br/>Downloading: 100%<br/>268M/268M [00:05&lt;00:00, 62.8MB/s]<br/>Downloading: 100%<br/>48.0/48.0 [00:00&lt;00:00, 1.70kB/s]<br/>Downloading: 100%<br/>232k/232k [00:00&lt;00:00, 6.48MB/s]</span></pre><p id="c26c" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">下一步，我们使用初始化变量<code class="fe nu nv nw nx b">text_classifier.</code>向文本分类模型提供输入。被调用的模型帮助我们对给定文本进行分类，并对文本的<code class="fe nu nv nw nx b">POSITIVE</code>和<code class="fe nu nv nw nx b">NEGATIVE</code>情感进行评分。有关该型号的更多信息，请点击此<a class="ae kv" href="https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english" rel="noopener ugc nofollow" target="_blank">链接</a>。</p><p id="4375" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">在下面给出的代码中，给出了一个表示负面情绪的句子，结果存储在<code class="fe nu nv nw nx b">clf_result.</code>中。在打印输出时，我们可以看到模型将该句子归类到<code class="fe nu nv nw nx b">NEGATIVE</code>类别中，并给出了一个<code class="fe nu nv nw nx b">score</code>(表示情绪得分)。</p><pre class="kg kh ki kj gt ny nx nz bn oa ob bi"><span id="fbd9" class="oc ms iq nx b be od oe l of og">clf_result = text_classifier("Oh God!!!! Its so horrible to hear about the news of aircraft")<br/>print(clf_result)<br/><br/>Output<br/>[{'label': 'NEGATIVE', 'score': 0.9992474317550659}]</span></pre><p id="1ace" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">现在让我们试试另一个句子，看看结果。在下面的代码片段中，可以看到结果是<code class="fe nu nv nw nx b">POSITIVE</code>标签，因为我们给出了一个表示解脱的语句。</p><pre class="kg kh ki kj gt ny nx nz bn oa ob bi"><span id="d8d7" class="oc ms iq nx b be od oe l of og">clf_result = text_classifier("Oh God!!!! So relieved to hear about the aircraft")<br/>print(clf_result)<br/><br/>Output<br/>[{'label': 'POSITIVE', 'score': 0.9974811673164368}]</span></pre><h2 id="f630" class="oh ms iq bd mt oi oj dn mx ok ol dp nb lf om on nd lj oo op nf ln oq or nh os bi translated">2.文本摘要</h2><p id="dadf" class="pw-post-body-paragraph kw kx iq ky b kz nj jr lb lc nk ju le lf nl lh li lj nm ll lm ln nn lp lq lr ij bi translated">文本摘要是从给定的一组句子中提取摘要的任务。第一步是导入<code class="fe nu nv nw nx b">pipeline</code>，接下来，我们用自己选择的任务进行实例化(<code class="fe nu nv nw nx b">summarization</code>)。文本摘要的默认模型是<code class="fe nu nv nw nx b">sshleifer/distilbart-cnn-12–6</code>，要了解关于该模型的更多信息，请查看此<a class="ae kv" href="https://huggingface.co/sshleifer/distilbart-cnn-12-6" rel="noopener ugc nofollow" target="_blank">链接</a>。在变量<code class="fe nu nv nw nx b">text_summarizer.</code>下调用模型</p><pre class="kg kh ki kj gt ny nx nz bn oa ob bi"><span id="8dc4" class="oc ms iq nx b be od oe l of og">from transformers import pipeline<br/>text_summarizer = pipeline("summarization")<br/><br/>Output:<br/>No model was supplied, defaulted to sshleifer/distilbart-cnn-12-6 and revision a4f8f3e (https://huggingface.co/sshleifer/distilbart-cnn-12-6).<br/>Using a pipeline without specifying a model name and revision in production is not recommended.<br/>Downloading: 100%<br/>1.80k/1.80k [00:00&lt;00:00, 47.4kB/s]<br/>Downloading: 100%<br/>1.22G/1.22G [00:50&lt;00:00, 47.4MB/s]<br/>Downloading: 100%<br/>26.0/26.0 [00:00&lt;00:00, 460B/s]<br/>Downloading: 100%<br/>899k/899k [00:00&lt;00:00, 1.60MB/s]<br/>Downloading: 100%<br/>456k/456k [00:00&lt;00:00, 1.73MB/s]<br/></span></pre><p id="1261" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">下面的代码片段显示了加载了要汇总的文本的<code class="fe nu nv nw nx b">input_text</code>变量。</p><pre class="kg kh ki kj gt ny nx nz bn oa ob bi"><span id="794d" class="oc ms iq nx b be od oe l of og">input_text = """Education is a purposeful activity directed at achieving certain aims,<br/>such as transmitting knowledge or fostering skills and character traits. <br/>These aims may include the development of understanding, rationality, kindness, and honesty. <br/>Various researchers emphasize the role of critical thinking in order to distinguish education <br/>from indoctrination. Some theorists require that education results in an improvement of the student <br/>while others prefer a value-neutral definition of the term. In a slightly different sense, education<br/>may also refer, not to the process, but to the product of this process: the mental states and dispositions <br/>possessed by educated people. Education originated as the transmission of cultural heritage from one generation <br/>to the next. Today, educational goals increasingly encompass new ideas such as the liberation of learners, skills <br/>needed for modern society, empathy, and complex vocational skills."""</span></pre><p id="95be" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">使用<code class="fe nu nv nw nx b">text_summarizer,</code>我们给模型输入，以及一个提到摘要最大长度的参数。在打印输出时，我们可以看到如下摘要。</p><pre class="kg kh ki kj gt ny nx nz bn oa ob bi"><span id="375a" class="oc ms iq nx b be od oe l of og">summary = text_summarizer(input_text, max_length =100)<br/>print(summary[0]['summary_text'])<br/><br/>Output:<br/>Some theorists require that education results in an improvement of the student.<br/>Others prefer a value-neutral definition of the term. Education originated <br/>as the transmission of cultural heritage from one generation to the next. <br/>Today, educational goals increasingly encompass new ideas such as the <br/>liberation of learners, skills needed for modern society, empathy, and <br/>complex vocational skills.</span></pre><h2 id="0a57" class="oh ms iq bd mt oi oj dn mx ok ol dp nb lf om on nd lj oo op nf ln oq or nh os bi translated">3.问题回答</h2><p id="cc23" class="pw-post-body-paragraph kw kx iq ky b kz nj jr lb lc nk ju le lf nl lh li lj nm ll lm ln nn lp lq lr ij bi translated">变形金刚的另一个有趣的应用是构建问答系统的能力。这个想法是提供一个模型，一组句子作为理解的背景。基于这种理解，模型给出了问题的答案。更简单地说，<strong class="ky ir">模型理解上下文，并基于该上下文提取问题的相关答案。</strong></p><p id="575b" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">为了利用QA模型，让我们首先用任务<code class="fe nu nv nw nx b">question-answering</code>实例化<code class="fe nu nv nw nx b">pipeline</code>。任务的默认模型是<code class="fe nu nv nw nx b"><a class="ae kv" href="https://huggingface.co/distilbert-base-cased-distilled-squad" rel="noopener ugc nofollow" target="_blank">distilbert-base-cased-distilled-squad</a>,</code>，因此模型权重被下载。正如我们在下面的代码片段中看到的，该模型使用用户定义的变量<code class="fe nu nv nw nx b">qna_model</code>来引用。</p><pre class="kg kh ki kj gt ny nx nz bn oa ob bi"><span id="9d71" class="oc ms iq nx b be od oe l of og">from transformers import pipeline<br/>qna_model = pipeline("question-answering")<br/><br/>Output:<br/>No model was supplied, defaulted to distilbert-base-cased-distilled-squad and revision 626af31 (https://huggingface.co/distilbert-base-cased-distilled-squad).<br/>Using a pipeline without specifying a model name and revision in production is not recommended.<br/>Downloading: 100%<br/>473/473 [00:00&lt;00:00, 2.63kB/s]<br/>Downloading: 100%<br/>261M/261M [00:06&lt;00:00, 51.3MB/s]<br/>Downloading: 100%<br/>29.0/29.0 [00:00&lt;00:00, 508B/s]<br/>Downloading: 100%<br/>213k/213k [00:00&lt;00:00, 1.49MB/s]<br/>Downloading: 100%<br/>436k/436k [00:00&lt;00:00, 1.09MB/s]</span></pre><p id="c1f9" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">下面，我们给出了一组关于GitHub的句子(<code class="fe nu nv nw nx b">input_text</code>)，模型将其作为上下文进行学习。</p><pre class="kg kh ki kj gt ny nx nz bn oa ob bi"><span id="6972" class="oc ms iq nx b be od oe l of og">input_text = """GitHub Inc is an Internet hosting service for software development <br/>and version control using Git. It provides the distributed version control of <br/>Git plus access control, bug tracking, software feature requests, task management,<br/>continuous integration, and wikis for every project. Headquartered in California, <br/>it has been a subsidiary of Microsoft since 2018. <br/>It is commonly used to host open source software development projects. <br/>As of June 2022, GitHub reported having over 83 million developers and more <br/>than 200 million repositories, including at least 28 million public <br/>repositories. It is the largest source code host as of November 2021.<br/>"""</span></pre><p id="a6a4" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">如下所示，我们根据<code class="fe nu nv nw nx b">input_text </code>提出了三个问题。<code class="fe nu nv nw nx b">question_1</code>是提取GitHub的一个定义，<code class="fe nu nv nw nx b">question_2</code>是为了提取一个数字，<code class="fe nu nv nw nx b">question_3</code>是为了看模型如何根据上下文回答一个是/否的问题。</p><pre class="kg kh ki kj gt ny nx nz bn oa ob bi"><span id="751a" class="oc ms iq nx b be od oe l of og">question_1 = "What is GitHub?"<br/>question_2 = "How many repositories does GitHub have?"<br/>question_3 = "Can I use GitHub to host my project?"</span></pre><p id="ec4e" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">现在让我们将<code class="fe nu nv nw nx b">input_text</code>作为上下文，将<code class="fe nu nv nw nx b">question_1</code>作为问题提供给模型，并打印出答案。瞧，我们有一个模型可以帮助我们理解一篇文章并快速得到答案！！</p><pre class="kg kh ki kj gt ny nx nz bn oa ob bi"><span id="1bf8" class="oc ms iq nx b be od oe l of og">answer_1 = qna_model(question = question_1, context = input_text)<br/>print(answer_1)<br/><br/>Output:<br/>{'score': 0.17357327044010162,<br/> 'start': 14,<br/> 'end': 86,<br/> 'answer': 'an Internet hosting service for software development and version control'}</span></pre><p id="45d4" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">同理，让我们试试另外两个问题，看看结果。</p><pre class="kg kh ki kj gt ny nx nz bn oa ob bi"><span id="7375" class="oc ms iq nx b be od oe l of og">answer_2 = qna_model(question = question_2, context = input_text)<br/>print(answer_2)<br/><br/>Output:<br/>{'score': 0.3084281086921692,<br/> 'start': 506,<br/> 'end': 527,<br/> 'answer': 'more than 200 million'}</span></pre><pre class="ot ny nx nz bn oa ob bi"><span id="20f7" class="oc ms iq nx b be od oe l of og">answer_3 = qna_model(question = question_3, context = input_text)<br/>answer_3<br/><br/>Output:<br/>{'score': 0.471432626247406,<br/> 'start': 364,<br/> 'end': 433,<br/> 'answer': 'It is commonly used to host open source software development projects'}</span></pre><p id="d41d" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">前两个问题给了我们想要的答案。第三个问题的答案实际上是肯定的，模型通过指出在GitHub中托管项目的可能性做出了类似的回答。</p><h2 id="2dc3" class="oh ms iq bd mt oi oj dn mx ok ol dp nb lf om on nd lj oo op nf ln oq or nh os bi translated">4.文本生成</h2><p id="15bc" class="pw-post-body-paragraph kw kx iq ky b kz nj jr lb lc nk ju le lf nl lh li lj nm ll lm ln nn lp lq lr ij bi translated">下一个有趣的应用是使用变压器生成文本。我们可以通过提供<code class="fe nu nv nw nx b">prompt,</code> <code class="fe nu nv nw nx b">max_length</code>和<code class="fe nu nv nw nx b">num_return_sequences</code>来利用文本生成模型。顾名思义，<code class="fe nu nv nw nx b">max_length</code>表示生成的文本长度，<code class="fe nu nv nw nx b">num_return_seuqences</code>表示生成的文本数量。A <code class="fe nu nv nw nx b">prompt</code>是模型基于其生成新单词的<strong class="ky ir">上下文/想法</strong>。</p><p id="24fb" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">在下面的代码中，我们用<code class="fe nu nv nw nx b">text-generation</code>任务实例化<code class="fe nu nv nw nx b">pipeline</code>,默认模型的(<code class="fe nu nv nw nx b">gpt2,</code>查看此<a class="ae kv" href="https://huggingface.co/gpt2" rel="noopener ugc nofollow" target="_blank">链接</a>了解更多细节)权重被加载到变量<code class="fe nu nv nw nx b">text_generator.</code>中</p><pre class="kg kh ki kj gt ny nx nz bn oa ob bi"><span id="ee87" class="oc ms iq nx b be od oe l of og">from transformers import pipeline<br/>text_generator = pipeline("text-generation")<br/><br/>Output:<br/>No model was supplied, defaulted to gpt2 and revision 6c0e608 (https://huggingface.co/gpt2).<br/>Using a pipeline without specifying a model name and revision in production is not recommended.<br/>Downloading: 100%<br/>665/665 [00:00&lt;00:00, 14.2kB/s]<br/>Downloading: 100%<br/>548M/548M [00:11&lt;00:00, 40.0MB/s]<br/>Downloading: 100%<br/>1.04M/1.04M [00:00&lt;00:00, 3.07MB/s]<br/>Downloading: 100%<br/>456k/456k [00:00&lt;00:00, 867kB/s]<br/>Downloading: 100%<br/>1.36M/1.36M [00:00&lt;00:00, 3.09MB/s]<br/></span></pre><p id="0ad1" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">我们将看到三个不同提示的例子。前两个提示是关于'<em class="mq">基于AI的文本生成'</em>。第一个如下所示。</p><pre class="kg kh ki kj gt ny nx nz bn oa ob bi"><span id="e3d3" class="oc ms iq nx b be od oe l of og">prompt = "AI based text generation is"<br/>text_generator(prompt, max_length=30, num_return_sequences=5)<br/>Output:<br/>Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.<br/>[{'generated_text': 'AI based text generation is a great idea as for you do not need to build and deploy your own font. The free font solution is the free Font'},<br/> {'generated_text': 'AI based text generation is the only system that\'s able to take the power of the internet offline."\n\nIt will work with all services underwritten'},<br/> {'generated_text': 'AI based text generation is available that can work with any text size on one device, including on computers running Windows or OSX. The Microsoft RDR'},<br/> {'generated_text': 'AI based text generation is used in this research to create a novel, non-text vector for the translation of human words, which will help reduce the'},<br/> {'generated_text': 'AI based text generation is essential to the efficiency of our business.\n\nIt may take a while but the key is using it to be productive for'}]</span></pre><p id="74f4" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">第一个和第二个提示的区别是给出的最后一个单词。在第一个例子中，我们给出了“<em class="mq">是</em>”，在第二个例子中，我们给出了“<em class="mq">是</em>”。从下面的输出可以非常清楚地看出，模型是如何根据提示高效地生成的。</p><pre class="kg kh ki kj gt ny nx nz bn oa ob bi"><span id="a53c" class="oc ms iq nx b be od oe l of og">prompt = "AI based text generation was"<br/>text_generator(prompt, max_length=30, num_return_sequences=5)<br/>Output:<br/>Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.<br/>[{'generated_text': 'AI based text generation was done on a fully automated system (i.e., that uses the current technology, the first machine to run the command,'},<br/> {'generated_text': 'AI based text generation was launched in 2010 in Turkey.\n\nThe first of this type of font will be available to the public from the next month'},<br/> {'generated_text': 'AI based text generation was born in 1995 on the idea that we should build a set of models that would automatically detect and translate the text in real time'},<br/> {'generated_text': 'AI based text generation was a major problem. Text is generated in both high performance and non-proprietary ways. As in every other field,'},<br/> {'generated_text': 'AI based text generation was built. However, we never considered a lot of ways to address the many potential issues with what we created with Text.org'}]</span></pre><p id="32e3" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">第三个提示是关于'<em class="mq">使用GitHub，</em>结果可以看到下面。同样明显的是，该模型不会重复生成的句子，而是生成不同的句子。</p><pre class="kg kh ki kj gt ny nx nz bn oa ob bi"><span id="15e3" class="oc ms iq nx b be od oe l of og">prompt = "I am using Github to"<br/>text_generator(prompt, max_length=30, num_return_sequences=5)<br/>Output:<br/>Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.<br/>[{'generated_text': "I am using Github to get the job done so I'll have to follow through in this tutorial. I created all the tutorials on youtube, but I"},<br/> {'generated_text': 'I am using Github to start a new project, and I am wondering if you can help me make some modifications and give the repository a try.\n'},<br/> {'generated_text': 'I am using Github to start a blog, and this is how I create what I call a monthly blog.\n\nIf you run into anything,'},<br/> {'generated_text': 'I am using Github to serve the rest of the system.\n\nCreate an executable:\n\nimport os import os.path as path path ='},<br/> {'generated_text': "I am using Github to post updates to my work. I don't understand why people want to check in on my work and delete it while it is"}]</span></pre><h2 id="af1d" class="oh ms iq bd mt oi oj dn mx ok ol dp nb lf om on nd lj oo op nf ln oq or nh os bi translated">5.命名实体识别</h2><p id="8644" class="pw-post-body-paragraph kw kx iq ky b kz nj jr lb lc nk ju le lf nl lh li lj nm ll lm ln nn lp lq lr ij bi translated">变形金刚系列的下一个重要应用是识别给定文本中的实体。实体可以是个人、组织、位置等。</p><p id="724d" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">第一步，用<code class="fe nu nv nw nx b">ner</code>实例化<code class="fe nu nv nw nx b">pipeline</code>作为预期任务。默认模型是<code class="fe nu nv nw nx b">bert-large-cased-finetuned-conll03-english</code>，相应的模型权重被下载到<code class="fe nu nv nw nx b">named_entity_recognition</code>。</p><pre class="kg kh ki kj gt ny nx nz bn oa ob bi"><span id="8032" class="oc ms iq nx b be od oe l of og">from transformers import pipeline<br/>named_entity_recognition = pipeline("ner", aggregation_strategy = "simple")<br/><br/>Output:<br/>No model was supplied, defaulted to dbmdz/bert-large-cased-finetuned-conll03-english and revision f2482bf (https://huggingface.co/dbmdz/bert-large-cased-finetuned-conll03-english).<br/>Using a pipeline without specifying a model name and revision in production is not recommended.<br/>Downloading: 100%<br/>998/998 [00:00&lt;00:00, 23.5kB/s]<br/>Downloading: 100%<br/>1.33G/1.33G [00:42&lt;00:00, 41.7MB/s]<br/>Downloading: 100%<br/>60.0/60.0 [00:00&lt;00:00, 1.07kB/s]<br/>Downloading: 100%<br/>213k/213k [00:00&lt;00:00, 1.85MB/s]</span></pre><p id="5d72" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">现在，我们用一组句子加载<code class="fe nu nv nw nx b">input_text</code>来提取实体。</p><pre class="kg kh ki kj gt ny nx nz bn oa ob bi"><span id="b43c" class="oc ms iq nx b be od oe l of og">input_text = """GitHub Inc is an Internet hosting service for software <br/>development and version control using Git. It provides the distributed <br/>version control of Git plus access control, bug tracking, software feature <br/>requests, task management, continuous integration, and wikis for every project.<br/>Headquartered in California, it has been a subsidiary of Microsoft since 2018. <br/>It is commonly used to host open source software development projects. <br/>As of June 2022, GitHub reported having over 83 million developers and <br/>more than 200 million repositories, including at least 28 million public <br/>repositories. It is the largest source code host as of November 2021.<br/>"""</span></pre><p id="818e" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">对于模型(<code class="fe nu nv nw nx b">named_entity_recognition</code>)，我们给出<code class="fe nu nv nw nx b">input_text</code>并打印结果(<code class="fe nu nv nw nx b">tags</code>)。我们可以看到GitHub Inc，微软，GitHub被命名为组织，California被命名为位置，Internet，Git被命名为杂项。输出还会提到单词的开头和结尾，以及每个分类的分数。</p><pre class="kg kh ki kj gt ny nx nz bn oa ob bi"><span id="fbd4" class="oc ms iq nx b be od oe l of og">ctags = named_entity_recognition(input_text)<br/>print(tags)<br/><br/>Output:<br/>[{'entity_group': 'ORG',<br/>  'score': 0.99605906,<br/>  'word': 'GitHub Inc',<br/>  'start': 0,<br/>  'end': 10},<br/> {'entity_group': 'MISC',<br/>  'score': 0.91944593,<br/>  'word': 'Internet',<br/>  'start': 17,<br/>  'end': 25},<br/> {'entity_group': 'MISC',<br/>  'score': 0.9152951,<br/>  'word': 'Git',<br/>  'start': 93,<br/>  'end': 96},<br/> {'entity_group': 'MISC',<br/>  'score': 0.93599296,<br/>  'word': 'Git',<br/>  'start': 145,<br/>  'end': 148},<br/> {'entity_group': 'LOC',<br/>  'score': 0.9990779,<br/>  'word': 'California',<br/>  'start': 301,<br/>  'end': 311},<br/> {'entity_group': 'ORG',<br/>  'score': 0.9995492,<br/>  'word': 'Microsoft',<br/>  'start': 341,<br/>  'end': 350},<br/> {'entity_group': 'ORG',<br/>  'score': 0.9892499,<br/>  'word': 'GitHub',<br/>  'start': 452,<br/>  'end': 458}]</span></pre><p id="a6fb" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">为了以更易读的形式查看结果，我们可以安装并导入<code class="fe nu nv nw nx b">pandas</code>库，并创建输出的<code class="fe nu nv nw nx b">DataFrame</code>(<code class="fe nu nv nw nx b">tags</code>)。打印它会给我们一个标签表，如下所示。</p><pre class="kg kh ki kj gt ny nx nz bn oa ob bi"><span id="0f62" class="oc ms iq nx b be od oe l of og">import pandas as pd<br/>tags = named_entity_recognition(input_text)<br/>pd.DataFrame(tags)<br/>print(tags)<br/><br/>Output:<br/>entity_group  score    word       start end<br/>0 ORG         0.996059 GitHub Inc   0   10<br/>1 MISC        0.919446 Internet    17   25<br/>2 MISC        0.915295 Git         93   96<br/>3 MISC        0.935993 Git         145  148<br/>4 LOC         0.999078 California  301  311<br/>5 ORG         0.999549 Microsoft   341  350<br/>6 ORG         0.989250 GitHub      452  458</span></pre><h2 id="2d31" class="oh ms iq bd mt oi oj dn mx ok ol dp nb lf om on nd lj oo op nf ln oq or nh os bi translated">摘要</h2><p id="a3f3" class="pw-post-body-paragraph kw kx iq ky b kz nj jr lb lc nk ju le lf nl lh li lj nm ll lm ln nn lp lq lr ij bi translated">在本文中，我们介绍了变形金刚及其在迁移学习中的辅助作用。我们还看到了利用拥抱脸模型的简单步骤。我们经历了各种应用程序，如情感分析、摘要、问题回答、文本生成和命名实体生成。还有更多的应用程序需要探索，这将在本文的第2部分中讨论。</p><div class="ou ov gp gr ow ox"><a rel="noopener  ugc nofollow" target="_blank" href="/a-journey-into-the-fabulous-applications-of-transformers-part-2-81a349a70cf3"><div class="oy ab fo"><div class="oz ab pa cl cj pb"><h2 class="bd ir gy z fp pc fr fs pd fu fw ip bi translated">变压器神奇应用之旅——第二部分</h2><div class="pe l"><h3 class="bd b gy z fp pc fr fs pd fu fw dk translated">演示重点是自然语言处理使用Python，拥抱脸</h3></div><div class="pf l"><p class="bd b dl z fp pc fr fs pd fu fw dk translated">pub.towardsai.net</p></div></div><div class="pg l"><div class="ph l pi pj pk pg pl kp ox"/></div></div></a></div><p id="b72b" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">了解了所有这些令人着迷的应用程序的可能性之后，选择一个你感兴趣的任务，并为该任务尝试不同的模型和输入。</p><p id="e065" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">前进，成功！！！！</p><h2 id="d1cc" class="oh ms iq bd mt oi oj dn mx ok ol dp nb lf om on nd lj oo op nf ln oq or nh os bi translated">参考</h2><ul class=""><li id="e6fa" class="pm pn iq ky b kz nj lc nk lf po lj pp ln pq lr pr ps pt pu bi translated">变形金刚的自然语言处理:用拥抱脸构建语言应用程序。</li><li id="7454" class="pm pn iq ky b kz pv lc pw lf px lj py ln pz lr pr ps pt pu bi translated">https://jalammar.github.io/illustrated-transformer/<a class="ae kv" href="https://jalammar.github.io/illustrated-transformer/" rel="noopener ugc nofollow" target="_blank"/></li><li id="f790" class="pm pn iq ky b kz pv lc pw lf px lj py ln pz lr pr ps pt pu bi translated">【https://towardsdatascience.com/transformers-89034557de14 T4】</li><li id="5d09" class="pm pn iq ky b kz pv lc pw lf px lj py ln pz lr pr ps pt pu bi translated"><a class="ae kv" href="https://www.youtube.com/watch?v=KmAISyVvE1Y&amp;list=PLIXJ-Sacf8u60G1TwcznBmK6rEL3gmZmV" rel="noopener ugc nofollow" target="_blank">https://www.youtube.com/watch?v=KmAISyVvE1Y&amp;list = PLIXJ-sacf 8 u 60g 1 twcznbmk 6 rel 3 gmzmv</a></li></ul><blockquote class="no np nq"><p id="5e6d" class="kw kx mq ky b kz la jr lb lc ld ju le nr lg lh li ns lk ll lm nt lo lp lq lr ij bi translated">请在此<a class="ae kv" href="https://medium.com/@dharini_r" rel="noopener">页面</a>中找到更多与NLP相关的文章。</p><p id="b740" class="kw kx mq ky b kz la jr lb lc ld ju le nr lg lh li ns lk ll lm nt lo lp lq lr ij bi translated">谢谢大家！！</p></blockquote></div></div>    
</body>
</html>