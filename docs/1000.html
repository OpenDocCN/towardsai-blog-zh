<html>
<head>
<title>Old Photo Restoration using Deep Learning</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">使用深度学习的旧照片恢复</h1>
<blockquote>原文：<a href="https://pub.towardsai.net/old-photo-restoration-using-deep-learning-47d4ab1bdc4d?source=collection_archive---------0-----------------------#2020-10-04">https://pub.towardsai.net/old-photo-restoration-using-deep-learning-47d4ab1bdc4d?source=collection_archive---------0-----------------------#2020-10-04</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><h2 id="ff54" class="ir is it bd b dl iu iv iw ix iy iz dk ja translated" aria-label="kicker paragraph"><a class="ae ep" href="https://towardsai.net/p/category/machine-learning/deep-learning" rel="noopener ugc nofollow" target="_blank">深度学习</a></h2><div class=""/><div class=""><h2 id="2581" class="pw-subtitle-paragraph jz jc it bd b ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq dk translated">想象一下，你有你祖母18岁时的旧的、折叠的、甚至撕破的高清照片，没有任何瑕疵！</h2></div><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div class="gh gi kr"><img src="../Images/28b9935899999be9908db520d7e4863b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1376/format:webp/1*nNtCKVlQ7fzkGn-uzlTvsQ.png"/></div><figcaption class="kz la gj gh gi lb lc bd b be z dk translated">图片来自https://arxiv.org/pdf/2009.07047.pdf<a class="ae ld" href="https://arxiv.org/pdf/2009.07047.pdf" rel="noopener ugc nofollow" target="_blank"/></figcaption></figure><p id="ba35" class="pw-post-body-paragraph le lf it lg b lh li kd lj lk ll kg lm ln lo lp lq lr ls lt lu lv lw lx ly lz im bi translated">想象一下，你有你祖母18岁时的旧的，折叠的，甚至撕破的高清照片，没有任何瑕疵。<br/>这被称为旧照片恢复，这篇论文刚刚开辟了一条全新的途径，使用深度学习方法来解决这个问题。</p><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="ma mb di mc bf md"><div class="gh gi gj"><img src="../Images/cd71a6dcb2b9cbaa5935a4b9c25caf98.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Ifw22eS0Et1ySnRohyVe8g.png"/></div></div><figcaption class="kz la gj gh gi lb lc bd b be z dk translated"><a class="ae ld" href="https://arxiv.org/pdf/2009.07047.pdf" rel="noopener ugc nofollow" target="_blank">https://arxiv.org/pdf/2009.07047.pdf</a></figcaption></figure></div><div class="ab cl me mf hx mg" role="separator"><span class="mh bw bk mi mj mk"/><span class="mh bw bk mi mj mk"/><span class="mh bw bk mi mj"/></div><div class="im in io ip iq"><h2 id="0b5d" class="ml mm it bd mn mo mp dn mq mr ms dp mt ln mu mv mw lr mx my mz lv na nb nc iz bi translated">技术概述</h2><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div class="gh gi nd"><img src="../Images/14ad87be943ae48fc648459c6960acc5.png" data-original-src="https://miro.medium.com/v2/resize:fit:686/format:webp/1*JbEvXdG6qPycvL6aitCBZQ.png"/></div><figcaption class="kz la gj gh gi lb lc bd b be z dk translated">图片来自<a class="ae ld" href="https://arxiv.org/pdf/2009.07047.pdf" rel="noopener ugc nofollow" target="_blank">https://arxiv.org/pdf/2009.07047.pdf</a></figcaption></figure><p id="912f" class="pw-post-body-paragraph le lf it lg b lh li kd lj lk ll kg lm ln lo lp lq lr ls lt lu lv lw lx ly lz im bi translated">复古照片复原是计算机视觉的一个重要领域。我们都希望亲人的老照片清晰好看。</p><p id="4d99" class="pw-post-body-paragraph le lf it lg b lh li kd lj lk ll kg lm ln lo lp lq lr ls lt lu lv lw lx ly lz im bi translated">一张这样的照片并没有像这张更好看的照片那样给人带来荣誉，也没有给人带来那么多美好的回忆。</p><p id="e32e" class="pw-post-body-paragraph le lf it lg b lh li kd lj lk ll kg lm ln lo lp lq lr ls lt lu lv lw lx ly lz im bi translated">我们都至少有一张我们在乎的老照片，随着时间的推移，它看起来越来越差。这就是为什么许多人正在努力解决这个问题。</p><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div class="gh gi ne"><img src="../Images/4ae847d5e33d40b2958e55ab9940aa2b.png" data-original-src="https://miro.medium.com/v2/resize:fit:680/format:webp/1*xr7FbMAsGFkgQey2iY_swg.png"/></div><figcaption class="kz la gj gh gi lb lc bd b be z dk translated">图片来自<a class="ae ld" href="https://arxiv.org/pdf/2009.07047.pdf" rel="noopener ugc nofollow" target="_blank">https://arxiv.org/pdf/2009.07047.pdf</a></figcaption></figure><p id="6cd7" class="pw-post-body-paragraph le lf it lg b lh li kd lj lk ll kg lm ln lo lp lq lr ls lt lu lv lw lx ly lz im bi translated">在本文中，来自香港大学和微软研究院的研究人员提出了一种新的网络来解决这一问题，称为“通过深层潜在空间翻译恢复旧照片”。</p><p id="dafa" class="pw-post-body-paragraph le lf it lg b lh li kd lj lk ll kg lm ln lo lp lq lr ls lt lu lv lw lx ly lz im bi translated">他们正在使用深度学习来恢复遭受严重退化的旧照片，就像这张一样。</p><p id="932a" class="pw-post-body-paragraph le lf it lg b lh li kd lj lk ll kg lm ln lo lp lq lr ls lt lu lv lw lx ly lz im bi translated">目前有许多可用的方法，甚至为此开发了商业应用程序，但是这种新技术产生的结果比所有方法都好！看看最好的商业应用程序，如Remini或美图，可以对这些图片做些什么，以及研究人员通过他们的技术获得的结果:</p><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div class="gh gi nf"><img src="../Images/ac67c3954bd76858ba8fd3f6b11cca9c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1348/format:webp/1*eQ7IKWiqJ9S4mEnBQFnLvg.png"/></div><figcaption class="kz la gj gh gi lb lc bd b be z dk translated">图片来自<a class="ae ld" href="https://arxiv.org/pdf/2009.07047.pdf" rel="noopener ugc nofollow" target="_blank">https://arxiv.org/pdf/2009.07047.pdf</a></figcaption></figure><p id="fa76" class="pw-post-body-paragraph le lf it lg b lh li kd lj lk ll kg lm ln lo lp lq lr ls lt lu lv lw lx ly lz im bi translated">以前的传统恢复技术的主要问题是它们不能一般化。这是因为他们都在使用监督学习，这是由真实的旧图片和合成用于训练的图片之间的域差距引起的问题。如你所见:</p><div class="ks kt ku kv gt ab cb"><figure class="ng kw nh ni nj nk nl paragraph-image"><img src="../Images/64f8cc6f97fd37df210ce9cf5eb87115.png" data-original-src="https://miro.medium.com/v2/resize:fit:1000/format:webp/1*9tUofQoUIclBzIWdN_Fltw.jpeg"/></figure><figure class="ng kw nm ni nj nk nl paragraph-image"><div role="button" tabindex="0" class="ma mb di mc bf md"><img src="../Images/b5f941a636bd1ff625e70b4faaa7e6e1.png" data-original-src="https://miro.medium.com/v2/resize:fit:850/format:webp/1*B-jqgyiZZCmTIRuRycIVLQ.jpeg"/></div><figcaption class="kz la gj gh gi lb lc bd b be z dk nn di no np translated">左边是合成图，右边是真实的老照片。你可以看到即使有假划痕和颜色变化也已经是高清了。右图来自<a class="ae ld" href="https://funny.pho.to/fr/old-photo-effect/" rel="noopener ugc nofollow" target="_blank">https://funny.pho.to/fr/old-photo-effect/</a>左图来自<a class="ae ld" href="https://www.pinterest.ca/kenschilling/vintage-photos-of-children-playing-outside/" rel="noopener ugc nofollow" target="_blank">https://www . Pinterest . ca/ken schilling/vintage-photos-of-children-playing-outside/</a></figcaption></figure></div><p id="6160" class="pw-post-body-paragraph le lf it lg b lh li kd lj lk ll kg lm ln lo lp lq lr ls lt lu lv lw lx ly lz im bi translated">正如你在这些图像中看到的，合成的旧图像和真实的旧图像之间有很大的差异。你可以看到，合成图像已经是高清晰度的，即使有假划痕和颜色变化，相比之下，另一个包含更少的细节。</p><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div class="gh gi nq"><img src="../Images/d2046688b84cf9f3db0c462adeaf36bf.png" data-original-src="https://miro.medium.com/v2/resize:fit:1166/format:webp/1*9hduEtUeobhY5nFqj-qrNQ.png"/></div><figcaption class="kz la gj gh gi lb lc bd b be z dk translated">图片来自https://arxiv.org/pdf/2009.07047.pdf<a class="ae ld" href="https://arxiv.org/pdf/2009.07047.pdf" rel="noopener ugc nofollow" target="_blank"/></figcaption></figure><p id="296b" class="pw-post-body-paragraph le lf it lg b lh li kd lj lk ll kg lm ln lo lp lq lr ls lt lu lv lw lx ly lz im bi translated">他们通过专门为此任务创建自己的新网络来解决这个问题。基本上，他们使用两个变分自动编码器，也称为VAEs，分别将旧(退化)和干净(恢复)的照片转换到两个潜在空间。<br/>这种到潜在空间的转换是通过合成的成对数据来学习的，但能够在真实照片上很好地推广，因为在这种紧凑的潜在空间上，相同的域间隙要小得多。</p><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div class="gh gi nr"><img src="../Images/c1b5561a69c024a3a25ae3e7802ba352.png" data-original-src="https://miro.medium.com/v2/resize:fit:1256/format:webp/1*mFimXth4eEg7yk0Jlq67tw.png"/></div><figcaption class="kz la gj gh gi lb lc bd b be z dk translated">图片来自<a class="ae ld" href="https://arxiv.org/pdf/2009.07047.pdf" rel="noopener ugc nofollow" target="_blank">https://arxiv.org/pdf/2009.07047.pdf</a></figcaption></figure><p id="83be" class="pw-post-body-paragraph le lf it lg b lh li kd lj lk ll kg lm ln lo lp lq lr ls lt lu lv lw lx ly lz im bi translated">由VAEs产生的来自两个潜在空间的域间隙通过联合训练一个对抗性鉴别器来消除。<br/>您可以在此图像中看到，来自潜在空间的新域“Zx”和“Zr”比原始旧图片“R”和合成旧图片“X”彼此更接近。<br/>恢复退化照片的映射在该潜在空间中完成。</p><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div class="gh gi nq"><img src="../Images/3320f1db6b815098d18fc7da502b6df1.png" data-original-src="https://miro.medium.com/v2/resize:fit:1166/format:webp/1*-xNtLLgzl8TYXifHYE36EA.png"/></div><figcaption class="kz la gj gh gi lb lc bd b be z dk translated">图片来自<a class="ae ld" href="https://arxiv.org/pdf/2009.07047.pdf" rel="noopener ugc nofollow" target="_blank">https://arxiv.org/pdf/2009.07047.pdf</a></figcaption></figure><p id="b175" class="pw-post-body-paragraph le lf it lg b lh li kd lj lk ll kg lm ln lo lp lq lr ls lt lu lv lw lx ly lz im bi translated">他们的网络分为特定的分支，每个分支解决一个特定的问题，他们称之为部分非本地块。<br/>有一个针对结构性缺陷的全局分支，例如使用非局部块的划痕和灰尘斑点，考虑到全局上下文。<br/>然后，他们深入到两个局部分支，通过使用几个残余块来瞄准非结构化缺陷，如噪声和模糊。<br/>最后，这些分支融合到潜在空间中，提高了从所有这些缺陷中恢复旧照片的能力。</p><p id="dcdf" class="pw-post-body-paragraph le lf it lg b lh li kd lj lk ll kg lm ln lo lp lq lr ls lt lu lv lw lx ly lz im bi translated">为了产生更好的结果，还有最后一步。<br/>由于我们想要恢复的老照片很可能是来自我们所爱的人的图片，所以它们总会有一张脸在里面。</p><figure class="ks kt ku kv gt kw gh gi paragraph-image"><a href="https://www.louisbouchard.ai/learnai/"><div class="gh gi ns"><img src="../Images/d6d4f598ae72cf7f2fb082a3e0a0d220.png" data-original-src="https://miro.medium.com/v2/resize:fit:924/format:webp/0*fqRa4yjYoXrzncvQ.png"/></div></a></figure><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div class="gh gi nt"><img src="../Images/6caf3a13cf429a8ab3af31d23d4e182d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1286/format:webp/1*Sp2bHpKoCsEKdFc9_VaG2A.png"/></div><figcaption class="kz la gj gh gi lb lc bd b be z dk translated">图片来自<a class="ae ld" href="https://arxiv.org/pdf/2009.07047.pdf" rel="noopener ugc nofollow" target="_blank">https://arxiv.org/pdf/2009.07047.pdf</a></figcaption></figure><p id="deaf" class="pw-post-body-paragraph le lf it lg b lh li kd lj lk ll kg lm ln lo lp lq lr ls lt lu lv lw lx ly lz im bi translated">他们添加了一个人脸细化网络，从潜在空间的图片中恢复旧照片中人脸的精细细节，称为“z”，并使用退化的人脸进入网络的多个区域。<br/>如下图所示，这大大增强了面部的感知质量。</p><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div class="gh gi nu"><img src="../Images/cd4d1c238cb4e026060da2af6ebc9b3f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1390/format:webp/1*5a5melUiNk3wfNhxlvkhGw.png"/></div><figcaption class="kz la gj gh gi lb lc bd b be z dk translated">图片来自<a class="ae ld" href="https://arxiv.org/pdf/2009.07047.pdf" rel="noopener ugc nofollow" target="_blank">https://arxiv.org/pdf/2009.07047.pdf</a></figcaption></figure></div><div class="ab cl me mf hx mg" role="separator"><span class="mh bw bk mi mj mk"/><span class="mh bw bk mi mj mk"/><span class="mh bw bk mi mj"/></div><div class="im in io ip iq"><h2 id="b29a" class="ml mm it bd mn mo mp dn mq mr ms dp mt ln mu mv mw lr mx my mz lv na nb nc iz bi translated">更多结果</h2><p id="b365" class="pw-post-body-paragraph le lf it lg b lh nv kd lj lk nw kg lm ln nx lp lq lr ny lt lu lv nz lx ly lz im bi translated">现在我们已经看到了它是如何工作的，让我们来看看这个惊人的新网络的更多结果…</p><figure class="ks kt ku kv gt kw"><div class="bz fp l di"><div class="oa ob l"/></div></figure></div><div class="ab cl me mf hx mg" role="separator"><span class="mh bw bk mi mj mk"/><span class="mh bw bk mi mj mk"/><span class="mh bw bk mi mj"/></div><div class="im in io ip iq"><h2 id="06a6" class="ml mm it bd mn mo mp dn mq mr ms dp mt ln mu mv mw lr mx my mz lv na nb nc iz bi translated">结论</h2><p id="1fca" class="pw-post-body-paragraph le lf it lg b lh nv kd lj lk nw kg lm ln nx lp lq lr ny lt lu lv nz lx ly lz im bi translated">当然，这只是这篇新论文的一个简单概述。<br/>我强烈建议阅读下面链接的文章，了解更多信息。</p><blockquote class="oc od oe"><p id="2675" class="le lf of lg b lh li kd lj lk ll kg lm og lo lp lq oh ls lt lu oi lw lx ly lz im bi translated"><strong class="lg jd">论文，</strong>T8】https://arxiv.org/pdf/2009.07047.pdf</p></blockquote></div><div class="ab cl me mf hx mg" role="separator"><span class="mh bw bk mi mj mk"/><span class="mh bw bk mi mj mk"/><span class="mh bw bk mi mj"/></div><div class="im in io ip iq"><p id="f1ac" class="pw-post-body-paragraph le lf it lg b lh li kd lj lk ll kg lm ln lo lp lq lr ls lt lu lv lw lx ly lz im bi translated">如果你喜欢我的工作并想支持我，我会非常感谢你在我的社交媒体频道上关注我:</p><ul class=""><li id="facb" class="oj ok it lg b lh li lk ll ln ol lr om lv on lz oo op oq or bi translated">支持我的最好方式就是在<a class="ae ld" href="https://medium.com/@whats_ai" rel="noopener"> <strong class="lg jd">中</strong> </a>关注我。</li><li id="1268" class="oj ok it lg b lh os lk ot ln ou lr ov lv ow lz oo op oq or bi translated">订阅我的<a class="ae ld" href="https://www.youtube.com/channel/UCUzGQrN-lyyc0BWTYoJM_Sg" rel="noopener ugc nofollow" target="_blank"> <strong class="lg jd"> YouTube频道</strong> </a>。</li><li id="e390" class="oj ok it lg b lh os lk ot ln ou lr ov lv ow lz oo op oq or bi translated">在<a class="ae ld" href="https://www.linkedin.com/company/what-is-artificial-intelligence" rel="noopener ugc nofollow" target="_blank"> <strong class="lg jd"> LinkedIn </strong> </a>上关注我的项目</li><li id="564e" class="oj ok it lg b lh os lk ot ln ou lr ov lv ow lz oo op oq or bi translated">一起学习AI，加入我们的<a class="ae ld" href="https://discord.gg/SVse4Sr" rel="noopener ugc nofollow" target="_blank"> <strong class="lg jd">不和谐社区</strong> </a>，<em class="of">分享你的项目、论文、最佳课程，寻找Kaggle队友，等等！</em></li></ul></div></div>    
</body>
</html>