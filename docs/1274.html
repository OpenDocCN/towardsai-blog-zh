<html>
<head>
<title>Let’s See How a Computer Sees…</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">让我们来看看电脑是如何看的…</h1>
<blockquote>原文：<a href="https://pub.towardsai.net/lets-see-how-a-computer-sees-34da517d28b3?source=collection_archive---------2-----------------------#2020-12-19">https://pub.towardsai.net/lets-see-how-a-computer-sees-34da517d28b3?source=collection_archive---------2-----------------------#2020-12-19</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><h2 id="1ca0" class="io ip iq bd b dl ir is it iu iv iw dk ix translated" aria-label="kicker paragraph"><a class="ae ep" href="https://towardsai.net/p/category/machine-learning/deep-learning" rel="noopener ugc nofollow" target="_blank">深度学习</a>，<a class="ae ep" href="https://towardsai.net/p/category/programming" rel="noopener ugc nofollow" target="_blank">编程</a></h2><div class=""/><figure class="gl gn jx jy jz ka gh gi paragraph-image"><div role="button" tabindex="0" class="kb kc di kd bf ke"><div class="gh gi jw"><img src="../Images/b35d3abdaa11bb72122bece13a205dd5.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*6V_IDGKOVFO_4VS-.jpeg"/></div></div><figcaption class="kh ki gj gh gi kj kk bd b be z dk translated">照片由<a class="ae kl" href="https://unsplash.com/@averey?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText" rel="noopener ugc nofollow" target="_blank"> Robina Weermeijer </a>在<a class="ae kl" href="https://unsplash.com/s/photos/brain?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>拍摄</figcaption></figure><p id="5602" class="pw-post-body-paragraph km kn iq ko b kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">在人类中，理解视觉信息有多个阶段，计算机也遵循这个过程。</p><p id="7f6e" class="pw-post-body-paragraph km kn iq ko b kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">现在让我们试着放大一点人类大脑是如何工作的。想象一下，你走出去，环顾四周，你会发现很多你很快就能认出来的东西，比如:</p><ul class=""><li id="0b92" class="lk ll iq ko b kp kq kt ku kx lm lb ln lf lo lj lp lq lr ls bi translated">嘿，那是新开的披萨店。</li><li id="b6e8" class="lk ll iq ko b kp lt kt lu kx lv lb lw lf lx lj lp lq lr ls bi translated">嘿，看那只狗。</li><li id="cdc1" class="lk ll iq ko b kp lt kt lu kx lv lb lw lf lx lj lp lq lr ls bi translated">这辆新车看起来棒极了。</li></ul><p id="5bbc" class="pw-post-body-paragraph km kn iq ko b kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">精彩的清单还在继续……</p><p id="b0f7" class="pw-post-body-paragraph km kn iq ko b kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">嗯，我现在有一个问题要问你。你有没有想过你是如何对事物进行分类的？</p><p id="dd99" class="pw-post-body-paragraph km kn iq ko b kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">那是你的<strong class="ko ja">虚拟皮层系统</strong>为你服务，这个系统负责处理视觉信息。</p><p id="4a03" class="pw-post-body-paragraph km kn iq ko b kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">如果你还记得，我们讨论过阶段。嗯，图像到达的第一阶段被称为<strong class="ko ja"> V1。</strong></p><p id="7961" class="pw-post-body-paragraph km kn iq ko b kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">这个V1区域由两个简单和复杂的单元组成。这两个细胞从物体上捕捉特征，然后特征被识别，图像被分类。这是人类大脑工作方式的简要介绍。</p><p id="b479" class="pw-post-body-paragraph km kn iq ko b kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">现在，让我们看看计算机是如何对图像进行分类的。这个概念就是<strong class="ko ja">卷积神经网络</strong> (CNN)，我们将在本文中探讨这个概念。</p><p id="6c54" class="pw-post-body-paragraph km kn iq ko b kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">就像我们的人脑一样，CNN对一个图像的分类也有一些阶段。现在让我们试着理解这些阶段。CNN就像一个视觉皮层系统。</p><p id="376d" class="pw-post-body-paragraph km kn iq ko b kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">在这里，图像是我们的输入，图像可以是，</p><ul class=""><li id="bbc3" class="lk ll iq ko b kp kq kt ku kx lm lb ln lf lo lj lp lq lr ls bi translated"><strong class="ko ja">灰度</strong>图像</li><li id="5f9d" class="lk ll iq ko b kp lt kt lu kx lv lb lw lf lx lj lp lq lr ls bi translated"><strong class="ko ja">彩色</strong>图像(这些图像是3个通道(<strong class="ko ja">红、绿、蓝</strong>)的组合)</li></ul><p id="f9eb" class="pw-post-body-paragraph km kn iq ko b kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">现在，你一定想知道CNN中的卷积是什么？</p><p id="2d16" class="pw-post-body-paragraph km kn iq ko b kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">CNN中的卷积是图像和权重经过点积的运算。</p><p id="f36e" class="pw-post-body-paragraph km kn iq ko b kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">图像被表示为像素值的矩阵，这些图像被输入到我们的CNN。第一步是将点积应用于输入和权重。</p><p id="fbaf" class="pw-post-body-paragraph km kn iq ko b kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated"><strong class="ko ja">权重</strong></p><p id="ce1e" class="pw-post-body-paragraph km kn iq ko b kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">这些重量也被称为过滤器。这些也表示为矩阵。</p><p id="c27e" class="pw-post-body-paragraph km kn iq ko b kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">让我们以一个场景来理解过滤器。我们都对运动感兴趣，对吗？所以，在每项运动中，都有不同的位置。例如，在板球运动中，有击球手和投球手。这两位在各自的领域都很专业。过滤器也是如此，而且还有许多不同的过滤器，它们在各自的领域中是专门的。</p><p id="d313" class="pw-post-body-paragraph km kn iq ko b kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">例如，一些从图像中捕捉边缘，一些模糊图像，一些锐化图像，等等。</p><p id="440d" class="pw-post-body-paragraph km kn iq ko b kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">在CNN中，滤波器的值被初始化，并且在训练过程中，滤波器的值被改变或调整。</p><p id="bb66" class="pw-post-body-paragraph km kn iq ko b kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">就像在烹饪节目中，参与者首先根据他们的理解烹饪菜肴，然后根据要求进行更改或纠正。</p><p id="d20d" class="pw-post-body-paragraph km kn iq ko b kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">对于本博客，我们将使用CIFAR10数据集。它有以下几类:“飞机”、“汽车”、“鸟”、“猫”、“鹿”、“狗”、“青蛙”、“马”、“船”、“卡车”。CIFAR-10中的图像大小为3×32×32，即32×32像素大小的3通道彩色图像。</p><p id="1eac" class="pw-post-body-paragraph km kn iq ko b kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">我们还将使用权重和偏差，这将有助于我们跟踪模型的性能和损失。</p><p id="3261" class="pw-post-body-paragraph km kn iq ko b kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated"><strong class="ko ja">让我们开始</strong></p><p id="f6ac" class="pw-post-body-paragraph km kn iq ko b kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">首先，您需要在这里创建一个WandB帐户<a class="ae kl" href="https://www.wandb.com/" rel="noopener ugc nofollow" target="_blank">，我们将在这里跟踪我们模型的性能。</a></p><p id="63dd" class="pw-post-body-paragraph km kn iq ko b kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">创建帐户后，您现在需要安装它，我使用google colab笔记本来安装这个数据集。</p><pre class="ly lz ma mb gt mc md me mf aw mg bi"><span id="86ac" class="mh mi iq md b gy mj mk l ml mm"># Installing the package<br/>!pip install wandb -q</span><span id="d45f" class="mh mi iq md b gy mn mk l ml mm"># importing the library<br/>import wandb</span><span id="e194" class="mh mi iq md b gy mn mk l ml mm"># login<br/>wandb.login()</span></pre><p id="a85a" class="pw-post-body-paragraph km kn iq ko b kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">该数据集可在PyTorch的<strong class="ko ja"> torchvision.datasets </strong>中获得。</p><p id="6ba5" class="pw-post-body-paragraph km kn iq ko b kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">让我们导入库</p><pre class="ly lz ma mb gt mc md me mf aw mg bi"><span id="ad38" class="mh mi iq md b gy mj mk l ml mm">import torch<br/>import torchvision<br/>from torchvision.transforms as transforms</span></pre><p id="d593" class="pw-post-body-paragraph km kn iq ko b kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">torchvision包由流行的数据集和计算机视觉的普通图像转换组成。</p><pre class="ly lz ma mb gt mc md me mf aw mg bi"><span id="e97d" class="mh mi iq md b gy mj mk l ml mm">transform = transforms.Compose([transforms.ToTensor(),transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])</span><span id="df6f" class="mh mi iq md b gy mn mk l ml mm">trainset = torchvision.datasets.CIFAR10(root = './data', train = True, download = True, transform=transform)</span><span id="29ed" class="mh mi iq md b gy mn mk l ml mm">testset = torchvision.datasets.CIFAR10(root = './data', train = False, transform=transform)</span><span id="11c3" class="mh mi iq md b gy mn mk l ml mm">trainloader = torch.utils.data.DataLoader(trainset, batch_size=4, shuffle = True, num_workers=2)</span><span id="9ca4" class="mh mi iq md b gy mn mk l ml mm">testloader = torch.utils.data.DataLoader(testset, batch_size=4, shuffle=False, num_workers=2)</span><span id="ffe1" class="mh mi iq md b gy mn mk l ml mm">classes = ('plane', 'car', 'bird', 'cat','deer', 'dog', 'frog', 'horse', 'ship', 'truck')</span></pre><p id="6937" class="pw-post-body-paragraph km kn iq ko b kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">让我们来理解代码，</p><p id="0e07" class="pw-post-body-paragraph km kn iq ko b kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">1] <strong class="ko ja">变换。撰写</strong></p><p id="a3aa" class="pw-post-body-paragraph km kn iq ko b kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">变换用于图像变换，我们可以使用许多不同的变换。compose就像<strong class="ko ja"> sklearn.compose </strong>(我们可以使用Compose链接不同的转换)</p><p id="5d30" class="pw-post-body-paragraph km kn iq ko b kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">您可以简单地使用Compose并一起使用它们，而不是为每个转换创建一个变量。</p><p id="4515" class="pw-post-body-paragraph km kn iq ko b kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">我们使用了<strong class="ko ja">转换。作为我们的第一个转换器，它将我们的图像转换成张量。张量图像是一个具有<code class="fe mo mp mq md b">(C, H, W)</code>形状的张量，其中<code class="fe mo mp mq md b">C</code>是通道数，<code class="fe mo mp mq md b">H</code>和<code class="fe mo mp mq md b">W</code>是图像的高度和宽度。</strong></p><p id="7ad2" class="pw-post-body-paragraph km kn iq ko b kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">我们使用的第二个转换器是<strong class="ko ja">转换。Normalize() </strong>，我们将值0.5和0.5传递给归一化转换，以将像素转换为0到1之间的值，这意味着平均值为0.5且标准偏差为0.5的分布。</p><p id="aba5" class="pw-post-body-paragraph km kn iq ko b kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">2] <strong class="ko ja">数据集</strong></p><p id="10ad" class="pw-post-body-paragraph km kn iq ko b kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">现在我们从<strong class="ko ja">火炬视觉下载了我们的数据集。数据集</strong>我们把它们分成两组——训练集和测试集。</p><p id="8437" class="pw-post-body-paragraph km kn iq ko b kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">现在我们使用了<strong class="ko ja">torch . utils . data . data loader</strong>，这个数据加载器从我们创建的集合中获取数据，并批量提供数据。</p><p id="b7f1" class="pw-post-body-paragraph km kn iq ko b kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated"><strong class="ko ja">网络</strong></p><p id="b359" class="pw-post-body-paragraph km kn iq ko b kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">现在，让我们定义我们的网络，</p><pre class="ly lz ma mb gt mc md me mf aw mg bi"><span id="f095" class="mh mi iq md b gy mj mk l ml mm">import torch.nn as nn<br/>import torch.nn.functional as Fclass Net(nn.Module):<br/>    def __init__(self):<br/>        super(Net, self).__init__()<br/>        self.conv1 = nn.Conv2d(3, 6, 5)<br/>        self.pool = nn.MaxPool2d(2, 2) <br/>        self.conv2 = nn.Conv2d(6, 16, 5)<br/>        self.fc1 = nn.Linear(16 * 5 * 5, 120)<br/>        self.fc2 = nn.Linear(120, 84)<br/>        self.fc3 = nn.Linear(84, 10)<br/>    <br/>    def forward(self, x):<br/>        x = self.pool(F.relu(self.conv1(x)))<br/>        x = self.pool(F.relu(self.conv2(x)))<br/>        x = x.view(-1, 16 * 5 * 5)<br/>        x = F.relu(self.fc1(x))<br/>        x = F.relu(self.fc2(x))<br/>        x = self.fc3(x)<br/>        return x<br/>net = Net()</span></pre><p id="e4c7" class="pw-post-body-paragraph km kn iq ko b kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">在这里，我使用两个卷积层和三个线性层。</p><p id="4b1b" class="pw-post-body-paragraph km kn iq ko b kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">第一个卷积层接受3个参数，1]输入通道2]输出通道3]内核大小</p><p id="0913" class="pw-post-body-paragraph km kn iq ko b kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">1] <strong class="ko ja"> in_channels= </strong>输入图像中的通道数如果图像是灰度的，那么in_channels = 1，当输入是彩色的，那么它等于3，因为彩色图像有三个通道，即(红、绿、蓝)</p><p id="3bef" class="pw-post-body-paragraph km kn iq ko b kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">2] <strong class="ko ja"> out_channels= </strong>卷积运算产生的通道数</p><p id="87b7" class="pw-post-body-paragraph km kn iq ko b kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">3] <strong class="ko ja"> kernel_size= </strong>这是将被卷积的矩阵的大小。</p><p id="59b2" class="pw-post-body-paragraph km kn iq ko b kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">第二卷积层具有相同的参数。</p><p id="2566" class="pw-post-body-paragraph km kn iq ko b kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">我们将最大池应用于我们的卷积图像。MaxPool2d 的作用是从矩阵中取最大值。</p><p id="b028" class="pw-post-body-paragraph km kn iq ko b kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">现在，我们使用三个线性层后，应用第二个卷积层。</p><p id="d489" class="pw-post-body-paragraph km kn iq ko b kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated"><strong class="ko ja"> nn。Linear= </strong>这将对我们的输入和输出样本应用线性变换。<br/>是全连接层，有输入有输出。现在，它的输入会有一个权重。它的输出将是<em class="mr"/>【XW+b】，因为它完全是线性的，没有激活函数。</p><p id="e25d" class="pw-post-body-paragraph km kn iq ko b kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">它定义了我们的模型的结构，就像你已经收集了你的菜的配料，现在正向函数告诉你如何使用这些配料。</p><p id="afd3" class="pw-post-body-paragraph km kn iq ko b kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">关于我在这里使用的超级函数的非常棒的文章<a class="ae kl" href="https://realpython.com/python-super/" rel="noopener ugc nofollow" target="_blank">https://realpython.com/python-super/</a>。</p><p id="41a2" class="pw-post-body-paragraph km kn iq ko b kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">现在，我们定义损失函数和优化器，</p><pre class="ly lz ma mb gt mc md me mf aw mg bi"><span id="13af" class="mh mi iq md b gy mj mk l ml mm">import torch.optim as optim<br/>criterion = nn.CrossEntropyLoss()<br/>optimizer = optim.Adam(net.parameters())</span></pre><p id="bf4c" class="pw-post-body-paragraph km kn iq ko b kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">我已经在我之前的<a class="ae kl" href="https://medium.com/towards-artificial-intelligence/logistic-regression-with-pytorch-198a4ec80649" rel="noopener">文章</a>中解释了损失函数和优化器。</p><p id="b311" class="pw-post-body-paragraph km kn iq ko b kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated"><strong class="ko ja">训练网络</strong></p><p id="2e01" class="pw-post-body-paragraph km kn iq ko b kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">训练前一定要运行<strong class="ko ja"> wandb.init() </strong>。这将初始化正在运行的进程。</p><p id="138a" class="pw-post-body-paragraph km kn iq ko b kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">它接受许多参数，但我们将在这里使用最重要的一个，那就是<strong class="ko ja">‘实体’</strong>=您的用户名，<strong class="ko ja">‘项目’</strong>=您的项目名称。</p><pre class="ly lz ma mb gt mc md me mf aw mg bi"><span id="8dcd" class="mh mi iq md b gy mj mk l ml mm">wandb.init(entity = 'pratik_raut', project = 'Image Classification with Pytorch 2')</span><span id="87c7" class="mh mi iq md b gy mn mk l ml mm">epochs = 40<br/># <strong class="md ja">reference</strong> - <a class="ae kl" href="https://pytorch.org/tutorials/beginner/blitz/cifar10_tutorial.html" rel="noopener ugc nofollow" target="_blank">https://pytorch.org/tutorials/beginner/blitz/cifar10_tutorial.html</a></span><span id="5108" class="mh mi iq md b gy mn mk l ml mm">for epoch in range(1, epochs+1):  <strong class="md ja"># loop over the dataset multiple times</strong><br/>    running_loss = 0.0<br/>    for i, data in enumerate(trainloader, 0):<strong class="md ja">    # get the inputs; data is a list of [inputs, labels]<br/>        </strong>inputs, labels = data<strong class="md ja">    # zero the parameter gradients</strong><br/>        optimizer.zero_grad()<strong class="md ja">    # forward + backward + optimize<br/>        </strong>outputs = net(inputs)<br/>        loss = criterion(outputs, labels)<br/>        loss.backward()<br/>        optimizer.step()<strong class="md ja">    # print statistics</strong><br/>        running_loss += loss.item()<br/>        if i % 2000 == 1999:    <strong class="md ja"># print every 2000 mini-batches</strong><br/>            print('[%d, %5d] loss: %.3f' % <br/>                 (epoch + 1, i + 1, running_loss /2000))<br/>        running_loss = 0.0<strong class="md ja">    # Log the loss and accuracy values at the end of each epoch</strong><br/>    wandb.log({"Epoch": epoch, "Train Loss":running_loss})</span><span id="cdcc" class="mh mi iq md b gy mn mk l ml mm">print('Finished Training')</span></pre><figure class="ly lz ma mb gt ka gh gi paragraph-image"><div class="gh gi ms"><img src="../Images/7678c81770b10bdadb22085e20b59671.png" data-original-src="https://miro.medium.com/v2/resize:fit:1208/format:webp/1*l-7hBHhPTPCfEEh4PPgR3g.png"/></div></figure><p id="e4d5" class="pw-post-body-paragraph km kn iq ko b kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">这是在wandb帐户上生成的图表，这是对wandb跟踪您的模型性能的有用性的简单观察。</p><p id="7337" class="pw-post-body-paragraph km kn iq ko b kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">让我们试着预测一些图像，</p><pre class="ly lz ma mb gt mc md me mf aw mg bi"><span id="2d20" class="mh mi iq md b gy mj mk l ml mm">dataiter = iter(testloader)<br/>images, labels = dataiter.next()</span><span id="63f8" class="mh mi iq md b gy mn mk l ml mm"><strong class="md ja"># print images</strong><br/>imshow(torchvision.utils.make_grid(images))</span><span id="cc10" class="mh mi iq md b gy mn mk l ml mm">print('GroundTruth: ', ' '.join('%5s' % classes[labels[j]] for j in range(4)))</span></pre><figure class="ly lz ma mb gt ka gh gi paragraph-image"><div class="gh gi mt"><img src="../Images/7e7d1a5eeb3db5526a1072de2e2d25cf.png" data-original-src="https://miro.medium.com/v2/resize:fit:802/format:webp/1*Ic4t0jPkq8WwCHwBWxKzIg.png"/></div></figure><p id="ec5e" class="pw-post-body-paragraph km kn iq ko b kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">代码在<a class="ae kl" href="https://colab.research.google.com/drive/1Ba4BC5fdAxHEVE2ObNUBygcIhk-5BQvW#scrollTo=OvreFf_TtNXf" rel="noopener ugc nofollow" target="_blank"> <strong class="ko ja"> Google Colab </strong> </a>上有。这就是我希望你喜欢和学习。这只是一个简单的网络，希望大家多加补充，谢谢。</p><p id="fa82" class="pw-post-body-paragraph km kn iq ko b kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated"><strong class="ko ja">免责声明</strong>-标题中无链接的图片为作者所有；否则，会提供一个链接。</p></div></div>    
</body>
</html>