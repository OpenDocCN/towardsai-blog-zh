<html>
<head>
<title>Extract Tweets Without Limitations in a Few Lines of Code Using Python</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">使用Python在几行代码中无限制地提取推文</h1>
<blockquote>原文：<a href="https://pub.towardsai.net/extract-tweets-without-limitations-in-a-few-lines-of-code-using-python-21578f89a00c?source=collection_archive---------0-----------------------#2022-12-09">https://pub.towardsai.net/extract-tweets-without-limitations-in-a-few-lines-of-code-using-python-21578f89a00c?source=collection_archive---------0-----------------------#2022-12-09</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="d8f8" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">数据量不应该是一个限制。</h2></div><figure class="ki kj kk kl gt km"><div class="bz fp l di"><div class="kn ko l"/></div><figcaption class="kp kq gj gh gi kr ks bd b be z dk translated">喜欢—关注—订阅—分享</figcaption></figure><h1 id="0125" class="kt ku it bd kv kw kx ky kz la lb lc ld jz le ka lf kc lg kd lh kf li kg lj lk bi translated">介绍</h1><p id="abb9" class="pw-post-body-paragraph ll lm it ln b lo lp ju lq lr ls jx lt lu lv lw lx ly lz ma mb mc md me mf mg im bi translated">如果你熟悉Tweepy库，你可能也熟悉这样一个事实，即你不能超过一定数量的Tweepy，我认为这对于需要大量数据的实验来说是一个巨大的缺点。</p><p id="5dd4" class="pw-post-body-paragraph ll lm it ln b lo mh ju lq lr mi jx lt lu mj lw lx ly mk ma mb mc ml me mf mg im bi translated">城里来了个新玩家:<code class="fe mm mn mo mp b"><a class="ae mq" href="https://github.com/JustAnotherArchivist/snscrape" rel="noopener ugc nofollow" target="_blank">snscrape</a></code>专门为社交网络服务(简称SNS)打造的python库。</p><p id="287c" class="pw-post-body-paragraph ll lm it ln b lo mh ju lq lr mi jx lt lu mj lw lx ly mk ma mb mc ml me mf mg im bi translated">它可以从脸书、Instagram、乳齿象、Reddit、Telegram、Twitter、VKontakte和微博等各种平台收集用户资料、标签和特定用户帖子等信息。</p><p id="961d" class="pw-post-body-paragraph ll lm it ln b lo mh ju lq lr mi jx lt lu mj lw lx ly mk ma mb mc ml me mf mg im bi translated">只是锦上添花🍰，你不需要申请任何API凭证🎉。</p><h1 id="e1ab" class="kt ku it bd kv kw kx ky kz la lb lc ld jz le ka lf kc lg kd lh kf li kg lj lk bi translated">我们开始吧</h1><p id="68d1" class="pw-post-body-paragraph ll lm it ln b lo lp ju lq lr ls jx lt lu lv lw lx ly lz ma mb mc md me mf mg im bi translated">在这个概念教程中，我们将使用<code class="fe mm mn mo mp b"><a class="ae mq" href="https://github.com/JustAnotherArchivist/snscrape" rel="noopener ugc nofollow" target="_blank">snscrape</a></code>提取数千条推文，并在本地保存为数据帧。你可以得到更多。一切都是可能的🚀！</p><h2 id="5442" class="mr ku it bd kv ms mt dn kz mu mv dp ld lu mw mx lf ly my mz lh mc na nb lj nc bi translated">先决条件</h2><p id="5fc8" class="pw-post-body-paragraph ll lm it ln b lo lp ju lq lr ls jx lt lu lv lw lx ly lz ma mb mc md me mf mg im bi translated">首先，你必须安装<code class="fe mm mn mo mp b">snscrape</code>库。但要做到这一点，你需要在电脑上安装Python，从<a class="ae mq" href="https://www.python.org/downloads/" rel="noopener ugc nofollow" target="_blank">官网</a>下载安装即可。</p><p id="495a" class="pw-post-body-paragraph ll lm it ln b lo mh ju lq lr mi jx lt lu mj lw lx ly mk ma mb mc ml me mf mg im bi translated">一旦你安装了Python，你就可以在你的终端或者Jupyter笔记本中使用下面的<code class="fe mm mn mo mp b">pip</code>命令来安装<code class="fe mm mn mo mp b">snscrape</code>:</p><pre class="ki kj kk kl gt nd mp ne bn nf ng bi"><span id="b72b" class="nh ku it mp b be ni nj l nk nl"># (1) From your terminal<br/>pip3 install snscrape<br/><br/># (2) From Jupyter Notebook<br/>!pip3 install snscrape </span></pre><p id="0f13" class="pw-post-body-paragraph ll lm it ln b lo mh ju lq lr mi jx lt lu mj lw lx ly mk ma mb mc ml me mf mg im bi translated">一旦成功，您应该能够使用以下语句导入它以供进一步使用:</p><pre class="ki kj kk kl gt nd mp ne bn nf ng bi"><span id="f868" class="nh ku it mp b be ni nj l nk nl">import snscrape.modules.twitter as snt</span></pre><p id="d570" class="pw-post-body-paragraph ll lm it ln b lo mh ju lq lr mi jx lt lu mj lw lx ly mk ma mb mc ml me mf mg im bi translated">这样，您就可以在任何需要使用<code class="fe mm mn mo mp b">snscrape.modules.twitter</code>模块的地方使用<code class="fe mm mn mo mp b">snt</code>。</p><h2 id="8def" class="mr ku it bd kv ms mt dn kz mu mv dp ld lu mw mx lf ly my mz lh mc na nb lj nc bi translated">抓取推文</h2><p id="5fa4" class="pw-post-body-paragraph ll lm it ln b lo lp ju lq lr ls jx lt lu lv lw lx ly lz ma mb mc md me mf mg im bi translated">一旦库被正确设置，你就可以开始收集你需要的推文了。在这一部分，我们将收集与2022年世界杯相关的推文。</p><p id="ad94" class="pw-post-body-paragraph ll lm it ln b lo mh ju lq lr mi jx lt lu mj lw lx ly mk ma mb mc ml me mf mg im bi translated">拉推需要<code class="fe mm mn mo mp b">TwitterSearchScraper</code>模块。在深入研究之前，让我们通过获取一个带有标签<code class="fe mm mn mo mp b">#worldcup2022</code>的tweet样本来理解提取的tweet信息的输出格式</p><pre class="ki kj kk kl gt nd mp ne bn nf ng bi"><span id="e106" class="nh ku it mp b be ni nj l nk nl"># Get Tweets with the #worldcup<br/>world_cup_scraper = snt.TwitterSearchScraper("#worldcup")<br/><br/>print(type(world_cup_scraper))</span></pre><p id="a734" class="pw-post-body-paragraph ll lm it ln b lo mh ju lq lr mi jx lt lu mj lw lx ly mk ma mb mc ml me mf mg im bi translated">打印声明显示:</p><p id="bb74" class="pw-post-body-paragraph ll lm it ln b lo mh ju lq lr mi jx lt lu mj lw lx ly mk ma mb mc ml me mf mg im bi translated"><code class="fe mm mn mo mp b">&lt;class 'snscrape.modumes.twitter.TwitterSearchScraper'&gt;</code>。这仅仅意味着<code class="fe mm mn mo mp b">TwitterSearchScraper</code>模块的应用程序也返回一个<code class="fe mm mn mo mp b">TwitterSearchScraper</code>对象。</p><p id="64ce" class="pw-post-body-paragraph ll lm it ln b lo mh ju lq lr mi jx lt lu mj lw lx ly mk ma mb mc ml me mf mg im bi translated">为了能够获取实际的tweets数据，您需要应用如下所示的<code class="fe mm mn mo mp b">get_items()</code>函数。</p><pre class="ki kj kk kl gt nd mp ne bn nf ng bi"><span id="bed4" class="nh ku it mp b be ni nj l nk nl"># Let's get the first tweet from the world_cup_scraper search<br/>for world_cup_tweet in world_cup_scraper.get_items():<br/>   break</span></pre><p id="ac18" class="pw-post-body-paragraph ll lm it ln b lo mh ju lq lr mi jx lt lu mj lw lx ly mk ma mb mc ml me mf mg im bi translated">前面的for循环只抓取第一条tweet的数据。我们可以通过键入下面的代码来显示world_cup_tweet的原始数据。</p><pre class="ki kj kk kl gt nd mp ne bn nf ng bi"><span id="bfcd" class="nh ku it mp b be ni nj l nk nl">world_cup_tweet</span></pre><figure class="ki kj kk kl gt km gh gi paragraph-image"><div role="button" tabindex="0" class="nn no di np bf nq"><div class="gh gi nm"><img src="../Images/32a7df34eabc24842bc661c1b1ebbaee.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*yAGcDo-1EhuxBuYDje_8Gw.png"/></div></div><figcaption class="kp kq gj gh gi kr ks bd b be z dk translated">第一条推文的原始数据(图片由作者提供)</figcaption></figure><p id="f9db" class="pw-post-body-paragraph ll lm it ln b lo mh ju lq lr mi jx lt lu mj lw lx ly mk ma mb mc ml me mf mg im bi translated">正如你所看到的，原始数据是以<code class="fe mm mn mo mp b">key=value</code>的格式显示的，其中一些带有绿色下划线。并非所有的列都有用。所以让我们只考虑在column_name列表中指定的那些。</p><pre class="ki kj kk kl gt nd mp ne bn nf ng bi"><span id="d024" class="nh ku it mp b be ni nj l nk nl">column_names = ['url', 'date', 'content', 'username','displayname',<br/>                'description', 'followersCount', 'friendsCount',<br/>                'likeCount', 'world_cup_tweet']</span></pre><p id="f89e" class="pw-post-body-paragraph ll lm it ln b lo mh ju lq lr mi jx lt lu mj lw lx ly mk ma mb mc ml me mf mg im bi translated">请记住，如果您没有指定要收集的tweet的数量，这个抓取过程可能会永远运行下去，试图抓取所有的tweet。为了简单起见，假设我们想要最多200000条推文。</p><pre class="ki kj kk kl gt nd mp ne bn nf ng bi"><span id="0ee2" class="nh ku it mp b be ni nj l nk nl">total_tweet = 20000</span></pre><p id="d49a" class="pw-post-body-paragraph ll lm it ln b lo mh ju lq lr mi jx lt lu mj lw lx ly mk ma mb mc ml me mf mg im bi translated">将所有这些放在一起，我们得到下面的helper函数，它获取所需数量的tweets。</p><pre class="ki kj kk kl gt nd mp ne bn nf ng bi"><span id="1f06" class="nh ku it mp b be ni nj l nk nl"># Putting all togeter<br/>def grab_tweets(total_number):<br/>    <br/>    <br/>    final_tweets = []<br/>    <br/>    for index, world_cup_tweet in enumerate(world_cup_scraper.get_items()):<br/><br/>        user = world_cup_tweet.user<br/><br/>        tweet_data = [world_cup_tweet.url, <br/>                      world_cup_tweet.date, <br/>                      world_cup_tweet.content, <br/>                      user.username, <br/>                      user.displayname,<br/>                      user.description, <br/>                      user.followersCount,<br/>                      user.friendsCount,<br/>                      world_cup_tweet.likeCount, <br/>                      world_cup_tweet.retweetCount<br/>                      ]<br/><br/>        final_tweets.append(tweet_data)<br/><br/>        if(index == total_number):<br/>            break<br/>            <br/>        <br/>    # Create the dataframe<br/>    final_tweets_df = pd.DataFrame(final_tweets, columns = column_names)<br/>    <br/>    return final_tweets_df</span></pre><ul class=""><li id="27f9" class="nt nu it ln b lo mh lr mi lu nv ly nw mc nx mg ny nz oa ob bi translated"><code class="fe mm mn mo mp b">break</code>语句很重要，因为它允许程序在到达<code class="fe mm mn mo mp b">total_number</code>时不再继续。</li></ul><p id="f566" class="pw-post-body-paragraph ll lm it ln b lo mh ju lq lr mi jx lt lu mj lw lx ly mk ma mb mc ml me mf mg im bi translated">最后，我们可以调用指定了<code class="fe mm mn mo mp b">total_number</code>参数的函数，然后我们用<code class="fe mm mn mo mp b">.shape</code>属性显示数据的形状，用<code class="fe mm mn mo mp b">.head()</code>函数显示前五行。</p><pre class="ki kj kk kl gt nd mp ne bn nf ng bi"><span id="18cf" class="nh ku it mp b be ni nj l nk nl"># Call the grab_tweets() function<br/>final_tweets_data = grab_tweets(20000)<br/><br/># Show the shape<br/>print(final_tweets_data.shape)<br/><br/># Show the first 5 rows <br/>final_tweets_data.head()</span></pre><ul class=""><li id="6df5" class="nt nu it ln b lo mh lr mi lu nv ly nw mc nx mg ny nz oa ob bi translated">形状为(20000，10) → 20000行10列。</li></ul><p id="3299" class="pw-post-body-paragraph ll lm it ln b lo mh ju lq lr mi jx lt lu mj lw lx ly mk ma mb mc ml me mf mg im bi translated">下面是前五行。</p><figure class="ki kj kk kl gt km gh gi paragraph-image"><div role="button" tabindex="0" class="nn no di np bf nq"><div class="gh gi oc"><img src="../Images/094350abf22a3bd851ce1e0c7bb835ba.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*SEyJ5RIlRgG9OHxs9Fh0hw.png"/></div></div><figcaption class="kp kq gj gh gi kr ks bd b be z dk translated">推文的前5行(图片由作者提供)</figcaption></figure><h2 id="1966" class="mr ku it bd kv ms mt dn kz mu mv dp ld lu mw mx lf ly my mz lh mc na nb lj nc bi translated">具体语言的推文呢？</h2><p id="52e6" class="pw-post-body-paragraph ll lm it ln b lo lp ju lq lr ls jx lt lu lv lw lx ly lz ma mb mc md me mf mg im bi translated">以前的推文是不分语言收集的，如果我们对特定语言的推文感兴趣，这并不理想。例如，假设我们只对法语推文感兴趣，这可以通过在<code class="fe mm mn mo mp b">TwitterSearchScraper</code>模块中指定<code class="fe mm mn mo mp b">lang</code>参数来实现，如下所示:</p><ul class=""><li id="73dd" class="nt nu it ln b lo mh lr mi lu nv ly nw mc nx mg ny nz oa ob bi translated"><code class="fe mm mn mo mp b">TwitterSearchScraper("topic lang:language")</code></li></ul><p id="3a8d" class="pw-post-body-paragraph ll lm it ln b lo mh ju lq lr mi jx lt lu mj lw lx ly mk ma mb mc ml me mf mg im bi translated">为此，我们将创建一个新函数，并稍微修改之前的函数:</p><pre class="ki kj kk kl gt nd mp ne bn nf ng bi"><span id="478a" class="nh ku it mp b be ni nj l nk nl">def get_language_specific_tweets(topic, total_number, lang="fr"):<br/>    <br/>    # Get the topic from using the scraper and the language<br/>    topic_scraper = snt.TwitterSearchScraper(f"{topic} lang:{lang}")<br/>    <br/>    # Grab the tweets<br/>    final_tweets_as_df = grab_tweets(topic_scraper, total_number)<br/>    <br/>    return final_tweets_as_df</span></pre><p id="1cf4" class="pw-post-body-paragraph ll lm it ln b lo mh ju lq lr mi jx lt lu mj lw lx ly mk ma mb mc ml me mf mg im bi translated">这个新函数将感兴趣的主题(例如<code class="fe mm mn mo mp b">#worldcup</code>)、tweets的总数以及感兴趣的语言(默认为<code class="fe mm mn mo mp b">french</code>)作为参数。</p><p id="50e7" class="pw-post-body-paragraph ll lm it ln b lo mh ju lq lr mi jx lt lu mj lw lx ly mk ma mb mc ml me mf mg im bi translated">除此之外，我们稍微修改了一下原来的函数来满足前面函数的要求，因为这次我们有了一个新的参数:<code class="fe mm mn mo mp b">topic_scraper</code>。</p><pre class="ki kj kk kl gt nd mp ne bn nf ng bi"><span id="1f97" class="nh ku it mp b be ni nj l nk nl"># Putting all togeter<br/>def grab_tweets(scraper, total_number):<br/>    <br/>    <br/>    final_tweets = []<br/>    <br/>    for index, world_cup_tweet in enumerate(scraper.get_items()):<br/><br/>        user = world_cup_tweet.user<br/><br/>        tweet_data = [world_cup_tweet.url, <br/>                      world_cup_tweet.date, <br/>                      world_cup_tweet.content, <br/>                      user.username, <br/>                      user.displayname,<br/>                      user.description, <br/>                      user.followersCount,<br/>                      user.friendsCount,<br/>                      world_cup_tweet.likeCount, <br/>                      world_cup_tweet.retweetCount<br/>                      ]<br/><br/>        final_tweets.append(tweet_data)<br/><br/>        if(index == total_number):<br/>            break<br/>            <br/>        <br/>    # Create the dataframe<br/>    final_tweets_df = pd.DataFrame(final_tweets, columns = column_names)<br/>    <br/>    return final_tweets_df</span></pre><p id="1fd8" class="pw-post-body-paragraph ll lm it ln b lo mh ju lq lr mi jx lt lu mj lw lx ly mk ma mb mc ml me mf mg im bi translated">这里最后举几个抓取法语推文和英语推文的例子。</p><pre class="ki kj kk kl gt nd mp ne bn nf ng bi"><span id="f1b4" class="nh ku it mp b be ni nj l nk nl"># French Tweets<br/>topic = "#worldcup"<br/>lang = "fr"<br/>fr_df = get_language_specific_tweets(topic, 200, lang)<br/><br/>fr_df.head()</span></pre><figure class="ki kj kk kl gt km gh gi paragraph-image"><div role="button" tabindex="0" class="nn no di np bf nq"><div class="gh gi od"><img src="../Images/cf2fed61d97e819794dd5ebba58dee99.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*vp3_VpMCpm9YE184eZ_Znw.png"/></div></div><figcaption class="kp kq gj gh gi kr ks bd b be z dk translated">法语推特(图片由作者提供)</figcaption></figure><pre class="ki kj kk kl gt nd mp ne bn nf ng bi"><span id="0acc" class="nh ku it mp b be ni nj l nk nl"># English Tweets about worldcup<br/>topic = "#worldcup"<br/>lang = "en"<br/>en_df = get_language_specific_tweets(topic, 200, lang)</span></pre><figure class="ki kj kk kl gt km gh gi paragraph-image"><div role="button" tabindex="0" class="nn no di np bf nq"><div class="gh gi oe"><img src="../Images/6e897c86a1e561bb9cb17550ff7b8a57.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*misoZEMwvh77DF_TFsDCGQ.png"/></div></div><figcaption class="kp kq gj gh gi kr ks bd b be z dk translated">英文推文(图片作者)</figcaption></figure><h1 id="022c" class="kt ku it bd kv kw kx ky kz la lb lc ld jz le ka lf kc lg kd lh kf li kg lj lk bi translated">结论</h1><p id="7d1b" class="pw-post-body-paragraph ll lm it ln b lo lp ju lq lr ls jx lt lu lv lw lx ly lz ma mb mc md me mf mg im bi translated">在这篇博客中，我们解释了如何使用<code class="fe mm mn mo mp b">snscrape</code>库抓取推文。我们还演示了如何定制刮擦过程来满足您的需求。<code class="fe mm mn mo mp b">snscrape</code>绝对是一个必去的图书馆，可以有效地收集用于多种目的的推文。</p><p id="ac4b" class="pw-post-body-paragraph ll lm it ln b lo mh ju lq lr mi jx lt lu mj lw lx ly mk ma mb mc ml me mf mg im bi translated">此外，如果你喜欢阅读我的故事，并希望支持我的写作，可以考虑<a class="ae mq" href="https://zoumanakeita.medium.com/membership" rel="noopener">成为一个媒体成员</a>。每月支付5美元，你就可以无限制地阅读媒体上的故事。</p><p id="af03" class="pw-post-body-paragraph ll lm it ln b lo mh ju lq lr mi jx lt lu mj lw lx ly mk ma mb mc ml me mf mg im bi translated">欢迎在<a class="ae mq" href="https://zoumanakeita.medium.com/" rel="noopener">媒体</a>、<a class="ae mq" href="https://twitter.com/zoumana_keita_" rel="noopener ugc nofollow" target="_blank">推特</a>和<a class="ae mq" href="https://www.youtube.com/channel/UC9xKdy8cz6ZuJU5FTNtM_pQ" rel="noopener ugc nofollow" target="_blank"> YouTube </a>上关注我，或者在<a class="ae mq" href="https://www.linkedin.com/in/zoumana-keita/" rel="noopener ugc nofollow" target="_blank"> LinkedIn </a>上问好。讨论人工智能、人工智能、数据科学、自然语言处理和人工智能是一种乐趣！</p></div></div>    
</body>
</html>