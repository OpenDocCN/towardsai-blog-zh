<html>
<head>
<title>Variable Reduction with Principal Component Analysis</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">主成分分析的变量约简</h1>
<blockquote>原文：<a href="https://pub.towardsai.net/machine-learning-1096c38e6a18?source=collection_archive---------1-----------------------#2021-05-17">https://pub.towardsai.net/machine-learning-1096c38e6a18?source=collection_archive---------1-----------------------#2021-05-17</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><h2 id="42a5" class="ir is it bd b dl iu iv iw ix iy iz dk ja translated" aria-label="kicker paragraph"><a class="ae ep" href="https://towardsai.net/p/category/machine-learning" rel="noopener ugc nofollow" target="_blank">机器学习</a></h2><div class=""/><div class=""><h2 id="8f9c" class="pw-subtitle-paragraph jz jc it bd b ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq dk translated">使用库Plotly Express对MNIST数据集进行可视化的示例</h2></div><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi kr"><img src="../Images/e790aa28cee2f5355fa8418f37597e88.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*tBj0kpFHiIP2NXJEQtNsbQ.png"/></div></div><figcaption class="ld le gj gh gi lf lg bd b be z dk translated">作者插图</figcaption></figure><p id="f208" class="pw-post-body-paragraph lh li it lj b lk ll kd lm ln lo kg lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">实际上，我在数据科学实习中遇到了这个话题。这不是第一次了。我在大学期间已经看过了，但是我从来没有真正理解我们应该使用这种方法的原因。大多数时候都是用高深的理论术语来解释，而没有给出在现实世界中应用的例子。那么，什么是主成分分析呢？我们为什么要利用它？这种方法的优点是什么？</p><blockquote class="md me mf"><p id="02f3" class="lh li mg lj b lk ll kd lm ln lo kg lp mh lr ls lt mi lv lw lx mj lz ma mb mc im bi translated">主成分分析是一种无监督的技术，它可以降低数据集的维数，同时尽可能地保留可变性。</p></blockquote><p id="6d0a" class="pw-post-body-paragraph lh li it lj b lk ll kd lm ln lo kg lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">它是怎么做到的？它将大量的观察变量减少到更少的分量，称为主分量。<strong class="lj jd">主成分是数据集中原始变量的线性组合</strong>。此外，这些成分使方差最大化，并且彼此不相关。第一个部分从数据中获取最大量的信息，因此它是方差最大的线性组合。第二分量考虑了第二大方差，并且与第一分量不相关。因此，方差从第一个分量到最后一个分量单调递减。</p><p id="7ab3" class="pw-post-body-paragraph lh li it lj b lk ll kd lm ln lo kg lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">主成分分析是卡尔·皮尔逊在1901年发现的，但同时，它也非常现代，因为它现在被广泛用于描述目的。特别是，在低维空间中表示高维数据非常有用。您可以在2D或3D维度空间中可视化数据集。当数据集中有三个以上的变量时，这是不可能的。它在诸如人脸识别和图像压缩等领域有应用。</p><h1 id="5119" class="mk ml it bd mm mn mo mp mq mr ms mt mu ki mv kj mw kl mx km my ko mz kp na nb bi translated">PCA是如何工作的？</h1><p id="e8e5" class="pw-post-body-paragraph lh li it lj b lk nc kd lm ln nd kg lp lq ne ls lt lu nf lw lx ly ng ma mb mc im bi translated">这种方法可以概括为5个步骤:</p><ol class=""><li id="08ca" class="nh ni it lj b lk ll ln lo lq nj lu nk ly nl mc nm nn no np bi translated">首先，数据集中的数量变量需要标准化。它们应该具有等于0的平均值和可比较的数值范围。</li></ol><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div class="gh gi nq"><img src="../Images/49c84c581831f458e2471aa54772987c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1334/format:webp/1*O1m7WkH6rlWX9TxLew9UUQ.png"/></div></figure><p id="e8b3" class="pw-post-body-paragraph lh li it lj b lk ll kd lm ln lo kg lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">2.一旦数据标准化，您就可以构建协方差矩阵</p><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div class="gh gi nr"><img src="../Images/a7d7247530d57098b95dc54433a18fd7.png" data-original-src="https://miro.medium.com/v2/resize:fit:1184/format:webp/1*Dd1rQi5pxpHXo3z4EvWy0w.png"/></div></figure><p id="10de" class="pw-post-body-paragraph lh li it lj b lk ll kd lm ln lo kg lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">3.从协方差矩阵计算特征向量和相应的特征值。</p><p id="3808" class="pw-post-body-paragraph lh li it lj b lk ll kd lm ln lo kg lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">4.需要按照降序对特征值进行排序，以对相应的特征向量进行排序。</p><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div class="gh gi ns"><img src="../Images/0ea99372af0d609343a66570dd317e62.png" data-original-src="https://miro.medium.com/v2/resize:fit:1294/format:webp/1*kjTp34riCHkkRbCnKD3QRA.png"/></div></figure><p id="b78b" class="pw-post-body-paragraph lh li it lj b lk ll kd lm ln lo kg lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">5.选择具有k个最大特征值的k个特征向量。k表示新特征子空间的维数。从顶部k个特征向量构建投影矩阵W。</p><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi nt"><img src="../Images/f6b0d3916fbb58be3f712fe99e46270d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*7hO1Sk_Vdyu4N6wNJB_mOA.png"/></div></div></figure><p id="259d" class="pw-post-body-paragraph lh li it lj b lk ll kd lm ln lo kg lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">7.使用投影矩阵W变换d维数据集，以获得新的k维特征子空间。</p><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div class="gh gi nu"><img src="../Images/bd2e2bad5451ab4596fc3de6a961fa88.png" data-original-src="https://miro.medium.com/v2/resize:fit:1082/format:webp/1*elh186joRhPbBhFOPBGDIA.png"/></div></figure><h1 id="a78a" class="mk ml it bd mm mn mo mp mq mr ms mt mu ki mv kj mw kl mx km my ko mz kp na nb bi translated">认证后活动的实施</h1><p id="d87c" class="pw-post-body-paragraph lh li it lj b lk nc kd lm ln nd kg lp lq ne ls lt lu nf lw lx ly ng ma mb mc im bi translated">我将展示应用于MNIST数据集的主成分分析的步骤，该数据集包含手写数字的图像。让我们导入sklearn库提供的数据集:</p><figure class="ks kt ku kv gt kw"><div class="bz fp l di"><div class="nv nw l"/></div></figure><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi nx"><img src="../Images/22dd0cd013dc049a571e0055cfd526cf.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*g_HBXtUUMWuvVVHsNvRX0g.png"/></div></div></figure><p id="82da" class="pw-post-body-paragraph lh li it lj b lk ll kd lm ln lo kg lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">在应用PCA之前，我们需要标准化数据:</p><figure class="ks kt ku kv gt kw"><div class="bz fp l di"><div class="nv nw l"/></div></figure><p id="5bde" class="pw-post-body-paragraph lh li it lj b lk ll kd lm ln lo kg lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">我们通过将特征矩阵与其转置形式相乘来获得协方差矩阵。</p><figure class="ks kt ku kv gt kw"><div class="bz fp l di"><div class="nv nw l"/></div></figure><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi ny"><img src="../Images/a6cd1d86f36ed641517a8c5e40469dde.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*03QoiYDhYyB7gdn4FNR-9Q.png"/></div></div></figure><p id="78bd" class="pw-post-body-paragraph lh li it lj b lk ll kd lm ln lo kg lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">协方差矩阵的维数是64 x 64，其中64是数据集的列数。下一步是从协方差矩阵计算特征值和特征向量。</p><figure class="ks kt ku kv gt kw"><div class="bz fp l di"><div class="nv nw l"/></div></figure><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi nz"><img src="../Images/0d0d317b8a6665b6475016d950c8a033.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*U25NSE86gE4Si74je5jmuw.png"/></div></div></figure><p id="9a81" class="pw-post-body-paragraph lh li it lj b lk ll kd lm ln lo kg lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">一旦计算出特征值，我们就可以导出由分量解释的累积方差。每个分量解释的方差是分量j 的<strong class="lj jd">特征值与所有分量特征值</strong>之和<strong class="lj jd">的比值。下面我将计算由组件解释的累积方差。</strong></p><figure class="ks kt ku kv gt kw"><div class="bz fp l di"><div class="nv nw l"/></div></figure><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi oa"><img src="../Images/cb1fa70ba7d0d19bb2d3d66e23198cbf.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*QAu7_pj6fXEoLGoU5NH9kQ.png"/></div></div></figure><p id="f761" class="pw-post-body-paragraph lh li it lj b lk ll kd lm ln lo kg lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">我们可以观察到，前四个分量占据了解释的累积方差的大约37%。只有当我们至少有20个组件时，累积方差才在80%左右。然后，我们选择20作为组件的数量。</p><p id="8622" class="pw-post-body-paragraph lh li it lj b lk ll kd lm ln lo kg lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">我们按降序对特征值和特征向量进行排序，因为我们希望首先得到可变性最高的特征值。一旦特征向量以正确的方式排序，我们可以将组件的数量减少到20。这个矩阵被称为<strong class="lj jd">投影矩阵</strong>，由可变性最高的前k个特征向量构建而成。</p><figure class="ks kt ku kv gt kw"><div class="bz fp l di"><div class="nv nw l"/></div></figure><p id="948b" class="pw-post-body-paragraph lh li it lj b lk ll kd lm ln lo kg lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">最后，我们可以使用投影矩阵来转换我们的标准化数据集，以获得<strong class="lj jd">新的k维特征子空间</strong>。</p><figure class="ks kt ku kv gt kw"><div class="bz fp l di"><div class="nv nw l"/></div></figure><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi ob"><img src="../Images/6c76b9ef2c111c2be4cda37da60b7b60.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*bDYiYVEQ85rDLJ14GPwdmA.png"/></div></div></figure><h1 id="efc7" class="mk ml it bd mm mn mo mp mq mr ms mt mu ki mv kj mw kl mx km my ko mz kp na nb bi translated"><strong class="ak">在MNIST数据集上使用sklearn的PCA</strong></h1><p id="b61e" class="pw-post-body-paragraph lh li it lj b lk nc kd lm ln nd kg lp lq ne ls lt lu nf lw lx ly ng ma mb mc im bi translated">我将展示在Sklearn中实现的PCA，它总是应用于MNIST数据集。使用标准化数据集，我们需要选择组件的数量，这些组件需要被指定为PCA函数中的自变量。</p><figure class="ks kt ku kv gt kw"><div class="bz fp l di"><div class="nv nw l"/></div></figure><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div class="gh gi oc"><img src="../Images/3f98e5e215305fba9f2207ee004e3201.png" data-original-src="https://miro.medium.com/v2/resize:fit:1384/format:webp/1*G_9WLOQuHmqT5TrzUMIXbQ.png"/></div></figure><p id="fae8" class="pw-post-body-paragraph lh li it lj b lk ll kd lm ln lo kg lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">我们获得了与之前相同的结果，我们保留了20个成分，这解释了数据可变性的80%。然后，我们选择20作为组件的数量。</p><figure class="ks kt ku kv gt kw"><div class="bz fp l di"><div class="nv nw l"/></div></figure><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div class="gh gi od"><img src="../Images/3ec083ad9576066c4d582cf93730b54b.png" data-original-src="https://miro.medium.com/v2/resize:fit:954/format:webp/1*2hT0QRLh4tTGsZp2atiF2Q.png"/></div></figure><p id="f6a7" class="pw-post-body-paragraph lh li it lj b lk ll kd lm ln lo kg lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">为了更快地了解组件保留的可变性，我们可以绘制出解释的方差。我们将使用<a class="ae oe" href="https://plotly.com/python/pca-visualization/" rel="noopener ugc nofollow" target="_blank"> plotly express库</a>，它允许构建交互式动态散点图。</p><figure class="ks kt ku kv gt kw"><div class="bz fp l di"><div class="nv nw l"/></div></figure><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi of"><img src="../Images/36ddd8be8bf47cf94ec199d393113b68.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*DmQ_Aup3Xq_5H7_8yiIBYA.png"/></div></div></figure><p id="03d0" class="pw-post-body-paragraph lh li it lj b lk ll kd lm ln lo kg lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">另一件有趣的事情是数据集的每一列对主成分的贡献。事实上，主成分是原始变量的线性组合。但是这些原始变量中的每一个都有不同的权重来创建这些分量。我将提取前五个组件，以便有一个更简单的概述。查看这些贡献的一个简单方法是显示热图:</p><figure class="ks kt ku kv gt kw"><div class="bz fp l di"><div class="nv nw l"/></div></figure><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi og"><img src="../Images/320d1b5dea81df466d9c32ed10921bd8.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*mt7qfXAoDJqBZ67u-8S6Rg.png"/></div></div></figure><p id="1b44" class="pw-post-body-paragraph lh li it lj b lk ll kd lm ln lo kg lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">现在，您可以观察哪个像素对每个主成分的贡献更大。这些权重称为负载，可以有负值(深紫色)、中性值或正值(黄色)。一般来说，在这个特定的数据集中，这些负载非常小，影响很小。当这些值大于-/+0.75时，载荷被认为是强的和显著的，但这不是我们的情况。使用plotly.express中的函数px.im_show的好处是，当您将鼠标悬停在这个彩色矩阵的单元格上时，您可以看到每个细节。这样，你就可以对这种无监督的方法有更好的解读。</p><p id="e85a" class="pw-post-body-paragraph lh li it lj b lk ll kd lm ln lo kg lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">一旦我们了解了主成分是如何获得的，我们就有兴趣将所有数据集可视化为一个图形。由于主成分分析降低了图像数据集的维度，这是可能的。我们可以通过函数scatter_matrix显示几个主成分。我选择只显示前四个组件，以便有一个更简单和清晰的可视化。</p><figure class="ks kt ku kv gt kw"><div class="bz fp l di"><div class="nv nw l"/></div></figure><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi oh"><img src="../Images/d2126f40d723fef2718dcfcfcc8c72c4.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*rxsz-YHytkT2aSa9gwFRhQ.png"/></div></div></figure><p id="19de" class="pw-post-body-paragraph lh li it lj b lk ll kd lm ln lo kg lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">该图还显示了解释的总差异和每个组成部分解释的差异。第一个分量捕获了数据中最大的可变性，11.7%。第二个分量保留9.5 %的方差，依此类推。</p><p id="9fdb" class="pw-post-body-paragraph lh li it lj b lk ll kd lm ln lo kg lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">如果我们只想看到前两个部分，我们可以显示一个简单的散点图。这样，我们在2维空间中减少了64维的数据集:</p><figure class="ks kt ku kv gt kw"><div class="bz fp l di"><div class="nv nw l"/></div></figure><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi oi"><img src="../Images/a07a34ff9be5b3820563ca31d784c83f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*CoIUpPNMHMrdr1IOb5klww.png"/></div></div></figure><p id="cf40" class="pw-post-body-paragraph lh li it lj b lk ll kd lm ln lo kg lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">我们还可以在图中添加一个额外的组件。正如我们所看到的，前三个组件一起捕获了解释的总方差的大约40%,我们可以更好地可视化我们的数据集。</p><figure class="ks kt ku kv gt kw"><div class="bz fp l di"><div class="nv nw l"/></div></figure><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div class="gh gi oj"><img src="../Images/2aad6fe66949fce64ebe56bb1bf1b3f2.png" data-original-src="https://miro.medium.com/v2/resize:fit:1200/1*k6HFC-J696mGgLcOJvcw4A.gif"/></div></figure><p id="07d2" class="pw-post-body-paragraph lh li it lj b lk ll kd lm ln lo kg lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">数字的类别沿着这个3D空间重叠。一些数字相互混淆。例如，3和8没有分开，8的簇部分地覆盖了数字3的簇。所以，阶级划分得还不够。这些限制的原因是PCA使用线性变换来获得主分量，并且不考虑非线性特征。一种更好的可视化MNIST数据集的方法是t-SNE(t-分布式随机相邻实体)。</p></div><div class="ab cl ok ol hx om" role="separator"><span class="on bw bk oo op oq"/><span class="on bw bk oo op oq"/><span class="on bw bk oo op"/></div><div class="im in io ip iq"><h1 id="cd44" class="mk ml it bd mm mn or mp mq mr os mt mu ki ot kj mw kl ou km my ko ov kp na nb bi translated">最终想法:</h1><p id="0fca" class="pw-post-body-paragraph lh li it lj b lk nc kd lm ln nd kg lp lq ne ls lt lu nf lw lx ly ng ma mb mc im bi translated">我希望这个指南能帮助你掌握这种方法。正如您在示例中看到的，它有一些限制，但它仍然有用，因为它易于理解，并且具有很高的可解释性。</p><p id="e8d3" class="pw-post-body-paragraph lh li it lj b lk ll kd lm ln lo kg lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">感谢阅读。祝你有愉快的一天。</p></div><div class="ab cl ok ol hx om" role="separator"><span class="on bw bk oo op oq"/><span class="on bw bk oo op oq"/><span class="on bw bk oo op"/></div><div class="im in io ip iq"><p id="5aca" class="pw-post-body-paragraph lh li it lj b lk ll kd lm ln lo kg lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated"><strong class="lj jd">参考文献:</strong></p><ul class=""><li id="7bb5" class="nh ni it lj b lk ll ln lo lq nj lu nk ly nl mc ow nn no np bi translated"><a class="ae oe" href="https://www.askpython.com/python/examples/principal-component-analysis" rel="noopener ugc nofollow" target="_blank">https://www . ask python . com/python/examples/principal-component-analysis</a></li><li id="534d" class="nh ni it lj b lk ox ln oy lq oz lu pa ly pb mc ow nn no np bi translated"><a class="ae oe" href="https://www.researchgate.net/post/How-can-I-interpret-PCA-results" rel="noopener ugc nofollow" target="_blank">https://www . research gate . net/post/How-can-I-interpret-PCA-results</a></li></ul></div><div class="ab cl ok ol hx om" role="separator"><span class="on bw bk oo op oq"/><span class="on bw bk oo op oq"/><span class="on bw bk oo op"/></div><div class="im in io ip iq"><p id="376e" class="pw-post-body-paragraph lh li it lj b lk ll kd lm ln lo kg lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">你喜欢我的文章吗？<a class="ae oe" href="https://eugenia-anello.medium.com/membership" rel="noopener"> <em class="mg">成为会员</em> </a> <em class="mg">每天无限获取数据科学新帖！这是一种间接的支持我的方式，不会给你带来任何额外的费用。如果您已经是会员，</em> <a class="ae oe" href="https://eugenia-anello.medium.com/subscribe" rel="noopener"> <em class="mg">订阅</em> </a> <em class="mg">每当我发布新的数据科学和python指南时，您都可以收到电子邮件！</em></p></div></div>    
</body>
</html>