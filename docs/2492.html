<html>
<head>
<title>Univariate Time Series With Stacked LSTM, BiLSTM, and NeuralProphet</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">具有堆叠LSTM、BiLSTM和NeuralProphet的单变量时间序列</h1>
<blockquote>原文：<a href="https://pub.towardsai.net/univariate-time-series-with-stacked-lstm-bilstm-and-neuralprophet-c8d6a11a9665?source=collection_archive---------0-----------------------#2022-01-17">https://pub.towardsai.net/univariate-time-series-with-stacked-lstm-bilstm-and-neuralprophet-c8d6a11a9665?source=collection_archive---------0-----------------------#2022-01-17</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><h2 id="f334" class="io ip iq bd b dl ir is it iu iv iw dk ix translated" aria-label="kicker paragraph"><a class="ae ep" href="https://towardsai.net/p/category/machine-learning/deep-learning" rel="noopener ugc nofollow" target="_blank">深度学习</a></h2><div class=""/><div class=""><h2 id="56ed" class="pw-subtitle-paragraph jw iz iq bd b jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn dk translated">为多步时间序列开发深度学习LSTM、BiLSTM模型和NeuralProphet</h2></div><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div role="button" tabindex="0" class="ku kv di kw bf kx"><div class="gh gi ko"><img src="../Images/a0fadbd7a916bad79a6bf9eb61be1fdd.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*7s0V3E8weget4WrTBZPqmA.jpeg"/></div></div><figcaption class="la lb gj gh gi lc ld bd b be z dk translated">为时间序列开发LSTM、BiLSTM模型和NeuralProphet由<a class="ae le" href="https://unsplash.com/@nick604?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText" rel="noopener ugc nofollow" target="_blank"> Nick Chong </a>在<a class="ae le" href="https://unsplash.com/s/photos/stock-market?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上拍摄</figcaption></figure><h1 id="1b83" class="lf lg iq bd lh li lj lk ll lm ln lo lp kf lq kg lr ki ls kj lt kl lu km lv lw bi translated">目录</h1><ul class=""><li id="73f8" class="lx ly iq lz b ma mb mc md me mf mg mh mi mj mk ml mm mn mo bi translated"><a class="ae le" href="https://medium.com/p/c8d6a11a9665/#20b9" rel="noopener">简介</a></li><li id="6e30" class="lx ly iq lz b ma mp mc mq me mr mg ms mi mt mk ml mm mn mo bi translated"><a class="ae le" href="https://medium.com/p/c8d6a11a9665/#a6df" rel="noopener">什么是时间序列？</a></li><li id="6559" class="lx ly iq lz b ma mp mc mq me mr mg ms mi mt mk ml mm mn mo bi translated"><a class="ae le" href="https://medium.com/p/c8d6a11a9665/#320e" rel="noopener">什么是LSTM </a>？</li><li id="1987" class="lx ly iq lz b ma mp mc mq me mr mg ms mi mt mk ml mm mn mo bi translated"><a class="ae le" href="https://medium.com/p/c8d6a11a9665/#69d8" rel="noopener">什么是双向LSTM </a>？</li><li id="0c36" class="lx ly iq lz b ma mp mc mq me mr mg ms mi mt mk ml mm mn mo bi translated"><a class="ae le" href="https://medium.com/p/c8d6a11a9665/#eadc" rel="noopener">什么是NeuralProphet </a>？</li><li id="7fa8" class="lx ly iq lz b ma mp mc mq me mr mg ms mi mt mk ml mm mn mo bi translated"><a class="ae le" href="https://medium.com/p/c8d6a11a9665/#f89c" rel="noopener">让我们从股票数据开始</a></li><li id="1085" class="lx ly iq lz b ma mp mc mq me mr mg ms mi mt mk ml mm mn mo bi translated"><a class="ae le" href="https://medium.com/p/c8d6a11a9665/#5668" rel="noopener">模型实施阶段</a></li><li id="b50b" class="lx ly iq lz b ma mp mc mq me mr mg ms mi mt mk ml mm mn mo bi translated"><a class="ae le" href="https://medium.com/p/c8d6a11a9665/#4146" rel="noopener">车型训练&amp;验证失败</a></li><li id="9c47" class="lx ly iq lz b ma mp mc mq me mr mg ms mi mt mk ml mm mn mo bi translated"><a class="ae le" href="https://medium.com/p/c8d6a11a9665/#4f1c" rel="noopener">结论</a></li><li id="0f30" class="lx ly iq lz b ma mp mc mq me mr mg ms mi mt mk ml mm mn mo bi translated"><a class="ae le" href="https://medium.com/p/c8d6a11a9665/#5856" rel="noopener">参考</a></li></ul><h1 id="20b9" class="lf lg iq bd lh li lj lk ll lm ln lo lp kf lq kg lr ki ls kj lt kl lu km lv lw bi translated">介绍</h1><p id="5f2e" class="pw-post-body-paragraph mu mv iq lz b ma mb ka mw mc md kd mx me my mz na mg nb nc nd mi ne nf ng mk ij bi translated">你愿意尝试回归之外的方法来解决你的时间序列问题吗？然后，这篇文章将通过深度学习技术利用时间序列来实现更好的优化和预测，以使用单变量因变量作为随时间变化的单个时间序列来进行预测。对数据科学家来说，预测股市是一种有吸引力的潜力，其动机是挑战，而不是对财务收益的渴望。我们检查市场的每日涨跌，并想象一定有一种模式，在这种模式中，我们的模型优于股票交易。</p><p id="2a20" class="pw-post-body-paragraph mu mv iq lz b ma nh ka mw mc ni kd mx me nj mz na mg nk nc nd mi nl nf ng mk ij bi translated">因此，这篇文章的主要目的是；实现深度学习算法递归神经网络(RNNs)的两个顺序模型，如堆叠LSTM、双向LSTM和用<a class="ae le" href="https://pytorch.org/" rel="noopener ugc nofollow" target="_blank"> PyTorch </a>构建的<a class="ae le" href="https://github.com/ourownstory/neural_prophet/?utm_source=hootsuite&amp;utm_medium&amp;utm_term&amp;utm_content&amp;utm_campaign&amp;fbclid=IwAR1G35yRHAhO-UwiuR2UPGKwBlUtU98cJyPxu5vA4P-XTDzgBEwLe5Iq0EA" rel="noopener ugc nofollow" target="_blank"> NeuralProphet </a>，使用基于深度学习的时间序列预测来预测股票价格。</p><p id="cc85" class="pw-post-body-paragraph mu mv iq lz b ma nh ka mw mc ni kd mx me nj mz na mg nk nc nd mi nl nf ng mk ij bi translated">让我们假设读者已经基本掌握了时间序列和深度学习模型。但是，我将简要解释文章的一些概念，以刷新对基本面的一些想法。</p><h1 id="a6df" class="lf lg iq bd lh li lj lk ll lm ln lo lp kf lq kg lr ki ls kj lt kl lu km lv lw bi translated">什么是时间序列？</h1><blockquote class="nm nn no"><p id="cf59" class="mu mv np lz b ma nh ka mw mc ni kd mx nq nj mz na nr nk nc nd ns nl nf ng mk ij bi translated"><a class="ae le" href="https://www.investopedia.com/terms/t/timeseries.asp" rel="noopener ugc nofollow" target="_blank">时间序列的定义:</a> <em class="iq"> <br/> </em>时间序列是一段时间内连续出现的数据点序列。这可以与<a class="ae le" href="https://www.investopedia.com/terms/c/cross_sectional_analysis.asp" rel="noopener ugc nofollow" target="_blank">横截面数据</a>形成对比，后者捕捉一个时间点。</p></blockquote><p id="8ed7" class="pw-post-body-paragraph mu mv iq lz b ma nh ka mw mc ni kd mx me nj mz na mg nk nc nd mi nl nf ng mk ij bi translated">为了简单起见，时间序列是一组随着时间的推移对对象的观察，在个人财务的每日收盘价或全年的每小时程序中每分钟测量一次。现在让我们把时间序列分成两部分:<strong class="lz ja">分析</strong>和<strong class="lz ja">预测</strong>。</p><p id="09de" class="pw-post-body-paragraph mu mv iq lz b ma nh ka mw mc ni kd mx me nj mz na mg nk nc nd mi nl nf ng mk ij bi translated">时间序列分析涉及了解序列内在特征的不同方面，以便您可以获得更好的信息来做出有意义的预测。另一方面，将模型与过去的数据进行拟合，并使用它来预测未来的观察值，这就是时间序列预测的全部内容。</p><h1 id="320e" class="lf lg iq bd lh li lj lk ll lm ln lo lp kf lq kg lr ki ls kj lt kl lu km lv lw bi translated">什么是<strong class="ak"> LSTM </strong></h1><p id="4ff8" class="pw-post-body-paragraph mu mv iq lz b ma mb ka mw mc md kd mx me my mz na mg nb nc nd mi ne nf ng mk ij bi translated">长期短期记忆(LSTM)，一种人工<a class="ae le" href="https://www.ibm.com/cloud/learn/recurrent-neural-networks" rel="noopener ugc nofollow" target="_blank">递归神经网络</a> (RNN)的形式，可以用来根据历史数据预测库存值。它的开发是为了消除长期依赖的问题，并有助于避免<a class="ae le" href="https://www.analyticsvidhya.com/blog/2021/06/the-challenge-of-vanishing-exploding-gradients-in-deep-neural-networks/" rel="noopener ugc nofollow" target="_blank">梯度消失</a>。LSTMs适合于对序列数据建模，因为它们维护内部状态来跟踪已经看到的数据。时间序列和自然语言处理是LSTMs中的两个常见用途，因为它们具有反馈联系；这意味着不仅可以处理单个数据点，还可以处理完整的数据序列。</p><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div role="button" tabindex="0" class="ku kv di kw bf kx"><div class="gh gi nt"><img src="../Images/02b796d7579968f63bc3d29f1cefead3.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*X_xacrIrIn53VRCAG330YQ.jpeg"/></div></div><figcaption class="la lb gj gh gi lc ld bd b be z dk translated">LSTM街区的结构——来自作者</figcaption></figure><p id="9e92" class="pw-post-body-paragraph mu mv iq lz b ma nh ka mw mc ni kd mx me nj mz na mg nk nc nd mi nl nf ng mk ij bi translated">LSTM由许多内存块组成，如图所示是一个完整的内存块。两个状态被带到下一个块；单元格状态(存储和加载信息)和隐藏状态(携带之前事件的信息并覆盖)。LSTMs使用一个称为gates的过程来学习。这些门可以学习序列中的哪些信息应该被保留或删除。因此，LSTM包含三个门:输入、遗忘和输出。更多关于LSTM的细节请点击这里。</p><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div class="gh gi nu"><img src="../Images/7039476d6bb6882a757e287e9d0c1a31.png" data-original-src="https://miro.medium.com/v2/resize:fit:1120/format:webp/1*fRsPdpOMZkNhRWr5utn2Iw.png"/></div></figure><p id="15ba" class="pw-post-body-paragraph mu mv iq lz b ma nh ka mw mc ni kd mx me nj mz na mg nk nc nd mi nl nf ng mk ij bi translated"><strong class="lz ja"> f </strong> <em class="np"> t </em> <strong class="lz ja"> =忘门</strong></p><p id="f6f9" class="pw-post-body-paragraph mu mv iq lz b ma nh ka mw mc ni kd mx me nj mz na mg nk nc nd mi nl nf ng mk ij bi translated"><strong class="lz ja">I</strong>T10】tT12】=输入门</p><p id="83df" class="pw-post-body-paragraph mu mv iq lz b ma nh ka mw mc ni kd mx me nj mz na mg nk nc nd mi nl nf ng mk ij bi translated"><strong class="lz ja">o</strong>t<em class="np">t</em>T18】=输出门</p><p id="b9f6" class="pw-post-body-paragraph mu mv iq lz b ma nh ka mw mc ni kd mx me nj mz na mg nk nc nd mi nl nf ng mk ij bi translated"><strong class="lz ja">C</strong>T22】tT24】=细胞状态</p><p id="788d" class="pw-post-body-paragraph mu mv iq lz b ma nh ka mw mc ni kd mx me nj mz na mg nk nc nd mi nl nf ng mk ij bi translated"><strong class="lz ja">h</strong>T28】tT30】=隐藏状态</p><h1 id="69d8" class="lf lg iq bd lh li lj lk ll lm ln lo lp kf lq kg lr ki ls kj lt kl lu km lv lw bi translated">什么是双向LSTM</h1><p id="ef39" class="pw-post-body-paragraph mu mv iq lz b ma mb ka mw mc md kd mx me my mz na mg nb nc nd mi ne nf ng mk ij bi translated">双向长短期记忆(BiLSTM)是一种允许任何神经网络以两种方式存储序列信息的技术，或者向后或者向前。我们的输入双向运行，区分一个<a class="ae le" href="https://en.wikipedia.org/wiki/Bidirectional_recurrent_neural_networks" rel="noopener ugc nofollow" target="_blank"> BiLSTM </a>和一个标准LSTM。我们可以有两个方向的输入流；在任何时间点存储过去和未来的信息。然而，正常的LSTMs允许一个方向的输入流(向前或向后)。</p><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div role="button" tabindex="0" class="ku kv di kw bf kx"><div class="gh gi nv"><img src="../Images/f0a2cdeb3b22ab6513b22e4e48a02524.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*-EOMBUbNUp1icoPnkvS8dQ.png"/></div></div><figcaption class="la lb gj gh gi lc ld bd b be z dk translated">双向LSTM的基本结构—图片<a class="ae le" href="https://www.mdpi.com/2076-3417/11/17/8129/htm" rel="noopener ugc nofollow" target="_blank">来源</a></figcaption></figure><h1 id="eadc" class="lf lg iq bd lh li lj lk ll lm ln lo lp kf lq kg lr ki ls kj lt kl lu km lv lw bi translated">什么是神经营养</h1><p id="c174" class="pw-post-body-paragraph mu mv iq lz b ma mb ka mw mc md kd mx me my mz na mg nb nc nd mi ne nf ng mk ij bi translated">NeuralProphet是一个新的开源时间序列预测工具包，使用<a class="ae le" href="https://pytorch.org/" rel="noopener ugc nofollow" target="_blank"> PyTorch </a>创建，基于神经网络。它是Prophet(自动预测程序)的增强版本，这是一个预测库，允许您在<a class="ae le" href="https://ai.facebook.com/blog/ar-net-a-simple-autoregressive-neural-network-for-time-series/" rel="noopener ugc nofollow" target="_blank"> AR-Net库</a>(自回归神经网络)的影响下，利用更高级和复杂的深度学习模型进行时间序列预测。</p><p id="000e" class="pw-post-body-paragraph mu mv iq lz b ma nh ka mw mc ni kd mx me nj mz na mg nk nc nd mi nl nf ng mk ij bi translated"><em class="np"> *使用以下命令从GitHub安装该工具的最新版本，并查看以下链接获取</em> <strong class="lz ja"> NeuralProphet </strong>文档<em class="np">。</em></p><pre class="kp kq kr ks gt nw nx ny nz aw oa bi"><span id="639e" class="ob lg iq nx b gy oc od l oe of">#Use (!pip)if it did not install<br/>pip install neuralprophet</span><span id="4753" class="ob lg iq nx b gy og od l oe of">#Live version(more features)if you are going to use the Jupyter<br/>pip install neuralprophet[live]</span></pre><div class="oh oi gp gr oj ok"><a href="https://github.com/ourownstory/neural_prophet" rel="noopener  ugc nofollow" target="_blank"><div class="ol ab fo"><div class="om ab on cl cj oo"><h2 class="bd ja gy z fp op fr fs oq fu fw iz bi translated">GitHub-ourowstory/neural _ prophet:neural prophet:一个简单的预测包</h2><div class="or l"><h3 class="bd b gy z fp op fr fs oq fu fw dk translated">请注意，该项目仍处于测试阶段。请报告您遇到的任何问题或您的建议。我们…</h3></div><div class="os l"><p class="bd b dl z fp op fr fs oq fu fw dk translated">github.com</p></div></div><div class="ot l"><div class="ou l ov ow ox ot oy ky ok"/></div></div></a></div><h1 id="f89c" class="lf lg iq bd lh li lj lk ll lm ln lo lp kf lq kg lr ki ls kj lt kl lu km lv lw bi translated">让我们从股票数据开始</h1><h2 id="28cd" class="ob lg iq bd lh oz pa dn ll pb pc dp lp me pd pe lr mg pf pg lt mi ph pi lv iw bi translated">1.数据准备</h2><p id="2d71" class="pw-post-body-paragraph mu mv iq lz b ma mb ka mw mc md kd mx me my mz na mg nb nc nd mi ne nf ng mk ij bi translated">在本项目中，数据取自从<a class="ae le" href="https://finance.yahoo.com/quote/AAPL/history?p=AAPL%5C" rel="noopener ugc nofollow" target="_blank"> <strong class="lz ja">雅虎财经</strong> </a>直接导出的<strong class="lz ja">苹果公司(AAPL) </strong>和<strong class="lz ja"/>2010年1月4日至2021年11月2日。股票价格历史将是过去11年(<em class="np">包括</em> <strong class="lz ja"> <em class="np">新冠肺炎</em> </strong> <em class="np">时期</em>)以来我们使用神经网络，数据越多，模型训练越好。如上所述，上述模型和工具将作为单变量时间序列应用于数据集的“日期”。</p><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div role="button" tabindex="0" class="ku kv di kw bf kx"><div class="gh gi pj"><img src="../Images/019103bb9baf5166df26cfd41575da5e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*XC0V22G0QDRxr4QgvqYDRg.png"/></div></div><figcaption class="la lb gj gh gi lc ld bd b be z dk translated">如何从雅虎财经导出股票价格历史——来自作者</figcaption></figure><h2 id="95a4" class="ob lg iq bd lh oz pa dn ll pb pc dp lp me pd pe lr mg pf pg lt mi ph pi lv iw bi translated">2.数据预处理</h2><ul class=""><li id="23cb" class="lx ly iq lz b ma mb mc md me mf mg mh mi mj mk ml mm mn mo bi translated">导入库</li></ul><pre class="kp kq kr ks gt nw nx ny nz aw oa bi"><span id="736b" class="ob lg iq nx b gy oc od l oe of"># Use <strong class="nx ja">Colab</strong> notebooks(recommended) or <strong class="nx ja">jupyterlab, etc.</strong><br/>import pandas as pd<br/>import numpy as np<br/>import seaborn as sns<br/>import matplotlib.pyplot as plt<br/>from matplotlib.pylab import rcParams<br/>from datetime import datetime<br/>import warnings<br/>warnings.filterwarnings('ignore')<br/>%matplotlib inline</span></pre><ul class=""><li id="3e47" class="lx ly iq lz b ma nh mc ni me pk mg pl mi pm mk ml mm mn mo bi translated">读取和浏览数据</li></ul><pre class="kp kq kr ks gt nw nx ny nz aw oa bi"><span id="dfce" class="ob lg iq nx b gy oc od l oe of"># Reading the exported file as CSV. <br/>data = pd.read_csv("AAPL.csv")<br/>print(data.head())</span><span id="ca2c" class="ob lg iq nx b gy og od l oe of"># Check duplicate, nan and so on. <br/>data.duplicated().sum().any()<br/>data.isna().sum()<br/></span><span id="ad5e" class="ob lg iq nx b gy og od l oe of"># Function to explore and validate<br/>def explore(df):<br/>   print(f"Dataset Shape: {df.shape}")<br/>   summary = pd.DataFrame(df.dtypes,columns=['dtypes'])<br/>   summary = summary.reset_index()<br/>   summary['Name'] = summary['index']<br/>   summary = summary[['Name','dtypes']]<br/>   summary['Missing'] = df.isnull().sum().values<br/>   summary['Uniques'] = df.nunique().values<br/>   return summary</span><span id="5bf9" class="ob lg iq nx b gy og od l oe of"># function call<br/>explore(data)</span></pre><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div class="gh gi pn"><img src="../Images/f5a478a8d5b0a3d3edf0457d657717db.png" data-original-src="https://miro.medium.com/v2/resize:fit:1268/format:webp/1*UAx4O_Azbl4RQ35GWu-3DQ.png"/></div><figcaption class="la lb gj gh gi lc ld bd b be z dk translated">探索<em class="po">功能</em>的结果—来自作者</figcaption></figure><p id="2bab" class="pw-post-body-paragraph mu mv iq lz b ma nh ka mw mc ni kd mx me nj mz na mg nk nc nd mi nl nf ng mk ij bi translated">如您所见，在应用<em class="np">浏览函数</em>后，“日期”是一个对象类型，需要更改为日期时间格式，如下所示:</p><pre class="kp kq kr ks gt nw nx ny nz aw oa bi"><span id="76a7" class="ob lg iq nx b gy oc od l oe of"># convert Date from object to datetime<br/>data['Date'] = pd.to_datetime(data['Date'], infer_datetime_format=True)</span><span id="2c8b" class="ob lg iq nx b gy og od l oe of"># print info to check conversion <br/>data=data.set_index(['Date']) # set date as index or rest_index()<br/>data.head()<br/>print(data.info())</span><span id="fee1" class="ob lg iq nx b gy og od l oe of"><strong class="nx ja"># Output:<br/></strong>Data columns (total 7 columns):<br/> #   Column     Non-Null Count  Dtype         <br/>---  ------     --------------  -----         <br/> 0   <strong class="nx ja">Date </strong>      2980 non-null   datetime64[ns]<br/> 1   Open       2980 non-null   float64       <br/> 2   High       2980 non-null   float64       <br/> 3   Low        2980 non-null   float64       <br/> 4   Close      2980 non-null   float64       <br/> 5   <strong class="nx ja">Adj Close</strong>  2980 non-null   float64       <br/> 6   Volume     2980 non-null   int64<br/> #   Column     Non-Null Count  Dtype         <br/>---  ------     --------------  -----         </span></pre><h1 id="5668" class="lf lg iq bd lh li lj lk ll lm ln lo lp kf lq kg lr ki ls kj lt kl lu km lv lw bi translated">模型实施阶段</h1><h2 id="6441" class="ob lg iq bd lh oz pa dn ll pb pc dp lp me pd pe lr mg pf pg lt mi ph pi lv iw bi translated">1.堆叠LSTM</h2><p id="57fc" class="pw-post-body-paragraph mu mv iq lz b ma mb ka mw mc md kd mx me my mz na mg nb nc nd mi ne nf ng mk ij bi translated">对股票数据进行预处理后,“Adj Close”特性将成为目标值。因此，“Adj Close”考虑了任何可能在收盘后影响股价的因素(拆分、股息和配股)。</p><p id="2b43" class="pw-post-body-paragraph mu mv iq lz b ma nh ka mw mc ni kd mx me nj mz na mg nk nc nd mi nl nf ng mk ij bi translated">然后，在模型拟合之前，使用来自<a class="ae le" href="https://scikit-learn.org/stable/modules/preprocessing.html#normalization" rel="noopener ugc nofollow" target="_blank"> sklearn </a>的MinMaxScaler函数对数据进行标准化，这将促进和提升神经网络的性能。</p><ul class=""><li id="9245" class="lx ly iq lz b ma nh mc ni me pk mg pl mi pm mk ml mm mn mo bi translated">让我们深入研究代码:</li></ul><figure class="kp kq kr ks gt kt"><div class="bz fp l di"><div class="pp pq l"/></div><figcaption class="la lb gj gh gi lc ld bd b be z dk translated">堆叠的LSTM代码—来自作者</figcaption></figure><p id="bc3e" class="pw-post-body-paragraph mu mv iq lz b ma nh ka mw mc ni kd mx me nj mz na mg nk nc nd mi nl nf ng mk ij bi translated">如果多次耐心等待后验证损失仍未减少(训练后无改善)，现在是时候构建带有<a class="ae le" href="https://www.tensorflow.org/api_docs/python/tf/keras/callbacks/EarlyStopping" rel="noopener ugc nofollow" target="_blank">提前停止</a>的堆叠LSTM(多层)以避免过度拟合。</p><p id="b0dc" class="pw-post-body-paragraph mu mv iq lz b ma nh ka mw mc ni kd mx me nj mz na mg nk nc nd mi nl nf ng mk ij bi translated">注意:<a class="ae le" href="https://www.tensorflow.org/api_docs/python/tf/random/set_seed" rel="noopener ugc nofollow" target="_blank">如果您希望每次运行模型时都得到相同的结果，而每次运行都不会得到不同的结果，请设置TensorFlow的随机种子</a>(可重复的结果)，或者保存模型或其权重以供以后最佳训练使用(<a class="ae le" href="https://www.tensorflow.org/tutorials/keras/save_and_load" rel="noopener ugc nofollow" target="_blank">关于如何存储和加载模型的更多详细信息，请参见</a>)。</p><figure class="kp kq kr ks gt kt"><div class="bz fp l di"><div class="pp pq l"/></div><figcaption class="la lb gj gh gi lc ld bd b be z dk translated">堆叠LSTM模型—作者提供</figcaption></figure><pre class="kp kq kr ks gt nw nx ny nz aw oa bi"><span id="38f9" class="ob lg iq nx b gy oc od l oe of"># The figure below of the real “Adj Close” feature of Apple stock from the dataset (y-axis is the stock price and x-axis is the date).</span><span id="2c63" class="ob lg iq nx b gy og od l oe of">data.set_index('Date')['Adj Close'].plot(figsize=FIGURE_SIZE)</span></pre><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div role="button" tabindex="0" class="ku kv di kw bf kx"><div class="gh gi pr"><img src="../Images/c101ee37642710321788e0933649bb16.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*48O_g4zHr1Sv9D347IZYWg.png"/></div></div><figcaption class="la lb gj gh gi lc ld bd b be z dk translated">从2010年1月4日到2021年11月2日，苹果股票在“调整收盘”时的实际价格——来自作者</figcaption></figure><ul class=""><li id="5c09" class="lx ly iq lz b ma nh mc ni me pk mg pl mi pm mk ml mm mn mo bi translated">可视化堆叠LSTM结果</li></ul><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div role="button" tabindex="0" class="ku kv di kw bf kx"><div class="gh gi ps"><img src="../Images/b066d0d4f3774b874dc375995da5624e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*nd4MRQW_locHFx8cjbbKmQ.png"/></div></div><figcaption class="la lb gj gh gi lc ld bd b be z dk translated">预测苹果股票价格在“调整收盘”时的叠加LSTM结果——来自作者</figcaption></figure><h2 id="6a11" class="ob lg iq bd lh oz pa dn ll pb pc dp lp me pd pe lr mg pf pg lt mi ph pi lv iw bi translated">2.双向LSTM</h2><p id="a200" class="pw-post-body-paragraph mu mv iq lz b ma mb ka mw mc md kd mx me my mz na mg nb nc nd mi ne nf ng mk ij bi translated">从堆叠的LSTM数据集构建具有相同选定特征(调整后收盘价)的<strong class="lz ja"> </strong>双向LSTM模型。</p><figure class="kp kq kr ks gt kt"><div class="bz fp l di"><div class="pp pq l"/></div><figcaption class="la lb gj gh gi lc ld bd b be z dk translated">BiLSTM代码—来自作者</figcaption></figure><p id="185e" class="pw-post-body-paragraph mu mv iq lz b ma nh ka mw mc ni kd mx me nj mz na mg nk nc nd mi nl nf ng mk ij bi translated">如下图所示，利用ReLU(整流线性单元)<a class="ae le" href="https://en.wikipedia.org/wiki/Activation_function" rel="noopener ugc nofollow" target="_blank">激活功能</a>创建了一层BiLSTM。但是，如果应用RMSProp(均方根传播)优化器，它将产生与Adam优化器(在BiLSTM构建中使用)几乎相似的结果，您可以试验所有的优化器。</p><figure class="kp kq kr ks gt kt"><div class="bz fp l di"><div class="pp pq l"/></div><figcaption class="la lb gj gh gi lc ld bd b be z dk translated">比尔斯特姆大厦——来自作者</figcaption></figure><ul class=""><li id="1b85" class="lx ly iq lz b ma nh mc ni me pk mg pl mi pm mk ml mm mn mo bi translated">可视化BiLSTM结果</li></ul><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div role="button" tabindex="0" class="ku kv di kw bf kx"><div class="gh gi pt"><img src="../Images/a16c901c3619f2df533e1f08ece28de0.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*zCxo06SD5FYzTnW7jPFjfw.png"/></div></div><figcaption class="la lb gj gh gi lc ld bd b be z dk translated">比尔斯特姆预测苹果股票价格“接近”的结果——来自作者</figcaption></figure><h2 id="f8f9" class="ob lg iq bd lh oz pa dn ll pb pc dp lp me pd pe lr mg pf pg lt mi ph pi lv iw bi translated">3.神经营养细胞</h2><p id="61be" class="pw-post-body-paragraph mu mv iq lz b ma mb ka mw mc md kd mx me my mz na mg nb nc nd mi ne nf ng mk ij bi translated">最后，让我们从用于基于神经网络的时间序列建模的NeuralProphet开始。</p><ul class=""><li id="5e36" class="lx ly iq lz b ma nh mc ni me pk mg pl mi pm mk ml mm mn mo bi translated">安装并导入库，如下例所示:</li></ul><figure class="kp kq kr ks gt kt"><div class="bz fp l di"><div class="pp pq l"/></div><figcaption class="la lb gj gh gi lc ld bd b be z dk translated">安装和导入NeuralProphet —来自作者</figcaption></figure><p id="7801" class="pw-post-body-paragraph mu mv iq lz b ma nh ka mw mc ni kd mx me nj mz na mg nk nc nd mi nl nf ng mk ij bi translated">NeuralProphet模型拟合对象假定时间序列数据有一个名为<strong class="lz ja"> ds </strong>(日期)<strong class="lz ja"> </strong>的日期列和一个预期为<strong class="lz ja"> y ( </strong>预测<strong class="lz ja"> </strong>列名-调整关闭)的时间序列值。遵循以下代码:</p><figure class="kp kq kr ks gt kt"><div class="bz fp l di"><div class="pp pq l"/></div><figcaption class="la lb gj gh gi lc ld bd b be z dk translated">阅读神经营养学家的数据——来自作者</figcaption></figure><p id="60da" class="pw-post-body-paragraph mu mv iq lz b ma nh ka mw mc ni kd mx me nj mz na mg nk nc nd mi nl nf ng mk ij bi translated">用默认超参数初始化NeuralProphet模型。<a class="ae le" href="https://pandas.pydata.org/pandas-docs/stable/user_guide/timeseries.html#offset-aliases" rel="noopener ugc nofollow" target="_blank"> <strong class="lz ja"> D </strong>频率</a>作为基于每日调整收盘价的数据。</p><p id="22d0" class="pw-post-body-paragraph mu mv iq lz b ma nh ka mw mc ni kd mx me nj mz na mg nk nc nd mi nl nf ng mk ij bi translated">用1000个纪元(你可以选择你的纪元)训练模型，这将需要几分钟的等待时间，NeuralProphet在训练上很快就能做出预测。</p><figure class="kp kq kr ks gt kt"><div class="bz fp l di"><div class="pp pq l"/></div><figcaption class="la lb gj gh gi lc ld bd b be z dk translated">创建神经营养模型—来自作者</figcaption></figure><p id="fc4a" class="pw-post-body-paragraph mu mv iq lz b ma nh ka mw mc ni kd mx me nj mz na mg nk nc nd mi nl nf ng mk ij bi translated">用更多组件绘制预测，但结果显示的是<strong class="lz ja">模型。【剧情(预测)】T17。</strong></p><figure class="kp kq kr ks gt kt"><div class="bz fp l di"><div class="pp pq l"/></div><figcaption class="la lb gj gh gi lc ld bd b be z dk translated">神经原植物的情节代码——来自作者</figcaption></figure><ul class=""><li id="82c5" class="lx ly iq lz b ma nh mc ni me pk mg pl mi pm mk ml mm mn mo bi translated">可视化gNeuralProphet结果</li></ul><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div role="button" tabindex="0" class="ku kv di kw bf kx"><div class="gh gi pu"><img src="../Images/51bbb391248591bc4f2accdfaffafcdc.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*OUOy1PP1-pWTx8YPXstjHA.png"/></div></div><figcaption class="la lb gj gh gi lc ld bd b be z dk translated">预测苹果股票价格“Adj Close”的神经网络预测结果——来自作者</figcaption></figure><p id="9c06" class="pw-post-body-paragraph mu mv iq lz b ma nh ka mw mc ni kd mx me nj mz na mg nk nc nd mi nl nf ng mk ij bi translated">在这段代码中，通过NeuralProphet手动将数据集分为训练和测试，以使用30%的训练数据作为验证数据。</p><figure class="kp kq kr ks gt kt"><div class="bz fp l di"><div class="pp pq l"/></div><figcaption class="la lb gj gh gi lc ld bd b be z dk translated">有分裂的神经原植物——来自作者</figcaption></figure><ul class=""><li id="ac5c" class="lx ly iq lz b ma nh mc ni me pk mg pl mi pm mk ml mm mn mo bi translated">可视化神经营养结果</li></ul><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div role="button" tabindex="0" class="ku kv di kw bf kx"><div class="gh gi pv"><img src="../Images/7001a094e7355773c7db2252dc41fdcb.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*OwR3t99jkrAleFeGm74xxg.png"/></div></div><figcaption class="la lb gj gh gi lc ld bd b be z dk translated">在“Adj Close”分裂时预测苹果股票价格的神经营养图结果—来自作者</figcaption></figure><h1 id="4146" class="lf lg iq bd lh li lj lk ll lm ln lo lp kf lq kg lr ki ls kj lt kl lu km lv lw bi translated"><strong class="ak">型号T </strong>下雨&amp;验证失败</h1><p id="55c1" class="pw-post-body-paragraph mu mv iq lz b ma mb ka mw mc md kd mx me my mz na mg nb nc nd mi ne nf ng mk ij bi translated"><a class="ae le" href="https://machinelearningmastery.com/learning-curves-for-diagnosing-machine-learning-model-performance/" rel="noopener ugc nofollow" target="_blank">学习曲线</a>只是一个图表，显示了在培训期间学习的特定指标的体验进度。要评估模型在预测中的性能，请查看每个模型中的时段数及其损失。</p><p id="2e2b" class="pw-post-body-paragraph mu mv iq lz b ma nh ka mw mc ni kd mx me nj mz na mg nk nc nd mi nl nf ng mk ij bi translated"><strong class="lz ja">注:</strong> O <a class="ae le" href="https://machinelearningmastery.com/overfitting-and-underfitting-with-machine-learning-algorithms/" rel="noopener ugc nofollow" target="_blank">过拟合和欠拟合</a>是常见的，但过量必须用退出等策略来控制，以保证<a class="ae le" href="https://machinelearningmastery.com/introduction-to-regularization-to-reduce-overfitting-and-improve-generalization-error/" rel="noopener ugc nofollow" target="_blank">泛化</a>。因此，目标是尽可能地最小化验证损失，直到它与列车损失达到良好的拟合。本文中所有实现的模型都使用了<a class="ae le" href="https://medium.com/p/c8d6a11a9665/#bc3e" rel="noopener">提前停止来避免过度拟合</a>。</p><ul class=""><li id="6c60" class="lx ly iq lz b ma nh mc ni me pk mg pl mi pm mk ml mm mn mo bi translated"><strong class="lz ja">堆叠LSTM列车&amp;验证损失:</strong></li></ul><pre class="kp kq kr ks gt nw nx ny nz aw oa bi"><span id="8d8a" class="ob lg iq nx b gy oc od l oe of"><strong class="nx ja">RMSE </strong>(Root Mean Square Error) performance metrics:</span><span id="54c3" class="ob lg iq nx b gy og od l oe of"><strong class="nx ja">Train Data</strong>: 20.75, <strong class="nx ja">Test Data</strong>: 80.098</span></pre><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div role="button" tabindex="0" class="ku kv di kw bf kx"><div class="gh gi pw"><img src="../Images/b454e5edba6189c7b0ea33aad9529bee.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*q61A1M2TNNcKGKUHNaAycw.png"/></div></div><figcaption class="la lb gj gh gi lc ld bd b be z dk translated">堆叠的LSTM多层-来自作者</figcaption></figure><p id="b3aa" class="pw-post-body-paragraph mu mv iq lz b ma nh ka mw mc ni kd mx me nj mz na mg nk nc nd mi nl nf ng mk ij bi translated">在<strong class="lz ja">确认损失</strong>结束时的波动点可以是学习可以停止的点。因为这之后的经验可能会显示过度拟合的复杂性。</p><ul class=""><li id="3cb7" class="lx ly iq lz b ma nh mc ni me pk mg pl mi pm mk ml mm mn mo bi translated"><strong class="lz ja"> BiLSTM列车&amp;验证损失:</strong></li></ul><pre class="kp kq kr ks gt nw nx ny nz aw oa bi"><span id="2047" class="ob lg iq nx b gy oc od l oe of"><strong class="nx ja">RMSE</strong> performance metrics: <strong class="nx ja">Train Data</strong>: 20.288, <strong class="nx ja">Test Data</strong>: 87.739</span></pre><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div role="button" tabindex="0" class="ku kv di kw bf kx"><div class="gh gi px"><img src="../Images/90c4a62f479cbfb9230c4a023930823a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*65ZBZiKRzQLwzTResyrzzg.png"/></div></div><figcaption class="la lb gj gh gi lc ld bd b be z dk translated">双向LSTM (BiLSTM)一层—来自作者</figcaption></figure><p id="5f0c" class="pw-post-body-paragraph mu mv iq lz b ma nh ka mw mc ni kd mx me nj mz na mg nk nc nd mi nl nf ng mk ij bi translated">该图显示了<strong class="lz ja">验证损失</strong>如何增长，然后在三个时期内从大到小突然下降到低于0.05的水平。ReLU激活功能用于处理<a class="ae le" href="https://analyticsindiamag.com/can-relu-cause-exploding-gradients-if-applied-to-solve-vanishing-gradients/" rel="noopener ugc nofollow" target="_blank">消失/爆炸梯度问题</a>，可能会导致BiLSTM训练中的高脉冲。</p><ul class=""><li id="8907" class="lx ly iq lz b ma nh mc ni me pk mg pl mi pm mk ml mm mn mo bi translated"><strong class="lz ja">神经营养因子序列&amp;验证损失:</strong></li></ul><pre class="kp kq kr ks gt nw nx ny nz aw oa bi"><span id="b7ad" class="ob lg iq nx b gy oc od l oe of"><strong class="nx ja">RMSE</strong> performance metrics: <strong class="nx ja">Train Data: </strong>1.16, <strong class="nx ja">Test Data: </strong>31.8</span></pre><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div role="button" tabindex="0" class="ku kv di kw bf kx"><div class="gh gi py"><img src="../Images/7dfef040d1e6c03aa50e87d949e6dadb.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Q6FApDhZwwEcmOrQM-cDvw.png"/></div></div><figcaption class="la lb gj gh gi lc ld bd b be z dk translated">神经原植物——来自作者</figcaption></figure><p id="7e7a" class="pw-post-body-paragraph mu mv iq lz b ma nh ka mw mc ni kd mx me nj mz na mg nk nc nd mi nl nf ng mk ij bi translated">训练和验证损失正在改善，但它们之间存在差距，这意味着它们的行为不同于来自各种分布的数据集。</p><h1 id="4f1c" class="lf lg iq bd lh li lj lk ll lm ln lo lp kf lq kg lr ki ls kj lt kl lu km lv lw bi translated">结论</h1><p id="f5f8" class="pw-post-body-paragraph mu mv iq lz b ma mb ka mw mc md kd mx me my mz na mg nb nc nd mi ne nf ng mk ij bi translated">正如我们所见，我们的模型运行良好。它可以准确地跟踪2010年至2021年大多数意想不到的跳跃/下跌；但是，您可以通过修补超参数并进行更多调整来增强性能。其他几个动作可以帮助微调超参数，例如改变隐藏层的数量、神经元的数量、学习速率、激活函数和优化器设置。但是，这些问题留待下一次讨论。</p><p id="8e01" class="pw-post-body-paragraph mu mv iq lz b ma nh ka mw mc ni kd mx me nj mz na mg nk nc nd mi nl nf ng mk ij bi translated">我希望您已经通过在Tensorflow中实现堆叠LSTM和比尔斯特姆模型，以及探索NeuralProphet建模库，使用深度学习理解了时间序列预测。因此，这里介绍的模型可用于各种其他时间序列预测场景，在这些场景中，您可以将多元数据指定为一个<a class="ae le" href="https://www.tensorflow.org/tutorials/structured_data/time_series#baseline" rel="noopener ugc nofollow" target="_blank"> 3D张量</a>。</p><p id="4e08" class="pw-post-body-paragraph mu mv iq lz b ma nh ka mw mc ni kd mx me nj mz na mg nk nc nd mi nl nf ng mk ij bi translated">如果您有任何意见或问题，请在下面发表。这个项目的整个Jupyter笔记本具有EDA(探索性数据分析)、可视化、培训后转换回原始形式、性能指标、未来预测等等，可在我的GitHub存储库中访问。</p><p id="0b4c" class="pw-post-body-paragraph mu mv iq lz b ma nh ka mw mc ni kd mx me nj mz na mg nk nc nd mi nl nf ng mk ij bi translated"><strong class="lz ja"> <em class="np">这篇文章的所有源代码和更多可以在我的GitHub找到:</em> </strong></p><div class="oh oi gp gr oj ok"><a href="https://github.com/A-safarji/Time-series-deep-learning/" rel="noopener  ugc nofollow" target="_blank"><div class="ol ab fo"><div class="om ab on cl cj oo"><h2 class="bd ja gy z fp op fr fs oq fu fw iz bi translated">GitHub-A-safarji/Time-series-Deep-learning:开发深度学习LSTM、BiLSTM模型和…</h2><div class="or l"><h3 class="bd b gy z fp op fr fs oq fu fw dk translated">使用公司的历史数据预测股票价格使用神经网络进行股票的多步预测…</h3></div><div class="os l"><p class="bd b dl z fp op fr fs oq fu fw dk translated">github.com</p></div></div><div class="ot l"><div class="pz l ov ow ox ot oy ky ok"/></div></div></a></div><blockquote class="nm nn no"><p id="da6a" class="mu mv np lz b ma nh ka mw mc ni kd mx nq nj mz na nr nk nc nd ns nl nf ng mk ij bi translated"><strong class="lz ja"> <em class="iq">免责声明:</em> </strong> <em class="iq">已经尝试使用时间序列分析算法来预测股票价格，但是它们不可用于在真实市场中下注。这只是深度学习模型预测股票的教程和实现。因此，不打算让其他人购买本出版社的股票。</em></p></blockquote><p id="43ff" class="pw-post-body-paragraph mu mv iq lz b ma nh ka mw mc ni kd mx me nj mz na mg nk nc nd mi nl nf ng mk ij bi translated">😃感谢您的宝贵时间。 <strong class="lz ja"> <em class="np">快乐学习！</em> </strong></p></div><div class="ab cl qa qb hu qc" role="separator"><span class="qd bw bk qe qf qg"/><span class="qd bw bk qe qf qg"/><span class="qd bw bk qe qf"/></div><div class="ij ik il im in"><h1 id="5856" class="lf lg iq bd lh li qh lk ll lm qi lo lp kf qj kg lr ki qk kj lt kl ql km lv lw bi translated">参考</h1><div class="oh oi gp gr oj ok"><a href="https://www.investopedia.com/terms/t/timeseries.asp" rel="noopener  ugc nofollow" target="_blank"><div class="ol ab fo"><div class="om ab on cl cj oo"><h2 class="bd ja gy z fp op fr fs oq fu fw iz bi translated">了解时间序列</h2><div class="or l"><h3 class="bd b gy z fp op fr fs oq fu fw dk translated">时间序列是在一段时间内连续出现的数据点序列。这可以是…</h3></div><div class="os l"><p class="bd b dl z fp op fr fs oq fu fw dk translated">www.investopedia.com</p></div></div><div class="ot l"><div class="qm l ov ow ox ot oy ky ok"/></div></div></a></div><div class="oh oi gp gr oj ok"><a href="https://www.ibm.com/cloud/learn/recurrent-neural-networks" rel="noopener  ugc nofollow" target="_blank"><div class="ol ab fo"><div class="om ab on cl cj oo"><h2 class="bd ja gy z fp op fr fs oq fu fw iz bi translated">什么是递归神经网络？</h2><div class="or l"><h3 class="bd b gy z fp op fr fs oq fu fw dk translated">了解递归神经网络如何使用顺序数据来解决语言翻译中常见的时态问题…</h3></div><div class="os l"><p class="bd b dl z fp op fr fs oq fu fw dk translated">www.ibm.com</p></div></div><div class="ot l"><div class="qn l ov ow ox ot oy ky ok"/></div></div></a></div><p id="b67c" class="pw-post-body-paragraph mu mv iq lz b ma nh ka mw mc ni kd mx me nj mz na mg nk nc nd mi nl nf ng mk ij bi translated">基于深度学习双向LSTM神经网络的短期负荷预测。<em class="np">应用科学</em>。<a class="ae le" href="https://doi.org/10.3390/app11178129" rel="noopener ugc nofollow" target="_blank">https://doi.org/10.3390/app11178129</a></p><div class="oh oi gp gr oj ok"><a href="https://ieeexplore.ieee.org/document/9005997" rel="noopener  ugc nofollow" target="_blank"><div class="ol ab fo"><div class="om ab on cl cj oo"><h2 class="bd ja gy z fp op fr fs oq fu fw iz bi translated">LSTM和比尔斯特姆在时间序列预测中的表现</h2><div class="or l"><h3 class="bd b gy z fp op fr fs oq fu fw dk translated">基于机器和深度学习的算法是解决时间预测问题的新兴方法</h3></div><div class="os l"><p class="bd b dl z fp op fr fs oq fu fw dk translated">ieeexplore.ieee.org</p></div></div><div class="ot l"><div class="qo l ov ow ox ot oy ky ok"/></div></div></a></div><div class="oh oi gp gr oj ok"><a href="https://neuralprophet.com/html/contents.html" rel="noopener  ugc nofollow" target="_blank"><div class="ol ab fo"><div class="om ab on cl cj oo"><h2 class="bd ja gy z fp op fr fs oq fu fw iz bi translated">神经营养文献</h2><div class="or l"><h3 class="bd b gy z fp op fr fs oq fu fw dk translated">基于神经网络，受脸书先知和AR-Net启发，构建于Pytorch之上。可以安装NeuralProphet</h3></div><div class="os l"><p class="bd b dl z fp op fr fs oq fu fw dk translated">neuralprophet.com</p></div></div></div></a></div><div class="oh oi gp gr oj ok"><a href="https://machinelearningmastery.com/how-to-develop-lstm-models-for-time-series-forecasting/" rel="noopener  ugc nofollow" target="_blank"><div class="ol ab fo"><div class="om ab on cl cj oo"><h2 class="bd ja gy z fp op fr fs oq fu fw iz bi translated">如何开发用于时间序列预测的LSTM模型—机器学习掌握</h2><div class="or l"><h3 class="bd b gy z fp op fr fs oq fu fw dk translated">长短期记忆网络，简称LSTMs，可用于时间序列预测。有很多种…</h3></div><div class="os l"><p class="bd b dl z fp op fr fs oq fu fw dk translated">machinelearningmastery.com</p></div></div><div class="ot l"><div class="qp l ov ow ox ot oy ky ok"/></div></div></a></div><div class="oh oi gp gr oj ok"><a href="https://programming-review.com/machine-learning/overfitting" rel="noopener  ugc nofollow" target="_blank"><div class="ol ab fo"><div class="om ab on cl cj oo"><h2 class="bd ja gy z fp op fr fs oq fu fw iz bi translated">如何防止过拟合|正则化-编程复习</h2><div class="or l"><h3 class="bd b gy z fp op fr fs oq fu fw dk translated">机器学习工程师害怕过度拟合。首先，他们发现过度拟合，然后他们试图避免它。这里…</h3></div><div class="os l"><p class="bd b dl z fp op fr fs oq fu fw dk translated">programming-review.com</p></div></div><div class="ot l"><div class="qq l ov ow ox ot oy ky ok"/></div></div></a></div></div></div>    
</body>
</html>