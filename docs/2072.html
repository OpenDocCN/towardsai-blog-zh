<html>
<head>
<title>Automatic Malaria Detection Using Neural Network</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">基于神经网络的疟疾自动检测</h1>
<blockquote>原文：<a href="https://pub.towardsai.net/automatic-malaria-detection-using-neural-network-55d5d58341c2?source=collection_archive---------0-----------------------#2021-08-08">https://pub.towardsai.net/automatic-malaria-detection-using-neural-network-55d5d58341c2?source=collection_archive---------0-----------------------#2021-08-08</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><h2 id="7055" class="ir is it bd b dl iu iv iw ix iy iz dk ja translated" aria-label="kicker paragraph"><a class="ae ep" href="https://towardsai.net/p/category/machine-learning/deep-learning" rel="noopener ugc nofollow" target="_blank">深度学习</a></h2><div class=""/><div class=""><h2 id="ede2" class="pw-subtitle-paragraph jz jc it bd b ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq dk translated">具有图像处理技术的深度学习项目</h2></div><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div class="gh gi kr"><img src="../Images/cf64f7ceeff75346b6261473a14127f6.png" data-original-src="https://miro.medium.com/v2/resize:fit:1316/format:webp/1*5dGroSHEJjHskGoCzG3sUQ.png"/></div><figcaption class="kz la gj gh gi lb lc bd b be z dk translated">作者的照片</figcaption></figure><blockquote class="ld le lf"><p id="f9b4" class="lg lh li lj b lk ll kd lm ln lo kg lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated"><strong class="lj jd">T3】简介T5】</strong></p></blockquote><p id="873f" class="pw-post-body-paragraph lg lh it lj b lk ll kd lm ln lo kg lp md lr ls lt me lv lw lx mf lz ma mb mc im bi translated">在这项工作中，建立了一个自动系统，它包括三个部分，即预处理，分割和分类。</p><p id="b468" class="pw-post-body-paragraph lg lh it lj b lk ll kd lm ln lo kg lp md lr ls lt me lv lw lx mf lz ma mb mc im bi translated">预处理部分包括改变色彩空间、降噪、去除不想要的对象:这使用了灰度转换、形态学操作和过滤。</p><p id="2faa" class="pw-post-body-paragraph lg lh it lj b lk ll kd lm ln lo kg lp md lr ls lt me lv lw lx mf lz ma mb mc im bi translated">分割部分包括分离红细胞并将其保存到其他位置:这部分包括应用各种技术，如Otsu阈值处理和距离变换。</p><p id="5c9b" class="pw-post-body-paragraph lg lh it lj b lk ll kd lm ln lo kg lp md lr ls lt me lv lw lx mf lz ma mb mc im bi translated">最后，在分类部分，识别细胞是健康的还是寄生的。预训练的卷积神经网络模型VGG16用于分类任务。</p><p id="1131" class="pw-post-body-paragraph lg lh it lj b lk ll kd lm ln lo kg lp md lr ls lt me lv lw lx mf lz ma mb mc im bi translated">“Mal' aria”是一个意大利词，意思是“糟糕的空气”，疟疾一词由此而来。它是由受感染的雌性按蚊叮咬引起的，其中含有疟原虫属的原生动物寄生虫。</p><p id="32ce" class="pw-post-body-paragraph lg lh it lj b lk ll kd lm ln lo kg lp md lr ls lt me lv lw lx mf lz ma mb mc im bi translated">主要有四种类型的疟原虫感染人体:恶性疟原虫、间日疟原虫、卵形疟原虫和三日疟原虫。</p><p id="2dbf" class="pw-post-body-paragraph lg lh it lj b lk ll kd lm ln lo kg lp md lr ls lt me lv lw lx mf lz ma mb mc im bi translated">感染疟疾的病人的体征和症状是发热、发冷、出汗、头痛、恶心和呕吐、全身疼痛和全身不适。</p><blockquote class="ld le lf"><p id="4d5c" class="lg lh li lj b lk ll kd lm ln lo kg lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated"><strong class="lj jd"> <em class="it">疟疾的各种诊断方法</em> </strong></p></blockquote><ul class=""><li id="4376" class="mg mh it lj b lk ll ln lo md mi me mj mf mk mc ml mm mn mo bi translated"><strong class="lj jd">厚血涂片和薄血涂片:</strong>诊断需要在载玻片上制备两份血涂片，一份厚涂片和一份薄涂片。它包括使用染色来增强显微镜下细胞或特定细胞成分的可视性。</li><li id="e7a5" class="mg mh it lj b lk mp ln mq md mr me ms mf mt mc ml mm mn mo bi translated"><strong class="lj jd">快速诊断测试(抗原测试):</strong>在显微镜检查不可用的情况下，RDT用于诊断疟疾，而不是血涂片。它也被称为“量油尺”测试。从人体的手指棒上取一滴血，通过改变测试条的颜色来指示阳性测试结果。疟疾抗原在这项测试中被检测出来。</li><li id="b7b3" class="mg mh it lj b lk mp ln mq md mr me ms mf mt mc ml mm mn mo bi translated"><strong class="lj jd">分子测试(聚合酶链式反应，PCR):</strong>PCR是一种实验室测试方法，可扩增寄生虫的DNA，并检测和鉴定引起感染的疟原虫种类。</li><li id="f0c7" class="mg mh it lj b lk mp ln mq md mr me ms mf mt mc ml mm mn mo bi translated"><strong class="lj jd">抗体检测(血清学):</strong>检测患者血液中存在的抗体，抗体由身体对疟疾感染的反应产生。这种测试不能诊断严重感染，但有助于确定一个人以前是否感染过疟疾。</li></ul><blockquote class="ld le lf"><p id="a9d2" class="lg lh li lj b lk ll kd lm ln lo kg lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated"><strong class="lj jd"> <em class="it"> CAD用于疟疾诊断</em> </strong></p></blockquote><p id="21c6" class="pw-post-body-paragraph lg lh it lj b lk ll kd lm ln lo kg lp md lr ls lt me lv lw lx mf lz ma mb mc im bi translated">计算机辅助诊断系统是一类使用计算机视觉技术的计算机系统，旨在帮助诊断血液涂片图像中的疟原虫。</p><h2 id="da60" class="mu mv it bd mw mx my dn mz na nb dp nc md nd ne nf me ng nh ni mf nj nk nl iz bi translated"><strong class="ak">用于疟疾诊断的CADx阶段</strong></h2><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div class="gh gi nm"><img src="../Images/a27e5bfbded1a75ea0c39cfb09dcf9c0.png" data-original-src="https://miro.medium.com/v2/resize:fit:1032/format:webp/1*HvhM_RiYIvZnIV7msrODMQ.png"/></div><figcaption class="kz la gj gh gi lb lc bd b be z dk translated">作者的照片</figcaption></figure><p id="fd04" class="pw-post-body-paragraph lg lh it lj b lk ll kd lm ln lo kg lp md lr ls lt me lv lw lx mf lz ma mb mc im bi translated">图像预处理及其技术包括颜色转换、调整大小和裁剪、数据扩充、归一化、去噪、去除和过滤。</p><h2 id="0005" class="mu mv it bd mw mx my dn mz na nb dp nc md nd ne nf me ng nh ni mf nj nk nl iz bi translated">分割</h2><p id="e8c3" class="pw-post-body-paragraph lg lh it lj b lk nn kd lm ln no kg lp md np ls lt me nq lw lx mf nr ma mb mc im bi translated">图像分割是计算机视觉中的一个审查过程，因为它涉及将视觉输入分割成片段(表示对象或对象的一部分，并理解像素集或“超像素”)以解开图像分析。</p><ul class=""><li id="f503" class="mg mh it lj b lk ll ln lo md mi me mj mf mk mc ml mm mn mo bi translated">语义分割:它包括检测图像中的对象，并根据定义的类别排列检测到的对象。</li><li id="e8ec" class="mg mh it lj b lk mp ln mq md mr me ms mf mt mc ml mm mn mo bi translated">实例分割:它包括检测定义类别中的对象，这在语义分割之后又进了一步。</li></ul><h2 id="200e" class="mu mv it bd mw mx my dn mz na nb dp nc md nd ne nf me ng nh ni mf nj nk nl iz bi translated">分类</h2><p id="2e49" class="pw-post-body-paragraph lg lh it lj b lk nn kd lm ln no kg lp md np ls lt me nq lw lx mf nr ma mb mc im bi translated">识别给定数据点类别的过程。这些类许多项目被称为目标/标签或类别。它属于监督学习，其中在数据集中提供类。</p><ul class=""><li id="1f2a" class="mg mh it lj b lk ll ln lo md mi me mj mf mk mc ml mm mn mo bi translated"><strong class="lj jd">:懒惰学习者:</strong>存储训练数据，等待分类时出现测试数据，当出现测试数据时，根据存储的训练数据中的相关数据进行分类。它的训练时间较少，但预测时间较长。</li><li id="2777" class="mg mh it lj b lk mp ln mq md mr me ms mf mt mc ml mm mn mo bi translated"><strong class="lj jd">渴望学习者:</strong>该学习者基于训练数据构建分类模型。由于急切的学习者，模型需要更多的时间。</li></ul><div class="ns nt gp gr nu nv"><a rel="noopener  ugc nofollow" target="_blank" href="/hyper-parameters-randomseachcv-and-gridsearchcv-in-machine-learning-b7d091cf56f4"><div class="nw ab fo"><div class="nx ab ny cl cj nz"><h2 class="bd jd gy z fp oa fr fs ob fu fw jc bi translated">超参数:机器学习中的RandomSeachCV和GridSearchCV</h2><div class="oc l"><h3 class="bd b gy z fp oa fr fs ob fu fw dk translated">提高算法精确度的技术</h3></div><div class="od l"><p class="bd b dl z fp oa fr fs ob fu fw dk translated">pub.towardsai.net</p></div></div><div class="oe l"><div class="of l og oh oi oe oj kx nv"/></div></div></a></div><div class="ns nt gp gr nu nv"><a rel="noopener  ugc nofollow" target="_blank" href="/understand-cnn-basics-with-a-keras-example-in-python-c1fd6c449935"><div class="nw ab fo"><div class="nx ab ny cl cj nz"><h2 class="bd jd gy z fp oa fr fs ob fu fw jc bi translated">通过Python中的Keras示例了解CNN基础知识</h2><div class="oc l"><h3 class="bd b gy z fp oa fr fs ob fu fw dk translated">用于图像过程分析的深度神经网络算法</h3></div><div class="od l"><p class="bd b dl z fp oa fr fs ob fu fw dk translated">pub.towardsai.net</p></div></div><div class="oe l"><div class="ok l og oh oi oe oj kx nv"/></div></div></a></div><blockquote class="ld le lf"><p id="8067" class="lg lh li lj b lk ll kd lm ln lo kg lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated"><strong class="lj jd"> <em class="it">项目的数据集</em> </strong></p></blockquote><ul class=""><li id="f570" class="mg mh it lj b lk ll ln lo md mi me mj mf mk mc ml mm mn mo bi translated">未受影响的图像总数:27558</li><li id="6e6f" class="mg mh it lj b lk mp ln mq md mr me ms mf mt mc ml mm mn mo bi translated">受影响的图像总数:27558</li></ul><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div class="gh gi ol"><img src="../Images/c0665713e0e495a2721fd0fa42ba4d8d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1094/format:webp/1*yFlLNPVmClwnVYGhfyJg7Q.png"/></div><figcaption class="kz la gj gh gi lb lc bd b be z dk translated">作者的照片</figcaption></figure><blockquote class="ld le lf"><p id="3716" class="lg lh li lj b lk ll kd lm ln lo kg lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated"><strong class="lj jd"> <em class="it">项目的Python代码</em> </strong></p></blockquote><h2 id="3406" class="mu mv it bd mw mx my dn mz na nb dp nc md nd ne nf me ng nh ni mf nj nk nl iz bi translated">导入库</h2><pre class="ks kt ku kv gt om on oo op aw oq bi"><span id="ad44" class="mu mv it on b gy or os l ot ou"># load libraries<br/>import cv2<br/>import numpy as np<br/>import os<br/>from keras.utils import np_utils<br/>import matplotlib.pyplot as plt<br/>import itertools<br/>import time<br/>from keras.models import Sequential<br/>from keras.models import Model<br/>from keras import applications<br/>from keras.callbacks import ModelCheckpoint, TensorBoard<br/>from keras.layers import Conv2D, Activation, Dense, MaxPooling2D, Flatten, Dropout, GlobalAveragePooling2D<br/>from sklearn.metrics import log_loss<br/>from sklearn.utils import class_weight<br/>from keras.optimizers import SGD<br/>from sklearn.metrics import roc_curve, auc<br/>from sklearn.metrics import classification_report,confusion_matrix, accuracy_score<br/>import matplotlib.pyplot as plt<br/>from sklearn.metrics import average_precision_score<br/>%matplotlib inline</span></pre><h2 id="a7c5" class="mu mv it bd mw mx my dn mz na nb dp nc md nd ne nf me ng nh ni mf nj nk nl iz bi translated">读取图像并将其定义到训练和测试集</h2><pre class="ks kt ku kv gt om on oo op aw oq bi"><span id="4212" class="mu mv it on b gy or os l ot ou">#define data directories<br/>train_data_dir = r'C:\cell_images\training_images' <br/>valid_data_dir = r'C:\cell_images\validation_images'<br/>test_data_dir = r'C:\cell_images\testing_images'</span><span id="b5fc" class="mu mv it on b gy ov os l ot ou">#loading number of images to train, test, and valid set<br/>nb_train_samples = 22046 <br/>nb_valid_samples = 2756 <br/>nb_test_samples = 2756 </span><span id="1f51" class="mu mv it on b gy ov os l ot ou"># binary classification<br/>num_classes = 2 <br/>img_rows_orig = 100 <br/>img_cols_orig = 100</span></pre><h2 id="3123" class="mu mv it bd mw mx my dn mz na nb dp nc md nd ne nf me ng nh ni mf nj nk nl iz bi translated">制作加载图像的函数</h2><pre class="ks kt ku kv gt om on oo op aw oq bi"><span id="634a" class="mu mv it on b gy or os l ot ou">def load_training_data():<br/>    labels = os.listdir(train_data_dir)<br/>    total = len(labels)<br/>    X_train = np.ndarray((nb_train_samples, img_rows_orig, img_cols_orig, 3), dtype=np.uint8)<br/>    Y_train = np.zeros((nb_train_samples,), dtype='uint8')<br/>    i = 0<br/>    print('-'*30)<br/>    print('Creating training images...')<br/>    print('-'*30)<br/>    j = 0<br/>    for label in labels:<br/>        image_names_train = os.listdir(os.path.join(train_data_dir, label))<br/>        total = len(image_names_train)<br/>        print(label, total)<br/>        for image_name in image_names_train:<br/>            img = cv2.imread(os.path.join(train_data_dir, label, image_name), cv2.IMREAD_COLOR)<br/>            img = cv2.resize(img, (100, 100))<br/>            img = np.array([img])<br/>            X_train[i] = img<br/>            Y_train[i] = j<br/>            if i % 100 == 0:<br/>                print('Done: {0}/{1} images'.format(i, total))<br/>            i += 1<br/>        j += 1    <br/>    print(i)                <br/>    print('Loading done.')<br/>    print('Transform targets to keras compatible format.')<br/>    Y_train = np_utils.to_categorical(Y_train[:nb_train_samples], num_classes)<br/>    np.save('imgs_train.npy', X_train, Y_train) <br/>    return X_train, Y_train<br/>    <br/>def load_validation_data():<br/>    # Load validation images<br/>    labels = os.listdir(valid_data_dir)<br/>    X_valid = np.ndarray((nb_valid_samples, img_rows_orig, img_cols_orig, 3), dtype=np.uint8)<br/>    Y_valid = np.zeros((nb_valid_samples,), dtype='uint8')<br/>    i = 0<br/>    print('-'*30)<br/>    print('Creating validation images...')<br/>    print('-'*30)<br/>    j = 0<br/>    for label in labels:<br/>        image_names_valid = os.listdir(os.path.join(valid_data_dir, label))<br/>        total = len(image_names_valid)<br/>        print(label, total)<br/>        for image_name in image_names_valid:<br/>            '''img = cv2.imread(os.path.join(valid_data_dir, label,<br/>                      image_name), cv2.IMREAD_COLOR)<br/>            img = cv2.resize(img, (100, 100))<br/>            img = np.array([img])'''<br/>            try:<br/>               # path=os.path.join(mypath,n)<br/>                img=cv2.imread(os.path.join(valid_data_dir, label, image_name), cv2.IMREAD_COLOR)<br/>                img=cv2.resize(img, (100,100))<br/>                img = np.array([img])    <br/>                X_valid[i] = img<br/>                Y_valid[i] = j<br/>                if i % 100 == 0:<br/>                    print('Done: {0}/{1} images'.format(i, total))</span><span id="cf0f" class="mu mv it on b gy ov os l ot ou">except Exception as e:<br/>                print(str(e))<br/>             <br/>            i += 1<br/>        j += 1     <br/>            <br/>    print(i)            <br/>    print('Loading done.')<br/>    print('Transform targets to keras compatible format.');<br/>    Y_valid = np_utils.to_categorical(Y_valid[:nb_valid_samples],<br/>                            num_classes)<br/>    return X_valid, Y_valid</span><span id="8754" class="mu mv it on b gy ov os l ot ou">def load_test_data():<br/>    labels = os.listdir(test_data_dir)<br/>    Y_test = np.zeros((nb_test_samples,), dtype='uint8')<br/>    i = 0<br/>    print('-'*30)<br/>    print('Creating test images...')<br/>    print('-'*30)<br/>    j = 0<br/>    for label in labels:<br/>        image_names_test = os.listdir(os.path.join(test_data_dir, label))<br/>        total = len(image_names_test)<br/>        print(label, total)<br/>        for image_name in image_names_test:<br/>            img = cv2.imread(os.path.join(test_data_dir, label, image_name), cv2.IMREAD_COLOR)<br/>            img = cv2.resize(img, (100, 100))<br/>            img = np.array([img])<br/>            X_test[i] = img<br/>            Y_test[i] = j<br/>            if i % 100 == 0:<br/>                print('Done: {0}/{1} images'.format(i, total))<br/>            i += 1<br/>        j += 1<br/>    print(i)            <br/>    print('Loading done.')<br/>    print('Transform targets to keras compatible format.');<br/>    Y_test = np_utils.to_categorical(Y_test[:nb_test_samples], num_classes)<br/>    np.save('imgs_test.npy', X_test, Y_test) <br/>    return X_test, Y_test</span></pre><div class="ns nt gp gr nu nv"><a rel="noopener  ugc nofollow" target="_blank" href="/understand-optimizers-in-deep-learning-694f4f0eb048"><div class="nw ab fo"><div class="nx ab ny cl cj nz"><h2 class="bd jd gy z fp oa fr fs ob fu fw jc bi translated">理解深度学习中的优化器</h2><div class="oc l"><h3 class="bd b gy z fp oa fr fs ob fu fw dk translated">优化器是机器学习的典范</h3></div><div class="od l"><p class="bd b dl z fp oa fr fs ob fu fw dk translated">pub.towardsai.net</p></div></div><div class="oe l"><div class="ow l og oh oi oe oj kx nv"/></div></div></a></div><h2 id="6984" class="mu mv it bd mw mx my dn mz na nb dp nc md nd ne nf me ng nh ni mf nj nk nl iz bi translated">调整图像大小</h2><pre class="ks kt ku kv gt om on oo op aw oq bi"><span id="069a" class="mu mv it on b gy or os l ot ou">def load_resized_training_data(img_rows, img_cols):</span><span id="0ea9" class="mu mv it on b gy ov os l ot ou">X_train, Y_train = load_training_data()<br/>    X_train = np.array([cv2.resize(img, (img_rows,img_cols)) for img in X_train[:nb_train_samples,:,:,:]])<br/>    <br/>    return X_train, Y_train<br/>    <br/>def load_resized_validation_data(img_rows, img_cols):</span><span id="fa45" class="mu mv it on b gy ov os l ot ou">X_valid, Y_valid = load_validation_data()<br/>    X_valid = np.array([cv2.resize(img, (img_rows,img_cols)) for img in X_valid[:nb_valid_samples,:,:,:]])<br/>        <br/>    return X_valid, Y_valid</span><span id="eecc" class="mu mv it on b gy ov os l ot ou">def load_resized_test_data(img_rows, img_cols):</span><span id="2c4a" class="mu mv it on b gy ov os l ot ou">X_test, Y_test = load_test_data()<br/>    X_test = np.array([cv2.resize(img, (img_rows,img_cols)) for img in X_test[:nb_test_samples,:,:,:]])<br/>    <br/>    return X_test, Y_test</span></pre><h2 id="7c0a" class="mu mv it bd mw mx my dn mz na nb dp nc md nd ne nf me ng nh ni mf nj nk nl iz bi translated">绘制混淆矩阵的函数</h2><pre class="ks kt ku kv gt om on oo op aw oq bi"><span id="1f0b" class="mu mv it on b gy or os l ot ou">def plot_confusion_matrix(cm, classes,<br/>                          normalize=False, <br/>                          title='Confusion matrix',<br/>                          cmap=plt.cm.Blues):<br/>    plt.imshow(cm, interpolation='nearest', cmap=cmap)<br/>    plt.title(title)<br/>    plt.colorbar()<br/>    tick_marks = np.arange(len(classes))<br/>    plt.xticks(tick_marks, classes, rotation=45)<br/>    plt.yticks(tick_marks, classes)</span><span id="eb16" class="mu mv it on b gy ov os l ot ou">if normalize:<br/>        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]<br/>        print("Normalized confusion matrix")<br/>    else:<br/>        print('Confusion matrix, without normalization')</span><span id="1368" class="mu mv it on b gy ov os l ot ou">print(cm)<br/>    thresh = cm.max() / 2.<br/>    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):<br/>        plt.text(j, i, cm[i, j],<br/>                 horizontalalignment="center",<br/>                 <br/>    plt.tight_layout()<br/>    plt.ylabel('True label')<br/>    plt.xlabel('Predicted label')</span></pre><h2 id="c02f" class="mu mv it bd mw mx my dn mz na nb dp nc md nd ne nf me ng nh ni mf nj nk nl iz bi translated">将数据分为训练、测试和有效</h2><pre class="ks kt ku kv gt om on oo op aw oq bi"><span id="3c49" class="mu mv it on b gy or os l ot ou">img_rows=100 <br/>img_cols=100<br/>channel = 3 #RGB<br/>num_classes = 2 <br/>batch_size = 32 <br/>num_epoch = 30 </span><span id="efdc" class="mu mv it on b gy ov os l ot ou">#load data<br/>X_train, Y_train = load_resized_training_data(img_rows, img_cols)<br/>X_valid, Y_valid = load_resized_validation_data(img_rows, img_cols)<br/>X_test, Y_test = load_resized_test_data(img_rows, img_cols)</span></pre><h2 id="3784" class="mu mv it bd mw mx my dn mz na nb dp nc md nd ne nf me ng nh ni mf nj nk nl iz bi translated">使用预训练的VGG16模型</h2><pre class="ks kt ku kv gt om on oo op aw oq bi"><span id="5066" class="mu mv it on b gy or os l ot ou">base_model = applications.VGG16(weights='imagenet', include_top=False, input_shape=(img_rows, img_cols, channel))</span><span id="2b50" class="mu mv it on b gy ov os l ot ou">#extract feature from the optimal layer for your data<br/>base_model = Model(input=base_model.input, output=base_model.get_layer('block5_conv2').output)</span><span id="5f38" class="mu mv it on b gy ov os l ot ou">#get the model summary<br/>base_model.summary()</span></pre><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div class="gh gi ox"><img src="../Images/c3d1e0a87262b0556b8c6350779c989f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1034/format:webp/1*4dHhcLnaBOubdqgzuVkvzA.png"/></div><figcaption class="kz la gj gh gi lb lc bd b be z dk translated">作者的照片</figcaption></figure><pre class="ks kt ku kv gt om on oo op aw oq bi"><span id="fa93" class="mu mv it on b gy or os l ot ou">x = base_model.output<br/>x = GlobalAveragePooling2D()(x)<br/>x = Dense(1024, activation='relu')(x)<br/>x = Dropout(0.5)(x)<br/>predictions = Dense(num_classes, activation='softmax', name='predictions')(x)</span><span id="f93b" class="mu mv it on b gy ov os l ot ou">#we will train this model<br/>model = Model(inputs=base_model.input, outputs=predictions)</span><span id="0870" class="mu mv it on b gy ov os l ot ou">#freezing layers for large gradient and training top layer<br/>for layer in base_model.layers:<br/>    layer.trainable = False</span><span id="c542" class="mu mv it on b gy ov os l ot ou">#fix the optimizer<br/>sgd = SGD(lr=0.00001, decay=1e-6, momentum=0.9, nesterov=True)</span><span id="fff3" class="mu mv it on b gy ov os l ot ou">#compile the model<br/>model.compile(optimizer=sgd,<br/>              loss='categorical_crossentropy',<br/>              metrics=['accuracy'])</span></pre><h2 id="d51a" class="mu mv it bd mw mx my dn mz na nb dp nc md nd ne nf me ng nh ni mf nj nk nl iz bi translated">训练模型</h2><pre class="ks kt ku kv gt om on oo op aw oq bi"><span id="c506" class="mu mv it on b gy or os l ot ou">filepath = 'C:\\weights\\weight' + model.name + '.{epoch:02d}-{val_acc:.4f}.hdf5'<br/>checkpoint = ModelCheckpoint(filepath, monitor='val_acc', verbose=1, <br/>                             save_weights_only=True, save_best_only=True, mode='max', period=1)<br/>tensor_board = TensorBoard(log_dir='logs/', histogram_freq=0, batch_size=batch_size)<br/>callbacks_list = [checkpoint, tensor_board]</span><span id="d5ce" class="mu mv it on b gy ov os l ot ou">#compute training time<br/>t=time.time()<br/>hist = model.fit(X_train, Y_train, batch_size=batch_size, <br/>                 callbacks=callbacks_list,<br/>                 epochs=num_epoch, verbose=1, <br/>                 shuffle=True, validation_data=[X_valid, Y_valid])</span><span id="5b28" class="mu mv it on b gy ov os l ot ou">#compute the training time<br/>print('Training time: %s' % (time.time()-t))</span></pre><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="oz pa di pb bf pc"><div class="gh gi oy"><img src="../Images/664f63b1facad6494e1cd4f2c50204e5.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*QThhaDb0FmBIAh2unAssjA.png"/></div></div><figcaption class="kz la gj gh gi lb lc bd b be z dk translated">作者的照片</figcaption></figure><h2 id="be00" class="mu mv it bd mw mx my dn mz na nb dp nc md nd ne nf me ng nh ni mf nj nk nl iz bi translated">训练损失和验证损失</h2><pre class="ks kt ku kv gt om on oo op aw oq bi"><span id="c704" class="mu mv it on b gy or os l ot ou">train_loss=hist.history['loss']<br/>val_loss=hist.history['val_loss']<br/>train_acc=hist.history['acc']<br/>val_acc=hist.history['val_acc']<br/>xc=range(num_epoch)</span><span id="be96" class="mu mv it on b gy ov os l ot ou">plt.figure(1,figsize=(20,10), dpi=100)<br/>plt.plot(xc,train_loss)<br/>plt.plot(xc,val_loss)<br/>plt.xlabel('num of Epochs')<br/>plt.ylabel('loss')<br/>plt.title('train_loss vs val_loss')<br/>plt.grid(True)<br/>plt.legend(['train','val'])<br/>plt.style.use(['classic'])</span><span id="be3f" class="mu mv it on b gy ov os l ot ou">plt.figure(2,figsize=(20,10), dpi=100)<br/>plt.plot(xc,train_acc)<br/>plt.plot(xc,val_acc)<br/>plt.xlabel('num of Epochs')<br/>plt.ylabel('accuracy')<br/>plt.title('train_acc vs val_acc')<br/>plt.grid(True)<br/>plt.legend(['train','val'])<br/>plt.style.use(['classic'])</span></pre><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="oz pa di pb bf pc"><div class="gh gi pd"><img src="../Images/39e9ed540dbd0632cb4cadec1b390823.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*T1xO2mnWL6HjmBqh5z44Sg.png"/></div></div><figcaption class="kz la gj gh gi lb lc bd b be z dk translated">作者的照片</figcaption></figure><h2 id="0be4" class="mu mv it bd mw mx my dn mz na nb dp nc md nd ne nf me ng nh ni mf nj nk nl iz bi translated">训练准确性和验证准确性</h2><p id="3836" class="pw-post-body-paragraph lg lh it lj b lk nn kd lm ln no kg lp md np ls lt me nq lw lx mf nr ma mb mc im bi translated">模型经过30个历元后的训练准确率为96.335%，模型训练所用时间为9746.627秒。该模型在作为原始数据集一部分的测试数据集上的测试精度是0.95065，并且测试在34秒内完成。</p><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="oz pa di pb bf pc"><div class="gh gi pe"><img src="../Images/a65eeade38cf70dba4479c0fb9af00eb.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*a_KpLsXrTlJSf_yEftNzdQ.png"/></div></div><figcaption class="kz la gj gh gi lb lc bd b be z dk translated">作者的照片</figcaption></figure><h2 id="fe44" class="mu mv it bd mw mx my dn mz na nb dp nc md nd ne nf me ng nh ni mf nj nk nl iz bi translated">根据测试数据进行预测</h2><pre class="ks kt ku kv gt om on oo op aw oq bi"><span id="df5f" class="mu mv it on b gy or os l ot ou"><br/>X_test, Y_test = load_resized_test_data(img_rows, img_cols)<br/>print(X_test.shape, Y_test.shape)<br/>print(‘-’*30)<br/>print(‘Predicting on the test data…’)<br/>print(‘-’*30)<br/>y_pred = model.predict(X_test, batch_size=batch_size, verbose=1)</span><span id="eb7c" class="mu mv it on b gy ov os l ot ou"># compute the accuracy<br/>Test_accuracy = accuracy_score(Y_test.argmax(axis=-1),y_pred.argmax(axis=-1))<br/>print(“Test_Accuracy = “,Test_accuracy)</span></pre><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div class="gh gi pf"><img src="../Images/cfaee2eb4b8eab5a504b2de45560f31a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1250/format:webp/1*FNwYliDc3x7T_yXwfL52Qw.png"/></div><figcaption class="kz la gj gh gi lb lc bd b be z dk translated">作者的照片</figcaption></figure><h2 id="ab8a" class="mu mv it bd mw mx my dn mz na nb dp nc md nd ne nf me ng nh ni mf nj nk nl iz bi translated">受试者工作特征曲线</h2><pre class="ks kt ku kv gt om on oo op aw oq bi"><span id="e7ee" class="mu mv it on b gy or os l ot ou">#compute the ROC-AUC values<br/>fpr = dict()<br/>tpr = dict()<br/>roc_auc = dict()<br/>for i in range(num_classes):<br/>    fpr[i], tpr[i], _ = roc_curve(Y_test[:, i], y_pred[:, i])<br/>    roc_auc[i] = auc(fpr[i], tpr[i])<br/>    <br/># ROC curve and ROC area<br/>fpr["micro"], tpr["micro"], _ = roc_curve(Y_test.ravel(), y_pred.ravel())<br/>roc_auc["micro"] = auc(fpr["micro"], tpr["micro"])</span><span id="ef5e" class="mu mv it on b gy ov os l ot ou">#Plot ROC curves<br/>plt.figure(figsize=(20,10), dpi=100)<br/>lw = 1<br/>plt.plot(fpr[1], tpr[1], color='red',<br/>         lw=lw, label='ROC curve (area = %0.4f)' % roc_auc[1])<br/>plt.plot([0, 1], [0, 1], color='black', lw=lw, linestyle='--')<br/>plt.xlim([0.0, 1.0])<br/>plt.ylim([0.0, 1.05])<br/>plt.xlabel('False Positive Rate')<br/>plt.ylabel('True Positive Rate')<br/>plt.title('Receiver operating characteristics')<br/>plt.legend(loc="lower right")<br/>plt.show()</span><span id="34fe" class="mu mv it on b gy ov os l ot ou"># computhe the cross-entropy loss score<br/>score = log_loss(Y_test,y_pred)<br/>print(score)</span><span id="ee74" class="mu mv it on b gy ov os l ot ou"># compute the average precision score<br/>prec_score = average_precision_score(Y_test,y_pred)  <br/>print(prec_score)</span><span id="9ff4" class="mu mv it on b gy ov os l ot ou"># transfer it back<br/>y_pred = np.argmax(y_pred, axis=1)<br/>Y_test = np.argmax(Y_test, axis=1)<br/>print(y_pred)<br/>print(Y_test)</span><span id="0bae" class="mu mv it on b gy ov os l ot ou">#save the predictions as a CSV file for further analysis<br/>np.savetxt('vgg16_model_y_pred.csv',y_pred,fmt='%i',delimiter = ",")<br/>np.savetxt('vgg16_model_Y_test.csv',Y_test,fmt='%i',delimiter = ",")</span></pre><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="oz pa di pb bf pc"><div class="gh gi pg"><img src="../Images/fec391946cdc477e818b16ce7fb1b062.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*zYzU0xAqDSow23DWeYUaSQ.png"/></div></div><figcaption class="kz la gj gh gi lb lc bd b be z dk translated">作者的照片</figcaption></figure><h2 id="f985" class="mu mv it bd mw mx my dn mz na nb dp nc md nd ne nf me ng nh ni mf nj nk nl iz bi translated">分类报告和混淆矩阵</h2><pre class="ks kt ku kv gt om on oo op aw oq bi"><span id="f8a6" class="mu mv it on b gy or os l ot ou">target_names = ['class 0(abnormal)', 'class 1(normal)'] #decide the labels for your own data<br/>print(classification_report(Y_test,y_pred,target_names=target_names))<br/>print(confusion_matrix(Y_test,y_pred))<br/>cnf_matrix = (confusion_matrix(Y_test,y_pred))<br/>np.set_printoptions(precision=4)</span><span id="3c03" class="mu mv it on b gy ov os l ot ou"># Plot non-normalized confusion matrix<br/>plt.figure(figsize=(20,10), dpi=100)<br/>plot_confusion_matrix(cnf_matrix, classes=target_names,<br/>                  title='Confusion matrix')<br/>plt.show()</span></pre><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div class="gh gi ph"><img src="../Images/a696040a593ccd05a06dbd1bdd996c61.png" data-original-src="https://miro.medium.com/v2/resize:fit:1070/format:webp/1*tyZ9yAvOcx-xcTIjAcul4g.png"/></div><figcaption class="kz la gj gh gi lb lc bd b be z dk translated">作者的照片</figcaption></figure><h2 id="1215" class="mu mv it bd mw mx my dn mz na nb dp nc md nd ne nf me ng nh ni mf nj nk nl iz bi translated">结论</h2><p id="60c3" class="pw-post-body-paragraph lg lh it lj b lk nn kd lm ln no kg lp md np ls lt me nq lw lx mf nr ma mb mc im bi translated">这里使用图像处理技术进行预处理和分割。VGG-16模型在30个时期后的训练精度是96.335%，训练所用的时间是9746.627秒，而在作为原始数据集一部分的测试数据集上的测试精度是0.95065，测试在34秒内完成。</p><p id="4068" class="pw-post-body-paragraph lg lh it lj b lk ll kd lm ln lo kg lp md lr ls lt me lv lw lx mf lz ma mb mc im bi translated">我希望你喜欢这篇文章。通过我的<a class="ae pi" href="https://www.linkedin.com/in/data-scientist-95040a1ab/" rel="noopener ugc nofollow" target="_blank"> LinkedIn </a>和<a class="ae pi" href="https://twitter.com/amitprius" rel="noopener ugc nofollow" target="_blank"> twitter </a>联系我。</p><h1 id="7b1b" class="pj mv it bd mw pk pl pm mz pn po pp nc ki pq kj nf kl pr km ni ko ps kp nl pt bi translated">推荐文章</h1><p id="53c8" class="pw-post-body-paragraph lg lh it lj b lk nn kd lm ln no kg lp md np ls lt me nq lw lx mf nr ma mb mc im bi translated"><a class="ae pi" href="https://medium.com/towards-artificial-intelligence/nlp-zero-to-hero-with-python-2df6fcebff6e?sk=2231d868766e96b13d1e9d7db6064df1" rel="noopener"> 1。NLP —零到英雄与Python </a> <br/> 2。<a class="ae pi" rel="noopener ugc nofollow" target="_blank" href="/numpy-linear-algebra-on-images-ed3180978cdb?source=friends_link&amp;sk=d9afa4a1206971f9b1f64862f6291ac0"> NumPy:图像上的线性代数</a>T5】3。<a class="ae pi" rel="noopener ugc nofollow" target="_blank" href="/exception-handling-concepts-in-python-4d5116decac3?source=friends_link&amp;sk=a0ed49d9fdeaa67925eac34ecb55ea30">Python中的异常处理概念</a> <br/> 4。<a class="ae pi" rel="noopener ugc nofollow" target="_blank" href="/principal-component-analysis-in-dimensionality-reduction-with-python-1a613006d531?source=friends_link&amp;sk=3ed0671fdc04ba395dd36478bcea8a55">用Python进行主成分分析降维</a> <br/> 5。<a class="ae pi" href="https://medium.com/towards-artificial-intelligence/fully-explained-k-means-clustering-with-python-e7caa573176a?source=friends_link&amp;sk=9c5c613ceb10f2d203712634f3b6fb28" rel="noopener">用Python全面讲解K-means聚类</a> <br/> 6。<a class="ae pi" href="https://medium.com/towards-artificial-intelligence/fully-explained-linear-regression-with-python-fe2b313f32f3?source=friends_link&amp;sk=53c91a2a51347ec2d93f8222c0e06402" rel="noopener">用Python </a> <br/> 7全面讲解了线性回归。<a class="ae pi" href="https://medium.com/towards-artificial-intelligence/fully-explained-logistic-regression-with-python-f4a16413ddcd?source=friends_link&amp;sk=528181f15a44e48ea38fdd9579241a78" rel="noopener">用Python </a> <br/>充分解释了Logistic回归8。<a class="ae pi" rel="noopener ugc nofollow" target="_blank" href="/differences-between-concat-merge-and-join-with-python-1a6541abc08d?source=friends_link&amp;sk=3b37b694fb90db16275059ea752fc16a">concat()、merge()和join()与Python </a> <br/>的区别9。<a class="ae pi" rel="noopener ugc nofollow" target="_blank" href="/data-wrangling-with-python-part-1-969e3cc81d69?source=friends_link&amp;sk=9c3649cf20f31a5c9ead51c50c89ba0b">与Python的数据角力—第一部分</a> <br/> 10。<a class="ae pi" href="https://medium.com/analytics-vidhya/confusion-matrix-in-machine-learning-91b6e2b3f9af?source=friends_link&amp;sk=11c6531da0bab7b504d518d02746d4cc" rel="noopener">机器学习中的混淆矩阵</a></p></div></div>    
</body>
</html>