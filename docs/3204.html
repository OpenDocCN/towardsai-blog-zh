<html>
<head>
<title>A Simple Adjustment Improves Out-of-Distribution Detection for Any Classifier</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">简单的调整改进了任何分类器的分布外检测</h1>
<blockquote>原文：<a href="https://pub.towardsai.net/a-simple-adjustment-improves-out-of-distribution-detection-for-any-classifier-5e96bbb2d627?source=collection_archive---------0-----------------------#2022-10-12">https://pub.towardsai.net/a-simple-adjustment-improves-out-of-distribution-detection-for-any-classifier-5e96bbb2d627?source=collection_archive---------0-----------------------#2022-10-12</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><p id="6658" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated"><em class="kl">作者:乌莉娅娜·特卡琴科，乔纳斯·穆勒，柯蒂斯·g·诺斯卡特</em></p><figure class="kn ko kp kq gt kr gh gi paragraph-image"><div role="button" tabindex="0" class="ks kt di ku bf kv"><div class="gh gi km"><img src="../Images/0ebeae752a570c846a277d067e5b5cb6.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*ZkxqXEtn650zqfgdsaQy4w.png"/></div></div><figcaption class="ky kz gj gh gi la lb bd b be z dk translated">作者原创图片</figcaption></figure><p id="ba27" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">任何试图在真实世界数据集(不是我们在学校工作的完美策划的数据)上训练ML模型的人可能都处理过数据中的异常值。大多数异常值和非分布(OOD)检测算法的问题是，它们做了一个很大的假设，即一个模型在所有类别中都是一样有信心的，但大多数时候，这个假设是错误的。例如，在ImageNet上训练的模型通常对<code class="fe lc ld le lf b">bananas</code>过于自信(预测概率接近1 ),但对数据集中十个不同但非常相似的<code class="fe lc ld le lf b">lizard</code>类信心不足(预测概率低，接近0)。</p><p id="d216" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">在本文中，我将向您展示一种<strong class="jp ir">对模型预测概率的新颖而简单的调整，这种调整可以通过基于真实世界数据训练的模型来改进OOD检测</strong>。这里第一次介绍，这种独特的方法植根于理论，只需几行代码就可以运行。</p><h2 id="359d" class="lg lh iq bd li lj lk dn ll lm ln dp lo jy lp lq lr kc ls lt lu kg lv lw lx ly bi translated">背景</h2><p id="15d4" class="pw-post-body-paragraph jn jo iq jp b jq lz js jt ju ma jw jx jy mb ka kb kc mc ke kf kg md ki kj kk ij bi translated">识别测试数据中并非源于训练数据分布的异常值对于部署可靠的机器学习模型至关重要。虽然已经提出了许多特殊的(例如，生成的)模型来用于这种分布外(也称为异常/新奇)检测的任务，但是这些模型通常专用于特定的数据类型，并且实现起来并不简单。取而代之的是，更简单的食品检测方法已经变得相当popular⁴ ⁶.，这种方法对带有类别标签的数据使用已经训练好的分类器KNN distance⁵ ⁷和Mahalanobis距离⁴等方法利用训练好的神经网络的中间特征表示来识别OOD实例。</p><p id="7625" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">一个更简单的方法是仅使用由训练的分类器输出的预测的类概率，并量化它们的不确定性作为明显性的度量。两种特别流行的面向对象方法是最大软最大概率(MSP)⁶或Entropy⁴ ⁵.与大多数其他方法相比，MSP和熵需要更少的模型信息，并且需要更少的计算来识别异常值。在这里，我们介绍一个简单的改进这些基线方法，以提高其有效性。</p><h1 id="4e6c" class="me lh iq bd li mf mg mh ll mi mj mk lo ml mm mn lr mo mp mq lu mr ms mt lx mu bi translated">基于基线预测的OOD检测方法</h1><p id="5346" class="pw-post-body-paragraph jn jo iq jp b jq lz js jt ju ma jw jx jy mb ka kb kc mc ke kf kg md ki kj kk ij bi translated">考虑图像<code class="fe lc ld le lf b">x</code>和分类器模型<code class="fe lc ld le lf b">p = h(x)</code>，其中<code class="fe lc ld le lf b">p</code>是该图像属于每个类别<code class="fe lc ld le lf b">k ∈ {1,…,K}</code>的模型预测概率向量。基于<code class="fe lc ld le lf b">p</code>，可以<a class="ae mv" href="https://arxiv.org/pdf/1610.02136.pdf" rel="noopener ugc nofollow" target="_blank">为<code class="fe lc ld le lf b">x</code>计算</a>两个简单的OOD分数。</p><p id="c608" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated"><strong class="jp ir">最大软最大概率(MSP) </strong> —量化模型在其预测的最可能类别中的置信度:</p><figure class="kn ko kp kq gt kr gh gi paragraph-image"><div class="gh gi mw"><img src="../Images/59b9865da2cbf44ccee0daa778dd2e09.png" data-original-src="https://miro.medium.com/v2/resize:fit:856/format:webp/1*8bg_buSjaCE29oUv_LrGog.png"/></div><figcaption class="ky kz gj gh gi la lb bd b be z dk translated">示例x的MSP分数</figcaption></figure><p id="9dea" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated"><strong class="jp ir">熵</strong> —量化模型的概率预测在所有K类中的平均分布程度:</p><figure class="kn ko kp kq gt kr gh gi paragraph-image"><div class="gh gi mx"><img src="../Images/c2c0b2bc65b1fea22c2abe6c6f8ad894.png" data-original-src="https://miro.medium.com/v2/resize:fit:1058/format:webp/1*ogbeTz4xrY3lcrhWvtPKfg.png"/></div><figcaption class="ky kz gj gh gi la lb bd b be z dk translated">示例x的熵值</figcaption></figure><p id="e209" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">尽管事实上这些分数没有明确地估计认知uncertainty⁴.，但是已经显示出这些分数对于检测OOD images⁶非常有效</p><h1 id="060d" class="me lh iq bd li mf mg mh ll mi mj mk lo ml mm mn lr mo mp mq lu mr ms mt lx mu bi translated">改进基线方法的简单调整</h1><p id="7eaf" class="pw-post-body-paragraph jn jo iq jp b jq lz js jt ju ma jw jx jy mb ka kb kc mc ke kf kg md ki kj kk ij bi translated">模型预测概率<code class="fe lc ld le lf b">p</code>会受到估计误差的影响。经过训练的模型可能会偏向于预测特定的类，尤其是当原始数据集中的类不平衡时。为了解决这些问题，我们使用<em class="kl">类置信阈值⁴ </em>来调整预测概率，根据调整后预测的MSP/熵形成新的OOD分数。</p><h2 id="2032" class="lg lh iq bd li lj lk dn ll lm ln dp lo jy lp lq lr kc ls lt lu kg lv lw lx ly bi translated">计算类别置信度阈值</h2><p id="8d91" class="pw-post-body-paragraph jn jo iq jp b jq lz js jt ju ma jw jx jy mb ka kb kc mc ke kf kg md ki kj kk ij bi translated">设<code class="fe lc ld le lf b">yᵢ</code>表示我们训练数据中第I个例子的类别标签，而<code class="fe lc ld le lf b">pᵢₖ</code>表示这个例子<code class="fe lc ld le lf b">xᵢ</code>属于类别<code class="fe lc ld le lf b">k</code>的概率。根据我们的模型，我们计算一个<em class="kl">置信阈值</em>向量，其第k个元素定义为:</p><figure class="kn ko kp kq gt kr gh gi paragraph-image"><div class="gh gi my"><img src="../Images/361d603eb8e850468748e3064c8319f9.png" data-original-src="https://miro.medium.com/v2/resize:fit:968/format:webp/1*tlBNmet4sMk0VKyj-OmBCg.png"/></div><figcaption class="ky kz gj gh gi la lb bd b be z dk translated">类别<code class="fe lc ld le lf b">k</code>的置信阈值，其中<code class="fe lc ld le lf b">Nₖ</code>表示标记为类别<code class="fe lc ld le lf b">k</code>的训练样本的数量</figcaption></figure><p id="c982" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">置信度阈值是我们的模型在标记为某类的示例中预测的该类的平均概率。因此，该向量代表了我们的模型预测特定类别(例如标记为该类别的示例)的倾向，并已被证明是确定概率预测可靠性的自然阈值⁴.</p><h2 id="fcea" class="lg lh iq bd li lj lk dn ll lm ln dp lo jy lp lq lr kc ls lt lu kg lv lw lx ly bi translated">调整噪声的模型预测概率</h2><p id="68d9" class="pw-post-body-paragraph jn jo iq jp b jq lz js jt ju ma jw jx jy mb ka kb kc mc ke kf kg md ki kj kk ij bi translated">对于任何新的示例<code class="fe lc ld le lf b">x</code>，其预测的概率向量<code class="fe lc ld le lf b">p = h(x)</code>随后由类别置信度阈值调整如下:</p><figure class="kn ko kp kq gt kr gh gi paragraph-image"><div role="button" tabindex="0" class="ks kt di ku bf kv"><div class="gh gi mz"><img src="../Images/aed0294b3836e6e40ff44ba43b43b789.png" data-original-src="https://miro.medium.com/v2/resize:fit:608/format:webp/1*_MJt-m_qWYjJpsrzADysGA.png"/></div></div><figcaption class="ky kz gj gh gi la lb bd b be z dk translated">由类别置信度阈值调整的预测概率向量</figcaption></figure><p id="0827" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">这里,<code class="fe lc ld le lf b">cࠡ</code>是置信阈值向量中的最大值(以确保非负概率),而<code class="fe lc ld le lf b">Z</code>是归一化常数(以确保所有类别的概率总和为1):</p><figure class="kn ko kp kq gt kr gh gi paragraph-image"><div class="gh gi na"><img src="../Images/088a1e79293165c94f1dde86417a9244.png" data-original-src="https://miro.medium.com/v2/resize:fit:1320/format:webp/1*ksCUV4oZzR5ZLD73U9Ap4w.png"/></div><figcaption class="ky kz gj gh gi la lb bd b be z dk translated">最大置信阈值向量<code class="fe lc ld le lf b">cࠡ </code>和归一化常数<code class="fe lc ld le lf b">Z</code></figcaption></figure><p id="716e" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">值得注意的是，虽然置信阈值向量<code class="fe lc ld le lf b">c</code>总是使用训练预测的概率和标签来计算。可以使用这些阈值来调整任何模型输出预测概率(即，对于额外的测试数据)。</p><h2 id="fc49" class="lg lh iq bd li lj lk dn ll lm ln dp lo jy lp lq lr kc ls lt lu kg lv lw lx ly bi translated">计算调整后的OOD分数</h2><p id="405d" class="pw-post-body-paragraph jn jo iq jp b jq lz js jt ju ma jw jx jy mb ka kb kc mc ke kf kg md ki kj kk ij bi translated">通过简单地将调整后的预测概率<code class="fe lc ld le lf b">p̃</code>代替<code class="fe lc ld le lf b">p</code>插入各自的MSP/熵公式中，就可以提高<code class="fe lc ld le lf b">x</code>的OOD分数。因此，这种调整后的OOD检测过程仍然非常简单，并且易于在实际部署中实现。</p><h2 id="7947" class="lg lh iq bd li lj lk dn ll lm ln dp lo jy lp lq lr kc ls lt lu kg lv lw lx ly bi translated">基准绩效</h2><p id="64e4" class="pw-post-body-paragraph jn jo iq jp b jq lz js jt ju ma jw jx jy mb ka kb kc mc ke kf kg md ki kj kk ij bi translated">遵循标准的OOD基准程序，现有的图像分类数据集被成对分组，其中:一个数据集用于训练Swin Transformer⁸分类器，并被视为分布内训练数据，而第二个数据集的样本与第一个数据集的测试数据混合(以50-50的比例)作为分布外图像。每种OOD评分方法都应用于测试集中的所有图像(不知道它们的来源或标签),以产生这些图像的等级，我们使用AUROC评估这些分数检测OOD示例的程度。</p><figure class="kn ko kp kq gt kr gh gi paragraph-image"><div role="button" tabindex="0" class="ks kt di ku bf kv"><div class="gh gi nb"><img src="../Images/8bf4df7c5bf9df91a64508bdee5dacc6.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*lBLPFeTJThsx90up4PVA2g.png"/></div></div><figcaption class="ky kz gj gh gi la lb bd b be z dk translated">作者的原始图像，用于评估食品检测分数的输入/输出分布数据设置</figcaption></figure><p id="fae4" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">我们基于流行的图像分类数据集考虑两种不同的OOD检测问题:CIFAR-10⁵对CIFAR-100⁵和MNIST⁶对FASHION-MNIST⁷.我们的第一个基准依赖于这些数据集的原始版本，其中类自然以相等的比例出现。</p><p id="b9dc" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">我们还运行了第二个基准测试，其中我们在每个训练集中引入了类别不平衡。这里，我们为CIFAR-10、MNIST和时尚-MNIST创建新的不平衡训练集，其中在每个训练集中:6个类每个包含总样本的2 %, 4个类每个包含样本的22%。我们还为CIFAR-100创建了一个不平衡的训练集，其中90个类每个都有0.63%的样本，10个类每个都有4.25%的样本。这使我们能够评估我们的OOD分数在标记的训练数据中以不相等的比例出现的设置中的表现，这在现实世界的应用中是常见的情况。</p><h2 id="aecb" class="lg lh iq bd li lj lk dn ll lm ln dp lo jy lp lq lr kc ls lt lu kg lv lw lx ly bi translated">改进基线方法结果</h2><p id="4abd" class="pw-post-body-paragraph jn jo iq jp b jq lz js jt ju ma jw jx jy mb ka kb kc mc ke kf kg md ki kj kk ij bi translated">表1和表2列出了针对每个基准设置，通过调整和原始(未调整)OOD评分方法实现的AUROC性能。对于许多in-distribution / OOD数据集对，我们提出的调整带来了明显的改善。</p><figure class="kn ko kp kq gt kr gh gi paragraph-image"><div role="button" tabindex="0" class="ks kt di ku bf kv"><div class="gh gi nc"><img src="../Images/c754a8f735c0c14c0160644f91b6d1e7.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*8lS0M7GW2g8hVX929tuJmw.png"/></div></div><figcaption class="ky kz gj gh gi la lb bd b be z dk translated">表1:原始(平衡)数据集的分布外检测性能(AUROC)(越高越好)。</figcaption></figure><figure class="kn ko kp kq gt kr gh gi paragraph-image"><div role="button" tabindex="0" class="ks kt di ku bf kv"><div class="gh gi nc"><img src="../Images/69109b52ae1f834b8773e26358d3b3c6.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*LJ5OpwFyjaJqEBR-bSyleQ.png"/></div></div><figcaption class="ky kz gj gh gi la lb bd b be z dk translated">表2:不平衡数据集的分布外检测性能(AUROC )(越高越好)。</figcaption></figure><p id="9494" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">只需对训练好的分类器输出的预测概率进行微小调整，熵和基于MSP的分布外检测分数的性能都得到了提高。</p><p id="87f8" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">在任何数据集上运行该OOD方法的代码已经在<a class="ae mv" href="https://github.com/cleanlab/cleanlab/blob/master/cleanlab/outlier.py" rel="noopener ugc nofollow" target="_blank">这里</a>可用。</p><h1 id="4da0" class="me lh iq bd li mf mg mh ll mi mj mk lo ml mm mn lr mo mp mq lu mr ms mt lx mu bi translated">参考</h1><p id="6a7c" class="pw-post-body-paragraph jn jo iq jp b jq lz js jt ju ma jw jx jy mb ka kb kc mc ke kf kg md ki kj kk ij bi translated">[1]杨军，周，王，李，刘.广义非分布检测综述.<em class="kl"> arXiv:2110.11334 </em>。2021.</p><p id="f791" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">[2] Ran，x，Xu，m .，Mei，l .，Xu Q，和Liu Q .通过具有可靠不确定性估计的变分自动编码器检测非分布样本。<em class="kl">神经网络</em>。2022.</p><p id="5715" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">[3]曹，s .和张，z .用于分布外检测的深度混合模型.IEEE/CVF计算机视觉和模式识别会议文集。2022.</p><p id="4d46" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">[4] Kirsch，a .，Mukhoti，j .，van Amersfoort，j .，Torr，P. H. S .，和Gal，y .关于食品检测中的缺陷:熵被认为是有害的。<em class="kl">深度学习中的不确定性和鲁棒性ICML研讨会</em>。2021.</p><p id="1846" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">[5] Kuan，j .和Mueller，j.《回到基础:再访分布外检测基线》。<em class="kl">关于分配转移原则的ICML研讨会。</em> 2022年</p><p id="3e25" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">[6] Hendrycks，d .和Gimpel，k.《在神经网络中检测错误分类和非分布样本的基线》.在2017年国际学习代表大会上。</p><p id="3960" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">[7] Angiulli，f .和Pizzuti，c.《高维空间中的快速异常值检测》。2002年欧洲数据挖掘和知识发现原理会议。</p><p id="d5f8" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">[8] Lee，k .、Lee，k .、Lee，h .和Shin，j.《用于检测分布外样本和对抗性攻击的简单统一框架》。神经信息处理系统进展，31，2018。</p><p id="68e2" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">[9] Fort，s .，Ren，j .和Lakshminarayanan，b.《探索分布外检测的极限》。神经信息处理系统进展，34，2021。</p><p id="db4e" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">[10] Krizhevsky，a .从微小图像中学习多层次特征。2009.</p><p id="acc3" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">[11]邓，l .用于机器学习研究的手写数字图像mnist数据库.IEEE信号处理杂志，29(6):141–142，2012</p><p id="e129" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">[12] Xiao，h .，Rasul，k .和Vollgraf，R. Fashion-mnist:一种用于机器学习算法基准测试的新型图像数据集。arXiv预印本arXiv:1708.07747，2017。</p><p id="b53c" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">[13] Liu，z .，Lin，y .，Cao，y .，Hu，h .，Wei，y .，Zhang，z .，Lin，s .，和Guo，B. Swin transformer:使用移位窗口的分层视觉转换器。2021年IEEE/CVF计算机视觉国际会议论文集。</p><p id="35f2" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">[14] Northcutt C，Jiang L，Chuang I .自信学习:估计数据集标签中的不确定性.人工智能研究杂志。2021.</p></div></div>    
</body>
</html>