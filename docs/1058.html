<html>
<head>
<title>Basic Linear Algebra for Deep Learning and Machine Learning Python Tutorial</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">深度学习和机器学习Python教程的基础线性代数</h1>
<blockquote>原文：<a href="https://pub.towardsai.net/basic-linear-algebra-for-deep-learning-and-machine-learning-ml-python-tutorial-444e23db3e9e?source=collection_archive---------0-----------------------#2020-10-19">https://pub.towardsai.net/basic-linear-algebra-for-deep-learning-and-machine-learning-ml-python-tutorial-444e23db3e9e?source=collection_archive---------0-----------------------#2020-10-19</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><figure class="is it gp gr iu iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi ir"><img src="../Images/36c10a3837a0f55ee5651df628c1fb1f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*ucstSFi9hpmh2v-b0UMQzw.png"/></div></div><figcaption class="jc jd gj gh gi je jf bd b be z dk translated">图1:一个三维欧几里得空间，用来表示线性方程组[ <a class="ae jg" href="https://en.wikipedia.org/wiki/Linear_algebra" rel="noopener ugc nofollow" target="_blank"> 1 </a> ] [ <a class="ae jg" href="https://en.wikipedia.org/wiki/Euclidean_space" rel="noopener ugc nofollow" target="_blank"> 2 </a> ]的解。图像是由Richard Connor、Lucia Vadicamo和Fausto Rabitti [ <a class="ae jg" href="https://www.researchgate.net/publication/318720793_High-Dimensional_Simplexes_for_Supermetric_Search" rel="noopener ugc nofollow" target="_blank"> 3 </a> ]创作的“<a class="ae jg" href="https://www.researchgate.net/publication/318720793_High-Dimensional_Simplexes_for_Supermetric_Search" rel="noopener ugc nofollow" target="_blank"> <strong class="bd jh">用于超度量搜索的高维简单图”的矢量衍生图。</strong></a></figcaption></figure><h2 id="c61d" class="ji jj jk bd b dl jl jm jn jo jp jq dk jr translated" aria-label="kicker paragraph"><a class="ae ep" href="https://towardsai.net/p/category/machine-learning/deep-learning" rel="noopener ugc nofollow" target="_blank">深度学习</a>，<a class="ae ep" href="https://towardsai.net/p/category/editorial" rel="noopener ugc nofollow" target="_blank">编辑</a>，<a class="ae ep" href="https://towardsai.net/p/category/machine-intelligence" rel="noopener ugc nofollow" target="_blank">机器学习</a>，<a class="ae ep" href="https://towardsai.net/p/category/mathematics" rel="noopener ugc nofollow" target="_blank">数学</a>，<a class="ae ep" href="https://towardsai.net/p/category/programming" rel="noopener ugc nofollow" target="_blank">编程</a>，<a class="ae ep" href="https://towardsai.net/p/category/tutorial" rel="noopener ugc nofollow" target="_blank">教程</a></h2><div class=""/><div class=""><h2 id="5d07" class="pw-subtitle-paragraph kq jt jk bd b kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh dk translated">线性代数入门教程，用于<a class="ae jg" href="https://mld.ai/mldcmu" rel="noopener ugc nofollow" target="_blank">机器学习</a> (ML)和深度学习，包含Python中的示例代码实现</h2></div><p id="6809" class="pw-post-body-paragraph li lj jk lk b ll lm ku ln lo lp kx lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">最后更新，2021年1月6日</p><p id="f156" class="pw-post-body-paragraph li lj jk lk b ll lm ku ln lo lp kx lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated"><strong class="lk ju">作者:</strong>萨妮娅·帕维斯，<a class="ae jg" href="https://mktg.best/vguzs" rel="noopener ugc nofollow" target="_blank">罗伯托·伊里翁多</a></p><div class="is it gp gr iu me"><a href="https://members.towardsai.net/" rel="noopener  ugc nofollow" target="_blank"><div class="mf ab fo"><div class="mg ab mh cl cj mi"><h2 class="bd ju gy z fp mj fr fs mk fu fw jt bi translated">加入我们吧↓ |面向人工智能成员|数据驱动的社区</h2><div class="ml l"><h3 class="bd b gy z fp mj fr fs mk fu fw dk translated">加入人工智能，成为会员，你将不仅支持人工智能，但你将有机会…</h3></div><div class="mm l"><p class="bd b dl z fp mj fr fs mk fu fw dk translated">members.towardsai.net</p></div></div><div class="mn l"><div class="mo l mp mq mr mn ms ja me"/></div></div></a></div><p id="38ae" class="pw-post-body-paragraph li lj jk lk b ll lm ku ln lo lp kx lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated"><strong class="lk ju">本教程的代码可在</strong><a class="ae jg" href="https://github.com/towardsai/tutorials/tree/master/linear-algebra-for-ml-and-deep-learning" rel="noopener ugc nofollow" target="_blank"><strong class="lk ju">Github</strong></a><strong class="lk ju">上获得，其完整实现也可在</strong><a class="ae jg" href="https://colab.research.google.com/drive/1WhzsrEQ-JatDbaaJ81Wh8aYY9jqGWdsw?usp=sharing" rel="noopener ugc nofollow" target="_blank"><strong class="lk ju">Google Colab</strong></a><strong class="lk ju">上获得。</strong></p><h2 id="cfcc" class="mt mu jk bd jh mv mw dn mx my mz dp na lr nb nc nd lv ne nf ng lz nh ni nj jq bi translated">目录</h2><ol class=""><li id="f046" class="nk nl jk lk b ll nm lo nn lr no lv np lz nq md nr ns nt nu bi translated"><a class="ae jg" href="#46d0" rel="noopener ugc nofollow">简介</a></li><li id="d0ac" class="nk nl jk lk b ll nv lo nw lr nx lv ny lz nz md nr ns nt nu bi translated"><a class="ae jg" href="#60ee" rel="noopener ugc nofollow">机器学习和深度学习中的线性代数</a></li><li id="9704" class="nk nl jk lk b ll nv lo nw lr nx lv ny lz nz md nr ns nt nu bi translated"><a class="ae jg" href="#56b6" rel="noopener ugc nofollow">矩阵</a></li><li id="4cf8" class="nk nl jk lk b ll nv lo nw lr nx lv ny lz nz md nr ns nt nu bi translated"><a class="ae jg" href="#a2b1" rel="noopener ugc nofollow">矢量</a></li><li id="81c8" class="nk nl jk lk b ll nv lo nw lr nx lv ny lz nz md nr ns nt nu bi translated"><a class="ae jg" href="#f25a" rel="noopener ugc nofollow">矩阵乘法</a></li><li id="4839" class="nk nl jk lk b ll nv lo nw lr nx lv ny lz nz md nr ns nt nu bi translated"><a class="ae jg" href="#1986" rel="noopener ugc nofollow">转置矩阵</a></li><li id="65ac" class="nk nl jk lk b ll nv lo nw lr nx lv ny lz nz md nr ns nt nu bi translated"><a class="ae jg" href="#2173" rel="noopener ugc nofollow">逆矩阵</a></li><li id="37ba" class="nk nl jk lk b ll nv lo nw lr nx lv ny lz nz md nr ns nt nu bi translated"><a class="ae jg" href="#c383" rel="noopener ugc nofollow">正交矩阵</a></li><li id="810f" class="nk nl jk lk b ll nv lo nw lr nx lv ny lz nz md nr ns nt nu bi translated"><a class="ae jg" href="#fa6e" rel="noopener ugc nofollow">对角矩阵</a></li><li id="e7b7" class="nk nl jk lk b ll nv lo nw lr nx lv ny lz nz md nr ns nt nu bi translated"><a class="ae jg" href="#7788" rel="noopener ugc nofollow">正规方程中的转置矩阵和逆矩阵</a></li><li id="3279" class="nk nl jk lk b ll nv lo nw lr nx lv ny lz nz md nr ns nt nu bi translated"><a class="ae jg" href="#555f" rel="noopener ugc nofollow">线性方程</a></li><li id="a433" class="nk nl jk lk b ll nv lo nw lr nx lv ny lz nz md nr ns nt nu bi translated"><a class="ae jg" href="#94b3" rel="noopener ugc nofollow">向量规范</a></li><li id="3941" class="nk nl jk lk b ll nv lo nw lr nx lv ny lz nz md nr ns nt nu bi translated"><a class="ae jg" href="#dda9" rel="noopener ugc nofollow"> L1常模或曼哈顿常模</a></li><li id="12a4" class="nk nl jk lk b ll nv lo nw lr nx lv ny lz nz md nr ns nt nu bi translated"><a class="ae jg" href="#11bc" rel="noopener ugc nofollow"> L2范数或欧几里德范数</a></li><li id="d6d0" class="nk nl jk lk b ll nv lo nw lr nx lv ny lz nz md nr ns nt nu bi translated"><a class="ae jg" href="#41da" rel="noopener ugc nofollow">机器学习中的正则化</a></li><li id="51a8" class="nk nl jk lk b ll nv lo nw lr nx lv ny lz nz md nr ns nt nu bi translated"><a class="ae jg" href="#564d" rel="noopener ugc nofollow">套索</a></li><li id="2653" class="nk nl jk lk b ll nv lo nw lr nx lv ny lz nz md nr ns nt nu bi translated"><a class="ae jg" href="#d6fd" rel="noopener ugc nofollow">山脊</a></li><li id="fe01" class="nk nl jk lk b ll nv lo nw lr nx lv ny lz nz md nr ns nt nu bi translated"><a class="ae jg" href="#c54b" rel="noopener ugc nofollow">特征提取和特征选择</a></li><li id="7b46" class="nk nl jk lk b ll nv lo nw lr nx lv ny lz nz md nr ns nt nu bi translated"><a class="ae jg" href="#953f" rel="noopener ugc nofollow">协方差矩阵</a></li><li id="24a4" class="nk nl jk lk b ll nv lo nw lr nx lv ny lz nz md nr ns nt nu bi translated"><a class="ae jg" href="#bcd2" rel="noopener ugc nofollow">特征值和特征向量</a></li><li id="fe0a" class="nk nl jk lk b ll nv lo nw lr nx lv ny lz nz md nr ns nt nu bi translated"><a class="ae jg" href="#9c2e" rel="noopener ugc nofollow">正交性</a></li><li id="f8ff" class="nk nl jk lk b ll nv lo nw lr nx lv ny lz nz md nr ns nt nu bi translated"><a class="ae jg" href="#4312" rel="noopener ugc nofollow">标准正交集</a></li><li id="d2be" class="nk nl jk lk b ll nv lo nw lr nx lv ny lz nz md nr ns nt nu bi translated"><a class="ae jg" href="#b757" rel="noopener ugc nofollow">跨度</a></li><li id="cb0b" class="nk nl jk lk b ll nv lo nw lr nx lv ny lz nz md nr ns nt nu bi translated"><a class="ae jg" href="#f187" rel="noopener ugc nofollow">基础</a></li><li id="e5a5" class="nk nl jk lk b ll nv lo nw lr nx lv ny lz nz md nr ns nt nu bi translated"><a class="ae jg" href="#7594" rel="noopener ugc nofollow">主成分分析</a></li><li id="5b09" class="nk nl jk lk b ll nv lo nw lr nx lv ny lz nz md nr ns nt nu bi translated"><a class="ae jg" href="#740e" rel="noopener ugc nofollow">矩阵分解或矩阵分解</a></li><li id="c8f1" class="nk nl jk lk b ll nv lo nw lr nx lv ny lz nz md nr ns nt nu bi translated"><a class="ae jg" href="#3904" rel="noopener ugc nofollow">结论</a></li><li id="6a5d" class="nk nl jk lk b ll nv lo nw lr nx lv ny lz nz md nr ns nt nu bi translated"><a class="ae jg" href="#3902" rel="noopener ugc nofollow">资源</a></li><li id="f9b7" class="nk nl jk lk b ll nv lo nw lr nx lv ny lz nz md nr ns nt nu bi translated"><a class="ae jg" href="#8f6f" rel="noopener ugc nofollow">参考文献</a></li></ol><blockquote class="oa"><p id="ab35" class="ob oc jk bd od oe of og oh oi oj md dk translated">📚查看我们关于<a class="ae jg" href="https://towardsai.net/p/news/best-laptops-for-machine-learning-deep-learning-data-science-ml-f55602197593" rel="noopener ugc nofollow" target="_blank">用于机器学习、数据科学和深度学习的最佳笔记本电脑</a>的编辑推荐。📚</p></blockquote></div><div class="ab cl ok ol hx om" role="separator"><span class="on bw bk oo op oq"/><span class="on bw bk oo op oq"/><span class="on bw bk oo op"/></div><div class="im in io ip iq"><h1 id="46d0" class="or mu jk bd jh os ot ou mx ov ow ox na kz oy la nd lc oz ld ng lf pa lg nj pb bi translated">介绍</h1><p id="a8ae" class="pw-post-body-paragraph li lj jk lk b ll nm ku ln lo nn kx lq lr pc lt lu lv pd lx ly lz pe mb mc md im bi translated"><a class="ae jg" href="https://mld.ai/mldcmu" rel="noopener ugc nofollow" target="_blank"> <strong class="lk ju">机器学习</strong> </a>和深度学习系统的基础完全基于数学原理和概念。理解数学原理的基本基础是必要的。在基线和模型构建过程中，许多数学概念，如维数灾难、正则化、二进制、多类、有序回归等，都必须在头脑中保持艺术性。</p><p id="decf" class="pw-post-body-paragraph li lj jk lk b ll lm ku ln lo lp kx lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">深度学习的基本单元，通常称为神经元，完全基于其数学概念，这涉及到涉及输入和权重的相乘值的总和。它的激活函数，如Sigmoid、ReLU和其他函数，是使用数学定理构建的。</p><p id="bac6" class="pw-post-body-paragraph li lj jk lk b ll lm ku ln lo lp kx lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">这些是正确理解机器学习和深度学习的基本概念的基本数学领域:</p><ul class=""><li id="1ee9" class="nk nl jk lk b ll lm lo lp lr pf lv pg lz ph md pi ns nt nu bi translated">线性代数。</li><li id="0cf6" class="nk nl jk lk b ll nv lo nw lr nx lv ny lz nz md pi ns nt nu bi translated">向量微积分。</li><li id="baf6" class="nk nl jk lk b ll nv lo nw lr nx lv ny lz nz md pi ns nt nu bi translated">矩阵分解。</li><li id="ff4a" class="nk nl jk lk b ll nv lo nw lr nx lv ny lz nz md pi ns nt nu bi translated">概率和分布。</li><li id="1f60" class="nk nl jk lk b ll nv lo nw lr nx lv ny lz nz md pi ns nt nu bi translated">解析几何。</li></ul><h1 id="60ee" class="or mu jk bd jh os pj ou mx ov pk ox na kz pl la nd lc pm ld ng lf pn lg nj pb bi translated">机器学习和深度学习中的线性代数</h1><p id="6377" class="pw-post-body-paragraph li lj jk lk b ll nm ku ln lo nn kx lq lr pc lt lu lv pd lx ly lz pe mb mc md im bi translated">由于向量的可用性和处理向量的若干规则，线性代数在机器学习中起着必不可少的作用。我们主要处理机器学习中的分类器或回归器问题，然后通过从实际值到预测值的计算来应用误差最小化技术。因此，我们使用线性代数来处理前面提到的计算。线性代数处理大量数据，或者换句话说，“线性代数是数据的基础数学。”</p><p id="d2a3" class="pw-post-body-paragraph li lj jk lk b ll lm ku ln lo lp kx lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">这些是我们在机器学习(ML)和深度学习[ <a class="ae jg" href="https://d2l.ai/chapter_preliminaries/linear-algebra.html" rel="noopener ugc nofollow" target="_blank"> 11 </a> ]中使用的线性代数的一些领域:</p><ul class=""><li id="5fbf" class="nk nl jk lk b ll lm lo lp lr pf lv pg lz ph md pi ns nt nu bi translated">向量和矩阵。</li><li id="36fc" class="nk nl jk lk b ll nv lo nw lr nx lv ny lz nz md pi ns nt nu bi translated">线性方程组。</li><li id="c6fc" class="nk nl jk lk b ll nv lo nw lr nx lv ny lz nz md pi ns nt nu bi translated">向量空间。</li><li id="d681" class="nk nl jk lk b ll nv lo nw lr nx lv ny lz nz md pi ns nt nu bi translated">基础。</li></ul><p id="eee8" class="pw-post-body-paragraph li lj jk lk b ll lm ku ln lo lp kx lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">此外，这些是机器学习(ML)和深度学习的领域，我们在这些领域应用线性代数的方法:</p><ul class=""><li id="9a3c" class="nk nl jk lk b ll lm lo lp lr pf lv pg lz ph md pi ns nt nu bi translated">回归线的推导。</li><li id="07de" class="nk nl jk lk b ll nv lo nw lr nx lv ny lz nz md pi ns nt nu bi translated">预测目标值的线性方程。</li><li id="8403" class="nk nl jk lk b ll nv lo nw lr nx lv ny lz nz md pi ns nt nu bi translated">支持向量机分类(SVM)。</li><li id="5978" class="nk nl jk lk b ll nv lo nw lr nx lv ny lz nz md pi ns nt nu bi translated">降维。</li><li id="bbe4" class="nk nl jk lk b ll nv lo nw lr nx lv ny lz nz md pi ns nt nu bi translated">均方误差或损失函数。</li><li id="3fca" class="nk nl jk lk b ll nv lo nw lr nx lv ny lz nz md pi ns nt nu bi translated">正规化。</li><li id="08a8" class="nk nl jk lk b ll nv lo nw lr nx lv ny lz nz md pi ns nt nu bi translated">协方差矩阵。</li><li id="6b37" class="nk nl jk lk b ll nv lo nw lr nx lv ny lz nz md pi ns nt nu bi translated">卷积。</li></ul><figure class="pp pq pr ps gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi po"><img src="../Images/32ed0665bc314fcde6775c185612069c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*o-KdapzNQNhnO1IN.png"/></div></div><figcaption class="jc jd gj gh gi je jf bd b be z dk translated">图2:一个矢量积。</figcaption></figure><h1 id="56b6" class="or mu jk bd jh os pj ou mx ov pk ox na kz pl la nd lc pm ld ng lf pn lg nj pb bi translated">[数]矩阵</h1><p id="aa0e" class="pw-post-body-paragraph li lj jk lk b ll nm ku ln lo nn kx lq lr pc lt lu lv pd lx ly lz pe mb mc md im bi translated">矩阵是线性代数的重要组成部分。它存储<em class="pt"> m*n </em>个数据元素，我们用它来计算线性方程组或线性映射。它是实值元素[ <a class="ae jg" href="https://d2l.ai/chapter_preliminaries/linear-algebra.html" rel="noopener ugc nofollow" target="_blank"> 11 </a> ]的一个<em class="pt"> m*n </em>元组。</p><figure class="pp pq pr ps gt iv gh gi paragraph-image"><div class="gh gi pu"><img src="../Images/75017c786d33a89f9b80a25c35e7cd9f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1328/format:webp/0*ELnRHqb0dtq1DGAt.png"/></div><figcaption class="jc jd gj gh gi je jf bd b be z dk translated">图3:矩阵表示。</figcaption></figure><p id="f951" class="pw-post-body-paragraph li lj jk lk b ll lm ku ln lo lp kx lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">行数和列数称为矩阵的维数。</p><h1 id="a2b1" class="or mu jk bd jh os pj ou mx ov pk ox na kz pl la nd lc pm ld ng lf pn lg nj pb bi translated">矢量</h1><p id="f909" class="pw-post-body-paragraph li lj jk lk b ll nm ku ln lo nn kx lq lr pc lt lu lv pd lx ly lz pe mb mc md im bi translated">在线性代数中，向量是一个<em class="pt"> n*1 </em>矩阵。它只有一列。</p><figure class="pp pq pr ps gt iv gh gi paragraph-image"><div class="gh gi pv"><img src="../Images/e5218283a2b1a0daad551dee2f9e1f9a.png" data-original-src="https://miro.medium.com/v2/resize:fit:464/format:webp/0*7byg3hv_heUVDh-e.png"/></div><figcaption class="jc jd gj gh gi je jf bd b be z dk translated">图4:向量表示。</figcaption></figure><h1 id="f25a" class="or mu jk bd jh os pj ou mx ov pk ox na kz pl la nd lc pm ld ng lf pn lg nj pb bi translated">矩阵乘法</h1><p id="b519" class="pw-post-body-paragraph li lj jk lk b ll nm ku ln lo nn kx lq lr pc lt lu lv pd lx ly lz pe mb mc md im bi translated">矩阵乘法是行和列的点积，其中矩阵的行与另一个矩阵列相乘并求和。</p><figure class="pp pq pr ps gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi pw"><img src="../Images/d93bb0c06fa745545b08564aaf51dd87.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*gvuDq-5TCsANOw4rKfmsUQ.png"/></div></div><figcaption class="jc jd gj gh gi je jf bd b be z dk translated">图5:矩阵乘法。</figcaption></figure><h2 id="2185" class="mt mu jk bd jh mv mw dn mx my mz dp na lr nb nc nd lv ne nf ng lz nh ni nj jq bi translated">在线性回归中</h2><p id="a886" class="pw-post-body-paragraph li lj jk lk b ll nm ku ln lo nn kx lq lr pc lt lu lv pd lx ly lz pe mb mc md im bi translated">预测房价有多个特征。下表列出了不同房屋的特点和目标价值(价格)。</p><figure class="pp pq pr ps gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi px"><img src="../Images/648386f437e1f3a10177653d6cdb6073.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*fb0hS1mXq3blynsK.png"/></div></div><figcaption class="jc jd gj gh gi je jf bd b be z dk translated">图6:表1展示了预测房价的房屋特征。</figcaption></figure><figure class="pp pq pr ps gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi py"><img src="../Images/c6a2c9fb182dc4722f3189d0354d1c92.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*v4bva1F3DF2ZUVFE.png"/></div></div><figcaption class="jc jd gj gh gi je jf bd b be z dk translated">图7:特性和目标变量。</figcaption></figure><p id="bba7" class="pw-post-body-paragraph li lj jk lk b ll lm ku ln lo lp kx lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">因此，要计算假设:</p><figure class="pp pq pr ps gt iv gh gi paragraph-image"><div class="gh gi pz"><img src="../Images/a988a88b3711525f79141a08140211e8.png" data-original-src="https://miro.medium.com/v2/resize:fit:1318/format:webp/0*vg5fFl2pVPTu-VGJ.png"/></div><figcaption class="jc jd gj gh gi je jf bd b be z dk translated">图8:特性和系数。</figcaption></figure><figure class="pp pq pr ps gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi qa"><img src="../Images/4f417a645a2461052709d36b650d9f69.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*kIFF5IXqGbhKk9aa.png"/></div></div><figcaption class="jc jd gj gh gi je jf bd b be z dk translated">图9:房价预测的假设计算。</figcaption></figure><h1 id="1986" class="or mu jk bd jh os pj ou mx ov pk ox na kz pl la nd lc pm ld ng lf pn lg nj pb bi translated">转置矩阵</h1><p id="d3d0" class="pw-post-body-paragraph li lj jk lk b ll nm ku ln lo nn kx lq lr pc lt lu lv pd lx ly lz pe mb mc md im bi translated">对于<strong class="lk ju"> A </strong> ∈ R^ <em class="pt"> m*n </em>矩阵<strong class="lk ju"> B </strong> ∈ R^ <em class="pt"> n*m </em>与<strong class="lk ju">b</strong><em class="pt">ij =</em><strong class="lk ju"><em class="pt">a</em></strong>ij称为<strong class="lk ju"> A </strong>的转置。表示为<strong class="lk ju">b</strong>=<strong class="lk ju">a</strong>^<em class="pt">t .</em></p><p id="4da2" class="pw-post-body-paragraph li lj jk lk b ll lm ku ln lo lp kx lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">示例:</p><figure class="pp pq pr ps gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi qb"><img src="../Images/462007e4ef5dc053f35e9e8efcdd9ce5.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*WFWYm0gsjW3q7Uo_.png"/></div></div><figcaption class="jc jd gj gh gi je jf bd b be z dk translated">图10:矩阵a的转置</figcaption></figure><h1 id="2173" class="or mu jk bd jh os pj ou mx ov pk ox na kz pl la nd lc pm ld ng lf pn lg nj pb bi translated">逆矩阵</h1><p id="a6bf" class="pw-post-body-paragraph li lj jk lk b ll nm ku ln lo nn kx lq lr pc lt lu lv pd lx ly lz pe mb mc md im bi translated">考虑一个方阵<strong class="lk ju"> A </strong> ∈ R^ <em class="pt"> n*n. </em>设矩阵<strong class="lk ju"> B </strong> ∈R^ <em class="pt"> n*n </em>具有<strong class="lk ju"> AB </strong> = In = <strong class="lk ju"> BA，B </strong>称为<strong class="lk ju"> A </strong>的逆，记为<strong class="lk ju"> A </strong> ^ <em class="pt"> -1。</em></p><figure class="pp pq pr ps gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi qc"><img src="../Images/aa756ae032635bf6fdbf6319bd4d209c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*fed_Kj4TyOKbtAqw.png"/></div></div><figcaption class="jc jd gj gh gi je jf bd b be z dk translated">图11:矩阵A和b。</figcaption></figure><figure class="pp pq pr ps gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi qd"><img src="../Images/76faf853224a49883abeb9bd6c00f4ee.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*Y_G98ruMakKBPsXg.png"/></div></div><figcaption class="jc jd gj gh gi je jf bd b be z dk translated">图12:矩阵A和b之间的乘法。</figcaption></figure><figure class="pp pq pr ps gt iv gh gi paragraph-image"><div class="gh gi qe"><img src="../Images/6cd74bfbc871214e04382b243766a7d0.png" data-original-src="https://miro.medium.com/v2/resize:fit:998/format:webp/0*zO0V6t08Uv_Rpshf.png"/></div><figcaption class="jc jd gj gh gi je jf bd b be z dk translated">图13:转置矩阵。</figcaption></figure><h1 id="c383" class="or mu jk bd jh os pj ou mx ov pk ox na kz pl la nd lc pm ld ng lf pn lg nj pb bi translated">正交矩阵</h1><p id="f093" class="pw-post-body-paragraph li lj jk lk b ll nm ku ln lo nn kx lq lr pc lt lu lv pd lx ly lz pe mb mc md im bi translated">方阵A∈R^ <em class="pt"> n*n </em>是正交矩阵当且仅当它的列是正交的(单位长度)，因此:</p><figure class="pp pq pr ps gt iv gh gi paragraph-image"><div class="gh gi qf"><img src="../Images/c903045c574b808cf122fa5bec552829.png" data-original-src="https://miro.medium.com/v2/resize:fit:1114/format:webp/0*i_xcXloZ9z7Or1yC.png"/></div><figcaption class="jc jd gj gh gi je jf bd b be z dk translated">图14:正交矩阵的方程。</figcaption></figure><p id="bfb3" class="pw-post-body-paragraph li lj jk lk b ll lm ku ln lo lp kx lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">示例:</p><figure class="pp pq pr ps gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi qg"><img src="../Images/4550d4189f30b6c81453863fe8351387.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*8dI5J_rdTyzoHLoe.png"/></div></div><figcaption class="jc jd gj gh gi je jf bd b be z dk translated">图15:矩阵A及其转置矩阵。</figcaption></figure><p id="2476" class="pw-post-body-paragraph li lj jk lk b ll lm ku ln lo lp kx lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">因此，</p><figure class="pp pq pr ps gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi qb"><img src="../Images/b074c8d1607bc3b03194a424664a0a63.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*TqcDGg0WIQ8AVyQU.png"/></div></div><figcaption class="jc jd gj gh gi je jf bd b be z dk translated">图16:乘以A的转置。</figcaption></figure><h1 id="fa6e" class="or mu jk bd jh os pj ou mx ov pk ox na kz pl la nd lc pm ld ng lf pn lg nj pb bi translated">对角矩阵</h1><p id="89a9" class="pw-post-body-paragraph li lj jk lk b ll nm ku ln lo nn kx lq lr pc lt lu lv pd lx ly lz pe mb mc md im bi translated">方阵A∈R^ <em class="pt"> n*n </em>是一个对角矩阵，其中除了主对角线上的元素之外，所有元素都为零，如下所示:</p><blockquote class="qh qi qj"><p id="b664" class="li lj pt lk b ll lm ku ln lo lp kx lq qk ls lt lu ql lw lx ly qm ma mb mc md im bi translated"><em class="jk"> Aij =0代表所有I！= j </em></p><p id="2133" class="li lj pt lk b ll lm ku ln lo lp kx lq qk ls lt lu ql lw lx ly qm ma mb mc md im bi translated"><em class="jk"> Aij = 0为部分或全部i = j </em></p></blockquote><p id="412b" class="pw-post-body-paragraph li lj jk lk b ll lm ku ln lo lp kx lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">示例:</p><figure class="pp pq pr ps gt iv gh gi paragraph-image"><div class="gh gi qn"><img src="../Images/c3cae5cb2c7086fdef16615ee5ec9edd.png" data-original-src="https://miro.medium.com/v2/resize:fit:1086/format:webp/0*xz_8Ap6Ic4OgkJmU.png"/></div><figcaption class="jc jd gj gh gi je jf bd b be z dk translated">图17:对角矩阵a。</figcaption></figure><h1 id="7788" class="or mu jk bd jh os pj ou mx ov pk ox na kz pl la nd lc pm ld ng lf pn lg nj pb bi translated">正规方程中的转置矩阵和逆矩阵</h1><p id="7ae2" class="pw-post-body-paragraph li lj jk lk b ll nm ku ln lo nn kx lq lr pc lt lu lv pd lx ly lz pe mb mc md im bi translated">正规方程方法通过明确地获取关于θJ的导数并将它们设置为零来最小化<em class="pt"> J </em>。我们可以不用梯度下降[ <a class="ae jg" href="https://www.geeksforgeeks.org/ml-normal-equation-in-linear-regression/" rel="noopener ugc nofollow" target="_blank"> 4 </a> ]直接求出<strong class="lk ju"> θ </strong>的值。</p><figure class="pp pq pr ps gt iv gh gi paragraph-image"><div class="gh gi qo"><img src="../Images/e4e72da145f5ce6abff8846c471e60fb.png" data-original-src="https://miro.medium.com/v2/resize:fit:1320/format:webp/0*bhROeoOBomoIGI9d.png"/></div><figcaption class="jc jd gj gh gi je jf bd b be z dk translated">图18:误差最小化。</figcaption></figure><p id="144e" class="pw-post-body-paragraph li lj jk lk b ll lm ku ln lo lp kx lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">实现通过从上表中取出数据，“表1”如图5所示。</p><figure class="pp pq pr ps gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi qp"><img src="../Images/d008db8dbb50415dea963abe925a88ff.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*YH5j5VzTwXJbcJQd.png"/></div></div><figcaption class="jc jd gj gh gi je jf bd b be z dk translated">图19:矩阵x下的特性和矩阵y下的价格。</figcaption></figure><p id="05dc" class="pw-post-body-paragraph li lj jk lk b ll lm ku ln lo lp kx lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">创建特征x和目标y的矩阵:</p><pre class="pp pq pr ps gt qq qr qs qt aw qu bi"><span id="4dd6" class="mt mu jk qr b gy qv qw l qx qy">import numpy as np Features<br/>x = np.array([[2, 1834, 1],[3, 1534, 2],[2, 962, 3]])# Target or Price<br/>y = [8500, 9600, 258800]</span></pre><p id="ff6a" class="pw-post-body-paragraph li lj jk lk b ll lm ku ln lo lp kx lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">矩阵x的转置:</p><pre class="pp pq pr ps gt qq qr qs qt aw qu bi"><span id="af0d" class="mt mu jk qr b gy qv qw l qx qy"># Transpose of x<br/>transpose_x = x.transpose()</span><span id="2b5b" class="mt mu jk qr b gy qz qw l qx qy">transpose_x</span></pre><figure class="pp pq pr ps gt iv gh gi paragraph-image"><div class="gh gi ra"><img src="../Images/f419915f5769185fb03ecffca0f48235.png" data-original-src="https://miro.medium.com/v2/resize:fit:1124/format:webp/0*ufv0mBG81n_FLqg4.png"/></div><figcaption class="jc jd gj gh gi je jf bd b be z dk translated">图20:特性x的转置。</figcaption></figure><p id="c525" class="pw-post-body-paragraph li lj jk lk b ll lm ku ln lo lp kx lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">转置矩阵与原始矩阵x的乘法:</p><pre class="pp pq pr ps gt qq qr qs qt aw qu bi"><span id="52fe" class="mt mu jk qr b gy qv qw l qx qy">multi_transpose_x_to_x = np.dot(transpose_x, x)multi_transpose_x_to_x</span></pre><figure class="pp pq pr ps gt iv gh gi paragraph-image"><div class="gh gi rb"><img src="../Images/afa83749afbf4660ff5669ad7736e6cf.png" data-original-src="https://miro.medium.com/v2/resize:fit:888/format:webp/0*Uy6pPY4DJzhSgv8S.png"/></div><figcaption class="jc jd gj gh gi je jf bd b be z dk translated">图21:转置矩阵与原始矩阵相乘。</figcaption></figure><p id="48d9" class="pw-post-body-paragraph li lj jk lk b ll lm ku ln lo lp kx lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">转置矩阵与原始矩阵相乘的逆</p><pre class="pp pq pr ps gt qq qr qs qt aw qu bi"><span id="8af5" class="mt mu jk qr b gy qv qw l qx qy">inverse_of_multi_transpose_x_to_x = np.linalg.inv(multi_transpose_x_to_x)inverse_of_multi_transpose_x_to_x</span></pre><figure class="pp pq pr ps gt iv gh gi paragraph-image"><div class="gh gi rc"><img src="../Images/f5267bf8903faffbdf5750c1507914ff.png" data-original-src="https://miro.medium.com/v2/resize:fit:1194/format:webp/0*9FjfdtTSrl8lt3P3.png"/></div><figcaption class="jc jd gj gh gi je jf bd b be z dk translated">图22:逆矩阵。</figcaption></figure><p id="ab1f" class="pw-post-body-paragraph li lj jk lk b ll lm ku ln lo lp kx lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">转置的x与y相乘:</p><pre class="pp pq pr ps gt qq qr qs qt aw qu bi"><span id="2464" class="mt mu jk qr b gy qv qw l qx qy">multiplication_transposed_x_y = np.dot(transpose_x, y)multiplication_transposed_x_y</span></pre><figure class="pp pq pr ps gt iv gh gi paragraph-image"><div class="gh gi rd"><img src="../Images/c5e38ab2b580ce1ea3f980cbdf6ba602.png" data-original-src="https://miro.medium.com/v2/resize:fit:852/format:webp/0*boiA06t0mi7HJzfi.png"/></div><figcaption class="jc jd gj gh gi je jf bd b be z dk translated">图23:转置的x与y相乘。</figcaption></figure><p id="3ea3" class="pw-post-body-paragraph li lj jk lk b ll lm ku ln lo lp kx lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">θ值的计算:</p><pre class="pp pq pr ps gt qq qr qs qt aw qu bi"><span id="fdba" class="mt mu jk qr b gy qv qw l qx qy">theta = np.dot(inverse_of_multi_transpose_x_to_x, multiplication_transposed_x_y)theta</span></pre><figure class="pp pq pr ps gt iv gh gi paragraph-image"><div class="gh gi re"><img src="../Images/6107f5ec8f96a78ae7f1b8e8649bcb0e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1188/format:webp/0*be1XAbz2fOwiGc9G.png"/></div><figcaption class="jc jd gj gh gi je jf bd b be z dk translated">图24:θ。</figcaption></figure><h1 id="555f" class="or mu jk bd jh os pj ou mx ov pk ox na kz pl la nd lc pm ld ng lf pn lg nj pb bi translated">线性方程</h1><p id="c5b4" class="pw-post-body-paragraph li lj jk lk b ll nm ku ln lo nn kx lq lr pc lt lu lv pd lx ly lz pe mb mc md im bi translated">线性方程是线性代数的核心部分，许多问题都是通过它来表述和解决的。这是一个直线方程。</p><p id="22cc" class="pw-post-body-paragraph li lj jk lk b ll lm ku ln lo lp kx lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">我们将线性方程表示在图24中:</p><figure class="pp pq pr ps gt iv gh gi paragraph-image"><div class="gh gi rf"><img src="../Images/5594fcdf055aa63a755ddb4466c9ac85.png" data-original-src="https://miro.medium.com/v2/resize:fit:1308/format:webp/0*_Oses4gsL0xZLdbp.png"/></div><figcaption class="jc jd gj gh gi je jf bd b be z dk translated">图25:线性方程。</figcaption></figure><figure class="pp pq pr ps gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi rg"><img src="../Images/86488fb1fd06aa038d86088279a5c2a6.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*--D11UETZtaq0Otj.png"/></div></div><figcaption class="jc jd gj gh gi je jf bd b be z dk translated">图26:展示y = 4x + 5的线性方程的图表</figcaption></figure><p id="222a" class="pw-post-body-paragraph li lj jk lk b ll lm ku ln lo lp kx lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">例子:<em class="pt"> x = 2 </em></p><figure class="pp pq pr ps gt iv gh gi paragraph-image"><div class="gh gi rh"><img src="../Images/32b0546d0b2c356596577fbf81d93d43.png" data-original-src="https://miro.medium.com/v2/resize:fit:1102/format:webp/0*zNVWh8CdIhLOOefm.png"/></div><figcaption class="jc jd gj gh gi je jf bd b be z dk translated">图27:y对上述线性方程的导数。</figcaption></figure><h2 id="1c38" class="mt mu jk bd jh mv mw dn mx my mz dp na lr nb nc nd lv ne nf ng lz nh ni nj jq bi translated">线性回归中的线性方程</h2><p id="780f" class="pw-post-body-paragraph li lj jk lk b ll nm ku ln lo nn kx lq lr pc lt lu lv pd lx ly lz pe mb mc md im bi translated">回归是给出直线方程的过程。它试图用一组特定的数据找到一条最佳拟合线。直线方程基于线性方程:</p><blockquote class="qh qi qj"><p id="a9f9" class="li lj pt lk b ll lm ku ln lo lp kx lq qk ls lt lu ql lw lx ly qm ma mb mc md im bi translated"><em class="jk"> Y = bX + a </em></p></blockquote><p id="2a17" class="pw-post-body-paragraph li lj jk lk b ll lm ku ln lo lp kx lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">在哪里，</p><p id="feeb" class="pw-post-body-paragraph li lj jk lk b ll lm ku ln lo lp kx lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated"><strong class="lk ju"> a </strong> =它是一个<em class="pt"> Y轴截距</em>，决定了直线与Y轴的交叉点。</p><p id="be54" class="pw-post-body-paragraph li lj jk lk b ll lm ku ln lo lp kx lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated"><strong class="lk ju"> b </strong> =是一个<em class="pt">斜率</em>，决定了线条倾斜的方向和程度。</p><p id="7243" class="pw-post-body-paragraph li lj jk lk b ll lm ku ln lo lp kx lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated"><strong class="lk ju">实施</strong></p><p id="de3c" class="pw-post-body-paragraph li lj jk lk b ll lm ku ln lo lp kx lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">预测房子的价格，变量是平方英尺和价格。</p><p id="912e" class="pw-post-body-paragraph li lj jk lk b ll lm ku ln lo lp kx lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">读取房价数据:</p><pre class="pp pq pr ps gt qq qr qs qt aw qu bi"><span id="5871" class="mt mu jk qr b gy qv qw l qx qy">import pandas as pddf = pd.read_csv('house_price.csv')df.head()</span></pre><figure class="pp pq pr ps gt iv gh gi paragraph-image"><div class="gh gi ri"><img src="../Images/8670c9a704a5cf13e9ab21fe2753852b.png" data-original-src="https://miro.medium.com/v2/resize:fit:540/format:webp/0*VMr1PVUPR4T4OkO-.png"/></div><figcaption class="jc jd gj gh gi je jf bd b be z dk translated">图28:房价表。</figcaption></figure><p id="b328" class="pw-post-body-paragraph li lj jk lk b ll lm ku ln lo lp kx lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">计算平均值:</p><pre class="pp pq pr ps gt qq qr qs qt aw qu bi"><span id="920e" class="mt mu jk qr b gy qv qw l qx qy">def get_mean(value):<br/>    total = sum(value)<br/>    length = len(value)<br/>    mean = total/length<br/>    return mean</span></pre><p id="8290" class="pw-post-body-paragraph li lj jk lk b ll lm ku ln lo lp kx lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">计算差异:</p><pre class="pp pq pr ps gt qq qr qs qt aw qu bi"><span id="1ec7" class="mt mu jk qr b gy qv qw l qx qy">def get_variance(value):<br/>    mean = get_mean(value)<br/>    mean_difference_square = [pow((item - mean), 2) for item in value]<br/>    variance = sum(mean_difference_square)/float(len(value)-1)<br/>    return variance</span></pre><p id="9135" class="pw-post-body-paragraph li lj jk lk b ll lm ku ln lo lp kx lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">计算协方差:</p><pre class="pp pq pr ps gt qq qr qs qt aw qu bi"><span id="93ca" class="mt mu jk qr b gy qv qw l qx qy">def get_covariance(value1, value2):<br/>    value1_mean = get_mean(value1)<br/>    value2_mean = get_mean(value2)<br/>    values_size = len(value1)<br/>    covariance = 0.0<br/>    for i in range(0, values_size):<br/>        covariance += (value1[i] - value1_mean) * (value2[i] - value2_mean)<br/>    return covariance / float(values_size - 1)</span></pre><p id="97bc" class="pw-post-body-paragraph li lj jk lk b ll lm ku ln lo lp kx lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">线性回归实现:</p><pre class="pp pq pr ps gt qq qr qs qt aw qu bi"><span id="e337" class="mt mu jk qr b gy qv qw l qx qy">def linear_regression(df):<br/>    X = df['square_feet']<br/>    Y = df['price']<br/>    m = len(X)    square_feet_mean = get_mean(X)<br/>    price_mean = get_mean(Y)<br/>    <br/>    #variance of X<br/>    square_feet_variance = get_variance(X)<br/>    price_variance = get_variance(Y)<br/>    <br/>    covariance_of_price_and_square_feet = get_covariance(X, Y)<br/>    w1 = covariance_of_price_and_square_feet        float(square_feet_variance)    w0 = price_mean - w1 * square_feet_mean<br/>    <br/>    # prediction --&gt; Linear Equation<br/>    prediction = w0 + w1 * X<br/>    <br/>    df['price (prediction)'] = prediction<br/>    return df['price (prediction)']</span></pre><p id="0445" class="pw-post-body-paragraph li lj jk lk b ll lm ku ln lo lp kx lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">调用'<em class="pt">线性_回归</em>'方法:</p><pre class="pp pq pr ps gt qq qr qs qt aw qu bi"><span id="1ff8" class="mt mu jk qr b gy qv qw l qx qy">linear_regression(df)</span></pre><figure class="pp pq pr ps gt iv gh gi paragraph-image"><div class="gh gi rj"><img src="../Images/44fbb481862d23ad9447a3540c54fd82.png" data-original-src="https://miro.medium.com/v2/resize:fit:1036/format:webp/0*OHNtcHAg9ZFg6F7C.png"/></div><figcaption class="jc jd gj gh gi je jf bd b be z dk translated">图29:预测价格。</figcaption></figure><p id="f842" class="pw-post-body-paragraph li lj jk lk b ll lm ku ln lo lp kx lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">“线性回归”方法中使用的线性方程:</p><figure class="pp pq pr ps gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi rk"><img src="../Images/8029a0e12f822a2dcf3acaafd808f1a1.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*UFGzKHDfaR5EKtmh.png"/></div></div><figcaption class="jc jd gj gh gi je jf bd b be z dk translated">图30:线性回归的线性方程。</figcaption></figure><h1 id="94b3" class="or mu jk bd jh os pj ou mx ov pk ox na kz pl la nd lc pm ld ng lf pn lg nj pb bi translated">向量范数</h1><p id="2e87" class="pw-post-body-paragraph li lj jk lk b ll nm ku ln lo nn kx lq lr pc lt lu lv pd lx ly lz pe mb mc md im bi translated">向量范数测量向量的大小[ <a class="ae jg" href="https://www.slideserve.com/jaimie/vector-norms" rel="noopener ugc nofollow" target="_blank"> 5 </a> ]。从根本上讲，给定变量<em class="pt"> x </em>的大小可以用它的范数||x||来表示，范数表示两个变量x和y之间的距离，用||x-y||来表示。</p><p id="fdad" class="pw-post-body-paragraph li lj jk lk b ll lm ku ln lo lp kx lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">向量范数的一般方程:</p><figure class="pp pq pr ps gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi rl"><img src="../Images/9ccc40e7d95d0a6593e33a5497ad4a11.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*5qXKJUzIKFPqjkci.png"/></div></div><figcaption class="jc jd gj gh gi je jf bd b be z dk translated">图31:向量范数方程||x||。</figcaption></figure><p id="4546" class="pw-post-body-paragraph li lj jk lk b ll lm ku ln lo lp kx lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">这些是p-范数的一般类别:</p><ul class=""><li id="445b" class="nk nl jk lk b ll lm lo lp lr pf lv pg lz ph md pi ns nt nu bi translated">L1标准或曼哈顿标准。</li><li id="c95e" class="nk nl jk lk b ll nv lo nw lr nx lv ny lz nz md pi ns nt nu bi translated">L2范数或欧几里德范数。</li></ul><p id="73cb" class="pw-post-body-paragraph li lj jk lk b ll lm ku ln lo lp kx lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">L1和L2规范用于正则化。</p><h1 id="dda9" class="or mu jk bd jh os pj ou mx ov pk ox na kz pl la nd lc pm ld ng lf pn lg nj pb bi translated">L1标准还是曼哈顿标准</h1><p id="cf1d" class="pw-post-body-paragraph li lj jk lk b ll nm ku ln lo nn kx lq lr pc lt lu lv pd lx ly lz pe mb mc md im bi translated">对于x ∈ <strong class="lk ju"> R^ </strong> n，定义了<strong class="lk ju"> R </strong> ^ <em class="pt"> n </em>上的L1范数，如图31所示:</p><figure class="pp pq pr ps gt iv gh gi paragraph-image"><div class="gh gi rm"><img src="../Images/b81531e869c35b6ef140c4fd631d6691.png" data-original-src="https://miro.medium.com/v2/resize:fit:1218/format:webp/0*i3qrnFsihP_hMSpU.png"/></div><figcaption class="jc jd gj gh gi je jf bd b be z dk translated">图32: L1范数或曼哈顿范数方程。</figcaption></figure><figure class="pp pq pr ps gt iv gh gi paragraph-image"><div class="gh gi rn"><img src="../Images/d66a0ccfef3e6444eaa8ccaad408cdbd.png" data-original-src="https://miro.medium.com/v2/resize:fit:572/format:webp/0*thRJFYxu9m73ntcs.png"/></div><figcaption class="jc jd gj gh gi je jf bd b be z dk translated">图33: L1标准表示法。</figcaption></figure><p id="a3de" class="pw-post-body-paragraph li lj jk lk b ll lm ku ln lo lp kx lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">如图32所示，红线代表L1范数方程的向量集。</p><h1 id="11bc" class="or mu jk bd jh os pj ou mx ov pk ox na kz pl la nd lc pm ld ng lf pn lg nj pb bi translated">L2范数或欧几里德范数</h1><p id="f7ac" class="pw-post-body-paragraph li lj jk lk b ll nm ku ln lo nn kx lq lr pc lt lu lv pd lx ly lz pe mb mc md im bi translated">x∈<strong class="lk ju">r</strong>t28】^n的L2范数定义为:</p><figure class="pp pq pr ps gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi ro"><img src="../Images/63ddcef3fdde7caf457d360eae39a564.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*Q3hsfP9d5wVd7_v4.png"/></div></div><figcaption class="jc jd gj gh gi je jf bd b be z dk translated">图34: L2范数或欧几里德范数方程。</figcaption></figure><figure class="pp pq pr ps gt iv gh gi paragraph-image"><div class="gh gi rp"><img src="../Images/6c7ef034b1dea5b44cf708c30a4f5ab3.png" data-original-src="https://miro.medium.com/v2/resize:fit:650/format:webp/0*nNh3YXjtVyJpN8fw.png"/></div><figcaption class="jc jd gj gh gi je jf bd b be z dk translated">图35: L2标准表示法。</figcaption></figure><p id="a742" class="pw-post-body-paragraph li lj jk lk b ll lm ku ln lo lp kx lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">如图34所示，红线代表L2范数方程的向量集。</p><h1 id="41da" class="or mu jk bd jh os pj ou mx ov pk ox na kz pl la nd lc pm ld ng lf pn lg nj pb bi translated">机器学习中的正则化</h1><p id="fe26" class="pw-post-body-paragraph li lj jk lk b ll nm ku ln lo nn kx lq lr pc lt lu lv pd lx ly lz pe mb mc md im bi translated">正则化是修改损失函数以惩罚学习权重的特定值的过程。正规化有助于我们避免过度拟合。</p><p id="bbfb" class="pw-post-body-paragraph li lj jk lk b ll lm ku ln lo lp kx lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">对于以下操作，它是机器学习中的一个优秀补充:</p><ul class=""><li id="9f9b" class="nk nl jk lk b ll lm lo lp lr pf lv pg lz ph md pi ns nt nu bi translated">来处理共线性。</li><li id="1c02" class="nk nl jk lk b ll nv lo nw lr nx lv ny lz nz md pi ns nt nu bi translated">从数据中滤除噪声。</li><li id="0ba4" class="nk nl jk lk b ll nv lo nw lr nx lv ny lz nz md pi ns nt nu bi translated">以防止过度拟合。</li><li id="dbb0" class="nk nl jk lk b ll nv lo nw lr nx lv ny lz nz md pi ns nt nu bi translated">以获得良好的性能。</li></ul><p id="e98c" class="pw-post-body-paragraph li lj jk lk b ll lm ku ln lo lp kx lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">这些是标准的正则化技术:</p><ul class=""><li id="3d6b" class="nk nl jk lk b ll lm lo lp lr pf lv pg lz ph md pi ns nt nu bi translated">L1正则化</li><li id="0127" class="nk nl jk lk b ll nv lo nw lr nx lv ny lz nz md pi ns nt nu bi translated">L2正则化(岭)</li></ul><p id="ccb3" class="pw-post-body-paragraph li lj jk lk b ll lm ku ln lo lp kx lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">正则化是规范的应用。</p><h2 id="564d" class="mt mu jk bd jh mv mw dn mx my mz dp na lr nb nc nd lv ne nf ng lz nh ni nj jq bi translated">L1正则化</h2><p id="4dfc" class="pw-post-body-paragraph li lj jk lk b ll nm ku ln lo nn kx lq lr pc lt lu lv pd lx ly lz pe mb mc md im bi translated">套索是一种普遍的正规化技术。其公式如图35所示:</p><figure class="pp pq pr ps gt iv gh gi paragraph-image"><div class="gh gi rm"><img src="../Images/8212d40167a8742a0148293dc232ee6a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1218/format:webp/0*Kt0CYXSblA4puh1f.png"/></div><figcaption class="jc jd gj gh gi je jf bd b be z dk translated">图36: L1正则化方程。</figcaption></figure><h2 id="d6fd" class="mt mu jk bd jh mv mw dn mx my mz dp na lr nb nc nd lv ne nf ng lz nh ni nj jq bi translated">L2正则化(岭)</h2><p id="2d20" class="pw-post-body-paragraph li lj jk lk b ll nm ku ln lo nn kx lq lr pc lt lu lv pd lx ly lz pe mb mc md im bi translated">L2正则化方程(岭):</p><figure class="pp pq pr ps gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi rq"><img src="../Images/6f360c33ac89a71c162a088a47cc6de1.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*D7qVpc7KRmfQgjP3.png"/></div></div><figcaption class="jc jd gj gh gi je jf bd b be z dk translated">图37: L2正则化(山脊)。</figcaption></figure><p id="f104" class="pw-post-body-paragraph li lj jk lk b ll lm ku ln lo lp kx lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">其中，λ =通过调整惩罚项的权重来控制复杂度的权衡。</p><h1 id="c54b" class="or mu jk bd jh os pj ou mx ov pk ox na kz pl la nd lc pm ld ng lf pn lg nj pb bi translated">特征提取和特征选择</h1><p id="e06a" class="pw-post-body-paragraph li lj jk lk b ll nm ku ln lo nn kx lq lr pc lt lu lv pd lx ly lz pe mb mc md im bi translated">特征提取和特征选择的主要目的是选择一组最优的低维特征来提高分类效率。这些术语本质上是在处理维数灾难问题。在矩阵中执行特征选择和特征提取。</p><h2 id="6dc0" class="mt mu jk bd jh mv mw dn mx my mz dp na lr nb nc nd lv ne nf ng lz nh ni nj jq bi translated">特征抽出</h2><p id="32b4" class="pw-post-body-paragraph li lj jk lk b ll nm ku ln lo nn kx lq lr pc lt lu lv pd lx ly lz pe mb mc md im bi translated">在特征提取中，我们通过某种函数映射从现有特征中找到一组特征。</p><figure class="pp pq pr ps gt iv gh gi paragraph-image"><div class="gh gi rr"><img src="../Images/15161ffb9ca3c14f257dc66b53961e75.png" data-original-src="https://miro.medium.com/v2/resize:fit:826/format:webp/0*OYVIFjDoYhSRs_xi.png"/></div><figcaption class="jc jd gj gh gi je jf bd b be z dk translated">图38:特征提取。</figcaption></figure><h2 id="1376" class="mt mu jk bd jh mv mw dn mx my mz dp na lr nb nc nd lv ne nf ng lz nh ni nj jq bi translated">特征选择</h2><p id="ef0b" class="pw-post-body-paragraph li lj jk lk b ll nm ku ln lo nn kx lq lr pc lt lu lv pd lx ly lz pe mb mc md im bi translated">在特征选择中，选择原始特征的子集。</p><figure class="pp pq pr ps gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi rs"><img src="../Images/4fdbc24da972c3a487b5185d4356f7ff.png" data-original-src="https://miro.medium.com/v2/resize:fit:668/format:webp/0*HGEV5OwOKBc1x0eZ.png"/></div></div><figcaption class="jc jd gj gh gi je jf bd b be z dk translated">图39:特性选择。</figcaption></figure><p id="14f7" class="pw-post-body-paragraph li lj jk lk b ll lm ku ln lo lp kx lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">主要的特征提取方法有:</p><ul class=""><li id="1e63" class="nk nl jk lk b ll lm lo lp lr pf lv pg lz ph md pi ns nt nu bi translated">主成分分析</li><li id="0208" class="nk nl jk lk b ll nv lo nw lr nx lv ny lz nz md pi ns nt nu bi translated">线性判别分析(LDA)</li></ul><p id="72ac" class="pw-post-body-paragraph li lj jk lk b ll lm ku ln lo lp kx lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">PCA是一种关键的特征提取方法，了解协方差矩阵、特征值或特征向量的概念对于理解PCA的概念是至关重要的。</p><h1 id="953f" class="or mu jk bd jh os pj ou mx ov pk ox na kz pl la nd lc pm ld ng lf pn lg nj pb bi translated">协方差矩阵</h1><p id="adf8" class="pw-post-body-paragraph li lj jk lk b ll nm ku ln lo nn kx lq lr pc lt lu lv pd lx ly lz pe mb mc md im bi translated">协方差矩阵是PCA推导的组成部分。以下概念对于计算协方差矩阵非常重要:</p><ul class=""><li id="3c0a" class="nk nl jk lk b ll lm lo lp lr pf lv pg lz ph md pi ns nt nu bi translated">方差。</li><li id="f639" class="nk nl jk lk b ll nv lo nw lr nx lv ny lz nz md pi ns nt nu bi translated">协方差。</li></ul><h2 id="31ed" class="mt mu jk bd jh mv mw dn mx my mz dp na lr nb nc nd lv ne nf ng lz nh ni nj jq bi translated">差异</h2><figure class="pp pq pr ps gt iv gh gi paragraph-image"><div class="gh gi rt"><img src="../Images/dcb56cd5b65ed5343198a7e5c53d6ba0.png" data-original-src="https://miro.medium.com/v2/resize:fit:1026/format:webp/0*nRlqCDaeoiWU-EyK.png"/></div><figcaption class="jc jd gj gh gi je jf bd b be z dk translated">图40:方差方程。</figcaption></figure><p id="1d8c" class="pw-post-body-paragraph li lj jk lk b ll lm ku ln lo lp kx lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">或者</p><figure class="pp pq pr ps gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi ru"><img src="../Images/48f2584853ff080caf71d7f6bdafee10.png" data-original-src="https://miro.medium.com/v2/resize:fit:870/format:webp/0*_kXeC7dt5GKg0ht-.png"/></div></div><figcaption class="jc jd gj gh gi je jf bd b be z dk translated">图41:扩展形式的方差方程。</figcaption></figure><p id="4fbb" class="pw-post-body-paragraph li lj jk lk b ll lm ku ln lo lp kx lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">方差的局限性在于它不探究变量之间的关系。</p><h2 id="c289" class="mt mu jk bd jh mv mw dn mx my mz dp na lr nb nc nd lv ne nf ng lz nh ni nj jq bi translated">协方差</h2><p id="0376" class="pw-post-body-paragraph li lj jk lk b ll nm ku ln lo nn kx lq lr pc lt lu lv pd lx ly lz pe mb mc md im bi translated">协方差用于度量两个随机变量的联合可变性。</p><figure class="pp pq pr ps gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi rv"><img src="../Images/ba5c3a8f74a768efc696ef4f473196a6.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*lG8xms-bMGutp1mp.png"/></div></div><figcaption class="jc jd gj gh gi je jf bd b be z dk translated">图42:协方差方程。</figcaption></figure><h1 id="1ec0" class="or mu jk bd jh os pj ou mx ov pk ox na kz pl la nd lc pm ld ng lf pn lg nj pb bi translated">协方差矩阵</h1><p id="73f2" class="pw-post-body-paragraph li lj jk lk b ll nm ku ln lo nn kx lq lr pc lt lu lv pd lx ly lz pe mb mc md im bi translated">协方差矩阵是给出每对给定随机向量元素之间的协方差的平方矩阵。</p><figure class="pp pq pr ps gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi rw"><img src="../Images/6d6b290590646442e4ecf07596dfdcce.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*iXTQvPVsl9_iKxzp.png"/></div></div><figcaption class="jc jd gj gh gi je jf bd b be z dk translated">图43:协方差矩阵。</figcaption></figure><p id="dc19" class="pw-post-body-paragraph li lj jk lk b ll lm ku ln lo lp kx lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">协方差矩阵的等式:</p><figure class="pp pq pr ps gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi rx"><img src="../Images/0e3b0fe78d2195932302baa3ff1c943b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*rCitqDTsmrZY9VMW.png"/></div></div><figcaption class="jc jd gj gh gi je jf bd b be z dk translated">图44:协方差矩阵方程。</figcaption></figure><h1 id="bcd2" class="or mu jk bd jh os pj ou mx ov pk ox na kz pl la nd lc pm ld ng lf pn lg nj pb bi translated">特征值和特征向量</h1><p id="64df" class="pw-post-body-paragraph li lj jk lk b ll nm ku ln lo nn kx lq lr pc lt lu lv pd lx ly lz pe mb mc md im bi translated">特征值的定义:</p><blockquote class="qh qi qj"><p id="33c7" class="li lj pt lk b ll lm ku ln lo lp kx lq qk ls lt lu ql lw lx ly qm ma mb mc md im bi translated"><em class="jk">设m是一个n*n矩阵。如果在</em> <strong class="lk ju"> <em class="jk"> R </em> </strong> <em class="jk"> ^n中存在非零向量x，使得mx = λx. </em>，则标量λ称为m的特征值</p></blockquote><p id="87d8" class="pw-post-body-paragraph li lj jk lk b ll lm ku ln lo lp kx lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">对于特征向量:</p><blockquote class="qh qi qj"><p id="b9b2" class="li lj pt lk b ll lm ku ln lo lp kx lq qk ls lt lu ql lw lx ly qm ma mb mc md im bi translated"><em class="jk">向量x称为λ对应的特征向量。</em></p></blockquote><h2 id="7637" class="mt mu jk bd jh mv mw dn mx my mz dp na lr nb nc nd lv ne nf ng lz nh ni nj jq bi translated">特征值和特征向量的计算</h2><p id="1465" class="pw-post-body-paragraph li lj jk lk b ll nm ku ln lo nn kx lq lr pc lt lu lv pd lx ly lz pe mb mc md im bi translated">设m为<strong class="lk ju"> n*n </strong>矩阵，有特征值<strong class="lk ju"> <em class="pt"> λ </em> </strong> <em class="pt">和</em>对应的<em class="pt"> </em>特征向量x .所以，<strong class="lk ju"> mx = <em class="pt"> λx </em> </strong> <em class="pt">。</em>这个等式可以写成如下:</p><p id="7209" class="pw-post-body-paragraph li lj jk lk b ll lm ku ln lo lp kx lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated"><strong class="lk ju"> mx — λx <em class="pt"> = </em> 0 </strong></p><p id="2e13" class="pw-post-body-paragraph li lj jk lk b ll lm ku ln lo lp kx lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">所以，等式:</p><figure class="pp pq pr ps gt iv gh gi paragraph-image"><div class="gh gi ry"><img src="../Images/c08768e47374cab7912a1e5145c6ab4b.png" data-original-src="https://miro.medium.com/v2/resize:fit:950/format:webp/0*7c8d7__Yr8O8cJFg.png"/></div><figcaption class="jc jd gj gh gi je jf bd b be z dk translated">图45:求解λ的这个方程，我们得到了m的所有特征值。</figcaption></figure><p id="2294" class="pw-post-body-paragraph li lj jk lk b ll lm ku ln lo lp kx lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated"><strong class="lk ju">例子</strong>:</p><p id="34c1" class="pw-post-body-paragraph li lj jk lk b ll lm ku ln lo lp kx lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">计算给定矩阵<strong class="lk ju"> <em class="pt"> m </em> </strong>的特征值和特征向量:</p><figure class="pp pq pr ps gt iv gh gi paragraph-image"><div class="gh gi rz"><img src="../Images/a62a640d3f50e8c3f539ccce3e6f1433.png" data-original-src="https://miro.medium.com/v2/resize:fit:1126/format:webp/0*IdkICl8Wb9TLQI2R.png"/></div><figcaption class="jc jd gj gh gi je jf bd b be z dk translated">图46:矩阵m。</figcaption></figure><p id="468c" class="pw-post-body-paragraph li lj jk lk b ll lm ku ln lo lp kx lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">解决方案:</p><p id="ad1c" class="pw-post-body-paragraph li lj jk lk b ll lm ku ln lo lp kx lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">这里，矩阵的大小是2。所以:</p><figure class="pp pq pr ps gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi sa"><img src="../Images/eb38f450bcbc8ebbfb6fbc05fb0b99df.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*MLwNdgJ24OqO6idN.png"/></div></div><figcaption class="jc jd gj gh gi je jf bd b be z dk translated">图47:派生的第一步。</figcaption></figure><figure class="pp pq pr ps gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi sb"><img src="../Images/7a33f0061a265229b5d04d674008014b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*XmwWpfvgfvuVqwxL.png"/></div></div><figcaption class="jc jd gj gh gi je jf bd b be z dk translated">图48:派生的第二步。</figcaption></figure><figure class="pp pq pr ps gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi sc"><img src="../Images/075534e0e028a41c2438e301da6668ff.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*DBEkldkVPlnKLszH.png"/></div></div><figcaption class="jc jd gj gh gi je jf bd b be z dk translated">图49:派生的第三步。</figcaption></figure><figure class="pp pq pr ps gt iv gh gi paragraph-image"><div class="gh gi sd"><img src="../Images/cb09f913095c9fdeb8d7a546009abb1e.png" data-original-src="https://miro.medium.com/v2/resize:fit:802/format:webp/0*4tGF8qdMRz6mAlgW.png"/></div><figcaption class="jc jd gj gh gi je jf bd b be z dk translated">图50:派生的第四步。</figcaption></figure><figure class="pp pq pr ps gt iv gh gi paragraph-image"><div class="gh gi se"><img src="../Images/0d5ba07b3272e2819f44edd1ca120f3c.png" data-original-src="https://miro.medium.com/v2/resize:fit:996/format:webp/0*7XwkPrkOZx3EFIrd.png"/></div><figcaption class="jc jd gj gh gi je jf bd b be z dk translated">图51:衍生的第五步。</figcaption></figure><figure class="pp pq pr ps gt iv gh gi paragraph-image"><div class="gh gi sf"><img src="../Images/a9f012a3c315f900f2790de135a0ec42.png" data-original-src="https://miro.medium.com/v2/resize:fit:874/format:webp/0*-4ecG6Ux5hgHnT3l.png"/></div><figcaption class="jc jd gj gh gi je jf bd b be z dk translated">图52:推导的第六步。</figcaption></figure><p id="8a20" class="pw-post-body-paragraph li lj jk lk b ll lm ku ln lo lp kx lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">这里<strong class="lk ju"> m </strong>的特征值为<strong class="lk ju"> 2 </strong>和<strong class="lk ju"> -1 </strong>。</p><p id="9fcb" class="pw-post-body-paragraph li lj jk lk b ll lm ku ln lo lp kx lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">每个特征值有多个可用的特征向量。</p><h1 id="9c2e" class="or mu jk bd jh os pj ou mx ov pk ox na kz pl la nd lc pm ld ng lf pn lg nj pb bi translated">正交性</h1><p id="49db" class="pw-post-body-paragraph li lj jk lk b ll nm ku ln lo nn kx lq lr pc lt lu lv pd lx ly lz pe mb mc md im bi translated">如果两个向量v和w的点积为零，则称它们正交[ <a class="ae jg" href="http://people.math.harvard.edu/~knill/teaching/math19b_2011/handouts/math19b_2011.pdf" rel="noopener ugc nofollow" target="_blank"> 7 </a> ]。</p><blockquote class="qh qi qj"><p id="b1fa" class="li lj pt lk b ll lm ku ln lo lp kx lq qk ls lt lu ql lw lx ly qm ma mb mc md im bi translated"><strong class="lk ju"> <em class="jk"> v.w = 0 </em> </strong></p></blockquote><p id="0989" class="pw-post-body-paragraph li lj jk lk b ll lm ku ln lo lp kx lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">示例:</p><figure class="pp pq pr ps gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi sc"><img src="../Images/78331cb746f7590fb4977d4da576f5e2.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*lw7Mj5PR_6CIY9v5.png"/></div></div><figcaption class="jc jd gj gh gi je jf bd b be z dk translated">图53:正交性。</figcaption></figure><h1 id="4312" class="or mu jk bd jh os pj ou mx ov pk ox na kz pl la nd lc pm ld ng lf pn lg nj pb bi translated">标准正交集</h1><p id="fbab" class="pw-post-body-paragraph li lj jk lk b ll nm ku ln lo nn kx lq lr pc lt lu lv pd lx ly lz pe mb mc md im bi translated">如果集合中的所有向量都是相互正交的，并且所有向量的长度都是单位长度，那么这个集合称为正交集合[ <a class="ae jg" href="https://en.wikipedia.org/wiki/Orthonormality" rel="noopener ugc nofollow" target="_blank"> 8 </a> ]。构成一个基的标准正交集叫做标准正交基。</p><h1 id="b757" class="or mu jk bd jh os pj ou mx ov pk ox na kz pl la nd lc pm ld ng lf pn lg nj pb bi translated">跨度</h1><p id="c87f" class="pw-post-body-paragraph li lj jk lk b ll nm ku ln lo nn kx lq lr pc lt lu lv pd lx ly lz pe mb mc md im bi translated">设<strong class="lk ju"> V </strong>为向量空间，其元素为v <em class="pt"> 1 </em>，v <em class="pt"> 2 </em>，…..，v <em class="pt"> n </em> ∈ V。</p><p id="ce5a" class="pw-post-body-paragraph li lj jk lk b ll lm ku ln lo lp kx lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">这些元素的总和乘以代表图53所示等式的标量，所有线性组合的集合称为跨度。</p><figure class="pp pq pr ps gt iv gh gi paragraph-image"><div class="gh gi sg"><img src="../Images/e559ce30350db2aef13db467eac2a141.png" data-original-src="https://miro.medium.com/v2/resize:fit:1286/format:webp/0*A-Mg0840UlqUldkG.png"/></div><figcaption class="jc jd gj gh gi je jf bd b be z dk translated">图54:跨度方程。</figcaption></figure><p id="0650" class="pw-post-body-paragraph li lj jk lk b ll lm ku ln lo lp kx lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">示例:</p><figure class="pp pq pr ps gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi sh"><img src="../Images/82f931fdeb5962f66af82ccd058e67f4.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*K_O9JfpmT9YKcyKW.png"/></div></div><figcaption class="jc jd gj gh gi je jf bd b be z dk translated">图55:三个不同的向量。</figcaption></figure><p id="0bd6" class="pw-post-body-paragraph li lj jk lk b ll lm ku ln lo lp kx lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">因此:</p><blockquote class="qh qi qj"><p id="60dd" class="li lj pt lk b ll lm ku ln lo lp kx lq qk ls lt lu ql lw lx ly qm ma mb mc md im bi translated"><em class="jk"> Span (v1，v2，v3) = av1 + bv2 + cv3 </em></p></blockquote><figure class="pp pq pr ps gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi si"><img src="../Images/286838a38b2e6963ba1dc78e1cf5a3ed.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*RmEmwuMqGF2qP-qq.png"/></div></div><figcaption class="jc jd gj gh gi je jf bd b be z dk translated">图56:跨度方程的计算。</figcaption></figure><h1 id="f187" class="or mu jk bd jh os pj ou mx ov pk ox na kz pl la nd lc pm ld ng lf pn lg nj pb bi translated">基础</h1><p id="aba3" class="pw-post-body-paragraph li lj jk lk b ll nm ku ln lo nn kx lq lr pc lt lu lv pd lx ly lz pe mb mc md im bi translated">向量空间的基础是一系列向量，这些向量构成一个线性独立的集合，并且跨越空间[ <a class="ae jg" href="https://en.wikibooks.org/wiki/Linear_Algebra/Basis" rel="noopener ugc nofollow" target="_blank"> 9 </a>。</p><p id="eb76" class="pw-post-body-paragraph li lj jk lk b ll lm ku ln lo lp kx lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">示例:</p><p id="d7ba" class="pw-post-body-paragraph li lj jk lk b ll lm ku ln lo lp kx lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">下面的向量序列是一个基础:</p><figure class="pp pq pr ps gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi sj"><img src="../Images/58a149e8f5e90dd6130e67e07f54ff2d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*BCpsciQuTyV1T6Vs.png"/></div></div><figcaption class="jc jd gj gh gi je jf bd b be z dk translated">图57:基本表示。</figcaption></figure><p id="fe96" class="pw-post-body-paragraph li lj jk lk b ll lm ku ln lo lp kx lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">它是线性独立的，如下所示:</p><figure class="pp pq pr ps gt iv gh gi paragraph-image"><div class="gh gi sk"><img src="../Images/678808a51e3bbfdc4da02482080bf4a3.png" data-original-src="https://miro.medium.com/v2/resize:fit:1354/format:webp/0*aV-f2oErITnT-l_G.png"/></div><figcaption class="jc jd gj gh gi je jf bd b be z dk translated">图58:线性独立性。</figcaption></figure><figure class="pp pq pr ps gt iv gh gi paragraph-image"><div class="gh gi sf"><img src="../Images/3cc92f0973bd7df15a9f3aeb36528ce1.png" data-original-src="https://miro.medium.com/v2/resize:fit:874/format:webp/0*T5tlLM1md6dT7fGt.png"/></div><figcaption class="jc jd gj gh gi je jf bd b be z dk translated">图59:基本方程。</figcaption></figure><h1 id="7594" class="or mu jk bd jh os pj ou mx ov pk ox na kz pl la nd lc pm ld ng lf pn lg nj pb bi translated">主成分分析</h1><p id="b979" class="pw-post-body-paragraph li lj jk lk b ll nm ku ln lo nn kx lq lr pc lt lu lv pd lx ly lz pe mb mc md im bi translated">主成分分析致力于合理地处理尽可能多的数据知识。这是一种降维技术。它找到方差最大的方向，并用它们来投影数据以降低维数。</p><p id="8fc3" class="pw-post-body-paragraph li lj jk lk b ll lm ku ln lo lp kx lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">主成分分析的计算步骤:</p><p id="13e9" class="pw-post-body-paragraph li lj jk lk b ll lm ku ln lo lp kx lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">假设有一个值为x <em class="pt"> 1 </em>，x <em class="pt"> 2 </em>的<strong class="lk ju"> N*1 </strong>向量，…..，x <em class="pt"> m. </em></p><ul class=""><li id="8382" class="nk nl jk lk b ll lm lo lp lr pf lv pg lz ph md pi ns nt nu bi translated">计算样本平均值:</li></ul><figure class="pp pq pr ps gt iv gh gi paragraph-image"><div class="gh gi sl"><img src="../Images/69be01f71c78701f0d1e68278f7d44fe.png" data-original-src="https://miro.medium.com/v2/resize:fit:966/format:webp/0*YMPzQiOqQ_lBJYoA.png"/></div><figcaption class="jc jd gj gh gi je jf bd b be z dk translated">图60:样本均值方程。</figcaption></figure><ul class=""><li id="3f20" class="nk nl jk lk b ll lm lo lp lr pf lv pg lz ph md pi ns nt nu bi translated">用向量值减去样本平均值:</li></ul><figure class="pp pq pr ps gt iv gh gi paragraph-image"><div class="gh gi sm"><img src="../Images/d523981159ea9f602ec157e0a5136171.png" data-original-src="https://miro.medium.com/v2/resize:fit:682/format:webp/0*Y8VJf2-ikVzSjNJr.png"/></div><figcaption class="jc jd gj gh gi je jf bd b be z dk translated">图61:减去样本均值。</figcaption></figure><ul class=""><li id="cbdf" class="nk nl jk lk b ll lm lo lp lr pf lv pg lz ph md pi ns nt nu bi translated">计算样本协方差矩阵:</li></ul><figure class="pp pq pr ps gt iv gh gi paragraph-image"><div class="gh gi sn"><img src="../Images/ee7feea5c58820d6a42f72536e4988cd.png" data-original-src="https://miro.medium.com/v2/resize:fit:1300/format:webp/0*nibZ-9fwW207mnkJ.png"/></div><figcaption class="jc jd gj gh gi je jf bd b be z dk translated">图62:协方差矩阵的方程。</figcaption></figure><ul class=""><li id="0500" class="nk nl jk lk b ll lm lo lp lr pf lv pg lz ph md pi ns nt nu bi translated">计算协方差矩阵的特征值和特征向量</li></ul><figure class="pp pq pr ps gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi so"><img src="../Images/48f34f0826ba74dd6031f66f70b3b3e1.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*A1Ovnlmbl6JMXf6X.png"/></div></div><figcaption class="jc jd gj gh gi je jf bd b be z dk translated">图63:特征值和特征向量。</figcaption></figure><ul class=""><li id="45cb" class="nk nl jk lk b ll lm lo lp lr pf lv pg lz ph md pi ns nt nu bi translated"><strong class="lk ju">降维</strong>:仅用前k个特征向量近似x(k&lt;N)。</li></ul><h2 id="fd4c" class="mt mu jk bd jh mv mw dn mx my mz dp na lr nb nc nd lv ne nf ng lz nh ni nj jq bi translated">主成分分析的Python实现</h2><p id="9a26" class="pw-post-body-paragraph li lj jk lk b ll nm ku ln lo nn kx lq lr pc lt lu lv pd lx ly lz pe mb mc md im bi translated">Python实现PCA的主要目标是:</p><ul class=""><li id="24c5" class="nk nl jk lk b ll lm lo lp lr pf lv pg lz ph md pi ns nt nu bi translated">实现协方差矩阵。</li><li id="743e" class="nk nl jk lk b ll nv lo nw lr nx lv ny lz nz md pi ns nt nu bi translated">求特征值和特征向量。</li><li id="edf3" class="nk nl jk lk b ll nv lo nw lr nx lv ny lz nz md pi ns nt nu bi translated">从主成分分析中理解降维的概念。</li></ul><p id="aa38" class="pw-post-body-paragraph li lj jk lk b ll lm ku ln lo lp kx lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated"><strong class="lk ju">加载虹膜数据</strong></p><pre class="pp pq pr ps gt qq qr qs qt aw qu bi"><span id="c8c8" class="mt mu jk qr b gy qv qw l qx qy">import numpy as npimport pylab as plimport pandas as pdfrom sklearn import datasetsimport matplotlib.pyplot as pltfrom sklearn.preprocessing import StandardScalerload_iris = datasets.load_iris()iris_df = pd.DataFrame(load_iris.data, columns=[load_iris.feature_names])iris_df.head()</span></pre><figure class="pp pq pr ps gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi sp"><img src="../Images/2bfe9e8a3fab1e0cb76722443358d975.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*Q3Up4t6mDoCUPsxU.png"/></div></div><figcaption class="jc jd gj gh gi je jf bd b be z dk translated">图64: Iris数据集表格。</figcaption></figure><p id="d0ed" class="pw-post-body-paragraph li lj jk lk b ll lm ku ln lo lp kx lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated"><strong class="lk ju">标准化</strong></p><p id="e290" class="pw-post-body-paragraph li lj jk lk b ll lm ku ln lo lp kx lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">对数据进行标准化总是有好处的，这样可以使数据的所有要素保持相同的比例。</p><pre class="pp pq pr ps gt qq qr qs qt aw qu bi"><span id="194c" class="mt mu jk qr b gy qv qw l qx qy">standardized_x = StandardScaler().fit_transform(load_iris.data)standardized_x[:2]</span></pre><figure class="pp pq pr ps gt iv gh gi paragraph-image"><div class="gh gi sq"><img src="../Images/804a33394913bc7e8614cc3d0b3854a1.png" data-original-src="https://miro.medium.com/v2/resize:fit:1260/format:webp/0*U_Qfvyly5pYsKbRR.png"/></div><figcaption class="jc jd gj gh gi je jf bd b be z dk translated">图65:标准化数据集。</figcaption></figure><p id="b46a" class="pw-post-body-paragraph li lj jk lk b ll lm ku ln lo lp kx lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated"><strong class="lk ju">计算协方差矩阵</strong></p><pre class="pp pq pr ps gt qq qr qs qt aw qu bi"><span id="1126" class="mt mu jk qr b gy qv qw l qx qy">covariance_matrix_x = np.cov(standardized_x.T)covariance_matrix_x</span></pre><figure class="pp pq pr ps gt iv gh gi paragraph-image"><div class="gh gi sr"><img src="../Images/c9d4e44101494009899128823c36349a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1246/format:webp/0*5JbnH_i970X2NXs1.png"/></div><figcaption class="jc jd gj gh gi je jf bd b be z dk translated">图iris数据集的协方差矩阵。</figcaption></figure><p id="c9ee" class="pw-post-body-paragraph li lj jk lk b ll lm ku ln lo lp kx lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated"><strong class="lk ju">从协方差矩阵计算特征值和特征向量</strong></p><pre class="pp pq pr ps gt qq qr qs qt aw qu bi"><span id="47e9" class="mt mu jk qr b gy qv qw l qx qy">eigenvalues, eigenvectors = np.linalg.eig(covariance_matrix_x)</span><span id="87e7" class="mt mu jk qr b gy qz qw l qx qy">eigenvalues</span></pre><figure class="pp pq pr ps gt iv gh gi paragraph-image"><div class="gh gi ss"><img src="../Images/463d487a76c00c37e0ab6a7907d0cd5c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1098/format:webp/0*ff3cAGLClRIXfe3h.png"/></div><figcaption class="jc jd gj gh gi je jf bd b be z dk translated">图67:特征值阵列。</figcaption></figure><pre class="pp pq pr ps gt qq qr qs qt aw qu bi"><span id="132b" class="mt mu jk qr b gy qv qw l qx qy">eigenvectors</span></pre><figure class="pp pq pr ps gt iv gh gi paragraph-image"><div class="gh gi st"><img src="../Images/04a3bfe24cd9d6b1806db1a34b870fe3.png" data-original-src="https://miro.medium.com/v2/resize:fit:1266/format:webp/0*vI92PrONr7Gr0Jn6.png"/></div><figcaption class="jc jd gj gh gi je jf bd b be z dk translated">图68:特征向量数组。</figcaption></figure><p id="f3b4" class="pw-post-body-paragraph li lj jk lk b ll lm ku ln lo lp kx lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated"><strong class="lk ju">检查特征值的方差</strong></p><pre class="pp pq pr ps gt qq qr qs qt aw qu bi"><span id="1c54" class="mt mu jk qr b gy qv qw l qx qy">total_of_eigenvalues = sum(eigenvalues)varariance = [(i / total_of_eigenvalues)*100 for i in sorted(eigenvalues, reverse=True)]varariance</span></pre><figure class="pp pq pr ps gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi sh"><img src="../Images/58187c6d347d980cf050d6c1b2d7b188.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*E2ZsG5kucP0XOAzi.png"/></div></div><figcaption class="jc jd gj gh gi je jf bd b be z dk translated">图69:虹膜数据集特征值的方差。</figcaption></figure><p id="50a1" class="pw-post-body-paragraph li lj jk lk b ll lm ku ln lo lp kx lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">图68所示的值表示方差，分析如下:</p><ul class=""><li id="adac" class="nk nl jk lk b ll lm lo lp lr pf lv pg lz ph md pi ns nt nu bi translated">第一成分= 72.96%</li><li id="ed2d" class="nk nl jk lk b ll nv lo nw lr nx lv ny lz nz md pi ns nt nu bi translated">第二成分= 22.85%</li><li id="dd58" class="nk nl jk lk b ll nv lo nw lr nx lv ny lz nz md pi ns nt nu bi translated">第三部分= 3.5%</li><li id="c2ed" class="nk nl jk lk b ll nv lo nw lr nx lv ny lz nz md pi ns nt nu bi translated">第四成分= 0.5%</li></ul><p id="43fa" class="pw-post-body-paragraph li lj jk lk b ll lm ku ln lo lp kx lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">因此，<strong class="lk ju">第三</strong>和<strong class="lk ju">第四</strong>组件分别具有非常低的方差。这些都可以放下。因为这些组件不能增加任何价值。</p><p id="42b3" class="pw-post-body-paragraph li lj jk lk b ll lm ku ln lo lp kx lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated"><strong class="lk ju">仅取第一和第二组件并整形</strong></p><pre class="pp pq pr ps gt qq qr qs qt aw qu bi"><span id="673e" class="mt mu jk qr b gy qv qw l qx qy">eigenpairs = [(np.abs(eigenvalues[i]), eigenvectors[:,i]) for i in range(len(eigenvalues))]# Sorting from Higher values to lower valueeigenpairs.sort(key=lambda x: x[0], reverse=True)eigenpairs</span></pre><figure class="pp pq pr ps gt iv gh gi paragraph-image"><div class="gh gi su"><img src="../Images/34f950fdd03374d6a4a51989003590a1.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*PtwlDgYd5qRuknVV.png"/></div><figcaption class="jc jd gj gh gi je jf bd b be z dk translated">图70:特征对的结果。</figcaption></figure><p id="cdfa" class="pw-post-body-paragraph li lj jk lk b ll lm ku ln lo lp kx lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated"><strong class="lk ju">执行Eigenparis的矩阵称重</strong></p><pre class="pp pq pr ps gt qq qr qs qt aw qu bi"><span id="de90" class="mt mu jk qr b gy qv qw l qx qy">matrix_weighing = np.hstack((eigenpairs[0][1].reshape(4,1),eigenpairs[1][1].reshape(4,1)))matrix_weighing</span></pre><figure class="pp pq pr ps gt iv gh gi paragraph-image"><div class="gh gi sv"><img src="../Images/5d4ba8c6a77d9a7de2d2eb505c1423d4.png" data-original-src="https://miro.medium.com/v2/resize:fit:810/format:webp/0*iq9QJ-9X36ToZF0f.png"/></div><figcaption class="jc jd gj gh gi je jf bd b be z dk translated">图71:矩阵加权的结果。</figcaption></figure><p id="f4a4" class="pw-post-body-paragraph li lj jk lk b ll lm ku ln lo lp kx lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">将标准化矩阵乘以矩阵权重:</p><pre class="pp pq pr ps gt qq qr qs qt aw qu bi"><span id="8fdd" class="mt mu jk qr b gy qv qw l qx qy">Y = standardized_x.dot(matrix_weighing)Y</span></pre><figure class="pp pq pr ps gt iv gh gi paragraph-image"><div class="gh gi sw"><img src="../Images/97b57973694ee847cb8a954e8e4a7b82.png" data-original-src="https://miro.medium.com/v2/resize:fit:862/format:webp/0*X7w3s5f5dkeCzw-8.png"/></div><figcaption class="jc jd gj gh gi je jf bd b be z dk translated">图72:产品结果。</figcaption></figure><p id="82a6" class="pw-post-body-paragraph li lj jk lk b ll lm ku ln lo lp kx lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated"><strong class="lk ju">绘图</strong></p><pre class="pp pq pr ps gt qq qr qs qt aw qu bi"><span id="71ab" class="mt mu jk qr b gy qv qw l qx qy">plt.figure()target_names = load_iris.target_names<br/>y = load_iris.targetfor c, i, target_name in zip("rgb", [0, 1, 2], target_names):<br/>    plt.scatter(Y[y==i,0], Y[y==i,1], c=c, label=target_name)plt.xlabel('PCA 1')<br/>plt.ylabel('PCA 2')<br/>plt.legend()<br/>plt.title('PCA')<br/>plt.show()</span></pre><figure class="pp pq pr ps gt iv gh gi paragraph-image"><div class="gh gi sx"><img src="../Images/5df7e7bee18a9264c34402f57e29ceb1.png" data-original-src="https://miro.medium.com/v2/resize:fit:1100/format:webp/0*Pn5wiKWFDfCDZR42.png"/></div><figcaption class="jc jd gj gh gi je jf bd b be z dk translated">图73:第一个数据集的PCA 1和PCA 2的绘制结果。</figcaption></figure><h1 id="740e" class="or mu jk bd jh os pj ou mx ov pk ox na kz pl la nd lc pm ld ng lf pn lg nj pb bi translated">矩阵分解或矩阵分解</h1><p id="475d" class="pw-post-body-paragraph li lj jk lk b ll nm ku ln lo nn kx lq lr pc lt lu lv pd lx ly lz pe mb mc md im bi translated">矩阵分解或因式分解也是机器学习中使用的线性代数的重要组成部分。基本上，它是将矩阵分解成矩阵的乘积。</p><p id="424e" class="pw-post-body-paragraph li lj jk lk b ll lm ku ln lo lp kx lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">有几种矩阵分解技术，如LU分解、奇异值分解(SVD)等。</p><p id="549f" class="pw-post-body-paragraph li lj jk lk b ll lm ku ln lo lp kx lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated"><strong class="lk ju">奇异值分解</strong></p><p id="4662" class="pw-post-body-paragraph li lj jk lk b ll lm ku ln lo lp kx lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">这是一种降维技术。根据奇异值分解矩阵:</p><p id="fa58" class="pw-post-body-paragraph li lj jk lk b ll lm ku ln lo lp kx lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">设M是一个矩形矩阵，可以分解成三个矩阵的乘积——(1)正交矩阵(U)，(2)对角矩阵(S)，和(3)正交矩阵(V)的转置。</p><figure class="pp pq pr ps gt iv gh gi paragraph-image"><div class="gh gi sy"><img src="../Images/8961edd3f2cb97370c34786533a79581.png" data-original-src="https://miro.medium.com/v2/resize:fit:934/format:webp/0*FlujsMFf7Ro95YAA.png"/></div><figcaption class="jc jd gj gh gi je jf bd b be z dk translated">图74:矩阵的三个乘积。</figcaption></figure><h1 id="3904" class="or mu jk bd jh os pj ou mx ov pk ox na kz pl la nd lc pm ld ng lf pn lg nj pb bi translated">结论</h1><p id="40f3" class="pw-post-body-paragraph li lj jk lk b ll nm ku ln lo nn kx lq lr pc lt lu lv pd lx ly lz pe mb mc md im bi translated">机器学习和深度学习已经建立在数学概念的基础上。一个广阔的数学领域被用来建立算法和计算数据。</p><p id="07f6" class="pw-post-body-paragraph li lj jk lk b ll lm ku ln lo lp kx lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">线性代数是研究向量[ <a class="ae jg" href="https://math.libretexts.org/Bookshelves/Linear_Algebra" rel="noopener ugc nofollow" target="_blank"> 10 </a> ]以及操纵向量的若干规则。它是一个关键的基础设施，它涵盖了机器学习的许多领域，如线性回归、分类变量中的一键编码、用于降维的PCA(主成分分析)、用于推荐系统的矩阵分解。</p><p id="a4e2" class="pw-post-body-paragraph li lj jk lk b ll lm ku ln lo lp kx lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">深度学习完全基于线性代数和微积分。它也用于多种优化技术，如梯度下降、随机梯度下降等。</p><p id="a5b8" class="pw-post-body-paragraph li lj jk lk b ll lm ku ln lo lp kx lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">矩阵是线性代数的重要组成部分，我们用它来简洁地表示线性方程组、线性映射等。此外，向量是唯一的对象，可以加在一起并与标量相乘，从而产生另一个类似的对象。任何建议或反馈对于继续改进都至关重要。如果你有任何问题，请在评论中告诉我们。</p></div><div class="ab cl ok ol hx om" role="separator"><span class="on bw bk oo op oq"/><span class="on bw bk oo op oq"/><span class="on bw bk oo op"/></div><div class="im in io ip iq"><p id="8774" class="pw-post-body-paragraph li lj jk lk b ll lm ku ln lo lp kx lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated"><strong class="lk ju">免责声明:</strong>本文中表达的观点仅代表作者个人，不代表卡耐基梅隆大学或其他(直接或间接)与作者相关的公司的观点。这些文章并不打算成为最终产品，而是当前思想的反映，同时也是讨论和改进的催化剂。</p><p id="9f51" class="pw-post-body-paragraph li lj jk lk b ll lm ku ln lo lp kx lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">通过<a class="ae jg" href="https://towardsai.net/" rel="noopener ugc nofollow" target="_blank">向艾</a>发布</p><h1 id="3902" class="or mu jk bd jh os pj ou mx ov pk ox na kz pl la nd lc pm ld ng lf pn lg nj pb bi translated">资源:</h1><p id="b141" class="pw-post-body-paragraph li lj jk lk b ll nm ku ln lo nn kx lq lr pc lt lu lv pd lx ly lz pe mb mc md im bi translated"><a class="ae jg" href="https://colab.research.google.com/drive/1WhzsrEQ-JatDbaaJ81Wh8aYY9jqGWdsw?usp=sharing" rel="noopener ugc nofollow" target="_blank"> Google colab实现</a>。</p><p id="155c" class="pw-post-body-paragraph li lj jk lk b ll lm ku ln lo lp kx lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated"><a class="ae jg" href="https://github.com/towardsai/tutorials/tree/master/linear-algebra-for-ml-and-deep-learning" rel="noopener ugc nofollow" target="_blank"> Github库</a>。</p><p id="b564" class="pw-post-body-paragraph li lj jk lk b ll lm ku ln lo lp kx lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">线性代数，潜入深度学习，<a class="ae jg" href="https://mktg.best/llmqk" rel="noopener ugc nofollow" target="_blank">https://d2l.ai/chapter_preliminaries/linear-algebra.html</a></p><h1 id="8f6f" class="or mu jk bd jh os pj ou mx ov pk ox na kz pl la nd lc pm ld ng lf pn lg nj pb bi translated">参考</h1><p id="89a8" class="pw-post-body-paragraph li lj jk lk b ll nm ku ln lo nn kx lq lr pc lt lu lv pd lx ly lz pe mb mc md im bi translated">[1]线性代数，维基百科，<a class="ae jg" href="https://en.wikipedia.org/wiki/Linear_algebra" rel="noopener ugc nofollow" target="_blank">https://en.wikipedia.org/wiki/Linear_algebra</a></p><p id="144d" class="pw-post-body-paragraph li lj jk lk b ll lm ku ln lo lp kx lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">[2]欧几里得空间，维基百科，<a class="ae jg" href="https://en.wikipedia.org/wiki/Euclidean_space" rel="noopener ugc nofollow" target="_blank">https://en.wikipedia.org/wiki/Euclidean_space</a></p><p id="df74" class="pw-post-body-paragraph li lj jk lk b ll lm ku ln lo lp kx lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">[3]用于超度量搜索的高维Simplexes，Richard Connor，Lucia Vadicamo，Fausto Rabitti，ResearchGate，<a class="ae jg" href="https://www.researchgate.net/publication/318720793_High-Dimensional_Simplexes_for_Supermetric_Search" rel="noopener ugc nofollow" target="_blank">https://www . research gate . net/publication/318720793 _ High-Dimensional _ simple xes _ for _ super metric _ Search</a></p><p id="0280" class="pw-post-body-paragraph li lj jk lk b ll lm ku ln lo lp kx lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">[4] ML |线性回归中的正规方程，GeeksforGeeks，<a class="ae jg" href="https://www.geeksforgeeks.org/ml-normal-equation-in-linear-regression/" rel="noopener ugc nofollow" target="_blank">https://www . geeks forgeeks . org/ML-Normal-Equation-in-Linear-Regression/</a></p><p id="fd0b" class="pw-post-body-paragraph li lj jk lk b ll lm ku ln lo lp kx lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">[5]https://www.slideserve.com/jaimie/vector-norms<a class="ae jg" href="https://www.slideserve.com/jaimie/vector-norms" rel="noopener ugc nofollow" target="_blank">石溪大学计算机科学系CSE541的Roger Crawfis的矢量规范</a></p><p id="eb44" class="pw-post-body-paragraph li lj jk lk b ll lm ku ln lo lp kx lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">[6]方差估计模拟，莱斯大学在线统计书，<a class="ae jg" href="http://onlinestatbook.com/2/summarizing_distributions/variance_est.html" rel="noopener ugc nofollow" target="_blank">http://Online Stat Book . com/2/summaring _ distributions/Variance _ est . html</a></p><p id="9db9" class="pw-post-body-paragraph li lj jk lk b ll lm ku ln lo lp kx lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">[7]哈佛大学奥利弗·克尼尔第十七讲:正交性<a class="ae jg" href="http://people.math.harvard.edu/~knill/teaching/math19b_2011/handouts/math19b_2011.pdf" rel="noopener ugc nofollow" target="_blank">http://people . math . Harvard . edu/~ knill/teaching/math 19b _ 2011/讲义/math19b_2011.pdf </a></p><p id="a754" class="pw-post-body-paragraph li lj jk lk b ll lm ku ln lo lp kx lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">[8]标准正交，维基百科，<a class="ae jg" href="https://en.wikipedia.org/wiki/Orthonormality" rel="noopener ugc nofollow" target="_blank">https://en.wikipedia.org/wiki/Orthonormality</a></p><p id="c54f" class="pw-post-body-paragraph li lj jk lk b ll lm ku ln lo lp kx lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">[9]线性代数/基础，Wikibooks，<a class="ae jg" href="https://en.wikibooks.org/wiki/Linear_Algebra/Basis" rel="noopener ugc nofollow" target="_blank">https://en.wikibooks.org/wiki/Linear_Algebra/Basis</a></p><p id="fd44" class="pw-post-body-paragraph li lj jk lk b ll lm ku ln lo lp kx lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">[10]线性代数，LibreTexts，<a class="ae jg" href="https://math.libretexts.org/Bookshelves/Linear_Algebra" rel="noopener ugc nofollow" target="_blank">https://math.libretexts.org/Bookshelves/Linear_Algebra</a></p><p id="098f" class="pw-post-body-paragraph li lj jk lk b ll lm ku ln lo lp kx lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">[11]线性代数，潜入深度学习，阿斯顿·张，扎克·c·利普顿，，亚历克斯·j·斯莫拉，<a class="ae jg" href="https://mktg.best/llmqk" rel="noopener ugc nofollow" target="_blank"/></p></div></div>    
</body>
</html>