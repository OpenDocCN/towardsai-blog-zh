<html>
<head>
<title>Conciliating AI &amp; Privacy: Rules and Good Practices</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">调和人工智能与隐私:规则与良好实践</h1>
<blockquote>原文：<a href="https://pub.towardsai.net/conciliating-ai-privacy-rules-and-good-practices-7859541c4977?source=collection_archive---------3-----------------------#2020-12-19">https://pub.towardsai.net/conciliating-ai-privacy-rules-and-good-practices-7859541c4977?source=collection_archive---------3-----------------------#2020-12-19</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><figure class="io ip gp gr iq ir gh gi paragraph-image"><div class="ab gu cl is"><img src="../Images/1c181940fed3fe6d7ae654b3b190967b.png" data-original-src="https://miro.medium.com/v2/format:webp/1*UxYcjmCX24IGundnep-R1A.png"/></div><figcaption class="iv iw gj gh gi ix iy bd b be z dk translated">作者图片</figcaption></figure><h2 id="166a" class="iz ja jb bd b dl jc jd je jf jg jh dk ji translated" aria-label="kicker paragraph"><a class="ae ep" href="https://towardsai.net/p/category/privacy-and-security" rel="noopener ugc nofollow" target="_blank">隐私和安全</a></h2><div class=""/><div class=""><h2 id="b0ec" class="pw-subtitle-paragraph kh jk jb bd b ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky dk translated">如何在不侵犯客户隐私的情况下从数据中获取最大价值</h2></div><h2 id="381c" class="kz la jb bd lb lc ld dn le lf lg dp lh li lj lk ll lm ln lo lp lq lr ls lt jh bi translated">1.人工智能和个人数据:一场敏感的辩论</h2><p id="e711" class="pw-post-body-paragraph lu lv jb lw b lx ly kl lz ma mb ko mc li md me mf lm mg mh mi lq mj mk ml mm ij bi translated">按照严格的计算机科学定义，人工智能(AI)是指由计算机、机器人或其他机器呈现的任何类型的人类智能。普遍使用将这一定义扩展到计算机或机器模仿人类思维能力的能力——从经验和例子中学习，识别物体，理解和回答语言，做出决定——以及这些能力与其他能力的结合，以完成人类可以完成的功能，如问候酒店客户或驾驶汽车。</p><p id="79b5" class="pw-post-body-paragraph lu lv jb lw b lx mn kl lz ma mo ko mc li mp me mf lm mq mh mi lq mr mk ml mm ij bi translated">就其本身而言，私人数据的定义根据每种情况下适用的法律而有所不同，但我们可以将其概括地描述为一条关于个人或实体的信息，可以合理地排除在公众视野之外。<strong class="lw jl">例如，欧盟的通用数据保护条例(GDPR) </strong>定义[1]:</p><blockquote class="ms"><p id="bcc3" class="mt mu jb bd mv mw mx my mz na nb mm dk translated">“个人数据”是指与已识别或可识别的自然人(“数据主体”)直接或间接相关的任何信息</p></blockquote></div><div class="ab cl nc nd hu ne" role="separator"><span class="nf bw bk ng nh ni"/><span class="nf bw bk ng nh ni"/><span class="nf bw bk ng nh"/></div><div class="ij ik il im in"><p id="3b6b" class="pw-post-body-paragraph lu lv jb lw b lx mn kl lz ma mo ko mc li mp me mf lm mq mh mi lq mr mk ml mm ij bi translated">对人工智能的商业应用或学术研究的概述表明，<strong class="lw jl">随着这些模型和算法继续推进最先进的边界，他们消费任何可用数据的欲望以侵犯隐私利益的方式增长。</strong></p><p id="f087" class="pw-post-body-paragraph lu lv jb lw b lx mn kl lz ma mo ko mc li mp me mf lm mq mh mi lq mr mk ml mm ij bi translated">关于AI的争论和私人数据的使用往往凸显了这些所谓智能应用的局限性和缺点。隐性偏见、大规模收集和技术的快速发展使隐私法变得非常复杂，而且往往滞后。</p><p id="1b5f" class="pw-post-body-paragraph lu lv jb lw b lx mn kl lz ma mo ko mc li mp me mf lm mq mh mi lq mr mk ml mm ij bi translated">本文将讨论<strong class="lw jl">隐私保护新范式的挑战</strong>。然后，我们将重点关注<strong class="lw jl">可用于实现高效人工智能系统的工具</strong>，同时遵守《通用数据保护条例》规定的规则。</p></div><div class="ab cl nc nd hu ne" role="separator"><span class="nf bw bk ng nh ni"/><span class="nf bw bk ng nh ni"/><span class="nf bw bk ng nh"/></div><div class="ij ik il im in"><blockquote class="nj nk nl"><p id="8a33" class="lu lv nm lw b lx mn kl lz ma mo ko mc nn mp me mf no mq mh mi np mr mk ml mm ij bi translated"><a class="ae nq" href="https://datavalue-consulting.com/livre-blanc-migration-vers-le-big-data/" rel="noopener ugc nofollow" target="_blank"> <strong class="lw jl">下载我们的白皮书《成功的大数据迁移》</strong> </a></p></blockquote></div><div class="ab cl nc nd hu ne" role="separator"><span class="nf bw bk ng nh ni"/><span class="nf bw bk ng nh ni"/><span class="nf bw bk ng nh"/></div><div class="ij ik il im in"><h1 id="17f5" class="nr la jb bd lb ns nt nu le nv nw nx lh kq ny kr ll kt nz ku lp kw oa kx lt ob bi translated">2.人工智能系统中保护个人数据的四大支柱</h1><p id="7af9" class="pw-post-body-paragraph lu lv jb lw b lx ly kl lz ma mb ko mc li md me mf lm mg mh mi lq mj mk ml mm ij bi translated">因此，确保人工智能系统的隐私并监管消费者数据的使用，需要一种范式转变。这一新愿景以更全面的方式处理人工智能背景下的隐私和相关风险，采取旨在规范个人数据处理和识别违规案例的措施。</p><p id="616d" class="pw-post-body-paragraph lu lv jb lw b lx mn kl lz ma mo ko mc li mp me mf lm mq mh mi lq mr mk ml mm ij bi translated">许多组织、公司和一些立法者提供了不同的变体，但它们都围绕着4个支柱:</p><ul class=""><li id="c124" class="oc od jb lw b lx mn ma mo li oe lm of lq og mm oh oi oj ok bi translated"><strong class="lw jl">交代:</strong></li></ul><p id="a378" class="pw-post-body-paragraph lu lv jb lw b lx mn kl lz ma mo ko mc li mp me mf lm mq mh mi lq mr mk ml mm ij bi translated">理解数据是如何被用来得出一个特定的决定的，以及哪些特征在结论中扮演了重要的角色，这并不是一件容易的事情。这需要:</p><ol class=""><li id="c4b4" class="oc od jb lw b lx mn ma mo li oe lm of lq og mm ol oi oj ok bi translated">识别AI所做的决定</li><li id="2019" class="oc od jb lw b lx om ma on li oo lm op lq oq mm ol oi oj ok bi translated">对具体决策的分析</li><li id="bccd" class="oc od jb lw b lx om ma on li oo lm op lq oq mm ol oi oj ok bi translated">建立个人寻求解释的途径</li></ol><p id="fbd7" class="pw-post-body-paragraph lu lv jb lw b lx mn kl lz ma mo ko mc li mp me mf lm mq mh mi lq mr mk ml mm ij bi translated"><strong class="lw jl">对机器学习算法进行逆向工程可能很困难，如果不是不可能的话</strong>在深度学习算法的情况下，这种困难甚至会增加。</p><blockquote class="ms"><p id="1245" class="mt mu jb bd mv mw mx my mz na nb mm dk translated">《GDPR》要求，对于任何“对其产生法律效力或对其产生类似重大影响”的自动决定(信贷、保险等)。数据主体可以求助于能够审查决策并解释其逻辑的人[2]。</p></blockquote><p id="7f18" class="pw-post-body-paragraph lu lv jb lw b lx or kl lz ma os ko mc li ot me mf lm ou mh mi lq ov mk ml mm ij bi translated">将人的因素纳入决策循环中，除了会带来巨大的监管负担之外，还会在开发过程中增加一个额外的步骤。</p><ul class=""><li id="5c36" class="oc od jb lw b lx mn ma mo li oe lm of lq og mm oh oi oj ok bi translated"><strong class="lw jl">透明度:</strong></li></ul><p id="b512" class="pw-post-body-paragraph lu lv jb lw b lx mn kl lz ma mo ko mc li mp me mf lm mq mh mi lq mr mk ml mm ij bi translated"><strong class="lw jl">明确回答“公司如何处理您的数据？”极大地促进了公司的责任感，消除了用户和/或合作伙伴的顾虑。</strong></p><p id="f449" class="pw-post-body-paragraph lu lv jb lw b lx mn kl lz ma mo ko mc li mp me mf lm mq mh mi lq mr mk ml mm ij bi translated">“隐私政策”就是一个具体的例子。对于大多数消费者来说，这些传统上冗长且不必要的文档可以由声明代替:</p><ol class=""><li id="c18e" class="oc od jb lw b lx mn ma mo li oe lm of lq og mm ol oi oj ok bi translated">提供了收集、使用和保护数据的性质和方式的完整描述，</li><li id="2ccf" class="oc od jb lw b lx om ma on li oo lm op lq oq mm ol oi oj ok bi translated">它确定了人工智能个人数据的重要用例，以及产品中实施的各种决策算法。</li></ol><ul class=""><li id="1032" class="oc od jb lw b lx mn ma mo li oe lm of lq og mm oh oi oj ok bi translated"><strong class="lw jl">风险评估:</strong></li></ul><p id="4243" class="pw-post-body-paragraph lu lv jb lw b lx mn kl lz ma mo ko mc li mp me mf lm mq mh mi lq mr mk ml mm ij bi translated">这是GDPR对新技术或高风险数据使用的另一个要求。在这种情况下，它是关于<strong class="lw jl">提前评估和减轻保密风险，</strong>包括人工智能系统和提供给该系统的数据的设计中的潜在偏差，以及对用户的潜在影响。例如，Twitter在去年九月引起了争议，因为用户证明它的照片裁剪算法带有“种族”偏见[3]。</p><ul class=""><li id="6d54" class="oc od jb lw b lx mn ma mo li oe lm of lq og mm oh oi oj ok bi translated"><strong class="lw jl">审计:</strong></li></ul><p id="954f" class="pw-post-body-paragraph lu lv jb lw b lx mn kl lz ma mo ko mc li mp me mf lm mq mh mi lq mr mk ml mm ij bi translated">无论是内部(自我审核)还是外部(由第三方组织进行)，<a class="ae nq" href="https://datavalue-consulting.com/pilotage-transformation/consulting-it/" rel="noopener ugc nofollow" target="_blank"> <strong class="lw jl">审核对于监控和符合要求仍然是必要的。</strong> </a> <strong class="lw jl"> </strong>由于审计本质上是回顾性的，一个好的策略是将审计结果与风险评估结合起来进行人工智能决策，这是前瞻性的。这可以更好地告知该公司在人工智能和隐私方面的立场，尽管——正如可解释性的情况一样——审计机器学习算法很困难，仍在开发中。</p><h1 id="abf3" class="nr la jb bd lb ns ow nu le nv ox nx lh kq oy kr ll kt oz ku lp kw pa kx lt ob bi translated">3.人工智能与隐私:主要技术趋势</h1><p id="43a0" class="pw-post-body-paragraph lu lv jb lw b lx ly kl lz ma mb ko mc li md me mf lm mg mh mi lq mj mk ml mm ij bi translated">在保持AI系统性能的同时满足所有之前列出的约束似乎很困难，如果不是不可能的话，但有几种解决方案可供探索，特别是联邦学习和差分隐私。</p><p id="9140" class="pw-post-body-paragraph lu lv jb lw b lx mn kl lz ma mo ko mc li mp me mf lm mq mh mi lq mr mk ml mm ij bi translated"><strong class="lw jl">联合学习是一种创新的方法</strong>以分散的方式训练机器学习模型。培训过程与内部存储数据的需求之间的分离使公司能够释放更多的能力，同时降低可能的费用和风险。</p><p id="5e4e" class="pw-post-body-paragraph lu lv jb lw b lx mn kl lz ma mo ko mc li mp me mf lm mq mh mi lq mr mk ml mm ij bi translated">这种学习方法超越了在用户设备上进行预测的本地模型的使用，走向了作为该架构成员的设备之间的真正协作:</p><ul class=""><li id="98d4" class="oc od jb lw b lx mn ma mo li oe lm of lq og mm oh oi oj ok bi translated">首先在所有设备上部署相同的机器学习模型，</li><li id="f06b" class="oc od jb lw b lx om ma on li oo lm op lq oq mm oh oi oj ok bi translated">然后，这些设备用它们的本地数据完成训练阶段，并本地更新模型的权重和超参数，</li><li id="ddba" class="oc od jb lw b lx om ma on li oo lm op lq oq mm oh oi oj ok bi translated">然后，他们使用加密通信将这些更新分别发送到云或中央服务器，</li><li id="c285" class="oc od jb lw b lx om ma on li oo lm op lq oq mm oh oi oj ok bi translated">然后对这些更新进行汇总和平均，以获得共享模型的平均权重和超参数。</li></ul><p id="5a44" class="pw-post-body-paragraph lu lv jb lw b lx mn kl lz ma mo ko mc li mp me mf lm mq mh mi lq mr mk ml mm ij bi translated">最重要的是，所有训练数据都保留在用户的设备上，没有任何个人更新以可识别的方式存储在云中。</p><figure class="pc pd pe pf gt ir gh gi paragraph-image"><div class="gh gi pb"><img src="../Images/b78e40df88cebdacd2edf7be01ad9869.png" data-original-src="https://miro.medium.com/v2/resize:fit:1276/format:webp/1*6r2nNTcq1wH9qy5lw0VSXw.png"/></div><figcaption class="iv iw gj gh gi ix iy bd b be z dk translated">联合学习架构中的沟通[4]</figcaption></figure><p id="68dd" class="pw-post-body-paragraph lu lv jb lw b lx mn kl lz ma mo ko mc li mp me mf lm mq mh mi lq mr mk ml mm ij bi translated">这类应用的一个旗舰例子是为Android智能手机开发的“Gboard”功能:当Gboard显示一个建议时，你的手机会在本地存储关于当前上下文以及你是否点击了该建议(该建议是否有帮助)的信息。)，联邦学习模型根据这一历史在本地进行训练，数百万台Android设备共享它们的结果(新的权重和参数)，以在Gboard的AI模型的下一次迭代中进行改进。</p><figure class="pc pd pe pf gt ir gh gi paragraph-image"><div role="button" tabindex="0" class="ph pi di pj bf pk"><div class="gh gi pg"><img src="../Images/bbade36cef6a5729b7adfbe44ea95e7b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/1*Fta4NXeqHa7gdm8b3Gfmxg.gif"/></div></div><figcaption class="iv iw gj gh gi ix iy bd b be z dk translated">谷歌键盘服务如何工作[5]</figcaption></figure><p id="d01c" class="pw-post-body-paragraph lu lv jb lw b lx mn kl lz ma mo ko mc li mp me mf lm mq mh mi lq mr mk ml mm ij bi translated"><strong class="lw jl">差分隐私将数据从原始状态转换为一种格式，允许组织从大部分数据中学习</strong>，同时确保结果不会区分或重新识别个人数据。</p><p id="5c73" class="pw-post-body-paragraph lu lv jb lw b lx mn kl lz ma mo ko mc li mp me mf lm mq mh mi lq mr mk ml mm ij bi translated">自21世纪初以来，研究表明，87%的美国人口可以通过{出生日期，性别，邮政编码}  [6]的组合来唯一识别。2007年，研究人员对网飞发布的一个匿名数据库进行了逆向工程，揭露了该平台50万用户的偏好和观点[7]。</p><p id="d2b1" class="pw-post-body-paragraph lu lv jb lw b lx mn kl lz ma mo ko mc li mp me mf lm mq mh mi lq mr mk ml mm ij bi translated">微软、谷歌和苹果等主要公司已经转向差分隐私，以帮助确保敏感数据的机密性。大型科技公司的这种关注有助于将差分隐私推出研究实验室，并将其集成到应用程序设计和产品开发中。</p><p id="a400" class="pw-post-body-paragraph lu lv jb lw b lx mn kl lz ma mo ko mc li mp me mf lm mq mh mi lq mr mk ml mm ij bi translated">差异保密现在是SME(中小型企业)和软件初创公司采用的一种技术，因为他们发现它有很大的附加值。</p><figure class="pc pd pe pf gt ir gh gi paragraph-image"><div role="button" tabindex="0" class="ph pi di pj bf pk"><div class="gh gi pl"><img src="../Images/bfb804a08327737536df06162b4236a3.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*ePSZtYPsSpFW7YxYoC2vDw.png"/></div></div><figcaption class="iv iw gj gh gi ix iy bd b be z dk translated">匿名数据集的示例</figcaption></figure><p id="2676" class="pw-post-body-paragraph lu lv jb lw b lx mn kl lz ma mo ko mc li mp me mf lm mq mh mi lq mr mk ml mm ij bi translated">差分隐私机制本质上向原始数据添加噪声(通常是高斯或拉普拉斯)，以实现可量化的机密性级别。知道了这个水平，我们就可以估计出我们的数据集中可以公开的最大信息量。有两种主要方法:</p><p id="d824" class="pw-post-body-paragraph lu lv jb lw b lx mn kl lz ma mo ko mc li mp me mf lm mq mh mi lq mr mk ml mm ij bi translated"><strong class="lw jl">本地差分隐私= </strong>噪声被添加到数据集中的每个单独的数据点(或者由公司的一名雇员在获得数据后添加，或者由个人自己在发布他们的数据之前添加。公司可用)。</p><figure class="pc pd pe pf gt ir gh gi paragraph-image"><div role="button" tabindex="0" class="ph pi di pj bf pk"><div class="gh gi pm"><img src="../Images/8fa94bdd6ed68b5cc9b01d2d5a94927e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*CYws_gATIaN9IhgDlP3g7A.jpeg"/></div></div><figcaption class="iv iw gj gh gi ix iy bd b be z dk translated">局部差分机密性图</figcaption></figure><p id="69b5" class="pw-post-body-paragraph lu lv jb lw b lx mn kl lz ma mo ko mc li mp me mf lm mq mh mi lq mr mk ml mm ij bi translated"><strong class="lw jl">全局差分隐私= </strong>保护个人隐私所需的噪声被添加到原始数据查询的输出中。</p><figure class="pc pd pe pf gt ir gh gi paragraph-image"><div role="button" tabindex="0" class="ph pi di pj bf pk"><div class="gh gi pm"><img src="../Images/930ae71f24d7bbc2365f9f7a242b4067.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*9_fF1RgB8N1q3tN11GwAaA.jpeg"/></div></div><figcaption class="iv iw gj gh gi ix iy bd b be z dk translated">全局差分隐私图</figcaption></figure><p id="a74b" class="pw-post-body-paragraph lu lv jb lw b lx mn kl lz ma mo ko mc li mp me mf lm mq mh mi lq mr mk ml mm ij bi translated">一般来说，与局部差异隐私相比，全局差异隐私可以产生更准确的结果，同时保持相同的隐私级别。另一方面，当使用全局差分隐私时，捐赠数据的人应该相信接收实体会添加必要的噪声来维护他们的隐私。</p><h1 id="18a9" class="nr la jb bd lb ns ow nu le nv ox nx lh kq oy kr ll kt oz ku lp kw pa kx lt ob bi translated">结论</h1><p id="076f" class="pw-post-body-paragraph lu lv jb lw b lx ly kl lz ma mb ko mc li md me mf lm mg mh mi lq mj mk ml mm ij bi translated">人工智能的性能和尊重数据隐私之间的联盟是一项艰巨的任务，但充满了机遇和希望。显然，任何孤立实施的措施都不能完全有效地防止滥用。因此，在智能算法的决策具有重要意义的情况下，将几个层次的测量结果结合起来使它们协同工作是有意义的。</p><blockquote class="nj nk nl"><p id="bf4f" class="lu lv nm lw b lx mn kl lz ma mo ko mc nn mp me mf no mq mh mi np mr mk ml mm ij bi translated"><strong class="lw jl">注:本文最初发表于it的法文版</strong> <a class="ae nq" href="https://datavalue-consulting.com/ia-et-vie-privee-regles-bonnes-pratiques/" rel="noopener ugc nofollow" target="_blank"> <strong class="lw jl">此处</strong> </a></p></blockquote><h2 id="0a51" class="kz la jb bd lb lc ld dn le lf lg dp lh li lj lk ll lm ln lo lp lq lr ls lt jh bi translated">参考资料:</h2><ul class=""><li id="3868" class="oc od jb lw b lx ly ma mb li pn lm po lq pp mm oh oi oj ok bi translated">[1]<a class="ae nq" href="https://gdpr-info.eu/art-4-gdpr/" rel="noopener ugc nofollow" target="_blank">GDPR第四条第一款</a></li><li id="1235" class="oc od jb lw b lx om ma on li oo lm op lq oq mm oh oi oj ok bi translated">[2]<a class="ae nq" href="https://gdpr-info.eu/recitals/no-71/" rel="noopener ugc nofollow" target="_blank">GDPR第71场独奏会</a></li><li id="c69d" class="oc od jb lw b lx om ma on li oo lm op lq oq mm oh oi oj ok bi translated">[3] <a class="ae nq" href="https://memeburn.com/2020/09/twitter-investigating-cropping-algorithm-after-users-flag-racial-bias/" rel="noopener ugc nofollow" target="_blank"> Twitter裁剪算法</a></li><li id="a177" class="oc od jb lw b lx om ma on li oo lm op lq oq mm oh oi oj ok bi translated">【4】<a class="ae nq" href="https://medium.com/sap-machine-learning-research/privacy-preserving-collaborative-machine-learning-35236870cd43" rel="noopener">保护隐私的协同机器学习；</a>作者:Robin Geyer、Moin Nabi和Tassilo Klein</li><li id="662c" class="oc od jb lw b lx om ma on li oo lm op lq oq mm oh oi oj ok bi translated">[5] <a class="ae nq" href="https://ai.googleblog.com/2017/04/federated-learning-collaborative.html" rel="noopener ugc nofollow" target="_blank">联邦学习:没有集中训练数据的协同机器学习</a>，谷歌AI博客</li><li id="c5c7" class="oc od jb lw b lx om ma on li oo lm op lq oq mm oh oi oj ok bi translated">[6] <a class="ae nq" href="http://www.latanyasweeney.org/work/identifiability.html" rel="noopener ugc nofollow" target="_blank">政策与法律:去识别数据的可识别性</a>，作者Latanya Sweeney博士</li><li id="868e" class="oc od jb lw b lx om ma on li oo lm op lq oq mm oh oi oj ok bi translated">【7】<a class="ae nq" href="https://arxiv.org/abs/cs/0610105" rel="noopener ugc nofollow" target="_blank">如何打破Netflix奖项数据集的匿名性</a>；作者:阿尔温德·纳拉亚南，维塔利·什马蒂科夫</li></ul></div></div>    
</body>
</html>