<html>
<head>
<title>Linear Regression vs. Logistic Regression</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">线性回归与逻辑回归</h1>
<blockquote>原文：<a href="https://pub.towardsai.net/machine-learning-fcf74f121167?source=collection_archive---------0-----------------------#2021-07-01">https://pub.towardsai.net/machine-learning-fcf74f121167?source=collection_archive---------0-----------------------#2021-07-01</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><h2 id="d276" class="ir is it bd b dl iu iv iw ix iy iz dk ja translated" aria-label="kicker paragraph"><a class="ae ep" href="https://towardsai.net/p/category/machine-learning" rel="noopener ugc nofollow" target="_blank">机器学习</a></h2><div class=""/><div class=""><h2 id="c4c6" class="pw-subtitle-paragraph jz jc it bd b ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq dk translated">监督机器学习算法的比较研究</h2></div><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi kr"><img src="../Images/637ffb03006cfc04a9660c1033625339.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*iNub0pKJjfWG39G4mb8gJg.png"/></div></div><figcaption class="ld le gj gh gi lf lg bd b be z dk translated">作者的照片</figcaption></figure><p id="9681" class="pw-post-body-paragraph lh li it lj b lk ll kd lm ln lo kg lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">我写这篇文章是为了深入了解线性和逻辑回归算法之间的相似性和差异，以及它们在代码帮助下的工作。</p><blockquote class="md me mf"><p id="8458" class="lh li mg lj b lk ll kd lm ln lo kg lp mh lr ls lt mi lv lw lx mj lz ma mb mc im bi translated"><strong class="lj jd"> <em class="it">线性回归</em> </strong></p></blockquote><p id="73cb" class="pw-post-body-paragraph lh li it lj b lk ll kd lm ln lo kg lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">众所周知，线性回归是一种有监督的机器学习算法，是一种用来研究两个连续变量即因变量和自变量之间关系的统计方法。它还预测连续值，并找到描述变量的最佳拟合线。</p><p id="4890" class="pw-post-body-paragraph lh li it lj b lk ll kd lm ln lo kg lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated"><strong class="lj jd">数学线性回归</strong></p><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div class="gh gi mk"><img src="../Images/0d5c6dbd328759509daf246ed8c31852.png" data-original-src="https://miro.medium.com/v2/resize:fit:1280/format:webp/1*70ug29KUSq7hMAzsk0CWcQ.png"/></div><figcaption class="ld le gj gh gi lf lg bd b be z dk translated">图片<a class="ae ml" href="https://www.slideshare.net/KirillEremenko/deep-learning-az-regression-classification-module-7" rel="noopener ugc nofollow" target="_blank">来源</a></figcaption></figure><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div class="gh gi mm"><img src="../Images/970e139e9ea7e792b237cf153218f465.png" data-original-src="https://miro.medium.com/v2/resize:fit:1006/format:webp/1*ZcAOhC1OhOto9mhAbst0iw.png"/></div><figcaption class="ld le gj gh gi lf lg bd b be z dk translated">图像<a class="ae ml" href="https://www.slideshare.net/KirillEremenko/deep-learning-az-regression-classification-module-7" rel="noopener ugc nofollow" target="_blank">来源</a></figcaption></figure><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div class="gh gi mn"><img src="../Images/d25639cf5096f2f34695411de7cb5b4f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1022/format:webp/1*a_l1eW788GI21BzLkVni0Q.png"/></div><figcaption class="ld le gj gh gi lf lg bd b be z dk translated">图像<a class="ae ml" href="https://www.slideshare.net/KirillEremenko/deep-learning-az-regression-classification-module-7" rel="noopener ugc nofollow" target="_blank">来源</a></figcaption></figure><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div class="gh gi mo"><img src="../Images/60fd8babf8448c1b8dbe92b3daa02d00.png" data-original-src="https://miro.medium.com/v2/resize:fit:1018/format:webp/1*eiME1ljQ_713i_LyWLbNDA.png"/></div><figcaption class="ld le gj gh gi lf lg bd b be z dk translated">图像<a class="ae ml" href="https://www.slideshare.net/KirillEremenko/deep-learning-az-regression-classification-module-7" rel="noopener ugc nofollow" target="_blank">来源</a></figcaption></figure><p id="478c" class="pw-post-body-paragraph lh li it lj b lk ll kd lm ln lo kg lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">分类模型之一，线性模型，即逻辑回归，用于预测分类数据。</p><div class="mp mq gp gr mr ms"><a rel="noopener  ugc nofollow" target="_blank" href="/fully-explained-linear-regression-with-python-fe2b313f32f3"><div class="mt ab fo"><div class="mu ab mv cl cj mw"><h2 class="bd jd gy z fp mx fr fs my fu fw jc bi translated">用Python全面解释线性回归</h2><div class="mz l"><h3 class="bd b gy z fp mx fr fs my fu fw dk translated">如何用一个真实的例子解决回归问题。</h3></div><div class="na l"><p class="bd b dl z fp mx fr fs my fu fw dk translated">pub.towardsai.net</p></div></div><div class="nb l"><div class="nc l nd ne nf nb ng lb ms"/></div></div></a></div><blockquote class="md me mf"><p id="b976" class="lh li mg lj b lk ll kd lm ln lo kg lp mh lr ls lt mi lv lw lx mj lz ma mb mc im bi translated"><strong class="lj jd"> <em class="it">逻辑回归</em> </strong></p></blockquote><p id="4c59" class="pw-post-body-paragraph lh li it lj b lk ll kd lm ln lo kg lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">这是另一种受监督的机器学习算法，用于对数据集进行统计分析，其中有一个或多个决定结果的独立变量。用一个二分变量(两个可能的结果，即1 <strong class="lj jd"> </strong>(真、成功、怀孕等)来衡量结果。)或0(假、失败、未怀孕等<strong class="lj jd">。).</strong></p><p id="008d" class="pw-post-body-paragraph lh li it lj b lk ll kd lm ln lo kg lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">此外，它使用概率的概念，即<strong class="lj jd"> </strong>是事件发生的可能性或几率。</p><p id="c61b" class="pw-post-body-paragraph lh li it lj b lk ll kd lm ln lo kg lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated"><strong class="lj jd">逻辑回归Vs线性回归</strong></p><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div class="gh gi nh"><img src="../Images/6c42de93be36be527f94c988a8922f39.png" data-original-src="https://miro.medium.com/v2/resize:fit:1036/format:webp/1*qbx6JZwba8DT7oLzfrw72Q.png"/></div></figure><p id="53fb" class="pw-post-body-paragraph lh li it lj b lk ll kd lm ln lo kg lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">概率和sigmoid的概念将线性回归修改为逻辑回归。</p><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div class="gh gi ni"><img src="../Images/e5b2732100758a6f71b2ab5077f3d050.png" data-original-src="https://miro.medium.com/v2/resize:fit:660/format:webp/1*WE3O9lGqJM8r6uoC2st5UA.png"/></div><figcaption class="ld le gj gh gi lf lg bd b be z dk translated">图片<a class="ae ml" href="https://www.youtube.com/watch?v=yIYKR4sgzI8" rel="noopener ugc nofollow" target="_blank">来源</a></figcaption></figure><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div class="gh gi nj"><img src="../Images/831c16f135dcbc5e00c059cf558cb54b.png" data-original-src="https://miro.medium.com/v2/resize:fit:918/format:webp/1*M6wwFUZ6s12fOU4UyAgPqQ.png"/></div><figcaption class="ld le gj gh gi lf lg bd b be z dk translated">图片<a class="ae ml" href="https://www.youtube.com/watch?v=yIYKR4sgzI8" rel="noopener ugc nofollow" target="_blank">来源</a></figcaption></figure><p id="bbad" class="pw-post-body-paragraph lh li it lj b lk ll kd lm ln lo kg lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated"><strong class="lj jd">借助概率进行逻辑回归</strong></p><p id="071a" class="pw-post-body-paragraph lh li it lj b lk ll kd lm ln lo kg lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">让我们举一个有年龄和老年福利的数据集的例子。年龄在35岁或35岁以上的人可以得到老年津贴，年龄在35岁以下的人不能得到老年津贴。</p><p id="6ae3" class="pw-post-body-paragraph lh li it lj b lk ll kd lm ln lo kg lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">我们将阈值设置为0.5，以了解工作情况，在下图中，根据概率值，超过0.5的值有更高的机会获得给定的收益。</p><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi nk"><img src="../Images/f25c8a7a9ea2936fc61adecc05643253.png" data-original-src="https://miro.medium.com/v2/resize:fit:956/format:webp/1*6B_sj7Hte24E6cbZkR_8eQ.png"/></div></div><figcaption class="ld le gj gh gi lf lg bd b be z dk translated">图像<a class="ae ml" href="https://www.youtube.com/watch?v=yIYKR4sgzI8" rel="noopener ugc nofollow" target="_blank">来源</a></figcaption></figure><p id="4b8c" class="pw-post-body-paragraph lh li it lj b lk ll kd lm ln lo kg lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated"><strong class="lj jd">线性回归和逻辑回归在以下方面相似。</strong></p><ul class=""><li id="1d01" class="nl nm it lj b lk ll ln lo lq nn lu no ly np mc nq nr ns nt bi translated">两者都是有监督的机器学习算法。</li><li id="085d" class="nl nm it lj b lk nu ln nv lq nw lu nx ly ny mc nq nr ns nt bi translated">两个模型都是参数回归，这意味着两个模型都使用线性方程进行预测。</li></ul><div class="mp mq gp gr mr ms"><a rel="noopener  ugc nofollow" target="_blank" href="/fully-explained-logistic-regression-with-python-f4a16413ddcd"><div class="mt ab fo"><div class="mu ab mv cl cj mw"><h2 class="bd jd gy z fp mx fr fs my fu fw jc bi translated">用Python全面解释逻辑回归</h2><div class="mz l"><h3 class="bd b gy z fp mx fr fs my fu fw dk translated">机器学习算法中的统计非线性方法</h3></div><div class="na l"><p class="bd b dl z fp mx fr fs my fu fw dk translated">pub.towardsai.net</p></div></div><div class="nb l"><div class="nz l nd ne nf nb ng lb ms"/></div></div></a></div><p id="b7e7" class="pw-post-body-paragraph lh li it lj b lk ll kd lm ln lo kg lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated"><strong class="lj jd">差异</strong></p><ul class=""><li id="bf78" class="nl nm it lj b lk ll ln lo lq nn lu no ly np mc nq nr ns nt bi translated">目标变量中的连续值由线性回归处理，而目标列中的二进制类由逻辑回归处理。</li><li id="a812" class="nl nm it lj b lk nu ln nv lq nw lu nx ly ny mc nq nr ns nt bi translated">线性回归寻找最佳拟合直线，而逻辑回归将直线值拟合到sigmoid曲线。</li><li id="4192" class="nl nm it lj b lk nu ln nv lq nw lu nx ly ny mc nq nr ns nt bi translated">线性回归中的损失函数可以用均方差法计算，而逻辑回归则用最大似然估计。</li></ul><blockquote class="md me mf"><p id="b132" class="lh li mg lj b lk ll kd lm ln lo kg lp mh lr ls lt mi lv lw lx mj lz ma mb mc im bi translated"><strong class="lj jd"> <em class="it">用于线性回归的代码</em> </strong></p></blockquote><pre class="ks kt ku kv gt oa ob oc od aw oe bi"><span id="a1a6" class="of og it ob b gy oh oi l oj ok">#import libraries</span><span id="e8a3" class="of og it ob b gy ol oi l oj ok">import numpy as np<br/>import pandas as pd<br/>import matplotlib.pyplot as plt</span><span id="df39" class="of og it ob b gy ol oi l oj ok">datafile=pd.read_csv("salaryData.csv")<br/>print(datafile)</span></pre><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div class="gh gi om"><img src="../Images/db7052f595db56a9b7f161036a029de5.png" data-original-src="https://miro.medium.com/v2/resize:fit:584/format:webp/1*F3Cne9VFr55azMoEpCEljQ.png"/></div><figcaption class="ld le gj gh gi lf lg bd b be z dk translated">作者的照片</figcaption></figure><pre class="ks kt ku kv gt oa ob oc od aw oe bi"><span id="e7be" class="of og it ob b gy oh oi l oj ok">#visualisation usingh scatter plot</span><span id="a71f" class="of og it ob b gy ol oi l oj ok">x=datafile['YearsExperience']<br/>y=datafile['Salary']</span><span id="69e6" class="of og it ob b gy ol oi l oj ok">plt.xlabel('YearsExperience')<br/>plt.ylabel('Salary')<br/>plt.scatter(x,y,color='red',marker='+')<br/>plt.show()</span></pre><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div class="gh gi nj"><img src="../Images/74a08ec4b19e54a1dee5185de4382c50.png" data-original-src="https://miro.medium.com/v2/resize:fit:918/format:webp/1*LMJWWMbIQbhLgXIikjPCqQ.png"/></div><figcaption class="ld le gj gh gi lf lg bd b be z dk translated">作者的照片</figcaption></figure><pre class="ks kt ku kv gt oa ob oc od aw oe bi"><span id="e883" class="of og it ob b gy oh oi l oj ok">#Splitting of data set in to testing and training</span><span id="4eb4" class="of og it ob b gy ol oi l oj ok">x=datafile.iloc[:,:-1].values<br/>y=datafile.iloc[:,1].values</span><span id="048b" class="of og it ob b gy ol oi l oj ok">print(x)</span></pre><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div class="gh gi on"><img src="../Images/24c18f290bf74cac32e856120efad00e.png" data-original-src="https://miro.medium.com/v2/resize:fit:222/format:webp/1*mpjuqpACr2X38Nk-o-sOhw.png"/></div><figcaption class="ld le gj gh gi lf lg bd b be z dk translated">作者的照片</figcaption></figure><pre class="ks kt ku kv gt oa ob oc od aw oe bi"><span id="b8d8" class="of og it ob b gy oh oi l oj ok">import sklearn</span><span id="d463" class="of og it ob b gy ol oi l oj ok">from sklearn.model_selection import train_test_split</span><span id="865a" class="of og it ob b gy ol oi l oj ok">xtrain,xtest,ytrain,ytest=train_test_split(x,y,test_size=1/3,random_state=1)</span><span id="b6b5" class="of og it ob b gy ol oi l oj ok">#creating simple linear model</span><span id="5239" class="of og it ob b gy ol oi l oj ok">x=datafile.iloc[:,:-1].values</span><span id="fe5b" class="of og it ob b gy ol oi l oj ok">y=datafile.iloc[:,1].values</span><span id="37ee" class="of og it ob b gy ol oi l oj ok">from sklearn.linear_model import LinearRegression</span><span id="e02f" class="of og it ob b gy ol oi l oj ok">model=LinearRegression()   #y=ax+b<br/>model.fit(xtrain,ytrain)</span><span id="bb40" class="of og it ob b gy ol oi l oj ok">LinearRegression(copy_X=True, fit_intercept=True, n_jobs=None, normalize=False)</span><span id="868e" class="of og it ob b gy ol oi l oj ok">#prediction</span><span id="0a67" class="of og it ob b gy ol oi l oj ok">y_pred=model.predict(xtest)<br/>y_pred</span></pre><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div class="gh gi oo"><img src="../Images/6184263038fc82034d9c17dd46105395.png" data-original-src="https://miro.medium.com/v2/resize:fit:1010/format:webp/1*O1dlDQxOgBsPP86CfA45Nw.png"/></div><figcaption class="ld le gj gh gi lf lg bd b be z dk translated">作者的照片</figcaption></figure><pre class="ks kt ku kv gt oa ob oc od aw oe bi"><span id="4194" class="of og it ob b gy oh oi l oj ok">#plotting linear regression</span><span id="5587" class="of og it ob b gy ol oi l oj ok">plt.scatter(xtrain,ytrain,color='red')<br/>plt.plot(xtrain,model.predict(xtrain))<br/>plt.show()</span></pre><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div class="gh gi op"><img src="../Images/43a4b0af51f1babd3471aec359d7bcd8.png" data-original-src="https://miro.medium.com/v2/resize:fit:844/format:webp/1*7z-dWR8gIGWjtlbYFh2UdA.png"/></div><figcaption class="ld le gj gh gi lf lg bd b be z dk translated">作者的照片</figcaption></figure><blockquote class="md me mf"><p id="9765" class="lh li mg lj b lk ll kd lm ln lo kg lp mh lr ls lt mi lv lw lx mj lz ma mb mc im bi translated"><strong class="lj jd"> <em class="it">逻辑回归码</em> </strong></p></blockquote><pre class="ks kt ku kv gt oa ob oc od aw oe bi"><span id="98ce" class="of og it ob b gy oh oi l oj ok"># Importing Libraries and data set</span><span id="0a66" class="of og it ob b gy ol oi l oj ok">import numpy as np<br/>import pandas as pd<br/>import matplotlib.pyplot as plt</span><span id="5927" class="of og it ob b gy ol oi l oj ok">datafile=pd.read_csv(‘LR.csv’)<br/>datafile</span></pre><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div class="gh gi oq"><img src="../Images/be7782b686038e6ae0cb34936f122804.png" data-original-src="https://miro.medium.com/v2/resize:fit:906/format:webp/1*lFolxpnk37gTxZ6KoRRU7w.png"/></div><figcaption class="ld le gj gh gi lf lg bd b be z dk translated">作者的照片</figcaption></figure><pre class="ks kt ku kv gt oa ob oc od aw oe bi"><span id="a08c" class="of og it ob b gy oh oi l oj ok">X=datafile.iloc[:,[0,1]].values</span><span id="baee" class="of og it ob b gy ol oi l oj ok">Y=datafile.iloc[:,2].values</span><span id="04f1" class="of og it ob b gy ol oi l oj ok">#training and testing data</span><span id="91be" class="of og it ob b gy ol oi l oj ok">from sklearn.model_selection import train_test_split</span><span id="3dbf" class="of og it ob b gy ol oi l oj ok">X_train,X_test,Y_train,Y_test=train_test_split(X,Y,test_size=0.25,random_state=0)</span><span id="9a42" class="of og it ob b gy ol oi l oj ok">from sklearn.preprocessing import StandardScaler</span><span id="a213" class="of og it ob b gy ol oi l oj ok">sc=StandardScaler()</span><span id="73c1" class="of og it ob b gy ol oi l oj ok">X_train=sc.fit_transform(X_train)</span><span id="c40d" class="of og it ob b gy ol oi l oj ok">X_test =sc.transform(X_test)</span></pre><p id="23db" class="pw-post-body-paragraph lh li it lj b lk ll kd lm ln lo kg lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">逻辑回归在数据集训练部分的应用。</p><pre class="ks kt ku kv gt oa ob oc od aw oe bi"><span id="b00f" class="of og it ob b gy oh oi l oj ok">from sklearn.linear_model import LogisticRegression</span><span id="d0de" class="of og it ob b gy ol oi l oj ok">classifer=LogisticRegression(random_state=0)</span><span id="e1ed" class="of og it ob b gy ol oi l oj ok">classifer.fit(X_train,Y_train)</span></pre><p id="2c74" class="pw-post-body-paragraph lh li it lj b lk ll kd lm ln lo kg lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">预测值执行</p><pre class="ks kt ku kv gt oa ob oc od aw oe bi"><span id="4806" class="of og it ob b gy oh oi l oj ok">Y_pred=classifer.predict(X_test)</span><span id="ebce" class="of og it ob b gy ol oi l oj ok"># Confusion matrix.</span><span id="10a8" class="of og it ob b gy ol oi l oj ok">from sklearn.metrics import confusion_matrix</span><span id="efb9" class="of og it ob b gy ol oi l oj ok">cm=confusion_matrix(Y_test,Y_pred)</span><span id="1b92" class="of og it ob b gy ol oi l oj ok">cm</span><span id="c522" class="of og it ob b gy ol oi l oj ok">#output:<br/>array([[65,  3],<br/>      [ 8, 24]])</span></pre><p id="b476" class="pw-post-body-paragraph lh li it lj b lk ll kd lm ln lo kg lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">准确(性)</p><pre class="ks kt ku kv gt oa ob oc od aw oe bi"><span id="b6f8" class="of og it ob b gy oh oi l oj ok">from sklearn.metrics import accuracy_score</span><span id="59fa" class="of og it ob b gy ol oi l oj ok">accuracy_score(Y_test,Y_pred)</span><span id="e089" class="of og it ob b gy ol oi l oj ok"><strong class="ob jd">#output:</strong><br/>0.89</span></pre><p id="fec7" class="pw-post-body-paragraph lh li it lj b lk ll kd lm ln lo kg lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">我希望你喜欢这篇文章。通过我的<a class="ae ml" href="https://www.linkedin.com/in/data-scientist-95040a1ab/" rel="noopener ugc nofollow" target="_blank"> LinkedIn </a>和<a class="ae ml" href="https://twitter.com/amitprius" rel="noopener ugc nofollow" target="_blank"> twitter </a>联系我。</p><h1 id="bb45" class="or og it bd os ot ou ov ow ox oy oz pa ki pb kj pc kl pd km pe ko pf kp pg ph bi translated">推荐文章</h1><p id="5939" class="pw-post-body-paragraph lh li it lj b lk pi kd lm ln pj kg lp lq pk ls lt lu pl lw lx ly pm ma mb mc im bi translated"><a class="ae ml" href="https://medium.com/towards-artificial-intelligence/nlp-zero-to-hero-with-python-2df6fcebff6e?sk=2231d868766e96b13d1e9d7db6064df1" rel="noopener"> 1。NLP —零到英雄与Python </a> <br/> 2。<a class="ae ml" href="https://medium.com/towards-artificial-intelligence/python-data-structures-data-types-and-objects-244d0a86c3cf?sk=42f4b462499f3fc3a160b21e2c94dba6" rel="noopener"> Python数据结构数据类型和对象</a>T5】3 .<a class="ae ml" rel="noopener ugc nofollow" target="_blank" href="/exception-handling-concepts-in-python-4d5116decac3?source=friends_link&amp;sk=a0ed49d9fdeaa67925eac34ecb55ea30">Python中的异常处理概念</a> <br/> 4。<a class="ae ml" rel="noopener ugc nofollow" target="_blank" href="/deep-learning-88e218b74a14?source=friends_link&amp;sk=540bf9088d31859d50dbddab7524ba35">为什么LSTM在深度学习方面比RNN更有用？</a> <br/> 5。<a class="ae ml" rel="noopener ugc nofollow" target="_blank" href="/neural-networks-the-rise-of-recurrent-neural-networks-df740252da88?source=friends_link&amp;sk=6844935e3de14e478ce00f0b22e419eb">神经网络:递归神经网络的兴起</a> <br/> 6。<a class="ae ml" href="https://medium.com/towards-artificial-intelligence/fully-explained-linear-regression-with-python-fe2b313f32f3?source=friends_link&amp;sk=53c91a2a51347ec2d93f8222c0e06402" rel="noopener">用Python </a> <br/> 7全面讲解了线性回归。<a class="ae ml" href="https://medium.com/towards-artificial-intelligence/fully-explained-logistic-regression-with-python-f4a16413ddcd?source=friends_link&amp;sk=528181f15a44e48ea38fdd9579241a78" rel="noopener">用Python </a> <br/>充分解释了Logistic回归8。<a class="ae ml" rel="noopener ugc nofollow" target="_blank" href="/differences-between-concat-merge-and-join-with-python-1a6541abc08d?source=friends_link&amp;sk=3b37b694fb90db16275059ea752fc16a">concat()、merge()和join()与Python </a> <br/>的区别9。<a class="ae ml" rel="noopener ugc nofollow" target="_blank" href="/data-wrangling-with-python-part-1-969e3cc81d69?source=friends_link&amp;sk=9c3649cf20f31a5c9ead51c50c89ba0b">与Python的数据角力—第一部分</a> <br/> 10。<a class="ae ml" href="https://medium.com/analytics-vidhya/confusion-matrix-in-machine-learning-91b6e2b3f9af?source=friends_link&amp;sk=11c6531da0bab7b504d518d02746d4cc" rel="noopener">机器学习中的混淆矩阵</a></p></div></div>    
</body>
</html>