<html>
<head>
<title>Easing up the process of Tensorflow 2.0 Object Detection API and TensorRT</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">简化Tensorflow 2.0对象检测API和TensorRT的流程</h1>
<blockquote>原文：<a href="https://pub.towardsai.net/easing-up-the-process-of-tensorflow-2-0-object-detection-api-and-tensorrt-fd2d790c12f3?source=collection_archive---------0-----------------------#2020-09-08">https://pub.towardsai.net/easing-up-the-process-of-tensorflow-2-0-object-detection-api-and-tensorrt-fd2d790c12f3?source=collection_archive---------0-----------------------#2020-09-08</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><h2 id="02bd" class="io ip iq bd b dl ir is it iu iv iw dk ix translated" aria-label="kicker paragraph"><a class="ae ep" href="https://towardsai.net/p/category/computer-vision" rel="noopener ugc nofollow" target="_blank">计算机视觉</a></h2><div class=""/><p id="7d70" class="pw-post-body-paragraph jw jx iq jy b jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ij bi translated">使用<strong class="jy ja">蒙克的TF-Object-Detection-API </strong>训练自己的物体探测器的详细步骤，在GPU系统上使用<strong class="jy ja">tensort</strong>和<strong class="jy ja"> run </strong> <strong class="jy ja">推论</strong>进行优化</p><figure class="kv kw kx ky gt kz gh gi paragraph-image"><div role="button" tabindex="0" class="la lb di lc bf ld"><div class="gh gi ku"><img src="../Images/9088dced2749d46ffa8730b50fe92180.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*OarqVV-ARRAfeP_tdpHNcg.png"/></div></div></figure><p id="bdf3" class="pw-post-body-paragraph jw jx iq jy b jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ij bi translated"><strong class="jy ja">的全部代码可作为</strong> <a class="ae lg" href="https://github.com/Tessellate-Imaging/Monk_Object_Detection/blob/master/application_model_zoo/Example%20-%20BDD100K%20dataset%20with%20TensorRT%20optimization.ipynb" rel="noopener ugc nofollow" target="_blank"> <strong class="jy ja"> jupyter笔记本</strong> </a> <strong class="jy ja"> at </strong> <a class="ae lg" href="https://github.com/Tessellate-Imaging/Monk_Object_Detection" rel="noopener ugc nofollow" target="_blank"> <strong class="jy ja">和尚物体探测库</strong> </a></p></div><div class="ab cl lh li hu lj" role="separator"><span class="lk bw bk ll lm ln"/><span class="lk bw bk ll lm ln"/><span class="lk bw bk ll lm"/></div><div class="ij ik il im in"><p id="d904" class="pw-post-body-paragraph jw jx iq jy b jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ij bi lo translated">每个计算机视觉工程师都使用开源库，目标是在自定义数据集上使用它。用于对象检测的最常用的库之一是Tensorflow，用于其不断扩展的模型动物园。Tensorflow最近增加了对TF 2.0对象检测API的支持。使用TensorFlow对象检测API进行自定义对象检测以及使用TensorRT进行进一步的模型优化<strong class="jy ja">是一个冗长耗时的过程</strong>并且<strong class="jy ja">容易出错</strong>。</p><p id="e670" class="pw-post-body-paragraph jw jx iq jy b jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ij bi translated"><strong class="jy ja">为了克服通常面临的问题并减少开发人员的工作量</strong><br/>*修改tfrecord示例并以严格的格式排列数据以适应自定义数据<br/> *更新配置文件<br/> *使用正确的文件来训练引擎<br/> *将训练好的检查点转换为其他格式以进行推理<br/> *搜索运行推理的正确方式<br/> *使用TensorRT等优化模型<br/>我们<strong class="jy ja">将TF对象检测API与低代码monk集成</strong></p><p id="70a5" class="pw-post-body-paragraph jw jx iq jy b jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ij bi translated">有了它，<strong class="jy ja">开发人员可以轻松地</strong> <br/> ★将自定义数据集转换为tf记录<br/> ★使用pythonic语法更新配置文件<br/> ★训练引擎并导出为不同的推理格式<br/> ★使用检查点或保存的模型格式进行推理<br/> ★使用TensorRT引擎优化模型以实现更快的推理</p></div><div class="ab cl lh li hu lj" role="separator"><span class="lk bw bk ll lm ln"/><span class="lk bw bk ll lm ln"/><span class="lk bw bk ll lm"/></div><div class="ij ik il im in"><h1 id="9269" class="lx ly iq bd lz ma mb mc md me mf mg mh mi mj mk ml mm mn mo mp mq mr ms mt mu bi translated">使用TF 2.0对象检测API训练自定义数据集时面临的问题</h1><p id="4b0a" class="pw-post-body-paragraph jw jx iq jy b jz mv kb kc kd mw kf kg kh mx kj kk kl my kn ko kp mz kr ks kt ij bi translated">除了过程步骤，还提到了开发人员或研究人员通常面临的问题，以及为什么我们想到使用低代码开源库来简化这个过程。</p><p id="eb1c" class="pw-post-body-paragraph jw jx iq jy b jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ij bi translated"><strong class="jy ja">第一步</strong>:安装先决条件，编译模型。</p><p id="829e" class="pw-post-body-paragraph jw jx iq jy b jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ij bi translated">*使用旧版本2.0.0和2.1.0进行培训会导致错误</p><pre class="kv kw kx ky gt na nb nc nd aw ne bi"><span id="f264" class="nf ly iq nb b gy ng nh l ni nj">AttributeError: module ‘tensorflow_core.keras.utils’ has no attribute ‘register_keras_serializable’</span></pre><p id="3bc3" class="pw-post-body-paragraph jw jx iq jy b jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ij bi translated">*使用2.2.0版进行培训还会导致以下错误</p><pre class="kv kw kx ky gt na nb nc nd aw ne bi"><span id="7dae" class="nf ly iq nb b gy ng nh l ni nj">AttributeError: 'CollectiveAllReduceExtended' object has no attribute '_cfer_fn_cache'</span></pre><p id="c127" class="pw-post-body-paragraph jw jx iq jy b jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ij bi translated">*版本2.3.0运行时没有任何错误，并且也与colab兼容。</p><p id="11cb" class="pw-post-body-paragraph jw jx iq jy b jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ij bi translated">因此选择了V-2.3.0，V-2 . 4 . 0发布后将很快升级到V-2.3.0，因为在V-2 . 3 . 0中tf-lite转换容易出错</p><p id="f45a" class="pw-post-body-paragraph jw jx iq jy b jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ij bi translated"><strong class="jy ja">第二步</strong>:数据集设置</p><p id="845c" class="pw-post-body-paragraph jw jx iq jy b jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ij bi translated">* TF模型的dataset_tools提供了COCO、VOC、OID等公共数据集的例子；但并不是所有的公共数据集都用这些格式标注。</p><p id="3986" class="pw-post-body-paragraph jw jx iq jy b jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ij bi translated">*一旦以这种格式进行了注释，就需要将它安排在一个数据结构中，该数据结构可以被馈送到object _ detection/dataset _ tools/中存在的文件中；或者修改这些文件以接收管道中的定制数据</p><p id="aeb2" class="pw-post-body-paragraph jw jx iq jy b jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ij bi translated">为了使这个过程更容易，我们添加了一个简单的解析器来将注释转换成VOC格式的数据，并进一步转换成tfrecords。</p><p id="26f2" class="pw-post-body-paragraph jw jx iq jy b jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ij bi translated"><strong class="jy ja">第三步</strong>:模型和配置文件+训练</p><p id="a3a4" class="pw-post-body-paragraph jw jx iq jy b jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ij bi translated">*权重和配置文件必须从模型动物园下载，数据结构必须以这种格式更新</p><figure class="kv kw kx ky gt kz gh gi paragraph-image"><div class="gh gi nk"><img src="../Images/693039c41b5b2024d2e5dd730bb48a10.png" data-original-src="https://miro.medium.com/v2/resize:fit:1200/format:webp/1*Me5j_RbW4LLSpozg277VyQ.png"/></div><figcaption class="nl nm gj gh gi nn no bd b be z dk translated">数据格式。<a class="ae lg" href="https://github.com/tensorflow/models/blob/master/research/object_detection/g3doc/tf2_training_and_evaluation.md" rel="noopener ugc nofollow" target="_blank">演职员表</a></figcaption></figure><p id="c404" class="pw-post-body-paragraph jw jx iq jy b jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ij bi translated">*发布此消息后，必须更新配置文件元素。必须更改超过25个元素的集合，包括数据集详细信息、基本特征提取详细信息、检查点详细信息、优化器详细信息、tf记录详细信息。</p><p id="b0a4" class="pw-post-body-paragraph jw jx iq jy b jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ij bi translated">*更新配置详细信息后，即可进行培训</p><p id="4146" class="pw-post-body-paragraph jw jx iq jy b jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ij bi translated">为了避免手动更改配置文件和文件夹结构格式，创建了pythonic API包装器。</p><p id="5078" class="pw-post-body-paragraph jw jx iq jy b jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ij bi translated"><strong class="jy ja">第四步</strong>:将模型导出为已保存的模型格式并进行推理</p><p id="4b01" class="pw-post-body-paragraph jw jx iq jy b jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ij bi translated">*然后，检查点文件可以转换为“保存的模型”格式。</p><p id="3a8a" class="pw-post-body-paragraph jw jx iq jy b jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ij bi translated">*这里的一般问题包括ssd fpn和resnet格式的转换。</p><p id="312e" class="pw-post-body-paragraph jw jx iq jy b jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ij bi translated">*在检查点文件上运行推理需要对象检测模型生成器，而保存的模型”。pb”格式可以使用tf的load_model函数加载。</p><p id="56a2" class="pw-post-body-paragraph jw jx iq jy b jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ij bi translated">*在运行推理之前，在saved_model上创建一个图形函数通常会加快进程</p><p id="ce9e" class="pw-post-body-paragraph jw jx iq jy b jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ij bi translated"><strong class="jy ja">第五步</strong>:tensort模型转换和推理</p><p id="f8cf" class="pw-post-body-paragraph jw jx iq jy b jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ij bi translated">*保存的模型可以进行优化，以便在不同的NVidia GPU机器上运行</p><p id="bcdd" class="pw-post-body-paragraph jw jx iq jy b jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ij bi translated">TensorRT的问题是开发系统(训练和转换模型的系统)和部署系统(部署模型的系统)的库版本必须相同。</p><p id="d123" class="pw-post-body-paragraph jw jx iq jy b jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ij bi translated">* * The的下一个问题是，它根据所用模型的<a class="ae lg" href="https://developer.nvidia.com/cuda-gpus" rel="noopener ugc nofollow" target="_blank">计算兼容性</a>来优化模型。简单来说，在colab上优化的模型不能在<a class="ae lg" href="https://www.nvidia.com/en-in/autonomous-machines/embedded-systems/jetson-nano/" rel="noopener ugc nofollow" target="_blank"> Jetson Nano </a>板上运行。因此，模型需要在部署机器上的运行时进行转换和构建。</p><p id="213a" class="pw-post-body-paragraph jw jx iq jy b jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ij bi translated">* TensorRT模型只能从saved_model(" .pb”)文件，它以类似的格式生成一个优化的模型，然后需要对其进行推断。</p></div><div class="ab cl lh li hu lj" role="separator"><span class="lk bw bk ll lm ln"/><span class="lk bw bk ll lm ln"/><span class="lk bw bk ll lm"/></div><div class="ij ik il im in"><h1 id="c0d9" class="lx ly iq bd lz ma mb mc md me mf mg mh mi mj mk ml mm mn mo mp mq mr ms mt mu bi translated">让我们开始这个过程</h1><p id="83c9" class="pw-post-body-paragraph jw jx iq jy b jz mv kb kc kd mw kf kg kh mx kj kk kl my kn ko kp mz kr ks kt ij bi translated">注意:完整的代码可以在<a class="ae lg" href="https://github.com/Tessellate-Imaging/Monk_Object_Detection" rel="noopener ugc nofollow" target="_blank">僧侣物体探测图书馆</a>的<a class="ae lg" href="https://github.com/Tessellate-Imaging/Monk_Object_Detection/blob/master/application_model_zoo/Example%20-%20BDD100K%20dataset%20with%20TensorRT%20optimization.ipynb" rel="noopener ugc nofollow" target="_blank"> jupyter笔记本</a>中获得。这里，我只提到了整个工作中的重要步骤。</p><h1 id="26fb" class="lx ly iq bd lz ma np mc md me nq mg mh mi nr mk ml mm ns mo mp mq nt ms mt mu bi translated">步骤1 —安装</h1><p id="6615" class="pw-post-body-paragraph jw jx iq jy b jz mv kb kc kd mw kf kg kh mx kj kk kl my kn ko kp mz kr ks kt ij bi translated"><strong class="jy ja">对于本地或基于云的系统:</strong></p><figure class="kv kw kx ky gt kz"><div class="bz fp l di"><div class="nu nv l"/></div></figure><p id="00c3" class="pw-post-body-paragraph jw jx iq jy b jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ij bi translated">这将安装<br/> *先决条件库，如numpy、scipy、opencv、pillow、lxml等<br/> * Tensorflow 2.3.0和tensor flow-models-python-2 . 2 . 0<br/>* tensor flow对象检测API</p><p id="ec7b" class="pw-post-body-paragraph jw jx iq jy b jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ij bi translated">同样，它也可以安装在colab上</p><figure class="kv kw kx ky gt kz"><div class="bz fp l di"><div class="nu nv l"/></div></figure></div><div class="ab cl lh li hu lj" role="separator"><span class="lk bw bk ll lm ln"/><span class="lk bw bk ll lm ln"/><span class="lk bw bk ll lm"/></div><div class="ij ik il im in"><h1 id="67fb" class="lx ly iq bd lz ma mb mc md me mf mg mh mi mj mk ml mm mn mo mp mq mr ms mt mu bi translated">步骤2 —数据准备</h1><p id="6eb7" class="pw-post-body-paragraph jw jx iq jy b jz mv kb kc kd mw kf kg kh mx kj kk kl my kn ko kp mz kr ks kt ij bi translated">如下所述，数据集需要采用简单的pascal VOC格式</p><figure class="kv kw kx ky gt kz gh gi paragraph-image"><div role="button" tabindex="0" class="la lb di lc bf ld"><div class="gh gi nw"><img src="../Images/1a041d935963bdda68aa595dbaf0b850.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*-pdLJr7xhjyTBA8VGVIcqw.png"/></div></div><figcaption class="nl nm gj gh gi nn no bd b be z dk translated">PASCAL VOC格式</figcaption></figure><p id="102b" class="pw-post-body-paragraph jw jx iq jy b jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ij bi translated">要从COCO或任何其他格式转换数据集，请查看这些详细教程<a class="ae lg" href="https://github.com/Tessellate-Imaging/Monk_Object_Detection/tree/master/example_notebooks/13_tf_obj_2" rel="noopener ugc nofollow" target="_blank"/></p><p id="d64f" class="pw-post-body-paragraph jw jx iq jy b jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ij bi translated">对于本教程，我们使用BDD100K道路物体检测数据集— <a class="ae lg" href="https://www.kaggle.com/solesensei/solesensei_bdd100k" rel="noopener ugc nofollow" target="_blank">信用</a></p><p id="1d0b" class="pw-post-body-paragraph jw jx iq jy b jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ij bi translated">Github上的这个<a class="ae lg" href="https://github.com/Tessellate-Imaging/Monk_Object_Detection/blob/master/application_model_zoo/Example%20-%20BDD100K%20dataset%20with%20TensorRT%20optimization.ipynb" rel="noopener ugc nofollow" target="_blank"> jupyter笔记本</a>中提到了下载数据并将其转换为Pascal VOC格式的完整步骤</p></div><div class="ab cl lh li hu lj" role="separator"><span class="lk bw bk ll lm ln"/><span class="lk bw bk ll lm ln"/><span class="lk bw bk ll lm"/></div><div class="ij ik il im in"><h1 id="a31a" class="lx ly iq bd lz ma mb mc md me mf mg mh mi mj mk ml mm mn mo mp mq mr ms mt mu bi translated">步骤3-系统参数设置</h1><p id="b747" class="pw-post-body-paragraph jw jx iq jy b jz mv kb kc kd mw kf kg kh mx kj kk kl my kn ko kp mz kr ks kt ij bi translated">★装载检测器</p><figure class="kv kw kx ky gt kz"><div class="bz fp l di"><div class="nu nv l"/></div></figure><p id="33c3" class="pw-post-body-paragraph jw jx iq jy b jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ij bi translated">★列出所有型号。目前支持26种不同的型号</p><figure class="kv kw kx ky gt kz gh gi paragraph-image"><div class="gh gi nx"><img src="../Images/a388210a61a9db40e65aac7b56158caa.png" data-original-src="https://miro.medium.com/v2/resize:fit:1116/format:webp/1*veS8fYVdKqJNUlhZCKesLA.png"/></div></figure><p id="7284" class="pw-post-body-paragraph jw jx iq jy b jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ij bi translated">★用参数设置训练和验证数据</p><p id="ae30" class="pw-post-body-paragraph jw jx iq jy b jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ij bi translated">*根据可用的GPU内存设置批量大小。24的大小非常适合带有V100 GPU (16 GB VRAM)的AWS p3.2x实例</p><figure class="kv kw kx ky gt kz"><div class="bz fp l di"><div class="nu nv l"/></div></figure><p id="b758" class="pw-post-body-paragraph jw jx iq jy b jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ij bi translated">★创建TF记录！！！</p><p id="a7a9" class="pw-post-body-paragraph jw jx iq jy b jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ij bi translated">*批量大小、类别数量、tf_record详细信息都将自动保存在配置文件中</p><figure class="kv kw kx ky gt kz"><div class="bz fp l di"><div class="nu nv l"/></div></figure><p id="aea6" class="pw-post-body-paragraph jw jx iq jy b jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ij bi translated">★从型号列表中选择型号</p><p id="e609" class="pw-post-body-paragraph jw jx iq jy b jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ij bi translated">*在本例中，我们选择了带有<a class="ae lg" href="https://www.google.com/url?sa=t&amp;rct=j&amp;q=&amp;esrc=s&amp;source=web&amp;cd=&amp;cad=rja&amp;uact=8&amp;ved=2ahUKEwiN26vOqtTrAhVTAXIKHR4tBdIQFjABegQIAxAB&amp;url=https%3A%2F%2Ftowardsdatascience.com%2Freview-fpn-feature-pyramid-network-object-detection-262fc7482610&amp;usg=AOvVaw3eJJIumHSndicBMkalNev1" rel="noopener ugc nofollow" target="_blank">特征金字塔网络</a>的<a class="ae lg" href="https://www.google.com/url?sa=t&amp;rct=j&amp;q=&amp;esrc=s&amp;source=web&amp;cd=&amp;cad=rja&amp;uact=8&amp;ved=2ahUKEwiQv_b9qtTrAhVBWX0KHaItBMYQFjAEegQIBRAB&amp;url=https%3A%2F%2Fmedium.com%2Finveterate-learner%2Freal-time-object-detection-part-1-understanding-ssd-65797a5e675b&amp;usg=AOvVaw2sMnVDScmyiKp-gEbaVVMO" rel="noopener ugc nofollow" target="_blank"> SSD </a> <a class="ae lg" href="https://www.google.com/url?sa=t&amp;rct=j&amp;q=&amp;esrc=s&amp;source=web&amp;cd=&amp;cad=rja&amp;uact=8&amp;ved=2ahUKEwj-_I3xqtTrAhXEbn0KHa99BjAQFjABegQIBRAB&amp;url=https%3A%2F%2Fblog.exxactcorp.com%2Fdeep-learning-with-tensorflow-training-resnet-50-from-scratch-using-the-imagenet-dataset%2F&amp;usg=AOvVaw14ccFgXnzuWW2zf1cjm20M" rel="noopener ugc nofollow" target="_blank"> Resnet50 </a>，它接收形状为640x604x3的输入图像(RGB图像)</p><figure class="kv kw kx ky gt kz"><div class="bz fp l di"><div class="nu nv l"/></div></figure><p id="78c9" class="pw-post-body-paragraph jw jx iq jy b jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ij bi translated">★设置所有其他超参数</p><p id="ee6f" class="pw-post-body-paragraph jw jx iq jy b jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ij bi translated">*设置训练步数—对于大型数据集，理想值是训练100K步数</p><p id="7f58" class="pw-post-body-paragraph jw jx iq jy b jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ij bi translated">*所有模型的最佳初始学习率可以设置为0.01左右，而ssd_mobilenet_v2和faster_rcnn_inception模型可以采用更高的学习率。</p><figure class="kv kw kx ky gt kz"><div class="bz fp l di"><div class="nu nv l"/></div></figure><p id="89c8" class="pw-post-body-paragraph jw jx iq jy b jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ij bi translated">★设置输出推理图路径和TensorRT参数</p><p id="12e2" class="pw-post-body-paragraph jw jx iq jy b jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ij bi translated">* TensorRT优化是可选的</p><p id="a537" class="pw-post-body-paragraph jw jx iq jy b jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ij bi translated">* TensorRT优化支持3种类型的优化——FP32、FP16和INT8</p><p id="47b0" class="pw-post-body-paragraph jw jx iq jy b jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ij bi translated">*浮点量化对于像Jetson Nano这样的板很有用。</p><p id="8c4f" class="pw-post-body-paragraph jw jx iq jy b jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ij bi translated">* INT8优化在创建时构建，而其他两个优化在部署机器上构建。构建很容易被认为是对模型进行的实际优化。上面提到的TensorRT的一个问题是，它应该构建在您希望部署它的机器上，或者应该构建在具有相同TensorRT库和Cuda计算功能的机器上。</p><p id="d1bc" class="pw-post-body-paragraph jw jx iq jy b jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ij bi translated">*因此，建议在部署计算机上运行INT8优化。</p><p id="6a5a" class="pw-post-body-paragraph jw jx iq jy b jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ij bi translated">*因为，对于这个例子，我们在AWS P3.2x实例上训练和运行推理，所以我们采用INT8量化。</p><figure class="kv kw kx ky gt kz"><div class="bz fp l di"><div class="nu nv l"/></div></figure></div><div class="ab cl lh li hu lj" role="separator"><span class="lk bw bk ll lm ln"/><span class="lk bw bk ll lm ln"/><span class="lk bw bk ll lm"/></div><div class="ij ik il im in"><h1 id="00aa" class="lx ly iq bd lz ma mb mc md me mf mg mh mi mj mk ml mm mn mo mp mq mr ms mt mu bi translated">步骤4—培训和模型导出</h1><p id="7574" class="pw-post-body-paragraph jw jx iq jy b jz mv kb kc kd mw kf kg kh mx kj kk kl my kn ko kp mz kr ks kt ij bi translated">★要训练运行以下命令。</p><p id="c9cf" class="pw-post-body-paragraph jw jx iq jy b jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ij bi translated">*由于它运行一个TF引擎，在jupyter notebook上作为一个包装运行它会导致系统退出。</p><p id="aee0" class="pw-post-body-paragraph jw jx iq jy b jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ij bi translated">*因此，提供了一个名为train.py的脚本。</p><p id="856b" class="pw-post-body-paragraph jw jx iq jy b jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ij bi translated">*一旦训练完成，检查点文件将保存在您在hyperparameter setup命令中提到的output_directory中。</p><figure class="kv kw kx ky gt kz"><div class="bz fp l di"><div class="nu nv l"/></div></figure><p id="c188" class="pw-post-body-paragraph jw jx iq jy b jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ij bi translated">★将训练好的模型导出到saved_model("。pb ")格式运行以下命令。</p><p id="f0b8" class="pw-post-body-paragraph jw jx iq jy b jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ij bi translated">*由于它运行一个TF引擎，在jupyter notebook上作为一个包装运行它会导致系统退出。</p><p id="310c" class="pw-post-body-paragraph jw jx iq jy b jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ij bi translated">*因此，提供了一个名为export.py的脚本。</p><p id="c874" class="pw-post-body-paragraph jw jx iq jy b jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ij bi translated">*产出。pb文件将保存在您在export_params setup命令中设置的export_directory中。</p><figure class="kv kw kx ky gt kz"><div class="bz fp l di"><div class="nu nv l"/></div></figure></div><div class="ab cl lh li hu lj" role="separator"><span class="lk bw bk ll lm ln"/><span class="lk bw bk ll lm ln"/><span class="lk bw bk ll lm"/></div><div class="ij ik il im in"><h1 id="6c6a" class="lx ly iq bd lz ma mb mc md me mf mg mh mi mj mk ml mm mn mo mp mq mr ms mt mu bi translated">步骤5 —优化前的推理和速度基准</h1><p id="884e" class="pw-post-body-paragraph jw jx iq jy b jz mv kb kc kd mw kf kg kh mx kj kk kl my kn ko kp mz kr ks kt ij bi translated">★装载检测器</p><figure class="kv kw kx ky gt kz"><div class="bz fp l di"><div class="nu nv l"/></div></figure><p id="2f34" class="pw-post-body-paragraph jw jx iq jy b jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ij bi translated">★加载训练好的模型</p><p id="640e" class="pw-post-body-paragraph jw jx iq jy b jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ij bi translated">*在导出的目录中加载表单saved_model</p><figure class="kv kw kx ky gt kz"><div class="bz fp l di"><div class="nu nv l"/></div></figure><p id="3b4b" class="pw-post-body-paragraph jw jx iq jy b jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ij bi translated">★对单个图像进行推理</p><figure class="kv kw kx ky gt kz"><div class="bz fp l di"><div class="nu nv l"/></div></figure><figure class="kv kw kx ky gt kz gh gi paragraph-image"><div role="button" tabindex="0" class="la lb di lc bf ld"><div class="gh gi ku"><img src="../Images/901a47e556cc410487a3c50173ac5a91.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*IykLuMqEf5QdPOgOa6BEeQ.png"/></div></div></figure><p id="d6b1" class="pw-post-body-paragraph jw jx iq jy b jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ij bi translated">★运行基准速度分析</p><p id="5a42" class="pw-post-body-paragraph jw jx iq jy b jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ij bi translated">*未经优化，这些是AWS P3.2x实例的结果</p><pre class="kv kw kx ky gt na nb nc nd aw ne bi"><span id="1d57" class="nf ly iq nb b gy ng nh l ni nj">Average Image loading time : 0.0121 sec<br/>Average Inference time     : 0.0347 sec<br/>Result extraction time     : 0.0848 sec<br/>total_repetitions          : 100<br/>total_time                 : 3.4712 sec<br/>images_per_sec             : 28<br/>latency_mean               : 34.7123 ms<br/>latency_median             : 34.9255 ms<br/>latency_min                : 32.2594 ms</span></pre><figure class="kv kw kx ky gt kz"><div class="bz fp l di"><div class="nu nv l"/></div></figure></div><div class="ab cl lh li hu lj" role="separator"><span class="lk bw bk ll lm ln"/><span class="lk bw bk ll lm ln"/><span class="lk bw bk ll lm"/></div><div class="ij ik il im in"><h1 id="48ff" class="lx ly iq bd lz ma mb mc md me mf mg mh mi mj mk ml mm mn mo mp mq mr ms mt mu bi translated">步骤6 —使用TensorRT-6进行优化</h1><p id="cdcf" class="pw-post-body-paragraph jw jx iq jy b jz mv kb kc kd mw kf kg kh mx kj kk kl my kn ko kp mz kr ks kt ij bi translated">★安装TensorRT6</p><p id="4604" class="pw-post-body-paragraph jw jx iq jy b jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ij bi translated">*访问<a class="ae lg" href="https://developer.nvidia.com/tensorrt" rel="noopener ugc nofollow" target="_blank"> Nvidia TensorRT </a>页面下载TRT6</p><p id="4b89" class="pw-post-body-paragraph jw jx iq jy b jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ij bi translated">*根据操作系统和CUDA版本，从TensorRT网站下载软件包。</p><figure class="kv kw kx ky gt kz gh gi paragraph-image"><div role="button" tabindex="0" class="la lb di lc bf ld"><div class="gh gi ny"><img src="../Images/131fd1ee797711b3d1d8e67aeea8340f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*UMWDXrtgsXYdhZEQFfe0cQ.png"/></div></div></figure><figure class="kv kw kx ky gt kz"><div class="bz fp l di"><div class="nu nv l"/></div></figure><p id="9b5a" class="pw-post-body-paragraph jw jx iq jy b jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ij bi translated">★要使用TensorRT进行优化，请运行以下命令。</p><p id="86ab" class="pw-post-body-paragraph jw jx iq jy b jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ij bi translated">*由于它运行一个TF引擎，在jupyter notebook上作为一个包装运行它会导致系统退出。</p><p id="3811" class="pw-post-body-paragraph jw jx iq jy b jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ij bi translated">*因此，提供了一个名为optimize.py的脚本。</p><p id="1848" class="pw-post-body-paragraph jw jx iq jy b jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ij bi translated">*在导出的已保存模型上运行它</p><figure class="kv kw kx ky gt kz"><div class="bz fp l di"><div class="nu nv l"/></div></figure></div><div class="ab cl lh li hu lj" role="separator"><span class="lk bw bk ll lm ln"/><span class="lk bw bk ll lm ln"/><span class="lk bw bk ll lm"/></div><div class="ij ik il im in"><h1 id="b2ea" class="lx ly iq bd lz ma mb mc md me mf mg mh mi mj mk ml mm mn mo mp mq mr ms mt mu bi translated">步骤7—优化后的推理和速度基准</h1><p id="5c2e" class="pw-post-body-paragraph jw jx iq jy b jz mv kb kc kd mw kf kg kh mx kj kk kl my kn ko kp mz kr ks kt ij bi translated">★装载检测器</p><figure class="kv kw kx ky gt kz"><div class="bz fp l di"><div class="nu nv l"/></div></figure><p id="2709" class="pw-post-body-paragraph jw jx iq jy b jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ij bi translated">★加载训练好的模型</p><p id="d3ed" class="pw-post-body-paragraph jw jx iq jy b jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ij bi translated">*从优化的saved_model加载</p><figure class="kv kw kx ky gt kz"><div class="bz fp l di"><div class="nu nv l"/></div></figure><p id="ad12" class="pw-post-body-paragraph jw jx iq jy b jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ij bi translated">★对单个图像进行推理</p><figure class="kv kw kx ky gt kz"><div class="bz fp l di"><div class="nu nv l"/></div></figure><figure class="kv kw kx ky gt kz gh gi paragraph-image"><div role="button" tabindex="0" class="la lb di lc bf ld"><div class="gh gi ku"><img src="../Images/2045420d311554f781b347b251c3e5da.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*HIK3_lCcXOwgurD5a-hxeA.png"/></div></div></figure><p id="261c" class="pw-post-body-paragraph jw jx iq jy b jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ij bi translated">★运行基准速度分析</p><p id="0c90" class="pw-post-body-paragraph jw jx iq jy b jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ij bi translated">*未经优化，这些是AWS P3.2x实例的结果</p><pre class="kv kw kx ky gt na nb nc nd aw ne bi"><span id="f633" class="nf ly iq nb b gy ng nh l ni nj">Average Image loading time : 0.0117 sec<br/>Average Inference time     : 0.0169 sec<br/>Result extraction time     : 0.0822 sec<br/>total_repetitions          : 100<br/>total_time                 : 1.6907 sec<br/>images_per_sec             : 59<br/>latency_mean               : 16.9070 ms<br/>latency_median             : 16.8167 ms<br/>latency_min                : 16.2708 ms</span></pre><figure class="kv kw kx ky gt kz"><div class="bz fp l di"><div class="nu nv l"/></div></figure></div><div class="ab cl lh li hu lj" role="separator"><span class="lk bw bk ll lm ln"/><span class="lk bw bk ll lm ln"/><span class="lk bw bk ll lm"/></div><div class="ij ik il im in"><h1 id="4a90" class="lx ly iq bd lz ma mb mc md me mf mg mh mi mj mk ml mm mn mo mp mq mr ms mt mu bi translated">结论</h1><p id="ba80" class="pw-post-body-paragraph jw jx iq jy b jz mv kb kc kd mw kf kg kh mx kj kk kl my kn ko kp mz kr ks kt ij bi translated">使用Monk对象检测库，您可以轻松地</p><p id="4458" class="pw-post-body-paragraph jw jx iq jy b jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ij bi translated">★将自定义数据集转换为tf记录<br/> ★使用pythonic语法更新配置文件<br/> ★训练引擎并导出为不同的推理格式<br/> ★使用检查点或保存的模型格式进行推理<br/> ★使用TensorRT引擎优化模型以实现更快的推理<br/> ★ <strong class="jy ja">每秒处理的优化后图像几乎翻了一番</strong></p></div><div class="ab cl lh li hu lj" role="separator"><span class="lk bw bk ll lm ln"/><span class="lk bw bk ll lm ln"/><span class="lk bw bk ll lm"/></div><div class="ij ik il im in"><p id="45c3" class="pw-post-body-paragraph jw jx iq jy b jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ij bi translated">在<a class="ae lg" href="https://github.com/Tessellate-Imaging/Monk_Object_Detection" rel="noopener ugc nofollow" target="_blank"> Monk对象检测库</a>的<a class="ae lg" href="https://github.com/Tessellate-Imaging/Monk_Object_Detection/blob/master/application_model_zoo/Example%20-%20BDD100K%20dataset%20with%20TensorRT%20optimization.ipynb" rel="noopener ugc nofollow" target="_blank"> GitHub </a>上可以获得全部代码</p><p id="c6f7" class="pw-post-body-paragraph jw jx iq jy b jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ij bi translated">编码快乐！！</p></div><div class="ab cl lh li hu lj" role="separator"><span class="lk bw bk ll lm ln"/><span class="lk bw bk ll lm ln"/><span class="lk bw bk ll lm"/></div><div class="ij ik il im in"><h1 id="8f4f" class="lx ly iq bd lz ma mb mc md me mf mg mh mi mj mk ml mm mn mo mp mq mr ms mt mu bi translated"><strong class="ak">附录— 1 </strong></h1><p id="a945" class="pw-post-body-paragraph jw jx iq jy b jz mv kb kc kd mw kf kg kh mx kj kk kl my kn ko kp mz kr ks kt ij bi translated">更多关于<strong class="jy ja"> </strong> <a class="ae lg" href="https://github.com/Tessellate-Imaging/Monk_Object_Detection" rel="noopener ugc nofollow" target="_blank"> <strong class="jy ja">和尚对象检测库</strong> </a></p><figure class="kv kw kx ky gt kz gh gi paragraph-image"><div role="button" tabindex="0" class="la lb di lc bf ld"><div class="gh gi nz"><img src="../Images/7d96706a615152128c44585082951f8b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*aeJLgRpDM4cfZ4E90Drigw.png"/></div></div></figure><figure class="kv kw kx ky gt kz gh gi paragraph-image"><div class="gh gi oa"><img src="../Images/a8ef95ad1870c81c3d558658178e2bae.png" data-original-src="https://miro.medium.com/v2/resize:fit:1042/format:webp/1*vNL-fgcR03-dQSUZfO00qg.png"/></div></figure></div></div>    
</body>
</html>