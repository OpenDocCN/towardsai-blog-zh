<html>
<head>
<title>Digit Classification using Tensorflow, Keras</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">使用张量流的数字分类，Keras</h1>
<blockquote>原文：<a href="https://pub.towardsai.net/digit-classification-using-tensorflow-keras-db16f2ea321e?source=collection_archive---------1-----------------------#2020-07-26">https://pub.towardsai.net/digit-classification-using-tensorflow-keras-db16f2ea321e?source=collection_archive---------1-----------------------#2020-07-26</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><h2 id="a99e" class="ir is it bd b dl iu iv iw ix iy iz dk ja translated" aria-label="kicker paragraph"><a class="ae ep" href="https://towardsai.net/p/category/machine-learning/deep-learning" rel="noopener ugc nofollow" target="_blank">深度学习</a></h2><div class=""/><div class=""><h2 id="2202" class="pw-subtitle-paragraph jz jc it bd b ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq dk translated">全部代码可在我的Github repo 的<a class="ae kr" href="https://github.com/arditoibryan/Projects/tree/master/20200724_Image_Classification" rel="noopener ugc nofollow" target="_blank">获得。来源可以在</a><a class="ae kr" href="https://www.sitepoint.com/keras-digit-recognition-tutorial/" rel="noopener ugc nofollow" target="_blank">网站</a>上找到。</h2></div><p id="8e8d" class="pw-post-body-paragraph ks kt it ku b kv kw kd kx ky kz kg la lb lc ld le lf lg lh li lj lk ll lm ln im bi translated">当开始在卷积神经网络上工作时，数字分类是一个经典的练习。深度学习在图像分类上的表现令人难以置信。我曾在网上搜索过类似的教程，但它们中的许多都没有使用标准化的数据集，其他的在代码中有错误或者已经过时，所以我从现有的一个教程中取了一些代码来编写这个详细的指南。</p><figure class="lp lq lr ls gt lt gh gi paragraph-image"><div role="button" tabindex="0" class="lu lv di lw bf lx"><div class="gh gi lo"><img src="../Images/c3b8a963d73d29f4c876f037bd3a3035.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*4MrKoe1m1OKUJAlg-yTlLQ.png"/></div></div><figcaption class="ma mb gj gh gi mc md bd b be z dk translated">Mnist数据集中的数字</figcaption></figure><p id="7a10" class="pw-post-body-paragraph ks kt it ku b kv kw kd kx ky kz kg la lb lc ld le lf lg lh li lj lk ll lm ln im bi translated">在整篇文章中，我将使用由28x28位数字组成的mnist数据集。如果要进行图像分类(比如说猫vs狗)，可以使用相同的代码作为基础(虽然这个代码处理的是灰度图像，但还不能适应RGB)。</p><h2 id="8fbc" class="me mf it bd mg mh mi dn mj mk ml dp mm lb mn mo mp lf mq mr ms lj mt mu mv iz bi translated">导入库</h2><pre class="lp lq lr ls gt mw mx my mz aw na bi"><span id="fe91" class="me mf it mx b gy nb nc l nd ne">from keras.datasets import mnist<br/>%matplotlib inline<br/>import matplotlib.pyplot as plt</span><span id="e95c" class="me mf it mx b gy nf nc l nd ne">Output: Using TensorFlow backend</span></pre><h2 id="b89b" class="me mf it bd mg mh mi dn mj mk ml dp mm lb mn mo mp lf mq mr ms lj mt mu mv iz bi translated">导入数据</h2><p id="3a05" class="pw-post-body-paragraph ks kt it ku b kv ng kd kx ky nh kg la lb ni ld le lf nj lh li lj nk ll lm ln im bi translated">我可以访问这个数据集的最简单的方法是通过访问<strong class="ku jd"> mnist库</strong>。数据集已经被拆分，可以在四个分区中使用。</p><pre class="lp lq lr ls gt mw mx my mz aw na bi"><span id="4dee" class="me mf it mx b gy nb nc l nd ne">(X_train, y_train), (X_test, y_test) = mnist.load_data()<br/>print(X_train.shape)<br/>print(X_test.shape)</span><span id="0cd1" class="me mf it mx b gy nf nc l nd ne">Output:<br/>(60000, 28, 28)<br/>(10000, 28, 28)</span></pre><p id="e204" class="pw-post-body-paragraph ks kt it ku b kv kw kd kx ky kz kg la lb lc ld le lf lg lh li lj lk ll lm ln im bi translated">在检查了训练和测试分区的形状之后，整个数据集由总共70，000个数字28x28组成。我将使用60.000来训练AI，其余的数据集来衡量准确性。</p><h2 id="be3a" class="me mf it bd mg mh mi dn mj mk ml dp mm lb mn mo mp lf mq mr ms lj mt mu mv iz bi translated">显示数据集中的图像</h2><p id="852e" class="pw-post-body-paragraph ks kt it ku b kv ng kd kx ky nh kg la lb ni ld le lf nj lh li lj nk ll lm ln im bi translated">在开始创建模型之前，我想知道我正在使用哪种数据。本质上，我将所有特征(图像)存储在<strong class="ku jd"> X </strong>数据集中(训练和测试)，而所有标签存储在<strong class="ku jd"> y </strong>数据集中(训练和测试)。</p><pre class="lp lq lr ls gt mw mx my mz aw na bi"><span id="851d" class="me mf it mx b gy nb nc l nd ne">#show one image with label<br/>#print(y_train[0]) label<br/>plt.imshow(X_train[0], cmap='Greys') #feature/image<br/>plt.show()</span></pre><figure class="lp lq lr ls gt lt gh gi paragraph-image"><div class="gh gi nl"><img src="../Images/a4a4302fb4b7632ffc683b504f45f111.png" data-original-src="https://miro.medium.com/v2/resize:fit:624/format:webp/1*kAEZAITQ_scukVco5pWV0Q.png"/></div><figcaption class="ma mb gj gh gi mc md bd b be z dk translated">X_train[0]</figcaption></figure><h2 id="3350" class="me mf it bd mg mh mi dn mj mk ml dp mm lb mn mo mp lf mq mr ms lj mt mu mv iz bi translated">预处理</h2><p id="b91f" class="pw-post-body-paragraph ks kt it ku b kv ng kd kx ky nh kg la lb ni ld le lf nj lh li lj nk ll lm ln im bi translated">预处理阶段允许我为CNN(卷积神经网络)准备数据。我将首先必须重塑数据添加一个额外的维度，然后将其规范化。</p><pre class="lp lq lr ls gt mw mx my mz aw na bi"><span id="036f" class="me mf it mx b gy nb nc l nd ne">#save in the right format for CNN input<br/>X_train = X_train.reshape(60000, 28, 28, 1)<br/>X_test = X_test.reshape(10000, 28, 28, 1)<br/>X_train.shape</span></pre><p id="d70c" class="pw-post-body-paragraph ks kt it ku b kv kw kd kx ky kz kg la lb lc ld le lf lg lh li lj lk ll lm ln im bi translated">为了规范化数据，我必须将它转换成浮点类型的numpy数组。</p><pre class="lp lq lr ls gt mw mx my mz aw na bi"><span id="f3cc" class="me mf it mx b gy nb nc l nd ne">#normalize<br/>import numpy as np<br/>X_train = np.array(X_train, dtype=np.float64)<br/>X_test = np.array(X_test, dtype=np.float64)<br/>X_train /= 255<br/>X_test /= 255</span></pre><h2 id="74f3" class="me mf it bd mg mh mi dn mj mk ml dp mm lb mn mo mp lf mq mr ms lj mt mu mv iz bi translated">创建模型</h2><p id="d360" class="pw-post-body-paragraph ks kt it ku b kv ng kd kx ky nh kg la lb ni ld le lf nj lh li lj nk ll lm ln im bi translated">我从这个来源得到了这个模型。显而易见，主要开发人员已经进行了大量调整，以确定最佳超参数。</p><pre class="lp lq lr ls gt mw mx my mz aw na bi"><span id="83c1" class="me mf it mx b gy nb nc l nd ne">import tensorflow<br/>from keras.models import Sequential<br/>from keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPooling2D</span><span id="85a0" class="me mf it mx b gy nf nc l nd ne">model = Sequential()<br/>model.add(Conv2D(32, kernel_size=(3, 3),<br/>     activation='relu',<br/>     input_shape=(28, 28, 1))) #image size<br/>model.add(Conv2D(64, (3, 3), activation='relu'))<br/>model.add(MaxPooling2D(pool_size=(2, 2)))<br/>model.add(Dropout(0.25))<br/>model.add(Flatten())<br/>model.add(Dense(128, activation='relu'))<br/>model.add(Dropout(0.5))<br/>model.add(Dense(10, activation='softmax')) #number of classes</span><span id="0ffb" class="me mf it mx b gy nf nc l nd ne">model.compile(loss='sparse_categorical_crossentropy',<br/>      optimizer='adam',<br/>      metrics=['accuracy'])</span><span id="8b9c" class="me mf it mx b gy nf nc l nd ne">batch_size = 128<br/>epochs = 10</span><span id="df48" class="me mf it mx b gy nf nc l nd ne">model.fit(X_train, y_train,<br/>          batch_size=batch_size,<br/>          epochs=epochs,<br/>          verbose=2,<br/>          validation_data=(X_test, y_test))</span><span id="9397" class="me mf it mx b gy nf nc l nd ne">score = model.evaluate(X_test, y_test, verbose=0)<br/>print('Test loss:', score[0])<br/>print('Test accuracy:', score[1])</span></pre><h2 id="50d4" class="me mf it bd mg mh mi dn mj mk ml dp mm lb mn mo mp lf mq mr ms lj mt mu mv iz bi translated">培训产出</h2><pre class="lp lq lr ls gt mw mx my mz aw na bi"><span id="8fc2" class="me mf it mx b gy nb nc l nd ne">Train on 60000 samples, validate on 10000 samples<br/>Epoch 1/10<br/> - 152s - loss: 0.2349 - accuracy: 0.9284 - val_loss: 0.0476 - val_accuracy: 0.9844<br/>Epoch 2/10<br/> - 141s - loss: 0.0860 - accuracy: 0.9742 - val_loss: 0.0369 - val_accuracy: 0.9873<br/>Epoch 3/10<br/> - 148s - loss: 0.0602 - accuracy: 0.9814 - val_loss: 0.0340 - val_accuracy: 0.9886<br/>Epoch 4/10<br/> - 141s - loss: 0.0523 - accuracy: 0.9835 - val_loss: 0.0302 - val_accuracy: 0.9899<br/>Epoch 5/10<br/> - 140s - loss: 0.0436 - accuracy: 0.9866 - val_loss: 0.0313 - val_accuracy: 0.9899<br/>Epoch 6/10<br/> - 141s - loss: 0.0377 - accuracy: 0.9872 - val_loss: 0.0311 - val_accuracy: 0.9907<br/>Epoch 7/10<br/> - 140s - loss: 0.0343 - accuracy: 0.9889 - val_loss: 0.0296 - val_accuracy: 0.9911<br/>Epoch 8/10<br/> - 140s - loss: 0.0295 - accuracy: 0.9902 - val_loss: 0.0279 - val_accuracy: 0.9915<br/>Epoch 9/10<br/> - 141s - loss: 0.0246 - accuracy: 0.9919 - val_loss: 0.0269 - val_accuracy: 0.9917<br/>Epoch 10/10<br/> - 140s - loss: 0.0232 - accuracy: 0.9926 - val_loss: 0.0304 - val_accuracy: 0.9913<br/>Test loss: 0.030353095355434654<br/>Test accuracy: 0.9912999868392944</span></pre><p id="1273" class="pw-post-body-paragraph ks kt it ku b kv kw kd kx ky kz kg la lb lc ld le lf lg lh li lj lk ll lm ln im bi translated">正如你所看到的，这个模型有99%的准确率。</p><h2 id="3b2f" class="me mf it bd mg mh mi dn mj mk ml dp mm lb mn mo mp lf mq mr ms lj mt mu mv iz bi translated">预言；预测；预告</h2><p id="4186" class="pw-post-body-paragraph ks kt it ku b kv ng kd kx ky nh kg la lb ni ld le lf nj lh li lj nk ll lm ln im bi translated">使用下面的代码，我可以在测试数据集中输入任何数字并进行预测。</p><pre class="lp lq lr ls gt mw mx my mz aw na bi"><span id="7ae0" class="me mf it mx b gy nb nc l nd ne">#predict digit in x_train<br/>prediction = model.predict(X_test[0].reshape(1, 28, 28, 1))<br/>print(prediction.argmax())</span></pre><h2 id="534a" class="me mf it bd mg mh mi dn mj mk ml dp mm lb mn mo mp lf mq mr ms lj mt mu mv iz bi translated">为什么制作这个教程…</h2><p id="4e8d" class="pw-post-body-paragraph ks kt it ku b kv ng kd kx ky nh kg la lb ni ld le lf nj lh li lj nk ll lm ln im bi translated">如果网上有这么多？我花了一段时间才找到合适的。例如，如果您遵循我提供的原始来源的所有说明，CNN将输出一个错误。事实上，标签(可能是因为早期的TensorFlow版本)不能one_hot编码，但它们必须是数字。</p><p id="efe7" class="pw-post-body-paragraph ks kt it ku b kv kw kd kx ky kz kg la lb lc ld le lf lg lh li lj lk ll lm ln im bi translated">三言两语，我的代码是最新的，会节省你宝贵的时间。</p></div></div>    
</body>
</html>