<html>
<head>
<title>About Ensemble Techniques in ML.</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">关于ML中的合奏技术。</h1>
<blockquote>原文：<a href="https://pub.towardsai.net/about-ensemble-techniques-in-ml-6bf402bff620?source=collection_archive---------2-----------------------#2022-02-20">https://pub.towardsai.net/about-ensemble-techniques-in-ml-6bf402bff620?source=collection_archive---------2-----------------------#2022-02-20</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><div class=""><h2 id="2be0" class="pw-subtitle-paragraph jn ip iq bd b jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke dk translated">你从概念上理解ML系综技术了吗？</h2></div><p id="ed1e" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">这篇文章谈论了不同的集成技术，一个ML爱好者应该知道这些技术来提高他们模型的结果。这是一篇通读的文章，只关注概念上的理解(把代码留到以后)。</p><figure class="lc ld le lf gt lg gh gi paragraph-image"><div role="button" tabindex="0" class="lh li di lj bf lk"><div class="gh gi lb"><img src="../Images/f3c5a90895bacee686e26a479dd05944.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*xl_l1RHdl64NQp8a"/></div></div><figcaption class="ln lo gj gh gi lp lq bd b be z dk translated">在<a class="ae lr" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上由<a class="ae lr" href="https://unsplash.com/@gwundrig?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">Manuel n Geli</a>拍摄的照片</figcaption></figure><p id="6f46" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">如果你有一个采访或演示即将到来，或者如果你在这里了解合奏技术在几分钟内，那么这个职位是你的理想选择。所以现在开始…</p><h2 id="99dd" class="ls lt iq bd lu lv lw dn lx ly lz dp ma ko mb mc md ks me mf mg kw mh mi mj mk bi translated">“合奏”的嗡嗡声</h2><p id="63f3" class="pw-post-body-paragraph kf kg iq kh b ki ml jr kk kl mm ju kn ko mn kq kr ks mo ku kv kw mp ky kz la ij bi translated">在过去的20年里，“<em class="mq">合奏</em>一直是一个流行语，不是因为它的语义——“一群音乐家<em class="mq">”，而是因为数据/ML科学家。这是大多数科学家的首选解决方案，因为他们从这些技术中获益匪浅。</em></p><h2 id="5bb4" class="ls lt iq bd lu lv lw dn lx ly lz dp ma ko mb mc md ks me mf mg kw mh mi mj mk bi translated">什么是合奏技巧？</h2><p id="194a" class="pw-post-body-paragraph kf kg iq kh b ki ml jr kk kl mm ju kn ko mn kq kr ks mo ku kv kw mp ky kz la ij bi translated">作为一名数据科学家，您手头有一些技术可以用来提高模型的性能。即<strong class="kh ir"><em class="mq"/></strong><strong class="kh ir"><em class="mq">装袋</em></strong><strong class="kh ir"><em class="mq">堆垛</em></strong><strong class="kh ir"><em class="mq">级联</em> </strong>。使用来自多个基线模型的“组合”结果，我们可以通过最终模型实现更高的“广义”性能。</p><h2 id="fdb2" class="ls lt iq bd lu lv lw dn lx ly lz dp ma ko mb mc md ks me mf mg kw mh mi mj mk bi translated">集成技术如何提高模型性能？</h2><p id="013e" class="pw-post-body-paragraph kf kg iq kh b ki ml jr kk kl mm ju kn ko mn kq kr ks mo ku kv kw mp ky kz la ij bi translated">这里有一个很好的类比来回答这个问题:</p><p id="2da0" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">假设你在一家投资公司工作，你必须决定是否投资一家特定的公司。</p><ul class=""><li id="0946" class="mr ms iq kh b ki kj kl km ko mt ks mu kw mv la mw mx my mz bi translated">去找你公司里最好的股票市场顾问，问问他是否应该投资a公司。假设他说</li></ul><blockquote class="na nb nc"><p id="4790" class="kf kg mq kh b ki kj jr kk kl km ju kn nd kp kq kr ne kt ku kv nf kx ky kz la ij bi translated">我为这家公司做基本面分析。这家公司成功的可能性是80%。</p></blockquote><p id="ee3c" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">因为80%的信心对于巨额投资来说是不够的，下面是你接下来可以做的事情:</p><ul class=""><li id="2e8a" class="mr ms iq kh b ki kj kl km ko mt ks mu kw mv la mw mx my mz bi translated">去找公司里的另一位股市顾问，听听她对投资的看法。假设她说，</li></ul><blockquote class="na nb nc"><p id="f100" class="kf kg mq kh b ki kj jr kk kl km ju kn nd kp kq kr ne kt ku kv nf kx ky kz la ij bi translated">我对这家公司进行了技术分析，这家公司成功的可能性是85%。</p></blockquote><h2 id="998a" class="ls lt iq bd lu lv lw dn lx ly lz dp ma ko mb mc md ks me mf mg kw mh mi mj mk bi translated">这是否增加了你的信心？</h2><p id="8c7c" class="pw-post-body-paragraph kf kg iq kh b ki ml jr kk kl mm ju kn ko mn kq kr ks mo ku kv kw mp ky kz la ij bi translated">是啊！因为我们有两个最好的顾问说这家公司值得投资，至少有80%的机会。</p><p id="624c" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">现在，如果你有<strong class="kh ir"> <em class="mq">时间</em></strong><strong class="kh ir"><em class="mq">资源</em> </strong>得到一个第三/第四/第五……的意见，你一定会选择去追求。</p><p id="994c" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">将这个类比移动到ML领域，你的顾问是经过<strong class="kh ir">训练的</strong>基线模型、<strong class="kh ir">时间、</strong>和<strong class="kh ir">资源</strong>，他们拥有训练模型的时间和计算能力。你是决定是否投资的最终模型。</p><h2 id="13ae" class="ls lt iq bd lu lv lw dn lx ly lz dp ma ko mb mc md ks me mf mg kw mh mi mj mk bi translated">模型的“改进”性能意味着什么？</h2><p id="4f10" class="pw-post-body-paragraph kf kg iq kh b ki ml jr kk kl mm ju kn ko mn kq kr ks mo ku kv kw mp ky kz la ij bi translated">从广义上讲，它增加了模型的<strong class="kh ir"><em class="mq"/></strong>精度，降低了模型的<strong class="kh ir"> <em class="mq">偏差</em> </strong>和<strong class="kh ir"> <em class="mq">方差</em> </strong>。</p></div><div class="ab cl ng nh hu ni" role="separator"><span class="nj bw bk nk nl nm"/><span class="nj bw bk nk nl nm"/><span class="nj bw bk nk nl"/></div><div class="ij ik il im in"><p id="b80e" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">在继续学习技巧之前，请注意以下几点:</p><ul class=""><li id="1789" class="mr ms iq kh b ki kj kl km ko mt ks mu kw mv la mw mx my mz bi translated">集成技术涉及<strong class="kh ir">多个</strong>机器学习模型</li><li id="17c2" class="mr ms iq kh b ki nn kl no ko np ks nq kw nr la mw mx my mz bi translated">输入每个模型的数据可以是<strong class="kh ir">相同/不同的</strong>，这就引出了两种数据采样方法。</li></ul><h2 id="a869" class="ls lt iq bd lu lv lw dn lx ly lz dp ma ko mb mc md ks me mf mg kw mh mi mj mk bi translated">随机采样/混合训练数据</h2><p id="f719" class="pw-post-body-paragraph kf kg iq kh b ki ml jr kk kl mm ju kn ko mn kq kr ks mo ku kv kw mp ky kz la ij bi translated">传统的方法是使用整个训练数据在单个模型上进行训练/验证。</p><figure class="lc ld le lf gt lg gh gi paragraph-image"><div role="button" tabindex="0" class="lh li di lj bf lk"><div class="gh gi ns"><img src="../Images/fe90eea607d490022bbd8954dacc2b7c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*G_C9rI_UbNMIw9_h.png"/></div></div><figcaption class="ln lo gj gh gi lp lq bd b be z dk translated">来源:<a class="ae lr" href="https://www.researchgate.net/figure/Illustration-of-different-sampling-schemes-for-approximating-a-U-statistic-For_fig1_270824717" rel="noopener ugc nofollow" target="_blank">研究之门</a></figcaption></figure><p id="c5c6" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated"><em class="mq">集合</em>数据采样方式有以下几种:</p><ol class=""><li id="049c" class="mr ms iq kh b ki kj kl km ko mt ks mu kw mv la nt mx my mz bi translated"><strong class="kh ir">替换取样</strong></li></ol><ul class=""><li id="23a8" class="mr ms iq kh b ki kj kl km ko mt ks mu kw mv la mw mx my mz bi translated">允许从每个模型的全部训练数据中随机抽样一个子集。</li><li id="48d3" class="mr ms iq kh b ki nn kl no ko np ks nq kw nr la mw mx my mz bi translated">适用于大型数据集，在这种情况下，模型之间的数据协方差会更小。</li></ul><p id="3e70" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated"><strong class="kh ir"> 2。无替换取样</strong></p><ul class=""><li id="5ad7" class="mr ms iq kh b ki kj kl km ko mt ks mu kw mv la mw mx my mz bi translated">允许数据均匀地分布在基线模型中，这样任何模型都没有公共数据。</li><li id="dc50" class="mr ms iq kh b ki nn kl no ko np ks nq kw nr la mw mx my mz bi translated">适用于较小的数据集，在这种情况下，模型之间数据的结果协方差为0。</li></ul><p id="a2da" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated"><strong class="kh ir"> 3。伯努利采样:</strong></p><ul class=""><li id="fa64" class="mr ms iq kh b ki kj kl km ko mt ks mu kw mv la mw mx my mz bi translated">每个数据点都要经过伯努利试验，伯努利试验决定该数据点是否必须是样本的一部分。如果使用随机抽样，这不是特别有用。</li></ul></div><div class="ab cl ng nh hu ni" role="separator"><span class="nj bw bk nk nl nm"/><span class="nj bw bk nk nl nm"/><span class="nj bw bk nk nl"/></div><div class="ij ik il im in"><h1 id="540f" class="nu lt iq bd lu nv nw nx lx ny nz oa ma jw ob jx md jz oc ka mg kc od kd mj oe bi translated">已经简要介绍了技术！</h1><p id="1941" class="pw-post-body-paragraph kf kg iq kh b ki ml jr kk kl mm ju kn ko mn kq kr ks mo ku kv kw mp ky kz la ij bi translated">这是所有合奏技巧的概览图:</p><figure class="lc ld le lf gt lg gh gi paragraph-image"><div role="button" tabindex="0" class="lh li di lj bf lk"><div class="gh gi of"><img src="../Images/9eb5499399cc8c6c5ef3fd003af9dcec.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*vkx6ZZ0bmEIY5mUx4b8PRg.png"/></div></div><figcaption class="ln lo gj gh gi lp lq bd b be z dk translated">集成技术概述</figcaption></figure></div><div class="ab cl ng nh hu ni" role="separator"><span class="nj bw bk nk nl nm"/><span class="nj bw bk nk nl nm"/><span class="nj bw bk nk nl"/></div><div class="ij ik il im in"><h2 id="c139" class="ls lt iq bd lu lv lw dn lx ly lz dp ma ko mb mc md ks me mf mg kw mh mi mj mk bi translated">引导聚集</h2><figure class="lc ld le lf gt lg gh gi paragraph-image"><div role="button" tabindex="0" class="lh li di lj bf lk"><div class="gh gi og"><img src="../Images/4884aad353bbe5b95253501d0fd862cb.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*bX_0MFB6MN5WVo8tyfDfNg.png"/></div></div><figcaption class="ln lo gj gh gi lp lq bd b be z dk translated">图片来源:作者</figcaption></figure><p id="7b0c" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">这里有一点关于<strong class="kh ir">自举采样</strong>的步骤:</p><ul class=""><li id="e418" class="mr ms iq kh b ki kj kl km ko mt ks mu kw mv la mw mx my mz bi translated">随机样本<strong class="kh ir">用</strong>替换用作模型输入的数据子集。</li></ul><p id="5a8b" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">以下是完成<strong class="kh ir">聚合</strong>步骤的两种方法:</p><ul class=""><li id="e72b" class="mr ms iq kh b ki kj kl km ko mt ks mu kw mv la mw mx my mz bi translated"><strong class="kh ir">硬投票</strong>:输出所有预测标签的模式。对于分类任务非常有用。</li><li id="8552" class="mr ms iq kh b ki nn kl no ko np ks nq kw nr la mw mx my mz bi translated"><strong class="kh ir">聚合</strong>:输出所有模型结果的聚合。对回归有用。此外，我们还可以对不同模型的结果进行加权平均。</li></ul><p id="7015" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">以下是关于<strong class="kh ir">装袋</strong>的几点注意事项:</p><ul class=""><li id="2eea" class="mr ms iq kh b ki kj kl km ko mt ks mu kw mv la mw mx my mz bi translated">装袋可以<strong class="kh ir">减少</strong>方差而不影响模型的偏差。这是因为该技术中的自举采样和聚集步骤。</li><li id="ce5e" class="mr ms iq kh b ki nn kl no ko np ks nq kw nr la mw mx my mz bi translated">bagging优先选择<strong class="kh ir">低偏差</strong>和<strong class="kh ir">高方差</strong>模型作为学习器。鉴于前一点，偏差仍然很低，装袋后方差减少。</li><li id="b59a" class="mr ms iq kh b ki nn kl no ko np ks nq kw nr la mw mx my mz bi translated"><strong class="kh ir">低偏差</strong>模型包括<em class="mq">决策树</em>、<em class="mq"> KNN </em>和<em class="mq"> SVM </em>。</li></ul></div><div class="ab cl ng nh hu ni" role="separator"><span class="nj bw bk nk nl nm"/><span class="nj bw bk nk nl nm"/><span class="nj bw bk nk nl"/></div><div class="ij ik il im in"><h2 id="ceaf" class="ls lt iq bd lu lv lw dn lx ly lz dp ma ko mb mc md ks me mf mg kw mh mi mj mk bi translated">助推</h2><p id="f03f" class="pw-post-body-paragraph kf kg iq kh b ki ml jr kk kl mm ju kn ko mn kq kr ks mo ku kv kw mp ky kz la ij bi translated">提升包括用多个弱分类器创建一个强分类器。主要用于减少<strong class="kh ir"> <em class="mq">偏差</em> </strong>。</p><p id="2033" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">模型是按顺序训练的，<strong class="kh ir">难以</strong>并行训练，这意味着训练的时间复杂度很高。常见的增压技术简述如下:</p><p id="d916" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated"><strong class="kh ir">【AdaBoost】<br/></strong>为了增加一个模型的性能，我们<strong class="kh ir">增加</strong>误分类<strong class="kh ir">的权重/错误地</strong>预测数据。这个加权的数据在下一次迭代中作为输入提供给下一个学习者。</p><figure class="lc ld le lf gt lg gh gi paragraph-image"><div class="gh gi oh"><img src="../Images/790318dc5a46fdc3f4947df83f0d6ee1.png" data-original-src="https://miro.medium.com/v2/resize:fit:892/format:webp/0*vDBUqkriyakBWLb6.jpg"/></div><figcaption class="ln lo gj gh gi lp lq bd b be z dk translated">来源:<a class="ae lr" href="https://www.sciencedirect.com/science/article/pii/B9780128177365000090" rel="noopener ugc nofollow" target="_blank">科学直接</a></figcaption></figure><p id="42cb" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">因为错误分类的数据现在权重更大，所以模型现在将给予这些数据点更大的重要性，并且其预测正确的概率将增加。</p><p id="482a" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">最后，使用投票机制来决定所有组合模型(弱学习者和强学习者)的输出。</p><p id="fb14" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated"><strong class="kh ir">梯度提升<br/> </strong>在这种情况下，我们基于前一个学习器的<strong class="kh ir">残差</strong>来训练连续的学习器。这是通过将<strong class="kh ir">残差</strong>设置为用于训练新模型的<strong class="kh ir">目标标签</strong>来实现的。</p><figure class="lc ld le lf gt lg gh gi paragraph-image"><div role="button" tabindex="0" class="lh li di lj bf lk"><div class="gh gi oi"><img src="../Images/6a9875ab9e60efcabfda7297308d9bc3.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*SwcX6oSUYpGzP2uVgBTI4w.png"/></div></div><figcaption class="ln lo gj gh gi lp lq bd b be z dk translated">来源:<a class="ae lr" href="https://campus.datacamp.com/courses/machine-learning-with-tree-based-models-in-python/boosting?ex=5" rel="noopener ugc nofollow" target="_blank">数据营</a></figcaption></figure><p id="2722" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">在分类的情况下，残差是根据类的概率计算的。概率是根据赔率计算的。(<a class="ae lr" href="https://towardsdatascience.com/https-towardsdatascience-com-what-and-why-of-log-odds-64ba988bf704" rel="noopener" target="_blank">参考</a>)</p><p id="a8bc" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated"><strong class="kh ir"> Xtreme渐变增强(XGB) </strong></p><p id="affc" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">XGBoost是残差梯度提升中最先进的算法。与传统的升压技术相比，它有几个优点:</p><ul class=""><li id="35d6" class="mr ms iq kh b ki kj kl km ko mt ks mu kw mv la mw mx my mz bi translated">并行处理:XGBoost支持GPU和Spark兼容性。</li><li id="70b7" class="mr ms iq kh b ki nn kl no ko np ks nq kw nr la mw mx my mz bi translated">基于现有模型进行训练:XGBoost允许保存训练结果，并在任何其他情况下基于这些结果进行构建。</li><li id="a2d0" class="mr ms iq kh b ki nn kl no ko np ks nq kw nr la mw mx my mz bi translated">引入新的正则化参数，防止过度拟合并减少偏差。</li></ul><p id="76e3" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">引入了新的超参数，例如:<br/> 1。动态确定决策树的适当深度和复杂度。<br/> 2。允许行采样+列采样。<br/> 3。随机化参数<br/> 4。<a class="ae lr" href="https://arxiv.org/abs/1808.03064" rel="noopener ugc nofollow" target="_blank">牛顿树推进</a>优化学习树结构。</p></div><div class="ab cl ng nh hu ni" role="separator"><span class="nj bw bk nk nl nm"/><span class="nj bw bk nk nl nm"/><span class="nj bw bk nk nl"/></div><div class="ij ik il im in"><h2 id="4d95" class="ls lt iq bd lu lv lw dn lx ly lz dp ma ko mb mc md ks me mf mg kw mh mi mj mk bi translated">堆垛</h2><ul class=""><li id="34e4" class="mr ms iq kh b ki ml kl mm ko oj ks ok kw ol la mw mx my mz bi translated">允许一起训练多个模型以获得预测。</li><li id="b9d5" class="mr ms iq kh b ki nn kl no ko np ks nq kw nr la mw mx my mz bi translated">第一个模型的结果被聚集并用作元学习者的训练数据。</li></ul><figure class="lc ld le lf gt lg gh gi paragraph-image"><div class="gh gi om"><img src="../Images/fceee6d952f77970b10590c98fddcfa6.png" data-original-src="https://miro.medium.com/v2/resize:fit:1096/format:webp/0*b0SO59Z510wSkS79.png"/></div><figcaption class="ln lo gj gh gi lp lq bd b be z dk translated">来源:<a class="ae lr" href="http://rasbt.github.io/mlxtend/user_guide/classifier/StackingClassifier/" rel="noopener ugc nofollow" target="_blank"> MLXtend </a></figcaption></figure><ul class=""><li id="3a2c" class="mr ms iq kh b ki kj kl km ko mt ks mu kw mv la mw mx my mz bi translated">每个基线模型的输出被用作元分类器的输入，并用实际输出进行训练。</li><li id="0994" class="mr ms iq kh b ki nn kl no ko np ks nq kw nr la mw mx my mz bi translated">使用不同的基线模型将导致堆叠分类器的更好的性能。</li><li id="1b85" class="mr ms iq kh b ki nn kl no ko np ks nq kw nr la mw mx my mz bi translated">在竞争激烈的ML环境中很受欢迎(例如:<em class="mq"> Kaggle </em>)</li></ul></div><div class="ab cl ng nh hu ni" role="separator"><span class="nj bw bk nk nl nm"/><span class="nj bw bk nk nl nm"/><span class="nj bw bk nk nl"/></div><div class="ij ik il im in"><h2 id="f01f" class="ls lt iq bd lu lv lw dn lx ly lz dp ma ko mb mc md ks me mf mg kw mh mi mj mk bi translated">级联</h2><ul class=""><li id="33d0" class="mr ms iq kh b ki ml kl mm ko oj ks ok kw ol la mw mx my mz bi translated">这种集成技术广泛用于关键应用，如信用卡交易中的欺诈检测和医疗诊断(例如:癌症检测)。</li></ul><figure class="lc ld le lf gt lg gh gi paragraph-image"><div role="button" tabindex="0" class="lh li di lj bf lk"><div class="gh gi on"><img src="../Images/3bc2eff8d2a94fe2f02cd7629739abd3.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*8vQgAd334PGQH8XmT7lFeA.png"/></div></div><figcaption class="ln lo gj gh gi lp lq bd b be z dk translated">图片来源:作者</figcaption></figure><p id="5dd7" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">上图是ML模型如何级联的一种表示。</p><ul class=""><li id="3cc7" class="mr ms iq kh b ki kj kl km ko mt ks mu kw mv la mw mx my mz bi translated"><strong class="kh ir">注意</strong>每个模型中的数据可能不同。</li><li id="ba37" class="mr ms iq kh b ki nn kl no ko np ks nq kw nr la mw mx my mz bi translated">模型的复杂性随着模型数量的增加而增加。</li><li id="5450" class="mr ms iq kh b ki nn kl no ko np ks nq kw nr la mw mx my mz bi translated">每个模型都可以被训练为针对/分类一个特定的特征(见下面的例子)</li></ul><p id="d3e4" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">考虑级联的另一种可能性，通过创建模型网络来定位特征并执行分类:</p><figure class="lc ld le lf gt lg gh gi paragraph-image"><div role="button" tabindex="0" class="lh li di lj bf lk"><div class="gh gi oo"><img src="../Images/bd8f1db76b143f9f3e723be111a8fe24.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*wO_067wmrDqksa4acRz7mg.png"/></div></div><figcaption class="ln lo gj gh gi lp lq bd b be z dk translated">图片来源:作者</figcaption></figure><p id="17b0" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">分类器网络可用于检测关键应用中的不同用例，这些应用需要较高的准确度和置信度。</p><p id="28f5" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">总之，有了机器学习模型，你可以随心所欲地发挥创造力！</p><p id="fedc" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">希望这有所帮助:)</p></div></div>    
</body>
</html>