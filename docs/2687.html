<html>
<head>
<title>Sparse Transformers | A Demo</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">稀疏变形金刚|演示</h1>
<blockquote>原文：<a href="https://pub.towardsai.net/sparse-transformers-a-demo-58b6b1ebf3e4?source=collection_archive---------2-----------------------#2022-04-18">https://pub.towardsai.net/sparse-transformers-a-demo-58b6b1ebf3e4?source=collection_archive---------2-----------------------#2022-04-18</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><figure class="ip iq gp gr ir is gh gi paragraph-image"><div role="button" tabindex="0" class="it iu di iv bf iw"><div class="gh gi io"><img src="../Images/7d521c07e03a105f892d7d5b09011874.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*KXP54ZHPzJfenZQS"/></div></div><figcaption class="iz ja gj gh gi jb jc bd b be z dk translated">在<a class="ae jd" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上由<a class="ae jd" href="https://unsplash.com/@_rishabhpandoh_?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Rishabh Pandoh </a>拍摄的照片</figcaption></figure><div class=""/><div class=""><h2 id="112d" class="pw-subtitle-paragraph kd jf jg bd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku dk translated">稀疏情况下BERT能走多快？</h2></div></div><div class="ab cl kv kw hu kx" role="separator"><span class="ky bw bk kz la lb"/><span class="ky bw bk kz la lb"/><span class="ky bw bk kz la"/></div><div class="ij ik il im in"><h1 id="cb37" class="lc ld jg bd le lf lg lh li lj lk ll lm km ln kn lo kp lp kq lq ks lr kt ls lt bi translated">这里有个小秘密:</h1><p id="59fb" class="pw-post-body-paragraph lu lv jg lw b lx ly kh lz ma mb kk mc md me mf mg mh mi mj mk ml mm mn mo mp ij bi translated">如果你想分析19个稀疏BERT模型执行推理的速度，你只需要一个YAML文件和16GB的内存就可以知道。剧透警告:</p><p id="1f93" class="pw-post-body-paragraph lu lv jg lw b lx mq kh lz ma mr kk mc md ms mf mg mh mt mj mk ml mu mn mo mp ij bi translated">…它们在CPU上运行。</p><p id="0004" class="pw-post-body-paragraph lu lv jg lw b lx mq kh lz ma mr kk mc md ms mf mg mh mt mj mk ml mu mn mo mp ij bi translated">…而且它们超级快！</p><figure class="mw mx my mz gt is gh gi paragraph-image"><div role="button" tabindex="0" class="it iu di iv bf iw"><div class="gh gi mv"><img src="../Images/03d901e18941188a202054d85e9fe53e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*dGNHvk3RZT_zRqMNIVTsmA.png"/></div></div></figure><p id="9eec" class="pw-post-body-paragraph lu lv jg lw b lx mq kh lz ma mr kk mc md ms mf mg mh mt mj mk ml mu mn mo mp ij bi translated">来自Neural Magic的<a class="ae jd" href="https://github.com/neuralmagic/deepsparse" rel="noopener ugc nofollow" target="_blank"><strong class="lw jh">DeepSparse</strong></a><strong class="lw jh"/>repo的最新功能就是deep sparse服务器！本文的目的不仅是展示为多达19个稀疏BERT模型提供服务的无缝性，还展示稀疏性对模型性能的影响。作为一点背景，稀疏化是采用经过训练的深度学习模型并从过度参数化的网络中移除冗余信息的过程，从而产生更快、更小的模型。对于这个演示，我们将使用各种BERT模型并加载它们进行推理，以显示相对于模型稀疏化的准确性和速度之间的权衡。</p><p id="8816" class="pw-post-body-paragraph lu lv jg lw b lx mq kh lz ma mr kk mc md ms mf mg mh mt mj mk ml mu mn mo mp ij bi translated">DeepSparse服务器建立在我们的DeepSparse引擎和流行的FastAPI web框架之上，允许任何人以GPU级的速度在生产中部署稀疏模型，但在CPU上！借助DeepSparse引擎，我们可以集成到流行的深度学习库(例如，Hugging Face、Ultralytics)中，从而允许您使用ONNX部署稀疏模型。</p><p id="4629" class="pw-post-body-paragraph lu lv jg lw b lx mq kh lz ma mr kk mc md ms mf mg mh mt mj mk ml mu mn mo mp ij bi translated">如前所述，在生产中运行模型所需的所有配置只需要一个YAML文件和少量内存(由于稀疏性)。为了快速开始为四个经过问答任务训练的BERT模型提供服务，下面是配置YAML文件的样子:</p><figure class="mw mx my mz gt is gh gi paragraph-image"><div role="button" tabindex="0" class="it iu di iv bf iw"><div class="gh gi na"><img src="../Images/ad7d829961734186a9e7718203feda60.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*sScp2Lf79lTGgAylu9tpIA.png"/></div></div><figcaption class="iz ja gj gh gi jb jc bd b be z dk translated">config.yaml</figcaption></figure><p id="2e62" class="pw-post-body-paragraph lu lv jg lw b lx mq kh lz ma mr kk mc md ms mf mg mh mt mj mk ml mu mn mo mp ij bi translated">如果您想变大并加载所有19个神经魔术稀疏BERT模型:这是配置文件看起来像什么👀：</p><figure class="mw mx my mz gt is gh gi paragraph-image"><div role="button" tabindex="0" class="it iu di iv bf iw"><div class="gh gi na"><img src="../Images/32826a3cbf9bc401fc21b2ac7e5a1024.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*OqMbiV7W3hFUGAOzbQXpgA.png"/></div></div></figure><p id="ed7a" class="pw-post-body-paragraph lu lv jg lw b lx mq kh lz ma mr kk mc md ms mf mg mh mt mj mk ml mu mn mo mp ij bi translated">为了便于使用，我们在Streamlit上构建了一个演示，任何人都可以在NLP中演示问答任务的服务器和模型。为了同时测试19个模型，该应用程序在谷歌云平台的虚拟机上进行测试。</p><p id="be9f" class="pw-post-body-paragraph lu lv jg lw b lx mq kh lz ma mr kk mc md ms mf mg mh mt mj mk ml mu mn mo mp ij bi translated">为了给我在测试中使用的计算提供一些基础，下面是一些细节:</p><figure class="mw mx my mz gt is"><div class="bz fp l di"><div class="nb nc l"/></div></figure><p id="4a45" class="pw-post-body-paragraph lu lv jg lw b lx mq kh lz ma mr kk mc md ms mf mg mh mt mj mk ml mu mn mo mp ij bi translated"><em class="nd">请记住，在本文描述的相同计算限制下，裸机实际上会执行得更快。然而，由于这些模型已经非常快了，我很乐意通过虚拟化来展示它们的速度。</em></p><p id="9429" class="pw-post-body-paragraph lu lv jg lw b lx mq kh lz ma mr kk mc md ms mf mg mh mt mj mk ml mu mn mo mp ij bi translated">我们不仅强烈建议您在一台虚拟机上运行相同的测试来进行性能基准测试，而且这样您就有了将所有19个BERTs加载到内存中所需的RAM，否则您会得到这个👇：</p><figure class="mw mx my mz gt is"><div class="bz fp l di"><div class="ne nc l"/></div><figcaption class="iz ja gj gh gi jb jc bd b be z dk translated">伯父</figcaption></figure><p id="7b49" class="pw-post-body-paragraph lu lv jg lw b lx mq kh lz ma mr kk mc md ms mf mg mh mt mj mk ml mu mn mo mp ij bi translated">如果您喜欢在本地机器上快速启动，而不用担心内存不足的问题，那么您应该尝试只将一些模型加载到内存中。下面的代码将向你展示如何用4个模型做到这一点(尽管大多数稀疏模型都是超轻的，你可以随意添加更多)。</p><h1 id="80ea" class="lc ld jg bd le lf nf lh li lj ng ll lm km nh kn lo kp ni kq lq ks nj kt ls lt bi translated">开始使用SparseServer。用户界面</h1><p id="eb0c" class="pw-post-body-paragraph lu lv jg lw b lx ly kh lz ma mb kk mc md me mf mg mh mi mj mk ml mm mn mo mp ij bi translated">我们将我们的应用程序分成单独的服务器和客户端目录。服务器目录包含用于加载模型的YAML文件，客户端包含Streamlit应用程序的逻辑:</p><pre class="mw mx my mz gt nk nl nm nn aw no bi"><span id="dfec" class="np ld jg nl b gy nq nr l ns nt">~sparseserver-ui/<br/>    |__client/<br/>       |__app.py<br/>       |__pipelineclient.py<br/>       |__samples.py<br/>       |__settings.py     <br/>    |__server/<br/>       |__big-config.yaml<br/>       |__config.yaml<br/>    |__requirements.txt<br/>    |__README.md</span></pre><h2 id="3382" class="np ld jg bd le nu nv dn li nw nx dp lm md ny nz lo mh oa ob lq ml oc od ls oe bi translated">1.克隆深度稀疏存储库:</h2><pre class="mw mx my mz gt nk nl nm nn aw no bi"><span id="b7f7" class="np ld jg nl b gy nq nr l ns nt">&gt;&gt;&gt; git clone <a class="ae jd" href="https://github.com/neuralmagic/deepsparse.git" rel="noopener ugc nofollow" target="_blank">https://github.com/neuralmagic/deepsparse.git</a></span></pre><h2 id="303f" class="np ld jg bd le nu nv dn li nw nx dp lm md ny nz lo mh oa ob lq ml oc od ls oe bi translated">2.安装DeepSparse服务器并简化:</h2><pre class="mw mx my mz gt nk nl nm nn aw no bi"><span id="7281" class="np ld jg nl b gy nq nr l ns nt">&gt;&gt;&gt; cd deepsparse/examples/sparseserver-ui</span><span id="a0a3" class="np ld jg nl b gy of nr l ns nt">&gt;&gt;&gt; pip install -r requirements.txt</span></pre><p id="b176" class="pw-post-body-paragraph lu lv jg lw b lx mq kh lz ma mr kk mc md ms mf mg mh mt mj mk ml mu mn mo mp ij bi translated">在我们运行服务器之前，您可以在我们的启动CLI命令中配置<code class="fe og oh oi nl b">host</code>和<code class="fe og oh oi nl b">port</code>参数。如果您选择使用默认设置，它将在<code class="fe og oh oi nl b">localhost</code>和端口<code class="fe og oh oi nl b">5543</code>上运行服务器。有关CLI参数的更多信息，请运行:</p><pre class="mw mx my mz gt nk nl nm nn aw no bi"><span id="c742" class="np ld jg nl b gy nq nr l ns nt">&gt;&gt;&gt; deepsparse.server --help</span></pre><h2 id="f7b4" class="np ld jg bd le nu nv dn li nw nx dp lm md ny nz lo mh oa ob lq ml oc od ls oe bi translated">3.运行DeepSparse服务器:</h2><p id="02cf" class="pw-post-body-paragraph lu lv jg lw b lx ly kh lz ma mb kk mc md me mf mg mh mi mj mk ml mm mn mo mp ij bi translated">好吧！是时候为<code class="fe og oh oi nl b">config.yaml</code>中定义的所有模型提供服务了。这个YAML文件将从Neural Magic的<a class="ae jd" href="https://sparsezoo.neuralmagic.com/?domain=nlp&amp;sub_domain=question_answering&amp;page=1" rel="noopener ugc nofollow" target="_blank"> SparseZoo </a> 🦾.下载四个模型</p><pre class="mw mx my mz gt nk nl nm nn aw no bi"><span id="67fe" class="np ld jg nl b gy nq nr l ns nt">&gt;&gt;&gt; deepsparse.server --config_file server/config.yaml</span></pre><p id="c622" class="pw-post-body-paragraph lu lv jg lw b lx mq kh lz ma mr kk mc md ms mf mg mh mt mj mk ml mu mn mo mp ij bi translated">下载完模型并且您的服务器启动并运行后，打开第二个终端来测试客户端。</p><p id="a70f" class="pw-post-body-paragraph lu lv jg lw b lx mq kh lz ma mr kk mc md ms mf mg mh mt mj mk ml mu mn mo mp ij bi translated">⚠️ <em class="nd">如果您在第一次运行服务器时更改了</em> <code class="fe og oh oi nl b"><em class="nd">host</em></code> <em class="nd">和</em> <code class="fe og oh oi nl b"><em class="nd">port</em></code> <em class="nd">配置，请同时调整</em> <code class="fe og oh oi nl b"><em class="nd">pipelineclient.py</em></code> <em class="nd">模块中的这些变量。</em></p><h2 id="da26" class="np ld jg bd le nu nv dn li nw nx dp lm md ny nz lo mh oa ob lq ml oc od ls oe bi translated">4.运行Streamlit客户端:</h2><pre class="mw mx my mz gt nk nl nm nn aw no bi"><span id="e123" class="np ld jg nl b gy nq nr l ns nt">&gt;&gt;&gt; streamlit run client/app.py --browser.serverAddress="localhost"</span></pre><p id="0b5e" class="pw-post-body-paragraph lu lv jg lw b lx mq kh lz ma mr kk mc md ms mf mg mh mt mj mk ml mu mn mo mp ij bi translated">就是这样！点击终端中的URL，您就可以开始与演示交互了。您可以从列表中选择示例，也可以添加自己的上下文和问题。</p><figure class="mw mx my mz gt is gh gi paragraph-image"><div role="button" tabindex="0" class="it iu di iv bf iw"><div class="gh gi oj"><img src="../Images/afe7266e025f48826d23789951d2afcb.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*aw8S1QOB9T2-YB7BjQEm8w.png"/></div></div></figure><p id="b0d2" class="pw-post-body-paragraph lu lv jg lw b lx mq kh lz ma mr kk mc md ms mf mg mh mt mj mk ml mu mn mo mp ij bi translated">在未来，我们将扩展NLP任务的数量，不仅仅是回答问题，这样你就可以在稀疏性方面获得更大的性能。</p><p id="c402" class="pw-post-body-paragraph lu lv jg lw b lx mq kh lz ma mr kk mc md ms mf mg mh mt mj mk ml mu mn mo mp ij bi translated">完整代码:查看<a class="ae jd" href="https://github.com/neuralmagic/deepsparse/tree/main/examples/sparseserver-ui" rel="noopener ugc nofollow" target="_blank"> SparseServer。用户界面</a> …</p><p id="44bf" class="pw-post-body-paragraph lu lv jg lw b lx mq kh lz ma mr kk mc md ms mf mg mh mt mj mk ml mu mn mo mp ij bi translated">…别忘了给深度稀疏回购一个GitHub⭐！</p><ul class=""><li id="e907" class="ok ol jg lw b lx mq ma mr md om mh on ml oo mp op oq or os bi translated">瑞奇科斯塔| <a class="ae jd" href="https://neuralmagic.com/" rel="noopener ugc nofollow" target="_blank">神经魔法</a> 🧙</li></ul></div></div>    
</body>
</html>