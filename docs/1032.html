<html>
<head>
<title>NLP News Cypher | 10.11.20</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">NLP新闻密码| 10.11.20</h1>
<blockquote>原文：<a href="https://pub.towardsai.net/nlp-news-cypher-10-11-20-cdfff4d69157?source=collection_archive---------2-----------------------#2020-10-11">https://pub.towardsai.net/nlp-news-cypher-10-11-20-cdfff4d69157?source=collection_archive---------2-----------------------#2020-10-11</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><figure class="ip iq gp gr ir is gh gi paragraph-image"><div role="button" tabindex="0" class="it iu di iv bf iw"><div class="gh gi io"><img src="../Images/35c743293d203131a23f0a120280753c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*tmKAyXNusY3NwuYd"/></div></div><figcaption class="iz ja gj gh gi jb jc bd b be z dk translated"><a class="ae jd" href="https://unsplash.com/@ankhesenamunnn?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">安赫塞娜蒙</a>在<a class="ae jd" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上拍照</figcaption></figure><h2 id="6256" class="je jf jg bd b dl jh ji jj jk jl jm dk jn translated" aria-label="kicker paragraph">自然语言处理每周时事通讯</h2><div class=""/><div class=""><h2 id="9431" class="pw-subtitle-paragraph km jp jg bd b kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld dk translated">代码的颂歌</h2></div></div><div class="ab cl le lf hu lg" role="separator"><span class="lh bw bk li lj lk"/><span class="lh bw bk li lj lk"/><span class="lh bw bk li lj"/></div><div class="ij ik il im in"><p id="7937" class="pw-post-body-paragraph ll lm jg ln b lo lp kq lq lr ls kt lt lu lv lw lx ly lz ma mb mc md me mf mg ij bi mh translated">嘿，欢迎回来！这周我们有另一个很棒的NLP密码。和往常一样，如果你喜欢阅读，请给它一个👏👏并与你的敌人分享。</p><p id="35ae" class="pw-post-body-paragraph ll lm jg ln b lo lp kq lq lr ls kt lt lu lv lw lx ly lz ma mb mc md me mf mg ij bi translated">此外，我们用14个新闻数据集和5个新笔记本更新了<a class="ae jd" href="https://datasets.quantumstat.com/" rel="noopener ugc nofollow" target="_blank">大坏NLP数据库</a>和<a class="ae jd" href="https://notebooks.quantumstat.com/" rel="noopener ugc nofollow" target="_blank"> Super Duper NLP Repo </a>。感谢<strong class="ln jq">如来·拉哈、</strong><strong class="ln jq"/>和<strong class="ln jq">柳井·艾拉扎</strong>的杰出贡献。👩‍💻</p><blockquote class="mq mr ms"><p id="0aed" class="ll lm mt ln b lo lp kq lq lr ls kt lt mu lv lw lx mv lz ma mb mw md me mf mg ij bi translated">新:其中一个笔记本包括来自Silero的“语音到文本”推理<em class="jg">😁</em></p></blockquote><p id="6527" class="pw-post-body-paragraph ll lm jg ln b lo lp kq lq lr ls kt lt lu lv lw lx ly lz ma mb mc md me mf mg ij bi translated">仅供参考:BBND更新的大部分来自CodeXGLUE基准测试(上个月发布)，其中有几个数据集用于代码相关任务中的机器学习(例如代码完成或code-2-code翻译，仅举几例)。这是整个画面👇：</p><figure class="my mz na nb gt is gh gi paragraph-image"><div role="button" tabindex="0" class="it iu di iv bf iw"><div class="gh gi mx"><img src="../Images/74b6dd9abcc92d77a957b95a1a848689.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*jnK42LlHYT9Fa19t.jpg"/></div></div></figure><h2 id="b121" class="nc nd jg bd ne nf ng dn nh ni nj dp nk lu nl nm nn ly no np nq mc nr ns nt jm bi translated">给我看看代码！</h2><p id="9c45" class="pw-post-body-paragraph ll lm jg ln b lo nu kq lq lr nv kt lt lu nw lw lx ly nx ma mb mc ny me mf mg ij bi translated">喜欢在arXiv上追踪代码的预印本吗？现在arXiv上有一个特殊的按钮标签，可以访问机器学习论文的源代码(如果有的话)！赢了！😎</p><p id="60fc" class="pw-post-body-paragraph ll lm jg ln b lo lp kq lq lr ls kt lt lu lv lw lx ly lz ma mb mc md me mf mg ij bi translated"><strong class="ln jq">博客</strong>:</p><div class="ip iq gp gr ir nz"><a href="https://blog.arxiv.org/2020/10/08/new-arxivlabs-feature-provides-instant-access-to-code/" rel="noopener  ugc nofollow" target="_blank"><div class="oa ab fo"><div class="ob ab oc cl cj od"><h2 class="bd jq gy z fp oe fr fs of fu fw jp bi translated">新的arXivLabs特性提供了对代码的即时访问</h2><div class="og l"><h3 class="bd b gy z fp oe fr fs of fu fw dk translated">当读者激活arXiv摘要记录页上的代码工具时，作者的代码实现将…</h3></div><div class="oh l"><p class="bd b dl z fp oe fr fs of fu fw dk translated">blog.arxiv.org</p></div></div><div class="oi l"><div class="oj l ok ol om oi on ix nz"/></div></div></a></div><figure class="my mz na nb gt is gh gi paragraph-image"><div role="button" tabindex="0" class="it iu di iv bf iw"><div class="gh gi oo"><img src="../Images/578eca8a6068317bd6a6f94d47673daf.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*alnfFsWIa_1De7cX"/></div></div><figcaption class="iz ja gj gh gi jb jc bd b be z dk translated">解密的</figcaption></figure></div><div class="ab cl le lf hu lg" role="separator"><span class="lh bw bk li lj lk"/><span class="lh bw bk li lj lk"/><span class="lh bw bk li lj"/></div><div class="ij ik il im in"><h1 id="12a3" class="op nd jg bd ne oq or os nh ot ou ov nk kv ow kw nn ky ox kz nq lb oy lc nt oz bi translated">本周</h1><blockquote class="mq mr ms"><p id="65da" class="ll lm mt ln b lo lp kq lq lr ls kt lt mu lv lw lx mv lz ma mb mw md me mf mg ij bi translated">法律伯特</p><p id="6c29" class="ll lm mt ln b lo lp kq lq lr ls kt lt mu lv lw lx mv lz ma mb mw md me mf mg ij bi translated">印度伯特</p><p id="e6ed" class="ll lm mt ln b lo lp kq lq lr ls kt lt mu lv lw lx mv lz ma mb mw md me mf mg ij bi translated">野外意图检测</p><p id="7416" class="ll lm mt ln b lo lp kq lq lr ls kt lt mu lv lw lx mv lz ma mb mw md me mf mg ij bi translated">维基百科2Vec</p><p id="f7e6" class="ll lm mt ln b lo lp kq lq lr ls kt lt mu lv lw lx mv lz ma mb mw md me mf mg ij bi translated">文本数据扩充</p><p id="e640" class="ll lm mt ln b lo lp kq lq lr ls kt lt mu lv lw lx mv lz ma mb mw md me mf mg ij bi translated">2020年人工智能状况报告</p><p id="a49a" class="ll lm mt ln b lo lp kq lq lr ls kt lt mu lv lw lx mv lz ma mb mw md me mf mg ij bi translated">荣誉文件</p><p id="6271" class="ll lm mt ln b lo lp kq lq lr ls kt lt mu lv lw lx mv lz ma mb mw md me mf mg ij bi translated">本周数据集:eQASC</p></blockquote></div><div class="ab cl le lf hu lg" role="separator"><span class="lh bw bk li lj lk"/><span class="lh bw bk li lj lk"/><span class="lh bw bk li lj"/></div><div class="ij ik il im in"><h1 id="5b9b" class="op nd jg bd ne oq or os nh ot ou ov nk kv ow kw nn ky ox kz nq lb oy lc nt oz bi translated">法律伯特</h1><p id="e1f5" class="pw-post-body-paragraph ll lm jg ln b lo nu kq lq lr nv kt lt lu nw lw lx ly nx ma mb mc ny me mf mg ij bi translated">直接从EMNLP中，我们现在有了法律领域的预训练模型，称为法律BERT！这些模型经过训练，着眼于在法律研究、计算法律和法律技术领域的应用。在培训中，模特接触了12 GB的英语法律文本，这些文本来自立法、法庭案例和合同。👇</p><figure class="my mz na nb gt is gh gi paragraph-image"><div role="button" tabindex="0" class="it iu di iv bf iw"><div class="gh gi pa"><img src="../Images/313ff3f94915659e05facd229cd57a6d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*k4c4NhNvnoQfJuoo2pZpmg.png"/></div></div><figcaption class="iz ja gj gh gi jb jc bd b be z dk translated">训练前语料库</figcaption></figure><p id="a344" class="pw-post-body-paragraph ll lm jg ln b lo lp kq lq lr ls kt lt lu lv lw lx ly lz ma mb mc md me mf mg ij bi translated">哪些地方获得了最佳性能提升？</p><blockquote class="mq mr ms"><p id="ffdf" class="ll lm mt ln b lo lp kq lq lr ls kt lt mu lv lw lx mv lz ma mb mw md me mf mg ij bi translated">“在最具挑战性的最终任务中，性能提升更大(例如，ECHR案例和合同标题中的多标签分类，以及NER合同中的租赁详细信息)”</p></blockquote><p id="7dea" class="pw-post-body-paragraph ll lm jg ln b lo lp kq lq lr ls kt lt lu lv lw lx ly lz ma mb mc md me mf mg ij bi translated">在文本分类和序列标记任务上评估该模型。</p><p id="d32a" class="pw-post-body-paragraph ll lm jg ln b lo lp kq lq lr ls kt lt lu lv lw lx ly lz ma mb mc md me mf mg ij bi translated"><strong class="ln jq">论文</strong>:<a class="ae jd" href="https://arxiv.org/pdf/2010.02559.pdf" rel="noopener ugc nofollow" target="_blank">https://arxiv.org/pdf/2010.02559.pdf</a></p><p id="9a2a" class="pw-post-body-paragraph ll lm jg ln b lo lp kq lq lr ls kt lt lu lv lw lx ly lz ma mb mc md me mf mg ij bi translated"><strong class="ln jq">洛斯莫德洛斯</strong>:</p><div class="ip iq gp gr ir nz"><a href="https://huggingface.co/nlpaueb" rel="noopener  ugc nofollow" target="_blank"><div class="oa ab fo"><div class="ob ab oc cl cj od"><h2 class="bd jq gy z fp oe fr fs of fu fw jp bi translated">nlpaueb (AUEB NLP集团)</h2><div class="og l"><h3 class="bd b gy z fp oe fr fs of fu fw dk translated">我们正踏上通过自然语言解决人工智能并使其大众化的旅程。</h3></div><div class="oh l"><p class="bd b dl z fp oe fr fs of fu fw dk translated">huggingface.co</p></div></div><div class="oi l"><div class="pb l ok ol om oi on ix nz"/></div></div></a></div><h1 id="4718" class="op nd jg bd ne oq pc os nh ot pd ov nk kv pe kw nn ky pf kz nq lb pg lc nt oz bi translated">印度伯特</h1><p id="8d79" class="pw-post-body-paragraph ll lm jg ln b lo nu kq lq lr nv kt lt lu nw lw lx ly nx ma mb mc ny me mf mg ij bi translated">如果你对印度语感兴趣，请查看基于高频变压器的印度伯特库👀。他们的多语言ALBERT模型支持12种语言，并在自定义的90亿令牌语料库上进行训练。该图书馆承担多种评估任务:</p><p id="d37e" class="pw-post-body-paragraph ll lm jg ln b lo lp kq lq lr ls kt lt lu lv lw lx ly lz ma mb mc md me mf mg ij bi translated">新闻分类，命名实体识别，标题预测，维基百科章节标题预测，完形填空式问答(WCQA，跨语言句子检索(XSR)等等。</p><p id="30e2" class="pw-post-body-paragraph ll lm jg ln b lo lp kq lq lr ls kt lt lu lv lw lx ly lz ma mb mc md me mf mg ij bi translated"><strong class="ln jq"> GitHub </strong>:</p><div class="ip iq gp gr ir nz"><a href="https://github.com/AI4Bharat/indic-bert" rel="noopener  ugc nofollow" target="_blank"><div class="oa ab fo"><div class="ob ab oc cl cj od"><h2 class="bd jq gy z fp oe fr fs of fu fw jp bi translated">AI4Bharat/indic-bert</h2><div class="og l"><h3 class="bd b gy z fp oe fr fs of fu fw dk translated">Indic bert是一个多语言ALBERT模型，专门涵盖12种主要的印度语言。它是在我们的……</h3></div><div class="oh l"><p class="bd b dl z fp oe fr fs of fu fw dk translated">github.com</p></div></div><div class="oi l"><div class="ph l ok ol om oi on ix nz"/></div></div></a></div><p id="3e9d" class="pw-post-body-paragraph ll lm jg ln b lo lp kq lq lr ls kt lt lu lv lw lx ly lz ma mb mc md me mf mg ij bi translated">感谢如来转发他们的模型给我们！</p><h2 id="ff42" class="nc nd jg bd ne nf ng dn nh ni nj dp nk lu nl nm nn ly no np nq mc nr ns nt jm bi translated">本周可乐</h2><div class="ip iq gp gr ir nz"><a href="https://colab.research.google.com/github/ai4bharat/indic-bert/blob/master/notebooks/finetuning.ipynb" rel="noopener  ugc nofollow" target="_blank"><div class="oa ab fo"><div class="ob ab oc cl cj od"><h2 class="bd jq gy z fp oe fr fs of fu fw jp bi translated">谷歌联合实验室</h2><div class="og l"><h3 class="bd b gy z fp oe fr fs of fu fw dk translated">编辑描述</h3></div><div class="oh l"><p class="bd b dl z fp oe fr fs of fu fw dk translated">colab.research.google.com</p></div></div><div class="oi l"><div class="pi l ok ol om oi on ix nz"/></div></div></a></div><h1 id="1b2e" class="op nd jg bd ne oq pc os nh ot pd ov nk kv pe kw nn ky pf kz nq lb pg lc nt oz bi translated">野外意图检测</h1><p id="2fc6" class="pw-post-body-paragraph ll lm jg ln b lo nu kq lq lr nv kt lt lu nw lw lx ly nx ma mb mc ny me mf mg ij bi translated">底线:我们需要更多真实世界的数据集。在最近的这篇Haptik论文中，作者展示了在给定3个包含范围内和范围外查询的真实数据集时，4个NLU平台(RASA、Dialogflow、LUIS、Haptik)和BERT的性能。<em class="mt">(由于难以推广到数据的测试集，结果参差不齐)</em></p><p id="21bc" class="pw-post-body-paragraph ll lm jg ln b lo lp kq lq lr ls kt lt lu lv lw lx ly lz ma mb mc md me mf mg ij bi translated">什么样的数据集？</p><blockquote class="mq mr ms"><p id="1947" class="ll lm mt ln b lo lp kq lq lr ls kt lt mu lv lw lx mv lz ma mb mw md me mf mg ij bi translated">“每个数据集在一个领域中包含不同的意向集—床垫产品零售、健身补充品零售和在线游戏……”</p></blockquote><p id="29d6" class="pw-post-body-paragraph ll lm jg ln b lo lp kq lq lr ls kt lt lu lv lw lx ly lz ma mb mc md me mf mg ij bi translated">* <em class="mt">这里的真实世界指的是真实的用户查询，而不是众包。</em></p><p id="4c7f" class="pw-post-body-paragraph ll lm jg ln b lo lp kq lq lr ls kt lt lu lv lw lx ly lz ma mb mc md me mf mg ij bi translated"><strong class="ln jq">在这里找到数据</strong>:</p><div class="ip iq gp gr ir nz"><a href="https://github.com/hellohaptik/HINT3" rel="noopener  ugc nofollow" target="_blank"><div class="oa ab fo"><div class="ob ab oc cl cj od"><h2 class="bd jq gy z fp oe fr fs of fu fw jp bi translated">hellohaptik/HINT3</h2><div class="og l"><h3 class="bd b gy z fp oe fr fs of fu fw dk translated">这个存储库包含论文“提示3:提高野外意图检测的标准”的数据集和代码…</h3></div><div class="oh l"><p class="bd b dl z fp oe fr fs of fu fw dk translated">github.com</p></div></div><div class="oi l"><div class="pj l ok ol om oi on ix nz"/></div></div></a></div><p id="28a2" class="pw-post-body-paragraph ll lm jg ln b lo lp kq lq lr ls kt lt lu lv lw lx ly lz ma mb mc md me mf mg ij bi translated"><strong class="ln jq">论文</strong>:<a class="ae jd" href="https://arxiv.org/pdf/2009.13833.pdf" rel="noopener ugc nofollow" target="_blank">https://arxiv.org/pdf/2009.13833.pdf</a></p><h1 id="6277" class="op nd jg bd ne oq pc os nh ot pd ov nk kv pe kw nn ky pf kz nq lb pg lc nt oz bi translated">维基百科2Vec</h1><p id="8740" class="pw-post-body-paragraph ll lm jg ln b lo nu kq lq lr nv kt lt lu nw lw lx ly nx ma mb mc ny me mf mg ij bi translated">你听说过Wikipedia2Vec吗，它已经存在好几年了。它包含单词和概念的嵌入，在维基百科中有相应的页面。由于维基百科是信息检索中研究最多的数据集之一，这可能会对你有用。它们的嵌入有12种语言，并且包括一个API。</p><div class="ip iq gp gr ir nz"><a href="https://wikipedia2vec.github.io/wikipedia2vec/" rel="noopener  ugc nofollow" target="_blank"><div class="oa ab fo"><div class="ob ab oc cl cj od"><h2 class="bd jq gy z fp oe fr fs of fu fw jp bi translated">维基百科2Vec</h2><div class="og l"><h3 class="bd b gy z fp oe fr fs of fu fw dk translated">Wikipedia2Vec是一个工具，用于获得单词和实体的嵌入(或向量表示)(例如，概念…</h3></div><div class="oh l"><p class="bd b dl z fp oe fr fs of fu fw dk translated">wikipedia2vec.github.io</p></div></div></div></a></div><p id="e5ef" class="pw-post-body-paragraph ll lm jg ln b lo lp kq lq lr ls kt lt lu lv lw lx ly lz ma mb mc md me mf mg ij bi translated"><strong class="ln jq">维基百科2Vec的应用:</strong></p><ul class=""><li id="6f31" class="pk pl jg ln b lo lp lr ls lu pm ly pn mc po mg pp pq pr ps bi translated">实体链接:<a class="ae jd" href="https://arxiv.org/abs/1601.01343" rel="noopener ugc nofollow" target="_blank"> Yamada等人，2016 </a>，<a class="ae jd" href="https://arxiv.org/abs/1706.09147" rel="noopener ugc nofollow" target="_blank"> Eshel等人，2017 </a>，<a class="ae jd" href="https://arxiv.org/abs/1911.03834" rel="noopener ugc nofollow" target="_blank"> Chen等人，2019 </a>，<a class="ae jd" href="https://arxiv.org/abs/1911.03681" rel="noopener ugc nofollow" target="_blank"> Poerner等人，2020 </a>。</li><li id="0518" class="pk pl jg ln b lo pt lr pu lu pv ly pw mc px mg pp pq pr ps bi translated">命名实体识别:<a class="ae jd" href="http://www.aclweb.org/anthology/I17-2017" rel="noopener ugc nofollow" target="_blank">佐藤等人，2017 </a>，<a class="ae jd" href="http://ceur-ws.org/Vol-2421/eHealth-KD_paper_6.pdf" rel="noopener ugc nofollow" target="_blank">拉拉-克拉雷斯和加西亚-塞拉诺，2019 </a>。</li><li id="0962" class="pk pl jg ln b lo pt lr pu lu pv ly pw mc px mg pp pq pr ps bi translated">问题解答:<a class="ae jd" href="https://arxiv.org/abs/1803.08652" rel="noopener ugc nofollow" target="_blank">山田等人，2017 </a>，<a class="ae jd" href="https://arxiv.org/abs/1911.03681" rel="noopener ugc nofollow" target="_blank">波尔纳等人，2020 </a>。</li><li id="0cf2" class="pk pl jg ln b lo pt lr pu lu pv ly pw mc px mg pp pq pr ps bi translated">实体分型:<a class="ae jd" href="https://arxiv.org/abs/1806.02960" rel="noopener ugc nofollow" target="_blank">山田等，2018 </a>。</li><li id="4441" class="pk pl jg ln b lo pt lr pu lu pv ly pw mc px mg pp pq pr ps bi translated">文本分类:<a class="ae jd" href="https://arxiv.org/abs/1806.02960" rel="noopener ugc nofollow" target="_blank">山田等人，2018 </a>，<a class="ae jd" href="https://arxiv.org/abs/1909.01259" rel="noopener ugc nofollow" target="_blank">山田和神童，2019 </a>。</li><li id="da43" class="pk pl jg ln b lo pt lr pu lu pv ly pw mc px mg pp pq pr ps bi translated">关系分类:<a class="ae jd" href="https://arxiv.org/abs/1911.03681" rel="noopener ugc nofollow" target="_blank"> Poerner等人，2020 </a>。</li><li id="300b" class="pk pl jg ln b lo pt lr pu lu pv ly pw mc px mg pp pq pr ps bi translated">意译检测:<a class="ae jd" href="https://ieeexplore.ieee.org/abstract/document/8606845" rel="noopener ugc nofollow" target="_blank"> Duong等人，2018 </a>。</li><li id="f162" class="pk pl jg ln b lo pt lr pu lu pv ly pw mc px mg pp pq pr ps bi translated">知识图补全:<a class="ae jd" href="https://aaai.org/ojs/index.php/AAAI/article/view/4162" rel="noopener ugc nofollow" target="_blank">沙阿等人，2019 </a>。</li><li id="1a68" class="pk pl jg ln b lo pt lr pu lu pv ly pw mc px mg pp pq pr ps bi translated">假新闻检测:<a class="ae jd" href="https://arxiv.org/abs/1906.11126" rel="noopener ugc nofollow" target="_blank"> Singh等人，2019 </a>。</li><li id="0be9" class="pk pl jg ln b lo pt lr pu lu pv ly pw mc px mg pp pq pr ps bi translated">电影剧情分析:<a class="ae jd" href="https://arxiv.org/abs/1908.10328" rel="noopener ugc nofollow" target="_blank">paparampidi等，2019 </a>。</li><li id="9ee1" class="pk pl jg ln b lo pt lr pu lu pv ly pw mc px mg pp pq pr ps bi translated">利用维基百科知识增强BERT:<a class="ae jd" href="https://arxiv.org/abs/1911.03681" rel="noopener ugc nofollow" target="_blank">poer ner等人，2019 </a>。</li><li id="6bbf" class="pk pl jg ln b lo pt lr pu lu pv ly pw mc px mg pp pq pr ps bi translated">小说实体发现:<a class="ae jd" href="https://arxiv.org/abs/2002.00206" rel="noopener ugc nofollow" target="_blank">张等，2020 </a>。</li><li id="5c5c" class="pk pl jg ln b lo pt lr pu lu pv ly pw mc px mg pp pq pr ps bi translated">实体检索:<a class="ae jd" href="https://link.springer.com/chapter/10.1007%2F978-3-030-45439-5_7" rel="noopener ugc nofollow" target="_blank"> Gerritse等人，2020 </a>。</li></ul><p id="402c" class="pw-post-body-paragraph ll lm jg ln b lo lp kq lq lr ls kt lt lu lv lw lx ly lz ma mb mc md me mf mg ij bi translated"><strong class="ln jq">论文</strong>:<a class="ae jd" href="https://t.co/f9tjsypbhw?amp=1" rel="noopener ugc nofollow" target="_blank">https://arxiv.org/abs/1812.06280</a></p><h1 id="4cd1" class="op nd jg bd ne oq pc os nh ot pd ov nk kv pe kw nn ky pf kz nq lb pg lc nt oz bi translated">文本数据扩充</h1><p id="37fa" class="pw-post-body-paragraph ll lm jg ln b lo nu kq lq lr nv kt lt lu nw lw lx ly nx ma mb mc ny me mf mg ij bi translated">NLPaug是一个用于数据扩充的方便的库，您可以在字符或单词级别上向数据集中注入噪声，从而提高模型性能。</p><p id="cf9b" class="pw-post-body-paragraph ll lm jg ln b lo lp kq lq lr ls kt lt lu lv lw lx ly lz ma mb mc md me mf mg ij bi translated">这里有一个例子来说明我的意思:</p><figure class="my mz na nb gt is gh gi paragraph-image"><div role="button" tabindex="0" class="it iu di iv bf iw"><div class="gh gi py"><img src="../Images/7a9c007200c6a471187de8681e3db81a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*SR0JitHuiy5OdkMf.png"/></div></div></figure><p id="f479" class="pw-post-body-paragraph ll lm jg ln b lo lp kq lq lr ls kt lt lu lv lw lx ly lz ma mb mc md me mf mg ij bi translated">以下是它的一些特点:</p><ul class=""><li id="9615" class="pk pl jg ln b lo lp lr ls lu pm ly pn mc po mg pp pq pr ps bi translated">OCR增强器、QWERTY增强器和随机字符增强器</li><li id="2f3a" class="pk pl jg ln b lo pt lr pu lu pv ly pw mc px mg pp pq pr ps bi translated"><code class="fe pz qa qb qc b">Word</code> : WordNet增强器、word2vec增强器、GloVe增强器、fasttext增强器、BERT增强器、随机单词字符</li><li id="327c" class="pk pl jg ln b lo pt lr pu lu pv ly pw mc px mg pp pq pr ps bi translated">顺序增强器，有时是增强器</li></ul><p id="2332" class="pw-post-body-paragraph ll lm jg ln b lo lp kq lq lr ls kt lt lu lv lw lx ly lz ma mb mc md me mf mg ij bi translated"><strong class="ln jq">关于图书馆的博文</strong>:</p><div class="ip iq gp gr ir nz"><a href="https://towardsdatascience.com/data-augmentation-library-for-text-9661736b13ff" rel="noopener follow" target="_blank"><div class="oa ab fo"><div class="ob ab oc cl cj od"><h2 class="bd jq gy z fp oe fr fs of fu fw jp bi translated">文本数据扩充库</h2><div class="og l"><h3 class="bd b gy z fp oe fr fs of fu fw dk translated">在前面的故事中，您了解了为NLP任务模型生成更多训练数据的不同方法。在这个…</h3></div><div class="oh l"><p class="bd b dl z fp oe fr fs of fu fw dk translated">towardsdatascience.com</p></div></div><div class="oi l"><div class="qd l ok ol om oi on ix nz"/></div></div></a></div><p id="7efd" class="pw-post-body-paragraph ll lm jg ln b lo lp kq lq lr ls kt lt lu lv lw lx ly lz ma mb mc md me mf mg ij bi translated"><strong class="ln jq"> GitHub </strong>:</p><div class="ip iq gp gr ir nz"><a href="https://github.com/makcedward/nlpaug" rel="noopener  ugc nofollow" target="_blank"><div class="oa ab fo"><div class="ob ab oc cl cj od"><h2 class="bd jq gy z fp oe fr fs of fu fw jp bi translated">makcedward/nlpaug</h2><div class="og l"><h3 class="bd b gy z fp oe fr fs of fu fw dk translated">这个python库帮助你为你的机器学习项目扩充nlp。请访问此介绍…</h3></div><div class="oh l"><p class="bd b dl z fp oe fr fs of fu fw dk translated">github.com</p></div></div><div class="oi l"><div class="qe l ok ol om oi on ix nz"/></div></div></a></div><blockquote class="mq mr ms"><p id="6b5a" class="ll lm mt ln b lo lp kq lq lr ls kt lt mu lv lw lx mv lz ma mb mw md me mf mg ij bi translated">揭秘:SDNR有一个nlpaug colab<em class="jg">👆</em></p></blockquote><h1 id="df4c" class="op nd jg bd ne oq pc os nh ot pd ov nk kv pe kw nn ky pf kz nq lb pg lc nt oz bi translated">2020年人工智能状况报告</h1><p id="0bcb" class="pw-post-body-paragraph ll lm jg ln b lo nu kq lq lr nv kt lt lu nw lw lx ly nx ma mb mc ny me mf mg ij bi translated">年度人工智能报告出来了，NLP大获全胜。</p><p id="a216" class="pw-post-body-paragraph ll lm jg ln b lo lp kq lq lr ls kt lt lu lv lw lx ly lz ma mb mc md me mf mg ij bi translated"><strong class="ln jq">TL；博士在NLP方面的事情</strong>:</p><p id="e829" class="pw-post-body-paragraph ll lm jg ln b lo lp kq lq lr ls kt lt lu lv lw lx ly lz ma mb mc md me mf mg ij bi translated">只有15%的论文公布了他们的代码。</p><p id="6e5f" class="pw-post-body-paragraph ll lm jg ln b lo lp kq lq lr ls kt lt lu lv lw lx ly lz ma mb mc md me mf mg ij bi translated">在研究论文方面，脸书的PyTorch正在快速超越谷歌的TensorFlow。</p><p id="0c84" class="pw-post-body-paragraph ll lm jg ln b lo lp kq lq lr ls kt lt lu lv lw lx ly lz ma mb mc md me mf mg ij bi translated"><em class="mt">较大的模型比较小的对等体需要更少的数据来实现相同的性能。</em></p><p id="ad07" class="pw-post-body-paragraph ll lm jg ln b lo lp kq lq lr ls kt lt lu lv lw lx ly lz ma mb mc md me mf mg ij bi translated">生物学正在经历它的“人工智能时刻”:仅在2020年就有超过21，000篇论文。</p><p id="a2ed" class="pw-post-body-paragraph ll lm jg ln b lo lp kq lq lr ls kt lt lu lv lw lx ly lz ma mb mc md me mf mg ij bi translated">大学毕业生流失到科技公司。</p><p id="6bfe" class="pw-post-body-paragraph ll lm jg ln b lo lp kq lq lr ls kt lt lu lv lw lx ly lz ma mb mc md me mf mg ij bi translated"><em class="mt">企业中多层次人才的崛起。</em></p><p id="c3fb" class="pw-post-body-paragraph ll lm jg ln b lo lp kq lq lr ls kt lt lu lv lw lx ly lz ma mb mc md me mf mg ij bi translated"><em class="mt"> NLP用于利用《世界新闻》自动量化公司的环境、社会和治理(ESG)认知。</em></p><p id="afb9" class="pw-post-body-paragraph ll lm jg ln b lo lp kq lq lr ls kt lt lu lv lw lx ly lz ma mb mc md me mf mg ij bi translated"><em class="mt">模型和数据集共享正在推动NLP的寒武纪大爆发。</em></p><div class="ip iq gp gr ir nz"><a href="https://www.stateof.ai/" rel="noopener  ugc nofollow" target="_blank"><div class="oa ab fo"><div class="ob ab oc cl cj od"><h2 class="bd jq gy z fp oe fr fs of fu fw jp bi translated">2020年人工智能状况报告</h2><div class="og l"><h3 class="bd b gy z fp oe fr fs of fu fw dk translated">《人工智能状况报告》分析了人工智能领域最有趣的发展。我们旨在引发一场知情的对话…</h3></div><div class="oh l"><p class="bd b dl z fp oe fr fs of fu fw dk translated">www.stateof.ai</p></div></div><div class="oi l"><div class="qf l ok ol om oi on ix nz"/></div></div></a></div><h1 id="3aa0" class="op nd jg bd ne oq pc os nh ot pd ov nk kv pe kw nn ky pf kz nq lb pg lc nt oz bi translated">荣誉文件</h1><figure class="my mz na nb gt is"><div class="bz fp l di"><div class="qg qh l"/></div><figcaption class="iz ja gj gh gi jb jc bd b be z dk translated"><a class="ae jd" href="https://arxiv.org/pdf/2010.00462.pdf" rel="noopener ugc nofollow" target="_blank">链接</a></figcaption></figure><p id="7350" class="pw-post-body-paragraph ll lm jg ln b lo lp kq lq lr ls kt lt lu lv lw lx ly lz ma mb mc md me mf mg ij bi translated">论文:<a class="ae jd" href="https://arxiv.org/pdf/2009.13013.pdf" rel="noopener ugc nofollow" target="_blank">https://arxiv.org/pdf/2009.13013.pdf</a>T29】稀疏开域QA </p><p id="62ca" class="pw-post-body-paragraph ll lm jg ln b lo lp kq lq lr ls kt lt lu lv lw lx ly lz ma mb mc md me mf mg ij bi translated">论文:<a class="ae jd" href="https://arxiv.org/pdf/2010.03099.pdf" rel="noopener ugc nofollow" target="_blank">https://arxiv.org/pdf/2010.03099.pdf</a>T33】小说框架蒸馏</p><p id="178b" class="pw-post-body-paragraph ll lm jg ln b lo lp kq lq lr ls kt lt lu lv lw lx ly lz ma mb mc md me mf mg ij bi translated">论文:<a class="ae jd" href="https://arxiv.org/pdf/2010.03604.pdf" rel="noopener ugc nofollow" target="_blank">https://arxiv.org/pdf/2010.03604.pdf</a>T37】语义角色标注图</p><h1 id="a64c" class="op nd jg bd ne oq pc os nh ot pd ov nk kv pe kw nn ky pf kz nq lb pg lc nt oz bi translated">本周数据集:eQASC</h1><h1 id="5a00" class="op nd jg bd ne oq pc os nh ot pd ov nk kv pe kw nn ky pf kz nq lb pg lc nt oz bi translated">这是什么？</h1><p id="707d" class="pw-post-body-paragraph ll lm jg ln b lo nu kq lq lr nv kt lt lu nw lw lx ly nx ma mb mc ny me mf mg ij bi translated">数据集包含对QASC数据集中的问题的98k 2跳解释，并带有注释，指示它们是有效解释还是无效解释。</p><h1 id="4c71" class="op nd jg bd ne oq pc os nh ot pd ov nk kv pe kw nn ky pf kz nq lb pg lc nt oz bi translated">样本:</h1><figure class="my mz na nb gt is gh gi paragraph-image"><div role="button" tabindex="0" class="it iu di iv bf iw"><div class="gh gi qi"><img src="../Images/74ffe56b1f747607a21e39859f6b2d3d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*hqx-F_-_hZ3aFqH6.png"/></div></div></figure><h1 id="3d60" class="op nd jg bd ne oq pc os nh ot pd ov nk kv pe kw nn ky pf kz nq lb pg lc nt oz bi translated">它在哪里？</h1><div class="ip iq gp gr ir nz"><a href="https://allenai.org/data/eqasc" rel="noopener  ugc nofollow" target="_blank"><div class="oa ab fo"><div class="ob ab oc cl cj od"><h2 class="bd jq gy z fp oe fr fs of fu fw jp bi translated">eq ASC:QASC数据集的多跳解释-艾伦人工智能研究所</h2><div class="og l"><h3 class="bd b gy z fp oe fr fs of fu fw dk translated">这个知识库解决了目前缺乏训练数据来区分有效的多跳解释和无效的…</h3></div><div class="oh l"><p class="bd b dl z fp oe fr fs of fu fw dk translated">allenai.org</p></div></div><div class="oi l"><div class="qj l ok ol om oi on ix nz"/></div></div></a></div></div><div class="ab cl le lf hu lg" role="separator"><span class="lh bw bk li lj lk"/><span class="lh bw bk li lj lk"/><span class="lh bw bk li lj"/></div><div class="ij ik il im in"><blockquote class="qk"><p id="e266" class="ql qm jg bd qn qo qp qq qr qs qt mg dk translated">每周日，我们都会对来自世界各地的研究人员的NLP新闻和代码进行每周综述。</p><p id="4115" class="ql qm jg bd qn qo qp qq qr qs qt mg dk translated"><em class="qu">如需完整报道，请关注我们的推特:</em><a class="ae jd" href="http://twitter.com/Quantum_Stat" rel="noopener ugc nofollow" target="_blank"><em class="qu">@ Quantum _ Stat</em></a></p></blockquote><figure class="qw qx qy qz ra is gh gi paragraph-image"><div class="gh gi qv"><img src="../Images/ebdf236f296f822165cad92569a367ec.png" data-original-src="https://miro.medium.com/v2/resize:fit:108/0*GunYYjECaMp56UuQ"/></div><figcaption class="iz ja gj gh gi jb jc bd b be z dk translated"><a class="ae jd" href="http://www.quantumstat.com/" rel="noopener ugc nofollow" target="_blank">www.quantumstat.com</a></figcaption></figure></div></div>    
</body>
</html>