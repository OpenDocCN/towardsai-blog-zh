<html>
<head>
<title>Sound and Acoustic patterns to diagnose COVID [Part 3]</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">声音和声学模式诊断COVID[第3部分]</h1>
<blockquote>原文：<a href="https://pub.towardsai.net/sound-and-acoustic-patterns-to-diagnose-covid-part-3-624273949804?source=collection_archive---------3-----------------------#2022-04-08">https://pub.towardsai.net/sound-and-acoustic-patterns-to-diagnose-covid-part-3-624273949804?source=collection_archive---------3-----------------------#2022-04-08</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><figure class="gl gn jo jp jq jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi jn"><img src="../Images/e32096f018e9e74316d816b6b6086bd7.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*u2DWEHFFVdC1QeHvA0b8pw.jpeg"/></div></div></figure><p id="b8f3" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated"><a class="ae kw" href="https://medium.com/@himanp/speech-and-acoustic-patterns-to-diagnose-covid-part-1-80f5d36be792" rel="noopener"> <em class="kx">将</em> </a>链接到本案例研究的第1部分</p><p id="d020" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated"><a class="ae kw" href="https://medium.com/@himanp/sound-and-acoustic-patterns-to-diagnose-covid-part-2-85f202d60dcb" rel="noopener"> <em class="kx">将</em> </a>链接到本案例研究的第二部分</p><p id="0062" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">在最后一部分中，我们根据我们的训练数据建立了一些模型，并根据我们的测试数据计算了一些指标。</p><h2 id="0e5a" class="ky kz iq bd la lb lc dn ld le lf dp lg kj lh li lj kn lk ll lm kr ln lo lp lq bi translated"><strong class="ak">贝叶斯优化和超点:</strong></h2><p id="ced6" class="pw-post-body-paragraph jy jz iq ka b kb lr kd ke kf ls kh ki kj lt kl km kn lu kp kq kr lv kt ku kv ij bi translated">Hyperopt是一种基于贝叶斯优化和SMBO(基于序列模型的全局优化)来寻找最佳模型和超参数的工具。本质上，通过贝叶斯优化，它可以找到P(得分|配置)，即对于不同的配置，给定特定配置的得分概率，然后确定最佳配置。该配置可以是具有不同超参数值的模型，或者具有不同超参数的不同模型。使用贝叶斯优化，该算法能够缩小搜索空间，以找到这些配置并更快地提供结果。</p><p id="d248" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">我已经使用这个工具为我们的数据集找到了最佳的模型和参数，然后实现了它。</p><figure class="lw lx ly lz gt jr"><div class="bz fp l di"><div class="ma mb l"/></div><figcaption class="mc md gj gh gi me mf bd b be z dk translated">使用超点的贝叶斯优化</figcaption></figure><figure class="lw lx ly lz gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi mg"><img src="../Images/6377b77e45f4806967155ba8d2a33c3e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*ouPnJDldeotGk13E"/></div></div><figcaption class="mc md gj gh gi me mf bd b be z dk translated">远视结果</figcaption></figure><p id="48c0" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">根据以上所述，最佳模型是KNN，具有欧几里得距离并且K=1。还建议使用L1归一化作为预处理步骤。</p><h2 id="06d5" class="ky kz iq bd la lb lc dn ld le lf dp lg kj lh li lj kn lk ll lm kr ln lo lp lq bi translated">k-最近邻:</h2><p id="86b8" class="pw-post-body-paragraph jy jz iq ka b kb lr kd ke kf ls kh ki kj lt kl km kn lu kp kq kr lv kt ku kv ij bi translated">在KNN中，在数据集中找到查询点的邻域，并且大多数邻域的类标签被给定为查询点的类标签。下面是结果。</p><figure class="lw lx ly lz gt jr gh gi paragraph-image"><div class="gh gi mh"><img src="../Images/b389cdada1a68fdd79c5ed331e3a1962.png" data-original-src="https://miro.medium.com/v2/resize:fit:948/0*Yta8atsJOBdPPx81"/></div></figure><p id="c954" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">该模型产生了0.11的列车对数损失和0.14的测试对数损失。训练准确率为100%，而测试准确率为98%。值得注意的是，训练损失和测试损失之间的差异较小，表明该模型没有过拟合。</p><p id="4333" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">从下面的混淆矩阵图中可以看出，在测试数据中，所有阳性点都被正确分类，而一个阴性点被错误分类。</p><figure class="lw lx ly lz gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi mi"><img src="../Images/c4cae0a349c28de96db8034d799af336.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*K4h-N5kUQQON1cHI"/></div></div><figcaption class="mc md gj gh gi me mf bd b be z dk translated">KNN的困惑矩阵</figcaption></figure><figure class="lw lx ly lz gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi mj"><img src="../Images/ebca9e35c62a4cbce812e35896a34806.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*jC7ed2nl_144hiAs"/></div></div><figcaption class="mc md gj gh gi me mf bd b be z dk translated">KNN的精确数据</figcaption></figure><p id="177a" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">从上面的精度图可以得出结论，85%的预测阳性是实际阳性，100%的预测阴性是实际阴性。</p><figure class="lw lx ly lz gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi mk"><img src="../Images/263a541e5ad90f1a83ee7891e94b8f38.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*MGFAnCS2W7IXm7nH"/></div></div><figcaption class="mc md gj gh gi me mf bd b be z dk translated">回想用python绘制的KNN数据</figcaption></figure><p id="19ff" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">从上面的回忆图可以得出，正面类有100%的回忆，而负面类有97%的回忆。</p><p id="8dc6" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">这就结束了我们问题的经典机器学习实现。总之，KNN表现最好。超参数调整和获得更好结果的空间更大，但是，很明显，经典技术可以在非常有限的容量内对我们的数据进行分类，并且很有可能过度拟合训练数据。</p><p id="4dbd" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">现在，因为这个问题是医学诊断的问题，对我们来说重要的指标是真阳性率和假阴性率。重要的是减少FNs并增加TPs。</p><p id="0be1" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">下面是所有上述模型的TP和FN图。</p><figure class="lw lx ly lz gt jr"><div class="bz fp l di"><div class="ma mb l"/></div></figure><figure class="lw lx ly lz gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi ml"><img src="../Images/fedc6cb516e5a329c0dabc7490a9e6cf.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*-80EF6uvQpMQdUOo"/></div></div><figcaption class="mc md gj gh gi me mf bd b be z dk translated">所有型号的TP和FN图</figcaption></figure><h1 id="d3cc" class="mm kz iq bd la mn mo mp ld mq mr ms lg mt mu mv lj mw mx my lm mz na nb lp nc bi translated">基于深度学习的模型</h1><p id="c319" class="pw-post-body-paragraph jy jz iq ka b kb lr kd ke kf ls kh ki kj lt kl km kn lu kp kq kr lv kt ku kv ij bi translated">接下来，我们将实现一些深度学习模型，并分析它们的性能。</p><h2 id="e3d7" class="ky kz iq bd la lb lc dn ld le lf dp lg kj lh li lj kn lk ll lm kr ln lo lp lq bi translated">卷积神经网络</h2><p id="df30" class="pw-post-body-paragraph jy jz iq ka b kb lr kd ke kf ls kh ki kj lt kl km kn lu kp kq kr lv kt ku kv ij bi translated">核用于逐个像素地对图像进行卷积，点积存储在另一个矩阵中，该矩阵是该卷积的结果。许多这样的卷积层被用来从输入图像中学习。在我们的例子中，图像是之前详细讨论过的声谱图。我们所有的数据集都被转换成光谱图。对这些频谱图使用CNN，然后是二进制分类层，以预测频谱图是属于covid正声音还是covid负声音。</p><p id="e862" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated"><strong class="ka ir"> VGGNet: </strong></p><p id="d1fb" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">这是基于卷积的架构。整个架构只使用3x3内核，stride 2使用2x2最大池。这极大地简化了这个架构。VGG 16号有16层。这用于我们任务的迁移学习。在Keras中，有一个在imagenet数据集上训练的预先构建的VGG 16模型。</p><p id="8ec3" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">迁移学习是指将预先训练好的模型重新用于当前工作，而不是从头开始构建模型。如果我们移除顶层，这些顶层是平坦且完全连接的密集层，则得到的输出是瓶颈特征。初始层的权重被冻结，因此渐变不会穿过它们，权重也不会更新。微调意味着使用较低的学习速率，因此权重不会剧烈更新。</p><p id="f378" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">在我们的任务中，将应用瓶颈和微调来查看结果。</p><figure class="lw lx ly lz gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi nd"><img src="../Images/f5168876e91388348e81862b9ca827bb.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*hPIJdqb8qcgvmzgd"/></div></div></figure><figure class="lw lx ly lz gt jr gh gi paragraph-image"><div class="gh gi ne"><img src="../Images/3788766ff88a610c8b009c8041c9f218.png" data-original-src="https://miro.medium.com/v2/resize:fit:1154/0*M2A26FdrPAaagKNr"/></div></figure><p id="7f73" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated"><strong class="ka ir"> CNN模式一:</strong></p><figure class="lw lx ly lz gt jr"><div class="bz fp l di"><div class="ma mb l"/></div></figure><p id="f7b0" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">图像数据生成器和来自数据帧方法的流用于准备我们的图像以供训练。在进行测试训练分割后，我们在验证集中获得了30%的图像，在训练集中获得了70%的图像。对于使用瓶颈特性的第一个任务，所用图像的目标大小是原始光谱图的大小，即288x432。当shuffle为真时，使用的类模式是二进制的，因为我们的任务是二进制分类。</p><figure class="lw lx ly lz gt jr gh gi paragraph-image"><div class="gh gi nf"><img src="../Images/dba12d35b004bffefeb51959bce7fcd3.png" data-original-src="https://miro.medium.com/v2/resize:fit:1294/0*f8wqvG7gmmQIzUnb"/></div><figcaption class="mc md gj gh gi me mf bd b be z dk translated">由图像数据生成器创建训练和验证集</figcaption></figure><figure class="lw lx ly lz gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi ng"><img src="../Images/47c06875c459c09bc37796e8acab7ea7.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*aAmxrDATQbUCrTr9"/></div></div><figcaption class="mc md gj gh gi me mf bd b be z dk translated">CNN 1的最终模型总结</figcaption></figure><p id="c411" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">在最终的模型中，有一个输入层，然后是顶部被移除的VGG 16模型。重物被冻结在这里。权重用imagenet数据集初始化。我们有一个卷积层，一个汇集层，然后是平坦和密集的层。最后，我们有一个用于二进制分类的单个sigmoid神经元。</p><p id="72a1" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">模型用Adam optimizer编译，学习率为0.01，二进制交叉熵损失，一组度量。度量包括二进制准确度、TP、FP、TN、FN。</p><p id="13c7" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">该模型被训练了50个时期。</p><pre class="lw lx ly lz gt nh ni nj nk aw nl bi"><span id="1569" class="ky kz iq ni b gy nm nn l no np">30/30 [==============================] — 13s 433ms/step — loss: 3.9778e-07 — binary_accuracy: 1.0000 — tp: 11.0000 — tn: 108.0000 — fp: 0.0000e+00 — fn: 0.0000e+00 — val_loss: 0.8592 — val_binary_accuracy: 0.9412 — val_tp: 5.0000 — val_tn: 43.0000 — val_fp: 0.0000e+00 — val_fn: 3.0000</span><span id="8c3f" class="ky kz iq ni b gy nq nn l no np">&lt;keras.callbacks.History at 0x7f955de702d0&gt;</span></pre><p id="6c1c" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">该模型对训练集产生了100%的准确率。总共有3个假阴性的验证组的准确度为0.94。</p><p id="3727" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated"><strong class="ka ir"> CNN模式二:</strong></p><p id="e5f1" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">对于微调用于迁移学习的VGG 16模型的第二个任务，图像被调整为224x224，这是VGG 16模型的标准输入大小。当shuffle为真时，使用的类模式是二进制的，因为我们的任务是二进制分类。</p><figure class="lw lx ly lz gt jr"><div class="bz fp l di"><div class="ma mb l"/></div></figure><figure class="lw lx ly lz gt jr gh gi paragraph-image"><div class="gh gi nf"><img src="../Images/84003d6cd1bacd0a49633d8d22ec9fd3.png" data-original-src="https://miro.medium.com/v2/resize:fit:1294/0*MmHDr5Cf-MGiHTtG"/></div><figcaption class="mc md gj gh gi me mf bd b be z dk translated">由图像数据生成器创建训练和验证集</figcaption></figure><p id="c3e1" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">在这个模型中，基本模型是VGG 16。我们冻结了这个模型的初始层，但没有冻结后面的层。6层不冻。</p><figure class="lw lx ly lz gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi nr"><img src="../Images/9a2e68537c48a560656f28350372dd4a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*3ZvvcV5KrD2DN_l-"/></div></div><figcaption class="mc md gj gh gi me mf bd b be z dk translated">冻结VGG-16模型的初始层</figcaption></figure><p id="ae53" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">最终的模型包含输入层，如上所述的VGG 16，后面是2个卷积层。这里，卷积层用于完全连接的层。这加快了训练的速度。然后是flatten层，后面是sigmoid激活的输出层。该网络中大约有1.3亿个可训练参数。</p><p id="663f" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">在编译这个模型时，我们使用了降低学习率的概念。我们使用的Adam优化器的学习率较低，为0.0001。我们还使用了之前描述的相同指标。使用最小为0.000001的递减学习率。</p><figure class="lw lx ly lz gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi ns"><img src="../Images/81cb06ad7f4d2f1f989230e4fafb1e4f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*R3e4WMUC5F-pgZPB"/></div></div><figcaption class="mc md gj gh gi me mf bd b be z dk translated">CNN模型2的最终总结</figcaption></figure><pre class="lw lx ly lz gt nh ni nj nk aw nl bi"><span id="3870" class="ky kz iq ni b gy nm nn l no np">Epoch 50/50</span><span id="2294" class="ky kz iq ni b gy nq nn l no np">30/30 [==============================] — 16s 531ms/step — loss: 4.6876e-07 — binary_accuracy: 1.0000 — tp: 16.0000 — tn: 103.0000 — fp: 0.0000e+00 — fn: 0.0000e+00 — val_loss: 0.1338 — val_binary_accuracy: 0.9608 — val_tp: 2.0000 — val_tn: 47.0000 — val_fp: 1.0000 — val_fn: 1.0000 — lr: 1.0000e-06</span><span id="c903" class="ky kz iq ni b gy nq nn l no np">&lt;keras.callbacks.History at 0x7f6aa02ca7d0&gt;</span></pre><p id="d6b7" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">如上所述，我们对模型进行了50个时期的训练。在训练集上获得了100%的准确率，在验证集上获得了96%的准确率。但是，假阴性只有1，假阳性是1。这比CNN模型1好得多，因为我们最关心的是减少FN和增加TP，这是在该模型中实现的。</p><h2 id="3ec9" class="ky kz iq bd la lb lc dn ld le lf dp lg kj lh li lj kn lk ll lm kr ln lo lp lq bi translated">多层感知器</h2><p id="5e08" class="pw-post-body-paragraph jy jz iq ka b kb lr kd ke kf ls kh ki kj lt kl km kn lu kp kq kr lv kt ku kv ij bi translated">多层感知器由4个密集层，一个输入层和一个输出层组成。输出包括1个sigmoid单元，因为我们的任务是二元分类。作为度量，使用二进制准确度和混淆矩阵分量。二进制交叉熵被用作损失函数。Adam optimizer用作学习率为0.01的优化器。</p><p id="ca01" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">这里，我们使用了用于经典机器学习模型的表格特征。</p><figure class="lw lx ly lz gt jr"><div class="bz fp l di"><div class="ma mb l"/></div></figure><p id="440b" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">下面是模型总结。我们的模型有大约186，000个可训练参数。</p><figure class="lw lx ly lz gt jr gh gi paragraph-image"><div class="gh gi nt"><img src="../Images/4e3822cb228a46f066e7bb67f3aa4476.png" data-original-src="https://miro.medium.com/v2/resize:fit:1344/0*MLWGbtKlrqS8qcTW"/></div><figcaption class="mc md gj gh gi me mf bd b be z dk translated">模型摘要</figcaption></figure><figure class="lw lx ly lz gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi nu"><img src="../Images/b7b3b2b11d63179b4fdacfd74400b4f0.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*uLmI7GrBr27h_BpI"/></div></div></figure><p id="12a9" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">如上所述，该模型被训练了100个时期，并且最后的损失非常低。该模型实现了100%训练和验证准确性。</p><blockquote class="nv nw nx"><p id="4a46" class="jy jz kx ka b kb kc kd ke kf kg kh ki ny kk kl km nz ko kp kq oa ks kt ku kv ij bi translated">然而，对于结果的整体视图，我们需要在数据的多个训练/测试分割上训练和测试上述模型。</p></blockquote><p id="539d" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated"><strong class="ka ir">重新运行基于MLP的模型，使用几次列车测试分割，以了解平均性能</strong></p><p id="04d6" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">在该实验中，创建了多个列车测试分段，并在其上运行了MLP模型。性能指标被捕获和记录。</p><figure class="lw lx ly lz gt jr"><div class="bz fp l di"><div class="ma mb l"/></div></figure><figure class="lw lx ly lz gt jr gh gi paragraph-image"><div class="gh gi ob"><img src="../Images/41e0cb7eec90dafa356c4bdc0ee66280.png" data-original-src="https://miro.medium.com/v2/resize:fit:322/0*_K0CZDJuO18oHXwL"/></div><figcaption class="mc md gj gh gi me mf bd b be z dk translated">第一次运行中分类标签的训练测试分割</figcaption></figure><figure class="lw lx ly lz gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi oc"><img src="../Images/688361a76964a22123bf66d11475b0a9.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*51ykVFnJKrxjVzDK"/></div></div><figcaption class="mc md gj gh gi me mf bd b be z dk translated">第一次运行的结果</figcaption></figure><p id="acba" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">如上所述，这是5次运行的第一次运行，其中在训练数据集中我们有14个正点，而在测试数据集中，我们有5个正点。在运行模型100个时期后，测试损失为0.014，准确率为100%。</p><p id="1db0" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">类似的过程在不同的列车测试分段上重复了5次。下面是最终结果。正如所观察到的，精确度在90%以上，并且在许多运行中接近100%。更重要的是，我们有低的假阴性和高的真阳性。</p><p id="90f2" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">因此，我们将把这款车型作为最终车型进行生产。</p><figure class="lw lx ly lz gt jr gh gi paragraph-image"><div class="gh gi od"><img src="../Images/de65f7494516f7428f4bcee94c6b23d1.png" data-original-src="https://miro.medium.com/v2/resize:fit:1328/0*-fWV_Khf1rghx7fx"/></div><figcaption class="mc md gj gh gi me mf bd b be z dk translated">5次运行的最终结果</figcaption></figure><h1 id="67d3" class="mm kz iq bd la mn mo mp ld mq mr ms lg mt mu mv lj mw mx my lm mz na nb lp nc bi translated">部署和生产</h1><p id="ad76" class="pw-post-body-paragraph jy jz iq ka b kb lr kd ke kf ls kh ki kj lt kl km kn lu kp kq kr lv kt ku kv ij bi translated">最后使用的模型是深度学习MLP模型。部署和产品电离所需的两个关键文件是保存的模型文件和用于数据标准化的pickle文件。围绕该模型创建了一个API，它将音频文件作为输入，并将标签作为输出返回。输出是JSON格式的。</p><p id="912a" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">用户界面很简单。文件被上传，点击分类按钮。这将把文件发送到服务器，并将一个类标签返回给客户机。这是通过使用<strong class="ka ir">烧瓶API模块</strong>实现的。</p><p id="ecc1" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">我们将使用AWS云来部署这个应用程序。我们将使用弹性云计算服务。首先，将启动EC2实例并安装所需的库。然后使用安全副本，我们将所需的文件从本地传输到EC2箱。然后在EC2服务器上运行app.py文件。</p><figure class="lw lx ly lz gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi oe"><img src="../Images/386784addaa84072ee0920da05030dd1.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*yQiih34aYTPd-sML"/></div></div><figcaption class="mc md gj gh gi me mf bd b be z dk translated">显示复制文件的EC2框</figcaption></figure><figure class="lw lx ly lz gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi of"><img src="../Images/3da4f37b5341084a4bf30b6b914cd9f5.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*63ZxwzB-591gzBPh"/></div></div><figcaption class="mc md gj gh gi me mf bd b be z dk translated">从EC2机器打开的UI</figcaption></figure><figure class="lw lx ly lz gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi og"><img src="../Images/4e951ddfad066a78ee97b8bfc4a0d93f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*KX9g38j1lP6nTczL"/></div></div><figcaption class="mc md gj gh gi me mf bd b be z dk translated">EC2主机返回的预测</figcaption></figure><h1 id="ef33" class="mm kz iq bd la mn mo mp ld mq mr ms lg mt mu mv lj mw mx my lm mz na nb lp nc bi translated">结论</h1><p id="4ae5" class="pw-post-body-paragraph jy jz iq ka b kb lr kd ke kf ls kh ki kj lt kl km kn lu kp kq kr lv kt ku kv ij bi translated">在这个案例研究中，我们试图创建一个可以对咳嗽声进行分类的工作模型。即使只有很小的数据集，结果也很好，很有希望。采用了经典的机器学习方法和深度学习方法。在经典方法中，KNN给出了最好的结果。为了找到最佳模型，我们还利用了贝叶斯优化。</p><p id="d2fe" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">在深度学习方法中，实现了多层感知器和卷积神经网络。对于经典方法和MLP，我们使用表格数据。这些数据是从音频信号的时间序列中设计出来的。对于CNN，我们使用光谱图。</p><p id="f76f" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">作为最终模型，我们选择了MLP，因为它给出了很好的结果，而且训练速度更快。与CNN相比，它具有相对较短的预测时间和较低的预测成本。</p><p id="d2ee" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">该模型部署在AWS EC2服务上。围绕该模型，使用Flask开发了一个API。</p><p id="7d4b" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">希望你喜欢阅读它！！</p></div></div>    
</body>
</html>