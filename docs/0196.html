<html>
<head>
<title>Scalable Efficient Deep-RL</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">可扩展高效Deep-RL</h1>
<blockquote>原文：<a href="https://pub.towardsai.net/scalable-efficient-deep-rl-ea67c0a5f4b2?source=collection_archive---------0-----------------------#2019-11-07">https://pub.towardsai.net/scalable-efficient-deep-rl-ea67c0a5f4b2?source=collection_archive---------0-----------------------#2019-11-07</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="1571" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">一种更有效的方法来扩展强化学习算法</h2></div><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ki"><img src="../Images/6043f4da9ef5f1f3e805a2660030a392.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*9Pbw6HZ3NoHDoiwwbOvaVQ.jpeg"/></div></div><figcaption class="ku kv gj gh gi kw kx bd b be z dk translated">照片由<a class="ae ky" href="https://unsplash.com/@davealmine?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText" rel="noopener ugc nofollow" target="_blank">达维德·扎维亚</a>在<a class="ae ky" href="https://unsplash.com/s/photos/dandelion?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上拍摄</figcaption></figure><h1 id="ee50" class="kz la it bd lb lc ld le lf lg lh li lj jz lk ka ll kc lm kd ln kf lo kg lp lq bi translated">介绍</h1><p id="8a21" class="pw-post-body-paragraph lr ls it lt b lu lv ju lw lx ly jx lz ma mb mc md me mf mg mh mi mj mk ml mm im bi translated">传统的可扩展强化学习框架，如<a class="ae ky" href="https://arxiv.org/abs/1802.01561" rel="noopener ugc nofollow" target="_blank">英帕拉</a>和<a class="ae ky" href="https://openreview.net/forum?id=r1lyTjAqYX" rel="noopener ugc nofollow" target="_blank"> R2D2 </a>，并行运行多个代理来收集转换，每个代理都有自己的来自参数服务器(或学习者)的模型副本。这种架构强加了高带宽要求，因为它们需要模型参数、环境信息等的传输。在本文中，我们讨论了一个现代的可扩展RL代理，称为SEED(Scalable Efficient Deep-RL)，由Google Brain团队的espe Holt&amp;Marinier&amp;Stanczyk等人提出。它利用现代加速器来加快数据收集和学习过程，并降低运行成本(在谷歌云上测量，与IMPALA相比降低了80%)。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi mn"><img src="../Images/c9f0310d05b2743b6e8ff99d4563cd2d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*-pGsFlnFZdgS8rOxNNwqEw.png"/></div></div><figcaption class="ku kv gj gh gi kw kx bd b be z dk translated">种子和黑斑羚的比较。来源:SEED RL:具有加速中央推理的可扩展且高效的深度RL</figcaption></figure><h2 id="3448" class="mo la it bd lb mp mq dn lf mr ms dp lj ma mt mu ll me mv mw ln mi mx my lp mz bi translated">传统分布式RL的不足</h2><p id="f311" class="pw-post-body-paragraph lr ls it lt b lu lv ju lw lx ly jx lz ma mb mc md me mf mg mh mi mj mk ml mm im bi translated">这里我们比较种子和黑斑羚。IMPALA架构，在Ape-X、OpenAI Rapid等中也以各种形式使用。主要由两部分组成:大量行动者周期性地复制学习者的模型参数，并与环境交互以收集轨迹，而学习者异步地接收来自行动者的转换并优化其模型。</p><p id="db58" class="pw-post-body-paragraph lr ls it lt b lu na ju lw lx nb jx lz ma nc mc md me nd mg mh mi ne mk ml mm im bi translated">这种架构的不足之处有很多原因:</p><ol class=""><li id="3ccf" class="nf ng it lt b lu na lx nb ma nh me ni mi nj mm nk nl nm nn bi translated"><strong class="lt iu">使用CPU进行神经网络推理</strong>:演员通常使用CPU进行推理，然而，众所周知，这对于神经网络来说是计算效率低下的。</li><li id="2f25" class="nf ng it lt b lu no lx np ma nq me nr mi ns mm nk nl nm nn bi translated"><strong class="lt iu">低效的资源利用</strong>:参与者在两个任务之间交替:环境步骤和推理步骤。这两个任务的计算需求通常不相似，这导致利用率低或速度慢。例如，一些环境本质上是单线程的，而神经网络很容易并行化</li><li id="4587" class="nf ng it lt b lu no lx np ma nq me nr mi ns mm nk nl nm nn bi translated"><strong class="lt iu">带宽需求</strong>:模型参数、循环状态和转换在参与者和学习者之间传递，这会给网络带宽带来巨大的负担。</li></ol><h1 id="5062" class="kz la it bd lb lc ld le lf lg lh li lj jz lk ka ll kc lm kd ln kf lo kg lp lq bi translated">种子的结构</h1><p id="946f" class="pw-post-body-paragraph lr ls it lt b lu lv ju lw lx ly jx lz ma mb mc md me mf mg mh mi mj mk ml mm im bi translated">SEED旨在解决上述问题。如图1b所示，推理和转换集合被移动到学习者，这使得它在概念上成为具有远程环境的单机设置。对于每一个单独的环境步骤，观察结果被发送给学习者，学习者运行推理并将动作发送回参与者</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi nt"><img src="../Images/37d2db187d80f779d5e5e3c4006a97a6.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*NOIO7YaUGbe5UmE8lfBofg.png"/></div></div><figcaption class="ku kv gj gh gi kw kx bd b be z dk translated">来源:SEED RL:具有加速中央推理的可扩展且高效的深度RL</figcaption></figure><p id="db70" class="pw-post-body-paragraph lr ls it lt b lu na ju lw lx nb jx lz ma nc mc md me nd mg mh mi ne mk ml mm im bi translated">学习者架构由三种类型的线程组成:</p><ul class=""><li id="c1a7" class="nf ng it lt b lu na lx nb ma nh me ni mi nj mm nu nl nm nn bi translated"><strong class="lt iu">推理</strong>:推理线程接收来自不同行动者的一批变迁(如状态、奖励、完成信号)，加载对应的递归状态，做出动作。然后将动作发送回参与者，同时存储最新的循环状态。</li><li id="4511" class="nf ng it lt b lu no lx np ma nq me nr mi ns mm nu nl nm nn bi translated"><strong class="lt iu">数据预取</strong>:当轨迹完全展开时，它会被添加到FIFO队列或重放缓冲区，稍后由数据预取线程进行采样</li><li id="12d5" class="nf ng it lt b lu no lx np ma nq me nr mi ns mm nu nl nm nn bi translated"><strong class="lt iu">训练</strong>:训练线程获取存储在设备缓冲区的预取轨迹，使用训练TPU(或GPU)主机应用梯度。</li></ul><p id="357b" class="pw-post-body-paragraph lr ls it lt b lu na ju lw lx nb jx lz ma nc mc md me nd mg mh mi ne mk ml mm im bi translated">这个模型在参与者等待来自学习者的响应时引入了一些参与者的浪费。为了减少演员的空闲时间，SEED采用了两种策略:</p><ol class=""><li id="75f2" class="nf ng it lt b lu na lx nb ma nh me ni mi nj mm nk nl nm nn bi translated">它让每个参与者运行多个环境。因此，在等待学习者的动作时，演员可以自由地进入另一个环境。</li><li id="6ecf" class="nf ng it lt b lu no lx np ma nq me nr mi ns mm nk nl nm nn bi translated">它求助于一个使用gRPC的简单框架— —一个高性能的RPC库。具体来说，他们采用流RPC，演员和学习者之间的连接保持开放，元数据只发送一次。此外，该框架包括一个批处理模块，可以有效地将多个参与者推理调用批处理在一起。如果参与者和学习者可以在同一台机器上运行，gRPC会使用Unix域套接字，从而减少延迟、CPU和系统调用开销。总的来说，包括网络和推理在内的端到端延迟对于我们下面考虑的一些模型来说更快</li></ol><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi nv"><img src="../Images/216608599511ebcbf630763764c0f1c2.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*bffrPvQIBs40uzMvcHdCww.png"/></div></div><figcaption class="ku kv gj gh gi kw kx bd b be z dk translated">不同环境和模型下IMPALA和SEED的端到端推理延迟</figcaption></figure><h2 id="ed9c" class="mo la it bd lb mp mq dn lf mr ms dp lj ma mt mu ll me mv mw ln mi mx my lp mz bi translated">成本比较</h2><p id="a56b" class="pw-post-body-paragraph lr ls it lt b lu lv ju lw lx ly jx lz ma mb mc md me mf mg mh mi mj mk ml mm im bi translated">下图比较了在Google Cloud上不同环境下训练SEED和IMPALA的成本。我们可以看到，随着网络变得越来越大，SEED节省了更多的成本。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi nw"><img src="../Images/38e37d6424d84e86f78009885b0510e5.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*ko6tl3O6vTIuyUplT1OyEA.png"/></div></div></figure><h1 id="ad8e" class="kz la it bd lb lc ld le lf lg lh li lj jz lk ka ll kc lm kd ln kf lo kg lp lq bi translated">参考</h1><p id="f097" class="pw-post-body-paragraph lr ls it lt b lu lv ju lw lx ly jx lz ma mb mc md me mf mg mh mi mj mk ml mm im bi translated">埃斯佩霍尔特、拉塞、拉斐尔·马里尼尔、彼得·斯坦奇克、王柯和马尔钦·米哈尔斯基。2019.“SEED RL:具有加速中央推理的可扩展且高效的深度RL”，1–19。<a class="ae ky" href="http://arxiv.org/abs/1910.06591" rel="noopener ugc nofollow" target="_blank">http://arxiv.org/abs/1910.06591</a>。</p></div></div>    
</body>
</html>