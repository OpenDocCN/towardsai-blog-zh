<html>
<head>
<title>Linear Algebra for AI: NLP and ML Use Cases Simply Explained</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">人工智能的线性代数:简单解释NLP和ML用例</h1>
<blockquote>原文：<a href="https://pub.towardsai.net/linear-algebra-for-ai-nlp-and-ml-use-cases-simply-explained-c0bac7159a7f?source=collection_archive---------4-----------------------#2022-07-22">https://pub.towardsai.net/linear-algebra-for-ai-nlp-and-ml-use-cases-simply-explained-c0bac7159a7f?source=collection_archive---------4-----------------------#2022-07-22</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="0f19" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">5个NLP用例，5个ML用例，以及在人工智能问题中应用线性代数的理由</h2></div><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ki"><img src="../Images/222d49c3d43ddb86b24d73d3d06aa09c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*kw4DS3iP0-ZR4XJRAGIOPA.jpeg"/></div></div><figcaption class="ku kv gj gh gi kw kx bd b be z dk translated">来自Unsplash的Ryoji Iwata </figcaption></figure><p id="b2ed" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">线性代数是一门研究向量空间和它们之间的线性映射的数学学科[1]。它在人工智能实现中是必不可少的，因为它允许在高维数据中解锁含义，这是一种常见的用例管道(在人工智能中)。</p><p id="0548" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">实现的应用包括解决人工智能中许多用例的问题，包括机器学习、深度学习和自然语言处理。也就是说，它可以用来预测神经网络的行为，也可以用来提高深度学习模型的准确性。</p><h1 id="d145" class="lv lw it bd lx ly lz ma mb mc md me mf jz mg ka mh kc mi kd mj kf mk kg ml mm bi translated"><strong class="ak">作为一个向量空间，它能够对数据进行数学运算，这是许多机器学习算法所必需的。</strong></h1><p id="a7c2" class="pw-post-body-paragraph kz la it lb b lc mn ju le lf mo jx lh li mp lk ll lm mq lo lp lq mr ls lt lu im bi translated">此外，线性代数提供了一种理解和可视化高维数据的方法，常用于自然语言处理任务。最后，线性代数用于许多优化问题，这些问题是自然语言处理和机器学习的必要条件。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ms"><img src="../Images/7084ff342979cfc37a6ede10f19cd15c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*KlD5CWRDbTytZefdqEvzGg.jpeg"/></div></div><figcaption class="ku kv gj gh gi kw kx bd b be z dk translated">来自Unsplash的<a class="ae ky" href="https://unsplash.com/@dan__burton" rel="noopener ugc nofollow" target="_blank">丹·伯顿</a></figcaption></figure><h1 id="7978" class="lv lw it bd lx ly lz ma mb mc md me mf jz mg ka mh kc mi kd mj kf mk kg ml mm bi translated"><strong class="ak">跨NLP和ML应用线性代数的理由</strong></h1><h2 id="808e" class="mt lw it bd lx mu mv dn mb mw mx dp mf li my mz mh lm na nb mj lq nc nd ml ne bi translated">首先，BLUF(底线在前面):</h2><p id="3246" class="pw-post-body-paragraph kz la it lb b lc mn ju le lf mo jx lh li mp lk ll lm mq lo lp lq mr ls lt lu im bi translated">1.文本分类和识别文本数据中的潜在主题</p><p id="6c87" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">2.根据输入向量训练模型以预测结果。</p><p id="d58e" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">3.<strong class="lb iu"> </strong>确定对给定任务最重要的输入特征。</p><p id="408f" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">4.寻找数据集中变量之间的线性关系。</p><p id="0b4f" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">5.将数据集转换到低维空间，同时保留重要信息。</p><p id="6eff" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">6.在将数据集输入学习算法之前，可视化数据集或减少数据集的大小。</p><p id="d9c3" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">7.通过基于数据中的线性关系添加约束来规范学习算法。</p><p id="4dda" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">8.解决机器学习任务中出现的优化问题，比如最小化一个成本函数。</p><p id="9b93" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">9.由于对矩阵运算的要求，它被应用于机器学习算法的实现中。</p><p id="1aba" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">为了避免把这篇文章变成一个全面的指南，我将只讨论前2个(因为你目前有前9个写在BLUF下)。如果你希望我也扩展其他七个，请友好地向我表达你的兴趣；我很高兴为深度潜水写一个单独的帖子。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi nf"><img src="../Images/9885a3cb60c5479f06ab7e4748a20876.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*KhjpKuKrHDsiJRkr1d0vtg.jpeg"/></div></div><figcaption class="ku kv gj gh gi kw kx bd b be z dk translated">来自Unsplash的Mick Haupt</figcaption></figure><h1 id="8fc3" class="lv lw it bd lx ly lz ma mb mc md me mf jz mg ka mh kc mi kd mj kf mk kg ml mm bi translated"><strong class="ak"> 1。</strong> <strong class="ak">文本分类和识别文本数据中的潜在主题</strong></h1><p id="32f5" class="pw-post-body-paragraph kz la it lb b lc mn ju le lf mo jx lh li mp lk ll lm mq lo lp lq mr ls lt lu im bi translated">线性代数可以用于分析文本语料库的结构，以提取关于词汇、句法和语义模式的信息。具体来说，它可以表示和计算向量空间模型中单词和文档之间的关系[3]。其他用例包括计算文本或单词之间的相似性度量，这对于信息检索和机器翻译等任务很有帮助。</p><p id="b99b" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">通过线性代数进行集成，将文本数据转换为更易于分类的形式，这可以通过将文本数据表示为矩阵来实现，其中每行代表一个文档，每列代表一个单词。此外，可以使用诸如奇异值分解[2]之类的技术来转换矩阵，以获得数据的降维表示。这种简化的表示可以用作分类器(例如支持向量机)的输入，以训练可以识别文本数据中的主题的模型。</p><h1 id="f336" class="lv lw it bd lx ly lz ma mb mc md me mf jz mg ka mh kc mi kd mj kf mk kg ml mm bi translated"><strong class="ak"> 2。根据输入向量训练模型以预测结果。</strong></h1><p id="0890" class="pw-post-body-paragraph kz la it lb b lc mn ju le lf mo jx lh li mp lk ll lm mq lo lp lq mr ls lt lu im bi translated">线性代数可以用向量和矩阵来表示和操作数据，这对于NLP和ML任务的数据预处理是很有效的。此外，它可以通过多种方式基于深度学习的输入向量来实现训练模型以预测结果。一些例子:</p><p id="cceb" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">—找到给定输入向量的最佳权重:通过使用线性代数，我们可以找到为给定输入向量提供最小误差的权重，从而使模型的训练能够基于输入向量预测结果。</p><p id="9aae" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">—执行矩阵运算:使用它来转换输入向量以提高预测的准确性。例如，可以实现矩阵乘法来改变输入向量的比例，或者可以使用矩阵加法来向输入向量添加新的特征。</p><p id="7ace" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">—求解线性方程组:构建它以找到一组权重的最佳值，从而训练一个模型来基于输入向量预测结果。</p><p id="e16b" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">—确定矩阵的秩:矩阵可用于确定线性方程组[7]中自由变量的数量，以训练模型并进行预测分析。</p><p id="ebc3" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">—对矩阵求逆:实施它来求解线性方程组，以便跨NLP或ML进行预测分析。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ki"><img src="../Images/34559eab9ff981cf82a1b075e3d11307.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*-wKh9ZNVeb76tfEygKDASA.jpeg"/></div></div><figcaption class="ku kv gj gh gi kw kx bd b be z dk translated">来自Unsplash的Elena Mozhvilo</figcaption></figure><h1 id="56b0" class="lv lw it bd lx ly lz ma mb mc md me mf jz mg ka mh kc mi kd mj kf mk kg ml mm bi translated"><strong class="ak">NLP和ML的用例</strong></h1><h2 id="67ad" class="mt lw it bd lx mu mv dn mb mw mx dp mf li my mz mh lm na nb mj lq nc nd ml ne bi translated">BLUF:</h2><p id="fd79" class="pw-post-body-paragraph kz la it lb b lc mn ju le lf mo jx lh li mp lk ll lm mq lo lp lq mr ls lt lu im bi translated">—线性代数用于NLP任务，如依存分析和词义消歧。</p><p id="2ec7" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">— ML任务，如回归和分类。</p><p id="ec33" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">—当您想要在低维空间中表示高维数据时。这对NLP和ML任务都很有用，因为它可以帮助减少数据的维数，同时仍然保留重要的信息。</p><p id="0a18" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">—整合it以解决优化问题。这与NLP(例如，找到句子中两个单词之间的最短路径)和ML(例如，找到最小化成本函数的参数)都相关。</p><p id="e6db" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">—实现它以从文本数据创建要素。可以使用矩阵来创建文档的单词包表示，其中每行对应于词汇表中的一个单词，每列[8][10]对应于一个文档。</p><h1 id="6711" class="lv lw it bd lx ly lz ma mb mc md me mf jz mg ka mh kc mi kd mj kf mk kg ml mm bi translated"><strong class="ak">使用线性代数进行自然语言处理</strong></h1><p id="c99f" class="pw-post-body-paragraph kz la it lb b lc mn ju le lf mo jx lh li mp lk ll lm mq lo lp lq mr ls lt lu im bi translated">—使用它将文本文档表示为高维空间中的向量。例如，这可以通过将每个单词表示为一个向量，然后将文档中所有单词的向量组合起来以获得单个文档向量来实现。这种方法通常用于主题建模和文档分类任务。</p><p id="1129" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">—应用它来解决NLP任务中出现的优化问题，如序列比对和机器翻译。这些问题通常可以表示为矩阵，然后可以使用线性代数技术进行处理。</p><p id="eeab" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">—线性回归是NLP任务(如情感分析和文本分类)中常用的技术。这种技术依靠线性代数来寻找模型参数的最佳值，从而最小化训练数据集上的误差。</p><p id="283c" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">—集成它以发现数据集中的模式。也就是说，奇异值分解是一种技术，它可以降低数据集的维数，同时保留关于变量之间关系的重要信息。SVD已经被用于诸如词义消歧和命名实体识别的任务。</p><p id="1937" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">—利用它来开发高效处理大型数据集的算法。例如，块矩阵运算[4]可以帮助减少执行任务所需的计算时间，例如主题建模和文档分类。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ng"><img src="../Images/a8ece3b739024e204c04ef02fd5c842d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*_lgl6FSpeiO2H5VQE3Ig5A.jpeg"/></div></div><figcaption class="ku kv gj gh gi kw kx bd b be z dk translated">来自Unsplash的<a class="ae ky" href="https://unsplash.com/@brett_jordan" rel="noopener ugc nofollow" target="_blank">布雷特·乔丹</a></figcaption></figure><h1 id="17f4" class="lv lw it bd lx ly lz ma mb mc md me mf jz mg ka mh kc mi kd mj kf mk kg ml mm bi translated"><strong class="ak">利用线性代数进行机器学习</strong></h1><p id="cd26" class="pw-post-body-paragraph kz la it lb b lc mn ju le lf mo jx lh li mp lk ll lm mq lo lp lq mr ls lt lu im bi translated">—线性代数用于矢量化，这是许多机器学习算法的重要部分。例如，支持向量机使用矢量化将数据点转换到一个更高维的空间，以便它们可以被超平面分隔开[9]。</p><p id="9dca" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">—线性代数也用于主成分分析，主成分分析通常用于在将数据输入机器学习算法之前降低数据的维度，以通过减少数据中的噪声量来提高性能[11]。</p><p id="71ec" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">—线性代数用于求特征向量和特征值，常用于特征工程。也就是说，PCA旋转使用特征向量来旋转数据集的坐标，以使沿新轴的方差最大化[5]。</p><p id="6704" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">—矩阵分解技术(如奇异值分解)通常用于推荐系统中，以找到解释用户偏好的潜在因素。该信息可以被馈送到协作过滤算法中，以基于用户与其他用户的相似性(基于所选择的相似性特征的接近性或近似性)向用户做出推荐。</p><p id="0b56" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">—最小二乘回归等线性代数概念广泛用于监督学习方法，如普通最小二乘回归(OLSR) [6]。</p><h1 id="eda3" class="lv lw it bd lx ly lz ma mb mc md me mf jz mg ka mh kc mi kd mj kf mk kg ml mm bi translated"><strong class="ak">结论</strong></h1><p id="67ca" class="pw-post-body-paragraph kz la it lb b lc mn ju le lf mo jx lh li mp lk ll lm mq lo lp lq mr ls lt lu im bi translated">线性代数是一个强大的工具，可用于NLP和ML任务。此外，在NLP和机器学习生命周期中预处理数据、训练模型、正则化和解决优化问题的用例中，可以看到它的影响。两个空间具有持久的影响:求解未知的预测结果和应用主成分分析进行降维和数据可视化。</p></div><div class="ab cl nh ni hx nj" role="separator"><span class="nk bw bk nl nm nn"/><span class="nk bw bk nl nm nn"/><span class="nk bw bk nl nm"/></div><div class="im in io ip iq"><p id="2310" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">如果您有任何编辑/修改建议或关于进一步扩展此主题的建议，请考虑与我分享您的想法。</p><h1 id="e47e" class="lv lw it bd lx ly lz ma mb mc md me mf jz mg ka mh kc mi kd mj kf mk kg ml mm bi translated"><strong class="ak">另外，请考虑订阅我的每周简讯:</strong></h1><div class="no np gp gr nq nr"><a href="https://pventures.substack.com/" rel="noopener  ugc nofollow" target="_blank"><div class="ns ab fo"><div class="nt ab nu cl cj nv"><h2 class="bd iu gy z fp nw fr fs nx fu fw is bi translated">周日报告#1</h2><div class="ny l"><h3 class="bd b gy z fp nw fr fs nx fu fw dk translated">设计思维与AI的共生关系设计思维能向AI揭示什么，AI又能如何拥抱…</h3></div><div class="nz l"><p class="bd b dl z fp nw fr fs nx fu fw dk translated">pventures.substack.com</p></div></div><div class="oa l"><div class="ob l oc od oe oa of ks nr"/></div></div></a></div></div><div class="ab cl nh ni hx nj" role="separator"><span class="nk bw bk nl nm nn"/><span class="nk bw bk nl nm nn"/><span class="nk bw bk nl nm"/></div><div class="im in io ip iq"><h1 id="bd2d" class="lv lw it bd lx ly og ma mb mc oh me mf jz oi ka mh kc oj kd mj kf ok kg ml mm bi translated"><strong class="ak">我写了以下与这篇文章相关的内容；您可能对它们感兴趣:</strong></h1><div class="no np gp gr nq nr"><a rel="noopener  ugc nofollow" target="_blank" href="/16-open-source-nlp-models-for-sentiment-analysis-one-rises-on-top-b5867e247116"><div class="ns ab fo"><div class="nt ab nu cl cj nv"><h2 class="bd iu gy z fp nw fr fs nx fu fw is bi translated">16个用于情感分析的开源NLP模型；一个在顶端升起</h2><div class="ny l"><h3 class="bd b gy z fp nw fr fs nx fu fw dk translated">介绍16款车型，深入了解风格。</h3></div><div class="nz l"><p class="bd b dl z fp nw fr fs nx fu fw dk translated">pub.towardsai.net</p></div></div><div class="oa l"><div class="ol l oc od oe oa of ks nr"/></div></div></a></div><div class="no np gp gr nq nr"><a href="https://medium.com/@AnilTilbe/top-20-data-engineering-tools-and-5-stand-out-a71714b12f3c" rel="noopener follow" target="_blank"><div class="ns ab fo"><div class="nt ab nu cl cj nv"><h2 class="bd iu gy z fp nw fr fs nx fu fw is bi translated">20大数据工程工具，其中5款脱颖而出</h2><div class="ny l"><h3 class="bd b gy z fp nw fr fs nx fu fw dk translated">20大开源数据工程工具，以及5个脱颖而出的工具，用于在您的数据生命周期中部署…</h3></div><div class="nz l"><p class="bd b dl z fp nw fr fs nx fu fw dk translated">medium.com</p></div></div><div class="oa l"><div class="om l oc od oe oa of ks nr"/></div></div></a></div><div class="no np gp gr nq nr"><a rel="noopener  ugc nofollow" target="_blank" href="/bayesian-inference-the-best-5-models-and-10-best-practices-for-machine-learning-11238a43929e"><div class="ns ab fo"><div class="nt ab nu cl cj nv"><h2 class="bd iu gy z fp nw fr fs nx fu fw is bi translated">贝叶斯推理:机器学习的5个最佳模型和10个最佳实践</h2><div class="ny l"><h3 class="bd b gy z fp nw fr fs nx fu fw dk translated">将贝叶斯推理应用于机器学习问题的优势、5大模型和10大最佳实践</h3></div><div class="nz l"><p class="bd b dl z fp nw fr fs nx fu fw dk translated">pub.towardsai.net</p></div></div><div class="oa l"><div class="on l oc od oe oa of ks nr"/></div></div></a></div><p id="0a88" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><em class="oo">参考文献。</em></p><p id="3a1c" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><strong class="lb iu"> <em class="oo"> 1。</em> </strong> <em class="oo">应用线性代数导论。(未注明)。检索2022年7月21日，来自</em><a class="ae ky" href="https://books.google.com/books?hl=en&amp;#38;lr=&amp;#38;id=IApaDwAAQBAJ&amp;#38;oi=fnd&amp;#38;pg=PR11&amp;#38;dq=linear+algebra+artificial+intelligence&amp;#38;ots=szO9d3dwRM&amp;#38;sig=qw5PVQjBTJf3tx-bYybn-dMasRw#v=onepage&amp;#38;q=linear%20algebra%20artificial%20intelligence&amp;#38;f=false" rel="noopener ugc nofollow" target="_blank"><em class="oo">https://books.google.com/books?hl=en&amp;# 38；lr =&amp;# 38；id = IApaDwAAQBAJ&amp;# 38；oi = fnd&amp;# 38；pg = PR11&amp;# 38；dq =线性+代数+人工+智能&amp;# 38；ots = szo 9d 3 dwrm&amp;# 38；SIG = qw 5 pvqjbtjf 3 tx-bYybn-dMasRw # v = one page&amp;# 38；q =线性% 20代数% 20人工% 20智能&amp;# 38；f=false </em> </a></p><p id="a941" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><strong class="lb iu">②<em class="oo">。</em> </strong> <em class="oo">奇异值分解:它的计算和一些应用。(未注明)。IEEE Xplore。检索到2022年7月21日，来自</em><a class="ae ky" href="https://ieeexplore.ieee.org/abstract/document/1102314" rel="noopener ugc nofollow" target="_blank"><em class="oo">https://ieeexplore.ieee.org/abstract/document/1102314</em></a></p><p id="ea18" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><strong class="lb iu"> <em class="oo"> 3。</em> </strong>【阿罗】【李】【梁】【马】&amp;# 38；里斯特斯基。(2018).词义的线性代数结构及其在多义词中的应用。计算语言学协会汇刊，6，483–495。<a class="ae ky" href="https://doi.org/10.1162/tacl_a_00034" rel="noopener ugc nofollow" target="_blank"><em class="oo">https://doi.org/10.1162/tacl_a_00034</em></a></p><p id="26dd" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><strong class="lb iu"> <em class="oo"> 4。</em> </strong> <em class="oo">线性代数语言中的图形算法。(2011).工业和应用数学学会。</em><a class="ae ky" href="https://epubs.siam.org/doi/pdf/10.1137/1.9780898719918.fm" rel="noopener ugc nofollow" target="_blank"><em class="oo">https://epubs.siam.org/doi/pdf/10.1137/1.9780898719918.fm</em></a></p><p id="31fb" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><strong class="lb iu"> <em class="oo"> 5。</em> </strong> <em class="oo">分析基于pca的人脸识别算法:特征向量选择和距离测度。(未注明)。计算机视觉中的经验评估方法。检索于2022年7月21日，来自</em><a class="ae ky" href="https://www.worldscientific.com/doi/abs/10.1142/9789812777423_0003" rel="noopener ugc nofollow" target="_blank"><em class="oo">https://www . world scientific . com/doi/ABS/10.1142/9789812777423 _ 0003</em></a></p><p id="c696" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><strong class="lb iu"> <em class="oo"> 6。</em> </strong> <em class="oo">工业与应用数学学会。(未注明)。工业和应用数学学会。检索2022年7月21日，转自</em><a class="ae ky" href="https://epubs.siam.org/doi/abs/10.1137/1036055" rel="noopener ugc nofollow" target="_blank"><em class="oo">https://epubs.siam.org/doi/abs/10.1137/1036055</em></a></p><p id="fde7" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><strong class="lb iu">7<em class="oo">。</em> </strong> <em class="oo">线性代数小测验。</em><a class="ae ky" href="https://www.gotoquiz.com/linear_algebra_quiz" rel="noopener ugc nofollow" target="_blank"><em class="oo">https://www.gotoquiz.com/linear_algebra_quiz</em></a></p><p id="e484" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><strong class="lb iu"> <em class="oo"> 8。</em> </strong> <em class="oo">一种使用典型相关分析的语义向量空间模型。</em><a class="ae ky" href="https://www.cis.upenn.edu/~ungar/papers/EMNLP_simple.pdf" rel="noopener ugc nofollow" target="_blank"><em class="oo">https://www.cis.upenn.edu/~ungar/papers/EMNLP_simple.pdf</em></a></p><p id="c945" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><strong class="lb iu"> <em class="oo"> 9。</em> </strong> <em class="oo">蛋白质不同途径的实证研究……—欣达维。</em><a class="ae ky" href="https://www.hindawi.com/journals/tswj/2014/236717/" rel="noopener ugc nofollow" target="_blank"><em class="oo">https://www.hindawi.com/journals/tswj/2014/236717/</em></a></p><p id="b6b4" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><strong class="lb iu"> <em class="oo"> 10。</em> </strong> <em class="oo">多类文本分类同喀拉斯和LSTM。</em><a class="ae ky" href="https://djajafer.medium.com/multi-class-text-classification-with-keras-and-lstm-4c5525bef592" rel="noopener"><em class="oo">https://djajafer . medium . com/multi-class-text-classification-with-keras-and-lstm-4c 5525 bef 592</em></a></p><p id="fbda" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><strong class="lb iu"> <em class="oo"> 11。S . linshot:单细胞的细胞谱系和伪时间推断。</em><a class="ae ky" href="https://bmcgenomics.biomedcentral.com/articles/10.1186/s12864-018-4772-0" rel="noopener ugc nofollow" target="_blank"><em class="oo">https://bmcgenomics . biomed central . com/articles/10.1186/s 12864-018-4772-0</em></a></strong></p></div></div>    
</body>
</html>