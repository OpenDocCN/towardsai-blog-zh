<html>
<head>
<title>Sound and Acoustic patterns to diagnose COVID [Part 2]</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">声音和声学模式诊断COVID[第2部分]</h1>
<blockquote>原文：<a href="https://pub.towardsai.net/sound-and-acoustic-patterns-to-diagnose-covid-part-2-85f202d60dcb?source=collection_archive---------4-----------------------#2022-04-08">https://pub.towardsai.net/sound-and-acoustic-patterns-to-diagnose-covid-part-2-85f202d60dcb?source=collection_archive---------4-----------------------#2022-04-08</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><figure class="gl gn jo jp jq jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi jn"><img src="../Images/e32096f018e9e74316d816b6b6086bd7.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*u2DWEHFFVdC1QeHvA0b8pw.jpeg"/></div></div></figure><p id="ed24" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated"><a class="ae kw" href="https://medium.com/@himanp/speech-and-acoustic-patterns-to-diagnose-covid-part-1-80f5d36be792" rel="noopener"> <em class="kx">将</em> </a>链接到本案例研究的第1部分</p><p id="1bf1" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated"><a class="ae kw" href="https://medium.com/@himanp/sound-and-acoustic-patterns-to-diagnose-covid-part-3-624273949804" rel="noopener">将</a>链接到本案例研究的第3部分</p><h1 id="b768" class="ky kz iq bd la lb lc ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv bi translated">探索我们的特征</h1><p id="ec24" class="pw-post-body-paragraph jy jz iq ka b kb lw kd ke kf lx kh ki kj ly kl km kn lz kp kq kr ma kt ku kv ij bi translated">首先，我们将把我们的类标签转换成整数并存储它们。</p><figure class="mc md me mf gt jr gh gi paragraph-image"><div class="gh gi mb"><img src="../Images/6191c51d442ab3aa8b38adf455bf446c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1154/format:webp/1*ZnRFhvkJZDFq_l6AFaYp5Q.png"/></div></figure><p id="e05c" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">我们将为所有音频文件提取上一部分中讨论的所有特征，并将它们存储在pandas数据框中。</p><p id="112c" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">所有解释的特征都是从我们的数据集中提取的。音频文件以单声道或单声道的形式被消费。音频也被截短为5秒钟，以省去不太重要和异常的声音。提取20个MFCCss，并对每个MFCC取平均值。Mean还接管了其他功能。</p><p id="ec40" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">我已经使用Librosa库从声谱图中提取了所有这些特征，并将它们存储在数据帧中。所有提取的特征都是数字的，因此不需要任何编码策略。</p><figure class="mc md me mf gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi mg"><img src="../Images/49cb828524daa241792d841b74dd91a2.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*2pIfmbMhbwCerqPm-bAa_A.png"/></div></div><figcaption class="mh mi gj gh gi mj mk bd b be z dk translated">提取音频特征的代码</figcaption></figure><figure class="mc md me mf gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi ml"><img src="../Images/d291956209e6b1079245cd006699a43e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*46VH3364NwqGWqbRHdGXHg.png"/></div></div><figcaption class="mh mi gj gh gi mj mk bd b be z dk translated">包含要素的最终数据框</figcaption></figure><p id="bdec" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">一些特征的基本统计。您可以在下面观察“chroma_stft”的统计数据。你也可以看到我们的最终功能列表。</p><pre class="mc md me mf gt mm mn mo mp aw mq bi"><span id="7d1c" class="mr kz iq mn b gy ms mt l mu mv">#stats of features and final column list<br/>new_df['chroma_stft'].describe()<br/>new_df.columns</span></pre><figure class="mc md me mf gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi mw"><img src="../Images/497935e6574889936b07e659200c5f79.png" data-original-src="https://miro.medium.com/v2/resize:fit:814/format:webp/1*hvuxUwcBE46zIyH-jn4fYQ.png"/></div></div></figure><figure class="mc md me mf gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi mx"><img src="../Images/1cdbe0652dfabff03a33ba75e10ccf55.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*E7Jl6vSqewiQ1nvzmstAdw.png"/></div></div></figure><p id="533c" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">使用一些特征对图进行配对以理解可分性</p><pre class="mc md me mf gt mm mn mo mp aw mq bi"><span id="baba" class="mr kz iq mn b gy ms mt l mu mv">#pair plots of features<br/>#There is not much information in the pair plots.<br/>#there is no clear boundary that separates positives from negatives</span><span id="f3b6" class="mr kz iq mn b gy my mt l mu mv">import seaborn as sns</span><span id="5206" class="mr kz iq mn b gy my mt l mu mv">a = new_df.shape[0]</span><span id="341b" class="mr kz iq mn b gy my mt l mu mv">sns.pairplot(new_df[['chroma_stft', 'rmse', 'spectral_centroid', 'spectral_rolloff', 'labels']][0:a],  hue='labels', vars=['chroma_stft', 'rmse', 'spectral_centroid', 'spectral_rolloff'])</span><span id="35d9" class="mr kz iq mn b gy my mt l mu mv">plt.show()</span></pre><figure class="mc md me mf gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi mz"><img src="../Images/2288799d7547c5720d5c5319d3d37dc9.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*y-L_damxKcHiNPGg"/></div></div><figcaption class="mh mi gj gh gi mj mk bd b be z dk translated">我们的4个特征的配对图</figcaption></figure><p id="1196" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">下面我们将绘制并查看“光谱滚降”特性的分布。</p><pre class="mc md me mf gt mm mn mo mp aw mq bi"><span id="5622" class="mr kz iq mn b gy ms mt l mu mv"># Distribution of the spectral_rolloff feature</span><span id="6be3" class="mr kz iq mn b gy my mt l mu mv">plt.figure(figsize=(15, 15))</span><span id="1d19" class="mr kz iq mn b gy my mt l mu mv">plt.subplot(1,2,1)</span><span id="4eba" class="mr kz iq mn b gy my mt l mu mv">sns.violinplot(x = 'labels', y = 'spectral_rolloff', data = new_df[0:] , )</span><span id="a026" class="mr kz iq mn b gy my mt l mu mv">plt.subplot(1,2,2)</span><span id="f977" class="mr kz iq mn b gy my mt l mu mv">sns.distplot(new_df[new_df['labels'] == 1.0]['spectral_rolloff'][0:] , label = "1", color = 'red')</span><span id="7e77" class="mr kz iq mn b gy my mt l mu mv">sns.distplot(new_df[new_df['labels'] == 0.0]['spectral_rolloff'][0:] , label = "0" , color = 'blue' )</span><span id="95db" class="mr kz iq mn b gy my mt l mu mv">plt.show()</span></pre><figure class="mc md me mf gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi na"><img src="../Images/13a9a93df85bbd682683b70afb4ec785.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*CiCQS7OiQGIMbRtr"/></div></div><figcaption class="mh mi gj gh gi mj mk bd b be z dk translated">光谱衰减的小提琴图和密度分布图</figcaption></figure><pre class="mc md me mf gt mm mn mo mp aw mq bi"><span id="123f" class="mr kz iq mn b gy ms mt l mu mv"># Distribution of the spectral_centroid feature</span><span id="4951" class="mr kz iq mn b gy my mt l mu mv">plt.figure(figsize=(15, 15))</span><span id="10a3" class="mr kz iq mn b gy my mt l mu mv">plt.subplot(1,2,1)</span><span id="9d2a" class="mr kz iq mn b gy my mt l mu mv">sns.violinplot(x = 'labels', y = 'spectral_centroid', data = new_df[0:] , )</span><span id="7c1b" class="mr kz iq mn b gy my mt l mu mv">plt.subplot(1,2,2)</span><span id="5574" class="mr kz iq mn b gy my mt l mu mv">sns.distplot(new_df[new_df['labels'] == 1.0]['spectral_centroid'][0:] , label = "1", color = 'red')</span><span id="0c39" class="mr kz iq mn b gy my mt l mu mv">sns.distplot(new_df[new_df['labels'] == 0.0]['spectral_centroid'][0:] , label = "0" , color = 'blue' )</span><span id="3f45" class="mr kz iq mn b gy my mt l mu mv">plt.show()</span></pre><figure class="mc md me mf gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi nb"><img src="../Images/23b6c59f319cb23bb2211ce6f213092c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*ZMAeAIZKXyDjxeYpVRDjMA.png"/></div></div><figcaption class="mh mi gj gh gi mj mk bd b be z dk translated">光谱质心的小提琴图和密度分布图</figcaption></figure><p id="1e4b" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">TSNE情节:</p><figure class="mc md me mf gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi nc"><img src="../Images/14223e6d2ce1eb9ae15cc76ed66454e5.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*7ek6r-jUp3vJSk3d52pwLA.png"/></div></div></figure><figure class="mc md me mf gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi nd"><img src="../Images/a7848edc5f79cef88fa3e0fc5c1290ba.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*1yTcs1n_1AZh1Nya-FEr1A.png"/></div></div></figure><figure class="mc md me mf gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi ne"><img src="../Images/73370d294dc4284fc1366bcec195ab83.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*yqRTw_3NFTvjSn5herI6wA.png"/></div></div></figure><figure class="mc md me mf gt jr gh gi paragraph-image"><div class="gh gi nf"><img src="../Images/064f77a7b3a2d2080298cf95b3b226b2.png" data-original-src="https://miro.medium.com/v2/resize:fit:1252/0*J0jkAi0WfZm33ePV"/></div><figcaption class="mh mi gj gh gi mj mk bd b be z dk translated">TSNE图</figcaption></figure><p id="5353" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">对一些特征的单变量分析表明，没有足够的分离可用于单个特征进行分类。在分布图中，正类分布和负类分布之间有很多重叠。在结对图中，您可以观察到我们的类之间没有清晰的决策边界或聚类。在TSNE图中，我们确实看到了一些聚集现象，这是一个好现象。</p><h1 id="3c39" class="ky kz iq bd la lb lc ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv bi translated">建模和性能分析</h1><p id="dc44" class="pw-post-body-paragraph jy jz iq ka b kb lw kd ke kf lx kh ki kj ly kl km kn lz kp kq kr ma kt ku kv ij bi translated">在上一节中，我们提取了色度STFT、rmse等特征，并以表格形式存储它们。标签也以文本格式存储，我们将其转换为二进制格式用于建模。0将被称为“非covid”，而1将被称为“covid”。创建自定义函数来绘制混淆矩阵、精度矩阵和召回矩阵。</p><p id="74c2" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">当处理像我们这样的不平衡数据时，用上述指标补充准确性指标是很重要的。混淆矩阵、回忆、精确度和F1分数使我们对预测结果有了更好的理解。F1分数只是根据召回率和精确度构建的指标，因此我们不会用它来评估和分析我们的结果。</p><p id="dc0f" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated"><strong class="ka ir">混乱矩阵:</strong></p><p id="de18" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">在像我们这样的二进制分类设置中，它是一个2x2矩阵，实际值(Y)在一个轴上，预测值(Y_hat)在另一个轴上。混淆矩阵由4个部分组成——真阳性(TP)、假阳性(FP)、真阴性(TN)和假阴性(FN)。</p><p id="7d9f" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">True Positive:模型正确预测了正类(有covid)。例如，模型预测有6人实际患有covid。这个计数被称为真阳性。</p><p id="4e30" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">假阳性:模型错误地预测了阳性类别。例如，模型预测有4个人患有covid，但实际上他们并没有。在这种情况下，实际的类是负的。</p><p id="0765" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">真阴性:模型正确预测了阴性类别。例如，50个没有covid的人被模型预测为没有covid。在这种情况下，实际类也是负的。</p><p id="40ce" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">假阴性:模型错误地预测了阴性类别。实际课堂是积极的。例如，模型预测有5个人没有covid，而实际上他们有。</p><figure class="mc md me mf gt jr gh gi paragraph-image"><div class="gh gi ng"><img src="../Images/2bff3b767ff9640793d205a870b5a693.png" data-original-src="https://miro.medium.com/v2/resize:fit:1214/0*qIHAvy9g53RrSBcW"/></div><figcaption class="mh mi gj gh gi mj mk bd b be z dk translated">二元混淆矩阵图</figcaption></figure><p id="e837" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">使用上述值，可以计算出— TPR(真阳性率)、FPR(假阳性率)、TNR(真阴性率)和FNR(假阴性率)。所有这些的公式都包含在下图中。</p><p id="45c9" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">通常，希望具有高的TPR、TNR和低的FPR和FNR。然而，在医疗诊断领域，更多地关注TPR和FNR通常是有意义的。在我们的项目中，更重要的是我们尽可能地增加真阳性率和减少假阴性率，以创造最大的业务影响。</p><figure class="mc md me mf gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi mx"><img src="../Images/1bbd4e3e0433ed8c290123f77f402ec4.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*F1XciZV0RdLdUq8g"/></div></div><figcaption class="mh mi gj gh gi mj mk bd b be z dk translated">度量公式</figcaption></figure><p id="ee36" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated"><strong class="ka ir">精度:</strong></p><p id="b883" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">它描述了我们积极预测的质量。是百分比或比率告诉我们有多少我们预测的正点数实际上是正的。该值始终介于0和1之间。为了得到百分比，我们可以用100乘以这个比率。</p><p id="ae23" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">精度= TP/(TP + FP)</p><p id="cff7" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated"><strong class="ka ir">回忆:</strong></p><p id="de19" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">这是一个比率，它告诉我们在所有的实际阳性中，有多少是预测的阳性。例如，如果模型预测10名实际阳性受试者中有5名covid阳性，则召回率为5/10或50%。</p><p id="cb4c" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">召回= TP/(TP + FN)</p><p id="e856" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">我们将把数据分成测试和训练子集。训练集有119个点，26个特征，测试集有51个点，相同的特征。数据也会保存到pickle文件中，以便于将来访问。此外，将数据标准化也很重要。</p><pre class="mc md me mf gt mm mn mo mp aw mq bi"><span id="0973" class="mr kz iq mn b gy ms mt l mu mv">#Train test split</span><span id="b3d4" class="mr kz iq mn b gy my mt l mu mv">X_train,X_test, y_train, y_test = train_test_split(new_df_1, y_true, stratify=y_true, test_size=0.3)</span><span id="ba23" class="mr kz iq mn b gy my mt l mu mv">#save our objects to pickle</span><span id="c674" class="mr kz iq mn b gy my mt l mu mv">import pickle</span><span id="bc8d" class="mr kz iq mn b gy my mt l mu mv">with open('/SplitData.pickle', 'wb') as handle:</span><span id="c219" class="mr kz iq mn b gy my mt l mu mv">pickle.dump([X_train,X_test, y_train, y_test], handle)</span><span id="0ff6" class="mr kz iq mn b gy my mt l mu mv">#load the objects from pickle</span><span id="3d4d" class="mr kz iq mn b gy my mt l mu mv">import pickle</span><span id="3434" class="mr kz iq mn b gy my mt l mu mv">with open('/SplitData.pickle', 'rb') as handle:</span><span id="7844" class="mr kz iq mn b gy my mt l mu mv">X_train,X_test, y_train, y_test = pickle.load(handle)</span></pre><figure class="mc md me mf gt jr gh gi paragraph-image"><div class="gh gi nh"><img src="../Images/b8dd4e064dbbff2fc2011d0894e1e1d2.png" data-original-src="https://miro.medium.com/v2/resize:fit:1008/0*mlDVD1kNE456JP1i"/></div><figcaption class="mh mi gj gh gi mj mk bd b be z dk translated">分割周围的健全性检查</figcaption></figure><p id="1cf0" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">现在，我们准备根据我们的数据训练模型。</p><p id="bd5a" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated"><strong class="ka ir">逻辑回归:</strong></p><p id="499f" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">在逻辑回归中，目的是找到一个能把我们两个阶层分开的地方。日志丢失用于优化。L2正则化被用作正则化方法以避免过拟合。Alpha用作驱动正则化的超参数。值0.1用作alpha。随机梯度下降用于寻找最小值/最大值。</p><p id="49db" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">使用sigmoid的校准也用于获得输出的精确概率。</p><p id="e642" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">在逻辑回归中，模型产生了0.138的训练损失和0.21的测试损失。训练准确率为95%，而测试准确率为88%。值得注意的是，这里的高测试精度并不能给出真实的结果，因为我们的数据集是不平衡的。有可能高精度仅来自不平衡类，即我们数据中的负类。</p><figure class="mc md me mf gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi ni"><img src="../Images/9f97e1b3110b25d6d7747f6c72c69cc5.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*95i1dg2vBGXx8450GNdnbQ.png"/></div></div></figure><figure class="mc md me mf gt jr gh gi paragraph-image"><div class="gh gi nj"><img src="../Images/7acef029f41b62aff9cb0b7555e944d0.png" data-original-src="https://miro.medium.com/v2/resize:fit:1352/0*D-EkoogfTfOQMtF2"/></div></figure><p id="2af2" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">从混淆矩阵中，可以观察到该模型能够正确预测13个阳性中的8个阳性。真正的负面预测是正确的。这是为了火车数据。</p><p id="5b2f" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">在测试数据中，可以观察到该模型不能正确地预测任何正的点。</p><pre class="mc md me mf gt mm mn mo mp aw mq bi"><span id="949d" class="mr kz iq mn b gy ms mt l mu mv">#Plotting the matrices for Test data<br/>plot_confusion_matrix(y_test, sig_clf.predict(X_test))</span></pre><figure class="mc md me mf gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi nk"><img src="../Images/934d47c2b8a50fec047af73dd24ca0dd.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*UcxQVSJGZpz0t6Dt"/></div></div><figcaption class="mh mi gj gh gi mj mk bd b be z dk translated">逻辑回归模型的混淆矩阵</figcaption></figure><figure class="mc md me mf gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi nl"><img src="../Images/d219c0d4ef64a9ffad9a21e07e6cb941.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*d77eA9fDKt6T6HVv"/></div></div><figcaption class="mh mi gj gh gi mj mk bd b be z dk translated">逻辑回归模型的精度图</figcaption></figure><p id="a656" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">从上面的精度图可以推断，对于正类，我们有0或没有精度，对于负类，精度是0.882，这意味着，在所有的负预测中，88.2%是正确的负预测。</p><figure class="mc md me mf gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi nm"><img src="../Images/b2c8b46c07e2d5d771c12f2623ff2299.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*7eN4ze3jUDWsXpMU"/></div></div><figcaption class="mh mi gj gh gi mj mk bd b be z dk translated">在python上绘制的逻辑回归模型的回忆图</figcaption></figure><p id="ccc4" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">从上面的召回图可以推断，正面类的召回是0，负面类的召回是1，这意味着，在所有负面点中，100%被正确预测。同样，在所有积极的观点中，没有一个是正确预测的。</p><p id="2947" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">总之，像逻辑回归这样的简单模型不能够很好地执行，或者能够识别正类和负类之间的差异。它高度偏向不平衡的阶层——消极阶层。</p><p id="dfad" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">使用下面的代码，将您的结果保存在一个文件中，该文件可用于以后存储其他结果。</p><figure class="mc md me mf gt jr"><div class="bz fp l di"><div class="nn no l"/></div></figure><figure class="mc md me mf gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi np"><img src="../Images/7fb443261866f4ce58a13be8bf4c878c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*6YhqWppvzfwQCp9bIUE0tA.png"/></div></div></figure><p id="9cc3" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated"><strong class="ka ir">随机森林:</strong></p><p id="6218" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">下一个实现的模型是随机森林。这是一个基于决策树的集成模型。由于线性模型不能分离数据，所以尝试非线性的、更复杂的模型是有意义的。</p><p id="685d" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">使用的基础学习器的数量是50，并且每个基础学习器树的最大深度被限制为4。这两个都是超参数，可以使用交叉验证集进行调整。</p><p id="2b04" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">使用sigmoid的校准也用于获得输出的精确概率。</p><p id="4f24" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">在随机森林模型中，观察到0.091的训练日志损失和0.0229的测试日志损失。观察到100%的训练准确度和94%的测试准确度。根据混淆矩阵，测试数据集中的所有阴性点都被正确分类，并且一半阳性点也被正确分类。</p><p id="a9f5" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">总之，像Random forest这样更复杂的模型比简单的线性模型做得更好，并且能够合理地区分类别。</p><figure class="mc md me mf gt jr gh gi paragraph-image"><div class="gh gi nq"><img src="../Images/03d041ddc4160fbabfef6820a1da9a82.png" data-original-src="https://miro.medium.com/v2/resize:fit:1268/0*q7IUNiQ7EhWW3nIz"/></div></figure><figure class="mc md me mf gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi nr"><img src="../Images/ad892d6872ec7745eac3de08d23dae2b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*oyRLCGfbTvtRK92s"/></div></div><figcaption class="mh mi gj gh gi mj mk bd b be z dk translated">随机森林模型的混淆矩阵</figcaption></figure><figure class="mc md me mf gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi ns"><img src="../Images/39fa9a79e76a92a67f557298d5dbd937.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*cNqNeaPCgrxBs8hD"/></div></div><figcaption class="mh mi gj gh gi mj mk bd b be z dk translated">随机森林模型的精确数据</figcaption></figure><p id="0e4b" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">从上面的精度图可以推断出，对于正类，我们有100%的精度，对于正类，这意味着，在所有的正预测中，它们100%是正确的。同样，在所有负面预测中，92%是正确的负面预测。</p><figure class="mc md me mf gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi nt"><img src="../Images/d075f6fb164777dbd3bb5eece33dd9d1.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*uZnvTffhWU5vjsVb"/></div></div><figcaption class="mh mi gj gh gi mj mk bd b be z dk translated">召回随机森林模型的数据</figcaption></figure><p id="bd72" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">从上面的回忆图中，可以推断正面类的回忆是50 %,这意味着在所有正面点中，50%被模型正确预测。类似地，否定类的召回率是100 %,这意味着在测试数据中所有真正的否定点中，所有都被模型正确预测。</p><p id="ac59" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">结果保存在性能文件中。</p><p id="3e49" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated"><strong class="ka ir">梯度推进决策树</strong></p><p id="3937" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">实现的下一个模型是梯度推进决策树。这也是一个基于集合的复杂模型，它迭代地减少来自决策树的误差。基础学习者使用的数量是500，这是决策树。校准使用sigmoid来调整输出的概率。</p><figure class="mc md me mf gt jr"><div class="bz fp l di"><div class="nn no l"/></div></figure><figure class="mc md me mf gt jr gh gi paragraph-image"><div class="gh gi nu"><img src="../Images/77ccf94990c4ebccd029e4aeaca1618d.png" data-original-src="https://miro.medium.com/v2/resize:fit:990/0*oxZNYKy1oCzDtAfg"/></div><figcaption class="mh mi gj gh gi mj mk bd b be z dk translated">GBDT的模型结果</figcaption></figure><p id="3ee1" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">训练损失在0.08左右，测试损失在0.22左右。在训练集上观察到100%的准确度，而在测试集上观察到96%的准确度。这是对随机森林模型的改进。</p><figure class="mc md me mf gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi nv"><img src="../Images/d7694d77d910d94c275422292121b293.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*vKjH1_lSZFlu9qLc"/></div></div><figcaption class="mh mi gj gh gi mj mk bd b be z dk translated">GBDT模型的混淆矩阵</figcaption></figure><p id="ebd3" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">所有消极点都被正确分类。6个阳性点中的4个也被正确分类，这是对随机森林模型的改进。</p><p id="38c2" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">总之，GBDT的表现略好于随机森林模型，能够合理地将积极的点分类。</p><figure class="mc md me mf gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi nw"><img src="../Images/054589d9fb3cca761079a9b04795ff91.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*hkyCUhmx79fI-8GQ"/></div></div><figcaption class="mh mi gj gh gi mj mk bd b be z dk translated">GBDT的精确数据</figcaption></figure><p id="a534" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">从上面的图可以推断，模型预测的所有正点都是正确的。预测的95%的消极点实际上是消极的，剩下的5%实际上是积极的。</p><figure class="mc md me mf gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi gj"><img src="../Images/611248c7760f35b28d457682f3957463.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*QHOHS9qSYutraaUY"/></div></div><figcaption class="mh mi gj gh gi mj mk bd b be z dk translated">回想用python绘制的GBDT数据</figcaption></figure><p id="d6d4" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">从上面的回忆图中，可以推断出该模型能够预测所有积极点中66%的积极点。该模型能够100%地预测所有负面点。</p><blockquote class="nx ny nz"><p id="bc92" class="jy jz kx ka b kb kc kd ke kf kg kh ki oa kk kl km ob ko kp kq oc ks kt ku kv ij bi translated">值得注意的是，我们在数据的单一训练测试分割上训练了上述模型。在较小的数据集的情况下，总是在训练测试数据的多个分割上训练和计算度量，以获得结果的整体画面。</p></blockquote><p id="8b88" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated"><strong class="ka ir">结论:</strong></p><p id="1421" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">在这一部分，我们看到了我们的特点，对它们做了一些EDA，并建立了一些经典的机器学习模型。</p><p id="5054" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">在下一部分:</p><ol class=""><li id="b434" class="od oe iq ka b kb kc kf kg kj of kn og kr oh kv oi oj ok ol bi translated">我们将尝试贝叶斯优化来找到最佳模型</li><li id="fe77" class="od oe iq ka b kb om kf on kj oo kn op kr oq kv oi oj ok ol bi translated">构建深度学习模型</li><li id="21a9" class="od oe iq ka b kb om kf on kj oo kn op kr oq kv oi oj ok ol bi translated">生产一个深度学习模型</li></ol></div></div>    
</body>
</html>