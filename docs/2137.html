<html>
<head>
<title>Is it possible to do Text Classification on unlabeled data? (Feat. Zero-Shot Classification) [Experiment]</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">有没有可能在无标签数据上做文本分类？(壮举。零射击分类)[实验]</h1>
<blockquote>原文：<a href="https://pub.towardsai.net/is-it-possible-to-do-text-classification-on-unlabeled-data-feat-zero-shot-classification-8caa584a1661?source=collection_archive---------0-----------------------#2021-08-30">https://pub.towardsai.net/is-it-possible-to-do-text-classification-on-unlabeled-data-feat-zero-shot-classification-8caa584a1661?source=collection_archive---------0-----------------------#2021-08-30</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><h2 id="88a5" class="ir is it bd b dl iu iv iw ix iy iz dk ja translated" aria-label="kicker paragraph"><a class="ae ep" href="https://towardsai.net/p/category/nlp" rel="noopener ugc nofollow" target="_blank">自然语言处理</a></h2><div class=""/><figure class="gl gn ka kb kc kd gh gi paragraph-image"><div role="button" tabindex="0" class="ke kf di kg bf kh"><div class="gh gi jz"><img src="../Images/e8cdfe67b512ea877b17675cbabce2e6.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*3WFE40xpkt2gMo3Q"/></div></div><figcaption class="kk kl gj gh gi km kn bd b be z dk translated">由<a class="ae ko" href="https://unsplash.com/@markusspiske?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">马库斯·斯皮斯克</a>在<a class="ae ko" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上拍摄的照片</figcaption></figure><p id="6ad0" class="pw-post-body-paragraph kp kq it kr b ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj lk ll lm im bi translated">几个月前，我做了一个实验来回答这个问题:如果我们没有目标标签，有可能进行情感分析吗？该过程是使用无监督算法来生成标签，这些标签将用于微调BERT模型。该实验产生了具有71.1%准确度的微调的BERT模型。(<a class="ae ko" href="https://nlpiation.medium.com/is-it-possible-to-do-sentiment-analysis-on-unlabeled-data-using-bert-feat-vader-experiment-357bba53768c" rel="noopener">点击这里</a>阅读全文)</p><p id="97ff" class="pw-post-body-paragraph kp kq it kr b ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj lk ll lm im bi translated">在这篇文章中，我们将尝试使用零炮分类法来获得更好的精度。当我们没有足够的训练数据时，这些模型非常方便。它们可以通过将输入序列(在我们的例子中是评论)和自定义标签(正面、负面、中性……情绪)传递给一个完全不同目标的训练模型来使用。互联网上的许多例子使用这些模型将序列(如推文)分类成不同的类别(如经济、政治、体育等)。但是让我们看看他们实际上做得有多好，我们应该使用他们吗？</p></div><div class="ab cl ln lo hx lp" role="separator"><span class="lq bw bk lr ls lt"/><span class="lq bw bk lr ls lt"/><span class="lq bw bk lr ls"/></div><div class="im in io ip iq"><h1 id="975d" class="lu lv it bd lw lx ly lz ma mb mc md me mf mg mh mi mj mk ml mm mn mo mp mq mr bi translated">数据集</h1><p id="ef41" class="pw-post-body-paragraph kp kq it kr b ks ms ku kv kw mt ky kz la mu lc ld le mv lg lh li mw lk ll lm im bi translated">我们将使用50K IMDB情感数据库(来自<a class="ae ko" href="https://www.kaggle.com/lakshmi25npathi/imdb-dataset-of-50k-movie-reviews" rel="noopener ugc nofollow" target="_blank"> Kaggle </a>)。它是由用户电影评论和他们的正面/负面情感标签组成的数据集。在本实验中，使用相同的测试集(最后5K个样本)以获得与前一篇文章相当的结果是非常重要的。请记住，我们不需要训练/验证集，因为在使用零触发分类器时没有训练/微调步骤。(这才是重点！)</p><figure class="mx my mz na gt kd"><div class="bz fp l di"><div class="nb nc l"/></div><figcaption class="kk kl gj gh gi km kn bd b be z dk translated">加载IMDB csv文件，并将最后5K个样本用作测试集。</figcaption></figure></div><div class="ab cl ln lo hx lp" role="separator"><span class="lq bw bk lr ls lt"/><span class="lq bw bk lr ls lt"/><span class="lq bw bk lr ls"/></div><div class="im in io ip iq"><h1 id="fcff" class="lu lv it bd lw lx ly lz ma mb mc md me mf mg mh mi mj mk ml mm mn mo mp mq mr bi translated">加载模型</h1><p id="1ff1" class="pw-post-body-paragraph kp kq it kr b ks ms ku kv kw mt ky kz la mu lc ld le mv lg lh li mw lk ll lm im bi translated">我们可以使用Huggingface的<a class="ae ko" href="https://huggingface.co/transformers/main_classes/pipelines.html" rel="noopener ugc nofollow" target="_blank">管道</a>来加载零镜头分类器模型。默认模型设置为BART，但是您可以从他们的<a class="ae ko" href="https://huggingface.co/models?pipeline_tag=zero-shot-classification&amp;sort=downloads" rel="noopener ugc nofollow" target="_blank">中枢</a>中选择任何预先训练的模型。在这个实验中，我们将使用默认的BART模型，第一步是下载/加载预训练的模型。</p><figure class="mx my mz na gt kd"><div class="bz fp l di"><div class="nb nc l"/></div><figcaption class="kk kl gj gh gi km kn bd b be z dk translated">加载预训练模型的代码。</figcaption></figure><p id="1285" class="pw-post-body-paragraph kp kq it kr b ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj lk ll lm im bi translated">上面的代码将创建一个模型并自动下载权重。下一步是试图根据给定的评论得出正面/负面的预测。</p><figure class="mx my mz na gt kd"><div class="bz fp l di"><div class="nb nc l"/></div><figcaption class="kk kl gj gh gi km kn bd b be z dk translated">从分类器获取预测的代码。</figcaption></figure><figure class="mx my mz na gt kd gh gi paragraph-image"><div role="button" tabindex="0" class="ke kf di kg bf kh"><div class="gh gi nd"><img src="../Images/52ec1ffa6f135dccb6dbdf3774404deb.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*XkziQMc9p0cAc2WnP4wSvQ.png"/></div></div><figcaption class="kk kl gj gh gi km kn bd b be z dk translated">上面代码的输出。</figcaption></figure><p id="7c19" class="pw-post-body-paragraph kp kq it kr b ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj lk ll lm im bi translated">如你所见，模型以98.8%的确定性预测了负面标签。需要注意的是，库会根据分数自动对标签进行排序，所以我们总能得到第一个索引作为预测的标签。除非我们在调用分类对象时，通过将<strong class="kr jd"> multi_label </strong>标志设置为True，出现了多标签分类问题。让我们编写代码来循环测试集并对它们进行分类。</p><figure class="mx my mz na gt kd"><div class="bz fp l di"><div class="nb nc l"/></div><figcaption class="kk kl gj gh gi km kn bd b be z dk translated">示例推理循环的代码。</figcaption></figure><p id="98ba" class="pw-post-body-paragraph kp kq it kr b ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj lk ll lm im bi translated">上面的代码将对所有的样本进行分类，并使用Sklearn库计算准确率得分。这个简单的代码，没有任何预先训练，将导致<strong class="kr jd"> 88.2% </strong>的准确率！太不可思议了！还有一步可以提高精度。</p></div><div class="ab cl ln lo hx lp" role="separator"><span class="lq bw bk lr ls lt"/><span class="lq bw bk lr ls lt"/><span class="lq bw bk lr ls"/></div><div class="im in io ip iq"><h1 id="e441" class="lu lv it bd lw lx ly lz ma mb mc md me mf mg mh mi mj mk ml mm mn mo mp mq mr bi translated">零拍模特是如何训练的？</h1><p id="e0a8" class="pw-post-body-paragraph kp kq it kr b ks ms ku kv kw mt ky kz la mu lc ld le mv lg lh li mw lk ll lm im bi translated">该模型在自然语言推理(NLI)语料库上进行了训练。它是一个数据集，由称为“前提”和“假设”的序列对组成，带有真/假标签，用于确定给定前提时假设是否为真。这里有一个例子:</p><pre class="mx my mz na gt ne nf ng nh aw ni bi"><span id="3af9" class="nj lv it nf b gy nk nl l nm nn">Premise    : Cars are racing in the track.<br/>Hypothesis : A car race is happening.<br/>Label      : True</span></pre><p id="dc89" class="pw-post-body-paragraph kp kq it kr b ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj lk ll lm im bi translated">该模型将通过尝试预测正确的标签来学习序列之间的关系。通过同样的逻辑，我们可以使用如下的序列对来确定一个序列是否应该被归类为一个特定的标签。</p><pre class="mx my mz na gt ne nf ng nh aw ni bi"><span id="b403" class="nj lv it nf b gy nk nl l nm nn">Premise    : The movie was so boring, I actually ...<br/>Hypothesis : This example is negative.</span></pre><p id="fe47" class="pw-post-body-paragraph kp kq it kr b ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj lk ll lm im bi translated">基于给定的序列，一个好的模型将返回True。这和Huggingface用的是同一个概念。它实际上使用了同样提到的模板“这个例子是{}”评估每个自定义标签。</p></div><div class="ab cl ln lo hx lp" role="separator"><span class="lq bw bk lr ls lt"/><span class="lq bw bk lr ls lt"/><span class="lq bw bk lr ls"/></div><div class="im in io ip iq"><h1 id="2fc9" class="lu lv it bd lw lx ly lz ma mb mc md me mf mg mh mi mj mk ml mm mn mo mp mq mr bi translated">更改假设模板</h1><p id="99a0" class="pw-post-body-paragraph kp kq it kr b ks ms ku kv kw mt ky kz la mu lc ld le mv lg lh li mw lk ll lm im bi translated">理想情况下，在假设模板中提供更多关于任务的信息会导致更准确的结果。理论上，如果我们使用模板“文本主题是关于{}”有望得到更好的结果。当试图预测文本主题(如经济、政治、体育……)而不是默认的“这个例子是{}”时让我们看看改变模板序列是否会增加准确性。</p><figure class="mx my mz na gt kd"><div class="bz fp l di"><div class="nb nc l"/></div></figure><p id="0e8d" class="pw-post-body-paragraph kp kq it kr b ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj lk ll lm im bi translated">假设模板必须有一个“{}”占位符，该占位符将在评估过程中被替换为候选标签。我使用新模板“这篇评论的观点是{}”重新运行相同的测试循环。并且将准确率从<strong class="kr jd"> 3.5% </strong>提高到<strong class="kr jd"> 91.7% </strong>！</p></div><div class="ab cl ln lo hx lp" role="separator"><span class="lq bw bk lr ls lt"/><span class="lq bw bk lr ls lt"/><span class="lq bw bk lr ls"/></div><div class="im in io ip iq"><h1 id="27f1" class="lu lv it bd lw lx ly lz ma mb mc md me mf mg mh mi mj mk ml mm mn mo mp mq mr bi translated">结论</h1><p id="f9d6" class="pw-post-body-paragraph kp kq it kr b ks ms ku kv kw mt ky kz la mu lc ld le mv lg lh li mw lk ll lm im bi translated">零触发分类器工作得如此之好，这是值得注意的。我从<a class="ae ko" href="https://nlpiation.medium.com/is-it-possible-to-do-sentiment-analysis-on-unlabeled-data-using-bert-feat-vader-experiment-357bba53768c" rel="noopener">之前的实验</a>中获得的最佳精度是<strong class="kr jd"> 71% </strong>这确实不是一个干净的方法。现在，我们得到了<strong class="kr jd"> 91.7% </strong>，甚至没有在特定数据集上对模型进行微调。</p><blockquote class="no"><p id="13b0" class="np nq it bd nr ns nt nu nv nw nx lm dk translated">我每周给NLP的书呆子发一份时事通讯。如果您想了解自然语言处理的最新发展，可以考虑订阅。<br/> <a class="ae ko" href="https://nlpiation.github.io/" rel="noopener ugc nofollow" target="_blank">阅读更多，订阅</a> —加入酷孩子俱乐部，立即报名！</p></blockquote></div></div>    
</body>
</html>