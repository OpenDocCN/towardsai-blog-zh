<html>
<head>
<title>Data Preprocessing — An important stage that is ignored by masses</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">数据预处理——一个被大众忽视的重要阶段</h1>
<blockquote>原文：<a href="https://pub.towardsai.net/data-preprocessing-an-important-stage-that-is-ignored-by-masses-7471564af929?source=collection_archive---------3-----------------------#2020-11-23">https://pub.towardsai.net/data-preprocessing-an-important-stage-that-is-ignored-by-masses-7471564af929?source=collection_archive---------3-----------------------#2020-11-23</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><h2 id="0c12" class="io ip iq bd b dl ir is it iu iv iw dk ix translated" aria-label="kicker paragraph"><a class="ae ep" href="https://towardsai.net/p/category/data-mining" rel="noopener ugc nofollow" target="_blank">数据挖掘</a></h2><div class=""/><div class=""><h2 id="1056" class="pw-subtitle-paragraph jw iz iq bd b jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn dk translated">在分析之前，抛光很重要</h2></div><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div role="button" tabindex="0" class="ku kv di kw bf kx"><div class="gh gi ko"><img src="../Images/873981e4a7586e0792231570777fdf25.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*jYBAzYZ_a47empFL0mlGdA.jpeg"/></div></div><figcaption class="la lb gj gh gi lc ld bd b be z dk translated">照片由来自<a class="ae le" href="https://www.pexels.com/photo/multi-colored-folders-piled-up-159519/?utm_content=attributionCopyText&amp;utm_medium=referral&amp;utm_source=pexels" rel="noopener ugc nofollow" target="_blank"> Pexels </a>的<a class="ae le" href="https://www.pexels.com/@pixabay?utm_content=attributionCopyText&amp;utm_medium=referral&amp;utm_source=pexels" rel="noopener ugc nofollow" target="_blank"> Pixabay </a>拍摄</figcaption></figure><p id="623e" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">科学界的天才<strong class="lh ja">阿尔伯特·爱因斯坦</strong>曾经引用过:</p><blockquote class="mb"><p id="8381" class="mc md iq bd me mf mg mh mi mj mk ma dk translated">如果给你一个60分钟要解决的问题，那么花55分钟定义这个问题，然后花5分钟解决它。T11】</p></blockquote><p id="eef1" class="pw-post-body-paragraph lf lg iq lh b li mm ka lk ll mn kd ln lo mo lq lr ls mp lu lv lw mq ly lz ma ij bi translated">无论我迄今为止在数据科学领域做了什么，我现在都想用一种不同的方式来重新定义这句话，如下所示:</p><blockquote class="mb"><p id="01ec" class="mc md iq bd me mf mg mh mi mj mk ma dk translated"><strong class="ak"> <em class="ml">“如果给你一个数据集来执行分析以创建可视化，然后应用算法来训练模型以产生最佳性能，那么将大部分时间花在数据预处理技术上以获得更干净和正确的数据。”</em>T15】</strong></p></blockquote><h1 id="0349" class="mr ms iq bd mt mu mv mw mx my mz na nb kf nc kg nd ki ne kj nf kl ng km nh ni bi translated">为什么我们需要数据预处理？</h1><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div class="gh gi nj"><img src="../Images/9c02efefb8bf000d576d86d4093a7d58.png" data-original-src="https://miro.medium.com/v2/resize:fit:1258/format:webp/1*KLwui3NuGgFLiN4yE1-4IQ.png"/></div><figcaption class="la lb gj gh gi lc ld bd b be z dk translated"><a class="ae le" href="https://recommender-systems.readthedocs.io/en/latest/_images/Kdd-process.png" rel="noopener ugc nofollow" target="_blank">来源</a></figcaption></figure><p id="bd2d" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">在数据挖掘过程中，所获得的数据集并不总是需要完全精炼并准备好被训练成模型。数据集可能包含异常值、噪声或重复值，从而导致数据的不正确可视化。此外，在训练模型时，质量差的数据集可能会为我们提供非常好的性能或准确性，但在模型测试期间，它可能会生成很高的错误值。这将损害机器学习中方差和偏差的经验法则。为了避免这种情况，我们引入了一些在数据预处理阶段细化数据时使用的技术。</p><h1 id="0f4a" class="mr ms iq bd mt mu mv mw mx my mz na nb kf nk kg nd ki nl kj nf kl nm km nh ni bi translated">数据预处理技术</h1><ul class=""><li id="155c" class="nn no iq lh b li np ll nq lo nr ls ns lw nt ma nu nv nw nx bi translated">聚合</li><li id="757b" class="nn no iq lh b li ny ll nz lo oa ls ob lw oc ma nu nv nw nx bi translated">抽样</li><li id="ad66" class="nn no iq lh b li ny ll nz lo oa ls ob lw oc ma nu nv nw nx bi translated">降维</li><li id="48a7" class="nn no iq lh b li ny ll nz lo oa ls ob lw oc ma nu nv nw nx bi translated">特征子集选择</li><li id="4682" class="nn no iq lh b li ny ll nz lo oa ls ob lw oc ma nu nv nw nx bi translated">特征创建</li><li id="919a" class="nn no iq lh b li ny ll nz lo oa ls ob lw oc ma nu nv nw nx bi translated">离散化和二值化</li><li id="5640" class="nn no iq lh b li ny ll nz lo oa ls ob lw oc ma nu nv nw nx bi translated">变量变换</li></ul><h1 id="b621" class="mr ms iq bd mt mu mv mw mx my mz na nb kf nk kg nd ki nl kj nf kl nm km nh ni bi translated">聚合</h1><p id="d71b" class="pw-post-body-paragraph lf lg iq lh b li np ka lk ll nq kd ln lo od lq lr ls oe lu lv lw of ly lz ma ij bi translated">聚合是将两个或多个属性组合成一个属性的技术。</p><h2 id="7f10" class="og ms iq bd mt oh oi dn mx oj ok dp nb lo ol om nd ls on oo nf lw op oq nh iw bi translated">聚合的目的</h2><h2 id="41c9" class="og ms iq bd mt oh oi dn mx oj ok dp nb lo ol om nd ls on oo nf lw op oq nh iw bi translated">数据简化:</h2><p id="30d6" class="pw-post-body-paragraph lf lg iq lh b li np ka lk ll nq kd ln lo od lq lr ls oe lu lv lw of ly lz ma ij bi translated">当我们组合这些属性时，我们获得了一个更小的数据集，其中包含了更少的属性。这有助于我们减少内存使用和快速响应时间。在下面的示例中，属性税与收入合并，因为税块适用于收入超过5L的人。最终，由于通过应用条件来合并列，记录减少了。</p><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div class="gh gi or"><img src="../Images/01f035e9e4a31bde42c7599ba2d857f7.png" data-original-src="https://miro.medium.com/v2/resize:fit:1162/format:webp/1*R-m9PVAD1ExP3C2KmDPV4A.png"/></div><figcaption class="la lb gj gh gi lc ld bd b be z dk translated">作者图片</figcaption></figure><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div class="gh gi os"><img src="../Images/a2d4bd6f767c0397f99d10432e45862c.png" data-original-src="https://miro.medium.com/v2/resize:fit:864/format:webp/1*FXGNKzdT1ZJZLY3jjO_l0A.png"/></div><figcaption class="la lb gj gh gi lc ld bd b be z dk translated">作者图片</figcaption></figure><h2 id="e7c5" class="og ms iq bd mt oh oi dn mx oj ok dp nb lo ol om nd ls on oo nf lw op oq nh iw bi translated">比例变化:</h2><p id="b13c" class="pw-post-body-paragraph lf lg iq lh b li np ka lk ll nq kd ln lo od lq lr ls oe lu lv lw of ly lz ma ij bi translated">可以通过应用比例的变化来聚集数据集。这里我们改变了给定数据集的可能值的总数。例如，在这里的给定数据帧中，计算给定一天中每一分钟的股价。如果我们每周都要分析数据呢？因此，我们得出给定一周的最高价、最低价、收盘价和总成交量的值。这将显著减少数据集中的记录。</p><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div class="gh gi ot"><img src="../Images/19e4563b837cd439e81f704e2e43f094.png" data-original-src="https://miro.medium.com/v2/resize:fit:1218/format:webp/1*W2ge9bdTwro63FDQnd6Mfg.png"/></div><figcaption class="la lb gj gh gi lc ld bd b be z dk translated">作者图片</figcaption></figure><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div class="gh gi ou"><img src="../Images/e56379aa266b3046ae602a0171e6b8d2.png" data-original-src="https://miro.medium.com/v2/resize:fit:974/format:webp/1*jlpUjX1ZbuxfR6wE18UFGA.png"/></div><figcaption class="la lb gj gh gi lc ld bd b be z dk translated">作者图片</figcaption></figure><h1 id="4ac9" class="mr ms iq bd mt mu mv mw mx my mz na nb kf nk kg nd ki nl kj nf kl nm km nh ni bi translated">抽样</h1><ul class=""><li id="f1f7" class="nn no iq lh b li np ll nq lo nr ls ns lw nt ma nu nv nw nx bi translated">抽样是用于数据选择的主要技术。</li></ul><p id="a879" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">–它通常用于数据的初步调查和最终数据分析。</p><ul class=""><li id="8ebd" class="nn no iq lh b li lj ll lm lo ov ls ow lw ox ma nu nv nw nx bi translated"><strong class="lh ja">采样用于数据挖掘，因为处理整个感兴趣的数据集太昂贵或太耗时。</strong></li></ul><h2 id="6a7f" class="og ms iq bd mt oh oi dn mx oj ok dp nb lo ol om nd ls on oo nf lw op oq nh iw bi translated">取样类型</h2><h2 id="4b80" class="og ms iq bd mt oh oi dn mx oj ok dp nb lo ol om nd ls on oo nf lw op oq nh iw bi translated"><strong class="ak">简单随机抽样</strong></h2><p id="04b0" class="pw-post-body-paragraph lf lg iq lh b li np ka lk ll nq kd ln lo od lq lr ls oe lu lv lw of ly lz ma ij bi translated">给定人群中的每条记录都有同等的机会被选中。</p><h2 id="0de0" class="og ms iq bd mt oh oi dn mx oj ok dp nb lo ol om nd ls on oo nf lw op oq nh iw bi translated"><strong class="ak">无替换取样</strong></h2><p id="035b" class="pw-post-body-paragraph lf lg iq lh b li np ka lk ll nq kd ln lo od lq lr ls oe lu lv lw of ly lz ma ij bi translated">选择每个记录将从原始群体中删除该记录。</p><h2 id="f8c2" class="og ms iq bd mt oh oi dn mx oj ok dp nb lo ol om nd ls on oo nf lw op oq nh iw bi translated"><strong class="ak">替换取样</strong></h2><p id="a461" class="pw-post-body-paragraph lf lg iq lh b li np ka lk ll nq kd ln lo od lq lr ls oe lu lv lw of ly lz ma ij bi translated">选择记录并不会将其从原始群体中移除。这些记录可以在以后用于取样。</p><h2 id="6850" class="og ms iq bd mt oh oi dn mx oj ok dp nb lo ol om nd ls on oo nf lw op oq nh iw bi translated"><strong class="ak">分层抽样</strong></h2><p id="414c" class="pw-post-body-paragraph lf lg iq lh b li np ka lk ll nq kd ln lo od lq lr ls oe lu lv lw of ly lz ma ij bi translated">当采样时，记录被分割成分区，从单个分区中选取单个记录。</p><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div class="gh gi oy"><img src="../Images/c5954141d324ffe7d6e292bcbae699bf.png" data-original-src="https://miro.medium.com/v2/resize:fit:1364/format:webp/1*w8EYl2_it1iDfpbTxPa27w.png"/></div><figcaption class="la lb gj gh gi lc ld bd b be z dk translated">作者图片</figcaption></figure><p id="86c4" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">上图是一个更好理解采样概念的例子。从原始图中删除点可能不会影响原始图，但仍然会产生预期的结果。</p><h1 id="fd0b" class="mr ms iq bd mt mu mv mw mx my mz na nb kf nk kg nd ki nl kj nf kl nm km nh ni bi translated">降维</h1><p id="5485" class="pw-post-body-paragraph lf lg iq lh b li np ka lk ll nq kd ln lo od lq lr ls oe lu lv lw of ly lz ma ij bi translated">它是一种找出对输出有很大影响的最相关的特征并丢弃最不相关的特征以降低建模的计算成本并执行模型的平滑功能的技术。</p><h2 id="594e" class="og ms iq bd mt oh oi dn mx oj ok dp nb lo ol om nd ls on oo nf lw op oq nh iw bi translated">优势:</h2><ul class=""><li id="065a" class="nn no iq lh b li np ll nq lo nr ls ns lw nt ma nu nv nw nx bi translated">去除不相关的特征。</li><li id="b928" class="nn no iq lh b li ny ll nz lo oa ls ob lw oc ma nu nv nw nx bi translated">提高模型的预测精度。</li><li id="d51e" class="nn no iq lh b li ny ll nz lo oa ls ob lw oc ma nu nv nw nx bi translated">促进存储和计算成本的降低。</li><li id="a507" class="nn no iq lh b li ny ll nz lo oa ls ob lw oc ma nu nv nw nx bi translated">提高对数据和模型的理解。</li></ul><p id="e25a" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">考虑我们用来解释聚合概念的同一个例子。我们可以直接根据个人的收入来计算应纳税额，而不是用百分比来表示税收。因此，减少要素或列会缩短模型的计算时间。</p><h1 id="a4ee" class="mr ms iq bd mt mu mv mw mx my mz na nb kf nk kg nd ki nl kj nf kl nm km nh ni bi translated">特征子集选择</h1><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div role="button" tabindex="0" class="ku kv di kw bf kx"><div class="gh gi oz"><img src="../Images/acfb347e8fde06ba5dd144b46a618b96.png" data-original-src="https://miro.medium.com/v2/resize:fit:1290/format:webp/1*KSz3EgVjxDRtgYYrj4397Q.png"/></div></div><figcaption class="la lb gj gh gi lc ld bd b be z dk translated">数据挖掘简介—庞-谭宁、迈克尔·斯坦巴克、维平·库马尔</figcaption></figure><p id="ab04" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">特征子集选择也是一种类型降维技术。这里，我们选取了有助于定义鲁棒系统的最佳输出集，该系统可以使我们的误差率最小。在数据挖掘过程中，任何不包含与输出要素相关的特定信息的特定要素都会被丢弃或忽略。</p><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div class="gh gi pa"><img src="../Images/f103d938246577fdbb3c2e344276800c.png" data-original-src="https://miro.medium.com/v2/resize:fit:876/format:webp/1*_VsavLNBHttvv7mirhKXJg.png"/></div><figcaption class="la lb gj gh gi lc ld bd b be z dk translated">作者图片</figcaption></figure><p id="5a23" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">在上图中，我们正在计算一名员工的工资。在这种情况下，我们需要员工的id、工作年限和部门。一个人的性别对输出几乎没有任何影响。因此，在使用该模型计算雇员的工资时，我们放弃了性别列。</p><p id="fb5e" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">应用特征选择技术的方法很少，如下所述:</p><h2 id="8d26" class="og ms iq bd mt oh oi dn mx oj ok dp nb lo ol om nd ls on oo nf lw op oq nh iw bi translated"><strong class="ak">强力方法:</strong></h2><p id="4061" class="pw-post-body-paragraph lf lg iq lh b li np ka lk ll nq kd ln lo od lq lr ls oe lu lv lw of ly lz ma ij bi translated">用户必须尝试所有可能的特征子集作为数据挖掘算法的输入。这种方法是一种试错法，在实践中不推荐使用。</p><h2 id="3aa5" class="og ms iq bd mt oh oi dn mx oj ok dp nb lo ol om nd ls on oo nf lw op oq nh iw bi translated">过滤方法:</h2><p id="becd" class="pw-post-body-paragraph lf lg iq lh b li np ka lk ll nq kd ln lo od lq lr ls oe lu lv lw of ly lz ma ij bi translated">在运行数据挖掘算法之前选择功能。我们找到特征之间的依赖性并定义相关性。相关值介于-1到1之间。相关值越高，特征就变得越重要。</p><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div class="gh gi pb"><img src="../Images/945008763a4c03ed2d78462b8640ac3b.png" data-original-src="https://miro.medium.com/v2/resize:fit:584/format:webp/1*d_-4x9y22WAqaSY3L3tJDA.png"/></div><figcaption class="la lb gj gh gi lc ld bd b be z dk translated">作者图片</figcaption></figure><h2 id="5846" class="og ms iq bd mt oh oi dn mx oj ok dp nb lo ol om nd ls on oo nf lw op oq nh iw bi translated">包装方法:</h2><p id="3f2b" class="pw-post-body-paragraph lf lg iq lh b li np ka lk ll nq kd ln lo od lq lr ls oe lu lv lw of ly lz ma ij bi translated">使用数据挖掘算法作为黑盒来查找属性的最佳子集。</p><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div class="gh gi pc"><img src="../Images/00fd1d21ccd38cb895773f91262705d8.png" data-original-src="https://miro.medium.com/v2/resize:fit:1036/format:webp/1*W0i6_NZpE5HyV1JZbnA9wQ.png"/></div><figcaption class="la lb gj gh gi lc ld bd b be z dk translated">作者图片</figcaption></figure><h1 id="2f0b" class="mr ms iq bd mt mu mv mw mx my mz na nb kf nk kg nd ki nl kj nf kl nm km nh ni bi translated">特征创建</h1><h2 id="0a66" class="og ms iq bd mt oh oi dn mx oj ok dp nb lo ol om nd ls on oo nf lw op oq nh iw bi translated">特征抽出</h2><p id="3223" class="pw-post-body-paragraph lf lg iq lh b li np ka lk ll nq kd ln lo od lq lr ls oe lu lv lw of ly lz ma ij bi translated">从一组给定的属性生成有限特征的过程称为特征提取。例如，如果给你一个名人的面部图像，那么可能仅仅发生代表图像像素的一些边缘或边界就足以让个人识别该名人。因此，如果给我们一个60*60像素的图像，那么我们可以将图像的大小调整为35*35像素，只包含微小的细节，这对于了解图像所代表的内容是必要的。</p><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div class="gh gi pd"><img src="../Images/4a86f55491f1b91cb6f979aaecc2e829.png" data-original-src="https://miro.medium.com/v2/resize:fit:1054/format:webp/1*tj_k4ZPiv4OViSMJRW1IyA.png"/></div><figcaption class="la lb gj gh gi lc ld bd b be z dk translated"><a class="ae le" href="https://www.researchgate.net/publication/327415969_A_Study_on_Face_Detection_Using_Viola-Jones_Algorithm_for_Various_Backgrounds_Angels_and_Distances" rel="noopener ugc nofollow" target="_blank">来源</a></figcaption></figure><p id="b1bb" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">在上面的图像中，我们可以只提取眼睛部分或者两眼之间的部分来生成图像供用户查看。</p><h2 id="044c" class="og ms iq bd mt oh oi dn mx oj ok dp nb lo ol om nd ls on oo nf lw op oq nh iw bi translated">特征构造</h2><p id="ca70" class="pw-post-body-paragraph lf lg iq lh b li np ka lk ll nq kd ln lo od lq lr ls oe lu lv lw of ly lz ma ij bi translated">从现有要素构建新要素的过程称为要素构造。例如，如果我们得到如下所示的学生数据，它包含4个特征，如姓名、id、科学和数学分数。如果老师想要计算这两个科目的分数百分比，那么我们插入一个根据这两个科目的分数计算的新列。</p><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div class="gh gi pe"><img src="../Images/9cae749ed7746270aa22beed5f05aa57.png" data-original-src="https://miro.medium.com/v2/resize:fit:1192/format:webp/1*luUAjyeCJjHYFVuPf_Npbw.png"/></div><figcaption class="la lb gj gh gi lc ld bd b be z dk translated">作者图片</figcaption></figure><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div role="button" tabindex="0" class="ku kv di kw bf kx"><div class="gh gi pf"><img src="../Images/857cde480713570ea67331dfbcb28a97.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*xGQSO1RnoaWbnhk38gqe-Q.png"/></div></div><figcaption class="la lb gj gh gi lc ld bd b be z dk translated">作者图片</figcaption></figure><h1 id="c39e" class="mr ms iq bd mt mu mv mw mx my mz na nb kf nk kg nd ki nl kj nf kl nm km nh ni bi translated">离散化和二值化</h1><h2 id="fb96" class="og ms iq bd mt oh oi dn mx oj ok dp nb lo ol om nd ls on oo nf lw op oq nh iw bi translated">[数]离散化</h2><p id="3a71" class="pw-post-body-paragraph lf lg iq lh b li np ka lk ll nq kd ln lo od lq lr ls oe lu lv lw of ly lz ma ij bi translated">离散化是一种根据值对要素进行分组的方法。</p><p id="2af5" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">更一般地说，它是一种为变量的给定连续值集指定离散范围的方法。</p><p id="52d0" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">如下所示，我们定义了该国某个特定城市某个家庭的平均成员人数。从通过各种来源收集的不同数据中可以看出，某个城市的家庭成员一般都在一个确定的范围内。定义给定要素范围的过程有助于通过减小数据集的大小来降低计算的复杂性。</p><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div role="button" tabindex="0" class="ku kv di kw bf kx"><div class="gh gi pg"><img src="../Images/d4dfb6c8f0e5a38ef37f36fafdec37bc.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*VTuiNt0gCU6T8bN3wNHVBg.png"/></div></div><figcaption class="la lb gj gh gi lc ld bd b be z dk translated">作者图片</figcaption></figure><h2 id="d08f" class="og ms iq bd mt oh oi dn mx oj ok dp nb lo ol om nd ls on oo nf lw op oq nh iw bi translated">二值化</h2><p id="5ad3" class="pw-post-body-paragraph lf lg iq lh b li np ka lk ll nq kd ln lo od lq lr ls oe lu lv lw of ly lz ma ij bi translated">这是一种将属性转换成二进制变量格式的方法。具有多个相关值的特征使用skit-learn库中可用的方法进行分类编码，并以0和1的形式表示。</p><p id="28be" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">考虑下面的例子，在这个例子中，我们考虑到了人们和他们所属的国家。因为有大量的国家，所以我们可以将国家的表示转换成二进制格式。</p><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div class="gh gi ph"><img src="../Images/2009c613d6b76aae148eba0236f63daf.png" data-original-src="https://miro.medium.com/v2/resize:fit:962/format:webp/1*mMPGkh-zYiiCwYKNpIcF9w.png"/></div><figcaption class="la lb gj gh gi lc ld bd b be z dk translated">作者图片</figcaption></figure><h1 id="1578" class="mr ms iq bd mt mu mv mw mx my mz na nb kf nk kg nd ki nl kj nf kl nm km nh ni bi translated">属性转换</h1><p id="04c6" class="pw-post-body-paragraph lf lg iq lh b li np ka lk ll nq kd ln lo od lq lr ls oe lu lv lw of ly lz ma ij bi translated">一种在相同比例范围内映射特征的技术。这些特征总是具有不同范围的值。例如，重量总是以千克为单位，其值通常在80-120千克之间。人的身高是以厘米为单位来衡量的，它的范围是160厘米-180厘米。因此，在预测输出函数时，所有特征必须落在相同的范围内。为了达到同样的目的，我们使用下面提到的两种著名技术:</p><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div role="button" tabindex="0" class="ku kv di kw bf kx"><div class="gh gi pi"><img src="../Images/12b04c2883dba01fa3137b745a809cdb.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*xm-nCPMowsg96Mt5hWtxog.png"/></div></div><figcaption class="la lb gj gh gi lc ld bd b be z dk translated">作者图片</figcaption></figure><h2 id="e421" class="og ms iq bd mt oh oi dn mx oj ok dp nb lo ol om nd ls on oo nf lw op oq nh iw bi translated">z分数标准化</h2><p id="094a" class="pw-post-body-paragraph lf lg iq lh b li np ka lk ll nq kd ln lo od lq lr ls oe lu lv lw of ly lz ma ij bi translated">一种使用给定特征的均值和标准差来找出给定记录的归一化特征值的方法。归一化值如上图所示，其中平均值从原始值中减去，然后除以其标准偏差。这将在-1到1的范围内转换任何给定特性的值。</p><h2 id="eebb" class="og ms iq bd mt oh oi dn mx oj ok dp nb lo ol om nd ls on oo nf lw op oq nh iw bi translated">最小/最大标准化</h2><p id="d55a" class="pw-post-body-paragraph lf lg iq lh b li np ka lk ll nq kd ln lo od lq lr ls oe lu lv lw of ly lz ma ij bi translated">一种使用特征的最小值和最大值来找出给定记录的归一化特征值的方法。归一化值如上图所示，其中最小值从原始值中减去，然后除以其最大值。这将在1到-1的范围内转换给定特性的值。</p><p id="991c" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">来源参考:</p><div class="pj pk gp gr pl pm"><a href="https://www.coursehero.com/file/p7qdlan/Reduce-amount-of-time-and-memory-required-by-data-mining-algorithms-Allow-data/" rel="noopener  ugc nofollow" target="_blank"><div class="pn ab fo"><div class="po ab pp cl cj pq"><h2 class="bd ja gy z fp pr fr fs ps fu fw iz bi translated">减少数据挖掘算法所需的时间和内存量允许数据|课程英雄</h2><div class="pt l"><h3 class="bd b gy z fp pr fr fs ps fu fw dk translated">减少数据挖掘算法所需的时间和内存量允许来自伊拉斯谟大学CS FEB53020的数据…</h3></div><div class="pu l"><p class="bd b dl z fp pr fr fs ps fu fw dk translated">www.coursehero.com</p></div></div><div class="pv l"><div class="pw l px py pz pv qa ky pm"/></div></div></a></div><div class="pj pk gp gr pl pm"><a href="https://towardsdatascience.com/data-preprocessing-in-data-mining-machine-learning-79a9662e2eb" rel="noopener follow" target="_blank"><div class="pn ab fo"><div class="po ab pp cl cj pq"><h2 class="bd ja gy z fp pr fr fs ps fu fw iz bi translated">数据挖掘和机器学习中的数据预处理</h2><div class="pt l"><h3 class="bd b gy z fp pr fr fs ps fu fw dk translated">有了详细的概念…</h3></div><div class="pu l"><p class="bd b dl z fp pr fr fs ps fu fw dk translated">towardsdatascience.com</p></div></div><div class="pv l"><div class="qb l px py pz pv qa ky pm"/></div></div></a></div></div></div>    
</body>
</html>