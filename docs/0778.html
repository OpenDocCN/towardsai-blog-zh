<html>
<head>
<title>Getting Started with Titanic Kaggle | Part 2</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">泰坦尼克号起航|第二部分</h1>
<blockquote>原文：<a href="https://pub.towardsai.net/getting-started-with-titanic-kaggle-part-2-by-durgesh-samariya-f062f3b65b6e?source=collection_archive---------2-----------------------#2020-08-08">https://pub.towardsai.net/getting-started-with-titanic-kaggle-part-2-by-durgesh-samariya-f062f3b65b6e?source=collection_archive---------2-----------------------#2020-08-08</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><h2 id="9933" class="ir is it bd b dl iu iv iw ix iy iz dk ja translated" aria-label="kicker paragraph"><a class="ae ep" href="https://towardsai.net/p/category/machine-learning" rel="noopener ugc nofollow" target="_blank">机器学习</a></h2><div class=""/><div class=""><h2 id="afcc" class="pw-subtitle-paragraph jz jc it bd b ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq dk translated">让我们开发一个模型来预测泰坦尼克号对Kaggle的挑战</h2></div><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi kr"><img src="../Images/333a00e553e53a485599bd7522ebae02.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*UQzwjhmryMUHDR0sT-9GIw.jpeg"/></div></div><figcaption class="ld le gj gh gi lf lg bd b be z dk translated">来源:<a class="ae lh" href="https://www.nationalgeographic.org/media/sinking-of-the-titanic/" rel="noopener ugc nofollow" target="_blank">国家地理</a></figcaption></figure><p id="0c64" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">在上一篇文章中，我们开始着手泰坦尼克号卡格尔比赛。如果你还没有读过，你可以在这里阅读<a class="ae lh" href="https://medium.com/towards-artificial-intelligence/getting-started-with-titanic-kaggle-447a309f2d19" rel="noopener"/>。所以在这篇文章中，我们将使用机器学习来开发预测模型。</p><p id="0744" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">如果您已经关注了我的上一篇文章，那么现在我们的数据已经准备好了，可以准备模型了。有大量的预测算法可供尝试。然而，我们的问题是分类问题，因此我将尝试以下分类/回归算法。</p><ul class=""><li id="2e77" class="me mf it lk b ll lm lo lp lr mg lv mh lz mi md mj mk ml mm bi translated">支持向量机</li><li id="b2d7" class="me mf it lk b ll mn lo mo lr mp lv mq lz mr md mj mk ml mm bi translated">k-最近邻</li><li id="3897" class="me mf it lk b ll mn lo mo lr mp lv mq lz mr md mj mk ml mm bi translated">线性SVC</li><li id="774c" class="me mf it lk b ll mn lo mo lr mp lv mq lz mr md mj mk ml mm bi translated">决策图表</li><li id="a672" class="me mf it lk b ll mn lo mo lr mp lv mq lz mr md mj mk ml mm bi translated">随机森林</li></ul></div><div class="ab cl ms mt hx mu" role="separator"><span class="mv bw bk mw mx my"/><span class="mv bw bk mw mx my"/><span class="mv bw bk mw mx"/></div><div class="im in io ip iq"><h1 id="6aec" class="mz na it bd nb nc nd ne nf ng nh ni nj ki nk kj nl kl nm km nn ko no kp np nq bi translated">首先要做的事。</h1><h1 id="263d" class="mz na it bd nb nc nr ne nf ng ns ni nj ki nt kj nl kl nu km nn ko nv kp np nq bi translated">导入所有必需的机器学习库</h1><p id="2cb5" class="pw-post-body-paragraph li lj it lk b ll nw kd ln lo nx kg lq lr ny lt lu lv nz lx ly lz oa mb mc md im bi translated">为了开发一个机器学习模型，我们需要导入<a class="ae lh" href="https://scikit-learn.org/stable/" rel="noopener ugc nofollow" target="_blank"> Scikit-learn </a>库。</p><blockquote class="ob oc od"><p id="bbc8" class="li lj oe lk b ll lm kd ln lo lp kg lq of ls lt lu og lw lx ly oh ma mb mc md im bi translated">Scikit-Learn是一个开源的机器学习库，支持监督和非监督学习。它还提供了用于模型拟合、数据预处理、模型选择和评估的各种工具，以及许多其他实用工具。— <a class="ae lh" href="https://scikit-learn.org/stable/getting_started.html" rel="noopener ugc nofollow" target="_blank"> Scikit-Learn </a></p></blockquote><p id="7b4c" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">让我们从Scikit-Learn导入所有需要的算法。</p><pre class="ks kt ku kv gt oi oj ok ol aw om bi"><span id="bb44" class="on na it oj b gy oo op l oq or"><em class="oe"># machine learning</em><br/>from sklearn.svm import SVC, LinearSVC<br/>from sklearn.ensemble import RandomForestClassifier<br/>from sklearn.neighbors import KNeighborsClassifier<br/>from sklearn.tree import DecisionTreeClassifier</span></pre><p id="d32f" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">每种机器学习分类算法都需要训练和测试数据来训练和测试模型。</p><pre class="ks kt ku kv gt oi oj ok ol aw om bi"><span id="fe82" class="on na it oj b gy oo op l oq or"># dropping Name, Survived and PassengerId column<br/>X_train = train_data.drop(["Name", "Survived", "PassengerId"], axis=1)<br/>Y_train = train_data["Survived"]<br/>X_test  = test_data.drop(['Name',"PassengerId"], axis=1).copy()<br/>X_train.shape, Y_train.shape, X_test.shape</span></pre></div><div class="ab cl ms mt hx mu" role="separator"><span class="mv bw bk mw mx my"/><span class="mv bw bk mw mx my"/><span class="mv bw bk mw mx"/></div><div class="im in io ip iq"><h1 id="e5a3" class="mz na it bd nb nc nd ne nf ng nh ni nj ki nk kj nl kl nm km nn ko no kp np nq bi translated">支持向量机</h1><blockquote class="ob oc od"><p id="12f5" class="li lj oe lk b ll lm kd ln lo lp kg lq of ls lt lu og lw lx ly oh ma mb mc md im bi translated">支持向量机在高维或无限维空间中构造一个超平面或一组超平面，可用于分类、回归或其他任务，如异常值检测。— <a class="ae lh" href="https://en.wikipedia.org/wiki/Support_vector_machine" rel="noopener ugc nofollow" target="_blank">维基百科</a></p></blockquote><pre class="ks kt ku kv gt oi oj ok ol aw om bi"><span id="ef74" class="on na it oj b gy oo op l oq or"><em class="oe"># Support Vector Machine</em><br/>svc = SVC()<br/>svc.fit(X_train, Y_train)<br/>svm_Y_pred = svc.predict(X_test)<br/>svc_accuracy = svc.score(X_train, Y_train)<br/>svc_accuracy</span><span id="c6fe" class="on na it oj b gy os op l oq or"># output<br/>0.6823793490460157</span></pre><h1 id="d75c" class="mz na it bd nb nc nr ne nf ng ns ni nj ki nt kj nl kl nu km nn ko nv kp np nq bi translated">k-最近邻</h1><blockquote class="ob oc od"><p id="aa72" class="li lj oe lk b ll lm kd ln lo lp kg lq of ls lt lu og lw lx ly oh ma mb mc md im bi translated">在K <em class="it"> -NN分类</em>中，输出的是一个类成员关系。一个对象通过其邻居的多数投票来分类，其中该对象被分配到其<em class="it"> k </em>个最近邻居中最常见的类别— <a class="ae lh" href="https://en.wikipedia.org/wiki/K-nearest_neighbors_algorithm" rel="noopener ugc nofollow" target="_blank">维基百科</a></p></blockquote><pre class="ks kt ku kv gt oi oj ok ol aw om bi"><span id="8398" class="on na it oj b gy oo op l oq or"><em class="oe"># k-nearest neighbor</em><br/>knn = KNeighborsClassifier(n_neighbors = 3)<br/>knn.fit(X_train, Y_train)<br/>knn_Y_pred = knn.predict(X_test)<br/>knn_accuracy = knn.score(X_train, Y_train)<br/>knn_accuracy</span><span id="f23c" class="on na it oj b gy os op l oq or"># output<br/>0.8406285072951739</span></pre><h1 id="d719" class="mz na it bd nb nc nr ne nf ng ns ni nj ki nt kj nl kl nu km nn ko nv kp np nq bi translated">线性支持向量分类</h1><blockquote class="ob oc od"><p id="678e" class="li lj oe lk b ll lm kd ln lo lp kg lq of ls lt lu og lw lx ly oh ma mb mc md im bi translated">类似于带有参数kernel='linear '的SVC，但它是根据liblinear而不是libsvm实现的，因此它在选择惩罚和损失函数方面具有更大的灵活性，并且应该可以更好地扩展到大量样本。— <a class="ae lh" href="https://scikit-learn.org/stable/modules/generated/sklearn.svm.LinearSVC.html" rel="noopener ugc nofollow" target="_blank">来源</a></p></blockquote><pre class="ks kt ku kv gt oi oj ok ol aw om bi"><span id="269e" class="on na it oj b gy oo op l oq or"><em class="oe"># Linear SVC</em><br/><br/>linear_svc = LinearSVC()<br/>linear_svc.fit(X_train, Y_train)<br/>linear_svc_Y_pred = linear_svc.predict(X_test)<br/>linear_svc_accuracy = linear_svc.score(X_train, Y_train)<br/>linear_svc_accuracy</span><span id="0642" class="on na it oj b gy os op l oq or"># output<br/>0.792368125701459</span></pre><h1 id="ff5f" class="mz na it bd nb nc nr ne nf ng ns ni nj ki nt kj nl kl nu km nn ko nv kp np nq bi translated">决策树</h1><blockquote class="ob oc od"><p id="1ae3" class="li lj oe lk b ll lm kd ln lo lp kg lq of ls lt lu og lw lx ly oh ma mb mc md im bi translated">决策树学习是数据挖掘中常用的一种方法。目标是创建一个模型，根据几个输入变量预测目标变量的值。</p><p id="2f08" class="li lj oe lk b ll lm kd ln lo lp kg lq of ls lt lu og lw lx ly oh ma mb mc md im bi translated">决策树是对例子进行分类的简单表示。对于本节，假设所有输入要素都有有限的离散域，并且有一个称为“分类”的目标要素。分类领域的每个元素被称为一个<em class="it">类</em>。— <a class="ae lh" href="https://en.wikipedia.org/wiki/Decision_tree_learning" rel="noopener ugc nofollow" target="_blank">维基百科</a></p></blockquote><pre class="ks kt ku kv gt oi oj ok ol aw om bi"><span id="6dc3" class="on na it oj b gy oo op l oq or"><em class="oe"># Decision Tree</em><br/><br/>decision_tree = DecisionTreeClassifier()<br/>decision_tree.fit(X_train, Y_train)<br/>decision_tree_Y_pred = decision_tree.predict(X_test)<br/>decision_tree_accuracy = decision_tree.score(X_train, Y_train)<br/>decision_tree_accuracy</span><span id="69bd" class="on na it oj b gy os op l oq or"># output<br/>0.9797979797979798</span></pre><h1 id="0883" class="mz na it bd nb nc nr ne nf ng ns ni nj ki nt kj nl kl nu km nn ko nv kp np nq bi translated">随机森林</h1><blockquote class="ob oc od"><p id="08e3" class="li lj oe lk b ll lm kd ln lo lp kg lq of ls lt lu og lw lx ly oh ma mb mc md im bi translated">随机<strong class="lk jd"> </strong>森林或随机<strong class="lk jd"> </strong>决策<strong class="lk jd"> </strong>森林是一种用于分类、回归和其他任务的集成学习方法，其通过在训练时构建大量决策树并输出作为个体树的类(分类)或均值预测(回归)的模式的类来操作。— <a class="ae lh" href="https://en.wikipedia.org/wiki/Random_forest" rel="noopener ugc nofollow" target="_blank">维基百科</a></p></blockquote><pre class="ks kt ku kv gt oi oj ok ol aw om bi"><span id="53d0" class="on na it oj b gy oo op l oq or"><em class="oe"># Random Forest</em><br/><br/>random_forest = RandomForestClassifier(n_estimators=100)<br/>random_forest.fit(X_train, Y_train<br/>random_forest_Y_pred = random_forest.predict(X_test)<br/>random_forest.score(X_train, Y_train)<br/>random_forest_accuracy = random_forest.score(X_train, Y_train)<br/>random_forest_accuracy</span><span id="90db" class="on na it oj b gy os op l oq or"># output<br/>0.9797979797979798</span></pre></div><div class="ab cl ms mt hx mu" role="separator"><span class="mv bw bk mw mx my"/><span class="mv bw bk mw mx my"/><span class="mv bw bk mw mx"/></div><div class="im in io ip iq"><h1 id="2e66" class="mz na it bd nb nc nd ne nf ng nh ni nj ki nk kj nl kl nm km nn ko no kp np nq bi translated">每个模型的提交文件</h1><p id="86d4" class="pw-post-body-paragraph li lj it lk b ll nw kd ln lo nx kg lq lr ny lt lu lv nz lx ly lz oa mb mc md im bi translated">现在，我们使用不同的模型对每个测试数据进行预测。是时候为竞赛创建一个提交文件了。我们必须创建一个像这样的提交文件。</p><figure class="ks kt ku kv gt kw"><div class="bz fp l di"><div class="ot ou l"/></div></figure><p id="83a6" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">提交文件包含两列。</p><ul class=""><li id="ec51" class="me mf it lk b ll lm lo lp lr mg lv mh lz mi md mj mk ml mm bi translated">从892到1148的乘客id(在test.csv中可用)</li><li id="3547" class="me mf it lk b ll mn lo mo lr mp lv mq lz mr md mj mk ml mm bi translated">幸存——这是我们用不同的模型预测的。</li></ul><p id="e6b6" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">让我们看看如何做到这一点。</p><pre class="ks kt ku kv gt oi oj ok ol aw om bi"><span id="a659" class="on na it oj b gy oo op l oq or"><em class="oe"># submission file from each model</em><br/>svm_submission = pd.DataFrame({"PassengerId": test_data["PassengerId"], "Survived": svm_Y_pred})<br/>svm_submission.to_csv('svm_submission.csv', index=False)<br/><br/>knn_submission = pd.DataFrame({"PassengerId": test_data["PassengerId"], "Survived": knn_Y_pred})<br/>knn_submission.to_csv('knn_submission.csv', index=False)<br/><br/>linear_svc_submission = pd.DataFrame({"PassengerId": test_data["PassengerId"], "Survived": linear_svc_Y_pred})<br/>linear_svc_submission.to_csv('linear_svc_submission.csv', index=False)<br/><br/>decision_tree_submission = pd.DataFrame({"PassengerId": test_data["PassengerId"], "Survived": decision_tree_Y_pred})<br/>decision_tree_submission.to_csv('decision_tree_submission.csv', index=False)<br/><br/>random_forest_submission = pd.DataFrame({"PassengerId": test_data["PassengerId"], "Survived": random_forest_Y_pred})<br/>random_forest_submission.to_csv('random_forest_submission.csv', index=False)</span></pre><p id="a442" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">现在我们有五个不同的提交文件。你甚至可以尝试不同的算法来寻找更好的解决方案。这是帖子的结尾。你可以在这里找到完整的kaggle内核。</p><p id="df71" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated"><strong class="lk jd">感谢阅读！快乐的机器学习。</strong></p></div><div class="ab cl ms mt hx mu" role="separator"><span class="mv bw bk mw mx my"/><span class="mv bw bk mw mx my"/><span class="mv bw bk mw mx"/></div><div class="im in io ip iq"><p id="78e9" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">如果你喜欢我的工作并想支持我，我会非常感谢你在我的社交媒体频道上关注我:</p><ul class=""><li id="7426" class="me mf it lk b ll lm lo lp lr mg lv mh lz mi md mj mk ml mm bi translated">支持我的最好方式就是在<a class="ae lh" href="https://medium.com/@themlphdstudent" rel="noopener"><strong class="lk jd"/></a>媒体上关注我。</li><li id="ebc2" class="me mf it lk b ll mn lo mo lr mp lv mq lz mr md mj mk ml mm bi translated">订阅我的新<a class="ae lh" href="https://www.youtube.com/c/themlphdstudent" rel="noopener ugc nofollow" target="_blank"> <strong class="lk jd"> YouTube频道</strong> </a>。</li><li id="993a" class="me mf it lk b ll mn lo mo lr mp lv mq lz mr md mj mk ml mm bi translated">在我的<a class="ae lh" href="http://eepurl.com/hampwT" rel="noopener ugc nofollow" target="_blank"> <strong class="lk jd">邮箱列表</strong> </a>报名。</li></ul></div><div class="ab cl ms mt hx mu" role="separator"><span class="mv bw bk mw mx my"/><span class="mv bw bk mw mx my"/><span class="mv bw bk mw mx"/></div><div class="im in io ip iq"><p id="0bfc" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated"><strong class="lk jd">万一你错过了上一篇文章</strong></p><p id="9af7" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated"><a class="ae lh" href="https://medium.com/towards-artificial-intelligence/getting-started-with-titanic-kaggle-447a309f2d19" rel="noopener">泰坦尼克号起航|第一部</a></p><p id="8c24" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated"><strong class="lk jd">如果你错过了我的python系列。</strong></p><ul class=""><li id="b7a0" class="me mf it lk b ll lm lo lp lr mg lv mh lz mi md mj mk ml mm bi translated">第0天:<a class="ae lh" href="/@durgeshsamariya/100-days-of-machine-learning-code-a9074e1c42c3" rel="noopener ugc nofollow" target="_blank">挑战介绍</a></li><li id="8a02" class="me mf it lk b ll mn lo mo lr mp lv mq lz mr md mj mk ml mm bi translated">第1天:<a class="ae lh" href="/the-innovation/python-basics-variables-data-types-and-list-59cea3dfe10f" rel="noopener ugc nofollow" target="_blank"> Python基础知识— 1 </a></li><li id="c4ab" class="me mf it lk b ll mn lo mo lr mp lv mq lz mr md mj mk ml mm bi translated">第2天:<a class="ae lh" href="https://towardsdatascience.com/python-basics-2-working-with-list-tuples-dictionaries-871c6c01bb51" rel="noopener" target="_blank"> Python基础知识— 2 </a></li><li id="8764" class="me mf it lk b ll mn lo mo lr mp lv mq lz mr md mj mk ml mm bi translated">第3天:<a class="ae lh" href="/towards-artificial-intelligence/python-basics-3-97a8e69066e7" rel="noopener ugc nofollow" target="_blank"> Python基础知识— 3 </a></li><li id="05b4" class="me mf it lk b ll mn lo mo lr mp lv mq lz mr md mj mk ml mm bi translated">第4天:<a class="ae lh" href="/javarevisited/python-basics-4-functions-working-with-functions-classes-working-with-class-inheritance-70e0338c1b2e" rel="noopener ugc nofollow" target="_blank"> Python基础— 4 </a></li><li id="5859" class="me mf it lk b ll mn lo mo lr mp lv mq lz mr md mj mk ml mm bi translated">第5天:<a class="ae lh" href="/towards-artificial-intelligence/python-basics-5-files-and-exceptions-by-durgesh-samariya-5d892d170640" rel="noopener ugc nofollow" target="_blank"> Python基础— 5 </a></li></ul><p id="8771" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">我希望你会喜欢我的其他文章。</p><ul class=""><li id="d6bd" class="me mf it lk b ll lm lo lp lr mg lv mh lz mi md mj mk ml mm bi translated">给初学者的Git</li><li id="a64d" class="me mf it lk b ll mn lo mo lr mp lv mq lz mr md mj mk ml mm bi translated"><a class="ae lh" href="/@durgeshsamariya/august-2020-monthly-machine-learning-reading-list-by-durgesh-samariya-20028aa1d5cc" rel="noopener ugc nofollow" target="_blank">八月月度阅读清单</a></li><li id="63eb" class="me mf it lk b ll mn lo mo lr mp lv mq lz mr md mj mk ml mm bi translated"><a class="ae lh" href="/towards-artificial-intelligence/a-curated-list-of-clustering-resources-fe355e0e058e" rel="noopener ugc nofollow" target="_blank">集群资源</a></li><li id="de76" class="me mf it lk b ll mn lo mo lr mp lv mq lz mr md mj mk ml mm bi translated"><a class="ae lh" href="/dev-genius/curated-list-of-outlier-detection-resources-35ed27d0e46e" rel="noopener ugc nofollow" target="_blank">离群点检测资源</a></li></ul></div></div>    
</body>
</html>