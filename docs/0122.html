<html>
<head>
<title>Baby Steps to TensorFlow</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">婴儿迈向TensorFlow</h1>
<blockquote>原文：<a href="https://pub.towardsai.net/baby-steps-to-tensorflow-22972dd3bd7e?source=collection_archive---------1-----------------------#2019-08-01">https://pub.towardsai.net/baby-steps-to-tensorflow-22972dd3bd7e?source=collection_archive---------1-----------------------#2019-08-01</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><h2 id="581f" class="io ip iq bd b dl ir is it iu iv iw dk ix translated" aria-label="kicker paragraph">创建一个简单的面向AI的张量流模型的教程|<a class="ae ep" href="https://towardsai.net/" rel="noopener ugc nofollow" target="_blank"/></h2><div class=""/><div class=""><h2 id="eec1" class="pw-subtitle-paragraph jw iz iq bd b jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn dk translated">训练您的第一个基于Tensorflow的神经网络模型，用于摄氏度到华氏<strong class="ak">度</strong>的转换</h2></div><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div class="gh gi ko"><img src="../Images/60bd9d740eae0aac92900211d7d7a4d2.png" data-original-src="https://miro.medium.com/v2/resize:fit:1024/format:webp/1*i2Vl51I1XTiZOgm0CORw6A.png"/></div></figure><p id="aa0f" class="pw-post-body-paragraph kw kx iq ky b kz la ka lb lc ld kd le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">TensorFlow是一个面向研究和生产的开源机器学习库。它提供了<a class="ae ls" href="https://medium.com/free-code-camp/what-is-an-api-in-english-please-b880a3214a82" rel="noopener"><strong class="ky ja"><em class="lt">API</em></strong></a>供初学者和专家开发桌面、移动、web和云。参见<a class="ae ls" href="https://www.tensorflow.org/tutorials" rel="noopener ugc nofollow" target="_blank"> <strong class="ky ja"> <em class="lt">链接</em> </strong> </a> <strong class="ky ja"> <em class="lt">。</em>T19】</strong></p><p id="7725" class="pw-post-body-paragraph kw kx iq ky b kz la ka lb lc ld kd le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">软件库是一组函数和模块，您可以通过代码调用它们来执行特定的任务。</p><p id="4583" class="pw-post-body-paragraph kw kx iq ky b kz la ka lb lc ld kd le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">在继续之前，我假设你已经习惯了用python编码，并且对机器学习有一些基本的了解。</p><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div role="button" tabindex="0" class="lv lw di lx bf ly"><div class="gh gi lu"><img src="../Images/cecbda32abb9ca3ae8539c44a9ed3d68.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*jAzi88LbxU3q0-5iJ1cjyw.png"/></div></div><figcaption class="lz ma gj gh gi mb mc bd b be z dk translated">多维数组(张量)| <a class="ae ls" href="https://s3-ap-south-1.amazonaws.com/av-blog-media/wp-content/uploads/2017/03/29102900/Image1.png" rel="noopener ugc nofollow" target="_blank"> img_credit </a></figcaption></figure><p id="b9b4" class="pw-post-body-paragraph kw kx iq ky b kz la ka lb lc ld kd le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">TensorFlow可以说是GitHub上最受欢迎的机器学习库。它基于计算图的概念。</p><p id="0694" class="pw-post-body-paragraph kw kx iq ky b kz la ka lb lc ld kd le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">在计算图中，节点代表持久数据或数学运算，边代表节点之间的数据流。流经这些边缘的数据是一个被称为张量的多维数组，因此该库被命名为“<strong class="ky ja"> TensorFlow </strong>”。</p><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div role="button" tabindex="0" class="lv lw di lx bf ly"><div class="gh gi md"><img src="../Images/48c9c2d3d6f426747649c705962b5e31.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Ys2X6Q-hgzUoyLWkWpYFbQ.png"/></div></div><figcaption class="lz ma gj gh gi mb mc bd b be z dk translated">节点代表圆形，边是箭头| <a class="ae ls" href="https://cdn-images-1.medium.com/max/1600/1*zeXlzGhBoCl8clrpwtVbRQ.png" rel="noopener"> img_credit </a></figcaption></figure><p id="6372" class="pw-post-body-paragraph kw kx iq ky b kz la ka lb lc ld kd le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">这里我们将尽量保持简单，只介绍基本概念。</p><p id="ee85" class="pw-post-body-paragraph kw kx iq ky b kz la ka lb lc ld kd le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">我们要解决的问题是使用简单的张量流模型将摄氏温度值转换为华氏温度值，其近似公式为:</p><pre class="kp kq kr ks gt me mf mg mh aw mi bi"><span id="a349" class="mj mk iq mf b gy ml mm l mn mo"><strong class="mf ja">Fahrenheit = Celsius * 1.8 + 32</strong></span></pre><blockquote class="mp mq mr"><p id="9f60" class="kw kx lt ky b kz la ka lb lc ld kd le ms lg lh li mt lk ll lm mu lo lp lq lr ij bi translated">这意味着手动将30摄氏度转换为华氏温度，我们需要做的就是将30乘以1.8，然后将32加到结果上，得到86。参见<a class="ae ls" href="https://www.rapidtables.com/convert/temperature/30-c-to-f.html" rel="noopener ugc nofollow" target="_blank"> <strong class="ky ja">链接</strong> </a></p></blockquote><p id="7f5c" class="pw-post-body-paragraph kw kx iq ky b kz la ka lb lc ld kd le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">当然，创建一个直接执行这种转换的传统Python函数是足够简单的，但这将是机器学习的<strong class="ky ja"> <em class="lt">而不是</em> </strong>。</p><p id="77bb" class="pw-post-body-paragraph kw kx iq ky b kz la ka lb lc ld kd le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">相反，我们将为TensorFlow提供一些样本摄氏温度值及其对应的华氏温度值。然后，我们将通过训练过程训练一个模型来计算上述公式。我们将使用该模型将任意值从摄氏温度转换为华氏温度，并最终评估该模型。</p><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div role="button" tabindex="0" class="lv lw di lx bf ly"><div class="gh gi mv"><img src="../Images/1b52b92cc3f98196797f89169d5525fd.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*RST3NDXBkbw9bir__quz2Q.jpeg"/></div></div></figure><h2 id="6f65" class="mj mk iq bd mw mx my dn mz na nb dp nc lf nd ne nf lj ng nh ni ln nj nk nl iw bi translated">底漆:</h2><blockquote class="mp mq mr"><p id="2fc0" class="kw kx lt ky b kz la ka lb lc ld kd le ms lg lh li mt lk ll lm mu lo lp lq lr ij bi translated"><strong class="ky ja">神经网络:</strong></p><p id="67cc" class="kw kx lt ky b kz la ka lb lc ld kd le ms lg lh li mt lk ll lm mu lo lp lq lr ij bi translated">神经网络基本上是一组可以学习模式的功能。</p></blockquote><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div class="gh gi nm"><img src="../Images/2c408f50edfd8e67a4c0f132fcd9431d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1020/1*OR-E2JnFw8PW03poaeSfIw.gif"/></div><figcaption class="lz ma gj gh gi mb mc bd b be z dk translated">具有两个隐藏层的神经网络的视觉| <a class="ae ls" href="https://www.google.com/url?sa=i&amp;source=images&amp;cd=&amp;ved=2ahUKEwjagLWqkL3jAhWS5OAKHQ9bAXcQjRx6BAgBEAU&amp;url=http%3A%2F%2Fpages.cs.wisc.edu%2F~bolo%2Fshipyard%2Fneural%2Flocal.html&amp;psig=AOvVaw38MiIHLhoyqHZyg8b5pOx2&amp;ust=1563493222437896" rel="noopener ugc nofollow" target="_blank"> img_credit </a></figcaption></figure><blockquote class="mp mq mr"><p id="8c97" class="kw kx lt ky b kz la ka lb lc ld kd le ms lg lh li mt lk ll lm mu lo lp lq lr ij bi translated">在传统编程中，我们将规则和数据集传递给程序，然后计算机返回答案。<br/>在机器学习中，我们基本上是将答案和尽可能多的关于例子的数据(成对的特征和标签)传递给计算机，计算机找出规则，以准确预测或确定未来看不见的数据的答案。</p></blockquote><h1 id="9ca4" class="nn mk iq bd mw no np nq mz nr ns nt nc kf nu kg nf ki nv kj ni kl nw km nl nx bi translated">导入依赖项</h1><p id="84d3" class="pw-post-body-paragraph kw kx iq ky b kz ny ka lb lc nz kd le lf oa lh li lj ob ll lm ln oc lp lq lr ij bi translated">首先导入TensorFlow为<code class="fe od oe of mf b"><strong class="ky ja">tf</strong></code>便于使用。我们还告诉它只显示错误日志，如果有的话。</p><pre class="kp kq kr ks gt me mf mg mh aw mi bi"><span id="6dc8" class="mj mk iq mf b gy ml mm l mn mo"><strong class="mf ja">import tensorflow as tf<br/>tf.logging.set_verbosity(tf.logging.ERROR)</strong></span><span id="677d" class="mj mk iq mf b gy og mm l mn mo"><strong class="mf ja">import numpy as np<br/>import matplotlib.pyplot as plt</strong></span></pre><h2 id="05bb" class="mj mk iq bd mw mx my dn mz na nb dp nc lf nd ne nf lj ng nh ni ln nj nk nl iw bi translated">设置培训数据:</h2><p id="ff04" class="pw-post-body-paragraph kw kx iq ky b kz ny ka lb lc nz kd le lf oa lh li lj ob ll lm ln oc lp lq lr ij bi translated">由于任务是创建一个模型，当给定摄氏度时，该模型可以预测华氏温度值，因此我们将创建两个列表来训练该模型。一个用于摄氏度，另一个用于相应的华氏温度值。</p><pre class="kp kq kr ks gt me mf mg mh aw mi bi"><span id="6492" class="mj mk iq mf b gy ml mm l mn mo"># Let's create two lists for celsius and fahrenheit using numpy</span><span id="a7f6" class="mj mk iq mf b gy og mm l mn mo"><strong class="mf ja">celsius_q    = np.array([-40, -10,  0,  8, 15, 22,  38],  dtype=float)</strong></span><span id="5283" class="mj mk iq mf b gy og mm l mn mo"><strong class="mf ja">fahrenheit_a = np.array([-40,  14, 32, 46, 59, 72, 100],  dtype=float)</strong></span><span id="c8b8" class="mj mk iq mf b gy og mm l mn mo"># Let's iterate through the list and print out the corresponding #values</span><span id="0a62" class="mj mk iq mf b gy og mm l mn mo"><strong class="mf ja">for i,c in enumerate(celsius_q):<br/>    print("{} degrees Celsius = {} degrees Fahrenhet".format(c, fahrenheit_a[i]))</strong></span><span id="b2bb" class="mj mk iq mf b gy og mm l mn mo">&gt;&gt; <br/>-40.0 degrees Celsius = -40.0 degrees Fahrenheit <br/>-10.0 degrees Celsius = 14.0 degrees Fahrenheit <br/>0.0 degrees Celsius = 32.0 degrees Fahrenheit <br/>8.0 degrees Celsius = 46.0 degrees Fahrenheit <br/>15.0 degrees Celsius = 59.0 degrees Fahrenheit <br/>22.0 degrees Celsius = 72.0 degrees Fahrenhet <br/>38.0 degrees Celsius = 100.0 degrees Fahrenhet</span></pre><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div role="button" tabindex="0" class="lv lw di lx bf ly"><div class="gh gi oh"><img src="../Images/5a61237a40557c600a1dc7243351ce4f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*dsLvntcyMnwJgmE9VhPZfQ.png"/></div></div></figure><h2 id="abe0" class="mj mk iq bd mw mx my dn mz na nb dp nc lf nd ne nf lj ng nh ni ln nj nk nl iw bi translated">创建模型:</h2><p id="6835" class="pw-post-body-paragraph kw kx iq ky b kz ny ka lb lc nz kd le lf oa lh li lj ob ll lm ln oc lp lq lr ij bi translated">我们将使用最简单的模型，一个密集的网络。为了简单起见，这个网络只有一层和一个神经元</p><h2 id="a6d3" class="mj mk iq bd mw mx my dn mz na nb dp nc lf nd ne nf lj ng nh ni ln nj nk nl iw bi translated">构建一个层:</h2><p id="48a0" class="pw-post-body-paragraph kw kx iq ky b kz ny ka lb lc nz kd le lf oa lh li lj ob ll lm ln oc lp lq lr ij bi translated">我们将调用图层L1，并使用语法tf.keras.layers.Dense对其进行实例化，配置如下</p><blockquote class="mp mq mr"><p id="b419" class="kw kx lt ky b kz la ka lb lc ld kd le ms lg lh li mt lk ll lm mu lo lp lq lr ij bi translated">。input_shape=[1]，它指定该层的输入是单个值，即该形状是一个具有1个成员的一维数组。</p><p id="7b94" class="kw kx lt ky b kz la ka lb lc ld kd le ms lg lh li mt lk ll lm mu lo lp lq lr ij bi translated">。units = 1，这指定了层中神经元的数量。神经元的数量决定了模型需要学习多少内部变量来解决问题</p></blockquote><pre class="kp kq kr ks gt me mf mg mh aw mi bi"><span id="6f53" class="mj mk iq mf b gy ml mm l mn mo"><strong class="mf ja">L1 =  tf.keras.layer.Dense(units=1, input_shape=[1])</strong></span></pre><h2 id="5a3a" class="mj mk iq bd mw mx my dn mz na nb dp nc lf nd ne nf lj ng nh ni ln nj nk nl iw bi translated">将层组装到模型中:</h2><p id="02bc" class="pw-post-body-paragraph kw kx iq ky b kz ny ka lb lc nz kd le lf oa lh li lj ob ll lm ln oc lp lq lr ij bi translated">一旦定义了层，我们需要将它们组装到我们的模型中。我们将使用顺序模型定义，它接受一系列层作为参数。指定从输入到输出的计算顺序。</p><p id="551b" class="pw-post-body-paragraph kw kx iq ky b kz la ka lb lc ld kd le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">这个模型只有一个单层L1</p><pre class="kp kq kr ks gt me mf mg mh aw mi bi"><span id="117b" class="mj mk iq mf b gy ml mm l mn mo"><strong class="mf ja">tf.keras.Sequential([L1])</strong></span></pre><p id="84d5" class="pw-post-body-paragraph kw kx iq ky b kz la ka lb lc ld kd le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">请注意，我们可以通过简单地执行以下操作，在一行代码中构建和组装该层</p><pre class="kp kq kr ks gt me mf mg mh aw mi bi"><span id="5a77" class="mj mk iq mf b gy ml mm l mn mo"><strong class="mf ja">model= tf.keras.Sequential(tf.keras.layer.Dense(units=1, input_shape=[1]))</strong></span></pre><h2 id="0d67" class="mj mk iq bd mw mx my dn mz na nb dp nc lf nd ne nf lj ng nh ni ln nj nk nl iw bi translated">用损失和优化函数编译模型:</h2><p id="9c6b" class="pw-post-body-paragraph kw kx iq ky b kz ny ka lb lc nz kd le lf oa lh li lj ob ll lm ln oc lp lq lr ij bi translated">在训练之前，必须编译模型。编译时，模型给出:</p><blockquote class="mp mq mr"><p id="61fd" class="kw kx lt ky b kz la ka lb lc ld kd le ms lg lh li mt lk ll lm mu lo lp lq lr ij bi translated">1.损失函数:一种衡量预测和期望结果之间差异的方法。(这种差异称为损失)</p><p id="f68e" class="kw kx lt ky b kz la ka lb lc ld kd le ms lg lh li mt lk ll lm mu lo lp lq lr ij bi translated">2.优化函数:调整内部值或参数以减少损失的一种方式。</p></blockquote><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div role="button" tabindex="0" class="lv lw di lx bf ly"><div class="gh gi oi"><img src="../Images/a9418a2ff023a09f2b5f06b474c078f4.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*G4toi8TRuTpSARdLhL1o6w.png"/></div></div><figcaption class="lz ma gj gh gi mb mc bd b be z dk translated">测量损耗以优化内部参数。</figcaption></figure><pre class="kp kq kr ks gt me mf mg mh aw mi bi"><span id="8ce4" class="mj mk iq mf b gy ml mm l mn mo"><strong class="mf ja">model.compile(loss= 'mean_squared_error', optimizer= tf.keras.Optimizers.Adam(0.1))</strong></span></pre><p id="ec39" class="pw-post-body-paragraph kw kx iq ky b kz la ka lb lc ld kd le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">事实上，计算当前损失并改善它的行为就是训练一个模型(<strong class="ky ja"> <em class="lt"> model.fit </em> </strong>)的全部内容。</p><p id="7fa2" class="pw-post-body-paragraph kw kx iq ky b kz la ka lb lc ld kd le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">在训练期间，优化器函数(在这种情况下是Adam Optimizer，代表自适应矩估计优化器)用于计算对模型内部参数的调整。有关优化器算法的更多详细信息，请参见本文<a class="ae ls" href="http://ruder.io/optimizing-gradient-descent/index.html#adam" rel="noopener ugc nofollow" target="_blank"><strong class="ky ja"><em class="lt"/></strong></a><strong class="ky ja"><em class="lt">。</em>T13】</strong></p><p id="34ba" class="pw-post-body-paragraph kw kx iq ky b kz la ka lb lc ld kd le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">TensorFlow使用数值微调来调整这些参数，所有这些复杂性对我们来说都是隐藏的，因此我们不会在这里深入讨论这些细节。</p><p id="4203" class="pw-post-body-paragraph kw kx iq ky b kz la ka lb lc ld kd le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">重要的是要知道</p><p id="f287" class="pw-post-body-paragraph kw kx iq ky b kz la ka lb lc ld kd le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">损失函数(mean_squared_error)和优化函数(Adam)是像这样的简单模型的标准函数，但许多其他函数也是可用的，没有必要了解它们在这一点上的内部工作方式。</p><p id="56fb" class="pw-post-body-paragraph kw kx iq ky b kz la ka lb lc ld kd le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">在上面的代码单元格中，有一个0.1的值传递给了Adam优化器。那就是<strong class="ky ja"> <em class="lt">的学习率。</em> </strong>学习率就是优化器函数在调整模型中的值时所采用的大小。如果学习率太小，就需要太多的迭代来优化模型，如果学习率太大，精度就会下降。找到一个好的值通常需要一些反复试验，但它通常在0.001(默认)和0.1之间。</p><h2 id="e1ab" class="mj mk iq bd mw mx my dn mz na nb dp nc lf nd ne nf lj ng nh ni ln nj nk nl iw bi translated">训练模型:</h2><p id="0b04" class="pw-post-body-paragraph kw kx iq ky b kz ny ka lb lc nz kd le lf oa lh li lj ob ll lm ln oc lp lq lr ij bi translated">我们通过调用fit()方法来训练模型。</p><p id="ae43" class="pw-post-body-paragraph kw kx iq ky b kz la ka lb lc ld kd le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">在训练期间，模型接受摄氏温度值，并使用当前内部变量(称为权重)执行一些计算，然后输出相当于华氏温度的值。</p><p id="e990" class="pw-post-body-paragraph kw kx iq ky b kz la ka lb lc ld kd le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">由于权重最初是随机设置的，因此输出值不会接近正确值。输出值和期望结果之间的差异将使用损失函数来计算，而优化器函数确定应该如何调整权重来减少损失。</p><p id="754b" class="pw-post-body-paragraph kw kx iq ky b kz la ka lb lc ld kd le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">这个计算、比较、调整的循环由fit()方法控制。</p><pre class="kp kq kr ks gt me mf mg mh aw mi bi"><span id="8c30" class="mj mk iq mf b gy ml mm l mn mo"><strong class="mf ja">history = model.fit(celsius_q, fahrenheit_a, epochs=500, verbose=False)</strong></span><span id="07a4" class="mj mk iq mf b gy og mm l mn mo"><strong class="mf ja">print("Finished training the model")</strong></span></pre><p id="ca8a" class="pw-post-body-paragraph kw kx iq ky b kz la ka lb lc ld kd le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">fit()方法的第一个参数是输入(摄氏温度值)，第二个参数是期望的输出(华氏温度值)，epochs指定训练应该运行多少次，verbose控制训练发生时应该打印出多少数据。在这种情况下，verbose=False意味着不打印任何训练数据。</p><p id="909a" class="pw-post-body-paragraph kw kx iq ky b kz la ka lb lc ld kd le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">我们将所有这些输出参数保存在一个名为history的变量中，以便在需要时可以调用或访问这些内部值，特别是如果我们想要实时绘制训练损失。然后我们训练模型。</p><h1 id="b61b" class="nn mk iq bd mw no np nq mz nr ns nt nc kf nu kg nf ki nv kj ni kl nw km nl nx bi translated">显示培训统计数据:</h1><p id="a68c" class="pw-post-body-paragraph kw kx iq ky b kz ny ka lb lc nz kd le lf oa lh li lj ob ll lm ln oc lp lq lr ij bi translated">fit方法返回一个历史对象。我们可以使用这个对象来绘制我们的模型的损失如何在每个训练时期之后下降。</p><p id="15a6" class="pw-post-body-paragraph kw kx iq ky b kz la ka lb lc ld kd le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">让我们使用Matplotlib库来可视化训练损失。</p><pre class="kp kq kr ks gt me mf mg mh aw mi bi"><span id="d10d" class="mj mk iq mf b gy ml mm l mn mo"><strong class="mf ja">import matplotlib.pyplot as plt<br/>plt.xlabel('Epoch Number', color='yellow')<br/>plt.ylabel("Loss Magnitude", color='yellow')<br/>plt.plot(history.history['loss'])<br/>plt.xticks(color='white')<br/>plt.yticks(color='white')<br/>plt.show()</strong></span></pre><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div role="button" tabindex="0" class="lv lw di lx bf ly"><div class="gh gi oj"><img src="../Images/6c3c8b93741da4f2f0fdfa712814ed9a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*ReXa3tWl6i4bvDiywr29wA.png"/></div></div><figcaption class="lz ma gj gh gi mb mc bd b be z dk translated">正如你所看到的，我们的模型开始时改进很快，然后慢慢地，稳定地改进，直到接近完美</figcaption></figure><h1 id="33c6" class="nn mk iq bd mw no np nq mz nr ns nt nc kf nu kg nf ki nv kj ni kl nw km nl nx bi translated">使用模型预测值:</h1><p id="de22" class="pw-post-body-paragraph kw kx iq ky b kz ny ka lb lc nz kd le lf oa lh li lj ob ll lm ln oc lp lq lr ij bi translated">既然模型已经被训练来学习摄氏_q和华氏_a之间的关系或模式，我们可以使用它来预测以前未知的摄氏到华氏温度。</p><p id="8dc9" class="pw-post-body-paragraph kw kx iq ky b kz la ka lb lc ld kd le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">例如，200摄氏度到华氏温度，我们已经知道是:-</p><p id="178a" class="pw-post-body-paragraph kw kx iq ky b kz la ka lb lc ld kd le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi">200 * 1.8 + 32 = 392</p><p id="f729" class="pw-post-body-paragraph kw kx iq ky b kz la ka lb lc ld kd le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">让我们用训练过的模型来运行它</p><pre class="kp kq kr ks gt me mf mg mh aw mi bi"><span id="8c84" class="mj mk iq mf b gy ml mm l mn mo"><strong class="mf ja">model.predict([200])</strong></span><span id="3b41" class="mj mk iq mf b gy og mm l mn mo">&gt;&gt;<br/>  <strong class="mf ja">[[393.65097]]</strong></span><span id="f9f3" class="mj mk iq mf b gy og mm l mn mo"># Our model outputs 393.7, which is very close to the desired.</span></pre><p id="c49a" class="pw-post-body-paragraph kw kx iq ky b kz la ka lb lc ld kd le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">让我们定义一个简单的方法来创建摄氏度，然后我们使用我们的模型来预测每个摄氏度的华氏温度值，我们将预测值与期望值进行比较，打印出这些值，最后是均方误差。</p><pre class="kp kq kr ks gt me mf mg mh aw mi bi"><span id="c7d6" class="mj mk iq mf b gy ml mm l mn mo"><strong class="mf ja">def test_model(model):<br/>    MSE = []<br/>    xx, yy = [], []<br/>    for x in range(10, 110, 10):<br/>        y_hat = model.predict([x]).astype(float)<br/>        y_hat = y_hat[0]<br/>        y = x * 1.8 + 32<br/>        error_squ = (y_hat - y)**2<br/>        MSE.append(error_squ)<br/>        print('celsius is {}, Fahrenheit is {}, Model predicted Fahrenheit is {}, Diff_Squared is {}'.format(x, y, y_hat, error_squ ))<br/>    MSE = sum(MSE) / len(MSE)<br/>    print('Total MSE is {}'.format(MSE))</strong></span><span id="b106" class="mj mk iq mf b gy og mm l mn mo"><strong class="mf ja">print(test_model(model))</strong></span><span id="253c" class="mj mk iq mf b gy og mm l mn mo">&gt;&gt; <br/>See cell output below</span></pre><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div role="button" tabindex="0" class="lv lw di lx bf ly"><div class="gh gi ok"><img src="../Images/981640424b458f3b8e8194f3e5c32c38.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*lV2wzfOfr1quHVvljY5y2Q.png"/></div></div><figcaption class="lz ma gj gh gi mb mc bd b be z dk translated">打印出每个预测、期望值和最终仅4.5的MSE</figcaption></figure><h1 id="55a6" class="nn mk iq bd mw no np nq mz nr ns nt nc kf nu kg nf ki nv kj ni kl nw km nl nx bi translated">要查看:</h1><ol class=""><li id="955b" class="ol om iq ky b kz ny lc nz lf on lj oo ln op lr oq or os ot bi translated">我们创建了一个带有密集层的简单模型</li><li id="e5d4" class="ol om iq ky b kz ou lc ov lf ow lj ox ln oy lr oq or os ot bi translated">我们用3500个例子(超过500个时期的7对)来训练它</li></ol><p id="1fec" class="pw-post-body-paragraph kw kx iq ky b kz la ka lb lc ld kd le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">我们的模型调整了密集层中的内部参数(权重),直到它能够使用损失和优化器函数为任何摄氏度值返回正确的华氏温度值，甚至是那些以前没有看到的值。</p><h1 id="ecc8" class="nn mk iq bd mw no np nq mz nr ns nt nc kf nu kg nf ki nv kj ni kl nw km nl nx bi translated">查看层权重:</h1><p id="6b7b" class="pw-post-body-paragraph kw kx iq ky b kz ny ka lb lc nz kd le lf oa lh li lj ob ll lm ln oc lp lq lr ij bi translated">最后，让我们打印密集层的内部参数</p><pre class="kp kq kr ks gt me mf mg mh aw mi bi"><span id="0b67" class="mj mk iq mf b gy ml mm l mn mo"><strong class="mf ja">print('These are the internal layer variables{}'.format(L1.get_weights()))</strong></span><span id="395d" class="mj mk iq mf b gy og mm l mn mo">&gt;&gt;<br/>This prints out:-<br/><strong class="mf ja">These are the internal layer variables: [array([[1.8278279]], dtype=float32), array([28.5018], dtype=float32)]</strong></span></pre><p id="302a" class="pw-post-body-paragraph kw kx iq ky b kz la ka lb lc ld kd le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">请注意，第一个变量是1.8，而第二个变量是28.5，相对接近32 <strong class="ky ja"> <em class="lt">(记住将摄氏度转换为华氏度的公式是摄氏度乘以1.8加32) </em> </strong></p><p id="95eb" class="pw-post-body-paragraph kw kx iq ky b kz la ka lb lc ld kd le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">因此，对于由单个神经元和单个输入和单个输出组成的神经网络，内部数学看起来与线公式相同，也称为<a class="ae ls" href="https://en.wikipedia.org/wiki/Linear_equation#Slope%E2%80%93intercept_form" rel="noopener ugc nofollow" target="_blank"> <strong class="ky ja"> <em class="lt">斜率截距形式</em> </strong> </a>，其形式为:</p><p id="34d4" class="pw-post-body-paragraph kw kx iq ky b kz la ka lb lc ld kd le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated"><strong class="ky ja"> <em class="lt"> y = mx + b </em> </strong></p><p id="9fe8" class="pw-post-body-paragraph kw kx iq ky b kz la ka lb lc ld kd le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">其形式与我们上面使用的转换公式相同</p><p id="426e" class="pw-post-body-paragraph kw kx iq ky b kz la ka lb lc ld kd le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated"><strong class="ky ja"> <em class="lt">华氏= 1.8 *摄氏+ 32 </em> </strong></p><p id="4dc7" class="pw-post-body-paragraph kw kx iq ky b kz la ka lb lc ld kd le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">既然形式是一样的，变量就应该收敛在标准的1.8和32上，就是这么回事。</p><h1 id="df58" class="nn mk iq bd mw no np nq mz nr ns nt nc kf nu kg nf ki nv kj ni kl nw km nl nx bi translated">一个小实验…</h1><p id="196a" class="pw-post-body-paragraph kw kx iq ky b kz ny ka lb lc nz kd le lf oa lh li lj ob ll lm ln oc lp lq lr ij bi translated">只是为了好玩，让我们把事情复杂化一点，让我们增加更密集的层和更多的神经元，这意味着要学习更多的内部变量。</p><pre class="kp kq kr ks gt me mf mg mh aw mi bi"><span id="b7e7" class="mj mk iq mf b gy ml mm l mn mo"># First Dense layer<br/><strong class="mf ja">L1 = tf.keras.layer.Dense(units=4, input_shape=[1])</strong><br/># Second Dense layer<br/><strong class="mf ja">L2 = tf.keras.layer.Dense(units=4)<br/></strong># Third Dense Layer<br/><strong class="mf ja">L3 = tf.keras.layer.Dense(units=1)<br/></strong># Let's assemble all the layers into a Sequential model<br/><strong class="mf ja">model = tf.keras.Sequential([L1, L2, L3])<br/></strong># Let's compile the model<br/><strong class="mf ja">model.compile(loss='Mean_Squared_Error',Optimizer=tf.keras.optimizers.Adam(0.1))<br/></strong># Let's train the model<br/><strong class="mf ja">model.fit(celsius_q, fahrenheit_a, epochs=500, verbose=False)<br/>print("Finished training the model")<br/></strong># Now let's print out the layer variables of each layer<br/><strong class="mf ja">print("These are the L1 variables: {}".format(L1.get_weights()))<br/>print("These are the L2 variables: {}".format(L2.get_weights()))<br/>print("These are the L3 variables: {}".format(L3.get_weights()))</strong></span><span id="0bcd" class="mj mk iq mf b gy og mm l mn mo">&gt;&gt;<br/><strong class="mf ja">Finished training the model <br/>These are the L1 variables: [array([[0.38865   , 0.16998766, 0.06720579, 0.38802674]], dtype=float32), array([ 3.093483 ,  2.9697134, -2.297267 ,  3.08295  ], dtype=float32)] <br/>These are the L2 variables: [array([[-0.61909986, -0.42321223, -0.12353817, -1.0181226 ],        [-0.8338606 , -0.3931085 , -0.35709453, -0.02496582],        [ 0.04785354,  0.83791655,  0.62090117, -0.35727897],        [-1.0036206 , -0.4417855 , -0.26475334, -0.7752834 ]],       dtype=float32), array([-2.9957104, -3.0123546, -2.1529603, -2.9795303], dtype=float32)] <br/>These are the L3 variables: [array([[-1.1074247 ],        [-1.004997  ],        [-0.512665  ],        [-0.70594513]], dtype=float32), array([2.9236865], dtype=float32)]</strong></span></pre><p id="6585" class="pw-post-body-paragraph kw kx iq ky b kz la ka lb lc ld kd le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">我们可以清楚地看到，内层变量不是斜率截距形式，而是更复杂。这种增加的复杂性通常会导致更好的预测输出，但复杂性并不总是在所有情况下都更好。</p><p id="ebf6" class="pw-post-body-paragraph kw kx iq ky b kz la ka lb lc ld kd le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">让我们用之前定义的test_model方法再运行一次模型，看看添加的层和神经元是否改进了预测，</p><pre class="kp kq kr ks gt me mf mg mh aw mi bi"><span id="5bc7" class="mj mk iq mf b gy ml mm l mn mo"><strong class="mf ja">print(test_model(model))</strong></span><span id="a391" class="mj mk iq mf b gy og mm l mn mo">&gt;&gt;<br/>This prints out:- </span><span id="03a2" class="mj mk iq mf b gy og mm l mn mo"><strong class="mf ja">celsius is 10, Fahrenheit is 50.0, Model predicted Fahrenheit is [49.93202209], Diff_Squared is [0.004621] <br/>celsius is 20, Fahrenheit is 68.0, Model predicted Fahrenheit is [67.91150665], Diff_Squared is [0.00783107] <br/>celsius is 30, Fahrenheit is 86.0, Model predicted Fahrenheit is [85.89100647], Diff_Squared is [0.01187959] <br/>celsius is 40, Fahrenheit is 104.0, Model predicted Fahrenheit is [103.87049103], Diff_Squared is [0.01677257] <br/>celsius is 50, Fahrenheit is 122.0, Model predicted Fahrenheit is [121.84999084], Diff_Squared is [0.02250275] <br/>celsius is 60, Fahrenheit is 140.0, Model predicted Fahrenheit is [139.82948303], Diff_Squared is [0.02907604] <br/>celsius is 70, Fahrenheit is 158.0, Model predicted Fahrenheit is [157.80897522], Diff_Squared is [0.03649047] <br/>celsius is 80, Fahrenheit is 176.0, Model predicted Fahrenheit isonclusion[175.78848267], Diff_Squared is [0.04473958] <br/>celsius is 90, Fahrenheit is 194.0, Model predicted Fahrenheit is [193.76795959], Diff_Squared is [0.05384275] <br/>celsius is 100, Fahrenheit is 212.0, Model predicted Fahrenheit is [211.74746704], Diff_Squared is [0.0637729] <br/>Total MSE is [0.02915287]</strong></span></pre><p id="0d96" class="pw-post-body-paragraph kw kx iq ky b kz la ka lb lc ld kd le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">我们可以看到惊人的进步。</p><p id="92ab" class="pw-post-body-paragraph kw kx iq ky b kz la ka lb lc ld kd le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">更复杂的模型是<strong class="ky ja"><em class="lt"/></strong>精度99.83%，而<strong class="ky ja"> <em class="lt"> MSE只有0.03 </em> </strong></p><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div role="button" tabindex="0" class="lv lw di lx bf ly"><div class="gh gi oz"><img src="../Images/46a08988a8e92d5b3717930f4f1f059a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*a1i82PqoBo7KBtNyGsjdZg.png"/></div></div><figcaption class="lz ma gj gh gi mb mc bd b be z dk translated">在张量流中漫步</figcaption></figure><h2 id="5d36" class="mj mk iq bd mw mx my dn mz na nb dp nc lf nd ne nf lj ng nh ni ln nj nk nl iw bi translated"><strong class="ak">结论:</strong></h2><p id="106c" class="pw-post-body-paragraph kw kx iq ky b kz ny ka lb lc nz kd le lf oa lh li lj ob ll lm ln oc lp lq lr ij bi translated">我希望我已经带您进行了一次简短但有趣的介绍，了解了TensorFlow机器学习和深度学习库的复杂性和神奇之处。这仅仅是皮毛。但这足以让你开始。</p><p id="1612" class="pw-post-body-paragraph kw kx iq ky b kz la ka lb lc ld kd le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">你可以在GitHub 上找到代码单元格<a class="ae ls" href="https://github.com/Blackman9t/ML_and_DL_with_tensor_flow/blob/master/2_Celsius_to_Fahrenheit.ipynb" rel="noopener ugc nofollow" target="_blank"/></p><p id="cbbc" class="pw-post-body-paragraph kw kx iq ky b kz la ka lb lc ld kd le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">但更重要的是，在udacity.com<a class="ae ls" href="https://www.udacity.com/course/intro-to-tensorflow-for-deep-learning--ud187" rel="noopener ugc nofollow" target="_blank">的</a>参加这个免费的课程，它非常详细地涵盖了所有这些主题</p><p id="2597" class="pw-post-body-paragraph kw kx iq ky b kz la ka lb lc ld kd le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated"><strong class="ky ja">干杯！</strong></p><h2 id="1d68" class="mj mk iq bd mw mx my dn mz na nb dp nc lf nd ne nf lj ng nh ni ln nj nk nl iw bi translated">关于我:</h2><p id="2a6d" class="pw-post-body-paragraph kw kx iq ky b kz ny ka lb lc nz kd le lf oa lh li lj ob ll lm ln oc lp lq lr ij bi translated">劳伦斯是技术层的数据专家，对公平和可解释的人工智能和数据科学充满热情。我持有IBM的 <strong class="ky ja"> <em class="lt">数据科学专业</em> </strong> <em class="lt">和</em> <strong class="ky ja"> <em class="lt">高级数据科学专业</em> </strong> <em class="lt">证书。我已经使用ML和DL库进行了几个项目，我喜欢尽可能多地编写函数代码，即使现有的库比比皆是。最后，我从未停止学习和实验，是的，我拥有几个数据科学和人工智能认证，并且我已经写了几篇强烈推荐的文章。</em></p><p id="2aed" class="pw-post-body-paragraph kw kx iq ky b kz la ka lb lc ld kd le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">请随时在以下网址找到我</p><p id="31dd" class="pw-post-body-paragraph kw kx iq ky b kz la ka lb lc ld kd le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated"><a class="ae ls" href="https://github.com/Lawrence-Krukrubo" rel="noopener ugc nofollow" target="_blank"> <strong class="ky ja"> Github </strong> </a></p><p id="f239" class="pw-post-body-paragraph kw kx iq ky b kz la ka lb lc ld kd le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated"><a class="ae ls" href="https://www.linkedin.com/in/lawrencekrukrubo/" rel="noopener ugc nofollow" target="_blank"> <strong class="ky ja">领英</strong> </a></p><p id="4257" class="pw-post-body-paragraph kw kx iq ky b kz la ka lb lc ld kd le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated"><a class="ae ls" href="https://twitter.com/LKrukrubo" rel="noopener ugc nofollow" target="_blank"> <strong class="ky ja">推特</strong> </a></p></div></div>    
</body>
</html>