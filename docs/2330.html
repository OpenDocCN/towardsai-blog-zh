<html>
<head>
<title>Finding the Needle in the Haystack: How to Train a Dense Passage Retriever</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">大海捞针:如何训练密集通道检索器</h1>
<blockquote>原文：<a href="https://pub.towardsai.net/finding-the-needle-in-the-haystack-how-to-use-the-dense-passage-retriever-adc6a5527ff4?source=collection_archive---------0-----------------------#2021-11-13">https://pub.towardsai.net/finding-the-needle-in-the-haystack-how-to-use-the-dense-passage-retriever-adc6a5527ff4?source=collection_archive---------0-----------------------#2021-11-13</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><h2 id="cf25" class="ir is it bd b dl iu iv iw ix iy iz dk ja translated" aria-label="kicker paragraph"><a class="ae ep" href="https://towardsai.net/p/category/nlp" rel="noopener ugc nofollow" target="_blank">自然语言处理</a></h2><div class=""/><div class=""><h2 id="8573" class="pw-subtitle-paragraph jz jc it bd b ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq dk translated">让我们看看如何使用简单的Transformer训练一个模型来执行Transformer模型的密集通道检索。</h2></div><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi kr"><img src="../Images/6fc8402c7651324095e8f06f7eb30f9e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*cydJhSrRucYSNAzA"/></div></div><figcaption class="ld le gj gh gi lf lg bd b be z dk translated">照片由<a class="ae lh" href="https://unsplash.com/@matt__feeney?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">马修·费尼</a>在<a class="ae lh" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上拍摄</figcaption></figure><h1 id="9e43" class="li lj it bd lk ll lm ln lo lp lq lr ls ki lt kj lu kl lv km lw ko lx kp ly lz bi translated">段落检索导论</h1><p id="adb5" class="pw-post-body-paragraph ma mb it mc b md me kd mf mg mh kg mi mj mk ml mm mn mo mp mq mr ms mt mu mv im bi translated">段落检索是一个概念上简单的任务，其中系统必须<em class="mw">检索</em>给定输入<em class="mw">查询</em>的最相关段落。开放领域问答是段落检索的常见用例。这里，系统可以访问候选<em class="mw">上下文(可能包含问题答案的段落)</em>的大型语料库，并且任务是检索与问题最相关的一个或多个段落——最相关的一个或多个段落是最有可能包含回答问题所必需的信息的段落。</p><blockquote class="mx my mz"><p id="c947" class="ma mb mw mc b md na kd mf mg nb kg mi nc nd ml mm ne nf mp mq ng nh mt mu mv im bi translated">例如，考虑一个检索系统，其中段落语料库包含大量维基百科文章。如果你问这个系统<em class="it">“魔戒是谁写的？”</em>，最相关的文章(在这种情况下无疑会包含答案)是维基百科关于“指环王”的文章。</p></blockquote><p id="2807" class="pw-post-body-paragraph ma mb it mc b md na kd mf mg nb kg mi mj nd ml mm mn nf mp mq mr nh mt mu mv im bi translated">概括地说，段落检索设置可用于任何需要将某个输入查询与段落集合中最相关或最相似的段落(该段落可以是任何类型的文本序列)进行匹配的情况。这种匹配或相似性计算是通过为输入查询生成向量表示并将其与段落语料库的向量表示进行比较来执行的。通常，语料库的向量表示是为了效率而预先计算的，因为语料库通常是段落的静态集合。</p><p id="81be" class="pw-post-body-paragraph ma mb it mc b md na kd mf mg nb kg mi mj nd ml mm mn nf mp mq mr nh mt mu mv im bi translated">用于段落检索的模型可以分为两个主要阵营，传统的<em class="mw">稀疏</em>方法(例如BM25 [1])和最近的<em class="mw">密集</em>方法，它们使用神经网络来生成密集向量表示。直到最近，传统的<em class="mw">稀疏</em>方法通常在检索准确性和训练/预测速度方面都优于<em class="mw">密集</em>方法。然而，变压器模型生成密集表示的适应性已经使得<em class="mw">密集</em>方法超过了传统技术，至少在检索准确性方面。训练和预测速度仍然坚定地支持<em class="mw">稀疏</em>方法，但准确性的提高通常足以忽略这一点！</p><h1 id="8280" class="li lj it bd lk ll lm ln lo lp lq lr ls ki lt kj lu kl lv km lw ko lx kp ly lz bi translated">密集通道检索器</h1><p id="7752" class="pw-post-body-paragraph ma mb it mc b md me kd mf mg mh kg mi mj mk ml mm mn mo mp mq mr ms mt mu mv im bi translated">成功利用变压器的电力进行<em class="mw">密集</em>段落检索的首批型号之一是被恰当命名为<strong class="mc jd">密集段落检索器(DPR)</strong>【2】。该模型的架构非常简单，使用两个编码器模型，一个用于嵌入(生成向量表示)段落，另一个用于嵌入输入查询。这种设置称为双编码器架构，使用两个独立的并行训练的BERT模型。</p><p id="a2ab" class="pw-post-body-paragraph ma mb it mc b md na kd mf mg nb kg mi mj nd ml mm mn nf mp mq mr nh mt mu mv im bi translated"><em class="mw">请注意，术语段落、上下文和文档经常互换使用。</em></p><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div class="gh gi ni"><img src="../Images/3dab8951f187343fa8c93c8d688fa4a2.png" data-original-src="https://miro.medium.com/v2/resize:fit:1042/format:webp/1*q0123GtMX06cAcAmg1f-aQ.png"/></div><figcaption class="ld le gj gh gi lf lg bd b be z dk translated">DPR双编码器架构(图表由作者创建)</figcaption></figure><p id="d908" class="pw-post-body-paragraph ma mb it mc b md na kd mf mg nb kg mi mj nd ml mm mn nf mp mq mr nh mt mu mv im bi translated">在训练过程中，每个训练实例由一个输入查询、一个相关(肯定)段落和<em class="mw"> n </em>个不相关(否定)段落组成。该模型被训练来增加相关的查询和段落对之间的点积相似度，即，减小由查询编码器生成的查询表示和由上下文编码器生成的段落表示之间的距离。</p><p id="9fa4" class="pw-post-body-paragraph ma mb it mc b md na kd mf mg nb kg mi mj nd ml mm mn nf mp mq mr nh mt mu mv im bi translated">在检索数据集中，肯定段落通常是显式可用的，但是否定段落需要被选择。DPR使用<em class="mw">批量否定</em>技术为每个问题选择否定段落。这里，对于每个查询，给定批次(在训练期间)的所有其他查询的<em class="mw">正</em>段落被用作特定查询的<em class="mw">负</em>段落。</p><p id="4107" class="pw-post-body-paragraph ma mb it mc b md na kd mf mg nb kg mi mj nd ml mm mn nf mp mq mr nh mt mu mv im bi translated">接下来，我们将看看如何用简单的变形金刚训练一个DPR模型！</p><h1 id="0396" class="li lj it bd lk ll lm ln lo lp lq lr ls ki lt kj lu kl lv km lw ko lx kp ly lz bi translated">数据集</h1><p id="73d8" class="pw-post-body-paragraph ma mb it mc b md me kd mf mg mh kg mi mj mk ml mm mn mo mp mq mr ms mt mu mv im bi translated">DPR论文在五个标准基准数据集上展示了其模型的性能。在本文中，我们将使用其中一个数据集，特别是来自Google的自然问题数据集。</p><p id="3816" class="pw-post-body-paragraph ma mb it mc b md na kd mf mg nb kg mi mj nd ml mm mn nf mp mq mr nh mt mu mv im bi translated">原始数据集在这里是可用的，但是我们将使用DPR作者发布的预处理版本。按照以下步骤下载数据集。</p><ol class=""><li id="8fd6" class="nj nk it mc b md na mg nb mj nl mn nm mr nn mv no np nq nr bi translated">从DPR回购下载/复制<a class="ae lh" href="https://github.com/facebookresearch/DPR/blob/main/dpr/data/download_data.py" rel="noopener ugc nofollow" target="_blank">数据下载脚本</a>。</li></ol><pre class="ks kt ku kv gt ns nt nu nv aw nw bi"><span id="3945" class="nx lj it nt b gy ny nz l oa ob">wget https://raw.githubusercontent.com/facebookresearch/DPR/main/dpr/data/download_data.py</span></pre><p id="c9d4" class="pw-post-body-paragraph ma mb it mc b md na kd mf mg nb kg mi mj nd ml mm mn nf mp mq mr nh mt mu mv im bi translated">2.从包含下载脚本的目录中运行以下命令。</p><pre class="ks kt ku kv gt ns nt nu nv aw nw bi"><span id="5197" class="nx lj it nt b gy ny nz l oa ob">python download_data.py --resource data.retriever.nq-train<br/>python download_data.py --resource data.retriever.nq-dev</span></pre><p id="aa80" class="pw-post-body-paragraph ma mb it mc b md na kd mf mg nb kg mi mj nd ml mm mn nf mp mq mr nh mt mu mv im bi translated">3.这应该将两个JSON文件(<code class="fe oc od oe nt b">nq-train.json</code>和<code class="fe oc od oe nt b">nq-dev.json</code>)下载到<code class="fe oc od oe nt b">downloads/data/</code>中。让我们清理一下。</p><pre class="ks kt ku kv gt ns nt nu nv aw nw bi"><span id="09d9" class="nx lj it nt b gy ny nz l oa ob">mv downloads/data .<br/>mv data/retriever/* data</span><span id="295d" class="nx lj it nt b gy of nz l oa ob">rm -r data/retriever<br/>rm -r download</span></pre><p id="ec59" class="pw-post-body-paragraph ma mb it mc b md na kd mf mg nb kg mi mj nd ml mm mn nf mp mq mr nh mt mu mv im bi translated">该目录最终应该如下所示:</p><pre class="ks kt ku kv gt ns nt nu nv aw nw bi"><span id="acb9" class="nx lj it nt b gy ny nz l oa ob"><strong class="nt jd">.</strong> <br/>├── <strong class="nt jd">data</strong> <br/>│   ├── LICENSE <br/>│   ├── nq-dev.json <br/>│   ├── nq-train.json <br/>│   └── README <br/>└── download_data.py</span></pre><h1 id="7888" class="li lj it bd lk ll lm ln lo lp lq lr ls ki lt kj lu kl lv km lw ko lx kp ly lz bi translated">设置</h1><p id="73c2" class="pw-post-body-paragraph ma mb it mc b md me kd mf mg mh kg mi mj mk ml mm mn mo mp mq mr ms mt mu mv im bi translated">现在，我们将安装简单的转换器和我们需要的其他库。</p><ol class=""><li id="9389" class="nj nk it mc b md na mg nb mj nl mn nm mr nn mv no np nq nr bi translated">从<a class="ae lh" href="https://www.anaconda.com/distribution/" rel="noopener ugc nofollow" target="_blank">这里</a>安装Anaconda或Miniconda包管理器。</li><li id="2bdc" class="nj nk it mc b md og mg oh mj oi mn oj mr ok mv no np nq nr bi translated">创建新的虚拟环境并安装软件包。<br/> <code class="fe oc od oe nt b">conda create -n simpletransformers python pandas tqdm wandb</code> <br/> <code class="fe oc od oe nt b">conda activate simpletransformers</code> <br/> <code class="fe oc od oe nt b">conda install pytorch&gt;=1.6 cudatoolkit=11.0 -c pytorch<br/></code> <em class="mw">注意:选择您系统上安装的Cuda工具包版本。</em></li><li id="39a3" class="nj nk it mc b md og mg oh mj oi mn oj mr ok mv no np nq nr bi translated">安装简单的变压器。<br/> <code class="fe oc od oe nt b">pip install simpletransformers</code></li></ol><h1 id="5538" class="li lj it bd lk ll lm ln lo lp lq lr ls ki lt kj lu kl lv km lw ko lx kp ly lz bi translated">数据准备</h1><p id="de27" class="pw-post-body-paragraph ma mb it mc b md me kd mf mg mh kg mi mj mk ml mm mn mo mp mq mr ms mt mu mv im bi translated">Simple Transformers本身支持DPR回购协议中使用的数据格式，因此我们不需要对下载的文件进行预处理。</p><p id="f865" class="pw-post-body-paragraph ma mb it mc b md na kd mf mg nb kg mi mj nd ml mm mn nf mp mq mr nh mt mu mv im bi translated">但是，简单转换器还支持其他输入格式，这对于您自己的数据集来说可能更方便。查看<a class="ae lh" href="https://simpletransformers.ai/docs/retrieval-data-formats/" rel="noopener ugc nofollow" target="_blank">文件</a>了解更多详情。</p><h1 id="ce9c" class="li lj it bd lk ll lm ln lo lp lq lr ls ki lt kj lu kl lv km lw ko lx kp ly lz bi translated">训练模型</h1><p id="3e79" class="pw-post-body-paragraph ma mb it mc b md me kd mf mg mh kg mi mj mk ml mm mn mo mp mq mr ms mt mu mv im bi translated">随着数据集的下载和环境的设置，我们现在准备开始训练一个DPR模型！根据本文，我们将设置查询编码器和上下文编码器作为<code class="fe oc od oe nt b">bert-base-uncased</code>模型。</p><figure class="ks kt ku kv gt kw"><div class="bz fp l di"><div class="ol om l"/></div></figure><p id="ae01" class="pw-post-body-paragraph ma mb it mc b md na kd mf mg nb kg mi mj nd ml mm mn nf mp mq mr nh mt mu mv im bi translated"><em class="mw"/><code class="fe oc od oe nt b"><em class="mw">train_batch_size</em></code><em class="mw">设置为</em> <code class="fe oc od oe nt b"><em class="mw">40</em></code> <em class="mw">，这需要24 GB内存的GPU。如果你的GPU内存少，可能需要减少</em> <code class="fe oc od oe nt b"><em class="mw">train_batch_size</em></code> <em class="mw">。您还可以减少</em> <code class="fe oc od oe nt b"><em class="mw">num_train_epochs</em></code> <em class="mw">来更快地完成训练，但这可能会降低模型的最终性能。</em></p><p id="0f63" class="pw-post-body-paragraph ma mb it mc b md na kd mf mg nb kg mi mj nd ml mm mn nf mp mq mr nh mt mu mv im bi translated"><em class="mw">这里</em>  <em class="mw">可以看到用权重&amp;偏差</em> <a class="ae lh" href="https://wandb.ai/thilina/Training%20DPR%20on%20NQ?workspace=user-thilina" rel="noopener ugc nofollow" target="_blank"> <em class="mw">可视化的训练进度。</em></a></p><h1 id="fa11" class="li lj it bd lk ll lm ln lo lp lq lr ls ki lt kj lu kl lv km lw ko lx kp ly lz bi translated">评估模型</h1><p id="0453" class="pw-post-body-paragraph ma mb it mc b md me kd mf mg mh kg mi mj mk ml mm mn mo mp mq mr ms mt mu mv im bi translated">接下来，我们加载训练好的模型并评估它的性能(我们也可以在<code class="fe oc od oe nt b">train_model()</code>之后调用<code class="fe oc od oe nt b">eval_model()</code>)。</p><figure class="ks kt ku kv gt kw"><div class="bz fp l di"><div class="ol om l"/></div></figure><p id="615f" class="pw-post-body-paragraph ma mb it mc b md na kd mf mg nb kg mi mj nd ml mm mn nf mp mq mr nh mt mu mv im bi translated"><em class="mw">加载用简单转换器训练的DPR模型时，不需要分别指定查询编码器和上下文编码器。我们只需要提供模型文件夹的路径(本例中为</em> <code class="fe oc od oe nt b"><em class="mw">outputs</em></code> <em class="mw">)作为</em> <code class="fe oc od oe nt b"><em class="mw">model_name</em></code> <em class="mw">。</em></p><p id="8dcc" class="pw-post-body-paragraph ma mb it mc b md na kd mf mg nb kg mi mj nd ml mm mn nf mp mq mr nh mt mu mv im bi translated">让我们看看结果吧！</p><figure class="ks kt ku kv gt kw"><div class="bz fp l di"><div class="ol om l"/></div></figure><h2 id="522e" class="nx lj it bd lk on oo dn lo op oq dp ls mj or os lu mn ot ou lw mr ov ow ly iz bi translated">快速了解一下指标</h2><p id="4ecb" class="pw-post-body-paragraph ma mb it mc b md me kd mf mg mh kg mi mj mk ml mm mn mo mp mq mr ms mt mu mv im bi translated"><a class="ae lh" href="https://en.wikipedia.org/wiki/Mean_reciprocal_rank" rel="noopener ugc nofollow" target="_blank">平均倒数排名(MRR) </a>是用于评估诸如文档检索之类的排名任务的有用度量。MRR分数取决于相关段落是否被检索到(如果没有，分数为0)以及相关段落在检索列表中的排名(在列表上的位置)。</p><p id="eed9" class="pw-post-body-paragraph ma mb it mc b md na kd mf mg nb kg mi mj nd ml mm mn nf mp mq mr nh mt mu mv im bi translated">Top <em class="mw"> k </em>精度只是检查top <em class="mw"> k </em>检索到的段落是否包含相关段落。如果是，分数为1，否则为0。</p><p id="9219" class="pw-post-body-paragraph ma mb it mc b md na kd mf mg nb kg mi mj nd ml mm mn nf mp mq mr nh mt mu mv im bi translated">对评估数据中的所有查询的分数进行平均。</p><h1 id="2fc1" class="li lj it bd lk ll lm ln lo lp lq lr ls ki lt kj lu kl lv km lw ko lx kp ly lz bi translated">包裹</h1><p id="0c3a" class="pw-post-body-paragraph ma mb it mc b md me kd mf mg mh kg mi mj mk ml mm mn mo mp mq mr ms mt mu mv im bi translated">段落检索是开放领域问答等任务的重要组成部分。本文演示了如何使用简单的转换器训练和使用密集通道检索模型。</p><p id="4f56" class="pw-post-body-paragraph ma mb it mc b md na kd mf mg nb kg mi mj nd ml mm mn nf mp mq mr nh mt mu mv im bi translated"><em class="mw">更多技术细节，可以参考简单的变形金刚文档</em> <a class="ae lh" href="https://simpletransformers.ai/docs/retrieval-specifics/" rel="noopener ugc nofollow" target="_blank"> <em class="mw">这里</em> </a> <em class="mw">。</em></p><h1 id="54fb" class="li lj it bd lk ll lm ln lo lp lq lr ls ki lt kj lu kl lv km lw ko lx kp ly lz bi translated">参考</h1><ol class=""><li id="5997" class="nj nk it mc b md me mg mh mj ox mn oy mr oz mv no np nq nr bi translated">s .罗伯逊和h .萨拉戈萨，2009年。<em class="mw">概率相关性框架:BM25及以后</em>。现在出版公司。</li><li id="ed98" class="nj nk it mc b md og mg oh mj oi mn oj mr ok mv no np nq nr bi translated">Karpukhin，v .，ouz，b .，Min，s .，Lewis，p .，Wu，l .，Edunov，s .，Chen，d .和Yih，W.T .，2020年。面向开放领域问答的密集段落检索。arXiv预印本arXiv:2004.04906 </li></ol></div></div>    
</body>
</html>