<html>
<head>
<title>How To Set Up and Run Cuda Operations In PyTorch</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">如何在PyTorch中设置和运行Cuda操作</h1>
<blockquote>原文：<a href="https://pub.towardsai.net/how-to-set-up-and-run-cuda-operations-in-pytorch-c5363f73a18e?source=collection_archive---------4-----------------------#2022-10-01">https://pub.towardsai.net/how-to-set-up-and-run-cuda-operations-in-pytorch-c5363f73a18e?source=collection_archive---------4-----------------------#2022-10-01</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><h1 id="df04" class="jn jo iq bd jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk bi translated">介绍</h1><p id="92cf" class="pw-post-body-paragraph kl km iq kn b ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li ij bi translated">近年来深度学习的出现创造了对计算资源和加速工作负载的需求。深度学习中涉及的各种操作，如矩阵乘法、图像平铺和处理语音样本块，可以并行化，以获得更好的性能，并加速机器学习模型的开发。因此，许多深度学习库，如TensorFlow和Pytorch，为用户提供了一组函数或API来利用他们的GPU。CUDA就是这样一种编程模型和计算平台，它使我们能够通过在GPU之间并行化任务来更快地执行复杂的操作。</p><p id="f26e" class="pw-post-body-paragraph kl km iq kn b ko lj kq kr ks lk ku kv kw ll ky kz la lm lc ld le ln lg lh li ij bi translated">本文将讨论什么是CUDA，以及如何设置CUDA环境并运行Pytorch中可用的各种CUDA操作。</p><figure class="lp lq lr ls gt lt gh gi paragraph-image"><div role="button" tabindex="0" class="lu lv di lw bf lx"><div class="gh gi lo"><img src="../Images/91119a303d52d14180df601536033db6.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*aJ-29aPrNfdrUcdH"/></div></div><figcaption class="ma mb gj gh gi mc md bd b be z dk translated">卢卡斯·凯普纳在<a class="ae me" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上的照片</figcaption></figure><h1 id="ada5" class="jn jo iq bd jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk bi translated">什么是CUDA</h1><p id="5518" class="pw-post-body-paragraph kl km iq kn b ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li ij bi translated"><strong class="kn ir">CUDA</strong>(<strong class="kn ir">C</strong>computer<strong class="kn ir">U</strong>ni fied<strong class="kn ir">D</strong>evice<strong class="kn ir">A</strong>architecture)是Nvidia开发的编程模型和并行计算平台。使用CUDA，可以最大限度地利用Nvidia提供的GPU，从而提高计算能力，并通过并行化任务更快地执行操作。PyTorch提供了一个torch.cuda库来设置和运行cuda操作。</p><p id="d9ec" class="pw-post-body-paragraph kl km iq kn b ko lj kq kr ks lk ku kv kw ll ky kz la lm lc ld le ln lg lh li ij bi translated">使用Pytorch CUDA，我们可以创建张量并将它们分配给设备。一旦分配，我们就可以对其执行操作，并且结果也被分配给设备。</p><h1 id="cdf1" class="jn jo iq bd jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk bi translated">装置</h1><p id="803b" class="pw-post-body-paragraph kl km iq kn b ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li ij bi translated">Pytorch在其官方网站上提供了一个用户友好的界面，我们可以在那里选择我们的操作系统、期望的编程语言和其他要求，如下图所示。</p><p id="6ac9" class="pw-post-body-paragraph kl km iq kn b ko lj kq kr ks lk ku kv kw ll ky kz la lm lc ld le ln lg lh li ij bi translated">参考Pytorch官方链接— <a class="ae me" href="https://pytorch.org/get-started/locally/" rel="noopener ugc nofollow" target="_blank">本地启动| PyTorch </a>并根据我们的系统规格选择要求。Pytorch为Windows和Linux操作系统提供了CUDA库。对于windows，请确保使用CUDA 11.6，因为windows不再支持CUDA 10.2和ROCm。对于Python编程语言，我们可以在conda、pip、源码包中选择一个，而LibTorch用于C++和Java语言。</p><h1 id="9ad9" class="jn jo iq bd jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk bi translated">在PyTorch中运行CUDA操作</h1><p id="1504" class="pw-post-body-paragraph kl km iq kn b ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li ij bi translated">一旦安装成功，我们可以使用<strong class="kn ir"> torch.cuda </strong>接口在Pytorch中运行cuda操作。</p><p id="7520" class="pw-post-body-paragraph kl km iq kn b ko lj kq kr ks lk ku kv kw ll ky kz la lm lc ld le ln lg lh li ij bi translated">要确保安装是否成功，请使用torch.version.cuda命令，如下所示:</p><pre class="lp lq lr ls gt mf mg mh mi aw mj bi"><span id="d4c0" class="mk jo iq mg b gy ml mm l mn mo"># Importing Pytorch</span><span id="a2bb" class="mk jo iq mg b gy mp mm l mn mo">import torch</span><span id="b485" class="mk jo iq mg b gy mp mm l mn mo"># To print Cuda version</span><span id="adc7" class="mk jo iq mg b gy mp mm l mn mo">print(“Pytorch CUDA Version is “, torch.version.cuda)</span></pre><p id="c204" class="pw-post-body-paragraph kl km iq kn b ko lj kq kr ks lk ku kv kw ll ky kz la lm lc ld le ln lg lh li ij bi translated">如果安装成功，上述代码将显示以下输出</p><pre class="lp lq lr ls gt mf mg mh mi aw mj bi"><span id="f36f" class="mk jo iq mg b gy ml mm l mn mo"># Output</span><span id="d30a" class="mk jo iq mg b gy mp mm l mn mo">Pytorch CUDA Version is 11.6</span></pre><p id="b5eb" class="pw-post-body-paragraph kl km iq kn b ko lj kq kr ks lk ku kv kw ll ky kz la lm lc ld le ln lg lh li ij bi translated">在使用CUDA之前，我们必须确定我们的系统是否支持CUDA。</p><p id="cc22" class="pw-post-body-paragraph kl km iq kn b ko lj kq kr ks lk ku kv kw ll ky kz la lm lc ld le ln lg lh li ij bi translated">使用torch.cuda.is_available()命令，如下所示</p><pre class="lp lq lr ls gt mf mg mh mi aw mj bi"><span id="b6b9" class="mk jo iq mg b gy ml mm l mn mo"># Importing Pytorch</span><span id="f257" class="mk jo iq mg b gy mp mm l mn mo">import torch</span><span id="75ad" class="mk jo iq mg b gy mp mm l mn mo"># To check whether CUDA is supported</span><span id="cc5d" class="mk jo iq mg b gy mp mm l mn mo">print(“Whether CUDA is supported by our system:”, torch.cuda.is_available())</span></pre><p id="0d23" class="pw-post-body-paragraph kl km iq kn b ko lj kq kr ks lk ku kv kw ll ky kz la lm lc ld le ln lg lh li ij bi translated">上述命令将返回一个布尔值，如下所示</p><pre class="lp lq lr ls gt mf mg mh mi aw mj bi"><span id="7c9e" class="mk jo iq mg b gy ml mm l mn mo"># Output</span><span id="b273" class="mk jo iq mg b gy mp mm l mn mo">Whether CUDA is supported by our system: True</span></pre><p id="43ba" class="pw-post-body-paragraph kl km iq kn b ko lj kq kr ks lk ku kv kw ll ky kz la lm lc ld le ln lg lh li ij bi translated">Pytorch CUDA还提供了以下函数，用于在给定设备id时了解设备ID和设备名称，如下所示</p><pre class="lp lq lr ls gt mf mg mh mi aw mj bi"><span id="1d21" class="mk jo iq mg b gy ml mm l mn mo"># Importing Pytorch</span><span id="4e0a" class="mk jo iq mg b gy mp mm l mn mo">import torch</span><span id="f243" class="mk jo iq mg b gy mp mm l mn mo"># To know the CUDA device ID and name of the device</span><span id="1c06" class="mk jo iq mg b gy mp mm l mn mo">Cuda_id = torch.cuda.current_device()</span><span id="aebd" class="mk jo iq mg b gy mp mm l mn mo">print(“CUDA Device ID: ”, torch.cuda.current_device())</span><span id="70f8" class="mk jo iq mg b gy mp mm l mn mo">print(“Name of the current CUDA Device: ”, torch.cuda.get_device_name(cuda_id))</span></pre><p id="1b5f" class="pw-post-body-paragraph kl km iq kn b ko lj kq kr ks lk ku kv kw ll ky kz la lm lc ld le ln lg lh li ij bi translated">上述代码将显示以下输出–</p><pre class="lp lq lr ls gt mf mg mh mi aw mj bi"><span id="1965" class="mk jo iq mg b gy ml mm l mn mo"># Output</span><span id="763f" class="mk jo iq mg b gy mp mm l mn mo">CUDA Device ID: 0</span><span id="5f40" class="mk jo iq mg b gy mp mm l mn mo">Name of the current CUDA Device: NVIDIA GeForce FTX 1650</span></pre><p id="a8aa" class="pw-post-body-paragraph kl km iq kn b ko lj kq kr ks lk ku kv kw ll ky kz la lm lc ld le ln lg lh li ij bi translated">我们还可以通过指定ID来更改默认的CUDA设备，如下所示</p><pre class="lp lq lr ls gt mf mg mh mi aw mj bi"><span id="e90d" class="mk jo iq mg b gy ml mm l mn mo"># Importing Pytorch</span><span id="d2b2" class="mk jo iq mg b gy mp mm l mn mo">import torch</span><span id="d933" class="mk jo iq mg b gy mp mm l mn mo"># To change the Default CUDA device</span><span id="d688" class="mk jo iq mg b gy mp mm l mn mo">torch.cuda.set_device(1)</span></pre><p id="a79c" class="pw-post-body-paragraph kl km iq kn b ko lj kq kr ks lk ku kv kw ll ky kz la lm lc ld le ln lg lh li ij bi translated">注意:使用CUDA时，一定要开发与设备无关的代码，因为有些系统可能没有GPU，必须在CPU上运行，反之亦然。这可以通过在我们的代码中添加下面一行来实现-</p><pre class="lp lq lr ls gt mf mg mh mi aw mj bi"><span id="0ed7" class="mk jo iq mg b gy ml mm l mn mo">device = ‘cuda’ if torch.cuda.is_available() else ‘cpu’</span></pre><h1 id="56d4" class="jn jo iq bd jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk bi translated">使用CUDA操作张量</h1><p id="5c4b" class="pw-post-body-paragraph kl km iq kn b ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li ij bi translated">通常，Pytorch张量与NumPy数组相同。它是一个用于数值计算的n维数组。张量和NumPy数组的唯一区别是张量可以在CPU和GPU上运行。</p><p id="2117" class="pw-post-body-paragraph kl km iq kn b ko lj kq kr ks lk ku kv kw ll ky kz la lm lc ld le ln lg lh li ij bi translated">Pytorch CUDA提供了以下函数来处理张量——</p><p id="0730" class="pw-post-body-paragraph kl km iq kn b ko lj kq kr ks lk ku kv kw ll ky kz la lm lc ld le ln lg lh li ij bi translated">tensor.device返回张量的设备名称。默认是“CPU”。</p><p id="864c" class="pw-post-body-paragraph kl km iq kn b ko lj kq kr ks lk ku kv kw ll ky kz la lm lc ld le ln lg lh li ij bi translated">tensor.to(设备名称)—返回所述设备上张量的新实例。“CPU”表示CPU，而“cuda”表示支持CUDA的GPU。</p><p id="5a9d" class="pw-post-body-paragraph kl km iq kn b ko lj kq kr ks lk ku kv kw ll ky kz la lm lc ld le ln lg lh li ij bi translated">tensor.cpu() —将张量从当前设备传输到cpu。</p><p id="7863" class="pw-post-body-paragraph kl km iq kn b ko lj kq kr ks lk ku kv kw ll ky kz la lm lc ld le ln lg lh li ij bi translated">让我们通过创建一个张量并执行一些基本操作来理解上述函数的用法。</p><p id="57a5" class="pw-post-body-paragraph kl km iq kn b ko lj kq kr ks lk ku kv kw ll ky kz la lm lc ld le ln lg lh li ij bi translated">我们将创建一个样本张量并在CPU上执行张量操作(平方)，然后我们将张量传输到GPU并再次执行相同的操作并了解性能。</p><p id="863e" class="pw-post-body-paragraph kl km iq kn b ko lj kq kr ks lk ku kv kw ll ky kz la lm lc ld le ln lg lh li ij bi translated">进口火炬</p><pre class="lp lq lr ls gt mf mg mh mi aw mj bi"><span id="b45c" class="mk jo iq mg b gy ml mm l mn mo"># Creating a sample tensor</span><span id="2fca" class="mk jo iq mg b gy mp mm l mn mo">x = torch.randint(1, 1000, (100, 100))</span><span id="1705" class="mk jo iq mg b gy mp mm l mn mo"># Checking the device name: will return ‘CPU’ by default</span><span id="9c16" class="mk jo iq mg b gy mp mm l mn mo">print(“Device Name: ” , x.device)</span><span id="7e9d" class="mk jo iq mg b gy mp mm l mn mo"># Applying tensor operation</span><span id="0db9" class="mk jo iq mg b gy mp mm l mn mo">res_cpu = x ** 2</span><span id="6ef9" class="mk jo iq mg b gy mp mm l mn mo"># Transferring tensor to GPU</span><span id="831e" class="mk jo iq mg b gy mp mm l mn mo">x = x.to(torch.device(‘cuda’))</span><span id="1e99" class="mk jo iq mg b gy mp mm l mn mo"># Checking the device name: will return ‘cuda:0’</span><span id="9cb1" class="mk jo iq mg b gy mp mm l mn mo">print(“Device Name after transferring: ”, x.device)</span><span id="f7fd" class="mk jo iq mg b gy mp mm l mn mo"># Applying same tensor operation</span><span id="08d6" class="mk jo iq mg b gy mp mm l mn mo">res_gpu = x ** 2</span><span id="3d86" class="mk jo iq mg b gy mp mm l mn mo"># Transferring tensor from GPU to CPU</span><span id="c95e" class="mk jo iq mg b gy mp mm l mn mo">x.cpu()</span></pre><h1 id="f851" class="jn jo iq bd jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk bi translated">使用CUDA运行机器学习模型</h1><p id="2fdc" class="pw-post-body-paragraph kl km iq kn b ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li ij bi translated">CUDA提供以下功能将机器学习模型转移到以下设备</p><p id="5394" class="pw-post-body-paragraph kl km iq kn b ko lj kq kr ks lk ku kv kw ll ky kz la lm lc ld le ln lg lh li ij bi translated">model.to(设备名称)—返回指定设备名称上的机器学习模型的新实例。“CPU”表示CPU，而“cuda”表示支持CUDA的GPU。</p><p id="5b5d" class="pw-post-body-paragraph kl km iq kn b ko lj kq kr ks lk ku kv kw ll ky kz la lm lc ld le ln lg lh li ij bi translated">为了演示上述功能，我们将从torchvision.models导入预训练的“Resnet-18”模型</p><pre class="lp lq lr ls gt mf mg mh mi aw mj bi"><span id="ed22" class="mk jo iq mg b gy ml mm l mn mo"># Importing Pytorch</span><span id="9027" class="mk jo iq mg b gy mp mm l mn mo">Import torch</span><span id="6a9c" class="mk jo iq mg b gy mp mm l mn mo">import torchvision.models as models</span><span id="1629" class="mk jo iq mg b gy mp mm l mn mo"># Making the code device-agnostic</span><span id="6bb3" class="mk jo iq mg b gy mp mm l mn mo">device = ‘cuda’ if torch.cuda.is_available() else ‘cpu’</span><span id="daaf" class="mk jo iq mg b gy mp mm l mn mo"># Instantiating a pre-trained model</span><span id="d704" class="mk jo iq mg b gy mp mm l mn mo">model = models.resnet18(pretrained=True)</span><span id="5266" class="mk jo iq mg b gy mp mm l mn mo"># Transferring the model to a CUDA-enabled GPU</span><span id="b0b2" class="mk jo iq mg b gy mp mm l mn mo">model = model.to(device)</span></pre><p id="3493" class="pw-post-body-paragraph kl km iq kn b ko lj kq kr ks lk ku kv kw ll ky kz la lm lc ld le ln lg lh li ij bi translated">一旦模型被转移，我们可以在支持CUDA的GPU上继续机器学习工作流的剩余部分。</p><h1 id="8d1a" class="jn jo iq bd jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk bi translated">结论</h1><p id="ae19" class="pw-post-body-paragraph kl km iq kn b ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li ij bi translated">读完这篇文章，你可以理解如何在我们的系统中安装PyTorch CUDA库，实现PyTorch CUDA的基本命令，用CUDA处理张量和机器学习模型。</p></div></div>    
</body>
</html>