<html>
<head>
<title>Generative AI and Future</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">生成人工智能与未来</h1>
<blockquote>原文：<a href="https://pub.towardsai.net/generative-ai-and-future-c3b1695876f2?source=collection_archive---------0-----------------------#2022-07-17">https://pub.towardsai.net/generative-ai-and-future-c3b1695876f2?source=collection_archive---------0-----------------------#2022-07-17</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><div class=""><h2 id="cb45" class="pw-subtitle-paragraph jn ip iq bd b jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke dk translated">甘，三号，达尔二号，接下来呢</h2></div><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi kf"><img src="../Images/4e0387047517c48b9eed14592a993b37.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*YkP53X55EM4DFndLcCj8QA.jpeg"/></div></div><figcaption class="kr ks gj gh gi kt ku bd b be z dk translated"><a class="ae kv" href="https://unsplash.com/@joshgordon?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText" rel="noopener ugc nofollow" target="_blank">乔什·戈登</a>在<a class="ae kv" href="https://unsplash.com/s/photos/beautiful?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上拍照</figcaption></figure><p id="acc9" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">过去的十年是AI的黄金十年，但有意义的AI才刚刚开始:<a class="ae kv" href="https://en.wikipedia.org/wiki/Computer_vision" rel="noopener ugc nofollow" target="_blank"> CV </a>是目前业界领先的领域，<a class="ae kv" href="https://en.wikipedia.org/wiki/Natural_language_processing" rel="noopener ugc nofollow" target="_blank"> NLP </a>依然是AI皇冠上的明珠，<a class="ae kv" href="https://en.wikipedia.org/wiki/Reinforcement_learning" rel="noopener ugc nofollow" target="_blank"> RL </a>期待<a class="ae kv" href="https://en.wikipedia.org/wiki/Self-driving_car" rel="noopener ugc nofollow" target="_blank"> L4/L5 </a>在路上的验证，但<a class="ae kv" href="https://en.wikipedia.org/wiki/Artificial_general_intelligence" rel="noopener ugc nofollow" target="_blank"> AGI </a>(人工通用智能)才是未来。</p><p id="0596" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">生殖人工智能是一种新生但有创造性的方法。它是过去十年深度学习演进中最成功的ML框架之一。它是一种无监督或半监督的机器学习，用于创建新内容，包括但不限于数字图像、视频、音频、文本或代码。到目前为止，生成性人工智能有两个突出的框架:生成性对抗网络(<strong class="ky ir">甘</strong>)和生成性预训练转换器(<strong class="ky ir"> GPT </strong>)。</p><h2 id="4d86" class="ls lt iq bd lu lv lw dn lx ly lz dp ma lf mb mc md lj me mf mg ln mh mi mj mk bi translated">生成对抗网络(<strong class="ak">干</strong>)</h2><p id="7bb6" class="pw-post-body-paragraph kw kx iq ky b kz ml jr lb lc mm ju le lf mn lh li lj mo ll lm ln mp lp lq lr ij bi mq translated">安使用两个神经网络相互竞争以获得更准确的预测，使一个与另一个竞争(因此是“对抗性的”)以产生新的合成数据实例，这些实例可以被视为真实数据。GANs使用合作零和博弈框架来学习。它们广泛用于图像、视频和语音生成。</p><p id="f396" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">GAN训练主要有三个步骤:<br/> 1。从训练集中选择几幅真实图像。<br/> 2。通过对随机噪声向量进行采样并使用发生器从它们创建图像来生成几个假图像。<br/> 3。使用假图像和真实图像训练鉴别器一个或多个时期。</p><h2 id="670d" class="ls lt iq bd lu lv lw dn lx ly lz dp ma lf mb mc md lj me mf mg ln mh mi mj mk bi translated">创成式预训练变压器(<strong class="ak"> GPT </strong>)</h2><p id="5cfa" class="pw-post-body-paragraph kw kx iq ky b kz ml jr lb lc mm ju le lf mn lh li lj mo ll lm ln mp lp lq lr ij bi mq translated">PT是一种基于transformer架构的自回归语言模型，以生成式和无监督的方式进行预训练，在零/一/少量多任务设置中表现良好。</p><p id="b276" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">转换器是一种具有自关注机制的编码器-解码器架构。由于它可以访问每个输入单词的状态向量，与<a class="ae kv" href="https://en.wikipedia.org/wiki/Long_short-term_memory" rel="noopener ugc nofollow" target="_blank"> LSTM </a>不同，它只使用来自较低层的其他表征的信息，并且可以并行计算所有表征，因此它表现出显著提高的准确性和训练性能。从<a class="ae kv" href="https://en.wikipedia.org/wiki/BERT_(language_model)" rel="noopener ugc nofollow" target="_blank">伯特</a>(变形金刚的双向编码器表示)到罗伯塔、GPT-2、T5、<a class="ae kv" href="https://www.microsoft.com/en-us/research/blog/turing-nlg-a-17-billion-parameter-language-model-by-microsoft/" rel="noopener ugc nofollow" target="_blank">图林恩格</a>到<a class="ae kv" href="https://en.wikipedia.org/wiki/GPT-3" rel="noopener ugc nofollow" target="_blank"> GPT-3 </a>。BERT开始时有大约1.1亿个参数，但最新的GPT-3有1750亿个参数和96个关注层，批量大小为3.2米，单词量为4990亿个。培训费用约为460万美元。然而，有许多关于GPT-3用例的激动人心的故事。</p><p id="cee8" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">变压器应用包括但不限于:<br/> 1。文本生成<br/> 2。文本摘要<br/> 3。文本分类(即情感分析)<br/> 4。语言翻译<br/> 5。问题解答<br/> 6。搜索<br/> 7。命名实体识别</p><h2 id="503e" class="ls lt iq bd lu lv lw dn lx ly lz dp ma lf mb mc md lj me mf mg ln mh mi mj mk bi translated">达尔第二季</h2><p id="f3c6" class="pw-post-body-paragraph kw kx iq ky b kz ml jr lb lc mm ju le lf mn lh li lj mo ll lm ln mp lp lq lr ij bi translated">DALL E 2是一个出色的文本到图像生成人工智能系统。它主要采用两种技术:CLIP(对比语言图像预训练)和扩散模型。剪辑对于将文本描述与图像元素联系起来至关重要。扩散模型是基于变压器的生成模型。它使用一种经过修改的GPT-3来生成图像。它可以结合概念、属性和样式，以比DALL E更高的分辨率生成更真实的图像。</p><p id="7adf" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">DALL E的模型是GPT-3的多模态实现，有<a class="ae kv" href="https://en.wikipedia.org/wiki/DALL-E" rel="noopener ugc nofollow" target="_blank">120亿个参数</a>，在来自互联网的文本-图像对上进行训练。DALL-E 2使用了35亿个参数，比它的前身少。它被有效地优化。我们可以看到用更小的参数获得更好结果的机会。</p><h2 id="0eb4" class="ls lt iq bd lu lv lw dn lx ly lz dp ma lf mb mc md lj me mf mg ln mh mi mj mk bi translated">变压器统一</h2><p id="e867" class="pw-post-body-paragraph kw kx iq ky b kz ml jr lb lc mm ju le lf mn lh li lj mo ll lm ln mp lp lq lr ij bi translated">深度学习的应用有很多，但语言和视觉是两个主要分支。它们是认知学习的基本领域，但是被两种不同的数字学习模型分开:RNN和CNN。由于它们复杂多变的体系结构，ML科学家不得不独立研究和开发这两个相关的主题，然后很难共享和共同发展。</p><p id="80ac" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">变形金刚改变游戏。transformer不仅在语言建模方面取得了成功，而且在计算机视觉(CV)方面也展现出了前景。视觉变形金刚(ViT)在<a class="ae kv" href="https://pytorch.org" rel="noopener ugc nofollow" target="_blank">py torch</a>&amp;<a class="ae kv" href="https://www.tensorflow.org" rel="noopener ugc nofollow" target="_blank">tensor flow</a>有售。此外，基于变压器的GAN和GAN类变压器已成功用于生成式视觉人工智能。</p><h2 id="5847" class="ls lt iq bd lu lv lw dn lx ly lz dp ma lf mb mc md lj me mf mg ln mh mi mj mk bi translated">大型模型和下一步</h2><p id="6552" class="pw-post-body-paragraph kw kx iq ky b kz ml jr lb lc mm ju le lf mn lh li lj mo ll lm ln mp lp lq lr ij bi translated">我们对GPT-3和transformer的成功感到兴奋，但它们是非常大的模型，需要大数据和超级计算能力。<a class="ae kv" href="https://people.eecs.berkeley.edu/~istoica/" rel="noopener ugc nofollow" target="_blank">扬·斯托伊察</a>教授通过扩展OpenAI的研究说明了ML计算需求的增长，如下所示:</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi mz"><img src="../Images/8c3dea82291b0ba589683749bd8a3b8e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*TTHrt5vRN2mG09IE7QWN0w.png"/></div></div><figcaption class="kr ks gj gh gi kt ku bd b be z dk translated">图片由<a class="ae kv" href="https://youtu.be/tgB671SFS4w" rel="noopener ugc nofollow" target="_blank">离子斯托伊察</a>在anyscale的射线的谈话</figcaption></figure><p id="8e32" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">ML计算需求的增长几乎是著名的摩尔定律的17.5倍。需求增加发生在处理和内存两方面。那么，在我们知道摩尔定律目前面临的挑战的情况下，我们如何应对这种爆炸性的需求呢？是否应该继续追求大模型？</p><p id="972d" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">从ML准确性和性能的角度来看，大模型本身不是问题，但是我们必须以一些实用的方式进行优化和创新:</p><ol class=""><li id="a6b2" class="na nb iq ky b kz la lc ld lf nc lj nd ln ne lr nf ng nh ni bi translated"><strong class="ky ir">以数据为中心或大数据</strong>:除了大数据，以数据为中心的ML方法论还可以推动高质量的好数据。</li><li id="8d69" class="na nb iq ky b kz nj lc nk lf nl lj nm ln nn lr nf ng nh ni bi translated"><strong class="ky ir">硬件基础设施</strong> : GPU、TPU、FPGA等仍然是计算能力的核心发展，但他们的分布式云解决方案可以扩展计算和内存能力。</li><li id="9a43" class="na nb iq ky b kz nj lc nk lf nl lj nm ln nn lr nf ng nh ni bi translated"><strong class="ky ir">模型架构和算法</strong> : GPT期待GPT-4和GPT-5，但优化模型架构和继续发明更好的模型至关重要。</li><li id="67da" class="na nb iq ky b kz nj lc nk lf nl lj nm ln nn lr nf ng nh ni bi translated"><strong class="ky ir">框架设计</strong>是优化ML培训和服务实施的关键。例如，<a class="ae kv" href="https://www.ray.io" rel="noopener ugc nofollow" target="_blank"> Ray </a>是一个开源框架，用于简单地生产和扩展Python ML工作负载。</li></ol><h2 id="4317" class="ls lt iq bd lu lv lw dn lx ly lz dp ma lf mb mc md lj me mf mg ln mh mi mj mk bi translated">简单地</h2><p id="744f" class="pw-post-body-paragraph kw kx iq ky b kz ml jr lb lc mm ju le lf mn lh li lj mo ll lm ln mp lp lq lr ij bi translated">生成式人工智能是一种新兴的创新技术，用于数字内容生成。甘和都是视觉和语言的两个成熟的ML框架。变形金刚正在改变游戏，以统一两个DL主题(CNN和RNN)，这也可以适用于生殖人工智能。自回归转换器可以为视觉和语言生成解决方案提供统一的架构。</p><p id="e2c9" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">对于数字图像、视频、音频、文本或代码，有许多有意义的生成应用。不久之后，生成式人工智能可以扩展到元宇宙和web3，它们需要越来越多的自动生成数字内容。</p></div><div class="ab cl no np hu nq" role="separator"><span class="nr bw bk ns nt nu"/><span class="nr bw bk ns nt nu"/><span class="nr bw bk ns nt"/></div><div class="ij ik il im in"><h2 id="7e0f" class="ls lt iq bd lu lv lw dn lx ly lz dp ma lf mb mc md lj me mf mg ln mh mi mj mk bi translated">参考</h2><p id="343e" class="pw-post-body-paragraph kw kx iq ky b kz ml jr lb lc mm ju le lf mn lh li lj mo ll lm ln mp lp lq lr ij bi translated">1.生成敌对网络:<a class="ae kv" href="https://arxiv.org/abs/1406.2661" rel="noopener ugc nofollow" target="_blank">https://arxiv.org/abs/1406.2661</a><br/>2。注意力是你所需要的:<a class="ae kv" href="https://arxiv.org/abs/1706.03762" rel="noopener ugc nofollow" target="_blank">https://arxiv.org/pdf/1706.03762.pdf</a>T5】3。DALL E 2详情:<a class="ae kv" href="https://openai.com/dall-e-2/" rel="noopener ugc nofollow" target="_blank">https://openai.com/dall-e-2/</a><br/>4 .伊恩·斯托伊察—雷:分布式系统的通用框架:<a class="ae kv" href="https://youtu.be/tgB671SFS4w" rel="noopener ugc nofollow" target="_blank">https://youtu.be/tgB671SFS4w</a></p></div></div>    
</body>
</html>