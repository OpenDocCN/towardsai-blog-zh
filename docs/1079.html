<html>
<head>
<title>The NLP Cypher | 10.25.20</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">NLP密码| 10.25.20</h1>
<blockquote>原文：<a href="https://pub.towardsai.net/the-nlp-cypher-10-25-20-189183c030f?source=collection_archive---------2-----------------------#2020-10-25">https://pub.towardsai.net/the-nlp-cypher-10-25-20-189183c030f?source=collection_archive---------2-----------------------#2020-10-25</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><figure class="ip iq gp gr ir is gh gi paragraph-image"><div role="button" tabindex="0" class="it iu di iv bf iw"><div class="gh gi io"><img src="../Images/d3d318330b70f69792743dea11a199cc.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*NJhMhgcPYGzOtVgR"/></div></div><figcaption class="iz ja gj gh gi jb jc bd b be z dk translated">优哈娜·纳西夫在<a class="ae jd" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上的照片</figcaption></figure><h2 id="74cc" class="je jf jg bd b dl jh ji jj jk jl jm dk jn translated" aria-label="kicker paragraph">自然语言处理每周时事通讯</h2><div class=""/><div class=""><h2 id="890f" class="pw-subtitle-paragraph km jp jg bd b kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld dk translated">为女王陛下服务</h2></div></div><div class="ab cl le lf hu lg" role="separator"><span class="lh bw bk li lj lk"/><span class="lh bw bk li lj lk"/><span class="lh bw bk li lj"/></div><div class="ij ik il im in"><p id="6436" class="pw-post-body-paragraph ll lm jg ln b lo lp kq lq lr ls kt lt lu lv lw lx ly lz ma mb mc md me mf mg ij bi mh translated"><span class="l mi mj mk bm ml mm mn mo mp di"> W </span>在<a class="ae jd" href="https://datasets.quantumstat.com/" rel="noopener ugc nofollow" target="_blank">大坏的NLP数据库</a>中闲逛时，我发现了一个独特的数据集。这些东西，以及它附带的GitHub回购，让我觉得很奇怪，首先是因为它的内容，其次是因为它的作者/赞助商。所以我去了兔子洞。</p><p id="369b" class="pw-post-body-paragraph ll lm jg ln b lo lp kq lq lr ls kt lt lu lv lw lx ly lz ma mb mc md me mf mg ij bi translated">这个名为re3d的数据集是由英国的几家咨询公司代表<a class="ae jd" href="https://en.wikipedia.org/wiki/Defence_Science_and_Technology_Laboratory" rel="noopener ugc nofollow" target="_blank">国防科技实验室</a> (DSTL)创建的，该实验室是高度机密的<a class="ae jd" href="https://en.wikipedia.org/wiki/Porton_Down" rel="noopener ugc nofollow" target="_blank"> Porton Down </a>政府设施的一部分。技术实验室是英国国防部的子机构，你可以把它看作是英国版的DARPA/Skunkworks。他们有一段“有趣”的历史。但是，为什么英国最秘密的实验室之一对NLP，更具体地说，对实体/关系提取数据集感兴趣呢？嗯……根据他们的回购协议:</p><blockquote class="mq mr ms"><p id="c49d" class="ll lm mt ln b lo lp kq lq lr ls kt lt mu lv lw lx mv lz ma mb mw md me mf mg ij bi translated">该项目旨在创建一个“黄金标准”数据集，可用于训练和验证自然语言处理(NLP)的机器学习方法；特别关注与国防和安全情报分析师相关的实体和关系提取<strong class="ln jq">。</strong></p></blockquote><p id="6f51" class="pw-post-body-paragraph ll lm jg ln b lo lp kq lq lr ls kt lt lu lv lw lx ly lz ma mb mc md me mf mg ij bi translated">说什么？！🧐</p><p id="1f52" class="pw-post-body-paragraph ll lm jg ln b lo lp kq lq lr ls kt lt lu lv lw lx ly lz ma mb mc md me mf mg ij bi translated">他们的数据集由JSON文件组成，其中提取了包含几个“有趣”部门的实体和关系:<a class="ae jd" href="https://github.com/dstl/re3d/tree/master/Australian%20Department%20of%20Foreign%20Affairs" rel="noopener ugc nofollow" target="_blank">澳大利亚外交部</a>、<a class="ae jd" href="https://github.com/dstl/re3d/tree/master/BBC%20Online" rel="noopener ugc nofollow" target="_blank"> BBC在线</a>、<a class="ae jd" href="https://github.com/dstl/re3d/tree/master/CENTCOM" rel="noopener ugc nofollow" target="_blank">中央司令部</a>、<a class="ae jd" href="https://github.com/dstl/re3d/tree/master/Delegation%20of%20the%20European%20Union%20to%20Syria" rel="noopener ugc nofollow" target="_blank">欧盟驻叙利亚代表团</a>、<a class="ae jd" href="https://github.com/dstl/re3d/tree/master/UK%20Government" rel="noopener ugc nofollow" target="_blank">英国政府</a>、<a class="ae jd" href="https://github.com/dstl/re3d/tree/master/US%20State%20Department" rel="noopener ugc nofollow" target="_blank">美国国务院</a>、&amp;(每个人的最爱)<a class="ae jd" href="https://github.com/dstl/re3d/tree/master/Wikipedia" rel="noopener ugc nofollow" target="_blank">维基百科</a>。👨‍💻</p><p id="b468" class="pw-post-body-paragraph ll lm jg ln b lo lp kq lq lr ls kt lt lu lv lw lx ly lz ma mb mc md me mf mg ij bi translated">那么它看起来像什么？下面是CENTCOM(美国中央司令部)文件夹中relations.json文件的一个示例:它显示了实体“Joseph Votel”的元数据，他与实体“美国中央司令部司令”的关系是“IsSynomymOf ”,还包括来自源文档的文本跨度元数据。👁</p><pre class="mx my mz na gt nb nc nd ne aw nf bi"><span id="d428" class="ng nh jg nc b gy ni nj l nk nl">{'_id': '001C9C3F3DFE16B4921B1E906F66E161-3-14-47-0-12-IsSynonymOf',  'begin': 395,  <br/>'confidence': 1,  <br/>'documentId': '001C9C3F3DFE16B4921B1E906F66E161',  <br/>'end': 397,  <br/>'source': 'commander of U.S. Central Command',  <br/>'sourceBegin': 397,  <br/>'sourceEnd': 430,  <br/>'target': 'Joseph Votel',  <br/>'targetBegin': 383,  <br/>'targetEnd': 395,  <br/>'type': 'IsSynonymOf',  <br/>'value': ','}</span></pre><p id="0f46" class="pw-post-body-paragraph ll lm jg ln b lo lp kq lq lr ls kt lt lu lv lw lx ly lz ma mb mc md me mf mg ij bi translated">以下是上例中的源URL:</p><pre class="mx my mz na gt nb nc nd ne aw nf bi"><span id="d364" class="ng nh jg nc b gy ni nj l nk nl">“sourceUrl” : “http://www.centcom.mil/MEDIA/PRESS-RELEASES/Press-Release-View/Article/904608/centcom-reinforces-support-for-syrian-arab-coalition/”</span></pre><p id="17a8" class="pw-post-body-paragraph ll lm jg ln b lo lp kq lq lr ls kt lt lu lv lw lx ly lz ma mb mc md me mf mg ij bi translated">本质上，这个数据集允许一个人从公开可用的文章中创建与军事人员、位置、武器和其他款待的关系/实体图。如果你发挥想象力，这个数据集可以用来做一些疯狂的事情。😬</p><figure class="mx my mz na gt is"><div class="bz fp l di"><div class="nm nn l"/></div><figcaption class="iz ja gj gh gi jb jc bd b be z dk translated">绝对机密的</figcaption></figure><p id="a2c5" class="pw-post-body-paragraph ll lm jg ln b lo lp kq lq lr ls kt lt lu lv lw lx ly lz ma mb mc md me mf mg ij bi translated">他们的GitHub repo提供了他们的关系和实体模式的完整视图，而且DSTL似乎还有其他“有趣”的存储库，您可能想看看。试试这个数据集，让我知道你还能找到什么！别告诉军情六处。info @ quantumstat。com</p><p id="7522" class="pw-post-body-paragraph ll lm jg ln b lo lp kq lq lr ls kt lt lu lv lw lx ly lz ma mb mc md me mf mg ij bi translated">这条信息将在30秒后自毁。</p><div class="ip iq gp gr ir no"><a href="https://github.com/dstl/re3d" rel="noopener  ugc nofollow" target="_blank"><div class="np ab fo"><div class="nq ab nr cl cj ns"><h2 class="bd jq gy z fp nt fr fs nu fu fw jp bi translated">dstl/re3d</h2><div class="nv l"><h3 class="bd b gy z fp nt fr fs nu fu fw dk translated">该数据集是Aleph Insights和Committed Software代表国防部开展的一个项目的成果…</h3></div><div class="nw l"><p class="bd b dl z fp nt fr fs nu fu fw dk translated">github.com</p></div></div><div class="nx l"><div class="ny l nz oa ob nx oc ix no"/></div></div></a></div><h2 id="aecc" class="ng nh jg bd od oe of dn og oh oi dp oj lu ok ol om ly on oo op mc oq or os jm bi translated">NLP的RL</h2><figure class="mx my mz na gt is"><div class="bz fp l di"><div class="ot nn l"/></div></figure><h1 id="775d" class="ou nh jg bd od ov ow ox og oy oz pa oj kv pb kw om ky pc kz op lb pd lc os pe bi translated">新回购</h1><h2 id="2af3" class="ng nh jg bd od oe of dn og oh oi dp oj lu ok ol om ly on oo op mc oq or os jm bi">(👨‍💻)</h2><p id="2d93" class="pw-post-body-paragraph ll lm jg ln b lo pf kq lq lr pg kt lt lu ph lw lx ly pi ma mb mc pj me mf mg ij bi translated"><strong class="ln jq"> MAST:具有三模态分层注意力的多模态抽象概括</strong></p><blockquote class="mq mr ms"><p id="233c" class="ll lm mt ln b lo lp kq lq lr ls kt lt mu lv lw lx mv lz ma mb mw md me mf mg ij bi translated">一种新的多模态抽象文本摘要模型，利用了来自所有三种模态(文本、音频和视频)的信息。</p></blockquote><div class="ip iq gp gr ir no"><a href="https://github.com/amankhullar/mast" rel="noopener  ugc nofollow" target="_blank"><div class="np ab fo"><div class="nq ab nr cl cj ns"><h2 class="bd jq gy z fp nt fr fs nu fu fw jp bi translated">amankhullar/桅杆</h2><div class="nv l"><h3 class="bd b gy z fp nt fr fs nu fu fw dk translated">EMNLP NLPBT 2020纸代码。MAST在300h版本的How2数据集上接受训练…</h3></div><div class="nw l"><p class="bd b dl z fp nt fr fs nu fu fw dk translated">github.com</p></div></div><div class="nx l"><div class="pk l nz oa ob nx oc ix no"/></div></div></a></div><p id="0476" class="pw-post-body-paragraph ll lm jg ln b lo lp kq lq lr ls kt lt lu lv lw lx ly lz ma mb mc md me mf mg ij bi translated"><strong class="ln jq"> CharacterBERT:为来自字符的单词级开放词汇表表示协调ELMo和BERT</strong></p><blockquote class="mq mr ms"><p id="eafa" class="ll lm mt ln b lo lp kq lq lr ls kt lt mu lv lw lx mv lz ma mb mw md me mf mg ij bi translated">CharacterBERT是BERT的一个变体，它通过关注每个输入标记的字符来生成单词级上下文表示。</p></blockquote><div class="ip iq gp gr ir no"><a href="https://github.com/helboukkouri/character-bert" rel="noopener  ugc nofollow" target="_blank"><div class="np ab fo"><div class="nq ab nr cl cj ns"><h2 class="bd jq gy z fp nt fr fs nu fu fw jp bi translated">海尔布克库里/字符-伯特</h2><div class="nv l"><h3 class="bd b gy z fp nt fr fs nu fu fw dk translated">这是“CharacterBERT:调和ELMo和BERT的单词级开放词汇……</h3></div><div class="nw l"><p class="bd b dl z fp nt fr fs nu fu fw dk translated">github.com</p></div></div><div class="nx l"><div class="pl l nz oa ob nx oc ix no"/></div></div></a></div><p id="e752" class="pw-post-body-paragraph ll lm jg ln b lo lp kq lq lr ls kt lt lu lv lw lx ly lz ma mb mc md me mf mg ij bi translated"><strong class="ln jq">利用图卷积网络的多跳问题生成</strong></p><blockquote class="mq mr ms"><p id="de9e" class="ll lm mt ln b lo lp kq lq lr ls kt lt mu lv lw lx mv lz ma mb mw md me mf mg ij bi translated">多跳问题生成(QG)旨在通过从不同段落收集多个分散证据的<em class="jg">聚合</em>和<em class="jg">推理</em>来生成与答案相关的问题。</p></blockquote><div class="ip iq gp gr ir no"><a href="https://github.com/HLTCHKUST/MulQG" rel="noopener  ugc nofollow" target="_blank"><div class="np ab fo"><div class="nq ab nr cl cj ns"><h2 class="bd jq gy z fp nt fr fs nu fu fw jp bi translated">HLTCHKUST/MulQG</h2><div class="nv l"><h3 class="bd b gy z fp nt fr fs nu fu fw dk translated">这是论文的实现:基于图卷积网络的多跳问题生成。、颜……</h3></div><div class="nw l"><p class="bd b dl z fp nt fr fs nu fu fw dk translated">github.com</p></div></div><div class="nx l"><div class="pm l nz oa ob nx oc ix no"/></div></div></a></div><p id="1c89" class="pw-post-body-paragraph ll lm jg ln b lo lp kq lq lr ls kt lt lu lv lw lx ly lz ma mb mc md me mf mg ij bi translated">TweetBERT:用于Twitter文本分析的预训练语言表示模型</p><blockquote class="mq mr ms"><p id="cf7e" class="ll lm mt ln b lo lp kq lq lr ls kt lt mu lv lw lx mv lz ma mb mw md me mf mg ij bi translated">在每个Twitter数据集上，TweetBERT模型在Twitter文本挖掘任务中明显优于传统BERT模型超过7%。</p></blockquote><div class="ip iq gp gr ir no"><a href="https://github.com/mohiuddin02/TweetBERT" rel="noopener  ugc nofollow" target="_blank"><div class="np ab fo"><div class="nq ab nr cl cj ns"><h2 class="bd jq gy z fp nt fr fs nu fu fw jp bi translated">mohiuddin02/TweetBERT</h2><div class="nv l"><h3 class="bd b gy z fp nt fr fs nu fu fw dk translated">TweetBERT:用于Twitter文本分析的预训练语言表示模型GitHub拥有超过5000万…</h3></div><div class="nw l"><p class="bd b dl z fp nt fr fs nu fu fw dk translated">github.com</p></div></div><div class="nx l"><div class="pn l nz oa ob nx oc ix no"/></div></div></a></div><p id="4488" class="pw-post-body-paragraph ll lm jg ln b lo lp kq lq lr ls kt lt lu lv lw lx ly lz ma mb mc md me mf mg ij bi translated"><strong class="ln jq"> GSum:一个用于引导神经抽象概括的通用框架</strong></p><blockquote class="mq mr ms"><p id="13d4" class="ll lm mt ln b lo lp kq lq lr ls kt lt mu lv lw lx mv lz ma mb mw md me mf mg ij bi translated">GSUm是一个抽象的摘要框架，它可以有效地将不同类型的外部指导作为输入，生成不同质量的摘要。</p></blockquote><div class="ip iq gp gr ir no"><a href="https://github.com/neulab/guided_summarization" rel="noopener  ugc nofollow" target="_blank"><div class="np ab fo"><div class="nq ab nr cl cj ns"><h2 class="bd jq gy z fp nt fr fs nu fu fw jp bi translated">neu lab/guided _摘要</h2><div class="nv l"><h3 class="bd b gy z fp nt fr fs nu fu fw dk translated">此时您不能执行该操作。您已使用另一个标签页或窗口登录。您已在另一个选项卡中注销，或者…</h3></div><div class="nw l"><p class="bd b dl z fp nt fr fs nu fu fw dk translated">github.com</p></div></div><div class="nx l"><div class="po l nz oa ob nx oc ix no"/></div></div></a></div><p id="2d2b" class="pw-post-body-paragraph ll lm jg ln b lo lp kq lq lr ls kt lt lu lv lw lx ly lz ma mb mc md me mf mg ij bi translated"><strong class="ln jq"> NeuSpell:一个神经拼写纠正工具包</strong></p><blockquote class="mq mr ms"><p id="5828" class="ll lm mt ln b lo lp kq lq lr ls kt lt mu lv lw lx mv lz ma mb mw md me mf mg ij bi translated">这个工具包包括10个拼写检查器，对来自多个(公开可用的)来源的自然发生的拼写错误进行评估。</p></blockquote><div class="ip iq gp gr ir no"><a href="https://github.com/neuspell/neuspell" rel="noopener  ugc nofollow" target="_blank"><div class="np ab fo"><div class="nq ab nr cl cj ns"><h2 class="bd jq gy z fp nt fr fs nu fu fw jp bi translated">新拼写/新拼写</h2><div class="nv l"><h3 class="bd b gy z fp nt fr fs nu fu fw dk translated">NeuSpell:一个神经拼写纠正工具包NeuSpell是一个用于上下文敏感拼写的开源工具包…</h3></div><div class="nw l"><p class="bd b dl z fp nt fr fs nu fu fw dk translated">github.com</p></div></div><div class="nx l"><div class="pp l nz oa ob nx oc ix no"/></div></div></a></div><p id="dd2e" class="pw-post-body-paragraph ll lm jg ln b lo lp kq lq lr ls kt lt lu lv lw lx ly lz ma mb mc md me mf mg ij bi translated"><strong class="ln jq">增强SBERT:用于改进成对句子评分任务的双编码器的数据增强方法</strong></p><blockquote class="mq mr ms"><p id="453a" class="ll lm mt ln b lo lp kq lq lr ls kt lt mu lv lw lx mv lz ma mb mw md me mf mg ij bi translated">交叉编码器用于标记更大的一组输入对，以增加双编码器的训练数据，用于成对句子评分。(思考语义文本相似性)</p></blockquote><div class="ip iq gp gr ir no"><a href="https://github.com/UKPLab/sentence-transformers" rel="noopener  ugc nofollow" target="_blank"><div class="np ab fo"><div class="nq ab nr cl cj ns"><h2 class="bd jq gy z fp nt fr fs nu fu fw jp bi translated">uk plab/句子-变形金刚</h2><div class="nv l"><h3 class="bd b gy z fp nt fr fs nu fu fw dk translated">这个框架提供了一个简单的方法来计算句子和段落的密集向量表示(也称为…</h3></div><div class="nw l"><p class="bd b dl z fp nt fr fs nu fu fw dk translated">github.com</p></div></div><div class="nx l"><div class="pq l nz oa ob nx oc ix no"/></div></div></a></div><p id="db31" class="pw-post-body-paragraph ll lm jg ln b lo lp kq lq lr ls kt lt lu lv lw lx ly lz ma mb mc md me mf mg ij bi translated"><strong class="ln jq">表格和文本上的开放式问题回答</strong></p><blockquote class="mq mr ms"><p id="e4c8" class="ll lm mt ln b lo lp kq lq lr ls kt lt mu lv lw lx mv lz ma mb mw md me mf mg ij bi translated">一种新的大规模数据集，称为开放表格文本问答(OTT-QA)，用于对表格和文本数据进行开放问答。</p></blockquote><div class="ip iq gp gr ir no"><a href="https://github.com/wenhuchen/OTT-QA" rel="noopener  ugc nofollow" target="_blank"><div class="np ab fo"><div class="nq ab nr cl cj ns"><h2 class="bd jq gy z fp nt fr fs nu fu fw jp bi translated">文虎臣/OTT-QA</h2><div class="nv l"><h3 class="bd b gy z fp nt fr fs nu fu fw dk translated">该库包含OTT-QA数据集，用于通过表格和文本回答开放式问题，以及基线代码…</h3></div><div class="nw l"><p class="bd b dl z fp nt fr fs nu fu fw dk translated">github.com</p></div></div><div class="nx l"><div class="pr l nz oa ob nx oc ix no"/></div></div></a></div></div><div class="ab cl le lf hu lg" role="separator"><span class="lh bw bk li lj lk"/><span class="lh bw bk li lj lk"/><span class="lh bw bk li lj"/></div><div class="ij ik il im in"><h1 id="57cf" class="ou nh jg bd od ov ps ox og oy pt pa oj kv pu kw om ky pv kz op lb pw lc os pe bi translated">M2M-100</h1><p id="d33b" class="pw-post-body-paragraph ll lm jg ln b lo pf kq lq lr pg kt lt lu ph lw lx ly pi ma mb mc pj me mf mg ij bi translated">因此，这种模型成为了本周的头条新闻，脸书人工智能揭示了M2M-100，这是一种独立于英语数据的多语言翻译模型，可以处理任何一对100种语言。这很方便，因为与传统方法相比，BLUE的性能提高了10个点(传统方法需要英语作为中间人，因为它有丰富的数据集(例如，中文到英文，然后英文到法文，用于中文到法文的翻译任务)。))</p><p id="b91b" class="pw-post-body-paragraph ll lm jg ln b lo lp kq lq lr ls kt lt lu lv lw lx ly lz ma mb mc md me mf mg ij bi translated">训练数据来源于海量的<a class="ae jd" href="https://arxiv.org/abs/1911.04944" rel="noopener ugc nofollow" target="_blank"> CCMatrix </a>和<a class="ae jd" href="https://arxiv.org/abs/1911.06154" rel="noopener ugc nofollow" target="_blank"> CCAligned </a>数据集。此外，他们还发布了一个12B参数模型检查点供您使用。(如果你有大量的图形处理器)</p><div class="ip iq gp gr ir no"><a href="https://github.com/pytorch/fairseq/tree/master/examples/m2m_100?fbclid=IwAR3aeGvLraZ-cjnFumAdWFK8OELwm3y6BwOK8O_4NNE52mSdfyAwSs75iII" rel="noopener  ugc nofollow" target="_blank"><div class="np ab fo"><div class="nq ab nr cl cj ns"><h2 class="bd jq gy z fp nt fr fs nu fu fw jp bi translated">pytorch/fairseq</h2><div class="nv l"><h3 class="bd b gy z fp nt fr fs nu fu fw dk translated">在这项工作中，我们创建了一个真正的多对多多语言翻译模型，可以直接在任何对…</h3></div><div class="nw l"><p class="bd b dl z fp nt fr fs nu fu fw dk translated">github.com</p></div></div><div class="nx l"><div class="px l nz oa ob nx oc ix no"/></div></div></a></div><h1 id="d4f3" class="ou nh jg bd od ov ow ox og oy oz pa oj kv pb kw om ky pc kz op lb pd lc os pe bi translated">数据中毒</h1><p id="6673" class="pw-post-body-paragraph ll lm jg ln b lo pf kq lq lr pg kt lt lu ph lw lx ly pi ma mb mc pj me mf mg ij bi translated">数据安全很重要。尤其是当人们使用这些数据来训练他们的模型时。根据Eric Wallace的新博客文章，有一些方法可以通过在输入中使用特定的触发短语来影响模型的预测。他使用的例子是对手为“苹果iPhones”评论设置触发阶段(偏向正面评论)。当你在野外遇到新数据进行推断时，该模型会预测关于“苹果iPhones”的样本评论为正面，即使评论可能是负面的。请继续阅读，了解他们是如何做到的:</p><div class="ip iq gp gr ir no"><a href="https://www.ericswallace.com/poisoning" rel="noopener  ugc nofollow" target="_blank"><div class="np ab fo"><div class="nq ab nr cl cj ns"><h2 class="bd jq gy z fp nt fr fs nu fu fw jp bi translated">数据中毒</h2><div class="nv l"><h3 class="bd b gy z fp nt fr fs nu fu fw dk translated">现代NLP痴迷于收集大型训练集。例如，用于训练的无监督数据集…</h3></div><div class="nw l"><p class="bd b dl z fp nt fr fs nu fu fw dk translated">www.ericswallace.com</p></div></div><div class="nx l"><div class="py l nz oa ob nx oc ix no"/></div></div></a></div><h1 id="5db1" class="ou nh jg bd od ov ow ox og oy oz pa oj kv pb kw om ky pc kz op lb pd lc os pe bi translated">ReGex仍然存在，并且运行良好</h1><p id="501d" class="pw-post-body-paragraph ll lm jg ln b lo pf kq lq lr pg kt lt lu ph lw lx ly pi ma mb mc pj me mf mg ij bi translated">Amit Chaudhary的牛逼博客讨论了一个经典:正则表达式。这篇精心制作的文章既是一个介绍，也是一个备忘单，可以帮助regex noob熟悉底层Python(也称为eagles dare)。</p><div class="ip iq gp gr ir no"><a href="https://amitness.com/regex/" rel="noopener  ugc nofollow" target="_blank"><div class="np ab fo"><div class="nq ab nr cl cj ns"><h2 class="bd jq gy z fp nt fr fs nu fu fw jp bi translated">正则表达式的可视化指南</h2><div class="nv l"><h3 class="bd b gy z fp nt fr fs nu fu fw dk translated">在NLP中，根据模式检查文本或者从文本中提取与模式匹配的部分是一项常见的任务</h3></div><div class="nw l"><p class="bd b dl z fp nt fr fs nu fu fw dk translated">amitness.com</p></div></div><div class="nx l"><div class="pz l nz oa ob nx oc ix no"/></div></div></a></div><h1 id="cfb4" class="ou nh jg bd od ov ow ox og oy oz pa oj kv pb kw om ky pc kz op lb pd lc os pe bi translated">外汇数据转储</h1><p id="b218" class="pw-post-body-paragraph ll lm jg ln b lo pf kq lq lr pg kt lt lu ph lw lx ly pi ma mb mc pj me mf mg ij bi translated">想要十年的外汇交易数据吗？有人使用了Dukascopy API，并为自己开了一个派对。可以通过seedbox/torrent获得。</p><p id="08dd" class="pw-post-body-paragraph ll lm jg ln b lo lp kq lq lr ls kt lt lu lv lw lx ly lz ma mb mc md me mf mg ij bi translated"><strong class="ln jq">总档案</strong> 463</p><p id="3f84" class="pw-post-body-paragraph ll lm jg ln b lo lp kq lq lr ls kt lt lu lv lw lx ly lz ma mb mc md me mf mg ij bi translated"><strong class="ln jq">总行数</strong>8495770706</p><p id="4cf4" class="pw-post-body-paragraph ll lm jg ln b lo lp kq lq lr ls kt lt lu lv lw lx ly lz ma mb mc md me mf mg ij bi translated"><strong class="ln jq">总数据点</strong>33983082824</p><p id="44e0" class="pw-post-body-paragraph ll lm jg ln b lo lp kq lq lr ls kt lt lu lv lw lx ly lz ma mb mc md me mf mg ij bi translated"><strong class="ln jq">总解压缩大小</strong> 501 GB</p><p id="c340" class="pw-post-body-paragraph ll lm jg ln b lo lp kq lq lr ls kt lt lu lv lw lx ly lz ma mb mc md me mf mg ij bi translated"><strong class="ln jq">总压缩大小</strong> 61 GB</p><figure class="mx my mz na gt is"><div class="bz fp l di"><div class="qa nn l"/></div><figcaption class="iz ja gj gh gi jb jc bd b be z dk translated">解密的</figcaption></figure><h1 id="c0aa" class="ou nh jg bd od ov ow ox og oy oz pa oj kv pb kw om ky pc kz op lb pd lc os pe bi translated">在Rust中搜索(别担心，有python包装器)</h1><p id="088c" class="pw-post-body-paragraph ll lm jg ln b lo pf kq lq lr pg kt lt lu ph lw lx ly pi ma mb mc pj me mf mg ij bi translated">MeiliSearch你试过吗？如果你喜欢搜索和索引数据，你应该给它一个驱动器。我在探索上面介绍中讨论的詹姆斯·邦德数据集时使用了它。它也是用Rust写的，所以非常快！</p><p id="c002" class="pw-post-body-paragraph ll lm jg ln b lo lp kq lq lr ls kt lt lu lv lw lx ly lz ma mb mc md me mf mg ij bi translated">以下是其开箱即用的强大功能列表:</p><ul class=""><li id="3b4c" class="qb qc jg ln b lo lp lr ls lu qd ly qe mc qf mg qg qh qi qj bi translated">搜索即时体验(答案&lt; 50 milliseconds) 🔥</li><li id="eebf" class="qb qc jg ln b lo qk lr ql lu qm ly qn mc qo mg qg qh qi qj bi translated">Full-text search</li><li id="8e9e" class="qb qc jg ln b lo qk lr ql lu qm ly qn mc qo mg qg qh qi qj bi translated">Typo tolerant (understands typos and miss-spelling)</li><li id="f942" class="qb qc jg ln b lo qk lr ql lu qm ly qn mc qo mg qg qh qi qj bi translated">Faceted search and filters</li><li id="67b0" class="qb qc jg ln b lo qk lr ql lu qm ly qn mc qo mg qg qh qi qj bi translated">Supports Kanji characters</li><li id="dc4a" class="qb qc jg ln b lo qk lr ql lu qm ly qn mc qo mg qg qh qi qj bi translated">Supports Synonym</li><li id="b5b5" class="qb qc jg ln b lo qk lr ql lu qm ly qn mc qo mg qg qh qi qj bi translated">Easy to install, deploy, and maintain</li><li id="ce20" class="qb qc jg ln b lo qk lr ql lu qm ly qn mc qo mg qg qh qi qj bi translated">Whole documents are returned</li><li id="bdb5" class="qb qc jg ln b lo qk lr ql lu qm ly qn mc qo mg qg qh qi qj bi translated">Highly customizable</li><li id="707f" class="qb qc jg ln b lo qk lr ql lu qm ly qn mc qo mg qg qh qi qj bi translated">RESTful API</li></ul><div class="ip iq gp gr ir no"><a href="https://github.com/meilisearch/MeiliSearch" rel="noopener  ugc nofollow" target="_blank"><div class="np ab fo"><div class="nq ab nr cl cj ns"><h2 class="bd jq gy z fp nt fr fs nu fu fw jp bi translated">meilisearch/MeiliSearch</h2><div class="nv l"><h3 class="bd b gy z fp nt fr fs nu fu fw dk translated">⚡ Lightning Fast, Ultra Relevant, and Typo-Tolerant Search Engine 🔍 MeiliSearch is a powerful, fast, open-source, easy…</h3></div><div class="nw l"><p class="bd b dl z fp nt fr fs nu fu fw dk translated">github.com</p></div></div><div class="nx l"><div class="qp l nz oa ob nx oc ix no"/></div></div></a></div><p id="057d" class="pw-post-body-paragraph ll lm jg ln b lo lp kq lq lr ls kt lt lu lv lw lx ly lz ma mb mc md me mf mg ij bi translated"><strong class="ln jq">文档</strong></p><div class="ip iq gp gr ir no"><a href="https://docs.meilisearch.com/guides/introduction/" rel="noopener  ugc nofollow" target="_blank"><div class="np ab fo"><div class="nq ab nr cl cj ns"><h2 class="bd jq gy z fp nt fr fs nu fu fw jp bi translated">介绍</h2><div class="nv l"><h3 class="bd b gy z fp nt fr fs nu fu fw dk translated">开源即时搜索引擎</h3></div><div class="nw l"><p class="bd b dl z fp nt fr fs nu fu fw dk translated">docs.meilisearch.com</p></div></div><div class="nx l"><div class="qq l nz oa ob nx oc ix no"/></div></div></a></div><p id="5805" class="pw-post-body-paragraph ll lm jg ln b lo lp kq lq lr ls kt lt lu lv lw lx ly lz ma mb mc md me mf mg ij bi translated">抱歉，没有“本周数据集”。这一次，有<a class="ae jd" href="https://blazorguy.net/Blazor/BlazorGalaga/" rel="noopener ugc nofollow" target="_blank">这个</a></p></div><div class="ab cl le lf hu lg" role="separator"><span class="lh bw bk li lj lk"/><span class="lh bw bk li lj lk"/><span class="lh bw bk li lj"/></div><div class="ij ik il im in"><blockquote class="qr"><p id="b2b9" class="qs qt jg bd qu qv qw qx qy qz ra mg dk translated"><em class="rb">每周日，我们都会对来自世界各地的研究人员的NLP新闻和代码进行每周综述。</em></p><p id="d2e4" class="qs qt jg bd qu qv qw qx qy qz ra mg dk translated"><em class="rb">如需完整报道，请关注我们的Twitter:</em><a class="ae jd" href="http://twitter.com/Quantum_Stat" rel="noopener ugc nofollow" target="_blank"><em class="rb">@ Quantum _ Stat</em></a></p></blockquote><figure class="rd re rf rg rh is gh gi paragraph-image"><div class="gh gi rc"><img src="../Images/5901293a48d381c9bcb9ea93dc2ef37a.png" data-original-src="https://miro.medium.com/v2/resize:fit:108/0*snDXFcPahk8vRLKo"/></div><figcaption class="iz ja gj gh gi jb jc bd b be z dk translated"><a class="ae jd" href="http://www.quantumstat.com/" rel="noopener ugc nofollow" target="_blank">www.quantumstat.com</a></figcaption></figure></div></div>    
</body>
</html>