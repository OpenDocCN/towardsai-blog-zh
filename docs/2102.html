<html>
<head>
<title>Microsoft Uses GANs with Discrete Data</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">微软对离散数据使用GANs</h1>
<blockquote>原文：<a href="https://pub.towardsai.net/microsoft-uses-gans-with-discrete-data-c33ad16616e7?source=collection_archive---------1-----------------------#2021-08-17">https://pub.towardsai.net/microsoft-uses-gans-with-discrete-data-c33ad16616e7?source=collection_archive---------1-----------------------#2021-08-17</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><h2 id="dfb8" class="ir is it bd b dl iu iv iw ix iy iz dk ja translated" aria-label="kicker paragraph"><a class="ae ep" href="https://towardsai.net/p/category/machine-learning" rel="noopener ugc nofollow" target="_blank">机器学习</a></h2><div class=""/><div class=""><h2 id="91b0" class="pw-subtitle-paragraph jz jc it bd b ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq dk translated">边界搜索GAN是一种使用离散数据训练GAN模型的方法。</h2></div><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi kr"><img src="../Images/f571bbe7d540c2255d7d869246d69267.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*UuDI_x1gKK6QotwCI-keig.png"/></div></div><figcaption class="ld le gj gh gi lf lg bd b be z dk translated">图片来源:微软</figcaption></figure><blockquote class="lh li lj"><p id="5086" class="lk ll lm ln b lo lp kd lq lr ls kg lt lu lv lw lx ly lz ma mb mc md me mf mg im bi translated">我最近创办了一份专注于人工智能的教育时事通讯，已经有超过10万名订户。《序列》是一份无废话(意思是没有炒作，没有新闻等)的ML导向时事通讯，需要5分钟阅读。目标是让你与机器学习项目、研究论文和概念保持同步。请通过订阅以下内容来尝试一下:</p></blockquote><div class="mh mi gp gr mj mk"><a href="https://thesequence.substack.com/" rel="noopener  ugc nofollow" target="_blank"><div class="ml ab fo"><div class="mm ab mn cl cj mo"><h2 class="bd jd gy z fp mp fr fs mq fu fw jc bi translated">序列</h2><div class="mr l"><h3 class="bd b gy z fp mp fr fs mq fu fw dk translated">订阅人工智能世界中最相关的项目和研究论文。受到102，000多人的信任…</h3></div><div class="ms l"><p class="bd b dl z fp mp fr fs mq fu fw dk translated">thesequence.substack.com</p></div></div><div class="mt l"><div class="mu l mv mw mx mt my lb mk"/></div></div></a></div><p id="fddc" class="pw-post-body-paragraph lk ll it ln b lo lp kd lq lr ls kg lt mz lv lw lx na lz ma mb nb md me mf mg im bi translated">生成模型是深度学习的子学科，专注于静态精确目标数据的创建。在深度学习研究中，我们可以找到不同组的生成模型，如玻尔兹曼机器或定向生成网络。然而，在过去几年中，生成模型的最受欢迎奖无疑是生成对抗网络。在短短几年内，GANs已经成为图像生成等关键任务深度学习场景的首选模型。</p><p id="7431" class="pw-post-body-paragraph lk ll it ln b lo lp kd lq lr ls kg lt mz lv lw lx na lz ma mb nb md me mf mg im bi translated">尽管它很受欢迎，但当今大多数GAN技术仅在处理连续数据时有效。这是因为GAN模型通常依赖于生成的样本是完全可微分的，因此对于离散数据不太适用。2018年，来自微软的研究人员提出了一项名为<a class="ae nc" href="https://www.microsoft.com/en-us/research/publication/boundary-seeking-gans/" rel="noopener ugc nofollow" target="_blank">边界搜索GAN</a>的新技术，可以使用离散数据训练GAN模型。</p><h1 id="09fe" class="nd ne it bd nf ng nh ni nj nk nl nm nn ki no kj np kl nq km nr ko ns kp nt nu bi translated">了解GANs</h1><p id="473b" class="pw-post-body-paragraph lk ll it ln b lo nv kd lq lr nw kg lt mz nx lw lx na ny ma mb nb nz me mf mg im bi translated">对于围绕GANs的所有讨论，生成方法是一种相对较新的技术，由深度学习Ian Goodfellow在2014年的一篇<a class="ae nc" href="https://arxiv.org/abs/1406.2661" rel="noopener ugc nofollow" target="_blank">研究论文中提出。GANs背后的主要思想是创建包含两个基本模型的网络:捕获数据分布的生成模型G和估计样本来自训练数据而不是G的概率的判别模型D。G的训练过程是使D出错的概率最大化。</a></p><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi oa"><img src="../Images/7097f7dc286344ef6073bfdba0be49d9.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*JwoQerKlHBO9B2FI4BUVjQ.png"/></div></div><figcaption class="ld le gj gh gi lf lg bd b be z dk translated">图片来源:微软</figcaption></figure><p id="dcee" class="pw-post-body-paragraph lk ll it ln b lo lp kd lq lr ls kg lt mz lv lw lx na lz ma mb nb md me mf mg im bi translated">g an在处理连续数据时非常有效，因为生成器和鉴别器的组成是完全可微分的，这意味着两个网络都可以使用反向传播等算法进行训练。然而，这在离散数据的情况下是不正确的，因为那些分布几乎在任何地方都具有零梯度(否则是无限的)，所以不可能单独使用反向传播来训练发生器。</p><h1 id="46e4" class="nd ne it bd nf ng nh ni nj nk nl nm nn ki no kj np kl nq km nr ko ns kp nt nu bi translated">为什么离散世代很重要？</h1><p id="23db" class="pw-post-body-paragraph lk ll it ln b lo nv kd lq lr nw kg lt mz nx lw lx na ny ma mb nb nz me mf mg im bi translated">既然我们已经了解了将GAN模型用于离散数据的挑战，那么下一个显而易见的问题是，这到底有什么关系？事实证明，离散GAN模型是大量自然语言处理场景的关键，如机器翻译或字幕生成。类似地，离散生成用于其他领域，例如图像分割，因为它应该避免传统模型的过拟合挑战。</p><h1 id="5303" class="nd ne it bd nf ng nh ni nj nk nl nm nn ki no kj np kl nq km nr ko ns kp nt nu bi translated">什么是寻求边界的甘？</h1><p id="3649" class="pw-post-body-paragraph lk ll it ln b lo nv kd lq lr nw kg lt mz nx lw lx na ny ma mb nb nz me mf mg im bi translated">微软寻求边界的GANs背后的想法是引入一个新的政策梯度，有效地处理离散数据。如前所述，GANs只有在价值函数完全可微时才起作用。对于离散数据，用于训练离散变量生成器的梯度几乎处处为零，因此不可能使用值函数直接训练生成器。然而，如果我们改变梯度会发生什么？</p><p id="b958" class="pw-post-body-paragraph lk ll it ln b lo lp kd lq lr ls kg lt mz lv lw lx na lz ma mb nb md me mf mg im bi translated">边界搜索GANs简单地引入了一种双梯度方法，它能有效地处理离散数据分布。最初，边界搜索型gan使用基于KL-divergence的策略梯度，该策略梯度使用重要性权重。然后，该技术将该梯度与一个较低方差的梯度相结合，该梯度为每个z定义了一个唯一的奖励信号，并证明这可以用于解决我们最初的问题。结果是一个GAN模型，其中鉴别器可用于制定为生成器提供策略梯度的重要性权重。</p><h1 id="74cc" class="nd ne it bd nf ng nh ni nj nk nl nm nn ki no kj np kl nq km nr ko ns kp nt nu bi translated">寻求边界的甘在行动</h1><p id="8317" class="pw-post-body-paragraph lk ll it ln b lo nv kd lq lr nw kg lt mz nx lw lx na ny ma mb nb nz me mf mg im bi translated">微软团队将边界搜索GAN方法用于测试不同的离散数据生成场景。其中一个实验使用了著名的MNIST和西里巴数据集。在MNIST实验的情况下，结果在数量上优于竞争方法，例如WGAN-GP。下图显示了该算法如何能够生成逼真且高度可变的手写数字。</p><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div class="gh gi ob"><img src="../Images/6044f819bdde6e17d660e1d8bdffc6a3.png" data-original-src="https://miro.medium.com/v2/resize:fit:1140/format:webp/1*RUl7G_F4bwOwUPTXAms-XA.jpeg"/></div><figcaption class="ld le gj gh gi lf lg bd b be z dk translated">图片来源:微软</figcaption></figure><p id="60fb" class="pw-post-body-paragraph lk ll it ln b lo lp kd lq lr ls kg lt mz lv lw lx na lz ma mb nb md me mf mg im bi translated">类似地，在CelebA实验中，被训练为BGAN的生成器产生了相当逼真的图像，这些图像很好地类似于原始数据集并且具有良好的多样性</p><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div class="gh gi oc"><img src="../Images/302f1d8d5df33d2e0cfaf4456b3aa9cf.png" data-original-src="https://miro.medium.com/v2/resize:fit:448/format:webp/1*Tt2e2_9Pkecbtsa5wZBYgg.jpeg"/></div><figcaption class="ld le gj gh gi lf lg bd b be z dk translated">Groundtruth 16色(4位)量化CelebA图像向下采样至32 × 32。图片来源:微软</figcaption></figure><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div class="gh gi oc"><img src="../Images/e5b4453005f400d823743a43c421b093.png" data-original-src="https://miro.medium.com/v2/resize:fit:448/format:webp/1*CsOwWK6iY_-BEyHpopiWUg.jpeg"/></div><figcaption class="ld le gj gh gi lf lg bd b be z dk translated">从发生器产生的样本被训练为在量化的CelebA上寻找GAN的边界50个时期。图片来源:微软</figcaption></figure></div></div>    
</body>
</html>