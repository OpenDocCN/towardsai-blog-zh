<html>
<head>
<title>Decrypting QAnon</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">解密QAnon</h1>
<blockquote>原文：<a href="https://pub.towardsai.net/the-language-of-qanon-2e3411afa9be?source=collection_archive---------2-----------------------#2021-03-20">https://pub.towardsai.net/the-language-of-qanon-2e3411afa9be?source=collection_archive---------2-----------------------#2021-03-20</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><h2 id="5248" class="io ip iq bd b dl ir is it iu iv iw dk ix translated" aria-label="kicker paragraph"><a class="ae ep" href="https://towardsai.net/p/category/nlp" rel="noopener ugc nofollow" target="_blank">自然语言处理</a>，<a class="ae ep" href="https://towardsai.net/p/category/opinion" rel="noopener ugc nofollow" target="_blank">意见</a></h2><div class=""/><div class=""><h2 id="c1dd" class="pw-subtitle-paragraph jw iz iq bd b jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn dk translated">以NLP为导向看运动的核心文本。</h2></div><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div role="button" tabindex="0" class="ku kv di kw bf kx"><div class="gh gi ko"><img src="../Images/c06a444e6ca3da0dc3d7f61b50393c31.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*91H4HMTQ68BkOZo73MjvzA.jpeg"/></div></div><figcaption class="la lb gj gh gi lc ld bd b be z dk translated">2020年1月，弗吉尼亚第二修正案集会上的QAnon旗。鸣谢:安东尼·克里德/Flickr (CC-BY 2.0)</figcaption></figure><p id="a29e" class="pw-post-body-paragraph le lf iq lg b lh li ka lj lk ll kd lm ln lo lp lq lr ls lt lu lv lw lx ly lz ij bi translated">特朗普和拜登政府之间的过渡最有趣的影响之一是公众对<a class="ae ma" href="https://edition.cnn.com/2020/12/15/us/qanon-trump-twitter-invs/index.html" rel="noopener ugc nofollow" target="_blank"> QAnon </a>的兴趣下降——这是一种臭名昭著的网络阴谋论，与这位美国前总统及其选举欺诈的虚假指控密切相关。如下图所示，关于QAnon运动的讨论在1月初达到顶峰，与国会山风暴相对应，这是一个关键事件，QAnon相关的在线内容起到了推波助澜的作用。</p><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div role="button" tabindex="0" class="ku kv di kw bf kx"><div class="gh gi mb"><img src="../Images/08a83f8624ef40345be1f4f02368d92a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*pkYwkQPf9kpyzakROv8DZA.png"/></div></div><figcaption class="la lb gj gh gi lc ld bd b be z dk translated">“qanon”一词的谷歌研究趋势，美国，2021年1月4日–2021年3月4日。</figcaption></figure><p id="e5d8" class="pw-post-body-paragraph le lf iq lg b lh li ka lj lk ll kd lm ln lo lp lq lr ls lt lu lv lw lx ly lz ij bi translated">然而，在接下来的几周里，QAnon在公共话语中戏剧性地失去了相关性；下降的主要原因是其内容从脸书、Twitter和Youtube等主要社交媒体上被大量删除，这导致QAnonists迁移到Parler或Gab等右翼回音室。</p><p id="6bbe" class="pw-post-body-paragraph le lf iq lg b lh li ka lj lk ll kd lm ln lo lp lq lr ls lt lu lv lw lx ly lz ij bi translated">尽管如此，QAnon运动仍然在政治舞台上发挥着重要作用，仔细看看它的显著特征可能会很有意思。在这篇文章中，我将采用一些基本的数据科学技术，带你浏览QAnon的“圣书”，即塑造了该运动世界观的大量在线帖子。我们走吧！</p></div><div class="ab cl mc md hu me" role="separator"><span class="mf bw bk mg mh mi"/><span class="mf bw bk mg mh mi"/><span class="mf bw bk mg mh"/></div><div class="ij ik il im in"><h2 id="a86f" class="mj mk iq bd ml mm mn dn mo mp mq dp mr ln ms mt mu lr mv mw mx lv my mz na iw bi translated">你会说卡侬语吗？</h2><p id="b3b3" class="pw-post-body-paragraph le lf iq lg b lh nb ka lj lk nc kd lm ln nd lp lq lr ne lt lu lv nf lx ly lz ij bi translated">我不打算在这里重述该运动的特点和目标(见<a class="ae ma" href="https://en.wikipedia.org/wiki/QAnon" rel="noopener ugc nofollow" target="_blank">维基百科</a>)，但在我们挖掘其文本之前，你可能会喜欢他们所谓的作者，神秘的“Q”的一点背景。根据QAnon lore的说法，他/她是一名高调的美国情报官员，在政府内部充当某种间谍，并在<em class="ng"> 8chan </em>或<em class="ng"> 8kun </em>等留言板上分享关于特朗普对抗深层国家的英勇战争的情报。这些神秘的帖子然后由社区调查和研究，邀请社区“跟踪线索”,从字里行间解读秘密行动的编码证据。</p><p id="06b9" class="pw-post-body-paragraph le lf iq lg b lh li ka lj lk ll kd lm ln lo lp lq lr ls lt lu lv lw lx ly lz ij bi translated">关于Q的真实身份的猜测经常指向管理员罗恩和吉姆·沃特金斯，而瑞士一家公司的风格分析表明，这些帖子至少是由两个人在不同时期写的。然而，由于Q的“旅行码”——一种用于在<em class="ng"> 8chan — </em>上验证身份的在线签名——已经不止一次被泄露，很可能有几个人用这个名字发了帖子。但是基本的NLP技术能告诉我们这些帖子的内容是什么呢？</p><p id="fd3c" class="pw-post-body-paragraph le lf iq lg b lh li ka lj lk ll kd lm ln lo lp lq lr ls lt lu lv lw lx ly lz ij bi translated">我的实验开始在网上搜索“Q drops ”,很快我就登陆了一个收集这些所谓的英特尔片段的镜像网站。投放相当不定期(最后一次可用的日期是2020年12月8日)，但一个横幅警告不要“将沉默误认为不作为”，因为有时Q“战略上陷入黑暗”，而“重大军事行动正在幕后发生”。令人印象深刻。</p><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div class="gh gi nh"><img src="../Images/997f7309cac0ae13fe0d98a5be254b3e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1196/format:webp/1*MJyKpiliscSgWgbbu45fNw.png"/></div><figcaption class="la lb gj gh gi lc ld bd b be z dk translated">“下落”样本(Q的帖子#4915)。鸣谢:公共领域图像。</figcaption></figure><p id="94af" class="pw-post-body-paragraph le lf iq lg b lh li ka lj lk ll kd lm ln lo lp lq lr ls lt lu lv lw lx ly lz ij bi translated">无论如何，我下载了一堆可用的drops(追溯到2017年10月29日，并方便地打包在1255页长的PDF中)，并将其转换为TXT格式。然后，是时候进行一些Python编码了:如果你想继续的话，这里有我的Colab笔记本的链接。</p><p id="eebf" class="pw-post-body-paragraph le lf iq lg b lh li ka lj lk ll kd lm ln lo lp lq lr ls lt lu lv lw lx ly lz ij bi translated">首先，我做了一些文本预处理，删除了非字母字符(尽管我怀疑一些标志性的数字，如特朗普的“45”)，停用词(如“状态”，指Twiter帖子)和少于两个字符的单词——主要是前面步骤的副产品。在你问之前，我确实注意到了图标“Q”的出现:它们几乎有12，000个，因为这个字母用于签署大多数帖子。</p><p id="5e54" class="pw-post-body-paragraph le lf iq lg b lh li ka lj lk ll kd lm ln lo lp lq lr ls lt lu lv lw lx ly lz ij bi translated">清理完语料后，我建立了一个词频词典，从中选出了出现频率最高的500个关键词。为了提高数据集质量，我检查了这些关键字是否属于英语词汇，同时手动添加了未识别的单个名称和重要单词(例如“potus”)。</p><p id="b64e" class="pw-post-body-paragraph le lf iq lg b lh li ka lj lk ll kd lm ln lo lp lq lr ls lt lu lv lw lx ly lz ij bi translated">最终的字典有486个条目。但是如何以一种有意义的方式来观想它们呢？</p><h2 id="befc" class="mj mk iq bd ml mm mn dn mo mp mq dp mr ln ms mt mu lr mv mw mx lv my mz na iw bi translated">探索QAnon的热门话题</h2><p id="def7" class="pw-post-body-paragraph le lf iq lg b lh nb ka lj lk nc kd lm ln nd lp lq lr ne lt lu lv nf lx ly lz ij bi translated">在Medium上的前一篇文章中，我谈到了单词云，以及它们如何通过可视化来直观地理解大文本的意思。因此，一个解决方案是将数据输入到WordCloud算法中。结果如下:</p><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div role="button" tabindex="0" class="ku kv di kw bf kx"><div class="gh gi ni"><img src="../Images/346bf7eab8fb0c997fba17cc92566651.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*xBQ4xeDLf7PvD6PS1CRCsA.png"/></div></div><figcaption class="la lb gj gh gi lc ld bd b be z dk translated">鸣谢:wordcloud对GDJ/Pixabay原创图片的阐述。我不是很确定为什么所有的单词都是双倍的，但我怀疑这与WordCloud算法如何填充掩码空间有关。</figcaption></figure><p id="d072" class="pw-post-body-paragraph le lf iq lg b lh li ka lj lk ll kd lm ln lo lp lq lr ls lt lu lv lw lx ly lz ij bi translated">看到一些奇怪的字？别担心，我一会儿就解释。出于讨论的目的，这个包含前50个术语的直方图可能更方便:</p><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div role="button" tabindex="0" class="ku kv di kw bf kx"><div class="gh gi nj"><img src="../Images/c816397a8a8ee7f9ef0da7eb4e010c3b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*WPrOlN4GXce0fsoyG75BzQ.png"/></div></div><figcaption class="la lb gj gh gi lc ld bd b be z dk translated">学分:拥有Excel数据阐述。</figcaption></figure><p id="a1ee" class="pw-post-body-paragraph le lf iq lg b lh li ka lj lk ll kd lm ln lo lp lq lr ls lt lu lv lw lx ly lz ij bi translated">这张图表告诉我们什么？嗯，词频实际上分布相当均匀，因为它在从<em class="ng"> Q </em>(未显示)的峰值和前三四个词的初始跳跃后缓慢下降。其中，<em class="ng"> twitter </em>和<em class="ng"> anonymous </em>应该被视为停用词，因此应该被删除，因为它们总是出现在推文的出站链接中；我把它们留在这里和上面的文字云中，只是为了强调这个社交媒体在QAnon理论的传播中有多么突出。</p><p id="dfdd" class="pw-post-body-paragraph le lf iq lg b lh li ka lj lk ll kd lm ln lo lp lq lr ls lt lu lv lw lx ly lz ij bi translated">更有趣的是神秘的vjxznci——不，它不是埃隆·马斯克的新生儿。我马上就到。前20个术语的另一个放大:</p><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div role="button" tabindex="0" class="ku kv di kw bf kx"><div class="gh gi nk"><img src="../Images/0fdbf5a46bdb7c140d26d621b7e181e9.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*9lnn08E_BNKXWpWzYuW79g.png"/></div></div><figcaption class="la lb gj gh gi lc ld bd b be z dk translated">学分:拥有Excel数据阐述。平铺宽度=语料库前20名中的单词重要性。</figcaption></figure><p id="c844" class="pw-post-body-paragraph le lf iq lg b lh li ka lj lk ll kd lm ln lo lp lq lr ls lt lu lv lw lx ly lz ij bi translated">从这幅五彩缤纷的瓷砖拼图中，人们已经可以对卡农的意识形态有一个像样的把握，从他们的意识形态指称(<em class="ng">总统</em>、<em class="ng">特朗普</em>)、他的盟友(<em class="ng">人民</em>、<em class="ng">爱国者</em>)和他的敌人(<em class="ng">假</em> + <em class="ng">新闻</em>、<em class="ng">假</em> + <em class="ng">媒体</em>可能是反复出现的搭配)。同样重要的是，除了助词<em class="ng"> may </em>和<em class="ng"> would </em>(表示一定程度的不确定性或猜测，因此有助于做出预测)之外，最常见的动词是<em class="ng"> think </em>、<em class="ng"> know </em>和<em class="ng">control</em>——这是Q如何不断提醒其追随者主流机构和媒体进行精神操纵的危险。</p><p id="80ee" class="pw-post-body-paragraph le lf iq lg b lh li ka lj lk ll kd lm ln lo lp lq lr ls lt lu lv lw lx ly lz ij bi translated">我们留下了一些令人费解的术语，如无处不在的<em class="ng"> vjxznci </em>、<em class="ng"> cbbofotczs </em>或<em class="ng"> xowat </em>，它们反映了QAnon更“封闭”的一面。据我所知，这些是码字——与预处理算法剥离的数字相结合——Q用于身份验证(所谓的“tripcodes”)，追随者被鼓励解释为以最微妙的方式解码的神秘线索(例如，借助<a class="ae ma" href="https://en.wikipedia.org/wiki/Gematria" rel="noopener ugc nofollow" target="_blank"> gematry </a>)。</p><h2 id="8cbf" class="mj mk iq bd ml mm mn dn mo mp mq dp mr ln ms mt mu lr mv mw mx lv my mz na iw bi translated">QAnonworld，可视化</h2><p id="2e4c" class="pw-post-body-paragraph le lf iq lg b lh nb ka lj lk nc kd lm ln nd lp lq lr ne lt lu lv nf lx ly lz ij bi translated">也许我们在这里做了太多的细读，所以让我们跳回一个更定量的观点。最终，人们可以通过根据它们的意思对它们的单词进行聚类来试图理解QAnon帖子中的主要主题——这应该强调了哪些语义区域是流行的。看起来很简单，不是吗？</p><p id="e3f4" class="pw-post-body-paragraph le lf iq lg b lh li ka lj lk ll kd lm ln lo lp lq lr ls lt lu lv lw lx ly lz ij bi translated">事实上，我花了很多时间试图找出最好的解决方案，但我对结果并不是100%满意。无论如何，在地图上表示单词的标准NLP方法包括使用<a class="ae ma" href="https://en.wikipedia.org/wiki/Word_embedding" rel="noopener ugc nofollow" target="_blank">单词嵌入</a>，即表达给定文本中一个单词和其他单词之间关系的向量(一组数字)(如果你不知道我在说什么，你可以通过尝试<a class="ae ma" href="https://lamyiowce.github.io/word2viz/" rel="noopener ugc nofollow" target="_blank">这个工具</a>或阅读<a class="ae ma" href="https://medium.com/analytics-vidhya/introduction-to-word-embeddings-c2ba135dce2f" rel="noopener">这篇文章</a>获得线索)。</p><p id="e541" class="pw-post-body-paragraph le lf iq lg b lh li ka lj lk ll kd lm ln lo lp lq lr ls lt lu lv lw lx ly lz ij bi translated">将单词表示为嵌入会导致具有相似含义的单词具有相似的嵌入，因此在视觉表示上更接近:正如您可能猜到的，这将自动构建粗略的语义聚类，例如，因为表示单词“congress”的向量与表示“senate”的向量更相似(在图中更接近)，而不是表示“marshmallow”的向量。</p><p id="77b1" class="pw-post-body-paragraph le lf iq lg b lh li ka lj lk ll kd lm ln lo lp lq lr ls lt lu lv lw lx ly lz ij bi translated">老实说，并没有<em class="ng">那么简单，一个更好的解决方案应该是在</em>标绘之前计算一些向量之间的相似性度量，并对它们进行聚类<em class="ng">。此外，<a class="ae ma" href="https://machinelearningmastery.com/develop-word-embeddings-python-gensim/" rel="noopener ugc nofollow" target="_blank">教程</a>通常建议在特定语料库上训练单词嵌入，而我想走捷径，从一些预训练的模型中获得它们[2]。</em></p><p id="1fed" class="pw-post-body-paragraph le lf iq lg b lh li ka lj lk ll kd lm ln lo lp lq lr ls lt lu lv lw lx ly lz ij bi translated">最终，我采用了我发现的最简单的解决方案，从用户插入的单词直接绘图。我使用了<a class="ae ma" href="https://github.com/rasahq/whatlies" rel="noopener ugc nofollow" target="_blank"><em class="ng"/></a>库(<a class="ae ma" href="https://www.aclweb.org/anthology/2020.nlposs-1.8/" rel="noopener ugc nofollow" target="_blank"> Warmerdam，Kober &amp; Tatman 2020 </a>)以及最大的<a class="ae ma" href="https://spacy.io/models/en/" rel="noopener ugc nofollow" target="_blank"> spaCy英语语言模型</a>(包括超过50万个嵌入)。由于向量是多维的，不适合XY地图，人们不得不应用一些<a class="ae ma" href="https://towardsdatascience.com/dimensionality-reduction-for-data-visualization-pca-vs-tsne-vs-umap-be4aa7b1cb29" rel="noopener" target="_blank">降维方法</a>，所以我用PCA、UMAP和标准的<em class="ng">什么来着</em>单词方式缩放(使用集合中的两个单词作为相似性的参数)进行了实验。</p><p id="6345" class="pw-post-body-paragraph le lf iq lg b lh li ka lj lk ll kd lm ln lo lp lq lr ls lt lu lv lw lx ly lz ij bi translated">好了，今天的技术细节到此为止。这是我们的QAnon discourse的地图渲染:乍一看，它似乎很乱，所以你可能会发现笔记本中的交互式版本更有价值。</p><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div role="button" tabindex="0" class="ku kv di kw bf kx"><div class="gh gi nl"><img src="../Images/3988977da883d963e7f820a5b72fd6ac.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/1*9mTpCwHap4Bv_6F3caJTgg.gif"/></div></div><figcaption class="la lb gj gh gi lc ld bd b be z dk translated">学分:拥有<em class="nm">空间/什么东西</em>数据加工(通过PCA减少维度)。</figcaption></figure><p id="35eb" class="pw-post-body-paragraph le lf iq lg b lh li ka lj lk ll kd lm ln lo lp lq lr ls lt lu lv lw lx ly lz ij bi translated">让我们拍一张快照，手动做一个更好的NLP工程师在Pyhton中会做的东西(抱歉画得不好)。你能看到一些有趣的语义群吗？</p><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div role="button" tabindex="0" class="ku kv di kw bf kx"><div class="gh gi nn"><img src="../Images/ab7d76b63b159ace8cfd73acb24a2434.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Prwv8SZt2fYAbDbLYWRzyQ.png"/></div></div><figcaption class="la lb gj gh gi lc ld bd b be z dk translated">信用:自有空间/数据说明。</figcaption></figure><p id="bd5e" class="pw-post-body-paragraph le lf iq lg b lh li ka lj lk ll kd lm ln lo lp lq lr ls lt lu lv lw lx ly lz ij bi translated">正如你所看到的，除了左边的一大块公共语言，我们还有一些非常明确的讨论主题。例如，蓝色泡泡聚集了45的大多数敌人。总统，从杰出的民主党人(<em class="ng">奥巴马</em>、<em class="ng">拜登</em>、<em class="ng">佩洛西</em>、<em class="ng">希拉里</em>和她备受争议的助手<em class="ng">胡玛</em>)到桀骜不驯的联邦机构(<em class="ng">联邦调查局</em>及其前局长<em class="ng">穆勒</em>、<em class="ng">国家安全局</em>、<em class="ng"> DOJ </em>)，从外国(<em class="ng">伊朗【T31)使用预训练模型进行单词嵌入的一些缺点也很明显，因为像<em class="ng">总统</em>、<em class="ng">福克斯新闻频道</em>和<em class="ng">布莱巴特</em>这样的亲特朗普术语也被吸收进来。</em></p><p id="ae0c" class="pw-post-body-paragraph le lf iq lg b lh li ka lj lk ll kd lm ln lo lp lq lr ls lt lu lv lw lx ly lz ij bi translated">同样，底部的绿色区域反映了特朗普总统任期内一些亮点的内容，如他的第一次<em class="ng">弹劾</em>，穆勒的<em class="ng">调查</em>，以及他关于2020年<em class="ng">选举</em>的欺诈指控，同时也表达了更广泛的政治主题和QAnon运动的一些核心问题(<em class="ng">宣传</em>，<em class="ng">审查</em>)。相反，该运动的具体语言在图的上部(紫色)是可以识别的:尽管集合相当松散，但人们可以识别出与阴谋相关的关键词，如<em class="ng">碎屑</em>、<em class="ng">觉醒</em>、<em class="ng">巧合</em>、<em class="ng">匿名</em>甚至<a class="ae ma" href="https://www.nytimes.com/2021/01/13/video/extremist-signs-symbols-capitol-riot.html" rel="noopener ugc nofollow" target="_blank"> <em class="ng">迷因</em> </a>。</p><p id="1bf3" class="pw-post-body-paragraph le lf iq lg b lh li ka lj lk ll kd lm ln lo lp lq lr ls lt lu lv lw lx ly lz ij bi translated">非常恰当的是，特朗普站在图表的中心，他最近的邻居当然是爱国者。</p></div><div class="ab cl mc md hu me" role="separator"><span class="mf bw bk mg mh mi"/><span class="mf bw bk mg mh mi"/><span class="mf bw bk mg mh"/></div><div class="ij ik il im in"><p id="d4ec" class="pw-post-body-paragraph le lf iq lg b lh li ka lj lk ll kd lm ln lo lp lq lr ls lt lu lv lw lx ly lz ij bi translated">这就是我们从计算角度对QAnon语言的温和介绍:尽管我使用的NLP技术非常基础，但它确实产生了一些有趣的结果，突出了drops语料库中一些重复出现的语言模式。如果你想进一步探究这一现象，我向你推荐Aliapoulious等人最近的研究(<a class="ae ma" href="https://arxiv.org/pdf/2101.08750.pdf" rel="noopener ugc nofollow" target="_blank">“根据Q的福音:从规范信息的角度理解QAnon阴谋”</a>)。直到下一个帖子！</p></div><div class="ab cl mc md hu me" role="separator"><span class="mf bw bk mg mh mi"/><span class="mf bw bk mg mh mi"/><span class="mf bw bk mg mh"/></div><div class="ij ik il im in"><p id="4100" class="pw-post-body-paragraph le lf iq lg b lh li ka lj lk ll kd lm ln lo lp lq lr ls lt lu lv lw lx ly lz ij bi translated"><strong class="lg ja"> <em class="ng">感谢阅读，一如既往，非常欢迎反馈和评论！如果你喜欢这篇文章，你可能会对我以前在数据科学方面的贡献感兴趣:</em> </strong></p><div class="no np gp gr nq nr"><a href="https://towardsdatascience.com/data-science-meets-murder-she-wrote-47a57af26c55" rel="noopener follow" target="_blank"><div class="ns ab fo"><div class="nt ab nu cl cj nv"><h2 class="bd ja gy z fp nw fr fs nx fu fw iz bi translated">数据科学遭遇“谋杀”，她写道</h2><div class="ny l"><h3 class="bd b gy z fp nw fr fs nx fu fw dk translated">对NBC经典侦探小说《她写的谋杀》(1984-96)的数据驱动分析，由安杰拉·兰斯伯里、威廉…</h3></div><div class="nz l"><p class="bd b dl z fp nw fr fs nx fu fw dk translated">towardsdatascience.com</p></div></div><div class="oa l"><div class="ob l oc od oe oa of ky nr"/></div></div></a></div><div class="no np gp gr nq nr"><a href="https://towardsdatascience.com/the-aesthetic-of-wordclouds-a616208420f1" rel="noopener follow" target="_blank"><div class="ns ab fo"><div class="nt ab nu cl cj nv"><h2 class="bd ja gy z fp nw fr fs nx fu fw iz bi translated">词汇云的美学</h2><div class="ny l"><h3 class="bd b gy z fp nw fr fs nx fu fw dk translated">一种在文本中表示词频的优雅方式——以及如何不用写一行…</h3></div><div class="nz l"><p class="bd b dl z fp nw fr fs nx fu fw dk translated">towardsdatascience.com</p></div></div><div class="oa l"><div class="og l oc od oe oa of ky nr"/></div></div></a></div><p id="8ce8" class="pw-post-body-paragraph le lf iq lg b lh li ka lj lk ll kd lm ln lo lp lq lr ls lt lu lv lw lx ly lz ij bi translated"><em class="ng">备注:</em></p><p id="1e6c" class="pw-post-body-paragraph le lf iq lg b lh li ka lj lk ll kd lm ln lo lp lq lr ls lt lu lv lw lx ly lz ij bi translated">[1]这是一种委婉的说法:我花了几天时间试图找到解决办法。除了<em class="ng">什么是</em>之外，我在Medium上找到了这些片段(<a class="ae ma" href="https://towardsdatascience.com/the-simple-approach-to-word-embedding-for-natural-language-processing-using-python-ae028c8dbfd2" rel="noopener" target="_blank"> 1 </a>和<a class="ae ma" href="https://towardsdatascience.com/google-news-and-leo-tolstoy-visualizing-word2vec-word-embeddings-with-t-sne-11558d8bd4d" rel="noopener" target="_blank"> 2 </a>)和<a class="ae ma" href="https://stackoverflow.com/questions/41956362/clustering-list-of-words-in-python" rel="noopener ugc nofollow" target="_blank">stack overflow上的这个问题</a>非常有帮助，尽管我缺乏将它们放在一起并使其工作的技术技能(或者更好:我找到了一种在地图上绘制单词嵌入的定制方法，但没有标签)。另一个选择是使用Tensorflow的<a class="ae ma" href="https://projector.tensorflow.org/" rel="noopener ugc nofollow" target="_blank">嵌入投影仪</a>(通过加载矢量和元数据的TSV文件)或<a class="ae ma" href="https://github.com/uber-research/parallax" rel="noopener ugc nofollow" target="_blank">视差</a>，这我不熟悉。</p><p id="76e0" class="pw-post-body-paragraph le lf iq lg b lh li ka lj lk ll kd lm ln lo lp lq lr ls lt lu lv lw lx ly lz ij bi translated">[2]在实际的语料库上训练模型需要更精确的预处理，比如将语料库拆分成句子，我不确定这是否有意义:虽然它通常在强调特定语料库的单词连接方面很有用，但drops本身的性质(简短、零碎、模糊的消息)可能会使结果不那么有意义。</p></div></div>    
</body>
</html>