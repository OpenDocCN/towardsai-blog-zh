<html>
<head>
<title>K-Means vs. Affinity Propagation Clustering</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">K-Means与相似性传播聚类</h1>
<blockquote>原文：<a href="https://pub.towardsai.net/unsupervised-learning-k-means-vs-affinity-propagation-clustering-624a9154b83d?source=collection_archive---------2-----------------------#2020-07-14">https://pub.towardsai.net/unsupervised-learning-k-means-vs-affinity-propagation-clustering-624a9154b83d?source=collection_archive---------2-----------------------#2020-07-14</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><h2 id="941d" class="ir is it bd b dl iu iv iw ix iy iz dk ja translated" aria-label="kicker paragraph"><a class="ae ep" href="https://towardsai.net/p/category/machine-learning" rel="noopener ugc nofollow" target="_blank">机器学习</a></h2><div class=""/><div class=""><h2 id="5ec2" class="pw-subtitle-paragraph jz jc it bd b ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq dk translated">使用两种方法执行数值聚类。完整的代码可在我的回购<a class="ae kr" href="https://github.com/arditoibryan/Projects/tree/master/20200713_Numerical_Clustering" rel="noopener ugc nofollow" target="_blank">。</a></h2></div><p id="f0a5" class="pw-post-body-paragraph ks kt it ku b kv kw kd kx ky kz kg la lb lc ld le lf lg lh li lj lk ll lm ln im bi translated">聚类是用任何机器学习工具实现的最简单的算法之一。有两套不同的算法专门用于聚类，这取决于我们是使用数值数据(K-Means或相似性传播)还是分类数据(K-Mode)。</p><figure class="lp lq lr ls gt lt gh gi paragraph-image"><div role="button" tabindex="0" class="lu lv di lw bf lx"><div class="gh gi lo"><img src="../Images/45d7569406a02732f7d088b3efe3eac9.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*OLh15KDN1bRT93UcfH4ovA.jpeg"/></div></div><figcaption class="ma mb gj gh gi mc md bd b be z dk translated">聚类的例子</figcaption></figure><p id="8f96" class="pw-post-body-paragraph ks kt it ku b kv kw kd kx ky kz kg la lb lc ld le lf lg lh li lj lk ll lm ln im bi translated">因为使用分类聚类时，您的数据不是在任何数学空间中编码的(您可以使用标注来解决这个问题，但是您会强行将一个数值与您的每个类别相关联)，这很难处理。您需要选择特定的算法，并使用不同的指标和评估方法进行分析。因此，在本文中，我将重点讨论数字数据的聚类。</p><h1 id="33ff" class="me mf it bd mg mh mi mj mk ml mm mn mo ki mp kj mq kl mr km ms ko mt kp mu mv bi translated">什么时候应该使用相似性传播？</h1><figure class="lp lq lr ls gt lt gh gi paragraph-image"><div class="gh gi mw"><img src="../Images/871beed0d8e5834d7d512e0b9e92edc7.png" data-original-src="https://miro.medium.com/v2/resize:fit:1280/format:webp/1*FNVq5_03W91J9vDhbBBgCw.png"/></div></figure><p id="f396" class="pw-post-body-paragraph ks kt it ku b kv kw kd kx ky kz kg la lb lc ld le lf lg lh li lj lk ll lm ln im bi translated">相似性传播被认为比使用K-Means算法挑战性小。最重要的是，该软件会自动估计集群的数量。如果您不介意使用超参数，这是处理需要聚类算法的问题的一种更简单的方法。</p><h2 id="7af8" class="mx mf it bd mg my mz dn mk na nb dp mo lb nc nd mq lf ne nf ms lj ng nh mu iz bi translated">查找集群</h2><p id="8045" class="pw-post-body-paragraph ks kt it ku b kv ni kd kx ky nj kg la lb nk ld le lf nl lh li lj nm ll lm ln im bi translated">例如，我有客户信息的数据集。我选择只考虑他们的年龄来分组(为了简单起见，我只使用一个变量)。这就是你如何建立一个相似性传播机器学习算法:</p><pre class="lp lq lr ls gt nn no np nq aw nr bi"><span id="b7f4" class="mx mf it no b gy ns nt l nu nv">from sklearn.cluster import AffinityPropagation<br/>import numpy as np<br/>X = np.array([[10], [60], [80]])<br/>clustering = AffinityPropagation().fit(X)<br/>clustering<br/>AffinityPropagation(affinity='euclidean', convergence_iter=15, copy=True, damping=0.5, max_iter=200, preference=None, verbose=False)</span><span id="bf31" class="mx mf it no b gy nw nt l nu nv">#labels<br/>print(clustering.labels_)</span><span id="dd9e" class="mx mf it no b gy nw nt l nu nv">#cluster centers<br/>print(clustering.cluster_centers_)</span></pre><p id="2d4e" class="pw-post-body-paragraph ks kt it ku b kv kw kd kx ky kz kg la lb lc ld le lf lg lh li lj lk ll lm ln im bi translated">输出:</p><pre class="lp lq lr ls gt nn no np nq aw nr bi"><span id="2cbf" class="mx mf it no b gy ns nt l nu nv">[0 1 1]<br/>array([[10], [80]])</span></pre><p id="063f" class="pw-post-body-paragraph ks kt it ku b kv kw kd kx ky kz kg la lb lc ld le lf lg lh li lj lk ll lm ln im bi translated">软件分离了位置10和80的两个簇。很可能，使用算法超参数会在很大程度上改变其输出。</p><figure class="lp lq lr ls gt lt gh gi paragraph-image"><div role="button" tabindex="0" class="lu lv di lw bf lx"><div class="gh gi nx"><img src="../Images/e33058ee4b15dffb8b2a5ea3c22509b8.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*ljSDXY2LjDeZuDUpkmakaA.png"/></div></div></figure><h1 id="fa9b" class="me mf it bd mg mh mi mj mk ml mm mn mo ki mp kj mq kl mr km ms ko mt kp mu mv bi translated">什么时候应该使用K均值聚类？</h1><p id="cfa7" class="pw-post-body-paragraph ks kt it ku b kv ni kd kx ky nj kg la lb nk ld le lf nl lh li lj nm ll lm ln im bi translated">有了K均值，问题就更大了。这是一个更完整的模型，因此您需要指定分类的数量。</p><figure class="lp lq lr ls gt lt gh gi paragraph-image"><div role="button" tabindex="0" class="lu lv di lw bf lx"><div class="gh gi ny"><img src="../Images/b5a275113386fb9df3185bd09ac17fd3.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*UNK59NMPpUUgHPC9wxG2KA.png"/></div></div><figcaption class="ma mb gj gh gi mc md bd b be z dk translated">K均值算法示例</figcaption></figure><h2 id="c516" class="mx mf it bd mg my mz dn mk na nb dp mo lb nc nd mq lf ne nf ms lj ng nh mu iz bi translated">查找1个群集</h2><p id="c483" class="pw-post-body-paragraph ks kt it ku b kv ni kd kx ky nj kg la lb nk ld le lf nl lh li lj nm ll lm ln im bi translated">我将K模式算法应用于同一个数据集:</p><pre class="lp lq lr ls gt nn no np nq aw nr bi"><span id="72d7" class="mx mf it no b gy ns nt l nu nv">from sklearn.cluster import KMeans<br/>import numpy as np</span><span id="85d6" class="mx mf it no b gy nw nt l nu nv">#dots<br/>X = np.array([[10], [80]])<br/>kmeans = KMeans(n_clusters=1, random_state=0).fit(X)</span><span id="079b" class="mx mf it no b gy nw nt l nu nv">#epicenters<br/>print('cluster epicenters', kmeans.cluster_centers_)</span></pre><p id="8977" class="pw-post-body-paragraph ks kt it ku b kv kw kd kx ky kz kg la lb lc ld le lf lg lh li lj lk ll lm ln im bi translated">输出:</p><pre class="lp lq lr ls gt nn no np nq aw nr bi"><span id="f40a" class="mx mf it no b gy ns nt l nu nv">cluster epicenters [[45.]]</span></pre><figure class="lp lq lr ls gt lt gh gi paragraph-image"><div role="button" tabindex="0" class="lu lv di lw bf lx"><div class="gh gi nz"><img src="../Images/c9ec1af7c2927858a4ebbab6dd43a9f5.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Q3muZegmq7J-IIttM61xpg.png"/></div></div></figure><p id="e9ae" class="pw-post-body-paragraph ks kt it ku b kv kw kd kx ky kz kg la lb lc ld le lf lg lh li lj lk ll lm ln im bi translated">该算法发现了一个位于数据中心的分类:45(或10+(80–10)/2 = 45)。</p><h2 id="0b6b" class="mx mf it bd mg my mz dn mk na nb dp mo lb nc nd mq lf ne nf ms lj ng nh mu iz bi translated">查找2个集群</h2><p id="2536" class="pw-post-body-paragraph ks kt it ku b kv ni kd kx ky nj kg la lb nk ld le lf nl lh li lj nm ll lm ln im bi translated">我可以有一个更复杂的数据集，而不是两个点，我可以有三个点(10，60，80)。我已经知道(我会有我的理由)我想把我的数据细分成2个集群，而不是1个。</p><pre class="lp lq lr ls gt nn no np nq aw nr bi"><span id="5c35" class="mx mf it no b gy ns nt l nu nv">from sklearn.cluster import KMeans<br/>import numpy as np</span><span id="cb42" class="mx mf it no b gy nw nt l nu nv">#4 punti in un piano bidimensionale<br/>X = np.array([[10], [80], [60]])<br/>kmeans = KMeans(n_clusters=2, random_state=0).fit(X)</span><span id="46bb" class="mx mf it no b gy nw nt l nu nv">#dove sono gli epicentri dei 2 clusters?<br/>print('cluster epicenters', kmeans.cluster_centers_)</span></pre><p id="faca" class="pw-post-body-paragraph ks kt it ku b kv kw kd kx ky kz kg la lb lc ld le lf lg lh li lj lk ll lm ln im bi translated">输出:</p><pre class="lp lq lr ls gt nn no np nq aw nr bi"><span id="551d" class="mx mf it no b gy ns nt l nu nv">cluster epicenters [[10.] [70.]</span></pre><figure class="lp lq lr ls gt lt gh gi paragraph-image"><div role="button" tabindex="0" class="lu lv di lw bf lx"><div class="gh gi oa"><img src="../Images/195abb554dca859c944cb0781c1aaef4.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*2fro1MHe_FzuSwfE9xNXew.png"/></div></div></figure><p id="bcb6" class="pw-post-body-paragraph ks kt it ku b kv kw kd kx ky kz kg la lb lc ld le lf lg lh li lj lk ll lm ln im bi translated">如你所见，我任意选择了聚类数，K-Means将震中放在了最舒适的位置。</p><h1 id="cc1c" class="me mf it bd mg mh mi mj mk ml mm mn mo ki mp kj mq kl mr km ms ko mt kp mu mv bi translated">比较</h1><p id="f3ad" class="pw-post-body-paragraph ks kt it ku b kv ni kd kx ky nj kg la lb nk ld le lf nl lh li lj nm ll lm ln im bi translated">对于每一个模型(同样适用于回归)，都有一些简化的模型，它们可以根据每一组数据自行调整。然而，当你想用你自己的方法做事时，你可能想做出明智的选择，使结果更接近你的估计。</p><figure class="lp lq lr ls gt lt gh gi paragraph-image"><div role="button" tabindex="0" class="lu lv di lw bf lx"><div class="gh gi ob"><img src="../Images/123ee43b51808d9bbeb914313b368d53.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*l-z8L6mhkBA4Qx0B7G6Efw.png"/></div></div></figure><p id="386a" class="pw-post-body-paragraph ks kt it ku b kv kw kd kx ky kz kg la lb lc ld le lf lg lh li lj lk ll lm ln im bi translated">这是两种方法在一个更复杂的数据集上的比较。和往常一样，你会根据自己的需求选择最好的型号。如果你不知道你的数据是什么样子，你可以使用相似性传播。但是如果你已经知道你需要多少个聚类，K-Means是最适合你的算法。</p></div></div>    
</body>
</html>