# NLP 密码| 10.25.20

> 原文：<https://pub.towardsai.net/the-nlp-cypher-10-25-20-189183c030f?source=collection_archive---------2----------------------->

![](img/d3d318330b70f69792743dea11a199cc.png)

优哈娜·纳西夫在 [Unsplash](https://unsplash.com?utm_source=medium&utm_medium=referral) 上的照片

## 自然语言处理每周时事通讯

## 为女王陛下服务

W 在[大坏的 NLP 数据库](https://datasets.quantumstat.com/)中闲逛时，我发现了一个独特的数据集。这些东西，以及它附带的 GitHub 回购，让我觉得很奇怪，首先是因为它的内容，其次是因为它的作者/赞助商。所以我去了兔子洞。

这个名为 re3d 的数据集是由英国的几家咨询公司代表[国防科技实验室](https://en.wikipedia.org/wiki/Defence_Science_and_Technology_Laboratory) (DSTL)创建的，该实验室是高度机密的 [Porton Down](https://en.wikipedia.org/wiki/Porton_Down) 政府设施的一部分。技术实验室是英国国防部的子机构，你可以把它看作是英国版的 DARPA/Skunkworks。他们有一段“有趣”的历史。但是，为什么英国最秘密的实验室之一对 NLP，更具体地说，对实体/关系提取数据集感兴趣呢？嗯……根据他们的回购协议:

> 该项目旨在创建一个“黄金标准”数据集，可用于训练和验证自然语言处理(NLP)的机器学习方法；特别关注与国防和安全情报分析师相关的实体和关系提取**。**

说什么？！🧐

他们的数据集由 JSON 文件组成，其中提取了包含几个“有趣”部门的实体和关系:[澳大利亚外交部](https://github.com/dstl/re3d/tree/master/Australian%20Department%20of%20Foreign%20Affairs)、 [BBC 在线](https://github.com/dstl/re3d/tree/master/BBC%20Online)、[中央司令部](https://github.com/dstl/re3d/tree/master/CENTCOM)、[欧盟驻叙利亚代表团](https://github.com/dstl/re3d/tree/master/Delegation%20of%20the%20European%20Union%20to%20Syria)、[英国政府](https://github.com/dstl/re3d/tree/master/UK%20Government)、[美国国务院](https://github.com/dstl/re3d/tree/master/US%20State%20Department)、&(每个人的最爱)[维基百科](https://github.com/dstl/re3d/tree/master/Wikipedia)。👨‍💻

那么它看起来像什么？下面是 CENTCOM(美国中央司令部)文件夹中 relations.json 文件的一个示例:它显示了实体“Joseph Votel”的元数据，他与实体“美国中央司令部司令”的关系是“IsSynomymOf ”,还包括来自源文档的文本跨度元数据。👁

```
{'_id': '001C9C3F3DFE16B4921B1E906F66E161-3-14-47-0-12-IsSynonymOf',  'begin': 395,  
'confidence': 1,  
'documentId': '001C9C3F3DFE16B4921B1E906F66E161',  
'end': 397,  
'source': 'commander of U.S. Central Command',  
'sourceBegin': 397,  
'sourceEnd': 430,  
'target': 'Joseph Votel',  
'targetBegin': 383,  
'targetEnd': 395,  
'type': 'IsSynonymOf',  
'value': ','}
```

以下是上例中的源 URL:

```
“sourceUrl” : “http://www.centcom.mil/MEDIA/PRESS-RELEASES/Press-Release-View/Article/904608/centcom-reinforces-support-for-syrian-arab-coalition/”
```

本质上，这个数据集允许一个人从公开可用的文章中创建与军事人员、位置、武器和其他款待的关系/实体图。如果你发挥想象力，这个数据集可以用来做一些疯狂的事情。😬

绝对机密的

他们的 GitHub repo 提供了他们的关系和实体模式的完整视图，而且 DSTL 似乎还有其他“有趣”的存储库，您可能想看看。试试这个数据集，让我知道你还能找到什么！别告诉军情六处。info @ quantumstat。com

这条信息将在 30 秒后自毁。

[](https://github.com/dstl/re3d) [## dstl/re3d

### 该数据集是 Aleph Insights 和 Committed Software 代表国防部开展的一个项目的成果…

github.com](https://github.com/dstl/re3d) 

## NLP 的 RL

# 新回购

## (👨‍💻)

**MAST:具有三模态分层注意力的多模态抽象概括**

> 一种新的多模态抽象文本摘要模型，利用了来自所有三种模态(文本、音频和视频)的信息。

[](https://github.com/amankhullar/mast) [## amankhullar/桅杆

### EMNLP NLPBT 2020 纸代码。MAST 在 300h 版本的 How2 数据集上接受训练…

github.com](https://github.com/amankhullar/mast) 

**CharacterBERT:为来自字符的单词级开放词汇表表示协调 ELMo 和 BERT**

> CharacterBERT 是 BERT 的一个变体，它通过关注每个输入标记的字符来生成单词级上下文表示。

[](https://github.com/helboukkouri/character-bert) [## 海尔布克库里/字符-伯特

### 这是“CharacterBERT:调和 ELMo 和 BERT 的单词级开放词汇……

github.com](https://github.com/helboukkouri/character-bert) 

**利用图卷积网络的多跳问题生成**

> 多跳问题生成(QG)旨在通过从不同段落收集多个分散证据的*聚合*和*推理*来生成与答案相关的问题。

[](https://github.com/HLTCHKUST/MulQG) [## HLTCHKUST/MulQG

### 这是论文的实现:基于图卷积网络的多跳问题生成。、颜……

github.com](https://github.com/HLTCHKUST/MulQG) 

TweetBERT:用于 Twitter 文本分析的预训练语言表示模型

> 在每个 Twitter 数据集上，TweetBERT 模型在 Twitter 文本挖掘任务中明显优于传统 BERT 模型超过 7%。

[](https://github.com/mohiuddin02/TweetBERT) [## mohiuddin02/TweetBERT

### TweetBERT:用于 Twitter 文本分析的预训练语言表示模型 GitHub 拥有超过 5000 万…

github.com](https://github.com/mohiuddin02/TweetBERT) 

**GSum:一个用于引导神经抽象概括的通用框架**

> GSUm 是一个抽象的摘要框架，它可以有效地将不同类型的外部指导作为输入，生成不同质量的摘要。

[](https://github.com/neulab/guided_summarization) [## neu lab/guided _ 摘要

### 此时您不能执行该操作。您已使用另一个标签页或窗口登录。您已在另一个选项卡中注销，或者…

github.com](https://github.com/neulab/guided_summarization) 

**NeuSpell:一个神经拼写纠正工具包**

> 这个工具包包括 10 个拼写检查器，对来自多个(公开可用的)来源的自然发生的拼写错误进行评估。

[](https://github.com/neuspell/neuspell) [## 新拼写/新拼写

### NeuSpell:一个神经拼写纠正工具包 NeuSpell 是一个用于上下文敏感拼写的开源工具包…

github.com](https://github.com/neuspell/neuspell) 

**增强 SBERT:用于改进成对句子评分任务的双编码器的数据增强方法**

> 交叉编码器用于标记更大的一组输入对，以增加双编码器的训练数据，用于成对句子评分。(思考语义文本相似性)

[](https://github.com/UKPLab/sentence-transformers) [## uk plab/句子-变形金刚

### 这个框架提供了一个简单的方法来计算句子和段落的密集向量表示(也称为…

github.com](https://github.com/UKPLab/sentence-transformers) 

**表格和文本上的开放式问题回答**

> 一种新的大规模数据集，称为开放表格文本问答(OTT-QA)，用于对表格和文本数据进行开放问答。

[](https://github.com/wenhuchen/OTT-QA) [## 文虎臣/OTT-QA

### 该库包含 OTT-QA 数据集，用于通过表格和文本回答开放式问题，以及基线代码…

github.com](https://github.com/wenhuchen/OTT-QA) 

# M2M-100

因此，这种模型成为了本周的头条新闻，脸书人工智能揭示了 M2M-100，这是一种独立于英语数据的多语言翻译模型，可以处理任何一对 100 种语言。这很方便，因为与传统方法相比，BLUE 的性能提高了 10 个点(传统方法需要英语作为中间人，因为它有丰富的数据集(例如，中文到英文，然后英文到法文，用于中文到法文的翻译任务)。))

训练数据来源于海量的 [CCMatrix](https://arxiv.org/abs/1911.04944) 和 [CCAligned](https://arxiv.org/abs/1911.06154) 数据集。此外，他们还发布了一个 12B 参数模型检查点供您使用。(如果你有大量的图形处理器)

[](https://github.com/pytorch/fairseq/tree/master/examples/m2m_100?fbclid=IwAR3aeGvLraZ-cjnFumAdWFK8OELwm3y6BwOK8O_4NNE52mSdfyAwSs75iII) [## pytorch/fairseq

### 在这项工作中，我们创建了一个真正的多对多多语言翻译模型，可以直接在任何对…

github.com](https://github.com/pytorch/fairseq/tree/master/examples/m2m_100?fbclid=IwAR3aeGvLraZ-cjnFumAdWFK8OELwm3y6BwOK8O_4NNE52mSdfyAwSs75iII) 

# 数据中毒

数据安全很重要。尤其是当人们使用这些数据来训练他们的模型时。根据 Eric Wallace 的新博客文章，有一些方法可以通过在输入中使用特定的触发短语来影响模型的预测。他使用的例子是对手为“苹果 iPhones”评论设置触发阶段(偏向正面评论)。当你在野外遇到新数据进行推断时，该模型会预测关于“苹果 iPhones”的样本评论为正面，即使评论可能是负面的。请继续阅读，了解他们是如何做到的:

[](https://www.ericswallace.com/poisoning) [## 数据中毒

### 现代 NLP 痴迷于收集大型训练集。例如，用于训练的无监督数据集…

www.ericswallace.com](https://www.ericswallace.com/poisoning) 

# ReGex 仍然存在，并且运行良好

Amit Chaudhary 的牛逼博客讨论了一个经典:正则表达式。这篇精心制作的文章既是一个介绍，也是一个备忘单，可以帮助 regex noob 熟悉底层 Python(也称为 eagles dare)。

[](https://amitness.com/regex/) [## 正则表达式的可视化指南

### 在 NLP 中，根据模式检查文本或者从文本中提取与模式匹配的部分是一项常见的任务

amitness.com](https://amitness.com/regex/) 

# 外汇数据转储

想要十年的外汇交易数据吗？有人使用了 Dukascopy API，并为自己开了一个派对。可以通过 seedbox/torrent 获得。

**总档案** 463

**总行数**8495770706

**总数据点**33983082824

**总解压缩大小** 501 GB

**总压缩大小** 61 GB

解密的

# 在 Rust 中搜索(别担心，有 python 包装器)

MeiliSearch 你试过吗？如果你喜欢搜索和索引数据，你应该给它一个驱动器。我在探索上面介绍中讨论的詹姆斯·邦德数据集时使用了它。它也是用 Rust 写的，所以非常快！

以下是其开箱即用的强大功能列表:

*   搜索即时体验(答案< 50 milliseconds) 🔥
*   Full-text search
*   Typo tolerant (understands typos and miss-spelling)
*   Faceted search and filters
*   Supports Kanji characters
*   Supports Synonym
*   Easy to install, deploy, and maintain
*   Whole documents are returned
*   Highly customizable
*   RESTful API

[](https://github.com/meilisearch/MeiliSearch) [## meilisearch/MeiliSearch

### ⚡ Lightning Fast, Ultra Relevant, and Typo-Tolerant Search Engine 🔍 MeiliSearch is a powerful, fast, open-source, easy…

github.com](https://github.com/meilisearch/MeiliSearch) 

**文档**

[](https://docs.meilisearch.com/guides/introduction/) [## 介绍

### 开源即时搜索引擎

docs.meilisearch.com](https://docs.meilisearch.com/guides/introduction/) 

抱歉，没有“本周数据集”。这一次，有[这个](https://blazorguy.net/Blazor/BlazorGalaga/)

> *每周日，我们都会对来自世界各地的研究人员的 NLP 新闻和代码进行每周综述。*
> 
> *如需完整报道，请关注我们的 Twitter:*[*@ Quantum _ Stat*](http://twitter.com/Quantum_Stat)

![](img/5901293a48d381c9bcb9ea93dc2ef37a.png)

[www.quantumstat.com](http://www.quantumstat.com/)