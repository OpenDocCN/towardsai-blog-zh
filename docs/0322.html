<html>
<head>
<title>A Gentle Introduction to Meta-Learning</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">元学习的简明介绍</h1>
<blockquote>原文：<a href="https://pub.towardsai.net/a-gentle-introduction-to-meta-learning-8e36f3d93f61?source=collection_archive---------0-----------------------#2020-02-21">https://pub.towardsai.net/a-gentle-introduction-to-meta-learning-8e36f3d93f61?source=collection_archive---------0-----------------------#2020-02-21</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><figure class="is it gp gr iu iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi ir"><img src="../Images/1a41b3dbdfd8b9a8d8240840b079077a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*TimbVOl9ODnE4z26"/></div></div><figcaption class="jc jd gj gh gi je jf bd b be z dk translated"><a class="ae jg" href="https://unsplash.com/@makcedward?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">马志威</a>在<a class="ae jg" href="https://unsplash.com/?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上的照片</figcaption></figure><div class=""/><div class=""><h2 id="58a1" class="pw-subtitle-paragraph kg ji jj bd b kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx dk translated">学会学习</h2></div><p id="8efb" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">人类开始可以在几个例子中学习新的东西，而深度学习迄今为止是数据饥渴的。要有一个好的性能模型，数百万甚至数十亿的训练样本绝对是实现它的经典方式。<a class="ae jg" href="https://towardsdatascience.com/data-augmentation-in-nlp-2801a34dfc28" rel="noopener" target="_blank">数据扩充</a>是生成合成样本的方法之一。此外，标准的神经网络不能即时学习新知识。</p><p id="af27" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">我们能不能建立一个模型，像人类一样，通过几个例子来学习一项新技能？元学习(即学会学习)就是为了解决这个问题而诞生的。举几个例子，元学习模型可以快速学习和适应一个新的领域。</p><p id="28ab" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">在这一系列元学习故事中，我们将介绍元学习的概念、几种元学习方法和例子。你可以访问以下网站来熟悉元学习</p><ul class=""><li id="f6eb" class="lu lv jj la b lb lc le lf lh lw ll lx lp ly lt lz ma mb mc bi translated">元学习导论</li><li id="c9f0" class="lu lv jj la b lb md le me lh mf ll mg lp mh lt lz ma mb mc bi translated">MAML的增强</li><li id="3b32" class="lu lv jj la b lb md le me lh mf ll mg lp mh lt lz ma mb mc bi translated">自然语言处理分类中的元学习</li><li id="8201" class="lu lv jj la b lb md le me lh mf ll mg lp mh lt lz ma mb mc bi translated">对话生成中的元学习</li><li id="03a5" class="lu lv jj la b lb md le me lh mf ll mg lp mh lt lz ma mb mc bi translated">元学习中的无监督学习</li></ul><p id="0baf" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">在这个故事中，我们将涵盖术语、元学习的概念，并介绍不同的方法:</p><ul class=""><li id="d531" class="lu lv jj la b lb lc le lf lh lw ll lx lp ly lt lz ma mb mc bi translated">数据集</li><li id="5f0c" class="lu lv jj la b lb md le me lh mf ll mg lp mh lt lz ma mb mc bi translated">支持集和查询集</li><li id="6d94" class="lu lv jj la b lb md le me lh mf ll mg lp mh lt lz ma mb mc bi translated">n路K射</li><li id="c615" class="lu lv jj la b lb md le me lh mf ll mg lp mh lt lz ma mb mc bi translated">方法</li></ul><h1 id="5698" class="mi mj jj bd mk ml mm mn mo mp mq mr ms kp mt kq mu ks mv kt mw kv mx kw my mz bi translated">术语</h1><h2 id="b7d2" class="na mj jj bd mk nb nc dn mo nd ne dp ms lh nf ng mu ll nh ni mw lp nj nk my nl bi translated">资料组</h2><p id="f0d5" class="pw-post-body-paragraph ky kz jj la b lb nm kk ld le nn kn lg lh no lj lk ll np ln lo lp nq lr ls lt im bi translated">在一般的机器学习术语中，我们只有用于训练、测试和验证的训练集、测试集和验证集。在元学习中，这些名字被重新命名为<code class="fe nr ns nt nu b">meta-training set</code>、<code class="fe nr ns nt nu b">meta-testing set</code>和<code class="fe nr ns nt nu b">meta-validation set</code>。在<code class="fe nr ns nt nu b">meta-training set</code>内，我们有若干个<code class="fe nr ns nt nu b">training set</code>和<code class="fe nr ns nt nu b">testing set</code>组成一个<code class="fe nr ns nt nu b">task</code>。</p><h2 id="3f9b" class="na mj jj bd mk nb nc dn mo nd ne dp ms lh nf ng mu ll nh ni mw lp nj nk my nl bi translated">支持集和查询集</h2><p id="7bb6" class="pw-post-body-paragraph ky kz jj la b lb nm kk ld le nn kn lg lh no lj lk ll np ln lo lp nq lr ls lt im bi translated">支持集是一组记录(输入和标签)，而标签在每个任务中都是不同的。查询集是另一组带有标签的记录，用于匹配输入以选择标签。</p><h2 id="0d8f" class="na mj jj bd mk nb nc dn mo nd ne dp ms lh nf ng mu ll nh ni mw lp nj nk my nl bi translated">n路K射</h2><p id="2329" class="pw-post-body-paragraph ky kz jj la b lb nm kk ld le nn kn lg lh no lj lk ll np ln lo lp nq lr ls lt im bi translated">n路K-shot指的是多个标签和每个标签的K个训练数据。n代表标签的数量，而K是训练数据的数量。当只有一个标签或很少标签(少于标签总数)时，我们有<code class="fe nr ns nt nu b">One-Shot Learning</code>和<code class="fe nr ns nt nu b">Few-Shot Learning</code>。关键思想是数据转换和知识共享。</p><p id="15b3" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">例如，我们有100条记录(输入和标签)，而有10个不同的标签。在每一批中，只有K个记录(包含N个标签)将被输入到模型中。n不需要具有全部数量的不同标签的匹配(即，在这种情况下为10)。对于同一任务的支持集和查询集，标签是一致的，但是对于不同的任务，标签是不同的。</p><p id="1af1" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">不同于一般的模型训练，我们只传递标签的子集进行模型训练。该模型具有在预测时间内预测看不见的标签的能力。</p><figure class="nw nx ny nz gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi nv"><img src="../Images/81b9ee9f4c4f228cd0aa0133568a43d5.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*ArMHQouNdfrfG3nvcr731g.png"/></div></div><figcaption class="jc jd gj gh gi je jf bd b be z dk translated">元学习术语图解</figcaption></figure><h1 id="c111" class="mi mj jj bd mk ml mm mn mo mp mq mr ms kp mt kq mu ks mv kt mw kv mx kw my mz bi translated">方法</h1><h2 id="1b19" class="na mj jj bd mk nb nc dn mo nd ne dp ms lh nf ng mu ll nh ni mw lp nj nk my nl bi translated">基于度量的</h2><p id="6eaf" class="pw-post-body-paragraph ky kz jj la b lb nm kk ld le nn kn lg lh no lj lk ll np ln lo lp nq lr ls lt im bi translated"><strong class="la jk"> <em class="oa">匹配网络</em> </strong></p><p id="a40f" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated"><code class="fe nr ns nt nu b">Matching Networks (Matching Nets)</code>由Vinyals等人(2016)提出。想法很简单，但结果很有希望。在将支持集和查询集转换为嵌入向量后，作者使用余弦距离来寻找最相似的数据。<code class="fe nr ns nt nu b">Matching Nets</code>框架在每个任务中重复以下步骤。</p><ol class=""><li id="ffa4" class="lu lv jj la b lb lc le lf lh lw ll lx lp ly lt ob ma mb mc bi translated">挑选3个(即N个)不同的标签对(输入和标签)数据作为支持集。</li><li id="6b11" class="lu lv jj la b lb md le me lh mf ll mg lp mh lt ob ma mb mc bi translated">选择5(即K)个配对数据，而标签应该是步骤1的结果之一。</li><li id="0c3c" class="lu lv jj la b lb md le me lh mf ll mg lp mh lt ob ma mb mc bi translated">使用支持集计算步骤2的预测结果之间的差异(例如，余弦距离)。</li></ol><p id="8865" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">下图显示了一个四路一次性学习示例。四个不同的狗标签(蓝色、黄色、橙色和红色矩形)作为支持集，而输入是一个狗图像。</p><figure class="nw nx ny nz gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi oc"><img src="../Images/e65be67c3504ce1367df39b00940f22d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1398/format:webp/1*cSfObiG5saBykSUVlAXiAQ.png"/></div></div><figcaption class="jc jd gj gh gi je jf bd b be z dk translated">匹配网络架构(Vinyals等人，2016年)</figcaption></figure><p id="716a" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">在这种模型架构下，Vinyals等人在计算机视觉(CV)和自然语言处理(NLP)领域对其进行了评估，以确认该模型可以应用于不同领域的问题。在CV领域，选择<a class="ae jg" href="https://www.omniglot.com/" rel="noopener ugc nofollow" target="_blank"> Omniglo </a>和<a class="ae jg" href="http://www.image-net.org/" rel="noopener ugc nofollow" target="_blank"> ImageNet </a>作为实验的数据集。</p><figure class="nw nx ny nz gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi od"><img src="../Images/1242cfd7969d3bc4fd5ea3f59efb30e7.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*r3GnFqRhrK_EJo1IzMrtPA.png"/></div></div><figcaption class="jc jd gj gh gi je jf bd b be z dk translated">对<a class="ae jg" href="https://www.omniglot.com/" rel="noopener ugc nofollow" target="_blank"> Omniglo </a>的性能评估(Vinyals等人，2016)</figcaption></figure><figure class="nw nx ny nz gt iv gh gi paragraph-image"><div class="gh gi oe"><img src="../Images/8abaf226b77080b8c94b5114f70fe809.png" data-original-src="https://miro.medium.com/v2/resize:fit:1298/format:webp/1*ilbPQ9-YiliHBLQBAzhpzQ.png"/></div><figcaption class="jc jd gj gh gi je jf bd b be z dk translated">对<a class="ae jg" href="http://www.image-net.org/" rel="noopener ugc nofollow" target="_blank"> ImageNet </a>子集的性能评估(Vinyals等人，2016年)</figcaption></figure><p id="9e70" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">对于NLP领域，利用<a class="ae jg" href="https://catalog.ldc.upenn.edu/LDC99T42" rel="noopener ugc nofollow" target="_blank"> Penn Treebank </a>数据集进行实验。给定一个有漏词的句子和支持句子集，最终模型输出是支持句子集的最佳匹配标签。而与另一个模型相比，匹配网络的性能并不令人满意。</p><figure class="nw nx ny nz gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi of"><img src="../Images/b7e0a09fec97b843289da9fbf55f8704.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*d083M2RMS0TtNnyefGgK4Q.png"/></div></div><figcaption class="jc jd gj gh gi je jf bd b be z dk translated">NLP中输入数据和支持集的示例(Vinyals等人，2016年)</figcaption></figure><p id="c02a" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated"><strong class="la jk"> <em class="oa">原型网络</em> </strong></p><p id="46f3" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated"><code class="fe nr ns nt nu b">Prototypical Networks</code>是Snell等人在2017年提出的。应用聚类概念来预测数据的标签，而该聚类模型将针对每一集进行训练，并根据该模型来计算损失。</p><p id="fef2" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">在每集中，该模型将把一个支持集和一个查询集转移到嵌入层。聚类的质心(即下图中的c1、c2和c3)是相应标签的平均值。而查询集(即下图中的x)将被分类到最近的聚类(即下图中的c2。<code class="fe nr ns nt nu b">Prototypical Networks</code>不使用余弦距离，而是使用欧几里得距离的平方来计算查询集之间的差异和支持集的质心。</p><figure class="nw nx ny nz gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi og"><img src="../Images/220430dded69c60a115ba39e8e134459.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*fT0ehhSvAnJuapgfVPuFCQ.png"/></div></div><figcaption class="jc jd gj gh gi je jf bd b be z dk translated">少射原型(左)，零射原型(右)。(斯内尔等人，2017年)</figcaption></figure><p id="34a0" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">Sneel等人使用完全相同的数据集(Omniglot和mini ImageNet)将结果与<code class="fe nr ns nt nu b">Matching Nets</code> (Vinyals等人，2016)进行比较。实验表明<code class="fe nr ns nt nu b">Prototypical Networks</code> (Snell et al .，2017)比<code class="fe nr ns nt nu b">Matching Nets</code> (Vinyals et al .，2016)取得了更好的性能。</p><figure class="nw nx ny nz gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi oh"><img src="../Images/3b91b54891591101cb1d600a8c5039e2.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*1uFUb9Xf9IRWb_kWkKyHxA.png"/></div></div><figcaption class="jc jd gj gh gi je jf bd b be z dk translated">Omniglot上的少量射击分类精度。(斯内尔等人，2017年)</figcaption></figure><figure class="nw nx ny nz gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi oi"><img src="../Images/b862669ab7ee208636a4be46012d09ca.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*i9VmrplCAERSlk4JQ82OJg.png"/></div></div><figcaption class="jc jd gj gh gi je jf bd b be z dk translated">miniImageNet上的少镜头分类精度。(斯内尔等人，2017年)</figcaption></figure><p id="c3a1" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated"><strong class="la jk"> <em class="oa">勤勤循环比较器</em> </strong></p><p id="deb7" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated"><code class="fe nr ns nt nu b">Attentive Recurrent Comparators (ARC)</code>由Shyam等人(2017)提出。它的灵感来自于人类比较一组物体的方式。例如，人类在玩照片狩猎游戏时，总是在两个物体之间来回寻找。这是因为我们的大脑不能一次分辨整个图像。</p><figure class="nw nx ny nz gt iv gh gi paragraph-image"><div class="gh gi oj"><img src="../Images/277a5ca573097e17ba2b47fe51f34146.png" data-original-src="https://miro.medium.com/v2/resize:fit:730/format:webp/0*mPUrqlqytLAEfbrj.jpg"/></div><figcaption class="jc jd gj gh gi je jf bd b be z dk translated">照片搜寻游戏(<a class="ae jg" href="https://en.wikipedia.org/wiki/Photo_Hunt#/media/File:Photo_Hunt_screen_shot.jpg" rel="noopener ugc nofollow" target="_blank">来源</a>)</figcaption></figure><p id="8bf4" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">ARC使用类似的方法，来回比较一对输入。在每一次<strong class="la jk"> <em class="oa">扫视</em> </strong>中，两幅图像的一部分将被交替传递给模型，而不是整个传递图像。</p><figure class="nw nx ny nz gt iv gh gi paragraph-image"><div class="gh gi ok"><img src="../Images/f75fc1d3d99460df3ec1033a4a41185d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1200/0*bn3U4NRSRiIosTIl.gif"/></div><figcaption class="jc jd gj gh gi je jf bd b be z dk translated">弧形在两个物体之间来回看(<a class="ae jg" href="https://github.com/sanyam5/arc-pytorch" rel="noopener ugc nofollow" target="_blank">来源</a>)</figcaption></figure><p id="14f2" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">通过利用注意机制和长时短记忆(LSTM)结构，ARC交替注意两个图像A和图像B(输入对)的一部分。</p><p id="a9b6" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">神经网络将h(t-1)(第一步中的空值)转换为omega(t)。ω(t)是文中提到的一个<strong class="la jk"><em class="oa"/></strong>。提取一小部分用于学习的简单方法是随机/顺序裁剪图像。Shyam等人建议使用柯西衰变核而不是这种简单的方法，因为它比另一种方法更平滑。</p><figure class="nw nx ny nz gt iv gh gi paragraph-image"><div class="gh gi ol"><img src="../Images/7648909da6e731b03fc053c6a34c45f0.png" data-original-src="https://miro.medium.com/v2/resize:fit:1168/format:webp/1*lD184AblNkvXJckDA9AJfw.png"/></div><figcaption class="jc jd gj gh gi je jf bd b be z dk translated">比较两个对象的弧形可视化(Shyam等人，2017年)</figcaption></figure><p id="f798" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">经过某一轮<strong class="la jk"> <em class="oa">一瞥</em> </strong>后，隐藏状态会传递给一个线性图层，输出的要么是两幅图像相似，要么不是。</p><figure class="nw nx ny nz gt iv gh gi paragraph-image"><div class="gh gi om"><img src="../Images/62c550f02fbf432d628bb24adc7eeeca.png" data-original-src="https://miro.medium.com/v2/resize:fit:1108/format:webp/1*l0igxbfkdoBryud61xAjqA.png"/></div><figcaption class="jc jd gj gh gi je jf bd b be z dk translated">对<a class="ae jg" href="https://www.omniglot.com/" rel="noopener ugc nofollow" target="_blank"> Omniglo </a>的性能评估(Shyam等人，2017年)</figcaption></figure><h2 id="ff04" class="na mj jj bd mk nb nc dn mo nd ne dp ms lh nf ng mu ll nh ni mw lp nj nk my nl bi translated">基于优化</h2><p id="30ca" class="pw-post-body-paragraph ky kz jj la b lb nm kk ld le nn kn lg lh no lj lk ll np ln lo lp nq lr ls lt im bi translated"><strong class="la jk"> <em class="oa">基于LSTM的元学习者</em> </strong></p><p id="2a05" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated"><code class="fe nr ns nt nu b">LSTM-based meta-learner</code>由Ravi和Larochelle于2016年提出。作者观察到，由于局限性，基于梯度的优化在一些标记的例子面前失败。基于梯度的算法不能快速收敛，并且每次都需要初始化权重。Ravi和Larochelle训练了一个基于LSTM元学习器优化器来优化最终的神经网络模型。</p><p id="8607" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">首先，我们将数据集分成两个子数据集，即元训练和元测试。之后，D(训练)和D(测试)将被分割成小批量，如下所示。每次，每个记录集(1行)都将输入到一个模型中，用于模型训练。</p><figure class="nw nx ny nz gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi on"><img src="../Images/0abf61f8091ec048b3c4a25ebc35d31c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*CFWxtvXgEWf0WAbWMW60ow.png"/></div></div><figcaption class="jc jd gj gh gi je jf bd b be z dk translated">元学习设置(Ravi和Larochelle，2016年)</figcaption></figure><p id="e848" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">训练元学习者非常简单。将逐步提供解释:</p><ul class=""><li id="c5bb" class="lu lv jj la b lb lc le lf lh lw ll lx lp ly lt lz ma mb mc bi translated">1:模型参数是随机初始化的</li><li id="73d7" class="lu lv jj la b lb md le me lh mf ll mg lp mh lt lz ma mb mc bi translated">4:将元训练数据集分为D(训练)和D(测试)</li><li id="0114" class="lu lv jj la b lb md le me lh mf ll mg lp mh lt lz ma mb mc bi translated">5:初始化元学习者参数</li><li id="d5e4" class="lu lv jj la b lb md le me lh mf ll mg lp mh lt lz ma mb mc bi translated">8:将D(训练)拆分为批次</li><li id="45a3" class="lu lv jj la b lb md le me lh mf ll mg lp mh lt lz ma mb mc bi translated">9:训练学习者并获得损失</li><li id="4cab" class="lu lv jj la b lb md le me lh mf ll mg lp mh lt lz ma mb mc bi translated">10:反馈损失和对元学习者的输出</li><li id="c712" class="lu lv jj la b lb md le me lh mf ll mg lp mh lt lz ma mb mc bi translated">11:根据#10输出更新学习者参数</li><li id="b1fe" class="lu lv jj la b lb md le me lh mf ll mg lp mh lt lz ma mb mc bi translated">15:从学员处获得测试批次的损失</li><li id="a9da" class="lu lv jj la b lb md le me lh mf ll mg lp mh lt lz ma mb mc bi translated">16:更新元学习者参数</li></ul><figure class="nw nx ny nz gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi oo"><img src="../Images/bd554d1372a55ebce4a6ef6597f9eb83.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*76Dn0Yv4fjs561E2_DGJOw.png"/></div></div><figcaption class="jc jd gj gh gi je jf bd b be z dk translated"><code class="fe nr ns nt nu b">LSTM-based meta-learner</code>程序(Ravi和Larochelle，2016年)</figcaption></figure><figure class="nw nx ny nz gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi op"><img src="../Images/f90535c4409a03cbcc7e102b0b41d5aa.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*oNg3q-pDBo9e50rh4qlLgA.png"/></div></div><figcaption class="jc jd gj gh gi je jf bd b be z dk translated">miniImageNet上的少镜头分类精度。(拉维和拉罗歇尔，2016年)</figcaption></figure><p id="bbc9" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated"><strong class="la jk"> <em class="oa">模型不可知元学习(MAML) </em> </strong></p><p id="211f" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated"><code class="fe nr ns nt nu b">Model-Agnostic Meta-Learning (MAML)</code>由芬恩等人于2017年提出。这是一个与模型无关的框架。模型不可知意味着它不是特定于模型的。Finn等人在回归、分类和强化学习问题上评估了这个框架，结果是有希望的。</p><p id="fae8" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">MAML的目标是学习一个模型，如果一个模型是预先训练好的，它可以在新的任务上取得快速进展。在这个框架中涉及两个梯度更新。在计算了一批梯度(还没有更新到模型)之后，将基于前述的一批梯度计算第二个梯度。他们称之为<strong class="la jk">更新涉及到一个渐变通过一个渐变</strong>。</p><p id="5a64" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">下图显示了逐渐变更新渐变的概念。虚线是每个任务的梯度，而实线是考虑所有任务的梯度后的最终梯度。</p><figure class="nw nx ny nz gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi oq"><img src="../Images/b3af9c3cfc676ef57209d21e67c43bcb.png" data-original-src="https://miro.medium.com/v2/resize:fit:806/format:webp/1*m5gptHFOAfGCpac88nKntg.png"/></div></div><figcaption class="jc jd gj gh gi je jf bd b be z dk translated">针对能够快速适应新任务的表征θ进行优化(Finn等人，2017年)</figcaption></figure><p id="d0d6" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">首先，需要通过使用以下过程来训练预训练的MAML模型。将逐步提供解释:</p><ul class=""><li id="10df" class="lu lv jj la b lb lc le lf lh lw ll lx lp ly lt lz ma mb mc bi translated"><em class="oa">要求分配任务</em>:从任务池中生成批量任务。相同的记录可以存在于不同的任务中，它可以分别在任务1、任务2中被支持集、查询集。</li><li id="2fb0" class="lu lv jj la b lb md le me lh mf ll mg lp mh lt lz ma mb mc bi translated"><em class="oa">需要步长超参数</em>:初始化一个学习率参数。</li><li id="7294" class="lu lv jj la b lb md le me lh mf ll mg lp mh lt lz ma mb mc bi translated"><em class="oa"> 1 </em>:重量初始化</li><li id="a91f" class="lu lv jj la b lb md le me lh mf ll mg lp mh lt lz ma mb mc bi translated"><em class="oa">2</em>:for循环，保持训练直到完成</li><li id="412b" class="lu lv jj la b lb md le me lh mf ll mg lp mh lt lz ma mb mc bi translated"><em class="oa"> 3 </em>:从任务池中获取一批任务</li><li id="348b" class="lu lv jj la b lb md le me lh mf ll mg lp mh lt lz ma mb mc bi translated"><em class="oa">4 ~ 7</em>:for循环，逐个遍历任务。评估任务并计算每个任务的梯度下降。在实际编码中，有<a class="ae jg" href="https://github.com/cbfinn/maml/blob/master/maml.py#L99" rel="noopener ugc nofollow" target="_blank">内部for循环</a>对任务进行多次求值。</li><li id="84bc" class="lu lv jj la b lb md le me lh mf ll mg lp mh lt lz ma mb mc bi translated"><em class="oa"> 8 </em>:根据步骤<em class="oa"> 6 </em>更新每批任务的梯度下降。</li></ul><figure class="nw nx ny nz gt iv gh gi paragraph-image"><div class="gh gi or"><img src="../Images/bd062926ce6a0f57299df90a5b638f56.png" data-original-src="https://miro.medium.com/v2/resize:fit:1112/format:webp/1*iqRJZIH7z5_OOFz2rhgfdA.png"/></div><figcaption class="jc jd gj gh gi je jf bd b be z dk translated">元学习程序(Finn等人，2017年)</figcaption></figure><p id="ad7e" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">在微调阶段，它非常类似于元学习阶段，除了没有权重初始化(因为我们已经有一个预训练的权重)</p><figure class="nw nx ny nz gt iv gh gi paragraph-image"><div class="gh gi os"><img src="../Images/2ae42148c564a72b36d44e5a5077b5c2.png" data-original-src="https://miro.medium.com/v2/resize:fit:1094/format:webp/1*SU9j0EqV1TyvTSRb4m2j4A.png"/></div><figcaption class="jc jd gj gh gi je jf bd b be z dk translated">微调程序(Finn等人，2017年)</figcaption></figure><h2 id="b18a" class="na mj jj bd mk nb nc dn mo nd ne dp ms lh nf ng mu ll nh ni mw lp nj nk my nl bi translated">基于记忆的</h2><p id="2491" class="pw-post-body-paragraph ky kz jj la b lb nm kk ld le nn kn lg lh no lj lk ll np ln lo lp nq lr ls lt im bi translated"><strong class="la jk"> <em class="oa">记忆增强神经网络</em> </strong></p><p id="89c3" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated"><code class="fe nr ns nt nu b">Memory-Augmented Neural Networks (MANN)</code>中的一次性学习是由桑托罗等人(2016)提出的。他们将MANN应用于元学习，使得模型可以访问外部记忆(或信息)来辅助模型预测结果。在此之前，我们将快速浏览一下曼恩概念，并在元学习中回到曼恩。这有助于解决记忆罕见的事件。</p><p id="7e0a" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated"><a class="ae jg" href="https://arxiv.org/pdf/1410.5401.pdf" rel="noopener ugc nofollow" target="_blank">神经图灵机</a> (NTM)是Graves等人在2014年推出的。一个快速的一些总结是，模型的回复既取决于内部记忆(即RNN隐藏状态)又取决于外部记忆(即神经网络之外的记忆库)来决定输出。为了访问外部存储器，NTM提供了两种方法来寻址相应的存储器。第一个是内容寻址，当相似性度量是余弦相似性时，该模型将处理相似性记忆。另一个是位置寻址，模型将通过旋转关注特定的位置。</p><figure class="nw nx ny nz gt iv gh gi paragraph-image"><div class="gh gi ot"><img src="../Images/515ed09c9562919fd7a8e805e48e64d3.png" data-original-src="https://miro.medium.com/v2/resize:fit:1146/format:webp/1*sNMYiHDv0VDKDAXLul6WJQ.png"/></div><figcaption class="jc jd gj gh gi je jf bd b be z dk translated">NTM建筑(格雷夫斯等人，2014)</figcaption></figure><p id="d492" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">桑托罗等人按照NTM的设置进行了一些修改，这些修改是输入和寻址方法。<strong class="la jk">输入</strong>包括特征(x_t)和y_(t-1)的时间偏移。y时间偏移意味着前一个“记录y”标签。<strong class="la jk">最近最少使用的访问(LRUA) </strong>用于访问外部存储器。Graves等人没有使用内容寻址或位置寻址，而是提到LRUA适合基于序列的预测任务，但不适用于独立于序列任务的信息的联合编码。LRUA将内存写入最少使用的内存位置或最近使用的内存位置。</p><figure class="nw nx ny nz gt iv gh gi paragraph-image"><div class="gh gi ou"><img src="../Images/b2ead37bbb96f15930788378dad1f5ff.png" data-original-src="https://miro.medium.com/v2/resize:fit:1076/format:webp/1*ehH8-9UoqeLab9nYPmmGVw.png"/></div><figcaption class="jc jd gj gh gi je jf bd b be z dk translated">曼恩任务设置(桑托罗等人，2016年)</figcaption></figure><p id="40dd" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated"><strong class="la jk"><em class="oa">【Meta net】</em></strong></p><p id="df47" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">蒙克达赖和于介绍<code class="fe nr ns nt nu b">Meta Networks (MetaNet)</code>。元网络模型解决了动态学习新任务信息能力的缺乏。所提出的解决方案利用了特定于任务的嵌入(快速权重)和学习嵌入(慢速权重)。</p><p id="6039" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">特定于任务的嵌入是从元学习者那里学习的，元学习者是一个任务不可知的模型。在生成嵌入之后，它将传递给一个基础学习者，这是一个特定于任务的模型来生成输出。</p><figure class="nw nx ny nz gt iv gh gi paragraph-image"><div class="gh gi ov"><img src="../Images/d7a8d70be925e320ad25a85b94f9a206.png" data-original-src="https://miro.medium.com/v2/resize:fit:1046/format:webp/1*UNFTYM3EcKi56NZ30m_PQA.png"/></div><figcaption class="jc jd gj gh gi je jf bd b be z dk translated">元网络架构(Munkhdalai和Yu，2017)</figcaption></figure><p id="58c8" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">为了训练元网络，有三个主要步骤:获取元信息、生成快速权重和优化慢速权重。下面是伪:</p><p id="924b" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">步骤2~4:训练模型以获取嵌入，而loss_emb被设计用于捕获表征目标。</p><p id="e515" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">步骤5:生成嵌入。</p><p id="b12b" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">步骤7~14:针对目标任务训练模型。</p><p id="e120" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">步骤16~20:生成输出</p><figure class="nw nx ny nz gt iv gh gi paragraph-image"><div class="gh gi ow"><img src="../Images/2b9d13a00441f7ae03ce27f264d52d1d.png" data-original-src="https://miro.medium.com/v2/resize:fit:984/format:webp/1*rBrBLX-o4wOKK94ZmVCH1Q.png"/></div><figcaption class="jc jd gj gh gi je jf bd b be z dk translated">元网络培训程序(蒙克达莱和于，2017年)</figcaption></figure><h1 id="ebd4" class="mi mj jj bd mk ml mm mn mo mp mq mr ms kp mt kq mu ks mv kt mw kv mx kw my mz bi translated">附录</h1><figure class="nw nx ny nz gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi ox"><img src="../Images/41aedb9c86e368d080f3e7a2a3ba4591.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*8wNzb_kF98pnzHJhhJWscQ.png"/></div></div><figcaption class="jc jd gj gh gi je jf bd b be z dk translated">已发表的元学习方法的比较(Metz等人，2018年)</figcaption></figure><h1 id="ea47" class="mi mj jj bd mk ml mm mn mo mp mq mr ms kp mt kq mu ks mv kt mw kv mx kw my mz bi translated">拿走</h1><p id="8bda" class="pw-post-body-paragraph ky kz jj la b lb nm kk ld le nn kn lg lh no lj lk ll np ln lo lp nq lr ls lt im bi translated">百花齐放，百家争鸣。解决元学习问题有很多不同的方法。从我的经验来看，元学习主要是在计算机视觉(CV)领域发展起来的，同时也有一些研究者将其应用于自然语言处理(NLP)领域。一个可能的原因是迁移学习(如<a class="ae jg" href="https://towardsdatascience.com/how-bert-leverage-attention-mechanism-and-transformer-to-learn-word-contextual-relations-5bbee1b6dbdb" rel="noopener" target="_blank"> BERT </a>，<a class="ae jg" href="https://medium.com/dataseries/why-does-xlnet-outperform-bert-da98a8503d5b" rel="noopener"> XLNet </a>)非常成功，各种词汇量太高，无法在NLP中采用元学习。</p><h1 id="cc8f" class="mi mj jj bd mk ml mm mn mo mp mq mr ms kp mt kq mu ks mv kt mw kv mx kw my mz bi translated">喜欢学习？</h1><p id="49f6" class="pw-post-body-paragraph ky kz jj la b lb nm kk ld le nn kn lg lh no lj lk ll np ln lo lp nq lr ls lt im bi translated">我是湾区的数据科学家。关注数据科学的最新发展，尤其是NLP、数据扩充和平台相关领域。在<a class="ae jg" href="https://www.linkedin.com/in/edwardma1026" rel="noopener ugc nofollow" target="_blank"> LinkedIn </a>或<a class="ae jg" href="https://github.com/makcedward" rel="noopener ugc nofollow" target="_blank"> Github </a>上随时联系<a class="ae jg" href="https://makcedward.github.io/" rel="noopener ugc nofollow" target="_blank"> me </a>。</p><h1 id="4516" class="mi mj jj bd mk ml mm mn mo mp mq mr ms kp mt kq mu ks mv kt mw kv mx kw my mz bi translated">延伸阅读</h1><ul class=""><li id="b8d7" class="lu lv jj la b lb nm le nn lh oy ll oz lp pa lt lz ma mb mc bi translated"><a class="ae jg" href="http://metalearning-symposium.ml/files/vinyals.pdf" rel="noopener ugc nofollow" target="_blank">viny als的模型与优化元学习</a>(NIPS 2017)</li><li id="cbe7" class="lu lv jj la b lb md le me lh mf ll mg lp mh lt lz ma mb mc bi translated"><a class="ae jg" href="https://towardsdatascience.com/data-augmentation-library-for-text-9661736b13ff" rel="noopener" target="_blank">文本的数据扩充</a></li><li id="2069" class="lu lv jj la b lb md le me lh mf ll mg lp mh lt lz ma mb mc bi translated">原型网络实现(<a class="ae jg" href="https://github.com/jakesnell/prototypical-networks/" rel="noopener ugc nofollow" target="_blank"> PyTorch </a>)</li><li id="48dd" class="lu lv jj la b lb md le me lh mf ll mg lp mh lt lz ma mb mc bi translated">匹配网络实现(<a class="ae jg" href="https://github.com/AntreasAntoniou/MatchingNetworks" rel="noopener ugc nofollow" target="_blank"> TensorFlow </a>，<a class="ae jg" href="https://github.com/activatedgeek/Matching-Networks" rel="noopener ugc nofollow" target="_blank"> PyTorch </a>)</li><li id="ef88" class="lu lv jj la b lb md le me lh mf ll mg lp mh lt lz ma mb mc bi translated">电弧实现(<a class="ae jg" href="https://github.com/pranv/ARC" rel="noopener ugc nofollow" target="_blank"> Theano </a>，<a class="ae jg" href="https://github.com/sanyam5/arc-pytorch" rel="noopener ugc nofollow" target="_blank"> PyTorch </a>)</li><li id="898f" class="lu lv jj la b lb md le me lh mf ll mg lp mh lt lz ma mb mc bi translated">基于LSTM的元学习(<a class="ae jg" href="https://github.com/twitter/meta-learning-lstm" rel="noopener ugc nofollow" target="_blank"> Torch </a>，<a class="ae jg" href="https://github.com/markdtw/meta-learning-lstm-pytorch" rel="noopener ugc nofollow" target="_blank"> PyTorch </a>)</li><li id="cb2c" class="lu lv jj la b lb md le me lh mf ll mg lp mh lt lz ma mb mc bi translated">MAML实现(<a class="ae jg" href="https://github.com/cbfinn/maml" rel="noopener ugc nofollow" target="_blank"> TensorFlow </a>，<a class="ae jg" href="https://github.com/dragen1860/MAML-Pytorch" rel="noopener ugc nofollow" target="_blank"> PyTorch </a>)</li><li id="58e5" class="lu lv jj la b lb md le me lh mf ll mg lp mh lt lz ma mb mc bi translated">MANN实现中的一次性学习(<a class="ae jg" href="https://github.com/hmishra2250/NTM-One-Shot-TF" rel="noopener ugc nofollow" target="_blank"> Tensorflow </a>，<a class="ae jg" href="https://github.com/t2kien/Memory-Augmented-Neural-Network---Oneshot-learning" rel="noopener ugc nofollow" target="_blank"> Keras </a>)</li><li id="dee0" class="lu lv jj la b lb md le me lh mf ll mg lp mh lt lz ma mb mc bi translated">元网络实现(<a class="ae jg" href="https://bitbucket.org/tsendeemts/metanet/src/master/" rel="noopener ugc nofollow" target="_blank">链接器</a>)</li><li id="d9f6" class="lu lv jj la b lb md le me lh mf ll mg lp mh lt lz ma mb mc bi translated"><a class="ae jg" href="https://github.com/brendenlake/omniglot" rel="noopener ugc nofollow" target="_blank"> Omniglot数据集</a></li><li id="0a6b" class="lu lv jj la b lb md le me lh mf ll mg lp mh lt lz ma mb mc bi translated"><a class="ae jg" href="http://image-net.org/download" rel="noopener ugc nofollow" target="_blank"> ImageNet数据集</a></li></ul><h1 id="6d21" class="mi mj jj bd mk ml mm mn mo mp mq mr ms kp mt kq mu ks mv kt mw kv mx kw my mz bi translated">参考</h1><ul class=""><li id="1947" class="lu lv jj la b lb nm le nn lh oy ll oz lp pa lt lz ma mb mc bi translated">A.Graves，G. Wayne和I. Danihelka。<a class="ae jg" href="https://arxiv.org/pdf/1410.5401.pdf" rel="noopener ugc nofollow" target="_blank">神经图灵机</a>。2014</li><li id="00ae" class="lu lv jj la b lb md le me lh mf ll mg lp mh lt lz ma mb mc bi translated">A.桑托罗、s .巴尔图诺夫、m .伯特温尼克、d .威斯特拉和t .利利拉普。<a class="ae jg" href="https://arxiv.org/pdf/1605.06065.pdf" rel="noopener ugc nofollow" target="_blank">用记忆增强神经网络进行一次性学习</a>。2016</li><li id="10ea" class="lu lv jj la b lb md le me lh mf ll mg lp mh lt lz ma mb mc bi translated">O.Vinyals、C. Blundell、T. Lillicrap、K. Kavukcuoglu和D. Wierstra。<a class="ae jg" href="https://arxiv.org/pdf/1606.04080.pdf" rel="noopener ugc nofollow" target="_blank">一次性学习的匹配网络</a>。2016</li><li id="197f" class="lu lv jj la b lb md le me lh mf ll mg lp mh lt lz ma mb mc bi translated">南拉维和拉罗彻尔。<a class="ae jg" href="https://openreview.net/pdf?id=rJY0-Kcll" rel="noopener ugc nofollow" target="_blank">作为少量学习模型的优化</a>。2016</li><li id="52e2" class="lu lv jj la b lb md le me lh mf ll mg lp mh lt lz ma mb mc bi translated">J.斯内尔，k .斯维斯基和R. S .泽梅尔。<a class="ae jg" href="https://arxiv.org/pdf/1703.05175.pdf" rel="noopener ugc nofollow" target="_blank">用于少量学习的原型网络</a>。2017</li><li id="0200" class="lu lv jj la b lb md le me lh mf ll mg lp mh lt lz ma mb mc bi translated">页（page的缩写）希亚姆，s .古普塔和a .杜克基帕蒂。<a class="ae jg" href="https://arxiv.org/pdf/1703.00767.pdf" rel="noopener ugc nofollow" target="_blank">细心的递归比较器</a>。2017</li><li id="4090" class="lu lv jj la b lb md le me lh mf ll mg lp mh lt lz ma mb mc bi translated">C.芬恩、p .阿贝耳和s .莱文。<a class="ae jg" href="https://arxiv.org/pdf/1703.03400.pdf" rel="noopener ugc nofollow" target="_blank">用于深度网络快速适应的模型不可知元学习</a>。2017</li><li id="f393" class="lu lv jj la b lb md le me lh mf ll mg lp mh lt lz ma mb mc bi translated">T.蒙克达赖和于。<a class="ae jg" href="https://arxiv.org/pdf/1703.00837.pdf" rel="noopener ugc nofollow" target="_blank">元网络</a>。2017</li><li id="0df5" class="lu lv jj la b lb md le me lh mf ll mg lp mh lt lz ma mb mc bi translated">长度梅斯，N. Maheswaranathan，B. Cheung和J. Sohl-Dickstein。<a class="ae jg" href="https://arxiv.org/pdf/1804.00222.pdf" rel="noopener ugc nofollow" target="_blank">无监督表示学习的元学习更新规则</a>。2018</li></ul></div></div>    
</body>
</html>