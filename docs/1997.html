<html>
<head>
<title>Autoencoders for Image Labeling</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">用于图像标记的自动编码器</h1>
<blockquote>原文：<a href="https://pub.towardsai.net/autoencoders-for-image-labeling-84242decd3d2?source=collection_archive---------0-----------------------#2021-07-19">https://pub.towardsai.net/autoencoders-for-image-labeling-84242decd3d2?source=collection_archive---------0-----------------------#2021-07-19</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><h2 id="0aa4" class="ir is it bd b dl iu iv iw ix iy iz dk ja translated" aria-label="kicker paragraph"><a class="ae ep" href="https://towardsai.net/p/category/machine-learning/deep-learning" rel="noopener ugc nofollow" target="_blank">深度学习</a></h2><div class=""/><div class=""><h2 id="f8e3" class="pw-subtitle-paragraph jz jc it bd b ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq dk translated">了解如何使用深度卷积自动编码器标记图像</h2></div><p id="a203" class="pw-post-body-paragraph kr ks it kt b ku kv kd kw kx ky kg kz la lb lc ld le lf lg lh li lj lk ll lm im bi translated"><em class="ln">你在一个文件夹中混合了不同类别的图像，当你知道类别的数量时，你如何标记这些图像。</em></p><p id="e2c1" class="pw-post-body-paragraph kr ks it kt b ku kv kd kw kx ky kg kz la lb lc ld le lf lg lh li lj lk ll lm im bi translated"><em class="ln">在这里，您将实现深度卷积自动编码器，仅使用时尚MNIST图像来标记时尚MNIST数据集。</em></p><figure class="lp lq lr ls gt lt gh gi paragraph-image"><div role="button" tabindex="0" class="lu lv di lw bf lx"><div class="gh gi lo"><img src="../Images/c0a8e68a49bb28c54fe6a2264f42a7bd.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*FDes6OFb8SMRvxh_FSROXQ.png"/></div></div></figure><p id="4bc6" class="pw-post-body-paragraph kr ks it kt b ku kv kd kw kx ky kg kz la lb lc ld le lf lg lh li lj lk ll lm im bi translated">使用自动编码器为标记图像所做的假设:</p><ul class=""><li id="e2f2" class="ma mb it kt b ku kv kx ky la mc le md li me lm mf mg mh mi bi translated">了解数据集中的类的数量</li><li id="27bd" class="ma mb it kt b ku mj kx mk la ml le mm li mn lm mf mg mh mi bi translated">每堂课都有几张图片</li></ul><h1 id="5f25" class="mo mp it bd mq mr ms mt mu mv mw mx my ki mz kj na kl nb km nc ko nd kp ne nf bi translated">自动编码器概述</h1><p id="4589" class="pw-post-body-paragraph kr ks it kt b ku ng kd kw kx nh kg kz la ni lc ld le nj lg lh li nk lk ll lm im bi translated">自动编码器由编码器和解码器网络组成。编码器将高维输入编码成低维潜在表示，也称为瓶颈层。解码器采用这种低维潜在表示，并重构原始输入。自动编码器的目标是最小化输入和输出之间的重构误差。<strong class="kt jd"> </strong>这有助于自动编码器学习输入数据中的重要特征。</p><figure class="lp lq lr ls gt lt gh gi paragraph-image"><div class="gh gi nl"><img src="../Images/b5f2dcedaa18d6e0d88737deeb2202e9.png" data-original-src="https://miro.medium.com/v2/resize:fit:1064/format:webp/0*TqQtCypvY8kBIBNT.png"/></div><figcaption class="nm nn gj gh gi no np bd b be z dk translated">来源:<a class="ae nq" href="https://lilianweng.github.io/lil-log/2018/08/12/from-autoencoder-to-beta-vae.html" rel="noopener ugc nofollow" target="_blank">https://lilian Weng . github . io/lil-log/2018/08/12/from-auto encoder-to-beta-vae . html</a></figcaption></figure><p id="5078" class="pw-post-body-paragraph kr ks it kt b ku kv kd kw kx ky kg kz la lb lc ld le lf lg lh li lj lk ll lm im bi translated"><strong class="kt jd">自动编码器的应用</strong></p><ul class=""><li id="cec0" class="ma mb it kt b ku kv kx ky la mc le md li me lm mf mg mh mi bi translated">图像压缩中的降维</li><li id="07d7" class="ma mb it kt b ku mj kx mk la ml le mm li mn lm mf mg mh mi bi translated">从压缩的图像中重建图像</li><li id="1cb3" class="ma mb it kt b ku mj kx mk la ml le mm li mn lm mf mg mh mi bi translated">提取图像的特征并标记它们</li><li id="719a" class="ma mb it kt b ku mj kx mk la ml le mm li mn lm mf mg mh mi bi translated">图像去噪</li><li id="803f" class="ma mb it kt b ku mj kx mk la ml le mm li mn lm mf mg mh mi bi translated"><a class="ae nq" href="https://medium.com/analytics-vidhya/image-anomaly-detection-using-autoencoders-ae937c7fd2d1" rel="noopener">图像异常检测</a></li></ul><h2 id="709b" class="nr mp it bd mq ns nt dn mu nu nv dp my la nw nx na le ny nz nc li oa ob ne iz bi translated">时尚MNIST数据集标注体系结构</h2><p id="8261" class="pw-post-body-paragraph kr ks it kt b ku ng kd kw kx nh kg kz la ni lc ld le nj lg lh li nk lk ll lm im bi translated"><strong class="kt jd">步骤1: </strong> <strong class="kt jd">创建深度卷积自动编码器</strong></p><p id="4c6f" class="pw-post-body-paragraph kr ks it kt b ku kv kd kw kx ky kg kz la lb lc ld le lf lg lh li lj lk ll lm im bi translated">自动编码器将<strong class="kt jd"> </strong>由一个将图像压缩成潜在表示的编码器和一个将压缩图像重建回原始尺寸的解码器组成。</p><p id="a81f" class="pw-post-body-paragraph kr ks it kt b ku kv kd kw kx ky kg kz la lb lc ld le lf lg lh li lj lk ll lm im bi translated">使用SSIM损失函数计算原始图像和重建图像之间的损失</p><figure class="lp lq lr ls gt lt gh gi paragraph-image"><div class="gh gi oc"><img src="../Images/5548bdbbe4a672bd20d43fd50dd48717.png" data-original-src="https://miro.medium.com/v2/resize:fit:1176/format:webp/1*DVQ_Vk_jfBkiIywSF2Medg.png"/></div><figcaption class="nm nn gj gh gi no np bd b be z dk translated">训练深度Conv自动编码器，然后使用KMeans(image by author)从编码数据创建图像簇</figcaption></figure><p id="786a" class="pw-post-body-paragraph kr ks it kt b ku kv kd kw kx ky kg kz la lb lc ld le lf lg lh li lj lk ll lm im bi translated"><strong class="kt jd">步骤2:使用KMeans </strong>为编码图像数据生成聚类</p><p id="6a53" class="pw-post-body-paragraph kr ks it kt b ku kv kd kw kx ky kg kz la lb lc ld le lf lg lh li lj lk ll lm im bi translated">使用无监督KMeans算法对编码数据进行聚类，编码器的输出包含压缩的图像数据。聚类的数量就是数据集中的类的数量。</p><p id="bc25" class="pw-post-body-paragraph kr ks it kt b ku kv kd kw kx ky kg kz la lb lc ld le lf lg lh li lj lk ll lm im bi translated"><strong class="kt jd">步骤3:将每个类别的样本图像与每个聚类中的图像进行比较</strong></p><figure class="lp lq lr ls gt lt gh gi paragraph-image"><div role="button" tabindex="0" class="lu lv di lw bf lx"><div class="gh gi od"><img src="../Images/7e28648a7fac0c15c8ea0ac25036adb6.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*xkWBTjX-kuM74B-uUG4dJA.png"/></div></div><figcaption class="nm nn gj gh gi no np bd b be z dk translated">基于聚类分配将重建的样本图像与重建的图像进行比较</figcaption></figure><p id="1ba0" class="pw-post-body-paragraph kr ks it kt b ku kv kd kw kx ky kg kz la lb lc ld le lf lg lh li lj lk ll lm im bi translated">使用Autoencoder重建每个类别的样本图像以及每个聚类的图像。使用SSIM、结构相似性指数比较重建图像。如果结构相似性损失函数中的差异小于阈值，则来自聚类的图像属于来自样本类的图像。</p><p id="4a6b" class="pw-post-body-paragraph kr ks it kt b ku kv kd kw kx ky kg kz la lb lc ld le lf lg lh li lj lk ll lm im bi translated">需要对阈值进行实验，以获得一组良好的原始标记图像。</p><h2 id="c55e" class="nr mp it bd mq ns nt dn mu nu nv dp my la nw nx na le ny nz nc li oa ob ne iz bi translated">利用Autoencoder实现时尚目录数据的标注</h2><p id="c67d" class="pw-post-body-paragraph kr ks it kt b ku ng kd kw kx nh kg kz la ni lc ld le nj lg lh li nk lk ll lm im bi translated"><strong class="kt jd">加载时尚MNIST数据集</strong></p><pre class="lp lq lr ls gt oe of og oh aw oi bi"><span id="10b2" class="nr mp it of b gy oj ok l ol om"># set the image dimension<br/><strong class="of jd">IMG_WIDTH= 28 <br/>IMG_HEIGHT= 28 <br/>IMG_CHANNELS=1<br/>IMG_DIM = (IMG_HEIGHT, IMG_WIDTH)<br/>input_shape = (IMG_HEIGHT, IMG_WIDTH, IMG_CHANNELS)</strong></span><span id="0029" class="nr mp it of b gy on ok l ol om">#Load Fashion MNIST and scale the data<br/><strong class="of jd">(x_train, y_train), (x_test, y_test) = tf.keras.datasets.fashion_mnist.load_data()</strong><br/># Rescale the images from [0,255] to the [0.0,1.0] range.<br/><strong class="of jd">x_train, x_test = x_train[..., np.newaxis]/255.0, x_test[..., np.newaxis]/255.0<br/>x_train = x_train.reshape(-1, IMG_WIDTH, IMG_HEIGHT,IMG_CHANNELS)</strong></span></pre><p id="8dea" class="pw-post-body-paragraph kr ks it kt b ku kv kd kw kx ky kg kz la lb lc ld le lf lg lh li lj lk ll lm im bi translated"><strong class="kt jd">创建深度Conv自动编码器</strong></p><pre class="lp lq lr ls gt oe of og oh aw oi bi"><span id="b3c6" class="nr mp it of b gy oj ok l ol om"># Create the Encoder and Decoder<br/>#pass the gray scale input image of size(28,28,1)<br/><strong class="of jd">inputs = tf.keras.Input(shape=input_shape, name='input_layer')</strong><br/># Conv Block 1 -&gt; BatchNorm-&gt;leaky Relu<br/><strong class="of jd">encoded = tf.keras.layers.Conv2D(32, kernel_size=3, strides= 1, padding='same', name='conv_1')(inputs)<br/>encoded = tf.keras.layers.BatchNormalization(name='batchnorm_1')(encoded)<br/>encoded = tf.keras.layers.LeakyReLU(name='leaky_relu_1')(encoded)</strong></span><span id="0239" class="nr mp it of b gy on ok l ol om"># Conv Block 2 -&gt; BatchNorm-&gt;leaky Relu<br/><strong class="of jd">encoded = tf.keras.layers.Conv2D(64, kernel_size=3, strides= 2, padding='same', name='conv_2')(encoded)<br/>encoded = tf.keras.layers.BatchNormalization(name='batchnorm_2')(encoded)<br/>encoded = tf.keras.layers.LeakyReLU(name='leaky_relu_2')(encoded)</strong></span><span id="d55b" class="nr mp it of b gy on ok l ol om"># Conv Block 3 -&gt; BatchNorm-&gt;leaky Relu<br/><strong class="of jd">encoded = tf.keras.layers.Conv2D(64, kernel_size=3, strides=2, padding='same', name='conv_3')(encoded)<br/>encoded = tf.keras.layers.BatchNormalization(name='batchnorm_3')(encoded)<br/>encoded = tf.keras.layers.LeakyReLU(name='leaky_relu_3')(encoded)<br/>encoded_shape= tf.keras.backend.int_shape(encoded)</strong><br/><br/><strong class="of jd">encoded = tf.keras.layers.Flatten()(encoded)<br/>encoded = tf.keras.layers.Dense(10)(encoded)<br/>encoder=tf.keras.Model(inputs, encoded, name='encoder')<br/>encoder.summary()<br/>latent=tf.keras.Input(shape=(10,))</strong><br/>#Decoder<br/># DeConv Block 1-&gt; BatchNorm-&gt;leaky Relu.<br/><strong class="of jd">decoded= tf.keras.layers.Dense(np.prod(encoded_shape[1:]))(latent)<br/>decoded= tf.keras.layers.Reshape((encoded_shape[1], encoded_shape[2], encoded_shape[3]))(decoded)<br/>decoded = tf.keras.layers.Conv2DTranspose(64, 3, strides= 2, padding='same',name='conv_transpose_1')(decoded)<br/>decoded = tf.keras.layers.BatchNormalization(name='batchnorm_4')(decoded)<br/>decoded = tf.keras.layers.LeakyReLU(name='leaky_relu_4')(decoded)</strong><br/># DeConv Block 2-&gt; BatchNorm-&gt;leaky Relu<br/><strong class="of jd">decoded = tf.keras.layers.Conv2DTranspose(64, 3, strides= 2, padding='same', name='conv_transpose_2')(decoded)<br/>decoded = tf.keras.layers.BatchNormalization(name='batchnorm_5')(decoded)<br/>decoded = tf.keras.layers.LeakyReLU(name='leaky_relu_5')(decoded)</strong><br/># DeConv Block 3-&gt; BatchNorm-&gt;leaky Relu<br/><strong class="of jd">decoded = tf.keras.layers.Conv2DTranspose(32, 3, 1, padding='same', name='conv_transpose_3')(decoded)<br/>decoded = tf.keras.layers.BatchNormalization(name='batchnorm_6')(decoded)<br/>decoded = tf.keras.layers.LeakyReLU(name='leaky_relu_6')(decoded)</strong><br/># output<br/><strong class="of jd">outputs = tf.keras.layers.Conv2DTranspose(1, 3, 1,padding='same', activation='sigmoid', name='conv_transpose_4')(decoded)</strong></span><span id="291d" class="nr mp it of b gy on ok l ol om"><strong class="of jd">decoder= tf.keras.Model(latent, outputs, name="decoder")</strong><br/><strong class="of jd">Autoencoder = tf.keras.Model(inputs, decoder(encoder(inputs)),name="autoencoder")  <br/>Autoencoder.summary()</strong></span></pre><figure class="lp lq lr ls gt lt gh gi paragraph-image"><div class="gh gi oo"><img src="../Images/528f0fa1d80953ed3612ba0e922b1e0f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1110/format:webp/1*Xijj8sRuHpjcLVgPLqyD_w.png"/></div></figure><p id="48a8" class="pw-post-body-paragraph kr ks it kt b ku kv kd kw kx ky kg kz la lb lc ld le lf lg lh li lj lk ll lm im bi translated"><strong class="kt jd">训练自动编码器</strong></p><pre class="lp lq lr ls gt oe of og oh aw oi bi"><span id="434d" class="nr mp it of b gy oj ok l ol om"># SSIM Loss functtion<br/><strong class="of jd">def ssim_loss(y_true, y_pred):<br/>  return 1- tf.reduce_mean(tf.image.ssim(y_true, y_pred, 2.0))</strong></span><span id="7a4f" class="nr mp it of b gy on ok l ol om"># compile the model <br/><strong class="of jd">optimizer = 'adam'<br/>Autoencoder.compile(optimizer=optimizer, loss=ssim_loss, )</strong></span><span id="3e2b" class="nr mp it of b gy on ok l ol om">#training<br/><strong class="of jd">Autoencoder.fit(x_train, x_train, batch_size=64, epochs=20)</strong></span></pre><p id="1d63" class="pw-post-body-paragraph kr ks it kt b ku kv kd kw kx ky kg kz la lb lc ld le lf lg lh li lj lk ll lm im bi translated"><strong class="kt jd">使用KMeans </strong>创建编码数据的图像簇</p><p id="bfa1" class="pw-post-body-paragraph kr ks it kt b ku kv kd kw kx ky kg kz la lb lc ld le lf lg lh li lj lk ll lm im bi translated">使用编码器生成图像的压缩或编码特征</p><pre class="lp lq lr ls gt oe of og oh aw oi bi"><span id="4e60" class="nr mp it of b gy oj ok l ol om"><strong class="of jd">feature_model = tf.keras.Model(inputs=encoder.input, outputs=encoder.output)<br/>features = feature_model.predict(x_test)</strong></span></pre><p id="2ca1" class="pw-post-body-paragraph kr ks it kt b ku kv kd kw kx ky kg kz la lb lc ld le lf lg lh li lj lk ll lm im bi translated">绘制原始图像和作为编码器输出的压缩图像</p><pre class="lp lq lr ls gt oe of og oh aw oi bi"><span id="f029" class="nr mp it of b gy oj ok l ol om"><strong class="of jd">plt.figure(figsize=(20, 4))<br/>n=10<br/>for i in range(10):<br/>    ax = plt.subplot(2, n, i + 1)<br/>    plt.imshow(x_test[i].reshape(28, 28))<br/>    plt.title("Input data "+ str(y_train[i]))<br/>    ax.get_xaxis().set_visible(False)<br/>    ax.get_yaxis().set_visible(False)<br/>    <br/>    ax = plt.subplot(2, n, i + n+1)<br/>    plt.imshow(features[i].reshape(10, 1))<br/>    plt.title(" Compressed " + str(y_train[i]))<br/>    ax.get_xaxis().set_visible(False)<br/>    ax.get_yaxis().set_visible(False)</strong></span><span id="ef7d" class="nr mp it of b gy on ok l ol om"><strong class="of jd">plt.show()</strong></span></pre><figure class="lp lq lr ls gt lt gh gi paragraph-image"><div role="button" tabindex="0" class="lu lv di lw bf lx"><div class="gh gi op"><img src="../Images/f2965107b1c68d59281596364d6bbc09.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*4-KKPlgeNsMyx0IIwHpM9g.png"/></div></div><figcaption class="nm nn gj gh gi no np bd b be z dk translated">原始输入图像和图像的压缩pr编码数据</figcaption></figure><p id="3b1b" class="pw-post-body-paragraph kr ks it kt b ku kv kd kw kx ky kg kz la lb lc ld le lf lg lh li lj lk ll lm im bi translated">要从压缩数据中重建图像，请将编码特征传递给解码器</p><pre class="lp lq lr ls gt oe of og oh aw oi bi"><span id="df76" class="nr mp it of b gy oj ok l ol om"><strong class="of jd">reconstruction_model = tf.keras.Model(latent, outputs, name="decoder")<br/>recon_image = reconstruction_model.predict(features)</strong></span></pre><figure class="lp lq lr ls gt lt gh gi paragraph-image"><div role="button" tabindex="0" class="lu lv di lw bf lx"><div class="gh gi oq"><img src="../Images/ccdfedb9e724f4203cb77f57c526637c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*bdfjNXd5M_7vCcStZ3GRjg.png"/></div></div></figure><h2 id="f183" class="nr mp it bd mq ns nt dn mu nu nv dp my la nw nx na le ny nz nc li oa ob ne iz bi translated">对编码要素运行KMeans聚类</h2><p id="e123" class="pw-post-body-paragraph kr ks it kt b ku ng kd kw kx nh kg kz la ni lc ld le nj lg lh li nk lk ll lm im bi translated">正如我们所知，时尚MNIST有10个类别，对编码的要素运行KMeans聚类算法以聚类成10个不同的类</p><pre class="lp lq lr ls gt oe of og oh aw oi bi"><span id="5a0d" class="nr mp it of b gy oj ok l ol om"><strong class="of jd">from sklearn.cluster import KMeans<br/>kmeans_img = KMeans(n_clusters=10, init='k-means++', max_iter=10000, n_init=20, random_state=0)<br/>y_means_img = kmeans_img.fit_predict(features)</strong></span></pre><p id="7a17" class="pw-post-body-paragraph kr ks it kt b ku kv kd kw kx ky kg kz la lb lc ld le lf lg lh li lj lk ll lm im bi translated"><strong class="kt jd">重建每个聚类中的图像</strong></p><pre class="lp lq lr ls gt oe of og oh aw oi bi"><span id="e739" class="nr mp it of b gy oj ok l ol om"><strong class="of jd">test_x_predictions = Autoencoder.predict(x_test)</strong></span></pre><p id="d673" class="pw-post-body-paragraph kr ks it kt b ku kv kd kw kx ky kg kz la lb lc ld le lf lg lh li lj lk ll lm im bi translated"><strong class="kt jd">重建每个类别的样本图像</strong></p><p id="c4a1" class="pw-post-body-paragraph kr ks it kt b ku kv kd kw kx ky kg kz la lb lc ld le lf lg lh li lj lk ll lm im bi translated">为了方便起见，我在这里用y_train来表示类9，它是一个踝靴。</p><p id="7c82" class="pw-post-body-paragraph kr ks it kt b ku kv kd kw kx ky kg kz la lb lc ld le lf lg lh li lj lk ll lm im bi translated">对于自定义数据集，您可以使用每个类中的一些样本图像。</p><pre class="lp lq lr ls gt oe of og oh aw oi bi"><span id="0a1c" class="nr mp it of b gy oj ok l ol om"><strong class="of jd">train_filter = [key for (key, label) in enumerate(y_train) if int(label) == 9 ]<br/>train_x_pred= Autoencoder.predict(x_train[train_filter])</strong></span></pre><p id="ad5b" class="pw-post-body-paragraph kr ks it kt b ku kv kd kw kx ky kg kz la lb lc ld le lf lg lh li lj lk ll lm im bi translated">您可以遍历不同的集群进行比较。出于演示的目的，我硬编码了一个与踝靴图像相匹配的集群。</p><pre class="lp lq lr ls gt oe of og oh aw oi bi"><span id="6c56" class="nr mp it of b gy oj ok l ol om"><strong class="of jd">selected_col=data_cluster.index[data_cluster['cluster'] ==6]</strong></span></pre><p id="6ec1" class="pw-post-body-paragraph kr ks it kt b ku kv kd kw kx ky kg kz la lb lc ld le lf lg lh li lj lk ll lm im bi translated">如果样本图像和聚类中的图像之间的重建损失小于阈值，则聚类中的图像属于样本图像的类别。</p><p id="59e8" class="pw-post-body-paragraph kr ks it kt b ku kv kd kw kx ky kg kz la lb lc ld le lf lg lh li lj lk ll lm im bi translated">样本图像和属于正确聚类的图像之间的SSIM损失应该最小。</p><pre class="lp lq lr ls gt oe of og oh aw oi bi"><span id="eb39" class="nr mp it of b gy oj ok l ol om"><strong class="of jd">SSIM_THRESHOLD=0.3<br/>for i in range(len(selected_col)):<br/>    if ssim_loss(test_x_predictions[selected_col[i]],train_x_pred[i])&lt;SSIM_THRESHOLD: <br/>   good_labeled_image_idx.append(selected_col[i])</strong></span></pre><figure class="lp lq lr ls gt lt gh gi paragraph-image"><div role="button" tabindex="0" class="lu lv di lw bf lx"><div class="gh gi or"><img src="../Images/58551f24d2db85fefa04a4ee375c0c57.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*idsrDCaD0ydBeTo3V2zRNw.png"/></div></div></figure><p id="029a" class="pw-post-body-paragraph kr ks it kt b ku kv kd kw kx ky kg kz la lb lc ld le lf lg lh li lj lk ll lm im bi translated">可以玩阈值。下面的输出显示了当您增加SSIM损失阈值时，看起来相似但不属于同一类的图像将如何添加。你会发现更多的图像，但其中一些会被错误标记。</p><pre class="lp lq lr ls gt oe of og oh aw oi bi"><span id="466d" class="nr mp it of b gy oj ok l ol om"><strong class="of jd">SSIM_THRESHOLD=0.8<br/>for i in range(len(selected_col)):<br/>    if ssim_loss(test_x_predictions[selected_col[i]],train_x_pred[i])&lt;SSIM_THRESHOLD: <br/>        good_labeled_image_idx.append(selected_col[i])</strong></span></pre><figure class="lp lq lr ls gt lt gh gi paragraph-image"><div class="gh gi os"><img src="../Images/b7aa8c24edbc362040bebcf8f6042a96.png" data-original-src="https://miro.medium.com/v2/resize:fit:1346/format:webp/1*-csjUINJ9V3AvLqAJ6EF2Q.png"/></div></figure><p id="5d28" class="pw-post-body-paragraph kr ks it kt b ku kv kd kw kx ky kg kz la lb lc ld le lf lg lh li lj lk ll lm im bi translated">随着SSIM阈值的增加，您将识别出更多的图像，但图像会被错误标记，如下所示</p><figure class="lp lq lr ls gt lt gh gi paragraph-image"><div role="button" tabindex="0" class="lu lv di lw bf lx"><div class="gh gi ot"><img src="../Images/70ecd562f4571d89132619aa78489e53.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*CSz6-EQv_msKH91kIOLdiA.png"/></div></div></figure><p id="c5cc" class="pw-post-body-paragraph kr ks it kt b ku kv kd kw kx ky kg kz la lb lc ld le lf lg lh li lj lk ll lm im bi translated">分享您使用机器学习算法标记数据的经验，以及您面临的挑战。</p></div></div>    
</body>
</html>