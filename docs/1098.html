<html>
<head>
<title>Matrices in Data Science Are Always Real and Symmetric</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">数据科学中的矩阵总是实的和对称的</h1>
<blockquote>原文：<a href="https://pub.towardsai.net/matrices-in-data-science-are-always-real-and-symmetric-67dbf910213f?source=collection_archive---------2-----------------------#2020-10-29">https://pub.towardsai.net/matrices-in-data-science-are-always-real-and-symmetric-67dbf910213f?source=collection_archive---------2-----------------------#2020-10-29</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><figure class="is it gp gr iu iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi ir"><img src="../Images/7d7d30056dd9693c65aec7351a67fdfb.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*alZ0zfHJCEJMywm_QzKY9g.png"/></div></div><figcaption class="jc jd gj gh gi je jf bd b be z dk translated">Benjamin O. Tayo的图片</figcaption></figure><h2 id="ab10" class="jg jh ji bd b dl jj jk jl jm jn jo dk jp translated" aria-label="kicker paragraph"><a class="ae ep" href="https://towardsai.net/p/category/data-science" rel="noopener ugc nofollow" target="_blank">数据科学</a></h2><div class=""/><div class=""><h2 id="4855" class="pw-subtitle-paragraph ko jr ji bd b kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf dk translated">因为数据科学处理现实世界的问题，所以数据科学中的矩阵必须是实的和对称的</h2></div><h1 id="a3c1" class="lg lh ji bd li lj lk ll lm ln lo lp lq kx lr ky ls la lt lb lu ld lv le lw lx bi translated">介绍</h1><p id="7c8b" class="pw-post-body-paragraph ly lz ji ma b mb mc ks md me mf kv mg mh mi mj mk ml mm mn mo mp mq mr ms mt im bi translated">线性代数是数学的一个分支，在数据科学和机器学习中非常有用。大多数机器学习模型都可以用矩阵形式表示。因为数据科学处理的是现实世界的问题，所以数据科学中的矩阵必须是实的和对称的。对此也有一些例外。在图像处理等高级数据科学模型中，傅立叶分析被大量使用。因此，人们很容易遇到定义在复数空间上的矩阵。除此之外，对于大多数基本的数据科学和机器学习问题，遇到的矩阵总是实的和对称的。</p><p id="fddd" class="pw-post-body-paragraph ly lz ji ma b mb mu ks md me mv kv mg mh mw mj mk ml mx mn mo mp my mr ms mt im bi translated">在本文中，我们将考虑数据科学和机器学习中经常遇到的三个实对称矩阵模型的例子，即回归矩阵(<strong class="ma js">R</strong>)；协方差矩阵和线性判别分析矩阵(<strong class="ma js"> L </strong>)。</p><h1 id="f4ed" class="lg lh ji bd li lj lk ll lm ln lo lp lq kx lr ky ls la lt lb lu ld lv le lw lx bi translated">示例1:线性回归矩阵</h1><p id="7213" class="pw-post-body-paragraph ly lz ji ma b mb mc ks md me mf kv mg mh mi mj mk ml mm mn mo mp mq mr ms mt im bi translated">假设我们有一个包含4个预测要素和<em class="mz"> n </em>个观测值的数据集，如下所示。</p><figure class="nb nc nd ne gt iv gh gi paragraph-image"><div class="gh gi na"><img src="../Images/18462aa1dd29b44038750739c0fa549d.png" data-original-src="https://miro.medium.com/v2/resize:fit:836/format:webp/1*ziCm_w3q0a6fw0767fCrOg.png"/></div><figcaption class="jc jd gj gh gi je jf bd b be z dk translated"><strong class="bd li">表1 </strong>。具有4个变量和n个观察值的特征矩阵。第5列是目标变量(y)。</figcaption></figure><p id="539c" class="pw-post-body-paragraph ly lz ji ma b mb mu ks md me mv kv mg mh mw mj mk ml mx mn mo mp my mr ms mt im bi translated">我们希望构建一个多元回归模型来预测<em class="mz"> y </em>值(第5列)。因此，我们的模型可以表示为</p><figure class="nb nc nd ne gt iv gh gi paragraph-image"><div class="gh gi nf"><img src="../Images/1b931e427f76713e18f8460a83679e35.png" data-original-src="https://miro.medium.com/v2/resize:fit:1252/format:webp/1*OaDyXuSI15wWveI4r28a8Q.png"/></div></figure><p id="6897" class="pw-post-body-paragraph ly lz ji ma b mb mu ks md me mv kv mg mh mw mj mk ml mx mn mo mp my mr ms mt im bi translated">在矩阵形式中，该方程可以写成</p><figure class="nb nc nd ne gt iv gh gi paragraph-image"><div class="gh gi ng"><img src="../Images/d401e3e0f1853fd0a0c137012de6325a.png" data-original-src="https://miro.medium.com/v2/resize:fit:690/format:webp/1*AuThhaPyZ6yxdShBtL6ayw.png"/></div></figure><p id="a42b" class="pw-post-body-paragraph ly lz ji ma b mb mu ks md me mv kv mg mh mw mj mk ml mx mn mo mp my mr ms mt im bi translated">其中<strong class="ma js"> X </strong>是(n×4)特征矩阵，<strong class="ma js"> w </strong>是表示待确定回归系数的(4×1)矩阵，<strong class="ma js"> y </strong>是包含目标变量y的n个观测值的(n×1)矩阵。</p><p id="41e4" class="pw-post-body-paragraph ly lz ji ma b mb mu ks md me mv kv mg mh mw mj mk ml mx mn mo mp my mr ms mt im bi translated">注意<strong class="ma js"> X </strong>是一个矩形矩阵，所以我们不能通过取<strong class="ma js"> X </strong>的逆来解上面的方程。</p><p id="c3ec" class="pw-post-body-paragraph ly lz ji ma b mb mu ks md me mv kv mg mh mw mj mk ml mx mn mo mp my mr ms mt im bi translated">为了将<strong class="ma js"> X </strong>转换成方阵，我们通过<strong class="ma js"> X </strong>的<strong class="ma js">转置</strong>将等式的左侧和右侧相乘，即</p><figure class="nb nc nd ne gt iv gh gi paragraph-image"><div class="gh gi nh"><img src="../Images/589998ea67bc8b5f4b6252f61c562308.png" data-original-src="https://miro.medium.com/v2/resize:fit:604/format:webp/1*whmEdLsnt17pWw1t-yj8Tg.png"/></div></figure><p id="26d0" class="pw-post-body-paragraph ly lz ji ma b mb mu ks md me mv kv mg mh mw mj mk ml mx mn mo mp my mr ms mt im bi translated">这个等式也可以表示为</p><figure class="nb nc nd ne gt iv gh gi paragraph-image"><div class="gh gi ni"><img src="../Images/e06c9e1b9af2f2361447f8f24bece7c1.png" data-original-src="https://miro.medium.com/v2/resize:fit:518/format:webp/1*B2S6yCxij2wCGw9USZMtwA.png"/></div></figure><p id="c8a7" class="pw-post-body-paragraph ly lz ji ma b mb mu ks md me mv kv mg mh mw mj mk ml mx mn mo mp my mr ms mt im bi translated">在哪里</p><figure class="nb nc nd ne gt iv gh gi paragraph-image"><div class="gh gi nj"><img src="../Images/7b63cdfa1a36e84704c94a69ee8a5b96.png" data-original-src="https://miro.medium.com/v2/resize:fit:564/format:webp/1*800J3EjWL9KcC6hhk31Aqg.png"/></div></figure><p id="ae3a" class="pw-post-body-paragraph ly lz ji ma b mb mu ks md me mv kv mg mh mw mj mk ml mx mn mo mp my mr ms mt im bi translated">是(4 x 4)回归矩阵。显然，我们观察到<strong class="ma js"> R </strong>是一个实对称矩阵。请注意，在线性代数中，两个矩阵乘积的转置遵循以下关系</p><figure class="nb nc nd ne gt iv gh gi paragraph-image"><div class="gh gi nk"><img src="../Images/0459f251d56d7f7a6f8c001f5512401e.png" data-original-src="https://miro.medium.com/v2/resize:fit:586/format:webp/1*24BzYhiisTN7YoBjJixM8Q.png"/></div></figure><p id="1267" class="pw-post-body-paragraph ly lz ji ma b mb mu ks md me mv kv mg mh mw mj mk ml mx mn mo mp my mr ms mt im bi translated">既然我们已经简化了回归问题，并用(4x4)实数、对称且可逆的回归矩阵<strong class="ma js"> R </strong>来表示它，那么就可以直接表明回归方程的精确解是</p><figure class="nb nc nd ne gt iv gh gi paragraph-image"><div class="gh gi nl"><img src="../Images/66139e980c34a28859b6afd9391ce1b6.png" data-original-src="https://miro.medium.com/v2/resize:fit:684/format:webp/1*OMp11CPlH8KuhIkP2CfRGw.png"/></div></figure><h1 id="25cb" class="lg lh ji bd li lj lk ll lm ln lo lp lq kx lr ky ls la lt lb lu ld lv le lw lx bi translated">示例2:协方差矩阵</h1><p id="bb58" class="pw-post-body-paragraph ly lz ji ma b mb mc ks md me mf kv mg mh mi mj mk ml mm mn mo mp mq mr ms mt im bi translated">假设我们有一个高度相关的特征矩阵，其中有<em class="mz"> 4个</em>特征和<em class="mz"> n个</em>观察值，如下面的<strong class="ma js">表2 </strong>所示:</p><figure class="nb nc nd ne gt iv gh gi paragraph-image"><div class="gh gi nm"><img src="../Images/40a29fa2b8df72dfc410acb6e73ae49b.png" data-original-src="https://miro.medium.com/v2/resize:fit:514/format:webp/0*w5gIgKOwjinWsrFp.png"/></div><figcaption class="jc jd gj gh gi je jf bd b be z dk translated"><strong class="bd li">表二</strong>。具有4个变量和n个观察值的特征矩阵</figcaption></figure><p id="9e3e" class="pw-post-body-paragraph ly lz ji ma b mb mu ks md me mv kv mg mh mw mj mk ml mx mn mo mp my mr ms mt im bi translated">为了可视化特征之间的相关性，我们可以生成一个散点图。要量化要素之间的相关程度(多重共线性)，我们可以使用以下公式计算协方差矩阵:</p><figure class="nb nc nd ne gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi nn"><img src="../Images/8a576fd7c79705949d16323e8db51b28.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*Lu5nXecb6OzUF18o.png"/></div></div></figure><p id="d876" class="pw-post-body-paragraph ly lz ji ma b mb mu ks md me mv kv mg mh mw mj mk ml mx mn mo mp my mr ms mt im bi translated">在矩阵形式中，协方差矩阵可以表示为4 x 4实对称矩阵:</p><figure class="nb nc nd ne gt iv gh gi paragraph-image"><div class="gh gi no"><img src="../Images/256e937ea6e64e1811f4975998f9f563.png" data-original-src="https://miro.medium.com/v2/resize:fit:1360/format:webp/0*MhDmyZdzNYae-bX1.png"/></div></figure><p id="901d" class="pw-post-body-paragraph ly lz ji ma b mb mu ks md me mv kv mg mh mw mj mk ml mx mn mo mp my mr ms mt im bi translated">我们再次看到，协变矩阵是实的和对称的。可以通过执行酉变换(也称为主成分分析(PCA)变换)来对角化该矩阵，以获得以下内容:</p><figure class="nb nc nd ne gt iv gh gi paragraph-image"><div class="gh gi np"><img src="../Images/d914724490a1a032a5ff7fe02b0c1cfb.png" data-original-src="https://miro.medium.com/v2/resize:fit:1024/format:webp/0*gq5bIdrDN5CQXfbT.png"/></div></figure><p id="2952" class="pw-post-body-paragraph ly lz ji ma b mb mu ks md me mv kv mg mh mw mj mk ml mx mn mo mp my mr ms mt im bi translated">由于矩阵的迹在酉变换下保持不变，我们观察到对角矩阵的特征值之和等于包含在特征X1、X2、X3和X4中的总方差。</p><h1 id="2d8a" class="lg lh ji bd li lj lk ll lm ln lo lp lq kx lr ky ls la lt lb lu ld lv le lw lx bi translated">例3:线性判别分析矩阵</h1><p id="e391" class="pw-post-body-paragraph ly lz ji ma b mb mc ks md me mf kv mg mh mi mj mk ml mm mn mo mp mq mr ms mt im bi translated">数据科学中实对称矩阵的另一个例子是线性判别分析(LDA)矩阵。这个矩阵可以用以下形式表示</p><figure class="nb nc nd ne gt iv gh gi paragraph-image"><div class="gh gi nq"><img src="../Images/360ef6140199eee235c9262a4af94d87.png" data-original-src="https://miro.medium.com/v2/resize:fit:738/format:webp/1*FyoBjD7a6CQ7lLggKhqTsg.png"/></div></figure><p id="db5b" class="pw-post-body-paragraph ly lz ji ma b mb mu ks md me mv kv mg mh mw mj mk ml mx mn mo mp my mr ms mt im bi translated">其中<strong class="ma js"> S_W </strong>是特征内散布矩阵，<strong class="ma js"> S_B </strong>是特征间散布矩阵。由于矩阵<strong class="ma js"> S_W </strong>和<strong class="ma js"> S_B </strong>都是实对称的，因此<strong class="ma js"> L </strong>也是实对称的。<strong class="ma js"> L </strong>的对角化产生了一个优化类可分性和降维的特征子空间。因此，LDA是一种监督算法，而PCA不是。</p><p id="980e" class="pw-post-body-paragraph ly lz ji ma b mb mu ks md me mv kv mg mh mw mj mk ml mx mn mo mp my mr ms mt im bi translated">有关LDA实施的更多详细信息，请参见以下参考资料:</p><p id="f142" class="pw-post-body-paragraph ly lz ji ma b mb mu ks md me mv kv mg mh mw mj mk ml mx mn mo mp my mr ms mt im bi translated"><a class="ae nr" href="https://medium.com/towards-artificial-intelligence/machine-learning-dimensionality-reduction-via-linear-discriminant-analysis-cc96b49d2757" rel="noopener">机器学习:通过线性判别分析降维</a></p><p id="2e31" class="pw-post-body-paragraph ly lz ji ma b mb mu ks md me mv kv mg mh mw mj mk ml mx mn mo mp my mr ms mt im bi translated"><a class="ae nr" href="https://github.com/bot13956/linear-discriminant-analysis-iris-dataset" rel="noopener ugc nofollow" target="_blank">使用Iris数据集实施LDA的GitHub存储库</a></p><p id="545b" class="pw-post-body-paragraph ly lz ji ma b mb mu ks md me mv kv mg mh mw mj mk ml mx mn mo mp my mr ms mt im bi translated"><a class="ae nr" href="https://github.com/rasbt/python-machine-learning-book-3rd-edition" rel="noopener ugc nofollow" target="_blank">塞巴斯蒂安·拉什卡的《Python机器学习》，第3版(第5章)</a></p><h1 id="a303" class="lg lh ji bd li lj lk ll lm ln lo lp lq kx lr ky ls la lt lb lu ld lv le lw lx bi translated">摘要</h1><p id="f397" class="pw-post-body-paragraph ly lz ji ma b mb mc ks md me mf kv mg mh mi mj mk ml mm mn mo mp mq mr ms mt im bi translated">总之，我们已经讨论了数据科学和机器学习中实矩阵和对称矩阵的三个例子，即回归矩阵(<strong class="ma js">R</strong>)；协方差矩阵和线性判别分析矩阵(<strong class="ma js"> L </strong>)。因为数据科学处理的是现实世界的问题，所以数据科学中的矩阵必须是实的和对称的。</p><h1 id="386e" class="lg lh ji bd li lj lk ll lm ln lo lp lq kx lr ky ls la lt lb lu ld lv le lw lx bi translated">其他数据科学/机器学习资源</h1><p id="0d66" class="pw-post-body-paragraph ly lz ji ma b mb mc ks md me mf kv mg mh mi mj mk ml mm mn mo mp mq mr ms mt im bi translated">数据科学需要多少数学知识？</p><p id="cc0b" class="pw-post-body-paragraph ly lz ji ma b mb mu ks md me mv kv mg mh mw mj mk ml mx mn mo mp my mr ms mt im bi translated"><a class="ae nr" href="https://medium.com/towards-artificial-intelligence/data-science-curriculum-bf3bb6805576" rel="noopener">数据科学课程</a></p><p id="b7ff" class="pw-post-body-paragraph ly lz ji ma b mb mu ks md me mv kv mg mh mw mj mk ml mx mn mo mp my mr ms mt im bi translated"><a class="ae nr" href="https://towardsdatascience.com/5-best-degrees-for-getting-into-data-science-c3eb067883b1" rel="noopener" target="_blank">进入数据科学的5个最佳学位</a></p><p id="2111" class="pw-post-body-paragraph ly lz ji ma b mb mu ks md me mv kv mg mh mw mj mk ml mx mn mo mp my mr ms mt im bi translated"><a class="ae nr" href="https://towardsdatascience.com/theoretical-foundations-of-data-science-should-i-care-or-simply-focus-on-hands-on-skills-c53fb0caba66" rel="noopener" target="_blank">数据科学的理论基础——我应该关心还是仅仅关注实践技能？</a></p><p id="4dd6" class="pw-post-body-paragraph ly lz ji ma b mb mu ks md me mv kv mg mh mw mj mk ml mx mn mo mp my mr ms mt im bi translated"><a class="ae nr" href="https://towardsdatascience.com/machine-learning-project-planning-71bdb3a44349" rel="noopener" target="_blank">机器学习项目规划</a></p><p id="bf62" class="pw-post-body-paragraph ly lz ji ma b mb mu ks md me mv kv mg mh mw mj mk ml mx mn mo mp my mr ms mt im bi translated"><a class="ae nr" href="https://towardsdatascience.com/how-to-organize-your-data-science-project-dd6599cf000a" rel="noopener" target="_blank">如何组织你的数据科学项目</a></p><p id="04c1" class="pw-post-body-paragraph ly lz ji ma b mb mu ks md me mv kv mg mh mw mj mk ml mx mn mo mp my mr ms mt im bi translated"><a class="ae nr" href="https://medium.com/towards-artificial-intelligence/productivity-tools-for-large-scale-data-science-projects-64810dfbb971" rel="noopener">大型数据科学项目的生产力工具</a></p><p id="0ae7" class="pw-post-body-paragraph ly lz ji ma b mb mu ks md me mv kv mg mh mw mj mk ml mx mn mo mp my mr ms mt im bi translated"><a class="ae nr" href="https://towardsdatascience.com/a-data-science-portfolio-is-more-valuable-than-a-resume-2d031d6ce518" rel="noopener" target="_blank">数据科学作品集比简历更有价值</a></p><p id="daf6" class="pw-post-body-paragraph ly lz ji ma b mb mu ks md me mv kv mg mh mw mj mk ml mx mn mo mp my mr ms mt im bi translated"><strong class="ma js"> <em class="mz">如有疑问，请发邮件给我</em></strong>:benjaminobi@gmail.com</p></div></div>    
</body>
</html>