<html>
<head>
<title>This AI newsletter is all you need #13</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">这份人工智能时事通讯是你所需要的#13</h1>
<blockquote>原文：<a href="https://pub.towardsai.net/this-ai-newsletter-is-all-you-need-13-839bbe1aa38e?source=collection_archive---------2-----------------------#2022-09-20">https://pub.towardsai.net/this-ai-newsletter-is-all-you-need-13-839bbe1aa38e?source=collection_archive---------2-----------------------#2022-09-20</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><h1 id="17c4" class="jn jo iq bd jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk bi translated">这个星期在AI发生了什么</h1><p id="a118" class="pw-post-body-paragraph kl km iq kn b ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li ij bi translated">本周，我的注意力集中在艾玛德和他的团队所做的令人惊叹的工作上。本周，艾玛德<a class="ae lj" href="https://twitter.com/emostaque/status/1570501470751174656" rel="noopener ugc nofollow" target="_blank">宣布了OpenCLIP </a>，这是一个开源版本的CLIP，它击败了最先进的CLIP结果，改进了文本-图像编码对，这对当前的研究产生了巨大的影响，因为这样一个预先训练的开源模型将被数千名研究人员用来创建涉及图像和文本的惊人的新应用程序和模型。</p><p id="cf94" class="pw-post-body-paragraph kl km iq kn b ko lk kq kr ks ll ku kv kw lm ky kz la ln lc ld le lo lg lh li ij bi translated"><a class="ae lj" href="https://laion.ai/blog/large-openclip/" rel="noopener ugc nofollow" target="_blank"> OpenCLIP </a>到底是什么？OpenCLIP是OpenAI的CLIP(对比语言-图像预训练)的开源实现。他们到底带来了什么？为什么这很酷？这很酷，因为，作为稳定扩散，他们的目标是把CLIP带给你，普通的研究人员(就计算资源而言，而不是就技能而言，如果你正在阅读这篇文章，你肯定比普通的研究人员强！😉).这意味着他们希望能够训练/促进具有对比图像-文本监督的模型的研究。正如他们提到的，“我们的出发点是CLIP的实现，当在相同的数据集上训练时，它与原始剪辑模型的准确性相匹配。”这意味着他们带来了许多新的SOTA预训练模型，由于更有效的实现和开源代码，您可以实现这些模型(见下文)。查看<a class="ae lj" href="https://github.com/mlfoundations/open_clip" rel="noopener ugc nofollow" target="_blank">他们的知识库</a>以了解更多并实现他们的模型！</p><figure class="lq lr ls lt gt lu gh gi paragraph-image"><div role="button" tabindex="0" class="lv lw di lx bf ly"><div class="gh gi lp"><img src="../Images/d6328801894910101f39a79354e07916.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*XXs8h779dBhanbmF"/></div></div></figure><h2 id="38bb" class="mb jo iq bd jp mc md dn jt me mf dp jx kw mg mh kb la mi mj kf le mk ml kj mm bi translated">最热门新闻</h2><ol class=""><li id="914a" class="mn mo iq kn b ko kp ks kt kw mp la mq le mr li ms mt mu mv bi translated"><a class="ae lj" href="https://github.com/divamgupta/diffusionbee-stable-diffusion-ui" rel="noopener ugc nofollow" target="_blank">扩散蜂，一款稳定的M1 MAC的扩散GUI App！<br/></a>“Diffusion Bee是在您的M1 Mac上运行稳定扩散的最简单方法。附带一键安装程序。不需要依赖或技术知识。”</li><li id="4b69" class="mn mo iq kn b ko mw ks mx kw my la mz le na li ms mt mu mv bi translated">麻省理工学院的研究人员让DALL-E更有创意！正如这篇文章所强调的，研究人员开发了一种新方法，使用多个模型来创建更复杂的图像，以便更好地理解。这种方法称为可组合扩散，通过使用一组扩散模型生成图像来获得更好的结果，每个模型负责对图像的特定组件进行建模。</li><li id="6735" class="mn mo iq kn b ko mw ks mx kw my la mz le na li ms mt mu mv bi translated">我在2022年的《正午》节目中获得提名！<br/> 如果你能在那里支持我，并为我喜欢的作品投票，我将不胜感激！(科技YouTube和数据科学时事通讯都有)。提前感谢这个神奇的社区！😊🙏<br/>YT:<a class="ae lj" href="https://www.noonies.tech/2022/emerging-tech/2022-top-tech-youtuber" rel="noopener ugc nofollow" target="_blank">https://www . noon ies . tech/2022/emerging-tech/2022-top-tech-youtuber<br/></a>快讯:<a class="ae lj" href="https://www.noonies.tech/2022/emerging-tech/2022-best-data-science-newsletter" rel="noopener ugc nofollow" target="_blank">https://www . noon ies . tech/2022/emerging-tech/2022-best-data-science-Newsletter</a></li></ol><p id="e94b" class="pw-post-body-paragraph kl km iq kn b ko lk kq kr ks ll ku kv kw lm ky kz la ln lc ld le lo lg lh li ij bi translated">感谢<a class="ae lj" href="https://ws.towardsai.net/ywu" rel="noopener ugc nofollow" target="_blank">三角洲学院</a>为您带来这一期:</p><figure class="lq lr ls lt gt lu gh gi paragraph-image"><a href="http://ws.towardsai.net/ywu"><div class="gh gi nb"><img src="../Images/d05d25cac6bb413fa3ae1952820c0e57.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*wJ96gEzC_yjtc7pY"/></div></a></figure><h2 id="64e8" class="mb jo iq bd jp mc md dn jt me mf dp jx kw mg mh kb la mi mj kf le mk ml kj mm bi translated">本周最有趣的报纸</h2><ol class=""><li id="8bd2" class="mn mo iq kn b ko kp ks kt kw mp la mq le mr li ms mt mu mv bi translated"><a class="ae lj" href="https://arxiv.org/pdf/2209.04061.pdf" rel="noopener ugc nofollow" target="_blank">im 2 nerf:Image to Neural Radiance Field in the Wild<br/></a>一种学习框架，在给定野外单个输入图像的情况下，预测连续的神经对象表示，仅由现有识别方法的分割输出进行监督。</li><li id="66be" class="mn mo iq kn b ko mw ks mx kw my la mz le na li ms mt mu mv bi translated"><a class="ae lj" href="https://arxiv.org/pdf/2209.07511.pdf" rel="noopener ugc nofollow" target="_blank">视觉语言模型中零镜头泛化的测试时提示调优<br/> </a>测试时提示调优(TPT):一种可以用单个测试样本动态学习自适应提示的方法。</li><li id="3e19" class="mn mo iq kn b ko mw ks mx kw my la mz le na li ms mt mu mv bi translated"><a class="ae lj" href="https://arxiv.org/pdf/2209.06192.pdf" rel="noopener ugc nofollow" target="_blank"> StoryDALL-E:为故事延续调整预训练的文本到图像转换器<br/> </a>“我们首先提出故事延续的任务，其中生成的视觉故事以源图像为条件，允许更好地推广到具有新角色的叙事。[……]我们的工作表明，预训练的文本到图像合成模型可以适用于复杂和低资源的任务，如故事延续。”</li></ol><p id="c244" class="pw-post-body-paragraph kl km iq kn b ko lk kq kr ks ll ku kv kw lm ky kz la ln lc ld le lo lg lh li ij bi translated">喜欢这些论文和新闻摘要吗？ <a class="ae lj" href="https://www.linkedin.com/newsletters/what-s-ai-daily-research-tl-dr-6935956459641876480/" rel="noopener ugc nofollow" target="_blank"> <em class="nc">在你的收件箱</em> </a> <em class="nc">中获取每日回顾！</em></p><h1 id="6189" class="jn jo iq bd jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk bi translated">一起学习人工智能社区部分！</h1><h2 id="9663" class="mb jo iq bd jp mc md dn jt me mf dp jx kw mg mh kb la mi mj kf le mk ml kj mm bi translated">本周迷因！</h2><figure class="lq lr ls lt gt lu gh gi paragraph-image"><div class="gh gi nd"><img src="../Images/0246362476608f9a5701ad260f04acab.png" data-original-src="https://miro.medium.com/v2/resize:fit:1000/0*d3rA5neMMm8EI0B3"/></div></figure><p id="326c" class="pw-post-body-paragraph kl km iq kn b ko lk kq kr ks ll ku kv kw lm ky kz la ln lc ld le lo lg lh li ij bi translated">哦不…</p><p id="8389" class="pw-post-body-paragraph kl km iq kn b ko lk kq kr ks ll ku kv kw lm ky kz la ln lc ld le lo lg lh li ij bi translated">EDA代表探索性数据分析，是在考虑应用哪个模型之前调查将在ML模型中使用的数据的过程。</p><p id="0ec6" class="pw-post-body-paragraph kl km iq kn b ko lk kq kr ks ll ku kv kw lm ky kz la ln lc ld le lo lg lh li ij bi translated"><a class="ae lj" href="https://discord.com/channels/702624558536065165/830572933197201459/1019761572110934067" rel="noopener ugc nofollow" target="_blank"> friedliver#0614 </a>分享的Meme。</p><h2 id="8246" class="mb jo iq bd jp mc md dn jt me mf dp jx kw mg mh kb la mi mj kf le mk ml kj mm bi translated">来自Discord的特色社区帖子</h2><figure class="lq lr ls lt gt lu gh gi paragraph-image"><div role="button" tabindex="0" class="lv lw di lx bf ly"><div class="gh gi ne"><img src="../Images/dd3e4400f020ea051dbad97f3153d13c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*G5dkeSgWsD0_OU0M"/></div></div></figure><p id="7ebe" class="pw-post-body-paragraph kl km iq kn b ko lk kq kr ks ll ku kv kw lm ky kz la ln lc ld le lo lg lh li ij bi translated">来自Learn AI社区的deep2universe#6939 的一个很酷的<a class="ae lj" href="https://discord.com/channels/702624558536065165/702632051018301561/1020978060469743710" rel="noopener ugc nofollow" target="_blank">项目。该算法将在任何YouTube视频上运行，并对视频中的人进行姿势和运动检测。相当酷！正如他提到的，不幸的是，作者不得不停止扩展的开发，但开源代码供进一步使用。我们强烈鼓励任何希望解决一个有趣项目的人联系deep2universe on discord，接受他的工作。对于对计算机视觉感兴趣的人来说，这是一个非常棒的项目，尤其是运动或姿态检测。</a></p><p id="30d4" class="pw-post-body-paragraph kl km iq kn b ko lk kq kr ks ll ku kv kw lm ky kz la ln lc ld le lo lg lh li ij bi translated">观看更多演示视频:</p><figure class="lq lr ls lt gt lu"><div class="bz fp l di"><div class="nf ng l"/></div></figure><p id="3d6a" class="pw-post-body-paragraph kl km iq kn b ko lk kq kr ks ll ku kv kw lm ky kz la ln lc ld le lo lg lh li ij bi translated">下载<a class="ae lj" href="https://chrome.google.com/webstore/detail/youtube-motion-tracking/cpjloofnnmchhbdbdchjnhfoclnjliga" rel="noopener ugc nofollow" target="_blank">的Chrome扩展</a>。</p><p id="8899" class="pw-post-body-paragraph kl km iq kn b ko lk kq kr ks ll ku kv kw lm ky kz la ln lc ld le lo lg lh li ij bi translated">查看代码:</p><div class="nh ni gp gr nj nk"><a href="https://github.com/deep2universe/YouTube-Motion-Tracking" rel="noopener  ugc nofollow" target="_blank"><div class="nl ab fo"><div class="nm ab nn cl cj no"><h2 class="bd ir gy z fp np fr fs nq fu fw ip bi translated">GitHub-deep 2 universe/YouTube-运动跟踪:用于运动跟踪的YouTube AI扩展</h2><div class="nr l"><h3 class="bd b gy z fp np fr fs nq fu fw dk translated">这个视频源的一些例子标志是由一个3岁的女孩设计的。YouTube运动跟踪是一个Chrome…</h3></div><div class="ns l"><p class="bd b dl z fp np fr fs nq fu fw dk translated">github.com</p></div></div><div class="nt l"><div class="nu l nv nw nx nt ny lz nk"/></div></div></a></div><h2 id="8304" class="mb jo iq bd jp mc md dn jt me mf dp jx kw mg mh kb la mi mj kf le mk ml kj mm bi translated">本周最佳人工智能投票！</h2><figure class="lq lr ls lt gt lu gh gi paragraph-image"><div class="gh gi nz"><img src="../Images/5539165156865cd1baccf1e3f4fbab43.png" data-original-src="https://miro.medium.com/v2/resize:fit:1190/0*jsIgZiCt53DC4u7X"/></div></figure><p id="931e" class="pw-post-body-paragraph kl km iq kn b ko lk kq kr ks ll ku kv kw lm ky kz la ln lc ld le lo lg lh li ij bi translated">你认为周末、工作日或两者都工作怎么样？<a class="ae lj" href="https://discord.com/channels/702624558536065165/833660976196354079" rel="noopener ugc nofollow" target="_blank">加入关于不和的讨论</a>。</p><h1 id="3bff" class="jn jo iq bd jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk bi translated">泰策展组</h1><h2 id="9e98" class="mb jo iq bd jp mc md dn jt me mf dp jx kw mg mh kb la mi mj kf le mk ml kj mm bi translated">本周文章</h2><p id="45be" class="pw-post-body-paragraph kl km iq kn b ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li ij bi translated"><a class="ae lj" rel="noopener ugc nofollow" target="_blank" href="/difference-between-normalization-and-standardization-745030eaf96f"> <strong class="kn ir">规范化与标准化的区别</strong> </a> <strong class="kn ir"> </strong>由<a class="ae lj" href="https://chetanambi.medium.com/" rel="noopener">车谈安比</a>。<br/>机器学习管道中的一个关键过程是特征缩放。标准化和规范化是特征缩放的两种常用方法。但是它们的区别是什么，什么时候使用？这是刚开始数据科学之旅的人很常见的问题。作者用公式、可视化和代码很好地解释了不同之处。</p><h2 id="e840" class="mb jo iq bd jp mc md dn jt me mf dp jx kw mg mh kb la mi mj kf le mk ml kj mm bi translated">我们的必读文章</h2><p id="f2aa" class="pw-post-body-paragraph kl km iq kn b ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li ij bi translated"><a class="ae lj" rel="noopener ugc nofollow" target="_blank" href="/improve-your-classification-models-with-threshold-tuning-bb69fca15114">Edoardo Bianchi<a class="ae lj" href="https://medium.com/@edoardobianchi98" rel="noopener">通过阈值调整</a>改进您的分类模型</a></p><p id="0fbc" class="pw-post-body-paragraph kl km iq kn b ko lk kq kr ks ll ku kv kw lm ky kz la ln lc ld le lo lg lh li ij bi translated"><a class="ae lj" rel="noopener ugc nofollow" target="_blank" href="/imbalanced-data-real-time-bidding-6ee9c4ef957c">不平衡数据—实时投标</a>由<a class="ae lj" href="https://medium.com/@snehal.1409" rel="noopener"> Snehal Nair </a></p><p id="c4c2" class="pw-post-body-paragraph kl km iq kn b ko lk kq kr ks ll ku kv kw lm ky kz la ln lc ld le lo lg lh li ij bi translated">如果你对《走向人工智能》感兴趣，请查看我们的指南并注册。如果您的作品符合我们的编辑政策和标准，我们会将其发布到我们的网络上。</p><h2 id="0960" class="mb jo iq bd jp mc md dn jt me mf dp jx kw mg mh kb la mi mj kf le mk ml kj mm bi translated"><strong class="ak">劳伦关于增加黛尔创造力的道德观点</strong></h2><p id="09ac" class="pw-post-body-paragraph kl km iq kn b ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li ij bi translated">我认为这太不可思议了，这个模型能够坚持自然语言提示，这要感谢麻省理工学院的研究人员！但是，我不太同意一般的说法，这种能力增加了模型的创造力。这种提高似乎更多地集中在准确性上，而作为一个概念，创造性并不总是与准确性相关联。艺术往往需要打破规则或意外地工作，而这种“错误”是创作过程的一部分，往往使艺术如其本来一样令人惊叹。增加模型在线条上着色的能力并不遵循这个原则。同样，复杂性的增加也不一定与创造力的增加相关联——极其简单的事情也可能具有惊人的创造力。</p><p id="832f" class="pw-post-body-paragraph kl km iq kn b ko lk kq kr ks ll ku kv kw lm ky kz la ln lc ld le lo lg lh li ij bi translated">与我的第一个观点相反的观点可能是，在自然语言的限制下锻炼能力实际上是一种创造性的练习，而不是允许脱离脚本。然而，我要重申，打破参数比在参数范围内工作更有创造性。DALLE创作的第一波浪潮之所以如此有影响力，部分原因是缺乏对基于语言的先入为主的观念的关注(当然，除了它所接受的训练之外！).通过这种方式优化准确性，我们可能会失去一些创造性的印象。无论我们选择哪个方向，都将继续塑造我们培养创造力的尝试和人工智能数字艺术工具的未来！</p><h2 id="d114" class="mb jo iq bd jp mc md dn jt me mf dp jx kw mg mh kb la mi mj kf le mk ml kj mm bi translated">工作机会</h2><ul class=""><li id="ddbe" class="mn mo iq kn b ko kp ks kt kw mp la mq le mr li oa mt mu mv bi translated"><a class="ae lj" href="http://ws.towardsai.net/6cs" rel="noopener ugc nofollow" target="_blank"> <strong class="kn ir">高级软件工程师@ Captur </strong>(远程，±2小时英国时间)</a></li><li id="3b38" class="mn mo iq kn b ko mw ks mx kw my la mz le na li oa mt mu mv bi translated"><a class="ae lj" href="http://ws.towardsai.net/4a1" rel="noopener ugc nofollow" target="_blank"> <strong class="kn ir">高级ML工程师@安全保安</strong>(远程)</a></li><li id="86f4" class="mn mo iq kn b ko mw ks mx kw my la mz le na li oa mt mu mv bi translated"><a class="ae lj" href="http://ws.towardsai.net/qi0" rel="noopener ugc nofollow" target="_blank"><strong class="kn ir">ML/算法工程师@ Aurora Insight </strong>(混合远程)</a></li><li id="e925" class="mn mo iq kn b ko mw ks mx kw my la mz le na li oa mt mu mv bi translated"><a class="ae lj" href="http://ws.towardsai.net/6p6" rel="noopener ugc nofollow" target="_blank"> <strong class="kn ir">数据科学家@伊莱克特</strong>(远程)</a></li><li id="82e2" class="mn mo iq kn b ko mw ks mx kw my la mz le na li oa mt mu mv bi translated"><a class="ae lj" href="http://ws.towardsai.net/0s4" rel="noopener ugc nofollow" target="_blank"> <strong class="kn ir"> ML研究实习生@ Genesis Therapeutics </strong>(加州伯林盖姆)</a></li><li id="e4a3" class="mn mo iq kn b ko mw ks mx kw my la mz le na li oa mt mu mv bi translated"><a class="ae lj" href="https://ws.towardsai.net/zhr" rel="noopener ugc nofollow" target="_blank"> <strong class="kn ir">资深参谋数据科学家@一关注</strong>(远程)</a></li><li id="71ab" class="mn mo iq kn b ko mw ks mx kw my la mz le na li oa mt mu mv bi translated"><a class="ae lj" href="http://ws.towardsai.net/6l8" rel="noopener ugc nofollow" target="_blank"> <strong class="kn ir">研究科学家—语音识别@ bridge</strong>(远程)</a></li><li id="99e1" class="mn mo iq kn b ko mw ks mx kw my la mz le na li oa mt mu mv bi translated"><a class="ae lj" href="http://ws.towardsai.net/august-22-4-job-1" rel="noopener ugc nofollow" target="_blank"> <strong class="kn ir">计算机视觉科学家@ Percipient AI </strong>(加州圣克拉拉)</a></li><li id="6186" class="mn mo iq kn b ko mw ks mx kw my la mz le na li oa mt mu mv bi translated"><a class="ae lj" href="http://ws.towardsai.net/august-4-job-2" rel="noopener ugc nofollow" target="_blank"><strong class="kn ir">EvolutionIQentist @ EvolutionIQ</strong>(远程)</a>的高级数据科学家职位申请</li></ul><p id="09f3" class="pw-post-body-paragraph kl km iq kn b ko lk kq kr ks ll ku kv kw lm ky kz la ln lc ld le lo lg lh li ij bi translated"><em class="nc">有兴趣在此分享工作机会吗？联系sponsors@towardsai.net或在我们的</em> <a class="ae lj" href="http://ws.towardsai.net/lat-hiring-channel" rel="noopener ugc nofollow" target="_blank"> <em class="nc">【招聘频道】发布招聘机会</em> </a> <em class="nc">！</em></p><figure class="lq lr ls lt gt lu gh gi paragraph-image"><a href="https://confetti.ai"><div class="gh gi ob"><img src="../Images/5e7a0edab351fe468fe4125246625caa.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*fEq5ZuuNd_JzZs-I"/></div></a></figure></div></div>    
</body>
</html>