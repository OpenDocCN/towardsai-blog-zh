# 面向企业的新 GPT 协议—数据隐私是一个问题吗？

> 原文：<https://pub.towardsai.net/gpt-3-for-corporates-is-data-privacy-an-issue-92508aa30a00?source=collection_archive---------4----------------------->

## [自然语言处理](https://towardsai.net/p/category/nlp)

## GPT-3 正在改变企业利用人工智能增强现有产品的方式，并推出下一代产品。

![](img/903835ce46396413f53c91bcb6e1b900.png)

在这个 21 世纪，数据隐私不是一个选项，而是一个命令…

# 简要概述💡

生成式预训练 Transformer 3 是一个自回归语言模型，它使用深度学习来产生类似人类的文本。它是由 OpenAI 创建的 GPT-n 系列中的第三代语言预测模型。GPT-3 是 GPT-2 模型架构的扩展和放大版本，它包括修改的初始化、预规范化和可逆令牌化，并在零触发、单触发和少触发设置中的许多 NLP 任务上显示出强大的性能。

在上面的段落中，可以清楚地看到 GPT-3 如何控制所有的小模型，并在几乎所有的 NLP 任务中获得实质性的收益。它基于对大型数据集进行预训练，然后针对特定任务进行微调或启动的方法。今天的人工智能系统在各种语言任务之间切换时，在性能方面有其局限性，但 GPT-3 使其在不同语言任务之间切换非常灵活，在性能方面非常高效。

![](img/54a831b36031c9f298f8b58e9c1e2927.png)

GPT-3 接受了 1750 亿个参数的训练，这使得它能够模拟类似人脑的场景…

GPT-3 使用了 1750 亿个参数，这是迄今为止模型被训练的最大数量的参数。它带来了一些有趣的见解，向我们展示了如果我们可以扩大语言模型的训练，它可以显著提高任务不可知的，少数镜头的性能，使其与以前的 SOTA 方法相当，甚至更好。

# 访问 GPT-3 🗝️

对 GPT-3 的访问是以 API 的形式给出的。由于模型的庞大，OpenAI 社区决定不发布包含 1750 亿个参数的整个模型。与当前为一个用例设计的人工智能系统不同，GPT-3 的设计是任务不可知的，并提供了一个通用的“文本输入，文本输出”界面，为用户提供了灵活性，可以尝试任何语言任务。

![](img/0025c5e852af8f8a35b1f04f2948183b.png)

数据可以没有信息而存在，但信息不能没有数据而存在！

API 的设计方式是，一旦你给它提供 apt 文本提示，它将在 OpenAI 服务器的后端处理它，并返回完整的文本，试图匹配你给它的模式。不像当前的深度学习系统，需要海量的数据来实现 SOTA 性能，API 需要一些例子来为您的下游任务做准备。

> 该 API 被设计得非常简单和直观，以使机器学习团队更具生产力。以 API 的形式发布 GPT-3 背后的想法是让数据团队专注于机器学习研究，而不是担心分布式系统问题。

# 数据隐私/使用条款🔐

GPT-3 通过开放的 API 来提供其高级语言模型，这允许用户以 ***训练提示*** 的形式向 GPT-3 提供训练数据，模型使用这些数据来得出适当的结果。对于个人帐户，语言模型通常将训练数据存储为其在线学习功能的一部分，以便在移动中更好地使用模型，这对于使用涉及高度机密数据的 GPT-3 产生了障碍。数据隐私一直是全球企业最关心的问题，他们希望使用 GPT-3 来创建特定领域的应用程序。

![](img/0ad9f8ad328b236b2b7c303209dd1e5d.png)

整个世界只是另一个大数据问题…

简单来说，其核心 ***“一个语言模型所做的就是在给定一系列先前单词的情况下预测下一个单词。”OpenAI 已经设计了不同的技术来将语言模型(GPT-3)从这个简单的任务转换成更有用的任务，如问题回答、文档摘要、特定上下文文本生成等。对于一个语言模型来说，最好的结果通常是通过对特定领域的数据进行微调来实现的。GPT-3 使用微调的微型版本，它允许你通过提供几个例子来模拟一个特定的行为。***

在世界各地的企业对使用这种极其强大的语言模型产生了浓厚的兴趣后，OpenAI 提出了企业帐户，允许企业用户与 OpenAI 签署特殊的谅解备忘录(MoU)和数据隐私协议(DPA ),以克服围绕数据泄漏和数据隐私的担忧。

## 企业关注(询问)

*   OpenAI 公开的 GPT-3 API 端点不应保留或保存作为模型微调/训练过程的一部分提供给它的训练数据的任何部分。
*   任何第三方都不能通过向公开的 API 端点提供任何类型的输入来提取或访问作为训练提示的一部分显示给模型的数据。

## OpenAI 的回应

*   对于第一部分，GPT-3 以这样的方式设计，它带有一个默认的 ***【数据保留】*** 周期，这要求模型将数据保留一段时间，以便检测/防止滥用 API 功能(对于我们的 ***ToU 第 3[j]*** 节中提到的内容)。对于专门为企业设计的自定义数据隐私协议，保留窗口可以根据双方之间的相互协议而变得灵活，在此之后，数据将从 OpenAI 系统中清除。
*   对于关于泄漏数据的第二部分，这可以通过简单地创建数据和模型筒仓来轻松解决。OpenAI 将简单地隔离数据，因此无论保留期有多长，第三方都不会通过向 GPT-3 API 提供任何输入来访问或提取您的数据。
*   两个请求/要求都由 OpenAI 独立处理，其中保留期仅适用于 OpenAI，不适用于第三方。通过创建数据孤岛，无论保留时间有多长，第三方都无法访问数据。

# 参考

1.  [https://en.wikipedia.org/wiki/GPT-3](https://en.wikipedia.org/wiki/GPT-3)
2.  [https://openai.com/blog/openai-api](https://openai.com/blog/openai-api/)

如果你想了解更多，或者想让我写更多关于这个主题的东西，请随时联系我们。

我的社交链接:[LinkedIn](https://www.linkedin.com/in/shubhamsaboo/)|[Twitter](https://twitter.com/Saboo_Shubham_)|[Github](https://github.com/Shubhamsaboo)