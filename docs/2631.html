<html>
<head>
<title>Gaussian Naive Bayes Explained and Hands-On with Scikit-Learn</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">高斯朴素贝叶斯解释和实践与Scikit-Learn</h1>
<blockquote>原文：<a href="https://pub.towardsai.net/gaussian-naive-bayes-explained-and-hands-on-with-scikit-learn-4183b8cb0e4c?source=collection_archive---------0-----------------------#2022-03-23">https://pub.towardsai.net/gaussian-naive-bayes-explained-and-hands-on-with-scikit-learn-4183b8cb0e4c?source=collection_archive---------0-----------------------#2022-03-23</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><p id="61b8" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">使用Python和Google Colab</p><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div role="button" tabindex="0" class="ku kv di kw bf kx"><div class="gh gi ko"><img src="../Images/b8ba75a3db5e746990d03997fa376180.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*ARJOqVZOFch_l4CQjHrd1g.png"/></div></div></figure><p id="53a3" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">高斯朴素贝叶斯(GNB)是一种基于概率方法和高斯分布的机器学习(ML)中使用的分类技术。高斯朴素贝叶斯假设每个参数(也称为特征或预测值)都有独立的预测输出变量的能力。所有参数的预测组合就是最终的预测，它返回要分类到每个组中的因变量的概率。最终分类被分配给具有较高概率的组。</p><blockquote class="la lb lc"><p id="c561" class="jq jr ld js b jt ju jv jw jx jy jz ka le kc kd ke lf kg kh ki lg kk kl km kn im bi translated"><strong class="js iu">迷茫？让我们打破它……</strong></p></blockquote><h2 id="25bd" class="lh li it bd lj lk ll dn lm ln lo dp lp kb lq lr ls kf lt lu lv kj lw lx ly lz bi translated">什么是高斯分布？</h2><p id="47b5" class="pw-post-body-paragraph jq jr it js b jt ma jv jw jx mb jz ka kb mc kd ke kf md kh ki kj me kl km kn im bi translated">高斯分布也叫正态分布。正态分布是描述自然界中连续随机变量统计分布的统计模型。正态分布由其钟形曲线定义。正态分布的两个最重要的特征是均值(<strong class="js iu"> μ </strong>和标准差(<strong class="js iu"> σ </strong>)。平均值是分布的平均值，标准差是平均值周围分布的“宽度”。</p><p id="e49a" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">要知道正态分布的变量(<strong class="js iu"> X </strong>)从<strong class="js iu">∞&lt;X&lt;+∞</strong>连续分布(连续变量)，模型曲线下的总面积为1。</p><h2 id="d945" class="lh li it bd lj lk ll dn lm ln lo dp lp kb lq lr ls kf lt lu lv kj lw lx ly lz bi translated">多类高斯朴素贝叶斯</h2><p id="1a3f" class="pw-post-body-paragraph jq jr it js b jt ma jv jw jx mb jz ka kb mc kd ke kf md kh ki kj me kl km kn im bi translated">和往常一样，第一件事是导入必要的库:</p><pre class="kp kq kr ks gt mf mg mh mi aw mj bi"><span id="90f1" class="lh li it mg b gy mk ml l mm mn">from random import random<br/>from random import randint<br/>import pandas as pd<br/>import numpy as np<br/>import seaborn as sns<br/>import matplotlib.pyplot as plt<br/>import statistics<br/>from sklearn.model_selection import train_test_split<br/>from sklearn.preprocessing import StandardScaler<br/>from sklearn.naive_bayes import GaussianNB<br/>from sklearn.metrics import confusion_matrix<br/>from mlxtend.plotting import plot_decision_regions</span></pre><p id="75a3" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">现在，我们将创建一个预测变量呈正态分布的数据库。</p><pre class="kp kq kr ks gt mf mg mh mi aw mj bi"><span id="d7c8" class="lh li it mg b gy mk ml l mm mn"><strong class="mg iu">#Creating values for FeNO with 3 classes:<br/></strong>FeNO_0 = np.random.normal(20, 19, 200)<br/>FeNO_1 = np.random.normal(40, 20, 200)<br/>FeNO_2 = np.random.normal(60, 20, 200)</span><span id="0ff3" class="lh li it mg b gy mo ml l mm mn"><strong class="mg iu">#Creating values for FEV1 with 3 classes:<br/></strong>FEV1_0 = np.random.normal(4.65, 1, 200)<br/>FEV1_1 = np.random.normal(3.75, 1.2, 200)<br/>FEV1_2 = np.random.normal(2.85, 1.2, 200)</span><span id="4e98" class="lh li it mg b gy mo ml l mm mn"><strong class="mg iu">#Creating values for Broncho Dilation with 3 classes:<br/></strong>BD_0 = np.random.normal(150,49, 200)<br/>BD_1 = np.random.normal(201,50, 200)<br/>BD_2 = np.random.normal(251, 50, 200)</span><span id="66bb" class="lh li it mg b gy mo ml l mm mn"><strong class="mg iu">#Creating labels variable with three classes:(2)disease (1)possible disease (0)no disease:<br/></strong>not_asthma = np.zeros((200,), dtype=int)<br/>poss_asthma = np.ones((200,), dtype=int)<br/>asthma = np.full((200,), 2, dtype=int)</span><span id="2806" class="lh li it mg b gy mo ml l mm mn"><strong class="mg iu">#Concatenate classes into one variable:<br/></strong>FeNO = np.concatenate([FeNO_0, FeNO_1, FeNO_2])<br/>FEV1 = np.concatenate([FEV1_0, FEV1_1, FEV1_2])<br/>BD = np.concatenate([BD_0, BD_1, BD_2])<br/>dx = np.concatenate([not_asthma, poss_asthma, asthma])</span><span id="d4c3" class="lh li it mg b gy mo ml l mm mn"><strong class="mg iu">#Create DataFrame:<br/></strong>df = pd.DataFrame()</span><span id="3b9a" class="lh li it mg b gy mo ml l mm mn"><strong class="mg iu">#Add variables to DataFrame:<br/></strong>df['FeNO'] = FeNO.tolist()<br/>df['FEV1'] = FEV1.tolist()<br/>df['BD'] = BD.tolist()<br/>df['dx'] = dx.tolist()</span><span id="3af9" class="lh li it mg b gy mo ml l mm mn"><strong class="mg iu">#Check database:</strong><br/>df</span></pre><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div class="gh gi mp"><img src="../Images/ff23df879da02f20401a10ca07474036.png" data-original-src="https://miro.medium.com/v2/resize:fit:720/format:webp/1*TX8i875gefljEjvXZRCqqA.png"/></div></figure><p id="c5b9" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">我们有一个600行4列的数据框。现在我们可以通过目视检查来检查变量的分布:</p><pre class="kp kq kr ks gt mf mg mh mi aw mj bi"><span id="dd26" class="lh li it mg b gy mk ml l mm mn">fig, axs = plt.subplots(2, 3, figsize=(14, 7))</span><span id="0122" class="lh li it mg b gy mo ml l mm mn">sns.kdeplot(df['FEV1'], shade=True, color="b", ax=axs[0, 0])<br/>sns.kdeplot(df['FeNO'], shade=True, color="b", ax=axs[0, 1])<br/>sns.kdeplot(df['BD'], shade=True, color="b", ax=axs[0, 2])<br/>sns.distplot( a=df["FEV1"], hist=True, kde=True, rug=False, ax=axs[1, 0])<br/>sns.distplot( a=df["FeNO"], hist=True, kde=True, rug=False, ax=axs[1, 1])<br/>sns.distplot( a=df["BD"], hist=True, kde=True, rug=False, ax=axs[1, 2])</span><span id="9232" class="lh li it mg b gy mo ml l mm mn">plt.show()</span></pre><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div role="button" tabindex="0" class="ku kv di kw bf kx"><div class="gh gi ko"><img src="../Images/5f0edb53577717a579bedaa1b8f6860f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*RGseuckLL5KNN_GE_a3FjQ.png"/></div></div></figure><p id="d846" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">通过目测，我们的数据似乎接近高斯分布。我们可以仔细检查构建qq-plots:</p><pre class="kp kq kr ks gt mf mg mh mi aw mj bi"><span id="e62b" class="lh li it mg b gy mk ml l mm mn">from statsmodels.graphics.gofplots import qqplot<br/>from matplotlib import pyplot</span><span id="5837" class="lh li it mg b gy mo ml l mm mn"><strong class="mg iu">#q-q plot:</strong></span><span id="5ed4" class="lh li it mg b gy mo ml l mm mn">fig, axs = pyplot.subplots(1, 3, figsize=(15, 5))</span><span id="f72c" class="lh li it mg b gy mo ml l mm mn">qqplot(df['FEV1'], line='s', ax=axs[0])<br/>qqplot(df['FeNO'], line='s', ax=axs[1])<br/>qqplot(df['BD'], line='s', ax=axs[2])</span><span id="3c99" class="lh li it mg b gy mo ml l mm mn">pyplot.show()</span></pre><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div role="button" tabindex="0" class="ku kv di kw bf kx"><div class="gh gi mq"><img src="../Images/b6448445aea3ce030920ee6ec20758c7.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*MLmAM2QWUO7l9eMhFrGpzg.png"/></div></div></figure><p id="c5e9" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">对于我们的变量，我们没有一个完美的正态分布，但是我们足够接近并且能够使用它们。为了探索我们的数据集和变量之间的相关性，我们将构建一个配对图:</p><pre class="kp kq kr ks gt mf mg mh mi aw mj bi"><span id="7068" class="lh li it mg b gy mk ml l mm mn"><strong class="mg iu">#Exploring dataset:<br/></strong>sns.pairplot(df, kind="scatter", hue="dx")<br/>plt.show()</span></pre><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div class="gh gi mr"><img src="../Images/8f47c95f4c96a3ae7f70cf8f7872a19f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1160/format:webp/1*EgQb3m9qJ3Q2-A2BuGdZIw.png"/></div></figure><p id="f676" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">要检查三组的分布，并查看哪些参数最能区分类别，我们可以构建一个箱线图:</p><pre class="kp kq kr ks gt mf mg mh mi aw mj bi"><span id="0b9f" class="lh li it mg b gy mk ml l mm mn"><strong class="mg iu"># plotting both distibutions on the same figure</strong></span><span id="ef17" class="lh li it mg b gy mo ml l mm mn">fig, axs = plt.subplots(2, 3, figsize=(14, 7))</span><span id="e1f8" class="lh li it mg b gy mo ml l mm mn">fig = sns.kdeplot(df['FEV1'], hue= df['dx'], shade=True, color="r", ax=axs[0, 0])<br/>fig = sns.kdeplot(df['FeNO'], hue= df['dx'], shade=True, color="r", ax=axs[0, 1])<br/>fig = sns.kdeplot(df['BD'], hue= df['dx'], shade=True, color="r", ax=axs[0, 2])<br/>sns.boxplot(x=df["dx"], y=df["FEV1"], palette = 'magma', ax=axs[1, 0])<br/>sns.boxplot(x=df["dx"], y=df["FeNO"], palette = 'magma',ax=axs[1, 1])<br/>sns.boxplot(x=df["dx"], y=df["BD"], palette = 'magma',ax=axs[1, 2])</span><span id="f7f6" class="lh li it mg b gy mo ml l mm mn">plt.show()</span></pre><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div role="button" tabindex="0" class="ku kv di kw bf kx"><div class="gh gi ko"><img src="../Images/b8ba75a3db5e746990d03997fa376180.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*ARJOqVZOFch_l4CQjHrd1g.png"/></div></div></figure><h2 id="5306" class="lh li it bd lj lk ll dn lm ln lo dp lp kb lq lr ls kf lt lu lv kj lw lx ly lz bi translated"><strong class="ak">正态分布方程</strong></h2><p id="1bd6" class="pw-post-body-paragraph jq jr it js b jt ma jv jw jx mb jz ka kb mc kd ke kf md kh ki kj me kl km kn im bi translated">正态分布有一个数学等式，它定义了一个观察值属于其中一个组的概率。公式是:</p><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div class="gh gi ms"><img src="../Images/d252b728258edcd61c192e2ce26f4ecd.png" data-original-src="https://miro.medium.com/v2/resize:fit:1168/format:webp/1*WhOI2fD8rGz4Nz5JCGOWJA.png"/></div><figcaption class="mt mu gj gh gi mv mw bd b be z dk translated">其中<strong class="bd lj"> μ </strong>为平均值，<strong class="bd lj"> σ </strong>为标准差。</figcaption></figure><p id="0073" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">我们可以创建一个函数来计算这个概率:</p><pre class="kp kq kr ks gt mf mg mh mi aw mj bi"><span id="539f" class="lh li it mg b gy mk ml l mm mn"><strong class="mg iu">#Creating a Function:</strong></span><span id="9cfe" class="lh li it mg b gy mo ml l mm mn">def normal_dist(x , mean , sd):<br/>      prob_density = (1/sd*np.sqrt(2*np.pi)) * np.exp(-0.5*((x-mean)/sd)**2)<br/>      return prob_density</span></pre><p id="aa56" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">如果我们知道正态分布公式，我们可以手动计算观察值属于三组之一的概率。首先，我们需要计算所有预测参数和组的平均值和标准偏差:</p><pre class="kp kq kr ks gt mf mg mh mi aw mj bi"><span id="fe43" class="lh li it mg b gy mk ml l mm mn"><strong class="mg iu">#Group 0:<br/></strong>group_0 = df[df['dx'] == 0]</span><span id="42f8" class="lh li it mg b gy mo ml l mm mn">print('Mean FEV1 group 0: ', statistics.mean(group_0['FEV1']))<br/>print('SD FEV1 group 0: ', statistics.stdev(group_0['FEV1']))</span><span id="e94a" class="lh li it mg b gy mo ml l mm mn">print('Mean FeNO group 0: ', statistics.mean(group_0['FeNO']))<br/>print('SD FeNO group 0: ', statistics.stdev(group_0['FeNO']))</span><span id="bb3a" class="lh li it mg b gy mo ml l mm mn">print('Mean BD group 0: ', statistics.mean(group_0['BD']))<br/>print('SD BD group 0: ', statistics.stdev(group_0['BD']))</span><span id="c99e" class="lh li it mg b gy mo ml l mm mn"><strong class="mg iu">#Group 1:</strong><br/>group_1 = df[df['dx'] == 1]</span><span id="a674" class="lh li it mg b gy mo ml l mm mn">print('Mean FEV1 group 1: ', statistics.mean(group_1['FEV1']))<br/>print('SD FEV1 group 1: ', statistics.stdev(group_1['FEV1']))</span><span id="f718" class="lh li it mg b gy mo ml l mm mn">print('Mean FeNO group 1: ', statistics.mean(group_1['FeNO']))<br/>print('SD FeNO group 1: ', statistics.stdev(group_1['FeNO']))</span><span id="acd6" class="lh li it mg b gy mo ml l mm mn">print('Mean BD group 1: ', statistics.mean(group_1['BD']))<br/>print('SD BD group 1: ', statistics.stdev(group_1['BD']))</span><span id="cc50" class="lh li it mg b gy mo ml l mm mn"><strong class="mg iu">#Group 2:</strong><br/>group_2 = df[df['dx'] == 2]</span><span id="e829" class="lh li it mg b gy mo ml l mm mn">print('Mean FEV1 group 2: ', statistics.mean(group_2['FEV1']))<br/>print('SD FEV1 group 2: ', statistics.stdev(group_2['FEV1']))</span><span id="97fb" class="lh li it mg b gy mo ml l mm mn">print('Mean FeNO group 2: ', statistics.mean(group_2['FeNO']))<br/>print('SD FeNO group 2: ', statistics.stdev(group_2['FeNO']))</span><span id="ff72" class="lh li it mg b gy mo ml l mm mn">print('Mean BD group 2: ', statistics.mean(group_2['BD']))<br/>print('SD BD group 2: ', statistics.stdev(group_2['BD']))</span></pre><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div class="gh gi mx"><img src="../Images/3a209f1323b4191a05ac1be010b2ffba.png" data-original-src="https://miro.medium.com/v2/resize:fit:802/format:webp/1*yI859XRLKGj1cd2OMaaOGg.png"/></div></figure><p id="3f04" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">现在，用一个例子观察:<br/><strong class="js iu">Fe v1 = 2.75<br/>FeNO = 27<br/>BD = 125</strong></p><pre class="kp kq kr ks gt mf mg mh mi aw mj bi"><span id="7f6d" class="lh li it mg b gy mk ml l mm mn"><strong class="mg iu">#Probability for:<br/></strong>#FEV1 = 2.75<br/>#FeNO = 27<br/>#BD = 125</span><span id="eb4f" class="lh li it mg b gy mo ml l mm mn"><strong class="mg iu">#We have the same number of observations, so the general probability is: 0.33<br/></strong>Prob_geral = round(0.333, 3)</span><span id="5c32" class="lh li it mg b gy mo ml l mm mn"><strong class="mg iu">#Prob FEV1:<br/></strong>Prob_FEV1_0 = round(normal_dist(2.75, 4.70, 1.08), 10)<br/>print('Prob FEV1 0: ', Prob_FEV1_0)<br/>Prob_FEV1_1 = round(normal_dist(2.75, 3.70, 1.13), 10)<br/>print('Prob FEV1 1: ', Prob_FEV1_1)<br/>Prob_FEV1_2 = round(normal_dist(2.75, 3.01, 1.22), 10)<br/>print('Prob FEV1 2: ', Prob_FEV1_2)</span><span id="518a" class="lh li it mg b gy mo ml l mm mn"><strong class="mg iu">#Prob FeNO:<br/></strong>Prob_FeNO_0 = round(normal_dist(27, 19.71, 19.29), 10)<br/>print('Prob FeNO 0: ', Prob_FeNO_0)<br/>Prob_FeNO_1 = round(normal_dist(27, 42.34, 19.85), 10)<br/>print('Prob FeNO 1: ', Prob_FeNO_1)<br/>Prob_FeNO_2 = round(normal_dist(27, 61.78, 21.39), 10)<br/>print('Prob FeNO 2: ', Prob_FeNO_2)</span><span id="fabc" class="lh li it mg b gy mo ml l mm mn"><strong class="mg iu">#Prob BD:<br/></strong>Prob_BD_0 = round(normal_dist(125, 152.59, 50.33), 10)<br/>print('Prob BD 0: ', Prob_BD_0)<br/>Prob_BD_1 = round(normal_dist(125, 199.14, 50.81), 10)<br/>print('Prob BD 1: ', Prob_BD_1)<br/>Prob_BD_2 = round(normal_dist(125, 256.13, 47.04), 10)<br/>print('Prob BD 2: ', Prob_BD_2)</span><span id="6fb2" class="lh li it mg b gy mo ml l mm mn"><strong class="mg iu">#Compute probability:<br/></strong>Prob_group_0 = Prob_geral*Prob_FEV1_0*Prob_FeNO_0*Prob_BD_0<br/>print('Prob group 0: ', Prob_group_0)</span><span id="afd2" class="lh li it mg b gy mo ml l mm mn">Prob_group_1 = Prob_geral*Prob_FEV1_1*Prob_FeNO_1*Prob_BD_1<br/>print('Prob group 1: ', Prob_group_1)</span><span id="6e07" class="lh li it mg b gy mo ml l mm mn">Prob_group_2 = Prob_geral*Prob_FEV1_2*Prob_FeNO_2*Prob_BD_2<br/>print('Prob group 2: ', Prob_group_2)</span></pre><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div class="gh gi my"><img src="../Images/358ce0b701d7732593e5ffecdf582a74.png" data-original-src="https://miro.medium.com/v2/resize:fit:674/format:webp/1*1cPrZ6fpIqLYn2RoFwhhbg.png"/></div></figure><p id="4b01" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">根据给出的结果，我们看到我们的观察值FEV1 = 2.75，FeNO = 27，BD = 125有更高的概率属于第2组。然而，尽管这些步骤很有教育意义，对学习也很有帮助，但是做这些步骤很费时间，我们有一个更快的方法。我们可以使用Scikit-Learn中的高斯朴素贝叶斯，它在实现上类似于其他分类算法。我们创建<strong class="js iu"> <em class="ld"> X </em> </strong>和<strong class="js iu"> y </strong>变量，并执行训练和测试分割:</p><pre class="kp kq kr ks gt mf mg mh mi aw mj bi"><span id="fa45" class="lh li it mg b gy mk ml l mm mn"><strong class="mg iu">#Creating X and y:<br/></strong>X = df.drop('dx', axis=1)<br/>y = df['dx']</span><span id="b509" class="lh li it mg b gy mo ml l mm mn"><strong class="mg iu">#Data split into train and test:<br/></strong>X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30)</span></pre><p id="ce2d" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">我们还需要用标准标量函数转换/规范化我们的数据:</p><pre class="kp kq kr ks gt mf mg mh mi aw mj bi"><span id="0d6a" class="lh li it mg b gy mk ml l mm mn">sc = StandardScaler()<br/>X_train = sc.fit_transform(X_train)<br/>X_test = sc.transform(X_test)</span></pre><p id="60a2" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">现在构建并评估模型:</p><pre class="kp kq kr ks gt mf mg mh mi aw mj bi"><span id="7a2d" class="lh li it mg b gy mk ml l mm mn"><strong class="mg iu">#Build the model:</strong><br/>classifier = GaussianNB()<br/>classifier.fit(X_train, y_train)</span><span id="45f7" class="lh li it mg b gy mo ml l mm mn"><strong class="mg iu">#Evaluate the model:<br/></strong>print("training set score: %f" % classifier.score(X_train, y_train))<br/>print("test set score: %f" % classifier.score(X_test, y_test))</span></pre><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div class="gh gi mz"><img src="../Images/20a0685f22da6438825b292ebcbb6e8a.png" data-original-src="https://miro.medium.com/v2/resize:fit:502/format:webp/1*P3QMwULfVm7zQRcJruVX3w.png"/></div></figure><p id="53ce" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">我们可以使用混淆矩阵来可视化我们的结果:</p><pre class="kp kq kr ks gt mf mg mh mi aw mj bi"><span id="bd44" class="lh li it mg b gy mk ml l mm mn"><strong class="mg iu"># Predicting the Test set results</strong><br/>y_pred = classifier.predict(X_test)</span><span id="129c" class="lh li it mg b gy mo ml l mm mn"><strong class="mg iu">#Confusion Matrix:<br/></strong>cm = confusion_matrix(y_test, y_pred)<br/>print(cm)</span></pre><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div class="gh gi na"><img src="../Images/be5ed6aaeadd902a543f2fa009960767.png" data-original-src="https://miro.medium.com/v2/resize:fit:234/format:webp/1*YHBMfep1Y1ahT7npYqvFHg.png"/></div></figure><p id="b6c0" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">我们可以通过混淆矩阵看到，我们的模型是预测类0的最佳模型，但对类1和类2有较高的错误率。最后，我们可以使用两个变量构建决策边界图:</p><pre class="kp kq kr ks gt mf mg mh mi aw mj bi"><span id="0251" class="lh li it mg b gy mk ml l mm mn">df.to_csv('data.csv', index = False)<br/>data = pd.read_csv('data.csv')</span><span id="da8a" class="lh li it mg b gy mo ml l mm mn">def gaussian_nb_a(data):<br/>    x = data[['BD','FeNO',]].values<br/>    y = data['dx'].astype(int).values<br/>    Gauss_nb = GaussianNB()<br/>    Gauss_nb.fit(x,y)<br/>    print(Gauss_nb.score(x,y))<br/>    #Plot decision region:<br/>    plot_decision_regions(x,y, clf=Gauss_nb, legend=1)<br/>    #Adding axes annotations:<br/>    plt.xlabel('X_train')<br/>    plt.ylabel('y_train')<br/>    plt.title('Gaussian Naive Bayes')<br/>    plt.show()</span><span id="ddba" class="lh li it mg b gy mo ml l mm mn">def gaussian_nb_b(data):<br/>    x = data[['BD','FEV1',]].values<br/>    y = data['dx'].astype(int).values <br/>    Gauss_nb = GaussianNB()<br/>    Gauss_nb.fit(x,y)<br/>    print(Gauss_nb.score(x,y))<br/>    #Plot decision region:<br/>    plot_decision_regions(x,y, clf=Gauss_nb, legend=1)<br/>    #Adding axes annotations:<br/>    plt.xlabel('X_train')<br/>    plt.ylabel('y_train')<br/>    plt.title('Gaussian Naive Bayes') <br/>    plt.show()</span><span id="5d6d" class="lh li it mg b gy mo ml l mm mn">def gaussian_nb_c(data):<br/>    x = data[['FEV1','FeNO',]].values<br/>    y = data['dx'].astype(int).values<br/>    Gauss_nb = GaussianNB()<br/>    Gauss_nb.fit(x,y)<br/>    print(Gauss_nb.score(x,y))<br/>    #Plot decision region:<br/>    plot_decision_regions(x,y, clf=Gauss_nb, legend=1)<br/>    #Adding axes annotations:  <br/>    plt.xlabel('X_train')<br/>    plt.ylabel('y_train')  <br/>    plt.title('Gaussian Naive Bayes')<br/>    plt.show()</span><span id="2ec7" class="lh li it mg b gy mo ml l mm mn">gaussian_nb_a(data)<br/>gaussian_nb_b(data)<br/>gaussian_nb_c(data)</span></pre><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div role="button" tabindex="0" class="ku kv di kw bf kx"><div class="gh gi nb"><img src="../Images/861c095d55b1b5fca0aa95caf0bfc59f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*qZb2iJA4VffdHpr2D7MwGQ.png"/></div></div></figure><p id="fac5" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">感谢您的阅读！如果你有建议要添加到这个列表中，请告诉我，不要忘记订阅以接收关于我未来出版物的通知。</p><p id="7ec2" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">如果:你喜欢这篇文章，别忘了关注我，这样你就能收到所有关于新出版物的更新。</p><p id="f053" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">否则如果:你想了解更多，你可以通过<a class="ae nc" href="https://cdanielaam.medium.com/membership" rel="noopener">我的推荐链接</a>订阅媒体会员。它不会花你更多的钱，但会支付我一杯咖啡。</p><p id="49be" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">Else:谢谢！</p></div></div>    
</body>
</html>