<html>
<head>
<title>Diffusion Models — my “second?” artist.</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">扩散模型——我的“第二个？”艺术家。</h1>
<blockquote>原文：<a href="https://pub.towardsai.net/diffusion-models-my-second-artist-42f8aa0d31ab?source=collection_archive---------3-----------------------#2022-12-20">https://pub.towardsai.net/diffusion-models-my-second-artist-42f8aa0d31ab?source=collection_archive---------3-----------------------#2022-12-20</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><p id="18f3" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">扩散模型是深度学习中最流行的算法之一。它被广泛用于许多应用中，例如图像生成、对象检测和文本到图像的生成。在本文中，我将解释扩散模型是如何工作的(链接到论文<a class="ae kl" href="https://arxiv.org/pdf/2006.11239v2.pdf" rel="noopener ugc nofollow" target="_blank">去噪扩散概率模型</a></p><p id="02e8" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">该算法的主要思想是有两个随机过程:</p><ul class=""><li id="6fad" class="km kn iq jp b jq jr ju jv jy ko kc kp kg kq kk kr ks kt ku bi translated">正向过程(扩散过程)</li><li id="4c00" class="km kn iq jp b jq kv ju kw jy kx kc ky kg kz kk kr ks kt ku bi translated">翻转过程</li></ul><p id="ac7c" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">其中正向过程是固定的马尔可夫链，反向过程通常是用于生成图像的Unet。下面将详细介绍这两个过程。</p><figure class="lb lc ld le gt lf gh gi paragraph-image"><div role="button" tabindex="0" class="lg lh di li bf lj"><div class="gh gi la"><img src="../Images/5d0f07ac21c8524a3ec9f38af175effd.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*BVdB8HaEh5ICpCt4MtdiQQ.png"/></div></div></figure><h1 id="e1bb" class="lm ln iq bd lo lp lq lr ls lt lu lv lw lx ly lz ma mb mc md me mf mg mh mi mj bi translated">这两个过程是详细的</h1><p id="1937" class="pw-post-body-paragraph jn jo iq jp b jq mk js jt ju ml jw jx jy mm ka kb kc mn ke kf kg mo ki kj kk ij bi translated">如果你不熟悉随机过程，下面可能会让你头疼。就我所知，我会直观的解释一下。</p><h2 id="60ab" class="mp ln iq bd lo mq mr dn ls ms mt dp lw jy mu mv ma kc mw mx me kg my mz mi na bi translated">前进的过程</h2><p id="ff1c" class="pw-post-body-paragraph jn jo iq jp b jq mk js jt ju ml jw jx jy mm ka kb kc mn ke kf kg mo ki kj kk ij bi translated">该过程是一个具有高斯转移的固定马尔可夫链，其方差为β1，…，βT。在每个时间步，该过程将向图像添加一个具有给定方差的高斯噪声。</p><figure class="lb lc ld le gt lf gh gi paragraph-image"><div class="gh gi nb"><img src="../Images/84569d253dcd09dcf0ca88c1dd80f4d7.png" data-original-src="https://miro.medium.com/v2/resize:fit:1088/format:webp/1*0vnhl2lmtYNw1kLNhuOK-Q.png"/></div></figure><h2 id="a4e8" class="mp ln iq bd lo mq mr dn ls ms mt dp lw jy mu mv ma kc mw mx me kg my mz mi na bi translated">直观的解释</h2><p id="5c76" class="pw-post-body-paragraph jn jo iq jp b jq mk js jt ju ml jw jx jy mm ka kb kc mn ke kf kg mo ki kj kk ij bi translated">假设每个图像是一个数据点，那么你的整个数据集将形成一个分布。给定当前状态x_t-1，跃迁q(x_t | x_t-1)告诉我们下一个状态x_t的分布。然后，可以通过来自给定分布的递归样本数据来完成正向过程。或者，数学上，我们有封闭的形式:</p><figure class="lb lc ld le gt lf gh gi paragraph-image"><div class="gh gi nc"><img src="../Images/404cc9edaca6226f7c5e43457880099f.png" data-original-src="https://miro.medium.com/v2/resize:fit:652/format:webp/1*JLMOFAgFo8WBaWWqRWy1Uw.png"/></div></figure><p id="cdf7" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">其中，α t:= 1βt，αt是a_0与a_t的累计乘积，然后我们可以根据给定的预定方差从x_0直接采样x_t。而当时间步长T足够大时，注意(1-βt) &lt; 1, α¯t will reach to 0. This means the distribution of x_T will be approximate, a standard multivariate Gaussian.</p><h2 id="b5a3" class="mp ln iq bd lo mq mr dn ls ms mt dp lw jy mu mv ma kc mw mx me kg my mz mi na bi translated">The reverse process</h2><p id="1f42" class="pw-post-body-paragraph jn jo iq jp b jq mk js jt ju ml jw jx jy mm ka kb kc mn ke kf kg mo ki kj kk ij bi translated">This process is our deep learning model, where you sample some random noise and get an image. BUT how does it work? As above I mentioned that, we could treat our dataset as a distribution. Hence, if we find some way to sample a data point from it, we’ll get a real-looking image.</p><p id="4cce" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">Then the task for our model is to learn to sample the data distribution by trying to reverse the forward process. Particularly, in generating, the inputs of model, x_T, will be in standard Gaussian, then it reverses the process with learned Gaussian transition:</p><figure class="lb lc ld le gt lf gh gi paragraph-image"><div role="button" tabindex="0" class="lg lh di li bf lj"><div class="gh gi nd"><img src="../Images/e75a7a0f98e848c6aa0654a893b51d73.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*4KZxxjULi1K7lLjvkiMhsg.png"/></div></div></figure><p id="5ce7" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">&gt;训练</p><ul class=""><li id="9e7c" class="km kn iq jp b jq jr ju jv jy ko kc kp kg kq kk kr ks kt ku bi translated">给定一个输入图像，正向过程将采样x_t</li><li id="1210" class="km kn iq jp b jq kv ju kw jy kx kc ky kg kz kk kr ks kt ku bi translated">然后，采样的x_t将馈入模型，并尝试预测图像</li></ul><p id="640c" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">然后通过以下方式计算损失:</p><figure class="lb lc ld le gt lf gh gi paragraph-image"><div role="button" tabindex="0" class="lg lh di li bf lj"><div class="gh gi ne"><img src="../Images/a4258ce9082c5cefdf4e8ffac5b2144b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Lw5zftlrPkdvL2hKhZkpfQ.png"/></div></div></figure><p id="e35e" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">这可以解释为两个过程的跃迁分布之间的KL散度。实际上，这个公式简化为:</p><figure class="lb lc ld le gt lf gh gi paragraph-image"><div role="button" tabindex="0" class="lg lh di li bf lj"><div class="gh gi nf"><img src="../Images/aab53ebfdf97548b74c847bec1c82bf1.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*gxgy1VgZhK18Ds_jqQ-C_A.png"/></div></div></figure><p id="bdbd" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">有相当多的数学和其他参数来达到这一点，所以我把它留给有兴趣阅读这篇论文的人。</p><h2 id="fe6b" class="mp ln iq bd lo mq mr dn ls ms mt dp lw jy mu mv ma kc mw mx me kg my mz mi na bi translated">为什么是KL发散？</h2><p id="39da" class="pw-post-body-paragraph jn jo iq jp b jq mk js jt ju ml jw jx jy mm ka kb kc mn ke kf kg mo ki kj kk ij bi translated">KL散度告诉我们两个分布之间的长距离。我们想要的是使生成的图像的分布类似于数据集中图像的分布。然后，通过最小化KL散度，所生成图像的分布将被推向接近真实分布。</p><ul class=""><li id="9927" class="km kn iq jp b jq jr ju jv jy ko kc kp kg kq kk kr ks kt ku bi translated">思考:这不是唯一一个可以判断两个分布有多远的函数。事实上，在训练甘完成类似的任务时，我们有时会使用“推土机距离”(Wasserstein Loss)。但是为什么选择KLD呢？</li></ul><h1 id="6f8d" class="lm ln iq bd lo lp lq lr ls lt lu lv lw lx ly lz ma mb mc md me mf mg mh mi mj bi translated">训练一个模型生成一张名人脸。</h1><p id="0efc" class="pw-post-body-paragraph jn jo iq jp b jq mk js jt ju ml jw jx jy mm ka kb kc mn ke kf kg mo ki kj kk ij bi translated">我使用了来自<a class="ae kl" href="https://github.com/lucidrains/denoising-diffusion-pytorch" rel="noopener ugc nofollow" target="_blank">luci drains/去噪-扩散-pytorch </a>的优秀作品在Kaggle上的CelebA数据集上进行训练。<a class="ae kl" href="https://www.kaggle.com/code/minguer/fake-celeb-with-diffusion-models" rel="noopener ugc nofollow" target="_blank">我的笔记本</a></p><figure class="lb lc ld le gt lf gh gi paragraph-image"><div class="gh gi ng"><img src="../Images/cfdd6c64f0ccc93273d41e0a5b7fbf75.png" data-original-src="https://miro.medium.com/v2/resize:fit:1294/format:webp/1*mTpv5-IJhnX5H4PAx5HBcg.png"/></div></figure><p id="c68c" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">谢谢你</p><p id="f422" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">这是我第一篇分享实习中获得的知识的文章。希望我在这里分享的可以帮助到别人。如果你觉得这很有帮助，但是有所遗漏，请在评论中分享你的想法。我将非常感激。</p></div></div>    
</body>
</html>