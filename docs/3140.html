<html>
<head>
<title>From UNet to BERT: Extraction of Important Information from Scientific Papers</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">从UNet到BERT:从科学论文中提取重要信息</h1>
<blockquote>原文：<a href="https://pub.towardsai.net/from-unet-to-bert-extraction-of-important-information-from-scientific-papers-ef0f737e45e9?source=collection_archive---------3-----------------------#2022-09-21">https://pub.towardsai.net/from-unet-to-bert-extraction-of-important-information-from-scientific-papers-ef0f737e45e9?source=collection_archive---------3-----------------------#2022-09-21</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><h1 id="9354" class="jn jo iq bd jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk bi translated">目标</h1><p id="7537" class="pw-post-body-paragraph kl km iq kn b ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li ij bi translated">尽管每年发表的论文数量都在增加，但将机器学习应用于科学论文的工作却很少。机器学习模型也变得越来越智能。尽管科学论文即使对我们人类来说也很难理解，但它们包含独特的结构、格式和语言，这使它们有别于其他文档。</p><figure class="lk ll lm ln gt lo gh gi paragraph-image"><div role="button" tabindex="0" class="lp lq di lr bf ls"><div class="gh gi lj"><img src="../Images/a86cb9d39f75e74bd12e47f4d87bf0aa.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*u2Oh6swN8nbsiZjS"/></div></div><figcaption class="lv lw gj gh gi lx ly bd b be z dk translated">安德烈·德·森蒂斯峰在<a class="ae lz" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上拍摄的照片</figcaption></figure><p id="dd64" class="pw-post-body-paragraph kl km iq kn b ko ma kq kr ks mb ku kv kw mc ky kz la md lc ld le me lg lh li ij bi translated">在这个项目中，我将展示我们如何通过自然语言处理和计算机视觉的多学科方法从这些文档中提取和总结重要信息。请注意，这是我之前关于从科学论文中提取重要信息的<a class="ae lz" href="https://medium.com/@emanawel2/extraction-of-important-information-from-scientific-papers-812af55b24de" rel="noopener">的博客的延续。</a></p></div><div class="ab cl mf mg hu mh" role="separator"><span class="mi bw bk mj mk ml"/><span class="mi bw bk mj mk ml"/><span class="mi bw bk mj mk"/></div><div class="ij ik il im in"><h1 id="3b5f" class="jn jo iq bd jp jq mm js jt ju mn jw jx jy mo ka kb kc mp ke kf kg mq ki kj kk bi translated"><strong class="ak">重述</strong></h1><p id="6931" class="pw-post-body-paragraph kl km iq kn b ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li ij bi translated">我在之前的博客<a class="ae lz" href="https://medium.com/@emanawel2/extraction-of-important-information-from-scientific-papers-812af55b24de" rel="noopener">这里</a>已经谈到了计算机视觉部分。以下是对所涵盖内容的总结。</p><p id="fb7f" class="pw-post-body-paragraph kl km iq kn b ko ma kq kr ks mb ku kv kw mc ky kz la md lc ld le me lg lh li ij bi translated">计算机视觉部分包含一个<strong class="kn ir"> UNet-OCR </strong>管道，它执行以下操作:</p><ul class=""><li id="616e" class="mr ms iq kn b ko ma ks mb kw mt la mu le mv li mw mx my mz bi translated">UNet学习的重要章节摘录和</li><li id="b191" class="mr ms iq kn b ko na ks nb kw nc la nd le ne li mw mx my mz bi translated">使用OCR将所学章节转换为文本</li></ul><p id="c3c9" class="pw-post-body-paragraph kl km iq kn b ko ma kq kr ks mb ku kv kw mc ky kz la md lc ld le me lg lh li ij bi translated"><strong class="kn ir"> UNet </strong>生成一个黑白遮罩，突出显示给定论文的<em class="nf">标题、作者、</em>和<em class="nf">摘要</em>部分。随后是后处理步骤，其中掩蔽的图像被重构为RGB图像。然后，该图像被传递到光学字符识别(OCR)引擎，以转换成文本。我在OCR中使用了默认参数的Tesseract。</p><figure class="lk ll lm ln gt lo gh gi paragraph-image"><div class="gh gi ng"><img src="../Images/532befe951feb994575b84ca2463d0bf.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*SdsBRZ4lDGl9eLna"/></div><figcaption class="lv lw gj gh gi lx ly bd b be z dk translated">图1: UNet-OCR管道。作者图片</figcaption></figure><h1 id="9f1d" class="jn jo iq bd jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk bi translated"><strong class="ak">使用BERT进行文本摘要</strong></h1><p id="467d" class="pw-post-body-paragraph kl km iq kn b ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li ij bi translated">文本摘要是一种机器学习技术，旨在生成一个简洁而精确的文本摘要，而不会完全失去意义。文本摘要是自然语言处理的一个热门且研究较多的领域。</p><p id="cd47" class="pw-post-body-paragraph kl km iq kn b ko ma kq kr ks mb ku kv kw mc ky kz la md lc ld le me lg lh li ij bi translated">文本摘要有两种方法:</p><ul class=""><li id="0ae6" class="mr ms iq kn b ko ma ks mb kw mt la mu le mv li mw mx my mz bi translated"><strong class="kn ir">摘要文本摘要</strong></li><li id="e352" class="mr ms iq kn b ko na ks nb kw nc la nd le ne li mw mx my mz bi translated"><strong class="kn ir">抽象文本摘要</strong></li></ul><p id="8a0d" class="pw-post-body-paragraph kl km iq kn b ko ma kq kr ks mb ku kv kw mc ky kz la md lc ld le me lg lh li ij bi translated">在<strong class="kn ir">摘录文本摘要中，</strong>摘要是使用文本的摘录生成的。不会生成新文本；总结过程中仅使用现有文本。这可以通过给每个句子打分并从文本中生成<strong class="kn ir"> <em class="nf"> k </em> </strong>个最重要的句子来完成。</p><p id="b1a5" class="pw-post-body-paragraph kl km iq kn b ko ma kq kr ks mb ku kv kw mc ky kz la md lc ld le me lg lh li ij bi translated">抽象概括是人类如何对内容进行概括，即用自己的话来解释。摘要将包括文本中没有的单词、短语和句子。</p><p id="ae5a" class="pw-post-body-paragraph kl km iq kn b ko ma kq kr ks mb ku kv kw mc ky kz la md lc ld le me lg lh li ij bi translated">我在这个项目中使用了一种<strong class="kn ir">提取文本摘要</strong>方法，并使用了开源的<strong class="kn ir">Bert-Extractive summarizer[1]</strong>库。</p><p id="75d5" class="pw-post-body-paragraph kl km iq kn b ko ma kq kr ks mb ku kv kw mc ky kz la md lc ld le me lg lh li ij bi translated">BERT[2]代表来自Transformers[3]的双向编码器表示，是一个通过在非常大的语料库上训练来学习句子表示的模型。对于BERT模型，只有编码器部分取自变压器的编码器-解码器架构。</p><figure class="lk ll lm ln gt lo gh gi paragraph-image"><div class="gh gi nh"><img src="../Images/92ca858775797c0f7cc770db5116bb13.png" data-original-src="https://miro.medium.com/v2/resize:fit:720/format:webp/1*pff0QMHng5jWf4cOzIrwYA.png"/></div><figcaption class="lv lw gj gh gi lx ly bd b be z dk translated">图2:变压器架构。图片由Vaswani等人提供</figcaption></figure><p id="9450" class="pw-post-body-paragraph kl km iq kn b ko ma kq kr ks mb ku kv kw mc ky kz la md lc ld le me lg lh li ij bi translated">简而言之，编码器部分接受输入文本的单词嵌入。位置编码转换单词嵌入，以相对于其位置上下文向每个单词添加含义。注意力模块(多头注意力)计算每个单词的注意力向量。这些向量然后被一次一个向量地馈送给前馈神经网络。这个结果由每个单词的一组编码矢量组成，它是BERT模型的最终输出。</p><p id="72eb" class="pw-post-body-paragraph kl km iq kn b ko ma kq kr ks mb ku kv kw mc ky kz la md lc ld le me lg lh li ij bi translated"><strong class="kn ir">Bert-extract-summarizer</strong>知识库基于论文<em class="nf"> </em> <a class="ae lz" href="https://arxiv.org/abs/1906.04165" rel="noopener ugc nofollow" target="_blank"> <em class="nf">利用Bert对讲座</em></a>【4】<em class="nf">进行摘要文本摘要。这篇论文解释了使用BERT生成句子表示，然后使用K-mean算法将这些表示围绕<strong class="kn ir"> <em class="nf"> k </em> </strong>概念进行聚类。然后，返回最接近其各自质心的<em class="nf"> </em> <strong class="kn ir"> <em class="nf"> k </em> </strong>句子，作为其聚类的代表性摘要。</em></p><h1 id="cc67" class="jn jo iq bd jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk bi translated"><strong class="ak">入门</strong></h1><p id="8361" class="pw-post-body-paragraph kl km iq kn b ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li ij bi translated">首先克隆我在Dagshub[5]上的存储库。</p><pre class="lk ll lm ln gt ni nj nk nl aw nm bi"><span id="c4d5" class="nn jo iq nj b gy no np l nq nr">git clone <a class="ae lz" href="https://dagshub.com/Eman22S/Unet-OCR-2.0.git" rel="noopener ugc nofollow" target="_blank">https://dagshub.com/Eman22S/Unet-OCR-2.0.git</a> </span></pre><p id="4c7b" class="pw-post-body-paragraph kl km iq kn b ko ma kq kr ks mb ku kv kw mc ky kz la md lc ld le me lg lh li ij bi translated">安装DVC。</p><pre class="lk ll lm ln gt ni nj nk nl aw nm bi"><span id="ced3" class="nn jo iq nj b gy no np l nq nr">pip install dvc</span></pre><p id="89e1" class="pw-post-body-paragraph kl km iq kn b ko ma kq kr ks mb ku kv kw mc ky kz la md lc ld le me lg lh li ij bi translated">安装dagshub。</p><pre class="lk ll lm ln gt ni nj nk nl aw nm bi"><span id="7cd1" class="nn jo iq nj b gy no np l nq nr">pip install dagshub</span></pre><p id="be22" class="pw-post-body-paragraph kl km iq kn b ko ma kq kr ks mb ku kv kw mc ky kz la md lc ld le me lg lh li ij bi translated">安装宇宙魔方。</p><pre class="lk ll lm ln gt ni nj nk nl aw nm bi"><span id="6c2a" class="nn jo iq nj b gy no np l nq nr">sudo apt install tesseract-ocr-all -y</span></pre><p id="b1b7" class="pw-post-body-paragraph kl km iq kn b ko ma kq kr ks mb ku kv kw mc ky kz la md lc ld le me lg lh li ij bi translated">安装Bert。</p><pre class="lk ll lm ln gt ni nj nk nl aw nm bi"><span id="8b74" class="nn jo iq nj b gy no np l nq nr">pip install bert-extractive-summarizer</span></pre><p id="e48b" class="pw-post-body-paragraph kl km iq kn b ko ma kq kr ks mb ku kv kw mc ky kz la md lc ld le me lg lh li ij bi translated">配置您的DVC原点。</p><pre class="lk ll lm ln gt ni nj nk nl aw nm bi"><span id="7ed1" class="nn jo iq nj b gy no np l nq nr">dvc remote modify dv-origin — local auth basic <br/>dvc remote modify dv-origin — local user {your Dagshub username}<br/>dvc remote modify dv-origin — local password {your Dagshub password}</span></pre><p id="911f" class="pw-post-body-paragraph kl km iq kn b ko ma kq kr ks mb ku kv kw mc ky kz la md lc ld le me lg lh li ij bi translated">如果您对配置DVC感到困惑，请参考此<a class="ae lz" href="https://dagshub.com/docs/" rel="noopener ugc nofollow" target="_blank">文档</a>。</p><p id="1916" class="pw-post-body-paragraph kl km iq kn b ko ma kq kr ks mb ku kv kw mc ky kz la md lc ld le me lg lh li ij bi translated">接下来，使用以下命令将我的跟踪数据集拉入您的系统。</p><pre class="lk ll lm ln gt ni nj nk nl aw nm bi"><span id="ead9" class="nn jo iq nj b gy no np l nq nr">dvc pull -r dv-origin</span></pre><p id="761c" class="pw-post-body-paragraph kl km iq kn b ko ma kq kr ks mb ku kv kw mc ky kz la md lc ld le me lg lh li ij bi translated">在python shell中对您的图像运行tesseract。</p><pre class="lk ll lm ln gt ni nj nk nl aw nm bi"><span id="aa95" class="nn jo iq nj b gy no np l nq nr">import subprocess</span><span id="4c3c" class="nn jo iq nj b gy ns np l nq nr">result= subprocess.run(['tesseract','postprocessed/1409.1556_0.jpg',<br/>'-','-l','eng'], stdout=subprocess.PIPE)</span><span id="d263" class="nn jo iq nj b gy ns np l nq nr">result = result.stdout<br/>result = str(result)</span></pre><p id="ff25" class="pw-post-body-paragraph kl km iq kn b ko ma kq kr ks mb ku kv kw mc ky kz la md lc ld le me lg lh li ij bi translated">将这个结果传递给Summarizer模型。</p><pre class="lk ll lm ln gt ni nj nk nl aw nm bi"><span id="c614" class="nn jo iq nj b gy no np l nq nr"><strong class="nj ir">from</strong> summarizer <strong class="nj ir">import</strong> Summarizer <br/>body = result <br/>model = Summarizer() <br/>result = model(body, ratio=0.2)  <em class="nf"># Specified with ratio</em> result = model(body, num_sentences=3)  <em class="nf"># Will return 3 sentences<br/></em>print(result)</span></pre><p id="9e39" class="pw-post-body-paragraph kl km iq kn b ko ma kq kr ks mb ku kv kw mc ky kz la md lc ld le me lg lh li ij bi translated">上面的代码块使用您的文本<em class="nf"> (body) </em>和句子数= 3来调用模型。这意味着模型会用三句话总结你的文本。<em class="nf"> </em>你可以根据你的用例增加或减少句子的数量。如果你在谷歌Colab笔记本上参考<a class="ae lz" href="https://dagshub.com/Eman22S/Unet-OCR-2.0/src/master/UNet-to-BERT:%20Extraction%20of%20vital%20information%20from%20scientific%20papers%20.ipynb" rel="noopener ugc nofollow" target="_blank"> <em class="nf">这个</em> </a>笔记本。</p><h1 id="c07a" class="jn jo iq bd jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk bi translated">我用了什么？</h1><ol class=""><li id="bd49" class="mr ms iq kn b ko kp ks kt kw nt la nu le nv li nw mx my mz bi translated">Colab笔记本免费版</li><li id="5e30" class="mr ms iq kn b ko na ks nb kw nc la nd le ne li nw mx my mz bi translated">Dagshub作为我的在线知识库</li><li id="55dd" class="mr ms iq kn b ko na ks nb kw nc la nd le ne li nw mx my mz bi translated">DVC跟踪我的数据集</li><li id="919c" class="mr ms iq kn b ko na ks nb kw nc la nd le ne li nw mx my mz bi translated">伯特萃取摘要器</li></ol><h1 id="ce95" class="jn jo iq bd jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk bi translated"><strong class="ak">项目管道</strong></h1><p id="9804" class="pw-post-body-paragraph kl km iq kn b ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li ij bi translated">下图显示了在处<code class="fe nx ny nz nj b">1409.1556_0.jpg</code>找到<a class="ae lz" href="https://dagshub.com/Eman22S/Unet-OCR-2.0/src/master/testset/imgs/1409.1556_0.jpg" rel="noopener ugc nofollow" target="_blank">的输出。</a></p><figure class="lk ll lm ln gt lo gh gi paragraph-image"><div role="button" tabindex="0" class="lp lq di lr bf ls"><div class="gh gi oa"><img src="../Images/fd89f1fb4fb3d465866f2afbc157bfe4.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*RPc0l3yrLZ_igncvkpLQuA.png"/></div></div><figcaption class="lv lw gj gh gi lx ly bd b be z dk translated">图2:图像上的Bert输出。作者图片</figcaption></figure><h1 id="5955" class="jn jo iq bd jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk bi translated"><strong class="ak">结论</strong></h1><p id="4806" class="pw-post-body-paragraph kl km iq kn b ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li ij bi translated">您可以训练UNet从科学论文中提取任何一组部分，但是对于这个实验，我选择了<em class="nf">摘要、作者和标题</em>部分。伯特给了我们最后的结果，它是在摘要、作者和标题中找到的部分的总结。虽然大多数论文都有或多或少相似的格式、结构和章节，但这个项目的挑战是提取一个给定的章节，而这个章节对于一篇给定的论文来说可能存在，也可能不存在。</p><p id="d285" class="pw-post-body-paragraph kl km iq kn b ko ma kq kr ks mb ku kv kw mc ky kz la md lc ld le me lg lh li ij bi translated">至此，我们到达了最后的里程碑。恭喜你走到这一步！如有任何问题或反馈，请随时联系我们。很高兴收到你的来信！</p><h1 id="1fc1" class="jn jo iq bd jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk bi translated"><strong class="ak">参考文献</strong></h1><p id="a16d" class="pw-post-body-paragraph kl km iq kn b ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li ij bi translated">[1]https://github.com/dmmiller612/bert-extractive-summarizer<a class="ae lz" href="https://github.com/dmmiller612/bert-extractive-summarizer" rel="noopener ugc nofollow" target="_blank"/></p><p id="bdf9" class="pw-post-body-paragraph kl km iq kn b ko ma kq kr ks mb ku kv kw mc ky kz la md lc ld le me lg lh li ij bi translated">[2] Jacob Devlin、张明蔚、Kenton Lee和Kristina Toutanova。2019.<a class="ae lz" href="https://aclanthology.org/N19-1423" rel="noopener ugc nofollow" target="_blank"> BERT:用于语言理解的深度双向转换器的预训练</a>。在<em class="nf">计算语言学协会北美分会2019年会议记录:人类语言技术，第1卷(长和短论文)</em>，第4171-4186页，明尼苏达州明尼阿波利斯。计算语言学协会。</p><p id="0f03" class="pw-post-body-paragraph kl km iq kn b ko ma kq kr ks mb ku kv kw mc ky kz la md lc ld le me lg lh li ij bi translated">[3] Vaswani、Ashish、Noam Shazeer、Niki Parmar、Jakob Uszkoreit、Llion Jones、Aidan N. Gomez、ukasz Kaiser和Illia Polosukhin。“你需要的只是关注。”<em class="nf">神经信息处理系统进展</em> 30 (2017)。</p><p id="d25f" class="pw-post-body-paragraph kl km iq kn b ko ma kq kr ks mb ku kv kw mc ky kz la md lc ld le me lg lh li ij bi translated">[4]米勒，德里克。"利用BERT在课堂上进行摘录性文本摘要."<em class="nf"> arXiv预印本arXiv:1906.04165 </em> (2019)。</p><p id="9a40" class="pw-post-body-paragraph kl km iq kn b ko ma kq kr ks mb ku kv kw mc ky kz la md lc ld le me lg lh li ij bi translated">[5]<a class="ae lz" href="https://dagshub.com/docs/" rel="noopener ugc nofollow" target="_blank">https://dagshub.com/docs/</a></p><div class="ob oc gp gr od oe"><a href="https://www.kdnuggets.com/2019/01/approaches-text-summarization-overview.html" rel="noopener  ugc nofollow" target="_blank"><div class="of ab fo"><div class="og ab oh cl cj oi"><h2 class="bd ir gy z fp oj fr fs ok fu fw ip bi translated">文本摘要方法综述</h2><div class="ol l"><h3 class="bd b gy z fp oj fr fs ok fu fw dk translated">对人类语言文本的真正语义理解，表现在对文本的有效概括上，很可能是人类语言研究的基础</h3></div><div class="om l"><p class="bd b dl z fp oj fr fs ok fu fw dk translated">www.kdnuggets.com</p></div></div><div class="on l"><div class="oo l op oq or on os lt oe"/></div></div></a></div><div class="ob oc gp gr od oe"><a href="https://blog.floydhub.com/gentle-introduction-to-text-summarization-in-machine-learning/" rel="noopener  ugc nofollow" target="_blank"><div class="of ab fo"><div class="og ab oh cl cj oi"><h2 class="bd ir gy z fp oj fr fs ok fu fw ip bi translated">机器学习中的文本摘要简介</h2><div class="ol l"><h3 class="bd b gy z fp oj fr fs ok fu fw dk translated">机器学习文本摘要是机器学习和自然语言领域的一个常见问题</h3></div><div class="om l"><p class="bd b dl z fp oj fr fs ok fu fw dk translated">blog.floydhub.com</p></div></div><div class="on l"><div class="ot l op oq or on os lt oe"/></div></div></a></div><p id="eafd" class="pw-post-body-paragraph kl km iq kn b ko ma kq kr ks mb ku kv kw mc ky kz la md lc ld le me lg lh li ij bi translated">https://www.youtube.com/watch?v=TQQlZhbC5ps<a class="ae lz" href="https://www.youtube.com/watch?v=TQQlZhbC5ps" rel="noopener ugc nofollow" target="_blank"/></p></div></div>    
</body>
</html>