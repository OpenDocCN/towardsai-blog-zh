<html>
<head>
<title>Build TensorFlow Lite Model with Firebase AutoML Vision Edge</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">用Firebase AutoML Vision Edge构建TensorFlow Lite模型</h1>
<blockquote>原文：<a href="https://pub.towardsai.net/build-tensorflow-lite-model-with-firebase-automl-vision-edge-580302435895?source=collection_archive---------1-----------------------#2019-07-03">https://pub.towardsai.net/build-tensorflow-lite-model-with-firebase-automl-vision-edge-580302435895?source=collection_archive---------1-----------------------#2019-07-03</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><figure class="is it gp gr iu iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi ir"><img src="../Images/6dbeb59c79fbf4de73d6175f0180db10.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*vkE6tlzY5-T1-4yY"/></div></div></figure><h2 id="cb18" class="jc jd je bd b dl jf jg jh ji jj jk dk jl translated" aria-label="kicker paragraph">用Firebase AutoML | <a class="ae ep" href="https://towardsai.net" rel="noopener ugc nofollow" target="_blank">向AI </a>构建TFL模型</h2><div class=""/><div class=""><h2 id="f024" class="pw-subtitle-paragraph kk jn je bd b kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb dk translated">用Firebase ML工具包训练第一个图像分类模型</h2></div><p id="e428" class="pw-post-body-paragraph lc ld je le b lf lg ko lh li lj kr lk ll lm ln lo lp lq lr ls lt lu lv lw lx im bi translated"><em class="ly">本文最初发表于</em><a class="ae lz" href="https://thinkmobile.dev" rel="noopener ugc nofollow" target="_blank"><em class="ly">think mobile . dev</em></a><em class="ly">—一个关于在移动应用中实现智能解决方案的博客(</em> <a class="ae lz" href="https://thinkmobile.dev/build-tensorflow-lite-model-with-firebase-automl-vision-edge/" rel="noopener ugc nofollow" target="_blank"> <em class="ly">链接到文章</em> </a> <em class="ly">)。</em></p><p id="eb59" class="pw-post-body-paragraph lc ld je le b lf lg ko lh li lj kr lk ll lm ln lo lp lq lr ls lt lu lv lw lx im bi translated">一年多以来，Firebase——移动和web开发的后端平台，在其产品组合中包含了ML Kit SDK。多亏了这个特性，在移动应用中实现机器学习解决方案变得更加容易，不管我们拥有什么样的ML技能。有了像文本识别或图像标签这样的API，我们可以通过几行代码将这些功能添加到我们的应用程序中。<br/> ML Kit还提供了一种简单的方法来插入定制的机器学习解决方案——我们提供TensorFlow Lite模型，Firebase负责将其部署到我们的应用程序中——多平台(Android和iOS)，离线或在线(模型可以在运行时按需下载与应用程序捆绑)，并提供简化的代码来实现解释器。</p><p id="81a5" class="pw-post-body-paragraph lc ld je le b lf lg ko lh li lj kr lk ll lm ln lo lp lq lr ls lt lu lv lw lx im bi translated">在Google I/O 2019期间，ML Kit有一些新的公告。最有趣的事情之一是<strong class="le jo">AutoML Vision Edge</strong>——基于图像的自动模型训练解决方案。</p><figure class="ma mb mc md gt iv"><div class="bz fp l di"><div class="me mf l"/></div></figure><p id="d870" class="pw-post-body-paragraph lc ld je le b lf lg ko lh li lj kr lk ll lm ln lo lp lq lr ls lt lu lv lw lx im bi translated">在本帖中，我们将为<a class="ae lz" href="http://benchmark.ini.rub.de/?section=gtsrb&amp;subsection=dataset" rel="noopener ugc nofollow" target="_blank"> GTSRB数据集</a>(交通标志)的一个小子集构建一个简单的分类模型，预览其结构，并将其放入app中测试实现。<br/>如果你想看看我们还能如何建立交通标志分类模型，我鼓励你查看博客文章:<a class="ae lz" href="https://thinkmobile.dev/mobile-intelligence-traffic-signs-classification-with-retrained-mobilenet-model/" rel="noopener ugc nofollow" target="_blank">用再训练的MobileNet模型进行交通标志分类</a>。</p><div class="is it gp gr iu mg"><a href="https://thinkmobile.dev/mobile-intelligence-traffic-signs-classification-with-retrained-mobilenet-model" rel="noopener  ugc nofollow" target="_blank"><div class="mh ab fo"><div class="mi ab mj cl cj mk"><h2 class="bd jo gy z fp ml fr fs mm fu fw jn bi translated">交通标志分类与再培训移动网络模型“想，移动！</h2><div class="mn l"><h3 class="bd b gy z fp ml fr fs mm fu fw dk translated">用于GTSRB数据集的TensorFlow Lite分类模型本文是关于构建机器学习的系列文章的一部分…</h3></div><div class="mo l"><p class="bd b dl z fp ml fr fs mm fu fw dk translated">thinkmobile.dev</p></div></div><div class="mp l"><div class="mq l mr ms mt mp mu ja mg"/></div></div></a></div><h1 id="65b3" class="mv mw je bd mx my mz na nb nc nd ne nf kt ng ku nh kw ni kx nj kz nk la nl nm bi translated">Firebase限制</h1><p id="60c4" class="pw-post-body-paragraph lc ld je le b lf nn ko lh li no kr lk ll np ln lo lp nq lr ls lt nr lv lw lx im bi translated">在Firebase平台中，免费计划<a class="ae lz" href="https://firebase.google.com/docs/ml-kit/automl-image-labeling#pricing" rel="noopener ugc nofollow" target="_blank">允许我们</a>为一个数据集训练一个模型，该数据集可以包含多达1000张图像。培训过程不会超过1小时，我们每个项目的总时间不会超过3小时。也许这看起来不多，但通常应该足以在一小部分数据上验证我们最初的想法。如果有任何指标表明该模型可以工作，那么为全尺寸数据集的训练支付几美元并不是一个坏主意。特别是如果我们在ML方面没有什么经验，或者没有强大的环境。</p><h1 id="fb4a" class="mv mw je bd mx my mz na nb nc nd ne nf kt ng ku nh kw ni kx nj kz nk la nl nm bi translated">数据集准备</h1><p id="ed37" class="pw-post-body-paragraph lc ld je le b lf nn ko lh li no kr lk ll np ln lo lp nq lr ls lt nr lv lw lx im bi translated">原始的GTSRB数据集包含超过50 000幅图像，其中每幅图像都由40个标签中的一个进行分类。更多关于dataset的信息可以在官网上找到。对于我们的演示项目，我们将使用一个包含1000张图片的子集，这些图片有10个不同的标签(每个标签100张图片)。<br/>在Firebase <a class="ae lz" href="https://firebase.google.com/docs/ml-kit/train-image-labeler#prepare_training_data" rel="noopener ugc nofollow" target="_blank">文档</a>上，你可以找到更多关于数据集需求的信息。简而言之，建议每节课100张以上。图像(jpg、png、BMP或gif)可以作为zip文件上传，其目录结构类似于:</p><figure class="ma mb mc md gt iv"><div class="bz fp l di"><div class="ns mf l"/></div><figcaption class="nt nu gj gh gi nv nw bd b be z dk translated">Firebase AutoML的示例数据结构(<a class="ae lz" href="https://firebase.google.com/docs/ml-kit/train-image-labeler#option_1_structured_zip_archive" rel="noopener ugc nofollow" target="_blank">文档</a>)</figcaption></figure><p id="35ea" class="pw-post-body-paragraph lc ld je le b lf lg ko lh li lj kr lk ll lm ln lo lp lq lr ls lt lu lv lw lx im bi translated">图像被组织在目录中，其中每一个都是根据其中所有文件的标签来命名的。</p><p id="b6a4" class="pw-post-body-paragraph lc ld je le b lf lg ko lh li lj kr lk ll lm ln lo lp lq lr ls lt lu lv lw lx im bi translated">下面是这篇博文中使用的数据集的zip文件:<a class="ae lz" href="https://github.com/frogermcs/TFLite-Checker/raw/master/assets/gtsrb_firebase.zip" rel="noopener ugc nofollow" target="_blank">链接</a>。</p><h1 id="0b11" class="mv mw je bd mx my mz na nb nc nd ne nf kt ng ku nh kw ni kx nj kz nk la nl nm bi translated">培养</h1><p id="660f" class="pw-post-body-paragraph lc ld je le b lf nn ko lh li no kr lk ll np ln lo lp nq lr ls lt nr lv lw lx im bi translated">当我们有了想要的数据集，我们需要把它放到Firebase ML工具包中并运行训练过程。<br/>为此:</p><ol class=""><li id="e24a" class="nx ny je le b lf lg li lj ll nz lp oa lt ob lx oc od oe of bi translated">在Firebase控制台上创建一个新项目，</li><li id="4fd1" class="nx ny je le b lf og li oh ll oi lp oj lt ok lx oc od oe of bi translated">开发-&gt; ML工具包-&gt; AutoML -&gt;添加数据集，</li><li id="a805" class="nx ny je le b lf og li oh ll oi lp oj lt ok lx oc od oe of bi translated">设置名称，选择"单标签分类"、</li><li id="7ccc" class="nx ny je le b lf og li oh ll oi lp oj lt ok lx oc od oe of bi translated">拖放。压缩图片，</li><li id="600c" class="nx ny je le b lf og li oh ll oi lp oj lt ok lx oc od oe of bi translated">导入完成后，我们可以开始培训过程。在最后一步，您将能够选择一些选项，如模型大小或精度。<br/>这里我们挑选精度更高、延迟更高的。</li></ol><p id="4688" class="pw-post-body-paragraph lc ld je le b lf lg ko lh li lj kr lk ll lm ln lo lp lq lr ls lt lu lv lw lx im bi translated">培训过程应该需要一个多小时。完成后，我们应该会收到一封电子邮件通知我们。</p><figure class="ma mb mc md gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi ol"><img src="../Images/89e34e676788616914f15de91898862b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*5mOYn9akjPBvxn4-"/></div></div><figcaption class="nt nu gj gh gi nv nw bd b be z dk translated">在ML试剂盒Auto ML中导入和标记数据的过程。</figcaption></figure><h1 id="dbd1" class="mv mw je bd mx my mz na nb nc nd ne nf kt ng ku nh kw ni kx nj kz nk la nl nm bi translated">模型概述</h1><p id="4ac8" class="pw-post-body-paragraph lc ld je le b lf nn ko lh li no kr lk ll np ln lo lp nq lr ls lt nr lv lw lx im bi translated">训练结束后，我们应该回到Firebase控制台。这是开始研究我们的模型的好地方——它的性能和准确性。我们还可以看到一个混淆矩阵——图像被正确分类的频率，或者哪些标签最常被混淆。在决定我们应该将哪些数据添加到我们的数据集中以提高模型的性能时，这可能很有帮助。</p><figure class="ma mb mc md gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi ol"><img src="../Images/296db91c3fbce0f85e7c38d858ffb092.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*Vzq-GZVydA6C61SK"/></div></div><figcaption class="nt nu gj gh gi nv nw bd b be z dk translated">展示数据集性能的混淆矩阵示例。</figcaption></figure></div><div class="ab cl om on hx oo" role="separator"><span class="op bw bk oq or os"/><span class="op bw bk oq or os"/><span class="op bw bk oq or"/></div><div class="im in io ip iq"><p id="1a6b" class="pw-post-body-paragraph lc ld je le b lf lg ko lh li lj kr lk ll lm ln lo lp lq lr ls lt lu lv lw lx im bi translated">现在，训练好的模型已经可以使用了。它可以发布在Firebase主机上——该应用程序将按需下载，但需要Firebase SDK。或者我们可以下载训练好的模型。tflite文件，然后决定如何在我们的代码中处理它(使用或不使用Firebase SDK)。虽然firebase托管有很多优点(动态更新模型，A/B测试模型)，但这里我们将选择第二个选项——get。tflite文件并“手动”实现。关于发布或下载模型的更多信息可以在<a class="ae lz" href="https://firebase.google.com/docs/ml-kit/train-image-labeler#publish_or_download" rel="noopener ugc nofollow" target="_blank"> Firebase文档中找到</a>。</p><p id="0e13" class="pw-post-body-paragraph lc ld je le b lf lg ko lh li lj kr lk ll lm ln lo lp lq lr ls lt lu lv lw lx im bi translated">太好了，我们有。tflite文件，但现在还不想使用Firebase SDK，那么该怎么办呢？我们应该从模型调查开始——它是输入和输出规范。为了学习它，我们将使用<a class="ae lz" href="https://github.com/lutzroeder/netron" rel="noopener ugc nofollow" target="_blank"> Netron </a>应用程序。如果想了解更多关于调查TensorFlow Lite模型的信息，可以看看博文:<a class="ae lz" href="https://thinkmobile.dev/inspecting-tensorflow-lite-image-classification-model/" rel="noopener ugc nofollow" target="_blank">考察TensorFlow Lite图像分类模型</a>。</p><div class="is it gp gr iu mg"><a href="https://thinkmobile.dev/inspecting-tensorflow-lite-image-classification-model" rel="noopener  ugc nofollow" target="_blank"><div class="mh ab fo"><div class="mi ab mj cl cj mk"><h2 class="bd jo gy z fp ml fr fs mm fu fw jn bi translated">检查TensorFlow Lite图像分类模型“思考，移动！</h2><div class="mn l"><h3 class="bd b gy z fp ml fr fs mm fu fw dk translated">在以前的帖子中在移动app中实现TFLite模型之前需要知道什么，要么是关于构建一个机器学习…</h3></div><div class="mo l"><p class="bd b dl z fp ml fr fs mm fu fw dk translated">thinkmobile.dev</p></div></div><div class="mp l"><div class="ot l mr ms mt mp mu ja mg"/></div></div></a></div><p id="1add" class="pw-post-body-paragraph lc ld je le b lf lg ko lh li lj kr lk ll lm ln lo lp lq lr ls lt lu lv lw lx im bi translated">以下是我们从Netron获得的模型的一些信息:</p><ul class=""><li id="40fc" class="nx ny je le b lf lg li lj ll nz lp oa lt ob lx ou od oe of bi translated">它是量化的(ML Kit AutoML默认创建量化模型)，</li><li id="a0e5" class="nx ny je le b lf og li oh ll oi lp oj lt ok lx ou od oe of bi translated">输入张量具有1×224×224×3维度(224×224图像大小，具有3个通道像素)，</li><li id="95d3" class="nx ny je le b lf og li oh ll oi lp oj lt ok lx ou od oe of bi translated">输出张量具有1×10维(10个标签)。</li></ul><figure class="ma mb mc md gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi ol"><img src="../Images/976fa4fcc6677e3b948b0f2ede65475f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*2vGjo0KMFpSMd_qW"/></div></div><figcaption class="nt nu gj gh gi nv nw bd b be z dk translated">ML套件AutoML模型在Netron中预览</figcaption></figure><h1 id="ea1f" class="mv mw je bd mx my mz na nb nc nd ne nf kt ng ku nh kw ni kx nj kz nk la nl nm bi translated">Android应用程序</h1><p id="33f1" class="pw-post-body-paragraph lc ld je le b lf nn ko lh li no kr lk ll np ln lo lp nq lr ls lt nr lv lw lx im bi translated">最后一步是关于将TensorFlow Lite模型放入我们的移动应用程序。在检查TensorFlow Lite图像分类模型的帖子<a class="ae lz" href="https://thinkmobile.dev/inspecting-tensorflow-lite-image-classification-model/" rel="noopener ugc nofollow" target="_blank">中做了非常类似的事情(参见</a><a class="ae lz" href="https://github.com/frogermcs/TFLite-Checker" rel="noopener ugc nofollow" target="_blank"> TFLite-Checker </a> Github库的实现)。在帖子中，我们实现了*。对输入和输出张量使用浮点值的tflite模型(它们是非量化模型)。现在我们要添加一个量化版本的TensorFlow Lite模型。<br/>反映这一点的所有更改都可以在<a class="ae lz" href="https://github.com/frogermcs/TFLite-Checker/commit/7dde56cc2022d57c9015d874dee90e43b0c5f442" rel="noopener ugc nofollow" target="_blank">提交</a>中看到。它们是关于什么的？</p><p id="8da1" class="pw-post-body-paragraph lc ld je le b lf lg ko lh li lj kr lk ll lm ln lo lp lq lr ls lt lu lv lw lx im bi translated">1-输入张量的ByteBuffer现在是字节数组，而不是浮点数组:</p><figure class="ma mb mc md gt iv"><div class="bz fp l di"><div class="ns mf l"/></div></figure><p id="8e39" class="pw-post-body-paragraph lc ld je le b lf lg ko lh li lj kr lk ll lm ln lo lp lq lr ls lt lu lv lw lx im bi translated">2-结果表示为字节数组。这意味着我们需要对值进行规范化——转换成表示范围[0，1]内概率的浮点数。</p><figure class="ma mb mc md gt iv"><div class="bz fp l di"><div class="ns mf l"/></div></figure><p id="2503" class="pw-post-body-paragraph lc ld je le b lf lg ko lh li lj kr lk ll lm ln lo lp lq lr ls lt lu lv lw lx im bi translated">其余部分与<a class="ae lz" href="https://thinkmobile.dev/inspecting-tensorflow-lite-image-classification-model/" rel="noopener ugc nofollow" target="_blank">检查TensorFlow Lite图像分类模型</a>文章中介绍的实现非常相似。</p><p id="1c29" class="pw-post-body-paragraph lc ld je le b lf lg ko lh li lj kr lk ll lm ln lo lp lq lr ls lt lu lv lw lx im bi translated">当我们运行该应用程序时，分类结果远非完美(将限速30和80混淆，等等。)，但我们需要记住，在训练期间，我们使用了50 000幅可用图像中的1000幅。在完整数据集上训练的模型很可能会有更好的性能。<br/>同样重要的是，我们还没有为机器模型训练编写一行代码(并为其在应用程序中的实现添加了一些基本代码)。然而，我们仍然有一个概念的工作证明。</p><figure class="ma mb mc md gt iv gh gi paragraph-image"><div class="gh gi ov"><img src="../Images/a102abf149075efe98c8c6aa4fbce95b.png" data-original-src="https://miro.medium.com/v2/resize:fit:996/0*b0epmS4m5xHccpm4"/></div><figcaption class="nt nu gj gh gi nv nw bd b be z dk translated">示例应用程序的分类结果。</figcaption></figure><h1 id="f2d6" class="mv mw je bd mx my mz na nb nc nd ne nf kt ng ku nh kw ni kx nj kz nk la nl nm bi translated">源代码</h1><p id="7e57" class="pw-post-body-paragraph lc ld je le b lf nn ko lh li no kr lk ll np ln lo lp nq lr ls lt nr lv lw lx im bi translated">这篇博文的源代码可以在<a class="ae lz" href="https://github.com/frogermcs/TFLite-Checker" rel="noopener ugc nofollow" target="_blank"> Github </a> (Android应用和Colab笔记本)上获得。</p><div class="is it gp gr iu mg"><a href="https://github.com/frogermcs/TFLite-Checker" rel="noopener  ugc nofollow" target="_blank"><div class="mh ab fo"><div class="mi ab mj cl cj mk"><h2 class="bd jo gy z fp ml fr fs mm fu fw jn bi translated">frogermcs/TFLite-Checker</h2><div class="mn l"><h3 class="bd b gy z fp ml fr fs mm fu fw dk translated">检查*。tflite模型来获得足够的知识，以便在Android应用程序中实现它们。- frogermcs/TFLite-Checker</h3></div><div class="mo l"><p class="bd b dl z fp ml fr fs mm fu fw dk translated">github.com</p></div></div><div class="mp l"><div class="ow l mr ms mt mp mu ja mg"/></div></div></a></div><p id="36e6" class="pw-post-body-paragraph lc ld je le b lf lg ko lh li lj kr lk ll lm ln lo lp lq lr ls lt lu lv lw lx im bi translated">感谢阅读！🙂<br/>请在下面分享您的反馈。👇</p><p id="4c6d" class="pw-post-body-paragraph lc ld je le b lf lg ko lh li lj kr lk ll lm ln lo lp lq lr ls lt lu lv lw lx im bi translated"><em class="ly">本文最初发表于</em><a class="ae lz" href="https://thinkmobile.dev" rel="noopener ugc nofollow" target="_blank"><em class="ly">think mobile . dev</em></a><em class="ly">—一个关于在移动应用中实现智能解决方案的博客(</em> <a class="ae lz" href="https://thinkmobile.dev/build-tensorflow-lite-model-with-firebase-automl-vision-edge/" rel="noopener ugc nofollow" target="_blank"> <em class="ly">链接到文章</em> </a> <em class="ly">)。</em></p><div class="is it gp gr iu mg"><a href="https://thinkmobile.dev/build-tensorflow-lite-model-with-firebase-automl-vision-edge/" rel="noopener  ugc nofollow" target="_blank"><div class="mh ab fo"><div class="mi ab mj cl cj mk"><h2 class="bd jo gy z fp ml fr fs mm fu fw jn bi translated">使用Firebase AutoML Vision Edge构建TensorFlow Lite模型“思考，移动！</h2><div class="mn l"><h3 class="bd b gy z fp ml fr fs mm fu fw dk translated">用Firebase ML工具包训练第一个图像分类模型已经一年多了，Firebase -后端平台…</h3></div><div class="mo l"><p class="bd b dl z fp ml fr fs mm fu fw dk translated">thinkmobile.dev</p></div></div><div class="mp l"><div class="ox l mr ms mt mp mu ja mg"/></div></div></a></div></div></div>    
</body>
</html>