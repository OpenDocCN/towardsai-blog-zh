<html>
<head>
<title>The Intuition Behind GANs for Beginners</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">初学者GANs背后的直觉</h1>
<blockquote>原文：<a href="https://pub.towardsai.net/intuition-behind-gan-for-beginners-bb4da5c54480?source=collection_archive---------0-----------------------#2021-10-19">https://pub.towardsai.net/intuition-behind-gan-for-beginners-bb4da5c54480?source=collection_archive---------0-----------------------#2021-10-19</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><h2 id="1518" class="io ip iq bd b dl ir is it iu iv iw dk ix translated" aria-label="kicker paragraph"><a class="ae ep" href="https://towardsai.net/p/category/machine-learning/deep-learning" rel="noopener ugc nofollow" target="_blank">深度学习</a></h2><div class=""/><figure class="gl gn jx jy jz ka gh gi paragraph-image"><div role="button" tabindex="0" class="kb kc di kd bf ke"><div class="gh gi jw"><img src="../Images/9e00cc32910e802292f5f212ef859291.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Lx4-GeKanLfUK19qtcIPwA.jpeg"/></div></div><figcaption class="kh ki gj gh gi kj kk bd b be z dk translated">照片来自Unsplash</figcaption></figure><p id="b8ec" class="pw-post-body-paragraph kl km iq kn b ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li ij bi lj translated"><span class="l lk ll lm bm ln lo lp lq lr di"> Y </span>你可能听说过<a class="ae ls" href="https://www.youtube.com/watch?v=T76bK2t2r8g" rel="noopener ugc nofollow" target="_blank">深度造假视频</a>或者访问过<a class="ae ls" href="https://thispersondoesnotexist.com/" rel="noopener ugc nofollow" target="_blank">这个人不出境</a>，在那里甘被用来创造那些。很有趣吧。在这篇文章中，我们将深入讨论GAN背后的基本直觉，以及它在Tensorflow中的实现。让我们开始吧。</p><p id="4a7e" class="pw-post-body-paragraph kl km iq kn b ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li ij bi translated">简而言之，GAN是一种使用深度学习方法(如卷积神经网络)进行生成建模的方法。生成建模是机器学习中的一项无监督学习任务，其目标是找到输入数据中的隐藏模式，并产生与输入数据具有相似特征的似是而非的图像。</p><p id="6b49" class="pw-post-body-paragraph kl km iq kn b ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li ij bi translated">GAN能够通过训练称为<strong class="kn ja">生成器</strong>和<strong class="kn ja">鉴别器</strong>(也称为<strong class="kn ja">鉴别器</strong>)的两个竞争(和合作)网络来学习如何对输入分布建模。生成器的任务是不断找出如何生成假数据或信号来欺骗鉴别器。最初，一些噪声输入被提供给发电机以对其进行处理。另一方面，训练鉴别器来区分假信号和真信号。</p><p id="5914" class="pw-post-body-paragraph kl km iq kn b ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li ij bi translated">GAN的主要概念很简单。GAN模型架构包括两个子模型:用于生成新示例的生成器模型和用于对所生成的示例是真实的(来自域)还是虚假的(由生成器模型生成)进行分类的鉴别器模型。让我们把它看成:</p><figure class="lu lv lw lx gt ka gh gi paragraph-image"><div role="button" tabindex="0" class="kb kc di kd bf ke"><div class="gh gi lt"><img src="../Images/2f64ee0125fd478c44bfd5ad928b3e96.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*TXMkOzMORL1jEnUhRuIm9g.png"/></div></div><figcaption class="kh ki gj gh gi kj kk bd b be z dk translated">鉴别器和发生器模型</figcaption></figure><ul class=""><li id="e527" class="ly lz iq kn b ko kp ks kt kw ma la mb le mc li md me mf mg bi translated"><strong class="kn ja">鉴别器</strong>:学习如何将输入分类为真实(来自域)或虚假(生成)的模型。</li><li id="7c2c" class="ly lz iq kn b ko mh ks mi kw mj la mk le ml li md me mf mg bi translated"><strong class="kn ja">生成器</strong>:从问题域生成新的相似图像的模型。</li></ul><figure class="lu lv lw lx gt ka gh gi paragraph-image"><div class="gh gi mm"><img src="../Images/3f0bea940d061c8a2c76b8e64d984204.png" data-original-src="https://miro.medium.com/v2/resize:fit:1246/format:webp/1*ysg3iB3-7P2ccZp06i6otQ.png"/></div><figcaption class="kh ki gj gh gi kj kk bd b be z dk translated">生成器尝试生成类似于输入分布的可信图像</figcaption></figure><h1 id="4445" class="mn mo iq bd mp mq mr ms mt mu mv mw mx my mz na nb nc nd ne nf ng nh ni nj nk bi translated">甘是怎么工作的？</h1><p id="38fb" class="pw-post-body-paragraph kl km iq kn b ko nl kq kr ks nm ku kv kw nn ky kz la no lc ld le np lg lh li ij bi translated">构成GAN的两个神经网络被称为生成器和鉴别器。GAN生成器生成新的数据实例，鉴别器验证它们是属于数据集(真实的)还是生成的(虚假的)。鉴别器是一个全连接的神经网络，它将输入的示例分类为真实(1.0)或虚假(0.0)。每隔一段时间，生成器将假装其输出是真正的数据，并要求鉴别器将其标记为1.0。当假数据随后被呈现给<br/>鉴别器时，自然会被归类为标签接近0.0的假数据。</p><p id="61ba" class="pw-post-body-paragraph kl km iq kn b ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li ij bi translated">总的来说，整个过程是两个网络在相互合作的同时相互竞争。最后，当GAN训练收敛时，最终结果是一个生成器，它可以生成看似真实的似是而非的数据。鉴别器认为这个合成的数据是真实的，并将其标记为1.0。</p><figure class="lu lv lw lx gt ka gh gi paragraph-image"><div role="button" tabindex="0" class="kb kc di kd bf ke"><div class="gh gi nq"><img src="../Images/ecb79170fedc2303d2eb1bcbbcf0ba22.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*zchEX4YCEAPiEFk0tU6cmA.png"/></div></div><figcaption class="kh ki gj gh gi kj kk bd b be z dk translated">GAN:两个网络-&gt;生成器和鉴别器</figcaption></figure><p id="4f1b" class="pw-post-body-paragraph kl km iq kn b ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li ij bi translated">发生器的输入是噪声，输出是合成数据。同时，鉴别器的输入将是真实的或合成的数据。真实数据来自真实的采样数据，而假数据来自发生器。所有真实数据被标记为1.0(即100%真实概率)，而所有合成数据(虚假数据)被标记为0.0(即0%真实概率)。下面是GAN作者的一个算法:</p><figure class="lu lv lw lx gt ka gh gi paragraph-image"><div role="button" tabindex="0" class="kb kc di kd bf ke"><div class="gh gi nr"><img src="../Images/66bbef00ab0b5476481242e5883ab5f6.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*QVggBQDKnLt4VODt_y_ODA.png"/></div></div><figcaption class="kh ki gj gh gi kj kk bd b be z dk translated">原始论文中的算法:Goodfellow，Ian等[1]</figcaption></figure><p id="f564" class="pw-post-body-paragraph kl km iq kn b ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li ij bi translated">如您所见，鉴别器更新了k步，然后生成器才更新。这个过程不断重复。k可以设置为1，但通常值越大越好(Goodfellow等人，2014)。任何基于梯度的学习规则都可以用于优化。</p><p id="5733" class="pw-post-body-paragraph kl km iq kn b ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li ij bi translated">上述算法中显示的损失函数称为最小最大损失。因为生成器试图最小化函数，而鉴别器试图最大化函数。它可以写成:</p><figure class="lu lv lw lx gt ka gh gi paragraph-image"><div class="gh gi ns"><img src="../Images/0bf3761c7a9279f56f7090a819e12a4a.png" data-original-src="https://miro.medium.com/v2/resize:fit:754/format:webp/1*ziJg1iXfdxRRJkoOt0KJ9A.png"/></div><figcaption class="kh ki gj gh gi kj kk bd b be z dk translated">最小最大损失方程</figcaption></figure><p id="5f81" class="pw-post-body-paragraph kl km iq kn b ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li ij bi translated">一些批注是:</p><p id="4d89" class="pw-post-body-paragraph kl km iq kn b ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li ij bi translated">d(x)→鉴别器判定给定真实数据实例x为真实的概率。</p><p id="81fe" class="pw-post-body-paragraph kl km iq kn b ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li ij bi translated">Eₓ →总体实例的期望值。</p><p id="7f20" class="pw-post-body-paragraph kl km iq kn b ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li ij bi translated">G(z) →发电机输出给出噪声矢量z。</p><p id="3c35" class="pw-post-body-paragraph kl km iq kn b ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li ij bi translated">D(G(z)) →鉴别器给出的假数据实例z为真的概率。</p><p id="89b9" class="pw-post-body-paragraph kl km iq kn b ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li ij bi translated">E𝓏 →期望值总体生成虚假实例。</p><p id="dd92" class="pw-post-body-paragraph kl km iq kn b ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li ij bi translated">发电机不能直接影响函数中的<code class="fe nt nu nv nw b">log(D(x))</code>项，所以，对于发电机来说，最小化损耗就相当于最小化<code class="fe nt nu nv nw b">log(1 - D(G(z)))</code>。</p><p id="63aa" class="pw-post-body-paragraph kl km iq kn b ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li ij bi translated">总而言之，生成模型和判别模型之间的区别在于:</p><ul class=""><li id="91d5" class="ly lz iq kn b ko kp ks kt kw ma la mb le mc li md me mf mg bi translated">一个<strong class="kn ja">判别</strong>模型学习一个函数，该函数将输入数据(<em class="nx"> x </em>)映射到某个期望的输出类标签(<em class="nx"> y </em>)。用概率术语来说，他们直接学习条件分布<em class="nx"> P(y|x) </em>。</li><li id="962a" class="ly lz iq kn b ko mh ks mi kw mj la mk le ml li md me mf mg bi translated"><strong class="kn ja">生成型</strong>模型试图同时学习输入数据和标签的联合概率，即<em class="nx"> P(x，y) </em>。这可以通过贝叶斯规则转换为<em class="nx"> P(y|x) </em>用于分类，但是生成能力也可以用于其他事情，例如创建可能的新<em class="nx"> (x，y) </em>样本。</li></ul><p id="cf75" class="pw-post-body-paragraph kl km iq kn b ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li ij bi translated"><strong class="kn ja">训练鉴别器</strong></p><p id="e7a1" class="pw-post-body-paragraph kl km iq kn b ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li ij bi translated">鉴别器连接到两个损失函数。在鉴频器训练期间，鉴频器忽略发电机损耗，仅使用鉴频器损耗。我们在发电机培训中使用发电机损耗。</p><figure class="lu lv lw lx gt ka gh gi paragraph-image"><div role="button" tabindex="0" class="kb kc di kd bf ke"><div class="gh gi ny"><img src="../Images/860eb1891fcb07b83ca2c50853a3139b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*8xo_fa7-P9BvactmEaxkMQ.png"/></div></div><figcaption class="kh ki gj gh gi kj kk bd b be z dk translated"><strong class="bd mp">鉴别器训练中的反向传播</strong></figcaption></figure><p id="860a" class="pw-post-body-paragraph kl km iq kn b ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li ij bi translated">鉴别器的训练数据来自两个来源:</p><ul class=""><li id="20c0" class="ly lz iq kn b ko kp ks kt kw ma la mb le mc li md me mf mg bi translated"><strong class="kn ja">真实数据</strong>实例，如人的真实照片。鉴别器在训练中使用这些实例作为正面例子。</li><li id="3966" class="ly lz iq kn b ko mh ks mi kw mj la mk le ml li md me mf mg bi translated"><strong class="kn ja">假数据</strong>实例由生成器创建。鉴别器在训练中使用这些实例作为反面例子。</li></ul><p id="1cc4" class="pw-post-body-paragraph kl km iq kn b ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li ij bi translated">在上图中，两个“样本”框代表这两个输入鉴别器的数据源。在鉴别器训练期间，发电机不训练。它的权重保持不变，同时为鉴别器提供训练样本。</p><p id="71cd" class="pw-post-body-paragraph kl km iq kn b ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li ij bi translated">在鉴频器训练期间:</p><ol class=""><li id="cf1b" class="ly lz iq kn b ko kp ks kt kw ma la mb le mc li nz me mf mg bi translated">鉴别器对来自生成器的真实数据和虚假数据进行分类。</li><li id="0385" class="ly lz iq kn b ko mh ks mi kw mj la mk le ml li nz me mf mg bi translated">鉴别器损失惩罚将真实实例误分类为假实例或将假实例误分类为真实实例的鉴别器。</li><li id="60ee" class="ly lz iq kn b ko mh ks mi kw mj la mk le ml li nz me mf mg bi translated">鉴别器通过鉴别器网络从鉴别器损耗反向传播来更新其权重。</li></ol><p id="f9a0" class="pw-post-body-paragraph kl km iq kn b ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li ij bi translated"><strong class="kn ja">训练生成器</strong></p><p id="4e92" class="pw-post-body-paragraph kl km iq kn b ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li ij bi translated">GAN的发生器部分通过接受来自鉴别器的反馈来学习创建假数据。来自鉴频器的反馈有助于发生器随着时间的推移改善其输出。它学习使鉴别器将其输出分类为真实的。</p><figure class="lu lv lw lx gt ka gh gi paragraph-image"><div role="button" tabindex="0" class="kb kc di kd bf ke"><div class="gh gi oa"><img src="../Images/6de350f1849d71fe77021c73f8294e2e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*q1AK19ACgrQCpuKhAH5k8g.png"/></div></div><figcaption class="kh ki gj gh gi kj kk bd b be z dk translated"><strong class="bd mp">发电机培训中的反向传播</strong></figcaption></figure><p id="18f9" class="pw-post-body-paragraph kl km iq kn b ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li ij bi translated">上图描述了发电机的训练。它包括鉴别器和发生器的组合。发生器的输出传递到鉴别器网络，鉴别器与实际输出和输出损耗进行比较。发生器损耗惩罚发生器产生被鉴别器网络分类为假的样本。</p><p id="5e83" class="pw-post-body-paragraph kl km iq kn b ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li ij bi translated">反向传播通过计算权重对输出的影响，在正确的方向上调整每个权重。鉴别器参数被冻结，但梯度被传递到发生器。因此，反向传播从输出端开始，通过鉴频器流回发生器。</p><p id="5aba" class="pw-post-body-paragraph kl km iq kn b ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li ij bi translated">发生器训练要求发生器和鉴别器之间的集成比鉴别器训练要求的更紧密。训练生成器的一次迭代包括以下过程:</p><ol class=""><li id="122b" class="ly lz iq kn b ko kp ks kt kw ma la mb le mc li nz me mf mg bi translated">样本随机噪声。</li><li id="d5d0" class="ly lz iq kn b ko mh ks mi kw mj la mk le ml li nz me mf mg bi translated">从采样的随机噪声产生发电机输出。</li><li id="4ebe" class="ly lz iq kn b ko mh ks mi kw mj la mk le ml li nz me mf mg bi translated">获取生成器输出的鉴别器“真实”或“虚假”分类。</li><li id="417b" class="ly lz iq kn b ko mh ks mi kw mj la mk le ml li nz me mf mg bi translated">计算鉴别器分类的损失。</li><li id="988a" class="ly lz iq kn b ko mh ks mi kw mj la mk le ml li nz me mf mg bi translated">通过鉴别器和发生器反向传播以获得梯度。</li><li id="cb88" class="ly lz iq kn b ko mh ks mi kw mj la mk le ml li nz me mf mg bi translated">使用渐变仅更改发生器权重。(鉴别器重量被冻结)</li></ol><p id="60be" class="pw-post-body-paragraph kl km iq kn b ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li ij bi translated">训练GAN的伪代码:</p><figure class="lu lv lw lx gt ka gh gi paragraph-image"><div class="ab gu cl ob"><img src="../Images/4c25ae9fce1db24798cd64af995e01cd.png" data-original-src="https://miro.medium.com/v2/format:webp/1*tVVmKQUfsjaX4Mnq7CCvlA.png"/></div><figcaption class="kh ki gj gh gi kj kk bd b be z dk translated">GAN训练的伪代码</figcaption></figure><p id="c620" class="pw-post-body-paragraph kl km iq kn b ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li ij bi translated">现在你明白甘的基本直觉了。让我们尝试在Tensorflow 2中实现一个DCGAN。</p><p id="fecb" class="pw-post-body-paragraph kl km iq kn b ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li ij bi translated"><strong class="kn ja">张量流中的简单DC甘2 </strong></p><figure class="lu lv lw lx gt ka gh gi paragraph-image"><div class="gh gi oc"><img src="../Images/d25c2b1ae2b623c570a7076d90b4a4a6.png" data-original-src="https://miro.medium.com/v2/resize:fit:1242/format:webp/1*e1EqCBqfETIl_tgsZ7DZhA.png"/></div><figcaption class="kh ki gj gh gi kj kk bd b be z dk translated">DCGAN模型</figcaption></figure><p id="ede7" class="pw-post-body-paragraph kl km iq kn b ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li ij bi translated">发生器接受从均匀分布中采样的100维z矢量噪声。然后使用具有批量归一化和RELU激活函数的多层Conv2DTranspose。基本上，conv 2d将样本图像从100个暗淡向量转置到给定的形状。批量归一化用于收敛和快速训练。最后一层有sigmoid激活，生成28 x 28 x 1的假MNIST图像。</p><p id="a3f4" class="pw-post-body-paragraph kl km iq kn b ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li ij bi translated"><strong class="kn ja">代码:</strong></p><p id="c05b" class="pw-post-body-paragraph kl km iq kn b ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li ij bi translated">完整的代码可以在这个协作笔记本<a class="ae ls" href="https://colab.research.google.com/drive/1rAc9fyQbyT7daw4YL2Y5ZRNDin8GlHPI?usp=sharing" rel="noopener ugc nofollow" target="_blank">链接</a>中找到。</p><figure class="lu lv lw lx gt ka"><div class="bz fp l di"><div class="od oe l"/></div></figure><p id="5a47" class="pw-post-body-paragraph kl km iq kn b ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li ij bi translated">鉴别器类似于CNN图像分类器。它需要28x28x1的图像。它获取真实和虚假的图像，并将它们连接起来。它由具有leakyRELU激活功能的CONV2D层组成。最后一层是sigmoid，它输出1(真)或0(假)输出。</p><figure class="lu lv lw lx gt ka"><div class="bz fp l di"><div class="od oe l"/></div></figure><p id="fc10" class="pw-post-body-paragraph kl km iq kn b ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li ij bi translated">首先建立鉴别器模型，然后实例化生成器模型。最后，我们将鉴别器和生成器组合成对抗模型，并对它们进行训练。</p><figure class="lu lv lw lx gt ka"><div class="bz fp l di"><div class="od oe l"/></div></figure><p id="57f5" class="pw-post-body-paragraph kl km iq kn b ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li ij bi translated">输出:</p><figure class="lu lv lw lx gt ka gh gi paragraph-image"><div class="gh gi of"><img src="../Images/2a84fb1f350a9d47c084b2a6060130f6.png" data-original-src="https://miro.medium.com/v2/resize:fit:440/0*fxYCYBE54mEg4uSx"/></div></figure><p id="aff1" class="pw-post-body-paragraph kl km iq kn b ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li ij bi translated"><strong class="kn ja">参考文献</strong></p><p id="1965" class="pw-post-body-paragraph kl km iq kn b ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li ij bi translated">古德菲勒，伊恩，等着，〈生成性对抗性网络〉。神经信息处理系统进展。2014.</p><p id="b0a5" class="pw-post-body-paragraph kl km iq kn b ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li ij bi translated">[2]阿蒂恩萨，罗威尔。<em class="nx">使用Tensorflow 2和Keras的高级深度学习:应用DL、Gans、Vaes、Deep RL、无监督学习、物体检测和分割等等</em>。帕克特出版有限公司，2020年。</p><p id="a197" class="pw-post-body-paragraph kl km iq kn b ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li ij bi translated"><em class="nx">如果你喜欢，请分享并点击我非常欣赏的绿色图标。</em></p><figure class="lu lv lw lx gt ka gh gi paragraph-image"><div role="button" tabindex="0" class="kb kc di kd bf ke"><div class="gh gi og"><img src="../Images/2c9c73c410c025ffffffa8dfee10dbce.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/1*OBAJEpu9Izgs6ThKjUvTeA.gif"/></div></div></figure></div></div>    
</body>
</html>