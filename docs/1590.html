<html>
<head>
<title>OpenAI’s DALL·E: Text-to-Image Generation Explained</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">OpenAI的DALL E:解释文本到图像的生成</h1>
<blockquote>原文：<a href="https://pub.towardsai.net/openais-dall-e-text-to-image-generation-explained-1f6fb4bb5a0a?source=collection_archive---------2-----------------------#2021-02-28">https://pub.towardsai.net/openais-dall-e-text-to-image-generation-explained-1f6fb4bb5a0a?source=collection_archive---------2-----------------------#2021-02-28</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><h2 id="eb6d" class="ir is it bd b dl iu iv iw ix iy iz dk ja translated" aria-label="kicker paragraph"><a class="ae ep" href="https://towardsai.net/p/category/computer-vision" rel="noopener ugc nofollow" target="_blank">计算机视觉</a></h2><div class=""/><div class=""><h2 id="3026" class="pw-subtitle-paragraph jz jc it bd b ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq dk translated">OpenAI刚刚发布了解释DALL-E如何工作的论文！它被称为“零镜头文本到图像的生成”。</h2></div><blockquote class="kr ks kt"><p id="597e" class="ku kv kw kx b ky kz kd la lb lc kg ld le lf lg lh li lj lk ll lm ln lo lp lq im bi translated">原载于<a class="ae lr" href="https://www.louisbouchard.ai/openais-dall-e-text-to-image-generation-explained/" rel="noopener ugc nofollow" target="_blank"> louisbouchard.ai </a>，前两天在<a class="ae lr" href="https://www.louisbouchard.ai/tag/artificial-intelligence/" rel="noopener ugc nofollow" target="_blank">我的博客</a>上看到的！</p></blockquote><figure class="lt lu lv lw gt lx gh gi paragraph-image"><div role="button" tabindex="0" class="ly lz di ma bf mb"><div class="gh gi ls"><img src="../Images/4c35a8ed1ff0d8fbbce76fab8c07833e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*1Iw0SAKfc0f2-6Ayk-jJQQ.png"/></div></div></figure><p id="d44a" class="pw-post-body-paragraph ku kv it kx b ky kz kd la lb lc kg ld me lf lg lh mf lj lk ll mg ln lo lp lq im bi translated">它使用转换器架构从作为输入发送到网络的文本和基本图像生成图像。但它并不是简单地获取图像和文本，并将其发送到网络。首先，为了被transformer架构“理解”,信息需要被建模成一个单独的数据流。这是因为直接使用图像的像素对于高分辨率图像来说需要太多的内存。</p><figure class="lt lu lv lw gt lx gh gi paragraph-image"><div role="button" tabindex="0" class="ly lz di ma bf mb"><div class="gh gi mh"><img src="../Images/7114c22f31b9bb23d9732bace8d5a322.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*flCzuobeBgyW8nXObIdjjg.png"/></div></div><figcaption class="mi mj gj gh gi mk ml bd b be z dk translated">A.Ramesh等人，<a class="ae lr" href="https://arxiv.org/pdf/2102.12092.pdf" rel="noopener ugc nofollow" target="_blank">零镜头文本到图像生成</a>，2021。arXiv:2102.12092 [cs。简历]</figcaption></figure><p id="a1c8" class="pw-post-body-paragraph ku kv it kx b ky kz kd la lb lc kg ld me lf lg lh mf lj lk ll mg ln lo lp lq im bi translated">相反，他们使用一种称为dVAE的离散变分自动编码器，它将输入图像转换为32 x 32的网格，结果产生1024个图像标记，而不是高分辨率图像的数百万个标记。事实上，这个dVAE网络的唯一任务是通过生成新版本的图像来减少转换器的内存占用。当然，这也有一些缺点，虽然它保存了最重要的特征，但有时也会丢失精细的细节，使得它无法用于基于非常精确的图像特征的精细应用。你可以把它看作是一种图像压缩步骤。dVAE中的编码器和解码器由具有跳跃连接的经典卷积和ResNet架构组成。</p><p id="b182" class="pw-post-body-paragraph ku kv it kx b ky kz kd la lb lc kg ld me lf lg lh mf lj lk ll mg ln lo lp lq im bi translated">如果你以前从未听说过可变自动编码器，我强烈推荐你看我制作的解释它们的视频。</p><figure class="lt lu lv lw gt lx"><div class="bz fp l di"><div class="mm mn l"/></div></figure><p id="f463" class="pw-post-body-paragraph ku kv it kx b ky kz kd la lb lc kg ld me lf lg lh mf lj lk ll mg ln lo lp lq im bi translated">而且这个dVAE网络也在<a class="ae lr" href="https://github.com/openai/DALL-E" rel="noopener ugc nofollow" target="_blank"> OpenAI的GitHub </a>里分享过，带着笔记本自己试一下，实现细节在论文里，链接在下面的参考文献里！</p><figure class="lt lu lv lw gt lx gh gi paragraph-image"><div role="button" tabindex="0" class="ly lz di ma bf mb"><div class="gh gi mo"><img src="../Images/37de576cf89f0610857ac2bc293072df.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*q7F4N51nJ78d7OyEG0OV_Q.png"/></div></div><figcaption class="mi mj gj gh gi mk ml bd b be z dk translated">A.Ramesh等人，<a class="ae lr" href="https://arxiv.org/pdf/2102.12092.pdf" rel="noopener ugc nofollow" target="_blank">零镜头文本到图像生成</a>，2021。arXiv:2102.12092 [cs。简历]</figcaption></figure><p id="6621" class="pw-post-body-paragraph ku kv it kx b ky kz kd la lb lc kg ld me lf lg lh mf lj lk ll mg ln lo lp lq im bi translated">由离散VAE模型产生的这些图像标记随后与文本一起作为输入被发送到变换器模型。再次，正如我在之前关于Dall-E的视频中所描述的，这个变压器是一个120亿参数的稀疏变压器模型。</p><figure class="lt lu lv lw gt lx"><div class="bz fp l di"><div class="mm mn l"/></div></figure><p id="54d6" class="pw-post-body-paragraph ku kv it kx b ky kz kd la lb lc kg ld me lf lg lh mf lj lk ll mg ln lo lp lq im bi translated">我在之前的视频中已经介绍过，变压器的架构并不复杂，它是一种序列到序列模型，通常使用编码器和解码器。</p><figure class="lt lu lv lw gt lx"><div class="bz fp l di"><div class="mm mn l"/></div></figure><p id="8da9" class="pw-post-body-paragraph ku kv it kx b ky kz kd la lb lc kg ld me lf lg lh mf lj lk ll mg ln lo lp lq im bi translated">在这种情况下，它仅使用解码器，因为它将dVAE生成的图像和文本作为输入。由离散VAE生成的1024个图像标记中的每一个都可以访问所有文本标记，并且使用自我注意，它可以预测最佳的图像-文本配对。</p><figure class="lt lu lv lw gt lx gh gi paragraph-image"><div role="button" tabindex="0" class="ly lz di ma bf mb"><div class="gh gi mp"><img src="../Images/d0d6a73f017e843a62f06aec65db1d03.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*wxXW-FcSOqGp_sTVI-LY5A.png"/></div></div><figcaption class="mi mj gj gh gi mk ml bd b be z dk translated">OpenAI回形针&amp;代码:<a class="ae lr" href="https://openai.com/blog/clip/" rel="noopener ugc nofollow" target="_blank">https://openai.com/blog/clip/</a></figcaption></figure><figure class="lt lu lv lw gt lx gh gi paragraph-image"><div role="button" tabindex="0" class="ly lz di ma bf mb"><div class="gh gi mq"><img src="../Images/cbe9389f7bf9b37d77539001ae6a45a5.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*1QoHhIAR6vVU_H8L8FiuDQ.png"/></div></div><figcaption class="mi mj gj gh gi mk ml bd b be z dk translated">OpenAI回形针&amp;代码:【https://openai.com/blog/clip/ T2】</figcaption></figure><p id="11f8" class="pw-post-body-paragraph ku kv it kx b ky kz kd la lb lc kg ld me lf lg lh mf lj lk ll mg ln lo lp lq im bi translated">然后，它最终被输入到一个预先训练的对比模型中。这实际上是OpenAI在一月初发布的预训练剪辑模型。它用于优化图像和特定文本之间的关系。给定由转换器生成的图像和初始字幕，CLIP会根据图像与字幕的匹配程度来分配分数。CLIP模型甚至被用在Unsplash图像上，以帮助您找到您正在寻找的图像，以及从文本输入中找到视频中的特定帧。</p><figure class="lt lu lv lw gt lx gh gi paragraph-image"><div role="button" tabindex="0" class="ly lz di ma bf mb"><div class="gh gi mr"><img src="../Images/9962bd7cd630844e362663ff5cbe7213.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*WMrzLey3IhrINKixO2Hnfw.jpeg"/></div></div><figcaption class="mi mj gj gh gi mk ml bd b be z dk translated"><a class="ae lr" href="https://github.com/haltakov/natural-language-image-search" rel="noopener ugc nofollow" target="_blank">用于不平滑图像搜索的剪辑</a></figcaption></figure><figure class="lt lu lv lw gt lx gh gi paragraph-image"><div role="button" tabindex="0" class="ly lz di ma bf mb"><div class="gh gi ms"><img src="../Images/150db1426e8d65b670b2af8bca771308.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*nZau-V6X0PolEHBLat7-Yw.png"/></div></div><figcaption class="mi mj gj gh gi mk ml bd b be z dk translated">OpenAI回形针&amp;代码:<a class="ae lr" href="https://openai.com/blog/clip/" rel="noopener ugc nofollow" target="_blank">https://openai.com/blog/clip/</a></figcaption></figure><p id="8d4f" class="pw-post-body-paragraph ku kv it kx b ky kz kd la lb lc kg ld me lf lg lh mf lj lk ll mg ln lo lp lq im bi translated">当然，在我们的例子中，我们已经生成了一个图像，我们只是希望它匹配文本输入。嗯，CLIP仍然为我们提供了一个完美的衡量标准，可以用作惩罚函数，在训练期间迭代地改善变压器解码器的结果。CLIP的能力非常类似于GPT-2和GPT-3的“零射击”能力。类似地，CLIP也在4亿个文本-图像对的巨大数据集上进行训练。这种零拍摄能力意味着它对在训练数据集中找不到的图像和文本样本起作用，这些样本也被称为看不见的对象类别。</p><figure class="lt lu lv lw gt lx gh gi paragraph-image"><div role="button" tabindex="0" class="ly lz di ma bf mb"><div class="gh gi mt"><img src="../Images/7aa3ea6f98d840c76b0bfdfa33ad09c1.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*DsgMrEmdiPLKHwdYCO04HQ.png"/></div></div><figcaption class="mi mj gj gh gi mk ml bd b be z dk translated">A.Ramesh等人，<a class="ae lr" href="https://arxiv.org/pdf/2102.12092.pdf" rel="noopener ugc nofollow" target="_blank">零镜头文本到图像生成</a>，2021。arXiv:2102.12092 [cs。简历]</figcaption></figure><p id="f9dc" class="pw-post-body-paragraph ku kv it kx b ky kz kd la lb lc kg ld me lf lg lh mf lj lk ll mg ln lo lp lq im bi translated">最后，使用从互联网上获取的2.5亿个文本-图像对来训练整体架构，其中大部分来自维基百科，它基本上学习基于给定的令牌作为输入来生成新的图像，就像我们在文章前面描述的那样。这是可能的，因为变形金刚在训练期间可以使用更多的并行化，使其速度更快，同时产生更准确的结果，当与适当的编码系统一起使用时，它是强大的自然语言工具和强大的计算机视觉工具。</p><p id="38dc" class="pw-post-body-paragraph ku kv it kx b ky kz kd la lb lc kg ld me lf lg lh mf lj lk ll mg ln lo lp lq im bi translated">当然，这只是OpenAI这篇新论文的概述。我强烈建议阅读这篇文章和回形针，以便更好地理解这种方法。</p><h2 id="7039" class="mu mv it bd mw mx my dn mz na nb dp nc me nd ne nf mf ng nh ni mg nj nk nl iz bi translated">观看更多的例子和完整的解释</h2><figure class="lt lu lv lw gt lx"><div class="bz fp l di"><div class="mm mn l"/></div></figure></div><div class="ab cl nm nn hx no" role="separator"><span class="np bw bk nq nr ns"/><span class="np bw bk nq nr ns"/><span class="np bw bk nq nr"/></div><div class="im in io ip iq"><p id="b078" class="pw-post-body-paragraph ku kv it kx b ky kz kd la lb lc kg ld me lf lg lh mf lj lk ll mg ln lo lp lq im bi translated">如果你喜欢我的工作，并想了解最新的人工智能技术，你绝对应该在我的社交媒体频道上关注我。</p><ul class=""><li id="0fc0" class="nt nu it kx b ky kz lb lc me nv mf nw mg nx lq ny nz oa ob bi translated">订阅我的<a class="ae lr" href="https://www.youtube.com/channel/UCUzGQrN-lyyc0BWTYoJM_Sg" rel="noopener ugc nofollow" target="_blank"> <strong class="kx jd"> YouTube频道</strong> </a>。</li><li id="469d" class="nt nu it kx b ky oc lb od me oe mf of mg og lq ny nz oa ob bi translated">关注我的项目上<a class="ae lr" href="https://www.linkedin.com/in/whats-ai/" rel="noopener ugc nofollow" target="_blank"> <strong class="kx jd"> LinkedIn </strong> </a> <strong class="kx jd"> </strong>和这里上<strong class="kx jd"> </strong> <a class="ae lr" href="https://whats-ai.medium.com/" rel="noopener"> <strong class="kx jd">中</strong> </a> <strong class="kx jd">。</strong></li><li id="b388" class="nt nu it kx b ky oc lb od me oe mf of mg og lq ny nz oa ob bi translated">一起学习AI，加入我们的<a class="ae lr" href="https://discord.gg/learnaitogether" rel="noopener ugc nofollow" target="_blank"> <strong class="kx jd">不和谐社区</strong> </a>，<em class="kw">分享你的项目、论文、最佳课程，寻找Kaggle队友，等等！</em></li></ul></div><div class="ab cl nm nn hx no" role="separator"><span class="np bw bk nq nr ns"/><span class="np bw bk nq nr ns"/><span class="np bw bk nq nr"/></div><div class="im in io ip iq"><h1 id="e346" class="oh mv it bd mw oi oj ok mz ol om on nc ki oo kj nf kl op km ni ko oq kp nl or bi translated">参考</h1><ul class=""><li id="fdab" class="nt nu it kx b ky os lb ot me ou mf ov mg ow lq ny nz oa ob bi translated">A.Ramesh等人，零拍摄文本到图像的生成，2021年。arXiv:2102.12092 [cs。简历]</li><li id="1065" class="nt nu it kx b ky oc lb od me oe mf of mg og lq ny nz oa ob bi translated">用于DALL E的离散VAE的代码和更多信息:<a class="ae lr" href="https://github.com/openai/DALL-E" rel="noopener ugc nofollow" target="_blank">https://github.com/openai/DALL-E</a></li><li id="3824" class="nt nu it kx b ky oc lb od me oe mf of mg og lq ny nz oa ob bi translated">达尔福尔论文:<a class="ae lr" href="https://arxiv.org/pdf/2102.12092.pdf" rel="noopener ugc nofollow" target="_blank">https://arxiv.org/pdf/2102.12092.pdf</a></li><li id="c467" class="nt nu it kx b ky oc lb od me oe mf of mg og lq ny nz oa ob bi translated">OpenAI回形针&amp;代码:<a class="ae lr" href="https://openai.com/blog/clip/" rel="noopener ugc nofollow" target="_blank">https://openai.com/blog/clip/</a></li><li id="ee49" class="nt nu it kx b ky oc lb od me oe mf of mg og lq ny nz oa ob bi translated">用在无刷图像搜索上的剪辑:<a class="ae lr" href="https://github.com/haltakov/natural-language-image-search" rel="noopener ugc nofollow" target="_blank">https://github.com/haltakov/natural-language-image-search</a></li></ul></div></div>    
</body>
</html>