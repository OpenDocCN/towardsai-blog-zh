<html>
<head>
<title>Underfitting and Overfitting with Python Examples</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">Python示例的欠拟合和过拟合</h1>
<blockquote>原文：<a href="https://pub.towardsai.net/underfitting-and-overfitting-with-python-examples-5a66cb470ebd?source=collection_archive---------0-----------------------#2021-09-23">https://pub.towardsai.net/underfitting-and-overfitting-with-python-examples-5a66cb470ebd?source=collection_archive---------0-----------------------#2021-09-23</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><h2 id="cc0c" class="ir is it bd b dl iu iv iw ix iy iz dk ja translated" aria-label="kicker paragraph"><a class="ae ep" href="https://towardsai.net/p/category/machine-learning" rel="noopener ugc nofollow" target="_blank">机器学习</a></h2><div class=""/><div class=""><h2 id="8d71" class="pw-subtitle-paragraph jz jc it bd b ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq dk translated">提高机器学习算法的性能</h2></div><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div class="gh gi kr"><img src="../Images/2a78d83a1f36e642aa777ba234355fdf.png" data-original-src="https://miro.medium.com/v2/resize:fit:1138/format:webp/1*_Xa9wZQzApxvb06bD0nnUQ.png"/></div><figcaption class="kz la gj gh gi lb lc bd b be z dk translated">图片<a class="ae ld" href="https://www.kaggle.com/getting-started/166897" rel="noopener ugc nofollow" target="_blank">来源</a></figcaption></figure><blockquote class="le lf lg"><p id="8047" class="lh li lj lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated"><strong class="lk jd"> <em class="it">过拟合和欠拟合介绍</em> </strong></p></blockquote><p id="b2f1" class="pw-post-body-paragraph lh li it lk b ll lm kd ln lo lp kg lq me ls lt lu mf lw lx ly mg ma mb mc md im bi translated">当你开始学习机器学习的时候，会有很多容易混淆的术语介绍给你。这些术语包括过拟合、欠拟合、偏差-方差权衡等。这些概念通常是机器学习的核心。通过这篇文章，我将试图对这些术语有一个更好的理解。</p><p id="2e79" class="pw-post-body-paragraph lh li it lk b ll lm kd ln lo lp kg lq me ls lt lu mf lw lx ly mg ma mb mc md im bi translated">机器学习模型的唯一目的是很好地概括。泛化是模型从以前从未遇到过的输入中创建合理输出的能力。</p><p id="9d35" class="pw-post-body-paragraph lh li it lk b ll lm kd ln lo lp kg lq me ls lt lu mf lw lx ly mg ma mb mc md im bi translated">一般来说，程序只能对它们熟悉的输入做出“机器人式”的反应，所以它们不能这样做。模型的性能以及整个应用程序在很大程度上取决于模型的泛化。如果这个模型能够很好地推广，它将达到它的目的。</p><p id="e246" class="pw-post-body-paragraph lh li it lk b ll lm kd ln lo lp kg lq me ls lt lu mf lw lx ly mg ma mb mc md im bi translated">已经引入了几种技术来评估这种性能，从数据本身开始。过拟合和欠拟合等概念指的是可能影响模型性能的缺陷。这意味着了解模型的性能“有多差”是至关重要的。</p><p id="97e8" class="pw-post-body-paragraph lh li it lk b ll lm kd ln lo lp kg lq me ls lt lu mf lw lx ly mg ma mb mc md im bi translated">让我们假设我们想要用如下给出的数据集建立一个机器学习模型:</p><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div class="gh gi mh"><img src="../Images/1df668c04d54628272dd6641ffff2cae.png" data-original-src="https://miro.medium.com/v2/resize:fit:780/format:webp/1*jG0X35WpR92bHLLYS_0Dyg.png"/></div><figcaption class="kz la gj gh gi lb lc bd b be z dk translated">图片<a class="ae ld" href="https://towardsdatascience.com/what-are-overfitting-and-underfitting-in-machine-learning-a96b30864690" rel="noopener" target="_blank">来源</a></figcaption></figure><p id="f2fe" class="pw-post-body-paragraph lh li it lk b ll lm kd ln lo lp kg lq me ls lt lu mf lw lx ly mg ma mb mc md im bi translated">X轴是输入值，Y轴是输出值。</p><p id="a28b" class="pw-post-body-paragraph lh li it lk b ll lm kd ln lo lp kg lq me ls lt lu mf lw lx ly mg ma mb mc md im bi translated">在机器学习中，我们知道我们的构建模型可以通过像线性回归一样在数据点之间拟合一条线来将输入值映射到输出值。这条拟合线负责欠拟合和过拟合。</p><p id="21fb" class="pw-post-body-paragraph lh li it lk b ll lm kd ln lo lp kg lq me ls lt lu mf lw lx ly mg ma mb mc md im bi translated">在机器学习的训练阶段，假设在线性回归中，我们希望我们的模型遵循下图中给出的一条线，这是两个术语(欠拟合和过拟合)出现的地方。</p><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="mj mk di ml bf mm"><div class="gh gi mi"><img src="../Images/0ad0001c1ad14c88bb8b52ae7013c5b3.png" data-original-src="https://miro.medium.com/v2/resize:fit:728/format:webp/1*l_GPHkEq-jFcK_QLsAWgIw.png"/></div></div><figcaption class="kz la gj gh gi lb lc bd b be z dk translated">图像<a class="ae ld" href="https://towardsdatascience.com/what-are-overfitting-and-underfitting-in-machine-learning-a96b30864690" rel="noopener" target="_blank">来源</a></figcaption></figure><p id="0789" class="pw-post-body-paragraph lh li it lk b ll lm kd ln lo lp kg lq me ls lt lu mf lw lx ly mg ma mb mc md im bi translated">在我们继续深入之前，让我们澄清两个重要的术语:<br/>偏差和方差。假设使函数更容易学习的机器学习模型被称为偏差和方差，当您根据训练数据训练您的模型并获得非常低的误差时，但当您更改数据并训练相同的先前模型时，您会获得非常高的误差。</p><blockquote class="le lf lg"><p id="7bbf" class="lh li lj lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated"><strong class="lk jd"> <em class="it">过拟合</em> </strong></p></blockquote><p id="c683" class="pw-post-body-paragraph lh li it lk b ll lm kd ln lo lp kg lq me ls lt lu mf lw lx ly mg ma mb mc md im bi translated">过度拟合是指我们的模型训练从训练数据集中进行了太多，因此总成本将非常小，因此模型的泛化是不可靠的。</p><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div class="gh gi mn"><img src="../Images/e9d3cb389d2f1fa1b3397e8b3c633db4.png" data-original-src="https://miro.medium.com/v2/resize:fit:666/format:webp/1*UwuLK1y3ShkuJf13MMZVXA.png"/></div><figcaption class="kz la gj gh gi lb lc bd b be z dk translated">图像<a class="ae ld" href="https://towardsdatascience.com/what-are-overfitting-and-underfitting-in-machine-learning-a96b30864690" rel="noopener" target="_blank">来源</a></figcaption></figure><p id="c781" class="pw-post-body-paragraph lh li it lk b ll lm kd ln lo lp kg lq me ls lt lu mf lw lx ly mg ma mb mc md im bi translated">我们做的模型训练越多，过度拟合的可能性就越大。我们总是希望我们的模型能够找到趋势，而不是所有数据点的拟合线。</p><p id="cabb" class="pw-post-body-paragraph lh li it lk b ll lm kd ln lo lp kg lq me ls lt lu mf lw lx ly mg ma mb mc md im bi translated">如果处理不当，过度拟合也可能被称为高方差导致弊大于利。当我们进行训练时，模型学习是好的，并且适合它，但是当新的测试数据来预测时，准确性变得更低，这导致过度拟合。</p><blockquote class="le lf lg"><p id="00bb" class="lh li lj lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated"><strong class="lk jd">下装<em class="it"/>下装</strong></p></blockquote><p id="f030" class="pw-post-body-paragraph lh li it lk b ll lm kd ln lo lp kg lq me ls lt lu mf lw lx ly mg ma mb mc md im bi translated">当我们的机器学习模型没有从训练数据中学习到足够的知识，因此做出不可靠的预测时，就会出现欠拟合。</p><p id="5ec1" class="pw-post-body-paragraph lh li it lk b ll lm kd ln lo lp kg lq me ls lt lu mf lw lx ly mg ma mb mc md im bi translated">我们还期望我们的模型从输入数据点学习太多(即太多的模式)，这可以通过更早地停止训练来完成，并且还可以应用任何其他模型。这些结果将导致模型不能从训练数据中学习足够的模式，并且主导趋势也不能被捕获。这就是欠拟合的情况。</p><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div class="gh gi mo"><img src="../Images/bef8da46643a016a928517acbf14bd30.png" data-original-src="https://miro.medium.com/v2/resize:fit:618/format:webp/1*O25msWzF6y0Sd8JNyiaADg.png"/></div><figcaption class="kz la gj gh gi lb lc bd b be z dk translated">图像<a class="ae ld" href="https://towardsdatascience.com/what-are-overfitting-and-underfitting-in-machine-learning-a96b30864690" rel="noopener" target="_blank">来源</a></figcaption></figure><p id="82ea" class="pw-post-body-paragraph lh li it lk b ll lm kd ln lo lp kg lq me ls lt lu mf lw lx ly mg ma mb mc md im bi translated">欠拟合也被称为高偏差，这不利于模型泛化为过拟合。</p><div class="mp mq gp gr mr ms"><a rel="noopener  ugc nofollow" target="_blank" href="/introduction-to-mlops-for-data-science-e2ca5a759f68"><div class="mt ab fo"><div class="mu ab mv cl cj mw"><h2 class="bd jd gy z fp mx fr fs my fu fw jc bi translated">面向数据科学的MLOps简介</h2><div class="mz l"><h3 class="bd b gy z fp mx fr fs my fu fw dk translated">持续集成、持续开发和持续测试的一部分</h3></div><div class="na l"><p class="bd b dl z fp mx fr fs my fu fw dk translated">pub.towardsai.net</p></div></div><div class="nb l"><div class="nc l nd ne nf nb ng kx ms"/></div></div></a></div><div class="mp mq gp gr mr ms"><a rel="noopener  ugc nofollow" target="_blank" href="/feature-selection-and-removing-in-machine-learning-dd3726f5865c"><div class="mt ab fo"><div class="mu ab mv cl cj mw"><h2 class="bd jd gy z fp mx fr fs my fu fw jc bi translated">机器学习中的特征选择和去除</h2><div class="mz l"><h3 class="bd b gy z fp mx fr fs my fu fw dk translated">高维数据模型及其精度的改进</h3></div><div class="na l"><p class="bd b dl z fp mx fr fs my fu fw dk translated">pub.towardsai.net</p></div></div><div class="nb l"><div class="nh l nd ne nf nb ng kx ms"/></div></div></a></div><blockquote class="le lf lg"><p id="7ba6" class="lh li lj lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated"><strong class="lk jd"> <em class="it">下图总结了</em> </strong>的区别</p></blockquote><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div class="gh gi ni"><img src="../Images/5bf597225e5fa798014157c2ddc00483.png" data-original-src="https://miro.medium.com/v2/resize:fit:854/format:webp/1*4MPyjzTjeD94A3DZy1K6ug.png"/></div><figcaption class="kz la gj gh gi lb lc bd b be z dk translated">图像<a class="ae ld" href="https://www.analyticsvidhya.com/blog/2020/02/underfitting-overfitting-best-fitting-machine-learning/" rel="noopener ugc nofollow" target="_blank">来源</a></figcaption></figure><p id="ef77" class="pw-post-body-paragraph lh li it lk b ll lm kd ln lo lp kg lq me ls lt lu mf lw lx ly mg ma mb mc md im bi translated">借助于实例，我们得出结论，欠拟合模型在训练集或测试集中的表现都不好。</p><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div class="gh gi nj"><img src="../Images/ef90342a46e34671f219a243a6cce44c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1098/format:webp/1*YhGDvgrf3htx_xNyuOnynQ.png"/></div><figcaption class="kz la gj gh gi lb lc bd b be z dk translated">图像<a class="ae ld" href="https://datascience.foundation/sciencewhitepaper/underfitting-and-overfitting-in-machine-learning" rel="noopener ugc nofollow" target="_blank">来源</a></figcaption></figure><p id="16c7" class="pw-post-body-paragraph lh li it lk b ll lm kd ln lo lp kg lq me ls lt lu mf lw lx ly mg ma mb mc md im bi translated">我们演示了如何使用具有多项式特征的线性回归来逼近非线性函数，以及如何避免欠拟合和过拟合。</p><p id="2f02" class="pw-post-body-paragraph lh li it lk b ll lm kd ln lo lp kg lq me ls lt lu mf lw lx ly mg ma mb mc md im bi translated">我们要构造两个变量，比如X和Y，X是一个随机数或样本，而Y是余弦函数。该图将类似于下面简单绘制的X和y。</p><p id="6ae9" class="pw-post-body-paragraph lh li it lk b ll lm kd ln lo lp kg lq me ls lt lu mf lw lx ly mg ma mb mc md im bi translated">使用线性回归训练我们的模型，预测并可视化结果。</p><pre class="ks kt ku kv gt nk nl nm nn aw no bi"><span id="892f" class="np nq it nl b gy nr ns l nt nu">plt.plot(x,y, color = 'red', label="Actual)<br/>plt.scatter(x, y, edgecolor='b', s=20, label ="Samples")<br/>plt.xlabel("x")<br/>plt.ylabel("y")<br/>plt.legend(loc = "best")<br/>plt.show()</span></pre><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div class="gh gi nv"><img src="../Images/853ee5c051614d67ea83753932223443.png" data-original-src="https://miro.medium.com/v2/resize:fit:844/format:webp/1*FdSNMVFAHHmDOPYYOUJ1Ow.png"/></div><figcaption class="kz la gj gh gi lb lc bd b be z dk translated">图像<a class="ae ld" href="https://datascience.foundation/sciencewhitepaper/underfitting-and-overfitting-in-machine-learning." rel="noopener ugc nofollow" target="_blank">来源</a></figcaption></figure><p id="1c6a" class="pw-post-body-paragraph lh li it lk b ll lm kd ln lo lp kg lq me ls lt lu mf lw lx ly mg ma mb mc md im bi translated">让我们使用线性回归来训练、预测和可视化我们的模型。</p><pre class="ks kt ku kv gt nk nl nm nn aw no bi"><span id="dcde" class="np nq it nl b gy nr ns l nt nu">model = LinearRegression()<br/>model.fit(x[:, np.newaxis], y)</span><span id="ea97" class="np nq it nl b gy nw ns l nt nu">y_pred = model.predict(x1)</span></pre><p id="fe0a" class="pw-post-body-paragraph lh li it lk b ll lm kd ln lo lp kg lq me ls lt lu mf lw lx ly mg ma mb mc md im bi translated">现在，让我们想象一下我们预测的模型。</p><pre class="ks kt ku kv gt nk nl nm nn aw no bi"><span id="0dd5" class="np nq it nl b gy nr ns l nt nu">plt.plot(x,y, color = 'red', label="Actual)<br/>plt.scatter(x, y, edgecolor='b', s=20, label ="Samples")<br/>plt.plot(x1, y_pred, label="Model")</span><span id="40f0" class="np nq it nl b gy nw ns l nt nu"><br/>plt.xlabel("x")<br/>plt.ylabel("y")<br/>plt.legend(loc = "best")<br/>plt.show()</span></pre><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div class="gh gi nx"><img src="../Images/f98d708e6c40bf4875c10f40bd41b57c.png" data-original-src="https://miro.medium.com/v2/resize:fit:888/format:webp/1*T48nbXaiOFVfHIcBiWzfeg.png"/></div><figcaption class="kz la gj gh gi lb lc bd b be z dk translated">图片<a class="ae ld" href="https://datascience.foundation/sciencewhitepaper/underfitting-and-overfitting-in-machine-learning" rel="noopener ugc nofollow" target="_blank">来源</a></figcaption></figure><p id="82e4" class="pw-post-body-paragraph lh li it lk b ll lm kd ln lo lp kg lq me ls lt lu mf lw lx ly mg ma mb mc md im bi translated">直线不能捕捉数据中的模式。这是一个拟合不足的例子。这个模型的误差会很大。</p><blockquote class="le lf lg"><p id="3f8f" class="lh li lj lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated"><strong class="lk jd"> <em class="it">结论</em> </strong></p></blockquote><p id="4c0e" class="pw-post-body-paragraph lh li it lk b ll lm kd ln lo lp kg lq me ls lt lu mf lw lx ly mg ma mb mc md im bi translated">那么什么才是正确的衡量标准呢？根据我们拥有的模型，我们的模型的性能介于过拟合和欠拟合之间，但是只有当这些模型很好地概括时，该模型才能实现其目的。概括通过限制两种不期望的结果高偏差和高方差来发挥作用。</p><p id="d216" class="pw-post-body-paragraph lh li it lk b ll lm kd ln lo lp kg lq me ls lt lu mf lw lx ly mg ma mb mc md im bi translated">我希望你喜欢这篇文章。通过我的<a class="ae ld" href="https://www.linkedin.com/in/data-scientist-95040a1ab/" rel="noopener ugc nofollow" target="_blank"> LinkedIn </a>和<a class="ae ld" href="https://twitter.com/amitprius" rel="noopener ugc nofollow" target="_blank"> twitter </a>联系我。</p><h1 id="e369" class="ny nq it bd nz oa ob oc od oe of og oh ki oi kj oj kl ok km ol ko om kp on oo bi translated">推荐文章</h1><p id="fd15" class="pw-post-body-paragraph lh li it lk b ll op kd ln lo oq kg lq me or lt lu mf os lx ly mg ot mb mc md im bi translated">1.<a class="ae ld" rel="noopener ugc nofollow" target="_blank" href="/8-active-learning-insights-of-python-collection-module-6c9e0cc16f6b?source=friends_link&amp;sk=4a5c9f9ad552005636ae720a658281b1">8 Python的主动学习见解收集模块</a> <br/> 2。<a class="ae ld" rel="noopener ugc nofollow" target="_blank" href="/numpy-linear-algebra-on-images-ed3180978cdb?source=friends_link&amp;sk=d9afa4a1206971f9b1f64862f6291ac0"> NumPy:图像上的线性代数</a>T5】3。<a class="ae ld" rel="noopener ugc nofollow" target="_blank" href="/exception-handling-concepts-in-python-4d5116decac3?source=friends_link&amp;sk=a0ed49d9fdeaa67925eac34ecb55ea30">Python中的异常处理概念</a> <br/> 4。<a class="ae ld" rel="noopener ugc nofollow" target="_blank" href="/pandas-dealing-with-categorical-data-7547305582ff?source=friends_link&amp;sk=11c6809f6623dd4f6dd74d43727297cf">熊猫:处理分类数据</a> <br/> 5。<a class="ae ld" rel="noopener ugc nofollow" target="_blank" href="/hyper-parameters-randomseachcv-and-gridsearchcv-in-machine-learning-b7d091cf56f4?source=friends_link&amp;sk=cab337083fb09601114a6e466ec59689">超参数:机器学习中的RandomSeachCV和GridSearchCV</a><br/>6。<a class="ae ld" href="https://medium.com/towards-artificial-intelligence/fully-explained-linear-regression-with-python-fe2b313f32f3?source=friends_link&amp;sk=53c91a2a51347ec2d93f8222c0e06402" rel="noopener">用Python </a> <br/> 7全面讲解了线性回归。<a class="ae ld" href="https://medium.com/towards-artificial-intelligence/fully-explained-logistic-regression-with-python-f4a16413ddcd?source=friends_link&amp;sk=528181f15a44e48ea38fdd9579241a78" rel="noopener">用Python </a> <br/>充分解释了Logistic回归8。<a class="ae ld" rel="noopener ugc nofollow" target="_blank" href="/data-distribution-using-numpy-with-python-3b64aae6f9d6?source=friends_link&amp;sk=809e75802cbd25ddceb5f0f6496c9803">数据分发使用Numpy与Python </a> <br/> 9。<a class="ae ld" rel="noopener ugc nofollow" target="_blank" href="/decision-trees-vs-random-forests-in-machine-learning-be56c093b0f?source=friends_link&amp;sk=91377248a43b62fe7aeb89a69e590860">机器学习中的决策树vs随机森林</a> <br/> 10。<a class="ae ld" rel="noopener ugc nofollow" target="_blank" href="/standardization-in-data-preprocessing-with-python-96ae89d2f658?source=friends_link&amp;sk=f348435582e8fbb47407e9b359787e41">用Python实现数据预处理的标准化</a></p></div></div>    
</body>
</html>