<html>
<head>
<title>ArgMiner: End-to-End Argument Mining</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">ArgMiner:端到端参数挖掘</h1>
<blockquote>原文：<a href="https://pub.towardsai.net/argminer-end-to-end-argument-mining-9b1e69872103?source=collection_archive---------1-----------------------#2022-06-18">https://pub.towardsai.net/argminer-end-to-end-argument-mining-9b1e69872103?source=collection_archive---------1-----------------------#2022-06-18</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="7c94" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">一个基于PyTorch的包，用于对SOTA参数挖掘数据集进行处理、扩充、训练和执行推理</h2></div><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ki"><img src="../Images/e9f1192049b334792e10f393640b3837.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*j7FFmcRXWcZH05xmdIyPgw.png"/></div></div><figcaption class="ku kv gj gh gi kw kx bd b be z dk translated">论点挖掘任务的图示</figcaption></figure><p id="133b" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">论点挖掘(AM)是从文本中提取论点成分的任务，通常作为自动化写作评估系统的一部分。这是NLP中非常热门和令人兴奋的领域。用最基本的术语来说，一个好的AM模型获取一段原始文本，并正确地将其中的序列标记为它们所属的论元成分(这在封面照片中以图片形式显示)。虽然这个问题在历史上被视为语义分割问题，但最新的(SOTA) AM技术将其视为长文本序列上的命名实体识别(NER)问题。</p><p id="b511" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">尽管该领域有着悠久的历史，但关于NER AM数据集的文献相对较少，Christian Stab和Iryna Gurevych的<a class="ae lu" href="https://tudatalib.ulb.tu-darmstadt.de/handle/tudatalib/2421" rel="noopener ugc nofollow" target="_blank"> Argument注释论文</a>是2014年以来唯一的贡献。这一点在最近(截至2022年3月)随着说服(用于<a class="ae lu" href="https://www.kaggle.com/competitions/feedback-prize-2021/overview" rel="noopener ugc nofollow" target="_blank">反馈奖Kaggle竞赛</a>)和ARG2020数据集(<a class="ae lu" href="https://github.com/EducationalTestingService/argument-component-essays/" rel="noopener ugc nofollow" target="_blank"> GitHub页面</a>)的发布而得到了改善。正因为如此，虽然AM在单个数据集上取得了成功，但对AM模型的跨数据集性能却知之甚少。因此，也没有关于对抗性训练如何提高AM模型的跨数据集性能的研究。关于AM模型对对立例子的鲁棒性的研究也是缺乏的。</p><p id="afe5" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">每个数据集都以不同的格式存储，这使得上述挑战变得更加复杂，从而很难对实验数据的处理和扩充进行标准化(快速查看反馈奖竞赛的笔记本可以证实这一点，因为大部分代码都是用于处理数据的)。</p><p id="2e81" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">本文介绍了ArgMiner，这是一个基于PyTorch的包，用于使用基于Transformer的模型对SOTA参数挖掘数据集进行标准化数据处理、数据扩充、训练和推理。本文首先概要介绍了包的功能，然后介绍了SOTA数据集。然后详细描述ArgMiner的处理和扩充特性。最后，简要讨论了论证挖掘模型的推理和评估(通过Web应用程序)。这篇文章以一些结束语结束。</p><h1 id="4bf5" class="lv lw it bd lx ly lz ma mb mc md me mf jz mg ka mh kc mi kd mj kf mk kg ml mm bi translated">简而言之就是ArgMiner</h1><p id="103f" class="pw-post-body-paragraph ky kz it la b lb mn ju ld le mo jx lg lh mp lj lk ll mq ln lo lp mr lr ls lt im bi translated">ArgMiner的主要特性总结如下:</p><ul class=""><li id="3d09" class="ms mt it la b lb lc le lf lh mu ll mv lp mw lt mx my mz na bi translated">提供处理器从源中提取SOTA数据集，而无需编写任何额外的代码</li><li id="3212" class="ms mt it la b lb nb le nc lh nd ll ne lp nf lt mx my mz na bi translated">处理器可以在单词和子单词级别生成以下标记方法{io、bio、bieo、bixo},而无需额外的代码行</li><li id="bb18" class="ms mt it la b lb nb le nc lh nd ll ne lp nf lt mx my mz na bi translated">处理器有一个内置特性，可以在不改变数据处理流水线的情况下实现定制扩展</li><li id="51f1" class="ms mt it la b lb nb le nc lh nd ll ne lp nf lt mx my mz na bi translated">提供PyTorch数据集，用于使用任何HuggingFace标记分类模型进行参数挖掘微调</li><li id="c314" class="ms mt it la b lb nb le nc lh nd ll ne lp nf lt mx my mz na bi translated">为高效的训练和推理提供了管道</li></ul><p id="8294" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">下图显示了ArgMiner端到端的工作:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ng"><img src="../Images/af03072e97a74d5d9b1c71e7e9f44017.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*IpVtOFoGQknrTRMjEuPTMw.png"/></div></div></figure></div><div class="ab cl nh ni hx nj" role="separator"><span class="nk bw bk nl nm nn"/><span class="nk bw bk nl nm nn"/><span class="nk bw bk nl nm"/></div><div class="im in io ip iq"><h1 id="cee8" class="lv lw it bd lx ly no ma mb mc np me mf jz nq ka mh kc nr kd mj kf ns kg ml mm bi translated">处理和扩充</h1><h2 id="4204" class="nt lw it bd lx nu nv dn mb nw nx dp mf lh ny nz mh ll oa ob mj lp oc od ml oe bi translated"><strong class="ak">数据集</strong></h2><ul class=""><li id="7e30" class="ms mt it la b lb mn le mo lh of ll og lp oh lt mx my mz na bi translated"><strong class="la iu">议论文注释(AAE): </strong>这是在在线论文反馈论坛<a class="ae lu" href="https://essayforum.com/" rel="noopener ugc nofollow" target="_blank"> essayforum </a>上找到的402篇论文的集合。它有3个论证成分:<strong class="la iu">主张</strong>、<strong class="la iu">主要主张</strong>、<strong class="la iu">前提</strong>。数据集可以在TUDarmstadt <a class="ae lu" href="https://tudatalib.ulb.tu-darmstadt.de/handle/tudatalib/2421" rel="noopener ugc nofollow" target="_blank">数据存储</a>中找到；原<a class="ae lu" href="https://aclanthology.org/C14-1142.pdf" rel="noopener ugc nofollow" target="_blank"> p </a>论文在<a class="ae lu" href="https://aclanthology.org/C14-1142.pdf" rel="noopener ugc nofollow" target="_blank"> ACL </a>上，后续论文在<a class="ae lu" href="https://direct.mit.edu/coli/article/43/3/619/1573/Parsing-Argumentation-Structures-in-Persuasive" rel="noopener ugc nofollow" target="_blank"> MIT Press Direct </a>上。</li><li id="9ab7" class="ms mt it la b lb nb le nc lh nd ll ne lp nf lt mx my mz na bi translated">说服:这是美国6-12年级学生写的大约15000篇文章的合集。它有7个论点组成:<strong class="la iu">引</strong>、<strong class="la iu">立场</strong>、<strong class="la iu">主张</strong>、<strong class="la iu">反诉</strong>、<strong class="la iu">反驳</strong>、<strong class="la iu">证据</strong>、<strong class="la iu">结论</strong>、<strong class="la iu">陈述</strong>。数据集可以通过<a class="ae lu" href="https://www.kaggle.com/competitions/feedback-prize-2021/overview" rel="noopener ugc nofollow" target="_blank"> Kaggle反馈奖</a>比赛访问。</li><li id="62fb" class="ms mt it la b lb nb le nc lh nd ll ne lp nf lt mx my mz na bi translated">这是145篇中学生作文的合集。它有两个论证成分:<strong class="la iu">主张</strong>和<strong class="la iu">前提</strong>。数据集可以在<a class="ae lu" href="https://github.com/EducationalTestingService/argument-component-essays/" rel="noopener ugc nofollow" target="_blank"> GitHub </a>上公开获得，这项工作的论文在<a class="ae lu" href="https://arxiv.org/pdf/2103.04518.pdf" rel="noopener ugc nofollow" target="_blank"> ArXiv </a>上。</li></ul><p id="2d40" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">这些数据集以不同的方式存储和处理。例如，AAE和ARG2020数据集具有。包含两种类型信息的ann文件:1)自变量成分，其形式为:[自变量_成分_id，自变量_成分_文本，跨度_开始，跨度_结束，文本]和2)自变量关系，其形式为:[关系_id，关系_类型，自变量_成分_1，自变量_成分_2]。参数挖掘不需要参数关系，因此需要移除这些关系。此外，实际的essay _ ids是文件本身的名称，所以解析它的代码需要考虑它。数据是附带的。txt文件的原始文章文本以及。与ARG2020不同，AAE数据集附带了用于分割数据的训练测试id。</p><p id="b6bb" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">另一方面，说服数据集有一个更复杂的目录结构，train和test目录包含原始的。txt随笔。关于参数组件的实际信息包含在train.csv中，其格式如下:[essay_id，discourse_id，span_start，span_end，discourse_text，discourse_type，discourse_type_num，predictionstring]。</p><p id="5808" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">没有一个数据集实际上指出文章中不是论点部分的部分，即所谓的“其他”类。然而，NER问题通常需要这样做(否则你是选择性地查看文章中的信息，而不是整篇文章)。所以管道需要从文章中提取这些片段。</p><p id="e533" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">为了以标准化的格式处理这些千差万别的原始文本，ArgMiner采用了三个阶段:<strong class="la iu">预处理</strong>、<strong class="la iu">过程、</strong>和<strong class="la iu">后处理</strong>。这些将在接下来的章节中详细描述。</p><h2 id="c9e1" class="nt lw it bd lx nu nv dn mb nw nx dp mf lh ny nz mh ll oa ob mj lp oc od ml oe bi translated">预处理:从源中提取数据</h2><p id="b7ee" class="pw-post-body-paragraph ky kz it la b lb mn ju ld le mo jx lg lh mp lj lk ll mq ln lo lp mr lr ls lt im bi translated">该步骤获取原始格式的数据(针对每个数据集)，并使用<strong class="la iu"> span_start </strong>和<strong class="la iu"> span_end </strong>特性和原始文本来生成具有以下结构的数据帧:<strong class="la iu"> [essay_id，text，argument_component]。</strong></p><p id="6e5d" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">这实现了向前移动以生成NER标签或扩充数据的标准方法。这些处理器都基于一个基本的数据处理器类，该类具有保存和应用训练-测试-分割的内置特性，因此可以轻松地从中创建新的处理器。</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="oi oj l"/></div></figure><h2 id="67b4" class="nt lw it bd lx nu nv dn mb nw nx dp mf lh ny nz mh ll oa ob mj lp oc od ml oe bi translated">处理:生成标签和(可选)扩充数据</h2><p id="d1f8" class="pw-post-body-paragraph ky kz it la b lb mn ju ld le mo jx lg lh mp lj lk ll mq ln lo lp mr lr ls lt im bi translated">既然数据是标准格式，用户可以请求为数据生成NER风格的标签。在这一步结束时，数据集将看起来像这样:<strong class="la iu">【论文id，文本，参数组件，NER标签】</strong>。</p><p id="2934" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">然而，有时人们可能对扩充数据感兴趣，无论是为了对抗训练还是测试对抗例子的鲁棒性。在这种情况下，用户可以简单地提供<strong class="la iu">任何获取一段文本并返回一段增加的文本的函数。</strong>这意味着其他NLP增强库如<a class="ae lu" href="https://github.com/QData/TextAttack" rel="noopener ugc nofollow" target="_blank"> textattack </a>和<a class="ae lu" href="https://github.com/makcedward/nlpaug" rel="noopener ugc nofollow" target="_blank"> nlpaug </a>可以轻松使用。当使用增强器时，数据首先在</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="oi oj l"/></div></figure><h2 id="e2a9" class="nt lw it bd lx nu nv dn mb nw nx dp mf lh ny nz mh ll oa ob mj lp oc od ml oe bi translated">后处理:将序列聚合到文档</h2><p id="6bb6" class="pw-post-body-paragraph ky kz it la b lb mn ju ld le mo jx lg lh mp lj lk ll mq ln lo lp mr lr ls lt im bi translated">既然已经创建了标签，最后一步就非常简单了。在这里，任务是简单地通过它们的doc _ ids连接片段。这个阶段的结果输出是一个数据帧，其形式为:<strong class="la iu">【论文id，完整论文文本，NER标签】</strong>。使用内置的训练和测试特性，进行训练测试分割也非常容易。</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="oi oj l"/></div></figure></div><div class="ab cl nh ni hx nj" role="separator"><span class="nk bw bk nl nm nn"/><span class="nk bw bk nl nm nn"/><span class="nk bw bk nl nm"/></div><div class="im in io ip iq"><h1 id="4cb8" class="lv lw it bd lx ly no ma mb mc np me mf jz nq ka mh kc nr kd mj kf ns kg ml mm bi translated">PyTorch数据集</h1><p id="37ed" class="pw-post-body-paragraph ky kz it la b lb mn ju ld le mo jx lg lh mp lj lk ll mq ln lo lp mr lr ls lt im bi translated">我不会详细说明它的代码是如何工作的，但我会强调为什么它很棒:</p><ul class=""><li id="bc85" class="ms mt it la b lb lc le lf lh mu ll mv lp mw lt mx my mz na bi translated">PyTorch数据集旨在从。后处理()阶段。此时，变量<strong class="la iu"> strategy_level </strong>可以确定标记策略是否应该应用于一个<strong class="la iu">字</strong>或<strong class="la iu">令牌</strong>级别(见本节末尾)。</li><li id="365a" class="ms mt it la b lb nb le nc lh nd ll ne lp nf lt mx my mz na bi translated">数据集将类标签扩展到子标签。与Kaggle上的例子相比，这是一个巨大的改进，因为它是矢量化的，可以有效地使用GPU。</li><li id="d5b7" class="ms mt it la b lb nb le nc lh nd ll ne lp nf lt mx my mz na bi translated">数据集创建一个映射，将扩展标签缩减到它们的核心标签，以便进行推理(例如，“B-Claim，I-Claim，E-Claim”都被缩减为索赔，以便进行推理，如果不确定，我强烈推荐我的关于NER推理的<a class="ae lu" rel="noopener ugc nofollow" target="_blank" href="/an-in-depth-tutorial-on-the-f-score-for-ner-55e944bd28ce">教程</a></li></ul><p id="5d12" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">它使用起来也很简单，因为它是基于PyTorch的，所以您可以很容易地将其集成用于培训。举个例子:</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="oi oj l"/></div></figure><blockquote class="ok ol om"><p id="92fa" class="ky kz on la b lb lc ju ld le lf jx lg oo li lj lk op lm ln lo oq lq lr ls lt im bi translated"><strong class="la iu">一个简单的标签示例:</strong>考虑一个经典的(非参数挖掘)NER示例，带有句子“我是Johannes Schmidt”。假设令牌是I，am，Jo，hann，es，Sch，mi，dt。一个标准的生物标签方案将给出:I → O，am →O，Jo →B-PER，hann →I-PER，es →I-PER，Sch →I-PER，mi →I-PER，dt →I-PER。然而，你可能也想给B-{}单词的任何标记加上B-{}标签。这将是<strong class="la iu">的字级</strong>。于是<strong class="la iu">汉恩</strong>和<strong class="la iu"> es </strong>都获得了B-PER标签。最后，ArgMiner支持<strong class="la iu"> bixo </strong>标签方案，该方案将一个<strong class="la iu"> X </strong>分配给参数组件的所有子标签，这意味着所有的<strong class="la iu"> hann </strong>、<strong class="la iu"> es </strong>、<strong class="la iu"> mi </strong>和<strong class="la iu"> dt </strong>都将获得标签“<strong class="la iu"> X </strong></p></blockquote><h1 id="2437" class="lv lw it bd lx ly lz ma mb mc md me mf jz mg ka mh kc mi kd mj kf mk kg ml mm bi translated">推理</h1><p id="8aaf" class="pw-post-body-paragraph ky kz it la b lb mn ju ld le mo jx lg lh mp lj lk ll mq ln lo lp mr lr ls lt im bi translated">ArgMiner还提供了用于训练模型和运行推理的函数。但是，您也可以编写自己的训练循环。</p><p id="cc78" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">ArgMiner的定义特性是推理函数被编写为高效的(在可能的情况下使用GPU和矢量化)和批处理的(因此非常适合低内存设置)，这意味着推理函数也可以在针对验证数据的训练期间使用。</p><p id="28eb" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">推理循环对于训练数据调试也非常有帮助，因为它允许您添加想要度量的其他指标。然后将这些应用于张量，并在从子音还原为单词后应用于张量，这可以给你一个指示，告诉你性能到底在哪里下降。</p><p id="0520" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">另一个让这个推理循环与我见过的其他循环不同的特性是，当从标记映射回单词时，能够轻松地选择聚合级别。例如，给定两个标记“Unit”和“ed ”,每个类都有概率，您可以使用单词“Unit”的最佳概率、最佳平均概率或最佳最大概率将它们聚合为“United”。</p><p id="8fb6" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">总的来说，与反馈奖竞赛中使用的推理方案相比，这种推理方案提供了几个优点。</p><blockquote class="ok ol om"><p id="59ef" class="ky kz on la b lb lc ju ld le lf jx lg oo li lj lk op lm ln lo oq lq lr ls lt im bi translated">在我的另一篇文章中可以找到关于这个项目使用的推理的深入教程。</p></blockquote></div><div class="ab cl nh ni hx nj" role="separator"><span class="nk bw bk nl nm nn"/><span class="nk bw bk nl nm nn"/><span class="nk bw bk nl nm"/></div><div class="im in io ip iq"><h1 id="e36c" class="lv lw it bd lx ly no ma mb mc np me mf jz nq ka mh kc nr kd mj kf ns kg ml mm bi translated">Web应用程序</h1><p id="3f80" class="pw-post-body-paragraph ky kz it la b lb mn ju ld le mo jx lg lh mp lj lk ll mq ln lo lp mr lr ls lt im bi translated">ArgMiner附带了一个web应用程序，用于查看您的模型(或HuggingFace中的任何模型)给出的输出，还用于评估模型在您自己编写的自定义数据集上的性能。这是一种有用的(非正式的)方法，可以通过特定的例子来探测模型，看看它在做什么。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi or"><img src="../Images/630888a39455018d92ad3094c1570072.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*jfh6FxBQH6-RpuhI5vbH4A.png"/></div></div></figure></div><div class="ab cl nh ni hx nj" role="separator"><span class="nk bw bk nl nm nn"/><span class="nk bw bk nl nm nn"/><span class="nk bw bk nl nm"/></div><div class="im in io ip iq"><h1 id="c9c2" class="lv lw it bd lx ly no ma mb mc np me mf jz nq ka mh kc nr kd mj kf ns kg ml mm bi translated">结束语</h1><ul class=""><li id="067e" class="ms mt it la b lb mn le mo lh of ll og lp oh lt mx my mz na bi translated">很长一段时间以来，论点挖掘文献在数据集上很少，但随着说服和ARG2020的发布，这种情况有所改变</li><li id="aa6f" class="ms mt it la b lb nb le nc lh nd ll ne lp nf lt mx my mz na bi translated">对于论点挖掘中的知识转移以及鲁棒性，还需要做大量的研究。从数据处理的角度来看，这通常很困难，因为存在不同的源数据格式、多种表示数据的方法，以及由于使用不相等的段进行表示和推断而导致的效率问题</li><li id="ecc5" class="ms mt it la b lb nb le nc lh nd ll ne lp nf lt mx my mz na bi translated">ArgMiner是早期版本Access中的一个包，它标准化了对SOTA参数挖掘数据集的处理、扩充、训练和执行推理</li></ul><h2 id="0525" class="nt lw it bd lx nu nv dn mb nw nx dp mf lh ny nz mh ll oa ob mj lp oc od ml oe bi translated">一些限制和正在进行的工作</h2><p id="9e41" class="pw-post-body-paragraph ky kz it la b lb mn ju ld le mo jx lg lh mp lj lk ll mq ln lo lp mr lr ls lt im bi translated">虽然这个包的核心已经准备好了，但是还有一些细节需要解决，还有一些缺失的特性。这些描述如下:</p><ul class=""><li id="5c02" class="ms mt it la b lb lc le lf lh mu ll mv lp mw lt mx my mz na bi translated">ARG2020数据集的数据处理器</li><li id="c410" class="ms mt it la b lb nb le nc lh nd ll ne lp nf lt mx my mz na bi translated">增强功能目前只能将文本作为输入。进一步的改进也将着眼于标准化其他特性，例如，如果只对特定的类进行扩充。这对于理解模型非常有用，特别是确定特定的转换如何影响模型输出</li><li id="838d" class="ms mt it la b lb nb le nc lh nd ll ne lp nf lt mx my mz na bi translated">扩展数据处理器类，以允许分层训练-测试分割，以及基于其他特征的分割，例如课程学习的长度，零射击学习的类</li></ul><h2 id="b79c" class="nt lw it bd lx nu nv dn mb nw nx dp mf lh ny nz mh ll oa ob mj lp oc od ml oe bi translated">号召NLP爱好者</h2><p id="ec62" class="pw-post-body-paragraph ky kz it la b lb mn ju ld le mo jx lg lh mp lj lk ll mq ln lo lp mr lr ls lt im bi translated">如果你对参数挖掘和NLP感兴趣，并且你觉得这篇文章很有趣，我很乐意和你聊天，并把你添加为这个项目的合作者。我希望将这个项目进行得更深入，超越早期的Access版本，并将一些代码库重构为更通用的NLP util库，以及NLP诊断和数据健壮性库/应用程序(我对合并以下项目感兴趣:<a class="ae lu" href="https://arxiv.org/abs/2009.10795" rel="noopener ugc nofollow" target="_blank">数据制图</a>和<a class="ae lu" href="https://kawine.github.io/assets/dataset_difficulty.pdf" rel="noopener ugc nofollow" target="_blank">信息论数据集难度</a>)。这些是我非常兴奋的长期计划，但作为一名单独的开发人员却无法做到。如果你有兴趣，请通过<a class="ae lu" href="https://www.linkedin.com/in/namiyousef96/" rel="noopener ugc nofollow" target="_blank"> LinkedIn </a>联系我。</p><blockquote class="ok ol om"><p id="ffab" class="ky kz on la b lb lc ju ld le lf jx lg oo li lj lk op lm ln lo oq lq lr ls lt im bi translated">这个项目的资源库在<a class="ae lu" href="https://github.com/namiyousef/argument-mining" rel="noopener ugc nofollow" target="_blank"> GitHub </a>上公开发布</p></blockquote></div><div class="ab cl nh ni hx nj" role="separator"><span class="nk bw bk nl nm nn"/><span class="nk bw bk nl nm nn"/><span class="nk bw bk nl nm"/></div><div class="im in io ip iq"><p id="7379" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated"><em class="on">所有图片均由作者提供，除非另有说明。</em></p></div></div>    
</body>
</html>