<html>
<head>
<title>Metrics for Evaluating Classification Models</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">评估分类模型的度量标准</h1>
<blockquote>原文：<a href="https://pub.towardsai.net/metrics-for-evaluating-classification-models-6c1e01293b7f?source=collection_archive---------2-----------------------#2021-01-24">https://pub.towardsai.net/metrics-for-evaluating-classification-models-6c1e01293b7f?source=collection_archive---------2-----------------------#2021-01-24</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><h2 id="0b5a" class="io ip iq bd b dl ir is it iu iv iw dk ix translated" aria-label="kicker paragraph"><a class="ae ep" href="https://towardsai.net/p/category/machine-learning" rel="noopener ugc nofollow" target="_blank">机器学习</a></h2><div class=""/><p id="3ade" class="pw-post-body-paragraph jw jx iq jy b jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ij bi translated">从准确度到f分数，这里有8个指标来探究你的分类器的优点和缺点，以及如何在Python中实现它们</p><figure class="kv kw kx ky gt kz gh gi paragraph-image"><div role="button" tabindex="0" class="la lb di lc bf ld"><div class="gh gi ku"><img src="../Images/f920f5797896b6ef68e9703a5fbf72b0.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*kHRiyiPqH6zuJ1Cl"/></div></div><figcaption class="lg lh gj gh gi li lj bd b be z dk translated">由谢恩·奥尔登多夫在<a class="ae lk" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上拍摄的照片</figcaption></figure><h1 id="2260" class="ll lm iq bd ln lo lp lq lr ls lt lu lv lw lx ly lz ma mb mc md me mf mg mh mi bi translated">介绍</h1><p id="a415" class="pw-post-body-paragraph jw jx iq jy b jz mj kb kc kd mk kf kg kh ml kj kk kl mm kn ko kp mn kr ks kt ij bi translated">经过许多个漫长的白天和不眠之夜，你终于建立了你认为是有史以来最好的分类模型，并准备好向你的客户展示它。当您创建演示文稿时，您会试图想出最好的方法来展示您的模型相对于测试数据表现得非常好。</p><p id="3bf2" class="pw-post-body-paragraph jw jx iq jy b jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ij bi translated">当你调用它的<code class="fe mo mp mq mr b">.score()</code>方法时，你试图说它有一个“高分”,但这只是让它听起来像一个视频游戏。你盯着屏幕，意识到甚至你都不完全理解这个方法是如何给一个模型打分的。</p><p id="40e9" class="pw-post-body-paragraph jw jx iq jy b jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ij bi translated">分类模型有时比构建模型更难评分和呈现，但是不要害怕，我会在这里提供帮助。在这篇文章中，我将做以下工作:</p><ul class=""><li id="ea90" class="ms mt iq jy b jz ka kd ke kh mu kl mv kp mw kt mx my mz na bi translated">为您提供8种不同的度量标准，以清晰简洁的方式评估您的分类模型</li><li id="2159" class="ms mt iq jy b jz nb kd nc kh nd kl ne kp nf kt mx my mz na bi translated">通过一个演示模型向您展示如何在python中导入或构建它们</li><li id="7788" class="ms mt iq jy b jz nb kd nc kh nd kl ne kp nf kt mx my mz na bi translated">为您提供每个指标的用例，以便您可以决定哪一个最适合您的需求</li></ul><h1 id="f722" class="ll lm iq bd ln lo lp lq lr ls lt lu lv lw lx ly lz ma mb mc md me mf mg mh mi bi translated">满足我们的演示模型和数据</h1><p id="9199" class="pw-post-body-paragraph jw jx iq jy b jz mj kb kc kd mk kf kg kh ml kj kk kl mm kn ko kp mn kr ks kt ij bi translated">为了简单起见，我们将在整篇文章中使用Kaggle的<a class="ae lk" href="https://www.kaggle.com/c/titanic" rel="noopener ugc nofollow" target="_blank">泰坦尼克号比赛</a>中的幸存者数据。本文绝不是关于如何为这种竞争建立最佳的分类模型。我的建议是，如果你不熟悉这个数据集，可以看看Ken Jee的视频。</p><p id="bf97" class="pw-post-body-paragraph jw jx iq jy b jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ij bi translated">下面我们将导入数据，并准备好进行处理:</p><figure class="kv kw kx ky gt kz"><div class="bz fp l di"><div class="ng nh l"/></div></figure><p id="1d2d" class="pw-post-body-paragraph jw jx iq jy b jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ij bi translated">我们今天只讨论一个模型:经典的逻辑回归。如果你不熟悉这个模型，我的建议是看看Josh Starmer在这个StatQuest <a class="ae lk" href="https://www.youtube.com/watch?v=yIYKR4sgzI8" rel="noopener ugc nofollow" target="_blank">视频</a>中对这个主题的处理，记住，如果你能拟合一条线，你就能拟合一条曲线！</p><pre class="kv kw kx ky gt ni mr nj nk aw nl bi"><span id="8f45" class="nm lm iq mr b gy nn no l np nq">from sklearn.linear_model import LogisticRegression</span><span id="016e" class="nm lm iq mr b gy nr no l np nq"># Build a logistic regression object<br/>log_reg = LogisticRegression()</span><span id="8d52" class="nm lm iq mr b gy nr no l np nq"># Fit the training data to the model<br/>log_reg.fit(X_train, y_train)</span><span id="d3ae" class="nm lm iq mr b gy nr no l np nq"># Make predictions for our test data<br/>y_pred = log_reg.predict(X_test)</span></pre><p id="df98" class="pw-post-body-paragraph jw jx iq jy b jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ij bi translated">有一些模型被证明更擅长解决这种特定的分类问题，但判断结果是相同的，无论它是从Scikit-learn导入的逻辑回归模型的预测还是您自己构建的神经网络。</p><h1 id="2272" class="ll lm iq bd ln lo lp lq lr ls lt lu lv lw lx ly lz ma mb mc md me mf mg mh mi bi translated">混淆矩阵</h1><p id="7c11" class="pw-post-body-paragraph jw jx iq jy b jz mj kb kc kd mk kf kg kh ml kj kk kl mm kn ko kp mn kr ks kt ij bi translated">理解模型性能的最直观的方法是使用混淆矩阵。从Scikit-learn导入的混淆矩阵是一个简单的矩阵，它告诉您模型的预测属于4个不同的类别:</p><ul class=""><li id="b57f" class="ms mt iq jy b jz ka kd ke kh mu kl mv kp mw kt mx my mz na bi translated">你的模型预测的条目是目标类中的<strong class="jy ja">，并且是<strong class="jy ja">正确的</strong>，这些被称为<strong class="jy ja">真阳性</strong></strong></li><li id="6de7" class="ms mt iq jy b jz nb kd nc kh nd kl ne kp nf kt mx my mz na bi translated">你的模型预测的条目是<strong class="jy ja">而不是</strong>目标类中的 <strong class="jy ja">并且是<strong class="jy ja">正确的</strong>，它们被称为<strong class="jy ja">真否定</strong></strong></li><li id="fcdd" class="ms mt iq jy b jz nb kd nc kh nd kl ne kp nf kt mx my mz na bi translated">你的模型预测的条目在目标类的中<strong class="jy ja">并且<strong class="jy ja">不正确</strong>，这些被称为<strong class="jy ja">误报</strong></strong></li><li id="0f69" class="ms mt iq jy b jz nb kd nc kh nd kl ne kp nf kt mx my mz na bi translated">你的模型预测的条目是<strong class="jy ja">不是</strong>目标类中的 <strong class="jy ja">并且是<strong class="jy ja">不正确的</strong>，这些被称为<strong class="jy ja">假阴性</strong></strong></li></ul><p id="b586" class="pw-post-body-paragraph jw jx iq jy b jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ij bi translated">对于泰坦尼克号数据，这四个术语的含义如下:</p><ul class=""><li id="62c9" class="ms mt iq jy b jz ka kd ke kh mu kl mv kp mw kt mx my mz na bi translated">当我们的模型正确地预测到一个人会活下来时，就是真阳性</li><li id="127c" class="ms mt iq jy b jz nb kd nc kh nd kl ne kp nf kt mx my mz na bi translated">真正的否定是当我们的模型正确预测到一个人将会死亡</li><li id="c763" class="ms mt iq jy b jz nb kd nc kh nd kl ne kp nf kt mx my mz na bi translated">假阳性是当我们的模型错误地预测一个人会活下来</li><li id="fb68" class="ms mt iq jy b jz nb kd nc kh nd kl ne kp nf kt mx my mz na bi translated">假阴性是指我们的模型错误地预测到一个人会死亡</li></ul><pre class="kv kw kx ky gt ni mr nj nk aw nl bi"><span id="bc5d" class="nm lm iq mr b gy nn no l np nq">from sklearn.metrics import confusion_matrix</span><span id="5377" class="nm lm iq mr b gy nr no l np nq"># This creates our matrix for plotting<br/>con_mat = confusion_matrix(y_test, y_pred)</span></pre><p id="0f05" class="pw-post-body-paragraph jw jx iq jy b jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ij bi translated">像这样的二进制问题总是会产生一个2x2的数组。Scikit-Learn实际上有自己的内部方法来绘制混淆矩阵，但我们将从头开始做，并有以下警告:Scikit-Learn的混淆矩阵将<strong class="jy ja">始终</strong>在x轴上有您的模型的预测，在y轴上有真实值，这是<strong class="jy ja">不通用的</strong>，其他程序/指南可能会以不同的方式放置它们。</p><figure class="kv kw kx ky gt kz gh gi paragraph-image"><div class="gh gi ns"><img src="../Images/f9311884e508763ccde0c6b997633346.png" data-original-src="https://miro.medium.com/v2/resize:fit:768/format:webp/1*tZb56ZfvAeSwZu6AcAUo5w.jpeg"/></div><figcaption class="lg lh gj gh gi li lj bd b be z dk translated">作者图片</figcaption></figure><p id="271c" class="pw-post-body-paragraph jw jx iq jy b jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ij bi translated">在查看我们的矩阵时，我们的目标是让尽可能多的预测落在左上角(真正的负数)或右下角(真正的正数)的方块中。这两者与我们模型的错误预测相比越高越好。下面让我们看看我们是如何构建这个情节的:</p><pre class="kv kw kx ky gt ni mr nj nk aw nl bi"><span id="eea2" class="nm lm iq mr b gy nn no l np nq">import seaborn as sns<br/>import matplotlib.pyplot as plt<br/>%matplotlib inline</span><span id="c06f" class="nm lm iq mr b gy nr no l np nq"># Changing our dpi enables us to easily resize our image<br/>plt.figure(dpi=100)</span><span id="4edf" class="nm lm iq mr b gy nr no l np nq"># Build a heatmap using the con_mat array<br/>sns.heatmap(con_mat, cmap="YlGnBu", annot=True,<br/>       xticklabels=['Lost at Sea', 'Survived'],<br/>       yticklabels=['Lost at Sea', 'Survived'])</span><span id="7c66" class="nm lm iq mr b gy nr no l np nq"># Remember that our x-axis is always predictions in Scikit-Learn<br/>plt.xlabel('Predicted')</span><span id="3807" class="nm lm iq mr b gy nr no l np nq"># Our y-axis is always the actual results<br/>plt.ylabel('Actual')</span><span id="a5be" class="nm lm iq mr b gy nr no l np nq">plt.title('Logistic Regression Confusion Matrix');</span></pre><p id="5ba7" class="pw-post-body-paragraph jw jx iq jy b jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ij bi translated">由此产生的图将被颜色编码和注释，以准确显示我们的每个模型的预测落在哪里。</p><figure class="kv kw kx ky gt kz gh gi paragraph-image"><div class="gh gi nt"><img src="../Images/d3f4dfe435053b0abc3e3c001bd0782c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1200/format:webp/1*KO433Vm_d1P_fqimPF0HuQ.jpeg"/></div><figcaption class="lg lh gj gh gi li lj bd b be z dk translated">作者图片</figcaption></figure><p id="48aa" class="pw-post-body-paragraph jw jx iq jy b jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ij bi translated">我们现在可以很容易地看到，我们的模型的大多数预测是正确的，当不正确时，它更容易出现假阳性而不是假阴性。</p><p id="2d9f" class="pw-post-body-paragraph jw jx iq jy b jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ij bi translated">Seaborn还支持许多不同的调色板，根据品味、可读性或客户的配色方案来选择。</p><figure class="kv kw kx ky gt kz gh gi paragraph-image"><div role="button" tabindex="0" class="la lb di lc bf ld"><div class="gh gi nu"><img src="../Images/ada501f944d415b687d1644d2ccb9412.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Nzh0A4Eb10pwKijx5-4rOw.png"/></div></div><figcaption class="lg lh gj gh gi li lj bd b be z dk translated">光谱(左)，冰火(中)，火箭(右)</figcaption></figure><h2 id="d244" class="nm lm iq bd ln nv nw dn lr nx ny dp lv kh nz oa lz kl ob oc md kp od oe mh iw bi translated">使用案例:</h2><ul class=""><li id="4cb6" class="ms mt iq jy b jz mj kd mk kh of kl og kp oh kt mx my mz na bi translated">您希望轻松而精确地看到您的模型在哪里成功了，在哪里失败了</li><li id="3e4b" class="ms mt iq jy b jz nb kd nc kh nd kl ne kp nf kt mx my mz na bi translated">您正在构建演示文稿，并希望以一种清晰、可定制的方式直观地传达模型的结果</li></ul><h1 id="0933" class="ll lm iq bd ln lo lp lq lr ls lt lu lv lw lx ly lz ma mb mc md me mf mg mh mi bi translated">准确度、精密度、召回率和特异性</h1><p id="1653" class="pw-post-body-paragraph jw jx iq jy b jz mj kb kc kd mk kf kg kh ml kj kk kl mm kn ko kp mn kr ks kt ij bi translated">尽管我们的混淆矩阵看起来不错，但是很难用它来比较模型。如果我们试图找出逻辑回归、KNN、决策树或随机森林中的哪一个最适合我们的问题，那么必须整理和比较4个不同的地块，每个地块有4个不同的类别，这将是非常耗时的。</p><p id="b416" class="pw-post-body-paragraph jw jx iq jy b jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ij bi translated">谢天谢地，根据我们的真实预测和错误预测之间的关系，我们可以计算出四个分数。每一个都强调我们结果的不同方面，我们选择哪一个可以基于几个不同的因素，包括客户的需求，我们的预测，以及我们数据中的任何不平衡。</p><h2 id="209b" class="nm lm iq bd ln nv nw dn lr nx ny dp lv kh nz oa lz kl ob oc md kp od oe mh iw bi translated"><strong class="ak">准确率:</strong>(真阳性+真阴性)/所有预测</h2><p id="5dd2" class="pw-post-body-paragraph jw jx iq jy b jz mj kb kc kd mk kf kg kh ml kj kk kl mm kn ko kp mn kr ks kt ij bi translated">一个平衡的指标，奖励正确预测正面和负面结果的模型。当您调用它的<code class="fe mo mp mq mr b">.score()</code>方法时，这是许多模型的默认设置。</p><p id="d78e" class="pw-post-body-paragraph jw jx iq jy b jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ij bi translated">如果我们的目标类和非目标类之间的数据不平衡，这可能会产生误导，即如果在100个条目的数据集中有5个目标类，并且我们的模型预测一切都是负面的，它仍然会获得95%的准确率。</p><p id="c493" class="pw-post-body-paragraph jw jx iq jy b jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ij bi translated">准确性得分指标内置于Scikit-Learn中，只需将其导入，并将我们模型的预测与真实结果一起插入即可。</p><pre class="kv kw kx ky gt ni mr nj nk aw nl bi"><span id="d053" class="nm lm iq mr b gy nn no l np nq">from sklearn.metrics import accuracy_score</span><span id="6ef3" class="nm lm iq mr b gy nr no l np nq"># Remember to place the true results first <br/>accuracy = accuracy_score(y_test, y_pred)</span></pre><figure class="kv kw kx ky gt kz gh gi paragraph-image"><div role="button" tabindex="0" class="la lb di lc bf ld"><div class="gh gi oi"><img src="../Images/cf23547b8a7f1396796cc9811db7dba1.png" data-original-src="https://miro.medium.com/v2/resize:fit:628/format:webp/1*I5R93szhXm-BCVvV-EFt6A.png"/></div></div><figcaption class="lg lh gj gh gi li lj bd b be z dk translated">作者图片</figcaption></figure><h2 id="4e86" class="nm lm iq bd ln nv nw dn lr nx ny dp lv kh nz oa lz kl ob oc md kp od oe mh iw bi translated">精度:真阳性/(真阳性+假阳性)</h2><p id="a0e9" class="pw-post-body-paragraph jw jx iq jy b jz mj kb kc kd mk kf kg kh ml kj kk kl mm kn ko kp mn kr ks kt ij bi translated">一种衡量标准，优先考虑我们的模型做出的正面猜测，而忽略任何被归类为负面的猜测。</p><p id="3c6f" class="pw-post-body-paragraph jw jx iq jy b jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ij bi translated">这个指标的主要关注点是，当你的模型预测一个数据点是正的，同时原谅它可能错过的任何正的时候，你的模型是正确的。思考这个问题的一个好方法是引用这句话:<em class="oj">“十个有罪的人逃脱总比一个无辜的人受苦要好。”</em></p><p id="e61b" class="pw-post-body-paragraph jw jx iq jy b jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ij bi translated">当正面预测的后果远远超过负面预测的后果时，这是最好的选择。和准确性一样，精确度也可以从Scikit-Learn导入。</p><pre class="kv kw kx ky gt ni mr nj nk aw nl bi"><span id="f911" class="nm lm iq mr b gy nn no l np nq">from sklearn.metrics import precision_score</span><span id="e0f9" class="nm lm iq mr b gy nr no l np nq">precision = precision_score(y_test, y_pred)</span></pre><figure class="kv kw kx ky gt kz gh gi paragraph-image"><div class="gh gi ok"><img src="../Images/f907a7754c36c404da2d40e76a2d896d.png" data-original-src="https://miro.medium.com/v2/resize:fit:668/format:webp/1*HtZ0DzA1E2iCdF5cbk65qQ.png"/></div><figcaption class="lg lh gj gh gi li lj bd b be z dk translated">作者图片</figcaption></figure><h2 id="eff7" class="nm lm iq bd ln nv nw dn lr nx ny dp lv kh nz oa lz kl ob oc md kp od oe mh iw bi translated">回忆:真阳性/(真阳性+假阴性)</h2><p id="cd9d" class="pw-post-body-paragraph jw jx iq jy b jz mj kb kc kd mk kf kg kh ml kj kk kl mm kn ko kp mn kr ks kt ij bi translated">把回忆想象成精确的反面。recall优先考虑的不是正面预测，而是确保所有目标类都被正确识别，而不管有多少其他数据点被错误地归入其中。</p><p id="c6ad" class="pw-post-body-paragraph jw jx iq jy b jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ij bi translated">回忆强调识别所有的目标类别，这一点最好用需要对一个人是否患有高度传染性疾病进行分类的模型的假设情况来描述。假阳性会导致一点恐慌，这个人会被隔离几个星期。假阴性意味着这个人可以自由传播疾病。</p><p id="c077" class="pw-post-body-paragraph jw jx iq jy b jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ij bi translated">像准确度和精确度一样，召回可以从Scikit-Learn导入。</p><pre class="kv kw kx ky gt ni mr nj nk aw nl bi"><span id="9b08" class="nm lm iq mr b gy nn no l np nq">from sklearn.metrics import recall_score</span><span id="0b91" class="nm lm iq mr b gy nr no l np nq">recall = recall_score(y_test, y_pred)</span></pre><figure class="kv kw kx ky gt kz gh gi paragraph-image"><div class="gh gi ol"><img src="../Images/f9b6f84a1e442718d6bdfef8ea067369.png" data-original-src="https://miro.medium.com/v2/resize:fit:726/format:webp/1*-Xl3Hd0fF94kvQ_XBu-HsQ.png"/></div><figcaption class="lg lh gj gh gi li lj bd b be z dk translated">作者图片</figcaption></figure><h2 id="e07f" class="nm lm iq bd ln nv nw dn lr nx ny dp lv kh nz oa lz kl ob oc md kp od oe mh iw bi translated">特异性:真阴性/(真阴性+假阳性)</h2><p id="3da7" class="pw-post-body-paragraph jw jx iq jy b jz mj kb kc kd mk kf kg kh ml kj kk kl mm kn ko kp mn kr ks kt ij bi translated">专一得不到很多爱，很容易看出为什么。当大多数人建立模型时，他们会想到如何最好地识别某些东西，无论是罕见的疾病、贷款违约，还是<a class="ae lk" href="https://www.youtube.com/watch?v=ACmydtFDTGs" rel="noopener ugc nofollow" target="_blank">热狗/非热狗</a>。特异性奖励正确预测数据点不在目标类中的模型，惩罚其误报，并忽略其任何正确预测！</p><p id="3d1d" class="pw-post-body-paragraph jw jx iq jy b jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ij bi translated">特异性仍然是一个值得一提的指标。如果我们将模型的特异性分数视为对其精确度分数的补充，我们可以在考虑任何数据不平衡的情况下，一起使用这两者来查看模型是否更擅长返回真阴性或真阳性。</p><p id="b23a" class="pw-post-body-paragraph jw jx iq jy b jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ij bi translated">与其他指标不同，Scikit-Learn中不包括特异性。我们可以通过创建一个通用函数来克服这个问题，因为由<code class="fe mo mp mq mr b">confusion_matrix()</code>生成的所有混淆矩阵都有相同的索引。</p><pre class="kv kw kx ky gt ni mr nj nk aw nl bi"><span id="eacb" class="nm lm iq mr b gy nn no l np nq">def specificty_score(confusion_matrix):<br/>    true_negatives = confusion_matrix[0][0]<br/>    false_positives = confusion_matrix[0][1]<br/>    <br/>    return true_negatives / (true_negatives + false_positives)</span><span id="7776" class="nm lm iq mr b gy nr no l np nq">specificty = specificty_score(con_mat)</span></pre><figure class="kv kw kx ky gt kz gh gi paragraph-image"><div class="gh gi om"><img src="../Images/4fc0b5e6725dd9278479929c12563335.png" data-original-src="https://miro.medium.com/v2/resize:fit:916/format:webp/1*NwDo95hXHLZdw4_AX45nPA.png"/></div><figcaption class="lg lh gj gh gi li lj bd b be z dk translated">作者图片</figcaption></figure><h2 id="215b" class="nm lm iq bd ln nv nw dn lr nx ny dp lv kh nz oa lz kl ob oc md kp od oe mh iw bi translated">使用案例:</h2><ul class=""><li id="c2b5" class="ms mt iq jy b jz mj kd mk kh of kl og kp oh kt mx my mz na bi translated">您需要一种方法来快速轻松地比较不同的模型</li><li id="207e" class="ms mt iq jy b jz nb kd nc kh nd kl ne kp nf kt mx my mz na bi translated">您的客户对他们希望模型如何表现有明确的偏好，这可以转化为对这4个分数中的一个进行优先排序</li></ul><h1 id="9833" class="ll lm iq bd ln lo lp lq lr ls lt lu lv lw lx ly lz ma mb mc md me mf mg mh mi bi translated">f分数</h1><p id="28aa" class="pw-post-body-paragraph jw jx iq jy b jz mj kb kc kd mk kf kg kh ml kj kk kl mm kn ko kp mn kr ks kt ij bi translated">当我们向客户提出精度和召回率这样的分数时，他们的反应可能是合乎逻辑的“这两个听起来不错，我们能确保模型在这两方面都很好吗？”虽然在分类中，鱼与熊掌兼得可能是一项艰巨的任务，但至少有一种方法可以根据模型的精度和召回率之间的关系对模型进行评分:F-Scores。</p><h2 id="c39e" class="nm lm iq bd ln nv nw dn lr nx ny dp lv kh nz oa lz kl ob oc md kp od oe mh iw bi translated">F1得分:2 *(精确度*召回率)/(精确度+召回率)</h2><p id="fe60" class="pw-post-body-paragraph jw jx iq jy b jz mj kb kc kd mk kf kg kh ml kj kk kl mm kn ko kp mn kr ks kt ij bi translated">一个模型的F1分数是它在精确度和召回率之间的调和平均值。如果您希望您的模型在这两方面都同样出色，而不是偏爱其中一个，这就是您的度量标准。</p><p id="f683" class="pw-post-body-paragraph jw jx iq jy b jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ij bi translated">F1可以直接从Scikit-Learn导入。</p><pre class="kv kw kx ky gt ni mr nj nk aw nl bi"><span id="41bf" class="nm lm iq mr b gy nn no l np nq">from sklearn.metrics import f1_score</span><span id="9bf7" class="nm lm iq mr b gy nr no l np nq">f1 = f1_score(y_test, y_pred)</span></pre><figure class="kv kw kx ky gt kz gh gi paragraph-image"><div class="gh gi on"><img src="../Images/976b361cc1c4eeb3ed9e8e86b18b113b.png" data-original-src="https://miro.medium.com/v2/resize:fit:946/format:webp/1*7HGnz2yLVKt8GXhSFlTb0Q.png"/></div><figcaption class="lg lh gj gh gi li lj bd b be z dk translated">作者图片</figcaption></figure><h2 id="65d3" class="nm lm iq bd ln nv nw dn lr nx ny dp lv kh nz oa lz kl ob oc md kp od oe mh iw bi translated"><strong class="ak"> F </strong> β <strong class="ak">得分:(1 + </strong> β <strong class="ak"> ) *(精度*召回)/ ( </strong> β *精度+召回)</h2><p id="4f6a" class="pw-post-body-paragraph jw jx iq jy b jz mj kb kc kd mk kf kg kh ml kj kk kl mm kn ko kp mn kr ks kt ij bi translated">使用F1分数假设误分类或者假阴性或者假阳性导致相等的成本，这在现实生活中很难实现。对于我们倾向于精确或回忆，但仍然希望对方输入的情况，我们可以使用Fβ分数。</p><p id="1867" class="pw-post-body-paragraph jw jx iq jy b jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ij bi translated">与我们到目前为止看到的其他得分不同，计算我们的Fβ得分除了我们的模型预测和正确的目标值之外，还需要一个额外的参数:β参数。考虑β参数的一个简单方法是我们对召回率的偏好是精确率的多少倍，即β为0 . 5意味着我们对召回率的偏好是精确率的一半，β为1意味着我们对两者的偏好相同，β为2意味着我们对召回率的偏好是精确率的两倍。</p><p id="4413" class="pw-post-body-paragraph jw jx iq jy b jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ij bi translated">幸运的是，Sciki-Learn有一个内置的Fβ分数函数，我们可以导入它。</p><pre class="kv kw kx ky gt ni mr nj nk aw nl bi"><span id="c557" class="nm lm iq mr b gy nn no l np nq">from sklearn.metrics import fbeta_score</span><span id="c6f1" class="nm lm iq mr b gy nr no l np nq"># Our score where we favor recall<br/>fbeta_2 = fbeta_score(y_test, y_pred, 2)</span><span id="fd3b" class="nm lm iq mr b gy nr no l np nq"># Our score where we favor precision<br/>fbeta_half = fbeta_score(y_test, y_pred, .5)</span></pre><figure class="kv kw kx ky gt kz gh gi paragraph-image"><div class="gh gi oo"><img src="../Images/7db867e476081db4326059e2be3c7e32.png" data-original-src="https://miro.medium.com/v2/resize:fit:1136/format:webp/1*UUkfwn4yufl_P0uWybiyXw.png"/></div><figcaption class="lg lh gj gh gi li lj bd b be z dk translated">作者图片</figcaption></figure><h2 id="ffba" class="nm lm iq bd ln nv nw dn lr nx ny dp lv kh nz oa lz kl ob oc md kp od oe mh iw bi translated">使用案例:</h2><ul class=""><li id="e545" class="ms mt iq jy b jz mj kd mk kh of kl og kp oh kt mx my mz na bi translated">你和你的客户谈过不同的分数，他们想要在回忆和精确之间取得平衡</li><li id="4d53" class="ms mt iq jy b jz nb kd nc kh nd kl ne kp nf kt mx my mz na bi translated">你心中有一个清晰的比例，你有多喜欢其中一个</li></ul><h1 id="62d7" class="ll lm iq bd ln lo lp lq lr ls lt lu lv lw lx ly lz ma mb mc md me mf mg mh mi bi translated">“虚拟”模型</h1><p id="84d8" class="pw-post-body-paragraph jw jx iq jy b jz mj kb kc kd mk kf kg kh ml kj kk kl mm kn ko kp mn kr ks kt ij bi translated">我要介绍的最后一个指标看似简单:与简单规则相比，我们的模型表现如何？在我们目前的状态下，我们可以自信地说，我们的模型胜于掷硬币，但如果我们只是预测一切都是负面的，或者预测所有女人都幸存，所有男人都死亡，会怎么样？这些被称为“虚拟”模型，对于衡量我们的模型实际上有多成功非常有帮助。</p><p id="03ac" class="pw-post-body-paragraph jw jx iq jy b jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ij bi translated">Scikit-Learn实际上有它自己的<a class="ae lk" href="https://scikit-learn.org/stable/modules/generated/sklearn.dummy.DummyClassifier.html#sklearn.dummy.DummyClassifier" rel="noopener ugc nofollow" target="_blank">虚拟分类器</a>我们可以导入，但是在这种情况下，我们将基于上面提到的性别规则创建我们自己的预测数组。我们的目标是击败使用这个简单规则做出的预测。如果这不可能，那么我们需要返回并执行以下操作:</p><ul class=""><li id="42e4" class="ms mt iq jy b jz ka kd ke kh mu kl mv kp mw kt mx my mz na bi translated">收集更好的数据(如果可能)</li><li id="b181" class="ms mt iq jy b jz nb kd nc kh nd kl ne kp nf kt mx my mz na bi translated">更好地设计我们的功能</li><li id="c8c3" class="ms mt iq jy b jz nb kd nc kh nd kl ne kp nf kt mx my mz na bi translated">尝试不同的模型和/或不同的模型参数</li></ul><pre class="kv kw kx ky gt ni mr nj nk aw nl bi"><span id="a9dc" class="nm lm iq mr b gy nn no l np nq"># A simple trick since Sex_female is already a binary array<br/>dummy_y = X_test["Sex_female"]</span><span id="a320" class="nm lm iq mr b gy nr no l np nq"># Generate a dummy confustion matrix<br/>dummy_con_mat = confusion_matrix(y_test, dummy_y)</span><span id="209e" class="nm lm iq mr b gy nr no l np nq"># Generate the dummy variant of each score<br/>dummy_acc = accuracy_score(y_test, dummy_y)<br/>dummy_prec = precision_score(y_test, dummy_y)<br/>dummy_recall = recall_score(y_test, dummy_y)<br/>dummy_spec = = specificty_score(dummy_con_mat)<br/>dummy_f1 = f1_score(y_test, dummy_y)<br/>dummy_fbeta_2 = fbeta_score(y_test, dummy_y, 2)<br/>dummy_fbeta_half = fbeta_score(y_test, dummy_y, .5)</span></pre><figure class="kv kw kx ky gt kz gh gi paragraph-image"><div role="button" tabindex="0" class="la lb di lc bf ld"><div class="gh gi op"><img src="../Images/6b2eaf270ed2896f6384e50763fc3150.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*wnBRdKbKbyxSfXcdOjBrUg.png"/></div></div></figure><figure class="kv kw kx ky gt kz gh gi paragraph-image"><div role="button" tabindex="0" class="la lb di lc bf ld"><div class="gh gi oq"><img src="../Images/aab39386714b90c83a6fc4d6812b468f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1156/format:webp/1*uIgSh-0NgMVkHwC60FO3ew.png"/></div></div><figcaption class="lg lh gj gh gi li lj bd b be z dk translated">作者提供的图片</figcaption></figure><p id="14e2" class="pw-post-body-paragraph jw jx iq jy b jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ij bi translated">啊哦…看起来我们需要在这一个上回到制图板！</p><h2 id="5b0b" class="nm lm iq bd ln nv nw dn lr nx ny dp lv kh nz oa lz kl ob oc md kp od oe mh iw bi translated">使用案例:</h2><ul class=""><li id="1c03" class="ms mt iq jy b jz mj kd mk kh of kl og kp oh kt mx my mz na bi translated">您想要对您的模型进行健全性检查，以确保与简单的经验法则相比，它确实值得使用</li><li id="04b6" class="ms mt iq jy b jz nb kd nc kh nd kl ne kp nf kt mx my mz na bi translated">你希望你的模型能够超越一个初始基准</li></ul><h1 id="368d" class="ll lm iq bd ln lo lp lq lr ls lt lu lv lw lx ly lz ma mb mc md me mf mg mh mi bi translated">结论</h1><p id="a0e7" class="pw-post-body-paragraph jw jx iq jy b jz mj kb kc kd mk kf kg kh ml kj kk kl mm kn ko kp mn kr ks kt ij bi translated">我希望这篇文章让你对如何判断分类模型有更多的了解，而不仅仅是使用模型的内部评分方法。在回顾中，我们了解到以下内容:</p><ul class=""><li id="9c1d" class="ms mt iq jy b jz ka kd ke kh mu kl mv kp mw kt mx my mz na bi translated">评估您的分类模型的8个标准，包括它们背后的理论</li><li id="b40c" class="ms mt iq jy b jz nb kd nc kh nd kl ne kp nf kt mx my mz na bi translated">如何在python中导入或构建它们</li><li id="0fd8" class="ms mt iq jy b jz nb kd nc kh nd kl ne kp nf kt mx my mz na bi translated">每个指标的用例可以帮助您决定哪一个最适合您的需求</li></ul><p id="4802" class="pw-post-body-paragraph jw jx iq jy b jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ij bi translated">本文并没有穷尽分类指标，如果没有一个适合您的情况，那么我的建议是先通读Scikit-Learn的<a class="ae lk" href="https://scikit-learn.org/stable/modules/model_evaluation.html" rel="noopener ugc nofollow" target="_blank">指标和评分</a>文档，然后从那里开始实验。狩猎愉快！</p></div></div>    
</body>
</html>