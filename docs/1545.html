<html>
<head>
<title>Digit Classification Using CNN, Keras Deep Learning Framework</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">使用CNN，Keras深度学习框架进行数字分类</h1>
<blockquote>原文：<a href="https://pub.towardsai.net/digit-classification-using-cnn-keras-deep-learning-framework-3b4cfbafa285?source=collection_archive---------2-----------------------#2021-02-16">https://pub.towardsai.net/digit-classification-using-cnn-keras-deep-learning-framework-3b4cfbafa285?source=collection_archive---------2-----------------------#2021-02-16</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><h2 id="ecab" class="ir is it bd b dl iu iv iw ix iy iz dk ja translated" aria-label="kicker paragraph"><a class="ae ep" href="https://towardsai.net/p/category/machine-learning/deep-learning" rel="noopener ugc nofollow" target="_blank">深度学习</a></h2><div class=""/><div class=""><h2 id="cef7" class="pw-subtitle-paragraph jz jc it bd b ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq dk translated">详细的解释和算法，改进了我以前的代码。完整的代码<a class="ae kr" href="https://github.com/arditoibryan/Projects/blob/master/20200724_Image_Classification/Digit_Classification_2.ipynb" rel="noopener ugc nofollow" target="_blank">可在我的回购。</a></h2></div><p id="433e" class="pw-post-body-paragraph ks kt it ku b kv kw kd kx ky kz kg la lb lc ld le lf lg lh li lj lk ll lm ln im bi translated"><a class="ae kr" href="http://www.michelangiolo.best/" rel="noopener ugc nofollow" target="_blank"> <strong class="ku jd">点击这里了解我，我的项目，我的最新文章。</strong> </a></p><p id="83cd" class="pw-post-body-paragraph ks kt it ku b kv kw kd kx ky kz kg la lb lc ld le lf lg lh li lj lk ll lm ln im bi translated">在2020年，我已经发表了一篇关于如何进行数字分类的类似文章。尽管代码和结果几乎相同(毕竟是同一个问题)，但今年，在了解了更多关于深度学习架构的知识后，我对自己的代码有了更多的了解，并进行了更多的改进，引入了新的功能，希望能够解释笔记本的所有组件。</p><figure class="lp lq lr ls gt lt gh gi paragraph-image"><div role="button" tabindex="0" class="lu lv di lw bf lx"><div class="gh gi lo"><img src="../Images/b291a88dd9cfcfdc46f6944b9d6c8d42.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*7wEbAVeLNocFZHcQsUpwRw.png"/></div></div><figcaption class="ma mb gj gh gi mc md bd b be z dk translated">卷积神经网络的3D表示</figcaption></figure><h2 id="9b93" class="me mf it bd mg mh mi dn mj mk ml dp mm lb mn mo mp lf mq mr ms lj mt mu mv iz bi translated">最难的概念</h2><p id="7178" class="pw-post-body-paragraph ks kt it ku b kv mw kd kx ky mx kg la lb my ld le lf mz lh li lj na ll lm ln im bi translated">在执行图像分类时，有几个元步骤是使用CNN时所有类似模型共有的，但在第一次使用时可能会引起一些混淆:</p><ul class=""><li id="c686" class="nb nc it ku b kv kw ky kz lb nd lf ne lj nf ln ng nh ni nj bi translated">导入数据集</li><li id="939f" class="nb nc it ku b kv nk ky nl lb nm lf nn lj no ln ng nh ni nj bi translated">规范化和反规范化(如果需要)</li><li id="348a" class="nb nc it ku b kv nk ky nl lb nm lf nn lj no ln ng nh ni nj bi translated">数据扩充</li></ul><p id="b946" class="pw-post-body-paragraph ks kt it ku b kv kw kd kx ky kz kg la lb lc ld le lf lg lh li lj lk ll lm ln im bi translated">通过使用<strong class="ku jd"> mnist </strong>库，我已经可以下载完整的70，000个28x28个一位数的数据集。不幸的是，数据集已经被分割成训练和集合分区(X_train，y_train，X_test，y_test)，我认为这在导入数据集时是一个非常糟糕的做法:在预处理阶段处理整个数据集之前，只有在最后才应该分割数据，因为这是将数据输入模型之前的最后一步。</p><h2 id="06be" class="me mf it bd mg mh mi dn mj mk ml dp mm lb mn mo mp lf mq mr ms lj mt mu mv iz bi translated">为什么要标准化数据</h2><p id="a186" class="pw-post-body-paragraph ks kt it ku b kv mw kd kx ky mx kg la lb my ld le lf mz lh li lj na ll lm ln im bi translated">对于LSTM和CNN，图像需要调整到相同的形状(它们已经是28x28，但对于更复杂的数据集，这是一个强制性的步骤，您需要使用额外的代码行来执行)。然后，所有编码的像素，可能只有黑白的，也有三维的RGB，都需要归一化:从[0，255]的范围，要压缩到[0，1]的范围。</p><pre class="lp lq lr ls gt np nq nr ns aw nt bi"><span id="29d2" class="me mf it nq b gy nu nv l nw nx">X_train /= 255<br/>X_test /= 255</span></pre><p id="2b70" class="pw-post-body-paragraph ks kt it ku b kv kw kd kx ky kz kg la lb lc ld le lf lg lh li lj lk ll lm ln im bi translated">这是用于标准化图像数据(转换为NumPy数组)的标准代码。对于图像来说完美的原因是，在标准化期间，我需要指定用于标准化目的的范围。相反，我更喜欢使用我自己的代码(您可以在图像和数字数据上测试它，结果与允许您执行规范化的scikit-learn工具相同)，原因只有一个:您可以从库中找到的所有规范化工具都不能反规范化数据。执行影像分类时，此步骤可能不是必需的，但对于LSTM等数值模型，您需要在模型完成后再次对数据进行反规格化。</p><pre class="lp lq lr ls gt np nq nr ns aw nt bi"><span id="354f" class="me mf it nq b gy nu nv l nw nx">def create_scaler(*args):<br/>  min_d = np.min(args[0])<br/>  max_d = np.max(args[0])<br/>  for partition in args:<br/>    if np.min(partition) &lt; min_d:<br/>      min_d = np.min(partition)<br/>    if np.max(partition) &gt; max_d:<br/>      max_d = np.max(partition)<br/>  return [min_d, max_d]</span><span id="7f8e" class="me mf it nq b gy ny nv l nw nx">def normalizer(scaler, df):<br/>  min_d = scaler[0]<br/>  max_d = scaler[1]<br/>  normalized_df = (df - min_d) / (max_d - min_d)<br/>  return normalized_df</span><span id="7d56" class="me mf it nq b gy ny nv l nw nx">def denormalizer(scaler, normalized_df):<br/>  min_d = scaler[0]<br/>  max_d = scaler[1]<br/>  denormalized_df = normalized_df * (max_d - min_d) + min_d<br/>  return denormalized_df</span></pre><p id="994a" class="pw-post-body-paragraph ks kt it ku b kv kw kd kx ky kz kg la lb lc ld le lf lg lh li lj lk ll lm ln im bi translated">我使用这个工具来标准化数据所需要的只是原始数据，我可以手动输入或者使用create_scaler发现的scaler(数据的范围)。为了<strong class="ku jd">反规格化数据</strong>(将其转换回原始形式)，相反，我需要的是规格化版本和缩放器。您将在下面的代码中看到这一点。</p><h2 id="832d" class="me mf it bd mg mh mi dn mj mk ml dp mm lb mn mo mp lf mq mr ms lj mt mu mv iz bi translated">数据扩充</h2><p id="d80d" class="pw-post-body-paragraph ks kt it ku b kv mw kd kx ky mx kg la lb my ld le lf mz lh li lj na ll lm ln im bi translated">当训练数据不足时，我们可以人为地创建原始数据集的变体来扩展其大小。例如，如果我想只在1000张图像上创建一个模型(就像我通常做的那样)，这就不是一个足够的训练规模。我能做的是通过改变它们的形状和旋转来创建原始图像的变体，只要它们最终都具有相同的大小，以便模型可以接受它们。那1000张图片可以变成20000张。</p><p id="a581" class="pw-post-body-paragraph ks kt it ku b kv kw kd kx ky kz kg la lb lc ld le lf lg lh li lj lk ll lm ln im bi translated">因为数字分类在训练集中已经有60，000个图像，所以不需要增加数据。</p><h1 id="e23f" class="nz mf it bd mg oa ob oc mj od oe of mm ki og kj mp kl oh km ms ko oi kp mv oj bi translated">让我们编码</h1><h2 id="f23f" class="me mf it bd mg mh mi dn mj mk ml dp mm lb mn mo mp lf mq mr ms lj mt mu mv iz bi translated">1.导入库</h2><pre class="lp lq lr ls gt np nq nr ns aw nt bi"><span id="fbb5" class="me mf it nq b gy nu nv l nw nx">#to import data + preprocessing<br/>import numpy as np<br/>from keras.datasets import mnist<br/>import matplotlib.pyplot as plt<br/>%matplotlib inline</span><span id="17d9" class="me mf it nq b gy ny nv l nw nx">#to build the CNN<br/>import tensorflow<br/>from keras.models import Sequential<br/>from keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPooling2D</span><span id="8f64" class="me mf it nq b gy ny nv l nw nx">#test on a new image<br/>import imageio<br/>import numpy as np<br/>from matplotlib import pyplot as plt</span></pre><h2 id="4bd0" class="me mf it bd mg mh mi dn mj mk ml dp mm lb mn mo mp lf mq mr ms lj mt mu mv iz bi translated">2.看着这些数据</h2><pre class="lp lq lr ls gt np nq nr ns aw nt bi"><span id="6cba" class="me mf it nq b gy nu nv l nw nx">(X_train, y_train), (X_test, y_test) = mnist.load_data()<br/>print(X_train.shape)<br/>print(X_test.shape)<br/>print(y_train.shape)<br/>print(y_test.shape)</span></pre><h2 id="f92c" class="me mf it bd mg mh mi dn mj mk ml dp mm lb mn mo mp lf mq mr ms lj mt mu mv iz bi translated">3.预处理</h2><pre class="lp lq lr ls gt np nq nr ns aw nt bi"><span id="94b2" class="me mf it nq b gy nu nv l nw nx">#show one image with label<br/>print(y_train[0])<br/>plt.imshow(X_train[0], cmap='Greys')<br/>plt.show()</span></pre><p id="f2d2" class="pw-post-body-paragraph ks kt it ku b kv kw kd kx ky kz kg la lb lc ld le lf lg lh li lj lk ll lm ln im bi translated">我现在将塑造数据，使其适合神经网络。在它准备好之后，我还需要对它进行规范化。我使用我自己的定标器是出于一个非常精确的原因，事实上，对于常规的sklearn模型，我不能将其反向规格化。虽然这个模型处理的是分类数据，但我不需要逆向缩放，但使用最好的算法总是一个好的实践。</p><pre class="lp lq lr ls gt np nq nr ns aw nt bi"><span id="eb97" class="me mf it nq b gy nu nv l nw nx">#change shape to IMAGES only for CNN input<br/>X_train = X_train.reshape(60000, 28, 28, 1)<br/>X_test = X_test.reshape(10000, 28, 28, 1)<br/>#the labels are already in an acceptable shape</span><span id="ac68" class="me mf it nq b gy ny nv l nw nx">#normalize image data only<br/>scaler = create_scaler([0, 255])<br/>X_train_ = normalizer(scaler, X_train)<br/>X_test_ = normalizer(scaler, X_test)</span></pre><p id="6247" class="pw-post-body-paragraph ks kt it ku b kv kw kd kx ky kz kg la lb lc ld le lf lg lh li lj lk ll lm ln im bi translated">我还想包含不推荐使用的代码，这样您就可以看到我使用的代码和我以前想使用的代码之间的区别。</p><pre class="lp lq lr ls gt np nq nr ns aw nt bi"><span id="6a01" class="me mf it nq b gy nu nv l nw nx">#DEPRECATED: normalize, identical to the new method<br/>import numpy as np<br/>X_train = np.array(X_train, dtype=np.float64)<br/>X_test = np.array(X_test, dtype=np.float64)<br/>X_train /= 255<br/>X_test /= 255</span></pre><h2 id="f85e" class="me mf it bd mg mh mi dn mj mk ml dp mm lb mn mo mp lf mq mr ms lj mt mu mv iz bi translated">4.美国有线新闻网；卷积神经网络</h2><p id="3f47" class="pw-post-body-paragraph ks kt it ku b kv mw kd kx ky mx kg la lb my ld le lf mz lh li lj na ll lm ln im bi translated">不幸的是，没有一种简单的方法来创建CNN。我使用的是Keras提供的标准表格。</p><pre class="lp lq lr ls gt np nq nr ns aw nt bi"><span id="6332" class="me mf it nq b gy nu nv l nw nx">model = Sequential()<br/>model.add(Conv2D(32, kernel_size=(3, 3),<br/>     activation='relu',<br/>     input_shape=(28, 28, 1))) #image size<br/>model.add(Conv2D(64, (3, 3), activation='relu'))<br/>model.add(MaxPooling2D(pool_size=(2, 2)))<br/>model.add(Dropout(0.25))<br/>model.add(Flatten())<br/>model.add(Dense(128, activation='relu'))<br/>model.add(Dropout(0.5))<br/>model.add(Dense(10, activation='softmax')) #number of classes</span><span id="d27d" class="me mf it nq b gy ny nv l nw nx">model.compile(loss='sparse_categorical_crossentropy',<br/>      optimizer='adam',<br/>      metrics=['accuracy'])</span><span id="09eb" class="me mf it nq b gy ny nv l nw nx">batch_size = 128<br/>epochs = 10</span></pre><p id="7f5d" class="pw-post-body-paragraph ks kt it ku b kv kw kd kx ky kz kg la lb lc ld le lf lg lh li lj lk ll lm ln im bi translated">这是输出:</p><pre class="lp lq lr ls gt np nq nr ns aw nt bi"><span id="afee" class="me mf it nq b gy nu nv l nw nx">Epoch 1/10<br/>469/469 - 136s - loss: 0.2464 - accuracy: 0.9248 - val_loss: 0.0534 - val_accuracy: 0.9831<br/>Epoch 2/10<br/>469/469 - 135s - loss: 0.0860 - accuracy: 0.9749 - val_loss: 0.0437 - val_accuracy: 0.9864<br/>Epoch 3/10<br/>469/469 - 141s - loss: 0.0638 - accuracy: 0.9806 - val_loss: 0.0355 - val_accuracy: 0.9879<br/>Epoch 4/10<br/>469/469 - 135s - loss: 0.0513 - accuracy: 0.9842 - val_loss: 0.0328 - val_accuracy: 0.9891<br/>Epoch 5/10<br/>469/469 - 135s - loss: 0.0458 - accuracy: 0.9848 - val_loss: 0.0266 - val_accuracy: 0.9918<br/>Epoch 6/10<br/>469/469 - 135s - loss: 0.0370 - accuracy: 0.9880 - val_loss: 0.0291 - val_accuracy: 0.9912<br/>Epoch 7/10<br/>469/469 - 134s - loss: 0.0318 - accuracy: 0.9896 - val_loss: 0.0300 - val_accuracy: 0.9908<br/>Epoch 8/10<br/>469/469 - 134s - loss: 0.0300 - accuracy: 0.9908 - val_loss: 0.0342 - val_accuracy: 0.9905<br/>Epoch 9/10<br/>469/469 - 135s - loss: 0.0278 - accuracy: 0.9914 - val_loss: 0.0299 - val_accuracy: 0.9919<br/>Epoch 10/10<br/>469/469 - 134s - loss: 0.0240 - accuracy: 0.9924 - val_loss: 0.0310 - val_accuracy: 0.9914<br/>313/313 - 6s - loss: 0.0310 - accuracy: 0.9914<br/>Test loss: 0.03104633092880249<br/>Test accuracy: 0.9914000034332275</span></pre><p id="15d8" class="pw-post-body-paragraph ks kt it ku b kv kw kd kx ky kz kg la lb lc ld le lf lg lh li lj lk ll lm ln im bi translated">查看模型的摘要总是一个好的做法。我可以使用Keras模型类中可用的summary方法来做到这一点。</p><pre class="lp lq lr ls gt np nq nr ns aw nt bi"><span id="9464" class="me mf it nq b gy nu nv l nw nx">#   summarize model_1<br/>#input layer not included<br/>model.summary(line_length=None, positions=None, print_fn=None)</span><span id="48b6" class="me mf it nq b gy ny nv l nw nx">Model: "sequential"<br/>_________________________________________________________________<br/>Layer (type)                 Output Shape              Param #   <br/>=================================================================<br/>conv2d (Conv2D)              (None, 26, 26, 32)        320       <br/>_________________________________________________________________<br/>conv2d_1 (Conv2D)            (None, 24, 24, 64)        18496     <br/>_________________________________________________________________<br/>max_pooling2d (MaxPooling2D) (None, 12, 12, 64)        0         <br/>_________________________________________________________________<br/>dropout (Dropout)            (None, 12, 12, 64)        0         <br/>_________________________________________________________________<br/>flatten (Flatten)            (None, 9216)              0         <br/>_________________________________________________________________<br/>dense (Dense)                (None, 128)               1179776   <br/>_________________________________________________________________<br/>dropout_1 (Dropout)          (None, 128)               0         <br/>_________________________________________________________________<br/>dense_1 (Dense)              (None, 10)                1290      <br/>=================================================================<br/>Total params: 1,199,882<br/>Trainable params: 1,199,882<br/>Non-trainable params: 0<br/>_________________________________________________________________</span></pre><p id="a28a" class="pw-post-body-paragraph ks kt it ku b kv kw kd kx ky kz kg la lb lc ld le lf lg lh li lj lk ll lm ln im bi translated">还有一种非常有趣的可视化图层的方式:</p><pre class="lp lq lr ls gt np nq nr ns aw nt bi"><span id="9c24" class="me mf it nq b gy nu nv l nw nx">#   summarize model_2<br/>#input layer is included<br/>from keras.utils.vis_utils import plot_model<br/>plot_model(model, show_shapes=True, show_layer_names=True)</span></pre><figure class="lp lq lr ls gt lt gh gi paragraph-image"><div class="gh gi ok"><img src="../Images/10a1fc6ea02ceb4c6dca563cea0d720d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1058/format:webp/1*oSycYr2eeUd091d16QgocQ.png"/></div></figure><p id="3e8a" class="pw-post-body-paragraph ks kt it ku b kv kw kd kx ky kz kg la lb lc ld le lf lg lh li lj lk ll lm ln im bi translated">我现在可以训练模型了。这将需要几分钟的时间，虽然这仍然是一个雏形。通常，更复杂的图像数据需要几个小时，甚至几天来训练:这是云计算能力所必需的。</p><pre class="lp lq lr ls gt np nq nr ns aw nt bi"><span id="317e" class="me mf it nq b gy nu nv l nw nx">model.fit(X_train_, y_train,<br/>          batch_size=batch_size,<br/>          epochs=epochs,<br/>          verbose=2,<br/>          validation_data=(X_test, y_test))</span><span id="b8d9" class="me mf it nq b gy ny nv l nw nx">score = model.evaluate(X_test, y_test, verbose=2)<br/>print('Test loss:', score[0])<br/>print('Test accuracy:', score[1])</span></pre><h2 id="fa08" class="me mf it bd mg mh mi dn mj mk ml dp mm lb mn mo mp lf mq mr ms lj mt mu mv iz bi translated">5.在图像上测试它</h2><p id="33e2" class="pw-post-body-paragraph ks kt it ku b kv mw kd kx ky mx kg la lb my ld le lf mz lh li lj na ll lm ln im bi translated">我可以简单地在我已经从<strong class="ku jd"> mnist数据集</strong>下载的数据上测试模型(这就是我的准确度分数是如何计算的)，但是下载一个非标准化的图像并测试它会很好。</p><pre class="lp lq lr ls gt np nq nr ns aw nt bi"><span id="ca91" class="me mf it nq b gy nu nv l nw nx">im = imageio.imread("<a class="ae kr" href="https://i.imgur.com/a3Rql9C.png" rel="noopener ugc nofollow" target="_blank">https://i.imgur.com/a3Rql9C.png</a>")</span><span id="284c" class="me mf it nq b gy ny nv l nw nx">#visualize image<br/>gray = np.dot(im[...,:3], [0.299, 0.587, 0.114])<br/>plt.imshow(gray, cmap = plt.get_cmap('gray'))<br/>plt.show()</span></pre><figure class="lp lq lr ls gt lt gh gi paragraph-image"><div class="gh gi ol"><img src="../Images/1e8db46b63e2f080f8248cebae6659f0.png" data-original-src="https://miro.medium.com/v2/resize:fit:852/format:webp/1*brKN2USMIRZQNgmSORi1Aw.png"/></div><figcaption class="ma mb gj gh gi mc md bd b be z dk translated">URL上提供的图像</figcaption></figure><p id="06ff" class="pw-post-body-paragraph ks kt it ku b kv kw kd kx ky kz kg la lb lc ld le lf lg lh li lj lk ll lm ln im bi translated">在我下载了图像之后，我需要对它进行标准化，这样模型就可以在上面工作了。</p><pre class="lp lq lr ls gt np nq nr ns aw nt bi"><span id="b47b" class="me mf it nq b gy nu nv l nw nx"># reshape the image<br/>gray = gray.reshape(1, 28, 28, 1)</span><span id="a59a" class="me mf it nq b gy ny nv l nw nx"># normalize image<br/>gray /= 255</span></pre><p id="2cf8" class="pw-post-body-paragraph ks kt it ku b kv kw kd kx ky kz kg la lb lc ld le lf lg lh li lj lk ll lm ln im bi translated">现在我可以在上面测试模型了。人工智能会识别这个号码吗？</p><pre class="lp lq lr ls gt np nq nr ns aw nt bi"><span id="c365" class="me mf it nq b gy nu nv l nw nx">#predict digit in x_train<br/>prediction = model.predict(X_test[0].reshape(1, 28, 28, 1))<br/>print(y_test[0], prediction.argmax())</span><span id="9b9a" class="me mf it nq b gy ny nv l nw nx">5</span></pre><p id="7a11" class="pw-post-body-paragraph ks kt it ku b kv kw kd kx ky kz kg la lb lc ld le lf lg lh li lj lk ll lm ln im bi translated">太好了，人工智能识别出这是一个数字5。</p></div></div>    
</body>
</html>