<html>
<head>
<title>The NLP Cypher | 12.13.20</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">NLP密码| 12.13.20</h1>
<blockquote>原文：<a href="https://pub.towardsai.net/the-nlp-cypher-12-13-20-96758e9cd84b?source=collection_archive---------1-----------------------#2020-12-14">https://pub.towardsai.net/the-nlp-cypher-12-13-20-96758e9cd84b?source=collection_archive---------1-----------------------#2020-12-14</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><figure class="ip iq gp gr ir is gh gi paragraph-image"><div class="gh gi io"><img src="../Images/889365307a71d0cc05fc3560a2303009.png" data-original-src="https://miro.medium.com/v2/resize:fit:1390/format:webp/0*g2BRGAZJCahv5fyy.jpg"/></div><figcaption class="iv iw gj gh gi ix iy bd b be z dk translated">士兵在山峡中，与风暴| Vernet</figcaption></figure><h2 id="d524" class="iz ja jb bd b dl jc jd je jf jg jh dk ji translated" aria-label="kicker paragraph">自然语言处理每周时事通讯</h2><div class=""/><div class=""><h2 id="01fe" class="pw-subtitle-paragraph kh jk jb bd b ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky dk translated">神经炎后遗症</h2></div></div><div class="ab cl kz la hu lb" role="separator"><span class="lc bw bk ld le lf"/><span class="lc bw bk ld le lf"/><span class="lc bw bk ld le"/></div><div class="ij ik il im in"><p id="60ae" class="pw-post-body-paragraph lg lh jb li b lj lk kl ll lm ln ko lo lp lq lr ls lt lu lv lw lx ly lz ma mb ij bi mc translated">嘿，欢迎回来！一周又一周的会议(NeurIPS)过去了，许多事情已经慢慢进入NLP管道。</p><p id="434f" class="pw-post-body-paragraph lg lh jb li b lj lk kl ll lm ln ko lo lp lq lr ls lt lu lv lw lx ly lz ma mb ij bi translated">首先，GPT-3纸赢得了一个奖杯:</p><figure class="ml mm mn mo gt is"><div class="bz fp l di"><div class="mp mq l"/></div></figure><p id="4a54" class="pw-post-body-paragraph lg lh jb li b lj lk kl ll lm ln ko lo lp lq lr ls lt lu lv lw lx ly lz ma mb ij bi translated">此外，如果您需要赶上进度，这里有一个在NeurIPS上找到的以NLP为中心的论文列表:</p><div class="ip iq gp gr ir mr"><a href="https://www.topbots.com/neurips-2020-nlp-research-papers/" rel="noopener  ugc nofollow" target="_blank"><div class="ms ab fo"><div class="mt ab mu cl cj mv"><h2 class="bd jl gy z fp mw fr fs mx fu fw jk bi translated">NeurIPS 2020:自然语言处理(NLP)和对话式人工智能的关键研究论文</h2><div class="my l"><h3 class="bd b gy z fp mw fr fs mx fu fw dk translated">以下是NeurIPS 2020上介绍的最有趣的NLP和对话式AI研究论文。</h3></div><div class="mz l"><p class="bd b dl z fp mw fr fs mx fu fw dk translated">www.topbots.com</p></div></div><div class="na l"><div class="nb l nc nd ne na nf it mr"/></div></div></a></div><h2 id="0b9d" class="ng nh jb bd ni nj nk dn nl nm nn dp no lp np nq nr lt ns nt nu lx nv nw nx jh bi translated">模糊的秘密</h2><p id="c210" class="pw-post-body-paragraph lg lh jb li b lj ny kl ll lm nz ko lo lp oa lr ls lt ob lv lw lx oc lz ma mb ij bi translated">这是Depix，一个从像素化截图中恢复密码的库。如果你使用像素化来保护敏感信息，你需要一种新的方法。图书馆已经在GitHub上积累了10K之星😭😭。此外，beurtschipper的个人资料照片获得了本周头像提名。顺便说一句，这是很棒的工作！(另外，它要求像素化的图像是用线性盒式过滤器创建的)</p><figure class="ml mm mn mo gt is gh gi paragraph-image"><div role="button" tabindex="0" class="oe of di og bf oh"><div class="gh gi od"><img src="../Images/426c70c3b3816e7eab32bc69d7bef1b3.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*ya6xII-GWOsYMooG.png"/></div></div></figure><p id="d0b0" class="pw-post-body-paragraph lg lh jb li b lj lk kl ll lm ln ko lo lp lq lr ls lt lu lv lw lx ly lz ma mb ij bi translated"><strong class="li jl"> GitHub </strong>:</p><div class="ip iq gp gr ir mr"><a href="https://github.com/beurtschipper/Depix" rel="noopener  ugc nofollow" target="_blank"><div class="ms ab fo"><div class="mt ab mu cl cj mv"><h2 class="bd jl gy z fp mw fr fs mx fu fw jk bi translated">beurtschipper/Depix</h2><div class="my l"><h3 class="bd b gy z fp mw fr fs mx fu fw dk translated">Depix是一个从像素化的截图中恢复密码的工具。这种实现适用于像素化图像…</h3></div><div class="mz l"><p class="bd b dl z fp mw fr fs mx fu fw dk translated">github.com</p></div></div><div class="na l"><div class="oi l nc nd ne na nf it mr"/></div></div></a></div><h2 id="9513" class="ng nh jb bd ni nj nk dn nl nm nn dp no lp np nq nr lt ns nt nu lx nv nw nx jh bi translated">340密码就此终结</h2><p id="481e" class="pw-post-body-paragraph lg lh jb li b lj ny kl ll lm nz ko lo lp oa lr ls lt ob lv lw lx oc lz ma mb ij bi translated">如果你喜欢密码，(除了NLP密码😁)十二宫杀手的340密码本周被解密👀。作为背景，十二宫杀手是一个冷血的连环杀手，在60年代末至70年代初横行加利福尼亚，因向当局发送加密信息而闻名。他的第一个密码很早就被解密了，但是臭名昭著的340密码一直是个谜(准确的说是51年)。迄今...12月5日，被破译的十二宫杀手信息被一小群公民送到了联邦调查局。想知道他们是如何破解的，请看这个:</p><figure class="ml mm mn mo gt is"><div class="bz fp l di"><div class="mp mq l"/></div><figcaption class="iv iw gj gh gi ix iy bd b be z dk translated">解密的</figcaption></figure><h1 id="3c2c" class="oj nh jb bd ni ok ol om nl on oo op no kq oq kr nr kt or ku nu kw os kx nx ot bi translated">PyTorch闪电|分片训练</h1><p id="0b11" class="pw-post-body-paragraph lg lh jb li b lj ny kl ll lm nz ko lo lp oa lr ls lt ob lv lw lx oc lz ma mb ij bi translated">你现在可以通过给你的闪电训练器增加一面旗帜来节省大量的内存。PyTorch Lightning现在在其库中为那些希望在多个GPU上共享培训工作的人提供了这一功能。它们包括一个易于使用的用于训练语言模型的样本(顺便说一句，从NVIDIAs NeMo library，你可以在<a class="ae ou" href="https://notebooks.quantumstat.com/" rel="noopener ugc nofollow" target="_blank">超级骗子NLP Repo </a>上找到几个笔记本😁)在WikiText数据集上。</p><figure class="ml mm mn mo gt is gh gi paragraph-image"><div role="button" tabindex="0" class="oe of di og bf oh"><div class="gh gi ov"><img src="../Images/8b95629f8e7f5d99aadef32e6f632a23.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*yom7F4m8FrMSLewU.gif"/></div></div></figure><div class="ip iq gp gr ir mr"><a href="https://seannaren.medium.com/introducing-pytorch-lightning-sharded-train-sota-models-with-half-the-memory-7bcc8b4484f2" rel="noopener follow" target="_blank"><div class="ms ab fo"><div class="mt ab mu cl cj mv"><h2 class="bd jl gy z fp mw fr fs mx fu fw jk bi translated">介绍PyTorch闪电碎片:火车SOTA模型，一半的内存</h2><div class="my l"><h3 class="bd b gy z fp mw fr fs mx fu fw dk translated">Lightning 1.1揭示了分片训练-在多个GPU上训练深度学习模型，节省了50%以上的内存，而没有…</h3></div><div class="mz l"><p class="bd b dl z fp mw fr fs mx fu fw dk translated">seannaren.medium.com</p></div></div><div class="na l"><div class="ow l nc nd ne na nf it mr"/></div></div></a></div><p id="d5d4" class="pw-post-body-paragraph lg lh jb li b lj lk kl ll lm ln ko lo lp lq lr ls lt lu lv lw lx ly lz ma mb ij bi translated">如果您想要Lightning的技术内容和更多模型并行性:</p><div class="ip iq gp gr ir mr"><a href="https://pytorch-lightning.readthedocs.io/en/stable/multi_gpu.html#model-parallelism-beta" rel="noopener  ugc nofollow" target="_blank"><div class="ms ab fo"><div class="mt ab mu cl cj mv"><h2 class="bd jl gy z fp mw fr fs mx fu fw jk bi translated">多GPU培训- PyTorch Lightning 1.1.0文档</h2><div class="my l"><h3 class="bd b gy z fp mw fr fs mx fu fw dk translated">为了在不改变代码的情况下在CPU/GPU/TPU上进行训练，我们需要建立一些好习惯:)删除任何对。cuda()…</h3></div><div class="mz l"><p class="bd b dl z fp mw fr fs mx fu fw dk translated">py torch-lightning . readthedocs . io</p></div></div></div></a></div><h1 id="a653" class="oj nh jb bd ni ok ol om nl on oo op no kq oq kr nr kt or ku nu kw os kx nx ot bi translated">斜坡和期望的故事</h1><p id="bb72" class="pw-post-body-paragraph lg lh jb li b lj ny kl ll lm nz ko lo lp oa lr ls lt ob lv lw lx oc lz ma mb ij bi translated">在阅读NeurIPS merch时发现了这个伟大的资源。它包括视频和幻灯片，都是关于机器学习的数学知识。</p><ol class=""><li id="5361" class="ox oy jb li b lj lk lm ln lp oz lt pa lx pb mb pc pd pe pf bi translated">概述<a class="ae ou" href="https://youtu.be/k42AKAlGQAA" rel="noopener ugc nofollow" target="_blank">视频</a></li><li id="262a" class="ox oy jb li b lj pg lm ph lp pi lt pj lx pk mb pc pd pe pf bi translated">整合简介<a class="ae ou" href="https://youtu.be/Z14sGSf_QSA" rel="noopener ugc nofollow" target="_blank">视频</a> <a class="ae ou" href="https://mml-book.github.io/neurips2020/02-integration.pdf" rel="noopener ugc nofollow" target="_blank">幻灯片</a></li><li id="9a3d" class="ox oy jb li b lj pg lm ph lp pi lt pj lx pk mb pc pd pe pf bi translated">数值积分<a class="ae ou" href="https://youtu.be/VTu4dJIIidU" rel="noopener ugc nofollow" target="_blank">视频</a>T8】幻灯片</li><li id="53d8" class="ox oy jb li b lj pg lm ph lp pi lt pj lx pk mb pc pd pe pf bi translated">蒙特卡罗积分<a class="ae ou" href="https://youtu.be/SErqkJqO2fI" rel="noopener ugc nofollow" target="_blank">视频</a> <a class="ae ou" href="https://mml-book.github.io/neurips2020/04-monte-carlo.pdf" rel="noopener ugc nofollow" target="_blank">幻灯片</a></li><li id="8f9e" class="ox oy jb li b lj pg lm ph lp pi lt pj lx pk mb pc pd pe pf bi translated">标准化流程<a class="ae ou" href="https://youtu.be/7TOvhz93G9o" rel="noopener ugc nofollow" target="_blank">视频</a> <a class="ae ou" href="https://mml-book.github.io/neurips2020/05-normalizing-flows.pdf" rel="noopener ugc nofollow" target="_blank">幻灯片</a></li><li id="6daa" class="ox oy jb li b lj pg lm ph lp pi lt pj lx pk mb pc pd pe pf bi translated">时间序列中的推论<a class="ae ou" href="https://youtu.be/N4AgbWrJHc4" rel="noopener ugc nofollow" target="_blank">视频</a> <a class="ae ou" href="https://mml-book.github.io/neurips2020/06-time-series.pdf" rel="noopener ugc nofollow" target="_blank">幻灯片</a></li><li id="a969" class="ox oy jb li b lj pg lm ph lp pi lt pj lx pk mb pc pd pe pf bi translated">反向传播和自动微分<a class="ae ou" href="https://youtu.be/ZUpEm8iJUbE" rel="noopener ugc nofollow" target="_blank">视频</a>幻灯片<a class="ae ou" href="https://mml-book.github.io/neurips2020/07-autodiff.pdf" rel="noopener ugc nofollow" target="_blank">幻灯片</a></li><li id="63c9" class="ox oy jb li b lj pg lm ph lp pi lt pj lx pk mb pc pd pe pf bi translated">向前向后算法<a class="ae ou" href="https://youtu.be/ujIbJp9uxRk" rel="noopener ugc nofollow" target="_blank">视频</a> <a class="ae ou" href="https://mml-book.github.io/neurips2020/08-forward-backward.pdf" rel="noopener ugc nofollow" target="_blank">幻灯片</a></li><li id="7ebc" class="ox oy jb li b lj pg lm ph lp pi lt pj lx pk mb pc pd pe pf bi translated">隐函数定理<a class="ae ou" href="https://youtu.be/3gcGvsbkijk" rel="noopener ugc nofollow" target="_blank">视频</a> <a class="ae ou" href="https://mml-book.github.io/neurips2020/09-implicit-diff.pdf" rel="noopener ugc nofollow" target="_blank">幻灯片</a></li><li id="c45f" class="ox oy jb li b lj pg lm ph lp pi lt pj lx pk mb pc pd pe pf bi translated">邻接<a class="ae ou" href="https://youtu.be/jgcQHLKh55c" rel="noopener ugc nofollow" target="_blank">视频</a>幻灯片<a class="ae ou" href="https://mml-book.github.io/neurips2020/10-adjoint.pdf" rel="noopener ugc nofollow" target="_blank">的方法</a></li><li id="57f2" class="ox oy jb li b lj pg lm ph lp pi lt pj lx pk mb pc pd pe pf bi translated">拉格朗日法<a class="ae ou" href="https://youtu.be/rTFWxoa3u-8" rel="noopener ugc nofollow" target="_blank">视频</a>幻灯片<a class="ae ou" href="https://mml-book.github.io/neurips2020/11-lagrange.pdf" rel="noopener ugc nofollow" target="_blank">幻灯片</a></li><li id="f4c2" class="ox oy jb li b lj pg lm ph lp pi lt pj lx pk mb pc pd pe pf bi translated">随机梯度估计器<a class="ae ou" href="https://youtu.be/7wdIu2dNpY8" rel="noopener ugc nofollow" target="_blank">视频</a> <a class="ae ou" href="https://mml-book.github.io/neurips2020/12-stochastic-gradient.pdf" rel="noopener ugc nofollow" target="_blank">幻灯片</a></li></ol><div class="ip iq gp gr ir mr"><a href="https://mml-book.github.io/slopes-expectations.html" rel="noopener  ugc nofollow" target="_blank"><div class="ms ab fo"><div class="mt ab mu cl cj mv"><h2 class="bd jl gy z fp mw fr fs mx fu fw jk bi translated">去而复返:斜坡和期望的故事</h2><div class="my l"><h3 class="bd b gy z fp mw fr fs mx fu fw dk translated">《机器学习的数学》一书的配套网页。版权所有2020年由马克彼得戴森罗斯，奥尔多…</h3></div><div class="mz l"><p class="bd b dl z fp mw fr fs mx fu fw dk translated">mml-book.github.io</p></div></div></div></a></div><h1 id="3657" class="oj nh jb bd ni ok ol om nl on oo op no kq oq kr nr kt or ku nu kw os kx nx ot bi translated">MPNet</h1><p id="6212" class="pw-post-body-paragraph lg lh jb li b lj ny kl ll lm nz ko lo lp oa lr ls lt ob lv lw lx oc lz ma mb ij bi translated">一个新的微软预训练模型MPNet，来自NeurIPS，结合了屏蔽语言建模(又名BERT风格)MLM和置换语言建模PLM(又名XLNET风格)的优点。他们的GitHub还包括用于预训练和下游任务的脚本，如SQuAD和Glue benchmark。他们的博客文章提供了一些关于培训目标和基准相对于其他模型的优缺点的背景。(在HF的模型轮毂上也可以找到)</p><div class="ip iq gp gr ir mr"><a href="https://www.microsoft.com/en-us/research/blog/mpnet-combines-strengths-of-masked-and-permuted-language-modeling-for-language-understanding/?OCID=msr_blog_MPNet_NeurIPS_tw" rel="noopener  ugc nofollow" target="_blank"><div class="ms ab fo"><div class="mt ab mu cl cj mv"><h2 class="bd jl gy z fp mw fr fs mx fu fw jk bi translated">MPNet结合了屏蔽和置换语言建模的优势，用于语言理解…</h2><div class="my l"><h3 class="bd b gy z fp mw fr fs mx fu fw dk translated">预训练语言模型一直是自然语言处理领域的研究热点。这些模型，如伯特…</h3></div><div class="mz l"><p class="bd b dl z fp mw fr fs mx fu fw dk translated">www.microsoft.com</p></div></div><div class="na l"><div class="pl l nc nd ne na nf it mr"/></div></div></a></div><h1 id="6a0b" class="oj nh jb bd ni ok ol om nl on oo op no kq oq kr nr kt or ku nu kw os kx nx ot bi translated">图形挖掘| NeurIPS</h1><p id="0127" class="pw-post-body-paragraph lg lh jb li b lj ny kl ll lm nz ko lo lp oa lr ls lt ob lv lw lx oc lz ma mb ij bi translated">16个视频讲座，来自NeurIPS的Google w/r/t图形挖掘🔥🔥</p><blockquote class="pm pn po"><p id="9d78" class="lg lh pp li b lj lk kl ll lm ln ko lo pq lq lr ls pr lu lv lw ps ly lz ma mb ij bi translated">他们强调了基于图的学习和图算法在广泛领域的应用，如检测欺诈和滥用、查询聚类和重复检测、图像和多模态数据分析、尊重隐私的数据挖掘和推荐以及干扰下的实验设计。</p></blockquote><div class="ip iq gp gr ir mr"><a href="https://gm-neurips-2020.github.io/" rel="noopener  ugc nofollow" target="_blank"><div class="ms ab fo"><div class="mt ab mu cl cj mv"><h2 class="bd jl gy z fp mw fr fs mx fu fw jk bi translated">图形挖掘@ NeurIPS</h2><div class="my l"><h3 class="bd b gy z fp mw fr fs mx fu fw dk translated">谷歌的图形挖掘团队很高兴能够出席2020年NeurIPS大会。请在星期天加入我们…</h3></div><div class="mz l"><p class="bd b dl z fp mw fr fs mx fu fw dk translated">gm-neurips-2020.github.io</p></div></div><div class="na l"><div class="pt l nc nd ne na nf it mr"/></div></div></a></div><h1 id="3cfa" class="oj nh jb bd ni ok ol om nl on oo op no kq oq kr nr kt or ku nu kw os kx nx ot bi translated">回购密码👨‍💻</h1><h2 id="a256" class="ng nh jb bd ni nj nk dn nl nm nn dp no lp np nq nr lt ns nt nu lx nv nw nx jh bi translated">一组最近发布的回购文件引起了我们的关注👁</h2></div><div class="ab cl kz la hu lb" role="separator"><span class="lc bw bk ld le lf"/><span class="lc bw bk ld le lf"/><span class="lc bw bk ld le"/></div><div class="ij ik il im in"><h2 id="9543" class="ng nh jb bd ni nj nk dn nl nm nn dp no lp np nq nr lt ns nt nu lx nv nw nx jh bi translated">CTRLSum</h2><blockquote class="pm pn po"><p id="4d21" class="lg lh pp li b lj lk kl ll lm ln ko lo pq lq lr ls pr lu lv lw ps ly lz ma mb ij bi translated">CTRLSum是一个通用的可控摘要系统，用于在给定关键字或前缀形式的控制标记的情况下处理文本摘要。</p></blockquote><p id="78ef" class="pw-post-body-paragraph lg lh jb li b lj lk kl ll lm ln ko lo lp lq lr ls lt lu lv lw lx ly lz ma mb ij bi translated">您还可以生成现成的文本，它们还包括培训/评估脚本。</p><div class="ip iq gp gr ir mr"><a href="https://github.com/salesforce/ctrl-sum" rel="noopener  ugc nofollow" target="_blank"><div class="ms ab fo"><div class="mt ab mu cl cj mv"><h2 class="bd jl gy z fp mw fr fs mx fu fw jk bi translated">销售力量/控制-总和</h2><div class="my l"><h3 class="bd b gy z fp mw fr fs mx fu fw dk translated">这是PyTorch实现的论文:CTRLsum:走向通用可控的文本摘要</h3></div><div class="mz l"><p class="bd b dl z fp mw fr fs mx fu fw dk translated">github.com</p></div></div><div class="na l"><div class="pu l nc nd ne na nf it mr"/></div></div></a></div><h2 id="e335" class="ng nh jb bd ni nj nk dn nl nm nn dp no lp np nq nr lt ns nt nu lx nv nw nx jh bi translated">局部变化</h2><blockquote class="pm pn po"><p id="f094" class="lg lh pp li b lj lk kl ll lm ln ko lo pq lq lr ls pr lu lv lw ps ly lz ma mb ij bi translated">使用转换器通过服务条款(ToS)数据集进行主题变化检测。</p></blockquote><p id="e38d" class="pw-post-body-paragraph lg lh jb li b lj lk kl ll lm ln ko lo lp lq lr ls lt lu lv lw lx ly lz ma mb ij bi translated">这个回购中描述的“话题改变”是在段落层面，而不是句子层面。</p><div class="ip iq gp gr ir mr"><a href="https://github.com/dennlinger/TopicalChange" rel="noopener  ugc nofollow" target="_blank"><div class="ms ab fo"><div class="mt ab mu cl cj mv"><h2 class="bd jl gy z fp mw fr fs mx fu fw jk bi translated">丹林格/话题变化</h2><div class="my l"><h3 class="bd b gy z fp mw fr fs mx fu fw dk translated">Dennis Aumiller*、Satya Almasian*、Sebastian Lackner和Michael Gertz *此存储库包含…</h3></div><div class="mz l"><p class="bd b dl z fp mw fr fs mx fu fw dk translated">github.com</p></div></div><div class="na l"><div class="pv l nc nd ne na nf it mr"/></div></div></a></div><h2 id="2316" class="ng nh jb bd ni nj nk dn nl nm nn dp no lp np nq nr lt ns nt nu lx nv nw nx jh bi translated">UBAR</h2><p id="00bd" class="pw-post-body-paragraph lg lh jb li b lj ny kl ll lm nz ko lo lp oa lr ls lt ob lv lw lx oc lz ma mb ij bi translated">针对目标导向对话任务的GPT-2培训报告。在报告中提到的论文中，它在MultiWoz 2.0数据集上针对响应生成、策略优化(act和响应生成)、端到端建模(信念状态、act和响应生成)和对话状态跟踪进行了基准测试。</p><div class="ip iq gp gr ir mr"><a href="https://github.com/TonyNemo/UBAR-MultiWOZ" rel="noopener  ugc nofollow" target="_blank"><div class="ms ab fo"><div class="mt ab mu cl cj mv"><h2 class="bd jl gy z fp mw fr fs mx fu fw jk bi translated">托尼内莫/UBAR-穆蒂沃兹</h2><div class="my l"><h3 class="bd b gy z fp mw fr fs mx fu fw dk translated">这是AAAI 2021论文“UBAR:实现完全端到端的面向任务的对话系统…</h3></div><div class="mz l"><p class="bd b dl z fp mw fr fs mx fu fw dk translated">github.com</p></div></div><div class="na l"><div class="pw l nc nd ne na nf it mr"/></div></div></a></div><h2 id="3174" class="ng nh jb bd ni nj nk dn nl nm nn dp no lp np nq nr lt ns nt nu lx nv nw nx jh bi translated">知识图增强的关系抽取</h2><blockquote class="pm pn po"><p id="8826" class="lg lh pp li b lj lk kl ll lm ln ko lo pq lq lr ls pr lu lv lw ps ly lz ma mb ij bi translated">通过联合训练关系提取和知识图链接预测任务来提高关系提取模型的性能。</p></blockquote><p id="a0f1" class="pw-post-body-paragraph lg lh jb li b lj lk kl ll lm ln ko lo lp lq lr ls lt lu lv lw lx ly lz ma mb ij bi translated">培训脚本包括:</p><div class="ip iq gp gr ir mr"><a href="https://github.com/gstoica27/JRRELP" rel="noopener  ugc nofollow" target="_blank"><div class="ms ab fo"><div class="mt ab mu cl cj mv"><h2 class="bd jl gy z fp mw fr fs mx fu fw jk bi translated">gstoica27/JRRELP</h2><div class="my l"><h3 class="bd b gy z fp mw fr fs mx fu fw dk translated">知识图增强的关系提取乔治·斯托伊察、埃马努埃尔·安东尼奥斯·普拉塔尼奥斯和巴纳巴斯·波佐斯·奈瑞普斯…</h3></div><div class="mz l"><p class="bd b dl z fp mw fr fs mx fu fw dk translated">github.com</p></div></div><div class="na l"><div class="px l nc nd ne na nf it mr"/></div></div></a></div><h1 id="2eb1" class="oj nh jb bd ni ok ol om nl on oo op no kq oq kr nr kt or ku nu kw os kx nx ot bi translated">本周数据集:克罗斯纳</h1><p id="e3c7" class="pw-post-body-paragraph lg lh jb li b lj ny kl ll lm nz ko lo lp oa lr ls lt ob lv lw lx oc lz ma mb ij bi translated">一个命名实体识别(NER)数据集，涵盖五个不同的领域(政治、自然科学、音乐、文学和人工智能)。</p><h1 id="1396" class="oj nh jb bd ni ok ol om nl on oo op no kq oq kr nr kt or ku nu kw os kx nx ot bi translated">样品</h1><figure class="ml mm mn mo gt is gh gi paragraph-image"><div role="button" tabindex="0" class="oe of di og bf oh"><div class="gh gi py"><img src="../Images/db1e7937513d224369db3a3dd8073ef1.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*rM0LJdLhNR1SL6SV.png"/></div></div></figure><h1 id="c112" class="oj nh jb bd ni ok ol om nl on oo op no kq oq kr nr kt or ku nu kw os kx nx ot bi translated">它在哪里？</h1><div class="ip iq gp gr ir mr"><a href="https://github.com/zliucr/CrossNER" rel="noopener  ugc nofollow" target="_blank"><div class="ms ab fo"><div class="mt ab mu cl cj mv"><h2 class="bd jl gy z fp mw fr fs mx fu fw jk bi translated">zliucr/CrossNER</h2><div class="my l"><h3 class="bd b gy z fp mw fr fs mx fu fw dk translated">克罗斯纳:评估跨域命名实体识别(在AAAI-2021年接受)[PDF]克罗斯纳是一个完全标记…</h3></div><div class="mz l"><p class="bd b dl z fp mw fr fs mx fu fw dk translated">github.com</p></div></div><div class="na l"><div class="pz l nc nd ne na nf it mr"/></div></div></a></div></div><div class="ab cl kz la hu lb" role="separator"><span class="lc bw bk ld le lf"/><span class="lc bw bk ld le lf"/><span class="lc bw bk ld le"/></div><div class="ij ik il im in"><blockquote class="qa"><p id="f8ac" class="qb qc jb bd qd qe qf qg qh qi qj mb dk translated">每周日，我们都会对来自世界各地研究人员的NLP新闻和代码进行一次每周综述。</p><p id="ae89" class="qb qc jb bd qd qe qf qg qh qi qj mb dk translated">如需完整报道，请关注我们的Twitter: <a class="ae ou" href="http://twitter.com/Quantum_Stat" rel="noopener ugc nofollow" target="_blank"> @Quantum_Stat </a></p></blockquote><figure class="ql qm qn qo qp is gh gi paragraph-image"><div class="gh gi qk"><img src="../Images/57b723ac2e55f809c5d41ff2bf260783.png" data-original-src="https://miro.medium.com/v2/resize:fit:108/0*EcgP3TbUXhk2J3f4"/></div><figcaption class="iv iw gj gh gi ix iy bd b be z dk translated"><a class="ae ou" href="https://quantumstat.com" rel="noopener ugc nofollow" target="_blank">量子统计</a></figcaption></figure></div></div>    
</body>
</html>