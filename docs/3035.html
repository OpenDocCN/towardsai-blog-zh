<html>
<head>
<title>Using AI to Implement Vector-Based Technology in Topic Modeling</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">用人工智能实现基于向量的主题建模技术</h1>
<blockquote>原文：<a href="https://pub.towardsai.net/using-ai-to-implement-vector-based-technology-in-topic-modeling-9bed21ed3432?source=collection_archive---------1-----------------------#2022-08-11">https://pub.towardsai.net/using-ai-to-implement-vector-based-technology-in-topic-modeling-9bed21ed3432?source=collection_archive---------1-----------------------#2022-08-11</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><h1 id="c1b3" class="jn jo iq bd jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk bi translated">介绍</h1><p id="5703" class="pw-post-body-paragraph kl km iq kn b ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li ij bi translated">在这篇文章中，我们将分析我们从Twitter上搜集的5万条与Covid相关的推文，使用AI提取世界各地人们争论的主要话题。</p><p id="4163" class="pw-post-body-paragraph kl km iq kn b ko lj kq kr ks lk ku kv kw ll ky kz la lm lc ld le ln lg lh li ij bi translated">对于如此大量的非结构化数据，我们需要数周时间来读取和分类您的数据。然而，如果我们正确地知道如何使用最先进的NLP模型，这个庞大的任务可能是小菜一碟。</p><p id="1d8d" class="pw-post-body-paragraph kl km iq kn b ko lj kq kr ks lk ku kv kw ll ky kz la lm lc ld le ln lg lh li ij bi translated">为了完成这项任务，我们将使用称为<strong class="kn ir">编码器</strong>的模型，以及一种允许我们以自动方式将相似主题分组在一起的方法，称为<strong class="kn ir">主题建模</strong>。</p><h1 id="fe58" class="jn jo iq bd jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk bi translated"><strong class="ak">文本编码</strong></h1><p id="2d3a" class="pw-post-body-paragraph kl km iq kn b ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li ij bi translated">在开始直接处理我们的代码之前，我们将首先解释它背后的逻辑。我们将要用来执行这项任务的主要技术叫做编码，或者矢量化。通过使用称为嵌入的模型，我们能够将纯文本转换为属于高维空间(数百维)的几何坐标。</p><figure class="lp lq lr ls gt lt gh gi paragraph-image"><div role="button" tabindex="0" class="lu lv di lw bf lx"><div class="gh gi lo"><img src="../Images/d376769b84ca6bba2853f8480bd4cd44.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*wOTXgnwaRKiXd-WdJgTvtw.png"/></div></div><figcaption class="ma mb gj gh gi mc md bd b be z dk translated">此图片检索自:<a class="ae me" href="https://openai.com/blog/introducing-text-and-code-embeddings/" rel="noopener ugc nofollow" target="_blank">https://open ai . com/blog/introducing-text-and-code-embedding/</a></figcaption></figure><p id="2fe1" class="pw-post-body-paragraph kl km iq kn b ko lj kq kr ks lk ku kv kw ll ky kz la lm lc ld le ln lg lh li ij bi translated">空间中的每个点代表一段文字。编码器的价值在于它可以将具有相似含义的文本放置在更近的空间中。有了这个独特的工具，我们就可以应用机器学习技术将数据分组为共同的趋势。</p><h1 id="e5b3" class="jn jo iq bd jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk bi translated"><strong class="ak">什么是主题建模，为什么重要？</strong></h1><p id="ecf1" class="pw-post-body-paragraph kl km iq kn b ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li ij bi translated">主题建模是一种算法，当应用于纯文本时，能够提取语料库中讨论的主要主题。一旦我们对所有的推文进行了矢量化，并且在我们的高维笛卡尔平面中有50.000个点，我们就可以使用聚类技术对它们进行分组。</p><p id="4eef" class="pw-post-body-paragraph kl km iq kn b ko lj kq kr ks lk ku kv kw ll ky kz la lm lc ld le ln lg lh li ij bi translated">每组点都有相似的含义，因此有相似的主题。我们可以将50，000个样本分成几百个独立的组。通过从每个组中提取最常见的关键字，我们将能够用相应的主题来标记每个单独的组。</p><figure class="lp lq lr ls gt lt gh gi paragraph-image"><div role="button" tabindex="0" class="lu lv di lw bf lx"><div class="gh gi mf"><img src="../Images/2b2e84f686415eaf5087dc8ad55ab0c7.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*udI2_y1tQaRYH7A3.png"/></div></div><figcaption class="ma mb gj gh gi mc md bd b be z dk translated">此图片来自:<a class="ae me" href="https://nkoenig06.github.io/gd-tm-lda.html" rel="noopener ugc nofollow" target="_blank">https://nkoenig06.github.io/gd-tm-lda.html</a></figcaption></figure><h1 id="fa97" class="jn jo iq bd jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk bi translated"><strong class="ak">手头上！</strong>在这个项目中，我们要涵盖4个部分:</h1><ol class=""><li id="e46e" class="mg mh iq kn b ko kp ks kt kw mi la mj le mk li ml mm mn mo bi translated"><strong class="kn ir">网页抓取:</strong></li></ol><p id="d20d" class="pw-post-body-paragraph kl km iq kn b ko lj kq kr ks lk ku kv kw ll ky kz la lm lc ld le ln lg lh li ij bi translated">我们将首先在6个月内收集5万条关于新冠肺炎疫苗接种的推文作为样本语料。我们将使用的Python库叫做<code class="fe mp mq mr ms b">snscrape</code>。</p><p id="126a" class="pw-post-body-paragraph kl km iq kn b ko lj kq kr ks lk ku kv kw ll ky kz la lm lc ld le ln lg lh li ij bi translated">仅供参考:<a class="ae me" href="https://github.com/JustAnotherArchivist/snscrape" rel="noopener ugc nofollow" target="_blank">https://github.com/JustAnotherArchivist/snscrape</a></p><figure class="lp lq lr ls gt lt"><div class="bz fp l di"><div class="mt mu l"/></div></figure><figure class="lp lq lr ls gt lt gh gi paragraph-image"><div class="gh gi mv"><img src="../Images/9ac9776843ddf875dbdda31b893236cd.png" data-original-src="https://miro.medium.com/v2/resize:fit:1290/format:webp/1*B3QWg3uTEQHpJ6YYXlIvmA.png"/></div><figcaption class="ma mb gj gh gi mc md bd b be z dk translated">scraper.py的输出</figcaption></figure><p id="c92f" class="pw-post-body-paragraph kl km iq kn b ko lj kq kr ks lk ku kv kw ll ky kz la lm lc ld le ln lg lh li ij bi translated">在这个样本语料库中，我们只保存了两条信息:发布推文的时间和推文的文本。</p><p id="5494" class="pw-post-body-paragraph kl km iq kn b ko lj kq kr ks lk ku kv kw ll ky kz la lm lc ld le ln lg lh li ij bi translated"><strong class="kn ir"> 2。编码:</strong></p><p id="5588" class="pw-post-body-paragraph kl km iq kn b ko lj kq kr ks lk ku kv kw ll ky kz la lm lc ld le ln lg lh li ij bi translated">现在我们继续这个项目的亮点！我们也可以称这部分为编码，因为我们将文本数据转换为数字数据。我们将使用的Python库叫做<code class="fe mp mq mr ms b">SentenceTransformer</code>，它可以帮助我们实现几个预先训练好的编码模型。我们使用的来自<code class="fe mp mq mr ms b">SentenceTransformer</code>的预训练模型是<code class="fe mp mq mr ms b">all-MiniLM-L6-v2</code>，它将为每条推文创建768个维度。这个模型是健壮和快速的。要查看关于<code class="fe mp mq mr ms b">SentenceTransformer</code>预训练模型的更多详情，请查看<a class="ae me" href="https://www.sbert.net/docs/pretrained_models.html" rel="noopener ugc nofollow" target="_blank">https://www.sbert.net/docs/pretrained_models.html</a>了解更多信息。</p><p id="3155" class="pw-post-body-paragraph kl km iq kn b ko lj kq kr ks lk ku kv kw ll ky kz la lm lc ld le ln lg lh li ij bi translated">注意:不要忘记添加一个额外的列来存储数据集的文本向量。</p><figure class="lp lq lr ls gt lt"><div class="bz fp l di"><div class="mt mu l"/></div></figure><figure class="lp lq lr ls gt lt gh gi paragraph-image"><div role="button" tabindex="0" class="lu lv di lw bf lx"><div class="gh gi mw"><img src="../Images/ba05ed76cabed6d4df1e67579fff56bf.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*66m8NF7kL3oc8KQonVmgsA.png"/></div></div><figcaption class="ma mb gj gh gi mc md bd b be z dk translated">encoder.py的输出</figcaption></figure><p id="9508" class="pw-post-body-paragraph kl km iq kn b ko lj kq kr ks lk ku kv kw ll ky kz la lm lc ld le ln lg lh li ij bi translated"><strong class="kn ir"> 3。聚类:</strong></p><p id="7521" class="pw-post-body-paragraph kl km iq kn b ko lj kq kr ks lk ku kv kw ll ky kz la lm lc ld le ln lg lh li ij bi translated">您可能已经熟悉了集群。我们将从scikit-learn Python库中导入<code class="fe mp mq mr ms b">KMeans</code>。然后我们可以定义我们的语料库需要多少个聚类。根据经验，在超过10，000个样本的情况下，我们将把数据分成200个组。</p><figure class="lp lq lr ls gt lt"><div class="bz fp l di"><div class="mt mu l"/></div></figure><figure class="lp lq lr ls gt lt gh gi paragraph-image"><div role="button" tabindex="0" class="lu lv di lw bf lx"><div class="gh gi mx"><img src="../Images/edde8c7fdfc68479a3f43ea95691848c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*zBXh51myRRs_nu4AvuPY9w.png"/></div></div><figcaption class="ma mb gj gh gi mc md bd b be z dk translated">clustering.py的输出</figcaption></figure><p id="d831" class="pw-post-body-paragraph kl km iq kn b ko lj kq kr ks lk ku kv kw ll ky kz la lm lc ld le ln lg lh li ij bi translated"><strong class="kn ir"> 4。可视化:</strong></p><p id="54e3" class="pw-post-body-paragraph kl km iq kn b ko lj kq kr ks lk ku kv kw ll ky kz la lm lc ld le ln lg lh li ij bi translated">一旦我们完成了数据聚类。我们希望将结果可视化，并看看我们的聚类模型如何将推文分组到不同的主题中。然而，我们必须将可视化之前的维度从768维减少到2维，这样我们就可以理解我们作为人类<strong class="kn ir"> s </strong>的聚类的可视化。我们用于降维的降维算法是<code class="fe mp mq mr ms b">umap</code>。</p><p id="8168" class="pw-post-body-paragraph kl km iq kn b ko lj kq kr ks lk ku kv kw ll ky kz la lm lc ld le ln lg lh li ij bi translated">仅供参考:<a class="ae me" href="https://umap-learn.readthedocs.io/en/latest/" rel="noopener ugc nofollow" target="_blank">https://umap-learn.readthedocs.io/en/latest/</a></p><p id="f668" class="pw-post-body-paragraph kl km iq kn b ko lj kq kr ks lk ku kv kw ll ky kz la lm lc ld le ln lg lh li ij bi translated">下面是我们如何通过使用<code class="fe mp mq mr ms b">matplotlib.plotly</code> <strong class="kn ir">生成一个二维彩色图来可视化我们的聚类。</strong></p><p id="5660" class="pw-post-body-paragraph kl km iq kn b ko lj kq kr ks lk ku kv kw ll ky kz la lm lc ld le ln lg lh li ij bi translated">参考消息:<a class="ae me" href="https://www.activestate.com/blog/plotting-data-in-python-matplotlib-vs-plotly/" rel="noopener ugc nofollow" target="_blank">https://www . active state . com/blog/plotting-data-in-python-matplotlib-vs-plotly/</a></p><figure class="lp lq lr ls gt lt"><div class="bz fp l di"><div class="mt mu l"/></div></figure><figure class="lp lq lr ls gt lt gh gi paragraph-image"><div role="button" tabindex="0" class="lu lv di lw bf lx"><div class="gh gi my"><img src="../Images/8e14e7efd9efeb4f2e28fc3eadea57a9.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*7wiBlQUqaQ5mO3D4.gif"/></div></div><figcaption class="ma mb gj gh gi mc md bd b be z dk translated">visualization.py的输出</figcaption></figure><p id="ea52" class="pw-post-body-paragraph kl km iq kn b ko lj kq kr ks lk ku kv kw ll ky kz la lm lc ld le ln lg lh li ij bi translated">正如你在我们漂亮的图表中看到的，我们的5万条推文在一个二维平面上用200种颜色分成200组。该图将使用相同的颜色表示同一主题下的推文。</p><h1 id="f0e8" class="jn jo iq bd jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk bi translated"><strong class="ak">结论</strong></h1><p id="0676" class="pw-post-body-paragraph kl km iq kn b ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li ij bi translated">由于我们通过扫描文本中的相似性、词的频率和模式对语料库进行了聚类，因此我们可以很容易地理解当人们讨论新冠肺炎疫苗接种时最流行的趋势是什么。使用该算法可以提取的见解将证明对公共卫生行业和需要持续监控数据的政府是有价值的。</p></div></div>    
</body>
</html>