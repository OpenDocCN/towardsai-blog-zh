<html>
<head>
<title>The SimCLRv2 Framework</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">SimCLRv2框架</h1>
<blockquote>原文：<a href="https://pub.towardsai.net/the-simclrv2-framework-6de26606b7ef?source=collection_archive---------0-----------------------#2020-09-13">https://pub.towardsai.net/the-simclrv2-framework-6de26606b7ef?source=collection_archive---------0-----------------------#2020-09-13</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><h2 id="b697" class="ir is it bd b dl iu iv iw ix iy iz dk ja translated" aria-label="kicker paragraph"><a class="ae ep" href="https://towardsai.net/p/category/machine-learning" rel="noopener ugc nofollow" target="_blank">机器学习</a></h2><div class=""/><div class=""><h2 id="6132" class="pw-subtitle-paragraph jz jc it bd b ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq dk translated">一个巨大的自我学习算法通常表现得更好…</h2></div><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div class="gh gi kr"><img src="../Images/2d4f3eeac08a2ec47ed877f7cb29c815.png" data-original-src="https://miro.medium.com/v2/resize:fit:1000/format:webp/1*uJNFn4zT3U3wNZqFsQgoiA.jpeg"/></div><figcaption class="kz la gj gh gi lb lc bd b be z dk translated"><a class="ae ld" href="https://ai.googleblog.com/2020/04/advancing-self-supervised-and-semi.html" rel="noopener ugc nofollow" target="_blank"> Img_Credit </a></figcaption></figure><blockquote class="le"><p id="8529" class="lf lg it bd lh li lj lk ll lm ln lo dk translated">巨大的自我监督模型是强有力的半监督学习器..</p></blockquote><h1 id="5778" class="lp lq it bd lr ls lt lu lv lw lx ly lz ki ma kj mb kl mc km md ko me kp mf mg bi translated">目录:</h1><ol class=""><li id="c12e" class="mh mi it mj b mk ml mm mn mo mp mq mr ms mt lo mu mv mw mx bi translated">介绍</li><li id="5e3b" class="mh mi it mj b mk my mm mz mo na mq nb ms nc lo mu mv mw mx bi translated">关键洞察力</li><li id="0ebb" class="mh mi it mj b mk my mm mz mo na mq nb ms nc lo mu mv mw mx bi translated">结果</li><li id="082d" class="mh mi it mj b mk my mm mz mo na mq nb ms nc lo mu mv mw mx bi translated">为什么它很重要</li><li id="1e29" class="mh mi it mj b mk my mm mz mo na mq nb ms nc lo mu mv mw mx bi translated">我在想</li></ol><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="ne nf di ng bf nh"><div class="gh gi nd"><img src="../Images/d13a4a0e5550026568eae64fd443bb06.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*W4Ke7V-irmxrW9lIAuzWaw.jpeg"/></div></div><figcaption class="kz la gj gh gi lb lc bd b be z dk translated">计算机视觉的时代即将来临……|<a class="ae ld" href="https://www.iotforall.com/wp-content/uploads/2017/08/08.17-Computer-Vision.jpg" rel="noopener ugc nofollow" target="_blank">Img _ Credit</a></figcaption></figure><h1 id="5171" class="lp lq it bd lr ls lt lu lv lw lx ly lz ki ni kj mb kl nj km md ko nk kp mf mg bi translated"><strong class="ak">简介:</strong></h1><p id="0297" class="pw-post-body-paragraph nl nm it mj b mk ml kd nn mm mn kg no mo np nq nr mq ns nt nu ms nv nw nx lo im bi translated">计算机视觉中长期存在的问题可能即将结束，在这个问题上，模型发现在利用大量未标记数据进行训练的同时，很难在少数有标记的例子上进行学习。</p><p id="e91a" class="pw-post-body-paragraph nl nm it mj b mk ny kd nn mm nz kg no mo oa nq nr mq ob nt nu ms oc nw nx lo im bi translated"><strong class="mj jd">sim clr框架</strong> <br/>谷歌研究院的研究人员，由杰弗里·辛顿、陈婷和其他几个人组成的大脑团队构建了<a class="ae ld" href="https://github.com/google-research/simclr" rel="noopener ugc nofollow" target="_blank"> <strong class="mj jd"> <em class="od"> SimCLR框架</em> </strong> </a>。SimCLR是视觉表征对比学习的简单框架。SimCLR首先在未标记的数据集上学习图像的一般表示，然后可以使用少量标记的图像进行微调，以实现给定分类任务的良好性能。</p><p id="54bb" class="pw-post-body-paragraph nl nm it mj b mk ny kd nn mm nz kg no mo oa nq nr mq ob nt nu ms oc nw nx lo im bi translated">遵循被称为<a class="ae ld" href="https://ankeshanand.com/blog/2020/01/26/contrative-self-supervised-learning.html" rel="noopener ugc nofollow" target="_blank"> <strong class="mj jd"> <em class="od">对比学习</em> </strong> </a> <em class="od">的方法，通过同时最大化同一图像的不同变换视图之间的一致性和最小化不同图像的变换视图之间的一致性来学习通用表示。</em>使用该对比目标更新神经网络的参数使得对应视图的表示彼此“吸引”,而不对应视图的表示彼此“排斥”。</p><p id="6bbe" class="pw-post-body-paragraph nl nm it mj b mk ny kd nn mm nz kg no mo oa nq nr mq ob nt nu ms oc nw nx lo im bi translated">之后，SimCLR使用<a class="ae ld" href="https://en.wikipedia.org/wiki/Convolutional_neural_network#Fully_connected" rel="noopener ugc nofollow" target="_blank">全连接网络</a>(即<a class="ae ld" href="https://en.wikipedia.org/wiki/Multilayer_perceptron" rel="noopener ugc nofollow" target="_blank"> MLP </a>)计算图像表示的非线性投影(<strong class="mj jd">投影头</strong>)，这放大了不变特征并最大化了网络识别同一图像的不同变换的能力</p><p id="0202" class="pw-post-body-paragraph nl nm it mj b mk ny kd nn mm nz kg no mo oa nq nr mq ob nt nu ms oc nw nx lo im bi translated"><strong class="mj jd">simclrv 2框架的新特性:</strong></p><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="ne nf di ng bf nh"><div class="gh gi oe"><img src="../Images/b52424e2b70876a2f5bd931ec3385f08.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Co4X6v8d2i0w0e7VMhLYOQ.jpeg"/></div></div><figcaption class="kz la gj gh gi lb lc bd b be z dk translated"><a class="ae ld" href="https://arxiv.org/pdf/2006.10029.pdf" rel="noopener ugc nofollow" target="_blank"> Img_Credit </a></figcaption></figure><p id="6d88" class="pw-post-body-paragraph nl nm it mj b mk ny kd nn mm nz kg no mo oa nq nr mq ob nt nu ms oc nw nx lo im bi translated">在最近一篇题为<a class="ae ld" href="https://arxiv.org/abs/2006.10029" rel="noopener ugc nofollow" target="_blank"> <strong class="mj jd">“大型自我监督模型是强大的半监督学习器”</strong> </a>的论文中，谷歌的这个研究团队提高了最先进的(SOTA)自我监督模型在ImageNet数据集上的性能。这一壮举是使用SimCLRv2框架实现的，该框架由一个更大的自监督ResNet模型组成，构建于早期的SimCLR架构之上。因此，<a class="ae ld" href="https://arxiv.org/pdf/2006.10029.pdf" rel="noopener ugc nofollow" target="_blank"><strong class="mj jd"><em class="od">simclrv 2</em></strong></a>是对SimCLR框架的改进。</p><h1 id="61c4" class="lp lq it bd lr ls lt lu lv lw lx ly lz ki ni kj mb kl nj km md ko nk kp mf mg bi translated"><strong class="ak">关键洞察:</strong></h1><p id="bdc5" class="pw-post-body-paragraph nl nm it mj b mk ml kd nn mm mn kg no mo np nq nr mq ns nt nu ms nv nw nx lo im bi translated">诸如<a class="ae ld" href="https://arxiv.org/abs/1810.04805" rel="noopener ugc nofollow" target="_blank"><strong class="mj jd"><em class="od">BERT</em></strong></a>之类的自然语言处理模型的最新进展表明，在对较小的已标记数据集进行微调之前，可以通过首先对大的未标记数据集进行预训练来获得良好的结果。然而，现有的图像数据自监督方法复杂且难以采用。SimCLRv2倾向于简化和改进这一过程，它增强了早先引入的一种叫做<a class="ae ld" href="https://ankeshanand.com/blog/2020/01/26/contrative-self-supervised-learning.html" rel="noopener ugc nofollow" target="_blank"> <em class="od">对比学习</em> </a>的方法。</p><p id="7d36" class="pw-post-body-paragraph nl nm it mj b mk ny kd nn mm nz kg no mo oa nq nr mq ob nt nu ms oc nw nx lo im bi translated"><strong class="mj jd">工作原理:</strong></p><p id="30cf" class="pw-post-body-paragraph nl nm it mj b mk ny kd nn mm nz kg no mo oa nq nr mq ob nt nu ms oc nw nx lo im bi translated">通过研究SimCLR和SimCLRv2论文，我们发现这两种方法都使用了第一种方法，即在大型未标记数据集上进行自我监督预训练。这有助于模型通过同时最大化同一图像的不同变换视图之间的一致性和最小化不同图像的变换视图之间的一致性来学习数据的一般表示。</p><p id="c50f" class="pw-post-body-paragraph nl nm it mj b mk ny kd nn mm nz kg no mo oa nq nr mq ob nt nu ms oc nw nx lo im bi translated"><strong class="mj jd"> SimCLRv2对SimCLR框架进行了3项新的重大修改，包括:- </strong></p><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div class="gh gi of"><img src="../Images/165828bcb50f2d5c2a59436790cfda14.png" data-original-src="https://miro.medium.com/v2/resize:fit:1214/format:webp/1*RB-vrYfZfWhLOqmUT0SB5A.jpeg"/></div><figcaption class="kz la gj gh gi lb lc bd b be z dk translated">应用随机裁剪加上颜色变形会产生最大的效果…</figcaption></figure><p id="4cd5" class="pw-post-body-paragraph nl nm it mj b mk ny kd nn mm nz kg no mo oa nq nr mq ob nt nu ms oc nw nx lo im bi translated"><strong class="mj jd">第一步:</strong></p><p id="e3e6" class="pw-post-body-paragraph nl nm it mj b mk ny kd nn mm nz kg no mo oa nq nr mq ob nt nu ms oc nw nx lo im bi translated">在自我监督的预训练阶段，每个图像通过随机裁剪、随机颜色失真和高斯模糊进行增强。大小至关重要，因此SimCLRv2使用更深但更窄的<em class="od"> ResNet-152 </em>、<em class="od"> (3x)型号</em>，以及<em class="od">选择性内核(SK) </em>。而SimCLR使用的是<em class="od"> ResNet-50(4x) </em>，型号。</p><p id="22d6" class="pw-post-body-paragraph nl nm it mj b mk ny kd nn mm nz kg no mo oa nq nr mq ob nt nu ms oc nw nx lo im bi translated"><strong class="mj jd">第二步:</strong></p><p id="78ac" class="pw-post-body-paragraph nl nm it mj b mk ny kd nn mm nz kg no mo oa nq nr mq ob nt nu ms oc nw nx lo im bi translated">监督微调是使用几个标记的例子来完成的。SimCLRv2使用一个更宽的非线性投影头(MLP)，集成到基本编码器中。这种方法相当于从投影头的中间层进行微调，而不是像在SimCLR中那样从输入层进行微调。</p><p id="c19a" class="pw-post-body-paragraph nl nm it mj b mk ny kd nn mm nz kg no mo oa nq nr mq ob nt nu ms oc nw nx lo im bi translated"><strong class="mj jd">第三步:</strong></p><p id="7fca" class="pw-post-body-paragraph nl nm it mj b mk ny kd nn mm nz kg no mo oa nq nr mq ob nt nu ms oc nw nx lo im bi translated">再次使用相同的未标记的例子进行自我训练，但是以特定于任务的方式进行。大的、微调的网络被用作教师来估算用于训练学生网络的伪标签。因此，老师可以以最小的准确度损失被<a class="ae ld" href="https://arxiv.org/pdf/2006.10029.pdf" rel="noopener ugc nofollow" target="_blank">提取到一个更小的学生网络</a>中。</p><h1 id="ebfd" class="lp lq it bd lr ls lt lu lv lw lx ly lz ki ni kj mb kl nj km md ko nk kp mf mg bi translated"><strong class="ak">结果</strong>:</h1><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="ne nf di ng bf nh"><div class="gh gi og"><img src="../Images/7168dddc7ef80232b9b424d0df4dab1a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*gfZ66-8cq6PFBuIkHD8NAA.jpeg"/></div></div></figure><ul class=""><li id="6e13" class="mh mi it mj b mk ny mm nz mo oh mq oi ms oj lo ok mv mw mx bi translated">使用<em class="od"> ResNet-50 </em>架构，SimCLRv2在ImageNet数据的1%标签分数上与SimCLR抗衡，实现了73.9%的顶级准确性，比SOTA高53%。</li><li id="78a4" class="mh mi it mj b mk my mm mz mo na mq nb ms nc lo ok mv mw mx bi translated">在10%的标记分数下，SimCLRv2达到了77.5%的顶级准确率，比SOTA高18%。</li><li id="b499" class="mh mi it mj b mk my mm mz mo na mq nb ms nc lo ok mv mw mx bi translated">对于更大的网络，simclrv 2<em class="od">ResNet-152(3x+SK)</em>在1%和10%的标签分数上分别实现了76.6%和80.9%的顶级准确度，比SimCLR <em class="od"> ResNet-50(4x) </em>模型分别高出22%和9%。</li></ul><blockquote class="ol om on"><p id="26f6" class="nl nm od mj b mk ny kd nn mm nz kg no oo oa nq nr op ob nt nu oq oc nw nx lo im bi translated">该论文表明，更大的模型倾向于用更少的标签产生更大的改进，并且倾向于随着模型大小和训练时期的增加而持续改进。</p></blockquote><p id="81a5" class="pw-post-body-paragraph nl nm it mj b mk ny kd nn mm nz kg no mo oa nq nr mq ob nt nu ms oc nw nx lo im bi translated">名为<a class="ae ld" href="https://arxiv.org/abs/2006.10029" rel="noopener ugc nofollow" target="_blank"> <strong class="mj jd">“大的自监督模型是强的半监督学习器”</strong> </a> <strong class="mj jd"> </strong>的论文也展示了以下令人印象深刻的推论…</p><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="ne nf di ng bf nh"><div class="gh gi or"><img src="../Images/70bf7407787b0697782b9db7e48a9dd6.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*nQKrnQYdrYb9lrnfhmk06w.jpeg"/></div></div></figure><p id="efb1" class="pw-post-body-paragraph nl nm it mj b mk ny kd nn mm nz kg no mo oa nq nr mq ob nt nu ms oc nw nx lo im bi translated">SimCLRv2深度为152层，宽度为3倍，simclrv 2<em class="od">ResNet-152(3x+SK)</em>拥有超过<em class="od"/><strong class="mj jd"><em class="od">7.95亿个参数</em> </strong> <em class="od"> </em>，从上面的图表中可以看出，它在ImageNet ILSVRC-2012 数据集的1%、10%和100%上表现最佳。在线性评估和监督分类任务中也保持了这种优异的性能。</p><h2 id="6157" class="os lq it bd lr ot ou dn lv ov ow dp lz mo ox oy mb mq oz pa md ms pb pc mf iz bi translated">更大的模型更有标签效率。</h2><p id="e065" class="pw-post-body-paragraph nl nm it mj b mk ml kd nn mm mn kg no mo np nq nr mq ns nt nu ms nv nw nx lo im bi translated">该论文还表明，对于监督和半监督学习，更大的模型更具标签效率，但半监督学习的增益似乎更大。此外，值得指出的是，虽然模型越大越好，但一些模型(例如，使用SK)比其他模型的参数效率更高</p><h1 id="9966" class="lp lq it bd lr ls lt lu lv lw lx ly lz ki ni kj mb kl nj km md ko nk kp mf mg bi translated"><strong class="ak">为什么重要:</strong></h1><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div class="gh gi kr"><img src="../Images/28a9a79da324bac7f3b1ca5317e01fbf.png" data-original-src="https://miro.medium.com/v2/resize:fit:1000/format:webp/1*--ehmZfH4gkz9GjRGws3MA.jpeg"/></div></figure><p id="85f5" class="pw-post-body-paragraph nl nm it mj b mk ny kd nn mm nz kg no mo oa nq nr mq ob nt nu ms oc nw nx lo im bi translated">这个世界充满了未标记的数据。因此，本文中的发现可以用来提高任何计算机视觉应用的准确性，在这些应用中，标记额外数据比训练更大的模型(如医学成像)更昂贵或更困难。</p><h1 id="0b47" class="lp lq it bd lr ls lt lu lv lw lx ly lz ki ni kj mb kl nj km md ko nk kp mf mg bi translated"><strong class="ak">我在想:</strong></h1><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="ne nf di ng bf nh"><div class="gh gi nd"><img src="../Images/d5e069adc8a753f5827d0c0965d92168.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*pOildLjs7CyGQDeMsDwEEg.jpeg"/></div></div><figcaption class="kz la gj gh gi lb lc bd b be z dk translated">印度人工智能热潮背后的数据标签| <a class="ae ld" href="https://www.google.com/url?sa=i&amp;url=https%3A%2F%2Fwww.dailyo.in%2Ftechnology%2Fdata-labelling-artificial-intelligence-indian-ai-sector-facebook-technology%2Fstory%2F1%2F32396.html&amp;psig=AOvVaw3N9VBb76Tw2xUw5QR8WeJk&amp;ust=1600010608499000&amp;source=images&amp;cd=vfe&amp;ved=0CA0QjhxqFwoTCPCny5v24-sCFQAAAAAdAAAAABAD" rel="noopener ugc nofollow" target="_blank"> Img_Credit </a></figcaption></figure><p id="705e" class="pw-post-body-paragraph nl nm it mj b mk ny kd nn mm nz kg no mo oa nq nr mq ob nt nu ms oc nw nx lo im bi translated">针对特定任务进行微调的自我监督模型可以极大地改善计算机视觉应用。但是必须有一个平衡，因为有一个围绕<a class="ae ld" href="https://www.google.com/url?sa=i&amp;url=https%3A%2F%2Fwww.dailyo.in%2Ftechnology%2Fdata-labelling-artificial-intelligence-indian-ai-sector-facebook-technology%2Fstory%2F1%2F32396.html&amp;psig=AOvVaw3N9VBb76Tw2xUw5QR8WeJk&amp;ust=1600010608499000&amp;source=images&amp;cd=vfe&amp;ved=0CA0QjhxqFwoTCPCny5v24-sCFQAAAAAdAAAAABAD" rel="noopener ugc nofollow" target="_blank">人类数据标签服务</a>建立的整个行业，并且可能减少这些服务需求的技术可能会在这些困难时期导致收入损失。</p><p id="e427" class="pw-post-body-paragraph nl nm it mj b mk ny kd nn mm nz kg no mo oa nq nr mq ob nt nu ms oc nw nx lo im bi translated"><strong class="mj jd">干杯！</strong></p><h1 id="37e5" class="lp lq it bd lr ls lt lu lv lw lx ly lz ki ni kj mb kl nj km md ko nk kp mf mg bi translated">关于我:</h1><p id="f858" class="pw-post-body-paragraph nl nm it mj b mk ml kd nn mm mn kg no mo np nq nr mq ns nt nu ms nv nw nx lo im bi translated">劳伦斯是技术层的数据专家，对公平和可解释的人工智能和数据科学充满热情。我相信分享知识和经验是最好的学习方式。我同时持有IBM的 <strong class="mj jd"> <em class="od">数据科学专业</em> </strong> <em class="od">和</em> <strong class="mj jd"> <em class="od">高级数据科学专业</em> </strong> <em class="od">证书和IBM</em><strong class="mj jd"><em class="od">的</em> </strong> <em class="od"> </em> <strong class="mj jd"> <em class="od">数据科学讲解徽章</em> </strong> <em class="od">。我已经使用ML和DL库进行了几个项目，我喜欢尽可能多地编写我的函数。最后，我从未停止学习和尝试，是的，我已经写了几篇被强烈推荐的文章。</em></p><p id="0f0c" class="pw-post-body-paragraph nl nm it mj b mk ny kd nn mm nz kg no mo oa nq nr mq ob nt nu ms oc nw nx lo im bi translated">请随时在以下网址找到我</p><p id="0adf" class="pw-post-body-paragraph nl nm it mj b mk ny kd nn mm nz kg no mo oa nq nr mq ob nt nu ms oc nw nx lo im bi translated"><a class="ae ld" href="https://github.com/Lawrence-Krukrubo" rel="noopener ugc nofollow" target="_blank">T33】GithubT35】</a></p><p id="0cce" class="pw-post-body-paragraph nl nm it mj b mk ny kd nn mm nz kg no mo oa nq nr mq ob nt nu ms oc nw nx lo im bi translated"><a class="ae ld" href="https://www.linkedin.com/in/lawrencekrukrubo/" rel="noopener ugc nofollow" target="_blank"> <strong class="mj jd">领英</strong> </a></p><p id="15be" class="pw-post-body-paragraph nl nm it mj b mk ny kd nn mm nz kg no mo oa nq nr mq ob nt nu ms oc nw nx lo im bi translated"><a class="ae ld" href="https://twitter.com/LKrukrubo" rel="noopener ugc nofollow" target="_blank"> <strong class="mj jd">推特</strong> </a></p></div></div>    
</body>
</html>