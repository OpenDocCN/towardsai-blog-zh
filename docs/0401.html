<html>
<head>
<title>NLP News Cypher | 04.12.20</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">NLP新闻密码| 04.12.20</h1>
<blockquote>原文：<a href="https://pub.towardsai.net/nlp-news-cypher-04-12-20-a40cd3d8a4a2?source=collection_archive---------1-----------------------#2020-04-13">https://pub.towardsai.net/nlp-news-cypher-04-12-20-a40cd3d8a4a2?source=collection_archive---------1-----------------------#2020-04-13</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><figure class="ip iq gp gr ir is gh gi paragraph-image"><div role="button" tabindex="0" class="it iu di iv bf iw"><div class="gh gi io"><img src="../Images/e9a59ee907bf84c6c545467fa8a4eee1.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*AJvR3v03HI8dRnEt"/></div></div><figcaption class="iz ja gj gh gi jb jc bd b be z dk translated">照片由<a class="ae jd" href="https://unsplash.com/@szm?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Sz拍摄。马顿</a>开启<a class="ae jd" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">开启</a></figcaption></figure><div class=""/><div class=""><h2 id="04cc" class="pw-subtitle-paragraph kd jf jg bd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku dk translated">掉进兔子洞</h2></div></div><div class="ab cl kv kw hu kx" role="separator"><span class="ky bw bk kz la lb"/><span class="ky bw bk kz la lb"/><span class="ky bw bk kz la"/></div><div class="ij ik il im in"><p id="85db" class="pw-post-body-paragraph lc ld jg le b lf lg kh lh li lj kk lk ll lm ln lo lp lq lr ls lt lu lv lw lx ij bi ly translated"><span class="l lz ma mb bm mc md me mf mg di">我</span>叫它兔子。我的演示结束了。我们为那些对流式API、在线推理和生产中的变形金刚感兴趣的人构建了一个应用。</p><p id="3c5a" class="pw-post-body-paragraph lc ld jg le b lf lg kh lh li lj kk lk ll lm ln lo lp lq lr ls lt lu lv lw lx ij bi translated"><strong class="le jh"><em class="mh">* *更新:04 . 13 . 20:</em></strong><a class="ae jd" href="http://rabbit.quantumstat.com" rel="noopener ugc nofollow" target="_blank"><strong class="le jh"><em class="mh">rabbit.quantumstat.com</em></strong></a></p><p id="516e" class="pw-post-body-paragraph lc ld jg le b lf lg kh lh li lj kk lk ll lm ln lo lp lq lr ls lt lu lv lw lx ij bi translated">web应用程序(我在过去的<em class="mh">中已经展示过一次</em>)试图做一个非常困难的平衡动作。今天深度学习中最困难的瓶颈之一是利用NLP中最先进的模型(<em class="mh">变压器，RAM昂贵</em>)，并能够在生产中部署它们，而不会使您的服务器或银行帐户爆炸。我想我可能已经弄明白了，至少对于这个应用程序来说😎。</p><h2 id="cca3" class="mi mj jg bd mk ml mm dn mn mo mp dp mq ll mr ms mt lp mu mv mw lt mx my mz na bi translated">这是什么？</h2><p id="ce13" class="pw-post-body-paragraph lc ld jg le b lf nb kh lh li nc kk lk ll nd ln lo lp ne lr ls lt nf lv lw lx ij bi translated">RABBIT从几十个金融新闻来源(<em class="mh">通常的嫌疑人:彭博、美国消费者新闻与商业频道、华尔街日报和更多</em>)发送推文，并实时运行两个分类器！</p><p id="2879" class="pw-post-body-paragraph lc ld jg le b lf lg kh lh li lj kk lk ll lm ln lo lp lq lr ls lt lu lv lw lx ij bi translated">我在分类什么？第一个模型对金融领域的21个主题进行了分类:</p><figure class="nh ni nj nk gt is gh gi paragraph-image"><div role="button" tabindex="0" class="it iu di iv bf iw"><div class="gh gi ng"><img src="../Images/e1372545dfdc5ddf45234fa9f7ec4785.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*2rhBR6DnaLTDmzHCChWDxg.png"/></div></div><figcaption class="iz ja gj gh gi jb jc bd b be z dk translated">解密的</figcaption></figure><p id="902a" class="pw-post-body-paragraph lc ld jg le b lf lg kh lh li lj kk lk ll lm ln lo lp lq lr ls lt lu lv lw lx ij bi translated">第二个模型将推文分为看涨、看跌或中性。这是什么意思？这意味着，如果你是一个持有黄金的投资者/交易者，而推文提到黄金价格上涨，这将被贴上看涨，反向看跌的标签，如果你不在乎任何一种方式，这是中性的。事实上，这个应用程序应该是个性化的个人用户。因为你将看到的是一个面向普通观众的演示，所以我尽量用这个分类模式来概括。</p><blockquote class="nl nm nn"><p id="84c3" class="lc ld mh le b lf lg kh lh li lj kk lk no lm ln lo np lq lr ls nq lu lv lw lx ij bi translated">因此，这假定了分类中的一阶逻辑。意思是，我的逻辑不是假设n阶效应。例如，如果你持有石油，而石油价格上涨，这被认为是看涨的，(尽管石油上涨的原因可能是因为一些地缘政治冲突，这可能对市场产生负面影响(看跌)，这是一种假设的n阶效应)。</p></blockquote><h2 id="1cf1" class="mi mj jg bd mk ml mm dn mn mo mp dp mq ll mr ms mt lp mu mv mw lt mx my mz na bi translated">它靠什么运行？</h2><p id="8bb8" class="pw-post-body-paragraph lc ld jg le b lf nb kh lh li nc kk lk ll nd ln lo lp ne lr ls lt nf lv lw lx ij bi translated">我设计的后端可以根据需要扩展计算和连接。这些变形金刚是罗伯塔的精华版本，通过10K的推特从一个定制的数据集中获取。目前，我正在利用消息队列和异步框架来帮助我向用户推送推文。向亚当·金致敬，他在我们的一次数字炉边聊天中激发了这个想法。(仅供参考，你可以在这里查看他臭名昭著的GPT-2模型:<a class="ae jd" href="http://www.talktotransformer.com" rel="noopener ugc nofollow" target="_blank">talktotransformer.com</a></p><p id="4448" class="pw-post-body-paragraph lc ld jg le b lf lg kh lh li lj kk lk ll lm ln lo lp lq lr ls lt lu lv lw lx ij bi translated">RABBIT使用web-socket连接来实现流功能，并且只在4个CPU内核上运行。虽然这台计算机可能看起来很小，但当与这种架构结合时，它实际上快如闪电(甚至在用2个变压器进行在线推理时！).由于web套接字连接到浏览器，并且数据服务是单向的，因此向客户端扩展是相当健壮的。</p><h2 id="af46" class="mi mj jg bd mk ml mm dn mn mo mp dp mq ll mr ms mt lp mu mv mw lt mx my mz na bi translated">正误表</h2><p id="c47b" class="pw-post-body-paragraph lc ld jg le b lf nb kh lh li nc kk lk ll nd ln lo lp ne lr ls lt nf lv lw lx ij bi translated">最近，由于冠状病毒改变了新闻周期，出现了一些领域转移(这降低了模型的准确性)。我将继续添加更多的数据来减轻这种情况，尽管目前来看，它表现得相当好。</p><h2 id="9c02" class="mi mj jg bd mk ml mm dn mn mo mp dp mq ll mr ms mt lp mu mv mw lt mx my mz na bi translated">鳍状物</h2><p id="67d9" class="pw-post-body-paragraph lc ld jg le b lf nb kh lh li nc kk lk ll nd ln lo lp ne lr ls lt nf lv lw lx ij bi translated">将于明天，即4月13日正式发布。查看我的<a class="ae jd" href="https://twitter.com/Quantum_Stat" rel="noopener ugc nofollow" target="_blank"> <strong class="le jh">推特</strong> </a>进行更新。仅供参考，该应用程序最好在每周股市开放的交易时间使用，这样你就可以看到它快速流动(尽管从技术上讲，你可以随时查看)。</p><p id="b6fb" class="pw-post-body-paragraph lc ld jg le b lf lg kh lh li lj kk lk ll lm ln lo lp lq lr ls lt lu lv lw lx ij bi translated">以此作品为荣。它便宜，功能强大，速度快。</p><p id="ad9c" class="pw-post-body-paragraph lc ld jg le b lf lg kh lh li lj kk lk ll lm ln lo lp lq lr ls lt lu lv lw lx ij bi translated">未来可能的方法是从头开始创建一个语言模型，然后在我上面提到的自定义数据集上对其进行微调。此外，将是很好的添加更多的实时股票市场流的仪表板数据。</p><p id="32e5" class="pw-post-body-paragraph lc ld jg le b lf lg kh lh li lj kk lk ll lm ln lo lp lq lr ls lt lu lv lw lx ij bi translated">你这周过得怎么样？😎</p></div><div class="ab cl kv kw hu kx" role="separator"><span class="ky bw bk kz la lb"/><span class="ky bw bk kz la lb"/><span class="ky bw bk kz la"/></div><div class="ij ik il im in"><h1 id="d44e" class="nr mj jg bd mk ns nt nu mn nv nw nx mq km ny kn mt kp nz kq mw ks oa kt mz ob bi translated">本周:</h1><blockquote class="nl nm nn"><p id="e37a" class="lc ld mh le b lf lg kh lh li lj kk lk no lm ln lo np lq lr ls nq lu lv lw lx ij bi translated">裸金属</p><p id="17a7" class="lc ld mh le b lf lg kh lh li lj kk lk no lm ln lo np lq lr ls nq lu lv lw lx ij bi translated">本周可乐杯，关于自我关注</p><p id="e1a5" class="lc ld mh le b lf lg kh lh li lj kk lk no lm ln lo np lq lr ls nq lu lv lw lx ij bi translated">拥抱伊莱克特</p><p id="47de" class="lc ld mh le b lf lg kh lh li lj kk lk no lm ln lo np lq lr ls nq lu lv lw lx ij bi translated">科尔伯特·艾</p><p id="7262" class="lc ld mh le b lf lg kh lh li lj kk lk no lm ln lo np lq lr ls nq lu lv lw lx ij bi translated">一个非常大的新闻数据集</p><p id="2306" class="lc ld mh le b lf lg kh lh li lj kk lk no lm ln lo np lq lr ls nq lu lv lw lx ij bi translated">表示感谢</p><p id="8fa8" class="lc ld mh le b lf lg kh lh li lj kk lk no lm ln lo np lq lr ls nq lu lv lw lx ij bi translated">本周数据集:X姿态</p></blockquote><h1 id="dde1" class="nr mj jg bd mk ns oc nu mn nv od nx mq km oe kn mt kp of kq mw ks og kt mz ob bi translated">裸金属</h1><p id="6bc0" class="pw-post-body-paragraph lc ld jg le b lf nb kh lh li nc kk lk ll nd ln lo lp ne lr ls lt nf lv lw lx ij bi translated">人工智能芯片制造商押注NLP模型越来越大，尽管他们的芯片变得越来越智能。金属peeps表示，他们希望将NN输入隔离到单个内核，而不是批量处理它们。其结果是，只有网络中“需要”激发的神经元才会这样做，因为它们是孤立的:</p><blockquote class="nl nm nn"><p id="2612" class="lc ld mh le b lf lg kh lh li lj kk lk no lm ln lo np lq lr ls nq lu lv lw lx ij bi translated">”公司专注于“稀疏”的概念，即如果去除冗余信息，许多神经网络可以更有效地处理。Lie观察到“稀疏性有一个巨大的未开发的潜力”，并且“神经网络自然是稀疏的”。"</p></blockquote><div class="ip iq gp gr ir oh"><a href="https://www.zdnet.com/article/startup-tenstorrent-and-competitors-show-how-computing-is-changing-ai-and-vice-versa/" rel="noopener  ugc nofollow" target="_blank"><div class="oi ab fo"><div class="oj ab ok cl cj ol"><h2 class="bd jh gy z fp om fr fs on fu fw jf bi translated">初创公司Tenstorrent显示人工智能正在改变计算，反之亦然| ZDNet</h2><div class="oo l"><h3 class="bd b gy z fp om fr fs on fu fw dk translated">Tenstorrent是2016年成立并最终展示产品的人工智能芯片制造商中的一员。新一波的芯片…</h3></div><div class="op l"><p class="bd b dl z fp om fr fs on fu fw dk translated">www.zdnet.com</p></div></div><div class="oq l"><div class="or l os ot ou oq ov ix oh"/></div></div></a></div><p id="21ba" class="pw-post-body-paragraph lc ld jg le b lf lg kh lh li lj kk lk ll lm ln lo lp lq lr ls lt lu lv lw lx ij bi translated">有了这些知识，新的人工智能芯片不需要训练很长时间，并且可以在更早的时候退出训练。🧐</p><h1 id="1257" class="nr mj jg bd mk ns oc nu mn nv od nx mq km oe kn mt kp of kq mw ks og kt mz ob bi translated">本周可乐杯，关于自我关注</h1><p id="b2a6" class="pw-post-body-paragraph lc ld jg le b lf nb kh lh li nc kk lk ll nd ln lo lp ne lr ls lt nf lv lw lx ij bi translated">我会让你探索这一个:</p><div class="ip iq gp gr ir oh"><a href="https://colab.research.google.com/github/mrm8488/shared_colab_notebooks/blob/master/basic_self_attention_.ipynb" rel="noopener  ugc nofollow" target="_blank"><div class="oi ab fo"><div class="oj ab ok cl cj ol"><h2 class="bd jh gy z fp om fr fs on fu fw jf bi translated">谷歌联合实验室</h2><div class="oo l"><h3 class="bd b gy z fp om fr fs on fu fw dk translated">编辑描述</h3></div><div class="op l"><p class="bd b dl z fp om fr fs on fu fw dk translated">colab.research.google.com</p></div></div><div class="oq l"><div class="ow l os ot ou oq ov ix oh"/></div></div></a></div><h1 id="0bba" class="nr mj jg bd mk ns oc nu mn nv od nx mq km oe kn mt kp of kq mw ks og kt mz ob bi translated">拥抱伊莱克特</h1><p id="fcc7" class="pw-post-body-paragraph lc ld jg le b lf nb kh lh li nc kk lk ll nd ln lo lp ne lr ls lt nf lv lw lx ij bi translated">这种用相对较低的计算量训练语言模型的新方法现在出现在拥抱人脸库上。你可能还记得伊莱克特拉那激动人心的表演👇</p><figure class="nh ni nj nk gt is gh gi paragraph-image"><div class="gh gi ox"><img src="../Images/0e818b0919df2fb0df6ddd37fb57ffda.png" data-original-src="https://miro.medium.com/v2/resize:fit:1280/format:webp/0*ZRkF72eeOl1uXOxk.png"/></div></figure><div class="ip iq gp gr ir oh"><a href="https://github.com/huggingface/transformers/releases/tag/v2.8.0" rel="noopener  ugc nofollow" target="_blank"><div class="oi ab fo"><div class="oj ab ok cl cj ol"><h2 class="bd jh gy z fp om fr fs on fu fw jf bi translated">拥抱脸/变形金刚</h2><div class="oo l"><h3 class="bd b gy z fp om fr fs on fu fw dk translated">ELECTRA是一种新的自监督语言表征学习方法。它可以用来预训练变压器…</h3></div><div class="op l"><p class="bd b dl z fp om fr fs on fu fw dk translated">github.com</p></div></div><div class="oq l"><div class="oy l os ot ou oq ov ix oh"/></div></div></a></div><p id="bfd5" class="pw-post-body-paragraph lc ld jg le b lf lg kh lh li lj kk lk ll lm ln lo lp lq lr ls lt lu lv lw lx ij bi translated">开发人员很快就利用了ELECTRA，这是一个简单的变形金刚库，它构建在🤗的变形金刚，已经有了:</p><div class="ip iq gp gr ir oh"><a href="https://towardsdatascience.com/understanding-electra-and-training-an-electra-language-model-3d33e3a9660d" rel="noopener follow" target="_blank"><div class="oi ab fo"><div class="oj ab ok cl cj ol"><h2 class="bd jh gy z fp om fr fs on fu fw jf bi translated">理解ELECTRA并训练一个ELECTRA语言模型</h2><div class="oo l"><h3 class="bd b gy z fp om fr fs on fu fw dk translated">变形金刚模型如何学习语言？伊莱克特拉有什么新消息？你如何在一个…</h3></div><div class="op l"><p class="bd b dl z fp om fr fs on fu fw dk translated">towardsdatascience.com</p></div></div><div class="oq l"><div class="oz l os ot ou oq ov ix oh"/></div></div></a></div><h1 id="28d3" class="nr mj jg bd mk ns oc nu mn nv od nx mq km oe kn mt kp of kq mw ks og kt mz ob bi translated">科尔伯特·艾</h1><p id="dcc2" class="pw-post-body-paragraph lc ld jg le b lf nb kh lh li nc kk lk ll nd ln lo lp ne lr ls lt nf lv lw lx ij bi translated">GPT-2用一点幽默进行了反击。开发者阿巴斯·默罕默德和T2·舒巴姆·拉奥通过从YouTube上晚间节目的视频字幕中提取独白，创造了这个模型。他们为想做类似事情的人提供了一个很好的Colab笔记本，里面有很好的文档。(您可能需要获得自己的数据集😢)</p><p id="cfff" class="pw-post-body-paragraph lc ld jg le b lf lg kh lh li lj kk lk ll lm ln lo lp lq lr ls lt lu lv lw lx ij bi translated"><strong class="le jh"> Colab </strong>:</p><div class="ip iq gp gr ir oh"><a href="https://colab.research.google.com/gist/iam-abbas/b93961bc9468e375f1b75a1a6e47610c/colbert-ai-v2.ipynb" rel="noopener  ugc nofollow" target="_blank"><div class="oi ab fo"><div class="oj ab ok cl cj ol"><h2 class="bd jh gy z fp om fr fs on fu fw jf bi translated">谷歌联合实验室</h2><div class="oo l"><h3 class="bd b gy z fp om fr fs on fu fw dk translated">编辑描述</h3></div><div class="op l"><p class="bd b dl z fp om fr fs on fu fw dk translated">colab.research.google.com</p></div></div><div class="oq l"><div class="pa l os ot ou oq ov ix oh"/></div></div></a></div><h1 id="868b" class="nr mj jg bd mk ns oc nu mn nv od nx mq km oe kn mt kp of kq mw ks og kt mz ob bi translated">一个非常大的新闻数据集</h1><p id="7f1c" class="pw-post-body-paragraph lc ld jg le b lf nb kh lh li nc kk lk ll nd ln lo lp ne lr ls lt nf lv lw lx ij bi translated">在Reddit上找到了这块宝石。随着普通开发人员越来越接近从零开始训练他们自己的语言模型，从长远来看，超级大数据集将在NLP开发人员中变得越来越受欢迎。该数据集包含过去4年的270万篇新闻文章:</p><div class="ip iq gp gr ir oh"><a href="https://components.one/datasets/all-the-news-2-news-articles-dataset/" rel="noopener  ugc nofollow" target="_blank"><div class="oi ab fo"><div class="oj ab ok cl cj ol"><h2 class="bd jh gy z fp om fr fs on fu fw jf bi translated">所有新闻2.0:270万篇新闻文章-组件</h2><div class="oo l"><h3 class="bd b gy z fp om fr fs on fu fw dk translated">2017年发布的流行的All the News数据集的更新。该数据集包含来自26家公司的270万篇文章…</h3></div><div class="op l"><p class="bd b dl z fp om fr fs on fu fw dk translated">组件.一</p></div></div><div class="oq l"><div class="pb l os ot ou oq ov ix oh"/></div></div></a></div><h1 id="21e8" class="nr mj jg bd mk ns oc nu mn nv od nx mq km oe kn mt kp of kq mw ks og kt mz ob bi translated">表示感谢</h1><p id="53d0" class="pw-post-body-paragraph lc ld jg le b lf nb kh lh li nc kk lk ll nd ln lo lp ne lr ls lt nf lv lw lx ij bi translated">本周，一个相对较新的记号赋予器引起了我的注意，它吹嘘自己的速度优于其他著名的记号赋予器(它是用C++编写的)。如果你想比较它和其他产品(<a class="ae jd" href="https://github.com/huggingface/tokenizers" rel="noopener ugc nofollow" target="_blank">拥抱脸</a>、<a class="ae jd" href="https://github.com/google/sentencepiece/" rel="noopener ugc nofollow" target="_blank">句子片段</a>和<a class="ae jd" href="https://github.com/glample/fastBPE" rel="noopener ugc nofollow" target="_blank"> fastBPE </a>)的速度，看看他们的基准测试结果:</p><p id="b956" class="pw-post-body-paragraph lc ld jg le b lf lg kh lh li lj kk lk ll lm ln lo lp lq lr ls lt lu lv lw lx ij bi translated"><strong class="le jh">主回购:</strong></p><div class="ip iq gp gr ir oh"><a href="https://github.com/VKCOM/YouTokenToMe" rel="noopener  ugc nofollow" target="_blank"><div class="oi ab fo"><div class="oj ab ok cl cj ol"><h2 class="bd jh gy z fp om fr fs on fu fw jf bi translated">VKCOM/YouTokenToMe</h2><div class="oo l"><h3 class="bd b gy z fp om fr fs on fu fw dk translated">YouTokenToMe是一个无监督的文本标记器，专注于计算效率。它目前实现快速字节…</h3></div><div class="op l"><p class="bd b dl z fp om fr fs on fu fw dk translated">github.com</p></div></div><div class="oq l"><div class="pc l os ot ou oq ov ix oh"/></div></div></a></div><p id="9d8d" class="pw-post-body-paragraph lc ld jg le b lf lg kh lh li lj kk lk ll lm ln lo lp lq lr ls lt lu lv lw lx ij bi translated"><strong class="le jh">基准</strong>:</p><div class="ip iq gp gr ir oh"><a href="https://github.com/VKCOM/YouTokenToMe/blob/master/benchmark.md" rel="noopener  ugc nofollow" target="_blank"><div class="oi ab fo"><div class="oj ab ok cl cj ol"><h2 class="bd jh gy z fp om fr fs on fu fw jf bi translated">VKCOM/YouTokenToMe</h2><div class="oo l"><h3 class="bd b gy z fp om fr fs on fu fw dk translated">YouTokenToMe将与拥抱脸、句子和fastBPE相比较。这三种算法被认为是…</h3></div><div class="op l"><p class="bd b dl z fp om fr fs on fu fw dk translated">github.com</p></div></div><div class="oq l"><div class="pd l os ot ou oq ov ix oh"/></div></div></a></div><h1 id="d3c5" class="nr mj jg bd mk ns oc nu mn nv od nx mq km oe kn mt kp of kq mw ks og kt mz ob bi translated">本周数据集:X姿态</h1><p id="c62a" class="pw-post-body-paragraph lc ld jg le b lf nb kh lh li nc kk lk ll nd ln lo lp ne lr ls lt nf lv lw lx ij bi translated"><strong class="le jh">什么事？</strong></p><p id="d80a" class="pw-post-body-paragraph lc ld jg le b lf lg kh lh li lj kk lk ll lm ln lo lp lq lr ls lt lu lv lw lx ij bi translated"><em class="mh">“x-stance数据集包含150多个政治问题，以及候选人就这些问题撰写的67k条评论。”</em>评论有英语、德语、法语和意大利语。</p><p id="8a83" class="pw-post-body-paragraph lc ld jg le b lf lg kh lh li lj kk lk ll lm ln lo lp lq lr ls lt lu lv lw lx ij bi translated"><strong class="le jh">样品:</strong></p><figure class="nh ni nj nk gt is gh gi paragraph-image"><div role="button" tabindex="0" class="it iu di iv bf iw"><div class="gh gi pe"><img src="../Images/cb75ccb5de720ee9ce754ab20575b957.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*uH0xwMsoWXWdXVmd.png"/></div></div></figure><p id="77bd" class="pw-post-body-paragraph lc ld jg le b lf lg kh lh li lj kk lk ll lm ln lo lp lq lr ls lt lu lv lw lx ij bi translated"><strong class="le jh">在哪里？</strong></p><div class="ip iq gp gr ir oh"><a href="https://github.com/ZurichNLP/xstance" rel="noopener  ugc nofollow" target="_blank"><div class="oi ab fo"><div class="oj ab ok cl cj ol"><h2 class="bd jh gy z fp om fr fs on fu fw jf bi translated">ZurichNLP/xstance</h2><div class="oo l"><h3 class="bd b gy z fp om fr fs on fu fw dk translated">“X-Stance:Stance的多语言多目标数据集”一文附带的文档和评估脚本</h3></div><div class="op l"><p class="bd b dl z fp om fr fs on fu fw dk translated">github.com</p></div></div><div class="oq l"><div class="pf l os ot ou oq ov ix oh"/></div></div></a></div></div><div class="ab cl kv kw hu kx" role="separator"><span class="ky bw bk kz la lb"/><span class="ky bw bk kz la lb"/><span class="ky bw bk kz la"/></div><div class="ij ik il im in"><blockquote class="pg"><p id="25e0" class="ph pi jg bd pj pk pl pm pn po pp lx dk translated"><em class="pq">每周日，我们都会对来自世界各地研究人员的NLP新闻和代码进行一次每周综述。</em></p><p id="69c5" class="ph pi jg bd pj pk pl pm pn po pp lx dk translated"><em class="pq">如果您喜欢这篇文章，请帮助我们并与朋友分享！</em></p><p id="8d07" class="ph pi jg bd pj pk pl pm pn po pp lx dk translated"><em class="pq">如需完整报道，请关注我们的Twitter:</em><a class="ae jd" href="http://twitter.com/Quantum_Stat" rel="noopener ugc nofollow" target="_blank"><em class="pq">@ Quantum _ Stat</em></a></p></blockquote><figure class="ps pt pu pv pw is gh gi paragraph-image"><div class="gh gi pr"><img src="../Images/34437a7198f0d375231accb47918148e.png" data-original-src="https://miro.medium.com/v2/resize:fit:108/0*yFwec5MOWKaR6A1_"/></div><figcaption class="iz ja gj gh gi jb jc bd b be z dk translated"><a class="ae jd" href="http://www.quantumstat.com/" rel="noopener ugc nofollow" target="_blank">www.quantumstat.com</a></figcaption></figure></div></div>    
</body>
</html>