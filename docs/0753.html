<html>
<head>
<title>The language of a CEO, NLP analysis of Steve Jobs commencement speech</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">一个CEO的语言，史蒂夫·乔布斯毕业典礼演讲的NLP分析</h1>
<blockquote>原文：<a href="https://pub.towardsai.net/the-language-of-a-ceo-nlp-analysis-of-steve-jobs-commencement-speech-b7eadf56d1c5?source=collection_archive---------2-----------------------#2020-08-02">https://pub.towardsai.net/the-language-of-a-ceo-nlp-analysis-of-steve-jobs-commencement-speech-b7eadf56d1c5?source=collection_archive---------2-----------------------#2020-08-02</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><h2 id="1e65" class="ir is it bd b dl iu iv iw ix iy iz dk ja translated" aria-label="kicker paragraph"><a class="ae ep" href="https://towardsai.net/p/category/nlp" rel="noopener ugc nofollow" target="_blank">自然语言处理</a></h2><div class=""/><div class=""><h2 id="55eb" class="pw-subtitle-paragraph jz jc it bd b ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq dk translated">Github上有完整的代码<a class="ae kr" href="https://github.com/arditoibryan/Projects/tree/master/20200730_NLP_word_frequency" rel="noopener ugc nofollow" target="_blank">。</a></h2></div><p id="19b7" class="pw-post-body-paragraph ks kt it ku b kv kw kd kx ky kz kg la lb lc ld le lf lg lh li lj lk ll lm ln im bi translated">在这篇文章中，我将对史蒂夫·乔布斯的著名演讲进行文本分析，找出历史上使用频率最高的词。然而，这并不像听起来那么容易。我将解释如何使用Spacy的自然语言处理来处理单词。</p><figure class="lp lq lr ls gt lt gh gi paragraph-image"><div role="button" tabindex="0" class="lu lv di lw bf lx"><div class="gh gi lo"><img src="../Images/c04445b8d4b6a263aa3737003e2920c3.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*g8N_-4tXPbVxCTYNbmNTiA.png"/></div></div><figcaption class="ma mb gj gh gi mc md bd b be z dk translated">苹果，不一样的思考</figcaption></figure><h1 id="9d28" class="me mf it bd mg mh mi mj mk ml mm mn mo ki mp kj mq kl mr km ms ko mt kp mu mv bi translated">NLP的问题及其解决方法</h1><p id="748a" class="pw-post-body-paragraph ks kt it ku b kv mw kd kx ky mx kg la lb my ld le lf mz lh li lj na ll lm ln im bi translated">使用basic编程，有太多的文本元素存储为字符串，这将使我们的结果无用:</p><ul class=""><li id="99fd" class="nb nc it ku b kv kw ky kz lb nd lf ne lj nf ln ng nh ni nj bi translated">标点</li><li id="32d8" class="nb nc it ku b kv nk ky nl lb nm lf nn lj no ln ng nh ni nj bi translated">同根异字</li></ul><p id="5439" class="pw-post-body-paragraph ks kt it ku b kv kw kd kx ky kz kg la lb lc ld le lf lg lh li lj lk ll lm ln im bi translated">例如，句子:</p><pre class="lp lq lr ls gt np nq nr ns aw nt bi"><span id="2aea" class="nu mf it nq b gy nv nw l nx ny">'I asked my mother if she could buy me cookies. She told me she already bought them.'</span></pre><p id="fd8a" class="pw-post-body-paragraph ks kt it ku b kv kw kd kx ky kz kg la lb lc ld le lf lg lh li lj lk ll lm ln im bi translated">去掉标点符号后，如果我运行算法按频率提取单词，结果是这样的:</p><pre class="lp lq lr ls gt np nq nr ns aw nt bi"><span id="5690" class="nu mf it nq b gy nv nw l nx ny">('asked', 1),<br/>('mother', 1),<br/>('buy', 1),<br/>('cookies', 1),<br/>('told', 1),<br/>('bought', 1)</span></pre><p id="f3af" class="pw-post-body-paragraph ks kt it ku b kv kw kd kx ky kz kg la lb lc ld le lf lg lh li lj lk ll lm ln im bi translated">正如你所看到的，计算机在动词<strong class="ku jd">购买</strong>和<strong class="ku jd">购买</strong>之间做了很大的区分。实际上，因为它们来源于同一个动词，所以应该归入同一个范畴。我该如何解决这个问题？通过使用<strong class="ku jd">术语化</strong>。</p><h2 id="ae71" class="nu mf it bd mg nz oa dn mk ob oc dp mo lb od oe mq lf of og ms lj oh oi mu iz bi translated">词汇化</h2><p id="40d3" class="pw-post-body-paragraph ks kt it ku b kv mw kd kx ky mx kg la lb my ld le lf mz lh li lj na ll lm ln im bi translated">词汇化所做的就是遍历每个单词来找到它的词根。</p><figure class="lp lq lr ls gt lt gh gi paragraph-image"><div class="gh gi oj"><img src="../Images/26508e1f818cafc654d593a30857ce93.png" data-original-src="https://miro.medium.com/v2/resize:fit:692/format:webp/1*9EUJenANHktt0QHOig2AXw.png"/></div><figcaption class="ma mb gj gh gi mc md bd b be z dk translated">“change”一词的词汇化</figcaption></figure><p id="180c" class="pw-post-body-paragraph ks kt it ku b kv kw kd kx ky kz kg la lb lc ld le lf lg lh li lj lk ll lm ln im bi translated">这是我经过引理化后得到的结果。大家可以看到，现在<strong class="ku jd">买</strong>这个词算了两次。</p><pre class="lp lq lr ls gt np nq nr ns aw nt bi"><span id="5d57" class="nu mf it nq b gy nv nw l nx ny">('buy', 2),<br/>('ask', 1),<br/>('mother', 1),<br/>('cookie', 1),<br/>('tell', 1)]</span></pre><p id="0adc" class="pw-post-body-paragraph ks kt it ku b kv kw kd kx ky kz kg la lb lc ld le lf lg lh li lj lk ll lm ln im bi translated">我已经准备好编写软件并分析我想要的文本:</p><h1 id="57b8" class="me mf it bd mg mh mi mj mk ml mm mn mo ki mp kj mq kl mr km ms ko mt kp mu mv bi translated">安装库</h1><pre class="lp lq lr ls gt np nq nr ns aw nt bi"><span id="6bec" class="nu mf it nq b gy nv nw l nx ny">!pip install spacy</span></pre><p id="5f8f" class="pw-post-body-paragraph ks kt it ku b kv kw kd kx ky kz kg la lb lc ld le lf lg lh li lj lk ll lm ln im bi translated">spacy库是执行NLP分析的最佳工具之一。在spacy中还可以找到其他非常有用的应用，比如实体识别。今天我就限定自己统计词频。</p><h1 id="ceb1" class="me mf it bd mg mh mi mj mk ml mm mn mo ki mp kj mq kl mr km ms ko mt kp mu mv bi translated">创建单词计数器</h1><p id="69b9" class="pw-post-body-paragraph ks kt it ku b kv mw kd kx ky mx kg la lb my ld le lf mz lh li lj na ll lm ln im bi translated">这是保存整个实验的函数。作为输入，它接收一个文本和我们想要提取的最常见的单词的数量。</p><pre class="lp lq lr ls gt np nq nr ns aw nt bi"><span id="b67f" class="nu mf it nq b gy nv nw l nx ny">def top_frequent(text, num_words):<br/>  #frequency of most common words<br/>  import spacy<br/>  from collections import Counter</span><span id="6ede" class="nu mf it nq b gy ok nw l nx ny">nlp = spacy.load("en")<br/>  text = text</span><span id="b724" class="nu mf it nq b gy ok nw l nx ny">#lemmatization<br/>  doc = nlp(text)<br/>  token_list = list()<br/>  for token in doc:<br/>    #print(token, token.lemma_)<br/>    token_list.append(token.lemma_)<br/>  token_list</span><span id="b590" class="nu mf it nq b gy ok nw l nx ny">lemmatized = ''<br/>  for _ in token_list:<br/>    lemmatized = lemmatized + ' ' + _<br/>  lemmatized</span><span id="9b26" class="nu mf it nq b gy ok nw l nx ny">#remove stopwords and punctuations<br/>  doc = nlp(lemmatized)<br/>  words = [token.text for token in doc if token.is_stop != True and token.is_punct != True]<br/>  word_freq = Counter(words)<br/>  common_words = word_freq.most_common(num_words)<br/>  return common_words</span></pre><h1 id="27d8" class="me mf it bd mg mh mi mj mk ml mm mn mo ki mp kj mq kl mr km ms ko mt kp mu mv bi translated">史蒂夫·乔布斯毕业典礼演讲</h1><p id="53da" class="pw-post-body-paragraph ks kt it ku b kv mw kd kx ky mx kg la lb my ld le lf mz lh li lj na ll lm ln im bi translated">我把毕业典礼演讲作为输入，是把它作为一个变量。请记住使用三个<strong class="ku jd"> ' </strong>，这样无论您在文本区域中添加其他逗号、空格或不同的标点符号，都不会被视为代码。</p><pre class="lp lq lr ls gt np nq nr ns aw nt bi"><span id="5d94" class="nu mf it nq b gy nv nw l nx ny">text = '''<br/>I am honored to be with you today at your commencement from one of the finest universities in the world. I never graduated from college. Truth be told, this is the closest I’ve ever gotten to a college graduation. Today I want to tell you three stories from my life. That’s it. No big deal. Just three stories...<br/>'''</span></pre><p id="67e7" class="pw-post-body-paragraph ks kt it ku b kv kw kd kx ky kz kg la lb lc ld le lf lg lh li lj lk ll lm ln im bi translated">我将简单地调用文本上的函数:</p><pre class="lp lq lr ls gt np nq nr ns aw nt bi"><span id="e749" class="nu mf it nq b gy nv nw l nx ny">top_frequent(text, 10)</span></pre><p id="94aa" class="pw-post-body-paragraph ks kt it ku b kv kw kd kx ky kz kg la lb lc ld le lf lg lh li lj lk ll lm ln im bi translated">这些是演讲中最常用的词:</p><pre class="lp lq lr ls gt np nq nr ns aw nt bi"><span id="23de" class="nu mf it nq b gy nv nw l nx ny">('life', 16),<br/>('college', 12),<br/>('year', 12),<br/>('drop', 11),<br/>('want', 9),<br/>('look', 9),<br/>('love', 9),<br/>('Apple', 9)</span></pre><p id="5345" class="pw-post-body-paragraph ks kt it ku b kv kw kd kx ky kz kg la lb lc ld le lf lg lh li lj lk ll lm ln im bi translated">你觉得它们鼓舞人心吗？</p></div></div>    
</body>
</html>