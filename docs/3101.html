<html>
<head>
<title>Computer Vision A-Z Briefly Explained Part 1</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">计算机视觉A-Z简要解释了第1部分</h1>
<blockquote>原文：<a href="https://pub.towardsai.net/computer-vision-a-z-briefly-explained-part-1-7523128c1fb5?source=collection_archive---------3-----------------------#2022-09-07">https://pub.towardsai.net/computer-vision-a-z-briefly-explained-part-1-7523128c1fb5?source=collection_archive---------3-----------------------#2022-09-07</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="2377" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">提神和快速回忆</h2></div><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi ki"><img src="../Images/b9c4b9d9af9b70fee7f9415aa66a33ea.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*JmCpunNdzHlsw-YsMXcwVQ.png"/></div><figcaption class="kq kr gj gh gi ks kt bd b be z dk translated">作者图片</figcaption></figure><h1 id="09e8" class="ku kv it bd kw kx ky kz la lb lc ld le jz lf ka lg kc lh kd li kf lj kg lk ll bi translated">介绍</h1><p id="91cd" class="pw-post-body-paragraph lm ln it lo b lp lq ju lr ls lt jx lu lv lw lx ly lz ma mb mc md me mf mg mh im bi translated"><strong class="lo iu"> <em class="mi">计算机视觉</em> </strong>是<strong class="lo iu"> <em class="mi">人工智能</em> </strong>的一个领域，其中计算机试图从图片&amp;视频中收集信息，简单来说就是视觉样本。当然，<strong class="lo iu"> <em class="mi">编程</em> </strong>这些观念都很重要。但是在<strong class="lo iu"> <em class="mi">编程</em> </strong>之前，深入覆盖定义背后的逻辑是必不可少的。</p><p id="f04a" class="pw-post-body-paragraph lm ln it lo b lp mj ju lr ls mk jx lu lv ml lx ly lz mm mb mc md mn mf mg mh im bi translated">无论你是职业生涯的开端，还是你所在领域的前辈，阅读这些术语都会对你有所帮助。</p><p id="6680" class="pw-post-body-paragraph lm ln it lo b lp mj ju lr ls mk jx lu lv ml lx ly lz mm mb mc md mn mf mg mh im bi translated">在短短的7分钟内，你将深入了解整个<strong class="lo iu"> <em class="mi">计算机视觉</em> </strong>术语，有时还会用到数学函数、图表和现实生活中的例子。</p><p id="dfa0" class="pw-post-body-paragraph lm ln it lo b lp mj ju lr ls mk jx lu lv ml lx ly lz mm mb mc md mn mf mg mh im bi translated">现在，让我们开始我们的<strong class="lo iu"> <em class="mi">计算机视觉之旅。</em> </strong></p></div><div class="ab cl mo mp hx mq" role="separator"><span class="mr bw bk ms mt mu"/><span class="mr bw bk ms mt mu"/><span class="mr bw bk ms mt"/></div><div class="im in io ip iq"><pre class="kj kk kl km gt mv mw mx my aw mz bi"><span id="4b3d" class="na kv it mw b gy nb nc l nd ne"><strong class="mw iu">Content Table</strong></span><span id="bf22" class="na kv it mw b gy nf nc l nd ne">· <a class="ae ng" href="#09e8" rel="noopener ugc nofollow"><strong class="mw iu">Introduction</strong></a><br/>· <a class="ae ng" href="#7963" rel="noopener ugc nofollow">Padding</a><br/><strong class="mw iu">· </strong><a class="ae ng" href="#0f35" rel="noopener ugc nofollow"><strong class="mw iu">Convolution Operation</strong></a><strong class="mw iu"><br/></strong>  ∘ <a class="ae ng" href="#b1d3" rel="noopener ugc nofollow">Valid Convolution</a><br/>  ∘ <a class="ae ng" href="#3898" rel="noopener ugc nofollow">Same Convolution</a><br/>  ∘ <a class="ae ng" href="#0566" rel="noopener ugc nofollow">Strided Convolution</a><br/><strong class="mw iu">· </strong><a class="ae ng" href="#6c22" rel="noopener ugc nofollow"><strong class="mw iu">Pooling</strong></a><strong class="mw iu"><br/></strong>  ∘ <a class="ae ng" href="#e470" rel="noopener ugc nofollow">Average Pooling</a><br/>  ∘ <a class="ae ng" href="#82e8" rel="noopener ugc nofollow">Max Pooling </a><br/><strong class="mw iu">· </strong><a class="ae ng" href="#ca94" rel="noopener ugc nofollow"><strong class="mw iu">Famous Networks</strong></a><strong class="mw iu"><br/></strong>  ∘ <a class="ae ng" href="#bda9" rel="noopener ugc nofollow">LeNet-5</a><br/>  ∘ <a class="ae ng" href="#ab04" rel="noopener ugc nofollow">Layer Structure</a><br/>  ∘ <a class="ae ng" href="#0fa1" rel="noopener ugc nofollow">AlexNet</a><br/>  ∘ <a class="ae ng" href="#2de6" rel="noopener ugc nofollow">Structure</a><br/>  ∘ <a class="ae ng" href="#5b3d" rel="noopener ugc nofollow">VGG-16</a><br/>  ∘ <a class="ae ng" href="#7d2f" rel="noopener ugc nofollow">Inception Network</a><br/><strong class="mw iu">· </strong><a class="ae ng" href="#976d" rel="noopener ugc nofollow"><strong class="mw iu">Transfer Learning</strong></a><strong class="mw iu"><br/>· </strong><a class="ae ng" href="#df48" rel="noopener ugc nofollow"><strong class="mw iu">Data Augmentation</strong></a><strong class="mw iu"><br/></strong>· <a class="ae ng" href="#1d16" rel="noopener ugc nofollow"><strong class="mw iu">Conclusion</strong></a></span></pre></div><div class="ab cl mo mp hx mq" role="separator"><span class="mr bw bk ms mt mu"/><span class="mr bw bk ms mt mu"/><span class="mr bw bk ms mt"/></div><div class="im in io ip iq"><h1 id="7963" class="ku kv it bd kw kx nh kz la lb ni ld le jz nj ka lg kc nk kd li kf nl kg lk ll bi translated">填料</h1><p id="a77f" class="pw-post-body-paragraph lm ln it lo b lp lq ju lr ls lt jx lu lv lw lx ly lz ma mb mc md me mf mg mh im bi translated">向图像添加一个或多个层，以防止图像尺寸缩小。</p><h1 id="0f35" class="ku kv it bd kw kx ky kz la lb lc ld le jz lf ka lg kc lh kd li kf lj kg lk ll bi translated">卷积运算</h1><p id="0c39" class="pw-post-body-paragraph lm ln it lo b lp lq ju lr ls lt jx lu lv lw lx ly lz ma mb mc md me mf mg mh im bi translated">以特殊方式将图片的数字变换形式与预定义的数组相乘。</p><h2 id="b1d3" class="na kv it bd kw nm nn dn la no np dp le lv nq nr lg lz ns nt li md nu nv lk nw bi translated">有效卷积</h2><p id="940a" class="pw-post-body-paragraph lm ln it lo b lp lq ju lr ls lt jx lu lv lw lx ly lz ma mb mc md me mf mg mh im bi translated">卷积运算后，输入的大小将根据滤波器大小而改变。</p><h2 id="3898" class="na kv it bd kw nm nn dn la no np dp le lv nq nr lg lz ns nt li md nu nv lk nw bi translated">相同卷积</h2><p id="4b65" class="pw-post-body-paragraph lm ln it lo b lp lq ju lr ls lt jx lu lv lw lx ly lz ma mb mc md me mf mg mh im bi translated">填充操作之后，输出大小将与输入大小相同。</p><h2 id="0566" class="na kv it bd kw nm nn dn la no np dp le lv nq nr lg lz ns nt li md nu nv lk nw bi translated">步进卷积</h2><p id="4891" class="pw-post-body-paragraph lm ln it lo b lp lq ju lr ls lt jx lu lv lw lx ly lz ma mb mc md me mf mg mh im bi translated">当我们在乘法运算中使用移动盒子时，它的步长将是2而不是1。</p><h1 id="6c22" class="ku kv it bd kw kx ky kz la lb lc ld le jz lf ka lg kc lh kd li kf lj kg lk ll bi translated">联营</h1><p id="cb9f" class="pw-post-body-paragraph lm ln it lo b lp lq ju lr ls lt jx lu lv lw lx ly lz ma mb mc md me mf mg mh im bi translated">目的是减少输入图像。</p><h2 id="e470" class="na kv it bd kw nm nn dn la no np dp le lv nq nr lg lz ns nt li md nu nv lk nw bi translated">平均池</h2><p id="c23a" class="pw-post-body-paragraph lm ln it lo b lp lq ju lr ls lt jx lu lv lw lx ly lz ma mb mc md me mf mg mh im bi translated">通过平均进行汇集操作。</p><h2 id="82e8" class="na kv it bd kw nm nn dn la no np dp le lv nq nr lg lz ns nt li md nu nv lk nw bi translated">最大池化</h2><p id="72fe" class="pw-post-body-paragraph lm ln it lo b lp lq ju lr ls lt jx lu lv lw lx ly lz ma mb mc md me mf mg mh im bi translated">使合并操作区间计算相关数的最大值。</p><h1 id="ca94" class="ku kv it bd kw kx ky kz la lb lc ld le jz lf ka lg kc lh kd li kf lj kg lk ll bi translated">著名网络</h1><h2 id="bda9" class="na kv it bd kw nm nn dn la no np dp le lv nq nr lg lz ns nt li md nu nv lk nw bi translated">LeNet-5</h2><blockquote class="nx"><p id="8e6f" class="ny nz it bd oa ob oc od oe of og mh dk translated"><strong class="ak"> LeNet </strong>是LeCun等人在1998年提出的卷积神经网络结构[1]。一般来说，LeNet指的是LeNet-5，是一个简单的卷积神经网络。</p></blockquote><h2 id="ab04" class="na kv it bd kw nm oh dn la no oi dp le lv oj nr lg lz ok nt li md ol nv lk nw bi translated">层状结构</h2><ul class=""><li id="3e96" class="om on it lo b lp lq ls lt lv oo lz op md oq mh or os ot ou bi translated"><strong class="lo iu"> <em class="mi">第一层——卷积层</em> </strong></li><li id="8f03" class="om on it lo b lp ov ls ow lv ox lz oy md oz mh or os ot ou bi translated"><strong class="lo iu"> <em class="mi">第二层-平均汇集层</em> </strong></li><li id="44cd" class="om on it lo b lp ov ls ow lv ox lz oy md oz mh or os ot ou bi translated"><strong class="lo iu"> <em class="mi">第三层-第二卷积层</em> </strong></li><li id="1cab" class="om on it lo b lp ov ls ow lv ox lz oy md oz mh or os ot ou bi translated"><strong class="lo iu"> <em class="mi">第四层——平均汇集层</em> </strong></li><li id="8791" class="om on it lo b lp ov ls ow lv ox lz oy md oz mh or os ot ou bi translated"><strong class="lo iu"> <em class="mi">第五层——全连接卷积层</em> </strong></li><li id="f876" class="om on it lo b lp ov ls ow lv ox lz oy md oz mh or os ot ou bi translated"><strong class="lo iu"> <em class="mi">第六层——全连接卷积层</em> </strong></li><li id="c0d3" class="om on it lo b lp ov ls ow lv ox lz oy md oz mh or os ot ou bi translated"><strong class="lo iu"> <em class="mi">输出层——全连接Softmax输出层</em> </strong></li></ul><h2 id="0fa1" class="na kv it bd kw nm nn dn la no np dp le lv nq nr lg lz ns nt li md nu nv lk nw bi translated">AlexNet</h2><blockquote class="nx"><p id="d835" class="ny nz it bd oa ob oc od oe of og mh dk translated">AlexNet是一种卷积神经网络(CNN)架构的名称，由Alex Krizhevsky与Ilya Sutskever和Geoffrey Hinton合作设计，后者是Krizhevsky的博士顾问。</p></blockquote><h2 id="2de6" class="na kv it bd kw nm oh dn la no oi dp le lv oj nr lg lz ok nt li md ol nv lk nw bi translated">结构</h2><ul class=""><li id="afae" class="om on it lo b lp lq ls lt lv oo lz op md oq mh or os ot ou bi translated"><strong class="lo iu"> <em class="mi">第一层——卷积层</em> </strong></li><li id="aa30" class="om on it lo b lp ov ls ow lv ox lz oy md oz mh or os ot ou bi translated"><strong class="lo iu"> <em class="mi">第二层-第二卷积层</em> </strong></li><li id="2048" class="om on it lo b lp ov ls ow lv ox lz oy md oz mh or os ot ou bi translated"><strong class="lo iu"> <em class="mi">第三层——第三卷积层</em> </strong></li><li id="d637" class="om on it lo b lp ov ls ow lv ox lz oy md oz mh or os ot ou bi translated"><strong class="lo iu"> <em class="mi">第四层——第四卷积层</em> </strong></li><li id="56d1" class="om on it lo b lp ov ls ow lv ox lz oy md oz mh or os ot ou bi translated"><strong class="lo iu"> <em class="mi">第五层-第五卷积层</em> </strong></li><li id="e79b" class="om on it lo b lp ov ls ow lv ox lz oy md oz mh or os ot ou bi translated"><strong class="lo iu"> <em class="mi">第六层——全连通卷积层</em> </strong></li><li id="083c" class="om on it lo b lp ov ls ow lv ox lz oy md oz mh or os ot ou bi translated"><strong class="lo iu"> <em class="mi">第七层-第二全连通卷积层</em> </strong></li><li id="089f" class="om on it lo b lp ov ls ow lv ox lz oy md oz mh or os ot ou bi translated"><strong class="lo iu"> <em class="mi">八层——第三层全连通</em> </strong></li><li id="bf04" class="om on it lo b lp ov ls ow lv ox lz oy md oz mh or os ot ou bi translated"><strong class="lo iu"> <em class="mi">输出层-全连接Softmax输出层</em> </strong></li></ul><h2 id="5b3d" class="na kv it bd kw nm nn dn la no np dp le lv nq nr lg lz ns nt li md nu nv lk nw bi translated">VGG-16</h2><blockquote class="nx"><p id="8438" class="ny nz it bd oa ob oc od oe of og mh dk translated">V <!-- --> GG Net是牛津大学视觉几何小组(VGG)的Simonyan和Zisserman在2014年发明的一种预训练卷积神经网络(CNN)的名称。</p></blockquote><figure class="pb pc pd pe pf kn gh gi paragraph-image"><div role="button" tabindex="0" class="pg ph di pi bf pj"><div class="gh gi pa"><img src="../Images/8341e1385cf6673cc3f82350dac52073.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*q9ub2NZM3co9rfLVOUL1kg.png"/></div></div><figcaption class="kq kr gj gh gi ks kt bd b be z dk translated">图片由作者提供- Vgg-16结构</figcaption></figure><h2 id="7d2f" class="na kv it bd kw nm nn dn la no np dp le lv nq nr lg lz ns nt li md nu nv lk nw bi translated">初始网络</h2><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="pg ph di pi bf pj"><div class="gh gi pk"><img src="../Images/54aa05cc9426663ecfd6835ac5936c8b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*nAKVN07lL1ujrFoC"/></div></div><figcaption class="kq kr gj gh gi ks kt bd b be z dk translated">Christophe Hautier 在<a class="ae ng" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上拍摄的照片</figcaption></figure><p id="9f29" class="pw-post-body-paragraph lm ln it lo b lp mj ju lr ls mk jx lu lv ml lx ly lz mm mb mc md mn mf mg mh im bi translated">如果您无法决定要执行哪个卷积运算或池层，请执行所有操作，并将它们堆叠在一起，而不是执行其中一项。</p><p id="652f" class="pw-post-body-paragraph lm ln it lo b lp mj ju lr ls mk jx lu lv ml lx ly lz mm mb mc md mn mf mg mh im bi translated">如果你的问题是计算性的，那么使用瓶颈层。</p><h1 id="976d" class="ku kv it bd kw kx ky kz la lb lc ld le jz lf ka lg kc lh kd li kf lj kg lk ll bi translated">迁移学习</h1><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="pg ph di pi bf pj"><div class="gh gi pl"><img src="../Images/4375c84b8c82fb5e02f4cbc05177c331.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*VDoKmoCb2meIMrTq"/></div></div><figcaption class="kq kr gj gh gi ks kt bd b be z dk translated"><a class="ae ng" href="https://unsplash.com/@heftiba?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Toa Heftiba </a>在<a class="ae ng" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上拍摄的照片</figcaption></figure><p id="0c27" class="pw-post-body-paragraph lm ln it lo b lp mj ju lr ls mk jx lu lv ml lx ly lz mm mb mc md mn mf mg mh im bi translated">找另一个卷积深度学习网络，它用定义另一个问题，用预定义的softmax算法改变最后一层，这个算法是专门为你的例子定义的。假设在算法的最后，你有4到5个不同的东西要分类，然后完成你的代码。那会给你一个很好的结果。</p><h1 id="df48" class="ku kv it bd kw kx ky kz la lb lc ld le jz lf ka lg kc lh kd li kf lj kg lk ll bi translated">数据扩充</h1><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="pg ph di pi bf pj"><div class="gh gi pm"><img src="../Images/d5b8d6729cf5ac64cff683b828338f77.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*oZrIqSgiGaQFBOwk"/></div></div><figcaption class="kq kr gj gh gi ks kt bd b be z dk translated">汤米·邦德在<a class="ae ng" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上的照片</figcaption></figure><p id="08f6" class="pw-post-body-paragraph lm ln it lo b lp mj ju lr ls mk jx lu lv ml lx ly lz mm mb mc md mn mf mg mh im bi translated">这项技术用于提高计算机视觉系统的性能。</p><p id="8dd2" class="pw-post-body-paragraph lm ln it lo b lp mj ju lr ls mk jx lu lv ml lx ly lz mm mb mc md mn mf mg mh im bi translated">这种技术只是以不同的方式(镜像、裁剪、旋转、颜色偏移)复制您的数据，并将该数据添加到您的数据集中，并提高您的算法性能。</p><h1 id="1d16" class="ku kv it bd kw kx ky kz la lb lc ld le jz lf ka lg kc lh kd li kf lj kg lk ll bi translated">结论</h1><p id="33ab" class="pw-post-body-paragraph lm ln it lo b lp lq ju lr ls lt jx lu lv lw lx ly lz ma mb mc md me mf mg mh im bi translated">感谢您到目前为止阅读我的文章。</p><p id="070e" class="pw-post-body-paragraph lm ln it lo b lp mj ju lr ls mk jx lu lv ml lx ly lz mm mb mc md mn mf mg mh im bi translated">即使在计算机视觉中存在许多其他术语，正如我一直做的那样，我将把其他术语留给那篇文章的第二部分。</p></div><div class="ab cl mo mp hx mq" role="separator"><span class="mr bw bk ms mt mu"/><span class="mr bw bk ms mt mu"/><span class="mr bw bk ms mt"/></div><div class="im in io ip iq"><p id="5166" class="pw-post-body-paragraph lm ln it lo b lp mj ju lr ls mk jx lu lv ml lx ly lz mm mb mc md mn mf mg mh im bi translated">可以看一下那篇关于<a class="ae ng" rel="noopener ugc nofollow" target="_blank" href="/machine-learning-a-z-briefly-explained-4ff86bd81e3a">机器学习</a>、<a class="ae ng" rel="noopener ugc nofollow" target="_blank" href="/statistics-for-machine-learning-a-z-66a82fbf2622">统计</a>、<a class="ae ng" href="https://medium.datadriveninvestor.com/linear-algebra-a-z-for-machine-learning-68dadcd0b757" rel="noopener ugc nofollow" target="_blank">线性代数</a>、<a class="ae ng" href="https://medium.com/mlearning-ai/classification-a-z-briefly-explained-25ca811ab4e4" rel="noopener">分类</a>、<a class="ae ng" href="https://medium.com/towards-artificial-intelligence/deep-learning-a-z-briefly-explained-9026028f1281" rel="noopener">深度学习</a>、<a class="ae ng" rel="noopener ugc nofollow" target="_blank" href="/regression-a-z-briefly-explained-618e5d5c89f8">和回归</a>的结构化文章。</p></div><div class="ab cl mo mp hx mq" role="separator"><span class="mr bw bk ms mt mu"/><span class="mr bw bk ms mt mu"/><span class="mr bw bk ms mt"/></div><div class="im in io ip iq"><p id="2756" class="pw-post-body-paragraph lm ln it lo b lp mj ju lr ls mk jx lu lv ml lx ly lz mm mb mc md mn mf mg mh im bi translated">感谢您到目前为止阅读我的文章。</p></div><div class="ab cl mo mp hx mq" role="separator"><span class="mr bw bk ms mt mu"/><span class="mr bw bk ms mt mu"/><span class="mr bw bk ms mt"/></div><div class="im in io ip iq"><p id="d5c4" class="pw-post-body-paragraph lm ln it lo b lp mj ju lr ls mk jx lu lv ml lx ly lz mm mb mc md mn mf mg mh im bi translated"><strong class="lo iu"> <em class="mi">如果你也想在将来收到关于那类文章的电子邮件，并阅读&amp;下载免费备忘单，请在此订阅我的电子邮件列表</em> </strong> <a class="ae ng" href="https://gencay.ck.page/" rel="noopener ugc nofollow" target="_blank"> <strong class="lo iu"> <em class="mi">。</em> </strong> </a></p><p id="08ae" class="pw-post-body-paragraph lm ln it lo b lp mj ju lr ls mk jx lu lv ml lx ly lz mm mb mc md mn mf mg mh im bi translated">一般来说，我尽量每周发两封电子邮件。T25】</p></div><div class="ab cl mo mp hx mq" role="separator"><span class="mr bw bk ms mt mu"/><span class="mr bw bk ms mt mu"/><span class="mr bw bk ms mt"/></div><div class="im in io ip iq"><p id="8063" class="pw-post-body-paragraph lm ln it lo b lp mj ju lr ls mk jx lu lv ml lx ly lz mm mb mc md mn mf mg mh im bi translated"><strong class="lo iu"> <em class="mi">如果你还不是Medium的一员，渴望通过阅读来学习，这里是我推荐的</em> </strong> <a class="ae ng" href="https://medium.com/@geencay/membership" rel="noopener"> <strong class="lo iu"> <em class="mi">链接。</em>T34</strong></a></p><blockquote class="nx"><p id="197b" class="ny nz it bd oa ob oc od oe of og mh dk translated">“机器学习是人类需要做出的最后一项发明。”</p><p id="3574" class="ny nz it bd oa ob oc od oe of og mh dk translated">尼克·博斯特罗姆</p></blockquote></div></div>    
</body>
</html>