<html>
<head>
<title>Automatic Moderator for StackOverflow Questions</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">StackOverflow问题的自动主持人</h1>
<blockquote>原文：<a href="https://pub.towardsai.net/automatic-moderator-for-stackoverflow-questions-707cef5fe656?source=collection_archive---------2-----------------------#2021-02-01">https://pub.towardsai.net/automatic-moderator-for-stackoverflow-questions-707cef5fe656?source=collection_archive---------2-----------------------#2021-02-01</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><h2 id="6680" class="io ip iq bd b dl ir is it iu iv iw dk ix translated" aria-label="kicker paragraph"><a class="ae ep" href="https://towardsai.net/p/category/nlp" rel="noopener ugc nofollow" target="_blank">自然语言处理</a>，<a class="ae ep" href="https://towardsai.net/p/category/programming" rel="noopener ugc nofollow" target="_blank">编程</a></h2><div class=""/><figure class="gl gn jx jy jz ka gh gi paragraph-image"><div role="button" tabindex="0" class="kb kc di kd bf ke"><div class="gh gi jw"><img src="../Images/2c5b7764c300a6b40224c3be241fc58e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*dChtejKg8axDvUfQ8lMs8Q.png"/></div></div></figure><blockquote class="kh ki kj"><p id="b25c" class="kk kl km kn b ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li ij bi translated">在本文中，我们将尝试建立一个机器学习模型，该模型将自动预测人所提问题的质量，并相应地为其分配标签。</p></blockquote><p id="6658" class="pw-post-body-paragraph kk kl iq kn b ko kp kq kr ks kt ku kv lj kx ky kz lk lb lc ld ll lf lg lh li ij bi translated">如果你是机器学习新手，还可以。我会试着用初学者友好的语言详细阐述每一步。这是一个展示你的技能的伟大项目，因为我已经使用了大多数任务的图书馆，这将是你很容易向别人解释这项工作。</p><p id="3058" class="pw-post-body-paragraph kk kl iq kn b ko kp kq kr ks kt ku kv lj kx ky kz lk lb lc ld ll lf lg lh li ij bi translated">由于问题是由语言(单词/句子)组成的，所以是自然语言处理(<strong class="kn ja"> NLP </strong>)问题。NLP只是处理人类语言(语音/文本)的人工智能的一部分。Google translator是NLP最好的例子之一。</p><p id="dac7" class="pw-post-body-paragraph kk kl iq kn b ko kp kq kr ks kt ku kv lj kx ky kz lk lb lc ld ll lf lg lh li ij bi translated">现在，我们清楚了NLP和我们的问题陈述，让我们直接跳到编码部分😎。</p><h1 id="fe54" class="lm ln iq bd lo lp lq lr ls lt lu lv lw lx ly lz ma mb mc md me mf mg mh mi mj bi translated">使用的数据集:-</h1><p id="ad3f" class="pw-post-body-paragraph kk kl iq kn b ko mk kq kr ks ml ku kv lj mm ky kz lk mn lc ld ll mo lg lh li ij bi translated">我已经使用了数据集“<a class="ae mp" href="https://www.kaggle.com/imoore/60k-stack-overflow-questions-with-quality-rate" rel="noopener ugc nofollow" target="_blank"> 60k栈溢出问题与质量评级</a>”，该数据集在<strong class="kn ja"> Kaggle </strong>上可用。质量分为三类:-</p><ul class=""><li id="6c26" class="mq mr iq kn b ko kp ks kt lj ms lk mt ll mu li mv mw mx my bi translated"><strong class="kn ja">LQ _关闭</strong> =被社区关闭的低质量帖子</li><li id="d5de" class="mq mr iq kn b ko mz ks na lj nb lk nc ll nd li mv mw mx my bi translated"><strong class="kn ja">LQ _编辑</strong> =低质量的帖子在经过一些修改后仍然开放。</li><li id="354c" class="mq mr iq kn b ko mz ks na lj nb lk nc ll nd li mv mw mx my bi translated"><strong class="kn ja">总部</strong> =总分30+的优质岗位</li></ul><p id="c443" class="pw-post-body-paragraph kk kl iq kn b ko kp kq kr ks kt ku kv lj kx ky kz lk lb lc ld ll lf lg lh li ij bi translated">但是那里的数据集分为训练和测试。如果你想要一个单独的CSV文件，你可以在我的<a class="ae mp" href="https://github.com/PushkaraSharma/articles_codes/tree/master/StackOverflow%20Moderator" rel="noopener ugc nofollow" target="_blank"><strong class="kn ja">GitHub</strong></a><strong class="kn ja"/>repo中得到。</p><h1 id="de09" class="lm ln iq bd lo lp lq lr ls lt lu lv lw lx ly lz ma mb mc md me mf mg mh mi mj bi translated">先决条件:-</h1><p id="d31f" class="pw-post-body-paragraph kk kl iq kn b ko mk kq kr ks ml ku kv lj mm ky kz lk mn lc ld ll mo lg lh li ij bi translated">我假设您熟悉<strong class="kn ja"> <em class="km"> python </em> </strong>，并且已经在您的系统中安装了<strong class="kn ja"> <em class="km"> python 3 </em> </strong>。这个教程我用了一个<strong class="kn ja"> <em class="km"> jupyter笔记本</em> </strong>。你可以使用你喜欢的<strong class="kn ja"> IDE </strong>。</p><h1 id="368c" class="lm ln iq bd lo lp lq lr ls lt lu lv lw lx ly lz ma mb mc md me mf mg mh mi mj bi translated">安装所需的库</h1><p id="5013" class="pw-post-body-paragraph kk kl iq kn b ko mk kq kr ks ml ku kv lj mm ky kz lk mn lc ld ll mo lg lh li ij bi translated">对于这个项目，您需要在python中安装以下包。如果没有安装，可以直接使用<code class="fe ne nf ng nh b">pip install PackageName</code>。尽管这些库大多内置于anaconda套件中。</p><ul class=""><li id="6c09" class="mq mr iq kn b ko kp ks kt lj ms lk mt ll mu li mv mw mx my bi translated"><strong class="kn ja">熊猫</strong>——用于数据分析和数据操作</li><li id="8493" class="mq mr iq kn b ko mz ks na lj nb lk nc ll nd li mv mw mx my bi translated"><strong class="kn ja"> matplotlib </strong> —用于创建基本图</li><li id="c4f4" class="mq mr iq kn b ko mz ks na lj nb lk nc ll nd li mv mw mx my bi translated"><strong class="kn ja">seaborn</strong>——用于创造更吸引人的情节</li><li id="2f4d" class="mq mr iq kn b ko mz ks na lj nb lk nc ll nd li mv mw mx my bi translated"><strong class="kn ja"> re </strong>(正则表达式)—用于检查匹配的字符串</li><li id="ea05" class="mq mr iq kn b ko mz ks na lj nb lk nc ll nd li mv mw mx my bi translated"><strong class="kn ja"> nltk </strong> —用于执行自然语言处理任务。</li><li id="d4bd" class="mq mr iq kn b ko mz ks na lj nb lk nc ll nd li mv mw mx my bi translated"><strong class="kn ja"> sklearn </strong> —用于拆分和矢量化数据(这就是我们所使用的)</li><li id="bc27" class="mq mr iq kn b ko mz ks na lj nb lk nc ll nd li mv mw mx my bi translated"><strong class="kn ja"> xgboost </strong> —集成机器学习算法</li></ul><h1 id="bd6c" class="lm ln iq bd lo lp lq lr ls lt lu lv lw lx ly lz ma mb mc md me mf mg mh mi mj bi translated">开始编码吧！</h1><p id="77c1" class="pw-post-body-paragraph kk kl iq kn b ko mk kq kr ks ml ku kv lj mm ky kz lk mn lc ld ll mo lg lh li ij bi translated">在这里，首先我们必须导入我们将使用的所有库。熊猫将被用来操作我们的数据集。Matplotlib 将帮助我们创建简单的图表，如条形图。Seaborn 会创造一些高级好看的剧情。<strong class="kn ja"> <em class="km"> re </em> </strong>(正则表达式)用于删除问题中不想要的文本。<strong class="kn ja"> nltk </strong>(自然语言工具包)这里只用来获取停用词(像<code class="fe ne nf ng nh b">is,the,of</code>这样对我们的模型没有贡献的词)。这里的最后一行用于下载<strong class="kn ja">停用词</strong>。</p><pre class="ni nj nk nl gt nm nh nn no aw np bi"><span id="b49d" class="nq ln iq nh b gy nr ns l nt nu">import pandas as pd<br/>import matplotlib.pyplot as plt<br/>import seaborn as sns<br/>import re<br/>import nltk<br/>nltk.download('stopwords')</span></pre><figure class="ni nj nk nl gt ka gh gi paragraph-image"><div class="gh gi nv"><img src="../Images/23f3ea478726b49d8773c7a2f054b2d5.png" data-original-src="https://miro.medium.com/v2/resize:fit:1070/format:webp/1*OvbtRbGfXgkkpbKslqDeZA.png"/></div></figure><p id="5b19" class="pw-post-body-paragraph kk kl iq kn b ko kp kq kr ks kt ku kv lj kx ky kz lk lb lc ld ll lf lg lh li ij bi translated">现在，我们已经通过加载数据集简单地创建了数据帧<code class="fe ne nf ng nh b">df</code>。作为一个好的实践，我们打印出的数据帧的形状是<strong class="kn ja"> (60000，7) </strong>。然后我们打印了数据帧的前5行。</p><pre class="ni nj nk nl gt nm nh nn no aw np bi"><span id="7743" class="nq ln iq nh b gy nr ns l nt nu">df = pd.read_csv("data.csv")<br/>print(df.shape)</span><span id="cccc" class="nq ln iq nh b gy nw ns l nt nu">df.head()</span></pre><figure class="ni nj nk nl gt ka gh gi paragraph-image"><div role="button" tabindex="0" class="kb kc di kd bf ke"><div class="gh gi nx"><img src="../Images/35cc27dee5d66c3a2903d83c254bf030.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*DhPr6ByXX35F9UyWiyD1yw.png"/></div></div></figure><p id="d094" class="pw-post-body-paragraph kk kl iq kn b ko kp kq kr ks kt ku kv lj kx ky kz lk lb lc ld ll lf lg lh li ij bi translated">数据帧中有<strong class="kn ja"> 7 </strong>列，但我们只对<strong class="kn ja">标题</strong>、<strong class="kn ja">正文、</strong>和<strong class="kn ja"> y </strong>(标签)感兴趣。因此，我们简单地删除了分类任务不需要的列。</p><pre class="ni nj nk nl gt nm nh nn no aw np bi"><span id="be43" class="nq ln iq nh b gy nr ns l nt nu">df = df.drop(['Id','Tags','CreationDate','Unnamed: 0'],axis=1)<br/>df.head()</span></pre><figure class="ni nj nk nl gt ka gh gi paragraph-image"><div role="button" tabindex="0" class="kb kc di kd bf ke"><div class="gh gi ny"><img src="../Images/18366144fd16507d1a1861ea582d66c7.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*kF6vKQMN0oAZbcugrn8Yyw.png"/></div></div></figure><p id="5db3" class="pw-post-body-paragraph kk kl iq kn b ko kp kq kr ks kt ku kv lj kx ky kz lk lb lc ld ll lf lg lh li ij bi translated">现在，我们想对我们的数据进行一些探索性分析。因此，我们提取了标题、正文中的字数，以及两者的总字数。然后，我们打印了我们的数据框架，正如你从下面的截图中看到的。</p><pre class="ni nj nk nl gt nm nh nn no aw np bi"><span id="0a49" class="nq ln iq nh b gy nr ns l nt nu">#Number Of words in Selected Text<br/>df['Num_words_body'] = df['Body'].apply(lambda x:len(str(x).split()))<br/>#Number Of words in main text<br/>df['Num_words_title'] = df['Title'].apply(lambda x:len(str(x).split())) <br/>#Total  Number of words text and Selected Text<br/>df['Total_words'] = abs(df['Num_words_body'] + df['Num_words_title'])</span><span id="626e" class="nq ln iq nh b gy nw ns l nt nu">df.head()</span></pre><figure class="ni nj nk nl gt ka gh gi paragraph-image"><div role="button" tabindex="0" class="kb kc di kd bf ke"><div class="gh gi nx"><img src="../Images/20fc4aac0ae6407b6c3feb2bd374dc56.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*MtONdzWY2afItHzq8HXmug.png"/></div></div></figure><p id="0b67" class="pw-post-body-paragraph kk kl iq kn b ko kp kq kr ks kt ku kv lj kx ky kz lk lb lc ld ll lf lg lh li ij bi translated">可视化在分析中非常重要。在这里，首先我们定义我们的数字的大小。然后我们为<code class="fe ne nf ng nh b">Num_words_body</code>和<code class="fe ne nf ng nh b">Num_words_title</code>定义KDE图(核密度估计)。Kdeplot用于可视化连续变量的概率密度。最后用<code class="fe ne nf ng nh b">plt.xlim</code>设置x轴的x极限，即<strong class="kn ja"> 300 </strong></p><p id="be94" class="pw-post-body-paragraph kk kl iq kn b ko kp kq kr ks kt ku kv lj kx ky kz lk lb lc ld ll lf lg lh li ij bi translated">这里的情节暗示了两件事。首先，与正文相比，标题的长度很短(这是显而易见的),其次，标题的密度显示大多数标题大约有10个单词，正文的密度显示大多数正文大约有50个单词。</p><pre class="ni nj nk nl gt nm nh nn no aw np bi"><span id="1af7" class="nq ln iq nh b gy nr ns l nt nu">plt.figure(figsize=(12,6))<br/>p = sns.kdeplot(df['Num_words_body'],shade=True).set_title('Distribution of Body text')<br/>p = sns.kdeplot(df['Num_words_title'],shade=True).set_title('Distribution of Body text')<br/>plt.xlim(0,300)</span></pre><figure class="ni nj nk nl gt ka gh gi paragraph-image"><div role="button" tabindex="0" class="kb kc di kd bf ke"><div class="gh gi nz"><img src="../Images/7853a85358fdf2c7b4e434a5545e2c34.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*aV5oDv8cGt-IoXe6MV5V1w.png"/></div></div></figure><p id="3b86" class="pw-post-body-paragraph kk kl iq kn b ko kp kq kr ks kt ku kv lj kx ky kz lk lb lc ld ll lf lg lh li ij bi translated">现在，让我们看看基于类别的总字数分布，即<strong class="kn ja"> HQ </strong>、<strong class="kn ja"> LQ_CLOSE </strong>、<strong class="kn ja"> LQ_EDIT </strong>。这里，我们也使用了相同的kdeplot来做同样的事情。正如我们从下图中看到的，每个类别的分布看起来几乎相似，大多数问题的总长度一般在80-90个单词左右。</p><pre class="ni nj nk nl gt nm nh nn no aw np bi"><span id="56f7" class="nq ln iq nh b gy nr ns l nt nu">plt.figure(figsize=(12,6))<br/>p1=sns.kdeplot(df[df['Y']=='HQ']['Total_words'], shade=True,).set_title('Distribution of Total No.Of words Per Category')<br/>p2=sns.kdeplot(df[df['Y']=='LQ_CLOSE']['Total_words'], shade=True)<br/>p2=sns.kdeplot(df[df['Y']=='LQ_EDIT']['Total_words'], shade=True)<br/>plt.legend(labels=['HQ','LQ_CLOSE','LQ_EDIT'])<br/>plt.xlim(-20,500)</span></pre><figure class="ni nj nk nl gt ka gh gi paragraph-image"><div role="button" tabindex="0" class="kb kc di kd bf ke"><div class="gh gi oa"><img src="../Images/d98b41305ea04f8df17ad21ce527fe36.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*SHTbULTcl5DizUg7gs1GFA.png"/></div></div></figure><p id="a88c" class="pw-post-body-paragraph kk kl iq kn b ko kp kq kr ks kt ku kv lj kx ky kz lk lb lc ld ll lf lg lh li ij bi translated">现在我们将把目标标签转换成数值。虽然有各种各样的技术可以做到这一点，如一个热点编码和标签编码，但因为只有3个类别(LQ _关闭，LQ _编辑，总部)，我们可以简单地使用<code class="fe ne nf ng nh b">map</code>函数来完成这项任务。你可以在下面的截图中看到Y列的值变成了数字。</p><pre class="ni nj nk nl gt nm nh nn no aw np bi"><span id="db8d" class="nq ln iq nh b gy nr ns l nt nu">df['Y'] = df['Y'].map({'LQ_CLOSE':0,'LQ_EDIT':1,'HQ':2})<br/>df.head()</span></pre><figure class="ni nj nk nl gt ka gh gi paragraph-image"><div role="button" tabindex="0" class="kb kc di kd bf ke"><div class="gh gi ob"><img src="../Images/ba1539c5dd27727a90f46e14af9bb573.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*t3GO3i7rCZHiVAxzP5V48w.png"/></div></div></figure><p id="745c" class="pw-post-body-paragraph kk kl iq kn b ko kp kq kr ks kt ku kv lj kx ky kz lk lb lc ld ll lf lg lh li ij bi translated">现在，让我们检查在我们的数据帧中是否有任何空值或条目。在空值产生任何问题之前检查它们是一种好的做法。我们应该在早期阶段执行这项任务。</p><pre class="ni nj nk nl gt nm nh nn no aw np bi"><span id="497d" class="nq ln iq nh b gy nr ns l nt nu">df.isnull().sum()</span></pre><figure class="ni nj nk nl gt ka gh gi paragraph-image"><div class="gh gi oc"><img src="../Images/bce4ab1bceaffdbb178d56c965d23f94.png" data-original-src="https://miro.medium.com/v2/resize:fit:384/format:webp/1*a0mCbXs9Aj8eCI29r5UwFQ.png"/></div></figure><p id="e7ba" class="pw-post-body-paragraph kk kl iq kn b ko kp kq kr ks kt ku kv lj kx ky kz lk lb lc ld ll lf lg lh li ij bi translated">现在，我们将绘制条形图，显示每个标签的问题数量。我们在这里使用了<code class="fe ne nf ng nh b">matplotlib.pyplot</code>,结果发现每个类别的问题数量相等，即<strong class="kn ja"> 20000 </strong></p><pre class="ni nj nk nl gt nm nh nn no aw np bi"><span id="f1ab" class="nq ln iq nh b gy nr ns l nt nu">values = [len(df[df['Y']==0]),len(df[df['Y']==1]),len(df[df['Y']==2])]<br/>plt.bar(['LQ_CLOSE','LQ_EDIT','HQ'],values)<br/>plt.show()</span></pre><figure class="ni nj nk nl gt ka gh gi paragraph-image"><div role="button" tabindex="0" class="kb kc di kd bf ke"><div class="gh gi od"><img src="../Images/773427cd8f45c1fc0796d84c2be41443.png" data-original-src="https://miro.medium.com/v2/resize:fit:776/format:webp/1*kTfSyGi9tREuJHU1MZ8jBQ.png"/></div></div></figure><p id="35d9" class="pw-post-body-paragraph kk kl iq kn b ko kp kq kr ks kt ku kv lj kx ky kz lk lb lc ld ll lf lg lh li ij bi translated">这里，我们将标题和正文合并在一个名为<code class="fe ne nf ng nh b">All_text</code>的列中。之后，我们删除标题和正文列。</p><pre class="ni nj nk nl gt nm nh nn no aw np bi"><span id="e491" class="nq ln iq nh b gy nr ns l nt nu">df['All_text'] = df['Title']+' '+df['Body']<br/>new_df = df.copy()<br/>new_df = new_df.drop(['Title','Body'],axis=1)<br/>new_df.head()</span></pre><figure class="ni nj nk nl gt ka gh gi paragraph-image"><div class="gh gi oe"><img src="../Images/7e2beeb15f1f1846aeb7711d6374579a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1338/format:webp/1*7Vif4jPrnw3-2T1kQRLVFA.png"/></div></figure><p id="9e4c" class="pw-post-body-paragraph kk kl iq kn b ko kp kq kr ks kt ku kv lj kx ky kz lk lb lc ld ll lf lg lh li ij bi translated">我们存储了英语<strong class="kn ja">停用词</strong>(即<code class="fe ne nf ng nh b">of</code> <code class="fe ne nf ng nh b">the</code> <code class="fe ne nf ng nh b">to</code>等。)在<code class="fe ne nf ng nh b">stop_words</code>变量中。之后，我们定义了函数<code class="fe ne nf ng nh b">data_cleaning</code>，它接受一个字符串(问题)作为参数。在函数中，我们首先将数据转换成小写，然后删除除字母以外的任何字符。之后，数据被拆分并存储在一个名为<code class="fe ne nf ng nh b">data</code>的列表中。然后我们从列表中移除停用词，并使用<strong class="kn ja"> join </strong>将其转换回字符串。最后，我们返回清理后的数据字符串。</p><pre class="ni nj nk nl gt nm nh nn no aw np bi"><span id="500d" class="nq ln iq nh b gy nr ns l nt nu">from nltk.corpus import stopwords</span><span id="4540" class="nq ln iq nh b gy nw ns l nt nu">stop_words = stopwords.words('english')</span><span id="8a0d" class="nq ln iq nh b gy nw ns l nt nu">def data_cleaning(data):<br/>    data = data.lower()<br/>    data = re.sub(r'[^(a-zA-Z)\s]','',data)<br/>    data = data.split()<br/>    temp = []<br/>    for i in data:<br/>        if i not in stop_words:<br/>            temp.append(i)<br/>    data = ' '.join(temp)<br/>    return data</span></pre><p id="a063" class="pw-post-body-paragraph kk kl iq kn b ko kp kq kr ks kt ku kv lj kx ky kz lk lb lc ld ll lf lg lh li ij bi translated">这里，我们刚刚将<code class="fe ne nf ng nh b">data_cleaning</code>函数应用于<code class="fe ne nf ng nh b">All_text</code>的所有值。</p><pre class="ni nj nk nl gt nm nh nn no aw np bi"><span id="7bcb" class="nq ln iq nh b gy nr ns l nt nu">new_df['All_text'] = new_df['All_text'].apply(data_cleaning)<br/>new_df['All_text']</span></pre><p id="7dc1" class="pw-post-body-paragraph kk kl iq kn b ko kp kq kr ks kt ku kv lj kx ky kz lk lb lc ld ll lf lg lh li ij bi translated">我们从<code class="fe ne nf ng nh b">sklearn.model_selection</code>导入了<code class="fe ne nf ng nh b">train_test_split</code>，以5:1的比例将我们的数据分成训练集和测试集。正如您在下面的截图中看到的，培训数据由<strong class="kn ja"> 48，000个</strong>问题组成，测试数据由<strong class="kn ja"> 12，000个</strong>问题组成。</p><pre class="ni nj nk nl gt nm nh nn no aw np bi"><span id="5e19" class="nq ln iq nh b gy nr ns l nt nu">from sklearn.model_selection import train_test_split</span><span id="977f" class="nq ln iq nh b gy nw ns l nt nu">x_train,x_test,y_train,y_test = train_test_split(new_df['All_text'],new_df['Y'],test_size=0.20)<br/>print("X_train Size : ",x_train.size," Y_train Size : ",y_train.size)<br/>print("X_test Size : ",x_test.size," Y_test Size : ",y_test.size)</span></pre><figure class="ni nj nk nl gt ka gh gi paragraph-image"><div class="gh gi of"><img src="../Images/e77f25db2cb7a54a64f5efdaf39e9a72.png" data-original-src="https://miro.medium.com/v2/resize:fit:794/format:webp/1*ghulzFXNe89afsTvvIOfTg.png"/></div></figure><p id="4aa6" class="pw-post-body-paragraph kk kl iq kn b ko kp kq kr ks kt ku kv lj kx ky kz lk lb lc ld ll lf lg lh li ij bi translated">现在，我们将矢量化我们的数据。<strong class="kn ja">向量化</strong>是将单词或短语转换成相应的实数向量的过程，用于查找单词预测。为此，我们使用了代表“<em class="km">术语频率—反向文档</em>”频率的<code class="fe ne nf ng nh b">TfidfVectorizer</code>，它是分配给每个单词的结果分数的组成部分。</p><ul class=""><li id="3753" class="mq mr iq kn b ko kp ks kt lj ms lk mt ll mu li mv mw mx my bi translated"><strong class="kn ja">词频</strong>:总结给定单词在文档中出现的频率。</li><li id="1815" class="mq mr iq kn b ko mz ks na lj nb lk nc ll nd li mv mw mx my bi translated"><strong class="kn ja">逆文档频率</strong>:这将缩小文档中大量出现的单词。</li></ul><p id="fde1" class="pw-post-body-paragraph kk kl iq kn b ko kp kq kr ks kt ku kv lj kx ky kz lk lb lc ld ll lf lg lh li ij bi translated">不涉及数学，<strong class="kn ja"> TF-IDF </strong>是词频分数，试图突出更有趣的词，例如，在一个文档中频繁出现但不跨文档出现。</p><p id="9397" class="pw-post-body-paragraph kk kl iq kn b ko kp kq kr ks kt ku kv lj kx ky kz lk lb lc ld ll lf lg lh li ij bi translated">看这个<a class="ae mp" href="https://www.quora.com/How-does-TfidfVectorizer-work-in-laymans-terms" rel="noopener ugc nofollow" target="_blank">回答</a>了解更多关于TfidfVectorizer的内容。</p><pre class="ni nj nk nl gt nm nh nn no aw np bi"><span id="f2d9" class="nq ln iq nh b gy nr ns l nt nu">from sklearn.feature_extraction.text import TfidfVectorizer<br/>vec = TfidfVectorizer()<br/>x_train = vec.fit_transform(x_train)<br/>x_test = vec.transform(x_test)</span></pre><p id="9c8b" class="pw-post-body-paragraph kk kl iq kn b ko kp kq kr ks kt ku kv lj kx ky kz lk lb lc ld ll lf lg lh li ij bi translated">现在是我们训练模型的时候了。为此，我使用了<strong class="kn ja"> xgboost </strong>。Xgboost (Xtreme Gradient Boost)是一种基于决策树的机器学习算法，它也使用了<strong class="kn ja">梯度增强</strong>技术。这是最好的快速算法之一，在处理非结构化数据(图像/文本)时表现良好。但是这还不足以理解这个算法的内部工作原理。为此，你必须理解像<strong class="kn ja">装袋</strong>、<strong class="kn ja">助推</strong>、<strong class="kn ja">决策树</strong>这样的概念。所以，读完这篇文章后，我会建议你谷歌一下关于xgboost的更多信息。</p><pre class="ni nj nk nl gt nm nh nn no aw np bi"><span id="d7e4" class="nq ln iq nh b gy nr ns l nt nu">from xgboost import XGBClassifier<br/>xgb = XGBClassifier()<br/>xgb.fit(x_train,y_train)</span></pre><figure class="ni nj nk nl gt ka gh gi paragraph-image"><div role="button" tabindex="0" class="kb kc di kd bf ke"><div class="gh gi og"><img src="../Images/ff68d2c24ea9b23370f181a9e93ca3ef.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*KiPuysyUEzf-_DjvS5oiMQ.png"/></div></div></figure><p id="5a0a" class="pw-post-body-paragraph kk kl iq kn b ko kp kq kr ks kt ku kv lj kx ky kz lk lb lc ld ll lf lg lh li ij bi translated">我们的模型已经训练好了，现在是时候进行预测并检查我们模型的<strong class="kn ja">准确性</strong>了。这里，我们简单地使用了<code class="fe ne nf ng nh b">xgboost</code>提供的<code class="fe ne nf ng nh b">predict()</code>函数来进行预测，并将它们存储在名为<code class="fe ne nf ng nh b">predictions</code>的变量中。为了检查开发模型的性能，我们使用了<code class="fe ne nf ng nh b">accuracy_score</code>来计算正确预测的<strong class="kn ja"> % </strong>。(我们使用这个性能矩阵是因为我们有一个平衡的数据集)。我们模型的准确率是<strong class="kn ja"> 87.56% </strong>。</p><pre class="ni nj nk nl gt nm nh nn no aw np bi"><span id="28f2" class="nq ln iq nh b gy nr ns l nt nu">from sklearn.metrics import accuracy_score,plot_confusion_matrix<br/>predictions = xgb.predict(x_test)<br/>acc = accuracy_score(predictions,y_test)<br/>acc</span></pre><p id="944c" class="pw-post-body-paragraph kk kl iq kn b ko kp kq kr ks kt ku kv lj kx ky kz lk lb lc ld ll lf lg lh li ij bi translated">为了获得更多关于我们模型的信息以及它的预测哪里出错了，我们可以绘制出<strong class="kn ja">混淆矩阵</strong>。从图中可以看出，标签<strong class="kn ja">1</strong>(LQ _编辑)几乎是正确的，只有<strong class="kn ja"> 8 </strong>的预测是错误的。对于标签<strong class="kn ja"> 0 </strong>、<strong class="kn ja"> 2 </strong> (LQ_CLOSE，HQ)分别有<strong class="kn ja"> 686 </strong>和<strong class="kn ja"> 764 </strong>个错误预测。</p><pre class="ni nj nk nl gt nm nh nn no aw np bi"><span id="6f80" class="nq ln iq nh b gy nr ns l nt nu">plot_confusion_matrix(xgb,x_test,y_test)</span></pre><figure class="ni nj nk nl gt ka gh gi paragraph-image"><div class="gh gi oh"><img src="../Images/8d0e46c91f55dd92d3cd5e353e87c9b2.png" data-original-src="https://miro.medium.com/v2/resize:fit:638/format:webp/1*WdDdUr_Oo-59o3RuQe59WQ.png"/></div></figure><h1 id="5cdc" class="lm ln iq bd lo lp lq lr ls lt lu lv lw lx ly lz ma mb mc md me mf mg mh mi mj bi translated">预言；预测；预告</h1><p id="99d0" class="pw-post-body-paragraph kk kl iq kn b ko mk kq kr ks ml ku kv lj mm ky kz lk mn lc ld ll mo lg lh li ij bi translated">现在让我们预测一下用户提出的一个问题的质量标签。这里我们有问题的标题和主体，对其质量进行预测。</p><p id="5dd7" class="pw-post-body-paragraph kk kl iq kn b ko kp kq kr ks kt ku kv lj kx ky kz lk lb lc ld ll lf lg lh li ij bi translated"><strong class="kn ja">注</strong> :-我已经切掉了身体的实际长度，全身用于预测，可以在Github上传的一个笔记本里找到。</p><pre class="ni nj nk nl gt nm nh nn no aw np bi"><span id="b856" class="nq ln iq nh b gy nr ns l nt nu">title = "Pod install displaying error in cocoapods version 1.0.0.beta.1"<br/>body = """&lt;p&gt;My podfile was working but after updating to cocoapods version 1.0.0.beta.1&lt;/p&gt;\n\n&lt;p&gt;pod install displays following error&lt;/p&gt;\n\n&lt;pre&gt;&lt;code&gt;MacBook-Pro:iOS-TuneIn home$ pod install\nFully deintegrating due to major version update\nDeleted 1 'Copy Pods Resources' build phases.\nDeleted 1 'Check Pods Manifest.lock' build phases...."""<br/></span></pre><p id="f1a7" class="pw-post-body-paragraph kk kl iq kn b ko kp kq kr ks kt ku kv lj kx ky kz lk lb lc ld ll lf lg lh li ij bi translated">在这里，我们只需遵循我们之前讨论过的相同过程。标题和正文合并在一起，使用<code class="fe ne nf ng nh b">data_cleaning</code>功能清理文本。执行矢量化，然后进行预测。这个问题的实际类别是<strong class="kn ja"> HQ </strong>，预测类别是2(对应于<strong class="kn ja"> HQ </strong>)。</p><pre class="ni nj nk nl gt nm nh nn no aw np bi"><span id="6681" class="nq ln iq nh b gy nr ns l nt nu">All_text_testing = title+" "+body<br/>All_text_testing = data_cleaning(All_text_testing)<br/>All_text_testing_vector = vec.transform([All_text_testing])<br/>prediction = xgb.predict(All_text_testing_vector)<br/>prediction</span></pre><figure class="ni nj nk nl gt ka gh gi paragraph-image"><div class="gh gi oi"><img src="../Images/fd8ed0b021a544cdb546fcd98e481c52.png" data-original-src="https://miro.medium.com/v2/resize:fit:646/format:webp/1*mIlqSmpzYKnWvAq3-B1U3A.png"/></div><figcaption class="oj ok gj gh gi ol om bd b be z dk translated">预测类别</figcaption></figure><h1 id="cebb" class="lm ln iq bd lo lp lq lr ls lt lu lv lw lx ly lz ma mb mc md me mf mg mh mi mj bi translated">结论</h1><p id="4a28" class="pw-post-body-paragraph kk kl iq kn b ko mk kq kr ks ml ku kv lj mm ky kz lk mn lc ld ll mo lg lh li ij bi translated">因此，我们成功开发了预测StackOverflow问题质量的机器学习模型，准确率为<strong class="kn ja"> 87.5% </strong></p><h1 id="62c8" class="lm ln iq bd lo lp lq lr ls lt lu lv lw lx ly lz ma mb mc md me mf mg mh mi mj bi translated">未来的工作</h1><p id="14cc" class="pw-post-body-paragraph kk kl iq kn b ko mk kq kr ks ml ku kv lj mm ky kz lk mn lc ld ll mo lg lh li ij bi translated">仍然有一些方法可以改进模型的性能。其中一些是</p><ul class=""><li id="a2a7" class="mq mr iq kn b ko kp ks kt lj ms lk mt ll mu li mv mw mx my bi translated">使用一些先进的深度学习算法，如<strong class="kn ja"> RNN </strong>、<strong class="kn ja">伯特</strong>(因为我们有一个大数据集，深度学习算法可能会表现很好)</li><li id="fc1e" class="mq mr iq kn b ko mz ks na lj nb lk nc ll nd li mv mw mx my bi translated">使用更先进的数据清理流程。这里我们忽略了可能有助于提高整体性能的数字数据</li><li id="ffb3" class="mq mr iq kn b ko mz ks na lj nb lk nc ll nd li mv mw mx my bi translated">使用其他矢量化技术，如<strong class="kn ja"> Word2Vec </strong></li></ul><p id="0fe6" class="pw-post-body-paragraph kk kl iq kn b ko kp kq kr ks kt ku kv lj kx ky kz lk lb lc ld ll lf lg lh li ij bi translated">源代码在<a class="ae mp" href="https://github.com/PushkaraSharma/articles_codes/tree/master/StackOverflow%20Moderator" rel="noopener ugc nofollow" target="_blank"> <strong class="kn ja"> GitHub </strong> </a>上有。请随意改进。</p><p id="a7c4" class="pw-post-body-paragraph kk kl iq kn b ko kp kq kr ks kt ku kv lj kx ky kz lk lb lc ld ll lf lg lh li ij bi translated">谢谢你宝贵的时间。😊我希望你喜欢这个教程。</p><p id="0929" class="pw-post-body-paragraph kk kl iq kn b ko kp kq kr ks kt ku kv lj kx ky kz lk lb lc ld ll lf lg lh li ij bi translated">还有，查看我关于<strong class="kn ja"> </strong> <a class="ae mp" href="https://speaktocode.com/deep-learning/predict-stock-trend-using-deep-learning/" rel="noopener ugc nofollow" target="_blank"> <strong class="kn ja">利用深度学习</strong> </a>预测股票走势的文章</p></div></div>    
</body>
</html>