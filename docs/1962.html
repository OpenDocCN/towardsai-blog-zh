<html>
<head>
<title>Stemming and Lemmatization in NLP with Python</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">用Python实现自然语言处理中的词干化和词汇化</h1>
<blockquote>原文：<a href="https://pub.towardsai.net/natural-language-processing-ea960ba12d42?source=collection_archive---------2-----------------------#2021-07-05">https://pub.towardsai.net/natural-language-processing-ea960ba12d42?source=collection_archive---------2-----------------------#2021-07-05</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><h2 id="792b" class="ir is it bd b dl iu iv iw ix iy iz dk ja translated" aria-label="kicker paragraph"><a class="ae ep" href="https://towardsai.net/p/category/nlp" rel="noopener ugc nofollow" target="_blank">自然语言处理</a></h2><div class=""/><div class=""><h2 id="d604" class="pw-subtitle-paragraph jz jc it bd b ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq dk translated">自然语言处理中分析文本的技术</h2></div><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi kr"><img src="../Images/a1d8576d93f6031def1391e2e370e2cf.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*DPVs2zdiLVt2Ax1U"/></div></div><figcaption class="ld le gj gh gi lf lg bd b be z dk translated">由<a class="ae lh" href="https://unsplash.com/@micahboswell?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">米卡·博斯韦尔</a>在<a class="ae lh" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上拍摄的照片</figcaption></figure><p id="0723" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">在本文中，我们将研究自然语言处理技术中的词干化和词汇化。这两个主题对于文本数据的预处理和细化分析都非常重要。</p><ul class=""><li id="984b" class="me mf it lk b ll lm lo lp lr mg lv mh lz mi md mj mk ml mm bi translated"><strong class="lk jd">词干化:</strong>是将带后缀的词还原为其词根的过程。这是自然语言处理中一个重要的流水线过程。像‘快乐’、‘最快乐’、‘更快乐’这样的词属于词根，即‘快乐’。</li><li id="2641" class="me mf it lk b ll mn lo mo lr mp lv mq lz mr md mj mk ml mm bi translated"><strong class="lk jd">词汇化:</strong>这也是一个将单词还原到其本义的过程，但具有附加功能，如添加词性(POS)。</li></ul><p id="b051" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">这两种技术都用在文本挖掘过程中，以便从文本中提取最佳信息。</p><p id="5c10" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">词干提取过程简单快捷，主要依赖于基于模式的方法。而在词汇化中，它被用来从文本中获取更详细的信息。</p><p id="bc17" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">用于NLP任务的python用户友好库是Spacy、NLTK、TextBlob。</p><p id="d657" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">这个空间不包括词干提取过程，所以我们为这个过程选择了其他库。对于这两种方法，我们将尝试使用其他库。</p><p id="9b96" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">stemming提供了两个主要的库，第一个是porter stemmer，第二个是snowball stemmer。雪球词干分析器是波特词干分析器的一个更好的版本，可以获得更精确的词干词根。</p><p id="c57d" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">让我们看看使用NLTK库进行词干提取和词汇化的python示例。</p><blockquote class="ms mt mu"><p id="4c7f" class="li lj mv lk b ll lm kd ln lo lp kg lq mw ls lt lu mx lw lx ly my ma mb mc md im bi translated"><strong class="lk jd"> <em class="it">词干</em> </strong></p></blockquote><p id="9961" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">在这种方法中，我们将讨论波特词干。首先，我们需要导入NLTk库，下载“punkt ”,即句子分词器。然后导入porter词干分析器来处理句子的词干。词干化是在保持词义不变的情况下改变词的变化的过程。</p><pre class="ks kt ku kv gt mz na nb nc aw nd bi"><span id="4018" class="ne nf it na b gy ng nh l ni nj">import nltk<br/>nltk.download('punkt')<br/>from nltk.stem.porter import PorterStemmer<br/>porter_stemmer = PorterStemmer()</span></pre><p id="f7fe" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">现在，我们将以句子为例进行词干分析。</p><pre class="ks kt ku kv gt mz na nb nc aw nd bi"><span id="8e8e" class="ne nf it na b gy ng nh l ni nj">text = "Fruits are one of the essential crops among all, which have all nutrients"</span><span id="6150" class="ne nf it na b gy nk nh l ni nj"># Grab the tokens from the sentence<br/>tokens = nltk.word_tokenize(text)</span><span id="c409" class="ne nf it na b gy nk nh l ni nj">#To do stemming on these tokens<br/>for w in tokens:<br/>    print ("Actual: %s ---- Stem: %s"  % (w,porter_stemmer.stem(w)))</span></pre><p id="97fc" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">这部分代码将对tokens变量中的所有标记进行词干分析。</p><pre class="ks kt ku kv gt mz na nb nc aw nd bi"><span id="d94a" class="ne nf it na b gy ng nh l ni nj"><strong class="na jd">#output:</strong><br/>Actual: Fruits ---- Stem: fruit<br/>Actual: are ---- Stem: are<br/>Actual: one ---- Stem: one<br/>Actual: of ---- Stem: of<br/>Actual: the ---- Stem: the<br/>Actual: essential ---- Stem: essenti<br/>Actual: crops ---- Stem: crop<br/>Actual: among ---- Stem: among<br/>Actual: all ---- Stem: all<br/>Actual: , ---- Stem: ,<br/>Actual: which ---- Stem: which<br/>Actual: have ---- Stem: have<br/>Actual: all ---- Stem: all<br/>Actual: nutrients ---- Stem: nutrient</span></pre><p id="92d3" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">波特词干分析器的另一个例子如下所示:</p><pre class="ks kt ku kv gt mz na nb nc aw nd bi"><span id="262e" class="ne nf it na b gy ng nh l ni nj">from nltk.stem import PorterStemmer<br/>words= ["rest", "resting", "rests", "restful"]<br/>ps =PorterStemmer()<br/>for w in words:<br/>    rootWord=ps.stem(w)<br/>    print(rootWord)</span><span id="eefd" class="ne nf it na b gy nk nh l ni nj"><strong class="na jd">#output:</strong><br/>rest<br/>rest<br/>rest<br/>rest</span></pre><blockquote class="ms mt mu"><p id="572c" class="li lj mv lk b ll lm kd ln lo lp kg lq mw ls lt lu mx lw lx ly my ma mb mc md im bi translated"><strong class="lk jd"> <em class="it">词汇化</em> </strong></p></blockquote><p id="8d0d" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">对于同一个文本示例，我们将进行引理化，并注意两种方法的区别。</p><pre class="ks kt ku kv gt mz na nb nc aw nd bi"><span id="1b5c" class="ne nf it na b gy ng nh l ni nj">nltk.download('wordnet')<br/>from nltk.stem import WordNetLemmatizer<br/>lemma = WordNetLemmatizer()</span><span id="4a80" class="ne nf it na b gy nk nh l ni nj">text = "Fruits are one of the essential crops among all, which have all nutrients"</span><span id="9e66" class="ne nf it na b gy nk nh l ni nj">tokens = nltk.word_tokenize(text)<br/>for w in tokens:<br/>    print ("Actual: %s  Lemma: %s"  % (w,lemma.lemmatize(w)))</span></pre><p id="f69a" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">术语化的输出如下所示:</p><pre class="ks kt ku kv gt mz na nb nc aw nd bi"><span id="7b76" class="ne nf it na b gy ng nh l ni nj"><strong class="na jd">#output:</strong><br/>Actual: Fruits --- Lemma: <strong class="na jd">Fruits</strong><br/>Actual: are --- Lemma: are<br/>Actual: one --- Lemma: one<br/>Actual: of --- Lemma: of<br/>Actual: the --- Lemma: the<br/>Actual: essential --- Lemma: <strong class="na jd">essential</strong><br/>Actual: crops --- Lemma: crop<br/>Actual: among --- Lemma: among<br/>Actual: all --- Lemma: all<br/>Actual: , --- Lemma: ,<br/>Actual: which --- Lemma: which<br/>Actual: have --- Lemma: have<br/>Actual: all --- Lemma: all<br/>Actual: nutrients --- Lemma: nutrient</span></pre><p id="02ea" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">如果我们比较这两个的结果，那么我们会清楚地看到，引理化给出了上面输出中加粗的两个不同的引理。</p><p id="3bd2" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">在业务领域中，词汇化更受欢迎，因为它比词干化更可靠、更先进。</p><pre class="ks kt ku kv gt mz na nb nc aw nd bi"><span id="80ed" class="ne nf it na b gy ng nh l ni nj">from nltk.stem import WordNetLemmatizer<br/>  <br/>lem = WordNetLemmatizer()<br/>  <br/>print("days :", lem.lemmatize("days"))<br/>print("bottles :", lem.lemmatize("bottles"))<br/>  <br/># The pos parameter have 'a' means adjective<br/>print("happier :", lem.lemmatize("happier", pos ="a"))</span><span id="25f5" class="ne nf it na b gy nk nh l ni nj"><strong class="na jd">#output:</strong><br/>days : day<br/>bottles : bottle<br/>happier : happy</span></pre><div class="nl nm gp gr nn no"><a rel="noopener  ugc nofollow" target="_blank" href="/nlp-zero-to-hero-with-python-2df6fcebff6e"><div class="np ab fo"><div class="nq ab nr cl cj ns"><h2 class="bd jd gy z fp nt fr fs nu fu fw jc bi translated">NLP——使用Python从零到英雄</h2><div class="nv l"><h3 class="bd b gy z fp nt fr fs nu fu fw dk translated">学习自然语言处理基本概念的手册</h3></div><div class="nw l"><p class="bd b dl z fp nt fr fs nu fu fw dk translated">pub.towardsai.net</p></div></div><div class="nx l"><div class="ny l nz oa ob nx oc lb no"/></div></div></a></div><blockquote class="ms mt mu"><p id="fff1" class="li lj mv lk b ll lm kd ln lo lp kg lq mw ls lt lu mx lw lx ly my ma mb mc md im bi translated"><strong class="lk jd"> <em class="it">结论</em> </strong></p></blockquote><p id="3478" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">本文给出了自然语言处理中这两种方法的基本思想。NLTK库是一个用文本数据进行分析的极好的库。</p><p id="3386" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">我希望你喜欢这篇文章。通过我的<a class="ae lh" href="https://www.linkedin.com/in/data-scientist-95040a1ab/" rel="noopener ugc nofollow" target="_blank"> LinkedIn </a>和<a class="ae lh" href="https://twitter.com/amitprius" rel="noopener ugc nofollow" target="_blank"> twitter </a>联系我。</p><h1 id="6793" class="od nf it bd oe of og oh oi oj ok ol om ki on kj oo kl op km oq ko or kp os ot bi translated">推荐文章</h1><p id="c07b" class="pw-post-body-paragraph li lj it lk b ll ou kd ln lo ov kg lq lr ow lt lu lv ox lx ly lz oy mb mc md im bi translated">1.<a class="ae lh" rel="noopener ugc nofollow" target="_blank" href="/python-zero-to-hero-with-examples-c7a5dedb968b?source=friends_link&amp;sk=186aff630c2241aca16522241333e3e0"> Python:零到英雄配实例</a> <br/> 2。<a class="ae lh" href="https://medium.com/towards-artificial-intelligence/python-data-structures-data-types-and-objects-244d0a86c3cf?sk=42f4b462499f3fc3a160b21e2c94dba6" rel="noopener"> Python数据结构数据类型和对象</a>T5】3 .<a class="ae lh" rel="noopener ugc nofollow" target="_blank" href="/exception-handling-concepts-in-python-4d5116decac3?source=friends_link&amp;sk=a0ed49d9fdeaa67925eac34ecb55ea30">Python中的异常处理概念</a> <br/> 4。<a class="ae lh" rel="noopener ugc nofollow" target="_blank" href="/reading-csv-excel-json-and-html-file-formats-in-pandas-2e1e417d1d12?source=friends_link&amp;sk=1bafcb980bf95253f8c8e19d6643ec9e">在熊猫</a> <br/> 5中读取CSV()、Excel()、JSON()和HTML()文件格式。<a class="ae lh" rel="noopener ugc nofollow" target="_blank" href="/neural-networks-the-rise-of-recurrent-neural-networks-df740252da88?source=friends_link&amp;sk=6844935e3de14e478ce00f0b22e419eb">神经网络:递归神经网络的兴起</a> <br/> 6。<a class="ae lh" href="https://medium.com/towards-artificial-intelligence/fully-explained-linear-regression-with-python-fe2b313f32f3?source=friends_link&amp;sk=53c91a2a51347ec2d93f8222c0e06402" rel="noopener">用Python </a> <br/> 7全面讲解了线性回归。<a class="ae lh" href="https://medium.com/towards-artificial-intelligence/fully-explained-logistic-regression-with-python-f4a16413ddcd?source=friends_link&amp;sk=528181f15a44e48ea38fdd9579241a78" rel="noopener">用Python </a> <br/>充分解释了Logistic回归8。<a class="ae lh" rel="noopener ugc nofollow" target="_blank" href="/differences-between-concat-merge-and-join-with-python-1a6541abc08d?source=friends_link&amp;sk=3b37b694fb90db16275059ea752fc16a">concat()、merge()和join()与Python </a> <br/>的区别9。<a class="ae lh" rel="noopener ugc nofollow" target="_blank" href="/lasso-l1-and-ridge-l2-regularization-techniques-33b7f12ac0b?source=friends_link&amp;sk=b77a29aac0ab8d63ba6b449c03180cd5">套索(l1)和脊(l2)正则化技术</a> <br/> 10。<a class="ae lh" href="https://medium.com/analytics-vidhya/confusion-matrix-in-machine-learning-91b6e2b3f9af?source=friends_link&amp;sk=11c6531da0bab7b504d518d02746d4cc" rel="noopener">机器学习中的混淆矩阵</a></p></div></div>    
</body>
</html>