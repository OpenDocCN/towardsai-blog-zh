<html>
<head>
<title>Pyspark Handle Dataset With Columns Separator in Data</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">数据中带有列分隔符的Pyspark句柄数据集</h1>
<blockquote>原文：<a href="https://pub.towardsai.net/pyspark-handle-dataset-with-columns-separator-in-data-c98069d131aa?source=collection_archive---------4-----------------------#2021-01-11">https://pub.towardsai.net/pyspark-handle-dataset-with-columns-separator-in-data-c98069d131aa?source=collection_archive---------4-----------------------#2021-01-11</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><h2 id="023b" class="io ip iq bd b dl ir is it iu iv iw dk ix translated" aria-label="kicker paragraph"><a class="ae ep" href="https://towardsai.net/p/category/programming" rel="noopener ugc nofollow" target="_blank">编程</a></h2><div class=""/><p id="e523" class="pw-post-body-paragraph jw jx iq jy b jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ij bi translated">这篇博客的目的是处理数据集中出现列分隔符或定界符的特殊情况。对于Pyspark开发人员来说，处理这种类型的数据集有时是一件令人头疼的事情，但无论如何，这是必须要处理的。在我的博客中，我将分享我应对挑战的方法，我乐于学习，所以也请分享你的方法。</p><figure class="kv kw kx ky gt kz gh gi paragraph-image"><div class="gh gi ku"><img src="../Images/998934bb933cfa1ec302f8c8e84fb36c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1354/format:webp/1*z_nqJKzCsomwH1Qvb9p9EA.png"/></div><figcaption class="lc ld gj gh gi le lf bd b be z dk translated">来源:<a class="ae lg" href="https://spark.apache.org/docs/latest/api/python/index.html" rel="noopener ugc nofollow" target="_blank"> PySpark </a></figcaption></figure><p id="9d60" class="pw-post-body-paragraph jw jx iq jy b jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ij bi translated">数据集基本如下图所示:</p><pre class="kv kw kx ky gt lh li lj lk aw ll bi"><span id="4961" class="lm ln iq li b gy lo lp l lq lr">#first line is the header</span><span id="7c6d" class="lm ln iq li b gy ls lp l lq lr">NAME|AGE|DEP<br/>Vivek|Chaudhary|32|BSC<br/>John|Morgan|30|BE<br/>Ashwin|Rao|30|BE</span></pre><p id="548c" class="pw-post-body-paragraph jw jx iq jy b jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ij bi translated">数据集包含由分隔符“|”分隔的三列<strong class="jy ja">、【姓名】、【年龄】、</strong>。如果我们关注数据集，它还包含“|”作为列名<strong class="jy ja">。</strong></p><p id="92eb" class="pw-post-body-paragraph jw jx iq jy b jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ij bi translated">让我们进一步看看如何进行相同的操作:</p><p id="de7a" class="pw-post-body-paragraph jw jx iq jy b jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ij bi translated"><strong class="jy ja">步骤1。使用spark的read.csv()方法读取数据集:</strong></p><pre class="kv kw kx ky gt lh li lj lk aw ll bi"><span id="aceb" class="lm ln iq li b gy lo lp l lq lr">#create spark session </span><span id="7bd4" class="lm ln iq li b gy ls lp l lq lr">import pyspark<br/>from pyspark.sql import SparkSession<br/>spark=SparkSession.builder.appName(‘delimit’).getOrCreate()</span></pre><p id="2092" class="pw-post-body-paragraph jw jx iq jy b jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ij bi translated">上面的命令帮助我们连接到spark环境，并让我们使用spark.read.csv()读取数据集</p><pre class="kv kw kx ky gt lh li lj lk aw ll bi"><span id="99a4" class="lm ln iq li b gy lo lp l lq lr">#create dataframe</span><span id="5b20" class="lm ln iq li b gy ls lp l lq lr">df=spark.read.option(‘delimiter’,’|’).csv(r’&lt;path&gt;\delimit_data.txt’,inferSchema=True,header=True)</span><span id="3e37" class="lm ln iq li b gy ls lp l lq lr">df.show()</span></pre><figure class="kv kw kx ky gt kz gh gi paragraph-image"><div class="gh gi lt"><img src="../Images/166d9bbb99523d20dbd27b149193e87b.png" data-original-src="https://miro.medium.com/v2/resize:fit:438/format:webp/1*e-5vr_hGpk_2wLwyGtr7cA.png"/></div></figure><p id="b7cb" class="pw-post-body-paragraph jw jx iq jy b jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ij bi translated">从文件中读取数据并将数据放入内存后，它看起来是这样的。但是等等，最后一列数据在哪里，列<strong class="jy ja">年龄</strong>必须有一个整数数据类型，但是我们看到了别的东西。这不是我们所期望的。乱七八糟完全不匹配，不是吗？答案是肯定的，一团糟。让我想起碧碧·雷克萨的歌《我一团糟》😂😂</p><p id="c34a" class="pw-post-body-paragraph jw jx iq jy b jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ij bi translated">现在，让我们学习如何解决这个问题。</p><p id="5940" class="pw-post-body-paragraph jw jx iq jy b jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ij bi translated"><strong class="jy ja">步骤2。再次读取数据，但这次使用read.text()方法:</strong></p><pre class="kv kw kx ky gt lh li lj lk aw ll bi"><span id="0144" class="lm ln iq li b gy lo lp l lq lr">df=spark.read.text(r’C:\Users\lenovo\Python_Pyspark_Corp_Training\delimit_data.txt’)<br/>df.show(truncate=0)</span></pre><figure class="kv kw kx ky gt kz gh gi paragraph-image"><div class="gh gi lu"><img src="../Images/60e8f422b82d0672c45789881352a783.png" data-original-src="https://miro.medium.com/v2/resize:fit:460/format:webp/1*w1Q_n4I85MIy8MsjZWOoeg.png"/></div></figure><pre class="kv kw kx ky gt lh li lj lk aw ll bi"><span id="be95" class="lm ln iq li b gy lo lp l lq lr">#extract first row as this is our header<br/>head=df.first()[0]</span><span id="bf15" class="lm ln iq li b gy ls lp l lq lr">schema=[‘fname’,’lname’,’age’,’dep’]<br/>print(schema)</span><span id="0a18" class="lm ln iq li b gy ls lp l lq lr">Output: ['fname', 'lname', 'age', 'dep']</span></pre><p id="7508" class="pw-post-body-paragraph jw jx iq jy b jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ij bi translated">下一步是根据列分隔符分割数据集:</p><pre class="kv kw kx ky gt lh li lj lk aw ll bi"><span id="ae83" class="lm ln iq li b gy lo lp l lq lr">#filter the header, separate the columns and apply the schema<br/>df_new=df.filter(df[‘value’]!=head).rdd.map(lambda x:x[0].split(‘|’)).toDF(schema)<br/>df_new.show()</span></pre><figure class="kv kw kx ky gt kz gh gi paragraph-image"><div class="gh gi lv"><img src="../Images/560d3717f9b81907eefaaa6a32a7c84e.png" data-original-src="https://miro.medium.com/v2/resize:fit:468/format:webp/1*QHMlHBE3VKZY4o_88YSA7g.png"/></div></figure><p id="cccb" class="pw-post-body-paragraph jw jx iq jy b jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ij bi translated">现在，我们已经成功分离出了<strong class="jy ja">菌株</strong>。等等什么<strong class="jy ja">应变</strong>？不，伙计，这不是电晕病毒，这只是文本数据。留着吧，简单的伙伴。😜😜</p><p id="3ccd" class="pw-post-body-paragraph jw jx iq jy b jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ij bi translated">我们已经成功地将管道“|”分隔的列(“名称”)数据分成两列。现在数据更加干净，可以轻松播放。</p><p id="bdcd" class="pw-post-body-paragraph jw jx iq jy b jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ij bi translated">接下来，连接列<strong class="jy ja">“fname”</strong>和<strong class="jy ja">“lname”</strong>:</p><pre class="kv kw kx ky gt lh li lj lk aw ll bi"><span id="a88b" class="lm ln iq li b gy lo lp l lq lr">from pyspark.sql.functions import concat, col, lit<br/>df1=df_new.withColumn(‘fullname’,concat(col(‘fname’),lit(“|”),col(‘lname’)))<br/>df1.show()</span></pre><figure class="kv kw kx ky gt kz gh gi paragraph-image"><div class="gh gi lw"><img src="../Images/62d4653883262b46980d34a768611650.png" data-original-src="https://miro.medium.com/v2/resize:fit:732/format:webp/1*S0l3tA2OsAj1k_dvU5KF1w.png"/></div></figure><p id="d264" class="pw-post-body-paragraph jw jx iq jy b jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ij bi translated">为了验证数据转换，我们将把转换后的数据集写入一个CSV文件，然后使用<strong class="jy ja"> read.csv() </strong>方法读取它。</p><pre class="kv kw kx ky gt lh li lj lk aw ll bi"><span id="29eb" class="lm ln iq li b gy lo lp l lq lr">df1.write.option(‘sep’,’|’).mode(‘overwrite’).option(‘header’,’true’).csv(r’&lt;<em class="lx">file_path</em>&gt;\cust_sep.csv’)</span></pre><p id="893c" class="pw-post-body-paragraph jw jx iq jy b jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ij bi translated"><strong class="jy ja">下一步是数据验证:</strong></p><pre class="kv kw kx ky gt lh li lj lk aw ll bi"><span id="c7e5" class="lm ln iq li b gy lo lp l lq lr">df=spark.read.option(‘delimiter’,’|’).csv(r&lt;<em class="lx">filepath</em>&gt;,inferSchema=True,header=True)<br/>df.show()</span></pre><figure class="kv kw kx ky gt kz gh gi paragraph-image"><div class="gh gi lw"><img src="../Images/9bd3e0d23fc68368616ecf5f25993f25.png" data-original-src="https://miro.medium.com/v2/resize:fit:732/format:webp/1*mEHKQqXq7xtsocQ5SdyW1w.png"/></div></figure><p id="09b6" class="pw-post-body-paragraph jw jx iq jy b jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ij bi translated">数据现在看起来符合我们的要求。一个小练习，尝试使用不同的分隔符，如果发现任何异常，请告诉我。这个博客到此为止。下次会有不同的场景。</p><p id="6242" class="pw-post-body-paragraph jw jx iq jy b jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ij bi translated">感谢大家阅读我的博客。请分享您的观点或反馈。</p></div></div>    
</body>
</html>