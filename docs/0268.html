<html>
<head>
<title>The Rickety Tripod of IBM’s AI Ethics</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">IBM人工智能伦理摇摇欲坠的三脚架</h1>
<blockquote>原文：<a href="https://pub.towardsai.net/the-rickety-tripod-of-ibms-ai-ethics-76dd99e3cfe0?source=collection_archive---------2-----------------------#2020-01-09">https://pub.towardsai.net/the-rickety-tripod-of-ibms-ai-ethics-76dd99e3cfe0?source=collection_archive---------2-----------------------#2020-01-09</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><figure class="gl gn jo jp jq jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi jn"><img src="../Images/cfc46ba9851396ec808fafd66f9e2297.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*kuN1vaZTddMwnDIgJ45chQ.png"/></div></div><figcaption class="jy jz gj gh gi ka kb bd b be z dk translated">EmTech 2017/麻省理工学院</figcaption></figure><p id="117a" class="pw-post-body-paragraph kc kd iq ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz ij bi translated">英语最大的好处就是它最大的弱点。同一个词可以用得非常精确，也可以用得非常不精确，有时会产生令人困惑甚至致命的后果。</p><p id="9989" class="pw-post-body-paragraph kc kd iq ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz ij bi translated">我曾经从一个外科医生那里听说过这个故事。一名疑似肠道堵塞的患者需要手术来找出原因。她写下病例笔记，并把它们交给外科主任。然后，她不得不因为家庭事务紧急离开医院，并且在离开前没有机会与首席外科医生交谈。五天后，当她回来时，令她惊恐的是，那个男人并没有动手术。首席外科医生解释说，她的病历既没有说服力，也没有足够的描述来证明手术的合理性。该男子随后接受了手术，但死亡。</p><p id="07e2" class="pw-post-body-paragraph kc kd iq ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz ij bi translated">虽然有些极端，但它充分说明了语言是如何帮助或伤害人的。</p><p id="f357" class="pw-post-body-paragraph kc kd iq ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz ij bi translated">伦理就是这样一个词。</p><p id="128b" class="pw-post-body-paragraph kc kd iq ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz ij bi translated">医学伦理关注的是全民医疗保健权、安乐死、堕胎或医用大麻；建筑行业伦理是零伤害，生物伦理争论人类生殖系基因改造或异种移植的好处和时机，人工智能伦理似乎主要致力于说服社区人工智能是真实和安全的<strong class="ke ir">、</strong>而不是令人毛骨悚然的<strong class="ke ir">、T3，其议程是“先部署，后解决”:</strong></p><ul class=""><li id="cb12" class="la lb iq ke b kf kg kj kk kn lc kr ld kv le kz lf lg lh li bi translated">亚马逊拥有的漏洞百出的环形安全设备被宣传为安全，随后被发现是<a class="ae lj" href="https://www.gizmodo.com.au/2019/12/rings-hidden-data-let-us-map-amazons-sprawling-home-surveillance-network/" rel="noopener ugc nofollow" target="_blank">非隐私</a>和<a class="ae lj" href="https://www.thesun.co.uk/news/10627821/ring-amazon-sued-creepy-hacking-kids-camera/" rel="noopener ugc nofollow" target="_blank">令人毛骨悚然</a>，但随后亚马逊指责客户未能应用正确的隐私设置；</li><li id="108d" class="la lb iq ke b kf lk kj ll kn lm kr ln kv lo kz lf lg lh li bi translated">特斯拉汽车软件故障可能要对迄今为止造成<a class="ae lj" href="https://www.tesladeaths.com/" rel="noopener ugc nofollow" target="_blank"> 113 </a>人死亡负责，因为需要真实世界的数据来为60万辆已部署车辆的DNN提供动力，以及荒谬的安全建议，即在自动驾驶仪运行时把手放在方向盘上，即使在那里也无法实现该功能；</li><li id="d6e5" class="la lb iq ke b kf lk kj ll kn lm kr ln kv lo kz lf lg lh li bi translated">DeepMinds AlphaGo Zero消除了任何孩子玩古代围棋的理由；和</li><li id="5577" class="la lb iq ke b kf lk kj ll kn lm kr ln kv lo kz lf lg lh li bi translated">DeepFakes用于恶意欺骗，MelNet用于模仿声音；</li></ul><p id="2cee" class="pw-post-body-paragraph kc kd iq ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz ij bi translated">这些被滥用的技术越来越多，已经以股东利益的名义损害了人类的生活、工作和隐私。</p><p id="e072" class="pw-post-body-paragraph kc kd iq ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz ij bi translated">几年前，ANZ银行首席执行官Mike Smith对利润平衡法进行了最简洁的总结，他说首席执行官的工作就是在股东、客户和员工的需求之间取得平衡。与此同时，每年的NPAT回报率高达50亿澳元。</p><p id="967f" class="pw-post-body-paragraph kc kd iq ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz ij bi translated">虽然伦理本身是一个哲学概念，但最令人担忧的是，许多对此进行辩论的人大多不是哲学家本人，如<a class="ae lj" href="https://en.wikipedia.org/wiki/Daniel_Dennett" rel="noopener ugc nofollow" target="_blank">丹·丹尼特</a>博士或<a class="ae lj" href="https://nickbostrom.com/" rel="noopener ugc nofollow" target="_blank">尼克·博斯特伦</a>博士，而是事实上被<em class="lp">不知何故</em>任命为顾问职位、拥有浮夸头衔的技术从业者。</p><p id="49b4" class="pw-post-body-paragraph kc kd iq ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz ij bi translated">意大利帕多瓦大学的弗朗切斯卡·罗西博士就是这样一位杰出人士。谁是IBM的人工智能伦理全球领导者和杰出的研究员。</p><p id="0d6a" class="pw-post-body-paragraph kc kd iq ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz ij bi translated">虽然Rossi博士即将在2020年麻省理工学院的EmTech上发表演讲，但在2017年的EmTech上，在她的演讲“人工智能和社会责任的艺术”中，她谈到了她如何在“大约3年前”对人工智能的伦理感兴趣，并介绍了人工智能如何在这里，人工智能不是ML，从体育，医疗和税收的应用范围，以及人工智能将如何使用这种关于人工智能如何“创造”知识的想象理论来增强(而不是取代)人类决策:</p><blockquote class="lq lr ls"><p id="a30b" class="kc kd lp ke b kf kg kh ki kj kk kl km lt ko kp kq lu ks kt ku lv kw kx ky kz ij bi translated">“人工智能可以感知它的环境——理解数据，将数据转化为知识，在知识的基础上进行推理，然后决定采取哪些行动，做出哪些决定，然后适应新的情况，然后采取行动，在物理上朝着这个更高的机器人或嵌入式环境行动……需要将这些系统与你认为适合特定任务的道德价值观保持一致”</p></blockquote><p id="9c43" class="pw-post-body-paragraph kc kd iq ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz ij bi translated">正如伊萨克·牛顿爵士一生都在寻求点石成金一样，罗西博士代表IBM Watson试图说服我们，不仅人工智能代理可以将数据转化为人类知识，而且它们可以在伦理上与某些人(谁的？)行为集！</p><p id="9d75" class="pw-post-body-paragraph kc kd iq ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz ij bi translated">这一有缺陷的论点的整个本质是由使IBM的人工智能研究看起来友好所驱动的，并建立在三个谬误的摇摇欲坠的三脚架上:</p><ol class=""><li id="e7ef" class="la lb iq ke b kf kg kj kk kn lc kr ld kv le kz lw lg lh li bi translated">人工智能可以<em class="lp">感知</em>和<em class="lp">理解</em>数据，人工智能和人类将一起工作并成为一个<a class="ae lj" href="https://medium.com/towards-artificial-intelligence/dont-believe-scomo-what-ai-means-for-us-in-2020-51355ae77b4c" rel="noopener">团队</a>——拟人化傀儡谬论；</li><li id="3336" class="la lb iq ke b kf lk kj ll kn lm kr ln kv lo kz lw lg lh li bi translated">伦理可以以某种方式被“注入”到代码中，并通过外部化的行为来衡量——物理主义和<a class="ae lj" href="https://medium.com/the-digital-ethicist/from-computational-tool-to-artificial-intelligence-friend-mitsuku-p-zombies-and-the-blockhead-45189e7d1e2a" rel="noopener">p-僵尸谬误</a>；和</li><li id="8009" class="la lb iq ke b kf lk kj ll kn lm kr ln kv lo kz lw lg lh li bi translated">到底是谁的伦理价值集——<a class="ae lj" href="https://medium.com/@adhart81/it-wont-happen-to-me-the-ethics-behind-tesla-s-autopilot-47df88ece7a1" rel="noopener">功利主义</a> &amp;法西斯谬论。</li></ol><p id="ea24" class="pw-post-body-paragraph kc kd iq ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz ij bi translated">令人难以置信的是，像她这样的荣誉和学术地位的人，获得了哈佛大学拉德克利夫奖学金，却使用如此不可信和薄弱的后验假设，并被允许在麻省理工学院作为真理宣扬。</p><p id="848c" class="pw-post-body-paragraph kc kd iq ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz ij bi translated">但是，既然Rossi博士的认识论是计算科学，是IBM Watson认知计算，而不是哲学，也许她应该被原谅，因为她的心是对的，她正在努力？</p><p id="c45f" class="pw-post-body-paragraph kc kd iq ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz ij bi translated">这里的动力是像IBM这样的盈利企业，它们通过使用道德这个词作为营销工具，并在顾问角色中吸收备受称赞的学者，来寻求使人工智能增强人类决策看起来安全(甚至是好的)，因为你知道，所有的学者都是道德的。</p><p id="f4f9" class="pw-post-body-paragraph kc kd iq ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz ij bi translated">试图告诉那些在美国国立卫生研究院把猪心缝在肠子里的狒狒，那些学者是有道德的。</p><p id="3bbc" class="pw-post-body-paragraph kc kd iq ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz ij bi translated">虽然医学伦理学谈论人权，但在所有这些中，权利在哪里？虽然领先的遗传学家至少在谈论自愿暂停种系基因修改，因为他们不能完全预测后果是什么，但这种思想在人工智能伦理话语中的位置在哪里？</p><p id="0ee4" class="pw-post-body-paragraph kc kd iq ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz ij bi translated">对可自由获得的信息的基本阅读表明，康德伦理学把伦理说成是一种<em class="lp">义务</em>来判断一系列行为本身是对还是错——而不是简单地评估行为的好或坏后果，并且只有善意才是唯一好的东西。康德的绝对命令是用来评估行动的动机，而不是行动的结果。</p><p id="9324" class="pw-post-body-paragraph kc kd iq ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz ij bi translated">如果它的开发者的价值观或动机甚至不是你的，你会让特斯拉在你的脑袋里放一个Neuralink吗？</p><p id="2e90" class="pw-post-body-paragraph kc kd iq ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz ij bi translated">如果一个启用了Neuralink的人或一辆自动驾驶的特斯拉3说，基于功利主义，三分之一的儿童在不可避免的碰撞中被撞倒，从而拯救了成年乘客，这是道德的吗？当然不是。对成年司机来说，更道德的做法是撞上一堵墙或一根柱子，让车停下来，拯救所有的孩子，因为保护孩子的生命是成年人的责任，而不是他们自己的。</p><p id="b192" class="pw-post-body-paragraph kc kd iq ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz ij bi translated">事实上，在这种情况下，对我来说合乎道德的事情，可能会被像自恋者这样只看重自己的人视为完全疯狂，因为我不会把自己的幸福置于他人之上。或者屏幕上出现一个按钮，写着“即将发生碰撞，救救a)旁观者或b)自己”？伦理可以只是由AI开发者预先确定的，或者由焦点小组确定的二元或ABCD选择题值集吗？如果我不同意任何选项怎么办？</p><p id="939c" class="pw-post-body-paragraph kc kd iq ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz ij bi translated">衡量行动的动机是判断某件事是否道德的方式，而人工智能没有动机或意愿。在最复杂的表达中，它写下了自己的规则，目前是基于一系列的奖励和惩罚。至少首席执行官史密斯先生坦率地说出了他试图平衡的动机，也足够诚实地说他并不总是做对。</p><p id="383d" class="pw-post-body-paragraph kc kd iq ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz ij bi translated">代表IBM的全球人工智能伦理领袖罗西得出的谬误关系是，一个有伦理的人工智能将是一个安全和良好的人工智能。</p><p id="a09b" class="pw-post-body-paragraph kc kd iq ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz ij bi translated">胡扯。</p><p id="f7dd" class="pw-post-body-paragraph kc kd iq ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz ij bi translated">我们永远不可能拥有一个本质上合乎道德的人工智能系统。</p><p id="dc9d" class="pw-post-body-paragraph kc kd iq ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz ij bi translated">我们可以让<em class="lp">的研究人员</em>出于伦理动机制造人工智能，比如非营利的<a class="ae lj" href="https://openai.com/" rel="noopener ugc nofollow" target="_blank">开放人工智能</a>？我相信你应该有一个能够<a class="ae lj" href="https://medium.com/swlh/should-ai-be-taught-to-fear-935adda749aa" rel="noopener">害怕</a>的人工智能，它对错误的行为有一个存在性的惩罚。但是为了狂妄自大而制造AI是错误的。</p><p id="9a26" class="pw-post-body-paragraph kc kd iq ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz ij bi translated">我认为在2020年，道德这个词似乎被技术界的一些人非常不精确和不道德地使用，等同于一种普遍的友好行为集，但实际上只是被误用为安全人工智能的营销用语，这是绝对可耻的。</p><p id="9219" class="pw-post-body-paragraph kc kd iq ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz ij bi translated">要让人工智能服务于人类的需求，而不仅仅是那些拥有发达技术的人的利润动机，它必须只被视为一种工具；使用任何工具的危险在于对其来源、目的、参数和用法的不正确理解。</p></div></div>    
</body>
</html>