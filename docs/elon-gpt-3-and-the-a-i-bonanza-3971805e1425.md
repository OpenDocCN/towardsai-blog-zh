# 埃隆、GPT-3 和人工智能

> 原文：<https://pub.towardsai.net/elon-gpt-3-and-the-a-i-bonanza-3971805e1425?source=collection_archive---------2----------------------->

## [人工智能](https://towardsai.net/p/category/artificial-intelligence)、[科技](https://towardsai.net/p/category/technology)、[观点](https://towardsai.net/p/category/opinion)

![](img/3fcc07c28335477205025c76de7f39f9.png)

安迪·凯利在 [Unsplash](https://unsplash.com?utm_source=medium&utm_medium=referral) 上的照片

[NeuraLink](https://www.neuralink.com/) 和 [OpenAI](https://openai.com/) 有什么共同点？他们都在探索用湿实验室对干实验室的方法来合成智能。Neuralink [wet lab]正在尝试通过可植入的脑机接口与大脑进行交互，并直接从源头进行学习。open ai[干实验室]正在寻求模拟真实世界中的大脑功能。OpenAI 的研究人员希望将安全人工智能的使用民主化。这两家公司都是由现实版的托尼·斯塔克创立的，他是天才发明家，也是漫威超级英雄钢铁侠的化身。正如他的公司 SpaceX、特斯拉和 Powerwall 所展示的那样，富有远见的埃隆·马斯克引导我们走向技术先进的现实。

OpenAI 最近发布了他们的 [GPT-3](https://openai.com/blog/openai-api/) 模型。在这个版本中，OpenAI 展示了他们在构建具有语言技能的人工智能方面的实力。GTP-3 语言模型于本月早些时候发布，被誉为可以写“指环王”的续集，甚至可以开药方。

![](img/016a5c427aef3523dd85e0d15de6dcb6.png)

我们对 GPT 3 号了解多少？

高性能计算和大数据是人工智能应用于语言理解的最新进展背后的推动因素。我们现在可以使用大量数据模拟复杂宇宙的规律。通过正确的深度学习模型，我们甚至可以训练人工智能，学习模仿嵌入数据中的人类推理路径。这种发现隐藏真相的人工智能已经成为我们社会的一面镜子，因为它突出了几代人以来的社会偏见。毕竟，机器人反映了它们的创造者。如果我们想生产安全的人工智能，今天是我们个人和集体提高的机会。

人工智能语言研究的游戏规则是在更多的数据上训练更具实质性的语言模型。像 GTP-3 这样的语言模型是在大量数据上训练出来的。GPT-3 拥有 1750 亿个参数，并在 40GB 的互联网文本上进行训练。GPT-3 是限量发行的，凯文·拉克尔是获得这台巨型机器的幸运儿之一。凯文[分享了](https://lacker.io/ai/2020/07/06/giving-gpt-3-a-turing-test.html)一份关于 GPT-3 在哪些方面做得好，哪些方面做得差的精彩分析。GPT-3 经常表现得像一个没有阅读的聪明学生，试图通过考试。一些众所周知的事实，一些半真半假的事实，和一些直截了当的谎言串在一起，起初看起来像是一个流畅的叙述。你不会想依靠这个特定的学生来发掘下一个弦理论。

**信息≠知识**

记忆信息并不能帮助你解决数学考试中的复杂问题。像生活一样，数学让你面对新的情况，只有用全新的变量去拟合旧的方程才能解决。这个生活和数学的游戏需要推理。一个只记住宇宙法则的系统在被要求推理时会有所欠缺。GTP-3 偶尔能从记忆中产生令人印象深刻的结果，但当被要求创建逻辑内容时就会出错。

以下是为什么 GTP 3 号没有达到我们预期的一些理论和实践方面的原因。

1.  在人工智能解决方案的设计中，推理不能是事后的想法。像 GTP-3 这样的系统在任何过去经验稀少的领域都会表现不佳——你无法记住未知的东西。在谷歌搜索的世界里，测试一个人记忆事实的能力没有什么意义，而构建和应用知识更有意义。
2.  巨型人工智能模型拥有大量的内存和计算资源。没有多少个人或公司能够负担得起像 GTP-3 这样规模的生产环境。如果 OpenAI 热衷于将人工智能的访问民主化，这种方法肯定不会让大多数利益相关者参与、设计或进一步为人工智能做出贡献。
3.  对于在互联网上没有很好索引的专业领域，找到代表性的训练数据是一个挑战。如果我们想让人工智能像医生一样说话，国家医学图书馆将不足以作为一个训练场。
4.  人工智能在针对问题空间进行优化时表现最佳。像 BERT 这样更简单的语言模型在知识提取任务上给出了很好的结果(> 90% F1)。新的语言模型很难改善这些结果，也很难弥合 90% -> 100% F1 之间的差距。然而，像摘要这样的语言任务有更多未知的领域，可能会经历一次复兴。如果应用于正确的痛点，GPT-3 可能是一个强大的工具。

尽管有缺点，GTP 3 号还是给了媒体很大压力。

**业内 AI**

我从在小型创业公司和大型企业构建人工智能解决方案的经验中了解到，对底层人工智能堆栈的改变可能会导致回报递减。我们需要更好地设计问题以获得高保真的结果。今天，我们致力于开发高度专注于特定任务并垂直集成到商业解决方案中的人工智能。人类并不擅长所有事情，但是一旦他们专攻某项工作，他们就会表现出色。

GPT-3 不应该误导人们相信语言模型能够理解[或意义](https://www.aclweb.org/anthology/2020.acl-main.463.pdf)。如果艾将军是我们的目的地，记忆不会带我们去那里。语言模型可能是一个有用的起点，但是前面还有很长的路要走。