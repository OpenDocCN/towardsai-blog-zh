<html>
<head>
<title>Performance Analysis: YoloV5 vs YoloR</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">性能分析:YoloV5与YoloR</h1>
<blockquote>原文：<a href="https://pub.towardsai.net/performance-analysis-yolov5-vs-yolor-a873001db193?source=collection_archive---------0-----------------------#2021-12-28">https://pub.towardsai.net/performance-analysis-yolov5-vs-yolor-a873001db193?source=collection_archive---------0-----------------------#2021-12-28</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><h2 id="4382" class="io ip iq bd b dl ir is it iu iv iw dk ix translated" aria-label="kicker paragraph"><a class="ae ep" href="https://towardsai.net/p/category/machine-learning/deep-learning" rel="noopener ugc nofollow" target="_blank">深度学习</a></h2><div class=""/><div class=""><h2 id="bbce" class="pw-subtitle-paragraph jw iz iq bd b jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn dk translated">物体检测，哪个最好？？</h2></div><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div role="button" tabindex="0" class="ku kv di kw bf kx"><div class="gh gi ko"><img src="../Images/56a9a804ebdaf8bd1f67b9502ea77048.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*PGQ4fX1hy7NdikMBmpnTFA.jpeg"/></div></div><figcaption class="la lb gj gh gi lc ld bd b be z dk translated">照片由<a class="ae le" href="https://unsplash.com/@mcnoble?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText" rel="noopener ugc nofollow" target="_blank">马特·诺布尔</a>在<a class="ae le" href="https://unsplash.com/s/photos/vision-bot?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上拍摄</figcaption></figure><h1 id="3422" class="lf lg iq bd lh li lj lk ll lm ln lo lp kf lq kg lr ki ls kj lt kl lu km lv lw bi translated">目录</h1><ol class=""><li id="2ead" class="lx ly iq lz b ma mb mc md me mf mg mh mi mj mk ml mm mn mo bi translated">介绍</li><li id="24ed" class="lx ly iq lz b ma mp mc mq me mr mg ms mi mt mk ml mm mn mo bi translated">YoloV5:真的还是假的？？</li><li id="4bc3" class="lx ly iq lz b ma mp mc mq me mr mg ms mi mt mk ml mm mn mo bi translated">尤洛:你看起来只有一个形象</li><li id="7e17" class="lx ly iq lz b ma mp mc mq me mr mg ms mi mt mk ml mm mn mo bi translated">技术性能分析</li><li id="b211" class="lx ly iq lz b ma mp mc mq me mr mg ms mi mt mk ml mm mn mo bi translated">用例</li></ol><h1 id="bb0a" class="lf lg iq bd lh li lj lk ll lm ln lo lp kf lq kg lr ki ls kj lt kl lu km lv lw bi translated">介绍</h1><p id="974d" class="pw-post-body-paragraph mu mv iq lz b ma mb ka mw mc md kd mx me my mz na mg nb nc nd mi ne nf ng mk ij bi translated">对象检测是在几个预定义的类别中识别和区分图像中存在的对象的过程。对象检测的过程分为两个步骤:</p><ol class=""><li id="fc73" class="lx ly iq lz b ma nh mc ni me nj mg nk mi nl mk ml mm mn mo bi translated">找出图像中对象的总数</li><li id="47f7" class="lx ly iq lz b ma mp mc mq me mr mg ms mi mt mk ml mm mn mo bi translated">对第一步中提取的对象进行分类，并估计它们的大小</li></ol><p id="1dbe" class="pw-post-body-paragraph mu mv iq lz b ma nh ka mw mc ni kd mx me nm mz na mg nn nc nd mi no nf ng mk ij bi translated">通常有两种类型的对象检测算法:</p><ol class=""><li id="ec15" class="lx ly iq lz b ma nh mc ni me nj mg nk mi nl mk ml mm mn mo bi translated">两阶段目标检测:它涉及目标区域建议，然后是从区域建议和包围盒回归的目标分类。这种检测器实现了最高的精度，但是与其他类型的检测器相比速度较慢。一些这样的对象检测器是RCNN、fast-RCNN和Mask RCNN。</li><li id="9d6e" class="lx ly iq lz b ma mp mc mq me mr mg ms mi mt mk ml mm mn mo bi translated">一阶段目标检测:从图像中预测包围盒，取消了目标区域建议步骤。与两级检测器相比，这种检测器非常快，但是在检测小物体时存在困难。快速的推理速度使得一级检测器适合于实时应用。一些这样的探测器是YOLO、SSD和YoloR。</li></ol><p id="1f43" class="pw-post-body-paragraph mu mv iq lz b ma nh ka mw mc ni kd mx me nm mz na mg nn nc nd mi no nf ng mk ij bi translated">在了解了不同类型的物体探测器后，问题出现了:</p><blockquote class="np"><p id="de42" class="nq nr iq bd ns nt nu nv nw nx ny mk dk translated">“哪一个最好？?"</p></blockquote><p id="3356" class="pw-post-body-paragraph mu mv iq lz b ma nz ka mw mc oa kd mx me ob mz na mg oc nc nd mi od nf ng mk ij bi translated">从这么多算法中选择一个是非常令人困惑的。决策依赖于许多因素，并因每个用例而异。一些应用可能需要更快的推理速度，而一些应用需要精确的检测。对于第一种情况，应该选择一级检测器，而对于后一种情况，应该选择两级检测器。但是，从各自的类别中哪一个是最好的。为了进行相同的测试，我进行了两个一级对象检测器(即YoloV5和YoloR)的性能分析。</p></div><div class="ab cl oe of hu og" role="separator"><span class="oh bw bk oi oj ok"/><span class="oh bw bk oi oj ok"/><span class="oh bw bk oi oj"/></div><div class="ij ik il im in"><h1 id="9fce" class="lf lg iq bd lh li ol lk ll lm om lo lp kf on kg lr ki oo kj lt kl op km lv lw bi translated">YoloV5:真的还是假的？？</h1><p id="8f0c" class="pw-post-body-paragraph mu mv iq lz b ma mb ka mw mc md kd mx me my mz na mg nb nc nd mi ne nf ng mk ij bi translated">2020年Ultralytics发布YoloV5本身就是一个很大的争议。《约罗》的前三个版本由约瑟夫·雷德蒙和阿里·法尔哈迪出版。后来，约瑟夫中止了计算机视觉的研究。接着，YoloV4由延续Joseph Redmon传统的Alexey Bochkovskiy推出。Yolo的前四个版本是与同行评审的研究论文一起发表的，这与YoloV5的情况不同。Ultralytics声称YoloV5的推理速度为140 FPS，而YoloV4的推理速度为50 FPS。他们还声称YoloV5的大小比YoloV4小90%。</p><p id="af4f" class="pw-post-body-paragraph mu mv iq lz b ma nh ka mw mc ni kd mx me nm mz na mg nn nc nd mi no nf ng mk ij bi translated">Alexey Bochkovskiy和其他几位人工智能研究人员声称这是一种误导，因为YoloV5没有任何支持文件，他们表示这种比较是不准确的。后来，Ultralytics的首席执行官兼创始人Glenn Jocher表示，他和他的团队将很快发表研究论文，以支持YoloV5，但这尚未完成。</p><p id="b955" class="pw-post-body-paragraph mu mv iq lz b ma nh ka mw mc ni kd mx me nm mz na mg nn nc nd mi no nf ng mk ij bi translated"><a class="ae le" href="https://github.com/ultralytics/yolov5" rel="noopener ugc nofollow" target="_blank"> YoloV5参考值</a></p><h1 id="74f1" class="lf lg iq bd lh li lj lk ll lm ln lo lp kf lq kg lr ki ls kj lt kl lu km lv lw bi translated">尤洛:你看起来只有一个形象</h1><p id="7591" class="pw-post-body-paragraph mu mv iq lz b ma mb ka mw mc md kd mx me my mz na mg nb nc nd mi ne nf ng mk ij bi translated">《约略》于2021年初由简-王尧、何一豪和廖宏远出版。基本上就是隐性知识和显性知识相结合的概念。人类通过视觉、听觉和经验获得显性知识，而隐性知识是从过去的经验和潜意识学习中获得的。顾名思义，YoloR被开发来使用图像的一种表示执行多项任务。颜色对象检测从深层获得显性知识，从浅层获得隐性知识。该体系结构将两种表示结合起来形成一种表示，这种表示可以进一步用于服务各种任务。</p><p id="afe0" class="pw-post-body-paragraph mu mv iq lz b ma nh ka mw mc ni kd mx me nm mz na mg nn nc nd mi no nf ng mk ij bi translated"><a class="ae le" href="https://github.com/WongKinYiu/yolor" rel="noopener ugc nofollow" target="_blank">约洛参考</a></p><h1 id="7235" class="lf lg iq bd lh li lj lk ll lm ln lo lp kf lq kg lr ki ls kj lt kl lu km lv lw bi translated"><strong class="ak">性能分析</strong></h1><p id="1ae4" class="pw-post-body-paragraph mu mv iq lz b ma mb ka mw mc md kd mx me my mz na mg nb nc nd mi ne nf ng mk ij bi translated">这是YoloV5(你只看一次)和YoloR(你只看一次表示)的性能分析。这两个模型都是在具有相同超参数的相同数据集上训练的。</p><h2 id="e0e6" class="oq lg iq bd lh or os dn ll ot ou dp lp me ov ow lr mg ox oy lt mi oz pa lv iw bi translated">资料组</h2><p id="a042" class="pw-post-body-paragraph mu mv iq lz b ma mb ka mw mc md kd mx me my mz na mg nb nc nd mi ne nf ng mk ij bi translated">该数据集包含最初由<a class="ae le" href="https://github.com/cosmicad/dataset" rel="noopener ugc nofollow" target="_blank"> cosmicad </a>和<a class="ae le" href="https://github.com/akshaylamba/all_CELL_data" rel="noopener ugc nofollow" target="_blank">aksha lambda</a>开源的血细胞图像。共有364幅图像，分为三类，即红细胞、白细胞和血小板。三个类别大约有4888个标签。</p><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div role="button" tabindex="0" class="ku kv di kw bf kx"><div class="gh gi pb"><img src="../Images/bd310e1a2b87eab8c2ef21d64bd0ea61.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*opfT-RUHUpJPMrMB.png"/></div></div><figcaption class="la lb gj gh gi lc ld bd b be z dk translated">Roboflow的BCCD数据集<a class="ae le" href="https://public.roboflow.com/object-detection/bccd/" rel="noopener ugc nofollow" target="_blank">来源</a></figcaption></figure><h2 id="7bd5" class="oq lg iq bd lh or os dn ll ot ou dp lp me ov ow lr mg ox oy lt mi oz pa lv iw bi translated">超参数</h2><p id="d8e4" class="pw-post-body-paragraph mu mv iq lz b ma mb ka mw mc md kd mx me my mz na mg nb nc nd mi ne nf ng mk ij bi translated">如下所述，两个模型都考虑了很少的超参数。</p><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div class="gh gi pc"><img src="../Images/408b7c24aae385a68e76f0f9f600e474.png" data-original-src="https://miro.medium.com/v2/resize:fit:978/format:webp/1*5nkI80WQ6YhBiuXlsTxVEw.png"/></div><figcaption class="la lb gj gh gi lc ld bd b be z dk translated">来源:作者图片</figcaption></figure><h2 id="1824" class="oq lg iq bd lh or os dn ll ot ou dp lp me ov ow lr mg ox oy lt mi oz pa lv iw bi translated">韵律学</h2><p id="7207" class="pw-post-body-paragraph mu mv iq lz b ma mb ka mw mc md kd mx me my mz na mg nb nc nd mi ne nf ng mk ij bi translated">平均精度是评估两个模型性能的标准。第一个是以0.5作为IOU阈值的映射。而第二个是IOU阈值在0.5至0.95范围内以0.05为步长变化的图的平均值。</p><p id="4773" class="pw-post-body-paragraph mu mv iq lz b ma nh ka mw mc ni kd mx me nm mz na mg nn nc nd mi no nf ng mk ij bi translated">很明显，这两个模型在验证数据集上表现得一样好。训练时用的Google collab GPU:<strong class="lz ja">12GB内存的Nvidia k80。</strong></p><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div class="gh gi pd"><img src="../Images/75bb1cd3f8c2857eff40945008451dbf.png" data-original-src="https://miro.medium.com/v2/resize:fit:1032/format:webp/1*YYpBgJ-aYRI8FnAgc7QzmQ.png"/></div><figcaption class="la lb gj gh gi lc ld bd b be z dk translated">来源:作者图片</figcaption></figure><h2 id="3980" class="oq lg iq bd lh or os dn ll ot ou dp lp me ov ow lr mg ox oy lt mi oz pa lv iw bi translated">分析</h2><p id="3252" class="pw-post-body-paragraph mu mv iq lz b ma mb ka mw mc md kd mx me my mz na mg nb nc nd mi ne nf ng mk ij bi translated"><strong class="lz ja">约洛夫5 </strong>:在测试数据集上有更好的性能，尽管与约洛夫<br/>T5】约洛夫有几乎相同的地图:推理有更多的假阴性特征</p><h1 id="1a5a" class="lf lg iq bd lh li lj lk ll lm ln lo lp kf lq kg lr ki ls kj lt kl lu km lv lw bi translated">用例</h1><p id="4bfc" class="pw-post-body-paragraph mu mv iq lz b ma mb ka mw mc md kd mx me my mz na mg nb nc nd mi ne nf ng mk ij bi translated">近年来，对象检测已经被分解成几个对企业有用的用例。其中一些是:</p><ol class=""><li id="b988" class="lx ly iq lz b ma nh mc ni me nj mg nk mi nl mk ml mm mn mo bi translated">自动驾驶汽车:检测街道上的其他车辆和行人，并计算汽车与其他物体之间的距离。此外，检测街道上的招牌，以确保自动驾驶机器人没有违反任何驾驶规则。</li><li id="5f40" class="lx ly iq lz b ma mp mc mq me mr mg ms mi mt mk ml mm mn mo bi translated">闭路电视监控:对象检测可以使智能视频监控在没有任何人工参与的情况下检测可疑活动。此外，在存储CCTV摄像机的连续记录时，内存是一个大问题。这也可以通过对象检测来解决，其中当任何人进入帧中时开始记录。</li><li id="00e0" class="lx ly iq lz b ma mp mc mq me mr mg ms mi mt mk ml mm mn mo bi translated">医学科学:在柯维德·疫情时代，物体探测对人类帮助很大。一些行业采用了这种机制来检测游客是否戴着口罩，是否保持安全距离。</li><li id="0a5b" class="lx ly iq lz b ma mp mc mq me mr mg ms mi mt mk ml mm mn mo bi translated">品牌列表:公司花钱在直播的体育比赛中展示他们的品牌名称和标志。在这种情况下，对象检测用于分析向观众显示品牌名称和标志的比赛时间线。</li></ol><p id="3202" class="pw-post-body-paragraph mu mv iq lz b ma nh ka mw mc ni kd mx me nm mz na mg nn nc nd mi no nf ng mk ij bi translated">训练脚本和推理输出可以在这里找到</p><div class="pe pf gp gr pg ph"><a href="https://github.com/DhruvGangwani/YoloV5_vs_YoloR" rel="noopener  ugc nofollow" target="_blank"><div class="pi ab fo"><div class="pj ab pk cl cj pl"><h2 class="bd ja gy z fp pm fr fs pn fu fw iz bi translated">GitHub-DhruvGangwani/yolov 5 _ vs _ YoloR</h2><div class="po l"><h3 class="bd b gy z fp pm fr fs pn fu fw dk translated">此时您不能执行该操作。您已使用另一个标签页或窗口登录。您已在另一个选项卡中注销，或者…</h3></div><div class="pp l"><p class="bd b dl z fp pm fr fs pn fu fw dk translated">github.com</p></div></div><div class="pq l"><div class="pr l ps pt pu pq pv ky ph"/></div></div></a></div><h2 id="02a9" class="oq lg iq bd lh or os dn ll ot ou dp lp me ov ow lr mg ox oy lt mi oz pa lv iw bi translated">结论</h2><p id="1b2b" class="pw-post-body-paragraph mu mv iq lz b ma mb ka mw mc md kd mx me my mz na mg nb nc nd mi ne nf ng mk ij bi translated">在这篇博客中，我已经解释了YoloV5和YoloR的性能分析。从指标和性能来看，很明显YoloV5要好得多。这个博客包含了对象检测算法的技术方面，但是理解对象检测算法的架构方面也很重要。所以我会强烈推荐大家去读Neptune.ai的<a class="ae le" href="https://neptune.ai/blog/object-detection-algorithms-and-libraries" rel="noopener ugc nofollow" target="_blank">物体检测算法和库</a>，一站式了解几个这样的算法。</p><p id="cc92" class="pw-post-body-paragraph mu mv iq lz b ma nh ka mw mc ni kd mx me nm mz na mg nn nc nd mi no nf ng mk ij bi translated"><strong class="lz ja">谢谢。</strong></p></div></div>    
</body>
</html>