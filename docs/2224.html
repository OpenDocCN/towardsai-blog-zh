<html>
<head>
<title>To Supervise Or Not To Supervise? Supervised vs Unsupervised Learning</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">监督还是不监督？监督与非监督学习</h1>
<blockquote>原文：<a href="https://pub.towardsai.net/to-supervise-or-not-to-supervise-supervised-vs-unsupervised-learning-51c0cd545c0b?source=collection_archive---------2-----------------------#2021-10-05">https://pub.towardsai.net/to-supervise-or-not-to-supervise-supervised-vs-unsupervised-learning-51c0cd545c0b?source=collection_archive---------2-----------------------#2021-10-05</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><h2 id="d9e3" class="ir is it bd b dl iu iv iw ix iy iz dk ja translated" aria-label="kicker paragraph"><a class="ae ep" href="https://towardsai.net/p/category/machine-learning" rel="noopener ugc nofollow" target="_blank">机器学习</a></h2><div class=""/><p id="00c9" class="pw-post-body-paragraph jz ka it kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw im bi translated">解释监督学习和非监督学习的主要区别。</p><figure class="ky kz la lb gt lc gh gi paragraph-image"><div role="button" tabindex="0" class="ld le di lf bf lg"><div class="gh gi kx"><img src="../Images/7a7aedee113d0b8e3cadb946a8fc4bb7.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*BatXwSQ-BqyfXR29"/></div></div><figcaption class="lj lk gj gh gi ll lm bd b be z dk translated">由<a class="ae ln" href="https://unsplash.com/@askkell?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">安迪·凯利</a>在<a class="ae ln" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上拍摄</figcaption></figure><p id="f91e" class="pw-post-body-paragraph jz ka it kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw im bi translated">当我开始学习数据科学和机器学习时，我首先发现的是不同类型的学习及其相关算法。在ML领域有三种主要的学习类型:<strong class="kb jd">有监督的、无监督的和强化的</strong>。然而，监督和非监督学习是工业中最常见的类型，强化学习较少。在这篇非常短的文章中，我们将探讨这两种学习类型之间的差异，并列出属于每一类的常见算法。</p><h1 id="1c22" class="lo lp it bd lq lr ls lt lu lv lw lx ly lz ma mb mc md me mf mg mh mi mj mk ml bi translated">监督学习</h1><p id="5883" class="pw-post-body-paragraph jz ka it kb b kc mm ke kf kg mn ki kj kk mo km kn ko mp kq kr ks mq ku kv kw im bi translated">这是工业中最常用的类型，指的是标有<strong class="kb jd">输出</strong>的数据。通俗地说，这意味着我们的数据集有一个已知的输出。因此，监督学习的目标是使最佳模型与给定数据中的一组已知输入和输出相匹配。这使您能够从过去的经验中最大限度地提高性能，并发现哪些功能最能推动决策的关键见解。</p><p id="2ce7" class="pw-post-body-paragraph jz ka it kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw im bi translated">监督学习主要处理两类问题:<strong class="kb jd">分类</strong>和<strong class="kb jd">回归</strong>。</p><h2 id="0643" class="mr lp it bd lq ms mt dn lu mu mv dp ly kk mw mx mc ko my mz mg ks na nb mk iz bi translated">分类</h2><p id="2081" class="pw-post-body-paragraph jz ka it kb b kc mm ke kf kg mn ki kj kk mo km kn ko mp kq kr ks mq ku kv kw im bi translated">当标记的输出为<strong class="kb jd">真或假</strong>时，例如，是否购买汽车，这是一个分类问题，因为结果是<strong class="kb jd">二进制</strong> (1或0)。分类算法包括逻辑回归、支持向量机、决策树和神经网络。</p><h2 id="1b98" class="mr lp it bd lq ms mt dn lu mu mv dp ly kk mw mx mc ko my mz mg ks na nb mk iz bi translated">回归</h2><p id="ba83" class="pw-post-body-paragraph jz ka it kb b kc mm ke kf kg mn ki kj kk mo km kn ko mp kq kr ks mq ku kv kw im bi translated">如果数据有一个<strong class="kb jd">连续</strong>的输出，比如房价，那么我们就需要一个回归模型。算法包括线性回归、CatBoost和回归决策树。</p><h1 id="1dda" class="lo lp it bd lq lr ls lt lu lv lw lx ly lz ma mb mc md me mf mg mh mi mj mk ml bi translated">无监督学习</h1><p id="4043" class="pw-post-body-paragraph jz ka it kb b kc mm ke kf kg mn ki kj kk mo km kn ko mp kq kr ks mq ku kv kw im bi translated">对于无监督学习，数据没有标签输出。在这种情况下，我们试图在没有任何固有标签或特征的数据中找到模式和结构，并且没有“正确的答案”与监督学习一样，非监督学习可以分为两类:<strong class="kb jd">聚类</strong>和<strong class="kb jd">关联。</strong></p><h2 id="f13f" class="mr lp it bd lq ms mt dn lu mu mv dp ly kk mw mx mc ko my mz mg ks na nb mk iz bi translated"><strong class="ak">聚类</strong></h2><p id="533c" class="pw-post-body-paragraph jz ka it kb b kc mm ke kf kg mn ki kj kk mo km kn ko mp kq kr ks mq ku kv kw im bi translated">这种方法就是将数据合并成具有相似特征的<strong class="kb jd">簇</strong>来寻找模式，因此它被称为聚类。常见的算法包括K均值聚类。</p><h2 id="7f32" class="mr lp it bd lq ms mt dn lu mu mv dp ly kk mw mx mc ko my mz mg ks na nb mk iz bi translated">联合</h2><p id="f4cf" class="pw-post-body-paragraph jz ka it kb b kc mm ke kf kg mn ki kj kk mo km kn ko mp kq kr ks mq ku kv kw im bi translated">在这项技术中，我们试图找到数据集特征之间的<strong class="kb jd">隐藏规则</strong>。一种简单的思考方式是，我们试图测量可能给出相同输出的特性之间的相关性。使用关联的常见算法是Apriori算法。</p><h1 id="7f1e" class="lo lp it bd lq lr ls lt lu lv lw lx ly lz ma mb mc md me mf mg mh mi mj mk ml bi translated">半监督学习</h1><p id="64bf" class="pw-post-body-paragraph jz ka it kb b kc mm ke kf kg mn ki kj kk mo km kn ko mp kq kr ks mq ku kv kw im bi translated">这也是另一种类型的学习，它结合了无监督和监督学习的理念，被“巧妙地”称为半监督学习。这适用于我们通常有少量标记数据而有大量未标记数据的情况。我不会深入讨论这个范例，但是感兴趣的读者可以找到许多关于它的博客和文章。</p><h1 id="827d" class="lo lp it bd lq lr ls lt lu lv lw lx ly lz ma mb mc md me mf mg mh mi mj mk ml bi translated">摘要</h1><p id="c1d1" class="pw-post-body-paragraph jz ka it kb b kc mm ke kf kg mn ki kj kk mo km kn ko mp kq kr ks mq ku kv kw im bi translated">在这篇短文中，我们描述并解释了监督学习和非监督学习的区别。正如我刚才展示的，这一切都归结于数据是否有一个标记输出。</p><h1 id="3efb" class="lo lp it bd lq lr ls lt lu lv lw lx ly lz ma mb mc md me mf mg mh mi mj mk ml bi translated">和我联系！</h1><ul class=""><li id="ca40" class="nc nd it kb b kc mm kg mn kk ne ko nf ks ng kw nh ni nj nk bi translated"><a class="ae ln" href="/@egorhowell/membership" rel="noopener ugc nofollow" target="_blank"> <em class="nl">要想在媒体上阅读无限的故事，请务必在这里注册！</em> </a> <em class="nl"> </em>💜</li><li id="9786" class="nc nd it kb b kc nm kg nn kk no ko np ks nq kw nh ni nj nk bi translated"><a class="ae ln" href="/subscribe/@egorhowell" rel="noopener ugc nofollow" target="_blank"> <em class="nl">在我发布注册邮件通知时获得更新！</em>T13<em class="nl">T15】😀</em></a></li><li id="b8dc" class="nc nd it kb b kc nm kg nn kk no ko np ks nq kw nh ni nj nk bi translated"><a class="ae ln" href="https://www.linkedin.com/in/egor-howell-092a721b3/" rel="noopener ugc nofollow" target="_blank"> <em class="nl">领英</em> </a> <em class="nl"> </em>👔</li><li id="a7a0" class="nc nd it kb b kc nm kg nn kk no ko np ks nq kw nh ni nj nk bi translated"><a class="ae ln" href="https://twitter.com/EgorHowell" rel="noopener ugc nofollow" target="_blank"> <em class="nl">碎碎念</em> </a> <em class="nl"> </em> 🖊</li><li id="fb18" class="nc nd it kb b kc nm kg nn kk no ko np ks nq kw nh ni nj nk bi translated"><a class="ae ln" href="https://github.com/egorhowell" rel="noopener ugc nofollow" target="_blank"><em class="nl">github</em></a><em class="nl"/>🖥</li><li id="87b0" class="nc nd it kb b kc nm kg nn kk no ko np ks nq kw nh ni nj nk bi translated"><a class="ae ln" href="https://www.kaggle.com/egorphysics" rel="noopener ugc nofollow" target="_blank"><em class="nl"/></a><em class="nl"/>🏅</li></ul><blockquote class="nr ns nt"><p id="8c0c" class="jz ka nl kb b kc kd ke kf kg kh ki kj nu kl km kn nv kp kq kr nw kt ku kv kw im bi translated">(所有表情符号由<a class="ae ln" href="https://openmoji.org/" rel="noopener ugc nofollow" target="_blank"> OpenMoji </a>设计——开源表情符号和图标项目。许可证:<a class="ae ln" href="https://creativecommons.org/licenses/by-sa/4.0/#" rel="noopener ugc nofollow" target="_blank"> CC BY-SA 4.0 </a></p></blockquote></div></div>    
</body>
</html>