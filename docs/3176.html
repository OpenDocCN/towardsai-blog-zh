<html>
<head>
<title>CPU Real-time Face Detection With Python</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">用Python实现CPU实时人脸检测</h1>
<blockquote>原文：<a href="https://pub.towardsai.net/cpu-real-time-face-detection-with-python-21e0473451c4?source=collection_archive---------1-----------------------#2022-10-03">https://pub.towardsai.net/cpu-real-time-face-detection-with-python-21e0473451c4?source=collection_archive---------1-----------------------#2022-10-03</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="0162" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">本教程将教我们使用MediaPipe库检测图像、视频或网络视频流中的人脸和人脸标志，并显示出来！</h2></div><figure class="ki kj kk kl gt km"><div class="bz fp l di"><div class="kn ko l"/></div></figure><p id="0542" class="pw-post-body-paragraph kp kq it kr b ks kt ju ku kv kw jx kx ky kz la lb lc ld le lf lg lh li lj lk im bi translated"><strong class="kr iu">您见过的最先进的数据科学路线图！附带数以千计的免费学习资源和ChatGPT集成！</strong><a class="ae ll" href="https://87v9.short.gy/K93jZA" rel="noopener ugc nofollow" target="_blank"><strong class="kr iu"/></a></p><p id="fbe8" class="pw-post-body-paragraph kp kq it kr b ks kt ju ku kv kw jx kx ky kz la lb lc ld le lf lg lh li lj lk im bi translated">有可能在没有GPU的情况下实现实时性能对象检测模型吗？MediaPipe人脸检测是一个概念验证，它使得在几乎任何CPU上实时运行单类人脸检测成为可能。</p><figure class="ki kj kk kl gt km gh gi paragraph-image"><div class="ab gu cl lm"><img src="../Images/68605848d6c54bbe515729e810b47032.png" data-original-src="https://miro.medium.com/v2/format:webp/1*9UGEaDhhWVmqEtmVXA394A.jpeg"/></div><figcaption class="lp lq gj gh gi lr ls bd b be z dk translated">来源:图片由<a class="ae ll" href="https://unsplash.com/photos/7YVZYZeITc8" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上的<a class="ae ll" href="https://unsplash.com/@juricakoletic" rel="noopener ugc nofollow" target="_blank"> juricakoletic </a>提供</figcaption></figure><h2 id="1c6c" class="lt lu it bd lv lw lx dn ly lz ma dp mb ky mc md me lc mf mg mh lg mi mj mk ml bi translated">有什么问题？</h2><p id="8121" class="pw-post-body-paragraph kp kq it kr b ks mm ju ku kv mn jx kx ky mo la lb lc mp le lf lg mq li lj lk im bi translated">可能有许多需要单个类对象检测的情况。例如，我们想要检测属于一个类的所有对象的位置。例如，我们可以为人脸识别系统检测人脸，或者在实时相机对话中跟踪人脸。</p><p id="a11e" class="pw-post-body-paragraph kp kq it kr b ks kt ju ku kv kw jx kx ky kz la lb lc ld le lf lg lh li lj lk im bi translated">此外，大多数时候，我们希望实时运行这些模型。为了实现这一点，我们必须快速捕捉帧，我们的模型应该更快地对这些帧进行推理！这使我们能够在图像可用时立即对其进行处理。</p><p id="1db3" class="pw-post-body-paragraph kp kq it kr b ks kt ju ku kv kw jx kx ky kz la lb lc ld le lf lg lh li lj lk im bi translated">几年前，解决这一任务最容易获得和使用的解决方案(以及计算机视觉中的许多其他解决方案)是在先前训练的模型上执行<a class="ae ll" href="https://en.wikipedia.org/wiki/Transfer_learning" rel="noopener ugc nofollow" target="_blank">转移学习</a>(通常，在大规模数据集上训练的标准模型，如在<a class="ae ll" href="https://www.tensorflow.org/hub/" rel="noopener ugc nofollow" target="_blank"> Tensorflow Hub </a>或<a class="ae ll" href="https://github.com/tensorflow/models/blob/master/research/object_detection/g3doc/detection_model_zoo.md" rel="noopener ugc nofollow" target="_blank"> TF对象检测API </a>中找到的那些)。</p><p id="31a7" class="pw-post-body-paragraph kp kq it kr b ks kt ju ku kv kw jx kx ky kz la lb lc ld le lf lg lh li lj lk im bi translated">没有GPU，通用对象检测模型(如上所述)无法实时运行。许多经过训练的对象检测架构(如YOLO、FasterRCNN、SSD)在GPU上运行的实时推理中实现了令人印象深刻的准确性。但是，仅仅为了好玩而拥有一个专用的GPU来实现实时推理是不可行的，也是不值得的。</p><p id="fa46" class="pw-post-body-paragraph kp kq it kr b ks kt ju ku kv kw jx kx ky kz la lb lc ld le lf lg lh li lj lk im bi translated">我提到的模型致力于解决多类检测问题。只检测图像中的人脸比检测汽车、人、交通标志和狗(都在同一模型中)更简单。如果我们定义更详细的任务，我们可以假设网络需要学习更少的特征来执行工作。</p><h2 id="74cd" class="lt lu it bd lv lw lx dn ly lz ma dp mb ky mc md me lc mf mg mh lg mi mj mk ml bi translated">简介:</h2><p id="a657" class="pw-post-body-paragraph kp kq it kr b ks mm ju ku kv mn jx kx ky mo la lb lc mp le lf lg mq li lj lk im bi translated">本教程将教我们使用MediaPipe库检测图像、视频或网络视频流中的人脸。大量相似的算法和模型可以完成同样的任务。在这里，我们将借助Mediapipe库遍历检测管道，并经历一步一步的代码解释。</p><p id="7658" class="pw-post-body-paragraph kp kq it kr b ks kt ju ku kv kw jx kx ky kz la lb lc ld le lf lg lh li lj lk im bi translated">在继续之前，不要混淆面部检测和面部标志检测。面部检测检测您的整个面部，并绘制一个矩形框。面部标志检测面部特征，例如鼻子、眼睛、嘴和耳朵。在本教程中，我们将同时捕捉两者，因为MediaPipe人脸检测算法在一个模型中提供了两者。</p><h2 id="8c36" class="lt lu it bd lv lw lx dn ly lz ma dp mb ky mc md me lc mf mg mh lg mi mj mk ml bi translated">少数人脸检测应用:</h2><ul class=""><li id="95ad" class="mr ms it kr b ks mm kv mn ky mt lc mu lg mv lk mw mx my mz bi translated">人脸检测只是人脸识别之前的一个步骤，因为在我们能够识别人脸之前，我们首先需要定位它；</li><li id="9be1" class="mr ms it kr b ks na kv nb ky nc lc nd lg ne lk mw mx my mz bi translated">人脸情感识别是人脸检测的另一个广泛应用的用例；</li><li id="55f5" class="mr ms it kr b ks na kv nb ky nc lc nd lg ne lk mw mx my mz bi translated">因此，当我们使用智能手机的锁屏时，该应用程序可以识别我们的面部。人脸检测是要遵循的第一步；</li><li id="de70" class="mr ms it kr b ks na kv nb ky nc lc nd lg ne lk mw mx my mz bi translated">保安公司使用面部识别来保护他们的场所；</li><li id="eaca" class="mr ms it kr b ks na kv nb ky nc lc nd lg ne lk mw mx my mz bi translated">移民检查站使用面部识别来加强更智能的边境控制；</li><li id="8812" class="mr ms it kr b ks na kv nb ky nc lc nd lg ne lk mw mx my mz bi translated">车队公司可以使用面部识别来保护他们的车辆；</li><li id="6298" class="mr ms it kr b ks na kv nb ky nc lc nd lg ne lk mw mx my mz bi translated">拼车公司可以使用面部识别来确保正确的司机搭载正确的乘客；</li><li id="d31e" class="mr ms it kr b ks na kv nb ky nc lc nd lg ne lk mw mx my mz bi translated">面部识别对物联网很有用，因为它允许改善家庭中的安全措施和自动访问控制；</li><li id="a942" class="mr ms it kr b ks na kv nb ky nc lc nd lg ne lk mw mx my mz bi translated">面部识别技术作为人工智能监控系统的一部分，可以被执法部门使用；</li><li id="4f03" class="mr ms it kr b ks na kv nb ky nc lc nd lg ne lk mw mx my mz bi translated">零售商可以使用面部识别来定制线下产品，理论上可以将在线购买习惯与在线购买习惯进行映射；</li></ul><p id="c892" class="pw-post-body-paragraph kp kq it kr b ks kt ju ku kv kw jx kx ky kz la lb lc ld le lf lg lh li lj lk im bi translated">面部检测和识别技术已经成为许多行业使用的某种商品，我相信不可能列出所有可用的应用程序。</p><h2 id="1d61" class="lt lu it bd lv lw lx dn ly lz ma dp mb ky mc md me lc mf mg mh lg mi mj mk ml bi translated">基于MediaPipe库的人脸检测</h2><p id="ce61" class="pw-post-body-paragraph kp kq it kr b ks mm ju ku kv mn jx kx ky mo la lb lc mp le lf lg mq li lj lk im bi translated">在本教程中，我们将使用<a class="ae ll" href="https://google.github.io/mediapipe/solutions/face_detection.html" rel="noopener ugc nofollow" target="_blank"> Mediapipe的人脸检测模型</a>执行人脸检测功能。如果我们打开这款机型给定的深度概览，可以发现它完全基于BlazeFace机型，性能良好，轻量级。该模型侧重于在低端CPU和移动GPU上运行，以产生实时推理。它说推断速度是每秒200-1000帧，这取决于设备的规格。</p><p id="da10" class="pw-post-body-paragraph kp kq it kr b ks kt ju ku kv kw jx kx ky kz la lb lc ld le lf lg lh li lj lk im bi translated">如果你学习了我的关于<a class="ae ll" href="../remove-background" rel="noopener ugc nofollow" target="_blank">实时自拍分割</a>的教程，你应该已经熟悉我写的代码了。如果你没有机会看的话，我建议你快速浏览一下，因为我会继续做同一个项目。这一次，我将重点创建面部检测对象，我们将在该引擎上使用。</p><p id="3f18" class="pw-post-body-paragraph kp kq it kr b ks kt ju ku kv kw jx kx ky kz la lb lc ld le lf lg lh li lj lk im bi translated">以下是使用MediaPipe人脸检测器的完整人脸检测对象:</p><figure class="ki kj kk kl gt km"><div class="bz fp l di"><div class="nf ko l"/></div></figure><p id="a081" class="pw-post-body-paragraph kp kq it kr b ks kt ju ku kv kw jx kx ky kz la lb lc ld le lf lg lh li lj lk im bi translated">在使用Mediapipe面部检测模型之前，我们必须首先初始化该模型。为此，我们将使用简单的语法作为<code class="fe ng nh ni nj b">mp.solution.face_detection</code>，在初始化模型后，我们将使用一些参数调用人脸检测函数。初始化模型时有两个基本参数:</p><ul class=""><li id="3084" class="mr ms it kr b ks kt kv kw ky nk lc nl lg nm lk mw mx my mz bi translated"><strong class="kr iu"> model_selection </strong>:该参数取整数索引(0或1)。对于近距离人脸，建议使用0，它在距离相机2米以内效果最好。全范围模型推荐使用1，它最适合5米以内的人脸。如果未指定，默认值为0。</li><li id="f414" class="mr ms it kr b ks na kv nb ky nc lc nd lg ne lk mw mx my mz bi translated"><strong class="kr iu">min _ detection _ confidence</strong>:该参数取0.0到1.0范围内的浮点值。这里的默认值是0.5，相当于50%的置信度。例如，当检测人脸时，结果应该至少有50%的置信度表明人脸在那里；否则，它什么也检测不到。</li></ul><p id="537c" class="pw-post-body-paragraph kp kq it kr b ks kt ju ku kv kw jx kx ky kz la lb lc ld le lf lg lh li lj lk im bi translated">因此，当我们定义我们的<code class="fe ng nh ni nj b">MPfaceDetection</code>对象时，我们在内存中创建我们的模型。在下一步中，我们需要将我们的帧提供给这个对象。现在，当我们向我们的对象提供图像时，我们将使用来自<code class="fe ng nh ni nj b">FaceDetection</code>对象的<code class="fe ng nh ni nj b">process()</code>函数。如果我们仔细观察我们的结果，我们会看到每个检测到的人脸有六个坐标。这些坐标代表右眼、左眼、鼻尖、嘴中心、右耳区域和左耳区域。</p><p id="3f70" class="pw-post-body-paragraph kp kq it kr b ks kt ju ku kv kw jx kx ky kz la lb lc ld le lf lg lh li lj lk im bi translated">为了在我们的脸周围绘制一个矩形，MediaPipe有一个名为<code class="fe ng nh ni nj b">mp.drawing</code>的内置函数，我们在对象初始化步骤中初始化了这个函数。要画出矩形和主要人脸部分就像每次人脸检测调用<code class="fe ng nh ni nj b">mp_drawing.draw_detection</code>函数一样简单。</p><p id="214f" class="pw-post-body-paragraph kp kq it kr b ks kt ju ku kv kw jx kx ky kz la lb lc ld le lf lg lh li lj lk im bi translated">我还加了一个参数“<code class="fe ng nh ni nj b">mp_drawing_utils = True</code>”，有了这个参数，我们就用上了<code class="fe ng nh ni nj b">mp.drawing</code> utils。否则，我们可以使用OpenCV <code class="fe ng nh ni nj b">cv2.rectangle</code>函数用我们的颜色和厚度在我们的框架上绘制检测。此外，有时我们只对获取检测坐标感兴趣。当我们调用我们的对象时，我们可以通过设置<code class="fe ng nh ni nj b">return_tlbr</code> bool选项来获得它们。因此，我们可以只返回不同情况下的检测结果，而不是在一个帧上绘制矩形，这取决于用例。</p><p id="0238" class="pw-post-body-paragraph kp kq it kr b ks kt ju ku kv kw jx kx ky kz la lb lc ld le lf lg lh li lj lk im bi translated">下面是一个简单的代码示例，仅使用摄像头流上的人脸检测对象运行我们的引擎:</p><figure class="ki kj kk kl gt km"><div class="bz fp l di"><div class="nf ko l"/></div></figure><p id="a78c" class="pw-post-body-paragraph kp kq it kr b ks kt ju ku kv kw jx kx ky kz la lb lc ld le lf lg lh li lj lk im bi translated">由此，我们应该看到与我相似的观点:</p><figure class="ki kj kk kl gt km gh gi paragraph-image"><div class="ab gu cl lm"><img src="../Images/975fb3c1d062bea99bf5b6e5d79dd75f.png" data-original-src="https://miro.medium.com/v2/format:webp/1*Z5ac_z_UYXwiWFIFNTo8kA.png"/></div></figure><h1 id="b1a6" class="nn lu it bd lv no np nq ly nr ns nt mb jz nu ka me kc nv kd mh kf nw kg mk nx bi translated">结论:</h1><p id="cd87" class="pw-post-body-paragraph kp kq it kr b ks mm ju ku kv mn jx kx ky mo la lb lc mp le lf lg mq li lj lk im bi translated">在本教程中，我们了解了使用MediaPipe库来检测图像、保存的视频或实时网络摄像头流中的人脸是多么简单。我向您介绍了如何创建一个自定义对象，以便在我的引擎对象中使用。类似地，我们可以为任何其他人脸检测实现创建一个对象，并将其用于相同的引擎。</p><p id="52cf" class="pw-post-body-paragraph kp kq it kr b ks kt ju ku kv kw jx kx ky kz la lb lc ld le lf lg lh li lj lk im bi translated">有了所有这些代码，我们已经将检测到的人脸结果与一些标志如嘴、耳朵、眼睛和鼻子可视化了。对于不同的角度，地标的结果可能不是那么精确，但是对于正面来说是方便的。</p><p id="5fd9" class="pw-post-body-paragraph kp kq it kr b ks kt ju ku kv kw jx kx ky kz la lb lc ld le lf lg lh li lj lk im bi translated">在下一个教程中，我将创建另一个对象，它将允许我们自己绘制草图或制作动画。那太棒了！</p><p id="e14b" class="pw-post-body-paragraph kp kq it kr b ks kt ju ku kv kw jx kx ky kz la lb lc ld le lf lg lh li lj lk im bi translated">感谢阅读！一如既往，本教程给出的所有代码都可以在我的<a class="ae ll" href="https://github.com/pythonlessons/background_removal" rel="noopener ugc nofollow" target="_blank"> GitHub </a>页面找到，并且免费使用！</p></div><div class="ab cl ny nz hx oa" role="separator"><span class="ob bw bk oc od oe"/><span class="ob bw bk oc od oe"/><span class="ob bw bk oc od"/></div><div class="im in io ip iq"><p id="7d1b" class="pw-post-body-paragraph kp kq it kr b ks kt ju ku kv kw jx kx ky kz la lb lc ld le lf lg lh li lj lk im bi translated"><em class="of">原载于</em>【https://pylessons.com/face-detection】<em class="of"/></p></div></div>    
</body>
</html>