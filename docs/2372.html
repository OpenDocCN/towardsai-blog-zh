<html>
<head>
<title>Credit Default Modelling Using Decision Trees</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">使用决策树的信用违约建模</h1>
<blockquote>原文：<a href="https://pub.towardsai.net/random-forest-medium-article-736c3f9514f4?source=collection_archive---------2-----------------------#2021-11-25">https://pub.towardsai.net/random-forest-medium-article-736c3f9514f4?source=collection_archive---------2-----------------------#2021-11-25</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><div class=""><h2 id="3e32" class="pw-subtitle-paragraph jn ip iq bd b jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke dk translated">使用基于树的技术检测信用价值</h2></div><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi kf"><img src="../Images/8f719b7d4e0a76e2d4f52e27ed0be837.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*3rHan-UbUZ5WrbCMrHSdLw.jpeg"/></div></div><figcaption class="kr ks gj gh gi kt ku bd b be z dk translated">瑞安·博恩摄于<a class="ae kv" href="https://unsplash.com/photos/x8i6FfaZAbs" rel="noopener ugc nofollow" target="_blank"> Unsplash </a></figcaption></figure><p id="1f4d" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">历史上，机器学习算法一直用于信用和欺诈领域。随着计算能力的提高，行业已经从基于树的Logit模型转向更先进的机器学习技术，包括打包和提升。行业。这篇文章旨在为读者提供决策树、Bagging和随机森林算法的数学观点。在最后一节，作者讨论了如何利用LendingClub的数据将这些技术用于信用违约和欺诈防范。</p><h1 id="9cb2" class="ls lt iq bd lu lv lw lx ly lz ma mb mc jw md jx me jz mf ka mg kc mh kd mi mj bi translated"><strong class="ak">决策树</strong></h1><h2 id="402d" class="mk lt iq bd lu ml mm dn ly mn mo dp mc lf mp mq me lj mr ms mg ln mt mu mi mv bi translated">1.介绍</h2><p id="3a27" class="pw-post-body-paragraph kw kx iq ky b kz mw jr lb lc mx ju le lf my lh li lj mz ll lm ln na lp lq lr ij bi translated">决策树背后的基本直觉是以二叉树的形式绘制出所有可能的决策路径。用使用萼片长宽比(x1)和花瓣长宽比(x2)来识别花类型(y)的例子来展示相同的内容</p><p id="b68e" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">x1&gt;1.7的初始分裂有助于识别花类型y=1</p><p id="5757" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">在x2&gt;2.8处的下一个节点分裂有助于识别y=2和y=3</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi nb"><img src="../Images/e07e5e1854c3defd7fae6fe83031437e.png" data-original-src="https://miro.medium.com/v2/resize:fit:778/format:webp/1*_4SGe9tCixX2Wl3MeLmPmg.jpeg"/></div><figcaption class="kr ks gj gh gi kt ku bd b be z dk translated">决策树的示例</figcaption></figure><p id="e7f5" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">数学上，<strong class="ky ir">决策树</strong>使用二元决策规则将输入<strong class="ky ir"> x ∈ R^d </strong>映射到输出<strong class="ky ir"> y </strong>:</p><h2 id="886b" class="mk lt iq bd lu ml mm dn ly mn mo dp mc lf mp mq me lj mr ms mg ln mt mu mi mv bi translated">树中的每个节点都有一个拆分规则</h2><ul class=""><li id="dc6b" class="nc nd iq ky b kz mw lc mx lf ne lj nf ln ng lr nh ni nj nk bi translated">基于自顶向下贪婪算法的分裂</li><li id="dc08" class="nc nd iq ky b kz nl lc nm lf nn lj no ln np lr nh ni nj nk bi translated">每个叶节点都与一个输出值相关联</li></ul><h2 id="bac8" class="mk lt iq bd lu ml mm dn ly mn mo dp mc lf mp mq me lj mr ms mg ln mt mu mi mv bi translated">每个拆分规则的形式如下</h2><ul class=""><li id="221c" class="nc nd iq ky b kz mw lc mx lf ne lj nf ln ng lr nh ni nj nk bi translated">h(x) = 1{xj &gt; t}</li></ul><h2 id="79ef" class="mk lt iq bd lu ml mm dn ly mn mo dp mc lf mp mq me lj mr ms mg ln mt mu mi mv bi translated">2.分割标准</h2><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi nq"><img src="../Images/f95a416ffcf0c8321346c4dec6eb9eee.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*XsAbbEuj4IsbxGUcKK1-bA.jpeg"/></div></div></figure><h2 id="6219" class="mk lt iq bd lu ml mm dn ly mn mo dp mc lf mp mq me lj mr ms mg ln mt mu mi mv bi translated">3.几何视图</h2><h2 id="1b3e" class="mk lt iq bd lu ml mm dn ly mn mo dp mc lf mp mq me lj mr ms mg ln mt mu mi mv bi translated">动机:</h2><ul class=""><li id="5d5f" class="nc nd iq ky b kz mw lc mx lf ne lj nf ln ng lr nh ni nj nk bi translated">对空间进行分区，使一个区域中的数据具有相同的预测</li><li id="2099" class="nc nd iq ky b kz nl lc nm lf nn lj no ln np lr nh ni nj nk bi translated">每个分区代表二维平面中的一条垂直线或水平线</li></ul><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi nr"><img src="../Images/baabc5217c75e8677215732bf4b4db08.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*KBgHVmlR0lWjB8fiPDaVfQ.jpeg"/></div></div><figcaption class="kr ks gj gh gi kt ku bd b be z dk translated">决策树的几何视图</figcaption></figure><h2 id="ad84" class="mk lt iq bd lu ml mm dn ly mn mo dp mc lf mp mq me lj mr ms mg ln mt mu mi mv bi translated">4.挑战</h2><ul class=""><li id="d652" class="nc nd iq ky b kz mw lc mx lf ne lj nf ln ng lr nh ni nj nk bi translated">决策树不能推断</li></ul><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi ns"><img src="../Images/cdc08e16262d7b8956aa4c04f2c8af34.png" data-original-src="https://miro.medium.com/v2/resize:fit:700/format:webp/1*_lFk9vmeQloV4ZRDILYcqQ.jpeg"/></div></figure><ul class=""><li id="3fee" class="nc nd iq ky b kz la lc ld lf nt lj nu ln nv lr nh ni nj nk bi translated">数据变化的高方差或不稳定性:通过数据的微小变化，我们可以看到决策树结构的变化</li><li id="f2c5" class="nc nd iq ky b kz nl lc nm lf nn lj no ln np lr nh ni nj nk bi translated">决策树中高方差的原因在于它们是基于贪婪算法的事实。它侧重于优化手头的节点分裂，而不是考虑分裂如何影响整个树。贪婪的方法使决策树运行得更快，但也使它们容易<strong class="ky ir">过度拟合</strong>。</li></ul><p id="e0c2" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">在接下来的部分中，我们将讨论如何克服这些挑战</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi nw"><img src="../Images/c10055c7785f9eb19c7e452bdf164eed.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*PRSd14GW-bvfmCzaqrlYjA.jpeg"/></div></div><figcaption class="kr ks gj gh gi kt ku bd b be z dk translated">不同的整体建筑——托马斯·格里斯贝克<a class="ae kv" href="https://unsplash.com/@jack_scorner?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText" rel="noopener ugc nofollow" target="_blank">在</a><a class="ae kv" href="https://unsplash.com/s/photos/forest?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上拍摄的照片</figcaption></figure><h1 id="6a91" class="ls lt iq bd lu lv lw lx ly lz ma mb mc jw md jx me jz mf ka mg kc mh kd mi mj bi translated">引导聚合器</h1><h2 id="dfc3" class="mk lt iq bd lu ml mm dn ly mn mo dp mc lf mp mq me lj mr ms mg ln mt mu mi mv bi translated">1.动机</h2><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi nx"><img src="../Images/21f0d71f528d487728d5986433983b5e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*4qkRPo6tvBh0_Hk5uwwy6w.jpeg"/></div></div></figure><h2 id="f317" class="mk lt iq bd lu ml mm dn ly mn mo dp mc lf mp mq me lj mr ms mg ln mt mu mi mv bi translated">2.算法</h2><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi ny"><img src="../Images/3af27ce9064709617974a5c5d91924d7.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*tNMY7LdAuIym8DxUx4Hh1w.jpeg"/></div></div></figure><h1 id="678b" class="ls lt iq bd lu lv lw lx ly lz ma mb mc jw md jx me jz mf ka mg kc mh kd mi mj bi translated">随机森林</h1><h2 id="fc4e" class="mk lt iq bd lu ml mm dn ly mn mo dp mc lf mp mq me lj mr ms mg ln mt mu mi mv bi translated">1.动机</h2><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi nz"><img src="../Images/d457fceadf8c3f6a9ecca97e35dcf1db.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*X1Sk2aMuEdZB8gUl1ULxTw.jpeg"/></div></div></figure><h2 id="90c5" class="mk lt iq bd lu ml mm dn ly mn mo dp mc lf mp mq me lj mr ms mg ln mt mu mi mv bi translated">2.算法</h2><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi oa"><img src="../Images/5ea3e7ae95a1121818a4b122d543fb44.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*9959LACwh-hym-l7l7r-vw.jpeg"/></div></div></figure><p id="8849" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">随机森林的另一个优势是它不需要维持数据集，因此可以有效地处理较小的数据集。我们可以计算出袋外(OOB)误差，而不是测试误差。其框架如下所示:</p><h2 id="5552" class="mk lt iq bd lu ml mm dn ly mn mo dp mc lf mp mq me lj mr ms mg ln mt mu mi mv bi translated">3.出包错误</h2><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi ob"><img src="../Images/a29b36ba85c73ef2595a928c66bcae7c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*ARIqQU1bamE5YuX_lFd-1w.jpeg"/></div></div></figure><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi oc"><img src="../Images/71da35718e0bfc67281e3257871ba471.png" data-original-src="https://miro.medium.com/v2/resize:fit:1180/format:webp/1*SjfnpynR3D9nE109e3mj9A.jpeg"/></div><figcaption class="kr ks gj gh gi kt ku bd b be z dk translated">创建袋外器械包的示例</figcaption></figure><h1 id="e5de" class="ls lt iq bd lu lv lw lx ly lz ma mb mc jw md jx me jz mf ka mg kc mh kd mi mj bi translated">朱庇特实验室</h1><p id="d9f8" class="pw-post-body-paragraph kw kx iq ky b kz mw jr lb lc mx ju le lf my lh li lj mz ll lm ln na lp lq lr ij bi translated">在这里，我们探索来自LendingClub.com的数据</p><p id="d79c" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">考虑到许多不同的因素，包括借款人的FICO分数、利率，甚至贷款的目的，我们试图预测某笔贷款是否会全额偿还。</p><h2 id="d60a" class="mk lt iq bd lu ml mm dn ly mn mo dp mc lf mp mq me lj mr ms mg ln mt mu mi mv bi translated">为什么选择决策树/随机森林？</h2><p id="b52b" class="pw-post-body-paragraph kw kx iq ky b kz mw jr lb lc mx ju le lf my lh li lj mz ll lm ln na lp lq lr ij bi translated">决策树是一种伟大的“粗略且现成的”ML技术，可以应用于许多不同的场景。它们直观、快速，可以处理数字和分类数据。决策树最大的缺点是它们倾向于过度拟合给定的数据，导致方差或偏差的错误。随机森林通过对数据的随机样本采用许多不同的决策树来解决这个问题，因此在选择ML模型时通常是更明智的选择。</p><h2 id="c4ce" class="mk lt iq bd lu ml mm dn ly mn mo dp mc lf mp mq me lj mr ms mg ln mt mu mi mv bi translated">进口</h2><pre class="kg kh ki kj gt od oe of og aw oh bi"><span id="5e37" class="mk lt iq oe b gy oi oj l ok ol">import pandas as pd<br/>import numpy as np<br/>import seaborn as sns<br/>import matplotlib.pyplot as plt<br/>%matplotlib inline</span></pre><h2 id="24b3" class="mk lt iq bd lu ml mm dn ly mn mo dp mc lf mp mq me lj mr ms mg ln mt mu mi mv bi translated">探索性分析</h2><pre class="kg kh ki kj gt od oe of og aw oh bi"><span id="9614" class="mk lt iq oe b gy oi oj l ok ol">loans = pd.read_csv('loan_data.csv')</span><span id="7e2f" class="mk lt iq oe b gy om oj l ok ol">loans.head()</span></pre><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="ab gu cl on"><img src="../Images/d0fe57191c4060622ad0a1c08d539be3.png" data-original-src="https://miro.medium.com/v2/format:webp/1*z2tZPYcmdTLpu3FlSozYGA.png"/></div></figure><p id="6cdc" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">“未完全支付”列是我们有兴趣预测的一列。</p><pre class="kg kh ki kj gt od oe of og aw oh bi"><span id="3a8d" class="mk lt iq oe b gy oi oj l ok ol">loans.info()</span><span id="4fcc" class="mk lt iq oe b gy om oj l ok ol">&lt;class 'pandas.core.frame.DataFrame'&gt;<br/>RangeIndex: 9578 entries, 0 to 9577<br/>Data columns (total 14 columns):<br/> #   Column             Non-Null Count  Dtype  <br/>---  ------             --------------  -----  <br/> 0   credit.policy      9578 non-null   int64  <br/> 1   purpose            9578 non-null   object <br/> 2   int.rate           9578 non-null   float64<br/> 3   installment        9578 non-null   float64<br/> 4   log.annual.inc     9578 non-null   float64<br/> 5   dti                9578 non-null   float64<br/> 6   fico               9578 non-null   int64  <br/> 7   days.with.cr.line  9578 non-null   float64<br/> 8   revol.bal          9578 non-null   int64  <br/> 9   revol.util         9578 non-null   float64<br/> 10  inq.last.6mths     9578 non-null   int64  <br/> 11  delinq.2yrs        9578 non-null   int64  <br/> 12  pub.rec            9578 non-null   int64  <br/> 13  not.fully.paid     9578 non-null   int64  <br/>dtypes: float64(6), int64(7), object(1)<br/>memory usage: 1.0+ MB</span><span id="6125" class="mk lt iq oe b gy om oj l ok ol">loans.describe()</span></pre><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="ab gu cl on"><img src="../Images/1e9eff1763519df9e1cb64fd99ef87b4.png" data-original-src="https://miro.medium.com/v2/format:webp/1*ckCD3z2bTqqd2bhH8F_pNQ.png"/></div></figure><h2 id="9756" class="mk lt iq bd lu ml mm dn ly mn mo dp mc lf mp mq me lj mr ms mg ln mt mu mi mv bi translated"><strong class="ak">部分栏目信息</strong></h2><ul class=""><li id="d3c7" class="nc nd iq ky b kz mw lc mx lf ne lj nf ln ng lr nh ni nj nk bi translated">credit.policy:如果客户符合LendingClub.com的信用核保标准，则为1，否则为0。</li><li id="0212" class="nc nd iq ky b kz nl lc nm lf nn lj no ln np lr nh ni nj nk bi translated">目的:贷款的目的(取值“信用卡”、“债务合并”、“教育”、“主要购买”、“小型企业”和“所有其他”)。</li><li id="12e3" class="nc nd iq ky b kz nl lc nm lf nn lj no ln np lr nh ni nj nk bi translated">int.rate:贷款的利率，以比例表示(11%的利率将存储为0.11)。被LendingClub.com判断为风险较高的借款人会被分配较高的利率。</li><li id="370d" class="nc nd iq ky b kz nl lc nm lf nn lj no ln np lr nh ni nj nk bi translated">分期付款:借款人所欠的每月分期付款，如果贷款是有资金的。</li><li id="d337" class="nc nd iq ky b kz nl lc nm lf nn lj no ln np lr nh ni nj nk bi translated">log.annual.inc:借款人自报年收入的自然日志。</li><li id="36d3" class="nc nd iq ky b kz nl lc nm lf nn lj no ln np lr nh ni nj nk bi translated">dti:借款人的债务收入比(债务额除以年收入)。</li><li id="0f0c" class="nc nd iq ky b kz nl lc nm lf nn lj no ln np lr nh ni nj nk bi translated">fico:借款人的FICO信用评分。</li><li id="397c" class="nc nd iq ky b kz nl lc nm lf nn lj no ln np lr nh ni nj nk bi translated">days.with.cr.line:借款人拥有信用额度的天数。</li><li id="f869" class="nc nd iq ky b kz nl lc nm lf nn lj no ln np lr nh ni nj nk bi translated">revol.bal:借款人的循环余额(信用卡账单周期结束时未支付的金额)。</li><li id="ab5c" class="nc nd iq ky b kz nl lc nm lf nn lj no ln np lr nh ni nj nk bi translated">revol.util:借款人的循环额度利用率(相对于可用信贷总额的已用信贷额度)。</li><li id="20c9" class="nc nd iq ky b kz nl lc nm lf nn lj no ln np lr nh ni nj nk bi translated">inq.last.6mths:最近6个月内债权人对借款人的查询次数。</li><li id="7ff1" class="nc nd iq ky b kz nl lc nm lf nn lj no ln np lr nh ni nj nk bi translated">拖欠2年:在过去的2年中，借款人拖欠还款超过30天的次数。</li><li id="06f3" class="nc nd iq ky b kz nl lc nm lf nn lj no ln np lr nh ni nj nk bi translated">pub.rec:借款人的贬损公共记录数量(破产申请、税收留置权或判决)。</li></ul><h2 id="8c88" class="mk lt iq bd lu ml mm dn ly mn mo dp mc lf mp mq me lj mr ms mg ln mt mu mi mv bi translated">数据可视化</h2><pre class="kg kh ki kj gt od oe of og aw oh bi"><span id="c19c" class="mk lt iq oe b gy oi oj l ok ol">plt.figure(figsize=(11,7))<br/>sns.countplot(loans['purpose'], hue = loans['not.fully.paid'])</span><span id="efe4" class="mk lt iq oe b gy om oj l ok ol">We split our target function with respect to the purpose for which a loan was taken. </span></pre><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="ab gu cl on"><img src="../Images/273750c7ed7e2a468eafcec6cb451e2c.png" data-original-src="https://miro.medium.com/v2/format:webp/1*xuBBqqqXATpF1nYu6HJSvw.png"/></div></figure><pre class="kg kh ki kj gt od oe of og aw oh bi"><span id="7715" class="mk lt iq oe b gy oi oj l ok ol">new_df = loans.groupby('purpose')['not.fully.paid'].value_counts(normalize=True)<br/>new_df = new_df.mul(100).rename('Percent').reset_index()</span><span id="c05f" class="mk lt iq oe b gy om oj l ok ol">new_df1 = new_df[new_df["not.fully.paid"]==1]</span><span id="b813" class="mk lt iq oe b gy om oj l ok ol">new_df1=new_df1.sort_values("Percent")</span><span id="7464" class="mk lt iq oe b gy om oj l ok ol">g=sns.catplot(x="purpose", y='Percent', kind='bar', data=new_df1, aspect=2)<br/>g.ax.set_ylim(0,30)<br/><br/><br/>for p in g.ax.patches:<br/>    txt = str(p.get_height().round(1)) + '%'<br/>    txt_x = p.get_x()<br/>    txt_y = p.get_height()<br/>    g.ax.text(txt_x,txt_y,txt,fontsize=18,verticalalignment='bottom',multialignment='right')</span><span id="979e" class="mk lt iq oe b gy om oj l ok ol">We would like to understand the risk as a percentage hence we look at proportion of unpaid loans in each purpose type</span></pre><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="ab gu cl on"><img src="../Images/0f604f1889ada837dba4d09faa04df64.png" data-original-src="https://miro.medium.com/v2/format:webp/1*OV2aIihO8dCE7opQp2mdbw.png"/></div></figure><pre class="kg kh ki kj gt od oe of og aw oh bi"><span id="12b0" class="mk lt iq oe b gy oi oj l ok ol">sns.boxplot(data =loans, x ='purpose', y= loans['int.rate']).legend().set_visible(False)</span><span id="722c" class="mk lt iq oe b gy om oj l ok ol">Given the knowledge of risk basis purpose, we would like to understand if the APR offered to a customer take into account purpose. </span></pre><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi oo"><img src="../Images/48f33edb98a392a277a206362b19717d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*kZkJVDBSXtPTheMRUTRTLg.jpeg"/></div></div></figure><pre class="kg kh ki kj gt od oe of og aw oh bi"><span id="9f23" class="mk lt iq oe b gy oi oj l ok ol">df=loans<br/>f,(ax1,ax2,ax3)= plt.subplots(1,3,figsize=(25,10))<br/>sns.distplot(df['int.rate'], bins= 30,ax=ax1)<br/>sns.boxplot(data =df, x ='credit.policy', y= df['int.rate'],ax=ax2).legend().set_visible(False)<br/>sns.boxplot(data = df['int.rate'], ax=ax3)<br/>print("Interest Rate Distribution, Credit Policy range based on the Credit policy , General Interest rate")<br/><br/>Interest Rate Distribution, Credit Policy range based on the Credit policy , General Interest rate</span></pre><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="ab gu cl on"><img src="../Images/7466012cb663ba42bfdea79b6c6d1516.png" data-original-src="https://miro.medium.com/v2/format:webp/1*J2f2r3qnXBDwsOP6oT-RnQ.png"/></div></figure><pre class="kg kh ki kj gt od oe of og aw oh bi"><span id="ff1f" class="mk lt iq oe b gy oi oj l ok ol">plt.figure(figsize=(10,6))<br/>loans[loans['credit.policy']==1]['fico'].hist(alpha=0.5,color='blue',<br/>                                              bins=30,label='Credit.Policy=1')<br/>loans[loans['credit.policy']==0]['fico'].hist(alpha=0.5,color='red',<br/>                                              bins=30,label='Credit.Policy=0')<br/>plt.legend()<br/>plt.xlabel('FICO')</span><span id="04cd" class="mk lt iq oe b gy om oj l ok ol">Text(0.5, 0, 'FICO')</span><span id="fe2a" class="mk lt iq oe b gy om oj l ok ol">To understand if Credit Policy Underwriting from Lending Club have FICO based cut-off for applying customers, we look at the following histogram. </span></pre><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="ab gu cl on"><img src="../Images/3e41377effa49e924a1d90c63b4b44ad.png" data-original-src="https://miro.medium.com/v2/format:webp/1*DE5ecNp5lbb2xrB7n-7Olg.png"/></div></figure><pre class="kg kh ki kj gt od oe of og aw oh bi"><span id="f577" class="mk lt iq oe b gy oi oj l ok ol">sns.boxplot(data =loans, x ='credit.policy', y= loans['fico']).legend().set_visible(False)</span><span id="981e" class="mk lt iq oe b gy om oj l ok ol">Credit Policy promotes individuals with Higher FICO </span></pre><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="ab gu cl on"><img src="../Images/29f63dad758d0dab2f85185c4bf61e15.png" data-original-src="https://miro.medium.com/v2/format:webp/1*R1TfjXR455RX63KQdC7a2w.png"/></div></figure><p id="c5a4" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">让我们在数字数据之间绘制一个seaborn pairplot:</p><pre class="kg kh ki kj gt od oe of og aw oh bi"><span id="b744" class="mk lt iq oe b gy oi oj l ok ol">sns.pairplot(loans.drop(['credit.policy', 'purpose',<br/>       'inq.last.6mths', 'delinq.2yrs', 'pub.rec', 'not.fully.paid'], axis=1))</span><span id="c83e" class="mk lt iq oe b gy om oj l ok ol">&lt;seaborn.axisgrid.PairGrid at 0x1d9e00432c8&gt;</span></pre><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="ab gu cl on"><img src="../Images/24dee4019008d8315518bdff89a03466.png" data-original-src="https://miro.medium.com/v2/format:webp/1*GABOO6dYjHsh6TaFhlVprg.png"/></div></figure><h2 id="6dce" class="mk lt iq bd lu ml mm dn ly mn mo dp mc lf mp mq me lj mr ms mg ln mt mu mi mv bi translated">清洁</h2><p id="a2ec" class="pw-post-body-paragraph kw kx iq ky b kz mw jr lb lc mx ju le lf my lh li lj mz ll lm ln na lp lq lr ij bi translated">让我们将“目的”列转换为虚拟变量，这样我们就可以将它们包含在我们的分析中:</p><pre class="kg kh ki kj gt od oe of og aw oh bi"><span id="13b7" class="mk lt iq oe b gy oi oj l ok ol">final_data = pd.get_dummies(loans,columns = ['purpose'], drop_first=True)</span><span id="28c4" class="mk lt iq oe b gy om oj l ok ol">final_data.head()</span></pre><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="ab gu cl on"><img src="../Images/d5ce51120748a2f30664e3075ae1c230.png" data-original-src="https://miro.medium.com/v2/format:webp/1*bNbdWoWzcaT13px6ne3fWg.png"/></div></figure><pre class="kg kh ki kj gt od oe of og aw oh bi"><span id="5434" class="mk lt iq oe b gy oi oj l ok ol">from sklearn.model_selection import train_test_split</span><span id="36a7" class="mk lt iq oe b gy om oj l ok ol">X= final_data.drop('not.fully.paid', axis=1)<br/>y= final_data['not.fully.paid']<br/>X_train, X_test, y_train, y_test = train_test_split(X,y,test_size = 0.3, random_state = 101)</span></pre><h2 id="e14a" class="mk lt iq bd lu ml mm dn ly mn mo dp mc lf mp mq me lj mr ms mg ln mt mu mi mv bi translated">决策树:</h2><pre class="kg kh ki kj gt od oe of og aw oh bi"><span id="7d4d" class="mk lt iq oe b gy oi oj l ok ol">from sklearn.tree import DecisionTreeClassifier</span><span id="fbc3" class="mk lt iq oe b gy om oj l ok ol">dtree = DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,<br/>            max_features=None, max_leaf_nodes=None,<br/>            min_impurity_decrease=0.0, min_impurity_split=None,<br/>            min_samples_leaf=1, min_samples_split=2,<br/>            min_weight_fraction_leaf=0.0,  random_state=None,<br/>            splitter='best')</span><span id="f027" class="mk lt iq oe b gy om oj l ok ol">dtree.fit(X_train, y_train)</span><span id="35eb" class="mk lt iq oe b gy om oj l ok ol">DecisionTreeClassifier()</span><span id="e522" class="mk lt iq oe b gy om oj l ok ol">pred = dtree.predict(X_test)</span></pre><h2 id="3ee5" class="mk lt iq bd lu ml mm dn ly mn mo dp mc lf mp mq me lj mr ms mg ln mt mu mi mv bi translated">估价</h2><pre class="kg kh ki kj gt od oe of og aw oh bi"><span id="c3b6" class="mk lt iq oe b gy oi oj l ok ol">np.array((pred==y_test)).sum()</span><span id="916e" class="mk lt iq oe b gy om oj l ok ol">2104</span><span id="b8ec" class="mk lt iq oe b gy om oj l ok ol">from sklearn.metrics import classification_report, confusion_matrix</span><span id="97a0" class="mk lt iq oe b gy om oj l ok ol">print(classification_report(y_test,pred))</span><span id="343c" class="mk lt iq oe b gy om oj l ok ol">precision    recall  f1-score   support<br/><br/>           0       0.86      0.82      0.84      2431<br/>           1       0.19      0.23      0.21       443<br/><br/>    accuracy                           0.73      2874<br/>   macro avg       0.52      0.53      0.53      2874<br/>weighted avg       0.75      0.73      0.74      2874</span><span id="d63b" class="mk lt iq oe b gy om oj l ok ol">print(confusion_matrix(y_test,pred))</span><span id="02c7" class="mk lt iq oe b gy om oj l ok ol">[[2000  431]<br/> [ 339  104]]</span></pre><h2 id="7d8e" class="mk lt iq bd lu ml mm dn ly mn mo dp mc lf mp mq me lj mr ms mg ln mt mu mi mv bi translated">随机森林:</h2><pre class="kg kh ki kj gt od oe of og aw oh bi"><span id="7e31" class="mk lt iq oe b gy oi oj l ok ol">from sklearn.ensemble import RandomForestClassifier</span><span id="d66b" class="mk lt iq oe b gy om oj l ok ol">dfor = RandomForestClassifier()</span><span id="e30d" class="mk lt iq oe b gy om oj l ok ol">dfor.fit(X_train, y_train)</span><span id="8e14" class="mk lt iq oe b gy om oj l ok ol">RandomForestClassifier()</span><span id="0ceb" class="mk lt iq oe b gy om oj l ok ol">pred2 = dfor.predict(X_test)</span></pre><h2 id="a612" class="mk lt iq bd lu ml mm dn ly mn mo dp mc lf mp mq me lj mr ms mg ln mt mu mi mv bi translated">估价</h2><pre class="kg kh ki kj gt od oe of og aw oh bi"><span id="5f20" class="mk lt iq oe b gy oi oj l ok ol">(y_test == pred2).sum()</span><span id="3a85" class="mk lt iq oe b gy om oj l ok ol">2427</span></pre><p id="6f0e" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">我们可以看到这比一棵树做出了更好的预测</p><pre class="kg kh ki kj gt od oe of og aw oh bi"><span id="e39d" class="mk lt iq oe b gy oi oj l ok ol">print(classification_report(y_test,pred2))</span><span id="952c" class="mk lt iq oe b gy om oj l ok ol">precision    recall  f1-score   support<br/><br/>           0       0.85      0.99      0.92      2431<br/>           1       0.42      0.02      0.05       443<br/><br/>    accuracy                           0.84      2874<br/>   macro avg       0.64      0.51      0.48      2874<br/>weighted avg       0.78      0.84      0.78      2874</span><span id="79d8" class="mk lt iq oe b gy om oj l ok ol">print(confusion_matrix(y_test,pred2))</span><span id="5fb8" class="mk lt iq oe b gy om oj l ok ol">[[2416   15]<br/> [ 432   11]]</span></pre><h2 id="893a" class="mk lt iq bd lu ml mm dn ly mn mo dp mc lf mp mq me lj mr ms mg ln mt mu mi mv bi translated">超级参数调整~随机森林</h2><ul class=""><li id="1ced" class="nc nd iq ky b kz mw lc mx lf ne lj nf ln ng lr nh ni nj nk bi translated">n _估计量:随机森林中的树的数量</li><li id="9810" class="nc nd iq ky b kz nl lc nm lf nn lj no ln np lr nh ni nj nk bi translated">max_features:每次分割要考虑的最大特征数</li><li id="3896" class="nc nd iq ky b kz nl lc nm lf nn lj no ln np lr nh ni nj nk bi translated">max_depth:每个估计器的最大深度</li><li id="69ac" class="nc nd iq ky b kz nl lc nm lf nn lj no ln np lr nh ni nj nk bi translated">min_sample_split:有效分割所需的最小样本</li><li id="0bd4" class="nc nd iq ky b kz nl lc nm lf nn lj no ln np lr nh ni nj nk bi translated">min_samples_leaf:每个叶节点所需的最小样本数</li></ul><pre class="kg kh ki kj gt od oe of og aw oh bi"><span id="a460" class="mk lt iq oe b gy oi oj l ok ol">from sklearn.model_selection import RandomizedSearchCV<br/># Number of trees in random forest<br/>n_estimators = [int(x) for x in np.linspace(start = 200, stop = 2000, num = 10)]<br/># Number of features to consider at every split<br/>max_features = ['auto', 'sqrt']<br/># Maximum number of levels in tree<br/>max_depth = [int(x) for x in np.linspace(10, 110, num = 11)]<br/>max_depth.append(None)<br/># Minimum number of samples required to split a node<br/>min_samples_split = [2, 5, 10]<br/># Minimum number of samples required at each leaf node<br/>min_samples_leaf = [1, 2, 4]<br/># Create the random grid<br/>random_grid = {'n_estimators': n_estimators,<br/>               'max_features': max_features,<br/>               'max_depth': max_depth,<br/>               'min_samples_split': min_samples_split,<br/>               'min_samples_leaf': min_samples_leaf,<br/>               }<br/>print(random_grid)</span><span id="10a8" class="mk lt iq oe b gy om oj l ok ol">{'n_estimators': [200, 400, 600, 800, 1000, 1200, 1400, 1600, 1800, 2000], 'max_features': ['auto', 'sqrt'], 'max_depth': [10, 20, 30, 40, 50, 60, 70, 80, 90, 100, 110, None], 'min_samples_split': [2, 5, 10], 'min_samples_leaf': [1, 2, 4]}</span></pre><h2 id="5ea1" class="mk lt iq bd lu ml mm dn ly mn mo dp mc lf mp mq me lj mr ms mg ln mt mu mi mv bi translated">k倍交叉验证</h2><p id="2e83" class="pw-post-body-paragraph kw kx iq ky b kz mw jr lb lc mx ju le lf my lh li lj mz ll lm ln na lp lq lr ij bi translated">交叉验证(CV)技术最好用最常用的方法K倍CV举例说明。当我们处理机器学习问题时，我们确保将数据分成训练集和测试集。在K-Fold CV中，我们进一步将我们的训练集分成K个子集，称为折叠。然后，我们迭代拟合模型K次，每次在第K-1个褶皱上训练数据，并在第K个褶皱上评估(称为验证数据)。</p><pre class="kg kh ki kj gt od oe of og aw oh bi"><span id="3d41" class="mk lt iq oe b gy oi oj l ok ol"># Use the random grid to search for best hyperparameters<br/># First create the base model to tune<br/>rf = RandomForestClassifier()<br/># Random search of parameters, using 3 fold cross validation, <br/># search across 100 different combinations, and use all available cores<br/>rf_random = RandomizedSearchCV(estimator = rf, param_distributions = random_grid, n_iter = 100, cv = 3, verbose=2, random_state=42, n_jobs = -1)<br/># Fit the random search model<br/>rf_random.fit(X_train, y_train)</span><span id="b0e4" class="mk lt iq oe b gy om oj l ok ol">Fitting 3 folds for each of 100 candidates, totalling 300 fits<br/><br/><br/><br/><br/><br/>RandomizedSearchCV(cv=3, estimator=RandomForestClassifier(), n_iter=100, n_jobs=-1,<br/>param_distributions={'max_depth': [10, 20, 30, 40, 50, 60,<br/>                           70, 80, 90, 100, 110,None], 'max_features': ['auto', 'sqrt'],<br/>'min_samples_leaf': [1, 2, 4],<br/>'min_samples_split': [2, 5, 10],<br/>'n_estimators': [200, 400, 600, 800,1000, 1200, 1400, 1600,<br/>                                  1800, 2000]},      random_state=42, verbose=2)</span><span id="0e52" class="mk lt iq oe b gy om oj l ok ol">rf_random.best_params_</span><span id="ec8e" class="mk lt iq oe b gy om oj l ok ol">{'n_estimators': 200,<br/> 'min_samples_split': 10,<br/> 'min_samples_leaf': 2,<br/> 'max_features': 'sqrt',<br/> 'max_depth': 110}</span></pre><h2 id="7555" class="mk lt iq bd lu ml mm dn ly mn mo dp mc lf mp mq me lj mr ms mg ln mt mu mi mv bi translated">参考</h2><ol class=""><li id="b5c6" class="nc nd iq ky b kz mw lc mx lf ne lj nf ln ng lr op ni nj nk bi translated"><a class="ae kv" href="https://www.kaggle.com/bdmj12/random-forest-lendingclub-project/notebook" rel="noopener ugc nofollow" target="_blank">https://www . ka ggle . com/bdmj 12/random-forest-lending club-project/notebook</a></li><li id="86b1" class="nc nd iq ky b kz nl lc nm lf nn lj no ln np lr op ni nj nk bi translated"><a class="ae kv" href="https://www.kaggle.com/megr25/lending-club-decision-tree-and-random-forest" rel="noopener ugc nofollow" target="_blank">https://www . ka ggle . com/megr 25/lending-club-decision-tree-and-random-forest</a></li><li id="ee6d" class="nc nd iq ky b kz nl lc nm lf nn lj no ln np lr op ni nj nk bi translated">【https://www.kaggle.com/megr25/lending-club-loans/version/1 T4】</li><li id="4de2" class="nc nd iq ky b kz nl lc nm lf nn lj no ln np lr op ni nj nk bi translated"><a class="ae kv" href="http://www.cs.columbia.edu/~amueller/comsw4995s18/schedule/" rel="noopener ugc nofollow" target="_blank">http://www.cs.columbia.edu/~amueller/comsw4995s18/schedule/</a></li><li id="e2ed" class="nc nd iq ky b kz nl lc nm lf nn lj no ln np lr op ni nj nk bi translated"><a class="ae kv" href="https://medium.com/@appaloosastore/string-similarity-algorithms-compared-3f7b4d12f0ff" rel="noopener">https://medium . com/@ appaloosastore/string-similarity-algorithms-comparated-3f 7 B4 d 12 f 0 ff</a></li><li id="bd82" class="nc nd iq ky b kz nl lc nm lf nn lj no ln np lr op ni nj nk bi translated"><a class="ae kv" href="https://stanford.edu/~shervine/teaching/cs-229/cheatsheet-deep-learning" rel="noopener ugc nofollow" target="_blank">https://Stanford . edu/~ shervine/teaching/cs-229/cheat sheet-deep-learning</a></li><li id="3e79" class="nc nd iq ky b kz nl lc nm lf nn lj no ln np lr op ni nj nk bi translated"><a class="ae kv" href="https://towardsdatascience.com/random-forests-algorithm-explained-with-a-real-life-example-and-some-python-code-affbfa5a942c" rel="noopener" target="_blank">https://towards data science . com/random-forests-algorithm-explained-with-a-real-life-example-and-some-python-code-afbffa 942 c</a></li><li id="4fe7" class="nc nd iq ky b kz nl lc nm lf nn lj no ln np lr op ni nj nk bi translated"><a class="ae kv" href="https://www.kdnuggets.com/2017/08/machine-learning-abstracts-decision-trees.html" rel="noopener ugc nofollow" target="_blank">https://www . kdnugges . com/2017/08/machine-learning-abstracts-decision-trees . html</a></li><li id="826a" class="nc nd iq ky b kz nl lc nm lf nn lj no ln np lr op ni nj nk bi translated">Clements，J. M .，Xu，d .，n .和Efimov，d.《使用表格财务数据进行信用风险监控的顺序深度学习》。arXiv预印本arXiv:2012.15330，2020</li></ol></div></div>    
</body>
</html>