<html>
<head>
<title>Looking for Connections in Your Data? Correlation Techniques Come to the Rescue!</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">在数据中寻找联系？相关技术来拯救！</h1>
<blockquote>原文：<a href="https://pub.towardsai.net/looking-for-connections-in-your-data-correlation-techniques-come-to-rescue-53121a149f96?source=collection_archive---------2-----------------------#2020-06-18">https://pub.towardsai.net/looking-for-connections-in-your-data-correlation-techniques-come-to-rescue-53121a149f96?source=collection_archive---------2-----------------------#2020-06-18</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><figure class="ip iq gp gr ir is gh gi paragraph-image"><div role="button" tabindex="0" class="it iu di iv bf iw"><div class="gh gi io"><img src="../Images/0ce975efc3b32cad953fcfc27fa09c76.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*bQf6YqSFdmZiL_0G"/></div></div><figcaption class="iz ja gj gh gi jb jc bd b be z dk translated">理解数据中的联系有其自身的优势(照片由<a class="ae jd" href="https://unsplash.com/@clintadair?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">克林特·王茂林</a>在<a class="ae jd" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上拍摄)</figcaption></figure><h2 id="cf99" class="je jf jg bd b dl jh ji jj jk jl jm dk jn translated" aria-label="kicker paragraph"><a class="ae ep" href="https://towardsai.net/p/category/data-science" rel="noopener ugc nofollow" target="_blank">数据科学</a></h2><div class=""/><div class=""><h2 id="078e" class="pw-subtitle-paragraph km jp jg bd b kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld dk translated">简单地说，相关技术</h2></div><p id="dca9" class="pw-post-body-paragraph le lf jg lg b lh li kq lj lk ll kt lm ln lo lp lq lr ls lt lu lv lw lx ly lz ij bi translated">机器学习模型的好坏取决于你使用的数据。这就是为什么数据科学家通常会花费数小时来预处理和清理数据。关键是只选择对最终模型的性能贡献最大的特征。这里<em class="ma">特征工程</em>进入了画面。</p><h2 id="716c" class="mb mc jg bd md me mf dn mg mh mi dp mj ln mk ml mm lr mn mo mp lv mq mr ms jm bi translated">有什么关联？</h2><p id="0863" class="pw-post-body-paragraph le lf jg lg b lh mt kq lj lk mu kt lm ln mv lp lq lr mw lt lu lv mx lx ly lz ij bi translated">简单来说，<em class="ma">相关性是一个特性与另一个特性</em>相关程度的度量。例如，身高和体重可以<em class="ma">正相关</em> <em class="ma">相关</em>。而身高和工资<em class="ma">根本不相关。</em></p><p id="fe0a" class="pw-post-body-paragraph le lf jg lg b lh li kq lj lk ll kt lm ln lo lp lq lr ls lt lu lv lw lx ly lz ij bi translated">通过使用另一个相关要素输入缺失值或消除高度相关的冗余要素，了解要素之间的相关性有助于进行要素工程。</p><p id="a688" class="pw-post-body-paragraph le lf jg lg b lh li kq lj lk ll kt lm ln lo lp lq lr ls lt lu lv lw lx ly lz ij bi translated"><strong class="lg jq">在本文中，我们将讨论各种相关技术及其有用性。</strong></p><p id="3113" class="pw-post-body-paragraph le lf jg lg b lh li kq lj lk ll kt lm ln lo lp lq lr ls lt lu lv lw lx ly lz ij bi translated">以下是最广泛使用的相关技术，</p><ol class=""><li id="ece9" class="my mz jg lg b lh li lk ll ln na lr nb lv nc lz nd ne nf ng bi translated">协方差</li><li id="def8" class="my mz jg lg b lh nh lk ni ln nj lr nk lv nl lz nd ne nf ng bi translated">皮尔逊相关系数</li><li id="624e" class="my mz jg lg b lh nh lk ni ln nj lr nk lv nl lz nd ne nf ng bi translated">斯皮尔曼等级相关系数</li></ol><p id="f07a" class="pw-post-body-paragraph le lf jg lg b lh li kq lj lk ll kt lm ln lo lp lq lr ls lt lu lv lw lx ly lz ij bi translated">让我们开始吧！</p></div><div class="ab cl nm nn hu no" role="separator"><span class="np bw bk nq nr ns"/><span class="np bw bk nq nr ns"/><span class="np bw bk nq nr"/></div><div class="ij ik il im in"><h2 id="db15" class="mb mc jg bd md me mf dn mg mh mi dp mj ln mk ml mm lr mn mo mp lv mq mr ms jm bi translated">1.协方差:</h2><p id="5962" class="pw-post-body-paragraph le lf jg lg b lh mt kq lj lk mu kt lm ln mv lp lq lr mw lt lu lv mx lx ly lz ij bi translated">协方差是两个特征的<em class="ma">联合概率</em>的度量。对于两个特征，比如说，<em class="ma"> X和Y </em>，设<em class="ma"> E(X)，E(Y) </em>分别为<em class="ma"> X，Y </em>的期望值，【n】为数据点的总数。X，Y的协方差由下式给出:</p><figure class="nu nv nw nx gt is gh gi paragraph-image"><div class="gh gi nt"><img src="../Images/c56ba8764a2e2cfb88e724c49c82f768.png" data-original-src="https://miro.medium.com/v2/resize:fit:1006/format:webp/1*l_-0XR365Cf80y0oz7FFlg.png"/></div><figcaption class="iz ja gj gh gi jb jc bd b be z dk translated">X，Y的协方差的数学公式</figcaption></figure><p id="8921" class="pw-post-body-paragraph le lf jg lg b lh li kq lj lk ll kt lm ln lo lp lq lr ls lt lu lv lw lx ly lz ij bi translated">协方差的符号表示特征之间的线性关系的趋势。然而，协方差的大小并不表示特征之间关系的强度。</p><ul class=""><li id="6484" class="my mz jg lg b lh li lk ll ln na lr nb lv nc lz ny ne nf ng bi translated">如果<strong class="lg jq">协方差(X，Y)为正</strong>，则意味着一个特征的较大值对应于另一个特征的较大值，对于较小值也是如此，(即，这些特征倾向于表现出<strong class="lg jq">相似的行为</strong></li></ul><figure class="nu nv nw nx gt is gh gi paragraph-image"><div class="gh gi nz"><img src="../Images/310ef6224bd839ea15802feb8a0aa257.png" data-original-src="https://miro.medium.com/v2/resize:fit:460/format:webp/1*d1BoXoGFQX0iTdfau_3E6w.png"/></div><figcaption class="iz ja gj gh gi jb jc bd b be z dk translated">当协方差(X，Y)为正时，X，Y的样本图</figcaption></figure><ul class=""><li id="167e" class="my mz jg lg b lh li lk ll ln na lr nb lv nc lz ny ne nf ng bi translated">如果<strong class="lg jq">协方差(X，Y)为负</strong>，则意味着一个特征的较大值对应于另一个特征的较小值(即，这些特征倾向于显示与<strong class="lg jq">相反的行为</strong>)</li></ul><figure class="nu nv nw nx gt is gh gi paragraph-image"><div class="gh gi oa"><img src="../Images/7705a0cf2f5af8d47af6f91cb17a64f2.png" data-original-src="https://miro.medium.com/v2/resize:fit:456/format:webp/1*J4xBzjNmBqBdLJwTV5TWVg.png"/></div><figcaption class="iz ja gj gh gi jb jc bd b be z dk translated">协方差(X，Y)为负时X，Y的样本图</figcaption></figure><h2 id="3031" class="mb mc jg bd md me mf dn mg mh mi dp mj ln mk ml mm lr mn mo mp lv mq mr ms jm bi translated">缺点:</h2><ol class=""><li id="54c9" class="my mz jg lg b lh mt lk mu ln ob lr oc lv od lz nd ne nf ng bi translated">从特征的协方差来看，不能解释特征之间相似(或相异)的强弱。</li><li id="c762" class="my mz jg lg b lh nh lk ni ln nj lr nk lv nl lz nd ne nf ng bi translated">要素单位的变化可能会改变要素的协方差值，从而使其不可靠。</li></ol></div><div class="ab cl nm nn hu no" role="separator"><span class="np bw bk nq nr ns"/><span class="np bw bk nq nr ns"/><span class="np bw bk nq nr"/></div><div class="ij ik il im in"><h2 id="1690" class="mb mc jg bd md me mf dn mg mh mi dp mj ln mk ml mm lr mn mo mp lv mq mr ms jm bi translated">2.皮尔逊相关系数(PCC):</h2><p id="2bd3" class="pw-post-body-paragraph le lf jg lg b lh mt kq lj lk mu kt lm ln mv lp lq lr mw lt lu lv mx lx ly lz ij bi translated">皮尔逊相关系数是测量两个特征之间的线性相关性的统计量。对于两个特征，X，Y设σX，σY分别为X，Y的标准差。X，Y的PCC由下式给出</p><figure class="nu nv nw nx gt is gh gi paragraph-image"><div class="gh gi oe"><img src="../Images/dc145a6edac7219f2fc23d094fe35ef2.png" data-original-src="https://miro.medium.com/v2/resize:fit:440/format:webp/1*JO3o0udPBFTwfTLsYPO6dQ.png"/></div><figcaption class="iz ja gj gh gi jb jc bd b be z dk translated">X，Y的PCC的数学公式</figcaption></figure><p id="5330" class="pw-post-body-paragraph le lf jg lg b lh li kq lj lk ll kt lm ln lo lp lq lr ls lt lu lv lw lx ly lz ij bi translated">它的值介于+1和-1之间，其中</p><ul class=""><li id="2e32" class="my mz jg lg b lh li lk ll ln na lr nb lv nc lz ny ne nf ng bi translated">1是一个<strong class="lg jq">完美的正线性相关</strong></li><li id="0d88" class="my mz jg lg b lh nh lk ni ln nj lr nk lv nl lz ny ne nf ng bi translated">0是<strong class="lg jq">没有线性相关性</strong></li><li id="1c69" class="my mz jg lg b lh nh lk ni ln nj lr nk lv nl lz ny ne nf ng bi translated">—1是一个<strong class="lg jq">完美的负线性相关</strong></li></ul><p id="9150" class="pw-post-body-paragraph le lf jg lg b lh li kq lj lk ll kt lm ln lo lp lq lr ls lt lu lv lw lx ly lz ij bi translated">PCC可以洞察变量之间的相似性强度(这是协方差的一个主要缺点)。</p><ul class=""><li id="c56e" class="my mz jg lg b lh li lk ll ln na lr nb lv nc lz ny ne nf ng bi translated">如果PCC值为-1，则存在<strong class="lg jq">严格负线性相关性</strong></li></ul><figure class="nu nv nw nx gt is gh gi paragraph-image"><div class="gh gi of"><img src="../Images/90599f427a38f80dfcc224b01488d8ca.png" data-original-src="https://miro.medium.com/v2/resize:fit:570/format:webp/1*ocfdaURebGAV3hX2cg-0_A.png"/></div><figcaption class="iz ja gj gh gi jb jc bd b be z dk translated">值为PCC -1的变量样本图</figcaption></figure><ul class=""><li id="dea6" class="my mz jg lg b lh li lk ll ln na lr nb lv nc lz ny ne nf ng bi translated">如果PCC值位于(-1，0)，则存在<strong class="lg jq">不太完美的负线性相关性</strong></li></ul><figure class="nu nv nw nx gt is gh gi paragraph-image"><div class="gh gi og"><img src="../Images/c7bba0b79d3ba54bc7fce6b014e0f699.png" data-original-src="https://miro.medium.com/v2/resize:fit:592/format:webp/1*Y8niGhthb0klZwPF2Mxe6Q.png"/></div><figcaption class="iz ja gj gh gi jb jc bd b be z dk translated">PCC值为(-1，0)的变量样本图</figcaption></figure><ul class=""><li id="2b48" class="my mz jg lg b lh li lk ll ln na lr nb lv nc lz ny ne nf ng bi translated">如果PCC值位于(0，+1)，则存在<strong class="lg jq">不太完美的正线性相关</strong></li></ul><figure class="nu nv nw nx gt is gh gi paragraph-image"><div class="gh gi oh"><img src="../Images/d4d4a4ad8c57641e82e290f5df346f62.png" data-original-src="https://miro.medium.com/v2/resize:fit:584/format:webp/1*vcXFGIwmF6eG5ZT4guQTjQ.png"/></div><figcaption class="iz ja gj gh gi jb jc bd b be z dk translated">PCC值为(0，+1)的变量样本图</figcaption></figure><ul class=""><li id="35de" class="my mz jg lg b lh li lk ll ln na lr nb lv nc lz ny ne nf ng bi translated">如果PCC值为+1，则存在<strong class="lg jq">严格正线性相关性</strong></li></ul><figure class="nu nv nw nx gt is gh gi paragraph-image"><div class="gh gi oi"><img src="../Images/c8aba956f184b6d2362d6e0d8e062966.png" data-original-src="https://miro.medium.com/v2/resize:fit:598/format:webp/1*Mn9sOvq1v2F7_kXD01wieA.png"/></div><figcaption class="iz ja gj gh gi jb jc bd b be z dk translated">值为PCC +1的变量样本图</figcaption></figure><ul class=""><li id="8c1f" class="my mz jg lg b lh li lk ll ln na lr nb lv nc lz ny ne nf ng bi translated">如果PCC值为0，则<strong class="lg jq">不相关</strong></li></ul><figure class="nu nv nw nx gt is gh gi paragraph-image"><div class="gh gi oi"><img src="../Images/46dd772e4f896fde7d04972e3cffc3b6.png" data-original-src="https://miro.medium.com/v2/resize:fit:598/format:webp/1*OMiZ3w6r4A3oAlGT9W4NXQ.png"/></div><figcaption class="iz ja gj gh gi jb jc bd b be z dk translated">值为PCC 0的变量样本图</figcaption></figure><h2 id="2ee1" class="mb mc jg bd md me mf dn mg mh mi dp mj ln mk ml mm lr mn mo mp lv mq mr ms jm bi translated">缺点:</h2><p id="164a" class="pw-post-body-paragraph le lf jg lg b lh mt kq lj lk mu kt lm ln mv lp lq lr mw lt lu lv mx lx ly lz ij bi translated">PCC不能很好地处理<em class="ma">非线性关系</em>。对于以下所有图，特征之间的PCC为0。</p><figure class="nu nv nw nx gt is gh gi paragraph-image"><div class="gh gi oj"><img src="../Images/eba7332dc83bcbbac75b1d311000a394.png" data-original-src="https://miro.medium.com/v2/resize:fit:1172/format:webp/1*RZWQyBNhM7giC1iz-Z54vA.png"/></div><figcaption class="iz ja gj gh gi jb jc bd b be z dk translated">非线性曲线</figcaption></figure></div><div class="ab cl nm nn hu no" role="separator"><span class="np bw bk nq nr ns"/><span class="np bw bk nq nr ns"/><span class="np bw bk nq nr"/></div><div class="ij ik il im in"><h2 id="f38c" class="mb mc jg bd md me mf dn mg mh mi dp mj ln mk ml mm lr mn mo mp lv mq mr ms jm bi translated">3.斯皮尔曼等级相关系数；</h2><p id="9bb7" class="pw-post-body-paragraph le lf jg lg b lh mt kq lj lk mu kt lm ln mv lp lq lr mw lt lu lv mx lx ly lz ij bi translated">斯皮尔曼等级相关系数(SRCC)评估两个特征之间的关系可以使用<em class="ma">单调函数(无论线性与否)</em>描述的有多好，其中PCC只能评估线性关系。</p><p id="9713" class="pw-post-body-paragraph le lf jg lg b lh li kq lj lk ll kt lm ln lo lp lq lr ls lt lu lv lw lx ly lz ij bi translated">两个变量之间的Spearman等级相关系数等于两个变量等级值之间的<em class="ma"> Pearson相关系数</em>。<em class="ma"> Rank </em>是变量内观察值的相对位置标签。</p><blockquote class="ok"><p id="e9e6" class="ol om jg bd on oo op oq or os ot lz dk translated">直观上，当两个变量之间的观测值具有相似的秩时，两个变量之间的Spearman秩相关系数将会很高，而当两个变量之间的观测值具有不同的秩时，该相关系数将会很低。</p></blockquote><p id="d804" class="pw-post-body-paragraph le lf jg lg b lh ou kq lj lk ov kt lm ln ow lp lq lr ox lt lu lv oy lx ly lz ij bi translated">Spearman等级相关系数位于+1和-1之间，其中</p><ul class=""><li id="2114" class="my mz jg lg b lh li lk ll ln na lr nb lv nc lz ny ne nf ng bi translated">1是一个<strong class="lg jq">完全正相关</strong></li><li id="f9be" class="my mz jg lg b lh nh lk ni ln nj lr nk lv nl lz ny ne nf ng bi translated">0是<strong class="lg jq">不相关</strong></li><li id="9fe5" class="my mz jg lg b lh nh lk ni ln nj lr nk lv nl lz ny ne nf ng bi translated">—1是一个<strong class="lg jq">完美负相关</strong></li></ul><h2 id="75c5" class="mb mc jg bd md me mf dn mg mh mi dp mj ln mk ml mm lr mn mo mp lv mq mr ms jm bi translated">优势:</h2><ul class=""><li id="8fbe" class="my mz jg lg b lh mt lk mu ln ob lr oc lv od lz ny ne nf ng bi translated">Spearman等级相关系数比Pearson相关系数对强异常值<strong class="lg jq">不敏感</strong></li><li id="2daf" class="my mz jg lg b lh nh lk ni ln nj lr nk lv nl lz ny ne nf ng bi translated">当被比较的两个变量单调相关时，Spearman等级相关系数为1，即使它们的关系不是线性的。</li></ul></div><div class="ab cl nm nn hu no" role="separator"><span class="np bw bk nq nr ns"/><span class="np bw bk nq nr ns"/><span class="np bw bk nq nr"/></div><div class="ij ik il im in"><p id="0dff" class="pw-post-body-paragraph le lf jg lg b lh li kq lj lk ll kt lm ln lo lp lq lr ls lt lu lv lw lx ly lz ij bi translated">谢谢你的阅读。我也将在未来写更多初学者友好的帖子。请在<a class="ae jd" href="https://medium.com/@ramyavidiyala" rel="noopener">媒体</a>上关注我，以便了解他们。我欢迎反馈，可以通过Twitter <a class="ae jd" href="https://twitter.com/ramya_vidiyala" rel="noopener ugc nofollow" target="_blank"> ramya_vidiyala </a>和LinkedIn <a class="ae jd" href="https://www.linkedin.com/in/ramya-vidiyala-308ba6139/" rel="noopener ugc nofollow" target="_blank"> RamyaVidiyala </a>联系我。快乐学习！</p></div></div>    
</body>
</html>