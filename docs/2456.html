<html>
<head>
<title>This Microsoft Model Excels at Common Sense Reasoning</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">这个微软模型擅长常识推理</h1>
<blockquote>原文：<a href="https://pub.towardsai.net/this-microsoft-model-excels-at-common-sense-reasoning-57a5ff360a3c?source=collection_archive---------0-----------------------#2022-01-03">https://pub.towardsai.net/this-microsoft-model-excels-at-common-sense-reasoning-57a5ff360a3c?source=collection_archive---------0-----------------------#2022-01-03</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><h2 id="b005" class="ir is it bd b dl iu iv iw ix iy iz dk ja translated" aria-label="kicker paragraph"><a class="ae ep" href="https://towardsai.net/p/category/artificial-intelligence" rel="noopener ugc nofollow" target="_blank">人工智能</a></h2><div class=""/><div class=""><h2 id="2598" class="pw-subtitle-paragraph jz jc it bd b ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq dk translated">KEAR是一个聪明的架构，用常识推理来扩展transformer模型。</h2></div><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi kr"><img src="../Images/4ed36eb032c9f0e76e6f68b55280f4da.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*wAPJsd4d_hxDKr0G.jpg"/></div></div><figcaption class="ld le gj gh gi lf lg bd b be z dk translated">来源:https://futurism.com/teaching-ai-common-sense<a class="ae lh" href="https://futurism.com/teaching-ai-common-sense" rel="noopener ugc nofollow" target="_blank"/></figcaption></figure><p id="067d" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">常识是人脑的认知品质之一，很难量化甚至解释。毫不奇怪，在ML模型中重建常识推理已经成为整个领域最相关的挑战之一。重建常识的挑战是ML中一个基本哲学困境的根源:逻辑和知识之间的摩擦<em class="me">。通过进化，人类首先发展了世界的知识模型，并整合了逻辑推理。这一过程在软件行业中被逆转，在神经网络创建两个高度不同的思想流派之前，逻辑模型已经被采用。现在，创建结合逻辑推理和神经网络的架构已经变得非常重要。</em></p><p id="c66d" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">从ML的角度来看，已经成为常识推理能力中心的学科是问答(QA)模型。尽管近年来我们已经看到语言模型在转换器和预训练架构方面取得了巨大的进步，但大多数模型仍然难以解决基本的常识推理问题。最近，<a class="ae lh" href="https://www.microsoft.com/en-us/research/publication/human-parity-on-commonsenseqa-augmenting-self-attention-with-external-attention/" rel="noopener ugc nofollow" target="_blank">微软研究院发表了一篇论文</a>，详细描述了一个ML架构，它在常识QA基准测试中实现了人类类型的性能。</p><p id="4e1e" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">这种新的微软架构被称为常识推理或KEAR的知识丰富的外部注意力，它解决了QA模型中常识推理的一个基本挑战，该挑战与利用文本输入之外的数据有关。举一个简单的问题，比如<em class="me">“你的狗会喜欢什么样的款待？”。</em>为了选择正确的答案，例如<em class="me">骨骼</em>，ML模型将需要结合输入数据集中经常缺少的知识。解决这个问题的默认方法是用许多表达常识推理的规则来补充模型，但是这种方法很快就会遇到可伸缩性问题。</p><p id="e90c" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">为了应对这一挑战，KEAR用来自ConceptNet数据集的常识知识补充了一个语言模型。当被问及诸如<em class="me">“你的狗会喜欢什么样的款待？”</em>，KEAR将从ConceptNet中检索一系列候选答案，如<em class="me">沙拉、宠物、注意力、骨头、大量注意力</em>。可以从外部数据集(如字典)中检索一些附加数据。之后，KEAR将候选答案与输入连接起来，并将其传递给基于<a class="ae lh" href="https://www.microsoft.com/en-us/research/publication/deberta-decoding-enhanced-bert-with-disentangled-attention-2/" rel="noopener ugc nofollow" target="_blank"> DeBERTa架构</a>的模型，该模型选择最终答案。</p><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi mf"><img src="../Images/5989fc9201881bc76a05d74233f4a584.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*7HkH5IE95dsZv20E.gif"/></div></div><figcaption class="ld le gj gh gi lf lg bd b be z dk translated">图片来源:微软研究院</figcaption></figure><p id="57a0" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">从架构的角度来看，KEAR扩展了传统的transformer模型，增加了额外的关注层，毫不奇怪，这就是所谓的外部关注。这种机制是对transformer架构中自我关注机制的补充，可以帮助确定外部数据集的哪些元素与给定的输入更相关。</p><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi mg"><img src="../Images/8d279fb0f1079d441471203bafbf06bf.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*rxGZL70sRIQPLpCxuNIO7g.png"/></div></div><figcaption class="ld le gj gh gi lf lg bd b be z dk translated">图片来源:微软研究院</figcaption></figure><p id="07d4" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">微软研究院使用<a class="ae lh" href="https://www.tau-nlp.org/commonsenseqa" rel="noopener ugc nofollow" target="_blank"> CommonsenseQA </a>基准测试评估了KEAR，该模型达到了89.4%的准确率，与人类水平的性能相当。同样，KEAR在<a class="ae lh" href="https://inklab.usc.edu/XCSR/" rel="noopener ugc nofollow" target="_blank"> X-CSR </a>常识推理挑战赛的排行榜上高居榜首。KEAR背后的想法非常有前途，并且很容易整合到QA模型中，所以如果我们在不久的将来看到这个模型中有更多的迭代，我们也不会感到惊讶。</p></div></div>    
</body>
</html>