<html>
<head>
<title>Model Overfitting? Use L2 Regularization!</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">模型过度拟合？使用L2正规化！</h1>
<blockquote>原文：<a href="https://pub.towardsai.net/model-overfitting-use-l2-regularization-9f7ca4aadb19?source=collection_archive---------4-----------------------#2020-10-19">https://pub.towardsai.net/model-overfitting-use-l2-regularization-9f7ca4aadb19?source=collection_archive---------4-----------------------#2020-10-19</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><h2 id="b7fb" class="io ip iq bd b dl ir is it iu iv iw dk ix translated" aria-label="kicker paragraph"><a class="ae ep" href="https://towardsai.net/p/category/machine-learning/deep-learning" rel="noopener ugc nofollow" target="_blank">深度学习</a></h2><div class=""/><div class=""><h2 id="e174" class="pw-subtitle-paragraph jw iz iq bd b jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn dk translated">用这个来增强你的深度学习模型！</h2></div><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div role="button" tabindex="0" class="ku kv di kw bf kx"><div class="gh gi ko"><img src="../Images/d0457cbb9015e67e17cc9bebe2f1b3c7.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*-lZJg8_ch7JKuaHP"/></div></div><figcaption class="la lb gj gh gi lc ld bd b be z dk translated">由<a class="ae le" href="https://unsplash.com/@mrsamuel?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Samuel-Elias Nadler </a>在<a class="ae le" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上拍摄</figcaption></figure><p id="14af" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">被困在付费墙后面？点击<a class="ae le" href="https://d3nyal.medium.com/model-overfitting-use-l2-regularization-9f7ca4aadb19?source=friends_link&amp;sk=0ddf4a825566bd4124e6afb17a511488" rel="noopener">这里</a>阅读完整故事与我的朋友链接！</p><p id="a218" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">在上一篇文章中，我们讨论了指数加权平均值！现在，为了进一步提高模型的准确性，我们将讨论L2正则化。在这里看一看我的上一篇文章:</p><div class="mb mc gp gr md me"><a href="https://medium.com/towards-artificial-intelligence/training-taking-too-long-use-exponentially-weighted-averages-c15279f3df55" rel="noopener follow" target="_blank"><div class="mf ab fo"><div class="mg ab mh cl cj mi"><h2 class="bd ja gy z fp mj fr fs mk fu fw iz bi translated">训练时间太长？使用指数加权平均值！</h2><div class="ml l"><h3 class="bd b gy z fp mj fr fs mk fu fw dk translated">使用这种优化来加快你的训练！</h3></div><div class="mm l"><p class="bd b dl z fp mj fr fs mk fu fw dk translated">medium.com</p></div></div><div class="mn l"><div class="mo l mp mq mr mn ms ky me"/></div></div></a></div><blockquote class="mt"><p id="0bb2" class="mu mv iq bd mw mx my mz na nb nc ma dk translated">正则化是我们对学习算法进行的任何修改，目的是减少其泛化误差，而不是训练误差。~伊恩·古德菲勒</p></blockquote></div><div class="ab cl nd ne hu nf" role="separator"><span class="ng bw bk nh ni nj"/><span class="ng bw bk nh ni nj"/><span class="ng bw bk nh ni"/></div><div class="ij ik il im in"><p id="deef" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">现在，有两种类型的正规化，<strong class="lh ja"> L1 </strong>和<strong class="lh ja"> L2 </strong>。当然，还有其他的，但这些是我们谈论<em class="nk"> L正则化</em>时通常想到的。我们改天会谈到L1正规化，今天，让我们把手伸进L2。</p><h1 id="05b5" class="nl nm iq bd nn no np nq nr ns nt nu nv kf nw kg nx ki ny kj nz kl oa km ob oc bi translated">L2正则是什么？</h1><p id="8a20" class="pw-post-body-paragraph lf lg iq lh b li od ka lk ll oe kd ln lo of lq lr ls og lu lv lw oh ly lz ma ij bi translated">使用L2的模型叫做<a class="ae le" href="https://ncss-wpengine.netdna-ssl.com/wp-content/themes/ncss/pdf/Procedures/NCSS/Ridge_Regression.pdf" rel="noopener ugc nofollow" target="_blank"> <strong class="lh ja"> <em class="nk">岭回归</em> </strong> </a> <strong class="lh ja"> <em class="nk">。</em> </strong></p><p id="73f6" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">但首先，你可能会问<strong class="lh ja"> <em class="nk">这有什么必要？</em> </strong>我们这些机器学习从业者，通常会尝试不同的架构来尝试解决一个ML问题。事先，几乎不可能预测架构是否会做得好，有时，模型<a class="ae le" href="https://www.investopedia.com/terms/o/overfitting.asp" rel="noopener ugc nofollow" target="_blank"> <strong class="lh ja"> <em class="nk">过拟合</em> </strong> </a>。过度拟合是这样的:</p><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div class="gh gi oi"><img src="../Images/056eb1c83b1f485c414e28a9eeaefe63.png" data-original-src="https://miro.medium.com/v2/resize:fit:1050/1*mVX_TO11bljHyzHwYkeJLw.gif"/></div><figcaption class="la lb gj gh gi lc ld bd b be z dk translated">来源:<a class="ae le" href="https://towardsdatascience.com/over-fitting-and-regularization-64d16100f45c" rel="noopener" target="_blank">走向数据科学</a></figcaption></figure><p id="d20b" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">你看到了吗？该模型在<em class="nk">不犯任何错误的前提下</em>，只是训练自己成为给定数据的最佳模型，因此，它不会在<strong class="lh ja">新数据</strong>上很好地<em class="nk">推广</em>。这就是为什么，我们有像正则化等技术。</p><p id="87df" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">正则化基本上是给算法的损失函数增加一个<strong class="lh ja">惩罚项</strong>。这改变了模型的权重，这是由于<em class="nk">最小化</em>损失函数而产生的。</p><p id="86c9" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">对于使用L2的正则化，我们基本上<em class="nk">改变</em><strong class="lh ja">损失函数</strong>和我们<strong class="lh ja">反向传播的方式</strong>。</p><p id="4ed2" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">损失函数被改变，使得该表达式被<strong class="lh ja">添加到现有的损失函数中</strong>。添加的表达式是:</p><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div class="gh gi oj"><img src="../Images/99b654bc4601cc46c2d93192183d12bb.png" data-original-src="https://miro.medium.com/v2/resize:fit:268/format:webp/1*-3QVmD0VZ3JAs1TXx4zQvA.png"/></div><figcaption class="la lb gj gh gi lc ld bd b be z dk translated">添加的表达式</figcaption></figure><p id="cd5c" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">这个术语叫做“<strong class="lh ja"> <em class="nk">星等的平方</em> </strong>”。</p><p id="e2d8" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">其中:<br/> - ' <em class="nk"> λ' </em>是一个<em class="nk">正则化超参数</em>。<br/>-<em class="nk">m</em>为SET _ y . shape【1】<br/>-<em class="nk">W</em>为权重矩阵。</p><p id="056d" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated"><em class="nk"> λ，</em>此处<em class="nk">，</em>控制两个目标之间的<em class="nk">权衡</em>:<strong class="lh ja"><em class="nk">很好地拟合训练数据</em> </strong> vs <strong class="lh ja"> <em class="nk">保持参数较小以避免过拟合</em> </strong> <em class="nk">。</em></p><p id="057c" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">并且通过添加正则化项的梯度来改变反向传播，该梯度为:</p><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div class="gh gi ok"><img src="../Images/7842a772898a204d78ce1ea7fcb780f6.png" data-original-src="https://miro.medium.com/v2/resize:fit:1028/format:webp/1*Q7q6TnUDU6PbUt_oKuUKWg.png"/></div><figcaption class="la lb gj gh gi lc ld bd b be z dk translated">新渐变</figcaption></figure><h1 id="c935" class="nl nm iq bd nn no np nq nr ns nt nu nv kf nw kg nx ki ny kj nz kl oa km ob oc bi translated">λ怎么选？</h1><p id="3705" class="pw-post-body-paragraph lf lg iq lh b li od ka lk ll oe kd ln lo of lq lr ls og lu lv lw oh ly lz ma ij bi translated">选择超参数的值在深度学习领域已经混乱了几十年，这个超参数也不例外。</p><p id="c95b" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">但是在选择<em class="nk"> λ </em>的值时，请记住以下几点:</p><ul class=""><li id="1b1a" class="ol om iq lh b li lj ll lm lo on ls oo lw op ma oq or os ot bi translated">更大的值<em class="nk"> λ </em>将使权重收缩到更接近0，这可能会导致拟合不足。</li><li id="44cd" class="ol om iq lh b li ou ll ov lo ow ls ox lw oy ma oq or os ot bi translated"><em class="nk">λ</em><strong class="lh ja"><em class="nk"/></strong><em class="nk">= 0</em><strong class="lh ja"><em class="nk">，</em> </strong>将没有正则化效果。</li></ul><p id="4dbe" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">此外，在选择<em class="nk"> λ </em>的值时，我们必须牢记偏差与方差的权衡。</p><p id="9e96" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">现在，我听到了这场辩论。但是我们改天再讨论这个话题。</p></div><div class="ab cl nd ne hu nf" role="separator"><span class="ng bw bk nh ni nj"/><span class="ng bw bk nh ni nj"/><span class="ng bw bk nh ni"/></div><div class="ij ik il im in"><p id="4245" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">我本可以在使用L2之前和之后添加一个模型准确性的例子，但是不，拖延！</p><p id="87ba" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">好吧，我希望这篇文章能帮助你！下面我们连线一下<a class="ae le" href="https://www.linkedin.com/in/d3ni/" rel="noopener ugc nofollow" target="_blank"> Linkedin </a>。</p><h1 id="fcb1" class="nl nm iq bd nn no np nq nr ns nt nu nv kf nw kg nx ki ny kj nz kl oa km ob oc bi translated">进一步阅读</h1><div class="mb mc gp gr md me"><a href="https://medium.com/towards-artificial-intelligence/training-taking-too-long-use-exponentially-weighted-averages-c15279f3df55" rel="noopener follow" target="_blank"><div class="mf ab fo"><div class="mg ab mh cl cj mi"><h2 class="bd ja gy z fp mj fr fs mk fu fw iz bi translated">训练时间太长？使用指数加权平均值！</h2><div class="ml l"><h3 class="bd b gy z fp mj fr fs mk fu fw dk translated">使用这种优化来加快你的训练！</h3></div><div class="mm l"><p class="bd b dl z fp mj fr fs mk fu fw dk translated">medium.com</p></div></div><div class="mn l"><div class="mo l mp mq mr mn ms ky me"/></div></div></a></div><div class="mb mc gp gr md me"><a href="https://medium.com/datadriveninvestor/model-overfitting-use-dropout-a32010f0afd0" rel="noopener follow" target="_blank"><div class="mf ab fo"><div class="mg ab mh cl cj mi"><h2 class="bd ja gy z fp mj fr fs mk fu fw iz bi translated">模型过度拟合？使用辍学！</h2><div class="ml l"><h3 class="bd b gy z fp mj fr fs mk fu fw dk translated">最好的正规化技术。</h3></div><div class="mm l"><p class="bd b dl z fp mj fr fs mk fu fw dk translated">medium.com</p></div></div><div class="mn l"><div class="pd l mp mq mr mn ms ky me"/></div></div></a></div><div class="mb mc gp gr md me"><a href="https://medium.com/quick-code/deep-learning-for-cats-vs-dogs-classification-309463f3fc46" rel="noopener follow" target="_blank"><div class="mf ab fo"><div class="mg ab mh cl cj mi"><h2 class="bd ja gy z fp mj fr fs mk fu fw iz bi translated">针对猫vs狗分类的深度学习！</h2><div class="ml l"><h3 class="bd b gy z fp mj fr fs mk fu fw dk translated">区分猫狗的循序渐进指南！</h3></div><div class="mm l"><p class="bd b dl z fp mj fr fs mk fu fw dk translated">medium.com</p></div></div><div class="mn l"><div class="pe l mp mq mr mn ms ky me"/></div></div></a></div></div><div class="ab cl nd ne hu nf" role="separator"><span class="ng bw bk nh ni nj"/><span class="ng bw bk nh ni nj"/><span class="ng bw bk nh ni"/></div><div class="ij ik il im in"><h1 id="d4e9" class="nl nm iq bd nn no pf nq nr ns pg nu nv kf ph kg nx ki pi kj nz kl pj km ob oc bi translated">联系人</h1><p id="b18c" class="pw-post-body-paragraph lf lg iq lh b li od ka lk ll oe kd ln lo of lq lr ls og lu lv lw oh ly lz ma ij bi translated">如果你想了解我最新的文章和项目<a class="ae le" href="/@D3nii" rel="noopener ugc nofollow" target="_blank">，请在Medium </a>上关注我。以下是我的一些联系人详细信息:</p><ul class=""><li id="ba2f" class="ol om iq lh b li lj ll lm lo on ls oo lw op ma oq or os ot bi translated"><a class="ae le" href="https://www.linkedin.com/in/d3ni/" rel="noopener ugc nofollow" target="_blank"> Linkedin </a></li><li id="ed81" class="ol om iq lh b li ou ll ov lo ow ls ox lw oy ma oq or os ot bi translated"><a class="ae le" href="https://github.com/D3nii?tab=repositories" rel="noopener ugc nofollow" target="_blank"> GitHub </a></li><li id="e83c" class="ol om iq lh b li ou ll ov lo ow ls ox lw oy ma oq or os ot bi translated"><a class="ae le" href="https://twitter.com/danyal0_o" rel="noopener ugc nofollow" target="_blank">推特</a></li></ul><blockquote class="mt"><p id="fe03" class="mu mv iq bd mw mx my mz na nb nc ma dk translated">快乐学习。:)</p></blockquote></div></div>    
</body>
</html>