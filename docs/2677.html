<html>
<head>
<title>Introduction To Intel Distribution of OpenVINO Toolkit</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">OpenVINO Toolkit英特尔发行版简介</h1>
<blockquote>原文：<a href="https://pub.towardsai.net/introduction-to-intel-distribution-of-openvino-toolkit-b1ba5b0cf24f?source=collection_archive---------1-----------------------#2022-04-12">https://pub.towardsai.net/introduction-to-intel-distribution-of-openvino-toolkit-b1ba5b0cf24f?source=collection_archive---------1-----------------------#2022-04-12</a></blockquote><div><div class="fc ii ij ik il im"/><div class="in io ip iq ir"><div class=""/><div class=""><h2 id="1da8" class="pw-subtitle-paragraph jr it iu bd b js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki dk translated">优化深度学习模型以加快推理速度，并在异构英特尔架构上部署</h2></div></div><div class="ab cl kj kk hy kl" role="separator"><span class="km bw bk kn ko kp"/><span class="km bw bk kn ko kp"/><span class="km bw bk kn ko"/></div><div class="in io ip iq ir"><figure class="kr ks kt ku gu kv gi gj paragraph-image"><div role="button" tabindex="0" class="kw kx di ky bf kz"><div class="gi gj kq"><img src="../Images/2ac61d5b2fed5d48c13e98056a3afc42.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*XMWv32GF_S_X0DyXRdqXAw.jpeg"/></div></div><figcaption class="lc ld gk gi gj le lf bd b be z dk translated">作者图片</figcaption></figure><p id="249a" class="pw-post-body-paragraph lg lh iu li b lj lk jv ll lm ln jy lo lp lq lr ls lt lu lv lw lx ly lz ma mb in bi translated"><strong class="li iv">目录</strong></p><p id="add9" class="pw-post-body-paragraph lg lh iu li b lj lk jv ll lm ln jy lo lp lq lr ls lt lu lv lw lx ly lz ma mb in bi translated"><a class="ae mc" href="#2ef4" rel="noopener ugc nofollow">简介</a><br/>T5】什么是OpenVINO Toolkit？<br/><a class="ae mc" href="#f6d6" rel="noopener ugc nofollow">open vino工具包是如何工作的？</a> <br/> ∘ <a class="ae mc" href="#9f90" rel="noopener ugc nofollow">英特尔发布的OpenVINO工具包内容</a> <br/> ∘ <a class="ae mc" href="#920a" rel="noopener ugc nofollow">英特尔发布的OpenVINO工具包的基本工作流程</a> <br/> <a class="ae mc" href="#935e" rel="noopener ugc nofollow">安装</a> <br/> <a class="ae mc" href="#92e7" rel="noopener ugc nofollow">示例</a> <br/> ∘ <a class="ae mc" href="#d13c" rel="noopener ugc nofollow">步骤1—下载模型</a> <br/> ∘ <a class="ae mc" href="#006a" rel="noopener ugc nofollow">步骤2—导入库</a> <br/> ∘ <a class="ae mc" href="#79f7" rel="noopener ugc nofollow">步骤3—将模型转换为IR【t3t </a> <br/> ∘ <a class="ae mc" href="#4850" rel="noopener ugc nofollow">第六步—加载一张图片</a> <br/> ∘ <a class="ae mc" href="#7640" rel="noopener ugc nofollow">第七步—推断</a> <br/> <a class="ae mc" href="#6fca" rel="noopener ugc nofollow">汇总</a> <br/> <a class="ae mc" href="#1bd6" rel="noopener ugc nofollow">引用</a></p><h1 id="2ef4" class="md me iu bd mf mg mh mi mj mk ml mm mn ka mo kb mp kd mq ke mr kg ms kh mt mu bi translated">介绍</h1><p id="be18" class="pw-post-body-paragraph lg lh iu li b lj mv jv ll lm mw jy lo lp mx lr ls lt my lv lw lx mz lz ma mb in bi translated">oneAPI是由英特尔开发的统一编程语言。借助oneAPI工具包，可以在CPU、GPU、FPGA、AI加速器等上运行相同的代码。没有任何代码更改。oneAPI工具包进一步提高了性能。快速的性能是通过高度优化的低级库实现的，如oneDAL、oneMKL等。</p><p id="511a" class="pw-post-body-paragraph lg lh iu li b lj lk jv ll lm ln jy lo lp lq lr ls lt lu lv lw lx ly lz ma mb in bi translated">有七个oneAPI工具包，每个工具包都是为不同的用户设计的。比如你看到的，AI Analytics Toolkit是给数据科学家用的，HPC Toolkit是给HPC开发者用的，等等。</p><ul class=""><li id="fe46" class="na nb iu li b lj lk lm ln lp nc lt nd lx ne mb nf ng nh ni bi translated"><a class="ae mc" href="https://www.intel.com/content/www/us/en/developer/tools/oneapi/toolkits.html#base-kit" rel="noopener ugc nofollow" target="_blank">英特尔oneAPI基础工具包</a>(面向大多数开发人员)</li><li id="6a5b" class="na nb iu li b lj nj lm nk lp nl lt nm lx nn mb nf ng nh ni bi translated"><a class="ae mc" href="https://www.intel.com/content/www/us/en/developer/tools/oneapi/toolkits.html#hpc-kit" rel="noopener ugc nofollow" target="_blank">英特尔oneAPI HPC工具包</a>(面向HPC开发人员)</li><li id="c214" class="na nb iu li b lj nj lm nk lp nl lt nm lx nn mb nf ng nh ni bi translated"><a class="ae mc" href="https://www.intel.com/content/www/us/en/developer/tools/oneapi/toolkits.html#analytics-kit" rel="noopener ugc nofollow" target="_blank">英特尔oneAPI人工智能分析工具包</a>(面向数据科学家)</li><li id="b0d5" class="na nb iu li b lj nj lm nk lp nl lt nm lx nn mb nf ng nh ni bi translated"><a class="ae mc" href="https://www.intel.com/content/www/us/en/developer/tools/oneapi/toolkits.html#openvino-kit" rel="noopener ugc nofollow" target="_blank"> <strong class="li iv">英特尔发布的OpenVINO工具包</strong> </a> <strong class="li iv">(针对深度学习)</strong></li><li id="2da5" class="na nb iu li b lj nj lm nk lp nl lt nm lx nn mb nf ng nh ni bi translated"><a class="ae mc" href="https://www.intel.com/content/www/us/en/developer/tools/oneapi/toolkits.html#rendering-kit" rel="noopener ugc nofollow" target="_blank">英特尔oneAPI渲染工具包</a>(面向视觉创作者、科学家和工程师)</li><li id="2bfc" class="na nb iu li b lj nj lm nk lp nl lt nm lx nn mb nf ng nh ni bi translated"><a class="ae mc" href="https://www.intel.com/content/www/us/en/developer/tools/oneapi/toolkits.html#iot-kit" rel="noopener ugc nofollow" target="_blank">英特尔oneAPI物联网工具包</a>(面向边缘设备和物联网开发人员)</li><li id="40c6" class="na nb iu li b lj nj lm nk lp nl lt nm lx nn mb nf ng nh ni bi translated"><a class="ae mc" href="https://www.intel.com/content/www/us/en/developer/tools/oneapi/toolkits.html#bring-up-kit" rel="noopener ugc nofollow" target="_blank">英特尔系统启动工具包</a>(面向系统工程师)</li></ul><div class="no np gq gs nq nr"><a rel="noopener  ugc nofollow" target="_blank" href="/introduction-to-intels-oneapi-ai-analytics-toolkit-8dd873925b96"><div class="ns ab fp"><div class="nt ab nu cl cj nv"><h2 class="bd iv gz z fq nw fs ft nx fv fx it bi translated">英特尔oneAPI人工智能分析工具包简介</h2><div class="ny l"><h3 class="bd b gz z fq nw fs ft nx fv fx dk translated">借助英特尔优化的oneAPI AI分析工具包，加快您的数据处理和机器学习流程</h3></div><div class="nz l"><p class="bd b dl z fq nw fs ft nx fv fx dk translated">pub.towardsai.net</p></div></div><div class="oa l"><div class="ob l oc od oe oa of la nr"/></div></div></a></div><p id="5fd6" class="pw-post-body-paragraph lg lh iu li b lj lk jv ll lm ln jy lo lp lq lr ls lt lu lv lw lx ly lz ma mb in bi translated">在本文中，我们将介绍OpenVINO toolkit的英特尔发行版，它是什么，它是如何工作的，以及如何通过示例使用它。让我们开始吧。</p><h1 id="234b" class="md me iu bd mf mg mh mi mj mk ml mm mn ka mo kb mp kd mq ke mr kg ms kh mt mu bi translated">什么是OpenVINO Toolkit？</h1><p id="11ab" class="pw-post-body-paragraph lg lh iu li b lj mv jv ll lm mw jy lo lp mx lr ls lt my lv lw lx mz lz ma mb in bi translated">您是否正在尝试加速与视觉相关的推理任务，如图像分类、图像字幕、物体检测等。在你的深度学习应用上？那么只需看看英特尔发布的OpenVINO toolkit就够了。</p><p id="f5d1" class="pw-post-body-paragraph lg lh iu li b lj lk jv ll lm ln jy lo lp lq lr ls lt lu lv lw lx ly lz ma mb in bi translated">OpenVINO代表Open<strong class="li iv">V</strong>I<strong class="li iv">I</strong>N<strong class="li iv">N</strong>eural Network<strong class="li iv">O</strong>optimization。顾名思义，它用于优化深度学习模型的神经网络，以完成与视觉相关的任务。</p><p id="3b03" class="pw-post-body-paragraph lg lh iu li b lj lk jv ll lm ln jy lo lp lq lr ls lt lu lv lw lx ly lz ma mb in bi translated">OpenVINO toolkit包含通过应用不同的技术(如修剪、量化等)来优化神经网络的工具和库。在英特尔架构上以<em class="og">与硬件无关的</em>方式加速推理。因此，通过使用OpenVINO toolkit，您可以获得更快的推理、对英特尔架构上异构执行的支持、优化库OpenCV等优势。</p><h1 id="f6d6" class="md me iu bd mf mg mh mi mj mk ml mm mn ka mo kb mp kd mq ke mr kg ms kh mt mu bi translated">OpenVINO Toolkit是如何工作的？</h1><p id="f392" class="pw-post-body-paragraph lg lh iu li b lj mv jv ll lm mw jy lo lp mx lr ls lt my lv lw lx mz lz ma mb in bi translated">正如你所看到的，OpenVINO采用了使用任何框架开发的深度学习模型，如<em class="og"> TensorFlow、PyTorch、Mxnet、Keras、ONNX </em>和<em class="og"> Caffe </em>，并将它们转换为一种标准格式(IR——中间表示格式),可以在任何英特尔硬件架构上运行，如CPU、GPU、集成GPU、FPGA、VPU等。同时，OpenVINO还为推理提供了优化的性能。</p><figure class="kr ks kt ku gu kv gi gj paragraph-image"><div role="button" tabindex="0" class="kw kx di ky bf kz"><div class="gi gj oh"><img src="../Images/1b7b5d7f2ae3e31693455ec9020d557a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*oVxwVfEOLSpi1kaa_juHjg.png"/></div></div><figcaption class="lc ld gk gi gj le lf bd b be z dk translated">来源:<a class="ae mc" href="https://www.intel.com/content/www/us/en/developer/tools/openvino-toolkit/overview.html" rel="noopener ugc nofollow" target="_blank">https://www . Intel . com/content/www/us/en/developer/tools/open vino-toolkit/overview . html</a></figcaption></figure><h2 id="9f90" class="oi me iu bd mf oj ok dn mj ol om dp mn lp on oo mp lt op oq mr lx or os mt ot bi translated"><strong class="ak">英特尔发布OpenVINO工具包内容</strong></h2><p id="1153" class="pw-post-body-paragraph lg lh iu li b lj mv jv ll lm mw jy lo lp mx lr ls lt my lv lw lx mz lz ma mb in bi translated">英特尔发布的OpenVINO toolkit包含-</p><ul class=""><li id="ccb7" class="na nb iu li b lj lk lm ln lp nc lt nd lx ne mb nf ng nh ni bi translated"><strong class="li iv">模型优化器— </strong>模型优化器加载任何经过训练的深度学习，并将其转换为IR(中间表示)格式。IR格式为更快的推断进行了优化。</li><li id="4081" class="na nb iu li b lj nj lm nk lp nl lt nm lx nn mb nf ng nh ni bi translated"><strong class="li iv">推理机</strong>—推理机读取IR格式，并负责在不同的硬件架构上运行模型，如CPU、GPU、集成GPU等。</li><li id="f087" class="na nb iu li b lj nj lm nk lp nl lt nm lx nn mb nf ng nh ni bi translated"><strong class="li iv">模型动物园—</strong>open vino的模型动物园包含经过英特尔优化的预训练模型(如VGG16、Alexnet、Yolo等)以及公开发布的预训练模型。这些预训练模型包括涉及对象检测、图像分类、图像分割等的用例。Model Zoo资源库包含许多示例，可以帮助您快速入门OpenVINO。</li></ul><h2 id="920a" class="oi me iu bd mf oj ok dn mj ol om dp mn lp on oo mp lt op oq mr lx or os mt ot bi translated">英特尔发布OpenVINO工具包的基本工作流程</h2><p id="f915" class="pw-post-body-paragraph lg lh iu li b lj mv jv ll lm mw jy lo lp mx lr ls lt my lv lw lx mz lz ma mb in bi translated"><strong class="li iv">步骤1 — </strong>作为第一步，将已经训练好的深度学习模型加载到模型优化器中，然后模型优化器将模型转换成中间表示。这种红外格式包含两个文件—</p><ul class=""><li id="eff3" class="na nb iu li b lj lk lm ln lp nc lt nd lx ne mb nf ng nh ni bi translated"><em class="og">。XML</em>——描述网络拓扑。</li><li id="a89b" class="na nb iu li b lj nj lm nk lp nl lt nm lx nn mb nf ng nh ni bi translated"><em class="og">。bin </em> -包含二进制格式的权重和偏差。</li></ul><figure class="kr ks kt ku gu kv gi gj paragraph-image"><div role="button" tabindex="0" class="kw kx di ky bf kz"><div class="gi gj ou"><img src="../Images/a9bdc5c8e18f22b3aa758478d2e88e59.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*z0jwPRrlkEJ0YQ0C3yCOpw.png"/></div></div><figcaption class="lc ld gk gi gj le lf bd b be z dk translated">基本工作流程(来源:英特尔)</figcaption></figure><p id="977c" class="pw-post-body-paragraph lg lh iu li b lj lk jv ll lm ln jy lo lp lq lr ls lt lu lv lw lx ly lz ma mb in bi translated">注意，可以使用应用训练后量化方法的<a class="ae mc" href="https://docs.openvino.ai/latest/pot_introduction.html#doxid-pot-introduction" rel="noopener ugc nofollow" target="_blank"> <strong class="li iv">训练后优化</strong> </a>对生成的IR文件进行进一步优化。</p><p id="75c0" class="pw-post-body-paragraph lg lh iu li b lj lk jv ll lm ln jy lo lp lq lr ls lt lu lv lw lx ly lz ma mb in bi translated"><strong class="li iv">步骤2 — </strong>接下来，在用户应用中，推理引擎加载IR文件，并使用它们在云、边缘或内部的英特尔架构上进行推理。</p><h1 id="935e" class="md me iu bd mf mg mh mi mj mk ml mm mn ka mo kb mp kd mq ke mr kg ms kh mt mu bi translated">装置</h1><p id="d789" class="pw-post-body-paragraph lg lh iu li b lj mv jv ll lm mw jy lo lp mx lr ls lt my lv lw lx mz lz ma mb in bi translated">既然我们已经理解了什么是OpenVINO以及它做什么，让我们安装这个工具包，然后在下一节中，我们看两个例子。</p><p id="c748" class="pw-post-body-paragraph lg lh iu li b lj lk jv ll lm ln jy lo lp lq lr ls lt lu lv lw lx ly lz ma mb in bi translated">在开始安装之前，请检查<a class="ae mc" href="https://www.intel.com/content/www/us/en/developer/tools/openvino-toolkit/system-requirements.html" rel="noopener ugc nofollow" target="_blank"> <strong class="li iv"> <em class="og">系统需求</em> </strong> </a>。</p><p id="d914" class="pw-post-body-paragraph lg lh iu li b lj lk jv ll lm ln jy lo lp lq lr ls lt lu lv lw lx ly lz ma mb in bi translated">(1).安装OpenVINO工具包有两个选项。根据您的需求选择合适的产品。</p><ul class=""><li id="f0f3" class="na nb iu li b lj lk lm ln lp nc lt nd lx ne mb nf ng nh ni bi translated"><strong class="li iv"><em class="og">OpenVINO Runtime</em></strong>—如果您已经完成了模型开发并准备好进行部署，那么继续使用open vino Runtime。</li><li id="dcee" class="na nb iu li b lj nj lm nk lp nl lt nm lx nn mb nf ng nh ni bi translated"><strong class="li iv"> <em class="og"> OpenVINO开发工具— </em> </strong>如果需要开发模型，将其转换为IR格式，优化后安装OpenVINO开发工具。</li></ul><p id="ccfd" class="pw-post-body-paragraph lg lh iu li b lj lk jv ll lm ln jy lo lp lq lr ls lt lu lv lw lx ly lz ma mb in bi translated">(2).转到下面的链接，并按照屏幕上的指示下载。<a class="ae mc" href="https://www.intel.com/content/www/us/en/developer/tools/openvino-toolkit/download.html" rel="noopener ugc nofollow" target="_blank">https://www . Intel . com/content/www/us/en/developer/tools/open vino-toolkit/download . html</a>。</p><p id="9219" class="pw-post-body-paragraph lg lh iu li b lj lk jv ll lm ln jy lo lp lq lr ls lt lu lv lw lx ly lz ma mb in bi translated">选择<em class="og">环境:开发工具</em>、<em class="og">操作系统:Linux </em>、<em class="og"> OpenVINO工具包版本:2022.1 </em>、<em class="og">发行版:pip </em>、<em class="og">框架:TensorFlow 2.x </em>后，要求我使用命令<code class="fe ov ow ox oy b">pip install openvino-dev[tensorflow2]==2021.4.2</code>安装OpenVINO。根据您的操作系统、框架等遵循类似的步骤，并安装软件。</p><pre class="kr ks kt ku gu oz oy pa pb aw pc bi"><span id="68c1" class="oi me iu oy b gz pd pe l pf pg"># Create environment <br/>conda create -n openvino_env python=3.8</span><span id="b884" class="oi me iu oy b gz ph pe l pf pg"># Activate the environment<br/>conda activate openvino_env</span><span id="6839" class="oi me iu oy b gz ph pe l pf pg"># Install OpenVINO<br/>pip install openvino-dev[tensorflow2]==2021.4.2</span><span id="7084" class="oi me iu oy b gz ph pe l pf pg"># Install and Open Jupyter notebook<br/>pip install jupyter<br/>jupyter notebook</span></pre><p id="db1b" class="pw-post-body-paragraph lg lh iu li b lj lk jv ll lm ln jy lo lp lq lr ls lt lu lv lw lx ly lz ma mb in bi translated">要确认安装，请在命令提示符下运行<code class="fe ov ow ox oy b">mo -h</code>,如果您获得了关于model optimizer命令的详细信息，那么您的安装就成功了。</p><h1 id="92e7" class="md me iu bd mf mg mh mi mj mk ml mm mn ka mo kb mp kd mq ke mr kg ms kh mt mu bi translated">例子</h1><p id="2212" class="pw-post-body-paragraph lg lh iu li b lj mv jv ll lm mw jy lo lp mx lr ls lt my lv lw lx mz lz ma mb in bi translated">在这一节中，我们将使用预先训练好的张量流模型<code class="fe ov ow ox oy b">inception-resnet-v2-tf</code>来完成使用OpenVINO工具包的图像分类任务。从您在上一节中创建的虚拟环境<code class="fe ov ow ox oy b">openvino_env</code>中打开Jupyter笔记本。</p><h2 id="d13c" class="oi me iu bd mf oj ok dn mj ol om dp mn lp on oo mp lt op oq mr lx or os mt ot bi translated"><strong class="ak">步骤1—下载模型</strong></h2><p id="4a95" class="pw-post-body-paragraph lg lh iu li b lj mv jv ll lm mw jy lo lp mx lr ls lt my lv lw lx mz lz ma mb in bi translated">执行以下命令，将预先训练好的模型<code class="fe ov ow ox oy b">inception-resnet-v2-tf</code>下载到<code class="fe ov ow ox oy b">/home/chetan/public</code>文件夹。</p><pre class="kr ks kt ku gu oz oy pa pb aw pc bi"><span id="5b0c" class="oi me iu oy b gz pd pe l pf pg"><strong class="oy iv">!omz_downloader --name inception-resnet-v2-tf</strong><br/>################|| Downloading inception-resnet-v2-tf ||################</span><span id="4e27" class="oi me iu oy b gz ph pe l pf pg">========== Downloading /home/chetan/public/inception-resnet-v2-tf/inception_resnet_v2_2018_04_27.tgz<br/>... 100%, 220587 KB, 6325 KB/s, 34 seconds passed</span><span id="84dc" class="oi me iu oy b gz ph pe l pf pg">========== Unpacking /home/chetan/public/inception-resnet-v2-tf/inception_resnet_v2_2018_04_27.tgz</span></pre><h2 id="006a" class="oi me iu bd mf oj ok dn mj ol om dp mn lp on oo mp lt op oq mr lx or os mt ot bi translated"><strong class="ak">步骤2—导入库</strong></h2><pre class="kr ks kt ku gu oz oy pa pb aw pc bi"><span id="af6c" class="oi me iu oy b gz pd pe l pf pg">import cv2<br/>import matplotlib.pyplot as plt<br/>import numpy as np<br/>from openvino.runtime import Core<br/>from pathlib import Path<br/>from IPython.display import Markdown</span></pre><h2 id="79f7" class="oi me iu bd mf oj ok dn mj ol om dp mn lp on oo mp lt op oq mr lx or os mt ot bi translated"><strong class="ak">步骤3—将模型转换为IR </strong></h2><p id="eb2c" class="pw-post-body-paragraph lg lh iu li b lj mv jv ll lm mw jy lo lp mx lr ls lt my lv lw lx mz lz ma mb in bi translated"><strong class="li iv">步骤3a——设置预训练和转换模型的路径</strong></p><pre class="kr ks kt ku gu oz oy pa pb aw pc bi"><span id="5552" class="oi me iu oy b gz pd pe l pf pg">model_path = Path("/home/chetan/public/inception-resnet-v2-tf/inception_resnet_v2.pb")<br/>ir_path = Path(model_path).with_suffix(".xml")</span></pre><p id="c905" class="pw-post-body-paragraph lg lh iu li b lj lk jv ll lm ln jy lo lp lq lr ls lt lu lv lw lx ly lz ma mb in bi translated"><strong class="li iv">步骤3b —构建运行模型优化器的命令</strong></p><p id="966c" class="pw-post-body-paragraph lg lh iu li b lj lk jv ll lm ln jy lo lp lq lr ls lt lu lv lw lx ly lz ma mb in bi translated">接下来，我们需要构造命令来运行模型优化器。要获得对<code class="fe ov ow ox oy b">mo</code>所有参数的概述，请运行<code class="fe ov ow ox oy b">mo --help</code>。以下是对以下代码中使用的参数的解释—</p><p id="002e" class="pw-post-body-paragraph lg lh iu li b lj lk jv ll lm ln jy lo lp lq lr ls lt lu lv lw lx ly lz ma mb in bi translated"><em class="og">输入模型:</em>预训练模型或源模型的路径(TensorFlow、PyTorch、Caffe、Mxnet等)</p><p id="4779" class="pw-post-body-paragraph lg lh iu li b lj lk jv ll lm ln jy lo lp lq lr ls lt lu lv lw lx ly lz ma mb in bi translated"><em class="og"> input_shape </em>:应该馈入模型输入节点的形状。</p><p id="06bf" class="pw-post-body-paragraph lg lh iu li b lj lk jv ll lm ln jy lo lp lq lr ls lt lu lv lw lx ly lz ma mb in bi translated"><em class="og"> mean_values: </em>是用于每个通道的输入图像的平均值，遵循[R，G，B]格式。请注意，顺序取决于用于训练的模型。</p><p id="25d5" class="pw-post-body-paragraph lg lh iu li b lj lk jv ll lm ln jy lo lp lq lr ls lt lu lv lw lx ly lz ma mb in bi translated"><em class="og"> scale_values: </em>所有的值都除以这个值。</p><p id="4263" class="pw-post-body-paragraph lg lh iu li b lj lk jv ll lm ln jy lo lp lq lr ls lt lu lv lw lx ly lz ma mb in bi translated"><em class="og"> data_type </em>:指定中间张量和权重的数据类型。例如，如果原始模型是FP32，那么指定FP16将导致模型权重和偏差压缩到FP16。</p><p id="68d5" class="pw-post-body-paragraph lg lh iu li b lj lk jv ll lm ln jy lo lp lq lr ls lt lu lv lw lx ly lz ma mb in bi translated"><em class="og"> output_dir </em>:您要存储转换后的ir格式模型的文件夹。</p><pre class="kr ks kt ku gu oz oy pa pb aw pc bi"><span id="6df8" class="oi me iu oy b gz pd pe l pf pg">mo_command = f"""mo<br/>                 --input_model "{model_path}"<br/>                 --input_shape "[1,299,299,3]"<br/>                 --mean_values="[127.5,127.5,127.5]"<br/>                 --scale_values="[127.5]"<br/>                 --data_type FP16<br/>                 --output_dir "{model_path.parent}"<br/>                 """<br/>mo_command = " ".join(mo_command.split())<br/>print("Model Optimizer command to convert TensorFlow to OpenVINO:")<br/>display(Markdown(f"`{mo_command}`"))</span></pre><p id="af0c" class="pw-post-body-paragraph lg lh iu li b lj lk jv ll lm ln jy lo lp lq lr ls lt lu lv lw lx ly lz ma mb in bi translated"><strong class="li iv">步骤3c —运行模型优化器</strong></p><p id="7c4e" class="pw-post-body-paragraph lg lh iu li b lj lk jv ll lm ln jy lo lp lq lr ls lt lu lv lw lx ly lz ma mb in bi translated">在前面的步骤中构建了模型优化器命令后，运行下面的命令。这将把模型转换成红外格式。请注意，这需要几分钟时间。</p><pre class="kr ks kt ku gu oz oy pa pb aw pc bi"><span id="757e" class="oi me iu oy b gz pd pe l pf pg">print("Exporting TF model to IR. This may take a few minutes.")<br/>! $mo_command</span></pre><p id="f4e1" class="pw-post-body-paragraph lg lh iu li b lj lk jv ll lm ln jy lo lp lq lr ls lt lu lv lw lx ly lz ma mb in bi translated">模型优化器将创建3个文件— <code class="fe ov ow ox oy b">inception_resnet_v2.xml</code>、<code class="fe ov ow ox oy b">inception_resnet_v2.mapping</code>和<code class="fe ov ow ox oy b">inception_resnet_v2.bin</code>。</p><h2 id="9181" class="oi me iu bd mf oj ok dn mj ol om dp mn lp on oo mp lt op oq mr lx or os mt ot bi translated">步骤4-加载转换后的模型</h2><p id="6af1" class="pw-post-body-paragraph lg lh iu li b lj mv jv ll lm mw jy lo lp mx lr ls lt my lv lw lx mz lz ma mb in bi translated">在上一步中，我们已经将模型转换为IR。接下来，用<code class="fe ov ow ox oy b">Core()</code>初始化推理机，然后用<code class="fe ov ow ox oy b">read_model()</code>加载IR，最后用<code class="fe ov ow ox oy b">compile_model()</code>编译特定设备的模型。因为我们是在CPU上做的，所以设置device_name='CPU '。</p><pre class="kr ks kt ku gu oz oy pa pb aw pc bi"><span id="8700" class="oi me iu oy b gz pd pe l pf pg"># Load the converted model<br/>ie = Core()<br/>model = ie.read_model(model="public/inception-resnet-v2-tf/inception_resnet_v2.xml")<br/>compiled_model = ie.compile_model(model=model, device_name="CPU")</span></pre><p id="284f" class="pw-post-body-paragraph lg lh iu li b lj lk jv ll lm ln jy lo lp lq lr ls lt lu lv lw lx ly lz ma mb in bi translated">我们只通过了。要读取的xml文件_model。但是read_model需要。bin文件放在同一个目录中。</p><h2 id="e6a8" class="oi me iu bd mf oj ok dn mj ol om dp mn lp on oo mp lt op oq mr lx or os mt ot bi translated">步骤5-获取型号信息</h2><p id="3ec3" class="pw-post-body-paragraph lg lh iu li b lj mv jv ll lm mw jy lo lp mx lr ls lt my lv lw lx mz lz ma mb in bi translated">我们可以从<code class="fe ov ow ox oy b">model.inputs</code>和<code class="fe ov ow ox oy b">model.outputs</code>或者<code class="fe ov ow ox oy b">compiled_model.inputs</code>和<code class="fe ov ow ox oy b">compiled_model.outputs</code>得到模型的输入和输出信息。</p><pre class="kr ks kt ku gu oz oy pa pb aw pc bi"><span id="6828" class="oi me iu oy b gz pd pe l pf pg">input_key = next(iter(compiled_model.inputs))<br/>output_key = next(iter(compiled_model.outputs))<br/>network_input_shape = input_key.shape</span></pre><h2 id="4850" class="oi me iu bd mf oj ok dn mj ol om dp mn lp on oo mp lt op oq mr lx or os mt ot bi translated">步骤6 —加载图像</h2><p id="2545" class="pw-post-body-paragraph lg lh iu li b lj mv jv ll lm mw jy lo lp mx lr ls lt my lv lw lx mz lz ma mb in bi translated">下面我们从网上加载一张孟加拉虎<a class="ae mc" href="https://biologydictionary.net/bengal-tiger/" rel="noopener ugc nofollow" target="_blank"> <strong class="li iv">图片</strong> </a>。inception_resnet模型需要RGB格式的图像，因此我们将图像从BGR2RGB转换，并根据模型调整图像大小，最后调整图像大小。</p><pre class="kr ks kt ku gu oz oy pa pb aw pc bi"><span id="9cd1" class="oi me iu oy b gz pd pe l pf pg"># The Inception Resnet network expects images in RGB format<br/>image = cv2.cvtColor(cv2.imread(filename="data/cat.jpeg"), code=cv2.COLOR_BGR2RGB)</span><span id="be77" class="oi me iu oy b gz ph pe l pf pg"># Resize image to network input image shape<br/>resized_image = cv2.resize(src=image, dsize=(299, 299))</span><span id="780a" class="oi me iu oy b gz ph pe l pf pg"># Transpose image to network input shape<br/>input_image = np.expand_dims(resized_image, 0)</span><span id="9893" class="oi me iu oy b gz ph pe l pf pg">plt.imshow(image);</span></pre><figure class="kr ks kt ku gu kv gi gj paragraph-image"><div class="gi gj pi"><img src="../Images/347f0e33497aba9b1dd94fe65a9bd004.png" data-original-src="https://miro.medium.com/v2/resize:fit:1200/format:webp/0*7BVBKZaq85IDUS4D.jpg"/></div><figcaption class="lc ld gk gi gj le lf bd b be z dk translated">来源:<a class="ae mc" href="https://biologydictionary.net/bengal-tiger/" rel="noopener ugc nofollow" target="_blank">https://biologydictionary.net/bengal-tiger/</a></figcaption></figure><h2 id="7640" class="oi me iu bd mf oj ok dn mj ol om dp mn lp on oo mp lt op oq mr lx or os mt ot bi translated">第七步——推理</h2><p id="2270" class="pw-post-body-paragraph lg lh iu li b lj mv jv ll lm mw jy lo lp mx lr ls lt my lv lw lx mz lz ma mb in bi translated">在最后一步，我们通过调用<code class="fe ov ow ox oy b">compiled_model()</code>进行推理。该模型将<code class="fe ov ow ox oy b">result_index</code>输出为293，为了获得该值的含义，我们需要相应的标签<code class="fe ov ow ox oy b">labels.txt</code>，即“<strong class="li iv"> <em class="og"> tiger </em> </strong>”。</p><pre class="kr ks kt ku gu oz oy pa pb aw pc bi"><span id="0495" class="oi me iu oy b gz pd pe l pf pg">result = compiled_model([input_image])[output_key]<br/>result_index = np.argmax(result)</span><span id="f451" class="oi me iu oy b gz ph pe l pf pg"># Convert the inference result to a class name.<br/>imagenet_classes = open("/home/chetan/public/inception-resnet-v2-tf/labels.txt").read().splitlines()</span><span id="b5ca" class="oi me iu oy b gz ph pe l pf pg">imagenet_classes[result_index]</span></pre><p id="4132" class="pw-post-body-paragraph lg lh iu li b lj lk jv ll lm ln jy lo lp lq lr ls lt lu lv lw lx ly lz ma mb in bi translated">输出:</p><pre class="kr ks kt ku gu oz oy pa pb aw pc bi"><span id="ded0" class="oi me iu oy b gz pd pe l pf pg">Result index 293<br/>Predicted class: tiger</span></pre><p id="75f8" class="pw-post-body-paragraph lg lh iu li b lj lk jv ll lm ln jy lo lp lq lr ls lt lu lv lw lx ly lz ma mb in bi translated">您刚刚通过OpenVINO workflow运行了一个TensorFlow模型。万岁！给自己一个鼓励！！这是你应得的👏。这是向您介绍OpenVINO工具包的一个简单例子。</p><p id="034f" class="pw-post-body-paragraph lg lh iu li b lj lk jv ll lm ln jy lo lp lq lr ls lt lu lv lw lx ly lz ma mb in bi translated">在<a class="ae mc" href="https://docs.openvino.ai/latest/index.html" rel="noopener ugc nofollow" target="_blank">官方文档</a>上有数百个教程和演示可以用来开始使用OpenVINO，涵盖了各种用例。我强烈建议你尽可能多的看一些例子。以便您可以在下一个深度学习应用程序中轻松使用OpenVINO工具包。</p><h1 id="6fca" class="md me iu bd mf mg mh mi mj mk ml mm mn ka mo kb mp kd mq ke mr kg ms kh mt mu bi translated">摘要</h1><p id="d048" class="pw-post-body-paragraph lg lh iu li b lj mv jv ll lm mw jy lo lp mx lr ls lt my lv lw lx mz lz ma mb in bi translated">在这篇博客中，我们介绍了什么是OpenVINO toolkit，它是如何工作的，该工具包包含什么，最后通过一个使用预训练模型的图像分类示例。希望这篇文章对你有用。</p><p id="f5bb" class="pw-post-body-paragraph lg lh iu li b lj lk jv ll lm ln jy lo lp lq lr ls lt lu lv lw lx ly lz ma mb in bi translated">注意，OpenVINO工具包包含了很多工具和库。在这篇文章中，我仅仅触及了皮毛🙂。要学的东西太多了比如<em class="og">模型动物园</em>、<em class="og"> OpenVINO深度学习工作台</em>、<em class="og">优化后量化(POT) </em>、<em class="og">附加组件(OpenVINO模型服务器</em>、<em class="og"> OpenVINO安全</em>等等。)、<em class="og">媒体处理&amp;计算机视觉库(OpenCV、OpenCL) </em>等。对于那些好奇的头脑，我建议你多探索一下OpenVINO。</p><h1 id="fa3b" class="md me iu bd mf mg mh mi mj mk ml mm mn ka mo kb mp kd mq ke mr kg ms kh mt mu bi translated">进一步阅读</h1><ul class=""><li id="801c" class="na nb iu li b lj mv lm mw lp pj lt pk lx pl mb nf ng nh ni bi translated"><a class="ae mc" rel="noopener ugc nofollow" target="_blank" href="/the-difference-between-a-a-b-and-a-b-in-python-a7338d96e408">Python中a=a+b和a+=b的区别</a></li><li id="2e20" class="na nb iu li b lj nj lm nk lp nl lt nm lx nn mb nf ng nh ni bi translated"><a class="ae mc" href="https://pythonsimplified.com/generate-fake-data-using-faker-and-python/" rel="noopener ugc nofollow" target="_blank">使用Faker和Python生成假数据</a></li><li id="3308" class="na nb iu li b lj nj lm nk lp nl lt nm lx nn mb nf ng nh ni bi translated"><a class="ae mc" href="https://pythonsimplified.com/difference-between-sort-and-sorted-in-python/" rel="noopener ugc nofollow" target="_blank">Python中sort()和sorted()的区别</a></li><li id="a3d5" class="na nb iu li b lj nj lm nk lp nl lt nm lx nn mb nf ng nh ni bi translated"><a class="ae mc" href="https://pythonsimplified.com/the-most-controversial-python-walrus-operator/" rel="noopener ugc nofollow" target="_blank">最有争议的蟒蛇海象运营商</a></li><li id="ff85" class="na nb iu li b lj nj lm nk lp nl lt nm lx nn mb nf ng nh ni bi translated"><a class="ae mc" href="https://pythonsimplified.com/understanding-indexing-and-slicing-in-python/" rel="noopener ugc nofollow" target="_blank">了解Python中的索引和切片</a></li><li id="455c" class="na nb iu li b lj nj lm nk lp nl lt nm lx nn mb nf ng nh ni bi translated"><a class="ae mc" href="https://pythonsimplified.com/making-sense-of-python-iterables-and-iterators/" rel="noopener ugc nofollow" target="_blank">理解Python中的可迭代项和迭代器</a></li><li id="cbbe" class="na nb iu li b lj nj lm nk lp nl lt nm lx nn mb nf ng nh ni bi translated"><a class="ae mc" href="https://pythonsimplified.com/understanding-generators-in-python/" rel="noopener ugc nofollow" target="_blank">理解Python中的生成器</a></li></ul><p id="91c3" class="pw-post-body-paragraph lg lh iu li b lj lk jv ll lm ln jy lo lp lq lr ls lt lu lv lw lx ly lz ma mb in bi translated">我希望你喜欢阅读这篇文章。如果你喜欢我的文章并想订阅Medium，你可以点击这里的<a class="ae mc" href="https://chetanambi.medium.com/membership" rel="noopener"><strong class="li iv"/></a>。你的会员费直接支持我和你看的其他作家。你也可以在媒体上看到所有的故事。</p><div class="no np gq gs nq nr"><a href="https://chetanambi.medium.com/membership" rel="noopener follow" target="_blank"><div class="ns ab fp"><div class="nt ab nu cl cj nv"><h2 class="bd iv gz z fq nw fs ft nx fv fx it bi translated">通过我的推荐链接加入媒体- Chetan Ambi</h2><div class="ny l"><h3 class="bd b gz z fq nw fs ft nx fv fx dk translated">阅读Chetan Ambi的每一个故事(以及媒体上成千上万的其他作家)。您的会员费直接支持…</h3></div><div class="nz l"><p class="bd b dl z fq nw fs ft nx fv fx dk translated">chetanambi.medium.com</p></div></div><div class="oa l"><div class="pm l oc od oe oa of la nr"/></div></div></a></div></div><div class="ab cl kj kk hy kl" role="separator"><span class="km bw bk kn ko kp"/><span class="km bw bk kn ko kp"/><span class="km bw bk kn ko"/></div><div class="in io ip iq ir"><h1 id="1bd6" class="md me iu bd mf mg pn mi mj mk po mm mn ka pp kb mp kd pq ke mr kg pr kh mt mu bi translated">参考</h1><p id="17e5" class="pw-post-body-paragraph lg lh iu li b lj mv jv ll lm mw jy lo lp mx lr ls lt my lv lw lx mz lz ma mb in bi translated">[1].<a class="ae mc" href="https://docs.openvino.ai/latest/index.html" rel="noopener ugc nofollow" target="_blank">https://docs.openvino.ai/latest/index.html</a></p><p id="185e" class="pw-post-body-paragraph lg lh iu li b lj lk jv ll lm ln jy lo lp lq lr ls lt lu lv lw lx ly lz ma mb in bi translated">[2].<a class="ae mc" href="https://www.intel.com/content/www/us/en/developer/tools/devcloud/edge/learn/openvino.html" rel="noopener ugc nofollow" target="_blank">https://www . Intel . com/content/www/us/en/developer/tools/dev cloud/edge/learn/open vino . html</a></p><p id="5baa" class="pw-post-body-paragraph lg lh iu li b lj lk jv ll lm ln jy lo lp lq lr ls lt lu lv lw lx ly lz ma mb in bi translated">#oneAPI</p></div></div>    
</body>
</html>