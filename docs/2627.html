<html>
<head>
<title>Support Vector Machine (SVM) for Binary and Multi-Class Classification: Hands-On with Scikit-Learn</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">用于二元和多类分类的支持向量机(SVM ): sci kit-Learn实践</h1>
<blockquote>原文：<a href="https://pub.towardsai.net/support-vector-machine-svm-for-binary-and-multiclass-classification-hands-on-with-scikit-learn-29cdbe5cb90e?source=collection_archive---------0-----------------------#2022-03-22">https://pub.towardsai.net/support-vector-machine-svm-for-binary-and-multiclass-classification-hands-on-with-scikit-learn-29cdbe5cb90e?source=collection_archive---------0-----------------------#2022-03-22</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="74ae" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">使用Python和Google Colab</h2></div><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ki"><img src="../Images/1a67f2952df280e9ad4d47acc66412e8.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Taeejb3P6-AABQoiEU3EVQ.png"/></div></div></figure><p id="c9ac" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">支持向量机(SVM)是一种基于线性模型的分类算法。它允许二进制或多类分类(应用<a class="ae lq" href="https://medium.com/p/560eb87a7b8" rel="noopener"> one-vs-rest技术</a>)。在本文中，我将通过一个完整的实践教程来指导您在二进制和多类数据中实现SVM模型。</p><p id="a1bc" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">如果你想知道更多关于SVM和算法如何在幕后工作，你可以找到我的另一篇<a class="ae lq" href="https://medium.com/p/560eb87a7b8" rel="noopener">文章</a>:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi lr"><img src="../Images/9e5f9a5b31442bd7b2b043dcebe39f1c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1264/format:webp/1*1xOQ2IHVtQ7KbjDySZ04cw.png"/></div><figcaption class="ls lt gj gh gi lu lv bd b be z dk translated">【https://medium.com/p/560eb87a7b8 T4】</figcaption></figure><h2 id="d941" class="lw lx it bd ly lz ma dn mb mc md dp me ld mf mg mh lh mi mj mk ll ml mm mn mo bi translated">SVM二元分类</h2><p id="41e7" class="pw-post-body-paragraph ku kv it kw b kx mp ju kz la mq jx lc ld mr lf lg lh ms lj lk ll mt ln lo lp im bi translated">在二元分类中，我们希望预测我们的数据属于两个类别中的哪一个。在本教程中，我将使用在Kaggle上免费下载的<a class="ae lq" href="https://www.kaggle.com/zaraavagyan/weathercsv" rel="noopener ugc nofollow" target="_blank"> weather.csv </a>数据。这个数据集有六个数值变量和两个分类变量。分类变量，一个是二元的(“Rain”:0或1)，另一个是多类的(“Description”:0代表正常温度，1代表寒冷，2代表温暖)。我们将使用数值变量来预测分类变量，对于二进制SVM使用“Rain ”,对于多分类SVM使用“Description”。</p><p id="39b0" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">我们开始吧。</p><p id="33bd" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">与我的其他项目示例一样，我将使用Google Colab来运行我的分析。</p><p id="d7c8" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">首先，我们需要加载必要的库:</p><pre class="kj kk kl km gt mu mv mw mx aw my bi"><span id="4170" class="lw lx it mv b gy mz na l nb nc">import numpy as np<br/>import pandas as pd<br/>import matplotlib.pyplot as plt<br/>import seaborn as sns<br/>from sklearn.model_selection import train_test_split<br/>from sklearn.svm import LinearSVC<br/>from mlxtend.plotting import plot_decision_regions</span></pre><p id="a0ad" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">要加载数据库，请执行以下操作:</p><pre class="kj kk kl km gt mu mv mw mx aw my bi"><span id="25f4" class="lw lx it mv b gy mz na l nb nc">df = pd.read_csv("/content/weather.csv")<br/>df</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi nd"><img src="../Images/dd1a0fe9265d2b99ac3757438eb3c74a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*XSHX6aE0I6ojwSJxvOTCHg.png"/></div></div><figcaption class="ls lt gj gh gi lu lv bd b be z dk translated">weather.csv数据集</figcaption></figure><p id="9e2e" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">我们的目标是预测降雨，其中1表示<strong class="kw iu"><em class="ne"/></strong>【下雨】，0表示<strong class="kw iu"> <em class="ne">【无雨】</em> </strong>。我们可以探索我们的数据集，并查看变量根据<strong class="kw iu"><em class="ne"/></strong>或<strong class="kw iu"> <em class="ne">【无雨】</em> </strong>类别的表现。我们可以检查相关性和分布。</p><pre class="kj kk kl km gt mu mv mw mx aw my bi"><span id="1246" class="lw lx it mv b gy mz na l nb nc">#Exploring dataset:<br/>sns.pairplot(df, kind="scatter", hue="Rain")<br/>plt.show()</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi nf"><img src="../Images/d057630aaa96ef34353e2f23676fc5bd.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*g9r7Y-Z9zgb8g8jW8gWw0Q.png"/></div></div></figure><p id="b509" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">变量之间的相关性可以使用热图进行评估:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi ng"><img src="../Images/b5a228d55c915d8c0d4149bb0ca7d815.png" data-original-src="https://miro.medium.com/v2/resize:fit:824/format:webp/1*LgzxyBbjmH0wJVFiMqTlWQ.png"/></div></figure><p id="bae2" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">我们还可以根据两个类别检查参数的分布:</p><pre class="kj kk kl km gt mu mv mw mx aw my bi"><span id="ebb3" class="lw lx it mv b gy mz na l nb nc">fig, axs = plt.subplots(2, 3, figsize=(14, 7))</span><span id="868a" class="lw lx it mv b gy nh na l nb nc">sns.histplot(data=df, x="Temperature_c", hue="Rain", kde=True, color="skyblue", ax=axs[0, 0])<br/>sns.histplot(data=df, x="Humidity", hue="Rain", kde=True, color="skyblue", ax=axs[0, 1])<br/>sns.histplot(data=df, x="Wind_Speed_kmh", hue="Rain", kde=True, color="skyblue", ax=axs[0, 2])<br/>sns.histplot(data=df, x="Wind_Bearing_degrees", hue="Rain", kde=True, color="skyblue", ax=axs[1, 0])<br/>sns.histplot(data=df, x="Visibility_km", hue="Rain", kde=True, color="skyblue", ax=axs[1, 1])<br/>sns.histplot(data=df, x="Pressure_millibars", hue="Rain", kde=True, color="skyblue", ax=axs[1, 2])</span><span id="e83a" class="lw lx it mv b gy nh na l nb nc">plt.show()</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ki"><img src="../Images/20c07cac1049b4cd0ad32589af4531d9.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*EG82uengxEg3mNwy00howQ.png"/></div></div></figure><pre class="kj kk kl km gt mu mv mw mx aw my bi"><span id="d069" class="lw lx it mv b gy mz na l nb nc">fig, axs = plt.subplots(2, 3, figsize=(14, 7))</span><span id="f0ea" class="lw lx it mv b gy nh na l nb nc">sns.boxplot(x=df["Rain"], y=df["Temperature_c"], ax=axs[0, 0])<br/>sns.boxplot(x=df["Rain"], y=df["Humidity"], ax=axs[0, 1])<br/>sns.boxplot(x=df["Rain"], y=df["Wind_Speed_kmh"], ax=axs[0, 2])<br/>sns.boxplot(x=df["Rain"], y=df["Wind_Bearing_degrees"],ax=axs[1, 0])<br/>sns.boxplot(x=df["Rain"], y=df["Visibility_km"], ax=axs[1, 1] )<br/>sns.boxplot(x=df["Rain"], y=df["Pressure_millibars"], ax=axs[1, 2])</span><span id="2a7f" class="lw lx it mv b gy nh na l nb nc">plt.show()</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ni"><img src="../Images/6c0681ebc8e1553a050178269a00d9db.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*3bl5zOxHW2ImprqA0l2FDw.png"/></div></div></figure><p id="e592" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">一些变量似乎善于区分这两个群体，如温度或能见度。现在我们建立我们的SVM模型。我们需要创建我们的<strong class="kw iu"> <em class="ne"> X </em> </strong>变量(带有预测变量或特征)和<strong class="kw iu"><em class="ne"/></strong>(带有标签)。</p><pre class="kj kk kl km gt mu mv mw mx aw my bi"><span id="0f5d" class="lw lx it mv b gy mz na l nb nc">X = df.drop('Rain', axis=1)<br/>X = df.drop('Description', axis=1)</span><span id="1bdb" class="lw lx it mv b gy nh na l nb nc">y = df['Rain']</span></pre><p id="b5e2" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">并拆分我们的数据，80%的观测值用于建模，20%用于测试。</p><pre class="kj kk kl km gt mu mv mw mx aw my bi"><span id="ce8c" class="lw lx it mv b gy mz na l nb nc">X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20)</span></pre><p id="6e73" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">现在我们可以构建和评估我们的模型:</p><pre class="kj kk kl km gt mu mv mw mx aw my bi"><span id="6c1e" class="lw lx it mv b gy mz na l nb nc">LinearSVM = LinearSVC().fit(X_train, y_train)</span><span id="ad0b" class="lw lx it mv b gy nh na l nb nc">print("training set score: %f" % LinearSVM.score(X_train, y_train))<br/>print("test set score: %f" % LinearSVM.score(X_test, y_test))</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi nj"><img src="../Images/0f79956c2c4b95d36ccb039106a3c09a.png" data-original-src="https://miro.medium.com/v2/resize:fit:554/format:webp/1*GnUPMraZLQGFkCF0A2g2sg.png"/></div></figure><p id="bc20" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">我们的模型在预测降雨方面表现很好，训练子样本的准确率为96%，测试子样本的准确率为95%。由于训练和测试精度非常接近，这意味着我们的模型没有过度拟合。然而，我们仍然可以通过改变C参数来改进我们的模型。你可以在我的另一篇文章中读到更多关于<a class="ae lq" rel="noopener ugc nofollow" target="_blank" href="/logistic-regression-for-binary-classification-hands-on-with-scikit-learn-a5c06b0f2d60"> C参数的内容。我们将使用C=100进行尝试。</a></p><pre class="kj kk kl km gt mu mv mw mx aw my bi"><span id="79ac" class="lw lx it mv b gy mz na l nb nc">#C=100<br/>LinearSVM100 = LinearSVC(C=100).fit(X_train, y_train)</span><span id="4abd" class="lw lx it mv b gy nh na l nb nc">print("training set score: %f" % LinearSVM100.score(X_train, y_train))<br/>print("test set score: %f" % LinearSVM100.score(X_test, y_test))</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi nk"><img src="../Images/f4656b6a2d5268e2de0f4ef5ca8918d7.png" data-original-src="https://miro.medium.com/v2/resize:fit:556/format:webp/1*pq6kZZSkQFCO7Ic0X-nuUg.png"/></div></figure><p id="8858" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">将C改为100(默认情况下该值为1)改进了我们的模型。现在我们的训练准确率达到98.2%，测试准确率达到97.5%。但是我们也可以尝试降低这个参数，看看会发生什么:</p><pre class="kj kk kl km gt mu mv mw mx aw my bi"><span id="d7fa" class="lw lx it mv b gy mz na l nb nc">#C=0.01<br/>LinearSVM001 = LinearSVC(C=0.01).fit(X_train, y_train)</span><span id="be1f" class="lw lx it mv b gy nh na l nb nc">print("training set score: %f" % LinearSVM001.score(X_train, y_train))<br/>print("test set score: %f" % LinearSVM001.score(X_test, y_test))</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi nl"><img src="../Images/0e62776f7ac5d71dbc4fb2a88a0cbc4f.png" data-original-src="https://miro.medium.com/v2/resize:fit:510/format:webp/1*VWMuef__2zoqnbcf2degRw.png"/></div></figure><p id="cc12" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">正如你所看到的，将C改为0.01改进了我们的SVM模型。现在，我们对训练数据集的准确率为99%，对测试子样本的准确率为98.2%。这应该是我们最好的模型。</p><p id="a6b1" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">为了可视化结果，我们可以用这两个类构建一个表示。我们在方框图中看到，最能区分这两个等级的参数是<strong class="kw iu">温度_c </strong>和<strong class="kw iu">能见度_km </strong>。因为我们将只构建一个二维图形可视化，所以我们将使用这两个特性。</p><pre class="kj kk kl km gt mu mv mw mx aw my bi"><span id="64fd" class="lw lx it mv b gy mz na l nb nc">data = pd.read_csv('weather.csv')</span><span id="2632" class="lw lx it mv b gy nh na l nb nc">def LinearSVM_comparison(data,c):<br/>    x = data[[<strong class="mv iu">'Temperature_c'</strong>,<strong class="mv iu">'Visibility_km'</strong>,]].values<br/>    y = data['Rain'].astype(int).values<br/>    LinearSVM_plot = LinearSVC(C=c)<br/>    LinearSVM_plot.fit(x,y)<br/>    print(LinearSVM_plot.score(x,y))<br/>    #Plot decision region:<br/>    plot_decision_regions(x,y, clf=LinearSVM_plot, legend=2)<br/>    #Adding axes annotations:<br/>    plt.xlabel('X_train')<br/>    plt.ylabel('y_train')<br/>    plt.title('Linear SVM with C='+str(c))<br/>    plt.show()</span></pre><p id="339a" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">该函数还允许我们使用增强模型的C参数(C=0.01)来构建带有决策边界的图形:</p><pre class="kj kk kl km gt mu mv mw mx aw my bi"><span id="d2ed" class="lw lx it mv b gy mz na l nb nc">LinearSVM_comparison(data,<strong class="mv iu">0.01</strong>)</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi nm"><img src="../Images/5b05cc5e248e8ab7c582936b70391f17.png" data-original-src="https://miro.medium.com/v2/resize:fit:786/format:webp/1*8f8tnpih39TrBJIcyJPQ2g.png"/></div></figure><h2 id="814f" class="lw lx it bd ly lz ma dn mb mc md dp me ld mf mg mh lh mi mj mk ll ml mm mn mo bi translated">用SVM进行多类分类</h2><p id="bed2" class="pw-post-body-paragraph ku kv it kw b kx mp ju kz la mq jx lc ld mr lf lg lh ms lj lk ll mt ln lo lp im bi translated">使用SVM的多类分类类似于二分类，但是我们的机器应用一对其余(OVR)技术。我们现在要预测的三类是0(常温)、1(冷)、2(暖)。和往常一样，我们从数据检查开始:</p><pre class="kj kk kl km gt mu mv mw mx aw my bi"><span id="9e9e" class="lw lx it mv b gy mz na l nb nc">#Exploring dataset:<br/>sns.pairplot(df, kind="scatter", hue="Description")<br/>plt.show()</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi nn"><img src="../Images/bcd48bf680e9426cd9269ec92be1cc93.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*5tr6MzxtJZIv_rNcxjgnvA.png"/></div></div></figure><p id="735b" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">我们可以检查数据是如何分布在三个类别中的:</p><pre class="kj kk kl km gt mu mv mw mx aw my bi"><span id="6241" class="lw lx it mv b gy mz na l nb nc">fig, axs = plt.subplots(2, 3, figsize=(14, 7))</span><span id="e96c" class="lw lx it mv b gy nh na l nb nc">sns.histplot(data=df, x="Temperature_c", hue="Description", kde=True, color="skyblue", ax=axs[0, 0])<br/>sns.histplot(data=df, x="Humidity", hue="Description", kde=True, color="skyblue", ax=axs[0, 1])<br/>sns.histplot(data=df, x="Wind_Speed_kmh", hue="Description", kde=True, color="skyblue", ax=axs[0, 2])<br/>sns.histplot(data=df, x="Wind_Bearing_degrees", hue="Description", kde=True, color="skyblue", ax=axs[1, 0])<br/>sns.histplot(data=df, x="Visibility_km", hue="Description", kde=True, color="skyblue", ax=axs[1, 1])<br/>sns.histplot(data=df, x="Pressure_millibars", hue="Description", kde=True, color="skyblue", ax=axs[1, 2])</span><span id="a5c9" class="lw lx it mv b gy nh na l nb nc">plt.show()</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ki"><img src="../Images/43265666d08149285f434c2c12dc16c7.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*9qNIXtvQnOHHBcIEG10vcA.png"/></div></div></figure><p id="6045" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">以及变量如何区分这三个类别:</p><pre class="kj kk kl km gt mu mv mw mx aw my bi"><span id="e3b2" class="lw lx it mv b gy mz na l nb nc">fig, axs = plt.subplots(2, 3, figsize=(14, 7))</span><span id="963b" class="lw lx it mv b gy nh na l nb nc">sns.boxplot(x=df["Description"], y=df["Temperature_c"], ax=axs[0, 0])<br/>sns.boxplot(x=df["Description"], y=df["Humidity"], ax=axs[0, 1])<br/>sns.boxplot(x=df["Description"], y=df["Wind_Speed_kmh"], ax=axs[0, 2])<br/>sns.boxplot(x=df["Description"], y=df["Wind_Bearing_degrees"], ax=axs[1, 0])<br/>sns.boxplot(x=df["Description"], y=df["Visibility_km"], ax=axs[1, 1])<br/>sns.boxplot(x=df["Description"], y=df["Pressure_millibars"], ax=axs[1, 2])</span><span id="812c" class="lw lx it mv b gy nh na l nb nc">plt.show()</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ni"><img src="../Images/cecbd4e747b5004059812308d98dbe6e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*d139pEZ9FBMJdwfLqmzr2w.png"/></div></div></figure><p id="f13e" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">通过目测，<strong class="kw iu">温度_c </strong>和<strong class="kw iu">湿度</strong>似乎是划分三个等级的最佳特征。现在我们可以建立我们的模型了。我们将从创建一个新的<strong class="kw iu"> <em class="ne"> y </em> </strong>变量开始，因为我们已经从之前的二进制分类分析中获得了<strong class="kw iu"> <em class="ne"> X </em> </strong>。</p><pre class="kj kk kl km gt mu mv mw mx aw my bi"><span id="3069" class="lw lx it mv b gy mz na l nb nc">y = df['Description']</span></pre><p id="5eea" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">并再次执行训练和测试数据分割(因为我们有不同的<strong class="kw iu"><em class="ne"/></strong>):</p><pre class="kj kk kl km gt mu mv mw mx aw my bi"><span id="f024" class="lw lx it mv b gy mz na l nb nc">X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20)</span></pre><p id="308d" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">构建和评估模型:</p><pre class="kj kk kl km gt mu mv mw mx aw my bi"><span id="a2e9" class="lw lx it mv b gy mz na l nb nc">LinearSVM = LinearSVC().fit(X_train, y_train)</span><span id="0dfd" class="lw lx it mv b gy nh na l nb nc">print("training set score: %f" % LinearSVM.score(X_train, y_train))<br/>print("test set score: %f" % LinearSVM.score(X_test, y_test))</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi no"><img src="../Images/975bc0ddbdf383a383be53e408aa8787.png" data-original-src="https://miro.medium.com/v2/resize:fit:526/format:webp/1*3KlEzG-cIMj87Iw0VWsQ5g.png"/></div></figure><p id="13a7" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">开箱即用，我们的模型具有良好的性能，训练集的准确率为91%，测试集的准确率为90%。模型没有过度拟合。我们仍然可以用不同的C值测试我们的模型，看看会发生什么:</p><pre class="kj kk kl km gt mu mv mw mx aw my bi"><span id="25dc" class="lw lx it mv b gy mz na l nb nc">#C=100<br/>LinearSVM100 = LinearSVC(C=100).fit(X_train, y_train)</span><span id="9f00" class="lw lx it mv b gy nh na l nb nc">print("training set score: %f" % LinearSVM100.score(X_train, y_train))<br/>print("test set score: %f" % LinearSVM100.score(X_test, y_test))</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi np"><img src="../Images/99755bc3a34f7580b3a86dbe40146b19.png" data-original-src="https://miro.medium.com/v2/resize:fit:508/format:webp/1*MMP3FBK37rkMhvjAuUqEkQ.png"/></div></figure><p id="7b71" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">当C=100时，我们的模型精度下降了大约1%，所以C=100不是更好的选择。</p><pre class="kj kk kl km gt mu mv mw mx aw my bi"><span id="789d" class="lw lx it mv b gy mz na l nb nc">#C=0.01<br/>LinearSVM001 = LinearSVC(C=0.01).fit(X_train, y_train)</span><span id="62a6" class="lw lx it mv b gy nh na l nb nc">print("training set score: %f" % LinearSVM001.score(X_train, y_train))<br/>print("test set score: %f" % LinearSVM001.score(X_test, y_test))</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi nq"><img src="../Images/b1823aef618206f4daff38c3f141e0bc.png" data-original-src="https://miro.medium.com/v2/resize:fit:502/format:webp/1*e_QORTY3YFeVPPwuij83Cw.png"/></div></figure><p id="6bcb" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">当C=0.01时，我们可以看到测试集的准确性有一点提高，所以我们应该使用这个值。现在让我们使用特征<strong class="kw iu">湿度</strong>和<strong class="kw iu">温度_c、</strong>和<strong class="kw iu"> C=0.01 </strong>来构建一个具有决策边界的图形:</p><pre class="kj kk kl km gt mu mv mw mx aw my bi"><span id="a1be" class="lw lx it mv b gy mz na l nb nc">data = pd.read_csv('weather.csv')</span><span id="6f28" class="lw lx it mv b gy nh na l nb nc">def LinearSVM_comparison(data,c):<br/>    x = data[['<strong class="mv iu">Humidity</strong>','<strong class="mv iu">Temperature_c</strong>',]].values<br/>    y = data['Description'].astype(int).values<br/>    LinearSVM_plot = LinearSVC(C=c)<br/>    LinearSVM_plot.fit(x,y)<br/>    print(LinearSVM_plot.score(x,y))<br/>    #Plot decision region:<br/>    plot_decision_regions(x,y, clf=LinearSVM_plot, legend=2)<br/>    #Adding axes annotations:<br/>    plt.xlabel('X_train') <br/>    plt.ylabel('y_train') <br/>    plt.title('Linear SVM with C='+str(c))<br/>    plt.show()</span><span id="eced" class="lw lx it mv b gy nh na l nb nc">LinearSVM_comparison(data,0.01)</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi nr"><img src="../Images/1489544ef377bb4dbea33d9370eb8b23.png" data-original-src="https://miro.medium.com/v2/resize:fit:800/format:webp/1*FoR0DFNeC-ZQ6KVbpm_kgA.png"/></div></figure><p id="d368" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">感谢您的阅读！如果你有建议要添加到这个列表中，请告诉我，不要忘记订阅以接收关于我未来出版物的通知。</p><p id="5aa8" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">如果:你喜欢这篇文章，别忘了关注我，这样你就能收到所有关于新出版物的更新。</p><p id="63b7" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">否则如果:你想了解更多，你可以通过<a class="ae lq" href="https://cdanielaam.medium.com/membership" rel="noopener">我的推荐链接</a>订阅媒体会员。它不会花你更多的钱，但会支付我一杯咖啡。</p><p id="ee17" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">Else:谢谢！</p></div></div>    
</body>
</html>