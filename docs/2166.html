<html>
<head>
<title>10 NeRF Papers You Should Follow-up — Part 1</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">你应该跟进的10篇NeRF论文—第1部分</h1>
<blockquote>原文：<a href="https://pub.towardsai.net/10-nerf-papers-you-should-follow-up-part-1-9566707b8f30?source=collection_archive---------0-----------------------#2021-09-09">https://pub.towardsai.net/10-nerf-papers-you-should-follow-up-part-1-9566707b8f30?source=collection_archive---------0-----------------------#2021-09-09</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><h2 id="a464" class="io ip iq bd b dl ir is it iu iv iw dk ix translated" aria-label="kicker paragraph"><a class="ae ep" href="https://towardsai.net/p/category/computer-vision" rel="noopener ugc nofollow" target="_blank">计算机视觉</a></h2><div class=""/><div class=""><h2 id="088e" class="pw-subtitle-paragraph jw iz iq bd b jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn dk translated">向NeRF研究人员推荐10篇论文。第2部分将很快推出。</h2></div><p id="6811" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">人类通常从眼睛获取大部分信息。计算机视觉已经在许多任务中显示出成功的性能，在处理视觉数据时减少了人工劳动。近年来，视觉渲染已经成为计算机视觉中最热门的领域之一。NeRF是Neural Radiance Fields的缩写，在渲染方面表现出了令人难以置信的性能，在真实场景中实现了可靠而逼真的渲染。对于研究者来说，一篇影响很大的论文，涉及的利益很大；然而，由于变种数量激增，很难跟进。在本文中，我们将深入研究NeRF和后续论文的摘要。本文主要介绍NeRF的变体。这是我的文章中介绍的论文列表。</p><ol class=""><li id="8a13" class="lk ll iq kq b kr ks ku kv kx lm lb ln lf lo lj lp lq lr ls bi translated">NeRF:将场景表示为用于视图合成的神经辐射场</li><li id="439a" class="lk ll iq kq b kr lt ku lu kx lv lb lw lf lx lj lp lq lr ls bi translated">NeRF++分析和改进神经辐射场</li><li id="ec67" class="lk ll iq kq b kr lt ku lu kx lv lb lw lf lx lj lp lq lr ls bi translated">野外的NeRF:无约束照片集的神经辐射场</li><li id="72ca" class="lk ll iq kq b kr lt ku lu kx lv lb lw lf lx lj lp lq lr ls bi translated">NSVF:神经稀疏体素场</li><li id="04fb" class="lk ll iq kq b kr lt ku lu kx lv lb lw lf lx lj lp lq lr ls bi translated">动态场景的神经辐射场</li><li id="5360" class="lk ll iq kq b kr lt ku lu kx lv lb lw lf lx lj lp lq lr ls bi translated">DeRF:分解辐射场</li><li id="f976" class="lk ll iq kq b kr lt ku lu kx lv lb lw lf lx lj lp lq lr ls bi translated">用于实时视图合成的烘焙神经辐射场</li><li id="9a61" class="lk ll iq kq b kr lt ku lu kx lv lb lw lf lx lj lp lq lr ls bi translated">基洛纳夫:用数千个微小的MLP加速神经辐射场</li><li id="46f7" class="lk ll iq kq b kr lt ku lu kx lv lb lw lf lx lj lp lq lr ls bi translated">深度监督的NeRF:更少的视图和更快的免费训练</li><li id="63ab" class="lk ll iq kq b kr lt ku lu kx lv lb lw lf lx lj lp lq lr ls bi translated">自校准神经辐射场</li></ol></div><div class="ab cl ly lz hu ma" role="separator"><span class="mb bw bk mc md me"/><span class="mb bw bk mc md me"/><span class="mb bw bk mc md"/></div><div class="ij ik il im in"><h1 id="b2ff" class="mf mg iq bd mh mi mj mk ml mm mn mo mp kf mq kg mr ki ms kj mt kl mu km mv mw bi translated">1.NeRF:将场景表示为用于视图合成的神经辐射场(第一个NeRF)</h1><figure class="my mz na nb gt nc gh gi paragraph-image"><div role="button" tabindex="0" class="nd ne di nf bf ng"><div class="gh gi mx"><img src="../Images/bed56917cb0ccdae4aaedfcaee692879.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*5Vj-ilABDvi8ZnEyi9lyyQ.png"/></div></div><figcaption class="nj nk gj gh gi nl nm bd b be z dk translated">NeRF建筑插图。</figcaption></figure><p id="a2c1" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">论文链接:【https://arxiv.org/abs/2003.08934】<br/>作者:<a class="ae nn" href="https://arxiv.org/search/cs?searchtype=author&amp;query=Mildenhall%2C+B" rel="noopener ugc nofollow" target="_blank">本·米尔登霍尔</a>，<a class="ae nn" href="https://arxiv.org/search/cs?searchtype=author&amp;query=Srinivasan%2C+P+P" rel="noopener ugc nofollow" target="_blank">普拉图尔·p·斯里尼瓦桑</a>，<a class="ae nn" href="https://arxiv.org/search/cs?searchtype=author&amp;query=Tancik%2C+M" rel="noopener ugc nofollow" target="_blank">马修·坦西克</a>，<a class="ae nn" href="https://arxiv.org/search/cs?searchtype=author&amp;query=Barron%2C+J+T" rel="noopener ugc nofollow" target="_blank">乔纳森·t·巴伦</a>，<a class="ae nn" href="https://arxiv.org/search/cs?searchtype=author&amp;query=Ramamoorthi%2C+R" rel="noopener ugc nofollow" target="_blank">拉维·拉马穆尔蒂</a>，<a class="ae nn" href="https://arxiv.org/search/cs?searchtype=author&amp;query=Ng%2C+R" rel="noopener ugc nofollow" target="_blank">任Ng </a> <br/>大会:ECCV20 <strong class="kq ja">(最佳论文荣誉奖)</strong></p><p id="f9cb" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated"><strong class="kq ja">描述</strong></p><ul class=""><li id="ec49" class="lk ll iq kq b kr ks ku kv kx lm lb ln lf lo lj no lq lr ls bi translated">第一篇论文提出了NeRF架构。他们处理<strong class="kq ja">视图依赖</strong>问题。由于光的属性，例如反射，通过接收观察方向作为输入，对象根据它们的观察方向具有不同的颜色。</li><li id="53f7" class="lk ll iq kq b kr lt ku lu kx lv lb lw lf lx lj no lq lr ls bi translated">给定规范空间中的位置向量和观察方向，网络输出颜色和体积密度。下图显示了网络架构。</li></ul><figure class="my mz na nb gt nc gh gi paragraph-image"><div class="gh gi np"><img src="../Images/a4bb36d679190185151034d7da1661e4.png" data-original-src="https://miro.medium.com/v2/resize:fit:1304/format:webp/1*ygftZNmAxHOVni-aicpJPg.png"/></div></figure><ul class=""><li id="8736" class="lk ll iq kq b kr ks ku kv kx lm lb ln lf lo lj no lq lr ls bi translated">该模型是端到端设计的。对于来自训练图像的每条射线，该模型通过对分层采样的射线中的点的体积密度进行颜色加权求和来呈现射线的颜色。详情建议参考论文。训练目标是每条射线的预测颜色与地面真实颜色的L2差。</li><li id="6247" class="lk ll iq kq b kr lt ku lu kx lv lb lw lf lx lj no lq lr ls bi translated">他们采用了两种稳定有效的训练策略，即<strong class="kq ja">分层体积采样</strong>和<strong class="kq ja">位置编码</strong>。</li></ul><h1 id="42d4" class="mf mg iq bd mh mi nq mk ml mm nr mo mp kf ns kg mr ki nt kj mt kl nu km mv mw bi translated">2.NeRF++分析和改进神经辐射场</h1><figure class="my mz na nb gt nc gh gi paragraph-image"><div class="gh gi nv"><img src="../Images/368645614f5fd0c5e6591cbe69df26f4.png" data-original-src="https://miro.medium.com/v2/resize:fit:962/format:webp/1*G0XJBFlXqbNn3qns10eRpw.png"/></div><figcaption class="nj nk gj gh gi nl nm bd b be z dk translated">反向球面参数化</figcaption></figure><p id="644b" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">论文链接:<a class="ae nn" href="https://arxiv.org/abs/2010.07492" rel="noopener ugc nofollow" target="_blank">https://arxiv.org/abs/2003.08934</a></p><p id="95b7" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated"><strong class="kq ja">描述</strong></p><ul class=""><li id="fd7a" class="lk ll iq kq b kr ks ku kv kx lm lb ln lf lo lj no lq lr ls bi translated"><strong class="kq ja">动机</strong>:原NeRF由于背景深度设置模糊，室外场景渲染困难。换句话说，NeRF无法渲染无界场景。NeRF++通过<strong class="kq ja">分离前景和背景采样</strong>来解决这个问题。</li><li id="6ae6" class="lk ll iq kq b kr lt ku lu kx lv lb lw lf lx lj no lq lr ls bi translated">他们设置单位球来分离场景的前景和背景。<strong class="kq ja">对于前景</strong>中的点，也就是单位球面内的点，<strong class="kq ja">它们遵循与原始NeRF </strong>相同的方法。但是，对于背景中的<strong class="kq ja">点，也就是单位球面外的点，<strong class="kq ja">用其距离</strong>重新参数化坐标。因此，前景网络接收5维输入；然而，背景网络接收6维输入。</strong></li></ul><figure class="my mz na nb gt nc gh gi paragraph-image"><div class="gh gi nw"><img src="../Images/0b03a4d70e80d475e51da86512e113c4.png" data-original-src="https://miro.medium.com/v2/resize:fit:986/format:webp/0*mH0aT6aabrGjsMO-.png"/></div></figure><figure class="my mz na nb gt nc gh gi paragraph-image"><div class="gh gi nx"><img src="../Images/5faee171bad66c7dc4a716e6b6e6bf29.png" data-original-src="https://miro.medium.com/v2/resize:fit:802/format:webp/0*33JMiRCYM5TRY4aQ.png"/></div></figure><h1 id="a1c6" class="mf mg iq bd mh mi nq mk ml mm nr mo mp kf ns kg mr ki nt kj mt kl nu km mv mw bi translated">3.野外的NeRF:无约束照片集的神经辐射场</h1><figure class="my mz na nb gt nc gh gi paragraph-image"><div role="button" tabindex="0" class="nd ne di nf bf ng"><div class="gh gi ny"><img src="../Images/e5f4662eaceee4023ae690e965c61986.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*TGjnARY1YdZfkTiT70A5eA.png"/></div></div></figure><p id="c935" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">论文链接:<a class="ae nn" href="https://arxiv.org/abs/2008.02268" rel="noopener ugc nofollow" target="_blank">https://arxiv.org/abs/2008.02268</a><br/>作者:<a class="ae nn" href="https://arxiv.org/search/cs?searchtype=author&amp;query=Martin-Brualla%2C+R" rel="noopener ugc nofollow" target="_blank">里卡多·马丁-布鲁阿拉</a>，<a class="ae nn" href="https://arxiv.org/search/cs?searchtype=author&amp;query=Radwan%2C+N" rel="noopener ugc nofollow" target="_blank">诺哈·拉德万</a>，<a class="ae nn" href="https://arxiv.org/search/cs?searchtype=author&amp;query=Sajjadi%2C+M+S+M" rel="noopener ugc nofollow" target="_blank">迈赫迪·s·m·萨贾迪</a>，<a class="ae nn" href="https://arxiv.org/search/cs?searchtype=author&amp;query=Barron%2C+J+T" rel="noopener ugc nofollow" target="_blank">乔纳森·t·巴伦</a>，<a class="ae nn" href="https://arxiv.org/search/cs?searchtype=author&amp;query=Dosovitskiy%2C+A" rel="noopener ugc nofollow" target="_blank">阿列克谢·多索维茨基</a>，<a class="ae nn" href="https://arxiv.org/search/cs?searchtype=author&amp;query=Duckworth%2C+D" rel="noopener ugc nofollow" target="_blank">丹尼尔·杜克沃斯</a> <br/>大会:CVPR20口述</p><p id="bc08" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated"><strong class="kq ja">描述</strong></p><ul class=""><li id="bcdb" class="lk ll iq kq b kr ks ku kv kx lm lb ln lf lo lj no lq lr ls bi translated"><strong class="kq ja">动机</strong>:虽然NeRF极大地影响了渲染任务，但是它需要在静态条件下捕获的图像集合，可以忽略的光照变化，以及场景中没有瞬态对象。相比之下，NeRF-W能够从<strong class="kq ja">不受约束的照片集中进行可靠的渲染，尤其是从互联网</strong>上收集的照片。</li><li id="5407" class="lk ll iq kq b kr lt ku lu kx lv lb lw lf lx lj no lq lr ls bi translated">所提出的模型在渲染过程中分离了<strong class="kq ja">静态</strong>和<strong class="kq ja">瞬态</strong>对象。由于瞬态物体在不同场景中不一定位于它们当前的姿态，它们的模型计算光线的<strong class="kq ja">不确定性</strong>。然后，基于计算的不确定性，他们的模型较少关注具有高不确定性的射线。</li><li id="a5cc" class="lk ll iq kq b kr lt ku lu kx lv lb lw lf lx lj no lq lr ls bi translated">在我个人看来，在无约束的照片集上定义一个评价指标是一个具有挑战性和争议性的问题。本文很好地提出了一个具有令人信服的直觉的评价指标。要了解更多信息，我强烈推荐阅读这篇文章。</li></ul><h1 id="a189" class="mf mg iq bd mh mi nq mk ml mm nr mo mp kf ns kg mr ki nt kj mt kl nu km mv mw bi translated">4.NSVF:神经稀疏体素场</h1><figure class="my mz na nb gt nc gh gi paragraph-image"><div role="button" tabindex="0" class="nd ne di nf bf ng"><div class="gh gi nz"><img src="../Images/989c907d0026da57e55370c0f0c05732.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*Sitz1FcdlgBqjDjD.png"/></div></div></figure><p id="bc14" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">论文链接:<a class="ae nn" href="https://arxiv.org/pdf/2007.11571.pdf" rel="noopener ugc nofollow" target="_blank"/><br/>作者:<a class="ae nn" href="https://arxiv.org/search/cs?searchtype=author&amp;query=Liu%2C+L" rel="noopener ugc nofollow" target="_blank">刘凌杰</a>，<a class="ae nn" href="https://arxiv.org/search/cs?searchtype=author&amp;query=Gu%2C+J" rel="noopener ugc nofollow" target="_blank">顾</a>，<a class="ae nn" href="https://arxiv.org/search/cs?searchtype=author&amp;query=Lin%2C+K+Z" rel="noopener ugc nofollow" target="_blank">蔡卓琳</a>，<a class="ae nn" href="https://arxiv.org/search/cs?searchtype=author&amp;query=Chua%2C+T" rel="noopener ugc nofollow" target="_blank">蔡达生</a>，<a class="ae nn" href="https://arxiv.org/search/cs?searchtype=author&amp;query=Theobalt%2C+C" rel="noopener ugc nofollow" target="_blank"> Christian Theobalt </a> <br/>发布会:NeurIPS20(聚焦)</p><p id="892d" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated"><strong class="kq ja">描述</strong></p><ul class=""><li id="5e3e" class="lk ll iq kq b kr ks ku kv kx lm lb ln lf lo lj no lq lr ls bi translated"><strong class="kq ja">动机</strong>:提高推理时间是NeRF应该克服的一个关键挑战。他们指出，当累积的alpha值几乎为1时，光线中的最后一个点是不必要的。此外，对于正则空间中体积密度较小的部分，我们可以省略渲染。作者在各种数据集上实验性地展示了他们的灵感。</li><li id="52f8" class="lk ll iq kq b kr lt ku lu kx lv lb lw lf lx lj no lq lr ls bi translated">从大的体素尺寸开始，所提出的模型<strong class="kq ja">修剪体积密度低于某个阈值</strong>的体素。然后，它减少体素的大小。重复上述过程，他们获得具有小体素尺寸的体素八叉树。在推理时间内，当一个点位于修剪后的体素 l内时，他们跳过渲染该点。此外，他们采用早期光线终止，当累积的alpha值高于阈值时，该终止会忽略渲染。</li><li id="af68" class="lk ll iq kq b kr lt ku lu kx lv lb lw lf lx lj no lq lr ls bi translated">写得很好的论文。这里的想法鼓励了未来的工作，以改善NeRF的推理时间。</li></ul><h1 id="0947" class="mf mg iq bd mh mi nq mk ml mm nr mo mp kf ns kg mr ki nt kj mt kl nu km mv mw bi translated">5.动态场景的神经辐射场</h1><figure class="my mz na nb gt nc gh gi paragraph-image"><div role="button" tabindex="0" class="nd ne di nf bf ng"><div class="gh gi oa"><img src="../Images/0725864e730d633f4a8d9875a9f498d3.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*t4Cg_U8skN0t11iXXPP8RQ.png"/></div></div></figure><p id="50ea" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">论文链接:<a class="ae nn" href="https://arxiv.org/abs/2011.13961" rel="noopener ugc nofollow" target="_blank">https://arxiv.org/abs/2011.13961</a><br/>作者:<a class="ae nn" href="https://arxiv.org/search/cs?searchtype=author&amp;query=Pumarola%2C+A" rel="noopener ugc nofollow" target="_blank">阿尔伯特</a>、<a class="ae nn" href="https://arxiv.org/search/cs?searchtype=author&amp;query=Corona%2C+E" rel="noopener ugc nofollow" target="_blank">恩里克</a>、<a class="ae nn" href="https://arxiv.org/search/cs?searchtype=author&amp;query=Pons-Moll%2C+G" rel="noopener ugc nofollow" target="_blank">杰拉德【庞斯-莫尔】、</a><a class="ae nn" href="https://arxiv.org/search/cs?searchtype=author&amp;query=Moreno-Noguer%2C+F" rel="noopener ugc nofollow" target="_blank">弗朗切斯克</a>、<br/>大会:CVPR21</p><p id="66a9" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated"><strong class="kq ja">描述</strong></p><ul class=""><li id="9adc" class="lk ll iq kq b kr ks ku kv kx lm lb ln lf lo lj no lq lr ls bi translated"><strong class="kq ja">动机</strong> : D-NeRF实现了动态场景的渲染。所提出的模型对于每个时间戳只需要一个视图，这表明它非常适用于真实世界的渲染。</li><li id="3f1c" class="lk ll iq kq b kr lt ku lu kx lv lb lw lf lx lj no lq lr ls bi translated">想法很简单。他们添加了一个名为<strong class="kq ja">的变形网络</strong>，预测某个地点在特定时间的位置差。利用变形网络的估计位置，规范网络预测颜色和体积密度。</li></ul><figure class="my mz na nb gt nc gh gi paragraph-image"><div class="gh gi ob"><img src="../Images/cd75eb3fafff0bd2247ad7fdabd393e1.png" data-original-src="https://miro.medium.com/v2/resize:fit:626/format:webp/1*zQtVS-VQfH2R-r95NNWxSQ.png"/></div></figure><ul class=""><li id="e831" class="lk ll iq kq b kr ks ku kv kx lm lb ln lf lo lj no lq lr ls bi translated">这个想法简单而直观。这项工作是有意义的，因为它能够为每个时间戳提供单一视图的视频。我希望很快D-NeRF的变体能够渲染包含背景的真实世界场景。</li></ul><h1 id="4454" class="mf mg iq bd mh mi nq mk ml mm nr mo mp kf ns kg mr ki nt kj mt kl nu km mv mw bi translated">6.DeRF:分解的神经辐射场</h1><figure class="my mz na nb gt nc gh gi paragraph-image"><div class="gh gi oc"><img src="../Images/38ba9a4ece73c63c527413da62fffbff.png" data-original-src="https://miro.medium.com/v2/resize:fit:916/format:webp/0*eQTbX6-6ArdAzRI0.png"/></div></figure><p id="e0a8" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">论文链接:【https://arxiv.org/abs/2011.13961】<br/>作者:<a class="ae nn" href="https://arxiv.org/search/cs?searchtype=author&amp;query=Rebain%2C+D" rel="noopener ugc nofollow" target="_blank">丹尼尔·热班</a><a class="ae nn" href="https://arxiv.org/search/cs?searchtype=author&amp;query=Jiang%2C+W" rel="noopener ugc nofollow" target="_blank">姜维</a><a class="ae nn" href="https://arxiv.org/search/cs?searchtype=author&amp;query=Yazdani%2C+S" rel="noopener ugc nofollow" target="_blank">索罗什·亚兹达尼</a><a class="ae nn" href="https://arxiv.org/search/cs?searchtype=author&amp;query=Li%2C+K" rel="noopener ugc nofollow" target="_blank">李柯</a><a class="ae nn" href="https://arxiv.org/search/cs?searchtype=author&amp;query=Yi%2C+K+M" rel="noopener ugc nofollow" target="_blank">光武义</a><a class="ae nn" href="https://arxiv.org/search/cs?searchtype=author&amp;query=Tagliasacchi%2C+A" rel="noopener ugc nofollow" target="_blank">安德里亚·塔利亚萨基</a> <br/>发布会:CVPR21</p><p id="b281" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated"><strong class="kq ja">描述</strong></p><ul class=""><li id="0d2d" class="lk ll iq kq b kr ks ku kv kx lm lb ln lf lo lj no lq lr ls bi translated"><strong class="kq ja">动机</strong>:转发一个大型MLP网络比转发多个小型MLP网络需要更大的计算预算。通过将场景分解成多个MLP网络，他们减少了渲染过程中的计算量。</li><li id="ffae" class="lk ll iq kq b kr lt ku lu kx lv lb lw lf lx lj no lq lr ls bi translated">当在特定的3D点中渲染颜色和体积密度时，他们明确地学习每个MLP的重要性。关于l1到计算的距离参数，他们对来自每个MLP网络的渲染颜色进行加权。</li><li id="1936" class="lk ll iq kq b kr lt ku lu kx lv lb lw lf lx lj no lq lr ls bi translated">使用<strong class="kq ja">画师算法</strong>，模型从<strong class="kq ja">向后到</strong>渲染到外部缓冲区。</li></ul><h1 id="9507" class="mf mg iq bd mh mi nq mk ml mm nr mo mp kf ns kg mr ki nt kj mt kl nu km mv mw bi translated">7.用于实时视图合成的烘焙神经渲染场</h1><figure class="my mz na nb gt nc gh gi paragraph-image"><div role="button" tabindex="0" class="nd ne di nf bf ng"><div class="gh gi od"><img src="../Images/472fb14414e5809330150694adc86eb4.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*K62U3nvSPQeJqRgH9EJM2w.png"/></div></div></figure><p id="2402" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">论文链接:<a class="ae nn" href="https://arxiv.org/abs/2103.14645" rel="noopener ugc nofollow" target="_blank">https://arxiv.org/abs/2011.13961</a><br/>作者:<a class="ae nn" href="https://arxiv.org/search/cs?searchtype=author&amp;query=Hedman%2C+P" rel="noopener ugc nofollow" target="_blank">彼得·海德曼</a>，<a class="ae nn" href="https://arxiv.org/search/cs?searchtype=author&amp;query=Srinivasan%2C+P+P" rel="noopener ugc nofollow" target="_blank">普拉图尔·p·斯里尼瓦桑</a>，<a class="ae nn" href="https://arxiv.org/search/cs?searchtype=author&amp;query=Mildenhall%2C+B" rel="noopener ugc nofollow" target="_blank">本·米尔登霍尔</a>，<a class="ae nn" href="https://arxiv.org/search/cs?searchtype=author&amp;query=Barron%2C+J+T" rel="noopener ugc nofollow" target="_blank">乔纳森·t·巴伦</a>，<a class="ae nn" href="https://arxiv.org/search/cs?searchtype=author&amp;query=Debevec%2C+P" rel="noopener ugc nofollow" target="_blank">保罗·德贝维奇</a> <br/>会议:ICCV21</p><p id="0c04" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated"><strong class="kq ja">描述</strong></p><ul class=""><li id="3af5" class="lk ll iq kq b kr ks ku kv kx lm lb ln lf lo lj no lq lr ls bi translated"><strong class="kq ja">动机</strong>:尽管NeRF的许多变种都提高了推理时间，但实现实时渲染仍然具有挑战性。通过分离<strong class="kq ja">镜面颜色</strong>和<strong class="kq ja">阿尔法合成颜色</strong>，它们在保持渲染质量的同时，最大限度地减少了推理时间内的计算。</li><li id="a085" class="lk ll iq kq b kr lt ku lu kx lv lb lw lf lx lj no lq lr ls bi translated">作者提出了被称为<strong class="kq ja">镜面特征</strong>的特征，其隐含地编码视点相关的颜色，即<strong class="kq ja">镜面颜色</strong>。此外，从经过训练的NeRF网络中，他们基于3D规范空间中的估计体积密度生成<strong class="kq ja">稀疏体素网格</strong>。</li><li id="5543" class="lk ll iq kq b kr lt ku lu kx lv lb lw lf lx lj no lq lr ls bi translated">将生成的稀疏体素网格的颜色存储到纹理图谱中，在<strong class="kq ja"> </strong>推理时间内<strong class="kq ja">跳过渲染</strong>。最终，在推断时间内唯一需要计算的是一个微小的MLP网络渲染的视图相关颜色。</li></ul><h1 id="bc4c" class="mf mg iq bd mh mi nq mk ml mm nr mo mp kf ns kg mr ki nt kj mt kl nu km mv mw bi translated">8.基洛纳夫:用数千兆像素加速神经辐射场</h1><figure class="my mz na nb gt nc gh gi paragraph-image"><div class="gh gi oe"><img src="../Images/19e20080dcab6609e9b2d6c469a86501.png" data-original-src="https://miro.medium.com/v2/resize:fit:1070/format:webp/1*x2aRxxuwFKERz-gApN7Xfg.png"/></div></figure><p id="2e2d" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">论文链接:<a class="ae nn" href="https://arxiv.org/abs/2103.13744" rel="noopener ugc nofollow" target="_blank"/><br/>作者:<a class="ae nn" href="https://arxiv.org/search/cs?searchtype=author&amp;query=Reiser%2C+C" rel="noopener ugc nofollow" target="_blank">克里斯蒂安·赖泽</a>，<a class="ae nn" href="https://arxiv.org/search/cs?searchtype=author&amp;query=Peng%2C+S" rel="noopener ugc nofollow" target="_blank">宋有朋</a>，<a class="ae nn" href="https://arxiv.org/search/cs?searchtype=author&amp;query=Liao%2C+Y" rel="noopener ugc nofollow" target="_blank">伊一·廖</a>，<a class="ae nn" href="https://arxiv.org/search/cs?searchtype=author&amp;query=Geiger%2C+A" rel="noopener ugc nofollow" target="_blank">安德里亚斯·盖格</a> <br/>会议:ICCV21</p><p id="5802" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated"><strong class="kq ja">描述</strong></p><ul class=""><li id="d028" class="lk ll iq kq b kr ks ku kv kx lm lb ln lf lo lj no lq lr ls bi translated"><strong class="kq ja">动机</strong>:动机类似于“DeRF:分解神经辐射场”的动机。所提出的算法首先用成千上万个小得多的网络划分规范空间。</li><li id="d9bf" class="lk ll iq kq b kr lt ku lu kx lv lb lw lf lx lj no lq lr ls bi translated">将训练好的香草神经纤维网络设置为教师模型，他们<strong class="kq ja">将教师模型提炼为多个网络</strong>。为了选择合适的网络，他们定义了一个映射函数。简单地提取教师网络无法生成可靠的场景。因此，他们将<strong class="kq ja"> L2正则化</strong>应用于网络最后两层的权重和偏差。</li></ul><h1 id="9da2" class="mf mg iq bd mh mi nq mk ml mm nr mo mp kf ns kg mr ki nt kj mt kl nu km mv mw bi translated">9.深度监督的NeRF:更少的视图和更快的免费训练</h1><figure class="my mz na nb gt nc gh gi paragraph-image"><div role="button" tabindex="0" class="nd ne di nf bf ng"><div class="gh gi of"><img src="../Images/09ec63ebe5a592c9256c205463971a28.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*iiuOkf8cRJBA1qZR0wNggw.png"/></div></div></figure><p id="e114" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">论文链接:<a class="ae nn" href="https://arxiv.org/abs/2107.02791" rel="noopener ugc nofollow" target="_blank"/><br/>作者:<a class="ae nn" href="https://arxiv.org/search/cs?searchtype=author&amp;query=Deng%2C+K" rel="noopener ugc nofollow" target="_blank">乐康</a>，<a class="ae nn" href="https://arxiv.org/search/cs?searchtype=author&amp;query=Liu%2C+A" rel="noopener ugc nofollow" target="_blank">廖骏伦</a>，<a class="ae nn" href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zhu%2C+J" rel="noopener ugc nofollow" target="_blank">朱俊彦</a>，<a class="ae nn" href="https://arxiv.org/search/cs?searchtype=author&amp;query=Ramanan%2C+D" rel="noopener ugc nofollow" target="_blank">提婆拉玛南</a> <br/>会议:ICCV21</p><p id="1113" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated"><strong class="kq ja">描述</strong></p><ul class=""><li id="1e29" class="lk ll iq kq b kr ks ku kv kx lm lb ln lf lo lj no lq lr ls bi translated"><strong class="kq ja">动机</strong> : NeRF需要一组图像和图像对应的相机姿态。在一般的SfM中，相机姿态是用深度值来估计的。但是，NeRF会忽略估计的深度值。作者认为来自深度值的<strong class="kq ja">监督有利于NeRF </strong>学习<strong class="kq ja">精确的体积密度</strong>，从而产生更好的渲染精度。</li><li id="cde0" class="lk ll iq kq b kr lt ku lu kx lv lb lw lf lx lj no lq lr ls bi translated">通过训练的体积密度，他们可以估计每条射线的深度。他们提出的深度损失的目标是通过附加的显式损失项来学习精确的深度值。</li></ul><h1 id="9dcb" class="mf mg iq bd mh mi nq mk ml mm nr mo mp kf ns kg mr ki nt kj mt kl nu km mv mw bi translated">10.自校准神经辐射场</h1><figure class="my mz na nb gt nc gh gi paragraph-image"><div role="button" tabindex="0" class="nd ne di nf bf ng"><div class="gh gi og"><img src="../Images/9ac095774f8e47761110013a6065c02c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*negu3ZGFreldk7NtGLtWNQ.png"/></div></div></figure><p id="652a" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">论文链接:<a class="ae nn" href="https://arxiv.org/abs/2108.13826" rel="noopener ugc nofollow" target="_blank">https://arxiv.org/abs/2011.13961</a><br/>作者:<a class="ae nn" href="https://arxiv.org/search/cs?searchtype=author&amp;query=Jeong%2C+Y" rel="noopener ugc nofollow" target="_blank">郑允佑</a>，<a class="ae nn" href="https://arxiv.org/search/cs?searchtype=author&amp;query=Ahn%2C+S" rel="noopener ugc nofollow" target="_blank">安雪君</a>，<a class="ae nn" href="https://arxiv.org/search/cs?searchtype=author&amp;query=Choy%2C+C" rel="noopener ugc nofollow" target="_blank">蔡克明</a>，<a class="ae nn" href="https://arxiv.org/search/cs?searchtype=author&amp;query=Anandkumar%2C+A" rel="noopener ugc nofollow" target="_blank"> Animashree Anandkumar </a>，<a class="ae nn" href="https://arxiv.org/search/cs?searchtype=author&amp;query=Cho%2C+M" rel="noopener ugc nofollow" target="_blank">苏民町</a>，<a class="ae nn" href="https://arxiv.org/search/cs?searchtype=author&amp;query=Park%2C+J" rel="noopener ugc nofollow" target="_blank">宰植公园</a> <br/>会议:ICCV21</p><p id="3e35" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated"><strong class="kq ja">描述</strong></p><ul class=""><li id="0f02" class="lk ll iq kq b kr ks ku kv kx lm lb ln lf lo lj no lq lr ls bi translated"><strong class="kq ja">动机</strong>:一般NeRF框架假设使用COLMAP估计的相机信息足够准确。由于NeRF的目标是使网络过度适应场景，因此估计的相机信息的准确性至关重要。</li><li id="5fdf" class="lk ll iq kq b kr lt ku lu kx lv lb lw lf lx lj no lq lr ls bi translated">作者提出了一个扩展的相机模型来反映相机中的复杂噪声。通过<strong class="kq ja">联合优化相机和NeRF参数</strong>，SCNeRF无需仔细校准相机信息即可进行渲染。此外，该算法产生了比普通NeRF和NeRF++更好的渲染质量。</li></ul><p id="b368" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">我们很快会带着第二部分的附加论文回来。如果文章有益有趣，请关注我的个人账户。<br/>LinkedIn:<a class="ae nn" href="https://www.linkedin.com/in/yoonwoo-jeong-6994ab185/" rel="noopener ugc nofollow" target="_blank">https://www.linkedin.com/in/yoonwoo-jeong-6994ab185/</a><br/>GitHub:<a class="ae nn" href="https://github.com/jeongyw12382?tab=repositories" rel="noopener ugc nofollow" target="_blank">https://github.com/jeongyw12382</a><br/>邮件:jyw123822@gmail.com</p></div></div>    
</body>
</html>