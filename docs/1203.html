<html>
<head>
<title>Convolutional Neural Networks (CNNs) Tutorial with Python</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">Python卷积神经网络(CNN)教程</h1>
<blockquote>原文：<a href="https://pub.towardsai.net/convolutional-neural-networks-cnns-tutorial-with-python-417c29f0403f?source=collection_archive---------0-----------------------#2020-12-02">https://pub.towardsai.net/convolutional-neural-networks-cnns-tutorial-with-python-417c29f0403f?source=collection_archive---------0-----------------------#2020-12-02</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><figure class="is it gp gr iu iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi ir"><img src="../Images/0f96eb650f6b81f642cd33c3690279f0.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*fr3B59VjWL9by2DA.png"/></div></div><figcaption class="jc jd gj gh gi je jf bd b be z dk translated">来源:<a class="ae jg" href="https://pixabay.com/photos/neural-networks-brain-5321301/" rel="noopener ugc nofollow" target="_blank"> Pixabay </a></figcaption></figure><h2 id="63c9" class="jh ji jj bd b dl jk jl jm jn jo jp dk jq translated" aria-label="kicker paragraph"><a class="ae ep" href="https://towardsai.net/p/category/machine-learning/deep-learning" rel="noopener ugc nofollow" target="_blank">深度学习</a>、<a class="ae ep" href="https://towardsai.net/p/category/editorial" rel="noopener ugc nofollow" target="_blank">编辑</a>、<a class="ae ep" href="https://towardsai.net/p/category/programming" rel="noopener ugc nofollow" target="_blank">编程</a></h2><div class=""/><div class=""><h2 id="7058" class="pw-subtitle-paragraph kp js jj bd b kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg dk translated">关于使用Python的卷积神经网络(CNN)的深入教程</h2></div><p id="cdc5" class="pw-post-body-paragraph lh li jj lj b lk ll kt lm ln lo kw lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">最后更新，2021年1月8日</p><p id="4a50" class="pw-post-body-paragraph lh li jj lj b lk ll kt lm ln lo kw lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated"><strong class="lj jt">作者:</strong>萨妮娅·帕维斯，<a class="ae jg" href="https://mktg.best/vguzs" rel="noopener ugc nofollow" target="_blank">罗伯托·伊里翁多</a></p><div class="is it gp gr iu md"><a href="https://members.towardsai.net/" rel="noopener  ugc nofollow" target="_blank"><div class="me ab fo"><div class="mf ab mg cl cj mh"><h2 class="bd jt gy z fp mi fr fs mj fu fw js bi translated">加入我们吧↓ |面向人工智能成员|数据驱动的社区</h2><div class="mk l"><h3 class="bd b gy z fp mi fr fs mj fu fw dk translated">加入人工智能，成为会员，你将不仅支持人工智能，但你将有机会…</h3></div><div class="ml l"><p class="bd b dl z fp mi fr fs mj fu fw dk translated">members.towardsai.net</p></div></div><div class="mm l"><div class="mn l mo mp mq mm mr ja md"/></div></div></a></div><p id="364a" class="pw-post-body-paragraph lh li jj lj b lk ll kt lm ln lo kw lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated"><strong class="lj jt">本教程的代码可在</strong><a class="ae jg" href="https://github.com/towardsai/tutorials/tree/master/convolutional-neural-networks-python" rel="noopener ugc nofollow" target="_blank"><strong class="lj jt">Github</strong></a><strong class="lj jt">上获得，其完整实现也可在</strong><a class="ae jg" href="https://colab.research.google.com/drive/1OLBEe0LwK9DcyzInOSDBmPp_Z5udLyqI?usp=sharing" rel="noopener ugc nofollow" target="_blank"><strong class="lj jt">Google Colab</strong></a><strong class="lj jt">上获得。</strong></p><h2 id="bfd9" class="ms mt jj bd mu mv mw dn mx my mz dp na lq nb nc nd lu ne nf ng ly nh ni nj jp bi translated">目录</h2><ol class=""><li id="dd17" class="nk nl jj lj b lk nm ln nn lq no lu np ly nq mc nr ns nt nu bi translated"><a class="ae jg" href="#124c" rel="noopener ugc nofollow">简介</a></li><li id="098c" class="nk nl jj lj b lk nv ln nw lq nx lu ny ly nz mc nr ns nt nu bi translated"><a class="ae jg" href="#e8a2" rel="noopener ugc nofollow">网络架构</a></li><li id="bfec" class="nk nl jj lj b lk nv ln nw lq nx lu ny ly nz mc nr ns nt nu bi translated"><a class="ae jg" href="#a889" rel="noopener ugc nofollow">卷积</a></li><li id="f5c4" class="nk nl jj lj b lk nv ln nw lq nx lu ny ly nz mc nr ns nt nu bi translated"><a class="ae jg" href="#5f95" rel="noopener ugc nofollow">卷积层</a></li><li id="3fe9" class="nk nl jj lj b lk nv ln nw lq nx lu ny ly nz mc nr ns nt nu bi translated"><a class="ae jg" href="#d143" rel="noopener ugc nofollow">汇集层/子采样层</a></li><li id="92f5" class="nk nl jj lj b lk nv ln nw lq nx lu ny ly nz mc nr ns nt nu bi translated"><a class="ae jg" href="#9deb" rel="noopener ugc nofollow">跨步</a></li><li id="c19a" class="nk nl jj lj b lk nv ln nw lq nx lu ny ly nz mc nr ns nt nu bi translated"><a class="ae jg" href="#78ff" rel="noopener ugc nofollow">全连接层</a></li><li id="9555" class="nk nl jj lj b lk nv ln nw lq nx lu ny ly nz mc nr ns nt nu bi translated"><a class="ae jg" href="#48df" rel="noopener ugc nofollow">非线性层</a></li><li id="f27a" class="nk nl jj lj b lk nv ln nw lq nx lu ny ly nz mc nr ns nt nu bi translated"><a class="ae jg" href="#c55c" rel="noopener ugc nofollow">卷积神经网络的Python实现</a></li><li id="7d71" class="nk nl jj lj b lk nv ln nw lq nx lu ny ly nz mc nr ns nt nu bi translated"><a class="ae jg" href="#14b9" rel="noopener ugc nofollow">CNN的超参数</a></li><li id="9981" class="nk nl jj lj b lk nv ln nw lq nx lu ny ly nz mc nr ns nt nu bi translated"><a class="ae jg" href="#0703" rel="noopener ugc nofollow">CNN中的正则化方法</a></li><li id="790b" class="nk nl jj lj b lk nv ln nw lq nx lu ny ly nz mc nr ns nt nu bi translated"><a class="ae jg" href="#d39a" rel="noopener ugc nofollow">结论</a></li><li id="994c" class="nk nl jj lj b lk nv ln nw lq nx lu ny ly nz mc nr ns nt nu bi translated"><a class="ae jg" href="#c6be" rel="noopener ugc nofollow">资源</a></li><li id="fce1" class="nk nl jj lj b lk nv ln nw lq nx lu ny ly nz mc nr ns nt nu bi translated"><a class="ae jg" href="#ee0b" rel="noopener ugc nofollow">参考文献</a></li></ol><blockquote class="oa"><p id="e93b" class="ob oc jj bd od oe of og oh oi oj mc dk translated">📚查看我们对<a class="ae jg" href="https://towardsai.net/p/machine-learning/best-machine-learning-books-free-and-paid-ml-book-recommendations-40c9ab30b0c" rel="noopener ugc nofollow" target="_blank">最佳机器学习书籍</a>的编辑推荐。📚</p></blockquote></div><div class="ab cl ok ol hx om" role="separator"><span class="on bw bk oo op oq"/><span class="on bw bk oo op oq"/><span class="on bw bk oo op"/></div><div class="im in io ip iq"><h1 id="124c" class="or mt jj bd mu os ot ou mx ov ow ox na ky oy kz nd lb oz lc ng le pa lf nj pb bi translated">介绍</h1><p id="62fa" class="pw-post-body-paragraph lh li jj lj b lk nm kt lm ln nn kw lp lq pc ls lt lu pd lw lx ly pe ma mb mc im bi translated"><a class="ae jg" href="http://yann.lecun.com/" rel="noopener ugc nofollow" target="_blank"><strong class="lj jt">Yann le Cun</strong></a><strong class="lj jt"/>和<a class="ae jg" href="https://yoshuabengio.org/" rel="noopener ugc nofollow" target="_blank"> <strong class="lj jt"> Yoshua Bengio </strong> </a>于1995年推出卷积神经网络[ <a class="ae jg" href="https://www.researchgate.net/profile/Yann_Lecun/publication/2453996_Convolutional_Networks_for_Images_Speech_and_Time-Series/links/0deec519dfa2325502000000.pdf" rel="noopener ugc nofollow" target="_blank"> 1 </a> ]，也称为卷积网络或CNN。CNN是一种特殊的多层神经网络[ <a class="ae jg" href="https://doi.org/10.3390/sym12050803" rel="noopener ugc nofollow" target="_blank"> 2 </a> ]，以明显的网格状拓扑结构处理数据。它的网络基础基于一种叫做<strong class="lj jt">卷积</strong>的数学运算。从根本上说，<a class="ae jg" href="https://mld.ai/mldcmu" rel="noopener ugc nofollow" target="_blank"> <strong class="lj jt">机器学习</strong> </a>算法使用矩阵乘法，但相比之下，CNN至少在一层中使用卷积来代替矩阵乘法——卷积是一种特殊的线性运算。</p><p id="fe27" class="pw-post-body-paragraph lh li jj lj b lk ll kt lm ln lo kw lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">卷积神经网络(CNN)无疑是最受欢迎的深度学习架构。它们的应用无处不在，包括图像和视频识别、图像分析、推荐系统、自然语言处理、计算接口、金融时间序列以及其他一些应用。</p><p id="62c4" class="pw-post-body-paragraph lh li jj lj b lk ll kt lm ln lo kw lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">生物学发现激发了具有以下标准能力的神经网络的发展:</p><p id="33f6" class="pw-post-body-paragraph lh li jj lj b lk ll kt lm ln lo kw lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated"><strong class="lj jt">输入→权重→逻辑功能→输出</strong></p><p id="6f49" class="pw-post-body-paragraph lh li jj lj b lk ll kt lm ln lo kw lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">关于CNN的基本事实:</p><ul class=""><li id="2f95" class="nk nl jj lj b lk ll ln lo lq pf lu pg ly ph mc pi ns nt nu bi translated">CNN是由视觉皮层中的局部敏感和方向选择性神经细胞的发现在神经生物学上驱动的。</li><li id="d848" class="nk nl jj lj b lk nv ln nw lq nx lu ny ly nz mc pi ns nt nu bi translated">它们是一个多层神经网络。</li><li id="e57b" class="nk nl jj lj b lk nv ln nw lq nx lu ny ly nz mc pi ns nt nu bi translated">它们隐含地提取相关特征。</li><li id="4f60" class="nk nl jj lj b lk nv ln nw lq nx lu ny ly nz mc pi ns nt nu bi translated">它们是一个前馈网络，可以从图像中提取拓扑特征。</li><li id="419a" class="nk nl jj lj b lk nv ln nw lq nx lu ny ly nz mc pi ns nt nu bi translated">它们通过最少的预处理直接从像素图像中识别视觉模式。</li><li id="b23e" class="nk nl jj lj b lk nv ln nw lq nx lu ny ly nz mc pi ns nt nu bi translated">它们惊人地强大，因为它们可以很容易地识别具有极端可变性的模式。例如手写。</li><li id="f4f4" class="nk nl jj lj b lk nv ln nw lq nx lu ny ly nz mc pi ns nt nu bi translated">用一种反向传播算法来训练CNN。</li><li id="e48c" class="nk nl jj lj b lk nv ln nw lq nx lu ny ly nz mc pi ns nt nu bi translated">CNN在视觉皮层中具有神经元细胞，构成了CNN背后的基础，并监视特定的特征。</li></ul><h2 id="4660" class="ms mt jj bd mu mv mw dn mx my mz dp na lq nb nc nd lu ne nf ng ly nh ni nj jp bi translated">为什么需要CNN？</h2><p id="ded6" class="pw-post-body-paragraph lh li jj lj b lk nm kt lm ln nn kw lp lq pc ls lt lu pd lw lx ly pe ma mb mc im bi translated">对于图像识别和其他应用，CNN有几个优点，例如:</p><ul class=""><li id="93db" class="nk nl jj lj b lk ll ln lo lq pf lu pg ly ph mc pi ns nt nu bi translated">使用CNN的检测对于像由于相机镜头、不同照明条件、不同姿势、部分遮挡的存在、水平和垂直移动等引起的形状变化这样的失真是鲁棒的。</li><li id="c864" class="nk nl jj lj b lk nv ln nw lq nx lu ny ly nz mc pi ns nt nu bi translated">它需要更少的内存来处理和执行。</li><li id="283d" class="nk nl jj lj b lk nv ln nw lq nx lu ny ly nz mc pi ns nt nu bi translated">很直白，适合训练。通过使用CNN，我们可以显著减少参数的数量。因此，培训时间也相应减少。</li></ul><h2 id="a547" class="ms mt jj bd mu mv mw dn mx my mz dp na lq nb nc nd lu ne nf ng ly nh ni nj jp bi translated">卷积神经网络的类型</h2><p id="1543" class="pw-post-body-paragraph lh li jj lj b lk nm kt lm ln nn kw lp lq pc ls lt lu pd lw lx ly pe ma mb mc im bi translated">以下是一些不同类型的CNN:</p><ul class=""><li id="8bf5" class="nk nl jj lj b lk ll ln lo lq pf lu pg ly ph mc pi ns nt nu bi translated"><strong class="lj jt"> 1D CNN → </strong>在这种情况下，内核向一个方向移动。1D CNN的输入和输出数据是二维的。1D CNN主要用于时间序列。</li><li id="9c64" class="nk nl jj lj b lk nv ln nw lq nx lu ny ly nz mc pi ns nt nu bi translated"><strong class="lj jt"> 2D CNN → </strong>在2D CNN的领导下，内核向两个方向移动。2D CNN的输入和输出数据是三维的。我们通常在图像数据问题上使用这个。</li><li id="ac5c" class="nk nl jj lj b lk nv ln nw lq nx lu ny ly nz mc pi ns nt nu bi translated"><strong class="lj jt"> 3D CNN → </strong>这里，内核向三个方向移动。3D CNN的输入和输出数据是四维的。工程师在3D图像上使用3D CNNs，如磁共振成像、CT扫描和其他复杂应用的DICOM图像。</li></ul><h1 id="e8a2" class="or mt jj bd mu os pj ou mx ov pk ox na ky pl kz nd lb pm lc ng le pn lf nj pb bi translated">网络体系结构</h1><p id="70e0" class="pw-post-body-paragraph lh li jj lj b lk nm kt lm ln nn kw lp lq pc ls lt lu pd lw lx ly pe ma mb mc im bi translated">CNN架构由不同层的堆叠开发，这些层通过可微分函数将输入音量转换成输出音量。通常使用几种不同类型的层。</p><p id="35df" class="pw-post-body-paragraph lh li jj lj b lk ll kt lm ln lo kw lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">下面是CNN中不同层的堆栈:</p><ul class=""><li id="da3f" class="nk nl jj lj b lk ll ln lo lq pf lu pg ly ph mc pi ns nt nu bi translated">卷积层</li><li id="f0cd" class="nk nl jj lj b lk nv ln nw lq nx lu ny ly nz mc pi ns nt nu bi translated">汇集层</li><li id="0f17" class="nk nl jj lj b lk nv ln nw lq nx lu ny ly nz mc pi ns nt nu bi translated">全连接层</li></ul><p id="ea01" class="pw-post-body-paragraph lh li jj lj b lk ll kt lm ln lo kw lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">总之，完整CNN层的例子:</p><figure class="pp pq pr ps gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi po"><img src="../Images/07083099ae9b92aa46816524e260047a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*QliIRRhUvpsRN1f7.png"/></div></div><figcaption class="jc jd gj gh gi je jf bd b be z dk translated">图1:一个全卷积神经网络(CNN)架构的例子。</figcaption></figure><p id="cca1" class="pw-post-body-paragraph lh li jj lj b lk ll kt lm ln lo kw lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">CNN的完整架构:</p><figure class="pp pq pr ps gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi pt"><img src="../Images/772250dd5bb2c696ea29169631bec4fa.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*6KbXzGTeVmars-Bo.png"/></div></div><figcaption class="jc jd gj gh gi je jf bd b be z dk translated">图2:CNN架构的完整概述。</figcaption></figure><figure class="pp pq pr ps gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi pu"><img src="../Images/c40ea3b557ac82ae4646319c80c29da4.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*ttHUnnPGk7fc4Y84.gif"/></div></div><figcaption class="jc jd gj gh gi je jf bd b be z dk translated">图3:卷积神经网络如何表现|来源:分解它:关于机器学习的问答[ <a class="ae jg" href="https://www.google.com/about/main/machine-learning-qa/" rel="noopener ugc nofollow" target="_blank"> 5 </a> ]</figcaption></figure><p id="368b" class="pw-post-body-paragraph lh li jj lj b lk ll kt lm ln lo kw lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated"><strong class="lj jt">图像处理</strong>是对一幅图像进行操作以获得增强图像或从中提取一些关键信息的过程。有三种不同的方法来执行图像处理:</p><ul class=""><li id="6d8a" class="nk nl jj lj b lk ll ln lo lq pf lu pg ly ph mc pi ns nt nu bi translated">直方图处理。</li><li id="0edf" class="nk nl jj lj b lk nv ln nw lq nx lu ny ly nz mc pi ns nt nu bi translated">转换函数。</li><li id="213f" class="nk nl jj lj b lk nv ln nw lq nx lu ny ly nz mc pi ns nt nu bi translated">卷积。</li></ul><h1 id="a889" class="or mt jj bd mu os pj ou mx ov pk ox na ky pl kz nd lb pm lc ng le pn lf nj pb bi translated">盘旋</h1><p id="d374" class="pw-post-body-paragraph lh li jj lj b lk nm kt lm ln nn kw lp lq pc ls lt lu pd lw lx ly pe ma mb mc im bi translated">卷积是对名为<strong class="lj jt"> f </strong>和<strong class="lj jt"> g </strong>的两个函数的数学计算，给出第三个函数<strong class="lj jt"> (f * g) </strong>。第三个函数揭示了一个函数的形状是如何被另一个函数修改的。它的数学方程式如下:</p><figure class="pp pq pr ps gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi pv"><img src="../Images/f2029bdd36114b2731e34183d94b1a77.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*hsokIMeo8_cJl8Xn.png"/></div></div><figcaption class="jc jd gj gh gi je jf bd b be z dk translated">图4:卷积方程。</figcaption></figure><p id="5c56" class="pw-post-body-paragraph lh li jj lj b lk ll kt lm ln lo kw lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">在了解卷积的概念之前，有必要了解遮罩或滤镜的概念。</p><figure class="pp pq pr ps gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi pw"><img src="../Images/f3b1ffbf508d1f975bb6c74f3b7f3226.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*VxS3KqR55LKQ1YVx.png"/></div></div><figcaption class="jc jd gj gh gi je jf bd b be z dk translated">图5:卷积方程。</figcaption></figure><h2 id="5e87" class="ms mt jj bd mu mv mw dn mx my mz dp na lq nb nc nd lu ne nf ng ly nh ni nj jp bi translated"><strong class="ak">遮罩或滤镜</strong></h2><p id="d2db" class="pw-post-body-paragraph lh li jj lj b lk nm kt lm ln nn kw lp lq pc ls lt lu pd lw lx ly pe ma mb mc im bi translated">掩码是一个小矩阵，其值称为权重。一个二维矩阵表示它。它也被称为过滤。它有趣的一点是应该是奇数。否则很难找到面膜的mid。</p><figure class="pp pq pr ps gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi px"><img src="../Images/4602ac38323f50720526426057632bf9.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*5cyB9pnerN68Afpr.png"/></div></div><figcaption class="jc jd gj gh gi je jf bd b be z dk translated">图6:一个数组的掩码。</figcaption></figure><p id="41d7" class="pw-post-body-paragraph lh li jj lj b lk ll kt lm ln lo kw lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">下面是数组中掩码的代码示例:</p><pre class="pp pq pr ps gt py pz qa qb aw qc bi"><span id="a955" class="ms mt jj pz b gy qd qe l qf qg">import numpy as np<br/>import numpy.ma as ma</span><span id="461d" class="ms mt jj pz b gy qh qe l qf qg">original_array = np.array([1, 2, 3, -1, 5])</span><span id="c033" class="ms mt jj pz b gy qh qe l qf qg">original_array</span></pre><figure class="pp pq pr ps gt iv gh gi paragraph-image"><div class="gh gi qi"><img src="../Images/49d425c2a6ea95e42718205ac278401e.png" data-original-src="https://miro.medium.com/v2/resize:fit:632/format:webp/0*QcbtbIQeQ6cr_k4u.png"/></div><figcaption class="jc jd gj gh gi je jf bd b be z dk translated">图7:原始数组。</figcaption></figure><p id="70d6" class="pw-post-body-paragraph lh li jj lj b lk ll kt lm ln lo kw lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">创建原始数组的掩码:</p><pre class="pp pq pr ps gt py pz qa qb aw qc bi"><span id="4ec9" class="ms mt jj pz b gy qd qe l qf qg">masked = ma.masked_array(original_array, mask=[0, 0, 0, 1, 0])</span><span id="df82" class="ms mt jj pz b gy qh qe l qf qg">masked</span></pre><figure class="pp pq pr ps gt iv gh gi paragraph-image"><div class="gh gi qj"><img src="../Images/efd3fdef5f45eef219d16b79a35bd447.png" data-original-src="https://miro.medium.com/v2/resize:fit:1246/format:webp/0*lTxVERnl70v5WIhl.png"/></div><figcaption class="jc jd gj gh gi je jf bd b be z dk translated">图8:原始数组的掩码。</figcaption></figure><h2 id="bd44" class="ms mt jj bd mu mv mw dn mx my mz dp na lq nb nc nd lu ne nf ng ly nh ni nj jp bi translated"><strong class="ak">为什么卷积在CNN中很重要？</strong></h2><p id="bcc6" class="pw-post-body-paragraph lh li jj lj b lk nm kt lm ln nn kw lp lq pc ls lt lu pd lw lx ly pe ma mb mc im bi translated">CNN中的<strong class="lj jt">卷积</strong>循环至关重要，因为它可以在以下情况下处理图像:</p><ul class=""><li id="0a67" class="nk nl jj lj b lk ll ln lo lq pf lu pg ly ph mc pi ns nt nu bi translated">模糊</li><li id="6ffe" class="nk nl jj lj b lk nv ln nw lq nx lu ny ly nz mc pi ns nt nu bi translated">磨刀</li><li id="3503" class="nk nl jj lj b lk nv ln nw lq nx lu ny ly nz mc pi ns nt nu bi translated">边缘检测</li><li id="0528" class="nk nl jj lj b lk nv ln nw lq nx lu ny ly nz mc pi ns nt nu bi translated">噪声降低</li></ul><h2 id="ca10" class="ms mt jj bd mu mv mw dn mx my mz dp na lq nb nc nd lu ne nf ng ly nh ni nj jp bi translated"><strong class="ak">卷积是如何执行的？</strong></h2><p id="35c3" class="pw-post-body-paragraph lh li jj lj b lk nm kt lm ln nn kw lp lq pc ls lt lu pd lw lx ly pe ma mb mc im bi translated">执行卷积的步骤如下:</p><ul class=""><li id="be45" class="nk nl jj lj b lk ll ln lo lq pf lu pg ly ph mc pi ns nt nu bi translated">水平和垂直翻转遮罩仅一次。</li><li id="a9bf" class="nk nl jj lj b lk nv ln nw lq nx lu ny ly nz mc pi ns nt nu bi translated">将遮罩滑动到图像上。</li><li id="005a" class="nk nl jj lj b lk nv ln nw lq nx lu ny ly nz mc pi ns nt nu bi translated">将相似的元素相乘，然后相加。</li><li id="498a" class="nk nl jj lj b lk nv ln nw lq nx lu ny ly nz mc pi ns nt nu bi translated">重复上述所有步骤，直到计算出图像的所有值[ <a class="ae jg" href="https://www.tutorialspoint.com/dip/concept_of_convolution.htm" rel="noopener ugc nofollow" target="_blank"> 8 </a> ]。</li></ul><figure class="pp pq pr ps gt iv gh gi paragraph-image"><div class="gh gi qk"><img src="../Images/b00f346cd16e16d48ccae94b7bac7007.png" data-original-src="https://miro.medium.com/v2/resize:fit:1052/0*La9_J7dqnk-DEWyb.gif"/></div><figcaption class="jc jd gj gh gi je jf bd b be z dk translated">图9:卷积特征或激活图或特征图。</figcaption></figure><p id="fcd6" class="pw-post-body-paragraph lh li jj lj b lk ll kt lm ln lo kw lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">按照上述步骤:</p><p id="df00" class="pw-post-body-paragraph lh li jj lj b lk ll kt lm ln lo kw lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">面具下方:</p><figure class="pp pq pr ps gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi ql"><img src="../Images/8ccd33b40ec18a1771b63763a4ccee92.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*VJ0sadPliZFui3vr.png"/></div></div><figcaption class="jc jd gj gh gi je jf bd b be z dk translated">图10:掩模阵列。</figcaption></figure><p id="ee4b" class="pw-post-body-paragraph lh li jj lj b lk ll kt lm ln lo kw lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">水平翻转→<strong class="lj jt"/></p><figure class="pp pq pr ps gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi qm"><img src="../Images/75e3dcea814b32c0d6cd9db3d456fc1a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*7qA0CGBaiz9WvCfh.png"/></div></div><figcaption class="jc jd gj gh gi je jf bd b be z dk translated">图11:水平翻转蒙版。</figcaption></figure><p id="bd3a" class="pw-post-body-paragraph lh li jj lj b lk ll kt lm ln lo kw lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">垂直翻转→<strong class="lj jt"/></p><figure class="pp pq pr ps gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi qn"><img src="../Images/d96f9230b8815585cc00ee40b09dfccc.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*foXsBKo3WqcHhfRC.png"/></div></div><figcaption class="jc jd gj gh gi je jf bd b be z dk translated">图12:垂直翻转遮罩。</figcaption></figure><p id="01f2" class="pw-post-body-paragraph lh li jj lj b lk ll kt lm ln lo kw lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">让我们来看看下面这张图片的尺寸:</p><figure class="pp pq pr ps gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi qo"><img src="../Images/7ad6c94bfe626fe58aa8feec019c0e6d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*KZCZZobegiDTO8dG.png"/></div></div><figcaption class="jc jd gj gh gi je jf bd b be z dk translated">图13:图像的尺寸。</figcaption></figure><p id="78c2" class="pw-post-body-paragraph lh li jj lj b lk ll kt lm ln lo kw lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">现在，为了<strong class="lj jt">计算卷积</strong>,请遵循以下步骤:</p><ul class=""><li id="955b" class="nk nl jj lj b lk ll ln lo lq pf lu pg ly ph mc pi ns nt nu bi translated">将遮罩的核心放在图像的每个部分。</li><li id="0385" class="nk nl jj lj b lk nv ln nw lq nx lu ny ly nz mc pi ns nt nu bi translated">将类似的元素相乘并相加</li><li id="396c" class="nk nl jj lj b lk nv ln nw lq nx lu ny ly nz mc pi ns nt nu bi translated">最后，将结果粘贴到蒙版中心所在的图像元素上。</li></ul><figure class="pp pq pr ps gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi qp"><img src="../Images/3224101f8e29a5e488b90fa9e0113ff4.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*-LLXc2_vZn0HtLF4.png"/></div></div><figcaption class="jc jd gj gh gi je jf bd b be z dk translated">图14:图像上的遮罩。</figcaption></figure><p id="6747" class="pw-post-body-paragraph lh li jj lj b lk ll kt lm ln lo kw lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">从图14中可以看出:</p><ul class=""><li id="995d" class="nk nl jj lj b lk ll ln lo lq pf lu pg ly ph mc pi ns nt nu bi translated">绿色框是遮罩，框中的绿色值是遮罩的值</li><li id="c9c8" class="nk nl jj lj b lk nv ln nw lq nx lu ny ly nz mc pi ns nt nu bi translated">蓝框及其值与图像相关</li></ul><p id="627e" class="pw-post-body-paragraph lh li jj lj b lk ll kt lm ln lo kw lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated"><strong class="lj jt">现在，计算图像的第一个像素↓ </strong></p><p id="e2f9" class="pw-post-body-paragraph lh li jj lj b lk ll kt lm ln lo kw lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">px1 = (5 * 2) + (4 *4) + (1* 0)</p><p id="d21c" class="pw-post-body-paragraph lh li jj lj b lk ll kt lm ln lo kw lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">px1 = 10+ 16+16+10</p><p id="8549" class="pw-post-body-paragraph lh li jj lj b lk ll kt lm ln lo kw lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">px1 = 52</p><p id="431a" class="pw-post-body-paragraph lh li jj lj b lk ll kt lm ln lo kw lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">图像第一个像素的结果是52。因此，根据结果，我们遵循以下步骤:</p><ul class=""><li id="862d" class="nk nl jj lj b lk ll ln lo lq pf lu pg ly ph mc pi ns nt nu bi translated">将值52放在原始图像的第一个索引处。</li><li id="0407" class="nk nl jj lj b lk nv ln nw lq nx lu ny ly nz mc pi ns nt nu bi translated">对图像的每个像素重复此步骤。</li></ul><h1 id="5f95" class="or mt jj bd mu os pj ou mx ov pk ox na ky pl kz nd lb pm lc ng le pn lf nj pb bi translated">卷积层</h1><p id="1f13" class="pw-post-body-paragraph lh li jj lj b lk nm kt lm ln nn kw lp lq pc ls lt lu pd lw lx ly pe ma mb mc im bi translated">CNN是具有一些卷积层和一些其他层的神经网络。卷积层有几个执行卷积运算的滤波器。卷积层应用于二维输入，由于其出色的图像分类工作性能而非常著名。它们基于一个小核<strong class="lj jt"> k </strong>与一个二维输入的离散卷积，这个输入可以是另一个卷积层的输出。卷积层是CNN [ <a class="ae jg" href="https://en.wikipedia.org/wiki/Convolutional_neural_network" rel="noopener ugc nofollow" target="_blank"> 9 </a> ]的核心构件。</p><figure class="pp pq pr ps gt iv gh gi paragraph-image"><div class="gh gi qq"><img src="../Images/0db4339b1aae2da689d06b94f882ba21.png" data-original-src="https://miro.medium.com/v2/resize:fit:890/format:webp/0*vavLr5rbJ7zc7fHX.png"/></div><figcaption class="jc jd gj gh gi je jf bd b be z dk translated">图15:带滤波器的卷积层。</figcaption></figure><figure class="pp pq pr ps gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi qr"><img src="../Images/87146c1cf528f0e53a46da63277139d4.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*oTbsPd6BaJ4PbIm6.png"/></div></div><figcaption class="jc jd gj gh gi je jf bd b be z dk translated">图16:卷积层。</figcaption></figure><p id="8fd9" class="pw-post-body-paragraph lh li jj lj b lk ll kt lm ln lo kw lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">卷积在所有空间位置上共享相同的参数；然而，传统的矩阵乘法不共享任何参数。</p><figure class="pp pq pr ps gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi qs"><img src="../Images/526559e7c42734a9d14530f045878b9a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1326/format:webp/0*HKGB2W2-wGaJ4qUN.png"/></div></div><figcaption class="jc jd gj gh gi je jf bd b be z dk translated">图17:卷积共享相同参数。</figcaption></figure><p id="eb73" class="pw-post-body-paragraph lh li jj lj b lk ll kt lm ln lo kw lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">在Keras中构建卷积图层:</p><pre class="pp pq pr ps gt py pz qa qb aw qc bi"><span id="fb84" class="ms mt jj pz b gy qd qe l qf qg">from keras.models import Sequential<br/>from keras.layers.convolutional import Conv2D</span><span id="9e8c" class="ms mt jj pz b gy qh qe l qf qg">model = Sequential()</span><span id="f6ce" class="ms mt jj pz b gy qh qe l qf qg">model.add(Conv2D(32, (3, 3), input_shape=(32, 32, 3), padding='same', activation='relu'))</span></pre><p id="535b" class="pw-post-body-paragraph lh li jj lj b lk ll kt lm ln lo kw lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">以上代码实现的解释:</p><ul class=""><li id="543b" class="nk nl jj lj b lk ll ln lo lq pf lu pg ly ph mc pi ns nt nu bi translated">输出将有<strong class="lj jt"> 32 </strong>特征地图。</li><li id="9545" class="nk nl jj lj b lk nv ln nw lq nx lu ny ly nz mc pi ns nt nu bi translated">内核大小将会是3x3。</li><li id="5b1c" class="nk nl jj lj b lk nv ln nw lq nx lu ny ly nz mc pi ns nt nu bi translated">输入形状为三通道的<strong class="lj jt"> 32x32 </strong>。</li><li id="99df" class="nk nl jj lj b lk nv ln nw lq nx lu ny ly nz mc pi ns nt nu bi translated"><strong class="lj jt">填充=相同</strong>。这意味着输入需要相同维度的输出。</li><li id="0d7f" class="nk nl jj lj b lk nv ln nw lq nx lu ny ly nz mc pi ns nt nu bi translated">激活指定激活功能。</li></ul><p id="5d5c" class="pw-post-body-paragraph lh li jj lj b lk ll kt lm ln lo kw lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">接下来，使用不同的参数值构建一个卷积层，如下所示:</p><pre class="pp pq pr ps gt py pz qa qb aw qc bi"><span id="d0f2" class="ms mt jj pz b gy qd qe l qf qg">model.add(Conv2D(32, (3, 3), activation='relu', padding='valid')</span></pre><p id="d87a" class="pw-post-body-paragraph lh li jj lj b lk ll kt lm ln lo kw lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">所以，从上面卷积层的代码来看:</p><ul class=""><li id="d7ca" class="nk nl jj lj b lk ll ln lo lq pf lu pg ly ph mc pi ns nt nu bi translated">内核=3X3</li><li id="23bc" class="nk nl jj lj b lk nv ln nw lq nx lu ny ly nz mc pi ns nt nu bi translated"><strong class="lj jt"> padding=valid: </strong>这意味着输出维度可以采用任何形式[ <a class="ae jg" href="https://github.com/sagar448/Keras-Convolutional-Neural-Network-Python" rel="noopener ugc nofollow" target="_blank"> 10 </a> ]。</li></ul><h1 id="d143" class="or mt jj bd mu os pj ou mx ov pk ox na ky pl kz nd lb pm lc ng le pn lf nj pb bi translated">汇集层/子采样层</h1><p id="3440" class="pw-post-body-paragraph lh li jj lj b lk nm kt lm ln nn kw lp lq pc ls lt lu pd lw lx ly pe ma mb mc im bi translated">基本上，池层用于降低图像的维度。它还用于使用多个过滤器检测图像中的边缘、眼睛、鼻子、角落等。它的功能是减少参数的数量，也减少网络中的空间大小。有两种方法可以实现池化:</p><ul class=""><li id="4d2b" class="nk nl jj lj b lk ll ln lo lq pf lu pg ly ph mc pi ns nt nu bi translated"><strong class="lj jt"> Max Pooling </strong>:表示矩形邻域内的最大输出。</li><li id="1b8d" class="nk nl jj lj b lk nv ln nw lq nx lu ny ly nz mc pi ns nt nu bi translated"><strong class="lj jt">平均池</strong>:表示一个矩形邻域的平均输出。</li></ul><p id="7de6" class="pw-post-body-paragraph lh li jj lj b lk ll kt lm ln lo kw lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">最常用的池是最大池和平均池。图像的空间尺寸减小了，因为它给出了更少的像素和更少的特征或参数用于进一步的计算。</p><p id="1cf1" class="pw-post-body-paragraph lh li jj lj b lk ll kt lm ln lo kw lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">因此，池层有两个重要目的:</p><ul class=""><li id="3925" class="nk nl jj lj b lk ll ln lo lq pf lu pg ly ph mc pi ns nt nu bi translated">随着网络从一个卷积图层移动到下一个卷积图层，要素地图的空间大小不断减小，从而减少了参数的数量。</li><li id="7d8a" class="nk nl jj lj b lk nv ln nw lq nx lu ny ly nz mc pi ns nt nu bi translated">弃牌时逐步识别基本特征(这在最大池中比在平均池中更真实)。</li></ul><figure class="pp pq pr ps gt iv gh gi paragraph-image"><div class="gh gi qt"><img src="../Images/1c7a3ecc4e48c931fa923b8c0d01b432.png" data-original-src="https://miro.medium.com/v2/resize:fit:380/0*qKCvk9__jrgkZOFp.gif"/></div><figcaption class="jc jd gj gh gi je jf bd b be z dk translated">图18:池层中的输入和输出矩阵。</figcaption></figure><p id="c183" class="pw-post-body-paragraph lh li jj lj b lk ll kt lm ln lo kw lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">上图显示了一个最大池，带有一个步幅为2的2X2过滤器。</p><p id="087f" class="pw-post-body-paragraph lh li jj lj b lk ll kt lm ln lo kw lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">最大池和平均池的描述如下:</p><figure class="pp pq pr ps gt iv gh gi paragraph-image"><div class="gh gi qu"><img src="../Images/a669789e1ee672e6dbef1ee3e5136b81.png" data-original-src="https://miro.medium.com/v2/resize:fit:1396/format:webp/0*N4GVyjd8dwElMyg9.png"/></div><figcaption class="jc jd gj gh gi je jf bd b be z dk translated">图19:最大池和平均池。</figcaption></figure><p id="f73e" class="pw-post-body-paragraph lh li jj lj b lk ll kt lm ln lo kw lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">在Keras中实现最大池层，如下所示:</p><pre class="pp pq pr ps gt py pz qa qb aw qc bi"><span id="e840" class="ms mt jj pz b gy qd qe l qf qg">model.add(MaxPooling2D(pool_size=(2, 2)))</span></pre><p id="83ff" class="pw-post-body-paragraph lh li jj lj b lk ll kt lm ln lo kw lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">这里，内核大小= 2 x 2</p><p id="89b8" class="pw-post-body-paragraph lh li jj lj b lk ll kt lm ln lo kw lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">对像素进行二次采样不会改变对象，因此池化可以对像素进行二次采样以使图像变小。</p><figure class="pp pq pr ps gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi qv"><img src="../Images/e9cb7ff51931eb76545f5f2957e6e4c7.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*oxg9ELto0bAei9Na.png"/></div></div><figcaption class="jc jd gj gh gi je jf bd b be z dk translated">图20:按池进行二次抽样。</figcaption></figure><h1 id="9deb" class="or mt jj bd mu os pj ou mx ov pk ox na ky pl kz nd lb pm lc ng le pn lf nj pb bi translated">进展</h1><p id="4d13" class="pw-post-body-paragraph lh li jj lj b lk nm kt lm ln nn kw lp lq pc ls lt lu pd lw lx ly pe ma mb mc im bi translated">它是神经网络中的一个组件，主要修改视频和图像的运动。步幅是一个与填充配合使用的参数。例如，如果步幅设置为1，我们一次移动一个像素或单位。类似地，如果步幅设置为2，我们移动2个单位像素或单位。</p><p id="d834" class="pw-post-body-paragraph lh li jj lj b lk ll kt lm ln lo kw lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">本质上，步幅是卷积滤波器经过的像素数量，就像滑动窗口一样，在它刚刚覆盖的所有像素的加权平均值上移动。旧的加权平均值成为下一图层中的要素地图中的一个像素。下一个加权平均值来自一个新的像素集合，它形成了后续图层中的特征图中的下一个像素。</p><p id="75c3" class="pw-post-body-paragraph lh li jj lj b lk ll kt lm ln lo kw lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">下面是一个stride的动画演示:</p><p id="1ae7" class="pw-post-body-paragraph lh li jj lj b lk ll kt lm ln lo kw lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated"><strong class="lj jt">1</strong>的步幅:</p><figure class="pp pq pr ps gt iv gh gi paragraph-image"><div class="gh gi qw"><img src="../Images/2ad292e55c1f6b71004bf86fbbf223f9.png" data-original-src="https://miro.medium.com/v2/resize:fit:990/0*FObaG3xnQocArlde"/></div><figcaption class="jc jd gj gh gi je jf bd b be z dk translated">图21:1的步幅。</figcaption></figure><p id="de98" class="pw-post-body-paragraph lh li jj lj b lk ll kt lm ln lo kw lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated"><strong class="lj jt">2的步幅:</strong></p><figure class="pp pq pr ps gt iv gh gi paragraph-image"><div class="gh gi qx"><img src="../Images/ed5c4f5fdd7cc98cc8ddda37f5fe620a.png" data-original-src="https://miro.medium.com/v2/resize:fit:790/0*NiIhU7HohP5r3bhn"/></div><figcaption class="jc jd gj gh gi je jf bd b be z dk translated">图22:2的步幅。</figcaption></figure><p id="b2ed" class="pw-post-body-paragraph lh li jj lj b lk ll kt lm ln lo kw lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">图22中的stride动画简单地解释了:</p><blockquote class="qy qz ra"><p id="2709" class="lh li rb lj b lk ll kt lm ln lo kw lp rc lr ls lt rd lv lw lx re lz ma mb mc im bi translated"><em class="jj">卷积神经网络中的Stride稀释了在图像上水平和垂直扫描特征时可以跳过的步骤。</em></p></blockquote><p id="79e4" class="pw-post-body-paragraph lh li jj lj b lk ll kt lm ln lo kw lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">在CNN中，大步从一个网络层到另一个网络层。因此，有两种选择，要么减小数据大小，要么保持数据大小不变。因此，填充和步幅都会影响数据大小。填充在stride中是必不可少的，因为如果没有填充，下一层将减少数据大小。</p><p id="9ec0" class="pw-post-body-paragraph lh li jj lj b lk ll kt lm ln lo kw lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">当使用stride时，它从左上角的filer开始，计算第一个节点的值，当它将节点移动两个单位时，当过滤器延伸到图像之外时，它继续，创建一个空间。<strong class="lj jt">因此，填充用于填充大步行走产生的空隙</strong>。</p><p id="17ff" class="pw-post-body-paragraph lh li jj lj b lk ll kt lm ln lo kw lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">让我们取一个内核为<strong class="lj jt"> 3X3 </strong>的<strong class="lj jt"> 5X5 </strong>的输入层如下:</p><figure class="pp pq pr ps gt iv gh gi paragraph-image"><div class="gh gi rf"><img src="../Images/3917d74a1a06680edc269ee15cea5624.png" data-original-src="https://miro.medium.com/v2/resize:fit:544/format:webp/0*USH14JAnaONfbijY.png"/></div><figcaption class="jc jd gj gh gi je jf bd b be z dk translated">图23: 5x5输入层。</figcaption></figure><p id="c535" class="pw-post-body-paragraph lh li jj lj b lk ll kt lm ln lo kw lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">应用1:</p><figure class="pp pq pr ps gt iv gh gi paragraph-image"><div class="gh gi rg"><img src="../Images/ee2db1f0cedd966ca5c75ba51e7a6420.png" data-original-src="https://miro.medium.com/v2/resize:fit:512/format:webp/0*fJjCQnz-l1xCw_y9.png"/></div><figcaption class="jc jd gj gh gi je jf bd b be z dk translated">图24:步幅为1。</figcaption></figure><p id="552b" class="pw-post-body-paragraph lh li jj lj b lk ll kt lm ln lo kw lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">应用步幅2:</p><figure class="pp pq pr ps gt iv gh gi paragraph-image"><div class="gh gi rh"><img src="../Images/d2acc8f33208f94665c7e6615ac106de.png" data-original-src="https://miro.medium.com/v2/resize:fit:548/format:webp/0*iHc_5siwd36KpZ_K.png"/></div><figcaption class="jc jd gj gh gi je jf bd b be z dk translated">图25:步幅为2。</figcaption></figure><p id="1ac1" class="pw-post-body-paragraph lh li jj lj b lk ll kt lm ln lo kw lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">假设我们应用步幅3，同时仍然查看5x5输入，会发生什么情况？</p><figure class="pp pq pr ps gt iv gh gi paragraph-image"><div class="gh gi ri"><img src="../Images/12e4036ad660b18e900b76559a45ffbc.png" data-original-src="https://miro.medium.com/v2/resize:fit:612/format:webp/0*ety5233Qv3FPHJoQ.png"/></div><figcaption class="jc jd gj gh gi je jf bd b be z dk translated">图26:应用步幅3。</figcaption></figure><p id="e39e" class="pw-post-body-paragraph lh li jj lj b lk ll kt lm ln lo kw lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">因此，这里需要填充。对于整个输入，添加的填充数据的宽度等于内核宽度减一，或者高度等于内核高度减一(如果它在上面和下面),以便内核可以查看最边缘，如图27所示:</p><figure class="pp pq pr ps gt iv gh gi paragraph-image"><div class="gh gi rj"><img src="../Images/750a02e05fdbf00e38dd0304802d99e4.png" data-original-src="https://miro.medium.com/v2/resize:fit:726/format:webp/0*oSKXeZn23TqVH0UB.png"/></div><figcaption class="jc jd gj gh gi je jf bd b be z dk translated">图27:带衬垫的步幅。</figcaption></figure><p id="e4ac" class="pw-post-body-paragraph lh li jj lj b lk ll kt lm ln lo kw lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">因此，从上面的图示来看:</p><p id="6662" class="pw-post-body-paragraph lh li jj lj b lk ll kt lm ln lo kw lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">没有填充意味着下一层的数据大小将减少。同时，引入足够的衬垫将保持尺寸不变。此外，它以更大的步长限制了卷积运算中两个后续点积的重叠。这意味着激活中的每个输出值将更加独立于相邻值。</p><h1 id="78ff" class="or mt jj bd mu os pj ou mx ov pk ox na ky pl kz nd lb pm lc ng le pn lf nj pb bi translated">全连接层</h1><p id="be93" class="pw-post-body-paragraph lh li jj lj b lk nm kt lm ln nn kw lp lq pc ls lt lu pd lw lx ly pe ma mb mc im bi translated">这一层是决定最终预测的所有输入和权重的总和，代表最后一个池层的输出。顾名思义，完全连接使第一层中的每个节点都连接到第二层中的节点。基于由先前层[ <a class="ae jg" href="https://www.aidevnepal.co/nepali-handwritten-character-recognition-using-cnn/" rel="noopener ugc nofollow" target="_blank"> 11 </a> ]提取的特征执行分类。它将一层中的每个神经元连接到另一层中的每个神经元。</p><figure class="pp pq pr ps gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi rk"><img src="../Images/016ea75844b3e24d253fe026ca4141fc.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*C_-6S2ogUrAD_ptj.png"/></div></div><figcaption class="jc jd gj gh gi je jf bd b be z dk translated">图28:一个完全连接的层。</figcaption></figure><p id="0e23" class="pw-post-body-paragraph lh li jj lj b lk ll kt lm ln lo kw lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">CNN可以分为两类<strong class="lj jt"/>:</p><ul class=""><li id="824e" class="nk nl jj lj b lk ll ln lo lq pf lu pg ly ph mc pi ns nt nu bi translated">特征抽出</li><li id="f36e" class="nk nl jj lj b lk nv ln nw lq nx lu ny ly nz mc pi ns nt nu bi translated">分类</li></ul><p id="1eb7" class="pw-post-body-paragraph lh li jj lj b lk ll kt lm ln lo kw lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">全连接层的主要职责是做分类。它与softmax或sigmoid激活单元一起用于结果。</p><h1 id="48df" class="or mt jj bd mu os pj ou mx ov pk ox na ky pl kz nd lb pm lc ng le pn lf nj pb bi translated">非线性层</h1><p id="e469" class="pw-post-body-paragraph lh li jj lj b lk nm kt lm ln nn kw lp lq pc ls lt lu pd lw lx ly pe ma mb mc im bi translated">应用于最后一层的激活函数与其他层非常不同。用于multiclass的激活是softmax函数，该函数以0和1的概率(总和为1)归一化完全连接的层。</p><p id="d208" class="pw-post-body-paragraph lh li jj lj b lk ll kt lm ln lo kw lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">通常，Softmax仅用于输出层，用于需要将输入分类为多个类别的神经网络。通常的神经网络，尤其是CNN，依赖于非线性“触发”函数来发出信号，明确识别每个隐藏层上的可能特征。</p><p id="eb60" class="pw-post-body-paragraph lh li jj lj b lk ll kt lm ln lo kw lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">为了有效地实现这个非线性层，CNN使用下面的函数:</p><ul class=""><li id="37ff" class="nk nl jj lj b lk ll ln lo lq pf lu pg ly ph mc pi ns nt nu bi translated">校正线性单位</li><li id="7a23" class="nk nl jj lj b lk nv ln nw lq nx lu ny ly nz mc pi ns nt nu bi translated">连续触发功能</li></ul><p id="869a" class="pw-post-body-paragraph lh li jj lj b lk ll kt lm ln lo kw lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">带有非线性函数“Relu”的Keras代码如下:</p><pre class="pp pq pr ps gt py pz qa qb aw qc bi"><span id="eb62" class="ms mt jj pz b gy qd qe l qf qg">model.add(Dense(512, activation='relu'))</span></pre><p id="08af" class="pw-post-body-paragraph lh li jj lj b lk ll kt lm ln lo kw lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">这里有512个隐藏单元。</p><p id="4f3a" class="pw-post-body-paragraph lh li jj lj b lk ll kt lm ln lo kw lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">Keras代码如下，带有非线性函数“Softmax”:</p><pre class="pp pq pr ps gt py pz qa qb aw qc bi"><span id="ed35" class="ms mt jj pz b gy qd qe l qf qg">model.add(Dense(10, activation='softmax'))</span></pre><h1 id="c55c" class="or mt jj bd mu os pj ou mx ov pk ox na ky pl kz nd lb pm lc ng le pn lf nj pb bi translated">卷积神经网络的Python实现</h1><p id="0575" class="pw-post-body-paragraph lh li jj lj b lk nm kt lm ln nn kw lp lq pc ls lt lu pd lw lx ly pe ma mb mc im bi translated">针对CNN的Keras CNNs层代码实现:</p><p id="8071" class="pw-post-body-paragraph lh li jj lj b lk ll kt lm ln lo kw lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">导入所有必需的库</p><pre class="pp pq pr ps gt py pz qa qb aw qc bi"><span id="b2d1" class="ms mt jj pz b gy qd qe l qf qg">import numpy as np</span><span id="c06e" class="ms mt jj pz b gy qh qe l qf qg">import pandas as pd</span><span id="3f35" class="ms mt jj pz b gy qh qe l qf qg">from keras.optimizers import SGD</span><span id="728b" class="ms mt jj pz b gy qh qe l qf qg">from keras.datasets import cifar10</span><span id="3a64" class="ms mt jj pz b gy qh qe l qf qg">from keras.models import Sequential</span><span id="26fd" class="ms mt jj pz b gy qh qe l qf qg">from keras.utils import np_utils as utils</span><span id="d438" class="ms mt jj pz b gy qh qe l qf qg">from keras.layers import Dropout, Dense, Flatten</span><span id="7202" class="ms mt jj pz b gy qh qe l qf qg">from keras.layers.convolutional import Conv2D, MaxPooling2D</span></pre><p id="9748" class="pw-post-body-paragraph lh li jj lj b lk ll kt lm ln lo kw lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">加载Cifar01数据:</p><pre class="pp pq pr ps gt py pz qa qb aw qc bi"><span id="786b" class="ms mt jj pz b gy qd qe l qf qg">(X, y), (X_test, y_test) = cifar10.load_data()</span></pre><p id="61d6" class="pw-post-body-paragraph lh li jj lj b lk ll kt lm ln lo kw lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">显示测试数据集</p><pre class="pp pq pr ps gt py pz qa qb aw qc bi"><span id="6d73" class="ms mt jj pz b gy qd qe l qf qg">X_test</span></pre><figure class="pp pq pr ps gt iv gh gi paragraph-image"><div class="gh gi rl"><img src="../Images/4bd5e29d7f47f5d4b46ee72a6c25bc8c.png" data-original-src="https://miro.medium.com/v2/resize:fit:630/format:webp/0*WS-hHvbuXJ2XUrP_.png"/></div><figcaption class="jc jd gj gh gi je jf bd b be z dk translated">图29: Cifar01。</figcaption></figure><p id="290f" class="pw-post-body-paragraph lh li jj lj b lk ll kt lm ln lo kw lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">标准化数据:</p><pre class="pp pq pr ps gt py pz qa qb aw qc bi"><span id="9a41" class="ms mt jj pz b gy qd qe l qf qg">X, X_test = X.astype('float32')/255.0, X_test.astype('float32')/255.0</span></pre><p id="423d" class="pw-post-body-paragraph lh li jj lj b lk ll kt lm ln lo kw lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">转换为分类:</p><pre class="pp pq pr ps gt py pz qa qb aw qc bi"><span id="4739" class="ms mt jj pz b gy qd qe l qf qg">y, y_test = utils.to_categorical(y, 10), u.to_categorical(y_test, 10)</span></pre><p id="7fec" class="pw-post-body-paragraph lh li jj lj b lk ll kt lm ln lo kw lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">初始化模型:</p><pre class="pp pq pr ps gt py pz qa qb aw qc bi"><span id="cfa2" class="ms mt jj pz b gy qd qe l qf qg">model = Sequential()</span></pre><p id="f78f" class="pw-post-body-paragraph lh li jj lj b lk ll kt lm ln lo kw lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">使用以下参数添加卷积层:</p><ul class=""><li id="29de" class="nk nl jj lj b lk ll ln lo lq pf lu pg ly ph mc pi ns nt nu bi translated">特征图= 32</li><li id="3c0e" class="nk nl jj lj b lk nv ln nw lq nx lu ny ly nz mc pi ns nt nu bi translated">内核大小= 3x3</li><li id="4649" class="nk nl jj lj b lk nv ln nw lq nx lu ny ly nz mc pi ns nt nu bi translated">输入形状= 32x32</li><li id="2270" class="nk nl jj lj b lk nv ln nw lq nx lu ny ly nz mc pi ns nt nu bi translated">通道= 3</li><li id="55a0" class="nk nl jj lj b lk nv ln nw lq nx lu ny ly nz mc pi ns nt nu bi translated">Padding = 3 →表示输出的维度与输入的维度相同。</li></ul><pre class="pp pq pr ps gt py pz qa qb aw qc bi"><span id="893e" class="ms mt jj pz b gy qd qe l qf qg">model.add(Conv2D(32, (3, 3), input_shape=(32, 32, 3), padding='same', activation='relu'))</span></pre><p id="f89a" class="pw-post-body-paragraph lh li jj lj b lk ll kt lm ln lo kw lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">添加辍学率:</p><pre class="pp pq pr ps gt py pz qa qb aw qc bi"><span id="dc8e" class="ms mt jj pz b gy qd qe l qf qg">model.add(Dropout(0.2))</span></pre><p id="56ba" class="pw-post-body-paragraph lh li jj lj b lk ll kt lm ln lo kw lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">添加另一个CNN图层，填充=有效。</p><p id="2c8d" class="pw-post-body-paragraph lh li jj lj b lk ll kt lm ln lo kw lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">padding = valid →这意味着输出维度可以采用任何形式。</p><pre class="pp pq pr ps gt py pz qa qb aw qc bi"><span id="6cb4" class="ms mt jj pz b gy qd qe l qf qg">model.add(Conv2D(32, (3, 3), activation='relu', padding='valid'))</span></pre><p id="29df" class="pw-post-body-paragraph lh li jj lj b lk ll kt lm ln lo kw lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">添加最大池层。</p><pre class="pp pq pr ps gt py pz qa qb aw qc bi"><span id="8867" class="ms mt jj pz b gy qd qe l qf qg">model.add(MaxPooling2D(pool_size=(2, 2)))</span></pre><p id="f916" class="pw-post-body-paragraph lh li jj lj b lk ll kt lm ln lo kw lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">扁平化数据:</p><p id="1f0f" class="pw-post-body-paragraph lh li jj lj b lk ll kt lm ln lo kw lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">在CNN中，重要的是在将数据输入到输出或密集层之前将其展平。</p><pre class="pp pq pr ps gt py pz qa qb aw qc bi"><span id="efbb" class="ms mt jj pz b gy qd qe l qf qg">model.add(Flatten())</span></pre><p id="71ae" class="pw-post-body-paragraph lh li jj lj b lk ll kt lm ln lo kw lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">添加密集层:</p><pre class="pp pq pr ps gt py pz qa qb aw qc bi"><span id="5a74" class="ms mt jj pz b gy qd qe l qf qg">model.add(Dense(512, activation='relu'))</span></pre><p id="e613" class="pw-post-body-paragraph lh li jj lj b lk ll kt lm ln lo kw lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">这里，隐藏单元的数量是521。</p><p id="73fe" class="pw-post-body-paragraph lh li jj lj b lk ll kt lm ln lo kw lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">添加辍学:</p><pre class="pp pq pr ps gt py pz qa qb aw qc bi"><span id="3459" class="ms mt jj pz b gy qd qe l qf qg">model.add(Dropout(0.3))</span></pre><p id="7008" class="pw-post-body-paragraph lh li jj lj b lk ll kt lm ln lo kw lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">添加输出密集图层:</p><pre class="pp pq pr ps gt py pz qa qb aw qc bi"><span id="8628" class="ms mt jj pz b gy qd qe l qf qg">model.add(Dense(10, activation='softmax'))</span></pre><p id="149f" class="pw-post-body-paragraph lh li jj lj b lk ll kt lm ln lo kw lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">编译模型:</p><pre class="pp pq pr ps gt py pz qa qb aw qc bi"><span id="59dc" class="ms mt jj pz b gy qd qe l qf qg">model.compile(loss='categorical_crossentropy',              optimizer=SGD(momentum=0.5, decay=0.0004), metrics=['accuracy'])</span></pre><p id="98f6" class="pw-post-body-paragraph lh li jj lj b lk ll kt lm ln lo kw lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">用25个时期拟合算法:</p><pre class="pp pq pr ps gt py pz qa qb aw qc bi"><span id="f295" class="ms mt jj pz b gy qd qe l qf qg">model.fit(X, y, validation_data=(X_test, y_test), epochs=25,          batch_size=512)</span></pre><figure class="pp pq pr ps gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi rm"><img src="../Images/0a052a52268fee22ca3ee0cfd655f1a6.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*Sk1hLmoG6r9daj9b.png"/></div></div><figcaption class="jc jd gj gh gi je jf bd b be z dk translated">图30:CNN的训练。</figcaption></figure><p id="08b2" class="pw-post-body-paragraph lh li jj lj b lk ll kt lm ln lo kw lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">检查准确性:</p><pre class="pp pq pr ps gt py pz qa qb aw qc bi"><span id="b864" class="ms mt jj pz b gy qd qe l qf qg">print("Accuracy: &amp;2.f%%" %(model.evaluate(X_test, y_test)[1]*100))</span></pre><h1 id="14b9" class="or mt jj bd mu os pj ou mx ov pk ox na ky pl kz nd lb pm lc ng le pn lf nj pb bi translated">CNN的超参数</h1><p id="20ea" class="pw-post-body-paragraph lh li jj lj b lk nm kt lm ln nn kw lp lq pc ls lt lu pd lw lx ly pe ma mb mc im bi translated">超参数对于控制学习过程非常重要。它在管理网络结构(如隐藏单元的数量)的训练之前应用。优化时应在intelligence中保留以下内容:</p><h1 id="c08e" class="or mt jj bd mu os pj ou mx ov pk ox na ky pl kz nd lb pm lc ng le pn lf nj pb bi translated">最大池形状</h1><p id="4bfd" class="pw-post-body-paragraph lh li jj lj b lk nm kt lm ln nn kw lp lq pc ls lt lu pd lw lx ly pe ma mb mc im bi translated">在最大池中，在矩阵中选择最大值。矩阵的大小可以是<strong class="lj jt"> 2x2 </strong>或<strong class="lj jt"> 3x3 </strong>。典型值为<strong class="lj jt"> 2x2 </strong>。巨大的输入量可能会保证<strong class="lj jt"> 4x4 </strong>在较低的层中形成池。因此，选择更大的形状将显著降低信号的维度，并可能导致过多的信息损失。</p><p id="1fe0" class="pw-post-body-paragraph lh li jj lj b lk ll kt lm ln lo kw lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">代码示例:</p><pre class="pp pq pr ps gt py pz qa qb aw qc bi"><span id="1274" class="ms mt jj pz b gy qd qe l qf qg">model.add(MaxPooling1D(pool_size=2))</span></pre><h1 id="04cc" class="or mt jj bd mu os pj ou mx ov pk ox na ky pl kz nd lb pm lc ng le pn lf nj pb bi translated">过滤器形状</h1><p id="ede4" class="pw-post-body-paragraph lh li jj lj b lk nm kt lm ln nn kw lp lq pc ls lt lu pd lw lx ly pe ma mb mc im bi translated">在给定的数据集中找到合适的粒度级别而不过度拟合是至关重要的。</p><p id="6266" class="pw-post-body-paragraph lh li jj lj b lk ll kt lm ln lo kw lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">代码示例:</p><pre class="pp pq pr ps gt py pz qa qb aw qc bi"><span id="1991" class="ms mt jj pz b gy qd qe l qf qg">model.add(Conv1D(filters=32, kernel_size=3, padding='same', activation='relu'))</span></pre><h1 id="e08b" class="or mt jj bd mu os pj ou mx ov pk ox na ky pl kz nd lb pm lc ng le pn lf nj pb bi translated">过滤器数量</h1><p id="8778" class="pw-post-body-paragraph lh li jj lj b lk nm kt lm ln nn kw lp lq pc ls lt lu pd lw lx ly pe ma mb mc im bi translated">应仔细选择过滤器的数量，因为特征图的数量直接控制容量，并取决于可用示例的数量和任务复杂性[ <a class="ae jg" href="https://en.wikipedia.org/wiki/Convolutional_neural_network" rel="noopener ugc nofollow" target="_blank"> 9 </a> ]。</p><p id="516a" class="pw-post-body-paragraph lh li jj lj b lk ll kt lm ln lo kw lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">代码示例:</p><pre class="pp pq pr ps gt py pz qa qb aw qc bi"><span id="6435" class="ms mt jj pz b gy qd qe l qf qg">model.add(Conv1D(filters=32, kernel_size=3, padding='same', activation='relu'))</span></pre><h1 id="0703" class="or mt jj bd mu os pj ou mx ov pk ox na ky pl kz nd lb pm lc ng le pn lf nj pb bi translated">细胞神经网络的正则化方法</h1><p id="2ebe" class="pw-post-body-paragraph lh li jj lj b lk nm kt lm ln nn kw lp lq pc ls lt lu pd lw lx ly pe ma mb mc im bi translated">正则化是一种包含额外信息以解决不规则问题或停止过度拟合的方法。CNN也使用正则化来处理所有这些问题。以下是CNN使用的不同类型的正则化技术:</p><ul class=""><li id="f6d9" class="nk nl jj lj b lk ll ln lo lq pf lu pg ly ph mc pi ns nt nu bi translated">经验主义的</li><li id="b9f3" class="nk nl jj lj b lk nv ln nw lq nx lu ny ly nz mc pi ns nt nu bi translated">明确的</li></ul><p id="a461" class="pw-post-body-paragraph lh li jj lj b lk ll kt lm ln lo kw lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">经验正则化的不同类别:</p><ul class=""><li id="94b4" class="nk nl jj lj b lk ll ln lo lq pf lu pg ly ph mc pi ns nt nu bi translated">拒绝传统社会的人</li><li id="8840" class="nk nl jj lj b lk nv ln nw lq nx lu ny ly nz mc pi ns nt nu bi translated">下拉连接</li><li id="2881" class="nk nl jj lj b lk nv ln nw lq nx lu ny ly nz mc pi ns nt nu bi translated">随机汇集</li></ul><p id="6513" class="pw-post-body-paragraph lh li jj lj b lk ll kt lm ln lo kw lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">层中丢失的代码实现:</p><pre class="pp pq pr ps gt py pz qa qb aw qc bi"><span id="eced" class="ms mt jj pz b gy qd qe l qf qg">model.add(Dropout(0.2))</span></pre><p id="3d53" class="pw-post-body-paragraph lh li jj lj b lk ll kt lm ln lo kw lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">不同类别的显式正则化:</p><ul class=""><li id="68a4" class="nk nl jj lj b lk ll ln lo lq pf lu pg ly ph mc pi ns nt nu bi translated">提前停止</li><li id="75c5" class="nk nl jj lj b lk nv ln nw lq nx lu ny ly nz mc pi ns nt nu bi translated">重量衰减</li><li id="b2f9" class="nk nl jj lj b lk nv ln nw lq nx lu ny ly nz mc pi ns nt nu bi translated">参数数量</li><li id="050d" class="nk nl jj lj b lk nv ln nw lq nx lu ny ly nz mc pi ns nt nu bi translated">最大范数约束</li></ul><h1 id="1e18" class="or mt jj bd mu os pj ou mx ov pk ox na ky pl kz nd lb pm lc ng le pn lf nj pb bi translated">提前停止</h1><p id="5b3d" class="pw-post-body-paragraph lh li jj lj b lk nm kt lm ln nn kw lp lq pc ls lt lu pd lw lx ly pe ma mb mc im bi translated">过拟合是机器学习和深度学习中常见的问题。有几种方法可以避免这类问题，早期停止是其中之一。它会提前停止这个过程。</p><p id="f427" class="pw-post-body-paragraph lh li jj lj b lk ll kt lm ln lo kw lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">代码片段实现:</p><pre class="pp pq pr ps gt py pz qa qb aw qc bi"><span id="eede" class="ms mt jj pz b gy qd qe l qf qg">from keras.callbacks import EarlyStopping</span><span id="ff14" class="ms mt jj pz b gy qh qe l qf qg">earlystop = EarlyStopping(monitor = 'val_loss', min_delta = 0, </span><span id="e879" class="ms mt jj pz b gy qh qe l qf qg">patience = 3, verbose = 1, restore_best_weights = True)</span></pre><p id="54d3" class="pw-post-body-paragraph lh li jj lj b lk ll kt lm ln lo kw lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">以上代码的解释:</p><ul class=""><li id="de46" class="nk nl jj lj b lk ll ln lo lq pf lu pg ly ph mc pi ns nt nu bi translated"><strong class="lj jt">监控:</strong>监控数值。即val_loss</li><li id="9417" class="nk nl jj lj b lk nv ln nw lq nx lu ny ly nz mc pi ns nt nu bi translated"><strong class="lj jt"> min_delta: </strong>为监控值。例如，如果min_delta = 1，则意味着如果监控值的绝对变化小于1 [ <a class="ae jg" href="https://www.kdnuggets.com/2019/08/keras-callbacks-explained-three-minutes.html" rel="noopener ugc nofollow" target="_blank"> 12 </a> ]，则训练过程将停止。</li><li id="cc29" class="nk nl jj lj b lk nv ln nw lq nx lu ny ly nz mc pi ns nt nu bi translated"><strong class="lj jt">耐心:</strong>如果经过一定次数的历元仍无改善，将停止训练。</li><li id="285a" class="nk nl jj lj b lk nv ln nw lq nx lu ny ly nz mc pi ns nt nu bi translated"><strong class="lj jt"> restore_best_weights: </strong>如果它的值设置为true，那么它会在停止后保持最佳权重。</li></ul><h1 id="d39a" class="or mt jj bd mu os pj ou mx ov pk ox na ky pl kz nd lb pm lc ng le pn lf nj pb bi translated">结论</h1><p id="1bd9" class="pw-post-body-paragraph lh li jj lj b lk nm kt lm ln nn kw lp lq pc ls lt lu pd lw lx ly pe ma mb mc im bi translated">卷积神经网络是一种特殊的多层神经网络，主要用于提取特征。它们通过非常简单的处理直接从像素图像中识别视觉模式。</p><p id="3007" class="pw-post-body-paragraph lh li jj lj b lk ll kt lm ln lo kw lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">CNN使用称为<strong class="lj jt">卷积</strong>和<strong class="lj jt">汇集</strong>的两种操作来将图像缩减为其基本特征，并使用这些特征来理解和适当地分类图像[ <a class="ae jg" href="https://kgptalkie.com/2d-cnn-in-tensorflow-2-0-on-cifar-10-object-recognition-in-images/" rel="noopener ugc nofollow" target="_blank"> 6 </a> ]。</p><p id="d59e" class="pw-post-body-paragraph lh li jj lj b lk ll kt lm ln lo kw lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">CNN的另一个好处是，与具有相同数量隐藏单元的全连接网络相比，它们更容易训练，参数更少。</p><p id="ee74" class="pw-post-body-paragraph lh li jj lj b lk ll kt lm ln lo kw lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">卷积神经网络(CNN)被用于各种领域，如医疗保健，诊断肺炎、糖尿病和乳腺癌等疾病，自动驾驶汽车，监视监控等[ <a class="ae jg" href="https://theappsolutions.com/blog/development/convolutional-neural-networks/" rel="noopener ugc nofollow" target="_blank"> 7 </a> ]。</p></div><div class="ab cl ok ol hx om" role="separator"><span class="on bw bk oo op oq"/><span class="on bw bk oo op oq"/><span class="on bw bk oo op"/></div><div class="im in io ip iq"><p id="1b84" class="pw-post-body-paragraph lh li jj lj b lk ll kt lm ln lo kw lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated"><strong class="lj jt">免责声明:</strong>本文表达的观点仅代表作者个人观点，不代表卡内基梅隆大学或其他(直接或间接)与作者相关的公司的观点。这些文章并不打算成为最终产品，而是当前思想的反映，同时也是讨论和改进的催化剂。</p><p id="5ac8" class="pw-post-body-paragraph lh li jj lj b lk ll kt lm ln lo kw lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated"><strong class="lj jt">除非另有说明，所有图片均来自作者。</strong></p><p id="1e91" class="pw-post-body-paragraph lh li jj lj b lk ll kt lm ln lo kw lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">通过<a class="ae jg" href="https://towardsai.net/" rel="noopener ugc nofollow" target="_blank">向AI </a>发布</p><h1 id="c6be" class="or mt jj bd mu os pj ou mx ov pk ox na ky pl kz nd lb pm lc ng le pn lf nj pb bi translated">资源</h1><p id="0d73" class="pw-post-body-paragraph lh li jj lj b lk nm kt lm ln nn kw lp lq pc ls lt lu pd lw lx ly pe ma mb mc im bi translated"><a class="ae jg" href="https://github.com/towardsai/tutorials/tree/master/convolutional-neural-networks-python" rel="noopener ugc nofollow" target="_blank"> Github库</a>。</p><p id="d388" class="pw-post-body-paragraph lh li jj lj b lk ll kt lm ln lo kw lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated"><a class="ae jg" href="https://colab.research.google.com/drive/1OLBEe0LwK9DcyzInOSDBmPp_Z5udLyqI?usp=sharing" rel="noopener ugc nofollow" target="_blank"> Google colab实现</a>。</p><h1 id="ee0b" class="or mt jj bd mu os pj ou mx ov pk ox na ky pl kz nd lb pm lc ng le pn lf nj pb bi translated">参考</h1><p id="7dcc" class="pw-post-body-paragraph lh li jj lj b lk nm kt lm ln nn kw lp lq pc ls lt lu pd lw lx ly pe ma mb mc im bi translated">[1]图像、语音和时间序列的卷积网络，Yann Lecun，Yoshua Bengio，<a class="ae jg" href="https://www.researchgate.net/profile/Yann_Lecun/publication/2453996_Convolutional_Networks_for_Images_Speech_and_Time-Series/links/0deec519dfa2325502000000.pdf" rel="noopener ugc nofollow" target="_blank">https://www . research gate . net/profile/Yann _ le Cun/publication/2453996 _ Convolutional _ Networks _ for _ Images _ Speech _ and _ Time-Series/links/0 deec 519 DFA 232550200000 . pdf</a></p><p id="3c14" class="pw-post-body-paragraph lh li jj lj b lk ll kt lm ln lo kw lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">[2]基于中医哲学和深度学习的体质分类，李永辉，Muhammad Saqlain Aslam *，杨凯琳，高忠安，和Shin-You Teng，<a class="ae jg" href="https://doi.org/10.3390/sym12050803" rel="noopener ugc nofollow" target="_blank">https://doi.org/10.3390/sym12050803</a></p><p id="9931" class="pw-post-body-paragraph lh li jj lj b lk ll kt lm ln lo kw lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">[3]卷积神经网络，维基百科，<a class="ae jg" href="https://en.wikipedia.org/wiki/Convolutional_neural_network" rel="noopener ugc nofollow" target="_blank">https://en.wikipedia.org/wiki/Convolutional_neural_network</a></p><p id="297d" class="pw-post-body-paragraph lh li jj lj b lk ll kt lm ln lo kw lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">[4]神经网络的主要类型及其应用—教程，普拉蒂克·舒克拉，罗伯特·伊里翁多，<a class="ae jg" href="https://towardsai.net/p/machine-learning/main-types-of-neural-networks-and-its-applications-tutorial-734480d7ec8e" rel="noopener ugc nofollow" target="_blank">https://toward sai . net/p/machine-learning/Main-Types-of-Neural-Networks-and-Its-Applications—教程-734480d7ec8e </a></p><p id="231b" class="pw-post-body-paragraph lh li jj lj b lk ll kt lm ln lo kw lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">[5]分解一下:关于机器学习的问答，谷歌，【https://www.google.com/about/main/machine-learning-qa/ T4】</p><p id="8517" class="pw-post-body-paragraph lh li jj lj b lk ll kt lm ln lo kw lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">[6]2D CNN in tensor flow 2.0 on CIFAR-10—图像中的物体识别，KGP有声，<a class="ae jg" href="https://kgptalkie.com/2d-cnn-in-tensorflow-2-0-on-cifar-10-object-recognition-in-images/" rel="noopener ugc nofollow" target="_blank">https://kgptalkie . com/2d-CNN-in-tensor flow-2-0-on-CIFAR-10-Object-Recognition-in-Images/</a></p><p id="fc8a" class="pw-post-body-paragraph lh li jj lj b lk ll kt lm ln lo kw lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">[7]卷积神经网络的商业应用，App Solutions，<a class="ae jg" href="https://theappsolutions.com/blog/development/convolutional-neural-networks/" rel="noopener ugc nofollow" target="_blank">https://theapp Solutions . com/blog/development/convolutionary-Neural-Networks/</a></p><p id="1dfe" class="pw-post-body-paragraph lh li jj lj b lk ll kt lm ln lo kw lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">[8]卷积的概念，TutorialsPoint，<a class="ae jg" href="https://www.tutorialspoint.com/dip/concept_of_convolution.htm" rel="noopener ugc nofollow" target="_blank">https://www . TutorialsPoint . com/dip/Concept _ of _ Convolution . htm</a></p><p id="91d2" class="pw-post-body-paragraph lh li jj lj b lk ll kt lm ln lo kw lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">[9]卷积神经网络，维基百科，<a class="ae jg" href="https://en.wikipedia.org/wiki/Convolutional_neural_network" rel="noopener ugc nofollow" target="_blank">https://en.wikipedia.org/wiki/Convolutional_neural_network</a></p><p id="3445" class="pw-post-body-paragraph lh li jj lj b lk ll kt lm ln lo kw lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">[10] Keras卷积神经网络与Python，Sagar Jaiswal，Github，<a class="ae jg" href="https://github.com/sagar448/Keras-Convolutional-Neural-Network-Python" rel="noopener ugc nofollow" target="_blank">https://Github . com/Sagar 448/Keras-convolutionary-Neural-Network-Python</a></p><p id="2493" class="pw-post-body-paragraph lh li jj lj b lk ll kt lm ln lo kw lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">[11]使用CNN的尼泊尔语手写字符识别，AI DEV Nepal，<a class="ae jg" href="https://www.aidevnepal.co/nepali-handwritten-character-recognition-using-cnn/" rel="noopener ugc nofollow" target="_blank">https://www . aidev Nepal . co/Nepali-handled-Character-Recognition-using-CNN/</a></p><p id="36f2" class="pw-post-body-paragraph lh li jj lj b lk ll kt lm ln lo kw lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">[12] Keras回调三分钟讲解，Andre Duong，KDnuggets，<a class="ae jg" href="https://www.kdnuggets.com/2019/08/keras-callbacks-explained-three-minutes.html" rel="noopener ugc nofollow" target="_blank">https://www . kdnugges . com/2019/08/Keras-Callbacks-Explained-Three-Minutes . html</a></p><p id="7375" class="pw-post-body-paragraph lh li jj lj b lk ll kt lm ln lo kw lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">[13]，，邢克罗，，窦，“利用深度学习对计算机断层图像上的肺结节进行分类”，<em class="rb">《医疗保健工程杂志》</em>，第2017卷，文章ID 8314740，7页，2017。https://doi.org/10.1155/2017/8314740<a class="ae jg" href="https://doi.org/10.1155/2017/8314740" rel="noopener ugc nofollow" target="_blank"/></p></div></div>    
</body>
</html>