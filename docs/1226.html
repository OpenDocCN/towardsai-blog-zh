<html>
<head>
<title>5 Steps to Build a KNN Classifier</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">构建KNN分类器的5个步骤</h1>
<blockquote>原文：<a href="https://pub.towardsai.net/5-steps-to-build-a-knn-classifier-d0fd102b28b5?source=collection_archive---------3-----------------------#2020-12-07">https://pub.towardsai.net/5-steps-to-build-a-knn-classifier-d0fd102b28b5?source=collection_archive---------3-----------------------#2020-12-07</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><h2 id="10f7" class="ir is it bd b dl iu iv iw ix iy iz dk ja translated" aria-label="kicker paragraph"><a class="ae ep" href="https://towardsai.net/p/category/machine-learning" rel="noopener ugc nofollow" target="_blank">机器学习</a>，<a class="ae ep" href="https://towardsai.net/p/category/programming" rel="noopener ugc nofollow" target="_blank">编程</a></h2><div class=""/><div class=""><h2 id="9e1f" class="pw-subtitle-paragraph jz jc it bd b ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq dk translated">使用Python和sci-kit，学习构建一个简单的k近邻分类。</h2></div><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi kr"><img src="../Images/00321671c70bf4af251536b453d2f2d9.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*_OZqWvXueI7Tfp3O"/></div></div><figcaption class="ld le gj gh gi lf lg bd b be z dk translated">照片由<a class="ae lh" href="https://unsplash.com/@jontyson?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">乔恩·泰森</a>在<a class="ae lh" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>拍摄</figcaption></figure><p id="3566" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi me translated"><span class="l mf mg mh bm mi mj mk ml mm di">T</span>he<a class="ae lh" href="https://en.wikipedia.org/wiki/K-nearest_neighbors_algorithm" rel="noopener ugc nofollow" target="_blank">k-最近邻算法</a>适用于不同的分类和回归问题。最接近的k个训练样本用于预测新输入数据的类别，即，已知的最相似样本用于对未知数据样本进行分类。由于sci-kit库提供了处理该算法的所有必要工具，您可以使用这5个步骤在Python中构建自己的KNN分类器！</p><h1 id="0893" class="mn mo it bd mp mq mr ms mt mu mv mw mx ki my kj mz kl na km nb ko nc kp nd ne bi translated">1.导入库并获取数据</h1><p id="2dcb" class="pw-post-body-paragraph li lj it lk b ll nf kd ln lo ng kg lq lr nh lt lu lv ni lx ly lz nj mb mc md im bi translated">重要的事情先来。像往常一样，从导入所有必需的库开始。然后，使用pandas的<em class="nk"> read_csv </em>方法导入一个表。该命令构建了一个易于处理的数据框，并降低了处理数据集的复杂性。</p><pre class="ks kt ku kv gt nl nm nn no aw np bi"><span id="3d24" class="nq mo it nm b gy nr ns l nt nu">import pandas as pd<br/>import numpy as np<br/>import matplotlib.pyplot as plt</span><span id="cb22" class="nq mo it nm b gy nv ns l nt nu">df = pd.read_csv(‘KNN_Project_Data.csv’)</span></pre><p id="7255" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">本例中使用的<a class="ae lh" href="https://www.kaggle.com/tbyrnes/knn-project-data" rel="noopener ugc nofollow" target="_blank">KNN _项目_数据. csv </a>模板由<a class="ae lh" href="https://www.kaggle.com/" rel="noopener ugc nofollow" target="_blank"> Kaggle </a>提供。各种数据集都托管在那里，可以免费下载。然而，它可以被替换为您希望用于此KNN分类器的任何其他表。</p><p id="aee9" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">Pandas的head方法允许快速检查数据帧是否像预期的那样，以及导入是否正确运行。</p><pre class="ks kt ku kv gt nl nm nn no aw np bi"><span id="2280" class="nq mo it nm b gy nr ns l nt nu">df.head()</span></pre><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi nw"><img src="../Images/28624dd768f7a18c99f36bd8ebfd1695.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*KbsqZpF-tXJ2pECE698AGQ.png"/></div></div><figcaption class="ld le gj gh gi lf lg bd b be z dk translated">图片由作者提供。</figcaption></figure><h1 id="1272" class="mn mo it bd mp mq mr ms mt mu mv mw mx ki my kj mz kl na km nb ko nc kp nd ne bi translated">2.标准化</h1><p id="aefd" class="pw-post-body-paragraph li lj it lk b ll nf kd ln lo ng kg lq lr nh lt lu lv ni lx ly lz nj mb mc md im bi translated">在这个预处理步骤中，数据为进一步的分析做准备。因此，有必要导入<em class="nk">标准缩放器</em>并从中创建一个对象。然后，使缩放器适合特性，但是不要包括“目标类”,因为这是我们的输出类。现在,<em class="nk"> transform() </em>方法转换要素的缩放版本，随后，我们再次创建熊猫数据框。和以前一样，使用<em class="nk"> head() </em>方法检查是否一切正常。</p><pre class="ks kt ku kv gt nl nm nn no aw np bi"><span id="c572" class="nq mo it nm b gy nr ns l nt nu">from sklearn.preprocessing import StandardScaler</span><span id="7118" class="nq mo it nm b gy nv ns l nt nu">scaler = StandardScaler()<br/>scaler.fit(df.drop('TARGET CLASS',axis=1))<br/>scaled_features = scaler.transform(df.drop('TARGET CLASS',axis=1))<br/>df_feat = pd.DataFrame(scaled_features,columns=df.columns[:-1])</span><span id="73d4" class="nq mo it nm b gy nv ns l nt nu">df_feat.head()</span></pre><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi nx"><img src="../Images/23530beae1eb667d26b63e64f4cbb189.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*s55vFOAbOzSTVOHMulpzjQ.png"/></div></div><figcaption class="ld le gj gh gi lf lg bd b be z dk translated">图片由作者提供。</figcaption></figure><h1 id="3778" class="mn mo it bd mp mq mr ms mt mu mv mw mx ki my kj mz kl na km nb ko nc kp nd ne bi translated">3.列车测试分离</h1><p id="6c82" class="pw-post-body-paragraph li lj it lk b ll nf kd ln lo ng kg lq lr nh lt lu lv ni lx ly lz nj mb mc md im bi translated">要分割数据集，导入<em class="nk"> train_test_split </em>函数。我们选择25%的测试规模，而数据集的另外75%用于训练。结果，我们得到4个变量:<em class="nk"> X_train </em>和<em class="nk"> X_test。</em>这些是未来的输入变量，而<em class="nk"> y_train </em>和<em class="nk"> y_test </em>标记输出。</p><pre class="ks kt ku kv gt nl nm nn no aw np bi"><span id="f277" class="nq mo it nm b gy nr ns l nt nu">from sklearn.model_selection import train_test_split</span><span id="2c1c" class="nq mo it nm b gy nv ns l nt nu">X_train, X_test, y_train, y_test = train_test_split(scaled_features, df[‘TARGET CLASS’], test_size=0.25)</span></pre><h1 id="98bf" class="mn mo it bd mp mq mr ms mt mu mv mw mx ki my kj mz kl na km nb ko nc kp nd ne bi translated">4.建立模型</h1><p id="5408" class="pw-post-body-paragraph li lj it lk b ll nf kd ln lo ng kg lq lr nh lt lu lv ni lx ly lz nj mb mc md im bi translated">为了构建模型，我们需要导入<em class="nk"> KNeighborsClassifier。</em>我们用它创建一个对象，并选择邻居的数量为3。这是一个任意的选择，我们可以在后面的阶段看到如何通过迭代不同的值得到一些性能更好的值。同时，<em class="nk"> fit() </em>方法训练我们的KNN模型。</p><pre class="ks kt ku kv gt nl nm nn no aw np bi"><span id="a083" class="nq mo it nm b gy nr ns l nt nu">from sklearn.neighbors import KNeighborsClassifier</span><span id="9dc1" class="nq mo it nm b gy nv ns l nt nu">knn = KNeighborsClassifier(n_neighbors=3)<br/>knn.fit(X_train,y_train)</span></pre><h1 id="9875" class="mn mo it bd mp mq mr ms mt mu mv mw mx ki my kj mz kl na km nb ko nc kp nd ne bi translated">5.评估模型</h1><p id="efc3" class="pw-post-body-paragraph li lj it lk b ll nf kd ln lo ng kg lq lr nh lt lu lv ni lx ly lz nj mb mc md im bi translated">最后，建立模型，输入数据，并进行训练。有不同的方法来评估我们的模型，但是在这个例子中，我们坚持使用<a class="ae lh" href="https://www.scikit-yb.org/en/latest/api/classifier/classification_report.html" rel="noopener ugc nofollow" target="_blank">分类报告</a>、<a class="ae lh" href="https://www.scikit-yb.org/en/latest/api/classifier/confusion_matrix.html?highlight=confusion%20matrix" rel="noopener ugc nofollow" target="_blank">混淆矩阵</a>和<a class="ae lh" href="https://www.scikit-yb.org/en/latest/api/model_selection/cross_validation.html?highlight=accuracy#classification" rel="noopener ugc nofollow" target="_blank">准确度分数</a>。为此，从sci-kit中导入它们。然后，使用您的模型预测值，将创建的测试集作为输入，并打印结果。</p><pre class="ks kt ku kv gt nl nm nn no aw np bi"><span id="edc2" class="nq mo it nm b gy nr ns l nt nu">from sklearn.metrics import classification_report<br/>from sklearn.metrics import confusion_matrix<br/>from sklearn.metrics import accuracy_score</span><span id="6f70" class="nq mo it nm b gy nv ns l nt nu">pred = knn.predict(X_test)</span><span id="3417" class="nq mo it nm b gy nv ns l nt nu">print(confusion_matrix(y_test,pred))<br/>print(‘Accuracy score: ‘+ str(accuracy_score(y_test,pred)))<br/>print(classification_report(y_test,pred))</span></pre><p id="684d" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">结果，我们得到以下输出:</p><pre class="ks kt ku kv gt nl nm nn no aw np bi"><span id="607c" class="nq mo it nm b gy nr ns l nt nu">[[101  21]<br/> [ 23 105]]</span><span id="6116" class="nq mo it nm b gy nv ns l nt nu">Test accuracy score: 0.824</span><span id="0c3e" class="nq mo it nm b gy nv ns l nt nu">                precision    recall  f1-score   support<br/><br/>           0       0.81      0.83      0.82       122<br/>           1       0.83      0.82      0.83       128<br/><br/>    accuracy                           0.82       250<br/>   macro avg       0.82      0.82      0.82       250<br/>weighted avg       0.82      0.82      0.82       250</span></pre><h1 id="b337" class="mn mo it bd mp mq mr ms mt mu mv mw mx ki my kj mz kl na km nb ko nc kp nd ne bi translated">奖励:选择K值</h1><p id="b6aa" class="pw-post-body-paragraph li lj it lk b ll nf kd ln lo ng kg lq lr nh lt lu lv ni lx ly lz nj mb mc md im bi translated">因为k的任意选择不太可能是最佳的，所以使用循环并检查更好的选择是改善结果的简单方法。</p><pre class="ks kt ku kv gt nl nm nn no aw np bi"><span id="979f" class="nq mo it nm b gy nr ns l nt nu">error_rate = []</span><span id="4d2d" class="nq mo it nm b gy nv ns l nt nu">for i in range(1,15):<br/>     knn = KNeighborsClassifier(n_neighbors=i)<br/>     knn.fit(X_train,y_train)<br/>     pred_i = knn.predict(X_test)<br/>     error_rate.append(np.mean(pred_i != y_test))</span><span id="ea04" class="nq mo it nm b gy nv ns l nt nu">plt.plot(range(1,15), error_rate, linestyle='dashed', marker='x', markersize=10)<br/>plt.title('Comparison K Value')<br/>plt.xlabel('K')<br/>plt.ylabel('Error')</span></pre><p id="f474" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">通过绘制误差率，很明显我们对k=3的任意选择并不是最佳选择。相反，通过设置k=7可以显著降低错误率。</p><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div class="gh gi ny"><img src="../Images/26b9652125593052fbd37abc961a5601.png" data-original-src="https://miro.medium.com/v2/resize:fit:1230/format:webp/1*NKsryESJaKw3bXmrbQpsew.png"/></div><figcaption class="ld le gj gh gi lf lg bd b be z dk translated">图片由作者提供。</figcaption></figure><h1 id="e570" class="mn mo it bd mp mq mr ms mt mu mv mw mx ki my kj mz kl na km nb ko nc kp nd ne bi translated">结论</h1><p id="3846" class="pw-post-body-paragraph li lj it lk b ll nf kd ln lo ng kg lq lr nh lt lu lv ni lx ly lz nj mb mc md im bi translated">Python和sci-kit学习构建第一个KNN分类算法的简单工具。只需要5个步骤，而大量的数据集可以在互联网上找到，比如在<a class="ae lh" href="https://www.kaggle.com/" rel="noopener ugc nofollow" target="_blank"> Kaggle </a>上。为了改善结果，通过不同数量的最近邻值的简单迭代表明，任意选择可能不是最好的。因此，回头，调整k值，你的KNN分类器就准备好了。</p></div><div class="ab cl nz oa hx ob" role="separator"><span class="oc bw bk od oe of"/><span class="oc bw bk od oe of"/><span class="oc bw bk od oe"/></div><div class="im in io ip iq"><p id="606a" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">你对这个话题有什么想法或见解？我很好奇，靠近我！</p></div></div>    
</body>
</html>