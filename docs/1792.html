<html>
<head>
<title>The NLP Cypher | 04.25.21</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">NLP密码| 04.25.21</h1>
<blockquote>原文：<a href="https://pub.towardsai.net/the-nlp-cypher-04-25-21-eec02a889e5e?source=collection_archive---------2-----------------------#2021-04-26">https://pub.towardsai.net/the-nlp-cypher-04-25-21-eec02a889e5e?source=collection_archive---------2-----------------------#2021-04-26</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><figure class="ip iq gp gr ir is gh gi paragraph-image"><div class="gh gi io"><img src="../Images/b81e3ddab4e6d1a9fc70237950f127a0.png" data-original-src="https://miro.medium.com/v2/resize:fit:726/format:webp/0*N_TUk0ey0HIt9Hs4.jpg"/></div><figcaption class="iv iw gj gh gi ix iy bd b be z dk translated">圣米迦勒压倒恶魔|拉斐尔</figcaption></figure><h2 id="045c" class="iz ja jb bd b dl jc jd je jf jg jh dk ji translated" aria-label="kicker paragraph">自然语言处理每周时事通讯</h2><div class=""/><div class=""><h2 id="e1cf" class="pw-subtitle-paragraph kh jk jb bd b ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky dk translated">不要让步</h2></div></div><div class="ab cl kz la hu lb" role="separator"><span class="lc bw bk ld le lf"/><span class="lc bw bk ld le lf"/><span class="lc bw bk ld le"/></div><div class="ij ik il im in"><p id="b766" class="pw-post-body-paragraph lg lh jb li b lj lk kl ll lm ln ko lo lp lq lr ls lt lu lv lw lx ly lz ma mb ij bi translated">在以前的NLP密码版本中，我已经表明了我对神秘线索和谜题的渴望，作为NLP模型的推理挑战。其基本原理是，如果NLP模型可以在需要n阶逻辑来解决的任务上接近人类的表现，那么就可以开辟一条新的表现途径，而不仅仅是句法的模式识别(这是SOTA语言模型的当前缺陷)。</p><p id="d7dd" class="pw-post-body-paragraph lg lh jb li b lj lk kl ll lm ln ko lo lp lq lr ls lt lu lv lw lx ly lz ma mb ij bi translated">本周的一篇新论文提供了一个新的数据集，其中充满了神秘的纵横字谜(不要与传统的纵横字谜混淆)线索和使用T5模型的基准测试结果。虽然这项研究不会很快对企业中的应用深度学习产生直接影响，但任何使NLP模型在这些类型的任务中更接近人类水平的表现的结果都将是人工智能的重要一步。</p><p id="f867" class="pw-post-body-paragraph lg lh jb li b lj lk kl ll lm ln ko lo lp lq lr ls lt lu lv lw lx ly lz ma mb ij bi translated"><a class="ae mc" href="https://arxiv.org/pdf/2104.08620.pdf" rel="noopener ugc nofollow" target="_blank">论文</a></p><div class="ip iq gp gr ir md"><a href="https://github.com/jsrozner/decrypt" rel="noopener  ugc nofollow" target="_blank"><div class="me ab fo"><div class="mf ab mg cl cj mh"><h2 class="bd jl gy z fp mi fr fs mj fu fw jk bi translated">jsrozner/decrypt</h2><div class="mk l"><h3 class="bd b gy z fp mi fr fs mj fu fw dk translated">用于解密加密纵横字谜的文件库</h3></div><div class="ml l"><p class="bd b dl z fp mi fr fs mj fu fw dk translated">github.com</p></div></div><div class="mm l"><div class="mn l mo mp mq mm mr it md"/></div></div></a></div><h1 id="01d1" class="ms mt jb bd mu mv mw mx my mz na nb nc kq nd kr ne kt nf ku ng kw nh kx ni nj bi translated">即时调优| NLP训练的下一个前沿？</h1><p id="d3e3" class="pw-post-body-paragraph lg lh jb li b lj nk kl ll lm nl ko lo lp nm lr ls lt nn lv lw lx no lz ma mb ij bi translated">如果你训练模型，这是一篇重要的文章。展示了微调的天数是如何计算的，因为快速调优可能是调优大型语言模型的一种更有效的方法。提示调优允许用户使用冻结的模型，并且只调优文本提示(与改变整个模型的模型调优((又名微调))相反)。</p><p id="ffb6" class="pw-post-body-paragraph lg lh jb li b lj lk kl ll lm ln ko lo lp lq lr ls lt lu lv lw lx ly lz ma mb ij bi translated">这意味着我们不必为每个新的NLP任务训练一个新的模型副本！本文展示了如何克服先前涉及快速转向的障碍，使其与传统微调不相上下或具有竞争力。此外，即时调优的简单性有助于防止畴变。🧐</p><p id="396c" class="pw-post-body-paragraph lg lh jb li b lj lk kl ll lm ln ko lo lp lq lr ls lt lu lv lw lx ly lz ma mb ij bi translated">这篇文章让我想起了多任务学习是怎么回事，其中适配器在使用冻结模型时有一种“类似”的方法，并且只有适配器针对每个任务进行了微调(这不是即时调优，但在使用冻结模型以提高效率/灵活性的意义上是类似的)。之后，您可以为各种任务堆叠适配器，并使用冻结模型进行嵌入。在之前的NLP密码中，我采访了<a class="ae mc" href="https://adapterhub.ml/" rel="noopener ugc nofollow" target="_blank">适配器中枢</a>的主要作者Jonas Pfeiffer。</p><figure class="np nq nr ns gt is"><div class="bz fp l di"><div class="nt nu l"/></div><figcaption class="iv iw gj gh gi ix iy bd b be z dk translated"><a class="ae mc" href="https://arxiv.org/pdf/2104.08691.pdf" rel="noopener ugc nofollow" target="_blank">链接</a></figcaption></figure><h1 id="6bfb" class="ms mt jb bd mu mv mw mx my mz na nb nc kq nd kr ne kt nf ku ng kw nh kx ni nj bi translated">闪电变压器</h1><p id="b3be" class="pw-post-body-paragraph lg lh jb li b lj nk kl ll lm nl ko lo lp nm lr ls lt nn lv lw lx no lz ma mb ij bi translated">PyTorch Lightning合并了变形金刚库和九头蛇框架。🥶:使用起来相当简单。</p><p id="0f47" class="pw-post-body-paragraph lg lh jb li b lj lk kl ll lm ln ko lo lp lq lr ls lt lu lv lw lx ly lz ma mb ij bi translated">以下是电梯间推介:</p><ul class=""><li id="efb9" class="nv nw jb li b lj lk lm ln lp nx lt ny lx nz mb oa ob oc od bi translated">使用<a class="ae mc" href="https://github.com/huggingface/transformers" rel="noopener ugc nofollow" target="_blank"> HuggingFace Transformers </a>模型和数据集进行训练，带有Lightning自定义回调、记录器、加速器和高性能扩展。</li><li id="42eb" class="nv nw jb li b lj oe lm of lp og lt oh lx oi mb oa ob oc od bi translated">无缝内存和速度优化，如<a class="ae mc" href="https://pytorch-lightning.readthedocs.io/en/latest/multi_gpu.html#deepspeed" rel="noopener ugc nofollow" target="_blank"> DeepSpeed ZeRO </a>或<a class="ae mc" href="https://pytorch-lightning.readthedocs.io/en/latest/multi_gpu.html#sharded-training" rel="noopener ugc nofollow" target="_blank">fair scale shared Training</a>，无需更改代码。</li><li id="ba83" class="nv nw jb li b lj oe lm of lp og lt oh lx oi mb oa ob oc od bi translated">由<a class="ae mc" href="https://hydra.cc/" rel="noopener ugc nofollow" target="_blank"> Hydra </a>支持的强大配置组合——无需接触代码即可轻松更换模型、优化器、调度器和更多配置。</li><li id="f12d" class="nv nw jb li b lj oe lm of lp og lt oh lx oi mb oa ob oc od bi translated">用于快速研究和实验的Transformer任务抽象——该库从头开始构建，与任务无关，支持几乎没有摩擦地跨所有模态创建transformer任务。</li></ul><p id="a301" class="pw-post-body-paragraph lg lh jb li b lj lk kl ll lm ln ko lo lp lq lr ls lt lu lv lw lx ly lz ma mb ij bi translated"><strong class="li jl">代码</strong></p><div class="ip iq gp gr ir md"><a href="https://github.com/PyTorchLightning/lightning-transformers" rel="noopener  ugc nofollow" target="_blank"><div class="me ab fo"><div class="mf ab mg cl cj mh"><h2 class="bd jl gy z fp mi fr fs mj fu fw jk bi translated">手电筒/闪电变压器</h2><div class="mk l"><h3 class="bd b gy z fp mi fr fs mj fu fw dk translated">选项1:从PyPI pip安装lightning-transformers #而不是:` python train.py...`，和…一起跑</h3></div><div class="ml l"><p class="bd b dl z fp mi fr fs mj fu fw dk translated">github.com</p></div></div><div class="mm l"><div class="oj l mo mp mq mm mr it md"/></div></div></a></div><p id="5427" class="pw-post-body-paragraph lg lh jb li b lj lk kl ll lm ln ko lo lp lq lr ls lt lu lv lw lx ly lz ma mb ij bi translated"><strong class="li jl">文档</strong></p><div class="ip iq gp gr ir md"><a href="https://lightning-transformers.readthedocs.io/en/latest/" rel="noopener  ugc nofollow" target="_blank"><div class="me ab fo"><div class="mf ab mg cl cj mh"><h2 class="bd jl gy z fp mi fr fs mj fu fw jk bi translated">雷电变压器.雷电变压器文件</h2><div class="mk l"><h3 class="bd b gy z fp mi fr fs mj fu fw dk translated">闪电变压器提供了一个灵活的界面，培训和微调SOTA变压器模型使用…</h3></div><div class="ml l"><p class="bd b dl z fp mi fr fs mj fu fw dk translated">闪电变压器. readthedocs.io</p></div></div></div></a></div><p id="b53f" class="pw-post-body-paragraph lg lh jb li b lj lk kl ll lm ln ko lo lp lq lr ls lt lu lv lw lx ly lz ma mb ij bi translated"><strong class="li jl">博客</strong></p><div class="ip iq gp gr ir md"><a href="https://pytorch-lightning.medium.com/training-transformers-at-scale-with-pytorch-lightning-e1cb25f6db29" rel="noopener follow" target="_blank"><div class="me ab fo"><div class="mf ab mg cl cj mh"><h2 class="bd jl gy z fp mi fr fs mj fu fw jk bi translated">用PyTorch Lightning大规模训练变压器</h2><div class="mk l"><h3 class="bd b gy z fp mi fr fs mj fu fw dk translated">介绍闪电变压器，一个新的图书馆，无缝集成PyTorch闪电，拥抱脸…</h3></div><div class="ml l"><p class="bd b dl z fp mi fr fs mj fu fw dk translated">pytorch-lightning.medium.com</p></div></div><div class="mm l"><div class="ok l mo mp mq mm mr it md"/></div></div></a></div><h1 id="f558" class="ms mt jb bd mu mv mw mx my mz na nb nc kq nd kr ne kt nf ku ng kw nh kx ni nj bi translated">NLP食谱</h1><p id="fecd" class="pw-post-body-paragraph lg lh jb li b lj nk kl ll lm nl ko lo lp nm lr ls lt nn lv lw lx no lz ma mb ij bi translated">关于变压器最新技术的教育论文，比较不同变体的性能和使用案例。</p><p id="7bf8" class="pw-post-body-paragraph lg lh jb li b lj lk kl ll lm ln ko lo lp lq lr ls lt lu lv lw lx ly lz ma mb ij bi translated"><a class="ae mc" href="https://arxiv.org/ftp/arxiv/papers/2104/2104.10640.pdf" rel="noopener ugc nofollow" target="_blank">https://arxiv.org/ftp/arxiv/papers/2104/2104.10640.pdf</a></p><h1 id="b840" class="ms mt jb bd mu mv mw mx my mz na nb nc kq nd kr ne kt nf ku ng kw nh kx ni nj bi translated">金融中的NLP</h1><figure class="np nq nr ns gt is gh gi paragraph-image"><div role="button" tabindex="0" class="om on di oo bf op"><div class="gh gi ol"><img src="../Images/edce14678a3492a6e9feb2bd4c692d06.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*lEThlKb0rm90Y3n-.jpg"/></div></div></figure><p id="bf20" class="pw-post-body-paragraph lg lh jb li b lj lk kl ll lm ln ko lo lp lq lr ls lt lu lv lw lx ly lz ma mb ij bi translated">这篇路孚特实验室的博客在路透社的新闻档案中强调了他们对定制预训练版本的BERT的思考。</p><div class="ip iq gp gr ir md"><a href="https://perspectives.refinitiv.com/ai-digitalization/using-nlp-to-unlock-value-in-financial-services-terminology/" rel="noopener  ugc nofollow" target="_blank"><div class="me ab fo"><div class="mf ab mg cl cj mh"><h2 class="bd jl gy z fp mi fr fs mj fu fw jk bi translated">NLP:释放金融服务术语的价值|路孚特观点</h2><div class="mk l"><h3 class="bd b gy z fp mi fr fs mj fu fw dk translated">路孚特实验室已经用金融和商业新闻预先训练了一个自然语言处理(NLP)模型，以便它…</h3></div><div class="ml l"><p class="bd b dl z fp mi fr fs mj fu fw dk translated">perspectives.refinitiv.com</p></div></div><div class="mm l"><div class="oq l mo mp mq mm mr it md"/></div></div></a></div><h1 id="a4de" class="ms mt jb bd mu mv mw mx my mz na nb nc kq nd kr ne kt nf ku ng kw nh kx ni nj bi translated">人们多久复制粘贴一次堆栈溢出？</h1><p id="efb7" class="pw-post-body-paragraph lg lh jb li b lj nk kl ll lm nl ko lo lp nm lr ls lt nn lv lw lx no lz ma mb ij bi translated">他们向我们承诺会飞的汽车，但我们得到的是<em class="or">“每四个访问堆栈溢出问题的用户中，就有一个在访问页面的五分钟内复制了一些东西。”</em></p><p id="0fc2" class="pw-post-body-paragraph lg lh jb li b lj lk kl ll lm ln ko lo lp lq lr ls lt lu lv lw lx ly lz ma mb ij bi translated">如果你想知道我们在编码方面有多糟糕，看看这个博客吧。</p><p id="f7c4" class="pw-post-body-paragraph lg lh jb li b lj lk kl ll lm ln ko lo lp lq lr ls lt lu lv lw lx ly lz ma mb ij bi">😭😭😭😭</p><div class="ip iq gp gr ir md"><a href="https://stackoverflow.blog/2021/04/19/how-often-do-people-actually-copy-and-paste-from-stack-overflow-now-we-know/" rel="noopener  ugc nofollow" target="_blank"><div class="me ab fo"><div class="mf ab mg cl cj mh"><h2 class="bd jl gy z fp mi fr fs mj fu fw jk bi translated">人们从堆栈溢出中复制粘贴的频率有多高？现在我们知道了。-堆栈溢出博客</h2><div class="mk l"><h3 class="bd b gy z fp mi fr fs mj fu fw dk translated">他们说每个笑话背后都有一个真理的内核。就我们最近的愚人节玩笑而言，它可能更像是…</h3></div><div class="ml l"><p class="bd b dl z fp mi fr fs mj fu fw dk translated">stackoverflow.blog</p></div></div><div class="mm l"><div class="os l mo mp mq mm mr it md"/></div></div></a></div><h1 id="ea0c" class="ms mt jb bd mu mv mw mx my mz na nb nc kq nd kr ne kt nf ku ng kw nh kx ni nj bi translated">信息提取库</h1><p id="101a" class="pw-post-body-paragraph lg lh jb li b lj nk kl ll lm nl ko lo lp nm lr ls lt nn lv lw lx no lz ma mb ij bi translated">一个信息检索库，在内部使用基于Java的Terrier IR平台来支持索引和检索操作。以下是神经排序/密集检索的一些特征:</p><blockquote class="ot ou ov"><p id="2303" class="lg lh or li b lj lk kl ll lm ln ko lo ow lq lr ls ox lu lv lw oy ly lz ma mb ij bi translated">BERT(通过OpenNIR)、T5、ColBERT、ANCE、DeepCT和doc2query。</p></blockquote><p id="f60b" class="pw-post-body-paragraph lg lh jb li b lj lk kl ll lm ln ko lo lp lq lr ls lt lu lv lw lx ly lz ma mb ij bi translated">-OpenNIR: [ <a class="ae mc" href="https://github.com/Georgetown-IR-Lab/OpenNIR" rel="noopener ugc nofollow" target="_blank"> Github </a> ] [ <a class="ae mc" href="https://opennir.net/" rel="noopener ugc nofollow" target="_blank">文档</a></p><p id="8eb0" class="pw-post-body-paragraph lg lh jb li b lj lk kl ll lm ln ko lo lp lq lr ls lt lu lv lw lx ly lz ma mb ij bi translated">-py terrier _ ANCE:[<a class="ae mc" href="https://github.com/terrierteam/pyterrier_ance" rel="noopener ugc nofollow" target="_blank">Github</a>]—密集检索</p><p id="3a7d" class="pw-post-body-paragraph lg lh jb li b lj lk kl ll lm ln ko lo lp lq lr ls lt lu lv lw lx ly lz ma mb ij bi translated">-py terrier _ ColBERT:[<a class="ae mc" href="https://github.com/terrierteam/pyterrier_colbert" rel="noopener ugc nofollow" target="_blank">Github</a>]—密集检索和/或神经重新排序</p><p id="8722" class="pw-post-body-paragraph lg lh jb li b lj lk kl ll lm ln ko lo lp lq lr ls lt lu lv lw lx ly lz ma mb ij bi translated">-py terrier _ T5:[<a class="ae mc" href="https://github.com/terrierteam/pyterrier_t5" rel="noopener ugc nofollow" target="_blank">Github</a>]—神经重排序</p><p id="9625" class="pw-post-body-paragraph lg lh jb li b lj lk kl ll lm ln ko lo lp lq lr ls lt lu lv lw lx ly lz ma mb ij bi translated">-py terrier _ doc 2 query:[<a class="ae mc" href="https://github.com/terrierteam/pyterrier_doc2query" rel="noopener ugc nofollow" target="_blank">Github</a>]—神经增强索引</p><p id="0525" class="pw-post-body-paragraph lg lh jb li b lj lk kl ll lm ln ko lo lp lq lr ls lt lu lv lw lx ly lz ma mb ij bi translated">-py terrier _ DeepCT:[<a class="ae mc" href="https://github.com/terrierteam/pyterrier_deepct" rel="noopener ugc nofollow" target="_blank">Github</a>]—神经增强索引</p><div class="ip iq gp gr ir md"><a href="https://github.com/terrier-org/pyterrier" rel="noopener  ugc nofollow" target="_blank"><div class="me ab fo"><div class="mf ab mg cl cj mh"><h2 class="bd jl gy z fp mi fr fs mj fu fw jk bi translated">terrier-org/pyterrier</h2><div class="mk l"><h3 class="bd b gy z fp mi fr fs mj fu fw dk translated">PyTerrier的Python API开始使用py Terrier最简单的方法是使用我们的Colab笔记本——寻找…</h3></div><div class="ml l"><p class="bd b dl z fp mi fr fs mj fu fw dk translated">github.com</p></div></div><div class="mm l"><div class="oz l mo mp mq mm mr it md"/></div></div></a></div><h1 id="b238" class="ms mt jb bd mu mv mw mx my mz na nb nc kq nd kr ne kt nf ku ng kw nh kx ni nj bi translated">深度稀疏推理</h1><p id="9065" class="pw-post-body-paragraph lg lh jb li b lj nk kl ll lm nl ko lo lp nm lr ls lt nn lv lw lx no lz ma mb ij bi translated">来自Neural Magic的Mark Kurtz介绍了NM针对稀疏模型的深度稀疏推理机。该引擎希望模型以ONNX格式接收，然后通过其引擎在CPU上以惊人的速度运行它们。希望NLP将很快到来…🤞。(我刚才描述的是视频的结尾，开头是Nir Shavit对稀疏性和为什么它很棒的一个很酷的介绍)。</p><figure class="np nq nr ns gt is"><div class="bz fp l di"><div class="pa nu l"/></div></figure><h1 id="624a" class="ms mt jb bd mu mv mw mx my mz na nb nc kq nd kr ne kt nf ku ng kw nh kx ni nj bi translated">人工智能在企业中的采用2021</h1><p id="59a7" class="pw-post-body-paragraph lg lh jb li b lj nk kl ll lm nl ko lo lp nm lr ls lt nn lv lw lx no lz ma mb ij bi translated">奥赖利的调查出来了，有货:</p><blockquote class="ot ou ov"><p id="874a" class="lg lh or li b lj lk kl ll lm ln ko lo ow lq lr ls ox lu lv lw oy ly lz ma mb ij bi translated">我们收到的回复几乎是去年的三倍，推广力度也差不多。更多的人在用AI工作。</p><p id="afae" class="lg lh or li b lj lk kl ll lm ln ko lo ow lq lr ls ox lu lv lw oy ly lz ma mb ij bi translated">在过去，公司文化一直是人工智能采用的最大障碍。虽然它仍然是一个问题，文化已经下降到第四位。</p><p id="56e4" class="lg lh or li b lj lk kl ll lm ln ko lo ow lq lr ls ox lu lv lw oy ly lz ma mb ij bi translated">今年，人工智能采用的最大障碍是缺乏技术人员和招聘困难。这种短缺已经预测了好几年了；我们终于看到了。</p><p id="b415" class="lg lh or li b lj lk kl ll lm ln ko lo ow lq lr ls ox lu lv lw oy ly lz ma mb ij bi translated">第二大障碍是高质量数据的可用性。这种认识是这个领域正在成长的标志。</p><p id="a840" class="lg lh or li b lj lk kl ll lm ln ko lo ow lq lr ls ox lu lv lw oy ly lz ma mb ij bi translated">报告“成熟”实践的应答者的百分比在过去几年中大致相同。鉴于受访者数量的增加，这并不奇怪:我们怀疑许多组织刚刚开始他们的人工智能项目。</p><p id="0ddd" class="lg lh or li b lj lk kl ll lm ln ko lo ow lq lr ls ox lu lv lw oy ly lz ma mb ij bi translated">零售业领域的成熟实践比例最高；教育程度最低。但教育也是“考虑”人工智能的受访者比例最高的领域。</p><p id="b9c4" class="lg lh or li b lj lk kl ll lm ln ko lo ow lq lr ls ox lu lv lw oy ly lz ma mb ij bi translated">相对较少的回答者对数据和模型使用版本控制。对数据和模型进行版本控制的工具仍然不成熟，但它们对于使人工智能结果可重复和可靠来说是至关重要的。</p></blockquote><div class="ip iq gp gr ir md"><a href="https://www.oreilly.com/radar/ai-adoption-in-the-enterprise-2021/" rel="noopener  ugc nofollow" target="_blank"><div class="me ab fo"><div class="mf ab mg cl cj mh"><h2 class="bd jl gy z fp mi fr fs mj fu fw jk bi translated">人工智能在企业中的采用2021</h2><div class="mk l"><h3 class="bd b gy z fp mi fr fs mj fu fw dk translated">在二月的前几周，我们要求我们的数据和人工智能简讯的接收者参与一项关于人工智能的调查…</h3></div><div class="ml l"><p class="bd b dl z fp mi fr fs mj fu fw dk translated">www.oreilly.com</p></div></div><div class="mm l"><div class="pb l mo mp mq mm mr it md"/></div></div></a></div><h1 id="4780" class="ms mt jb bd mu mv mw mx my mz na nb nc kq nd kr ne kt nf ku ng kw nh kx ni nj bi translated">回购密码👨‍💻</h1><h2 id="3da0" class="pc mt jb bd mu pd pe dn my pf pg dp nc lp ph pi ne lt pj pk ng lx pl pm ni jh bi translated">一组最近发布的回购引起了我们的注意👁</h2></div><div class="ab cl kz la hu lb" role="separator"><span class="lc bw bk ld le lf"/><span class="lc bw bk ld le lf"/><span class="lc bw bk ld le"/></div><div class="ij ik il im in"><h2 id="0630" class="pc mt jb bd mu pd pe dn my pf pg dp nc lp ph pi ne lt pj pk ng lx pl pm ni jh bi translated">BEIR |信息检索任务的零射击基准</h2><blockquote class="ot ou ov"><p id="47d3" class="lg lh or li b lj lk kl ll lm ln ko lo ow lq lr ls ox lu lv lw oy ly lz ma mb ij bi translated">基准测试包括17个数据集，9个不同领域的任务。在零发射设置中评估的9个SOTA反演模型。</p></blockquote><div class="ip iq gp gr ir md"><a href="https://github.com/UKPLab/beir" rel="noopener  ugc nofollow" target="_blank"><div class="me ab fo"><div class="mf ab mg cl cj mh"><h2 class="bd jl gy z fp mi fr fs mj fu fw jk bi translated">UKPLab/beir</h2><div class="mk l"><h3 class="bd b gy z fp mi fr fs mj fu fw dk translated">BEIR是一个包含不同IR任务的异构基准。它还为…提供了一个通用而简单的框架</h3></div><div class="ml l"><p class="bd b dl z fp mi fr fs mj fu fw dk translated">github.com</p></div></div><div class="mm l"><div class="pn l mo mp mq mm mr it md"/></div></div></a></div><p id="3378" class="pw-post-body-paragraph lg lh jb li b lj lk kl ll lm ln ko lo lp lq lr ls lt lu lv lw lx ly lz ma mb ij bi translated"><a class="ae mc" href="https://www.connectedpapers.com/main/8faeb5d1b0580e7aa4fbda02ae594252dba88893/arxiv" rel="noopener ugc nofollow" target="_blank"> <strong class="li jl">连接论文</strong> </a> <strong class="li jl">📈</strong></p></div><div class="ab cl kz la hu lb" role="separator"><span class="lc bw bk ld le lf"/><span class="lc bw bk ld le lf"/><span class="lc bw bk ld le"/></div><div class="ij ik il im in"><h2 id="affe" class="pc mt jb bd mu pd pe dn my pf pg dp nc lp ph pi ne lt pj pk ng lx pl pm ni jh bi translated">电动的</h2><blockquote class="ot ou ov"><p id="0b57" class="lg lh or li b lj lk kl ll lm ln ko lo ow lq lr ls ox lu lv lw oy ly lz ma mb ij bi translated">适用于生物医学领域的预先训练的特定领域语言模型。它在BC5CDR语料库上为命名实体识别设置了最先进的结果，并在第7届BioASQ-factoid挑战的5次运行中的2次运行中提供了最佳结果。</p></blockquote><div class="ip iq gp gr ir md"><a href="https://github.com/gmpoli/electramed" rel="noopener  ugc nofollow" target="_blank"><div class="me ab fo"><div class="mf ab mg cl cj mh"><h2 class="bd jl gy z fp mi fr fs mj fu fw jk bi translated">GMP Li/electra med</h2><div class="mk l"><h3 class="bd b gy z fp mi fr fs mj fu fw dk translated">生物医学自然语言处理动机的一种新的预训练语言表示模型</h3></div><div class="ml l"><p class="bd b dl z fp mi fr fs mj fu fw dk translated">github.com</p></div></div></div></a></div><p id="57f1" class="pw-post-body-paragraph lg lh jb li b lj lk kl ll lm ln ko lo lp lq lr ls lt lu lv lw lx ly lz ma mb ij bi translated"><a class="ae mc" href="https://www.connectedpapers.com/main/1991ea2ec85113cadf38faea840f4b5cf73ae0c7/arxiv" rel="noopener ugc nofollow" target="_blank"> <strong class="li jl">连接论文</strong> </a> <strong class="li jl">📈</strong></p></div><div class="ab cl kz la hu lb" role="separator"><span class="lc bw bk ld le lf"/><span class="lc bw bk ld le lf"/><span class="lc bw bk ld le"/></div><div class="ij ik il im in"><h2 id="2cbe" class="pc mt jb bd mu pd pe dn my pf pg dp nc lp ph pi ne lt pj pk ng lx pl pm ni jh bi translated">检索写插槽填充</h2><blockquote class="ot ou ov"><p id="d74c" class="lg lh or li b lj lk kl ll lm ln ko lo ow lq lr ls ox lu lv lw oy ly lz ma mb ij bi translated">使用RAG来改进槽填充任务(即，以[实体，槽，？]，任务要求生成丢失的槽)。这允许自动化知识图的创建。</p></blockquote><div class="ip iq gp gr ir md"><a href="https://github.com/IBM/retrieve-write-slot-filling" rel="noopener  ugc nofollow" target="_blank"><div class="me ab fo"><div class="mf ab mg cl cj mh"><h2 class="bd jl gy z fp mi fr fs mj fu fw jk bi translated">IBM/检索-写入-槽填充</h2><div class="mk l"><h3 class="bd b gy z fp mi fr fs mj fu fw dk translated">这是我们提交给T-REx和zsRE任务的KILT排行榜代码。它包括训练DPR的代码…</h3></div><div class="ml l"><p class="bd b dl z fp mi fr fs mj fu fw dk translated">github.com</p></div></div><div class="mm l"><div class="po l mo mp mq mm mr it md"/></div></div></a></div><p id="9290" class="pw-post-body-paragraph lg lh jb li b lj lk kl ll lm ln ko lo lp lq lr ls lt lu lv lw lx ly lz ma mb ij bi translated"><a class="ae mc" href="https://www.connectedpapers.com/main/a0517a71d3a29f6a05bdffa1bbe53ac621f77f17/arxiv" rel="noopener ugc nofollow" target="_blank"> <strong class="li jl">连接论文</strong> </a> <strong class="li jl">📈</strong></p></div><div class="ab cl kz la hu lb" role="separator"><span class="lc bw bk ld le lf"/><span class="lc bw bk ld le lf"/><span class="lc bw bk ld le"/></div><div class="ij ik il im in"><h2 id="febb" class="pc mt jb bd mu pd pe dn my pf pg dp nc lp ph pi ne lt pj pk ng lx pl pm ni jh bi translated">电容器</h2><blockquote class="ot ou ov"><p id="fe5c" class="lg lh or li b lj lk kl ll lm ln ko lo ow lq lr ls ox lu lv lw oy ly lz ma mb ij bi translated">基于Transformer LMs的通用预训练架构，用于提高密集优化就绪性。目前支持的架构包括所有采用BERT或RoBERTa架构的型号。</p></blockquote><div class="ip iq gp gr ir md"><a href="https://github.com/luyug/Condenser" rel="noopener  ugc nofollow" target="_blank"><div class="me ab fo"><div class="mf ab mg cl cj mh"><h2 class="bd jl gy z fp mi fr fs mj fu fw jk bi translated">luyug/冷凝器</h2><div class="mk l"><h3 class="bd b gy z fp mi fr fs mj fu fw dk translated">用于将预训练的变压器编码器LM转换为Condenser的代码，Condenser是一种专用于…</h3></div><div class="ml l"><p class="bd b dl z fp mi fr fs mj fu fw dk translated">github.com</p></div></div></div></a></div><p id="f6f8" class="pw-post-body-paragraph lg lh jb li b lj lk kl ll lm ln ko lo lp lq lr ls lt lu lv lw lx ly lz ma mb ij bi translated"><a class="ae mc" href="https://www.connectedpapers.com/main/9bbdcc03d872987eef9165f4a63c3878a5b05189/arxiv" rel="noopener ugc nofollow" target="_blank"> <strong class="li jl">连接论文</strong> </a> <strong class="li jl">📈</strong></p></div><div class="ab cl kz la hu lb" role="separator"><span class="lc bw bk ld le lf"/><span class="lc bw bk ld le lf"/><span class="lc bw bk ld le"/></div><div class="ij ik il im in"><h2 id="16f7" class="pc mt jb bd mu pd pe dn my pf pg dp nc lp ph pi ne lt pj pk ng lx pl pm ni jh bi translated">Text2App</h2><blockquote class="ot ou ov"><p id="a134" class="lg lh or li b lj lk kl ll lm ln ko lo ow lq lr ls ox lu lv lw oy ly lz ma mb ij bi translated">一个允许用户根据自然语言规范创建功能性Android应用程序的框架。<em class="jb">🙈</em></p></blockquote><figure class="np nq nr ns gt is gh gi paragraph-image"><div class="gh gi pp"><img src="../Images/b26420fb41642ebf2c4f4adecaf5280c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1150/format:webp/0*PVrwBu_YOOo1gNzE.png"/></div></figure><div class="ip iq gp gr ir md"><a href="https://github.com/Masum06/Text2App" rel="noopener  ugc nofollow" target="_blank"><div class="me ab fo"><div class="mf ab mg cl cj mh"><h2 class="bd jl gy z fp mi fr fs mj fu fw jk bi translated">Masum06/Text2App</h2><div class="mk l"><h3 class="bd b gy z fp mi fr fs mj fu fw dk translated">此时您不能执行该操作。您已使用另一个标签页或窗口登录。您已在另一个选项卡中注销，或者…</h3></div><div class="ml l"><p class="bd b dl z fp mi fr fs mj fu fw dk translated">github.com</p></div></div><div class="mm l"><div class="pq l mo mp mq mm mr it md"/></div></div></a></div><p id="ac86" class="pw-post-body-paragraph lg lh jb li b lj lk kl ll lm ln ko lo lp lq lr ls lt lu lv lw lx ly lz ma mb ij bi translated"><a class="ae mc" href="https://www.connectedpapers.com/main/b669aac8df4fb450ca0784fbf597d7ce58ff4787/arxiv" rel="noopener ugc nofollow" target="_blank"> <strong class="li jl">连接论文</strong> </a> <strong class="li jl">📈</strong></p></div><div class="ab cl kz la hu lb" role="separator"><span class="lc bw bk ld le lf"/><span class="lc bw bk ld le lf"/><span class="lc bw bk ld le"/></div><div class="ij ik il im in"><h2 id="b7ac" class="pc mt jb bd mu pd pe dn my pf pg dp nc lp ph pi ne lt pj pk ng lx pl pm ni jh bi translated">先知网络-X</h2><blockquote class="ot ou ov"><p id="f338" class="lg lh or li b lj lk kl ll lm ln ko lo ow lq lr ls ox lu lv lw oy ly lz ma mb ij bi translated">ProphetNet为中文、英文对话、中文对话、多语言和代码生成提供了预训练模型。</p></blockquote><div class="ip iq gp gr ir md"><a href="https://github.com/microsoft/ProphetNet" rel="noopener  ugc nofollow" target="_blank"><div class="me ab fo"><div class="mf ab mg cl cj mh"><h2 class="bd jl gy z fp mi fr fs mj fu fw jk bi translated">微软/预言网</h2><div class="mk l"><h3 class="bd b gy z fp mi fr fs mj fu fw dk translated">这个报告提供了在ProphetNet上复制实验的代码。本文提出了一种新的预训练算法</h3></div><div class="ml l"><p class="bd b dl z fp mi fr fs mj fu fw dk translated">github.com</p></div></div><div class="mm l"><div class="pr l mo mp mq mm mr it md"/></div></div></a></div><p id="17bf" class="pw-post-body-paragraph lg lh jb li b lj lk kl ll lm ln ko lo lp lq lr ls lt lu lv lw lx ly lz ma mb ij bi translated"><a class="ae mc" href="https://www.connectedpapers.com/main/26e3d58181724f9ef77973ff0f65bac06e499fec/arxiv" rel="noopener ugc nofollow" target="_blank"> <strong class="li jl">连接论文</strong> </a> <strong class="li jl">📈</strong></p></div><div class="ab cl kz la hu lb" role="separator"><span class="lc bw bk ld le lf"/><span class="lc bw bk ld le lf"/><span class="lc bw bk ld le"/></div><div class="ij ik il im in"><h2 id="e330" class="pc mt jb bd mu pd pe dn my pf pg dp nc lp ph pi ne lt pj pk ng lx pl pm ni jh bi translated">LAMPRET:用于文档理解的布局感知多模式预处理</h2><blockquote class="ot ou ov"><p id="a154" class="lg lh or li b lj lk kl ll lm ln ko lo ow lq lr ls ox lu lv lw oy ly lz ma mb ij bi translated">一种通用的预训练方法，利用文档的结构和内容，并考虑多媒体内容，如图像，以学习全面的多模态文档表示。</p></blockquote><p id="e11a" class="pw-post-body-paragraph lg lh jb li b lj lk kl ll lm ln ko lo lp lq lr ls lt lu lv lw lx ly lz ma mb ij bi translated"><strong class="li jl">论文</strong>:<a class="ae mc" href="https://arxiv.org/pdf/2104.08405.pdf" rel="noopener ugc nofollow" target="_blank">https://arxiv.org/pdf/2104.08405.pdf</a></p><p id="af93" class="pw-post-body-paragraph lg lh jb li b lj lk kl ll lm ln ko lo lp lq lr ls lt lu lv lw lx ly lz ma mb ij bi translated"><a class="ae mc" href="https://www.connectedpapers.com/main/1a3f12fa1da8f2a871390ffb0c7d95360909d13d/arxiv" rel="noopener ugc nofollow" target="_blank"> <strong class="li jl">连接论文</strong> </a> <strong class="li jl">📈</strong></p></div><div class="ab cl kz la hu lb" role="separator"><span class="lc bw bk ld le lf"/><span class="lc bw bk ld le lf"/><span class="lc bw bk ld le"/></div><div class="ij ik il im in"><h1 id="ff81" class="ms mt jb bd mu mv ps mx my mz pt nb nc kq pu kr ne kt pv ku ng kw pw kx ni nj bi translated">本周数据集:GooAQ🥑:谷歌回答谷歌问题！</h1><h2 id="80c7" class="pc mt jb bd mu pd pe dn my pf pg dp nc lp ph pi ne lt pj pk ng lx pl pm ni jh bi translated">这是什么？</h2><p id="da44" class="pw-post-body-paragraph lg lh jb li b lj nk kl ll lm nl ko lo lp nm lr ls lt nn lv lw lx no lz ma mb ij bi translated">一个问答数据集，包含从谷歌收集的超过500万个问题和300万个答案。GOOAQ问题是使用自动完成功能从Google搜索引擎半自动收集的。</p><h2 id="17ca" class="pc mt jb bd mu pd pe dn my pf pg dp nc lp ph pi ne lt pj pk ng lx pl pm ni jh bi translated">样品</h2><pre class="np nq nr ns gt px py pz qa aw qb bi"><span id="9e69" class="pc mt jb py b gy qc qd l qe qf">{<br/>  "id": 5009708,<br/>  "question": "carbon dioxide comprises approximately what percentage of tropospheric gases?",<br/>  "short_answer": "04%",<br/>  "answer": "Carbon dioxide comprise approximately . 04% of tropospheric gases.",<br/>  "answer_type": "feat_snip"<br/>}</span></pre><h2 id="e700" class="pc mt jb bd mu pd pe dn my pf pg dp nc lp ph pi ne lt pj pk ng lx pl pm ni jh bi translated">它在哪里？</h2><div class="ip iq gp gr ir md"><a href="https://github.com/allenai/gooaq" rel="noopener  ugc nofollow" target="_blank"><div class="me ab fo"><div class="mf ab mg cl cj mh"><h2 class="bd jl gy z fp mi fr fs mj fu fw jk bi translated">allenai/gooaq</h2><div class="mk l"><h3 class="bd b gy z fp mi fr fs mj fu fw dk translated">这个存储库包含我们最近在长格式问题回答方面的工作所附带的代码/数据。请注意这个数据集…</h3></div><div class="ml l"><p class="bd b dl z fp mi fr fs mj fu fw dk translated">github.com</p></div></div></div></a></div></div><div class="ab cl kz la hu lb" role="separator"><span class="lc bw bk ld le lf"/><span class="lc bw bk ld le lf"/><span class="lc bw bk ld le"/></div><div class="ij ik il im in"><blockquote class="qg"><p id="b330" class="qh qi jb bd qj qk ql qm qn qo qp mb dk translated">每周日，我们都会对来自世界各地的研究人员的NLP新闻和代码进行每周综述。</p><p id="8639" class="qh qi jb bd qj qk ql qm qn qo qp mb dk translated"><em class="qq">完整报道，关注我们的推特:</em><a class="ae mc" href="http://twitter.com/Quantum_Stat" rel="noopener ugc nofollow" target="_blank"><em class="qq">@ Quantum _ Stat</em></a></p></blockquote><figure class="qs qt qu qv qw is gh gi paragraph-image"><div class="gh gi qr"><img src="../Images/605d15bdf547bb10223a0601abc84af6.png" data-original-src="https://miro.medium.com/v2/resize:fit:108/0*vgf45g9haG4f6VcH"/></div><figcaption class="iv iw gj gh gi ix iy bd b be z dk translated"><a class="ae mc" href="https://quantumstat.com/" rel="noopener ugc nofollow" target="_blank">量子统计</a></figcaption></figure></div></div>    
</body>
</html>