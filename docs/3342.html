<html>
<head>
<title>Working on a Computer Vision Project? These Code Chunks Will Help You !!!</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">从事计算机视觉项目？这些代码块将帮助您！！！</h1>
<blockquote>原文：<a href="https://pub.towardsai.net/working-on-a-computer-vision-project-these-code-chunks-will-help-you-45756bbe7e65?source=collection_archive---------1-----------------------#2022-11-27">https://pub.towardsai.net/working-on-a-computer-vision-project-these-code-chunks-will-help-you-45756bbe7e65?source=collection_archive---------1-----------------------#2022-11-27</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><div class=""><h2 id="0289" class="pw-subtitle-paragraph jn ip iq bd b jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke dk translated">介绍计算机视觉项目中的几种“习惯”方法</h2></div><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi kf"><img src="../Images/898df04f691055d867cdea352ccacaab.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*K1RYveEPTCBgvf6LwOs7rA.png"/></div></div><figcaption class="kr ks gj gh gi kt ku bd b be z dk translated">计算机视觉项目[ <a class="ae kv" href="https://blogs.nvidia.com/blog/2019/10/23/drive-labs-panoptic-segmentation/" rel="noopener ugc nofollow" target="_blank">来源</a> ]</figcaption></figure><blockquote class="kw"><p id="68dc" class="kx ky iq bd kz la lb lc ld le lf lg dk translated">"虚拟现实和增强现实最终将会融合，智能眼镜将会接管我们的数字互动."― <strong class="ak">卡洛斯·洛佩斯(方正@奥瑞斯)</strong></p></blockquote><p id="57f2" class="pw-post-body-paragraph lh li iq lj b lk ll jr lm ln lo ju lp lq lr ls lt lu lv lw lx ly lz ma mb lg ij bi mc translated"><span class="l md me mf bm mg mh mi mj mk di">在计算机视觉和机器学习领域工作的惊人之处在于，每隔几年，就会有人发明一些疯狂的东西，让你彻底重新考虑什么是可能的！！！</span></p><p id="06a7" class="pw-post-body-paragraph lh li iq lj b lk ml jr lm ln mm ju lp lq mn ls lt lu mo lw lx ly mp ma mb lg ij bi translated">自计算机视觉算法出现以来，世界获得了一种新的视角&amp;一种新的思维和跟踪物体的方式。从基于区域的卷积神经网络[RCNN]到YOLO V7、detectron-2、segformer和分类架构，计算机视觉发生了巨大的变化，以实现更高的检测效率和更高的延迟，同时对时间和计算费用的要求更低。</p><p id="47cb" class="pw-post-body-paragraph lh li iq lj b lk ml jr lm ln mm ju lp lq mn ls lt lu mo lw lx ly mp ma mb lg ij bi translated">计算机视觉项目是许多事情的组合，从数据收集到成功部署。了解数据以及正确的处理和培训是成功的关键。下面是一些代码块，以及对它们工作的描述，将会让你在项目中的工作更轻松。</p><h1 id="d3d6" class="mq mr iq bd ms mt mu mv mw mx my mz na jw nb jx nc jz nd ka ne kc nf kd ng nh bi translated">1.了解数据集的实例</h1><p id="0b51" class="pw-post-body-paragraph lh li iq lj b lk ni jr lm ln nj ju lp lq nk ls lt lu nl lw lx ly nm ma mb lg ij bi translated">对于对象检测或分割项目，我们借助外部标注工具对数据集进行标注，如<a class="ae kv" href="https://www.makesense.ai/" rel="noopener ugc nofollow" target="_blank"> makesense.ai </a>、<a class="ae kv" href="https://www.robots.ox.ac.uk/~vgg/software/via/via_demo.html" rel="noopener ugc nofollow" target="_blank"> VGG标注器</a>、<a class="ae kv" href="https://github.com/heartexlabs/labelImg" rel="noopener ugc nofollow" target="_blank"> LableIMG </a>等。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi nn"><img src="../Images/444ba157593b47998691243b3f85040f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*KdW_Y2JnHtQkZgKSk690YQ.png"/></div></div><figcaption class="kr ks gj gh gi kt ku bd b be z dk translated">物体检测中的不平衡数据集示例[图像<a class="ae kv" href="https://www.semanticscholar.org/paper/Frame-Augmentation-for-Imbalanced-Object-Detection-Elasal-Swart/f183c02ef708ef6e7c49a3720947599d54014ccb" rel="noopener ugc nofollow" target="_blank">源</a> ]</figcaption></figure><p id="2506" class="pw-post-body-paragraph lh li iq lj b lk ml jr lm ln mm ju lp lq mn ls lt lu mo lw lx ly mp ma mb lg ij bi translated">我们知道图像的确切数量，但很难知道每个类有多少实例。了解类的实例将告诉您数据集是否不平衡。如果你的例子不均衡，将会对学习模式产生深远的影响。因此，在下载带注释的数据集及其注释文件后，您可以使用下面的代码块来查看类平衡状态。</p><pre class="kg kh ki kj gt no np nq bn nr ns bi"><span id="c375" class="nt mr iq np b be nu nv l nw nx">import os<br/>#Give path of folder in which you stored images and annotations <br/>path = r"Your dataset *folder* location" <br/># Change the directory to path <br/>os.chdir(path)<br/>x=[]<br/># Spinning through all files <br/>for file in os.listdir():<br/># Checking for text annotation file <br/>    if file.endswith(".txt"):<br/>        file_path = f"{path}\{file}"<br/>        with open(file_path, 'r') as f:<br/>            for line in f:<br/>                a=line[0]<br/>                x.append(a)<br/>print(x)<br/>#to count instances <br/>from collections import Counter<br/>Counter(x)</span></pre><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi ny"><img src="../Images/02ba6eab872adc0d4e8fbe3a85dd95d1.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*mjsIo27_AIG2rQVmuBsSBQ.png"/></div></div><figcaption class="kr ks gj gh gi kt ku bd b be z dk translated">作者形象</figcaption></figure><p id="699d" class="pw-post-body-paragraph lh li iq lj b lk ml jr lm ln mm ju lp lq mn ls lt lu mo lw lx ly mp ma mb lg ij bi translated">最后，您可以看到计数器给出了每个类的实例值，然后根据您的模型标准，您可以决定数据集是否需要进一步平衡。</p><h1 id="beed" class="mq mr iq bd ms mt mu mv mw mx my mz na jw nb jx nc jz nd ka ne kc nf kd ng nh bi translated">2.图像预处理</h1><p id="ed77" class="pw-post-body-paragraph lh li iq lj b lk ni jr lm ln nj ju lp lq nk ls lt lu nl lw lx ly nm ma mb lg ij bi translated">在我们的图像数据集中，除了类实例，我们还有许多其他对象/事物。如果我们把它作为模型的学习目的，那么这些其他的项目都可以归为噪音。有许多用例声称，消除这些噪声，然后将其发送到模型进行训练，可以提高模型的性能。那么如何对图像进行预处理呢？参见下面的代码。</p><pre class="kg kh ki kj gt no np nq bn nr ns bi"><span id="bbab" class="nt mr iq np b be nu nv l nw nx">#Writing a function to create mouse masking <br/>#We are using mouse click events here<br/>import numpy as np<br/>import cv2 as cv<br/>drawing = False # true if mouse is pressed<br/>mode = True # if True, draw rectangle. Press 'm' to toggle to curve<br/>ix,iy = -1,-1<br/># mouse callback function<br/>def draw_circle(event,x,y,flags,param):<br/>    global ix,iy,drawing,mode<br/>    if event == cv.EVENT_LBUTTONDOWN:<br/>        drawing = True<br/>        ix,iy = x,y<br/>    elif event == cv.EVENT_MOUSEMOVE:<br/>        if drawing == True:<br/>            if mode == True:<br/>                cv.rectangle(img,(ix,iy),(x,y),(255,255,255),-1)<br/>                #(255,255,255) represents white color but you can give any.<br/>                # -1 represents filled box and 1 represents hollow box <br/>            else:<br/>                cv.circle(img,(x,y),5,(0,0,255),-1)<br/>    elif event == cv.EVENT_LBUTTONUP:<br/>        drawing = False<br/>        if mode == True:<br/>            cv.rectangle(img,(ix,iy),(x,y),(255,255,255),-1)<br/>        else:<br/>            cv.circle(img,(x,y),5,(0,0,255),-1)<br/>            <br/>#storing final output        <br/>            <br/>    cv2.imwrite("new_img.jpg",img)</span></pre><pre class="nz no np nq bn nr ns bi"><span id="1d3d" class="nt mr iq np b be nu nv l nw nx">#Calling function and using it on input image <br/>import cv2 <br/>img = cv2.imread(r"Your image path",1)<br/>#resizing to fit on screen<br/>img = cv2.resize(img,(1200,800))<br/>cv.namedWindow('image')<br/>cv.setMouseCallback('image',draw_circle)<br/>while(1):<br/>    cv.imshow('image',img)<br/>    k = cv.waitKey(1) &amp; 0xFF<br/>    if k == ord('m'):<br/>        mode = not mode<br/>    elif k == 27:<br/>        break<br/>cv.destroyAllWindows()</span></pre><p id="fdac" class="pw-post-body-paragraph lh li iq lj b lk ml jr lm ln mm ju lp lq mn ls lt lu mo lw lx ly mp ma mb lg ij bi translated">如果您运行上面的代码，那么您的训练图像将出现在您的面前，您的鼠标将充当面具制作人。点击并悬停鼠标在一个不必要的对象上会直接创建一个对象上的面具。出于用例目的，我选择了白色，但是您可以根据您的问题选择任何颜色。你可以训练一个单独的物体检测模型来检测噪声，在它下面，你可以附上这段代码。首先，该模型将检测噪声，然后该代码将使用您想要的颜色来遮盖该边界框。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi oa"><img src="../Images/0fdc078f717e9d32e58c1269d1d1c223.png" data-original-src="https://miro.medium.com/v2/resize:fit:1200/1*RhSUIbk3Vrbn_kow0qF5Qw.gif"/></div><figcaption class="kr ks gj gh gi kt ku bd b be z dk translated">噪声对象的掩蔽[图片由作者提供]</figcaption></figure><p id="e9ef" class="pw-post-body-paragraph lh li iq lj b lk ml jr lm ln mm ju lp lq mn ls lt lu mo lw lx ly mp ma mb lg ij bi translated">对于图像预处理，你可以做很多事情，比如裁剪，模糊/对比等等。你可以阅读我的博客了解更多的图像预处理技术。</p><div class="ob oc gp gr od oe"><a href="https://medium.com/nerd-for-tech/do-you-know-these-basic-image-processing-operations-2bac0e3363e8" rel="noopener follow" target="_blank"><div class="of ab fo"><div class="og ab oh cl cj oi"><h2 class="bd ir gy z fp oj fr fs ok fu fw ip bi translated">你知道这些基本的图像处理操作吗？</h2><div class="ol l"><h3 class="bd b gy z fp oj fr fs ok fu fw dk translated">Python中的图像处理基础</h3></div><div class="om l"><p class="bd b dl z fp oj fr fs ok fu fw dk translated">medium.com</p></div></div><div class="on l"><div class="oo l op oq or on os kp oe"/></div></div></a></div><h1 id="fed8" class="mq mr iq bd ms mt mu mv mw mx my mz na jw nb jx nc jz nd ka ne kc nf kd ng nh bi translated">3.数据扩充</h1><p id="2a26" class="pw-post-body-paragraph lh li iq lj b lk ni jr lm ln nj ju lp lq nk ls lt lu nl lw lx ly nm ma mb lg ij bi translated">在每个计算机视觉项目中，您都希望扩大数据集，使其更大，从而使模型的工作更容易。有很多开源软件可以为你做增强，比如<a class="ae kv" href="https://app.roboflow.com/" rel="noopener ugc nofollow" target="_blank"> Roboflow </a>。但是很多时候，数据的安全性和保密性会有问题。因此，您可以在python编辑器上进行自己的数据集扩充。TensorFlow有一个名为“<a class="ae kv" href="https://www.tensorflow.org/api_docs/python/tf/keras/preprocessing/image/ImageDataGenerator" rel="noopener ugc nofollow" target="_blank"><strong class="lj ir"><em class="ot">imagedata generator</em></strong></a>的库，可以帮助你做到这一点。参见下面的代码。</p><pre class="kg kh ki kj gt no np nq bn nr ns bi"><span id="d510" class="nt mr iq np b be nu nv l nw nx"># FOR COMPLETE FOLDER ANNOTATION<br/>#imports <br/>import tensorflow<br/>import keras<br/>import numpy as np<br/>import os<br/>from PIL import Image<br/>from skimage import io<br/>SIZE = 128<br/>dataset = []<br/>image_directory = 'Image folder address/'<br/>from keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img<br/># Gving required augmentations to image <br/>#ImageDataGenerator has many Augmentations, choose those who are good for your condition<br/>datagen = ImageDataGenerator(<br/>        rotation_range=40,<br/>        width_shift_range=0.2,<br/>        height_shift_range=0.2,<br/>        shear_range=0.2,<br/>        zoom_range=0.2,<br/>        horizontal_flip=True,<br/>        fill_mode='nearest')<br/><br/>my_images = os.listdir(image_directory)<br/>for i, image_name in enumerate(my_images):<br/>    if (image_name.split('.')[1] == 'jpg'):<br/>        image = io.imread(image_directory + image_name)<br/>        image = Image.fromarray(image,'RGB')<br/>        image = image.resize((SIZE,SIZE))<br/>        dataset.append(np.array(image))  <br/>x = np.array(dataset)<br/>i = 0<br/>for batch in datagen.flow(x, batch_size=20,<br/>                          save_to_dir='preview', save_prefix='Hard_Hat', save_format='jpeg'):<br/>    i += 1<br/>    if i &gt; 200:<br/>        break<br/><br/> </span></pre><pre class="nz no np nq bn nr ns bi"><span id="6f16" class="nt mr iq np b be nu nv l nw nx">#FOR SINGLE IMAGE ANNOTATION<br/><br/>import tensorflow<br/>import keras<br/>from keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img<br/>#Adress of image<br/>img = load_img('Image address [should end with .jpg or .png]')  <br/>#Required augmentations <br/>datagen = ImageDataGenerator(<br/>        rotation_range=40,<br/>        width_shift_range=0.2,<br/>        height_shift_range=0.2,<br/>        shear_range=0.2,<br/>        zoom_range=0.2,<br/>        horizontal_flip=True,<br/>        fill_mode='nearest')<br/><br/>x = img_to_array(img) <br/>x = x.reshape((1,) + x.shape)  <br/><br/>i = 0<br/>for batch in datagen.flow(x, batch_size=1,<br/>                          save_to_dir='preview/green_Aug', save_prefix='Hard_Hat_orange_Aug', save_format='jpeg'):<br/>    i += 1<br/>    if i &gt; 20:     #20 is the output images that we will get. you can set any limit according to project<br/>        break  <br/></span></pre><p id="6c5c" class="pw-post-body-paragraph lh li iq lj b lk ml jr lm ln mm ju lp lq mn ls lt lu mo lw lx ly mp ma mb lg ij bi translated">第一段代码是用于图像文件夹的。你可以用它来做质量增强。第二个块用于单个图像。根据您的使用情况，您可以使用以上任何一种。最后一个“<strong class="lj ir"> i </strong>”是你要创建的合成图像的数量。选择一个合适的数字并增加它。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi ou"><img src="../Images/90508df067937e2013ca2d39307b1136.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*9uOVOqcUlRTKg7QudEh1dA.png"/></div></div><figcaption class="kr ks gj gh gi kt ku bd b be z dk translated">通过代码增强图像[图片由作者提供]</figcaption></figure><h1 id="5350" class="mq mr iq bd ms mt mu mv mw mx my mz na jw nb jx nc jz nd ka ne kc nf kd ng nh bi translated">4.数据集创建</h1><p id="6f6d" class="pw-post-body-paragraph lh li iq lj b lk ni jr lm ln nj ju lp lq nk ls lt lu nl lw lx ly nm ma mb lg ij bi translated">很多时候，您需要来自网络摄像头的图像。但是很难点开保存在带标签的文件夹里进行分类或者物体检测。它还涉及大量的手动任务。下面的代码是点击特定标签的图像，它会直接将它们存储在适当的位置。</p><blockquote class="ov ow ox"><p id="b274" class="lh li ot lj b lk ml jr lm ln mm ju lp oy mn ls lt oz mo lw lx pa mp ma mb lg ij bi translated">提及你的标签和每节课你想要多少张图片。然后指定存储路径。在每一个<strong class="lj ir"> time.sleep(5) </strong>之后，它将点击图像，直到创建数据。</p></blockquote><pre class="kg kh ki kj gt no np nq bn nr ns bi"><span id="1395" class="nt mr iq np b be nu nv l nw nx"># Importing modules <br/>import cv2 <br/>import uuid<br/>import os<br/>import time<br/><br/>#Classes that you want to use<br/>labels = ['happyface', 'sadface', 'angryface', 'excitedface']<br/># How many images you want for each class<br/>number_imgs = 5<br/>#Image path <br/>IMAGES_PATH = os.path.join('Tensorflow', 'workspace', 'images', 'collectedimages')</span></pre><pre class="nz no np nq bn nr ns bi"><span id="bdeb" class="nt mr iq np b be nu nv l nw nx">if not os.path.exists(IMAGES_PATH):<br/>    if os.name == 'posix':<br/>        !mkdir -p {IMAGES_PATH}<br/>    if os.name == 'nt':<br/>         !mkdir {IMAGES_PATH}<br/>for label in labels:<br/>    path = os.path.join(IMAGES_PATH, label)<br/>    if not os.path.exists(path):<br/>        !mkdir {path}</span></pre><pre class="nz no np nq bn nr ns bi"><span id="2625" class="nt mr iq np b be nu nv l nw nx"># This will open your Webcam and start clicking images and save it in .jpg format<br/>for label in labels:<br/>    cap = cv2.VideoCapture(0)<br/>    print('Collecting images for {}'.format(label))<br/>    time.sleep(5)<br/>    for imgnum in range(number_imgs):<br/>        print('Collecting image {}'.format(imgnum))<br/>        ret, frame = cap.read()<br/>        imgname = os.path.join(IMAGES_PATH,label,label+'.'+'{}.jpg'.format(str(uuid.uuid1())))<br/>        cv2.imwrite(imgname, frame)<br/>        cv2.imshow('frame', frame)           <br/>        time.sleep(2)<br/>        if cv2.waitKey(1) &amp; 0xFF == ord('q'):         <br/>            break<br/>cap.release()<br/>cv2.destroyAllWindows()</span></pre><p id="eef4" class="pw-post-body-paragraph lh li iq lj b lk ml jr lm ln mm ju lp lq mn ls lt lu mo lw lx ly mp ma mb lg ij bi translated">运行代码块后，您会得到下面的结果。图像将存储在指定的位置。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi pb"><img src="../Images/ae8d8261f0a5072ee5e37f6ef5fc2d91.png" data-original-src="https://miro.medium.com/v2/resize:fit:1036/format:webp/1*zRLdibDPNCZcmT4sa0lfBw.png"/></div><figcaption class="kr ks gj gh gi kt ku bd b be z dk translated">作者图片</figcaption></figure><h1 id="a724" class="mq mr iq bd ms mt mu mv mw mx my mz na jw nb jx nc jz nd ka ne kc nf kd ng nh bi translated">5.从图像中提取区域</h1><p id="8801" class="pw-post-body-paragraph lh li iq lj b lk ni jr lm ln nj ju lp lq nk ls lt lu nl lw lx ly nm ma mb lg ij bi translated">这是最有用的事情，不仅是检测或分割对象，而且提取它们的区域。我们使用许多技术，如像素测量等。但问题是，你必须在提取区域之前进行校准，以匹配原始尺寸及其在图像中的表示和它们的比例。因此，对于校准，人们使用内置比率和参考对象方案，但我尝试了一种新的方法来计算校准系数。你只需要画一条线来进行校准。我在下面的博客中提到了如何做到这一点。</p><div class="ob oc gp gr od oe"><a href="https://medium.com/@BH_Chinmay/calibration-in-image-processing-c4c164870f21" rel="noopener follow" target="_blank"><div class="of ab fo"><div class="og ab oh cl cj oi"><h2 class="bd ir gy z fp oj fr fs ok fu fw ip bi translated">图像处理中的校准</h2><div class="ol l"><h3 class="bd b gy z fp oj fr fs ok fu fw dk translated">很多时候在图像处理和物体检测问题中，我们都要从图像中测量物体的大小。在…</h3></div><div class="om l"><p class="bd b dl z fp oj fr fs ok fu fw dk translated">medium.com</p></div></div><div class="on l"><div class="pc l op oq or on os kp oe"/></div></div></a></div></div><div class="ab cl pd pe hu pf" role="separator"><span class="pg bw bk ph pi pj"/><span class="pg bw bk ph pi pj"/><span class="pg bw bk ph pi"/></div><div class="ij ik il im in"><p id="3b45" class="pw-post-body-paragraph lh li iq lj b lk ml jr lm ln mm ju lp lq mn ls lt lu mo lw lx ly mp ma mb lg ij bi translated">这是一些能帮助你构建和贡献你的项目的小块。有很多事情我想涵盖，但仍然，这是足够的这个博客部分。</p><h1 id="d9ee" class="mq mr iq bd ms mt mu mv mw mx my mz na jw nb jx nc jz nd ka ne kc nf kd ng nh bi translated">如果你觉得这篇文章很有见地</h1><p id="6a2e" class="pw-post-body-paragraph lh li iq lj b lk ni jr lm ln nj ju lp lq nk ls lt lu nl lw lx ly nm ma mb lg ij bi translated">如果你觉得这篇文章很有见地，请关注我的<a class="ae kv" href="https://www.linkedin.com/in/chinmay-bhalerao-6b5284137/" rel="noopener ugc nofollow" target="_blank"> <strong class="lj ir"> Linkedin </strong> </a>和<a class="ae kv" href="https://medium.com/@BH_Chinmay" rel="noopener"> <strong class="lj ir"> medium </strong> </a>。你也可以<a class="ae kv" href="https://medium.com/@BH_Chinmay" rel="noopener"> <strong class="lj ir">订阅</strong> </a>在我发表文章的时候得到通知。让我们创建一个社区！感谢您的支持！</p><h1 id="6fcc" class="mq mr iq bd ms mt mu mv mw mx my mz na jw nb jx nc jz nd ka ne kc nf kd ng nh bi translated">如果你想支持我:</h1><p id="39d4" class="pw-post-body-paragraph lh li iq lj b lk ni jr lm ln nj ju lp lq nk ls lt lu nl lw lx ly nm ma mb lg ij bi translated">作为你的关注和鼓掌是最重要的事情，但你也可以通过买咖啡来支持我。<a class="ae kv" href="https://www.buymeacoffee.com/chinmaybhalerao" rel="noopener ugc nofollow" target="_blank"> <strong class="lj ir">咖啡</strong> </a> <strong class="lj ir">。</strong></p><h2 id="bae9" class="pk mr iq bd ms pl pm dn mw pn po dp na lq pp pq nc lu pr ps ne ly pt pu ng pv bi translated">你可以阅读我的其他博客，涉及:</h2><div class="ob oc gp gr od oe"><a href="https://medium.com/mlearning-ai/feature-selection-techniques-for-data-57f0eacd8fa8" rel="noopener follow" target="_blank"><div class="of ab fo"><div class="og ab oh cl cj oi"><h2 class="bd ir gy z fp oj fr fs ok fu fw ip bi translated">数据的特征选择技术</h2><div class="ol l"><h3 class="bd b gy z fp oj fr fs ok fu fw dk translated">启发式和进化特征选择技术</h3></div><div class="om l"><p class="bd b dl z fp oj fr fs ok fu fw dk translated">medium.com</p></div></div><div class="on l"><div class="pw l op oq or on os kp oe"/></div></div></a></div><div class="ob oc gp gr od oe"><a href="https://medium.com/geekculture/simultaneous-localization-and-mapping-slam-systems-44d4369fcb46" rel="noopener follow" target="_blank"><div class="of ab fo"><div class="og ab oh cl cj oi"><h2 class="bd ir gy z fp oj fr fs ok fu fw ip bi translated">同步定位和绘图系统</h2><div class="ol l"><h3 class="bd b gy z fp oj fr fs ok fu fw dk translated">超越DROID-SLAM系统简介</h3></div><div class="om l"><p class="bd b dl z fp oj fr fs ok fu fw dk translated">medium.com</p></div></div><div class="on l"><div class="px l op oq or on os kp oe"/></div></div></a></div><div class="ob oc gp gr od oe"><a rel="noopener  ugc nofollow" target="_blank" href="/genetic-algorithm-optimization-8299856949d3"><div class="of ab fo"><div class="og ab oh cl cj oi"><h2 class="bd ir gy z fp oj fr fs ok fu fw ip bi translated">遗传算法优化</h2><div class="ol l"><h3 class="bd b gy z fp oj fr fs ok fu fw dk translated">进化和自然启发优化算法的详细解释</h3></div><div class="om l"><p class="bd b dl z fp oj fr fs ok fu fw dk translated">pub.towardsai.net</p></div></div><div class="on l"><div class="py l op oq or on os kp oe"/></div></div></a></div><div class="ob oc gp gr od oe"><a rel="noopener  ugc nofollow" target="_blank" href="/ant-colony-optimization-an-overview-4bf7cb909b80"><div class="of ab fo"><div class="og ab oh cl cj oi"><h2 class="bd ir gy z fp oj fr fs ok fu fw ip bi translated">蚁群优化:综述</h2><div class="ol l"><h3 class="bd b gy z fp oj fr fs ok fu fw dk translated">基于种群的元启发式自然优化算法</h3></div><div class="om l"><p class="bd b dl z fp oj fr fs ok fu fw dk translated">pub.towardsai.net</p></div></div><div class="on l"><div class="pz l op oq or on os kp oe"/></div></div></a></div><p id="8739" class="pw-post-body-paragraph lh li iq lj b lk ml jr lm ln mm ju lp lq mn ls lt lu mo lw lx ly mp ma mb lg ij bi translated">结束，</p><p id="0d48" class="pw-post-body-paragraph lh li iq lj b lk ml jr lm ln mm ju lp lq mn ls lt lu mo lw lx ly mp ma mb lg ij bi translated">钦迈·巴勒劳</p></div></div>    
</body>
</html>