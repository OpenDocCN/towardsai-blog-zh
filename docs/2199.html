<html>
<head>
<title>Web Scraping Movie Data with Beautiful Soup library in python</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">用python中漂亮的汤库进行电影数据的Web抓取</h1>
<blockquote>原文：<a href="https://pub.towardsai.net/web-scraping-movie-data-with-beautiful-soup-library-in-python-b51ae9206ea8?source=collection_archive---------2-----------------------#2021-09-23">https://pub.towardsai.net/web-scraping-movie-data-with-beautiful-soup-library-in-python-b51ae9206ea8?source=collection_archive---------2-----------------------#2021-09-23</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><h2 id="5c44" class="ir is it bd b dl iu iv iw ix iy iz dk ja translated" aria-label="kicker paragraph"><a class="ae ep" href="https://towardsai.net/p/category/web-scraping" rel="noopener ugc nofollow" target="_blank">网页抓取</a></h2><div class=""/><div class=""><h2 id="8402" class="pw-subtitle-paragraph jz jc it bd b ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq dk translated">从电影网站提取数据</h2></div><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi kr"><img src="../Images/8bdd82950b23cdebe58908f8b794015b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*RYvPJ6RVVzKqRpdsfV0t4g.png"/></div></div></figure><blockquote class="ld le lf"><p id="badb" class="lg lh li lj b lk ll kd lm ln lo kg lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated"><strong class="lj jd"> <em class="it">简介</em> </strong></p></blockquote><p id="2bfe" class="pw-post-body-paragraph lg lh it lj b lk ll kd lm ln lo kg lp md lr ls lt me lv lw lx mf lz ma mb mc im bi translated">在本文中，我们将尝试借助一个漂亮的汤库来删除电影的细节。这个库对于从HTML页面抓取数据和解析器非常有用。</p><p id="c314" class="pw-post-body-paragraph lg lh it lj b lk ll kd lm ln lo kg lp md lr ls lt me lv lw lx mf lz ma mb mc im bi translated">下面显示了我们将收集到的电影细节的链接:</p><pre class="ks kt ku kv gt mg mh mi mj aw mk bi"><span id="32be" class="ml mm it mh b gy mn mo l mp mq"><a class="ae mr" href="http://www.imdb.com/search/title?release_date=2021&amp;sort=num_votes,desc&amp;page=1" rel="noopener ugc nofollow" target="_blank">http://www.imdb.com/search/title?release_date=2021&amp;sort=num_votes,desc&amp;page=1</a></span></pre><p id="2d2d" class="pw-post-body-paragraph lg lh it lj b lk ll kd lm ln lo kg lp md lr ls lt me lv lw lx mf lz ma mb mc im bi translated">我们将从这个页面中抓取的内容是<code class="fe ms mt mu mh b">movie_name</code>、<code class="fe ms mt mu mh b">release_year</code>、<code class="fe ms mt mu mh b">imdb</code>评分、<code class="fe ms mt mu mh b">metascore</code>和<code class="fe ms mt mu mh b">total_users</code>投票。</p><p id="7bd2" class="pw-post-body-paragraph lg lh it lj b lk ll kd lm ln lo kg lp md lr ls lt me lv lw lx mf lz ma mb mc im bi translated">首先，我们需要使用请求库来获取页面细节。</p><pre class="ks kt ku kv gt mg mh mi mj aw mk bi"><span id="d207" class="ml mm it mh b gy mn mo l mp mq">from requests import get<br/>url = 'http://www.imdb.com/search/title?release_date=2021&amp;<br/>       sort=num_votes,desc&amp;page=1'</span><span id="4b7d" class="ml mm it mh b gy mv mo l mp mq">response = get(url)<br/>print(response.text[:500])</span></pre><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi mw"><img src="../Images/e2cca15628f26872136b2eeb5dd399cc.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*tIIVLwBvoURln2hZwbJrnw.png"/></div></div></figure><p id="e689" class="pw-post-body-paragraph lg lh it lj b lk ll kd lm ln lo kg lp md lr ls lt me lv lw lx mf lz ma mb mc im bi translated">现在，我们将使用漂亮的汤从数据中提取文本。</p><pre class="ks kt ku kv gt mg mh mi mj aw mk bi"><span id="6c4e" class="ml mm it mh b gy mn mo l mp mq">from bs4 import BeautifulSoup<br/>html_soup = BeautifulSoup(response.text, 'html.parser')<br/>type(html_soup)</span><span id="a64b" class="ml mm it mh b gy mv mo l mp mq">#output:<br/>bs4.BeautifulSoup</span></pre><p id="6b6e" class="pw-post-body-paragraph lg lh it lj b lk ll kd lm ln lo kg lp md lr ls lt me lv lw lx mf lz ma mb mc im bi translated">HTML页面包含一个带有class属性的“div”标记。因此，我们将创建一个变量来保存所有具有特定类值的div类。</p><pre class="ks kt ku kv gt mg mh mi mj aw mk bi"><span id="a957" class="ml mm it mh b gy mn mo l mp mq">movie_containers = html_soup.find_all('div', class_ = 'lister-item<br/>                                                    mode-advanced')<br/>print(type(movie_containers))<br/>print(len(movie_containers))</span><span id="6828" class="ml mm it mh b gy mv mo l mp mq">#output:<br/>&lt;class 'bs4.element.ResultSet'&gt;<br/>50</span></pre><p id="6498" class="pw-post-body-paragraph lg lh it lj b lk ll kd lm ln lo kg lp md lr ls lt me lv lw lx mf lz ma mb mc im bi translated">所以，一个页面上的电影评论数量是50。开始提取2021年第一部电影的数据。</p><pre class="ks kt ku kv gt mg mh mi mj aw mk bi"><span id="675d" class="ml mm it mh b gy mn mo l mp mq">first_movie = movie_containers[0]<br/>first_movie.div</span><span id="a7aa" class="ml mm it mh b gy mv mo l mp mq">#output:<br/>&lt;div class="lister-top-right"&gt;<br/>&lt;div class="ribbonize" data-caller="filmosearch" data-tconst="tt12361974"&gt;&lt;/div&gt;<br/>&lt;/div&gt;</span><span id="88c1" class="ml mm it mh b gy mv mo l mp mq">-------------------------------------------------------------</span><span id="fc76" class="ml mm it mh b gy mv mo l mp mq">first_movie.a</span><span id="155a" class="ml mm it mh b gy mv mo l mp mq">#output:<br/>&lt;a href="/title/tt12361974/"&gt; &lt;img alt="Zack Snyder's Justice League" class="loadlate" data-tconst="tt12361974" height="98"&gt;<br/>&lt;/a&gt;</span><span id="a972" class="ml mm it mh b gy mv mo l mp mq">-------------------------------------------------------------</span><span id="73cf" class="ml mm it mh b gy mv mo l mp mq">first_movie.h3</span><span id="4681" class="ml mm it mh b gy mv mo l mp mq">#output:<br/>&lt;h3 class="lister-item-header"&gt;<br/>&lt;span class="lister-item-index unbold text-primary"&gt;1.&lt;/span&gt;<br/>&lt;a href="/title/tt12361974/"&gt;Zack Snyder's Justice League&lt;/a&gt;<br/>&lt;span class="lister-item-year text-muted unbold"&gt;(2021)&lt;/span&gt;<br/>&lt;/h3&gt;</span></pre><p id="428a" class="pw-post-body-paragraph lg lh it lj b lk ll kd lm ln lo kg lp md lr ls lt me lv lw lx mf lz ma mb mc im bi translated">如果我们在上面的代码中看到，h3标题标签包含了锚标签中的电影名称。因此，我们需要从锚标签中获取电影名称。</p><pre class="ks kt ku kv gt mg mh mi mj aw mk bi"><span id="c381" class="ml mm it mh b gy mn mo l mp mq">first_movie.h3.a</span><span id="a0de" class="ml mm it mh b gy mv mo l mp mq">#output:<br/>&lt;a href="/title/tt12361974/"&gt;Zack Snyder's Justice League&lt;/a&gt;</span><span id="4616" class="ml mm it mh b gy mv mo l mp mq">-------------------------------------------------------------</span><span id="515d" class="ml mm it mh b gy mv mo l mp mq">first_name = first_movie.h3.a.text<br/>first_name</span><span id="c146" class="ml mm it mh b gy mv mo l mp mq">#output:<br/>"Zack Snyder's Justice League"</span></pre><p id="7061" class="pw-post-body-paragraph lg lh it lj b lk ll kd lm ln lo kg lp md lr ls lt me lv lw lx mf lz ma mb mc im bi translated">我们得到了第一部电影的名字，现在我们将试着找到上映的年份。h3标题标记内的年份是span标记。</p><pre class="ks kt ku kv gt mg mh mi mj aw mk bi"><span id="dde9" class="ml mm it mh b gy mn mo l mp mq">first_year = first_movie.h3.find('span', class_ = 'lister-item-year <br/>                                                 text-muted unbold')<br/>first_year</span><span id="b13f" class="ml mm it mh b gy mv mo l mp mq">#output:<br/>&lt;span class="lister-item-year text-muted unbold"&gt;(2021)&lt;/span&gt;</span><span id="3617" class="ml mm it mh b gy mv mo l mp mq">-------------------------------------------------------------</span><span id="973c" class="ml mm it mh b gy mv mo l mp mq">first_year = first_year.text<br/>first_year = first_year.replace('(','')<br/>first_year = first_year.replace(')','')<br/>first_year</span><span id="ab19" class="ml mm it mh b gy mv mo l mp mq">#output:<br/>'2021'</span></pre><p id="012e" class="pw-post-body-paragraph lg lh it lj b lk ll kd lm ln lo kg lp md lr ls lt me lv lw lx mf lz ma mb mc im bi translated">是时候获得这部电影的IMDb评分了。</p><pre class="ks kt ku kv gt mg mh mi mj aw mk bi"><span id="2b8d" class="ml mm it mh b gy mn mo l mp mq">first_imdb = float(first_movie.strong.text)<br/>first_imdb</span><span id="ca48" class="ml mm it mh b gy mv mo l mp mq">#output:<br/>81</span></pre><p id="71bf" class="pw-post-body-paragraph lg lh it lj b lk ll kd lm ln lo kg lp md lr ls lt me lv lw lx mf lz ma mb mc im bi translated">为了找到电影的投票，我们需要检查span属性。</p><pre class="ks kt ku kv gt mg mh mi mj aw mk bi"><span id="a837" class="ml mm it mh b gy mn mo l mp mq">first_votes = first_movie.find('span', attrs = {'name':'nv'})<br/>first_votes</span><span id="e69d" class="ml mm it mh b gy mv mo l mp mq">#output:<br/>&lt;span data-value="335227" name="nv"&gt;335,227&lt;/span&gt;</span><span id="1efb" class="ml mm it mh b gy mv mo l mp mq">-------------------------------------------------------------</span><span id="2f29" class="ml mm it mh b gy mv mo l mp mq">first_votes = int(first_votes['data-value'])<br/>first_votes</span><span id="3f77" class="ml mm it mh b gy mv mo l mp mq">#output:<br/>335227</span></pre><div class="mx my gp gr mz na"><a rel="noopener  ugc nofollow" target="_blank" href="/introduction-to-mlops-for-data-science-e2ca5a759f68"><div class="nb ab fo"><div class="nc ab nd cl cj ne"><h2 class="bd jd gy z fp nf fr fs ng fu fw jc bi translated">面向数据科学的MLOps简介</h2><div class="nh l"><h3 class="bd b gy z fp nf fr fs ng fu fw dk translated">持续集成、持续开发和持续测试的一部分</h3></div><div class="ni l"><p class="bd b dl z fp nf fr fs ng fu fw dk translated">pub.towardsai.net</p></div></div><div class="nj l"><div class="nk l nl nm nn nj no lb na"/></div></div></a></div><div class="mx my gp gr mz na"><a href="https://medium.com/pythoneers/forget-html-and-flask-start-using-streamlit-1b394cfe4595" rel="noopener follow" target="_blank"><div class="nb ab fo"><div class="nc ab nd cl cj ne"><h2 class="bd jd gy z fp nf fr fs ng fu fw jc bi translated">忘记HTML和Flask，开始使用Streamlit</h2><div class="nh l"><h3 class="bd b gy z fp nf fr fs ng fu fw dk translated">数据科学和机器学习的WebApp框架</h3></div><div class="ni l"><p class="bd b dl z fp nf fr fs ng fu fw dk translated">medium.com</p></div></div><div class="nj l"><div class="np l nl nm nn nj no lb na"/></div></div></a></div><p id="01c1" class="pw-post-body-paragraph lg lh it lj b lk ll kd lm ln lo kg lp md lr ls lt me lv lw lx mf lz ma mb mc im bi translated">是时候获取这一页所有电影的所有信息了。</p><pre class="ks kt ku kv gt mg mh mi mj aw mk bi"><span id="42fd" class="ml mm it mh b gy mn mo l mp mq"><strong class="mh jd">#Make a empty list of all variables</strong><br/>names = []<br/>years = []<br/>imdb_ratings = []<br/>metascores = []<br/>votes = []</span><span id="3caf" class="ml mm it mh b gy mv mo l mp mq"><strong class="mh jd"># Extract data from individual movie container</strong><br/>for container in movie_containers:</span></pre><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div class="gh gi nq"><img src="../Images/66a3b94e336f9d7080a8a521ee92b05f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1324/format:webp/1*wcNAtPSdM_Z3hcnBTmvOog.png"/></div></figure><pre class="ks kt ku kv gt mg mh mi mj aw mk bi"><span id="6240" class="ml mm it mh b gy mn mo l mp mq"><strong class="mh jd"># The name</strong><br/>   name = container.h3.a.text<br/> names.append(name)</span><span id="d49e" class="ml mm it mh b gy mv mo l mp mq"><strong class="mh jd"># The year</strong><br/> year = container.h3.find('span', class_ = 'lister-item-year').text<br/> years.append(year)</span><span id="6c08" class="ml mm it mh b gy mv mo l mp mq"><strong class="mh jd"># The IMDB rating</strong><br/> imdb = float(container.strong.text)<br/> imdb_ratings.append(imdb)</span><span id="84ed" class="ml mm it mh b gy mv mo l mp mq"><strong class="mh jd"># The Metascore</strong><br/> m_score = container.find('span', class_ = 'metascore')<br/> if m_score is not None:<br/>   metascores.append(int(m_score.text))<br/> else:<br/>   metascores.append(None)</span><span id="c22e" class="ml mm it mh b gy mv mo l mp mq"><strong class="mh jd"># The number of votes</strong><br/> vote = container.find('span', attrs = {'name':'nv'})['data-value']<br/> votes.append(int(vote))</span></pre><p id="a0cc" class="pw-post-body-paragraph lg lh it lj b lk ll kd lm ln lo kg lp md lr ls lt me lv lw lx mf lz ma mb mc im bi translated">现在，我们将制作从电影页面收集的信息的数据框架。</p><pre class="ks kt ku kv gt mg mh mi mj aw mk bi"><span id="6ed8" class="ml mm it mh b gy mn mo l mp mq">import pandas as pd<br/>test_df = pd.DataFrame({'movie_name': names,<br/>                        'release_year': years,<br/>                        'imdb': imdb_ratings,<br/>                        'metascore': metascores,<br/>                        'votes': votes<br/>                      })<br/>print(test_df.info())<br/>test_df</span></pre><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi nr"><img src="../Images/cf707eaecdeb75605b4121b6408504dd.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*rx6Tvt97eSJq1PxZWdlYQA.png"/></div></div></figure><p id="83ca" class="pw-post-body-paragraph lg lh it lj b lk ll kd lm ln lo kg lp md lr ls lt me lv lw lx mf lz ma mb mc im bi translated">这个电影网站的第一页包含了这部电影的50个条目，我们从第一页中提取了这些信息。</p><blockquote class="ld le lf"><p id="080f" class="lg lh li lj b lk ll kd lm ln lo kg lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated"><strong class="lj jd"> <em class="it">结论</em> </strong></p></blockquote><p id="ccc0" class="pw-post-body-paragraph lg lh it lj b lk ll kd lm ln lo kg lp md lr ls lt me lv lw lx mf lz ma mb mc im bi translated">网页抓取对于数据科学和机器学习的人来说是一个非常有用的工具。</p><p id="e9c8" class="pw-post-body-paragraph lg lh it lj b lk ll kd lm ln lo kg lp md lr ls lt me lv lw lx mf lz ma mb mc im bi translated">我希望你喜欢这篇文章。通过我的<a class="ae mr" href="https://www.linkedin.com/in/data-scientist-95040a1ab/" rel="noopener ugc nofollow" target="_blank"> LinkedIn </a>和<a class="ae mr" href="https://twitter.com/amitprius" rel="noopener ugc nofollow" target="_blank"> twitter </a>联系我。</p><h1 id="1a69" class="ns mm it bd nt nu nv nw nx ny nz oa ob ki oc kj od kl oe km of ko og kp oh oi bi translated">推荐文章</h1><p id="1d4b" class="pw-post-body-paragraph lg lh it lj b lk oj kd lm ln ok kg lp md ol ls lt me om lw lx mf on ma mb mc im bi translated">1.<a class="ae mr" rel="noopener ugc nofollow" target="_blank" href="/8-active-learning-insights-of-python-collection-module-6c9e0cc16f6b?source=friends_link&amp;sk=4a5c9f9ad552005636ae720a658281b1">8 Python的主动学习见解收集模块</a> <br/> 2。<a class="ae mr" rel="noopener ugc nofollow" target="_blank" href="/numpy-linear-algebra-on-images-ed3180978cdb?source=friends_link&amp;sk=d9afa4a1206971f9b1f64862f6291ac0"> NumPy:图像上的线性代数</a>T5】3。<a class="ae mr" rel="noopener ugc nofollow" target="_blank" href="/exception-handling-concepts-in-python-4d5116decac3?source=friends_link&amp;sk=a0ed49d9fdeaa67925eac34ecb55ea30">Python中的异常处理概念</a> <br/> 4。<a class="ae mr" rel="noopener ugc nofollow" target="_blank" href="/pandas-dealing-with-categorical-data-7547305582ff?source=friends_link&amp;sk=11c6809f6623dd4f6dd74d43727297cf">熊猫:处理分类数据</a> <br/> 5。<a class="ae mr" rel="noopener ugc nofollow" target="_blank" href="/hyper-parameters-randomseachcv-and-gridsearchcv-in-machine-learning-b7d091cf56f4?source=friends_link&amp;sk=cab337083fb09601114a6e466ec59689">超参数:机器学习中的RandomSeachCV和GridSearchCV</a><br/>6。<a class="ae mr" href="https://medium.com/towards-artificial-intelligence/fully-explained-linear-regression-with-python-fe2b313f32f3?source=friends_link&amp;sk=53c91a2a51347ec2d93f8222c0e06402" rel="noopener">用Python </a> <br/> 7全面讲解了线性回归。<a class="ae mr" href="https://medium.com/towards-artificial-intelligence/fully-explained-logistic-regression-with-python-f4a16413ddcd?source=friends_link&amp;sk=528181f15a44e48ea38fdd9579241a78" rel="noopener">用Python </a> <br/>充分解释了Logistic回归8。<a class="ae mr" rel="noopener ugc nofollow" target="_blank" href="/data-distribution-using-numpy-with-python-3b64aae6f9d6?source=friends_link&amp;sk=809e75802cbd25ddceb5f0f6496c9803">数据分发使用Numpy与Python </a> <br/> 9。<a class="ae mr" rel="noopener ugc nofollow" target="_blank" href="/decision-trees-vs-random-forests-in-machine-learning-be56c093b0f?source=friends_link&amp;sk=91377248a43b62fe7aeb89a69e590860">机器学习中的决策树vs随机森林</a> <br/> 10。<a class="ae mr" rel="noopener ugc nofollow" target="_blank" href="/standardization-in-data-preprocessing-with-python-96ae89d2f658?source=friends_link&amp;sk=f348435582e8fbb47407e9b359787e41">用Python实现数据预处理的标准化</a></p></div></div>    
</body>
</html>