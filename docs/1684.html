<html>
<head>
<title>Part II — Pre-processing Techniques in Image Processing with Python</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">第二部分Python图像处理中的预处理技术</h1>
<blockquote>原文：<a href="https://pub.towardsai.net/part-ii-pre-processing-techniques-in-image-processing-with-python-17fb628453ff?source=collection_archive---------0-----------------------#2021-03-19">https://pub.towardsai.net/part-ii-pre-processing-techniques-in-image-processing-with-python-17fb628453ff?source=collection_archive---------0-----------------------#2021-03-19</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><h2 id="47de" class="ir is it bd b dl iu iv iw ix iy iz dk ja translated" aria-label="kicker paragraph"><a class="ae ep" href="https://towardsai.net/p/category/computer-vision" rel="noopener ugc nofollow" target="_blank">计算机视觉</a></h2><div class=""/><div class=""><h2 id="5212" class="pw-subtitle-paragraph jz jc it bd b ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq dk translated">OpenCV下的图像处理技术</h2></div><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi kr"><img src="../Images/5985717642238261eb860b5a7fb12f02.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*v3sdonXvVvclnqJn"/></div></div><figcaption class="ld le gj gh gi lf lg bd b be z dk translated">由<a class="ae lh" href="https://unsplash.com/@patuphotos?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Patrick </a>在<a class="ae lh" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上拍摄</figcaption></figure><p id="8887" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">在本文中，我们将使用OpenCV工具进行图像处理。</p><h2 id="4d5e" class="me mf it bd mg mh mi dn mj mk ml dp mm lr mn mo mp lv mq mr ms lz mt mu mv iz bi translated">涵盖的主题:</h2><ul class=""><li id="644d" class="mw mx it lk b ll my lo mz lr na lv nb lz nc md nd ne nf ng bi translated"><strong class="lk jd">模糊图像</strong></li><li id="12ab" class="mw mx it lk b ll nh lo ni lr nj lv nk lz nl md nd ne nf ng bi translated"><strong class="lk jd">增强对比度</strong></li><li id="d806" class="mw mx it lk b ll nh lo ni lr nj lv nk lz nl md nd ne nf ng bi translated"><strong class="lk jd">隔离颜色</strong></li><li id="dd52" class="mw mx it lk b ll nh lo ni lr nj lv nk lz nl md nd ne nf ng bi translated"><strong class="lk jd">移除背景</strong></li></ul><div class="nm nn gp gr no np"><a rel="noopener  ugc nofollow" target="_blank" href="/pre-processing-techniques-in-image-processing-with-python-81e5c8babf09"><div class="nq ab fo"><div class="nr ab ns cl cj nt"><h2 class="bd jd gy z fp nu fr fs nv fu fw jc bi translated">Python图像处理中的预处理技术</h2><div class="nw l"><h3 class="bd b gy z fp nu fr fs nv fu fw dk translated">OpenCV下的图像处理技术</h3></div><div class="nx l"><p class="bd b dl z fp nu fr fs nv fu fw dk translated">pub.towardsai.net</p></div></div><div class="ny l"><div class="nz l oa ob oc ny od lb np"/></div></div></a></div><h2 id="d6ee" class="me mf it bd mg mh mi dn mj mk ml dp mm lr mn mo mp lv mq mr ms lz mt mu mv iz bi translated">模糊图像</h2><p id="e1fd" class="pw-post-body-paragraph li lj it lk b ll my kd ln lo mz kg lq lr oe lt lu lv of lx ly lz og mb mc md im bi translated">当我们试图模糊图像时，每个像素将被转换为其相邻像素的平均值。将对可以表示为内核的相邻像素执行数学运算。该内核的大小有助于确定模糊量，较大的内核产生更平滑的图像。</p><p id="8d34" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">例如，我们希望通过平均每个像素周围的5*5内核的值来模糊图像。</p><pre class="ks kt ku kv gt oh oi oj ok aw ol bi"><span id="6499" class="me mf it oi b gy om on l oo op"># Load libraries<br/>import cv2<br/>import numpy as np<br/>from matplotlib import pyplot as plt</span><span id="f71a" class="me mf it oi b gy oq on l oo op"># Load image as grayscale<br/>image = cv2.imread(“images/plane_256x256.jpg”, cv2.IMREAD_GRAYSCALE)</span><span id="8b35" class="me mf it oi b gy oq on l oo op"># Blur image<br/>image_blurry = cv2.blur(image, (5,5))</span><span id="1604" class="me mf it oi b gy oq on l oo op"># Show image<br/>plt.imshow(image_blurry, cmap=”gray”), plt.axis(“off”)<br/>plt.show()</span></pre><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div class="gh gi or"><img src="../Images/6e87e4a6ed4dfe3778e8fb1f466ad0aa.png" data-original-src="https://miro.medium.com/v2/resize:fit:674/format:webp/0*XkQSc1VhBw8LW55E.png"/></div><figcaption class="ld le gj gh gi lf lg bd b be z dk translated">作者的照片</figcaption></figure><p id="8465" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">现在，我们可以将内核大小增加到100*100来看看模糊的效果</p><pre class="ks kt ku kv gt oh oi oj ok aw ol bi"><span id="f16d" class="me mf it oi b gy om on l oo op"># Blur image<br/>image_very_blurry = cv2.blur(image, (100,100))</span><span id="34ed" class="me mf it oi b gy oq on l oo op"># Show image<br/>plt.imshow(image_very_blurry, cmap=”gray”), plt.xticks([]), plt.yticks([])<br/>plt.show()</span></pre><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div class="gh gi os"><img src="../Images/382d10f7bbaed615290a84bc44a67378.png" data-original-src="https://miro.medium.com/v2/resize:fit:626/format:webp/0*O-J6GoeXcTpFMRF9.png"/></div><figcaption class="ld le gj gh gi lf lg bd b be z dk translated">作者的照片</figcaption></figure><p id="6162" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">内核广泛用于图像处理步骤，如锐化、边缘检测等。</p><p id="9c45" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">对于模糊图像，内核看起来像</p><pre class="ks kt ku kv gt oh oi oj ok aw ol bi"><span id="61ae" class="me mf it oi b gy om on l oo op"># Create kernel<br/>kernel = np.ones((5,5)) / 25.0</span><span id="2a14" class="me mf it oi b gy oq on l oo op"># Show kernel<br/>kernel</span><span id="d69a" class="me mf it oi b gy oq on l oo op">#output: <br/>array([[ 0.04, 0.04, 0.04, 0.04, 0.04],<br/> [ 0.04, 0.04, 0.04, 0.04, 0.04],<br/> [ 0.04, 0.04, 0.04, 0.04, 0.04],<br/> [ 0.04, 0.04, 0.04, 0.04, 0.04],<br/> [ 0.04, 0.04, 0.04, 0.04, 0.04]])</span></pre><p id="d844" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">出现在内核中的中心元素是被检查的像素，而其余的元素将是邻居。正如我们所看到的，所有元素都有相同的值，这意味着它们被归一化为相加为1，其中感兴趣的像素的结果值。</p><p id="716a" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">我们可以手动这样做，并使用“filter2D”将它应用到图像的内核，以产生类似的模糊效果。</p><pre class="ks kt ku kv gt oh oi oj ok aw ol bi"><span id="125b" class="me mf it oi b gy om on l oo op"># Apply kernel<br/>image_kernel = cv2.filter2D(image, -1, kernel)</span><span id="36ce" class="me mf it oi b gy oq on l oo op"># Show image</span><span id="b8ea" class="me mf it oi b gy oq on l oo op">plt.imshow(image_kernel, cmap=”gray”), plt.xticks([]), plt.yticks([])<br/>plt.show()</span></pre><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div class="gh gi ot"><img src="../Images/8125d49bcf937541d1edbf407e18ea03.png" data-original-src="https://miro.medium.com/v2/resize:fit:672/format:webp/0*c5XQkfCS_JDRHlnx.png"/></div><figcaption class="ld le gj gh gi lf lg bd b be z dk translated">作者的照片</figcaption></figure><div class="nm nn gp gr no np"><a rel="noopener  ugc nofollow" target="_blank" href="/z-statistics-t-statistics-p-statistics-are-still-confusing-you-87557047e20a"><div class="nq ab fo"><div class="nr ab ns cl cj nt"><h2 class="bd jd gy z fp nu fr fs nv fu fw jc bi translated">Z-统计量，T-统计量，P-统计量还在迷惑你？</h2><div class="nw l"><h3 class="bd b gy z fp nu fr fs nv fu fw dk translated">机器学习统计学中的定义和概念</h3></div><div class="nx l"><p class="bd b dl z fp nu fr fs nv fu fw dk translated">pub.towardsai.net</p></div></div><div class="ny l"><div class="ou l oa ob oc ny od lb np"/></div></div></a></div><h2 id="1a57" class="me mf it bd mg mh mi dn mj mk ml dp mm lr mn mo mp lv mq mr ms lz mt mu mv iz bi translated">增强对比度</h2><p id="cd8c" class="pw-post-body-paragraph li lj it lk b ll my kd ln lo mz kg lq lr oe lt lu lv of lx ly lz og mb mc md im bi translated">当我们想要增强给定图像的像素之间的对比度时，图像处理将提供直方图均衡化工具，使图像中的对象和形状突出。</p><p id="289f" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">OpenCV库为灰度图像提供了“均衡”方法。</p><pre class="ks kt ku kv gt oh oi oj ok aw ol bi"><span id="b4c3" class="me mf it oi b gy om on l oo op"># Load libraries<br/>import cv2<br/>import numpy as np<br/>from matplotlib import pyplot as plt</span><span id="ea29" class="me mf it oi b gy oq on l oo op"># Load image<br/>image = cv2.imread(“images/plane_256x256.jpg”, cv2.IMREAD_GRAYSCALE)</span><span id="f385" class="me mf it oi b gy oq on l oo op"># Enhance image<br/>image_enhanced = cv2.equalizeHist(image)</span><span id="4e4a" class="me mf it oi b gy oq on l oo op"># Show image<br/>plt.imshow(image_enhanced, cmap=”gray”), plt.axis(“off”)<br/>plt.show()</span></pre><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div class="gh gi ov"><img src="../Images/7ecd16de4092b6888cf44cad5e248a97.png" data-original-src="https://miro.medium.com/v2/resize:fit:650/format:webp/0*czwr2A91hfqN_-lW.png"/></div><figcaption class="ld le gj gh gi lf lg bd b be z dk translated">作者的照片</figcaption></figure><p id="d92f" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">当我们有彩色图像时，首先将图像转换成YUV颜色格式。YUV的独立色彩空间是亮度或亮度，即Y和颜色，即U和v。转换完成后，直接对图像应用<strong class="lk jd"><em class="ow">【equalize hist】</em></strong>方法，然后将其转换回BGR或RGB格式</p><pre class="ks kt ku kv gt oh oi oj ok aw ol bi"><span id="a264" class="me mf it oi b gy om on l oo op"># Load image<br/>image_bgr = cv2.imread(“images/plane.jpg”)</span><span id="a908" class="me mf it oi b gy oq on l oo op"># Convert to YUV<br/>image_yuv = cv2.cvtColor(image_bgr, cv2.COLOR_BGR2YUV)</span><span id="6494" class="me mf it oi b gy oq on l oo op"># Apply histogram equalization<br/>image_yuv[:, :, 0] = cv2.equalizeHist(image_yuv[:, :, 0])</span><span id="ee51" class="me mf it oi b gy oq on l oo op"># Convert to RGB<br/>image_rgb = cv2.cvtColor(image_yuv, cv2.COLOR_YUV2RGB)</span><span id="e545" class="me mf it oi b gy oq on l oo op"># Show image<br/>plt.imshow(image_rgb), plt.axis(“off”)<br/>plt.show()</span></pre><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div class="gh gi ox"><img src="../Images/e3a09d7007c12f489fc0bb685155f7ab.png" data-original-src="https://miro.medium.com/v2/resize:fit:908/format:webp/0*GzBBe3G46BkVw4kz.png"/></div><figcaption class="ld le gj gh gi lf lg bd b be z dk translated">作者的照片</figcaption></figure><p id="444a" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">长话短说，这将图像转换为更宽范围的像素强度，得到的图像通常看起来不像真实的图像，而只是底层数据的视觉表示。</p><p id="2a52" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">如果直方图均衡化方法可以区分图像中感兴趣的对象，那么它就增加了图像处理流水线的价值。</p><div class="nm nn gp gr no np"><a rel="noopener  ugc nofollow" target="_blank" href="/word-cloud-with-python-82e833d8c636"><div class="nq ab fo"><div class="nr ab ns cl cj nt"><h2 class="bd jd gy z fp nu fr fs nv fu fw jc bi translated">使用Python的词云</h2><div class="nw l"><h3 class="bd b gy z fp nu fr fs nv fu fw dk translated">文本注释转换为词云可视化</h3></div><div class="nx l"><p class="bd b dl z fp nu fr fs nv fu fw dk translated">pub.towardsai.net</p></div></div><div class="ny l"><div class="oy l oa ob oc ny od lb np"/></div></div></a></div><h2 id="cfa9" class="me mf it bd mg mh mi dn mj mk ml dp mm lr mn mo mp lv mq mr ms lz mt mu mv iz bi translated">隔离颜色</h2><p id="8951" class="pw-post-body-paragraph li lj it lk b ll my kd ln lo mz kg lq lr oe lt lu lv of lx ly lz og mb mc md im bi translated">借助OpenCV库分离图像中的颜色非常简单。要隔离图像中的颜色，请定义一个颜色范围，然后对图像应用蒙版。在步骤中，首先将图像转换为HSV(色调、饱和度、值)格式。第二，定义一个范围的值，用于从图像中分离这些值，但这是一个困难且非常耗时的部分。最后，我们可以“使用bitwise_and”为图像创建一个遮罩(保留白色区域)，并将其转换为所需的输出格式。</p><pre class="ks kt ku kv gt oh oi oj ok aw ol bi"><span id="a966" class="me mf it oi b gy om on l oo op"># Load libraries<br/>import cv2<br/>import numpy as np<br/>from matplotlib import pyplot as plt</span><span id="96ae" class="me mf it oi b gy oq on l oo op"># Load image<br/>image_bgr = cv2.imread(‘images/plane_256x256.jpg’)</span><span id="9d53" class="me mf it oi b gy oq on l oo op"># Convert BGR to HSV<br/>image_hsv = cv2.cvtColor(image_bgr, cv2.COLOR_BGR2HSV)</span><span id="1022" class="me mf it oi b gy oq on l oo op"># Defining the range of HSV color space for blue color<br/>lower_blue = np.array([50,100,50])<br/>upper_blue = np.array([130,255,255])</span><span id="3dbc" class="me mf it oi b gy oq on l oo op"># Create mask<br/>mask = cv2.inRange(image_hsv, lower_blue, upper_blue)</span><span id="cdd5" class="me mf it oi b gy oq on l oo op"># Mask image<br/>image_bgr_masked = cv2.bitwise_and(image_bgr, image_bgr, mask=mask)</span><span id="605d" class="me mf it oi b gy oq on l oo op"># Convert BGR to RGB<br/>image_rgb = cv2.cvtColor(image_bgr_masked, cv2.COLOR_BGR2RGB)</span><span id="d370" class="me mf it oi b gy oq on l oo op"># Show image<br/>plt.imshow(image_rgb), plt.axis(“off”)<br/>plt.show()</span></pre><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div class="gh gi oz"><img src="../Images/52d4c7ef3275d90950ecad3f89d8d288.png" data-original-src="https://miro.medium.com/v2/resize:fit:634/format:webp/0*EvyCnvWe_mEiXdTR.png"/></div><figcaption class="ld le gj gh gi lf lg bd b be z dk translated">作者的照片</figcaption></figure><pre class="ks kt ku kv gt oh oi oj ok aw ol bi"><span id="005d" class="me mf it oi b gy om on l oo op"># Show image<br/>plt.imshow(mask, cmap=’gray’), plt.axis(“off”)<br/>plt.show()</span></pre><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div class="gh gi pa"><img src="../Images/107e59ff9c2614714e97b8f274028283.png" data-original-src="https://miro.medium.com/v2/resize:fit:700/format:webp/0*zAp4GwfECbDDYs88.png"/></div><figcaption class="ld le gj gh gi lf lg bd b be z dk translated">作者的照片</figcaption></figure><h2 id="aa88" class="me mf it bd mg mh mi dn mj mk ml dp mm lr mn mo mp lv mq mr ms lz mt mu mv iz bi translated">移除背景</h2><p id="dd55" class="pw-post-body-paragraph li lj it lk b ll my kd ln lo mz kg lq lr oe lt lu lv of lx ly lz og mb mc md im bi translated">如果我们想要隔离图像的前景或移除图像中的背景，则在感兴趣的对象周围标记一个矩形，并运行“GrabCut”算法。</p><p id="72c8" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">在代码结果中，我们可以发现“GrabCut”算法做得很好，但仍然有一些区域在图像中留下了轻微的背景。</p><p id="18c2" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">为了避免这种情况，我们可以手动标记它们并删除不需要的区域，但在现实世界的应用程序中，我们会获得成千上万的图像，手动修复它们将会非常繁忙。</p><pre class="ks kt ku kv gt oh oi oj ok aw ol bi"><span id="d8dc" class="me mf it oi b gy om on l oo op"># Load library<br/>import cv2<br/>import numpy as np<br/>from matplotlib import pyplot as plt</span><span id="e39c" class="me mf it oi b gy oq on l oo op"># Load image and convert to RGB<br/>image_bgr = cv2.imread(‘images/plane_256x256.jpg’)<br/>image_rgb = cv2.cvtColor(image_bgr, cv2.COLOR_BGR2RGB)</span><span id="b397" class="me mf it oi b gy oq on l oo op"># Parameter of rectangle: (x, y, width, height)<br/>rectangle = (0, 56, 256, 150)</span><span id="9b89" class="me mf it oi b gy oq on l oo op"># Create initial mask<br/>mask = np.zeros(image_rgb.shape[:2], np.uint8)</span><span id="968a" class="me mf it oi b gy oq on l oo op"># Create temporary arrays used by grabCut<br/>bgdModel = np.zeros((1, 65), np.float64)<br/>fgdModel = np.zeros((1, 65), np.float64)</span><span id="f2a7" class="me mf it oi b gy oq on l oo op"># Run grabCut<br/>cv2.grabCut(image_rgb,           # Our image<br/> mask,                           # The Mask<br/> rectangle,                      # Our rectangle<br/> bgdModel,                       # Temporary array for background<br/> fgdModel,                       # Temporary array for background<br/> 5,                              # Number of iterations<br/> cv2.GC_INIT_WITH_RECT)          # Initiative using our rectangle</span><span id="48fb" class="me mf it oi b gy oq on l oo op">#Create mask where sure and likely backgrounds set to 0, otherwise 1<br/>mask_2 = np.where((mask==2) | (mask==0), 0, 1).astype(‘uint8’)</span><span id="e304" class="me mf it oi b gy oq on l oo op"># To subtract background convolve original image and mask image<br/>image_rgb_nobg = image_rgb * mask_2[:, :, np.newaxis]</span><span id="dda1" class="me mf it oi b gy oq on l oo op"># Show image<br/>plt.imshow(image_rgb_nobg), plt.axis(“off”)<br/>plt.show()</span></pre><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div class="gh gi pb"><img src="../Images/293006090865764adf73387fadf41039.png" data-original-src="https://miro.medium.com/v2/resize:fit:662/format:webp/0*FRCATiwdRUKAU8lZ.png"/></div><figcaption class="ld le gj gh gi lf lg bd b be z dk translated">作者的照片</figcaption></figure><p id="8267" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">在这里，我们在感兴趣的区域周围标记出矩形，“GrabCut”算法假设标记的矩形外部的每个元素都是背景，它使用此信息来计算标记的矩形内部的背景。然后我们创建一个遮罩来表示图像中不同的背景区域。</p><pre class="ks kt ku kv gt oh oi oj ok aw ol bi"><span id="5fd3" class="me mf it oi b gy om on l oo op"># Show mask<br/>plt.imshow(mask, cmap=’gray’), plt.axis(“off”)<br/>plt.show()</span></pre><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi ot"><img src="../Images/c3e8e0f1eb70fc00d4ab3754630f997c.png" data-original-src="https://miro.medium.com/v2/resize:fit:672/format:webp/0*zTg3jTJrUn-O-RV_.png"/></div></div><figcaption class="ld le gj gh gi lf lg bd b be z dk translated">作者的照片</figcaption></figure><p id="ccac" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">在上图中，黑色区域是标记矩形之外的区域，算法假定它是背景。灰色区域是由“GrabCut”算法学习的区域，作为图像中标记矩形内的背景。图像中的白色区域表示感兴趣的区域。</p><p id="e685" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">创建的蒙版非常有助于创建第二个蒙版，合并上面蒙版图像中的黑色和灰色区域，结果只保留了前景。</p><pre class="ks kt ku kv gt oh oi oj ok aw ol bi"><span id="402a" class="me mf it oi b gy om on l oo op"># Show mask<br/>plt.imshow(mask_2, cmap=’gray’), plt.axis(“off”)<br/>plt.show()</span></pre><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div class="gh gi pc"><img src="../Images/2b776e2ebe68ff4139c52c81dcd41ea6.png" data-original-src="https://miro.medium.com/v2/resize:fit:804/format:webp/0*Ayh6ESgqYSkcpsrw.png"/></div><figcaption class="ld le gj gh gi lf lg bd b be z dk translated">作者的照片</figcaption></figure><p id="a356" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">我希望你喜欢这篇文章。通过我的<a class="ae lh" href="https://www.linkedin.com/in/data-scientist-95040a1ab/" rel="noopener ugc nofollow" target="_blank"> LinkedIn </a>和<a class="ae lh" href="https://twitter.com/amitprius" rel="noopener ugc nofollow" target="_blank"> twitter </a>联系我。</p><h1 id="f7c9" class="pd mf it bd mg pe pf pg mj ph pi pj mm ki pk kj mp kl pl km ms ko pm kp mv pn bi translated">推荐文章</h1><p id="6314" class="pw-post-body-paragraph li lj it lk b ll my kd ln lo mz kg lq lr oe lt lu lv of lx ly lz og mb mc md im bi translated"><a class="ae lh" href="https://medium.com/towards-artificial-intelligence/nlp-zero-to-hero-with-python-2df6fcebff6e?sk=2231d868766e96b13d1e9d7db6064df1" rel="noopener"> 1。NLP —零到英雄与Python </a> <br/> 2。<a class="ae lh" href="https://medium.com/towards-artificial-intelligence/python-data-structures-data-types-and-objects-244d0a86c3cf?sk=42f4b462499f3fc3a160b21e2c94dba6" rel="noopener"> Python数据结构数据类型和对象</a>T5】3 .<a class="ae lh" rel="noopener ugc nofollow" target="_blank" href="/data-preprocessing-concepts-with-python-b93c63f14bb6?source=friends_link&amp;sk=5cc4ac66c6c02a6f02077fd43df9681a">数据预处理概念同Python </a> <br/> 4。<a class="ae lh" rel="noopener ugc nofollow" target="_blank" href="/principal-component-analysis-in-dimensionality-reduction-with-python-1a613006d531?source=friends_link&amp;sk=3ed0671fdc04ba395dd36478bcea8a55">用Python进行主成分分析降维</a> <br/> 5。<a class="ae lh" href="https://medium.com/towards-artificial-intelligence/fully-explained-k-means-clustering-with-python-e7caa573176a?source=friends_link&amp;sk=9c5c613ceb10f2d203712634f3b6fb28" rel="noopener">用Python全面讲解K-means聚类</a> <br/> 6。<a class="ae lh" href="https://medium.com/towards-artificial-intelligence/fully-explained-linear-regression-with-python-fe2b313f32f3?source=friends_link&amp;sk=53c91a2a51347ec2d93f8222c0e06402" rel="noopener">用Python </a> <br/> 7全面讲解了线性回归。<a class="ae lh" href="https://medium.com/towards-artificial-intelligence/fully-explained-logistic-regression-with-python-f4a16413ddcd?source=friends_link&amp;sk=528181f15a44e48ea38fdd9579241a78" rel="noopener">用Python </a> <br/>充分解释了Logistic回归8。<a class="ae lh" href="https://medium.com/towards-artificial-intelligence/basic-of-time-series-with-python-a2f7cb451a76?source=friends_link&amp;sk=09d77be2d6b8779973e41ab54ebcf6c5" rel="noopener">用Python实现时间序列的基础知识</a> <br/> 9。<a class="ae lh" rel="noopener ugc nofollow" target="_blank" href="/data-wrangling-with-python-part-1-969e3cc81d69?source=friends_link&amp;sk=9c3649cf20f31a5c9ead51c50c89ba0b">与Python的数据角力—第一部分</a> <br/> 10。<a class="ae lh" href="https://medium.com/analytics-vidhya/confusion-matrix-in-machine-learning-91b6e2b3f9af?source=friends_link&amp;sk=11c6531da0bab7b504d518d02746d4cc" rel="noopener">机器学习中的混淆矩阵</a></p></div></div>    
</body>
</html>