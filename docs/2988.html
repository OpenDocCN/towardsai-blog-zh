<html>
<head>
<title>Meta AI’s Make-A-Scene Pushes the Boundaries of AI Art Synthesis</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">Meta AI的制作场景推动了人工智能艺术合成的边界</h1>
<blockquote>原文：<a href="https://pub.towardsai.net/meta-ais-make-a-scene-pushes-the-boundaries-of-ai-art-synthesis-4792c94b2d3f?source=collection_archive---------2-----------------------#2022-07-26">https://pub.towardsai.net/meta-ais-make-a-scene-pushes-the-boundaries-of-ai-art-synthesis-4792c94b2d3f?source=collection_archive---------2-----------------------#2022-07-26</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="92b1" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">新的模式使用文本到图像和图像到图像的生成来产生惊人的艺术输出。</h2></div><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ki"><img src="../Images/312c7f513dd0d2c44fedf848dda669aa.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*mmh3QFwL-hSgn6_O.jpg"/></div></div><figcaption class="ku kv gj gh gi kw kx bd b be z dk translated">图片来源:Meta AI</figcaption></figure><blockquote class="ky kz la"><p id="9f67" class="lb lc ld le b lf lg ju lh li lj jx lk ll lm ln lo lp lq lr ls lt lu lv lw lx im bi translated">我最近创办了一份专注于人工智能的教育时事通讯，已经有超过125，000名订户。《序列》是一份无废话(意思是没有炒作，没有新闻等)的ML导向时事通讯，需要5分钟阅读。目标是让你与机器学习项目、研究论文和概念保持同步。请通过订阅以下内容来尝试一下:</p></blockquote><div class="ly lz gp gr ma mb"><a href="https://thesequence.substack.com/" rel="noopener  ugc nofollow" target="_blank"><div class="mc ab fo"><div class="md ab me cl cj mf"><h2 class="bd iu gy z fp mg fr fs mh fu fw is bi translated">序列</h2><div class="mi l"><h3 class="bd b gy z fp mg fr fs mh fu fw dk translated">与机器学习、人工智能和数据发展保持同步的最佳资源…</h3></div><div class="mj l"><p class="bd b dl z fp mg fr fs mh fu fw dk translated">thesequence.substack.com</p></div></div><div class="mk l"><div class="ml l mm mn mo mk mp ks mb"/></div></div></a></div><p id="7b3a" class="pw-post-body-paragraph lb lc it le b lf lg ju lh li lj jx lk mq lm ln lo mr lq lr ls ms lu lv lw lx im bi translated">最近几个月，人工智能(AI)在文本到图像合成方面的研究已经脱离了图表。像OpenAI的DALL-E 2、GLIDE或谷歌的Parti或Imagen这样的模型已经显示了使用深度学习模拟创造性表达的可能性。尽管取得了进展，但这些模型在生成捕捉文本输入的完整语义的图像方面仍有非常明显的局限性。最近，Meta AI公布了一种叫做<a class="ae mt" href="https://arxiv.org/abs/2203.13131" rel="noopener ugc nofollow" target="_blank">制作场景</a>的新方法，该方法使用一些聪明的技术来解决文本到图像合成中的一些基本挑战。</p><p id="9adf" class="pw-post-body-paragraph lb lc it le b lf lg ju lh li lj jx lk mq lm ln lo mr lq lr ls ms lu lv lw lx im bi translated">使用文本到图像合成来模拟人类创造性表达的过程目前面临各种障碍:</p><p id="8225" class="pw-post-body-paragraph lb lc it le b lf lg ju lh li lj jx lk mq lm ln lo mr lq lr ls ms lu lv lw lx im bi translated"><strong class="le iu">可控性:</strong>使用文本作为唯一的输入，很难捕捉物体、表情、形状和图像的其他基本方面之间的空间关系。</p><p id="9673" class="pw-post-body-paragraph lb lc it le b lf lg ju lh li lj jx lk mq lm ln lo mr lq lr ls ms lu lv lw lx im bi translated"><strong class="le iu">质量和分辨率:</strong>如今大多数文本到图像模型都被限制为256x256图像。</p><p id="0bb5" class="pw-post-body-paragraph lb lc it le b lf lg ju lh li lj jx lk mq lm ln lo mr lq lr ls ms lu lv lw lx im bi translated"><strong class="le iu">人类感知:</strong>由文本到图像合成方法产生的图像通常不强调与人类注意力和感知自然相关的特定对象。</p><h1 id="ec6a" class="mu mv it bd mw mx my mz na nb nc nd ne jz nf ka ng kc nh kd ni kf nj kg nk nl bi translated">大闹一场</h1><p id="a921" class="pw-post-body-paragraph lb lc it le b lf nm ju lh li nn jx lk mq no ln lo mr np lr ls ms nq lv lw lx im bi translated">Meta AI的Make-A-Scene通过在一个高度可扩展的模型中结合文本到图像和图像到图像的生成，解决了上述一些挑战。使用草图形式的图像输入有助于提高产生的输出的准确性，细化位置、对象之间的关系、表情等方面。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi nr"><img src="../Images/582c859256640242b04cff327a693140.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*LnI4CI1TIQI1P75d6eqADQ.png"/></div></div><figcaption class="ku kv gj gh gi kw kx bd b be z dk translated">图片来源:Meta AI</figcaption></figure><p id="bae5" class="pw-post-body-paragraph lb lc it le b lf lg ju lh li lj jx lk mq lm ln lo mr lq lr ls ms lu lv lw lx im bi translated">Make-A-Scene的架构由一个使用文本和图像标记作为输入的自回归转换器组成。此外，变压器使用有条件控制的场景tokes使用分割地图。在推断阶段，从输入图像或直接从变换器生成分割标记。为了有效地管理损失，Make-A-Scene使用矢量量化的变分自动编码器(VQVAE)来编码和解码图像和场景令牌，其中显式损失针对与人类感知和注意力相关的特定图像区域。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi ns"><img src="../Images/c69b71fb94ffda999ca05aa9d9caa5a5.png" data-original-src="https://miro.medium.com/v2/resize:fit:764/format:webp/1*6VIVxGv7zT2N8bSEI2Imwg.png"/></div><figcaption class="ku kv gj gh gi kw kx bd b be z dk translated">图片来源:Meta AI</figcaption></figure><p id="99db" class="pw-post-body-paragraph lb lc it le b lf lg ju lh li lj jx lk mq lm ln lo mr lq lr ls ms lu lv lw lx im bi translated">结果是一个模型，它可以从文本输入输出高分辨率图像，同时提高生成输出的可控性和人类感知。</p><h1 id="ccef" class="mu mv it bd mw mx my mz na nb nc nd ne jz nf ka ng kc nh kd ni kf nj kg nk nl bi translated">在实践中大闹一场</h1><p id="8f67" class="pw-post-body-paragraph lb lc it le b lf nm ju lh li nn jx lk mq no ln lo mr np lr ls ms nq lv lw lx im bi translated">为了验证Make-A-Scene的功能，Meta AI为ofia Crespo、Scott Eaton、Alexander Reben和Refik Anadol等知名人工智能艺术家提供了一个版本。他们的一些测试产生了惊人的发明:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi nt"><img src="../Images/917dac02ee30f195da594ef3cb59b3fa.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*eQQbTLB36_qU4hT_zhnSsw.png"/></div></div><figcaption class="ku kv gj gh gi kw kx bd b be z dk translated">图片来源:Meta AI</figcaption></figure><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi nu"><img src="../Images/3bb901e8d6060ddeedb94045be5f6989.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*8XxZwjJy2UpFW5eyVt3lsw.png"/></div></div><figcaption class="ku kv gj gh gi kw kx bd b be z dk translated">图片来源:Meta AI</figcaption></figure><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi nv"><img src="../Images/274fc84e0d562468722d0b06d0a6b4d6.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Xw6n3vgktFO_e3pYiWXpDw.png"/></div></div><figcaption class="ku kv gj gh gi kw kx bd b be z dk translated">图片来源:Meta AI</figcaption></figure><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi nw"><img src="../Images/e148d151849b607d4bdf9d84de26ef7d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*iZIKR21XVYV1kTJ8n_Uwrg.png"/></div></div><figcaption class="ku kv gj gh gi kw kx bd b be z dk translated">图片来源:Meta AI</figcaption></figure><p id="3478" class="pw-post-body-paragraph lb lc it le b lf lg ju lh li lj jx lk mq lm ln lo mr lq lr ls ms lu lv lw lx im bi translated">制作一个场景代表了文本到图像合成的一个有趣的发展。Meta AI没有开源实现，但已经有一些尝试来重现论文中概述的模型。</p></div></div>    
</body>
</html>