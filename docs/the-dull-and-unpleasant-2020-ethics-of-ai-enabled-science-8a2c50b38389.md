# 人工智能科学沉闷而令人不快的 2020 伦理

> 原文：<https://pub.towardsai.net/the-dull-and-unpleasant-2020-ethics-of-ai-enabled-science-8a2c50b38389?source=collection_archive---------2----------------------->

![](img/85065ae9596e73d850e0633ef6ba6c79.png)

Pixabay 提供的 Wild0ne

在 1997 年的电影《加蒂卡》中，伊桑·霍克展示了人类精神在一个假设的、过渡到完全清晰的、基因编辑的未来中的蛮力决心，23 年后的今天，所有希望自己孩子成功的父母都被迫做出艰难的选择。编辑，给你的孩子最好的基因，或者让大自然随机重组它们，产生一个不确定的结果。

伊桑成功地完成了所有的脑力和体力任务，成为了一名虚构世界的宇航员，这个世界充满了被认为身体完美的天才，但是，抛开*和*gat tica 的科学家如何确定“最佳基因”的标准不谈，我们在 2020 年面临的现实是一个有趣的现实，具有这部电影的一些特征。

虽然中国遗传学家何建奎是[现在失踪](https://www.abc.net.au/news/2018-12-07/chinese-scientist-who-edited-twins-genes-he-jiankui-missing/10588528)，他可能在历史上被认为是使 Gattica 未来成为现实的人。每个有经济能力的父母都可能决定去基因控制法律不太严格的国家旅行，并决定这样做，要么是为了子宫内的孩子，要么是为了他们自己。

用人类构成的材料扮演上帝是一件看起来有点遥远的事情，然而，在数据科学技术的许多用户无意识的道德规范的推动下，用人们的声誉和潜力扮演上帝在这里是真实的。

读到斯坦福大学和华沙大学的这一 ML [研究成果](https://arxiv.org/pdf/1904.05270.pdf)时，我真的感到非常不安，在那里，从谷歌街景图像中获得的房屋颗粒特征被发现可以预测其居民的车祸风险*，因为*房屋的人口统计特征。

令人不安的是，这种 ML 和模型选择预测的努力，它只需要一个广义线性回归模型(GLM)这样做。甚至不需要贝叶斯或 DNN 方法。这支持了 Kaggle 的最新从业者调查，即良好的线性回归仍然非常有用。GLM 的有效性仅仅是由公开可用的大数据实现的。

美国有大量可用的公共人口统计数据，这些数据出现在这篇研究论文中。除了像谷歌和脸书的隐私政策嵌入在他们的服务条款中，允许研究人员自由支配将这些数据加入到你的演讲和视频数据行为中，未经同意对公民进行预测性远程分析的时代已经到来。

虽然作者在他们的结论中正确地提出了数据隐私，但很明显，a)他们希望打动的保险公司；以及 b)大学部门及其内部部门的地位压倒了对社会公民的可怕影响。

我发现像这样的研究人员写了一篇论文，创造了一个新的，对他们来说已被证实的事实，然后得出了本质上的结论‘哦，是的，有隐私问题，但看看我们的模型有多有预测性，我们发表了一篇论文，尽管是在 archivx.org 的 T2

这个模型的可怕的*先验的*含义是，你住在哪里是你是否会发生车祸的不变的预测。他们的模型优化“证明”了这一点。

正如我们在之前所说的[，伦理不是一个‘部门’,也不是一个附属品，更不是一个事后的想法。这项研究的伦理实际上是*而*创造模型的行为正在进行中。这种情况下的道德当然是由数据的可用性和模型本身的数学来决定的。这里的人类研究人员恰好是这辆巴士上的乘客。他们不受控制。数学和数据的框架围绕并超越了它们[1]。](https://medium.com/swlh/saving-the-web-and-the-ethics-of-bravery-d1356fab9968)

在这种以数据和数学为中心的伦理中，更值得注意的是对人类潜力的忽视。

以这项研究为例，现在可以肯定地“证明”你住在哪里预示着你发生事故的倾向。

沿着这些思路的另一项研究是基因图谱。

这些研究人员估计他们已经发现了大约 109 个基因标记，这些标记可以为你是否会患上精神疾病提供线索。).

这位科学家的双重不道德的*先验*论述是:

1.  我们携带的不可磨灭的 DNA 的关系预示着我们将来是否会有精神疾病；和
2.  精神病学诊断实际上是一门因果科学，就像物理或化学一样。

如果你读过任何关于医疗权力的文献，你就会知道医生，尤其是精神病医生，他们自己是通过把病人作为实验对象来复制自己权力的积极参与者。20 世纪 80 年代的 DSM-3 曾经将同性恋归类为精神疾病，现在在 2013 年的 DSM-5 中已经不是了。艾伦·图灵的医学阉割不是白做的。这个社区有过度的法律支持，根据一个专家的意见，不经审判就把人监禁起来。如果你看到一个，赶快跑开。非常危险。尤其是哈佛大学的精神病学教授。权力越来越大。只有上帝、维特根斯坦或阿西能质疑他们？

否[2]。教授们只是基因科学和精神病学诊断艺术这辆大客车上的乘客。

然而，主要的一点是，在这种情况下，正如预测车祸一样，人工智能和数据科学已经被用于创造另一种假定不可改变的因果关系。也就是说，如果你有这 109 个基因中的任何一个，你可能会患上精神疾病，不管当时的 DSM *说精神疾病是什么。*

这种联系，这种关系具有相同的不变性特征，我不能反驳我的基因，就像我不能反驳我住在哪里一样，数据和数学都是这么说的。

如果这种基因图谱以鉴定为借口在出生时应用，一个婴儿拥有这 109 个基因中的任何一个，他们的未来会是什么样子？他们会一辈子扛红旗吗？如果一个孩子在一个容易发生车祸的家庭中长大，当他们申请自己的保险时，他们会“继承”这种“耻辱”吗？

这就是 2020 年人工智能预测的沉闷和令人不快的伦理问题。它在两个方面辜负了我们。**不变性**，这带来了对人类潜力的无知，以及研究者本身是他们所服务的科学话语的嵌入式伦理的**主体**的事实。

就像伊桑一样，他克服了他所谓的身体和精神限制，以智慧战胜了加蒂卡的科学家，证明他们是错误的，并成功地成为了一名宇航员，我们所有人都具有异常强大的能力，能够超越我们的环境，实现宏伟和意想不到的事情。

今天，人工智能支持的数据科学的问题是，这种潜在的事实没有在任何模型中得到考虑，因为它无法测量也无法量化。它是无形的。但至少可以考虑一下？

更有争议、违反直觉和难以解决的问题是，我认为科学家认为为他们服务的许多人工智能数据和数学中隐含的伦理实际上使科学家服务并复制它。他们在下一个算法，下一篇论文中再现了这种枯燥和令人不快的伦理，并教给他们的学生，他们的孩子。它复制它们。*他们*是巴士上的乘客，巴士上说人类是不可改变的，他们的模型证明了这一点，所以他们只能相信。

也许解决不变性也能解决这个棘手的问题？

**脚注**

[1]我们甚至不会开始评论某些职业，如数据科学，如何根据其本质和实践中固有的人文主义和非人文主义来预选他们的从业者。

[2]要了解精神病学的论述，你可以从诊所的诞生开始。例如，历史上，精神病患者被称为着魔，学者，神谕或女巫。现在由于精神病学的力量，他们被关起来，被麻醉，未经审判，不再是社区的一部分，很危险。是不是精神病学家应该被关起来，因为他们占据了学者们的权力场所？