<html>
<head>
<title>All About K-Means Clustering</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">关于K均值聚类的所有内容</h1>
<blockquote>原文：<a href="https://pub.towardsai.net/all-about-k-means-clustering-b6529efac76a?source=collection_archive---------4-----------------------#2022-05-31">https://pub.towardsai.net/all-about-k-means-clustering-b6529efac76a?source=collection_archive---------4-----------------------#2022-05-31</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><p id="2ba2" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">在本文中，我们将通过回答以下问题来理解聚类算法:</p><ol class=""><li id="69bf" class="kl km iq jp b jq jr ju jv jy kn kc ko kg kp kk kq kr ks kt bi translated">什么是集群？</li><li id="1c1b" class="kl km iq jp b jq ku ju kv jy kw kc kx kg ky kk kq kr ks kt bi translated">集群的实际应用有哪些？</li><li id="a9a9" class="kl km iq jp b jq ku ju kv jy kw kc kx kg ky kk kq kr ks kt bi translated">K-means聚类是如何工作的？</li><li id="ab61" class="kl km iq jp b jq ku ju kv jy kw kc kx kg ky kk kq kr ks kt bi translated">怎样才能求K的值？</li><li id="89e5" class="kl km iq jp b jq ku ju kv jy kw kc kx kg ky kk kq kr ks kt bi translated">K-Means聚类的优缺点是什么？</li><li id="99bf" class="kl km iq jp b jq ku ju kv jy kw kc kx kg ky kk kq kr ks kt bi translated">如何实现K-Means聚类？</li></ol><h1 id="c5c9" class="kz la iq bd lb lc ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw bi translated"><strong class="ak">什么是聚类？</strong></h1><p id="cbc0" class="pw-post-body-paragraph jn jo iq jp b jq lx js jt ju ly jw jx jy lz ka kb kc ma ke kf kg mb ki kj kk ij bi translated">经典的定义是:</p><blockquote class="mc md me"><p id="5240" class="jn jo mf jp b jq jr js jt ju jv jw jx mg jz ka kb mh kd ke kf mi kh ki kj kk ij bi translated">聚类是一种无监督的机器学习技术，它在未标记的数据中找到某些模式/结构，根据它们的属性将它们分成不同的组</p></blockquote><figure class="mk ml mm mn gt mo gh gi paragraph-image"><div class="gh gi mj"><img src="../Images/01121eb060fa4ac85b2f18f6f6a4ef34.png" data-original-src="https://miro.medium.com/v2/resize:fit:1324/format:webp/1*Kr7-H1EiC1OQM1sqoulf8w.png"/></div></figure><p id="c7e5" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">为了理解这个定义，让我们举个例子:在图书馆里，书是以一种特殊的方式组织起来的，这样当一个人寻找某本书时，他/她就能找到它。所以，为了组织这些书，它们被按照它们相似的属性组合在一起。这种通过相似的属性和行为将不同元素分组的技术称为聚类。</p><h1 id="8079" class="kz la iq bd lb lc ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw bi translated"><strong class="ak">集群的实际应用是什么？</strong></h1><p id="344e" class="pw-post-body-paragraph jn jo iq jp b jq lx js jt ju ly jw jx jy lz ka kb kc ma ke kf kg mb ki kj kk ij bi translated">不同的聚类技术用于解决日常生活中面临的现实挑战。一些应用如下:</p><ul class=""><li id="c881" class="kl km iq jp b jq jr ju jv jy kn kc ko kg kp kk mr kr ks kt bi translated"><strong class="jp ir">对于客户细分:</strong>你可以根据客户的购买行为、他们在你网站上的活跃程度等等来对他们进行分类。这有助于了解你的客户是谁，他们需要什么，这样你就可以针对每个细分市场调整你的产品和营销活动。例如，在推荐系统中，这对于推荐同一个集群中的其他用户喜欢的内容非常有用。</li><li id="54b7" class="kl km iq jp b jq ku ju kv jy kw kc kx kg ky kk mr kr ks kt bi translated"><strong class="jp ir">对于数据分析:</strong>当分析一个新的数据集时，首先发现相似实例的聚类通常是有用的，因为单独分析聚类通常更容易。</li><li id="ba52" class="kl km iq jp b jq ku ju kv jy kw kc kx kg ky kk mr kr ks kt bi translated"><strong class="jp ir">作为一种降维技术:</strong>一旦数据集被聚类，通常可以测量每个实例与每个聚类的相似性(相似性是一个实例与一个聚类匹配程度的任何度量)。然后，每个实例的特征向量x可以替换为其聚类相似性的向量。如果有k个簇，那么这个向量是k维的。这通常比原始特征向量的维数低得多，但它可以为进一步处理保留足够的信息。</li><li id="9024" class="kl km iq jp b jq ku ju kv jy kw kc kx kg ky kk mr kr ks kt bi translated"><strong class="jp ir">对于异常检测(也称为离群点检测):</strong>对所有聚类都具有低亲和力的任何实例都可能是异常。例如，如果您已经根据网站用户的行为对他们进行了分类，那么您可以检测到具有异常行为的用户，例如每秒异常的请求数等等。异常检测在检测制造中的缺陷或欺诈检测中特别有用。</li><li id="61b8" class="kl km iq jp b jq ku ju kv jy kw kc kx kg ky kk mr kr ks kt bi translated"><strong class="jp ir">对于半监督学习:</strong>如果你只有几个标签，你可以执行聚类并将标签传播到同一个聚类中的所有实例。这可以大大增加后续监督学习算法可用的标签数量，从而提高其性能。</li><li id="a3c0" class="kl km iq jp b jq ku ju kv jy kw kc kx kg ky kk mr kr ks kt bi translated"><strong class="jp ir">对于搜索引擎:</strong>例如，一些搜索引擎让你搜索与参考图片相似的图片。要构建这样一个系统，首先要对数据库中的所有图像应用聚类算法:相似的图像将出现在同一个聚类中。然后，当用户提供参考图像时，您需要做的就是使用训练好的聚类模型找到该图像的聚类，然后您可以简单地返回该聚类中的所有图像。</li><li id="045c" class="kl km iq jp b jq ku ju kv jy kw kc kx kg ky kk mr kr ks kt bi translated"><strong class="jp ir">分割图像:</strong>通过根据颜色对像素进行聚类，然后用聚类的平均颜色替换每个像素的颜色，可以大大减少图像中不同颜色的数量。这种技术被用在许多物体检测和跟踪系统中，因为它使得检测每个物体的轮廓变得更容易。</li></ul><h1 id="3cc0" class="kz la iq bd lb lc ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw bi translated">K-means聚类是如何工作的？</h1><p id="4015" class="pw-post-body-paragraph jn jo iq jp b jq lx js jt ju ly jw jx jy lz ka kb kc ma ke kf kg mb ki kj kk ij bi translated">K-Means是一种聚类方法，其中根据数据与K个中心的距离，将数据分组为K个不同的非重叠聚类。首先需要指定<strong class="jp ir"> K </strong>的值，然后算法将这些点准确地分配给一个聚类。</p><h2 id="2160" class="ms la iq bd lb mt mu dn lf mv mw dp lj jy mx my ln kc mz na lr kg nb nc lv nd bi translated">算法:</h2><ol class=""><li id="ea01" class="kl km iq jp b jq lx ju ly jy ne kc nf kg ng kk kq kr ks kt bi translated">随机分配K个中心。</li><li id="00f7" class="kl km iq jp b jq ku ju kv jy kw kc kx kg ky kk kq kr ks kt bi translated">计算所有点与所有K个中心的距离，并根据最短距离将这些点分配给聚类。模型的<em class="mf">惯性</em>是每个实例与其最近质心之间的均方距离。目标是拥有一个惯性最低的模型。</li><li id="26f6" class="kl km iq jp b jq ku ju kv jy kw kc kx kg ky kk kq kr ks kt bi translated">一旦所有的点都被分配到集群，重新计算质心。</li><li id="9899" class="kl km iq jp b jq ku ju kv jy kw kc kx kg ky kk kq kr ks kt bi translated">重复步骤2和3，直到质心的位置停止变化，并且点的簇分配变得恒定。</li></ol><p id="3b4f" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">K-Means聚类的算法非常简单。现在，让我们把我们在算法中讨论过的东西形象化，以便更好地理解它。</p><p id="8420" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">第一步是分配k的值。k的值表示我们想要分离数据的组的数量。</p><figure class="mk ml mm mn gt mo gh gi paragraph-image"><div class="gh gi nh"><img src="../Images/8fae5f3380bec4c413726b2084a9af14.png" data-original-src="https://miro.medium.com/v2/resize:fit:1206/format:webp/1*MvvK-VyY36Ee4mpwqCJOtw.png"/></div><figcaption class="ni nj gj gh gi nk nl bd b be z dk translated">静止点是k形质心</figcaption></figure><p id="966b" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">这里我们指定了k = 3的值。这意味着我们已经生成了三个随机质心，基于这些质心我们可以分离我们的数据。</p><p id="a51e" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">第二步现在我们必须计算每个数据点相对于每个质心的距离，我们已经介绍过了。然后选择最近的质心并指定一个组。</p><figure class="mk ml mm mn gt mo gh gi paragraph-image"><div class="gh gi nm"><img src="../Images/796b3c7b989dd4caa3d25f5707f28ec7.png" data-original-src="https://miro.medium.com/v2/resize:fit:1192/format:webp/1*fkj_GBmN8fwMFl9574PS3A.png"/></div></figure><p id="4129" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">第三步是重新计算我们引入的质心的坐标。这个步骤可以通过计算分配给各个质心的点的平均值来完成。</p><figure class="mk ml mm mn gt mo gh gi paragraph-image"><div class="gh gi nm"><img src="../Images/0530bd4ea77b1b51840cab3faf7f2dc0.png" data-original-src="https://miro.medium.com/v2/resize:fit:1192/format:webp/1*ArJjZ_7nr4AjRTBAS-u0JA.png"/></div></figure><p id="437d" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">第四步是重复第二步和第三步，直到质心的坐标停止移动。</p><figure class="mk ml mm mn gt mo gh gi paragraph-image"><div class="gh gi nm"><img src="../Images/9826a85f592cbeaf3d64af73b7b055f7.png" data-original-src="https://miro.medium.com/v2/resize:fit:1192/format:webp/1*zByD6kD9hLmmd7lAw8fAPQ.png"/></div></figure><p id="26a4" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">因此，最终输出将如下所示:</p><figure class="mk ml mm mn gt mo gh gi paragraph-image"><div class="gh gi nn"><img src="../Images/dc1fe8fb95b306f481b531bc3674f135.png" data-original-src="https://miro.medium.com/v2/resize:fit:1186/format:webp/1*fwTlEMYku1UYbjnFedryuA.png"/></div></figure><p id="2fce" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">所以，我们也可视化了k-means聚类的核心直觉。但是还有一个问题我们必须回答，我们如何决定k的值，让我们看看如何决定？</p><h1 id="c635" class="kz la iq bd lb lc ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw bi translated">怎样才能求出K的值？</h1><p id="a989" class="pw-post-body-paragraph jn jo iq jp b jq lx js jt ju ly jw jx jy lz ka kb kc ma ke kf kg mb ki kj kk ij bi translated">借助于一种方法可以求出K的值，这种方法就是T2肘法。让我们看看这个肘法是怎么回事。</p><figure class="mk ml mm mn gt mo gh gi paragraph-image"><div role="button" tabindex="0" class="np nq di nr bf ns"><div class="gh gi no"><img src="../Images/86980fd8712bcb97d481816aac92faf5.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*H5oGB7GxUIyQ7vX2Um07Aw.png"/></div></div></figure><p id="c830" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">该方法基于类内距离平方和(WCSS或惯性)与类数量之间的关系。观察到，首先随着集群数量的增加，WCSS急剧下降，然后在一定数量的集群之后，WCSS的下降不那么显著。在WCSS和聚类数之间的图变得相对模糊之后的点被称为拐点，并且在该点的聚类数是最优聚类数，因为即使在该点之后增加聚类数，变化也不会减少太多。</p><h1 id="996a" class="kz la iq bd lb lc ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw bi translated">K-Means聚类的优缺点是什么？</h1><h2 id="4712" class="ms la iq bd lb mt mu dn lf mv mw dp lj jy mx my ln kc mz na lr kg nb nc lv nd bi translated">优势:</h2><ol class=""><li id="20c6" class="kl km iq jp b jq lx ju ly jy ne kc nf kg ng kk kq kr ks kt bi translated">这个算法非常容易理解和实现。</li><li id="0e60" class="kl km iq jp b jq ku ju kv jy kw kc kx kg ky kk kq kr ks kt bi translated">该算法高效、稳健、灵活</li><li id="908a" class="kl km iq jp b jq ku ju kv jy kw kc kx kg ky kk kq kr ks kt bi translated">如果数据集是不同的球形聚类，则给出最佳结果</li></ol><h2 id="e587" class="ms la iq bd lb mt mu dn lf mv mw dp lj jy mx my ln kc mz na lr kg nb nc lv nd bi translated"><strong class="ak">缺点:</strong></h2><ol class=""><li id="6f48" class="kl km iq jp b jq lx ju ly jy ne kc nf kg ng kk kq kr ks kt bi translated">该算法需要预先指定聚类中心的数量，即k的值。</li><li id="0ab0" class="kl km iq jp b jq ku ju kv jy kw kc kx kg ky kk kq kr ks kt bi translated">它不能处理异常值和噪声数据，因为质心会发生偏转</li><li id="e5b8" class="kl km iq jp b jq ku ju kv jy kw kc kx kg ky kk kq kr ks kt bi translated">它不能很好地处理非常大的数据集，因为它需要大量的计算时间。</li></ol><h1 id="e6fe" class="kz la iq bd lb lc ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw bi translated">如何实现K-Means聚类？</h1><p id="5f9d" class="pw-post-body-paragraph jn jo iq jp b jq lx js jt ju ly jw jx jy lz ka kb kc ma ke kf kg mb ki kj kk ij bi translated">K-Means聚类的实现非常简单，只需遵循我们上面讨论的算法。</p><blockquote class="mc md me"><p id="297c" class="jn jo mf jp b jq jr js jt ju jv jw jx mg jz ka kb mh kd ke kf mi kh ki kj kk ij bi translated"><strong class="jp ir">注:</strong>下面的k-means代码是从零开始的。我没有使用scikit-learn库来构建代码。</p></blockquote><p id="5101" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">首先，让我们从python导入导入包开始。</p><figure class="mk ml mm mn gt mo gh gi paragraph-image"><div class="gh gi nt"><img src="../Images/f36960da9adf7687dbbca1d71ddc2206.png" data-original-src="https://miro.medium.com/v2/resize:fit:768/format:webp/1*bgX5TBzCuEZKtmm2zRok1w.png"/></div></figure><p id="46ee" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">现在，创建一个玩具数据集。</p><figure class="mk ml mm mn gt mo gh gi paragraph-image"><div role="button" tabindex="0" class="np nq di nr bf ns"><div class="gh gi nu"><img src="../Images/c76d92b1e86da0317139a9ca2d554785.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*yiXMnJZQUwd8kd4LZANnMw.png"/></div></div></figure><p id="3d7b" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">可视化我们的玩具数据集</p><figure class="mk ml mm mn gt mo gh gi paragraph-image"><div class="gh gi nv"><img src="../Images/c917b0c8e56e36b53f0ff2318a4b2fe2.png" data-original-src="https://miro.medium.com/v2/resize:fit:982/format:webp/1*lGTaORphHVALR2T5Z5m88A.png"/></div></figure><p id="505a" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">步骤1:初始化K的值，即创建5个随机质心</p><figure class="mk ml mm mn gt mo gh gi paragraph-image"><div class="gh gi nw"><img src="../Images/72791582cbef269226365e6ceb18c23a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1042/format:webp/1*hkspjVthgFSC6pyW1UQg0w.png"/></div></figure><p id="3035" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">想象质心。</p><figure class="mk ml mm mn gt mo gh gi paragraph-image"><div class="gh gi nx"><img src="../Images/9fc29421b864e1d0ef3fe882342e86bc.png" data-original-src="https://miro.medium.com/v2/resize:fit:974/format:webp/1*Atn2J42hAYRfBxQ06EIipQ.png"/></div></figure><p id="5b46" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">步骤2:计算每个数据点到质心的距离，并指定最近的质心。</p><figure class="mk ml mm mn gt mo gh gi paragraph-image"><div class="gh gi ny"><img src="../Images/ca57e57c46934b84d4f1b7a77573547d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1024/format:webp/1*4wS4DTwIGoY4k2COyUDmOw.png"/></div></figure><p id="18a6" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">可视化数据以及它们如何与质心组合在一起。</p><figure class="mk ml mm mn gt mo gh gi paragraph-image"><div class="gh gi nz"><img src="../Images/ec52a58ba8fd920efeff65a98192ab2d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1016/format:webp/1*7xkwweLom-kNUJW2dSvdCw.png"/></div></figure><p id="e443" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">步骤3:计算每个组的平均值，并将其分配给质心，以创建新的质心。</p><figure class="mk ml mm mn gt mo gh gi paragraph-image"><div class="gh gi oa"><img src="../Images/e63e2b11296d25cb4c77d343e1923c41.png" data-original-src="https://miro.medium.com/v2/resize:fit:848/format:webp/1*JS5o4k-qsACGYzP4lSzi9A.png"/></div></figure><p id="4ade" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">可视化新的质心。</p><figure class="mk ml mm mn gt mo gh gi paragraph-image"><div class="gh gi ob"><img src="../Images/d733e9ef84e6ad101401baa3bcc23156.png" data-original-src="https://miro.medium.com/v2/resize:fit:1010/format:webp/1*-gbQsmW4Jh_oNTXlxkKJsw.png"/></div></figure><p id="e792" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">第四步:现在重复第二步和第三步，直到质心停止变化。</p><figure class="mk ml mm mn gt mo gh gi paragraph-image"><div class="gh gi oc"><img src="../Images/0a90846862351c1dc73c701b04bdce60.png" data-original-src="https://miro.medium.com/v2/resize:fit:988/format:webp/1*xhhdQLta6yDBen-eVyS1LQ.png"/></div></figure><p id="c864" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">可视化最终聚类。</p><figure class="mk ml mm mn gt mo gh gi paragraph-image"><div class="gh gi od"><img src="../Images/809f0837570a91706fd531946b8c8e49.png" data-original-src="https://miro.medium.com/v2/resize:fit:976/format:webp/1*wzTNnhiTfiXTI_okksfljg.png"/></div></figure><blockquote class="mc md me"><p id="801a" class="jn jo mf jp b jq jr js jt ju jv jw jx mg jz ka kb mh kd ke kf mi kh ki kj kk ij bi translated"><em class="iq">本文使用的笔记本链接:</em></p></blockquote><div class="oe of gp gr og oh"><a href="https://github.com/Akashdawari/Articles_Blogs_Content/blob/main/K-Means%20Clustering.ipynb" rel="noopener  ugc nofollow" target="_blank"><div class="oi ab fo"><div class="oj ab ok cl cj ol"><h2 class="bd ir gy z fp om fr fs on fu fw ip bi translated">Articles _ Blogs _ Content/K-Means clustering . ipynb at main Akashdawari/Articles _ Blogs _ Content</h2><div class="oo l"><h3 class="bd b gy z fp om fr fs on fu fw dk translated">这个知识库包含了jupyter关于发表在博客上的文章的笔记本。…</h3></div><div class="op l"><p class="bd b dl z fp om fr fs on fu fw dk translated">github.com</p></div></div><div class="oq l"><div class="or l os ot ou oq ov mp oh"/></div></div></a></div><p id="e4dd" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">喜欢并分享如果你觉得这篇文章有帮助。还有，关注我的medium，了解更多机器学习和深度学习相关的内容。</p></div></div>    
</body>
</html>