<html>
<head>
<title>26 Words About Neural Networks, Every AI-Savvy Leader Must Know</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">关于神经网络的26个词，每个精通人工智能的领导者都必须知道</h1>
<blockquote>原文：<a href="https://pub.towardsai.net/26-words-about-neural-networks-every-ai-neural-networks-1085bd972fd5?source=collection_archive---------4-----------------------#2020-05-22">https://pub.towardsai.net/26-words-about-neural-networks-every-ai-neural-networks-1085bd972fd5?source=collection_archive---------4-----------------------#2020-05-22</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><h2 id="dcce" class="io ip iq bd b dl ir is it iu iv iw dk ix translated" aria-label="kicker paragraph">人工智能</h2><div class=""/><div class=""><h2 id="74c8" class="pw-subtitle-paragraph jw iz iq bd b jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn dk translated">你能解释这些吗？检验你的知识！</h2></div><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div role="button" tabindex="0" class="ku kv di kw bf kx"><div class="gh gi ko"><img src="../Images/0b20aeeb5e5119ed4c581f3f652e1800.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*cniBfqi65-TP6P39k_vR-g.jpeg"/></div></div><figcaption class="la lb gj gh gi lc ld bd b be z dk translated">来源:<a class="ae le" href="https://www.needpix.com/photo/915859/artificial-intelligence-ai-robot-android-droid-intelligence-health" rel="noopener ugc nofollow" target="_blank"> NeedPix </a></figcaption></figure><p id="05f0" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated"><em class="mb">【这是</em> <strong class="lh ja"> <em class="mb">系列</em> </strong> <em class="mb">的第6部。在继续之前，请确保您阅读了关于</em> <a class="ae le" href="https://medium.com/towards-artificial-intelligence/ai-search-e0cb610237f6" rel="noopener"> <em class="mb">搜索</em></a><a class="ae le" href="https://medium.com/towards-artificial-intelligence/ai-knowledge-1020a00eb45d" rel="noopener"><em class="mb">知识</em></a><a class="ae le" href="https://medium.com/towards-artificial-intelligence/ai-uncertainty-4ac6810899ac" rel="noopener"><em class="mb">不确定性</em></a><em class="mb"/><a class="ae le" href="https://medium.com/towards-artificial-intelligence/ai-optimization-b8735dc09448" rel="noopener"><em class="mb">优化</em> </a>，以及<a class="ae le" href="https://medium.com/towards-artificial-intelligence/ai-learning-2eaea82ee6d" rel="noopener"> <em class="mb">机器学习</em> </a> <em class="mb">。下一个题目是</em> <a class="ae le" href="https://medium.com/towards-artificial-intelligence/ai-language-1d266caa72c6" rel="noopener"> <em class="mb">语文</em> </a> <em class="mb">。】</em></p><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div role="button" tabindex="0" class="ku kv di kw bf kx"><div class="gh gi mc"><img src="../Images/0874f43f3addf68cd01ae6ba5b7ebb6a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*HcHHVgR4uDProeogCiJkPQ.png"/></div></div></figure><p id="697b" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">表现最好的AI应用有一个共同点:它们都是围绕<strong class="lh ja"> <em class="mb">人工神经网络构建的。</em> </strong>这些人脑启发的计算模型<strong class="lh ja"> <em class="mb"> </em> </strong>催生了最近流行的<strong class="lh ja"> <em class="mb">深度学习</em> </strong>技术。</p><p id="92d7" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">这两个概念并不新鲜；事实上，它们已经存在了70多年<em class="mb">【更多信息，请查看</em><a class="md me ep" href="https://medium.com/u/f902dfcdf9c9?source=post_page-----1085bd972fd5--------------------------------" rel="noopener" target="_blank"><em class="mb">Jaspreet</em></a><em class="mb">的</em> <a class="ae le" href="https://towardsdatascience.com/a-concise-history-of-neural-networks-2070655d3fec" rel="noopener" target="_blank"> <em class="mb">神经网络简史</em></a><em class="mb"/>。</p><p id="e114" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">只是从最近开始，我们才能够通过更好更便宜的计算能力有效地运行如此复杂的数学计算。</p><p id="e98b" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated"><strong class="lh ja">但是人类和人工神经网络到底有什么区别呢？</strong> <br/> <strong class="lh ja">还有，我们能让计算机像我们一样思考吗？</strong></p><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div class="gh gi mf"><img src="../Images/55ee555e0f9e8dd480833f78fc9f3a9a.png" data-original-src="https://miro.medium.com/v2/resize:fit:500/1*2lY4JWCeWpO0Y8KJWT3W1Q.gif"/></div></figure><p id="2115" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">为了帮助你回答这些问题，本文围绕<strong class="lh ja"> <em class="mb">神经网络</em> </strong>领域，对<strong class="lh ja"><em class="mb"/></strong>主要概念和术语进行了简要的定义和解释。</p></div><div class="ab cl mg mh hu mi" role="separator"><span class="mj bw bk mk ml mm"/><span class="mj bw bk mk ml mm"/><span class="mj bw bk mk ml"/></div><div class="ij ik il im in"><h1 id="0411" class="mn mo iq bd mp mq mr ms mt mu mv mw mx kf my kg mz ki na kj nb kl nc km nd ne bi translated">神经网络</h1><p id="ee2b" class="pw-post-body-paragraph lf lg iq lh b li nf ka lk ll ng kd ln lo nh lq lr ls ni lu lv lw nj ly lz ma ij bi translated"><strong class="lh ja">神经网络:</strong>生物神经网络，由实际的生物神经元组成</p><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div role="button" tabindex="0" class="ku kv di kw bf kx"><div class="gh gi nk"><img src="../Images/2c62492c5633e7635f4e37f674f1b754.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*R_yKnsJb8M1TsGU-6O0edw.png"/></div></div><figcaption class="la lb gj gh gi lc ld bd b be z dk translated">神经网络</figcaption></figure><p id="2a7d" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated"><strong class="lh ja">神经元:</strong>通过专门的连接与其他细胞进行交流的神经细胞</p><p id="429e" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated"><strong class="lh ja">人工神经网络:</strong>某种程度上受人类神经网络启发的计算系统，它“学习”执行任务，而无需使用特定于任务的规则进行编程，其中神经元的连接被建模为权重</p><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div role="button" tabindex="0" class="ku kv di kw bf kx"><div class="gh gi nl"><img src="../Images/c07cf1c7b34772062580d2c60a0f5b24.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*HHl38yvlg_zUVJOegeNadw.png"/></div></div><figcaption class="la lb gj gh gi lc ld bd b be z dk translated">人工神经网络</figcaption></figure><p id="801b" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated"><strong class="lh ja">阶跃函数:</strong>从一个常数值突然增加或减少到另一个常数值的函数，例如:</p><pre class="kp kq kr ks gt nm nn no np aw nq bi"><span id="9dbc" class="nr mo iq nn b gy ns nt l nu nv">g(x) = 1 if x ≥ 0, else 0</span></pre><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div role="button" tabindex="0" class="ku kv di kw bf kx"><div class="gh gi nw"><img src="../Images/31a9930a56cc9bc3cf947fe0b38cc202.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*MmNnPdP6q2UncODobHl4gw.png"/></div></div><figcaption class="la lb gj gh gi lc ld bd b be z dk translated">阶跃函数</figcaption></figure><p id="1b38" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated"><strong class="lh ja">逻辑sigmoid: </strong>具有特征“S”形曲线或sigmoid曲线的数学函数，例如:</p><pre class="kp kq kr ks gt nm nn no np aw nq bi"><span id="0713" class="nr mo iq nn b gy ns nt l nu nv">g(x) = e[x] / (e[x] +1)</span></pre><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div role="button" tabindex="0" class="ku kv di kw bf kx"><div class="gh gi nx"><img src="../Images/57d5a4fd43295abfcdb157adfad8b24d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Pmwnn2TTfFQmX26jPEo-TQ.png"/></div></div><figcaption class="la lb gj gh gi lc ld bd b be z dk translated">逻辑乙状结肠</figcaption></figure><p id="bc59" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated"><strong class="lh ja">校正线性单元(ReLU): </strong>一种激活函数，常用于计算机视觉、语音识别&amp;深度神经网络，例如:</p><pre class="kp kq kr ks gt nm nn no np aw nq bi"><span id="939d" class="nr mo iq nn b gy ns nt l nu nv">g(x) = max(0, x)</span></pre><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div role="button" tabindex="0" class="ku kv di kw bf kx"><div class="gh gi ny"><img src="../Images/826269df274ed0b89c63b7ebec0c7cf0.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Yjtixv1rhsD1CzbNmLTUzw.png"/></div></div><figcaption class="la lb gj gh gi lc ld bd b be z dk translated">整流线性装置</figcaption></figure><p id="37e0" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated"><em class="mb">【更多详情请查看</em> <a class="md me ep" href="https://medium.com/u/ea644bb7cd3e?source=post_page-----1085bd972fd5--------------------------------" rel="noopener" target="_blank"> <em class="mb">丹青刘</em> </a> <em class="mb">的</em> <a class="ae le" href="https://medium.com/@danqing/a-practical-guide-to-relu-b83ca804f1f7" rel="noopener"> <em class="mb">实用指南ReLU</em></a><em class="mb"/></p><p id="ee61" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated"><strong class="lh ja">梯度下降:</strong>训练神经网络时最小化损失的算法</p><p id="780a" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated"><strong class="lh ja">随机梯度下降:</strong>一种迭代方法，用于优化具有适当平滑特性的目标函数</p><p id="65a6" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated"><strong class="lh ja">小批量梯度下降:</strong>梯度下降算法的变体，将训练数据集分成小批量，以计算模型误差并更新模型系数</p><p id="13ca" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated"><strong class="lh ja">感知器:</strong>用于二进制分类器的监督学习的学习算法，或者:仅由输入值、权重和偏差、净和以及激活函数组成的单层神经网络</p><p id="66d5" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated"><strong class="lh ja">多层神经网络:</strong>具有输入层、输出层和至少一个隐藏层的人工神经网络</p><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div role="button" tabindex="0" class="ku kv di kw bf kx"><div class="gh gi nz"><img src="../Images/50cd36bb961807dbad8f137df6f077f0.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*m8-zMyRnD9q9KDG0Iie3QA.png"/></div></div><figcaption class="la lb gj gh gi lc ld bd b be z dk translated">多层神经网络</figcaption></figure><p id="8260" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated"><strong class="lh ja">反向传播:</strong>用于训练具有隐藏层的神经网络的算法</p><p id="8a64" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated"><strong class="lh ja">深度神经网络:</strong>具有多个隐藏层的神经网络</p><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div role="button" tabindex="0" class="ku kv di kw bf kx"><div class="gh gi oa"><img src="../Images/617b0faf7caec94f5a7fc44269a42ebf.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*G3QJ-JpmBlmOxrYfK6fWRg.png"/></div></div><figcaption class="la lb gj gh gi lc ld bd b be z dk translated">深度神经网络</figcaption></figure><p id="32ba" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated"><strong class="lh ja">删除:</strong>从神经网络中临时删除随机选择的单元，以防止过度依赖某些单元</p><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div role="button" tabindex="0" class="ku kv di kw bf kx"><div class="gh gi ob"><img src="../Images/ccb3f52a633e37dcff035fd1673b9365.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*D3mhaQK--juArbAlGb2Odg.png"/></div></div><figcaption class="la lb gj gh gi lc ld bd b be z dk translated">拒绝传统社会的人</figcaption></figure><p id="c41f" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated"><strong class="lh ja">计算机视觉:</strong>分析和理解数字图像的计算方法</p><p id="d5dd" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated"><strong class="lh ja"> Tensorflow: </strong>谷歌的一个开源框架，用于运行机器学习、深度学习和分析任务</p><p id="49da" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated"><em class="mb">[</em><a class="md me ep" href="https://medium.com/u/b1d410cb9700?source=post_page-----1085bd972fd5--------------------------------" rel="noopener" target="_blank"><em class="mb">tensor flow</em></a><em class="mb">之前的媒体博客已经搬家，现在位于</em> <a class="ae le" href="https://blog.tensorflow.org/" rel="noopener ugc nofollow" target="_blank"> <em class="mb">这里</em></a><em class="mb">……】</em></p><p id="9bfa" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated"><strong class="lh ja">图像卷积:</strong>应用过滤器，将图像的每个像素值添加到其邻居，根据核矩阵进行加权</p><p id="26f6" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated"><strong class="lh ja">汇集:</strong>通过从输入中的区域取样来减少输入的大小</p><p id="ab14" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated"><strong class="lh ja">最大汇集:</strong>通过选择每个区域的最大值来汇集</p><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div role="button" tabindex="0" class="ku kv di kw bf kx"><div class="gh gi oc"><img src="../Images/59dfeb95bb754319facc41957327e2fd.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*qii4vYl16eFl5vTOtZSXOw.png"/></div></div><figcaption class="la lb gj gh gi lc ld bd b be z dk translated">最大池化</figcaption></figure><p id="9b39" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated"><strong class="lh ja">卷积神经网络:</strong>使用卷积的神经网络，通常用于分析图像</p><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div role="button" tabindex="0" class="ku kv di kw bf kx"><div class="gh gi od"><img src="../Images/191cf5c5f5d8df3b3748c66bc99168d7.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*K0Cx_6tKD_ZdYcgDDNLNFg.png"/></div></div><figcaption class="la lb gj gh gi lc ld bd b be z dk translated">卷积神经网络</figcaption></figure><p id="987f" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated"><strong class="lh ja">前馈神经网络:</strong>仅在一个方向上有连接的神经网络</p><p id="a593" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated"><strong class="lh ja">递归神经网络:</strong>一种神经网络，它产生反馈到其自身输入的输出</p><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div role="button" tabindex="0" class="ku kv di kw bf kx"><div class="gh gi oe"><img src="../Images/559d46c1b76fe5e3e942ab590cfd4774.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*fXvVKE2zFU7LxsKdrg2EVA.png"/></div></div><figcaption class="la lb gj gh gi lc ld bd b be z dk translated">递归神经网络</figcaption></figure><p id="4d50" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">既然你已经能够解释神经网络最基本的术语，你已经准备好进一步探索这个兔子洞了。</p><p id="1de6" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">通过探索<strong class="lh ja"> <em class="mb">其他剩余的关键主题</em> </strong>，包括<a class="ae le" href="https://medium.com/towards-artificial-intelligence/ai-search-e0cb610237f6" rel="noopener"> <em class="mb">搜索</em> </a>，<a class="ae le" href="https://medium.com/towards-artificial-intelligence/ai-knowledge-1020a00eb45d" rel="noopener"> <em class="mb">知识</em> </a>，<a class="ae le" href="https://medium.com/towards-artificial-intelligence/ai-uncertainty-4ac6810899ac" rel="noopener"> <em class="mb">不确定性</em> </a> <em class="mb">，</em> <a class="ae le" href="https://medium.com/towards-artificial-intelligence/ai-optimization-b8735dc09448" rel="noopener"> <em class="mb">优化</em> </a>，<a class="ae le" href="https://medium.com/towards-artificial-intelligence/ai-learning-2eaea82ee6d" rel="noopener"> <em class="mb">机器学习</em> </a>和<a class="ae le" href="https://medium.com/towards-artificial-intelligence/ai-language-1d266caa72c6" rel="noopener">，完成您成为一名成熟的人工智能领导者的旅程</a></p><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div role="button" tabindex="0" class="ku kv di kw bf kx"><div class="gh gi mc"><img src="../Images/0874f43f3addf68cd01ae6ba5b7ebb6a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*HcHHVgR4uDProeogCiJkPQ.png"/></div></div></figure><p id="a55e" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated"><strong class="lh ja"> <em class="mb">喜欢读什么？</em> </strong> <em class="mb"> </em> <strong class="lh ja"> <em class="mb">渴望了解更多？</em> </strong> <em class="mb"> <br/>关注我上</em> <a class="ae le" href="https://medium.com/@yannique" rel="noopener"> <em class="mb">中</em> </a> <em class="mb">或</em><a class="ae le" href="https://www.linkedin.com/in/yannique/" rel="noopener ugc nofollow" target="_blank"><em class="mb">LinkedIn</em></a><em class="mb">。</em></p></div><div class="ab cl mg mh hu mi" role="separator"><span class="mj bw bk mk ml mm"/><span class="mj bw bk mk ml mm"/><span class="mj bw bk mk ml"/></div><div class="ij ik il im in"><p id="ce81" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated"><strong class="lh ja"> <em class="mb">关于作者:<br/> </em> </strong> Yannique Hecht作品在结合策略、客户洞察、数据、创新等领域。虽然他的职业生涯一直在航空、旅游、金融和技术行业，但他对管理充满热情。Yannique专门开发AI &amp;机器学习产品商业化的策略。</p></div></div>    
</body>
</html>