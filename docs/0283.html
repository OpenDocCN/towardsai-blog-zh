<html>
<head>
<title>NLP News Cypher | 01.19.20</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">NLP新闻密码| 01.19.20</h1>
<blockquote>原文：<a href="https://pub.towardsai.net/nlp-news-cypher-01-19-20-9e49c22401b3?source=collection_archive---------2-----------------------#2020-01-20">https://pub.towardsai.net/nlp-news-cypher-01-19-20-9e49c22401b3?source=collection_archive---------2-----------------------#2020-01-20</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><figure class="ip iq gp gr ir is gh gi paragraph-image"><div role="button" tabindex="0" class="it iu di iv bf iw"><div class="gh gi io"><img src="../Images/95f5b61f7b18c7a1b7ab3a1f6a3b7d90.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*uiUbGdOBNi-LJ67C"/></div></div><figcaption class="iz ja gj gh gi jb jc bd b be z dk translated">罗伯特·穆雷在<a class="ae jd" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上的照片</figcaption></figure><div class=""/><div class=""><h2 id="06e7" class="pw-subtitle-paragraph kd jf jg bd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku dk translated">走向人工智能和无限</h2></div></div><div class="ab cl kv kw hu kx" role="separator"><span class="ky bw bk kz la lb"/><span class="ky bw bk kz la lb"/><span class="ky bw bk kz la"/></div><div class="ij ik il im in"><p id="c3bc" class="pw-post-body-paragraph lc ld jg le b lf lg kh lh li lj kk lk ll lm ln lo lp lq lr ls lt lu lv lw lx ij bi ly translated"><span class="l lz ma mb bm mc md me mf mg di">第二个。我们回来了！多好的一周啊！</span></p><p id="aeed" class="pw-post-body-paragraph lc ld jg le b lf lg kh lh li lj kk lk ll lm ln lo lp lq lr ls lt lu lv lw lx ij bi translated">首先，我们很高兴地宣布，我们现在将在《走向人工智能的平台》上发布我们的每周博客💪💪！很高兴这次出版合作，因为我们打算将NLP趋势带给更多的全球读者，从纽约的开发者到香港的商业专业人士。</p><p id="515e" class="pw-post-body-paragraph lc ld jg le b lf lg kh lh li lj kk lk ll lm ln lo lp lq lr ls lt lu lv lw lx ij bi translated">谈到全球…</p><p id="4ece" class="pw-post-body-paragraph lc ld jg le b lf lg kh lh li lj kk lk ll lm ln lo lp lq lr ls lt lu lv lw lx ij bi translated">如果你在过去的一周里很忙:我们放弃了“<strong class="le jh">大坏NLP数据库</strong>”，这是一个为ML和NLP开发者准备的大型数据集集合！数据库继续增长，我们已经收到了来自用户的极好的建议。更新即将推出！</p><p id="8daf" class="pw-post-body-paragraph lc ld jg le b lf lg kh lh li lj kk lk ll lm ln lo lp lq lr ls lt lu lv lw lx ij bi translated"><strong class="le jh">周三公告文章:</strong></p><div class="ip iq gp gr ir mh"><a href="https://medium.com/towards-artificial-intelligence/nlp-dataset-library-14443ddd3084" rel="noopener follow" target="_blank"><div class="mi ab fo"><div class="mj ab mk cl cj ml"><h2 class="bd jh gy z fp mm fr fs mn fu fw jf bi translated">NLP数据集库</h2><div class="mo l"><h3 class="bd b gy z fp mm fr fs mn fu fw dk translated">面向ML开发人员的数百个数据集(还在增加)</h3></div><div class="mp l"><p class="bd b dl z fp mm fr fs mn fu fw dk translated">medium.com</p></div></div><div class="mq l"><div class="mr l ms mt mu mq mv ix mh"/></div></div></a></div><p id="6543" class="pw-post-body-paragraph lc ld jg le b lf lg kh lh li lj kk lk ll lm ln lo lp lq lr ls lt lu lv lw lx ij bi translated"><strong class="le jh">数据库:</strong></p><div class="ip iq gp gr ir mh"><a href="https://quantumstat.com/dataset/dataset.html" rel="noopener  ugc nofollow" target="_blank"><div class="mi ab fo"><div class="mj ab mk cl cj ml"><h2 class="bd jh gy z fp mm fr fs mn fu fw jf bi translated">大坏NLP数据库-量子统计</h2><div class="mo l"><h3 class="bd b gy z fp mm fr fs mn fu fw dk translated">自然语言处理中各种任务的数据集</h3></div><div class="mp l"><p class="bd b dl z fp mm fr fs mn fu fw dk translated">quantumstat.com</p></div></div><div class="mq l"><div class="mw l ms mt mu mq mv ix mh"/></div></div></a></div><p id="0454" class="pw-post-body-paragraph lc ld jg le b lf lg kh lh li lj kk lk ll lm ln lo lp lq lr ls lt lu lv lw lx ij bi translated">谢谢大家的支持！</p><figure class="my mz na nb gt is gh gi paragraph-image"><div class="gh gi mx"><img src="../Images/1c4c7b18d0fd2275929cd48cacb3edee.png" data-original-src="https://miro.medium.com/v2/resize:fit:1150/format:webp/1*FdOf0arPaeBToJKyA4bTvA.png"/></div><figcaption class="iz ja gj gh gi jb jc bd b be z dk translated">解密的</figcaption></figure><h1 id="8435" class="nc nd jg bd ne nf ng nh ni nj nk nl nm km nn kn no kp np kq nq ks nr kt ns nt bi translated">本周:</h1><blockquote class="nu nv nw"><p id="7a1c" class="lc ld nx le b lf lg kh lh li lj kk lk ny lm ln lo nz lq lr ls oa lu lv lw lx ij bi translated">重整变压器</p><p id="f909" class="lc ld nx le b lf lg kh lh li lj kk lk ny lm ln lo nz lq lr ls oa lu lv lw lx ij bi translated">说出想法和想法</p><p id="60fc" class="lc ld nx le b lf lg kh lh li lj kk lk ny lm ln lo nz lq lr ls oa lu lv lw lx ij bi translated">识别脸书的实时语音</p><p id="98f6" class="lc ld nx le b lf lg kh lh li lj kk lk ny lm ln lo nz lq lr ls oa lu lv lw lx ij bi translated">深度黑客</p><p id="6765" class="lc ld nx le b lf lg kh lh li lj kk lk ny lm ln lo nz lq lr ls oa lu lv lw lx ij bi translated">Wolfram数据分析网络研讨会</p><p id="c5c8" class="lc ld nx le b lf lg kh lh li lj kk lk ny lm ln lo nz lq lr ls oa lu lv lw lx ij bi translated">康尼遇见空间</p><p id="6625" class="lc ld nx le b lf lg kh lh li lj kk lk ny lm ln lo nz lq lr ls oa lu lv lw lx ij bi translated">我推荐研究论文</p><p id="4f6d" class="lc ld nx le b lf lg kh lh li lj kk lk ny lm ln lo nz lq lr ls oa lu lv lw lx ij bi translated">本周数据集:记录</p><p id="3ec3" class="lc ld nx le b lf lg kh lh li lj kk lk ny lm ln lo nz lq lr ls oa lu lv lw lx ij bi translated">同时，回到维加斯农场…</p></blockquote><h1 id="7d8b" class="nc nd jg bd ne nf ng nh ni nj nk nl nm km nn kn no kp np kq nq ks nr kt ns nt bi translated">重整变压器</h1><blockquote class="nu nv nw"><p id="576f" class="lc ld nx le b lf lg kh lh li lj kk lk ny lm ln lo nz lq lr ls oa lu lv lw lx ij bi translated">Transformer模型旨在处理多达100万个单词的上下文窗口，所有这些都在单个加速器上，并且仅使用16GB内存</p></blockquote><p id="c5bd" class="pw-post-body-paragraph lc ld jg le b lf lg kh lh li lj kk lk ll lm ln lo lp lq lr ls lt lu lv lw lx ij bi translated">谷歌以一声巨响和一个新的变形金刚开始了新的一年。谷歌的新模型想要解决两个问题:注意力和记忆力，这两个问题都是大输入序列的变形金刚所面临的压力。</p><p id="17ed" class="pw-post-body-paragraph lc ld jg le b lf lg kh lh li lj kk lk ll lm ln lo lp lq lr ls lt lu lv lw lx ij bi translated">在大量单词的情况下，注意力很难扩展，因此，谷歌引入了一种哈希技术，允许模型有效地将相似的向量“连接”在一起，并将它们分成组块。在关注这些片段之后，这导致计算负荷的减少。</p><p id="397a" class="pw-post-body-paragraph lc ld jg le b lf lg kh lh li lj kk lk ll lm ln lo lp lq lr ls lt lu lv lw lx ij bi translated">在多层模型中会出现存储问题，因为需要在每一层为反向传递保存激活。这可能会导致您的GPU的内存爆炸又名OOM错误。</p><figure class="my mz na nb gt is"><div class="bz fp l di"><div class="ob oc l"/></div><figcaption class="iz ja gj gh gi jb jc bd b be z dk translated"><a class="ae jd" href="https://arxiv.org/pdf/1707.04585.pdf" rel="noopener ugc nofollow" target="_blank">链接</a></figcaption></figure><p id="8a37" class="pw-post-body-paragraph lc ld jg le b lf lg kh lh li lj kk lk ll lm ln lo lp lq lr ls lt lu lv lw lx ij bi translated">为了缓解这个问题，谷歌转向可逆层。(这种技术在上面的文章中讨论过)。它避免在内存中存储每一层的激活，而是通过一种巧妙的技术在向后传递时计算它们。</p><p id="bb13" class="pw-post-body-paragraph lc ld jg le b lf lg kh lh li lj kk lk ll lm ln lo lp lq lr ls lt lu lv lw lx ij bi translated"><strong class="le jh">博客:</strong></p><div class="ip iq gp gr ir mh"><a href="https://ai.googleblog.com/2020/01/reformer-efficient-transformer.html" rel="noopener  ugc nofollow" target="_blank"><div class="mi ab fo"><div class="mj ab mk cl cj ml"><h2 class="bd jh gy z fp mm fr fs mn fu fw jf bi translated">改革者:高效的变压器</h2><div class="mo l"><h3 class="bd b gy z fp mm fr fs mn fu fw dk translated">理解连续数据——如语言、音乐或视频——是一项具有挑战性的任务，尤其是当有…</h3></div><div class="mp l"><p class="bd b dl z fp mm fr fs mn fu fw dk translated">ai.googleblog.com</p></div></div><div class="mq l"><div class="od l ms mt mu mq mv ix mh"/></div></div></a></div><p id="d66e" class="pw-post-body-paragraph lc ld jg le b lf lg kh lh li lj kk lk ll lm ln lo lp lq lr ls lt lu lv lw lx ij bi translated"><strong class="le jh">用于文本生成的Colab:</strong></p><div class="ip iq gp gr ir mh"><a href="https://colab.research.google.com/github/google/trax/blob/master/trax/models/reformer/text_generation.ipynb" rel="noopener  ugc nofollow" target="_blank"><div class="mi ab fo"><div class="mj ab mk cl cj ml"><h2 class="bd jh gy z fp mm fr fs mn fu fw jf bi translated">谷歌联合实验室</h2><div class="mo l"><h3 class="bd b gy z fp mm fr fs mn fu fw dk translated">编辑描述</h3></div><div class="mp l"><p class="bd b dl z fp mm fr fs mn fu fw dk translated">colab.research.google.com</p></div></div><div class="mq l"><div class="oe l ms mt mu mq mv ix mh"/></div></div></a></div><h1 id="9606" class="nc nd jg bd ne nf ng nh ni nj nk nl nm km nn kn no kp np kq nq ks nr kt ns nt bi translated">说心里话</h1><p id="4862" class="pw-post-body-paragraph lc ld jg le b lf of kh lh li og kk lk ll oh ln lo lp oi lr ls lt oj lv lw lx ij bi translated">脸书的对话式人工智能研究小组ParlAI的新研究将一个在几个基于图像的对话任务(又名多模态)中表现良好的单一模型结合在一起。下面是一些输出示例:</p><figure class="my mz na nb gt is gh gi paragraph-image"><div role="button" tabindex="0" class="it iu di iv bf iw"><div class="gh gi ok"><img src="../Images/d9d8a2aab6b3614409cc8f25d5ea43fa.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*3aeqj-aHscO0LbnJ"/></div></div></figure><p id="fb79" class="pw-post-body-paragraph lc ld jg le b lf lg kh lh li lj kk lk ll lm ln lo lp lq lr ls lt lu lv lw lx ij bi translated"><strong class="le jh">论文:</strong></p><figure class="my mz na nb gt is"><div class="bz fp l di"><div class="ob oc l"/></div><figcaption class="iz ja gj gh gi jb jc bd b be z dk translated"><a class="ae jd" href="https://arxiv.org/pdf/1912.12394.pdf" rel="noopener ugc nofollow" target="_blank">链接</a></figcaption></figure><h1 id="ba94" class="nc nd jg bd ne nf ng nh ni nj nk nl nm km nn kn no kp np kq nq ks nr kt ns nt bi translated">识别脸书的实时语音</h1><p id="fcd6" class="pw-post-body-paragraph lc ld jg le b lf of kh lh li og kk lk ll oh ln lo lp oi lr ls lt oj lv lw lx ij bi translated">脸书开源了他们的wav2letter@anywhere语音识别框架。这里的要点是，这个框架的推论是针对实时性能的。此外，它在LibriSpeech数据集上实现了SOTA性能！</p><p id="3bc9" class="pw-post-body-paragraph lc ld jg le b lf lg kh lh li lj kk lk ll lm ln lo lp lq lr ls lt lu lv lw lx ij bi translated"><strong class="le jh">博客:</strong></p><div class="ip iq gp gr ir mh"><a href="https://ai.facebook.com/blog/online-speech-recognition-with-wav2letteranywhere/" rel="noopener  ugc nofollow" target="_blank"><div class="mi ab fo"><div class="mj ab mk cl cj ml"><h2 class="bd jh gy z fp mm fr fs mn fu fw jf bi translated">使用wav2letter@anywhere进行在线语音识别</h2><div class="mo l"><h3 class="bd b gy z fp mm fr fs mn fu fw dk translated">从输入音频流实时转录语音的过程称为在线语音识别。大多数…</h3></div><div class="mp l"><p class="bd b dl z fp mm fr fs mn fu fw dk translated">ai.facebook.com</p></div></div><div class="mq l"><div class="ol l ms mt mu mq mv ix mh"/></div></div></a></div><p id="c1ae" class="pw-post-body-paragraph lc ld jg le b lf lg kh lh li lj kk lk ll lm ln lo lp lq lr ls lt lu lv lw lx ij bi translated"><strong class="le jh"> GitHub: </strong></p><div class="ip iq gp gr ir mh"><a href="https://github.com/facebookresearch/wav2letter/tree/master/recipes/models/sota/2019" rel="noopener  ugc nofollow" target="_blank"><div class="mi ab fo"><div class="mj ab mk cl cj ml"><h2 class="bd jh gy z fp mm fr fs mn fu fw jf bi translated">facebookresearch/wav2letter</h2><div class="mo l"><h3 class="bd b gy z fp mm fr fs mn fu fw dk translated">在本文中，我们考虑:声学建模的不同架构:不同的标准:不同的…</h3></div><div class="mp l"><p class="bd b dl z fp mm fr fs mn fu fw dk translated">github.com</p></div></div><div class="mq l"><div class="om l ms mt mu mq mv ix mh"/></div></div></a></div><h1 id="dcb6" class="nc nd jg bd ne nf ng nh ni nj nk nl nm km nn kn no kp np kq nq ks nr kt ns nt bi translated">深度黑客</h1><p id="f338" class="pw-post-body-paragraph lc ld jg le b lf of kh lh li og kk lk ll oh ln lo lp oi lr ls lt oj lv lw lx ij bi translated">当进行工程设计时，饼干会在微观层面上破碎。是的，你可以从一个大的微调变压器获得很好的效果，但你仍然需要磨练你的经典技巧。Priyansh Trivedi在他的博客中透露了一些关于这个话题的信息:</p><div class="ip iq gp gr ir mh"><a href="https://priyansh.page/bag-of-tricks/2020/01/10/bagoftricks-p1.html" rel="noopener  ugc nofollow" target="_blank"><div class="mi ab fo"><div class="mj ab mk cl cj ml"><h2 class="bd jh gy z fp mm fr fs mn fu fw jf bi translated">诡计多端👜对于NLP模型-(第1部分)</h2><div class="mo l"><h3 class="bd b gy z fp mm fr fs mn fu fw dk translated">这是一系列简单的，部分显而易见的，并且(很大程度上)独立的提高性能的文章中的第一篇…</h3></div><div class="mp l"><p class="bd b dl z fp mm fr fs mn fu fw dk translated">priyansh.page</p></div></div><div class="mq l"><div class="on l ms mt mu mq mv ix mh"/></div></div></a></div><h1 id="c759" class="nc nd jg bd ne nf ng nh ni nj nk nl nm km nn kn no kp np kq nq ks nr kt ns nt bi translated">Wolfram数据分析网络研讨会</h1><p id="58a2" class="pw-post-body-paragraph lc ld jg le b lf of kh lh li og kk lk ll oh ln lo lp oi lr ls lt oj lv lw lx ij bi translated">有三个90分钟。即将到来的Wolfram网络研讨会将重点介绍定制的Twitter分析、虚拟地图的数据挖掘以及如何创建自动报告系统(等等)。如果你对Wolfram语言和这些科目感兴趣，可以在这里注册<a class="ae jd" href="https://register.gotowebinar.com/register/483834997595797260?source=blog" rel="noopener ugc nofollow" target="_blank">。</a></p><p id="b03f" class="pw-post-body-paragraph lc ld jg le b lf lg kh lh li lj kk lk ll lm ln lo lp lq lr ls lt lu lv lw lx ij bi translated"><strong class="le jh">博客:</strong></p><div class="ip iq gp gr ir mh"><a href="https://blog.wolfram.com/2020/01/16/3-free-wolfram-u-webinars-showcasing-innovative-data-science-applications/" rel="noopener  ugc nofollow" target="_blank"><div class="mi ab fo"><div class="mj ab mk cl cj ml"><h2 class="bd jh gy z fp mm fr fs mn fu fw jf bi translated">3场免费的Wolfram U网络研讨会，展示创新的数据科学应用——Wolfram博客</h2><div class="mo l"><h3 class="bd b gy z fp mm fr fs mn fu fw dk translated">2020年1月16日- Jamie Peterson，Wolfram U技术项目经理，希望实现您的新年计划…</h3></div><div class="mp l"><p class="bd b dl z fp mm fr fs mn fu fw dk translated">blog.wolfram.com</p></div></div><div class="mq l"><div class="oo l ms mt mu mq mv ix mh"/></div></div></a></div><h1 id="fa4f" class="nc nd jg bd ne nf ng nh ni nj nk nl nm km nn kn no kp np kq nq ks nr kt ns nt bi translated">康尼遇见空间</h1><p id="9c97" class="pw-post-body-paragraph lc ld jg le b lf of kh lh li og kk lk ll oh ln lo lp oi lr ls lt oj lv lw lx ij bi translated">现在好了。特别为布拉姆呐喊。他更新了spacy_conll repo，允许你将文本解析成CoNLL-U格式。该插件现在可以在命令行或python脚本中用作自定义管道。</p><p id="9e64" class="pw-post-body-paragraph lc ld jg le b lf lg kh lh li lj kk lk ll lm ln lo lp lq lr ls lt lu lv lw lx ij bi translated">你会问什么？</p><pre class="my mz na nb gt op oq or os aw ot bi"><span id="08e6" class="ou nd jg oq b gy ov ow l ox oy">&gt;  python -m spacy_conll --input_str "I like cookies . What about you ?" --is_tokenized --include_headers<br/># sent_id = 1<br/># text = I like cookies .<br/>1       I       -PRON-  PRON    PRP     PronType=prs    2       nsubj   _       _<br/>2       like    like    VERB    VBP     VerbForm=fin|Tense=pres 0       ROOT    _       _<br/>3       cookies cookie  NOUN    NNS     Number=plur     2       dobj    _       _<br/>4       .       .       PUNCT   .       PunctType=peri  2       punct   _       _<br/><br/># sent_id = 2<br/># text = What about you ?<br/>1       What    what    NOUN    WP      PronType=int|rel        2       dep     _       _<br/>2       about   about   ADP     IN      _       0       ROOT    _       _<br/>3       you     -PRON-  PRON    PRP     PronType=prs    2       pobj    _       _<br/>4       ?       ?       PUNCT   .       PunctType=peri  2       punct   _       _</span></pre><div class="ip iq gp gr ir mh"><a href="https://github.com/BramVanroy/spacy_conll" rel="noopener  ugc nofollow" target="_blank"><div class="mi ab fo"><div class="mj ab mk cl cj ml"><h2 class="bd jh gy z fp mm fr fs mn fu fw jf bi translated">BramVanroy/spacy_conll</h2><div class="mo l"><h3 class="bd b gy z fp mm fr fs mn fu fw dk translated">这个模块允许你把一个文本解析成CoNLL-U格式。您可以将它用作命令行工具，或者将其嵌入到您的…</h3></div><div class="mp l"><p class="bd b dl z fp mm fr fs mn fu fw dk translated">github.com</p></div></div><div class="mq l"><div class="oz l ms mt mu mq mv ix mh"/></div></div></a></div><h1 id="c9a0" class="nc nd jg bd ne nf ng nh ni nj nk nl nm km nn kn no kp np kq nq ks nr kt ns nt bi translated">我推荐研究论文</h1><p id="a291" class="pw-post-body-paragraph lc ld jg le b lf of kh lh li og kk lk ll oh ln lo lp oi lr ls lt oj lv lw lx ij bi translated">Santosh创建了一个使用自然语言搜索研究论文的推荐引擎，称为自然语言推荐！它是根据摘要训练的，所以描述越长，搜索结果越好。</p><p id="af47" class="pw-post-body-paragraph lc ld jg le b lf lg kh lh li lj kk lk ll lm ln lo lp lq lr ls lt lu lv lw lx ij bi translated">查看他的GitHub，其中还包括一个用于测试引擎的Colab。</p><div class="ip iq gp gr ir mh"><a href="https://github.com/Santosh-Gupta/NaturalLanguageRecommendations" rel="noopener  ugc nofollow" target="_blank"><div class="mi ab fo"><div class="mj ab mk cl cj ml"><h2 class="bd jh gy z fp mm fr fs mn fu fw jf bi translated">Santosh-Gupta/natural language建议</h2><div class="mo l"><h3 class="bd b gy z fp mm fr fs mn fu fw dk translated">https://colab . research . Google . com/github/Santosh-Gupta/natural language recommendations/blob/master/notebooks/inference/De…</h3></div><div class="mp l"><p class="bd b dl z fp mm fr fs mn fu fw dk translated">github.com</p></div></div><div class="mq l"><div class="pa l ms mt mu mq mv ix mh"/></div></div></a></div><h1 id="a8a8" class="nc nd jg bd ne nf ng nh ni nj nk nl nm km nn kn no kp np kq nq ks nr kt ns nt bi translated">本周数据集:记录</h1><p id="668e" class="pw-post-body-paragraph lc ld jg le b lf of kh lh li og kk lk ll oh ln lo lp oi lr ls lt oj lv lw lx ij bi translated"><strong class="le jh">是什么:</strong></p><p id="62fd" class="pw-post-body-paragraph lc ld jg le b lf lg kh lh li lj kk lk ll lm ln lo lp lq lr ls lt lu lv lw lx ij bi translated">"需要常识推理的阅读理解数据集."</p><p id="eec0" class="pw-post-body-paragraph lc ld jg le b lf lg kh lh li lj kk lk ll lm ln lo lp lq lr ls lt lu lv lw lx ij bi translated"><strong class="le jh">样本:</strong></p><div class="ip iq gp gr ir mh"><a href="https://sheng-z.github.io/ReCoRD-explorer/examples/002.html" rel="noopener  ugc nofollow" target="_blank"><div class="mi ab fo"><div class="mj ab mk cl cj ml"><h2 class="bd jh gy z fp mm fr fs mn fu fw jf bi translated">记录</h2><div class="mo l"><h3 class="bd b gy z fp mm fr fs mn fu fw dk translated">常识推理阅读理解数据集(ReCoRD)是一种新的阅读理解数据集</h3></div><div class="mp l"><p class="bd b dl z fp mm fr fs mn fu fw dk translated">sheng-z.github.io</p></div></div><div class="mq l"><div class="pb l ms mt mu mq mv ix mh"/></div></div></a></div><p id="310b" class="pw-post-body-paragraph lc ld jg le b lf lg kh lh li lj kk lk ll lm ln lo lp lq lr ls lt lu lv lw lx ij bi translated"><strong class="le jh">在哪里？</strong></p><div class="ip iq gp gr ir mh"><a href="https://sheng-z.github.io/ReCoRD-explorer/" rel="noopener  ugc nofollow" target="_blank"><div class="mi ab fo"><div class="mj ab mk cl cj ml"><h2 class="bd jh gy z fp mm fr fs mn fu fw jf bi translated">记录</h2><div class="mo l"><h3 class="bd b gy z fp mm fr fs mn fu fw dk translated">常识推理阅读理解数据集(ReCoRD)是一种新的阅读理解数据集</h3></div><div class="mp l"><p class="bd b dl z fp mm fr fs mn fu fw dk translated">sheng-z.github.io</p></div></div><div class="mq l"><div class="pc l ms mt mu mq mv ix mh"/></div></div></a></div><h1 id="5554" class="nc nd jg bd ne nf ng nh ni nj nk nl nm km nn kn no kp np kq nq ks nr kt ns nt bi translated">同时，回到维加斯农场…</h1><p id="548f" class="pw-post-body-paragraph lc ld jg le b lf of kh lh li og kk lk ll oh ln lo lp oi lr ls lt oj lv lw lx ij bi translated">最后但同样重要的是，我不敢相信这是真的，但显然indeed.com有一个招聘启事，要求有国防部“绝密”许可的护卫？！？！？🤣🤣🤣你有资格吗？在下面发帖:</p><div class="ip iq gp gr ir mh"><a href="https://www.indeed.com/q-Defense-Contract-l-Las-Vegas,-NV-jobs.html?advn=7484472901929921&amp;vjk=6dfb72e3d9bf100b" rel="noopener  ugc nofollow" target="_blank"><div class="mi ab fo"><div class="mj ab mk cl cj ml"><h2 class="bd jh gy z fp mm fr fs mn fu fw jf bi translated">国防合同工作，在内华达州拉斯维加斯的就业| Indeed.com</h2><div class="mo l"><h3 class="bd b gy z fp mm fr fs mn fu fw dk translated">内华达州Indeed.com的拉斯韦加斯有57个国防合同职位。适用于就业律师，技术员，指挥官…</h3></div><div class="mp l"><p class="bd b dl z fp mm fr fs mn fu fw dk translated">www.indeed.com</p></div></div></div></a></div><figure class="my mz na nb gt is"><div class="bz fp l di"><div class="pd oc l"/></div></figure></div><div class="ab cl kv kw hu kx" role="separator"><span class="ky bw bk kz la lb"/><span class="ky bw bk kz la lb"/><span class="ky bw bk kz la"/></div><div class="ij ik il im in"><blockquote class="pe"><p id="347b" class="pf pg jg bd ph pi pj pk pl pm pn lx dk translated">每周日，我们都会对来自世界各地研究人员的NLP新闻和代码进行一次每周综述。</p><p id="33b5" class="pf pg jg bd ph pi pj pk pl pm pn lx dk translated"><em class="po">如果您喜欢这篇文章，请帮助我们，并与朋友或社交媒体分享！</em></p><p id="7e3e" class="pf pg jg bd ph pi pj pk pl pm pn lx dk translated"><em class="po">如需完整报道，请关注我们的Twitter:</em><a class="ae jd" href="https://twitter.com/Quantum_Stat" rel="noopener ugc nofollow" target="_blank"><em class="po">@ Quantum _ Stat</em></a></p></blockquote><figure class="pq pr ps pt pu is gh gi paragraph-image"><div class="gh gi pp"><img src="../Images/738c3ee02768b9c5bcddc6dd41d844c9.png" data-original-src="https://miro.medium.com/v2/resize:fit:120/0*7Tm2cCbaioeyEyow"/></div><figcaption class="iz ja gj gh gi jb jc bd b be z dk translated"><a class="ae jd" href="http://www.quantumstat.com/" rel="noopener ugc nofollow" target="_blank">www.quantumstat.com</a></figcaption></figure></div></div>    
</body>
</html>