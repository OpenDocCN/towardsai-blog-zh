<html>
<head>
<title>Malawi News Classification -An NLP Project</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">马拉维新闻分类NLP项目</h1>
<blockquote>原文：<a href="https://pub.towardsai.net/malawi-news-classification-an-nlp-project-adfa867abfd9?source=collection_archive---------3-----------------------#2021-08-11">https://pub.towardsai.net/malawi-news-classification-an-nlp-project-adfa867abfd9?source=collection_archive---------3-----------------------#2021-08-11</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><h2 id="fc05" class="io ip iq bd b dl ir is it iu iv iw dk ix translated" aria-label="kicker paragraph"><a class="ae ep" href="https://towardsai.net/p/category/nlp" rel="noopener ugc nofollow" target="_blank">自然语言处理</a></h2><div class=""/><p id="7837" class="pw-post-body-paragraph jw jx iq jy b jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ij bi translated">使用文本分类器预测马拉维新闻文章中的各种类别。</p><figure class="kv kw kx ky gt kz gh gi paragraph-image"><div role="button" tabindex="0" class="la lb di lc bf ld"><div class="gh gi ku"><img src="../Images/e5534ecdbadf41a409aa498f3ee5c373.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*SwzxIF6El-3jGOg9"/></div></div><figcaption class="lg lh gj gh gi li lj bd b be z dk translated"><a class="ae lk" href="https://unsplash.com/@thenewmalcolm?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">奥比·奥尼耶多尔</a>在<a class="ae lk" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上的照片</figcaption></figure><h1 id="4bda" class="ll lm iq bd ln lo lp lq lr ls lt lu lv lw lx ly lz ma mb mc md me mf mg mh mi bi translated">介绍</h1><p id="329f" class="pw-post-body-paragraph jw jx iq jy b jz mj kb kc kd mk kf kg kh ml kj kk kl mm kn ko kp mn kr ks kt ij bi translated">文本分类在我们日常使用的应用程序中很常见。例如，电子邮件提供商使用文本分类来过滤掉收件箱中的垃圾邮件。文本分类的另一个最常见的用途是在客户服务中，他们使用情感分析来区分差评和好评<a class="ae lk" href="https://addiai.com/text-classification/" rel="noopener ugc nofollow" target="_blank"> ADDI AI 2050 </a>。文本分类的现代应用已经超越了更高级的分类形式，包括多语言和多标签分类。</p><figure class="kv kw kx ky gt kz gh gi paragraph-image"><div class="gh gi mo"><img src="../Images/4cea66b2c8fc70544959945c925eb113.png" data-original-src="https://miro.medium.com/v2/resize:fit:1278/format:webp/0*N09Ou7dKfXkngzq1.png"/></div><figcaption class="lg lh gj gh gi li lj bd b be z dk translated">垃圾邮件过滤器文本分类示例| <a class="ae lk" href="https://addiai.com/text-classification/" rel="noopener ugc nofollow" target="_blank"> ADDI AI 2050 </a></figcaption></figure><p id="1ec7" class="pw-post-body-paragraph jw jx iq jy b jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ij bi translated">近年来，英语已经取得了很大的进步，但是在低资源语言和不同长度的语言上训练分类模型仍然存在困难。在这个Zindi <a class="ae lk" href="https://zindi.africa/competitions/ai4d-malawi-news-classification-challenge" rel="noopener ugc nofollow" target="_blank">竞赛</a>中，我们获得了用Chichewa语言编写的新闻文章，并在多标签分类上训练我们的模型，因为有19个新闻类别。文本由不同长度的新闻文章组成，因此找出一个更好的模型将是一项具有挑战性的任务。<a class="ae lk" href="https://zindi.africa/competitions/ai4d-malawi-news-classification-challenge" rel="noopener ugc nofollow" target="_blank"> —津迪</a>。</p><figure class="kv kw kx ky gt kz gh gi paragraph-image"><div role="button" tabindex="0" class="la lb di lc bf ld"><div class="gh gi mp"><img src="../Images/5b9e9bd601e10025572cb21270fa2a79.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*jER1iEvkRb1aK1a7.jpeg"/></div></div><figcaption class="lg lh gj gh gi li lj bd b be z dk translated"><a class="ae lk" href="https://zindi.africa/competitions/ai4d-malawi-news-classification-challenge" rel="noopener ugc nofollow" target="_blank">津迪竞赛</a> | AI4D马拉维新闻分类挑战赛</figcaption></figure><p id="966f" class="pw-post-body-paragraph jw jx iq jy b jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ij bi translated">项目代码简单有效，具有竞争力。我已经用矢量器、Porter stemmer对测试进行了预处理。我还使用了多种方法来清理我的文本，以提高整体模型性能。最后，我使用SKlearn随机梯度下降(SGD)分类器来预测新闻类别。我还试验了各种神经网络和梯度推进模型，但它们都失败了，因为具有最小超参数调整的简单逻辑回归在此数据上工作得很好。</p></div><div class="ab cl mq mr hu ms" role="separator"><span class="mt bw bk mu mv mw"/><span class="mt bw bk mu mv mw"/><span class="mt bw bk mu mv"/></div><div class="ij ik il im in"><h1 id="4612" class="ll lm iq bd ln lo mx lq lr ls my lu lv lw mz ly lz ma na mc md me nb mg mh mi bi translated">密码</h1><p id="a457" class="pw-post-body-paragraph jw jx iq jy b jz mj kb kc kd mk kf kg kh ml kj kk kl mm kn ko kp mn kr ks kt ij bi translated"><a class="ae lk" href="https://deepnote.com/" rel="noopener ugc nofollow" target="_blank"> <strong class="jy ja"> Deepnote </strong> </a>环境用于训练分类模型。</p><h2 id="d720" class="nc lm iq bd ln nd ne dn lr nf ng dp lv kh nh ni lz kl nj nk md kp nl nm mh iw bi translated">导入库</h2><pre class="kv kw kx ky gt nn no np nq aw nr bi"><span id="7d0e" class="nc lm iq no b gy ns nt l nu nv">from sklearn.feature_extraction.text import TfidfVectorizer<br/>from sklearn.metrics import accuracy_score, classification_report, confusion_matrix<br/>from sklearn.model_selection import train_test_split<br/>from sklearn.linear_model import SGDClassifier<br/>from sklearn.preprocessing import LabelEncoder<br/>from nltk.stem import WordNetLemmatizer<br/>from imblearn.over_sampling import SMOTE<br/>import matplotlib.pyplot as plt<br/>import seaborn as sns<br/>import pandas as pd<br/>import numpy as np<br/>import re<br/>import warnings<br/>warnings.filterwarnings("ignore")</span></pre><h2 id="1415" class="nc lm iq bd ln nd ne dn lr nf ng dp lv kh nh ni lz kl nj nk md kp nl nm mh iw bi translated">读取训练/测试数据集</h2><p id="ce67" class="pw-post-body-paragraph jw jx iq jy b jz mj kb kc kd mk kf kg kh ml kj kk kl mm kn ko kp mn kr ks kt ij bi translated">数据是从马拉维的各种新闻出版公司收集的。tNyasa有限公司数据科学实验室使用了三家主要的广播公司:国家在线报纸、玛利亚电台和马拉维广播公司<a class="ae lk" href="https://zindi.africa/competitions/ai4d-malawi-news-classification-challenge/data" rel="noopener ugc nofollow" target="_blank"> — Zindi </a>。<br/>训练数据包含三列:</p><ul class=""><li id="3124" class="nw nx iq jy b jz ka kd ke kh ny kl nz kp oa kt ob oc od oe bi translated"><strong class="jy ja"> ID </strong>:唯一标识符</li><li id="f8cb" class="nw nx iq jy b jz of kd og kh oh kl oi kp oj kt ob oc od oe bi translated"><strong class="jy ja">正文</strong>:新闻文章</li><li id="6b56" class="nw nx iq jy b jz of kd og kh oh kl oi kp oj kt ob oc od oe bi translated"><strong class="jy ja">标签</strong>:新闻文章的分类。</li></ul><p id="3e4e" class="pw-post-body-paragraph jw jx iq jy b jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ij bi translated"><strong class="jy ja">任务</strong>是将新闻文章分为19类中的一类。</p><p id="2bea" class="pw-post-body-paragraph jw jx iq jy b jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ij bi translated">如您所见，训练数据有<strong class="jy ja"> 1436 </strong>个样本，而测试数据集有<strong class="jy ja"> 620 </strong>个样本。</p><pre class="kv kw kx ky gt nn no np nq aw nr bi"><span id="148c" class="nc lm iq no b gy ns nt l nu nv">train_data = pd.read_csv("../input/malawi-news-classification-challenge/Train.csv")<br/>test_data = pd.read_csv("../input/malawi-news-classification-challenge/Test.csv")<br/>print(train_data.shape)<br/>print(test_data.shape)</span><span id="a61a" class="nc lm iq no b gy ok nt l nu nv"><strong class="no ja">&gt;&gt; (1436, 3)<br/>&gt;&gt; (620, 2)</strong></span></pre><p id="2d04" class="pw-post-body-paragraph jw jx iq jy b jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ij bi translated">让我们看看最上面的两列</p><pre class="kv kw kx ky gt nn no np nq aw nr bi"><span id="0cb8" class="nc lm iq no b gy ns nt l nu nv">train_data.head(2)</span></pre><figure class="kv kw kx ky gt kz gh gi paragraph-image"><div class="gh gi ol"><img src="../Images/266ed74e2bd9a1ba6fc26fff2ca947d4.png" data-original-src="https://miro.medium.com/v2/resize:fit:1256/format:webp/1*Bgh_eBeJck-gU1zR6WQLcw.png"/></div></figure><p id="3412" class="pw-post-body-paragraph jw jx iq jy b jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ij bi translated">让我们看看最下面的两列</p><pre class="kv kw kx ky gt nn no np nq aw nr bi"><span id="806e" class="nc lm iq no b gy ns nt l nu nv">train_data.tail(2)</span></pre><figure class="kv kw kx ky gt kz gh gi paragraph-image"><div role="button" tabindex="0" class="la lb di lc bf ld"><div class="gh gi om"><img src="../Images/57ce23cd7cd785fa52f893eab9951082.png" data-original-src="https://miro.medium.com/v2/resize:fit:1370/format:webp/1*WpOKfE0M1zFEvAzlNas9Sw.png"/></div></div></figure><p id="bab9" class="pw-post-body-paragraph jw jx iq jy b jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ij bi translated">让我们看看训练数据集标签分布</p><p id="3093" class="pw-post-body-paragraph jw jx iq jy b jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ij bi translated">很明显，我们的类别分布不平衡，这可能会在机器学习模型训练过程中造成问题。<strong class="jy ja">政治</strong>类别在我们的训练数据集中领先。</p><pre class="kv kw kx ky gt nn no np nq aw nr bi"><span id="218e" class="nc lm iq no b gy ns nt l nu nv">train_data.Label.value_counts().plot(kind='bar');</span></pre><figure class="kv kw kx ky gt kz gh gi paragraph-image"><div class="gh gi on"><img src="../Images/4dd012b79a33e446fa0ab195dd944af3.png" data-original-src="https://miro.medium.com/v2/resize:fit:750/format:webp/0*T_ZKEeGNUxQhSpNM.png"/></div><figcaption class="lg lh gj gh gi li lj bd b be z dk translated">作者图片|图1</figcaption></figure><h2 id="871f" class="nc lm iq bd ln nd ne dn lr nf ng dp lv kh nh ni lz kl nj nk md kp nl nm mh iw bi translated">清理文本</h2><ul class=""><li id="688e" class="nw nx iq jy b jz mj kd mk kh oo kl op kp oq kt ob oc od oe bi translated">删除特殊字符。</li><li id="0b9e" class="nw nx iq jy b jz of kd og kh oh kl oi kp oj kt ob oc od oe bi translated">降低文本。</li><li id="86f8" class="nw nx iq jy b jz of kd og kh oh kl oi kp oj kt ob oc od oe bi translated">词汇词汇化。</li></ul><pre class="kv kw kx ky gt nn no np nq aw nr bi"><span id="d33c" class="nc lm iq no b gy ns nt l nu nv">wn = WordNetLemmatizer()<br/>def text_preprocessing(review):<br/>    review = re.sub('[^a-zA-Z]', ' ', review)<br/>    review = review.lower()<br/>    review = review.split()<br/>    review = [wn.lemmatize(word) for word in review if not word in chichewa]<br/>    review = ' '.join(review)<br/>    return review</span></pre><h2 id="cd15" class="nc lm iq bd ln nd ne dn lr nf ng dp lv kh nh ni lz kl nj nk md kp nl nm mh iw bi translated">应用文本预处理</h2><p id="0598" class="pw-post-body-paragraph jw jx iq jy b jz mj kb kc kd mk kf kg kh ml kj kk kl mm kn ko kp mn kr ks kt ij bi translated">简单地在测试和训练数据集上应用上述函数。</p><pre class="kv kw kx ky gt nn no np nq aw nr bi"><span id="dbb0" class="nc lm iq no b gy ns nt l nu nv">train_data['Text'] = train_data['Text'].apply(text_preprocessing)<br/>test_data['Text'] = test_data['Text'].apply(text_preprocessing)<br/>print(train_data.head())<br/>print(test_data.head())</span></pre><p id="a53f" class="pw-post-body-paragraph jw jx iq jy b jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ij bi translated"><strong class="jy ja">查看输出</strong></p><p id="d7bc" class="pw-post-body-paragraph jw jx iq jy b jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ij bi translated">如您所见，我们有了更清晰的文本，可以在我们的模型上进行训练。</p><figure class="kv kw kx ky gt kz gh gi paragraph-image"><div class="gh gi or"><img src="../Images/7beb6484af27b151c9763f786a8e74bd.png" data-original-src="https://miro.medium.com/v2/resize:fit:1098/format:webp/1*OlQSCDawiM_UPt-yDvrmKQ.png"/></div></figure><h2 id="8a70" class="nc lm iq bd ln nd ne dn lr nf ng dp lv kh nh ni lz kl nj nk md kp nl nm mh iw bi translated">文本矢量化</h2><p id="cb5a" class="pw-post-body-paragraph jw jx iq jy b jz mj kb kc kd mk kf kg kh ml kj kk kl mm kn ko kp mn kr ks kt ij bi translated">术语频率逆文档频率(TFIDF)。该算法将文本数据转换成有意义的数字表示<a class="ae lk" href="https://medium.com/@cmukesh8688/tf-idf-vectorizer-scikit-learn-dbc0244a911a" rel="noopener">媒介</a>。转换是必要的，因为机器学习模型不理解文本数据，所以我们需要将数据转换成数字格式。我们将使用SKlearn TFIDF转换将我们的文本数据转换为矢量，我们最终的数据形状将有49480列/特征。</p><pre class="kv kw kx ky gt nn no np nq aw nr bi"><span id="19c5" class="nc lm iq no b gy ns nt l nu nv">vectorizer = TfidfVectorizer()<br/>X = vectorizer.fit_transform(train_data['Text']).toarray()<br/>training = pd.DataFrame(X, columns=vectorizer.get_feature_names())<br/>print(training.shape)<br/>X_test_final = vectorizer.transform(test_data['Text']).toarray()<br/>test_new = pd.DataFrame(X_test_final, columns=vectorizer.get_feature_names())<br/>print(test_new.shape)</span><span id="f39d" class="nc lm iq no b gy ok nt l nu nv"><strong class="no ja">&gt;&gt; (1436, 49480)<br/>&gt;&gt; (620, 49480)</strong></span></pre><h2 id="cb3b" class="nc lm iq bd ln nd ne dn lr nf ng dp lv kh nh ni lz kl nj nk md kp nl nm mh iw bi translated">为培训准备数据</h2><p id="5cf0" class="pw-post-body-paragraph jw jx iq jy b jz mj kb kc kd mk kf kg kh ml kj kk kl mm kn ko kp mn kr ks kt ij bi translated">使用我们的训练数据得到<strong class="jy ja"> X </strong>(训练特征)和<strong class="jy ja"> y </strong>(目标)。我们将使用标签编码将字符串标签转换成数字标签，如[1，2，3…]</p><pre class="kv kw kx ky gt nn no np nq aw nr bi"><span id="7042" class="nc lm iq no b gy ns nt l nu nv">X = training <br/>y = train_data['Label']</span></pre><p id="3bc7" class="pw-post-body-paragraph jw jx iq jy b jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ij bi translated"><strong class="jy ja">标签编码</strong></p><pre class="kv kw kx ky gt nn no np nq aw nr bi"><span id="2f7d" class="nc lm iq no b gy ns nt l nu nv">label_encoder = LabelEncoder() <br/>y_label = label_encoder.fit_transform(y)</span></pre><p id="f5d8" class="pw-post-body-paragraph jw jx iq jy b jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ij bi translated">我们的数据相当不平衡，如图<strong class="jy ja">图1 </strong>所示。政治类别的样本数量最多，其次是社会和宗教。数据的这种<strong class="jy ja">不平衡</strong>将导致我们的模型表现最差，因此为了提高模型性能，我们必须通过移除额外样本或使用合成少数过采样技术(SMOTE)来平衡我们的数据。SMOTE 是一种过采样技术，为少数类<a class="ae lk" href="https://www.analyticsvidhya.com/blog/2020/10/overcoming-class-imbalance-using-smote-techniques/" rel="noopener ugc nofollow" target="_blank">(analyticsvidhya.com)</a>生成合成样本。</p><p id="09fe" class="pw-post-body-paragraph jw jx iq jy b jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ij bi translated">在我们的例子中，所有的少数阶级将被合成以匹配多数阶级<strong class="jy ja">政治。如你所见，所有的类都有相同数量的样本，这是完全平衡的。</strong></p><pre class="kv kw kx ky gt nn no np nq aw nr bi"><span id="fa51" class="nc lm iq no b gy ns nt l nu nv">smote = SMOTE() <br/>X, y_label = smote.fit_resample(X,y_label) np.bincount(y_label)</span><span id="d8c7" class="nc lm iq no b gy ok nt l nu nv"><strong class="no ja">&gt;&gt; array([279, 279, 279, 279, 279, 279, 279, 279, 279, 279, 279, 279, 279, 279, 279, 279, 279, 279, 279, 279])</strong></span></pre><h2 id="ea7b" class="nc lm iq bd ln nd ne dn lr nf ng dp lv kh nh ni lz kl nj nk md kp nl nm mh iw bi translated">培训模式</h2><p id="0437" class="pw-post-body-paragraph jw jx iq jy b jz mj kb kc kd mk kf kg kh ml kj kk kl mm kn ko kp mn kr ks kt ij bi translated"><strong class="jy ja">我用过:</strong></p><ul class=""><li id="96f0" class="nw nx iq jy b jz ka kd ke kh ny kl nz kp oa kt ob oc od oe bi translated"><a class="ae lk" href="https://en.wikipedia.org/wiki/Neural_network" rel="noopener ugc nofollow" target="_blank">神经网络</a></li><li id="e456" class="nw nx iq jy b jz of kd og kh oh kl oi kp oj kt ob oc od oe bi translated"><a class="ae lk" href="https://xgboost.readthedocs.io/" rel="noopener ugc nofollow" target="_blank"> XGBoost </a></li><li id="96ba" class="nw nx iq jy b jz of kd og kh oh kl oi kp oj kt ob oc od oe bi translated"><a class="ae lk" href="https://lightgbm.readthedocs.io/en/latest/pythonapi/lightgbm.LGBMClassifier.html" rel="noopener ugc nofollow" target="_blank"> LGBM分类器</a></li><li id="1bb2" class="nw nx iq jy b jz of kd og kh oh kl oi kp oj kt ob oc od oe bi translated"><a class="ae lk" href="https://catboost.ai/docs/concepts/python-reference_catboostclassifier.html" rel="noopener ugc nofollow" target="_blank"> Catboost </a></li><li id="2bac" class="nw nx iq jy b jz of kd og kh oh kl oi kp oj kt ob oc od oe bi translated">汽车公司</li><li id="08b0" class="nw nx iq jy b jz of kd og kh oh kl oi kp oj kt ob oc od oe bi translated"><a class="ae lk" href="https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html" rel="noopener ugc nofollow" target="_blank">逻辑回归</a></li><li id="76fc" class="nw nx iq jy b jz of kd og kh oh kl oi kp oj kt ob oc od oe bi translated"><a class="ae lk" href="https://arxiv.org/abs/1908.07442" rel="noopener ugc nofollow" target="_blank"> Tabnet </a></li><li id="8763" class="nw nx iq jy b jz of kd og kh oh kl oi kp oj kt ob oc od oe bi translated"><a class="ae lk" href="https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html" rel="noopener ugc nofollow" target="_blank">随机森林分类器</a></li></ul><p id="5d38" class="pw-post-body-paragraph jw jx iq jy b jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ij bi translated">但都比不上SGD。简而言之，使用SGD分类和简单的超参数调整会得到最好的结果。该估计器通过随机梯度下降(SGD)学习<a class="ae lk" href="https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.SGDClassifier.html" rel="noopener ugc nofollow" target="_blank"> sklearn.linear_model实现正则化线性模型。SGD分类器</a>。</p><ul class=""><li id="e7b1" class="nw nx iq jy b jz ka kd ke kh ny kl nz kp oa kt ob oc od oe bi translated"><strong class="jy ja">分成训练和测试:</strong>10%的测试数据集</li><li id="a7d3" class="nw nx iq jy b jz of kd og kh oh kl oi kp oj kt ob oc od oe bi translated"><strong class="jy ja">使用SGD分类器</strong>:使用损失函数作为铰链，其中<em class="os"> alpha </em> =0.0004，<em class="os"> max_iter </em> =20</li></ul><pre class="kv kw kx ky gt nn no np nq aw nr bi"><span id="eec3" class="nc lm iq no b gy ns nt l nu nv">X_train, X_test, y_train, y_test = train_test_split(X, y_label, test_size=0.1, random_state=0)<br/>model = SGDClassifier(loss='hinge', <br/>                      alpha=4e-4, <br/>                      max_iter=20, <br/>                      verbose=False)<br/>model.fit(X_train, y_train)</span><span id="3864" class="nc lm iq no b gy ok nt l nu nv"><strong class="no ja">&gt;&gt; SGDClassifier(alpha=0.0004, max_iter=20, verbose=False)</strong></span></pre><h2 id="5722" class="nc lm iq bd ln nd ne dn lr nf ng dp lv kh nh ni lz kl nj nk md kp nl nm mh iw bi translated">估价</h2><p id="6352" class="pw-post-body-paragraph jw jx iq jy b jz mj kb kc kd mk kf kg kh ml kj kk kl mm kn ko kp mn kr ks kt ij bi translated">我们的模型用过采样技术表现得相当好。</p><blockquote class="ot ou ov"><p id="9cf7" class="jw jx os jy b jz ka kb kc kd ke kf kg ow ki kj kk ox km kn ko oy kq kr ks kt ij bi translated">没有SMOTE的训练模型获得了最高的55%的准确率。</p></blockquote><pre class="kv kw kx ky gt nn no np nq aw nr bi"><span id="17ae" class="nc lm iq no b gy ns nt l nu nv">pred = model.predict(X_test)<br/>print("Train Accuracy Score:",round(model.score(X_train, y_train),2))<br/>print("Test Accuracy Score:",round(accuracy_score(y_test, pred),2))</span><span id="4d87" class="nc lm iq no b gy ok nt l nu nv"><strong class="no ja">Train Accuracy Score: 0.99</strong></span><span id="2d80" class="nc lm iq no b gy ok nt l nu nv"><strong class="no ja">Test Accuracy Score: 0.95</strong></span></pre><h2 id="05bb" class="nc lm iq bd ln nd ne dn lr nf ng dp lv kh nh ni lz kl nj nk md kp nl nm mh iw bi translated">分类报告</h2><p id="5cde" class="pw-post-body-paragraph jw jx iq jy b jz mj kb kc kd mk kf kg kh ml kj kk kl mm kn ko kp mn kr ks kt ij bi translated">每个班级的分类报告也很惊人，因为大多数f1分数都在90%到100%之间。</p><pre class="kv kw kx ky gt nn no np nq aw nr bi"><span id="09e5" class="nc lm iq no b gy ns nt l nu nv">print(classification_report(y_test, pred))</span><span id="ec5a" class="nc lm iq no b gy ok nt l nu nv">                 <strong class="no ja">precision  recall  f1-score   support</strong></span><span id="a676" class="nc lm iq no b gy ok nt l nu nv">           0       1.00      1.00      1.00        30<br/>           1       1.00      1.00      1.00        25<br/>           2       0.96      0.83      0.89        29<br/>           3       0.92      1.00      0.96        22<br/>           4       0.97      1.00      0.98        29<br/>           5       1.00      1.00      1.00        29<br/>           6       0.87      0.90      0.89        30<br/>           7       0.90      0.93      0.92        30<br/>           8       0.95      1.00      0.98        20<br/>           9       1.00      1.00      1.00        37<br/>          10       1.00      1.00      1.00        25<br/>          11       0.90      0.75      0.82        24<br/>          12       1.00      1.00      1.00        31<br/>          13       0.79      0.92      0.85        25<br/>          14       0.82      0.62      0.71        29<br/>          15       0.95      0.95      0.95        19<br/>          16       1.00      1.00      1.00        30<br/>          17       0.94      1.00      0.97        32<br/>          18       0.91      1.00      0.95        30<br/>          19       1.00      1.00      1.00        32</span><span id="849b" class="nc lm iq no b gy ok nt l nu nv">    accuracy                           0.95       558<br/>   macro avg       0.94      0.94      0.94       558<br/>weighted avg       0.95      0.95      0.94       558</span></pre><h2 id="6dcf" class="nc lm iq bd ln nd ne dn lr nf ng dp lv kh nh ni lz kl nj nk md kp nl nm mh iw bi translated">混淆矩阵</h2><p id="5754" class="pw-post-body-paragraph jw jx iq jy b jz mj kb kc kd mk kf kg kh ml kj kk kl mm kn ko kp mn kr ks kt ij bi translated">我们在测试数据集上有一个几乎完美的混淆矩阵，如图2所示。</p><pre class="kv kw kx ky gt nn no np nq aw nr bi"><span id="ebc4" class="nc lm iq no b gy ns nt l nu nv">test_pred = label_encoder.inverse_transform(pred)<br/>test_label = label_encoder.inverse_transform(y_test)<br/>cf_matrix = confusion_matrix(test_pred, test_label)<br/>sns.heatmap(cf_matrix, annot=True;</span></pre><figure class="kv kw kx ky gt kz gh gi paragraph-image"><div class="gh gi oz"><img src="../Images/a2bb93af5aaba3daa5041af1dee80f2a.png" data-original-src="https://miro.medium.com/v2/resize:fit:698/format:webp/0*uMKL56EFKRZP9Rpb.png"/></div><figcaption class="lg lh gj gh gi li lj bd b be z dk translated">作者混淆矩阵|图2</figcaption></figure></div><div class="ab cl mq mr hu ms" role="separator"><span class="mt bw bk mu mv mw"/><span class="mt bw bk mu mv mw"/><span class="mt bw bk mu mv"/></div><div class="ij ik il im in"><h1 id="5912" class="ll lm iq bd ln lo mx lq lr ls my lu lv lw mz ly lz ma na mc md me nb mg mh mi bi translated">提交</h1><p id="9bd6" class="pw-post-body-paragraph jw jx iq jy b jz mj kb kc kd mk kf kg kh ml kj kk kl mm kn ko kp mn kr ks kt ij bi translated">是时候在测试数据库上预测并创建我们的CVS文件了。这个文件将被上传到Zindi服务器，作为隐藏测试数据集的最终分数。</p><pre class="kv kw kx ky gt nn no np nq aw nr bi"><span id="9d9d" class="nc lm iq no b gy ns nt l nu nv">sub_pred = model.predict(test_new)<br/>submission = pd.DataFrame()<br/>submission['ID'] = test_data['ID']<br/>submission['Label'] = label_encoder.inverse_transform(sub_pred)<br/>submission.to_csv('submission.csv', index=False)</span></pre><figure class="kv kw kx ky gt kz gh gi paragraph-image"><div role="button" tabindex="0" class="la lb di lc bf ld"><div class="gh gi pa"><img src="../Images/bc004a699f06f1b72314c54ba2f109cb.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*S1psKGw93GpXUOZS.jpeg"/></div></div><figcaption class="lg lh gj gh gi li lj bd b be z dk translated">作者图片</figcaption></figure></div><div class="ab cl mq mr hu ms" role="separator"><span class="mt bw bk mu mv mw"/><span class="mt bw bk mu mv mw"/><span class="mt bw bk mu mv"/></div><div class="ij ik il im in"><h1 id="c3ed" class="ll lm iq bd ln lo mx lq lr ls my lu lv lw mz ly lz ma na mc md me nb mg mh mi bi translated">结论</h1><p id="307d" class="pw-post-body-paragraph jw jx iq jy b jz mj kb kc kd mk kf kg kh ml kj kk kl mm kn ko kp mn kr ks kt ij bi translated">我们在测试数据集上得到了一个相当糟糕的分数。似乎我的模型在训练和验证上都过度拟合了。这是我用过采样得到的最好的分数，尽管我的模型是过拟合的，但我用SMOTE和SGDClassifier得到了最好的结果。</p><p id="2c19" class="pw-post-body-paragraph jw jx iq jy b jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ij bi translated">我对从神经网络到Automl的各种机器学习模型进行了有趣的实验，但数据集非常小而且不平衡，无法获得更好的分数。</p><blockquote class="ot ou ov"><p id="f1d5" class="jw jx os jy b jz ka kb kc kd ke kf kg ow ki kj kk ox km kn ko oy kq kr ks kt ij bi translated">获胜的解决方案得分为0.7。</p></blockquote><p id="2033" class="pw-post-body-paragraph jw jx iq jy b jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ij bi translated">关注数据应该是获得更好结果的首要任务。这篇文章非常简单，对初学者友好，所以任何人都可以使用我的代码获得前50名。</p></div><div class="ab cl mq mr hu ms" role="separator"><span class="mt bw bk mu mv mw"/><span class="mt bw bk mu mv mw"/><span class="mt bw bk mu mv"/></div><div class="ij ik il im in"><p id="b6b7" class="pw-post-body-paragraph jw jx iq jy b jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ij bi translated"><strong class="jy ja">项目文件:</strong><a class="ae lk" href="https://github.com/kingabzpro/Malawi-News-Classification" rel="noopener ugc nofollow" target="_blank">GitHub</a>|<a class="ae lk" href="https://dagshub.com/kingabzpro/Malawi-News-Classification" rel="noopener ugc nofollow" target="_blank">DAGsHub</a>|<a class="ae lk" href="https://deepnote.com/project/Malawi-News-Classification-ML-G_9I1JMHQFeJzyoJfCFDfg/%2FMalawi-News-Classification%2Fmalawi-news-classification.ipynb" rel="noopener ugc nofollow" target="_blank">deep note</a></p></div><div class="ab cl mq mr hu ms" role="separator"><span class="mt bw bk mu mv mw"/><span class="mt bw bk mu mv mw"/><span class="mt bw bk mu mv"/></div><div class="ij ik il im in"><blockquote class="ot ou ov"><p id="061c" class="jw jx os jy b jz ka kb kc kd ke kf kg ow ki kj kk ox km kn ko oy kq kr ks kt ij bi translated">你可以在<a class="ae lk" href="https://www.linkedin.com/in/1abidaliawan/" rel="noopener ugc nofollow" target="_blank"> LinkedIn </a>和<a class="ae lk" href="https://www.polywork.com/kingabzpro" rel="noopener ugc nofollow" target="_blank"> Polywork </a>上关注我，我在那里发布了关于数据科学和机器学习的惊人文章。</p></blockquote></div><div class="ab cl mq mr hu ms" role="separator"><span class="mt bw bk mu mv mw"/><span class="mt bw bk mu mv mw"/><span class="mt bw bk mu mv"/></div><div class="ij ik il im in"><p id="3a2a" class="pw-post-body-paragraph jw jx iq jy b jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ij bi translated"><em class="os">本文中显示的媒体不归Analytics Vidhya所有，由作者自行决定使用。</em></p><p id="5a43" class="pw-post-body-paragraph jw jx iq jy b jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ij bi translated"><em class="os">相关</em></p></div><div class="ab cl mq mr hu ms" role="separator"><span class="mt bw bk mu mv mw"/><span class="mt bw bk mu mv mw"/><span class="mt bw bk mu mv"/></div><div class="ij ik il im in"><p id="2966" class="pw-post-body-paragraph jw jx iq jy b jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ij bi translated"><em class="os">原载于2021年8月11日</em><a class="ae lk" href="https://www.analyticsvidhya.com/blog/2021/08/malawi-news-classification-an-nlp-project" rel="noopener ugc nofollow" target="_blank"><em class="os">https://www.analyticsvidhya.com</em></a>T22。</p></div></div>    
</body>
</html>