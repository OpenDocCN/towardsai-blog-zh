<html>
<head>
<title>Build Animatable 3D Models with AI</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">用人工智能构建可动画化的3D模型</h1>
<blockquote>原文：<a href="https://pub.towardsai.net/build-animatable-3d-models-with-ai-507e921ea5a2?source=collection_archive---------0-----------------------#2022-08-14">https://pub.towardsai.net/build-animatable-3d-models-with-ai-507e921ea5a2?source=collection_archive---------0-----------------------#2022-08-14</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="8170" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">使用BANMo从图片创建可变形的3D模型！</h2></div><blockquote class="ki kj kk"><p id="6dcf" class="kl km kn ko b kp kq ju kr ks kt jx ku kv kw kx ky kz la lb lc ld le lf lg lh im bi translated">最初发表于<a class="ae li" href="https://www.louisbouchard.ai/banmo/" rel="noopener ugc nofollow" target="_blank"> louisbouchard.ai </a>，前两天在<a class="ae li" href="https://www.louisbouchard.ai/banmo/" rel="noopener ugc nofollow" target="_blank">我的博客上读到的！</a></p></blockquote><h2 id="8d84" class="lj lk it bd ll lm ln dn lo lp lq dp lr ls lt lu lv lw lx ly lz ma mb mc md me bi translated">观看视频，了解更多结果！</h2><figure class="mf mg mh mi gt mj"><div class="bz fp l di"><div class="mk ml l"/></div></figure><p id="2346" class="pw-post-body-paragraph kl km it ko b kp kq ju kr ks kt jx ku ls kw kx ky lw la lb lc ma le lf lg lh im bi translated">如果你在VFX，游戏开发，或创建3D场景，这种新的人工智能模型是给你的。很快在你的创作管道中看到这种模型或类似的方法，我不会感到惊讶，这使你在制作3D模型上花费更少的时间、金钱和精力。看看那个…</p><figure class="mf mg mh mi gt mj gh gi paragraph-image"><div role="button" tabindex="0" class="mn mo di mp bf mq"><div class="gh gi mm"><img src="../Images/e8b69fb4e3ec7b0a334f51c17b5c34a4.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/1*gCNcDgxRkhaFMPctKHl6dQ.gif"/></div></div><figcaption class="mt mu gj gh gi mv mw bd b be z dk translated"><strong class="bd ll">左</strong>:输入视频；<strong class="bd ll">右</strong>:每一时刻的重建。对应关系显示为相同的颜色。图片来自<a class="ae li" href="https://banmo-www.github.io/" rel="noopener ugc nofollow" target="_blank">作者的项目页面</a>。</figcaption></figure><p id="cead" class="pw-post-body-paragraph kl km it ko b kp kq ju kr ks kt jx ku ls kw kx ky lw la lb lc ma le lf lg lh im bi translated">当然，它并不完美，但这是用手机拍摄的一个随意的视频即时完成的。它不需要昂贵的多摄像头设置或复杂的深度传感器。人工智能背后的美妙之处之一是:让复杂而昂贵的技术可供初创公司或个人使用，以创建具有专业质量结果的项目。只需拍摄一个对象，并将其转换为可以立即导入的模型。如果您不满意，您可以对细节进行微调，但整个模型将在几秒钟内出现！</p><p id="5c96" class="pw-post-body-paragraph kl km it ko b kp kq ju kr ks kt jx ku ls kw kx ky lw la lb lc ma le lf lg lh im bi translated">你在上面看到的是一个名为BANMo的人工智能模型的结果，最近在我参加的CVPR活动上分享了这个结果。老实说，他们引起我的注意也是因为猫。尽管如此，它并不完全是一个诱饵。论文和方法实际上非常棒。它不像任何重建3D模型中的物体的NeRF方法。BANMo解决了一个我们称为关节式3D形状重建的任务，这意味着它可以通过视频和图片来建模可变形的物体，还有什么比猫更容易变形呢？比看到结果更酷的是理解它是如何工作的…</p><figure class="mf mg mh mi gt mj gh gi paragraph-image"><div role="button" tabindex="0" class="mn mo di mp bf mq"><div class="gh gi mx"><img src="../Images/9d0721ff93d25e1cb446b398fe1c03a0.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*5rM0oDnFWgZs5iaoIQFFBg.png"/></div></div><figcaption class="mt mu gj gh gi mv mw bd b be z dk translated">图片来自<a class="ae li" href="https://banmo-www.github.io/banmo-cvpr.pdf" rel="noopener ugc nofollow" target="_blank">纸张</a>。</figcaption></figure><p id="ad9e" class="pw-post-body-paragraph kl km it ko b kp kq ju kr ks kt jx ku ls kw kx ky lw la lb lc ma le lf lg lh im bi translated">该模型从一些你想捕捉的物体的随意拍摄的视频开始，显示它如何移动和变形。你要把你的猫咕噜咕噜地吃进花瓶的视频发到那里！</p><p id="39cd" class="pw-post-body-paragraph kl km it ko b kp kq ju kr ks kt jx ku ls kw kx ky lw la lb lc ma le lf lg lh im bi translated">BANMo利用这些视频来创建他们所谓的规范空间。这个初步的结果会给你关于物体的形状、外观和关节的信息。它是模型对你的对象的形状的理解，它如何在空间中移动，它属于砖块和斑点之间的哪个位置，通过那些大球和各种颜色来描述。</p><figure class="mf mg mh mi gt mj gh gi paragraph-image"><a href="http://eepurl.com/huGLT5"><div class="gh gi my"><img src="../Images/13061735465f89757ce3261995b7e0ef.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*ekcUdSOnXtONEKUW.png"/></div></a></figure><p id="d058" class="pw-post-body-paragraph kl km it ko b kp kq ju kr ks kt jx ku ls kw kx ky lw la lb lc ma le lf lg lh im bi translated">然后，它采用这个3D表示，并应用您想要的任何姿势，尽可能接近现实地模拟猫的行为和发音。</p><p id="9bee" class="pw-post-body-paragraph kl km it ko b kp kq ju kr ks kt jx ku ls kw kx ky lw la lb lc ma le lf lg lh im bi translated">似乎很神奇，不是吗？那是因为我们还没说完。我们很快从视频转到模型，但这是有趣的地方。</p><figure class="mf mg mh mi gt mj gh gi paragraph-image"><div role="button" tabindex="0" class="mn mo di mp bf mq"><div class="gh gi mz"><img src="../Images/420a93d7df5293b1cd4c3f482e4e8bcc.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*S_BXr7ltEinrAa3MsnuQVA.png"/></div></div><figcaption class="mt mu gj gh gi mv mw bd b be z dk translated">图片来自<a class="ae li" href="https://banmo-www.github.io/banmo-cvpr.pdf" rel="noopener ugc nofollow" target="_blank">纸</a>。</figcaption></figure><p id="cb37" class="pw-post-body-paragraph kl km it ko b kp kq ju kr ks kt jx ku ls kw kx ky lw la lb lc ma le lf lg lh im bi translated">那么在这个规范空间中，他们用什么来把视频图像转换成这样的表示呢？你猜对了:一个类似NeRF的模型！</p><p id="936f" class="pw-post-body-paragraph kl km it ko b kp kq ju kr ks kt jx ku ls kw kx ky lw la lb lc ma le lf lg lh im bi translated">如果你不熟悉这种方法，我强烈建议你观看我制作的许多视频中的一个，然后回来看剩下的。</p><p id="53a4" class="pw-post-body-paragraph kl km it ko b kp kq ju kr ks kt jx ku ls kw kx ky lw la lb lc ma le lf lg lh im bi translated">简而言之，NeRF启发的方法必须预测物体的每个三维像素的三个基本属性，正如你在这里看到的:颜色，密度，以及使用为此训练的神经网络的规范嵌入。为了实现具有真实关节和运动的3D模型，BANMo使用相机的空间位置和多个帧来了解拍摄光线，允许它通过视频的所有帧来迭代地重建和改进3D模型，类似于我们理解一个对象，移动它并从各个方向观察它。</p><figure class="mf mg mh mi gt mj gh gi paragraph-image"><div role="button" tabindex="0" class="mn mo di mp bf mq"><div class="gh gi na"><img src="../Images/f5e9a05ff3b4e33e87c845c5135252ea.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*rOHnlb5ic1BIsEpbsqFwvA.png"/></div></div><figcaption class="mt mu gj gh gi mv mw bd b be z dk translated">图片来自<a class="ae li" href="https://banmo-www.github.io/banmo-cvpr.pdf" rel="noopener ugc nofollow" target="_blank">报社</a>。</figcaption></figure><p id="9700" class="pw-post-body-paragraph kl km it ko b kp kq ju kr ks kt jx ku ls kw kx ky lw la lb lc ma le lf lg lh im bi translated">这部分是通过观察视频自动完成的，这要感谢我们刚刚提到的规范嵌入。这种嵌入将包含对象的每个部分的所有必要特征，以允许您使用对象的新的期望位置进行查询，从而在给定观察的情况下实施相干重建。它基本上将所需的位置从图片映射到具有正确视点和光照条件的3D模型，并为所需的形状和关节提供线索。</p><figure class="mf mg mh mi gt mj gh gi paragraph-image"><div class="gh gi nb"><img src="../Images/84c598d1effeb1ee5107ca1ea7c0ec08.png" data-original-src="https://miro.medium.com/v2/resize:fit:482/1*sPez1EGGH1TkVrwitt9cMQ.gif"/></div><figcaption class="mt mu gj gh gi mv mw bd b be z dk translated">图片来自<a class="ae li" href="https://banmo-www.github.io/" rel="noopener ugc nofollow" target="_blank">作者项目页面</a>。</figcaption></figure><p id="69e5" class="pw-post-body-paragraph kl km it ko b kp kq ju kr ks kt jx ku ls kw kx ky lw la lb lc ma le lf lg lh im bi translated">最后要提的是我们的颜色。这些颜色代表了我们使用的不同视频和图像中共享的猫的身体属性。这是我们将学习和研究的功能，从所有视频中获取有价值的信息，并将它们合并到同一个3D模型中，以改善我们的结果。</p><p id="9d36" class="pw-post-body-paragraph kl km it ko b kp kq ju kr ks kt jx ku ls kw kx ky lw la lb lc ma le lf lg lh im bi translated">瞧！</p><p id="fae5" class="pw-post-body-paragraph kl km it ko b kp kq ju kr ks kt jx ku ls kw kx ky lw la lb lc ma le lf lg lh im bi translated">你最终得到了这只漂亮的3D可变形彩色猫，你可以在你的应用程序中使用它！</p><figure class="mf mg mh mi gt mj gh gi paragraph-image"><div class="gh gi nc"><img src="../Images/00297afe6afc9749e723fe058a8d36cf.png" data-original-src="https://miro.medium.com/v2/resize:fit:1200/1*7C2KQlyozEezaGlKINYnGA.gif"/></div><figcaption class="mt mu gj gh gi mv mw bd b be z dk translated">图片来自<a class="ae li" href="https://banmo-www.github.io/" rel="noopener ugc nofollow" target="_blank">作者的项目页面</a>。</figcaption></figure><p id="5ca6" class="pw-post-body-paragraph kl km it ko b kp kq ju kr ks kt jx ku ls kw kx ky lw la lb lc ma le lf lg lh im bi translated">当然，这只是对BANMo的一个概述，我邀请您阅读本文以更深入地理解这个模型。</p><h2 id="f00b" class="lj lk it bd ll lm ln dn lo lp lq dp lr ls lt lu lv lw lx ly lz ma mb mc md me bi translated">参考</h2><p id="d35c" class="pw-post-body-paragraph kl km it ko b kp nd ju kr ks ne jx ku ls nf kx ky lw ng lb lc ma nh lf lg lh im bi translated">项目页面:<a class="ae li" href="https://banmo-www.github.io/" rel="noopener ugc nofollow" target="_blank">、</a>、【论文:杨、Vo、m、Neverova、n、Ramanan、d、Vedaldi、a、Joo、h、2022。Banmo:从许多休闲视频中构建可动画化的3d神经模型。在<em class="kn">IEEE/CVF计算机视觉和模式识别会议论文集</em>(第2863–2873页)。<br/>代码:<a class="ae li" href="https://github.com/facebookresearch/banmo" rel="noopener ugc nofollow" target="_blank">https://github.com/facebookresearch/banmo</a></p></div></div>    
</body>
</html>