<html>
<head>
<title>Serving Python Machine Learning Models With Ease</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">轻松服务于Python机器学习模型</h1>
<blockquote>原文：<a href="https://pub.towardsai.net/serving-python-machine-learning-models-with-ease-29e1ba9e2155?source=collection_archive---------0-----------------------#2022-04-19">https://pub.towardsai.net/serving-python-machine-learning-models-with-ease-29e1ba9e2155?source=collection_archive---------0-----------------------#2022-04-19</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><figure class="gl gn jo jp jq jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi jn"><img src="../Images/360da4e3eb1f61ff0304f905e4021828.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*Dq5dVWUorrAdddxF"/></div></div><figcaption class="jy jz gj gh gi ka kb bd b be z dk translated">照片由<a class="ae kc" href="https://unsplash.com/@marius?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Marius Masalar </a>在<a class="ae kc" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上拍摄</figcaption></figure><p id="a4d5" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">有没有训练过一个新模型，并且只想通过API直接使用它？有时候你不想写Flask代码，或者把你的模型打包并在Docker中运行。如果这听起来像你，你肯定想看看<a class="ae kc" href="https://github.com/seldonio/mlserver" rel="noopener ugc nofollow" target="_blank"> MLServer </a>。这是一个基于python的推理服务器，最近正式上市，它真正出色的地方在于它也是一个为生产环境设计的高性能服务器。这意味着，通过在本地为模型提供服务，您可以在与它们进入生产环境时完全相同的环境中运行。</p><p id="718c" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">这篇博客以几个图像模型为例，带您了解如何使用MLServer</p><h1 id="9175" class="lb lc iq bd ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly bi translated">资料组</h1><p id="3e0f" class="pw-post-body-paragraph kd ke iq kf b kg lz ki kj kk ma km kn ko mb kq kr ks mc ku kv kw md ky kz la ij bi translated">我们将要使用的数据集是<a class="ae kc" href="https://www.kaggle.com/zalando-research/fashionmnist" rel="noopener ugc nofollow" target="_blank">时尚MNIST数据集</a>。它包含70，000幅灰度为28x28像素的服装图像，分为10个不同的类别(上衣、连衣裙、外套、裤子等)。</p><p id="9135" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated"><em class="me">如果你想复制这篇博客中的代码，确保你下载了文件，并把它们解压到一个名为</em> <code class="fe mf mg mh mi b"><em class="me">data</em></code> <em class="me">的文件夹中。GitHub repo中省略了它们，因为它们非常大。</em></p><h1 id="e9f0" class="lb lc iq bd ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly bi translated">培训Scikit-learn模型</h1><p id="53e0" class="pw-post-body-paragraph kd ke iq kf b kg lz ki kj kk ma km kn ko mb kq kr ks mc ku kv kw md ky kz la ij bi translated">首先，我们将使用scikit-learn框架训练一个支持向量机(SVM)模型。然后，我们将模型保存到一个名为<code class="fe mf mg mh mi b">Fashion-MNIST.joblib</code>的文件中。</p><pre class="mj mk ml mm gt mn mi mo mp aw mq bi"><span id="b5a2" class="mr lc iq mi b gy ms mt l mu mv">import pandas as pd<br/>from sklearn import svm<br/>import time<br/>import joblib</span><span id="6d2f" class="mr lc iq mi b gy mw mt l mu mv">#Load Training Data<br/>train = pd.read_csv('../../data/fashion-mnist_train.csv', header=0)<br/>y_train = train['label']<br/>X_train = train.drop(['label'], axis=1)<br/>classifier = svm.SVC(kernel="poly", degree=4, gamma=0.1)</span><span id="a37a" class="mr lc iq mi b gy mw mt l mu mv">#Train Model<br/>start = time.time()<br/>classifier.fit(X_train.values, y_train.values)<br/>end = time.time()<br/>exec_time = end-start<br/>print(f'Execution time: {exec_time} seconds')</span><span id="d04e" class="mr lc iq mi b gy mw mt l mu mv">#Save Model<br/>joblib.dump(classifier, "Fashion-MNIST.joblib")</span></pre><p id="513f" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">注意:SVM算法不是特别适合大型数据集，因为它的二次性质。本例中的模型将取决于您的硬件，需要几分钟来训练。</p><h1 id="34cf" class="lb lc iq bd ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly bi translated">服务于Scikit-learn模型</h1><p id="d88b" class="pw-post-body-paragraph kd ke iq kf b kg lz ki kj kk ma km kn ko mb kq kr ks mc ku kv kw md ky kz la ij bi translated">好了，我们现在已经有了一个保存的模型文件<code class="fe mf mg mh mi b">Fashion-MNIST.joblib</code>。让我们来看看如何使用MLServer实现这一点...</p><p id="e719" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">首先，我们需要安装MLServer。</p><p id="82ae" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated"><code class="fe mf mg mh mi b">pip install mlserver</code></p><p id="0cec" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">额外的运行时是可选的，但是当服务模型时，我们将安装Scikit-Learn和XGBoost</p><p id="7b44" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated"><code class="fe mf mg mh mi b">pip install mlserver-sklearn mlserver-xgboost</code></p><p id="71aa" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated"><em class="me">你可以在这里</em> 找到所有推理运行时 <a class="ae kc" href="https://mlserver.readthedocs.io/en/latest/runtimes/index.html#included-inference-runtimes" rel="noopener ugc nofollow" target="_blank"> <em class="me">的细节</em></a></p><p id="c467" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">完成后，我们需要做的就是添加两个配置文件:</p><ul class=""><li id="327c" class="mx my iq kf b kg kh kk kl ko mz ks na kw nb la nc nd ne nf bi translated"><code class="fe mf mg mh mi b">settings.json</code> -包含服务器本身的配置。</li><li id="670d" class="mx my iq kf b kg ng kk nh ko ni ks nj kw nk la nc nd ne nf bi translated"><code class="fe mf mg mh mi b">model-settings.json</code>——顾名思义，这个文件包含了我们想要运行的模型的配置。</li></ul><p id="8503" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">对于我们的<code class="fe mf mg mh mi b">settings.json</code>文件，只定义一个参数就足够了:</p><pre class="mj mk ml mm gt mn mi mo mp aw mq bi"><span id="dc2c" class="mr lc iq mi b gy ms mt l mu mv">{<br/>    "debug": "true"<br/>}</span></pre><p id="5c09" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated"><code class="fe mf mg mh mi b">model-settings.json</code>文件需要更多的信息，因为它需要了解我们试图服务的模型:</p><pre class="mj mk ml mm gt mn mi mo mp aw mq bi"><span id="ed9d" class="mr lc iq mi b gy ms mt l mu mv">{<br/>    "name": "fashion-sklearn",<br/>    "implementation": "mlserver_sklearn.SKLearnModel",<br/>    "parameters": {<br/>        "uri": "./Fashion_MNIST.joblib",<br/>        "version": "v1"<br/>    }<br/>}</span></pre><p id="dd2e" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">这个<code class="fe mf mg mh mi b">name</code>参数应该是不言自明的。它为MLServer提供了一个惟一的标识符，这在服务多个模型时特别有用(我们稍后会谈到这一点)。<code class="fe mf mg mh mi b">implementation</code>定义使用哪个预建服务器(如果有的话)。它与用于训练模型的机器学习框架紧密耦合。在我们的例子中，我们使用scikit-learn训练模型，因此我们将使用MLServer的scikit-learn实现。对于model，<code class="fe mf mg mh mi b">parameters</code>我们只需要提供模型文件的位置以及版本号。</p><p id="a9b6" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">就这样，两个小的配置文件，我们准备好使用命令来服务我们的模型:</p><p id="fd54" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated"><code class="fe mf mg mh mi b">mlserver start .</code></p><p id="ed9e" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">嘣，我们现在已经让我们的模型在本地生产就绪的服务器上运行了。现在已经准备好通过HTTP和gRPC接受请求了(分别是默认端口<code class="fe mf mg mh mi b">8080</code>和<code class="fe mf mg mh mi b">8081</code>)。</p><h1 id="d18c" class="lb lc iq bd ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly bi translated">测试模型</h1><p id="4be4" class="pw-post-body-paragraph kd ke iq kf b kg lz ki kj kk ma km kn ko mb kq kr ks mc ku kv kw md ky kz la ij bi translated">既然我们的模型已经建立并运行了。让我们发送一些请求来看看它的运行情况。</p><p id="6674" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">为了对我们的模型进行预测，我们需要向以下URL发送一个POST请求:</p><p id="b8c6" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated"><code class="fe mf mg mh mi b">http://localhost:8080/v2/models/&lt;MODEL_NAME&gt;/versions/&lt;VERSION&gt;/infer</code></p><p id="401c" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">这意味着要访问我们之前培训的scikit-learn模型，我们需要用<code class="fe mf mg mh mi b">fashion-sklearn</code>替换<code class="fe mf mg mh mi b">MODEL_NAME</code>，用<code class="fe mf mg mh mi b">v1</code>替换<code class="fe mf mg mh mi b">VERSION</code>。</p><p id="55e4" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">下面的代码显示了如何导入测试数据，向模型服务器发出请求，然后将结果与实际标签进行比较:</p><pre class="mj mk ml mm gt mn mi mo mp aw mq bi"><span id="a598" class="mr lc iq mi b gy ms mt l mu mv">import pandas as pd<br/>import requests</span><span id="2ab5" class="mr lc iq mi b gy mw mt l mu mv">#Import test data, grab the first row and corresponding label<br/>test = pd.read_csv('../../data/fashion-mnist_test.csv', header=0)<br/>y_test = test['label'][0:1]<br/>X_test = test.drop(['label'],axis=1)[0:1]</span><span id="6971" class="mr lc iq mi b gy mw mt l mu mv">#Prediction request parameters<br/>inference_request = {<br/>    "inputs": [<br/>        {<br/>          "name": "predict",<br/>          "shape": X_test.shape,<br/>          "datatype": "FP64",<br/>          "data": X_test.values.tolist()<br/>        }<br/>    ]<br/>}<br/>endpoint = "http://localhost:8080/v2/models/fashion-sklearn/versions/v1/infer"</span><span id="9307" class="mr lc iq mi b gy mw mt l mu mv">#Make request and print response<br/>response = requests.post(endpoint, json=inference_request)<br/>print(response.text)<br/>print(y_test.values)</span></pre><p id="2357" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">当运行上面的<code class="fe mf mg mh mi b">test.py</code>代码时，我们从MLServer得到以下响应:</p><pre class="mj mk ml mm gt mn mi mo mp aw mq bi"><span id="cbeb" class="mr lc iq mi b gy ms mt l mu mv">{<br/>  "model_name": "fashion-sklearn",<br/>  "model_version": "v1",<br/>  "id": "31c3fa70-2e56-49b1-bcec-294452dbe73c",<br/>  "parameters": null,<br/>  "outputs": [<br/>    {<br/>      "name": "predict",<br/>      "shape": [<br/>        1<br/>      ],<br/>      "datatype": "INT64",<br/>      "parameters": null,<br/>      "data": [<br/>        0<br/>      ]<br/>    }<br/>  ]<br/>}</span></pre><p id="8fa6" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">您会注意到MLServer已经生成了一个请求id，并自动添加了用于服务我们请求的模型和版本的元数据。一旦我们的模型进入生产阶段，获取这种元数据是非常重要的；它允许我们记录每个请求，以便进行审计和故障排除。</p><p id="215e" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">您可能还注意到MLServer已经为<code class="fe mf mg mh mi b">outputs</code>返回了一个数组。在我们的请求中，我们只发送了一行数据，但是MLServer也处理批量请求并将它们一起返回。您甚至可以使用一种叫做<a class="ae kc" href="https://mlserver.readthedocs.io/en/latest/user-guide/adaptive-batching.html" rel="noopener ugc nofollow" target="_blank">自适应批处理</a>的技术来优化在生产环境中处理多个请求的方式。</p><p id="9c54" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">在我们上面的例子中，模型的预测可以在<code class="fe mf mg mh mi b">outputs[0].data</code>中找到，这表明模型已经用类别<code class="fe mf mg mh mi b">0</code>标记了这个样本(值0对应于类别<code class="fe mf mg mh mi b">t-shirt/top</code>)。那个样本的真实标签也是一个<code class="fe mf mg mh mi b">0</code>，所以这个模型的预测是正确的！</p><h1 id="91f6" class="lb lc iq bd ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly bi translated">为XGBoost模型定型</h1><p id="488f" class="pw-post-body-paragraph kd ke iq kf b kg lz ki kj kk ma km kn ko mb kq kr ks mc ku kv kw md ky kz la ij bi translated">现在我们已经看到了如何使用MLServer创建和服务单个模型，让我们看看如何处理在不同框架中训练的多个模型。</p><p id="9543" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">我们将使用相同的时尚MNIST数据集，但这一次，我们将训练一个<a class="ae kc" href="https://xgboost.readthedocs.io/en/stable/" rel="noopener ugc nofollow" target="_blank"> XGBoost </a>模型。</p><pre class="mj mk ml mm gt mn mi mo mp aw mq bi"><span id="b0dc" class="mr lc iq mi b gy ms mt l mu mv">import pandas as pd<br/>import xgboost as xgb<br/>import time</span><span id="1761" class="mr lc iq mi b gy mw mt l mu mv">#Load Training Data<br/>train = pd.read_csv('../../data/fashion-mnist_train.csv', header=0)<br/>y_train = train['label']<br/>X_train = train.drop(['label'], axis=1)<br/>dtrain = xgb.DMatrix(X_train.values, label=y_train.values)</span><span id="90e6" class="mr lc iq mi b gy mw mt l mu mv">#Train Model<br/>params = {<br/>    'max_depth': 5,<br/>    'eta': 0.3,<br/>    'verbosity': 1,<br/>    'objective': 'multi:softmax',<br/>    'num_class' : 10<br/>}<br/>num_round = 50</span><span id="c206" class="mr lc iq mi b gy mw mt l mu mv">start = time.time()<br/>bstmodel = xgb.train(params, dtrain, num_round, evals=[(dtrain, 'label')], verbose_eval=10)<br/>end = time.time()<br/>exec_time = end-start<br/>print(f'Execution time: {exec_time} seconds')</span><span id="940a" class="mr lc iq mi b gy mw mt l mu mv">#Save Model<br/>bstmodel.save_model('Fashion_MNIST.json')</span></pre><p id="4d62" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">上面用来训练XGBoost模型的代码类似于我们之前用来训练scikit-learn模型的代码，但是这一次我们的模型以XGBoost兼容的格式保存为<code class="fe mf mg mh mi b">Fashion_MNIST.json</code>。</p><h1 id="d880" class="lb lc iq bd ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly bi translated">服务多个模型</h1><p id="f566" class="pw-post-body-paragraph kd ke iq kf b kg lz ki kj kk ma km kn ko mb kq kr ks mc ku kv kw md ky kz la ij bi translated">MLServer很酷的一点是它支持<a class="ae kc" href="https://mlserver.readthedocs.io/en/latest/examples/mms/README.html" rel="noopener ugc nofollow" target="_blank">多模型服务</a>。这意味着您不必为您想要部署的每个ML模型创建或运行一个新的服务器。使用我们在上面构建的模型，我们将使用这个特性同时为它们服务。</p><p id="d235" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">当MLServer启动时，它将在目录(以及任何子目录)中搜索<code class="fe mf mg mh mi b">model-settings.json</code>文件。如果你有多个<code class="fe mf mg mh mi b">model-settings.json</code>文件，那么它会自动为它们服务。</p><p id="7e20" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated"><em class="me">注意:您仍然只需要根目录</em>中的一个 <code class="fe mf mg mh mi b"><em class="me">settings.json</em></code> <em class="me">(服务器配置)文件</em></p><p id="4a24" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">下面是我的目录结构的细目分类，供参考:</p><pre class="mj mk ml mm gt mn mi mo mp aw mq bi"><span id="7ea1" class="mr lc iq mi b gy ms mt l mu mv">.<br/>├── data<br/>│   ├── fashion-mnist_test.csv<br/>│   └── fashion-mnist_train.csv<br/>├── models<br/>│   ├── sklearn<br/>│   │   ├── Fashion_MNIST.joblib<br/>│   │   ├── model-settings.json<br/>│   │   ├── test.py<br/>│   │   └── train.py<br/>│   └── xgboost<br/>│       ├── Fashion_MNIST.json<br/>│       ├── model-settings.json<br/>│       ├── test.py<br/>│       └── train.py<br/>├── README.md<br/>├── settings.json<br/>└── test_models.py</span></pre><p id="b2a0" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">注意有两个<code class="fe mf mg mh mi b">model-settings.json</code>文件——一个用于scikit-learn模型，一个用于XGBoost模型。</p><p id="2ea0" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">我们现在可以运行<code class="fe mf mg mh mi b">mlserver start .</code>，它将开始处理两个模型的请求。</p><pre class="mj mk ml mm gt mn mi mo mp aw mq bi"><span id="ea34" class="mr lc iq mi b gy ms mt l mu mv">[mlserver] INFO - Loaded model 'fashion-sklearn' succesfully.<br/>[mlserver] INFO - Loaded model 'fashion-xgboost' succesfully.</span></pre><h1 id="df00" class="lb lc iq bd ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly bi translated">测试多个模型的准确性</h1><p id="93d8" class="pw-post-body-paragraph kd ke iq kf b kg lz ki kj kk ma km kn ko mb kq kr ks mc ku kv kw md ky kz la ij bi translated">现在这两个模型都已经在MLServer上运行了，我们可以使用测试集中的样本来验证我们的每个模型有多准确。</p><p id="53d3" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">以下代码向每个模型发送一个批处理请求(包含完整的测试集),然后将收到的预测与真实标签进行比较。在整个测试集上这样做给了我们一个相当好的方法来衡量每个模型的准确性，并在最后打印出来。</p><pre class="mj mk ml mm gt mn mi mo mp aw mq bi"><span id="9588" class="mr lc iq mi b gy ms mt l mu mv">import pandas as pd<br/>import requests<br/>import json</span><span id="12b3" class="mr lc iq mi b gy mw mt l mu mv">#Import the test data and split the data from the labels<br/>test = pd.read_csv('./data/fashion-mnist_test.csv', header=0)<br/>y_test = test['label']<br/>X_test = test.drop(['label'],axis=1)</span><span id="d94b" class="mr lc iq mi b gy mw mt l mu mv">#Build the inference request<br/>inference_request = {<br/>    "inputs": [<br/>        {<br/>          "name": "predict",<br/>          "shape": X_test.shape,<br/>          "datatype": "FP64",<br/>          "data": X_test.values.tolist()<br/>        }<br/>    ]<br/>}</span><span id="2a14" class="mr lc iq mi b gy mw mt l mu mv">#Send the prediction request to the relevant model, compare responses to training labels and calculate accuracy<br/>def infer(model_name, version):<br/>    endpoint = f"http://localhost:8080/v2/models/{model_name}/versions/{version}/infer"<br/>    response = requests.post(endpoint, json=inference_request)</span><span id="0449" class="mr lc iq mi b gy mw mt l mu mv">    #calculate accuracy<br/>    correct = 0<br/>    for i, prediction in enumerate(json.loads(response.text)['outputs'][0]['data']):<br/>        if y_test[i] == prediction:<br/>            correct += 1<br/>    accuracy = correct / len(y_test)<br/>    print(f'Model Accuracy for {model_name}: {accuracy}')</span><span id="bf17" class="mr lc iq mi b gy mw mt l mu mv">infer("fashion-xgboost", "v1")<br/>infer("fashion-sklearn", "v1")</span></pre><p id="fd0e" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">结果显示，XGBoost模型略微优于SVM scikit-learn模型:</p><pre class="mj mk ml mm gt mn mi mo mp aw mq bi"><span id="86ee" class="mr lc iq mi b gy ms mt l mu mv">Model Accuracy for fashion-xgboost: 0.8953<br/>Model Accuracy for fashion-sklearn: 0.864</span></pre><h1 id="a335" class="lb lc iq bd ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly bi translated">摘要</h1><p id="996b" class="pw-post-body-paragraph kd ke iq kf b kg lz ki kj kk ma km kn ko mb kq kr ks mc ku kv kw md ky kz la ij bi translated">希望到现在为止，您已经理解了使用<a class="ae kc" href="https://mlserver.readthedocs.io/en/latest/index.html" rel="noopener ugc nofollow" target="_blank"> MLServer </a>为模型提供服务是多么容易。要了解更多信息，值得阅读一下<a class="ae kc" href="https://mlserver.readthedocs.io/en/latest/index.html" rel="noopener ugc nofollow" target="_blank">文档</a>，看看不同框架的<a class="ae kc" href="https://mlserver.readthedocs.io/en/latest/examples/index.html" rel="noopener ugc nofollow" target="_blank">示例。</a></p><p id="fd43" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">这个例子中的所有代码都可以在<a class="ae kc" href="https://github.com/edshee/mlserver-example" rel="noopener ugc nofollow" target="_blank">这里</a>找到。</p></div></div>    
</body>
</html>