<html>
<head>
<title>Machine Learning Algorithms For Beginners with Code Examples in Python</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">面向初学者的机器学习算法，带Python代码示例</h1>
<blockquote>原文：<a href="https://pub.towardsai.net/machine-learning-algorithms-for-beginners-with-python-code-examples-ml-19c6afd60daa?source=collection_archive---------0-----------------------#2020-06-03">https://pub.towardsai.net/machine-learning-algorithms-for-beginners-with-python-code-examples-ml-19c6afd60daa?source=collection_archive---------0-----------------------#2020-06-03</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><figure class="is it gp gr iu iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi ir"><img src="../Images/3d063bc3ee847deba9a71c9bdc212eee.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Lejtm0oGlOC5U0-J0JmGhg.png"/></div></div><figcaption class="jc jd gj gh gi je jf bd b be z dk translated">机器学习算法树|来源:图片作者<a class="ae jg" href="https://medium.com/@o.xlnwel" rel="noopener"> Sherwin Chen </a>，使用时请相应引用。引用来源可以在文章底部找到。</figcaption></figure><h2 id="4f08" class="jh ji jj bd b dl jk jl jm jn jo jp dk jq translated" aria-label="kicker paragraph"><a class="ae ep" href="https://towardsai.net/p/category/machine-learning" rel="noopener ugc nofollow" target="_blank">机器学习</a>、<a class="ae ep" href="https://towardsai.net/p/category/scholarly" rel="noopener ugc nofollow" target="_blank">学者型</a>、<a class="ae ep" href="https://towardsai.net/p/category/tutorial" rel="noopener ugc nofollow" target="_blank">教程型</a></h2><div class=""/><div class=""><h2 id="0751" class="pw-subtitle-paragraph kp js jj bd b kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg dk translated">用Python编写代码示例的初学者最佳机器学习算法。使用Google Colab启动编码示例</h2></div><p id="4506" class="pw-post-body-paragraph lh li jj lj b lk ll kt lm ln lo kw lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated"><strong class="lj jt">作者:</strong> <a class="ae jg" href="https://www.linkedin.com/in/pratik-shukla28/" rel="noopener ugc nofollow" target="_blank">普拉蒂克·舒克拉</a>，<a class="ae jg" href="https://mktg.best/vguzs" rel="noopener ugc nofollow" target="_blank">罗伯特·伊里翁多</a>，舍温·陈</p><p id="8538" class="pw-post-body-paragraph lh li jj lj b lk ll kt lm ln lo kw lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">最后更新于2021年4月14日</p><div class="is it gp gr iu md"><a href="https://members.towardsai.net/" rel="noopener  ugc nofollow" target="_blank"><div class="me ab fo"><div class="mf ab mg cl cj mh"><h2 class="bd jt gy z fp mi fr fs mj fu fw js bi translated">加入我们吧↓ |面向人工智能成员|数据驱动的社区</h2><div class="mk l"><h3 class="bd b gy z fp mi fr fs mj fu fw dk translated">加入人工智能，成为会员，你将不仅支持人工智能，但你将有机会…</h3></div><div class="ml l"><p class="bd b dl z fp mi fr fs mj fu fw dk translated">members.towardsai.net</p></div></div><div class="mm l"><div class="mn l mo mp mq mm mr ja md"/></div></div></a></div><p id="f286" class="pw-post-body-paragraph lh li jj lj b lk ll kt lm ln lo kw lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated"><a class="ae jg" href="https://mld.ai/mldcmu" rel="noopener ugc nofollow" target="_blank"> <strong class="lj jt">机器学习</strong> </a> <strong class="lj jt"> (ML) </strong>正在迅速改变世界，来自工业和学术界追求的各种类型的应用和研究。机器学习正在影响我们日常生活的方方面面。从使用NLP和机器学习的语音助手来预约、查看我们的日历和播放音乐，到程序化广告，这些广告如此准确，以至于它们可以在我们想到之前预测我们将需要什么。</p><p id="e490" class="pw-post-body-paragraph lh li jj lj b lk ll kt lm ln lo kw lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">通常情况下，机器学习科学领域的复杂性可能会令人难以承受，这使得跟上“什么是重要的”成为一项非常具有挑战性的任务。然而，为了确保我们为那些寻求学习机器学习，但对这些概念很陌生的人提供一条学习途径。在这篇文章中，我们看看最关键的基本算法，希望它们能让你的机器学习之旅不那么具有挑战性。</p><p id="9647" class="pw-post-body-paragraph lh li jj lj b lk ll kt lm ln lo kw lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">任何建议或反馈对持续改进都至关重要。如果你有任何问题，请在评论中告诉我们。</p><h1 id="66c0" class="ms mt jj bd mu mv mw mx my mz na nb nc ky nd kz ne lb nf lc ng le nh lf ni nj bi translated">索引</h1><ul class=""><li id="4cef" class="nk nl jj lj b lk nm ln nn lq no lu np ly nq mc nr ns nt nu bi translated">机器学习导论。</li><li id="34a9" class="nk nl jj lj b lk nv ln nw lq nx lu ny ly nz mc nr ns nt nu bi translated">主要的机器学习算法。</li><li id="8ddf" class="nk nl jj lj b lk nv ln nw lq nx lu ny ly nz mc nr ns nt nu bi translated">监督与非监督学习。</li><li id="278c" class="nk nl jj lj b lk nv ln nw lq nx lu ny ly nz mc nr ns nt nu bi translated">线性回归。</li><li id="d6d5" class="nk nl jj lj b lk nv ln nw lq nx lu ny ly nz mc nr ns nt nu bi translated">多变量线性回归。</li><li id="8393" class="nk nl jj lj b lk nv ln nw lq nx lu ny ly nz mc nr ns nt nu bi translated">多项式回归。</li><li id="3d9e" class="nk nl jj lj b lk nv ln nw lq nx lu ny ly nz mc nr ns nt nu bi translated">指数回归。</li><li id="d152" class="nk nl jj lj b lk nv ln nw lq nx lu ny ly nz mc nr ns nt nu bi translated">正弦回归。</li><li id="6f05" class="nk nl jj lj b lk nv ln nw lq nx lu ny ly nz mc nr ns nt nu bi translated">对数回归。</li></ul></div><div class="ab cl oa ob hx oc" role="separator"><span class="od bw bk oe of og"/><span class="od bw bk oe of og"/><span class="od bw bk oe of"/></div><div class="im in io ip iq"><blockquote class="oh"><p id="32fc" class="oi oj jj bd ok ol om on oo op oq mc dk translated">📚查看我们的教程，用数学和Python深入研究<a class="ae jg" href="https://towardsai.net/p/machine-learning/calculating-simple-linear-regression-and-linear-best-fit-an-in-depth-tutorial-with-math-and-python-804a0cb23660" rel="noopener ugc nofollow" target="_blank">简单线性回归</a>。📚</p></blockquote><h1 id="f7db" class="ms mt jj bd mu mv mw mx my mz na nb nc ky or kz ne lb os lc ng le ot lf ni nj bi translated">什么是机器学习？</h1><figure class="ou ov ow ox gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi ir"><img src="../Images/f4f6933f4ea8952fdc3150e11d84eeab.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Uosf1GeTSRd3LE1fFJRhbw.jpeg"/></div></div><figcaption class="jc jd gj gh gi je jf bd b be z dk translated">来源:<a class="ae jg" href="https://mld.ai/mldcmu" rel="noopener ugc nofollow" target="_blank">卡耐基梅隆大学机器学习系</a></figcaption></figure><blockquote class="oh"><p id="c780" class="oi oj jj bd ok ol oy oz pa pb pc mc dk translated">如果一个计算机程序在T类任务中的性能，如P所测量的，随着经验E的增加而提高，那么就说它从经验E中学习了一些任务T和性能测量P</p></blockquote><p id="57b7" class="pw-post-body-paragraph lh li jj lj b lk pd kt lm ln pe kw lp lq pf ls lt lu pg lw lx ly ph ma mb mc im bi translated">机器学习的行为类似于儿童的成长。随着孩子的成长，她在执行任务T中的经验E增加，这导致更高的绩效测量(P)。</p><p id="fbd5" class="pw-post-body-paragraph lh li jj lj b lk ll kt lm ln lo kw lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">例如，我们给孩子一个“形状分类积木”玩具。(现在我们都知道，在这个玩具里，我们有不同的形状和形状洞)。在这种情况下，我们任务是为一个形状找到一个合适的形状孔。之后，孩子观察形状，并试图将它放入一个成型的孔中。假设这个玩具有三种形状:圆形、三角形和正方形。在她第一次尝试寻找一个形状的洞时，她的表现度量(P)是1/3，这意味着孩子找到了3个正确形状的洞中的1个。</p><p id="c1e1" class="pw-post-body-paragraph lh li jj lj b lk ll kt lm ln lo kw lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">第二，孩子又尝试了一次，并注意到她在这项任务中有点经验。考虑到获得的经验(E)，孩子在另一次尝试这个任务，当测量表现(P)时，结果是2/3。在重复这个任务(T) 100次后，婴儿现在知道了哪个形状进入哪个形状孔。</p><p id="dc35" class="pw-post-body-paragraph lh li jj lj b lk ll kt lm ln lo kw lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">所以她的经验(E)增加了，她的表现(P)也增加了，然后我们注意到随着尝试这个玩具的次数增加。性能也会提高，从而导致更高的精度。</p><p id="8170" class="pw-post-body-paragraph lh li jj lj b lk ll kt lm ln lo kw lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">这样的执行类似于机器学习。机器所做的是，接受一个任务(T)，执行它，并测量它的性能(P)。现在，一台机器有大量的数据，因此当它处理这些数据时，它的经验(E)会随着时间的推移而增加，从而产生更高的性能指标(P)。因此，在浏览所有数据后，我们的机器学习模型的准确性增加了，这意味着我们的模型做出的预测将非常准确。</p><p id="5fde" class="pw-post-body-paragraph lh li jj lj b lk ll kt lm ln lo kw lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">阿瑟·塞缪尔对机器学习的另一个定义是:</p><blockquote class="oh"><p id="ab19" class="oi oj jj bd ok ol om on oo op oq mc dk translated">机器学习是计算机科学的子领域，它赋予“计算机无需显式编程就能学习的能力。”~亚瑟·塞缪尔[2]</p></blockquote><p id="cc45" class="pw-post-body-paragraph lh li jj lj b lk pd kt lm ln pe kw lp lq pf ls lt lu pg lw lx ly ph ma mb mc im bi translated">让我们试着理解这个定义:它指出“在没有明确编程的情况下学习”——这意味着我们不会用一套特定的规则来教计算机，相反，我们要做的是给计算机足够的数据，并给它时间从中学习，通过犯自己的错误并改进这些错误。例如，我们没有教孩子如何适应这些形状，但通过多次执行相同的任务，孩子学会了自己适应玩具的形状。</p><p id="9b99" class="pw-post-body-paragraph lh li jj lj b lk ll kt lm ln lo kw lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">因此，我们可以说，我们没有明确地教孩子如何适应这些形状。我们对机器做同样的事情。我们给它足够的数据来工作，并向它提供我们想要的信息。所以它处理数据并准确预测数据。</p><h2 id="95cf" class="pi mt jj bd mu pj pk dn my pl pm dp nc lq pn po ne lu pp pq ng ly pr ps ni jp bi translated">我们为什么需要机器学习？</h2><p id="173c" class="pw-post-body-paragraph lh li jj lj b lk nm kt lm ln nn kw lp lq pt ls lt lu pu lw lx ly pv ma mb mc im bi translated">例如，我们有一组猫和狗的图像。我们想做的是把它们归为一群猫狗。为此，我们需要找出不同的动物特征，例如:</p><ol class=""><li id="28b0" class="nk nl jj lj b lk ll ln lo lq pw lu px ly py mc pz ns nt nu bi translated">每种动物有几只眼睛？</li><li id="d401" class="nk nl jj lj b lk nv ln nw lq nx lu ny ly nz mc pz ns nt nu bi translated">每种动物的眼睛是什么颜色？</li><li id="5168" class="nk nl jj lj b lk nv ln nw lq nx lu ny ly nz mc pz ns nt nu bi translated">每种动物的身高是多少？</li><li id="e591" class="nk nl jj lj b lk nv ln nw lq nx lu ny ly nz mc pz ns nt nu bi translated">每种动物的重量是多少？</li><li id="a2d4" class="nk nl jj lj b lk nv ln nw lq nx lu ny ly nz mc pz ns nt nu bi translated">每种动物一般吃什么？</li></ol><p id="aeb4" class="pw-post-body-paragraph lh li jj lj b lk ll kt lm ln lo kw lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">我们在每个问题的答案上形成一个向量。接下来，我们应用一组规则，例如:</p><blockquote class="oh"><p id="1381" class="oi oj jj bd ok ol om on oo op oq mc dk translated">如果身高超过1英尺，体重超过15磅，那么它可能是一只猫。</p></blockquote><p id="e9ad" class="pw-post-body-paragraph lh li jj lj b lk pd kt lm ln pe kw lp lq pf ls lt lu pg lw lx ly ph ma mb mc im bi translated">现在，我们必须为每个数据点制定这样一套规则。此外，我们放置一个if、else if、else语句的决策树，并检查它是否属于其中一个类别。</p><p id="c240" class="pw-post-body-paragraph lh li jj lj b lk ll kt lm ln lo kw lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">让我们假设这个实验的结果没有收获，因为它错误地分类了许多动物，这给了我们一个使用机器学习的绝佳机会。</p><p id="b86d" class="pw-post-body-paragraph lh li jj lj b lk ll kt lm ln lo kw lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">机器学习所做的是用不同种类的算法处理数据，并告诉我们哪个特征更重要，以确定它是猫还是狗。因此，我们可以基于两个或三个特征来简化它，而不是应用许多规则集，结果，它给了我们更高的准确性。以前的方法不够一般化，不足以做出预测。</p><p id="118e" class="pw-post-body-paragraph lh li jj lj b lk ll kt lm ln lo kw lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">机器学习模型在许多任务中帮助我们，例如:</p><ul class=""><li id="e717" class="nk nl jj lj b lk ll ln lo lq pw lu px ly py mc nr ns nt nu bi translated">物体识别</li><li id="6e46" class="nk nl jj lj b lk nv ln nw lq nx lu ny ly nz mc nr ns nt nu bi translated">摘要</li><li id="a6c9" class="nk nl jj lj b lk nv ln nw lq nx lu ny ly nz mc nr ns nt nu bi translated">预言；预测；预告</li><li id="ceff" class="nk nl jj lj b lk nv ln nw lq nx lu ny ly nz mc nr ns nt nu bi translated">分类</li><li id="05ae" class="nk nl jj lj b lk nv ln nw lq nx lu ny ly nz mc nr ns nt nu bi translated">使聚集</li><li id="e13e" class="nk nl jj lj b lk nv ln nw lq nx lu ny ly nz mc nr ns nt nu bi translated">推荐系统</li><li id="74d0" class="nk nl jj lj b lk nv ln nw lq nx lu ny ly nz mc nr ns nt nu bi translated">以及其他等等</li></ul><h2 id="bdec" class="pi mt jj bd mu pj pk dn my pl pm dp nc lq pn po ne lu pp pq ng ly pr ps ni jp bi translated">什么是机器学习模型？</h2><p id="c152" class="pw-post-body-paragraph lh li jj lj b lk nm kt lm ln nn kw lp lq pt ls lt lu pu lw lx ly pv ma mb mc im bi translated">机器学习模型是一个负责处理机器学习相关任务的问答系统。把它想象成一个在解题时代表数据的算法系统。我们下面要解决的方法对于解决商业问题的行业相关目的是有益的。</p><p id="e557" class="pw-post-body-paragraph lh li jj lj b lk ll kt lm ln lo kw lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">例如，让我们想象我们正在研究Google Adwords的ML系统，我们的任务是实现一个ML算法来使用数据传达特定的人口统计或区域。这样的任务旨在从使用数据收集有价值的见解，以改善业务成果。</p><h1 id="f893" class="ms mt jj bd mu mv mw mx my mz na nb nc ky nd kz ne lb nf lc ng le nh lf ni nj bi translated">主要的机器学习算法:</h1><h2 id="a3dd" class="pi mt jj bd mu pj pk dn my pl pm dp nc lq pn po ne lu pp pq ng ly pr ps ni jp bi translated">1.回归(预测)</h2><p id="25ff" class="pw-post-body-paragraph lh li jj lj b lk nm kt lm ln nn kw lp lq pt ls lt lu pu lw lx ly pv ma mb mc im bi translated">我们使用回归算法来预测连续值。</p><p id="b139" class="pw-post-body-paragraph lh li jj lj b lk ll kt lm ln lo kw lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">回归算法:</p><ul class=""><li id="e42b" class="nk nl jj lj b lk ll ln lo lq pw lu px ly py mc nr ns nt nu bi translated">线性回归</li><li id="8526" class="nk nl jj lj b lk nv ln nw lq nx lu ny ly nz mc nr ns nt nu bi translated">多项式回归</li><li id="3f21" class="nk nl jj lj b lk nv ln nw lq nx lu ny ly nz mc nr ns nt nu bi translated">指数回归</li><li id="3269" class="nk nl jj lj b lk nv ln nw lq nx lu ny ly nz mc nr ns nt nu bi translated">逻辑回归</li><li id="f732" class="nk nl jj lj b lk nv ln nw lq nx lu ny ly nz mc nr ns nt nu bi translated">对数回归</li></ul><h2 id="c9fd" class="pi mt jj bd mu pj pk dn my pl pm dp nc lq pn po ne lu pp pq ng ly pr ps ni jp bi translated">2.分类</h2><p id="09e4" class="pw-post-body-paragraph lh li jj lj b lk nm kt lm ln nn kw lp lq pt ls lt lu pu lw lx ly pv ma mb mc im bi translated">我们使用分类算法来预测一组项目的类别。</p><p id="6f62" class="pw-post-body-paragraph lh li jj lj b lk ll kt lm ln lo kw lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">分类算法:</p><ul class=""><li id="6a18" class="nk nl jj lj b lk ll ln lo lq pw lu px ly py mc nr ns nt nu bi translated">k-最近邻</li><li id="fc71" class="nk nl jj lj b lk nv ln nw lq nx lu ny ly nz mc nr ns nt nu bi translated">决策树</li><li id="1a61" class="nk nl jj lj b lk nv ln nw lq nx lu ny ly nz mc nr ns nt nu bi translated">随机森林</li><li id="80f8" class="nk nl jj lj b lk nv ln nw lq nx lu ny ly nz mc nr ns nt nu bi translated">支持向量机</li><li id="6e74" class="nk nl jj lj b lk nv ln nw lq nx lu ny ly nz mc nr ns nt nu bi translated">朴素贝叶斯</li></ul><h2 id="a302" class="pi mt jj bd mu pj pk dn my pl pm dp nc lq pn po ne lu pp pq ng ly pr ps ni jp bi translated">3.使聚集</h2><p id="b040" class="pw-post-body-paragraph lh li jj lj b lk nm kt lm ln nn kw lp lq pt ls lt lu pu lw lx ly pv ma mb mc im bi translated">我们使用聚类算法进行汇总或构建数据。</p><p id="c816" class="pw-post-body-paragraph lh li jj lj b lk ll kt lm ln lo kw lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">聚类算法:</p><ul class=""><li id="ca3e" class="nk nl jj lj b lk ll ln lo lq pw lu px ly py mc nr ns nt nu bi translated">k均值</li><li id="0a28" class="nk nl jj lj b lk nv ln nw lq nx lu ny ly nz mc nr ns nt nu bi translated">基于密度的噪声应用空间聚类</li><li id="bf1c" class="nk nl jj lj b lk nv ln nw lq nx lu ny ly nz mc nr ns nt nu bi translated">均值漂移</li><li id="1078" class="nk nl jj lj b lk nv ln nw lq nx lu ny ly nz mc nr ns nt nu bi translated">等级体系的</li></ul><h2 id="1244" class="pi mt jj bd mu pj pk dn my pl pm dp nc lq pn po ne lu pp pq ng ly pr ps ni jp bi translated">4.联合</h2><p id="3d7b" class="pw-post-body-paragraph lh li jj lj b lk nm kt lm ln nn kw lp lq pt ls lt lu pu lw lx ly pv ma mb mc im bi translated">我们使用关联算法来关联同时发生的项目或事件。</p><p id="34ac" class="pw-post-body-paragraph lh li jj lj b lk ll kt lm ln lo kw lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">关联算法:</p><ul class=""><li id="f77f" class="nk nl jj lj b lk ll ln lo lq pw lu px ly py mc nr ns nt nu bi translated">推测的</li></ul><h2 id="41c4" class="pi mt jj bd mu pj pk dn my pl pm dp nc lq pn po ne lu pp pq ng ly pr ps ni jp bi translated">5.异常检测</h2><p id="1cdb" class="pw-post-body-paragraph lh li jj lj b lk nm kt lm ln nn kw lp lq pt ls lt lu pu lw lx ly pv ma mb mc im bi translated">我们使用异常检测来发现异常活动和异常案例，如欺诈检测。</p><h2 id="437e" class="pi mt jj bd mu pj pk dn my pl pm dp nc lq pn po ne lu pp pq ng ly pr ps ni jp bi translated">6.序列模式挖掘</h2><p id="5b12" class="pw-post-body-paragraph lh li jj lj b lk nm kt lm ln nn kw lp lq pt ls lt lu pu lw lx ly pv ma mb mc im bi translated">我们使用序列模式挖掘来预测序列中数据实例之间的下一个数据事件。</p><h2 id="34e0" class="pi mt jj bd mu pj pk dn my pl pm dp nc lq pn po ne lu pp pq ng ly pr ps ni jp bi translated">7.降维</h2><p id="4d09" class="pw-post-body-paragraph lh li jj lj b lk nm kt lm ln nn kw lp lq pt ls lt lu pu lw lx ly pv ma mb mc im bi translated">我们使用降维来减少数据的大小，以便从数据集中只提取有用的特征。</p><h2 id="890c" class="pi mt jj bd mu pj pk dn my pl pm dp nc lq pn po ne lu pp pq ng ly pr ps ni jp bi translated">8.推荐系统</h2><p id="9161" class="pw-post-body-paragraph lh li jj lj b lk nm kt lm ln nn kw lp lq pt ls lt lu pu lw lx ly pv ma mb mc im bi translated">我们使用推荐算法来构建推荐引擎。</p><p id="7c50" class="pw-post-body-paragraph lh li jj lj b lk ll kt lm ln lo kw lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">示例:</p><ul class=""><li id="ae00" class="nk nl jj lj b lk ll ln lo lq pw lu px ly py mc nr ns nt nu bi translated">网飞推荐系统。</li><li id="c479" class="nk nl jj lj b lk nv ln nw lq nx lu ny ly nz mc nr ns nt nu bi translated">一个图书推荐系统。</li><li id="529e" class="nk nl jj lj b lk nv ln nw lq nx lu ny ly nz mc nr ns nt nu bi translated">亚马逊上的产品推荐系统。</li></ul><p id="f029" class="pw-post-body-paragraph lh li jj lj b lk ll kt lm ln lo kw lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">如今，我们听到许多热门词汇，如人工智能、机器学习、深度学习等。</p><h1 id="a54d" class="ms mt jj bd mu mv mw mx my mz na nb nc ky nd kz ne lb nf lc ng le nh lf ni nj bi translated"><strong class="ak">人工智能、机器学习、深度学习的根本区别是什么？</strong></h1><blockquote class="oh"><p id="d32d" class="oi oj jj bd ok ol om on oo op oq mc dk translated">📚查看我们对<a class="ae jg" href="https://towardsai.net/p/machine-learning/best-machine-learning-books-free-and-paid-ml-book-recommendations-40c9ab30b0c" rel="noopener ugc nofollow" target="_blank">最佳机器学习书籍</a>的编辑推荐。📚</p></blockquote><h2 id="575c" class="pi mt jj bd mu pj qa dn my pl qb dp nc lq qc po ne lu qd pq ng ly qe ps ni jp bi translated">人工智能(AI):</h2><p id="44b3" class="pw-post-body-paragraph lh li jj lj b lk nm kt lm ln nn kw lp lq pt ls lt lu pu lw lx ly pv ma mb mc im bi translated">根据安德鲁·摩尔教授的定义，人工智能(AI)是让计算机以我们认为需要人类智能的方式运行的科学和工程[4]。</p><p id="079c" class="pw-post-body-paragraph lh li jj lj b lk ll kt lm ln lo kw lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">其中包括:</p><ul class=""><li id="88d0" class="nk nl jj lj b lk ll ln lo lq pw lu px ly py mc nr ns nt nu bi translated">计算机视觉</li><li id="57a8" class="nk nl jj lj b lk nv ln nw lq nx lu ny ly nz mc nr ns nt nu bi translated">语言处理</li><li id="2dda" class="nk nl jj lj b lk nv ln nw lq nx lu ny ly nz mc nr ns nt nu bi translated">创造力</li><li id="bd42" class="nk nl jj lj b lk nv ln nw lq nx lu ny ly nz mc nr ns nt nu bi translated">摘要</li></ul><h2 id="25c1" class="pi mt jj bd mu pj pk dn my pl pm dp nc lq pn po ne lu pp pq ng ly pr ps ni jp bi translated"><strong class="ak">机器学习(ML): </strong></h2><p id="b34a" class="pw-post-body-paragraph lh li jj lj b lk nm kt lm ln nn kw lp lq pt ls lt lu pu lw lx ly pv ma mb mc im bi translated">根据Tom Mitchell教授的定义，机器学习是指人工智能的一个科学分支，主要研究计算机算法，让计算机程序通过经验自动改进[3]。</p><p id="7fe1" class="pw-post-body-paragraph lh li jj lj b lk ll kt lm ln lo kw lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">其中包括:</p><ul class=""><li id="9190" class="nk nl jj lj b lk ll ln lo lq pw lu px ly py mc nr ns nt nu bi translated">分类</li><li id="0b37" class="nk nl jj lj b lk nv ln nw lq nx lu ny ly nz mc nr ns nt nu bi translated">神经网络</li><li id="3851" class="nk nl jj lj b lk nv ln nw lq nx lu ny ly nz mc nr ns nt nu bi translated">使聚集</li></ul><h2 id="02e4" class="pi mt jj bd mu pj pk dn my pl pm dp nc lq pn po ne lu pp pq ng ly pr ps ni jp bi translated"><strong class="ak">深度学习:</strong></h2><p id="4fe0" class="pw-post-body-paragraph lh li jj lj b lk nm kt lm ln nn kw lp lq pt ls lt lu pu lw lx ly pv ma mb mc im bi translated">深度学习是机器学习的一个子集，其中分层的神经网络结合高计算能力和大数据集，可以创建强大的机器学习模型。[3]</p><figure class="ou ov ow ox gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi qf"><img src="../Images/dfb17b8c5e49450170e8576b47583d29.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*tKEOeCXmg0_i-eMaUcCTvw.png"/></div></div><figcaption class="jc jd gj gh gi je jf bd b be z dk translated">神经网络抽象表示|照片由克林·王茂林通过<a class="ae jg" href="https://unsplash.com/photos/BW0vK-FA3eg" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>拍摄</figcaption></figure><h1 id="6ad1" class="ms mt jj bd mu mv mw mx my mz na nb nc ky nd kz ne lb nf lc ng le nh lf ni nj bi translated">为什么我们更喜欢用Python实现机器学习算法？</h1><p id="cfce" class="pw-post-body-paragraph lh li jj lj b lk nm kt lm ln nn kw lp lq pt ls lt lu pu lw lx ly pv ma mb mc im bi translated">Python是一种流行的通用编程语言。我们可以用Python写机器学习算法，效果很好。Python在数据科学家中如此受欢迎的原因是Python已经实现了各种各样的模块和库，使我们的生活更加舒适。</p><p id="cda7" class="pw-post-body-paragraph lh li jj lj b lk ll kt lm ln lo kw lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">让我们简单看一下一些令人兴奋的Python库。</p><ol class=""><li id="451a" class="nk nl jj lj b lk ll ln lo lq pw lu px ly py mc pz ns nt nu bi translated"><strong class="lj jt"> Numpy </strong>:这是一个在Python中处理n维数组的数学库。它使我们能够有效和高效地进行计算。</li><li id="a915" class="nk nl jj lj b lk nv ln nw lq nx lu ny ly nz mc pz ns nt nu bi translated"><strong class="lj jt"> Scipy </strong>:它是一个数值算法和特定领域工具箱的集合，包括信号处理、优化、统计等等。Scipy是用于科学和高性能计算的函数库。</li><li id="8ede" class="nk nl jj lj b lk nv ln nw lq nx lu ny ly nz mc pz ns nt nu bi translated"><strong class="lj jt"> Matplotlib </strong>:这是一个流行的绘图包，提供2D绘图以及3D绘图。</li><li id="6c32" class="nk nl jj lj b lk nv ln nw lq nx lu ny ly nz mc pz ns nt nu bi translated"><strong class="lj jt"> Scikit-learn </strong>:这是一个免费的python编程语言的机器学习库。它拥有大部分的分类、回归和聚类算法，并且可以使用Python数字库，比如Numpy、Scipy。</li></ol><p id="a455" class="pw-post-body-paragraph lh li jj lj b lk ll kt lm ln lo kw lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated"><strong class="lj jt">机器学习算法分为两组:</strong></p><ul class=""><li id="6098" class="nk nl jj lj b lk ll ln lo lq pw lu px ly py mc nr ns nt nu bi translated">监督学习算法</li><li id="9978" class="nk nl jj lj b lk nv ln nw lq nx lu ny ly nz mc nr ns nt nu bi translated">无监督学习算法</li></ul><h1 id="bc24" class="ms mt jj bd mu mv mw mx my mz na nb nc ky nd kz ne lb nf lc ng le nh lf ni nj bi translated">I .监督学习算法:</h1><p id="a503" class="pw-post-body-paragraph lh li jj lj b lk nm kt lm ln nn kw lp lq pt ls lt lu pu lw lx ly pv ma mb mc im bi translated">目标:预测类或值标签。</p><p id="e6af" class="pw-post-body-paragraph lh li jj lj b lk ll kt lm ln lo kw lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">监督学习是机器学习的一个分支(目前可能是机器/深度学习的主流)，与从标记的训练数据中推断函数有关。训练数据由一组*(输入，目标)*对组成，其中输入可以是特征向量，目标指示我们希望函数输出什么。根据目标的类型，我们可以将监督学习大致分为两类:分类和回归。分类涉及分类目标；例子从一些简单的情况，如图像分类，到一些高级的主题，如机器翻译和图像字幕。回归涉及连续的目标。它的应用包括股票预测、图像屏蔽和其他——都属于这一类。</p><figure class="ou ov ow ox gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi qg"><img src="../Images/50936f914f825ff73b242b1a94a5d1d8.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*o6WovrAQ7Z1vNhjg"/></div></div><figcaption class="jc jd gj gh gi je jf bd b be z dk translated">下面是监督学习的例子|图片来源:Shirota Yuri，<a class="ae jg" href="https://unsplash.com/photos/p0hDztR46cw" rel="noopener ugc nofollow" target="_blank"> Unsplash </a></figcaption></figure><p id="1faa" class="pw-post-body-paragraph lh li jj lj b lk ll kt lm ln lo kw lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">为了理解监督学习是什么，我们将使用一个例子。例如，我们给一个孩子100个填充动物玩具，其中每种动物有10个，比如10只狮子、10只猴子、10只大象等等。接下来，我们教孩子根据动物的不同特征识别不同类型的动物。例如，如果它的颜色是橙色，那么它可能是一只狮子。如果它是一种有鼻子的大动物，那么它可能是一头大象。</p><p id="870f" class="pw-post-body-paragraph lh li jj lj b lk ll kt lm ln lo kw lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">我们教孩子如何区分动物，这是监督学习的一个例子。现在，当我们给孩子不同的动物时，他应该能够将它们归类到适当的动物组。</p><p id="6723" class="pw-post-body-paragraph lh li jj lj b lk ll kt lm ln lo kw lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">为了这个例子，我们注意到他的分类有8/10是正确的。所以我们可以说这个孩子做得很好。这同样适用于计算机。我们为他们提供了数千个数据点及其实际标记值(标记数据是将数据与其特征值一起分类到不同的组中)。然后它在训练期学习它的不同特点。训练期结束后，我们可以使用我们训练好的模型进行预测。请记住，我们已经向机器输入了标记数据，因此它的预测算法是基于监督学习的。简而言之，我们可以说这个例子的预测是基于标记数据的。</p><p id="637d" class="pw-post-body-paragraph lh li jj lj b lk ll kt lm ln lo kw lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">监督学习算法的例子:</p><ul class=""><li id="bc81" class="nk nl jj lj b lk ll ln lo lq pw lu px ly py mc nr ns nt nu bi translated">线性回归</li><li id="7439" class="nk nl jj lj b lk nv ln nw lq nx lu ny ly nz mc nr ns nt nu bi translated">逻辑回归</li><li id="a628" class="nk nl jj lj b lk nv ln nw lq nx lu ny ly nz mc nr ns nt nu bi translated">k-最近邻</li><li id="d9b5" class="nk nl jj lj b lk nv ln nw lq nx lu ny ly nz mc nr ns nt nu bi translated">决策图表</li><li id="be64" class="nk nl jj lj b lk nv ln nw lq nx lu ny ly nz mc nr ns nt nu bi translated">随机森林</li><li id="8dde" class="nk nl jj lj b lk nv ln nw lq nx lu ny ly nz mc nr ns nt nu bi translated">支持向量机</li></ul><h1 id="b1f9" class="ms mt jj bd mu mv mw mx my mz na nb nc ky nd kz ne lb nf lc ng le nh lf ni nj bi translated">二。无监督学习:</h1><p id="249e" class="pw-post-body-paragraph lh li jj lj b lk nm kt lm ln nn kw lp lq pt ls lt lu pu lw lx ly pv ma mb mc im bi translated">目标:确定数据模式/分组。</p><p id="7d62" class="pw-post-body-paragraph lh li jj lj b lk ll kt lm ln lo kw lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">与监督学习相反。无监督学习从不标记的数据中进行推断，这是一种描述数据中隐藏结构的函数。</p><p id="3227" class="pw-post-body-paragraph lh li jj lj b lk ll kt lm ln lo kw lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">可能最基本的一类无监督学习就是降维方法，比如PCA，t-SNE，而PCA一般用于数据预处理，t-SNE通常用于数据可视化。</p><p id="0927" class="pw-post-body-paragraph lh li jj lj b lk ll kt lm ln lo kw lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">一个更高级的分支是聚类，它探索数据中隐藏的模式，然后对它们进行预测；示例包括K均值聚类、高斯混合模型、隐马尔可夫模型等。</p><p id="2688" class="pw-post-body-paragraph lh li jj lj b lk ll kt lm ln lo kw lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">随着深度学习的复兴，无监督学习越来越受到关注，因为它将我们从手动标记数据中解放出来。鉴于深度学习，我们考虑两种无监督学习:<strong class="lj jt">表示学习</strong>和<strong class="lj jt">生成模型</strong>。</p><p id="45ff" class="pw-post-body-paragraph lh li jj lj b lk ll kt lm ln lo kw lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">表征学习旨在提取对一些下游任务有用的高级代表特征，而生成模型旨在从一些隐藏参数中再现输入数据。</p><figure class="ou ov ow ox gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi qg"><img src="../Images/d3bbf3f661790d582bf243d0c6956b1f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*7rObqHqHLgi6s3Su"/></div></div><figcaption class="jc jd gj gh gi je jf bd b be z dk translated">为了说明下面无监督学习的例子|来源:Jelleke Vanooteghem的照片，<a class="ae jg" href="https://unsplash.com/photos/bNUGJD3gO94" rel="noopener ugc nofollow" target="_blank"> Unsplash </a></figcaption></figure><p id="9f41" class="pw-post-body-paragraph lh li jj lj b lk ll kt lm ln lo kw lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">无监督学习听起来很有效。在这种类型的算法中，我们没有标记数据。因此，机器必须处理输入数据，并试图对输出做出结论。例如，还记得我们给了一个形状玩具的小孩吗？在这种情况下，他会从自己的错误中学习，为不同的形状找到完美的形状洞。</p><p id="94a3" class="pw-post-body-paragraph lh li jj lj b lk ll kt lm ln lo kw lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">但问题是，我们不是通过教授适合形状的方法来喂养孩子(出于机器学习的目的，称为标记数据)。然而，孩子从玩具的不同特性中学习，并试图对它们做出结论。简而言之，预测是基于未标记的数据。</p><p id="2589" class="pw-post-body-paragraph lh li jj lj b lk ll kt lm ln lo kw lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">无监督学习算法的例子:</p><ul class=""><li id="204f" class="nk nl jj lj b lk ll ln lo lq pw lu px ly py mc nr ns nt nu bi translated">降维</li><li id="7727" class="nk nl jj lj b lk nv ln nw lq nx lu ny ly nz mc nr ns nt nu bi translated">密度估计</li><li id="1cc3" class="nk nl jj lj b lk nv ln nw lq nx lu ny ly nz mc nr ns nt nu bi translated">市场篮子分析</li><li id="43fc" class="nk nl jj lj b lk nv ln nw lq nx lu ny ly nz mc nr ns nt nu bi translated">生成对抗网络</li><li id="cecd" class="nk nl jj lj b lk nv ln nw lq nx lu ny ly nz mc nr ns nt nu bi translated">使聚集</li></ul></div><div class="ab cl oa ob hx oc" role="separator"><span class="od bw bk oe of og"/><span class="od bw bk oe of og"/><span class="od bw bk oe of"/></div><div class="im in io ip iq"><figure class="ou ov ow ox gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi qf"><img src="../Images/e59277265115ceeaa24448bc9520eab2.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*H17RkdpL0FeJK2fQ9KlmEA.png"/></div></div><figcaption class="jc jd gj gh gi je jf bd b be z dk translated">在抽象的现实生活中，神经网络会是什么样子？资料来源:蒂莫·沃尔茨</figcaption></figure><blockquote class="oh"><p id="ed8a" class="oi oj jj bd ok ol oy oz pa pb pc mc dk translated"><strong class="ak">在本文中，我们将使用几种类型的回归算法和Python代码示例。</strong></p></blockquote><h1 id="a92f" class="ms mt jj bd mu mv mw mx my mz na nb nc ky or kz ne lb os lc ng le ot lf ni nj bi translated">1.线性回归:</h1><figure class="ou ov ow ox gt iv gh gi paragraph-image"><div class="gh gi qh"><img src="../Images/864127ce1f005ca94d2199835bdd1742.png" data-original-src="https://miro.medium.com/v2/resize:fit:1286/format:webp/0*Vb5HGtdMQp-GWwXr.png"/></div><figcaption class="jc jd gj gh gi je jf bd b be z dk translated">图中的线性回归算法|来源:用Python处理的图像。</figcaption></figure><p id="c3ba" class="pw-post-body-paragraph lh li jj lj b lk ll kt lm ln lo kw lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">线性回归是一种对输入要素和输出之间的关系进行建模的统计方法。输入特性称为<strong class="lj jt">自变量</strong>，输出称为<strong class="lj jt">因变量</strong>。我们的目标是通过将输入要素乘以其最佳系数来预测基于输入要素的输出值。</p><h2 id="ab38" class="pi mt jj bd mu pj pk dn my pl pm dp nc lq pn po ne lu pp pq ng ly pr ps ni jp bi translated">线性回归的一些实际例子:</h2><p id="c2fd" class="pw-post-body-paragraph lh li jj lj b lk nm kt lm ln nn kw lp lq pt ls lt lu pu lw lx ly pv ma mb mc im bi translated">(1)预测产品的销售。</p><p id="259e" class="pw-post-body-paragraph lh li jj lj b lk ll kt lm ln lo kw lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">(2)预测经济增长。</p><p id="1232" class="pw-post-body-paragraph lh li jj lj b lk ll kt lm ln lo kw lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">(3)预测石油价格。</p><p id="0c21" class="pw-post-body-paragraph lh li jj lj b lk ll kt lm ln lo kw lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">(4)预测一辆新车的排放。</p><p id="f4d5" class="pw-post-body-paragraph lh li jj lj b lk ll kt lm ln lo kw lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">(GPA对高校录取的影响。</p><p id="95e4" class="pw-post-body-paragraph lh li jj lj b lk ll kt lm ln lo kw lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated"><strong class="lj jt">有两种类型的线性回归:</strong></p><ol class=""><li id="9aa6" class="nk nl jj lj b lk ll ln lo lq pw lu px ly py mc pz ns nt nu bi translated">简单线性回归</li><li id="9905" class="nk nl jj lj b lk nv ln nw lq nx lu ny ly nz mc pz ns nt nu bi translated">多元线性回归</li></ol><h2 id="3f1d" class="pi mt jj bd mu pj pk dn my pl pm dp nc lq pn po ne lu pp pq ng ly pr ps ni jp bi translated">1.1简单线性回归:</h2><p id="c18c" class="pw-post-body-paragraph lh li jj lj b lk nm kt lm ln nn kw lp lq pt ls lt lu pu lw lx ly pv ma mb mc im bi translated">在简单线性回归中，我们仅基于一个输入特征来预测输出/因变量。简单线性回归由下式给出:</p><figure class="ou ov ow ox gt iv gh gi paragraph-image"><div class="gh gi qi"><img src="../Images/c64069f9777b8afdce7b1cf0b499bd3c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1106/format:webp/0*yY6gRxHojuRxlPJq.png"/></div><figcaption class="jc jd gj gh gi je jf bd b be z dk translated">线性回归方程|来源:图片由作者创作。</figcaption></figure><p id="4dd5" class="pw-post-body-paragraph lh li jj lj b lk ll kt lm ln lo kw lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">下面我们将使用Python中的sklearn库实现简单的线性回归。</p><h2 id="c1f7" class="pi mt jj bd mu pj pk dn my pl pm dp nc lq pn po ne lu pp pq ng ly pr ps ni jp bi translated">Python中的分步实现:</h2><p id="415e" class="pw-post-body-paragraph lh li jj lj b lk nm kt lm ln nn kw lp lq pt ls lt lu pu lw lx ly pv ma mb mc im bi translated"><strong class="lj jt"> a .导入所需库:</strong></p><p id="39ec" class="pw-post-body-paragraph lh li jj lj b lk ll kt lm ln lo kw lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">由于我们要使用各种库进行计算，所以我们需要导入它们。</p><figure class="ou ov ow ox gt iv gh gi paragraph-image"><div class="gh gi qj"><img src="../Images/81746bd57c4821c0cdaa458c8576ed9e.png" data-original-src="https://miro.medium.com/v2/resize:fit:654/format:webp/0*7GOoa1-eFoY3ftSF.png"/></div><figcaption class="jc jd gj gh gi je jf bd b be z dk translated">来源:图片由作者创作。</figcaption></figure><p id="bd44" class="pw-post-body-paragraph lh li jj lj b lk ll kt lm ln lo kw lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated"><strong class="lj jt"> b .读取CSV文件:</strong></p><p id="051f" class="pw-post-body-paragraph lh li jj lj b lk ll kt lm ln lo kw lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">我们<strong class="lj jt"> </strong>检查数据集的前五行。在这种情况下，我们使用的是车辆模型数据集——请在<a class="ae jg" href="https://s3-api.us-geo.objectstorage.softlayer.net/cf-courses-data/CognitiveClass/ML0101ENv3/labs/FuelConsumptionCo2.csv" rel="noopener ugc nofollow" target="_blank"> Softlayer IBM </a>上查看数据集。</p><figure class="ou ov ow ox gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi qk"><img src="../Images/7f05ee9692248e2c79a8ad3e4eb8739e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*NRdSXCWzKBMu1ksf.png"/></div></div><figcaption class="jc jd gj gh gi je jf bd b be z dk translated">来源:图片由作者创作。</figcaption></figure><p id="e1b0" class="pw-post-body-paragraph lh li jj lj b lk ll kt lm ln lo kw lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated"><strong class="lj jt"> c .选择我们在预测值时要考虑的特征:</strong></p><p id="640f" class="pw-post-body-paragraph lh li jj lj b lk ll kt lm ln lo kw lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">这里，我们的目标是从数据集中的“发动机尺寸”值预测“co2排放量”值。</p><figure class="ou ov ow ox gt iv gh gi paragraph-image"><div class="gh gi ql"><img src="../Images/1f4192fb53631112b04a60273004756f.png" data-original-src="https://miro.medium.com/v2/resize:fit:760/format:webp/0*3LrRS2JVHdm1bP8l.png"/></div><figcaption class="jc jd gj gh gi je jf bd b be z dk translated">来源:图片由作者创作。</figcaption></figure><p id="dc42" class="pw-post-body-paragraph lh li jj lj b lk ll kt lm ln lo kw lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated"><strong class="lj jt"> d .绘制数据:</strong></p><p id="00f6" class="pw-post-body-paragraph lh li jj lj b lk ll kt lm ln lo kw lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">我们可以在散点图上显示我们的数据。</p><figure class="ou ov ow ox gt iv gh gi paragraph-image"><div class="gh gi qm"><img src="../Images/33cdd3ed827dac3402e8203946139080.png" data-original-src="https://miro.medium.com/v2/resize:fit:1162/format:webp/0*bwSUA7XohSJV9ekz.png"/></div><figcaption class="jc jd gj gh gi je jf bd b be z dk translated">线性回归算法的数据图|来源:图片由作者创建。</figcaption></figure><p id="0fb5" class="pw-post-body-paragraph lh li jj lj b lk ll kt lm ln lo kw lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated"><strong class="lj jt"> e .将数据分为训练和测试数据:</strong></p><p id="bec6" class="pw-post-body-paragraph lh li jj lj b lk ll kt lm ln lo kw lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">为了检查模型的准确性，我们将把数据分为训练数据集和测试数据集。我们将使用训练数据来训练我们的模型，然后我们将使用测试数据集来检查我们的模型的准确性。</p><figure class="ou ov ow ox gt iv gh gi paragraph-image"><div class="gh gi qn"><img src="../Images/5f283ec836e45014ad996dbaaba441b7.png" data-original-src="https://miro.medium.com/v2/resize:fit:898/format:webp/0*RwuaUKddgtSs24HV.png"/></div><figcaption class="jc jd gj gh gi je jf bd b be z dk translated">来源:图片由作者创作。</figcaption></figure><p id="4a48" class="pw-post-body-paragraph lh li jj lj b lk ll kt lm ln lo kw lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated"><strong class="lj jt"> f .训练我们的模型:</strong></p><p id="0bc7" class="pw-post-body-paragraph lh li jj lj b lk ll kt lm ln lo kw lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">这里是我们如何训练我们的模型，并找到我们的最佳拟合回归线的系数。</p><figure class="ou ov ow ox gt iv gh gi paragraph-image"><div class="gh gi qo"><img src="../Images/0a62059810f60e8cb5ba4c34da9a18ca.png" data-original-src="https://miro.medium.com/v2/resize:fit:1096/format:webp/0*2-Ipxk7gK6k5oARe.png"/></div><figcaption class="jc jd gj gh gi je jf bd b be z dk translated">来源:图片由作者创作。</figcaption></figure><p id="1c09" class="pw-post-body-paragraph lh li jj lj b lk ll kt lm ln lo kw lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated"><strong class="lj jt"> g .绘制最佳拟合线:</strong></p><p id="f4c9" class="pw-post-body-paragraph lh li jj lj b lk ll kt lm ln lo kw lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">基于这些系数，我们可以为数据集绘制最佳拟合线。</p><figure class="ou ov ow ox gt iv gh gi paragraph-image"><div class="gh gi qp"><img src="../Images/45b45a7998898b356ecd9c598b753964.png" data-original-src="https://miro.medium.com/v2/resize:fit:1126/format:webp/0*l-TY7VZeWAmn2OwF.png"/></div><figcaption class="jc jd gj gh gi je jf bd b be z dk translated">基于系数的线性回归数据图|来源:图片由作者创建。</figcaption></figure><p id="6caa" class="pw-post-body-paragraph lh li jj lj b lk ll kt lm ln lo kw lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated"><strong class="lj jt"> h .预测功能:</strong></p><p id="34ee" class="pw-post-body-paragraph lh li jj lj b lk ll kt lm ln lo kw lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">我们将对测试数据集使用预测函数。</p><figure class="ou ov ow ox gt iv gh gi paragraph-image"><div class="gh gi qq"><img src="../Images/2dc02f6a68172cd85e4543b982669d58.png" data-original-src="https://miro.medium.com/v2/resize:fit:1046/format:webp/0*AiOQQmKCq_OIAcR2.png"/></div><figcaption class="jc jd gj gh gi je jf bd b be z dk translated">来源:图片由作者创作。</figcaption></figure><p id="3a2a" class="pw-post-body-paragraph lh li jj lj b lk ll kt lm ln lo kw lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated"><strong class="lj jt">一、预测二氧化碳排放量:</strong></p><p id="c681" class="pw-post-body-paragraph lh li jj lj b lk ll kt lm ln lo kw lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">根据回归线预测二氧化碳排放量。</p><figure class="ou ov ow ox gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi qr"><img src="../Images/3756f0e375a8a763c5b2661a660fd740.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*QpDaJPJE1wPtDJwV.png"/></div></div><figcaption class="jc jd gj gh gi je jf bd b be z dk translated">来源:图片由作者创作。</figcaption></figure><p id="76e8" class="pw-post-body-paragraph lh li jj lj b lk ll kt lm ln lo kw lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated"><strong class="lj jt"> j .检查测试数据的准确性:</strong></p><p id="d04b" class="pw-post-body-paragraph lh li jj lj b lk ll kt lm ln lo kw lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">我们可以通过比较数据集中的实际值和预测值来检查模型的准确性。</p><figure class="ou ov ow ox gt iv gh gi paragraph-image"><div class="gh gi qs"><img src="../Images/b88cd1b87694535125513d50609c48f0.png" data-original-src="https://miro.medium.com/v2/resize:fit:1220/format:webp/0*4aHG4t9NkbJGTuen.png"/></div><figcaption class="jc jd gj gh gi je jf bd b be z dk translated">来源:图片由作者创作。</figcaption></figure><p id="ff20" class="pw-post-body-paragraph lh li jj lj b lk ll kt lm ln lo kw lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">将所有这些放在一起:</p><pre class="ou ov ow ox gt qt qu qv qw aw qx bi"><span id="d1b6" class="pi mt jj qu b gy qy qz l ra rb"># Import required libraries:<br/>import pandas as pd<br/>import numpy as np<br/>import matplotlib.pyplot as plt<br/>from sklearn import linear_model</span><span id="d26a" class="pi mt jj qu b gy rc qz l ra rb"># Read the CSV file :<br/>data = pd.read_csv(“Fuel.csv”)<br/>data.head()</span><span id="6656" class="pi mt jj qu b gy rc qz l ra rb"># Let’s select some features to explore more :<br/>data = data[[“ENGINESIZE”,”CO2EMISSIONS”]]</span><span id="0ad5" class="pi mt jj qu b gy rc qz l ra rb"># ENGINESIZE vs CO2EMISSIONS:<br/>plt.scatter(data[“ENGINESIZE”] , data[“CO2EMISSIONS”] , color=”blue”)<br/>plt.xlabel(“ENGINESIZE”)<br/>plt.ylabel(“CO2EMISSIONS”)<br/>plt.show()</span><span id="993d" class="pi mt jj qu b gy rc qz l ra rb"># Generating training and testing data from our data:<br/># We are using 80% data for training.<br/>train = data[:(int((len(data)*0.8)))]<br/>test = data[(int((len(data)*0.8))):]</span><span id="7006" class="pi mt jj qu b gy rc qz l ra rb"># Modeling:<br/># Using sklearn package to model data :<br/>regr = linear_model.LinearRegression()<br/>train_x = np.array(train[[“ENGINESIZE”]])<br/>train_y = np.array(train[[“CO2EMISSIONS”]])<br/>regr.fit(train_x,train_y)</span><span id="5d9a" class="pi mt jj qu b gy rc qz l ra rb"># The coefficients:<br/>print (“coefficients : “,regr.coef_) #Slope<br/>print (“Intercept : “,regr.intercept_) #Intercept</span><span id="7a33" class="pi mt jj qu b gy rc qz l ra rb"># Plotting the regression line:<br/>plt.scatter(train[“ENGINESIZE”], train[“CO2EMISSIONS”], color=’blue’)<br/>plt.plot(train_x, regr.coef_*train_x + regr.intercept_, ‘-r’)<br/>plt.xlabel(“Engine size”)<br/>plt.ylabel(“Emission”)</span><span id="1267" class="pi mt jj qu b gy rc qz l ra rb"># Predicting values:<br/># Function for predicting future values :<br/>def get_regression_predictions(input_features,intercept,slope):<br/> predicted_values = input_features*slope + intercept<br/> return predicted_values</span><span id="f092" class="pi mt jj qu b gy rc qz l ra rb"># Predicting emission for future car:<br/>my_engine_size = 3.5<br/>estimatd_emission = get_regression_predictions(my_engine_size,regr.intercept_[0],regr.coef_[0][0])<br/>print (“Estimated Emission :”,estimatd_emission)</span><span id="6568" class="pi mt jj qu b gy rc qz l ra rb"># Checking various accuracy:<br/>from sklearn.metrics import r2_score<br/>test_x = np.array(test[[‘ENGINESIZE’]])<br/>test_y = np.array(test[[‘CO2EMISSIONS’]])<br/>test_y_ = regr.predict(test_x)</span><span id="8c97" class="pi mt jj qu b gy rc qz l ra rb">print(“Mean absolute error: %.2f” % np.mean(np.absolute(test_y_ — test_y)))<br/>print(“Mean sum of squares (MSE): %.2f” % np.mean((test_y_ — test_y) ** 2))<br/>print(“R2-score: %.2f” % r2_score(test_y_ , test_y) )</span></pre><p id="207a" class="pw-post-body-paragraph lh li jj lj b lk ll kt lm ln lo kw lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated"><strong class="lj jt">在Google Colab上发布:</strong></p><div class="is it gp gr iu md"><a href="https://colab.research.google.com/drive/1CdiInssgUbBJ9GB2D4n_RSsuAjhsNTkk?usp=sharing" rel="noopener  ugc nofollow" target="_blank"><div class="me ab fo"><div class="mf ab mg cl cj mh"><h2 class="bd jt gy z fp mi fr fs mj fu fw js bi translated">谷歌联合实验室</h2><div class="mk l"><h3 class="bd b gy z fp mi fr fs mj fu fw dk translated">线性回归示例—https://towardsai.net/machine-learning-algorithms</h3></div><div class="ml l"><p class="bd b dl z fp mi fr fs mj fu fw dk translated">colab.research.google.com</p></div></div><div class="mm l"><div class="rd l mo mp mq mm mr ja md"/></div></div></a></div></div><div class="ab cl oa ob hx oc" role="separator"><span class="od bw bk oe of og"/><span class="od bw bk oe of og"/><span class="od bw bk oe of"/></div><div class="im in io ip iq"><h2 id="af64" class="pi mt jj bd mu pj pk dn my pl pm dp nc lq pn po ne lu pp pq ng ly pr ps ni jp bi translated">1.2多变量线性回归:</h2><p id="cd35" class="pw-post-body-paragraph lh li jj lj b lk nm kt lm ln nn kw lp lq pt ls lt lu pu lw lx ly pv ma mb mc im bi translated">在简单线性回归中，我们只能考虑一个输入要素来预测输出要素的值。然而，在多变量线性回归中，我们可以基于多个输入特征来预测输出。这是多元线性回归的公式。</p><figure class="ou ov ow ox gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi re"><img src="../Images/82d65516cc40e41ead9e4c21ca66ef1d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1198/format:webp/0*vBi83LjeAoOAM2Wb.png"/></div></div><figcaption class="jc jd gj gh gi je jf bd b be z dk translated">多元线性回归方程|来源:图片由作者创作。</figcaption></figure><h2 id="194a" class="pi mt jj bd mu pj pk dn my pl pm dp nc lq pn po ne lu pp pq ng ly pr ps ni jp bi translated">Python中的分步实现:</h2><p id="d341" class="pw-post-body-paragraph lh li jj lj b lk nm kt lm ln nn kw lp lq pt ls lt lu pu lw lx ly pv ma mb mc im bi translated"><strong class="lj jt"> a .导入所需的库:</strong></p><figure class="ou ov ow ox gt iv gh gi paragraph-image"><div class="gh gi rf"><img src="../Images/4ddab48dd62c3e56396de83663ffd558.png" data-original-src="https://miro.medium.com/v2/resize:fit:578/format:webp/0*DZiUNH0MLT9rmjMo.png"/></div><figcaption class="jc jd gj gh gi je jf bd b be z dk translated">来源:图片由作者创作。</figcaption></figure><p id="3265" class="pw-post-body-paragraph lh li jj lj b lk ll kt lm ln lo kw lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated"><strong class="lj jt"> b .读取CSV文件:</strong></p><figure class="ou ov ow ox gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi rg"><img src="../Images/15584b5629f46ba9279426f448f3602e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*FZd4cvyp2-mwB1wF.png"/></div></div><figcaption class="jc jd gj gh gi je jf bd b be z dk translated">来源:图片由作者创作。</figcaption></figure><p id="a8f5" class="pw-post-body-paragraph lh li jj lj b lk ll kt lm ln lo kw lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated"><strong class="lj jt"> c .定义X和Y: </strong></p><p id="63a3" class="pw-post-body-paragraph lh li jj lj b lk ll kt lm ln lo kw lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">x存储我们要考虑的输入特性，Y存储输出的值。</p><figure class="ou ov ow ox gt iv gh gi paragraph-image"><div class="gh gi rh"><img src="../Images/d3ba2f86da87c0be2121e83fde7834f6.png" data-original-src="https://miro.medium.com/v2/resize:fit:1358/format:webp/0*367uNujw-dDcMJsx.png"/></div><figcaption class="jc jd gj gh gi je jf bd b be z dk translated">来源:图片由作者创作。</figcaption></figure><p id="6266" class="pw-post-body-paragraph lh li jj lj b lk ll kt lm ln lo kw lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated"><strong class="lj jt"> d .将数据分成测试和训练数据集:</strong></p><p id="c7cb" class="pw-post-body-paragraph lh li jj lj b lk ll kt lm ln lo kw lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">在这里，我们将80%的数据用于训练，20%的数据用于测试。</p><figure class="ou ov ow ox gt iv gh gi paragraph-image"><div class="gh gi ri"><img src="../Images/ad407c82cfa33a40f47c3c09bd145ab7.png" data-original-src="https://miro.medium.com/v2/resize:fit:894/format:webp/0*6N5edEe5nsuLgcq1.png"/></div><figcaption class="jc jd gj gh gi je jf bd b be z dk translated">来源:图片由作者创作。</figcaption></figure><p id="5d21" class="pw-post-body-paragraph lh li jj lj b lk ll kt lm ln lo kw lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated"><strong class="lj jt"> e .训练我们的模型:</strong></p><p id="d279" class="pw-post-body-paragraph lh li jj lj b lk ll kt lm ln lo kw lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">这里我们要用80%的数据来训练我们的模型。</p><figure class="ou ov ow ox gt iv gh gi paragraph-image"><div class="gh gi rj"><img src="../Images/e8761016393a6ec45ae52b2c9cf1101f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1356/format:webp/0*fI_KpTIrR19QKHbd.png"/></div><figcaption class="jc jd gj gh gi je jf bd b be z dk translated">来源:图片由作者创作。</figcaption></figure><p id="b0a2" class="pw-post-body-paragraph lh li jj lj b lk ll kt lm ln lo kw lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated"><strong class="lj jt"> f .求输入特征的系数:</strong></p><p id="a1d4" class="pw-post-body-paragraph lh li jj lj b lk ll kt lm ln lo kw lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">现在我们需要知道哪个特性对输出变量的影响更大。为此，我们将打印系数值。请注意，负系数意味着它对输出有相反的影响。即，如果该特征的值增加，则输出值减少。</p><figure class="ou ov ow ox gt iv gh gi paragraph-image"><div class="gh gi rk"><img src="../Images/e804b63a593694e002e75c7abb7b2914.png" data-original-src="https://miro.medium.com/v2/resize:fit:1230/format:webp/0*Px614EnO8JswTSUs.png"/></div><figcaption class="jc jd gj gh gi je jf bd b be z dk translated">来源:图片由作者创作。</figcaption></figure><p id="3dc0" class="pw-post-body-paragraph lh li jj lj b lk ll kt lm ln lo kw lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated"><strong class="lj jt"> g .预测值:</strong></p><figure class="ou ov ow ox gt iv gh gi paragraph-image"><div class="gh gi rl"><img src="../Images/c030a60bab758a1865e2fae794af9190.png" data-original-src="https://miro.medium.com/v2/resize:fit:624/format:webp/0*9IZiwMID4lMa6J_V.png"/></div><figcaption class="jc jd gj gh gi je jf bd b be z dk translated">来源:图片由作者创作。</figcaption></figure><p id="4047" class="pw-post-body-paragraph lh li jj lj b lk ll kt lm ln lo kw lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated"><strong class="lj jt"> h .模型的精度:</strong></p><figure class="ou ov ow ox gt iv gh gi paragraph-image"><div class="gh gi rm"><img src="../Images/edbfec9048ff7ea5efae4c08013c6443.png" data-original-src="https://miro.medium.com/v2/resize:fit:628/format:webp/0*_pxtuIxVeuspCwk9.png"/></div><figcaption class="jc jd gj gh gi je jf bd b be z dk translated">来源:图片由作者创作。</figcaption></figure><p id="fc04" class="pw-post-body-paragraph lh li jj lj b lk ll kt lm ln lo kw lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">现在请注意，这里我们对简单和多变量线性回归使用了相同的数据集。我们可以注意到，多元线性回归的精度远远好于简单线性回归的精度。</p><p id="a922" class="pw-post-body-paragraph lh li jj lj b lk ll kt lm ln lo kw lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">将所有这些放在一起:</p><pre class="ou ov ow ox gt qt qu qv qw aw qx bi"><span id="8f39" class="pi mt jj qu b gy qy qz l ra rb"># Import the required libraries:<br/>import pandas as pd<br/>import numpy as np<br/>import matplotlib.pyplot as plt<br/>from sklearn import linear_model</span><span id="c08e" class="pi mt jj qu b gy rc qz l ra rb"># Read the CSV file:<br/>data = pd.read_csv(“Fuel.csv”)<br/>data.head()</span><span id="3e6f" class="pi mt jj qu b gy rc qz l ra rb"># Consider features we want to work on:<br/>X = data[[ ‘ENGINESIZE’, ‘CYLINDERS’, ‘FUELCONSUMPTION_CITY’,’FUELCONSUMPTION_HWY’, <br/> ‘FUELCONSUMPTION_COMB’,’FUELCONSUMPTION_COMB_MPG’]]</span><span id="1ca8" class="pi mt jj qu b gy rc qz l ra rb">Y = data[“CO2EMISSIONS”]</span><span id="9785" class="pi mt jj qu b gy rc qz l ra rb"># Generating training and testing data from our data:<br/># We are using 80% data for training.<br/>train = data[:(int((len(data)*0.8)))]<br/>test = data[(int((len(data)*0.8))):]</span><span id="fa9b" class="pi mt jj qu b gy rc qz l ra rb">#Modeling:<br/>#Using sklearn package to model data :<br/>regr = linear_model.LinearRegression()</span><span id="bee3" class="pi mt jj qu b gy rc qz l ra rb">train_x = np.array(train[[ ‘ENGINESIZE’, ‘CYLINDERS’, ‘FUELCONSUMPTION_CITY’,<br/> ‘FUELCONSUMPTION_HWY’, ‘FUELCONSUMPTION_COMB’,’FUELCONSUMPTION_COMB_MPG’]])<br/>train_y = np.array(train[“CO2EMISSIONS”])</span><span id="ffed" class="pi mt jj qu b gy rc qz l ra rb">regr.fit(train_x,train_y)</span><span id="cf2d" class="pi mt jj qu b gy rc qz l ra rb">test_x = np.array(test[[ ‘ENGINESIZE’, ‘CYLINDERS’, ‘FUELCONSUMPTION_CITY’,<br/> ‘FUELCONSUMPTION_HWY’, ‘FUELCONSUMPTION_COMB’,’FUELCONSUMPTION_COMB_MPG’]])<br/>test_y = np.array(test[“CO2EMISSIONS”])</span><span id="bca1" class="pi mt jj qu b gy rc qz l ra rb"># print the coefficient values:<br/>coeff_data = pd.DataFrame(regr.coef_ , X.columns , columns=[“Coefficients”])<br/>coeff_data</span><span id="7c07" class="pi mt jj qu b gy rc qz l ra rb">#Now let’s do prediction of data:<br/>Y_pred = regr.predict(test_x)</span><span id="264d" class="pi mt jj qu b gy rc qz l ra rb"># Check accuracy:<br/>from sklearn.metrics import r2_score<br/>R = r2_score(test_y , Y_pred)<br/>print (“R² :”,R)</span></pre><p id="30ce" class="pw-post-body-paragraph lh li jj lj b lk ll kt lm ln lo kw lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated"><strong class="lj jt">在Google Colab上发布:</strong></p><div class="is it gp gr iu md"><a href="https://colab.research.google.com/drive/1CdiInssgUbBJ9GB2D4n_RSsuAjhsNTkk#scrollTo=sTVcjiI_AX2X&amp;line=1&amp;uniqifier=1" rel="noopener  ugc nofollow" target="_blank"><div class="me ab fo"><div class="mf ab mg cl cj mh"><h2 class="bd jt gy z fp mi fr fs mj fu fw js bi translated">谷歌联合实验室</h2><div class="mk l"><h3 class="bd b gy z fp mi fr fs mj fu fw dk translated">多变量线性回归—https://towardsai.net/machine-learning-algorithms</h3></div><div class="ml l"><p class="bd b dl z fp mi fr fs mj fu fw dk translated">colab.research.google.com</p></div></div><div class="mm l"><div class="rn l mo mp mq mm mr ja md"/></div></div></a></div></div><div class="ab cl oa ob hx oc" role="separator"><span class="od bw bk oe of og"/><span class="od bw bk oe of og"/><span class="od bw bk oe of"/></div><div class="im in io ip iq"><h2 id="d9f2" class="pi mt jj bd mu pj pk dn my pl pm dp nc lq pn po ne lu pp pq ng ly pr ps ni jp bi translated">1.3多项式回归:</h2><figure class="ou ov ow ox gt iv gh gi paragraph-image"><div class="gh gi ro"><img src="../Images/35eb24e9b51a1553ab4811c22ae0c4f2.png" data-original-src="https://miro.medium.com/v2/resize:fit:1250/format:webp/0*bsK1T7rIFUmugzdl.png"/></div><figcaption class="jc jd gj gh gi je jf bd b be z dk translated">来源:图片由作者创作。</figcaption></figure><p id="7119" class="pw-post-body-paragraph lh li jj lj b lk ll kt lm ln lo kw lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">有时我们的数据不仅仅遵循线性趋势。我们有时有遵循多项式趋势的数据。因此，我们将使用多项式回归。</p><p id="3276" class="pw-post-body-paragraph lh li jj lj b lk ll kt lm ln lo kw lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">在深入研究它的实现之前，我们需要知道一些主要多项式数据的图形是什么样子的。</p><h2 id="5ee9" class="pi mt jj bd mu pj pk dn my pl pm dp nc lq pn po ne lu pp pq ng ly pr ps ni jp bi translated">多项式函数及其图形；</h2><p id="a74b" class="pw-post-body-paragraph lh li jj lj b lk nm kt lm ln nn kw lp lq pt ls lt lu pu lw lx ly pv ma mb mc im bi translated">a.图为<strong class="lj jt"> Y=X </strong>:</p><figure class="ou ov ow ox gt iv gh gi paragraph-image"><div class="gh gi rp"><img src="../Images/3e64748c74e46eb90a6bf849d8646956.png" data-original-src="https://miro.medium.com/v2/resize:fit:924/format:webp/0*P0nnXbpjhzHt5wOk.png"/></div><figcaption class="jc jd gj gh gi je jf bd b be z dk translated">来源:图片由作者创作。</figcaption></figure><p id="62d9" class="pw-post-body-paragraph lh li jj lj b lk ll kt lm ln lo kw lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">b.图形为<strong class="lj jt"> Y = X </strong>:</p><figure class="ou ov ow ox gt iv gh gi paragraph-image"><div class="gh gi rq"><img src="../Images/fb01ac1adf8f864e1080d7c3d12d7be3.png" data-original-src="https://miro.medium.com/v2/resize:fit:892/format:webp/0*9aNRafm-0-NT8XEl.png"/></div><figcaption class="jc jd gj gh gi je jf bd b be z dk translated">来源:图片由作者创作。</figcaption></figure><p id="b2c8" class="pw-post-body-paragraph lh li jj lj b lk ll kt lm ln lo kw lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">c.图形为<strong class="lj jt"> Y = X </strong>:</p><figure class="ou ov ow ox gt iv gh gi paragraph-image"><div class="gh gi rr"><img src="../Images/2ac763b2312c7e7bd2fbc8586cca9fe0.png" data-original-src="https://miro.medium.com/v2/resize:fit:890/format:webp/0*kqOFG6q9Yfpps6vZ.png"/></div><figcaption class="jc jd gj gh gi je jf bd b be z dk translated">来源:图片由作者创作。</figcaption></figure><p id="849b" class="pw-post-body-paragraph lh li jj lj b lk ll kt lm ln lo kw lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">d.具有多个多项式的图:<strong class="lj jt"> Y = X +X +X </strong>:</p><figure class="ou ov ow ox gt iv gh gi paragraph-image"><div class="gh gi rs"><img src="../Images/a637bb8be14470da3be51b8a6fe8c46a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1052/format:webp/0*mknUaVeCP2kmuYvp.png"/></div><figcaption class="jc jd gj gh gi je jf bd b be z dk translated">来源:图片由作者创作。</figcaption></figure><p id="da68" class="pw-post-body-paragraph lh li jj lj b lk ll kt lm ln lo kw lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">在上图中，我们可以看到红点显示的是Y=X +X +X的图形，蓝点显示的是Y=X的图形。在这里，我们可以看到最显著的幂影响了我们图形的形状。</p><p id="8013" class="pw-post-body-paragraph lh li jj lj b lk ll kt lm ln lo kw lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated"><strong class="lj jt">下面是多项式回归的公式:</strong></p><figure class="ou ov ow ox gt iv gh gi paragraph-image"><div class="gh gi rt"><img src="../Images/745c09c84c3e80a119b6a0758d525269.png" data-original-src="https://miro.medium.com/v2/resize:fit:1176/format:webp/0*XhbRe7N9Qv2Nh4Ue.png"/></div><figcaption class="jc jd gj gh gi je jf bd b be z dk translated">多项式回归的公式|来源:图片由作者创作。</figcaption></figure><p id="93d4" class="pw-post-body-paragraph lh li jj lj b lk ll kt lm ln lo kw lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">在之前的回归模型中，我们使用sci-kit学习库来实现。在这里，我们将使用正规方程来实现它。这里请注意，我们也可以使用scikit-learn来实现多项式回归，但是另一种方法将让我们了解它是如何工作的。</p><p id="38d1" class="pw-post-body-paragraph lh li jj lj b lk ll kt lm ln lo kw lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">等式如下:</p><figure class="ou ov ow ox gt iv gh gi paragraph-image"><div class="gh gi ru"><img src="../Images/d68b0c0108412d00b5c86184d00897be.png" data-original-src="https://miro.medium.com/v2/resize:fit:506/format:webp/0*u31TKpg-u14Lvchn.png"/></div><figcaption class="jc jd gj gh gi je jf bd b be z dk translated">来源:图片由作者创作。</figcaption></figure><p id="59a9" class="pw-post-body-paragraph lh li jj lj b lk ll kt lm ln lo kw lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">在上面的等式中:</p><p id="8076" class="pw-post-body-paragraph lh li jj lj b lk ll kt lm ln lo kw lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">θ:最佳定义的假设参数。</p><p id="b519" class="pw-post-body-paragraph lh li jj lj b lk ll kt lm ln lo kw lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">x:输入每个实例的特征值。</p><p id="3f56" class="pw-post-body-paragraph lh li jj lj b lk ll kt lm ln lo kw lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">y:每个实例的输出值。</p><h2 id="b1ca" class="pi mt jj bd mu pj pk dn my pl pm dp nc lq pn po ne lu pp pq ng ly pr ps ni jp bi translated">1.3.1多项式回归的假设函数</h2><figure class="ou ov ow ox gt iv gh gi paragraph-image"><div class="gh gi rv"><img src="../Images/f66bf0b1eb839b51d4ca9ee81483c27b.png" data-original-src="https://miro.medium.com/v2/resize:fit:800/format:webp/0*INKlgIx8IsHh9LNW.png"/></div><figcaption class="jc jd gj gh gi je jf bd b be z dk translated">来源:图片由作者创作。</figcaption></figure><p id="a439" class="pw-post-body-paragraph lh li jj lj b lk ll kt lm ln lo kw lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">标准方程中的主矩阵:</p><figure class="ou ov ow ox gt iv gh gi paragraph-image"><div class="gh gi rw"><img src="../Images/d9912d5e1244723409a70e0438080bf0.png" data-original-src="https://miro.medium.com/v2/resize:fit:668/format:webp/0*ALEhjHXrBYZpMjs8.png"/></div><figcaption class="jc jd gj gh gi je jf bd b be z dk translated">来源:图片由作者创作。</figcaption></figure><h2 id="db90" class="pi mt jj bd mu pj pk dn my pl pm dp nc lq pn po ne lu pp pq ng ly pr ps ni jp bi translated"><strong class="ak">用Python一步步实现:</strong></h2><p id="fdea" class="pw-post-body-paragraph lh li jj lj b lk nm kt lm ln nn kw lp lq pt ls lt lu pu lw lx ly pv ma mb mc im bi translated"><strong class="lj jt"> a .导入所需的库:</strong></p><figure class="ou ov ow ox gt iv gh gi paragraph-image"><div class="gh gi rf"><img src="../Images/9d343c7159a0a25d926366fb56174755.png" data-original-src="https://miro.medium.com/v2/resize:fit:578/format:webp/0*972PhzQzsnjhljUh.png"/></div><figcaption class="jc jd gj gh gi je jf bd b be z dk translated">来源:图片由作者创作。</figcaption></figure><p id="bd0d" class="pw-post-body-paragraph lh li jj lj b lk ll kt lm ln lo kw lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated"><strong class="lj jt"> b .生成数据点:</strong></p><p id="5529" class="pw-post-body-paragraph lh li jj lj b lk ll kt lm ln lo kw lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">我们将生成一个数据集来实现我们的多项式回归。</p><figure class="ou ov ow ox gt iv gh gi paragraph-image"><div class="gh gi rx"><img src="../Images/0e3876d5a0d47d58ec0f9a74e2a80bdd.png" data-original-src="https://miro.medium.com/v2/resize:fit:944/format:webp/0*o4nNKh7K2CbY0jDH.png"/></div><figcaption class="jc jd gj gh gi je jf bd b be z dk translated">来源:图片由作者创作。</figcaption></figure><p id="511b" class="pw-post-body-paragraph lh li jj lj b lk ll kt lm ln lo kw lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated"><strong class="lj jt"> c .初始化x，x，x向量:</strong></p><p id="0c31" class="pw-post-body-paragraph lh li jj lj b lk ll kt lm ln lo kw lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">我们取x的最大幂为3。所以我们的X矩阵会有X，X，X。</p><figure class="ou ov ow ox gt iv gh gi paragraph-image"><div class="gh gi ry"><img src="../Images/25f5da73993be56901ee879bb2af3f8c.png" data-original-src="https://miro.medium.com/v2/resize:fit:382/format:webp/0*xWnEc_djrN7Vhm6-.png"/></div><figcaption class="jc jd gj gh gi je jf bd b be z dk translated">来源:图片由作者创作。</figcaption></figure><p id="9159" class="pw-post-body-paragraph lh li jj lj b lk ll kt lm ln lo kw lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated"><strong class="lj jt">d . X矩阵的第1列:</strong></p><p id="7783" class="pw-post-body-paragraph lh li jj lj b lk ll kt lm ln lo kw lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">主矩阵X的第一列将总是1，因为它保存β_ 0的系数。</p><figure class="ou ov ow ox gt iv gh gi paragraph-image"><div class="gh gi rz"><img src="../Images/b33d7c260c6e17442229ea8d66a3603e.png" data-original-src="https://miro.medium.com/v2/resize:fit:454/format:webp/0*GIsucZ5MyDCRgZla.png"/></div><figcaption class="jc jd gj gh gi je jf bd b be z dk translated">来源:图片由作者创作。</figcaption></figure><p id="e846" class="pw-post-body-paragraph lh li jj lj b lk ll kt lm ln lo kw lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated"><strong class="lj jt"> e .形成完整的x矩阵:</strong></p><p id="c23b" class="pw-post-body-paragraph lh li jj lj b lk ll kt lm ln lo kw lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">请看这个实现开始时的矩阵X。我们将通过添加向量来创建它。</p><figure class="ou ov ow ox gt iv gh gi paragraph-image"><div class="gh gi sa"><img src="../Images/3a3d029aa0ef6474238c5944c2d4e89b.png" data-original-src="https://miro.medium.com/v2/resize:fit:644/format:webp/0*jTweXawKn-lvWFaB.png"/></div><figcaption class="jc jd gj gh gi je jf bd b be z dk translated">来源:图片由作者创作。</figcaption></figure><p id="aad1" class="pw-post-body-paragraph lh li jj lj b lk ll kt lm ln lo kw lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated"><strong class="lj jt"> f .矩阵的转置:</strong></p><p id="86c2" class="pw-post-body-paragraph lh li jj lj b lk ll kt lm ln lo kw lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">我们将逐步计算θ的值。首先，我们需要找到矩阵的转置。</p><figure class="ou ov ow ox gt iv gh gi paragraph-image"><div class="gh gi sb"><img src="../Images/7b1b22226cd3595689bc9bd7bd9f19cd.png" data-original-src="https://miro.medium.com/v2/resize:fit:678/format:webp/0*_u-XiM-zwDWuo4Sd.png"/></div><figcaption class="jc jd gj gh gi je jf bd b be z dk translated">来源:图片由作者创作。</figcaption></figure><p id="366d" class="pw-post-body-paragraph lh li jj lj b lk ll kt lm ln lo kw lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated"><strong class="lj jt"> g .矩阵乘法:</strong></p><p id="ae73" class="pw-post-body-paragraph lh li jj lj b lk ll kt lm ln lo kw lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">找到转置后，我们需要将其与原矩阵相乘。请记住，我们要用一个正规方程来实现它，所以我们必须遵循它的规则。</p><figure class="ou ov ow ox gt iv gh gi paragraph-image"><div class="gh gi sc"><img src="../Images/062c9b593328cf6a12e768270efaa6d3.png" data-original-src="https://miro.medium.com/v2/resize:fit:940/format:webp/0*kXvrSxcspP4ljoo4.png"/></div><figcaption class="jc jd gj gh gi je jf bd b be z dk translated">来源:图片由作者创作。</figcaption></figure><p id="a9a9" class="pw-post-body-paragraph lh li jj lj b lk ll kt lm ln lo kw lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated"><strong class="lj jt"> h .矩阵的逆:</strong></p><p id="1537" class="pw-post-body-paragraph lh li jj lj b lk ll kt lm ln lo kw lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">寻找矩阵的逆矩阵并将其存储在<strong class="lj jt"> temp1 </strong>中。</p><figure class="ou ov ow ox gt iv gh gi paragraph-image"><div class="gh gi sd"><img src="../Images/3cbafa0dca4206bb883e31ab8b8910d5.png" data-original-src="https://miro.medium.com/v2/resize:fit:808/format:webp/0*DbuoHlNbKB5BsyVN.png"/></div><figcaption class="jc jd gj gh gi je jf bd b be z dk translated">来源:图片由作者创作。</figcaption></figure><p id="baf7" class="pw-post-body-paragraph lh li jj lj b lk ll kt lm ln lo kw lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated"><strong class="lj jt">一、矩阵乘法:</strong></p><p id="8580" class="pw-post-body-paragraph lh li jj lj b lk ll kt lm ln lo kw lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">找到转置的X和Y向量的乘积，并将其存储在temp2变量中。</p><figure class="ou ov ow ox gt iv gh gi paragraph-image"><div class="gh gi se"><img src="../Images/2d5afbe75c54bd2c7ee58adebfcaded6.png" data-original-src="https://miro.medium.com/v2/resize:fit:798/format:webp/0*p4o2_z4763y80x8d.png"/></div><figcaption class="jc jd gj gh gi je jf bd b be z dk translated">来源:图片由作者创作。</figcaption></figure><p id="799d" class="pw-post-body-paragraph lh li jj lj b lk ll kt lm ln lo kw lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated"><strong class="lj jt"> j .系数值:</strong></p><p id="c9bb" class="pw-post-body-paragraph lh li jj lj b lk ll kt lm ln lo kw lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">要计算系数值，我们需要将temp1和temp2相乘。见正规方程公式。</p><figure class="ou ov ow ox gt iv gh gi paragraph-image"><div class="gh gi sf"><img src="../Images/033814fee585e542a08e932414411f74.png" data-original-src="https://miro.medium.com/v2/resize:fit:962/format:webp/0*acxp644eDoc5nZsi.png"/></div><figcaption class="jc jd gj gh gi je jf bd b be z dk translated">来源:图片由作者创作。</figcaption></figure><p id="c7e7" class="pw-post-body-paragraph lh li jj lj b lk ll kt lm ln lo kw lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated"><strong class="lj jt"> k .将系数存储在变量中:</strong></p><p id="603c" class="pw-post-body-paragraph lh li jj lj b lk ll kt lm ln lo kw lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">将这些系数值存储在不同的变量中。</p><figure class="ou ov ow ox gt iv gh gi paragraph-image"><div class="gh gi sg"><img src="../Images/5b5bc66d80dc3eaf61d108b8403a92bd.png" data-original-src="https://miro.medium.com/v2/resize:fit:384/format:webp/0*Hm5-ZP7DlZHpVIeY.png"/></div><figcaption class="jc jd gj gh gi je jf bd b be z dk translated">来源:图片由作者创作。</figcaption></figure><p id="8954" class="pw-post-body-paragraph lh li jj lj b lk ll kt lm ln lo kw lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated"><strong class="lj jt"> l .用曲线绘制数据:</strong></p><p id="63b2" class="pw-post-body-paragraph lh li jj lj b lk ll kt lm ln lo kw lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">用回归曲线绘制数据。</p><figure class="ou ov ow ox gt iv gh gi paragraph-image"><div class="gh gi sh"><img src="../Images/e2eb8dc34288627f53824eacb83e33ec.png" data-original-src="https://miro.medium.com/v2/resize:fit:1034/format:webp/0*LcAilYJJblH5mF3M.png"/></div><figcaption class="jc jd gj gh gi je jf bd b be z dk translated">来源:图片由作者创作。</figcaption></figure><p id="da99" class="pw-post-body-paragraph lh li jj lj b lk ll kt lm ln lo kw lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated"><strong class="lj jt"> m .预测功能:</strong></p><p id="cea0" class="pw-post-body-paragraph lh li jj lj b lk ll kt lm ln lo kw lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">现在我们将使用回归曲线来预测输出。</p><figure class="ou ov ow ox gt iv gh gi paragraph-image"><div class="gh gi si"><img src="../Images/c0c710a80e21795ca085642903921514.png" data-original-src="https://miro.medium.com/v2/resize:fit:934/format:webp/0*x2Mg0p7qL0-qehGK.png"/></div><figcaption class="jc jd gj gh gi je jf bd b be z dk translated">来源:图片由作者创作。</figcaption></figure><p id="ab08" class="pw-post-body-paragraph lh li jj lj b lk ll kt lm ln lo kw lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated"><strong class="lj jt"> n .误差函数:</strong></p><p id="df3e" class="pw-post-body-paragraph lh li jj lj b lk ll kt lm ln lo kw lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">使用均方误差函数计算误差。</p><figure class="ou ov ow ox gt iv gh gi paragraph-image"><div class="gh gi sj"><img src="../Images/e901b39270a24b813ddc5a3cf828ff9c.png" data-original-src="https://miro.medium.com/v2/resize:fit:600/format:webp/0*O9rFgzUawcM5TN9Y.png"/></div><figcaption class="jc jd gj gh gi je jf bd b be z dk translated">来源:图片由作者创作。</figcaption></figure><p id="f229" class="pw-post-body-paragraph lh li jj lj b lk ll kt lm ln lo kw lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated"><strong class="lj jt"> o .计算误差:</strong></p><figure class="ou ov ow ox gt iv gh gi paragraph-image"><div class="gh gi sk"><img src="../Images/ee69e2a4b8c36db56b06db510e8870dd.png" data-original-src="https://miro.medium.com/v2/resize:fit:402/format:webp/0*9itcujUOgFVuZ79E.png"/></div><figcaption class="jc jd gj gh gi je jf bd b be z dk translated">来源:图片由作者创作。</figcaption></figure><p id="86e0" class="pw-post-body-paragraph lh li jj lj b lk ll kt lm ln lo kw lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">将所有这些放在一起:</p><pre class="ou ov ow ox gt qt qu qv qw aw qx bi"><span id="4678" class="pi mt jj qu b gy qy qz l ra rb"># Import required libraries:<br/>import numpy as np<br/>import matplotlib.pyplot as plt</span><span id="c233" class="pi mt jj qu b gy rc qz l ra rb"># Generate datapoints:<br/>x = np.arange(-5,5,0.1)<br/>y_noise = 20 * np.random.normal(size = len(x))<br/>y = 1*(x**3) + 1*(x**2) + 1*x + 3+y_noise<br/>plt.scatter(x,y)</span><span id="9b78" class="pi mt jj qu b gy rc qz l ra rb"># Make polynomial data:<br/>x1 = x<br/>x2 = np.power(x1,2)<br/>x3 = np.power(x1,3)</span><span id="c82b" class="pi mt jj qu b gy rc qz l ra rb"># Reshaping data:<br/>x1_new = np.reshape(x1,(n,1))<br/>x2_new = np.reshape(x2,(n,1))<br/>x3_new = np.reshape(x3,(n,1))</span><span id="e005" class="pi mt jj qu b gy rc qz l ra rb"># First column of matrix X:<br/>x_bias = np.ones((n,1))</span><span id="2ee4" class="pi mt jj qu b gy rc qz l ra rb"># Form the complete x matrix:<br/>x_new = np.append(x_bias,x1_new,axis=1)<br/>x_new = np.append(x_new,x2_new,axis=1)<br/>x_new = np.append(x_new,x3_new,axis=1)</span><span id="d205" class="pi mt jj qu b gy rc qz l ra rb"># Finding transpose:<br/>x_new_transpose = np.transpose(x_new)</span><span id="6dc1" class="pi mt jj qu b gy rc qz l ra rb"># Finding dot product of original and transposed matrix :<br/>x_new_transpose_dot_x_new = x_new_transpose.dot(x_new)</span><span id="8589" class="pi mt jj qu b gy rc qz l ra rb"># Finding Inverse:<br/>temp_1 = np.linalg.inv(x_new_transpose_dot_x_new)# Finding the dot product of transposed x and y :<br/>temp_2 = x_new_transpose.dot(y)</span><span id="c9ee" class="pi mt jj qu b gy rc qz l ra rb"># Finding coefficients:<br/>theta = temp_1.dot(temp_2)<br/>theta</span><span id="2328" class="pi mt jj qu b gy rc qz l ra rb"># Store coefficient values in different variables:<br/>beta_0 = theta[0]<br/>beta_1 = theta[1]<br/>beta_2 = theta[2]<br/>beta_3 = theta[3]</span><span id="58cb" class="pi mt jj qu b gy rc qz l ra rb"># Plot the polynomial curve:<br/>plt.scatter(x,y)<br/>plt.plot(x,beta_0 + beta_1*x1 + beta_2*x2 + beta_3*x3,c=”red”)</span><span id="8687" class="pi mt jj qu b gy rc qz l ra rb"># Prediction function:<br/>def prediction(x1,x2,x3,beta_0,beta_1,beta_2,beta_3):<br/> y_pred = beta_0 + beta_1*x1 + beta_2*x2 + beta_3*x3<br/> return y_pred<br/> <br/># Making predictions:<br/>pred = prediction(x1,x2,x3,beta_0,beta_1,beta_2,beta_3)<br/> <br/># Calculate accuracy of model:<br/>def err(y_pred,y):<br/> var = (y — y_pred)<br/> var = var*var<br/> n = len(var)<br/> MSE = var.sum()<br/> MSE = MSE/n<br/> <br/> return MSE</span><span id="b73e" class="pi mt jj qu b gy rc qz l ra rb"># Calculating the error:<br/>error = err(pred,y)<br/>error</span></pre></div><div class="ab cl oa ob hx oc" role="separator"><span class="od bw bk oe of og"/><span class="od bw bk oe of og"/><span class="od bw bk oe of"/></div><div class="im in io ip iq"><p id="2a2c" class="pw-post-body-paragraph lh li jj lj b lk ll kt lm ln lo kw lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated"><strong class="lj jt">在Google Colab上发布:</strong></p><div class="is it gp gr iu md"><a href="https://colab.research.google.com/drive/1CdiInssgUbBJ9GB2D4n_RSsuAjhsNTkk#scrollTo=OnN44asuAo_m&amp;line=1&amp;uniqifier=1" rel="noopener  ugc nofollow" target="_blank"><div class="me ab fo"><div class="mf ab mg cl cj mh"><h2 class="bd jt gy z fp mi fr fs mj fu fw js bi translated">谷歌联合实验室</h2><div class="mk l"><h3 class="bd b gy z fp mi fr fs mj fu fw dk translated">多项式回归-https://towardsai.net/machine-learning-algorithms</h3></div><div class="ml l"><p class="bd b dl z fp mi fr fs mj fu fw dk translated">colab.research.google.com</p></div></div><div class="mm l"><div class="sl l mo mp mq mm mr ja md"/></div></div></a></div><h2 id="6166" class="pi mt jj bd mu pj pk dn my pl pm dp nc lq pn po ne lu pp pq ng ly pr ps ni jp bi translated">1.4指数回归:</h2><figure class="ou ov ow ox gt iv gh gi paragraph-image"><div class="gh gi sm"><img src="../Images/fce574f0cc3162760efa355e9fe37a15.png" data-original-src="https://miro.medium.com/v2/resize:fit:1270/format:webp/0*jdPo-a_l3ScgQcVQ.png"/></div><figcaption class="jc jd gj gh gi je jf bd b be z dk translated">来源:图片由作者创作。</figcaption></figure><p id="fd08" class="pw-post-body-paragraph lh li jj lj b lk ll kt lm ln lo kw lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated"><strong class="lj jt">指数增长的一些真实例子:</strong></p><p id="8255" class="pw-post-body-paragraph lh li jj lj b lk ll kt lm ln lo kw lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">1.培养中的微生物。</p><p id="2f48" class="pw-post-body-paragraph lh li jj lj b lk ll kt lm ln lo kw lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">2.食物变质。</p><p id="a48f" class="pw-post-body-paragraph lh li jj lj b lk ll kt lm ln lo kw lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">3.人类人口。</p><p id="bb85" class="pw-post-body-paragraph lh li jj lj b lk ll kt lm ln lo kw lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">4.复利。</p><p id="dd03" class="pw-post-body-paragraph lh li jj lj b lk ll kt lm ln lo kw lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">5.流行病(如新冠肺炎)。</p><p id="94bb" class="pw-post-body-paragraph lh li jj lj b lk ll kt lm ln lo kw lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">6.埃博拉疫情。</p><p id="07bc" class="pw-post-body-paragraph lh li jj lj b lk ll kt lm ln lo kw lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">7.入侵物种。</p><p id="339c" class="pw-post-body-paragraph lh li jj lj b lk ll kt lm ln lo kw lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">8.着火了。</p><p id="f9d3" class="pw-post-body-paragraph lh li jj lj b lk ll kt lm ln lo kw lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">9.癌细胞。</p><p id="f4b1" class="pw-post-body-paragraph lh li jj lj b lk ll kt lm ln lo kw lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">10.智能手机的使用和销售。</p><p id="64b2" class="pw-post-body-paragraph lh li jj lj b lk ll kt lm ln lo kw lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated"><strong class="lj jt">指数回归公式如下:</strong></p><figure class="ou ov ow ox gt iv gh gi paragraph-image"><div class="gh gi sn"><img src="../Images/c916065bd6ece3712e0a007cb545505d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1104/format:webp/0*-rx399GK7i6xWayW.png"/></div><figcaption class="jc jd gj gh gi je jf bd b be z dk translated">指数回归的公式|来源:图片由作者创作。</figcaption></figure><p id="2682" class="pw-post-body-paragraph lh li jj lj b lk ll kt lm ln lo kw lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">在这种情况下，我们将使用scikit-learn库来查找a、b、c等系数值。</p><h2 id="6a38" class="pi mt jj bd mu pj pk dn my pl pm dp nc lq pn po ne lu pp pq ng ly pr ps ni jp bi translated"><strong class="ak">用Python一步步实现</strong></h2><p id="ccee" class="pw-post-body-paragraph lh li jj lj b lk nm kt lm ln nn kw lp lq pt ls lt lu pu lw lx ly pv ma mb mc im bi translated"><strong class="lj jt"> a .导入所需库:</strong></p><figure class="ou ov ow ox gt iv gh gi paragraph-image"><div class="gh gi so"><img src="../Images/cac8ca9262b410203c74a339fc9930dd.png" data-original-src="https://miro.medium.com/v2/resize:fit:614/format:webp/0*Cb6fagmXipKf95yq.png"/></div><figcaption class="jc jd gj gh gi je jf bd b be z dk translated">来源:图片由作者创作。</figcaption></figure><p id="982a" class="pw-post-body-paragraph lh li jj lj b lk ll kt lm ln lo kw lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated"><strong class="lj jt"> b .插入数据点:</strong></p><figure class="ou ov ow ox gt iv gh gi paragraph-image"><div class="gh gi sp"><img src="../Images/121e1f765117ae314bf51cd940096abf.png" data-original-src="https://miro.medium.com/v2/resize:fit:880/format:webp/0*kbXwZPIEfY-1Usjr.png"/></div><figcaption class="jc jd gj gh gi je jf bd b be z dk translated">来源:图片由作者创作。</figcaption></figure><p id="4c02" class="pw-post-body-paragraph lh li jj lj b lk ll kt lm ln lo kw lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated"><strong class="lj jt"> c .实现指数函数算法:</strong></p><figure class="ou ov ow ox gt iv gh gi paragraph-image"><div class="gh gi sq"><img src="../Images/60d103c7e777e9799605445983be7361.png" data-original-src="https://miro.medium.com/v2/resize:fit:482/format:webp/0*OFufVhYViIKBWiIP.png"/></div><figcaption class="jc jd gj gh gi je jf bd b be z dk translated">来源:图片由作者创作。</figcaption></figure><p id="2404" class="pw-post-body-paragraph lh li jj lj b lk ll kt lm ln lo kw lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated"><strong class="lj jt"> d .应用最佳参数和协方差:</strong></p><p id="51da" class="pw-post-body-paragraph lh li jj lj b lk ll kt lm ln lo kw lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">这里我们使用curve_fit来寻找最佳的参数值。它返回两个变量，名为<strong class="lj jt"> popt，pcov。</strong></p><p id="7b91" class="pw-post-body-paragraph lh li jj lj b lk ll kt lm ln lo kw lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated"><strong class="lj jt"> popt </strong>存储最优参数的值，pcov存储其协方差的值。我们可以看到popt变量有两个值。这些值是我们的最佳参数。我们将使用这些参数并绘制最佳拟合曲线，如下所示。</p><figure class="ou ov ow ox gt iv gh gi paragraph-image"><div class="gh gi sr"><img src="../Images/a128f97f1b5a483b1843b6abe7e31d04.png" data-original-src="https://miro.medium.com/v2/resize:fit:804/format:webp/0*hKcku2LwGMCliXnZ.png"/></div><figcaption class="jc jd gj gh gi je jf bd b be z dk translated">来源:图片由作者创作。</figcaption></figure><p id="2050" class="pw-post-body-paragraph lh li jj lj b lk ll kt lm ln lo kw lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated"><strong class="lj jt"> e .绘制数据:</strong></p><p id="5a67" class="pw-post-body-paragraph lh li jj lj b lk ll kt lm ln lo kw lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">用找到的系数绘制数据。</p><figure class="ou ov ow ox gt iv gh gi paragraph-image"><div class="gh gi ss"><img src="../Images/cd001f7b221d67b5f1d19a0f5ae1e360.png" data-original-src="https://miro.medium.com/v2/resize:fit:946/format:webp/0*WKerQx69uAghadu9.png"/></div><figcaption class="jc jd gj gh gi je jf bd b be z dk translated">来源:图片由作者创作。</figcaption></figure><p id="0f28" class="pw-post-body-paragraph lh li jj lj b lk ll kt lm ln lo kw lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated"><strong class="lj jt"> f .检查模型的准确性:</strong></p><p id="f1ad" class="pw-post-body-paragraph lh li jj lj b lk ll kt lm ln lo kw lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">用<strong class="lj jt"> r2_score </strong>检查模型的准确性。</p><figure class="ou ov ow ox gt iv gh gi paragraph-image"><div class="gh gi st"><img src="../Images/dee5c7d472a2e15711a9458755164a3d.png" data-original-src="https://miro.medium.com/v2/resize:fit:750/format:webp/0*v1Zr9U1qkM9BbVT3.png"/></div><figcaption class="jc jd gj gh gi je jf bd b be z dk translated">来源:图片由作者创作。</figcaption></figure><p id="7363" class="pw-post-body-paragraph lh li jj lj b lk ll kt lm ln lo kw lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">将所有这些放在一起:</p><pre class="ou ov ow ox gt qt qu qv qw aw qx bi"><span id="db28" class="pi mt jj qu b gy qy qz l ra rb"># Import required libraries:<br/>import numpy as np<br/>import matplotlib.pyplot as plt<br/>from scipy.optimize import curve_fit</span><span id="0d3c" class="pi mt jj qu b gy rc qz l ra rb"># Dataset values :<br/>day = np.arange(0,8)<br/>weight = np.array([251,209,157,129,103,81,66,49])</span><span id="a12a" class="pi mt jj qu b gy rc qz l ra rb"># Exponential Function :<br/>def expo_func(x, a, b):<br/> return a * b ** x</span><span id="7400" class="pi mt jj qu b gy rc qz l ra rb">#popt :Optimal values for the parameters<br/>#pcov :The estimated covariance of popt</span><span id="125e" class="pi mt jj qu b gy rc qz l ra rb">popt, pcov = curve_fit(expo_func, day, weight)<br/>weight_pred = expo_func(day,popt[0],popt[1])</span><span id="bc96" class="pi mt jj qu b gy rc qz l ra rb"># Plotting the data<br/>plt.plot(day, weight_pred, ‘r-’)<br/>plt.scatter(day,weight,label=’Day vs Weight’)<br/>plt.title(“Day vs Weight a*b^x”)<br/>plt.xlabel(‘Day’)<br/>plt.ylabel(‘Weight’)<br/>plt.legend()<br/>plt.show()</span><span id="5672" class="pi mt jj qu b gy rc qz l ra rb"># Equation<br/>a=popt[0].round(4)<br/>b=popt[1].round(4)<br/>print(f’The equation of regression line is y={a}*{b}^x’)</span></pre><p id="e343" class="pw-post-body-paragraph lh li jj lj b lk ll kt lm ln lo kw lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated"><strong class="lj jt">在Google Colab上发布:</strong></p><div class="is it gp gr iu md"><a href="https://colab.research.google.com/drive/1CdiInssgUbBJ9GB2D4n_RSsuAjhsNTkk#scrollTo=q-w2fW-uDKHK&amp;line=26&amp;uniqifier=1" rel="noopener  ugc nofollow" target="_blank"><div class="me ab fo"><div class="mf ab mg cl cj mh"><h2 class="bd jt gy z fp mi fr fs mj fu fw js bi translated">谷歌联合实验室</h2><div class="mk l"><h3 class="bd b gy z fp mi fr fs mj fu fw dk translated">指数回归—https://towardsai.net/machine-learning-algorithms</h3></div><div class="ml l"><p class="bd b dl z fp mi fr fs mj fu fw dk translated">colab.research.google.com</p></div></div><div class="mm l"><div class="su l mo mp mq mm mr ja md"/></div></div></a></div></div><div class="ab cl oa ob hx oc" role="separator"><span class="od bw bk oe of og"/><span class="od bw bk oe of og"/><span class="od bw bk oe of"/></div><div class="im in io ip iq"><h2 id="1786" class="pi mt jj bd mu pj pk dn my pl pm dp nc lq pn po ne lu pp pq ng ly pr ps ni jp bi translated">1.5正弦回归:</h2><figure class="ou ov ow ox gt iv gh gi paragraph-image"><div class="gh gi sv"><img src="../Images/d33191c1328d57c4963e4b94eb03e794.png" data-original-src="https://miro.medium.com/v2/resize:fit:1296/format:webp/0*TRzT4S4yJ171RN5E.png"/></div><figcaption class="jc jd gj gh gi je jf bd b be z dk translated">来源:图片由作者创作。</figcaption></figure><p id="d460" class="pw-post-body-paragraph lh li jj lj b lk ll kt lm ln lo kw lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated"><strong class="lj jt">正弦回归的一些实际例子:</strong></p><ol class=""><li id="6c97" class="nk nl jj lj b lk ll ln lo lq pw lu px ly py mc pz ns nt nu bi translated">一代音乐浪潮。</li><li id="d48b" class="nk nl jj lj b lk nv ln nw lq nx lu ny ly nz mc pz ns nt nu bi translated">声音以波的形式传播。</li><li id="a1d3" class="nk nl jj lj b lk nv ln nw lq nx lu ny ly nz mc pz ns nt nu bi translated">建筑中的三角函数。</li><li id="bfc6" class="nk nl jj lj b lk nv ln nw lq nx lu ny ly nz mc pz ns nt nu bi translated">用于太空飞行。</li><li id="8cb9" class="nk nl jj lj b lk nv ln nw lq nx lu ny ly nz mc pz ns nt nu bi translated">GPS位置计算。</li><li id="0679" class="nk nl jj lj b lk nv ln nw lq nx lu ny ly nz mc pz ns nt nu bi translated">建筑。</li><li id="cb86" class="nk nl jj lj b lk nv ln nw lq nx lu ny ly nz mc pz ns nt nu bi translated">电流。</li><li id="78dd" class="nk nl jj lj b lk nv ln nw lq nx lu ny ly nz mc pz ns nt nu bi translated">无线电广播。</li><li id="241f" class="nk nl jj lj b lk nv ln nw lq nx lu ny ly nz mc pz ns nt nu bi translated">海洋的低潮和高潮。</li><li id="d99a" class="nk nl jj lj b lk nv ln nw lq nx lu ny ly nz mc pz ns nt nu bi translated">建筑。</li></ol><p id="ac08" class="pw-post-body-paragraph lh li jj lj b lk ll kt lm ln lo kw lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">有时我们有数据显示像正弦波一样的模式。因此，在这种情况下，我们使用正弦回归。下面我们可以展示算法的公式:</p><figure class="ou ov ow ox gt iv gh gi paragraph-image"><div class="gh gi re"><img src="../Images/6753e8691bf6fd8da50ff762b06eefb5.png" data-original-src="https://miro.medium.com/v2/resize:fit:1198/format:webp/0*RF9oensMRwAkAy-u.png"/></div><figcaption class="jc jd gj gh gi je jf bd b be z dk translated">正弦回归的公式|来源:图片由作者创作。</figcaption></figure><h2 id="b5ca" class="pi mt jj bd mu pj pk dn my pl pm dp nc lq pn po ne lu pp pq ng ly pr ps ni jp bi translated">Python中的分步实现:</h2><p id="50d9" class="pw-post-body-paragraph lh li jj lj b lk nm kt lm ln nn kw lp lq pt ls lt lu pu lw lx ly pv ma mb mc im bi translated"><strong class="lj jt"> a .生成数据集:</strong></p><figure class="ou ov ow ox gt iv gh gi paragraph-image"><div class="gh gi sw"><img src="../Images/1311d02d8c3c8655deeb7b9c597d8ba0.png" data-original-src="https://miro.medium.com/v2/resize:fit:966/format:webp/0*TPrhqFrRkWoxglUC.png"/></div><figcaption class="jc jd gj gh gi je jf bd b be z dk translated">来源:图片由作者创作。</figcaption></figure><figure class="ou ov ow ox gt iv gh gi paragraph-image"><div class="gh gi sx"><img src="../Images/20410e3401883bf7ff28bca02a9339ec.png" data-original-src="https://miro.medium.com/v2/resize:fit:926/format:webp/0*Dj9p007gTdqKYUGL.png"/></div><figcaption class="jc jd gj gh gi je jf bd b be z dk translated">来源:用Python处理的图片。</figcaption></figure><p id="695f" class="pw-post-body-paragraph lh li jj lj b lk ll kt lm ln lo kw lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated"><strong class="lj jt"> b .应用正弦函数:</strong></p><p id="d5c2" class="pw-post-body-paragraph lh li jj lj b lk ll kt lm ln lo kw lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">这里，我们创建了一个名为“calc_sine”的函数，根据最佳系数计算输出值。这里我们将使用scikit-learn库来查找最佳参数。</p><figure class="ou ov ow ox gt iv gh gi paragraph-image"><div class="gh gi sy"><img src="../Images/45509b07f616a793630aabd1b4a4bfdc.png" data-original-src="https://miro.medium.com/v2/resize:fit:930/format:webp/0*Nykcz_FJGehmkUQo.png"/></div><figcaption class="jc jd gj gh gi je jf bd b be z dk translated">来源:图片由作者创作。</figcaption></figure><figure class="ou ov ow ox gt iv gh gi paragraph-image"><div class="gh gi sd"><img src="../Images/5d8ec24f128f3a86fa919dee53feaf13.png" data-original-src="https://miro.medium.com/v2/resize:fit:808/format:webp/0*7Vgrmvjycc6UMgbW.png"/></div><figcaption class="jc jd gj gh gi je jf bd b be z dk translated">来源:用Python处理的图片。</figcaption></figure><p id="c14c" class="pw-post-body-paragraph lh li jj lj b lk ll kt lm ln lo kw lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">为什么正弦回归比线性回归表现更好？</p><p id="e96d" class="pw-post-body-paragraph lh li jj lj b lk ll kt lm ln lo kw lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">如果我们在用直线拟合我们的数据后检查模型的准确性，我们可以看到预测的准确性低于正弦波回归。这就是为什么我们使用正弦回归。</p><figure class="ou ov ow ox gt iv gh gi paragraph-image"><div class="gh gi sz"><img src="../Images/6b3a921d6bebc5c259fecaf9d875dc8d.png" data-original-src="https://miro.medium.com/v2/resize:fit:954/format:webp/0*q8iD_3VBnwXiCojm.png"/></div><figcaption class="jc jd gj gh gi je jf bd b be z dk translated">来源:图片由作者创作。</figcaption></figure><figure class="ou ov ow ox gt iv gh gi paragraph-image"><div class="gh gi ta"><img src="../Images/b6097460dfb5b8b6809a78e7d8d5dc2b.png" data-original-src="https://miro.medium.com/v2/resize:fit:858/format:webp/0*6CMtWyYelbr8SCyr.png"/></div><figcaption class="jc jd gj gh gi je jf bd b be z dk translated">来源:用Python处理的图片。</figcaption></figure><p id="d6d9" class="pw-post-body-paragraph lh li jj lj b lk ll kt lm ln lo kw lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">将所有这些放在一起:</p><pre class="ou ov ow ox gt qt qu qv qw aw qx bi"><span id="24b3" class="pi mt jj qu b gy qy qz l ra rb"># Import required libraries:<br/>import numpy as np<br/>import matplotlib.pyplot as plt<br/>from scipy.optimize import curve_fit<br/>from sklearn.metrics import r2_score</span><span id="f132" class="pi mt jj qu b gy rc qz l ra rb"># Generating dataset:</span><span id="3dce" class="pi mt jj qu b gy rc qz l ra rb"># Y = A*sin(B(X + C)) + D<br/># A = Amplitude<br/># Period = 2*pi/B<br/># Period = Length of One Cycle<br/># C = Phase Shift (In Radian)<br/># D = Vertical Shift</span><span id="6059" class="pi mt jj qu b gy rc qz l ra rb">X = np.linspace(0,1,100) #(Start,End,Points)</span><span id="21fa" class="pi mt jj qu b gy rc qz l ra rb"># Here…<br/># A = 1<br/># B= 2*pi<br/># B = 2*pi/Period<br/># Period = 1<br/># C = 0<br/># D = 0</span><span id="80ea" class="pi mt jj qu b gy rc qz l ra rb">Y = 1*np.sin(2*np.pi*X)</span><span id="b9fb" class="pi mt jj qu b gy rc qz l ra rb"># Adding some Noise :<br/>Noise = 0.4*np.random.normal(size=100)</span><span id="2df4" class="pi mt jj qu b gy rc qz l ra rb">Y_data = Y + Noiseplt.scatter(X,Y_data,c=”r”)</span><span id="d604" class="pi mt jj qu b gy rc qz l ra rb"># Calculate the value:<br/>def calc_sine(x,a,b,c,d):<br/> return a * np.sin(b* ( x + np.radians(c))) + d</span><span id="ae27" class="pi mt jj qu b gy rc qz l ra rb"># Finding optimal parameters :<br/>popt,pcov = curve_fit(calc_sine,X,Y_data)</span><span id="03f9" class="pi mt jj qu b gy rc qz l ra rb"># Plot the main data :<br/>plt.scatter(X,Y_data)# Plot the best fit curve :<br/>plt.plot(X,calc_sine(X,*popt),c=”r”)</span><span id="2a92" class="pi mt jj qu b gy rc qz l ra rb"># Check the accuracy :<br/>Accuracy =r2_score(Y_data,calc_sine(X,*popt))<br/>print (Accuracy)</span><span id="0795" class="pi mt jj qu b gy rc qz l ra rb"># Function to calculate the value :<br/>def calc_line(X,m,b):<br/> return b + X*m</span><span id="3167" class="pi mt jj qu b gy rc qz l ra rb"># It returns optimized parametes for our function :<br/># popt stores optimal parameters<br/># pcov stores the covarience between each parameters.<br/>popt,pcov = curve_fit(calc_line,X,Y_data)</span><span id="1767" class="pi mt jj qu b gy rc qz l ra rb"># Plot the main data :<br/>plt.scatter(X,Y_data)# Plot the best fit line :<br/>plt.plot(X,calc_line(X,*popt),c=”r”)</span><span id="55e4" class="pi mt jj qu b gy rc qz l ra rb"># Check the accuracy of model :<br/>Accuracy =r2_score(Y_data,calc_line(X,*popt))<br/>print (“Accuracy of Linear Model : “,Accuracy)</span></pre><p id="ea9b" class="pw-post-body-paragraph lh li jj lj b lk ll kt lm ln lo kw lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated"><strong class="lj jt">在Google Colab上发布:</strong></p><div class="is it gp gr iu md"><a href="https://colab.research.google.com/drive/1CdiInssgUbBJ9GB2D4n_RSsuAjhsNTkk#scrollTo=vPU_9qhzD2Z4&amp;line=48&amp;uniqifier=1" rel="noopener  ugc nofollow" target="_blank"><div class="me ab fo"><div class="mf ab mg cl cj mh"><h2 class="bd jt gy z fp mi fr fs mj fu fw js bi translated">谷歌联合实验室</h2><div class="mk l"><h3 class="bd b gy z fp mi fr fs mj fu fw dk translated">正弦回归—https://towardsai.net/machine-learning-algorithms</h3></div><div class="ml l"><p class="bd b dl z fp mi fr fs mj fu fw dk translated">colab.research.google.com</p></div></div><div class="mm l"><div class="tb l mo mp mq mm mr ja md"/></div></div></a></div></div><div class="ab cl oa ob hx oc" role="separator"><span class="od bw bk oe of og"/><span class="od bw bk oe of og"/><span class="od bw bk oe of"/></div><div class="im in io ip iq"><h2 id="f5b5" class="pi mt jj bd mu pj pk dn my pl pm dp nc lq pn po ne lu pp pq ng ly pr ps ni jp bi translated">1.6对数回归:</h2><figure class="ou ov ow ox gt iv gh gi paragraph-image"><div class="gh gi ro"><img src="../Images/8399ca600bdc0b8726cab23e63c59790.png" data-original-src="https://miro.medium.com/v2/resize:fit:1250/format:webp/0*bsxLw4iMjPUTKvsI.png"/></div><figcaption class="jc jd gj gh gi je jf bd b be z dk translated">对数回归图|来源:用Python处理的图像。</figcaption></figure><p id="dab6" class="pw-post-body-paragraph lh li jj lj b lk ll kt lm ln lo kw lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated"><strong class="lj jt">对数增长的一些真实例子:</strong></p><ol class=""><li id="ae3b" class="nk nl jj lj b lk ll ln lo lq pw lu px ly py mc pz ns nt nu bi translated">地震的震级。</li><li id="818c" class="nk nl jj lj b lk nv ln nw lq nx lu ny ly nz mc pz ns nt nu bi translated">声音的强度。</li><li id="d31f" class="nk nl jj lj b lk nv ln nw lq nx lu ny ly nz mc pz ns nt nu bi translated">溶液的酸度。</li><li id="83d6" class="nk nl jj lj b lk nv ln nw lq nx lu ny ly nz mc pz ns nt nu bi translated">溶液的pH值。</li><li id="e12e" class="nk nl jj lj b lk nv ln nw lq nx lu ny ly nz mc pz ns nt nu bi translated">化学反应的产量。</li><li id="1944" class="nk nl jj lj b lk nv ln nw lq nx lu ny ly nz mc pz ns nt nu bi translated">商品生产。</li><li id="1e08" class="nk nl jj lj b lk nv ln nw lq nx lu ny ly nz mc pz ns nt nu bi translated">婴儿的成长。</li><li id="6348" class="nk nl jj lj b lk nv ln nw lq nx lu ny ly nz mc pz ns nt nu bi translated">新冠肺炎图表。</li></ol><blockquote class="oh"><p id="1f8b" class="oi oj jj bd ok ol oy oz pa pb pc mc dk translated">📚查看我们对<a class="ae jg" href="https://towardsai.net/p/machine-learning/best-machine-learning-books-free-and-paid-ml-book-recommendations-40c9ab30b0c" rel="noopener ugc nofollow" target="_blank">最佳机器学习书籍</a>的编辑推荐。📚</p></blockquote><p id="5974" class="pw-post-body-paragraph lh li jj lj b lk pd kt lm ln pe kw lp lq pf ls lt lu pg lw lx ly ph ma mb mc im bi translated">有时，我们的数据在语句中呈指数增长，但在某个点之后，它变得平缓。在这种情况下，我们可以使用对数回归。</p><figure class="ou ov ow ox gt iv gh gi paragraph-image"><div class="gh gi tc"><img src="../Images/b00a6ecffbe0079f21648e684d4a2ee1.png" data-original-src="https://miro.medium.com/v2/resize:fit:1196/format:webp/0*DNmTUIf8S849wXoE.png"/></div><figcaption class="jc jd gj gh gi je jf bd b be z dk translated">对数回归方程|来源:图片由作者创作。</figcaption></figure><h2 id="e387" class="pi mt jj bd mu pj pk dn my pl pm dp nc lq pn po ne lu pp pq ng ly pr ps ni jp bi translated">Python中的分步实现:</h2><p id="0023" class="pw-post-body-paragraph lh li jj lj b lk nm kt lm ln nn kw lp lq pt ls lt lu pu lw lx ly pv ma mb mc im bi translated"><strong class="lj jt"> a .导入所需库:</strong></p><figure class="ou ov ow ox gt iv gh gi paragraph-image"><div class="gh gi td"><img src="../Images/5092562ed416c308a312586ffade4d57.png" data-original-src="https://miro.medium.com/v2/resize:fit:648/format:webp/0*Ji4UNOGUxRsNRzD8.png"/></div><figcaption class="jc jd gj gh gi je jf bd b be z dk translated">来源:图片由作者创作。</figcaption></figure><p id="cafc" class="pw-post-body-paragraph lh li jj lj b lk ll kt lm ln lo kw lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated"><strong class="lj jt"> b .生成数据集:</strong></p><figure class="ou ov ow ox gt iv gh gi paragraph-image"><div class="gh gi te"><img src="../Images/9003e17b4fc347e28e4f7544e9833b43.png" data-original-src="https://miro.medium.com/v2/resize:fit:942/format:webp/0*Vt5jL1E4qlmEST27.png"/></div><figcaption class="jc jd gj gh gi je jf bd b be z dk translated">来源:图片由作者创作。</figcaption></figure><p id="718e" class="pw-post-body-paragraph lh li jj lj b lk ll kt lm ln lo kw lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated"><strong class="lj jt"> c .我们的矩阵X的第一列:</strong></p><p id="d023" class="pw-post-body-paragraph lh li jj lj b lk ll kt lm ln lo kw lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">这里我们将使用我们的正规方程来寻找系数值。</p><figure class="ou ov ow ox gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi tf"><img src="../Images/e140291ebc882d6c142256a4b23e4b66.png" data-original-src="https://miro.medium.com/v2/resize:fit:734/format:webp/0*PPfNxp-2LIcdw8lS.png"/></div></div><figcaption class="jc jd gj gh gi je jf bd b be z dk translated">来源:图片由作者创作。</figcaption></figure><p id="509d" class="pw-post-body-paragraph lh li jj lj b lk ll kt lm ln lo kw lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated"><strong class="lj jt"> d .整形X: </strong></p><figure class="ou ov ow ox gt iv gh gi paragraph-image"><div class="gh gi tg"><img src="../Images/3613790d85c171e677e794d6b9b3c31e.png" data-original-src="https://miro.medium.com/v2/resize:fit:444/format:webp/0*ZlZg2D5_BtTt4yvl.png"/></div><figcaption class="jc jd gj gh gi je jf bd b be z dk translated">来源:图片由作者创作。</figcaption></figure><p id="7f59" class="pw-post-body-paragraph lh li jj lj b lk ll kt lm ln lo kw lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated"><strong class="lj jt"> e .走正规方程公式:</strong></p><figure class="ou ov ow ox gt iv gh gi paragraph-image"><div class="gh gi th"><img src="../Images/a467b069a191b2734cb10489e88b1d4e.png" data-original-src="https://miro.medium.com/v2/resize:fit:516/format:webp/0*O7gHnJsqN-N0X3B8.png"/></div><figcaption class="jc jd gj gh gi je jf bd b be z dk translated">来源:图片由作者创作。</figcaption></figure><p id="9de6" class="pw-post-body-paragraph lh li jj lj b lk ll kt lm ln lo kw lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated"><strong class="lj jt"> f .形成主矩阵X: </strong></p><figure class="ou ov ow ox gt iv gh gi paragraph-image"><div class="gh gi ti"><img src="../Images/d079a49109c3fe038819354f406a0001.png" data-original-src="https://miro.medium.com/v2/resize:fit:686/format:webp/0*KcG6ToWYRRpzhtfI.png"/></div><figcaption class="jc jd gj gh gi je jf bd b be z dk translated">来源:图片由作者创作。</figcaption></figure><p id="8148" class="pw-post-body-paragraph lh li jj lj b lk ll kt lm ln lo kw lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated"><strong class="lj jt"> g .寻找转置矩阵:</strong></p><figure class="ou ov ow ox gt iv gh gi paragraph-image"><div class="gh gi tf"><img src="../Images/d488a24180d34a4a08362ecaf16ba52d.png" data-original-src="https://miro.medium.com/v2/resize:fit:734/format:webp/0*osDlmvYMCsNxvU9b.png"/></div><figcaption class="jc jd gj gh gi je jf bd b be z dk translated">来源:图片由作者创作。</figcaption></figure><p id="4bfc" class="pw-post-body-paragraph lh li jj lj b lk ll kt lm ln lo kw lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">执行矩阵乘法:</p><figure class="ou ov ow ox gt iv gh gi paragraph-image"><div class="gh gi tj"><img src="../Images/0cfd789fc9088bfbbb1483d62d3bc6f6.png" data-original-src="https://miro.medium.com/v2/resize:fit:896/format:webp/0*BHqoSQfrxtLEXbP1.png"/></div><figcaption class="jc jd gj gh gi je jf bd b be z dk translated">来源:图片由作者创作。</figcaption></figure><p id="def5" class="pw-post-body-paragraph lh li jj lj b lk ll kt lm ln lo kw lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated"><strong class="lj jt">一、求逆:</strong></p><figure class="ou ov ow ox gt iv gh gi paragraph-image"><div class="gh gi tk"><img src="../Images/e91149a8962d489da765fe221dce689c.png" data-original-src="https://miro.medium.com/v2/resize:fit:830/format:webp/0*tp2-i5xw1mDQI9J2.png"/></div><figcaption class="jc jd gj gh gi je jf bd b be z dk translated">来源:图片由作者创作。</figcaption></figure><p id="d63f" class="pw-post-body-paragraph lh li jj lj b lk ll kt lm ln lo kw lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated"><strong class="lj jt"> j .矩阵乘法:</strong></p><figure class="ou ov ow ox gt iv gh gi paragraph-image"><div class="gh gi tl"><img src="../Images/98bd062cb6e64f0279bb2830cb42b822.png" data-original-src="https://miro.medium.com/v2/resize:fit:618/format:webp/0*MNMxwWgSP1TAkiPh.png"/></div><figcaption class="jc jd gj gh gi je jf bd b be z dk translated">来源:图片由作者创作。</figcaption></figure><p id="c248" class="pw-post-body-paragraph lh li jj lj b lk ll kt lm ln lo kw lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated"><strong class="lj jt"> k .求系数值:</strong></p><figure class="ou ov ow ox gt iv gh gi paragraph-image"><div class="gh gi tm"><img src="../Images/97cc2218d84e56faa4f2446f15f0cc91.png" data-original-src="https://miro.medium.com/v2/resize:fit:604/format:webp/0*dz1pgHhW3Ogg0KhO.png"/></div><figcaption class="jc jd gj gh gi je jf bd b be z dk translated">来源:图片由作者创作。</figcaption></figure><p id="6276" class="pw-post-body-paragraph lh li jj lj b lk ll kt lm ln lo kw lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated"><strong class="lj jt"> l .用回归曲线绘制数据:</strong></p><figure class="ou ov ow ox gt iv gh gi paragraph-image"><div class="gh gi tn"><img src="../Images/bb1c7c5df9e993069ee6789fb6d3c0be.png" data-original-src="https://miro.medium.com/v2/resize:fit:862/format:webp/0*olABbfj8UorD4m7R.png"/></div><figcaption class="jc jd gj gh gi je jf bd b be z dk translated">来源:图片由作者创作。</figcaption></figure><p id="e17b" class="pw-post-body-paragraph lh li jj lj b lk ll kt lm ln lo kw lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated"><strong class="lj jt"> m .精度:</strong></p><figure class="ou ov ow ox gt iv gh gi paragraph-image"><div class="gh gi to"><img src="../Images/dccb68a807b553f8e35da39c9bd789c5.png" data-original-src="https://miro.medium.com/v2/resize:fit:536/format:webp/0*O3a6LavvHlsg6ZSl.png"/></div><figcaption class="jc jd gj gh gi je jf bd b be z dk translated">来源:图片由作者创作。</figcaption></figure><p id="3033" class="pw-post-body-paragraph lh li jj lj b lk ll kt lm ln lo kw lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated"><strong class="lj jt">综合起来:</strong></p><pre class="ou ov ow ox gt qt qu qv qw aw qx bi"><span id="ef40" class="pi mt jj qu b gy qy qz l ra rb"># Import required libraries:<br/>import numpy as np<br/>import matplotlib.pyplot as plt<br/>from sklearn.metrics import r2_score</span><span id="2380" class="pi mt jj qu b gy rc qz l ra rb"># Dataset:<br/># Y = a + b*ln(X)<br/>X = np.arange(1,50,0.5)<br/>Y = 10 + 2*np.log(X)</span><span id="99d4" class="pi mt jj qu b gy rc qz l ra rb">#Adding some noise to calculate error!<br/>Y_noise = np.random.rand(len(Y))<br/>Y = Y +Y_noise<br/>plt.scatter(X,Y)</span><span id="27b6" class="pi mt jj qu b gy rc qz l ra rb"># 1st column of our X matrix should be 1:<br/>n = len(X)<br/>x_bias = np.ones((n,1))</span><span id="cedd" class="pi mt jj qu b gy rc qz l ra rb">print (X.shape)<br/>print (x_bias.shape)</span><span id="e804" class="pi mt jj qu b gy rc qz l ra rb"># Reshaping X :<br/>X = np.reshape(X,(n,1))<br/>print (X.shape)</span><span id="4386" class="pi mt jj qu b gy rc qz l ra rb"># Going with the formula:<br/># Y = a + b*ln(X)<br/>X_log = np.log(X)</span><span id="4004" class="pi mt jj qu b gy rc qz l ra rb"># Append the X_log to X_bias:<br/>x_new = np.append(x_bias,X_log,axis=1)</span><span id="a530" class="pi mt jj qu b gy rc qz l ra rb"># Transpose of a matrix:<br/>x_new_transpose = np.transpose(x_new)</span><span id="ea9c" class="pi mt jj qu b gy rc qz l ra rb"># Matrix multiplication:<br/>x_new_transpose_dot_x_new = x_new_transpose.dot(x_new)</span><span id="6cc8" class="pi mt jj qu b gy rc qz l ra rb"># Find inverse:<br/>temp_1 = np.linalg.inv(x_new_transpose_dot_x_new)</span><span id="0859" class="pi mt jj qu b gy rc qz l ra rb"># Matrix Multiplication:<br/>temp_2 = x_new_transpose.dot(Y)</span><span id="c43b" class="pi mt jj qu b gy rc qz l ra rb"># Find the coefficient values:<br/>theta = temp_1.dot(temp_2)</span><span id="8c8e" class="pi mt jj qu b gy rc qz l ra rb"># Plot the data:<br/>a = theta[0]<br/>b = theta[1]<br/>Y_plot = a + b*np.log(X)<br/>plt.scatter(X,Y)<br/>plt.plot(X,Y_plot,c=”r”)</span><span id="e532" class="pi mt jj qu b gy rc qz l ra rb"># Check the accuracy:<br/>Accuracy = r2_score(Y,Y_plot)<br/>print (Accuracy)</span></pre><p id="d544" class="pw-post-body-paragraph lh li jj lj b lk ll kt lm ln lo kw lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">在Google Colab上发布:</p><div class="is it gp gr iu md"><a href="https://colab.research.google.com/drive/1CdiInssgUbBJ9GB2D4n_RSsuAjhsNTkk#scrollTo=-FNHHye-Ek9P&amp;line=44&amp;uniqifier=1" rel="noopener  ugc nofollow" target="_blank"><div class="me ab fo"><div class="mf ab mg cl cj mh"><h2 class="bd jt gy z fp mi fr fs mj fu fw js bi translated">谷歌联合实验室</h2><div class="mk l"><h3 class="bd b gy z fp mi fr fs mj fu fw dk translated">对数回归—https://towardsai.net/machine-learning-algorithms</h3></div><div class="ml l"><p class="bd b dl z fp mi fr fs mj fu fw dk translated">colab.research.google.com</p></div></div><div class="mm l"><div class="tp l mo mp mq mm mr ja md"/></div></div></a></div></div><div class="ab cl oa ob hx oc" role="separator"><span class="od bw bk oe of og"/><span class="od bw bk oe of og"/><span class="od bw bk oe of"/></div><div class="im in io ip iq"><figure class="ou ov ow ox gt iv gh gi paragraph-image"><a href="https://www.buymeacoffee.com/pratu"><div class="gh gi tq"><img src="../Images/7ba4f2d6d12c187d5442ad1a88605fe8.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*-5oP6Xss4YY44doo.png"/></div></a><figcaption class="jc jd gj gh gi je jf bd b be z dk translated">给普拉蒂克买杯咖啡！</figcaption></figure><p id="bc9b" class="pw-post-body-paragraph lh li jj lj b lk ll kt lm ln lo kw lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated"><strong class="lj jt">免责声明:</strong>本文表达的观点仅代表作者个人观点，不代表卡内基梅隆大学或其他(直接或间接)与作者相关的公司的观点。这些文章并不打算成为最终产品，而是当前思想的反映，同时也是讨论和改进的催化剂。</p><h2 id="73e4" class="pi mt jj bd mu pj pk dn my pl pm dp nc lq pn po ne lu pp pq ng ly pr ps ni jp bi translated">引用</h2><p id="3ed2" class="pw-post-body-paragraph lh li jj lj b lk nm kt lm ln nn kw lp lq pt ls lt lu pu lw lx ly pv ma mb mc im bi translated">对于学术背景下的归属，请引用该工作为:</p><pre class="ou ov ow ox gt qt qu qv qw aw qx bi"><span id="4dec" class="pi mt jj qu b gy qy qz l ra rb">Shukla, et al., “Machine Learning Algorithms For Beginners with Code Examples in Python”, Towards AI, 2020</span></pre><h2 id="d831" class="pi mt jj bd mu pj pk dn my pl pm dp nc lq pn po ne lu pp pq ng ly pr ps ni jp bi translated">BibTex引文:</h2><pre class="ou ov ow ox gt qt qu qv qw aw qx bi"><span id="c9bc" class="pi mt jj qu b gy qy qz l ra rb">@article{pratik_iriondo_chen_2020, <br/> title={Machine Learning Algorithms For Beginners with Code Examples in Python}, <br/> url={<a class="ae jg" href="https://towardsai.net/machine-learning-algorithms" rel="noopener ugc nofollow" target="_blank">https://towardsai.net/machine-learning-algorithms</a>}, <br/> journal={Towards AI}, <br/> publisher={Towards AI Co.}, <br/> author={Pratik, Shukla and Iriondo, <br/> Roberto and Chen, Sherwin}, <br/> editor={Stanford, StacyEditor}, <br/> year={2020}, <br/> month={Jun}<br/>}</span></pre><h2 id="ecae" class="pi mt jj bd mu pj pk dn my pl pm dp nc lq pn po ne lu pp pq ng ly pr ps ni jp bi translated"><strong class="ak">参考文献:</strong></h2><p id="79ce" class="pw-post-body-paragraph lh li jj lj b lk nm kt lm ln nn kw lp lq pt ls lt lu pu lw lx ly pv ma mb mc im bi translated">[1]米切尔，汤姆。(1997).机器学习。麦格劳·希尔。第2页。国际标准书号0–07–042807–7</p><p id="bb65" class="pw-post-body-paragraph lh li jj lj b lk ll kt lm ln lo kw lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">[2]机器学习，亚瑟·塞缪尔，卡耐基·梅隆，【http://www.contrib.andrew.cmu.edu/~mndarwis/ML.html T4】</p><p id="895c" class="pw-post-body-paragraph lh li jj lj b lk ll kt lm ln lo kw lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">[3]机器学习(ML) vs. AI，走向AI，<a class="ae jg" href="https://towardsai.net/ai-vs-ml" rel="noopener ugc nofollow" target="_blank">https://towardsai.net/ai-vs-ml</a></p><p id="c65c" class="pw-post-body-paragraph lh li jj lj b lk ll kt lm ln lo kw lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">[4]关键机器学习定义，走向人工智能，<a class="ae jg" href="https://towardsai.net/machine-learning-definitions" rel="noopener ugc nofollow" target="_blank">https://towardsai.net/machine-learning-definitions</a></p><p id="4334" class="pw-post-body-paragraph lh li jj lj b lk ll kt lm ln lo kw lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">通过<a class="ae jg" href="https://towardsai.net/" rel="noopener ugc nofollow" target="_blank">向AI </a>发布</p><h1 id="1f35" class="ms mt jj bd mu mv mw mx my mz na nb nc ky nd kz ne lb nf lc ng le nh lf ni nj bi translated">推荐文章</h1><p id="6dfa" class="pw-post-body-paragraph lh li jj lj b lk nm kt lm ln nn kw lp lq pt ls lt lu pu lw lx ly pv ma mb mc im bi translated">一、<a class="ae jg" href="https://towardsai.net/p/machine-learning/best-datasets-for-machine-learning-and-data-science-d80e9f030279" rel="noopener ugc nofollow" target="_blank">机器学习和数据科学最佳数据集</a> <br/>二。<a class="ae jg" href="http://towardsai.net/ai-salaries" rel="noopener ugc nofollow" target="_blank">艾薪资冲天</a>三世<br/>。<a class="ae jg" href="https://towardsai.net/p/machine-learning/what-is-machine-learning-ml-b58162f97ec7" rel="noopener ugc nofollow" target="_blank">什么是机器学习？</a> <br/>四世。<a class="ae jg" href="https://towardsai.net/ml-masters" rel="noopener ugc nofollow" target="_blank">2020年最佳机器学习硕士项目</a> <br/>五、<a class="ae jg" href="https://towardsai.net/ml-phd" rel="noopener ugc nofollow" target="_blank">2020年最佳机器学习博士项目</a> <br/>六、<a class="ae jg" href="https://towardsai.net/p/machine-learning/best-machine-learning-blogs-6730ea2df3bd" rel="noopener ugc nofollow" target="_blank">最佳机器学习博客</a> <br/>七。<a class="ae jg" href="https://towardsai.net/p/machine-learning/key-machine-learning-ml-definitions-43e837ec6add" rel="noopener ugc nofollow" target="_blank">关键机器学习定义</a> <br/>八。<a class="ae jg" href="https://towardsai.net/ml-captcha" rel="noopener ugc nofollow" target="_blank">用机器学习在0.05秒内破解验证码</a> <br/>九。<a class="ae jg" href="https://towardsai.net/p/machine-learning/machine-learning-vs-ai-important-differences-between-them/robiriondo/3432/" rel="noopener ugc nofollow" target="_blank">机器学习vs. AI及其重要区别</a> <br/>十.<a class="ae jg" href="https://towardsai.net/p/machine-learning/moocs-vs-academia-ensuring-success-starting-in-a-machine-learning-ml-career-304b2e42315e" rel="noopener ugc nofollow" target="_blank">确保成功开创机器学习事业(ML) </a> <br/> XI。<a class="ae jg" href="https://towardsai.net/p/machine-learning/machine-learning-algorithms-for-beginners-with-python-code-examples-ml-19c6afd60daa" rel="noopener ugc nofollow" target="_blank">机器学习算法初学者</a> <br/>十二。<a class="ae jg" href="https://towardsai.net/neural-networks-with-python" rel="noopener ugc nofollow" target="_blank">神经网络从零开始详细用Python代码和数学</a> <br/> XIII。<a class="ae jg" href="https://towardsai.net/p/machine-learning/building-neural-networks-with-python-code-and-math-in-detail-ii-bbe8accbf3d1" rel="noopener ugc nofollow" target="_blank">用Python构建神经网络</a> <br/> XIV。<a class="ae jg" href="https://towardsai.net/p/machine-learning/main-types-of-neural-networks-and-its-applications-tutorial-734480d7ec8e" rel="noopener ugc nofollow" target="_blank">神经网络的主要类型</a> <br/>十五。<a class="ae jg" href="https://towardsai.net/p/machine-learning/monte-carlo-simulation-an-in-depth-tutorial-with-python-bcf6eb7856c8" rel="noopener ugc nofollow" target="_blank">用Python编写的蒙特卡洛模拟教程</a> <br/> XVI。<a class="ae jg" href="https://towardsai.net/p/nlp/natural-language-processing-nlp-with-python-tutorial-for-beginners-1f54e610a1a0" rel="noopener ugc nofollow" target="_blank">Python自然语言处理教程</a></p></div></div>    
</body>
</html>