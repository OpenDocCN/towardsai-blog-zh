<html>
<head>
<title>Convolutional Neural Networks for Dummies</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">虚拟卷积神经网络</h1>
<blockquote>原文：<a href="https://pub.towardsai.net/convolutional-neural-networks-for-dummies-afd7166cd9e?source=collection_archive---------1-----------------------#2020-07-24">https://pub.towardsai.net/convolutional-neural-networks-for-dummies-afd7166cd9e?source=collection_archive---------1-----------------------#2020-07-24</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><h2 id="5f9f" class="io ip iq bd b dl ir is it iu iv iw dk ix translated" aria-label="kicker paragraph"><a class="ae ep" href="https://towardsai.net/p/category/machine-learning/deep-learning" rel="noopener ugc nofollow" target="_blank">深度学习</a>，<a class="ae ep" href="https://towardsai.net/p/category/computer-vision" rel="noopener ugc nofollow" target="_blank">计算机视觉</a></h2><div class=""/><div class=""><h2 id="112d" class="pw-subtitle-paragraph jw iz iq bd b jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn dk translated">卷积神经网络完美指南</h2></div><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div role="button" tabindex="0" class="ku kv di kw bf kx"><div class="gh gi ko"><img src="../Images/24a21cc5e26f95249e6a033350269575.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*wk3ct87HfREUYv03-RLllw.jpeg"/></div></div></figure><p id="7347" class="pw-post-body-paragraph la lb iq lc b ld le ka lf lg lh kd li lj lk ll lm ln lo lp lq lr ls lt lu lv ij bi translated">你的社交媒体手柄上会弹出一个通知，说有人上传了一张可能有你的照片。</p><p id="b033" class="pw-post-body-paragraph la lb iq lc b ld le ka lf lg lh kd li lj lk ll lm ln lo lp lq lr ls lt lu lv ij bi translated">嘣！怎么发生的？</p><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div role="button" tabindex="0" class="ku kv di kw bf kx"><div class="gh gi lw"><img src="../Images/0d64489f729b3212a83069bf0ab3035e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*XupcNtiPIH5X-sCO"/></div></div><figcaption class="lx ly gj gh gi lz ma bd b be z dk translated">照片由<a class="ae mb" href="https://unsplash.com/@patrickian4?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Patrick Fore </a>在<a class="ae mb" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上拍摄</figcaption></figure><p id="c902" class="pw-post-body-paragraph la lb iq lc b ld le ka lf lg lh kd li lj lk ll lm ln lo lp lq lr ls lt lu lv ij bi translated">这就是<strong class="lc ja">图像分类的神奇之处。</strong></p><p id="a15b" class="pw-post-body-paragraph la lb iq lc b ld le ka lf lg lh kd li lj lk ll lm ln lo lp lq lr ls lt lu lv ij bi translated"><strong class="lc ja">卷积神经网络(CNN) </strong>隶属于<strong class="lc ja"> </strong> <a class="ae mb" href="https://medium.com/towards-artificial-intelligence/diving-deep-into-deep-learning-f34497c18f11" rel="noopener"> <strong class="lc ja">深度学习</strong> </a> <strong class="lc ja">。</strong>它们被用于涉及计算机视觉的操作中。如今，由于人工智能的范围正在极大地扩大，我们可以很容易地找到我们周围的卷积运算。这些技术发挥着重要作用，从<em class="mc">脸书自动标记、面部解锁、OCR到无人驾驶汽车。</em></p><p id="9070" class="pw-post-body-paragraph la lb iq lc b ld le ka lf lg lh kd li lj lk ll lm ln lo lp lq lr ls lt lu lv ij bi translated">图像分类获取输入(在这种情况下为图像),并在深度学习算法(即CNN)的帮助下输出该输入属于特定类别的类别/概率。</p></div><div class="ab cl md me hu mf" role="separator"><span class="mg bw bk mh mi mj"/><span class="mg bw bk mh mi mj"/><span class="mg bw bk mh mi"/></div><div class="ij ik il im in"><h1 id="d431" class="mk ml iq bd mm mn mo mp mq mr ms mt mu kf mv kg mw ki mx kj my kl mz km na nb bi translated">为什么是CNN？</h1><p id="caff" class="pw-post-body-paragraph la lb iq lc b ld nc ka lf lg nd kd li lj ne ll lm ln nf lp lq lr ng lt lu lv ij bi translated">根据<a class="ae mb" href="https://en.wikipedia.org/wiki/Universal_approximation_theorem" rel="noopener ugc nofollow" target="_blank">通用逼近定理</a>，<a class="ae mb" href="https://medium.com/towards-artificial-intelligence/diving-deep-into-deep-learning-f34497c18f11" rel="noopener">深度神经网络</a>是强大的函数逼近器。并且最好，这些可以使用<a class="ae mb" href="https://medium.com/towards-artificial-intelligence/diving-deep-into-deep-learning-f34497c18f11" rel="noopener"> <strong class="lc ja">反向传播</strong> </a>来提高它们的精度。</p><p id="b920" class="pw-post-body-paragraph la lb iq lc b ld le ka lf lg lh kd li lj lk ll lm ln lo lp lq lr ls lt lu lv ij bi translated">但是由于使用了如此多的参数，深度神经网络通常对过拟合非常敏感，甚至会因为长链而导致<strong class="lc ja">梯度消失</strong>问题。另外，<a class="ae mb" href="https://medium.com/towards-artificial-intelligence/diving-deep-into-deep-learning-f34497c18f11" rel="noopener">深度神经网络</a>无法处理图像中的<em class="mc">平移、旋转、光照</em>等变化。</p><p id="8521" class="pw-post-body-paragraph la lb iq lc b ld le ka lf lg lh kd li lj lk ll lm ln lo lp lq lr ls lt lu lv ij bi translated">因此，为了解决这个问题，我们开发了一种深度学习算法:<strong class="lc ja">卷积神经网络</strong>。</p></div><div class="ab cl md me hu mf" role="separator"><span class="mg bw bk mh mi mj"/><span class="mg bw bk mh mi mj"/><span class="mg bw bk mh mi"/></div><div class="ij ik il im in"><h1 id="cd40" class="mk ml iq bd mm mn mo mp mq mr ms mt mu kf mv kg mw ki mx kj my kl mz km na nb bi translated">图像分类</h1><h2 id="8f37" class="nh ml iq bd mm ni nj dn mq nk nl dp mu lj nm nn mw ln no np my lr nq nr na iw bi translated">人类如何观察一幅图像？</h2><p id="a9c3" class="pw-post-body-paragraph la lb iq lc b ld nc ka lf lg nd kd li lj ne ll lm ln nf lp lq lr ng lt lu lv ij bi translated">我们已经掌握了大脑快速判断物体的能力。</p><p id="b6ea" class="pw-post-body-paragraph la lb iq lc b ld le ka lf lg lh kd li lj lk ll lm ln lo lp lq lr ls lt lu lv ij bi translated">现在，它是如何发生的？</p><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div role="button" tabindex="0" class="ku kv di kw bf kx"><div class="gh gi ns"><img src="../Images/476d19aaa464b700f19f2ee84a5c2363.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*C1xtlEt34bXD0IuZ"/></div></div><figcaption class="lx ly gj gh gi lz ma bd b be z dk translated">照片由<a class="ae mb" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上的<a class="ae mb" href="https://unsplash.com/@saifmunqad?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Saifullah Munqad </a>拍摄</figcaption></figure><p id="31ae" class="pw-post-body-paragraph la lb iq lc b ld le ka lf lg lh kd li lj lk ll lm ln lo lp lq lr ls lt lu lv ij bi translated">我们的大脑会将物体的某些特征联系起来。举个例子，给你一个橘子和一个橙色的球。两者是相同的，但大脑仍然可以准确地区分它们，因为我们已经训练它，球的表面可能是光滑的，但橙子的表面有点粗糙。</p><p id="5798" class="pw-post-body-paragraph la lb iq lc b ld le ka lf lg lh kd li lj lk ll lm ln lo lp lq lr ls lt lu lv ij bi translated">多年来，我们训练我们的大脑来精确区分物体。CNN背后的想法也是如此，即训练我们的模型从图像中学习特征。</p><h2 id="07ee" class="nh ml iq bd mm ni nj dn mq nk nl dp mu lj nm nn mw ln no np my lr nq nr na iw bi translated">计算机如何观察图像？</h2><p id="cc4f" class="pw-post-body-paragraph la lb iq lc b ld nc ka lf lg nd kd li lj ne ll lm ln nf lp lq lr ng lt lu lv ij bi translated">当我们观察一幅图像时，我们会仔细观察各个方面，比如物体的边缘，物体的颜色，因为我们从小就被训练这样做。</p><p id="ffb5" class="pw-post-body-paragraph la lb iq lc b ld le ka lf lg lh kd li lj lk ll lm ln lo lp lq lr ls lt lu lv ij bi translated">但是，当我们将图像输入到模型中时，对它来说，它只不过是矩阵的集合。</p><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div role="button" tabindex="0" class="ku kv di kw bf kx"><div class="gh gi ko"><img src="../Images/0bc8b2e2262066101b811299f43b630b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*tQfvb1hAcbZ21Zik"/></div></div></figure><p id="82ff" class="pw-post-body-paragraph la lb iq lc b ld le ka lf lg lh kd li lj lk ll lm ln lo lp lq lr ls lt lu lv ij bi translated">对于我们的模型，图像是像素矩阵。如果我们传递彩色图像，它将是一个三维数组，RGB通道的范围从0到255。如果我们传递黑白图像，那么我们将得到一个二进制值的2D数组。</p><p id="d578" class="pw-post-body-paragraph la lb iq lc b ld le ka lf lg lh kd li lj lk ll lm ln lo lp lq lr ls lt lu lv ij bi translated">因此，当我们谈论分类时，我们希望我们的模型能够准确地定义这些变化，这样，我们得到的输出就尽可能地细微。</p><p id="f0d5" class="pw-post-body-paragraph la lb iq lc b ld le ka lf lg lh kd li lj lk ll lm ln lo lp lq lr ls lt lu lv ij bi translated"><strong class="lc ja">对于每一个特征，我们都有一个不同的矩阵来代表它的特征。</strong></p><h1 id="50fc" class="mk ml iq bd mm mn nt mp mq mr nu mt mu kf nv kg mw ki nw kj my kl nx km na nb bi translated">CNN是如何运作的？</h1><p id="25b0" class="pw-post-body-paragraph la lb iq lc b ld nc ka lf lg nd kd li lj ne ll lm ln nf lp lq lr ng lt lu lv ij bi translated">CNN的基本管道如下:</p><ul class=""><li id="2d22" class="ny nz iq lc b ld le lg lh lj oa ln ob lr oc lv od oe of og bi translated">输入图像。</li><li id="6e39" class="ny nz iq lc b ld oh lg oi lj oj ln ok lr ol lv od oe of og bi translated">执行卷积运算以获得激活图。</li><li id="3df6" class="ny nz iq lc b ld oh lg oi lj oj ln ok lr ol lv od oe of og bi translated">应用池层使我们的模型健壮。</li><li id="2479" class="ny nz iq lc b ld oh lg oi lj oj ln ok lr ol lv od oe of og bi translated"><a class="ae mb" href="https://medium.com/analytics-vidhya/activation-functions-explained-8690ea7bdec9" rel="noopener">激活功能(主要是ReLu) </a>用于避免非线性。</li><li id="90d4" class="ny nz iq lc b ld oh lg oi lj oj ln ok lr ol lv od oe of og bi translated">将最后的输出展平成一个线性向量。</li><li id="b4a2" class="ny nz iq lc b ld oh lg oi lj oj ln ok lr ol lv od oe of og bi translated">该向量被传递给完全连接的<a class="ae mb" href="https://medium.com/towards-artificial-intelligence/diving-deep-into-deep-learning-f34497c18f11" rel="noopener">人工神经网络。</a></li><li id="3f81" class="ny nz iq lc b ld oh lg oi lj oj ln ok lr ol lv od oe of og bi translated">全连通层将为我们所追求的每个类提供一个概率。</li><li id="8254" class="ny nz iq lc b ld oh lg oi lj oj ln ok lr ol lv od oe of og bi translated">重复该过程以获得定义良好的训练权重和特征检测器。</li></ul><h2 id="9663" class="nh ml iq bd mm ni nj dn mq nk nl dp mu lj nm nn mw ln no np my lr nq nr na iw bi translated">卷积层</h2><p id="36f7" class="pw-post-body-paragraph la lb iq lc b ld nc ka lf lg nd kd li lj ne ll lm ln nf lp lq lr ng lt lu lv ij bi translated">卷积滤波器从图像中清除特征，即它试图从图像中学习。它计算滤镜值和图像像素值之间的点积，以形成卷积层。</p><p id="b04a" class="pw-post-body-paragraph la lb iq lc b ld le ka lf lg lh kd li lj lk ll lm ln lo lp lq lr ls lt lu lv ij bi translated">每次执行反向传播时，滤波器矩阵中的值都会更新。然而，滤波器矩阵的维数由程序员明确确定。</p></div><div class="ab cl md me hu mf" role="separator"><span class="mg bw bk mh mi mj"/><span class="mg bw bk mh mi mj"/><span class="mg bw bk mh mi"/></div><div class="ij ik il im in"><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div class="gh gi om"><img src="../Images/d1b5660fc0620d4ec8f4d4a135a9051c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1052/0*fOdQ6oirqIR7YucA.gif"/></div><figcaption class="lx ly gj gh gi lz ma bd b be z dk translated">卷积运算</figcaption></figure><p id="2d1e" class="pw-post-body-paragraph la lb iq lc b ld le ka lf lg lh kd li lj lk ll lm ln lo lp lq lr ls lt lu lv ij bi translated">应用于3D输入的每个滤波器将给出2D输出，并且通过组合所有这些2D输出，我们得到3D最终输出。</p><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div role="button" tabindex="0" class="ku kv di kw bf kx"><div class="gh gi on"><img src="../Images/7cd22a767e1a1d31ba5e25ebba110647.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*_FwZzfO3h9RbLzwcrI5T_w.jpeg"/></div></div></figure><blockquote class="oo op oq"><p id="7d10" class="la lb mc lc b ld le ka lf lg lh kd li or lk ll lm os lo lp lq ot ls lt lu lv ij bi translated">过滤器的数量越多，我们的模型学习的特征数量就越多。</p></blockquote><p id="796c" class="pw-post-body-paragraph la lb iq lc b ld le ka lf lg lh kd li lj lk ll lm ln lo lp lq lr ls lt lu lv ij bi translated">当我们使用卷积滤波器时，输出图像的维数从(h，w，c)降低到(h-f+1，w-f+1，c ),这是显而易见的，因为我们不能将核保持在角落，因为它会跨越输入边界。</p><p id="b02a" class="pw-post-body-paragraph la lb iq lc b ld le ka lf lg lh kd li lj lk ll lm ln lo lp lq lr ls lt lu lv ij bi translated">为了保留输出图像的尺寸，我们使用<strong class="lc ja"> <em class="mc">填充，</em> </strong>在填充中，我们对每个通道添加零。</p><blockquote class="oo op oq"><p id="bfc8" class="la lb mc lc b ld le ka lf lg lh kd li or lk ll lm os lo lp lq ot ls lt lu lv ij bi translated"><strong class="lc ja">内核越大，需要的填充就越大。</strong></p></blockquote><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div role="button" tabindex="0" class="ku kv di kw bf kx"><div class="gh gi ou"><img src="../Images/17311cad6982ed546d1039b2852dd1cc.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*ASwrqwp8HM885Srk.PNG"/></div></div><figcaption class="lx ly gj gh gi lz ma bd b be z dk translated">填充，<a class="ae mb" href="https://deeplizard.com/images/zero%20padding%20example%202.PNG" rel="noopener ugc nofollow" target="_blank">源</a></figcaption></figure><p id="a245" class="pw-post-body-paragraph la lb iq lc b ld le ka lf lg lh kd li lj lk ll lm ln lo lp lq lr ls lt lu lv ij bi translated">除了填充，我们经常使用<strong class="lc ja"><em class="mc"/></strong>。在卷积中，为了得到激活图，我们通常向下或向旁边跳过一个像素，但是如果我们希望跳过自定义数量像素，我们可以使用stride。</p><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div role="button" tabindex="0" class="ku kv di kw bf kx"><div class="gh gi ov"><img src="../Images/3f24736f7eac20c974fbfb829af72607.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*iZ-HpAHzfJgCK335"/></div></div><figcaption class="lx ly gj gh gi lz ma bd b be z dk translated">步幅，<a class="ae mb" href="https://indoml.com/2018/03/07/student-notes-convolutional-neural-networks-cnn-introduction/" rel="noopener ugc nofollow" target="_blank">来源</a></figcaption></figure><blockquote class="oo op oq"><p id="3420" class="la lb mc lc b ld le ka lf lg lh kd li or lk ll lm os lo lp lq ot ls lt lu lv ij bi translated"><strong class="lc ja">步幅越大，输出维度越小。</strong></p></blockquote><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div class="gh gi ow"><img src="../Images/ff27fa217fe649de1b76230e02262d32.png" data-original-src="https://miro.medium.com/v2/resize:fit:682/format:webp/1*dugpB4UbwgYg92IGefAdIA.png"/></div><figcaption class="lx ly gj gh gi lz ma bd b be z dk translated">跨步后输出</figcaption></figure><p id="9a17" class="pw-post-body-paragraph la lb iq lc b ld le ka lf lg lh kd li lj lk ll lm ln lo lp lq lr ls lt lu lv ij bi translated">如果我们同时执行步幅和填充，输出尺寸将是:-</p><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div class="gh gi ox"><img src="../Images/c1ccea3ca47325f3b84aae3cd563eefb.png" data-original-src="https://miro.medium.com/v2/resize:fit:1144/format:webp/1*XxJhC4atlbE87p06XYAseg.png"/></div><figcaption class="lx ly gj gh gi lz ma bd b be z dk translated">步幅和填充后的输出</figcaption></figure><h2 id="8502" class="nh ml iq bd mm ni nj dn mq nk nl dp mu lj nm nn mw ln no np my lr nq nr na iw bi translated">汇集层</h2><p id="ece3" class="pw-post-body-paragraph la lb iq lc b ld nc ka lf lg nd kd li lj ne ll lm ln nf lp lq lr ng lt lu lv ij bi translated">为了创建我们的模型更健壮和更有特色的检测器，CNN用max summary替换输出，以缩减数据大小和处理时间。这允许程序员区分具有较高影响的特性。</p><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div class="gh gi oy"><img src="../Images/7a6f86779931064ea1ef389f4a28fb2f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1140/format:webp/0*YvTtc1wFv52D3vQe.png"/></div><figcaption class="lx ly gj gh gi lz ma bd b be z dk translated">最大池化，<a class="ae mb" href="https://en.wikipedia.org/wiki/File:Max_pooling.png" rel="noopener ugc nofollow" target="_blank">来源</a></figcaption></figure><p id="0d5d" class="pw-post-body-paragraph la lb iq lc b ld le ka lf lg lh kd li lj lk ll lm ln lo lp lq lr ls lt lu lv ij bi translated">最大池有两个<strong class="lc ja">超参数</strong>:步幅和大小。跨距将决定要跳过的值的数量，大小将决定每个跳过的值池的面积。</p><h2 id="1048" class="nh ml iq bd mm ni nj dn mq nk nl dp mu lj nm nn mw ln no np my lr nq nr na iw bi translated"><a class="ae mb" href="https://medium.com/analytics-vidhya/activation-functions-explained-8690ea7bdec9" rel="noopener">激活功能(ReLU和乙状结肠)</a></h2><p id="f5aa" class="pw-post-body-paragraph la lb iq lc b ld nc ka lf lg nd kd li lj ne ll lm ln nf lp lq lr ng lt lu lv ij bi translated">在应用卷积和池化操作之后，激活函数被引入以适合值x&gt;0的非线性，并且如果不满足条件，则返回0。</p><p id="88aa" class="pw-post-body-paragraph la lb iq lc b ld le ka lf lg lh kd li lj lk ll lm ln lo lp lq lr ls lt lu lv ij bi translated">这种方法对于解决梯度递减问题是有效的。在<a class="ae mb" href="https://medium.com/analytics-vidhya/activation-functions-explained-8690ea7bdec9" rel="noopener"> ReLU激活功能后，非常小的重量将保持为0。</a></p><h2 id="47d4" class="nh ml iq bd mm ni nj dn mq nk nl dp mu lj nm nn mw ln no np my lr nq nr na iw bi translated">全连接层</h2><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div role="button" tabindex="0" class="ku kv di kw bf kx"><div class="gh gi oz"><img src="../Images/979288c0e04c651aa6f3b30e51b52c46.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*PgXilT2fVrVfbkSt.png"/></div></div><figcaption class="lx ly gj gh gi lz ma bd b be z dk translated">CNN架构，<a class="ae mb" href="https://cezannec.github.io/assets/cnn_intro/CNN_ex.png" rel="noopener ugc nofollow" target="_blank">来源</a></figcaption></figure><p id="85a1" class="pw-post-body-paragraph la lb iq lc b ld le ka lf lg lh kd li lj lk ll lm ln lo lp lq lr ls lt lu lv ij bi translated">至此，我们准备在我们的卷积神经网络中增加一个<a class="ae mb" href="https://medium.com/towards-artificial-intelligence/diving-deep-into-deep-learning-f34497c18f11" rel="noopener"> <strong class="lc ja">人工神经网络</strong> </a>。</p><p id="f788" class="pw-post-body-paragraph la lb iq lc b ld le ka lf lg lh kd li lj lk ll lm ln lo lp lq lr ls lt lu lv ij bi translated">这是最后一层，我们将输入展平特征输出到一个列向量。最后，我们将把最终的平坦化输出提供给softmax activation函数，该函数将为每个类分配一个概率。前一层中的每个节点都连接到最后一层，并表示要输出哪个不同的标签。</p><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div class="gh gi pa"><img src="../Images/35ac445f6a209ae590d91ab716e37349.png" data-original-src="https://miro.medium.com/v2/resize:fit:1264/format:webp/1*TjGDzMZJHnJVw8MdCbzs5Q.jpeg"/></div><figcaption class="lx ly gj gh gi lz ma bd b be z dk translated"><a class="ae mb" href="https://www.google.com/url?sa=i&amp;url=https%3A%2F%2Fwww.slideshare.net%2Fxavigiro%2Floss-functions-dlai-d4l2-2017-upc-deep-learning-for-artificial-intelligence&amp;psig=AOvVaw0FZB6DYmtxvMPBtJZFPmfR&amp;ust=1595314362126000&amp;source=images&amp;cd=vfe&amp;ved=0CAIQjRxqFwoTCNDgv6Kf2-oCFQAAAAAdAAAAABAJ" rel="noopener ugc nofollow" target="_blank">最终输出，来源</a></figcaption></figure></div><div class="ab cl md me hu mf" role="separator"><span class="mg bw bk mh mi mj"/><span class="mg bw bk mh mi mj"/><span class="mg bw bk mh mi"/></div><div class="ij ik il im in"><h1 id="a43e" class="mk ml iq bd mm mn mo mp mq mr ms mt mu kf mv kg mw ki mx kj my kl mz km na nb bi translated">CNN如何执行<a class="ae mb" href="https://medium.com/towards-artificial-intelligence/diving-deep-into-deep-learning-f34497c18f11" rel="noopener">反向传播</a>？</h1><p id="bf13" class="pw-post-body-paragraph la lb iq lc b ld nc ka lf lg nd kd li lj ne ll lm ln nf lp lq lr ng lt lu lv ij bi translated">我们使用<a class="ae mb" href="https://medium.com/towards-artificial-intelligence/diving-deep-into-deep-learning-f34497c18f11" rel="noopener">反向传播</a>来使我们的模型学习更好的权重和偏差，以帮助优化模型的性能。这是一个帮助我们的网络更好地学习的递归过程。</p><p id="9cb4" class="pw-post-body-paragraph la lb iq lc b ld le ka lf lg lh kd li lj lk ll lm ln lo lp lq lr ls lt lu lv ij bi translated">假设，您有两个输出类，一个用于猫，另一个用于狗。猫的神经元是确定的，当一些特定的特征如“胡须”、“猫虹膜”、“小而轻的身体”被识别出来时，它们就会被触发。</p><p id="3e69" class="pw-post-body-paragraph la lb iq lc b ld le ka lf lg lh kd li lj lk ll lm ln lo lp lq lr ls lt lu lv ij bi translated">通过大量的迭代，猫神经元知道当某些特征被激活时，图像就是一只猫。</p><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div role="button" tabindex="0" class="ku kv di kw bf kx"><div class="gh gi pb"><img src="../Images/4631d6c2c543ef3e4abdc5671157e704.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*zEkgA2N4wnV6zdBM"/></div></div><figcaption class="lx ly gj gh gi lz ma bd b be z dk translated">照片由<a class="ae mb" href="https://unsplash.com/@madhatterzone?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Manja Vitolic </a>在<a class="ae mb" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上拍摄</figcaption></figure><p id="3ec6" class="pw-post-body-paragraph la lb iq lc b ld le ka lf lg lh kd li lj lk ll lm ln lo lp lq lr ls lt lu lv ij bi translated">类似地，当一些特征如“大湿鼻子”、“耷拉的耳朵”、“沉重的身体”被触发时，狗的神经元是活跃的。</p><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div role="button" tabindex="0" class="ku kv di kw bf kx"><div class="gh gi pc"><img src="../Images/252241deacc64962634dee0487826823.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*W3zI4diePOFAuoYd"/></div></div><figcaption class="lx ly gj gh gi lz ma bd b be z dk translated">Victor Grabarczyk 在<a class="ae mb" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上拍摄的照片</figcaption></figure><p id="592c" class="pw-post-body-paragraph la lb iq lc b ld le ka lf lg lh kd li lj lk ll lm ln lo lp lq lr ls lt lu lv ij bi translated">随着我们的模型的进展，它被递归地训练，现在我们可以期望它们区分不同类的相关和重要特征，从而为那些特征提供更大的权重，以便那些特征可以对我们的输出产生显著的影响。</p></div><div class="ab cl md me hu mf" role="separator"><span class="mg bw bk mh mi mj"/><span class="mg bw bk mh mi mj"/><span class="mg bw bk mh mi"/></div><div class="ij ik il im in"><h1 id="afbd" class="mk ml iq bd mm mn mo mp mq mr ms mt mu kf mv kg mw ki mx kj my kl mz km na nb bi translated">让CNN变得更好</h1><p id="e660" class="pw-post-body-paragraph la lb iq lc b ld nc ka lf lg nd kd li lj ne ll lm ln nf lp lq lr ng lt lu lv ij bi translated">可悲的是，CNN并不完美，如果没有以适当的方式监督，它经常免于过度拟合。</p><p id="e482" class="pw-post-body-paragraph la lb iq lc b ld le ka lf lg lh kd li lj lk ll lm ln lo lp lq lr ls lt lu lv ij bi translated">尽管如此，它的一些问题可以通过讨论解决:</p><h2 id="ebb5" class="nh ml iq bd mm ni nj dn mq nk nl dp mu lj nm nn mw ln no np my lr nq nr na iw bi translated">数据集相对较小</h2><p id="fddb" class="pw-post-body-paragraph la lb iq lc b ld nc ka lf lg nd kd li lj ne ll lm ln nf lp lq lr ng lt lu lv ij bi translated"><strong class="lc ja">数据集小时，容易过拟合</strong>。例如，如果你只显示黑狗是狗，那么下一次它不会识别白狗是狗，因为对于我们的模型，狗只能是黑色的(这显然是错误的和种族主义的！)</p><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div role="button" tabindex="0" class="ku kv di kw bf kx"><div class="gh gi pd"><img src="../Images/a2bd600ab4871822240608c0efa3b7a4.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*Wo2ukQSwy67x6jzU"/></div></div><figcaption class="lx ly gj gh gi lz ma bd b be z dk translated">由<a class="ae mb" href="https://unsplash.com/@lightupphotos?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">克里斯蒂娜·安妮·科斯特洛</a>在<a class="ae mb" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上拍摄的照片</figcaption></figure><p id="5954" class="pw-post-body-paragraph la lb iq lc b ld le ka lf lg lh kd li lj lk ll lm ln lo lp lq lr ls lt lu lv ij bi translated">因此，在这种情况下，人为地增加训练样本的多样性和数量是可取的。一种方法是添加<strong class="lc ja"> </strong>图像增强<strong class="lc ja"> </strong>并创建新的变体。这些包括转换图像和创建尺寸变化，如<em class="mc">缩放、裁剪、翻转、移动、</em>等。</p><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div role="button" tabindex="0" class="ku kv di kw bf kx"><div class="gh gi pe"><img src="../Images/058464cca2a54ad5955a2f08f3daf9e1.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*uQzhaqxI0E9C9Gue.png"/></div></div><figcaption class="lx ly gj gh gi lz ma bd b be z dk translated">图像增强，<a class="ae mb" href="https://miro.medium.com/max/2880/1*segSp7W8dCZO779m_Cs6Dg.png" rel="noopener">来源</a></figcaption></figure><h2 id="f367" class="nh ml iq bd mm ni nj dn mq nk nl dp mu lj nm nn mw ln no np my lr nq nr na iw bi translated">过度记忆</h2><p id="0956" class="pw-post-body-paragraph la lb iq lc b ld nc ka lf lg nd kd li lj ne ll lm ln nf lp lq lr ng lt lu lv ij bi translated">我们拥有的层次越多，学到的特征就越多，这促进了记忆，抑制了概括。你训练你的模型越多，它就越有可能变得过于专业化。</p><p id="3b73" class="pw-post-body-paragraph la lb iq lc b ld le ka lf lg lh kd li lj lk ll lm ln lo lp lq lr ls lt lu lv ij bi translated">如果我们可以通过删除一些隐藏层和每层的神经元来降低复杂性，这是可以避免的。这种技术被称为<strong class="lc ja">辍学。</strong></p><p id="9437" class="pw-post-body-paragraph la lb iq lc b ld le ka lf lg lh kd li lj lk ll lm ln lo lp lq lr ls lt lu lv ij bi translated">这个想法是在每个时期丢弃一些随机神经元，最终结果将是所有输出的平均值。</p><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div role="button" tabindex="0" class="ku kv di kw bf kx"><div class="gh gi pf"><img src="../Images/5f98a5476f6db7aa9296866b6e79921b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*E0KmL4lvJL1zX0_O.png"/></div></div><figcaption class="lx ly gj gh gi lz ma bd b be z dk translated">带压差的标准NN v/s NN，<a class="ae mb" href="https://www.researchgate.net/profile/Giorgio_Roffo/publication/317277576/figure/fig27/AS:500357438029828@1496305917435/4-An-illustration-of-the-dropout-mechanism-within-the-proposed-CNN-a-Shows-a.png" rel="noopener ugc nofollow" target="_blank">来源</a>。</figcaption></figure><p id="76e0" class="pw-post-body-paragraph la lb iq lc b ld le ka lf lg lh kd li lj lk ll lm ln lo lp lq lr ls lt lu lv ij bi translated">没有参与计算功能的神经元，它们的权重不会使用反向传播来更新。</p></div><div class="ab cl md me hu mf" role="separator"><span class="mg bw bk mh mi mj"/><span class="mg bw bk mh mi mj"/><span class="mg bw bk mh mi"/></div><div class="ij ik il im in"><h1 id="0262" class="mk ml iq bd mm mn mo mp mq mr ms mt mu kf mv kg mw ki mx kj my kl mz km na nb bi translated">结论</h1><p id="90ca" class="pw-post-body-paragraph la lb iq lc b ld nc ka lf lg nd kd li lj ne ll lm ln nf lp lq lr ng lt lu lv ij bi translated">希望这篇文章能帮助你以最好的方式理解卷积神经网络，并帮助你实际使用它。</p><p id="c788" class="pw-post-body-paragraph la lb iq lc b ld le ka lf lg lh kd li lj lk ll lm ln lo lp lq lr ls lt lu lv ij bi translated">请留下你的建议和反馈。就像你一样，我也在学习如何成为一名更好的数据科学家和工程师。请帮助我改进，以便我可以在后续的文章发布中更好地帮助您。</p><p id="c183" class="pw-post-body-paragraph la lb iq lc b ld le ka lf lg lh kd li lj lk ll lm ln lo lp lq lr ls lt lu lv ij bi translated">一如既往，非常感谢您的阅读，如果您觉得这篇文章有用，请分享！</p></div><div class="ab cl md me hu mf" role="separator"><span class="mg bw bk mh mi mj"/><span class="mg bw bk mh mi mj"/><span class="mg bw bk mh mi"/></div><div class="ij ik il im in"><p id="228e" class="pw-post-body-paragraph la lb iq lc b ld le ka lf lg lh kd li lj lk ll lm ln lo lp lq lr ls lt lu lv ij bi translated">请随意连接:</p><blockquote class="oo op oq"><p id="11fd" class="la lb mc lc b ld le ka lf lg lh kd li or lk ll lm os lo lp lq ot ls lt lu lv ij bi translated"><em class="iq">LinkedIn ~</em><a class="ae mb" href="https://www.linkedin.com/in/dakshtrehan/" rel="noopener ugc nofollow" target="_blank">【https://www.linkedin.com/in/dakshtrehan/】T21</a></p><p id="9bb9" class="la lb mc lc b ld le ka lf lg lh kd li or lk ll lm os lo lp lq ot ls lt lu lv ij bi translated"><em class="iq">insta gram ~</em><a class="ae mb" href="https://www.instagram.com/_daksh_trehan_/" rel="noopener ugc nofollow" target="_blank"><em class="iq">https://www.instagram.com/_daksh_trehan_/</em></a></p><p id="788b" class="la lb mc lc b ld le ka lf lg lh kd li or lk ll lm os lo lp lq ot ls lt lu lv ij bi translated"><em class="iq">Github ~</em><a class="ae mb" href="https://github.com/dakshtrehan" rel="noopener ugc nofollow" target="_blank">T3】https://github.com/dakshtrehanT5】</a></p></blockquote><p id="c03c" class="pw-post-body-paragraph la lb iq lc b ld le ka lf lg lh kd li lj lk ll lm ln lo lp lq lr ls lt lu lv ij bi translated">关注更多机器学习/深度学习博客。</p><blockquote class="oo op oq"><p id="f13a" class="la lb mc lc b ld le ka lf lg lh kd li or lk ll lm os lo lp lq ot ls lt lu lv ij bi translated"><em class="iq">中等~</em><a class="ae mb" href="https://medium.com/@dakshtrehan" rel="noopener"><em class="iq">https://medium.com/@dakshtrehan</em></a></p></blockquote><h1 id="c270" class="mk ml iq bd mm mn nt mp mq mr nu mt mu kf nv kg mw ki nw kj my kl nx km na nb bi translated">想了解更多？</h1><p id="6031" class="pw-post-body-paragraph la lb iq lc b ld nc ka lf lg nd kd li lj ne ll lm ln nf lp lq lr ng lt lu lv ij bi translated"><a class="ae mb" href="https://towardsdatascience.com/detecting-covid-19-using-deep-learning-262956b6f981" rel="noopener" target="_blank">利用深度学习检测新冠肺炎</a></p><p id="2882" class="pw-post-body-paragraph la lb iq lc b ld le ka lf lg lh kd li lj lk ll lm ln lo lp lq lr ls lt lu lv ij bi translated"><a class="ae mb" href="https://towardsdatascience.com/the-inescapable-ai-algorithm-tiktok-ad4c6fd981b8" rel="noopener" target="_blank">无法逃脱的人工智能算法:抖音</a></p><p id="22e7" class="pw-post-body-paragraph la lb iq lc b ld le ka lf lg lh kd li lj lk ll lm ln lo lp lq lr ls lt lu lv ij bi translated"><a class="ae mb" href="https://medium.com/towards-artificial-intelligence/diving-deep-into-deep-learning-f34497c18f11" rel="noopener">深入钻研深度学习</a></p><p id="80f3" class="pw-post-body-paragraph la lb iq lc b ld le ka lf lg lh kd li lj lk ll lm ln lo lp lq lr ls lt lu lv ij bi translated"><a class="ae mb" href="https://medium.com/towards-artificial-intelligence/an-insiders-guide-to-cartoonization-using-machine-learning-ce3648adfe8" rel="noopener">使用机器学习的卡通化内部指南</a></p><p id="d3ae" class="pw-post-body-paragraph la lb iq lc b ld le ka lf lg lh kd li lj lk ll lm ln lo lp lq lr ls lt lu lv ij bi translated">你为什么要为乔治·弗洛伊德的谋杀和德里的骚乱负责？</p><p id="d251" class="pw-post-body-paragraph la lb iq lc b ld le ka lf lg lh kd li lj lk ll lm ln lo lp lq lr ls lt lu lv ij bi translated"><a class="ae mb" href="https://medium.com/towards-artificial-intelligence/why-choose-random-forest-and-not-decision-trees-a28278daa5d" rel="noopener">为什么选择随机森林而不是决策树</a></p><p id="2b9e" class="pw-post-body-paragraph la lb iq lc b ld le ka lf lg lh kd li lj lk ll lm ln lo lp lq lr ls lt lu lv ij bi translated"><a class="ae mb" href="https://medium.com/@dakshtrehan/clustering-what-it-is-when-to-use-it-a612bbe95881" rel="noopener">聚类:是什么？什么时候用？</a></p><p id="fef2" class="pw-post-body-paragraph la lb iq lc b ld le ka lf lg lh kd li lj lk ll lm ln lo lp lq lr ls lt lu lv ij bi translated"><a class="ae mb" href="https://medium.com/@dakshtrehan/start-off-your-ml-journey-with-k-nearest-neighbors-f72a122f428" rel="noopener">从k个最近邻居开始你的ML旅程</a></p><p id="9630" class="pw-post-body-paragraph la lb iq lc b ld le ka lf lg lh kd li lj lk ll lm ln lo lp lq lr ls lt lu lv ij bi translated"><a class="ae mb" href="https://medium.com/swlh/things-you-never-knew-about-naive-bayes-eb84b6ee039a" rel="noopener">朴素贝叶斯解释了</a></p><p id="90f0" class="pw-post-body-paragraph la lb iq lc b ld le ka lf lg lh kd li lj lk ll lm ln lo lp lq lr ls lt lu lv ij bi translated"><a class="ae mb" href="https://medium.com/analytics-vidhya/activation-functions-explained-8690ea7bdec9" rel="noopener">激活功能说明</a></p><p id="80d8" class="pw-post-body-paragraph la lb iq lc b ld le ka lf lg lh kd li lj lk ll lm ln lo lp lq lr ls lt lu lv ij bi translated"><a class="ae mb" href="https://towardsdatascience.com/parameters-optimization-explained-876561853de0" rel="noopener" target="_blank">参数优化说明</a></p><p id="89ee" class="pw-post-body-paragraph la lb iq lc b ld le ka lf lg lh kd li lj lk ll lm ln lo lp lq lr ls lt lu lv ij bi translated"><a class="ae mb" href="https://towardsdatascience.com/gradient-descent-explained-9b953fc0d2c" rel="noopener" target="_blank">梯度下降解释</a></p><p id="81cd" class="pw-post-body-paragraph la lb iq lc b ld le ka lf lg lh kd li lj lk ll lm ln lo lp lq lr ls lt lu lv ij bi translated"><a class="ae mb" href="https://towardsdatascience.com/logistic-regression-explained-ef1d816ea85a" rel="noopener" target="_blank">逻辑回归解释</a></p><p id="11da" class="pw-post-body-paragraph la lb iq lc b ld le ka lf lg lh kd li lj lk ll lm ln lo lp lq lr ls lt lu lv ij bi translated"><a class="ae mb" href="https://medium.com/towards-artificial-intelligence/linear-regression-explained-f5cc85ae2c5c" rel="noopener">线性回归解释</a></p><p id="ce43" class="pw-post-body-paragraph la lb iq lc b ld le ka lf lg lh kd li lj lk ll lm ln lo lp lq lr ls lt lu lv ij bi translated"><a class="ae mb" href="https://medium.com/datadriveninvestor/determining-perfect-fit-for-your-ml-model-339459eef670" rel="noopener">确定最适合您的ML模型</a></p><blockquote class="oo op oq"><p id="6a6d" class="la lb mc lc b ld le ka lf lg lh kd li or lk ll lm os lo lp lq ot ls lt lu lv ij bi translated"><em class="iq">干杯！</em></p></blockquote></div></div>    
</body>
</html>