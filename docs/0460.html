<html>
<head>
<title>A Rudimentary Voice Authentication System with Mobile Deployment</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">具有移动部署的基本语音认证系统</h1>
<blockquote>原文：<a href="https://pub.towardsai.net/a-rudimentary-voice-authentication-system-with-mobile-deployment-1d41f5baa319?source=collection_archive---------3-----------------------#2020-05-04">https://pub.towardsai.net/a-rudimentary-voice-authentication-system-with-mobile-deployment-1d41f5baa319?source=collection_archive---------3-----------------------#2020-05-04</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><h2 id="e5b5" class="io ip iq bd b dl ir is it iu iv iw dk ix translated" aria-label="kicker paragraph"><a class="ae ep" href="https://towardsai.net/p/category/machine-learning" rel="noopener ugc nofollow" target="_blank">机器学习</a>，<a class="ae ep" href="https://towardsai.net/p/category/programming" rel="noopener ugc nofollow" target="_blank">编程</a></h2><div class=""/><div class=""><h2 id="8d45" class="pw-subtitle-paragraph jw iz iq bd b jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn dk translated">说话人验证、Android部署、深度学习、Web服务</h2></div><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div class="gh gi ko"><img src="../Images/e1dd4465fb1aa4aa60f36e981db1e0a1.png" data-original-src="https://miro.medium.com/v2/resize:fit:650/format:webp/1*-LkmMPFNNrZA8_UZD7ceZA.png"/></div><figcaption class="kw kx gj gh gi ky kz bd b be z dk translated">我们的Android应用</figcaption></figure><p id="db53" class="pw-post-body-paragraph la lb iq lc b ld le ka lf lg lh kd li lj lk ll lm ln lo lp lq lr ls lt lu lv ij bi translated">对于我在大学的Android开发课程的小组项目组件，我们的团队构建并部署了一个身份验证系统，该系统通过说话者的语音档案进行身份验证。</p><p id="7869" class="pw-post-body-paragraph la lb iq lc b ld le ka lf lg lh kd li lj lk ll lm ln lo lp lq lr ls lt lu lv ij bi translated">随着口罩在这个新冠肺炎季节成为常态，依靠个人声音档案的认证系统可能比依靠面部识别的系统更有用。</p><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div role="button" tabindex="0" class="lx ly di lz bf ma"><div class="gh gi lw"><img src="../Images/c37d3993277cf9f78b233c8026773a7c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*Si_FvceD-T_pNTQl"/></div></div><figcaption class="kw kx gj gh gi ky kz bd b be z dk translated">通过遮住半张脸来克服面部识别系统(照片由<a class="ae mb" href="https://unsplash.com/@golfarisa?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">阿里萨·查塔萨</a>在<a class="ae mb" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上拍摄)</figcaption></figure></div><div class="ab cl mc md hu me" role="separator"><span class="mf bw bk mg mh mi"/><span class="mf bw bk mg mh mi"/><span class="mf bw bk mg mh"/></div><div class="ij ik il im in"><p id="b62b" class="pw-post-body-paragraph la lb iq lc b ld le ka lf lg lh kd li lj lk ll lm ln lo lp lq lr ls lt lu lv ij bi translated">在这篇短文中，我将描述语音认证系统的不同部分，以及我们在这个过程中做出的一些设计选择。</p><p id="978a" class="pw-post-body-paragraph la lb iq lc b ld le ka lf lg lh kd li lj lk ll lm ln lo lp lq lr ls lt lu lv ij bi translated">下面是这篇文章的概述:</p><ul class=""><li id="c7e5" class="mj mk iq lc b ld le lg lh lj ml ln mm lr mn lv mo mp mq mr bi translated">语音认证服务概述</li><li id="9b98" class="mj mk iq lc b ld ms lg mt lj mu ln mv lr mw lv mo mp mq mr bi translated">用户注册概述</li><li id="b629" class="mj mk iq lc b ld ms lg mt lj mu ln mv lr mw lv mo mp mq mr bi translated">用户验证概述</li><li id="01f7" class="mj mk iq lc b ld ms lg mt lj mu ln mv lr mw lv mo mp mq mr bi translated">挑战和设计决策</li><li id="f566" class="mj mk iq lc b ld ms lg mt lj mu ln mv lr mw lv mo mp mq mr bi translated">演示视频</li></ul><p id="bca0" class="pw-post-body-paragraph la lb iq lc b ld le ka lf lg lh kd li lj lk ll lm ln lo lp lq lr ls lt lu lv ij bi translated">大部分细节都是关于高层架构和移动应用部署的。</p><p id="a0cd" class="pw-post-body-paragraph la lb iq lc b ld le ka lf lg lh kd li lj lk ll lm ln lo lp lq lr ls lt lu lv ij bi translated">关于深度学习模型的细节可以在我的另一篇文章中找到(<a class="ae mb" href="https://medium.com/@ongkoonhan.lovefad/training-a-rudimentary-speaker-verification-model-with-contrastive-learning-186408a752ce" rel="noopener">用对比学习训练基本的说话人确认模型</a>)。</p></div><div class="ab cl mc md hu me" role="separator"><span class="mf bw bk mg mh mi"/><span class="mf bw bk mg mh mi"/><span class="mf bw bk mg mh"/></div><div class="ij ik il im in"><h1 id="094d" class="mx my iq bd mz na nb nc nd ne nf ng nh kf ni kg nj ki nk kj nl kl nm km nn no bi translated">语音认证服务概述</h1><p id="bb62" class="pw-post-body-paragraph la lb iq lc b ld np ka lf lg nq kd li lj nr ll lm ln ns lp lq lr nt lt lu lv ij bi translated">语音认证系统由几个主要组件组成:</p><p id="8b24" class="pw-post-body-paragraph la lb iq lc b ld le ka lf lg lh kd li lj lk ll lm ln lo lp lq lr ls lt lu lv ij bi translated"><strong class="lc ja">手机应用/客户端</strong> —提供认证服务的手机应用。可以将这种认证服务想象成类似于Android手机上的“密码锁”或“模式锁”服务，只是解锁是通过对着手机的麦克风说话来完成的。这在理论上可以被修改以用于任何其他需要认证功能的移动应用之上。</p><p id="6bdf" class="pw-post-body-paragraph la lb iq lc b ld le ka lf lg lh kd li lj lk ll lm ln lo lp lq lr ls lt lu lv ij bi translated"><strong class="lc ja">语音认证服务器</strong> —提供基于语音的认证的web服务器。web服务器托管深度学习(DL)模型，该模型赋予系统语音验证能力。DL模型通过确定两个输入语音记录是否来自同一个人来工作。</p><p id="447c" class="pw-post-body-paragraph la lb iq lc b ld le ka lf lg lh kd li lj lk ll lm ln lo lp lq lr ls lt lu lv ij bi translated"><strong class="lc ja">语音认证深度学习模型</strong> —与当今许多其他分类问题一样，复杂输入(如语音音频信号)的大多数问题都可以通过深度学习来解决。深度学习(DL)模型是离线训练的，然后部署到web服务器上，这意味着它可以随时在web服务器上重新训练和更新。DL模型的更多细节可以在<a class="ae mb" href="https://medium.com/@ongkoonhan.lovefad/training-a-rudimentary-speaker-verification-model-with-contrastive-learning-186408a752ce" rel="noopener">我的另一篇文章</a>中找到。</p><h1 id="f60a" class="mx my iq bd mz na nu nc nd ne nv ng nh kf nw kg nj ki nx kj nl kl ny km nn no bi translated">用户注册概述</h1><p id="a8fd" class="pw-post-body-paragraph la lb iq lc b ld np ka lf lg nq kd li lj nr ll lm ln ns lp lq lr nt lt lu lv ij bi translated">与所有认证服务一样，给定用户的“密码”需要首先在系统中注册。</p><p id="4e5b" class="pw-post-body-paragraph la lb iq lc b ld le ka lf lg lh kd li lj lk ll lm ln lo lp lq lr ls lt lu lv ij bi translated">对于我们的系统，用户首先注册一个配置文件，然后提供一个语音样本，作为以后认证时的参考。</p><ol class=""><li id="2b52" class="mj mk iq lc b ld le lg lh lj ml ln mm lr mn lv nz mp mq mr bi translated"><strong class="lc ja">用户资料注册(黑色)</strong></li><li id="bf89" class="mj mk iq lc b ld ms lg mt lj mu ln mv lr mw lv nz mp mq mr bi translated"><strong class="lc ja">用户语音参考捕获(红色)</strong></li></ol><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div role="button" tabindex="0" class="lx ly di lz bf ma"><div class="gh gi oa"><img src="../Images/e1f6ee8485c15498325a1d2689b6fbfb.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*W-gDDveoQhRQ1MmDm320qw.png"/></div></div></figure><p id="c105" class="pw-post-body-paragraph la lb iq lc b ld le ka lf lg lh kd li lj lk ll lm ln lo lp lq lr ls lt lu lv ij bi translated">用户在Android应用程序上注册一个新的个人资料，提供一些基本的个人信息(用户名等。)并将配置文件保存到Firebase数据库中。然后，Android应用程序会提示用户提交一个语音样本(参考样本)，该样本会保存到Firebase存储中(Firebase上的文件存储)。</p><h1 id="55bd" class="mx my iq bd mz na nu nc nd ne nv ng nh kf nw kg nj ki nx kj nl kl ny km nn no bi translated"><strong class="ak">用户认证概述</strong></h1><p id="6f70" class="pw-post-body-paragraph la lb iq lc b ld np ka lf lg nq kd li lj nr ll lm ln ns lp lq lr nt lt lu lv ij bi translated">与所有认证服务一样，在认证期间提供“密码”，并且该服务检查给定的密码是否与用户先前设置的存储的参考密码相匹配。</p><p id="6895" class="pw-post-body-paragraph la lb iq lc b ld le ka lf lg lh kd li lj lk ll lm ln lo lp lq lr ls lt lu lv ij bi translated">对于我们的系统，用户“登录”到他注册的个人资料，并提供一个现场语音样本进行认证。系统将该现场语音样本与先前提供的参考语音样本进行比较，并确定这两个语音样本是否来自同一个人。</p><ol class=""><li id="cb59" class="mj mk iq lc b ld le lg lh lj ml ln mm lr mn lv nz mp mq mr bi translated"><strong class="lc ja">用户档案和语音参考检索(黑色)</strong></li><li id="16d3" class="mj mk iq lc b ld ms lg mt lj mu ln mv lr mw lv nz mp mq mr bi translated"><strong class="lc ja">用户现场语音采集和认证(红色)</strong></li></ol><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div role="button" tabindex="0" class="lx ly di lz bf ma"><div class="gh gi ob"><img src="../Images/b3cc26be1b69fd6dd4823981271568ee.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*qyoubfvHTJZsjW9kDyGOMw.png"/></div></div></figure><p id="7b6f" class="pw-post-body-paragraph la lb iq lc b ld le ka lf lg lh kd li lj lk ll lm ln lo lp lq lr ls lt lu lv ij bi translated">用户通过在Android应用程序上提供用户名来“登录”他的注册资料，应用程序检查Firebase数据库上是否存在该用户。然后，从Firebase存储中下载该配置文件的参考语音样本，并提示用户提供一个现场语音样本。然后，Android应用程序将参考语音样本和现场语音样本都传递到web服务器，在web服务器上，DL模型会比较这两个语音样本，并确定它们是否来自同一个人。来自DL模型的肯定或否定结果然后被返回给Android应用程序。</p></div><div class="ab cl mc md hu me" role="separator"><span class="mf bw bk mg mh mi"/><span class="mf bw bk mg mh mi"/><span class="mf bw bk mg mh"/></div><div class="ij ik il im in"><h1 id="c35d" class="mx my iq bd mz na nb nc nd ne nf ng nh kf ni kg nj ki nk kj nl kl nm km nn no bi translated">挑战和设计决策</h1><p id="e271" class="pw-post-body-paragraph la lb iq lc b ld np ka lf lg nq kd li lj nr ll lm ln ns lp lq lr nt lt lu lv ij bi translated">没有一个软件工程项目是免于挑战的，为了平衡不同的目标，总要做出妥协。</p><h1 id="b12d" class="mx my iq bd mz na nu nc nd ne nv ng nh kf nw kg nj ki nx kj nl kl ny km nn no bi translated"><strong class="ak">py torch优于TensorFlow Lite的选择</strong></h1><p id="32a5" class="pw-post-body-paragraph la lb iq lc b ld np ka lf lg nq kd li lj nr ll lm ln ns lp lq lr nt lt lu lv ij bi translated">在项目的初始阶段，我实际上开始在Keras (TensorFlow)中构建DL模型。我们很快发现了在Android环境中部署TensorFlow Lite模型的困难。我们在网上看到的所有教程似乎都使用了谷歌提供的预训练TensorFlow Lite模型，我们没有看到任何教程部署定制模型。我还担心由于操作码不可用而卡住的可怕情况。</p><p id="99aa" class="pw-post-body-paragraph la lb iq lc b ld le ka lf lg lh kd li lj lk ll lm ln lo lp lq lr ls lt lu lv ij bi translated">另一方面，PyTorch在其网站上展示了如何立即追踪给定的模型。尽管跟踪有一些限制，但是当模型中的数据流很简单(从没有控制流的意义上来说)并且您坚持使用PyTorch张量和模块时，它将会工作。</p><p id="4604" class="pw-post-body-paragraph la lb iq lc b ld le ka lf lg lh kd li lj lk ll lm ln lo lp lq lr ls lt lu lv ij bi translated">我专注于概念化我的DL模型的高层架构，并快速训练一个在Android环境中测试它。基本模型在Android环境中工作的事实给了我继续投入更多时间和精力来改进模型性能的信心(同时坚持高层架构)。</p><p id="994e" class="pw-post-body-paragraph la lb iq lc b ld le ka lf lg lh kd li lj lk ll lm ln lo lp lq lr ls lt lu lv ij bi translated">只要经过训练的模型可以在Android上运行，我就可以关注以下内容，因为这对PyTorch脚本编写过程的影响很小(或者根本没有影响):</p><ul class=""><li id="27a6" class="mj mk iq lc b ld le lg lh lj ml ln mm lr mn lv mo mp mq mr bi translated">玩弄学习率</li><li id="864a" class="mj mk iq lc b ld ms lg mt lj mu ln mv lr mw lv mo mp mq mr bi translated">在分类器中堆叠更多层</li><li id="18b8" class="mj mk iq lc b ld ms lg mt lj mu ln mv lr mw lv mo mp mq mr bi translated">玩激活功能</li><li id="65af" class="mj mk iq lc b ld ms lg mt lj mu ln mv lr mw lv mo mp mq mr bi translated">调整数据采样方法</li><li id="a89b" class="mj mk iq lc b ld ms lg mt lj mu ln mv lr mw lv mo mp mq mr bi translated">对我的编码器使用不同的基本模型(迁移学习)</li><li id="564a" class="mj mk iq lc b ld ms lg mt lj mu ln mv lr mw lv mo mp mq mr bi translated">等等。</li></ul><h1 id="1a72" class="mx my iq bd mz na nu nc nd ne nv ng nh kf nw kg nj ki nx kj nl kl ny km nn no bi translated">为什么是Web服务？</h1><p id="e58c" class="pw-post-body-paragraph la lb iq lc b ld np ka lf lg nq kd li lj nr ll lm ln ns lp lq lr nt lt lu lv ij bi translated">在我们最初的设计中，团队希望构建一个完全原生的Android应用程序来执行语音认证。</p><p id="44cc" class="pw-post-body-paragraph la lb iq lc b ld le ka lf lg lh kd li lj lk ll lm ln lo lp lq lr ls lt lu lv ij bi translated"><strong class="lc ja">Android缺乏音频信号设施</strong> — Android可以处理、读取和播放大量媒体文件和文件格式。Android也可以将手机上的媒体输入存储成各种文件格式。</p><p id="7611" class="pw-post-body-paragraph la lb iq lc b ld le ka lf lg lh kd li lj lk ll lm ln lo lp lq lr ls lt lu lv ij bi translated">我需要的一个关键的东西是将音频文件转换成音频信号或字节流，这是Android没有提供的。Android Java子集中没有Javax Sound音频处理库，这也没有帮助。</p><p id="c1e4" class="pw-post-body-paragraph la lb iq lc b ld le ka lf lg lh kd li lj lk ll lm ln lo lp lq lr ls lt lu lv ij bi translated">在浏览了无数关于如何解析的网站后？wav文件以及如何管理采样率，随着项目截止日期的临近，我们认为这不值得我们浪费时间。</p><p id="32fb" class="pw-post-body-paragraph la lb iq lc b ld le ka lf lg lh kd li lj lk ll lm ln lo lp lq lr ls lt lu lv ij bi translated"><strong class="lc ja">缺乏Java中的信号处理库</strong>——在为DL模型构建数据预处理管道时，我非常依赖Python LibROSA (Librosa)库。Librosa自动处理许多音频处理任务，如自动向下采样或向上采样到目标频率(这是DL模型分析音频频谱图的关键)，以及创建melfilterbanks和melspectrograms。</p><p id="447b" class="pw-post-body-paragraph la lb iq lc b ld le ka lf lg lh kd li lj lk ll lm ln lo lp lq lr ls lt lu lv ij bi translated">我们希望使用Chaquopy库来自动将使用Librosa的Python代码转换成Java兼容的格式，但是Librosa库没有得到Chaquopy的正确支持(Numpy是支持的，但是我认为SciPy没有得到完全支持)。</p><p id="5163" class="pw-post-body-paragraph la lb iq lc b ld le ka lf lg lh kd li lj lk ll lm ln lo lp lq lr ls lt lu lv ij bi translated">虽然我们确实发现Github库已经在纯Java中手动重新创建了“类似Librosa”的函数，但Java中缺乏良好的信号处理库仍然迫使我们手动处理信号处理步骤。</p><p id="fa8d" class="pw-post-body-paragraph la lb iq lc b ld le ka lf lg lh kd li lj lk ll lm ln lo lp lq lr ls lt lu lv ij bi translated">Python中的Web服务——最终，我们放弃了在Android环境中部署我们的模型的计划。</p><p id="2fb1" class="pw-post-body-paragraph la lb iq lc b ld le ka lf lg lh kd li lj lk ll lm ln lo lp lq lr ls lt lu lv ij bi translated">相反，我们决定改变我们的方法，将DL模型托管在一个由Flask支持的web服务器上。因为我们可以在Python环境中工作，所以将DL模型包装成web服务非常简单，我们专注于用这个web服务制作我们的Android手机界面。管理Firebase存储和本地Android文件存储上的文件本身是另一个挑战，但这是一个更容易管理的挑战。</p><p id="9ec2" class="pw-post-body-paragraph la lb iq lc b ld le ka lf lg lh kd li lj lk ll lm ln lo lp lq lr ls lt lu lv ij bi translated">由于这些挑战，我们被迫分离我们的语音认证服务和我们的Android认证应用，从而形成了这种架构。</p><h1 id="9b30" class="mx my iq bd mz na nu nc nd ne nv ng nh kf nw kg nj ki nx kj nl kl ny km nn no bi translated">模型尺寸限制</h1><p id="7254" class="pw-post-body-paragraph la lb iq lc b ld np ka lf lg nq kd li lj nr ll lm ln ns lp lq lr nt lt lu lv ij bi translated">DL模型是在我的本地机器上训练和托管的，这台机器有一个带3GB VRAM的GPU。虽然这足以让模型为预测而训练和托管，但我可以使用的基本模型的大小是有限的。</p><p id="28f6" class="pw-post-body-paragraph la lb iq lc b ld le ka lf lg lh kd li lj lk ll lm ln lo lp lq lr ls lt lu lv ij bi translated">假设我们最初想在移动电话上部署语音认证DL模型，我们从最紧凑的图像模型MobileNetV2开始，这是由Google创建的模型，旨在用于资源有限的环境。</p><p id="4bdb" class="pw-post-body-paragraph la lb iq lc b ld le ka lf lg lh kd li lj lk ll lm ln lo lp lq lr ls lt lu lv ij bi translated">当我们决定将DL模型作为web服务托管时，我将基本模型更改为DenseNet121，这是我的(小)GPU可以容纳的最大模型。更强大的基本模型显著提高了语音认证DL模型的分类性能，但我最终受到了GPU VRAM大小的限制。遗憾的是，即使是像ResNet或ResNeXt这样的大型模型也无法使用。</p></div><div class="ab cl mc md hu me" role="separator"><span class="mf bw bk mg mh mi"/><span class="mf bw bk mg mh mi"/><span class="mf bw bk mg mh"/></div><div class="ij ik il im in"><h1 id="a8ff" class="mx my iq bd mz na nb nc nd ne nf ng nh kf ni kg nj ki nk kj nl kl nm km nn no bi translated">演示视频</h1><p id="e54a" class="pw-post-body-paragraph la lb iq lc b ld np ka lf lg nq kd li lj nr ll lm ln ns lp lq lr nt lt lu lv ij bi translated">这是我们录制的现场演示(原谅我们的新加坡口音😄).尽情享受吧！</p><figure class="kp kq kr ks gt kt"><div class="bz fp l di"><div class="oc od l"/></div></figure><p id="f9e2" class="pw-post-body-paragraph la lb iq lc b ld le ka lf lg lh kd li lj lk ll lm ln lo lp lq lr ls lt lu lv ij bi translated">感谢我的团队，他们付出了难以置信的努力，把看似不可能的事情变成了可能:吴清辉、沈伟明、何以成</p></div></div>    
</body>
</html>