<html>
<head>
<title>35 Words About Uncertainty, Every AI-Savvy Leader Must Know</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">关于不确定性的35个词，每个精通人工智能的领导者都必须知道</h1>
<blockquote>原文：<a href="https://pub.towardsai.net/ai-uncertainty-4ac6810899ac?source=collection_archive---------2-----------------------#2020-05-01">https://pub.towardsai.net/ai-uncertainty-4ac6810899ac?source=collection_archive---------2-----------------------#2020-05-01</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><h2 id="f6c2" class="io ip iq bd b dl ir is it iu iv iw dk ix translated" aria-label="kicker paragraph">人工智能</h2><div class=""/><div class=""><h2 id="74c8" class="pw-subtitle-paragraph jw iz iq bd b jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn dk translated">你能解释这些吗？检验你的知识！</h2></div><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div role="button" tabindex="0" class="ku kv di kw bf kx"><div class="gh gi ko"><img src="../Images/b94b54dbb3645bdac2bbbe8f1dd468bf.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Tbl2BQJQwUupnUqTOd55KA.jpeg"/></div></div></figure><p id="200e" class="pw-post-body-paragraph la lb iq lc b ld le ka lf lg lh kd li lj lk ll lm ln lo lp lq lr ls lt lu lv ij bi translated"><em class="lw">【这是</em> <strong class="lc ja"> <em class="lw">系列</em> </strong> <em class="lw">的第3部。继续之前，请确保您阅读了关于</em> <a class="ae lx" href="https://medium.com/towards-artificial-intelligence/ai-search-e0cb610237f6" rel="noopener"> <em class="lw">搜索</em> </a> <em class="lw">和</em> <a class="ae lx" href="https://medium.com/towards-artificial-intelligence/ai-knowledge-1020a00eb45d" rel="noopener"> <em class="lw">知识</em> </a> <em class="lw">。未来课题包括</em> <a class="ae lx" href="https://medium.com/towards-artificial-intelligence/ai-optimization-b8735dc09448" rel="noopener"> <em class="lw">优化</em></a><em class="lw"/><a class="ae lx" href="https://medium.com/towards-artificial-intelligence/ai-learning-2eaea82ee6d" rel="noopener"><em class="lw">机器学习</em></a><em class="lw"/><a class="ae lx" href="https://medium.com/towards-artificial-intelligence/26-words-about-neural-networks-every-ai-neural-networks-1085bd972fd5" rel="noopener"><em class="lw">神经网络</em> </a> <em class="lw">，以及</em> <a class="ae lx" href="https://medium.com/towards-artificial-intelligence/ai-language-1d266caa72c6" rel="noopener"> <em class="lw">语言</em> </a> <em class="lw">。】</em></p><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div role="button" tabindex="0" class="ku kv di kw bf kx"><div class="gh gi ly"><img src="../Images/6bca0797413f4c5c38401aa0e0c97611.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*I0zg8w3dwy-EtQCzTzMmkg.png"/></div></div></figure><p id="c0d7" class="pw-post-body-paragraph la lb iq lc b ld le ka lf lg lh kd li lj lk ll lm ln lo lp lq lr ls lt lu lv ij bi translated"><strong class="lc ja"> <em class="lw">围绕人工智能的不确定性是双重的</em>。</strong></p><p id="96f7" class="pw-post-body-paragraph la lb iq lc b ld le ka lf lg lh kd li lj lk ll lm ln lo lp lq lr ls lt lu lv ij bi translated"><strong class="lc ja"> <em class="lw">首先</em> </strong>，对于如何实际应用AI，我们还是知之甚少。<em class="lw">哪些技术最适合解决哪些问题？</em> <em class="lw">价值链的哪些部分从AI中受益最大？哪些技术技能在五年内是相关的？</em></p><p id="d587" class="pw-post-body-paragraph la lb iq lc b ld le ka lf lg lh kd li lj lk ll lm ln lo lp lq lr ls lt lu lv ij bi translated">为了获得这三个问题的潜在答案的初步想法，考虑跟随这个<a class="ae lx" href="https://www.mckinsey.com/business-functions/organization/our-insights/the-organization-blog/embrace-the-uncertainty-of-ai" rel="noopener ugc nofollow" target="_blank">麦肯锡资源</a>中的兔子洞。</p><p id="569c" class="pw-post-body-paragraph la lb iq lc b ld le ka lf lg lh kd li lj lk ll lm ln lo lp lq lr ls lt lu lv ij bi translated"><strong class="lc ja"> <em class="lw">其次</em> </strong>，计算机经常要处理不完美、不完整、甚至不确定的信息。这种约束要求人工智能只能以一定的概率“相信”某事。这就是我们关心的<strong class="lc ja"> <em class="lw">不确定性</em> </strong>的类型。为了让您入门，本文简要定义了<strong class="lc ja"> <em class="lw">的主要概念和术语。</em> </strong></p></div><div class="ab cl lz ma hu mb" role="separator"><span class="mc bw bk md me mf"/><span class="mc bw bk md me mf"/><span class="mc bw bk md me"/></div><div class="ij ik il im in"><h1 id="3c88" class="mg mh iq bd mi mj mk ml mm mn mo mp mq kf mr kg ms ki mt kj mu kl mv km mw mx bi translated">不确定</h1><p id="ee2b" class="pw-post-body-paragraph la lb iq lc b ld my ka lf lg mz kd li lj na ll lm ln nb lp lq lr nc lt lu lv ij bi translated">不确定性:涉及不完善或未知信息的情况</p><p id="a18a" class="pw-post-body-paragraph la lb iq lc b ld le ka lf lg lh kd li lj lk ll lm ln lo lp lq lr ls lt lu lv ij bi translated">概率:对一个事件发生的可能性或一个命题为真的数值描述</p><p id="3806" class="pw-post-body-paragraph la lb iq lc b ld le ka lf lg lh kd li lj lk ll lm ln lo lp lq lr ls lt lu lv ij bi translated"><strong class="lc ja">可能世界:</strong>给定一种情况下可能发生的事件，例如，掷骰子得到‘1’；用字母表示:</p><pre class="kp kq kr ks gt nd ne nf ng aw nh bi"><span id="6bd9" class="ni mh iq ne b gy nj nk l nl nm">ω</span></pre><p id="0f14" class="pw-post-body-paragraph la lb iq lc b ld le ka lf lg lh kd li lj lk ll lm ln lo lp lq lr ls lt lu lv ij bi translated"><strong class="lc ja">所有可能世界的集合:</strong>所有可能世界的组合，加起来等于一；例如，当掷骰子时得到‘1、2、3、4、5或6’；用字母表示:</p><pre class="kp kq kr ks gt nd ne nf ng aw nh bi"><span id="46bd" class="ni mh iq ne b gy nj nk l nl nm">Ω<br/>P(ω)</span></pre><p id="12a4" class="pw-post-body-paragraph la lb iq lc b ld le ka lf lg lh kd li lj lk ll lm ln lo lp lq lr ls lt lu lv ij bi translated"><strong class="lc ja">可能性范围:</strong>‘0’表示某事件肯定不会发生，而‘1’表示某事件绝对会发生，记为:</p><pre class="kp kq kr ks gt nd ne nf ng aw nh bi"><span id="cabd" class="ni mh iq ne b gy nj nk l nl nm">0 ≤ P(ω) ≤ 1</span></pre><p id="3603" class="pw-post-body-paragraph la lb iq lc b ld le ka lf lg lh kd li lj lk ll lm ln lo lp lq lr ls lt lu lv ij bi translated"><strong class="lc ja">无条件概率:</strong>在没有任何其他证据的情况下，对一个命题的相信程度</p><p id="cabc" class="pw-post-body-paragraph la lb iq lc b ld le ka lf lg lh kd li lj lk ll lm ln lo lp lq lr ls lt lu lv ij bi translated"><strong class="lc ja">条件概率:</strong>在给定一些已经揭示的证据的情况下，对一个命题的相信程度；给定“昨天下雨”的情况下，“今天下雨”的概率:</p><pre class="kp kq kr ks gt nd ne nf ng aw nh bi"><span id="b04d" class="ni mh iq ne b gy nj nk l nl nm">P(a|b) (probability of a given b), <br/>P(rain today|rain yesterday)</span><span id="b3f9" class="ni mh iq ne b gy nn nk l nl nm">P(a|b)     =   [P(a ∧ b)] / P(b)<br/>P(a ∧ b)   =   P(b) P(a|b)<br/>P(a ∧ b)   =   P(a) P(b|a)</span></pre><p id="8feb" class="pw-post-body-paragraph la lb iq lc b ld le ka lf lg lh kd li lj lk ll lm ln lo lp lq lr ls lt lu lv ij bi translated"><strong class="lc ja">随机变量:</strong>概率理论中的一个变量，有一个可能取值的范围，例如:</p><pre class="kp kq kr ks gt nd ne nf ng aw nh bi"><span id="a29c" class="ni mh iq ne b gy nj nk l nl nm">Weather<br/>{sun, cloud, rain, wind, snow}</span></pre><p id="d3b1" class="pw-post-body-paragraph la lb iq lc b ld le ka lf lg lh kd li lj lk ll lm ln lo lp lq lr ls lt lu lv ij bi translated"><strong class="lc ja">概率分布:</strong>提供不同可能结果发生概率的数学函数，例如:</p><pre class="kp kq kr ks gt nd ne nf ng aw nh bi"><span id="205a" class="ni mh iq ne b gy nj nk l nl nm">P(Flight = on time)   =  0.6 <br/>P(Flight = delayed)   =  0.3 <br/>P(Flight = cancelled) =  0.1</span><span id="57a2" class="ni mh iq ne b gy nn nk l nl nm">or:</span><span id="a637" class="ni mh iq ne b gy nn nk l nl nm">P(Flight) = ⟨0.6, 0.3, 0.1⟩</span></pre><p id="dff4" class="pw-post-body-paragraph la lb iq lc b ld le ka lf lg lh kd li lj lk ll lm ln lo lp lq lr ls lt lu lv ij bi translated"><strong class="lc ja">独立性:</strong>知道一个事件发生并不影响另一个事件的概率</p><pre class="kp kq kr ks gt nd ne nf ng aw nh bi"><span id="c80e" class="ni mh iq ne b gy nj nk l nl nm">P(a ∧ b) = P(a)P(b|a) or<br/>P(a ∧ b) = P(a)P(b)</span></pre><p id="7dbf" class="pw-post-body-paragraph la lb iq lc b ld le ka lf lg lh kd li lj lk ll lm ln lo lp lq lr ls lt lu lv ij bi translated"><strong class="lc ja">贝叶斯法则:</strong>(或称贝叶斯定理)概率论中最重要的法则之一，描述一个事件发生的概率，以可能相关的条件的先验知识为基础:</p><pre class="kp kq kr ks gt nd ne nf ng aw nh bi"><span id="3daa" class="ni mh iq ne b gy nj nk l nl nm">P(b|a) = [P(b) P(a|b)] / P(a)</span></pre><p id="f5a9" class="pw-post-body-paragraph la lb iq lc b ld le ka lf lg lh kd li lj lk ll lm ln lo lp lq lr ls lt lu lv ij bi translated">因此，知道…</p><pre class="kp kq kr ks gt nd ne nf ng aw nh bi"><span id="a6d9" class="ni mh iq ne b gy nj nk l nl nm">P(cloudy morning | rainy afternoon)</span></pre><p id="0e47" class="pw-post-body-paragraph la lb iq lc b ld le ka lf lg lh kd li lj lk ll lm ln lo lp lq lr ls lt lu lv ij bi translated">…我们可以计算:</p><pre class="kp kq kr ks gt nd ne nf ng aw nh bi"><span id="2e7a" class="ni mh iq ne b gy nj nk l nl nm">P(rainy afternoon | cloudy morning)<br/>P(rain|clouds) = [ P(clouds|rain)P(rain) ] / P(clouds)</span></pre><p id="f6c9" class="pw-post-body-paragraph la lb iq lc b ld le ka lf lg lh kd li lj lk ll lm ln lo lp lq lr ls lt lu lv ij bi translated"><strong class="lc ja">联合概率:</strong>两件事同时发生的可能性</p><pre class="kp kq kr ks gt nd ne nf ng aw nh bi"><span id="f794" class="ni mh iq ne b gy nj nk l nl nm">P(a,b) = P(a) * P(9)</span></pre><p id="4bfd" class="pw-post-body-paragraph la lb iq lc b ld le ka lf lg lh kd li lj lk ll lm ln lo lp lq lr ls lt lu lv ij bi translated"><strong class="lc ja">概率规则:</strong>一些用于计算不同概率的代数运算，包括否定、包含-排斥、边缘化或条件作用</p><p id="5808" class="pw-post-body-paragraph la lb iq lc b ld le ka lf lg lh kd li lj lk ll lm ln lo lp lq lr ls lt lu lv ij bi translated"><strong class="lc ja">否定:</strong>一个简便的概率规则，用来计算一个事件不发生的概率，例如:</p><pre class="kp kq kr ks gt nd ne nf ng aw nh bi"><span id="36f1" class="ni mh iq ne b gy nj nk l nl nm">P(¬cloud) = 1 − P(cloud)</span></pre><p id="aca7" class="pw-post-body-paragraph la lb iq lc b ld le ka lf lg lh kd li lj lk ll lm ln lo lp lq lr ls lt lu lv ij bi translated"><strong class="lc ja">包含-排除:</strong>另一个概率规则，它排除了计算事件a或b的概率的重复计算:</p><pre class="kp kq kr ks gt nd ne nf ng aw nh bi"><span id="af41" class="ni mh iq ne b gy nj nk l nl nm">P(a ∨ b) = P(a) + P(b) − P(a ∧ b)</span></pre><p id="750f" class="pw-post-body-paragraph la lb iq lc b ld le ka lf lg lh kd li lj lk ll lm ln lo lp lq lr ls lt lu lv ij bi translated"><strong class="lc ja">边缘化:</strong>一个非常有用的概率规则(更多细节<a class="ae lx" href="https://towardsdatascience.com/probability-concepts-explained-marginalisation-2296846344fc" rel="noopener" target="_blank">此处</a>作者<a class="no np ep" href="https://medium.com/u/c6ab8048de41?source=post_page-----4ac6810899ac--------------------------------" rel="noopener" target="_blank"> Jonny Brooks-Bartlett </a></p><pre class="kp kq kr ks gt nd ne nf ng aw nh bi"><span id="7fb5" class="ni mh iq ne b gy nj nk l nl nm">P(a) = P(a, b) + P(a, ¬b)</span></pre><p id="b595" class="pw-post-body-paragraph la lb iq lc b ld le ka lf lg lh kd li lj lk ll lm ln lo lp lq lr ls lt lu lv ij bi translated"><strong class="lc ja">条件作用:</strong>我们的最终概率规则，意味着如果我们有两个事件(a和b)，我们可以访问它们的条件概率，而不是它们的联合概率:</p><pre class="kp kq kr ks gt nd ne nf ng aw nh bi"><span id="0b40" class="ni mh iq ne b gy nj nk l nl nm">P(a) = P(a|b)P(b) + P(a|¬b)P(¬b)</span></pre><p id="b6af" class="pw-post-body-paragraph la lb iq lc b ld le ka lf lg lh kd li lj lk ll lm ln lo lp lq lr ls lt lu lv ij bi translated"><strong class="lc ja">贝叶斯网络:</strong>一种表示随机变量之间依赖关系的数据结构</p><p id="23de" class="pw-post-body-paragraph la lb iq lc b ld le ka lf lg lh kd li lj lk ll lm ln lo lp lq lr ls lt lu lv ij bi translated"><strong class="lc ja">推断:</strong>使用数据分析来推断潜在概率分布特性的过程</p><p id="7735" class="pw-post-body-paragraph la lb iq lc b ld le ka lf lg lh kd li lj lk ll lm ln lo lp lq lr ls lt lu lv ij bi translated"><strong class="lc ja">查询:</strong>要计算其分布的变量</p><p id="0bc9" class="pw-post-body-paragraph la lb iq lc b ld le ka lf lg lh kd li lj lk ll lm ln lo lp lq lr ls lt lu lv ij bi translated"><strong class="lc ja">证据变量:</strong>事件e的观察变量</p><p id="0348" class="pw-post-body-paragraph la lb iq lc b ld le ka lf lg lh kd li lj lk ll lm ln lo lp lq lr ls lt lu lv ij bi translated"><strong class="lc ja">隐藏变量:</strong>非证据，非查询变量</p><p id="3318" class="pw-post-body-paragraph la lb iq lc b ld le ka lf lg lh kd li lj lk ll lm ln lo lp lq lr ls lt lu lv ij bi translated"><strong class="lc ja">枚举推理:</strong>给定联合分布和条件概率，求解推理查询的过程</p><p id="3cd4" class="pw-post-body-paragraph la lb iq lc b ld le ka lf lg lh kd li lj lk ll lm ln lo lp lq lr ls lt lu lv ij bi translated"><strong class="lc ja">近似推断:</strong>估计解的系统迭代方法，如蒙特卡罗模拟</p><p id="8be7" class="pw-post-body-paragraph la lb iq lc b ld le ka lf lg lh kd li lj lk ll lm ln lo lp lq lr ls lt lu lv ij bi translated"><strong class="lc ja">抽样:</strong>一种使用各种概率方法从大量人口中选择样本的技术</p><p id="ebbc" class="pw-post-body-paragraph la lb iq lc b ld le ka lf lg lh kd li lj lk ll lm ln lo lp lq lr ls lt lu lv ij bi translated"><strong class="lc ja">拒绝抽样:</strong>(或接受-拒绝法)<strong class="lc ja"> </strong>从给定的分布中产生观察值的基本技术</p><p id="58b8" class="pw-post-body-paragraph la lb iq lc b ld le ka lf lg lh kd li lj lk ll lm ln lo lp lq lr ls lt lu lv ij bi translated"><strong class="lc ja">似然加权:</strong>重要性抽样的一种形式，按照预先定义的顺序对各种变量进行抽样，并使用证据来更新权重</p><p id="5256" class="pw-post-body-paragraph la lb iq lc b ld le ka lf lg lh kd li lj lk ll lm ln lo lp lq lr ls lt lu lv ij bi translated"><strong class="lc ja">马尔可夫假设:</strong>当前状态只依赖于有限固定数量的先前状态的假设</p><p id="f1cd" class="pw-post-body-paragraph la lb iq lc b ld le ka lf lg lh kd li lj lk ll lm ln lo lp lq lr ls lt lu lv ij bi translated"><strong class="lc ja">马尔可夫链:</strong>随机变量序列，其中每个变量的分布遵循马尔可夫假设</p><p id="392c" class="pw-post-body-paragraph la lb iq lc b ld le ka lf lg lh kd li lj lk ll lm ln lo lp lq lr ls lt lu lv ij bi translated"><strong class="lc ja">隐马尔可夫模型:</strong>一个系统的马尔可夫模型，该系统具有生成一些观察到的事件的隐藏状态</p><p id="12c9" class="pw-post-body-paragraph la lb iq lc b ld le ka lf lg lh kd li lj lk ll lm ln lo lp lq lr ls lt lu lv ij bi translated"><strong class="lc ja">传感器马尔可夫假设:</strong>假设证据变量只依赖于相应的状态</p><p id="cbdc" class="pw-post-body-paragraph la lb iq lc b ld le ka lf lg lh kd li lj lk ll lm ln lo lp lq lr ls lt lu lv ij bi translated"><strong class="lc ja">滤波:</strong>概率信息的实际应用:给定从开始到现在的观测值，计算出<em class="lw">当前状态</em>的分布</p><p id="7677" class="pw-post-body-paragraph la lb iq lc b ld le ka lf lg lh kd li lj lk ll lm ln lo lp lq lr ls lt lu lv ij bi translated"><strong class="lc ja">预测:</strong>概率信息的一个实际应用:给定从开始到现在的观测值，计算一个<em class="lw">未来状态</em>的分布</p><p id="2390" class="pw-post-body-paragraph la lb iq lc b ld le ka lf lg lh kd li lj lk ll lm ln lo lp lq lr ls lt lu lv ij bi translated"><strong class="lc ja">平滑:</strong>概率信息的实际应用:给定从开始到现在的观测值，计算<em class="lw">过去状态</em>的分布</p><p id="0f63" class="pw-post-body-paragraph la lb iq lc b ld le ka lf lg lh kd li lj lk ll lm ln lo lp lq lr ls lt lu lv ij bi translated"><strong class="lc ja">最可能的解释:</strong>概率信息的一个实际应用:给定从开始到现在的观测值，计算最可能的状态序列</p></div><div class="ab cl lz ma hu mb" role="separator"><span class="mc bw bk md me mf"/><span class="mc bw bk md me mf"/><span class="mc bw bk md me"/></div><div class="ij ik il im in"><blockquote class="nq"><p id="01c9" class="nr ns iq bd nt nu nv nw nx ny nz lv dk translated">"在掌握和应用人工智能的道路上，有一件事是肯定的:不确定性."</p></blockquote><p id="0b3c" class="pw-post-body-paragraph la lb iq lc b ld oa ka lf lg ob kd li lj oc ll lm ln od lp lq lr oe lt lu lv ij bi translated">既然你已经能够解释最基本的<em class="lw">不确定性</em>相关术语，你就有希望更加自如地独自探索这些概念。</p><p id="1061" class="pw-post-body-paragraph la lb iq lc b ld le ka lf lg lh kd li lj lk ll lm ln lo lp lq lr ls lt lu lv ij bi translated">这使你进入了成为一名成熟的人工智能领导者的第三阶段。探索<strong class="lc ja"> <em class="lw">类似AI相关话题</em> </strong>，包括<a class="ae lx" href="https://medium.com/towards-artificial-intelligence/ai-search-e0cb610237f6" rel="noopener"> <em class="lw">搜索</em></a><a class="ae lx" href="https://medium.com/towards-artificial-intelligence/ai-knowledge-1020a00eb45d" rel="noopener"><em class="lw">知识</em></a><a class="ae lx" href="https://medium.com/towards-artificial-intelligence/ai-optimization-b8735dc09448" rel="noopener"><em class="lw">优化</em></a><a class="ae lx" href="https://medium.com/towards-artificial-intelligence/ai-learning-2eaea82ee6d" rel="noopener"><em class="lw">机器学习</em></a><a class="ae lx" href="https://medium.com/towards-artificial-intelligence/26-words-about-neural-networks-every-ai-neural-networks-1085bd972fd5" rel="noopener"><em class="lw">神经网络</em></a><a class="ae lx" href="https://medium.com/towards-artificial-intelligence/ai-language-1d266caa72c6" rel="noopener"><em class="lw">语言</em> </a>。</p><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div role="button" tabindex="0" class="ku kv di kw bf kx"><div class="gh gi ly"><img src="../Images/6bca0797413f4c5c38401aa0e0c97611.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*I0zg8w3dwy-EtQCzTzMmkg.png"/></div></div></figure><p id="a55e" class="pw-post-body-paragraph la lb iq lc b ld le ka lf lg lh kd li lj lk ll lm ln lo lp lq lr ls lt lu lv ij bi translated"><strong class="lc ja"> <em class="lw">喜欢读什么？</em> </strong> <em class="lw"> </em> <strong class="lc ja"> <em class="lw">渴望了解更多？</em> </strong> <em class="lw"> <br/>跟我上</em> <a class="ae lx" href="https://medium.com/@yannique" rel="noopener"> <em class="lw">中</em> </a> <em class="lw">或</em><a class="ae lx" href="https://www.linkedin.com/in/yannique/" rel="noopener ugc nofollow" target="_blank"><em class="lw">LinkedIn</em></a><em class="lw">。</em></p></div><div class="ab cl lz ma hu mb" role="separator"><span class="mc bw bk md me mf"/><span class="mc bw bk md me mf"/><span class="mc bw bk md me"/></div><div class="ij ik il im in"><p id="ce81" class="pw-post-body-paragraph la lb iq lc b ld le ka lf lg lh kd li lj lk ll lm ln lo lp lq lr ls lt lu lv ij bi translated"><strong class="lc ja"> <em class="lw">关于作者:<br/> </em> </strong> Yannique Hecht作品在结合策略、客户洞察、数据、创新等领域。虽然他的职业生涯一直在航空、旅游、金融和技术行业，但他对管理充满热情。Yannique专门开发AI &amp;机器学习产品商业化的策略。</p></div></div>    
</body>
</html>