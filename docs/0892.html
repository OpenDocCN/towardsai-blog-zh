<html>
<head>
<title>How are learning Curves helpful?</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">学习曲线有什么帮助？</h1>
<blockquote>原文：<a href="https://pub.towardsai.net/learning-curves-d6cfb49908f0?source=collection_archive---------3-----------------------#2020-09-05">https://pub.towardsai.net/learning-curves-d6cfb49908f0?source=collection_archive---------3-----------------------#2020-09-05</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><h2 id="9db6" class="io ip iq bd b dl ir is it iu iv iw dk ix translated" aria-label="kicker paragraph"><a class="ae ep" href="https://towardsai.net/p/category/machine-learning" rel="noopener ugc nofollow" target="_blank">机器学习</a></h2><div class=""/><div class=""><h2 id="4f1a" class="pw-subtitle-paragraph jw iz iq bd b jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn dk translated">以正确的方式评估机器学习模型</h2></div><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div role="button" tabindex="0" class="ku kv di kw bf kx"><div class="gh gi ko"><img src="../Images/e5448e56f80b42db1efabf0c6ad4293b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*2xX8TlPO6hURgXZF"/></div></div><figcaption class="la lb gj gh gi lc ld bd b be z dk translated">由<a class="ae le" href="https://unsplash.com/@isaacmsmith?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">艾萨克·史密斯</a>在<a class="ae le" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上拍摄的照片</figcaption></figure><h2 id="2e86" class="lf lg iq bd lh li lj dn lk ll lm dp ln lo lp lq lr ls lt lu lv lw lx ly lz iw bi translated"><strong class="ak">学习曲线有助于分析机器学习模型在训练数据集的各种样本大小上的性能。</strong></h2><blockquote class="ma mb mc"><p id="ac0b" class="md me mf mg b mh mi ka mj mk ml kd mm mn mo mp mq mr ms mt mu mv mw mx my mz ij bi translated">为了理解学习曲线，很好地理解偏差-方差权衡是很重要的。你可以看看我的文章。</p></blockquote><div class="na nb gp gr nc nd"><a href="https://nvsyashwanth.github.io/machinelearningmaster/bias-variance/" rel="noopener  ugc nofollow" target="_blank"><div class="ne ab fo"><div class="nf ab ng cl cj nh"><h2 class="bd ja gy z fp ni fr fs nj fu fw iz bi translated">偏差-方差</h2><div class="nk l"><h3 class="bd b gy z fp ni fr fs nj fu fw dk translated">"避免过拟合和欠拟合的错误."</h3></div><div class="nl l"><p class="bd b dl z fp ni fr fs nj fu fw dk translated">nvsyashwanth.github.io</p></div></div><div class="nm l"><div class="nn l no np nq nm nr ky nd"/></div></div></a></div></div><div class="ab cl ns nt hu nu" role="separator"><span class="nv bw bk nw nx ny"/><span class="nv bw bk nw nx ny"/><span class="nv bw bk nw nx"/></div><div class="ij ik il im in"><h1 id="fcc7" class="nz lg iq bd lh oa ob oc lk od oe of ln kf og kg lr ki oh kj lv kl oi km lz oj bi translated">评估模型</h1><blockquote class="ok"><p id="dd0c" class="ol om iq bd on oo op oq or os ot mz dk translated">“评估模型时始终绘制学习曲线”</p></blockquote><p id="e781" class="pw-post-body-paragraph md me iq mg b mh ou ka mj mk ov kd mm lo ow mp mq ls ox mt mu lw oy mx my mz ij bi translated">好的，我们知道的基本情况是，如果一个模型在训练数据上表现很好，但泛化能力很差，那么这个模型就是<strong class="mg ja">过度拟合</strong>。如果它在这两方面都表现不佳，那么它就是<strong class="mg ja">欠匹配。</strong></p><p id="88c6" class="pw-post-body-paragraph md me iq mg b mh mi ka mj mk ml kd mm lo mo mp mq ls ms mt mu lw mw mx my mz ij bi translated">超参数的设置必须使偏差和方差尽可能低。</p><h2 id="ea5c" class="lf lg iq bd lh li lj dn lk ll lm dp ln lo lp lq lr ls lt lu lv lw lx ly lz iw bi translated">学习曲线有什么帮助？</h2><blockquote class="ok"><p id="4fa9" class="ol om iq bd on oo op oq or os ot mz dk translated">“学习曲线是模型在训练集和验证集上的性能图，是训练数据集的不同样本的函数。”</p></blockquote><p id="3a62" class="pw-post-body-paragraph md me iq mg b mh ou ka mj mk ov kd mm lo ow mp mq ls ox mt mu lw oy mx my mz ij bi translated">具体来说，学习曲线在y轴上显示训练和验证分数，在x轴上显示训练数据集的不同样本。</p><p id="3dcf" class="pw-post-body-paragraph md me iq mg b mh mi ka mj mk ml kd mm lo mo mp mq ls ms mt mu lw mw mx my mz ij bi translated">培训和验证分数可以是任何评估指标，如MSE、RMSE等。在你的训练和验证集上。</p><p id="dbad" class="pw-post-body-paragraph md me iq mg b mh mi ka mj mk ml kd mm lo mo mp mq ls ms mt mu lw mw mx my mz ij bi translated">学习曲线可用于理解模型的偏差和方差误差。</p><h2 id="1cf3" class="lf lg iq bd lh li lj dn lk ll lm dp ln lo lp lq lr ls lt lu lv lw lx ly lz iw bi translated">了解学习曲线</h2><p id="ea4c" class="pw-post-body-paragraph md me iq mg b mh oz ka mj mk pa kd mm lo pb mp mq ls pc mt mu lw pd mx my mz ij bi translated">让我们生成一些随机数据，为其拟合一个线性回归模型，并绘制用于评估模型的学习曲线。</p><pre class="kp kq kr ks gt pe pf pg ph aw pi bi"><span id="f99d" class="lf lg iq pf b gy pj pk l pl pm">from sklearn.linear_model import LinearRegression<br/>from sklearn.model_selection import train_test_split<br/>from sklearn.metrics import mean_squared_error as mse<br/>import numpy as np<br/>import seaborn as sns<br/>import matplotlib.pyplot as plt<br/>plt.style.use('seaborn')<br/>X = 1 * np.random.rand(100, 1)<br/>y = 3 +  3* X + np.random.randn(100, 1)<br/>X_train,X_val,y_train,y_val=train_test_split(X,y,test_size=0.2)<br/>regressor=LinearRegression()<br/>regressor.fit(X_train,y_train)<br/>predictions=regressor.predict(X_val)</span><span id="23a9" class="lf lg iq pf b gy pn pk l pl pm">plt.figure(1,figsize=(15,5))<br/>plt.subplot(121)<br/>plt.scatter(X,y)<br/>plt.plot(X_val,predictions,color='black')<br/>plt.title('Scikit Learn Linear Regression')</span><span id="5861" class="lf lg iq pf b gy pn pk l pl pm">train_errors=[]<br/>val_errors=[]<br/>plt.subplot(122)<br/>for i in range(1,len(X_train)):<br/>    regressor.fit(X_train[:i],y_train[:i])<br/>    train_preds=regressor.predict(X_train[:i])<br/>    val_preds=regressor.predict(X_val)<br/>    train_errors.append(mse(train_preds,y_train[:i]))<br/>    val_errors.append(mse(val_preds,y_val))<br/>plt.plot(range(1,len(X_train)),np.sqrt(train_errors),label='Training error')<br/>plt.plot(range(1,len(X_train)),np.sqrt(val_errors),label='Validation error')<br/>plt.title('Learning Curves')    <br/>plt.xlabel('Train set size')<br/>plt.ylabel('RMSE')<br/>plt.legend()<br/>plt.show()</span></pre><p id="da9e" class="pw-post-body-paragraph md me iq mg b mh mi ka mj mk ml kd mm lo mo mp mq ls ms mt mu lw mw mx my mz ij bi translated">看看上面代码的输出:</p><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div role="button" tabindex="0" class="ku kv di kw bf kx"><div class="gh gi po"><img src="../Images/f21dbe337e9e7f6fbba6390ef8309239.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*ijTORTMacGpZWc1tRCX4Ig.png"/></div></div><figcaption class="la lb gj gh gi lc ld bd b be z dk translated">左:回归线；右图:学习曲线。图片由作者提供。</figcaption></figure><p id="fa32" class="pw-post-body-paragraph md me iq mg b mh mi ka mj mk ml kd mm lo mo mp mq ls ms mt mu lw mw mx my mz ij bi translated">好吧，图像不错。但意义何在？一开始可能看起来太多了。看一看下面的步骤来理解代码和图像。</p><ol class=""><li id="0e0e" class="pp pq iq mg b mh mi mk ml lo pr ls ps lw pt mz pu pv pw px bi translated">我们生成了随机数据(X，y)。</li><li id="bec6" class="pp pq iq mg b mh py mk pz lo qa ls qb lw qc mz pu pv pw px bi translated">从相同的派生出训练和验证数据集。</li><li id="e8e6" class="pp pq iq mg b mh py mk pz lo qa ls qb lw qc mz pu pv pw px bi translated">使用Scikit Learn的LinearRegression类为我们的数据拟合一条线，这就是左边的图像所要表达的内容。</li><li id="d18d" class="pp pq iq mg b mh py mk pz lo qa ls qb lw qc mz pu pv pw px bi translated">然后，我们以与上面相同的方式拟合模型，但是这一次，我们针对训练样本大小1 -&gt;整个训练数据集大小来拟合模型。</li><li id="c07e" class="pp pq iq mg b mh py mk pz lo qa ls qb lw qc mz pu pv pw px bi translated">对于我们训练集的每个样本大小，我们对我们选择的训练样本大小和整个验证数据集进行预测。</li><li id="5b30" class="pp pq iq mg b mh py mk pz lo qa ls qb lw qc mz pu pv pw px bi translated">我们计算RMSE(均方根误差),并将其存储起来，以便以后绘图。搞定了。</li></ol><p id="de1c" class="pw-post-body-paragraph md me iq mg b mh mi ka mj mk ml kd mm lo mo mp mq ls ms mt mu lw mw mx my mz ij bi translated">我们可以看到训练和验证分数集中在一个特定的点。如右图所示，第一个收敛点w.r.t x轴大约是训练样本大小10。这意味着，超过这一点，模型将不会从增加训练样本大小中受益。考虑y轴，会聚点大约是RMSE值1。现在，这是没问题的，而且这个模型似乎可以很好地概括。</p><p id="cff8" class="pw-post-body-paragraph md me iq mg b mh mi ka mj mk ml kd mm lo mo mp mq ls ms mt mu lw mw mx my mz ij bi translated">但是，举个例子，y轴对应的收敛点的值很高(如下图所示)。这表明该模型存在高偏差。这意味着训练和验证误差很高，模型不会从增加训练样本大小中受益，从而导致拟合不足。</p><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div class="gh gi qd"><img src="../Images/9ea787de0905a666fff6d3b543129592.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*wdjLxj35npLbBLXMICa58A.png"/></div><figcaption class="la lb gj gh gi lc ld bd b be z dk translated">学习曲线。偏高。来源:<a class="ae le" href="https://www.coursera.org/learn/machine-learning?utm_source=gg&amp;utm_medium=sem&amp;utm_content=07-StanfordML-IN&amp;campaignid=1950458127&amp;adgroupid=69480953983&amp;device=c&amp;keyword=study%20machine%20learning%20online&amp;matchtype=b&amp;network=g&amp;devicemodel=&amp;adpostion=&amp;creativeid=351281535285&amp;hide_mobile_promo&amp;gclid=Cj0KCQjw7sz6BRDYARIsAPHzrNLkyWNF7MP321zRu0AVtBO6DPIqjMDX53EZpmr3ITLSxO_tFxk9xLcaAmQ4EALw_wcB" rel="noopener ugc nofollow" target="_blank">吴恩达的ML课程</a>。</figcaption></figure><p id="5e6b" class="pw-post-body-paragraph md me iq mg b mh mi ka mj mk ml kd mm lo mo mp mq ls ms mt mu lw mw mx my mz ij bi translated">另一方面，如果没有可见的收敛点(如下图所示)，这表明模型具有较高的方差和较少的数据。也就是说，验证误差可能非常高，模型会过度拟合。</p><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div class="gh gi qd"><img src="../Images/aec66cb33acb5d224a36f2eed80a30cd.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*udywvNAQ7pRbiuZmJCxjlA.png"/></div><figcaption class="la lb gj gh gi lc ld bd b be z dk translated">学习曲线。高方差。来源:<a class="ae le" href="https://www.coursera.org/learn/machine-learning?utm_source=gg&amp;utm_medium=sem&amp;utm_content=07-StanfordML-IN&amp;campaignid=1950458127&amp;adgroupid=69480953983&amp;device=c&amp;keyword=study%20machine%20learning%20online&amp;matchtype=b&amp;network=g&amp;devicemodel=&amp;adpostion=&amp;creativeid=351281535285&amp;hide_mobile_promo&amp;gclid=Cj0KCQjw7sz6BRDYARIsAPHzrNLkyWNF7MP321zRu0AVtBO6DPIqjMDX53EZpmr3ITLSxO_tFxk9xLcaAmQ4EALw_wcB" rel="noopener ugc nofollow" target="_blank">吴恩达的ML课程</a>。</figcaption></figure><h2 id="81c0" class="lf lg iq bd lh li lj dn lk ll lm dp ln lo lp lq lr ls lt lu lv lw lx ly lz iw bi translated">如何提高模型性能？</h2><p id="2bc2" class="pw-post-body-paragraph md me iq mg b mh oz ka mj mk pa kd mm lo pb mp mq ls pc mt mu lw pd mx my mz ij bi translated">在高偏差的情况下，增加特征的数量，或者减小正则化参数，从而增加模型的复杂性。</p><p id="4a89" class="pw-post-body-paragraph md me iq mg b mh mi ka mj mk ml kd mm lo mo mp mq ls ms mt mu lw mw mx my mz ij bi translated">在高方差的情况下，减少特征的数量，或者增加正则化参数，从而降低模型复杂度。要填补空白，只需增加你拥有的数据(而不是特性)。</p></div><div class="ab cl ns nt hu nu" role="separator"><span class="nv bw bk nw nx ny"/><span class="nv bw bk nw nx ny"/><span class="nv bw bk nw nx"/></div><div class="ij ik il im in"><h1 id="bcbf" class="nz lg iq bd lh oa ob oc lk od oe of ln kf og kg lr ki oh kj lv kl oi km lz oj bi translated">结论</h1><p id="5c0a" class="pw-post-body-paragraph md me iq mg b mh oz ka mj mk pa kd mm lo pb mp mq ls pc mt mu lw pd mx my mz ij bi translated">始终绘制学习曲线。对学习曲线有一个很好的理解有助于你评估你的模型和分析偏差-方差问题。希望你明白学习曲线的重要性。下一场见。</p><p id="3cef" class="pw-post-body-paragraph md me iq mg b mh mi ka mj mk ml kd mm lo mo mp mq ls ms mt mu lw mw mx my mz ij bi translated"><strong class="mg ja">原载于</strong><a class="ae le" href="https://nvsyashwanth.github.io/machinelearningmaster/learning-curves/" rel="noopener ugc nofollow" target="_blank"><strong class="mg ja">machine learning master</strong></a><strong class="mg ja">。</strong></p></div><div class="ab cl ns nt hu nu" role="separator"><span class="nv bw bk nw nx ny"/><span class="nv bw bk nw nx ny"/><span class="nv bw bk nw nx"/></div><div class="ij ik il im in"><blockquote class="ma mb mc"><p id="c6a1" class="md me mf mg b mh mi ka mj mk ml kd mm mn mo mp mq mr ms mt mu mv mw mx my mz ij bi translated">嘿，如果你喜欢这篇文章，请点击拍手按钮，分享这篇文章，以示你的支持。关注我，获取更多关于机器学习、深度学习和数据科学的文章。下一场见！T11】</p></blockquote></div><div class="ab cl ns nt hu nu" role="separator"><span class="nv bw bk nw nx ny"/><span class="nv bw bk nw nx ny"/><span class="nv bw bk nw nx"/></div><div class="ij ik il im in"><h1 id="02ef" class="nz lg iq bd lh oa ob oc lk od oe of ln kf og kg lr ki oh kj lv kl oi km lz oj bi translated">在网络上找到我</h1><p id="0c0b" class="pw-post-body-paragraph md me iq mg b mh oz ka mj mk pa kd mm lo pb mp mq ls pc mt mu lw pd mx my mz ij bi translated"><a class="ae le" href="https://nvsyashwanth.github.io/machinelearningmaster/" rel="noopener ugc nofollow" target="_blank"> <strong class="mg ja">博客</strong>:机器学习大师</a></p><p id="64c1" class="pw-post-body-paragraph md me iq mg b mh mi ka mj mk ml kd mm lo mo mp mq ls ms mt mu lw mw mx my mz ij bi translated"><a class="ae le" href="https://github.com/NvsYashwanth" rel="noopener ugc nofollow" target="_blank"> <strong class="mg ja"> GitHub简介:</strong>这是我分叉的地方</a></p><p id="fcba" class="pw-post-body-paragraph md me iq mg b mh mi ka mj mk ml kd mm lo mo mp mq ls ms mt mu lw mw mx my mz ij bi translated"><a class="ae le" href="https://www.linkedin.com/in/nvsyashwanth/" rel="noopener ugc nofollow" target="_blank"> <strong class="mg ja"> LinkedIn简介:</strong>联系和分享职业动态</a></p><p id="1200" class="pw-post-body-paragraph md me iq mg b mh mi ka mj mk ml kd mm lo mo mp mq ls ms mt mu lw mw mx my mz ij bi translated"><a class="ae le" href="https://twitter.com/YashwanthNvs" rel="noopener ugc nofollow" target="_blank"> <strong class="mg ja">推特:</strong>分享科技推特</a></p><h1 id="3d5c" class="nz lg iq bd lh oa qe oc lk od qf of ln kf qg kg lr ki qh kj lv kl qi km lz oj bi translated">谢谢你</h1></div></div>    
</body>
</html>