<html>
<head>
<title>Data Preprocessing Concepts with Python</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">Python中的数据预处理概念</h1>
<blockquote>原文：<a href="https://pub.towardsai.net/data-preprocessing-concepts-with-python-b93c63f14bb6?source=collection_archive---------0-----------------------#2021-02-27">https://pub.towardsai.net/data-preprocessing-concepts-with-python-b93c63f14bb6?source=collection_archive---------0-----------------------#2021-02-27</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><h2 id="62d1" class="ir is it bd b dl iu iv iw ix iy iz dk ja translated" aria-label="kicker paragraph"><a class="ae ep" href="https://towardsai.net/p/category/data-science" rel="noopener ugc nofollow" target="_blank">数据科学</a></h2><div class=""/><div class=""><h2 id="ed64" class="pw-subtitle-paragraph jz jc it bd b ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq dk translated">一种为机器学习估值器准备数据的稳健方法</h2></div><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi kr"><img src="../Images/fea054b96327f27fb0ece31c5c8efd41.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*3PcZ88HqowYhvcYNCQAToA.png"/></div></div><figcaption class="ld le gj gh gi lf lg bd b be z dk translated">数据预处理方法。作者的照片</figcaption></figure><p id="d975" class="pw-post-body-paragraph lh li it lj b lk ll kd lm ln lo kg lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">在本文中，我们将研究一些重要的数据预处理方法。这是一个非常重要的步骤，可视化的数据，并使其在一个合适的形式，使估计(算法)拟合良好，具有良好的准确性。</p><h2 id="3017" class="md me it bd mf mg mh dn mi mj mk dp ml lq mm mn mo lu mp mq mr ly ms mt mu iz bi translated">涵盖的主题:</h2><ol class=""><li id="aedc" class="mv mw it lj b lk mx ln my lq mz lu na ly nb mc nc nd ne nf bi translated">标准化</li><li id="8392" class="mv mw it lj b lk ng ln nh lq ni lu nj ly nk mc nc nd ne nf bi translated">使用稀疏数据和异常值进行缩放</li><li id="9b7e" class="mv mw it lj b lk ng ln nh lq ni lu nj ly nk mc nc nd ne nf bi translated">正常化</li><li id="cfd5" class="mv mw it lj b lk ng ln nh lq ni lu nj ly nk mc nc nd ne nf bi translated">分类编码</li><li id="e242" class="mv mw it lj b lk ng ln nh lq ni lu nj ly nk mc nc nd ne nf bi translated">归罪</li></ol><blockquote class="nl nm nn"><p id="e2bf" class="lh li no lj b lk ll kd lm ln lo kg lp np lr ls lt nq lv lw lx nr lz ma mb mc im bi translated"><strong class="lj jd"> <em class="it">标准化</em> </strong></p></blockquote><p id="ac1a" class="pw-post-body-paragraph lh li it lj b lk ll kd lm ln lo kg lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">标准化是处理数据点的平均值和标准偏差的过程。作为原始数据，这些值从很低到很高不等。因此，为了避免模型中的低性能，我们使用标准化。它说，平均值变成零，标准差变成一个单位。</p><p id="f199" class="pw-post-body-paragraph lh li it lj b lk ll kd lm ln lo kg lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">标准化的公式如下所示:</p><p id="79ae" class="pw-post-body-paragraph lh li it lj b lk ll kd lm ln lo kg lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated"><strong class="lj jd"> z =(特征值—均值)/标准差</strong></p><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi ns"><img src="../Images/78cbbcbf532b9f09684ecfdaafc8d611.png" data-original-src="https://miro.medium.com/v2/resize:fit:1382/format:webp/1*Ackv2fzilyjWLkhUdz-btg.png"/></div></div><figcaption class="ld le gj gh gi lf lg bd b be z dk translated">典型的均匀分布。作者的照片</figcaption></figure><p id="d6d1" class="pw-post-body-paragraph lh li it lj b lk ll kd lm ln lo kg lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">当我们使用算法来拟合我们的数据时，它假设数据是集中的，并且所有特征的方差的阶是相同的，否则估计器将不能正确预测。</p><p id="a443" class="pw-post-body-paragraph lh li it lj b lk ll kd lm ln lo kg lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">sklearn库在预处理类中有一个用StandardScaler标准化数据集的方法。</p><p id="5460" class="pw-post-body-paragraph lh li it lj b lk ll kd lm ln lo kg lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">我们使用import命令在python中使用这个特性。</p><pre class="ks kt ku kv gt nt nu nv nw aw nx bi"><span id="66e8" class="md me it nu b gy ny nz l oa ob">#Before modeling our estimator we should always some preprocessing scaling.</span><span id="fccb" class="md me it nu b gy oc nz l oa ob"># Feature Scaling<br/>from sklearn.preprocessing import StandardScaler<br/>sc = StandardScaler()<br/>X_train = sc.fit_transform(X_train)<br/>X_test = sc.transform(X_test)</span></pre><div class="od oe gp gr of og"><a rel="noopener  ugc nofollow" target="_blank" href="/z-statistics-t-statistics-p-statistics-are-still-confusing-you-87557047e20a"><div class="oh ab fo"><div class="oi ab oj cl cj ok"><h2 class="bd jd gy z fp ol fr fs om fu fw jc bi translated">Z-统计量，T-统计量，P-统计量还在迷惑你？</h2><div class="on l"><h3 class="bd b gy z fp ol fr fs om fu fw dk translated">机器学习统计学中的定义和概念</h3></div><div class="oo l"><p class="bd b dl z fp ol fr fs om fu fw dk translated">pub.towardsai.net</p></div></div><div class="op l"><div class="oq l or os ot op ou lb og"/></div></div></a></div><blockquote class="nl nm nn"><p id="c07e" class="lh li no lj b lk ll kd lm ln lo kg lp np lr ls lt nq lv lw lx nr lz ma mb mc im bi translated"><strong class="lj jd"> <em class="it">带有稀疏数据和离群值的缩放</em> </strong></p></blockquote><p id="7469" class="pw-post-body-paragraph lh li it lj b lk ll kd lm ln lo kg lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated"><strong class="lj jd">稀疏数据缩放:</strong></p><p id="8d4e" class="pw-post-body-paragraph lh li it lj b lk ll kd lm ln lo kg lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">数据的缩放是使特征值在“0”和“1”的某个范围内的另一种方式。有两种方法可以做到这一点，即MinMaxScaler和MaxAbsScaler。</p><p id="b812" class="pw-post-body-paragraph lh li it lj b lk ll kd lm ln lo kg lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">python的例子</p><pre class="ks kt ku kv gt nt nu nv nw aw nx bi"><span id="ca61" class="md me it nu b gy ny nz l oa ob">import numpy as np<br/>X_train = np.array([[ 1., 0.,  2.], [ 2.,  0.,  -1.], [ 0.,  2.,<br/>                                                             -1.]])</span><span id="7498" class="md me it nu b gy oc nz l oa ob">from sklearn.preprocessing import MinMaxScaler<br/>min_max_scaler = MinMaxScaler()</span><span id="7033" class="md me it nu b gy oc nz l oa ob">X_train_minmax = min_max_scaler.fit_transform(X_train)</span><span id="c235" class="md me it nu b gy oc nz l oa ob">print(X_train_minmax)</span><span id="dcb9" class="md me it nu b gy oc nz l oa ob">#output:<br/>array([[0.5, 0. , 1. ],<br/>       [1. , 0. , 0. ],<br/>       [0. , 1. , 0. ]])</span></pre><p id="388b" class="pw-post-body-paragraph lh li it lj b lk ll kd lm ln lo kg lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">正如我们看到的，输入值的范围是“0”和“1”。</p><p id="c2bc" class="pw-post-body-paragraph lh li it lj b lk ll kd lm ln lo kg lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">创建稀疏数据中心的缩放不是一个好主意，因为它可能会改变其结构。因此，对具有不同比例值的输入原始数据进行比例缩放是很好的。</p><p id="6092" class="pw-post-body-paragraph lh li it lj b lk ll kd lm ln lo kg lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated"><strong class="lj jd">带有异常值的缩放:</strong></p><p id="d17a" class="pw-post-body-paragraph lh li it lj b lk ll kd lm ln lo kg lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">当原始数据有许多异常值时，使用均值和方差进行缩放就不能很好地处理数据。因此，我们必须使用更稳健的方法，如四分位法(IQR)，因为异常值受均值和方差的影响。IQR的范围在25%和75%之间，其中移除了中间值并缩放了分位数范围。</p><p id="6a35" class="pw-post-body-paragraph lh li it lj b lk ll kd lm ln lo kg lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated"><code class="fe ov ow ox nu b">RobustScaler</code>取一些参数进行缩放。</p><ul class=""><li id="b30d" class="mv mw it lj b lk ll ln lo lq oy lu oz ly pa mc pb nd ne nf bi translated">第一个参数是<code class="fe ov ow ox nu b">with_centering</code>，如果为真，则在缩放之前将数据居中。</li><li id="c86b" class="mv mw it lj b lk ng ln nh lq ni lu nj ly nk mc pb nd ne nf bi translated">第二个参数是<code class="fe ov ow ox nu b">with_scaling</code>,如果为真，那么它在分位数范围内缩放数据。</li></ul><p id="846f" class="pw-post-body-paragraph lh li it lj b lk ll kd lm ln lo kg lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">python的例子</p><pre class="ks kt ku kv gt nt nu nv nw aw nx bi"><span id="27fb" class="md me it nu b gy ny nz l oa ob">from sklearn.preprocessing import RobustScaler<br/>X = [[ 1., 0.,  2.], [ 2.,  0.,  -1.], [ 0.,  2., -1.]]<br/>transformer = RobustScaler().fit(X)</span><span id="b071" class="md me it nu b gy oc nz l oa ob">transformer.transform(X)</span><span id="5c10" class="md me it nu b gy oc nz l oa ob">#output:<br/>array([[ 0.,  0.,  2.],<br/>       [ 1.,  0.,  0.],<br/>       [-1.,  2.,  0.]])</span></pre><blockquote class="nl nm nn"><p id="e78d" class="lh li no lj b lk ll kd lm ln lo kg lp np lr ls lt nq lv lw lx nr lz ma mb mc im bi translated"><strong class="lj jd"> <em class="it">正常化</em> </strong></p></blockquote><p id="9424" class="pw-post-body-paragraph lh li it lj b lk ll kd lm ln lo kg lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">这里的缩放过程是将这些值标准化为它们的单位范数。这种规范化的一个例子是MinMaxScaler。当我们处理成对形式的二次型时，这个过程是有用的，它可以是基于核的，也可以是基于点积的。</p><p id="01ae" class="pw-post-body-paragraph lh li it lj b lk ll kd lm ln lo kg lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">基于向量空间模型(即与文本数据样本相关的向量)也有助于数据过滤。</p><p id="c2ca" class="pw-post-body-paragraph lh li it lj b lk ll kd lm ln lo kg lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">两种类型的规范化如下所示:</p><ul class=""><li id="ad34" class="mv mw it lj b lk ll ln lo lq oy lu oz ly pa mc pb nd ne nf bi translated">归一化:它将输入向量缩放到单位范数。norm参数用于标准化所有非零值。它需要三个参数L1、L2和马克斯，其中L2是默认的规范。</li><li id="54b4" class="mv mw it lj b lk ng ln nh lq ni lu nj ly nk mc pb nd ne nf bi translated">规格化器:它也做同样的操作，但是在这个过程中fit方法是可选的。</li></ul><p id="eeb1" class="pw-post-body-paragraph lh li it lj b lk ll kd lm ln lo kg lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">Python的例子:</p><pre class="ks kt ku kv gt nt nu nv nw aw nx bi"><span id="51b3" class="md me it nu b gy ny nz l oa ob">from sklearn.preprocessing import normalize<br/>X = [[ 1., 0., 2.], [ 2., 0., -1.], [ 0., 2., -1.]]<br/>X_normalized = normalize(X, norm=’l2')</span><span id="6a06" class="md me it nu b gy oc nz l oa ob">print(X_normalized)</span><span id="b717" class="md me it nu b gy oc nz l oa ob">#output:<br/>array([[ 0.4472136 ,  0.        ,  0.89442719],<br/>       [ 0.89442719,  0.        , -0.4472136 ],<br/>       [ 0.        ,  0.89442719, -0.4472136 ]])</span></pre><p id="d257" class="pw-post-body-paragraph lh li it lj b lk ll kd lm ln lo kg lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">标准化器示例:</p><pre class="ks kt ku kv gt nt nu nv nw aw nx bi"><span id="9ed4" class="md me it nu b gy ny nz l oa ob">from sklearn.preprocessing import Normalizer<br/>X = [[ 1., 0., 2.], [ 2., 0., -1.], [ 0., 2., -1.]]</span><span id="d111" class="md me it nu b gy oc nz l oa ob">normalizer = preprocessing.Normalizer().fit(X)</span><span id="ffa2" class="md me it nu b gy oc nz l oa ob">normalizer.transform(X)</span><span id="2b07" class="md me it nu b gy oc nz l oa ob">#output:<br/>array([[ 0.4472136 ,  0.        ,  0.89442719],<br/>       [ 0.89442719,  0.        , -0.4472136 ],<br/>       [ 0.        ,  0.89442719, -0.4472136 ]])</span></pre><p id="7d2d" class="pw-post-body-paragraph lh li it lj b lk ll kd lm ln lo kg lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">规格化器在开始时在数据处理的流水线中是有用的。</p><p id="a0f0" class="pw-post-body-paragraph lh li it lj b lk ll kd lm ln lo kg lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">当我们使用稀疏输入时，重要的是将其转换为非CSR格式，以避免多个内存副本。CSR是压缩稀疏行进来的<strong class="lj jd"><em class="no">scipy . Sparse . CSR _ matrix</em></strong>。</p><div class="od oe gp gr of og"><a rel="noopener  ugc nofollow" target="_blank" href="/become-a-data-scientist-in-2021-with-these-following-steps-5bf70a0fe0a1"><div class="oh ab fo"><div class="oi ab oj cl cj ok"><h2 class="bd jd gy z fp ol fr fs om fu fw jc bi translated">按照以下步骤，在2021年成为一名数据科学家</h2><div class="on l"><h3 class="bd b gy z fp ol fr fs om fu fw dk translated">走上数据科学家之路需要具备的基本点</h3></div><div class="oo l"><p class="bd b dl z fp ol fr fs om fu fw dk translated">pub.towardsai.net</p></div></div><div class="op l"><div class="pc l or os ot op ou lb og"/></div></div></a></div><blockquote class="nl nm nn"><p id="a0f2" class="lh li no lj b lk ll kd lm ln lo kg lp np lr ls lt nq lv lw lx nr lz ma mb mc im bi translated"><strong class="lj jd"> <em class="it">分类编码</em> </strong></p></blockquote><p id="504d" class="pw-post-body-paragraph lh li it lj b lk ll kd lm ln lo kg lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">当我们得到一些原始数据集时，一些列不是连续的值，而是在一些二进制和多类别的类别中。因此，为了使它们成为整数值，我们使用编码方法。下面给出了一些编码方法:</p><ul class=""><li id="b16e" class="mv mw it lj b lk ll ln lo lq oy lu oz ly pa mc pb nd ne nf bi translated"><strong class="lj jd"/></li><li id="a32f" class="mv mw it lj b lk ng ln nh lq ni lu nj ly nk mc pb nd ne nf bi translated"><strong class="lj jd"> <em class="no">标签编码器:</em> </strong>用于将sklearn库中的二进制类别编码为数值。</li><li id="6277" class="mv mw it lj b lk ng ln nh lq ni lu nj ly nk mc pb nd ne nf bi translated"><strong class="lj jd"> <em class="no">一个热编码器:</em></strong>sk learn库提供了另一个特性，用新的特性列将categories类转换成新的数值0和1。</li><li id="f539" class="mv mw it lj b lk ng ln nh lq ni lu nj ly nk mc pb nd ne nf bi translated"><strong class="lj jd"> <em class="no">哈希:</em> </strong>在高维的情况下比一键编码更有用。当要素中有高基数时使用它。</li></ul><p id="f233" class="pw-post-body-paragraph lh li it lj b lk ll kd lm ln lo kg lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">还有很多其他的编码方式，像<strong class="lj jd"> <em class="no">均值编码</em>、</strong> <strong class="lj jd"> <em class="no">赫尔默特编码</em>、<em class="no">序数编码</em>、<em class="no">概率比编码</em> </strong>和等等。</p><p id="a998" class="pw-post-body-paragraph lh li it lj b lk ll kd lm ln lo kg lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated"><strong class="lj jd">Python的例子:</strong></p><pre class="ks kt ku kv gt nt nu nv nw aw nx bi"><span id="9864" class="md me it nu b gy ny nz l oa ob">df1=pd.get_dummies(df['State'],drop_first=True)</span></pre><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div class="gh gi pd"><img src="../Images/8b7554f85b318f6b0056330598d3c1f7.png" data-original-src="https://miro.medium.com/v2/resize:fit:790/format:webp/1*t5FPZdfw2q9kYS3b12yfpg.png"/></div><figcaption class="ld le gj gh gi lf lg bd b be z dk translated">获取假人编码。作者的照片</figcaption></figure><blockquote class="nl nm nn"><p id="e2d8" class="lh li no lj b lk ll kd lm ln lo kg lp np lr ls lt nq lv lw lx nr lz ma mb mc im bi translated"><strong class="lj jd"> <em class="it">插补</em> </strong></p></blockquote><p id="5ae0" class="pw-post-body-paragraph lh li it lj b lk ll kd lm ln lo kg lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">当原始数据中存在一些缺失值时，将缺失记录转换为数值称为输入。</p><p id="a3cf" class="pw-post-body-paragraph lh li it lj b lk ll kd lm ln lo kg lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">创建随机数据帧。</p><pre class="ks kt ku kv gt nt nu nv nw aw nx bi"><span id="9de6" class="md me it nu b gy ny nz l oa ob"># import the pandas library<br/>import pandas as pd<br/>import numpy as np</span><span id="03fc" class="md me it nu b gy oc nz l oa ob">df = pd.DataFrame(np.random.randn(4, 3), index=['a', 'c', 'e',<br/>'h'],columns=['First', 'Second', 'Three'])</span><span id="b5b4" class="md me it nu b gy oc nz l oa ob">df = df.reindex(['a', 'b', 'c', 'd', 'e', 'f', 'g', 'h'])</span><span id="97ec" class="md me it nu b gy oc nz l oa ob">print (df)</span></pre><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div class="gh gi pe"><img src="../Images/78935ea9aa8157ab24c6c66285b3ac0c.png" data-original-src="https://miro.medium.com/v2/resize:fit:524/format:webp/1*kaBK5Jo1ehOZ2VssOQZhWA.png"/></div><figcaption class="ld le gj gh gi lf lg bd b be z dk translated">缺少值的数据帧。作者的照片</figcaption></figure><p id="e0ff" class="pw-post-body-paragraph lh li it lj b lk ll kd lm ln lo kg lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">现在用零值代替。</p><pre class="ks kt ku kv gt nt nu nv nw aw nx bi"><span id="13fe" class="md me it nu b gy ny nz l oa ob">print ("NaN replaced with '0':")<br/>print (df.fillna(0))</span></pre><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi pf"><img src="../Images/1bfadc9e415ddf6a3136d37cbe43145a.png" data-original-src="https://miro.medium.com/v2/resize:fit:592/format:webp/1*EMv_WZc3Tujs0zUwxpnvig.png"/></div></div><figcaption class="ld le gj gh gi lf lg bd b be z dk translated">用零填充的缺失值。作者的照片</figcaption></figure><p id="64bf" class="pw-post-body-paragraph lh li it lj b lk ll kd lm ln lo kg lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">用平均值替换缺失值。</p><pre class="ks kt ku kv gt nt nu nv nw aw nx bi"><span id="3c46" class="md me it nu b gy ny nz l oa ob">from sklearn.impute import SimpleImputer<br/>imp = SimpleImputer(missing_values=np.nan, strategy='mean')</span></pre><p id="c0f7" class="pw-post-body-paragraph lh li it lj b lk ll kd lm ln lo kg lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">sklearn提供了简单的估算器来查找NAN值并用平均值填充。</p><p id="b066" class="pw-post-body-paragraph lh li it lj b lk ll kd lm ln lo kg lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">我们可以在管道中使用估算器来使估算器更好。</p><div class="od oe gp gr of og"><a rel="noopener  ugc nofollow" target="_blank" href="/correlation-and-its-types-in-statistics-7a723dcfd12d"><div class="oh ab fo"><div class="oi ab oj cl cj ok"><h2 class="bd jd gy z fp ol fr fs om fu fw jc bi translated">统计学中的相关性及其类型</h2><div class="on l"><h3 class="bd b gy z fp ol fr fs om fu fw dk translated">统计学有助于理解机器学习中的行为</h3></div><div class="oo l"><p class="bd b dl z fp ol fr fs om fu fw dk translated">pub.towardsai.net</p></div></div><div class="op l"><div class="pg l or os ot op ou lb og"/></div></div></a></div><blockquote class="nl nm nn"><p id="d702" class="lh li no lj b lk ll kd lm ln lo kg lp np lr ls lt nq lv lw lx nr lz ma mb mc im bi translated"><strong class="lj jd"> <em class="it">结论:</em> </strong></p></blockquote><p id="5a8b" class="pw-post-body-paragraph lh li it lj b lk ll kd lm ln lo kg lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">数据预处理是使数据集对我们的估计者更可靠的一个重要步骤。</p><p id="2718" class="pw-post-body-paragraph lh li it lj b lk ll kd lm ln lo kg lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">我希望你喜欢这篇文章。通过我的<a class="ae ph" href="https://www.linkedin.com/in/data-scientist-95040a1ab/" rel="noopener ugc nofollow" target="_blank"> LinkedIn </a>和<a class="ae ph" href="https://twitter.com/amitprius" rel="noopener ugc nofollow" target="_blank"> twitter </a>联系我。</p><h1 id="9733" class="pi me it bd mf pj pk pl mi pm pn po ml ki pp kj mo kl pq km mr ko pr kp mu ps bi translated">推荐文章</h1><ol class=""><li id="0bf0" class="mv mw it lj b lk mx ln my lq mz lu na ly nb mc nc nd ne nf bi translated"><a class="ae ph" href="https://medium.com/towards-artificial-intelligence/nlp-zero-to-hero-with-python-2df6fcebff6e?sk=2231d868766e96b13d1e9d7db6064df1" rel="noopener"> NLP —用Python从零到英雄</a></li></ol><p id="758b" class="pw-post-body-paragraph lh li it lj b lk ll kd lm ln lo kg lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">2.<a class="ae ph" href="https://medium.com/towards-artificial-intelligence/python-data-structures-data-types-and-objects-244d0a86c3cf?sk=42f4b462499f3fc3a160b21e2c94dba6" rel="noopener"> Python数据结构数据类型和对象</a></p><p id="2633" class="pw-post-body-paragraph lh li it lj b lk ll kd lm ln lo kg lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">3.<a class="ae ph" href="https://medium.com/towards-artificial-intelligence/python-zero-to-hero-with-examples-c7a5dedb968b?source=friends_link&amp;sk=186aff630c2241aca16522241333e3e0" rel="noopener"> Python:零到英雄带实例</a></p><p id="c944" class="pw-post-body-paragraph lh li it lj b lk ll kd lm ln lo kg lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">4.<a class="ae ph" href="https://medium.com/towards-artificial-intelligence/fully-explained-svm-classification-with-python-eda124997bcd?source=friends_link&amp;sk=da300d557992d67808746ee706269b2f" rel="noopener">用Python全面讲解SVM分类</a></p><p id="37bb" class="pw-post-body-paragraph lh li it lj b lk ll kd lm ln lo kg lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">5.<a class="ae ph" href="https://medium.com/towards-artificial-intelligence/fully-explained-k-means-clustering-with-python-e7caa573176a?source=friends_link&amp;sk=9c5c613ceb10f2d203712634f3b6fb28" rel="noopener">用Python全面解释K-means聚类</a></p><p id="fda6" class="pw-post-body-paragraph lh li it lj b lk ll kd lm ln lo kg lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">6.<a class="ae ph" href="https://medium.com/towards-artificial-intelligence/fully-explained-linear-regression-with-python-fe2b313f32f3?source=friends_link&amp;sk=53c91a2a51347ec2d93f8222c0e06402" rel="noopener">用Python全面解释线性回归</a></p><p id="d34f" class="pw-post-body-paragraph lh li it lj b lk ll kd lm ln lo kg lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">7.<a class="ae ph" href="https://medium.com/towards-artificial-intelligence/fully-explained-logistic-regression-with-python-f4a16413ddcd?source=friends_link&amp;sk=528181f15a44e48ea38fdd9579241a78" rel="noopener">用Python全面讲解逻辑回归</a></p><p id="e15d" class="pw-post-body-paragraph lh li it lj b lk ll kd lm ln lo kg lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">8.<a class="ae ph" href="https://medium.com/towards-artificial-intelligence/basic-of-time-series-with-python-a2f7cb451a76?source=friends_link&amp;sk=09d77be2d6b8779973e41ab54ebcf6c5" rel="noopener">Python时间序列基础</a></p><p id="e376" class="pw-post-body-paragraph lh li it lj b lk ll kd lm ln lo kg lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">9.<a class="ae ph" href="https://medium.com/towards-artificial-intelligence/numpy-zero-to-hero-with-python-d135f57d6082?source=friends_link&amp;sk=45c0921423cdcca2f5772f5a5c1568f1" rel="noopener"> NumPy:用Python零到英雄</a></p><p id="ccd6" class="pw-post-body-paragraph lh li it lj b lk ll kd lm ln lo kg lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">10.<a class="ae ph" href="https://medium.com/analytics-vidhya/confusion-matrix-in-machine-learning-91b6e2b3f9af?source=friends_link&amp;sk=11c6531da0bab7b504d518d02746d4cc" rel="noopener">机器学习中的混淆矩阵</a></p></div></div>    
</body>
</html>