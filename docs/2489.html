<html>
<head>
<title>Using Deep Learning for Object Detection in Aerial Images</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">使用深度学习进行航空图像中的目标检测</h1>
<blockquote>原文：<a href="https://pub.towardsai.net/using-deep-learning-for-object-detection-in-aerial-images-b255c276e17?source=collection_archive---------1-----------------------#2022-01-16">https://pub.towardsai.net/using-deep-learning-for-object-detection-in-aerial-images-b255c276e17?source=collection_archive---------1-----------------------#2022-01-16</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><h2 id="1078" class="io ip iq bd b dl ir is it iu iv iw dk ix translated" aria-label="kicker paragraph"><a class="ae ep" href="https://towardsai.net/p/category/machine-learning/deep-learning" rel="noopener ugc nofollow" target="_blank">深度学习</a></h2><div class=""/><div class=""><h2 id="e61d" class="pw-subtitle-paragraph jw iz iq bd b jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn dk translated">分享我第一次动手做ML项目的经验，以及我学到的东西</h2></div><p id="b432" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">机器学习、深度学习、数据科学……这些术语我们已经听了好几年了，它们似乎不会很快消失。我第一次听到“机器学习”这个词是在2018年，当时我14岁。</p><p id="0efb" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">一年后，我使用TensorFlow和Keras实现了一个基本图像分类的神经网络，作为我高中机器学习课的一部分。</p><p id="6d3a" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">快进2年多学习机器学习理论和动手实践，我高中毕业软件工程专业，重点是深度学习。我的最终项目的主题是“利用航拍图像中的物体检测处理非法建筑的系统”。</p><h1 id="8a71" class="lk ll iq bd lm ln lo lp lq lr ls lt lu kf lv kg lw ki lx kj ly kl lz km ma mb bi translated">背景</h1><p id="1c07" class="pw-post-body-paragraph ko kp iq kq b kr mc ka kt ku md kd kw kx me kz la lb mf ld le lf mg lh li lj ij bi translated">一些土木工程师的工作是帮助处理非法建筑。他们通过拍摄特定区域的航空图像并手动标记图像中的每座建筑物来实现这一点。他们用几年后拍摄的同一地点的航拍图像重复这一过程。然后，他们将两者进行比较，找出发生了什么变化(增加了新的建筑，某栋建筑增加了新的楼层，等等。)，并检查该地区建筑物的许可证，以确定是否存在违法建筑的情况。手动标记建筑物的问题是这个过程缓慢、困难且耗时。然而，如果这个过程是自动完成的，它将变得快速和容易，并将为许多工程师节省大量时间，最重要的是，将对打击非法建筑有很大帮助。</p><h1 id="6cfe" class="lk ll iq bd lm ln lo lp lq lr ls lt lu kf lv kg lw ki lx kj ly kl lz km ma mb bi translated">系统结构</h1><figure class="mi mj mk ml gt mm gh gi paragraph-image"><div role="button" tabindex="0" class="mn mo di mp bf mq"><div class="gh gi mh"><img src="../Images/66b0c1887954f3bb3fcfe72e62fcd778.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*zIHMdiLE_XXKGP5taevoNA.jpeg"/></div></div><figcaption class="mt mu gj gh gi mv mw bd b be z dk translated">系统的架构图。我的图像</figcaption></figure><p id="24df" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">该系统有几个层次:</p><ul class=""><li id="8eba" class="mx my iq kq b kr ks ku kv kx mz lb na lf nb lj nc nd ne nf bi translated">持久层—包含存储在系统中的所有数据，由以下组件组成:<br/>—存储业务数据的数据库<br/>—存储管理系统和检测服务器映像的文件存储。</li><li id="fe1d" class="mx my iq kq b kr ng ku nh kx ni lb nj lf nk lj nc nd ne nf bi translated">数据访问层—处理存储在数据库中的数据的代码。</li><li id="101e" class="mx my iq kq b kr ng ku nh kx ni lb nj lf nk lj nc nd ne nf bi translated">业务层—该层由以下几部分组成:<br/>—业务逻辑—包含UI所需的功能以及与检测逻辑组件的集成。这种集成是使用REST APIs实现的。<br/>–检测逻辑—该组件被实现为WEB服务，为REST请求提供服务。该服务的功能包括处理图像、检测图像上的建筑物、在建筑物周围绘制边界框，以及通过REST API提供处理后的图像。</li><li id="ed77" class="mx my iq kq b kr ng ku nh kx ni lb nj lf nk lj nc nd ne nf bi translated">UI层—这一层由工程师UI(一个桌面应用程序)和主管UI(一个网站)组成。关于UI的更全面的解释将在本文后面给出。</li></ul><h1 id="6e01" class="lk ll iq bd lm ln lo lp lq lr ls lt lu kf lv kg lw ki lx kj ly kl lz km ma mb bi translated">研究</h1><p id="f0f2" class="pw-post-body-paragraph ko kp iq kq b kr mc ka kt ku md kd kw kx me kz la lb mf ld le lf mg lh li lj ij bi translated">今天，有各种各样的机器学习算法，用于不同的用例，所以，要为我的项目选择正确的算法，我必须做一些研究。</p><p id="9088" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">我考虑了几种算法。其中包括SVM和RNN。</p><p id="824b" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">SVM是一种用于分类和回归问题的算法，它通过绘制决策边界/超平面来解决这些问题，这意味着该算法不是我们的任务(即图像中的对象检测)所需的算法。</p><figure class="mi mj mk ml gt mm gh gi paragraph-image"><div class="gh gi nl"><img src="../Images/fac705a19702f22191a85a6f556fd72d.png" data-original-src="https://miro.medium.com/v2/resize:fit:900/format:webp/1*g9OrIjJ1JLHzXzooDOxgLA.png"/></div><figcaption class="mt mu gj gh gi mv mw bd b be z dk translated">使用SVM算法的最大边缘超平面。图片来自维基百科</figcaption></figure><p id="f52a" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">在快速检查了SVM之后，我决定看看是否有一种神经网络可以派上用场。有许多类型的神经网络，如RNN(递归神经网络)，可以使用其内部存储器来处理各种长度的输入序列，以解决与时间序列数据、文本数据和视频数据相关的问题，如情感分类、语言翻译、关联手写识别等。同样，这不是我这个项目所需要的，所以rnn不是很有用。</p><figure class="mi mj mk ml gt mm gh gi paragraph-image"><div role="button" tabindex="0" class="mn mo di mp bf mq"><div class="gh gi nm"><img src="../Images/2ce493d669bcbf17e130e52767599b97.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*dFGLgnMMiFB786XpHP0etA.png"/></div></div><figcaption class="mt mu gj gh gi mv mw bd b be z dk translated">基本RNN架构图。图片来自edrawsoft的免费递归神经网络模板</figcaption></figure><figure class="mi mj mk ml gt mm gh gi paragraph-image"><div role="button" tabindex="0" class="mn mo di mp bf mq"><div class="gh gi nn"><img src="../Images/01ef409ccfc25e7ea33214faa3a52c84.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*HZaupIVRO-kkkd9T1BDlYQ.png"/></div></div><figcaption class="mt mu gj gh gi mv mw bd b be z dk translated">递归神经网络的基本结构。图片来自“<a class="ae no" href="https://www.mdpi.com/2073-4395/9/2/72/htm" rel="noopener ugc nofollow" target="_blank">基于LSTM神经网络的巴基斯坦小麦产量预测模型</a></figcaption></figure><p id="ebb2" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">在回顾了各种神经网络之后，我终于发现了可能适合我的项目的神经网络类型——CNN。</p><h2 id="e83c" class="np ll iq bd lm nq nr dn lq ns nt dp lu kx nu nv lw lb nw nx ly lf ny nz ma iw bi translated">卷积神经网络</h2><p id="759f" class="pw-post-body-paragraph ko kp iq kq b kr mc ka kt ku md kd kw kx me kz la lb mf ld le lf mg lh li lj ij bi translated">CNN是一种使用过滤器从图像中提取特征的神经网络。它主要用于分析视觉意象。</p><figure class="mi mj mk ml gt mm gh gi paragraph-image"><div role="button" tabindex="0" class="mn mo di mp bf mq"><div class="gh gi oa"><img src="../Images/fff293357945e7f1d58d1fca7db08cbd.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*3BRLw4lsANPEfGgimG3YVQ.png"/></div></div><figcaption class="mt mu gj gh gi mv mw bd b be z dk translated">典型的CNN架构。图片来自维基百科</figcaption></figure><p id="db4b" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">“但是什么是卷积呢？”你可能会问。卷积是应用于矩阵的数学运算，通常，图像以像素或数字的形式表示。在此操作期间，在过滤器(也称为“内核”)值和内核悬停在其上的图像值之间执行点积，直到内核完成在表示图像的矩阵中的每个值上的悬停。这个过程的目标是从输入图像中提取特征。</p><figure class="mi mj mk ml gt mm gh gi paragraph-image"><div class="gh gi ob"><img src="../Images/97a012b2fab34768eae9c1076293a6cf.png" data-original-src="https://miro.medium.com/v2/resize:fit:780/1*V4uobVv91cccRy9LtGYkKQ.gif"/></div><figcaption class="mt mu gj gh gi mv mw bd b be z dk translated">卷积过程图解。来自维基百科的Gif</figcaption></figure><p id="313c" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">另一个重要的层是池层，它负责减小卷积要素的空间大小，从而降低处理数据所需的计算能力。有两种类型的池:最大池和平均池。最大池返回内核覆盖的图像部分的最大值。平均池返回内核覆盖的图像部分的所有值的平均值。</p><figure class="mi mj mk ml gt mm gh gi paragraph-image"><div class="gh gi oc"><img src="../Images/ddc38fde5a50cafb1476ccef175f4ce4.png" data-original-src="https://miro.medium.com/v2/resize:fit:942/format:webp/1*QR_zsM7MENmmmc0Q3Mzalw.png"/></div><figcaption class="mt mu gj gh gi mv mw bd b be z dk translated">最大池插图。图片来自维基百科</figcaption></figure><h2 id="7789" class="np ll iq bd lm nq nr dn lq ns nt dp lu kx nu nv lw lb nw nx ly lf ny nz ma iw bi translated">视网膜网</h2><p id="38ae" class="pw-post-body-paragraph ko kp iq kq b kr mc ka kt ku md kd kw kx me kz la lb mf ld le lf mg lh li lj ij bi translated">在我的研究中，我检查了许多CNN架构，如RCNN、Yolo等。关于这些和其他的更多信息可以在<a class="ae no" href="https://towardsdatascience.com/r-cnn-fast-r-cnn-faster-r-cnn-yolo-object-detection-algorithms-36d53571365e" rel="noopener" target="_blank">这里</a>找到。我在这个项目上工作的时间有限，除了ML部分之外，我还必须处理它的其他组件，所以我必须找到一个已经实现了对象检测算法的库，它可以让我训练、预测和绘制检测到的对象周围的边界框。在网上广泛搜索后，我遇到了RetinaNet。</p><p id="7f5b" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">RetinaNet是一个复合网络，包括:</p><ul class=""><li id="13ea" class="mx my iq kq b kr ks ku kv kx mz lb na lf nb lj nc nd ne nf bi translated">称为特征金字塔(FPN)网络的主干网络以完全卷积的方式构建在ResNet之上，用于计算输入图像的特征映射。</li><li id="c349" class="mx my iq kq b kr ng ku nh kx ni lb nj lf nk lj nc nd ne nf bi translated">对象分类子网。</li><li id="ebfc" class="mx my iq kq b kr ng ku nh kx ni lb nj lf nk lj nc nd ne nf bi translated">包围盒回归子网络。</li></ul><p id="75c6" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">对象分类子网络和包围盒回归子网络建立在每个FPN层上，它们使用主干的输出。</p><figure class="mi mj mk ml gt mm gh gi paragraph-image"><div role="button" tabindex="0" class="mn mo di mp bf mq"><div class="gh gi od"><img src="../Images/406e2576a848d701658ecb0e24ecc41a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*DM_sRPMZnz9U1Ome3dK2DA.jpeg"/></div></div><figcaption class="mt mu gj gh gi mv mw bd b be z dk translated">RetinaNet的建筑可视化。图像来自“<a class="ae no" href="https://arxiv.org/abs/1708.02002" rel="noopener ugc nofollow" target="_blank">密集物体探测的焦损失</a></figcaption></figure><p id="dd3b" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">FPN的结构由两条横向连接的通路组成。</p><p id="5e42" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">第一种是自下而上的途径。在这个路径中，产生了输入图像的特征图。由输出相同比例的要素地图的每组连续图层生成的最后一个要素地图稍后将用作要素金字塔的基础。</p><figure class="mi mj mk ml gt mm gh gi paragraph-image"><div class="gh gi oe"><img src="../Images/847102679fae6905ef3e1e9d604da6af.png" data-original-src="https://miro.medium.com/v2/resize:fit:896/format:webp/1*WCvuJieTiVcJf8H_l7dzeg.jpeg"/></div><figcaption class="mt mu gj gh gi mv mw bd b be z dk translated">自下而上的路径可视化。图片来自“<a class="ae no" href="https://arxiv.org/abs/1612.03144" rel="noopener ugc nofollow" target="_blank">用于目标检测的特征金字塔网络</a></figcaption></figure><p id="f438" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">第二个是自上而下的途径。在该路径中，自下而上路径的最后一个特征地图被扩展到与倒数第二个特征地图相同的比例。然后将两者合并，并将新的特征图提供给两个子网络。重复该过程，直到来自自底向上路径的每个特征地图具有与横向连接相连接的对应的新特征地图。</p><figure class="mi mj mk ml gt mm gh gi paragraph-image"><div class="gh gi of"><img src="../Images/50ead3ba888d2179373b1fe4bacebc69.png" data-original-src="https://miro.medium.com/v2/resize:fit:1382/format:webp/1*uRi4koMZcUCHCxRXwjM0xA.jpeg"/></div><figcaption class="mt mu gj gh gi mv mw bd b be z dk translated">可视化自上而下的路径。图像来自“<a class="ae no" href="https://arxiv.org/abs/1612.03144" rel="noopener ugc nofollow" target="_blank">用于对象检测的特征金字塔网络</a></figcaption></figure><p id="9574" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">在我的项目中，我使用Keras-retina net(retina net的Keras实现)来训练、预测和绘制航空图像中检测到的建筑物周围的边界框。</p><h1 id="8a8e" class="lk ll iq bd lm ln lo lp lq lr ls lt lu kf lv kg lw ki lx kj ly kl lz km ma mb bi translated">创建数据集</h1><p id="15d4" class="pw-post-body-paragraph ko kp iq kq b kr mc ka kt ku md kd kw kx me kz la lb mf ld le lf mg lh li lj ij bi translated">在我找到执行所需任务的正确模块之后(在这个项目中，它是航空图像中的对象检测)，我需要用于模型训练和预测的数据。在搜索数据集时，我试图找到一个包含建筑物和元数据XML文件的图像，这些元数据XML文件在每个图像中存储建筑物的位置(每个图像一个XML文件)。不幸的是，我没有找到一个，但我确实找到了一个可能有用的数据集。这个数据集是<a class="ae no" href="https://www.kaggle.com/kbhartiya83/swimming-pool-and-car-detection" rel="noopener ugc nofollow" target="_blank">游泳池和汽车检测</a>数据集，它包含汽车和游泳池的图像，以及存储这些图像中游泳池和汽车位置的XML文件。你可能想知道我为什么选择这个数据集。原因很简单。在有汽车和游泳池的相同图片中，也有建筑物，因此我可以使用数据集的图像进行训练和预测。</p><figure class="mi mj mk ml gt mm gh gi paragraph-image"><div role="button" tabindex="0" class="mn mo di mp bf mq"><div class="gh gi og"><img src="../Images/be00386b37b576dccaa651e92c280e70.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*ZMK2dtoyVAfv6_a6"/></div></div><figcaption class="mt mu gj gh gi mv mw bd b be z dk translated">游泳池和汽车检测数据集。截图来自kaggle.com的我</figcaption></figure><p id="90db" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">创建存储图像中对象位置的XML文件。我使用了<a class="ae no" rel="noopener ugc nofollow" target="_blank" href="/cvat.org"> CVAT </a>，一个计算机视觉注释工具，它让我在图像中的物体周围画出边界框，然后生成我训练所需的XML文件。在我拥有的大约1000张图片中，我为600张图片创建了XML文件，每张224X224像素。</p><p id="34f9" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">现在我已经有了所有的图像和它们对应的XML文件，我可以开始训练模型了。</p><figure class="mi mj mk ml gt mm gh gi paragraph-image"><div role="button" tabindex="0" class="mn mo di mp bf mq"><div class="gh gi oh"><img src="../Images/113c08892d353f3b01e565c61a6dfcc6.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*i4IMuAPCqiUFPc0Xkp2a1Q.png"/></div></div><figcaption class="mt mu gj gh gi mv mw bd b be z dk translated">使用CVAT注释图像。截图来自cvat.org的我</figcaption></figure><h1 id="64dc" class="lk ll iq bd lm ln lo lp lq lr ls lt lu kf lv kg lw ki lx kj ly kl lz km ma mb bi translated">训练和预测</h1><p id="362c" class="pw-post-body-paragraph ko kp iq kq b kr mc ka kt ku md kd kw kx me kz la lb mf ld le lf mg lh li lj ij bi translated">现在，我剩下的就是训练模型，并使用项目中稍后生成的一个经过训练的模型文件。因为训练模型的代码是在Google Colab上运行的，所以我首先必须安装我的Google Drive。然后，我导入所有我需要的模块。之后，我从XML文件中提取注释，并将它们存储在训练所需的CSV文件中。最后一步是训练本身，这是我不得不重复几次的一步。这样做的原因是，我必须找到一定数量的时段(所有训练数据的一轮训练)、步骤(一定数量的数据被馈送到网络的时段的一部分)，这将给我最佳结果。</p><figure class="mi mj mk ml gt mm"><div class="bz fp l di"><div class="oi oj l"/></div></figure><p id="d088" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">我决定用不同数量的时期、步骤和批量大小尝试几次，看看哪一个能给我更好的结果。下表总结了我在寻找这些参数的更好组合方面的一些尝试。</p><figure class="mi mj mk ml gt mm gh gi paragraph-image"><div role="button" tabindex="0" class="mn mo di mp bf mq"><div class="gh gi ok"><img src="../Images/0a462b31a83306c69481e27283a46e79.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*urjMdlFCJmY9Z_l9FFrYrw.png"/></div></div></figure><p id="112a" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">从该表中可以看出，越多的时期和越多的步骤(=越小的批量)给了我们越好的结果，因为具有最多时期和步骤的训练尝试给出了最低的初始损失(2.96)和最低的最终损失(1.46)。</p><p id="92fe" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">每当一个时期结束时，就会为我们生成一个新的训练模型文件，该文件可用于预测。</p><p id="a204" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">对于预测，我使用了之前生成的一个训练模型文件，以及keras_retinanet的预测模块和边界框模块。我必须关注的一件事是绘制边界框所需的模型的置信度阈值。我开始使用不同的图像测试模型是如何完成的，根据模型的性能，我改变了置信度阈值，以便它不会太低(这可能导致在不是建筑物的对象周围绘制边界框)，也不会太高(这可能导致即使对象是建筑物也不会在对象周围绘制边界框)。</p><figure class="mi mj mk ml gt mm"><div class="bz fp l di"><div class="oi oj l"/></div></figure><p id="3f27" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">有用！我们的模型在建筑物周围绘制边界框方面做得非常好，并且具有非常高的置信度(不幸的是，由于某种原因，右上角检测到的建筑物的置信度在图像中看不到)。</p><figure class="mi mj mk ml gt mm gh gi paragraph-image"><div role="button" tabindex="0" class="mn mo di mp bf mq"><div class="gh gi oh"><img src="../Images/c838c94861d5c687a1cf9e70e5214c86.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*YaFaT20o9bJl2MCEqJAT7Q.png"/></div></div><figcaption class="mt mu gj gh gi mv mw bd b be z dk translated">检测到的建筑物周围绘制有边界框的航拍图像。我截图</figcaption></figure><p id="8751" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">现在我需要做的就是构建UI，这样用户就可以使用我的项目，并找到一种方法让我的python代码在一个主要用C#编写的项目中工作。</p><h1 id="5730" class="lk ll iq bd lm ln lo lp lq lr ls lt lu kf lv kg lw ki lx kj ly kl lz km ma mb bi translated">将我的项目带入生活</h1><p id="a39d" class="pw-post-body-paragraph ko kp iq kq b kr mc ka kt ku md kd kw kx me kz la lb mf ld le lf mg lh li lj ij bi translated">能够在航拍图像上执行对象检测是很酷的事情，但是如果不能在易于使用的UI中使用它，它还有什么价值呢？</p><p id="b084" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">这个项目中有两个用户，这意味着有两个UI环境。第一类用户是工程师。工程师的UI环境将主要用于检测新增和现有地址的航空图像中的建筑物，查看过去检测到的图像，并向主管发送报告。第二类用户是主管。主管负责查看工程师发送的报告，查看和添加建筑许可，并确定是否存在非法建筑的情况。</p><p id="5da0" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">幸运的是，我身边有windows窗体，它可以让我构建桌面应用程序，这就是将要使用对象检测的地方。</p><p id="7140" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">工程师可以在新添加的地址中拍摄的图像中检测建筑物</p><figure class="mi mj mk ml gt mm gh gi paragraph-image"><div role="button" tabindex="0" class="mn mo di mp bf mq"><div class="gh gi oh"><img src="../Images/bf716e243b78cfb74387b415f2d46fcc.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*I5CV6vMPHIlL92pLLtQd5Q.png"/></div></div><figcaption class="mt mu gj gh gi mv mw bd b be z dk translated">在新地址的航拍图像中检测建筑物。我截图</figcaption></figure><p id="b520" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">或者检测在系统中已经存在的地址中拍摄的图像中的建筑物，并将其与之前的图像进行比较。</p><figure class="mi mj mk ml gt mm gh gi paragraph-image"><div role="button" tabindex="0" class="mn mo di mp bf mq"><div class="gh gi oh"><img src="../Images/0b95544fdb5bd5c137638123afa86dea.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*B1DC2_LJ-26nHuvFAlrtQg.png"/></div></div><figcaption class="mt mu gj gh gi mv mw bd b be z dk translated">在现有地址的航拍图像中检测建筑物，并与之前的进行比较。我截图</figcaption></figure><p id="cd58" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">工程师还可以从不同的地址和时间查看带有边框的所有图像。</p><figure class="mi mj mk ml gt mm gh gi paragraph-image"><div role="button" tabindex="0" class="mn mo di mp bf mq"><div class="gh gi oh"><img src="../Images/d9fe831b3ff55d80ea780f70a91f7788.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*uTVoHrpGjMHtT3GOWrbTdg.png"/></div></div><figcaption class="mt mu gj gh gi mv mw bd b be z dk translated">使用边界框查看图像。我截图</figcaption></figure><p id="119f" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">甚至向他们的主管发送报告。</p><figure class="mi mj mk ml gt mm gh gi paragraph-image"><div role="button" tabindex="0" class="mn mo di mp bf mq"><div class="gh gi oh"><img src="../Images/e6d71326309df9e4ebfd46ec62650538.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*yRsVvbnPbfgXS6FsLH_kng.png"/></div></div><figcaption class="mt mu gj gh gi mv mw bd b be z dk translated">发送报告。我截图</figcaption></figure><p id="7c8f" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">说到主管，他们也有自己的UI，一个网站，用aspx搭建的。</p><p id="be8e" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">在他们的UI环境中，主管可以查看所有建筑许可。</p><figure class="mi mj mk ml gt mm gh gi paragraph-image"><div role="button" tabindex="0" class="mn mo di mp bf mq"><div class="gh gi oh"><img src="../Images/8e668c7c74bf63b42a4b2758634d0f2a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*b8lKHqzMP8cSfyf2yGKNIw.png"/></div></div><figcaption class="mt mu gj gh gi mv mw bd b be z dk translated">查看建筑许可。我截图</figcaption></figure><p id="1b53" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">添加新的建筑许可证。</p><figure class="mi mj mk ml gt mm gh gi paragraph-image"><div class="gh gi ol"><img src="../Images/0b6e5049931b09bd47687569793924cc.png" data-original-src="https://miro.medium.com/v2/resize:fit:1166/format:webp/1*1EerEKWclVBk2fno0QBvlA.png"/></div><figcaption class="mt mu gj gh gi mv mw bd b be z dk translated">添加新许可证。我截图</figcaption></figure><p id="b1a7" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">并查看发送给他们的报告。</p><figure class="mi mj mk ml gt mm gh gi paragraph-image"><div role="button" tabindex="0" class="mn mo di mp bf mq"><div class="gh gi oh"><img src="../Images/dad68bd9301f39e14a0a0037a05b094f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*MM0dQsHK5lIycCEJ3Awsvg.png"/></div></div><figcaption class="mt mu gj gh gi mv mw bd b be z dk translated">查看报告。我截图</figcaption></figure><p id="938c" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">我用相似的色调设计了两个环境，只是为了给人一种它们都是同一个系统的一部分的感觉。</p><p id="ddb6" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">现在你可以看到我在一个主要是C#的项目中使用了python，让我们看看我是如何做到这一点的。</p><h1 id="073c" class="lk ll iq bd lm ln lo lp lq lr ls lt lu kf lv kg lw ki lx kj ly kl lz km ma mb bi translated">在主要是C#的项目中使用python</h1><p id="9726" class="pw-post-body-paragraph ko kp iq kq b kr mc ka kt ku md kd kw kx me kz la lb mf ld le lf mg lh li lj ij bi translated">Python代码不能就这样在C#中运行，必须完成一些额外的步骤才能实现。将python文件转换成. EXE文件并使用C#代码运行它是可能的，但是我做了一些不同的事情。我已经用<a class="ae no" href="https://flask.palletsprojects.com/en/1.1.x/patterns/fileuploads/" rel="noopener ugc nofollow" target="_blank"> Flask </a>建立了一个web服务器，它处理来自管理系统的请求。</p><p id="3e87" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">管理系统向服务器发送POST请求，并在检测完成后接收表示包含边界框的图像的资源的URL。</p><figure class="mi mj mk ml gt mm"><div class="bz fp l di"><div class="oi oj l"/></div></figure><p id="7b6e" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">服务器接收图像，对其执行检测，并将表示包含边界框的图像的资源的URL返回给管理系统。</p><figure class="mi mj mk ml gt mm"><div class="bz fp l di"><div class="oi oj l"/></div></figure><p id="7e2c" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">然后，管理系统显示带有边框的图像，而不是没有边框的图像，如您之前所见。</p><h1 id="48fd" class="lk ll iq bd lm ln lo lp lq lr ls lt lu kf lv kg lw ki lx kj ly kl lz km ma mb bi translated">我学到了什么</h1><p id="b3f8" class="pw-post-body-paragraph ko kp iq kq b kr mc ka kt ku md kd kw kx me kz la lb mf ld le lf mg lh li lj ij bi translated">在这个过程中，我学到了一些技术知识，比如:</p><p id="9c02" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">1.用Flask设置web服务器。</p><p id="fa14" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">2.使用数据库。</p><p id="31a8" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">3.CNN架构。</p><p id="edfe" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">4.使用keras_retinanet执行对象检测。</p><p id="a095" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">5.REST API。</p><p id="76ca" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">但除了那些，我还学到了另一个教训，比如:</p><p id="8871" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">1.知识差距应该首先得到解决。</p><p id="04c9" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">2.事情会变得艰难，但这不是放弃的理由。</p><p id="9d5a" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">3.如果你需要帮助，你应该寻求帮助。</p><p id="193f" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated"><em class="om">差不多就是这样！非常感谢您阅读这篇文章。你也可以访问我的Github页面</em> <a class="ae no" href="https://github.com/NathanUrinovsky" rel="noopener ugc nofollow" target="_blank"> <em class="om">这里</em> </a> <em class="om">！</em></p><h1 id="1aae" class="lk ll iq bd lm ln lo lp lq lr ls lt lu kf lv kg lw ki lx kj ly kl lz km ma mb bi translated">来源</h1><p id="cca7" class="pw-post-body-paragraph ko kp iq kq b kr mc ka kt ku md kd kw kx me kz la lb mf ld le lf mg lh li lj ij bi translated">[1] T. Bandara，<a class="ae no" href="https://towardsdatascience.com/lets-build-a-simple-distributed-computing-system-for-modern-cloud-part-one-e2b745126211" rel="noopener" target="_blank">让我们为现代云</a> (2021)构建一个简单的分布式计算系统，走向数据科学</p><p id="fed6" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">[2] R. Ghandi，<a class="ae no" href="https://towardsdatascience.com/r-cnn-fast-r-cnn-faster-r-cnn-yolo-object-detection-algorithms-36d53571365e" rel="noopener" target="_blank"> R-CNN，Fast R-CNN，Fast R-CNN，YOLO——对象检测算法</a> (2018)，走向数据科学</p><p id="c286" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">[3] N. Kumar，<a class="ae no" href="https://towardsdatascience.com/recurrent-neural-networks-rnn-explained-the-eli5-way-3956887e8b75" rel="noopener" target="_blank">递归神经网络(RNN)解释了通向数据科学的ELI5方式</a> (2019)</p><p id="507b" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">[4] T. Lin，P. Dollár，R. Girshick，K. He，B. Hariharan和S. Belongie，<a class="ae no" href="https://arxiv.org/abs/1612.03144" rel="noopener ugc nofollow" target="_blank">用于物体检测的特征金字塔网络</a> (2016)，arXiv</p><p id="1009" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">[5] T. Lin，P. Goyal，R. Girshick，K. He和P. Dollár，<a class="ae no" href="http://arxiv.org/abs/1708.02002" rel="noopener ugc nofollow" target="_blank">密集物体探测的焦点损失</a> (2017)，arXiv</p><p id="8e16" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">[6] A. Pai，<a class="ae no" href="https://www.analyticsvidhya.com/blog/2020/02/cnn-vs-rnn-vs-mlp-analyzing-3-types-of-neural-networks-in-deep-learning/#h2_6" rel="noopener ugc nofollow" target="_blank">CNN vs . RNN vs . ANN——分析深度学习中的3种神经网络</a> (2020)，Analytics Vidhya</p><p id="d4cf" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">[7] R. Pupale，<a class="ae no" href="https://towardsdatascience.com/https-medium-com-pupalerushikesh-svm-f4b42800e989" rel="noopener" target="_blank">支持向量机(SVM)——概述</a> (2018)，走向数据科学</p><p id="b0c6" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">[8] S. Saha，<a class="ae no" href="https://towardsdatascience.com/a-comprehensive-guide-to-convolutional-neural-networks-the-eli5-way-3bd2b1164a53" rel="noopener" target="_blank">《卷积神经网络综合指南ELI5之路</a> (2018)，走向数据科学》</p><p id="22c2" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">[9] A. Tch，<a class="ae no" href="https://towardsdatascience.com/the-mostly-complete-chart-of-neural-networks-explained-3fb6f2367464" rel="noopener" target="_blank"/>(2017)向数据科学解释的最完整的神经网络图表</p><p id="e423" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">[10] N .曾，<a class="ae no" href="https://blog.zenggyu.com/en/post/2018-12-05/retinanet-explained-and-demystified/" rel="noopener ugc nofollow" target="_blank"> RetinaNet解释与去神秘化</a> (2018)，</p></div></div>    
</body>
</html>