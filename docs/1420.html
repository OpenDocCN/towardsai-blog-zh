<html>
<head>
<title>Deploy Deep Learning Models Using Streamlit and Heroku</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">使用Streamlit和Heroku部署深度学习模型</h1>
<blockquote>原文：<a href="https://pub.towardsai.net/deploy-deep-learning-models-using-streamlit-and-heroku-22f6efae9141?source=collection_archive---------1-----------------------#2021-01-22">https://pub.towardsai.net/deploy-deep-learning-models-using-streamlit-and-heroku-22f6efae9141?source=collection_archive---------1-----------------------#2021-01-22</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><h2 id="7cba" class="ir is it bd b dl iu iv iw ix iy iz dk ja translated" aria-label="kicker paragraph"><a class="ae ep" href="https://towardsai.net/p/category/machine-learning/deep-learning" rel="noopener ugc nofollow" target="_blank">深度学习</a>、<a class="ae ep" href="https://towardsai.net/p/category/programming" rel="noopener ugc nofollow" target="_blank">编程</a></h2><div class=""/><div class=""><h2 id="6490" class="pw-subtitle-paragraph jz jc it bd b ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq dk translated">将数据应用程序发布到互联网的便捷方式。</h2></div><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi kr"><img src="../Images/922873c57b747d3728b048e8c987c388.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*uPvQYKthKe0hjh6yOFXBUg.jpeg"/></div></div><figcaption class="ld le gj gh gi lf lg bd b be z dk translated">来源:<a class="ae lh" href="https://www.freepik.com/free-photo/conceptual-cloud-server-business-with-wooden-blocks-with-icons-dark-color-table-flat-lay_10183680.htm#page=1&amp;query=servers&amp;position=40" rel="noopener ugc nofollow" target="_blank">freepik.com</a></figcaption></figure><p id="8d7f" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">许多数据专业人士训练的深度学习和机器学习模型要么以<code class="fe me mf mg mh b">inference.ipynb</code>笔记本或<code class="fe me mf mg mh b">app.py</code>文件告终😅。那些能够在现实世界中制造敬畏的一丝不苟的模型架构永远见不到天日。这些模型只是坐在后台，通过API网关处理请求，默默地完成它们的工作，使系统更加智能。</p><p id="22b3" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">使用这些智能系统的人并不总是信任花费数小时、数周或数月收集数据、清理收集的数据、格式化数据以正确使用数据、编写模型架构、培训模型架构并验证它的数据专业人员。如果验证指标不是很好，再次回到起点并重复循环。这些人没有看到数据专业人员无法在预训练的ResNet上使用<em class="mi"> 4通道图像</em>来获得图像特征的努力，他们没有意识到数据专业人员花费了日日夜夜来优化训练参数以使模型收敛到更好的精度或达到更低的损失值， 他们看不到数据专家选择最佳层组合中的最佳层来预测最终输出的辛苦，也不知道当验证分数很低时的痛苦感觉，因为模型权重没有正确加载或在开始时使用了不同的种子值。</p><p id="7e4b" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">他们唯一看到的是漂亮的前端显示一个非常酷的进度条，同时API调用后端模型API并获得响应。有时，在组织中工作的人也会发生同样的事情，在一些地方，数据专业人员只是从互联网上的不同地方收集一堆数据，组合收集的数据，获取某人训练的一些预训练模型，用他们收集的数据复制训练过程，并等待一些<em class="mi"> n </em>天完成训练并检查验证分数。如果这种预先训练好的模式不起作用，他们就会再次搜索网络，尝试其他方法。这并不能完全概括整个过程，对于数据科学团队之外的人来说，这是一个非常刻板的观点<em class="mi">(而且，在某些地方这是正确的</em>😅<em class="mi"> ) </em>。</p><p id="be30" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated"><em class="mi">很抱歉咆哮</em>，只是人们通常会以居高临下的观点来看待深度学习工程师或数据科学家，比如“数据科学怎么会是最性感的工作？你们只是坐在那里，日复一日地观察那些从左到右的进度条，如果不起作用，就再做一次！”。对于这些，我们通常会说你是对的，不要进入所有的细节，因为我们正忙于让机器学习，并不关心任何不愿意或不能够通过反向传播从他们之前的讨论失败中学习的人。</p><p id="f4b9" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">现在，让我们从所有的夸夸其谈转移到一个数据专业人员在以独立的方式发布他们的模型时所面临的困难。在数据科学和深度学习领域工作的每个人都非常适应以多种方式部署API，并优化请求-响应时间。他们中的大多数人唯一缺乏的是编写前端代码并将其与他们的API/s集成并拥有一个漂亮的web应用程序的技能。学习web开发的概念是非常困难的，人们需要从基本的HTML开始，然后转向CSS以使web应用程序更有吸引力，比如添加很酷的进度条😅(没有冒犯web开发者的意思)。</p><p id="d878" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">因此，对于数据专业人员来说，浏览所有这些内容是一项艰巨的任务。我们通常认为，最好把这些精力放在下一个任务的背景研究上。除了用独立的UI界面来吸引最终用户进行模型推理，数据专家也有必要学习更进一步，将他们的模型放到互联网上，因为这将有助于他们和他们的同事。</p><p id="da2d" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">一旦模型出现在互联网上，任何人都可以通过极简但有吸引力的界面使用它；一个人的同事可以去检查模型性能，并指出被训练的模型缺乏预测性能的区域。他们不需要浏览jupyter笔记本并按顺序运行所有单元来检查模型性能，甚至不需要盯着一个绿色和黑色的终端窗口并进行API调用来检查性能。</p><p id="2d6e" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">任何对深度学习或数据建模没有任何想法的非数据科学专业人士都可以进入界面，尝试一些输入并检查性能，在大多数情况下，这些面向客户的人可以提供关于模型在现实世界数据中的表现以及它在生产中是否成功的最佳反馈。</p><p id="1775" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">我意识到这样一个事实，即对于数据专业人员来说，创建一个带有API的接口并使用一个网关来接收来自接口的请求以使机器不容易受到攻击并保护存储的数据免受外部威胁是一件非常麻烦的事情。但在博客的下一部分，我们将看到一种非常快速和简单的方法来构建或部署并在团队中共享数据应用程序，甚至通过互联网与最终用户共享。我们将关注Streamlit，它允许任何没有前端经验的人为他们的模型制作一个界面。</p><p id="cf6c" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">这将是一个动手操作的博客，我们将在其中部署我以前的<a class="ae lh" href="https://medium.com/nerd-for-tech/question-classification-using-self-attention-transformer-part-1-33e990636e76" rel="noopener">系列博客</a>中讨论和训练的基于文本的模型之一。如果你想浏览数据收集、模型架构开发和模型训练的整个过程，请浏览那个系列的博客，然后来看这个。如果你不想尝试整个过程，你可以从这里开始。</p><h2 id="77a9" class="mj mk it bd ml mm mn dn mo mp mq dp mr lr ms mt mu lv mv mw mx lz my mz na iz bi translated">🔵创建虚拟环境并安装Streamlit</h2><p id="0d80" class="pw-post-body-paragraph li lj it lk b ll nb kd ln lo nc kg lq lr nd lt lu lv ne lx ly lz nf mb mc md im bi translated"><em class="mi">此处</em> 提供 <a class="ae lh" href="https://docs.streamlit.io/en/stable/" rel="noopener ugc nofollow" target="_blank"> <em class="mi">的简化文档</em></a></p><p id="cbe9" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">转到您的终端并执行以下命令</p><pre class="ks kt ku kv gt ng mh nh ni aw nj bi"><span id="9274" class="mj mk it mh b gy nk nl l nm nn"># creating conda env<br/>$ conda create -n envname python=python_version<br/>$ conda activate envname  </span><span id="3cef" class="mj mk it mh b gy no nl l nm nn"># install streamlit <br/>$ /path/to/anaconda3/envs/envname/bin/pip install streamlit pipreqs tqdm</span></pre><ul class=""><li id="0b28" class="np nq it lk b ll lm lo lp lr nr lv ns lz nt md nu nv nw nx bi translated"><em class="mi">对于macOS来说，anaconda3文件夹的路径是</em> <code class="fe me mf mg mh b"><em class="mi">/Users/username/anaconda3/envs/envname/bin/pip</em></code></li><li id="290c" class="np nq it lk b ll ny lo nz lr oa lv ob lz oc md nu nv nw nx bi translated"><em class="mi">对于Linux来说，anaconda文件夹的路径是</em> <code class="fe me mf mg mh b"><em class="mi">/home/username/anaconda3/envs/envname/bin/pip</em></code></li><li id="bcd2" class="np nq it lk b ll ny lo nz lr oa lv ob lz oc md nu nv nw nx bi translated"><em class="mi">对于Windows，可以打开</em> <code class="fe me mf mg mh b"><em class="mi">conda prompt</em></code> <em class="mi">并激活环境，使用</em> <code class="fe me mf mg mh b"><em class="mi">pip</em></code> <em class="mi">或</em> <code class="fe me mf mg mh b"><em class="mi">conda</em></code> <em class="mi">命令安装依赖项</em></li></ul><h2 id="9f99" class="mj mk it bd ml mm mn dn mo mp mq dp mr lr ms mt mu lv mv mw mx lz my mz na iz bi translated">🔵使用Streamlit进行推理文件和模型缓存</h2><p id="6d8c" class="pw-post-body-paragraph li lj it lk b ll nb kd ln lo nc kg lq lr nd lt lu lv ne lx ly lz nf mb mc md im bi translated">我们将创建一个文件<code class="fe me mf mg mh b">streamlitinf.py</code>并将推理代码放入其中</p><ul class=""><li id="4942" class="np nq it lk b ll lm lo lp lr nr lv ns lz nt md nu nv nw nx bi translated">模型推理的导入</li></ul><pre class="ks kt ku kv gt ng mh nh ni aw nj bi"><span id="f952" class="mj mk it mh b gy nk nl l nm nn">from tokenizers import BertWordPieceTokenizer <br/>from TwoClassHeadClassificationTransformer import * <br/>import pickle  <br/>import torch  <br/>import torch.nn as nn  <br/>import numpy as np  <br/>import streamlit as st </span><span id="6a7a" class="mj mk it mh b gy no nl l nm nn"> <br/>SEED = 3007 <br/>torch.manual_seed(SEED) <br/>torch.cuda.manual_seed(SEED)</span></pre><ul class=""><li id="40cf" class="np nq it lk b ll lm lo lp lr nr lv ns lz nt md nu nv nw nx bi translated">公用事业</li></ul><pre class="ks kt ku kv gt ng mh nh ni aw nj bi"><span id="116c" class="mj mk it mh b gy nk nl l nm nn">def save_pickle(obj, filepath):<br/>    with open(filepath, 'wb') as fp:<br/>        pickle.dump(obj, fp)<br/><br/>def load_pickle(filepath):<br/>    with open(filepath, 'rb') as fp:<br/>        return pickle.load(fp)</span></pre><ul class=""><li id="a5cc" class="np nq it lk b ll lm lo lp lr nr lv ns lz nt md nu nv nw nx bi translated">模型负载函数</li></ul><pre class="ks kt ku kv gt ng mh nh ni aw nj bi"><span id="be10" class="mj mk it mh b gy nk nl l nm nn">@st.cache<br/>def load_model():<br/>		'''Initialize the model parameters and load model weights'''<br/>    tokenizer = BertWordPieceTokenizer('bert-word-piece-custom-wikitext-vocab-10k-vocab.txt', lowercase = True, strip_accents = True)<br/>    vocab_size = tokenizer.get_vocab_size()<br/>    pad_id = 0<br/>    CLS_label_id = 2<br/>    num_class_heads = 2<br/>    lst_num_cat_in_classes = [6, 47]<br/>    seq_len = 100<br/>    batch_size = 256<br/>    num_workers = 3<br/><br/>    model = TwoClassHeadClassificationTransformer(<br/>        vocab_size=vocab_size, pad_id=pad_id, CLS_label_id=CLS_label_id,<br/>        num_class_heads=num_class_heads, <br/>        lst_num_cat_in_classes=lst_num_cat_in_classes, num_pos=seq_len<br/>    )<br/>    model = torch.load('classification_model_best.pt', map_location = 'cpu')<br/>    model = model.to('cpu')<br/>    model = model.eval()<br/><br/>    return model</span></pre><ul class=""><li id="8c23" class="np nq it lk b ll lm lo lp lr nr lv ns lz nt md nu nv nw nx bi translated">推理功能</li></ul><pre class="ks kt ku kv gt ng mh nh ni aw nj bi"><span id="9815" class="mj mk it mh b gy nk nl l nm nn">@st.cache<br/>def inf(text, model):<br/>		'''Tokenize the input text convert it to tensor and predict using the <br/>			trained model<br/>		'''<br/>    class2names = {<br/>    "DESC": "DESCRIPTION",<br/>    "ENTY": "ENTITY",<br/>    "ABBR": "ABBREVIATION",<br/>    "HUM": "HUMAN",<br/>    "NUM": "NUMERIC",<br/>    "LOC": "LOCATION"<br/>    }<br/><br/>    class2names = load_pickle('class2names.pkl')<br/>    subclass2names = load_pickle('subclass2names.pkl')<br/>    idx2class = load_pickle('idx2class.pkl')<br/>    idx2subclass = load_pickle('idx2subclass.pkl')<br/><br/>    tokenizer = BertWordPieceTokenizer('bert-word-piece-custom-wikitext-vocab-10k-vocab.txt', lowercase = True, strip_accents = True)<br/><br/>    tokens = torch.FloatTensor(tokenizer.encode(text).ids).unsqueeze(0).to('cpu')<br/>    cls_, subcls = model(tokens)<br/>    clsIdx = cls_.max(1)[-1].item()<br/>    subclsIdx = subcls.max(1)[-1].item()<br/><br/>    return {<br/>        "class": class2names[idx2class[clsIdx]],<br/>        "subclass": subclass2names[idx2subclass[subclsIdx]]<br/>    }</span></pre><p id="4e61" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated"><code class="fe me mf mg mh b">load_model</code>函数上的<code class="fe me mf mg mh b">@st.cache</code>装饰器缓存模型，因此，对于每个请求，模型加载过程不会重复。对于Flask和FastAPI服务器，可以将它们设置为全局变量，以避免每次请求都加载模型。</p><p id="c1ae" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">上面的片段基本上类似于在<code class="fe me mf mg mh b">inference.ipynb</code>文件中准备的推理脚本😅。</p><h2 id="41ff" class="mj mk it bd ml mm mn dn mo mp mq dp mr lr ms mt mu lv mv mw mx lz my mz na iz bi translated">🔵带Streamlit的用户界面</h2><p id="b4f4" class="pw-post-body-paragraph li lj it lk b ll nb kd ln lo nc kg lq lr nd lt lu lv ne lx ly lz nf mb mc md im bi translated">这是创建一个界面来部署您的模型并让最终用户或互联网上的任何人与之交互的最简单的方法之一。这里，我们将创建<code class="fe me mf mg mh b">streamlitapp.py</code>文件，并将下面的代码放入其中，它将创建UI并与上面的推理脚本<code class="fe me mf mg mh b">streamlitinf.py</code>交互。</p><ul class=""><li id="85fe" class="np nq it lk b ll lm lo lp lr nr lv ns lz nt md nu nv nw nx bi translated">进口</li></ul><pre class="ks kt ku kv gt ng mh nh ni aw nj bi"><span id="ebf5" class="mj mk it mh b gy nk nl l nm nn">import streamlit as st<br/>import time<br/>from streamlitinf import load_model, inf</span></pre><ul class=""><li id="62d1" class="np nq it lk b ll lm lo lp lr nr lv ns lz nt md nu nv nw nx bi translated">页面配置</li></ul><pre class="ks kt ku kv gt ng mh nh ni aw nj bi"><span id="05ee" class="mj mk it mh b gy nk nl l nm nn">st.set_page_config(<br/>    page_title = 'Question Classification',<br/>    page_icon = '❓',<br/>)</span></pre><ul class=""><li id="e207" class="np nq it lk b ll lm lo lp lr nr lv ns lz nt md nu nv nw nx bi translated">应用程序的标题和输入字段</li></ul><pre class="ks kt ku kv gt ng mh nh ni aw nj bi"><span id="e945" class="mj mk it mh b gy nk nl l nm nn">st.title("Question Classification")<br/>questionText = st.text_input("Input Question?")</span></pre><ul class=""><li id="b19b" class="np nq it lk b ll lm lo lp lr nr lv ns lz nt md nu nv nw nx bi translated">放置预测的占位符</li></ul><pre class="ks kt ku kv gt ng mh nh ni aw nj bi"><span id="b267" class="mj mk it mh b gy nk nl l nm nn">classPlaceHolder = st.empty()<br/>subclassPlaceHolder = st.empty()</span></pre><ul class=""><li id="9747" class="np nq it lk b ll lm lo lp lr nr lv ns lz nt md nu nv nw nx bi translated">对文本提交的预测</li></ul><pre class="ks kt ku kv gt ng mh nh ni aw nj bi"><span id="f204" class="mj mk it mh b gy nk nl l nm nn">if questionText:<br/>    with st.spinner(text = 'Inference in Progress...'):<br/>        model = load_model()<br/>        op = inf(questionText, model)<br/>    st.balloons()<br/>    classPlaceHolder.header(f"Class: {op['class']}")<br/>    subclassPlaceHolder.header(f"Subclass: {op['subclass']}")</span></pre><p id="7054" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">这样，我们就完成了UI的创建。很简单，对吧？没有HTML、CSS和JavaScript <code class="fe me mf mg mh b">onClick</code>方法来调用API调用。</p><p id="2690" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">现在，让我们运行应用程序，试试它是否有效，看看它看起来有多好。转到包含<code class="fe me mf mg mh b">streamlitapp.py</code>文件的文件夹，使用以下命令。</p><pre class="ks kt ku kv gt ng mh nh ni aw nj bi"><span id="ad40" class="mj mk it mh b gy nk nl l nm nn">$ streamlit run streamlitapp.py</span></pre><p id="14f0" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">该命令一执行，您就会看到以下屏幕</p><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi od"><img src="../Images/72d658128688a1c50b0d83f5cbfff64d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*rFSvriQv7H4-AvSdZqWIwQ.png"/></div></div><figcaption class="ld le gj gh gi lf lg bd b be z dk translated">作者图片</figcaption></figure><p id="2da0" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">让我们尝试一些问题，看看它的表现如何</p><figure class="ks kt ku kv gt kw"><div class="bz fp l di"><div class="oe of l"/></div><figcaption class="ld le gj gh gi lf lg bd b be z dk translated">作者提供的视频</figcaption></figure><p id="e6ba" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated"><em class="mi">这是您的本地系统，现在让我们看看如何将它发布到互联网上供人们尝试。</em></p><h2 id="ac29" class="mj mk it bd ml mm mn dn mo mp mq dp mr lr ms mt mu lv mv mw mx lz my mz na iz bi translated">🔵与Heroku一起部署</h2><p id="7bf0" class="pw-post-body-paragraph li lj it lk b ll nb kd ln lo nc kg lq lr nd lt lu lv ne lx ly lz nf mb mc md im bi translated"><em class="mi">此处</em>  <em class="mi">代码库可用</em> <a class="ae lh" href="https://github.com/vatsalsaglani/StreamlitQuestionClassification" rel="noopener ugc nofollow" target="_blank"> <em class="mi">。</em></a></p><p id="6463" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">如果你没有Heroku 账号，你可以在这里创建一个<a class="ae lh" href="https://signup.heroku.com/" rel="noopener ugc nofollow" target="_blank"/>(这是免费的)。注册Heroku后，您需要下载<code class="fe me mf mg mh b">Heroku CLI</code>，下载步骤<a class="ae lh" href="https://devcenter.heroku.com/articles/heroku-cli#download-and-install" rel="noopener ugc nofollow" target="_blank">请点击</a>。下载完CLI后，您就可以继续学习了。</p><ul class=""><li id="f170" class="np nq it lk b ll lm lo lp lr nr lv ns lz nt md nu nv nw nx bi translated">通过终端登录Heroku</li></ul><pre class="ks kt ku kv gt ng mh nh ni aw nj bi"><span id="30b2" class="mj mk it mh b gy nk nl l nm nn">$ heroku login</span></pre><p id="93a4" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">执行该命令时，将要求您按任意键，并带您到浏览器，在那里您可以使用您的凭证登录。登录后，您可以返回到终端并遵循其余步骤。</p><ul class=""><li id="5db4" class="np nq it lk b ll lm lo lp lr nr lv ns lz nt md nu nv nw nx bi translated">添加一个<code class="fe me mf mg mh b">requirements.txt</code>文件</li></ul><p id="5986" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">Heroku服务器在构建应用程序时将下载这个文件中列出的需求。我们使用PyTorch GPU来训练我们的模型，但Heroku只有CPU实例和您的<strong class="lk jd"> slug </strong>的最大大小，即<em class="mi"> slug size </em>，这意味着—所有依赖项的总大小、模型的大小以及我们为UI和推理部分编写的每个脚本的大小不应超过<strong class="lk jd"> 500 MBs </strong>。但是GPU和CPU PyTorch包本身的大小约为650到700 MBs，因此我们需要提供PyTorch包的CPU轮文件，它约为125 MBs，因此小于阈值段大小。这个<code class="fe me mf mg mh b">requirements.txt</code>文件看起来会像这样。</p><pre class="ks kt ku kv gt ng mh nh ni aw nj bi"><span id="0d91" class="mj mk it mh b gy nk nl l nm nn">&lt;https://download.pytorch.org/whl/cpu/torch-1.5.0%2Bcpu-cp36-cp36m-linux_x86_64.whl&gt;<br/>streamlit==0.74.1<br/>tokenizers==0.10.0<br/>numpy<br/>tqdm</span></pre><ul class=""><li id="48bc" class="np nq it lk b ll lm lo lp lr nr lv ns lz nt md nu nv nw nx bi translated">添加<code class="fe me mf mg mh b">setup.sh</code>和<code class="fe me mf mg mh b">Procfile</code></li></ul><pre class="ks kt ku kv gt ng mh nh ni aw nj bi"><span id="a1d4" class="mj mk it mh b gy nk nl l nm nn">mkdir -p ~/.streamlit/</span><span id="8c99" class="mj mk it mh b gy no nl l nm nn">echo "\\<br/>[general]\\n\\<br/>email = \\"your-email@domain.com\\"\\n\\<br/>" &gt; ~/.streamlit/credentials.toml</span><span id="5ab3" class="mj mk it mh b gy no nl l nm nn">echo "\\<br/>[server]\\n\\<br/>headless = true\\n\\<br/>enableCORS=false\\n\\<br/>port = $PORT\\n\\<br/>" &gt; ~/.streamlit/config.toml</span></pre><p id="d31c" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated"><em class="mi">过程文件</em></p><pre class="ks kt ku kv gt ng mh nh ni aw nj bi"><span id="113f" class="mj mk it mh b gy nk nl l nm nn">web: sh setup.sh &amp;&amp; streamlit run streamlitapp.py</span></pre><ul class=""><li id="8d47" class="np nq it lk b ll lm lo lp lr nr lv ns lz nt md nu nv nw nx bi translated">用<code class="fe me mf mg mh b">git</code>初始化你的文件夹</li></ul><p id="39bb" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">移动到包含<code class="fe me mf mg mh b">streamlitapp.py</code>文件的文件夹，执行下面的命令</p><pre class="ks kt ku kv gt ng mh nh ni aw nj bi"><span id="4adb" class="mj mk it mh b gy nk nl l nm nn">$ git init<br/>$ git add .<br/>$ git commit -m "some message"</span></pre><ul class=""><li id="6016" class="np nq it lk b ll lm lo lp lr nr lv ns lz nt md nu nv nw nx bi translated">创建Heroku应用程序</li></ul><pre class="ks kt ku kv gt ng mh nh ni aw nj bi"><span id="8433" class="mj mk it mh b gy nk nl l nm nn">$ heroku create</span></pre><p id="4c87" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated"><em class="mi">这将为您的应用创建一个</em> <code class="fe me mf mg mh b"><em class="mi">URL</em></code> <em class="mi">以托管在</em>上</p><ul class=""><li id="fd2b" class="np nq it lk b ll lm lo lp lr nr lv ns lz nt md nu nv nw nx bi translated">推动和构建</li></ul><pre class="ks kt ku kv gt ng mh nh ni aw nj bi"><span id="bf34" class="mj mk it mh b gy nk nl l nm nn">$ git push heroku master</span></pre><p id="8a07" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">这个命令将把所有的模型文件推送到Heroku存储库，并开始构建过程。它会自动检测它是一个python应用程序，并安装python、pip和设置工具。它将安装依赖项，并从<code class="fe me mf mg mh b">Procfile</code>知道启动Streamlit应用程序的入口点命令。</p><p id="f1a5" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">构建日志看起来会像这样</p><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi og"><img src="../Images/44dc8877b80963e9cbb0a2e88a17c54d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Yk-_YbaLFbJy_sZ1GPEmrw.png"/></div></div><figcaption class="ld le gj gh gi lf lg bd b be z dk translated">作者图片</figcaption></figure><p id="99b2" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">要检查web应用程序是否已部署并正在运行，请在您的终端上使用以下命令</p><pre class="ks kt ku kv gt ng mh nh ni aw nj bi"><span id="a401" class="mj mk it mh b gy nk nl l nm nn">$ heroku ps:scale web=1</span></pre><p id="1cbd" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">就这样，我们结束了这篇博客。总结这篇博客，它以一个咆哮开始(这本来是可以避免的)，接着谈到了数据专业人员编写前端代码所面临的一些困难，然后谈到了博客的关键，即零前端体验的交互式UI的模型部署的简化方式，最后，我们将<a class="ae lh" href="http://localhost" rel="noopener ugc nofollow" target="_blank"> localhost </a>上的内容部署到Heroku。总之，我写这个博客很开心，希望你也喜欢。</p><p id="bc89" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated"><em class="mi">我们在Heroku上部署的真人版在这里</em><a class="ae lh" href="https://classifyquestions.herokuapp.com/" rel="noopener ugc nofollow" target="_blank"><em class="mi"/></a><em class="mi">。如果你喜欢NLP并想了解自我注意力变形金刚，可以看看这个</em> <a class="ae lh" href="https://medium.com/nerd-for-tech/question-classification-using-self-attention-transformer-part-1-33e990636e76" rel="noopener"> <em class="mi">博客</em> </a> <em class="mi">。</em></p></div></div>    
</body>
</html>