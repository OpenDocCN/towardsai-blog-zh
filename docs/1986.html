<html>
<head>
<title>This Microsoft Neural Network can Generate Images from Short Texts</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">这个微软神经网络可以从短文本中生成图像</h1>
<blockquote>原文：<a href="https://pub.towardsai.net/this-microsoft-neural-network-can-generate-images-from-short-texts-4b9729a1e57f?source=collection_archive---------0-----------------------#2021-07-15">https://pub.towardsai.net/this-microsoft-neural-network-can-generate-images-from-short-texts-4b9729a1e57f?source=collection_archive---------0-----------------------#2021-07-15</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><h2 id="8fd5" class="ir is it bd b dl iu iv iw ix iy iz dk ja translated" aria-label="kicker paragraph"><a class="ae ep" href="https://towardsai.net/p/category/nlp" rel="noopener ugc nofollow" target="_blank">自然语言处理</a></h2><div class=""/><div class=""><h2 id="7ec6" class="pw-subtitle-paragraph jz jc it bd b ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq dk translated">新方法结合了生成模型和自然语言处理。</h2></div><figure class="kr ks kt ku gt kv gh gi paragraph-image"><div class="ab gu cl kw"><img src="../Images/b09a3d3961a9d1a7f9070c7c5dac4204.png" data-original-src="https://miro.medium.com/v2/format:webp/1*9cvy8UhlAEXjE-d8iO6cWA.png"/></div></figure><blockquote class="kz la lb"><p id="fa4e" class="lc ld le lf b lg lh kd li lj lk kg ll lm ln lo lp lq lr ls lt lu lv lw lx ly im bi translated">我最近创办了一份专注于人工智能的教育时事通讯，已经有超过90，000名订户。《序列》是一份无废话(意思是没有炒作，没有新闻等)的ML导向时事通讯，需要5分钟阅读。目标是让你与机器学习项目、研究论文和概念保持同步。请通过订阅以下内容来尝试一下:</p></blockquote><div class="lz ma gp gr mb mc"><a href="https://thesequence.substack.com/" rel="noopener  ugc nofollow" target="_blank"><div class="md ab fo"><div class="me ab mf cl cj mg"><h2 class="bd jd gy z fp mh fr fs mi fu fw jc bi translated">序列</h2><div class="mj l"><h3 class="bd b gy z fp mh fr fs mi fu fw dk translated">订阅人工智能世界中最相关的项目和研究论文。受到85，000多人的信任…</h3></div><div class="mk l"><p class="bd b dl z fp mh fr fs mi fu fw dk translated">thesequence.substack.com</p></div></div><div class="ml l"><div class="mm l mn mo mp ml mq kx mc"/></div></div></a></div><p id="1cf5" class="pw-post-body-paragraph lc ld it lf b lg lh kd li lj lk kg ll mr ln lo lp ms lr ls lt mt lv lw lx ly im bi translated">人类在图像中建立知识。每当我们有一个想法或一次经历时，我们的大脑会立即形成它的视觉表现。类似地，我们的大脑不断在声音或纹理等感官信号与其视觉表征之间进行上下文切换。我们用视觉表示进行思考的能力还没有完全扩展到人工智能(AI)算法。今天，大多数人工智能模型都高度专注于一种形式的数据表示，如图像、文本或声音。最终，我们将开始看到能够在不同数据格式之间高效翻译的人工智能形式，以优化知识的创造。最近，来自微软<a class="ae mu" href="https://www.microsoft.com/en-us/research/publication/object-driven-text-to-image-synthesis-via-adversarial-training/" rel="noopener ugc nofollow" target="_blank">的人工智能研究人员发表了一篇论文，提出了一种基于短文本生成图像的方法。</a></p><p id="9999" class="pw-post-body-paragraph lc ld it lf b lg lh kd li lj lk kg ll mr ln lo lp ms lr ls lt mt lv lw lx ly im bi translated">我们从声音或文字描述中产生视觉表现的能力是人类认知的神奇要素之一。如果你被要求画一个篮球比赛的图像，你可能会从位于画布中心的三个或四个球员的轮廓开始。即使没有直接指定，你也可以添加一些细节，比如乌鸦，裁判，或者特定投篮位置的球员。所有这些细节丰富了基本的文本描述，以实现我们的篮球比赛的视觉版本。如果人工智能模型也能做到这一点，岂不是很棒？文本到图像(TTI)是深度学习的新兴学科之一，专注于从基本的文本表示生成图像。虽然TTI领域还处于非常早期的阶段，但我们已经看到了一些切实的进展，一些模型已被证明在非常具体的场景中非常熟练。然而，它们是TTI模型中仍需解决的非常具体的挑战。</p><h1 id="f0cf" class="mv mw it bd mx my mz na nb nc nd ne nf ki ng kj nh kl ni km nj ko nk kp nl nm bi translated">从文本生成图像:挑战与思考</h1><p id="e528" class="pw-post-body-paragraph lc ld it lf b lg nn kd li lj no kg ll mr np lo lp ms nq ls lt mt nr lw lx ly im bi translated">有几个相关的挑战传统上阻碍了TTI模型的发展，但其中大多数可以归为以下几类？</p><p id="bec5" class="pw-post-body-paragraph lc ld it lf b lg lh kd li lj lk kg ll mr ln lo lp ms lr ls lt mt lv lw lx ly im bi translated">1) <strong class="lf jd">依赖性挑战:</strong>显然，TTI模型高度依赖文本和视觉分析技术，尽管近年来它们取得了很大进展，但要实现主流采用还有很多工作要做。从这个角度来看，TTI模型的功能通常会受到底层文本分析和图像生成模型的限制。</p><p id="31a4" class="pw-post-body-paragraph lc ld it lf b lg lh kd li lj lk kg ll mr ln lo lp ms lr ls lt mt lv lw lx ly im bi translated">2) <strong class="lf jd">概念-对象关系:</strong>TTI模型中要解决的一个难以置信的难题是从文本描述中提取的概念与其对应的视觉对象之间的关系。实际上，可能有无限数量的对象匹配特定的文本描述。在TTI模型中，找出概念和对象之间的正确匹配仍然是关键的挑战。</p><p id="c615" class="pw-post-body-paragraph lc ld it lf b lg lh kd li lj lk kg ll mr ln lo lp ms lr ls lt mt lv lw lx ly im bi translated">3) <strong class="lf jd">物物关系:</strong>任何图像都是以视觉的形式表达物体之间的关系。为了反映给定的叙述，TTI模型不仅要生成正确的对象，还要生成它们之间的关系。在文本到图像生成技术中，生成包含多个对象并且这些对象之间具有语义上有意义的关系的更复杂的场景仍然是一个重大挑战。</p><h1 id="98d0" class="mv mw it bd mx my mz na nb nc nd ne nf ki ng kj nh kl ni km nj ko nk kp nl nm bi translated">对象驱动的注意GAN</h1><p id="1d0c" class="pw-post-body-paragraph lc ld it lf b lg nn kd li lj no kg ll mr np lo lp ms nq ls lt mt nr lw lx ly im bi translated">为了应对TTI模型的一些传统挑战，微软研究院依赖于日益流行的生成对抗网络(GANs)技术。GANs通常由两个机器学习模型组成——一个从文本描述生成图像的生成器，一个使用文本描述判断生成图像真实性的鉴别器。生成器试图让假图片通过鉴别器；另一方面，歧视者从不希望被愚弄。一起工作，鉴别器将发电机推向完美。微软对传统的GAN模型进行了创新，加入了自下而上的注意机制。Obj-GAN模型开发了一个对象驱动的注意力生成器和一个对象式鉴别器，从而使GANs能够合成复杂场景的高质量图像。</p><p id="4374" class="pw-post-body-paragraph lc ld it lf b lg lh kd li lj lk kg ll mr ln lo lp ms lr ls lt mt lv lw lx ly im bi translated">Obj-GAN的核心架构分两步执行TTI合成:</p><p id="e7d0" class="pw-post-body-paragraph lc ld it lf b lg lh kd li lj lk kg ll mr ln lo lp ms lr ls lt mt lv lw lx ly im bi translated"><strong class="lf jd"> 1)生成语义布局:</strong>该阶段包括生成元素，如类别标签、包围盒、显著对象的形状等。这个功能由两个主要组件完成:盒子生成器和形状生成器。</p><p id="6120" class="pw-post-body-paragraph lc ld it lf b lg lh kd li lj lk kg ll mr ln lo lp ms lr ls lt mt lv lw lx ly im bi translated"><strong class="lf jd"> 2)生成最终图像:</strong>该功能由一个多级图像生成器和一个鉴别器完成。</p><p id="ebc8" class="pw-post-body-paragraph lc ld it lf b lg lh kd li lj lk kg ll mr ln lo lp ms lr ls lt mt lv lw lx ly im bi translated">下图提供了Obj-GAN模型的高级架构。该模型接收具有一组标记的句子作为输入，然后将其编码为单词向量。之后，输入通过三个主要阶段进行处理:盒子生成、形状生成和图像生成。</p><figure class="kr ks kt ku gt kv gh gi paragraph-image"><div role="button" tabindex="0" class="nt nu di nv bf nw"><div class="gh gi ns"><img src="../Images/aa533074a90f8a4f7863c5be68beb77c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*aqoGpiRB1d71YXyPQa-aaw.png"/></div></div><figcaption class="nx ny gj gh gi nz oa bd b be z dk translated">图片来源:微软研究院</figcaption></figure><p id="a3fa" class="pw-post-body-paragraph lc ld it lf b lg lh kd li lj lk kg ll mr ln lo lp ms lr ls lt mt lv lw lx ly im bi translated">Obj-GAN模型的第一步将句子作为输入，并生成语义布局，即由边界框指定的对象序列。模型的框生成器负责生成一系列边界框，然后由形状生成器使用。给定一组边界框作为输入，形状生成器预测每个对象在其对应的框中的形状。由形状生成器产生的形状然后被图像生成器GAN模型使用。</p><p id="099b" class="pw-post-body-paragraph lc ld it lf b lg lh kd li lj lk kg ll mr ln lo lp ms lr ls lt mt lv lw lx ly im bi translated">Obj-GAN包括一个基于两个主要生成器的多级图像生成器神经网络。基本生成器首先根据全局句子向量和预先生成的语义布局生成低分辨率图像。然后，第二个生成器通过关注最相关的单词和预先生成的类别标签来细化不同区域的细节，并生成更高的分辨率。</p><figure class="kr ks kt ku gt kv gh gi paragraph-image"><div role="button" tabindex="0" class="nt nu di nv bf nw"><div class="gh gi ob"><img src="../Images/22158d44c916651402329eab37632506.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*PBI4n261RPiFc0hfIH1cUg.jpeg"/></div></div><figcaption class="nx ny gj gh gi nz oa bd b be z dk translated">图片来源:微软研究院</figcaption></figure><p id="448a" class="pw-post-body-paragraph lc ld it lf b lg lh kd li lj lk kg ll mr ln lo lp ms lr ls lt mt lv lw lx ly im bi translated">到目前为止，您可能想知道架构的对抗性组件在哪里发挥作用？这就是基于对象的鉴别器的作用。这个组件的作用是作为训练图像生成器的对手。Obj-GAN模型包括两个主要鉴别器:</p><p id="62c0" class="pw-post-body-paragraph lc ld it lf b lg lh kd li lj lk kg ll mr ln lo lp ms lr ls lt mt lv lw lx ly im bi translated"><strong class="lf jd">逐片鉴别器:</strong>该鉴别器用于训练盒子和形状生成器。第一个鉴别器试图评估生成的边界框是否对应于给定的句子，而第二个鉴别器做同样的事情来评估边界框和形状之间的对应关系。</p><p id="927b" class="pw-post-body-paragraph lc ld it lf b lg lh kd li lj lk kg ll mr ln lo lp ms lr ls lt mt lv lw lx ly im bi translated"><strong class="lf jd">基于对象的鉴别器:</strong>该鉴别器使用一组边界框和对象标签作为输入，并试图确定生成的图像是否符合原始描述。</p><p id="7092" class="pw-post-body-paragraph lc ld it lf b lg lh kd li lj lk kg ll mr ln lo lp ms lr ls lt mt lv lw lx ly im bi translated">对盒子、形状和图像生成使用对立的生成器-鉴别器组合使Obj-GAN比其他传统的TTI方法更有优势。微软用最先进的TTI模型对Obj-GAN进行了评估，结果非常显著。只要看看生成的图像质量的差异以及它们与原始句子的对应关系。</p><figure class="kr ks kt ku gt kv gh gi paragraph-image"><div role="button" tabindex="0" class="nt nu di nv bf nw"><div class="gh gi ob"><img src="../Images/6f12ae0542d98cd66dccd32876af631f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*AmFl8Ed1N3rq1Lcw2G0UYw.jpeg"/></div></div><figcaption class="nx ny gj gh gi nz oa bd b be z dk translated">图片来源:微软研究院</figcaption></figure><p id="0d9f" class="pw-post-body-paragraph lc ld it lf b lg lh kd li lj lk kg ll mr ln lo lp ms lr ls lt mt lv lw lx ly im bi translated">创建给定叙事的视觉表示的能力将是下一代文本和图像分析深度学习模型的重要焦点。Obj-GAN等想法无疑将相关创新带入了深度学习领域。</p></div></div>    
</body>
</html>