<html>
<head>
<title>DeepMind’s New Super Model: Perceiver IO is a Transformer that can Handle Any Dataset</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">DeepMind的新超级模型:感知者IO是一个可以处理任何数据集的转换器</h1>
<blockquote>原文：<a href="https://pub.towardsai.net/deepminds-new-super-model-perceiver-io-is-a-transformer-that-can-handle-any-dataset-dfcffa85fe61?source=collection_archive---------0-----------------------#2021-08-10">https://pub.towardsai.net/deepminds-new-super-model-perceiver-io-is-a-transformer-that-can-handle-any-dataset-dfcffa85fe61?source=collection_archive---------0-----------------------#2021-08-10</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><h2 id="158a" class="ir is it bd b dl iu iv iw ix iy iz dk ja translated" aria-label="kicker paragraph"><a class="ae ep" href="https://towardsai.net/p/category/artificial-intelligence" rel="noopener ugc nofollow" target="_blank">人工智能</a></h2><div class=""/><div class=""><h2 id="97b7" class="pw-subtitle-paragraph jz jc it bd b ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq dk translated">新的基于transformer的架构可以使用单一模型处理音频、视频和图像。</h2></div><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi kr"><img src="../Images/706a08632d44164d2a4b242161fc0a76.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*eE2xfcAEyuTW79S4.jpg"/></div></div><figcaption class="ld le gj gh gi lf lg bd b be z dk translated">来源:<a class="ae lh" href="https://www.zdnet.com/article/googles-supermodel-deepmind-perceiver-is-a-step-on-the-road-to-an-ai-machine-that-could-process-everything/" rel="noopener ugc nofollow" target="_blank">https://www . zdnet . com/article/Google s-super model-deep mind-epider-is-a-step-on-a-ai-machine-that-can-process-everything/</a></figcaption></figure><blockquote class="li lj lk"><p id="8d94" class="ll lm ln lo b lp lq kd lr ls lt kg lu lv lw lx ly lz ma mb mc md me mf mg mh im bi translated">我最近创办了一份专注于人工智能的教育时事通讯，已经有超过10万名订户。《序列》是一份无废话(意思是没有炒作，没有新闻等)的ML导向时事通讯，需要5分钟阅读。目标是让你与机器学习项目、研究论文和概念保持同步。请通过订阅以下内容来尝试一下:</p></blockquote><div class="mi mj gp gr mk ml"><a href="https://thesequence.substack.com/" rel="noopener  ugc nofollow" target="_blank"><div class="mm ab fo"><div class="mn ab mo cl cj mp"><h2 class="bd jd gy z fp mq fr fs mr fu fw jc bi translated">序列</h2><div class="ms l"><h3 class="bd b gy z fp mq fr fs mr fu fw dk translated">订阅人工智能世界中最相关的项目和研究论文。受到85，000多人的信任…</h3></div><div class="mt l"><p class="bd b dl z fp mq fr fs mr fu fw dk translated">thesequence.substack.com</p></div></div><div class="mu l"><div class="mv l mw mx my mu mz lb ml"/></div></div></a></div><p id="3e7c" class="pw-post-body-paragraph ll lm it lo b lp lq kd lr ls lt kg lu na lw lx ly nb ma mb mc nc me mf mg mh im bi translated">我们目前构建的大多数深度学习模型都是针对特定类型的数据集进行了高度优化的。擅长处理文本数据的架构不能应用于计算机视觉或音频分析。这种专业化水平自然会影响模型的创建，这些模型在给定的任务中高度专业化，而不能适应其他任务。这种限制与人类认知形成强烈对比，在人类认知中，许多任务需要不同的输入，如视觉和听觉。最近，DeepMind发表了两篇论文，揭示了可以处理不同类型的输入数据集的通用架构。</p><p id="7ec0" class="pw-post-body-paragraph ll lm it lo b lp lq kd lr ls lt kg lu na lw lx ly nb ma mb mc nc me mf mg mh im bi translated">第一篇论文名为<a class="ae lh" href="https://arxiv.org/abs/2103.03206" rel="noopener ugc nofollow" target="_blank">“感知者:迭代注意力的一般感知”</a>介绍了感知者，一种转换器架构，可以处理包括图像、点云、音频、视频及其组合在内的数据，但仅限于分类等简单任务。在<a class="ae lh" href="https://arxiv.org/abs/2107.14795" rel="noopener ugc nofollow" target="_blank">“感知者IO:结构化输入&amp;输出的通用架构”</a>中，DeepMind展示了感知者IO，这是一个更通用的感知者模型版本，可以应用于复杂的多模态任务，如计算机游戏。</p><p id="8cb9" class="pw-post-body-paragraph ll lm it lo b lp lq kd lr ls lt kg lu na lw lx ly nb ma mb mc nc me mf mg mh im bi translated">两种感知模型都基于变压器架构。尽管它在像Google BERT或OpenAI GPT-3这样的模型上取得了成功，但大多数transformer模型在输入最多几千个元素的场景中最为有效。图像、视频或书籍等数据类型可能包含数百万个元素，这使得使用转换器有点困难。为了解决这个问题，感知者依赖于一般的注意力层，它不对输入做出任何特定领域的假设。具体地，感知者注意力模型首先将输入编码成较小的潜在阵列，其处理成本与输入的大小无关。这允许感知者模型随着输入适度地缩放。</p><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi nd"><img src="../Images/f6f9042be44234e8b28aef4af46afef0.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*MToGgVxGTQj_PEsR"/></div></div><figcaption class="ld le gj gh gi lf lg bd b be z dk translated">图片来源:DeepMind</figcaption></figure><p id="ede0" class="pw-post-body-paragraph ll lm it lo b lp lq kd lr ls lt kg lu na lw lx ly nb ma mb mc nc me mf mg mh im bi translated">除了可伸缩性优势之外，以前的架构允许感知者模型使用不同的数据集实现健壮的概括水平。请参见下面重建视频和音频输入的示例。</p><p id="b79b" class="pw-post-body-paragraph ll lm it lo b lp lq kd lr ls lt kg lu na lw lx ly nb ma mb mc nc me mf mg mh im bi translated">以下是原视频。</p><figure class="ks kt ku kv gt kw"><div class="bz fp l di"><div class="ne nf l"/></div><figcaption class="ld le gj gh gi lf lg bd b be z dk translated">视频鸣谢:DeepMind</figcaption></figure><p id="5f46" class="pw-post-body-paragraph ll lm it lo b lp lq kd lr ls lt kg lu na lw lx ly nb ma mb mc nc me mf mg mh im bi translated">这是感知者产生的结果。</p><figure class="ks kt ku kv gt kw"><div class="bz fp l di"><div class="ne nf l"/></div><figcaption class="ld le gj gh gi lf lg bd b be z dk translated">视频鸣谢:DeepMind</figcaption></figure><p id="5080" class="pw-post-body-paragraph ll lm it lo b lp lq kd lr ls lt kg lu na lw lx ly nb ma mb mc nc me mf mg mh im bi translated">超级印象深刻！感知者是首批能够处理不同输入类型的大规模架构之一。在未来的研究中，我们很可能会看到DeepMind在这个概念上加倍努力。</p><p id="78bb" class="pw-post-body-paragraph ll lm it lo b lp lq kd lr ls lt kg lu na lw lx ly nb ma mb mc nc me mf mg mh im bi translated">在过去几年的深度学习中，变压器架构一直是最相关的里程碑的前沿和中心。变形金刚主要应用于谷歌BERT或OpenAI GPT-3等模型的自然语言场景，在计算机视觉等其他领域也取得了稳步进展。</p></div></div>    
</body>
</html>