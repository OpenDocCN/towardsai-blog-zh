<html>
<head>
<title>Tweet Topic Modeling: Using Short Text Topic Modeling on Tweets</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">Tweet主题建模:在tweet上使用短文本主题建模</h1>
<blockquote>原文：<a href="https://pub.towardsai.net/tweet-topic-modeling-part-3-using-short-text-topic-modeling-on-tweets-bc969a827fef?source=collection_archive---------0-----------------------#2021-01-19">https://pub.towardsai.net/tweet-topic-modeling-part-3-using-short-text-topic-modeling-on-tweets-bc969a827fef?source=collection_archive---------0-----------------------#2021-01-19</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><h2 id="ca9a" class="ir is it bd b dl iu iv iw ix iy iz dk ja translated" aria-label="kicker paragraph"><a class="ae ep" href="https://towardsai.net/p/category/data-mining" rel="noopener ugc nofollow" target="_blank">数据挖掘</a>，<a class="ae ep" href="https://towardsai.net/p/category/nlp" rel="noopener ugc nofollow" target="_blank">自然语言处理</a>，<a class="ae ep" href="https://towardsai.net/p/category/programming" rel="noopener ugc nofollow" target="_blank">编程</a></h2><div class=""/><div class=""><h2 id="7e03" class="pw-subtitle-paragraph jz jc it bd b ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq dk translated">这是一个多部分的系列，展示了如何为任何tweets集合收集、预处理、应用和可视化短文本主题建模</h2></div><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div class="gh gi kr"><img src="../Images/8dffe7a9481d6311a622427075d1202f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1218/format:webp/1*uiwNL8ReWla6rnergTHucg.jpeg"/></div></figure><p id="d6f0" class="pw-post-body-paragraph kz la it lb b lc ld kd le lf lg kg lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><strong class="lb jd"> <em class="lv">免责声明:</em> </strong> <em class="lv">本文仅出于教育目的。我们不鼓励任何人抓取网站，尤其是那些可能有条款和条件反对此类行为的网站。</em></p></div><div class="ab cl lw lx hx ly" role="separator"><span class="lz bw bk ma mb mc"/><span class="lz bw bk ma mb mc"/><span class="lz bw bk ma mb"/></div><div class="im in io ip iq"><h1 id="4d01" class="md me it bd mf mg mh mi mj mk ml mm mn ki mo kj mp kl mq km mr ko ms kp mt mu bi translated">介绍</h1><p id="ec8d" class="pw-post-body-paragraph kz la it lb b lc mv kd le lf mw kg lh li mx lk ll lm my lo lp lq mz ls lt lu im bi translated">主题建模是一种无监督的机器学习方法，目标是找到文本文档集合(语料库)中的“隐藏”主题(或聚类)。它真正的优势在于，你不需要带标签或带注释的数据，而是只接受原始文本数据作为输入，这也是它不受监督的原因。换句话说，模型在看到数据时并不知道主题是什么，而是使用所有文档中单词之间的统计关系来生成它们。</p><p id="35c2" class="pw-post-body-paragraph kz la it lb b lc ld kd le lf lg kg lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">最流行的主题建模方法之一是<strong class="lb jd">潜在狄利克雷分配(LDA) </strong>，这是一种生成概率模型算法，揭示了管理文档语义的潜在变量，这些变量代表抽象主题。LDA(以及一般的主题建模)的典型应用是将其应用于一组新闻文章，以识别共同的主题或话题，如科学、政治、金融等。然而，LDA的一个缺点是它不能很好地处理较短的文本，如<strong class="lb jd"> tweets。</strong>这是最近的<strong class="lb jd">短文本主题建模(STTM) </strong>的方法，其中一些建立在LDA之上，派上用场并且表现更好！</p><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div class="gh gi kr"><img src="../Images/8dffe7a9481d6311a622427075d1202f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1218/format:webp/1*uiwNL8ReWla6rnergTHucg.jpeg"/></div><figcaption class="na nb gj gh gi nc nd bd b be z dk translated">拥有健康专用Twitter账户的主要新闻来源(<em class="ne">作者图片</em>)</figcaption></figure><p id="595a" class="pw-post-body-paragraph kz la it lb b lc ld kd le lf lg kg lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">这一系列帖子旨在展示和解释如何使用Python来执行和应用特定的STTM方法(<strong class="lb jd">Gibbs Sampling Dirichlet Mixture Model</strong>或<strong class="lb jd"> GSDMM </strong>)来处理Twitter上的健康推文。它将是数据搜集/清理、编程、数据可视化和机器学习的结合。我将在接下来的4篇文章中依次讨论所有主题:</p><blockquote class="nf ng nh"><p id="a92d" class="kz la lv lb b lc ld kd le lf lg kg lh ni lj lk ll nj ln lo lp nk lr ls lt lu im bi translated"><a class="ae nl" href="https://medium.com/towards-artificial-intelligence/tweet-topic-modeling-using-twint-to-scrape-tweets-part-1-a9274e5199d2" rel="noopener">第1部分:从Twitter上抓取推文</a></p><p id="5ea8" class="kz la lv lb b lc ld kd le lf lg kg lh ni lj lk ll nj ln lo lp nk lr ls lt lu im bi translated"><a class="ae nl" href="https://medium.com/towards-artificial-intelligence/tweet-topic-modeling-part-2-cleaning-and-preprocessing-tweets-e3a08a8b1770" rel="noopener">第二部分:清理和预处理推文</a></p><p id="cce5" class="kz la lv lb b lc ld kd le lf lg kg lh ni lj lk ll nj ln lo lp nk lr ls lt lu im bi translated"><strong class="lb jd"> <em class="it">第三部分:应用短文本主题建模</em> </strong></p></blockquote><p id="75a1" class="pw-post-body-paragraph kz la it lb b lc ld kd le lf lg kg lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><a class="ae nl" href="https://medium.com/towards-artificial-intelligence/tweet-topic-modeling-part-4-visualizing-topic-modeling-results-with-plotly-66d5dbaaf7fb" rel="noopener"> <em class="lv">第四部分:可视化主题建模结果</em> </a></p><p id="6538" class="pw-post-body-paragraph kz la it lb b lc ld kd le lf lg kg lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">这些文章不会深入到LDA或STTM的细节，而是解释他们的直觉和需要知道的关键概念。鼓励有兴趣对LDA有更透彻的统计理解的读者查看这些伟大的文章和资源<a class="ae nl" href="http://www.cs.columbia.edu/~blei/papers/Blei2012.pdf" rel="noopener ugc nofollow" target="_blank"> <strong class="lb jd">这里</strong> </a>和<a class="ae nl" href="https://ldabook.com/index.html" rel="noopener ugc nofollow" target="_blank"> <strong class="lb jd">这里</strong> </a>。</p><p id="ebb2" class="pw-post-body-paragraph kz la it lb b lc ld kd le lf lg kg lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">作为先决条件，确保你的电脑上已经安装了<a class="ae nl" href="https://jupyter.readthedocs.io/en/latest/install.html" rel="noopener ugc nofollow" target="_blank"> Jupyter Notebook </a>、<a class="ae nl" href="https://www.python.org/downloads/" rel="noopener ugc nofollow" target="_blank"> Python </a>、&amp;、<a class="ae nl" href="https://git-scm.com/downloads" rel="noopener ugc nofollow" target="_blank"> Git </a>。</p><p id="057c" class="pw-post-body-paragraph kz la it lb b lc ld kd le lf lg kg lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">好吧，我们继续！</p></div><div class="ab cl lw lx hx ly" role="separator"><span class="lz bw bk ma mb mc"/><span class="lz bw bk ma mb mc"/><span class="lz bw bk ma mb"/></div><div class="im in io ip iq"><h1 id="1d25" class="md me it bd mf mg mh mi mj mk ml mm mn ki mo kj mp kl mq km mr ko ms kp mt mu bi translated">第3部分:应用短文本主题建模(STTM)</h1><p id="e66c" class="pw-post-body-paragraph kz la it lb b lc mv kd le lf mw kg lh li mx lk ll lm my lo lp lq mz ls lt lu im bi translated">在<a class="ae nl" href="https://medium.com/towards-artificial-intelligence/tweet-topic-modeling-part-2-cleaning-and-preprocessing-tweets-e3a08a8b1770" rel="noopener">上一篇文章</a>中，我们对所有的推文进行了预处理，为数据集中的每条推文生成了一个带有词汇化标记的数据框架。如果您刚刚加入我们的第3部分，此处提供的最终CSV<a class="ae nl" href="https://github.com/bicachu/short-text-topic-modeling-tutorial/blob/main/data/preprocessed_tweets.csv" rel="noopener ugc nofollow" target="_blank">供您参考。</a></p><p id="437f" class="pw-post-body-paragraph kz la it lb b lc ld kd le lf lg kg lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">本文将通过执行一些初步的探索性分析，然后在我们的数据上使用GSDMM算法构建一个STTM模型管道来生成主题。然后，我们将解释我们的结果，并尝试根据每个主题中的单词分布来分配主题。</p><h2 id="d91b" class="nm me it bd mf nn no dn mj np nq dp mn li nr ns mp lm nt nu mr lq nv nw mt iz bi translated">探索性数据分析</h2><p id="7c17" class="pw-post-body-paragraph kz la it lb b lc mv kd le lf mw kg lh li mx lk ll lm my lo lp lq mz ls lt lu im bi translated">让我们从做一些EDA开始。由于我们使用健康新闻推文数据集的关键目标之一是探索一段时间内的趋势，因此了解每日推文计数的密度可能是有用的。</p><pre class="ks kt ku kv gt nx ny nz oa aw ob bi"><span id="62a0" class="nm me it ny b gy oc od l oe of">import pandas as pd<br/>import matplotlib.pyplot as plt<br/>tweets_df = pd.read_csv(r'data/preprocessed_tweets.csv') #load data</span><span id="0674" class="nm me it ny b gy og od l oe of"># convert datetime to date and add year column<br/>tweets_df['date'] = pd.to_datetime(tweets_df['date'],<br/>                                   errors='coerce')<br/>tweets_df['year'] = tweets_df['date'].dt.year<br/>tweets_df['date'] = tweets_df['date'].dt.date</span><span id="87c8" class="nm me it ny b gy og od l oe of"># plot tweet daily counts over time<br/>tweets_df.groupby('date')['tweet'].count().plot(kind='line', color='green', figsize=(16,8))<br/>plt.xlabel('Year')<br/>plt.ylabel('Daily Tweets')<br/>plt.show()</span></pre><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="oi oj di ok bf ol"><div class="gh gi oh"><img src="../Images/d3d3f297325e84dc7d7b5528efbd7989.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*kggU0423KarmFu08LVEN0w.jpeg"/></div></div></figure><p id="131e" class="pw-post-body-paragraph kz la it lb b lc ld kd le lf lg kg lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">看起来在2020年数据集时间线的末尾，每天的推文会有一个巨大的峰值。这实际上对于包含健康新闻推文的数据集是有意义的，因为这大约是2020年新冠肺炎健康疫情的开始👨‍⚕️⚕️️.</p><p id="05ec" class="pw-post-body-paragraph kz la it lb b lc ld kd le lf lg kg lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">另一个我们可能想看看的领域是不同新闻来源的推文中剩余的平均字数(当然是在我们去掉停用词之后)。</p><pre class="ks kt ku kv gt nx ny nz oa aw ob bi"><span id="7792" class="nm me it ny b gy oc od l oe of"># calculate number of tokens for each tweet<br/>tweets_df[‘ntokens’] = tweets_df[‘tokens’].str.split().str.len()</span><span id="08ee" class="nm me it ny b gy og od l oe of"># plot average word count by user<br/>tweets_df.groupby(‘username’)     <br/>                 [‘ntokens’].mean().plot(kind=’barh’,figsize=(10,5))<br/>plt.xlabel(‘Average Words’)<br/>plt.ylabel(‘News Account’)<br/>plt.show()</span></pre><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div class="gh gi om"><img src="../Images/1167ab5bfc884ce6752f0dd1f9b61785.png" data-original-src="https://miro.medium.com/v2/resize:fit:1362/format:webp/1*0B0ySw7pQclo2BFR_rtI3w.jpeg"/></div></figure><p id="9acf" class="pw-post-body-paragraph kz la it lb b lc ld kd le lf lg kg lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">看起来大多数新闻来源平均有6-8个令牌。我不知道你怎么想，但对我来说，这听起来像是短文本的A+范例！</p><h2 id="9c4b" class="nm me it bd mf nn no dn mj np nq dp mn li nr ns mp lm nt nu mr lq nv nw mt iz bi translated">STTM概述</h2><p id="82fe" class="pw-post-body-paragraph kz la it lb b lc mv kd le lf mw kg lh li mx lk ll lm my lo lp lq mz ls lt lu im bi translated">在我们开始实现STTM方法之前，让我们多谈一谈为什么我们要用它来代替传统的主题建模算法，比如LDA。从一个<em class="lv">非常</em>高的水平，LDA产生2个统计分布:</p><blockquote class="on"><p id="246d" class="oo op it bd oq or os ot ou ov ow lu dk translated">1)每个主题的一组单词分布</p><p id="53c1" class="oo op it bd oq or os ot ou ov ow lu dk translated">2)每个文档的一组主题分布</p></blockquote><p id="85e7" class="pw-post-body-paragraph kz la it lb b lc ox kd le lf oy kg lh li oz lk ll lm pa lo lp lq pb ls lt lu im bi translated">这意味着，生成的每个主题都有相关的概率，即单词与其密切相关，并且文档可以由多个主题组成，每个主题都有自己的权重。例如，如果您的文档是一篇新闻📰关于stars⭐和球形行星🌎，LDA可能会生成以下主题和单词分布:</p><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="oi oj di ok bf ol"><div class="gh gi pc"><img src="../Images/0cc5cd4e030549b7a25b3b7b32cdfdc6.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*F1XQH7PIzmfGzdlYCTpsZQ.jpeg"/></div></div><figcaption class="na nb gj gh gi nc nd bd b be z dk translated">一篇科学新闻文章的主题/单词分布的简单但合理的例子</figcaption></figure><p id="c9a2" class="pw-post-body-paragraph kz la it lb b lc ld kd le lf lg kg lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">这在中型或大型文本中很有效，但在短文本中并不总是如此(&lt; 50 words) because of these key characteristics:</p><ul class=""><li id="c8ed" class="pd pe it lb b lc ld lf lg li pf lm pg lq ph lu pi pj pk pl bi translated">Each short text lacks enough word co-occurrence information.<strong class="lb jd">单词共现</strong>是两个单词在文本中同时出现的机会，它有助于推断所生成主题的单词分布。</li><li id="633f" class="pd pe it lb b lc pm lf pn li po lm pp lq pq lu pi pj pk pl bi translated">由于包含最少的单词，大多数主题可能仅由一个主题生成。</li><li id="2d2a" class="pd pe it lb b lc pm lf pn li po lm pp lq pq lu pi pj pk pl bi translated">文本中单词的统计信息不能完全捕获语义相关但很少共现的单词。</li></ul><p id="6620" class="pw-post-body-paragraph kz la it lb b lc ld kd le lf lg kg lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">因此，大多数STTM技术最初假设一篇短文本仅来自一个主题，从而减少了我们在LDA中看到的重叠主题。</p><h2 id="6364" class="nm me it bd mf nn no dn mj np nq dp mn li nr ns mp lm nt nu mr lq nv nw mt iz bi translated">吉布斯采样狄利克雷混合模型</h2><p id="c28c" class="pw-post-body-paragraph kz la it lb b lc mv kd le lf mw kg lh li mx lk ll lm my lo lp lq mz ls lt lu im bi translated">我们将为STTM使用的特定模型是Gibbs抽样Dirichlet混合模型(GSDMM ),它是一种改进的LDA算法，使用一个主题分配给一个文本的简单假设。</p><p id="c23f" class="pw-post-body-paragraph kz la it lb b lc ld kd le lf lg kg lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">在深入研究它的代码之前，让我们用一个叫做<strong class="lb jd">电影组过程(MGP) </strong>的类比来理解它在高层做了什么，这个类比是由介绍它的研究人员提出的。</p><p id="be17" class="pw-post-body-paragraph kz la it lb b lc ld kd le lf lg kg lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">这个想法很简单。想象一下，一位教授正在带领一班学生上电影课。开始上课时，学生们都被要求写下他们最喜欢的电影(相对入围)。学生代表文档，他们的电影列表代表单词。接下来，学生被随机分配到<code class="fe pr ps pt ny b">K</code>桌。目标是以这样一种方式对他们进行聚类和分组，即同一桌的学生分享相似的电影兴趣。最后，教授反复阅读班级花名册；每次叫到学生的名字时，他们必须选择满足以下一个或两个条件的新表:</p><p id="d8ab" class="pw-post-body-paragraph kz la it lb b lc ld kd le lf lg kg lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><em class="lv">1——选择一张学生人数多于当前学生人数的桌子。</em></p><p id="0f0d" class="pw-post-body-paragraph kz la it lb b lc ld kd le lf lg kg lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><em class="lv">2——选择一张桌子，让学生们分享相似的电影兴趣。</em></p><p id="35c5" class="pw-post-body-paragraph kz la it lb b lc ld kd le lf lg kg lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">条件1提高了<strong class="lb jd">完整性，</strong>所有对电影有相似兴趣的学生都坐在同一张桌子上，而不是分散在不同的桌子上。条件2有助于导致更好的<strong class="lb jd">同质性</strong>，确保<em class="lv">只有利益相似的</em>成员才会参与进来。在满足这些条件并不断重复它们直到我们接近最优(收敛)之后，我们期望一些表消失，而另一些表增长。希望学生们最终能得到一个最佳的桌子配置。简单来说，这就是GSDMM算法的作用！</p><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div class="gh gi pu"><img src="../Images/e57427066f4bcb4897ab95cbb4c2205f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1242/format:webp/1*9JNpYwGsmWIBHDm_yP6DZg.jpeg"/></div><figcaption class="na nb gj gh gi nc nd bd b be z dk translated">电影群组过程类比的视觉效果(图片由作者提供)</figcaption></figure><h2 id="bff1" class="nm me it bd mf nn no dn mj np nq dp mn li nr ns mp lm nt nu mr lq nv nw mt iz bi translated">STTM实施</h2><p id="d6b8" class="pw-post-body-paragraph kz la it lb b lc mv kd le lf mw kg lh li mx lk ll lm my lo lp lq mz ls lt lu im bi translated">现在，我们将开始建立我们的STTM管道，并在我们的健康新闻推特数据集上运行。如果使用你自己的数据集，这部分假设你已经预处理和标记了你的推文。否则可以参考<a class="ae nl" href="https://medium.com/towards-artificial-intelligence/tweet-topic-modeling-part-2-cleaning-and-preprocessing-tweets-e3a08a8b1770" rel="noopener">第二部分</a>。</p><p id="6c09" class="pw-post-body-paragraph kz la it lb b lc ld kd le lf lg kg lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">我们要做的第一件事是将GSDMM模型从<a class="ae nl" href="https://github.com/rwalk/gsdmm" rel="noopener ugc nofollow" target="_blank"> GitHub </a>加载到一个名为<code class="fe pr ps pt ny b">gsdmm</code>的文件夹中。在终端中运行以下命令。</p><pre class="ks kt ku kv gt nx ny nz oa aw ob bi"><span id="212f" class="nm me it ny b gy oc od l oe of">git clone <a class="ae nl" href="https://github.com/rwalk/gsdmm.git" rel="noopener ugc nofollow" target="_blank">https://github.com/rwalk/gsdmm.git</a> gsdmm</span></pre><p id="22ab" class="pw-post-body-paragraph kz la it lb b lc ld kd le lf lg kg lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">接下来，我们将导入模型。使用我们之前在EDA中加载的数据帧，我们将把我们的令牌转换成一个列表，然后创建一个最终的列表列表来保存我们所有tweets中的所有令牌。这是必要的，因为这是模型的正确输入格式。</p><pre class="ks kt ku kv gt nx ny nz oa aw ob bi"><span id="a7fb" class="nm me it ny b gy oc od l oe of">import numpy as np<br/>import pandas as pd<br/>import pickle<br/>import gsdmm<br/>from gsdmm import MovieGroupProcess<br/>from tqdm import tqdm</span><span id="7d04" class="nm me it ny b gy og od l oe of"># convert string of tokens into tokens list<br/>tweets_df['tokens'] = tweets_df.tokens.apply(lambda x:  <br/>                                             re.split('\s', x))</span><span id="9b9c" class="nm me it ny b gy og od l oe of"># create list of  token lists<br/>docs = tweets_df['tokens'].tolist()</span></pre><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div class="gh gi pv"><img src="../Images/253aa81aab71ab2f3e1058461b9bc626.png" data-original-src="https://miro.medium.com/v2/resize:fit:326/format:webp/1*5MbnHmYVxi3RvUkQwsJ2jw.jpeg"/></div><figcaption class="na nb gj gh gi nc nd bd b be z dk translated"><strong class="bd mf">文档</strong>的输出样本gsdmm模型所需的输入</figcaption></figure><p id="81be" class="pw-post-body-paragraph kz la it lb b lc ld kd le lf lg kg lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">在运行模型之前，我们需要了解并选择GSDMM的超参数:</p><ul class=""><li id="6718" class="pd pe it lb b lc ld lf lg li pf lm pg lq ph lu pi pj pk pl bi translated"><strong class="lb jd"> K </strong> —代表模型将找到的最大主题数。回想一下，GSDMM将清空无用的集群，并最终尝试找到主题的“真实”数量。这在理论上可行，但高度依赖于您的数据集和使用的其他超参数。例如，如果您将K设置为300来运行它，您可能会发现自己得到300个主题，这些主题对于您的数据可能是真实的，也可能是无用的。在我们的例子中，考虑到每条推文都很短，而且事实上所有推文都已经在健康主题领域下，我选择了<code class="fe pr ps pt ny b">K=10</code>，因为我们正在寻找健康方面的子主题。为了进一步阅读，有几种不同的方法来选择一个理想的K，我在最后的参考文献中包括了这些方法。</li><li id="bf0f" class="pd pe it lb b lc pm lf pn li po lm pp lq pq lu pi pj pk pl bi translated"><strong class="lb jd"> Alpha α </strong> —关于MGP，Alpha控制一个因素，该因素决定当一个表是空的时，它被移除的容易程度(低alpha =更少的表)。结果，随着alpha的增加，非空聚类的数量将变得更大，并且将会有更多的只有一个或几个文档的聚类。默认情况下，值<code class="fe pr ps pt ny b">α=0.1</code>在大多数数据集上工作良好。</li><li id="214d" class="pd pe it lb b lc pm lf pn li po lm pp lq pq lu pi pj pk pl bi translated"><strong class="lb jd"> Beta β </strong> —关于MGP，Beta控制如何根据表的相似性而不是表的流行度为学生选择表(低beta =更多相似的聚类)。结果，随着beta的增加，非空聚类的数量将变得更小，因为该模型将更加强调选择流行的聚类而不是相似的聚类。默认情况下，<code class="fe pr ps pt ny b">β=0.1</code>值适用于大多数数据集。</li><li id="efad" class="pd pe it lb b lc pm lf pn li po lm pp lq pq lu pi pj pk pl bi translated"><strong class="lb jd"> N_iters </strong> —对于MGP，这表示迭代的次数或每个学生被教授重新分配到新表的次数。根据<a class="ae nl" href="https://dl.acm.org/doi/10.1145/2623330.2623715" rel="noopener ugc nofollow" target="_blank">原始研究论文</a>，虽然我们将使用<code class="fe pr ps pt ny b">n_iters=30</code>作为默认值，但GSDMM收敛速度相当快，并且稳定性通常在10以内。</li></ul><p id="75ca" class="pw-post-body-paragraph kz la it lb b lc ld kd le lf lg kg lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">配置好超参数后，我们就可以训练模型了！✊</p><pre class="ks kt ku kv gt nx ny nz oa aw ob bi"><span id="bd84" class="nm me it ny b gy oc od l oe of"># train STMM model<br/>mgp = MovieGroupProcess(K=10, alpha=0.1, beta=0.1, n_iters=30)<br/>vocab = set(x for doc in docs for x in doc)<br/>n_terms = len(vocab)<br/>y = mgp.fit(docs, n_terms)</span><span id="90c5" class="nm me it ny b gy og od l oe of"># save model<br/>with open(‘dumps/trained_models/10clusters.model’, ‘wb’) as f:<br/> pickle.dump(mgp, f)<br/> f.close()</span></pre><p id="1bca" class="pw-post-body-paragraph kz la it lb b lc ld kd le lf lg kg lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">一旦模型训练完成(<em class="lv">注意:训练需要一些时间，这取决于你的数据集和迭代</em>)，我们将想要探索发现的主题并对它们进行评估。首先，让我们定义一些帮助器函数来简化这个过程。</p><figure class="ks kt ku kv gt kw"><div class="bz fp l di"><div class="pw px l"/></div></figure><p id="2d49" class="pw-post-body-paragraph kz la it lb b lc ld kd le lf lg kg lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">下面的代码将为我们提供对每个集群中的tweets数量及其热门词分布的统计洞察。</p><pre class="ks kt ku kv gt nx ny nz oa aw ob bi"><span id="6586" class="nm me it ny b gy oc od l oe of">doc_count = np.array(mgp.cluster_doc_count)<br/>print(‘Number of documents per topic :’, doc_count)<br/>print(‘*’*20)</span><span id="8108" class="nm me it ny b gy og od l oe of"># topics sorted by the number of documents they are allocated to<br/>top_index = doc_count.argsort()[-10:][::-1]<br/>print(‘Most important clusters (by number of docs inside):’,   <br/>       top_index)<br/>print(‘*’*20)</span><span id="f77e" class="nm me it ny b gy og od l oe of"># show the top 5 words in term frequency for each cluster <br/>topic_indices = np.arange(start=0, stop=len(doc_count), step=1)<br/>top_words(mgp.cluster_word_distribution, topic_indices, 5)</span></pre><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="oi oj di ok bf ol"><div class="gh gi py"><img src="../Images/10a9c63150aa5d8380267dc2a3d9ae42.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*iK99QeEhRv0XOT2V2kvtcA.jpeg"/></div></div></figure><p id="13b6" class="pw-post-body-paragraph kz la it lb b lc ld kd le lf lg kg lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">结果乍一看还蛮不错的！以下是我们可以从一些主题中推断出的一些一般模式:</p><ul class=""><li id="863a" class="pd pe it lb b lc ld lf lg li pf lm pg lq ph lu pi pj pk pl bi translated">第0类似乎涉及医疗保健及其背后的政治</li><li id="9569" class="pd pe it lb b lc pm lf pn li po lm pp lq pq lu pi pj pk pl bi translated"><strong class="lb jd">集群1 </strong>似乎只关注病毒和疫情</li><li id="8359" class="pd pe it lb b lc pm lf pn li po lm pp lq pq lu pi pj pk pl bi translated"><strong class="lb jd">聚类5 </strong>似乎与健康的生活方式和节食有关</li><li id="253e" class="pd pe it lb b lc pm lf pn li po lm pp lq pq lu pi pj pk pl bi translated">集群7似乎涉及正在进行的堕胎权利讨论</li><li id="35b0" class="pd pe it lb b lc pm lf pn li po lm pp lq pq lu pi pj pk pl bi translated"><strong class="lb jd">第8类</strong>似乎侧重于香烟和蒸汽对健康的影响</li></ul><p id="9e7e" class="pw-post-body-paragraph kz la it lb b lc ld kd le lf lg kg lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">如果我们想深入了解某些单词对特定的集群有多重要，我们可以使用前面定义的<code class="fe pr ps pt ny b">cluster_importance</code>函数来创建一个主题-单词矩阵，其中每个值代表该特定主题的单词重要性。</p><pre class="ks kt ku kv gt nx ny nz oa aw ob bi"><span id="583e" class="nm me it ny b gy oc od l oe of">phi = cluster_importance(mgp) # initialize phi matrix<br/>phi[1][‘coronavirus’]</span></pre><p id="dc45" class="pw-post-body-paragraph kz la it lb b lc ld kd le lf lg kg lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">输出值:0.000000000001</p><pre class="ks kt ku kv gt nx ny nz oa aw ob bi"><span id="1802" class="nm me it ny b gy oc od l oe of">phi[0][‘coronavirus’]</span></pre><p id="89c0" class="pw-post-body-paragraph kz la it lb b lc ld kd le lf lg kg lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><strong class="lb jd">输出:</strong>0.000000000001</p><p id="99e1" class="pw-post-body-paragraph kz la it lb b lc ld kd le lf lg kg lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">在这里，我们可以看到“冠状病毒”一词对于聚类1(似乎与病毒有关)的值为0.016，但是对于聚类0(似乎与医疗保健和政治有关)的值相对很小。</p><p id="9e15" class="pw-post-body-paragraph kz la it lb b lc ld kd le lf lg kg lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">一旦我们完成了探索，对聚类结果感到满意，下一步就是给每个聚类分配实际的人类可解释的主题。记住，主题建模会产生“潜在的”主题。在流程的最后，我们仍然需要一个人来解释集群，并定义每个集群的内容。这样做是一门艺术🎨不过。</p><p id="ca56" class="pw-post-body-paragraph kz la it lb b lc ld kd le lf lg kg lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">让我们为我们的10个集群而努力吧！</p><pre class="ks kt ku kv gt nx ny nz oa aw ob bi"><span id="36af" class="nm me it ny b gy oc od l oe of">topic_dict = {}<br/>topic_names = [‘healthcare &amp; policy’,<br/>               ‘virus/outbreaks’,<br/>               ‘cancer studies affecting woman/babies’,<br/>               ‘miscellaneous studies affecting women/children’,<br/>               ‘cancer &amp; heart disease’,<br/>               ‘diet &amp; exercise’,<br/>               ‘health &amp; medical workers’,<br/>               ‘abortion’,<br/>               ‘vaping &amp; cigarettes’,<br/>               ‘drug costs &amp; opioid crisis’]</span><span id="ccff" class="nm me it ny b gy og od l oe of">for i, topic_num in enumerate(topic_indices):<br/> topic_dict[topic_num]=topic_names[i]</span></pre><p id="8c52" class="pw-post-body-paragraph kz la it lb b lc ld kd le lf lg kg lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">定义好主题后，我们现在可以使用我们的<code class="fe pr ps pt ny b">topic_allocation</code>函数为每条tweet分配一个主题。</p><pre class="ks kt ku kv gt nx ny nz oa aw ob bi"><span id="3526" class="nm me it ny b gy oc od l oe of">topic_allocation(tweets_df, docs, mgp, topic_dict)</span></pre><p id="46ce" class="pw-post-body-paragraph kz la it lb b lc ld kd le lf lg kg lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><em class="lv">注意:该自定义主题分配功能是在</em> <code class="fe pr ps pt ny b"><em class="lv">gsdmm</em></code> <em class="lv">模块中原有的</em> <code class="fe pr ps pt ny b"><em class="lv">choose_best_label</em></code> <em class="lv">功能的基础上构建的，该功能选择最有可能属于某个文档的主题。如果你希望在分配主题时使用一个最小阈值，以便为任何不符合设置阈值的推文分配一个“其他”主题，你可以向帮助器函数添加一些代码，以接受一个额外的阈值输入参数。在分配主题之前，您需要调整代码来检查这种情况。</em></p><p id="3196" class="pw-post-body-paragraph kz la it lb b lc ld kd le lf lg kg lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">让我们来看看我们的推文及其指定主题的样本。</p><pre class="ks kt ku kv gt nx ny nz oa aw ob bi"><span id="8383" class="nm me it ny b gy oc od l oe of">tweets_df[[‘tweet’, ‘username’, ‘tokens’, ‘cluster’,   <br/>           ‘topic_name’]].sample(5)</span></pre><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="oi oj di ok bf ol"><div class="gh gi pz"><img src="../Images/44d1fe9f116b3ac02d440f209e562274.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*-dYzoiBS6EywrU_htnnt3Q.jpeg"/></div></div></figure><p id="41de" class="pw-post-body-paragraph kz la it lb b lc ld kd le lf lg kg lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">我们做到了！这些完美吗？没有——但是我们数据集中的每条推文现在都标有我们定义的潜在主题，以及我们的GSDMM模型产生的潜在主题。💪 🚀 🎆</p><p id="c4aa" class="pw-post-body-paragraph kz la it lb b lc ld kd le lf lg kg lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><a class="ae nl" href="https://github.com/bicachu/short-text-topic-modeling-tutorial/blob/main/sttm_notebook.ipynb" rel="noopener ugc nofollow" target="_blank"> <strong class="lb jd">完整笔记本</strong> </a></p></div><div class="ab cl lw lx hx ly" role="separator"><span class="lz bw bk ma mb mc"/><span class="lz bw bk ma mb mc"/><span class="lz bw bk ma mb"/></div><div class="im in io ip iq"><p id="a19f" class="pw-post-body-paragraph kz la it lb b lc ld kd le lf lg kg lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">在我们结束之前，让我们确保将数据框保存到一个csv文件中。你也可以在这里找到它的副本<a class="ae nl" href="https://github.com/bicachu/short-text-topic-modeling-tutorial/blob/main/data/sttm_10topics_results.csv" rel="noopener ugc nofollow" target="_blank">。</a></p><pre class="ks kt ku kv gt nx ny nz oa aw ob bi"><span id="7277" class="nm me it ny b gy oc od l oe of">tweets_df.to_csv(r’data/sttm_10topics_results.csv’, index = False,  <br/>                 header=True)</span></pre><p id="95ae" class="pw-post-body-paragraph kz la it lb b lc ld kd le lf lg kg lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">在本系列的下一个也是最后一个部分中，我们将开始使用热图和气泡图来更好地可视化和分析我们的主题建模结果！</p><h2 id="b814" class="nm me it bd mf nn no dn mj np nq dp mn li nr ns mp lm nt nu mr lq nv nw mt iz bi translated">额外收获:提取和存储每个主题模型的单词统计</h2><p id="092d" class="pw-post-body-paragraph kz la it lb b lc mv kd le lf mw kg lh li mx lk ll lm my lo lp lq mz ls lt lu im bi translated">如果你想看看我们如何提取每个主题的热门词、文档数、词频和词的重要性，请参考我笔记本的最后一部分<a class="ae nl" href="https://github.com/bicachu/short-text-topic-modeling-tutorial/blob/main/sttm_notebook.ipynb" rel="noopener ugc nofollow" target="_blank">这里</a>。使用许多辅助函数的代码要复杂得多，并且还需要具备Python的中级知识，尤其是使用各种数据结构。尽管如此，它还是很有价值的，可以帮助我们创建第4部分中绘制气泡图所需的数据。</p><p id="d528" class="pw-post-body-paragraph kz la it lb b lc ld kd le lf lg kg lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><em class="lv">我要感谢</em><a class="qa qb ep" href="https://medium.com/u/ad07e8173fb2?source=post_page-----bc969a827fef--------------------------------" rel="noopener" target="_blank"><em class="lv">maty as Amrouche</em></a><em class="lv">启发了这个项目，并提供了我能够利用的关于GSDMM的类似教程——查看下面参考资料中他的有用教程！</em></p><div class="qc qd gp gr qe qf"><a rel="noopener  ugc nofollow" target="_blank" href="/tweet-topic-modeling-part-4-visualizing-topic-modeling-results-with-plotly-66d5dbaaf7fb"><div class="qg ab fo"><div class="qh ab qi cl cj qj"><h2 class="bd jd gy z fp qk fr fs ql fu fw jc bi translated">Tweet主题建模第4部分:用Plotly可视化主题建模结果</h2><div class="qm l"><h3 class="bd b gy z fp qk fr fs ql fu fw dk translated">这是一个多部分的系列，展示了如何为任何集合抓取、预处理、应用和可视化短文本主题建模…</h3></div><div class="qn l"><p class="bd b dl z fp qk fr fs ql fu fw dk translated">pub.towardsai.net</p></div></div><div class="qo l"><div class="qp l qq qr qs qo qt kx qf"/></div></div></a></div></div><div class="ab cl lw lx hx ly" role="separator"><span class="lz bw bk ma mb mc"/><span class="lz bw bk ma mb mc"/><span class="lz bw bk ma mb"/></div><div class="im in io ip iq"><p id="a924" class="pw-post-body-paragraph kz la it lb b lc ld kd le lf lg kg lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><strong class="lb jd">参考资料和其他有用资源</strong></p><ul class=""><li id="6b8c" class="pd pe it lb b lc ld lf lg li pf lm pg lq ph lu pi pj pk pl bi translated">总体STTM <a class="ae nl" href="https://arxiv.org/pdf/1904.07695.pdf" rel="noopener ugc nofollow" target="_blank">研究论文</a></li><li id="47b7" class="pd pe it lb b lc pm lf pn li po lm pp lq pq lu pi pj pk pl bi translated"><a class="ae nl" href="https://dl.acm.org/doi/10.1145/2623330.2623715" rel="noopener ugc nofollow" target="_blank">GSD mm的原始研究论文</a></li><li id="17a2" class="pd pe it lb b lc pm lf pn li po lm pp lq pq lu pi pj pk pl bi translated"><a class="ae nl" href="https://github.com/bicachu/short-text-topic-modeling-tutorial/blob/main/sttm_notebook.ipynb" rel="noopener ugc nofollow" target="_blank"> STTM笔记本</a>本文供图</li><li id="53c5" class="pd pe it lb b lc pm lf pn li po lm pp lq pq lu pi pj pk pl bi translated">Matyas Amrouche的<a class="ae nl" href="https://towardsdatascience.com/short-text-topic-modeling-70e50a57c883" rel="noopener" target="_blank"> STTM文章</a></li><li id="3c3a" class="pd pe it lb b lc pm lf pn li po lm pp lq pq lu pi pj pk pl bi translated">gsdmm <a class="ae nl" href="https://github.com/rwalk/gsdmm" rel="noopener ugc nofollow" target="_blank"> Github页面</a></li><li id="31be" class="pd pe it lb b lc pm lf pn li po lm pp lq pq lu pi pj pk pl bi translated">使用话题连贯性选择K<a class="ae nl" href="https://www.machinelearningplus.com/nlp/topic-modeling-gensim-python/#14computemodelperplexityandcoherencescore" rel="noopener ugc nofollow" target="_blank">指南</a></li></ul></div></div>    
</body>
</html>