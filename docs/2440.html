<html>
<head>
<title>Mismatch-first Farthest-search in Active Learning</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">主动学习中的不匹配优先最远搜索</h1>
<blockquote>原文：<a href="https://pub.towardsai.net/mismatch-first-farthest-search-in-active-learning-300233d7a4e3?source=collection_archive---------1-----------------------#2021-12-23">https://pub.towardsai.net/mismatch-first-farthest-search-in-active-learning-300233d7a4e3?source=collection_archive---------1-----------------------#2021-12-23</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><h2 id="a003" class="io ip iq bd b dl ir is it iu iv iw dk ix translated" aria-label="kicker paragraph"><a class="ae ep" href="https://towardsai.net/p/category/machine-learning" rel="noopener ugc nofollow" target="_blank">机器学习</a></h2><div class=""/><div class=""><h2 id="1e5b" class="pw-subtitle-paragraph jw iz iq bd b jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn dk translated">不匹配第一最远遍历方法</h2></div><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div role="button" tabindex="0" class="ku kv di kw bf kx"><div class="gh gi ko"><img src="../Images/bea2bda510afc224a57921768ec0bfa1.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*Uul2cySEiksyrHJW"/></div></div><figcaption class="la lb gj gh gi lc ld bd b be z dk translated">由<a class="ae le" href="https://unsplash.com/@mrrrk_smith?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">约翰-马克·史密斯</a>在<a class="ae le" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上拍摄</figcaption></figure><p id="fc08" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated"><strong class="lh ja">主动学习</strong>是一种让学习者(如学生)主动参与学习过程的教学策略。与传统的学习过程相比，学习者不仅仅是坐着听，而是与教师一起互动。学习进度可以根据学习者的反馈进行调整。所以，主动学习的周期很重要。如果你不熟悉主动学习，你可以访问这个<a class="ae le" rel="noopener ugc nofollow" target="_blank" href="/active-learning-builds-a-valuable-dataset-from-scratch-cb4f66ff902c">帖子</a>。</p><h1 id="422f" class="mb mc iq bd md me mf mg mh mi mj mk ml kf mm kg mn ki mo kj mp kl mq km mr ms bi translated">整体架构</h1><p id="54af" class="pw-post-body-paragraph lf lg iq lh b li mt ka lk ll mu kd ln lo mv lq lr ls mw lu lv lw mx ly lz ma ij bi translated">除了<a class="ae le" href="http://Active Learning and Semi-supervised Learning" rel="noopener ugc nofollow" target="_blank">主动学习中的半监督学习</a>之外，我们将通过另一种方法来实现主动学习中的无监督学习和监督学习。Shuyang等人(2018)提出使用k -medoids(类似于k-mean，但聚类中心必须是数据点之一)来识别聚类中心，然后估计来自同一聚类的最不可能的数据点以进行标注。</p><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div class="gh gi my"><img src="../Images/5b839b7c27248b413b207adb94b57c05.png" data-original-src="https://miro.medium.com/v2/resize:fit:992/format:webp/1*TbEkM1gOrlvqlxLaYS4e5g.png"/></div><figcaption class="la lb gj gh gi lc ld bd b be z dk translated">整体标签流程(Shuyang等人，2018年)</figcaption></figure><h1 id="f840" class="mb mc iq bd md me mf mg mh mi mj mk ml kf mm kg mn ki mo kj mp kl mq km mr ms bi translated">使聚集</h1><p id="952e" class="pw-post-body-paragraph lf lg iq lh b li mt ka lk ll mu kd ln lo mv lq lr ls mw lu lv lw mx ly lz ma ij bi translated">采用K-medoids方法识别聚类质心。与classic K-medoids实现不同，它基于<a class="ae le" href="https://www.cs.utexas.edu/~ml/papers/semi-sdm-04.pdf" rel="noopener ugc nofollow" target="_blank">最远优先遍历</a>。确定质心后，主题专家(SME)将处理注释。通常，我们会从一个小的集群开始，比如4。Shuyang等人(2018)通过中值邻域测试方法估计了聚类数。简言之，</p><h1 id="9bb6" class="mb mc iq bd md me mf mg mh mi mj mk ml kf mm kg mn ki mo kj mp kl mq km mr ms bi translated">首先是不匹配</h1><p id="eee2" class="pw-post-body-paragraph lf lg iq lh b li mt ka lk ll mu kd ln lo mv lq lr ls mw lu lv lw mx ly lz ma ij bi translated">在SMEs注释了一些数据点之后，它可以用于训练分类模型并预测剩余的未注释的数据点。最近邻分类器和基于模型(例如逻辑回归)的分类器被训练用于预测。如果预测的标注没有对齐，它们将被选为另一轮注记的候选标注。</p><h1 id="ff51" class="mb mc iq bd md me mf mg mh mi mj mk ml kf mm kg mn ki mo kj mp kl mq km mr ms bi translated">最远搜索</h1><p id="550f" class="pw-post-body-paragraph lf lg iq lh b li mt ka lk ll mu kd ln lo mv lq lr ls mw lu lv lw mx ly lz ma ij bi translated">有了一组不匹配的数据点，Shuyang等人(2018)提出选择那些远离聚类质心的数据点。假设传播最大距离的标签很可能不属于特定类别。</p><h1 id="70b4" class="mb mc iq bd md me mf mg mh mi mj mk ml kf mm kg mn ki mo kj mp kl mq km mr ms bi translated">NLPatl编写的Python代码</h1><p id="2ad0" class="pw-post-body-paragraph lf lg iq lh b li mt ka lk ll mu kd ln lo mv lq lr ls mw lu lv lw mx ly lz ma ij bi translated">与主动学习一样，NLPatl 提供不匹配优先最远学习。它不是完全相同的实现，但遵循相似的架构和更大的灵活性。</p><p id="8dd5" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">你只需要让你的数据适合它，你就可以注释最有价值的数据点和自学的数据点。让我们准备好弄脏你的手。我将用几行代码演示如何在NLP中应用主动学习。你可以访问这个<a class="ae le" href="https://colab.research.google.com/drive/1dr1GY_vO_oOMixj4clzcMR7jLsNpbbvg#scrollTo=YCK94D1X7KBm" rel="noopener ugc nofollow" target="_blank">笔记本</a>获取完整版本的代码。</p><pre class="kp kq kr ks gt mz na nb nc aw nd bi"><span id="4e7b" class="ne mc iq na b gy nf ng l nh ni">learning = MismatchFarthestLearning(<br/>  clustering_sampling='nearest_mean',<br/>  embeddings='bert-base-uncased', embeddings_type='transformers',<br/>  embeddings_model_config={'nn_fwk': 'pt', 'padding': True,<br/>    'batch_size':8},<br/>  clustering='kmeans', clustering_model_config={'n_clusters': 3},<br/>  classification='logistic_regression')</span><span id="a78f" class="ne mc iq na b gy nj ng l nh ni">learning.explore_educate_in_notebook(train_texts)</span></pre><h1 id="07b3" class="mb mc iq bd md me mf mg mh mi mj mk ml kf mm kg mn ki mo kj mp kl mq km mr ms bi translated">参考</h1><ul class=""><li id="1540" class="nk nl iq lh b li mt ll mu lo nm ls nn lw no ma np nq nr ns bi translated">z舒扬，T海特托拉，T维尔塔宁。<a class="ae le" href="http://zhaoshuyang.com/static/documents/MAL2.pdf" rel="noopener ugc nofollow" target="_blank">一种使用聚类和基于委员会的样本选择进行声音事件分类的主动学习方法</a>。2018</li><li id="5e77" class="nk nl iq lh b li nt ll nu lo nv ls nw lw nx ma np nq nr ns bi translated"><a class="ae le" rel="noopener ugc nofollow" target="_blank" href="/active-learning-and-semi-supervised-learning-turn-your-unlabeled-data-into-annotated-data-6e5c0f58c9f3">主动学习简介</a></li><li id="706f" class="nk nl iq lh b li nt ll nu lo nv ls nw lw nx ma np nq nr ns bi translated"><a class="ae le" href="http://Active Learning and Semi-supervised Learning" rel="noopener ugc nofollow" target="_blank">在主动学习中使用半监督学习</a></li></ul><h1 id="a8bb" class="mb mc iq bd md me mf mg mh mi mj mk ml kf mm kg mn ki mo kj mp kl mq km mr ms bi translated">喜欢学习？</h1><p id="663b" class="pw-post-body-paragraph lf lg iq lh b li mt ka lk ll mu kd ln lo mv lq lr ls mw lu lv lw mx ly lz ma ij bi translated">我是湾区的数据科学家。专注于数据科学、人工智能，尤其是NLP和平台相关领域的最新发展。在<a class="ae le" href="https://www.linkedin.com/in/edwardma1026" rel="noopener ugc nofollow" target="_blank"> LinkedIn </a>或<a class="ae le" href="https://github.com/makcedward" rel="noopener ugc nofollow" target="_blank"> Github </a>上随意联系<a class="ae le" href="https://makcedward.github.io/" rel="noopener ugc nofollow" target="_blank"> me </a>。</p></div></div>    
</body>
</html>