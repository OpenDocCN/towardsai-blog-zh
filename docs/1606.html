<html>
<head>
<title>Predicting and Visualizing streaming Data through Python</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">通过Python预测和可视化流数据</h1>
<blockquote>原文：<a href="https://pub.towardsai.net/predicting-and-visualizing-streaming-data-through-python-2670003bc809?source=collection_archive---------3-----------------------#2021-03-03">https://pub.towardsai.net/predicting-and-visualizing-streaming-data-through-python-2670003bc809?source=collection_archive---------3-----------------------#2021-03-03</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><h2 id="3888" class="ir is it bd b dl iu iv iw ix iy iz dk ja translated" aria-label="kicker paragraph"><a class="ae ep" href="https://towardsai.net/p/category/programming" rel="noopener ugc nofollow" target="_blank">编程</a></h2><div class=""/><div class=""><h2 id="c8b6" class="pw-subtitle-paragraph jz jc it bd b ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq dk translated">预测行人流量并在地图上可视化</h2></div><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div class="gh gi kr"><img src="../Images/25da96b4cb17832c737b160d44e4e1a3.png" data-original-src="https://miro.medium.com/v2/resize:fit:1280/format:webp/1*7S2EF-j5k3hU-WTlRJZ7wQ.jpeg"/></div><figcaption class="kz la gj gh gi lb lc bd b be z dk translated">由<a class="ae ld" href="https://unsplash.com/@tommaso_27?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText" rel="noopener ugc nofollow" target="_blank">托马索·斯卡拉</a>在<a class="ae ld" href="https://unsplash.com/s/photos/pedestrian-street?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上拍摄的照片</figcaption></figure><p id="a37f" class="pw-post-body-paragraph le lf it lg b lh li kd lj lk ll kg lm ln lo lp lq lr ls lt lu lv lw lx ly lz im bi translated"><strong class="lg jd"> <em class="ma">目标简介</em> </strong></p><p id="eebf" class="pw-post-body-paragraph le lf it lg b lh li kd lj lk ll kg lm ln lo lp lq lr ls lt lu lv lw lx ly lz im bi translated">在批处理/静态数据上训练模型的技能非常重要，但在流数据上应用该模型的能力也非常重要。在当今快速发展的世界中，人们/组织希望他们的查询得到实时响应/预测，因为每个人都在自己的世界中非常忙碌，坦率地说，我们都同意有很多事情要做。因此，这篇文章是献给那些试图掌握实时预测技能的人的。这篇文章是我的<a class="ae ld" href="https://akashgoyal2110.medium.com/time-series-prediction-using-spark-8ee7fbe878e6" rel="noopener">上一篇</a>文章的延续，在那篇文章中，我们使用Apache Spark训练模型。</p><p id="4080" class="pw-post-body-paragraph le lf it lg b lh li kd lj lk ll kg lm ln lo lp lq lr ls lt lu lv lw lx ly lz im bi translated">正如第一段所述，到目前为止，您应该已经对我们在本文中讨论的内容有所了解，是的，您是对的，我们将实时部署之前创建的模型，然后看看我们如何在地图上可视化传感器部署在特定“位置”的结果。为了方便起见，我将再次分享这篇文章中的数据结构。这样你就不用再去看最后一个帖子了。</p><p id="8bd4" class="pw-post-body-paragraph le lf it lg b lh li kd lj lk ll kg lm ln lo lp lq lr ls lt lu lv lw lx ly lz im bi translated">遵循正确的方法总是好的，所以我们会像上次一样，解决一些关于要解决的问题的基本问题。</p><p id="477d" class="pw-post-body-paragraph le lf it lg b lh li kd lj lk ll kg lm ln lo lp lq lr ls lt lu lv lw lx ly lz im bi translated"><strong class="lg jd">哪些工具将用于处理实时流？</strong></p><p id="aa84" class="pw-post-body-paragraph le lf it lg b lh li kd lj lk ll kg lm ln lo lp lq lr ls lt lu lv lw lx ly lz im bi translated">根据这篇博客，使用的工具将是用于实时数据模拟的<a class="ae ld" href="https://kafka.apache.org/" rel="noopener ugc nofollow" target="_blank"> Apache Kafka </a>和<a class="ae ld" href="https://spark.apache.org/" rel="noopener ugc nofollow" target="_blank"> Apache Spark </a>。使用的编程语言是Python。</p><p id="c644" class="pw-post-body-paragraph le lf it lg b lh li kd lj lk ll kg lm ln lo lp lq lr ls lt lu lv lw lx ly lz im bi translated">这篇博客会使用什么类型的数据？</p><p id="3cc0" class="pw-post-body-paragraph le lf it lg b lh li kd lj lk ll kg lm ln lo lp lq lr ls lt lu lv lw lx ly lz im bi translated">这个博客中会用到两个数据集</p><ul class=""><li id="935e" class="mb mc it lg b lh li lk ll ln md lr me lv mf lz mg mh mi mj bi translated">行人计数数据</li></ul><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="ml mm di mn bf mo"><div class="gh gi mk"><img src="../Images/e26e1dcf7cc3eb36fca2675fd7620e14.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*7RPNmZ7vjPg-JnTk50M6NA.png"/></div></div></figure><ul class=""><li id="dabe" class="mb mc it lg b lh li lk ll ln md lr me lv mf lz mg mh mi mj bi translated">传感器信息数据</li></ul><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="ml mm di mn bf mo"><div class="gh gi mp"><img src="../Images/0e063ea31e4b2bbee63ff6c8fef33922.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*UdPKtQ8TgfT_bR9qI3qo1g.png"/></div></div></figure><p id="7dd1" class="pw-post-body-paragraph le lf it lg b lh li kd lj lk ll kg lm ln lo lp lq lr ls lt lu lv lw lx ly lz im bi translated">使用Apache Kafka，我们可以模拟一个实时流系统。其中新数据(位于逗号分隔的文件中)将实时流式传输，并且将首先根据需要对其进行处理，然后进行预测过程。在预测之后，我们将实时可视化数据，因为利益相关者不想打破他们的头脑去看预测，但是他们想看到能立即给他们答案的东西。</p><blockquote class="mq mr ms"><p id="f241" class="le lf ma lg b lh li kd lj lk ll kg lm mt lo lp lq mu ls lt lu mv lw lx ly lz im bi translated"><strong class="lg jd">不幸的是，由于版权问题，实际使用的数据无法上传，但同时我会分享数据的结构，所以任何类似结构的数据或可以转换成类似结构的数据都可以使用。</strong></p></blockquote><p id="3dfb" class="pw-post-body-paragraph le lf it lg b lh li kd lj lk ll kg lm ln lo lp lq lr ls lt lu lv lw lx ly lz im bi translated">现在让我们快速解决手头的问题。</p><h1 id="b77a" class="mw mx it bd my mz na nb nc nd ne nf ng ki nh kj ni kl nj km nk ko nl kp nm nn bi translated">用于实现目标的流程</h1><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="ml mm di mn bf mo"><div class="gh gi no"><img src="../Images/b2e18a70cd0bfd8120134c98b04e3d7b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*YwHVEpwoV2W8FTVAibKdVQ.png"/></div></div></figure><h1 id="c668" class="mw mx it bd my mz na nb nc nd ne nf ng ki nh kj ni kl nj km nk ko nl kp nm nn bi translated">步伐</h1><ol class=""><li id="4f89" class="mb mc it lg b lh np lk nq ln nr lr ns lv nt lz nu mh mi mj bi translated">设置Kafka生成器并发送数据</li><li id="48b3" class="mb mc it lg b lh nv lk nw ln nx lr ny lv nz lz nu mh mi mj bi translated">从流中读取数据</li><li id="10eb" class="mb mc it lg b lh nv lk nw ln nx lr ny lv nz lz nu mh mi mj bi translated">保留原始数据</li><li id="7cc4" class="mb mc it lg b lh nv lk nw ln nx lr ny lv nz lz nu mh mi mj bi translated">转换流数据</li><li id="67b5" class="mb mc it lg b lh nv lk nw ln nx lr ny lv nz lz nu mh mi mj bi translated">执行预测</li><li id="7c55" class="mb mc it lg b lh nv lk nw ln nx lr ny lv nz lz nu mh mi mj bi translated">持久化预测数据</li><li id="2c8b" class="mb mc it lg b lh nv lk nw ln nx lr ny lv nz lz nu mh mi mj bi translated">设置Kafka消费者</li><li id="7435" class="mb mc it lg b lh nv lk nw ln nx lr ny lv nz lz nu mh mi mj bi translated">形象化</li></ol><h1 id="860a" class="mw mx it bd my mz na nb nc nd ne nf ng ki nh kj ni kl nj km nk ko nl kp nm nn bi translated">设置Kafka生成器并发送数据</h1><p id="7ac7" class="pw-post-body-paragraph le lf it lg b lh np kd lj lk nq kg lm ln oa lp lq lr ob lt lu lv oc lx ly lz im bi translated">在这一步中，我们将为Kafka producer创建一个对象，该对象将具有我们需要用来创建数据流的Kafka服务器的配置。这将通过使用<code class="fe od oe of og b">KafkaProducer()</code>函数来完成，该函数有<strong class="lg jd">服务器和端口地址</strong>，要使用的<strong class="lg jd"> api版本</strong>，以及另外两个参数<strong class="lg jd"> value和key_serializer </strong>，Kafka生产者可以在这里被指示如何将用户提供的键和值对象转换成字节。要通过Kafka发送数据，将数据放在一个主题上是很重要的。如果你是一个绝对的初学者，你会想到一个关于卡夫卡的数据库，你把数据放在里面。参见下面的代码。</p><figure class="ks kt ku kv gt kw"><div class="bz fp l di"><div class="oh oi l"/></div></figure><p id="d91a" class="pw-post-body-paragraph le lf it lg b lh li kd lj lk ll kg lm ln lo lp lq lr ls lt lu lv lw lx ly lz im bi translated">下一步是发布所选主题的数据。请参见下面的代码块。</p><figure class="ks kt ku kv gt kw"><div class="bz fp l di"><div class="oh oi l"/></div></figure><h1 id="aebc" class="mw mx it bd my mz na nb nc nd ne nf ng ki nh kj ni kl nj km nk ko nl kp nm nn bi translated">从流中读取数据</h1><p id="f73a" class="pw-post-body-paragraph le lf it lg b lh np kd lj lk nq kg lm ln oa lp lq lr ob lt lu lv oc lx ly lz im bi translated">这里我们将看到如何使用Spark读取数据数据流，这相当容易。但是为了使它变得简单，我们需要了解以下内容:</p><ul class=""><li id="9321" class="mb mc it lg b lh li lk ll ln md lr me lv mf lz mg mh mi mj bi translated">火花<code class="fe od oe of og b">readStream</code> API</li><li id="70c6" class="mb mc it lg b lh nv lk nw ln nx lr ny lv nz lz mg mh mi mj bi translated">要从Kafka读取数据，我们需要使用format()函数，并以<code class="fe od oe of og b">‘kafka’</code>作为参数。</li><li id="3043" class="mb mc it lg b lh nv lk nw ln nx lr ny lv nz lz mg mh mi mj bi translated"><code class="fe od oe of og b">option(“kafka.bootstrap.servers”, “localhost:9092”)</code> —设置要使用的服务器。<code class="fe od oe of og b">localhost</code>可以替换为您想从中读取数据的服务器的IP地址。</li><li id="8439" class="mb mc it lg b lh nv lk nw ln nx lr ny lv nz lz mg mh mi mj bi translated"><code class="fe od oe of og b">option(“subscribe”, topic)</code> —从需要读取数据的位置设置Kafka主题的选项。</li></ul><figure class="ks kt ku kv gt kw"><div class="bz fp l di"><div class="oh oi l"/></div></figure><h1 id="8e49" class="mw mx it bd my mz na nb nc nd ne nf ng ki nh kj ni kl nj km nk ko nl kp nm nn bi translated">保留原始数据</h1><p id="3e5a" class="pw-post-body-paragraph le lf it lg b lh np kd lj lk nq kg lm ln oa lp lq lr ob lt lu lv oc lx ly lz im bi translated">保持原始数据始终是一个好的做法。这可以使用Spark的<code class="fe od oe of og b">writestream</code> API来完成。</p><ul class=""><li id="8c04" class="mb mc it lg b lh li lk ll ln md lr me lv mf lz mg mh mi mj bi translated">Spark的<code class="fe od oe of og b">writeStream</code> API</li><li id="0e77" class="mb mc it lg b lh nv lk nw ln nx lr ny lv nz lz mg mh mi mj bi translated">要以parquet格式写入数据，我们需要使用带有<code class="fe od oe of og b">'parquet'</code>参数的<code class="fe od oe of og b">format()</code>函数。</li><li id="a7a8" class="mb mc it lg b lh nv lk nw ln nx lr ny lv nz lz mg mh mi mj bi translated"><code class="fe od oe of og b">outputMode('append')</code>:在此模式下，只有新的行会被添加到结果表中。</li><li id="2c8d" class="mb mc it lg b lh nv lk nw ln nx lr ny lv nz lz mg mh mi mj bi translated"><code class="fe od oe of og b">option(path)</code>:存储结果表的文件路径。</li><li id="53f1" class="mb mc it lg b lh nv lk nw ln nx lr ny lv nz lz mg mh mi mj bi translated"><code class="fe od oe of og b">option(checkpointLocation)</code>:对状态设置检查点有助于恢复上一个状态。</li><li id="f58c" class="mb mc it lg b lh nv lk nw ln nx lr ny lv nz lz mg mh mi mj bi translated"><code class="fe od oe of og b">start()</code>:开始写入数据</li></ul><h1 id="a6ef" class="mw mx it bd my mz na nb nc nd ne nf ng ki nh kj ni kl nj km nk ko nl kp nm nn bi translated">转换流数据</h1><p id="5221" class="pw-post-body-paragraph le lf it lg b lh np kd lj lk nq kg lm ln oa lp lq lr ob lt lu lv oc lx ly lz im bi translated">为了准备用于预测的数据，我们可以像在上一篇文章中那样使用lag函数，或者我在这里讨论的另一种方法是，我们可以向<code class="fe od oe of og b">Date_Time</code>列添加一天，然后从那里提取所有的组成部分，例如日期(1，2，3…30/31)等。参见下面的代码。上一篇文章中讨论的模型非常简单，我们可以添加更多的功能，比如一年中的星期，等等。</p><figure class="ks kt ku kv gt kw"><div class="bz fp l di"><div class="oh oi l"/></div></figure><h1 id="100b" class="mw mx it bd my mz na nb nc nd ne nf ng ki nh kj ni kl nj km nk ko nl kp nm nn bi translated">执行预测</h1><p id="75a4" class="pw-post-body-paragraph le lf it lg b lh np kd lj lk nq kg lm ln oa lp lq lr ob lt lu lv oc lx ly lz im bi translated">这里，我们首先需要加载我们在<a class="ae ld" href="https://akashgoyal2110.medium.com/time-series-prediction-using-spark-8ee7fbe878e6" rel="noopener">上一篇</a>文章中学习保存的管道模型。可以使用函数<code class="fe od oe of og b">load()</code>加载模型，然后我们可以预测流数据和的值。要查看模型创建和预测，请参考github页面。</p><h1 id="8949" class="mw mx it bd my mz na nb nc nd ne nf ng ki nh kj ni kl nj km nk ko nl kp nm nn bi translated">持久化预测数据</h1><p id="69da" class="pw-post-body-paragraph le lf it lg b lh np kd lj lk nq kg lm ln oa lp lq lr ob lt lu lv oc lx ly lz im bi translated">预测数据可以像我们保存原始数据一样容易地保存</p><figure class="ks kt ku kv gt kw"><div class="bz fp l di"><div class="oh oi l"/></div></figure><h1 id="bbb6" class="mw mx it bd my mz na nb nc nd ne nf ng ki nh kj ni kl nj km nk ko nl kp nm nn bi translated">设置Kafka消费者</h1><p id="8553" class="pw-post-body-paragraph le lf it lg b lh np kd lj lk nq kg lm ln oa lp lq lr ob lt lu lv oc lx ly lz im bi translated">现在，在流程的这一部分，我们将为Kafka consumer创建一个对象，该对象将具有Kafka服务器的配置，我们需要使用该配置来消费我们在Kafka主题上发布的预测数据。(这个请参考代码)。我们需要使用<code class="fe od oe of og b">KafkaConsumer()</code>函数，我们将在其中设置<strong class="lg jd">服务器和端口地址</strong>，要使用的<strong class="lg jd"> api版本</strong>，值将被序列化的部分，就像我们在<code class="fe od oe of og b">KafkaProducer()</code>函数中所做的那样，还有<strong class="lg jd"> auto_offset_reset </strong>属性。以下是这些参数的简短描述。</p><ul class=""><li id="151c" class="mb mc it lg b lh li lk ll ln md lr me lv mf lz mg mh mi mj bi translated"><strong class="lg jd"> auto_offset_reset </strong>:参数值默认为“最新”。这使得总是采用提交数据的最新位置。</li><li id="db83" class="mb mc it lg b lh nv lk nw ln nx lr ny lv nz lz mg mh mi mj bi translated"><strong class="lg jd"> api_version </strong>:指定使用哪个api版本。</li><li id="0766" class="mb mc it lg b lh nv lk nw ln nx lr ny lv nz lz mg mh mi mj bi translated"><strong class="lg jd"> consumer_timeout_ms </strong>:这是以毫秒为单位的超时时间，超过该时间后，如果消费者无法消费任何消息，就会停止消费。</li><li id="ca1d" class="mb mc it lg b lh nv lk nw ln nx lr ny lv nz lz mg mh mi mj bi translated"><strong class="lg jd"> value_deserializer </strong>:序列化值，转换成字符串数据。</li><li id="84da" class="mb mc it lg b lh nv lk nw ln nx lr ny lv nz lz mg mh mi mj bi translated"><strong class="lg jd"> bootstrap_servers </strong>:必须使用的服务器地址。</li></ul><figure class="ks kt ku kv gt kw"><div class="bz fp l di"><div class="oh oi l"/></div></figure><h1 id="3242" class="mw mx it bd my mz na nb nc nd ne nf ng ki nh kj ni kl nj km nk ko nl kp nm nn bi translated">形象化</h1><p id="f301" class="pw-post-body-paragraph le lf it lg b lh np kd lj lk nq kg lm ln oa lp lq lr ob lt lu lv oc lx ly lz im bi translated">最后但并非最不重要的是可视化，它抢了利益相关者的风头，因为他们总是想看到这一点。在这一步中，我们将使用python的<strong class="lg jd">follow</strong>库创建一个地图可视化，其中包含感兴趣区域的坐标(在我的代码中是Melbourne)，还将缩放比例设置为15个单位，以便可以正确查看数据。</p><p id="4623" class="pw-post-body-paragraph le lf it lg b lh li kd lj lk ll kg lm ln lo lp lq lr ls lt lu lv lw lx ly lz im bi translated">我们将通过消耗的消息，每次消耗20条消息，地图将刷新显示可视化。为了确保我们只关注重要的位置，使用了预测行人数量大于2000的位置。您可以根据您的使用情况选择任何数字。要查看代码，请参考github页面。</p><figure class="ks kt ku kv gt kw"><div class="bz fp l di"><div class="oj oi l"/></div></figure><p id="737b" class="pw-post-body-paragraph le lf it lg b lh li kd lj lk ll kg lm ln lo lp lq lr ls lt lu lv lw lx ly lz im bi translated"><strong class="lg jd">请看一下</strong><a class="ae ld" href="https://github.com/akashgoyal2110/pedestrian-traffic-prediction/tree/main" rel="noopener ugc nofollow" target="_blank"><strong class="lg jd">github</strong></a><strong class="lg jd">页面，关于我在python笔记本中做过的更多事情，为了简洁起见，不得不在帖子中长话短说。</strong></p><p id="6605" class="pw-post-body-paragraph le lf it lg b lh li kd lj lk ll kg lm ln lo lp lq lr ls lt lu lv lw lx ly lz im bi translated">非常感谢你花时间阅读这篇文章，如果你想讨论与这篇文章相关的任何事情，请留下评论，我会尽力帮助你。另外，请点击鼓掌按钮，分享帖子。</p></div></div>    
</body>
</html>