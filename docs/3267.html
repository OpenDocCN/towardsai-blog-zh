<html>
<head>
<title>Getting a Peak of the Big Data/Cloud Computing Workflow Using AWS</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">使用AWS获得大数据/云计算工作流的峰值</h1>
<blockquote>原文：<a href="https://pub.towardsai.net/getting-a-peak-of-the-big-data-cloud-computing-workflow-using-aws-b9360327c8df?source=collection_archive---------3-----------------------#2022-10-27">https://pub.towardsai.net/getting-a-peak-of-the-big-data-cloud-computing-workflow-using-aws-b9360327c8df?source=collection_archive---------3-----------------------#2022-10-27</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><figure class="gl gn jo jp jq jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi jn"><img src="../Images/b6a00a7d3439bb03c9645b2596e2af18.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*Bi0vNyW5wgvhreOS"/></div></div><figcaption class="jy jz gj gh gi ka kb bd b be z dk translated">泰勒·维克在<a class="ae kc" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上的照片</figcaption></figure><p id="2af9" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">虽然我现在有机会接触这些不同的技术，但我仍然对大数据和云计算技术为消费者和企业提供的便利性、便携性和计算能力感到惊讶。例如，从消费者的角度来看，他们能够从任何设备访问所有重要信息，而不必担心丢失信息或忘记设备。从技术或数据从业者的角度来看，他们能够利用原始处理能力和数据存储能力，如果技术不存在，他们可能永远无法获得这些能力。虽然人工智能、机器学习、数据科学或分析等时髦词汇最近都在大肆宣传，但对我来说，云计算和云存储的进步作为创新的<em class="lb">和</em>关键驱动力之一从未得到足够的喜爱；让我们能够以真正变革的方式工作、协作和扩展解决方案。</p><p id="147b" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">既然我们已经唱出了对云计算的赞美，现在让我们关注数据从业者在利用这些技术来利用大数据和生成可操作的见解方面的观点。在本文中，我想为那些对大数据领域感兴趣的人展示一个数据科学家在处理大数据时的工作流程，使用<strong class="kf ir">亚马逊网络服务(AWS) </strong>提供的行业标准工具。更具体地说，我将回顾:</p><ol class=""><li id="2850" class="lc ld iq kf b kg kh kk kl ko le ks lf kw lg la lh li lj lk bi translated">如何访问存储与并行处理框架，<a class="ae kc" href="https://aws.amazon.com/emr/details/hadoop/what-is-hadoop/" rel="noopener ugc nofollow" target="_blank"> <strong class="kf ir"> Hadoop文件存储系统(HDFS)</strong></a>；</li><li id="d839" class="lc ld iq kf b kg ll kk lm ko ln ks lo kw lp la lh li lj lk bi translated">如何将数据上传到亚马逊的<a class="ae kc" href="https://docs.aws.amazon.com/AmazonS3/latest/userguide/Welcome.html" rel="noopener ugc nofollow" target="_blank"> <strong class="kf ir"> S3的</strong> </a> <strong class="kf ir"> </strong>云存储系统；</li><li id="d542" class="lc ld iq kf b kg ll kk lm ko ln ks lo kw lp la lh li lj lk bi translated">如何利用<strong class="kf ir"> PySpark </strong>大规模争论和分析数据；</li><li id="7d91" class="lc ld iq kf b kg ll kk lm ko ln ks lo kw lp la lh li lj lk bi translated">如何把你的作品存回HDFS，然后搬回S3；</li><li id="464d" class="lc ld iq kf b kg ll kk lm ko ln ks lo kw lp la lh li lj lk bi translated">如何连接笔记本环境，比如<strong class="kf ir"> JupyterLab </strong>或者亚马逊的<strong class="kf ir"> SageMaker </strong>。</li></ol><p id="fef0" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">请记住，在AWS上有许多方法可以完成相同的任务。除了已经拥有一个AWS帐户之外，熟悉Python、Bash和基本编程概念是获得本文价值的软先决条件。您还需要一个安全密钥，该密钥是在您最初注册AWS帐户以访问Amazon的EC2平台上的虚拟机时在一个. pem文件中提供给您的。好了，让我们开始吧！</p><p id="54c2" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated"><strong class="kf ir"> 1。旋转AWS弹性地图减少(EMR)集群</strong></p><p id="c5d3" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">跨云计算平台的第一步是启动Hadoop集群，以支持我们之前提到的存储和并行处理。亚马逊的EMR平台允许我们与Apache的Hadoop框架对接，以处理我们将使用的大型数据集，这是我们在计算云计算成本时必须牢记的因素，无论我们何时租用亚马逊的资源，亚马逊都会向我们收取费用。</p><p id="5aff" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">我们将使用的大多数工具都可以在“分析”子菜单下的“服务”菜单栏中找到。</p><figure class="lr ls lt lu gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi lq"><img src="../Images/7dc2ebb89e94b7e1819c4f70aa44843c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*6ZAHPmSObXUGgxcZ"/></div></div><figcaption class="jy jz gj gh gi ka kb bd b be z dk translated">来源:图片由作者提供</figcaption></figure><p id="2ee2" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">接下来，我们想点击<em class="lb">创建一个集群</em>，并概述我们在第1步中的工作所需的规范。我们在这里要做的第一件事是点击<em class="lb">转到高级设置</em>超链接，因为我们工作的规格将比<em class="lb">快速选项</em>设置中提供的规格更精细。导航到高级设置会将我们带到<em class="lb">步骤1:软件和步骤。</em></p><p id="3693" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">在这个演练中，我们将使用Amazon的EMR集群的旧版本，以确保我们将在AWS生态系统中使用的所有工具都能按预期工作。我们还想检查一下我们用于这项工作的工具套件，在本例中是Hadoop、JupyterHub、Hive和Spark。</p><figure class="lr ls lt lu gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi lq"><img src="../Images/3c6c40fae66e7dd2c1625969d2098bdc.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*8Ox4ZEAGjHLzAXbl"/></div></div><figcaption class="jy jz gj gh gi ka kb bd b be z dk translated">来源:图片由作者提供</figcaption></figure><p id="1af6" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">对于步骤2，我们可以保持默认设置不变。在第3步中，您需要在<em class="lb">集群名称</em>输入栏中命名您的集群。</p><p id="0d32" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">接下来，进入第4步，指定让我们能够访问EC2的密钥对很重要，EC2是AWS虚拟机，它让我们能够完全访问AWS生态系统。您的密钥对的名称应该与您给。pem注册后。一旦您指定了您的<em class="lb"> EC2密钥对</em>，导航到页面的右下角并点击<em class="lb">创建集群</em>。</p><figure class="lr ls lt lu gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi lq"><img src="../Images/8c1d5f11d16da702c82512b252611692.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*5L7P6G5QgUN8DGDJ"/></div></div><figcaption class="jy jz gj gh gi ka kb bd b be z dk translated">来源:图片由作者提供</figcaption></figure><p id="635d" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated"><strong class="kf ir"> 2。使用SSH连接到集群的头节点</strong></p><p id="7940" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">现在我们已经根据我们的工作规范配置了我们的参数，它将需要几分钟的时间来完全启动和运行。与此同时，我们可以检查以确保我们的设置以这样一种方式配置，即我们将能够通过SSH隧道访问我们的集群节点。为此，我们要确保我们回到了<em class="lb">摘要</em>选项卡，在<em class="lb">安全和访问</em>副标题下，我们要点击主标签的<em class="lb">安全组旁边的链接:</em></p><figure class="lr ls lt lu gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi lv"><img src="../Images/b5e15d95aeadaf1f4d04ee49767911a1.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*xl-GhIHo683hGaOl"/></div></div><figcaption class="jy jz gj gh gi ka kb bd b be z dk translated">来源:图片由作者提供</figcaption></figure><p id="2367" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">单击该安全链接会将您带到<em class="lb">安全组</em>页面。在这里，您需要右键单击在其描述中提到了<em class="lb">主组</em>的安全组，并选择<em class="lb">编辑入站规则</em>:</p><figure class="lr ls lt lu gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi lq"><img src="../Images/b3acc4cf7a7dc612bf7a51e36f37d7e5.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*x6EgGdebdT8nR5KA"/></div></div><figcaption class="jy jz gj gh gi ka kb bd b be z dk translated">来源:图片由作者提供</figcaption></figure><p id="7d84" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">最后，您需要确保其中一个入站规则已经预先选择了<em class="lb"> SSH </em>，以及<em class="lb"> My IP </em>选项。如果缺少其中一个选项，请使用下拉菜单选择SSH。如果不启用SSH访问，我们将无法访问与计算集群交互的EC2虚拟机。检查完这些选项后，继续点击<em class="lb">保存规则</em>，然后导航回主摘要选项卡。希望现在集群至少显示为<strong class="kf ir"> Starting </strong>，这样我们就可以开始建立SSH连接了。</p><figure class="lr ls lt lu gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi lq"><img src="../Images/89856bf9897da84b8829a11271798352.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*b0v8bbpFu0HriY5d"/></div></div><figcaption class="jy jz gj gh gi ka kb bd b be z dk translated">来源:图片由作者提供</figcaption></figure><p id="2617" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">在summary选项卡上，在显示<em class="lb"> Master Public DNS的地方，</em>单击<em class="lb">使用SSH </em>连接到主节点超链接，如果您已经在计算机上安装了<strong class="kf ir"> Bash终端</strong>，则直接导航到Mac/Linux选项卡，而不考虑操作系统。按照列出的说明操作，如果首先在Bash终端上使用cd命令直接导航到存储EC2密钥的目录/文件夹，事情会变得简单。</p><p id="5ada" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">接下来，将指令中突出显示的Bash命令复制并粘贴(<em class="lb"> Shift </em> + <em class="lb"> Insert </em>)到您的终端，除了确保在点击<em class="lb">之前删除~/相对文件路径字符，输入</em>，然后在出现指纹提示时键入<em class="lb"> yes </em>，如下图所示:</p><figure class="lr ls lt lu gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi lq"><img src="../Images/7cc3e0f58e283b057c6128b60b156497.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*lJx-kltyb3-8gSOq"/></div></div><figcaption class="jy jz gj gh gi ka kb bd b be z dk translated">来源:图片由作者提供</figcaption></figure><p id="c9b5" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">如果一切顺利，您应该会在终端上看到一个EMR标志，表明您现在已经完全连接到Amazon的EMR计算机集群。</p><figure class="lr ls lt lu gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi lw"><img src="../Images/fdf98285f256d43691379618bca0b64a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*XPDwk9w-RwpfSwma"/></div></div><figcaption class="jy jz gj gh gi ka kb bd b be z dk translated">来源:图片由作者提供</figcaption></figure><p id="3c66" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated"><strong class="kf ir"> 3。将文件从S3存储桶移动到HDFS </strong></p><p id="6b64" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">现在我们已经进入了EMR Hadoop框架，让我们将一个文件从公共S3存储桶复制到我们的Hadoop存储系统中。为此，请使用以下命令结构:</p><pre class="lr ls lt lu gt lx ly lz ma aw mb bi"><span id="1d72" class="mc md iq ly b gy me mf l mg mh">hadoop distcp {insert the S3 buckets address that you are copying from} {insert the hadoop directory you wish to move the file to}</span></pre><p id="3a74" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">就这么简单。</p><p id="4e5c" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">同样，命令结构是:</p><pre class="lr ls lt lu gt lx ly lz ma aw mb bi"><span id="0a08" class="mc md iq ly b gy me mf l mg mh">hadoop distcp {s3 bucket} {emr directory}</span></pre><figure class="lr ls lt lu gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi mi"><img src="../Images/e02dccb34e211d62830552e438ce7a23.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*kZXE2_1MChR7tKjY"/></div></div><figcaption class="jy jz gj gh gi ka kb bd b be z dk translated">来源:图片由作者提供</figcaption></figure><p id="cab0" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated"><strong class="kf ir"> 4。使用PySpark从HDFS读取文件</strong></p><p id="17a1" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">厉害！现在我们已经将CSV文件从S3转移到EMR，让我们利用Apache的大规模处理和分布式计算框架PySpark来读取数据并进行一些非常基本的探索性分析。</p><p id="2d95" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">我们的第一步是建立另一个SSH隧道来访问JupyterHub。为此，让我们导航回主摘要选项卡。向下进入<em class="lb">应用程序用户界面</em>副标题，点击<em class="lb">启用SSH连接</em>超链接:</p><figure class="lr ls lt lu gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi mj"><img src="../Images/cebda1fa1ee60d790fbebafe303fbaff.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*TAcj8IDHtMQPJqMk"/></div></div><figcaption class="jy jz gj gh gi ka kb bd b be z dk translated">来源:图片由作者提供</figcaption></figure><p id="cd63" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">这将把你带到一个与我们在步骤2中看到的相似的页面，因为我们基本上在重复相同的步骤。在这种情况下，第2步和第4步的最大区别在于，您需要打开另一个Bash终端页面，因为我们已经将前面的终端专用于建立与EMR的SSH连接。</p><p id="7fe9" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">记住不要忘记在SSH命令中删除密钥名文件路径中的~/字符，并在安全提示符下键入yes:</p><figure class="lr ls lt lu gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi lq"><img src="../Images/ecf448fd1aa6a4ab2a8e1c62fddcc7d1.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*8d1yY9Y5dyc39a9f"/></div></div><figcaption class="jy jz gj gh gi ka kb bd b be z dk translated">来源:图片由作者提供</figcaption></figure><p id="1483" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">建立连接后，导航回主摘要选项卡，单击摘要选项卡右侧的<em class="lb">应用程序用户界面</em>选项卡，然后将与<strong class="kf ir"> JupyterHub </strong>关联的<em class="lb">用户界面URL </em>复制并粘贴到另一个浏览器选项卡中:</p><figure class="lr ls lt lu gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi lq"><img src="../Images/ce49c12fe3c4e3a4658efcb9ad542a58.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*iSsim0_CeLCkSsEO"/></div></div><figcaption class="jy jz gj gh gi ka kb bd b be z dk translated">来源:图片由作者提供</figcaption></figure><p id="5466" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">如果正确执行了步骤4中的所有指令，我们应该会看到下面的JupyterHub登录页面。在访问JupyterHub URL时，您可能会遇到来自浏览器的安全警告。忽略它，进入下面的登录页面，在这里您可以输入与您的帐户相关的用户名和密码。</p><figure class="lr ls lt lu gt jr gh gi paragraph-image"><div class="gh gi mk"><img src="../Images/70f311b811b7cae7095b3b35d5b21606.png" data-original-src="https://miro.medium.com/v2/resize:fit:704/0*nAT_LtGDwPmZulXF"/></div><figcaption class="jy jz gj gh gi ka kb bd b be z dk translated">来源:图片由作者提供</figcaption></figure><p id="a898" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">一旦你登录了，界面就和你使用Jupyter Notebook差不多了。使用我们在JupyterHub中创建的笔记本，我们将使用PySpark完成以下任务:</p><p id="62d6" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">读取我们从HDFS复制的数据，使用<strong class="kf ir"> spark.read.csv(file_path，header=True) </strong>命令将我们的数据转换成我们现在应该非常熟悉的DataFrame格式；</p><ol class=""><li id="a933" class="lc ld iq kf b kg kh kk kl ko le ks lf kw lg la lh li lj lk bi translated">显示数据帧的模式；</li><li id="8263" class="lc ld iq kf b kg ll kk lm ko ln ks lo kw lp la lh li lj lk bi translated">计算数据帧中的行数；</li><li id="1e53" class="lc ld iq kf b kg ll kk lm ko ln ks lo kw lp la lh li lj lk bi translated">使用Spark SQL过滤标记为“data”的行，并计算符合该标准的行数；</li><li id="847e" class="lc ld iq kf b kg ll kk lm ko ln ks lo kw lp la lh li lj lk bi translated">最后，将我们的新数据帧保存为单独的文件，并保存在Hadoop中。</li><li id="dc6f" class="lc ld iq kf b kg ll kk lm ko ln ks lo kw lp la lh li lj lk bi translated">验证我们的数据是否正确保存在Hadoop中。为此，我们在Jupyter中运行df.write.csv()代码块之前运行了<strong class="kf ir"> Hadoop fs -ls bash </strong>命令。运行完最后一个Jupyter代码块后，我们再次使用<strong class="kf ir"> Hadoop fs -ls </strong>命令来检查我们保存为<strong class="kf ir"> eng_data_1gram </strong>的文件是否出现在我们的Hadoop目录中，它确实出现了。</li></ol><figure class="lr ls lt lu gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi ml"><img src="../Images/39d55b5cba01f062eefda23c3bdc4f7c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*rfLukoxSu60jynJc"/></div></div><figcaption class="jy jz gj gh gi ka kb bd b be z dk translated">来源:图片由作者提供</figcaption></figure><p id="5c56" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">请注意，我们在本演示中只运行简单的操作，因为在云中运行这些大规模的操作通常需要成本。</p><figure class="lr ls lt lu gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi mm"><img src="../Images/be8d814f95c53b1f8a949bf38eda3510.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*2F9dY1Qoy4Z2cEVD"/></div></div><figcaption class="jy jz gj gh gi ka kb bd b be z dk translated">来源:图片由作者提供</figcaption></figure><p id="9695" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated"><strong class="kf ir"> 5。合并Hadoop文件并上传到S3 </strong></p><p id="33cb" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">在过滤了“token”列中包含标签“data”的行之后，现在让我们将它与原始文件合并。我们可以使用下面的bash命令结构来完成这项任务:</p><pre class="lr ls lt lu gt lx ly lz ma aw mb bi"><span id="2218" class="mc md iq ly b gy me mf l mg mh">hadoop fs -getmerge {filepath_doc1} {doc2_file_name}.</span></pre><p id="d759" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">两个文件合并后，我们可以发出以下命令结构，将合并后的文件移动到S3存储桶中:</p><pre class="lr ls lt lu gt lx ly lz ma aw mb bi"><span id="46eb" class="mc md iq ly b gy me mf l mg mh">aws s3 cp {filename.format} {s3_bucket_address}.</span></pre><p id="6549" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">最后，您需要使用以下命令列出S3存储桶中的内容，以验证文件是否正确地发送到了您想要的目的地:</p><pre class="lr ls lt lu gt lx ly lz ma aw mb bi"><span id="7503" class="mc md iq ly b gy me mf l mg mh">aws s3 ls {s3_bucket_address}</span></pre><figure class="lr ls lt lu gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi mn"><img src="../Images/2cb9b433b8b66607e669fa5f8832d633.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*_bVBPWQhylOYWpAE"/></div></div><figcaption class="jy jz gj gh gi ka kb bd b be z dk translated">来源:图片由作者提供</figcaption></figure><p id="9b0b" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated"><strong class="kf ir"> 6。使用SageMaker从S3读取文件</strong></p><p id="5b3e" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">在本练习中，我们的最后一项行动是使用亚马逊的SageMaker笔记本环境和JupyterLab从S3存储桶中读取过滤后的数据，并使用传统的数据科学工具(如pandas和matplotlib.pyplot)绘制图表。为此，我们将执行以下步骤:</p><ol class=""><li id="7fbc" class="lc ld iq kf b kg kh kk kl ko le ks lf kw lg la lh li lj lk bi translated">通过运行awscli和s3fs的pip安装来配置我们的笔记本环境；</li><li id="85c0" class="lc ld iq kf b kg ll kk lm ko ln ks lo kw lp la lh li lj lk bi translated">导入我们需要的包，包括AWS包，我们将使用它直接访问我们的S3桶；</li><li id="ec53" class="lc ld iq kf b kg ll kk lm ko ln ks lo kw lp la lh li lj lk bi translated">将S3数据读入熊猫数据框，并使用matplotlib绘制线图。</li></ol><figure class="lr ls lt lu gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi lq"><img src="../Images/bf3e58e3ba6894f89115efd350a7e6dc.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*gAo0iPNfe5oYpFJC"/></div></div><figcaption class="jy jz gj gh gi ka kb bd b be z dk translated">来源:图片由作者提供</figcaption></figure><figure class="lr ls lt lu gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi lq"><img src="../Images/7ea817289d74e88200dea546ea813c0c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*0itmGZzc7dQzrzV1"/></div></div><figcaption class="jy jz gj gh gi ka kb bd b be z dk translated">来源:图片由作者提供</figcaption></figure><figure class="lr ls lt lu gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi lq"><img src="../Images/9405046ba6643959dc92afc08f7838c4.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*dOgVghZXu0JNH3dH"/></div></div><figcaption class="jy jz gj gh gi ka kb bd b be z dk translated">来源:图片由作者提供</figcaption></figure><p id="ee5c" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">就这样结束了！我希望您在阅读这篇文章时发现了价值，并能够对大数据从业者的工作流程有所了解。</p></div></div>    
</body>
</html>