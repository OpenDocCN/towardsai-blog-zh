<html>
<head>
<title>Review: DBPN &amp; D-DBPN — Deep Back-Projection Networks For Super-Resolution (Super Resolution)</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">综述:DBPN和D-DBPN——超分辨率的深度反投影网络(超分辨率)</h1>
<blockquote>原文：<a href="https://pub.towardsai.net/review-dbpn-d-dbpn-deep-back-projection-networks-for-super-resolution-super-resolution-c119ec738ee?source=collection_archive---------0-----------------------#2020-05-05">https://pub.towardsai.net/review-dbpn-d-dbpn-deep-back-projection-networks-for-super-resolution-super-resolution-c119ec738ee?source=collection_archive---------0-----------------------#2020-05-05</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><div class=""><h2 id="d14b" class="pw-subtitle-paragraph jn ip iq bd b jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke dk translated">迭代上下投影单元，优于<a class="ae kf" href="https://medium.com/coinmonks/review-srcnn-super-resolution-3cb3a4f67a7c?source=post_page---------------------------" rel="noopener"> SRCNN </a>、<a class="ae kf" href="https://towardsdatascience.com/review-fsrcnn-super-resolution-80ca2ee14da4?source=post_page---------------------------" rel="noopener" target="_blank"> FSRCNN </a>、<a class="ae kf" href="https://towardsdatascience.com/review-vdsr-super-resolution-f8050d49362f?source=post_page---------------------------" rel="noopener" target="_blank"> VDSR </a>、<a class="ae kf" href="https://medium.com/datadriveninvestor/review-drcn-deeply-recursive-convolutional-network-super-resolution-f0a380f79b20?source=post_page---------------------------" rel="noopener"> DRCN </a>、<a class="ae kf" href="https://towardsdatascience.com/review-drrn-deep-recursive-residual-network-super-resolution-dca4a35ce994?source=post_page---------------------------" rel="noopener" target="_blank"> DRRN </a>、<a class="ae kf" href="https://towardsdatascience.com/review-lapsrn-ms-lapsrn-laplacian-pyramid-super-resolution-network-super-resolution-c5fe2b65f5e8?source=post_page---------------------------" rel="noopener" target="_blank"> LapSRN </a>和<a class="ae kf" href="https://medium.com/@sh.tsang/review-edsr-mdsr-enhanced-deep-residual-networks-for-single-image-super-resolution-super-4364f3b7f86f" rel="noopener"> EDSR </a></h2></div><p id="e9c0" class="pw-post-body-paragraph kg kh iq ki b kj kk jr kl km kn ju ko kp kq kr ks kt ku kv kw kx ky kz la lb ij bi lc translated"><span class="l ld le lf bm lg lh li lj lk di">在</span>这个故事中，回顾了由丰田技术研究所和丰田技术研究所在芝加哥开发的<strong class="ki ir">深度反投影网络(DBPN)和密集DBPN (D-DBPN) </strong>。在DBPN:</p><ul class=""><li id="6298" class="ll lm iq ki b kj kk km kn kp ln kt lo kx lp lb lq lr ls lt bi translated">它利用<strong class="ki ir">迭代上采样层和下采样层</strong>，为每个阶段的投影误差提供误差反馈机制。<strong class="ki ir">构造相互连接的上采样和下采样级</strong>，每个级代表不同类型的图像退化和高分辨率分量。</li><li id="eaf0" class="ll lm iq ki b kj lu km lv kp lw kt lx kx ly lb lq lr ls lt bi translated">通过扩展这一思想，允许<strong class="ki ir">跨上采样和下采样阶段的特征串联(密集DBPN) </strong>进一步改善结果。</li></ul><p id="30e5" class="pw-post-body-paragraph kg kh iq ki b kj kk jr kl km kn ju ko kp kq kr ks kt ku kv kw kx ky kz la lb ij bi translated">这是一篇在<strong class="ki ir"> 2018 CVPR </strong>的论文，有大约<strong class="ki ir"> 300次引用</strong>。(<a class="lz ma ep" href="https://medium.com/u/aff72a0c1243?source=post_page-----c119ec738ee--------------------------------" rel="noopener" target="_blank"> Sik-Ho Tsang </a> @中)</p></div><div class="ab cl mb mc hu md" role="separator"><span class="me bw bk mf mg mh"/><span class="me bw bk mf mg mh"/><span class="me bw bk mf mg"/></div><div class="ij ik il im in"><h1 id="8c6e" class="mi mj iq bd mk ml mm mn mo mp mq mr ms jw mt jx mu jz mv ka mw kc mx kd my mz bi translated">概述</h1><ol class=""><li id="efb1" class="ll lm iq ki b kj na km nb kp nc kt nd kx ne lb nf lr ls lt bi translated"><strong class="ki ir">深度网络服务请求比较</strong></li><li id="2612" class="ll lm iq ki b kj lu km lv kp lw kt lx kx ly lb nf lr ls lt bi translated"><strong class="ki ir"> DBPN:放映单位</strong></li><li id="ea05" class="ll lm iq ki b kj lu km lv kp lw kt lx kx ly lb nf lr ls lt bi translated"><strong class="ki ir"> D-DBPN:密集投影单元</strong></li><li id="0f2f" class="ll lm iq ki b kj lu km lv kp lw kt lx kx ly lb nf lr ls lt bi translated"><strong class="ki ir">总体D-DBPN网络架构&amp;一些细节</strong></li><li id="4ac6" class="ll lm iq ki b kj lu km lv kp lw kt lx kx ly lb nf lr ls lt bi translated"><strong class="ki ir">消融研究</strong></li><li id="d34a" class="ll lm iq ki b kj lu km lv kp lw kt lx kx ly lb nf lr ls lt bi translated"><strong class="ki ir">最先进的(SOTA)对比</strong></li></ol></div><div class="ab cl mb mc hu md" role="separator"><span class="me bw bk mf mg mh"/><span class="me bw bk mf mg mh"/><span class="me bw bk mf mg"/></div><div class="ij ik il im in"><h1 id="f3b7" class="mi mj iq bd mk ml mm mn mo mp mq mr ms jw mt jx mu jz mv ka mw kc mx kd my mz bi translated"><strong class="ak"> 1。深度网络服务请求比较</strong></h1><figure class="nh ni nj nk gt nl gh gi paragraph-image"><div role="button" tabindex="0" class="nm nn di no bf np"><div class="gh gi ng"><img src="../Images/479f2e65418ee9837872844a409164b0.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*aecRhcxUGL7dWWf0MU5Biw.png"/></div></div><figcaption class="ns nt gj gh gi nu nv bd b be z dk translated"><strong class="bd mk">深网SR对比</strong></figcaption></figure><ul class=""><li id="8a37" class="ll lm iq ki b kj kk km kn kp ln kt lo kx lp lb lq lr ls lt bi translated"><strong class="ki ir"> (a)预定义的上采样</strong>:通常使用插值作为上采样算子来产生中分辨率(MR)图像。这个模式最早是由<a class="ae kf" href="https://medium.com/coinmonks/review-srcnn-super-resolution-3cb3a4f67a7c?source=post_page---------------------------" rel="noopener"> SRCNN </a>提出的。</li><li id="a0b0" class="ll lm iq ki b kj lu km lv kp lw kt lx kx ly lb lq lr ls lt bi translated"><strong class="ki ir"> (b)单次上采样</strong>:提供简单而有效的方法来提高空间分辨率。这个方法是由<a class="ae kf" href="https://towardsdatascience.com/review-fsrcnn-super-resolution-80ca2ee14da4?source=post_page---------------------------" rel="noopener" target="_blank"> FSRCNN </a>和<a class="ae kf" href="https://medium.com/datadriveninvestor/review-espcn-real-time-sr-super-resolution-8dceca249350?source=post_page---------------------------" rel="noopener"> ESPCN </a>提出的。</li><li id="7b12" class="ll lm iq ki b kj lu km lv kp lw kt lx kx ly lb lq lr ls lt bi translated"><strong class="ki ir"> (c)渐进上采样</strong>:最近在<a class="ae kf" href="https://towardsdatascience.com/review-lapsrn-ms-lapsrn-laplacian-pyramid-super-resolution-network-super-resolution-c5fe2b65f5e8?source=post_page---------------------------" rel="noopener" target="_blank"> LapSRN </a>中提出。它在一个前馈网络中逐步重建不同尺度的多幅超分辨率图像。</li><li id="130e" class="ll lm iq ki b kj lu km lv kp lw kt lx kx ly lb lq lr ls lt bi translated"><strong class="ki ir"> (d)迭代上采样和下采样</strong>:本文提出。DBPN负责<strong class="ki ir">提高不同深度的超分辨率特征的采样率</strong>和<strong class="ki ir">将计算重建误差的任务分配到各个阶段</strong>。</li><li id="07a8" class="ll lm iq ki b kj lu km lv kp lw kt lx kx ly lb lq lr ls lt bi translated">这种模式使网络能够通过学习各种上采样和下采样操作符来保持HR成分，同时生成更深层次的特征。</li></ul></div><div class="ab cl mb mc hu md" role="separator"><span class="me bw bk mf mg mh"/><span class="me bw bk mf mg mh"/><span class="me bw bk mf mg"/></div><div class="ij ik il im in"><h1 id="de19" class="mi mj iq bd mk ml mm mn mo mp mq mr ms jw mt jx mu jz mv ka mw kc mx kd my mz bi translated">2.<strong class="ak"> DBPN:放映单位</strong></h1><figure class="nh ni nj nk gt nl gh gi paragraph-image"><div role="button" tabindex="0" class="nm nn di no bf np"><div class="gh gi nw"><img src="../Images/db469ff8bf30508f50db97b7eea3f44d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*w3wt6Mgaod5-kA6fPTHk1A.png"/></div></div><figcaption class="ns nt gj gh gi nu nv bd b be z dk translated"><strong class="bd mk">提议的DBPN上下投影装置</strong></figcaption></figure><figure class="nh ni nj nk gt nl gh gi paragraph-image"><div class="gh gi nx"><img src="../Images/3f4f630838da87d1981164c8d1d9cc5d.png" data-original-src="https://miro.medium.com/v2/resize:fit:882/format:webp/1*dlGRnq8EFz6o4MpQdMjUxA.png"/></div></figure><h2 id="ca0b" class="ny mj iq bd mk nz oa dn mo ob oc dp ms kp od oe mu kt of og mw kx oh oi my oj bi translated">2.1.向上投影单元</h2><ul class=""><li id="efb3" class="ll lm iq ki b kj na km nb kp nc kt nd kx ne lb lq lr ls lt bi translated">该投影单元将之前计算的<strong class="ki ir"> LR特征映射<em class="ok"> Lt </em> -1作为输入</strong>，<strong class="ki ir">将其映射到一个(中间)HR映射<em class="ok"> Ht </em> 0 </strong>。</li><li id="b584" class="ll lm iq ki b kj lu km lv kp lw kt lx kx ly lb lq lr ls lt bi translated">然后，它试图<strong class="ki ir">将其映射回LR映射<em class="ok"> Lt </em> 0("反向投影")</strong>。</li><li id="19b4" class="ll lm iq ki b kj lu km lv kp lw kt lx kx ly lb lq lr ls lt bi translated"><strong class="ki ir">观察到的LR映射<em class="ok"> Lt </em> -1和重构的<em class="ok"> Lt </em> 0之间的残差<em class="ok"> elt </em>再次映射到HR，产生新的中间(残差)映射<em class="ok"> Ht </em> 1。</strong></li><li id="6497" class="ll lm iq ki b kj lu km lv kp lw kt lx kx ly lb lq lr ls lt bi translated"><strong class="ki ir">该单元的最终输出，即HR图<em class="ok"> Ht </em>，通过将两个中间HR图相加得到。</strong></li><li id="21cf" class="ll lm iq ki b kj lu km lv kp lw kt lx kx ly lb lq lr ls lt bi translated">上图的上半部分说明了这一步。</li></ul><h2 id="991d" class="ny mj iq bd mk nz oa dn mo ob oc dp ms kp od oe mu kt of og mw kx oh oi my oj bi translated">2.1.向下投影单元</h2><ul class=""><li id="b08e" class="ll lm iq ki b kj na km nb kp nc kt nd kx ne lb lq lr ls lt bi translated">向下投影单元的定义非常类似，但现在它的工作是<strong class="ki ir">将其输入的HR映射<em class="ok"> Ht </em>映射到LR映射<em class="ok">Lt</em>T5】，如上图的下半部分所示。</strong></li></ul><h2 id="8d62" class="ny mj iq bd mk nz oa dn mo ob oc dp ms kp od oe mu kt of og mw kx oh oi my oj bi translated">2.3.安排</h2><ul class=""><li id="f466" class="ll lm iq ki b kj na km nb kp nc kt nd kx ne lb lq lr ls lt bi translated">这些投影单元在<strong class="ki ir">的一系列阶段</strong>中，在H和l之间交替</li><li id="1fd1" class="ll lm iq ki b kj lu km lv kp lw kt lx kx ly lb lq lr ls lt bi translated">这些投影单元可以被理解为<strong class="ki ir">一种自校正过程，其将投影误差馈送到采样层</strong>并且<strong class="ki ir">通过反馈投影误差</strong>来迭代地改变解决方案。</li><li id="aeb5" class="ll lm iq ki b kj lu km lv kp lw kt lx kx ly lb lq lr ls lt bi translated">投影单元使用<strong class="ki ir">8×8和12×12等大尺寸滤镜。</strong>通常，避免使用大型过滤器，因为它会降低收敛速度，并可能产生次优结果。</li><li id="4f8c" class="ll lm iq ki b kj lu km lv kp lw kt lx kx ly lb lq lr ls lt bi translated">在本文中，<strong class="ki ir">我们的投影单元的迭代利用使得网络能够抑制这种限制</strong>，并且即使在浅网络中也能够在大比例因子上执行更好的性能。</li></ul></div><div class="ab cl mb mc hu md" role="separator"><span class="me bw bk mf mg mh"/><span class="me bw bk mf mg mh"/><span class="me bw bk mf mg"/></div><div class="ij ik il im in"><h1 id="6b0d" class="mi mj iq bd mk ml mm mn mo mp mq mr ms jw mt jx mu jz mv ka mw kc mx kd my mz bi translated">3.D- <strong class="ak"> DBPN:密集投影单元</strong></h1><figure class="nh ni nj nk gt nl gh gi paragraph-image"><div role="button" tabindex="0" class="nm nn di no bf np"><div class="gh gi ol"><img src="../Images/2a6ff6579c17936b49bfdde45846b5ca.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*aOXD-6vj_DeNCPE8B7e7sw.png"/></div></div><figcaption class="ns nt gj gh gi nu nv bd b be z dk translated"><strong class="bd mk">D-DBPN中建议的上下投影单元</strong></figcaption></figure><ul class=""><li id="07d7" class="ll lm iq ki b kj kk km kn kp ln kt lo kx lp lb lq lr ls lt bi translated">受<a class="ae kf" href="https://towardsdatascience.com/review-densenet-image-classification-b6631a8ef803?source=post_page---------------------------" rel="noopener" target="_blank"> DenseNet </a>的启发，<strong class="ki ir">稠密连接被引入</strong>称为的投影单元，产生稠密DBPN (D-DBPN)。</li><li id="3359" class="ll lm iq ki b kj lu km lv kp lw kt lx kx ly lb lq lr ls lt bi translated">但是要避免遗漏和批量规范，因为它们不适合SR。</li><li id="908f" class="ll lm iq ki b kj lu km lv kp lw kt lx kx ly lb lq lr ls lt bi translated">每个单元的输入是所有先前单元的输出的串联。</li><li id="73cb" class="ll lm iq ki b kj lu km lv kp lw kt lx kx ly lb lq lr ls lt bi translated"><strong class="ki ir"> 1×1卷积层在进入投影单元前作为特征池和降维。</strong></li></ul></div><div class="ab cl mb mc hu md" role="separator"><span class="me bw bk mf mg mh"/><span class="me bw bk mf mg mh"/><span class="me bw bk mf mg"/></div><div class="ij ik il im in"><h1 id="14f5" class="mi mj iq bd mk ml mm mn mo mp mq mr ms jw mt jx mu jz mv ka mw kc mx kd my mz bi translated"><strong class="ak"> 4。总体D-DBPN网络架构&amp;一些细节</strong></h1><figure class="nh ni nj nk gt nl gh gi paragraph-image"><div role="button" tabindex="0" class="nm nn di no bf np"><div class="gh gi om"><img src="../Images/0c2551c58ae724d2a410cbcfada3e1d3.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*3H5OwP2rvbtRa8UBhYARBg.png"/></div></div><figcaption class="ns nt gj gh gi nu nv bd b be z dk translated"><strong class="bd mk">总体迪DBPN网络架构</strong></figcaption></figure><h2 id="acde" class="ny mj iq bd mk nz oa dn mo ob oc dp ms kp od oe mu kt of og mw kx oh oi my oj bi translated">4.1.DBPN建筑</h2><ul class=""><li id="ba18" class="ll lm iq ki b kj na km nb kp nc kt nd kx ne lb lq lr ls lt bi translated">提出的D-DBPN可以分为<strong class="ki ir">三个部分:初始特征提取、投影和重建。</strong></li><li id="9193" class="ll lm iq ki b kj lu km lv kp lw kt lx kx ly lb lq lr ls lt bi translated">设conv( <em class="ok"> f </em>，<em class="ok"> n </em>)为卷积层，其中<em class="ok"> f </em>为滤波器大小，<em class="ok"> n </em>为滤波器个数。</li><li id="2a47" class="ll lm iq ki b kj lu km lv kp lw kt lx kx ly lb lq lr ls lt bi translated"><strong class="ki ir">初始特征提取:使用conv(3，<em class="ok"> n </em> 0)从输入中I </strong>初始LR特征映射<em class="ok"> L </em> 0。然后在进入投影步骤之前，使用conv(1，<em class="ok"> nR </em>)将尺寸从<em class="ok"> n0 </em>减小到<em class="ok"> nR </em>。</li><li id="9857" class="ll lm iq ki b kj lu km lv kp lw kt lx kx ly lb lq lr ls lt bi translated"><strong class="ki ir">反投影阶段:</strong>交替向上投影和向下投影。每个单元都可以访问所有先前单元的输出。</li><li id="34a7" class="ll lm iq ki b kj lu km lv kp lw kt lx kx ly lb lq lr ls lt bi translated"><strong class="ki ir">重建</strong>:最后将目标HR图像重建为<em class="ok">Isr</em>=<em class="ok">fRec</em>(<em class="ok">H</em>1、<em class="ok"> H </em> 2、…、<em class="ok"> Ht </em>)，其中<em class="ok"> fRec </em>使用conv(3，3)作为重建，【<em class="ok"> H </em> 1、<em class="ok"> H </em> 2、…、<em class="ok"> Ht </em>指</li></ul><h2 id="f4ca" class="ny mj iq bd mk nz oa dn mo ob oc dp ms kp od oe mu kt of og mw kx oh oi my oj bi translated">4.2.一些细节</h2><ul class=""><li id="2351" class="ll lm iq ki b kj na km nb kp nc kt nd kx ne lb lq lr ls lt bi translated">对于具有<strong class="ki ir"> <em class="ok"> T </em>级</strong>的网络，我们有<strong class="ki ir">初始提取级(2层)</strong>，然后是<strong class="ki ir"> <em class="ok"> T </em>上投影单元</strong>和<strong class="ki ir"><em class="ok"/>-1下投影单元</strong>、<strong class="ki ir">各有3层</strong>，接着是<strong class="ki ir">重建(多一层)</strong>。</li><li id="128c" class="ll lm iq ki b kj lu km lv kp lw kt lx kx ly lb lq lr ls lt bi translated">对于<strong class="ki ir">密网</strong>，除了前三个单元外，每个投影单元都增加了<strong class="ki ir"> conv(1，<em class="ok"> nR </em>)。</strong></li><li id="05d5" class="ll lm iq ki b kj lu km lv kp lw kt lx kx ly lb lq lr ls lt bi translated">对于<strong class="ki ir">的2倍放大，使用了6×6的卷积层</strong>，具有两个stridings和两个paddings。</li><li id="b4fa" class="ll lm iq ki b kj lu km lv kp lw kt lx kx ly lb lq lr ls lt bi translated">然后，<strong class="ki ir"> 4倍放大用一个8×8的卷积层</strong>四跨两填充。</li><li id="34fa" class="ll lm iq ki b kj lu km lv kp lw kt lx kx ly lb lq lr ls lt bi translated">最后，<strong class="ki ir"> 8倍放大使用一个12×12的卷积层</strong>，具有八个步长和两个填充。</li><li id="8dec" class="ll lm iq ki b kj lu km lv kp lw kt lx kx ly lb lq lr ls lt bi translated"><strong class="ki ir">使用了PReLU </strong>。</li><li id="0e53" class="ll lm iq ki b kj lu km lv kp lw kt lx kx ly lb lq lr ls lt bi translated">所有的网络都使用来自DIV2K、Flickr和ImageNet数据集的图像进行训练，而不进行增强。</li><li id="af57" class="ll lm iq ki b kj lu km lv kp lw kt lx kx ly lb lq lr ls lt bi translated">为了产生LR图像，使用双三次函数在特定的缩放因子上缩小HR图像。使用大小为32×32的批量大小20，用于LR图像。</li></ul></div><div class="ab cl mb mc hu md" role="separator"><span class="me bw bk mf mg mh"/><span class="me bw bk mf mg mh"/><span class="me bw bk mf mg"/></div><div class="ij ik il im in"><h1 id="0562" class="mi mj iq bd mk ml mm mn mo mp mq mr ms jw mt jx mu jz mv ka mw kc mx kd my mz bi translated">5.<strong class="ak">消融研究</strong></h1><h2 id="af2e" class="ny mj iq bd mk nz oa dn mo ob oc dp ms kp od oe mu kt of og mw kx oh oi my oj bi translated">5.1.深度分析</h2><figure class="nh ni nj nk gt nl gh gi paragraph-image"><div role="button" tabindex="0" class="nm nn di no bf np"><div class="gh gi on"><img src="../Images/c48bea0343480642d59de8bc5c0a699e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*xvtu9yy9Vr3SzRYD5pauiQ.png"/></div></div><figcaption class="ns nt gj gh gi nu nv bd b be z dk translated"><strong class="bd mk">dbpn对4倍放大结果的深度分析</strong></figcaption></figure><ul class=""><li id="6da1" class="ll lm iq ki b kj kk km kn kp ln kt lo kx lp lb lq lr ls lt bi translated">多重网络由原来的DBPN构造为<strong class="ki ir"> S ( <em class="ok"> T </em> = 2)、M ( <em class="ok"> T </em> = 4)、L ( <em class="ok"> T </em> = 6) </strong>。在特征提取中，我们使用conv(3，128)然后是conv(1，32)。然后，我们使用conv(1，1)进行重建。输入和输出图像仅为亮度。</li><li id="39ae" class="ll lm iq ki b kj lu km lv kp lw kt lx kx ly lb lq lr ls lt bi translated"><strong class="ki ir">S网络给出了比</strong><a class="ae kf" href="https://towardsdatascience.com/review-vdsr-super-resolution-f8050d49362f?source=post_page---------------------------" rel="noopener" target="_blank"><strong class="ki ir">VDSR</strong></a><strong class="ki ir"/><a class="ae kf" href="https://medium.com/datadriveninvestor/review-drcn-deeply-recursive-convolutional-network-super-resolution-f0a380f79b20?source=post_page---------------------------" rel="noopener"><strong class="ki ir">DRCN</strong></a><strong class="ki ir"/><a class="ae kf" href="https://towardsdatascience.com/review-lapsrn-ms-lapsrn-laplacian-pyramid-super-resolution-network-super-resolution-c5fe2b65f5e8?source=post_page---------------------------" rel="noopener" target="_blank"><strong class="ki ir">LapSRN</strong></a><strong class="ki ir">更高的PSNR。</strong>S网络仅使用<strong class="ki ir">12个卷积层，滤波器数量</strong>比<a class="ae kf" href="https://towardsdatascience.com/review-vdsr-super-resolution-f8050d49362f?source=post_page---------------------------" rel="noopener" target="_blank"> VDSR </a>、<a class="ae kf" href="https://medium.com/datadriveninvestor/review-drcn-deeply-recursive-convolutional-network-super-resolution-f0a380f79b20?source=post_page---------------------------" rel="noopener"> DRCN </a>和<a class="ae kf" href="https://towardsdatascience.com/review-lapsrn-ms-lapsrn-laplacian-pyramid-super-resolution-network-super-resolution-c5fe2b65f5e8?source=post_page---------------------------" rel="noopener" target="_blank"> LapSRN </a>少。</li><li id="bf61" class="ll lm iq ki b kj lu km lv kp lw kt lx kx ly lb lq lr ls lt bi translated"><strong class="ki ir">M网胜过所有</strong><a class="ae kf" href="https://towardsdatascience.com/review-vdsr-super-resolution-f8050d49362f?source=post_page---------------------------" rel="noopener" target="_blank"><strong class="ki ir">VDSR</strong></a><strong class="ki ir"/><a class="ae kf" href="https://medium.com/datadriveninvestor/review-drcn-deeply-recursive-convolutional-network-super-resolution-f0a380f79b20?source=post_page---------------------------" rel="noopener"><strong class="ki ir">DRCN</strong></a><strong class="ki ir"/><a class="ae kf" href="https://towardsdatascience.com/review-lapsrn-ms-lapsrn-laplacian-pyramid-super-resolution-network-super-resolution-c5fe2b65f5e8?source=post_page---------------------------" rel="noopener" target="_blank"><strong class="ki ir">LapSRN</strong></a><strong class="ki ir">，以及</strong><a class="ae kf" href="https://towardsdatascience.com/review-drrn-deep-recursive-residual-network-super-resolution-dca4a35ce994?source=post_page---------------------------" rel="noopener" target="_blank"><strong class="ki ir">DRRN</strong></a><strong class="ki ir">。</strong></li><li id="c223" class="ll lm iq ki b kj lu km lv kp lw kt lx kx ly lb lq lr ls lt bi translated">总之，M网络使用与 <a class="ae kf" href="https://towardsdatascience.com/review-lapsrn-ms-lapsrn-laplacian-pyramid-super-resolution-network-super-resolution-c5fe2b65f5e8?source=post_page---------------------------" rel="noopener" target="_blank"> <strong class="ki ir"> LapSRN </strong> </a> <strong class="ki ir">深度相同的<strong class="ki ir"> 24个卷积层。</strong>与<a class="ae kf" href="https://towardsdatascience.com/review-drrn-deep-recursive-residual-network-super-resolution-dca4a35ce994?source=post_page---------------------------" rel="noopener" target="_blank"> DRRN </a>(多达52个卷积层)相比，M网络不可否认地显示了我们投影单元的有效性。</strong></li><li id="68cb" class="ll lm iq ki b kj lu km lv kp lw kt lx kx ly lb lq lr ls lt bi translated">最后，<strong class="ki ir">L网络优于所有方法【31.86 dB，分别比<a class="ae kf" href="https://towardsdatascience.com/review-vdsr-super-resolution-f8050d49362f?source=post_page---------------------------" rel="noopener" target="_blank"> VDSR </a>、<a class="ae kf" href="https://medium.com/datadriveninvestor/review-drcn-deeply-recursive-convolutional-network-super-resolution-f0a380f79b20?source=post_page---------------------------" rel="noopener"> DRCN </a>、<a class="ae kf" href="https://towardsdatascience.com/review-lapsrn-ms-lapsrn-laplacian-pyramid-super-resolution-network-super-resolution-c5fe2b65f5e8?source=post_page---------------------------" rel="noopener" target="_blank"> LapSRN </a>和<a class="ae kf" href="https://towardsdatascience.com/review-drrn-deep-recursive-residual-network-super-resolution-dca4a35ce994?source=post_page---------------------------" rel="noopener" target="_blank"> DRRN </a>好0.51 dB、0.33 dB、0.32 dB、0.18 dB。</strong></li></ul><figure class="nh ni nj nk gt nl gh gi paragraph-image"><div role="button" tabindex="0" class="nm nn di no bf np"><div class="gh gi oo"><img src="../Images/36ac3643280c447595a69ae92d8d2b7b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*ZNFHSKhnIPrD_TSZGZ01lQ.png"/></div></div><figcaption class="ns nt gj gh gi nu nv bd b be z dk translated"><strong class="bd mk">DBPNs对8倍放大结果的深度分析</strong></figcaption></figure><ul class=""><li id="7018" class="ll lm iq ki b kj kk km kn kp ln kt lo kx lp lb lq lr ls lt bi translated">对于8倍放大的结果，每个建议的网络没有明显的性能增益<strong class="ki ir">,尤其是L和M网络</strong>,其差异仅为0:04 dB。</li></ul><h2 id="7fb6" class="ny mj iq bd mk nz oa dn mo ob oc dp ms kp od oe mu kt of og mw kx oh oi my oj bi translated">5.2.参数数量</h2><figure class="nh ni nj nk gt nl gh gi paragraph-image"><div role="button" tabindex="0" class="nm nn di no bf np"><div class="gh gi op"><img src="../Images/72202492ec333e67603aab44cfb6e2ad.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*urmbHih0BHLEcR7xgZUiBw.png"/></div></div><figcaption class="ns nt gj gh gi nu nv bd b be z dk translated"><strong class="bd mk">性能与参数数量。使用4倍放大的Set5数据集对结果进行评估</strong></figcaption></figure><figure class="nh ni nj nk gt nl gh gi paragraph-image"><div role="button" tabindex="0" class="nm nn di no bf np"><div class="gh gi oq"><img src="../Images/ec84ff9106b1a4e63413e078f6163e13.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*o0WqRa5b8bU0MYVs8htb5g.png"/></div></div><figcaption class="ns nt gj gh gi nu nv bd b be z dk translated"><strong class="bd mk">性能与参数数量。使用8倍放大的Set5数据集对结果进行评估</strong></figcaption></figure><ul class=""><li id="10e5" class="ll lm iq ki b kj kk km kn kp ln kt lo kx lp lb lq lr ls lt bi translated">构建SS网络，它是S网络的较轻版本，(<em class="ok"> T </em> = 2)，仅使用conv(3，64)接着conv(1，18)用于初始特征提取。</li><li id="a21b" class="ll lm iq ki b kj lu km lv kp lw kt lx kx ly lb lq lr ls lt bi translated">结果在4倍和8倍放大上均优于<a class="ae kf" href="https://medium.com/coinmonks/review-srcnn-super-resolution-3cb3a4f67a7c?source=post_page---------------------------" rel="noopener"> SRCNN </a>、<a class="ae kf" href="https://towardsdatascience.com/review-fsrcnn-super-resolution-80ca2ee14da4?source=post_page---------------------------" rel="noopener" target="_blank"> FSRCNN </a>和<a class="ae kf" href="https://towardsdatascience.com/review-vdsr-super-resolution-f8050d49362f?source=post_page---------------------------" rel="noopener" target="_blank"> VDSR </a>。</li><li id="34a2" class="ll lm iq ki b kj lu km lv kp lw kt lx kx ly lb lq lr ls lt bi translated"><strong class="ki ir">SS网络比</strong> <a class="ae kf" href="https://towardsdatascience.com/review-vdsr-super-resolution-f8050d49362f?source=post_page---------------------------" rel="noopener" target="_blank"> <strong class="ki ir"> VDSR </strong> </a> <strong class="ki ir">性能更好，在4倍和8倍放大</strong>上参数分别少72%和37%。</li><li id="cace" class="ll lm iq ki b kj lu km lv kp lw kt lx kx ly lb lq lr ls lt bi translated"><strong class="ki ir">S网络在4倍放大上比</strong><a class="ae kf" href="https://towardsdatascience.com/review-lapsrn-ms-lapsrn-laplacian-pyramid-super-resolution-network-super-resolution-c5fe2b65f5e8?source=post_page---------------------------" rel="noopener" target="_blank"><strong class="ki ir">LapSRN</strong></a><strong class="ki ir">少约27%的参数和更高的PSNR。</strong></li><li id="b1a7" class="ll lm iq ki b kj lu km lv kp lw kt lx kx ly lb lq lr ls lt bi translated">与放大4倍的<a class="ae kf" href="https://medium.com/@sh.tsang/review-edsr-mdsr-enhanced-deep-residual-networks-for-single-image-super-resolution-super-4364f3b7f86f" rel="noopener"><strong class="ki ir"/></a><strong class="ki ir">相比，<strong class="ki ir"> D-DBPN的参数减少了约76%，PSNR也大致相同。</strong></strong></li><li id="2dc3" class="ll lm iq ki b kj lu km lv kp lw kt lx kx ly lb lq lr ls lt bi translated">在8倍放大的情况下，与<a class="ae kf" href="https://medium.com/@sh.tsang/review-edsr-mdsr-enhanced-deep-residual-networks-for-single-image-super-resolution-super-4364f3b7f86f" rel="noopener"> EDSR </a>相比，D-DBPN的参数少了约47%，PSNR更好。</li></ul><h2 id="ef78" class="ny mj iq bd mk nz oa dn mo ob oc dp ms kp od oe mu kt of og mw kx oh oi my oj bi translated">5.3.深度串联</h2><figure class="nh ni nj nk gt nl gh gi paragraph-image"><div role="button" tabindex="0" class="nm nn di no bf np"><div class="gh gi or"><img src="../Images/ca011735b749ca86aa416b2dbc1cb95b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*IrTFBxT7viHc_pM1hQyhdA.png"/></div></div><figcaption class="ns nt gj gh gi nu nv bd b be z dk translated"><strong class="bd mk">来自D-DBPN中上投影单元的激活图样本，其中t = 7 </strong></figcaption></figure><ul class=""><li id="9f73" class="ll lm iq ki b kj kk km kn kp ln kt lo kx lp lb lq lr ls lt bi translated"><strong class="ki ir">深度拼接还与<em class="ok"> T </em> </strong>(反投影阶段)的数量密切相关，它显示了从投影单元生成的更详细的特征，也将提高结果的质量。</li><li id="ab35" class="ll lm iq ki b kj lu km lv kp lw kt lx kx ly lb lq lr ls lt bi translated">上图显示<strong class="ki ir">每一阶段都成功生成不同的特征来重建SR图像</strong>。</li></ul><h2 id="fa93" class="ny mj iq bd mk nz oa dn mo ob oc dp ms kp od oe mu kt of og mw kx oh oi my oj bi translated">5.4.密集连接</h2><figure class="nh ni nj nk gt nl gh gi paragraph-image"><div class="gh gi os"><img src="../Images/b0fa6c2797fa4fa16613c7d98d444ee0.png" data-original-src="https://miro.medium.com/v2/resize:fit:1376/format:webp/1*MD10HvJCUo0L8ZYM_EIdQA.png"/></div><figcaption class="ns nt gj gh gi nu nv bd b be z dk translated"><strong class="bd mk">DBPN-L和D-DBPN-L在4倍和8倍放大下的比较。</strong></figcaption></figure><ul class=""><li id="8ec0" class="ll lm iq ki b kj kk km kn kp ln kt lo kx lp lb lq lr ls lt bi translated">在4倍放大时，密集网络D-DBPN-L在Set5和Set14上的增益分别比DBPN-L高0.13 dB和0.05 dB。</li><li id="73b9" class="ll lm iq ki b kj lu km lv kp lw kt lx kx ly lb lq lr ls lt bi translated">在8×上，差距更大。在Set5和Set14上，D-DBPN-L分别比DBPN-L高0.23 dB和0.19 dB。</li></ul></div><div class="ab cl mb mc hu md" role="separator"><span class="me bw bk mf mg mh"/><span class="me bw bk mf mg mh"/><span class="me bw bk mf mg"/></div><div class="ij ik il im in"><h1 id="dfd0" class="mi mj iq bd mk ml mm mn mo mp mq mr ms jw mt jx mu jz mv ka mw kc mx kd my mz bi translated"><strong class="ak"> 6。最先进的(SOTA)对比</strong></h1><figure class="nh ni nj nk gt nl gh gi paragraph-image"><div role="button" tabindex="0" class="nm nn di no bf np"><div class="gh gi ot"><img src="../Images/7a846817bb3d34339f30ead969ba9874.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*JHg6JZzsXZpMncM6LvKXvQ.png"/></div></div><figcaption class="ns nt gj gh gi nu nv bd b be z dk translated"><strong class="bd mk">比例因子为2倍、4倍和8倍的平均PSNR/SSIM</strong></figcaption></figure><ul class=""><li id="21d1" class="ll lm iq ki b kj kk km kn kp ln kt lo kx lp lb lq lr ls lt bi translated">评估了5个数据集:Set5、Set14、BSDS100、Urban100和Manga109。</li><li id="577c" class="ll lm iq ki b kj lu km lv kp lw kt lx kx ly lb lq lr ls lt bi translated"><strong class="ki ir">最终的网络，D-DBPN </strong>，使用<strong class="ki ir"> conv(3，256)然后conv(1，64)用于初始特征提取</strong>和<strong class="ki ir">T7= 7用于反投影阶段</strong>。在<strong class="ki ir">重建中，conv(3。3) </strong>使用。RGB颜色通道用于输入和输出图像。训练不到四天。</li><li id="730a" class="ll lm iq ki b kj lu km lv kp lw kt lx kx ly lb lq lr ls lt bi translated">如上图所示，<strong class="ki ir"> D-DBPN优于现有的方法，包括</strong><a class="ae kf" href="https://medium.com/coinmonks/review-srcnn-super-resolution-3cb3a4f67a7c?source=post_page---------------------------" rel="noopener"><strong class="ki ir">Sr CNN</strong></a><strong class="ki ir"/><a class="ae kf" href="https://towardsdatascience.com/review-fsrcnn-super-resolution-80ca2ee14da4?source=post_page---------------------------" rel="noopener" target="_blank"><strong class="ki ir">fsr CNN</strong></a><strong class="ki ir"/><a class="ae kf" href="https://towardsdatascience.com/review-vdsr-super-resolution-f8050d49362f?source=post_page---------------------------" rel="noopener" target="_blank"><strong class="ki ir">VDSR</strong></a><strong class="ki ir"/><a class="ae kf" href="https://towardsdatascience.com/review-lapsrn-ms-lapsrn-laplacian-pyramid-super-resolution-network-super-resolution-c5fe2b65f5e8?source=post_page---------------------------" rel="noopener" target="_blank"><strong class="ki ir">LapSRN</strong></a><strong class="ki ir">，在除</strong> <a class="ae kf" href="https://medium.com/@sh.tsang/review-edsr-mdsr-enhanced-deep-residual-networks-for-single-image-super-resolution-super-4364f3b7f86f" rel="noopener">外的所有量表中大幅领先</a></li><li id="8bc2" class="ll lm iq ki b kj lu km lv kp lw kt lx kx ly lb lq lr ls lt bi translated">对于2倍和4倍放大，用<a class="ae kf" href="https://medium.com/@sh.tsang/review-edsr-mdsr-enhanced-deep-residual-networks-for-single-image-super-resolution-super-4364f3b7f86f" rel="noopener"> EDSR </a>获得可比的PSNR。然而，<a class="ae kf" href="https://medium.com/@sh.tsang/review-edsr-mdsr-enhanced-deep-residual-networks-for-single-image-super-resolution-super-4364f3b7f86f" rel="noopener"> EDSR </a>的结果倾向于产生比地面真实更强的边缘，并导致误导信息。</li><li id="2dfe" class="ll lm iq ki b kj lu km lv kp lw kt lx kx ly lb lq lr ls lt bi translated">在2倍放大的Urban100中，<a class="ae kf" href="https://medium.com/@sh.tsang/review-edsr-mdsr-enhanced-deep-residual-networks-for-single-image-super-resolution-super-4364f3b7f86f" rel="noopener"> EDSR </a>比D-DBPN高0.54 dB。</li><li id="30f7" class="ll lm iq ki b kj lu km lv kp lw kt lx kx ly lb lq lr ls lt bi translated">但是D-DBPN在<strong class="ki ir"> 8倍放大</strong>中显示了它的有效性。D-DBPN大大超过了所有现有的方法。</li><li id="4828" class="ll lm iq ki b kj lu km lv kp lw kt lx kx ly lb lq lr ls lt bi translated">有趣的结果显示在Manga109数据集上，其中D-DBPN获得25.50 dB，比<a class="ae kf" href="https://medium.com/@sh.tsang/review-edsr-mdsr-enhanced-deep-residual-networks-for-single-image-super-resolution-super-4364f3b7f86f" rel="noopener"> EDSR </a>好0.61 dB。</li><li id="467a" class="ll lm iq ki b kj lu km lv kp lw kt lx kx ly lb lq lr ls lt bi translated">而在Urban100数据集上，D-DBPN达到了23.25 dB，仅比<a class="ae kf" href="https://medium.com/@sh.tsang/review-edsr-mdsr-enhanced-deep-residual-networks-for-single-image-super-resolution-super-4364f3b7f86f" rel="noopener"> EDSR </a>好0.13 dB。</li></ul><figure class="nh ni nj nk gt nl gh gi paragraph-image"><div role="button" tabindex="0" class="nm nn di no bf np"><div class="gh gi ou"><img src="../Images/36002eb89244244199c43b19c7adbadc.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*sTZzqZZxtj0IZ-xKJkFkUg.png"/></div></div><figcaption class="ns nt gj gh gi nu nv bd b be z dk translated"><strong class="bd mk">我们的模型与其他作品在4倍超分辨率上的定性比较</strong></figcaption></figure><ul class=""><li id="0f99" class="ll lm iq ki b kj kk km kn kp ln kt lo kx lp lb lq lr ls lt bi translated">上图中睫毛的<strong class="ki ir"/><a class="ae kf" href="https://medium.com/@sh.tsang/review-edsr-mdsr-enhanced-deep-residual-networks-for-single-image-super-resolution-super-4364f3b7f86f" rel="noopener"><strong class="ki ir">EDSR</strong></a><strong class="ki ir">结果显示其被解释为<strong class="ki ir">条纹图案</strong>。另一方面，<strong class="ki ir"> D-DBPN的结果生成了更柔和的模式</strong>，主观上更接近地面真实。</strong></li><li id="29a3" class="ll lm iq ki b kj lu km lv kp lw kt lx kx ly lb lq lr ls lt bi translated">在<strong class="ki ir">蝴蝶</strong>图像上，<a class="ae kf" href="https://medium.com/@sh.tsang/review-edsr-mdsr-enhanced-deep-residual-networks-for-single-image-super-resolution-super-4364f3b7f86f" rel="noopener"> <strong class="ki ir"> EDSR </strong> </a> <strong class="ki ir">分离出白色图案</strong>表明<a class="ae kf" href="https://medium.com/@sh.tsang/review-edsr-mdsr-enhanced-deep-residual-networks-for-single-image-super-resolution-super-4364f3b7f86f" rel="noopener"> <strong class="ki ir"> EDSR </strong> </a> <strong class="ki ir">倾向于构造圆形、条纹等规则图案</strong>，而<strong class="ki ir"> D-DBPN构造的图案与地面真实</strong>相同。</li></ul><figure class="nh ni nj nk gt nl gh gi paragraph-image"><div role="button" tabindex="0" class="nm nn di no bf np"><div class="gh gi ov"><img src="../Images/33174159625f69be22e354caa38bdbd0.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*oFNoIItSKhhTGoaMeYuH0Q.png"/></div></div><figcaption class="ns nt gj gh gi nu nv bd b be z dk translated"><strong class="bd mk">我们的模型与其他作品在8倍超分辨率上的定性比较</strong></figcaption></figure><ul class=""><li id="3f2a" class="ll lm iq ki b kj kk km kn kp ln kt lo kx lp lb lq lr ls lt bi translated">从质量上来说，D-DBPN能够比其他网络更好地保留人力资源部分。</li><li id="6c52" class="ll lm iq ki b kj lu km lv kp lw kt lx kx ly lb lq lr ls lt bi translated">它表明<strong class="ki ir"> D-DBPN不仅可以从LR输入中提取特征，还可以创建上下文信息，以在大比例因子</strong>的情况下生成HR分量，例如8 <strong class="ki ir"> × </strong>放大。</li></ul></div><div class="ab cl mb mc hu md" role="separator"><span class="me bw bk mf mg mh"/><span class="me bw bk mf mg mh"/><span class="me bw bk mf mg"/></div><div class="ij ik il im in"><blockquote class="ow ox oy"><p id="99b6" class="kg kh ok ki b kj kk jr kl km kn ju ko oz kq kr ks pa ku kv kw pb ky kz la lb ij bi translated">在冠状病毒肆虐的日子里，给我一个挑战，这个月再写30个故事..？好吃吗？这是这个月的第六个故事了。感谢访问我的故事..</p></blockquote></div><div class="ab cl mb mc hu md" role="separator"><span class="me bw bk mf mg mh"/><span class="me bw bk mf mg mh"/><span class="me bw bk mf mg"/></div><div class="ij ik il im in"><h2 id="26da" class="ny mj iq bd mk nz oa dn mo ob oc dp ms kp od oe mu kt of og mw kx oh oi my oj bi translated">参考</h2><p id="8941" class="pw-post-body-paragraph kg kh iq ki b kj na jr kl km nb ju ko kp pc kr ks kt pd kv kw kx pe kz la lb ij bi translated">【2018 CVPR】【DBPN &amp; D-DBPN】<br/><a class="ae kf" href="https://arxiv.org/abs/1803.02735" rel="noopener ugc nofollow" target="_blank">用于超分辨率的深度反投影网络</a></p><h2 id="c076" class="ny mj iq bd mk nz oa dn mo ob oc dp ms kp od oe mu kt of og mw kx oh oi my oj bi translated">超分辨率</h2><p id="109a" class="pw-post-body-paragraph kg kh iq ki b kj na jr kl km nb ju ko kp pc kr ks kt pd kv kw kx pe kz la lb ij bi translated">)(我)(们)(都)(不)(想)(要)(让)(这)(些)(人)(都)(有)(这)(些)(的)(情)(况)(,)(我)(们)(都)(不)(想)(会)(有)(什)(么)(情)(况)(,)(我)(们)(都)(不)(想)(会)(有)(什)(么)(情)(况)(,)(我)(们)(还)(没)(有)(什)(么)(情)(况)(,)(我)(们)(还)(有)(什)(么)(情)(况)(,)(我)(们)(还)(没)(有)(什)(么)(好)(的)(情)(感)(。 )(我)(们)(都)(不)(知)(道)(,)(我)(们)(还)(不)(知)(道)(,)(我)(们)(还)(有)(些)(不)(知)(道)(的)(情)(况)(,)(我)(们)(还)(不)(知)(道)(,)(我)(们)(还)(是)(不)(知)(道)(,)(我)(们)(还)(是)(不)(知)(道)(,)(我)(们)(还)(不)(知)(道)(。</p><h2 id="b596" class="ny mj iq bd mk nz oa dn mo ob oc dp ms kp od oe mu kt of og mw kx oh oi my oj bi translated"><a class="ae kf" href="https://medium.com/@sh.tsang/overview-my-reviewed-paper-lists-tutorials-946ce59fbf9e" rel="noopener">我之前的其他评论</a></h2></div><div class="ab cl mb mc hu md" role="separator"><span class="me bw bk mf mg mh"/><span class="me bw bk mf mg mh"/><span class="me bw bk mf mg"/></div><div class="ij ik il im in"><p id="56bd" class="pw-post-body-paragraph kg kh iq ki b kj kk jr kl km kn ju ko kp kq kr ks kt ku kv kw kx ky kz la lb ij bi translated">由<a class="ae kf" href="https://towardsai.net/" rel="noopener ugc nofollow" target="_blank">向艾</a>发布</p></div></div>    
</body>
</html>