<html>
<head>
<title>The NLP Cypher | 02.28.21</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">NLP密码| 02.28.21</h1>
<blockquote>原文：<a href="https://pub.towardsai.net/the-nlp-cypher-02-28-21-59fc297a1b62?source=collection_archive---------2-----------------------#2021-03-01">https://pub.towardsai.net/the-nlp-cypher-02-28-21-59fc297a1b62?source=collection_archive---------2-----------------------#2021-03-01</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><figure class="ip iq gp gr ir is gh gi paragraph-image"><div class="gh gi io"><img src="../Images/232135d0928d1c46e8544f5e70e3022a.png" data-original-src="https://miro.medium.com/v2/resize:fit:886/format:webp/0*iUQPxi9bPgxILQh8.jpg"/></div><figcaption class="iv iw gj gh gi ix iy bd b be z dk translated">人类状况|马格里特</figcaption></figure><h2 id="91cb" class="iz ja jb bd b dl jc jd je jf jg jh dk ji translated" aria-label="kicker paragraph">自然语言处理每周时事通讯</h2><div class=""/><div class=""><h2 id="e1cf" class="pw-subtitle-paragraph kh jk jb bd b ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky dk translated">零距离射击</h2></div></div><div class="ab cl kz la hu lb" role="separator"><span class="lc bw bk ld le lf"/><span class="lc bw bk ld le lf"/><span class="lc bw bk ld le"/></div><div class="ij ik il im in"><p id="4780" class="pw-post-body-paragraph lg lh jb li b lj lk kl ll lm ln ko lo lp lq lr ls lt lu lv lw lx ly lz ma mb ij bi translated">嘿欢迎回来！这周有很多要谈的。但首先要做一些简单的家务。我们将在接下来的一周更新超级骗子NLP回购…终于😁。如果你有一个很棒的NLP笔记本要添加，请在我们的<a class="ae mc" href="https://quantumstat.com/contact/" rel="noopener ugc nofollow" target="_blank">联系页面</a>给我们留言，我们会在我们的更新推特上给你一个大喊。… 🚀</p></div><div class="ab cl kz la hu lb" role="separator"><span class="lc bw bk ld le lf"/><span class="lc bw bk ld le lf"/><span class="lc bw bk ld le"/></div><div class="ij ik il im in"><p id="350f" class="pw-post-body-paragraph lg lh jb li b lj lk kl ll lm ln ko lo lp lq lr ls lt lu lv lw lx ly lz ma mb ij bi translated">好的，如果你有一辆起亚汽车，请阅读这个…👇</p><figure class="me mf mg mh gt is gh gi paragraph-image"><div role="button" tabindex="0" class="mi mj di mk bf ml"><div class="gh gi md"><img src="../Images/68480d7e9315f8993b07512b0483578f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*pBfUp-CnVv-d0fO1.jpg"/></div></div></figure><p id="dff6" class="pw-post-body-paragraph lg lh jb li b lj lk kl ll lm ln ko lo lp lq lr ls lt lu lv lw lx ly lz ma mb ij bi translated">起亚显然在本月早些时候被勒索软件黑了，演员们希望得到全额报酬。他们在BTC要价整整2100万美元。起亚否认了它曾被黑客攻击的指控，尽管他们最近遭遇了网络中断。</p><p id="010b" class="pw-post-body-paragraph lg lh jb li b lj lk kl ll lm ln ko lo lp lq lr ls lt lu lv lw lx ly lz ma mb ij bi translated">在这里阅读更多<a class="ae mc" href="https://www.thedrive.com/tech/39309/the-apparent-hackers-behind-kias-ransomware-attack-are-demanding-millions-in-bitcoin" rel="noopener ugc nofollow" target="_blank"/>。</p><h2 id="acfb" class="mm mn jb bd mo mp mq dn mr ms mt dp mu lp mv mw mx lt my mz na lx nb nc nd jh bi translated">黑客攻击的后果👀</h2><blockquote class="ne nf ng"><p id="5ae3" class="lg lh nh li b lj lk kl ll lm ln ko lo ni lq lr ls nj lu lv lw nk ly lz ma mb ij bi translated">“起亚的关键联网服务仍然处于离线状态，这意味着客户无法使用起亚的基础设施支付汽车贷款、远程启动车辆或其他功能。”——驾驶博客</p></blockquote><h1 id="6ce7" class="nl mn jb bd mo nm nn no mr np nq nr mu kq ns kr mx kt nt ku na kw nu kx nd nv bi translated">一个伪DALL-E从灰烬中出现</h1><p id="c6ed" class="pw-post-body-paragraph lg lh jb li b lj nw kl ll lm nx ko lo lp ny lr ls lt nz lv lw lx oa lz ma mb ij bi translated">OpenAI在本周以先发制人的方式发布了DALL-E项目，发布了该模型的“部分”。他们发布了图像重建*部分* d-VAE。实际的编码器语言模型仍然不在口袋里，没有它，我们实际上无法实现他们在论文中演示的内容。</p><div class="ip iq gp gr ir ob"><a href="https://github.com/openai/DALL-E" rel="noopener  ugc nofollow" target="_blank"><div class="oc ab fo"><div class="od ab oe cl cj of"><h2 class="bd jl gy z fp og fr fs oh fu fw jk bi translated">openai/DALL-E</h2><div class="oi l"><h3 class="bd b gy z fp og fr fs oh fu fw dk translated">用于DALL E-open ai/DALL-E的分立PyTorch包</h3></div><div class="oj l"><p class="bd b dl z fp og fr fs oh fu fw dk translated">github.com</p></div></div><div class="ok l"><div class="ol l om on oo ok op it ob"/></div></div></a></div><h1 id="f917" class="nl mn jb bd mo nm nn no mr np nq nr mu kq ns kr mx kt nt ku na kw nu kx nd nv bi translated">OpenAI的剪辑实现:</h1><p id="f7a7" class="pw-post-body-paragraph lg lh jb li b lj nw kl ll lm nx ko lo lp ny lr ls lt nz lv lw lx oa lz ma mb ij bi translated">如果你仍然对OpenAI的剪辑感兴趣，我们在Reddit上找到了一个YUUUGE列表，突出显示了一吨运行该模型的Colab/Jupyter笔记本！！🔥🔥</p><p id="b3f6" class="pw-post-body-paragraph lg lh jb li b lj lk kl ll lm ln ko lo lp lq lr ls lt lu lv lw lx ly lz ma mb ij bi translated"><strong class="li jl"> ⚠ <em class="nh">警告列表的长度可能会影响您的判断，我们建议您在阅读时避免驾驶或操作重型机械。</em> ⚠ </strong></p><ol class=""><li id="0504" class="oq or jb li b lj lk lm ln lp os lt ot lx ou mb ov ow ox oy bi translated"><a class="ae mc" href="https://colab.research.google.com/drive/1NCceX2mbiKOSlAd_o7IU7nA9UskKN5WR?usp=sharing" rel="noopener ugc nofollow" target="_blank">The bigganxclip . ipynb—advad noun的合作研究</a>。使用BigGAN生成图像。据我所知，这是第一个发布的剪辑控制的BigGAN应用程序。<a class="ae mc" href="https://www.reddit.com/r/MachineLearning/comments/kzr4mg/p_the_big_sleep_texttoimage_generation_using/" rel="noopener ugc nofollow" target="_blank">说明和示例</a>。<a class="ae mc" href="https://colab.research.google.com/github/levindabhi/CLIP-Notebooks/blob/main/The_Big_Sleep_BigGANxCLIP.ipynb" rel="noopener ugc nofollow" target="_blank">levindabhi的笔记本文案</a>。</li><li id="252d" class="oq or jb li b lj oz lm pa lp pb lt pc lx pd mb ov ow ox oy bi translated">(2021年2月15日添加)<a class="ae mc" href="https://colab.research.google.com/drive/1yFzzffr1wo_DAQ3pmjmN_hmN2ympM2E-?usp=sharing" rel="noopener ugc nofollow" target="_blank">驱动集成大睡眠:bigganxclip . ipynb—advad noun合作实验室</a>。使用BigGAN生成图像。</li><li id="b1b9" class="oq or jb li b lj oz lm pa lp pb lt pc lx pd mb ov ow ox oy bi translated"><a class="ae mc" href="https://colab.research.google.com/drive/1MEWKbm-driRNF8PrU7ogS5o3se-ePyPb?usp=sharing" rel="noopener ugc nofollow" target="_blank">大睡眠lucidrains的合作实验室</a>。使用BigGAN生成图像。GitHub repo有一个本地机器版本。<a class="ae mc" href="https://github.com/lucidrains/big-sleep" rel="noopener ugc nofollow" target="_blank"> GitHub </a>。</li><li id="f409" class="oq or jb li b lj oz lm pa lp pb lt pc lx pd mb ov ow ox oy bi translated"><a class="ae mc" href="https://colab.research.google.com/drive/1Q2DIeMqYm_Sc5mlurnnurMMVqlgXpZNO?usp=sharing" rel="noopener ugc nofollow" target="_blank">大睡眠定制NMKD public . ipynb—NMKD合作实验室</a>。使用BigGAN生成图像。允许在一次运行中生成多个样本。</li><li id="a0e1" class="oq or jb li b lj oz lm pa lp pb lt pc lx pd mb ov ow ox oy bi translated"><a class="ae mc" href="https://colab.research.google.com/github/tg-bomze/collection-of-notebooks/blob/master/Text2Image.ipynb" rel="noopener ugc nofollow" target="_blank">文本2图像tg _ bomze的合作实验室</a>。使用BigGAN生成图像。<a class="ae mc" href="https://github.com/tg-bomze/collection-of-notebooks" rel="noopener ugc nofollow" target="_blank"> GitHub </a>。</li><li id="af5a" class="oq or jb li b lj oz lm pa lp pb lt pc lx pd mb ov ow ox oy bi translated"><a class="ae mc" href="https://colab.research.google.com/github/tg-bomze/collection-of-notebooks/blob/master/Text2Image_v2.ipynb" rel="noopener ugc nofollow" target="_blank">text 2 image _ v2—TG _ BOM ze的合作实验室</a>。使用BigGAN生成图像。<a class="ae mc" href="https://github.com/tg-bomze/collection-of-notebooks" rel="noopener ugc nofollow" target="_blank"> GitHub </a>。</li><li id="da7b" class="oq or jb li b lj oz lm pa lp pb lt pc lx pd mb ov ow ox oy bi translated"><a class="ae mc" href="https://colab.research.google.com/github/tg-bomze/collection-of-notebooks/blob/master/Text2Image_v3.ipynb" rel="noopener ugc nofollow" target="_blank">text 2 image _ v3—TG _ BOM ze的合作实验室</a>。使用BigGAN(默认)或Sigmoid生成图像。<a class="ae mc" href="https://github.com/tg-bomze/collection-of-notebooks" rel="noopener ugc nofollow" target="_blank"> GitHub </a>。</li><li id="af98" class="oq or jb li b lj oz lm pa lp pb lt pc lx pd mb ov ow ox oy bi translated">(添加于2021年2月26日)<a class="ae mc" href="https://colab.research.google.com/drive/1vOjrWwOh8E-EZXhOLpVm7Aw0m1i-fj8C?usp=sharing" rel="noopener ugc nofollow" target="_blank">图像引导大睡眠public . ipynb——JD ude _合作实验室</a>。使用BigGAN生成图像。<a class="ae mc" href="https://www.reddit.com/r/deepdream/comments/lsylr1/image_guided_bigsleep_notebook/" rel="noopener ugc nofollow" target="_blank"> Reddit帖子</a>。</li><li id="222c" class="oq or jb li b lj oz lm pa lp pb lt pc lx pd mb ov ow ox oy bi translated"><a class="ae mc" href="https://colab.research.google.com/github/eyaler/clip_biggan/blob/main/ClipBigGAN.ipynb" rel="noopener ugc nofollow" target="_blank">clipbiggan . ipynb—eyaler的合作实验室</a>。使用BigGAN生成图像/视频。<a class="ae mc" href="https://github.com/eyaler/clip_biggan" rel="noopener ugc nofollow" target="_blank"> GitHub </a>。<a class="ae mc" href="https://colab.research.google.com/github/levindabhi/CLIP-Notebooks/blob/main/ClipBigGAN.ipynb" rel="noopener ugc nofollow" target="_blank">笔记簿副本</a>由levindabhi制作。</li><li id="d741" class="oq or jb li b lj oz lm pa lp pb lt pc lx pd mb ov ow ox oy bi translated"><a class="ae mc" href="https://colab.research.google.com/github/eyaler/clip_biggan/blob/main/WanderCLIP.ipynb" rel="noopener ugc nofollow" target="_blank">wander clip . ipynb—eyaler的合作实验室</a>。使用BigGAN(默认)或Sigmoid生成图像/视频。<a class="ae mc" href="https://github.com/eyaler/clip_biggan" rel="noopener ugc nofollow" target="_blank"> GitHub </a>。</li><li id="ea08" class="oq or jb li b lj oz lm pa lp pb lt pc lx pd mb ov ow ox oy bi translated"><a class="ae mc" href="https://colab.research.google.com/drive/1yNkvkrHApFR6alyFC1EzhPGHs86yjH1P?usp=sharing" rel="noopener ugc nofollow" target="_blank">story 2 dipship . ipynb—邦克菲尔德合作</a>。使用BigGAN生成图像/视频。<a class="ae mc" href="https://github.com/lots-of-things/Story2Hallucination" rel="noopener ugc nofollow" target="_blank"> GitHub </a>。</li><li id="03e6" class="oq or jb li b lj oz lm pa lp pb lt pc lx pd mb ov ow ox oy bi translated">(2021年2月7日左右添加)<a class="ae mc" href="https://colab.research.google.com/github/lots-of-things/Story2Hallucination/blob/main/Story2Hallucination_GIF.ipynb" rel="noopener ugc nofollow" target="_blank">story 2幻觉_GIF.ipynb —邦克菲尔德合作</a>。使用BigGAN生成图像。<a class="ae mc" href="https://github.com/lots-of-things/Story2Hallucination" rel="noopener ugc nofollow" target="_blank"> GitHub </a>。</li><li id="80e0" class="oq or jb li b lj oz lm pa lp pb lt pc lx pd mb ov ow ox oy bi translated">(2021年2月24日增加)<a class="ae mc" href="https://colab.research.google.com/github/styler00dollar/Colab-BigGANxCLIP/blob/main/Colab-BigGANxCLIP.ipynb" rel="noopener ugc nofollow" target="_blank">cola b-bigganxclip . ipynb—styler 00 dollar的合作实验室</a>。使用BigGAN生成图像。“只是那个[advad noun]笔记本的一个更压缩/更小的版本”。GitHub 。</li><li id="216b" class="oq or jb li b lj oz lm pa lp pb lt pc lx pd mb ov ow ox oy bi translated"><a class="ae mc" href="https://colab.research.google.com/drive/1fWka_U56NhCegbbrQPt4PWpHPtNRdU49?usp=sharing" rel="noopener ugc nofollow" target="_blank">CLIP-glass . ipynb—gala tolo的合作实验室</a>。使用BigGAN(默认)或StyleGAN生成图像。GPT2配置用于图像到文本，而不是文本到图像。<a class="ae mc" href="https://github.com/galatolofederico/clip-glass" rel="noopener ugc nofollow" target="_blank"> GitHub </a>。</li><li id="4022" class="oq or jb li b lj oz lm pa lp pb lt pc lx pd mb ov ow ox oy bi translated">(2021年2月15日补充)<a class="ae mc" href="https://dank.xyz/" rel="noopener ugc nofollow" target="_blank"> dank.xyz </a>。使用BigGAN或StyleGAN生成图像。一个易于使用的网站，用于访问大睡眠和剪辑玻璃。据我所知，这个网站并不隶属于大睡眠或剪辑玻璃的开发商。<a class="ae mc" href="https://www.reddit.com/r/MediaSynthesis/comments/l8xlr8/big_sleep_a_lightsaber_in_the_jungle/glh5nxl/" rel="noopener ugc nofollow" target="_blank"> Reddit参考</a>。</li><li id="bd71" class="oq or jb li b lj oz lm pa lp pb lt pc lx pd mb ov ow ox oy bi translated">(2021年2月25日补充)<a class="ae mc" href="https://colab.research.google.com/drive/1Q-TbYvASMPRMXCOQjkxxf72CXYjR_8Vp?usp=sharing" rel="noopener ugc nofollow" target="_blank">Aleph-Image:CLIPxDAll-e . ipynb—advad noun的合作实验室</a>。使用DALL-E的离散VAE(变分自动编码器)组件生成图像。<a class="ae mc" href="https://twitter.com/advadnoun/status/1364822183751471109" rel="noopener ugc nofollow" target="_blank">推特参考</a>。<a class="ae mc" href="https://www.reddit.com/r/MachineLearning/comments/ls0e0f/p_texttoimage_google_colab_notebook_alephimage/" rel="noopener ugc nofollow" target="_blank"> Reddit帖子</a>。</li><li id="8118" class="oq or jb li b lj oz lm pa lp pb lt pc lx pd mb ov ow ox oy bi translated">(2021年2月26日补充)<a class="ae mc" href="https://colab.research.google.com/drive/1oA1fZP7N1uPBxwbGIvOEXbTsq2ORa9vb?usp=sharing" rel="noopener ugc nofollow" target="_blank">aleph 2 image(delta):CLIP+DALL-E decoder . ipynb—advad noun的Colaboratory </a>。使用DALL-E的离散VAE(变分自动编码器)组件生成图像。<a class="ae mc" href="https://twitter.com/advadnoun/status/1365439793602064391" rel="noopener ugc nofollow" target="_blank">推特参考</a>。<a class="ae mc" href="https://www.reddit.com/r/deepdream/comments/ltcqdh/new_google_colab_notebook_texttoimage_for_text_a/" rel="noopener ugc nofollow" target="_blank"> Reddit帖子</a>。</li><li id="54d3" class="oq or jb li b lj oz lm pa lp pb lt pc lx pd mb ov ow ox oy bi translated">(2021年2月27日增加)<a class="ae mc" href="https://colab.research.google.com/drive/1VAO22MNQekkrVq8ey2pCRznz4A0_jY29?usp=sharing" rel="noopener ugc nofollow" target="_blank">advad noun的gamma aleph 2 img . ipynb-合作实验室</a>的工作wow good副本。使用DALL-E的离散VAE(变分自动编码器)组件生成图像。<a class="ae mc" href="https://twitter.com/advadnoun/status/1365786025277018115" rel="noopener ugc nofollow" target="_blank">推特参考</a>。</li><li id="2d33" class="oq or jb li b lj oz lm pa lp pb lt pc lx pd mb ov ow ox oy bi translated">(添加于2021年2月27日)<a class="ae mc" href="https://colab.research.google.com/drive/1Fb7qTCumPvzSLp_2GMww4OV5BZdE-vKJ?usp=sharing" rel="noopener ugc nofollow" target="_blank"> Aleph-Image: CLIPxDAll-E(带有白色斑点修复# 2)——托马斯的合作实验室</a>。使用DALL-E的离散VAE(变分自动编码器)组件生成图像。在advadnoun的“Aleph-Image: CLIPxDAll-E”笔记本上应用这里提到的<a class="ae mc" href="https://twitter.com/NJetchev/status/1365435397506007043" rel="noopener ugc nofollow" target="_blank">的白色斑点修复</a>。</li><li id="659b" class="oq or jb li b lj oz lm pa lp pb lt pc lx pd mb ov ow ox oy bi translated">(2021年2月14日增加)<a class="ae mc" href="https://colab.research.google.com/drive/1ZSIVnriA5xf1umAegtbhtM0qzL3AT1rR?usp=sharing" rel="noopener ugc nofollow" target="_blank"> GA StyleGAN2 WikiArt CLIP实验-py torch-clean-pbay lies合作实验室</a>。使用StyleGAN生成图像。<a class="ae mc" href="https://twitter.com/pbaylies/status/1360792281498943490" rel="noopener ugc nofollow" target="_blank">更多信息</a>。</li><li id="ce21" class="oq or jb li b lj oz lm pa lp pb lt pc lx pd mb ov ow ox oy bi translated">(2021年2月15日增加)<a class="ae mc" href="https://colab.research.google.com/github/orpatashnik/StyleCLIP/blob/main/playground.ipynb" rel="noopener ugc nofollow" target="_blank">样式夹orpatashnik合作</a>。使用StyleGAN生成图像。<a class="ae mc" href="https://github.com/orpatashnik/StyleCLIP" rel="noopener ugc nofollow" target="_blank"> GitHub </a>。<a class="ae mc" href="https://twitter.com/OPatashnik/status/1361220550027325443" rel="noopener ugc nofollow" target="_blank">推特参考</a>。<a class="ae mc" href="https://www.reddit.com/r/MediaSynthesis/comments/ll5ann/edit_a_human_face_image_with_texttoimage_using/" rel="noopener ugc nofollow" target="_blank"> Reddit帖子</a>。</li><li id="5fac" class="oq or jb li b lj oz lm pa lp pb lt pc lx pd mb ov ow ox oy bi translated">(2021年2月15日添加)<a class="ae mc" href="https://github.com/vipermu/StyleCLIP" rel="noopener ugc nofollow" target="_blank">viper mu的StyleCLIP </a>。使用StyleGAN生成图像。</li><li id="f64a" class="oq or jb li b lj oz lm pa lp pb lt pc lx pd mb ov ow ox oy bi translated">(2021年2月24日添加)<a class="ae mc" href="https://colab.research.google.com/github/levindabhi/CLIP-Notebooks/blob/main/CLIP_StyleGAN.ipynb" rel="noopener ugc nofollow" target="_blank">CLIP _ style gan . ipynb—levindabhi的合作实验室</a>。使用StyleGAN生成图像。</li><li id="cfb1" class="oq or jb li b lj oz lm pa lp pb lt pc lx pd mb ov ow ox oy bi translated">(2021年2月23日增加)<a class="ae mc" href="https://colab.research.google.com/github/weihaox/TediGAN/blob/main/playground.ipynb" rel="noopener ugc nofollow" target="_blank">tedi gan—Wei haox合作实验室</a>。使用StyleGAN生成图像。<a class="ae mc" href="https://github.com/weihaox/TediGAN" rel="noopener ugc nofollow" target="_blank"> GitHub </a>。我得到错误“没有为感知模型找到预先训练的权重！”当我使用Colab笔记本时，它在我做出这里提到的<a class="ae mc" href="https://github.com/weihaox/TediGAN/issues/3" rel="noopener ugc nofollow" target="_blank"/>的改变时被修复。更改之后，我仍然在显示图像的单元格中得到一个错误，但是结果是在远程文件系统中。使用左侧的“文件”图标浏览远程文件系统。</li><li id="278a" class="oq or jb li b lj oz lm pa lp pb lt pc lx pd mb ov ow ox oy bi translated"><a class="ae mc" href="https://colab.research.google.com/github/nagolinc/notebooks/blob/main/TADNE_and_CLIP.ipynb" rel="noopener ugc nofollow" target="_blank"> TADNE和CLIP——nago Linc的合作实验室</a>。使用TADNE(“此动漫不存在”)生成图像。<a class="ae mc" href="https://github.com/nagolinc/notebooks" rel="noopener ugc nofollow" target="_blank"> GitHub </a>。</li><li id="4a67" class="oq or jb li b lj oz lm pa lp pb lt pc lx pd mb ov ow ox oy bi translated"><a class="ae mc" href="https://colab.research.google.com/github/nagolinc/notebooks/blob/main/CLIP_%2B_TADNE_(pytorch)_v2.ipynb" rel="noopener ugc nofollow" target="_blank">CLIP+TADNE(py torch)v2——nago Linc合作实验室</a>。使用TADNE(“此动漫不存在”)生成图像。<a class="ae mc" href="https://www.reddit.com/r/MediaSynthesis/comments/l9lbfy/instructions_for_using_free_animecentric_google/" rel="noopener ugc nofollow" target="_blank">说明和例子</a>。<a class="ae mc" href="https://github.com/nagolinc/notebooks" rel="noopener ugc nofollow" target="_blank"> GitHub </a>。levindabhi的笔记本副本</li><li id="376f" class="oq or jb li b lj oz lm pa lp pb lt pc lx pd mb ov ow ox oy bi translated">(2021年2月24日增加)<a class="ae mc" href="https://github.com/cloneofsimo/clipping-CLIP-to-GAN" rel="noopener ugc nofollow" target="_blank">cloneofsimo的CLIP-CLIP-to-GAN</a>。使用FastGAN生成图像。</li><li id="e773" class="oq or jb li b lj oz lm pa lp pb lt pc lx pd mb ov ow ox oy bi translated"><a class="ae mc" href="https://colab.research.google.com/drive/1FoHdqoqKntliaQKnMoNs3yn5EALqWtvP?usp=sharing" rel="noopener ugc nofollow" target="_blank">剪辑&amp;文本到图像的渐变上升(深度发呆？).ipynb—advad noun的合作实验室</a>。使用警报器生成图像。据我所知，这是第一个使用CLIP创建图像的应用程序。<a class="ae mc" href="https://www.reddit.com/r/MachineLearning/comments/ky8fq8/p_a_colab_notebook_from_ryan_murdock_that_creates/" rel="noopener ugc nofollow" target="_blank">说明和示例</a>。<a class="ae mc" href="https://colab.research.google.com/github/levindabhi/CLIP-Notebooks/blob/main/CLIP_%26_gradient_ascent_for_text_to_image_(Deep_Daze%20).ipynb" rel="noopener ugc nofollow" target="_blank">levindabhi的笔记本文案</a>。</li><li id="469b" class="oq or jb li b lj oz lm pa lp pb lt pc lx pd mb ov ow ox oy bi translated"><a class="ae mc" href="https://colab.research.google.com/drive/1_YOHdORb0Fg1Q7vWZ_KlrtFe9Ur3pmVj?usp=sharing" rel="noopener ugc nofollow" target="_blank">Deep Daze—luci drains的合作实验室</a>。使用警报器生成图像。GitHub repo有一个本地机器版本。<a class="ae mc" href="https://github.com/lucidrains/deep-daze" rel="noopener ugc nofollow" target="_blank"> GitHub </a>。levindabhi的笔记本副本。</li><li id="78dc" class="oq or jb li b lj oz lm pa lp pb lt pc lx pd mb ov ow ox oy bi translated"><a class="ae mc" href="https://colab.research.google.com/drive/1K1vfpTEvAmxW2rnhAaALRVyis8EiLOnD?usp=sharing" rel="noopener ugc nofollow" target="_blank">CLIP-SIREN-with sample dl . ipynb-norod 78的合作实验室</a>。使用警报器生成图像。</li><li id="a964" class="oq or jb li b lj oz lm pa lp pb lt pc lx pd mb ov ow ox oy bi translated">(添加于2021年2月17日)<a class="ae mc" href="https://colab.research.google.com/drive/1L14q4To5rMK8q2E6whOibQBnPnVbRJ_7" rel="noopener ugc nofollow" target="_blank"> Text2Image Siren+。ipynb—EPS 696的合作实验室</a>。使用警报器生成图像。<a class="ae mc" href="https://twitter.com/eps696/status/1360973092722528256" rel="noopener ugc nofollow" target="_blank">推特参考</a>。<a class="ae mc" href="https://www.reddit.com/r/deepdream/comments/lm9evo/colab_notebook_text2image_siren_seems_to_be/" rel="noopener ugc nofollow" target="_blank">例#1 </a>。<a class="ae mc" href="https://www.reddit.com/r/deepdream/comments/lm3cg3/texttoimage_editing_of_an_existing_image_with/" rel="noopener ugc nofollow" target="_blank">例#2 </a>。<a class="ae mc" href="https://www.reddit.com/r/deepdream/comments/lm3t7z/texttoimage_generation_for_text_a_firebreathing/" rel="noopener ugc nofollow" target="_blank">例3 </a>。</li><li id="b975" class="oq or jb li b lj oz lm pa lp pb lt pc lx pd mb ov ow ox oy bi translated">(2021年2月24日增加)<a class="ae mc" href="https://colab.research.google.com/github/styler00dollar/Colab-deep-daze/blob/main/Colab-Deep-Daze.ipynb" rel="noopener ugc nofollow" target="_blank">cola b-deep-daze—styler 00 dollar合作实验室</a>。使用警报器生成图像。我没有得到这个笔记本工作，但你的结果可能会有所不同。<a class="ae mc" href="https://github.com/styler00dollar/Colab-deep-daze" rel="noopener ugc nofollow" target="_blank"> GitHub </a>。</li><li id="6af3" class="oq or jb li b lj oz lm pa lp pb lt pc lx pd mb ov ow ox oy bi translated">(2021年2月18日添加)<a class="ae mc" href="https://colab.research.google.com/drive/1rJMSyF_dmpL1kmse7Rm9TurjihJ_cA5t" rel="noopener ugc nofollow" target="_blank">text 2 image FFT . ipynb—EPS 696合作实验室</a>。使用Lucent/Lucid的FFT(快速傅立叶变换)生成图像。<a class="ae mc" href="https://twitter.com/eps696/status/1362262010763821056" rel="noopener ugc nofollow" target="_blank">推特参考</a>。<a class="ae mc" href="https://www.reddit.com/r/deepdream/comments/lmoa8y/new_texttoimagevideo_notebook_text2image_fft_from/" rel="noopener ugc nofollow" target="_blank">例#1 </a>。例2 。</li></ol><h1 id="4dd1" class="nl mn jb bd mo nm nn no mr np nq nr mu kq ns kr mx kt nt ku na kw nu kx nd nv bi translated">语言模型微调的最新进展</h1><p id="d7c6" class="pw-post-body-paragraph lg lh jb li b lj nw kl ll lm nx ko lo lp ny lr ls lt nz lv lw lx oa lz ma mb ij bi translated">Sebastian Ruder是NLP迁移学习的先驱之一，他在博客上发布了一篇关于微调最新进展的精彩文章。下面讨论五个类别。如果你接近NLP领域，这是必读书。</p><figure class="me mf mg mh gt is gh gi paragraph-image"><div role="button" tabindex="0" class="mi mj di mk bf ml"><div class="gh gi pe"><img src="../Images/edb413aceeaed6a0d5ef797f7612d392.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*1JKxAIm5xD41I-Yw.png"/></div></div><figcaption class="iv iw gj gh gi ix iy bd b be z dk translated">解密的</figcaption></figure><div class="ip iq gp gr ir ob"><a href="https://ruder.io/recent-advances-lm-fine-tuning/" rel="noopener  ugc nofollow" target="_blank"><div class="oc ab fo"><div class="od ab oe cl cj of"><h2 class="bd jl gy z fp og fr fs oh fu fw jk bi translated">语言模型微调的最新进展</h2><div class="oi l"><h3 class="bd b gy z fp og fr fs oh fu fw dk translated">微调预先训练的语言模型(LM)已经成为在自然语言环境中进行迁移学习的事实标准</h3></div><div class="oj l"><p class="bd b dl z fp og fr fs oh fu fw dk translated">ruder.io</p></div></div><div class="ok l"><div class="pf l om on oo ok op it ob"/></div></div></a></div><h1 id="a7c3" class="nl mn jb bd mo nm nn no mr np nq nr mu kq ns kr mx kt nt ku na kw nu kx nd nv bi translated">在图形中可视化社区结构</h1><blockquote class="ne nf ng"><p id="fa8b" class="lg lh nh li b lj lk kl ll lm ln ko lo ni lq lr ls nj lu lv lw nk ly lz ma mb ij bi translated">Communities是一个Python库，用于检测图形中的社区结构。它实现了以下算法:</p></blockquote><blockquote class="pg"><p id="25ab" class="ph pi jb bd pj pk pl pm pn po pp mb dk translated">卢万法</p><p id="24a9" class="ph pi jb bd pj pk pq pr ps pt pu mb dk translated">格文-纽曼算法</p><p id="32f9" class="ph pi jb bd pj pk pq pr ps pt pu mb dk translated">分层聚类</p><p id="9165" class="ph pi jb bd pj pk pq pr ps pt pu mb dk translated">谱聚类</p><p id="84c2" class="ph pi jb bd pj pk pq pr ps pt pu mb dk translated">布朗-克尔博施算法</p></blockquote><div class="pv pw px py pz ob"><a href="https://github.com/shobrook/communities" rel="noopener  ugc nofollow" target="_blank"><div class="oc ab fo"><div class="od ab oe cl cj of"><h2 class="bd jl gy z fp og fr fs oh fu fw jk bi translated">肖布鲁克/社区</h2><div class="oi l"><h3 class="bd b gy z fp og fr fs oh fu fw dk translated">communities是一个Python库，用于检测图形中的社区结构。它实现了以下算法…</h3></div><div class="oj l"><p class="bd b dl z fp og fr fs oh fu fw dk translated">github.com</p></div></div><div class="ok l"><div class="qa l om on oo ok op it ob"/></div></div></a></div><h1 id="dea7" class="nl mn jb bd mo nm nn no mr np nq nr mu kq ns kr mx kt nt ku na kw nu kx nd nv bi translated">溢出| Python统计数据</h1><p id="a618" class="pw-post-body-paragraph lg lh jb li b lj nw kl ll lm nx ko lo lp ny lr ls lt nz lv lw lx oa lz ma mb ij bi translated">Stack Overflow博客上的有用帖子讨论了Python库，如numpy、pandas、matplotlib和seaborn。页面上有一个YouTube视频，他们在其中探索了纽约市的住房数据集。这是入门水平。</p><div class="ip iq gp gr ir ob"><a href="https://stackoverflow.blog/2021/02/23/level-up-mastering-statistics-with-python-part-2/" rel="noopener  ugc nofollow" target="_blank"><div class="oc ab fo"><div class="od ab oe cl cj of"><h2 class="bd jl gy z fp og fr fs oh fu fw jk bi translated">升级:用Python掌握统计-第2部分-堆栈溢出博客</h2><div class="oi l"><h3 class="bd b gy z fp og fr fs oh fu fw dk translated">欢迎回来！这是我们升级系列的第二堂课。如果你只是在收听，你可以了解我们…</h3></div><div class="oj l"><p class="bd b dl z fp og fr fs oh fu fw dk translated">stackoverflow.blog</p></div></div><div class="ok l"><div class="qb l om on oo ok op it ob"/></div></div></a></div><h1 id="ed14" class="nl mn jb bd mo nm nn no mr np nq nr mu kq ns kr mx kt nt ku na kw nu kx nd nv bi translated">贝特维兹</h1><blockquote class="ne nf ng"><p id="1de9" class="lg lh nh li b lj lk kl ll lm ln ko lo ni lq lr ls nj lu lv lw nk ly lz ma mb ij bi translated">BertViz是一个在变形金刚模型中可视化注意力的工具，支持变形金刚库中的所有模型(伯特、GPT-2、XLNet、罗伯塔、XLM、CTRL等。)</p></blockquote><p id="aab9" class="pw-post-body-paragraph lg lh jb li b lj lk kl ll lm ln ko lo lp lq lr ls lt lu lv lw lx ly lz ma mb ij bi translated">包括了<a class="ae mc" href="https://colab.research.google.com/drive/1PEHWRHrvxQvYr9NFRC-E_fr3xDq1htCj" rel="noopener ugc nofollow" target="_blank"><strong class="li jl"/></a><strong class="li jl">😎</strong></p><figure class="me mf mg mh gt is gh gi paragraph-image"><div class="gh gi qc"><img src="../Images/c6450744e55368e56e3b1734045f1bde.png" data-original-src="https://miro.medium.com/v2/resize:fit:1132/0*gaa2g5hOttMSAvI1.gif"/></div></figure><div class="ip iq gp gr ir ob"><a href="https://github.com/jessevig/bertviz" rel="noopener  ugc nofollow" target="_blank"><div class="oc ab fo"><div class="od ab oe cl cj of"><h2 class="bd jl gy z fp og fr fs oh fu fw jk bi translated">杰塞维格/贝特维兹</h2><div class="oi l"><h3 class="bd b gy z fp og fr fs oh fu fw dk translated">BertViz是一个在变形金刚模型中可视化注意力的工具，支持变形金刚的所有模型…</h3></div><div class="oj l"><p class="bd b dl z fp og fr fs oh fu fw dk translated">github.com</p></div></div><div class="ok l"><div class="qd l om on oo ok op it ob"/></div></div></a></div><h1 id="3b30" class="nl mn jb bd mo nm nn no mr np nq nr mu kq ns kr mx kt nt ku na kw nu kx nd nv bi translated">情境化主题模型</h1><p id="909e" class="pw-post-body-paragraph lg lh jb li b lj nw kl ll lm nx ko lo lp ny lr ls lt nz lv lw lx oa lz ma mb ij bi translated">如果您对主题建模感兴趣，请查看这个非常棒的库。它们包括一个zeroshot跨语言变体和一个针对各种用例的单词包方法。</p><div class="ip iq gp gr ir ob"><a href="https://github.com/MilaNLProc/contextualized-topic-models" rel="noopener  ugc nofollow" target="_blank"><div class="oc ab fo"><div class="od ab oe cl cj of"><h2 class="bd jl gy z fp og fr fs oh fu fw jk bi translated">MilaNLProc/语境化主题模型</h2><div class="oi l"><h3 class="bd b gy z fp og fr fs oh fu fw dk translated">语境化主题模型(CTM)是一个主题模型家族，使用预先训练好的语言表示(例如…</h3></div><div class="oj l"><p class="bd b dl z fp og fr fs oh fu fw dk translated">github.com</p></div></div><div class="ok l"><div class="qe l om on oo ok op it ob"/></div></div></a></div><h1 id="2cb2" class="nl mn jb bd mo nm nn no mr np nq nr mu kq ns kr mx kt nt ku na kw nu kx nd nv bi translated">软件更新| PyTorch闪电</h1><figure class="me mf mg mh gt is gh gi paragraph-image"><div role="button" tabindex="0" class="mi mj di mk bf ml"><div class="gh gi qf"><img src="../Images/eee3a73a039032e0315f12cdb929381e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*hi3Lpv9TesgRhOJN.png"/></div></div></figure><p id="e380" class="pw-post-body-paragraph lg lh jb li b lj lk kl ll lm ln ko lo lp lq lr ls lt lu lv lw lx ly lz ma mb ij bi translated">新功能:</p><ul class=""><li id="9b3b" class="oq or jb li b lj lk lm ln lp os lt ot lx ou mb qg ow ox oy bi translated"><a class="ae mc" href="https://pytorch-lightning.readthedocs.io/en/stable/advanced/profiler.html" rel="noopener ugc nofollow" target="_blank"> PyTorch亲笔签名侧写器</a></li><li id="1334" class="oq or jb li b lj oz lm pa lp pb lt pc lx pd mb qg ow ox oy bi translated"><a class="ae mc" href="https://pytorch-lightning.readthedocs.io/en/stable/advanced/multi_gpu.html?highlight=deepspeed#deepspeed" rel="noopener ugc nofollow" target="_blank">深度速度</a>模型并行度</li><li id="3778" class="oq or jb li b lj oz lm pa lp pb lt pc lx pd mb qg ow ox oy bi translated"><a class="ae mc" href="https://pytorch-lightning.readthedocs.io/en/stable/advanced/pruning_quantization.html" rel="noopener ugc nofollow" target="_blank">修剪</a></li><li id="ef71" class="oq or jb li b lj oz lm pa lp pb lt pc lx pd mb qg ow ox oy bi translated"><a class="ae mc" href="https://pytorch-lightning.readthedocs.io/en/stable/advanced/pruning_quantization.html" rel="noopener ugc nofollow" target="_blank">量化</a></li><li id="622f" class="oq or jb li b lj oz lm pa lp pb lt pc lx pd mb qg ow ox oy bi translated"><a class="ae mc" href="https://pytorch-lightning.readthedocs.io/en/1.2.0/advanced/training_tricks.html#stochastic-weight-averaging" rel="noopener ugc nofollow" target="_blank">随机</a> <a class="ae mc" href="https://pytorch-lightning.readthedocs.io/en/1.2.0/advanced/training_tricks.html#stochastic-weight-averaging" rel="noopener ugc nofollow" target="_blank">权重</a> <a class="ae mc" href="https://pytorch-lightning.readthedocs.io/en/1.2.0/advanced/training_tricks.html#stochastic-weight-averaging" rel="noopener ugc nofollow" target="_blank">平均</a></li></ul><div class="ip iq gp gr ir ob"><a href="https://pytorch-lightning.medium.com/pytorch-lightning-v1-2-0-43a032ade82b" rel="noopener follow" target="_blank"><div class="oc ab fo"><div class="od ab oe cl cj of"><h2 class="bd jl gy z fp og fr fs oh fu fw jk bi translated">py torch Lightning 1 . 2 . 0版</h2><div class="oi l"><h3 class="bd b gy z fp og fr fs oh fu fw dk translated">包括与DeepSpeed、PyTorch profiler、修剪、量化、SWA、PyTorch Geometric等的新集成。</h3></div><div class="oj l"><p class="bd b dl z fp og fr fs oh fu fw dk translated">pytorch-lightning.medium.com</p></div></div><div class="ok l"><div class="qh l om on oo ok op it ob"/></div></div></a></div><h1 id="c3c6" class="nl mn jb bd mo nm nn no mr np nq nr mu kq ns kr mx kt nt ku na kw nu kx nd nv bi translated">软件更新|拥抱脸</h1><p id="ac69" class="pw-post-body-paragraph lg lh jb li b lj nw kl ll lm nx ko lo lp ny lr ls lt nz lv lw lx oa lz ma mb ij bi translated">HF的一个新库，用于修剪模型，在保持准确性的同时减少参数。他们的稀疏笔记本可以在<a class="ae mc" href="https://notebooks.quantumstat.com/" rel="noopener ugc nofollow" target="_blank">超级骗子NLP Repo </a>上找到。</p><div class="ip iq gp gr ir ob"><a href="https://github.com/huggingface/nn_pruning" rel="noopener  ugc nofollow" target="_blank"><div class="oc ab fo"><div class="od ab oe cl cj of"><h2 class="bd jl gy z fp og fr fs oh fu fw jk bi translated">huggingface/nn_pruning</h2><div class="oi l"><h3 class="bd b gy z fp og fr fs oh fu fw dk translated">这里有这个网站的互动版本。实践证明，这是一种非常有效的网络剪枝方法</h3></div><div class="oj l"><p class="bd b dl z fp og fr fs oh fu fw dk translated">github.com</p></div></div><div class="ok l"><div class="qi l om on oo ok op it ob"/></div></div></a></div><h1 id="e36d" class="nl mn jb bd mo nm nn no mr np nq nr mu kq ns kr mx kt nt ku na kw nu kx nd nv bi translated">回购密码👨‍💻</h1><h2 id="3da0" class="mm mn jb bd mo mp mq dn mr ms mt dp mu lp mv mw mx lt my mz na lx nb nc nd jh bi translated">一组最近发布的回购引起了我们的注意👁</h2></div><div class="ab cl kz la hu lb" role="separator"><span class="lc bw bk ld le lf"/><span class="lc bw bk ld le lf"/><span class="lc bw bk ld le"/></div><div class="ij ik il im in"><h2 id="6eb5" class="mm mn jb bd mo mp mq dn mr ms mt dp mu lp mv mw mx lt my mz na lx nb nc nd jh bi translated">少量学习</h2><blockquote class="ne nf ng"><p id="f185" class="lg lh nh li b lj lk kl ll lm ln ko lo ni lq lr ls nj lu lv lw nk ly lz ma mb ij bi translated">一个代码库，使用类似于GPT三号论文的语言模型来执行少量的“上下文”学习。</p></blockquote><div class="ip iq gp gr ir ob"><a href="https://github.com/tonyzhaozh/few-shot-learning" rel="noopener  ugc nofollow" target="_blank"><div class="oc ab fo"><div class="od ab oe cl cj of"><h2 class="bd jl gy z fp og fr fs oh fu fw jk bi translated">tonyzhaozh/少投学习</h2><div class="oi l"><h3 class="bd b gy z fp og fr fs oh fu fw dk translated">这是一个代码库，使用类似于GPT-3论文的语言模型来执行少量的“上下文”学习。在…</h3></div><div class="oj l"><p class="bd b dl z fp og fr fs oh fu fw dk translated">github.com</p></div></div><div class="ok l"><div class="qj l om on oo ok op it ob"/></div></div></a></div><p id="f842" class="pw-post-body-paragraph lg lh jb li b lj lk kl ll lm ln ko lo lp lq lr ls lt lu lv lw lx ly lz ma mb ij bi translated"><a class="ae mc" href="https://www.connectedpapers.com/main/1423a89c03de83ca8e27ed64916552f6a2969a7d/arxiv" rel="noopener ugc nofollow" target="_blank"> <strong class="li jl">连接论文</strong> </a> <strong class="li jl">📈</strong></p></div><div class="ab cl kz la hu lb" role="separator"><span class="lc bw bk ld le lf"/><span class="lc bw bk ld le lf"/><span class="lc bw bk ld le"/></div><div class="ij ik il im in"><h2 id="ee8a" class="mm mn jb bd mo mp mq dn mr ms mt dp mu lp mv mw mx lt my mz na lx nb nc nd jh bi translated">图表和电子健康记录</h2><blockquote class="ne nf ng"><p id="93ca" class="lg lh nh li b lj lk kl ll lm ln ko lo ni lq lr ls nj lu lv lw nk ly lz ma mb ij bi translated">在基于公共数据和真实世界临床数据的各种电子健康记录预测任务中，模型优于现有的基于图形和非图形的方法。</p></blockquote><div class="ip iq gp gr ir ob"><a href="https://github.com/NYUMedML/GNN_for_EHR" rel="noopener  ugc nofollow" target="_blank"><div class="oc ab fo"><div class="od ab oe cl cj of"><h2 class="bd jl gy z fp og fr fs oh fu fw jk bi translated">EHR GNN的纽约</h2><div class="oi l"><h3 class="bd b gy z fp og fr fs oh fu fw dk translated">这个库包含了这篇论文的代码:“可变正则化的基于图的表示学习”。</h3></div><div class="oj l"><p class="bd b dl z fp og fr fs oh fu fw dk translated">github.com</p></div></div><div class="ok l"><div class="qk l om on oo ok op it ob"/></div></div></a></div></div><div class="ab cl kz la hu lb" role="separator"><span class="lc bw bk ld le lf"/><span class="lc bw bk ld le lf"/><span class="lc bw bk ld le"/></div><div class="ij ik il im in"><h2 id="affe" class="mm mn jb bd mo mp mq dn mr ms mt dp mu lp mv mw mx lt my mz na lx nb nc nd jh bi translated">用GPT-2生成代码</h2><blockquote class="ne nf ng"><p id="0b57" class="lg lh nh li b lj lk kl ll lm ln ko lo ni lq lr ls nj lu lv lw nk ly lz ma mb ij bi translated">在CodeSearchNet上为代码生成微调GPT-2</p></blockquote><div class="ip iq gp gr ir ob"><a href="https://github.com/kandluis/code-gen" rel="noopener  ugc nofollow" target="_blank"><div class="oc ab fo"><div class="od ab oe cl cj of"><h2 class="bd jl gy z fp og fr fs oh fu fw jk bi translated">kand Luis/代码-gen</h2><div class="oi l"><h3 class="bd b gy z fp og fr fs oh fu fw dk translated">from/cs 230/GPT-2-csn:$ pip install-r path/to/requirements . txt $ python download _ model . py 117m注意…</h3></div><div class="oj l"><p class="bd b dl z fp og fr fs oh fu fw dk translated">github.com</p></div></div><div class="ok l"><div class="ql l om on oo ok op it ob"/></div></div></a></div><p id="57f1" class="pw-post-body-paragraph lg lh jb li b lj lk kl ll lm ln ko lo lp lq lr ls lt lu lv lw lx ly lz ma mb ij bi translated"><a class="ae mc" href="https://www.connectedpapers.com/main/4891cc27e296e0ead23407a835bcd3bbb802ce67/arxiv" rel="noopener ugc nofollow" target="_blank"> <strong class="li jl">连接论文</strong> </a> <strong class="li jl">📈</strong></p></div><div class="ab cl kz la hu lb" role="separator"><span class="lc bw bk ld le lf"/><span class="lc bw bk ld le lf"/><span class="lc bw bk ld le"/></div><div class="ij ik il im in"><h2 id="2cbe" class="mm mn jb bd mo mp mq dn mr ms mt dp mu lp mv mw mx lt my mz na lx nb nc nd jh bi translated">REMOD:用于网络话语建模的关系抽取</h2><blockquote class="ne nf ng"><p id="d74c" class="lg lh nh li b lj lk kl ll lm ln ko lo ni lq lr ls nj lu lv lw nk ly lz ma mb ij bi translated">sdfsd</p></blockquote><div class="ip iq gp gr ir ob"><a href="https://github.com/mjsumpter/remod" rel="noopener  ugc nofollow" target="_blank"><div class="oc ab fo"><div class="od ab oe cl cj of"><h2 class="bd jl gy z fp og fr fs oh fu fw jk bi translated">mjsumpter/remod</h2><div class="oi l"><h3 class="bd b gy z fp og fr fs oh fu fw dk translated">以下是严格再现论文中引用的结果的说明。必要的软件包可以是…</h3></div><div class="oj l"><p class="bd b dl z fp og fr fs oh fu fw dk translated">github.com</p></div></div><div class="ok l"><div class="qm l om on oo ok op it ob"/></div></div></a></div><p id="9290" class="pw-post-body-paragraph lg lh jb li b lj lk kl ll lm ln ko lo lp lq lr ls lt lu lv lw lx ly lz ma mb ij bi translated"><a class="ae mc" href="https://www.connectedpapers.com/main/20f26ee9801af2645c56836f45a9a545f3ce5a1f/arxiv" rel="noopener ugc nofollow" target="_blank"> <strong class="li jl">连接论文</strong> </a> <strong class="li jl">📈</strong></p></div><div class="ab cl kz la hu lb" role="separator"><span class="lc bw bk ld le lf"/><span class="lc bw bk ld le lf"/><span class="lc bw bk ld le"/></div><div class="ij ik il im in"><h2 id="febb" class="mm mn jb bd mo mp mq dn mr ms mt dp mu lp mv mw mx lt my mz na lx nb nc nd jh bi translated">论元结构预测</h2><blockquote class="ne nf ng"><p id="fe5c" class="lg lh nh li b lj lk kl ll lm ln ko lo ni lq lr ls nj lu lv lw nk ly lz ma mb ij bi translated">此代码可用于训练一组神经网络，以在选择参数挖掘语料库上联合执行链接预测、关系分类和组件分类。</p></blockquote><div class="ip iq gp gr ir ob"><a href="https://github.com/AGalassi/StructurePrediction18" rel="noopener  ugc nofollow" target="_blank"><div class="oc ab fo"><div class="od ab oe cl cj of"><h2 class="bd jl gy z fp og fr fs oh fu fw jk bi translated">AGalassi/结构预测18</h2><div class="oi l"><h3 class="bd b gy z fp og fr fs oh fu fw dk translated">使用剩余深度网络、集成学习和注意力进行论元结构预测。这个代码可以是…</h3></div><div class="oj l"><p class="bd b dl z fp og fr fs oh fu fw dk translated">github.com</p></div></div><div class="ok l"><div class="qn l om on oo ok op it ob"/></div></div></a></div><p id="f6f8" class="pw-post-body-paragraph lg lh jb li b lj lk kl ll lm ln ko lo lp lq lr ls lt lu lv lw lx ly lz ma mb ij bi translated"><a class="ae mc" href="https://www.connectedpapers.com/main/c1cb5e412f10013e2fdf085f3153a8af824ccf0d/arxiv" rel="noopener ugc nofollow" target="_blank"> <strong class="li jl">连接论文</strong> </a> <strong class="li jl">📈</strong></p></div><div class="ab cl kz la hu lb" role="separator"><span class="lc bw bk ld le lf"/><span class="lc bw bk ld le lf"/><span class="lc bw bk ld le"/></div><div class="ij ik il im in"><h1 id="ff81" class="nl mn jb bd mo nm qo no mr np qp nr mu kq qq kr mx kt qr ku na kw qs kx nd nv bi translated">本周数据集:EmotionGIF 2020挑战</h1><h2 id="80c7" class="mm mn jb bd mo mp mq dn mr ms mt dp mu lp mv mw mx lt my mz na lx nb nc nd jh bi translated">这是什么？</h2><p id="4c09" class="pw-post-body-paragraph lg lh jb li b lj nw kl ll lm nx ko lo lp ny lr ls lt nz lv lw lx oa lz ma mb ij bi translated">数据集包含40，000条推文及其GIF回复，标有动画GIF的类别。挑战:给定未标记的推文，预测GIF回复的类别。gif被存储为MP4文件。</p><h2 id="c9a3" class="mm mn jb bd mo mp mq dn mr ms mt dp mu lp mv mw mx lt my mz na lx nb nc nd jh bi translated">样品</h2><p id="3ef5" class="pw-post-body-paragraph lg lh jb li b lj nw kl ll lm nx ko lo lp ny lr ls lt nz lv lw lx oa lz ma mb ij bi translated">【idx】:32，</p><p id="c618" class="pw-post-body-paragraph lg lh jb li b lj lk kl ll lm ln ko lo lp lq lr ls lt lu lv lw lx ly lz ma mb ij bi translated">" text ":"正好落在我的陷阱下面"，</p><p id="5e42" class="pw-post-body-paragraph lg lh jb li b lj lk kl ll lm ln ko lo lp lq lr ls lt lu lv lw lx ly lz ma mb ij bi translated">“回复”:“哎哟！”,</p><p id="1c0e" class="pw-post-body-paragraph lg lh jb li b lj lk kl ll lm ln ko lo lp lq lr ls lt lu lv lw lx ly lz ma mb ij bi translated">"类别":['awww '，' yes '，' oops']，</p><p id="8d41" class="pw-post-body-paragraph lg lh jb li b lj lk kl ll lm ln ko lo lp lq lr ls lt lu lv lw lx ly lz ma mb ij bi translated">" MP4 ":" Fe 6 EC 1 CD 04 CD 009 F3 a 5975 e 2d 288 ff 82 . MP4 "</p><h2 id="e700" class="mm mn jb bd mo mp mq dn mr ms mt dp mu lp mv mw mx lt my mz na lx nb nc nd jh bi translated">它在哪里？</h2><div class="ip iq gp gr ir ob"><a href="https://sites.google.com/view/emotiongif-2020/shared-task/dataset?authuser=0" rel="noopener  ugc nofollow" target="_blank"><div class="oc ab fo"><div class="od ab oe cl cj of"><h2 class="bd jl gy z fp og fr fs oh fu fw jk bi translated">emotion if 2020-数据集</h2><div class="oi l"><h3 class="bd b gy z fp og fr fs oh fu fw dk translated">激动人心的IF 2020挑战已经结束。这两轮比赛的大赢家是团队……共有30支参赛队伍</h3></div><div class="oj l"><p class="bd b dl z fp og fr fs oh fu fw dk translated">sites.google.com</p></div></div><div class="ok l"><div class="qt l om on oo ok op it ob"/></div></div></a></div></div><div class="ab cl kz la hu lb" role="separator"><span class="lc bw bk ld le lf"/><span class="lc bw bk ld le lf"/><span class="lc bw bk ld le"/></div><div class="ij ik il im in"><blockquote class="pg"><p id="b330" class="ph pi jb bd pj pk pq pr ps pt pu mb dk translated">每周日，我们都会对来自世界各地研究人员的NLP新闻和代码进行一次每周综述。</p><p id="8639" class="ph pi jb bd pj pk pq pr ps pt pu mb dk translated">如需完整报道，请关注我们的Twitter: <a class="ae mc" href="http://twitter.com/Quantum_Stat" rel="noopener ugc nofollow" target="_blank"> @Quantum_Stat </a></p></blockquote><figure class="pv pw px py pz is gh gi paragraph-image"><div class="gh gi qu"><img src="../Images/605d15bdf547bb10223a0601abc84af6.png" data-original-src="https://miro.medium.com/v2/resize:fit:108/0*vgf45g9haG4f6VcH"/></div><figcaption class="iv iw gj gh gi ix iy bd b be z dk translated"><a class="ae mc" href="https://quantumstat.com/" rel="noopener ugc nofollow" target="_blank">量子统计</a></figcaption></figure></div></div>    
</body>
</html>