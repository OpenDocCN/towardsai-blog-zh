<html>
<head>
<title>Stock Price Prediction Model for Netflix</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">网飞股票价格预测模型</h1>
<blockquote>原文：<a href="https://pub.towardsai.net/netflix-stock-prediction-model-a-comparative-study-of-linear-regression-k-nearest-neighbor-knn-4527ff17939b?source=collection_archive---------0-----------------------#2020-05-01">https://pub.towardsai.net/netflix-stock-prediction-model-a-comparative-study-of-linear-regression-k-nearest-neighbor-knn-4527ff17939b?source=collection_archive---------0-----------------------#2020-05-01</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><h2 id="9550" class="io ip iq bd b dl ir is it iu iv iw dk ix translated" aria-label="kicker paragraph">机器学习</h2><div class=""/><div class=""><h2 id="4fb7" class="pw-subtitle-paragraph jw iz iq bd b jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn dk translated">线性回归、K近邻(KNN)和支持向量机(SVM)的比较研究</h2></div><p id="6158" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">本文的目的是设计一个股票预测线性模型来预测网飞的收盘价。这将是对各种机器学习模型的比较研究，如线性回归、K-最近邻和支持向量机。</p><p id="257f" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">在设计模型之前，我浏览了互联网上一些与投资相关的博客和文章，以便更好地了解这件事，我发现了一些决定股票开盘价和收盘价的关键指标。因此，关于模型训练的本教程将不限于单个特征，而是这将是多特征训练的模型。</p><h2 id="3611" class="lk ll iq bd lm ln lo dn lp lq lr dp ls kx lt lu lv lb lw lx ly lf lz ma mb iw bi translated"><strong class="ak">股市基本影响因素</strong></h2><p id="53b1" class="pw-post-body-paragraph ko kp iq kq b kr mc ka kt ku md kd kw kx me kz la lb mf ld le lf mg lh li lj ij bi translated">作为一名数据科学家或ml专业人士，当我们对我们试图建立的业务或功能有了清晰的认识时，我们的工作就会变得轻松，所以我想我也必须分享一些业务见解，然而，我不是股票市场专业人士，但我认为这将建立一种理解。所以基本上,<strong class="kq ja">收盘价</strong>是买家在营业时间内为特定股票支付的最后价格，开盘价是该股票的第一笔交易价格，在股票交易中,<strong class="kq ja">开盘价</strong>可能与收盘价不同是一个非常常见的现象，原因是供求之间的波动决定了股票的吸引力。这种现象被称为<strong class="kq ja"> AHT(盘后交易)</strong>，它在改变股票开盘价方面起着关键作用。还有其他因素，我不是这方面的专家，所以我不打算深究。这一小段信息是为了让人们对现实世界的问题有一个基本的了解。<br/>因此，不再浪费时间，让我们直接跳到解决方案"<strong class="kq ja">编码</strong>"</p><h2 id="64e9" class="lk ll iq bd lm ln lo dn lp lq lr dp ls kx lt lu lv lb lw lx ly lf lz ma mb iw bi translated"><strong class="ak"> 1。导入先决条件:</strong></h2><pre class="mh mi mj mk gt ml mm mn mo aw mp bi"><span id="1a28" class="lk ll iq mm b gy mq mr l ms mt">import pandas as pd<br/>from sklearn.linear_model import LinearRegression<br/>from sklearn.model_selection import train_test_split<br/>import matplotlib.pyplot as plt<br/>import numpy as np<br/>import pandas_datareader as web</span></pre><blockquote class="mu mv mw"><p id="9227" class="ko kp mx kq b kr ks ka kt ku kv kd kw my ky kz la mz lc ld le na lg lh li lj ij bi translated">pandas_datareader库允许我们连接到网站并直接从互联网资源中提取数据，在我们的例子中，我们从Yahoo Finance API中提取数据。</p></blockquote><h2 id="3535" class="lk ll iq bd lm ln lo dn lp lq lr dp ls kx lt lu lv lb lw lx ly lf lz ma mb iw bi translated"><strong class="ak"> 2。读取并显示</strong></h2><pre class="mh mi mj mk gt ml mm mn mo aw mp bi"><span id="1d44" class="lk ll iq mm b gy mq mr l ms mt">df = web.DataReader(‘NFLX’, data_source=’yahoo’, start=’2012–01–01', end=’2020–04–28')<br/>df.tail(10)</span></pre><figure class="mh mi mj mk gt nc gh gi paragraph-image"><div class="gh gi nb"><img src="../Images/ba948d8529cd9960830ea26a3ce823cc.png" data-original-src="https://miro.medium.com/v2/resize:fit:1166/format:webp/1*cw-Y2-g9x8INWakLV42I8A.png"/></div><figcaption class="nf ng gj gh gi nh ni bd b be z dk translated">NFLX股票价格</figcaption></figure><pre class="mh mi mj mk gt ml mm mn mo aw mp bi"><span id="8dfa" class="lk ll iq mm b gy mq mr l ms mt">df.reset_index(inplace=True)<br/>df.describe()</span></pre><figure class="mh mi mj mk gt nc gh gi paragraph-image"><div class="gh gi nj"><img src="../Images/fcd5da7a4b863c840031e2cf52eaf236.png" data-original-src="https://miro.medium.com/v2/resize:fit:1202/format:webp/1*o3pBRpM5Iusc6uSC-mNNLw.png"/></div><figcaption class="nf ng gj gh gi nh ni bd b be z dk translated">股票价格统计</figcaption></figure><h2 id="34fc" class="lk ll iq bd lm ln lo dn lp lq lr dp ls kx lt lu lv lb lw lx ly lf lz ma mb iw bi translated"><strong class="ak"> 3。检查相关性</strong></h2><p id="1999" class="pw-post-body-paragraph ko kp iq kq b kr mc ka kt ku md kd kw kx me kz la lb mf ld le lf mg lh li lj ij bi translated">在我们检查相关性之前，让我们了解它到底是什么？</p><p id="f932" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">相关性是对两个特征之间的关联性或依赖性的度量，即<strong class="kq ja"> Y </strong>会随着<strong class="kq ja"> X </strong>的变化而变化多少。我们将使用的相关方法是<strong class="kq ja">皮尔逊相关法</strong>。</p><p id="5012" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated"><strong class="kq ja">皮尔逊相关系数</strong>是衡量相关性最流行的方式，取值范围从-1到1不等。在数学/物理学术语中，可以理解为如果两个特征正相关，那么它们是<strong class="kq ja">正比</strong>，如果它们共享负相关，那么它们是<strong class="kq ja">反比</strong>。</p><pre class="mh mi mj mk gt ml mm mn mo aw mp bi"><span id="5806" class="lk ll iq mm b gy mq mr l ms mt">corr = df.corr(method=’pearson’)<br/>corr</span></pre><figure class="mh mi mj mk gt nc gh gi paragraph-image"><div class="gh gi nk"><img src="../Images/e6e4e00834ab1c3fc46344a9d0f57e81.png" data-original-src="https://miro.medium.com/v2/resize:fit:998/format:webp/1*f1-fV9q_3yUOi_6xg0Zkuw.png"/></div><figcaption class="nf ng gj gh gi nh ni bd b be z dk translated">皮尔逊相关系数</figcaption></figure><p id="b2e0" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">不是所有的文字都是可以理解的，让我们把相关系数形象化。</p><pre class="mh mi mj mk gt ml mm mn mo aw mp bi"><span id="380e" class="lk ll iq mm b gy mq mr l ms mt">import seaborn as sb<br/>sb.heatmap(corr,xticklabels=corr.columns, yticklabels=corr.columns,<br/>            cmap='RdBu_r', annot=True, linewidth=0.5)</span></pre><figure class="mh mi mj mk gt nc gh gi paragraph-image"><div class="gh gi nl"><img src="../Images/cbe7ef9eda59783db780245f8b6dbf15.png" data-original-src="https://miro.medium.com/v2/resize:fit:1024/format:webp/1*2xQIQ3nrwXrJi_2NtwwhBg.png"/></div><figcaption class="nf ng gj gh gi nh ni bd b be z dk translated">相关图</figcaption></figure><p id="9094" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">深栗色区不是栗色5，哈哈开玩笑，但它表示高度相关的功能。</p><h2 id="05f1" class="lk ll iq bd lm ln lo dn lp lq lr dp ls kx lt lu lv lb lw lx ly lf lz ma mb iw bi translated"><strong class="ak"> 4。用独立特征可视化因变量</strong></h2><pre class="mh mi mj mk gt ml mm mn mo aw mp bi"><span id="f684" class="lk ll iq mm b gy mq mr l ms mt">#prepare dataset to work with <br/>nflx_df=df[[‘Date’,’High’,’Open’,’Low’,’Close’]]<br/>nflx_df.head(10)</span><span id="9306" class="lk ll iq mm b gy nm mr l ms mt">plt.figure(figsize=(16,8))<br/>plt.title('Netflix Stocks Closing Price History 2012-2020')<br/>plt.plot(nflx_df['Date'],nflx_df['Close'])<br/>plt.xlabel('Date',fontsize=18)<br/>plt.ylabel('Close Price US($)',fontsize=18)<br/>plt.style.use('fivethirtyeight')<br/>plt.show()</span></pre><figure class="mh mi mj mk gt nc gh gi paragraph-image"><div role="button" tabindex="0" class="no np di nq bf nr"><div class="gh gi nn"><img src="../Images/4784b7e890493539bd0684b61dfc7c20.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*1fEu_qzzcMKRXQqfLPrOOQ.png"/></div></div><figcaption class="nf ng gj gh gi nh ni bd b be z dk translated">日期与收盘价</figcaption></figure><pre class="mh mi mj mk gt ml mm mn mo aw mp bi"><span id="4db5" class="lk ll iq mm b gy mq mr l ms mt">#Plot Open vs Close<br/>nflx_df[['Open','Close']].head(20).plot(kind='bar',figsize=(16,8))<br/>plt.grid(which='major', linestyle='-', linewidth='0.5', color='green')<br/>plt.grid(which='minor', linestyle=':', linewidth='0.5', color='black')<br/>plt.show()</span></pre><figure class="mh mi mj mk gt nc gh gi paragraph-image"><div role="button" tabindex="0" class="no np di nq bf nr"><div class="gh gi ns"><img src="../Images/e1f4e95e7a01c6340a02da7299673537.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*I7sRWtcIDPNn8yUTIX5uAQ.png"/></div></div><figcaption class="nf ng gj gh gi nh ni bd b be z dk translated">开盘价与收盘价</figcaption></figure><pre class="mh mi mj mk gt ml mm mn mo aw mp bi"><span id="c323" class="lk ll iq mm b gy mq mr l ms mt">#Plot High vs Close<br/>nflx_df[['High','Close']].head(20).plot(kind='bar',figsize=(16,8))<br/>plt.grid(which='major', linestyle='-', linewidth='0.5', color='green')<br/>plt.grid(which='minor', linestyle=':', linewidth='0.5', color='black')<br/>plt.show()</span></pre><figure class="mh mi mj mk gt nc gh gi paragraph-image"><div role="button" tabindex="0" class="no np di nq bf nr"><div class="gh gi nt"><img src="../Images/c7290fed60261fa94f5456f8a6dc330a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Y35p4XHNsRuevUGX_bOHtg.png"/></div></div><figcaption class="nf ng gj gh gi nh ni bd b be z dk translated">高价与收盘价</figcaption></figure><pre class="mh mi mj mk gt ml mm mn mo aw mp bi"><span id="6198" class="lk ll iq mm b gy mq mr l ms mt">#Plot Low vs Close<br/>nflx_df[[‘Low’,’Close’]].head(20).plot(kind=’bar’,figsize=(16,8))<br/>plt.grid(which=’major’, linestyle=’-’, linewidth=’0.5', color=’green’)<br/>plt.grid(which=’minor’, linestyle=’:’, linewidth=’0.5', color=’black’)<br/>plt.show()</span></pre><figure class="mh mi mj mk gt nc gh gi paragraph-image"><div role="button" tabindex="0" class="no np di nq bf nr"><div class="gh gi nn"><img src="../Images/bd94335f238a0b78fa5f941c57a528df.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*z_amWFd3_oQ9lXWPPrs4gQ.png"/></div></div><figcaption class="nf ng gj gh gi nh ni bd b be z dk translated">低价对收盘价</figcaption></figure><h2 id="3103" class="lk ll iq bd lm ln lo dn lp lq lr dp ls kx lt lu lv lb lw lx ly lf lz ma mb iw bi translated"><strong class="ak"> 5。模型训练和测试</strong></h2><pre class="mh mi mj mk gt ml mm mn mo aw mp bi"><span id="4b23" class="lk ll iq mm b gy mq mr l ms mt">#Date format is DateTime and it will throw error while training so I have created seperate month, year and date entities</span><span id="36e8" class="lk ll iq mm b gy nm mr l ms mt">nflx_df[‘Year’]=df[‘Date’].dt.year<br/>nflx_df[‘Month’]=df[‘Date’].dt.month<br/>nflx_df[‘Day’]=df[‘Date’].dt.day</span></pre><p id="4243" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">为模型训练创建最终数据集</p><pre class="mh mi mj mk gt ml mm mn mo aw mp bi"><span id="e50c" class="lk ll iq mm b gy mq mr l ms mt">nfx_df=nflx_df[[‘Day’,’Month’,’Year’,’High’,’Open’,’Low’,’Close’]]<br/>nfx_df.head(10)</span></pre><figure class="mh mi mj mk gt nc gh gi paragraph-image"><div class="gh gi nu"><img src="../Images/5f769a3280f56169be9046e6924cc3ed.png" data-original-src="https://miro.medium.com/v2/resize:fit:894/format:webp/1*Rzq-B7dZgCSP1K5QWlEIMA.png"/></div><figcaption class="nf ng gj gh gi nh ni bd b be z dk translated">最终训练数据集</figcaption></figure><pre class="mh mi mj mk gt ml mm mn mo aw mp bi"><span id="6b8d" class="lk ll iq mm b gy mq mr l ms mt">#separate Independent and dependent variable<br/>X = nfx_df.iloc[:,nfx_df.columns !=’Close’]<br/>Y= nfx_df.iloc[:, 5]</span><span id="2ba0" class="lk ll iq mm b gy nm mr l ms mt">print(X.shape)  #output: (2093, 6)<br/>print(Y.shape) #output: (2093,)</span></pre><p id="e350" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">将数据集分为训练和测试</p><pre class="mh mi mj mk gt ml mm mn mo aw mp bi"><span id="50bc" class="lk ll iq mm b gy mq mr l ms mt">from sklearn.model_selection import train_test_split<br/>x_train,x_test,y_train,y_test= train_test_split(X,Y,test_size=.25)</span><span id="1ab0" class="lk ll iq mm b gy nm mr l ms mt">print(x_train.shape) #output: (1569, 6)<br/>print(x_test.shape)  #output: (524, 6)  <br/>print(y_train.shape) #output: (1569,)<br/>print(y_test.shape)  #output: (524,)<br/>#y_test to be evaluated with y_pred for Diff models</span></pre><h1 id="ee9c" class="nv ll iq bd lm nw nx ny lp nz oa ob ls kf oc kg lv ki od kj ly kl oe km mb of bi translated"><strong class="ak">模型1:线性回归</strong></h1><h2 id="2f9f" class="lk ll iq bd lm ln lo dn lp lq lr dp ls kx lt lu lv lb lw lx ly lf lz ma mb iw bi translated"><strong class="ak">线性回归模型训练和测试</strong></h2><pre class="mh mi mj mk gt ml mm mn mo aw mp bi"><span id="b29f" class="lk ll iq mm b gy mq mr l ms mt">lr_model=LinearRegression()<br/>lr_model.fit(x_train,y_train)</span><span id="a667" class="lk ll iq mm b gy nm mr l ms mt">y_pred=lr_model.predict(x_test)</span></pre><h2 id="1cb7" class="lk ll iq bd lm ln lo dn lp lq lr dp ls kx lt lu lv lb lw lx ly lf lz ma mb iw bi translated"><strong class="ak">线性模型交叉验证</strong></h2><p id="c048" class="pw-post-body-paragraph ko kp iq kq b kr mc ka kt ku md kd kw kx me kz la lb mf ld le lf mg lh li lj ij bi translated"><strong class="kq ja">交叉验证到底是什么？</strong></p><p id="036c" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">基本上，交叉验证是一种在数据集上评估模型的技术，在该数据集上模型没有被训练，即它可以是测试数据，也可以是根据可用性或可行性的另一组数据。</p><pre class="mh mi mj mk gt ml mm mn mo aw mp bi"><span id="cc5a" class="lk ll iq mm b gy mq mr l ms mt">from sklearn import model_selection<br/>from sklearn.model_selection import KFold<br/>kfold = model_selection.KFold(n_splits=20, random_state=100)<br/>results_kfold = model_selection.cross_val_score(lr_model, x_test, y_test.astype('int'), cv=kfold)<br/>print("Accuracy: ", results_kfold.mean()*100)</span><span id="454e" class="lk ll iq mm b gy nm mr l ms mt">#output: Accuracy: 99.999366595175</span></pre><p id="8b96" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated"><strong class="kq ja">绘制实际值与预测值的对比图</strong></p><pre class="mh mi mj mk gt ml mm mn mo aw mp bi"><span id="68cd" class="lk ll iq mm b gy mq mr l ms mt">plot_df=pd.DataFrame({‘Actual’:y_test,’Pred’:y_pred})<br/>plot_df.head(20).plot(kind='bar',figsize=(16,8))<br/>plt.grid(which='major', linestyle='-', linewidth='0.5', color='green')<br/>plt.grid(which='minor', linestyle=':', linewidth='0.5', color='black')<br/>plt.show()</span></pre><figure class="mh mi mj mk gt nc gh gi paragraph-image"><div role="button" tabindex="0" class="no np di nq bf nr"><div class="gh gi nt"><img src="../Images/a80839452e04be87f39992dba9b9119f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*6NbLCq2Y8AmxAtRt0aTwKA.png"/></div></div><figcaption class="nf ng gj gh gi nh ni bd b be z dk translated">线性实际与预测</figcaption></figure><h1 id="b3e2" class="nv ll iq bd lm nw nx ny lp nz oa ob ls kf oc kg lv ki od kj ly kl oe km mb of bi translated"><strong class="ak">模型二:KNN K近邻回归模型</strong></h1><h2 id="44cd" class="lk ll iq bd lm ln lo dn lp lq lr dp ls kx lt lu lv lb lw lx ly lf lz ma mb iw bi translated"><strong class="ak"> KNN模型培训和测试</strong></h2><pre class="mh mi mj mk gt ml mm mn mo aw mp bi"><span id="0890" class="lk ll iq mm b gy mq mr l ms mt">from sklearn.neighbors import KNeighborsRegressor<br/>knn_regressor=KNeighborsRegressor(n_neighbors = 5)<br/>knn_model=knn_regressor.fit(x_train,y_train)<br/>y_knn_pred=knn_model.predict(x_test)</span></pre><h2 id="3544" class="lk ll iq bd lm ln lo dn lp lq lr dp ls kx lt lu lv lb lw lx ly lf lz ma mb iw bi translated"><strong class="ak"> KNN交叉验证</strong></h2><pre class="mh mi mj mk gt ml mm mn mo aw mp bi"><span id="0edc" class="lk ll iq mm b gy mq mr l ms mt">knn_kfold = model_selection.KFold(n_splits=20, random_state=100)<br/>results_kfold = model_selection.cross_val_score(knn_model, x_test, y_test.astype(‘int’), cv=knn_kfold)<br/>print(“Accuracy: “, results_kfold.mean()*100)</span><span id="bfb6" class="lk ll iq mm b gy nm mr l ms mt">#output: Accuracy: 99.93813335235933</span></pre><h2 id="de74" class="lk ll iq bd lm ln lo dn lp lq lr dp ls kx lt lu lv lb lw lx ly lf lz ma mb iw bi translated"><strong class="ak">绘制实际与预测的对比图</strong></h2><pre class="mh mi mj mk gt ml mm mn mo aw mp bi"><span id="fc89" class="lk ll iq mm b gy mq mr l ms mt">plot_knn_df=pd.DataFrame({‘Actual’:y_test,’Pred’:y_knn_pred})<br/>plot_knn_df.head(20).plot(kind=’bar’,figsize=(16,8))<br/>plt.grid(which=’major’, linestyle=’-’, linewidth=’0.5', color=’green’)<br/>plt.grid(which=’minor’, linestyle=’:’, linewidth=’0.5', color=’black’)<br/>plt.show()</span></pre><figure class="mh mi mj mk gt nc gh gi paragraph-image"><div role="button" tabindex="0" class="no np di nq bf nr"><div class="gh gi og"><img src="../Images/1e1f38db8a5dcd7be7e86ac1e55fe6c3.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*OJhNkA182NpCJXO8JNkmKA.png"/></div></div><figcaption class="nf ng gj gh gi nh ni bd b be z dk translated">KNN实际与预测</figcaption></figure><h1 id="e16c" class="nv ll iq bd lm nw nx ny lp nz oa ob ls kf oc kg lv ki od kj ly kl oe km mb of bi translated"><strong class="ak">模型3: SVM支持向量机回归模型</strong></h1><h2 id="7ed3" class="lk ll iq bd lm ln lo dn lp lq lr dp ls kx lt lu lv lb lw lx ly lf lz ma mb iw bi translated"><strong class="ak"> SVM模型培训和测试</strong></h2><pre class="mh mi mj mk gt ml mm mn mo aw mp bi"><span id="f106" class="lk ll iq mm b gy mq mr l ms mt">from sklearn.svm import SVR<br/>svm_regressor = SVR(kernel=’linear’)<br/>svm_model=svm_regressor.fit(x_train,y_train)<br/>y_svm_pred=svm_model.predict(x_test)</span></pre><h2 id="a0ad" class="lk ll iq bd lm ln lo dn lp lq lr dp ls kx lt lu lv lb lw lx ly lf lz ma mb iw bi translated"><strong class="ak">绘制实际与预测的对比图</strong></h2><pre class="mh mi mj mk gt ml mm mn mo aw mp bi"><span id="cec1" class="lk ll iq mm b gy mq mr l ms mt">plot_svm_df=pd.DataFrame({‘Actual’:y_test,’Pred’:y_svm_pred})<br/>plot_svm_df.head(20).plot(kind=’bar’,figsize=(16,8))<br/>plt.grid(which=’major’, linestyle=’-’, linewidth=’0.5', color=’green’)<br/>plt.grid(which=’minor’, linestyle=’:’, linewidth=’0.5', color=’black’)<br/>plt.show()</span></pre><figure class="mh mi mj mk gt nc gh gi paragraph-image"><div role="button" tabindex="0" class="no np di nq bf nr"><div class="gh gi oh"><img src="../Images/9b6bcccce97b6685f3a05613f3af83cf.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*lPm_8PmXWYnceoEHZ4-78Q.png"/></div></div><figcaption class="nf ng gj gh gi nh ni bd b be z dk translated">SVM实际与预测</figcaption></figure><h2 id="a6b6" class="lk ll iq bd lm ln lo dn lp lq lr dp ls kx lt lu lv lb lw lx ly lf lz ma mb iw bi translated"><strong class="ak"> RMSE(均方根误差)</strong></h2><p id="01cc" class="pw-post-body-paragraph ko kp iq kq b kr mc ka kt ku md kd kw kx me kz la lb mf ld le lf mg lh li lj ij bi translated">均方根误差是残差的标准偏差，它衡量数据点与回归的距离。或者简单地说，数据点在最佳拟合线周围有多集中。</p><pre class="mh mi mj mk gt ml mm mn mo aw mp bi"><span id="d82b" class="lk ll iq mm b gy mq mr l ms mt">from sklearn.metrics import mean_squared_error , r2_score<br/>import math</span><span id="8e9c" class="lk ll iq mm b gy nm mr l ms mt">lr_mse=math.sqrt(mean_squared_error(y_test,y_pred))<br/>print(‘Linear Model Root mean square error’,lr_mse)</span><span id="bdaa" class="lk ll iq mm b gy nm mr l ms mt">knn_mse=math.sqrt(mean_squared_error(y_test,y_knn_pred))<br/>print(‘KNN Model Root mean square error’,mse)</span><span id="09c9" class="lk ll iq mm b gy nm mr l ms mt">svm_mse=math.sqrt(mean_squared_error(y_test,y_svm_pred))<br/>print(‘SVM Model Root mean square error SVM’,svm_mse)</span><span id="a19e" class="lk ll iq mm b gy nm mr l ms mt">#outputs as below:<br/>Linear Model Root mean square error 1.7539775065782694e-14 <br/>KNN Model Root mean square error 1.7539775065782694e-14 <br/>SVM Model Root mean square error SVM 0.0696764093622963</span></pre><p id="ef10" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated"><strong class="kq ja"> R2或r平方误差</strong></p><p id="10aa" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">r2或R2分数在0到100%之间变化。</p><p id="a66e" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated"><strong class="kq ja">R2得分的数学公式:(y_test[i] — y_pred[i]) **2 </strong></p><pre class="mh mi mj mk gt ml mm mn mo aw mp bi"><span id="224a" class="lk ll iq mm b gy mq mr l ms mt">print(‘Linear R2: ‘, r2_score(y_test, y_pred))<br/>print(‘KNN R2: ‘, r2_score(y_test, y_knn_pred))<br/>print(‘SVM R2: ‘, r2_score(y_test, y_svm_pred))</span><span id="0d3b" class="lk ll iq mm b gy nm mr l ms mt">#output as below:<br/>Linear R2:  1.0 <br/>KNN R2:  0.9997974105145412 <br/>SVM R2:  0.9999996581785765</span></pre><blockquote class="mu mv mw"><p id="1e91" class="ko kp mx kq b kr ks ka kt ku kv kd kw my ky kz la mz lc ld le na lg lh li lj ij bi translated">关于对RMSE和R2误差的基本数学理解，请参考我的博客:<a class="ae oi" href="https://www.geeksforgeeks.org/ml-mathematical-explanation-of-rmse-and-r-squared-error/" rel="noopener ugc nofollow" target="_blank">https://www . geeksforgeeks . org/ml-mathematical-explain-of-RMSE-and-r-squared-error/</a></p></blockquote><p id="71e2" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">我们的模型看起来非常好，有惊人的统计数据。</p><h1 id="d485" class="nv ll iq bd lm nw nx ny lp nz oa ob ls kf oc kg lv ki od kj ly kl oe km mb of bi translated"><strong class="ak">概要:</strong></h1><p id="53c9" class="pw-post-body-paragraph ko kp iq kq b kr mc ka kt ku md kd kw kx me kz la lb mf ld le lf mg lh li lj ij bi translated">必备库的使用</p><p id="4432" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">使用<strong class="kq ja"> pandas_datareader </strong>从网络中提取数据</p><p id="2fa2" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">基本股票理解</p><p id="15af" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">模型训练和测试</p><p id="f3a1" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">ML算法如<strong class="kq ja">线性回归</strong>、<strong class="kq ja"> K近邻</strong>和<strong class="kq ja">支持向量机</strong></p><p id="99d1" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated"><strong class="kq ja">模型的交叉验证</strong></p><p id="6387" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">Python <strong class="kq ja"> seaborn </strong>库可视化关联热图</p><p id="b43b" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated"><strong class="kq ja">皮尔森相关性</strong></p><p id="d553" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">使用Matplotlib对相关输出进行特征绘图。</p><p id="b1b7" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">实际值与预测值的绘图。</p><p id="0d24" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated"><strong class="kq ja">均方根误差</strong> (RMSE)。</p><p id="3b21" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated"><strong class="kq ja"> R平方误差</strong></p><p id="25f1" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">感谢所有人阅读我的博客，如果你喜欢我的内容和解释，请在媒体上关注我并分享你的反馈，这将永远帮助我们所有人提高我们的知识。</p><p id="1fd3" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">感谢阅读！</p><p id="f6ec" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">Vivek Chaudhary</p></div></div>    
</body>
</html>