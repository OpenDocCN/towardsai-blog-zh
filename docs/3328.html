<html>
<head>
<title>Facebook/Meta’s Galactica NLP Shuts Down in 48 Hrs!</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">脸书/梅塔的卡拉狄加NLP将在48小时后关闭！</h1>
<blockquote>原文：<a href="https://pub.towardsai.net/metas-galactica-shuts-down-in-48-hrs-76178054f41a?source=collection_archive---------0-----------------------#2022-11-22">https://pub.towardsai.net/metas-galactica-shuts-down-in-48-hrs-76178054f41a?source=collection_archive---------0-----------------------#2022-11-22</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><figure class="gl gn jr js jt ju gh gi paragraph-image"><div role="button" tabindex="0" class="jv jw di jx bf jy"><div class="gh gi jq"><img src="../Images/3da5e9b663b14008d578499488d1b494.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*6vkhHPf54HJHfCyJNfntbQ.png"/></div></div><figcaption class="kb kc gj gh gi kd ke bd b be z dk translated">资料来源:Galactica.org</figcaption></figure><p id="04a1" class="pw-post-body-paragraph kf kg it kh b ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc im bi ld translated">以下是关于卡拉狄加的论文摘要。Galactica是NLP模型，它本应是科学文献的一种新的开源大型语言模型。这种语言模型专门研究数学和科学，能够总结科学论文、生成wiki文章、回答问题等等。它也是完全开源的，可以下载不同型号的重量和在你自己的硬件上运行的说明。</p><blockquote class="lm ln lo"><p id="46a1" class="kf kg lp kh b ki kj kk kl km kn ko kp lq kr ks kt lr kv kw kx ls kz la lb lc im bi translated">信息过载是科学进步的主要障碍。科学文献和数据的爆炸式增长使得在大量信息中发现有用的见解变得更加困难。今天，科学知识可以通过搜索引擎获得，但他们无法独自组织科学知识。在本文中，我们介绍了Galactica:一个可以存储、组合和推理科学知识的大型语言模型。我们在大量的论文、参考资料、知识库和其他资源上进行训练。我们在一系列科学任务上超越了现有的模型。在乳胶方程等技术知识调查中，卡拉狄加以68.2%比49.0%的优势胜过最新的GPT-3。Galactica在推理方面也表现出色，在数学MMLU上以41.3%比35.7%的成绩超过Chinchilla，在数学上以20.4%比8.8%的成绩超过PaLM 540B。它还为PubMedQA和MedMCQA dev等下游任务设定了77.6%和52.9%的新水平。尽管没有在通用语料库上训练，卡拉狄加在大板凳上的表现优于布鲁姆和OPT-175B。我们相信这些结果展示了语言模型作为科学新界面的潜力。为了科学界的利益，我们开源了这个模型。</p></blockquote><figure class="lu lv lw lx gt ju gh gi paragraph-image"><div role="button" tabindex="0" class="jv jw di jx bf jy"><div class="gh gi lt"><img src="../Images/b9393ff6d1177331151a6da217068fa2.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*YhWXW2iCYatiCKVnaNNz9g.jpeg"/></div></div><figcaption class="kb kc gj gh gi kd ke bd b be z dk translated">演职员表:【https://unsplash.com/@ilumire T2】</figcaption></figure></div><div class="ab cl lz ma hx mb" role="separator"><span class="mc bw bk md me mf"/><span class="mc bw bk md me mf"/><span class="mc bw bk md me"/></div><div class="im in io ip iq"><h1 id="b6ac" class="mg mh it bd mi mj mk ml mm mn mo mp mq mr ms mt mu mv mw mx my mz na nb nc nd bi translated">卡拉狄加是什么</h1><p id="13f2" class="pw-post-body-paragraph kf kg it kh b ki ne kk kl km nf ko kp kq ng ks kt ku nh kw kx ky ni la lb lc im bi translated">卡拉狄加的科学理解来自于大量符号化信息的数据集。确保各种形态的最佳学习(如自然语言、数学公式、分子序列等)。)，采取了特殊的标记化步骤，包括识别数学运算字符或标记不同类型序列的开始和结束。</p><p id="52e9" class="pw-post-body-paragraph kf kg it kh b ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc im bi translated">卡拉狄加有一招妙计。实现了一个额外的特殊标记来识别逐步推理的部分，这鼓励卡拉狄加应用各种内部工作记忆，否则它将无法做到这一点。</p><figure class="lu lv lw lx gt ju gh gi paragraph-image"><div role="button" tabindex="0" class="jv jw di jx bf jy"><div class="gh gi nj"><img src="../Images/fd937e7c746d71714858d1d55bd33793.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*tzV309buhtKIeYiDrkoCzQ.png"/></div></div><figcaption class="kb kc gj gh gi kd ke bd b be z dk translated">来源:卡拉狄加出版物</figcaption></figure><p id="b357" class="pw-post-body-paragraph kf kg it kh b ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc im bi translated">卡拉狄加有5种尺寸，从2.5亿个参数到1200亿个参数。在测试过程中，研究人员发现他们的模型在许多基准测试中表现优于可比模型(<a class="ae ly" href="https://huggingface.co/docs/transformers/model_doc/opt" rel="noopener ugc nofollow" target="_blank"> OPT </a>、<a class="ae ly" href="https://huggingface.co/docs/transformers/model_doc/bloom" rel="noopener ugc nofollow" target="_blank"> BLOOM </a>、<a class="ae ly" href="https://huggingface.co/docs/transformers/model_doc/openai-gpt" rel="noopener ugc nofollow" target="_blank"> GPT-3 </a>和其他，取决于任务)，并接近匹配不是最佳表现者的最佳模型。</p><figure class="lu lv lw lx gt ju gh gi paragraph-image"><div role="button" tabindex="0" class="jv jw di jx bf jy"><div class="gh gi nk"><img src="../Images/9e61689f810ad088dde278b3256ccd2a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*W72qsqZ4CJQ_VGl_dcBu9Q.png"/></div></div><figcaption class="kb kc gj gh gi kd ke bd b be z dk translated">来源:卡拉狄加研究论文</figcaption></figure><p id="dcea" class="pw-post-body-paragraph kf kg it kh b ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc im bi translated">关于Galactica的符号化方法如何用于科学理解的更多细节，以及它的其他比较和基准，请查看这里的完整研究论文:<a class="ae ly" href="https://galactica.org/static/paper.pdf" rel="noopener ugc nofollow" target="_blank">https://galactica.org/static/paper.pdf</a>和GitHub知识库这里:<a class="ae ly" href="https://github.com/paperswithcode/galai" rel="noopener ugc nofollow" target="_blank">https://github.com/paperswithcode/galai</a></p><figure class="lu lv lw lx gt ju gh gi paragraph-image"><div role="button" tabindex="0" class="jv jw di jx bf jy"><div class="gh gi nl"><img src="../Images/81476ac9c206a8fa3c506aae609fefeb.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Zu3H6GxmujRPOAnj1YVAfg.png"/></div></div><figcaption class="kb kc gj gh gi kd ke bd b be z dk translated">演职员表:<a class="ae ly" href="https://unsplash.com/@candrawes" rel="noopener ugc nofollow" target="_blank">https://unsplash.com/@candrawes</a></figcaption></figure></div><div class="ab cl lz ma hx mb" role="separator"><span class="mc bw bk md me mf"/><span class="mc bw bk md me mf"/><span class="mc bw bk md me"/></div><div class="im in io ip iq"><h1 id="2996" class="mg mh it bd mi mj mk ml mm mn mo mp mq mr ms mt mu mv mw mx my mz na nb nc nd bi translated">失败了！</h1><p id="a5c5" class="pw-post-body-paragraph kf kg it kh b ki ne kk kl km nf ko kp kq ng ks kt ku nh kw kx ky ni la lb lc im bi translated">对于一家专注于生产虚拟现实/真相的公司来说，Meta与真相的斗争似乎仍在继续。令人不安的是，卡拉狄加以优异的成绩通过了基准测试，但真正的演示只持续了2天。这个模型无法区分真实和谎言。</p><p id="51a8" class="pw-post-body-paragraph kf kg it kh b ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc im bi translated">卡拉狄加本应帮助科学家浏览大量已发表的科学信息。它的开发者将其描述为能够查找引文、总结学术文献、解决数学问题以及执行其他任务，以帮助科学家进行研究和撰写论文。对于一个被描述为“科学的大型语言模型”的模型来说，在现实生活测试中的失败是一个沉重的打击。大型语言模型(LLM)的科学空间现在只有OpenAI的GPT-4可以期待了。</p><p id="a21b" class="pw-post-body-paragraph kf kg it kh b ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc im bi translated">值得称赞的是，Meta和带有代码的论文在Galactica的网站上明确表示，“语言模型的输出不能保证真实或可靠，即使是像Galactica这样经过高质量数据训练的大型模型。”大型语言模型非常复杂。当涉及到理解、推理、计划和常识等主题时，科学家们对如何评估LLM存在分歧。他们还承认，卡拉狄加在用于产生关于广为引用的概念的内容时表现最佳。他们警告说，在某些情况下，卡拉狄加可能会生成看似真实但不准确的文本。可以理解的是，模型最终产生的“输出”可能不是可与人脑相比的智能输出，而是随机漫谈的概率下一个单词。</p><div class="nm nn gp gr no np"><a href="https://ithinkbot.com/human-vs-gpt-methods-to-watermark-gpt-models-e23aefc63db8" rel="noopener  ugc nofollow" target="_blank"><div class="nq ab fo"><div class="nr ab ns cl cj nt"><h2 class="bd iu gy z fp nu fr fs nv fu fw is bi translated">OpenAI正在给GPT加水印:不再抄袭</h2><div class="nw l"><h3 class="bd b gy z fp nu fr fs nv fu fw dk translated">知识产权保护通常被称为人工智能模型的“水印”，对于人工智能的未来用例至关重要。这是被…</h3></div><div class="nx l"><p class="bd b dl z fp nu fr fs nv fu fw dk translated">ithinkbot.com</p></div></div><div class="ny l"><div class="nz l oa ob oc ny od jz np"/></div></div></a></div><h1 id="a123" class="mg mh it bd mi mj oe ml mm mn of mp mq mr og mt mu mv oh mx my mz oi nb nc nd bi translated">这是什么意思？</h1><ol class=""><li id="260a" class="oj ok it kh b ki ne km nf kq ol ku om ky on lc oo op oq or bi translated">对新模型进行基准测试是不明确的，可能需要改进</li><li id="71b8" class="oj ok it kh b ki os km ot kq ou ku ov ky ow lc oo op oq or bi translated">LLM可以产生看起来真实的输出(但实际上不是)</li></ol><p id="cd6a" class="pw-post-body-paragraph kf kg it kh b ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc im bi translated">卡拉狄加是实现新事物的一次有价值的尝试！我们从每次失败的实验中学到了有价值的见解。这不是一个痛击深度学习的机会，而是一个回到绘图板、调整和卷起袖子的呼吁。每一次失败的实验都让我们离成功更近一步。</p></div><div class="ab cl lz ma hx mb" role="separator"><span class="mc bw bk md me mf"/><span class="mc bw bk md me mf"/><span class="mc bw bk md me"/></div><div class="im in io ip iq"><p id="1b71" class="pw-post-body-paragraph kf kg it kh b ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc im bi translated">如果这篇文章对你有帮助，请按下“喜欢”按钮来分享你的爱。</p><p id="ae8e" class="pw-post-body-paragraph kf kg it kh b ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc im bi translated">请<a class="ae ly" href="https://ithinkbot.com/membership" rel="noopener ugc nofollow" target="_blank"> <strong class="kh iu"> <em class="lp">成为会员</em></strong></a><em class="lp"/><a class="ae ly" href="https://ithinkbot.com/subscribe" rel="noopener ugc nofollow" target="_blank"><strong class="kh iu"><em class="lp">订阅</em> </strong> </a>获取更多</p></div></div>    
</body>
</html>