<html>
<head>
<title>Decoding the Science Behind Generative Adversarial Networks</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">解码生成性对抗网络背后的科学</h1>
<blockquote>原文：<a href="https://pub.towardsai.net/decoding-science-behind-generative-adversarial-networks-4d188a67d863?source=collection_archive---------3-----------------------#2020-08-13">https://pub.towardsai.net/decoding-science-behind-generative-adversarial-networks-4d188a67d863?source=collection_archive---------3-----------------------#2020-08-13</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><h2 id="4c9b" class="io ip iq bd b dl ir is it iu iv iw dk ix translated" aria-label="kicker paragraph"><a class="ae ep" href="https://towardsai.net/p/category/machine-learning/deep-learning" rel="noopener ugc nofollow" target="_blank">深度学习</a></h2><div class=""/><div class=""><h2 id="d305" class="pw-subtitle-paragraph jw iz iq bd b jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn dk translated">一个假人指南，旨在GANs的艺术伪造！</h2></div><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div role="button" tabindex="0" class="ku kv di kw bf kx"><div class="gh gi ko"><img src="../Images/d298862094be12f65ab674ec45af4568.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*uUnsYGriQdTVz1UEQtu9BA.png"/></div></div></figure><p id="8395" class="pw-post-body-paragraph la lb iq lc b ld le ka lf lg lh kd li lj lk ll lm ln lo lp lq lr ls lt lu lv ij bi translated">去年，生成对抗网络(GANs)凭借那些令人印象深刻的假人类面孔在机器学习领域掀起了风暴。</p><p id="d185" class="pw-post-body-paragraph la lb iq lc b ld le ka lf lg lh kd li lj lk ll lm ln lo lp lq lr ls lt lu lv ij bi translated"><strong class="lc ja">加分* </strong>他们基本上是从无到有产生的。</p><p id="5a76" class="pw-post-body-paragraph la lb iq lc b ld le ka lf lg lh kd li lj lk ll lm ln lo lp lq lr ls lt lu lv ij bi translated">无可辩驳的是，GANs实现了隐式学习方法，其中模型在没有数据直接通过网络的情况下进行学习，不像那些直接从数据中学习权重的显式技术。</p><h1 id="3272" class="lw lx iq bd ly lz ma mb mc md me mf mg kf mh kg mi ki mj kj mk kl ml km mm mn bi translated">直觉</h1><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div role="button" tabindex="0" class="ku kv di kw bf kx"><div class="gh gi mo"><img src="../Images/c9687b3e2f71f47f0b7f134f8f43d417.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*O7tfe_dy4TG9tzO3"/></div></div><figcaption class="mp mq gj gh gi mr ms bd b be z dk translated">照片由<a class="ae mt" href="https://unsplash.com/@robertnyman?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">罗伯特·尼曼</a>在<a class="ae mt" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>拍摄</figcaption></figure><p id="d3f3" class="pw-post-body-paragraph la lb iq lc b ld le ka lf lg lh kd li lj lk ll lm ln lo lp lq lr ls lt lu lv ij bi translated">好的，假设在里约热内卢市，伪造货币的重罪正在增加，因此指定了一个部门来检查这些案件。侦探被期望去区分合法的和伪造的。当官员正确地对假币进行分类时，他们会受到赞赏，当他们犯了错误时，中央银行会提供反馈。现在，每当假货币被破获，伪造者的目标是在市场上流通更好的假货币。这是一个递归的过程，当侦探识别假货币时，伪造者学会了更好的方法来开发更真实的货币，类似地，随着市场上更多假货币的出现，侦探开发出了更好的策略来识别伪造的货币。通过相互学习，侦探和伪造者都会变得更擅长他们的工作。</p><p id="c4ce" class="pw-post-body-paragraph la lb iq lc b ld le ka lf lg lh kd li lj lk ll lm ln lo lp lq lr ls lt lu lv ij bi translated">这是甘斯背后的基本直觉。</p><p id="847c" class="pw-post-body-paragraph la lb iq lc b ld le ka lf lg lh kd li lj lk ll lm ln lo lp lq lr ls lt lu lv ij bi translated">在GANs中，有两个网络鉴别器(侦探)和生成器(伪造者)。生成器旨在创建假数据，而鉴别器则有望破解假数据。递归过程使得生成器和鉴别器都竞争以获得更好的性能。他们相互依赖，因为他们都在彼此的学习过程中发挥着重要作用。</p><p id="e985" class="pw-post-body-paragraph la lb iq lc b ld le ka lf lg lh kd li lj lk ll lm ln lo lp lq lr ls lt lu lv ij bi translated">另一点值得思考的是，两个网络都在不断学习。假设鉴别器错误地将假数据分类为真数据，这将导致生成器学习到当前开发的数据是好数据。但是，这在技术上是错误的，当鉴别器从政府得到同样的反馈时，它将被纠正。</p><h1 id="4a44" class="lw lx iq bd ly lz ma mb mc md me mf mg kf mh kg mi ki mj kj mk kl ml km mm mn bi translated">甘如何学习？</h1><blockquote class="mu mv mw"><p id="0e6d" class="la lb mx lc b ld le ka lf lg lh kd li my lk ll lm mz lo lp lq na ls lt lu lv ij bi translated"><strong class="lc ja">目标</strong>:生成新数据，即新图像、文本、语音等。</p></blockquote><h2 id="ce31" class="nb lx iq bd ly nc nd dn mc ne nf dp mg lj ng nh mi ln ni nj mk lr nk nl mm iw bi translated">生成建模</h2><p id="58b5" class="pw-post-body-paragraph la lb iq lc b ld nm ka lf lg nn kd li lj no ll lm ln np lp lq lr nq lt lu lv ij bi translated">这是一种建模类型，涉及基于给定数据的学习趋势，并尝试生成与提供的数据非常相似的样本。生成式建模的一个非常常见的例子是预测序列数据。</p><p id="a2bb" class="pw-post-body-paragraph la lb iq lc b ld le ka lf lg lh kd li lj lk ll lm ln lo lp lq lr ls lt lu lv ij bi translated">生成模型遵循联合概率分布。</p><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div class="gh gi nr"><img src="../Images/a6ba2eeca4be8d3af7b5ef7ba7d29763.png" data-original-src="https://miro.medium.com/v2/resize:fit:242/format:webp/1*bniXvaCD4Ea5i48X5Szk_g.jpeg"/></div></figure><blockquote class="mu mv mw"><p id="503e" class="la lb mx lc b ld le ka lf lg lh kd li my lk ll lm mz lo lp lq na ls lt lu lv ij bi translated">最终目标是从y中得到X。</p><p id="0a81" class="la lb mx lc b ld le ka lf lg lh kd li my lk ll lm mz lo lp lq na ls lt lu lv ij bi translated"><strong class="lc ja"> P(X，Y) </strong>可以读作变量X <strong class="lc ja">和</strong> Y的概率分布</p></blockquote><h2 id="5918" class="nb lx iq bd ly nc nd dn mc ne nf dp mg lj ng nh mi ln ni nj mk lr nk nl mm iw bi translated">判别建模</h2><p id="a5a6" class="pw-post-body-paragraph la lb iq lc b ld nm ka lf lg nn kd li lj no ll lm ln np lp lq lr nq lt lu lv ij bi translated">这种类型的模型通常包括那些旨在对来自给定趋势的数据进行分类的算法。把一个图像分析成里面的一只猫或者一只狗，可以算是它最好的例子。</p><p id="0e8c" class="pw-post-body-paragraph la lb iq lc b ld le ka lf lg lh kd li lj lk ll lm ln lo lp lq lr ls lt lu lv ij bi translated">而判别模型是对来自给定分布的数据进行判别(分类)的模型。辨别一幅给定的图片中是一只猫还是一只狗，是辨别建模最简单的例子。</p><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div class="gh gi ns"><img src="../Images/eab800c307e8729c92fdc68f3a7dfe96.png" data-original-src="https://miro.medium.com/v2/resize:fit:256/format:webp/1*ovsFzUNkG6p3MNg5ND-DYQ.jpeg"/></div></figure><blockquote class="mu mv mw"><p id="9d48" class="la lb mx lc b ld le ka lf lg lh kd li my lk ll lm mz lo lp lq na ls lt lu lv ij bi translated">最终目标是从x预测Y。</p><p id="5ad6" class="la lb mx lc b ld le ka lf lg lh kd li my lk ll lm mz lo lp lq na ls lt lu lv ij bi translated"><strong class="lc ja"> P(Y|X) </strong>可以看作是“给定事件X已经发生，事件Y发生的概率”。</p></blockquote><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div class="gh gi nt"><img src="../Images/fcd7ab9c39379189e4a1a6377027fc52.png" data-original-src="https://miro.medium.com/v2/resize:fit:1108/format:webp/0*oWJmfIelBU-6PHmK.png"/></div><figcaption class="mp mq gj gh gi mr ms bd b be z dk translated">区别性vs生成性，<a class="ae mt" href="https://developers.google.com/machine-learning/gan/images/generative_v_discriminative.png" rel="noopener ugc nofollow" target="_blank">来源</a></figcaption></figure><blockquote class="nu"><p id="1143" class="nv nw iq bd nx ny nz oa ob oc od lv dk translated">GAN遵循生成模型，因此它的目标是生成<strong class="ak"> P(X，Y) </strong></p></blockquote><h1 id="a87c" class="lw lx iq bd ly lz ma mb mc md me mf mg kf oe kg mi ki of kj mk kl og km mm mn bi translated">模型架构</h1><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div role="button" tabindex="0" class="ku kv di kw bf kx"><div class="gh gi oh"><img src="../Images/d1946a4382af01516a644b252e0c8911.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*G4ld0qOqrgrQ1BM3sH0Ksg.png"/></div></div><figcaption class="mp mq gj gh gi mr ms bd b be z dk translated">典型的甘</figcaption></figure><h2 id="7334" class="nb lx iq bd ly nc nd dn mc ne nf dp mg lj ng nh mi ln ni nj mk lr nk nl mm iw bi translated">噪音</h2><p id="ed4e" class="pw-post-body-paragraph la lb iq lc b ld nm ka lf lg nn kd li lj no ll lm ln np lp lq lr nq lt lu lv ij bi translated">这来自于可以转化为所需数据的随机分布。通过引入噪声，我们使GAN变得更加健壮，从而简化了其过程，使其能够“从目标分布的不同位置采样，产生各种各样的数据。”</p><p id="4955" class="pw-post-body-paragraph la lb iq lc b ld le ka lf lg lh kd li lj lk ll lm ln lo lp lq lr ls lt lu lv ij bi translated">噪声应从高斯分布中取样。</p><h2 id="aea8" class="nb lx iq bd ly nc nd dn mc ne nf dp mg lj ng nh mi ln ni nj mk lr nk nl mm iw bi translated">来自真实分布的数据</h2><p id="0f6b" class="pw-post-body-paragraph la lb iq lc b ld nm ka lf lg nn kd li lj no ll lm ln np lp lq lr nq lt lu lv ij bi translated">这是必需的分布。我们希望GAN在噪声数据的帮助下，生成受这种分布启发的数据。</p><h2 id="2309" class="nb lx iq bd ly nc nd dn mc ne nf dp mg lj ng nh mi ln ni nj mk lr nk nl mm iw bi translated">发电机</h2><p id="9070" class="pw-post-body-paragraph la lb iq lc b ld nm ka lf lg nn kd li lj no ll lm ln np lp lq lr nq lt lu lv ij bi translated">这是GAN的重要组成部分。它侧重于根据分布趋势开发数据。</p><p id="29c0" class="pw-post-body-paragraph la lb iq lc b ld le ka lf lg lh kd li lj lk ll lm ln lo lp lq lr ls lt lu lv ij bi translated">发生器需要对输入数据进行上采样，以产生输出数据。上采样层是一个无权重层，有助于增加输入向量的空间大小。</p><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div class="gh gi oi"><img src="../Images/b22070427292fffca37acf2a617a5e37.png" data-original-src="https://miro.medium.com/v2/resize:fit:1368/format:webp/1*6fXeI87qkfzCRIbs6QS6rQ.png"/></div></figure><p id="1ca3" class="pw-post-body-paragraph la lb iq lc b ld le ka lf lg lh kd li lj lk ll lm ln lo lp lq lr ls lt lu lv ij bi translated">生成器生成的数据会被鉴别器分类为真或假。如果生成的数据与实际数据的相似度较低，那么生成器将被罚款，损失更多，然后使用反向传播，它将试图从其错误中学习，以开发更好的策略来欺骗鉴别器。</p><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div class="gh gi oj"><img src="../Images/1178b6006d51a71a37df029935e950a9.png" data-original-src="https://miro.medium.com/v2/resize:fit:1154/format:webp/1*dnkqDB1hMt7Wc46X8IEzLg.png"/></div><figcaption class="mp mq gj gh gi mr ms bd b be z dk translated">发电机运行，<a class="ae mt" href="https://developers.google.com/machine-learning/gan/generator" rel="noopener ugc nofollow" target="_blank">来源</a></figcaption></figure><p id="7a73" class="pw-post-body-paragraph la lb iq lc b ld le ka lf lg lh kd li lj lk ll lm ln lo lp lq lr ls lt lu lv ij bi translated"><strong class="lc ja">发电机培训:</strong></p><ul class=""><li id="3a5e" class="ok ol iq lc b ld le lg lh lj om ln on lr oo lv op oq or os bi translated">样本随机噪声。</li><li id="03e1" class="ok ol iq lc b ld ot lg ou lj ov ln ow lr ox lv op oq or os bi translated">使用随机噪声产生输出。</li><li id="6f81" class="ok ol iq lc b ld ot lg ou lj ov ln ow lr ox lv op oq or os bi translated">基于鉴别器的分类分析损失。</li><li id="ff3d" class="ok ol iq lc b ld ot lg ou lj ov ln ow lr ox lv op oq or os bi translated">通过鉴别器和发生器反向传播以获得梯度。</li><li id="11af" class="ok ol iq lc b ld ot lg ou lj ov ln ow lr ox lv op oq or os bi translated">使用渐变更新权重。</li></ul><p id="b2e7" class="pw-post-body-paragraph la lb iq lc b ld le ka lf lg lh kd li lj lk ll lm ln lo lp lq lr ls lt lu lv ij bi translated"><strong class="lc ja">目标:</strong>最大限度降低检测出真假数据的概率。</p><p id="282e" class="pw-post-body-paragraph la lb iq lc b ld le ka lf lg lh kd li lj lk ll lm ln lo lp lq lr ls lt lu lv ij bi translated"><strong class="lc ja">接受输入:</strong>随机噪声</p><p id="3491" class="pw-post-body-paragraph la lb iq lc b ld le ka lf lg lh kd li lj lk ll lm ln lo lp lq lr ls lt lu lv ij bi translated"><strong class="lc ja">输出生成:</strong>假数据</p><h2 id="f3a7" class="nb lx iq bd ly nc nd dn mc ne nf dp mg lj ng nh mi ln ni nj mk lr nk nl mm iw bi translated">鉴别器</h2><p id="682f" class="pw-post-body-paragraph la lb iq lc b ld nm ka lf lg nn kd li lj no ll lm ln np lp lq lr nq lt lu lv ij bi translated">它只是一个常规的分类器，试图区分真实数据和虚假数据。它的网络架构取决于它所实现的数据类型，例如，它可能将RNN用于文本数据，将CNN用于图像数据。</p><p id="fa2e" class="pw-post-body-paragraph la lb iq lc b ld le ka lf lg lh kd li lj lk ll lm ln lo lp lq lr ls lt lu lv ij bi translated">它试图增加通道的数量，从而简化了解更多数据特征的过程。</p><p id="9da8" class="pw-post-body-paragraph la lb iq lc b ld le ka lf lg lh kd li lj lk ll lm ln lo lp lq lr ls lt lu lv ij bi translated">鉴别器试图对数据进行分类，它通常忽略生成器的损耗，只实现一个鉴别器的损耗。如果鉴别器用假数据对实际数据进行错误分类，它将被罚款，损失更大，然后使用反向传播，它将试图从错误中学习，以制定更好的策略来欺骗生成器。</p><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div class="gh gi oy"><img src="../Images/a16844ea48082e9d606c55e229431540.png" data-original-src="https://miro.medium.com/v2/resize:fit:1162/format:webp/1*UDbg7Ekf8qF1NhRt7SAjKg.png"/></div><figcaption class="mp mq gj gh gi mr ms bd b be z dk translated">鉴频器操作，<a class="ae mt" href="https://developers.google.com/machine-learning/gan/discriminator" rel="noopener ugc nofollow" target="_blank">源</a></figcaption></figure><p id="c758" class="pw-post-body-paragraph la lb iq lc b ld le ka lf lg lh kd li lj lk ll lm ln lo lp lq lr ls lt lu lv ij bi translated">甄别培训:</p><ul class=""><li id="e629" class="ok ol iq lc b ld le lg lh lj om ln on lr oo lv op oq or os bi translated">将输入数据分类为真或假。</li><li id="e332" class="ok ol iq lc b ld ot lg ou lj ov ln ow lr ox lv op oq or os bi translated">分析错误分类的损失函数。</li><li id="6125" class="ok ol iq lc b ld ot lg ou lj ov ln ow lr ox lv op oq or os bi translated">使用反向传播更新权重。</li></ul><p id="38cc" class="pw-post-body-paragraph la lb iq lc b ld le ka lf lg lh kd li lj lk ll lm ln lo lp lq lr ls lt lu lv ij bi translated">目标:最大化检测真假数据的概率。</p><p id="e166" class="pw-post-body-paragraph la lb iq lc b ld le ka lf lg lh kd li lj lk ll lm ln lo lp lq lr ls lt lu lv ij bi translated">输入:数据(真+假)</p><p id="f6b9" class="pw-post-body-paragraph la lb iq lc b ld le ka lf lg lh kd li lj lk ll lm ln lo lp lq lr ls lt lu lv ij bi translated">输出:数据真假的概率。</p><h2 id="0875" class="nb lx iq bd ly nc nd dn mc ne nf dp mg lj ng nh mi ln ni nj mk lr nk nl mm iw bi translated">训练我们的模型</h2><p id="d3e6" class="pw-post-body-paragraph la lb iq lc b ld nm ka lf lg nn kd li lj no ll lm ln np lp lq lr nq lt lu lv ij bi translated">在训练我们的模型时，必须分别训练两个网络。首先，对鉴别器进行几个步骤的训练，然后将训练转移到生成器。</p><p id="1484" class="pw-post-body-paragraph la lb iq lc b ld le ka lf lg lh kd li lj lk ll lm ln lo lp lq lr ls lt lu lv ij bi translated">如果我们试图同时训练两个网络，这就像瞄准一只飞鸟，因此增加了我们失败的机会。</p><p id="7e3c" class="pw-post-body-paragraph la lb iq lc b ld le ka lf lg lh kd li lj lk ll lm ln lo lp lq lr ls lt lu lv ij bi translated">随着生成器通过训练变得更好，鉴别器的性能受到影响，即它变得难以分类真实和虚假数据。如果发生器完美地成功实现其目标，即最小化检测的概率，鉴别器的精度下降到0.5。降级的不准确性表明discriminator已经将其策略从统计方法转向随机方法。这进一步降低了生成器的准确性，降低了模型的性能。</p><h1 id="52ee" class="lw lx iq bd ly lz ma mb mc md me mf mg kf mh kg mi ki mj kj mk kl ml km mm mn bi translated">GAN型号的类型</h1><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div class="gh gi oz"><img src="../Images/8f01cd9a0b5b3ce1ea7cab60a476a1b6.png" data-original-src="https://miro.medium.com/v2/resize:fit:1060/format:webp/0*a-WJg4NJHWN51KFy.png"/></div><figcaption class="mp mq gj gh gi mr ms bd b be z dk translated">甘斯变奏曲，<a class="ae mt" href="https://insidebigdata.com/wp-content/uploads/2019/09/arXiv_2019_Aug_pic4.png" rel="noopener ugc nofollow" target="_blank">来源</a></figcaption></figure><h1 id="281b" class="lw lx iq bd ly lz ma mb mc md me mf mg kf mh kg mi ki mj kj mk kl ml km mm mn bi translated">结论</h1><p id="df8c" class="pw-post-body-paragraph la lb iq lc b ld nm ka lf lg nn kd li lj no ll lm ln np lp lq lr nq lt lu lv ij bi translated">希望这篇文章能帮助你以尽可能好的方式理解生成对抗网络(GAN ),并帮助你实际运用它。</p><p id="4b10" class="pw-post-body-paragraph la lb iq lc b ld le ka lf lg lh kd li lj lk ll lm ln lo lp lq lr ls lt lu lv ij bi translated">一如既往，非常感谢您的阅读，如果您觉得这篇文章有用，请分享！</p></div><div class="ab cl pa pb hu pc" role="separator"><span class="pd bw bk pe pf pg"/><span class="pd bw bk pe pf pg"/><span class="pd bw bk pe pf"/></div><div class="ij ik il im in"><p id="fcd6" class="pw-post-body-paragraph la lb iq lc b ld le ka lf lg lh kd li lj lk ll lm ln lo lp lq lr ls lt lu lv ij bi translated">请随意连接:</p><blockquote class="mu mv mw"><p id="004f" class="la lb mx lc b ld le ka lf lg lh kd li my lk ll lm mz lo lp lq na ls lt lu lv ij bi translated">领英~<a class="ae mt" href="https://www.linkedin.com/in/dakshtrehan/" rel="noopener ugc nofollow" target="_blank">https://www.linkedin.com/in/dakshtrehan/</a></p><p id="97ee" class="la lb mx lc b ld le ka lf lg lh kd li my lk ll lm mz lo lp lq na ls lt lu lv ij bi translated">insta gram ~<a class="ae mt" href="https://www.instagram.com/_daksh_trehan_/" rel="noopener ugc nofollow" target="_blank">https://www.instagram.com/_daksh_trehan_/</a></p><p id="53e1" class="la lb mx lc b ld le ka lf lg lh kd li my lk ll lm mz lo lp lq na ls lt lu lv ij bi translated">github ~<a class="ae mt" href="https://github.com/dakshtrehan" rel="noopener ugc nofollow" target="_blank">https://github.com/dakshtrehan</a></p></blockquote><p id="b44b" class="pw-post-body-paragraph la lb iq lc b ld le ka lf lg lh kd li lj lk ll lm ln lo lp lq lr ls lt lu lv ij bi translated">关注更多机器学习/深度学习博客。</p><blockquote class="mu mv mw"><p id="63ef" class="la lb mx lc b ld le ka lf lg lh kd li my lk ll lm mz lo lp lq na ls lt lu lv ij bi translated">https://medium.com/@dakshtrehan中型~ <a class="ae mt" href="https://medium.com/@dakshtrehan" rel="noopener"/></p></blockquote><h1 id="d8ee" class="lw lx iq bd ly lz ma mb mc md me mf mg kf mh kg mi ki mj kj mk kl ml km mm mn bi translated">想了解更多？</h1><p id="751d" class="pw-post-body-paragraph la lb iq lc b ld nm ka lf lg nn kd li lj no ll lm ln np lp lq lr nq lt lu lv ij bi translated"><a class="ae mt" href="https://towardsdatascience.com/detecting-covid-19-using-deep-learning-262956b6f981" rel="noopener" target="_blank">利用深度学习检测新冠肺炎</a></p><p id="f06e" class="pw-post-body-paragraph la lb iq lc b ld le ka lf lg lh kd li lj lk ll lm ln lo lp lq lr ls lt lu lv ij bi translated"><a class="ae mt" href="https://towardsdatascience.com/the-inescapable-ai-algorithm-tiktok-ad4c6fd981b8" rel="noopener" target="_blank">无法逃脱的人工智能算法:抖音</a></p><p id="905a" class="pw-post-body-paragraph la lb iq lc b ld le ka lf lg lh kd li lj lk ll lm ln lo lp lq lr ls lt lu lv ij bi translated"><a class="ae mt" href="https://medium.com/towards-artificial-intelligence/an-insiders-guide-to-cartoonization-using-machine-learning-ce3648adfe8" rel="noopener">使用机器学习的卡通化内部指南</a></p><p id="a526" class="pw-post-body-paragraph la lb iq lc b ld le ka lf lg lh kd li lj lk ll lm ln lo lp lq lr ls lt lu lv ij bi translated"><a class="ae mt" href="https://medium.com/@dakshtrehan/why-are-you-responsible-for-george-floyds-murder-delhi-communal-riots-4c1edb7acbc5" rel="noopener">你为什么要为乔治·弗洛伊德的谋杀和德里的社区骚乱负责？</a></p><p id="202e" class="pw-post-body-paragraph la lb iq lc b ld le ka lf lg lh kd li lj lk ll lm ln lo lp lq lr ls lt lu lv ij bi translated"><a class="ae mt" href="https://medium.com/towards-artificial-intelligence/understanding-lstms-and-gru-s-b69749acaa35" rel="noopener">理解LSTM和GRU的</a></p><p id="f643" class="pw-post-body-paragraph la lb iq lc b ld le ka lf lg lh kd li lj lk ll lm ln lo lp lq lr ls lt lu lv ij bi translated"><a class="ae mt" href="https://medium.com/towards-artificial-intelligence/recurrent-neural-networks-for-dummies-8d2c4c725fbe" rel="noopener">用于假人的递归神经网络</a></p><p id="2c32" class="pw-post-body-paragraph la lb iq lc b ld le ka lf lg lh kd li lj lk ll lm ln lo lp lq lr ls lt lu lv ij bi translated"><a class="ae mt" href="https://medium.com/towards-artificial-intelligence/convolutional-neural-networks-for-dummies-afd7166cd9e" rel="noopener">虚拟卷积神经网络</a></p><p id="a8b1" class="pw-post-body-paragraph la lb iq lc b ld le ka lf lg lh kd li lj lk ll lm ln lo lp lq lr ls lt lu lv ij bi translated"><a class="ae mt" href="https://medium.com/towards-artificial-intelligence/diving-deep-into-deep-learning-f34497c18f11" rel="noopener">深入钻研深度学习</a></p><p id="925c" class="pw-post-body-paragraph la lb iq lc b ld le ka lf lg lh kd li lj lk ll lm ln lo lp lq lr ls lt lu lv ij bi translated"><a class="ae mt" href="https://medium.com/towards-artificial-intelligence/why-choose-random-forest-and-not-decision-trees-a28278daa5d" rel="noopener">为什么选择随机森林而不是决策树</a></p><p id="5ccf" class="pw-post-body-paragraph la lb iq lc b ld le ka lf lg lh kd li lj lk ll lm ln lo lp lq lr ls lt lu lv ij bi translated"><a class="ae mt" href="https://medium.com/@dakshtrehan/clustering-what-it-is-when-to-use-it-a612bbe95881" rel="noopener">聚类:是什么？什么时候用？</a></p><p id="1ede" class="pw-post-body-paragraph la lb iq lc b ld le ka lf lg lh kd li lj lk ll lm ln lo lp lq lr ls lt lu lv ij bi translated"><a class="ae mt" href="https://medium.com/@dakshtrehan/start-off-your-ml-journey-with-k-nearest-neighbors-f72a122f428" rel="noopener">从k个最近邻居开始你的ML之旅</a></p><p id="880a" class="pw-post-body-paragraph la lb iq lc b ld le ka lf lg lh kd li lj lk ll lm ln lo lp lq lr ls lt lu lv ij bi translated"><a class="ae mt" href="https://medium.com/swlh/things-you-never-knew-about-naive-bayes-eb84b6ee039a" rel="noopener">朴素贝叶斯解释了</a></p><p id="9a16" class="pw-post-body-paragraph la lb iq lc b ld le ka lf lg lh kd li lj lk ll lm ln lo lp lq lr ls lt lu lv ij bi translated"><a class="ae mt" href="https://medium.com/analytics-vidhya/activation-functions-explained-8690ea7bdec9" rel="noopener">激活功能说明</a></p><p id="6a1b" class="pw-post-body-paragraph la lb iq lc b ld le ka lf lg lh kd li lj lk ll lm ln lo lp lq lr ls lt lu lv ij bi translated"><a class="ae mt" href="https://towardsdatascience.com/parameters-optimization-explained-876561853de0" rel="noopener" target="_blank">参数优化说明</a></p><p id="1ba6" class="pw-post-body-paragraph la lb iq lc b ld le ka lf lg lh kd li lj lk ll lm ln lo lp lq lr ls lt lu lv ij bi translated"><a class="ae mt" href="https://towardsdatascience.com/gradient-descent-explained-9b953fc0d2c" rel="noopener" target="_blank">梯度下降解释</a></p><p id="ecbc" class="pw-post-body-paragraph la lb iq lc b ld le ka lf lg lh kd li lj lk ll lm ln lo lp lq lr ls lt lu lv ij bi translated"><a class="ae mt" href="https://towardsdatascience.com/logistic-regression-explained-ef1d816ea85a" rel="noopener" target="_blank">逻辑回归解释</a></p><p id="01e0" class="pw-post-body-paragraph la lb iq lc b ld le ka lf lg lh kd li lj lk ll lm ln lo lp lq lr ls lt lu lv ij bi translated"><a class="ae mt" href="https://medium.com/towards-artificial-intelligence/linear-regression-explained-f5cc85ae2c5c" rel="noopener">线性回归解释</a></p><p id="b780" class="pw-post-body-paragraph la lb iq lc b ld le ka lf lg lh kd li lj lk ll lm ln lo lp lq lr ls lt lu lv ij bi translated"><a class="ae mt" href="https://medium.com/datadriveninvestor/determining-perfect-fit-for-your-ml-model-339459eef670" rel="noopener">确定最适合您的ML模型</a></p><blockquote class="mu mv mw"><p id="27c5" class="la lb mx lc b ld le ka lf lg lh kd li my lk ll lm mz lo lp lq na ls lt lu lv ij bi translated">干杯！</p></blockquote></div></div>    
</body>
</html>