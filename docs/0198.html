<html>
<head>
<title>Introduction to Federated Learning</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">联邦学习简介</h1>
<blockquote>原文：<a href="https://pub.towardsai.net/introduction-to-federated-learning-bae7ab3766a3?source=collection_archive---------0-----------------------#2019-11-12">https://pub.towardsai.net/introduction-to-federated-learning-bae7ab3766a3?source=collection_archive---------0-----------------------#2019-11-12</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><h1 id="b621" class="jn jo iq bd jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk bi translated">介绍</h1><p id="7785" class="pw-post-body-paragraph kl km iq kn b ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li ij bi translated">任何深度学习模型都从数据中学习，数据必须收集或上传到服务器上(一台机器或数据中心)。一个最现实最有意义的深度学习模型可以从个人数据中学习。个人数据是非常隐私和敏感的，没有人愿意把它发送或上传到服务器上。联合学习是一种合作的机器学习方法，在这种方法中，我们训练了一个模型，而没有将数据集中在服务器上，这是一种主要的革命。</p><p id="2328" class="pw-post-body-paragraph kl km iq kn b ko lj kq kr ks lk ku kv kw ll ky kz la lm lc ld le ln lg lh li ij bi lo translated">如果我们把模型带到数据产生的地方，而不是把数据带到一个地方来训练一个模型，会怎么样？</p><p id="dbc7" class="pw-post-body-paragraph kl km iq kn b ko lj kq kr ks lk ku kv kw ll ky kz la lm lc ld le ln lg lh li ij bi translated">主要使用案例是当我们想要使用来自多个移动设备的数据来重复改进预训练模型时，或者它可以是任何类型的嵌入式设备，如连接到互联网的各种物联网，而无需将数据上传到终端服务器或云。</p><p id="631c" class="pw-post-body-paragraph kl km iq kn b ko lj kq kr ks lk ku kv kw ll ky kz la lm lc ld le ln lg lh li ij bi translated">这真的很有趣，因为这个问题的实际解决方案非常简单。首先，客户端、移动设备获得预训练的模型，然后使用本地数据改进该模型。因此，实际模型在本地设备上进行训练，并将模型发送回服务器。</p><p id="5c60" class="pw-post-body-paragraph kl km iq kn b ko lj kq kr ks lk ku kv kw ll ky kz la lm lc ld le ln lg lh li ij bi translated">服务器结合了它从客户端获得的所有模型。这个组合模型将成为下一个发送给客户的初始模型，我们只需重复这个过程。所有这些设备都受益于每个设备的数据。</p><figure class="lz ma mb mc gt md gh gi paragraph-image"><div role="button" tabindex="0" class="me mf di mg bf mh"><div class="gh gi ly"><img src="../Images/22b52ae3be14d6f772eb4455930caef9.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*HWc5NuExyEaj5mRVKOj8sQ.png"/></div></div><figcaption class="mk ml gj gh gi mm mn bd b be z dk translated"><a class="ae mo" href="https://1.bp.blogspot.com/-K65Ed68KGXk/WOa9jaRWC6I/AAAAAAAABsM/gglycD_anuQSp-i67fxER1FOlVTulvV2gCLcB/s1600/FederatedLearning_FinalFiles_Flow%2BChart1.png" rel="noopener ugc nofollow" target="_blank"> <strong class="bd jp">密学</strong> </a></figcaption></figure><h2 id="1e46" class="mp jo iq bd jp mq mr dn jt ms mt dp jx kw mu mv kb la mw mx kf le my mz kj na bi translated"><strong class="ak">联合学习方法的挑战</strong></h2><ul class=""><li id="a140" class="nb nc iq kn b ko kp ks kt kw nd la ne le nf li ng nh ni nj bi translated"><strong class="kn ir">性能:</strong>如果客户端只有几个训练样本，它仍然可以了解一些数据。如果我们有50，000个客户端，每个客户端都有小数据，他们会花大部分时间来回发送模型，如果模型非常大，他们不会花太多时间训练</li><li id="3a69" class="nb nc iq kn b ko nk ks nl kw nm la nn le no li ng nh ni nj bi translated"><strong class="kn ir">隐私:</strong>通过查看权重的变化，有人可以算出个人数据。因此，如果有人知道了来自权重更新的训练数据，我们就不能使用联合学习。</li></ul><p id="e07f" class="pw-post-body-paragraph kl km iq kn b ko lj kq kr ks lk ku kv kw ll ky kz la lm lc ld le ln lg lh li ij bi translated">为了解决这两个问题，Google开发了一个<a class="ae mo" href="https://eprint.iacr.org/2017/281" rel="noopener ugc nofollow" target="_blank">安全聚合协议</a>，其中的主要思想是服务器生成一个公钥和私钥对，并向每个客户端共享公钥。</p><p id="55d6" class="pw-post-body-paragraph kl km iq kn b ko lj kq kr ks lk ku kv kw ll ky kz la lm lc ld le ln lg lh li ij bi translated">然后，客户端直接相互对话，并使用服务器的公钥共享其加密的更新权重。所有客户端只有服务器共享的公钥，因此任何客户端都无法看到其他权重的更新。</p><p id="6f2b" class="pw-post-body-paragraph kl km iq kn b ko lj kq kr ks lk ku kv kw ll ky kz la lm lc ld le ln lg lh li ij bi translated">所有客户端将其模型的所有权重累积到一个单一的最终更新中，并发送回服务器。然后，服务器使用私钥对其进行解密，并更新服务器的模型权重。在这个过程中，服务器会累积权重，因此服务器也看不到任何特定客户端的权重更新。在这个安全聚合协议中，在服务器进行平均之前，不能检查任何个人电话的更新。服务器可以请求将更新共享给客户端，并且客户端只有在已经与其他客户端同步并且将它们的权重累积到某个阈值|客户端数量| &gt;阈值时才会做出响应。在从客户端获得响应后，服务器用一个私钥重建累积的权重，并计算聚合值。</p><p id="5b89" class="pw-post-body-paragraph kl km iq kn b ko lj kq kr ks lk ku kv kw ll ky kz la lm lc ld le ln lg lh li ij bi translated">一个问题，你可能会问，客户端如何积累加密的权重？答案是同态加密。同态加密允许您对加密值执行计算，而无需解密它们。你可以通过安装<a class="ae mo" href="https://github.com/n1analytics/python-paillier" rel="noopener ugc nofollow" target="_blank"> python-paillier </a>库(pip install phe)自己试试。</p><figure class="lz ma mb mc gt md"><div class="bz fp l di"><div class="np nq l"/></div><figcaption class="mk ml gj gh gi mm mn bd b be z dk translated">Python中的同态加密</figcaption></figure><h1 id="1c54" class="jn jo iq bd jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk bi translated">结论</h1><p id="100d" class="pw-post-body-paragraph kl km iq kn b ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li ij bi translated">使用联合学习，现在我们可以开发一个非常有用和精确的模型，从医疗保健和个人管理等个人数据中学习，这些数据通常被严格锁定，这使得研究很困难。</p><p id="91cb" class="pw-post-body-paragraph kl km iq kn b ko lj kq kr ks lk ku kv kw ll ky kz la lm lc ld le ln lg lh li ij bi translated">我希望这篇文章能够帮助您理解使用用户个人和私有数据的联合学习。我还试图解释用户的数据是如何安全的，没有客户端的深度学习模型可以嗅探用户的敏感数据，甚至服务器的深度学习模型也不能看到用户的敏感数据。</p><h1 id="4231" class="jn jo iq bd jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk bi translated">参考</h1><div class="nr ns gp gr nt nu"><a href="https://ai.googleblog.com/2017/04/federated-learning-collaborative.html" rel="noopener  ugc nofollow" target="_blank"><div class="nv ab fo"><div class="nw ab nx cl cj ny"><h2 class="bd ir gy z fp nz fr fs oa fu fw ip bi translated">联合学习:没有集中训练数据的协作机器学习</h2><div class="ob l"><h3 class="bd b gy z fp nz fr fs oa fu fw dk translated">标准的机器学习方法需要将训练数据集中在一台机器或数据中心。还有…</h3></div><div class="oc l"><p class="bd b dl z fp nz fr fs oa fu fw dk translated">ai.googleblog.com</p></div></div><div class="od l"><div class="oe l of og oh od oi mi nu"/></div></div></a></div><div class="nr ns gp gr nt nu"><a href="https://ai.google/research/pubs/pub45808" rel="noopener  ugc nofollow" target="_blank"><div class="nv ab fo"><div class="nw ab nx cl cj ny"><h2 class="bd ir gy z fp nz fr fs oa fu fw ip bi translated">基于用户持有数据的联邦学习的实用安全聚合——Google AI</h2><div class="ob l"><h3 class="bd b gy z fp nz fr fs oa fu fw dk translated">安全聚合是一类安全的多方计算算法，其中一组相互不信任的成员…</h3></div><div class="oc l"><p class="bd b dl z fp nz fr fs oa fu fw dk translated">ai.google</p></div></div><div class="od l"><div class="oj l of og oh od oi mi nu"/></div></div></a></div></div></div>    
</body>
</html>