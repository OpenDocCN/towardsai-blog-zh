<html>
<head>
<title>Overview Of Vision Transformers Is All You Need</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">视觉变形金刚概述是你所需要的</h1>
<blockquote>原文：<a href="https://pub.towardsai.net/overview-of-vision-transformers-is-all-you-need-88727438ff8d?source=collection_archive---------0-----------------------#2022-09-10">https://pub.towardsai.net/overview-of-vision-transformers-is-all-you-need-88727438ff8d?source=collection_archive---------0-----------------------#2022-09-10</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="103e" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">变形金刚如何成为计算机视觉的下一个突破？</h2></div><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ki"><img src="../Images/9984e8acbd8b5da9c61248067b4ce37b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*U06ICQtQEDC11WMbCtLBwA.jpeg"/></div></div><figcaption class="ku kv gj gh gi kw kx bd b be z dk translated">约书亚·厄尔在<a class="ae ky" href="https://unsplash.com/s/photos/overview?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上的照片</figcaption></figure><p id="a3a3" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">深度学习的<strong class="lb iu">变形金刚</strong>历史上，一切都始于2017年的那篇著名论文<a class="ae ky" href="https://arxiv.org/abs/1706.03762" rel="noopener ugc nofollow" target="_blank"><strong class="lb iu">‘注意力是你所需要的全部</strong></a><strong class="lb iu">’</strong>。谷歌大脑团队发表了他们的研究，通过使用<strong class="lb iu">转换器</strong>改变了<strong class="lb iu">自然语言处理</strong>的命运。</p><p id="9981" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><em class="lv">在图像上使用相同技术的想法可能开启了视觉技术的新时代……</em></p><blockquote class="lw lx ly"><p id="10a5" class="kz la lv lb b lc ld ju le lf lg jx lh lz lj lk ll ma ln lo lp mb lr ls lt lu im bi translated">一、<strong class="lb iu">简介</strong></p></blockquote><ul class=""><li id="8cb5" class="mc md it lb b lc ld lf lg li me lm mf lq mg lu mh mi mj mk bi translated">在这篇文章中，我根据我的研究准备了一份视觉变形金刚的概述。在我的学习过程中，我总结了一些笔记来回答这些问题来理解变形金刚。</li></ul><p id="08dd" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><strong class="lb iu"> — — <em class="lv">什么是Transformer，为什么要用在深度学习中？</em> </strong></p><p id="1475" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><strong class="lb iu"> — — <em class="lv">为什么以及如何将Transformer应用于视觉？</em> </strong></p><p id="304f" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><strong class="lb iu"> — — <em class="lv">视觉变形金刚和CNN有什么区别？</em> </strong></p><p id="7ebb" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><strong class="lb iu">——<em class="lv">Transformer如何用于物体检测？</em> </strong></p><p id="ad1c" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">视觉变形金刚准备好生产了吗？ </p><ul class=""><li id="a8f3" class="mc md it lb b lc ld lf lg li me lm mf lq mg lu mh mi mj mk bi translated">这些笔记会很有用，特别是对于那些经常听变形金刚但还不能开始的人。让我们开始…</li></ul><blockquote class="lw lx ly"><p id="ccb9" class="kz la lv lb b lc ld ju le lf lg jx lh lz lj lk ll ma ln lo lp mb lr ls lt lu im bi translated"><strong class="lb iu"> <em class="it">什么是Transformer，为什么要用在深度学习中？</em> </strong></p></blockquote><ul class=""><li id="ebed" class="mc md it lb b lc ld lf lg li me lm mf lq mg lu mh mi mj mk bi translated"><strong class="lb iu"> Transformer </strong>，一种基于<strong class="lb iu">注意力</strong>机制的新模型架构，于2017年由一些研究人员和谷歌大脑团队在论文<strong class="lb iu">‘注意力是你所需要的全部’</strong>中首次提出。</li><li id="5cd0" class="mc md it lb b lc ml lf mm li mn lm mo lq mp lu mh mi mj mk bi translated">在那之前，<strong class="lb iu">递归神经网络(RNN) </strong>、<strong class="lb iu">长短期记忆(LSTM) </strong>和<strong class="lb iu">门控递归网络</strong>大多被用作<strong class="lb iu">自然语言处理</strong>应用中的最新网络，因为它们能够找到序列数据的信息。然而，这些网络在NLP任务中有一些主要的缺点。</li></ul><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi mq"><img src="../Images/410e0cd602879146fa9e3849390693e7.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*uKB2F3DZxA2UYITWuOpqJw.png"/></div></div><figcaption class="ku kv gj gh gi kw kx bd b be z dk translated">RNN建筑公司。来源:<a class="ae ky" href="https://stanford.edu/~shervine/teaching/cs-230/cheatsheet-recurrent-neural-networks" rel="noopener ugc nofollow" target="_blank">https://Stanford . edu/~ shervine/teaching/cs-230/cheat sheet-recurrent-neural-networks</a></figcaption></figure><ul class=""><li id="55c1" class="mc md it lb b lc ld lf lg li me lm mf lq mg lu mh mi mj mk bi translated">它们不足以从文本数据中理解全局意义，因为它是顺序处理的。正如您在上面的传统<strong class="lb iu"> RNN架构</strong>的图片中所看到的，每个时间戳的输出都必须作为输入提供给下一个时间戳。这导致了<strong class="lb iu">短时记忆</strong>，也阻止了<strong class="lb iu">平行训练</strong>。即使<strong class="lb iu"> LSTM </strong>可以增加内存容量，但这还不够，而且计算量仍然很大。</li><li id="1a1d" class="mc md it lb b lc ml lf mm li mn lm mo lq mp lu mh mi mj mk bi translated">另一方面，<strong class="lb iu"> Transformer </strong>尤其是它的<strong class="lb iu">注意力机制</strong>在<strong class="lb iu"> NLP </strong>任务上创造了突破。OpenAI的<strong class="lb iu"> GPT-3 </strong>模型和谷歌的<strong class="lb iu">伯特</strong>模型是这一突破的最大例子。</li></ul><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi mr"><img src="../Images/457260f901db17b42c31a5f2b7d37765.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*qoFGiRNdbWUyKD6RcTqU0w.png"/></div></div><figcaption class="ku kv gj gh gi kw kx bd b be z dk translated">谷歌的BERT例子。来源:<a class="ae ky" href="https://blog.google/products/search/search-language-understanding-bert/" rel="noopener ugc nofollow" target="_blank">https://blog . Google/products/search/search-language-understanding-Bert/</a></figcaption></figure><ul class=""><li id="65af" class="mc md it lb b lc ld lf lg li me lm mf lq mg lu mh mi mj mk bi translated"><strong class="lb iu">变压器</strong> <strong class="lb iu">架构</strong>的主要部分由<strong class="lb iu">编码器</strong>和<strong class="lb iu">解码器</strong>组成。<strong class="lb iu">变形金刚</strong>一次性将所有输入，如一个句子，作为嵌入，而<strong class="lb iu"> RNN </strong>和<strong class="lb iu"> LSTM </strong>模型逐字输入。并且这些嵌入在<strong class="lb iu">关注块</strong>中被处理。</li><li id="6653" class="mc md it lb b lc ml lf mm li mn lm mo lq mp lu mh mi mj mk bi translated"><strong class="lb iu">关注块</strong>的目的是提取输入句子的单词之间的关系/依存关系。因此，这些特征有助于获得对上下文的<strong class="lb iu">全局理解</strong>。除了<strong class="lb iu">注意机制</strong>和<strong class="lb iu">嵌入</strong>、<strong class="lb iu">层模型</strong>、<strong class="lb iu">前馈网络</strong>和<strong class="lb iu"> softmax函数</strong>也在该网络中使用。</li></ul><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi ms"><img src="../Images/22c9a28498cdb6b8383bee8cdb5b4668.png" data-original-src="https://miro.medium.com/v2/resize:fit:1056/format:webp/1*oOARpS3YcGzPRi90JcXOFg.png"/></div><figcaption class="ku kv gj gh gi kw kx bd b be z dk translated">变压器模型架构。来源:<a class="ae ky" href="https://arxiv.org/pdf/1706.03762.pdf" rel="noopener ugc nofollow" target="_blank">https://arxiv.org/pdf/1706.03762.pdf</a></figcaption></figure><ul class=""><li id="4626" class="mc md it lb b lc ld lf lg li me lm mf lq mg lu mh mi mj mk bi translated">我不打算解释关于模型架构的所有细节，但我应该提到的是<strong class="lb iu">注意力区块</strong>是<strong class="lb iu">变形金刚</strong>最关键的部分。我们将在下一部分更详细地看到相同的架构。上面可以看到<strong class="lb iu">变压器</strong>的模型架构。关于该模型的进一步解释可以在该研究的官方论文中找到。</li></ul><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi mt"><img src="../Images/999dc87795b443065c32a0bdfac9d222.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*mMbtT7LA-CsTg4SzizZYrg.png"/></div></div><figcaption class="ku kv gj gh gi kw kx bd b be z dk translated">注意力可视化。来源:<a class="ae ky" href="https://arxiv.org/pdf/1706.03762.pdf" rel="noopener ugc nofollow" target="_blank">https://arxiv.org/pdf/1706.03762.pdf</a></figcaption></figure><ul class=""><li id="c05f" class="mc md it lb b lc ld lf lg li me lm mf lq mg lu mh mi mj mk bi translated">在上面的<strong class="lb iu">注意机制</strong>的例子中，你可以看到<strong class="lb iu">长距离依赖</strong>在网络的<strong class="lb iu">编码器</strong>部分。您在此看到的所有<strong class="lb iu">注意事项</strong>仅为工作<strong class="lb iu">【制作】</strong>显示。每种不同的颜色也代表不同的<strong class="lb iu">注意力头</strong>。令人印象深刻的是，许多注意力集中在<strong class="lb iu">、</strong>、<strong class="lb iu">、【更多】、<strong class="lb iu">、【困难】、</strong>之间。</strong></li></ul><blockquote class="lw lx ly"><p id="129c" class="kz la lv lb b lc ld ju le lf lg jx lh lz lj lk ll ma ln lo lp mb lr ls lt lu im bi translated"><strong class="lb iu"> <em class="it">为什么以及如何将Transformer应用于视觉？</em> </strong></p></blockquote><ul class=""><li id="9cc3" class="mc md it lb b lc ld lf lg li me lm mf lq mg lu mh mi mj mk bi translated">正如我提到的，<strong class="lb iu">注意机构</strong>是<strong class="lb iu">变形金刚</strong>的心脏。这使得<strong class="lb iu">变形金刚</strong>成为NLP任务事实上的标准。从<strong class="lb iu">局部</strong>到<strong class="lb iu">全局理解</strong>…像人类一样。</li><li id="b514" class="mc md it lb b lc ml lf mm li mn lm mo lq mp lu mh mi mj mk bi translated">2020年，谷歌研究和大脑团队在图像上使用了几乎相同的技术，他们表明，对<strong class="lb iu">CNN</strong>的依赖是不必要的，直接应用于图像补丁序列的纯<strong class="lb iu">转换器</strong>可以在<strong class="lb iu">图像分类</strong>任务上表现得非常好。他们在名为<a class="ae ky" href="https://arxiv.org/pdf/2010.11929.pdf" rel="noopener ugc nofollow" target="_blank"><strong class="lb iu">‘一张图像抵得上16×16个字’</strong></a>的论文中发表了他们的研究。</li></ul><p id="b6a3" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><strong class="lb iu">视觉变压器</strong>型号可在下面查看。让我解释一下这个模型是如何工作的。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi mu"><img src="../Images/4cfff4b592711396c9c94a59f05b8efb.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*npXur681uiYILWJINh2rqQ.png"/></div></div><figcaption class="ku kv gj gh gi kw kx bd b be z dk translated">模型概述。来源:<a class="ae ky" href="https://arxiv.org/pdf/2010.11929.pdf" rel="noopener ugc nofollow" target="_blank">https://arxiv.org/pdf/2010.11929.pdf</a></figcaption></figure><ul class=""><li id="aa22" class="mc md it lb b lc ld lf lg li me lm mf lq mg lu mh mi mj mk bi translated">整个过程的第一步是<strong class="lb iu">将<strong class="lb iu">图像</strong>拆分</strong>成<strong class="lb iu">固定大小的面片</strong>、<strong class="lb iu">展平</strong>它们，然后线性<strong class="lb iu">嵌入</strong>它们每一个。你可以在<strong class="lb iu"> NLP </strong>中把这些小块想象成单词，把整个图像想象成一个句子。</li></ul><p id="afef" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><em class="lv">你可能会问为什么我们不把所有的像素都当成面片。这个问题的第一个答案与</em> <strong class="lb iu"> <em class="lv">计算复杂度</em> </strong> <em class="lv">有关。如果我们把每一个像素看作一个面片，那么</em> <strong class="lb iu"> <em class="lv">注意机制</em> </strong> <em class="lv">的复杂度会非常高。此外，图像不同角落或侧面的像素彼此之间没有有意义的关系。因此，网络没有必要额外关注。</em></p><ul class=""><li id="a590" class="mc md it lb b lc ld lf lg li me lm mf lq mg lu mh mi mj mk bi translated">下一步是将位置嵌入添加到面片嵌入中。然后，<strong class="lb iu">变压器</strong>编码器由嵌入的结果序列馈送。</li></ul><p id="6129" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><em class="lv">在说变压器编码器之前，我想提一点。如果你意识到我们把</em> <strong class="lb iu"> <em class="lv">面片</em> </strong> <em class="lv">和它们的</em> <strong class="lb iu"> <em class="lv">位置</em> </strong> <em class="lv">组合起来。但是，没有关于</em> <strong class="lb iu"> <em class="lv">像素</em> </strong> <em class="lv">位置的信息。</em></p><p id="b9ac" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><em class="lv">有研究试图通过将补丁分成更小的补丁来解决这个问题。此外，本研究的作者在ImageNet上实现了81%的top-1准确率</em><strong class="lb iu"><em class="lv"/></strong><em class="lv">。这比具有类似计算成本的最先进的视觉变压器高大约1.7%。他们称自己的框架为</em> <a class="ae ky" href="https://arxiv.org/abs/2103.00112" rel="noopener ugc nofollow" target="_blank"> <strong class="lb iu"> <em class="lv">【变压器中的变压器(TNT) </em> </strong> </a> <em class="lv">。你可以在下面看到他们的模型，并查看他们的论文了解详情。</em></p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi mv"><img src="../Images/2218610817325432f11e1af6d1f168a4.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*KTmnrFZXE6hjMwGhfR993w.png"/></div></div><figcaption class="ku kv gj gh gi kw kx bd b be z dk translated">TNT框架。来源:<a class="ae ky" href="https://arxiv.org/pdf/2103.00112.pdf" rel="noopener ugc nofollow" target="_blank">https://arxiv.org/pdf/2103.00112.pdf</a></figcaption></figure><p id="1806" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">让我们继续从<strong class="lb iu">视觉</strong> <strong class="lb iu">变压器编码器……</strong></p><ul class=""><li id="04b8" class="mc md it lb b lc ld lf lg li me lm mf lq mg lu mh mi mj mk bi translated"><strong class="lb iu">变压器编码器</strong>包括<strong class="lb iu">多头自关注(MSA)、MLP块</strong>和<strong class="lb iu">层形态(LN) </strong>。</li><li id="f98e" class="mc md it lb b lc ml lf mm li mn lm mo lq mp lu mh mi mj mk bi translated"><strong class="lb iu"> MSA </strong>的目的是像在<strong class="lb iu"> NLP </strong>中一样在<strong class="lb iu">补丁</strong>之间抽取<strong class="lb iu">注意力</strong>。在图像的每个补丁之后，<strong class="lb iu">自我关注度</strong>将评估该补丁与图像的其他补丁之间的<strong class="lb iu">关注度</strong>。别忘了，我们把这种<strong class="lb iu">注意机制</strong> <strong class="lb iu">叫做多头自我注意</strong>，每个头都有一个<strong class="lb iu">注意模式</strong>。</li><li id="ca25" class="mc md it lb b lc ml lf mm li mn lm mo lq mp lu mh mi mj mk bi translated"><strong class="lb iu"> Layernorm(LN) </strong>在每个块之前使用，<strong class="lb iu">剩余连接</strong>在每个块之后应用。</li><li id="72b6" class="mc md it lb b lc ml lf mm li mn lm mo lq mp lu mh mi mj mk bi translated"><strong class="lb iu"> MLP </strong>用于实现架构的<strong class="lb iu">分类头</strong>。MLP由预训练时的一个<strong class="lb iu">隐层</strong>和微调时的一个<strong class="lb iu">单线层</strong>组成。</li></ul><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi mw"><img src="../Images/24da578582baab8500a0ee47ca9c6ddd.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*uDoqlTc9RTHQEzFeuz45rw.png"/></div></div><figcaption class="ku kv gj gh gi kw kx bd b be z dk translated">注意地图示例。来源:<a class="ae ky" href="https://arxiv.org/pdf/2010.11929.pdf" rel="noopener ugc nofollow" target="_blank">https://arxiv.org/pdf/2010.11929.pdf</a></figcaption></figure><ul class=""><li id="89a9" class="mc md it lb b lc ld lf lg li me lm mf lq mg lu mh mi mj mk bi translated">你可以在上面的<strong class="lb iu">图片</strong>中看到<strong class="lb iu">注意机制</strong>是如何工作的。你还记得显示<strong class="lb iu">注意力头</strong>如何在<strong class="lb iu"> NLP </strong>中工作的例子吗？就像在那里，你看到我们在所有的<strong class="lb iu">注意力</strong>头被组合起来之后得到了什么。</li></ul><p id="59c1" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">你可以在他们的<a class="ae ky" href="https://github.com/google-research/vision_transformer" rel="noopener ugc nofollow" target="_blank"> GitHub库</a>上找到谷歌大脑团队的最新发展和模型。关于<strong class="lb iu">视觉转换器</strong>的详细实现和解释可以在那里找到。</p><blockquote class="lw lx ly"><p id="da6b" class="kz la lv lb b lc ld ju le lf lg jx lh lz lj lk ll ma ln lo lp mb lr ls lt lu im bi translated"><strong class="lb iu"><em class="it">CNN和视觉变形金刚的主要区别是什么？</em>T49】</strong></p></blockquote><ul class=""><li id="247c" class="mc md it lb b lc ld lf lg li me lm mf lq mg lu mh mi mj mk bi translated"><strong class="lb iu">视觉变压器</strong>在图像上的<strong class="lb iu">感应偏差</strong>比<strong class="lb iu"> CNNs </strong>小。2007年，<strong class="lb iu"> Geoffrey Hinton </strong>说CNN的一个主要问题来自于网络中的<strong class="lb iu">池层</strong>。这些层导致部分图像和整个图像的重要信息的损失。这也导致图像不同部分之间失去联系，并使<strong class="lb iu">局部理解</strong>图像。然而，T <strong class="lb iu">转换器</strong>的<strong class="lb iu">自我关注层</strong>是<strong class="lb iu">全局的，</strong>它带给它们<strong class="lb iu">全局的理解</strong>。</li><li id="6618" class="mc md it lb b lc ml lf mm li mn lm mo lq mp lu mh mi mj mk bi translated">根据<strong class="lb iu">视觉变形金刚的官方论文，</strong>在<strong class="lb iu">CNN</strong>和<strong class="lb iu">视觉变形金刚</strong>之间可以观察到不同的对比。</li><li id="d882" class="mc md it lb b lc ml lf mm li mn lm mo lq mp lu mh mi mj mk bi translated"><strong class="lb iu"> CNN </strong>与<strong class="lb iu">变形金刚</strong>相比，使用<strong class="lb iu">更少的数据量</strong>效果更好，如下图所示。主要原因来自于有这个<strong class="lb iu">感应偏置</strong>。然而，如果<strong class="lb iu">变形金刚</strong>可以被<strong class="lb iu">大</strong> <strong class="lb iu">数据量</strong>馈入，那么它们会用<strong class="lb iu">全局方法带来更好的结果，</strong>相反<strong class="lb iu"> Cnn的</strong>受限能力因为<strong class="lb iu">局部敏感性</strong>。</li></ul><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi mx"><img src="../Images/eb171c209827510cfc27833e9d32fa10.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*_gqeVgo0Za_rtDTut3JxzA.png"/></div></div><figcaption class="ku kv gj gh gi kw kx bd b be z dk translated">性能比较。<a class="ae ky" href="https://arxiv.org/pdf/2010.11929.pdf" rel="noopener ugc nofollow" target="_blank">https://arxiv.org/pdf/2010.11929.pdf</a></figcaption></figure><ul class=""><li id="dc42" class="mc md it lb b lc ld lf lg li me lm mf lq mg lu mh mi mj mk bi translated">另外，当比较<strong class="lb iu">内存效率</strong>时，特别是<strong class="lb iu">大视野变压器</strong>型号比<strong class="lb iu"> ResNet </strong>型号内存效率更高。</li></ul><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi my"><img src="../Images/08473099f84f5c64648281cdc76c80d4.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*1V4-oYk9M-NzowpLOqiBUg.png"/></div></div><figcaption class="ku kv gj gh gi kw kx bd b be z dk translated">性能比较。<a class="ae ky" href="https://arxiv.org/pdf/2010.11929.pdf" rel="noopener ugc nofollow" target="_blank">https://arxiv.org/pdf/2010.11929.pdf</a></figcaption></figure><ul class=""><li id="2574" class="mc md it lb b lc ld lf lg li me lm mf lq mg lu mh mi mj mk bi translated">当针对不同架构比较预训练<strong class="lb iu">计算性能</strong>时，<strong class="lb iu">视觉变形器</strong>通常在相同的<strong class="lb iu">计算预算</strong>下<strong class="lb iu">超过</strong>结果。然而，<strong class="lb iu">混合</strong>模型为较小的模型尺寸带来了更好的结果。</li></ul><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi mz"><img src="../Images/f66ac0b2a59371ee86a93867f16e7f6f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*ILJ7mkwcdv5AE3EIGfpPYQ.png"/></div></div><figcaption class="ku kv gj gh gi kw kx bd b be z dk translated">总预训练计算[exaFLOPS]。来源:<a class="ae ky" href="https://arxiv.org/pdf/2010.11929.pdf" rel="noopener ugc nofollow" target="_blank">https://arxiv.org/pdf/2010.11929.pdf</a></figcaption></figure><p id="e97e" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><strong class="lb iu"> <em class="lv">混动车型</em> </strong> <em class="lv">不在本帖解释。我在下一部分只讲了</em> <strong class="lb iu"> <em class="lv"> DETR框架</em> </strong> <em class="lv">。从名字就可以理解，混动车型是</em> <strong class="lb iu"> <em class="lv">变形金刚</em> </strong> <em class="lv">和</em><strong class="lb iu"><em class="lv">CNN</em></strong><em class="lv">的组合。这个话题将是下一篇文章的主题。</em></p><ul class=""><li id="a200" class="mc md it lb b lc ld lf lg li me lm mf lq mg lu mh mi mj mk bi translated">这两种方法的另一个区别是<strong class="lb iu">视觉变形金刚</strong>能够学习<strong class="lb iu">有意义的信息</strong>，即使在<strong class="lb iu">最底层</strong>。<strong class="lb iu">CNN</strong>能够在最后一层提取<strong class="lb iu">高层</strong>信息。通过比较来自<strong class="lb iu">变形金刚</strong>的可视化<strong class="lb iu">注意力图</strong>和来自<strong class="lb iu">CNN</strong>的<strong class="lb iu">权重</strong>可以观察到这些差异</li></ul><blockquote class="lw lx ly"><p id="2e48" class="kz la lv lb b lc ld ju le lf lg jx lh lz lj lk ll ma ln lo lp mb lr ls lt lu im bi translated"><strong class="lb iu"> <em class="it">变形金刚中的物体检测</em> </strong></p></blockquote><p id="376b" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><strong class="lb iu">物体检测</strong>是计算机视觉的主要<strong class="lb iu">任务之一，我认为是工程师和我使用最多的任务之一。这就是为什么我插入了两个著名的<strong class="lb iu">物体检测</strong>方法，它们在管道中使用了<strong class="lb iu">变压器</strong>。</strong></p><p id="c4f1" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><strong class="lb iu"> <em class="lv">【检测变压器(DETR)】</em></strong></p><ul class=""><li id="ec16" class="mc md it lb b lc ld lf lg li me lm mf lq mg lu mh mi mj mk bi translated">2020年，<strong class="lb iu">脸书</strong>出版<strong class="lb iu"> DETR </strong>。他们已经发布了第一个<strong class="lb iu">物体检测</strong>框架，使用<strong class="lb iu">转换器</strong>作为检测流水线中的核心构件。<strong class="lb iu">CNN</strong>也被用在了这条管道上。此外，这项研究的作者已经取得了比<strong class="lb iu">更快的R-CNN </strong>更有竞争力的结果。</li></ul><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi na"><img src="../Images/d984b448d4e02126e41571e5d705c3b7.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*zF23iKqrw5rwUBrXnVjoPg.png"/></div></div><figcaption class="ku kv gj gh gi kw kx bd b be z dk translated">DETR管道公司。来源:<a class="ae ky" href="https://arxiv.org/abs/2005.12872" rel="noopener ugc nofollow" target="_blank">https://arxiv.org/abs/2005.12872</a></figcaption></figure><ul class=""><li id="3d3d" class="mc md it lb b lc ld lf lg li me lm mf lq mg lu mh mi mj mk bi translated"><strong class="lb iu">脸书的DETR </strong>就是<strong class="lb iu">混动</strong>车型的一个很好的例子。它由<strong class="lb iu"> CNN </strong>、<strong class="lb iu">变压器编解码</strong>和<strong class="lb iu">前馈网络</strong>组成。</li><li id="4c8a" class="mc md it lb b lc ml lf mm li mn lm mo lq mp lu mh mi mj mk bi translated"><strong class="lb iu"> CNN主干</strong>用于提取图像的<strong class="lb iu">特征</strong>，而不是将输入图像分割成小块。这些<strong class="lb iu">特征</strong>是<strong class="lb iu">变平</strong>和<strong class="lb iu">组合</strong>与<strong class="lb iu">位置编码</strong>。</li><li id="18c4" class="mc md it lb b lc ml lf mm li mn lm mo lq mp lu mh mi mj mk bi translated"><strong class="lb iu">变压器编码器</strong>将这组图像<strong class="lb iu">特征</strong>作为一个序列。正如我们之前看到的，<strong class="lb iu">变压器</strong>编码器包括一个<strong class="lb iu">多头自关注</strong>模块、<strong class="lb iu">规格化器、</strong>和<strong class="lb iu">前馈网络</strong>。在这个网络中，<strong class="lb iu">位置编码</strong>也是固定的。</li></ul><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi nb"><img src="../Images/d2dbbdfd5a37eadce92a5b0ba04e543d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*CFIRKpmVyWTmkBAlazcRdQ.png"/></div></div><figcaption class="ku kv gj gh gi kw kx bd b be z dk translated">编码器自我关注。来源:https://arxiv.org/abs/2005.12872</figcaption></figure><ul class=""><li id="34ab" class="mc md it lb b lc ld lf lg li me lm mf lq mg lu mh mi mj mk bi translated">正如你在上面看到的，多亏了<strong class="lb iu">注意机制，变形金刚编码器</strong>甚至能够在模型的最后一个<strong class="lb iu">编码器层</strong>分离物体。</li><li id="8256" class="mc md it lb b lc ml lf mm li mn lm mo lq mp lu mh mi mj mk bi translated">在<strong class="lb iu">解码器</strong>部分，机制与<strong class="lb iu">原变压器</strong>几乎相同。唯一的区别是，该模型在每个<strong class="lb iu">解码器层</strong>并行解码<strong class="lb iu">‘N’个嵌入</strong>。这些嵌入来自<strong class="lb iu">编码器</strong>部分，也被称为“<strong class="lb iu">对象查询</strong>”。这“N”个对象被转换成嵌入并被发送到<strong class="lb iu">前馈网络</strong>。</li><li id="3da1" class="mc md it lb b lc ml lf mm li mn lm mo lq mp lu mh mi mj mk bi translated"><strong class="lb iu">前馈网络</strong>用于<strong class="lb iu">预测</strong>问题。来自<strong class="lb iu">变压器解码器</strong>的嵌入输出被发送到这些网络。然后，他们预测一个<strong class="lb iu">检测</strong>(类和边界框)或者一个<strong class="lb iu">‘无对象’</strong>类。你可以把这个类想象成标准物体检测模型中的<strong class="lb iu">‘背景’类</strong>。</li></ul><p id="2096" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><strong class="lb iu">代码</strong>和<strong class="lb iu">预训练模型</strong>可以在本作官方<a class="ae ky" href="https://github.com/facebookresearch/detr" rel="noopener ugc nofollow" target="_blank"> GitHub库</a>中找到。</p><p id="4e73" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><strong class="lb iu">你只看一个序列(YOLOS) </strong></p><ul class=""><li id="472a" class="mc md it lb b lc ld lf lg li me lm mf lq mg lu mh mi mj mk bi translated"><strong class="lb iu"> YOLOS </strong>是<strong class="lb iu">视觉转换器</strong>的优化版本，用于<strong class="lb iu">物体检测</strong>任务。因为这种方法没有被设计成高性能的对象检测器。它的性能对未来的发展是有希望的。</li></ul><p id="fbbe" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><strong class="lb iu"> YOLOS </strong>架构与最初的<strong class="lb iu">视觉转换器</strong>方案非常相似，如下图所示。你注意到有<strong class="lb iu">【Pat-Tok】</strong><strong class="lb iu">【PE】</strong><strong class="lb iu">【Det-Tok】</strong>。</p><ul class=""><li id="c993" class="mc md it lb b lc ld lf lg li me lm mf lq mg lu mh mi mj mk bi translated"><strong class="lb iu">‘Pat-Tok’</strong>定义一个展平的<strong class="lb iu">图像补片</strong>的嵌入。<strong class="lb iu">‘PE’</strong>表示<strong class="lb iu">位置嵌入，</strong>和<strong class="lb iu">‘Det-Tok’</strong>定义了对象绑定的可学习嵌入。</li><li id="5366" class="mc md it lb b lc ml lf mm li mn lm mo lq mp lu mh mi mj mk bi translated">在架构上，<strong class="lb iu">视觉转换器</strong>和<strong class="lb iu"> YOLOS </strong>的第一个区别是有100个随机初始化的可学习<strong class="lb iu">检测令牌(' Det-Tok') </strong>，而不是使用一个可学习的<strong class="lb iu">类令牌</strong>，后者用于<strong class="lb iu">分类</strong>。</li><li id="65db" class="mc md it lb b lc ml lf mm li mn lm mo lq mp lu mh mi mj mk bi translated">架构的主体部分与<strong class="lb iu">视觉转换器</strong> <strong class="lb iu">编码器</strong>相同。每个变压器编码器层包括一个<strong class="lb iu">多头自关注块</strong>、<strong class="lb iu">层名</strong>和<strong class="lb iu"> MLP </strong>块，如我们在前面部分中所述。</li><li id="8c08" class="mc md it lb b lc ml lf mm li mn lm mo lq mp lu mh mi mj mk bi translated"><strong class="lb iu"> MLP </strong>头像用于<strong class="lb iu">实现</strong>分类<strong class="lb iu">和</strong>包围盒回归。</li></ul><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi nc"><img src="../Images/61359e5d15679836515563befd773f56.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*rX-ve7ca7CmeK03LByAmsw.png"/></div></div><figcaption class="ku kv gj gh gi kw kx bd b be z dk translated">YOLOS架构概述。来源:<a class="ae ky" href="https://arxiv.org/pdf/2106.00666.pdf" rel="noopener ugc nofollow" target="_blank">https://arxiv.org/pdf/2106.00666.pdf</a></figcaption></figure><ul class=""><li id="f298" class="mc md it lb b lc ld lf lg li me lm mf lq mg lu mh mi mj mk bi translated">这两种方法的第二个区别是<strong class="lb iu">损失函数</strong>。<strong class="lb iu">视觉转换器</strong>使用<strong class="lb iu">图像分类损失</strong>，而<strong class="lb iu"> YOLOS </strong>使用<strong class="lb iu">二分匹配损失</strong>。</li><li id="fc41" class="mc md it lb b lc ml lf mm li mn lm mo lq mp lu mh mi mj mk bi translated">你可以在两个不同的<strong class="lb iu"> YOLOS-S </strong>模型的最后一层的头上检查<strong class="lb iu">自我关注</strong>地图可视化检测令牌和相应的预测。</li></ul><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi nd"><img src="../Images/fde61e18bd982d2aef5b174577c1c8b4.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*D0Ppu7olVFVydIO-4xZcBA.png"/></div></div><figcaption class="ku kv gj gh gi kw kx bd b be z dk translated">自我注意地图可视化。来源:<a class="ae ky" href="https://arxiv.org/pdf/2106.00666.pdf" rel="noopener ugc nofollow" target="_blank">https://arxiv.org/pdf/2106.00666.pdf</a></figcaption></figure><ul class=""><li id="4581" class="mc md it lb b lc ld lf lg li me lm mf lq mg lu mh mi mj mk bi translated">你可以在这个<a class="ae ky" href="https://github.com/hustvl/YOLOS" rel="noopener ugc nofollow" target="_blank"> GitHub库</a>找到<strong class="lb iu">代码</strong>和<strong class="lb iu">预训练</strong>模型。</li></ul><p id="613d" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">所以，在所有这些信息之后，我想分享一下我对这个问题的想法…</p><blockquote class="lw lx ly"><p id="17c7" class="kz la lv lb b lc ld ju le lf lg jx lh lz lj lk ll ma ln lo lp mb lr ls lt lu im bi translated"><strong class="lb iu"> <em class="it">视觉变形金刚准备好量产了吗？</em>T55】</strong></p></blockquote><p id="5de4" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">当然，这个问题没有具体的答案。任何任务的解决技术都可以根据项目需求而变化。</p><p id="cfeb" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">然而，在大多数项目的<strong class="lb iu">生产</strong>过程之前，有一些基本点需要关注，如<strong class="lb iu">推断时间</strong>、<strong class="lb iu">精度</strong>、<strong class="lb iu">模型训练要求、</strong>和<strong class="lb iu">部署</strong>过程。</p><p id="5785" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">那么关于<strong class="lb iu">变形金刚</strong>和<strong class="lb iu">CNN</strong>的区别，应该选择哪一个来制作呢？</p><ul class=""><li id="9d59" class="mc md it lb b lc ld lf lg li me lm mf lq mg lu mh mi mj mk bi translated">由于<strong class="lb iu">变压器</strong>需要大量数据用于<strong class="lb iu">高精度</strong>，<strong class="lb iu">数据收集</strong>过程会延长项目时间。在数据<strong class="lb iu">较少的情况下，CNN</strong>通常比<strong class="lb iu">变压器</strong>表现更好。</li><li id="12a8" class="mc md it lb b lc ml lf mm li mn lm mo lq mp lu mh mi mj mk bi translated"><strong class="lb iu">变压器<strong class="lb iu">的训练时间</strong>看起来比<strong class="lb iu"> CNNs </strong>要少。根据对<strong class="lb iu">计算效率</strong>和<strong class="lb iu">精度</strong>的比较，在<strong class="lb iu">模型训练</strong>时间有限的情况下，可以选择<strong class="lb iu">变压器</strong>。</strong></li><li id="552c" class="mc md it lb b lc ml lf mm li mn lm mo lq mp lu mh mi mj mk bi translated"><strong class="lb iu">自我关注机制</strong>可以给开发的模型带来更多<strong class="lb iu">意识</strong>。既然<strong class="lb iu">CNN</strong>开发的模型的<strong class="lb iu">弱点</strong>如此难以理解，那么<strong class="lb iu">注意力地图</strong>就可以可视化，它们可以帮助开发者指导如何改进模型。这个过程对于基于CNN的模型来说更加困难。</li><li id="b939" class="mc md it lb b lc ml lf mm li mn lm mo lq mp lu mh mi mj mk bi translated">最后但同样重要的是，所选方法的<strong class="lb iu">部署</strong>应该简单而快速，以便准备好进行部署(如果没有时间限制，没问题)。即使有一些<strong class="lb iu">框架</strong>用于<strong class="lb iu">变形金刚</strong>，基于CNN的方法部署起来仍然不那么复杂。</li></ul><p id="f8d1" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">正如我在开始时说的，我们不能说这个问题的具体答案。<strong class="lb iu">混合动力车型</strong>也在开发中，表现良好。应该始终如一地关注这些方法的现状。在做出决策之前，应该考虑不同方法的项目需求和能力。</p><p id="a8aa" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">由于我们生活在一个每天都有越来越多数据的世界，而且开发从未停止，<strong class="lb iu">变形金刚</strong>将更适合部署在实际应用中…</p><blockquote class="lw lx ly"><p id="6d7b" class="kz la lv lb b lc ld ju le lf lg jx lh lz lj lk ll ma ln lo lp mb lr ls lt lu im bi translated"><strong class="lb iu">结论</strong></p></blockquote><ul class=""><li id="0836" class="mc md it lb b lc ld lf lg li me lm mf lq mg lu mh mi mj mk bi translated">从<strong class="lb iu">图像分类</strong>到<strong class="lb iu">图像分割，</strong>变形金刚<strong class="lb iu">成为<strong class="lb iu">计算机视觉</strong>应用的一部分。我们可以在变形金刚的列表中添加<strong class="lb iu">动作识别</strong>、<strong class="lb iu">图像增强</strong>、<strong class="lb iu">超分辨率</strong>，或者<strong class="lb iu"> 3D重建</strong>任务。</strong></li><li id="515d" class="mc md it lb b lc ml lf mm li mn lm mo lq mp lu mh mi mj mk bi translated">毫无疑问，随着更多数据的到来，我们将在未来的<strong class="lb iu">视觉技术</strong>中看到表现良好的、基于<strong class="lb iu">变压器的</strong>方法。</li><li id="b07f" class="mc md it lb b lc ml lf mm li mn lm mo lq mp lu mh mi mj mk bi translated">我想以提到这种方法对我最重要的影响来结束我的文章。CNN一直是我思考计算机视觉的<strong class="lb iu">未来的中心。作为一名学生，可能当时我的眼界还不够。然而，<strong class="lb iu">变形金刚</strong>让我明白/记住新的方法总会到来。</strong></li></ul><p id="69f5" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">这种进化是如此令人兴奋，我很高兴成为人工智能革命的一部分！T9】</p><blockquote class="lw lx ly"><p id="0055" class="kz la lv lb b lc ld ju le lf lg jx lh lz lj lk ll ma ln lo lp mb lr ls lt lu im bi translated">关于我</p></blockquote><ul class=""><li id="a3ed" class="mc md it lb b lc ld lf lg li me lm mf lq mg lu mh mi mj mk bi translated">我是<strong class="lb iu">新技术<a class="ae ky" href="https://www.neosperience.com/" rel="noopener ugc nofollow" target="_blank"><strong class="lb iu"/></a>的机器学习工程师实习生</strong>。我正在帕维亚大学<a class="ae ky" href="https://web-en.unipv.it/" rel="noopener ugc nofollow" target="_blank"/>攻读<strong class="lb iu">数据科学</strong>的<strong class="lb iu">硕士学位。</strong></li><li id="bd6c" class="mc md it lb b lc ml lf mm li mn lm mo lq mp lu mh mi mj mk bi translated"><strong class="lb iu"> Neosperience </strong>通过利用<strong class="lb iu"> AI </strong>的软件解决方案释放同理心的力量，使品牌能够了解、参与和扩大其客户群。在<a class="ae ky" href="http://www.neosperience.com/" rel="noopener ugc nofollow" target="_blank">www.neosperience.com</a>伸手。</li></ul></div></div>    
</body>
</html>