<html>
<head>
<title>Testing TensorFlow Lite Image Classification Model</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">测试TensorFlow Lite影像分类模型</h1>
<blockquote>原文：<a href="https://pub.towardsai.net/testing-tensorflow-lite-image-classification-model-e9c0100d8de3?source=collection_archive---------0-----------------------#2019-05-31">https://pub.towardsai.net/testing-tensorflow-lite-image-classification-model-e9c0100d8de3?source=collection_archive---------0-----------------------#2019-05-31</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><figure class="is it gp gr iu iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi ir"><img src="../Images/850c8738bee94c25c3567364d95e8443.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*8a-JoYUA8-mCVxdgdMg4cQ.png"/></div></div></figure><h2 id="1b83" class="jc jd je bd b dl jf jg jh ji jj jk dk jl translated" aria-label="kicker paragraph"><a class="ae ep" href="https://towardsai.net/p/category/machine-learning" rel="noopener ugc nofollow" target="_blank">机器学习</a></h2><div class=""/><div class=""><h2 id="c136" class="pw-subtitle-paragraph kk jn je bd b kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb dk translated">确保您的ML模型在移动应用程序上正确工作(第1部分)</h2></div><p id="5db2" class="pw-post-body-paragraph lc ld je le b lf lg ko lh li lj kr lk ll lm ln lo lp lq lr ls lt lu lv lw lx im bi translated"><em class="ly">本文最初发表于</em><a class="ae lz" href="https://thinkmobile.dev" rel="noopener ugc nofollow" target="_blank"><em class="ly">think mobile . dev</em></a><em class="ly">—一个关于在移动应用中实现智能解决方案的博客(</em> <a class="ae lz" href="https://thinkmobile.dev/testing-tensorflow-lite-image-classification-model/" rel="noopener ugc nofollow" target="_blank"> <em class="ly">链接到文章</em> </a> <em class="ly">)。</em></p><p id="3b8e" class="pw-post-body-paragraph lc ld je le b lf lg ko lh li lj kr lk ll lm ln lo lp lq lr ls lt lu lv lw lx im bi translated">寻找如何在移动设备上自动测试TensorFlow Lite模型？检查本条的<a class="ae lz" href="https://thinkmobile.dev/automate-testing-of-tensorflow-lite-model-implementation/" rel="noopener ugc nofollow" target="_blank">第二部分。</a></p><p id="8ef4" class="pw-post-body-paragraph lc ld je le b lf lg ko lh li lj kr lk ll lm ln lo lp lq lr ls lt lu lv lw lx im bi translated">随着时间的推移，构建TensorFlow Lite模型并在移动应用程序上部署它们变得越来越简单。但是即使有了更容易实现的库和API，仍然有至少三个主要步骤要完成:</p><ol class=""><li id="b6eb" class="ma mb je le b lf lg li lj ll mc lp md lt me lx mf mg mh mi bi translated">建立张量流模型，</li><li id="28f4" class="ma mb je le b lf mj li mk ll ml lp mm lt mn lx mf mg mh mi bi translated">将其转换为TensorFlow Lite模型，</li><li id="19f9" class="ma mb je le b lf mj li mk ll ml lp mm lt mn lx mf mg mh mi bi translated">在移动应用程序上实施。</li></ol><p id="3738" class="pw-post-body-paragraph lc ld je le b lf lg ko lh li lj kr lk ll lm ln lo lp lq lr ls lt lu lv lw lx im bi translated">在这些步骤之间需要传递一组信息—模型输入/输出形状、值格式等。如果你知道它们(例如，感谢在<a class="ae lz" href="https://thinkmobile.dev/inspecting-tensorflow-lite-image-classification-model/" rel="noopener ugc nofollow" target="_blank">这篇</a>博客文章中描述的可视化技术和工具)，还有另一个问题，许多软件工程师都在努力解决。</p><blockquote class="mo mp mq"><p id="0cb8" class="lc ld ly le b lf lg ko lh li lj kr lk mr lm ln lo ms lq lr ls mt lu lv lw lx im bi translated"><strong class="le jo">为什么在移动应用上实现的模型与在python环境中实现的不同？</strong></p><p id="9595" class="lc ld ly le b lf lg ko lh li lj kr lk mr lm ln lo ms lq lr ls mt lu lv lw lx im bi translated"><strong class="le jo">软件工程师</strong></p></blockquote><p id="8945" class="pw-post-body-paragraph lc ld je le b lf lg ko lh li lj kr lk ll lm ln lo lp lq lr ls lt lu lv lw lx im bi translated">在本帖中，我们将尝试可视化<strong class="le jo"> TensorFlow </strong>、<strong class="le jo"> TensorFlow Lite和</strong>、T28】量化TensorFlow Lite (带<a class="ae lz" href="https://www.tensorflow.org/lite/performance/post_training_quantization" rel="noopener ugc nofollow" target="_blank">训练后量化</a>)模型之间的差异。这应该有助于我们在出现问题时进行早期模型调试。<br/>这里，我们将只关注张量流方面。值得记住的是，它不包括移动应用程序实现的正确性(如位图预处理和数据转换)。这将在以后的文章中描述。</p><p id="2f0d" class="pw-post-body-paragraph lc ld je le b lf lg ko lh li lj kr lk ll lm ln lo lp lq lr ls lt lu lv lw lx im bi translated"><strong class="le jo">重要通知</strong> —此处和Colab笔记本中的代码仅显示了TensorFlow和TensorFlow Lite模型之间目测比较的一些基本想法(在小数据批量上)。它不检查它们的速度和性能的任何其他因素，也不进行任何精确的并排交叉比较。</p><h1 id="6300" class="mu mv je bd mw mx my mz na nb nc nd ne kt nf ku ng kw nh kx ni kz nj la nk nl bi translated">张量流模型准备</h1><p id="14af" class="pw-post-body-paragraph lc ld je le b lf nm ko lh li nn kr lk ll no ln lo lp np lr ls lt nq lv lw lx im bi translated"><em class="ly">如果已经有TF模型为</em> <code class="fe nr ns nt nu b">SavedModel</code> <em class="ly">，可以跳过这一段，直接进入</em> <strong class="le jo"> <em class="ly">从SavedModel </em> </strong> <em class="ly">部分加载TensorFlow模型。</em></p><p id="cf12" class="pw-post-body-paragraph lc ld je le b lf lg ko lh li lj kr lk ll lm ln lo lp lq lr ls lt lu lv lw lx im bi translated">作为一个例子，我们将构建一个简单的TensorFlow模型，该模型对花卉进行分类，并基于迁移学习技术构建在<strong class="le jo"> MobileNet v2 </strong>之上。该代码是从Udacity的<a class="ae lz" href="https://classroom.udacity.com/courses/ud187" rel="noopener ugc nofollow" target="_blank"> TensorFlow免费课程</a>中获取并获得灵感的，我强烈推荐给每个想开始使用这个机器学习框架的人(无论是它的机器学习工程师，还是在客户端实现ML解决方案的软件工程师)。</p><p id="750c" class="pw-post-body-paragraph lc ld je le b lf lg ko lh li lj kr lk ll lm ln lo lp lq lr ls lt lu lv lw lx im bi translated">该模型的结构如下:</p><figure class="nv nw nx ny gt iv"><div class="bz fp l di"><div class="nz oa l"/></div><figcaption class="ob oc gj gh gi od oe bd b be z dk translated">基于MobileNet v2构建的花卉分类模型</figcaption></figure><p id="76dc" class="pw-post-body-paragraph lc ld je le b lf lg ko lh li lj kr lk ll lm ln lo lp lq lr ls lt lu lv lw lx im bi translated">对于训练，我们将使用Keras <code class="fe nr ns nt nu b">ImageDataGenerators</code>和Google提供的示例数据集:</p><figure class="nv nw nx ny gt iv"><div class="bz fp l di"><div class="nz oa l"/></div></figure><p id="411b" class="pw-post-body-paragraph lc ld je le b lf lg ko lh li lj kr lk ll lm ln lo lp lq lr ls lt lu lv lw lx im bi translated">经过10次训练后，准确率约为87%。对我们的需求来说，这很好👌。</p><figure class="nv nw nx ny gt iv"><div class="bz fp l di"><div class="nz oa l"/></div></figure><p id="e300" class="pw-post-body-paragraph lc ld je le b lf lg ko lh li lj kr lk ll lm ln lo lp lq lr ls lt lu lv lw lx im bi translated">当模型准备好时，我们将把它导出为<code class="fe nr ns nt nu b">SavedModel</code>格式:</p><figure class="nv nw nx ny gt iv"><div class="bz fp l di"><div class="nz oa l"/></div></figure><h1 id="e3be" class="mu mv je bd mw mx my mz na nb nc nd ne kt nf ku ng kw nh kx ni kz nj la nk nl bi translated">从SavedModel加载TensorFlow模型</h1><p id="09d7" class="pw-post-body-paragraph lc ld je le b lf nm ko lh li nn kr lk ll no ln lo lp np lr ls lt nq lv lw lx im bi translated">现在，当我们以<code class="fe nr ns nt nu b">SavedModel</code>格式保存TensorFlow模型时，让我们加载它。如果您不想花费时间来构建和训练您的模型，从这里开始是完全可以的。</p><figure class="nv nw nx ny gt iv"><div class="bz fp l di"><div class="nz oa l"/></div><figcaption class="ob oc gj gh gi od oe bd b be z dk translated">因为我们的模型使用来自TensorFlow Hub的自定义层，我们需要用<code class="fe nr ns nt nu b">custom_obiects</code>参数明确指出它的实现。</figcaption></figure><h1 id="a25f" class="mu mv je bd mw mx my mz na nb nc nd ne kt nf ku ng kw nh kx ni kz nj la nk nl bi translated">检查模型的预测</h1><p id="eec4" class="pw-post-body-paragraph lc ld je le b lf nm ko lh li nn kr lk ll no ln lo lp np lr ls lt nq lv lw lx im bi translated">现在，我们将从验证数据集制作一批32个图像，并在加载的模型上运行推理过程:</p><figure class="nv nw nx ny gt iv"><div class="bz fp l di"><div class="nz oa l"/></div></figure><p id="ac50" class="pw-post-body-paragraph lc ld je le b lf lg ko lh li lj kr lk ll lm ln lo lp lq lr ls lt lu lv lw lx im bi translated">对于数据可视化，我们将使用<a class="ae lz" href="https://pandas.pydata.org/" rel="noopener ugc nofollow" target="_blank">熊猫库</a>。这是我们通过<code class="fe nr ns nt nu b">tf_pred_dataframe.head()</code>打印数值时所看到的。</p><figure class="nv nw nx ny gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi of"><img src="../Images/de0faf7df6172e581463aa4664607809.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*0wEoiJFbuvwnSukm"/></div></div><figcaption class="ob oc gj gh gi od oe bd b be z dk translated">预测结果用熊猫数据框表示</figcaption></figure><p id="7c84" class="pw-post-body-paragraph lc ld je le b lf lg ko lh li lj kr lk ll lm ln lo lp lq lr ls lt lu lv lw lx im bi translated">这里的每一行代表一个单独图像的预测结果(我们的数据帧有32行)。每个单元格包含标签对该图像的置信度。一行中所有值的总和为1(因为我们模型的最后一层使用了<a class="ae lz" href="https://en.wikipedia.org/wiki/Softmax_function" rel="noopener ugc nofollow" target="_blank"> Softmax </a>激活函数)。</p><p id="ffbb" class="pw-post-body-paragraph lc ld je le b lf lg ko lh li lj kr lk ll lm ln lo lp lq lr ls lt lu lv lw lx im bi translated">我们也可以打印这些图像和预测:</p><figure class="nv nw nx ny gt iv"><div class="bz fp l di"><div class="nz oa l"/></div></figure><p id="6397" class="pw-post-body-paragraph lc ld je le b lf lg ko lh li lj kr lk ll lm ln lo lp lq lr ls lt lu lv lw lx im bi translated">上面的代码将显示:</p><figure class="nv nw nx ny gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi og"><img src="../Images/3bba36c872f2ee1a7a1a4b4aad23efd6.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*fk6vdaa3vLoHmLTu"/></div></div></figure><h1 id="02e1" class="mu mv je bd mw mx my mz na nb nc nd ne kt nf ku ng kw nh kx ni kz nj la nk nl bi translated">TensorFlow Lite模型</h1><h2 id="597c" class="oh mv je bd mw oi oj dn na ok ol dp ne ll om on ng lp oo op ni lt oq or nk jk bi translated">将模型转换为TensorFlow Lite</h2><p id="8225" class="pw-post-body-paragraph lc ld je le b lf nm ko lh li nn kr lk ll no ln lo lp np lr ls lt nq lv lw lx im bi translated">现在我们将创建两个TensorFlow Lite模型——非量化和量化，基于我们创建的模型。<br/>由于TensorFlow 2.0的性质，我们需要将TensorFlow模型转换成<strong class="le jo">具体函数</strong>，然后转换成TensorFlow Lite(更多信息<a class="ae lz" href="https://www.tensorflow.org/lite/r2/convert/concrete_function" rel="noopener ugc nofollow" target="_blank">在此</a>)。</p><figure class="nv nw nx ny gt iv"><div class="bz fp l di"><div class="nz oa l"/></div><figcaption class="ob oc gj gh gi od oe bd b be z dk translated">由于TensorFlow 2.0的急切执行，在最终转换为TensorFlow Lite之前，需要将模型转换为具体函数。</figcaption></figure><p id="6736" class="pw-post-body-paragraph lc ld je le b lf lg ko lh li lj kr lk ll lm ln lo lp lq lr ls lt lu lv lw lx im bi translated">这样一来，我们就会得到两个文件:<strong class="le jo">花。tflite </strong> (TensorFlow Lite标准模型)和<strong class="le jo"> flowers_quant.tflite </strong>(训练后量化的TensorFlow Lite量化模型)。</p><h1 id="195f" class="mu mv je bd mw mx my mz na nb nc nd ne kt nf ku ng kw nh kx ni kz nj la nk nl bi translated">运行TFLite模型</h1><p id="4425" class="pw-post-body-paragraph lc ld je le b lf nm ko lh li nn kr lk ll no ln lo lp np lr ls lt nq lv lw lx im bi translated">现在让我们将TFLite模型加载到解释器(<a class="ae lz" href="https://www.tensorflow.org/versions/r2.0/api_docs/python/tf/lite/Interpreter" rel="noopener ugc nofollow" target="_blank"> tf.lite.Interpreter </a>)表示中，这样我们就可以在其上运行推理过程。</p><figure class="nv nw nx ny gt iv"><div class="bz fp l di"><div class="nz oa l"/></div><figcaption class="ob oc gj gh gi od oe bd b be z dk translated">默认情况下，解释器可以对一幅图像(输入形状:1x224x224x3)运行推理过程。</figcaption></figure><p id="0107" class="pw-post-body-paragraph lc ld je le b lf lg ko lh li lj kr lk ll lm ln lo lp lq lr ls lt lu lv lw lx im bi translated">在运行推理之前，我们需要调整输入和输出张量的大小，以接受一批32幅图像:</p><figure class="nv nw nx ny gt iv"><div class="bz fp l di"><div class="nz oa l"/></div></figure><p id="8980" class="pw-post-body-paragraph lc ld je le b lf lg ko lh li lj kr lk ll lm ln lo lp lq lr ls lt lu lv lw lx im bi translated">同样，我们把数据放入熊猫数据框。<br/>下面是我们可以看到的<code class="fe nr ns nt nu b">tflite_pred_dataframe.head()</code>:</p><figure class="nv nw nx ny gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi og"><img src="../Images/8e79bbe44c5ab552e566df0701d6816d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*yssiFSGPw4U7P8fQ"/></div></div><figcaption class="ob oc gj gh gi od oe bd b be z dk translated">用熊猫数据框表示的TFLite模型的预测结果</figcaption></figure><p id="cdaa" class="pw-post-body-paragraph lc ld je le b lf lg ko lh li lj kr lk ll lm ln lo lp lq lr ls lt lu lv lw lx im bi translated">我们将对第二个模型— <strong class="le jo"> flowers_quant.tflite </strong>进行完全相同的操作。<br/>数据帧预览:</p><figure class="nv nw nx ny gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi of"><img src="../Images/3ce53cf0550a2eeab4bae02d8cad20dd.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*9YG_vidJaKEl9P5x"/></div></div></figure><h1 id="1caf" class="mu mv je bd mw mx my mz na nb nc nd ne kt nf ku ng kw nh kx ni kz nj la nk nl bi translated">结果比较</h1><p id="485b" class="pw-post-body-paragraph lc ld je le b lf nm ko lh li nn kr lk ll no ln lo lp np lr ls lt nq lv lw lx im bi translated">现在，我们可以做的是连接来自TF、TF Lite和TF Lite quant模型的数据框架，在表之间进行目测比较。这段代码的灵感来自StackOverflow ( <a class="ae lz" href="https://stackoverflow.com/a/47112033/2021293" rel="noopener ugc nofollow" target="_blank">链接</a>到答案)。🙂</p><figure class="nv nw nx ny gt iv"><div class="bz fp l di"><div class="nz oa l"/></div></figure><p id="3474" class="pw-post-body-paragraph lc ld je le b lf lg ko lh li lj kr lk ll lm ln lo lp lq lr ls lt lu lv lw lx im bi translated">因此，我们可以看到数据帧中突出显示的行在TF/TF Lite模型之间是不同的。</p><figure class="nv nw nx ny gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi os"><img src="../Images/58868a348ea0a4656588bc54d8be0b8a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*5TZrf3_dPwAhtysC"/></div></div></figure><p id="2427" class="pw-post-body-paragraph lc ld je le b lf lg ko lh li lj kr lk ll lm ln lo lp lq lr ls lt lu lv lw lx im bi translated">正如我们所看到的，在大多数情况下，所有模型之间的预测都是不同的，通常相差很小。<br/>tensor flow和TensorFlow Lite模型之间的高置信度预测彼此非常接近(在某些情况下甚至有相似之处)。量化模型最突出，但这是优化的成本(模型重量减少3-4倍)。</p><p id="2cc1" class="pw-post-body-paragraph lc ld je le b lf lg ko lh li lj kr lk ll lm ln lo lp lq lr ls lt lu lv lw lx im bi translated">为了使预测结果更具可读性，让我们简化数据帧，只显示最高分的预测和相应的标签。</p><figure class="nv nw nx ny gt iv"><div class="bz fp l di"><div class="nz oa l"/></div></figure><p id="084d" class="pw-post-body-paragraph lc ld je le b lf lg ko lh li lj kr lk ll lm ln lo lp lq lr ls lt lu lv lw lx im bi translated">现在，每个数据帧(TF、TFLite和TFLite quant)仅显示该标签的标签指数和置信度。</p><figure class="nv nw nx ny gt iv gh gi paragraph-image"><div class="gh gi ot"><img src="../Images/ec04f3d0c3bde9570dac49b2172a3605.png" data-original-src="https://miro.medium.com/v2/resize:fit:506/0*ZFCa5x7MQQ4WuMs8"/></div></figure><p id="a183" class="pw-post-body-paragraph lc ld je le b lf lg ko lh li lj kr lk ll lm ln lo lp lq lr ls lt lu lv lw lx im bi translated">让我们连接数据帧并强调它们之间的差异:</p><figure class="nv nw nx ny gt iv gh gi paragraph-image"><div class="gh gi ou"><img src="../Images/00189fb4fd3c6e5304df9dad23658523.png" data-original-src="https://miro.medium.com/v2/resize:fit:1136/0*1nXvcI3vQJaQtaUS"/></div></figure><p id="7984" class="pw-post-body-paragraph lc ld je le b lf lg ko lh li lj kr lk ll lm ln lo lp lq lr ls lt lu lv lw lx im bi translated">如你所见，尽管存在差异，TFLite模型通常为图像指出相同的标签(在我们的图像验证批次中)。信心的差异通常很小。量化的TF Lite模型在这里并不同样好。在一些置信度得分上有很大的差异，而且在某些情况下，这个模型指出了不同的标签。</p><p id="b9af" class="pw-post-body-paragraph lc ld je le b lf lg ko lh li lj kr lk ll lm ln lo lp lq lr ls lt lu lv lw lx im bi translated">以下是我们图像批次中TFLite和TFLite quant型号的对比:</p><figure class="nv nw nx ny gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi of"><img src="../Images/929950f542c14f92d5d8292c8ee86f93.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*JUACVQJCYcMKvb0h"/></div></div></figure><p id="d0ae" class="pw-post-body-paragraph lc ld je le b lf lg ko lh li lj kr lk ll lm ln lo lp lq lr ls lt lu lv lw lx im bi translated">现在，由我们来决定模型尺寸缩减(在我们的例子中是3-4倍)是否值得。</p><h1 id="5461" class="mu mv je bd mw mx my mz na nb nc nd ne kt nf ku ng kw nh kx ni kz nj la nk nl bi translated">后续步骤</h1><p id="266e" class="pw-post-body-paragraph lc ld je le b lf nm ko lh li nn kr lk ll no ln lo lp np lr ls lt nq lv lw lx im bi translated">在这篇博文中，我们对TensorFlow、TensorFlow Lite和量化TensorFlow Lite模型进行了并排比较。我们可以注意到TF和TFLite之间的细微差别，而TFLite quant上的差别稍大一些。但这不是我们能检查的所有东西。</p><p id="7f1d" class="pw-post-body-paragraph lc ld je le b lf lg ko lh li lj kr lk ll lm ln lo lp lq lr ls lt lu lv lw lx im bi translated">这些模型是在相同的环境(Colab或Jupyter notebook)中进行检查的，但问题也可能会进一步发生——在移动应用程序实施中。例如在图像处理或数据转换中。</p><p id="ee02" class="pw-post-body-paragraph lc ld je le b lf lg ko lh li lj kr lk ll lm ln lo lp lq lr ls lt lu lv lw lx im bi translated">在以后的博客文章中，我们将仔细研究如何在移动设备上直接测试TF Lite模型实现的正确性。</p><h1 id="c789" class="mu mv je bd mw mx my mz na nb nc nd ne kt nf ku ng kw nh kx ni kz nj la nk nl bi translated">源代码</h1><p id="c42a" class="pw-post-body-paragraph lc ld je le b lf nm ko lh li nn kr lk ll no ln lo lp np lr ls lt nq lv lw lx im bi translated">这篇博文的源代码可以在Github (Colab笔记本，以及未来的移动应用)上找到:<a class="ae lz" href="https://github.com/frogermcs/TFLite-Tester" rel="noopener ugc nofollow" target="_blank">https://github.com/frogermcs/TFLite-Tester</a></p><p id="cdfb" class="pw-post-body-paragraph lc ld je le b lf lg ko lh li lj kr lk ll lm ln lo lp lq lr ls lt lu lv lw lx im bi translated">本帖呈现完整代码的笔记本可以在这里运行:<a class="ae lz" href="https://colab.research.google.com/github/frogermcs/TFLite-Tester/blob/master/notebooks/Testing_TFLite_model.ipynb" rel="noopener ugc nofollow" target="_blank">https://colab . research . Google . com/github/frogermcs/TFLite-Tester/blob/master/notebooks/Testing _ TFLite _ model . ipynb</a></p><div class="is it gp gr iu ov"><a href="https://colab.research.google.com/github/frogermcs/TFLite-Tester/blob/master/notebooks/Testing_TFLite_model.ipynb" rel="noopener  ugc nofollow" target="_blank"><div class="ow ab fo"><div class="ox ab oy cl cj oz"><h2 class="bd jo gy z fp pa fr fs pb fu fw jn bi translated">谷歌联合实验室</h2><div class="pc l"><h3 class="bd b gy z fp pa fr fs pb fu fw dk translated">编辑描述</h3></div><div class="pd l"><p class="bd b dl z fp pa fr fs pb fu fw dk translated">colab.research.google.com</p></div></div><div class="pe l"><div class="pf l pg ph pi pe pj ja ov"/></div></div></a></div><p id="ac8b" class="pw-post-body-paragraph lc ld je le b lf lg ko lh li lj kr lk ll lm ln lo lp lq lr ls lt lu lv lw lx im bi translated">感谢阅读！🙂</p><p id="da58" class="pw-post-body-paragraph lc ld je le b lf lg ko lh li lj kr lk ll lm ln lo lp lq lr ls lt lu lv lw lx im bi translated">请在下面分享您的反馈。👇</p></div><div class="ab cl pk pl hx pm" role="separator"><span class="pn bw bk po pp pq"/><span class="pn bw bk po pp pq"/><span class="pn bw bk po pp"/></div><div class="im in io ip iq"><p id="077c" class="pw-post-body-paragraph lc ld je le b lf lg ko lh li lj kr lk ll lm ln lo lp lq lr ls lt lu lv lw lx im bi translated">寻找如何在移动设备上自动测试TensorFlow Lite模型？查看本条的<a class="ae lz" href="https://thinkmobile.dev/automate-testing-of-tensorflow-lite-model-implementation/" rel="noopener ugc nofollow" target="_blank">第二部分。</a></p><div class="is it gp gr iu ov"><a href="https://thinkmobile.dev/automate-testing-of-tensorflow-lite-model-implementation/" rel="noopener  ugc nofollow" target="_blank"><div class="ow ab fo"><div class="ox ab oy cl cj oz"><h2 class="bd jo gy z fp pa fr fs pb fu fw jn bi translated">TensorFlow Lite模型实现的自动化测试“思考，移动！</h2><div class="pc l"><h3 class="bd b gy z fp pa fr fs pb fu fw dk translated">确保您的ML模型在移动应用程序上正确工作(第2部分)这是关于测试机器的第2篇文章…</h3></div><div class="pd l"><p class="bd b dl z fp pa fr fs pb fu fw dk translated">thinkmobile.dev</p></div></div><div class="pe l"><div class="pr l pg ph pi pe pj ja ov"/></div></div></a></div><p id="0a64" class="pw-post-body-paragraph lc ld je le b lf lg ko lh li lj kr lk ll lm ln lo lp lq lr ls lt lu lv lw lx im bi translated"><em class="ly">本文最初发表于</em><a class="ae lz" href="https://thinkmobile.dev" rel="noopener ugc nofollow" target="_blank"><em class="ly">think mobile . dev</em></a><em class="ly">—一个关于在移动应用中实现智能解决方案的博客(</em> <a class="ae lz" href="https://thinkmobile.dev/testing-tensorflow-lite-image-classification-model/" rel="noopener ugc nofollow" target="_blank"> <em class="ly">链接到文章</em> </a> <em class="ly">)。</em></p><div class="is it gp gr iu ov"><a href="https://thinkmobile.dev/testing-tensorflow-lite-image-classification-model/" rel="noopener  ugc nofollow" target="_blank"><div class="ow ab fo"><div class="ox ab oy cl cj oz"><h2 class="bd jo gy z fp pa fr fs pb fu fw jn bi translated">测试TensorFlow Lite图像分类模型“思考，移动！</h2><div class="pc l"><h3 class="bd b gy z fp pa fr fs pb fu fw dk translated">确保您的ML模型在移动应用程序上正常工作(第1部分)构建TensorFlow Lite模型并部署它们…</h3></div><div class="pd l"><p class="bd b dl z fp pa fr fs pb fu fw dk translated">thinkmobile.dev</p></div></div><div class="pe l"><div class="ps l pg ph pi pe pj ja ov"/></div></div></a></div></div></div>    
</body>
</html>