<html>
<head>
<title>Understanding Tensor Dimensions in Deep Learning models with Pytorch</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">用Pytorch理解深度学习模型中的张量维数</h1>
<blockquote>原文：<a href="https://pub.towardsai.net/understanding-tensor-dimensions-in-deep-learning-models-with-pytorch-4ee828693826?source=collection_archive---------0-----------------------#2021-06-18">https://pub.towardsai.net/understanding-tensor-dimensions-in-deep-learning-models-with-pytorch-4ee828693826?source=collection_archive---------0-----------------------#2021-06-18</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><h2 id="ccb1" class="ir is it bd b dl iu iv iw ix iy iz dk ja translated" aria-label="kicker paragraph"><a class="ae ep" href="https://towardsai.net/p/category/machine-learning/deep-learning" rel="noopener ugc nofollow" target="_blank">深度学习</a></h2><div class=""/><figure class="gl gn ka kb kc kd gh gi paragraph-image"><div role="button" tabindex="0" class="ke kf di kg bf kh"><div class="gh gi jz"><img src="../Images/c6d9ab6c3c811fc78929cfc91a667c55.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*B2iwh7-ZhIS5lsQqP4RWlQ.png"/></div></div><figcaption class="kk kl gj gh gi km kn bd b be z dk translated">作者插图。</figcaption></figure><p id="d410" class="pw-post-body-paragraph ko kp it kq b kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj lk ll im bi translated"><em class="lm">这篇文章是Pytorch构建深度学习模型系列指南的第三篇。下面，是全系列:</em></p><p id="df28" class="pw-post-body-paragraph ko kp it kq b kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj lk ll im bi translated"><em class="lm">第一部:</em> <a class="ae ln" rel="noopener ugc nofollow" target="_blank" href="/pytorch-tutorial-for-beginners-8331afc552c4"> <em class="lm"> Pytorch初学者教程</em> </a></p><p id="6b13" class="pw-post-body-paragraph ko kp it kq b kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj lk ll im bi translated"><em class="lm">第二部分:</em> <a class="ae ln" href="https://medium.com/mlearning-ai/manipulating-pytorch-datasets-c58487ab113f?sk=5d4cf7bd62d527d7c968b8db696b633f" rel="noopener"> <em class="lm">操纵Pytorch数据集</em> </a></p><p id="4c51" class="pw-post-body-paragraph ko kp it kq b kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj lk ll im bi translated"><em class="lm">第三部分:理解DL模型中的张量维度(本帖)</em></p><p id="91ea" class="pw-post-body-paragraph ko kp it kq b kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj lk ll im bi translated"><em class="lm">第四部分:</em> <a class="ae ln" href="https://medium.com/dataseries/visualizing-the-feature-maps-and-filters-by-convolutional-neural-networks-e1462340518e" rel="noopener"> <em class="lm"> CNN &amp;特征可视化</em> </a></p><p id="ef6e" class="pw-post-body-paragraph ko kp it kq b kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj lk ll im bi translated"><em class="lm">第五部分:</em> <a class="ae ln" rel="noopener ugc nofollow" target="_blank" href="/tuning-pytorch-hyperparameters-with-optuna-470edcfd4dc"> <em class="lm">超参数调谐用Optuna </em> </a></p><p id="2ae3" class="pw-post-body-paragraph ko kp it kq b kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj lk ll im bi translated"><em class="lm">第六部分:</em> <a class="ae ln" href="https://medium.com/dataseries/k-fold-cross-validation-with-pytorch-and-sklearn-d094aa00105f?sk=2466aaedc4e454b89f880a32604a2e0a" rel="noopener"> <em class="lm"> K折交叉验证</em> </a></p><p id="3c6d" class="pw-post-body-paragraph ko kp it kq b kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj lk ll im bi translated"><em class="lm">第七部分:</em> <a class="ae ln" href="https://medium.com/dataseries/convolutional-autoencoder-in-pytorch-on-mnist-dataset-d65145c132ac" rel="noopener"> <em class="lm">卷积自动编码器</em> </a></p><p id="6523" class="pw-post-body-paragraph ko kp it kq b kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj lk ll im bi translated"><em class="lm">第八部分:</em> <a class="ae ln" href="https://ai.plainenglish.io/denoising-autoencoder-in-pytorch-on-mnist-dataset-a76b8824e57e" rel="noopener ugc nofollow" target="_blank"> <em class="lm">去噪</em> </a></p><p id="3e28" class="pw-post-body-paragraph ko kp it kq b kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj lk ll im bi translated"><em class="lm">第九部分:</em> <a class="ae ln" href="https://medium.com/dataseries/variational-autoencoder-with-pytorch-2d359cbf027b" rel="noopener"> <em class="lm">变型自动编码器</em> </a></p><p id="1cd3" class="pw-post-body-paragraph ko kp it kq b kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj lk ll im bi translated"><em class="lm">本系列的目标是通过实现示例尽可能使Pytorch更加直观和易于使用。互联网上有许多教程可以使用Pytorch构建多种类型的具有挑战性的模型，但同时也会令人困惑，因为当您从一个教程转到另一个教程时，总会有轻微的差异。在这个系列中，我想从最简单的主题开始，到更高级的主题。</em></p><h1 id="3a81" class="lo lp it bd lq lr ls lt lu lv lw lx ly lz ma mb mc md me mf mg mh mi mj mk ml bi translated">介绍</h1><p id="94a9" class="pw-post-body-paragraph ko kp it kq b kr mm kt ku kv mn kx ky kz mo lb lc ld mp lf lg lh mq lj lk ll im bi translated">如果你开始使用Pytorch，并建立了一个卷积神经网络，你可能会遇到关于张量维数的错误。你疯狂地在网上寻找，希望找到犯同样错误的人。但是这会浪费时间，即使你纠正了错误，如果你对输入和输出形状没有深入的了解，你还会犯同样的错误。本指南将帮助您理解功能中要求的尺寸，如<code class="fe mr ms mt mu b">torch.nn.Conv2d</code>层和<code class="fe mr ms mt mu b">torch.nn.linear</code>层，它们具有不同的输入和输出尺寸。</p><h1 id="7dd6" class="lo lp it bd lq lr ls lt lu lv lw lx ly lz ma mb mc md me mf mg mh mi mj mk ml bi translated">内容:</h1><ol class=""><li id="4872" class="mv mw it kq b kr mm kv mn kz mx ld my lh mz ll na nb nc nd bi translated"><a class="ae ln" href="#2645" rel="noopener ugc nofollow"> <strong class="kq jd">输出nn的形状。Conv2d和nn。线性</strong> </a></li><li id="b416" class="mv mw it kq b kr ne kv nf kz ng ld nh lh ni ll na nb nc nd bi translated"><a class="ae ln" href="#add4" rel="noopener ugc nofollow"> <strong class="kq jd">输出nn的形状。convtranspose 2d</strong>T15】</a></li><li id="4b9f" class="mv mw it kq b kr ne kv nf kz ng ld nh lh ni ll na nb nc nd bi translated"><a class="ae ln" href="#301b" rel="noopener ugc nofollow"><strong class="kq jd">CNN cifar 10上的例子</strong> </a></li><li id="f4fe" class="mv mw it kq b kr ne kv nf kz ng ld nh lh ni ll na nb nc nd bi translated"><a class="ae ln" href="#a414" rel="noopener ugc nofollow"><strong class="kq jd">cifar 10上的Autoencoder示例</strong> </a></li></ol></div><div class="ab cl nj nk hx nl" role="separator"><span class="nm bw bk nn no np"/><span class="nm bw bk nn no np"/><span class="nm bw bk nn no"/></div><div class="im in io ip iq"><h1 id="2645" class="lo lp it bd lq lr nq lt lu lv nr lx ly lz ns mb mc md nt mf mg mh nu mj mk ml bi translated"><strong class="ak"> 1。神经网络的输出形状。Conv2d和nn。线性</strong></h1><p id="4685" class="pw-post-body-paragraph ko kp it kq b kr mm kt ku kv mn kx ky kz mo lb lc ld mp lf lg lh mq lj lk ll im bi translated">你需要知道的第一件事是，深度学习模型，如CNN和autoencoder，可以用于不同类型的输入数据:</p><ul class=""><li id="44c8" class="mv mw it kq b kr ks kv kw kz nv ld nw lh nx ll ny nb nc nd bi translated"><strong class="kq jd">三维视频</strong>。形状(<em class="lm"> batch_size </em>、<em class="lm">通道</em>、<em class="lm">深度</em>、<em class="lm">高度</em>、<em class="lm">宽度</em>)用于<code class="fe mr ms mt mu b">nn.Conv3d</code>输入。</li><li id="e5ef" class="mv mw it kq b kr ne kv nf kz ng ld nh lh ni ll ny nb nc nd bi translated"><strong class="kq jd">二维图像</strong>。形状(<em class="lm"> batch_size </em>、<em class="lm">通道</em>、<em class="lm">高度</em>、<em class="lm">宽度</em>)用于<code class="fe mr ms mt mu b">nn.Conv2d</code>输入。</li><li id="13d4" class="mv mw it kq b kr ne kv nf kz ng ld nh lh ni ll ny nb nc nd bi translated"><strong class="kq jd">文字</strong>和<strong class="kq jd">音频</strong>，都是1D。形状(<em class="lm">批量大小</em>、<em class="lm">通道</em>、<em class="lm">数量特征)</em>用于<code class="fe mr ms mt mu b">nn.Conv1d</code>输入。输入形状也可以是(<em class="lm"> seq_len </em>，<em class="lm"> batch_size </em>，<em class="lm"> num_features </em>)，以防我们将其传递给递归神经网络。</li></ul><p id="309e" class="pw-post-body-paragraph ko kp it kq b kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj lk ll im bi translated">一般而言，您可以注意到<strong class="kq jd">批次大小</strong>和<strong class="kq jd">通道</strong>在大多数情况下是第一个大小，添加它们是为了满足卷积层的函数条件:</p><ul class=""><li id="5338" class="mv mw it kq b kr ks kv kw kz nv ld nw lh nx ll ny nb nc nd bi translated"><code class="fe mr ms mt mu b">nn.Conv1d</code>需要一个3d张量</li><li id="3247" class="mv mw it kq b kr ne kv nf kz ng ld nh lh ni ll ny nb nc nd bi translated"><code class="fe mr ms mt mu b">nn.Conv2d</code>需要一个四维张量</li><li id="b99d" class="mv mw it kq b kr ne kv nf kz ng ld nh lh ni ll ny nb nc nd bi translated">需要一个5d张量</li></ul><figure class="oa ob oc od gt kd gh gi paragraph-image"><div role="button" tabindex="0" class="ke kf di kg bf kh"><div class="gh gi nz"><img src="../Images/1419c0aae00fc813ffaf9edda17d1ed2.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*b95O-IwjGd2Js2PkFMHRwg.png"/></div></div><figcaption class="kk kl gj gh gi km kn bd b be z dk translated">作者插图。用形状(3，4，4)可视化图像的两种方法</figcaption></figure><p id="92cb" class="pw-post-body-paragraph ko kp it kq b kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj lk ll im bi translated">在这些第一尺寸之后，随后的尺寸根据输入和任务的类型而变化。在CNN中，最常见的情况是将图像作为输入来执行分类任务。因此，我们将重点关注:</p><p id="e75e" class="pw-post-body-paragraph ko kp it kq b kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj lk ll im bi translated"><code class="fe mr ms mt mu b">nn.Conv2d(in_channels,out_channels,kernel_size,stride=1,padding=0,dilation=1)</code></p><p id="101b" class="pw-post-body-paragraph ko kp it kq b kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj lk ll im bi translated">其中:</p><blockquote class="oe of og"><p id="53f1" class="ko kp lm kq b kr ks kt ku kv kw kx ky oh la lb lc oi le lf lg oj li lj lk ll im bi translated"><strong class="kq jd"> in_channels </strong>是输入图像中的通道数，而<strong class="kq jd"> out_channels </strong>是卷积产生的通道数<strong class="kq jd"> </strong></p></blockquote><p id="0b22" class="pw-post-body-paragraph ko kp it kq b kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj lk ll im bi translated">处理图像时有三种可能的情况:</p><ol class=""><li id="4196" class="mv mw it kq b kr ks kv kw kz nv ld nw lh nx ll na nb nc nd bi translated">如果图像是灰度的，输入通道是1。</li><li id="6e12" class="mv mw it kq b kr ne kv nf kz ng ld nh lh ni ll na nb nc nd bi translated">如果图像是彩色的，输入通道是3。</li><li id="7829" class="mv mw it kq b kr ne kv nf kz ng ld nh lh ni ll na nb nc nd bi translated">如果有一个额外的阿尔法通道，我们有4个输入通道。</li></ol><p id="8441" class="pw-post-body-paragraph ko kp it kq b kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj lk ll im bi translated">要计算每个卷积层中高度和宽度的输出维度，在应用池层后，需要记住这两个公式:</p><figure class="oa ob oc od gt kd gh gi paragraph-image"><div role="button" tabindex="0" class="ke kf di kg bf kh"><div class="gh gi ok"><img src="../Images/4b0764232cdde76f1324a454258d09af.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*lX9LkwXZXcxSHd-AfMsEIQ.png"/></div></div><figcaption class="kk kl gj gh gi km kn bd b be z dk translated">来源:<a class="ae ln" href="https://pytorch.org/docs/stable/generated/torch.nn.Conv2d.html" rel="noopener ugc nofollow" target="_blank">https://py torch . org/docs/stable/generated/torch . nn . conv2d . html</a></figcaption></figure><p id="91da" class="pw-post-body-paragraph ko kp it kq b kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj lk ll im bi translated">在这里，你看到两个公式，但你通常会有相同的公式。这取决于填充、膨胀和内核大小。在CNN中，卷积核/滤波器通常是3×3，而池通常应用于2×2窗口、步幅2和无填充。因此，对于这些值，公式对于输出的宽度和高度是相同的。</p><p id="08be" class="pw-post-body-paragraph ko kp it kq b kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj lk ll im bi translated">在最后一个卷积层+池层之后，一个或多个全连接层被添加到CNN架构中。卷积层和汇集层产生的输出是三维的，但是全连接层需要一个1D数数组。因此，我们使用以下函数将输出展平为一维向量:</p><p id="288e" class="pw-post-body-paragraph ko kp it kq b kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj lk ll im bi translated"><code class="fe mr ms mt mu b">torch.nn.Linear(in_features,out_features, bias=True)</code></p><p id="5733" class="pw-post-body-paragraph ko kp it kq b kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj lk ll im bi translated">其中:</p><ul class=""><li id="6779" class="mv mw it kq b kr ks kv kw kz nv ld nw lh nx ll ny nb nc nd bi translated"><strong class="kq jd"> in_features </strong>构成<strong class="kq jd"> </strong>每个输入样本的大小</li><li id="1549" class="mv mw it kq b kr ne kv nf kz ng ld nh lh ni ll ny nb nc nd bi translated"><strong class="kq jd"> out_features </strong>构成<strong class="kq jd"/><strong class="kq jd"/>每个输出样本的大小</li></ul><p id="06c5" class="pw-post-body-paragraph ko kp it kq b kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj lk ll im bi translated">展平输出形状有两个主要功能:</p><ul class=""><li id="2ead" class="mv mw it kq b kr ks kv kw kz nv ld nw lh nx ll ny nb nc nd bi translated"><code class="fe mr ms mt mu b">image = image.view(image.size(0),-1)</code> <strong class="kq jd"> </strong>其中批量大小为image.size(0)。</li><li id="eefe" class="mv mw it kq b kr ne kv nf kz ng ld nh lh ni ll ny nb nc nd bi translated"><code class="fe mr ms mt mu b">image = torch.flatten(image.size(0),start_dim=1)</code></li></ul></div><div class="ab cl nj nk hx nl" role="separator"><span class="nm bw bk nn no np"/><span class="nm bw bk nn no np"/><span class="nm bw bk nn no"/></div><div class="im in io ip iq"><h1 id="add4" class="lo lp it bd lq lr nq lt lu lv nr lx ly lz ns mb mc md nt mf mg mh nu mj mk ml bi translated">2.<strong class="ak"> nn的输出形状。ConvTranspose2d </strong></h1><p id="8fc2" class="pw-post-body-paragraph ko kp it kq b kr mm kt ku kv mn kx ky kz mo lb lc ld mp lf lg lh mq lj lk ll im bi translated">如果我们改变任务，假设我们想要建立一个模型，该模型能够在给定数据流形的情况下重建图像，该数据流形是具有相关特征的压缩输入。一种特殊类型的前馈神经网络专门用于这项任务，被称为<strong class="kq jd">自动编码器</strong>。它由两个网络组成:编码器和解码器。第一个网络，编码器，压缩输入数据以提取最相关的信息，这些信息将包含在一个缩减的空间中，称为<strong class="kq jd">编码空间</strong>。第二个网络，解码器，是相反的过程。它从这个编码空间恢复数据，并重建原始图像。</p><p id="a077" class="pw-post-body-paragraph ko kp it kq b kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj lk ll im bi translated">仍然有<code class="fe mr ms mt mu b">torch.nn.Conv2d</code>层和<code class="fe mr ms mt mu b">torch.nn.linear</code>层，但也有其他类型的层:</p><p id="8d99" class="pw-post-body-paragraph ko kp it kq b kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj lk ll im bi translated"><code class="fe mr ms mt mu b">nn.ConvTranspose2d(in_channels,out_channels,kernel_size,stride=1,out_padding=0,padding=0,dilation=1)</code></p><p id="ee81" class="pw-post-body-paragraph ko kp it kq b kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj lk ll im bi translated">参数与<code class="fe mr ms mt mu b">nn.Conv2d</code>函数中的相同。解码器由转置卷积层组成，转置卷积层学习“上采样”压缩表示。所以这些函数是卷积运算的逆运算。因此，通道的数量、宽度和高度将逐层增加，而不是减少。</p><p id="08b5" class="pw-post-body-paragraph ko kp it kq b kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj lk ll im bi translated">要计算每个卷积层中高度和宽度的输出维度，在应用池层后，需要记住这两个公式:</p><blockquote class="oe of og"><p id="51be" class="ko kp lm kq b kr ks kt ku kv kw kx ky oh la lb lc oi le lf lg oj li lj lk ll im bi translated">out _ height =(in _ height-1)* stride[0]-2 * padding[0]+exploation[0]*(kernel _ size[0]-1)+output _ padding[0]+1</p><p id="bf2c" class="ko kp lm kq b kr ks kt ku kv kw kx ky oh la lb lc oi le lf lg oj li lj lk ll im bi translated">out _ width =(in _ width-1)* stride[1]-2 * padding[1]+exploation[1]*(kernel _ size[1]-1)+output _ padding[1]+1</p></blockquote></div><div class="ab cl nj nk hx nl" role="separator"><span class="nm bw bk nn no np"/><span class="nm bw bk nn no np"/><span class="nm bw bk nn no"/></div><div class="im in io ip iq"><h1 id="301b" class="lo lp it bd lq lr nq lt lu lv nr lx ly lz ns mb mc md nt mf mg mh nu mj mk ml bi translated">3.CIFAR10上的CNN示例</h1><figure class="oa ob oc od gt kd gh gi paragraph-image"><div class="gh gi ol"><img src="../Images/60a7cbe29f7c36e45875c371013869d7.png" data-original-src="https://miro.medium.com/v2/resize:fit:944/format:webp/0*UfTvlckTIoSvEalS.png"/></div></figure><p id="994d" class="pw-post-body-paragraph ko kp it kq b kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj lk ll im bi translated">来源:<a class="ae ln" href="https://pytorch.org/tutorials/beginner/blitz/cifar10_tutorial.html" rel="noopener ugc nofollow" target="_blank">https://py torch . org/tutorials/初学者/blitz/cifar 10 _ tutorial . html</a></p><p id="e804" class="pw-post-body-paragraph ko kp it kq b kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj lk ll im bi translated">我们来看一个摘自Pytorch官网<a class="ae ln" href="https://pytorch.org/tutorials/beginner/blitz/cifar10_tutorial.html" rel="noopener ugc nofollow" target="_blank"> cifar_tutorial </a>的例子:</p><pre class="oa ob oc od gt om mu on oo aw op bi"><span id="b92e" class="oq lp it mu b gy or os l ot ou"><strong class="mu jd">class</strong> <strong class="mu jd">Net(nn.Module):</strong><br/>    <strong class="mu jd">def</strong> __init__<strong class="mu jd">(</strong>self<strong class="mu jd">):</strong><br/>        super<strong class="mu jd">().</strong>__init__<strong class="mu jd">()</strong><br/>        self<strong class="mu jd">.conv1</strong> <strong class="mu jd">=</strong> <strong class="mu jd">nn.Conv2d(</strong>3<strong class="mu jd">,</strong> 6<strong class="mu jd">,</strong> 5<strong class="mu jd">)</strong><br/>        self<strong class="mu jd">.pool</strong> <strong class="mu jd">=</strong> <strong class="mu jd">nn.MaxPool2d(</strong>2<strong class="mu jd">,</strong> 2<strong class="mu jd">)</strong><br/>        self<strong class="mu jd">.conv2</strong> <strong class="mu jd">=</strong> <strong class="mu jd">nn.Conv2d(</strong>6<strong class="mu jd">,</strong> 16<strong class="mu jd">,</strong> 5<strong class="mu jd">)</strong><br/>        self<strong class="mu jd">.fc1</strong> <strong class="mu jd">=</strong> <strong class="mu jd">nn.Linear(</strong>16 <strong class="mu jd">*</strong> 5 <strong class="mu jd">*</strong> 5<strong class="mu jd">,</strong> 120<strong class="mu jd">)</strong><br/>        self<strong class="mu jd">.fc2</strong> <strong class="mu jd">=</strong> <strong class="mu jd">nn.Linear(</strong>120<strong class="mu jd">,</strong> 84<strong class="mu jd">)</strong><br/>        self<strong class="mu jd">.fc3</strong> <strong class="mu jd">=</strong> <strong class="mu jd">nn.Linear(</strong>84<strong class="mu jd">,</strong> 10<strong class="mu jd">)</strong><br/><br/>    <strong class="mu jd">def</strong> <strong class="mu jd">forward(</strong>self<strong class="mu jd">,</strong> <strong class="mu jd">x):</strong><br/>        <strong class="mu jd">x</strong> <strong class="mu jd">=</strong> self<strong class="mu jd">.pool(F.relu(</strong>self<strong class="mu jd">.conv1(x)))</strong><br/>        <strong class="mu jd">x</strong> <strong class="mu jd">=</strong> self<strong class="mu jd">.pool(F.relu(</strong>self<strong class="mu jd">.conv2(x)))</strong><br/>        <strong class="mu jd">x</strong> <strong class="mu jd">=</strong> <strong class="mu jd">torch.flatten(x,</strong> 1<strong class="mu jd">)</strong> <br/>        <strong class="mu jd">x</strong> <strong class="mu jd">=</strong> <strong class="mu jd">F.relu(</strong>self<strong class="mu jd">.fc1(x))</strong><br/>        <strong class="mu jd">x</strong> <strong class="mu jd">=</strong> <strong class="mu jd">F.relu(</strong>self<strong class="mu jd">.fc2(x))</strong><br/>        <strong class="mu jd">x</strong> <strong class="mu jd">=</strong> self<strong class="mu jd">.fc3(x)</strong><br/>        <strong class="mu jd">return</strong> <strong class="mu jd">x</strong></span></pre><p id="fa8b" class="pw-post-body-paragraph ko kp it kq b kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj lk ll im bi translated">在CNN架构中，我们有两个卷积层和三个线性层。每个卷积层之后是最大池层和作为非线性激活函数的ReLU。您可以快速观察到，第一个卷积层上的输出通道数等于第二个卷积层上的输入通道数。如果检查前一个线性图层的输出要素数和后一个线性图层的输入要素数，情况也是如此。</p><p id="30aa" class="pw-post-body-paragraph ko kp it kq b kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj lk ll im bi translated">我将一步一步地解释输入和输出形状。首先你需要问自己:我的图像的输入形状是什么？它是有色的还是有色的？在本例中，CIFAR10数据集包含大小为<em class="lm"> 3 </em> x <em class="lm"> 32 </em> x <em class="lm"> 32 </em>的图像，并带有3个彩色通道。若要检查定型集的维度，在应用DataLoader之前，您应该编写:</p><pre class="oa ob oc od gt om mu on oo aw op bi"><span id="b957" class="oq lp it mu b gy or os l ot ou">trainset[0][0].shape</span></pre><figure class="oa ob oc od gt kd gh gi paragraph-image"><div class="gh gi ov"><img src="../Images/d7109f9b44485133471f2f9af11e431d.png" data-original-src="https://miro.medium.com/v2/resize:fit:982/format:webp/1*2j5ojkk3G_TVO0lm0kyV4g.png"/></div></figure><p id="1d1c" class="pw-post-body-paragraph ko kp it kq b kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj lk ll im bi translated">要在创建DataLoader对象后查看形状，您应该这样做:</p><pre class="oa ob oc od gt om mu on oo aw op bi"><span id="7a49" class="oq lp it mu b gy or os l ot ou">dataiter1 = iter(trainloader)<br/>images1,labels1 = dataiter1.next()</span><span id="159c" class="oq lp it mu b gy ow os l ot ou">print(type(dataiter1))<br/>print(type(images1))<br/>print(images1.shape)<br/>print(labels1.shape)</span></pre><figure class="oa ob oc od gt kd gh gi paragraph-image"><div role="button" tabindex="0" class="ke kf di kg bf kh"><div class="gh gi ox"><img src="../Images/9eb512537bcac52606770341cf9fe6e0.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*cKwK4ky4GIYKZrgy2ORm-Q.png"/></div></div></figure><p id="bf4b" class="pw-post-body-paragraph ko kp it kq b kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj lk ll im bi translated">返回的第一个形状是图像的形状，另一个是目标的形状。函数<strong class="kq jd"> iter </strong>用于提供一个可迭代的数据集，而<strong class="kq jd"> next </strong>需要得到第一次迭代的第一项。这样，我们可以看到第一个图像的形状，(4，3，32，32)，其中4是选择的批量大小，3是通道的数量，宽度和高度是32。</p><p id="b715" class="pw-post-body-paragraph ko kp it kq b kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj lk ll im bi translated">在<strong class="kq jd">第一个卷积层+maxpooling层</strong>之后，我们将计算输出形状:</p><blockquote class="oe of og"><p id="4ec0" class="ko kp lm kq b kr ks kt ku kv kw kx ky oh la lb lc oi le lf lg oj li lj lk ll im bi translated">out _ width = out _ height =(in _ dim-kernel _ size)/stride+1 =(32–5)/1+1 = 28</p><p id="0c83" class="ko kp lm kq b kr ks kt ku kv kw kx ky oh la lb lc oi le lf lg oj li lj lk ll im bi translated">out_width = out_height = 28/2 = 14</p></blockquote><p id="4a89" class="pw-post-body-paragraph ko kp it kq b kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj lk ll im bi translated">我们对一幅3×32×32的图像进行多次卷积，每次使用不同的5×5大小的滤波器，得到6×28×28的输出。在应用最大池后，窗口大小和跨距配置将产生的输出大小减半，即6 x 14 x 14输出。</p><p id="9f29" class="pw-post-body-paragraph ko kp it kq b kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj lk ll im bi translated">在第二卷积层+maxpooling之后，我们得到:</p><blockquote class="oe of og"><p id="f3b5" class="ko kp lm kq b kr ks kt ku kv kw kx ky oh la lb lc oi le lf lg oj li lj lk ll im bi translated">out _ width = out _ height =(in _ dim-kernel _ size)/stride+1 =(14–5)/1+1 = 10</p><p id="1789" class="ko kp lm kq b kr ks kt ku kv kw kx ky oh la lb lc oi le lf lg oj li lj lk ll im bi translated">out_width = out_height = 10/2 = 5</p></blockquote><p id="c9a9" class="pw-post-body-paragraph ko kp it kq b kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj lk ll im bi translated">在第二卷积层+maxpooling之后，我们将3D输出展平为一维向量:</p><blockquote class="oe of og"><p id="432c" class="ko kp lm kq b kr ks kt ku kv kw kx ky oh la lb lc oi le lf lg oj li lj lk ll im bi translated">out _ dim = out _ channels x out _ height x out _ width = 16 x 5 x 5</p></blockquote><p id="1c10" class="pw-post-body-paragraph ko kp it kq b kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj lk ll im bi translated">现在最难的部分完成了！最后，您需要在最后一个完全连接的层(称为输出层)中指定输出隐藏单元的数量。目标是将图像分类到10类中的一类。因此输出特征的数量将是10。</p></div><div class="ab cl nj nk hx nl" role="separator"><span class="nm bw bk nn no np"/><span class="nm bw bk nn no np"/><span class="nm bw bk nn no"/></div><div class="im in io ip iq"><h1 id="a414" class="lo lp it bd lq lr nq lt lu lv nr lx ly lz ns mb mc md nt mf mg mh nu mj mk ml bi translated">4.CIFAR10上的自动编码器示例</h1><p id="34cf" class="pw-post-body-paragraph ko kp it kq b kr mm kt ku kv mn kx ky kz mo lb lc ld mp lf lg lh mq lj lk ll im bi translated">让我们来看一个取自<a class="ae ln" href="https://analyticsindiamag.com/how-to-implement-convolutional-autoencoder-in-pytorch-with-cuda/" rel="noopener ugc nofollow" target="_blank"> analyticsindiamag </a>网站的例子，略有改动。卷积自动编码器再次应用于CIFAR10数据集。</p><pre class="oa ob oc od gt om mu on oo aw op bi"><span id="3712" class="oq lp it mu b gy or os l ot ou">class Autoencoder(nn.Module):<br/>    def __init__(self,d=2):<br/>        super(Autoencoder, self).__init__()<br/>  <br/>        # encoder<br/>        self.<strong class="mu jd">enc1</strong> = nn.Conv2d(<br/>            in_channels=3, out_channels=8, kernel_size=3,stride=2<br/>        )<br/>        # out_width = (32-3)/2+1 = 29/2+1 = 15<br/>        self.<strong class="mu jd">enc2</strong> = nn.Conv2d(<br/>            in_channels=8, out_channels=16, kernel_size=3,stride=2<br/>        )</span><span id="4093" class="oq lp it mu b gy ow os l ot ou">        self.<strong class="mu jd">enc3</strong> = nn.Flatten(start_dim=1)<br/>        self.<strong class="mu jd">enc4</strong> = nn.Linear(7*7*16, d)   <br/>  <br/>        # decoder <br/>  <br/>        self.<strong class="mu jd">dec1</strong> = nn.Linear(d,7*7*16)<br/>        self.<strong class="mu jd">dec2</strong> = nn.Unflatten(dim=1, unflattened_size=(16, 7, 7))<br/>        self.<strong class="mu jd">dec3</strong> = nn.ConvTranspose2d(<br/>            in_channels=16, out_channels=8, kernel_size=3,stride=2 <br/>        )<br/>        self.<strong class="mu jd">dec4</strong> = nn.ConvTranspose2d(in_channels=8,               out_channels=3, kernel_size=3,stride=2,output_padding=1<br/>        )</span><span id="4313" class="oq lp it mu b gy ow os l ot ou">    def forward(self, x):<br/>       x = F.relu(self.<strong class="mu jd">enc1</strong>(x))<br/>       x = F.relu(self.<strong class="mu jd">enc2</strong>(x))<br/>       x = self.<strong class="mu jd">enc3</strong>(x)<br/>       x = self.<strong class="mu jd">enc4</strong>(x)</span><span id="9b96" class="oq lp it mu b gy ow os l ot ou">       x = F.relu(self.<strong class="mu jd">dec1</strong>(x))<br/>       x = self.<strong class="mu jd">dec2</strong>(x)<br/>       x = F.relu(self.<strong class="mu jd">dec3</strong>(x))<br/>       x = torch.sigmoid(self.<strong class="mu jd">dec4</strong>(x))</span><span id="380c" class="oq lp it mu b gy ow os l ot ou">       return x</span></pre><p id="7b61" class="pw-post-body-paragraph ko kp it kq b kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj lk ll im bi translated">我们可以一步一步地计算形状。首先，我们知道原图是3×32×32。</p><p id="7b71" class="pw-post-body-paragraph ko kp it kq b kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj lk ll im bi translated">现在，让我们看看<strong class="kq jd">编码器</strong>的形状:</p><ul class=""><li id="b867" class="mv mw it kq b kr ks kv kw kz nv ld nw lh nx ll ny nb nc nd bi translated">[con v1]:out _ width = out _ height =(32–3)/2+1 = 29/2+1 = 15</li><li id="71e7" class="mv mw it kq b kr ne kv nf kz ng ld nh lh ni ll ny nb nc nd bi translated">[con v2]:out _ width = out _ height =(15–3)/2+1 = 7</li><li id="7921" class="mv mw it kq b kr ne kv nf kz ng ld nh lh ni ll ny nb nc nd bi translated">[展平]: 7x7x16</li><li id="30f9" class="mv mw it kq b kr ne kv nf kz ng ld nh lh ni ll ny nb nc nd bi translated">[线性]: d=2</li></ul><p id="5517" class="pw-post-body-paragraph ko kp it kq b kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj lk ll im bi translated">一旦定义了编码器，<strong class="kq jd">解码器</strong>将恢复编码空间d中的信息，我们将重建图像，图像大小需要为3×32×32:</p><ul class=""><li id="2da9" class="mv mw it kq b kr ks kv kw kz nv ld nw lh nx ll ny nb nc nd bi translated">[线性]: 7x7x16</li><li id="0b79" class="mv mw it kq b kr ne kv nf kz ng ld nh lh ni ll ny nb nc nd bi translated">(16，7，7)</li><li id="aef4" class="mv mw it kq b kr ne kv nf kz ng ld nh lh ni ll ny nb nc nd bi translated">[con v1]:out _ width = out _ height =(7–1)* 2+3 = 15</li><li id="62b6" class="mv mw it kq b kr ne kv nf kz ng ld nh lh ni ll ny nb nc nd bi translated">[con v2]:out _ width = out _ height =(15–1)* 2+3 = 28+1+3 = 32</li></ul></div><div class="ab cl nj nk hx nl" role="separator"><span class="nm bw bk nn no np"/><span class="nm bw bk nn no np"/><span class="nm bw bk nn no"/></div><div class="im in io ip iq"><h1 id="f081" class="lo lp it bd lq lr nq lt lu lv nr lx ly lz ns mb mc md nt mf mg mh nu mj mk ml bi translated"><strong class="ak">总结</strong></h1><ul class=""><li id="0a23" class="mv mw it kq b kr mm kv mn kz mx ld my lh mz ll ny nb nc nd bi translated">您的图像的输入形状为(<em class="lm">批量大小</em>、<em class="lm">通道</em>、<em class="lm">深度</em>、<em class="lm">高度</em>、<em class="lm">宽度</em>)</li><li id="e609" class="mv mw it kq b kr ne kv nf kz ng ld nh lh ni ll ny nb nc nd bi translated"><em class="lm">out _ width = out _ height =(in _ width-2 * padding-kernel _ size)/stride+1</em>在<strong class="kq jd"> nn的大多数情况下。Conv2d </strong></li><li id="0259" class="mv mw it kq b kr ne kv nf kz ng ld nh lh ni ll ny nb nc nd bi translated">第一个完全连接的层将接收具有形状的一维向量(<em class="lm">输出通道x输出高度x输出宽度</em></li><li id="c80d" class="mv mw it kq b kr ne kv nf kz ng ld nh lh ni ll ny nb nc nd bi translated"><em class="lm">out _ width = out _ height =</em>(<em class="lm">in _ width</em>–1)* stride+kernel _ size<em class="lm">-2 * padding</em>+out _ padding+1<strong class="kq jd">conv transpose 2d</strong></li></ul></div><div class="ab cl nj nk hx nl" role="separator"><span class="nm bw bk nn no np"/><span class="nm bw bk nn no np"/><span class="nm bw bk nn no"/></div><div class="im in io ip iq"><h1 id="e13a" class="lo lp it bd lq lr nq lt lu lv nr lx ly lz ns mb mc md nt mf mg mh nu mj mk ml bi translated">最终想法:</h1><p id="7485" class="pw-post-body-paragraph ko kp it kq b kr mm kt ku kv mn kx ky kz mo lb lc ld mp lf lg lh mq lj lk ll im bi translated">我希望这篇教程能让你更好地使用Pytorch构建CNN架构。这很容易受阻，因为有些事情在头脑中不是很清楚，有时你需要从基础开始前进。感谢阅读。祝您愉快！</p></div><div class="ab cl nj nk hx nl" role="separator"><span class="nm bw bk nn no np"/><span class="nm bw bk nn no np"/><span class="nm bw bk nn no"/></div><div class="im in io ip iq"><p id="7931" class="pw-post-body-paragraph ko kp it kq b kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj lk ll im bi translated">你喜欢我的文章吗？<a class="ae ln" href="https://eugenia-anello.medium.com/membership" rel="noopener"> <em class="lm">成为会员</em> </a> <em class="lm">每天无限获取数据科学新帖！这是一种间接的支持我的方式，不会给你带来任何额外的费用。如果您已经是会员，</em> <a class="ae ln" href="https://eugenia-anello.medium.com/subscribe" rel="noopener"> <em class="lm">订阅</em> </a> <em class="lm">每当我发布新的数据科学和python指南时，您都会收到电子邮件！</em></p></div></div>    
</body>
</html>