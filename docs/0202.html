<html>
<head>
<title>Free ObjDetection API from EazyMind</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">EazyMind提供的免费对象检测API</h1>
<blockquote>原文：<a href="https://pub.towardsai.net/free-objdetection-api-from-eazymind-tut-1-2159e6ffd25d?source=collection_archive---------0-----------------------#2019-11-20">https://pub.towardsai.net/free-objdetection-api-from-eazymind-tut-1-2159e6ffd25d?source=collection_archive---------0-----------------------#2019-11-20</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><h2 id="d7ad" class="io ip iq bd b dl ir is it iu iv iw dk ix translated" aria-label="kicker paragraph">物体检测教程，第一部分| <a class="ae ep" href="https://towardsai.net" rel="noopener ugc nofollow" target="_blank">走向AI </a></h2><div class=""/><p id="3697" class="pw-post-body-paragraph jw jx iq jy b jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ij bi translated">本系列教程介绍了<a class="ae ku" href="http://bit.ly/2VxhPqU" rel="noopener ugc nofollow" target="_blank"> EazyMind </a>(一个人工智能即服务平台)提供的不同API。<a class="ae ku" href="http://bit.ly/2VxhPqU" rel="noopener ugc nofollow" target="_blank"> EazyMind </a>免费提供多项AI服务；Obj检测就是其中之一！</p><p id="38d7" class="pw-post-body-paragraph jw jx iq jy b jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ij bi translated">EazyMind 也提供<a class="ae ku" href="http://bit.ly/eazysum" rel="noopener ugc nofollow" target="_blank">文本摘要</a>作为另一个免费的API。</p><figure class="kw kx ky kz gt la gh gi paragraph-image"><div role="button" tabindex="0" class="lb lc di ld bf le"><div class="gh gi kv"><img src="../Images/b06c7f888eaae7df4136e4beec2545ec.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*tm4MZj4dEitncZb-.jpeg"/></div></div><figcaption class="lh li gj gh gi lj lk bd b be z dk translated">EazyMind还提供免费的文本摘要API</figcaption></figure><p id="cf52" class="pw-post-body-paragraph jw jx iq jy b jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ij bi translated">今天我们将介绍如何使用<a class="ae ku" href="http://bit.ly/2VxhPqU" rel="noopener ugc nofollow" target="_blank"> EazyMind </a>提供的<strong class="jy ja">对象检测API </strong>。我们还将介绍这个API是如何构建的，所以让我们开始吧！！</p><figure class="kw kx ky kz gt la gh gi paragraph-image"><div role="button" tabindex="0" class="lb lc di ld bf le"><div class="gh gi ll"><img src="../Images/47f685dce1ee458ce6073c1e56989cf9.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*jI1r-jH4pk74d1Sjg0SoJQ.jpeg"/></div></div></figure><figure class="kw kx ky kz gt la gh gi paragraph-image"><div role="button" tabindex="0" class="lb lc di ld bf le"><div class="gh gi ll"><img src="../Images/79ae0490a8a1f802155c0e6afd015722.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*T0fhD_IgwtruvxHV2EQkpA.jpeg"/></div></div></figure><h1 id="5b4f" class="lm ln iq bd lo lp lq lr ls lt lu lv lw lx ly lz ma mb mc md me mf mg mh mi mj bi translated">1.如何在你的项目中使用ObjDetecion免费API</h1><p id="0f8e" class="pw-post-body-paragraph jw jx iq jy b jz mk kb kc kd ml kf kg kh mm kj kk kl mn kn ko kp mo kr ks kt ij bi translated"><a class="ae ku" href="http://bit.ly/2VxhPqU" rel="noopener ugc nofollow" target="_blank"> EazyMind </a>以<a class="ae ku" href="http://bit.ly/2Ef5XnS" rel="noopener ugc nofollow" target="_blank"> python PyPI </a>包的形式提供其免费API，你需要在<a class="ae ku" href="http://bit.ly/2VxhPqU" rel="noopener ugc nofollow" target="_blank"> EazyMind </a>上免费注册，然后使用你的密钥访问该API</p><ol class=""><li id="89a4" class="mp mq iq jy b jz ka kd ke kh mr kl ms kp mt kt mu mv mw mx bi translated">在<a class="ae ku" href="http://bit.ly/2VxhPqU" rel="noopener ugc nofollow" target="_blank"> EazyMind </a>上的第一个自由注册</li><li id="5485" class="mp mq iq jy b jz my kd mz kh na kl nb kp nc kt mu mv mw mx bi translated">拿你的钥匙</li><li id="e29a" class="mp mq iq jy b jz my kd mz kh na kl nb kp nc kt mu mv mw mx bi translated">安装python包</li></ol><pre class="kw kx ky kz gt nd ne nf ng aw nh bi"><span id="0363" class="ni ln iq ne b gy nj nk l nl nm">pip install eazymind</span></pre><p id="129e" class="pw-post-body-paragraph jw jx iq jy b jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ij bi translated">4.然后使用API本身</p><pre class="kw kx ky kz gt nd ne nf ng aw nh bi"><span id="6768" class="ni ln iq ne b gy nj nk l nl nm">from eazymind.vision.eazyobjdetect import  Detector<br/>key = "xxxxxxxxxxxx"</span><span id="811c" class="ni ln iq ne b gy nn nk l nl nm">with open("image1.jpg" , "rb") as img:<br/>    detector = Detector(key)<br/>    detected_image = detector.run(img.read())<br/>    with open("out_detected.jpg" , "wb") as out_img:<br/>        out_img.write(detected_image)</span></pre><p id="39d8" class="pw-post-body-paragraph jw jx iq jy b jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ij bi translated">注意:你也可以通过curl调用来使用这个API</p><pre class="kw kx ky kz gt nd ne nf ng aw nh bi"><span id="b901" class="ni ln iq ne b gy nj nk l nl nm">curl -X POST  <br/>  http://eazymind.herokuapp.com/arabic_sum/eazyobjdetect <br/>  -F imagedata=@{imagefile}.jpg <br/>  -F key={eazymind api key} <br/>  -o {outputfile}.jpg</span></pre><p id="cf42" class="pw-post-body-paragraph jw jx iq jy b jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ij bi translated">您可以进一步扩展这个API，用任何其他语言调用它，因为毕竟它只是HTTP调用。</p><p id="1119" class="pw-post-body-paragraph jw jx iq jy b jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ij bi translated">现在，让我们进一步了解这个API是如何构建的！！</p><h1 id="e9fd" class="lm ln iq bd lo lp lq lr ls lt lu lv lw lx ly lz ma mb mc md me mf mg mh mi mj bi translated">2.API的构建方式</h1><p id="7272" class="pw-post-body-paragraph jw jx iq jy b jz mk kb kc kd ml kf kg kh mm kj kk kl mn kn ko kp mo kr ks kt ij bi translated">我们已经创建了这个API，作为谷歌通过使<a class="ae ku" href="https://github.com/tensorflow/models/blob/master/research/object_detection/object_detection_tutorial.ipynb" rel="noopener ugc nofollow" target="_blank">他们的工作开源</a>所做的巨大努力的延伸，我真诚地感谢他们将他们的工作公之于众，我们已经通过一个API将他们的工作包装在<a class="ae ku" href="http://bit.ly/2VxhPqU" rel="noopener ugc nofollow" target="_blank"> EazyMind </a>中。</p><h2 id="ee5f" class="ni ln iq bd lo no np dn ls nq nr dp lw kh ns nt ma kl nu nv me kp nw nx mi iw bi translated">2a。使用的模型</h2><p id="f512" class="pw-post-body-paragraph jw jx iq jy b jz mk kb kc kd ml kf kg kh mm kj kk kl mn kn ko kp mo kr ks kt ij bi translated">谷歌已经为ObjDetection提供了一个<a class="ae ku" href="https://github.com/tensorflow/models/blob/master/research/object_detection/g3doc/detection_model_zoo.md" rel="noopener ugc nofollow" target="_blank">型号列表</a>，它们提供了速度和精度之间的平衡，我们选择了<strong class="jy ja"> ssd_mobilenet_v1_coco </strong>作为我们的选择型号</p><h2 id="0999" class="ni ln iq bd lo no np dn ls nq nr dp lw kh ns nt ma kl nu nv me kp nw nx mi iw bi translated">2b。张量流模型</h2><p id="e08a" class="pw-post-body-paragraph jw jx iq jy b jz mk kb kc kd ml kf kg kh mm kj kk kl mn kn ko kp mo kr ks kt ij bi translated">我们已经使用了<a class="ae ku" href="https://github.com/tensorflow/models/blob/master/research/object_detection/object_detection_tutorial.ipynb" rel="noopener ugc nofollow" target="_blank">这个代码库</a>并将其添加到<a class="ae ku" href="http://bit.ly/2VxhPqU" rel="noopener ugc nofollow" target="_blank"> EazyMind </a>中。它建成了</p></div><div class="ab cl ny nz hu oa" role="separator"><span class="ob bw bk oc od oe"/><span class="ob bw bk oc od oe"/><span class="ob bw bk oc od"/></div><div class="ij ik il im in"><p id="79df" class="pw-post-body-paragraph jw jx iq jy b jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ij bi translated"><a class="ae ku" href="http://bit.ly/2VxhPqU" rel="noopener ugc nofollow" target="_blank"> EazyMind </a>也提供了<a class="ae ku" href="http://bit.ly/eazysum" rel="noopener ugc nofollow" target="_blank">文本摘要</a>作为另一个免费的API，看看吧！！</p><pre class="kw kx ky kz gt nd ne nf ng aw nh bi"><span id="13d0" class="ni ln iq ne b gy nj nk l nl nm">from eazymind.nlp.eazysum import Summarizer<br/>key = "xxxxxxxxxxxx"</span><span id="09d6" class="ni ln iq ne b gy nn nk l nl nm">sentence = """Facebook CEO Mark Zuckerberg, left, makes the keynote speech at F8, the Facebook's developer conference, Tuesday, April 30, 2019, in San Jose, Calif. (AP Photo/Tony Avelar )<br/>Facebook says that, unlike its past, its future is privacy<br/>A trader works ahead of the closing bell on the floor of the New York Stock Exchange (NYSE) on April 12, 2019 in New York City. (Photo by Johannes EISELE / AFP)        (Photo credit should read JOHANNES EISELE/AFP/Getty Images)<br/>Resilience is still the word for stocks"""</span><span id="6487" class="ni ln iq ne b gy nn nk l nl nm">summarizer = Summarizer(key)<br/>print(summarizer.run(sentence))</span></pre><p id="c17f" class="pw-post-body-paragraph jw jx iq jy b jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ij bi translated">如果你喜欢文本摘要的概念，我们已经发布了多个关于这个主题的教程，你可以在这里找到这些博客<a class="ae ku" href="https://github.com/theamrzaki/text_summurization_abstractive_methods#blogs" rel="noopener ugc nofollow" target="_blank">的链接，在这里</a>找到它的开源代码<a class="ae ku" href="http://bit.ly/eazysum" rel="noopener ugc nofollow" target="_blank">。</a></p><blockquote class="of og oh"><p id="9872" class="jw jx oi jy b jz ka kb kc kd ke kf kg oj ki kj kk ok km kn ko ol kq kr ks kt ij bi translated"><em class="iq">我真心希望你喜欢阅读本教程，并且</em>我真心希望这些API对你有所帮助<em class="iq">。</em></p><p id="f282" class="jw jx oi jy b jz ka kb kc kd ke kf kg oj ki kj kk ok km kn ko ol kq kr ks kt ij bi translated"><a class="ae ku" href="https://www.facebook.com/profile.php?id=445521342941282&amp;ref=br_rs" rel="noopener ugc nofollow" target="_blank"> <em class="iq">关注脸书页面上的EazyMind</em></a><em class="iq">至</em> <strong class="jy ja"> <em class="iq">享受免费的AI项目咨询。</em>T25】</strong></p><p id="e96e" class="jw jx oi jy b jz ka kb kc kd ke kf kg oj ki kj kk ok km kn ko ol kq kr ks kt ij bi translated"><em class="iq">希望在谈论EazyMind的其他功能时再次见到您，以保持对:D的关注</em></p></blockquote></div></div>    
</body>
</html>