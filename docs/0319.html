<html>
<head>
<title>NLP News Cypher | 02.16.20</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">NLP新闻密码| 02.16.20</h1>
<blockquote>原文：<a href="https://pub.towardsai.net/nlp-news-cypher-02-16-20-e3101b7400cb?source=collection_archive---------2-----------------------#2020-02-17">https://pub.towardsai.net/nlp-news-cypher-02-16-20-e3101b7400cb?source=collection_archive---------2-----------------------#2020-02-17</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><figure class="ip iq gp gr ir is gh gi paragraph-image"><div role="button" tabindex="0" class="it iu di iv bf iw"><div class="gh gi io"><img src="../Images/861b1d6106db00181d62c53ece474c63.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*Np0-K85GbfTJ5X3s"/></div></div><figcaption class="iz ja gj gh gi jb jc bd b be z dk translated">戴维·阿拉克里扬在<a class="ae jd" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上的照片</figcaption></figure><h2 id="855d" class="je jf jg bd b dl jh ji jj jk jl jm dk jn translated" aria-label="kicker paragraph">自然语言处理每周时事通讯</h2><div class=""/><div class=""><h2 id="d5de" class="pw-subtitle-paragraph km jp jg bd b kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld dk translated">天空中伟大的演出</h2></div></div><div class="ab cl le lf hu lg" role="separator"><span class="lh bw bk li lj lk"/><span class="lh bw bk li lj lk"/><span class="lh bw bk li lj"/></div><div class="ij ik il im in"><p id="fbbc" class="pw-post-body-paragraph ll lm jg ln b lo lp kq lq lr ls kt lt lu lv lw lx ly lz ma mb mc md me mf mg ij bi mh translated">第二…我们回来了！你这周过得怎么样？</p><p id="4aee" class="pw-post-body-paragraph ll lm jg ln b lo lp kq lq lr ls kt lt lu lv lw lx ly lz ma mb mc md me mf mg ij bi translated">上周是非常有趣和冒险的，许多新的数据集、研究和NLP研究被一炮打响！</p><p id="a895" class="pw-post-body-paragraph ll lm jg ln b lo lp kq lq lr ls kt lt lu lv lw lx ly lz ma mb mc md me mf mg ij bi translated">也是在纽约，AAAI会议召开了。在那里，图灵奖获得者(LeCun、Bengio和Hinton)聚在一起进行了一些激动人心的演讲。</p><p id="d47f" class="pw-post-body-paragraph ll lm jg ln b lo lp kq lq lr ls kt lt lu lv lw lx ly lz ma mb mc md me mf mg ij bi translated">Yoshua非常兴奋，他甚至开了一个博客…他的第一句话是:</p><div class="ip iq gp gr ir mq"><a href="https://yoshuabengio.org/2020/02/10/fusce-risus/" rel="noopener  ugc nofollow" target="_blank"><div class="mr ab fo"><div class="ms ab mt cl cj mu"><h2 class="bd jq gy z fp mv fr fs mw fu fw jp bi translated">Yoshua Bengio的博客-第一句话- Yoshua Bengio</h2><div class="mx l"><h3 class="bd b gy z fp mv fr fs mw fu fw dk translated">我经常在社交媒体上写评论和帖子，但这些往往只是暂时可见的，所以我想我需要一个…</h3></div><div class="my l"><p class="bd b dl z fp mv fr fs mw fu fw dk translated">yoshuabengio.org</p></div></div><div class="mz l"><div class="na l nb nc nd mz ne ix mq"/></div></div></a></div><p id="2032" class="pw-post-body-paragraph ll lm jg ln b lo lp kq lq lr ls kt lt lu lv lw lx ly lz ma mb mc md me mf mg ij bi translated">Yann发表了演讲并分享了幻灯片:</p><div class="ip iq gp gr ir mq"><a href="https://drive.google.com/file/d/1r-mDL4IX_hzZLDBKp8_e8VZqD7fOzBkF/view" rel="noopener  ugc nofollow" target="_blank"><div class="mr ab fo"><div class="ms ab mt cl cj mu"><h2 class="bd jq gy z fp mv fr fs mw fu fw jp bi translated">lecun-20200209-aaai.pdf</h2><div class="mx l"><h3 class="bd b gy z fp mv fr fs mw fu fw dk translated">编辑描述</h3></div><div class="my l"><p class="bd b dl z fp mv fr fs mw fu fw dk translated">drive.google.com</p></div></div><div class="mz l"><div class="nf l nb nc nd mz ne ix mq"/></div></div></a></div><p id="a21f" class="pw-post-body-paragraph ll lm jg ln b lo lp kq lq lr ls kt lt lu lv lw lx ly lz ma mb mc md me mf mg ij bi translated">Yann的自我监督学习谈话显示了NLP在过去几年里给我们带来了多少。你可能从BERT和其他变形金刚那里听说过“屏蔽”，这种过滤掉数据导致模型适应信息缺乏的关键概念是幻灯片的症结所在，其后果是深远的。问问计算机视觉领域的人就知道了:</p><figure class="ng nh ni nj gt is"><div class="bz fp l di"><div class="nk nl l"/></div></figure><p id="b229" class="pw-post-body-paragraph ll lm jg ln b lo lp kq lq lr ls kt lt lu lv lw lx ly lz ma mb mc md me mf mg ij bi translated">最后但同样重要的是，在AAAI会议上，杰出论文奖授予了艾伦研究所WinoGrande数据集的作者。特别感谢Chandra在几周前向我们转发了数据集。它已经被添加到<a class="ae jd" href="https://quantumstat.com/dataset/dataset.html" rel="noopener ugc nofollow" target="_blank">大坏NLP数据库</a>的保险库中。👍</p><figure class="ng nh ni nj gt is"><div class="bz fp l di"><div class="nk nl l"/></div></figure></div><div class="ab cl le lf hu lg" role="separator"><span class="lh bw bk li lj lk"/><span class="lh bw bk li lj lk"/><span class="lh bw bk li lj"/></div><div class="ij ik il im in"><h1 id="f3c4" class="nm nn jg bd no np nq nr ns nt nu nv nw kv nx kw ny ky nz kz oa lb ob lc oc od bi translated">本周:</h1><blockquote class="oe of og"><p id="237e" class="ll lm oh ln b lo lp kq lq lr ls kt lt oi lv lw lx oj lz ma mb ok md me mf mg ij bi translated">高尔基图来了</p><p id="c8a6" class="ll lm oh ln b lo lp kq lq lr ls kt lt oi lv lw lx oj lz ma mb ok md me mf mg ij bi translated">压缩伯特</p><p id="c3d6" class="ll lm oh ln b lo lp kq lq lr ls kt lt oi lv lw lx oj lz ma mb ok md me mf mg ij bi translated">DeepMind保持PG-19</p><p id="3d77" class="ll lm oh ln b lo lp kq lq lr ls kt lt oi lv lw lx oj lz ma mb ok md me mf mg ij bi translated">极速和零度冷却</p><p id="7729" class="ll lm oh ln b lo lp kq lq lr ls kt lt oi lv lw lx oj lz ma mb ok md me mf mg ij bi translated">开域QA反击！</p><p id="c169" class="ll lm oh ln b lo lp kq lq lr ls kt lt oi lv lw lx oj lz ma mb ok md me mf mg ij bi translated">为什么模型会失败</p><p id="14be" class="ll lm oh ln b lo lp kq lq lr ls kt lt oi lv lw lx oj lz ma mb ok md me mf mg ij bi translated">卡格尔，科拉布和伯恩斯先生</p><p id="0a28" class="ll lm oh ln b lo lp kq lq lr ls kt lt oi lv lw lx oj lz ma mb ok md me mf mg ij bi translated">本周数据集:WinoGrande</p></blockquote></div><div class="ab cl le lf hu lg" role="separator"><span class="lh bw bk li lj lk"/><span class="lh bw bk li lj lk"/><span class="lh bw bk li lj"/></div><div class="ij ik il im in"><h1 id="5d8a" class="nm nn jg bd no np nq nr ns nt nu nv nw kv nx kw ny ky nz kz oa lb ob lc oc od bi translated">高尔基图来了</h1><p id="576c" class="pw-post-body-paragraph ll lm jg ln b lo ol kq lq lr om kt lt lu on lw lx ly oo ma mb mc op me mf mg ij bi translated"><em class="oh">“今年AAAI共收到1591篇论文，其中约有140篇与图形相关。”</em></p><p id="7252" class="pw-post-body-paragraph ll lm jg ln b lo lp kq lq lr ls kt lt lu lv lw lx ly lz ma mb mc md me mf mg ij bi translated">不能有一个会议不提到高尔金的知识图的覆盖范围！</p><p id="ac2b" class="pw-post-body-paragraph ll lm jg ln b lo lp kq lq lr ls kt lt lu lv lw lx ly lz ma mb mc md me mf mg ij bi translated">流行什么</p><p id="b6f7" class="pw-post-body-paragraph ll lm jg ln b lo lp kq lq lr ls kt lt lu lv lw lx ly lz ma mb mc md me mf mg ij bi translated">在语言模型上转储知识图…</p><p id="f22a" class="pw-post-body-paragraph ll lm jg ln b lo lp kq lq lr ls kt lt lu lv lw lx ly lz ma mb mc md me mf mg ij bi translated">不同模式知识图上的实体匹配…</p><p id="c355" class="pw-post-body-paragraph ll lm jg ln b lo lp kq lq lr ls kt lt lu lv lw lx ly lz ma mb mc md me mf mg ij bi translated">时态知识图也称为动态图…</p><p id="78e5" class="pw-post-body-paragraph ll lm jg ln b lo lp kq lq lr ls kt lt lu lv lw lx ly lz ma mb mc md me mf mg ij bi translated">对于那些构建面向目标的机器人来说👇，请查阅模式引导的对话状态跟踪研讨会论文:</p><figure class="ng nh ni nj gt is"><div class="bz fp l di"><div class="oq nl l"/></div><figcaption class="iz ja gj gh gi jb jc bd b be z dk translated"><a class="ae jd" href="https://arxiv.org/pdf/2002.01359.pdf" rel="noopener ugc nofollow" target="_blank">链接</a></figcaption></figure><div class="ip iq gp gr ir mq"><a href="https://medium.com/@mgalkin/knowledge-graphs-aaai-2020-c457ad5aafc0" rel="noopener follow" target="_blank"><div class="mr ab fo"><div class="ms ab mt cl cj mu"><h2 class="bd jq gy z fp mv fr fs mw fu fw jp bi translated">知识图表@ AAAI 2020</h2><div class="mx l"><h3 class="bd b gy z fp mv fr fs mw fu fw dk translated">2020的第一个重大AI事件已经来了！希望你假期过得愉快🎄，或者新年快乐，如果你的…</h3></div><div class="my l"><p class="bd b dl z fp mv fr fs mw fu fw dk translated">medium.com</p></div></div><div class="mz l"><div class="or l nb nc nd mz ne ix mq"/></div></div></a></div><h1 id="a3d4" class="nm nn jg bd no np os nr ns nt ot nv nw kv ou kw ny ky ov kz oa lb ow lc oc od bi translated">压缩伯特</h1><p id="91a1" class="pw-post-body-paragraph ll lm jg ln b lo ol kq lq lr om kt lt lu on lw lx ly oo ma mb mc op me mf mg ij bi translated">Peeps在拥抱脸的社区图书馆上丢了一个新的BERT。这是BERT的压缩版本，在6个粘合任务上优于蒸馏版本(实际上与基本模型相当)！这对那些希望在计算上省钱的人来说太棒了！(和我一样😁)</p><div class="ip iq gp gr ir mq"><a href="https://huggingface.co/canwenxu/BERT-of-Theseus-MNLI" rel="noopener  ugc nofollow" target="_blank"><div class="mr ab fo"><div class="ms ab mt cl cj mu"><h2 class="bd jq gy z fp mv fr fs mw fu fw jp bi translated">残文旭/伯特修斯-MNLI拥抱脸</h2><div class="mx l"><h3 class="bd b gy z fp mv fr fs mw fu fw dk translated">参见我们的论文“BERT-of-Theseus:通过渐进式模块替换压缩BERT”。忒修斯的伯特是一个新的压缩…</h3></div><div class="my l"><p class="bd b dl z fp mv fr fs mw fu fw dk translated">huggingface.co</p></div></div><div class="mz l"><div class="ox l nb nc nd mz ne ix mq"/></div></div></a></div><h1 id="62bf" class="nm nn jg bd no np os nr ns nt ot nv nw kv ou kw ny ky ov kz oa lb ow lc oc od bi translated">DeepMind保持PG-19</h1><p id="d07a" class="pw-post-body-paragraph ll lm jg ln b lo ol kq lq lr om kt lt lu on lw lx ly oo ma mb mc op me mf mg ij bi translated">这家研究巨头发布了一个新的转换器Compressive Transformer和一个新的数据集PG-19，用于语言建模。</p><p id="7cad" class="pw-post-body-paragraph ll lm jg ln b lo lp kq lq lr ls kt lt lu lv lw lx ly lz ma mb mc md me mf mg ij bi translated">该数据集由1919年前出版的古登堡计划的28，000本书组成。</p><p id="13d4" class="pw-post-body-paragraph ll lm jg ln b lo lp kq lq lr ls kt lt lu lv lw lx ly lz ma mb mc md me mf mg ij bi translated">transformer的目标是通过能够维护书籍文本的长上下文来帮助解决当前transformer的内存限制。</p><blockquote class="oe of og"><p id="931e" class="ll lm oh ln b lo lp kq lq lr ls kt lt oi lv lw lx oj lz ma mb ok md me mf mg ij bi translated">“压缩变形金刚能够产生各种风格的叙事，从多角色对话，第一人称日记条目，或第三人称散文。”</p></blockquote><p id="db4a" class="pw-post-body-paragraph ll lm jg ln b lo lp kq lq lr ls kt lt lu lv lw lx ly lz ma mb mc md me mf mg ij bi translated"><strong class="ln jq">博客:</strong></p><div class="ip iq gp gr ir mq"><a href="https://deepmind.com/blog/article/A_new_model_and_dataset_for_long-range_memory" rel="noopener  ugc nofollow" target="_blank"><div class="mr ab fo"><div class="ms ab mt cl cj mu"><h2 class="bd jq gy z fp mv fr fs mw fu fw jp bi translated">一个新的长期记忆模型和数据集</h2><div class="mx l"><h3 class="bd b gy z fp mv fr fs mw fu fw dk translated">这个博客介绍了一个新的长期记忆模型，压缩变压器，以及一个新的基准…</h3></div><div class="my l"><p class="bd b dl z fp mv fr fs mw fu fw dk translated">deepmind.com</p></div></div><div class="mz l"><div class="oy l nb nc nd mz ne ix mq"/></div></div></a></div><h1 id="7ff9" class="nm nn jg bd no np os nr ns nt ot nv nw kv ou kw ny ky ov kz oa lb ow lc oc od bi translated">极速和零度冷却</h1><p id="2063" class="pw-post-body-paragraph ll lm jg ln b lo ol kq lq lr om kt lt lu on lw lx ly oo ma mb mc op me mf mg ij bi translated">微软不得不提醒大型科技公司，它有一些王牌。它发布了一个名为DeepSpeed的新库。这是什么？</p><blockquote class="oe of og"><p id="0fd8" class="ll lm oh ln b lo lp kq lq lr ls kt lt oi lv lw lx oj lz ma mb ok md me mf mg ij bi translated">“…[它]是一种新的并行化优化器，它大大减少了模型和数据并行所需的资源，同时大幅增加了可训练的参数数量。研究人员利用这些突破创造了图灵自然语言生成(<a class="ae jd" href="https://www.microsoft.com/en-us/research/blog/turing-nlg-a-17-billion-parameter-language-model-by-microsoft" rel="noopener ugc nofollow" target="_blank">图灵-NLG </a>)，这是最大的公共已知语言模型，有170亿个参数，你可以在这篇附带的博客文章中了解更多关于<a class="ae jd" href="https://www.microsoft.com/en-us/research/blog/turing-nlg-a-17-billion-parameter-language-model-by-microsoft" rel="noopener ugc nofollow" target="_blank">的信息。</a></p></blockquote><p id="d702" class="pw-post-body-paragraph ll lm jg ln b lo lp kq lq lr ls kt lt lu lv lw lx ly lz ma mb mc md me mf mg ij bi translated">是的，你没看错，170亿参数。它与PyTorch兼容。这个新的图书馆能够训练更大的变形金刚，但是更有效率！</p><div class="ip iq gp gr ir mq"><a href="https://www.microsoft.com/en-us/research/blog/zero-deepspeed-new-system-optimizations-enable-training-models-with-over-100-billion-parameters/?OCID=msr_blog_zerodeep_tw" rel="noopener  ugc nofollow" target="_blank"><div class="mr ab fo"><div class="ms ab mt cl cj mu"><h2 class="bd jq gy z fp mv fr fs mw fu fw jp bi translated">ZeRO &amp; DeepSpeed:新的系统优化支持超过1000亿个参数的训练模型…</h2><div class="mx l"><h3 class="bd b gy z fp mv fr fs mw fu fw dk translated">人工智能的最新趋势是，更大的自然语言模型提供更好的准确性；但是，较大的型号…</h3></div><div class="my l"><p class="bd b dl z fp mv fr fs mw fu fw dk translated">www.microsoft.com</p></div></div><div class="mz l"><div class="oz l nb nc nd mz ne ix mq"/></div></div></a></div><h1 id="33da" class="nm nn jg bd no np os nr ns nt ot nv nw kv ou kw ny ky ov kz oa lb ow lc oc od bi translated">开域QA反击！</h1><p id="02cf" class="pw-post-body-paragraph ll lm jg ln b lo ol kq lq lr om kt lt lu on lw lx ly oo ma mb mc op me mf mg ij bi translated">在过去的几年里，开放领域的QA几乎停滞不前。自从脸书放弃了DrQA之后，这个领域并没有看到太多的进步，直到几天前，谷歌的一个新模型在自然问题基准上以几分之差达到了SOTA！</p><figure class="ng nh ni nj gt is gh gi paragraph-image"><div role="button" tabindex="0" class="it iu di iv bf iw"><div class="gh gi pa"><img src="../Images/ed67000b2f682309e6716022b28fe7f8.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*UfOJu-Wv5r6G7eDA"/></div></div><figcaption class="iz ja gj gh gi jb jc bd b be z dk translated">解密的</figcaption></figure><div class="ip iq gp gr ir mq"><a href="https://threader.app/thread/1227378652318330885" rel="noopener  ugc nofollow" target="_blank"><div class="mr ab fo"><div class="ms ab mt cl cj mu"><h2 class="bd jq gy z fp mv fr fs mw fu fw jp bi translated">@kelvin_guu写的一个线程</h2><div class="mx l"><h3 class="bd b gy z fp mv fr fs mw fu fw dk translated">来自谷歌研究的新消息！领域:http://realm.page.link/paper我们训练了一个LM，它很少出现在…</h3></div><div class="my l"><p class="bd b dl z fp mv fr fs mw fu fw dk translated">线程应用程序</p></div></div><div class="mz l"><div class="pb l nb nc nd mz ne ix mq"/></div></div></a></div><p id="6710" class="pw-post-body-paragraph ll lm jg ln b lo lp kq lq lr ls kt lt lu lv lw lx ly lz ma mb mc md me mf mg ij bi translated">附注:他们计划开源它:</p><figure class="ng nh ni nj gt is"><div class="bz fp l di"><div class="nk nl l"/></div></figure><p id="5b76" class="pw-post-body-paragraph ll lm jg ln b lo lp kq lq lr ls kt lt lu lv lw lx ly lz ma mb mc md me mf mg ij bi translated"><strong class="ln jq">论文:</strong></p><figure class="ng nh ni nj gt is"><div class="bz fp l di"><div class="oq nl l"/></div><figcaption class="iz ja gj gh gi jb jc bd b be z dk translated"><a class="ae jd" href="https://kentonl.com/pub/gltpc.2020.pdf" rel="noopener ugc nofollow" target="_blank">链接</a></figcaption></figure><h1 id="ed63" class="nm nn jg bd no np os nr ns nt ot nv nw kv ou kw ny ky ov kz oa lb ow lc oc od bi translated">为什么模型会失败</h1><p id="20c1" class="pw-post-body-paragraph ll lm jg ln b lo ol kq lq lr om kt lt lu on lw lx ly oo ma mb mc op me mf mg ij bi translated">哦，天啊，在野外放模型的时候，有时候事情并不像预期的那样。我们都理解当看到SOTA模型由于新兴环境的琐碎属性而表现不佳时所感到的焦虑(现实世界中的事物是适应性的，而不是静态的)。</p><p id="8d08" class="pw-post-body-paragraph ll lm jg ln b lo lp kq lq lr ls kt lt lu lv lw lx ly lz ma mb mc md me mf mg ij bi translated">Hady Elsahar在这篇直观的文章中讨论了畴变问题及其对模型性能的影响:</p><div class="ip iq gp gr ir mq"><a href="https://medium.com/@hadyelsahar/predicting-when-ml-models-fail-in-production-a8a021592f8a" rel="noopener follow" target="_blank"><div class="mr ab fo"><div class="ms ab mt cl cj mu"><h2 class="bd jq gy z fp mv fr fs mw fu fw jp bi translated">预测ML模型何时在生产中失败</h2><div class="mx l"><h3 class="bd b gy z fp mv fr fs mw fu fw dk translated">要不要批注？预测域转移下的性能下降。Hady Elsahar和Matthias的#EMNLP2019论文…</h3></div><div class="my l"><p class="bd b dl z fp mv fr fs mw fu fw dk translated">medium.com</p></div></div><div class="mz l"><div class="pc l nb nc nd mz ne ix mq"/></div></div></a></div><h1 id="2269" class="nm nn jg bd no np os nr ns nt ot nv nw kv ou kw ny ky ov kz oa lb ow lc oc od bi translated">卡格尔，科拉布和伯恩斯先生</h1><p id="f859" class="pw-post-body-paragraph ll lm jg ln b lo ol kq lq lr om kt lt lu on lw lx ly oo ma mb mc op me mf mg ij bi translated">现在在Kaggle上，你可以每周使用30个小时的TPUs，一次最多使用3个小时。</p><div class="ip iq gp gr ir mq"><a href="https://www.kaggle.com/docs/tpu?utm_medium=social&amp;utm_source=twitter&amp;utm_campaign=tpu-announcement-1" rel="noopener  ugc nofollow" target="_blank"><div class="mr ab fo"><div class="ms ab mt cl cj mu"><h2 class="bd jq gy z fp mv fr fs mw fu fw jp bi translated">张量处理单元(TPUs)文档</h2><div class="mx l"><h3 class="bd b gy z fp mv fr fs mw fu fw dk translated">Kaggle是世界上最大的数据科学社区，拥有强大的工具和资源来帮助您实现您的数据…</h3></div><div class="my l"><p class="bd b dl z fp mv fr fs mw fu fw dk translated">www.kaggle.com</p></div></div></div></a></div><p id="dd84" class="pw-post-body-paragraph ll lm jg ln b lo lp kq lq lr ls kt lt lu lv lw lx ly lz ma mb mc md me mf mg ij bi translated"><strong class="ln jq">科拉布:</strong></p><p id="dd95" class="pw-post-body-paragraph ll lm jg ln b lo lp kq lq lr ls kt lt lu lv lw lx ly lz ma mb mc md me mf mg ij bi translated">推出Colab Pro，每月10美元，它提供更好的GPU和更长的运行时间:</p><div class="ip iq gp gr ir mq"><a href="https://9to5google.com/2020/02/08/google-introduces-colab-pro/" rel="noopener  ugc nofollow" target="_blank"><div class="mr ab fo"><div class="ms ab mt cl cj mu"><h2 class="bd jq gy z fp mv fr fs mw fu fw jp bi translated">谷歌推出Colab Pro w/更快的GPU，更多内存-9比5</h2><div class="mx l"><h3 class="bd b gy z fp mv fr fs mw fu fw dk translated">Google Colab是数据科学家和人工智能研究人员在线共享工作的有用工具。该公司本周悄悄…</h3></div><div class="my l"><p class="bd b dl z fp mv fr fs mw fu fw dk translated">9to5google.com</p></div></div><div class="mz l"><div class="pd l nb nc nd mz ne ix mq"/></div></div></a></div><p id="4fa0" class="pw-post-body-paragraph ll lm jg ln b lo lp kq lq lr ls kt lt lu lv lw lx ly lz ma mb mc md me mf mg ij bi translated"><strong class="ln jq">谷歌像:</strong></p><figure class="ng nh ni nj gt is"><div class="bz fp l di"><div class="pe nl l"/></div><figcaption class="iz ja gj gh gi jb jc bd b be z dk translated">伯恩斯先生</figcaption></figure><h1 id="5c66" class="nm nn jg bd no np os nr ns nt ot nv nw kv ou kw ny ky ov kz oa lb ow lc oc od bi translated">本周数据集:WinoGrande</h1><p id="834e" class="pw-post-body-paragraph ll lm jg ln b lo ol kq lq lr om kt lt lu on lw lx ly oo ma mb mc op me mf mg ij bi translated"><strong class="ln jq">什么事？</strong></p><p id="203d" class="pw-post-body-paragraph ll lm jg ln b lo lp kq lq lr ls kt lt lu lv lw lx ly lz ma mb mc md me mf mg ij bi translated">公式化为具有二元选项的填空任务，目标是为需要常识推理的给定句子选择正确的选项。</p><p id="e706" class="pw-post-body-paragraph ll lm jg ln b lo lp kq lq lr ls kt lt lu lv lw lx ly lz ma mb mc md me mf mg ij bi translated"><strong class="ln jq">样本:</strong></p><p id="2f5b" class="pw-post-body-paragraph ll lm jg ln b lo lp kq lq lr ls kt lt lu lv lw lx ly lz ma mb mc md me mf mg ij bi translated">卡特里娜有财力买得起一辆新车，而莫妮卡却没有，因为她有份高薪工作。</p><p id="47f8" class="pw-post-body-paragraph ll lm jg ln b lo lp kq lq lr ls kt lt lu lv lw lx ly lz ma mb mc md me mf mg ij bi translated"><em class="oh">选项1: </em>卡特里娜</p><p id="8d53" class="pw-post-body-paragraph ll lm jg ln b lo lp kq lq lr ls kt lt lu lv lw lx ly lz ma mb mc md me mf mg ij bi translated">选项2: 莫妮卡</p><p id="f4f8" class="pw-post-body-paragraph ll lm jg ln b lo lp kq lq lr ls kt lt lu lv lw lx ly lz ma mb mc md me mf mg ij bi translated"><strong class="ln jq">在哪里？</strong></p><div class="ip iq gp gr ir mq"><a href="https://github.com/allenai/winogrande" rel="noopener  ugc nofollow" target="_blank"><div class="mr ab fo"><div class="ms ab mt cl cj mu"><h2 class="bd jq gy z fp mv fr fs mw fu fw jp bi translated">阿莱奈/威诺兰德</h2><div class="mx l"><h3 class="bd b gy z fp mv fr fs mw fu fw dk translated">1.1版(2019年12月2日)通过download_winogrande.sh下载数据集。/data/ ├──火车_[xs，s，m，l，xl]。jsonl #培训…</h3></div><div class="my l"><p class="bd b dl z fp mv fr fs mw fu fw dk translated">github.com</p></div></div><div class="mz l"><div class="pf l nb nc nd mz ne ix mq"/></div></div></a></div></div><div class="ab cl le lf hu lg" role="separator"><span class="lh bw bk li lj lk"/><span class="lh bw bk li lj lk"/><span class="lh bw bk li lj"/></div><div class="ij ik il im in"><blockquote class="pg"><p id="492c" class="ph pi jg bd pj pk pl pm pn po pp mg dk translated">每周日，我们都会对来自世界各地的研究人员的NLP新闻和代码进行每周综述。</p><p id="99bc" class="ph pi jg bd pj pk pl pm pn po pp mg dk translated">如果您喜欢这篇文章，请帮助我们，并与朋友或社交媒体分享！</p><p id="694f" class="ph pi jg bd pj pk pl pm pn po pp mg dk translated"><em class="pq">完整报道，关注我们的推特:</em><a class="ae jd" href="https://twitter.com/Quantum_Stat" rel="noopener ugc nofollow" target="_blank"><em class="pq">@ Quantum _ Stat</em></a></p></blockquote><figure class="ps pt pu pv pw is gh gi paragraph-image"><div class="gh gi pr"><img src="../Images/1dfe94e2d92c5185e234e6bf5291ceb3.png" data-original-src="https://miro.medium.com/v2/resize:fit:108/0*jjRh2H4WhimASf-3"/></div><figcaption class="iz ja gj gh gi jb jc bd b be z dk translated"><a class="ae jd" href="http://www.quantumstat.com/" rel="noopener ugc nofollow" target="_blank">www.quantumstat.com</a></figcaption></figure></div></div>    
</body>
</html>