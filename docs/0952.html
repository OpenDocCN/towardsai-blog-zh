<html>
<head>
<title>Word Mover’s Distance (WMD) Explained: An Effective Method of Document Classification</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">词移动距离解释:一种有效的文档分类方法</h1>
<blockquote>原文：<a href="https://pub.towardsai.net/word-movers-distance-wmd-explained-an-effective-method-of-document-classification-89cb258401f4?source=collection_archive---------0-----------------------#2020-09-21">https://pub.towardsai.net/word-movers-distance-wmd-explained-an-effective-method-of-document-classification-89cb258401f4?source=collection_archive---------0-----------------------#2020-09-21</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><figure class="ip iq gp gr ir is gh gi paragraph-image"><div role="button" tabindex="0" class="it iu di iv bf iw"><div class="gh gi io"><img src="../Images/55bd27fa676988d7f35c4000908c940e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*i_UBTgmduE85X7yj8bPTDQ.png"/></div></div><figcaption class="iz ja gj gh gi jb jc bd b be z dk translated">来源:*图片来自<a class="ae jd" href="http://proceedings.mlr.press/v37/kusnerb15.pdf" rel="noopener ugc nofollow" target="_blank">原文</a></figcaption></figure><h2 id="d8d3" class="je jf jg bd b dl jh ji jj jk jl jm dk jn translated" aria-label="kicker paragraph"><a class="ae ep" href="https://towardsai.net/p/category/nlp" rel="noopener ugc nofollow" target="_blank">自然语言处理</a></h2><div class=""/><div class=""><h2 id="b0c3" class="pw-subtitle-paragraph km jp jg bd b kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld dk translated">[阅读]从单词嵌入到文档距离</h2></div><p id="9c64" class="pw-post-body-paragraph le lf jg lg b lh li kq lj lk ll kt lm ln lo lp lq lr ls lt lu lv lw lx ly lz ij bi translated">文档分类和文档检索已经显示出广泛的应用。文档分类的一个基本部分是正确地生成文档表示。<a class="ae jd" href="http://mkusner.github.io/" rel="noopener ugc nofollow" target="_blank"> Matt J. Kusner </a>等人在2015年提出了单词移动器距离(WMD) [1]，其中单词嵌入被纳入计算两个文档之间的距离。利用给定的预先训练的单词嵌入，通过计算“一个文档的嵌入单词需要‘行进’以到达另一个文档的嵌入单词的最小距离量”，可以用语义来测量文档之间的不同。</p><p id="2418" class="pw-post-body-paragraph le lf jg lg b lh li kq lj lk ll kt lm ln lo lp lq lr ls lt lu lv lw lx ly lz ij bi translated">在接下来的章节中，我们将讨论WMD的原理，约束和近似，WMD的预取和修剪，WMD的性能。</p><h1 id="2bf2" class="ma mb jg bd mc md me mf mg mh mi mj mk kv ml kw mm ky mn kz mo lb mp lc mq mr bi translated">大规模杀伤性武器原理</h1><p id="2d9e" class="pw-post-body-paragraph le lf jg lg b lh ms kq lj lk mt kt lm ln mu lp lq lr mv lt lu lv mw lx ly lz ij bi translated">如前所述，WMD试图测量两个文档的语义距离，语义测量是由word2vec嵌入带来的。具体来说，在他们的实验中使用了跳格词2vec。一旦获得单词嵌入，文档之间的语义距离由以下三部分定义:文档表示、相似性度量和(稀疏)流矩阵。</p><h2 id="f531" class="mx mb jg bd mc my mz dn mg na nb dp mk ln nc nd mm lr ne nf mo lv ng nh mq jm bi translated">文本文档表示</h2><p id="1460" class="pw-post-body-paragraph le lf jg lg b lh ms kq lj lk mt kt lm ln mu lp lq lr mv lt lu lv mw lx ly lz ij bi translated">文本文档被表示为向量<strong class="lg jq"> d </strong>，其中每个元素表示一个单词在文档中的归一化频率，即</p><figure class="nj nk nl nm gt is gh gi paragraph-image"><div class="gh gi ni"><img src="../Images/31c1ea9a50f294606dd08402258a197d.png" data-original-src="https://miro.medium.com/v2/resize:fit:828/1*Z82P-YfuEXBJ3IFacUOUug.gif"/></div></figure><p id="415f" class="pw-post-body-paragraph le lf jg lg b lh li kq lj lk ll kt lm ln lo lp lq lr ls lt lu lv lw lx ly lz ij bi translated">注意，文档表示<strong class="lg jq"> d </strong>是高维空间中的稀疏向量。</p><h2 id="c1dc" class="mx mb jg bd mc my mz dn mg na nb dp mk ln nc nd mm lr ne nf mo lv ng nh mq jm bi translated">语义相似性度量定义</h2><p id="2aa0" class="pw-post-body-paragraph le lf jg lg b lh ms kq lj lk mt kt lm ln mu lp lq lr mv lt lu lv mw lx ly lz ij bi translated">两个给定单词<strong class="lg jq">x _</strong>T14】I和<strong class="lg jq">x _</strong>T18】j在嵌入空间中的欧几里德距离定义如下:</p><figure class="nj nk nl nm gt is gh gi paragraph-image"><div class="gh gi no"><img src="../Images/940a9067798f309e3010c3382f8d9a99.png" data-original-src="https://miro.medium.com/v2/resize:fit:336/1*cpNrpU_2H83_3VEYR_vABA.gif"/></div></figure><p id="3ab2" class="pw-post-body-paragraph le lf jg lg b lh li kq lj lk ll kt lm ln lo lp lq lr ls lt lu lv lw lx ly lz ij bi translated">WMD中，<strong class="lg jq"> x_ </strong> <em class="nn"> i </em>和<strong class="lg jq"> x_ </strong> <em class="nn"> j </em>来自不同的单据，<em class="nn"> c(i，j) </em>是word <strong class="lg jq"> x_ </strong> <em class="nn"> i </em>到<strong class="lg jq"> x_ </strong> <em class="nn"> j. </em>的“差旅费”</p><h2 id="089a" class="mx mb jg bd mc my mz dn mg na nb dp mk ln nc nd mm lr ne nf mo lv ng nh mq jm bi translated">流动矩阵定义</h2><p id="2c7e" class="pw-post-body-paragraph le lf jg lg b lh ms kq lj lk mt kt lm ln mu lp lq lr mv lt lu lv mw lx ly lz ij bi translated">假设有一个源文档A和一个目标文档b，定义一个流矩阵<strong class="lg jq"> T </strong>。流矩阵中的每个元素，<strong class="lg jq"> T </strong> _{ <em class="nn"> ij} </em>，表示单词<em class="nn"> i </em>(在文档A中)转换为单词<em class="nn"> j </em>(在文档B中)的次数，然后用词汇表中的总字数对值进行归一化。也就是说，</p><figure class="nj nk nl nm gt is gh gi paragraph-image"><div class="gh gi np"><img src="../Images/7b531a1c185f850226a9a93f3b7d893d.png" data-original-src="https://miro.medium.com/v2/resize:fit:186/1*qOK_3gYSh2T2vidFb2duYg.gif"/></div></figure><p id="df70" class="pw-post-body-paragraph le lf jg lg b lh li kq lj lk ll kt lm ln lo lp lq lr ls lt lu lv lw lx ly lz ij bi translated">因此，语义距离定义如下:</p><figure class="nj nk nl nm gt is gh gi paragraph-image"><div class="gh gi nq"><img src="../Images/374aafda6cfb17fe10d92c4f74a86f21.png" data-original-src="https://miro.medium.com/v2/resize:fit:450/1*YKcE8os5BZiT34lg7g9tyg.gif"/></div></figure><p id="68bd" class="pw-post-body-paragraph le lf jg lg b lh li kq lj lk ll kt lm ln lo lp lq lr ls lt lu lv lw lx ly lz ij bi translated">通过调整<strong class="lg jq"> T </strong>中的值，可以得到两个文档之间的语义距离。距离也是将所有单词从一个文档移动到另一个文档所需的最小累积成本。</p><h2 id="3f59" class="mx mb jg bd mc my mz dn mg na nb dp mk ln nc nd mm lr ne nf mo lv ng nh mq jm bi translated">约束和下限近似</h2><p id="6e45" class="pw-post-body-paragraph le lf jg lg b lh ms kq lj lk mt kt lm ln mu lp lq lr mv lt lu lv mw lx ly lz ij bi translated">最小累积成本有两个限制，即</p><figure class="nj nk nl nm gt is gh gi paragraph-image"><div class="gh gi np"><img src="../Images/7b531a1c185f850226a9a93f3b7d893d.png" data-original-src="https://miro.medium.com/v2/resize:fit:186/1*qOK_3gYSh2T2vidFb2duYg.gif"/></div><figcaption class="iz ja gj gh gi jb jc bd b be z dk translated">对于文档A中的任何单词I，文档B中的任何单词j</figcaption></figure><p id="5ca5" class="pw-post-body-paragraph le lf jg lg b lh li kq lj lk ll kt lm ln lo lp lq lr ls lt lu lv lw lx ly lz ij bi translated">总的来说，约束最小累积成本的计算复杂度是<em class="nn"> O(p logp)，</em>其中<em class="nn"> p </em>是文档中唯一单词的数量。也就是说，WMD可能不适用于大型文档，或者具有大量独特单词的文档。本文提出了两种加速WMD计算的方法。两种加速方法都导致实际WMD值的近似值。</p><p id="1727" class="pw-post-body-paragraph le lf jg lg b lh li kq lj lk ll kt lm ln lo lp lq lr ls lt lu lv lw lx ly lz ij bi translated"><strong class="lg jq">字质心距离(WCD) </strong></p><p id="b74a" class="pw-post-body-paragraph le lf jg lg b lh li kq lj lk ll kt lm ln lo lp lq lr ls lt lu lv lw lx ly lz ij bi translated">通过使用三角形不等式，可以证明累积成本总是大于或等于由单词嵌入的平均值加权的文档向量之间的欧几里德距离。这样计算复杂度降到了<em class="nn"> O(dp) </em>(此处<em class="nn">，d </em>表示文档向量的维数<strong class="lg jq"> d </strong>。)</p><p id="cbe1" class="pw-post-body-paragraph le lf jg lg b lh li kq lj lk ll kt lm ln lo lp lq lr ls lt lu lv lw lx ly lz ij bi translated"><strong class="lg jq">放宽大规模杀伤性武器(RWMD) </strong></p><p id="1331" class="pw-post-body-paragraph le lf jg lg b lh li kq lj lk ll kt lm ln lo lp lq lr ls lt lu lv lw lx ly lz ij bi translated">目标中有两个约束。如果去除一个约束，累积成本的最佳解决方案是对于一个文档中的每个单词，将其所有概率质量移动到另一个文档中最相似的单词。这意味着成本最小化问题转化为寻找嵌入空间中两个字嵌入的最小欧几里德距离。所以去掉一个约束，保留另一个，就有了两个近似的下界:姑且称之为<em class="nn"> l1 </em>(保留对<em class="nn"> i </em>的约束)和<em class="nn"> l2 </em>(保留对<em class="nn"> j </em>的约束)。更接近的近似值<em class="nn"> l </em>可以定义为:</p><p id="02ca" class="pw-post-body-paragraph le lf jg lg b lh li kq lj lk ll kt lm ln lo lp lq lr ls lt lu lv lw lx ly lz ij bi translated"><em class="nn"> l=max(l1，l2)。</em></p><p id="a37c" class="pw-post-body-paragraph le lf jg lg b lh li kq lj lk ll kt lm ln lo lp lq lr ls lt lu lv lw lx ly lz ij bi translated">有了这个近似的累积成本，作者称之为宽松的WMD (RWMD)，计算复杂度降低到O(p)。</p><h1 id="94e7" class="ma mb jg bd mc md me mf mg mh mi mj mk kv ml kw mm ky mn kz mo lb mp lc mq mr bi translated">预取和修剪</h1><p id="899b" class="pw-post-body-paragraph le lf jg lg b lh ms kq lj lk mt kt lm ln mu lp lq lr mv lt lu lv mw lx ly lz ij bi translated">为了高效地找到查询文档的k个最近邻，可以利用WCD和RWMD来降低计算成本。</p><ol class=""><li id="a950" class="nr ns jg lg b lh li lk ll ln nt lr nu lv nv lz nw nx ny nz bi translated">使用WCD估计每个文档到查询文档之间的距离。</li><li id="d1e3" class="nr ns jg lg b lh oa lk ob ln oc lr od lv oe lz nw nx ny nz bi translated">按升序对估计的距离进行排序，然后使用WMD计算到这些文档的第一个<em class="nn"> k </em>的精确距离。</li><li id="8ed2" class="nr ns jg lg b lh oa lk ob ln oc lr od lv oe lz nw nx ny nz bi translated">遍历剩余的文档(不在上一步的第一个<em class="nn"> k </em>中)，计算RWMD下界。</li><li id="0489" class="nr ns jg lg b lh oa lk ob ln oc lr od lv oe lz nw nx ny nz bi translated">如果一个文档(到查询文档)的RWMD近似大于到第一个<em class="nn"> k个</em>文档的所有计算的WMD距离(在步骤2中)，这意味着该文档一定不在查询文档的k个最近邻中，因此它可以被剪除。否则，精确的WMD距离被计算并更新到<em class="nn"> k </em>最近的邻居。</li></ol><h1 id="fbd5" class="ma mb jg bd mc md me mf mg mh mi mj mk kv ml kw mm ky mn kz mo lb mp lc mq mr bi translated">大规模杀伤性武器的性能</h1><p id="8f2a" class="pw-post-body-paragraph le lf jg lg b lh ms kq lj lk mt kt lm ln mu lp lq lr mv lt lu lv mw lx ly lz ij bi translated">作者在八个文档数据集上评估了在<em class="nn"> k </em> NN背景下的WMD性能，并与BOW、TFIDF、BM25 LSI、LDA、mSDA、CCG进行了性能比较。他们的实验表明，WMD在8个数据集的6个上表现最好。对于其余2个数据集，即使WMD不是性能最好的，错误率也非常接近性能最好的。</p><p id="05fe" class="pw-post-body-paragraph le lf jg lg b lh li kq lj lk ll kt lm ln lo lp lq lr ls lt lu lv lw lx ly lz ij bi translated">一个有趣的实验结果是，作者进行了一个实验来评估如果下界用于最近邻检索，下界的紧密性和kNN错误率之间的关系。这表明紧密性并不直接转化为检索的准确性。在作者的陈述中，一次只接受一个约束的RWMDs(命名为RWMD_c1和RWMD_c2)的紧密性明显高于WCD，然而RWMD_c1和RWMD_c2在<em class="nn"> k </em> NN精度方面的表现都不如WCD。我的新观点是，这可能是由于RWMD_c1和RWMD_c2的不对称约束造成的。因为只有剩余的一个约束导出到距离度量的非严格定义，并且RWMD_c1和RWMD_c2都不是严格的距离近似。</p><h1 id="12e1" class="ma mb jg bd mc md me mf mg mh mi mj mk kv ml kw mm ky mn kz mo lb mp lc mq mr bi translated">工作的潜在扩展</h1><p id="022d" class="pw-post-body-paragraph le lf jg lg b lh ms kq lj lk mt kt lm ln mu lp lq lr mv lt lu lv mw lx ly lz ij bi translated">WMD的性能在文档分类任务中大放异彩。在我看来，对于大规模杀伤性武器的进一步探索，有几件事可以尝试。</p><p id="513d" class="pw-post-body-paragraph le lf jg lg b lh li kq lj lk ll kt lm ln lo lp lq lr ls lt lu lv lw lx ly lz ij bi translated">作者利用不同的数据集进行单词嵌入生成，但是嵌入方法坚持使用<em class="nn"> word2vec </em>和<em class="nn"> skip-gram </em>。通过将word2vet改为其他方法(如GloVe ),可以看到嵌入方法对WMD的意义，这将是很有趣的。</p><p id="6c00" class="pw-post-body-paragraph le lf jg lg b lh li kq lj lk ll kt lm ln lo lp lq lr ls lt lu lv lw lx ly lz ij bi translated">请注意，WMD不能处理词汇外(OOV)数据，当在距离计算中遇到OOV单词时，它会直接将其丢弃。这可能是WMD的性能在所有数据集上不如其他方法的原因。OOV词的嵌入可以基于上下文信息来构建。例如，BiLSTM语言模型可以帮助生成OOV单词嵌入[2]。此外，字节对编码(BPE)也可以构建OOV字嵌入。</p><h1 id="cda0" class="ma mb jg bd mc md me mf mg mh mi mj mk kv ml kw mm ky mn kz mo lb mp lc mq mr bi translated">参考</h1><p id="acf7" class="pw-post-body-paragraph le lf jg lg b lh ms kq lj lk mt kt lm ln mu lp lq lr mv lt lu lv mw lx ly lz ij bi translated">[1]原文:<a class="ae jd" href="http://proceedings.mlr.press/v37/kusnerb15.pdf" rel="noopener ugc nofollow" target="_blank">从单词嵌入到文档距离</a></p><p id="1775" class="pw-post-body-paragraph le lf jg lg b lh li kq lj lk ll kt lm ln lo lp lq lr ls lt lu lv lw lx ly lz ij bi translated">[2]<a class="ae jd" href="https://www.researchgate.net/publication/335757797_Language_Modelling_for_Handling_Out-of-Vocabulary_Words_in_Natural_Language_Processing?showFulltext=1&amp;linkId=5d7a26a04585151ee4afb0c5" rel="noopener ugc nofollow" target="_blank">https://www . researchgate . net/publication/335757797 _ Language _ modeling _ for _ Handling _ Out-of-Vocabulary _ Words _ in _ Natural _ Language _ Processing？show full text = 1&amp;linkId = 5d 7a 26 a 04585151 E4 AFB 0 c 5</a></p><p id="53bf" class="pw-post-body-paragraph le lf jg lg b lh li kq lj lk ll kt lm ln lo lp lq lr ls lt lu lv lw lx ly lz ij bi translated">[3]大规模杀伤性武器<a class="ae jd" href="https://github.com/mkusner/wmd" rel="noopener ugc nofollow" target="_blank">代号</a></p></div></div>    
</body>
</html>