<html>
<head>
<title>Fake News Detection with Model Selection and Hyperparameter Optimization in Python (&gt;97% acc.)</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">Python中模型选择和超参数优化的假新闻检测(&gt; 97% acc。)</h1>
<blockquote>原文：<a href="https://pub.towardsai.net/fake-news-detection-with-model-selection-and-hyperparameter-optimization-in-python-d738f3d35d3b?source=collection_archive---------0-----------------------#2022-08-24">https://pub.towardsai.net/fake-news-detection-with-model-selection-and-hyperparameter-optimization-in-python-d738f3d35d3b?source=collection_archive---------0-----------------------#2022-08-24</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="ebd1" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">模型选择和超参数优化的假新闻检测实用指南</h2></div><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ki"><img src="../Images/e110ed0b451d29d509de7cccd29420d1.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*_Mk-D8hGwDn5wriy"/></div></div><figcaption class="ku kv gj gh gi kw kx bd b be z dk translated">照片由<a class="ae ky" href="https://unsplash.com/@pixel_talkies?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Nijwam Swargiary </a>在<a class="ae ky" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上拍摄</figcaption></figure><h1 id="10ca" class="kz la it bd lb lc ld le lf lg lh li lj jz lk ka ll kc lm kd ln kf lo kg lp lq bi translated">介绍</h1><p id="895f" class="pw-post-body-paragraph lr ls it lt b lu lv ju lw lx ly jx lz ma mb mc md me mf mg mh mi mj mk ml mm im bi mn translated">本文旨在描述用于假新闻检测的模型选择和超参数调整过程。</p><p id="a744" class="pw-post-body-paragraph lr ls it lt b lu mw ju lw lx mx jx lz ma my mc md me mz mg mh mi na mk ml mm im bi translated">我的<a class="ae ky" href="https://towardsdatascience.com/model-selection-and-hyperparameter-tuning-on-amazon-kindle-book-reviews-with-python-6d17ec46d318" rel="noopener" target="_blank">上一篇文章</a>，在其中我解释了<strong class="lt iu">模型选择</strong>是如何在一个<strong class="lt iu">亚马逊Kindle评论</strong>数据集上的机器学习领域内执行的，在读者中获得了成功。该项目提出了一个限制，尽管考虑到包含大约1，000，000条评论的数据集的大小，我们无法在很大一部分看不见的数据上部署该算法。由于计算的限制，这是在50，000条记录上完成的，大约5%。</p><p id="39a8" class="pw-post-body-paragraph lr ls it lt b lu mw ju lw lx mx jx lz ma my mc md me mz mg mh mi na mk ml mm im bi translated">在本文中，我们的目标是识别和调整性能最好的模型。这次将对所有记录进行训练和测试，产生的模型将部署在不同的数据集上，以测试其准确性和泛化能力。</p><h2 id="524a" class="nb la it bd lb nc nd dn lf ne nf dp lj ma ng nh ll me ni nj ln mi nk nl lp nm bi translated">数据</h2><p id="47e9" class="pw-post-body-paragraph lr ls it lt b lu lv ju lw lx ly jx lz ma mb mc md me mf mg mh mi mj mk ml mm im bi translated">训练数据集有两个:一个只包含真实的新闻(<code class="fe nn no np nq b">True.csv</code>)，另一个不包含真实的新闻(<code class="fe nn no np nq b">Fake.csv</code> ) [1]。你可以在下面的<a class="ae ky" href="https://www.kaggle.com/datasets/clmentbisaillon/fake-and-real-news-dataset" rel="noopener ugc nofollow" target="_blank">链接</a>找到这两个。这两个CSV的结构相同:</p><ul class=""><li id="099d" class="nr ns it lt b lu mw lx mx ma nt me nu mi nv mm nw nx ny nz bi translated"><code class="fe nn no np nq b">title</code> —新闻标题</li><li id="c92b" class="nr ns it lt b lu oa lx ob ma oc me od mi oe mm nw nx ny nz bi translated"><code class="fe nn no np nq b">text</code> —新闻语料库</li><li id="72f2" class="nr ns it lt b lu oa lx ob ma oc me od mi oe mm nw nx ny nz bi translated"><code class="fe nn no np nq b">subject</code> —描述新闻标题的内容(新闻、政治……)</li><li id="fc7a" class="nr ns it lt b lu oa lx ob ma oc me od mi oe mm nw nx ny nz bi translated"><code class="fe nn no np nq b">date</code> —新闻标题发布的日期</li></ul><p id="a59c" class="pw-post-body-paragraph lr ls it lt b lu mw ju lw lx mx jx lz ma my mc md me mz mg mh mi na mk ml mm im bi translated"><code class="fe nn no np nq b">True.csv</code>包含大约21000条记录，而<code class="fe nn no np nq b">Fake.csv</code>显示其中的18000条。</p><p id="6570" class="pw-post-body-paragraph lr ls it lt b lu mw ju lw lx mx jx lz ma my mc md me mz mg mh mi na mk ml mm im bi translated">另一个仅用于测试目的的数据集将用于在看不见的数据上部署模型[4]。记录是根据Chrome扩展的分类从244个网站搜集来的，该扩展名为<a class="ae ky" href="https://github.com/selfagency/bs-detector" rel="noopener ugc nofollow" target="_blank"> BS Detector </a>。你可以在下面的<a class="ae ky" href="https://www.kaggle.com/datasets/mrisdal/fake-news" rel="noopener ugc nofollow" target="_blank">链接</a>找到数据集。最大的区别是，这一个只包含假评论。它总共有21个栏目，其中最相关的是:</p><ul class=""><li id="05f6" class="nr ns it lt b lu mw lx mx ma nt me nu mi nv mm nw nx ny nz bi translated"><code class="fe nn no np nq b">uuid</code> —新闻的唯一标识符字母数字串</li><li id="2411" class="nr ns it lt b lu oa lx ob ma oc me od mi oe mm nw nx ny nz bi translated"><code class="fe nn no np nq b">ord_in_thread</code> —同一篇文章被刮了多少次</li><li id="b905" class="nr ns it lt b lu oa lx ob ma oc me od mi oe mm nw nx ny nz bi translated"><code class="fe nn no np nq b">author</code>——新闻的作者</li><li id="f78f" class="nr ns it lt b lu oa lx ob ma oc me od mi oe mm nw nx ny nz bi translated"><code class="fe nn no np nq b">published</code>—发布日期和时间</li><li id="6139" class="nr ns it lt b lu oa lx ob ma oc me od mi oe mm nw nx ny nz bi translated"><code class="fe nn no np nq b">title</code>—新闻标题</li><li id="dc51" class="nr ns it lt b lu oa lx ob ma oc me od mi oe mm nw nx ny nz bi translated"><code class="fe nn no np nq b">text</code>—新闻语料库</li><li id="0bdc" class="nr ns it lt b lu oa lx ob ma oc me od mi oe mm nw nx ny nz bi translated"><code class="fe nn no np nq b">language</code> —新闻语言</li><li id="bcb3" class="nr ns it lt b lu oa lx ob ma oc me od mi oe mm nw nx ny nz bi translated"><code class="fe nn no np nq b">crawled</code> —从网站上抓取的日期和时间</li><li id="3100" class="nr ns it lt b lu oa lx ob ma oc me od mi oe mm nw nx ny nz bi translated"><code class="fe nn no np nq b">site_url</code> —网站的帖子网址链接</li><li id="6505" class="nr ns it lt b lu oa lx ob ma oc me od mi oe mm nw nx ny nz bi translated"><code class="fe nn no np nq b">country</code> —新闻发布的地方</li></ul><p id="9c85" class="pw-post-body-paragraph lr ls it lt b lu mw ju lw lx mx jx lz ma my mc md me mz mg mh mi na mk ml mm im bi translated">对于分类问题，对于三个数据集，我们只需要<code class="fe nn no np nq b">text</code>和新闻真实与否的信息。</p><p id="4ae5" class="pw-post-body-paragraph lr ls it lt b lu mw ju lw lx mx jx lz ma my mc md me mz mg mh mi na mk ml mm im bi translated">下面是两个数据集的文本列中的两个示例:</p><pre class="kj kk kl km gt of nq og oh aw oi bi"><span id="fcb8" class="nb la it nq b gy oj ok l ol om">The head of a conservative Republican faction in the U.S. Congress, who voted this month for a huge expansion of the national debt to pay for tax cuts, called himself a “fiscal conservative” on Sunday and urged budget restraint in 2018. In keeping with a sharp pivot under way among Republicans, U.S. Representative Mark Meadows, speaking on CBS’ “Face the Nation,” drew a hard line on federal spending, which lawmakers are bracing to do battle over in January... </span></pre><p id="2f20" class="pw-post-body-paragraph lr ls it lt b lu mw ju lw lx mx jx lz ma my mc md me mz mg mh mi na mk ml mm im bi translated">第一个语料库提供了真实的新闻，你可以从它专注于讲述事实的客观语气中看出。</p><pre class="kj kk kl km gt of nq og oh aw oi bi"><span id="63b3" class="nb la it nq b gy oj ok l ol om">They should pay all the back all the money plus interest. The entire family and everyone who came in with them need to be deported asap. Why did it take two years to bust them? \nHere we go again …another group stealing from the government and taxpayers! A group of Somalis stole over four million in government benefits over just 10 months! \nWe’ve reported on numerous cases like this one where the Muslim refugees/immigrants commit fraud by scamming our system…It’s way out of control!</span></pre><p id="536e" class="pw-post-body-paragraph lr ls it lt b lu mw ju lw lx mx jx lz ma my mc md me mz mg mh mi na mk ml mm im bi translated">第二个显示一条假新闻。报道的信息表达了不合理的仇恨，它不仅限于描述事实。这篇文章希望提高公众的意识，并针对特定人群进行负面报道。当然，这样的信息可能是极其危险的，尤其是如果不真实的话。</p><p id="4022" class="pw-post-body-paragraph lr ls it lt b lu mw ju lw lx mx jx lz ma my mc md me mz mg mh mi na mk ml mm im bi translated">第二个样本表明需要特别注意清洁部分。除了停用字词之外，还需要过滤掉HTML文本标签(例如“\n”、“/”)以及特殊字符(例如“…”、“！”).</p><h2 id="07ac" class="nb la it bd lb nc nd dn lf ne nf dp lj ma ng nh ll me ni nj ln mi nk nl lp nm bi translated">模型</h2><p id="4b6c" class="pw-post-body-paragraph lr ls it lt b lu lv ju lw lx ly jx lz ma mb mc md me mf mg mh mi mj mk ml mm im bi translated">对于这个项目，我考虑了7种常见的分类模型，包括参数和非参数模型。他们都是被监督的学习模型:</p><ul class=""><li id="17ae" class="nr ns it lt b lu mw lx mx ma nt me nu mi nv mm nw nx ny nz bi translated">线性判别分析(LDA)</li><li id="227e" class="nr ns it lt b lu oa lx ob ma oc me od mi oe mm nw nx ny nz bi translated">k近邻</li><li id="2ca8" class="nr ns it lt b lu oa lx ob ma oc me od mi oe mm nw nx ny nz bi translated">高斯朴素贝叶斯</li><li id="9d39" class="nr ns it lt b lu oa lx ob ma oc me od mi oe mm nw nx ny nz bi translated">逻辑回归</li><li id="40f4" class="nr ns it lt b lu oa lx ob ma oc me od mi oe mm nw nx ny nz bi translated">决策树分类器</li><li id="e47d" class="nr ns it lt b lu oa lx ob ma oc me od mi oe mm nw nx ny nz bi translated">支持向量机(SVM)</li></ul><p id="1164" class="pw-post-body-paragraph lr ls it lt b lu mw ju lw lx mx jx lz ma my mc md me mz mg mh mi na mk ml mm im bi translated">对于每一个背后的基本原理的更深入的解释，我建议你阅读我的<a class="ae ky" href="https://towardsdatascience.com/model-selection-and-hyperparameter-tuning-on-amazon-kindle-book-reviews-with-python-6d17ec46d318" rel="noopener" target="_blank">上一篇文章</a>。</p><blockquote class="on"><p id="f483" class="oo op it bd oq or os ot ou ov ow mm dk translated">第一个目标是确定最适合假新闻分类问题的模型。</p></blockquote><p id="e943" class="pw-post-body-paragraph lr ls it lt b lu ox ju lw lx oy jx lz ma oz mc md me pa mg mh mi pb mk ml mm im bi translated">我们实现它的方法是通过ML管道对每个模型进行交叉验证。在精确度和效率方面最好的两个模型将在由于超参数调整而优化之后被进一步评估。</p><h1 id="624d" class="kz la it bd lb lc ld le lf lg lh li lj jz lk ka ll kc lm kd ln kf lo kg lp lq bi translated">代码部署</h1><h2 id="b75e" class="nb la it bd lb nc nd dn lf ne nf dp lj ma ng nh ll me ni nj ln mi nk nl lp nm bi translated"><strong class="ak">预处理</strong></h2><p id="1358" class="pw-post-body-paragraph lr ls it lt b lu lv ju lw lx ly jx lz ma mb mc md me mf mg mh mi mj mk ml mm im bi translated">如前所述，第一个<a class="ae ky" href="https://www.kaggle.com/datasets/clmentbisaillon/fake-and-real-news-dataset" rel="noopener ugc nofollow" target="_blank">链接</a>包含两个数据集，一个只有<strong class="lt iu">真实新闻</strong>，另一个只有<strong class="lt iu">虚假新闻</strong>。如果我们想要执行训练和测试，我们现在需要把它们放在一起。</p><ul class=""><li id="d07a" class="nr ns it lt b lu mw lx mx ma nt me nu mi nv mm nw nx ny nz bi translated">让我们从导入<code class="fe nn no np nq b">pandas</code>开始</li><li id="ba73" class="nr ns it lt b lu oa lx ob ma oc me od mi oe mm nw nx ny nz bi translated">我们将这两个CSV转换成<strong class="lt iu">熊猫数据帧</strong>并命名为它们</li><li id="f3b9" class="nr ns it lt b lu oa lx ob ma oc me od mi oe mm nw nx ny nz bi translated">需要添加一个分类栏来识别某个记录是不是假新闻。使用命令<code class="fe nn no np nq b">fake['classification'] = 1</code>我们创建了一个名为<strong class="lt iu">分类的<strong class="lt iu">新列</strong>，</strong>，它的所有行都被设置为1。我们的分类器将识别假新闻，并给它们赋值1。</li><li id="fed4" class="nr ns it lt b lu oa lx ob ma oc me od mi oe mm nw nx ny nz bi translated">然后将两个数据帧<strong class="lt iu">连接起来</strong>，并且通过将参数<code class="fe nn no np nq b">ignore_index</code>设置为等于<code class="fe nn no np nq b">True</code>来重置它们的索引计数</li></ul><pre class="kj kk kl km gt of nq og oh aw oi bi"><span id="cddd" class="nb la it nq b gy oj ok l ol om">#Importing library<br/>import pandas as pd</span><span id="0129" class="nb la it nq b gy pc ok l ol om">#assigning dataframe names to csv files<br/>true = pd.read_csv("True.csv")<br/>fake = pd.read_csv("Fake.csv")</span><span id="45a2" class="nb la it nq b gy pc ok l ol om">#Adding classification column<br/>fake['classification'] = 1<br/>true['classification'] = 0</span><span id="bdae" class="nb la it nq b gy pc ok l ol om">#concatenate two dataframes together<br/>true_fake = pd.concat([true,fake], ignore_index=True)</span></pre><h2 id="2fd1" class="nb la it bd lb nc nd dn lf ne nf dp lj ma ng nh ll me ni nj ln mi nk nl lp nm bi translated">数据探索</h2><p id="d805" class="pw-post-body-paragraph lr ls it lt b lu lv ju lw lx ly jx lz ma mb mc md me mf mg mh mi mj mk ml mm im bi translated"><strong class="lt iu">数据探索</strong>专注于可视化数据，以引导更深入的分析，发现早期见解并识别模式。我们可以通过简单地绘制每个类别的新闻数量来开始这个过程:</p><ul class=""><li id="2d46" class="nr ns it lt b lu mw lx mx ma nt me nu mi nv mm nw nx ny nz bi translated">我们进口<code class="fe nn no np nq b">matplotlib</code></li><li id="c8ed" class="nr ns it lt b lu oa lx ob ma oc me od mi oe mm nw nx ny nz bi translated">创建了一个名为<code class="fe nn no np nq b">category_dist</code>的新变量，它计算数字1和0在分类列中出现的次数</li><li id="a8ea" class="nr ns it lt b lu oa lx ob ma oc me od mi oe mm nw nx ny nz bi translated">通过<code class="fe nn no np nq b">plt</code>和一系列命令，我们可以选择大小、图表类型、颜色、标签、标题以及是否需要网格线。</li></ul><pre class="kj kk kl km gt of nq og oh aw oi bi"><span id="a59d" class="nb la it nq b gy oj ok l ol om">#Importing library<br/>import matplotlib.pyplot as plt</span><span id="37a8" class="nb la it nq b gy pc ok l ol om">#Counting values within each classification bucket<br/>category_dist = true_fake['classification'].value_counts()</span><span id="2e8c" class="nb la it nq b gy pc ok l ol om">#Defining chart<br/>plt.figure(figsize=(8,6))<br/>category_dist.plot(kind='bar', color = '#89b4a1')<br/>plt.xlabel("Classification", fontsize = 12)<br/>plt.ylabel("Number of News Headlines by Classification", fontsize = 12)<br/>plt.title("Distribution of News Headlines by Classification", fontsize = 15)<br/>plt.grid(False)</span><span id="3acc" class="nb la it nq b gy pc ok l ol om">#Generating chart<br/>plt.show()</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi pd"><img src="../Images/872ed247af9b43f9b9525dd1a80b0fd5.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*7vUPbpaiwIGAf4JtO6dmsA.png"/></div></div><figcaption class="ku kv gj gh gi kw kx bd b be z dk translated">按分类的新闻分布—按作者的图表</figcaption></figure><p id="3104" class="pw-post-body-paragraph lr ls it lt b lu mw ju lw lx mx jx lz ma my mc md me mz mg mh mi na mk ml mm im bi translated">数据帧由大约<strong class="lt iu"> 40.000 </strong>条记录组成，假新闻略多。鉴于这种差异不是很大，我们不需要实现任何不平衡的数据处理技术，如上采样。</p><p id="811a" class="pw-post-body-paragraph lr ls it lt b lu mw ju lw lx mx jx lz ma my mc md me mz mg mh mi na mk ml mm im bi translated">向型号选择管道输入超过40，000条记录，每条记录包含750个字或更多，可能导致<strong class="lt iu"> RAM内存过载</strong>。这个问题的一个简单解决方案是<strong class="lt iu">选择一小部分</strong>记录。</p><p id="fa65" class="pw-post-body-paragraph lr ls it lt b lu mw ju lw lx mx jx lz ma my mc md me mz mg mh mi na mk ml mm im bi translated"><code class="fe nn no np nq b">pandas</code>提供了一个易于使用的命令，允许开发人员对指定数量的记录进行采样，同时设置一个<code class="fe nn no np nq b">random_state</code>用于结果再现。我决定选择3000条记录，这是一个任意的数字，表示略少于10%的数据帧，它应该不会导致RAM过载。</p><pre class="kj kk kl km gt of nq og oh aw oi bi"><span id="4484" class="nb la it nq b gy oj ok l ol om">sample_df = true_fake.sample(3000, replace=True, random_state = 44)</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi pd"><img src="../Images/7bea9318a8f08f4146009aac9d358657.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*gW2pqsY_Q_jGjPqSe6J-lQ.png"/></div></div><figcaption class="ku kv gj gh gi kw kx bd b be z dk translated">新闻分类分布示例—按作者分类的图表</figcaption></figure><p id="6bea" class="pw-post-body-paragraph lr ls it lt b lu mw ju lw lx mx jx lz ma my mc md me mz mg mh mi na mk ml mm im bi translated">即使有3000条记录，虚假新闻和真实新闻之间的分布保持不变。这意味着我们可以进入下一阶段。</p><h2 id="27ea" class="nb la it bd lb nc nd dn lf ne nf dp lj ma ng nh ll me ni nj ln mi nk nl lp nm bi translated">文本清理</h2><p id="ebe2" class="pw-post-body-paragraph lr ls it lt b lu lv ju lw lx ly jx lz ma mb mc md me mf mg mh mi mj mk ml mm im bi translated">自然语言处理中的文本清理是最基本的。<strong class="lt iu">停用词</strong>、<strong class="lt iu">特殊字符</strong>和<strong class="lt iu"> HTML标签</strong>都为我们的模型处理增加了不必要的复杂性。</p><p id="4de9" class="pw-post-body-paragraph lr ls it lt b lu mw ju lw lx mx jx lz ma my mc md me mz mg mh mi na mk ml mm im bi translated">消除以上所有问题会导致培训和测试时间的<strong class="lt iu">改进</strong>。在完成了对我在文章开头展示的真实新闻样本的清理过程后，最终结果如下所示:</p><pre class="kj kk kl km gt of nq og oh aw oi bi"><span id="d46a" class="nb la it nq b gy oj ok l ol om">washington reuters head conservative republican faction u congress voted month huge expansion national debt pay tax cuts called fiscal conservative sunday urged budget restraint 2018 keeping sharp pivot way among republicans u representative mark meadows speaking cbs face nation drew hard line federal spending lawmakers bracing battle january...</span></pre><p id="95b8" class="pw-post-body-paragraph lr ls it lt b lu mw ju lw lx mx jx lz ma my mc md me mz mg mh mi na mk ml mm im bi translated">以上是模型将被训练和测试的新闻语料库的例子。</p><h2 id="1875" class="nb la it bd lb nc nd dn lf ne nf dp lj ma ng nh ll me ni nj ln mi nk nl lp nm bi translated">型号选择</h2><p id="0dba" class="pw-post-body-paragraph lr ls it lt b lu lv ju lw lx ly jx lz ma mb mc md me mf mg mh mi mj mk ml mm im bi translated">是时候实施<strong class="lt iu">模式选择</strong>机制了。代码通过<strong class="lt iu">计数矢量器</strong>和前面列出的所有模型传输数据，最后执行<strong class="lt iu"> k倍交叉验证</strong>。然后计算平均精度，并组织成箱线图。让我们一步一步地分解它:</p><ul class=""><li id="e03c" class="nr ns it lt b lu mw lx mx ma nt me nu mi nv mm nw nx ny nz bi translated"><code class="fe nn no np nq b">scikit-learn</code>和<code class="fe nn no np nq b">matplotlib</code>是唯一需要的两个<strong class="lt iu">库</strong>吗？Sklearn包括对数据执行机器学习所需的所有功能。每个模型通过一个“子库”导入:<code class="fe nn no np nq b">LogisticRegression</code>、<code class="fe nn no np nq b">KNeighborsClassifier</code>、<code class="fe nn no np nq b">DecisionTreeClassifier</code>、<code class="fe nn no np nq b">SVC</code>、<code class="fe nn no np nq b">GaussianNB</code>、<code class="fe nn no np nq b">LinearDiscriminantAnalysis</code>。</li><li id="2363" class="nr ns it lt b lu oa lx ob ma oc me od mi oe mm nw nx ny nz bi translated">在这个阶段，我们可以从数据中定义输入和目标变量。输入变量<code class="fe nn no np nq b">x</code>是“<strong class="lt iu"> <em class="pe">文本</em> </strong>”，包含评论的语料库；输出变量<code class="fe nn no np nq b">y</code>为“<strong class="lt iu"> <em class="pe">分类</em> </strong>”，标注为<strong class="lt iu"> 0 </strong>和<strong class="lt iu"> 1 </strong>。</li><li id="b7df" class="nr ns it lt b lu oa lx ob ma oc me od mi oe mm nw nx ny nz bi translated">我们知道，一些用于分析的模型，包括决策树分类器，需要一个<strong class="lt iu">密集矩阵</strong>。密集矩阵大多包含非零值。<code class="fe nn no np nq b">ToDenseTransformer</code>类确保所有矩阵都是密集的，以避免任何错误。</li><li id="2ae1" class="nr ns it lt b lu oa lx ob ma oc me od mi oe mm nw nx ny nz bi translated">然后创建列表<code class="fe nn no np nq b">models</code>，分配给每个模型的对象被添加到列表中。另一方面，列表<code class="fe nn no np nq b">results</code>将包含所有与其名称相关的不同模型分数。</li><li id="6f62" class="nr ns it lt b lu oa lx ob ma oc me od mi oe mm nw nx ny nz bi translated"><code class="fe nn no np nq b">kfold</code>参数表示我们想要多少个<strong class="lt iu"> <em class="pe"> </em> </strong> k倍。这就引入了<strong class="lt iu">交叉验证</strong>的概念。交叉验证旨在更好地估计模型的准确性。定义为<strong class="lt iu"> k倍</strong>交叉验证，其中<strong class="lt iu"> <em class="pe"> </em> k </strong>为数据被划分的子组数。该模型在一个分组上进行训练，并在剩余的<strong class="lt iu"> k-1 </strong>上进行测试。准确度是根据平均分计算的。</li><li id="6985" class="nr ns it lt b lu oa lx ob ma oc me od mi oe mm nw nx ny nz bi translated"><strong class="lt iu">流水线</strong>在选择的<strong class="lt iu"> k-fold </strong>上应用<strong class="lt iu">计数矢量器</strong>、<strong class="lt iu">密集变换器</strong>和<strong class="lt iu">选择模型</strong>并执行交叉验证。然后它在控制台上打印结果。</li><li id="670a" class="nr ns it lt b lu oa lx ob ma oc me od mi oe mm nw nx ny nz bi translated"><code class="fe nn no np nq b">matplotlib</code>最终生成一个<strong class="lt iu">箱线图</strong>，这样我们可以更好地解释结果。</li></ul><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="pf pg l"/></div><figcaption class="ku kv gj gh gi kw kx bd b be z dk translated">为我们的数据寻找性能最佳的模型——按作者编码</figcaption></figure><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ph"><img src="../Images/cc266296028f3f807144c1bea0ec653d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Z-hnPyx5nnMcLqGVcEA2VA.png"/></div></div><figcaption class="ku kv gj gh gi kw kx bd b be z dk translated">模型选择过程后算法的准确性比较—作者提供的图表</figcaption></figure><p id="572d" class="pw-post-body-paragraph lr ls it lt b lu mw ju lw lx mx jx lz ma my mc md me mz mg mh mi na mk ml mm im bi translated">箱线图为您提供了我们模型在精确度方面的五个关键数值的信息:</p><ul class=""><li id="9e98" class="nr ns it lt b lu mw lx mx ma nt me nu mi nv mm nw nx ny nz bi translated"><strong class="lt iu">最小值</strong></li><li id="62bd" class="nr ns it lt b lu oa lx ob ma oc me od mi oe mm nw nx ny nz bi translated">第一个四分位数(第25个百分点)</li><li id="98e8" class="nr ns it lt b lu oa lx ob ma oc me od mi oe mm nw nx ny nz bi translated"><strong class="lt iu">中位数</strong>(第二个四分位数)</li><li id="fb75" class="nr ns it lt b lu oa lx ob ma oc me od mi oe mm nw nx ny nz bi translated">第三个四分位数(75%)</li><li id="e83b" class="nr ns it lt b lu oa lx ob ma oc me od mi oe mm nw nx ny nz bi translated"><strong class="lt iu">最大值</strong>。</li></ul><p id="77a1" class="pw-post-body-paragraph lr ls it lt b lu mw ju lw lx mx jx lz ma my mc md me mz mg mh mi na mk ml mm im bi translated">在<strong class="lt iu"> x轴</strong>上，有所有被纳入分析的模型进行交叉验证。相反，在<strong class="lt iu"> y轴</strong>上，我们有准确度分数。单从图表来看，很难准确说出每个模型的表现有多好；例如，逻辑回归和决策树分类器彼此非常接近。在这种情况下，控制台上打印的值会有所帮助:</p><pre class="kj kk kl km gt of nq og oh aw oi bi"><span id="50bc" class="nb la it nq b gy oj ok l ol om">LR: 0.986333 (0.006046)<br/>LDA: 0.777333 (0.028628)<br/>KNN: 0.693000 (0.022531)<br/>CART: 0.990333 (0.007219)<br/>NB: 0.833333 (0.017951)<br/>SVM: 0.971333 (0.009452)</span></pre><p id="fc90" class="pw-post-body-paragraph lr ls it lt b lu mw ju lw lx mx jx lz ma my mc md me mz mg mh mi na mk ml mm im bi translated">左边的数字表示平均准确度，括号中的数字是交叉验证后计算的方差。很明显<strong class="lt iu"> CART </strong>在准确性方面是<strong class="lt iu">表现最好的</strong>，但是<strong class="lt iu">逻辑回归</strong>在提供<strong class="lt iu">一致的</strong>结果方面略胜一筹(差距很小)。</p><h2 id="6d89" class="nb la it bd lb nc nd dn lf ne nf dp lj ma ng nh ll me ni nj ln mi nk nl lp nm bi translated">逻辑回归超参数调整</h2><p id="4c04" class="pw-post-body-paragraph lr ls it lt b lu lv ju lw lx ly jx lz ma mb mc md me mf mg mh mi mj mk ml mm im bi translated">逻辑回归是具有最高精确度和最低方差的两个模型之一，这使其成为<strong class="lt iu">超参数调整</strong>阶段的绝佳候选。</p><p id="9f72" class="pw-post-body-paragraph lr ls it lt b lu mw ju lw lx mx jx lz ma my mc md me mz mg mh mi na mk ml mm im bi translated">与逻辑回归模型相关的两个参数是:</p><ul class=""><li id="750f" class="nr ns it lt b lu mw lx mx ma nt me nu mi nv mm nw nx ny nz bi translated"><em class="pe">解算器</em>是<em class="pe"> </em>一种帮助模型更好地适应数据的算法。在逻辑回归的情况下，有5种类型:<code class="fe nn no np nq b">liblinear</code>、<code class="fe nn no np nq b">lbfgs</code>、<code class="fe nn no np nq b">newton-cg</code>、<code class="fe nn no np nq b">sag</code>和<code class="fe nn no np nq b">saga</code>。</li><li id="e200" class="nr ns it lt b lu oa lx ob ma oc me od mi oe mm nw nx ny nz bi translated"><em class="pe"> C参数</em>表示正则化强度。分配给C的值越高，意味着正则化越强。当模型以看不见的数据呈现时，正则化是泛化的同义词。</li></ul><p id="915c" class="pw-post-body-paragraph lr ls it lt b lu mw ju lw lx mx jx lz ma my mc md me mz mg mh mi na mk ml mm im bi translated">以下代码调整上述超参数以及计数矢量器参数，以找到最佳组合:</p><ul class=""><li id="7bcd" class="nr ns it lt b lu mw lx mx ma nt me nu mi nv mm nw nx ny nz bi translated">在前一个代码单元中已经导入了库，但是我决定重新导入它们以使这个代码片段独立。在这种情况下，我们只需要<code class="fe nn no np nq b">sklearn</code>以及与交叉验证、模型部署、流水线和计数矢量器相关的子包。</li><li id="f49b" class="nr ns it lt b lu oa lx ob ma oc me od mi oe mm nw nx ny nz bi translated">这次的流水线只包括<strong class="lt iu">计数矢量器</strong>和<strong class="lt iu">逻辑回归</strong>模型。不需要密集变压器</li><li id="c6e5" class="nr ns it lt b lu oa lx ob ma oc me od mi oe mm nw nx ny nz bi translated">转到参数列表，这些包含了<code class="fe nn no np nq b">grid_search</code>为管道的每个组件尝试的所有可能的超参数组合。例如，参数<strong class="lt iu"> </strong> <code class="fe nn no np nq b">max_df</code>的计数，矢量器负责模型的<strong class="lt iu">泛化</strong>。<code class="fe nn no np nq b">max_df</code>删除出现太频繁的单词，0.7的<code class="fe nn no np nq b">max_df</code>忽略出现在超过70%的文档中的术语。在一个场景中，<code class="fe nn no np nq b">vect__max_df</code>将使用内核<code class="fe nn no np nq b">poly</code>和参数<code class="fe nn no np nq b">C</code>10将0.7的<code class="fe nn no np nq b">max_df</code>与(1，1)的<code class="fe nn no np nq b">ngram_range</code>组合起来。因为每个交叉验证进行了5次，所以总“适合”(组合)是405。</li><li id="1569" class="nr ns it lt b lu oa lx ob ma oc me od mi oe mm nw nx ny nz bi translated">启动<code class="fe nn no np nq b">grid_search.fit</code>后，最后一部分代码开始在控制台上打印计算结果</li></ul><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="pf pg l"/></div><figcaption class="ku kv gj gh gi kw kx bd b be z dk translated">为计数矢量器和逻辑回归模型寻找最佳参数—由作者编写代码</figcaption></figure><p id="3acd" class="pw-post-body-paragraph lr ls it lt b lu mw ju lw lx mx jx lz ma my mc md me mz mg mh mi na mk ml mm im bi translated">逻辑回归模型的最佳超参数设置如下:</p><pre class="kj kk kl km gt of nq og oh aw oi bi"><span id="3ff4" class="nb la it nq b gy oj ok l ol om">Best: 0.989000 using {'LR__C': 100, 'LR__solver': 'liblinear', 'vect__max_df': 0.8, 'vect__ngram_range': (1, 3)} </span><span id="040e" class="nb la it nq b gy pc ok l ol om">0.986667 (0.004346) with: {'LR__C': 100, 'LR__solver': 'newton-cg', 'vect__max_df': 0.7, 'vect__ngram_range': (1, 1)} </span><span id="3636" class="nb la it nq b gy pc ok l ol om">0.984333 (0.005228) with: {'LR__C': 100, 'LR__solver': 'newton-cg', 'vect__max_df': 0.7, 'vect__ngram_range': (1, 2)}</span></pre><ul class=""><li id="b913" class="nr ns it lt b lu mw lx mx ma nt me nu mi nv mm nw nx ny nz bi translated">C = 100</li><li id="8e18" class="nr ns it lt b lu oa lx ob ma oc me od mi oe mm nw nx ny nz bi translated">内核类型= liblinear</li><li id="7fb7" class="nr ns it lt b lu oa lx ob ma oc me od mi oe mm nw nx ny nz bi translated">max_df = 0.7</li><li id="8ed9" class="nr ns it lt b lu oa lx ob ma oc me od mi oe mm nw nx ny nz bi translated">ngram_range = (1，3)</li></ul><p id="1248" class="pw-post-body-paragraph lr ls it lt b lu mw ju lw lx mx jx lz ma my mc md me mz mg mh mi na mk ml mm im bi translated">通过这些设置，当在仅3000条新闻上部署交叉验证方法时，该模型实现了98%的准确性。结果已经非常有希望了。给定最优的<strong class="lt iu">超参数</strong>，例如<code class="fe nn no np nq b">C </code>和<code class="fe nn no np nq b">max_df</code>，我们已经可以知道算法的泛化应该足以正确地对看不见的数据进行分类。</p><pre class="kj kk kl km gt of nq og oh aw oi bi"><span id="0f3c" class="nb la it nq b gy oj ok l ol om">              precision    recall  f1-score   support<br/>      <br/>           0       1.00      1.00      1.00      4310    <br/>           1       1.00      1.00      1.00      4670</span><span id="245a" class="nb la it nq b gy pc ok l ol om">    accuracy                           1.00      8980   <br/>   macro avg       1.00      1.00      1.00      8980 <br/>weighted avg       1.00      1.00      1.00      8980</span></pre><p id="983c" class="pw-post-body-paragraph lr ls it lt b lu mw ju lw lx mx jx lz ma my mc md me mz mg mh mi na mk ml mm im bi translated">令人惊讶的是，当部署在大约9000个看不见的测试记录上时，该模型呈现出100%的准确性。尤其是在这种情况下，可能有多种原因导致一个训练有素的模型如此精确。</p><p id="cc19" class="pw-post-body-paragraph lr ls it lt b lu mw ju lw lx mx jx lz ma my mc md me mz mg mh mi na mk ml mm im bi translated"><strong class="lt iu">“过拟合”</strong>就是其中之一。如果模型在同一数据集中对记录进行了很好的分类，但是当它部署到新数据上时，它失去了准确性，那么可能会发生过度拟合。</p><p id="91eb" class="pw-post-body-paragraph lr ls it lt b lu mw ju lw lx mx jx lz ma my mc md me mz mg mh mi na mk ml mm im bi translated">第二个原因可能是“<strong class="lt iu">幸运拉动</strong>”。如果一个模型在数据集的正确部分进行训练，并在容易分类的记录上进行测试，那么可能发生了幸运的拉动。然而，另一方面，交叉验证应该从根本上消除这个问题。</p><p id="9172" class="pw-post-body-paragraph lr ls it lt b lu mw ju lw lx mx jx lz ma my mc md me mz mg mh mi na mk ml mm im bi translated">第三个原因可能是数据集具有外部数据所没有的<strong class="lt iu">共同特征</strong>。有可能这个数据集中的所有假新闻都包含“假”这个词或标签。对于一个模型来说，在同一个数据集中理解真实和虚假的新闻要容易得多，但是一旦出现新的数据，准确性可能会下降。</p><p id="b109" class="pw-post-body-paragraph lr ls it lt b lu mw ju lw lx mx jx lz ma my mc md me mz mg mh mi na mk ml mm im bi translated">上述所有问题的常见解决方案是在不同的数据集上部署模型，并评估性能是保持不变还是下降。</p><h2 id="ee71" class="nb la it bd lb nc nd dn lf ne nf dp lj ma ng nh ll me ni nj ln mi nk nl lp nm bi translated">决策树分类器</h2><p id="45ff" class="pw-post-body-paragraph lr ls it lt b lu lv ju lw lx ly jx lz ma mb mc md me mf mg mh mi mj mk ml mm im bi translated">决策树分类器(CART)在用于分析的6种算法中显示出最好的准确性。超参数调优后，性能应该会更好。</p><p id="6c00" class="pw-post-body-paragraph lr ls it lt b lu mw ju lw lx mx jx lz ma my mc md me mz mg mh mi na mk ml mm im bi translated">购物车模型的三个参数是:</p><ul class=""><li id="30ca" class="nr ns it lt b lu mw lx mx ma nt me nu mi nv mm nw nx ny nz bi translated"><code class="fe nn no np nq b">max_features</code>是“每次做出拆分决定时要考虑的特征数量”[5]。如果数据有50列，那么您可以将该参数设置为10，以便在训练阶段只包括这50列中的10列。</li><li id="4711" class="nr ns it lt b lu oa lx ob ma oc me od mi oe mm nw nx ny nz bi translated"><code class="fe nn no np nq b">max_depth</code>是一棵树可以拥有的“分枝”的最大数量。较高的值可能会导致过度拟合。</li><li id="4912" class="nr ns it lt b lu oa lx ob ma oc me od mi oe mm nw nx ny nz bi translated"><code class="fe nn no np nq b">min_samples_leaf</code>是“一个叶节点所需的最小样本数”【5】。该值决定了树需要的最小分割点。</li></ul><p id="f638" class="pw-post-body-paragraph lr ls it lt b lu mw ju lw lx mx jx lz ma my mc md me mz mg mh mi na mk ml mm im bi translated">除了超参数之外，与逻辑回归相比，CART模型的代码片段没有其他变化。</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="pf pg l"/></div><figcaption class="ku kv gj gh gi kw kx bd b be z dk translated">为计数矢量器和CART模型寻找最佳参数—按作者编码</figcaption></figure><p id="e7ff" class="pw-post-body-paragraph lr ls it lt b lu mw ju lw lx mx jx lz ma my mc md me mz mg mh mi na mk ml mm im bi translated">购物车模型中性能最好的超参数设置如下:</p><pre class="kj kk kl km gt of nq og oh aw oi bi"><span id="cb22" class="nb la it nq b gy oj ok l ol om">Best: 0.990000 using {'CART__max_depth': 4, 'CART__max_features': 0.8, 'CART__min_samples_leaf': 0.04, 'vect__max_df': 0.7, 'vect__ngram_range': (1, 1)}</span><span id="7c6a" class="nb la it nq b gy pc ok l ol om">0.986667 (0.006055) with: {'CART__max_depth': 3, 'CART__max_features': 0.2, 'CART__min_samples_leaf': 0.04, 'vect__max_df': 0.7, 'vect__ngram_range': (1, 2)} </span><span id="e88c" class="nb la it nq b gy pc ok l ol om">0.906000 (0.104337) with: {'CART__max_depth': 3, 'CART__max_features': 0.2, 'CART__min_samples_leaf': 0.04, 'vect__max_df': 0.7, 'vect__ngram_range': (1, 3)}</span></pre><ul class=""><li id="b3c8" class="nr ns it lt b lu mw lx mx ma nt me nu mi nv mm nw nx ny nz bi translated">max_depth = 4</li><li id="04a6" class="nr ns it lt b lu oa lx ob ma oc me od mi oe mm nw nx ny nz bi translated">最大特征数= 0.8</li><li id="230e" class="nr ns it lt b lu oa lx ob ma oc me od mi oe mm nw nx ny nz bi translated">最小样本叶= 0.04</li><li id="c302" class="nr ns it lt b lu oa lx ob ma oc me od mi oe mm nw nx ny nz bi translated">max_df = 0.7</li><li id="2a9f" class="nr ns it lt b lu oa lx ob ma oc me od mi oe mm nw nx ny nz bi translated">ngram_range = (1，1)</li></ul><p id="d6e3" class="pw-post-body-paragraph lr ls it lt b lu mw ju lw lx mx jx lz ma my mc md me mz mg mh mi na mk ml mm im bi translated">使用计数矢量器和算法的上述超参数，平均准确度达到99%的分数。</p><pre class="kj kk kl km gt of nq og oh aw oi bi"><span id="9298" class="nb la it nq b gy oj ok l ol om">              precision    recall  f1-score   support<br/>      <br/>           0       0.99      1.00      0.99      4310     <br/>           1       1.00      0.99      0.99      4670</span><span id="745d" class="nb la it nq b gy pc ok l ol om">    accuracy                           0.99      8980    <br/>   macro avg       0.99      0.99      0.99      8980 <br/>weighted avg       0.99      0.99      0.99      8980</span></pre><p id="7d06" class="pw-post-body-paragraph lr ls it lt b lu mw ju lw lx mx jx lz ma my mc md me mz mg mh mi na mk ml mm im bi translated">一旦我们在40，000条记录上部署模型，并在9000条记录上测试它，准确性保持不变。99%的准确率仍然是一个很大的成就，但另一方面，大约4000条记录中有1%被错误分类，逻辑回归似乎总体上是部署在新记录上的更好的解决方案。</p><h2 id="3412" class="nb la it bd lb nc nd dn lf ne nf dp lj ma ng nh ll me ni nj ln mi nk nl lp nm bi translated">对来自不同数据集的看不见的数据测试模型</h2><p id="8e75" class="pw-post-body-paragraph lr ls it lt b lu lv ju lw lx ly jx lz ma mb mc md me mf mg mh mi mj mk ml mm im bi translated">我们终于到了最后阶段。作为对迄今所做工作的提醒:</p><ol class=""><li id="1561" class="nr ns it lt b lu mw lx mx ma nt me nu mi nv mm pi nx ny nz bi translated">我们认为逻辑回归是最好的模型</li><li id="15d9" class="nr ns it lt b lu oa lx ob ma oc me od mi oe mm pi nx ny nz bi translated">调整逻辑回归模型</li><li id="6ed4" class="nr ns it lt b lu oa lx ob ma oc me od mi oe mm pi nx ny nz bi translated">对31000条记录进行训练，并对剩下的9000条记录进行测试</li></ol><p id="20e5" class="pw-post-body-paragraph lr ls it lt b lu mw ju lw lx mx jx lz ma my mc md me mz mg mh mi na mk ml mm im bi translated">本节旨在了解数据集内某个共同特征的先前假设是否为真。我们怎么做呢？我们通过在一个单独的假新闻数据集上测试该模型是否产生相同的结果来做到这一点[4]。数据集只呈现一个限制，它只包含假新闻。</p><p id="93c6" class="pw-post-body-paragraph lr ls it lt b lu mw ju lw lx mx jx lz ma my mc md me mz mg mh mi na mk ml mm im bi translated">以下代码片段显示了如何继续:</p><ul class=""><li id="5ee8" class="nr ns it lt b lu mw lx mx ma nt me nu mi nv mm nw nx ny nz bi translated">我们进口<code class="fe nn no np nq b">pandas</code></li><li id="e0df" class="nr ns it lt b lu oa lx ob ma oc me od mi oe mm nw nx ny nz bi translated">从CSV文件创建数据帧，并将其重新命名为<code class="fe nn no np nq b">fake_test</code></li><li id="44d7" class="nr ns it lt b lu oa lx ob ma oc me od mi oe mm nw nx ny nz bi translated">从21个可用列中选择相关列，并过滤掉所有非英文记录</li><li id="9baa" class="nr ns it lt b lu oa lx ob ma oc me od mi oe mm nw nx ny nz bi translated">在我们设置了输入和输出变量之后，所有的记录都需要用单词包方法进行转换</li><li id="ec2f" class="nr ns it lt b lu oa lx ob ma oc me od mi oe mm nw nx ny nz bi translated">最后，命令<code class="fe nn no np nq b">LR.predict</code>用训练好的模型对记录进行分类</li></ul><pre class="kj kk kl km gt of nq og oh aw oi bi"><span id="b9d4" class="nb la it nq b gy oj ok l ol om">#Importing libraries<br/>import pandas as pd</span><span id="00e4" class="nb la it nq b gy pc ok l ol om">#Creating dataframe<br/>fake_test = pd.read_csv("fake.csv")</span><span id="cb5e" class="nb la it nq b gy pc ok l ol om">#Adding classification column to identify fake-news<br/>fake_test['classification'] = 1</span><span id="43fe" class="nb la it nq b gy pc ok l ol om">#Selecting relevant columns with only english records<br/>fake_test = fake_test[['text', 'language', 'classification']]<br/>fake_test = fake_test.query("language == 'english'")</span><span id="51f6" class="nb la it nq b gy pc ok l ol om">#Espliciting input and output variables<br/>x_test = fake_test['text']<br/>y_test = fake_test['classification']</span><span id="ec90" class="nb la it nq b gy pc ok l ol om">#Transforming 'text' column into bag of words<br/>bow_test = count_vect.transform(x_test.values.astype('U'))</span><span id="7614" class="nb la it nq b gy pc ok l ol om">#Classify new records<br/>predicted_LR_test = LR.predict(bow_test)</span><span id="9f8c" class="nb la it nq b gy pc ok l ol om">#Print accuracy report<br/>print(classification_report(y_test, predicted_LR_test))</span></pre><p id="263f" class="pw-post-body-paragraph lr ls it lt b lu mw ju lw lx mx jx lz ma my mc md me mz mg mh mi na mk ml mm im bi translated">正如预期的那样，数据集只包含假新闻，分类器正确地预测了每一个假新闻，保持了在调整和测试阶段所承诺的内容。我们的模型以100%的精度分类新闻是否是假的，即使使用具有最小计算成本的外部数据集。</p><pre class="kj kk kl km gt of nq og oh aw oi bi"><span id="da3d" class="nb la it nq b gy oj ok l ol om">              precision    recall  f1-score   support<br/>      <br/>           0       0.00      0.00      0.00         0     <br/>           1       1.00      0.97      0.98     12357</span><span id="9be0" class="nb la it nq b gy pc ok l ol om">    accuracy                           0.97     12357    <br/>   macro avg       0.50      0.48      0.49     12357 <br/>weighted avg       1.00      0.97      0.98     12357</span></pre><p id="85e9" class="pw-post-body-paragraph lr ls it lt b lu mw ju lw lx mx jx lz ma my mc md me mz mg mh mi na mk ml mm im bi translated">尽管总体精度受到召回分数的影响。现在，如果精度在数学上定义为:</p><pre class="kj kk kl km gt of nq og oh aw oi bi"><span id="f9a0" class="nb la it nq b gy oj ok l ol om">p = true positives / (true positives + false positives)</span></pre><p id="15d8" class="pw-post-body-paragraph lr ls it lt b lu mw ju lw lx mx jx lz ma my mc md me mz mg mh mi na mk ml mm im bi translated">召回分数定义为:</p><pre class="kj kk kl km gt of nq og oh aw oi bi"><span id="d541" class="nb la it nq b gy oj ok l ol om">r = true positives / (true positives + false negatives)</span></pre><p id="a044" class="pw-post-body-paragraph lr ls it lt b lu mw ju lw lx mx jx lz ma my mc md me mz mg mh mi na mk ml mm im bi translated">所以你可以从下面的混淆矩阵中看到，420条本该被归类为假的记录，实际上被模型归类为真。尽管如此，考虑到该算法已经部署在不同的数据集上，性能还是令人满意的。它允许我们消除<strong class="lt iu">过度拟合</strong>和<strong class="lt iu">共同特征</strong>假设。</p><pre class="kj kk kl km gt of nq og oh aw oi bi"><span id="ced3" class="nb la it nq b gy oj ok l ol om">             predicted<br/>             (0)    (1)<br/>            --------------<br/>       (1) | 420  | 11937|<br/>actual      --------------<br/>       (0) | 0    | 0    |<br/>            --------------</span></pre><h1 id="081c" class="kz la it bd lb lc ld le lf lg lh li lj jz lk ka ll kc lm kd ln kf lo kg lp lq bi translated">结论</h1><p id="624e" class="pw-post-body-paragraph lr ls it lt b lu lv ju lw lx ly jx lz ma mb mc md me mf mg mh mi mj mk ml mm im bi translated">该项目显示了实施<strong class="lt iu">模型选择</strong>和<strong class="lt iu">超参数调整</strong>机制的重要性，它们允许从业者探索各种不同的选项，最终在多个视角下产生出色的执行模型。</p><p id="e6ed" class="pw-post-body-paragraph lr ls it lt b lu mw ju lw lx mx jx lz ma my mc md me mz mg mh mi na mk ml mm im bi translated">最重要的是，与人类相比，它提醒我们机器学习在<strong class="lt iu">速度</strong>方面的潜力。该算法只花了几分钟时间进行训练，随后对数万条记录进行了分类。一个人完成同样的任务需要几个星期。</p><p id="a54e" class="pw-post-body-paragraph lr ls it lt b lu mw ju lw lx mx jx lz ma my mc md me mz mg mh mi na mk ml mm im bi translated">接下来可能的步骤包括将<strong class="lt iu">部署到另一个包含虚假和真实新闻的数据集</strong>上，或者在基于<strong class="lt iu">机器学习的产品</strong>中实现该算法，例如<a class="ae ky" href="https://github.com/selfagency/bs-detector" rel="noopener ugc nofollow" target="_blank"> BS检测器</a>。</p><p id="ff6a" class="pw-post-body-paragraph lr ls it lt b lu mw ju lw lx mx jx lz ma my mc md me mz mg mh mi na mk ml mm im bi translated">最后，这篇文章旨在提高对假新闻问题的认识，这个问题在社交媒体平台上可能太受欢迎了。在信息时代，<strong class="lt iu">误传</strong>是我们需要解决的一个魔咒，而AI代表了一个做这件事的伟大工具。</p></div><div class="ab cl pj pk hx pl" role="separator"><span class="pm bw bk pn po pp"/><span class="pm bw bk pn po pp"/><span class="pm bw bk pn po"/></div><div class="im in io ip iq"><p id="b86d" class="pw-post-body-paragraph lr ls it lt b lu mw ju lw lx mx jx lz ma my mc md me mz mg mh mi na mk ml mm im bi translated"><em class="pe">最后一点，如果您喜欢该内容，请考虑添加一个关注，以便在新文章发布时得到通知。如果你对这篇文章有什么要考虑的，写在评论里吧！我很想读读它们:)谢谢你的阅读！</em></p><p id="dd7d" class="pw-post-body-paragraph lr ls it lt b lu mw ju lw lx mx jx lz ma my mc md me mz mg mh mi na mk ml mm im bi translated"><em class="pe"> PS:如果你喜欢我写的东西，如果你能通过</em> <a class="ae ky" href="https://giovanni-valdata.medium.com/membership" rel="noopener"> <em class="pe">这个链接</em> </a> <em class="pe">订阅一个灵媒会员，那对我来说就是全世界。有了会员资格，你就获得了媒体文章提供的惊人价值，这是支持我的内容的一种间接方式！</em></p></div><div class="ab cl pj pk hx pl" role="separator"><span class="pm bw bk pn po pp"/><span class="pm bw bk pn po pp"/><span class="pm bw bk pn po"/></div><div class="im in io ip iq"><p id="cb3f" class="pw-post-body-paragraph lr ls it lt b lu mw ju lw lx mx jx lz ma my mc md me mz mg mh mi na mk ml mm im bi translated">[1]假新闻检测数据集—维多利亚大学。(2022).2022年8月11日检索，来自Uvic.ca网站:<a class="ae ky" href="https://www.uvic.ca/ecs/ece/isot/datasets/fake-news/index.php" rel="noopener ugc nofollow" target="_blank">https://www . uvic . ca/ECS/ECE/isot/datasets/fake-news/index . PHP</a></p><p id="d65d" class="pw-post-body-paragraph lr ls it lt b lu mw ju lw lx mx jx lz ma my mc md me mz mg mh mi na mk ml mm im bi translated">[2] Ahmed H，Traore I，Saad S .“使用文本分类检测观点垃圾邮件和假新闻”，《安全与隐私杂志》第1卷第1期，Wiley，<br/>2018年1月/2月。</p><p id="9d5f" class="pw-post-body-paragraph lr ls it lt b lu mw ju lw lx mx jx lz ma my mc md me mz mg mh mi na mk ml mm im bi translated">[3] Ahmed H，Traore I，Saad S. (2017)“使用N-Gram分析和机器学习技术检测在线假新闻。载于:Traore I .，Woungang I .，Awad A. (eds)分布式和云环境中的智能、安全和可靠的系统。ISDDC 2017。计算机科学讲义，第10618卷。施普林格，湛(第127- 138页)。</p><p id="a000" class="pw-post-body-paragraph lr ls it lt b lu mw ju lw lx mx jx lz ma my mc md me mz mg mh mi na mk ml mm im bi translated">[4]梅根·里斯达尔。(2016).“对假新闻[数据集]变得真实”。卡格尔。<a class="ae ky" href="https://doi.org/10.34740/KAGGLE/DSV/911" rel="noopener ugc nofollow" target="_blank">https://doi.org/10.34740/KAGGLE/DSV/911</a></p><p id="35a7" class="pw-post-body-paragraph lr ls it lt b lu mw ju lw lx mx jx lz ma my mc md me mz mg mh mi na mk ml mm im bi translated">[5]sk learn . tree . decision tree classifier .(2022)。2022年8月11日检索，来自scikit-learn网站:<a class="ae ky" href="https://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html" rel="noopener ugc nofollow" target="_blank">https://sci kit-learn . org/stable/modules/generated/sk learn . tree . decision tree classifier . html</a>‌</p></div></div>    
</body>
</html>