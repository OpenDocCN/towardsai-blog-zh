<html>
<head>
<title>The Rome Call for AI Ethics</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">人工智能伦理的罗马呼吁</h1>
<blockquote>原文：<a href="https://pub.towardsai.net/the-rome-call-for-ai-ethics-2c1a00ad528?source=collection_archive---------1-----------------------#2020-05-14">https://pub.towardsai.net/the-rome-call-for-ai-ethics-2c1a00ad528?source=collection_archive---------1-----------------------#2020-05-14</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><h2 id="788b" class="ir is it bd b dl iu iv iw ix iy iz dk ja translated" aria-label="kicker paragraph">人工智能</h2><div class=""/><div class=""><h2 id="dbae" class="pw-subtitle-paragraph jz jc it bd b ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq dk translated">当教皇、微软和IBM联手列出道德人工智能的六项原则时</h2></div><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi kr"><img src="../Images/9c1d064d3adc3f7673632b2f22eaae89.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*7IQEW96JteCV7G0W"/></div></div><figcaption class="ld le gj gh gi lf lg bd b be z dk translated">克里斯托夫·切尔马克在<a class="ae lh" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上拍摄的照片</figcaption></figure><p id="6274" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi me translated"><span class="l mf mg mh bm mi mj mk ml mm di">现在是2020年，这是人工智能快速发展的时期，尤其是深度学习，以及人们对数据越来越担忧的时期。公司每天收集用户的个人数据，并以各种方式使用这些数据。许多被认为是道德的，并遵守服务条款。其他的充其量也就是见不得光。在所有公司中，脸书是讨论这些问题时最常被提起的公司。</span></p><p id="8938" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">最近，微软、IBM和教皇陛下签署了一份向世界承诺的承诺书，坚持开发符合道德的人工智能产品和服务的六项原则。到目前为止，该提案只遭到了批评，要么是因为过于含糊不清，要么是因为缺乏执行政策的权力。在这篇文章中，我建议我们不要批评整个誓言，而是把重点放在原则本身。暂时忘掉教皇，或者微软，或者IBM。这些原则是什么意思，AI领域是如何处理的？</p><p id="e1e4" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">绰号为“T10”的罗马称“T11”列出了以下六条原则:</p><ol class=""><li id="05f8" class="mn mo it lk b ll lm lo lp lr mp lv mq lz mr md ms mt mu mv bi translated">透明性:人工智能系统必须是可解释的。</li><li id="f497" class="mn mo it lk b ll mw lo mx lr my lv mz lz na md ms mt mu mv bi translated"><strong class="lk jd">包容:</strong>必须考虑全人类的需求。</li><li id="2f72" class="mn mo it lk b ll mw lo mx lr my lv mz lz na md ms mt mu mv bi translated"><strong class="lk jd">责任:</strong>设计AI的人必须负责。</li><li id="0a11" class="mn mo it lk b ll mw lo mx lr my lv mz lz na md ms mt mu mv bi translated"><strong class="lk jd">不偏不倚:</strong>不偏不倚地创造或行动。</li><li id="23ce" class="mn mo it lk b ll mw lo mx lr my lv mz lz na md ms mt mu mv bi translated">可靠性:人工智能系统必须可靠地工作。</li><li id="af8d" class="mn mo it lk b ll mw lo mx lr my lv mz lz na md ms mt mu mv bi translated"><strong class="lk jd">安全和隐私:</strong> AI应该是安全的，尊重用户隐私。</li></ol><p id="13fc" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">每个概念都描述了人工智能及其创造者应该坚持的一个方面。最终，它恳求人工智能为全人类的福祉而工作，拥抱所有人，不歧视任何人。虽然这些想法的确很宽泛，梵蒂冈对企业没有实权，但它们本身就有价值，可以单独分析。</p><p id="20c1" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">当我们抛开所有的政治诉求时，有一个信息非常突出:<em class="nb">我们应该更有道德意识，并开始更经常地思考它。</em></p><p id="982c" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">最近，神经网络主导了人工智能领域，简单地说，它们与所要求的完全相反。深度学习是无法解释的。它是有偏见的，局限于它所知道的数据。它远非强健。它容易受到敌对攻击，最后但并非最不重要的是，它只对使用它们的人负责。</p><p id="d00e" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">在下文中，我将对这些原则中的每一条进行评论，阐述它们的重要性和意义，同时也指出可能是解决这些问题的关键的研究方向。</p><p id="925f" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">让我们简短地绕道古希腊。</p><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi nc"><img src="../Images/957e410cb165dca03bb5a88ad9687b7f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*t6Zu4CcH5FdpHanL"/></div></div><figcaption class="ld le gj gh gi lf lg bd b be z dk translated">照片由<a class="ae lh" href="https://unsplash.com/@macpukpro?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Puk Patrick </a>在<a class="ae lh" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上拍摄</figcaption></figure><h1 id="c190" class="nd ne it bd nf ng nh ni nj nk nl nm nn ki no kj np kl nq km nr ko ns kp nt nu bi translated">道德和伦理</h1><p id="5344" class="pw-post-body-paragraph li lj it lk b ll nv kd ln lo nw kg lq lr nx lt lu lv ny lx ly lz nz mb mc md im bi translated">道德是我们认为正确和错误的一系列行为。这是我们的行为准则:我们的法律。道德告诉我们什么是对的，什么是错的。好公民努力达到他们社会的道德标准。</p><p id="1964" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">道德的问题在于它是相对的。它随着时间和社会的不同而变化。奴隶制曾经被接受，也禁止妇女参政。这些变了。目前，我们讨论娱乐性药物的合法性和流产的权利。道德总是被审查的。</p><p id="8bca" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">另一方面，伦理是完美道德的概念。一个伦理社会是一个坚持最高道德标准的社会。道德不会改变。这是绝对的。这是对是非的科学研究。</p><p id="8858" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">伦理的问题是我们不知道它看起来像什么。所有的法律都力求尽可能地接近伦理。我们检讨我们的道德，试图成为一个更有道德的社会。<em class="nb">伦理是一个目标。</em></p><h2 id="30dd" class="oa ne it bd nf ob oc dn nj od oe dp nn lr of og np lv oh oi nr lz oj ok nt iz bi translated">道德人工智能与伦理人工智能</h2><p id="1587" class="pw-post-body-paragraph li lj it lk b ll nv kd ln lo nw kg lq lr nx lt lu lv ny lx ly lz nz mb mc md im bi translated">一个好的基线定义是，道德人工智能是一个坚持其社会道德标准的人工智能。换句话说，如果一家公司的人工智能没有违反任何法律，它可以被认为是道德的。希望所有的人工智能至少是道德的。辩护所寻求的是超越我们的准则所认为的体面。</p><p id="c2a3" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">法律和技术并不密切相关，这不是什么大新闻。大多数国家的法律比我们今天拥有的技术还要早。这迫使许多公司在灰色地带运营。这并不意味着他们在做坏事，而是缺乏明确的法律来界定什么是可接受的，什么是不可接受的，特别是在民法统治下的国家。</p><p id="ea0c" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">恳求敦促一个更道德的人工智能:超越我们目前的状态说是可以的。换句话说，这是一个讨论什么应该被接受，什么不应该被接受的电话。这是一个呼吁，以检讨我们的道德有关人工智能。</p><h1 id="fb55" class="nd ne it bd nf ng nh ni nj nk nl nm nn ki no kj np kl nq km nr ko ns kp nt nu bi translated">透明度</h1><blockquote class="ol"><p id="38c5" class="om on it bd oo op oq or os ot ou md dk translated">(……)原则上，人工智能系统必须是可解释的</p></blockquote><p id="1d90" class="pw-post-body-paragraph li lj it lk b ll ov kd ln lo ow kg lq lr ox lt lu lv oy lx ly lz oz mb mc md im bi translated">人工智能中的可解释性是一个涉及大量工作的广泛话题。本质上，它致力于回答为什么一个算法会预测A而不是b。拥有能够解释自己的算法。</p><p id="d4f1" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">当贷款被拒绝时，人们通常会询问原因。如果一个算法给出了最终的答案，它应该能够提供一个合理的解释，说明它为什么选择否认它。给定一个答案，对于经理来说，提出建议并不难，比如更低的价值或者更高的利率。可解释性超越了可理解的解释。这一切都是关于见解和决策。</p><p id="ae65" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">大多数时候，可解释性取决于设计。对贷款说“是或否”的系统比提供分数的系统更难理解。图像分类器比提供边界框或者更好的分割图的分类器更难解释。</p><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi pa"><img src="../Images/99e863ffb019e2d13c6252b12be3d491.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*GFL-KOxw7O-BT4TsEa0crg.jpeg"/></div></div><figcaption class="ld le gj gh gi lf lg bd b be z dk translated">使用YOLOv3模型使用OpenCV检测到的对象。边界框作为分类的一种形式解释。维基百科:<a class="ae lh" href="https://commons.wikimedia.org/wiki/User:MTheiler" rel="noopener ugc nofollow" target="_blank">MTheiler</a><a class="ae lh" href="https://creativecommons.org/licenses/by-sa/4.0" rel="noopener ugc nofollow" target="_blank">CC BY-SA 4.0</a></figcaption></figure><p id="603c" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">深刻的学习是不透明的；它是一个黑匣子。然而，我们可以用可解释的方式设计问题。进行物体检测，而不是分类。尝试分段。等等。<em class="nb">我们可以为解释而设计。</em></p><p id="f642" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">除了设计，还有很多工作致力于揭示对最终预测贡献最大的输入。OS<a class="ae lh" href="https://arxiv.org/abs/1708.08296" rel="noopener ugc nofollow" target="_blank">Samek<em class="nb">et al .</em></a><em class="nb"/>的工作是一个很好的起点，因为它为如何实现可解释性提供了一个全面的解释。</p><h1 id="a51b" class="nd ne it bd nf ng nh ni nj nk nl nm nn ki no kj np kl nq km nr ko ns kp nt nu bi translated">包含</h1><blockquote class="ol"><p id="4583" class="om on it bd oo op oq or os ot ou md dk translated">“(……)必须考虑到所有人的需要，以便每个人都能受益，所有个人都能得到表达自己和发展的最佳条件”</p></blockquote><p id="d225" class="pw-post-body-paragraph li lj it lk b ll ov kd ln lo ow kg lq lr ox lt lu lv oy lx ly lz oz mb mc md im bi translated">本质上，这是关于偏见。我们需要适用于所有种族的面部探测器。可以避开口音的语音识别模块。尽管完全不带偏见可能不可行，但我们肯定可以做得更多。</p><p id="897d" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">我认为风格转换文学对这一讨论有很多贡献。最初的方法是由<a class="ae lh" href="https://arxiv.org/abs/1508.06576" rel="noopener ugc nofollow" target="_blank"> Gatys等人</a>提出的，需要对每种新造型进行重新训练。后来的作品将这一过程优化为单次向前传递，代价是将网络限制为一种独特的风格。最后，Huang &amp; Belongie提出了一个<a class="ae lh" href="http://openaccess.thecvf.com/content_iccv_2017/html/Huang_Arbitrary_Style_Transfer_ICCV_2017_paper.html" rel="noopener ugc nofollow" target="_blank">任意风格转换模型</a>，基于一种新颖的规范化技术:自适应实例规范化(AdaIN)。</p><p id="9b60" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">从某种意义上说，这类似于一种从语音中去除重音的方法，创造了一种“标准化的声音”同样地，涉及一种可以将人脸归一化为无偏表示的技术。该模型不是对任何样式和内容图像都不偏不倚，而是使样式和内容图像相互偏向，并使用中性模型。我们可以通过设计来加强包容性<em class="nb">。</em></p><p id="f0be" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">另一个令人印象深刻的包容性观点是<em class="nb">硬件包容性</em>:能够在尽可能多的设备上运行。像<a class="ae lh" href="https://arxiv.org/abs/1810.04805" rel="noopener ugc nofollow" target="_blank"> Bert </a>和<a class="ae lh" href="http://papers.nips.cc/paper/7181-attention-is-all-you-need" rel="noopener ugc nofollow" target="_blank"> Transformer </a>这样的型号远非手机友好型，而<a class="ae lh" href="https://arxiv.org/abs/1704.04861" rel="noopener ugc nofollow" target="_blank"> MobileNet </a>和<a class="ae lh" href="https://arxiv.org/abs/1707.01083" rel="noopener ugc nofollow" target="_blank"> ShuffleNet </a>则专门针对低端设备。</p><p id="cd75" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">另一个减少模型大小和复杂性的方法是<a class="ae lh" href="https://blog.tensorflow.org/2019/05/tf-model-optimization-toolkit-pruning-API.html" rel="noopener ugc nofollow" target="_blank">修剪</a>，这是一个寻找保持大部分原始精度的子网的任务。</p><h1 id="58ea" class="nd ne it bd nf ng nh ni nj nk nl nm nn ki no kj np kl nq km nr ko ns kp nt nu bi translated">责任</h1><blockquote class="ol"><p id="b794" class="om on it bd oo op oq or os ot ou md dk translated">“(……)设计和部署人工智能使用的人必须以负责任和透明的方式行事”</p></blockquote><p id="6656" class="pw-post-body-paragraph li lj it lk b ll ov kd ln lo ow kg lq lr ox lt lu lv oy lx ly lz oz mb mc md im bi translated">责任是最起码的技术原则。它声明我们，开发者，应该是道德的。用吴恩达的话说，AI是新的电。人工智能应布线至所有设备，但也应受限于电缆。我们不要忘记，为我们的设备提供动力的，也是为雷电提供动力的。</p><p id="04dd" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">将我们的目光移向未来，可以指出人工通用智能(AGI)，或者非正式地说，“类人”智能。到时候，不仅仅是我们用模型做什么，还有我们教它们做什么，以及我们在它们身上植入的道德。</p><h1 id="8385" class="nd ne it bd nf ng nh ni nj nk nl nm nn ki no kj np kl nq km nr ko ns kp nt nu bi translated">公平</h1><blockquote class="ol"><p id="3c9a" class="om on it bd oo op oq or os ot ou md dk translated">“(……)不制造偏见或根据偏见行事，从而维护公平和人类尊严”</p></blockquote><p id="1583" class="pw-post-body-paragraph li lj it lk b ll ov kd ln lo ow kg lq lr ox lt lu lv oy lx ly lz oz mb mc md im bi translated">这个原则也是关于偏见的，但是从不同的角度来看:开发者的偏见。有些事情我们的模特可以做，有些事情<em class="nb">我们</em>可以做。</p><p id="63ee" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">考虑一下关于包容性的讨论:创建不偏向任何口音的语音识别模块。虽然我们应该从技术角度研究如何做到这一点，但我们也可以仔细地对我们的人口进行抽样，以获得尽可能多的多样性。</p><h1 id="50f8" class="nd ne it bd nf ng nh ni nj nk nl nm nn ki no kj np kl nq km nr ko ns kp nt nu bi translated">可靠性</h1><blockquote class="ol"><p id="6e81" class="om on it bd oo op oq or os ot ou md dk translated">“(……)人工智能系统必须能够可靠地工作”</p></blockquote><p id="5421" class="pw-post-body-paragraph li lj it lk b ll ov kd ln lo ow kg lq lr ox lt lu lv oy lx ly lz oz mb mc md im bi translated">健壮性是最难解决的问题之一。具体到医疗领域，人工智能解决方案在它们的训练数据集之外效果不佳。医院A的x光机产生的图片可能与医院b提供的图片略有不同。有时，这种情况发生在同一家医院内。这种差异通常足以破坏自动诊断系统，使其要么发出错误警报，要么保持沉默。</p><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi pb"><img src="../Images/746d39f2325bd79a6c64b25e22f93aab.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*jg4UCniu4X8nORg6"/></div></div><figcaption class="ld le gj gh gi lf lg bd b be z dk translated">每次拍摄的x射线图像可能会有很大差异，这是一个可靠性挑战。<a class="ae lh" href="https://unsplash.com/@nci?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">国立癌症研究所</a>在<a class="ae lh" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上拍摄的照片</figcaption></figure><p id="6520" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">这种可靠性的缺乏并不局限于医学领域。事实上，大多数领域缺乏数据，这使得解决方案很难很好地推广到不可预见的情况。为帮助一些工业过程而制造的人工智能系统可能会被锁定在它接受培训的工厂，从而限制了它在不同设施中应用的潜力。</p><p id="3cfa" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">对于自然图片，简单的事情，如夜间或光线不好，有时足以混淆算法。拍得不好的照片也是如此。</p><p id="e108" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">在可能应对可靠性问题的研究中，一个日益增长的趋势是<a class="ae lh" href="https://arxiv.org/abs/1904.05046" rel="noopener ugc nofollow" target="_blank">少量学习</a>——从一个到几十个训练样本中学习的任务。我们人类可以从有限的经验中学习，我们的模型也应该如此。</p><p id="152c" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">从不同的角度来看，三位图灵奖获得者认为我们应该(1)超越卷积，(2)利用半监督学习，(3)寻找可以推理的网络。他们的观点在2020年AAAI会议上给出，我们可以在YouTube<a class="ae lh" href="https://www.youtube.com/watch?v=UX8OubxsY8w" rel="noopener ugc nofollow" target="_blank">上观看:</a></p><h1 id="d721" class="nd ne it bd nf ng nh ni nj nk nl nm nn ki no kj np kl nq km nr ko ns kp nt nu bi translated">安全性和隐私</h1><blockquote class="ol"><p id="51f4" class="om on it bd oo op oq or os ot ou md dk translated">“(……)人工智能系统必须安全工作，并尊重用户的隐私”</p></blockquote><p id="0d63" class="pw-post-body-paragraph li lj it lk b ll ov kd ln lo ow kg lq lr ox lt lu lv oy lx ly lz oz mb mc md im bi translated">这个原则有两点:一是安全，二是隐私。当前的系统容易受到恶意攻击，并且通常需要云资源来运行。</p><p id="7a08" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">对抗性攻击是一种专门的技术，以某种方式篡改输入，迫使网络输出特定的结果。虽然我们人类很容易被愚弄，但神经网络的天真并不幼稚。这个话题与可靠性密切相关:模型不应该被轻易愚弄。</p><p id="14ba" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">至于隐私，这更多的是与负责任的使用而不是安全联系在一起。如果我们负责任地设计人工智能，它也应该解决隐私问题。然而，有一个工程方面我们不应该忽视:人工智能发生的地方。</p><p id="3761" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">如果人工智能必须在云上处理敏感信息，那么就有很大的犯错空间。另一方面，如果在智能手机等边缘设备上使用，就不需要互联网。消除数据传输的需要是减少潜在安全缺陷的有效方法。同样，我们可以用智能设计来执行这个原则。</p></div><div class="ab cl pc pd hx pe" role="separator"><span class="pf bw bk pg ph pi"/><span class="pf bw bk pg ph pi"/><span class="pf bw bk pg ph"/></div><div class="im in io ip iq"><p id="bbfb" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi me translated"><span class="l mf mg mh bm mi mj mk ml mm di">总之，我们应该在设计层面考虑可解释性、包容性、安全性和隐私，而不是事后才想到。它归结为你如何制定你的问题，如何输入数据，以及是否有任何数据必须从其他地方发送或接收。现在用现有的方法可以做很多这样的事情。</span></p><p id="cc61" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">未来，我们有望在这些问题上做更多的工作。也许语言模型会进化为分类提供彻底的解释，也许我们会看到成功的标准化技术解决偏见。复杂的设计可能会产生与人眼一样健壮甚至更好的模型，同时又安全，适合在边缘运行。</p><p id="70aa" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">最重要的是，我们作为一个社会也可能进化得更有道德。道德是一个目标，我真诚地希望我们将继续朝着这个目标前进。</p></div></div>    
</body>
</html>