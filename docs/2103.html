<html>
<head>
<title>Essential preprocessing techniques</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">基本预处理技术</h1>
<blockquote>原文：<a href="https://pub.towardsai.net/essential-preprocessing-techniques-11b0f591bf3a?source=collection_archive---------2-----------------------#2021-08-17">https://pub.towardsai.net/essential-preprocessing-techniques-11b0f591bf3a?source=collection_archive---------2-----------------------#2021-08-17</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><h2 id="50d1" class="io ip iq bd b dl ir is it iu iv iw dk ix translated" aria-label="kicker paragraph"><a class="ae ep" href="https://towardsai.net/p/category/nlp" rel="noopener ugc nofollow" target="_blank">自然语言处理</a></h2><div class=""/><p id="c1f7" class="pw-post-body-paragraph jw jx iq jy b jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ij bi translated">文本数据的预处理技术用代码来解释，这些代码只通过预处理数据来改善结果。</p><figure class="kv kw kx ky gt kz gh gi paragraph-image"><div role="button" tabindex="0" class="la lb di lc bf ld"><div class="gh gi ku"><img src="../Images/6fe1459c9452b5ae0b9eca35d76a59d2.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*THA0hzfDYLE9RIh4"/></div></div><figcaption class="lg lh gj gh gi li lj bd b be z dk translated"><a class="ae lk" href="https://unsplash.com/@sure_mp?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">苏伦德兰议员</a>在<a class="ae lk" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上的照片</figcaption></figure><p id="bdb3" class="pw-post-body-paragraph jw jx iq jy b jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ij bi translated">使用的数据肯定是机器学习任务中最有影响力的元素之一。当然，所使用的技术应该根据<strong class="jy ja">类型的数据</strong>(例如<em class="ll">文本</em>数据，如在线帖子或对话、<em class="ll">图像</em>或<em class="ll">音频</em>)以及项目的<strong class="jy ja">目的(例如<em class="ll">分类</em>、<em class="ll">分析</em>)来选择。</strong></p><p id="5989" class="pw-post-body-paragraph jw jx iq jy b jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ij bi translated">预处理步骤的目标是清除数据并对其进行转换，以使模型具有最佳的可能结果。因为文本数据是自然语言，所以它可能包含不相关和无用的信息，这些信息应该被消除。另一个方面是，模型的数据应该是一致的，以提取尽可能多的信息。</p><h2 id="3b6a" class="lm ln iq bd lo lp lq dn lr ls lt dp lu kh lv lw lx kl ly lz ma kp mb mc md iw bi translated">NLP的最佳库</h2><p id="6d62" class="pw-post-body-paragraph jw jx iq jy b jz me kb kc kd mf kf kg kh mg kj kk kl mh kn ko kp mi kr ks kt ij bi translated">首先，为了执行这些技术，必须导入和使用特定的库。或许，NLP最流行的库之一是自然语言工具包，称为<a class="ae lk" href="https://www.nltk.org/" rel="noopener ugc nofollow" target="_blank"> <strong class="jy ja"> NLTK </strong> </a>。这是最复杂的自然语言处理库之一。</p><p id="3417" class="pw-post-body-paragraph jw jx iq jy b jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ij bi translated">更新和更侧重于优化，<a class="ae lk" href="https://spacy.io/" rel="noopener ugc nofollow" target="_blank"> <strong class="jy ja"> spaCy </strong> </a>是另一个很好的选择，如果你想处理文本数据。这个库比NLTK快得多，也准确得多。</p><p id="9222" class="pw-post-body-paragraph jw jx iq jy b jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ij bi translated">处理文本数据的一种方法是通过称为<strong class="jy ja"> RegEx的正则表达式。</strong> Python有一个专门为正则表达式操作创建的内置包，更准确地说是<strong class="jy ja"/><a class="ae lk" href="https://docs.python.org/3/library/re.html" rel="noopener ugc nofollow" target="_blank"><strong class="jy ja">re</strong></a><strong class="jy ja">。</strong></p><p id="4782" class="pw-post-body-paragraph jw jx iq jy b jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ij bi translated"><a class="ae lk" href="https://scikit-learn.org/stable/index.html" rel="noopener ugc nofollow" target="_blank"><strong class="jy ja">Scikit-learn</strong></a><strong class="jy ja"/>是<strong class="jy ja"> </strong>使用最多的机器学习库之一。这不是NLP的专长，但是它有很多预处理数据的工具。除了用于在分类之前准备数据的许多方法之外，它还具有文本数据方面的专门工具(例如，CountVectorizer、TfidfVectorizer)。</p><h2 id="5400" class="lm ln iq bd lo lp lq dn lr ls lt dp lu kh lv lw lx kl ly lz ma kp mb mc md iw bi translated">文本数据的处理方法</h2><ul class=""><li id="9a37" class="mj mk iq jy b jz me kd mf kh ml kl mm kp mn kt mo mp mq mr bi translated"><strong class="jy ja">标记化</strong></li></ul><p id="d32b" class="pw-post-body-paragraph jw jx iq jy b jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ij bi translated">这是使用自然语言最基本的过程之一，几乎每个项目都有一个标记化步骤。记号化是将文本分割成记号的过程，记号表示更小的文本片段。通常，分隔符是空格“，”甚至一些标点符号如“.”。下面是一个使用NLTK库中的tokenize包进行标记化的例子。</p><pre class="kv kw kx ky gt ms mt mu mv aw mw bi"><span id="7686" class="lm ln iq mt b gy mx my l mz na">from nltk.tokenize import word_tokenize</span><span id="9363" class="lm ln iq mt b gy nb my l mz na">text = "This is an example of A phrase WIth lowercase and UPPERCASE"<br/>tokens = word_tokenize(text)</span><span id="1e73" class="lm ln iq mt b gy nb my l mz na">print(tokens)</span><span id="e6d0" class="lm ln iq mt b gy nb my l mz na"><strong class="mt ja">[‘This’, ‘is’, ‘an’, ‘example’, ‘of’, ‘A’, ‘phrase’, ‘WIth’, ‘lowercase’, ‘and’, ‘UPPERCASE’]</strong></span></pre><ul class=""><li id="c084" class="mj mk iq jy b jz ka kd ke kh nc kl nd kp ne kt mo mp mq mr bi translated"><strong class="jy ja">小写</strong></li></ul><p id="6aa2" class="pw-post-body-paragraph jw jx iq jy b jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ij bi translated">计算机将单词视为数字，因此同样的单词写成小写或大写会有不同的解释。因为在大多数情况下，每个句子都以大写字母开头，所以可能会出现某些问题。下面是一个如何使用内置Python方法将短语转换成小写字母的示例。</p><pre class="kv kw kx ky gt ms mt mu mv aw mw bi"><span id="92be" class="lm ln iq mt b gy mx my l mz na">text = "This is an example of A phrase WIth lowercase and UPPERCASE"<br/>text_lower = text.lower() </span><span id="a7a7" class="lm ln iq mt b gy nb my l mz na">print(text_lower)</span><span id="b6b6" class="lm ln iq mt b gy nb my l mz na"><strong class="mt ja">"this is an example of a phrase with lowercase and uppercase"</strong></span></pre><ul class=""><li id="691f" class="mj mk iq jy b jz ka kd ke kh nc kl nd kp ne kt mo mp mq mr bi translated"><strong class="jy ja">删除标点符号</strong></li></ul><p id="9014" class="pw-post-body-paragraph jw jx iq jy b jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ij bi translated">消除标点符号是最常用的文本预处理技术之一，因为它可以清除数据。在大多数情况下，标点符号是常见的，每个短语至少包含一个或两个。另一方面，在一些任务中，标点符号会带来相关信息。例如，在情绪分析中，许多暂停点<em class="ll">“…”</em>可能表示抑郁的态度，或者许多<em class="ll"> </em>感叹号<em class="ll">“！”可能暗示喜悦甚至愤怒。下面你可以看到两个例子，一个使用<em class="ll">字符串</em>模块，一个使用<em class="ll"> re </em>库。</em></p><pre class="kv kw kx ky gt ms mt mu mv aw mw bi"><span id="b358" class="lm ln iq mt b gy mx my l mz na"><strong class="mt ja"><em class="ll"># example 1</em></strong><br/>import string</span><span id="8d6c" class="lm ln iq mt b gy nb my l mz na">text = "This is an example; of a phrase with a lot, of punctuation?         marks!!"<br/>text_without_punctuations = text.translate(text.maketrans('', '', string.punctuation))</span><span id="3ec5" class="lm ln iq mt b gy nb my l mz na">print(text_without_punctuations)</span><span id="111b" class="lm ln iq mt b gy nb my l mz na"><strong class="mt ja">"This is an example of a phrase with a lot of punctuation marks"</strong></span><span id="b611" class="lm ln iq mt b gy nb my l mz na"><strong class="mt ja"><em class="ll"># example 2</em></strong><br/>import re</span><span id="ca0d" class="lm ln iq mt b gy nb my l mz na">text = "This is an example; of a phrase with a lot, of punctuation? marks!!"<br/>text_without_punctuations = re.sub(r'[^\w\s]','',text)</span><span id="ef68" class="lm ln iq mt b gy nb my l mz na">print(text_without_punctuations)</span><span id="d59f" class="lm ln iq mt b gy nb my l mz na"><strong class="mt ja">"This is an example of a phrase with a lot of punctuation marks"</strong></span></pre><ul class=""><li id="f467" class="mj mk iq jy b jz ka kd ke kh nc kl nd kp ne kt mo mp mq mr bi translated"><strong class="jy ja">删除多余的空格</strong></li></ul><p id="9e85" class="pw-post-body-paragraph jw jx iq jy b jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ij bi translated">正如我在上一点中解释的，一些短语只是由于错误或在转换空格中的一些字符后有额外的空格，所以，在没有添加信息的情况下，空格的数量会大大增加。和前面的例子一样，我将介绍两种删除多余空格的方法，一种只使用特定于<em class="ll">字符串的</em>方法，另一种使用<em class="ll"> re </em>库。</p><pre class="kv kw kx ky gt ms mt mu mv aw mw bi"><span id="059c" class="lm ln iq mt b gy mx my l mz na"><strong class="mt ja"><em class="ll"># example 1</em></strong><br/>text = "This is  an    example of a phrase    with a  lot of spaces!"<br/>text_without_extra_spaces = " ".join(text.split())</span><span id="fcf5" class="lm ln iq mt b gy nb my l mz na">print(text_without_extra_spaces)</span><span id="045c" class="lm ln iq mt b gy nb my l mz na"><strong class="mt ja">"This is an example of a phrase with a lot of spaces!"</strong></span><span id="21e8" class="lm ln iq mt b gy nb my l mz na"><strong class="mt ja"><em class="ll"># example 2</em></strong><br/>import re</span><span id="17ac" class="lm ln iq mt b gy nb my l mz na">text = "This is  an    example of a phrase    with a  lot of spaces!"<br/>text_without_extra_spaces = re.sub("\s\s+" , " ", text)</span><span id="97ec" class="lm ln iq mt b gy nb my l mz na">print(text_without_extra_spaces)</span><span id="3be7" class="lm ln iq mt b gy nb my l mz na"><strong class="mt ja">"This is an example of a phrase with a lot of spaces!"</strong></span></pre><ul class=""><li id="4161" class="mj mk iq jy b jz ka kd ke kh nc kl nd kp ne kt mo mp mq mr bi translated"><strong class="jy ja">删除数字</strong></li></ul><p id="794a" class="pw-post-body-paragraph jw jx iq jy b jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ij bi translated">除了数字本身，它们也可能出现在一些单词中，尤其是在在线消息或社交媒体帖子中。比如，“<em class="ll"> ME2 </em>或者“<em class="ll"> 4EVER </em>”对于人类来说分别相当于“<em class="ll">我也</em>”到“<em class="ll">永远</em>”，但是计算机看它们完全不一样。下面是一个例子，其中只有数字从文本中删除，下面是一个例子，其中数字和包含数字的单词都被删除。对于每种情况，我将给出两个例子，一个只使用特定于<em class="ll">字符串的</em>方法，另一个使用<em class="ll"> re </em>库。</p><pre class="kv kw kx ky gt ms mt mu mv aw mw bi"><span id="6af5" class="lm ln iq mt b gy mx my l mz na"><strong class="mt ja"><em class="ll"># example 1</em></strong><br/>text = "Th1s 1s 1 exampl3 of a phras3 conta1n1ng 12 d1g1ts and 11 numb3rs"<br/>text_without_numbers = ''.join([i for i in text if not i.isdigit()])</span><span id="311b" class="lm ln iq mt b gy nb my l mz na">print(text_without_numbers)</span><span id="4d13" class="lm ln iq mt b gy nb my l mz na"><strong class="mt ja">"Ths s exampl of a phras contanng dgts and numbrs"</strong></span><span id="6ba3" class="lm ln iq mt b gy nb my l mz na"><strong class="mt ja"><em class="ll"># example 2</em></strong><br/>import re</span><span id="96e9" class="lm ln iq mt b gy nb my l mz na">text = "Th1s 1s 1 exampl3 of a phras3 conta1n1ng 12 d1g1ts and 11 numb3rs"<br/>pattern = r'[0-9]'<br/>text_without_numbers = re.sub(pattern, '', text)</span><span id="cc26" class="lm ln iq mt b gy nb my l mz na">print(text_without_numbers)</span><span id="99e1" class="lm ln iq mt b gy nb my l mz na"><strong class="mt ja">"Ths s exampl of a phras contanng dgts and numbrs"</strong></span><span id="aa7e" class="lm ln iq mt b gy nb my l mz na"><strong class="mt ja"><em class="ll"># example 3</em></strong><br/>text = "Th1s 1s 1 exampl3 of a phras3 conta1n1ng 12 d1g1ts and 11 numb3rs"<br/>text_without_numbers = ' '.join(s for s in words.split() if not any(c.isdigit() for c in s))<br/><br/>print(text_without_numbers)</span><span id="567b" class="lm ln iq mt b gy nb my l mz na"><strong class="mt ja">"of a and"</strong></span><span id="555c" class="lm ln iq mt b gy nb my l mz na"><strong class="mt ja"><em class="ll"># example 4</em></strong><br/>import re</span><span id="7212" class="lm ln iq mt b gy nb my l mz na">text = "Th1s 1s 1 exampl3 of a phras3 conta1n1ng 12 d1g1ts and 11 numb3rs"<br/>text_without_numbers = re.sub(r'\w*\d\w*', '', text).strip()</span><span id="d509" class="lm ln iq mt b gy nb my l mz na">print(text_without_numbers)</span><span id="0250" class="lm ln iq mt b gy nb my l mz na"><strong class="mt ja">"of a and"</strong></span></pre><ul class=""><li id="ca56" class="mj mk iq jy b jz ka kd ke kh nc kl nd kp ne kt mo mp mq mr bi translated"><strong class="jy ja">删除停止字</strong></li></ul><p id="fbe4" class="pw-post-body-paragraph jw jx iq jy b jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ij bi translated">停用词是一种语言中最常见的词，它们存储在一个列表中，因为它们被频繁使用，所以它们不会带来任何信息。在stop的英文例子中，单词可以是:<em class="ll"> the </em>，<em class="ll"> as </em>，<em class="ll"> of，</em>等。下面是一个如何使用NLTK库中的<em class="ll">语料库</em>包删除停用词的例子。必须提到的是，NLTK包含23种语言的停用词列表，包括荷兰语、法语或西班牙语。在删除停用词之前，应该对文本进行标记化，以便可以过滤这些词。</p><pre class="kv kw kx ky gt ms mt mu mv aw mw bi"><span id="a897" class="lm ln iq mt b gy mx my l mz na">from nltk.tokenize import word_tokenize</span><span id="4463" class="lm ln iq mt b gy nb my l mz na">text = "This is an example of a phrase with a lot of stop words"<br/>tokens = word_tokenize(text)</span><span id="71e9" class="lm ln iq mt b gy nb my l mz na">for word in tokens:<br/>    if word not in stopwords.words("english"):<br/>        without_stop_words.append(word)<br/>text_without_stop_words = ' '.join(without_stop_words)</span><span id="cdc8" class="lm ln iq mt b gy nb my l mz na">print(text_without_stop_words)</span><span id="9ac2" class="lm ln iq mt b gy nb my l mz na"><strong class="mt ja">[‘This’, ‘example’, ‘phrase’, ‘lot’, ‘stop’, ‘words’]</strong></span></pre><p id="83c6" class="pw-post-body-paragraph jw jx iq jy b jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ij bi translated">除了数据清理之外，删除所有这些单词、空格或标点符号也可以缩短时间，因为数据量减少了。</p><ul class=""><li id="a268" class="mj mk iq jy b jz ka kd ke kh nc kl nd kp ne kt mo mp mq mr bi translated"><strong class="jy ja">扩张收缩</strong></li></ul><p id="a72d" class="pw-post-body-paragraph jw jx iq jy b jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ij bi translated">为了更好地理解和分析文本，计算机需要知道“<em class="ll">不是</em>”和“<em class="ll">不是</em>”是同一个意思。缩略词可以用字典来解决，字典里有缩略词和扩展词，比如<a class="ae lk" href="https://gist.github.com/nealrs/96342d8231b75cf4bb82" rel="noopener ugc nofollow" target="_blank"> this </a>。一种更方便的方法是使用Python库，如下面我介绍的<em class="ll">py constructions</em>或<em class="ll">constructions</em>。</p><pre class="kv kw kx ky gt ms mt mu mv aw mw bi"><span id="475b" class="lm ln iq mt b gy mx my l mz na">!pip install contractions</span><span id="53c1" class="lm ln iq mt b gy nb my l mz na">import contractions</span><span id="79be" class="lm ln iq mt b gy nb my l mz na">text = "This is an example of a phrase with contractions such as: I'll, he'd, and she's."</span><span id="aa5d" class="lm ln iq mt b gy nb my l mz na">expanded_words = []<br/>for word in text.split():<br/>    expanded_words.append(contractions.fix(word))<br/>text_without_contractions = ' '.join(expanded_words)</span><span id="1afc" class="lm ln iq mt b gy nb my l mz na">print(text_without_contractions)</span><span id="15e2" class="lm ln iq mt b gy nb my l mz na"><strong class="mt ja">"This is an example of a phrase with contractions such as: I will, he would, and she is."</strong></span></pre><p id="d25c" class="pw-post-body-paragraph jw jx iq jy b jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ij bi translated">最后，我们来解释一下什么是词干化和词干化，它们之间有什么区别。</p><ul class=""><li id="6327" class="mj mk iq jy b jz ka kd ke kh nc kl nd kp ne kt mo mp mq mr bi translated"><strong class="jy ja">术语化</strong></li></ul><p id="618d" class="pw-post-body-paragraph jw jx iq jy b jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ij bi translated">在词元化中，通过从单词中提取词元，将单词替换为根单词或具有相似上下文的单词。它的主要目标是减少一个词的相关屈折和派生形式。在NLTK库的<em class="ll"> WordNetLemmatizer </em>的帮助下，你可以看到下面的词汇化。</p><pre class="kv kw kx ky gt ms mt mu mv aw mw bi"><span id="20ec" class="lm ln iq mt b gy mx my l mz na">import nltk<br/>from nltk.stem import WordNetLemmatizer<br/>  <br/>wnl = WordNetLemmatizer()<br/>words = ['oxen', 'mice', 'cats', 'flying', 'singing', <br/>         'amazing', 'jumping', 'boring', 'went']<br/>lemmatized_words = []</span><span id="d24f" class="lm ln iq mt b gy nb my l mz na">for word in words:<br/>    lemmatized_words.append(wnl.lemmatize(word))</span><span id="87ed" class="lm ln iq mt b gy nb my l mz na">print(lemmatized_words)</span><span id="f35d" class="lm ln iq mt b gy nb my l mz na"><strong class="mt ja">[‘ox’, ‘mouse’, ‘cat’, ‘flying’, ‘singing’, ‘amazing’, ‘jumping’, ‘boring’, ‘went’]</strong></span></pre><ul class=""><li id="350a" class="mj mk iq jy b jz ka kd ke kh nc kl nd kp ne kt mo mp mq mr bi translated"><strong class="jy ja">词干</strong></li></ul><p id="9c43" class="pw-post-body-paragraph jw jx iq jy b jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ij bi translated">词干化将单词形式简化为(伪)词干，这意味着它只是消除了单词的最后几个字符，存在含义和拼写错误的风险。在NLTK库的<em class="ll"> PorterStemmer </em>的帮助下，你可以看到下面的词汇化。</p><pre class="kv kw kx ky gt ms mt mu mv aw mw bi"><span id="1262" class="lm ln iq mt b gy mx my l mz na">import nltk<br/>from nltk.stem import PorterStemmer</span><span id="2962" class="lm ln iq mt b gy nb my l mz na">ps = PorterStemmer()<br/>words = ['oxen', 'mice', 'cats', 'flying', 'singing', <br/>         'amazing', 'jumping', 'boring', 'went']<br/>stemmed_words = []</span><span id="83b7" class="lm ln iq mt b gy nb my l mz na">for word in words:<br/>    stemmed_words.append(ps.stem((word)))</span><span id="4b15" class="lm ln iq mt b gy nb my l mz na">print(stemmed_words)</span><span id="f751" class="lm ln iq mt b gy nb my l mz na"><strong class="mt ja">[‘oxen’, ‘mice’, ‘cat’, ‘fli’, ‘sing’, ‘amaz’, ‘jump’, ‘bore’, ‘went’]</strong></span></pre><p id="018f" class="pw-post-body-paragraph jw jx iq jy b jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ij bi translated">词汇化的一个优点是，与词干化不同，这种技术考虑了上下文和词性参数，因此具有更好的准确性。从给出的例子可以看出，变元化比词干化具有更精确的结果。另一方面，由于词干提取不考虑上下文，因此更容易实现，运行速度也更快。</p></div><div class="ab cl nf ng hu nh" role="separator"><span class="ni bw bk nj nk nl"/><span class="ni bw bk nj nk nl"/><span class="ni bw bk nj nk"/></div><div class="ij ik il im in"><p id="f3c1" class="pw-post-body-paragraph jw jx iq jy b jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ij bi translated">在一般情况下，尤其是文本情况下，数据的预处理对于所获得的结果是非常相关的。这一步有助于计算机更好地理解文本并从中获得更多信息。</p><p id="9900" class="pw-post-body-paragraph jw jx iq jy b jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ij bi translated">感谢阅读！希望你喜欢这篇文章！</p></div></div>    
</body>
</html>