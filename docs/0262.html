<html>
<head>
<title>Building a Spam Detector Using Python’s NTLK Package</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">使用Python的NTLK包构建垃圾邮件检测器</h1>
<blockquote>原文：<a href="https://pub.towardsai.net/building-spam-detector-using-pythons-ntlk-package-b118bbf2ed8e?source=collection_archive---------2-----------------------#2020-01-06">https://pub.towardsai.net/building-spam-detector-using-pythons-ntlk-package-b118bbf2ed8e?source=collection_archive---------2-----------------------#2020-01-06</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><figure class="ip iq gp gr ir is gh gi paragraph-image"><div role="button" tabindex="0" class="it iu di iv bf iw"><div class="gh gi io"><img src="../Images/670cf9d0737e5e9dfe7ba1126223517d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*_PVyaKFW_46TWPBx.jpeg"/></div></div></figure><div class=""/><div class=""><h2 id="0c55" class="pw-subtitle-paragraph jy ja jb bd b jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp dk translated">NTLK —自然语言工具包</h2></div><p id="4c2e" class="pw-post-body-paragraph kq kr jb ks b kt ku kc kv kw kx kf ky kz la lb lc ld le lf lg lh li lj lk ll ij bi translated">在这一部分中，我们将从头到尾演示如何在Python 3中构建一个非常简单的文本分类器。</p><p id="18b2" class="pw-post-body-paragraph kq kr jb ks b kt ku kc kv kw kx kf ky kz la lb lc ld le lf lg lh li lj lk ll ij bi translated">我们的目标是建立一个预测模型，确定一条短信是垃圾邮件还是火腿。</p><p id="fcb6" class="pw-post-body-paragraph kq kr jb ks b kt ku kc kv kw kx kf ky kz la lb lc ld le lf lg lh li lj lk ll ij bi translated">代码位置<a class="ae lm" href="https://github.com/BindhuVinodh/Spam-Detector" rel="noopener ugc nofollow" target="_blank">https://github.com/BindhuVinodh/Spam-Detector</a></p><div class="ip iq gp gr ir ln"><a href="https://github.com/BindhuVinodh/Spam-Detector" rel="noopener  ugc nofollow" target="_blank"><div class="lo ab fo"><div class="lp ab lq cl cj lr"><h2 class="bd jc gy z fp ls fr fs lt fu fw ja bi translated">/垃圾邮件检测器</h2></div><div class="lu l"><div class="lv l lw lx ly lu lz ix ln"/></div></div></a></div><pre class="ma mb mc md gt me mf mg mh aw mi bi"><span id="e78b" class="mj mk jb mf b gy ml mm l mn mo"><em class="mp"># This Python 3 environment comes with many helpful analytics libraries installed</em><br/><em class="mp"># It is defined by the kaggle/python docker image: </em><a class="ae lm" href="https://github.com/kaggle/docker-python" rel="noopener ugc nofollow" target="_blank"><em class="mp">https://github.com/kaggle/docker-python</em></a><br/><em class="mp"># For example, here's several helpful packages to load in </em></span><span id="e715" class="mj mk jb mf b gy mq mm l mn mo">import numpy as np <em class="mp"># linear algebra</em><br/>import pandas as pd <em class="mp"># data processing, CSV file I/O (e.g. pd.read_csv)</em></span><span id="1aa7" class="mj mk jb mf b gy mq mm l mn mo"><em class="mp"># Input data files are available in the "../input/" directory.</em><br/><em class="mp"># For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory</em></span><span id="5302" class="mj mk jb mf b gy mq mm l mn mo">import os<br/>print(os.listdir("../input"))</span><span id="1aaa" class="mj mk jb mf b gy mq mm l mn mo"><em class="mp"># Any results you write to the current directory are saved as output.</em></span><span id="4fdf" class="mj mk jb mf b gy mq mm l mn mo">['SMSSpamCollection', 'readme']</span></pre><h1 id="6fa9" class="mr mk jb bd ms mt mu mv mw mx my mz na kh nb ki nc kk nd kl ne kn nf ko ng nh bi translated">获取数据</h1><p id="9563" class="pw-post-body-paragraph kq kr jb ks b kt ni kc kv kw nj kf ky kz nk lb lc ld nl lf lg lh nm lj lk ll ij bi translated">在[2]中:</p><pre class="ma mb mc md gt me mf mg mh aw mi bi"><span id="beed" class="mj mk jb mf b gy ml mm l mn mo">message = [line.rstrip() for line <strong class="mf jc">in</strong> open('../input/SMSSpamCollection')]<br/>print(len(message))</span><span id="52b2" class="mj mk jb mf b gy mq mm l mn mo">5574</span></pre><p id="0301" class="pw-post-body-paragraph kq kr jb ks b kt ku kc kv kw kx kf ky kz la lb lc ld le lf lg lh li lj lk ll ij bi translated">在[3]中:</p><pre class="ma mb mc md gt me mf mg mh aw mi bi"><span id="c14b" class="mj mk jb mf b gy ml mm l mn mo">for message_no,message <strong class="mf jc">in</strong> enumerate(message[:10]):<br/>    print(message_no,message)<br/>    print('<strong class="mf jc">\n</strong>')</span><span id="0848" class="mj mk jb mf b gy mq mm l mn mo">0 ham	Go until jurong point, crazy.. Available only in bugis n great world la e buffet... Cine there got amore wat...<br/></span><span id="aff7" class="mj mk jb mf b gy mq mm l mn mo">1 ham	Ok lar... Joking wif u oni...<br/></span><span id="02d5" class="mj mk jb mf b gy mq mm l mn mo">2 spam	Free entry in 2 a wkly comp to win FA Cup final tkts 21st May 2005. Text FA to 87121 to receive entry question(std txt rate)T&amp;C's apply 08452810075over18's<br/></span><span id="7809" class="mj mk jb mf b gy mq mm l mn mo">3 ham	U dun say so early hor... U c already then say...<br/></span><span id="0ca8" class="mj mk jb mf b gy mq mm l mn mo">4 ham	Nah I don't think he goes to usf, he lives around here though<br/></span><span id="0add" class="mj mk jb mf b gy mq mm l mn mo">5 spam	FreeMsg Hey there darling it's been 3 week's now and no word back! I'd like some fun you up for it still? Tb ok! XxX std chgs to send, £1.50 to rcv<br/></span><span id="1c05" class="mj mk jb mf b gy mq mm l mn mo">6 ham	Even my brother is not like to speak with me. They treat me like aids patent.<br/></span><span id="bafd" class="mj mk jb mf b gy mq mm l mn mo">7 ham	As per your request 'Melle Melle (Oru Minnaminunginte Nurungu Vettam)' has been set as your callertune for all Callers. Press *9 to copy your friends Callertune<br/></span><span id="2bf8" class="mj mk jb mf b gy mq mm l mn mo">8 spam	WINNER!! As a valued network customer you have been selected to receivea £900 prize reward! To claim call 09061701461. Claim code KL341. Valid 12 hours only.<br/></span><span id="b445" class="mj mk jb mf b gy mq mm l mn mo">9 spam	Had your mobile 11 months or more? U R entitled to Update to the latest colour mobiles with camera for Free! Call The Mobile Update Co FREE on 08002986030</span></pre><p id="9cf9" class="pw-post-body-paragraph kq kr jb ks b kt ku kc kv kw kx kf ky kz la lb lc ld le lf lg lh li lj lk ll ij bi translated">在[4]中:</p><pre class="ma mb mc md gt me mf mg mh aw mi bi"><span id="ca39" class="mj mk jb mf b gy ml mm l mn mo">import pandas as pd</span></pre><p id="e0be" class="pw-post-body-paragraph kq kr jb ks b kt ku kc kv kw kx kf ky kz la lb lc ld le lf lg lh li lj lk ll ij bi translated">在[5]中:</p><pre class="ma mb mc md gt me mf mg mh aw mi bi"><span id="4fbc" class="mj mk jb mf b gy ml mm l mn mo">message=pd.read_csv('../input/SMSSpamCollection',sep='<strong class="mf jc">\t</strong>',names=["labels","message"])<br/>message.head()</span></pre><p id="abf7" class="pw-post-body-paragraph kq kr jb ks b kt ku kc kv kw kx kf ky kz la lb lc ld le lf lg lh li lj lk ll ij bi translated">Out[5]:</p><p id="a7a0" class="pw-post-body-paragraph kq kr jb ks b kt ku kc kv kw kx kf ky kz la lb lc ld le lf lg lh li lj lk ll ij bi translated">labelsmessage0hamGo直到句容点，疯了..只有…1hamOk lar…开玩笑的wif U oni…2 spam免费参加2个星期的比赛赢得足总杯fina…3 hamu don说这么早hor… U c已经那么说了…4hamNah我不认为他去usf，他住在aro…</p><h1 id="4a59" class="mr mk jb bd ms mt mu mv mw mx my mz na kh nb ki nc kk nd kl ne kn nf ko ng nh bi translated">探索性数据分析</h1><p id="c016" class="pw-post-body-paragraph kq kr jb ks b kt ni kc kv kw nj kf ky kz nk lb lc ld nl lf lg lh nm lj lk ll ij bi translated">在[6]中:</p><pre class="ma mb mc md gt me mf mg mh aw mi bi"><span id="d0b8" class="mj mk jb mf b gy ml mm l mn mo">message.describe()</span></pre><p id="f4db" class="pw-post-body-paragraph kq kr jb ks b kt ku kc kv kw kx kf ky kz la lb lc ld le lf lg lh li lj lk ll ij bi translated">Out[6]:</p><p id="f500" class="pw-post-body-paragraph kq kr jb ks b kt ku kc kv kw kx kf ky kz la lb lc ld le lf lg lh li lj lk ll ij bi translated">labelsmessagecount 55725572 unique 25169topham抱歉，我稍后再打电话给482530</p><p id="dbcb" class="pw-post-body-paragraph kq kr jb ks b kt ku kc kv kw kx kf ky kz la lb lc ld le lf lg lh li lj lk ll ij bi translated">在[7]中:</p><pre class="ma mb mc md gt me mf mg mh aw mi bi"><span id="045b" class="mj mk jb mf b gy ml mm l mn mo">message.groupby('labels').describe()</span></pre><p id="4f93" class="pw-post-body-paragraph kq kr jb ks b kt ku kc kv kw kx kf ky kz la lb lc ld le lf lg lh li lj lk ll ij bi translated">Out[7]:</p><p id="21c9" class="pw-post-body-paragraph kq kr jb ks b kt ku kc kv kw kx kf ky kz la lb lc ld le lf lg lh li lj lk ll ij bi translated">message count uniquetopfreqlabelsham 48254516对不起，我稍后再打电话30 spam 747653请打电话给我们的客户服务代表</p><p id="f546" class="pw-post-body-paragraph kq kr jb ks b kt ku kc kv kw kx kf ky kz la lb lc ld le lf lg lh li lj lk ll ij bi translated">随着我们继续分析，我们希望开始考虑我们将要使用的功能。这符合<a class="ae lm" href="https://en.wikipedia.org/wiki/Feature_engineering" rel="noopener ugc nofollow" target="_blank">特征工程</a>的总体思路。您对数据的领域了解越多，您就越有能力从数据中设计出更多功能。一般来说，特征工程是垃圾邮件检测的一个非常大的部分。我鼓励你仔细阅读这个话题！</p><p id="fe88" class="pw-post-body-paragraph kq kr jb ks b kt ku kc kv kw kx kf ky kz la lb lc ld le lf lg lh li lj lk ll ij bi translated">让我们创建一个新列来检测短信有多长:</p><p id="45f4" class="pw-post-body-paragraph kq kr jb ks b kt ku kc kv kw kx kf ky kz la lb lc ld le lf lg lh li lj lk ll ij bi translated">在[8]中:</p><pre class="ma mb mc md gt me mf mg mh aw mi bi"><span id="3d5e" class="mj mk jb mf b gy ml mm l mn mo">message['length']=message['message'].apply(len)<br/>message.head()</span></pre><p id="dbb9" class="pw-post-body-paragraph kq kr jb ks b kt ku kc kv kw kx kf ky kz la lb lc ld le lf lg lh li lj lk ll ij bi translated">Out[8]:</p><p id="2075" class="pw-post-body-paragraph kq kr jb ks b kt ku kc kv kw kx kf ky kz la lb lc ld le lf lg lh li lj lk ll ij bi translated">labelsmessagelength0hamGo直到句容点，疯了..只有…1111hamOk lar…开玩笑的wif U oni…292 spam免费参加每周两次的比赛赢得足总杯fina…1553hamU dun这么早说… U c已经说了…494hamNah我不认为他去usf，他住在aro…61</p><h1 id="ea6c" class="mr mk jb bd ms mt mu mv mw mx my mz na kh nb ki nc kk nd kl ne kn nf ko ng nh bi translated">数据可视化</h1><p id="c376" class="pw-post-body-paragraph kq kr jb ks b kt ni kc kv kw nj kf ky kz nk lb lc ld nl lf lg lh nm lj lk ll ij bi translated">让我们想象一下！让我们做进口:</p><p id="498d" class="pw-post-body-paragraph kq kr jb ks b kt ku kc kv kw kx kf ky kz la lb lc ld le lf lg lh li lj lk ll ij bi translated">在[9]中:</p><pre class="ma mb mc md gt me mf mg mh aw mi bi"><span id="c33c" class="mj mk jb mf b gy ml mm l mn mo">import matplotlib.pyplot as plt<br/>import seaborn as sns<br/>%matplotlib inline</span></pre><p id="776d" class="pw-post-body-paragraph kq kr jb ks b kt ku kc kv kw kx kf ky kz la lb lc ld le lf lg lh li lj lk ll ij bi translated">在[10]中:</p><pre class="ma mb mc md gt me mf mg mh aw mi bi"><span id="9004" class="mj mk jb mf b gy ml mm l mn mo">message['length'].plot(bins=50,kind='hist')</span></pre><p id="d05b" class="pw-post-body-paragraph kq kr jb ks b kt ku kc kv kw kx kf ky kz la lb lc ld le lf lg lh li lj lk ll ij bi translated">Out[10]:</p><pre class="ma mb mc md gt me mf mg mh aw mi bi"><span id="380d" class="mj mk jb mf b gy ml mm l mn mo">&lt;matplotlib.axes._subplots.AxesSubplot at 0x7fdf3c7d92e8&gt;</span></pre><figure class="ma mb mc md gt is gh gi paragraph-image"><div class="gh gi nn"><img src="../Images/3dfa96f23475e76ccd85306ed21a0f32.png" data-original-src="https://miro.medium.com/v2/resize:fit:796/format:webp/0*CtEEKW92k4kEXuAa.png"/></div></figure><p id="019c" class="pw-post-body-paragraph kq kr jb ks b kt ku kc kv kw kx kf ky kz la lb lc ld le lf lg lh li lj lk ll ij bi translated">在[11]中:</p><pre class="ma mb mc md gt me mf mg mh aw mi bi"><span id="b37c" class="mj mk jb mf b gy ml mm l mn mo">message.length.describe()</span></pre><p id="d24e" class="pw-post-body-paragraph kq kr jb ks b kt ku kc kv kw kx kf ky kz la lb lc ld le lf lg lh li lj lk ll ij bi translated">Out[11]:</p><pre class="ma mb mc md gt me mf mg mh aw mi bi"><span id="d486" class="mj mk jb mf b gy ml mm l mn mo">count    5572.000000<br/>mean       80.489950<br/>std        59.942907<br/>min         2.000000<br/>25%        36.000000<br/>50%        62.000000<br/>75%       122.000000<br/>max       910.000000<br/>Name: length, dtype: float64</span></pre><p id="ac07" class="pw-post-body-paragraph kq kr jb ks b kt ku kc kv kw kx kf ky kz la lb lc ld le lf lg lh li lj lk ll ij bi translated">哇哦。910个字符，让我们使用掩码来查找此消息:</p><p id="1f01" class="pw-post-body-paragraph kq kr jb ks b kt ku kc kv kw kx kf ky kz la lb lc ld le lf lg lh li lj lk ll ij bi translated">在[12]中:</p><pre class="ma mb mc md gt me mf mg mh aw mi bi"><span id="3714" class="mj mk jb mf b gy ml mm l mn mo">message[message['length']==910]['message'].iloc[0]</span></pre><p id="4bda" class="pw-post-body-paragraph kq kr jb ks b kt ku kc kv kw kx kf ky kz la lb lc ld le lf lg lh li lj lk ll ij bi translated">Out[12]:</p><pre class="ma mb mc md gt me mf mg mh aw mi bi"><span id="589a" class="mj mk jb mf b gy ml mm l mn mo">"For me the love should start with attraction.i should feel that I need her every time around me.she should be the first thing which comes in my thoughts.I would start the day and end it with her.she should be there every time I dream.love will be then when my every breath has her name.my life should happen around her.my life will be named to her.I would cry for her.will give all my happiness and take all her sorrows.I will be ready to fight with anyone for her.I will be in love when I will be doing the craziest things for her.love will be when I don't have to proove anyone that my girl is the most beautiful lady on the whole planet.I will always be singing praises for her.love will be when I start up making chicken curry and end up makiing sambar.life will be the most beautiful then.will get every morning and thank god for the day because she is with me.I would like to say a lot..will tell later.."</span></pre><p id="b43e" class="pw-post-body-paragraph kq kr jb ks b kt ku kc kv kw kx kf ky kz la lb lc ld le lf lg lh li lj lk ll ij bi translated">看起来我们有某种罗密欧发送短信！但是让我们把注意力放回到尝试看看消息长度是否是ham和spam之间的区别特征上</p><h1 id="e6df" class="mr mk jb bd ms mt mu mv mw mx my mz na kh nb ki nc kk nd kl ne kn nf ko ng nh bi translated">文本预处理</h1><p id="4afa" class="pw-post-body-paragraph kq kr jb ks b kt ni kc kv kw nj kf ky kz nk lb lc ld nl lf lg lh nm lj lk ll ij bi translated">我们的数据的主要问题是它们都是文本格式(字符串)。到目前为止，我们所学的分类算法需要某种数字特征向量来执行分类任务。实际上有许多方法可以将语料库转换成矢量格式。最简单的是<a class="ae lm" href="http://en.wikipedia.org/wiki/Bag-of-words_model" rel="noopener ugc nofollow" target="_blank">单词袋</a>方法，文本中的每个唯一单词都用一个数字表示。</p><p id="43bb" class="pw-post-body-paragraph kq kr jb ks b kt ku kc kv kw kx kf ky kz la lb lc ld le lf lg lh li lj lk ll ij bi translated">在这一节中，我们将把原始消息(字符序列)转换成向量(数字序列)。</p><p id="ba47" class="pw-post-body-paragraph kq kr jb ks b kt ku kc kv kw kx kf ky kz la lb lc ld le lf lg lh li lj lk ll ij bi translated">作为第一步，让我们编写一个函数，将一条消息拆分成各个单词并返回一个列表。我们还将删除非常常见的单词，如“the”、“a”等..).为此，我们将利用NLTK库。它几乎是Python中处理文本的标准库，有很多有用的特性。这里我们只使用一些基本的。</p><p id="9bd3" class="pw-post-body-paragraph kq kr jb ks b kt ku kc kv kw kx kf ky kz la lb lc ld le lf lg lh li lj lk ll ij bi translated">让我们创建一个函数来处理消息列中的字符串，然后我们可以在pandas中使用<strong class="ks jc"> apply() </strong>来处理数据帧中的所有文本。</p><p id="c41c" class="pw-post-body-paragraph kq kr jb ks b kt ku kc kv kw kx kf ky kz la lb lc ld le lf lg lh li lj lk ll ij bi translated">首先去掉标点符号。我们可以利用Python内置的<strong class="ks jc">字符串</strong>库来快速获得所有可能的标点符号列表:</p><p id="e3fc" class="pw-post-body-paragraph kq kr jb ks b kt ku kc kv kw kx kf ky kz la lb lc ld le lf lg lh li lj lk ll ij bi translated">在[13]中:</p><pre class="ma mb mc md gt me mf mg mh aw mi bi"><span id="1faa" class="mj mk jb mf b gy ml mm l mn mo">import string<br/>mess = 'sample message!...'<br/>nopunc=[char for char <strong class="mf jc">in</strong> mess if char <strong class="mf jc">not</strong> <strong class="mf jc">in</strong> string.punctuation]<br/>nopunc=''.join(nopunc)<br/>print(nopunc)</span><span id="e54a" class="mj mk jb mf b gy mq mm l mn mo">sample message</span></pre><p id="8603" class="pw-post-body-paragraph kq kr jb ks b kt ku kc kv kw kx kf ky kz la lb lc ld le lf lg lh li lj lk ll ij bi translated">在[14]中:</p><pre class="ma mb mc md gt me mf mg mh aw mi bi"><span id="98b5" class="mj mk jb mf b gy ml mm l mn mo">from nltk.corpus import stopwords<br/>stopwords.words('english')[0:10]</span></pre><p id="550d" class="pw-post-body-paragraph kq kr jb ks b kt ku kc kv kw kx kf ky kz la lb lc ld le lf lg lh li lj lk ll ij bi translated">Out[14]:</p><pre class="ma mb mc md gt me mf mg mh aw mi bi"><span id="ada9" class="mj mk jb mf b gy ml mm l mn mo">['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', "you're"]</span></pre><p id="6e62" class="pw-post-body-paragraph kq kr jb ks b kt ku kc kv kw kx kf ky kz la lb lc ld le lf lg lh li lj lk ll ij bi translated">在[15]中:</p><pre class="ma mb mc md gt me mf mg mh aw mi bi"><span id="8661" class="mj mk jb mf b gy ml mm l mn mo">nopunc.split()</span></pre><p id="b237" class="pw-post-body-paragraph kq kr jb ks b kt ku kc kv kw kx kf ky kz la lb lc ld le lf lg lh li lj lk ll ij bi translated">Out[15]:</p><pre class="ma mb mc md gt me mf mg mh aw mi bi"><span id="5934" class="mj mk jb mf b gy ml mm l mn mo">['sample', 'message']</span></pre><p id="a90c" class="pw-post-body-paragraph kq kr jb ks b kt ku kc kv kw kx kf ky kz la lb lc ld le lf lg lh li lj lk ll ij bi translated">在[16]中:</p><pre class="ma mb mc md gt me mf mg mh aw mi bi"><span id="3802" class="mj mk jb mf b gy ml mm l mn mo">clean_mess=[word for word <strong class="mf jc">in</strong> nopunc.split() if word.lower() <strong class="mf jc">not</strong> <strong class="mf jc">in</strong> stopwords.words('english')]</span></pre><p id="c035" class="pw-post-body-paragraph kq kr jb ks b kt ku kc kv kw kx kf ky kz la lb lc ld le lf lg lh li lj lk ll ij bi translated">在[17]中:</p><pre class="ma mb mc md gt me mf mg mh aw mi bi"><span id="20d4" class="mj mk jb mf b gy ml mm l mn mo">clean_mess</span></pre><p id="f70d" class="pw-post-body-paragraph kq kr jb ks b kt ku kc kv kw kx kf ky kz la lb lc ld le lf lg lh li lj lk ll ij bi translated">Out[17]:</p><pre class="ma mb mc md gt me mf mg mh aw mi bi"><span id="3060" class="mj mk jb mf b gy ml mm l mn mo">['sample', 'message']</span></pre><p id="3920" class="pw-post-body-paragraph kq kr jb ks b kt ku kc kv kw kx kf ky kz la lb lc ld le lf lg lh li lj lk ll ij bi translated">现在，让我们将这两者放在一个函数中，稍后将其应用于我们的数据帧:</p><p id="b7d9" class="pw-post-body-paragraph kq kr jb ks b kt ku kc kv kw kx kf ky kz la lb lc ld le lf lg lh li lj lk ll ij bi translated">在[18]中:</p><pre class="ma mb mc md gt me mf mg mh aw mi bi"><span id="2e64" class="mj mk jb mf b gy ml mm l mn mo">def text_process(mess):<br/>    nopunc =[char for char <strong class="mf jc">in</strong> mess if char <strong class="mf jc">not</strong> <strong class="mf jc">in</strong> string.punctuation]<br/>    nopunc=''.join(nopunc)<br/>    return [word for word <strong class="mf jc">in</strong> nopunc.split() if word.lower() <strong class="mf jc">not</strong> <strong class="mf jc">in</strong> stopwords.words('english')]</span></pre><p id="9fa7" class="pw-post-body-paragraph kq kr jb ks b kt ku kc kv kw kx kf ky kz la lb lc ld le lf lg lh li lj lk ll ij bi translated">这是原始数据帧:</p><p id="102b" class="pw-post-body-paragraph kq kr jb ks b kt ku kc kv kw kx kf ky kz la lb lc ld le lf lg lh li lj lk ll ij bi translated">在[19]中:</p><pre class="ma mb mc md gt me mf mg mh aw mi bi"><span id="e99d" class="mj mk jb mf b gy ml mm l mn mo">message.head()</span></pre><p id="c9d3" class="pw-post-body-paragraph kq kr jb ks b kt ku kc kv kw kx kf ky kz la lb lc ld le lf lg lh li lj lk ll ij bi translated">Out[19]:</p><p id="d21e" class="pw-post-body-paragraph kq kr jb ks b kt ku kc kv kw kx kf ky kz la lb lc ld le lf lg lh li lj lk ll ij bi translated">labelsmessagelength0hamGo直到句容点，疯了..只有…1111hamOk lar…开玩笑的wif U oni…292 spam免费参加每周两次的比赛赢得足总杯fina…1553hamU dun这么早说… U c已经说了…494hamNah我不认为他去usf，他住在aro…61</p><p id="e67c" class="pw-post-body-paragraph kq kr jb ks b kt ku kc kv kw kx kf ky kz la lb lc ld le lf lg lh li lj lk ll ij bi translated">现在让我们“标记”这些消息。标记化只是用来描述将普通文本字符串转换成一系列标记(我们实际需要的单词)的过程的术语。</p><p id="a8b4" class="pw-post-body-paragraph kq kr jb ks b kt ku kc kv kw kx kf ky kz la lb lc ld le lf lg lh li lj lk ll ij bi translated">让我们来看看第列的输出示例:</p><p id="db0e" class="pw-post-body-paragraph kq kr jb ks b kt ku kc kv kw kx kf ky kz la lb lc ld le lf lg lh li lj lk ll ij bi translated"><strong class="ks jc">注意:</strong>对于我们没有考虑到的或者不是Unicode编码的符号(比如英镑符号)，我们可能会得到一些警告或错误</p><p id="5323" class="pw-post-body-paragraph kq kr jb ks b kt ku kc kv kw kx kf ky kz la lb lc ld le lf lg lh li lj lk ll ij bi translated">在[20]中:</p><pre class="ma mb mc md gt me mf mg mh aw mi bi"><span id="5235" class="mj mk jb mf b gy ml mm l mn mo">message['message'].head(5).apply(text_process)</span></pre><p id="93b1" class="pw-post-body-paragraph kq kr jb ks b kt ku kc kv kw kx kf ky kz la lb lc ld le lf lg lh li lj lk ll ij bi translated">Out[20]:</p><pre class="ma mb mc md gt me mf mg mh aw mi bi"><span id="cb33" class="mj mk jb mf b gy ml mm l mn mo">0    [Go, jurong, point, crazy, Available, bugis, n...<br/>1                       [Ok, lar, Joking, wif, u, oni]<br/>2    [Free, entry, 2, wkly, comp, win, FA, Cup, fin...<br/>3        [U, dun, say, early, hor, U, c, already, say]<br/>4    [Nah, dont, think, goes, usf, lives, around, t...<br/>Name: message, dtype: object</span></pre><p id="b770" class="pw-post-body-paragraph kq kr jb ks b kt ku kc kv kw kx kf ky kz la lb lc ld le lf lg lh li lj lk ll ij bi translated">在[21]中:</p><pre class="ma mb mc md gt me mf mg mh aw mi bi"><span id="660e" class="mj mk jb mf b gy ml mm l mn mo">message.head()</span></pre><p id="c59a" class="pw-post-body-paragraph kq kr jb ks b kt ku kc kv kw kx kf ky kz la lb lc ld le lf lg lh li lj lk ll ij bi translated">Out[21]:</p><p id="e51d" class="pw-post-body-paragraph kq kr jb ks b kt ku kc kv kw kx kf ky kz la lb lc ld le lf lg lh li lj lk ll ij bi translated">labelsmessagelength0hamGo直到句容点，疯了..只有…1111hamOk lar…开玩笑的wif U oni…292 spam免费参加每周两次的比赛赢得足总杯fina…1553hamU dun这么早说… U c已经说了…494hamNah我不认为他去usf，他住在aro…61</p><h1 id="1c98" class="mr mk jb bd ms mt mu mv mw mx my mz na kh nb ki nc kk nd kl ne kn nf ko ng nh bi translated">持续正常化</h1><p id="d9b9" class="pw-post-body-paragraph kq kr jb ks b kt ni kc kv kw nj kf ky kz nk lb lc ld nl lf lg lh nm lj lk ll ij bi translated">有很多方法可以继续规范化这个文本。如<a class="ae lm" href="https://en.wikipedia.org/wiki/Stemming" rel="noopener ugc nofollow" target="_blank">词干</a>或通过<a class="ae lm" href="http://www.nltk.org/book/ch05.html" rel="noopener ugc nofollow" target="_blank">词性</a>区分。</p><p id="f5bf" class="pw-post-body-paragraph kq kr jb ks b kt ku kc kv kw kx kf ky kz la lb lc ld le lf lg lh li lj lk ll ij bi translated">NLTK有许多内置工具和关于这些方法的大量文档。有时，由于许多人倾向于使用缩写或速记，它们对短信不太适用，例如:</p><pre class="ma mb mc md gt me mf mg mh aw mi bi"><span id="cc15" class="mj mk jb mf b gy ml mm l mn mo">'Nah dawg, IDK! Wut time u headin to da club?'</span></pre><p id="46a1" class="pw-post-body-paragraph kq kr jb ks b kt ku kc kv kw kx kf ky kz la lb lc ld le lf lg lh li lj lk ll ij bi translated">对抗</p><pre class="ma mb mc md gt me mf mg mh aw mi bi"><span id="0bfb" class="mj mk jb mf b gy ml mm l mn mo">'No dog, I don't know! What time are you heading to the club?'</span></pre><p id="afe3" class="pw-post-body-paragraph kq kr jb ks b kt ku kc kv kw kx kf ky kz la lb lc ld le lf lg lh li lj lk ll ij bi translated">一些文本规范化方法在使用这种类型的速记时会遇到麻烦，所以我将让您通过<a class="ae lm" href="http://www.nltk.org/book/" rel="noopener ugc nofollow" target="_blank"> NLTK在线书籍</a>来探索那些更高级的方法。</p><p id="8e45" class="pw-post-body-paragraph kq kr jb ks b kt ku kc kv kw kx kf ky kz la lb lc ld le lf lg lh li lj lk ll ij bi translated">现在，我们将只关注使用我们所拥有的来将我们的单词列表转换成SciKit-Learn可以使用的实际向量。</p><h1 id="c371" class="mr mk jb bd ms mt mu mv mw mx my mz na kh nb ki nc kk nd kl ne kn nf ko ng nh bi translated">…向量化…</h1><p id="afe0" class="pw-post-body-paragraph kq kr jb ks b kt ni kc kv kw nj kf ky kz nk lb lc ld nl lf lg lh nm lj lk ll ij bi translated">目前，我们有令牌列表形式的消息(也称为<a class="ae lm" href="http://nlp.stanford.edu/IR-book/html/htmledition/stemming-and-lemmatization-1.html" rel="noopener ugc nofollow" target="_blank">引理</a>)，现在我们需要将这些消息中的每一条转换为SciKit Learn的算法模型可以处理的向量。</p><p id="e678" class="pw-post-body-paragraph kq kr jb ks b kt ku kc kv kw kx kf ky kz la lb lc ld le lf lg lh li lj lk ll ij bi translated">现在，我们将把每条消息转换成机器学习模型可以理解的向量，这些消息用上面的一系列记号(词条)表示。</p><p id="fd68" class="pw-post-body-paragraph kq kr jb ks b kt ku kc kv kw kx kf ky kz la lb lc ld le lf lg lh li lj lk ll ij bi translated">我们将使用单词袋模型分三步完成:</p><ol class=""><li id="f598" class="no np jb ks b kt ku kw kx kz nq ld nr lh ns ll nt nu nv nw bi translated">计算一个单词在每条消息中出现的次数(称为词频)</li><li id="8a2d" class="no np jb ks b kt nx kw ny kz nz ld oa lh ob ll nt nu nv nw bi translated">对计数进行加权，以使频繁出现的令牌获得较低的权重(逆文档频率)</li><li id="a4f3" class="no np jb ks b kt nx kw ny kz nz ld oa lh ob ll nt nu nv nw bi translated">将向量归一化为单位长度，以从原始文本长度中提取(L2范数)</li></ol><p id="7c37" class="pw-post-body-paragraph kq kr jb ks b kt ku kc kv kw kx kf ky kz la lb lc ld le lf lg lh li lj lk ll ij bi translated">让我们开始第一步:</p><p id="8914" class="pw-post-body-paragraph kq kr jb ks b kt ku kc kv kw kx kf ky kz la lb lc ld le lf lg lh li lj lk ll ij bi translated">每个向量将具有与SMS语料库中的唯一单词一样多的维度。我们将首先使用SciKit Learn的<strong class="ks jc">计数矢量器</strong>。这个模型将把一组文本文档转换成一个令牌计数矩阵。</p><p id="7a81" class="pw-post-body-paragraph kq kr jb ks b kt ku kc kv kw kx kf ky kz la lb lc ld le lf lg lh li lj lk ll ij bi translated">我们可以把它想象成一个二维矩阵。其中一维是整个词汇表(每个单词一行)，另一维是实际的文档，在本例中，每个文本消息一列。</p><p id="eee5" class="pw-post-body-paragraph kq kr jb ks b kt ku kc kv kw kx kf ky kz la lb lc ld le lf lg lh li lj lk ll ij bi translated">例如:</p><p id="60bb" class="pw-post-body-paragraph kq kr jb ks b kt ku kc kv kw kx kf ky kz la lb lc ld le lf lg lh li lj lk ll ij bi translated"><table border="“1“"/></p><p id="052f" class="pw-post-body-paragraph kq kr jb ks b kt ku kc kv kw kx kf ky kz la lb lc ld le lf lg lh li lj lk ll ij bi translated">消息1消息2 …消息N </p><p id="12b9" class="pw-post-body-paragraph kq kr jb ks b kt ku kc kv kw kx kf ky kz la lb lc ld le lf lg lh li lj lk ll ij bi translated"><strong class="ks jc">字1计数</strong> 01…0 &lt; /tr &gt;</p><p id="b22c" class="pw-post-body-paragraph kq kr jb ks b kt ku kc kv kw kx kf ky kz la lb lc ld le lf lg lh li lj lk ll ij bi translated"><strong class="ks jc">字2计数</strong> 00…0 &lt; /tr &gt;</p><p id="5605" class="pw-post-body-paragraph kq kr jb ks b kt ku kc kv kw kx kf ky kz la lb lc ld le lf lg lh li lj lk ll ij bi translated"><strong class="ks jc"> … </strong> 12…0 &lt; /tr &gt;</p><p id="4f59" class="pw-post-body-paragraph kq kr jb ks b kt ku kc kv kw kx kf ky kz la lb lc ld le lf lg lh li lj lk ll ij bi translated"><strong class="ks jc">字数N计数</strong>01…1&lt;/tr&gt;T30】/表&gt;</p><p id="ca69" class="pw-post-body-paragraph kq kr jb ks b kt ku kc kv kw kx kf ky kz la lb lc ld le lf lg lh li lj lk ll ij bi translated">由于有如此多的消息，我们可以预期该单词在该文档中的出现会有很多零计数。因此，SciKit Learn将输出一个<a class="ae lm" href="https://en.wikipedia.org/wiki/Sparse_matrix" rel="noopener ugc nofollow" target="_blank">稀疏矩阵</a>。</p><p id="37ca" class="pw-post-body-paragraph kq kr jb ks b kt ku kc kv kw kx kf ky kz la lb lc ld le lf lg lh li lj lk ll ij bi translated">在[22]中:</p><pre class="ma mb mc md gt me mf mg mh aw mi bi"><span id="0741" class="mj mk jb mf b gy ml mm l mn mo">from sklearn.feature_extraction.text import CountVectorizer</span></pre><p id="83a6" class="pw-post-body-paragraph kq kr jb ks b kt ku kc kv kw kx kf ky kz la lb lc ld le lf lg lh li lj lk ll ij bi translated">让我们以一条短信为例，将它的字数统计作为一个向量，使用我们新的<code class="fe oc od oe mf b">bow_transformer</code>:</p><p id="6423" class="pw-post-body-paragraph kq kr jb ks b kt ku kc kv kw kx kf ky kz la lb lc ld le lf lg lh li lj lk ll ij bi translated">在[23]中:</p><pre class="ma mb mc md gt me mf mg mh aw mi bi"><span id="c3d5" class="mj mk jb mf b gy ml mm l mn mo">bow_transformer = CountVectorizer(analyzer=text_process).fit(message['message'])<br/>print(len(bow_transformer.vocabulary_))</span><span id="e685" class="mj mk jb mf b gy mq mm l mn mo">11425</span></pre><p id="c099" class="pw-post-body-paragraph kq kr jb ks b kt ku kc kv kw kx kf ky kz la lb lc ld le lf lg lh li lj lk ll ij bi translated">在[24]中:</p><pre class="ma mb mc md gt me mf mg mh aw mi bi"><span id="f903" class="mj mk jb mf b gy ml mm l mn mo">message4=message['message'][3]<br/>print(message4)</span><span id="1267" class="mj mk jb mf b gy mq mm l mn mo">U dun say so early hor... U c already then say...</span></pre><p id="35c2" class="pw-post-body-paragraph kq kr jb ks b kt ku kc kv kw kx kf ky kz la lb lc ld le lf lg lh li lj lk ll ij bi translated">现在让我们看看它的矢量表示:</p><p id="ff89" class="pw-post-body-paragraph kq kr jb ks b kt ku kc kv kw kx kf ky kz la lb lc ld le lf lg lh li lj lk ll ij bi translated">在[25]中:</p><pre class="ma mb mc md gt me mf mg mh aw mi bi"><span id="5ec8" class="mj mk jb mf b gy ml mm l mn mo">bow4=bow_transformer.transform([message4])<br/>print(bow4)<br/>print(bow4.shape)</span><span id="7524" class="mj mk jb mf b gy mq mm l mn mo">(0, 4068)	2<br/>  (0, 4629)	1<br/>  (0, 5261)	1<br/>  (0, 6204)	1<br/>  (0, 6222)	1<br/>  (0, 7186)	1<br/>  (0, 9554)	2<br/>(1, 11425)</span></pre><p id="b03c" class="pw-post-body-paragraph kq kr jb ks b kt ku kc kv kw kx kf ky kz la lb lc ld le lf lg lh li lj lk ll ij bi translated">这意味着在第4条消息中有7个唯一的单词(在删除了常用的停用词之后)。其中两个出现两次，其余的只出现一次。让我们继续检查并确认哪些出现了两次:</p><p id="4ce5" class="pw-post-body-paragraph kq kr jb ks b kt ku kc kv kw kx kf ky kz la lb lc ld le lf lg lh li lj lk ll ij bi translated">在[26]中:</p><pre class="ma mb mc md gt me mf mg mh aw mi bi"><span id="20c1" class="mj mk jb mf b gy ml mm l mn mo">print(bow_transformer.get_feature_names()[4073])<br/>print(bow_transformer.get_feature_names()[9570])</span><span id="c2da" class="mj mk jb mf b gy mq mm l mn mo">UIN<br/>schedule</span></pre><p id="f665" class="pw-post-body-paragraph kq kr jb ks b kt ku kc kv kw kx kf ky kz la lb lc ld le lf lg lh li lj lk ll ij bi translated">现在我们可以使用<strong class="ks jc">。在我们的单词包(bow)转换对象上转换</strong>,并转换消息的整个数据帧。让我们来看看整个SMS语料库的单词包是如何计算的，这是一个大型的稀疏矩阵:</p><p id="c022" class="pw-post-body-paragraph kq kr jb ks b kt ku kc kv kw kx kf ky kz la lb lc ld le lf lg lh li lj lk ll ij bi translated">在[27]中:</p><pre class="ma mb mc md gt me mf mg mh aw mi bi"><span id="ff50" class="mj mk jb mf b gy ml mm l mn mo">messages_bow = bow_transformer.transform(message['message'])</span></pre><p id="7c9f" class="pw-post-body-paragraph kq kr jb ks b kt ku kc kv kw kx kf ky kz la lb lc ld le lf lg lh li lj lk ll ij bi translated">在[28]中:</p><pre class="ma mb mc md gt me mf mg mh aw mi bi"><span id="c777" class="mj mk jb mf b gy ml mm l mn mo">print('Shape of Sparse Matrix: ',messages_bow.shape)<br/>print('Amount of non-zero occurences:',messages_bow.nnz)</span><span id="6731" class="mj mk jb mf b gy mq mm l mn mo">Shape of Sparse Matrix:  (5572, 11425)<br/>Amount of non-zero occurences: 50548</span></pre><p id="1432" class="pw-post-body-paragraph kq kr jb ks b kt ku kc kv kw kx kf ky kz la lb lc ld le lf lg lh li lj lk ll ij bi translated">在[29]中:</p><pre class="ma mb mc md gt me mf mg mh aw mi bi"><span id="c9ab" class="mj mk jb mf b gy ml mm l mn mo">sparsity =(100.0 * messages_bow.nnz/(messages_bow.shape[0]*messages_bow.shape[1]))<br/>print('sparsity:<strong class="mf jc">{}</strong>'.format(round(sparsity)))</span><span id="9fe9" class="mj mk jb mf b gy mq mm l mn mo">sparsity:0</span></pre><p id="a338" class="pw-post-body-paragraph kq kr jb ks b kt ku kc kv kw kx kf ky kz la lb lc ld le lf lg lh li lj lk ll ij bi translated">计数后，可以使用scikit-learn的<code class="fe oc od oe mf b">TfidfTransformer</code>通过<a class="ae lm" href="http://en.wikipedia.org/wiki/Tf%E2%80%93idf" rel="noopener ugc nofollow" target="_blank"> TF-IDF </a>对术语进行加权和归一化。</p></div><div class="ab cl of og hu oh" role="separator"><span class="oi bw bk oj ok ol"/><span class="oi bw bk oj ok ol"/><span class="oi bw bk oj ok"/></div><div class="ij ik il im in"><h1 id="d1d1" class="mr mk jb bd ms mt om mv mw mx on mz na kh oo ki nc kk op kl ne kn oq ko ng nh bi translated">那么什么是TF-IDF呢？</h1><p id="c9a5" class="pw-post-body-paragraph kq kr jb ks b kt ni kc kv kw nj kf ky kz nk lb lc ld nl lf lg lh nm lj lk ll ij bi translated">tf-idf代表<em class="mp">词频-逆文档频率</em>，TF-IDF权重是信息检索和文本挖掘中经常使用的一种权重。该权重是一种统计度量，用于评估一个单词对集合或语料库中的文档有多重要。重要性与单词在文档中出现的次数成比例增加，但是被单词在语料库中的频率抵消。tf-idf加权方案的变体通常被搜索引擎用作给定用户查询时对文档相关性进行评分和排序的中心工具。</p><p id="024e" class="pw-post-body-paragraph kq kr jb ks b kt ku kc kv kw kx kf ky kz la lb lc ld le lf lg lh li lj lk ll ij bi translated">最简单的排名函数之一是通过对每个查询项的tf-idf求和来计算的；许多更复杂的排名函数是这个简单模型的变体。</p><p id="7d7d" class="pw-post-body-paragraph kq kr jb ks b kt ku kc kv kw kx kf ky kz la lb lc ld le lf lg lh li lj lk ll ij bi translated">通常，tf-idf权重由两项组成:第一项计算归一化项频率(tf)，aka。单词在文档中出现的次数，除以该文档中的总单词数；第二项是逆文档频率(IDF ),计算为语料库中文档数量的对数除以特定术语出现的文档数量。</p><p id="e719" class="pw-post-body-paragraph kq kr jb ks b kt ku kc kv kw kx kf ky kz la lb lc ld le lf lg lh li lj lk ll ij bi translated"><strong class="ks jc"> TF:词频</strong>，衡量一个词在文档中出现的频率。因为每个文档的长度不同，所以一个术语在长文档中出现的时间可能比短文档多得多。因此，术语频率通常除以文档长度(又名。文档中的术语总数)作为标准化的一种方式:</p><p id="113a" class="pw-post-body-paragraph kq kr jb ks b kt ku kc kv kw kx kf ky kz la lb lc ld le lf lg lh li lj lk ll ij bi translated"><em class="mp"> TF(t) =(术语t在文档中出现的次数)/(文档中的总术语数)。</em></p><p id="51ca" class="pw-post-body-paragraph kq kr jb ks b kt ku kc kv kw kx kf ky kz la lb lc ld le lf lg lh li lj lk ll ij bi translated"><strong class="ks jc"> IDF:逆文档频率</strong>，衡量一个术语的重要程度。在计算TF时，所有项都被认为是同等重要的。然而，众所周知，某些术语，如“是”、“的”和“那个”，可能会出现很多次，但并不重要。因此，我们需要通过计算以下各项来降低常用术语的权重，同时提高稀有术语的权重:</p><p id="a9e2" class="pw-post-body-paragraph kq kr jb ks b kt ku kc kv kw kx kf ky kz la lb lc ld le lf lg lh li lj lk ll ij bi translated"><em class="mp"> IDF(t) = log_e(文档总数/其中包含术语t的文档数)。</em></p><p id="2269" class="pw-post-body-paragraph kq kr jb ks b kt ku kc kv kw kx kf ky kz la lb lc ld le lf lg lh li lj lk ll ij bi translated">下面是一个简单的例子。</p><p id="c663" class="pw-post-body-paragraph kq kr jb ks b kt ku kc kv kw kx kf ky kz la lb lc ld le lf lg lh li lj lk ll ij bi translated"><strong class="ks jc">示例:</strong></p><p id="5b08" class="pw-post-body-paragraph kq kr jb ks b kt ku kc kv kw kx kf ky kz la lb lc ld le lf lg lh li lj lk ll ij bi translated">考虑包含100个单词的文档，其中单词cat出现了3次。</p><p id="0038" class="pw-post-body-paragraph kq kr jb ks b kt ku kc kv kw kx kf ky kz la lb lc ld le lf lg lh li lj lk ll ij bi translated">cat的频率项(即tf)则为(3 / 100) = 0.03。现在，假设我们有1000万个文档，其中1000个文档中出现了单词cat。然后，逆文档频率(即idf)计算为log(10，000，000 / 1，000) = 4。因此，Tf-idf重量是这些量的乘积:0.03 * 4 = 0.12。</p></div><div class="ab cl of og hu oh" role="separator"><span class="oi bw bk oj ok ol"/><span class="oi bw bk oj ok ol"/><span class="oi bw bk oj ok"/></div><div class="ij ik il im in"><p id="1155" class="pw-post-body-paragraph kq kr jb ks b kt ku kc kv kw kx kf ky kz la lb lc ld le lf lg lh li lj lk ll ij bi translated">让我们来看看如何在SciKit Learn中实现这一点:</p><p id="bcec" class="pw-post-body-paragraph kq kr jb ks b kt ku kc kv kw kx kf ky kz la lb lc ld le lf lg lh li lj lk ll ij bi translated">在[30]中:</p><pre class="ma mb mc md gt me mf mg mh aw mi bi"><span id="4716" class="mj mk jb mf b gy ml mm l mn mo">from sklearn.feature_extraction.text import TfidfTransformer<br/>tfidf_transformer=TfidfTransformer().fit(messages_bow)<br/>tfidf4 = tfidf_transformer.transform(bow4)<br/>print(tfidf4)</span><span id="1097" class="mj mk jb mf b gy mq mm l mn mo">(0, 9554)	0.5385626262927564<br/>  (0, 7186)	0.4389365653379857<br/>  (0, 6222)	0.3187216892949149<br/>  (0, 6204)	0.29953799723697416<br/>  (0, 5261)	0.29729957405868723<br/>  (0, 4629)	0.26619801906087187<br/>  (0, 4068)	0.40832589933384067</span></pre><p id="a4b8" class="pw-post-body-paragraph kq kr jb ks b kt ku kc kv kw kx kf ky kz la lb lc ld le lf lg lh li lj lk ll ij bi translated">我们将继续检查单词<code class="fe oc od oe mf b">"u"</code>和单词<code class="fe oc od oe mf b">"university"</code>的IDF(逆文档频率)是多少？</p><p id="8c9c" class="pw-post-body-paragraph kq kr jb ks b kt ku kc kv kw kx kf ky kz la lb lc ld le lf lg lh li lj lk ll ij bi translated">在[31]中:</p><pre class="ma mb mc md gt me mf mg mh aw mi bi"><span id="a06e" class="mj mk jb mf b gy ml mm l mn mo">print(tfidf_transformer.idf_[bow_transformer.vocabulary_['u']])<br/>print(tfidf_transformer.idf_[bow_transformer.vocabulary_['university']])</span><span id="cca2" class="mj mk jb mf b gy mq mm l mn mo">3.2800524267409408<br/>8.527076498901426</span></pre><p id="4940" class="pw-post-body-paragraph kq kr jb ks b kt ku kc kv kw kx kf ky kz la lb lc ld le lf lg lh li lj lk ll ij bi translated">在[32]中:</p><pre class="ma mb mc md gt me mf mg mh aw mi bi"><span id="14e4" class="mj mk jb mf b gy ml mm l mn mo">messages_tfidf=tfidf_transformer.transform(messages_bow)<br/>print(messages_tfidf.shape)</span><span id="4161" class="mj mk jb mf b gy mq mm l mn mo">(5572, 11425)</span></pre><p id="1030" class="pw-post-body-paragraph kq kr jb ks b kt ku kc kv kw kx kf ky kz la lb lc ld le lf lg lh li lj lk ll ij bi translated">有许多方法可以对数据进行预处理和矢量化。这些步骤包括特征工程和建立“管道”。我鼓励您查阅SciKit Learn关于处理文本数据的文档，以及大量关于NLP主题的论文和书籍。</p><h1 id="6a21" class="mr mk jb bd ms mt mu mv mw mx my mz na kh nb ki nc kk nd kl ne kn nf ko ng nh bi translated">训练模型</h1><p id="fe8b" class="pw-post-body-paragraph kq kr jb ks b kt ni kc kv kw nj kf ky kz nk lb lc ld nl lf lg lh nm lj lk ll ij bi translated">通过将消息表示为向量，我们最终可以训练我们的垃圾邮件/垃圾邮件分类器。现在我们实际上可以使用几乎任何种类的分类算法。出于各种各样的原因，朴素贝叶斯分类算法是一个很好的选择。</p><p id="f1f4" class="pw-post-body-paragraph kq kr jb ks b kt ku kc kv kw kx kf ky kz la lb lc ld le lf lg lh li lj lk ll ij bi translated">在[33]中:</p><pre class="ma mb mc md gt me mf mg mh aw mi bi"><span id="ba89" class="mj mk jb mf b gy ml mm l mn mo">from sklearn.naive_bayes import MultinomialNB<br/>spam_detect_model = MultinomialNB().fit(messages_tfidf,message['labels'])</span></pre><p id="7e96" class="pw-post-body-paragraph kq kr jb ks b kt ku kc kv kw kx kf ky kz la lb lc ld le lf lg lh li lj lk ll ij bi translated">在[34]中:</p><pre class="ma mb mc md gt me mf mg mh aw mi bi"><span id="b899" class="mj mk jb mf b gy ml mm l mn mo">print('predicted:',spam_detect_model.predict(tfidf4)[0])<br/>print('expected:',message.labels[3])</span><span id="48d0" class="mj mk jb mf b gy mq mm l mn mo">predicted: ham<br/>expected: ham</span></pre><p id="0ffb" class="pw-post-body-paragraph kq kr jb ks b kt ku kc kv kw kx kf ky kz la lb lc ld le lf lg lh li lj lk ll ij bi translated">太棒了。我们已经开发了一个模型，可以尝试预测垃圾邮件与火腿分类！</p><h1 id="4578" class="mr mk jb bd ms mt mu mv mw mx my mz na kh nb ki nc kk nd kl ne kn nf ko ng nh bi translated">第6部分:模型评估</h1><p id="cbf0" class="pw-post-body-paragraph kq kr jb ks b kt ni kc kv kw nj kf ky kz nk lb lc ld nl lf lg lh nm lj lk ll ij bi translated">现在，我们想确定我们的模型在整个数据集上的总体表现。让我们从获得所有预测开始:</p><p id="9e71" class="pw-post-body-paragraph kq kr jb ks b kt ku kc kv kw kx kf ky kz la lb lc ld le lf lg lh li lj lk ll ij bi translated">在[35]中:</p><pre class="ma mb mc md gt me mf mg mh aw mi bi"><span id="5c8a" class="mj mk jb mf b gy ml mm l mn mo">all_predictions = spam_detect_model.predict(messages_tfidf)<br/>print(all_predictions)</span><span id="9287" class="mj mk jb mf b gy mq mm l mn mo">['ham' 'ham' 'spam' ... 'ham' 'ham' 'ham']</span></pre><p id="0d8f" class="pw-post-body-paragraph kq kr jb ks b kt ku kc kv kw kx kf ky kz la lb lc ld le lf lg lh li lj lk ll ij bi translated">我们可以使用SciKit Learn的内置分类报告，它返回<a class="ae lm" href="https://en.wikipedia.org/wiki/Precision_and_recall" rel="noopener ugc nofollow" target="_blank">精度、召回、</a>、<a class="ae lm" href="https://en.wikipedia.org/wiki/F1_score" rel="noopener ugc nofollow" target="_blank">f1-得分</a>，以及一个支持列(表示有多少案例支持该分类)。有关这些指标和下图的更多详细信息，请查看链接:</p><figure class="ma mb mc md gt is gh gi paragraph-image"><div class="gh gi or"><img src="../Images/01f60c2ad2f64be2bdfb8e7201153239.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*6xKE36CORmtYsvUq.png"/></div></figure><p id="a49c" class="pw-post-body-paragraph kq kr jb ks b kt ku kc kv kw kx kf ky kz la lb lc ld le lf lg lh li lj lk ll ij bi translated">在[36]中:</p><pre class="ma mb mc md gt me mf mg mh aw mi bi"><span id="a4d6" class="mj mk jb mf b gy ml mm l mn mo">from sklearn.metrics import classification_report,confusion_matrix<br/>print(classification_report(message['labels'],all_predictions))<br/>print(confusion_matrix(message['labels'],all_predictions))</span><span id="2fa5" class="mj mk jb mf b gy mq mm l mn mo">precision    recall  f1-score   support</span><span id="81a0" class="mj mk jb mf b gy mq mm l mn mo">        ham       0.98      1.00      0.99      4825<br/>       spam       1.00      0.85      0.92       747</span><span id="52f7" class="mj mk jb mf b gy mq mm l mn mo">avg / total       0.98      0.98      0.98      5572</span><span id="e656" class="mj mk jb mf b gy mq mm l mn mo">[[4825    0]<br/> [ 115  632]]</span></pre><p id="263d" class="pw-post-body-paragraph kq kr jb ks b kt ku kc kv kw kx kf ky kz la lb lc ld le lf lg lh li lj lk ll ij bi translated">评估模型性能有很多可能的标准。哪一个是最重要的取决于基于模型的决策的任务和业务效果？例如，将“垃圾邮件”误预测为“火腿”的成本，很可能比将“火腿”误预测为“垃圾邮件”要低得多。</p><p id="cf33" class="pw-post-body-paragraph kq kr jb ks b kt ku kc kv kw kx kf ky kz la lb lc ld le lf lg lh li lj lk ll ij bi translated">在上面的“评估”中，我们评估了用于训练的相同数据的准确性。<strong class="ks jc">你不应该在你训练的数据集上进行评估！</strong></p><p id="f531" class="pw-post-body-paragraph kq kr jb ks b kt ku kc kv kw kx kf ky kz la lb lc ld le lf lg lh li lj lk ll ij bi translated">这样的评估并没有告诉我们模型的真正预测能力。如果我们在训练过程中简单地记住每个例子，训练数据的准确率将会是100%，即使我们不能对任何新消息进行分类。</p><p id="691c" class="pw-post-body-paragraph kq kr jb ks b kt ku kc kv kw kx kf ky kz la lb lc ld le lf lg lh li lj lk ll ij bi translated">一种适当的方式是将数据分成训练/测试集，其中模型在其模型拟合和参数调整期间只看到<strong class="ks jc">训练数据</strong>。从未以任何方式使用过<strong class="ks jc">测试数据</strong>。这是我们对测试数据的最终评估，代表了真实的预测性能。</p><h1 id="ae21" class="mr mk jb bd ms mt mu mv mw mx my mz na kh nb ki nc kk nd kl ne kn nf ko ng nh bi translated">列车测试分离</h1><p id="3bca" class="pw-post-body-paragraph kq kr jb ks b kt ni kc kv kw nj kf ky kz nk lb lc ld nl lf lg lh nm lj lk ll ij bi translated">在[37]中:</p><pre class="ma mb mc md gt me mf mg mh aw mi bi"><span id="55d5" class="mj mk jb mf b gy ml mm l mn mo">from sklearn.model_selection import train_test_split<br/>msg_train,msg_test,label_train,label_test = train_test_split(message['message'],message['labels'],test_size=0.2)</span></pre><p id="0f65" class="pw-post-body-paragraph kq kr jb ks b kt ku kc kv kw kx kf ky kz la lb lc ld le lf lg lh li lj lk ll ij bi translated">在[38]中:</p><pre class="ma mb mc md gt me mf mg mh aw mi bi"><span id="74f5" class="mj mk jb mf b gy ml mm l mn mo">print(len(msg_train),len(msg_test),len(label_train),len(label_test))</span><span id="7b9f" class="mj mk jb mf b gy mq mm l mn mo">4457 1115 4457 1115</span></pre><p id="1e20" class="pw-post-body-paragraph kq kr jb ks b kt ku kc kv kw kx kf ky kz la lb lc ld le lf lg lh li lj lk ll ij bi translated">测试大小是整个数据集的20%(总共5572条消息中的1115条)，其余是训练(5572条消息中的4457条)。注意默认的分割应该是30/70。</p><h1 id="4a71" class="mr mk jb bd ms mt mu mv mw mx my mz na kh nb ki nc kk nd kl ne kn nf ko ng nh bi translated">创建数据管道</h1><p id="af72" class="pw-post-body-paragraph kq kr jb ks b kt ni kc kv kw nj kf ky kz nk lb lc ld nl lf lg lh nm lj lk ll ij bi translated">让我们再次运行我们的模型，然后根据测试集进行预测。我们将使用SciKit Learn的<a class="ae lm" href="http://scikit-learn.org/stable/modules/pipeline.html" rel="noopener ugc nofollow" target="_blank">管道</a>功能来存储工作流的管道。这将允许我们设置我们将对数据进行的所有转换，以供将来使用。让我们来看一个它是如何工作的例子:</p><p id="d074" class="pw-post-body-paragraph kq kr jb ks b kt ku kc kv kw kx kf ky kz la lb lc ld le lf lg lh li lj lk ll ij bi translated">在[39]中:</p><pre class="ma mb mc md gt me mf mg mh aw mi bi"><span id="9c84" class="mj mk jb mf b gy ml mm l mn mo">from sklearn.pipeline import Pipeline<br/>pipeline = Pipeline([<br/>   ( 'bow',CountVectorizer(analyzer=text_process)),<br/>    ('tfidf',TfidfTransformer()),<br/>    ('classifier',MultinomialNB()),<br/>])</span></pre><p id="6d95" class="pw-post-body-paragraph kq kr jb ks b kt ku kc kv kw kx kf ky kz la lb lc ld le lf lg lh li lj lk ll ij bi translated">在[40]:</p><pre class="ma mb mc md gt me mf mg mh aw mi bi"><span id="dc98" class="mj mk jb mf b gy ml mm l mn mo">pipeline.fit(msg_train,label_train)</span></pre><p id="9817" class="pw-post-body-paragraph kq kr jb ks b kt ku kc kv kw kx kf ky kz la lb lc ld le lf lg lh li lj lk ll ij bi translated">Out[40]:</p><pre class="ma mb mc md gt me mf mg mh aw mi bi"><span id="02fa" class="mj mk jb mf b gy ml mm l mn mo">Pipeline(memory=None,<br/>     steps=[('bow', CountVectorizer(analyzer=&lt;function text_process at 0x7fdf3393f510&gt;,<br/>        binary=False, decode_error='strict', dtype=&lt;class 'numpy.int64'&gt;,<br/>        encoding='utf-8', input='content', lowercase=True, max_df=1.0,<br/>        max_features=None, min_df=1, ngram_range=(1, 1), preprocessor=No...f=False, use_idf=True)), ('classifier', MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True))])</span></pre><p id="a3e0" class="pw-post-body-paragraph kq kr jb ks b kt ku kc kv kw kx kf ky kz la lb lc ld le lf lg lh li lj lk ll ij bi translated">在[41]中:</p><pre class="ma mb mc md gt me mf mg mh aw mi bi"><span id="0d40" class="mj mk jb mf b gy ml mm l mn mo">predictions = pipeline.predict(msg_test)</span></pre><p id="4fec" class="pw-post-body-paragraph kq kr jb ks b kt ku kc kv kw kx kf ky kz la lb lc ld le lf lg lh li lj lk ll ij bi translated">在[42]中:</p><pre class="ma mb mc md gt me mf mg mh aw mi bi"><span id="185b" class="mj mk jb mf b gy ml mm l mn mo">print(classification_report(predictions,label_test))</span><span id="4995" class="mj mk jb mf b gy mq mm l mn mo">precision    recall  f1-score   support</span><span id="f5b9" class="mj mk jb mf b gy mq mm l mn mo">        ham       1.00      0.96      0.98      1003<br/>       spam       0.74      1.00      0.85       112</span><span id="f9ad" class="mj mk jb mf b gy mq mm l mn mo">avg / total       0.97      0.97      0.97      1115</span></pre><p id="de02" class="pw-post-body-paragraph kq kr jb ks b kt ku kc kv kw kx kf ky kz la lb lc ld le lf lg lh li lj lk ll ij bi translated">测试大小是整个数据集的20%(总共5572条消息中的1115条)，其余是训练(5572条消息中的4457条)。注意默认的分割应该是30/70。</p></div></div>    
</body>
</html>