<html>
<head>
<title>Start-off your ML journey with K-Nearest Neighbors!</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">从K个最近的邻居开始你的ML之旅！</h1>
<blockquote>原文：<a href="https://pub.towardsai.net/start-off-your-ml-journey-with-k-nearest-neighbors-f72a122f428?source=collection_archive---------1-----------------------#2020-06-27">https://pub.towardsai.net/start-off-your-ml-journey-with-k-nearest-neighbors-f72a122f428?source=collection_archive---------1-----------------------#2020-06-27</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><h2 id="7b34" class="ir is it bd b dl iu iv iw ix iy iz dk ja translated" aria-label="kicker paragraph"><a class="ae ep" href="https://towardsai.net/p/category/machine-learning" rel="noopener ugc nofollow" target="_blank">机器学习</a></h2><div class=""/><div class=""><h2 id="8527" class="pw-subtitle-paragraph jz jc it bd b ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq dk translated">详细的理论讲解和scikit-learn实现附一个例子！</h2></div><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi kr"><img src="../Images/87d25bd0156296881e2c08b628ef75db.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*xiAx33sPfq1HjdAY5dXc6w.png"/></div></div></figure><p id="5bb2" class="pw-post-body-paragraph ld le it lf b lg lh kd li lj lk kg ll lm ln lo lp lq lr ls lt lu lv lw lx ly im bi translated"><strong class="lf jd">K-最近邻(KNN) </strong>是机器学习中的基本方法之一，也是在机器学习的世界中介绍自己的一种很好的方式。</p><h1 id="91fc" class="lz ma it bd mb mc md me mf mg mh mi mj ki mk kj ml kl mm km mn ko mo kp mp mq bi translated">目录:</h1><ol class=""><li id="3188" class="mr ms it lf b lg mt lj mu lm mv lq mw lu mx ly my mz na nb bi translated"><strong class="lf jd">T5】K-NN简介T7】</strong></li><li id="e456" class="mr ms it lf b lg nd lj ne lm nf lq ng lu nh ly my mz na nb bi translated"><strong class="lf jd"><em class="nc">K-NN是如何工作的？</em>T11】</strong></li><li id="4d44" class="mr ms it lf b lg nd lj ne lm nf lq ng lu nh ly my mz na nb bi translated"><strong class="lf jd"> <em class="nc">我们如何选择“K”？</em>T15】</strong></li><li id="8107" class="mr ms it lf b lg nd lj ne lm nf lq ng lu nh ly my mz na nb bi translated"><strong class="lf jd"> <em class="nc">伪代码为KNN </em> </strong></li><li id="406d" class="mr ms it lf b lg nd lj ne lm nf lq ng lu nh ly my mz na nb bi translated"><strong class="lf jd"> <em class="nc">实施KNN将乳腺癌分为恶性和良性</em> </strong></li><li id="7fe1" class="mr ms it lf b lg nd lj ne lm nf lq ng lu nh ly my mz na nb bi translated"><strong class="lf jd"><em class="nc">KNN的利弊</em> </strong></li></ol><h1 id="07df" class="lz ma it bd mb mc md me mf mg mh mi mj ki mk kj ml kl mm km mn ko mo kp mp mq bi translated">K-NN简介</h1><p id="a090" class="pw-post-body-paragraph ld le it lf b lg mt kd li lj mu kg ll lm ni lo lp lq nj ls lt lu nk lw lx ly im bi translated">KNN是<strong class="lf jd">监督学习算法</strong>，当输入新的未标记数据时，它依赖输入数据进行训练，以产生相关的输出。</p><p id="25c3" class="pw-post-body-paragraph ld le it lf b lg lh kd li lj lk kg ll lm ln lo lp lq lr ls lt lu lv lw lx ly im bi translated">举个例子，假设你是一个5岁孩子的监护人，你想让他知道一只“<em class="nc">狗</em>长什么样，你会给他看几张<em class="nc">狗</em>的照片，其余的可以是任何其他动物的照片。</p><p id="84c0" class="pw-post-body-paragraph ld le it lf b lg lh kd li lj lk kg ll lm ln lo lp lq lr ls lt lu lv lw lx ly im bi translated">每当你遇到一只"<em class="nc">狗</em>"你会告诉你的孩子<em class="nc">"它是一只狗"</em>每当其他动物出现你会告诉你的孩子<em class="nc">"不，它不是一只狗"</em>。重复这个过程几次将有助于你的孩子理解狗到底是什么，他可以区分和识别狗和其他动物。这叫做<strong class="lf jd"> <em class="nc">监督学习算法。</em> </strong></p><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi nl"><img src="../Images/55956fb9f443cac663cd8ce8aa4a8120.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*hmSQIQUBvHoZe2eD"/></div></div><figcaption class="nm nn gj gh gi no np bd b be z dk translated">“是一只狗”</figcaption></figure><p id="58f0" class="pw-post-body-paragraph ld le it lf b lg lh kd li lj lk kg ll lm ln lo lp lq lr ls lt lu lv lw lx ly im bi translated">监督机器学习算法用于解决<em class="nc">分类</em>或<em class="nc">回归</em>问题。一般来说，无监督学习算法用于<em class="nc">聚类</em>问题。</p><p id="f4f5" class="pw-post-body-paragraph ld le it lf b lg lh kd li lj lk kg ll lm ln lo lp lq lr ls lt lu lv lw lx ly im bi translated">K-NN是一个<strong class="lf jd">非参数</strong>，对应的是它对底层数据不做任何假设。它也被称为“<strong class="lf jd">懒惰学习算法</strong>”，因为它不会立即从输入数据中学习，而是在查询时进行分类。它保存数据集中的所有值，使其<strong class="lf jd">训练非常快</strong>，并且不像当代的SVM<strong class="lf jd">可以丢弃非支持向量</strong>。其懒惰的学习特性导致<strong class="lf jd">巨大的空间和时间复杂度</strong>。但是，这种算法对于小数据集来说还是很有效的。</p><p id="77c5" class="pw-post-body-paragraph ld le it lf b lg lh kd li lj lk kg ll lm ln lo lp lq lr ls lt lu lv lw lx ly im bi translated"><em class="nc"> KNN </em>是<strong class="lf jd">最不精确的算法，</strong>每当我们开发一个新算法时，我们都会用<em class="nc"> KNN </em>的算法来交叉检查它的精确度。它的准确性被用作新算法的最小阈值，这是KNN的优点和缺点。</p><p id="afca" class="pw-post-body-paragraph ld le it lf b lg lh kd li lj lk kg ll lm ln lo lp lq lr ls lt lu lv lw lx ly im bi translated">K-NN的预期输出是<strong class="lf jd">类成员</strong>。</p><p id="d64c" class="pw-post-body-paragraph ld le it lf b lg lh kd li lj lk kg ll lm ln lo lp lq lr ls lt lu lv lw lx ly im bi translated">与其他算法相比，它的独特之处在于它具有双重性，即它既可用于分类问题，也可用于回归问题。</p><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi nq"><img src="../Images/9a41015172f6b3e56824ca768cffa139.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*c6V7oQaCNoy9XaFpHljPxg.png"/></div></div></figure><p id="8323" class="pw-post-body-paragraph ld le it lf b lg lh kd li lj lk kg ll lm ln lo lp lq lr ls lt lu lv lw lx ly im bi translated">KNN的工作原理是<strong class="lf jd">多数票</strong>原则，也就是说，一个物体被其邻居的多数票分类，该物体被分配到其k个最近邻居中最常见的类别。</p><p id="d5b8" class="pw-post-body-paragraph ld le it lf b lg lh kd li lj lk kg ll lm ln lo lp lq lr ls lt lu lv lw lx ly im bi translated">使用<strong class="lf jd">距离度量</strong>来决定投票，并且假设数据在<strong class="lf jd">度量空间中。</strong></p><p id="11b8" class="pw-post-body-paragraph ld le it lf b lg lh kd li lj lk kg ll lm ln lo lp lq lr ls lt lu lv lw lx ly im bi translated">最常见的距离度量是:</p><ol class=""><li id="79ee" class="mr ms it lf b lg lh lj lk lm nr lq ns lu nt ly my mz na nb bi translated"><a class="ae nu" href="https://en.wikipedia.org/wiki/Euclidean_distance" rel="noopener ugc nofollow" target="_blank"> <strong class="lf jd">欧氏距离</strong> </a>:定义为两点之间的平方差之和的平方根。</li></ol><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div class="gh gi nv"><img src="../Images/c09055eab2c9b52df1a873dd223ca8db.png" data-original-src="https://miro.medium.com/v2/resize:fit:1060/format:webp/0*HazgRldllAKhHMl2.png"/></div></figure><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div class="gh gi nw"><img src="../Images/a678e5d0a7c29c8f85da9cce79517884.png" data-original-src="https://miro.medium.com/v2/resize:fit:596/format:webp/0*Iaxud2FaAva5hAa3.png"/></div></figure><p id="b679" class="pw-post-body-paragraph ld le it lf b lg lh kd li lj lk kg ll lm ln lo lp lq lr ls lt lu lv lw lx ly im bi translated"><strong class="lf jd"> 2。</strong> <a class="ae nu" href="https://en.wikipedia.org/wiki/Taxicab_geometry" rel="noopener ugc nofollow" target="_blank"> <strong class="lf jd">曼哈顿距离</strong> </a>:这是使用绝对差之和的真实向量之间的距离。</p><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi nx"><img src="../Images/47168f442fa8edccce39a3b404c140de.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*yXeEabjr5rilmXVZ.png"/></div></div></figure><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div class="gh gi ny"><img src="../Images/032392623da6f2dd03a222c97acb02c9.png" data-original-src="https://miro.medium.com/v2/resize:fit:552/format:webp/0*sN5SOKr4x3iCoCvM.png"/></div></figure></div><div class="ab cl nz oa hx ob" role="separator"><span class="oc bw bk od oe of"/><span class="oc bw bk od oe of"/><span class="oc bw bk od oe"/></div><div class="im in io ip iq"><h1 id="1245" class="lz ma it bd mb mc og me mf mg oh mi mj ki oi kj ml kl oj km mn ko ok kp mp mq bi translated">K-NN是如何工作的？</h1><ol class=""><li id="9ebc" class="mr ms it lf b lg mt lj mu lm mv lq mw lu mx ly my mz na nb bi translated">将数据分为测试集和训练集。</li><li id="fddd" class="mr ms it lf b lg nd lj ne lm nf lq ng lu nh ly my mz na nb bi translated">假设“<em class="nc"> k </em>的值。</li><li id="468e" class="mr ms it lf b lg nd lj ne lm nf lq ng lu nh ly my mz na nb bi translated">假设一个距离度量，并计算到其n个训练样本的距离。</li><li id="1e19" class="mr ms it lf b lg nd lj ne lm nf lq ng lu nh ly my mz na nb bi translated">对计算的距离进行排序，并获取k个最近的样本。</li><li id="46f6" class="mr ms it lf b lg nd lj ne lm nf lq ng lu nh ly my mz na nb bi translated">根据多数点，将类别分配给未标记的数据点。</li></ol><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi ol"><img src="../Images/b22d234d721e3724c6c33aae652d5481.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*iYpTYnOVUqyEJARwn_RQMA.png"/></div></div></figure><p id="8dd6" class="pw-post-body-paragraph ld le it lf b lg lh kd li lj lk kg ll lm ln lo lp lq lr ls lt lu lv lw lx ly im bi translated">我们试图计算不同点与一个新的未识别数据点之间的距离。</p><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi om"><img src="../Images/08def540890fada2489fc170840cf089.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*_p6jEEUWL-6ajbx8_Ax7rg.png"/></div></div></figure><p id="1b8a" class="pw-post-body-paragraph ld le it lf b lg lh kd li lj lk kg ll lm ln lo lp lq lr ls lt lu lv lw lx ly im bi translated">一旦计算出距离，我们取k-最近的样本，并根据多数票，将一个类别分配给一个未识别的数据点。</p><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi on"><img src="../Images/a8eb87ead6d98b9e68584888e446fdc7.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*MV28jrbDBIJz3Wd1xLVRcA.png"/></div></div></figure></div><div class="ab cl nz oa hx ob" role="separator"><span class="oc bw bk od oe of"/><span class="oc bw bk od oe of"/><span class="oc bw bk od oe"/></div><div class="im in io ip iq"><h1 id="38e0" class="lz ma it bd mb mc og me mf mg oh mi mj ki oi kj ml kl oj km mn ko ok kp mp mq bi translated">我们如何选择“K”？</h1><p id="0d20" class="pw-post-body-paragraph ld le it lf b lg mt kd li lj mu kg ll lm ni lo lp lq nj ls lt lu nk lw lx ly im bi translated">一个简洁的答案是，对于“<em class="nc"> K </em>”没有最优值。它是<strong class="lf jd">超参数</strong>，因此由你选择，但是记住它是决策边界，因此必须明智地选择。</p><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi oo"><img src="../Images/c2b2b8dc6fd39c4a8d39dbdc2c09f42f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*a8TEfnOmWdsJkRzbHTV9ug.png"/></div></div><figcaption class="nm nn gj gh gi no np bd b be z dk translated">K = 1 vs K = 15<a class="ae nu" href="https://sklearn.org/modules/neighbors.html" rel="noopener ugc nofollow" target="_blank">来源</a></figcaption></figure><p id="b6ad" class="pw-post-body-paragraph ld le it lf b lg lh kd li lj lk kg ll lm ln lo lp lq lr ls lt lu lv lw lx ly im bi translated">正如我们所见，当<strong class="lf jd"> K=1 </strong>时，曲线过于尖锐，但随着我们增加K，锐度降低，平滑度开始发挥作用。如果我们把K增加到无穷大，基于多数票，所有东西都将是红色、绿色或蓝色。</p><p id="ab27" class="pw-post-body-paragraph ld le it lf b lg lh kd li lj lk kg ll lm ln lo lp lq lr ls lt lu lv lw lx ly im bi translated"><em class="nc"> K </em>的值在确定决策边界时起着非常重要的作用；</p><blockquote class="op"><p id="39a9" class="oq or it bd os ot ou ov ow ox oy ly dk translated">k:太大；一切都被分类到给定的类中(欠拟合)</p><p id="8e86" class="oq or it bd os ot ou ov ow ox oy ly dk translated">k:太小；高度可变的数据集和不稳定的决策边界(过拟合)</p></blockquote><p id="f517" class="pw-post-body-paragraph ld le it lf b lg oz kd li lj pa kg ll lm pb lo lp lq pc ls lt lu pd lw lx ly im bi translated">“K”的值可以用两种方法确定:</p><ol class=""><li id="7ad3" class="mr ms it lf b lg lh lj lk lm nr lq ns lu nt ly my mz na nb bi translated"><strong class="lf jd"> <em class="nc">手动法</em> </strong>:我们需要使用点击&amp;试法；改变K值并观察训练和验证误差。</li></ol><p id="8db4" class="pw-post-body-paragraph ld le it lf b lg lh kd li lj lk kg ll lm ln lo lp lq lr ls lt lu lv lw lx ly im bi translated">如果训练误差很低但是测试误差很高，那么我们的模型就是<strong class="lf jd">过拟合</strong>。如果我们经历高训练误差但低测试误差，那么我们的模型是<strong class="lf jd">欠拟合</strong>。</p><p id="624b" class="pw-post-body-paragraph ld le it lf b lg lh kd li lj lk kg ll lm ln lo lp lq lr ls lt lu lv lw lx ly im bi translated">要了解有关为您的模型选择最佳拟合的更多信息:</p><div class="pe pf gp gr pg ph"><a href="https://medium.com/datadriveninvestor/determining-perfect-fit-for-your-ml-model-339459eef670" rel="noopener follow" target="_blank"><div class="pi ab fo"><div class="pj ab pk cl cj pl"><h2 class="bd jd gy z fp pm fr fs pn fu fw jc bi translated">确定最适合您的ML模型。</h2><div class="po l"><h3 class="bd b gy z fp pm fr fs pn fu fw dk translated">以最简单的方式教授过度拟合与欠拟合以及完美拟合。</h3></div><div class="pp l"><p class="bd b dl z fp pm fr fs pn fu fw dk translated">medium.com</p></div></div><div class="pq l"><div class="pr l ps pt pu pq pv lb ph"/></div></div></a></div><p id="aafe" class="pw-post-body-paragraph ld le it lf b lg lh kd li lj lk kg ll lm ln lo lp lq lr ls lt lu lv lw lx ly im bi translated">2.<strong class="lf jd"> <em class="nc">网格搜索</em> </strong> : Scikit-learn提供了<strong class="lf jd"> GridSearchCV </strong>函数，让我们可以轻松地检查k的多个值。</p><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div class="gh gi pw"><img src="../Images/accc4d0d69efcd791d29313baf71b7aa.png" data-original-src="https://miro.medium.com/v2/resize:fit:1230/format:webp/0*8I3QOgRo8sYn3pLo.png"/></div></figure></div><div class="ab cl nz oa hx ob" role="separator"><span class="oc bw bk od oe of"/><span class="oc bw bk od oe of"/><span class="oc bw bk od oe"/></div><div class="im in io ip iq"><h1 id="c093" class="lz ma it bd mb mc og me mf mg oh mi mj ki oi kj ml kl oj km mn ko ok kp mp mq bi translated">KNN的伪代码</h1><figure class="ks kt ku kv gt kw"><div class="bz fp l di"><div class="px py l"/></div></figure><figure class="ks kt ku kv gt kw"><div class="bz fp l di"><div class="px py l"/></div></figure><p id="a6c1" class="pw-post-body-paragraph ld le it lf b lg lh kd li lj lk kg ll lm ln lo lp lq lr ls lt lu lv lw lx ly im bi translated">这里，我们接受参数作为距离度量，然后计算未标记数据点到每个标记点的距离。</p><p id="63bc" class="pw-post-body-paragraph ld le it lf b lg lh kd li lj lk kg ll lm ln lo lp lq lr ls lt lu lv lw lx ly im bi translated">一旦计算出距离，我们就取唯一的值并使用<code class="fe pz qa qb qc b">argmax</code>来寻找多数投票，稍后我们可以仅使用这些投票将该点分类。</p></div><div class="ab cl nz oa hx ob" role="separator"><span class="oc bw bk od oe of"/><span class="oc bw bk od oe of"/><span class="oc bw bk od oe"/></div><div class="im in io ip iq"><h1 id="c363" class="lz ma it bd mb mc og me mf mg oh mi mj ki oi kj ml kl oj km mn ko ok kp mp mq bi translated"><strong class="ak"> <em class="qd">实施KNN将乳腺癌分为恶性和良性</em> </strong></h1><p id="20ac" class="pw-post-body-paragraph ld le it lf b lg mt kd li lj mu kg ll lm ni lo lp lq nj ls lt lu nk lw lx ly im bi translated">我们将在一个最常见的数据集(即乳腺癌检测)上实验我们的KNN模型。</p><p id="6408" class="pw-post-body-paragraph ld le it lf b lg lh kd li lj lk kg ll lm ln lo lp lq lr ls lt lu lv lw lx ly im bi translated">数据集包含569行和33列。癌症分为两部分，即良性(B)和恶性(M)。我们的目的是将随机癌症患者的特征分为B类或m类。</p><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div class="gh gi qe"><img src="../Images/0de1ded3b4a10f5d0b8a44370a66ff75.png" data-original-src="https://miro.medium.com/v2/resize:fit:992/format:webp/1*iBIw_7NUONaKkUj6Os9pkw.png"/></div></figure><p id="4c5e" class="pw-post-body-paragraph ld le it lf b lg lh kd li lj lk kg ll lm ln lo lp lq lr ls lt lu lv lw lx ly im bi translated">导入所有必需的库，可以在以下位置找到数据集:</p><p id="a978" class="pw-post-body-paragraph ld le it lf b lg lh kd li lj lk kg ll lm ln lo lp lq lr ls lt lu lv lw lx ly im bi translated"><a class="ae nu" href="http://archive.ics.uci.edu/ml/datasets/breast+cancer+wisconsin+%28diagnostic%29" rel="noopener ugc nofollow" target="_blank">乳腺癌数据</a></p><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi qf"><img src="../Images/081461dc670e9019d191aa954b391e7e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1374/format:webp/1*1-enhk9-eYMrexMDcW5mzQ.png"/></div></div></figure><p id="a778" class="pw-post-body-paragraph ld le it lf b lg lh kd li lj lk kg ll lm ln lo lp lq lr ls lt lu lv lw lx ly im bi translated">将数据标绘为良性(蓝色)和恶性(紫色)，未标记的数据点以红色显示。</p><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div class="gh gi qg"><img src="../Images/e66cab6d4112bd9ce790a11f02ade394.png" data-original-src="https://miro.medium.com/v2/resize:fit:1334/format:webp/1*h73D6Il9uMGHFAlzqGt90w.png"/></div></figure><p id="e14f" class="pw-post-body-paragraph ld le it lf b lg lh kd li lj lk kg ll lm ln lo lp lq lr ls lt lu lv lw lx ly im bi translated">在执行算法之后，数据点可以被视为良性家族的一部分。</p><p id="a962" class="pw-post-body-paragraph ld le it lf b lg lh kd li lj lk kg ll lm ln lo lp lq lr ls lt lu lv lw lx ly im bi translated"><strong class="lf jd">代码可在:</strong>找到</p><div class="pe pf gp gr pg ph"><a href="https://github.com/dakshtrehan/KNN-on-Breast-Cancer" rel="noopener  ugc nofollow" target="_blank"><div class="pi ab fo"><div class="pj ab pk cl cj pl"><h2 class="bd jd gy z fp pm fr fs pn fu fw jc bi translated">乳腺癌患者达赫施特莱汉/KNN</h2><div class="po l"><h3 class="bd b gy z fp pm fr fs pn fu fw dk translated">此时您不能执行该操作。您已使用另一个标签页或窗口登录。您已在另一个选项卡中注销，或者…</h3></div><div class="pp l"><p class="bd b dl z fp pm fr fs pn fu fw dk translated">github.com</p></div></div><div class="pq l"><div class="qh l ps pt pu pq pv lb ph"/></div></div></a></div><h2 id="d7ca" class="qi ma it bd mb qj qk dn mf ql qm dp mj lm qn qo ml lq qp qq mn lu qr qs mp iz bi translated"><strong class="ak">使用sci-kit learn执行KNN</strong></h2><figure class="ks kt ku kv gt kw"><div class="bz fp l di"><div class="px py l"/></div></figure></div><div class="ab cl nz oa hx ob" role="separator"><span class="oc bw bk od oe of"/><span class="oc bw bk od oe of"/><span class="oc bw bk od oe"/></div><div class="im in io ip iq"><h1 id="f240" class="lz ma it bd mb mc og me mf mg oh mi mj ki oi kj ml kl oj km mn ko ok kp mp mq bi translated">KNN的利与弊</h1><h2 id="c5a8" class="qi ma it bd mb qj qk dn mf ql qm dp mj lm qn qo ml lq qp qq mn lu qr qs mp iz bi translated">优点:</h2><ol class=""><li id="72fe" class="mr ms it lf b lg mt lj mu lm mv lq mw lu mx ly my mz na nb bi translated">简单易行</li><li id="9c50" class="mr ms it lf b lg nd lj ne lm nf lq ng lu nh ly my mz na nb bi translated">训练时间低。</li><li id="9962" class="mr ms it lf b lg nd lj ne lm nf lq ng lu nh ly my mz na nb bi translated">对有噪声的训练数据稳健。</li></ol><h2 id="45bc" class="qi ma it bd mb qj qk dn mf ql qm dp mj lm qn qo ml lq qp qq mn lu qr qs mp iz bi translated">缺点:</h2><ol class=""><li id="d75f" class="mr ms it lf b lg mt lj mu lm mv lq mw lu mx ly my mz na nb bi translated">确定完美的“K”是乏味的。</li><li id="80eb" class="mr ms it lf b lg nd lj ne lm nf lq ng lu nh ly my mz na nb bi translated">大量存储需求。</li><li id="af1e" class="mr ms it lf b lg nd lj ne lm nf lq ng lu nh ly my mz na nb bi translated">对异常值敏感。</li><li id="7c54" class="mr ms it lf b lg nd lj ne lm nf lq ng lu nh ly my mz na nb bi translated">最不精确的算法。</li></ol></div><div class="ab cl nz oa hx ob" role="separator"><span class="oc bw bk od oe of"/><span class="oc bw bk od oe of"/><span class="oc bw bk od oe"/></div><div class="im in io ip iq"><h1 id="86b5" class="lz ma it bd mb mc og me mf mg oh mi mj ki oi kj ml kl oj km mn ko ok kp mp mq bi translated">结论</h1><p id="8b28" class="pw-post-body-paragraph ld le it lf b lg mt kd li lj mu kg ll lm ni lo lp lq nj ls lt lu nk lw lx ly im bi translated">希望这篇文章能帮助你更好地理解KNN，也能帮助你实际运用它。</p><p id="dee6" class="pw-post-body-paragraph ld le it lf b lg lh kd li lj lk kg ll lm ln lo lp lq lr ls lt lu lv lw lx ly im bi translated">一如既往，非常感谢你的阅读，如果你觉得这篇文章有用，请分享！</p></div><div class="ab cl nz oa hx ob" role="separator"><span class="oc bw bk od oe of"/><span class="oc bw bk od oe of"/><span class="oc bw bk od oe"/></div><div class="im in io ip iq"><p id="ca23" class="pw-post-body-paragraph ld le it lf b lg lh kd li lj lk kg ll lm ln lo lp lq lr ls lt lu lv lw lx ly im bi translated">请随意连接:</p><blockquote class="qt qu qv"><p id="e2ee" class="ld le nc lf b lg lh kd li lj lk kg ll qw ln lo lp qx lr ls lt qy lv lw lx ly im bi translated"><em class="it">领英~</em><a class="ae nu" href="https://www.linkedin.com/in/dakshtrehan/" rel="noopener ugc nofollow" target="_blank">T3】https://www.linkedin.com/in/dakshtrehan/T5】</a></p><p id="9112" class="ld le nc lf b lg lh kd li lj lk kg ll qw ln lo lp qx lr ls lt qy lv lw lx ly im bi translated"><em class="it">insta gram ~</em><a class="ae nu" href="https://www.instagram.com/_daksh_trehan_/" rel="noopener ugc nofollow" target="_blank"><em class="it">https://www.instagram.com/_daksh_trehan_/</em></a></p><p id="a836" class="ld le nc lf b lg lh kd li lj lk kg ll qw ln lo lp qx lr ls lt qy lv lw lx ly im bi translated"><em class="it">Github ~</em><a class="ae nu" href="https://github.com/dakshtrehan" rel="noopener ugc nofollow" target="_blank">T15】https://github.com/dakshtrehan</a></p></blockquote><p id="2ce2" class="pw-post-body-paragraph ld le it lf b lg lh kd li lj lk kg ll lm ln lo lp lq lr ls lt lu lv lw lx ly im bi translated">关注更多机器学习/深度学习博客。</p><blockquote class="qt qu qv"><p id="28b4" class="ld le nc lf b lg lh kd li lj lk kg ll qw ln lo lp qx lr ls lt qy lv lw lx ly im bi translated"><em class="it">中等~</em><a class="ae nu" href="https://medium.com/@dakshtrehan" rel="noopener">【https://medium.com/@dakshtrehan】T21</a></p></blockquote><h2 id="151a" class="qi ma it bd mb qj qk dn mf ql qm dp mj lm qn qo ml lq qp qq mn lu qr qs mp iz bi translated">想了解更多？</h2><div class="pe pf gp gr pg ph"><a href="https://towardsdatascience.com/the-inescapable-ai-algorithm-tiktok-ad4c6fd981b8" rel="noopener follow" target="_blank"><div class="pi ab fo"><div class="pj ab pk cl cj pl"><h2 class="bd jd gy z fp pm fr fs pn fu fw jc bi translated">无法逃脱的人工智能算法:抖音</h2><div class="po l"><h3 class="bd b gy z fp pm fr fs pn fu fw dk translated">描述一个抖音用来吸引用户的渐进式推荐系统！</h3></div><div class="pp l"><p class="bd b dl z fp pm fr fs pn fu fw dk translated">towardsdatascience.com</p></div></div><div class="pq l"><div class="qz l ps pt pu pq pv lb ph"/></div></div></a></div><div class="pe pf gp gr pg ph"><a href="https://towardsdatascience.com/detecting-covid-19-using-deep-learning-262956b6f981" rel="noopener follow" target="_blank"><div class="pi ab fo"><div class="pj ab pk cl cj pl"><h2 class="bd jd gy z fp pm fr fs pn fu fw jc bi translated">使用深度学习检测新冠肺炎</h2><div class="po l"><h3 class="bd b gy z fp pm fr fs pn fu fw dk translated">一个实用的方法来帮助医生帮助我们对抗新冠肺炎</h3></div><div class="pp l"><p class="bd b dl z fp pm fr fs pn fu fw dk translated">towardsdatascience.com</p></div></div><div class="pq l"><div class="ra l ps pt pu pq pv lb ph"/></div></div></a></div><div class="pe pf gp gr pg ph"><a href="https://medium.com/@dakshtrehan/why-are-you-responsible-for-george-floyds-murder-delhi-communal-riots-4c1edb7acbc5" rel="noopener follow" target="_blank"><div class="pi ab fo"><div class="pj ab pk cl cj pl"><h2 class="bd jd gy z fp pm fr fs pn fu fw jc bi translated">为什么你要为乔治·弗洛伊德的谋杀和德里社区骚乱负责！！</h2><div class="po l"><h3 class="bd b gy z fp pm fr fs pn fu fw dk translated">一个ML爱好者改变世界的方法。</h3></div><div class="pp l"><p class="bd b dl z fp pm fr fs pn fu fw dk translated">medium.com</p></div></div><div class="pq l"><div class="rb l ps pt pu pq pv lb ph"/></div></div></a></div><div class="pe pf gp gr pg ph"><a href="https://medium.com/swlh/things-you-never-knew-about-naive-bayes-eb84b6ee039a" rel="noopener follow" target="_blank"><div class="pi ab fo"><div class="pj ab pk cl cj pl"><h2 class="bd jd gy z fp pm fr fs pn fu fw jc bi translated">关于朴素贝叶斯你不知道的事情！！</h2><div class="po l"><h3 class="bd b gy z fp pm fr fs pn fu fw dk translated">朴素贝叶斯快速指南，帮助你开发垃圾邮件过滤系统！</h3></div><div class="pp l"><p class="bd b dl z fp pm fr fs pn fu fw dk translated">medium.com</p></div></div><div class="pq l"><div class="rc l ps pt pu pq pv lb ph"/></div></div></a></div><div class="pe pf gp gr pg ph"><a href="https://medium.com/analytics-vidhya/activation-functions-explained-8690ea7bdec9" rel="noopener follow" target="_blank"><div class="pi ab fo"><div class="pj ab pk cl cj pl"><h2 class="bd jd gy z fp pm fr fs pn fu fw jc bi translated">解释激活功能</h2><div class="po l"><h3 class="bd b gy z fp pm fr fs pn fu fw dk translated">阶跃，Sigmoid，双曲正切，Softmax，ReLU，Leaky ReLU解释</h3></div><div class="pp l"><p class="bd b dl z fp pm fr fs pn fu fw dk translated">medium.com</p></div></div><div class="pq l"><div class="rd l ps pt pu pq pv lb ph"/></div></div></a></div><div class="pe pf gp gr pg ph"><a href="https://towardsdatascience.com/parameters-optimization-explained-876561853de0" rel="noopener follow" target="_blank"><div class="pi ab fo"><div class="pj ab pk cl cj pl"><h2 class="bd jd gy z fp pm fr fs pn fu fw jc bi translated">解释参数优化</h2><div class="po l"><h3 class="bd b gy z fp pm fr fs pn fu fw dk translated">梯度下降的简要描述指南，ADAM，ADAGRAD，RMSProp</h3></div><div class="pp l"><p class="bd b dl z fp pm fr fs pn fu fw dk translated">towardsdatascience.com</p></div></div><div class="pq l"><div class="re l ps pt pu pq pv lb ph"/></div></div></a></div><div class="pe pf gp gr pg ph"><a href="https://towardsdatascience.com/gradient-descent-explained-9b953fc0d2c" rel="noopener follow" target="_blank"><div class="pi ab fo"><div class="pj ab pk cl cj pl"><h2 class="bd jd gy z fp pm fr fs pn fu fw jc bi translated">梯度下降解释</h2><div class="po l"><h3 class="bd b gy z fp pm fr fs pn fu fw dk translated">梯度下降综合指南</h3></div><div class="pp l"><p class="bd b dl z fp pm fr fs pn fu fw dk translated">towardsdatascience.com</p></div></div><div class="pq l"><div class="rf l ps pt pu pq pv lb ph"/></div></div></a></div><div class="pe pf gp gr pg ph"><a href="https://towardsdatascience.com/logistic-regression-explained-ef1d816ea85a" rel="noopener follow" target="_blank"><div class="pi ab fo"><div class="pj ab pk cl cj pl"><h2 class="bd jd gy z fp pm fr fs pn fu fw jc bi translated">逻辑回归解释</h2><div class="po l"><h3 class="bd b gy z fp pm fr fs pn fu fw dk translated">尽可能简单地解释逻辑回归。</h3></div><div class="pp l"><p class="bd b dl z fp pm fr fs pn fu fw dk translated">towardsdatascience.com</p></div></div><div class="pq l"><div class="rg l ps pt pu pq pv lb ph"/></div></div></a></div><div class="pe pf gp gr pg ph"><a href="https://medium.com/towards-artificial-intelligence/linear-regression-explained-f5cc85ae2c5c" rel="noopener follow" target="_blank"><div class="pi ab fo"><div class="pj ab pk cl cj pl"><h2 class="bd jd gy z fp pm fr fs pn fu fw jc bi translated">线性回归解释</h2><div class="po l"><h3 class="bd b gy z fp pm fr fs pn fu fw dk translated">尽可能简单地解释线性回归。</h3></div><div class="pp l"><p class="bd b dl z fp pm fr fs pn fu fw dk translated">medium.com</p></div></div><div class="pq l"><div class="rh l ps pt pu pq pv lb ph"/></div></div></a></div><div class="pe pf gp gr pg ph"><a href="https://medium.com/datadriveninvestor/determining-perfect-fit-for-your-ml-model-339459eef670" rel="noopener follow" target="_blank"><div class="pi ab fo"><div class="pj ab pk cl cj pl"><h2 class="bd jd gy z fp pm fr fs pn fu fw jc bi translated">确定最适合您的ML模型。</h2><div class="po l"><h3 class="bd b gy z fp pm fr fs pn fu fw dk translated">以最简单的方式教授过度拟合与欠拟合以及完美拟合。</h3></div><div class="pp l"><p class="bd b dl z fp pm fr fs pn fu fw dk translated">medium.com</p></div></div><div class="pq l"><div class="pr l ps pt pu pq pv lb ph"/></div></div></a></div><div class="pe pf gp gr pg ph"><a href="https://levelup.gitconnected.com/relating-machine-learning-techniques-to-real-life-4dafd626fdff" rel="noopener  ugc nofollow" target="_blank"><div class="pi ab fo"><div class="pj ab pk cl cj pl"><h2 class="bd jd gy z fp pm fr fs pn fu fw jc bi translated">将机器学习技术与现实生活联系起来。</h2><div class="po l"><h3 class="bd b gy z fp pm fr fs pn fu fw dk translated">尽可能简单地解释ML模型的类型。</h3></div><div class="pp l"><p class="bd b dl z fp pm fr fs pn fu fw dk translated">levelup.gitconnected.com</p></div></div><div class="pq l"><div class="ri l ps pt pu pq pv lb ph"/></div></div></a></div><div class="pe pf gp gr pg ph"><a href="https://medium.com/towards-artificial-intelligence/serving-data-science-to-a-rookie-b03af9ea99a2" rel="noopener follow" target="_blank"><div class="pi ab fo"><div class="pj ab pk cl cj pl"><h2 class="bd jd gy z fp pm fr fs pn fu fw jc bi translated">为新手提供数据科学服务</h2><div class="po l"><h3 class="bd b gy z fp pm fr fs pn fu fw dk translated">所以，上周我的团队负责人让我面试一些可能加入团队的实习生，了解数据的作用…</h3></div><div class="pp l"><p class="bd b dl z fp pm fr fs pn fu fw dk translated">medium.com</p></div></div><div class="pq l"><div class="rj l ps pt pu pq pv lb ph"/></div></div></a></div><blockquote class="qt qu qv"><p id="9fec" class="ld le nc lf b lg lh kd li lj lk kg ll qw ln lo lp qx lr ls lt qy lv lw lx ly im bi translated">干杯</p></blockquote></div></div>    
</body>
</html>