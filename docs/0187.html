<html>
<head>
<title>Training a Machine Learning Model on a Dataset with Highly-Correlated Features</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">在具有高度相关特征的数据集上训练机器学习模型</h1>
<blockquote>原文：<a href="https://pub.towardsai.net/training-a-machine-learning-model-on-a-dataset-with-highly-correlated-features-debddf5b2e34?source=collection_archive---------0-----------------------#2019-10-21">https://pub.towardsai.net/training-a-machine-learning-model-on-a-dataset-with-highly-correlated-features-debddf5b2e34?source=collection_archive---------0-----------------------#2019-10-21</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><h2 id="be57" class="ir is it bd b dl iu iv iw ix iy iz dk ja translated" aria-label="kicker paragraph"><a class="ae ep" href="https://towardsai.net/p/category/machine-learning" rel="noopener ugc nofollow" target="_blank">机器学习</a></h2><div class=""/><figure class="gl gn ka kb kc kd gh gi paragraph-image"><div role="button" tabindex="0" class="ke kf di kg bf kh"><div class="gh gi jz"><img src="../Images/5f8904fa88a51a041570c8afd4bf0a0f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*QNyewXdJEuUZImWdWhvEow.png"/></div></div></figure><p id="67b9" class="pw-post-body-paragraph kk kl it km b kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh im bi translated">在上一篇文章中(<a class="ae li" href="https://medium.com/towards-artificial-intelligence/feature-selection-and-dimensionality-reduction-using-covariance-matrix-plot-b4c7498abd07" rel="noopener"> <strong class="km jd">使用协方差矩阵图进行特征选择和降维</strong> </a>)，我们已经展示了协方差矩阵图可以用于特征选择和降维。</p><p id="9aa7" class="pw-post-body-paragraph kk kl it km b kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh im bi translated">使用游轮数据集<a class="ae li" href="https://github.com/bot13956/ML_Model_for_Predicting_Ships_Crew_Size" rel="noopener ugc nofollow" target="_blank"><strong class="km jd">cruise _ ship _ info . CSV</strong></a><strong class="km jd">，</strong>我们发现，在6个预测特征[' <strong class="km jd">年龄</strong>'、<strong class="km jd">吨位</strong>'、<strong class="km jd">乘客</strong>'、<strong class="km jd">长度</strong>'、<strong class="km jd">舱室</strong>、<strong class="km jd">乘客密度</strong> ]中，如果我们假设重要特征具有相关系数 那么目标变量“<strong class="km jd">乘员</strong>”与4个预测变量:“<strong class="km jd">吨位</strong>”、“<strong class="km jd">乘客</strong>”、“<strong class="km jd">长度</strong>、“<strong class="km jd">车厢</strong>”强相关。</p><p id="48dc" class="pw-post-body-paragraph kk kl it km b kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh im bi translated">因此，我们能够将特征空间的维数从6降低到4。</p><p id="a84e" class="pw-post-body-paragraph kk kl it km b kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh im bi translated">现在，假设我们想在新的特征空间上建立一个模型来预测船员变量。我们的模型可以用以下形式表示:</p><figure class="lk ll lm ln gt kd gh gi paragraph-image"><div class="gh gi lj"><img src="../Images/d379c0c995273110b909feb13ddc71f1.png" data-original-src="https://miro.medium.com/v2/resize:fit:696/format:webp/1*5qXwU2YSoud3enwLQpODNw.png"/></div></figure><p id="7c27" class="pw-post-body-paragraph kk kl it km b kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh im bi translated">其中<strong class="km jd"> X </strong>为特征矩阵，<strong class="km jd"> w </strong>为训练时需要学习的权重。</p><p id="e1b4" class="pw-post-body-paragraph kk kl it km b kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh im bi translated">查看特征之间的协方差矩阵图，我们发现特征(预测变量)之间有很强的相关性，见上图。</p><h1 id="c9de" class="lo lp it bd lq lr ls lt lu lv lw lx ly lz ma mb mc md me mf mg mh mi mj mk ml bi translated">我们如何处理特征之间的相关性问题？</h1><p id="2c7a" class="pw-post-body-paragraph kk kl it km b kn mm kp kq kr mn kt ku kv mo kx ky kz mp lb lc ld mq lf lg lh im bi translated">在本文中，我们将使用一种称为<strong class="km jd">主成分分析(PCA) </strong>的技术将我们的特征转换到特征独立或不相关的空间中。然后，我们将在PCA空间上训练我们的模型。你可以从这篇文章中了解到更多关于PCA的知识:<a class="ae li" href="https://medium.com/towards-artificial-intelligence/machine-learning-dimensionality-reduction-via-principal-component-analysis-1bdc77462831" rel="noopener"> <strong class="km jd">机器学习:通过主成分分析进行降维</strong> </a> <strong class="km jd">。</strong></p><h1 id="8ed1" class="lo lp it bd lq lr ls lt lu lv lw lx ly lz ma mb mc md me mf mg mh mi mj mk ml bi translated">在PCA空间上训练模型</h1><h2 id="00be" class="mr lp it bd lq ms mt dn lu mu mv dp ly kv mw mx mc kz my mz mg ld na nb mk iz bi translated">1.导入必要的库</h2><pre class="lk ll lm ln gt nc nd ne nf aw ng bi"><span id="d12d" class="mr lp it nd b gy nh ni l nj nk">import numpy as np<br/>import pandas as pd<br/>import matplotlib.pyplot as plt<br/>import seaborn as sns</span></pre><h2 id="a499" class="mr lp it bd lq ms mt dn lu mu mv dp ly kv mw mx mc kz my mz mg ld na nb mk iz bi translated">2.读取数据集并显示列</h2><pre class="lk ll lm ln gt nc nd ne nf aw ng bi"><span id="174d" class="mr lp it nd b gy nh ni l nj nk">df=pd.read_csv("cruise_ship_info.csv")<br/>df.head()</span></pre><figure class="lk ll lm ln gt kd gh gi paragraph-image"><div class="gh gi nl"><img src="../Images/adf9217fbb37c2610b09bcc9463fec71.png" data-original-src="https://miro.medium.com/v2/resize:fit:1348/format:webp/0*VPJa5vaa-3sHFw1f.png"/></div></figure><h2 id="2183" class="mr lp it bd lq ms mt dn lu mu mv dp ly kv mw mx mc kz my mz mg ld na nb mk iz bi translated">3.选择重要变量(列)</h2><pre class="lk ll lm ln gt nc nd ne nf aw ng bi"><span id="c2d8" class="mr lp it nd b gy nh ni l nj nk">cols_selected = ['Tonnage', 'passengers', 'length', 'cabins','crew']<br/>  <br/>df[cols_selected].head()</span></pre><figure class="lk ll lm ln gt kd gh gi paragraph-image"><div role="button" tabindex="0" class="ke kf di kg bf kh"><div class="gh gi nm"><img src="../Images/2803e73669d8c11205dff39ff538c77f.png" data-original-src="https://miro.medium.com/v2/resize:fit:668/format:webp/0*EU3VtzUkm41x9pg2.png"/></div></div></figure><h2 id="6e4b" class="mr lp it bd lq ms mt dn lu mu mv dp ly kv mw mx mc kz my mz mg ld na nb mk iz bi translated">4.将数据划分为训练集和测试集</h2><pre class="lk ll lm ln gt nc nd ne nf aw ng bi"><span id="1e4e" class="mr lp it nd b gy nh ni l nj nk">from sklearn.model_selection import train_test_split<br/>X = df[cols_selected].iloc[:,0:4].values     <br/>y = df[cols_selected]['crew']</span><span id="48b1" class="mr lp it nd b gy nn ni l nj nk">X_train, X_test, y_train, y_test = train_test_split( X, y, test_size=0.4, random_state=0)</span></pre><h2 id="6bae" class="mr lp it bd lq ms mt dn lu mu mv dp ly kv mw mx mc kz my mz mg ld na nb mk iz bi translated">5.在PCA空间上建立多元线性回归模型</h2><pre class="lk ll lm ln gt nc nd ne nf aw ng bi"><span id="c341" class="mr lp it nd b gy nh ni l nj nk">from sklearn.preprocessing import StandardScaler<br/>from sklearn.decomposition import PCA<br/>from sklearn.linear_model import LinearRegression<br/>from sklearn.pipeline import Pipeline<br/>from sklearn.metrics import r2_score</span><span id="e34a" class="mr lp it nd b gy nn ni l nj nk">train_score = []<br/>test_score = []<br/>cum_variance = []</span><span id="f0ce" class="mr lp it nd b gy nn ni l nj nk">for i in range(1,5):<br/>    X_train, X_test, y_train, y_test = train_test_split( X, y, test_size=0.4, random_state=0)<br/>    y_train_std = sc_y.fit_transform(y_train[:, np.newaxis]).flatten()<br/>    <br/>    pipe_lr = Pipeline([('scl', StandardScaler()),<br/>                        ('pca', PCA(n_components=i)),<br/>                        ('slr',   LinearRegression())]) </span><span id="19f8" class="mr lp it nd b gy nn ni l nj nk">    pipe_lr.fit(X_train, y_train_std)</span><span id="e231" class="mr lp it nd b gy nn ni l nj nk">    y_train_pred_std = pipe_lr.predict(X_train)<br/>    y_test_pred_std = pipe_lr.predict(X_test)<br/>    y_train_pred=sc_y.inverse_transform(y_train_pred_std)<br/>    y_test_pred=sc_y.inverse_transform(y_test_pred_std)</span><span id="e35c" class="mr lp it nd b gy nn ni l nj nk">    train_score = np.append(train_score, <br/>                            r2_score(y_train, y_train_pred))</span><span id="e077" class="mr lp it nd b gy nn ni l nj nk">    test_score = np.append(test_score, <br/>                           r2_score(y_test, y_test_pred))</span><span id="23cc" class="mr lp it nd b gy nn ni l nj nk">    cum_variance = np.append(cum_variance, np.sum(pipe_lr.fit(X_train, y_train).named_steps['pca'].explained_variance_ratio_))</span></pre><p id="a82b" class="pw-post-body-paragraph kk kl it km b kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh im bi translated"><strong class="km jd">以下是PCA空间回归模型的输出:</strong></p><figure class="lk ll lm ln gt kd gh gi paragraph-image"><div role="button" tabindex="0" class="ke kf di kg bf kh"><div class="gh gi no"><img src="../Images/bfde40f6413d253e6a4aa83d83ffe75b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*c0Wui635Y8Rrk0fSCbG9tw.png"/></div></div><figcaption class="np nq gj gh gi nr ns bd b be z dk translated"><strong class="bd lq">组件重要性总结。</strong></figcaption></figure><p id="1536" class="pw-post-body-paragraph kk kl it km b kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh im bi translated">基于这一总结，我们看到95%的方差仅由第一主成分贡献。这意味着在最终模型中，只有第一主成分PC1可以被使用，因为其他3个成分PC2、PC3和PC4只贡献了总方差的大约5%。</p><p id="2ccd" class="pw-post-body-paragraph kk kl it km b kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh im bi translated">PCA降维对于具有4个特征的数据集来说似乎没什么大不了的，但是对于具有数百甚至数千个特征的复杂数据集来说，PCA可以是一个强大的工具，可用于移除特征之间的相关性，并有助于减少模型训练、测试和评估的计算时间。</p><p id="11ba" class="pw-post-body-paragraph kk kl it km b kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh im bi translated">总之，我们已经展示了如何使用python的sklearn包和游轮数据集实现PCA算法。主成分分析是一种非常强大的建模工具，尤其是在处理具有高度相关特征的复杂数据集时。您可以在<a class="ae li" href="https://github.com/bot13956/ML_Model_for_Predicting_Ships_Crew_Size" rel="noopener ugc nofollow" target="_blank"> <strong class="km jd"> Github </strong> </a>上下载本文的完整数据集和代码。</p><h1 id="f18a" class="lo lp it bd lq lr ls lt lu lv lw lx ly lz ma mb mc md me mf mg mh mi mj mk ml bi translated">参考</h1><ol class=""><li id="ee8b" class="nt nu it km b kn mm kr mn kv nv kz nw ld nx lh ny nz oa ob bi translated">拉什卡、塞巴斯蒂安和瓦希德·米尔贾利利<strong class="km jd">。</strong> <em class="oc"> Python机器学习，第二版</em>。Packt出版公司，2017年。</li><li id="2133" class="nt nu it km b kn od kr oe kv of kz og ld oh lh ny nz oa ob bi translated">Benjamin O. Tayo，<em class="oc">预测船只船员规模的机器学习模型</em>，<a class="ae li" href="https://github.com/bot13956/ML_Model_for_Predicting_Ships_Crew_Size" rel="noopener ugc nofollow" target="_blank">https://github . com/bot 13956/ML _ Model _ for _ Predicting _ Ships _ Crew _ Size</a>。</li></ol></div></div>    
</body>
</html>