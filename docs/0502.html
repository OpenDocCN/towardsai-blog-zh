<html>
<head>
<title>NLP News Cypher | 05.17.20</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">NLP新闻密码| 05.17.20</h1>
<blockquote>原文：<a href="https://pub.towardsai.net/nlp-news-cypher-05-17-20-5363293883e1?source=collection_archive---------2-----------------------#2020-05-17">https://pub.towardsai.net/nlp-news-cypher-05-17-20-5363293883e1?source=collection_archive---------2-----------------------#2020-05-17</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><figure class="ip iq gp gr ir is gh gi paragraph-image"><div role="button" tabindex="0" class="it iu di iv bf iw"><div class="gh gi io"><img src="../Images/ac323a2a8b04dbd024d5ec9d38783371.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*Hnicb-xOuHIs9wG6"/></div></div><figcaption class="iz ja gj gh gi jb jc bd b be z dk translated">谢莉·泰在<a class="ae jd" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上拍摄的照片</figcaption></figure><h2 id="aef6" class="je jf jg bd b dl jh ji jj jk jl jm dk jn translated" aria-label="kicker paragraph">自然语言处理每周时事通讯</h2><div class=""/><div class=""><h2 id="4f01" class="pw-subtitle-paragraph km jp jg bd b kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld dk translated">绿洲</h2></div></div><div class="ab cl le lf hu lg" role="separator"><span class="lh bw bk li lj lk"/><span class="lh bw bk li lj lk"/><span class="lh bw bk li lj"/></div><div class="ij ik il im in"><p id="7825" class="pw-post-body-paragraph ll lm jg ln b lo lp kq lq lr ls kt lt lu lv lw lx ly lz ma mb mc md me mf mg ij bi mh translated">你可能已经听说了，埃隆·马斯克不太高兴。当脸书的人工智能负责人杰罗姆·派森蒂决定通过<a class="ae jd" href="https://threader.app/conversation/1260493713924595716/nnkc3Ldm7g" rel="noopener ugc nofollow" target="_blank">在Twitter上就马斯克的人工智能知识呼吁</a>来火上浇油时，这也于事无补:</p><h2 id="e137" class="mq mr jg bd ms mt mu dn mv mw mx dp my lu mz na nb ly nc nd ne mc nf ng nh jm bi translated">😈牛肉丝😈</h2><h2 id="99e4" class="mq mr jg bd ms mt mu dn mv mw mx dp my lu mz na nb ly nc nd ne mc nf ng nh jm bi translated"><a class="ae jd" href="https://twitter.com/intent/user?screen_name=an_open_mind" rel="noopener ugc nofollow" target="_blank"> <strong class="ak">杰罗姆·佩森蒂</strong> </a> @an_open_mind</h2><p id="b91a" class="pw-post-body-paragraph ll lm jg ln b lo ni kq lq lr nj kt lt lu nk lw lx ly nl ma mb mc nm me mf mg ij bi translated">我相信AI社区中的很多人都可以公开说出来。<a class="ae jd" href="https://twitter.com/elonmusk" rel="noopener ugc nofollow" target="_blank"> @elonmusk </a>一说起AI就不知道自己在说什么。根本没有AGI这种东西，我们也远没有达到人类的智力水平。<a class="ae jd" href="https://threader.app/hashtag/noAGI" rel="noopener ugc nofollow" target="_blank">#诺阿吉</a></p><p id="96f4" class="pw-post-body-paragraph ll lm jg ln b lo lp kq lq lr ls kt lt lu lv lw lx ly lz ma mb mc md me mf mg ij bi">👇</p><h2 id="ee46" class="mq mr jg bd ms mt mu dn mv mw mx dp my lu mz na nb ly nc nd ne mc nf ng nh jm bi translated"><a class="ae jd" href="https://twitter.com/intent/user?screen_name=elonmusk" rel="noopener ugc nofollow" target="_blank"> <strong class="ak">埃隆马斯克</strong></a>@埃隆马斯克</h2><p id="3f73" class="pw-post-body-paragraph ll lm jg ln b lo ni kq lq lr nj kt lt lu nk lw lx ly nl ma mb mc nm me mf mg ij bi translated">脸书糟透了</p><p id="01d6" class="pw-post-body-paragraph ll lm jg ln b lo lp kq lq lr ls kt lt lu lv lw lx ly lz ma mb mc md me mf mg ij bi">👇</p><h2 id="0c57" class="mq mr jg bd ms mt mu dn mv mw mx dp my lu mz na nb ly nc nd ne mc nf ng nh jm bi translated"><a class="ae jd" href="https://twitter.com/intent/user?screen_name=ylecun" rel="noopener ugc nofollow" target="_blank"><strong class="ak">Yann le Cun</strong></a>@ y LeCun</h2><p id="9544" class="pw-post-body-paragraph ll lm jg ln b lo ni kq lq lr nj kt lt lu nk lw lx ly nl ma mb mc nm me mf mg ij bi translated">特斯拉工程师和科学家会问“我们还能用PyTorch吗？”<br/><a class="ae jd" href="https://youtu.be/oBklltKXtDE" rel="noopener ugc nofollow" target="_blank">https://youtu.be/oBklltKXtDE</a></p><p id="f5cc" class="pw-post-body-paragraph ll lm jg ln b lo lp kq lq lr ls kt lt lu lv lw lx ly lz ma mb mc md me mf mg ij bi">👇</p><h2 id="5f38" class="mq mr jg bd ms mt mu dn mv mw mx dp my lu mz na nb ly nc nd ne mc nf ng nh jm bi translated"><a class="ae jd" href="https://twitter.com/intent/user?screen_name=elonmusk" rel="noopener ugc nofollow" target="_blank"> <strong class="ak">埃隆马斯克</strong></a>@埃隆马斯克</h2><p id="39f4" class="pw-post-body-paragraph ll lm jg ln b lo ni kq lq lr nj kt lt lu nk lw lx ly nl ma mb mc nm me mf mg ij bi translated">公平点，PyTorch很棒！</p><p id="4a75" class="pw-post-body-paragraph ll lm jg ln b lo lp kq lq lr ls kt lt lu lv lw lx ly lz ma mb mc md me mf mg ij bi translated"><em class="nn">结束</em></p><p id="9f9a" class="pw-post-body-paragraph ll lm jg ln b lo lp kq lq lr ls kt lt lu lv lw lx ly lz ma mb mc md me mf mg ij bi translated">扎克是这样的:</p><figure class="no np nq nr gt is"><div class="bz fp l di"><div class="ns nt l"/></div><figcaption class="iz ja gj gh gi jb jc bd b be z dk translated">解密的</figcaption></figure><p id="d0b4" class="pw-post-body-paragraph ll lm jg ln b lo lp kq lq lr ls kt lt lu lv lw lx ly lz ma mb mc md me mf mg ij bi translated">与此同时，NVIDIA首席执行官黄先生(和他的皮夹克)在厨房发表了有史以来第一次主题演讲:</p><figure class="no np nq nr gt is"><div class="bz fp l di"><div class="nu nt l"/></div></figure><p id="21ae" class="pw-post-body-paragraph ll lm jg ln b lo lp kq lq lr ls kt lt lu lv lw lx ly lz ma mb mc md me mf mg ij bi translated">仅供参考，在过去的一周，我们发布了另一套笔记本电脑的超级骗子NLP回购！感谢所有贡献者:阿迪蒂亚·马尔特、卡皮尔·肖汉、维塞尔·科贾曼和萨亚克·保罗。😎</p><div class="ip iq gp gr ir nv"><a href="https://notebooks.quantumstat.com" rel="noopener  ugc nofollow" target="_blank"><div class="nw ab fo"><div class="nx ab ny cl cj nz"><h2 class="bd jq gy z fp oa fr fs ob fu fw jp bi translated">超级骗子NLP回购</h2><div class="oc l"><h3 class="bd b gy z fp oa fr fs ob fu fw dk translated">适用于NLP中各种任务的Colab笔记本</h3></div><div class="od l"><p class="bd b dl z fp oa fr fs ob fu fw dk translated">notebooks.quantumstat.com</p></div></div><div class="oe l"><div class="of l og oh oi oe oj ix nv"/></div></div></a></div><p id="f1ae" class="pw-post-body-paragraph ll lm jg ln b lo lp kq lq lr ls kt lt lu lv lw lx ly lz ma mb mc md me mf mg ij bi translated">附言——不要点这个🧐:</p><div class="ip iq gp gr ir nv"><a href="http://telehack.com/" rel="noopener  ugc nofollow" target="_blank"><div class="nw ab fo"><div class="nx ab ny cl cj nz"><h2 class="bd jq gy z fp oa fr fs ob fu fw jp bi translated">远程黑客</h2><div class="oc l"><h3 class="bd b gy z fp oa fr fs ob fu fw dk">?</h3></div><div class="od l"><p class="bd b dl z fp oa fr fs ob fu fw dk translated">telehack.com</p></div></div></div></a></div></div><div class="ab cl le lf hu lg" role="separator"><span class="lh bw bk li lj lk"/><span class="lh bw bk li lj lk"/><span class="lh bw bk li lj"/></div><div class="ij ik il im in"><h1 id="da33" class="ok mr jg bd ms ol om on mv oo op oq my kv or kw nb ky os kz ne lb ot lc nh ou bi translated">本周:</h1><blockquote class="ov ow ox"><p id="d7c0" class="ll lm nn ln b lo lp kq lq lr ls kt lt oy lv lw lx oz lz ma mb pa md me mf mg ij bi translated">流量管</p><p id="6ade" class="ll lm nn ln b lo lp kq lq lr ls kt lt oy lv lw lx oz lz ma mb pa md me mf mg ij bi translated">嵌套JSON</p><p id="c21f" class="ll lm nn ln b lo lp kq lq lr ls kt lt oy lv lw lx oz lz ma mb pa md me mf mg ij bi translated">可视化人工智能模型训练</p><p id="6a5a" class="ll lm nn ln b lo lp kq lq lr ls kt lt oy lv lw lx oz lz ma mb pa md me mf mg ij bi translated">DrKIT</p><p id="1c1c" class="ll lm nn ln b lo lp kq lq lr ls kt lt oy lv lw lx oz lz ma mb pa md me mf mg ij bi translated">课文2关于中央处理器的演讲</p><p id="3ade" class="ll lm nn ln b lo lp kq lq lr ls kt lt oy lv lw lx oz lz ma mb pa md me mf mg ij bi translated">T5激发了巴特的疑问</p><p id="933c" class="ll lm nn ln b lo lp kq lq lr ls kt lt oy lv lw lx oz lz ma mb pa md me mf mg ij bi translated">本周实验室:T5调谐🔥🔥</p><p id="080b" class="ll lm nn ln b lo lp kq lq lr ls kt lt oy lv lw lx oz lz ma mb pa md me mf mg ij bi translated">CMUs ML视频集合</p><p id="8b8e" class="ll lm nn ln b lo lp kq lq lr ls kt lt oy lv lw lx oz lz ma mb pa md me mf mg ij bi translated">本周数据集:街景文本(SVT)</p></blockquote></div><div class="ab cl le lf hu lg" role="separator"><span class="lh bw bk li lj lk"/><span class="lh bw bk li lj lk"/><span class="lh bw bk li lj"/></div><div class="ij ik il im in"><h1 id="817a" class="ok mr jg bd ms ol om on mv oo op oq my kv or kw nb ky os kz ne lb ot lc nh ou bi translated">流量管</h1><p id="da42" class="pw-post-body-paragraph ll lm jg ln b lo ni kq lq lr nj kt lt lu nk lw lx ly nl ma mb mc nm me mf mg ij bi translated">你可能已经使用了在超级Duper NLP Repo中找到的Tacotron模型进行文本2语音实验。现在NVIDIA发布了FlowTron，它有自己的可控风格调制。事实上，如果你听到上面黄视频中的主题旁白，FlowTron就是正在使用的模型。如果有兴趣，可以看看他们的博客页面，上面展示了Tacotron 2的各种风格演示。</p><p id="4a3a" class="pw-post-body-paragraph ll lm jg ln b lo lp kq lq lr ls kt lt lu lv lw lx ly lz ma mb mc md me mf mg ij bi translated"><strong class="ln jq">博客</strong>:</p><div class="ip iq gp gr ir nv"><a href="https://nv-adlr.github.io/Flowtron" rel="noopener  ugc nofollow" target="_blank"><div class="nw ab fo"><div class="nx ab ny cl cj nz"><h2 class="bd jq gy z fp oa fr fs ob fu fw jp bi translated">Flowtron:基于自回归流的文本语音合成生成网络</h2><div class="oc l"><h3 class="bd b gy z fp oa fr fs ob fu fw dk translated">LJ speech Ground Truth flow tron taco tron 2音频不支持音频不支持音频不支持Flowtron we…</h3></div><div class="od l"><p class="bd b dl z fp oa fr fs ob fu fw dk translated">nv-adlr.github.io</p></div></div><div class="oe l"><div class="pb l og oh oi oe oj ix nv"/></div></div></a></div><p id="68eb" class="pw-post-body-paragraph ll lm jg ln b lo lp kq lq lr ls kt lt lu lv lw lx ly lz ma mb mc md me mf mg ij bi translated"><strong class="ln jq"> GitHub </strong>:</p><div class="ip iq gp gr ir nv"><a href="https://github.com/NVIDIA/flowtron" rel="noopener  ugc nofollow" target="_blank"><div class="nw ab fo"><div class="nx ab ny cl cj nz"><h2 class="bd jq gy z fp oa fr fs ob fu fw jp bi translated">NVIDIA/flowtron</h2><div class="oc l"><h3 class="bd b gy z fp oa fr fs ob fu fw dk translated">在我们最近的论文中，我们提出了Flowtron:一个基于自回归流的生成网络，用于文本到语音合成…</h3></div><div class="od l"><p class="bd b dl z fp oa fr fs ob fu fw dk translated">github.com</p></div></div><div class="oe l"><div class="pc l og oh oi oe oj ix nv"/></div></div></a></div><h1 id="5a4f" class="ok mr jg bd ms ol pd on mv oo pe oq my kv pf kw nb ky pg kz ne lb ph lc nh ou bi translated">嵌套JSON</h1><p id="2ca9" class="pw-post-body-paragraph ll lm jg ln b lo ni kq lq lr nj kt lt lu nk lw lx ly nl ma mb mc nm me mf mg ij bi translated">这些JSON记录很快就会变得错综复杂，尤其是如果两个对象共享同一个键，比如人的“name”和公司名称的“name”。下面是一个快速浏览嵌套JSON数据的指南，它有一个隔离正确键的功能，给了我们所有人一个新的希望。😁</p><div class="ip iq gp gr ir nv"><a href="https://bcmullins.github.io/parsing-json-python/" rel="noopener  ugc nofollow" target="_blank"><div class="nw ab fo"><div class="nx ab ny cl cj nz"><h2 class="bd jq gy z fp oa fr fs ob fu fw jp bi translated">用Python解析嵌套的JSON记录</h2><div class="oc l"><h3 class="bd b gy z fp oa fr fs ob fu fw dk translated">JSON是web服务用于消息传递的典型格式，也是相对易读的。尽管…</h3></div><div class="od l"><p class="bd b dl z fp oa fr fs ob fu fw dk translated">bcmullins.github.io</p></div></div><div class="oe l"><div class="pi l og oh oi oe oj ix nv"/></div></div></a></div><h1 id="acb4" class="ok mr jg bd ms ol pd on mv oo pe oq my kv pf kw nb ky pg kz ne lb ph lc nh ou bi translated">可视化人工智能模型训练</h1><p id="a07c" class="pw-post-body-paragraph ll lm jg ln b lo ni kq lq lr nj kt lt lu nk lw lx ly nl ma mb mc nm me mf mg ij bi translated">标题说明了一切。这是一个一步一步的指南(w/Colab ),用于灌输重量和偏见可视化和拥抱脸的变形金刚库。在本例中，CoLA数据集上的DistilBERT用于观察Mathew的相关系数指标:</p><div class="ip iq gp gr ir nv"><a href="https://app.wandb.ai/jxmorris12/huggingface-demo/reports/A-Step-by-Step-Guide-to-Tracking-Hugging-Face-Model-Performance--VmlldzoxMDE2MTU" rel="noopener  ugc nofollow" target="_blank"><div class="nw ab fo"><div class="nx ab ny cl cj nz"><h2 class="bd jq gy z fp oa fr fs ob fu fw jp bi translated">跟踪拥抱脸模型性能的逐步指南</h2><div class="oc l"><h3 class="bd b gy z fp oa fr fs ob fu fw dk translated">本教程解释了如何训练一个模型(具体来说，一个NLP分类器)使用的权重和偏见和…</h3></div><div class="od l"><p class="bd b dl z fp oa fr fs ob fu fw dk translated">app.wandb.ai</p></div></div><div class="oe l"><div class="pj l og oh oi oe oj ix nv"/></div></div></a></div><h1 id="b8fe" class="ok mr jg bd ms ol pd on mv oo pe oq my kv pf kw nb ky pg kz ne lb ph lc nh ou bi translated">DrKIT</h1><p id="a111" class="pw-post-body-paragraph ll lm jg ln b lo ni kq lq lr nj kt lt lu nk lw lx ly nl ma mb mc nm me mf mg ij bi translated">搜索大量文档通常会导致多跳问题。通常，一个问题可能需要搜索知识库的多个区域才能准确回答查询。在这项工作中，CMU大学的作者试图梳理文档(像图表一样)，而不将文档转换成图表(将文档保持在原始状态)——这比知识图表更容易构建，并提供了一个主要的速度提升。</p><p id="6c1f" class="pw-post-body-paragraph ll lm jg ln b lo lp kq lq lr ls kt lt lu lv lw lx ly lz ma mb mc md me mf mg ij bi translated">表现如何？</p><p id="5448" class="pw-post-body-paragraph ll lm jg ln b lo lp kq lq lr ls kt lt lu lv lw lx ly lz ma mb mc md me mf mg ij bi translated">在MetaQA任务中:</p><blockquote class="ov ow ox"><p id="a894" class="ll lm nn ln b lo lp kq lq lr ls kt lt oy lv lw lx oz lz ma mb pa md me mf mg ij bi translated">该模型在2跳和3跳问题上分别比以前的最佳模型高出6%和9%，同时速度提高了10倍。<em class="jg">🔥🔥🔥🔥</em></p></blockquote><p id="4be6" class="pw-post-body-paragraph ll lm jg ln b lo lp kq lq lr ls kt lt lu lv lw lx ly lz ma mb mc md me mf mg ij bi translated">关于HotpotQA:</p><blockquote class="ov ow ox"><p id="9227" class="ll lm nn ln b lo lp kq lq lr ls kt lt oy lv lw lx oz lz ma mb pa md me mf mg ij bi translated">method牺牲了一些准确性(F1得分43比61 ),在速度方面提高了100倍。</p></blockquote><p id="d532" class="pw-post-body-paragraph ll lm jg ln b lo lp kq lq lr ls kt lt lu lv lw lx ly lz ma mb mc md me mf mg ij bi translated"><strong class="ln jq">博客</strong>:</p><div class="ip iq gp gr ir nv"><a href="https://blog.ml.cmu.edu/2020/05/15/differentiable-reasoning-over-text/" rel="noopener  ugc nofollow" target="_blank"><div class="nw ab fo"><div class="nx ab ny cl cj nz"><h2 class="bd jq gy z fp oa fr fs ob fu fw jp bi translated">文本上的微分推理</h2><div class="oc l"><h3 class="bd b gy z fp oa fr fs ob fu fw dk translated">我们都依赖搜索引擎来浏览每天发布的大量在线信息。现代搜索…</h3></div><div class="od l"><p class="bd b dl z fp oa fr fs ob fu fw dk translated">blog.ml.cmu.edu</p></div></div><div class="oe l"><div class="pk l og oh oi oe oj ix nv"/></div></div></a></div><p id="5b22" class="pw-post-body-paragraph ll lm jg ln b lo lp kq lq lr ls kt lt lu lv lw lx ly lz ma mb mc md me mf mg ij bi translated"><strong class="ln jq"> 16核CPU演示</strong>:</p><figure class="no np nq nr gt is gh gi paragraph-image"><div role="button" tabindex="0" class="it iu di iv bf iw"><div class="gh gi pl"><img src="../Images/8ce377415805446cf56cd09df7ee4a99.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*KHfezA3GQxDLGeaq.gif"/></div></div></figure><p id="7a74" class="pw-post-body-paragraph ll lm jg ln b lo lp kq lq lr ls kt lt lu lv lw lx ly lz ma mb mc md me mf mg ij bi translated"><strong class="ln jq">论文</strong>:</p><figure class="no np nq nr gt is"><div class="bz fp l di"><div class="pm nt l"/></div><figcaption class="iz ja gj gh gi jb jc bd b be z dk translated"><a class="ae jd" href="https://arxiv.org/pdf/2002.10640.pdf" rel="noopener ugc nofollow" target="_blank">链接</a></figcaption></figure><h1 id="0041" class="ok mr jg bd ms ol pd on mv oo pe oq my kv pf kw nb ky pg kz ne lb ph lc nh ou bi translated">课文2关于中央处理器的演讲</h1><p id="8803" class="pw-post-body-paragraph ll lm jg ln b lo ni kq lq lr nj kt lt lu nk lw lx ly nl ma mb mc nm me mf mg ij bi translated">来自脸书的新文本-2-语音模型可以在CPU上以500毫秒生成一秒钟的音频。此外，他们还包括风格嵌入，允许人工智能的声音模仿助理，柔软，快速，投影和正式的风格！</p><p id="67e1" class="pw-post-body-paragraph ll lm jg ln b lo lp kq lq lr ls kt lt lu lv lw lx ly lz ma mb mc md me mf mg ij bi translated">下面的链接里有演示演讲。坏消息是，这似乎不是开源的。😌</p><div class="ip iq gp gr ir nv"><a href="https://ai.facebook.com/blog/a-highly-efficient-real-time-text-to-speech-system-deployed-on-cpus/" rel="noopener  ugc nofollow" target="_blank"><div class="nw ab fo"><div class="nx ab ny cl cj nz"><h2 class="bd jq gy z fp oa fr fs ob fu fw jp bi translated">部署在CPU上的高效实时文本到语音转换系统</h2><div class="oc l"><h3 class="bd b gy z fp oa fr fs ob fu fw dk translated">脸书人工智能在CPU服务器上构建和部署了一个实时神经文本到语音转换系统，提供了业界领先的…</h3></div><div class="od l"><p class="bd b dl z fp oa fr fs ob fu fw dk translated">ai.facebook.com</p></div></div><div class="oe l"><div class="pn l og oh oi oe oj ix nv"/></div></div></a></div><h1 id="26b5" class="ok mr jg bd ms ol pd on mv oo pe oq my kv pf kw nb ky pg kz ne lb ph lc nh ou bi translated">T5激发了巴特的疑问</h1><p id="8031" class="pw-post-body-paragraph ll lm jg ln b lo ni kq lq lr nj kt lt lu nk lw lx ly nl ma mb mc nm me mf mg ij bi translated">因DrQA而出名的开放领域问答通常涉及两阶段模型方法，其中你搜索外部知识库(例如维基百科),然后使用另一个模型为查询检索数据。对于封闭领域的问答，就像小队任务一样，下游任务包括提供一个通用的预训练模型文本和一个问题，模型的任务是找到文本中的答案跨度。然而，在这个使用BART-large模型的回购中，Sewon Min使用了一个根据知识本身预先训练的模型，然后经过微调来回答问题！这种风格被称为开放域闭卷，其灵感来自下面的T5论文。直射🔥🔥。</p><p id="60e2" class="pw-post-body-paragraph ll lm jg ln b lo lp kq lq lr ls kt lt lu lv lw lx ly lz ma mb mc md me mf mg ij bi translated"><strong class="ln jq">巴特GitHub </strong>:</p><div class="ip iq gp gr ir nv"><a href="https://github.com/shmsw25/bart-closed-book-qa" rel="noopener  ugc nofollow" target="_blank"><div class="nw ab fo"><div class="nx ab ny cl cj nz"><h2 class="bd jq gy z fp oa fr fs ob fu fw jp bi translated">shmsw 25/Bart-闭卷-qa</h2><div class="oc l"><h3 class="bd b gy z fp oa fr fs ob fu fw dk translated">这是一个BART版本的序列到序列模型，用于闭卷设置中的开放域QA，基于PyTorch和…</h3></div><div class="od l"><p class="bd b dl z fp oa fr fs ob fu fw dk translated">github.com</p></div></div><div class="oe l"><div class="po l og oh oi oe oj ix nv"/></div></div></a></div><p id="9308" class="pw-post-body-paragraph ll lm jg ln b lo lp kq lq lr ls kt lt lu lv lw lx ly lz ma mb mc md me mf mg ij bi translated"><strong class="ln jq"> T5 GitHub </strong>:</p><div class="ip iq gp gr ir nv"><a href="https://github.com/google-research/google-research/tree/master/t5_closed_book_qa" rel="noopener  ugc nofollow" target="_blank"><div class="nw ab fo"><div class="nx ab ny cl cj nz"><h2 class="bd jq gy z fp oa fr fs ob fu fw jp bi translated">谷歌研究/谷歌研究</h2><div class="oc l"><h3 class="bd b gy z fp oa fr fs ob fu fw dk translated">这个库包含了复制实验的代码，你能把多少知识打包到…</h3></div><div class="od l"><p class="bd b dl z fp oa fr fs ob fu fw dk translated">github.com</p></div></div><div class="oe l"><div class="pp l og oh oi oe oj ix nv"/></div></div></a></div><p id="44c2" class="pw-post-body-paragraph ll lm jg ln b lo lp kq lq lr ls kt lt lu lv lw lx ly lz ma mb mc md me mf mg ij bi translated"><strong class="ln jq">纸基关T5 </strong>:</p><figure class="no np nq nr gt is"><div class="bz fp l di"><div class="pm nt l"/></div><figcaption class="iz ja gj gh gi jb jc bd b be z dk translated"><a class="ae jd" href="https://arxiv.org/pdf/2002.08910.pdf" rel="noopener ugc nofollow" target="_blank">链接</a></figcaption></figure><h1 id="a212" class="ok mr jg bd ms ol pd on mv oo pe oq my kv pf kw nb ky pg kz ne lb ph lc nh ou bi translated">本周实验室:T5调谐🔥🔥</h1><p id="b74a" class="pw-post-body-paragraph ll lm jg ln b lo ni kq lq lr nj kt lt lu nk lw lx ly nl ma mb mc nm me mf mg ij bi translated">学会用T5进行复习分类，情感分类，常识推断！</p><div class="ip iq gp gr ir nv"><a href="https://colab.research.google.com/drive/176NSaYjc2eeI-78oLH_F9-YV3po3qQQO" rel="noopener  ugc nofollow" target="_blank"><div class="nw ab fo"><div class="nx ab ny cl cj nz"><h2 class="bd jq gy z fp oa fr fs ob fu fw jp bi translated">谷歌联合实验室</h2><div class="oc l"><h3 class="bd b gy z fp oa fr fs ob fu fw dk translated">编辑描述</h3></div><div class="od l"><p class="bd b dl z fp oa fr fs ob fu fw dk translated">colab.research.google.com</p></div></div><div class="oe l"><div class="pq l og oh oi oe oj ix nv"/></div></div></a></div><h1 id="8372" class="ok mr jg bd ms ol pd on mv oo pe oq my kv pf kw nb ky pg kz ne lb ph lc nh ou bi translated">CMUs ML视频集合</h1><p id="b2bc" class="pw-post-body-paragraph ll lm jg ln b lo ni kq lq lr nj kt lt lu nk lw lx ly nl ma mb mc nm me mf mg ij bi translated">来自Graham Neubig，这个伟大的集合为您的机器学习启迪提供了24个讲座视频。当在第7个视频中讨论注意力时，你就知道这个系列是好的😁。在这些视频剪辑中，我们得到了从搜索树、文档级模型到机器阅读和NLG的一切:</p><figure class="no np nq nr gt is"><div class="bz fp l di"><div class="pr nt l"/></div></figure><h1 id="7b0a" class="ok mr jg bd ms ol pd on mv oo pe oq my kv pf kw nb ky pg kz ne lb ph lc nh ou bi translated">本周数据集:街景文本(SVT)</h1><h2 id="ad68" class="mq mr jg bd ms mt mu dn mv mw mx dp my lu mz na nb ly nc nd ne mc nf ng nh jm bi translated">这是什么？</h2><p id="97cc" class="pw-post-body-paragraph ll lm jg ln b lo ni kq lq lr nj kt lt lu nk lw lx ly nl ma mb mc nm me mf mg ij bi translated">数据集包含带有注释的街道场景图像，用于场景文本识别任务。</p><h2 id="0c2a" class="mq mr jg bd ms mt mu dn mv mw mx dp my lu mz na nb ly nc nd ne mc nf ng nh jm bi translated">样本:</h2><figure class="no np nq nr gt is gh gi paragraph-image"><div class="gh gi ps"><img src="../Images/3a6ef34031024ff2db80c1933f5012f9.png" data-original-src="https://miro.medium.com/v2/resize:fit:800/format:webp/0*z_YK2Pg_ow4xsKRZ.png"/></div></figure><h2 id="7b9a" class="mq mr jg bd ms mt mu dn mv mw mx dp my lu mz na nb ly nc nd ne mc nf ng nh jm bi translated">它在哪里？</h2><div class="ip iq gp gr ir nv"><a href="http://www.iapr-tc11.org/mediawiki/index.php/The_Street_View_Text_Dataset" rel="noopener  ugc nofollow" target="_blank"><div class="nw ab fo"><div class="nx ab ny cl cj nz"><h2 class="bd jq gy z fp oa fr fs ob fu fw jp bi translated">街道视图文本数据集</h2><div class="oc l"><h3 class="bd b gy z fp oa fr fs ob fu fw dk translated">数据集-&gt;数据集列表-&gt;当前页面王凯EBU3B，4148室。Sci。和工程师。大学…</h3></div><div class="od l"><p class="bd b dl z fp oa fr fs ob fu fw dk translated">www.iapr-tc11.org</p></div></div><div class="oe l"><div class="pt l og oh oi oe oj ix nv"/></div></div></a></div></div><div class="ab cl le lf hu lg" role="separator"><span class="lh bw bk li lj lk"/><span class="lh bw bk li lj lk"/><span class="lh bw bk li lj"/></div><div class="ij ik il im in"><blockquote class="pu"><p id="1de9" class="pv pw jg bd px py pz qa qb qc qd mg dk translated"><em class="qe">每周日，我们都会对来自世界各地研究人员的NLP新闻和代码进行一次每周综述。</em></p><p id="ece2" class="pv pw jg bd px py pz qa qb qc qd mg dk translated"><em class="qe">如果您喜欢这篇文章，请帮助我们并与朋友分享！</em></p><p id="662e" class="pv pw jg bd px py pz qa qb qc qd mg dk translated"><em class="qe">如需完整报道，请关注我们的Twitter:</em><a class="ae jd" href="http://twitter.com/Quantum_Stat" rel="noopener ugc nofollow" target="_blank"><em class="qe">@ Quantum _ Stat</em></a></p></blockquote><figure class="qg qh qi qj qk is gh gi paragraph-image"><div class="gh gi qf"><img src="../Images/953ef3796c6a2f0a3477b83fb528d436.png" data-original-src="https://miro.medium.com/v2/resize:fit:108/0*lTqGukLarnCdI90R"/></div><figcaption class="iz ja gj gh gi jb jc bd b be z dk translated"><a class="ae jd" href="http://www.quantumstat.com/" rel="noopener ugc nofollow" target="_blank">www.quantumstat.com</a></figcaption></figure></div></div>    
</body>
</html>