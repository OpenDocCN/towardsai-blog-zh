<html>
<head>
<title>4 Cognitive Biases In AI/ML Systems</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">人工智能/人工智能系统中的4种认知偏差</h1>
<blockquote>原文：<a href="https://pub.towardsai.net/4-cognitive-biases-in-ai-ml-systems-a208ac87177d?source=collection_archive---------3-----------------------#2022-10-25">https://pub.towardsai.net/4-cognitive-biases-in-ai-ml-systems-a208ac87177d?source=collection_archive---------3-----------------------#2022-10-25</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><div class=""><h2 id="f14d" class="pw-subtitle-paragraph jn ip iq bd b jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke dk translated">在理想世界中，机器是公正客观的。然而，设计这些机器的人类天生就有偏见。</h2></div><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi kf"><img src="../Images/a824c35b64cdc7c3edc9c734f4e39cdd.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*rSUBSiq9bauuUBny.jpg"/></div></div><figcaption class="kr ks gj gh gi kt ku bd b be z dk translated"><a class="ae kv" href="https://pixabay.com/illustrations/brain-chip-neurons-machine-learning-6010961/" rel="noopener ugc nofollow" target="_blank">图片由chenspec通过Pixabay提供</a></figcaption></figure><p id="0222" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">随着先进技术的快速扩散，现在越来越多的系统配备了人工智能和机器学习算法。</p><blockquote class="ls"><p id="4048" class="lt lu iq bd lv lw lx ly lz ma mb lr dk translated">然而，我们能客观地说这些系统是真正公平公正的吗？</p></blockquote><p id="8b24" class="pw-post-body-paragraph kw kx iq ky b kz mc jr lb lc md ju le lf me lh li lj mf ll lm ln mg lp lq lr ij bi translated">在这篇文章中，我分享了AI/ML系统的4种认知偏差，以及机器为什么会充满偏差，因为建造它们的<strong class="ky ir">工程师天生就不完美。</strong></p><h1 id="66c7" class="mh mi iq bd mj mk ml mm mn mo mp mq mr jw ms jx mt jz mu ka mv kc mw kd mx my bi translated">选择偏差</h1><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi kf"><img src="../Images/0c8df87ae3f0894d50ff4613efa58834.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*b8SuNmD2fUKM4ZVV.jpg"/></div></div><figcaption class="kr ks gj gh gi kt ku bd b be z dk translated"><a class="ae kv" href="https://pixabay.com/illustrations/cubes-choice-one-yellow-light-2492010/" rel="noopener ugc nofollow" target="_blank">图片由奇莫诺通过Pixabay拍摄</a></figcaption></figure><ul class=""><li id="3df4" class="mz na iq ky b kz la lc ld lf nb lj nc ln nd lr ne nf ng nh bi translated"><strong class="ky ir">选择偏差</strong>是指对不代表整个群体的<strong class="ky ir">训练/测试数据的选择。</strong></li><li id="ccfe" class="mz na iq ky b kz ni lc nj lf nk lj nl ln nm lr ne nf ng nh bi translated"><strong class="ky ir">示例:</strong>一名工程师选择回复他邮件的<strong class="ky ir">前100名志愿者</strong>作为他的训练数据</li><li id="34b8" class="mz na iq ky b kz ni lc nj lf nk lj nl ln nm lr ne nf ng nh bi translated"><strong class="ky ir">问题:</strong><strong class="ky ir">前100名受访者</strong>可能比<strong class="ky ir">后100名受访者</strong>更热衷于某项产品或研究。通过明确选择前100名受访者，工程师<strong class="ky ir">在他的数据收集方法中引入了不公平性。</strong></li><li id="031c" class="mz na iq ky b kz ni lc nj lf nk lj nl ln nm lr ne nf ng nh bi translated"><strong class="ky ir">解决方案:</strong>从你的电子邮件回复者池中选择一个<strong class="ky ir">随机样本</strong>100个用户，而不是前100个。</li></ul><h1 id="2175" class="mh mi iq bd mj mk ml mm mn mo mp mq mr jw ms jx mt jz mu ka mv kc mw kd mx my bi translated">报道偏差</h1><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi kf"><img src="../Images/5cbdbf33ced58302d69fe941a0a00207.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*BU47f01wBOYkIZlq.jpg"/></div></div><figcaption class="kr ks gj gh gi kt ku bd b be z dk translated"><a class="ae kv" href="https://pixabay.com/photos/board-chalk-feedback-review-3699978/" rel="noopener ugc nofollow" target="_blank">图片由athree233通过Pixabay </a></figcaption></figure><ul class=""><li id="4208" class="mz na iq ky b kz la lc ld lf nb lj nc ln nd lr ne nf ng nh bi translated"><strong class="ky ir">报道偏差</strong>是指<strong class="ky ir"> </strong>人(有意识和无意识)<strong class="ky ir">对自己报道的信息进行压制的倾向</strong>。</li><li id="879f" class="mz na iq ky b kz ni lc nj lf nk lj nl ln nm lr ne nf ng nh bi translated"><strong class="ky ir">举例:</strong>许多亚马逊产品<strong class="ky ir">的5星和1星评价多于2星、3星或4星评价</strong>，因为<strong class="ky ir">有极端经历(无论正面还是负面)的人比有中性经历的人更有可能发布评价</strong>。</li><li id="bd19" class="mz na iq ky b kz ni lc nj lf nk lj nl ln nm lr ne nf ng nh bi translated"><strong class="ky ir">问题:</strong>一个使用在线评论作为主要数据源的工程师可能会创建一个人工智能模型，这个模型在检测极端情绪方面<strong class="ky ir">很棒，但在检测更中性、更微妙的情绪方面却不太好。</strong></li><li id="cc53" class="mz na iq ky b kz ni lc nj lf nk lj nl ln nm lr ne nf ng nh bi translated"><strong class="ky ir">解决方案:</strong>考虑<strong class="ky ir">扩大数据收集范围，以解决代表性不足的数据。</strong></li></ul><h1 id="3394" class="mh mi iq bd mj mk ml mm mn mo mp mq mr jw ms jx mt jz mu ka mv kc mw kd mx my bi translated">隐性偏见</h1><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi kf"><img src="../Images/95d6c3b10e1b38889190a0a24c68917d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*uWKrIXi9uYs2B65k.jpg"/></div></div><figcaption class="kr ks gj gh gi kt ku bd b be z dk translated"><a class="ae kv" href="https://pixabay.com/illustrations/girl-woman-female-silhouette-young-4064552/" rel="noopener ugc nofollow" target="_blank">由Merio通过Pixabay拍摄的图像</a></figcaption></figure><ul class=""><li id="e917" class="mz na iq ky b kz la lc ld lf nb lj nc ln nd lr ne nf ng nh bi translated"><strong class="ky ir">内隐偏见</strong>指人们的<strong class="ky ir">无意识倾向于做出假设或将刻板印象与他人联系起来。</strong></li><li id="7270" class="mz na iq ky b kz ni lc nj lf nk lj nl ln nm lr ne nf ng nh bi translated">一位经常被狗咬伤的工程师认为狗比猫更具攻击性，尽管这种说法在科学上并不正确。</li><li id="dd22" class="mz na iq ky b kz ni lc nj lf nk lj nl ln nm lr ne nf ng nh bi translated"><strong class="ky ir">问题:</strong>工程师会认为<strong class="ky ir">基本事实</strong>是“狗=好斗”，因此<strong class="ky ir">微调她的人工智能模型，给狗贴上比猫更好斗的标签。</strong></li><li id="699b" class="mz na iq ky b kz ni lc nj lf nk lj nl ln nm lr ne nf ng nh bi translated"><strong class="ky ir">解决方案:</strong>由于隐性偏见对于个人来说是<strong class="ky ir">无意识的，让<strong class="ky ir">多名工程师编写AI </strong>和<strong class="ky ir">建立适当的同行评审程序</strong>将<strong class="ky ir">减少这种偏见的发生。</strong></strong></li></ul><h1 id="b5e8" class="mh mi iq bd mj mk ml mm mn mo mp mq mr jw ms jx mt jz mu ka mv kc mw kd mx my bi translated">框架偏差</h1><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi nn"><img src="../Images/8b8a0cd214cc1eae9b9d757eec50d8a3.png" data-original-src="https://miro.medium.com/v2/resize:fit:1132/format:webp/1*K9MG0LVwpJ-BWVgjabCZpg.png"/></div></figure><ul class=""><li id="3995" class="mz na iq ky b kz la lc ld lf nb lj nc ln nd lr ne nf ng nh bi translated"><strong class="ky ir">框架偏见</strong>指的是<strong class="ky ir"> </strong>人们的<strong class="ky ir">倾向于受信息呈现方式的影响。</strong></li><li id="65f8" class="mz na iq ky b kz ni lc nj lf nk lj nl ln nm lr ne nf ng nh bi translated"><strong class="ky ir">举例:</strong>一个工程师看到某个产品的<strong class="ky ir">阴暗沉闷的</strong>网站，就认为该产品一定销量不佳，而忽略了该产品的实际正销量数字。</li><li id="b214" class="mz na iq ky b kz ni lc nj lf nk lj nl ln nm lr ne nf ng nh bi translated"><strong class="ky ir">问题:</strong>在设计AI算法时，工程师可能会<strong class="ky ir">考虑主观变量，</strong>比如网站的颜色，<strong class="ky ir">而不是关注客观指标。</strong></li><li id="ef73" class="mz na iq ky b kz ni lc nj lf nk lj nl ln nm lr ne nf ng nh bi translated"><strong class="ky ir">解决方案:</strong> <strong class="ky ir">避免主观的</strong>(通常是定性的)数据，而<strong class="ky ir">优先考虑客观的、事实性的数据</strong>。</li></ul><h1 id="a2c7" class="mh mi iq bd mj mk ml mm mn mo mp mq mr jw ms jx mt jz mu ka mv kc mw kd mx my bi translated">总结和最佳实践</h1><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi no"><img src="../Images/c85d7c0a5c5ae330c49d71f072087593.png" data-original-src="https://miro.medium.com/v2/resize:fit:1086/format:webp/0*oQsLizWImscaZahj.jpg"/></div><figcaption class="kr ks gj gh gi kt ku bd b be z dk translated"><a class="ae kv" href="https://pixabay.com/illustrations/artificial-intelligence-ai-robot-2228610/" rel="noopener ugc nofollow" target="_blank">图片由Seanbatty通过Pixabay </a></figcaption></figure><p id="4159" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">快速回顾人工智能/人工智能系统中的4种认知偏差</p><ul class=""><li id="5246" class="mz na iq ky b kz la lc ld lf nb lj nc ln nd lr ne nf ng nh bi translated"><strong class="ky ir">选择偏倚(选择不代表整个群体的数据)</strong></li><li id="5aaf" class="mz na iq ky b kz ni lc nj lf nk lj nl ln nm lr ne nf ng nh bi translated"><strong class="ky ir">报告偏差(人们少报信息的倾向)</strong></li><li id="8ee9" class="mz na iq ky b kz ni lc nj lf nk lj nl ln nm lr ne nf ng nh bi translated"><strong class="ky ir">内隐偏见(人们无意识的倾向假设)</strong></li><li id="03ef" class="mz na iq ky b kz ni lc nj lf nk lj nl ln nm lr ne nf ng nh bi translated"><strong class="ky ir">框架偏见(人们受信息呈现方式影响的倾向)</strong></li></ul><p id="bd5a" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">提高人工智能/人工智能系统客观性的5个最佳实践</p><ul class=""><li id="0a57" class="mz na iq ky b kz la lc ld lf nb lj nc ln nd lr ne nf ng nh bi translated"><strong class="ky ir">始终选择一个随机样本(而不是第一个或最后一百个数据点)</strong></li><li id="25c7" class="mz na iq ky b kz ni lc nj lf nk lj nl ln nm lr ne nf ng nh bi translated"><strong class="ky ir">通过与其他数据源的比较来验证您的数据源</strong></li><li id="c1a4" class="mz na iq ky b kz ni lc nj lf nk lj nl ln nm lr ne nf ng nh bi translated"><strong class="ky ir">指派更多(多样化的)工程师开发人工智能/人工智能系统</strong></li><li id="e59b" class="mz na iq ky b kz ni lc nj lf nk lj nl ln nm lr ne nf ng nh bi translated"><strong class="ky ir">建立适当的同行审查程序，对逻辑和无意识偏见进行交叉审查</strong></li><li id="e8b4" class="mz na iq ky b kz ni lc nj lf nk lj nl ln nm lr ne nf ng nh bi translated">将客观和事实数据置于主观(通常是定性)数据之上。</li></ul></div><div class="ab cl np nq hu nr" role="separator"><span class="ns bw bk nt nu nv"/><span class="ns bw bk nt nu nv"/><span class="ns bw bk nt nu"/></div><div class="ij ik il im in"><p id="7388" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">如你所见，人类的感知存在严重缺陷，我们的不完美可能会渗透到我们构建的系统中。通过<strong class="ky ir">承认这些偏见，</strong>然而，我们可以<strong class="ky ir">优化我们构建的人工智能系统</strong>并<strong class="ky ir">使它们更加公平和客观。</strong></p><p id="c647" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">我希望你今天学到了新东西。如果你喜欢你正在阅读的东西，请鼓掌或关注！</p><p id="686f" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">我将在下一篇文章中介绍您。干杯！</p></div></div>    
</body>
</html>