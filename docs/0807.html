<html>
<head>
<title>Step By Step Guide In Creating Your Own Emotion Recognition System</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">一步一步引导你创建自己的情感识别系统</h1>
<blockquote>原文：<a href="https://pub.towardsai.net/step-by-step-guide-in-creating-your-own-emotion-recognition-system-b8aba98134c8?source=collection_archive---------1-----------------------#2020-08-16">https://pub.towardsai.net/step-by-step-guide-in-creating-your-own-emotion-recognition-system-b8aba98134c8?source=collection_archive---------1-----------------------#2020-08-16</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><h2 id="f746" class="io ip iq bd b dl ir is it iu iv iw dk ix translated" aria-label="kicker paragraph"><a class="ae ep" href="https://towardsai.net/p/category/computer-vision" rel="noopener ugc nofollow" target="_blank">计算机视觉</a>，<a class="ae ep" href="https://towardsai.net/p/category/machine-learning/deep-learning" rel="noopener ugc nofollow" target="_blank">深度学习</a></h2><div class=""/><figure class="gl gn jx jy jz ka gh gi paragraph-image"><div role="button" tabindex="0" class="kb kc di kd bf ke"><div class="gh gi jw"><img src="../Images/9e9d8f79f87bc21c5118f805324a4148.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*kNmSTa-xG_Ed_xmHPWAzeQ.png"/></div></div><figcaption class="kh ki gj gh gi kj kk bd b be z dk translated">情感识别模型</figcaption></figure><p id="5829" class="pw-post-body-paragraph kl km iq kn b ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li ij bi translated">你是对深度学习感到兴奋的人之一吗？你有没有想过创造一种可以探测人类情感的东西？<br/>嗯，如果是这样，那你就来对地方了。</p><p id="1c59" class="pw-post-body-paragraph kl km iq kn b ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li ij bi translated">在这篇文章中，我将一步一步地向你介绍我的情感识别模型，以及我发现的一些见解。</p><p id="01a1" class="pw-post-body-paragraph kl km iq kn b ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li ij bi translated">为了方便你浏览我的博客，我将列出这篇文章将要讨论的要点。</p><ol class=""><li id="ed24" class="lj lk iq kn b ko kp ks kt kw ll la lm le ln li lo lp lq lr bi translated">了解数据集</li><li id="4ec2" class="lj lk iq kn b ko ls ks lt kw lu la lv le lw li lo lp lq lr bi translated">创建助手功能</li><li id="2774" class="lj lk iq kn b ko ls ks lt kw lu la lv le lw li lo lp lq lr bi translated">将数据转换成所需的格式</li><li id="c1d7" class="lj lk iq kn b ko ls ks lt kw lu la lv le lw li lo lp lq lr bi translated">获取您的基本模型</li><li id="33b4" class="lj lk iq kn b ko ls ks lt kw lu la lv le lw li lo lp lq lr bi translated">准备微调模型</li><li id="a72f" class="lj lk iq kn b ko ls ks lt kw lu la lv le lw li lo lp lq lr bi translated">绘制洞察力</li><li id="7756" class="lj lk iq kn b ko ls ks lt kw lu la lv le lw li lo lp lq lr bi translated">重构微调模型</li><li id="23ab" class="lj lk iq kn b ko ls ks lt kw lu la lv le lw li lo lp lq lr bi translated">从谷歌拍摄的图像中做出预测</li></ol><p id="6113" class="pw-post-body-paragraph kl km iq kn b ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li ij bi translated">因此，如果你对此感到兴奋，那就让我们开始吧！</p></div><div class="ab cl lx ly hu lz" role="separator"><span class="ma bw bk mb mc md"/><span class="ma bw bk mb mc md"/><span class="ma bw bk mb mc"/></div><div class="ij ik il im in"><h1 id="1b08" class="me mf iq bd mg mh mi mj mk ml mm mn mo mp mq mr ms mt mu mv mw mx my mz na nb bi translated">了解数据集</h1><p id="de8e" class="pw-post-body-paragraph kl km iq kn b ko nc kq kr ks nd ku kv kw ne ky kz la nf lc ld le ng lg lh li ij bi translated">面部情感识别的数据集可以从Kaggle这里<a class="ae nh" href="https://www.kaggle.com/c/challenges-in-representation-learning-facial-expression-recognition-challenge/data" rel="noopener ugc nofollow" target="_blank">下载</a>。如果无法从那里下载数据，您可以使用此驱动器<a class="ae nh" href="https://drive.google.com/file/d/1q1KazCL9W9cQYsM09s3FzQjyUSct3YxV/view?usp=sharing" rel="noopener ugc nofollow" target="_blank">链接</a>下载数据集。</p><p id="34bb" class="pw-post-body-paragraph kl km iq kn b ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li ij bi translated">现在你已经有了数据集，你就可以跟着做了。<br/>那么，事不宜迟，让我们开始加载数据集。由于在本地机器上处理图像需要大量的时间和资源，因此我将使用colab的GPU来训练我的模型。因此，如果你没有自己的GPU，确保你切换到colab跟随。</p><h2 id="9c54" class="ni mf iq bd mg nj nk dn mk nl nm dp mo kw nn no ms la np nq mw le nr ns na iw bi translated">导入必要的库</h2><figure class="nt nu nv nw gt ka"><div class="bz fp l di"><div class="nx ny l"/></div></figure><pre class="nt nu nv nw gt nz oa ob oc aw od bi"><span id="75f3" class="ni mf iq oa b gy oe of l og oh"># Loading dataset<br/>data = pd.read_csv('fer2013.csv')</span></pre><p id="3ae9" class="pw-post-body-paragraph kl km iq kn b ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li ij bi translated">加载完数据集后，让我们尝试探索我们的数据。数据集由<strong class="kn ja"> 3列</strong>组成，即<strong class="kn ja">情感</strong>(目标变量)、<strong class="kn ja">像素、</strong>和<strong class="kn ja">用法</strong>。<br/>来自数据['情感']。unique()，我们可以发现我们的数据集中存在多少种类型的情绪。</p><blockquote class="oi oj ok"><p id="fe41" class="kl km ol kn b ko kp kq kr ks kt ku kv om kx ky kz on lb lc ld oo lf lg lh li ij bi translated">在这种情况下，这里有6种情绪被映射如下:<br/> <em class="iq"> 0 - &gt;愤怒<br/> 1 - &gt;厌恶<br/> 2 - &gt;恐惧<br/> 3 - &gt;快乐<br/> 4 - &gt;悲伤<br/> 5 - &gt;惊喜<br/> 6 - &gt;中性</em></p></blockquote><h2 id="c6fe" class="ni mf iq bd mg nj nk dn mk nl nm dp mo kw nn no ms la np nq mw le nr ns na iw bi translated">探索“用法”栏</h2><pre class="nt nu nv nw gt nz oa ob oc aw od bi"><span id="6931" class="ni mf iq oa b gy oe of l og oh"># exploring values in Usage column<br/>data['Usage].value_counts</span><span id="ad10" class="ni mf iq oa b gy op of l og oh">//========= Output ================//<br/>Training       28709 <br/>PublicTest      3589 <br/>PrivateTest     3589 <br/>Name: Usage, dtype: int64</span></pre><p id="3d82" class="pw-post-body-paragraph kl km iq kn b ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li ij bi translated">上面的代码告诉我们，数据集由“Training”、“PublicTest”和“PrivateTest”组成。现在我们必须决定哪种类型的数据用于训练、验证和测试。</p><p id="cd68" class="pw-post-body-paragraph kl km iq kn b ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li ij bi translated">我决定使用标记为“Training”的整个数据集作为训练集，PublicTest作为验证/开发集，PrivateTest作为测试集。我已经将数据集分为训练、验证和测试，并将其保存为单独的CSV文件。</p><p id="582f" class="pw-post-body-paragraph kl km iq kn b ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li ij bi translated">我选择的原因是我们希望我们的模型最终在测试数据上表现良好，因此公共测试数据似乎是我的最佳选择，因为它将描述我们的私有测试。因此，如果我们在验证集上推广得好，我们在测试数据上也会做得好。您可以从下面的链接下载CSV文件。<br/> <a class="ae nh" href="https://drive.google.com/file/d/1--39x9DupUs3-Jfhf3rWEATMN4pe2uu7/view?usp=sharing" rel="noopener ugc nofollow" target="_blank">训练数据</a>，<a class="ae nh" href="https://drive.google.com/file/d/1-HqdhlYhF6nUYNOcCrnsYKNhyK8sZNiF/view?usp=sharing" rel="noopener ugc nofollow" target="_blank">验证数据</a>，以及<a class="ae nh" href="https://drive.google.com/file/d/1-BkQFmtIHbfAJHcR5icfaDuwDQ_SSMIL/view?usp=sharing" rel="noopener ugc nofollow" target="_blank">测试数据</a></p><p id="c743" class="pw-post-body-paragraph kl km iq kn b ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li ij bi translated">到现在为止，我们已经加载并理解了一些我们的数据是关于什么的，以及我们将要预测什么。现在让我们<strong class="kn ja">开始为我们的模型创建助手函数。</strong></p></div><div class="ab cl lx ly hu lz" role="separator"><span class="ma bw bk mb mc md"/><span class="ma bw bk mb mc md"/><span class="ma bw bk mb mc"/></div><div class="ij ik il im in"><h1 id="14ba" class="me mf iq bd mg mh mi mj mk ml mm mn mo mp mq mr ms mt mu mv mw mx my mz na nb bi translated">助手功能</h1><p id="496a" class="pw-post-body-paragraph kl km iq kn b ko nc kq kr ks nd ku kv kw ne ky kz la nf lc ld le ng lg lh li ij bi translated">现在，我们将定义一些函数来帮助我们从数据集中提取特征和目标，并将它们存储在单独的列表中以备后用。</p><h2 id="5810" class="ni mf iq bd mg nj nk dn mk nl nm dp mo kw nn no ms la np nq mw le nr ns na iw bi translated">提取特征</h2><figure class="nt nu nv nw gt ka"><div class="bz fp l di"><div class="nx ny l"/></div></figure><p id="e1fa" class="pw-post-body-paragraph kl km iq kn b ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li ij bi translated">上面的函数解析整个文件并分离出特征和目标。因为我们的目标情感是在第一列中找到的，所以我们使用row[0]对其进行切片，并将其附加到我们的列表‘Y’中，而其余的特征被附加到列表‘X’中。</p><figure class="nt nu nv nw gt ka"><div class="bz fp l di"><div class="nx ny l"/></div></figure><p id="9167" class="pw-post-body-paragraph kl km iq kn b ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li ij bi translated">让我们检查一下数据的形状。</p><pre class="nt nu nv nw gt nz oa ob oc aw od bi"><span id="5533" class="ni mf iq oa b gy oe of l og oh"># Checking shape of our data</span><span id="b6fc" class="ni mf iq oa b gy op of l og oh">print(train_X.shape)<br/>print(train_Y.shape)<br/>print(val_X.shape)<br/>print(val_Y.shape)<br/>print(test_X.shape)<br/>print(test_Y.shape)</span><span id="6c27" class="ni mf iq oa b gy op of l og oh">############# Output ############<br/>(28709, 2304) // training-data<br/>(28709,) <br/>(3589, 2304) //validtaion-data <br/>(3589,) <br/>(3589, 2304) //testing-data <br/>(3589,)</span></pre><h2 id="658d" class="ni mf iq bd mg nj nk dn mk nl nm dp mo kw nn no ms la np nq mw le nr ns na iw bi translated">绘图功能</h2><figure class="nt nu nv nw gt ka"><div class="bz fp l di"><div class="nx ny l"/></div></figure><p id="8d0e" class="pw-post-body-paragraph kl km iq kn b ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li ij bi translated">上面的绘图函数用于分析我们的模型如何随着历元数的增加而执行。为了使用相同的功能，我引入了一个历史参数。因此，给定任何模型的历史，它将沿着x轴显示其精度和损耗图，以及历元数。</p><h2 id="9da4" class="ni mf iq bd mg nj nk dn mk nl nm dp mo kw nn no ms la np nq mw le nr ns na iw bi translated">情感分析</h2><p id="3cd9" class="pw-post-body-paragraph kl km iq kn b ko nc kq kr ks nd ku kv kw ne ky kz la nf lc ld le ng lg lh li ij bi translated">我们的下一个助手功能是绘制条形图来分析预测的情绪。该函数将构建一个条形图，并显示由我们的模型预测的每种情绪的置信水平。通过这种方式，我们可以跟踪我们的模型是如何执行的，以及什么使我们的模型变得混乱。</p><figure class="nt nu nv nw gt ka"><div class="bz fp l di"><div class="nx ny l"/></div></figure><h2 id="07c1" class="ni mf iq bd mg nj nk dn mk nl nm dp mo kw nn no ms la np nq mw le nr ns na iw bi translated">显示预测</h2><p id="ab45" class="pw-post-body-paragraph kl km iq kn b ko nc kq kr ks nd ku kv kw ne ky kz la nf lc ld le ng lg lh li ij bi translated">我们的最后一个辅助函数用于在我们自己的图像上绘制预测。在下面的函数中，我们简单地利用TensorFlow图像预处理库，并在进行预测之前将其转换为所需的格式。</p><figure class="nt nu nv nw gt ka"><div class="bz fp l di"><div class="nx ny l"/></div></figure><h1 id="93fc" class="me mf iq bd mg mh oq mj mk ml or mn mo mp os mr ms mt ot mv mw mx ou mz na nb bi translated">将数据转换成所需的格式</h1><p id="7fa3" class="pw-post-body-paragraph kl km iq kn b ko nc kq kr ks nd ku kv kw ne ky kz la nf lc ld le ng lg lh li ij bi translated">检查完助手函数后，现在我们可以调用extract_features函数，将数据转换成所需的格式。<br/>我们的模型需要shape(N，d，d，1)的数据，其中N等于训练样本的数量，d等于维数。我已经将我的数据保存在不同的文件中，所以我将加载数据并将其转换成我们的模型所期望的格式。</p><figure class="nt nu nv nw gt ka"><div class="bz fp l di"><div class="nx ny l"/></div></figure></div><div class="ab cl lx ly hu lz" role="separator"><span class="ma bw bk mb mc md"/><span class="ma bw bk mb mc md"/><span class="ma bw bk mb mc"/></div><div class="ij ik il im in"><h1 id="31e2" class="me mf iq bd mg mh mi mj mk ml mm mn mo mp mq mr ms mt mu mv mw mx my mz na nb bi translated">定义基础模型</h1><p id="5cf0" class="pw-post-body-paragraph kl km iq kn b ko nc kq kr ks nd ku kv kw ne ky kz la nf lc ld le ng lg lh li ij bi translated">最后，经过所有的预处理，我们现在可以构建我们的基本模型。<br/>我选择了具有多个卷积层的传统基本模型，在两个卷积层之后是最大池层。<br/>然而，这种架构的结果相对较差。<br/>在30个时期内，验证精度停留在0.25左右，没有任何提高。<br/>下面是我用于基本模型的模型架构。</p><pre class="nt nu nv nw gt nz oa ob oc aw od bi"><span id="b456" class="ni mf iq oa b gy oe of l og oh">def base_model():</span><span id="820d" class="ni mf iq oa b gy op of l og oh">#1st convolution layer<br/>model = Sequential()<br/>model.add(Conv2D(64, kernel_size=(3, 3), activation='relu', input_shape=(X_train.shape[1:])))<br/>model.add(Conv2D(64,kernel_size= (3, 3), activation='relu'))<br/>model.add(MaxPooling2D(pool_size=(2,2), strides=(2, 2)))<br/>model.add(Dropout(0.5))</span><span id="adbd" class="ni mf iq oa b gy op of l og oh">#2nd convolution layer<br/>model.add(Conv2D(64, (3, 3), activation='relu'))<br/>model.add(Conv2D(64, (3, 3), activation='relu'))<br/>model.add(MaxPooling2D(pool_size=(2,2), strides=(2, 2)))<br/>model.add(Dropout(0.5))</span><span id="a744" class="ni mf iq oa b gy op of l og oh">#3rd convolution layer<br/>model.add(Conv2D(128, (3, 3), activation='relu'))<br/>model.add(Conv2D(128, (3, 3), activation='relu'))<br/>model.add(MaxPooling2D(pool_size=(2,2), strides=(2, 2)))</span><span id="dbff" class="ni mf iq oa b gy op of l og oh">model.add(Flatten())</span><span id="e3f1" class="ni mf iq oa b gy op of l og oh">#fully connected neural networks<br/>model.add(Dense(1024, activation='relu'))<br/>model.add(Dropout(0.2))<br/>model.add(Dense(1024, activation='relu'))<br/>model.add(Dropout(0.2))<br/>model.add(Dense(num_labels, activation='softmax'))</span><span id="0eb0" class="ni mf iq oa b gy op of l og oh">return model</span></pre><p id="181a" class="pw-post-body-paragraph kl km iq kn b ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li ij bi translated">30个周期后的输出精度如下。</p><pre class="nt nu nv nw gt nz oa ob oc aw od bi"><span id="82cf" class="ni mf iq oa b gy oe of l og oh">Epoch 30/30</span><span id="66be" class="ni mf iq oa b gy op of l og oh">449/449 [==============================] - 8s 17ms/step - loss: 1.8105 - accuracy: 0.2513 - val_loss: 1.8126 - val_accuracy: 0.2494</span></pre><p id="f0b0" class="pw-post-body-paragraph kl km iq kn b ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li ij bi translated">正如你所看到的，我们之前的模型的结果很差，因为我们的训练和验证准确性没有真正提高。</p><p id="1e6d" class="pw-post-body-paragraph kl km iq kn b ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li ij bi translated">这里出现的问题是，在我们的下一个模型架构中，我们会带来什么变化？</p><p id="3ce7" class="pw-post-body-paragraph kl km iq kn b ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li ij bi translated">我计划在我的下一个模型架构中做如下的改变，包括:<br/> -增加一个批处理规范化层。<br/> -使用128个节点的密集层，<br/> -使用正则化子，<br/> -学习率0.001</p><h2 id="e364" class="ni mf iq bd mg nj nk dn mk nl nm dp mo kw nn no ms la np nq mw le nr ns na iw bi translated">调优模型架构</h2><figure class="nt nu nv nw gt ka"><div class="bz fp l di"><div class="nx ny l"/></div></figure><p id="ccc2" class="pw-post-body-paragraph kl km iq kn b ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li ij bi translated">基于我所考虑的因素，我定义了另一个模型架构。<br/>你可以从<a class="ae nh" href="https://www.youtube.com/watch?v=nUUqwaxLnWs" rel="noopener ugc nofollow" target="_blank">这里</a>了解BatchNormalization如何工作并改进我们的模型。</p><h2 id="4bad" class="ni mf iq bd mg nj nk dn mk nl nm dp mo kw nn no ms la np nq mw le nr ns na iw bi translated">过度拟合模型</h2><p id="9af1" class="pw-post-body-paragraph kl km iq kn b ko nc kq kr ks nd ku kv kw ne ky kz la nf lc ld le ng lg lh li ij bi translated">让我们将我们的模型用于过度拟合，然后对这种情况下的最佳超参数集进行一些分析。</p><figure class="nt nu nv nw gt ka"><div class="bz fp l di"><div class="nx ny l"/></div></figure><p id="49d0" class="pw-post-body-paragraph kl km iq kn b ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li ij bi translated">在80个时期结束时，我们可以清楚地看到，我们的模型已经过度拟合，因为我们的训练精度不断提高，而验证精度却停滞在0.65左右。</p><pre class="nt nu nv nw gt nz oa ob oc aw od bi"><span id="1246" class="ni mf iq oa b gy oe of l og oh">Epoch 80/80 449/449 [==============================] - 33s 73ms/step - loss: 0.2126 - accuracy: 0.9244 - val_loss: 1.6008 - val_accuracy: 0.6503</span><span id="8c7e" class="ni mf iq oa b gy op of l og oh"># Let's save this model for further testing<br/>  model_1.save('base_model(fer).h5')</span></pre><p id="f980" class="pw-post-body-paragraph kl km iq kn b ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li ij bi translated">现在是时候调用我们的一个助手函数来绘制图表，以查看我们的模型在80个时期内的进度。</p><pre class="nt nu nv nw gt nz oa ob oc aw od bi"><span id="e909" class="ni mf iq oa b gy oe of l og oh"># Lets plot the graph and see what it tell us<br/>  plot(history) # This will display the accuracy and loss graphs.</span></pre><figure class="nt nu nv nw gt ka gh gi paragraph-image"><div class="gh gi ov"><img src="../Images/d048ca12d1d0cb37b5093dba6d868cb5.png" data-original-src="https://miro.medium.com/v2/resize:fit:758/format:webp/1*DBXn82HhANm1AxwXkZF5hA.png"/></div><figcaption class="kh ki gj gh gi kj kk bd b be z dk translated">用于培训和验证的准确性和损失图</figcaption></figure><h1 id="5a94" class="me mf iq bd mg mh oq mj mk ml or mn mo mp os mr ms mt ot mv mw mx ou mz na nb bi translated">绘制洞察力</h1><p id="9a26" class="pw-post-body-paragraph kl km iq kn b ko nc kq kr ks nd ku kv kw ne ky kz la nf lc ld le ng lg lh li ij bi translated">图表清楚地证实了我们应该在10个时期左右停止训练，因为在10个时期之后，我们的模型没有真正的改善。<br/>因此，过度拟合模型的主要收获是训练大约10-12个时期并评估结果。这正是我们接下来要做的！<br/>但是在运行另一个模型之前，让我们从过度拟合的模型中进行一些预测，以将其与我们稍后将创建的模型进行比较。</p><h2 id="425a" class="ni mf iq bd mg nj nk dn mk nl nm dp mo kw nn no ms la np nq mw le nr ns na iw bi translated">根据过度拟合的模型进行预测</h2><p id="31a1" class="pw-post-body-paragraph kl km iq kn b ko nc kq kr ks nd ku kv kw ne ky kz la nf lc ld le ng lg lh li ij bi translated">我从谷歌上随机下载了不同情绪的图片，然后用我的过度拟合模型进行了测试。<br/>下面显示的是我从谷歌获得的随机图片的输出图片。</p><div class="nt nu nv nw gt ab cb"><figure class="ow ka ox oy oz pa pb paragraph-image"><img src="../Images/2b3e3cab84d3e70e5b6691cb77e5e2b2.png" data-original-src="https://miro.medium.com/v2/resize:fit:744/format:webp/1*5D_fziAnVnCHnYfgCwGEIQ.png"/></figure><figure class="ow ka pc oy oz pa pb paragraph-image"><div role="button" tabindex="0" class="kb kc di kd bf ke"><img src="../Images/19b65c4195ce1603d19beabd61bd0431.png" data-original-src="https://miro.medium.com/v2/resize:fit:786/format:webp/1*ZZLM5enTJkBISczRcitWKA.png"/></div></figure></div><div class="ab cb"><figure class="ow ka pd oy oz pa pb paragraph-image"><div role="button" tabindex="0" class="kb kc di kd bf ke"><img src="../Images/06542671810a69b3188b1759bc983ee2.png" data-original-src="https://miro.medium.com/v2/resize:fit:728/format:webp/1*aFaW15A3scDJ7ftYo1Qm-w.png"/></div></figure><figure class="ow ka pe oy oz pa pb paragraph-image"><div role="button" tabindex="0" class="kb kc di kd bf ke"><img src="../Images/c4977853ada8f1ca47ced258117359ab.png" data-original-src="https://miro.medium.com/v2/resize:fit:772/format:webp/1*bY7JiKvJXMKU3p2SGUoqsw.png"/></div></figure></div><div class="ab cb"><figure class="ow ka pf oy oz pa pb paragraph-image"><img src="../Images/f0d7f21dda731c27468f4f6332d73703.png" data-original-src="https://miro.medium.com/v2/resize:fit:800/format:webp/1*s711ssevqGrN1iM6NTV_BA.png"/></figure><figure class="ow ka pg oy oz pa pb paragraph-image"><img src="../Images/9069751a1411b5da2eb4bd14ab93555c.png" data-original-src="https://miro.medium.com/v2/resize:fit:716/format:webp/1*GbyhjlTFGDCQ5X8q-nYnlQ.png"/></figure></div><div class="ab cb"><figure class="ow ka ph oy oz pa pb paragraph-image"><img src="../Images/bf6c77063084e79589f85119283d106c.png" data-original-src="https://miro.medium.com/v2/resize:fit:718/format:webp/1*ZP2W8ghdN9zG1KuvZfTY8A.png"/></figure><figure class="ow ka pi oy oz pa pb paragraph-image"><img src="../Images/f534b922deb7937b973c16b0dc48f89f.png" data-original-src="https://miro.medium.com/v2/resize:fit:728/format:webp/1*dM2giP2_wWwm5peof9mHYg.png"/><figcaption class="kh ki gj gh gi kj kk bd b be z dk pj di pk pl translated">模型预测</figcaption></figure></div><p id="e2a3" class="pw-post-body-paragraph kl km iq kn b ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li ij bi translated">如你所见，我们的模型没有准确预测所有的情绪。<br/>在第一幅和第三幅图像中，它被错误地归类为<strong class="kn ja">恐惧。<br/> </strong>我尝试了很多<strong class="kn ja">厌恶</strong>的图像，但是没有一个图像能归为一类。我认为数据还不足以进行分类，所以我们可以删除这些行，以便稍后进行实验，但是现在，我们不会删除它。<br/>条形图还有助于我们分析模型最容易混淆的地方。根据我的发现，它很难检测出<strong class="kn ja">愤怒</strong>、<strong class="kn ja">惊讶、</strong>和<strong class="kn ja">恐惧</strong>的情绪，因为由于相同的地标，它不能很好地区分这些情绪。</p><p id="8b8b" class="pw-post-body-paragraph kl km iq kn b ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li ij bi translated">现在让我们运行12个时期的模型，并根据该模型进行预测，以进一步加强我们的分析。</p><h1 id="ceb9" class="me mf iq bd mg mh oq mj mk ml or mn mo mp os mr ms mt ot mv mw mx ou mz na nb bi translated">重新运行12个时期的优化模型</h1><pre class="nt nu nv nw gt nz oa ob oc aw od bi"><span id="874a" class="ni mf iq oa b gy oe of l og oh"># Running model for 12 epochs<br/>model_2 = base_model()<br/>hist_2 = model_2.fit(train_X, Y_train,<br/>batch_size=64,<br/>epochs=12,<br/>verbose=1,<br/>validation_data=(val_X, Y_val),<br/>shuffle=True,)</span></pre><p id="c58e" class="pw-post-body-paragraph kl km iq kn b ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li ij bi translated">这是我们在12个时代结束时得到的结果。</p><pre class="nt nu nv nw gt nz oa ob oc aw od bi"><span id="caa9" class="ni mf iq oa b gy oe of l og oh">Epoch 12/12 449/449 [==============================] - 33s 73ms/step - loss: 0.9368 - accuracy: 0.6493 - val_loss: 1.0876 - val_accuracy: 0.5932</span></pre><p id="5596" class="pw-post-body-paragraph kl km iq kn b ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li ij bi translated">现在让<strong class="kn ja">绘制它</strong></p><figure class="nt nu nv nw gt ka gh gi paragraph-image"><div class="gh gi pm"><img src="../Images/34b2d5d2dd44a8f8fdfa62af013fab4b.png" data-original-src="https://miro.medium.com/v2/resize:fit:770/format:webp/1*poEVraHFinMCMguXZHMxLw.png"/></div></figure><p id="a93a" class="pw-post-body-paragraph kl km iq kn b ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li ij bi translated">所以，现在我们已经摆脱了过度拟合。验证精度约为0.59，这在正常情况下较低，但在这个数据集上，我认为是足够的精度。</p><p id="7786" class="pw-post-body-paragraph kl km iq kn b ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li ij bi translated">让我们保存模型，并在从google下载的相同图像上绘制预测。</p><h2 id="d093" class="ni mf iq bd mg nj nk dn mk nl nm dp mo kw nn no ms la np nq mw le nr ns na iw bi translated">从模型中得出预测</h2><div class="nt nu nv nw gt ab cb"><figure class="ow ka pn oy oz pa pb paragraph-image"><img src="../Images/30e4356ec2f14ee150515a7fde426f46.png" data-original-src="https://miro.medium.com/v2/resize:fit:720/format:webp/1*PGVlHtfXlBHKrNo3HP6o6Q.png"/></figure><figure class="ow ka po oy oz pa pb paragraph-image"><div role="button" tabindex="0" class="kb kc di kd bf ke"><img src="../Images/2278d869c9abf1023a79c5a3ba87c0ad.png" data-original-src="https://miro.medium.com/v2/resize:fit:710/format:webp/1*hnfulrt-CskRa-cd48FL7A.png"/></div></figure></div><div class="ab cb"><figure class="ow ka pp oy oz pa pb paragraph-image"><img src="../Images/bb25aeee8f33b4c1e12cd026092e254e.png" data-original-src="https://miro.medium.com/v2/resize:fit:778/format:webp/1*OGCny2zU2FokfHVnLl7ZNA.png"/></figure><figure class="ow ka pp oy oz pa pb paragraph-image"><div role="button" tabindex="0" class="kb kc di kd bf ke"><img src="../Images/9fcad9fd3097ef192fe5a213e21da918.png" data-original-src="https://miro.medium.com/v2/resize:fit:770/format:webp/1*aR3l2ZLhPLSu4lJT9xV4WA.png"/></div></figure></div><div class="ab cb"><figure class="ow ka pq oy oz pa pb paragraph-image"><img src="../Images/fdbb2b2213b638c0aabce7f2441ac6dd.png" data-original-src="https://miro.medium.com/v2/resize:fit:796/format:webp/1*_12Rs91x9Qn9_N2DU8-uQA.png"/></figure><figure class="ow ka pr oy oz pa pb paragraph-image"><img src="../Images/86e69cef853d7254bcffa7ae0a011e77.png" data-original-src="https://miro.medium.com/v2/resize:fit:736/format:webp/1*aZeBnFFNwB1oB3A_ACZz6g.png"/></figure></div><p id="3646" class="pw-post-body-paragraph kl km iq kn b ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li ij bi translated"><strong class="kn ja">宾果</strong>！我们的最终模型似乎能很好地区分不同的情绪。<br/>正如你在上面的预测中看到的，它现在能够识别愤怒情绪，而以前它认为这是恐惧。此外，它还能够预测最后一张图片中的惊喜情绪。</p><p id="b793" class="pw-post-body-paragraph kl km iq kn b ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li ij bi translated">尽管模型精度有所提高，但仍然不够精确，更好的模型结构肯定会有所帮助。</p></div><div class="ab cl lx ly hu lz" role="separator"><span class="ma bw bk mb mc md"/><span class="ma bw bk mb mc md"/><span class="ma bw bk mb mc"/></div><div class="ij ik il im in"><h1 id="1995" class="me mf iq bd mg mh mi mj mk ml mm mn mo mp mq mr ms mt mu mv mw mx my mz na nb bi translated">要点和未来改进</h1><p id="3246" class="pw-post-body-paragraph kl km iq kn b ko nc kq kr ks nd ku kv kw ne ky kz la nf lc ld le ng lg lh li ij bi translated">如果我们仔细分析预测信心，我们可以清楚地看到，我们的模型似乎仍然混淆在愤怒，惊讶和恐惧之间。<br/>还应该注意的是<strong class="kn ja">厌恶</strong>情绪从来没有被预测过，所以移除这些行不会有什么坏处。</p><p id="2956" class="pw-post-body-paragraph kl km iq kn b ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li ij bi translated">对未来工作的另一个建议可以是从互联网上收集不同人类情绪的图像，并为这些情绪制作不同的目录。我们可以利用TensorFlow的图像生成器库来扩充图像并创建我们自己的数据集。<br/>最后，我们可以使用迁移学习或预训练网络，并在底部附加我们的卷积和分类器，并进行预测。</p><h1 id="0cdb" class="me mf iq bd mg mh oq mj mk ml or mn mo mp os mr ms mt ot mv mw mx ou mz na nb bi translated">结论</h1><p id="f644" class="pw-post-body-paragraph kl km iq kn b ko nc kq kr ks nd ku kv kw ne ky kz la nf lc ld le ng lg lh li ij bi translated">非常感谢你对我和这篇文章坚持了这么长时间。我知道这太长了，但是，我认为分享我的宝贵见解可能会帮助一些深度学习爱好者对手头的任务产生更好的直觉。</p><p id="7064" class="pw-post-body-paragraph kl km iq kn b ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li ij bi translated">这篇文章的完整代码可以在这里找到<a class="ae nh" href="https://github.com/Nabeel110/Emotion-Recognition" rel="noopener ugc nofollow" target="_blank">。</a></p><p id="9896" class="pw-post-body-paragraph kl km iq kn b ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li ij bi translated">最后，我期待您对这篇文章的反馈。</p></div></div>    
</body>
</html>