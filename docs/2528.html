<html>
<head>
<title>What Are Baseline Models and Benchmarking For Machine Learning, Why We Need Them? Part 1 Classification</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">什么是机器学习的基线模型和基准，为什么我们需要它们？第1部分分类</h1>
<blockquote>原文：<a href="https://pub.towardsai.net/what-are-baseline-models-and-benchmarking-for-machine-learning-why-we-need-them-affe0714cd07?source=collection_archive---------1-----------------------#2022-01-31">https://pub.towardsai.net/what-are-baseline-models-and-benchmarking-for-machine-learning-why-we-need-them-affe0714cd07?source=collection_archive---------1-----------------------#2022-01-31</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><h2 id="2794" class="io ip iq bd b dl ir is it iu iv iw dk ix translated" aria-label="kicker paragraph"><a class="ae ep" href="https://towardsai.net/p/category/machine-learning" rel="noopener ugc nofollow" target="_blank">机器学习</a></h2><div class=""/><p id="bb9e" class="pw-post-body-paragraph jw jx iq jy b jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ij bi translated">随机、机器学习、自动化ML基线模型和ML基准测试…</p><figure class="kv kw kx ky gt kz gh gi paragraph-image"><div role="button" tabindex="0" class="la lb di lc bf ld"><div class="gh gi ku"><img src="../Images/851805ff55299e02a12fbabc0e584fa1.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*u94G7olsk4oPEn3BQGsSow.jpeg"/></div></div><figcaption class="lg lh gj gh gi li lj bd b be z dk translated">跳高奥运——来源<a class="ae lk" href="https://www.worldathletics.org/disciplines/jumps/high-jump" rel="noopener ugc nofollow" target="_blank">此处</a></figcaption></figure><p id="4024" class="pw-post-body-paragraph jw jx iq jy b jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ij bi translated">我们可以用任何准备好的数据来训练机器学习模型，但我们如何确定从训练数据中学习到的机器学习模型？本文的目的是解释数据科学中的基线模型。</p><p id="1c62" class="pw-post-body-paragraph jw jx iq jy b jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ij bi translated">你可以在这里看到数据集<a class="ae lk" href="https://www.kaggle.com/c/titanic/data" rel="noopener ugc nofollow" target="_blank"/>，你可以在文章末尾看到完整的python代码。</p><h1 id="3f21" class="ll lm iq bd ln lo lp lq lr ls lt lu lv lw lx ly lz ma mb mc md me mf mg mh mi bi translated">什么是基线模型？</h1><p id="c364" class="pw-post-body-paragraph jw jx iq jy b jz mj kb kc kd mk kf kg kh ml kj kk kl mm kn ko kp mn kr ks kt ij bi translated">基线模型是我们训练的ML模型的参考。对于基线模型，数据科学家试图解释他们训练的模型如何好，基线模型的分数是数据科学家的阈值。</p><h1 id="a824" class="ll lm iq bd ln lo lp lq lr ls lt lu lv lw lx ly lz ma mb mc md me mf mg mh mi bi translated">基线模型有哪些类型？</h1><p id="7f37" class="pw-post-body-paragraph jw jx iq jy b jz mj kb kc kd mk kf kg kh ml kj kk kl mm kn ko kp mn kr ks kt ij bi translated">有三种类型的基线模型，即随机基线模型、ML基线模型和自动化ML基线模型。</p><h2 id="e484" class="mo lm iq bd ln mp mq dn lr mr ms dp lv kh mt mu lz kl mv mw md kp mx my mh iw bi translated">随机基线模型</h2><p id="bb93" class="pw-post-body-paragraph jw jx iq jy b jz mj kb kc kd mk kf kg kh ml kj kk kl mm kn ko kp mn kr ks kt ij bi translated">在现实世界中，数据并不总是可以预测的。在这些问题中，最好的基线模型是虚拟分类器或虚拟回归器。基线模型显示你的ml模型是否在学习。你可以在下面看到如何使用随机基线模型。</p><p id="3236" class="pw-post-body-paragraph jw jx iq jy b jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ij bi translated">首先，我们创建一个随机数据集进行分类。</p><pre class="kv kw kx ky gt mz na nb nc aw nd bi"><span id="54e4" class="mo lm iq na b gy ne nf l ng nh">import pandas as pd<br/>import numpy as np</span><span id="d7dd" class="mo lm iq na b gy ni nf l ng nh">np.random.seed(0)<br/>random_dim = (1000,3)<br/>random_X = np.random.random(random_dim)<br/>random_reg_y = np.random.random(random_dim[0])<br/>random_clf_y = np.random.randint(random_dim[1], size=random_dim[0])</span><span id="9547" class="mo lm iq na b gy ni nf l ng nh">train_clf = np.concatenate((random_X, random_clf_y.reshape(random_dim[0], 1)), axis=1)<br/>col_list = [str(i +1) for i in range(random_dim[1])]<br/>col_list.append('target')<br/>train_clf = pd.DataFrame(train_clf, columns=col_list)</span><span id="6349" class="mo lm iq na b gy ni nf l ng nh">train_clf['target'] = train_clf['target'].astype('str')<br/>train_clf</span></pre><figure class="kv kw kx ky gt kz gh gi paragraph-image"><div class="gh gi nj"><img src="../Images/9aed463bb748f656789d0e86bd6cdf2a.png" data-original-src="https://miro.medium.com/v2/resize:fit:528/format:webp/1*865QRY3JDjhF5UJflnEcuA.png"/></div><figcaption class="lg lh gj gh gi li lj bd b be z dk translated">随机分类数据集-按作者分类的影像</figcaption></figure><p id="a102" class="pw-post-body-paragraph jw jx iq jy b jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ij bi translated">然后我们通过使用pycaret compare_models函数来比较机器学习模型。根据结果，最好的模型是<strong class="jy ja">虚拟分类器</strong>，因为特征和目标之间没有关系。</p><pre class="kv kw kx ky gt mz na nb nc aw nd bi"><span id="7c0d" class="mo lm iq na b gy ne nf l ng nh">from pycaret.classification import *</span><span id="6a90" class="mo lm iq na b gy ni nf l ng nh">clf = setup(data=train_clf, <br/>            target='target', <br/>            numeric_features=col_list[:-1], <br/>            silent=True)</span><span id="9313" class="mo lm iq na b gy ni nf l ng nh">compare_models(sort='Accuracy')</span></pre><figure class="kv kw kx ky gt kz gh gi paragraph-image"><div class="gh gi nk"><img src="../Images/895ce6015197d5921221ec53555f54dd.png" data-original-src="https://miro.medium.com/v2/resize:fit:1334/format:webp/1*CVqRL7S-rWw8Es0C2BGr7w.png"/></div><figcaption class="lg lh gj gh gi li lj bd b be z dk translated">虚拟分类器—按作者分类的图像</figcaption></figure><h2 id="f714" class="mo lm iq bd ln mp mq dn lr mr ms dp lv kh mt mu lz kl mv mw md kp mx my mh iw bi translated">机器学习基线模型</h2><p id="202a" class="pw-post-body-paragraph jw jx iq jy b jz mj kb kc kd mk kf kg kh ml kj kk kl mm kn ko kp mn kr ks kt ij bi translated">如果数据是可预测的，第二步是创建一个ml基线模型。这个基线模型向我们展示了哪些特征对于预测是重要的，哪些是不重要的。通常，ml基线模型与特征工程一起使用。</p><h2 id="0462" class="mo lm iq bd ln mp mq dn lr mr ms dp lv kh mt mu lz kl mv mw md kp mx my mh iw bi translated">1.基线分数</h2><p id="daf3" class="pw-post-body-paragraph jw jx iq jy b jz mj kb kc kd mk kf kg kh ml kj kk kl mm kn ko kp mn kr ks kt ij bi translated">第一步是基线ml模型的分数计算。</p><pre class="kv kw kx ky gt mz na nb nc aw nd bi"><span id="f364" class="mo lm iq na b gy ne nf l ng nh">from pycaret.classification import *<br/><br/>CAT_FEATURES = ['Sex', 'Embarked']<br/>NUM_FEATURES = ['Pclass', 'Age', 'SibSp', 'Parch', 'Fare']<br/>IGN_FEATURES = ['PassengerId', 'Name', 'Ticket', 'Cabin']<br/><br/>clf = setup(data=titanic_train, <br/>            target='Survived',<br/>            categorical_features = CAT_FEATURES,<br/>            numeric_features = NUM_FEATURES,<br/>            ignore_features = IGN_FEATURES)</span><span id="37ca" class="mo lm iq na b gy ni nf l ng nh">baseline_model = create_model('rf')<br/><br/>baseline_preds = predict_model(baseline_model, raw_score=True)<br/>baseline_preds</span></pre><figure class="kv kw kx ky gt kz gh gi paragraph-image"><div class="gh gi nl"><img src="../Images/defd7fa13fc3f69edb64d0940711a35f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1232/format:webp/1*LbXsdohcwnQD9qwsvmNMBA.png"/></div><figcaption class="lg lh gj gh gi li lj bd b be z dk translated">基线模型(随机森林)得分-作者提供的图片</figcaption></figure><h2 id="070f" class="mo lm iq bd ln mp mq dn lr mr ms dp lv kh mt mu lz kl mv mw md kp mx my mh iw bi translated">2.特征工程</h2><p id="42d0" class="pw-post-body-paragraph jw jx iq jy b jz mj kb kc kd mk kf kg kh ml kj kk kl mm kn ko kp mn kr ks kt ij bi translated">在这一部分中，我们向数据集添加新要素。</p><pre class="kv kw kx ky gt mz na nb nc aw nd bi"><span id="2276" class="mo lm iq na b gy ne nf l ng nh">import re<br/>from sklearn.feature_extraction.text import TfidfVectorizer<br/>from sklearn.decomposition import TruncatedSVD<br/><br/><em class="nm"># Name</em><br/>titanic_train_FeaEng = titanic_train.copy()<br/>name_last = titanic_train_FeaEng['Name'].str.split(' ', n=1, expand=True)[1]<br/>title = name_last.str.split(' ', n=1, expand=True)[0]<br/>titanic_train_FeaEng['Title'] = title<br/><br/>name_len = titanic_train_FeaEng['Name'].str.len()<br/>titanic_train_FeaEng['Name_len'] = name_len<br/><br/><em class="nm"># Cabin</em><br/>cabin_first = []<br/>cabin_last = []<br/>cabin_len = []<br/><br/>for cabin <strong class="na ja">in</strong> titanic_train_FeaEng['Cabin']:<br/>    try:<br/>        re_list = re.split('(\d+)',cabin)<br/>        if len(re_list) &gt; 1:<br/>            cabin_first.append(re_list[0])<br/>            cabin_last.append(int(re_list[-2]))<br/>            cabin_len.append(len(re_list))<br/>        else:<br/>            cabin_first.append('None')<br/>            cabin_last.append(0)<br/>            cabin_len.append(0)<br/>    except:<br/>        cabin_first.append('None')<br/>        cabin_last.append(0)<br/>        cabin_len.append(0)<br/><br/>titanic_train_FeaEng['Cabin_First'] = cabin_first<br/>titanic_train_FeaEng['Cabin_Last'] = cabin_last<br/>titanic_train_FeaEng['Cabin_Len'] = cabin_len<br/><br/><em class="nm">...</em></span></pre><h2 id="c201" class="mo lm iq bd ln mp mq dn lr mr ms dp lv kh mt mu lz kl mv mw md kp mx my mh iw bi translated">3.特征重要性</h2><p id="826f" class="pw-post-body-paragraph jw jx iq jy b jz mj kb kc kd mk kf kg kh ml kj kk kl mm kn ko kp mn kr ks kt ij bi translated">在特征工程之后，我们将一个接一个地向数据集添加新特征，并且我们查看基线机器学习的分数。如果我们有一个更好的分数，这意味着新的特征有利于预测。</p><pre class="kv kw kx ky gt mz na nb nc aw nd bi"><span id="7b1c" class="mo lm iq na b gy ne nf l ng nh">feature_score_dict = {}<br/><br/>for index, feature <strong class="na ja">in</strong> enumerate(new_features):<br/>    old_features_temp = old_features.copy()<br/>    old_features_temp.append(feature)<br/>    titanic_train_FeaEng_temp = titanic_train_FeaEng[<br/>old_features_temp].copy()<br/>    <br/>    clf = setup(data=titanic_train_FeaEng_temp, <br/>            target='Survived')<br/>    <br/>    baseline_model = create_model('rf')<br/>    scores = pull()<br/>    feature_score_dict[feature] = scores</span></pre><h2 id="9cc2" class="mo lm iq bd ln mp mq dn lr mr ms dp lv kh mt mu lz kl mv mw md kp mx my mh iw bi translated">4.分数数据准备</h2><p id="e08a" class="pw-post-body-paragraph jw jx iq jy b jz mj kb kc kd mk kf kg kh ml kj kk kl mm kn ko kp mn kr ks kt ij bi translated">在这一部分中，我们准备包括用于可视化的分数的数据集。</p><pre class="kv kw kx ky gt mz na nb nc aw nd bi"><span id="3246" class="mo lm iq na b gy ne nf l ng nh">metric_list = []<br/>feature_list = []<br/>score_list = []<br/><br/>for key <strong class="na ja">in</strong> feature_score_dict.keys():<br/>    metric_list.extend(list(feature_score_dict[key].columns))<br/>    score_list.extend(list(feature_score_dict[key].loc['Mean', :]))<br/>    feature_list.extend([key for i <strong class="na ja">in</strong> range(len(feature_score_dict[key].columns))])<br/><br/>all_scores_pd = pd.DataFrame()<br/>all_scores_pd['Metric'] = metric_list<br/>all_scores_pd['Feature'] = feature_list<br/>all_scores_pd['Score'] = score_list</span></pre><h2 id="7478" class="mo lm iq bd ln mp mq dn lr mr ms dp lv kh mt mu lz kl mv mw md kp mx my mh iw bi translated">5.形象化</h2><pre class="kv kw kx ky gt mz na nb nc aw nd bi"><span id="962d" class="mo lm iq na b gy ne nf l ng nh">import matplotlib.pyplot as plt<br/>import seaborn as sns<br/><br/>col_list = ['Accuracy', 'AUC', 'Recall', 'Prec.', 'F1', 'Kappa']<br/>score_color = {'Accuracy':'C0', 'AUC':'C1', 'Recall':'C2', 'Prec.':'C3', 'F1':'C4', 'Kappa':'C5'}</span><span id="236c" class="mo lm iq na b gy ni nf l ng nh">...</span></pre><figure class="kv kw kx ky gt kz gh gi paragraph-image"><div role="button" tabindex="0" class="la lb di lc bf ld"><div class="gh gi nn"><img src="../Images/e5a025d2b2530f9c0588e236f211959e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*TRxaxrLWb3-F66Xvhha4og.png"/></div></div><figcaption class="lg lh gj gh gi li lj bd b be z dk translated">新特征对预测的重要性—作者提供的图片</figcaption></figure><h2 id="1fe5" class="mo lm iq bd ln mp mq dn lr mr ms dp lv kh mt mu lz kl mv mw md kp mx my mh iw bi translated">自动化机器学习基线模型</h2><p id="ae86" class="pw-post-body-paragraph jw jx iq jy b jz mj kb kc kd mk kf kg kh ml kj kk kl mm kn ko kp mn kr ks kt ij bi translated">最终的基线模型是自动化的ml基线模型。这是一个非常好的模型，可以作为你的ml模型的基准。如果你的ml模型比自动化基线模型更好，这是模型可以成为产品的一个非常强烈的信号。</p><h2 id="884b" class="mo lm iq bd ln mp mq dn lr mr ms dp lv kh mt mu lz kl mv mw md kp mx my mh iw bi translated">1.LightAutoML</h2><p id="e300" class="pw-post-body-paragraph jw jx iq jy b jz mj kb kc kd mk kf kg kh ml kj kk kl mm kn ko kp mn kr ks kt ij bi translated">首先，我们安装并导入lightautoml库。</p><pre class="kv kw kx ky gt mz na nb nc aw nd bi"><span id="fb61" class="mo lm iq na b gy ne nf l ng nh">%%capture<br/>!pip install -U lightautoml</span><span id="c52f" class="mo lm iq na b gy ni nf l ng nh"><em class="nm"># Imports from our package</em><br/>from lightautoml.automl.presets.tabular_presets import TabularAutoML, TabularUtilizedAutoML<br/>from lightautoml.dataset.roles import DatetimeRole<br/>from lightautoml.tasks import Task<br/><br/>import torch</span></pre><p id="6221" class="pw-post-body-paragraph jw jx iq jy b jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ij bi translated">之后，我们为lightautoml库准备任务、角色和度量。</p><pre class="kv kw kx ky gt mz na nb nc aw nd bi"><span id="186a" class="mo lm iq na b gy ne nf l ng nh">from sklearn.metrics import accuracy_score<br/>from sklearn.metrics import f1_score<br/><br/>N_THREADS = 4 <em class="nm"># threads cnt for lgbm and linear models</em><br/>N_FOLDS = 5 <em class="nm"># folds cnt for AutoML</em><br/>RANDOM_STATE = 42 <em class="nm"># fixed random state for various reasons</em><br/>TEST_SIZE = 0.2 <em class="nm"># Test size for metric check</em><br/>TIMEOUT = 300 <em class="nm"># Time in seconds for automl run</em><br/><br/>np.random.seed(RANDOM_STATE)<br/>torch.set_num_threads(N_THREADS)<br/><br/>def acc_score(y_true, y_pred, **kwargs):<br/>    return accuracy_score(y_true, (y_pred &gt; 0.5).astype(int), **kwargs)<br/><br/>def f1_metric(y_true, y_pred, **kwargs):<br/>    return f1_score(y_true, (y_pred &gt; 0.5).astype(int), **kwargs)<br/><br/>task = Task('binary', metric = acc_score)<br/><br/>roles = {<br/>    'target': 'Survived',<br/>    'drop': ['Passengerid', 'Name', 'Ticket'],<br/>}</span></pre><p id="0770" class="pw-post-body-paragraph jw jx iq jy b jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ij bi translated">现在，我们可以使用下面的代码来计算交叉验证分数。</p><pre class="kv kw kx ky gt mz na nb nc aw nd bi"><span id="09ae" class="mo lm iq na b gy ne nf l ng nh">%%time <br/>from sklearn.model_selection import StratifiedKFold<br/><br/>n_fold = 3<br/>skf = StratifiedKFold(n_splits=n_fold)<br/>skf.get_n_splits(titanic_train)<br/><br/>...</span><span id="5403" class="mo lm iq na b gy ni nf l ng nh">print('lightautoml_acc_score: ', lightautoml_acc_score)</span><span id="d837" class="mo lm iq na b gy ni nf l ng nh">lightautoml_acc_score:  0.7957351290684626</span></pre><h2 id="ee00" class="mo lm iq bd ln mp mq dn lr mr ms dp lv kh mt mu lz kl mv mw md kp mx my mh iw bi translated">2.H2O汽车公司</h2><p id="9d88" class="pw-post-body-paragraph jw jx iq jy b jz mj kb kc kd mk kf kg kh ml kj kk kl mm kn ko kp mn kr ks kt ij bi translated">首先，我们导入h2o库。</p><pre class="kv kw kx ky gt mz na nb nc aw nd bi"><span id="951e" class="mo lm iq na b gy ne nf l ng nh">import h2o<br/>from h2o.automl import H2OAutoML</span><span id="c3fc" class="mo lm iq na b gy ni nf l ng nh">h2o.init()</span></pre><figure class="kv kw kx ky gt kz gh gi paragraph-image"><div role="button" tabindex="0" class="la lb di lc bf ld"><div class="gh gi no"><img src="../Images/d30a3439f78d789c916ccdedc17bceb3.png" data-original-src="https://miro.medium.com/v2/resize:fit:814/format:webp/1*fT2wCWrDGK3YWs8j_jjVTg.png"/></div></div><figcaption class="lg lh gj gh gi li lj bd b be z dk translated">H2O Init —作者图片</figcaption></figure><p id="a3fb" class="pw-post-body-paragraph jw jx iq jy b jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ij bi translated">现在，我们可以使用下面的代码来计算交叉验证分数。</p><pre class="kv kw kx ky gt mz na nb nc aw nd bi"><span id="87f5" class="mo lm iq na b gy ne nf l ng nh">%%time<br/>acc_list = []<br/>for train_index, test_index <strong class="na ja">in</strong> skf.split(titanic_train, titanic_train['Survived']):<br/>    X_train, X_test = titanic_train.loc[train_index, :], titanic_train.loc[test_index, :]<br/>    y = X_test['Survived'].astype(int)<br/>    X_test.drop(['Survived'], axis=1, inplace=True)</span><span id="def7" class="mo lm iq na b gy ni nf l ng nh">...</span><span id="fb86" class="mo lm iq na b gy ni nf l ng nh">print('h2o_tautoml_acc_score: ', h2o_tautoml_acc_score)</span><span id="0b0b" class="mo lm iq na b gy ni nf l ng nh">h2o_tautoml_acc_score:  0.8271604938271605</span></pre><h2 id="ec86" class="mo lm iq bd ln mp mq dn lr mr ms dp lv kh mt mu lz kl mv mw md kp mx my mh iw bi translated">3.形象化</h2><p id="d82b" class="pw-post-body-paragraph jw jx iq jy b jz mj kb kc kd mk kf kg kh ml kj kk kl mm kn ko kp mn kr ks kt ij bi translated">在计算自动ml模型的分数之后。现在，你可以在下面看到你应该通过的强力ml生产的分数。</p><pre class="kv kw kx ky gt mz na nb nc aw nd bi"><span id="990d" class="mo lm iq na b gy ne nf l ng nh">fig, ax = plt.subplots(figsize=(24, 8))<br/>ax.plot([0, 10], [h2o_tautoml_acc_score, h2o_tautoml_acc_score], color='r')<br/>ax.text(10, h2o_tautoml_acc_score, 'Base_H2O')<br/>ax.plot([0, 10], [lightautoml_acc_score, lightautoml_acc_score], color='r')<br/>ax.text(10, lightautoml_acc_score, 'Base_LightAutoMl');</span></pre><figure class="kv kw kx ky gt kz gh gi paragraph-image"><div role="button" tabindex="0" class="la lb di lc bf ld"><div class="gh gi np"><img src="../Images/c82427fd24d2eff277e0a14a262ba377.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*pynZevNkE7xh16SEiYKOpA.png"/></div></div><figcaption class="lg lh gj gh gi li lj bd b be z dk translated">自动ML分数-按作者排序的图片</figcaption></figure></div><div class="ab cl nq nr hu ns" role="separator"><span class="nt bw bk nu nv nw"/><span class="nt bw bk nu nv nw"/><span class="nt bw bk nu nv"/></div><div class="ij ik il im in"><p id="715a" class="pw-post-body-paragraph jw jx iq jy b jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ij bi translated">在文章的这一部分，我们讨论了分类问题中的基线模型类型。在文章的第二部分，我们将讨论回归问题中的基线模型。</p><p id="45c4" class="pw-post-body-paragraph jw jx iq jy b jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ij bi translated">从这里你可以看到完整的python代码和所有的情节👉<a class="ae lk" href="https://www.kaggle.com/hasanbasriakcay/baseline-models-clf-random-ml-automl" rel="noopener ugc nofollow" target="_blank"> Kaggle笔记本</a>。</p><p id="d831" class="pw-post-body-paragraph jw jx iq jy b jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ij bi translated">👋感谢阅读。如果你喜欢我的作品，别忘了喜欢它，在Medium 和<a class="ae lk" href="https://www.linkedin.com/in/hasan-basri-akcay/" rel="noopener ugc nofollow" target="_blank"> LinkedIn </a>上关注我<a class="ae lk" href="https://medium.com/@hasan.basri.akcay" rel="noopener">。这将激励我为媒体社区提供更多的内容！😊</a></p><h1 id="1278" class="ll lm iq bd ln lo lp lq lr ls lt lu lv lw lx ly lz ma mb mc md me mf mg mh mi bi translated">参考资料:</h1><p id="57b3" class="pw-post-body-paragraph jw jx iq jy b jz mj kb kc kd mk kf kg kh ml kj kk kl mm kn ko kp mn kr ks kt ij bi translated">[1]:<a class="ae lk" href="https://www.kaggle.com/hasanbasriakcay/baseline-models-clf-random-ml-automl" rel="noopener ugc nofollow" target="_blank">https://www . ka ggle . com/hasanbasriakcay/baseline-models-clf-random-ml-automl</a><br/>【2】:<a class="ae lk" href="https://www.kaggle.com/c/titanic/data" rel="noopener ugc nofollow" target="_blank">https://www.kaggle.com/c/titanic/data</a><br/>【3】:<a class="ae lk" href="https://pycaret.gitbook.io/docs/" rel="noopener ugc nofollow" target="_blank">https://pycaret.gitbook.io/docs/</a><br/>【4】:<a class="ae lk" href="https://lightautoml.readthedocs.io/en/latest/index.html" rel="noopener ugc nofollow" target="_blank">https://lightautoml.readthedocs.io/en/latest/index.html</a><br/>【5】:<a class="ae lk" href="https://docs.h2o.ai/h2o/latest-stable/h2o-docs/automl.html" rel="noopener ugc nofollow" target="_blank">https://docs.h2o.ai/h2o/latest-stable/h2o-docs/automl.html</a></p><h1 id="de7d" class="ll lm iq bd ln lo lp lq lr ls lt lu lv lw lx ly lz ma mb mc md me mf mg mh mi bi translated">更多…</h1><div class="nx ny gp gr nz oa"><a href="https://medium.com/databulls/welcome-2022-what-has-changed-in-data-science-in-2021-dac24bd37929" rel="noopener follow" target="_blank"><div class="ob ab fo"><div class="oc ab od cl cj oe"><h2 class="bd ja gy z fp of fr fs og fu fw iz bi translated">欢迎，2022🎉。2021年数据科学发生了什么变化？</h2><div class="oh l"><h3 class="bd b gy z fp of fr fs og fu fw dk translated">最好的数据科学工具、方法和技术，如云计算产品、自动化ML工具、课程、IDEs…</h3></div><div class="oi l"><p class="bd b dl z fp of fr fs og fu fw dk translated">medium.com</p></div></div><div class="oj l"><div class="ok l ol om on oj oo le oa"/></div></div></a></div><div class="nx ny gp gr nz oa"><a href="https://medium.com/databulls/what-are-the-differences-between-data-scientists-that-earn-500-and-225-000-yearly-ea60ccdf03d7" rel="noopener follow" target="_blank"><div class="ob ab fo"><div class="oc ab od cl cj oe"><h2 class="bd ja gy z fp of fr fs og fu fw iz bi translated">挣500的数据科学家有什么区别💲和225.000💲每年？</h2><div class="oh l"><h3 class="bd b gy z fp of fr fs og fu fw dk translated">这篇文章是关于重要的人才，工具，国家的特点，和公司的特点，为高收入在…</h3></div><div class="oi l"><p class="bd b dl z fp of fr fs og fu fw dk translated">medium.com</p></div></div><div class="oj l"><div class="op l ol om on oj oo le oa"/></div></div></a></div><div class="nx ny gp gr nz oa"><a href="https://medium.com/databulls/5-important-python-libraries-and-methods-for-data-scientists-491186e9f999" rel="noopener follow" target="_blank"><div class="ob ab fo"><div class="oc ab od cl cj oe"><h2 class="bd ja gy z fp of fr fs og fu fw iz bi translated">数据科学家的5个重要Python库和方法！</h2><div class="oh l"><h3 class="bd b gy z fp of fr fs og fu fw dk translated">大多数python库都是为数据科学编写的，但是数据科学和机器领域的新手…</h3></div><div class="oi l"><p class="bd b dl z fp of fr fs og fu fw dk translated">medium.com</p></div></div><div class="oj l"><div class="oq l ol om on oj oo le oa"/></div></div></a></div><div class="nx ny gp gr nz oa"><a href="https://medium.com/databulls/olympic-medal-numbers-predictions-with-timeseries-part-2-data-analysis-5d5d7e38fc37" rel="noopener follow" target="_blank"><div class="ob ab fo"><div class="oc ab od cl cj oe"><h2 class="bd ja gy z fp of fr fs og fu fw iz bi translated">用时间序列预测奥运奖牌数，第2部分:数据分析</h2><div class="oh l"><h3 class="bd b gy z fp of fr fs og fu fw dk translated">Fbprophet、Darts、AutoTS、Arima、Sarimax和蒙特卡洛模拟</h3></div><div class="oi l"><p class="bd b dl z fp of fr fs og fu fw dk translated">medium.com</p></div></div><div class="oj l"><div class="or l ol om on oj oo le oa"/></div></div></a></div></div></div>    
</body>
</html>