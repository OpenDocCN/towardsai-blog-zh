<html>
<head>
<title>All Types of ML Accelerators</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">所有类型的ML加速器</h1>
<blockquote>原文：<a href="https://pub.towardsai.net/5-types-of-ml-accelerators-767d26a643de?source=collection_archive---------1-----------------------#2022-10-31">https://pub.towardsai.net/5-types-of-ml-accelerators-767d26a643de?source=collection_archive---------1-----------------------#2022-10-31</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><h2 id="d5b0" class="io ip iq bd b dl ir is it iu iv iw dk ix translated" aria-label="kicker paragraph">人工智能工程</h2><div class=""/><div class=""><h2 id="fc70" class="pw-subtitle-paragraph jw iz iq bd b jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn dk translated">机器学习加速器从培训到服务的全面概述</h2></div><p id="85db" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">过去十年是深度学习的时代。从AlphaGo到DELL-E 2等等，我们为不断出现的里程碑而激动不已。而且我们无法统计在我们的日常生活中发生了多少AI驱动的事情，包括Alexa设备、广告推荐、仓库机器人、自动驾驶汽车等等。</p><figure class="ll lm ln lo gt lp gh gi paragraph-image"><div role="button" tabindex="0" class="lq lr di ls bf lt"><div class="gh gi lk"><img src="../Images/5503548501c24da715fd1c56593ab3af.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*m6HaYEXmiRz8RRsn"/></div></div><figcaption class="lw lx gj gh gi ly lz bd b be z dk translated">Joshua Woroniecki 在<a class="ae ma" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上的照片</figcaption></figure><p id="8a7b" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">近年来，深度学习模型的规模呈指数级增长。武道2.0模型包含<a class="ae ma" href="https://towardsdatascience.com/distributed-parallel-training-data-parallelism-and-model-parallelism-ec2d234e3214" rel="noopener" target="_blank"> 1.75万亿</a>参数，在SageMaker训练平台240 ml.p4d.24xlarge实例上训练GPT-3大概需要<a class="ae ma" href="https://towardsdatascience.com/distributed-parallel-training-model-parallel-training-a768058aa02a" rel="noopener" target="_blank"> 25天</a>，这已经不是新闻了。</p><p id="0de2" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">但是随着深度学习训练和服务的发展，它变得越来越具有挑战性。<strong class="kq ja"> <em class="mb">可扩展性</em>和<em class="mb">效率</em> </strong>是深度学习模型增长对训练和服务的两大挑战。</p><p id="a180" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated"><em class="mb">深度学习系统是否墨守成规？</em></p><p id="966d" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated"><strong class="kq ja">不</strong>！我在之前的两篇文章中介绍了用于扩展训练的分布式并行训练:<a class="ae ma" href="https://towardsdatascience.com/distributed-parallel-training-model-parallel-training-a768058aa02a" rel="noopener" target="_blank">模型并行</a>和<a class="ae ma" href="https://towardsdatascience.com/distributed-parallel-training-data-parallelism-and-model-parallelism-ec2d234e3214" rel="noopener" target="_blank">分布式并行训练</a>。为了加速训练和服务，我分享了<a class="ae ma" href="https://medium.com/@luhuihu/inside-ml-compilers-ae28afbc4907" rel="noopener"> ML编译器</a>。</p><p id="b472" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated"><em class="mb">这些都是深度学习保护伞的解决方案吗？</em></p><p id="aa61" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated"><strong class="kq ja">不</strong>！在这里，我将总结五种主要类型的ML加速器或加速区域。</p><h2 id="a56a" class="mc md iq bd me mf mg dn mh mi mj dp mk kx ml mm mn lb mo mp mq lf mr ms mt iw bi translated">理解人工智能工程中的ML生命周期</h2><p id="fcf8" class="pw-post-body-paragraph ko kp iq kq b kr mu ka kt ku mv kd kw kx mw kz la lb mx ld le lf my lh li lj ij bi translated">在全面介绍ML加速器之前，让我们先来看看ML的生命周期。</p><p id="7e22" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">ML生命周期是数据和模型的生命周期。数据是ML的食粮，可以决定模型质量。生命周期中的每个领域都充满了加速的机会。</p><p id="55ac" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">MLOps可以自动化ML模型部署和服务的过程。但由于运营的性质，它仅限于AI工作流的<strong class="kq ja"> <em class="mb">横向</em> </strong>流程，无法从根本上改善培训和服务。</p><p id="b87d" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">AI工程，远超MLOps，可以<strong class="kq ja"> <em class="mb">整体</em> </strong>(横向和纵向)工程化ML工作流的流程以及培训和服务的架构。此外，它可以通过对整个ML生命周期的有效编排来加速服务和培训。</p><p id="ad8f" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">基于人工智能工程的整体人工智能生命周期，有五种主要类型的人工智能加速器(或加速领域):<em class="mb">硬件加速器、人工智能计算平台、人工智能框架、人工智能编译器和云服务</em>。请看下面他们的关系图。</p><figure class="ll lm ln lo gt lp gh gi paragraph-image"><div role="button" tabindex="0" class="lq lr di ls bf lt"><div class="gh gi mz"><img src="../Images/393cfb0932877c86b95e4b333ddac96f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*EyyvGoYT80-aHizaxlQQFA.png"/></div></div><figcaption class="lw lx gj gh gi ly lz bd b be z dk translated">培训和服务加速器的关系(作者)</figcaption></figure><p id="3695" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">我们可以看到硬件加速器和AI框架是加速的主流。但最近，ML编译器、AI计算平台和ML云服务变得越来越重要。</p><p id="dc37" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">让我们仔细看看下面的所有五个AI加速器。</p><h2 id="6b03" class="mc md iq bd me mf mg dn mh mi mj dp mk kx ml mm mn lb mo mp mq lf mr ms mt iw bi translated">1.人工智能框架</h2><p id="73dc" class="pw-post-body-paragraph ko kp iq kq b kr mu ka kt ku mv kd kw kx mw kz la lb mx ld le lf my lh li lj ij bi translated">当谈到加速人工智能训练和服务时，我们不能跳过选择正确的人工智能框架。可悲的是，没有完美或最好的人工智能框架适用于所有用例。研究和生产中广泛使用的三个AI框架是<strong class="kq ja"> <em class="mb"> TensorFlow、PyTorch和JAX </em> </strong>。它们从不同的角度出发，例如易用性、产品成熟度和可伸缩性。</p><p id="a1bd" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated"><strong class="kq ja"> TensorFlow </strong> : TensorFlow是旗舰AI框架。TensorFlow从一开始就主导了深度学习开源社区。TensorFlow服务是一个定义明确的成熟平台。<a class="ae ma" href="https://www.tensorflow.org/js" rel="noopener ugc nofollow" target="_blank"> TensorFlow.js </a>和<a class="ae ma" href="https://www.tensorflow.org/lite/" rel="noopener ugc nofollow" target="_blank"> TensorFlow Lite </a>对于web和IoT来说也已经成熟。</p><p id="ac9e" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">但由于深度学习早期探索的局限性，TensorFlow 1.x完全是以一种非常非Pythonic化的方式构建静态图。这成为使用“渴望”模式进行即时评估的障碍，这使得PyTorch在研究中快速上升。TensorFlow 2.x试图追赶，可惜从TensorFlow 1.x升级到2.x不得不野蛮。</p><p id="31b5" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">TensorFlow还推出了Keras，以便从高层更容易使用，以及<a class="ae ma" href="https://www.tensorflow.org/xla" rel="noopener ugc nofollow" target="_blank"> XLA </a>(加速线性代数)优化编译器，以提高低层速度。</p><p id="6124" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">PyTorch :凭借其热切的模式和Pythonic式的方法，PyTorch是当今深度学习领域(从研究到生产)的一支重要力量。除了<a class="ae ma" href="https://pytorch.org/serve/" rel="noopener ugc nofollow" target="_blank"> TorchServe </a>，PyTorch还集成了与框架无关的平台，比如<a class="ae ma" href="https://www.kubeflow.org/" rel="noopener ugc nofollow" target="_blank"> Kubeflow </a>。此外，PyTorch的受欢迎程度与拥抱脸的<a class="ae ma" href="https://huggingface.co/docs/transformers/index" rel="noopener ugc nofollow" target="_blank">变形金刚</a>库的成功密不可分。</p><p id="1969" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated"><strong class="kq ja"> JAX </strong>:基于设备加速<a class="ae ma" href="https://numpy.org/" rel="noopener ugc nofollow" target="_blank"> NumPy </a>和JIT(准时制)，谷歌推出<a class="ae ma" href="https://github.com/google/jax" rel="noopener ugc nofollow" target="_blank"> JAX </a>。正如PyTorch几年前所做的那样，这是一个更为本土的深度学习框架，在研究中迅速获得了牵引力。但它还不是谷歌声称的“官方”产品。</p><h2 id="a378" class="mc md iq bd me mf mg dn mh mi mj dp mk kx ml mm mn lb mo mp mq lf mr ms mt iw bi translated">2.硬件加速器</h2><p id="52d1" class="pw-post-body-paragraph ko kp iq kq b kr mu ka kt ku mv kd kw kx mw kz la lb mx ld le lf my lh li lj ij bi translated">我们可以有一篇关于硬件加速器的长篇文章。毫无疑问，NVIDIA的GPU点燃了加速DL训练，尽管它最初是为了显卡。</p><p id="01f5" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">用于神经网络训练的显卡在<a class="ae ma" href="https://www.deeplearningbook.org/contents/applications.html" rel="noopener ugc nofollow" target="_blank">通用GPU</a>问世后爆发式流行。这些GP-GPU可以执行任意代码，而不仅仅是渲染子例程。NVIDIA的CUDA编程语言提供了一种用类C语言编写任意代码的方法。凭借其相对方便的编程模型、大规模并行性和高内存带宽，gp-GPU现在成为神经网络编程的理想平台。</p><p id="198d" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">今天，NVIDIA支持从桌面到移动、工作站、移动工作站、控制台和数据中心的一系列GPU。</p><p id="6c81" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">随着英伟达GPU的成功，一路上不乏后继者，比如AMD的GPU，谷歌的TPU ASIC等</p><h2 id="d0ad" class="mc md iq bd me mf mg dn mh mi mj dp mk kx ml mm mn lb mo mp mq lf mr ms mt iw bi translated">3.人工智能计算平台</h2><p id="9565" class="pw-post-body-paragraph ko kp iq kq b kr mu ka kt ku mv kd kw kx mw kz la lb mx ld le lf my lh li lj ij bi translated">如上所述，ML训练和服务的速度很大程度上取决于硬件(例如，GPU和TPU)。这些驱动因素(即人工智能计算平台)对性能至关重要。比较知名的有两个:<em class="mb"> CUDA和OpenCL </em>。</p><p id="b3cc" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated"><strong class="kq ja"> CUDA </strong> : CUDA(计算统一设备架构)是NVIDIA于2007年发布的并行编程范例。它是为图形处理器和GPU的大量通用应用程序而设计的。CUDA是一个专有的API，只支持NVIDIA针对特斯拉架构的GPU。支持CUDA的显卡有GeForce 8系列、Tesla和Quadro。</p><p id="14ad" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated"><strong class="kq ja"> OpenCL </strong> : <a class="ae ma" href="https://en.wikipedia.org/wiki/OpenCL" rel="noopener ugc nofollow" target="_blank"> OpenCL </a>(开放计算语言)最初由苹果公司开发，由Khronos集团维护，用于异构计算，包括CPU、GPU、DSP和其他类型的处理器。这种可移植语言的适应性足以让每个硬件平台实现高性能，包括英伟达的GPU。</p><p id="160a" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">NVIDIA现在符合<a class="ae ma" href="https://developer.nvidia.com/opencl" rel="noopener ugc nofollow" target="_blank"> OpenCL 3.0 </a>，可用于R465和更高版本的驱动程序。使用OpenCL API，人们可以在GPU上启动使用C编程语言的有限子集编写的计算内核。</p><h2 id="d522" class="mc md iq bd me mf mg dn mh mi mj dp mk kx ml mm mn lb mo mp mq lf mr ms mt iw bi translated">4.ML编译器</h2><p id="e08d" class="pw-post-body-paragraph ko kp iq kq b kr mu ka kt ku mv kd kw kx mw kz la lb mx ld le lf my lh li lj ij bi translated">ML编译器在加速训练和服务方面起着至关重要的作用。ML编译器可以显著提高大规模模型服务的效率。有很多流行的编译器，比如<em class="mb"> Apache TVM、LLVM、谷歌MLIR、TensorFlow XLA、Meta Glow、PyTorch nvFuser、Intel PlaidML </em>。更多详情请参考<a class="ae ma" href="https://medium.com/@luhuihu/inside-ml-compilers-ae28afbc4907" rel="noopener"> ML编译器</a>。</p><h2 id="127f" class="mc md iq bd me mf mg dn mh mi mj dp mk kx ml mm mn lb mo mp mq lf mr ms mt iw bi translated">5.ML云服务</h2><p id="4738" class="pw-post-body-paragraph ko kp iq kq b kr mu ka kt ku mv kd kw kx mw kz la lb mx ld le lf my lh li lj ij bi translated">ML云平台和服务管理云中的ML平台。他们可以通过多种方式优化以提高效率。</p><p id="46ed" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">以亚马逊<a class="ae ma" href="https://aws.amazon.com/sagemaker" rel="noopener ugc nofollow" target="_blank"> SageMaker </a>为例。是领先的ML云平台服务。SageMaker为ML生命周期提供了广泛的功能，从准备到构建、培训/调整，以及部署/管理。</p><p id="480d" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">它优化了许多训练和服务效率的方法，例如，GPU上的<a class="ae ma" href="https://aws.amazon.com/blogs/machine-learning/run-multiple-deep-learning-models-on-gpu-with-amazon-sagemaker-multi-model-endpoints/" rel="noopener ugc nofollow" target="_blank">多模型端点</a>，使用<a class="ae ma" href="https://aws.amazon.com/blogs/machine-learning/improve-price-performance-of-your-model-training-using-amazon-sagemaker-heterogeneous-clusters/" rel="noopener ugc nofollow" target="_blank">异构集群</a>的经济高效的训练，以及适用于基于CPU的ML推理的专有<a class="ae ma" href="https://aws.amazon.com/blogs/machine-learning/aws-celebrates-5-years-of-innovation-with-amazon-sagemaker/" rel="noopener ugc nofollow" target="_blank"> Graviton </a>处理器。</p><h2 id="9d51" class="mc md iq bd me mf mg dn mh mi mj dp mk kx ml mm mn lb mo mp mq lf mr ms mt iw bi translated">最后的评论</h2><p id="d0ff" class="pw-post-body-paragraph ko kp iq kq b kr mu ka kt ku mv kd kw kx mw kz la lb mx ld le lf my lh li lj ij bi translated">随着DL培训和服务规模的扩大，这变得越来越具有挑战性。提高DL培训和服务效率是复杂的。基于ML生命周期，有五个领域可以加速ML培训和服务:<em class="mb"> AI框架、硬件加速器、计算平台、ML编译器和云服务</em>。人工智能工程可以用工程原理将所有这些协调在一起，以获得综合效率。</p></div></div>    
</body>
</html>