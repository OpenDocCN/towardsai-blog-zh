<html>
<head>
<title>Beginners Guide to Convolutional Neural Network from Scratch — Kuzushiji-MNIST</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">卷积神经网络入门指南-MNIST</h1>
<blockquote>原文：<a href="https://pub.towardsai.net/beginner-guides-to-convolutional-neural-network-from-scratch-kuzushiji-mnist-75f42c175b21?source=collection_archive---------0-----------------------#2019-06-03">https://pub.towardsai.net/beginner-guides-to-convolutional-neural-network-from-scratch-kuzushiji-mnist-75f42c175b21?source=collection_archive---------0-----------------------#2019-06-03</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><h2 id="3375" class="io ip iq bd b dl ir is it iu iv iw dk ix translated" aria-label="kicker paragraph"><a class="ae ep" href="https://towardsai.net/p/category/machine-learning" rel="noopener ugc nofollow" target="_blank">机器学习</a></h2><div class=""/><figure class="gl gn jx jy jz ka gh gi paragraph-image"><div role="button" tabindex="0" class="kb kc di kd bf ke"><div class="gh gi jw"><img src="../Images/fff293357945e7f1d58d1fca7db08cbd.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*3BRLw4lsANPEfGgimG3YVQ.png"/></div></div><figcaption class="kh ki gj gh gi kj kk bd b be z dk translated"><strong class="bd kl">图1 </strong>:卷积神经网络(<strong class="bd kl">来源</strong>:<a class="ae km" href="https://en.wikipedia.org/wiki/Convolutional_neural_network" rel="noopener ugc nofollow" target="_blank">https://en.wikipedia.org/wiki/Convolutional_neural_network</a>)</figcaption></figure><p id="d5d9" class="pw-post-body-paragraph kn ko iq kp b kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj lk ij bi translated">在之前的文章中，你可以在这里查看，我已经在库祖什基-MNIST (KMNIST)数据集上演示了各种降维技术。在这篇文章中，我将使用<code class="fe ll lm ln lo b">keras</code>从头构建卷积神经网络来预测KMNIST的类。</p><h1 id="69e7" class="lp lq iq bd kl lr ls lt lu lv lw lx ly lz ma mb mc md me mf mg mh mi mj mk ml bi translated">CNN是什么？</h1><p id="46a8" class="pw-post-body-paragraph kn ko iq kp b kq mm ks kt ku mn kw kx ky mo la lb lc mp le lf lg mq li lj lk ij bi translated">人工智能在过去几年里发展得更快，它是计算机科学的一个子领域，旨在创造智能机器。</p><p id="e7fc" class="pw-post-body-paragraph kn ko iq kp b kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj lk ij bi translated">人工智能有很多研究领域，例如，语音识别、自然语言处理(NLP)和计算机视觉。我将在这篇文章中重点介绍<strong class="kp ja"> <em class="mr">计算机视觉</em> </strong>。</p><figure class="mt mu mv mw gt ka gh gi paragraph-image"><div role="button" tabindex="0" class="kb kc di kd bf ke"><div class="gh gi ms"><img src="../Images/44bcf1746ae83b62252a4e4b7b9ee8e2.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*c8Onoc1mx9MqfGKw--n-dA.jpeg"/></div></div><figcaption class="kh ki gj gh gi kj kk bd b be z dk translated"><strong class="bd kl">图2: </strong>计算机视觉任务示例(<strong class="bd kl">来源</strong> : <a class="ae km" href="http://cs231n.stanford.edu/slides/2016/winter1516_lecture8.pdf" rel="noopener ugc nofollow" target="_blank">费-李非，安德烈·卡帕西&amp;贾斯廷·约翰逊(2016) </a>)</figcaption></figure><p id="b045" class="pw-post-body-paragraph kn ko iq kp b kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj lk ij bi translated">计算机视觉的目标是使机器、计算机或程序能够像人类一样观察世界，并将这些知识应用于特定的任务，如图像和视频识别、图像分类。这是随着深度学习算法的进步而实现的，更具体地说，是一个<strong class="kp ja">卷积神经网络</strong> (CNN / ConvNet)。</p><blockquote class="mx my mz"><p id="0eb2" class="kn ko mr kp b kq kr ks kt ku kv kw kx na kz la lb nb ld le lf nc lh li lj lk ij bi translated">卷积网络的架构是动物大脑中神经元的连接模式，受生物过程的启发，神经元之间的连接模式类似于动物视觉皮层的组织<a class="ae km" href="https://en.wikipedia.org/wiki/Visual_cortex" rel="noopener ugc nofollow" target="_blank"/>。</p></blockquote><p id="97a7" class="pw-post-body-paragraph kn ko iq kp b kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj lk ij bi translated">卷积神经网络具有通过应用相关滤波器来捕捉输入图像中的空间和时间依赖性的能力。由于所涉及的参数数量的减少和权重的可重用性，它对于图像数据集表现得更好。</p></div><div class="ab cl nd ne hu nf" role="separator"><span class="ng bw bk nh ni nj"/><span class="ng bw bk nh ni nj"/><span class="ng bw bk nh ni"/></div><div class="ij ik il im in"><h1 id="2699" class="lp lq iq bd kl lr nk lt lu lv nl lx ly lz nm mb mc md nn mf mg mh no mj mk ml bi translated">它是如何工作的？</h1><p id="e287" class="pw-post-body-paragraph kn ko iq kp b kq mm ks kt ku mn kw kx ky mo la lb lc mp le lf lg mq li lj lk ij bi translated">卷积神经网络(或ConvNets)不像我们人类那样查看图像。我们将图像视为带有颜色的平面画布，我们可能不太关心图像的宽度和高度，但我们可以感知这些参数。</p><figure class="mt mu mv mw gt ka gh gi paragraph-image"><div class="gh gi np"><img src="../Images/15678b561f287752cf34851da0fbd225.png" data-original-src="https://miro.medium.com/v2/resize:fit:1290/format:webp/1*oN0qi9u-OLxzYx08c2o1Ow.png"/></div><figcaption class="kh ki gj gh gi kj kk bd b be z dk translated">图3: RGB颜色组合</figcaption></figure><p id="f5d1" class="pw-post-body-paragraph kn ko iq kp b kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj lk ij bi translated">然而，ConvNets将图像视为不同维度的对象，例如三维对象，其中三维作为颜色编码(或颜色通道)，主要是红绿蓝(RGB)，它组合并产生我们看到的颜色(当然，不仅仅是RGB，例如灰度、HSV和CMYK)。</p><figure class="mt mu mv mw gt ka gh gi paragraph-image"><div role="button" tabindex="0" class="kb kc di kd bf ke"><div class="gh gi nq"><img src="../Images/1f8d92fbc75ce78c7c3ec17cb45b5956.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*BxoE8OyDrVoODWNS3W9adQ.jpeg"/></div></div><figcaption class="kh ki gj gh gi kj kk bd b be z dk translated">图4: 3x3x3 RGB图像</figcaption></figure><p id="a9db" class="pw-post-body-paragraph kn ko iq kp b kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj lk ij bi translated">实现ConvNets的第一个关键点是精确测量图像的每个维度，因为它将成为用于处理图像的线性代数运算的基础。</p><p id="0d96" class="pw-post-body-paragraph kn ko iq kp b kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj lk ij bi translated">图4演示了ConvNets如何处理RGB图像，每一层代表颜色(R-G-B ),数字代表强度(范围在0到255之间)。</p><figure class="mt mu mv mw gt ka gh gi paragraph-image"><div class="gh gi nr"><img src="../Images/4b4a7e0fb64f0bdbf274c70aebea7d6d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1266/format:webp/1*MG2tPqvNWe2457us0hkM9A.jpeg"/></div><figcaption class="kh ki gj gh gi kj kk bd b be z dk translated">图5: RGB(5，1，4)</figcaption></figure><p id="7b03" class="pw-post-body-paragraph kn ko iq kp b kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj lk ij bi translated">从图4继续，如果我们取左上角的像素，RGB (5，1，4)。我们的眼睛会看到紫色。</p><p id="43f7" class="pw-post-body-paragraph kn ko iq kp b kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj lk ij bi translated">想象一下现在的数码照片，一个700万像素的相机可以产生3072 x 2304像素(虽然我不是相机方面的专家！！)，那么这将是多么大的计算量呢？</p><p id="3ae9" class="pw-post-body-paragraph kn ko iq kp b kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj lk ij bi translated">卷积神经网络(ConvNets)要找出这些数字中哪些是重要信号(通过将图像简化为更容易处理的形式，并且不损失特征)，这实际上有助于它更准确地对图像进行分类。这是在设计ConvNet架构时要记住的另一个重要概念，该架构不仅擅长学习特征，而且更适合大规模图像数据集。</p></div><div class="ab cl nd ne hu nf" role="separator"><span class="ng bw bk nh ni nj"/><span class="ng bw bk nh ni nj"/><span class="ng bw bk nh ni"/></div><div class="ij ik il im in"><h1 id="e549" class="lp lq iq bd kl lr nk lt lu lv nl lx ly lz nm mb mc md nn mf mg mh no mj mk ml bi translated">卷积神经网络层</h1><figure class="mt mu mv mw gt ka gh gi paragraph-image"><div role="button" tabindex="0" class="kb kc di kd bf ke"><div class="gh gi ns"><img src="../Images/c3761afe8e91c27430581aa93ec24743.png" data-original-src="https://miro.medium.com/v2/resize:fit:1256/format:webp/1*RM7nqjYSMxkc0QlCxERQnw.png"/></div></div><figcaption class="kh ki gj gh gi kj kk bd b be z dk translated">图ConvNet架构示例</figcaption></figure><p id="058c" class="pw-post-body-paragraph kn ko iq kp b kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj lk ij bi translated">ConvNets中实现了几个主要层。</p><p id="fed2" class="pw-post-body-paragraph kn ko iq kp b kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj lk ij bi translated"><strong class="kp ja"> Conv2D层</strong></p><p id="7627" class="pw-post-body-paragraph kn ko iq kp b kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj lk ij bi translated">它是一个二维卷积层，主要用于从原始输入图像中提取特征。第一层负责捕捉低级特征，例如边缘、颜色、梯度方向。随着层的增加，该架构将试图捕捉高级功能。</p><figure class="mt mu mv mw gt ka gh gi paragraph-image"><div class="gh gi nt"><img src="../Images/c36c8d062fcfe7f5c7b078c614c2f2df.png" data-original-src="https://miro.medium.com/v2/resize:fit:936/format:webp/1*teV9bFJrVSRYhJdGFZLY9g.jpeg"/></div><figcaption class="kh ki gj gh gi kj kk bd b be z dk translated">图7:一维卷积</figcaption></figure><p id="f34d" class="pw-post-body-paragraph kn ko iq kp b kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj lk ij bi translated">Conv2D滤镜贯穿图像中的三个通道(红绿蓝)。每个频道的滤波器也可以不同。</p><p id="6c7f" class="pw-post-body-paragraph kn ko iq kp b kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj lk ij bi translated">红色区域显示当前<strong class="kp ja">滤波器</strong>被计算的区域，称为<strong class="kp ja">感受野</strong>。滤波器中的数字称为<strong class="kp ja">权重</strong>或<strong class="kp ja">参数</strong>。滤波器在图像周围滑动(或卷积)，它将计算<em class="mr">逐元素乘法</em>并将输出填充到输出，这被称为<strong class="kp ja">激活图</strong>(或<strong class="kp ja">特征图</strong>)。</p><p id="26e7" class="pw-post-body-paragraph kn ko iq kp b kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj lk ij bi translated">我们可以有多个卷积层来识别和捕捉高级特征，但这需要更多的计算能力。</p><p id="661d" class="pw-post-body-paragraph kn ko iq kp b kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj lk ij bi translated"><strong class="kp ja">汇集层</strong></p><p id="7fab" class="pw-post-body-paragraph kn ko iq kp b kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj lk ij bi translated">卷积层之后的下一层是汇集层(或下采样或子采样)。激活贴图被输入到下采样层，这个层将一次应用一个补丁(像卷积层)。</p><p id="105a" class="pw-post-body-paragraph kn ko iq kp b kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj lk ij bi translated">汇集图层逐渐减小了制图表达的空间大小。因此，它减少了网络中的参数数量和计算量。汇集层也旨在控制过度拟合。</p><figure class="mt mu mv mw gt ka gh gi paragraph-image"><div class="gh gi nu"><img src="../Images/6bb1dc2ab407ed327b771e05726cebb8.png" data-original-src="https://miro.medium.com/v2/resize:fit:1030/format:webp/1*aBRJyTG1vHqRHqit7k7r7A.jpeg"/></div><figcaption class="kh ki gj gh gi kj kk bd b be z dk translated">图8:池层的类型</figcaption></figure><p id="c860" class="pw-post-body-paragraph kn ko iq kp b kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj lk ij bi translated">有两种主要类型的池层:<strong class="kp ja">最大池</strong>返回特定池大小(2x2)的最大值，而<strong class="kp ja">平均池</strong>返回特定池大小的所有值的平均值，如图8所示。</p><p id="a848" class="pw-post-body-paragraph kn ko iq kp b kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj lk ij bi translated">最大池作为<strong class="kp ja">噪声抑制</strong>，而平均池作为噪声抑制机制进行维度缩减。因此，<strong class="kp ja"> max-pooling比平均池</strong>执行得好得多，并且是<strong class="kp ja">最常实现的</strong>池层。</p><p id="fcf2" class="pw-post-body-paragraph kn ko iq kp b kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj lk ij bi translated">在经历了上面的max-pooling层之后，我们已经使ConvNet模型能够理解图像特征。下一部分，我们将把它输入到完全连接的神经网络进行分类。</p><p id="eb96" class="pw-post-body-paragraph kn ko iq kp b kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj lk ij bi translated">然而，在将池层的输出馈送到全连接层之前，我们需要一个中间层来转换FC层中分类任务的数据的维度，这个中间层被称为<strong class="kp ja">扁平化层</strong>。</p><p id="a441" class="pw-post-body-paragraph kn ko iq kp b kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj lk ij bi translated"><strong class="kp ja">展平图层</strong></p><figure class="mt mu mv mw gt ka gh gi paragraph-image"><div class="gh gi nv"><img src="../Images/eab03003c5cab6a668acc79aa33dc9b4.png" data-original-src="https://miro.medium.com/v2/resize:fit:966/format:webp/1*9g4qz27omAxNE0zGOGTiBw.png"/></div><figcaption class="kh ki gj gh gi kj kk bd b be z dk translated">图9:展平图层</figcaption></figure><p id="1b94" class="pw-post-body-paragraph kn ko iq kp b kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj lk ij bi translated">如前所述，顾名思义，这一层将把多维数组展平/转换成一个长的连续的线性向量。用更专业的术语来说，它打破了数据的空间结构，将多维张量转换为一维张量，因此成为向量。</p><p id="a448" class="pw-post-body-paragraph kn ko iq kp b kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj lk ij bi translated"><strong class="kp ja">密集/全连通层</strong></p><p id="c5e9" class="pw-post-body-paragraph kn ko iq kp b kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj lk ij bi translated">每个神经元接收来自前一层所有神经元的输入，因此连接紧密。该层具有权重矩阵𝑊、偏置向量𝛽和前一层的激活𝑎.从图10a中可以看到一个例子。</p><p id="a0bb" class="pw-post-body-paragraph kn ko iq kp b kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj lk ij bi translated"><code class="fe ll lm ln lo b">Dense</code>实现<code class="fe ll lm ln lo b">output = activation(dot(input, kernel) + bias)</code>的操作。</p><p id="fc16" class="pw-post-body-paragraph kn ko iq kp b kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj lk ij bi translated"><strong class="kp ja">辍学</strong></p><figure class="mt mu mv mw gt ka gh gi paragraph-image"><div role="button" tabindex="0" class="kb kc di kd bf ke"><div class="gh gi nw"><img src="../Images/82b81af7209aa3e2d517cff9e2cdcb59.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*uQW2mYEVMCuUDBSDeNY6iQ.png"/></div></div><figcaption class="kh ki gj gh gi kj kk bd b be z dk translated">图10: Dropout method ( <strong class="bd kl">来源</strong> : Giorgio Roffo，<a class="ae km" href="https://www.researchgate.net/publication/317277576_Ranking_to_Learn_and_Learning_to_Rank_On_the_Role_of_Ranking_in_Pattern_Recognition_Applications" rel="noopener ugc nofollow" target="_blank"> Ranking to Learn和Learning to Rank:On the rolling in Pattern Recognition Applications</a><strong class="bd kl">)</strong></figcaption></figure><p id="d818" class="pw-post-body-paragraph kn ko iq kp b kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj lk ij bi translated">实际上，丢弃是一种<strong class="kp ja">正则化</strong>方法，在训练过程中，一些层输出的数量被随机忽略(丢弃，切换)。这种实现将具有使层被处理的效果——如同具有不同数量的节点和到前一层的连接的不同层。</p><p id="1272" class="pw-post-body-paragraph kn ko iq kp b kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj lk ij bi translated">在卷积网络中，丢失通常在全连接层而不是卷积层实现。</p></div><div class="ab cl nd ne hu nf" role="separator"><span class="ng bw bk nh ni nj"/><span class="ng bw bk nh ni nj"/><span class="ng bw bk nh ni"/></div><div class="ij ik il im in"><h1 id="c114" class="lp lq iq bd kl lr nk lt lu lv nl lx ly lz nm mb mc md nn mf mg mh no mj mk ml bi translated">Python在库祖什基-MNIST上的实现</h1><p id="29ab" class="pw-post-body-paragraph kn ko iq kp b kq mm ks kt ku mn kw kx ky mo la lb lc mp le lf lg mq li lj lk ij bi translated">在前一节中，提供了所有相关层的概念和定义。我将结合这些概念，使用<code class="fe ll lm ln lo b">keras</code>用Python语言对库祖什基-MNIST进行分类，并从头实现ConvNet。我将演示如何编写我们自己的回调对象，以便在模型中使用。</p><p id="bd95" class="pw-post-body-paragraph kn ko iq kp b kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj lk ij bi translated">KMNIST是MNIST数据集的替代产品，它也表示十类平假名字符。给定的数据集具有60，000幅训练图像和10，000幅测试图像。所有像素都是28x28像素。每个类均匀分布(10个类，每个类有6，000个图像)。</p><figure class="mt mu mv mw gt ka gh gi paragraph-image"><div role="button" tabindex="0" class="kb kc di kd bf ke"><div class="gh gi nx"><img src="../Images/5094e74c33b8601d3825a26925d5da59.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*rriNIcMJ6Pl8ZecD0lOzQg.jpeg"/></div></div><figcaption class="kh ki gj gh gi kj kk bd b be z dk translated">图11: Kuzushiji-MNIST</figcaption></figure><p id="4c5d" class="pw-post-body-paragraph kn ko iq kp b kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj lk ij bi translated">标签以从0到9的数字形式提供，每个数字代表不同的平假名字符(即0: お，1: き).图像也以<em class="mr"> NumPy </em>数组格式提供，形状为<code class="fe ll lm ln lo b">(60000, 28, 28)</code>。</p><p id="fc48" class="pw-post-body-paragraph kn ko iq kp b kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj lk ij bi translated">我们需要对图像(缩放到0和1)和标签(分类编码)数据集进行几次输入转换。最有效的方法是实现一个函数来处理，因为我们可以将它应用于训练和测试数据。我还将进一步细分训练数据，以创建一个<strong class="kp ja">验证</strong>数据集。</p><figure class="mt mu mv mw gt ka"><div class="bz fp l di"><div class="ny nz l"/></div></figure><p id="31a4" class="pw-post-body-paragraph kn ko iq kp b kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj lk ij bi translated">训练、验证和测试数据集分别由48，000、12，000和10，000幅图像组成，具有(28，28，1)的新形状。</p><p id="7285" class="pw-post-body-paragraph kn ko iq kp b kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj lk ij bi translated">如下面的代码片段所示，</p><ol class=""><li id="7282" class="oa ob iq kp b kq kr ku kv ky oc lc od lg oe lk of og oh oi bi translated">我们将在Keras中定义<code class="fe ll lm ln lo b">Sequential()</code>模型，并添加层来构建ConvNets。全连接的最后一层是具有10个输出神经元的输出层(与图像类的数量相同)。激活<strong class="kp ja"> softmax </strong>会给你每个类标签 的<strong class="kp ja"> <em class="mr">概率。</em></strong></li></ol><pre class="mt mu mv mw gt oj lo ok ol aw om bi"><span id="cc8c" class="on lq iq lo b gy oo op l oq or">model.add(Dense(NUM_CLASS, activation='softmax'))</span></pre><p id="be4a" class="pw-post-body-paragraph kn ko iq kp b kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj lk ij bi translated">2.选择要在模型中使用的<strong class="kp ja">损失</strong>、<strong class="kp ja">优化器</strong>和<strong class="kp ja">指标</strong></p><p id="6a61" class="pw-post-body-paragraph kn ko iq kp b kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj lk ij bi translated">3.定义<strong class="kp ja">回调</strong>功能</p><p id="ba03" class="pw-post-body-paragraph kn ko iq kp b kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj lk ij bi translated">4.训练和评估模型性能</p><figure class="mt mu mv mw gt ka"><div class="bz fp l di"><div class="ny nz l"/></div></figure><p id="4bb9" class="pw-post-body-paragraph kn ko iq kp b kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj lk ij bi translated"><strong class="kp ja">什么是回调函数？</strong></p><blockquote class="mx my mz"><p id="e843" class="kn ko mr kp b kq kr ks kt ku kv kw kx na kz la lb nb ld le lf nc lh li lj lk ij bi translated">回调是在训练过程的给定阶段应用的一组函数。在训练期间，您可以使用回调来查看模型的内部状态和统计数据。</p></blockquote><p id="1f3f" class="pw-post-body-paragraph kn ko iq kp b kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj lk ij bi translated">最终，它可以帮助您修复错误，构建更好的模型，并跟踪模型的训练。它可以用来可视化训练的进行情况，通过使用早期停止来帮助防止过度拟合，并自动保存最佳模型的权重。</p><figure class="mt mu mv mw gt ka gh gi paragraph-image"><div class="gh gi os"><img src="../Images/e5ec9f83367ec0f048e64e9e7c22ddf6.png" data-original-src="https://miro.medium.com/v2/resize:fit:1302/format:webp/1*7Y7M2VegrTOAuxBpXZ0cNA.jpeg"/></div><figcaption class="kh ki gj gh gi kj kk bd b be z dk translated">图12:训练期间的第7轮纪元</figcaption></figure><p id="a3c5" class="pw-post-body-paragraph kn ko iq kp b kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj lk ij bi translated">在本演示中，我手动创建<code class="fe ll lm ln lo b">callbacks</code>类来保存<code class="fe ll lm ln lo b">auc</code>每个时期的分数，并使用<code class="fe ll lm ln lo b">ModelCheckPoint</code>和<code class="fe ll lm ln lo b">EarlyStopping</code>来保存模型的最佳权重(基于验证数据集上的<strong class="kp ja">损失</strong>分数)并停止训练模型(如果验证数据集上的损失分数停止提高)。</p><p id="03df" class="pw-post-body-paragraph kn ko iq kp b kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj lk ij bi translated">图12显示了实际的回调，它打印每个时期的AUC分数，并将最佳权重保存到文件中。</p><p id="4f74" class="pw-post-body-paragraph kn ko iq kp b kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj lk ij bi translated">然后，我们根据测试图像计算模型性能。来自先前步骤的历史(或回调)可以被馈送以可视化模型如何在每个时期学习。</p><figure class="mt mu mv mw gt ka gh gi paragraph-image"><div role="button" tabindex="0" class="kb kc di kd bf ke"><div class="gh gi ot"><img src="../Images/ecf287541d739ca119f88f7ac1d7e877.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*HDmJdVpcwURzhDy56QtCZg.jpeg"/></div></div><figcaption class="kh ki gj gh gi kj kk bd b be z dk translated">图13: CNN从零开始的模型性能</figcaption></figure><p id="d75d" class="pw-post-body-paragraph kn ko iq kp b kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj lk ij bi translated">感谢您阅读至此。在本文中，我首先介绍了什么是ConvNet，以及它是如何工作的。还解释了ConvNet架构的各层。我通过使用Keras从头实现ConvNet并编写我们自己的回调函数来结束本文，这进一步帮助了模型开发过程。</p><p id="ad18" class="pw-post-body-paragraph kn ko iq kp b kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj lk ij bi translated">如果您有任何问题，请随时评论或通过LinkedIn <a class="ae km" href="https://www.linkedin.com/in/satsawat/" rel="noopener ugc nofollow" target="_blank">这里</a>联系我。</p></div><div class="ab cl nd ne hu nf" role="separator"><span class="ng bw bk nh ni nj"/><span class="ng bw bk nh ni nj"/><span class="ng bw bk nh ni"/></div><div class="ij ik il im in"><p id="b2b4" class="pw-post-body-paragraph kn ko iq kp b kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj lk ij bi translated"><strong class="kp ja"> GitHub笔记本—使用KMNIST数据集和Keras识别Kuzushiji字符</strong></p><div class="ou ov gp gr ow ox"><a href="https://github.com/netsatsawat/Kuzushiji-Classification/blob/master/code/Kuzushiji-MNIST-Classification.ipynb" rel="noopener  ugc nofollow" target="_blank"><div class="oy ab fo"><div class="oz ab pa cl cj pb"><h2 class="bd ja gy z fp pc fr fs pd fu fw iz bi translated">netsatsawat/Kuzushiji-分类</h2><div class="pe l"><h3 class="bd b gy z fp pc fr fs pd fu fw dk translated">展示深度学习如何帮助识别和分类汉字的知识库…</h3></div><div class="pf l"><p class="bd b dl z fp pc fr fs pd fu fw dk translated">github.com</p></div></div><div class="pg l"><div class="ph l pi pj pk pg pl kf ox"/></div></div></a></div></div><div class="ab cl nd ne hu nf" role="separator"><span class="ng bw bk nh ni nj"/><span class="ng bw bk nh ni nj"/><span class="ng bw bk nh ni"/></div><div class="ij ik il im in"><p id="83c2" class="pw-post-body-paragraph kn ko iq kp b kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj lk ij bi translated">[1]:“kmn ist数据集”(CODH创建)，改编自“Kuzushiji数据集”(NIJL等人创建)，doi:10.20676/00000341</p></div></div>    
</body>
</html>