<html>
<head>
<title>META’s PEER: A Collaborative Language Model</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">META的PEER:一个协作语言模型</h1>
<blockquote>原文：<a href="https://pub.towardsai.net/metas-peer-a-collaborative-language-model-a58a5dd709fe?source=collection_archive---------1-----------------------#2022-11-17">https://pub.towardsai.net/metas-peer-a-collaborative-language-model-a58a5dd709fe?source=collection_archive---------1-----------------------#2022-11-17</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><div class=""><h2 id="1df3" class="pw-subtitle-paragraph jn ip iq bd b jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke dk translated">同伴(计划、编辑、解释、重复):与人工智能合作编写文本</h2></div><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi kf"><img src="../Images/62f184d5b7072d86da07d6f06077e8d8.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*NQChqjQpNg0liuGhhboxkw.png"/></div></div><figcaption class="kr ks gj gh gi kt ku bd b be z dk translated">图片由作者使用<a class="ae kv" href="https://labs.openai.com/" rel="noopener ugc nofollow" target="_blank"> OpenAI DALL-E </a>制作</figcaption></figure><p id="9c92" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">近年来，语言模型显示出令人难以置信的能力(文本摘要、分类和生成)。我们已经习惯了<a class="ae kv" href="https://arxiv.org/abs/2005.14165" rel="noopener ugc nofollow" target="_blank"> GPT-3 </a>和各种允许使用简短文本提示进行写作的应用程序。另一方面，这些模型生成最终的文本，但是不能编辑它(修改、编辑等等)。<strong class="ky ir">在现实世界中，工作流要求多个用户能够编辑文本，以获得最终的高质量版本。</strong></p><p id="1556" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">最近，<a class="ae kv" href="https://ai.facebook.com/research/publications/peer-a-collaborative-language-model/" rel="noopener ugc nofollow" target="_blank">META</a>(与卡耐基梅隆大学和INRIA合作)发布的一种新模型以类似于人类的方式产生文本:撰写草稿，进行编辑，添加建议，甚至能够解释其行为。</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="ls lt l"/></div></figure><p id="49fc" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">正如作者所说，语言模型通常从左到右一次产生输出(它们一个接一个地预测单词)。这不是人类产生文本的方式。通常，这种方法更具协作性，由同一作者或其他作者对文本进行修改或提炼。这一点也很重要，因为并非所有由模型生成的文本都是高质量的文本(当模型生成的内容在话语中没有意义时，我们称之为幻觉)。另外，<a class="ae kv" href="https://en.wikipedia.org/wiki/Language_model" rel="noopener ugc nofollow" target="_blank">语言模型</a>并没有解释为什么会产生输出。</p><p id="5bc4" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">META提出的模型根据图中定义的模式进行操作:模型提出一个计划(例如，提出编辑)，然后用一个动作(编辑)实现这个计划，然后解释这个动作(通过文字说明或者链接到参考文献)，重复这个过程，直到文字令人满意。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi lu"><img src="../Images/3d8b34f3e8b59671a0756ecab19e0ec7.png" data-original-src="https://miro.medium.com/v2/resize:fit:1110/format:webp/1*SRzhCpHusDEGnWH5FRpKow.png"/></div><figcaption class="kr ks gj gh gi kt ku bd b be z dk translated">“图PEER(我们的协作语言模型)执行的步骤的图示:首先，用户或模型指定描述他们想要执行的动作的计划；然后，这个动作通过编辑来实现。该模型可以用自然语言和指向相关来源来解释编辑。我们可以重复这个过程，直到生成的文本不再需要更新为止。”—摘自原文章(<a class="ae kv" href="https://arxiv.org/pdf/2208.11663.pdf" rel="noopener ugc nofollow" target="_blank">来源</a>)</figcaption></figure><blockquote class="lv lw lx"><p id="05f8" class="kw kx ly ky b kz la jr lb lc ld ju le lz lg lh li ma lk ll lm mb lo lp lq lr ij bi translated">这种迭代方法不仅使模型能够将编写一致的事实文本的复杂任务分解为多个更简单的子任务，还允许人类在任何时候进行干预，并通过向模型提供自己的计划和评论或自己进行编辑，将模型导向正确的方向。—原创文章(<a class="ae kv" href="https://arxiv.org/pdf/2208.11663.pdf" rel="noopener ugc nofollow" target="_blank">来源</a>)</p></blockquote><p id="f073" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">作者总结了研究结果:</p><ul class=""><li id="ae31" class="mc md iq ky b kz la lc ld lf me lj mf ln mg lr mh mi mj mk bi translated">协作模式的引入。</li><li id="8364" class="mc md iq ky b kz ml lc mm lf mn lj mo ln mp lr mh mi mj mk bi translated">创建一个模型来填充写作过程的各个部分，并利用自学技巧。这使得它适用于任何领域。</li><li id="9c45" class="mc md iq ky b kz ml lc mm lf mn lj mo ln mp lr mh mi mj mk bi translated">该模型代表了最先进的技术，并超过了几个基线。</li><li id="e9a0" class="mc md iq ky b kz ml lc mm lf mn lj mo ln mp lr mh mi mj mk bi translated">作者发布了几个对等模型、数据和代码来训练它们。</li></ul><p id="4a0d" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">当然，能够训练这样一个模型的第一个挑战是找到正确的数据集。事实上，正如作者所说:</p><blockquote class="lv lw lx"><p id="5d85" class="kw kx ly ky b kz la jr lb lc ld ju le lz lg lh li ma lk ll lm mb lo lp lq lr ij bi translated">这主要是因为编辑历史很难从网络抓取中获得，而网络抓取是当前语言模型最重要的数据源(Brown et al .，2020；Rae等人，2021年)。但是即使在编辑历史可以被获得(例如，通过收集在不同时间对相同页面的抓取)或合成生成的情况下，编辑通常也没有用计划、文档或解释来注释。</p></blockquote><p id="235c" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">为了解决这些问题，作者过滤掉质量差的条目(低质量，由bot和恶意破坏造成)和其他预处理。他们还用合成数据生成来补充数据集。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi mq"><img src="../Images/936fb1c1cb3db3d57b661690b4ee86e9.png" data-original-src="https://miro.medium.com/v2/resize:fit:1012/format:webp/1*SveduZxVU7dmcOT-8aZVfQ.png"/></div><figcaption class="kr ks gj gh gi kt ku bd b be z dk translated">该表总结了所使用的数据集(还显示了训练集和测试集)。来自原文章(<a class="ae kv" href="https://arxiv.org/pdf/2208.11663.pdf" rel="noopener ugc nofollow" target="_blank">来源</a>)</figcaption></figure><p id="ea5c" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">出于这个原因，作者使用了维基百科。事实上，该网站不仅提供了多个主题的高质量文本，还拥有完整的编辑历史(评论、引用)。当然，使用单一来源也有其缺点:该模型特定于一个术语，并且将产生类似于训练集的文本。此外，作者指出，维基百科上的许多评论都是嘈杂的，并且不是所有的文档都包含足够的信息。</p><p id="607e" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">此外，为了解决这个问题，作者决定训练几个模型，每个模型学习编辑过程的一部分:</p><ul class=""><li id="8c7b" class="mc md iq ky b kz la lc ld lf me lj mf ln mg lr mh mi mj mk bi translated"><strong class="ky ir">同行编辑</strong>:模特学会策划，实现编辑。它自己学习如何编辑，但是用户也可以提供编辑</li><li id="3b34" class="mc md iq ky b kz ml lc mm lf mn lj mo ln mp lr mh mi mj mk bi translated"><strong class="ky ir">对等撤销</strong>:它被训练来猜测和撤销最近的编辑</li><li id="6885" class="mc md iq ky b kz ml lc mm lf mn lj mo ln mp lr mh mi mj mk bi translated">对等解释:它被训练来产生解释</li><li id="c218" class="mc md iq ky b kz ml lc mm lf mn lj mo ln mp lr mh mi mj mk bi translated"><strong class="ky ir">对等文档</strong>:它被训练生成一个文档，为编辑提供有用的背景信息</li></ul><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi mr"><img src="../Images/309719396094fefffec6eabb7f995da5.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*GgkY75okaCF5qzY9KT2k6A.png"/></div></div><figcaption class="kr ks gj gh gi kt ku bd b be z dk translated">来自原文章(<a class="ae kv" href="https://arxiv.org/pdf/2208.11663.pdf" rel="noopener ugc nofollow" target="_blank">来源</a>)</figcaption></figure><p id="4771" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">为了将PEER训练成一个通用模型，使其适用于不同的领域和不同的协作任务，作者做了几个实验:</p><ul class=""><li id="08ae" class="mc md iq ky b kz la lc ld lf me lj mf ln mg lr mh mi mj mk bi translated">同行能否在没有可用示例的领域中提出计划和编辑？自我训练就够了吗？</li><li id="dd3c" class="mc md iq ky b kz ml lc mm lf mn lj mo ln mp lr mh mi mj mk bi translated">PEER能跟得上人类修改命题吗？</li><li id="4044" class="mc md iq ky b kz ml lc mm lf mn lj mo ln mp lr mh mi mj mk bi translated">同行能建议正确的引文吗？文件有用吗？</li><li id="82a4" class="mc md iq ky b kz ml lc mm lf mn lj mo ln mp lr mh mi mj mk bi translated">同行是否优于单通模式？</li></ul><p id="832b" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">对于第一个问题，作者收集了维基百科的其他百科页面，维基新闻的帖子，以及<a class="ae kv" href="https://stackexchange.com/" rel="noopener ugc nofollow" target="_blank"> StackExchange </a>的烹饪、园艺、法律、电影、政治、旅游和工作场所子论坛的帖子。结果显示，PEER能够将从维基百科故事中学到的东西应用到其他领域。此外，没有计划和文件的模型性能下降。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi ms"><img src="../Images/929e4de944eb32449dbb5feb16ed245a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*qKpgfWiCAum3MKZEIQoiwA.png"/></div></div><figcaption class="kr ks gj gh gi kt ku bd b be z dk translated">来自原文章(<a class="ae kv" href="https://arxiv.org/pdf/2208.11663.pdf" rel="noopener ugc nofollow" target="_blank">来源</a>)</figcaption></figure><p id="8c3a" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">作者还检查了PEER是否能够使用不同的特定数据集完成其他下游任务(语法错误纠正、文本简化、编辑、减轻或删除文本中有偏见的单词、查找维基百科页面的更新、在维基百科中插入句子)。PEER还与<a class="ae kv" href="https://arxiv.org/abs/2204.07705" rel="noopener ugc nofollow" target="_blank"> Tk-instruct </a>、<a class="ae kv" href="https://arxiv.org/abs/2110.08207" rel="noopener ugc nofollow" target="_blank"> T0 </a>和<a class="ae kv" href="https://arxiv.org/abs/2110.08207" rel="noopener ugc nofollow" target="_blank">T0++</a>(T5的变体)、GPT3和<a class="ae kv" href="https://arxiv.org/abs/2205.01068" rel="noopener ugc nofollow" target="_blank">OPT</a>(gp T3的开源副本)进行了比较。尽管GPT3和OPT都更大，但PEER的表现优于这些模型。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi mt"><img src="../Images/80f49f49a23ff6cb67cd11491c318982.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*MSs-RPE0I63pZSyLnCRmKg.png"/></div></div><figcaption class="kr ks gj gh gi kt ku bd b be z dk translated">来自原文章(<a class="ae kv" href="https://arxiv.org/pdf/2208.11663.pdf" rel="noopener ugc nofollow" target="_blank">来源</a>)</figcaption></figure><p id="4f1a" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">此外，PEER能够提供参考文献中的引文和引用，从而提供更好的可解释性和可验证性。作者还引入了两个新的数据集(NE-Cite和NE-Quote ),以查看该模型是否能够引用特定段落而不是整个文档。该模型成功地为文本建议了适当的引用。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi mu"><img src="../Images/7d1f095bf7bcc767c5d62a1b4695a035.png" data-original-src="https://miro.medium.com/v2/resize:fit:964/format:webp/1*R3cAWBLLtzWzBoPVLkhAPA.png"/></div><figcaption class="kr ks gj gh gi kt ku bd b be z dk translated">来自原文章(<a class="ae kv" href="https://arxiv.org/pdf/2208.11663.pdf" rel="noopener ugc nofollow" target="_blank">来源</a>)</figcaption></figure><p id="2770" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">此外，作者通过选择三种可能的场景来测试模型从头生成文本(文本生成)的能力:单独的模型，带有人类计划建议，以及协作模型。结果表明，协作系统是最好的。</p><p id="6151" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">作者还展示了一个与PEER进行协作会话的示例:</p><blockquote class="lv lw lx"><p id="b85d" class="kw kx ly ky b kz la jr lb lc ld ju le lz lg lh li ma lk ll lm mb lo lp lq lr ij bi translated">如图4(左)所示，PEER能够从各种文档中提取和组合信息，以遵循所提供的计划。它做出了一些似是而非的假设，如Meta AI正在开发的模型，尽管这在任何文档中都没有明确说明，并且能够指出作者列表(文档0)作为该声明的参考。该模型对第五个计划的反应(“添加关于丑闻的信息”)说明了许多预训练语言模型的一个基本问题:它接受这个计划的前提，并通过幻想一个关于互联网审查的丑闻来遵循它。然而，与传统的从左到右的模型不同，PEER能够在下一步纠正它产生的错误信息</p></blockquote><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi mv"><img src="../Images/5e903d214f7de3bf79161d2f3e003599.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*jtuuxksG6mli83O8vlFFSQ.png"/></div></div><figcaption class="kr ks gj gh gi kt ku bd b be z dk translated">来自原文章(<a class="ae kv" href="https://arxiv.org/pdf/2208.11663.pdf" rel="noopener ugc nofollow" target="_blank">来源</a>)</figcaption></figure><p id="166a" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">作者讨论了几个局限性:</p><ul class=""><li id="fdf5" class="mc md iq ky b kz la lc ld lf me lj mf ln mg lr mh mi mj mk bi translated"><strong class="ky ir">接近</strong>。一个限制是假设在现实世界中并不总是可能的(每次编辑都有论文)。此外，引用可能会产生误导，因为当模型产生幻觉时，引用会给用户留下模型更权威、更令人困惑的印象。此外，输入和输出的表示使得处理整个文档的效率很低。</li><li id="dcd6" class="mc md iq ky b kz ml lc mm lf mn lj mo ln mp lr mh mi mj mk bi translated"><strong class="ky ir">评价</strong>。第一个限制是所有的评估都是用英语进行的。作者还表示，他们以非常有限的方式探索了合作的潜力(然而，这将需要一个能够在互联网上找到文档的动态检索引擎)。</li></ul><p id="6a07" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">总之，该模型提出了一种非常有趣的方法，其中利用语言模型作为助手可以建议在不同领域进行修改(“从句法和文体编辑到通过删除、更新或添加信息来改变文本的含义”)。尽管该模型有几个限制，但它是人工智能写作助手与人类合作的第一步。虽然作者已经宣布它将在此刻可用，但是还没有开源的存储库。你对此有什么想法？好奇想试试吗？请在评论中告诉我。</p><h1 id="442a" class="mw mx iq bd my mz na nb nc nd ne nf ng jw nh jx ni jz nj ka nk kc nl kd nm nn bi translated">如果你觉得有趣:</h1><p id="c512" class="pw-post-body-paragraph kw kx iq ky b kz no jr lb lc np ju le lf nq lh li lj nr ll lm ln ns lp lq lr ij bi translated">你可以寻找我的其他文章，你也可以<a class="ae kv" href="https://salvatore-raieli.medium.com/subscribe" rel="noopener"> <strong class="ky ir">订阅</strong> </a>在我发表文章时得到通知，你也可以在<strong class="ky ir"/><a class="ae kv" href="https://www.linkedin.com/in/salvatore-raieli/" rel="noopener ugc nofollow" target="_blank"><strong class="ky ir">LinkedIn</strong></a><strong class="ky ir">上连接或联系我。</strong>感谢您的支持！</p><p id="f9be" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">这是我的GitHub知识库的链接，我计划在这里收集代码和许多与机器学习、人工智能等相关的资源。</p><div class="nt nu gp gr nv nw"><a href="https://github.com/SalvatoreRa/tutorial" rel="noopener  ugc nofollow" target="_blank"><div class="nx ab fo"><div class="ny ab nz cl cj oa"><h2 class="bd ir gy z fp ob fr fs oc fu fw ip bi translated">GitHub - SalvatoreRa/tutorial:关于机器学习、人工智能、数据科学的教程…</h2><div class="od l"><h3 class="bd b gy z fp ob fr fs oc fu fw dk translated">关于机器学习、人工智能、数据科学的教程，包括数学解释和可重复使用的代码(python…</h3></div><div class="oe l"><p class="bd b dl z fp ob fr fs oc fu fw dk translated">github.com</p></div></div><div class="of l"><div class="og l oh oi oj of ok kp nw"/></div></div></a></div><p id="3ca0" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">或者随意查看我在Medium上的其他文章:</p><div class="nt nu gp gr nv nw"><a href="https://towardsdatascience.com/how-artificial-intelligence-could-save-the-amazon-rainforest-688fa505c455" rel="noopener follow" target="_blank"><div class="nx ab fo"><div class="ny ab nz cl cj oa"><h2 class="bd ir gy z fp ob fr fs oc fu fw ip bi translated">人工智能如何拯救亚马逊雨林</h2><div class="od l"><h3 class="bd b gy z fp ob fr fs oc fu fw dk translated">亚马逊正处于危险之中，人工智能可以帮助保护它</h3></div><div class="oe l"><p class="bd b dl z fp ob fr fs oc fu fw dk translated">towardsdatascience.com</p></div></div><div class="of l"><div class="ol l oh oi oj of ok kp nw"/></div></div></a></div><div class="nt nu gp gr nv nw"><a href="https://medium.com/mlearning-ai/metas-esmfold-the-rival-of-alpahfold2-2223b67f6021" rel="noopener follow" target="_blank"><div class="nx ab fo"><div class="ny ab nz cl cj oa"><h2 class="bd ir gy z fp ob fr fs oc fu fw ip bi translated">Meta的ESM fold:alpahfold 2的对手</h2><div class="od l"><h3 class="bd b gy z fp ob fr fs oc fu fw dk translated">Meta使用一种新方法来预测超过6亿个蛋白质结构</h3></div><div class="oe l"><p class="bd b dl z fp ob fr fs oc fu fw dk translated">medium.com</p></div></div><div class="of l"><div class="om l oh oi oj of ok kp nw"/></div></div></a></div><div class="nt nu gp gr nv nw"><a href="https://medium.com/mlearning-ai/dreamfusion-3d-models-from-text-561e8268a24c" rel="noopener follow" target="_blank"><div class="nx ab fo"><div class="ny ab nz cl cj oa"><h2 class="bd ir gy z fp ob fr fs oc fu fw ip bi translated">DreamFusion:来自文本的3D模型</h2><div class="od l"><h3 class="bd b gy z fp ob fr fs oc fu fw dk translated">一个新的谷歌扩散模型，允许从文本中获得3D图像。</h3></div><div class="oe l"><p class="bd b dl z fp ob fr fs oc fu fw dk translated">medium.com</p></div></div><div class="of l"><div class="on l oh oi oj of ok kp nw"/></div></div></a></div><p id="8283" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated"><a class="ae kv" href="https://medium.com/mlearning-ai/generate-a-piano-cover-with-ai-f4178bc9cb30" rel="noopener">https://medium . com/mlearning-ai/generate-a-piano-cover-with-ai-f 4178 BC 9 CB 30</a></p></div></div>    
</body>
</html>