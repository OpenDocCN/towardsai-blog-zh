<html>
<head>
<title>Deep Learning A-Z Briefly Explained</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">深度学习A-Z简要说明</h1>
<blockquote>原文：<a href="https://pub.towardsai.net/deep-learning-a-z-briefly-explained-9026028f1281?source=collection_archive---------1-----------------------#2022-08-25">https://pub.towardsai.net/deep-learning-a-z-briefly-explained-9026028f1281?source=collection_archive---------1-----------------------#2022-08-25</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="dffb" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">提神和快速回忆</h2></div><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi ki"><img src="../Images/9a1a583ecfb2b83f619c021271e61c16.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*5zjjAOgdYld91ei0JhYPhA.png"/></div><figcaption class="kq kr gj gh gi ks kt bd b be z dk translated">作者图片</figcaption></figure><h1 id="3c48" class="ku kv it bd kw kx ky kz la lb lc ld le jz lf ka lg kc lh kd li kf lj kg lk ll bi translated">介绍</h1><p id="0955" class="pw-post-body-paragraph lm ln it lo b lp lq ju lr ls lt jx lu lv lw lx ly lz ma mb mc md me mf mg mh im bi translated">深度学习主要由机器学习的子集来解释。</p><p id="1329" class="pw-post-body-paragraph lm ln it lo b lp mi ju lr ls mj jx lu lv mk lx ly lz ml mb mc md mm mf mg mh im bi translated">你已经知道机器学习的一切了，何必呢？</p><p id="6b55" class="pw-post-body-paragraph lm ln it lo b lp mi ju lr ls mj jx lu lv mk lx ly lz ml mb mc md mm mf mg mh im bi translated">下面是Andrew NG用下图解释的原因，是机器学习和深度学习的<strong class="lo iu"> <em class="mn"> Yoda </em> </strong>。(说尤达——我指的是大师)。</p><p id="004c" class="pw-post-body-paragraph lm ln it lo b lp mi ju lr ls mj jx lu lv mk lx ly lz ml mb mc md mm mf mg mh im bi translated">如果你正处于学习之旅的开始，这里有Andrew关于<a class="ae mo" href="https://www.coursera.org/specializations/machine-learning-introduction" rel="noopener ugc nofollow" target="_blank">机器学习</a>和<a class="ae mo" href="https://www.coursera.org/specializations/deep-learning" rel="noopener ugc nofollow" target="_blank">深度学习的课程。</a></p><p id="bd84" class="pw-post-body-paragraph lm ln it lo b lp mi ju lr ls mj jx lu lv mk lx ly lz ml mb mc md mm mf mg mh im bi translated">我可以很容易地说，由于我的经验，这些课程真的是顶轻推。</p><p id="f90b" class="pw-post-body-paragraph lm ln it lo b lp mi ju lr ls mj jx lu lv mk lx ly lz ml mb mc md mm mf mg mh im bi translated">现在我们来看看，为什么要深度学习？</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="mq mr di ms bf mt"><div class="gh gi mp"><img src="../Images/8fbd2feb4d0f8149fe862e70eed679e3.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*aCTStSEhLD2Vz2K9611jXQ.png"/></div></div><figcaption class="kq kr gj gh gi ks kt bd b be z dk translated">幻灯片作者<a class="ae mo" href="http://www.slideshare.net/ExtractConf" rel="noopener ugc nofollow" target="_blank">吴恩达</a>，版权所有。</figcaption></figure><p id="7b04" class="pw-post-body-paragraph lm ln it lo b lp mi ju lr ls mj jx lu lv mk lx ly lz ml mb mc md mm mf mg mh im bi translated">当然，也可能有其他原因，但我认为这是最有力的原因。</p><p id="a027" class="pw-post-body-paragraph lm ln it lo b lp mi ju lr ls mj jx lu lv mk lx ly lz ml mb mc md mm mf mg mh im bi translated">现在我来简单解释一下<strong class="lo iu"> <em class="mn">深度学习术语。</em>T13】</strong></p><p id="42c9" class="pw-post-body-paragraph lm ln it lo b lp mi ju lr ls mj jx lu lv mk lx ly lz ml mb mc md mm mf mg mh im bi translated">阅读本文大约6分钟后，您将熟悉深度学习术语。</p><p id="4ba1" class="pw-post-body-paragraph lm ln it lo b lp mi ju lr ls mj jx lu lv mk lx ly lz ml mb mc md mm mf mg mh im bi translated">由于<strong class="lo iu"> <em class="mn">那一次</em> </strong>，要么你可以为深度学习规划你的学习时间表，在学习深度学习的时候感觉很舒服，因为你已经有了事先的介绍。</p><p id="cd2f" class="pw-post-body-paragraph lm ln it lo b lp mi ju lr ls mj jx lu lv mk lx ly lz ml mb mc md mm mf mg mh im bi translated">如果你已经知道深度学习，但你觉得你必须重复才能感觉更好，那篇文章也会为你服务。</p><blockquote class="mu"><p id="8305" class="mv mw it bd mx my mz na nb nc nd mh dk translated">"重复是技能之母。"</p><p id="ffe1" class="mv mw it bd mx my mz na nb nc nd mh dk translated">托尼·罗宾斯</p></blockquote><p id="a989" class="pw-post-body-paragraph lm ln it lo b lp ne ju lr ls nf jx lu lv ng lx ly lz nh mb mc md ni mf mg mh im bi translated">任何人都知道，如果你想擅长某件事，你应该坚持不懈。</p><blockquote class="mu"><p id="2c89" class="mv mw it bd mx my mz na nb nc nd mh dk translated">只有那些坚持不懈并愿意深入研究事物的人，才能完成大师级的作品。</p><p id="22f3" class="mv mw it bd mx my mz na nb nc nd mh dk translated">保罗·柯艾略</p></blockquote><p id="fa6d" class="pw-post-body-paragraph lm ln it lo b lp ne ju lr ls nf jx lu lv ng lx ly lz nh mb mc md ni mf mg mh im bi translated">如果你觉得有动力，让我们开始吧。</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="nj nk l"/></div><figcaption class="kq kr gj gh gi ks kt bd b be z dk translated"><a class="ae mo" href="https://giphy.com/gifs/reaction-SiKqNZqksVYWmQEMjd" rel="noopener ugc nofollow" target="_blank">参考</a></figcaption></figure><pre class="kj kk kl km gt nl nm nn no aw np bi"><span id="a99f" class="nq kv it nm b gy nr ns l nt nu"><strong class="nm iu">Table Of Content</strong></span><span id="ee8b" class="nq kv it nm b gy nv ns l nt nu">· <a class="ae mo" href="#3c48" rel="noopener ugc nofollow"><strong class="nm iu">Introduction</strong></a><br/>· <a class="ae mo" href="#8a83" rel="noopener ugc nofollow">Neural Network</a><br/>· <a class="ae mo" href="#89b0" rel="noopener ugc nofollow">Layer</a><br/>  ∘ <a class="ae mo" href="#39db" rel="noopener ugc nofollow">Output Layer</a><br/>  ∘ <a class="ae mo" href="#96d3" rel="noopener ugc nofollow">Input Layer</a><br/>  ∘ <a class="ae mo" href="#c465" rel="noopener ugc nofollow">Hidden Layer</a><br/>· <a class="ae mo" href="#0304" rel="noopener ugc nofollow">Activation Functions</a><br/>  ∘ <a class="ae mo" href="#0a60" rel="noopener ugc nofollow">Sigmoid Activation Function</a><br/>  ∘ <a class="ae mo" href="#5b6c" rel="noopener ugc nofollow">Graph</a><br/>  ∘ <a class="ae mo" href="#3635" rel="noopener ugc nofollow">Function</a><br/>  ∘ <a class="ae mo" href="#d4a5" rel="noopener ugc nofollow">ReLU Activation Function</a><br/>  ∘ <a class="ae mo" href="#ec3c" rel="noopener ugc nofollow">Leaky ReLU Activation Function</a><br/>  ∘ <a class="ae mo" href="#6b08" rel="noopener ugc nofollow">Tanh Activation Function</a><br/>· <a class="ae mo" href="#64c6" rel="noopener ugc nofollow">Vectorization</a><br/>· <a class="ae mo" href="#0dad" rel="noopener ugc nofollow">Forward Propagation</a><br/>· <a class="ae mo" href="#821a" rel="noopener ugc nofollow">Back Propagation</a><br/>· <a class="ae mo" href="#ad49" rel="noopener ugc nofollow">Train Set</a><br/>· <a class="ae mo" href="#5838" rel="noopener ugc nofollow">Dev Set</a><br/>· <a class="ae mo" href="#d6f7" rel="noopener ugc nofollow">Test Set</a><br/>· <a class="ae mo" href="#1848" rel="noopener ugc nofollow">Initialization</a><br/>  ∘ <a class="ae mo" href="#220e" rel="noopener ugc nofollow">Random Initialization</a><br/>  ∘ <a class="ae mo" href="#e1d6" rel="noopener ugc nofollow">He Initialization — Xavier Initialization</a><br/>· <a class="ae mo" href="#f23a" rel="noopener ugc nofollow">Bias and Variance</a><br/>· <a class="ae mo" href="#7191" rel="noopener ugc nofollow">Regularization</a><br/>· <a class="ae mo" href="#0cd0" rel="noopener ugc nofollow">Normalization</a><br/>· <a class="ae mo" href="#58c2" rel="noopener ugc nofollow">Gradient Descent</a><br/>  ∘ <a class="ae mo" href="#6ba2" rel="noopener ugc nofollow">Mini batch Gradient Descent</a><br/>  ∘ <a class="ae mo" href="#4289" rel="noopener ugc nofollow">Stochastic Gradient Descent</a><br/>  ∘ <a class="ae mo" href="#acbb" rel="noopener ugc nofollow">Batch Gradient Descent</a><br/>· <a class="ae mo" href="#d883" rel="noopener ugc nofollow">Learning rate Decay</a><br/>  ∘ <a class="ae mo" href="#a213" rel="noopener ugc nofollow">Human-Level Performance</a><br/>· <a class="ae mo" href="#f8bb" rel="noopener ugc nofollow">Transfer Learning</a><br/>· <a class="ae mo" href="#0b56" rel="noopener ugc nofollow">Multi-task Learning</a><br/>· <a class="ae mo" href="#bca0" rel="noopener ugc nofollow">Tensorflow</a><br/>· <a class="ae mo" href="#5a99" rel="noopener ugc nofollow"><strong class="nm iu">Conclusion</strong></a><br/></span></pre></div><div class="ab cl nw nx hx ny" role="separator"><span class="nz bw bk oa ob oc"/><span class="nz bw bk oa ob oc"/><span class="nz bw bk oa ob"/></div><div class="im in io ip iq"><h1 id="8a83" class="ku kv it bd kw kx od kz la lb oe ld le jz of ka lg kc og kd li kf oh kg lk ll bi translated">神经网络</h1><p id="3fae" class="pw-post-body-paragraph lm ln it lo b lp lq ju lr ls lt jx lu lv lw lx ly lz ma mb mc md me mf mg mh im bi translated">在每个神经元中，构建神经元与下一层神经元紧密相连，在每个神经元中，计算不同的函数，然后使用其他网络计算来找到下一层的参数，然后再次这样做，直到到达最后一层，您将使用激活函数来进行预测。</p><h1 id="89b0" class="ku kv it bd kw kx ky kz la lb lc ld le jz lf ka lg kc lh kd li kf lj kg lk ll bi translated">层</h1><p id="2ffb" class="pw-post-body-paragraph lm ln it lo b lp lq ju lr ls lt jx lu lv lw lx ly lz ma mb mc md me mf mg mh im bi translated">它包含许多神经元。</p><h2 id="39db" class="nq kv it bd kw oi oj dn la ok ol dp le lv om on lg lz oo op li md oq or lk os bi translated">输出层</h2><p id="0d4d" class="pw-post-body-paragraph lm ln it lo b lp lq ju lr ls lt jx lu lv lw lx ly lz ma mb mc md me mf mg mh im bi translated">在最后一层，从这里开始，您将使用激活函数来计算结果。</p><h2 id="96d3" class="nq kv it bd kw oi oj dn la ok ol dp le lv om on lg lz oo op li md oq or lk os bi translated">输入层</h2><p id="004f" class="pw-post-body-paragraph lm ln it lo b lp lq ju lr ls lt jx lu lv lw lx ly lz ma mb mc md me mf mg mh im bi translated">你的特征。</p><h2 id="c465" class="nq kv it bd kw oi oj dn la ok ol dp le lv om on lg lz oo op li md oq or lk os bi translated">隐蔽层</h2><p id="abb8" class="pw-post-body-paragraph lm ln it lo b lp lq ju lr ls lt jx lu lv lw lx ly lz ma mb mc md me mf mg mh im bi translated">在输入层和输出层之间。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="mq mr di ms bf mt"><div class="gh gi ot"><img src="../Images/b3e71acf56f2068aec27206a9e7da9a9.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*IwdET9YObVGHWFHdDK7w6A.png"/></div></div><figcaption class="kq kr gj gh gi ks kt bd b be z dk translated">在坎瓦普罗设计</figcaption></figure><h1 id="0304" class="ku kv it bd kw kx ky kz la lb lc ld le jz lf ka lg kc lh kd li kf lj kg lk ll bi translated">激活功能</h1><p id="244f" class="pw-post-body-paragraph lm ln it lo b lp lq ju lr ls lt jx lu lv lw lx ly lz ma mb mc md me mf mg mh im bi translated">该函数在输出图层中用于计算y。</p><h2 id="0a60" class="nq kv it bd kw oi oj dn la ok ol dp le lv om on lg lz oo op li md oq or lk os bi translated">Sigmoid激活函数</h2><h2 id="5b6c" class="nq kv it bd kw oi oj dn la ok ol dp le lv om on lg lz oo op li md oq or lk os bi translated">图表</h2><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi ou"><img src="../Images/8f3352e1558072427991f64f1a41ee4b.png" data-original-src="https://miro.medium.com/v2/resize:fit:744/format:webp/1*idB70TKN5o3JFNAW4_ZVEA.png"/></div><figcaption class="kq kr gj gh gi ks kt bd b be z dk translated">作者图片</figcaption></figure><h2 id="3635" class="nq kv it bd kw oi oj dn la ok ol dp le lv om on lg lz oo op li md oq or lk os bi translated">功能</h2><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi ov"><img src="../Images/ce2f222b468c74650337dc5e5952b363.png" data-original-src="https://miro.medium.com/v2/resize:fit:508/format:webp/1*azsDlbUsVHlAk6vjDd0SQg.png"/></div><figcaption class="kq kr gj gh gi ks kt bd b be z dk translated">作者图片</figcaption></figure><h2 id="d4a5" class="nq kv it bd kw oi oj dn la ok ol dp le lv om on lg lz oo op li md oq or lk os bi translated">ReLU激活功能</h2><p id="6146" class="pw-post-body-paragraph lm ln it lo b lp lq ju lr ls lt jx lu lv lw lx ly lz ma mb mc md me mf mg mh im bi translated">Z &gt; 0，函数的导数将= 1</p><p id="0e9f" class="pw-post-body-paragraph lm ln it lo b lp mi ju lr ls mj jx lu lv mk lx ly lz ml mb mc md mm mf mg mh im bi translated">Z &lt; 0，导数= 0。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi ow"><img src="../Images/918461e088ac1739dcfffc0592577ac6.png" data-original-src="https://miro.medium.com/v2/resize:fit:736/format:webp/1*JeDJQRhZDc58AFSUrUkSug.png"/></div><figcaption class="kq kr gj gh gi ks kt bd b be z dk translated">作者图片</figcaption></figure><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi ox"><img src="../Images/ee871d81ab1ab021a33c65d89220da05.png" data-original-src="https://miro.medium.com/v2/resize:fit:444/format:webp/1*AuD2__98dmHIb8cBSCpKDA.png"/></div><figcaption class="kq kr gj gh gi ks kt bd b be z dk translated">作者图片</figcaption></figure><h2 id="ec3c" class="nq kv it bd kw oi oj dn la ok ol dp le lv om on lg lz oo op li md oq or lk os bi translated">泄漏ReLU激活功能</h2><p id="44bc" class="pw-post-body-paragraph lm ln it lo b lp lq ju lr ls lt jx lu lv lw lx ly lz ma mb mc md me mf mg mh im bi translated">当x &lt; 0, y will be a really little number to</p><p id="80f8" class="pw-post-body-paragraph lm ln it lo b lp mi ju lr ls mj jx lu lv mk lx ly lz ml mb mc md mm mf mg mh im bi translated"><em class="mn">(实际中用得不多)</em></p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi oy"><img src="../Images/33b17369095c1f56ddd51d96921800f3.png" data-original-src="https://miro.medium.com/v2/resize:fit:620/format:webp/1*yyfVbw2cXMZc9Zfdgyqlgg.png"/></div><figcaption class="kq kr gj gh gi ks kt bd b be z dk translated">作者图片</figcaption></figure><h2 id="6b08" class="nq kv it bd kw oi oj dn la ok ol dp le lv om on lg lz oo op li md oq or lk os bi translated">Tanh激活函数</h2><p id="ed44" class="pw-post-body-paragraph lm ln it lo b lp lq ju lr ls lt jx lu lv lw lx ly lz ma mb mc md me mf mg mh im bi translated">这个函数图就像一个sigmoid函数图。然而，不同的是Y将是-(1，1)，这意味着你的数据的平均值是零。</p><p id="dd59" class="pw-post-body-paragraph lm ln it lo b lp mi ju lr ls mj jx lu lv mk lx ly lz ml mb mc md mm mf mg mh im bi translated">该函数比隐藏层中的sigmoid激活函数使用得更多。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi oz"><img src="../Images/f04440b88f221add4e9551fb15e474b1.png" data-original-src="https://miro.medium.com/v2/resize:fit:758/format:webp/1*8HmqjklYzNtiJNdcz3nGVA.png"/></div><figcaption class="kq kr gj gh gi ks kt bd b be z dk translated">作者图片</figcaption></figure><h1 id="64c6" class="ku kv it bd kw kx ky kz la lb lc ld le jz lf ka lg kc lh kd li kf lj kg lk ll bi translated">…向量化…</h1><p id="18e2" class="pw-post-body-paragraph lm ln it lo b lp lq ju lr ls lt jx lu lv lw lx ly lz ma mb mc md me mf mg mh im bi translated">不要使用循环，而是使用NumPy特性来提高算法速度。</p><h1 id="0dad" class="ku kv it bd kw kx ky kz la lb lc ld le jz lf ka lg kc lh kd li kf lj kg lk ll bi translated">正向传播</h1><p id="7723" class="pw-post-body-paragraph lm ln it lo b lp lq ju lr ls lt jx lu lv lw lx ly lz ma mb mc md me mf mg mh im bi translated">包含从输入层到输出层的计算，用于将来反向传播的计算。</p><h1 id="821a" class="ku kv it bd kw kx ky kz la lb lc ld le jz lf ka lg kc lh kd li kf lj kg lk ll bi translated">反向传播</h1><p id="6869" class="pw-post-body-paragraph lm ln it lo b lp lq ju lr ls lt jx lu lv lw lx ly lz ma mb mc md me mf mg mh im bi translated">保存转发传播的结果。</p><p id="8b3c" class="pw-post-body-paragraph lm ln it lo b lp mi ju lr ls mj jx lu lv mk lx ly lz ml mb mc md mm mf mg mh im bi translated">并用它们来计算梯度。</p><p id="068c" class="pw-post-body-paragraph lm ln it lo b lp mi ju lr ls mj jx lu lv mk lx ly lz ml mb mc md mm mf mg mh im bi translated">设置您的超参数，并根据您参数的导数相应地更新您的参数。</p><h1 id="ad49" class="ku kv it bd kw kx ky kz la lb lc ld le jz lf ka lg kc lh kd li kf lj kg lk ll bi translated">列车组</h1><p id="dabb" class="pw-post-body-paragraph lm ln it lo b lp lq ju lr ls lt jx lu lv lw lx ly lz ma mb mc md me mf mg mh im bi translated">它用于拟合您的参数。</p><h1 id="5838" class="ku kv it bd kw kx ky kz la lb lc ld le jz lf ka lg kc lh kd li kf lj kg lk ll bi translated">开发集</h1><p id="8cc0" class="pw-post-body-paragraph lm ln it lo b lp lq ju lr ls lt jx lu lv lw lx ly lz ma mb mc md me mf mg mh im bi translated">另一个名称是保留交叉验证集。</p><p id="bc40" class="pw-post-body-paragraph lm ln it lo b lp mi ju lr ls mj jx lu lv mk lx ly lz ml mb mc md mm mf mg mh im bi translated">这个数据集用来调整你的超参数。</p><h1 id="d6f7" class="ku kv it bd kw kx ky kz la lb lc ld le jz lf ka lg kc lh kd li kf lj kg lk ll bi translated">测试装置</h1><p id="6b52" class="pw-post-body-paragraph lm ln it lo b lp lq ju lr ls lt jx lu lv lw lx ly lz ma mb mc md me mf mg mh im bi translated">用于评估模型的性能。</p><h1 id="1848" class="ku kv it bd kw kx ky kz la lb lc ld le jz lf ka lg kc lh kd li kf lj kg lk ll bi translated">初始化</h1><p id="f602" class="pw-post-body-paragraph lm ln it lo b lp lq ju lr ls lt jx lu lv lw lx ly lz ma mb mc md me mf mg mh im bi translated">设置我们参数的第一个值是很重要的，因为我们的参数将根据梯度的结果而改变，并且这些初始值将定义我们梯度下降算法的速度。</p><h2 id="220e" class="nq kv it bd kw oi oj dn la ok ol dp le lv om on lg lz oo op li md oq or lk os bi translated">随机初始化</h2><p id="6cf1" class="pw-post-body-paragraph lm ln it lo b lp lq ju lr ls lt jx lu lv lw lx ly lz ma mb mc md me mf mg mh im bi translated">参数是随机分配的。</p><h2 id="e1d6" class="nq kv it bd kw oi oj dn la ok ol dp le lv om on lg lz oo op li md oq or lk os bi translated">He初始化— Xavier初始化</h2><p id="8bf3" class="pw-post-body-paragraph lm ln it lo b lp lq ju lr ls lt jx lu lv lw lx ly lz ma mb mc md me mf mg mh im bi translated">随机分配的参数乘以；</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi pa"><img src="../Images/e81e20f5e02e39fca4103a615c9aa684.png" data-original-src="https://miro.medium.com/v2/resize:fit:740/format:webp/1*UjFedLtw_QaYgQeCB7FItA.png"/></div></figure><h1 id="f23a" class="ku kv it bd kw kx ky kz la lb lc ld le jz lf ka lg kc lh kd li kf lj kg lk ll bi translated">偏差和方差</h1><p id="5bb9" class="pw-post-body-paragraph lm ln it lo b lp lq ju lr ls lt jx lu lv lw lx ly lz ma mb mc md me mf mg mh im bi translated">高偏差-</p><ul class=""><li id="0287" class="pb pc it lo b lp mi ls mj lv pd lz pe md pf mh pg ph pi pj bi translated">装配不足</li><li id="03f9" class="pb pc it lo b lp pk ls pl lv pm lz pn md po mh pg ph pi pj bi translated">你的算法不是成功的训练集和开发集。</li></ul><p id="fe5d" class="pw-post-body-paragraph lm ln it lo b lp mi ju lr ls mj jx lu lv mk lx ly lz ml mb mc md mm mf mg mh im bi translated">高方差</p><ul class=""><li id="0d91" class="pb pc it lo b lp mi ls mj lv pd lz pe md pf mh pg ph pi pj bi translated">过度拟合</li><li id="5d43" class="pb pc it lo b lp pk ls pl lv pm lz pn md po mh pg ph pi pj bi translated">你的算法在训练集中是成功的，但在开发集中是失败的。</li></ul><h1 id="7191" class="ku kv it bd kw kx ky kz la lb lc ld le jz lf ka lg kc lh kd li kf lj kg lk ll bi translated">正规化</h1><p id="2d7b" class="pw-post-body-paragraph lm ln it lo b lp lq ju lr ls lt jx lu lv lw lx ly lz ma mb mc md me mf mg mh im bi translated">通过添加额外值来避免过度拟合的技术。</p><h1 id="0cd0" class="ku kv it bd kw kx ky kz la lb lc ld le jz lf ka lg kc lh kd li kf lj kg lk ll bi translated">正常化</h1><p id="b178" class="pw-post-body-paragraph lm ln it lo b lp lq ju lr ls lt jx lu lv lw lx ly lz ma mb mc md me mf mg mh im bi translated">更改要素的比例以提高之后的梯度下降速度。</p><h1 id="58c2" class="ku kv it bd kw kx ky kz la lb lc ld le jz lf ka lg kc lh kd li kf lj kg lk ll bi translated">梯度下降</h1><p id="4442" class="pw-post-body-paragraph lm ln it lo b lp lq ju lr ls lt jx lu lv lw lx ly lz ma mb mc md me mf mg mh im bi translated">该算法用于通过计算导数和更新参数来降低成本函数。</p><p id="4f61" class="pw-post-body-paragraph lm ln it lo b lp mi ju lr ls mj jx lu lv mk lx ly lz ml mb mc md mm mf mg mh im bi translated">该算法有3个不同的选项，根据数据的长度和算法速度而有所不同。</p><h2 id="6ba2" class="nq kv it bd kw oi oj dn la ok ol dp le lv om on lg lz oo op li md oq or lk os bi translated">小批量梯度下降</h2><p id="0410" class="pw-post-body-paragraph lm ln it lo b lp lq ju lr ls lt jx lu lv lw lx ly lz ma mb mc md me mf mg mh im bi translated">选择“m”长度的小批量并应用梯度下降。</p><h2 id="4289" class="nq kv it bd kw oi oj dn la ok ol dp le lv om on lg lz oo op li md oq or lk os bi translated">随机梯度下降</h2><p id="4ff6" class="pw-post-body-paragraph lm ln it lo b lp lq ju lr ls lt jx lu lv lw lx ly lz ma mb mc md me mf mg mh im bi translated">你的小批量= 1</p><h2 id="acbb" class="nq kv it bd kw oi oj dn la ok ol dp le lv om on lg lz oo op li md oq or lk os bi translated">批量梯度下降</h2><p id="73cf" class="pw-post-body-paragraph lm ln it lo b lp lq ju lr ls lt jx lu lv lw lx ly lz ma mb mc md me mf mg mh im bi translated">你的小批量=你的数据集长度。</p><h1 id="d883" class="ku kv it bd kw kx ky kz la lb lc ld le jz lf ka lg kc lh kd li kf lj kg lk ll bi translated">学习率衰减</h1><p id="4328" class="pw-post-body-paragraph lm ln it lo b lp lq ju lr ls lt jx lu lv lw lx ly lz ma mb mc md me mf mg mh im bi translated">以计算梯度下降的方式减小学习速率，以找到合适的局部最小值。</p><h2 id="a213" class="nq kv it bd kw oi oj dn la ok ol dp le lv om on lg lz oo op li md oq or lk os bi translated">人类水平的性能</h2><p id="2c63" class="pw-post-body-paragraph lm ln it lo b lp lq ju lr ls lt jx lu lv lw lx ly lz ma mb mc md me mf mg mh im bi translated">设置人类级别的性能，超越你的深度学习算法。<br/>大多设定为最佳人类表演。<br/>例如，如果下面陈述的三个人类表演；</p><ul class=""><li id="802c" class="pb pc it lo b lp mi ls mj lv pd lz pe md pf mh pg ph pi pj bi translated">% 0.5错误</li><li id="d2a4" class="pb pc it lo b lp pk ls pl lv pm lz pn md po mh pg ph pi pj bi translated">% 2错误</li><li id="467e" class="pb pc it lo b lp pk ls pl lv pm lz pn md po mh pg ph pi pj bi translated">% 1.5错误。<br/>那么应该是选人类级性能为0.5。<br/>你得到了逻辑。</li></ul><h1 id="f8bb" class="ku kv it bd kw kx ky kz la lb lc ld le jz lf ka lg kc lh kd li kf lj kg lk ll bi translated">迁移学习</h1><p id="5797" class="pw-post-body-paragraph lm ln it lo b lp lq ju lr ls lt jx lu lv lw lx ly lz ma mb mc md me mf mg mh im bi translated">你从你的深度学习网络中学到一些东西，比如，物体检测。<br/>如果您没有足够的数据来检测肿瘤，例如，您将使用第一个示例的几个层，并更改后面的层和/或激活函数来分析您的X射线结果。</p><h1 id="0b56" class="ku kv it bd kw kx ky kz la lb lc ld le jz lf ka lg kc lh kd li kf lj kg lk ll bi translated">多任务学习</h1><p id="c880" class="pw-post-body-paragraph lm ln it lo b lp lq ju lr ls lt jx lu lv lw lx ly lz ma mb mc md me mf mg mh im bi translated">由于你的深度学习网络，你将计算不止一个级别。</p><p id="41b5" class="pw-post-body-paragraph lm ln it lo b lp mi ju lr ls mj jx lu lv mk lx ly lz ml mb mc md mm mf mg mh im bi translated">例如，通过学习行人运动和阅读停车标志来预测自动驾驶汽车的运动。</p><h1 id="bca0" class="ku kv it bd kw kx ky kz la lb lc ld le jz lf ka lg kc lh kd li kf lj kg lk ll bi translated">张量流</h1><p id="9e26" class="pw-post-body-paragraph lm ln it lo b lp lq ju lr ls lt jx lu lv lw lx ly lz ma mb mc md me mf mg mh im bi translated">流行的Python机器学习Google开发的深度学习库。</p><h1 id="5a99" class="ku kv it bd kw kx ky kz la lb lc ld le jz lf ka lg kc lh kd li kf lj kg lk ll bi translated">结论</h1><p id="fa75" class="pw-post-body-paragraph lm ln it lo b lp lq ju lr ls lt jx lu lv lw lx ly lz ma mb mc md me mf mg mh im bi translated">现在你已经熟悉了很多深度学习的术语。</p><p id="714f" class="pw-post-body-paragraph lm ln it lo b lp mi ju lr ls mj jx lu lv mk lx ly lz ml mb mc md mm mf mg mh im bi translated">读完那篇文章后，如果你觉得你可能想了解更多，试着搜索类似的文章，如果你的学习冲动没有停止，我强烈推荐我在简介中添加链接的Andrew NG的一门课程。</p><p id="19d3" class="pw-post-body-paragraph lm ln it lo b lp mi ju lr ls mj jx lu lv mk lx ly lz ml mb mc md mm mf mg mh im bi translated">当然，你可能没有关于机器学习或其基础的先验知识。</p><p id="30aa" class="pw-post-body-paragraph lm ln it lo b lp mi ju lr ls mj jx lu lv mk lx ly lz ml mb mc md mm mf mg mh im bi translated">你可以看看那篇关于<a class="ae mo" rel="noopener ugc nofollow" target="_blank" href="/machine-learning-a-z-briefly-explained-4ff86bd81e3a">机器学习</a>、<a class="ae mo" rel="noopener ugc nofollow" target="_blank" href="/statistics-for-machine-learning-a-z-66a82fbf2622">统计</a>、<a class="ae mo" href="https://medium.datadriveninvestor.com/linear-algebra-a-z-for-machine-learning-68dadcd0b757" rel="noopener ugc nofollow" target="_blank">线性代数</a>、<a class="ae mo" href="https://medium.com/mlearning-ai/classification-a-z-briefly-explained-25ca811ab4e4" rel="noopener">分类</a>、<a class="ae mo" rel="noopener ugc nofollow" target="_blank" href="/regression-a-z-briefly-explained-618e5d5c89f8">和回归</a>的结构相同的文章。</p><p id="d8fa" class="pw-post-body-paragraph lm ln it lo b lp mi ju lr ls mj jx lu lv mk lx ly lz ml mb mc md mm mf mg mh im bi translated">如果你的反应是积极的，我将继续写这篇文章的第二部分。</p><p id="222f" class="pw-post-body-paragraph lm ln it lo b lp mi ju lr ls mj jx lu lv mk lx ly lz ml mb mc md mm mf mg mh im bi translated">感谢您到目前为止阅读我的文章。</p></div><div class="ab cl nw nx hx ny" role="separator"><span class="nz bw bk oa ob oc"/><span class="nz bw bk oa ob oc"/><span class="nz bw bk oa ob"/></div><div class="im in io ip iq"><p id="88df" class="pw-post-body-paragraph lm ln it lo b lp mi ju lr ls mj jx lu lv mk lx ly lz ml mb mc md mm mf mg mh im bi translated"><strong class="lo iu"> <em class="mn">如果你也想在将来收到关于那类文章的电子邮件，并阅读&amp;下载免费备忘单，请在此订阅我的电子邮件列表</em> </strong> <a class="ae mo" href="https://gencay.ck.page/" rel="noopener ugc nofollow" target="_blank"> <strong class="lo iu"> <em class="mn">。</em> </strong> </a></p><p id="a697" class="pw-post-body-paragraph lm ln it lo b lp mi ju lr ls mj jx lu lv mk lx ly lz ml mb mc md mm mf mg mh im bi translated">一般来说，我尽量每周发两封电子邮件。 </p></div><div class="ab cl nw nx hx ny" role="separator"><span class="nz bw bk oa ob oc"/><span class="nz bw bk oa ob oc"/><span class="nz bw bk oa ob"/></div><div class="im in io ip iq"><p id="9ee8" class="pw-post-body-paragraph lm ln it lo b lp mi ju lr ls mj jx lu lv mk lx ly lz ml mb mc md mm mf mg mh im bi translated"><strong class="lo iu"> <em class="mn">如果你还不是Medium的一员，渴望通过阅读来学习，这里是我推荐的</em> </strong> <a class="ae mo" href="https://medium.com/@geencay/membership" rel="noopener"> <strong class="lo iu"> <em class="mn">链接。</em>T32</strong></a></p></div><div class="ab cl nw nx hx ny" role="separator"><span class="nz bw bk oa ob oc"/><span class="nz bw bk oa ob oc"/><span class="nz bw bk oa ob"/></div><div class="im in io ip iq"><blockquote class="mu"><p id="699a" class="mv mw it bd mx my mz na nb nc nd mh dk translated">“机器学习是人类需要创造的最后一项发明。”</p><p id="cf99" class="mv mw it bd mx my mz na nb nc nd mh dk translated">尼克·博斯特伦</p></blockquote></div></div>    
</body>
</html>