<html>
<head>
<title>Understand Generative Adversarial Network (GAN) in Deep Learning</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">理解深度学习中的生成对抗网络</h1>
<blockquote>原文：<a href="https://pub.towardsai.net/understand-generative-adversarial-network-gan-in-deep-learning-d3afd5941a02?source=collection_archive---------1-----------------------#2021-07-22">https://pub.towardsai.net/understand-generative-adversarial-network-gan-in-deep-learning-d3afd5941a02?source=collection_archive---------1-----------------------#2021-07-22</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><h2 id="819e" class="ir is it bd b dl iu iv iw ix iy iz dk ja translated" aria-label="kicker paragraph"><a class="ae ep" href="https://towardsai.net/p/category/machine-learning/deep-learning" rel="noopener ugc nofollow" target="_blank">深度学习</a></h2><div class=""/><div class=""><h2 id="f7cc" class="pw-subtitle-paragraph jz jc it bd b ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq dk translated">在深度卷积神经网络模型中生成人工图像</h2></div><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi kr"><img src="../Images/beda25fd522388a5ef3009232b5d25a6.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Xo6YMeLvujBDjmeLH0vE_g.png"/></div></div><figcaption class="ld le gj gh gi lf lg bd b be z dk translated">图片<a class="ae lh" href="https://towardsdatascience.com/gan-introduction-and-implementation-part1-implement-a-simple-gan-in-tf-for-mnist-handwritten-de00a759ae5c" rel="noopener" target="_blank">来源</a></figcaption></figure><p id="c343" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">在本文中，我们将讨论生成对手网络(GAN ),它是由两个神经网络组成的深度神经网络架构，两个神经网络相互竞争。这里的“干”由两个词组成，其含义如下所示:</p><p id="d97a" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated"><strong class="lk jd"> <em class="me">生成式</em> </strong>是指生成接近我们想要近似的原始数据的概率分布。</p><p id="40af" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated"><strong class="lk jd"> <em class="me"> Adversarial </em> </strong>的意思是一般情况下是对立的，因为有两个模型即鉴别器和生成器，它们试图互相对立来学习概率分布函数。GAN是以对抗方式训练的神经网络，用于生成模拟我们想要近似的某种分布的数据。</p><p id="f2cb" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">机器学习中模型的分类。</p><ol class=""><li id="e194" class="mf mg it lk b ll lm lo lp lr mh lv mi lz mj md mk ml mm mn bi translated"><strong class="lk jd">判别模型:</strong>判别两类不同数据的模型。</li><li id="fb43" class="mf mg it lk b ll mo lo mp lr mq lv mr lz ms md mk ml mm mn bi translated"><strong class="lk jd">生成模型:</strong>该模型用于从随机分布的数据中生成图像，使分布D’接近真实图像分布D</li></ol><p id="8db0" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">数学上，</p><p id="02dd" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated"><strong class="lk jd"> z~Z映射到样本G(Z)~ D’</strong></p><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div class="gh gi mt"><img src="../Images/bf1e48e719107b0ca7cdd84d4c4130f6.png" data-original-src="https://miro.medium.com/v2/resize:fit:1228/format:webp/1*pmBkSb_e_H9T1Zmok7C3aA.png"/></div><figcaption class="ld le gj gh gi lf lg bd b be z dk translated">作者的照片</figcaption></figure><p id="3b41" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">在上图中，原始分布是一个圆D，数据点表示为X，其分布为D。生成器的工作是使随机分布Z到D '，并根据类似l1或l2范数的度量使其尽可能接近D。生成器G可以是神经网络或深度神经网络或卷积神经网络。</p><p id="713d" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">现在，在从生成模型中获得假样本后，鉴别器将区分假样本，即G(Z)和真样本，如果样本来自D，它将给出值“0 ”,如果来自D，它将给出值“1”。如果鉴别器给出值“0.5 ”,那么它将无法区分真样本和假样本。</p><div class="mu mv gp gr mw mx"><a rel="noopener  ugc nofollow" target="_blank" href="/understand-cnn-basics-with-a-keras-example-in-python-c1fd6c449935"><div class="my ab fo"><div class="mz ab na cl cj nb"><h2 class="bd jd gy z fp nc fr fs nd fu fw jc bi translated">通过Python中的Keras示例了解CNN基础知识</h2><div class="ne l"><h3 class="bd b gy z fp nc fr fs nd fu fw dk translated">用于图像过程分析的深度神经网络算法</h3></div><div class="nf l"><p class="bd b dl z fp nc fr fs nd fu fw dk translated">pub.towardsai.net</p></div></div><div class="ng l"><div class="nh l ni nj nk ng nl lb mx"/></div></div></a></div><div class="mu mv gp gr mw mx"><a rel="noopener  ugc nofollow" target="_blank" href="/bitcoin-price-prediction-with-rnn-and-lstm-in-python-f912d57c483e"><div class="my ab fo"><div class="mz ab na cl cj nb"><h2 class="bd jd gy z fp nc fr fs nd fu fw jc bi translated">用Python实现RNN和LSTM的比特币价格预测</h2><div class="ne l"><h3 class="bd b gy z fp nc fr fs nd fu fw dk translated">使用深度学习预测比特币价格</h3></div><div class="nf l"><p class="bd b dl z fp nc fr fs nd fu fw dk translated">pub.towardsai.net</p></div></div><div class="ng l"><div class="nm l ni nj nk ng nl lb mx"/></div></div></a></div><p id="9755" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated"><strong class="lk jd">生成敌对网络(GAN)中的损失函数是什么？</strong></p><p id="8e86" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">需要注意的重要部分是，生成器用于生成一个图像来欺骗鉴别器。鉴别器不能区分假图像和真实图像的时间，即发生器产生的假图像如此真实以至于不能鉴别。如果鉴别器知道从生成器生成的图像是假的，则它显示错误，并试图更新生成器和鉴别器中模型的权重和偏差。</p><p id="f42c" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">损失函数的公式是二元交叉熵，如下所示:</p><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div class="gh gi nn"><img src="../Images/78c19675ab0ac1341e7d9fc859563660.png" data-original-src="https://miro.medium.com/v2/resize:fit:924/format:webp/1*YfX9Y8066_neGGcRrbQ2RA.png"/></div></figure><p id="3d8a" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">其中<strong class="lk jd"> <em class="me"> y-hat </em> </strong>为重建图像，<strong class="lk jd"> <em class="me"> y </em> </strong>为原始图像。</p><p id="6b48" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">以GAN表示的实际损耗函数如下所示:</p><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div class="gh gi no"><img src="../Images/6234cab77285fa1edd0e1a26be5cba76.png" data-original-src="https://miro.medium.com/v2/resize:fit:1112/format:webp/1*WTclOCfUTyJOFgPPoGjERA.png"/></div></figure><blockquote class="np nq nr"><p id="f91b" class="li lj me lk b ll lm kd ln lo lp kg lq ns ls lt lu nt lw lx ly nu ma mb mc md im bi translated"><strong class="lk jd"> <em class="it">算法如何在生成性对抗网络中工作</em> </strong></p></blockquote><p id="689a" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">我们在制作GAN算法时可以做的基本步骤如下所示:</p><p id="4a09" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">步骤1:导入所有库</p><p id="df1e" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">步骤2:加载数据集</p><p id="0203" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">步骤3:现在我们可以给出训练和网络参数</p><p id="064c" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">步骤4:我们可以设置权重和偏差变量</p><p id="4c8f" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">第五步:现在，让生成器和鉴别器运行。</p><p id="4f86" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">步骤6:定义损失和优化</p><ul class=""><li id="ae4c" class="mf mg it lk b ll lm lo lp lr mh lv mi lz mj md nv ml mm mn bi translated">鉴别器损失:用于量化区分真假图像。</li><li id="e324" class="mf mg it lk b ll mo lo mp lr mq lv mr lz ms md nv ml mm mn bi translated">发生器损耗:用于欺骗鉴别器，使其误以为假图像是真图像。</li></ul><p id="2521" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">第七步:训练发生器和鉴别器，保存发生器的图像以匹配真实图像。</p><div class="mu mv gp gr mw mx"><a rel="noopener  ugc nofollow" target="_blank" href="/neural-networks-the-rise-of-recurrent-neural-networks-df740252da88"><div class="my ab fo"><div class="mz ab na cl cj nb"><h2 class="bd jd gy z fp nc fr fs nd fu fw jc bi translated">神经网络:递归神经网络的兴起</h2><div class="ne l"><h3 class="bd b gy z fp nc fr fs nd fu fw dk translated">深度学习中的渐进一代</h3></div><div class="nf l"><p class="bd b dl z fp nc fr fs nd fu fw dk translated">pub.towardsai.net</p></div></div><div class="ng l"><div class="nw l ni nj nk ng nl lb mx"/></div></div></a></div><blockquote class="np nq nr"><p id="417e" class="li lj me lk b ll lm kd ln lo lp kg lq ns ls lt lu nt lw lx ly nu ma mb mc md im bi translated"><strong class="lk jd"> <em class="it">生成性对抗网络的局限性</em> </strong></p></blockquote><ul class=""><li id="c9be" class="mf mg it lk b ll lm lo lp lr mh lv mi lz mj md nv ml mm mn bi translated"><strong class="lk jd">什么是GAN中的模式崩塌？</strong></li></ul><p id="b881" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">在训练期间，发生器可能会崩溃到始终产生相同输出的设置。这被称为模式崩溃。</p><ul class=""><li id="b2f7" class="mf mg it lk b ll lm lo lp lr mh lv mi lz mj md nv ml mm mn bi translated"><strong class="lk jd">消失渐变</strong></li></ul><p id="a8d4" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">权重和偏差的导数变得接近于零。</p><ul class=""><li id="b681" class="mf mg it lk b ll lm lo lp lr mh lv mi lz mj md nv ml mm mn bi translated"><strong class="lk jd">难以达成纳什均衡</strong></li></ul><p id="0f65" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">鉴别器和生成器的成本更新之间没有关系，因为生成器更新的成本与其他模型无关。因此，两种模型的梯度都不能保证收敛。</p><ul class=""><li id="c3b8" class="mf mg it lk b ll lm lo lp lr mh lv mi lz mj md nv ml mm mn bi translated"><strong class="lk jd">计数问题</strong></li></ul><p id="e710" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">在很多情况下，我们会看到模糊的图像，图像中的对象看起来更多，因为图像中的突然性会产生更多的预测。</p><ul class=""><li id="ea1a" class="mf mg it lk b ll lm lo lp lr mh lv mi lz mj md nv ml mm mn bi translated"><strong class="lk jd">透视问题</strong></li></ul><p id="9b89" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">有时生成性对抗网络<strong class="lk jd"> </strong>不能够理解图像的前后视图。</p><blockquote class="np nq nr"><p id="ff6e" class="li lj me lk b ll lm kd ln lo lp kg lq ns ls lt lu nt lw lx ly nu ma mb mc md im bi translated"><strong class="lk jd"> <em class="it">结论</em> </strong></p></blockquote><p id="1672" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">本文给出了生成性对抗网络的直觉。</p></div><div class="ab cl nx ny hx nz" role="separator"><span class="oa bw bk ob oc od"/><span class="oa bw bk ob oc od"/><span class="oa bw bk ob oc"/></div><div class="im in io ip iq"><p id="2e76" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">我希望你喜欢这篇文章。通过我的<a class="ae lh" href="https://www.linkedin.com/in/data-scientist-95040a1ab/" rel="noopener ugc nofollow" target="_blank"> LinkedIn </a>和<a class="ae lh" href="https://twitter.com/amitprius" rel="noopener ugc nofollow" target="_blank"> twitter </a>联系我。</p><h1 id="4ba5" class="oe of it bd og oh oi oj ok ol om on oo ki op kj oq kl or km os ko ot kp ou ov bi translated">推荐文章</h1><p id="4bf8" class="pw-post-body-paragraph li lj it lk b ll ow kd ln lo ox kg lq lr oy lt lu lv oz lx ly lz pa mb mc md im bi translated"><a class="ae lh" href="https://medium.com/towards-artificial-intelligence/nlp-zero-to-hero-with-python-2df6fcebff6e?sk=2231d868766e96b13d1e9d7db6064df1" rel="noopener"> 1。NLP —零到英雄用Python </a> <br/> 2。<a class="ae lh" href="https://medium.com/towards-artificial-intelligence/python-data-structures-data-types-and-objects-244d0a86c3cf?sk=42f4b462499f3fc3a160b21e2c94dba6" rel="noopener"> Python数据结构数据类型和对象</a> <br/> 3。<a class="ae lh" rel="noopener ugc nofollow" target="_blank" href="/exception-handling-concepts-in-python-4d5116decac3?source=friends_link&amp;sk=a0ed49d9fdeaa67925eac34ecb55ea30">Python中的异常处理概念</a> <br/> 4。<a class="ae lh" rel="noopener ugc nofollow" target="_blank" href="/deep-learning-88e218b74a14?source=friends_link&amp;sk=540bf9088d31859d50dbddab7524ba35">为什么LSTM在深度学习方面比RNN更有用？</a> <br/> 5。<a class="ae lh" rel="noopener ugc nofollow" target="_blank" href="/neural-networks-the-rise-of-recurrent-neural-networks-df740252da88?source=friends_link&amp;sk=6844935e3de14e478ce00f0b22e419eb">神经网络:递归神经网络的兴起</a> <br/> 6。<a class="ae lh" href="https://medium.com/towards-artificial-intelligence/fully-explained-linear-regression-with-python-fe2b313f32f3?source=friends_link&amp;sk=53c91a2a51347ec2d93f8222c0e06402" rel="noopener">用Python充分解释了线性回归</a> <br/> 7。<a class="ae lh" href="https://medium.com/towards-artificial-intelligence/fully-explained-logistic-regression-with-python-f4a16413ddcd?source=friends_link&amp;sk=528181f15a44e48ea38fdd9579241a78" rel="noopener">用Python </a> <br/>充分解释了Logistic回归8。<a class="ae lh" rel="noopener ugc nofollow" target="_blank" href="/differences-between-concat-merge-and-join-with-python-1a6541abc08d?source=friends_link&amp;sk=3b37b694fb90db16275059ea752fc16a">concat()、merge()和join()与Python </a> <br/> 9的区别。<a class="ae lh" rel="noopener ugc nofollow" target="_blank" href="/data-wrangling-with-python-part-1-969e3cc81d69?source=friends_link&amp;sk=9c3649cf20f31a5c9ead51c50c89ba0b">与Python的数据角力—第一部分</a>T30】10。<a class="ae lh" href="https://medium.com/analytics-vidhya/confusion-matrix-in-machine-learning-91b6e2b3f9af?source=friends_link&amp;sk=11c6531da0bab7b504d518d02746d4cc" rel="noopener">机器学习中的混淆矩阵</a></p></div></div>    
</body>
</html>