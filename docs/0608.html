<html>
<head>
<title>Gradient Descent Algorithm Explained</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">梯度下降算法讲解</h1>
<blockquote>原文：<a href="https://pub.towardsai.net/gradient-descent-algorithm-explained-2fe9da0de9a2?source=collection_archive---------0-----------------------#2020-06-21">https://pub.towardsai.net/gradient-descent-algorithm-explained-2fe9da0de9a2?source=collection_archive---------0-----------------------#2020-06-21</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><h2 id="18a8" class="io ip iq bd b dl ir is it iu iv iw dk ix translated" aria-label="kicker paragraph"><a class="ae ep" href="https://towardsai.net/p/category/machine-learning" rel="noopener ugc nofollow" target="_blank">机器学习</a></h2><div class=""/><div class=""><h2 id="06bd" class="pw-subtitle-paragraph jw iz iq bd b jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn dk translated">一步一步的数学推导</h2></div><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div role="button" tabindex="0" class="ku kv di kw bf kx"><div class="gh gi ko"><img src="../Images/b2c5dc32d1856d919efe8b1de5ce57e8.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*jYuoNcJOuwtVVBqnqaV0HQ.jpeg"/></div></div><figcaption class="la lb gj gh gi lc ld bd b be z dk translated">来源:<a class="ae le" href="https://unsplash.com/photos/LndSNO0J8F0" rel="noopener ugc nofollow" target="_blank"> Unsplash </a></figcaption></figure><h1 id="05da" class="lf lg iq bd lh li lj lk ll lm ln lo lp kf lq kg lr ki ls kj lt kl lu km lv lw bi translated">索引:</h1><ul class=""><li id="90b3" class="lx ly iq lz b ma mb mc md me mf mg mh mi mj mk ml mm mn mo bi translated">梯度下降的基础。</li><li id="f2b3" class="lx ly iq lz b ma mp mc mq me mr mg ms mi mt mk ml mm mn mo bi translated">推导的基本规则。</li><li id="8d7d" class="lx ly iq lz b ma mp mc mq me mr mg ms mi mt mk ml mm mn mo bi translated">单变量梯度下降。</li><li id="5825" class="lx ly iq lz b ma mp mc mq me mr mg ms mi mt mk ml mm mn mo bi translated">双变量梯度下降。</li><li id="474e" class="lx ly iq lz b ma mp mc mq me mr mg ms mi mt mk ml mm mn mo bi translated">均方误差函数的梯度下降。</li></ul></div><div class="ab cl mu mv hu mw" role="separator"><span class="mx bw bk my mz na"/><span class="mx bw bk my mz na"/><span class="mx bw bk my mz"/></div><div class="ij ik il im in"><h2 id="8a83" class="nb lg iq bd lh nc nd dn ll ne nf dp lp me ng nh lr mg ni nj lt mi nk nl lv iw bi translated">什么是梯度下降？</h2><p id="e324" class="pw-post-body-paragraph nm nn iq lz b ma mb ka no mc md kd np me nq nr ns mg nt nu nv mi nw nx ny mk ij bi translated">梯度下降是一种机器学习算法，它迭代地寻找其参数的最佳值。它考虑了用户定义的学习率和初始参数值。</p><h2 id="57b0" class="nb lg iq bd lh nc nd dn ll ne nf dp lp me ng nh lr mg ni nj lt mi nk nl lv iw bi translated">它是如何工作的？</h2><ul class=""><li id="2e62" class="lx ly iq lz b ma mb mc md me mf mg mh mi mj mk ml mm mn mo bi translated">从初始值开始。</li><li id="68c8" class="lx ly iq lz b ma mp mc mq me mr mg ms mi mt mk ml mm mn mo bi translated">计算成本。</li><li id="b75e" class="lx ly iq lz b ma mp mc mq me mr mg ms mi mt mk ml mm mn mo bi translated">使用Update函数更新值。</li><li id="a2a9" class="lx ly iq lz b ma mp mc mq me mr mg ms mi mt mk ml mm mn mo bi translated">返回成本函数的最小成本</li></ul><h2 id="7b28" class="nb lg iq bd lh nc nd dn ll ne nf dp lp me ng nh lr mg ni nj lt mi nk nl lv iw bi translated">我们为什么需要它？</h2><p id="4c93" class="pw-post-body-paragraph nm nn iq lz b ma mb ka no mc md kd np me nq nr ns mg nt nu nv mi nw nx ny mk ij bi translated">一般来说，我们要做的是，找到给出参数最优值的公式。但是在这个算法里，它是自己找值的！很有趣，不是吗？</p><h2 id="1089" class="nb lg iq bd lh nc nd dn ll ne nf dp lp me ng nh lr mg ni nj lt mi nk nl lv iw bi translated">公式:</h2><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div class="ab gu cl nz"><img src="../Images/1706dd8380821252b70f8ea3197c9c51.png" data-original-src="https://miro.medium.com/v2/format:webp/1*TKwMAQnyj_CJgZeT1dgg2g.png"/></div><figcaption class="la lb gj gh gi lc ld bd b be z dk translated">梯度下降公式</figcaption></figure></div><div class="ab cl mu mv hu mw" role="separator"><span class="mx bw bk my mz na"/><span class="mx bw bk my mz na"/><span class="mx bw bk my mz"/></div><div class="ij ik il im in"><h1 id="eb7b" class="lf lg iq bd lh li oa lk ll lm ob lo lp kf oc kg lr ki od kj lt kl oe km lv lw bi translated">推导的一些基本规则:</h1><p id="69da" class="pw-post-body-paragraph nm nn iq lz b ma mb ka no mc md kd np me nq nr ns mg nt nu nv mi nw nx ny mk ij bi translated">(一)标量倍数规则:</p><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div class="gh gi of"><img src="../Images/bc9b8510e21ffd98a66ac0cade749297.png" data-original-src="https://miro.medium.com/v2/resize:fit:500/format:webp/1*ki72jEbZo00eyyJpgrimdQ.png"/></div><figcaption class="la lb gj gh gi lc ld bd b be z dk translated">来源:图片由作者创作。</figcaption></figure><p id="5e34" class="pw-post-body-paragraph nm nn iq lz b ma og ka no mc oh kd np me oi nr ns mg oj nu nv mi ok nx ny mk ij bi translated">(B)总和规则:</p><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div class="gh gi ol"><img src="../Images/af232680bf3d8e2edf4c7c6ce61506e2.png" data-original-src="https://miro.medium.com/v2/resize:fit:478/format:webp/1*fSrSpG7_Zl8DyV4vG2rbtA.png"/></div><figcaption class="la lb gj gh gi lc ld bd b be z dk translated">来源:图片由作者创作。</figcaption></figure><p id="6517" class="pw-post-body-paragraph nm nn iq lz b ma og ka no mc oh kd np me oi nr ns mg oj nu nv mi ok nx ny mk ij bi translated">权力规则:</p><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div class="gh gi om"><img src="../Images/50348bc1595f375a49677748a12f2990.png" data-original-src="https://miro.medium.com/v2/resize:fit:562/format:webp/1*NlUFlckiYGtghsk0KXnVrw.png"/></div><figcaption class="la lb gj gh gi lc ld bd b be z dk translated">来源:图片由作者创作。</figcaption></figure><p id="f41d" class="pw-post-body-paragraph nm nn iq lz b ma og ka no mc oh kd np me oi nr ns mg oj nu nv mi ok nx ny mk ij bi translated">(D)连锁规则:</p><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div class="gh gi on"><img src="../Images/e7bba93963fbdf80aa2b3d385dab8abb.png" data-original-src="https://miro.medium.com/v2/resize:fit:992/format:webp/1*EItmT-Kn7dsavPesRB8S-Q.png"/></div><figcaption class="la lb gj gh gi lc ld bd b be z dk translated">来源:图片由作者创作。</figcaption></figure></div><div class="ab cl mu mv hu mw" role="separator"><span class="mx bw bk my mz na"/><span class="mx bw bk my mz na"/><span class="mx bw bk my mz"/></div><div class="ij ik il im in"><h2 id="bdc0" class="nb lg iq bd lh nc nd dn ll ne nf dp lp me ng nh lr mg ni nj lt mi nk nl lv iw bi translated">让我们看看各种例子来更好地理解它。</h2><h1 id="8597" class="lf lg iq bd lh li lj lk ll lm ln lo lp kf lq kg lr ki ls kj lt kl lu km lv lw bi translated">梯度下降最小化—单变量:</h1><p id="81ed" class="pw-post-body-paragraph nm nn iq lz b ma mb ka no mc md kd np me nq nr ns mg nt nu nv mi nw nx ny mk ij bi translated">我们将使用梯度下降来寻找使成本最小的<em class="oo"> θ </em>。但是让我们暂时忘记均方误差(MSE)成本函数，来看看一般的梯度下降函数。</p><p id="fbcb" class="pw-post-body-paragraph nm nn iq lz b ma og ka no mc oh kd np me oi nr ns mg oj nu nv mi ok nx ny mk ij bi translated">现在我们通常做的是，使用某种简化找到参数的最佳值，并建立一个函数，使我们的成本最小化。但是这里我们要做的是为我们的参数取一些默认值或随机值，让我们的程序迭代运行，以找到最小化的成本。</p><h2 id="8513" class="nb lg iq bd lh nc nd dn ll ne nf dp lp me ng nh lr mg ni nj lt mi nk nl lv iw bi translated">让我们深入探讨一下:</h2><p id="b8a5" class="pw-post-body-paragraph nm nn iq lz b ma mb ka no mc md kd np me nq nr ns mg nt nu nv mi nw nx ny mk ij bi translated">先拿一个很简单的函数来说:<strong class="lz ja"> J( <em class="oo"> θ </em> ) = <em class="oo"> θ </em> </strong>，我们的目标是求<em class="oo"> θ </em>的值，其中<strong class="lz ja">使J( <em class="oo"> θ </em> ) </strong>最小。</p><p id="6029" class="pw-post-body-paragraph nm nn iq lz b ma og ka no mc oh kd np me oi nr ns mg oj nu nv mi ok nx ny mk ij bi translated">从我们的成本函数中，我们可以清楚地说，对于<em class="oo"> θ </em> = 0，它将是最小的，但在处理一些复杂的函数时，得出这样的结论就不会那么容易了。</p><p id="d7c7" class="pw-post-body-paragraph nm nn iq lz b ma og ka no mc oh kd np me oi nr ns mg oj nu nv mi ok nx ny mk ij bi translated">(A)成本函数:我们将尝试最小化该函数的值。</p><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div class="gh gi op"><img src="../Images/953ceebd1ce3681f6253fe43817d17da.png" data-original-src="https://miro.medium.com/v2/resize:fit:288/format:webp/1*bqBPFnfWqwsZycSccu2l8Q.png"/></div><figcaption class="la lb gj gh gi lc ld bd b be z dk translated">来源:图片由作者创作。</figcaption></figure><p id="87cf" class="pw-post-body-paragraph nm nn iq lz b ma og ka no mc oh kd np me oi nr ns mg oj nu nv mi ok nx ny mk ij bi translated">(B)目标:最小化成本函数。</p><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div class="gh gi oq"><img src="../Images/ed3382a4fbcaf4789f43c46ac58a2a29.png" data-original-src="https://miro.medium.com/v2/resize:fit:278/format:webp/1*9_7aZKkiU_BC5kIMSSaKkA.png"/></div><figcaption class="la lb gj gh gi lc ld bd b be z dk translated">来源:图片由作者创作。</figcaption></figure><p id="b42b" class="pw-post-body-paragraph nm nn iq lz b ma og ka no mc oh kd np me oi nr ns mg oj nu nv mi ok nx ny mk ij bi translated">(C)更新函数:最初我们为我们的参数取一个随机数，这不是最佳的。为了使它最优，我们必须在每次迭代中更新它。这个函数会处理它。</p><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div class="gh gi om"><img src="../Images/79479327285dabd424a4582196c37ca2.png" data-original-src="https://miro.medium.com/v2/resize:fit:562/format:webp/1*IMTyJ-FZRbrisirky7osrQ.png"/></div><figcaption class="la lb gj gh gi lc ld bd b be z dk translated">来源:图片由作者创作。</figcaption></figure><p id="096e" class="pw-post-body-paragraph nm nn iq lz b ma og ka no mc oh kd np me oi nr ns mg oj nu nv mi ok nx ny mk ij bi translated">学习速度:下降速度。</p><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div role="button" tabindex="0" class="ku kv di kw bf kx"><div class="gh gi or"><img src="../Images/fb879d45fcfe4fe2c6225374edb049e6.png" data-original-src="https://miro.medium.com/v2/resize:fit:432/format:webp/1*6-ObfRstNBpoStczaMRsTA.png"/></div></div><figcaption class="la lb gj gh gi lc ld bd b be z dk translated">来源:图片由作者创作。</figcaption></figure><p id="feb4" class="pw-post-body-paragraph nm nn iq lz b ma og ka no mc oh kd np me oi nr ns mg oj nu nv mi ok nx ny mk ij bi translated">(E)更新参数:</p><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div class="gh gi os"><img src="../Images/16b4b56c1b744786c8e04f6b10b58bc1.png" data-original-src="https://miro.medium.com/v2/resize:fit:566/format:webp/1*Kyu02g-SF8L6RLV-hz4yWA.png"/></div><figcaption class="la lb gj gh gi lc ld bd b be z dk translated">来源:图片由作者创作。</figcaption></figure><p id="0bb5" class="pw-post-body-paragraph nm nn iq lz b ma og ka no mc oh kd np me oi nr ns mg oj nu nv mi ok nx ny mk ij bi translated">表格生成:</p><p id="e45c" class="pw-post-body-paragraph nm nn iq lz b ma og ka no mc oh kd np me oi nr ns mg oj nu nv mi ok nx ny mk ij bi translated">这里我们用θ = 5来表示。</p><p id="1c56" class="pw-post-body-paragraph nm nn iq lz b ma og ka no mc oh kd np me oi nr ns mg oj nu nv mi ok nx ny mk ij bi translated">记住这里θ = 0.8*θ，对于我们的学习率和代价函数。</p><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div class="gh gi ot"><img src="../Images/c31a7a74da43ffb4a1982a200ca4de99.png" data-original-src="https://miro.medium.com/v2/resize:fit:658/format:webp/1*tRf_Hm8dcW4Mehgnlgqquw.png"/></div><figcaption class="la lb gj gh gi lc ld bd b be z dk translated">来源:图片由作者创作。</figcaption></figure><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div class="gh gi ou"><img src="../Images/24ecf0e1728ee2db253c2271c220e1c1.png" data-original-src="https://miro.medium.com/v2/resize:fit:674/format:webp/1*QAjuibOHCsFOdHxMJsrpxw.png"/></div><figcaption class="la lb gj gh gi lc ld bd b be z dk translated">来源:图片由作者创作。</figcaption></figure><p id="b624" class="pw-post-body-paragraph nm nn iq lz b ma og ka no mc oh kd np me oi nr ns mg oj nu nv mi ok nx ny mk ij bi translated">这里我们可以看到，随着θ的降低，成本值也在降低。我们只需要找到它的最佳值。为了找到最佳值，我们必须进行多次迭代。迭代次数越多，我们得到的最优值就越多！</p><p id="c175" class="pw-post-body-paragraph nm nn iq lz b ma og ka no mc oh kd np me oi nr ns mg oj nu nv mi ok nx ny mk ij bi translated">图表:我们可以绘制上述各点的图表。</p><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div class="gh gi ov"><img src="../Images/e18fb0b614275647b7330b6cea87a39b.png" data-original-src="https://miro.medium.com/v2/resize:fit:824/format:webp/1*P7DRjva9EDRxsUIbWp9AuA.png"/></div><figcaption class="la lb gj gh gi lc ld bd b be z dk translated">来源:图片由作者创作。</figcaption></figure><h2 id="be2f" class="nb lg iq bd lh nc nd dn ll ne nf dp lp me ng nh lr mg ni nj lt mi nk nl lv iw bi translated">成本函数导数:</h2><p id="536f" class="pw-post-body-paragraph nm nn iq lz b ma mb ka no mc md kd np me nq nr ns mg nt nu nv mi nw nx ny mk ij bi translated">为什么梯度下降要用代价函数的导数？我们希望我们的成本函数最小，对吗？最小化成本函数只是让我们在预测值时有更低的错误率。理想情况下，我们取一个函数对0的导数，求参数。这里我们做同样的事情，但我们从一个随机数开始，并试图迭代地最小化它。</p><h2 id="3ae5" class="nb lg iq bd lh nc nd dn ll ne nf dp lp me ng nh lr mg ni nj lt mi nk nl lv iw bi translated">学习率/α:</h2><p id="c1ab" class="pw-post-body-paragraph nm nn iq lz b ma mb ka no mc md kd np me nq nr ns mg nt nu nv mi nw nx ny mk ij bi translated">学习速度让我们能够很好地控制我们前进的步伐。选择正确的学习速度是一项非常关键的任务。如果学习率太高，那么你可能会超过最小值而偏离。例如，在上面的例子中，如果我们取α= 2，那么每次迭代都会使我们远离最小值。所以我们使用小的阿尔法值。但是使用小的学习率的唯一问题是我们必须执行更多的迭代以达到最小的成本值，这增加了训练时间。</p><h2 id="ccba" class="nb lg iq bd lh nc nd dn ll ne nf dp lp me ng nh lr mg ni nj lt mi nk nl lv iw bi translated">收敛/停止梯度下降:</h2><p id="70bd" class="pw-post-body-paragraph nm nn iq lz b ma mb ka no mc md kd np me nq nr ns mg nt nu nv mi nw nx ny mk ij bi translated">注意，在上面的例子中，梯度下降实际上永远不会收敛到θ= 0的最小值。决定何时停止迭代的方法超出了我的专业水平。但是我可以告诉你，在做作业的时候，我们可以进行固定次数的迭代，比如100或1000次。</p></div><div class="ab cl mu mv hu mw" role="separator"><span class="mx bw bk my mz na"/><span class="mx bw bk my mz na"/><span class="mx bw bk my mz"/></div><div class="ij ik il im in"><h1 id="a978" class="lf lg iq bd lh li oa lk ll lm ob lo lp kf oc kg lr ki od kj lt kl oe km lv lw bi translated">梯度下降—多变量:</h1><p id="3932" class="pw-post-body-paragraph nm nn iq lz b ma mb ka no mc md kd np me nq nr ns mg nt nu nv mi nw nx ny mk ij bi translated">我们的最终目标是找到包含多个变量的MSE函数的参数。所以这里我们将讨论一个2变量的成本函数。理解这一点将对我们的MSE成本函数有很大帮助。</p><p id="5e13" class="pw-post-body-paragraph nm nn iq lz b ma og ka no mc oh kd np me oi nr ns mg oj nu nv mi ok nx ny mk ij bi translated">让我们来看看这个函数:</p><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div class="gh gi ow"><img src="../Images/91bb335c66d4964d2c43d4ea2bdbc5d2.png" data-original-src="https://miro.medium.com/v2/resize:fit:460/format:webp/1*HbZbaTQa3rjKYPFDBrqJJw.png"/></div><figcaption class="la lb gj gh gi lc ld bd b be z dk translated">来源:图片由作者创作。</figcaption></figure><p id="9d5a" class="pw-post-body-paragraph nm nn iq lz b ma og ka no mc oh kd np me oi nr ns mg oj nu nv mi ok nx ny mk ij bi translated">当最小化目标中有多个变量时，我们必须为更新函数定义单独的规则。由于成本函数中有多个参数，我们必须使用偏导数。这里我简化了偏导数过程。让我们看看这个。</p><p id="751d" class="pw-post-body-paragraph nm nn iq lz b ma og ka no mc oh kd np me oi nr ns mg oj nu nv mi ok nx ny mk ij bi translated">(A)成本函数:</p><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div class="gh gi ox"><img src="../Images/ffbc0c5ce0821a3559d71814a9e039b9.png" data-original-src="https://miro.medium.com/v2/resize:fit:544/format:webp/1*m0D497kN4qDuQ9dHZoh4Zg.png"/></div><figcaption class="la lb gj gh gi lc ld bd b be z dk translated">来源:图片由作者创作。</figcaption></figure><p id="9997" class="pw-post-body-paragraph nm nn iq lz b ma og ka no mc oh kd np me oi nr ns mg oj nu nv mi ok nx ny mk ij bi translated">目标:</p><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div class="gh gi oy"><img src="../Images/861fda436fa3a83d6dbe8b7c510e480a.png" data-original-src="https://miro.medium.com/v2/resize:fit:358/format:webp/1*_p9BDEbPPJ8pX57zVwmXoA.png"/></div><figcaption class="la lb gj gh gi lc ld bd b be z dk translated">来源:图片由作者创作。</figcaption></figure><p id="74cc" class="pw-post-body-paragraph nm nn iq lz b ma og ka no mc oh kd np me oi nr ns mg oj nu nv mi ok nx ny mk ij bi translated">(C)更新规则:</p><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div class="gh gi oz"><img src="../Images/471c11d4a0e0062a96783fde3ec4c983.png" data-original-src="https://miro.medium.com/v2/resize:fit:692/format:webp/1*gPpx5bs7z9oP5wZmjKNgaA.png"/></div><figcaption class="la lb gj gh gi lc ld bd b be z dk translated">来源:图片由作者创作。</figcaption></figure><p id="5987" class="pw-post-body-paragraph nm nn iq lz b ma og ka no mc oh kd np me oi nr ns mg oj nu nv mi ok nx ny mk ij bi translated">衍生产品:</p><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div class="gh gi pa"><img src="../Images/7246d0f7459e9f045fd69caea083064b.png" data-original-src="https://miro.medium.com/v2/resize:fit:958/format:webp/1*c7LTsVVPUs7P21H4xlhLsw.png"/></div><figcaption class="la lb gj gh gi lc ld bd b be z dk translated">来源:图片由作者创作。</figcaption></figure><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div class="gh gi pb"><img src="../Images/15f504ef9d8f14960d1fd818edf96a98.png" data-original-src="https://miro.medium.com/v2/resize:fit:956/format:webp/1*iO6y_f76K8IMbwTP7b7-Iw.png"/></div><figcaption class="la lb gj gh gi lc ld bd b be z dk translated">来源:图片由作者创作。</figcaption></figure><p id="08df" class="pw-post-body-paragraph nm nn iq lz b ma og ka no mc oh kd np me oi nr ns mg oj nu nv mi ok nx ny mk ij bi translated">(E)更新数值:</p><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div class="gh gi os"><img src="../Images/015662445939ed56a5cda2cbe649c688.png" data-original-src="https://miro.medium.com/v2/resize:fit:566/format:webp/1*ESe9Bez03C5khChJzrZSrA.png"/></div><figcaption class="la lb gj gh gi lc ld bd b be z dk translated">来源:图片由作者创作。</figcaption></figure><p id="a226" class="pw-post-body-paragraph nm nn iq lz b ma og ka no mc oh kd np me oi nr ns mg oj nu nv mi ok nx ny mk ij bi translated">学习率:</p><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div class="gh gi ol"><img src="../Images/812ea028773924195565c88cc318fb79.png" data-original-src="https://miro.medium.com/v2/resize:fit:478/format:webp/1*3hFUtNRe7LLFXOigmOssOg.png"/></div><figcaption class="la lb gj gh gi lc ld bd b be z dk translated">来源:图片由作者创作。</figcaption></figure><p id="49e0" class="pw-post-body-paragraph nm nn iq lz b ma og ka no mc oh kd np me oi nr ns mg oj nu nv mi ok nx ny mk ij bi translated">(G)表格:</p><p id="40b6" class="pw-post-body-paragraph nm nn iq lz b ma og ka no mc oh kd np me oi nr ns mg oj nu nv mi ok nx ny mk ij bi translated">从θ1 =1开始，θ2 =1。然后使用更新函数更新该值。</p><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div class="gh gi pc"><img src="../Images/75814cd625db14c0778a4455a1754810.png" data-original-src="https://miro.medium.com/v2/resize:fit:990/format:webp/1*qFA0hHiFBtMkTuLvMSbFTw.png"/></div><figcaption class="la lb gj gh gi lc ld bd b be z dk translated">来源:图片由作者创作。</figcaption></figure><p id="9897" class="pw-post-body-paragraph nm nn iq lz b ma og ka no mc oh kd np me oi nr ns mg oj nu nv mi ok nx ny mk ij bi translated">图表:</p><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div class="gh gi pd"><img src="../Images/911816e983a15276a253c34f69598cd5.png" data-original-src="https://miro.medium.com/v2/resize:fit:848/format:webp/1*-SVhF83aCwZSDGKtuhfrJw.png"/></div><figcaption class="la lb gj gh gi lc ld bd b be z dk translated">来源:图片由作者创作。</figcaption></figure><p id="c954" class="pw-post-body-paragraph nm nn iq lz b ma og ka no mc oh kd np me oi nr ns mg oj nu nv mi ok nx ny mk ij bi translated">这里我们可以看到，随着迭代次数的增加，我们的成本值在下降。</p><p id="1455" class="pw-post-body-paragraph nm nn iq lz b ma og ka no mc oh kd np me oi nr ns mg oj nu nv mi ok nx ny mk ij bi translated">注意，在python中实现程序时，在我们找到θ1和θ2的新值之前，不能更新新值。我们显然不想用θ1的新值去用θ2的旧值。</p></div><div class="ab cl mu mv hu mw" role="separator"><span class="mx bw bk my mz na"/><span class="mx bw bk my mz na"/><span class="mx bw bk my mz"/></div><div class="ij ik il im in"><h1 id="5aa4" class="lf lg iq bd lh li oa lk ll lm ob lo lp kf oc kg lr ki od kj lt kl oe km lv lw bi translated">均方误差的梯度下降；</h1><p id="3d3e" class="pw-post-body-paragraph nm nn iq lz b ma mb ka no mc md kd np me nq nr ns mg nt nu nv mi nw nx ny mk ij bi translated">既然我们知道了如何对一个多变量的方程进行梯度下降，我们可以返回来看看我们的MSE成本函数的梯度下降。</p><p id="b1d5" class="pw-post-body-paragraph nm nn iq lz b ma og ka no mc oh kd np me oi nr ns mg oj nu nv mi ok nx ny mk ij bi translated">我们开始吧！</p><p id="2595" class="pw-post-body-paragraph nm nn iq lz b ma og ka no mc oh kd np me oi nr ns mg oj nu nv mi ok nx ny mk ij bi translated">(一)假设功能:</p><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div class="gh gi pe"><img src="../Images/0c3f11cb86194571e73c6c265dc86de9.png" data-original-src="https://miro.medium.com/v2/resize:fit:552/format:webp/1*TbkK_7EHNSUvi_0n7jzQUg.png"/></div><figcaption class="la lb gj gh gi lc ld bd b be z dk translated">来源:图片由作者创作。</figcaption></figure><p id="08bc" class="pw-post-body-paragraph nm nn iq lz b ma og ka no mc oh kd np me oi nr ns mg oj nu nv mi ok nx ny mk ij bi translated">(B)成本函数:</p><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div class="gh gi pf"><img src="../Images/adf5e181c46728f8f19a8ce955fbcbc0.png" data-original-src="https://miro.medium.com/v2/resize:fit:700/format:webp/1*8RB1I6g2q-qjR-RKf7gxuQ.png"/></div><figcaption class="la lb gj gh gi lc ld bd b be z dk translated">来源:图片由作者创作。</figcaption></figure><p id="7137" class="pw-post-body-paragraph nm nn iq lz b ma og ka no mc oh kd np me oi nr ns mg oj nu nv mi ok nx ny mk ij bi translated">(C)求J(θ0，θ1) w.r.t对θ1的偏导数:</p><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div class="gh gi pg"><img src="../Images/172c847cc8c4c192811af5ac3ac9cd00.png" data-original-src="https://miro.medium.com/v2/resize:fit:1052/format:webp/1*qdwntOq1meZXvoGxu0zAyg.png"/></div><figcaption class="la lb gj gh gi lc ld bd b be z dk translated">来源:图片由作者创作。</figcaption></figure><p id="d6b0" class="pw-post-body-paragraph nm nn iq lz b ma og ka no mc oh kd np me oi nr ns mg oj nu nv mi ok nx ny mk ij bi translated">(D)简化一点:</p><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div class="gh gi ph"><img src="../Images/713979b117c6390df2b41369677009fe.png" data-original-src="https://miro.medium.com/v2/resize:fit:1030/format:webp/1*y1AKmA3_i_ZUcrOqZMCQXw.png"/></div><figcaption class="la lb gj gh gi lc ld bd b be z dk translated">来源:图片由作者创作。</figcaption></figure><p id="5421" class="pw-post-body-paragraph nm nn iq lz b ma og ka no mc oh kd np me oi nr ns mg oj nu nv mi ok nx ny mk ij bi translated">(E)定义变量u:</p><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div class="gh gi pi"><img src="../Images/259b3b689e24ad55d0fc1a5f724ba566.png" data-original-src="https://miro.medium.com/v2/resize:fit:790/format:webp/1*FeCbJh5LbTXOHwF8y7T3nQ.png"/></div><figcaption class="la lb gj gh gi lc ld bd b be z dk translated">来源:图片由作者创作。</figcaption></figure><p id="ac3c" class="pw-post-body-paragraph nm nn iq lz b ma og ka no mc oh kd np me oi nr ns mg oj nu nv mi ok nx ny mk ij bi translated">(F)u值:</p><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div class="gh gi pj"><img src="../Images/3084347021f3fb8ff0f6859fa49c079a.png" data-original-src="https://miro.medium.com/v2/resize:fit:496/format:webp/1*C2L3hcncoxj8-MqGCyuZow.png"/></div><figcaption class="la lb gj gh gi lc ld bd b be z dk translated">来源:图片由作者创作。</figcaption></figure><p id="f55c" class="pw-post-body-paragraph nm nn iq lz b ma og ka no mc oh kd np me oi nr ns mg oj nu nv mi ok nx ny mk ij bi translated">(G)求偏导数:</p><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div class="gh gi pk"><img src="../Images/251cb6b0d7fe1cbcf6a0a1d1ba26dd41.png" data-original-src="https://miro.medium.com/v2/resize:fit:622/format:webp/1*itgFE0yWdGcHFnLeQ6g7SA.png"/></div><figcaption class="la lb gj gh gi lc ld bd b be z dk translated">来源:图片由作者创作。</figcaption></figure><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div class="gh gi pl"><img src="../Images/4f5677f24ea7083f10aaf3fc9dc283b1.png" data-original-src="https://miro.medium.com/v2/resize:fit:810/format:webp/1*b4xvulTx1qZSOfhSSCV03Q.png"/></div><figcaption class="la lb gj gh gi lc ld bd b be z dk translated">来源:图片由作者创作。</figcaption></figure><p id="e2a8" class="pw-post-body-paragraph nm nn iq lz b ma og ka no mc oh kd np me oi nr ns mg oj nu nv mi ok nx ny mk ij bi translated">(H)重写方程式:</p><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div class="gh gi pm"><img src="../Images/1202ce6611033eda094e478d8d92ea43.png" data-original-src="https://miro.medium.com/v2/resize:fit:798/format:webp/1*JAR0mt64_zUWB_JyQ5t73A.png"/></div><figcaption class="la lb gj gh gi lc ld bd b be z dk translated">来源:图片由作者创作。</figcaption></figure><p id="5069" class="pw-post-body-paragraph nm nn iq lz b ma og ka no mc oh kd np me oi nr ns mg oj nu nv mi ok nx ny mk ij bi translated">(I)合并所有计算的数据:</p><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div class="gh gi pn"><img src="../Images/25baf396f726aa8ddb114a5e5690136f.png" data-original-src="https://miro.medium.com/v2/resize:fit:986/format:webp/1*sBJDri9lwDo3YRynTPRmQA.png"/></div><figcaption class="la lb gj gh gi lc ld bd b be z dk translated">来源:图片由作者创作。</figcaption></figure><p id="ae65" class="pw-post-body-paragraph nm nn iq lz b ma og ka no mc oh kd np me oi nr ns mg oj nu nv mi ok nx ny mk ij bi translated">(J)重复相同的过程推导J(θ0，θ1) w.r.t θ1:</p><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div class="gh gi po"><img src="../Images/70fc5ded996c73a20437533dcabe8e15.png" data-original-src="https://miro.medium.com/v2/resize:fit:1124/format:webp/1*tTyLwNtmXfWY_gBOHt9kWg.png"/></div><figcaption class="la lb gj gh gi lc ld bd b be z dk translated">来源:图片由作者创作。</figcaption></figure><p id="2ce5" class="pw-post-body-paragraph nm nn iq lz b ma og ka no mc oh kd np me oi nr ns mg oj nu nv mi ok nx ny mk ij bi translated">简化计算:</p><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div class="gh gi pp"><img src="../Images/421c0a2775d3e517d9973691d1883a8c.png" data-original-src="https://miro.medium.com/v2/resize:fit:802/format:webp/1*CNYpAlhuSI2wCbXnaz62Vg.png"/></div><figcaption class="la lb gj gh gi lc ld bd b be z dk translated">来源:图片由作者创作。</figcaption></figure><p id="0c5d" class="pw-post-body-paragraph nm nn iq lz b ma og ka no mc oh kd np me oi nr ns mg oj nu nv mi ok nx ny mk ij bi translated">(L)合并所有计算数据:</p><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div class="gh gi pq"><img src="../Images/a0d67621e36538fc1ffbae6becc5a8e5.png" data-original-src="https://miro.medium.com/v2/resize:fit:984/format:webp/1*dNBckXg28HQ1MsQicWr8EA.png"/></div><figcaption class="la lb gj gh gi lc ld bd b be z dk translated">来源:图片由作者创作。</figcaption></figure></div><div class="ab cl mu mv hu mw" role="separator"><span class="mx bw bk my mz na"/><span class="mx bw bk my mz na"/><span class="mx bw bk my mz"/></div><div class="ij ik il im in"><h1 id="0189" class="lf lg iq bd lh li oa lk ll lm ob lo lp kf oc kg lr ki od kj lt kl oe km lv lw bi translated">半均方误差:</h1><p id="4c50" class="pw-post-body-paragraph nm nn iq lz b ma mb ka no mc md kd np me nq nr ns mg nt nu nv mi nw nx ny mk ij bi translated">我们将我们的MSE成本函数乘以1/2，这样当我们求导时，2s就抵消了。将成本函数乘以一个标量不会影响最小值的位置，因此我们可以摆脱这一点。</p><h2 id="ebc2" class="nb lg iq bd lh nc nd dn ll ne nf dp lp me ng nh lr mg ni nj lt mi nk nl lv iw bi translated">决赛:</h2><p id="bb2d" class="pw-post-body-paragraph nm nn iq lz b ma mb ka no mc md kd np me nq nr ns mg nt nu nv mi nw nx ny mk ij bi translated">(A)成本函数:一半均方误差:</p><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div class="gh gi pr"><img src="../Images/bae3f72d9043f4732af12b8e1217fbca.png" data-original-src="https://miro.medium.com/v2/resize:fit:736/format:webp/1*An36RjYYRBw_ka5IXsrvQw.png"/></div><figcaption class="la lb gj gh gi lc ld bd b be z dk translated">来源:图片由作者创作。</figcaption></figure><p id="bf70" class="pw-post-body-paragraph nm nn iq lz b ma og ka no mc oh kd np me oi nr ns mg oj nu nv mi ok nx ny mk ij bi translated">目标:</p><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div class="gh gi oy"><img src="../Images/0a3322919ae1639dfed39807d5768ce2.png" data-original-src="https://miro.medium.com/v2/resize:fit:358/format:webp/1*kvUfMMAAEKNS_0LEMmHX-w.png"/></div><figcaption class="la lb gj gh gi lc ld bd b be z dk translated">来源:图片由作者创作。</figcaption></figure><p id="dbe2" class="pw-post-body-paragraph nm nn iq lz b ma og ka no mc oh kd np me oi nr ns mg oj nu nv mi ok nx ny mk ij bi translated">(C)更新规则:</p><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div class="gh gi ps"><img src="../Images/3b9eef79c7354caa9fdb195d86cb2d10.png" data-original-src="https://miro.medium.com/v2/resize:fit:738/format:webp/1*uN0FQKxxc20EBA0tufFcFQ.png"/></div><figcaption class="la lb gj gh gi lc ld bd b be z dk translated">来源:图片由作者创作。</figcaption></figure><p id="869d" class="pw-post-body-paragraph nm nn iq lz b ma og ka no mc oh kd np me oi nr ns mg oj nu nv mi ok nx ny mk ij bi translated">衍生产品:</p><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div class="gh gi pt"><img src="../Images/311a2f954deb905db30773dcb0c07a14.png" data-original-src="https://miro.medium.com/v2/resize:fit:860/format:webp/1*ObYSHZR04km6J41XvYh2cw.png"/></div><figcaption class="la lb gj gh gi lc ld bd b be z dk translated">来源:图片由作者创作。</figcaption></figure><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div class="gh gi pu"><img src="../Images/bc812f5b40156cbfbe4972940eba2685.png" data-original-src="https://miro.medium.com/v2/resize:fit:970/format:webp/1*SBzLstZTNxMCWykk409suQ.png"/></div><figcaption class="la lb gj gh gi lc ld bd b be z dk translated">来源:图片由作者创作。</figcaption></figure><p id="4b31" class="pw-post-body-paragraph nm nn iq lz b ma og ka no mc oh kd np me oi nr ns mg oj nu nv mi ok nx ny mk ij bi translated"><strong class="lz ja">原来如此，原来如此。我们终于成功了！</strong></p><h1 id="a391" class="lf lg iq bd lh li lj lk ll lm ln lo lp kf lq kg lr ki ls kj lt kl lu km lv lw bi translated">结论:</h1><p id="d450" class="pw-post-body-paragraph nm nn iq lz b ma mb ka no mc md kd np me nq nr ns mg nt nu nv mi nw nx ny mk ij bi translated">我们将在机器学习算法的各种应用中使用相同的方法。但那时我们不会深入讨论这个问题，我们只是使用最终的公式。但知道它是如何推导出来的总是好的！</p><h2 id="593d" class="nb lg iq bd lh nc nd dn ll ne nf dp lp me ng nh lr mg ni nj lt mi nk nl lv iw bi translated">最终配方:</h2><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div class="ab gu cl nz"><img src="../Images/1706dd8380821252b70f8ea3197c9c51.png" data-original-src="https://miro.medium.com/v2/format:webp/1*TKwMAQnyj_CJgZeT1dgg2g.png"/></div><figcaption class="la lb gj gh gi lc ld bd b be z dk translated">梯度下降公式</figcaption></figure></div><div class="ab cl mu mv hu mw" role="separator"><span class="mx bw bk my mz na"/><span class="mx bw bk my mz na"/><span class="mx bw bk my mz"/></div><div class="ij ik il im in"><p id="f29f" class="pw-post-body-paragraph nm nn iq lz b ma og ka no mc oh kd np me oi nr ns mg oj nu nv mi ok nx ny mk ij bi translated"><strong class="lz ja">你现在明白这个概念了吗？请写回信让我知道。如果你喜欢这篇文章，然后点击拍手图标。</strong></p><p id="4a37" class="pw-post-body-paragraph nm nn iq lz b ma og ka no mc oh kd np me oi nr ns mg oj nu nv mi ok nx ny mk ij bi translated"><strong class="lz ja"> <em class="oo">如果您有任何其他困惑，请随时联系我。</em></strong><a class="ae le" href="http://shuklapratik22@gmail.com" rel="noopener ugc nofollow" target="_blank"><strong class="lz ja">shuklapratik22@gmail.com</strong></a></p></div></div>    
</body>
</html>