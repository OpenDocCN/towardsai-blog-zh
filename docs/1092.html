<html>
<head>
<title>Imbalanced-learn: Handling imbalanced class problem</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">不平衡学习:处理不平衡的课堂问题</h1>
<blockquote>原文：<a href="https://pub.towardsai.net/imbalanced-learn-handling-imbalanced-class-problem-40aa3cb6525b?source=collection_archive---------2-----------------------#2020-10-28">https://pub.towardsai.net/imbalanced-learn-handling-imbalanced-class-problem-40aa3cb6525b?source=collection_archive---------2-----------------------#2020-10-28</a></blockquote><div><div class="fc ii ij ik il im"/><div class="in io ip iq ir"><h2 id="604c" class="is it iu bd b dl iv iw ix iy iz ja dk jb translated" aria-label="kicker paragraph"><a class="ae ep" href="https://towardsai.net/p/category/data-science" rel="noopener ugc nofollow" target="_blank">数据科学</a>，<a class="ae ep" href="https://towardsai.net/p/category/machine-learning" rel="noopener ugc nofollow" target="_blank">机器学习</a></h2><div class=""/><div class=""><h2 id="9a35" class="pw-subtitle-paragraph ka jd iu bd b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr dk translated">使用不平衡学习处理不平衡数据的实践指南</h2></div><figure class="kt ku kv kw gu kx gi gj paragraph-image"><div role="button" tabindex="0" class="ky kz di la bf lb"><div class="gi gj ks"><img src="../Images/d1a672a93dfdc8c8ed84792b0df2649d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*m41LugvMfs9RwpxH.png"/></div></div><figcaption class="le lf gk gi gj lg lh bd b be z dk translated">来源:<a class="ae li" href="https://www.kdnuggets.com/2020/01/top-tweets-jan22-28.html" rel="noopener ugc nofollow" target="_blank"> KDNuggets </a></figcaption></figure></div><div class="ab cl lj lk hy ll" role="separator"><span class="lm bw bk ln lo lp"/><span class="lm bw bk ln lo lp"/><span class="lm bw bk ln lo"/></div><div class="in io ip iq ir"><p id="3f81" class="pw-post-body-paragraph lq lr iu ls b lt lu ke lv lw lx kh ly lz ma mb mc md me mf mg mh mi mj mk ml in bi translated">在之前的文章<a class="ae li" href="https://medium.com/towards-artificial-intelligence/how-to-handle-imbalanced-data-in-machine-learning-9fe1334e9dff" rel="noopener">这里</a>中，我们已经介绍了处理不平衡数据的不同方法。</p><p id="b367" class="pw-post-body-paragraph lq lr iu ls b lt lu ke lv lw lx kh ly lz ma mb mc md me mf mg mh mi mj mk ml in bi translated">在本文中，让我们试着了解如何使用<code class="fe mm mn mo mp b">imbalanced-learn</code>库来处理不平衡的类问题。我们将利用<code class="fe mm mn mo mp b">Pycaret</code>库和UCI默认的信用卡客户数据集，它也内置在PyCaret中。让我们开始吧。</p><h1 id="42b0" class="mq mr iu bd ms mt mu mv mw mx my mz na kj nb kk nc km nd kn ne kp nf kq ng nh bi translated">不平衡学习</h1><p id="51a5" class="pw-post-body-paragraph lq lr iu ls b lt ni ke lv lw nj kh ly lz nk mb mc md nl mf mg mh nm mj mk ml in bi translated"><code class="fe mm mn mo mp b">Imbalanced-learn</code>是一个python包，提供了多种重采样技术来处理分类任务中经常遇到的类不平衡问题。请注意，不平衡学习与<a class="ae li" href="http://scikit-learn.org/stable/" rel="noopener ugc nofollow" target="_blank"> scikit-learn </a>兼容，也是<a class="ae li" href="https://github.com/scikit-learn-contrib" rel="noopener ugc nofollow" target="_blank"> scikit-learn-contrib </a>项目的一部分。</p><blockquote class="nn no np"><p id="a7aa" class="lq lr nq ls b lt lu ke lv lw lx kh ly nr ma mb mc ns me mf mg nt mi mj mk ml in bi translated">PyCaret 是一个低代码库，可以用来执行复杂的机器学习任务，只需要几行代码。PyCaret本质上是几个机器学习库和框架的Python包装器，比如<code class="fe mm mn mo mp b">scikit-learn</code>、<code class="fe mm mn mo mp b">XGBoost</code>、<code class="fe mm mn mo mp b">Microsoft LightGBM</code>、<code class="fe mm mn mo mp b">spaCy</code>等等。</p></blockquote><p id="37b1" class="pw-post-body-paragraph lq lr iu ls b lt lu ke lv lw lx kh ly lz ma mb mc md me mf mg mh mi mj mk ml in bi translated"><code class="fe mm mn mo mp b">imbalanced-learn</code>实现的重采样技术可以大致分为以下4大类。还列出了在每种方法下实现的所有方法的列表。</p><ul class=""><li id="83a0" class="nu nv iu ls b lt lu lw lx lz nw md nx mh ny ml nz oa ob oc bi translated">对大多数类进行欠采样</li><li id="725a" class="nu nv iu ls b lt od lw oe lz of md og mh oh ml nz oa ob oc bi translated">对少数民族阶层进行过度采样</li><li id="8c68" class="nu nv iu ls b lt od lw oe lz of md og mh oh ml nz oa ob oc bi translated">结合过采样和欠采样</li><li id="47d6" class="nu nv iu ls b lt od lw oe lz of md og mh oh ml nz oa ob oc bi translated">系综平衡集</li></ul><figure class="kt ku kv kw gu kx gi gj paragraph-image"><div role="button" tabindex="0" class="ky kz di la bf lb"><div class="gi gj oi"><img src="../Images/a02b833efe4b44cd7a1be9858e529009.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*asUmUFRQ7tr3c3xA1wSW3A.png"/></div></div></figure><h1 id="afb4" class="mq mr iu bd ms mt mu mv mw mx my mz na kj nb kk nc km nd kn ne kp nf kq ng nh bi translated">装置</h1><pre class="kt ku kv kw gu oj mp ok ol aw om bi"><span id="0a8f" class="on mr iu mp b gz oo op l oq or">!pip install -U imbalanced-learn</span></pre><p id="cea0" class="pw-post-body-paragraph lq lr iu ls b lt lu ke lv lw lx kh ly lz ma mb mc md me mf mg mh mi mj mk ml in bi translated">或者</p><pre class="kt ku kv kw gu oj mp ok ol aw om bi"><span id="c86a" class="on mr iu mp b gz oo op l oq or">!git clone <a class="ae li" href="https://github.com/scikit-learn-contrib/imbalanced-learn.git" rel="noopener ugc nofollow" target="_blank">https://github.com/scikit-learn-contrib/imbalanced-learn.git</a><br/>%cd imbalanced-learn<br/>!pip install .</span></pre><h1 id="c236" class="mq mr iu bd ms mt mu mv mw mx my mz na kj nb kk nc km nd kn ne kp nf kq ng nh bi translated">无重采样的基线模型</h1><p id="5632" class="pw-post-body-paragraph lq lr iu ls b lt ni ke lv lw nj kh ly lz nk mb mc md nl mf mg mh nm mj mk ml in bi translated">我们先导入Pycaret和信用卡客户数据的默认值。</p><pre class="kt ku kv kw gu oj mp ok ol aw om bi"><span id="462f" class="on mr iu mp b gz oo op l oq or">from pycaret.datasets import get_data<br/>dataset = get_data(‘credit’)</span></pre><p id="5469" class="pw-post-body-paragraph lq lr iu ls b lt lu ke lv lw lx kh ly lz ma mb mc md me mf mg mh mi mj mk ml in bi translated">正如你在下面看到的，这个信用违约数据集是不平衡的，负类(类0)占主导地位。</p><figure class="kt ku kv kw gu kx gi gj paragraph-image"><div class="gi gj os"><img src="../Images/08336f4114e0fa6a25c2dff31aa8a57d.png" data-original-src="https://miro.medium.com/v2/resize:fit:862/format:webp/1*sVGsHX8VocRxLRDpCa3fuA.png"/></div><figcaption class="le lf gk gi gj lg lh bd b be z dk translated">不平衡的阶级分布</figcaption></figure><p id="76d2" class="pw-post-body-paragraph lq lr iu ls b lt lu ke lv lw lx kh ly lz ma mb mc md me mf mg mh mi mj mk ml in bi translated">让我们看看没有应用任何重新采样(过采样或欠采样)技术的基线分数。</p><pre class="kt ku kv kw gu oj mp ok ol aw om bi"><span id="9bd9" class="on mr iu mp b gz oo op l oq or">from pycaret.classification import *<br/>clf = setup(data=dataset, target = ‘default’, session_id=123)</span></pre><p id="60b6" class="pw-post-body-paragraph lq lr iu ls b lt lu ke lv lw lx kh ly lz ma mb mc md me mf mg mh mi mj mk ml in bi translated">为简单起见，我将只查看准确性、AUC和F1分数。但是，您可以根据需要查看其他指标。没有任何重采样，线性判别分析给出了最好的准确度和F1值。极端梯度增强给出了最好的AUC分数。现在，让我们应用重新采样技术并比较结果。</p><figure class="kt ku kv kw gu kx gi gj paragraph-image"><div class="gi gj ot"><img src="../Images/5258f9e7da9c1b2d70f5ed5dd6d8b508.png" data-original-src="https://miro.medium.com/v2/resize:fit:1296/format:webp/1*BeQ1YMtgsqlZKb7POnJZRA.png"/></div><figcaption class="le lf gk gi gj lg lh bd b be z dk translated">没有重新取样的基线分数</figcaption></figure><h1 id="2342" class="mq mr iu bd ms mt mu mv mw mx my mz na kj nb kk nc km nd kn ne kp nf kq ng nh bi translated">1.过采样</h1><p id="b573" class="pw-post-body-paragraph lq lr iu ls b lt ni ke lv lw nj kh ly lz nk mb mc md nl mf mg mh nm mj mk ml in bi translated">这有助于增加数据集中少数类示例的数量。过采样的主要优点之一是在处理过程中，多数类和少数类都不会丢失信息。容易过拟合。</p><h2 id="dcca" class="on mr iu bd ms ou ov dn mw ow ox dp na lz oy oz nc md pa pb ne mh pc pd ng ja bi translated">a)随机过采样</h2><p id="8733" class="pw-post-body-paragraph lq lr iu ls b lt ni ke lv lw nj kh ly lz nk mb mc md nl mf mg mh nm mj mk ml in bi translated">它在代表性不足的班级(少数班级)中生成新的样本。</p><pre class="kt ku kv kw gu oj mp ok ol aw om bi"><span id="d34f" class="on mr iu mp b gz oo op l oq or">X = dataset.drop([‘default’], axis=1)<br/>y = dataset[‘default’]</span><span id="c165" class="on mr iu mp b gz pe op l oq or">from imblearn.over_sampling import RandomOverSampler<br/>ros = RandomOverSampler(random_state=123)</span><span id="ec1b" class="on mr iu mp b gz pe op l oq or">X_resampled, y_resampled = ros.fit_resample(X, y)</span></pre><figure class="kt ku kv kw gu kx gi gj paragraph-image"><div class="gi gj pf"><img src="../Images/2a0fe383cb82871afc112521841b6afc.png" data-original-src="https://miro.medium.com/v2/resize:fit:806/format:webp/1*6tVLFOgIIh1C9Y-CfzXJkw.png"/></div><figcaption class="le lf gk gi gj lg lh bd b be z dk translated">应用随机过采样后的平衡类</figcaption></figure><pre class="kt ku kv kw gu oj mp ok ol aw om bi"><span id="06ac" class="on mr iu mp b gz oo op l oq or">ros_dataset = X_resampled<br/>ros_dataset[‘default’] = y_resampled</span><span id="ebf2" class="on mr iu mp b gz pe op l oq or">from pycaret.classification import *</span><span id="66a8" class="on mr iu mp b gz pe op l oq or">clf = setup(data=ros_dataset, target = ‘default’, session_id=123)</span></pre><p id="cff0" class="pw-post-body-paragraph lq lr iu ls b lt lu ke lv lw lx kh ly lz ma mb mc md me mf mg mh mi mj mk ml in bi translated">从下面的结果可以看出，在应用随机过采样技术后，分数有了很大的提高。准确性提高到91%，AUC提高到97%，F1评分也提高了。Extra Trees分类器以几乎所有评估指标的最高分领先图表。</p><figure class="kt ku kv kw gu kx gi gj paragraph-image"><div class="gi gj pg"><img src="../Images/5aea16fa8811f7949e888f450eee1121.png" data-original-src="https://miro.medium.com/v2/resize:fit:1302/format:webp/1*4xJtuh1jdXPqAJCvok5HBQ.png"/></div><figcaption class="le lf gk gi gj lg lh bd b be z dk translated">应用随机过采样后的评估分数</figcaption></figure><blockquote class="nn no np"><p id="7e02" class="lq lr nq ls b lt lu ke lv lw lx kh ly nr ma mb mc ns me mf mg nt mi mj mk ml in bi translated">上面讨论的随机过采样的大部分代码适用于其余的方法。因此，接下来，我将只提供如何使用各自技术的细节以及重新采样后的结果。然而，所有方法的完整代码都在文章末尾给出。</p></blockquote><h2 id="7330" class="on mr iu bd ms ou ov dn mw ow ox dp na lz oy oz nc md pa pb ne mh pc pd ng ja bi translated">b) SMOTE &amp; ADASYN</h2><p id="20fa" class="pw-post-body-paragraph lq lr iu ls b lt ni ke lv lw nj kh ly lz nk mb mc md nl mf mg mh nm mj mk ml in bi translated">这两种方法通过插值生成新的样本。SMOTE代表合成少数过采样技术，ADASYN代表自适应合成(ADASYN)算法。</p><pre class="kt ku kv kw gu oj mp ok ol aw om bi"><span id="dcb5" class="on mr iu mp b gz oo op l oq or">from imblearn.over_sampling import SMOTE, ADASYN</span><span id="76c7" class="on mr iu mp b gz pe op l oq or">X_resampled, y_resampled = SMOTE(random_state=123).fit_resample(X, y)</span></pre><p id="4a89" class="pw-post-body-paragraph lq lr iu ls b lt lu ke lv lw lx kh ly lz ma mb mc md me mf mg mh mi mj mk ml in bi translated">根据下面的结果，当与准确性、AUC和F1得分指标进行比较时，SMOTE和ADASYN的过采样在该数据集上表现不佳。然而，精确度和召回分数的表现比随机过采样稍好。</p><figure class="kt ku kv kw gu kx gi gj paragraph-image"><div class="gi gj pg"><img src="../Images/d5b47ca76bdd67fb3b77793c179da0a7.png" data-original-src="https://miro.medium.com/v2/resize:fit:1302/format:webp/1*6GFLfq81QnKcK7YbfA6ftw.png"/></div><figcaption class="le lf gk gi gj lg lh bd b be z dk translated">应用SMOTE过采样后的评估分数</figcaption></figure><figure class="kt ku kv kw gu kx gi gj paragraph-image"><div class="gi gj ph"><img src="../Images/940189c0c6f13d2684aa85d0d968c257.png" data-original-src="https://miro.medium.com/v2/resize:fit:1304/format:webp/1*hPvu2henMUbLSfkEoSODpQ.png"/></div><figcaption class="le lf gk gi gj lg lh bd b be z dk translated">应用ADASYN过采样后的评估分数</figcaption></figure><h1 id="83b5" class="mq mr iu bd ms mt mu mv mw mx my mz na kj nb kk nc km nd kn ne kp nf kq ng nh bi translated">2.欠采样</h1><h2 id="9384" class="on mr iu bd ms ou ov dn mw ow ox dp na lz oy oz nc md pa pb ne mh pc pd ng ja bi translated">a)随机欠采样</h2><p id="7c5f" class="pw-post-body-paragraph lq lr iu ls b lt ni ke lv lw nj kh ly lz nk mb mc md nl mf mg mh nm mj mk ml in bi translated">这是通过为目标类随机选择数据子集来实现的。</p><pre class="kt ku kv kw gu oj mp ok ol aw om bi"><span id="3d91" class="on mr iu mp b gz oo op l oq or">from imblearn.under_sampling import RandomUnderSampler</span><span id="10bb" class="on mr iu mp b gz pe op l oq or">X_resampled, y_resampled = RandomUnderSampler(random_state=123).fit_resample(X, y)</span></pre><p id="dfd8" class="pw-post-body-paragraph lq lr iu ls b lt lu ke lv lw lx kh ly lz ma mb mc md me mf mg mh mi mj mk ml in bi translated">在欠采样技术中，因为只选择了数据子集，所以会有信息丢失。因此，与过采样相比，评估结果很可能会更低。下面的结果证实了这一点。</p><figure class="kt ku kv kw gu kx gi gj paragraph-image"><div role="button" tabindex="0" class="ky kz di la bf lb"><div class="gi gj pi"><img src="../Images/733121bc6719a13b6b7b32656a20867c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1310/format:webp/1*FA3ey3UJ_aHZRVUITP6ORQ.png"/></div></div><figcaption class="le lf gk gi gj lg lh bd b be z dk translated">随机欠采样的评估结果</figcaption></figure><h1 id="f719" class="mq mr iu bd ms mt mu mv mw mx my mz na kj nb kk nc km nd kn ne kp nf kq ng nh bi translated">3.过采样之后是欠采样</h1><p id="f4ed" class="pw-post-body-paragraph lq lr iu ls b lt ni ke lv lw nj kh ly lz nk mb mc md nl mf mg mh nm mj mk ml in bi translated">过采样方法SMOTE可以通过在边缘离群点和内嵌点之间插入新点来产生噪声样本。这个问题可以通过清理过采样产生的空间来解决。这是通过过采样和欠采样来实现的。</p><h2 id="e4aa" class="on mr iu bd ms ou ov dn mw ow ox dp na lz oy oz nc md pa pb ne mh pc pd ng ja bi translated">a) SMOTEENN</h2><p id="c93d" class="pw-post-body-paragraph lq lr iu ls b lt ni ke lv lw nj kh ly lz nk mb mc md nl mf mg mh nm mj mk ml in bi translated">SMOTEENN是SMOTE(过采样)，后面是ENN(欠采样)</p><pre class="kt ku kv kw gu oj mp ok ol aw om bi"><span id="b0cf" class="on mr iu mp b gz oo op l oq or">from imblearn.combine import SMOTEENN</span><span id="dea3" class="on mr iu mp b gz pe op l oq or">X_resampled, y_resampled = SMOTEENN(random_state=123).fit_resample(X, y)</span></pre><p id="588c" class="pw-post-body-paragraph lq lr iu ls b lt lu ke lv lw lx kh ly lz ma mb mc md me mf mg mh mi mj mk ml in bi translated">过采样后的欠采样技术也没有给出比随机过采样更好的结果。然而，精确度和召回分数有些稳定。</p><figure class="kt ku kv kw gu kx gi gj paragraph-image"><div class="gi gj pj"><img src="../Images/ef100db20383a6c07dd0cac6f7cb1522.png" data-original-src="https://miro.medium.com/v2/resize:fit:1288/format:webp/1*IZXzniRSr7turicIDu7WpQ.png"/></div><figcaption class="le lf gk gi gj lg lh bd b be z dk translated">应用SMOTEENN技术后的评估分数</figcaption></figure><h1 id="cd4c" class="mq mr iu bd ms mt mu mv mw mx my mz na kj nb kk nc km nd kn ne kp nf kq ng nh bi translated">4.系综平衡集</h1><h2 id="6df6" class="on mr iu bd ms ou ov dn mw ow ox dp na lz oy oz nc md pa pb ne mh pc pd ng ja bi translated">a)平衡随机森林分类器</h2><p id="c6bc" class="pw-post-body-paragraph lq lr iu ls b lt ni ke lv lw nj kh ly lz nk mb mc md nl mf mg mh nm mj mk ml in bi translated">在这种集成方法中，森林中的每棵树都将被提供一个平衡的引导样本。这个类提供了Sklearn的<code class="fe mm mn mo mp b">RandomForestClassifier</code>的所有功能。</p><pre class="kt ku kv kw gu oj mp ok ol aw om bi"><span id="ef84" class="on mr iu mp b gz oo op l oq or">from sklearn.model_selection import train_test_split<br/>from sklearn.metrics import balanced_accuracy_score, classification_report<br/>from imblearn.ensemble import BalancedRandomForestClassifier</span><span id="3cd8" class="on mr iu mp b gz pe op l oq or">X = dataset.drop([‘default’], axis=1)<br/>y = dataset[‘default’]</span><span id="b812" class="on mr iu mp b gz pe op l oq or">X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=0)</span><span id="fac6" class="on mr iu mp b gz pe op l oq or">brf = BalancedRandomForestClassifier(n_estimators=100, random_state=123)</span><span id="5358" class="on mr iu mp b gz pe op l oq or">brf.fit(X_train, y_train)</span><span id="e121" class="on mr iu mp b gz pe op l oq or">y_pred = brf.predict(X_test)<br/>print(balanced_accuracy_score(y_test, y_pred))</span></pre><h1 id="9e09" class="mq mr iu bd ms mt mu mv mw mx my mz na kj nb kk nc km nd kn ne kp nf kq ng nh bi translated">结论</h1><p id="2462" class="pw-post-body-paragraph lq lr iu ls b lt ni ke lv lw nj kh ly lz nk mb mc md nl mf mg mh nm mj mk ml in bi translated">对于这个默认的信用卡客户数据集，随机过采样技术在准确性、AUC等方面给出了最好的分数。因此，我们可以考虑额外的决策树分类器或随机森林分类器进行进一步的微调和集成。</p><p id="8454" class="pw-post-body-paragraph lq lr iu ls b lt lu ke lv lw lx kh ly lz ma mb mc md me mf mg mh mi mj mk ml in bi translated">在本文中，您已经了解了如何使用<code class="fe mm mn mo mp b">imbalanced-learn</code>库来处理不平衡数据。下次当你遇到不平衡的数据时，你可以试试这些技巧。</p><p id="0750" class="pw-post-body-paragraph lq lr iu ls b lt lu ke lv lw lx kh ly lz ma mb mc md me mf mg mh mi mj mk ml in bi translated"><em class="nq">阅读更多关于Python和数据科学的此类有趣文章，</em> <a class="ae li" href="https://pythonsimplified.com/" rel="noopener ugc nofollow" target="_blank"> <strong class="ls je"> <em class="nq">订阅</em> </strong> </a> <em class="nq">到我的博客</em><a class="ae li" href="http://www.pythonsimplified.com/" rel="noopener ugc nofollow" target="_blank"><strong class="ls je"><em class="nq">www.pythonsimplified.com</em></strong></a><strong class="ls je"><em class="nq">。</em> </strong>你也可以通过<a class="ae li" href="https://www.linkedin.com/in/chetanambi/" rel="noopener ugc nofollow" target="_blank"> <strong class="ls je"> LinkedIn </strong> </a>联系我。</p><h1 id="cb09" class="mq mr iu bd ms mt mu mv mw mx my mz na kj nb kk nc km nd kn ne kp nf kq ng nh bi translated"><strong class="ak">完整代码</strong></h1><figure class="kt ku kv kw gu kx"><div class="bz fq l di"><div class="pk pl l"/></div></figure></div><div class="ab cl lj lk hy ll" role="separator"><span class="lm bw bk ln lo lp"/><span class="lm bw bk ln lo lp"/><span class="lm bw bk ln lo"/></div><div class="in io ip iq ir"><h1 id="f767" class="mq mr iu bd ms mt pm mv mw mx pn mz na kj po kk nc km pp kn ne kp pq kq ng nh bi translated">参考</h1><div class="pr ps gq gs pt pu"><a href="https://imbalanced-learn.readthedocs.io/en/stable/" rel="noopener  ugc nofollow" target="_blank"><div class="pv ab fp"><div class="pw ab px cl cj py"><h2 class="bd je gz z fq pz fs ft qa fv fx jd bi translated">欢迎来到不平衡学习文档！-不平衡-学习0.5.0文档</h2><div class="qb l"><h3 class="bd b gz z fq pz fs ft qa fv fx dk translated">安装、测试和贡献包的信息。主要文档。这包含了深入的…</h3></div><div class="qc l"><p class="bd b dl z fq pz fs ft qa fv fx dk translated">不平衡-learn.readthedocs.io</p></div></div></div></a></div></div></div>    
</body>
</html>