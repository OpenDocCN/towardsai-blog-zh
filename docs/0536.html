<html>
<head>
<title>Simple Text Summarizer Using Extractive Method</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">使用提取方法的简单文本摘要</h1>
<blockquote>原文：<a href="https://pub.towardsai.net/simple-text-summarizer-using-extractive-method-849b65c2dc5a?source=collection_archive---------1-----------------------#2020-05-30">https://pub.towardsai.net/simple-text-summarizer-using-extractive-method-849b65c2dc5a?source=collection_archive---------1-----------------------#2020-05-30</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><h2 id="9e43" class="io ip iq bd b dl ir is it iu iv iw dk ix translated" aria-label="kicker paragraph"><a class="ae ep" href="https://towardsai.net/p/category/nlp" rel="noopener ugc nofollow" target="_blank">自然语言处理</a></h2><div class=""/><div class=""><h2 id="92bf" class="pw-subtitle-paragraph jw iz iq bd b jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn dk translated">自动对包含最重要句子的文章进行简短总结。</h2></div><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div role="button" tabindex="0" class="ku kv di kw bf kx"><div class="gh gi ko"><img src="../Images/13d336ba74b178b18fea2d83b46ba781.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*TVdi_vS-_Gzp3HAg9Ro80g.png"/></div></div><figcaption class="la lb gj gh gi lc ld bd b be z dk translated">将文章转换为摘要|来源:作者图片</figcaption></figure><blockquote class="le lf lg"><p id="ef43" class="lh li lj lk b ll lm ka ln lo lp kd lq lr ls lt lu lv lw lx ly lz ma mb mc md ij bi translated">你见过像shorts  中的<strong class="lk ja"> <em class="iq">这样的应用程序，它可以将文章或新闻转换成60个字的摘要。是的，这就是我们今天要建造的。在本文中，我们将使用<strong class="lk ja">提取方法</strong>构建一个文本摘要器，它非常容易构建，并且在处理结果时非常可靠。别急，我也来解释一下这个提取的方法是什么？</em></strong></p></blockquote><p id="22a4" class="pw-post-body-paragraph lh li iq lk b ll lm ka ln lo lp kd lq me ls lt lu mf lw lx ly mg ma mb mc md ij bi translated">您可能会发现许多关于<strong class="lk ja"> <em class="lj">文本摘要的文章</em> </strong>，但是这篇文章的独特之处在于它简短的<strong class="lk ja"><em class="lj"/></strong>和<strong class="lk ja"> <em class="lj">对初学者友好的</em> </strong>代码片段的高级描述。</p><p id="87ea" class="pw-post-body-paragraph lh li iq lk b ll lm ka ln lo lp kd lq me ls lt lu mf lw lx ly mg ma mb mc md ij bi translated">因此，文本摘要可以通过两种方式完成</p><ul class=""><li id="961a" class="mh mi iq lk b ll lm lo lp me mj mf mk mg ml md mm mn mo mp bi translated"><strong class="lk ja"> <em class="lj">提取方法</em></strong>——从文章中选择最有可能传达文章信息的<strong class="lk ja"> n </strong>个最重要的句子。这种方法非常容易实现并且对初学者友好。这是本教程选择这种方法的主要原因。</li><li id="877f" class="mh mi iq lk b ll mq lo mr me ms mf mt mg mu md mm mn mo mp bi translated"><strong class="lk ja"> <em class="lj">抽象法</em> </strong> —这种方法使用深度学习的概念，如<strong class="lk ja"> <em class="lj">编解码器</em> </strong>架构、<strong class="lk ja"> LSTM( </strong>长短期记忆<strong class="lk ja"> ) </strong>网络，这些对于初学者来说非常难以理解。这种方法生成文章的全新摘要，并包含甚至在原始文章中不存在的句子。这种方法可能会创造出没有任何意义的句子。</li></ul><p id="cb6b" class="pw-post-body-paragraph lh li iq lk b ll lm ka ln lo lp kd lq me ls lt lu mf lw lx ly mg ma mb mc md ij bi translated">现在，我们清楚了为什么选择提取方法，让我们直接跳到编码部分😎</p><h2 id="07f3" class="mv mw iq bd mx my mz dn na nb nc dp nd me ne nf ng mf nh ni nj mg nk nl nm iw bi translated"><strong class="ak">先决条件:- </strong></h2><p id="486a" class="pw-post-body-paragraph lh li iq lk b ll nn ka ln lo no kd lq me np lt lu mf nq lx ly mg nr mb mc md ij bi translated">我假设你熟悉<strong class="lk ja"> <em class="lj"> python </em> </strong>并且已经在你的系统中安装了<strong class="lk ja"> <em class="lj"> python 3 </em> </strong>。这个教程我用过<strong class="lk ja"> <em class="lj"> jupyter笔记本</em> </strong>。你可以使用你喜欢的<strong class="lk ja"> IDE </strong>。</p><h2 id="ab72" class="mv mw iq bd mx my mz dn na nb nc dp nd me ne nf ng mf nh ni nj mg nk nl nm iw bi translated"><strong class="ak">安装所需的库</strong></h2><p id="70c3" class="pw-post-body-paragraph lh li iq lk b ll nn ka ln lo no kd lq me np lt lu mf nq lx ly mg nr mb mc md ij bi translated">对于这个项目，您需要在python中安装以下包。如果没有安装，可以直接使用<code class="fe ns nt nu nv b">pip install PackageName</code>。<strong class="lk ja"> <em class="lj">抓取</em> </strong>部分是可选的，你也可以跳过它，使用任何你想要摘要的本地文本文件。</p><ul class=""><li id="c7ad" class="mh mi iq lk b ll lm lo lp me mj mf mk mg ml md mm mn mo mp bi translated"><strong class="lk ja"> bs4 </strong> —用于解析Html页面的BeautifulSoup。</li><li id="7d93" class="mh mi iq lk b ll mq lo mr me ms mf mt mg mu md mm mn mo mp bi translated">lxml  —它是用于用python处理Html和xml的包。</li><li id="4c0c" class="mh mi iq lk b ll mq lo mr me ms mf mt mg mu md mm mn mo mp bi translated"><strong class="lk ja"> nltk </strong> —用于执行自然语言处理任务。</li><li id="348a" class="mh mi iq lk b ll mq lo mr me ms mf mt mg mu md mm mn mo mp bi translated"><strong class="lk ja"> urllib </strong> —用于请求网页。</li></ul><h1 id="588d" class="nw mw iq bd mx nx ny nz na oa ob oc nd kf od kg ng ki oe kj nj kl of km nm og bi translated">开始编码吧！</h1><p id="1c2c" class="pw-post-body-paragraph lh li iq lk b ll nn ka ln lo no kd lq me np lt lu mf nq lx ly mg nr mb mc md ij bi translated">在这里，首先我们已经导入了我们将要使用的所有库。<strong class="lk ja"> <em class="lj"> bs4 </em> </strong>和<strong class="lk ja"> <em class="lj"> urllib </em> </strong>将用于文章的抓取。<strong class="lk ja"> <em class="lj"> re </em> </strong>(正则表达式)用于删除文章中不想要的文字。第4行用于安装<strong class="lk ja"> <em class="lj"> nltk( </em> </strong>自然语言工具包<strong class="lk ja"> <em class="lj"> ) </em> </strong>包，这是本教程最重要的包。之后，我们下载了文本处理所需的一些数据，如<strong class="lk ja"> <em class="lj"> punkt </em> </strong>(用于句子分词)和<strong class="lk ja"> <em class="lj">停用词</em> </strong>(如<code class="fe ns nt nu nv b">is,the,of</code>这样不起作用的词)。</p><pre class="kp kq kr ks gt oh nv oi oj aw ok bi"><span id="e1f4" class="mv mw iq nv b gy ol om l on oo"><strong class="nv ja">import</strong> bs4<br/><strong class="nv ja">import</strong> urllib.request as url<br/><strong class="nv ja">import</strong> re<br/>#!pip3 install nltk<br/><strong class="nv ja">import </strong>nltk<br/>nltk.download('punkt')<br/>nltk.download('stopwords')<br/><strong class="nv ja">from</strong> nltk <strong class="nv ja">import</strong> sent_tokenize<br/><strong class="nv ja">from</strong> nltk.corpus <strong class="nv ja">import</strong> stopwords<br/><strong class="nv ja">from</strong> nltk <strong class="nv ja">import</strong> word_tokenize<br/>stop_word = stopwords.words('english')<br/><strong class="nv ja">import</strong> string</span></pre><p id="924d" class="pw-post-body-paragraph lh li iq lk b ll lm ka ln lo lp kd lq me ls lt lu mf lw lx ly mg ma mb mc md ij bi translated">这里，我只是从用户那里获取了文章的URL。</p><pre class="kp kq kr ks gt oh nv oi oj aw ok bi"><span id="33fe" class="mv mw iq nv b gy ol om l on oo">url_name = input("Enter url of the text you want to summerize:")</span></pre><p id="c25b" class="pw-post-body-paragraph lh li iq lk b ll lm ka ln lo lp kd lq me ls lt lu mf lw lx ly mg ma mb mc md ij bi translated">在这段代码中，我们用urllib请求页面源，然后用<strong class="lk ja"><em class="lj">beautiful soup</em></strong>解析该页面，找到段落标签，并将文本添加到<code class="fe ns nt nu nv b">article</code>变量中。</p><pre class="kp kq kr ks gt oh nv oi oj aw ok bi"><span id="92b5" class="mv mw iq nv b gy ol om l on oo">web = url.urlopen(url_name)<br/>page = bs4.BeautifulSoup(web,'html.parser')<br/>elements = page.find_all('p')<br/>article = ''<br/>for i in elements:<br/>    article+= (i.text)<br/>article</span></pre><p id="fe75" class="pw-post-body-paragraph lh li iq lk b ll lm ka ln lo lp kd lq me ls lt lu mf lw lx ly mg ma mb mc md ij bi translated">现在，我们从包含要总结的整篇文章的字符串变量<code class="fe ns nt nu nv b">article</code>中删除所有特殊字符。为此，我们简单地使用了内置的<code class="fe ns nt nu nv b">replace</code>函数，还使用了正则表达式(<strong class="lk ja"> <em class="lj"> re </em> </strong>)来删除数字。</p><pre class="kp kq kr ks gt oh nv oi oj aw ok bi"><span id="7e5a" class="mv mw iq nv b gy ol om l on oo">processed = article.replace(r'^\s+|\s+?$','')<br/>processed = processed.replace('\n',' ')<br/>processed = processed.replace("\\",'')<br/>processed = processed.replace(",",'')<br/>processed = processed.replace('"','')<br/>processed = re.sub(r'\[[0-9]*\]','',processed)<br/>processed</span></pre><p id="3750" class="pw-post-body-paragraph lh li iq lk b ll lm ka ln lo lp kd lq me ls lt lu mf lw lx ly mg ma mb mc md ij bi translated">这里，我们简单地使用了<strong class="lk ja"><em class="lj">【nltk】</em></strong>的<code class="fe ns nt nu nv b">sent_tokenize</code>函数来制作包含文章中每个索引处的句子的列表。</p><pre class="kp kq kr ks gt oh nv oi oj aw ok bi"><span id="f3c8" class="mv mw iq nv b gy ol om l on oo">sentences = sent_tokenize(processed)</span></pre><p id="b8aa" class="pw-post-body-paragraph lh li iq lk b ll lm ka ln lo lp kd lq me ls lt lu mf lw lx ly mg ma mb mc md ij bi translated">之后我们把文章的人物转换成<code class="fe ns nt nu nv b">lowercase</code>。然后我们遍历文章的每个单词，检查它是否不是停用词或任何标点符号(我们已经删除了标点符号，但我们仍然使用它以防万一)。如果这个单词不在其中，我们只需将该单词添加到字典中，然后进一步统计该单词的<strong class="lk ja"> <em class="lj">频率</em> </strong>。</p><p id="4184" class="pw-post-body-paragraph lh li iq lk b ll lm ka ln lo lp kd lq me ls lt lu mf lw lx ly mg ma mb mc md ij bi translated">在截图中，你可以看到字典中包含了文章中的每个单词及其计数(单词出现的频率越高，越重要)。现在你知道为什么我们去掉了像<code class="fe ns nt nu nv b">of the for</code>这样的停用词，否则它们会出现在最上面。</p><pre class="kp kq kr ks gt oh nv oi oj aw ok bi"><span id="de9f" class="mv mw iq nv b gy ol om l on oo">frequency = {}<br/>processed1 = processed.lower()<br/>for word in word_tokenize(processed1):<br/>    if word not in stop_word and word not in string.punctuation:<br/>        if word not in frequency.keys():<br/>            frequency[word]=1<br/>        else:<br/>            frequency[word]+=1<br/>frequency</span></pre><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div class="gh gi op"><img src="../Images/6b673a26200a772ba65a8c91b295e1ef.png" data-original-src="https://miro.medium.com/v2/resize:fit:602/format:webp/1*Sw3oEthOgrf0-w6H4y6SEA.png"/></div><figcaption class="la lb gj gh gi lc ld bd b be z dk translated">包含文章中每个单词及其出现频率的词典</figcaption></figure><p id="4aeb" class="pw-post-body-paragraph lh li iq lk b ll lm ka ln lo lp kd lq me ls lt lu mf lw lx ly mg ma mb mc md ij bi translated">这里，我们通过简单地将每个单词的<strong class="lk ja">频率</strong>除以其中的<strong class="lk ja">最大频率</strong>来计算字典中每个单词的重要性。在截图中，你可以清楚地看到单词<code class="fe ns nt nu nv b">language</code>的重要性排在最前面，因为它的最大频率是<strong class="lk ja"> 22 </strong>。</p><pre class="kp kq kr ks gt oh nv oi oj aw ok bi"><span id="4660" class="mv mw iq nv b gy ol om l on oo">max_fre = max(frequency.values())<br/>for word in frequency.keys():<br/>    frequency[word]=(frequency[word]/max_fre)<br/>frequency</span></pre><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div class="gh gi oq"><img src="../Images/6123f0425afd434e16f7fa5e4b9c55d6.png" data-original-src="https://miro.medium.com/v2/resize:fit:852/format:webp/1*6yTj6QITSzbn5CqZrtL8sw.png"/></div><figcaption class="la lb gj gh gi lc ld bd b be z dk translated">文章中每个单词的重要性</figcaption></figure><p id="60e8" class="pw-post-body-paragraph lh li iq lk b ll lm ka ln lo lp kd lq me ls lt lu mf lw lx ly mg ma mb mc md ij bi translated">做完这些，现在我们要计算文章每一句话的重要性。为了做到这一点，我们遍历文章的每一个句子，然后为句子中的每个单词加上该单词的个人得分<strong class="lk ja">或重要性<strong class="lk ja">来给出该特定句子的最终得分。</strong></strong></p><p id="d747" class="pw-post-body-paragraph lh li iq lk b ll lm ka ln lo lp kd lq me ls lt lu mf lw lx ly mg ma mb mc md ij bi translated">在截图中，你可以清楚地看到，现在每个句子都有一些分数，代表那个句子有多重要。</p><pre class="kp kq kr ks gt oh nv oi oj aw ok bi"><span id="5662" class="mv mw iq nv b gy ol om l on oo">sentence_score = {}<br/>for sent in sentences:<br/>    for word in word_tokenize(sent):<br/>        if word in frequency.keys():<br/>            if len(sent.split(' '))&lt;30:<br/>                if sent not in sentence_score.keys():<br/>                    sentence_score[sent] = frequency[word]<br/>                else:<br/>                    sentence_score[sent]+=frequency[word]<br/>sentence_score</span></pre><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div role="button" tabindex="0" class="ku kv di kw bf kx"><div class="gh gi or"><img src="../Images/0a2d998afa775085711dc073a292c9f1.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*LzbU0FJ8vme8wOuXT59I2Q.png"/></div></div><figcaption class="la lb gj gh gi lc ld bd b be z dk translated">每句话的得分或重要性</figcaption></figure><p id="70b6" class="pw-post-body-paragraph lh li iq lk b ll lm ka ln lo lp kd lq me ls lt lu mf lw lx ly mg ma mb mc md ij bi translated"><strong class="lk ja">最后</strong>，我们用<code class="fe ns nt nu nv b">heapq</code>找到了得分最高的4个句子。你可以选择任意数量的句子。然后简单地加入所选句子的列表，形成一串摘要。</p><p id="71a6" class="pw-post-body-paragraph lh li iq lk b ll lm ka ln lo lp kd lq me ls lt lu mf lw lx ly mg ma mb mc md ij bi translated"><em class="lj">自然语言处理</em>文章的最终输出摘要可以在所附的截图中看到。</p><pre class="kp kq kr ks gt oh nv oi oj aw ok bi"><span id="48e2" class="mv mw iq nv b gy ol om l on oo">import heapq<br/>summary = heapq.nlargest(4,sentence_score,key = sentence_score.get)<br/>summary = ' '.join(summary)<br/>final = "SUMMARY:- \n  " +summary</span><span id="8902" class="mv mw iq nv b gy os om l on oo">textfinal = 'TEXT:-    '+processed<br/>textfinal = textfinal.encode('ascii','ignore')<br/>textfinal = str(textfinal) <br/>final</span></pre><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div role="button" tabindex="0" class="ku kv di kw bf kx"><div class="gh gi ot"><img src="../Images/496484f703ce9ab968811a5f2481bd64.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*08SR_0zXZ7rum84CTy_S7A.png"/></div></div><figcaption class="la lb gj gh gi lc ld bd b be z dk translated">最终摘录摘要</figcaption></figure><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div class="gh gi ou"><img src="../Images/7dc88f689be7f0e6ab2cfcd6a38b735d.png" data-original-src="https://miro.medium.com/v2/resize:fit:600/1*TKf1HyboReaMkt2W5TPSgg.gif"/></div><figcaption class="la lb gj gh gi lc ld bd b be z dk translated">是啊！我们做到了。</figcaption></figure><p id="16ce" class="pw-post-body-paragraph lh li iq lk b ll lm ka ln lo lp kd lq me ls lt lu mf lw lx ly mg ma mb mc md ij bi translated"><strong class="lk ja"> <em class="lj">摘录摘要</em> </strong>可能不达标，但足以传达给定文章的主旨。此外，它更可靠，因为它只输出文章本身的选定数量的句子，而不是生成自己的输出。</p><p id="394a" class="pw-post-body-paragraph lh li iq lk b ll lm ka ln lo lp kd lq me ls lt lu mf lw lx ly mg ma mb mc md ij bi translated">我也会试着为抽象方法做一个教程，但是对我来说解释起来会是一个很大的挑战。😬</p><p id="d429" class="pw-post-body-paragraph lh li iq lk b ll lm ka ln lo lp kd lq me ls lt lu mf lw lx ly mg ma mb mc md ij bi translated">谢谢你宝贵的时间。😊我希望你喜欢这个教程。</p><p id="31a7" class="pw-post-body-paragraph lh li iq lk b ll lm ka ln lo lp kd lq me ls lt lu mf lw lx ly mg ma mb mc md ij bi translated">另外，查看我的教程<a class="ae ov" href="https://medium.com/analytics-vidhya/visualize-interesting-sorting-algorithms-with-python-bdd64bdd0713" rel="noopener"> <em class="lj">如何可视化排序算法</em> </a></p><div class="ow ox gp gr oy oz"><a href="https://medium.com/analytics-vidhya/visualize-interesting-sorting-algorithms-with-python-bdd64bdd0713" rel="noopener follow" target="_blank"><div class="pa ab fo"><div class="pb ab pc cl cj pd"><h2 class="bd ja gy z fp pe fr fs pf fu fw iz bi translated">用Python可视化有趣的排序算法</h2><div class="pg l"><h3 class="bd b gy z fp pe fr fs pf fu fw dk translated">有各种类型的排序算法，有时很难理解它们…</h3></div><div class="ph l"><p class="bd b dl z fp pe fr fs pf fu fw dk translated">medium.com</p></div></div><div class="pi l"><div class="pj l pk pl pm pi pn ky oz"/></div></div></a></div></div></div>    
</body>
</html>