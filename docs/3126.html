<html>
<head>
<title>Stop Using Grid Search! The Complete Practical Tutorial on Keras Tuner</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">停止使用网格搜索！关于Keras调谐器的完整实用教程</h1>
<blockquote>原文：<a href="https://pub.towardsai.net/keras-tuner-tutorial-hyperparameter-optimization-tensorflow-keras-computer-vision-example-c9abbdad9887?source=collection_archive---------0-----------------------#2022-09-17">https://pub.towardsai.net/keras-tuner-tutorial-hyperparameter-optimization-tensorflow-keras-computer-vision-example-c9abbdad9887?source=collection_archive---------0-----------------------#2022-09-17</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><p id="87f0" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">深度神经网络自动超参数调谐实用教程。autoML教程。</p><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div role="button" tabindex="0" class="ku kv di kw bf kx"><div class="gh gi ko"><img src="../Images/a1285e78b48286ccb50e75e59da65331.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*WhHtUnz3j6EOo3_X"/></div></div><figcaption class="la lb gj gh gi lc ld bd b be z dk translated">由<a class="ae le" href="https://unsplash.com/@veri_ivanova?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">维里·伊万诺娃</a>在<a class="ae le" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>拍摄的照片</figcaption></figure></div><div class="ab cl lf lg hx lh" role="separator"><span class="li bw bk lj lk ll"/><span class="li bw bk lj lk ll"/><span class="li bw bk lj lk"/></div><div class="im in io ip iq"><h2 id="9378" class="lm ln it bd lo lp lq dn lr ls lt dp lu kb lv lw lx kf ly lz ma kj mb mc md me bi translated">内容:</h2><ol class=""><li id="2737" class="mf mg it js b jt mh jx mi kb mj kf mk kj ml kn mm mn mo mp bi translated">介绍</li><li id="95b7" class="mf mg it js b jt mq jx mr kb ms kf mt kj mu kn mm mn mo mp bi translated">加载数据</li><li id="46af" class="mf mg it js b jt mq jx mr kb ms kf mt kj mu kn mm mn mo mp bi translated">Keras调谐器的基础知识</li><li id="7aa3" class="mf mg it js b jt mq jx mr kb ms kf mt kj mu kn mm mn mo mp bi translated">将所有这些放在一起(代码解释)</li><li id="43bb" class="mf mg it js b jt mq jx mr kb ms kf mt kj mu kn mm mn mo mp bi translated">执行超参数搜索</li><li id="a625" class="mf mg it js b jt mq jx mr kb ms kf mt kj mu kn mm mn mo mp bi translated">提取和训练最佳模型</li><li id="dddf" class="mf mg it js b jt mq jx mr kb ms kf mt kj mu kn mm mn mo mp bi translated">额外收获:一些提示和技巧</li><li id="a868" class="mf mg it js b jt mq jx mr kb ms kf mt kj mu kn mm mn mo mp bi translated">最后的想法</li></ol><h1 id="55f2" class="mv ln it bd lo mw mx my lr mz na nb lu nc nd ne lx nf ng nh ma ni nj nk md nl bi translated">介绍</h1><p id="6312" class="pw-post-body-paragraph jq jr it js b jt mh jv jw jx mi jz ka kb nm kd ke kf nn kh ki kj no kl km kn im bi translated">在本文中，您不仅将学习如何使用KerasTuner，还将学习其他教程中没有包括的一些<strong class="js iu">技巧，例如单独调整每个层中的参数，或者与优化器一起调整学习速率，由于某些限制，这并不简单，等等。同时使用37个类别的手语计算机视觉数据集。</strong></p><p id="58b2" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">即使是专家也经常陷入试错程序的兔子洞，直到他们为自己的神经网络找到一个好的超参数组合。<strong class="js iu"> Keras-Tuner </strong>是一款工具，可以帮助你优化你的神经网络，找到一个接近最优的超参数集。在幕后，它利用高级搜索和优化方法，如超波段搜索和贝叶斯优化。您只需要定义搜索空间，Keras-Tuner会负责费力的调优过程！</p></div><div class="ab cl lf lg hx lh" role="separator"><span class="li bw bk lj lk ll"/><span class="li bw bk lj lk ll"/><span class="li bw bk lj lk"/></div><div class="im in io ip iq"><p id="31d2" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">你在考虑加入Medium吗？使用我的链接支持我的博客之旅。我会得到一半的奖励，不增加你的费用:)</p><div class="nq nr gp gr ns nt"><a href="https://medium.com/@poulinakis.kon/membership" rel="noopener follow" target="_blank"><div class="nu ab fo"><div class="nv ab nw cl cj nx"><h2 class="bd iu gy z fp ny fr fs nz fu fw is bi translated">通过我的推荐链接加入Medium-Konstantinos Poulinakis</h2><div class="oa l"><h3 class="bd b gy z fp ny fr fs nz fu fw dk translated">阅读深度学习，数据科学，技术和媒体上的想法。您的会员费直接支持…</h3></div><div class="ob l"><p class="bd b dl z fp ny fr fs nz fu fw dk translated">medium.com</p></div></div><div class="oc l"><div class="od l oe of og oc oh ky nt"/></div></div></a></div></div><div class="ab cl lf lg hx lh" role="separator"><span class="li bw bk lj lk ll"/><span class="li bw bk lj lk ll"/><span class="li bw bk lj lk"/></div><div class="im in io ip iq"><h1 id="e189" class="mv ln it bd lo mw oi my lr mz oj nb lu nc ok ne lx nf ol nh ma ni om nk md nl bi translated">一个深入实际的例子</h1><p id="cd18" class="pw-post-body-paragraph jq jr it js b jt mh jv jw jx mi jz ka kb nm kd ke kf nn kh ki kj no kl km kn im bi translated">我们就赶紧跳着练吧！</p><h2 id="6ed5" class="lm ln it bd lo lp lq dn lr ls lt dp lu kb lv lw lx kf ly lz ma kj mb mc md me bi translated">加载数据</h2><p id="2883" class="pw-post-body-paragraph jq jr it js b jt mh jv jw jx mi jz ka kb nm kd ke kf nn kh ki kj no kl km kn im bi translated">让我们假设我们想要在图像分类数据集上训练CNN。我们将展示如何利用KerasTuner轻松优化我们的神经网络。</p><p id="696f" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">首先，用pip安装Keras-Tuner库并导入必要的库。如果您不想从pip输出，使用<code class="fe on oo op oq b">-q</code>标志进行安静安装。</p><pre class="kp kq kr ks gt or oq os bn ot ou bi"><span id="c5ee" class="ov ln it oq b be ow ox l oy oz">!pip install keras-tuner --upgrade<br/>import keras_tuner<br/>from tensorflow import keras<br/>from keras import backend as K<br/>from tensorflow.keras import layers, losses<br/>import numpy as np<br/>import matplotlib.pyplot as plt<br/>import os</span></pre><p id="2782" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">接下来，我们需要加载一些数据来处理。我选择使用<a class="ae le" href="https://www.kaggle.com/datasets/ayuraj/asl-dataset" rel="noopener ugc nofollow" target="_blank">美国手语(ASL)数据集</a>，该数据集在<a class="ae le" href="https://creativecommons.org/publicdomain/zero/1.0/" rel="noopener ugc nofollow" target="_blank"> CCO </a>许可下可在Kaggle上获得。它包含代表美国手语的400x400 RGB手势图像。它有一个完整的37类，每类70张图片。我们将训练一个CNN模型来对这些手势进行分类。</p><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div class="gh gi pa"><img src="../Images/6002e43599f8138bc6ca971ad3077583.png" data-original-src="https://miro.medium.com/v2/resize:fit:654/format:webp/1*lEIbPEe_N2Vpz_yA6VtNPA.png"/></div></figure><p id="635e" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">由于数据集已经基于类构建在文件夹中，加载数据集最简单的方法是使用<code class="fe on oo op oq b">keras.utils.image_dataset_from_directory </code>实用程序。用<code class="fe on oo op oq b">directory </code>参数指定父目录路径，并使用<code class="fe on oo op oq b">labels=’inferred’</code>根据文件夹名自动加载标签。使用<code class="fe on oo op oq b">label_mode='categorical'</code>标签作为一个热点向量加载。如果你想让洗牌重现，你可以设置一个<code class="fe on oo op oq b">seed</code>，否则，根本不要使用种子选项。</p><pre class="kp kq kr ks gt or oq os bn ot ou bi"><span id="a577" class="ov ln it oq b be ow ox l oy oz">BATCH_SIZE = 64<br/>train_data = keras.utils.image_dataset_from_directory(<br/>                  directory="../input/asl-dataset/asl_dataset",<br/>                  labels= 'inferred',<br/>                  label_mode='categorical',<br/>                  color_mode='rgb',<br/>                  batch_size=BATCH_SIZE,<br/>                  seed=777,<br/>                  shuffle=True,<br/>                  image_size=(400, 400) )p</span></pre><p id="848c" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">现在使用下面的函数将<code class="fe on oo op oq b"> tf.data.dataset</code>项分成训练值测试子集。我对这个数据集使用0.7–0.15–0.15分割规则。</p><figure class="kp kq kr ks gt kt"><div class="bz fp l di"><div class="pb pc l"/></div><figcaption class="la lb gj gh gi lc ld bd b be z dk translated">将tf.data.Dataset拆分成train-val-test并打印它们的元素</figcaption></figure><p id="829b" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">数据集加载已完成。让我们进入激动人心的部分！</p><h2 id="edad" class="lm ln it bd lo lp lq dn lr ls lt dp lu kb lv lw lx kf ly lz ma kj mb mc md me bi translated">Keras调谐器的基础知识</h2><p id="59a2" class="pw-post-body-paragraph jq jr it js b jt mh jv jw jx mi jz ka kb nm kd ke kf nn kh ki kj no kl km kn im bi translated">在进入更复杂的代码之前，我们需要理解Keras-Tuner的工作流程。</p><ol class=""><li id="5e86" class="mf mg it js b jt ju jx jy kb pd kf pe kj pf kn mm mn mo mp bi translated">我们定义了一个<code class="fe on oo op oq b">build() </code>函数，它接受一个参数<strong class="js iu"> hp </strong> ( <code class="fe on oo op oq b">keras_tuner.Hyperparameter</code> object)。在里面，我们定义了我们的模型架构和超参数搜索空间。</li><li id="371f" class="mf mg it js b jt mq jx mr kb ms kf mt kj mu kn mm mn mo mp bi translated">为了定义一个搜索空间，<strong class="js iu"> hp </strong> object提供了4种方法。<code class="fe on oo op oq b">hp.Choice()</code>、<code class="fe on oo op oq b">hp.Int()</code>、<code class="fe on oo op oq b">hp.Float()</code>和<code class="fe on oo op oq b">hp.Boolean()</code>。<code class="fe on oo op oq b">hp.Choice()</code>方法是最通用的，它接受一系列str、int、float或boolean值，但所有这些值必须具有相同的类型。其他方法是不言自明的。这里有一些直观的例子</li></ol><pre class="kp kq kr ks gt or oq os bn ot ou bi"><span id="bc90" class="ov ln it oq b be ow ox l oy oz"># defining the number of neurons in a fully connected layer<br/>units = hp.Choice(name="neurons", values=[150, 200])<br/># defining the number of neurons dynamically with the hp.Int method<br/>units = hp.Int(name="neurons", min=100, max=200, step=10)<br/># defining the dropout rate<br/>dropout = hp.Int(name="dropout", min=0.0, max=0.3, step=0.05)<br/># Automatically assign True/False values.<br/>shuffle = hp.Boolean("shuffle", default=False)</span></pre><p id="5cc9" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">3.初始化负责搜索超参数空间的调谐器。Keras-Tuner提供了3种不同的搜索策略，随机搜索，贝叶斯优化和超波段。对于所有的调谐器，我们需要指定一个超级模型、一个要优化的度量、一个计算预算和一个可选的保存结果的目录。有关每个调谐器接受的参数的更多详细信息，请随时查看相关的<a class="ae le" href="https://keras.io/api/keras_tuner/tuners/" rel="noopener ugc nofollow" target="_blank">文档</a>。下面是一个超波段调谐器的例子。</p><pre class="kp kq kr ks gt or oq os bn ot ou bi"><span id="cc81" class="ov ln it oq b be ow ox l oy oz">tuner = keras_tuner.Hyperband(<br/>                       hypermodel=MyHyperModel(),<br/>                       objective = "val_accuracy", #optimize val acc<br/>                       max_epochs=50, #for each candidate model<br/>                       overwrite=True,  #overwrite previous results<br/>                       directory='hyperband_search_dir', #Saving dir<br/>                       project_name='sign_language_cnn')</span></pre><p id="389e" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">4.执行搜索。该命令将启动搜索。您需要提供用于训练和评估被搜索模型的训练和验证数据。</p><pre class="kp kq kr ks gt or oq os bn ot ou bi"><span id="2fee" class="ov ln it oq b be ow ox l oy oz">tuner.search(x=train_data, <br/>             max_trials=50,  # Max num of candidates to try<br/>             validation_data=val_data,<br/>             batch_size=BATCH_SIZE)</span></pre><h1 id="6280" class="mv ln it bd lo mw mx my lr mz na nb lu nc nd ne lx nf ng nh ma ni nj nk md nl bi translated">把所有的放在一起</h1><p id="8b31" class="pw-post-body-paragraph jq jr it js b jt mh jv jw jx mi jz ka kb nm kd ke kf nn kh ki kj no kl km kn im bi translated">以上都有很多种结合方式。下面介绍的方法提供了很大的灵活性。</p><p id="f362" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">首先，我们定义一个继承自<code class="fe on oo op oq b">keras_tuner.HyperModel</code>的超级模型类，并定义build和fit方法。</p><p id="ee1c" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">通过build方法，我们开发了我们的架构，并使用<strong class="js iu"> hp </strong>参数来设置超参数搜索空间。我们还编译我们的模型并返回它。</p><p id="cbdc" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">fit方法接受hp参数、要训练的模型、训练数据<code class="fe on oo op oq b">x </code>，并且还传递将被传递到keras <code class="fe on oo op oq b">model.fit()</code>方法中的<code class="fe on oo op oq b">*args</code>和<code class="fe on oo op oq b">**kwargs</code>。<code class="fe on oo op oq b">**kwargs</code>应该总是传递给<code class="fe on oo op oq b">model.fit()</code>，因为它包含了模型保存的回调和可选的tensorboard插件。</p><blockquote class="pg ph pi"><p id="d8ee" class="jq jr np js b jt ju jv jw jx jy jz ka pj kc kd ke pk kg kh ki pl kk kl km kn im bi translated">在我们的超级模型类中定义一个<code class="fe on oo op oq b">fit()</code>方法给了你在训练过程中搜索参数的灵活性，而不仅仅是在构建过程中。</p></blockquote><figure class="kp kq kr ks gt kt"><div class="bz fp l di"><div class="pb pc l"/></div><figcaption class="la lb gj gh gi lc ld bd b be z dk translated">超模类。在类内部，我们定义模型和搜索空间。</figcaption></figure><blockquote class="pg ph pi"><p id="ed42" class="jq jr np js b jt ju jv jw jx jy jz ka pj kc kd ke pk kg kh ki pl kk kl km kn im bi translated">以上网络和参数仅供展示之用。您可以随意定制网络和搜索空间，因为它更适合您的应用。</p></blockquote><h2 id="36be" class="lm ln it bd lo lp lq dn lr ls lt dp lu kb lv lw lx kf ly lz ma kj mb mc md me bi translated"><strong class="ak">来细说一下:</strong></h2><p id="fd1c" class="pw-post-body-paragraph jq jr it js b jt mh jv jw jx mi jz ka kb nm kd ke kf nn kh ki kj no kl km kn im bi translated">在第3–5行，我们开始构建Keras模型并添加一个调整大小层。在第7–8行，我们使用<code class="fe on oo op oq b">hp.Boolean</code>来评估是否最好添加一个标准化层，而在第10行，我们为辍学率定义了不同的可能值。</p><p id="730f" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated"><strong class="js iu">第12–17行</strong>稍微复杂一点。我们动态地指定我们的模型应该有多少卷积层<strong class="js iu">，同时为每一层定义不同的超参数空间。</strong>本质上，我们从7到8设置conv层的数量，并且对于每一层，我们独立地搜索最优的滤波器数量、核大小和激活函数。我们通过在字符串<code class="fe on oo op oq b">name=f”kernel_{i}”</code>中使用索引I，为循环中的每次迭代使用不同的<code class="fe on oo op oq b">name</code>参数来实现这一点。这给了我们很大的灵活性，允许我们极大地扩展搜索空间。然而，要小心，因为可能的组合可能会变得非常大，并且需要大量的计算能力。</p><blockquote class="pg ph pi"><p id="4a04" class="jq jr np js b jt ju jv jw jx jy jz ka pj kc kd ke pk kg kh ki pl kk kl km kn im bi translated">在循环中使用<code class="fe on oo op oq b">name=f”kernel_{i}”</code>指定可调变量的名称，允许您为每个层上的每个参数定义不同的搜索空间。</p></blockquote><p id="7c74" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">在第18–22行中，我们在conv块中添加(或不添加)漏失和批量标准化层。我们在28–31中也做了同样的工作，但针对的是全连接层。</p><p id="dee4" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">在第24–27行，我们添加了一个展平层，后面是可搜索数量的全连接层，每个层都有不同的参数要优化，类似于第12–17行。</p><p id="060f" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">在第36–39行，我们编译了我们的模型，但是优化器的选择和要使用的loss仍然是一个可搜索的超参数。Keras调谐器的一个限制是它不接受除int、float、str或boolean之外的变量。因此，我们不能在choice方法中传递<code class="fe on oo op oq b">keras.optimizer</code>对象。这将我们的超参数搜索限制在优化器和损失函数上，Keras已经给了它们一个字符串别名，例如<code class="fe on oo op oq b"> keras.optimizers.Adam() -&gt; 'adam'</code>。</p><p id="e74d" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated"><strong class="js iu">由于上述限制，如何调整学习速率并不简单。在第41–43行，我们以一种“黑客”的方式完成了</strong>。</p><blockquote class="pg ph pi"><p id="9faa" class="jq jr np js b jt ju jv jw jx jy jz ka pj kc kd ke pk kg kh ki pl kk kl km kn im bi translated">下面的代码允许您更改优化器的超参数，比如学习率，甚至当您调优不同的优化器时，keras tuner没有以直接的方式提供这些参数。</p><p id="1d1d" class="jq jr np js b jt ju jv jw jx jy jz ka pj kc kd ke pk kg kh ki pl kk kl km kn im bi translated"><code class="fe on oo op oq b">from keras import backend as K</code> <br/> <code class="fe on oo op oq b">learning rate = hp.Choice('lr', [0.03, 0.01, 0.003])</code> <br/> <code class="fe on oo op oq b">K.set_value(model.optimizer.learning_rate, learning_rate)</code></p></blockquote><p id="4a8d" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">在第48–53行，我们定义了超级模型类的<code class="fe on oo op oq b">fit(self, hp, model,x, *args, **kwargs)</code>方法。正如您可能观察到的，我们将惠普定义为一个论点。<strong class="js iu">这也允许我们在训练过程中调整超参数值。</strong>作为一个例子，我在每个时期之前使用了训练数据的混洗。确保将<code class="fe on oo op oq b">add**kwargs</code>作为一个参数，因为它包含了在搜索过程中保存模型的回调函数(以及可选的tensorboard插件)。</p><p id="ae09" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">通过运行下面几行作为测试，确保一切正常工作</p><pre class="kp kq kr ks gt or oq os bn ot ou bi"><span id="16a5" class="ov ln it oq b be ow ox l oy oz">classes = 37<br/>hp = keras_tuner.HyperParameters()<br/>hypermodel = MyHyperModel()<br/>model = hypermodel.build(hp, classes)<br/>hypermodel.fit(hp, model, np.random.rand(BATCH_SIZE, 400, 400,3),<br/>               np.random.rand(BATCH_SIZE, classes))</span></pre></div><div class="ab cl lf lg hx lh" role="separator"><span class="li bw bk lj lk ll"/><span class="li bw bk lj lk ll"/><span class="li bw bk lj lk"/></div><div class="im in io ip iq"><h1 id="4250" class="mv ln it bd lo mw oi my lr mz oj nb lu nc ok ne lx nf ol nh ma ni om nk md nl bi translated">执行超参数搜索</h1><p id="b21b" class="pw-post-body-paragraph jq jr it js b jt mh jv jw jx mi jz ka kb nm kd ke kf nn kh ki kj no kl km kn im bi translated">假设一切正常，现在是初始化搜索的时候了。在下面的代码中，我使用了贝叶斯优化策略。这是AutoML中最好的搜索方法之一。</p><p id="c590" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">传递一个超级模型对象，将目标设置为您希望优化的指标(例如“val_accuracy”、“train_loss”)，并使用<code class="fe on oo op oq b">max_trials </code>参数和保存模型的路径来定义计算预算。</p><pre class="kp kq kr ks gt or oq os bn ot ou bi"><span id="b2ad" class="ov ln it oq b be ow ox l oy oz">tuner = keras_tuner.BayesianOptimization(<br/>                        hypermodel=MyHyperModel(),<br/>                        objective = "val_accuracy",<br/>                        max_trials =10, #max candidates to test<br/>                        overwrite=True,<br/>                        directory='BO_search_dir',<br/>                        project_name='sign_language_cnn')</span></pre><p id="3a99" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">要开始搜索，执行下面的命令，就可以开始了。当你喝咖啡休息的时候，Keras-Tuner会处理剩下的事情。</p><pre class="kp kq kr ks gt or oq os bn ot ou bi"><span id="c832" class="ov ln it oq b be ow ox l oy oz"># epochs defines how many epochs each candidate model<br/># will be trained for. The more the better, but slower.<br/>tuner.search(x=train_data, epochs=10,<br/>             validation_data=val_data)</span></pre><p id="608d" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">一旦你喝完咖啡，或者一旦搜索完成，你可以用<code class="fe on oo op oq b">tuner.results_summary(1)</code>访问搜索结果。您可以看到为每个超参数选择了哪个值，以及最佳模型在其训练期间获得的验证分数。</p><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div class="gh gi pm"><img src="../Images/3e2106f281c86096e7455cad1fd9c8cc.png" data-original-src="https://miro.medium.com/v2/resize:fit:1136/format:webp/1*neUzwbvnQBGa1vVwJ9vrPg.png"/></div><figcaption class="la lb gj gh gi lc ld bd b be z dk translated">调谐器结果_摘要的输出。由于搜索策略的随机性，结果可能会有所不同。</figcaption></figure><p id="6a08" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">要自动提取和构建最佳候选模型，请运行下面几行。如果您想要提取多个表现最佳的模型，而不仅仅是第一个，请更改<code class="fe on oo op oq b"> tuner.get_best_hyperparameters(5)</code>中的数字。</p><pre class="kp kq kr ks gt or oq os bn ot ou bi"><span id="7605" class="ov ln it oq b be ow ox l oy oz"># Get the top 2 hyperparameters.<br/>best_hps = tuner.get_best_hyperparameters(1)<br/># Build the model with the best hp.<br/>h_model = MyHyperModel()<br/>model = h_model.build(best_hps[0])</span></pre><p id="ace2" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">接下来，我们必须在完整的数据集上为多个时期训练这个模型。<strong class="js iu">您还可以传递回调函数</strong>，例如提前停止、保存最佳模型和学习速率调度程序。</p><figure class="kp kq kr ks gt kt"><div class="bz fp l di"><div class="pb pc l"/></div><figcaption class="la lb gj gh gi lc ld bd b be z dk translated">用回调函数训练模型</figcaption></figure><p id="29bc" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">一旦你的模型被训练，绘制学习图用于检查和评估测试数据集。如果您满意，保存模型以供以后部署使用</p><p id="c818" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated"><code class="fe on oo op oq b">model.load_weights(‘Net_weights.h5’)<br/>model.evaluate(test_data)<br/>model.save(‘Best_model’)</code></p></div><div class="ab cl lf lg hx lh" role="separator"><span class="li bw bk lj lk ll"/><span class="li bw bk lj lk ll"/><span class="li bw bk lj lk"/></div><div class="im in io ip iq"><h1 id="2b28" class="mv ln it bd lo mw oi my lr mz oj nb lu nc ok ne lx nf ol nh ma ni om nk md nl bi translated">额外收获:一些提示和技巧</h1><ol class=""><li id="cbc0" class="mf mg it js b jt mh jx mi kb mj kf mk kj ml kn mm mn mo mp bi translated">如果你的数据集非常大，搜索时间太长，你可以在搜索过程中只使用一小部分进行训练，比如30%。这通常会在很短的时间内提供相似的结果。然后你可以在全套上重新训练最好的模型。</li><li id="f0e0" class="mf mg it js b jt mq jx mr kb ms kf mt kj mu kn mm mn mo mp bi translated">为了加快搜索过程，您可以减少每个候选人接受训练的时期数。然而，这可能会降低搜索优化的精度，因为倾向于在早期表现更好的候选人将会进一步进步，即使他们的表现在后来饱和。尝试在时间和结果精度之间找到最佳平衡点。</li><li id="1086" class="mf mg it js b jt mq jx mr kb ms kf mt kj mu kn mm mn mo mp bi translated">在搜索过程中可能出现的一个问题是您将耗尽磁盘空间。在搜索过程中，优化器会自动将所有模型保存在项目目录中，但不会动态删除被丢弃的模型。这将快速加载磁盘内存，并可能导致崩溃，特别是如果您正在Kaggle或Google Colab上运行代码。这是一个报告的问题[ <a class="ae le" href="https://github.com/keras-team/keras-tuner/issues/288" rel="noopener ugc nofollow" target="_blank"> 1 </a> ][ <a class="ae le" href="https://github.com/keras-team/keras-tuner/issues/481" rel="noopener ugc nofollow" target="_blank"> 2 </a> ]，开发者已经在Keras调谐器库中将其标记为增强。如果出现“磁盘空间不足”错误，请考虑限制搜索空间或将搜索分成多个较小的搜索。最后，如果您在本地环境中工作，请确保在每次搜索后丢弃“坏”模型。</li></ol><h1 id="67c1" class="mv ln it bd lo mw mx my lr mz na nb lu nc nd ne lx nf ng nh ma ni nj nk md nl bi translated">最后的想法</h1><p id="69e6" class="pw-post-body-paragraph jq jr it js b jt mh jv jw jx mi jz ka kb nm kd ke kf nn kh ki kj no kl km kn im bi translated">在本教程中，我们探索了Keras调谐器工具的使用。这个工具允许我们优化我们的网络架构(层数、神经元数等)..)以及它们的超参数(例如，激活函数、优化器、损耗等..).</p><p id="a1ca" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">与手动或网格搜索方法相比，KerasTuner中实施的搜索策略允许进行更快、更容易的微调。利用搜索方法，如贝叶斯优化或超波段搜索，不仅会节省你的时间，而且通常情况下，你会得到一个比没有它们更好的模型。</p><h1 id="e20f" class="mv ln it bd lo mw mx my lr mz na nb lu nc nd ne lx nf ng nh ma ni nj nk md nl bi translated">参考</h1><p id="8bef" class="pw-post-body-paragraph jq jr it js b jt mh jv jw jx mi jz ka kb nm kd ke kf nn kh ki kj no kl km kn im bi translated">[1] Keras调谐器文档，【https://keras-team.github.io/keras-tuner/ T4】</p><p id="b010" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">[2]贾斯珀·斯诺克，雨果·拉罗歇尔，瑞安·p·亚当斯，<br/> <em class="np">实用贝叶斯优化机器学习算法，(2012)，</em><a class="ae le" href="https://arxiv.org/abs/1206.2944" rel="noopener ugc nofollow" target="_blank">https://arxiv.org/abs/1206.2944</a></p><p id="e8e7" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">[3]李，贾米森，德萨沃，罗斯塔米扎德，塔尔沃卡，<em class="np">超波段:一种基于Bandit的超参数优化方法(2018)，</em><a class="ae le" href="https://arxiv.org/abs/1603.06560" rel="noopener ugc nofollow" target="_blank">14</a></p></div><div class="ab cl lf lg hx lh" role="separator"><span class="li bw bk lj lk ll"/><span class="li bw bk lj lk ll"/><span class="li bw bk lj lk"/></div><div class="im in io ip iq"><p id="b051" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated"><em class="np">如果你学到了一些有用的东西，请关注我，获取更多深度学习内容和技术教程。使劲鼓掌也让我感觉很棒:)</em></p><p id="1a5b" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">如果你愿意支持我，你可以使用我的链接成为Medium的一员。我会得到一半的奖励，不需要你额外付费:)</p><div class="nq nr gp gr ns nt"><a href="https://medium.com/@poulinakis.kon/membership" rel="noopener follow" target="_blank"><div class="nu ab fo"><div class="nv ab nw cl cj nx"><h2 class="bd iu gy z fp ny fr fs nz fu fw is bi translated">通过我的推荐链接加入Medium-Konstantinos Poulinakis</h2><div class="oa l"><h3 class="bd b gy z fp ny fr fs nz fu fw dk translated">阅读深度学习，数据科学，技术和媒体上的想法。您的会员费直接支持…</h3></div><div class="ob l"><p class="bd b dl z fp ny fr fs nz fu fw dk translated">medium.com</p></div></div><div class="oc l"><div class="od l oe of og oc oh ky nt"/></div></div></a></div><p id="7cd0" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated"><em class="np">感谢阅读，随时联系！</em></p><p id="8520" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated"><strong class="js iu">我的链接:</strong> <a class="ae le" href="https://medium.com/@poulinakis.kon" rel="noopener">中</a>|<a class="ae le" href="https://www.linkedin.com/in/konstantinos-poulinakis-4554821a3/" rel="noopener ugc nofollow" target="_blank"><em class="np"/>LinkedIn</a>|<a class="ae le" href="https://github.com/Poulinakis-Konstantinos" rel="noopener ugc nofollow" target="_blank">GitHub</a></p></div></div>    
</body>
</html>