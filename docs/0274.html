<html>
<head>
<title>Titanic Challenge — Machine Learning for Disaster Recovery — Part 2</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">泰坦尼克号挑战—灾难恢复的机器学习—第二部分</h1>
<blockquote>原文：<a href="https://pub.towardsai.net/titanic-challenge-machine-learning-for-disaster-recovery-part-2-22561e8137f4?source=collection_archive---------0-----------------------#2020-01-14">https://pub.towardsai.net/titanic-challenge-machine-learning-for-disaster-recovery-part-2-22561e8137f4?source=collection_archive---------0-----------------------#2020-01-14</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><figure class="ip iq gp gr ir is gh gi paragraph-image"><div role="button" tabindex="0" class="it iu di iv bf iw"><div class="gh gi io"><img src="../Images/be179c78e3b63e7aaad56a5b1ec403c0.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*g1MI_mlbbXFUxVcafy17cg.png"/></div></div><figcaption class="iz ja gj gh gi jb jc bd b be z dk translated">来源:<a class="ae jd" href="https://www.pxfuel.com/" rel="noopener ugc nofollow" target="_blank"> Pxfuel </a></figcaption></figure><div class=""/><div class=""><h2 id="c35e" class="pw-subtitle-paragraph kd jf jg bd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku dk translated">第2部分—预测模型构建</h2></div><p id="d3e8" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">代码位置:<a class="ae jd" href="https://github.com/BindhuVinodh/Titanic---Predictive-Model-Building" rel="noopener ugc nofollow" target="_blank">https://github.com/BindhuVinodh/Titanic预测建模</a></p><h1 id="887b" class="lr ls jg bd lt lu lv lw lx ly lz ma mb km mc kn md kp me kq mf ks mg kt mh mi bi translated">II —特征工程</h1><p id="1442" class="pw-post-body-paragraph kv kw jg kx b ky mj kh la lb mk kk ld le ml lg lh li mm lk ll lm mn lo lp lq ij bi translated">在前一部分中，我们研究了数据，发现了一些有趣的相关性。</p><p id="9442" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">在这一部分中，我们将看到如何处理和转换这些变量，使数据变得可由机器学习算法管理。</p><p id="6650" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">我们还将创建或“设计”在构建模型时有用的附加功能。</p><p id="25f4" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">我们将看到如何处理文本变量，如乘客姓名，并将这些信息集成到我们的模型中。</p><p id="e708" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">为了更加清晰，我们将把代码分解成独立的函数。</p><h1 id="c06f" class="lr ls jg bd lt lu lv lw lx ly lz ma mb km mc kn md kp me kq mf ks mg kt mh mi bi translated">加载数据</h1><p id="53a0" class="pw-post-body-paragraph kv kw jg kx b ky mj kh la lb mk kk ld le ml lg lh li mm lk ll lm mn lo lp lq ij bi translated">当开始机器学习问题时，一个技巧是将训练集一起附加到测试集。</p><p id="8739" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">我们将使用训练集设计新功能，以防止信息泄漏。然后我们将这些变量添加到测试集中。</p><p id="85c6" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">让我们加载训练集和测试集，并将它们附加在一起。</p><pre class="mo mp mq mr gt ms mt mu mv aw mw bi"><span id="11f8" class="mx ls jg mt b gy my mz l na nb">def get_combined_data():<br/>    # reading train data<br/>    train = pd.read_csv('./data/train.csv')<br/>    <br/>    # reading test data<br/>    test = pd.read_csv('./data/test.csv')<br/><br/>    # extracting and then removing the targets from the training data <br/>    targets = train.Survived<br/>    train.drop(['Survived'], 1, inplace=True)<br/>    <br/><br/>    # merging train data and test data for future feature engineering<br/>    # we'll also remove the PassengerID since this is not an informative feature<br/>    combined = train.append(test)<br/>    combined.reset_index(inplace=True)<br/>    combined.drop(['index', 'PassengerId'], inplace=True, axis=1)<br/>    <br/>    return combined<br/><br/>combined = get_combined_data()</span></pre><p id="187a" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">让我们来看看形状:</p><pre class="mo mp mq mr gt ms mt mu mv aw mw bi"><span id="98f2" class="mx ls jg mt b gy my mz l na nb">print(combined.shape)<br/># (1309, 10)</span></pre><p id="c161" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">组合了训练集和测试集。</p><p id="a4ba" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">您可能会注意到，总行数(1309)是训练集和测试集中行数的精确总和。</p><pre class="mo mp mq mr gt ms mt mu mv aw mw bi"><span id="e8b9" class="mx ls jg mt b gy my mz l na nb">combined.head()</span></pre><figure class="mo mp mq mr gt is gh gi paragraph-image"><div role="button" tabindex="0" class="it iu di iv bf iw"><div class="gh gi nc"><img src="../Images/97b1f4f94bfcb3c3259a4b0c9e72cc28.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*qPuwsjce--AwcCm3ip2AAw.png"/></div></div><figcaption class="iz ja gj gh gi jb jc bd b be z dk translated">提取乘客姓名</figcaption></figure><p id="900a" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">当查看乘客姓名时，人们可能会想知道如何处理它们以提取有用的信息。</p><p id="abd5" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">如果你仔细观察这些第一个例子:</p><ul class=""><li id="0d7a" class="nd ne jg kx b ky kz lb lc le nf li ng lm nh lq ni nj nk nl bi translated"><strong class="kx jh">布劳恩先生</strong>欧文·哈里斯</li><li id="c1dd" class="nd ne jg kx b ky nm lb nn le no li np lm nq lq ni nj nk nl bi translated"><strong class="kx jh">黑金小姐。</strong>莱娜</li><li id="52cc" class="nd ne jg kx b ky nm lb nn le no li np lm nq lq ni nj nk nl bi translated">Oliva y Ocana，Dona。费米纳</li><li id="fa7d" class="nd ne jg kx b ky nm lb nn le no li np lm nq lq ni nj nk nl bi translated">彼得，主人。迈克尔·J</li></ul><p id="1e41" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">你会注意到每个名字里面都有一个标题！这可能是一个简单的失误。或者夫人，但有时也可以是更高级的称呼，如主人、先生或夫人。在这种情况下，我们可以通过简单地解析姓名、提取头衔并将其转换为二进制变量来引入关于社会地位的附加信息。</p><p id="d4c3" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">让我们看看如何在下面的函数中做到这一点。</p><p id="f0fb" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">让我们先来看看火车系列中有哪些不同的标题</p><p id="45ea" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated"><code class="fe nr ns nt mt b">print(titles)<br/># set(['Sir', 'Major', 'the Countess', 'Don', 'Mlle', 'Capt', 'Dr', 'Lady', 'Rev', 'Mrs', 'Jonkheer', 'Master', 'Ms', 'Mr', 'Mme', 'Miss', 'Col'])</code></p><pre class="mo mp mq mr gt ms mt mu mv aw mw bi"><span id="6b79" class="mx ls jg mt b gy my mz l na nb">Title_Dictionary = {<br/>    "Capt": "Officer",<br/>    "Col": "Officer",<br/>    "Major": "Officer",<br/>    "Jonkheer": "Royalty",<br/>    "Don": "Royalty",<br/>    "Sir" : "Royalty",<br/>    "Dr": "Officer",<br/>    "Rev": "Officer",<br/>    "the Countess":"Royalty",<br/>    "Mme": "Mrs",<br/>    "Mlle": "Miss",<br/>    "Ms": "Mrs",<br/>    "Mr" : "Mr",<br/>    "Mrs" : "Mrs",<br/>    "Miss" : "Miss",<br/>    "Master" : "Master",<br/>    "Lady" : "Royalty"<br/>}</span><span id="8e70" class="mx ls jg mt b gy nu mz l na nb">def get_titles():<br/>    # we extract the title from each name<br/>    combined['Title'] = combined['Name'].map(lambda name:name.split(',')[1].split('.')[0].strip())<br/>    <br/>    # a map of more aggregated title<br/>    # we map each title<br/>    combined['Title'] = combined.Title.map(Title_Dictionary)<br/>    status('Title')<br/>    return combined</span></pre><h1 id="cca3" class="lr ls jg bd lt lu lv lw lx ly lz ma mb km mc kn md kp me kq mf ks mg kt mh mi bi translated">这个函数解析名字并提取标题。然后，它将标题映射到标题的类别。我们选择了:</h1><ul class=""><li id="ad14" class="nd ne jg kx b ky mj lb mk le nv li nw lm nx lq ni nj nk nl bi translated">警官</li><li id="8d1b" class="nd ne jg kx b ky nm lb nn le no li np lm nq lq ni nj nk nl bi translated">版税</li><li id="df80" class="nd ne jg kx b ky nm lb nn le no li np lm nq lq ni nj nk nl bi translated">先生</li><li id="60b2" class="nd ne jg kx b ky nm lb nn le no li np lm nq lq ni nj nk nl bi translated">夫人</li><li id="f97c" class="nd ne jg kx b ky nm lb nn le no li np lm nq lq ni nj nk nl bi translated">小姐ˌ女士</li><li id="aec9" class="nd ne jg kx b ky nm lb nn le no li np lm nq lq ni nj nk nl bi translated">掌握</li></ul><p id="63c6" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">让我们运行它！</p><pre class="mo mp mq mr gt ms mt mu mv aw mw bi"><span id="7abc" class="mx ls jg mt b gy my mz l na nb">combined = get_titles()<br/>combined.head()</span></pre><p id="4efc" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">让我们检查一下标题是否填对了。</p><pre class="mo mp mq mr gt ms mt mu mv aw mw bi"><span id="635f" class="mx ls jg mt b gy my mz l na nb">combined[combined['Title'].isnull()]</span></pre><p id="ce89" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">第1305行中确实有一个NaN值。其实对应的名字是Oliva y Ocana，<strong class="kx jh"> Dona </strong>。费尔米纳。</p><p id="f9fc" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">在训练数据集中没有遇到此标题。</p><p id="ed54" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">完美。现在我们有了一个名为<strong class="kx jh"> Title </strong>的额外列，其中包含了信息。</p><h1 id="3b94" class="lr ls jg bd lt lu lv lw lx ly lz ma mb km mc kn md kp me kq mf ks mg kt mh mi bi translated">处理年龄</h1><p id="28de" class="pw-post-body-paragraph kv kw jg kx b ky mj kh la lb mk kk ld le ml lg lh li mm lk ll lm mn lo lp lq ij bi translated">我们在第一部分已经看到，年龄变量缺少177个值。这是一个很大的数字(约占数据集的13%)。简单地用平均年龄或中值年龄来代替它们可能不是最佳解决方案，因为年龄可能因乘客的组和类别而不同。</p><p id="bb1e" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">为了理解原因，让我们按照性别、头衔和乘客级别对数据集进行分组，并计算每个子集的平均年龄。</p><p id="e7a3" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">为了避免测试集中的数据泄漏，我们使用训练集来填充训练中缺失的年龄，并且使用从训练集计算的值来填充测试集中的年龄。</p><p id="cf84" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">列车组中缺少的年龄数</p><pre class="mo mp mq mr gt ms mt mu mv aw mw bi"><span id="6271" class="mx ls jg mt b gy my mz l na nb">print(combined.iloc[:891].Age.isnull().sum())<br/># 177</span></pre><p id="3639" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">测试集中缺失年龄的数量</p><pre class="mo mp mq mr gt ms mt mu mv aw mw bi"><span id="db79" class="mx ls jg mt b gy my mz l na nb">print(combined.iloc[891:].Age.isnull().sum())<br/># 86</span><span id="c7d2" class="mx ls jg mt b gy nu mz l na nb">grouped_train = combined.iloc[:891].groupby(['Sex','Pclass','Title'])<br/>grouped_median_train = grouped_train.median()<br/>grouped_median_train = grouped_median_train.reset_index()[['Sex', 'Pclass', 'Title', 'Age']]</span><span id="9b9b" class="mx ls jg mt b gy nu mz l na nb">grouped_median_train.head()</span></pre><p id="d337" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">该数据框将帮助我们根据不同的标准估算缺失的年龄值。</p><p id="95c5" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">查看“年龄中位数”栏，看看这个值如何根据性别、阶级和职位的不同而有所不同。</p><p id="56da" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">例如:</p><ul class=""><li id="b324" class="nd ne jg kx b ky kz lb lc le nf li ng lm nh lq ni nj nk nl bi translated">如果乘客是女性，从1级乘客到皇室成员，平均年龄为40.5岁。</li><li id="3f15" class="nd ne jg kx b ky nm lb nn le no li np lm nq lq ni nj nk nl bi translated">如果乘客是男性，来自Pclass 3，具有Mr头衔，则中值年龄为26岁。</li></ul><p id="0642" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">让我们创建一个函数，根据这些不同的属性来填充缺少的年龄是<strong class="kx jh">组合</strong>。</p><pre class="mo mp mq mr gt ms mt mu mv aw mw bi"><span id="b610" class="mx ls jg mt b gy my mz l na nb">def fill_age(row):<br/>    condition = (<br/>        (grouped_median_train['Sex'] == row['Sex']) &amp; <br/>        (grouped_median_train['Title'] == row['Title']) &amp; <br/>        (grouped_median_train['Pclass'] == row['Pclass'])<br/>    ) <br/>    return grouped_median_train[condition]['Age'].values[0]<br/><br/><br/>def process_age():<br/>    global combined<br/>    # a function that fills the missing values of the Age variable<br/>    combined['Age'] = combined.apply(lambda row: fill_age(row) if np.isnan(row['Age']) else row['Age'], axis=1)<br/>    status('age')<br/>    return combined<br/><br/>combined = process_age()</span></pre><p id="b93c" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">完美。缺失的年代已经被取代。</p><p id="8f3e" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">但是，我们注意到票价中有一个缺失值，登机中有两个缺失值，客舱中有许多缺失值。我们稍后将回到这些变量。</p><p id="5605" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">让我们现在处理这些名字。</p><pre class="mo mp mq mr gt ms mt mu mv aw mw bi"><span id="7e5e" class="mx ls jg mt b gy my mz l na nb">def process_names():<br/>    global combined<br/>    # we clean the Name variable<br/>    combined.drop('Name', axis=1, inplace=True)<br/>    <br/>    # encoding in dummy variable<br/>    titles_dummies = pd.get_dummies(combined['Title'], prefix='Title')<br/>    combined = pd.concat([combined, titles_dummies], axis=1)<br/>    <br/>    # removing the title variable<br/>    combined.drop('Title', axis=1, inplace=True)<br/>    <br/>    status('names')<br/>    return combined</span></pre><p id="28e9" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">这个函数删除了Name列，因为我们创建了一个Title列，所以不再使用它。</p><p id="bb0d" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">然后，我们使用虚拟编码对标题值进行编码。</p><pre class="mo mp mq mr gt ms mt mu mv aw mw bi"><span id="348c" class="mx ls jg mt b gy my mz l na nb">combined = process_names()<br/><br/>combined.head()</span></pre><p id="830e" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">如你所见:</p><ul class=""><li id="4286" class="nd ne jg kx b ky kz lb lc le nf li ng lm nh lq ni nj nk nl bi translated">不再有名称功能。</li><li id="a562" class="nd ne jg kx b ky nm lb nn le no li np lm nq lq ni nj nk nl bi translated">出现了新的变量(Title_X)。这些特征是二元的。</li><li id="c06d" class="nd ne jg kx b ky nm lb nn le no li np lm nq lq ni nj nk nl bi translated">例如，如果Title_Mr = 1，则对应的标题是Mr。</li></ul><h1 id="792a" class="lr ls jg bd lt lu lv lw lx ly lz ma mb km mc kn md kp me kq mf ks mg kt mh mi bi translated">加工费</h1><p id="3fe6" class="pw-post-body-paragraph kv kw jg kx b ky mj kh la lb mk kk ld le ml lg lh li mm lk ll lm mn lo lp lq ij bi translated">让我们用列车组上计算的平均票价来估算缺失的票价值</p><pre class="mo mp mq mr gt ms mt mu mv aw mw bi"><span id="cfe7" class="mx ls jg mt b gy my mz l na nb">def process_fares():<br/>    global combined<br/>    # there's one missing fare value - replacing it with the mean.<br/>    combined.Fare.fillna(combined.iloc[:891].Fare.mean(), inplace=True)<br/>    status('fare')<br/>    return combined</span></pre><p id="d91b" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">该函数简单地用平均值替换一个缺失的票价值。</p><pre class="mo mp mq mr gt ms mt mu mv aw mw bi"><span id="8894" class="mx ls jg mt b gy my mz l na nb">combined = process_fares()</span></pre><h1 id="3f90" class="lr ls jg bd lt lu lv lw lx ly lz ma mb km mc kn md kp me kq mf ks mg kt mh mi bi translated">加工已开始</h1><pre class="mo mp mq mr gt ms mt mu mv aw mw bi"><span id="d89e" class="mx ls jg mt b gy my mz l na nb">def process_embarked():<br/>    global combined<br/>    # two missing embarked values - filling them with the most frequent one in the train  set(S)<br/>    combined.Embarked.fillna('S', inplace=True)<br/>    # dummy encoding <br/>    embarked_dummies = pd.get_dummies(combined['Embarked'], prefix='Embarked')<br/>    combined = pd.concat([combined, embarked_dummies], axis=1)<br/>    combined.drop('Embarked', axis=1, inplace=True)<br/>    status('embarked')<br/>    return combined</span></pre><p id="5ef9" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">该功能用最频繁的装载值替换装载的两个缺失值。</p><pre class="mo mp mq mr gt ms mt mu mv aw mw bi"><span id="9c6a" class="mx ls jg mt b gy my mz l na nb">combined = process_embarked()</span><span id="07a5" class="mx ls jg mt b gy nu mz l na nb">combined.head()</span></pre><h1 id="e6d7" class="lr ls jg bd lt lu lv lw lx ly lz ma mb km mc kn md kp me kq mf ks mg kt mh mi bi translated">加工舱</h1><pre class="mo mp mq mr gt ms mt mu mv aw mw bi"><span id="d845" class="mx ls jg mt b gy my mz l na nb">train_cabin, test_cabin = set(), set()</span><span id="91e5" class="mx ls jg mt b gy nu mz l na nb">for c in combined.iloc[:891]['Cabin']:<br/>    try:<br/>        train_cabin.add(c[0])<br/>    except:<br/>        train_cabin.add('U')<br/>        <br/>for c in combined.iloc[891:]['Cabin']:<br/>    try:<br/>        test_cabin.add(c[0])<br/>    except:<br/>        test_cabin.add('U')</span><span id="c2cb" class="mx ls jg mt b gy nu mz l na nb">print(train_cabin)<br/># set(['A', 'C', 'B', 'E', 'D', 'G', 'F', 'U', 'T'])</span><span id="f339" class="mx ls jg mt b gy nu mz l na nb">print(test_cabin)<br/># set(['A', 'C', 'B', 'E', 'D', 'G', 'F', 'U'])</span></pre><p id="65b8" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">我们在测试组中没有任何列车组中不存在的车厢字母。</p><pre class="mo mp mq mr gt ms mt mu mv aw mw bi"><span id="c013" class="mx ls jg mt b gy my mz l na nb">def process_cabin():<br/>    global combined    <br/>    # replacing missing cabins with U (for Uknown)<br/>    combined.Cabin.fillna('U', inplace=True)<br/>    <br/>    # mapping each Cabin value with the cabin letter<br/>    combined['Cabin'] = combined['Cabin'].map(lambda c: c[0])<br/>    <br/>    # dummy encoding ...<br/>    cabin_dummies = pd.get_dummies(combined['Cabin'], prefix='Cabin')    <br/>    combined = pd.concat([combined, cabin_dummies], axis=1)<br/><br/>    combined.drop('Cabin', axis=1, inplace=True)<br/>    status('cabin')<br/>    return combined</span></pre><p id="5316" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">该函数用U替换NaN值(对于未知的<em class="ny"/>)。然后，它将每个Cabin值映射到第一个字母。然后，它再次使用虚拟编码对客舱值进行编码。</p><pre class="mo mp mq mr gt ms mt mu mv aw mw bi"><span id="250a" class="mx ls jg mt b gy my mz l na nb">combined = process_cabin()</span></pre><p id="11f7" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">好了，现在没有丢失值了。</p><pre class="mo mp mq mr gt ms mt mu mv aw mw bi"><span id="6e89" class="mx ls jg mt b gy my mz l na nb">combined.head()</span></pre><h1 id="8929" class="lr ls jg bd lt lu lv lw lx ly lz ma mb km mc kn md kp me kq mf ks mg kt mh mi bi translated">加工性</h1><pre class="mo mp mq mr gt ms mt mu mv aw mw bi"><span id="29ac" class="mx ls jg mt b gy my mz l na nb">def process_sex():<br/>    global combined<br/>    # mapping string values to numerical one <br/>    combined['Sex'] = combined['Sex'].map({'male':1, 'female':0})<br/>    status('Sex')<br/>    return combined</span></pre><p id="3873" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">这个函数将字符串值male和female分别映射到1和0。</p><pre class="mo mp mq mr gt ms mt mu mv aw mw bi"><span id="527e" class="mx ls jg mt b gy my mz l na nb">combined = process_sex()</span></pre><h1 id="997b" class="lr ls jg bd lt lu lv lw lx ly lz ma mb km mc kn md kp me kq mf ks mg kt mh mi bi translated">处理Pclass</h1><pre class="mo mp mq mr gt ms mt mu mv aw mw bi"><span id="8d77" class="mx ls jg mt b gy my mz l na nb">def process_pclass():<br/>    <br/>    global combined<br/>    # encoding into 3 categories:<br/>    pclass_dummies = pd.get_dummies(combined['Pclass'], prefix="Pclass")<br/>    <br/>    # adding dummy variable<br/>    combined = pd.concat([combined, pclass_dummies],axis=1)<br/>    <br/>    # removing "Pclass"<br/>    combined.drop('Pclass',axis=1,inplace=True)<br/>    <br/>    status('Pclass')<br/>    return combined</span></pre><p id="f32c" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">此函数使用虚拟编码对Pclass (1，2，3)的值进行编码。</p><pre class="mo mp mq mr gt ms mt mu mv aw mw bi"><span id="2888" class="mx ls jg mt b gy my mz l na nb">combined = process_pclass()</span></pre><h1 id="409e" class="lr ls jg bd lt lu lv lw lx ly lz ma mb km mc kn md kp me kq mf ks mg kt mh mi bi translated">加工票</h1><p id="40ea" class="pw-post-body-paragraph kv kw jg kx b ky mj kh la lb mk kk ld le ml lg lh li mm lk ll lm mn lo lp lq ij bi translated">让我们首先来看看我们数据集中不同的票据前缀</p><pre class="mo mp mq mr gt ms mt mu mv aw mw bi"><span id="ad64" class="mx ls jg mt b gy my mz l na nb">def cleanTicket(ticket):<br/>    ticket = ticket.replace('.', '')<br/>    ticket = ticket.replace('/', '')<br/>    ticket = ticket.split()<br/>    ticket = map(lambda t : t.strip(), ticket)<br/>    ticket = list(filter(lambda t : not t.isdigit(), ticket))<br/>    if len(ticket) &gt; 0:<br/>        return ticket[0]<br/>    else: <br/>        return 'XXX'<br/><br/>tickets = set()<br/>for t in combined['Ticket']:<br/>    tickets.add(cleanTicket(t))<br/><br/>print(len(tickets))<br/>#37<br/><br/><br/>def process_ticket():<br/>    <br/>    global combined<br/>    <br/>    # a function that extracts each prefix of the ticket, returns 'XXX' if no prefix (i.e the ticket is a digit)<br/>    def cleanTicket(ticket):<br/>        ticket = ticket.replace('.','')<br/>        ticket = ticket.replace('/','')<br/>        ticket = ticket.split()<br/>        ticket = map(lambda t : t.strip(), ticket)<br/>        ticket = filter(lambda t : not t.isdigit(), ticket)<br/>        if len(ticket) &gt; 0:<br/>            return ticket[0]<br/>        else: <br/>            return 'XXX'<br/>    <br/><br/>    # Extracting dummy variables from tickets:<br/><br/>    combined['Ticket'] = combined['Ticket'].map(cleanTicket)<br/>    tickets_dummies = pd.get_dummies(combined['Ticket'], prefix='Ticket')<br/>    combined = pd.concat([combined, tickets_dummies], axis=1)<br/>    combined.drop('Ticket', inplace=True, axis=1)<br/><br/>    status('Ticket')<br/>    return combined<br/><br/>combined = process_ticket()</span></pre><h1 id="8cc5" class="lr ls jg bd lt lu lv lw lx ly lz ma mb km mc kn md kp me kq mf ks mg kt mh mi bi translated">加工系列</h1><p id="791a" class="pw-post-body-paragraph kv kw jg kx b ky mj kh la lb mk kk ld le ml lg lh li mm lk ll lm mn lo lp lq ij bi translated">这一部分包括根据家庭的大小创建新的变量(顺便说一下，大小是我们创建的另一个变量)。</p><p id="b3bb" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">这种新变量的创造是在一个现实的假设下完成的:大家庭聚集在一起，因此他们比独自旅行的人更有可能获救。</p><pre class="mo mp mq mr gt ms mt mu mv aw mw bi"><span id="8814" class="mx ls jg mt b gy my mz l na nb">def process_family():<br/>    <br/>    global combined<br/>    # introducing a new feature : the size of families (including the passenger)<br/>    combined['FamilySize'] = combined['Parch'] + combined['SibSp'] + 1<br/>    <br/>    # introducing other features based on the family size<br/>    combined['Singleton'] = combined['FamilySize'].map(lambda s: 1 if s == 1 else 0)<br/>    combined['SmallFamily'] = combined['FamilySize'].map(lambda s: 1 if 2 &lt;= s &lt;= 4 else 0)<br/>    combined['LargeFamily'] = combined['FamilySize'].map(lambda s: 1 if 5 &lt;= s else 0)<br/>    <br/>    status('family')<br/>    return combined</span></pre><p id="b1c0" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">该功能引入了4项新功能:</p><ul class=""><li id="589b" class="nd ne jg kx b ky kz lb lc le nf li ng lm nh lq ni nj nk nl bi translated">FamilySize:包括乘客本人在内的亲属总数。</li><li id="d9ee" class="nd ne jg kx b ky nm lb nn le no li np lm nq lq ni nj nk nl bi translated">西格顿:描述大小为1的家族的布尔变量</li><li id="6388" class="nd ne jg kx b ky nm lb nn le no li np lm nq lq ni nj nk nl bi translated">SmallFamily:描述2 &lt;= size &lt;= 4的家庭的布尔变量</li><li id="2ff7" class="nd ne jg kx b ky nm lb nn le no li np lm nq lq ni nj nk nl bi translated">LargeFamily:描述5 </li></ul><pre class="mo mp mq mr gt ms mt mu mv aw mw bi"><span id="e65d" class="mx ls jg mt b gy my mz l na nb">combined = process_family()</span><span id="1095" class="mx ls jg mt b gy nu mz l na nb">print(combined.shape)<br/># (1309, 67)</span></pre><p id="b5da" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">我们最终总共有67个特征。</p><pre class="mo mp mq mr gt ms mt mu mv aw mw bi"><span id="6be4" class="mx ls jg mt b gy my mz l na nb">combined.head()</span></pre><h1 id="2c23" class="lr ls jg bd lt lu lv lw lx ly lz ma mb km mc kn md kp me kq mf ks mg kt mh mi bi translated">三——建模</h1><p id="7053" class="pw-post-body-paragraph kv kw jg kx b ky mj kh la lb mk kk ld le ml lg lh li mm lk ll lm mn lo lp lq ij bi translated">在这一部分，我们根据我们创建的特征使用我们对乘客的了解，然后建立一个统计模型。你可以把这个模型想象成一个盒子，它处理任何新乘客的信息，并决定他是否幸存。</p><p id="33f8" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">有各种各样的模型可以使用，从逻辑回归到决策树和更复杂的模型，如随机森林和梯度推进树。</p><p id="9740" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">我们将使用随机森林。随机森林在纸牌游戏中证明了巨大的效率。</p><p id="bae6" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">回到我们的问题，我们现在必须:</p><ol class=""><li id="898d" class="nd ne jg kx b ky kz lb lc le nf li ng lm nh lq nz nj nk nl bi translated">断开训练集和测试集中的组合数据集。</li><li id="cc16" class="nd ne jg kx b ky nm lb nn le no li np lm nq lq nz nj nk nl bi translated">使用训练集建立预测模型。</li><li id="1d01" class="nd ne jg kx b ky nm lb nn le no li np lm nq lq nz nj nk nl bi translated">使用训练集评估模型。</li><li id="965f" class="nd ne jg kx b ky nm lb nn le no li np lm nq lq nz nj nk nl bi translated">使用测试集测试模型，并为提交生成一个输出文件。</li></ol><p id="4d6a" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">请记住，我们将不得不重申2。第三。直到达到可接受的评估分数。</p><p id="e7e1" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">让我们从导入有用的库开始。</p><pre class="mo mp mq mr gt ms mt mu mv aw mw bi"><span id="4d77" class="mx ls jg mt b gy my mz l na nb">from sklearn.pipeline import make_pipeline<br/>from sklearn.ensemble import RandomForestClassifier<br/>from sklearn.ensemble.gradient_boosting import GradientBoostingClassifier<br/>from sklearn.feature_selection import SelectKBest<br/>from sklearn.model_selection import StratifiedKFold<br/>from sklearn.model_selection import GridSearchCV<br/>from sklearn.model_selection import cross_val_score<br/>from sklearn.feature_selection import SelectFromModel<br/>from sklearn.linear_model import LogisticRegression, LogisticRegressionCV</span></pre><p id="ad9e" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">为了评估我们的模型，我们将使用五重交叉验证，因为它是竞争对手在排行榜中使用的指标。</p><p id="936c" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">为此，我们将定义一个小的评分函数。</p><pre class="mo mp mq mr gt ms mt mu mv aw mw bi"><span id="7e27" class="mx ls jg mt b gy my mz l na nb">def compute_score(clf, X, y, scoring='accuracy'):<br/>    xval = cross_val_score(clf, X, y, cv = 5, scoring=scoring)<br/>    return np.mean(xval)</span></pre><p id="4ec4" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">从组合的数据集中恢复训练集和测试集是一项简单的任务。</p><pre class="mo mp mq mr gt ms mt mu mv aw mw bi"><span id="93b6" class="mx ls jg mt b gy my mz l na nb">def recover_train_test_target():<br/>    global combined<br/>    <br/>    targets = pd.read_csv('./data/train.csv', usecols=['Survived'])['Survived'].values<br/>    train = combined.iloc[:891]<br/>    test = combined.iloc[891:]<br/>    <br/>    return train, test, targets<br/><br/>train, test, targets = recover_train_test_target()</span></pre><h1 id="8c5f" class="lr ls jg bd lt lu lv lw lx ly lz ma mb km mc kn md kp me kq mf ks mg kt mh mi bi translated">特征选择</h1><p id="bd79" class="pw-post-body-paragraph kv kw jg kx b ky mj kh la lb mk kk ld le ml lg lh li mm lk ll lm mn lo lp lq ij bi translated">到目前为止，我们已经开发了30多个功能。这个数字相当大。</p><p id="4c81" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">当特征工程完成后，我们通常倾向于通过选择“正确的”数量的捕捉本质的特征来降低维度。</p><p id="4f30" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">事实上，功能选择有很多好处:</p><ul class=""><li id="5de4" class="nd ne jg kx b ky kz lb lc le nf li ng lm nh lq ni nj nk nl bi translated">它减少了数据间的冗余</li><li id="80f2" class="nd ne jg kx b ky nm lb nn le no li np lm nq lq ni nj nk nl bi translated">它加快了训练过程</li><li id="f3ee" class="nd ne jg kx b ky nm lb nn le no li np lm nq lq ni nj nk nl bi translated">它减少了过度拟合</li></ul><p id="176b" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">基于树的估计器可用于计算特征重要性，这又可用于丢弃不相关的特征。</p><pre class="mo mp mq mr gt ms mt mu mv aw mw bi"><span id="42aa" class="mx ls jg mt b gy my mz l na nb">clf = RandomForestClassifier(n_estimators=50, max_features='sqrt')<br/>clf = clf.fit(train, targets)</span></pre><p id="6dd1" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">让我们来看看每个特性的重要性。</p><pre class="mo mp mq mr gt ms mt mu mv aw mw bi"><span id="7127" class="mx ls jg mt b gy my mz l na nb">features = pd.DataFrame()<br/>features['feature'] = train.columns<br/>features['importance'] = clf.feature_importances_<br/>features.sort_values(by=['importance'], ascending=True, inplace=True)<br/>features.set_index('feature', inplace=True)</span><span id="a6b2" class="mx ls jg mt b gy nu mz l na nb">features.plot(kind='barh', figsize=(25, 25))</span></pre><figure class="mo mp mq mr gt is gh gi paragraph-image"><div class="gh gi oa"><img src="../Images/ee117cefcd4cc1e93a00ace3db24aa56.png" data-original-src="https://miro.medium.com/v2/resize:fit:1180/format:webp/0*fzf2J23OZlukbB-f.png"/></div></figure><p id="f458" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">你可能注意到了，头衔、先生、年龄、费用和性别都很重要。</p><p id="bc3b" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">与Passenger_Id还有一个重要的关联。</p><p id="909a" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">现在，让我们将我们的训练集和测试集转换成一个更紧凑的数据集。</p><pre class="mo mp mq mr gt ms mt mu mv aw mw bi"><span id="6ee7" class="mx ls jg mt b gy my mz l na nb">model = SelectFromModel(clf, prefit=True)<br/>train_reduced = model.transform(train)<br/>print(train_reduced.shape)<br/># (891L, 14L)</span><span id="cd00" class="mx ls jg mt b gy nu mz l na nb">test_reduced = model.transform(test)<br/>print(test_reduced.shape)<br/># (418L, 14L)</span><span id="1b0b" class="mx ls jg mt b gy nu mz l na nb">logreg = LogisticRegression()<br/>logreg_cv = LogisticRegressionCV()<br/>rf = RandomForestClassifier()<br/>gboost = GradientBoostingClassifier()<br/><br/>models = [logreg, logreg_cv, rf, gboost]<br/><br/>for model in models:<br/>    print('Cross-validation of : {0}'.format(model.__class__))<br/>    score = compute_score(clf=model, X=train_reduced, y=targets, scoring='accuracy')<br/>    print('CV score = {0}'.format(score))<br/>    print('****')</span></pre><p id="9d9a" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">耶！现在我们减少了很多功能。</p><p id="5516" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">我们会看看我们是否会使用简化版或完整版的列车组。</p><h1 id="6a3e" class="lr ls jg bd lt lu lv lw lx ly lz ma mb km mc kn md kp me kq mf ks mg kt mh mi bi translated">让我们试试不同的基本型号</h1><pre class="mo mp mq mr gt ms mt mu mv aw mw bi"><span id="d985" class="mx ls jg mt b gy my mz l na nb">logreg = LogisticRegression()<br/>logreg_cv = LogisticRegressionCV()<br/>rf = RandomForestClassifier()<br/>gboost = GradientBoostingClassifier()<br/><br/>models = [logreg, logreg_cv, rf, gboost]<br/><br/>for model in models:<br/>    print('Cross-validation of : {0}'.format(model.__class__))<br/>    score = compute_score(clf=model, X=train_reduced, y=targets, scoring='accuracy')<br/>    print('CV score = {0}'.format(score))<br/>    print('****')</span><span id="7904" class="mx ls jg mt b gy nu mz l na nb">Cross-validation of : &lt;class 'sklearn.linear_model.logistic.LogisticRegression'&gt;<br/>CV score = 0.817071431282<br/>****<br/>Cross-validation of : &lt;class 'sklearn.linear_model.logistic.LogisticRegressionCV'&gt;<br/>CV score = 0.819318764148<br/>****<br/>Cross-validation of : &lt;class 'sklearn.ensemble.forest.RandomForestClassifier'&gt;<br/>CV score = 0.805891969854<br/>****<br/>Cross-validation of : &lt;class 'sklearn.ensemble.gradient_boosting.GradientBoostingClassifier'&gt;<br/>CV score = 0.830560996274<br/>****</span></pre><h1 id="7b6e" class="lr ls jg bd lt lu lv lw lx ly lz ma mb km mc kn md kp me kq mf ks mg kt mh mi bi translated">超参数调谐</h1><p id="37c8" class="pw-post-body-paragraph kv kw jg kx b ky mj kh la lb mk kk ld le ml lg lh li mm lk ll lm mn lo lp lq ij bi translated">正如建模部分开始时提到的，我们将使用随机森林模型。它可能不是这个任务的最佳模型，但是我们将展示如何调优。这项工作可以适用于不同的模型。</p><p id="ac76" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">随机森林相当方便。然而，为了获得预测任务的最佳模型，它们确实带有一些要调整的参数。</p><p id="d970" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">要了解更多关于随机森林的信息，您可以参考此<a class="ae jd" href="https://www.analyticsvidhya.com/blog/2015/06/tuning-random-forest-model/" rel="noopener ugc nofollow" target="_blank">链接</a>:</p><p id="8fda" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">此外，我们将使用全套列车。</p><pre class="mo mp mq mr gt ms mt mu mv aw mw bi"><span id="b28d" class="mx ls jg mt b gy my mz l na nb"># turn run_gs to True if you want to run the gridsearch again.<br/>run_gs = False<br/><br/>if run_gs:<br/>    parameter_grid = {<br/>                 'max_depth' : [4, 6, 8],<br/>                 'n_estimators': [50, 10],<br/>                 'max_features': ['sqrt', 'auto', 'log2'],<br/>                 'min_samples_split': [2, 3, 10],<br/>                 'min_samples_leaf': [1, 3, 10],<br/>                 'bootstrap': [True, False],<br/>                 }<br/>    forest = RandomForestClassifier()<br/>    cross_validation = StratifiedKFold(n_splits=5)<br/><br/>    grid_search = GridSearchCV(forest,<br/>                               scoring='accuracy',<br/>                               param_grid=parameter_grid,<br/>                               cv=cross_validation,<br/>                               verbose=1<br/>                              )<br/><br/>    grid_search.fit(train, targets)<br/>    model = grid_search<br/>    parameters = grid_search.best_params_<br/><br/>    print('Best score: {}'.format(grid_search.best_score_))<br/>    print('Best parameters: {}'.format(grid_search.best_params_))<br/>    <br/>else: <br/>    parameters = {'bootstrap': False, 'min_samples_leaf': 3, 'n_estimators': 50, <br/>                  'min_samples_split': 10, 'max_features': 'sqrt', 'max_depth': 6}<br/>    <br/>    model = RandomForestClassifier(**parameters)<br/>    model.fit(train, targets)</span></pre><p id="59cd" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">既然模型是通过扫描超参数的几种组合构建的，我们可以生成一个输出文件提交到Kaggle上。</p><pre class="mo mp mq mr gt ms mt mu mv aw mw bi"><span id="a1f3" class="mx ls jg mt b gy my mz l na nb">output = model.predict(test).astype(int)<br/>df_output = pd.DataFrame()<br/>aux = pd.read_csv('./data/test.csv')<br/>df_output['PassengerId'] = aux['PassengerId']<br/>df_output['Survived'] = output<br/>df_output[['PassengerId','Survived']].to_csv('./predictions/gridsearch_rf.csv', index=False)</span></pre><h1 id="5117" class="lr ls jg bd lt lu lv lw lx ly lz ma mb km mc kn md kp me kq mf ks mg kt mh mi bi translated">四、结论</h1><p id="6d24" class="pw-post-body-paragraph kv kw jg kx b ky mj kh la lb mk kk ld le ml lg lh li mm lk ll lm mn lo lp lq ij bi translated">在本文中，我们探索了由<a class="ae jd" href="http://kaggle.com/" rel="noopener ugc nofollow" target="_blank"> Kaggle </a>带给我们的一个有趣的数据集。</p><p id="1d8b" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">我们经历了数据科学管道的基本砖块:</p><ul class=""><li id="b9bb" class="nd ne jg kx b ky kz lb lc le nf li ng lm nh lq ni nj nk nl bi translated">数据探索和可视化:形成假设的第一步</li><li id="214c" class="nd ne jg kx b ky nm lb nn le no li np lm nq lq ni nj nk nl bi translated">数据清理</li><li id="5db5" class="nd ne jg kx b ky nm lb nn le no li np lm nq lq ni nj nk nl bi translated">特征工程</li><li id="9bb3" class="nd ne jg kx b ky nm lb nn le no li np lm nq lq ni nj nk nl bi translated">特征选择</li><li id="fe03" class="nd ne jg kx b ky nm lb nn le no li np lm nq lq ni nj nk nl bi translated">超参数调谐</li><li id="e17f" class="nd ne jg kx b ky nm lb nn le no li np lm nq lq ni nj nk nl bi translated">提交</li><li id="130d" class="nd ne jg kx b ky nm lb nn le no li np lm nq lq ni nj nk nl bi translated">混合</li></ul><p id="6307" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">关于这个挑战已经写了很多文章，所以很明显还有改进的空间。</p><p id="88d6" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">以下是我对后续步骤的建议:</p><ul class=""><li id="5cee" class="nd ne jg kx b ky kz lb lc le nf li ng lm nh lq ni nj nk nl bi translated">在数据中挖掘更多信息，并最终构建新功能。</li><li id="6852" class="nd ne jg kx b ky nm lb nn le no li np lm nq lq ni nj nk nl bi translated">尝试不同的模型:逻辑回归，梯度推进树，XGboost，…</li><li id="7b39" class="nd ne jg kx b ky nm lb nn le no li np lm nq lq ni nj nk nl bi translated">尝试集成学习技术(堆叠)</li><li id="ab9e" class="nd ne jg kx b ky nm lb nn le no li np lm nq lq ni nj nk nl bi translated">运行自动ML框架</li></ul><p id="e862" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">如果你能找到改进我的解决方案的方法，我会非常高兴。这可能会让我更新文章，并肯定给你的信用。所以请随意发表评论。</p></div></div>    
</body>
</html>