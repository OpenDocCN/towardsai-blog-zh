<html>
<head>
<title>Sound and Acoustic patterns to diagnose COVID [Part 1]</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">声音和声学模式诊断COVID[第1部分]</h1>
<blockquote>原文：<a href="https://pub.towardsai.net/speech-and-acoustic-patterns-to-diagnose-covid-part-1-80f5d36be792?source=collection_archive---------1-----------------------#2022-03-27">https://pub.towardsai.net/speech-and-acoustic-patterns-to-diagnose-covid-part-1-80f5d36be792?source=collection_archive---------1-----------------------#2022-03-27</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><figure class="gl gn jo jp jq jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi jn"><img src="../Images/e32096f018e9e74316d816b6b6086bd7.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*u2DWEHFFVdC1QeHvA0b8pw.jpeg"/></div></div></figure><p id="8d10" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated"><a class="ae kw" href="https://medium.com/@himanp/sound-and-acoustic-patterns-to-diagnose-covid-part-2-85f202d60dcb" rel="noopener"> <em class="kx">将</em> </a>链接到本案例研究的第2部分</p><p id="c17e" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated"><a class="ae kw" href="https://medium.com/@himanp/sound-and-acoustic-patterns-to-diagnose-covid-part-3-624273949804" rel="noopener">将</a>链接到本案例研究的第3部分</p><h1 id="3614" class="ky kz iq bd la lb lc ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv bi translated">理解问题和背景</h1><p id="883d" class="pw-post-body-paragraph jy jz iq ka b kb lw kd ke kf lx kh ki kj ly kl km kn lz kp kq kr ma kt ku kv ij bi translated">在这个案例研究中，我们将尝试建立一个模型，可以使用声音和音频波诊断COVID。这将需要我们设计和构建定制的深度学习模型，可以检测语音/音频的微小变化，以检测出有问题的医疗状况。</p><p id="2c8f" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">任何疾病的早期诊断都是成功治疗的关键。未确诊的疾病每年耗费数百万人的生命和积蓄。如果我们能够找到一种经济、简单的方法来提醒用户他们可能患有的疾病，这将有助于他们尽早寻求医疗咨询，并有效地解决问题。今天，我们可以获得大量数据、大量计算资源，以及深度学习方法的足够进步，可以帮助我们解决这些问题。</p><p id="76c2" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">有一些研究表明，生理变化和生物化学的变化会影响人体发出的声音。在人类历史上，身体的噪音长期用于疾病的诊断。医学研究文献建立了这种联系，从而成为开发基于语音、声音和声学数据的ML解决方案的基础。</p><p id="4f72" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">高精度的ML模型将是传统的基于化学的测试的廉价和快速的替代方案，并且可以大规模生产。我们的目标应该是建立一个由技术驱动的解决方案和当前流行的检测方法组成的生态系统，以有效应对未来的流行病，并改善人们可以获得的医疗服务。</p><h1 id="1b00" class="ky kz iq bd la lb lc ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv bi translated"><strong class="ak">数据集:</strong></h1><p id="cdbe" class="pw-post-body-paragraph jy jz iq ka b kb lw kd ke kf lx kh ki kj ly kl km kn lz kp kq kr ma kt ku kv ij bi translated">理想情况下，对于疾病检测，我们希望用户在他们的智能设备中以以下形式记录声音——咳嗽、朗读一段话以记录语音、定向呼吸声。这可以通过指导主动完成，也可以通过手机或智能助理等智能设备被动记录。我们的数据集将包括咳嗽声，用户可以记录和测试。</p><p id="3b3d" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated"><strong class="ka ir"> <em class="kx">咳嗽声</em> : </strong></p><p id="1bf5" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">核心气道——支气管和气管——通过一种称为咳嗽的强烈反射机制清除分泌或吸入的颗粒。在正常情况下，反射遵循从吸气到呼气的标准过程。它通常由物理和化学输入引发。胸腔压力随着声音和液体的爆炸而释放。这种压力排出导致流体运动、空气湍流和质量振动，从而产生独特的声音。这种声音的频率和带宽取决于许多因素，例如气道路径的直径、密度和排出空气的强度。声音由3个时间阶段组成——爆发、中间和发声。频谱在500赫兹到3.8千赫兹之间。对于使用麦克风记录咳嗽声来说，这已经足够了——这是我们案例研究的一个关键观察点。像COVID和肺炎这样的肺部疾病改变了呼吸道的物理结构，使我们有可能利用咳嗽声来识别它们。围绕使用咳嗽声准确识别百日咳、COPD(慢性阻塞性肺病)、结核病、哮喘和肺炎等疾病，已经有很多积极的研究。</p><p id="4368" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated"><strong class="ka ir">现实世界的挑战和限制</strong></p><p id="46f4" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">数据不容易获得。人们必须花时间提供录音和元数据，以创建一个足够大的数据库。此外，为了让我们的解决方案在现实世界中发挥作用，该模型也应该可以在少量数据上进行训练，这样，在出现新的疫情病毒或新的病毒株时，我们可以快速创建和部署解决方案来解决问题。</p><p id="d703" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">我们必须确保为我们的产品部署的web应用程序应该能够在合理的时间内处理录音。</p><p id="3e90" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">此外，能够向使用我们的web应用程序的用户提供准确的结果是绝对关键的。假阴性将很快摧毁解决方案的可信度。</p><p id="0766" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">在本案例研究中，我们将使用一个小型数据集。</p><p id="d322" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">数据集可从以下网址下载:</p><p id="f817" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">https://data.mendeley.com/datasets/ww5dfy53cw/1<a class="ae kw" href="https://data.mendeley.com/datasets/ww5dfy53cw/1" rel="noopener ugc nofollow" target="_blank"/></p><pre class="mb mc md me gt mf mg mh mi aw mj bi"><span id="94ae" class="mk kz iq mg b gy ml mm l mn mo">#class label distribution</span><span id="67b0" class="mk kz iq mg b gy mp mm l mn mo">x.plot.bar()</span></pre><figure class="mb mc md me gt jr gh gi paragraph-image"><div class="gh gi mq"><img src="../Images/04cf1145757e36315f08f99f4206bded.png" data-original-src="https://miro.medium.com/v2/resize:fit:1360/format:webp/1*cNMSoulZiy2V0bVgWvT_TQ.png"/></div><figcaption class="mr ms gj gh gi mt mu bd b be z dk translated">数据点的分类分布</figcaption></figure><pre class="mb mc md me gt mf mg mh mi aw mj bi"><span id="c048" class="mk kz iq mg b gy ml mm l mn mo">#visualise the wave file</span><span id="1997" class="mk kz iq mg b gy mp mm l mn mo">import librosa as lb<br/>import librosa.display</span><span id="dff1" class="mk kz iq mg b gy mp mm l mn mo">a,b = lb.load('/gdrive/MyDrive/Kaggle/trial_covid/--U7joUcTCo_ 0.000_ 10.000.wav', mono=True)</span><span id="5c04" class="mk kz iq mg b gy mp mm l mn mo">librosa.display.waveplot(y=a, sr=b, max_points=100000.0, color='r', alpha=0.5)</span></pre><figure class="mb mc md me gt jr gh gi paragraph-image"><div class="gh gi mv"><img src="../Images/60fbc597ffa8464515dd1d9eaf85e051.png" data-original-src="https://miro.medium.com/v2/resize:fit:1170/format:webp/1*UUCvnkRIkFCMuLCvmb6eOw.png"/></div><figcaption class="mr ms gj gh gi mt mu bd b be z dk translated">想象波形</figcaption></figure><h1 id="d779" class="ky kz iq bd la lb lc ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv bi translated">EDA、特征提取和对特征的理解</h1><p id="217a" class="pw-post-body-paragraph jy jz iq ka b kb lw kd ke kf lx kh ki kj ly kl km kn lz kp kq kr ma kt ku kv ij bi translated">特征的提取和分析对于发现数据点之间的关系是很重要的。音频不能直接提供给模型，因此提取特征是非常重要的。它以可解释的形式解释嵌入在音频信号中的大部分信息。分类、回归或聚类任务需要从音频中提取特征。时间、频率和振幅是声音信号的三个重要维度。</p><p id="601b" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">一个波完成一个完整周期所需的时间称为它的周期。信号在一秒钟内循环的次数就是频率。频率的倒数是时间周期。频率的度量单位是赫兹。自然界中的许多声音是复杂的，由许多频率合成的，它们可以表示为这些不同频率的叠加。机器学习需要对声音进行矢量化，这是通过测量不同时间声音的振幅来实现的。这种测量称为样本，每秒采集的样本数就是采样率。</p><p id="deb4" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated"><strong class="ka ir">声谱图:</strong></p><p id="cfe1" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">频谱图是音频的可视化，是一种以图像形式查看音频波的方法。嵌入音频的频率形成频谱。频谱是在频域中观察声音的一种方式。声谱图有这些颜色，它们代表了频谱。每种颜色代表频率的强度或振幅。因此，它以色带的形式代表了一段时间内音频波的频谱。较浅的颜色代表高浓度的频率，而较深的颜色意味着低浓度或无浓度。</p><p id="0e9d" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">通过将音频分成时间窗口并在每个窗口上进行傅立叶变换来创建频谱图。每个窗口都转换为分贝单位，以获得更好的结果。</p><p id="478c" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">有趣的是，声音是以一系列数字的形式存储在内存中的，这些数字是振幅。如果我们在一秒钟内采集100个样本，那么1秒钟的音频将被存储为一系列100个数字。</p><pre class="mb mc md me gt mf mg mh mi aw mj bi"><span id="0a2c" class="mk kz iq mg b gy ml mm l mn mo">#Plot wave and its spectrogram</span><span id="c222" class="mk kz iq mg b gy mp mm l mn mo">y,sr = librosa.load('trial_covid/--U7joUcTCo_ 0.000_ 10.000.wav', mono=True)</span><span id="2b8e" class="mk kz iq mg b gy mp mm l mn mo">librosa.display.waveplot(y=y, sr=sr, max_points=100000.0, color='b', alpha=0.5)</span><span id="27af" class="mk kz iq mg b gy mp mm l mn mo">print('\n\n')</span><span id="41c5" class="mk kz iq mg b gy mp mm l mn mo">#short time fourier transform of y, taking absolute values.</span><span id="3c53" class="mk kz iq mg b gy mp mm l mn mo">y_t = np.abs(librosa.stft(y))</span><span id="db28" class="mk kz iq mg b gy mp mm l mn mo">#conversion to decibles</span><span id="7fc9" class="mk kz iq mg b gy mp mm l mn mo">y_t_d = librosa.amplitude_to_db(y_t, ref=np.max)</span><span id="e2ea" class="mk kz iq mg b gy mp mm l mn mo">#plotting</span><span id="7b5c" class="mk kz iq mg b gy mp mm l mn mo">figure, ax = plt.subplots(figsize=(6,5))<br/>spectrogram = librosa.display.specshow(y_t_d, sr=sr, y_axis='linear', x_axis='time', ax=ax )</span><span id="735a" class="mk kz iq mg b gy mp mm l mn mo">ax.set(title='spectrogram')</span><span id="0c67" class="mk kz iq mg b gy mp mm l mn mo">figure.colorbar(spectrogram)</span></pre><figure class="mb mc md me gt jr gh gi paragraph-image"><div class="gh gi mw"><img src="../Images/420e46ce30216fa990c92f5fc185443f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1168/0*4ONJx2mtwb9-VtmA"/></div><figcaption class="mr ms gj gh gi mt mu bd b be z dk translated">来自数据集的咳嗽声的声谱图</figcaption></figure><p id="c065" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated"><strong class="ka ir">过零率:</strong></p><p id="5b97" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">这表示信号前进时符号的变化率。这个特征记录了波从正变到负的次数。这在语音识别中被大量使用。对于打击乐来说，过零率更高，例如开枪、演奏乐器等。</p><pre class="mb mc md me gt mf mg mh mi aw mj bi"><span id="d536" class="mk kz iq mg b gy ml mm l mn mo">#Visualizing zero crossing</span><span id="8f8f" class="mk kz iq mg b gy mp mm l mn mo">#pad false means, y[0] will not be considered as a zero crossing</span><span id="92b6" class="mk kz iq mg b gy mp mm l mn mo">y, sr = librosa.load('trial_covid/--U7joUcTCo_ 0.000_ 10.000.wav', mono=True)</span><span id="0f5a" class="mk kz iq mg b gy mp mm l mn mo">#zooming into the wave<br/>plt.plot(y[8000:8015])<br/>zero_cross_count = librosa.zero_crossings(y[8000:8015], pad=False)</span></pre><figure class="mb mc md me gt jr gh gi paragraph-image"><div class="gh gi mx"><img src="../Images/991eb8174745e245baa5b846866a79cf.png" data-original-src="https://miro.medium.com/v2/resize:fit:1234/format:webp/1*0ErNBvmjnFL99JKnflnYjw.png"/></div><figcaption class="mr ms gj gh gi mt mu bd b be z dk translated">可视化零交叉</figcaption></figure><p id="e6c7" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">在这部分波中有两个交叉点。</p><figure class="mb mc md me gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi my"><img src="../Images/06fe13a8022320954bf4d30cbf8d6b33.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*8fuvaEelkaZKFxwkQyjn2A.png"/></div></div></figure><p id="5208" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated"><strong class="ka ir">光谱质心:</strong></p><p id="662b" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">频谱质心代表音频信号的质量中心，它是使用声音中所有频率的加权平均值计算的。如果声音信号是均匀的，并且从开始到结束具有相同的频率分布，则质心将在中间，然而，如果开始处的频率比结束处的频率高，则质心将向左移动。</p><p id="faf9" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">质心在开始时上升，因为那里的振幅低，给高频部分一个支配的机会。</p><pre class="mb mc md me gt mf mg mh mi aw mj bi"><span id="ec51" class="mk kz iq mg b gy ml mm l mn mo"># Spectral centroid<br/># t frames of the spectrogram will give t centroids.</span><span id="9e7a" class="mk kz iq mg b gy mp mm l mn mo">import sklearn #need for normalization</span><span id="9cb9" class="mk kz iq mg b gy mp mm l mn mo">spec_cent = librosa.feature.spectral_centroid(y,sr=sr)[0]</span><span id="c8ed" class="mk kz iq mg b gy mp mm l mn mo">#frames for visualization</span><span id="3f19" class="mk kz iq mg b gy mp mm l mn mo">l = range(len(spec_cent))</span><span id="bad8" class="mk kz iq mg b gy mp mm l mn mo">frames = librosa.frames_to_time(l)</span><span id="8082" class="mk kz iq mg b gy mp mm l mn mo">spec_cent_nor = sklearn.preprocessing.minmax_scale(spec_cent, axis=0)</span><span id="f9d5" class="mk kz iq mg b gy mp mm l mn mo">librosa.display.waveplot(y,sr=sr,alpha=0.5)</span><span id="a161" class="mk kz iq mg b gy mp mm l mn mo">plt.plot(frames, spec_cent_nor, color='b')</span></pre><figure class="mb mc md me gt jr gh gi paragraph-image"><div class="gh gi mz"><img src="../Images/3f02abbf54331756dee01150dede9584.png" data-original-src="https://miro.medium.com/v2/resize:fit:1076/0*bHlgyToi5Iu1Rz44"/></div><figcaption class="mr ms gj gh gi mt mu bd b be z dk translated">波浪图上的光谱质心图</figcaption></figure><p id="f1d1" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated"><strong class="ka ir">频谱衰减:</strong></p><p id="c635" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">频谱滚降是总频谱能量低于某一百分比的频率。这是可配置的。例如，在频率“F”处，90%的光谱能量位于F以下。</p><pre class="mb mc md me gt mf mg mh mi aw mj bi"><span id="ee66" class="mk kz iq mg b gy ml mm l mn mo">#spectral rolloff - similar to centroid in implementation.</span><span id="53ff" class="mk kz iq mg b gy mp mm l mn mo">spec_rolloff = librosa.feature.spectral_rolloff(y,sr=sr)[0]</span><span id="1c59" class="mk kz iq mg b gy mp mm l mn mo">spec_rolloff_nor = sklearn.preprocessing.minmax_scale(spec_rolloff, axis=0)</span></pre><p id="7819" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated"><strong class="ka ir">梅尔光谱图:</strong></p><p id="aab3" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">这些是基于梅尔标度而不是赫兹标度的光谱图。mel标度使用对数变换频率。转换如下所示:</p><figure class="mb mc md me gt jr gh gi paragraph-image"><div class="gh gi na"><img src="../Images/da5092073af13b3180fbbe72e7598554.png" data-original-src="https://miro.medium.com/v2/resize:fit:1174/0*Af66hY8l1F3tpnsV"/></div></figure><p id="246e" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">对于上面使用的自然对数，系数是1127。如果使用基数为10的对数，系数将会改变。随着频率的增加，mel刻度从赫兹刻度逐渐变小。换句话说，对于以赫兹为单位的较高频率，mel值将会非常缓慢地变化，类似于在s形曲线中发生的情况。这类似于人类对声音的感知。对于人类来说，区分较低频率的声音更容易，但区分较高频率的声音要困难得多。例如，对于人类来说，区分150赫兹的声音和250赫兹的声音比区分1100赫兹和1200赫兹的声音更容易。即使两组声音相差相同，我们对它们的感知也不同。这就是mel scale在机器学习中有用的原因，因为它在声音方面更接近人类的感知。mel标度是赫兹标度的非线性变换，它将赫兹标度划分为多个频段，然后将它们变换为Mel标度中的相应频段。</p><figure class="mb mc md me gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi nb"><img src="../Images/3b94ca15cf82508e5ae6ebcc939ddc8c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Dr8r4pJxZJls96RIj6f9Ew.png"/></div></div><figcaption class="mr ms gj gh gi mt mu bd b be z dk translated">可视化mel和hz标度之间关系的代码</figcaption></figure><figure class="mb mc md me gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi nc"><img src="../Images/2342fe474c30408ba457664644946ab9.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*1aCDPeo_mwMeRA8-"/></div></div><figcaption class="mr ms gj gh gi mt mu bd b be z dk translated">hz与mel的关系</figcaption></figure><p id="4c21" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">从上图中可以看出，随着频率的增加，频率之间的距离在mel标度上减小，这很像人类对声音的感知。较低的频率在mel中具有较高的间隙，而较高的频率具有较小的间隙，例如在0和2000之间，以及6000到8000之间。</p><p id="6d7c" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">mel光谱图是在Mel标度上可视化的，与频率标度相反。这是根本的区别。</p><p id="0c93" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">我们还将振幅转换为分贝，以获得更清晰、更好的输出。</p><p id="65b2" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">Db = 20 * log10(振幅)</p><p id="b269" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">当谈到对声音的感知时，分贝尺度是一个指数尺度。每增加10分贝，对响度的感知就增加10倍。20分贝的声音比10分贝的声音大十倍。使用mel标度表示频率，分贝标度表示能力，我们将声音转换为更接近人类感知，这是深度学习的关键。颜色是用分贝标度表示的，而不是振幅。</p><pre class="mb mc md me gt mf mg mh mi aw mj bi"><span id="6813" class="mk kz iq mg b gy ml mm l mn mo">#create mel spectrograms and conver to decibel scale.</span><span id="7916" class="mk kz iq mg b gy mp mm l mn mo">y_spec = librosa.amplitude_to_db(librosa.feature.melspectrogram(y))</span><span id="52c2" class="mk kz iq mg b gy mp mm l mn mo">#plot mel spectrogram</span><span id="d024" class="mk kz iq mg b gy mp mm l mn mo">figure, ax = plt.subplots(figsize=(10,5))</span><span id="26d2" class="mk kz iq mg b gy mp mm l mn mo">ax.set(title = 'mel spectrogram' )</span><span id="b096" class="mk kz iq mg b gy mp mm l mn mo">f= librosa.display.specshow(y_spec,ax=ax)</span><span id="3e48" class="mk kz iq mg b gy mp mm l mn mo">plt.colorbar(f)</span></pre><figure class="mb mc md me gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi nd"><img src="../Images/c7c61db3f585b8c1d1c08bcf44eed5ca.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*8jOwZiEQ-idWY8fc"/></div></div><figcaption class="mr ms gj gh gi mt mu bd b be z dk translated">梅尔光谱图</figcaption></figure><p id="6f40" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">创建频谱图时，最小频率、最大频率、时间窗口长度、频带数量和跳跃长度(每步滑动时间窗口的样本数量)成为超参数。</p><p id="e887" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated"><strong class="ka ir"> Mel频率倒谱系数(MFCC)</strong>已经被广泛用于处理音频信号，尤其是语音。从而使它成为我们案例研究中的一个候选特征。对mel谱图值使用离散余弦变换来生成MFCCs。系数的数量是一个超参数，并调整到一个问题。MFCCs被成功地应用于语音识别问题。Libros库的默认值是20。MFCC从声谱图中提取最重要的特征，声谱图定义了人类感知的音频质量。</p><pre class="mb mc md me gt mf mg mh mi aw mj bi"><span id="98fe" class="mk kz iq mg b gy ml mm l mn mo">#Visualising Mel frequecy cepstral coeffs</span><span id="2aad" class="mk kz iq mg b gy mp mm l mn mo">#create MFCC</span><span id="b0a3" class="mk kz iq mg b gy mp mm l mn mo">y_mfcc = librosa.feature.mfcc(y)</span><span id="c9a9" class="mk kz iq mg b gy mp mm l mn mo">#plot MFCC</span><span id="c199" class="mk kz iq mg b gy mp mm l mn mo">figure, ax = plt.subplots(figsize=(10,5))</span><span id="1cb9" class="mk kz iq mg b gy mp mm l mn mo">ax.set(title = 'MFCCS' )</span><span id="5808" class="mk kz iq mg b gy mp mm l mn mo">f= librosa.display.specshow(y_mfcc,ax=ax,x_axis='time')</span><span id="c9dd" class="mk kz iq mg b gy mp mm l mn mo">plt.colorbar(f)</span></pre><figure class="mb mc md me gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi gj"><img src="../Images/e30d161f4ce8cdec2d1b2c9ec129abfb.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*kDhBWlAOmr4U0j7s"/></div></div><figcaption class="mr ms gj gh gi mt mu bd b be z dk translated">可视化MFCCs</figcaption></figure><p id="df4b" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated"><strong class="ka ir">色谱图和色度频率:</strong></p><p id="a169" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">音高是声音高度的度量。高音有高音，低音有低音。每种声音属于七个音高等级。</p><p id="6433" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">色度过滤器用于创建色谱图。滤波器将录制声音的能量投射到12个箱中——音符和按键。热图可以用来显示音高随时间的变化。通过在滤波器和傅立叶变换频谱图之间取点积，声音可以用一组音高来映射。</p><pre class="mb mc md me gt mf mg mh mi aw mj bi"><span id="6b5c" class="mk kz iq mg b gy ml mm l mn mo">#chroma filter banks</span><span id="cbf1" class="mk kz iq mg b gy mp mm l mn mo"># taking 'sr' and 'n_fft' as 22050 and 4096 respectively</span><span id="9b94" class="mk kz iq mg b gy mp mm l mn mo">chroma_filter_bank = librosa.filters.chroma(22050 , 4096)</span><span id="ee2a" class="mk kz iq mg b gy mp mm l mn mo">librosa.display.specshow(chroma_filter_bank)</span></pre><figure class="mb mc md me gt jr gh gi paragraph-image"><div class="gh gi ne"><img src="../Images/8a43fe97abf20420b2e781af18b507ee.png" data-original-src="https://miro.medium.com/v2/resize:fit:1304/format:webp/1*EQyvAmk4Ps8TlR__r9CfBw.png"/></div><figcaption class="mr ms gj gh gi mt mu bd b be z dk translated">色度过滤器</figcaption></figure><pre class="mb mc md me gt mf mg mh mi aw mj bi"><span id="7faf" class="mk kz iq mg b gy ml mm l mn mo">#chroma features of our sound wave</span><span id="9f67" class="mk kz iq mg b gy mp mm l mn mo">y_chroma = librosa.feature.chroma_stft(y, sr=sr)</span><span id="f052" class="mk kz iq mg b gy mp mm l mn mo">librosa.display.specshow(y_chroma, y_axis='chroma', x_axis='time')</span></pre><figure class="mb mc md me gt jr gh gi paragraph-image"><div class="gh gi nf"><img src="../Images/a57ad22b0580b582b047f458dcd52751.png" data-original-src="https://miro.medium.com/v2/resize:fit:1054/0*cWZmyCxJs4w4Swj5"/></div><figcaption class="mr ms gj gh gi mt mu bd b be z dk translated">色谱图</figcaption></figure><p id="29a5" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated"><strong class="ka ir">结论:</strong></p><p id="1867" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">在这一部分中，我们看到了问题、数据集，并看到了有助于我们在其上建立机器学习模型的特征。</p><p id="85f0" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">在下一部分中，我们将提取这些特性，并对它们进行一些EDA。</p><p id="8a93" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated"><strong class="ka ir">参考文献:</strong></p><ol class=""><li id="0db5" class="ng nh iq ka b kb kc kf kg kj ni kn nj kr nk kv nl nm nn no bi translated">使用梅尔频率倒谱系数和卷积神经网络对新冠肺炎咳嗽进行高精度分类，使用案例为Dunne等人的智能家居设备<a class="ae kw" href="https://www.researchgate.net/publication/343896485_High_accuracy_classification_of_COVID-19_coughs_using_Mel-frequency_cepstral_coefficients_and_a_Convolutional_Neural_Network_with_a_use_case_for_smart_home_devices" rel="noopener ugc nofollow" target="_blank"> <em class="kx">链接此处</em> </a></li><li id="e64c" class="ng nh iq ka b kb np kf nq kj nr kn ns kr nt kv nl nm nn no bi translated">cos wara-Sharma等人的用于新冠肺炎诊断的呼吸、咳嗽和声音数据库<a class="ae kw" href="https://arxiv.org/abs/2005.10548" rel="noopener ugc nofollow" target="_blank"> <em class="kx">链接此处</em> </a></li><li id="b528" class="ng nh iq ka b kb np kf nq kj nr kn ns kr nt kv nl nm nn no bi translated">新冠肺炎人工智能诊断仅使用Laguarta等人的咳嗽录音<a class="ae kw" href="https://www.researchgate.net/publication/344930557_COVID-19_Artificial_Intelligence_Diagnosis_using_only_Cough_Recordings" rel="noopener ugc nofollow" target="_blank"> <em class="kx">链接此处</em> </a></li></ol></div></div>    
</body>
</html>