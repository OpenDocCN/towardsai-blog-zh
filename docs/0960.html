<html>
<head>
<title>Beginner’s Guide to Understanding Convolutional Neural Networks</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">理解卷积神经网络的初学者指南</h1>
<blockquote>原文：<a href="https://pub.towardsai.net/beginners-guide-to-understanding-convolutional-neural-networks-b45386db207b?source=collection_archive---------2-----------------------#2020-09-22">https://pub.towardsai.net/beginners-guide-to-understanding-convolutional-neural-networks-b45386db207b?source=collection_archive---------2-----------------------#2020-09-22</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><h2 id="4826" class="io ip iq bd b dl ir is it iu iv iw dk ix translated" aria-label="kicker paragraph"><a class="ae ep" href="https://towardsai.net/p/category/machine-learning/deep-learning" rel="noopener ugc nofollow" target="_blank">深度学习</a></h2><div class=""/><p id="e1f4" class="pw-post-body-paragraph jw jx iq jy b jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ij bi translated">你好。因为你点击进入这个博客，意味着你听说过卷积神经网络(CNN)，但不能真正掌握它的想法，并正在寻找更多的信息，对不对？让我们以自上而下的方式深入这个话题——从大图到CNN的每个组成部分。</p><h1 id="dccb" class="ku kv iq bd kw kx ky kz la lb lc ld le lf lg lh li lj lk ll lm ln lo lp lq lr bi translated">定义</h1><p id="3a1f" class="pw-post-body-paragraph jw jx iq jy b jz ls kb kc kd lt kf kg kh lu kj kk kl lv kn ko kp lw kr ks kt ij bi translated">CNN是一类深度前馈(非递归)人工神经网络，用于分析视觉图像。</p><h1 id="741f" class="ku kv iq bd kw kx ky kz la lb lc ld le lf lg lh li lj lk ll lm ln lo lp lq lr bi translated">阅读前需要注意的事项</h1><ol class=""><li id="6e6c" class="lx ly iq jy b jz ls kd lt kh lz kl ma kp mb kt mc md me mf bi translated"><strong class="jy ja">图像</strong>只是像素值的矩阵。</li><li id="9db6" class="lx ly iq jy b jz mg kd mh kh mi kl mj kp mk kt mc md me mf bi translated"><strong class="jy ja">通道</strong>是一个常规术语，用于指代图像的某个组件。来自标准数码相机的图像将有三个通道——红色、绿色和蓝色(RGB)。你可以把它们想象成三个互相堆叠的2D矩阵(每种颜色一个)。<br/>而灰度图像只有一个通道。<br/>矩阵中每个像素的值的范围将从0到255。</li></ol><h1 id="eb67" class="ku kv iq bd kw kx ky kz la lb lc ld le lf lg lh li lj lk ll lm ln lo lp lq lr bi translated">CNN分为两个主要部分:</h1><ol class=""><li id="d069" class="lx ly iq jy b jz ls kd lt kh lz kl ma kp mb kt mc md me mf bi translated">这里将介绍特征学习<br/>的基本组件，如<strong class="jy ja">卷积层</strong>和<strong class="jy ja">池层</strong>。<br/>其他组件如<strong class="jy ja">丢失</strong>和<strong class="jy ja"> 1x1卷积</strong>也将被讨论，以给出CNN如何能够建立<em class="ml">深度</em>的感觉。</li><li id="fd0a" class="lx ly iq jy b jz mg kd mh kh mi kl mj kp mk kt mc md me mf bi translated">具有学习特征的任务预测<br/>取决于你希望CNN执行的任务——分类、回归、分段等。为了让这篇文章对初学者友好，我们将只讨论<strong class="jy ja">分类。</strong></li></ol><h1 id="1ca5" class="ku kv iq bd kw kx ky kz la lb lc ld le lf lg lh li lj lk ll lm ln lo lp lq lr bi translated">卷积层</h1><figure class="mn mo mp mq gt mr gh gi paragraph-image"><div class="gh gi mm"><img src="../Images/0e7de8a67e0c197106c87d417e45b499.png" data-original-src="https://miro.medium.com/v2/resize:fit:1052/1*ZCjPUFrB6eHPRi4eyP6aaA.gif"/></div><figcaption class="mu mv gj gh gi mw mx bd b be z dk translated">GIF来说明卷积。(<a class="ae my" href="https://cs231n.github.io/convolutional-networks/" rel="noopener ugc nofollow" target="_blank">来源</a>)</figcaption></figure><p id="5177" class="pw-post-body-paragraph jw jx iq jy b jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ij bi translated">为简单起见，图像用0和1像素值表示。<br/>在GIF中，一个3×3的黄色方框是用于对图像进行卷积的过滤器，这个过滤器是一个“X”检测器，它的作用类似于一个<strong class="jy ja">滑动窗口</strong>并执行<strong class="jy ja">逐元素乘法</strong>来搜索图像中的“X”图案。如果图像中的某个部分看起来像“X”，则下一层中该部分的卷积特征(特征图/激活图，这些术语可互换使用)的值将会很高。</p><p id="45e1" class="pw-post-body-paragraph jw jx iq jy b jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ij bi translated">如果要检测更多的模式，将需要更多类型的过滤器。这里是下一层的<strong class="jy ja">深度</strong>进入的部分。假设您使用3个过滤器，即“X”、“O”和“I”检测器来滑过图像，那么网络的下一层将是深度=3。(更多解释见下文)</p><p id="a956" class="pw-post-body-paragraph jw jx iq jy b jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ij bi translated">滤光器也可以是用于检测颜色对比度、纹理等的滤光器。在这些图像中，<em class="ml">取决于您希望CNN学习的预测任务</em>。</p><figure class="mn mo mp mq gt mr gh gi paragraph-image"><div class="gh gi mz"><img src="../Images/a2822801257226223616a589ab42ca70.png" data-original-src="https://miro.medium.com/v2/resize:fit:866/format:webp/1*4bkq6f6ZU3PkPzEHXfJrLQ.png"/></div><figcaption class="mu mv gj gh gi mw mx bd b be z dk translated">过滤器的例子对图像执行操作。</figcaption></figure><h1 id="3084" class="ku kv iq bd kw kx ky kz la lb lc ld le lf lg lh li lj lk ll lm ln lo lp lq lr bi translated">控制每个卷积层行为的超参数:</h1><ol class=""><li id="6be3" class="lx ly iq jy b jz ls kd lt kh lz kl ma kp mb kt mc md me mf bi translated">进展</li><li id="6108" class="lx ly iq jy b jz mg kd mh kh mi kl mj kp mk kt mc md me mf bi translated">填料</li><li id="b817" class="lx ly iq jy b jz mg kd mh kh mi kl mj kp mk kt mc md me mf bi translated">过滤器数量(下一层的深度)</li><li id="2026" class="lx ly iq jy b jz mg kd mh kh mi kl mj kp mk kt mc md me mf bi translated">过滤器的尺寸</li></ol><h1 id="ac7c" class="ku kv iq bd kw kx ky kz la lb lc ld le lf lg lh li lj lk ll lm ln lo lp lq lr bi translated">进展</h1><p id="6da1" class="pw-post-body-paragraph jw jx iq jy b jz ls kb kc kd lt kf kg kh lu kj kk kl lv kn ko kp lw kr ks kt ij bi translated">步幅是图像中滤镜移动的量。步幅越大，下一层的特征图越小。</p><figure class="mn mo mp mq gt mr gh gi paragraph-image"><div class="gh gi na"><img src="../Images/37ba35080828be9e58df96a9aeb2e926.png" data-original-src="https://miro.medium.com/v2/resize:fit:1188/format:webp/0*xgDU2SubxqbuhOE_.png"/></div><figcaption class="mu mv gj gh gi mw mx bd b be z dk translated">步幅= 1时的卷积示例。</figcaption></figure><figure class="mn mo mp mq gt mr gh gi paragraph-image"><div class="gh gi nb"><img src="../Images/11bbee7ab21bc3de65c72f2e34329319.png" data-original-src="https://miro.medium.com/v2/resize:fit:1254/format:webp/0*lLObfXD688RRzQsy.png"/></div><figcaption class="mu mv gj gh gi mw mx bd b be z dk translated">步幅= 2时的卷积示例。</figcaption></figure><p id="f29a" class="pw-post-body-paragraph jw jx iq jy b jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ij bi translated">运行过滤器所需的时间=((图像的高度*宽度)/步幅</p><h1 id="cf44" class="ku kv iq bd kw kx ky kz la lb lc ld le lf lg lh li lj lk ll lm ln lo lp lq lr bi translated">填料</h1><figure class="mn mo mp mq gt mr gh gi paragraph-image"><div class="gh gi nc"><img src="../Images/ee20a0890ffbfbfa940644b33fd43911.png" data-original-src="https://miro.medium.com/v2/resize:fit:530/format:webp/1*x5eQUEasvbOfzgIyf884og.png"/></div><figcaption class="mu mv gj gh gi mw mx bd b be z dk translated">32x32x3图像上填充= 2的示例。</figcaption></figure><p id="ded5" class="pw-post-body-paragraph jw jx iq jy b jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ij bi translated">示例图像中的填充也称为<strong class="jy ja">相同卷积</strong>。<br/>输入体积是32×32×3，加上填充，我们得到36×36×3的图像尺寸。然后，我们使用3个5x5x3滤波器和1的步长进行卷积，我们将得到32x32x3作为下一层的输出音量。</p><figure class="mn mo mp mq gt mr gh gi paragraph-image"><div class="gh gi nd"><img src="../Images/9f0ea2849cfc36dbea54441253238c47.png" data-original-src="https://miro.medium.com/v2/resize:fit:810/format:webp/1*8Gd2MAokcWLzGV1jQrfZHQ.png"/></div><figcaption class="mu mv gj gh gi mw mx bd b be z dk translated">卷积公式。输出和输入表示高度或宽度的大小。</figcaption></figure><blockquote class="ne nf ng"><p id="47a7" class="jw jx ml jy b jz ka kb kc kd ke kf kg nh ki kj kk ni km kn ko nj kq kr ks kt ij bi translated"><strong class="jy ja">对步幅的限制。</strong>再次注意，超参数的空间排列具有相互约束。例如，当<br/>输入的大小为10，没有使用零填充P=0，并且filterSize为3时，则不可能使用步长S=2，因为<br/>(wf+2P)/S+1 =(103+0)/2+1 = 4.5，即不是一个整数，表明神经元没有整齐对称地“适应”输入。<br/>因此，超参数的这种设置被认为是无效的，并且ConvNet库可以抛出一个异常或用零填充其余部分以使其适合，或者裁剪输入以使其适合，等等。</p></blockquote><h1 id="1a9f" class="ku kv iq bd kw kx ky kz la lb lc ld le lf lg lh li lj lk ll lm ln lo lp lq lr bi translated">过滤器数量(下一层的深度)</h1><p id="d82f" class="pw-post-body-paragraph jw jx iq jy b jz ls kb kc kd lt kf kg kh lu kj kk kl lv kn ko kp lw kr ks kt ij bi translated">示例:6x6x3图像，带4个3x3滤镜。卷积后，将得到4x4xn，n取决于您使用的滤波器的数量，换句话说，它是您使用的特征检测器的数量。在这种情况下，n将是4。</p><h1 id="7327" class="ku kv iq bd kw kx ky kz la lb lc ld le lf lg lh li lj lk ll lm ln lo lp lq lr bi translated">过滤器的尺寸</h1><p id="ae4f" class="pw-post-body-paragraph jw jx iq jy b jz ls kb kc kd lt kf kg kh lu kj kk kl lv kn ko kp lw kr ks kt ij bi translated">滤光器的尺寸通常是奇数<strong class="jy ja">以便滤光器具有<strong class="jy ja">中心像素/中心视觉</strong>从而知道滤光器的位置。如果过滤器的大小是均匀的，那么你需要一些不对称的填充。</strong></p><blockquote class="nk"><p id="be2c" class="nl nm iq bd nn no np nq nr ns nt kt dk translated">卷积层的权重/参数是卷积层中滤波器的值。这些是CNN内部可以学习的价值观。</p></blockquote></div><div class="ab cl nu nv hu nw" role="separator"><span class="nx bw bk ny nz oa"/><span class="nx bw bk ny nz oa"/><span class="nx bw bk ny nz"/></div><div class="ij ik il im in"><p id="a244" class="pw-post-body-paragraph jw jx iq jy b jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ij bi translated">在执行卷积之后，将应用一个<strong class="jy ja">激活函数</strong>来将非线性引入特征图。<br/>我们应用<strong class="jy ja">非线性</strong>的原因是<strong class="jy ja">卷积是一种线性运算</strong>——逐元素的矩阵乘法和加法，因此我们通过引入类似ReLU的非线性函数来说明非线性，防止模型计算线性函数，这将是一个糟糕的模型(<strong class="jy ja">因为模型将无法处理复杂的非线性问题</strong>)。更多激活功能将在另一篇文章中讨论，查看我的个人资料！</p></div><div class="ab cl nu nv hu nw" role="separator"><span class="nx bw bk ny nz oa"/><span class="nx bw bk ny nz oa"/><span class="nx bw bk ny nz"/></div><div class="ij ik il im in"><h1 id="cbc5" class="ku kv iq bd kw kx ob kz la lb oc ld le lf od lh li lj oe ll lm ln of lp lq lr bi translated">汇集层</h1><p id="7e62" class="pw-post-body-paragraph jw jx iq jy b jz ls kb kc kd lt kf kg kh lu kj kk kl lv kn ko kp lw kr ks kt ij bi translated">空间池(也称为子采样或下采样)降低了每个特征图的维度，并保留了图像中最重要的信息。空间池可以有不同的类型:最大、平均、总和等。</p><blockquote class="nk"><p id="f284" class="nl nm iq bd nn no np nq nr ns nt kt dk translated">在实践中，最大池已被证明工作得更好。</p></blockquote><p id="e772" class="pw-post-body-paragraph jw jx iq jy b jz og kb kc kd oh kf kg kh oi kj kk kl oj kn ko kp ok kr ks kt ij bi translated">最大池是最受欢迎的。这基本上需要一个过滤器(例如:大小为2x2)和一个相同长度的步幅(长度为2)。然后将其应用于输入体积，并输出滤波器所卷积的每个子区域中的最大数量。最大池的输出大小公式与卷积公式相同。</p><p id="3293" class="pw-post-body-paragraph jw jx iq jy b jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ij bi translated">池层没有任何可学习的参数，因此在CNN中添加更多池层不会直接增加模型的复杂性。</p><figure class="mn mo mp mq gt mr gh gi paragraph-image"><div class="gh gi ol"><img src="../Images/38633876282e2b75bbc513fa01a8651f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1204/format:webp/0*KxpARsMRPiIfVhPb.png"/></div><figcaption class="mu mv gj gh gi mw mx bd b be z dk translated">最大池插图。(<a class="ae my" href="https://cs231n.github.io/convolutional-networks/" rel="noopener ugc nofollow" target="_blank">来源</a>)</figcaption></figure><p id="ebed" class="pw-post-body-paragraph jw jx iq jy b jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ij bi translated">汇集的功能是逐渐减小输入表示的空间大小(长度和宽度变化，但深度不变)。<br/>具体来说，汇集:</p><ol class=""><li id="e5ec" class="lx ly iq jy b jz ka kd ke kh om kl on kp oo kt mc md me mf bi translated">使输入表示(要素尺寸)更小且更易于管理。</li><li id="db9e" class="lx ly iq jy b jz mg kd mh kh mi kl mj kp mk kt mc md me mf bi translated">减少网络中参数和计算的数量，从而控制过拟合。</li><li id="1721" class="lx ly iq jy b jz mg kd mh kh mi kl mj kp mk kt mc md me mf bi translated">使网络对输入图像中的小变换、扭曲和平移保持不变(输入中的小扭曲不会改变池化的输出，因为我们在局部邻域中取最大值/平均值)。</li></ol><h1 id="339c" class="ku kv iq bd kw kx ky kz la lb lc ld le lf lg lh li lj lk ll lm ln lo lp lq lr bi translated">脱落层</h1><p id="9a06" class="pw-post-body-paragraph jw jx iq jy b jz ls kb kc kd lt kf kg kh lu kj kk kl lv kn ko kp lw kr ks kt ij bi translated"><em class="ml">(不在CNN的传统架构中，但非常有用，因为它对解决过拟合问题很有帮助)</em></p><p id="3ae6" class="pw-post-body-paragraph jw jx iq jy b jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ij bi translated">辍学的想法本质上是简单化的。该层通过在训练期间将它们设置为零来“丢弃”该层中的一组随机激活图。就这么简单。</p><p id="9c14" class="pw-post-body-paragraph jw jx iq jy b jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ij bi translated">那么，这样一个简单且看似不必要、反直觉的过程有什么好处呢？嗯，在某种程度上，它迫使网络冗余。我的意思是网络应该能够为一个特定的例子提供正确的分类或输出，即使一些激活图被遗漏了。它确保网络不会过于“适应”训练数据，从而有助于缓解过度适应问题。<br/> <strong class="jy ja">一个重要的注意事项是，这一层只在训练时使用，而不在测试时使用。</strong></p><h1 id="aaa8" class="ku kv iq bd kw kx ky kz la lb lc ld le lf lg lh li lj lk ll lm ln lo lp lq lr bi translated">网络层中的网络(1x1卷积)</h1><p id="d40d" class="pw-post-body-paragraph jw jx iq jy b jz ls kb kc kd lt kf kg kh lu kj kk kl lv kn ko kp lw kr ks kt ij bi translated"><em class="ml">(不在CNN的传统架构中，但非常有用，因为它有助于生成更多功能，并以计算成本低廉的方式使网络更深入。)</em></p><p id="266a" class="pw-post-body-paragraph jw jx iq jy b jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ij bi translated">网络中的网络层指的是具有1×1大小过滤器的卷积层。-1x1卷积跨越一定的深度，因此我们可以将其视为1 x 1 x N卷积，其中N是层中应用的滤镜数量。实际上，该层正在执行N-D元素式乘法，其中N是输入体积进入该层的深度。</p><p id="e050" class="pw-post-body-paragraph jw jx iq jy b jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ij bi translated">例如:<br/>如果前一层有128个特征图，那么“1x1卷积”是所有这些特征图的卷积，每个特征图具有大小为1x1x128的过滤器。假设选择64个这样的1×1×128暗滤光器，那么结果将是64个特征地图，每个与之前的尺寸相同。在所有要素地图上使用单一学习过滤器(绑定权重),将每个输出要素地图作为“每像素”投影(点积)查看到低维空间。基本上，他们只是将128个特征图(对128个学习过滤器的代表性反应)压缩成64个特征图，忽略了空间维度。</p><p id="e33d" class="pw-post-body-paragraph jw jx iq jy b jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ij bi translated">请记住，像3x3x128过滤器这样的较大过滤器也将学习汇总所有要素地图的要素响应，因此以这种方式，所有大小的过滤器都做相同的事情。唯一的区别是1x1(学习的)过滤器仅在特征地图上这样做，其中3x3过滤器也考虑局部空间相关性。</p><p id="e2b7" class="pw-post-body-paragraph jw jx iq jy b jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ij bi translated">所以，用它有两个原因:<br/> 1。降维:<br/>当对大量特征图执行较大尺寸的卷积(空间3×3或5×5…)时，降低深度维度(#特征图)会显著减少计算量。这是在<a class="ae my" href="https://www.quora.com/How-does-the-Inception-module-work-in-GoogLeNet-deep-architecture" rel="noopener ugc nofollow" target="_blank"> GoogLeNet初始模块</a>中完成的，以便在不过度拟合的情况下使网络更深入。</p><p id="fd11" class="pw-post-body-paragraph jw jx iq jy b jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ij bi translated">2.由于将再次应用激活函数，因此将非线性应用于模型，从而使模型更加复杂，并且对复杂问题更加稳健。</p><figure class="mn mo mp mq gt mr gh gi paragraph-image"><div role="button" tabindex="0" class="oq or di os bf ot"><div class="gh gi op"><img src="../Images/c355d9345882ce841e7106acd55edd56.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*CgjHZ4aBgeekizDw.png"/></div></div><figcaption class="mu mv gj gh gi mw mx bd b be z dk translated">将特征学习部分的组件放在一起的图示。</figcaption></figure></div><div class="ab cl nu nv hu nw" role="separator"><span class="nx bw bk ny nz oa"/><span class="nx bw bk ny nz oa"/><span class="nx bw bk ny nz"/></div><div class="ij ik il im in"><h1 id="f2ee" class="ku kv iq bd kw kx ob kz la lb oc ld le lf od lh li lj oe ll lm ln of lp lq lr bi translated">分类</h1><p id="22fd" class="pw-post-body-paragraph jw jx iq jy b jz ls kb kc kd lt kf kg kh lu kj kk kl lv kn ko kp lw kr ks kt ij bi translated">卷积层的输出代表数据中的高级特征。虽然该输出可以展平并连接到输出图层，但添加全连接图层是一种(通常)获取这些要素的非线性组合的廉价方式。</p><p id="5558" class="pw-post-body-paragraph jw jx iq jy b jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ij bi translated">本质上，卷积层提供了一个有意义的、低维的、某种程度上不变的特征空间，并且全连接层正在该空间中学习一个(可能是非线性的)函数。</p><p id="fac8" class="pw-post-body-paragraph jw jx iq jy b jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ij bi translated">正常情况下，用于分类的管道是全连接层，它从展平步骤开始，然后是全连接层(这是一个充满连接来做分类的层，也称为密集层)，并附加有softmax函数。</p><h1 id="5b56" class="ku kv iq bd kw kx ky kz la lb lc ld le lf lg lh li lj lk ll lm ln lo lp lq lr bi translated">变平</h1><p id="085d" class="pw-post-body-paragraph jw jx iq jy b jz ls kb kc kd lt kf kg kh lu kj kk kl lv kn ko kp lw kr ks kt ij bi translated">CNN卷积部分的输出被转换成1D特征向量，供全连接层使用。这种操作称为展平。它获得卷积层的输出，展平其所有结构以创建单个长特征向量，供全连接层用于最终分类。</p><h1 id="ca4e" class="ku kv iq bd kw kx ky kz la lb lc ld le lf lg lh li lj lk ll lm ln lo lp lq lr bi translated">全连接层</h1><p id="e997" class="pw-post-body-paragraph jw jx iq jy b jz ls kb kc kd lt kf kg kh lu kj kk kl lv kn ko kp lw kr ks kt ij bi translated">完全连接层中的神经元与前一层中的所有激活具有完全连接，如在常规神经网络中所见。(当一层中的所有节点激活到下一层中的每个节点时。当第L层中的所有节点都连接到第(L+1)层中的所有节点时，我们称这些层为全连接层。)</p><p id="fdcf" class="pw-post-body-paragraph jw jx iq jy b jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ij bi translated"><strong class="jy ja">在该层中，权重和偏差与正常神经网络相同，使用成本来计算损失函数，使用梯度下降来优化参数，并降低成本函数。</strong></p><h1 id="1ab2" class="ku kv iq bd kw kx ky kz la lb lc ld le lf lg lh li lj lk ll lm ln lo lp lq lr bi translated">Softmax函数</h1><p id="c4f1" class="pw-post-body-paragraph jw jx iq jy b jz ls kb kc kd lt kf kg kh lu kj kk kl lv kn ko kp lw kr ks kt ij bi translated">这是我们可以用来在神经网络中进行分类的方法之一。然后，全连接层的输出通过softmax函数传递。<a class="ae my" href="http://cs231n.github.io/linear-classify/#softmax" rel="noopener ugc nofollow" target="_blank"> Softmax </a>函数获取任意实值分数的向量，并将其压缩为介于零和一之间的值的向量，总和为一。</p><h1 id="7e66" class="ku kv iq bd kw kx ky kz la lb lc ld le lf lg lh li lj lk ll lm ln lo lp lq lr bi translated">将所有东西放在一起:</h1><figure class="mn mo mp mq gt mr gh gi paragraph-image"><div role="button" tabindex="0" class="oq or di os bf ot"><div class="gh gi ou"><img src="../Images/4cc34264c6d3e0fad2a61c13226a5f0e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*bYlcS6GpW0T2ZoQL.png"/></div></div><figcaption class="mu mv gj gh gi mw mx bd b be z dk translated">卷积神经网络图解。</figcaption></figure><p id="a8b4" class="pw-post-body-paragraph jw jx iq jy b jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ij bi translated">文章到此结束，希望你已经对CNN的工作有所了解。请随意查看其他文章。如果你有任何问题，只要ping我或在下面评论！</p><p id="a15a" class="pw-post-body-paragraph jw jx iq jy b jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ij bi translated">3个可以让初学者轻松理解CNN的链接:</p><ul class=""><li id="c202" class="lx ly iq jy b jz ka kd ke kh om kl on kp oo kt ov md me mf bi translated"><a class="ae my" href="https://www.youtube.com/watch?v=FmpDIaiMIeA&amp;t=870s" rel="noopener ugc nofollow" target="_blank"> Youtube视频有清晰的CNN图片，作者Brandon Rohrer </a></li><li id="372c" class="lx ly iq jy b jz mg kd mh kh mi kl mj kp mk kt ov md me mf bi translated">Adit Deshpande对CNN的介绍</li><li id="b0e3" class="lx ly iq jy b jz mg kd mh kh mi kl mj kp mk kt ov md me mf bi translated">Ujjwal Karn对CNN的深入了解</li></ul><p id="4c73" class="pw-post-body-paragraph jw jx iq jy b jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ij bi translated">CNN上的更多强化学习(有代码解释):</p><ul class=""><li id="4610" class="lx ly iq jy b jz ka kd ke kh om kl on kp oo kt ov md me mf bi translated"><a class="ae my" href="http://cs231n.github.io/convolutional-networks/#conv" rel="noopener ugc nofollow" target="_blank">斯坦福大学的cs 231n</a></li></ul><p id="14d6" class="pw-post-body-paragraph jw jx iq jy b jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ij bi translated">摆弄过滤器，了解CNN中过滤器的概念:</p><ul class=""><li id="65d2" class="lx ly iq jy b jz ka kd ke kh om kl on kp oo kt ov md me mf bi translated"><a class="ae my" href="http://setosa.io/ev/image-kernels/" rel="noopener ugc nofollow" target="_blank">维克多·鲍威尔的图像内核</a></li></ul><p id="31c5" class="pw-post-body-paragraph jw jx iq jy b jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ij bi translated">我向初学者强烈推荐的课程:</p><ul class=""><li id="4788" class="lx ly iq jy b jz ka kd ke kh om kl on kp oo kt ov md me mf bi translated"><a class="ae my" href="https://www.coursera.org/specializations/deep-learning" rel="noopener ugc nofollow" target="_blank">吴恩达深度学习专业化</a></li></ul></div></div>    
</body>
</html>