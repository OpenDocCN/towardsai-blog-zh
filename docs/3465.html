<html>
<head>
<title>How is Google Aiming At a Trillion Parameter Model (PaLM): Page-by-Page Review</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">谷歌如何瞄准万亿参数模型(PaLM):一页一页的回顾</h1>
<blockquote>原文：<a href="https://pub.towardsai.net/aiming-at-a-trillion-parameter-model-palm-page-by-page-review-59e4f21e51e8?source=collection_archive---------0-----------------------#2022-12-30">https://pub.towardsai.net/aiming-at-a-trillion-parameter-model-palm-page-by-page-review-59e4f21e51e8?source=collection_archive---------0-----------------------#2022-12-30</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="b03f" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">路径:用于ML的异步分布式数据流和用路径扩展语言建模</h2></div><p id="49c8" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">这一次，我将从通常的1篇论文1篇综述的方法转向2篇论文1篇综述。原因是Pathways <a class="ae le" href="https://arxiv.org/abs/2203.12533" rel="noopener ugc nofollow" target="_blank">的论文</a> (Pathways:用于ML的异步分布式数据流)过于技术性，而<a class="ae le" href="https://arxiv.org/abs/2204.02311" rel="noopener ugc nofollow" target="_blank">的论文</a>(PaLM:Scaling Language Modeling with Pathways)讨论了这种架构在实际语言模型中的应用。应用论文很好讨论，有很多有趣的信息。然而，在看到我的文章现在有15分钟长后，我决定将这两篇文章分成1篇评论。</p></div><div class="ab cl lf lg hx lh" role="separator"><span class="li bw bk lj lk ll"/><span class="li bw bk lj lk ll"/><span class="li bw bk lj lk"/></div><div class="im in io ip iq"><h2 id="33a2" class="lm ln it bd lo lp lq dn lr ls lt dp lu kr lv lw lx kv ly lz ma kz mb mc md me bi translated">摘要中的摘要</h2><blockquote class="mf mg mh"><p id="d79c" class="ki kj mi kk b kl km ju kn ko kp jx kq mj ks kt ku mk kw kx ky ml la lb lc ld im bi translated"><strong class="kk iu">路径:用于m1的异步分布式数据流</strong></p><p id="b326" class="ki kj mi kk b kl km ju kn ko kp jx kq mj ks kt ku mk kw kx ky ml la lb lc ld im bi translated"><strong class="kk iu">我们提出了一种新的加速器大规模编排层的设计。我们的系统PATHWAYS利用了一种新颖的<em class="it">异步分布式数据流</em>设计，让控制平面并行执行，而不管数据平面</strong>中的依赖性。经过精心设计，这种设计允许PATHWAYS <strong class="kk iu">采用单控制器模型</strong>，从而更容易表达复杂的新并行模式。我们证明，当在2048个TPU上运行SPMD计算时，路径可以实现与最先进的系统相当的性能(100%加速器利用率)，同时还可以为跨16级流水线或跨两个通过数据中心网络连接的加速器岛分割的变压器模型提供与SPMD案例相当的吞吐量。<a class="ae le" href="https://arxiv.org/abs/2203.12533" rel="noopener ugc nofollow" target="_blank"><strong class="kk iu">https://arxiv.org/abs/2203.12533</strong></a></p></blockquote><h1 id="703a" class="mm ln it bd lo mn mo mp lr mq mr ms lu jz mt ka lx kc mu kd ma kf mv kg md mw bi translated">第一篇论文</h1><figure class="my mz na nb gt nc gh gi paragraph-image"><div role="button" tabindex="0" class="nd ne di nf bf ng"><div class="gh gi mx"><img src="../Images/c4e08d950ed222986cd86000b637e971.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*zAnqhfaaXRfOO-4wu35ujA.png"/></div></div></figure><h2 id="ab03" class="lm ln it bd lo lp lq dn lr ls lt dp lu kr lv lw lx kv ly lz ma kz mb mc md me bi translated">要点</h2><p id="5f19" class="pw-post-body-paragraph ki kj it kk b kl nj ju kn ko nk jx kq kr nl kt ku kv nm kx ky kz nn lb lc ld im bi translated">协调加速器(计算加速器，如TPUs张量处理单元和GPU ),以提高可用FLOPs(浮点运算)的利用率，从而降低总资源消耗(时间、金钱、电力等)。).PATHWAYS是一个新的范例，它使用异步操作的共享数据流图，可以跨异构并行计算有效地协调数据和模型状态。</p><h2 id="5a42" class="lm ln it bd lo lp lq dn lr ls lt dp lu kr lv lw lx kv ly lz ma kz mb mc md me bi translated">缩写和简要信息</h2><p id="8417" class="pw-post-body-paragraph ki kj it kk b kl nj ju kn ko nk jx kq kr nl kt ku kv nm kx ky kz nn lb lc ld im bi translated"><strong class="kk iu"> SPMD </strong>:单程序多数据。这是大型语言模型训练架构的当前标准。一般来说，这种体系结构最终无法利用大型计算资源孤岛(即异构计算灵活性较低)。大规模超大规模计算的最新进展已经达到了SPMD的极限。</p><p id="86cc" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated"><strong class="kk iu"> MPI编程模型</strong>:是一个应用程序接口，定义了一个并行计算的模型，其中每个并行进程都有自己的本地内存，数据必须通过在进程之间传递消息来显式共享。与SPMD类似，该模型对用户和底层系统都有太多的限制。</p><p id="2803" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated"><strong class="kk iu"> MoE模式</strong> : <strong class="kk iu">(混合专家</strong>)模型(Shazeer et al. 2017)使用计算稀疏性，这增加了跨加速器的异构计算需求。</p><p id="5f00" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">MPMD:多程序多数据模型。使用通过高带宽互连连接的大型同质加速器岛既昂贵又浪费。MPMD通过将子部分映射到可用的更小的加速器岛上，允许计算的灵活性。这提高了资源的利用率。(肖等，2020)</p><figure class="my mz na nb gt nc gh gi paragraph-image"><div role="button" tabindex="0" class="nd ne di nf bf ng"><div class="gh gi no"><img src="../Images/7ddfe65fb257bf58e83624aed70a6acd.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*L4HRrig8fJoOP568RO8j-w.png"/></div></div></figure><p id="278a" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">本文比较了PATHWAYS框架与最先进的(SOTA) ML系统的性能，为未来的ML工作负载做准备。这个框架是专门为跨多个“pod”或TPU的程序的有效执行而开发的，Google使用TPU进行ML加速。纸张流程如下—</p><ol class=""><li id="9104" class="np nq it kk b kl km ko kp kr nr kv ns kz nt ld nu nv nw nx bi translated">当前分布式ML系统的局限性</li><li id="ed5d" class="np nq it kk b kl ny ko nz kr oa kv ob kz oc ld nu nv nw nx bi translated">灵活编程模型的路径支持</li><li id="5217" class="np nq it kk b kl ny ko nz kr oa kv ob kz oc ld nu nv nw nx bi translated">路径架构</li><li id="123b" class="np nq it kk b kl ny ko nz kr oa kv ob kz oc ld nu nv nw nx bi translated">最后，共享数据流和异步联合调度解决#1中讨论的关键限制</li></ol><p id="5896" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">要记住的另一个派别是基础模型的标准化趋势(Bommasani等人，2021年),这些模型是在大规模的大数据上训练的，但可以与多个下游任务/训练等共享模型的状态。因此允许有效的并行。</p><h2 id="406d" class="lm ln it bd lo lp lq dn lr ls lt dp lu kr lv lw lx kv ly lz ma kz mb mc md me bi translated">途径背后的动机</h2><p id="6aec" class="pw-post-body-paragraph ki kj it kk b kl nj ju kn ko nk jx kq kr nl kt ku kv nm kx ky kz nn lb lc ld im bi translated">简单来说就是提高大型语言模型训练任务的计算效率和并行性。这里有一个例子，说明了SPMD py torch上的JAX如何允许在PCIe通道上进行通信，这比DCN连接要快几个联盟，而排队加速器计算是一个独立的过程。</p><figure class="my mz na nb gt nc gh gi paragraph-image"><div role="button" tabindex="0" class="nd ne di nf bf ng"><div class="gh gi od"><img src="../Images/f7acc38cc45a15104843314f2f679971.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*4w_rFKJeoZb5tn4wWOrFFg.png"/></div></div></figure><h2 id="876b" class="lm ln it bd lo lp lq dn lr ls lt dp lu kr lv lw lx kv ly lz ma kz mb mc md me bi translated">路径中的编程模型</h2><p id="f0b4" class="pw-post-body-paragraph ki kj it kk b kl nj ju kn ko nk jx kq kr nl kt ku kv nm kx ky kz nn lb lc ld im bi translated">PATHWAYS使用单控制器模型，这使得使用单独的控制平面来分离任务和协调变得更加容易。这些路径是在TPU上运行的，但是由于XLA数据共享的一些限制，今天的JAX不能扩展到单个TPU pod之外。然而，多控制器模型可以使用相同的代码在TPU上的ICI(内核间互连链路)上运行。由于路径可以通过ICI和DCN进行通信，这使得JAX项目第一次可以扩展到包含数千个TPU核心的多个TPU吊舱。</p><h2 id="9860" class="lm ln it bd lo lp lq dn lr ls lt dp lu kr lv lw lx kv ly lz ma kz mb mc md me bi translated">示踪程序介绍</h2><p id="b2c6" class="pw-post-body-paragraph ki kj it kk b kl nj ju kn ko nk jx kq kr nl kt ku kv nm kx ky kz nn lb lc ld im bi translated">默认情况下，每个编译后的函数都被转换成一个独立的PATHWAYS程序，其中只包含一个(分片)计算，这意味着如果用户想要连续运行多个函数，那么每个函数都需要一个单独的Python调用和从客户端到协调器的RPC。因此，一个名为new <em class="mi"> program tracer </em>(图2)的新程序，用户可以包装调用许多编译函数的Python代码块。追踪器生成单路径程序，其中每个编译的函数由数据流图中的计算节点表示。</p><figure class="my mz na nb gt nc gh gi paragraph-image"><div role="button" tabindex="0" class="nd ne di nf bf ng"><div class="gh gi oe"><img src="../Images/29187083c6d8bd3959747e3836a08997.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*icrZMZoMShwMfR10FLTrPg.png"/></div></div></figure><h2 id="56bc" class="lm ln it bd lo lp lq dn lr ls lt dp lu kr lv lw lx kv ly lz ma kz mb mc md me bi translated">路径中的资源管理器</h2><p id="3473" class="pw-post-body-paragraph ki kj it kk b kl nj ju kn ko nk jx kq kr nl kt ku kv nm kx ky kz nn lb lc ld im bi translated">PATHWAY的后端由一组加速器组成，这些加速器被分成紧密耦合的岛，这些岛依次通过DCN相互连接(图3)。PATHWAYS有一个“资源管理器”，负责集中管理所有孤岛上的设备。客户可能要求岛屿的“虚拟切片”,其具有适合其通信模式的特定2D或3D网格形状。每个虚拟片包含“虚拟设备”,允许客户端表达计算如何在网格上布置。资源管理器为满足期望的互连拓扑、存储器容量等的虚拟设备动态地分配物理设备。</p><figure class="my mz na nb gt nc gh gi paragraph-image"><div role="button" tabindex="0" class="nd ne di nf bf ng"><div class="gh gi of"><img src="../Images/a6ca5280c687292ca5e93a6a15e195ad.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*zZPOvXizkxB3B8g38uYtlQ.png"/></div></div></figure><p id="df66" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">我将跳过PATHWAYS的系统架构的更多细节，但它涉及到资源管理器、客户机、使用PLAQUE的协调实现以及团队调度的动态调度。在这幅图中，我们可以欣赏异步调度，它可以允许并行计算，从而节省大量的FLOPs。</p><figure class="my mz na nb gt nc gh gi paragraph-image"><div role="button" tabindex="0" class="nd ne di nf bf ng"><div class="gh gi og"><img src="../Images/839b31c78a0f66e9ed7c59902eb4f230.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*4gopzYbfFOgFfScwafg-WQ.png"/></div></div></figure><p id="88a2" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">最后，从这张图中，我们可以看到，无论使用多少台主机(x轴)，路径都优于单控制器系统。-O表示OpByOp，-C表示链，-F表示融合，其中用户代码分别包含单独的单元、跨所有节点执行的一系列单元或在单个节点中执行的一系列单元。此外，我们可以注意到，对于16台和512台路径主机配置，较小计算的每秒计算次数仍然明显较低。这意味着，对于具有128TPUs的16台主机，PATHWAYS的计算时间超过2.3毫秒；对于具有2048 TPUs的512台主机，PATHWAYS的计算时间超过35毫秒，PATHWAYS与JAX吞吐量相当。</p><figure class="my mz na nb gt nc gh gi paragraph-image"><div role="button" tabindex="0" class="nd ne di nf bf ng"><div class="gh gi oh"><img src="../Images/5608f911d3cba70e43e455c41d032c0a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*S3x8K4JRYIYFSpnEYe0RAg.png"/></div></div></figure><h2 id="5164" class="lm ln it bd lo lp lq dn lr ls lt dp lu kr lv lw lx kv ly lz ma kz mb mc md me bi translated">大比例模型性能</h2><p id="ad26" class="pw-post-body-paragraph ki kj it kk b kl nj ju kn ko nk jx kq kr nl kt ku kv nm kx ky kz nn lb lc ld im bi translated">研究人员比较了测试的T5模型，并得出结论，在文本到文本的NLP任务中使用的编码器-解码器架构中，JAX和通路的性能是相同的。这意味着路径的开销被计算规模/复杂性有效地掩盖了，我们可以从路径架构中受益，但不必为开销支付额外的成本。对于只有解码器的任务也是如此。系统的性能与TPU的数量成线性比例。</p><h2 id="e791" class="lm ln it bd lo lp lq dn lr ls lt dp lu kr lv lw lx kv ly lz ma kz mb mc md me bi translated">结论</h2><p id="6838" class="pw-post-body-paragraph ki kj it kk b kl nj ju kn ko nk jx kq kr nl kt ku kv nm kx ky kz nn lb lc ld im bi translated">PATHWAYS与SOTA多控制器性能相当，但没有单租户SPMDs的限制。PATHWAYS扩展了JAX计划的功能并改进了资源管理。PATHWAYS允许在pod级别进行集群管理，从而支持多租户共享、虚拟化和针对工作负载定制的灵活性。PATHWAYS在利用并发工作负载的资源方面是高效的，并且利用了高效的流水线执行，这为未来的研究奠定了坚实的基础。</p><p id="48c5" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">我必须承认，这是最难阅读的论文之一，主要是因为我对设计如此庞大的培训工作的复杂性缺乏了解。我觉得我需要阅读这篇文章，以理解为什么具有540B参数的PaLM模型将成为NLP之旅中的一个重要里程碑。我每天都在学习——如果我有什么遗漏，请随时纠正我。如果你想跟我学点什么，那就留下你的赞，关注，等等(下面的链接)。</p></div><div class="ab cl lf lg hx lh" role="separator"><span class="li bw bk lj lk ll"/><span class="li bw bk lj lk ll"/><span class="li bw bk lj lk"/></div><div class="im in io ip iq"><figure class="my mz na nb gt nc gh gi paragraph-image"><div role="button" tabindex="0" class="nd ne di nf bf ng"><div class="gh gi oi"><img src="../Images/de1869f56fd3fdcbec4b41c7a5da037b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/1*qneuOdUFNZ84xLfLtGaHLw.gif"/></div></div></figure><p id="5e9b" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">来支持我🔔<strong class="kk iu"> <em class="mi">拍手</em> </strong> | <strong class="kk iu"> <em class="mi">跟随| </em> </strong> <a class="ae le" href="https://ithinkbot.com/subscribe" rel="noopener ugc nofollow" target="_blank"> <strong class="kk iu"> <em class="mi">订阅</em> </strong> </a> <strong class="kk iu"> <em class="mi"> </em>🔔</strong></p><p id="40b5" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">使用我的链接成为会员:<a class="ae le" href="https://ithinkbot.com/membership" rel="noopener ugc nofollow" target="_blank">https://ithinkbot.com/membership</a></p><p id="f896" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">检查我的其他作品—</p><div class="oj ok gp gr ol om"><a href="https://ithinkbot.com/2022-year-of-chatgpt-what-is-the-future-979b034efdf9" rel="noopener  ugc nofollow" target="_blank"><div class="on ab fo"><div class="oo ab op cl cj oq"><h2 class="bd iu gy z fp or fr fs os fu fw is bi translated">2022:chat GPT年，未来如何？</h2><div class="ot l"><h3 class="bd b gy z fp or fr fs os fu fw dk translated">看着水晶球</h3></div><div class="ou l"><p class="bd b dl z fp or fr fs os fu fw dk translated">ithinkbot.com</p></div></div><div class="ov l"><div class="ow l ox oy oz ov pa nh om"/></div></div></a></div><div class="oj ok gp gr ol om"><a rel="noopener  ugc nofollow" target="_blank" href="/openai-debuts-chatgpt-50dd611278a4"><div class="on ab fo"><div class="oo ab op cl cj oq"><h2 class="bd iu gy z fp or fr fs os fu fw is bi translated">OpenAI首次亮相ChatGPT</h2><div class="ot l"><h3 class="bd b gy z fp or fr fs os fu fw dk translated">OpenAI周三发布了一款名为ChatGPT的新模型。这个模型被训练成在一个…</h3></div><div class="ou l"><p class="bd b dl z fp or fr fs os fu fw dk translated">pub.towardsai.net</p></div></div><div class="ov l"><div class="pb l ox oy oz ov pa nh om"/></div></div></a></div><div class="oj ok gp gr ol om"><a rel="noopener  ugc nofollow" target="_blank" href="/what-is-gpt-4-and-when-9f5073f25a6d"><div class="on ab fo"><div class="oo ab op cl cj oq"><h2 class="bd iu gy z fp or fr fs os fu fw is bi translated">什么是GPT-4(什么时候？)</h2><div class="ot l"><h3 class="bd b gy z fp or fr fs os fu fw dk translated">GPT-4是一个自然语言处理模型，由openAI作为GPT-3的继承者开发</h3></div><div class="ou l"><p class="bd b dl z fp or fr fs os fu fw dk translated">pub.towardsai.net</p></div></div><div class="ov l"><div class="pc l ox oy oz ov pa nh om"/></div></div></a></div><figure class="my mz na nb gt nc gh gi paragraph-image"><div role="button" tabindex="0" class="nd ne di nf bf ng"><div class="gh gi pd"><img src="../Images/0f01bc3872ad3826df0e2d8ff3ab8538.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*z63jDPqXlNsLcjjo"/></div></div><figcaption class="pe pf gj gh gi pg ph bd b be z dk translated">Denys Nevozhai 在<a class="ae le" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上拍摄的照片</figcaption></figure></div></div>    
</body>
</html>