<html>
<head>
<title>Linear Regression With PyTorch in Python</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">用Python中的PyTorch实现线性回归</h1>
<blockquote>原文：<a href="https://pub.towardsai.net/linear-regression-with-pytorch-in-python-79c6b40730b8?source=collection_archive---------2-----------------------#2022-03-16">https://pub.towardsai.net/linear-regression-with-pytorch-in-python-79c6b40730b8?source=collection_archive---------2-----------------------#2022-03-16</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="0e9b" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">机器学习应用的深度学习框架</h2></div><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ki"><img src="../Images/a107ca62478a306f0bfd304ceabb1c1f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*2nqCobqGSVqsfU6k"/></div></div><figcaption class="ku kv gj gh gi kw kx bd b be z dk translated">Emile Perron 在<a class="ae ky" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上的照片</figcaption></figure><p id="5fd4" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">在本文中，我们将借助PyTorch深度学习库创建一个线性回归模型。该项目旨在借助输入要素来确定苹果和橙子作物的产量。</p><p id="2f21" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">首先，我们需要创建数据并将它们转换成PyTorch库的张量。</p><pre class="kj kk kl km gt lv lw lx ly aw lz bi"><span id="929a" class="ma mb it lw b gy mc md l me mf">import numpy as np<br/>import torch</span></pre><p id="354d" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">现在，我们将为我们的模型生成输入和目标。</p><pre class="kj kk kl km gt lv lw lx ly aw lz bi"><span id="1cde" class="ma mb it lw b gy mc md l me mf">inputs = np.array([[20, 31, 48],<br/>                  [74, 82, 11],<br/>                  [56, 73, 36],<br/>                  [94, 75, 29],<br/>                  [63, 88, 17]], dtype = 'float32')</span><span id="ca98" class="ma mb it lw b gy mg md l me mf">targets = np.array([[25, 112],<br/>                    [71, 97],<br/>                    [117, 131],<br/>                    [48, 58],<br/>                    [107, 114]], dtype = 'float32')</span></pre><p id="b8e8" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">为了将数据输入到我们的模型中，首先，我们需要将它们转换成PyTorch张量，如下所示。</p><pre class="kj kk kl km gt lv lw lx ly aw lz bi"><span id="fb55" class="ma mb it lw b gy mc md l me mf">inputs = torch.from_numpy(inputs)<br/>targets = torch.from_numpy(targets)</span><span id="68b5" class="ma mb it lw b gy mg md l me mf">print(inputs)<br/>print(targets)</span><span id="e0de" class="ma mb it lw b gy mg md l me mf">#output:<br/>tensor([[20., 31., 48.],<br/>        [74., 82., 11.],<br/>        [56., 73., 36.],<br/>        [94., 75., 29.],<br/>        [63., 88., 17.]])<br/>tensor([[ 25., 112.],<br/>        [ 71.,  97.],<br/>        [117., 131.],<br/>        [ 48.,  58.],<br/>        [107., 114.]])</span></pre><p id="115d" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">原始数据如下所示。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi mh"><img src="../Images/1697ee5f2d8d54b862dfe374ce5476cf.png" data-original-src="https://miro.medium.com/v2/resize:fit:840/format:webp/1*WtTGqGePB40HYG9VfAKpOw.png"/></div></figure><p id="f138" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">特征的权重和偏差如下所示。</p><pre class="kj kk kl km gt lv lw lx ly aw lz bi"><span id="610c" class="ma mb it lw b gy mc md l me mf">kiwi_yield = w11*temp + w12*rainfall + w13*humidity + b1<br/>banana_yield = w21*temp + w22*rainfall + w23*humidity + b2</span></pre><div class="mi mj gp gr mk ml"><a href="https://medium.com/pythoneers/machine-learning-explanation-of-simple-linear-regression-algorithm-dc5fd44d015d" rel="noopener follow" target="_blank"><div class="mm ab fo"><div class="mn ab mo cl cj mp"><h2 class="bd iu gy z fp mq fr fs mr fu fw is bi translated">机器学习:简单线性回归算法的解释</h2><div class="ms l"><h3 class="bd b gy z fp mq fr fs mr fu fw dk translated">人工智能的一个分支</h3></div><div class="mt l"><p class="bd b dl z fp mq fr fs mr fu fw dk translated">medium.com</p></div></div><div class="mu l"><div class="mv l mw mx my mu mz ks ml"/></div></div></a></div><p id="239f" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">在这些数据的帮助下，我们将生成矩阵形式的随机权重和偏差。</p><pre class="kj kk kl km gt lv lw lx ly aw lz bi"><span id="7d84" class="ma mb it lw b gy mc md l me mf">w = torch.randn(2, 3, requires_grad = True)<br/>b = torch.randn(2, requires_grad = True)</span><span id="8870" class="ma mb it lw b gy mg md l me mf">print(w)<br/>print(b)</span><span id="cd97" class="ma mb it lw b gy mg md l me mf">#output:<br/>tensor([[ 0.8107,  1.2951, -1.4349],<br/>        [ 1.3329, -1.3815, -0.1888]], requires_grad=True)<br/>tensor([-1.1700,  0.2881], requires_grad=True)</span></pre><p id="f4f5" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">现在，我们的权重和偏差被初始化，现在我们将矩阵与下面给出的公式相乘。</p><pre class="kj kk kl km gt lv lw lx ly aw lz bi"><span id="c40f" class="ma mb it lw b gy mc md l me mf">y_hat = w*x + b</span></pre><p id="247d" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">该公式将使用我们的数据、权重和偏差来构建模型。</p><pre class="kj kk kl km gt lv lw lx ly aw lz bi"><span id="ba64" class="ma mb it lw b gy mc md l me mf">def model(x):<br/>    return x @ w.t() + b</span><span id="189b" class="ma mb it lw b gy mg md l me mf">preds = model(inputs)<br/>print(preds)</span><span id="8f29" class="ma mb it lw b gy mg md l me mf">#output:<br/>tensor([[-13.6817, -24.9436],<br/>        [149.2377, -16.4334],<br/>        [ 87.1170, -32.7139],<br/>        [130.5577,  16.4958],<br/>        [139.4815, -40.5173]], grad_fn=&lt;AddBackward0&gt;)</span></pre><p id="3350" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">这里我们看到预测值与原始目标值相差甚远，因为我们从随机权重和偏差值开始。</p><p id="025c" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">让我们计算模型的损失，这是非常糟糕的，但我们仍然需要找到损失。</p><pre class="kj kk kl km gt lv lw lx ly aw lz bi"><span id="1608" class="ma mb it lw b gy mc md l me mf">def mse(t1, t2):<br/>    diff = t1 - t2<br/>    return torch.sum(diff * diff) /diff.numel()</span><span id="6cba" class="ma mb it lw b gy mg md l me mf">loss = mse(preds, targets)<br/>print(loss)</span><span id="d882" class="ma mb it lw b gy mg md l me mf">#output:<br/>tensor(10040.2354, grad_fn=&lt;DivBackward0&gt;)</span></pre><p id="de49" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">价值是模型的损失，我们需要降低损失来改进模型。</p><p id="930b" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">现在，我们将使用梯度下降法通过更新权重和偏差值来降低模型中的误差。</p><pre class="kj kk kl km gt lv lw lx ly aw lz bi"><span id="73f0" class="ma mb it lw b gy mc md l me mf">with torch.no_grad():<br/>    w -= w.grad * 1e-5<br/>    b -= b.grad * 1e-5<br/>    w.grad.zero_()<br/>    b.grad.zero_()</span></pre><p id="ccb2" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">是时候再次运行模型，以查看使用新权重和偏差值的损失结果了。</p><pre class="kj kk kl km gt lv lw lx ly aw lz bi"><span id="4bd8" class="ma mb it lw b gy mc md l me mf">preds = model(inputs)<br/>loss = mse(preds, targets)<br/>print(loss)</span><span id="37c2" class="ma mb it lw b gy mg md l me mf">#output:<br/>tensor(7475.9697, grad_fn=&lt;DivBackward0&gt;)</span></pre><p id="0b58" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">误差现在从10040.2354减少到7475.9697。我们可以通过在训练中多次更新权重和偏差值来迭代模型，从而进一步减少损失。</p><pre class="kj kk kl km gt lv lw lx ly aw lz bi"><span id="4b7f" class="ma mb it lw b gy mc md l me mf">for i in range(10):<br/>    preds = model(inputs)<br/>    loss = mse(preds, targets)<br/>    loss.backward()</span><span id="bd5c" class="ma mb it lw b gy mg md l me mf">with torch.no_grad():<br/>    w -= w.grad * 1e-5<br/>    b -= b.grad * 1e-5<br/>    w.grad.zero_()<br/>    b.grad.zero_()</span></pre><p id="5bd7" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">该函数将用10个时期迭代模型，即该函数将更新权重和偏差10次，以提高模型精度并降低误差。</p><pre class="kj kk kl km gt lv lw lx ly aw lz bi"><span id="e427" class="ma mb it lw b gy mc md l me mf">preds = model(inputs)<br/>loss = mse(preds, targets)<br/>print(loss)</span><span id="596e" class="ma mb it lw b gy mg md l me mf">#output:<br/>tensor(3413.1062, grad_fn=&lt;DivBackward0&gt;)</span></pre><p id="cc8b" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">10个周期后误差更减少到3413，我们可以在20和30个周期上检查。</p><pre class="kj kk kl km gt lv lw lx ly aw lz bi"><span id="77b5" class="ma mb it lw b gy mc md l me mf">epochs          error<br/>20 epochs  --&gt; 2621.7429<br/>200 epochs --&gt; 737.8288<br/>500 epochs --&gt; 322.5351</span></pre><p id="13ac" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><strong class="lb iu">结论</strong></p><p id="1a51" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">本文是PyTorch框架使用深度学习算法的基本介绍。我举这个小例子只是为了展示PyTorch的工作功能。</p><p id="622c" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">我希望你喜欢这篇文章。通过我的<a class="ae ky" href="https://www.linkedin.com/in/data-scientist-95040a1ab/" rel="noopener ugc nofollow" target="_blank"> LinkedIn </a>和<a class="ae ky" href="https://twitter.com/amitprius" rel="noopener ugc nofollow" target="_blank"> Twitter </a>联系我。</p><h1 id="dce2" class="na mb it bd nb nc nd ne nf ng nh ni nj jz nk ka nl kc nm kd nn kf no kg np nq bi translated">推荐文章</h1><p id="baf9" class="pw-post-body-paragraph kz la it lb b lc nr ju le lf ns jx lh li nt lk ll lm nu lo lp lq nv ls lt lu im bi translated">1.<a class="ae ky" rel="noopener ugc nofollow" target="_blank" href="/8-active-learning-insights-of-python-collection-module-6c9e0cc16f6b">8 Python的主动学习见解收集模块</a> <br/> 2。<a class="ae ky" rel="noopener ugc nofollow" target="_blank" href="/numpy-linear-algebra-on-images-ed3180978cdb?source=friends_link&amp;sk=d9afa4a1206971f9b1f64862f6291ac0"> NumPy:图像上的线性代数</a>T5】3。<a class="ae ky" rel="noopener ugc nofollow" target="_blank" href="/exception-handling-concepts-in-python-4d5116decac3?source=friends_link&amp;sk=a0ed49d9fdeaa67925eac34ecb55ea30">Python中的异常处理概念</a> <br/> 4。<a class="ae ky" rel="noopener ugc nofollow" target="_blank" href="/pandas-dealing-with-categorical-data-7547305582ff?source=friends_link&amp;sk=11c6809f6623dd4f6dd74d43727297cf">熊猫:处理分类数据</a> <br/> 5。<a class="ae ky" rel="noopener ugc nofollow" target="_blank" href="/hyper-parameters-randomseachcv-and-gridsearchcv-in-machine-learning-b7d091cf56f4?source=friends_link&amp;sk=cab337083fb09601114a6e466ec59689">超参数:机器学习中的RandomSeachCV和GridSearchCV</a><br/>6。<a class="ae ky" href="https://medium.com/towards-artificial-intelligence/fully-explained-linear-regression-with-python-fe2b313f32f3?source=friends_link&amp;sk=53c91a2a51347ec2d93f8222c0e06402" rel="noopener">用Python </a> <br/> 7全面讲解了线性回归。<a class="ae ky" href="https://medium.com/towards-artificial-intelligence/fully-explained-logistic-regression-with-python-f4a16413ddcd?source=friends_link&amp;sk=528181f15a44e48ea38fdd9579241a78" rel="noopener">用Python </a> <br/>充分解释了Logistic回归8。<a class="ae ky" rel="noopener ugc nofollow" target="_blank" href="/data-distribution-using-numpy-with-python-3b64aae6f9d6?source=friends_link&amp;sk=809e75802cbd25ddceb5f0f6496c9803">数据分发使用Numpy与Python </a> <br/> 9。<a class="ae ky" rel="noopener ugc nofollow" target="_blank" href="/decision-trees-vs-random-forests-in-machine-learning-be56c093b0f?source=friends_link&amp;sk=91377248a43b62fe7aeb89a69e590860">机器学习中的决策树vs随机森林</a> <br/> 10。<a class="ae ky" rel="noopener ugc nofollow" target="_blank" href="/standardization-in-data-preprocessing-with-python-96ae89d2f658?source=friends_link&amp;sk=f348435582e8fbb47407e9b359787e41">用Python实现数据预处理的标准化</a></p></div></div>    
</body>
</html>