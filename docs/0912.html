<html>
<head>
<title>Discovering beer type from ingredients using Classification</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">利用分类从配料中发现啤酒类型</h1>
<blockquote>原文：<a href="https://pub.towardsai.net/discovering-beer-type-from-ingredients-using-classification-b2dd8b41e482?source=collection_archive---------2-----------------------#2020-09-10">https://pub.towardsai.net/discovering-beer-type-from-ingredients-using-classification-b2dd8b41e482?source=collection_archive---------2-----------------------#2020-09-10</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><h2 id="a22c" class="ir is it bd b dl iu iv iw ix iy iz dk ja translated" aria-label="kicker paragraph"><a class="ae ep" href="https://towardsai.net/p/category/machine-learning" rel="noopener ugc nofollow" target="_blank">机器学习</a></h2><div class=""/><div class=""><h2 id="06f6" class="pw-subtitle-paragraph jz jc it bd b ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq dk translated">使用支持向量机的啤酒分类器:全部代码可在我的Github repo 获得<a class="ae kr" href="https://github.com/arditoibryan/Projects/tree/master/20200827_Beer_Recipe_Classifier" rel="noopener ugc nofollow" target="_blank">。</a></h2></div><p id="5ec7" class="pw-post-body-paragraph ks kt it ku b kv kw kd kx ky kz kg la lb lc ld le lf lg lh li lj lk ll lm ln im bi translated">在本文中，我将分析一个包含近80，000个样本的数据集中的啤酒配方数据。通过使用监督学习，我将尝试从配方过程中估计啤酒的类型。该数据集已通过链接从Kaggle <a class="ae kr" href="https://www.kaggle.com/jtrofe/beer-recipes" rel="noopener ugc nofollow" target="_blank">下载。</a></p><figure class="lp lq lr ls gt lt gh gi paragraph-image"><div role="button" tabindex="0" class="lu lv di lw bf lx"><div class="gh gi lo"><img src="../Images/724d5c7a0a421a56292fa01e2bdd6f01.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*DcybFeZzeiHnDxZR"/></div></div><figcaption class="ma mb gj gh gi mc md bd b be z dk translated">照片由<a class="ae kr" href="https://unsplash.com/@giancarlor_photo?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">gian Carlo revoledo</a>在<a class="ae kr" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上拍摄</figcaption></figure><h1 id="85e8" class="me mf it bd mg mh mi mj mk ml mm mn mo ki mp kj mq kl mr km ms ko mt kp mu mv bi translated">创建模型的步骤</h1><p id="09b7" class="pw-post-body-paragraph ks kt it ku b kv mw kd kx ky mx kg la lb my ld le lf mz lh li lj na ll lm ln im bi translated">创建这个模型的大部分时间实际上都花在了预处理数据上。数据集是不完整的，不是时间序列，而是<strong class="ku jd">个独立样本</strong>，我无法使用插值来解决这个问题。</p><ul class=""><li id="33d2" class="nb nc it ku b kv kw ky kz lb nd lf ne lj nf ln ng nh ni nj bi translated">导入数据集</li><li id="6055" class="nb nc it ku b kv nk ky nl lb nm lf nn lj no ln ng nh ni nj bi translated">创建函数</li><li id="0a3c" class="nb nc it ku b kv nk ky nl lb nm lf nn lj no ln ng nh ni nj bi translated">预处理(2个阶段)</li><li id="b70b" class="nb nc it ku b kv nk ky nl lb nm lf nn lj no ln ng nh ni nj bi translated">提取要素和标注</li><li id="9bd5" class="nb nc it ku b kv nk ky nl lb nm lf nn lj no ln ng nh ni nj bi translated">剧烈的</li><li id="c655" class="nb nc it ku b kv nk ky nl lb nm lf nn lj no ln ng nh ni nj bi translated">训练模型</li><li id="7e4c" class="nb nc it ku b kv nk ky nl lb nm lf nn lj no ln ng nh ni nj bi translated">性能赋值</li></ul><h2 id="7be6" class="np mf it bd mg nq nr dn mk ns nt dp mo lb nu nv mq lf nw nx ms lj ny nz mu iz bi translated">导入数据集</h2><p id="d939" class="pw-post-body-paragraph ks kt it ku b kv mw kd kx ky mx kg la lb my ld le lf mz lh li lj na ll lm ln im bi translated">因为我使用Google Colab来执行实验，所以我已经将数据集下载到我的驱动器中，现在我将导入pandas。</p><pre class="lp lq lr ls gt oa ob oc od aw oe bi"><span id="61ce" class="np mf it ob b gy of og l oh oi">import pandas as pd<br/>from sklearn import preprocessing<br/>import numpy as np</span><span id="53de" class="np mf it ob b gy oj og l oh oi">#   importing dataset<br/>df = pd.read_csv('/content/drive/My Drive/Colab Notebooks/Projects/20200827_Beer_Classifier/recipeData.csv', engine='python')<br/>df</span></pre><figure class="lp lq lr ls gt lt gh gi paragraph-image"><div role="button" tabindex="0" class="lu lv di lw bf lx"><div class="gh gi ok"><img src="../Images/03eab13743129c955fe91891db4d8ec8.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*7kE1MXnv6VYk3u5CgyEqqw.png"/></div></div><figcaption class="ma mb gj gh gi mc md bd b be z dk translated">原始数据集</figcaption></figure><p id="eace" class="pw-post-body-paragraph ks kt it ku b kv kw kd kx ky kz kg la lb lc ld le lf lg lh li lj lk ll lm ln im bi translated">在继续下一步之前，我总是有一套预先准备好的函数供以后使用。在这种情况下，我只使用one_hot编码。然而，我不想在预处理过程中使用一大块代码，只使用一行代码调用它要舒服得多。</p><pre class="lp lq lr ls gt oa ob oc od aw oe bi"><span id="e1cf" class="np mf it ob b gy of og l oh oi">#   functions<br/>def one_hot(df, partitions):<br/>  #togliamo le colonne da X<br/>  for col in partitions:<br/>    k = df.pop(col)<br/>    k = pd.get_dummies(k, prefix=col)<br/>    df = pd.concat([df, k] , axis=1)<br/>  return df</span></pre><h2 id="3085" class="np mf it bd mg nq nr dn mk ns nt dp mo lb nu nv mq lf nw nx ms lj ny nz mu iz bi translated">预处理</h2><p id="db35" class="pw-post-body-paragraph ks kt it ku b kv mw kd kx ky mx kg la lb my ld le lf mz lh li lj na ll lm ln im bi translated">这个数据集的处理相当困难。我将预处理分为两个独立的阶段。</p><pre class="lp lq lr ls gt oa ob oc od aw oe bi"><span id="8625" class="np mf it ob b gy of og l oh oi">#   preprocessing_1</span><span id="bbd3" class="np mf it ob b gy oj og l oh oi">#getting rid of columns I do not need<br/>df = df.drop(['BeerID', 'Name', 'StyleID'], axis=1)</span></pre><p id="876f" class="pw-post-body-paragraph ks kt it ku b kv kw kd kx ky kz kg la lb lc ld le lf lg lh li lj lk ll lm ln im bi translated">看了一下数据后，我去掉了有太多NaN和BeetID的列，这是啤酒标签到数字的转换。如果我在特征中使用标签的副本，模型将会受到危害。</p><pre class="lp lq lr ls gt oa ob oc od aw oe bi"><span id="6ac6" class="np mf it ob b gy of og l oh oi">#getting rid of columns with NaN values<br/>df = df.drop(['URL', 'PrimingAmount', 'UserId', 'PrimingMethod', 'PitchRate', 'MashThickness', 'PrimaryTemp'], axis=1)<br/>df = df.dropna(axis=0)<br/>df</span></pre><p id="e1a4" class="pw-post-body-paragraph ks kt it ku b kv kw kd kx ky kz kg la lb lc ld le lf lg lh li lj lk ll lm ln im bi translated">在预处理的第二步，我需要去掉包含NaN值的行。我将和大约。七万个样本。然后，我需要对齐特征和标签的索引。</p><pre class="lp lq lr ls gt oa ob oc od aw oe bi"><span id="e494" class="np mf it ob b gy of og l oh oi">#   preprocessing_2<br/>#saving one_hot columns<br/>df_ = df[['SugarScale', 'BrewMethod', 'Style']]<br/>df_</span><span id="827c" class="np mf it ob b gy oj og l oh oi">#transform<br/>scaler = preprocessing.MinMaxScaler(feature_range=(0, 1))<br/>df = scaler.fit_transform(df.drop(['SugarScale', 'BrewMethod', 'Style'], axis=1))<br/>df = pd.DataFrame(df)</span><span id="768c" class="np mf it ob b gy oj og l oh oi">#standardizziamo datasets<br/>df.index = df_.index<br/>df</span><span id="f4b2" class="np mf it ob b gy oj og l oh oi">#reattach datasets<br/>df = pd.concat([df, df_], axis=1)<br/>df</span><span id="1c42" class="np mf it ob b gy oj og l oh oi">#one_hot<br/>df = one_hot(df, ['SugarScale', 'BrewMethod'])<br/>df</span><span id="e8f8" class="np mf it ob b gy oj og l oh oi">#dropna<br/>df = df.dropna(axis=0)<br/>df</span></pre><h2 id="d1de" class="np mf it bd mg nq nr dn mk ns nt dp mo lb nu nv mq lf nw nx ms lj ny nz mu iz bi translated">特征</h2><pre class="lp lq lr ls gt oa ob oc od aw oe bi"><span id="3184" class="np mf it ob b gy of og l oh oi">#   features<br/>X = df.copy()<br/>X</span></pre><figure class="lp lq lr ls gt lt gh gi paragraph-image"><div role="button" tabindex="0" class="lu lv di lw bf lx"><div class="gh gi ol"><img src="../Images/fd3c2178b64a263d1e7414fbafb31438.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*qt_8B6b7gSAZCtKNVUGyzw.png"/></div></div></figure><h2 id="a9c5" class="np mf it bd mg nq nr dn mk ns nt dp mo lb nu nv mq lf nw nx ms lj ny nz mu iz bi translated">标签</h2><pre class="lp lq lr ls gt oa ob oc od aw oe bi"><span id="1d29" class="np mf it ob b gy of og l oh oi">#   labels<br/>y = pd.DataFrame(X.pop('Style'))<br/>y</span></pre><figure class="lp lq lr ls gt lt gh gi paragraph-image"><div class="gh gi om"><img src="../Images/3caca4e0f3a19615c50f5acb1c217d35.png" data-original-src="https://miro.medium.com/v2/resize:fit:604/format:webp/1*LprqwEaFae7N1PEZ9kMRuA.png"/></div></figure><h2 id="f5cb" class="np mf it bd mg nq nr dn mk ns nt dp mo lb nu nv mq lf nw nx ms lj ny nz mu iz bi translated">裂开</h2><p id="a2ff" class="pw-post-body-paragraph ks kt it ku b kv mw kd kx ky mx kg la lb my ld le lf mz lh li lj na ll lm ln im bi translated">现在，我将按照80:20的比例将我的模型分为训练集和测试集。</p><pre class="lp lq lr ls gt oa ob oc od aw oe bi"><span id="a048" class="np mf it ob b gy of og l oh oi">from sklearn.model_selection import train_test_split</span><span id="bfeb" class="np mf it ob b gy oj og l oh oi">X_train , X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)</span></pre><h2 id="ced4" class="np mf it bd mg nq nr dn mk ns nt dp mo lb nu nv mq lf nw nx ms lj ny nz mu iz bi translated">训练模型</h2><p id="a3a4" class="pw-post-body-paragraph ks kt it ku b kv mw kd kx ky mx kg la lb my ld le lf mz lh li lj na ll lm ln im bi translated">我将使用支持向量机作为模型。这是最常见的分类模型之一。</p><pre class="lp lq lr ls gt oa ob oc od aw oe bi"><span id="9034" class="np mf it ob b gy of og l oh oi">from sklearn import svm<br/>clf = svm.SVC(C=1.2, kernel='linear', degree=3)<br/>clf.fit(X_train, y_train)</span></pre><h2 id="f672" class="np mf it bd mg nq nr dn mk ns nt dp mo lb nu nv mq lf nw nx ms lj ny nz mu iz bi translated">预言；预测；预告</h2><p id="3f1f" class="pw-post-body-paragraph ks kt it ku b kv mw kd kx ky mx kg la lb my ld le lf mz lh li lj na ll lm ln im bi translated">y_pred是我刚刚在测试集上创建的模型的估计。</p><pre class="lp lq lr ls gt oa ob oc od aw oe bi"><span id="f0c5" class="np mf it ob b gy of og l oh oi">y_pred = clf.predict(X_test)</span></pre><h2 id="41cc" class="np mf it bd mg nq nr dn mk ns nt dp mo lb nu nv mq lf nw nx ms lj ny nz mu iz bi translated">评估性能</h2><p id="88d6" class="pw-post-body-paragraph ks kt it ku b kv mw kd kx ky mx kg la lb my ld le lf mz lh li lj na ll lm ln im bi translated">为了评估性能，我将比较y_pred和y_test。</p><pre class="lp lq lr ls gt oa ob oc od aw oe bi"><span id="f211" class="np mf it ob b gy of og l oh oi">from sklearn import metrics<br/>print("Accuracy:", metrics.accuracy_score(y_test, y_pred))</span><span id="d0d1" class="np mf it ob b gy oj og l oh oi">#Using SyleID as label<br/>#Accuracy: 0.22434812055536743</span><span id="ec1c" class="np mf it ob b gy oj og l oh oi">#Using Style as label<br/>#Accuracy: 0.22631877481565513</span></pre><h2 id="c1f2" class="np mf it bd mg nq nr dn mk ns nt dp mo lb nu nv mq lf nw nx ms lj ny nz mu iz bi translated">结论</h2><p id="7bf7" class="pw-post-body-paragraph ks kt it ku b kv mw kd kx ky mx kg la lb my ld le lf mz lh li lj na ll lm ln im bi translated">自变量对因变量的预测非常糟糕。我尝试了多次调优，并在Kaggle上搜索了其他结果，不幸的是，最高的准确率大约是45%。</p></div></div>    
</body>
</html>