<html>
<head>
<title>NLP News Cypher | 09.27.20</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">NLP新闻密码| 09.27.20</h1>
<blockquote>原文：<a href="https://pub.towardsai.net/nlp-news-cypher-09-27-20-ef42286d2713?source=collection_archive---------2-----------------------#2020-09-27">https://pub.towardsai.net/nlp-news-cypher-09-27-20-ef42286d2713?source=collection_archive---------2-----------------------#2020-09-27</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><figure class="ip iq gp gr ir is gh gi paragraph-image"><div role="button" tabindex="0" class="it iu di iv bf iw"><div class="gh gi io"><img src="../Images/3df6422196a423d4cf0a3dc6c624f939.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*jUColg97ToPoEFH_"/></div></div><figcaption class="iz ja gj gh gi jb jc bd b be z dk translated">由<a class="ae jd" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上的<a class="ae jd" href="https://unsplash.com/@x_vinicius?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">vini cius Henrique摄影</a>拍摄</figcaption></figure><h2 id="df51" class="je jf jg bd b dl jh ji jj jk jl jm dk jn translated" aria-label="kicker paragraph">自然语言处理每周时事通讯</h2><div class=""/><div class=""><h2 id="7320" class="pw-subtitle-paragraph km jp jg bd b kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld dk translated">传说</h2></div></div><div class="ab cl le lf hu lg" role="separator"><span class="lh bw bk li lj lk"/><span class="lh bw bk li lj lk"/><span class="lh bw bk li lj"/></div><div class="ij ik il im in"><p id="6868" class="pw-post-body-paragraph ll lm jg ln b lo lp kq lq lr ls kt lt lu lv lw lx ly lz ma mb mc md me mf mg ij bi mh translated">嗯…欢迎回来！本周大量的研究结果出炉了！但是，仅供参考，由于篇幅有限，我们无法在这份时事通讯中涵盖所有的故事，所以如果你想要完整的报道，请关注我们的<a class="ae jd" href="https://twitter.com/Quantum_Stat" rel="noopener ugc nofollow" target="_blank"> twitter </a>，并且一如既往，如果你喜欢阅读，请给它一个👏👏与你的敌人分享。</p><p id="a7a8" class="pw-post-body-paragraph ll lm jg ln b lo lp kq lq lr ls kt lt lu lv lw lx ly lz ma mb mc md me mf mg ij bi translated">还有…昨天，对超级骗子NLP Repo和大坏NLP数据库又进行了一次更新:我们增加了10个数据集和5个新笔记本。亮点包括DialogRE数据集，它可能是第一个人注释的基于对话的关系提取数据集。FarsTail数据集，一个波斯语NLI数据集。😎</p><h2 id="f2db" class="mq mr jg bd ms mt mu dn mv mw mx dp my lu mz na nb ly nc nd ne mc nf ng nh jm bi translated">👁来自黑暗网络的随机故事<strong class="ak">👁</strong></h2><p id="479a" class="pw-post-body-paragraph ll lm jg ln b lo ni kq lq lr nj kt lt lu nk lw lx ly nl ma mb mc nm me mf mg ij bi translated">据网络安全专家Alon Gal称，过去两年来，黑客一直试图破解一个价值6.9亿美元的比特币钱包。钱包是。dat文件包含一个非常强硬的加密，它是黑客和潜在的大报酬之间的所有立场。但有人说这都是胡说八道，这种说法的真实性值得怀疑，但谁知道…🤷‍♂️.据Gal称，最近暗网上出现了一个“销售未拆封钱包的繁荣市场”。可能是我们的彩票出了矩阵！</p><p id="492a" class="pw-post-body-paragraph ll lm jg ln b lo lp kq lq lr ls kt lt lu lv lw lx ly lz ma mb mc md me mf mg ij bi translated">哦，我不是在开玩笑…👇</p><figure class="nn no np nq gt is"><div class="bz fp l di"><div class="nr ns l"/></div><figcaption class="iz ja gj gh gi jb jc bd b be z dk translated">解密的</figcaption></figure><h2 id="590c" class="mq mr jg bd ms mt mu dn mv mw mx dp my lu mz na nb ly nc nd ne mc nf ng nh jm bi translated">GPT-3公司化</h2><p id="6bd0" class="pw-post-body-paragraph ll lm jg ln b lo ni kq lq lr nj kt lt lu nk lw lx ly nl ma mb mc nm me mf mg ij bi translated">微软在1B对OpenAI的投资获得了回报。微软宣布，它将获得GPT-3的独家许可，用于自己的产品。🧐</p><div class="ip iq gp gr ir nt"><a href="https://blogs.microsoft.com/blog/2020/09/22/microsoft-teams-up-with-openai-to-exclusively-license-gpt-3-language-model/" rel="noopener  ugc nofollow" target="_blank"><div class="nu ab fo"><div class="nv ab nw cl cj nx"><h2 class="bd jq gy z fp ny fr fs nz fu fw jp bi translated">微软与OpenAI合作，独家授权GPT-3语言模型——微软官方…</h2><div class="oa l"><h3 class="bd b gy z fp ny fr fs nz fu fw dk translated">我在微软工作的最令人满意的部分之一是能够见证和影响…</h3></div><div class="ob l"><p class="bd b dl z fp ny fr fs nz fu fw dk translated">blogs.microsoft.com</p></div></div></div></a></div><figure class="nn no np nq gt is"><div class="bz fp l di"><div class="oc ns l"/></div></figure><h2 id="6031" class="mq mr jg bd ms mt mu dn mv mw mx dp my lu mz na nb ly nc nd ne mc nf ng nh jm bi translated">重新审视图表</h2><p id="2fb1" class="pw-post-body-paragraph ll lm jg ln b lo ni kq lq lr nj kt lt lu nk lw lx ly nl ma mb mc nm me mf mg ij bi translated">上周我们提到了一篇知识图表论文，并展示了一个图表，展示了KG三元组与超关系图之间的区别。事实证明，Galkin写了一篇关于它的博文(包括代码链接)。点击此处阅读:</p><div class="ip iq gp gr ir nt"><a href="https://towardsdatascience.com/representation-learning-on-rdf-and-lpg-knowledge-graphs-6a92f2660241" rel="noopener follow" target="_blank"><div class="nu ab fo"><div class="nv ab nw cl cj nx"><h2 class="bd jq gy z fp ny fr fs nz fu fw jp bi translated">RDF*和LPG知识图上的表示学习</h2><div class="oa l"><h3 class="bd b gy z fp ny fr fs nz fu fw dk translated">超关系公斤比三公斤编码更多的知识。我们采用了图ML的最新进展，并提出了一个GNN…</h3></div><div class="ob l"><p class="bd b dl z fp ny fr fs nz fu fw dk translated">towardsdatascience.com</p></div></div><div class="od l"><div class="oe l of og oh od oi ix nt"/></div></div></a></div><h2 id="bf85" class="mq mr jg bd ms mt mu dn mv mw mx dp my lu mz na nb ly nc nd ne mc nf ng nh jm bi translated">ML世界的抽象</h2><figure class="nn no np nq gt is gh gi paragraph-image"><div role="button" tabindex="0" class="it iu di iv bf iw"><div class="gh gi oj"><img src="../Images/fb9fe75866fc5a3905dc05e0a3eb2a3b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*Y46y6l5B-iUecSIG"/></div></div><figcaption class="iz ja gj gh gi jb jc bd b be z dk translated">解密的</figcaption></figure><h2 id="7578" class="mq mr jg bd ms mt mu dn mv mw mx dp my lu mz na nb ly nc nd ne mc nf ng nh jm bi translated">彭博的数据注释指南😬</h2><figure class="nn no np nq gt is"><div class="bz fp l di"><div class="ok ns l"/></div><figcaption class="iz ja gj gh gi jb jc bd b be z dk translated"><a class="ae jd" href="https://assets.bbhub.io/company/sites/40/2020/09/Annotation-Best-Practices-091020-FINAL.pdf" rel="noopener ugc nofollow" target="_blank">链接</a></figcaption></figure></div><div class="ab cl le lf hu lg" role="separator"><span class="lh bw bk li lj lk"/><span class="lh bw bk li lj lk"/><span class="lh bw bk li lj"/></div><div class="ij ik il im in"><h1 id="f8d8" class="ol mr jg bd ms om on oo mv op oq or my kv os kw nb ky ot kz ne lb ou lc nh ov bi translated">本周</h1><blockquote class="ow ox oy"><p id="57a7" class="ll lm oz ln b lo lp kq lq lr ls kt lt pa lv lw lx pb lz ma mb pc md me mf mg ij bi translated">伯特仍然是轻量级的</p><p id="cffe" class="ll lm oz ln b lo lp kq lq lr ls kt lt pa lv lw lx pb lz ma mb pc md me mf mg ij bi translated">动力工作台</p><p id="5251" class="ll lm oz ln b lo lp kq lq lr ls kt lt pa lv lw lx pb lz ma mb pc md me mf mg ij bi translated">面向任务聊天机器人中NLU的一种新方法</p><p id="4278" class="ll lm oz ln b lo lp kq lq lr ls kt lt pa lv lw lx pb lz ma mb pc md me mf mg ij bi translated">Wav2vec 2.0</p><p id="9809" class="ll lm oz ln b lo lp kq lq lr ls kt lt pa lv lw lx pb lz ma mb pc md me mf mg ij bi translated">谷歌推荐</p><p id="9a2b" class="ll lm oz ln b lo lp kq lq lr ls kt lt pa lv lw lx pb lz ma mb pc md me mf mg ij bi translated">X-LXMERT</p><p id="d44e" class="ll lm oz ln b lo lp kq lq lr ls kt lt pa lv lw lx pb lz ma mb pc md me mf mg ij bi translated">荣誉奖</p><p id="7a2d" class="ll lm oz ln b lo lp kq lq lr ls kt lt pa lv lw lx pb lz ma mb pc md me mf mg ij bi translated">本周数据集:量化宽松</p></blockquote></div><div class="ab cl le lf hu lg" role="separator"><span class="lh bw bk li lj lk"/><span class="lh bw bk li lj lk"/><span class="lh bw bk li lj"/></div><div class="ij ik il im in"><h1 id="9ef0" class="ol mr jg bd ms om on oo mv op oq or my kv os kw nb ky ot kz ne lb ou lc nh ov bi translated">伯特仍然是轻量级的</h1><p id="1342" class="pw-post-body-paragraph ll lm jg ln b lo ni kq lq lr nj kt lt lu nk lw lx ly nl ma mb mc nm me mf mg ij bi translated">pQRNN是Google发布的一个新的NLP模型，建立在PRADO之上。这是一个超轻模型，仅包含1.4M的参数，而我们习惯的是440M的BERT，并且在对<a class="ae jd" href="https://www.tensorflow.org/datasets/catalog/civil_comments" rel="noopener ugc nofollow" target="_blank"> civil_comments </a>数据集进行基准测试时，没有损失太多的准确性。如果你关注在线推理和边缘计算，超轻模型是非常重要的。普拉多是开源的。</p><p id="9ea1" class="pw-post-body-paragraph ll lm jg ln b lo lp kq lq lr ls kt lt lu lv lw lx ly lz ma mb mc md me mf mg ij bi translated"><strong class="ln jq">博客</strong>:</p><div class="ip iq gp gr ir nt"><a href="https://ai.googleblog.com/2020/09/advancing-nlp-with-efficient-projection.html" rel="noopener  ugc nofollow" target="_blank"><div class="nu ab fo"><div class="nv ab nw cl cj nx"><h2 class="bd jq gy z fp ny fr fs nz fu fw jp bi translated">利用高效的基于投影的模型架构推进NLP</h2><div class="oa l"><h3 class="bd b gy z fp ny fr fs nz fu fw dk translated">在过去的十年里，深度神经网络从根本上改变了自然语言处理(NLP ),主要是通过…</h3></div><div class="ob l"><p class="bd b dl z fp ny fr fs nz fu fw dk translated">ai.googleblog.com</p></div></div><div class="od l"><div class="pd l of og oh od oi ix nt"/></div></div></a></div><h1 id="54f1" class="ol mr jg bd ms om pe oo mv op pf or my kv pg kw nb ky ph kz ne lb pi lc nh ov bi translated">动力工作台</h1><p id="0cae" class="pw-post-body-paragraph ll lm jg ln b lo ni kq lq lr nj kt lt lu nk lw lx ly nl ma mb mc nm me mf mg ij bi translated">脸书引入了一个名为<a class="ae jd" href="https://dynabench.org/?fbclid=IwAR1IKYxj3114Q0YGXeUChr8oSufTok-eiTcDtlQpA-smzeSBduYihoEST28" rel="noopener ugc nofollow" target="_blank"> Dynabench </a>的新基准，它将人类和模型置于“回路”中，以测量当人类试图愚弄模型时，模型出错的频率。</p><h2 id="d04b" class="mq mr jg bd ms mt mu dn mv mw mx dp my lu mz na nb ly nc nd ne mc nf ng nh jm bi translated">等等，这到底是干什么的？(来自他们的主页)</h2><blockquote class="ow ox oy"><p id="2021" class="ll lm oz ln b lo lp kq lq lr ls kt lt pa lv lw lx pb lz ma mb pc md me mf mg ij bi translated">基本思想是我们动态地收集数据。人类的任务是找到对抗的例子，愚弄当前最先进的模型。这提供了两个好处:它允许我们衡量我们当前的SOTA方法到底有多好；它产生的数据可用于进一步训练更强的SOTA模型。这个过程会重复多轮:每次SOTA“解决”了一轮，我们就可以利用这些模型，在它们失败的地方对抗性地收集新的数据集。随着新样本的收集，数据集将定期发布。</p></blockquote><p id="d252" class="pw-post-body-paragraph ll lm jg ln b lo lp kq lq lr ls kt lt lu lv lw lx ly lz ma mb mc md me mf mg ij bi translated">如果您能够欺骗模型，该实例将被传递到下一轮数据集，以对模型的准确性施加更大的压力，并最终使该数据集/模型更加健壮。数据集不是一成不变的，您的模型会随着时间的推移而改进。🔥🔥</p><div class="ip iq gp gr ir nt"><a href="https://dynabench.org/" rel="noopener  ugc nofollow" target="_blank"><div class="nu ab fo"><div class="nv ab nw cl cj nx"><h2 class="bd jq gy z fp ny fr fs nz fu fw jp bi translated">动力工作台</h2><div class="oa l"><h3 class="bd b gy z fp ny fr fs nz fu fw dk translated">动力工作台</h3></div><div class="ob l"><p class="bd b dl z fp ny fr fs nz fu fw dk translated">Dynabenchdynabench.org</p></div></div></div></a></div><h1 id="15cc" class="ol mr jg bd ms om pe oo mv op pf or my kv pg kw nb ky ph kz ne lb pi lc nh ov bi translated">面向任务聊天机器人中NLU的一种新方法</h1><p id="1170" class="pw-post-body-paragraph ll lm jg ln b lo ni kq lq lr nj kt lt lu nk lw lx ly nl ma mb mc nm me mf mg ij bi translated">我和梅根一起喝咖啡时，温度会是多少？</p><p id="1385" class="pw-post-body-paragraph ll lm jg ln b lo lp kq lq lr ls kt lt lu lv lw lx ly lz ma mb mc md me mf mg ij bi translated">如果你知道如何构建面向任务的聊天机器人，你就会知道上面的问题对于你的模型来说很难准确回答。你的第一反应可能是想直接去填补空缺。但是语义机器的新论文告诉我们，有一个更好的方法…通过使用数据流图:</p><figure class="nn no np nq gt is gh gi paragraph-image"><div class="gh gi pj"><img src="../Images/6a504b6da81a5e31b5bc95fa77fa1608.png" data-original-src="https://miro.medium.com/v2/resize:fit:1124/format:webp/0*gPfxrF7ztas5B0rY.jpg"/></div></figure><p id="2c34" class="pw-post-body-paragraph ll lm jg ln b lo lp kq lq lr ls kt lt lu lv lw lx ly lz ma mb mc md me mf mg ij bi translated">他们的模式是NLU的新方法！传统上，面向任务的聊天机器人将包括NLU模块、状态跟踪和对话策略，作为独立的模块，但他们的新方法预测代理行为，并在单个模型内的图形中记录它们。这是该领域的一个新方向，非常令人兴奋！</p><p id="3f2a" class="pw-post-body-paragraph ll lm jg ln b lo lp kq lq lr ls kt lt lu lv lw lx ly lz ma mb mc md me mf mg ij bi translated">此外，他们还发布了一个名为<a class="ae jd" href="https://www.microsoft.com/en-us/research/project/smcalflow-dataset-0/" rel="noopener ugc nofollow" target="_blank"> SMCalFlow </a>的新数据集，其中包含超过41，517个用数据流程序注释的对话！这个数据集已经被添加到<a class="ae jd" href="https://datasets.quantumstat.com/" rel="noopener ugc nofollow" target="_blank">大坏NLP数据库</a>。</p><p id="0967" class="pw-post-body-paragraph ll lm jg ln b lo lp kq lq lr ls kt lt lu lv lw lx ly lz ma mb mc md me mf mg ij bi translated"><strong class="ln jq">博客:</strong></p><div class="ip iq gp gr ir nt"><a href="https://www.microsoft.com/en-us/research/blog/dialogue-as-dataflow-a-new-approach-to-conversational-ai/?OCID=msr_blog_semantic_tw" rel="noopener  ugc nofollow" target="_blank"><div class="nu ab fo"><div class="nv ab nw cl cj nx"><h2 class="bd jq gy z fp ny fr fs nz fu fw jp bi translated">利用数据流图改进对话式人工智能</h2><div class="oa l"><h3 class="bd b gy z fp ny fr fs nz fu fw dk translated">“说起来容易做起来难。”这四个词反映了对话式人工智能的前景。只需几秒钟就能问出何时…</h3></div><div class="ob l"><p class="bd b dl z fp ny fr fs nz fu fw dk translated">www.microsoft.com</p></div></div><div class="od l"><div class="pk l of og oh od oi ix nt"/></div></div></a></div><p id="feed" class="pw-post-body-paragraph ll lm jg ln b lo lp kq lq lr ls kt lt lu lv lw lx ly lz ma mb mc md me mf mg ij bi translated"><strong class="ln jq">论文</strong>:<a class="ae jd" href="https://www.mitpressjournals.org/doi/pdf/10.1162/tacl_a_00333" rel="noopener ugc nofollow" target="_blank">https://www . mitpressjournals . org/doi/pdf/10.1162/tacl _ a _ 00333</a></p><h1 id="580f" class="ol mr jg bd ms om pe oo mv op pf or my kv pg kw nb ky ph kz ne lb pi lc nh ov bi translated">Wav2vec 2.0</h1><p id="8d7c" class="pw-post-body-paragraph ll lm jg ln b lo ni kq lq lr nj kt lt lu nk lw lx ly nl ma mb mc nm me mf mg ij bi translated">脸书本周发布了Wav2vec 2.0，这是一个建立在流行的自我监督学习方法基础上的框架，并使其适应原始音频数据。它包括预先训练的模型，根据他们的论文，它是健壮的:</p><blockquote class="ow ox oy"><p id="0ffd" class="ll lm oz ln b lo lp kq lq lr ls kt lt pa lv lw lx pb lz ma mb pc md me mf mg ij bi translated">“我们的实验显示了对未标记数据进行预训练以进行语音处理的巨大潜力:当只使用10分钟的标记训练数据，或48次平均12.5秒的记录时，我们在Librispeech的test-clean/other上获得了5.2/8.6的WER。”</p></blockquote><p id="7b40" class="pw-post-body-paragraph ll lm jg ln b lo lp kq lq lr ls kt lt lu lv lw lx ly lz ma mb mc md me mf mg ij bi translated"><strong class="ln jq"> GitHub </strong>:</p><div class="ip iq gp gr ir nt"><a href="https://github.com/pytorch/fairseq/tree/master/examples/wav2vec" rel="noopener  ugc nofollow" target="_blank"><div class="nu ab fo"><div class="nv ab nw cl cj nx"><h2 class="bd jq gy z fp ny fr fs nz fu fw jp bi translated">pytorch/fairseq</h2><div class="oa l"><h3 class="bd b gy z fp ny fr fs nz fu fw dk translated">wav2vec 2.0学习未标记数据上的语音表示，如wav2vec 2.0:一个框架…</h3></div><div class="ob l"><p class="bd b dl z fp ny fr fs nz fu fw dk translated">github.com</p></div></div><div class="od l"><div class="pl l of og oh od oi ix nt"/></div></div></a></div><h1 id="fbee" class="ol mr jg bd ms om pe oo mv op pf or my kv pg kw nb ky ph kz ne lb pi lc nh ov bi translated">谷歌推荐</h1><pre class="nn no np nq gt pm pn po pp aw pq bi"><span id="23c4" class="mq mr jg pn b gy pr ps l pt pu">!pip install tensorflow_recommenders</span></pre><p id="518c" class="pw-post-body-paragraph ll lm jg ln b lo lp kq lq lr ls kt lt lu lv lw lx ly lz ma mb mc md me mf mg ij bi translated">这很酷，TensorFlow有一个新的推荐系统库:TensorFlow推荐器(TFRS)。他们的博客文章展示了一个例子，说明如何使用该库来构建基于MovieLens数据集的电影推荐系统。他们的例子遵循双塔模型，其中他们使用两个子模型分别学习查询和候选的表示。</p><p id="5945" class="pw-post-body-paragraph ll lm jg ln b lo lp kq lq lr ls kt lt lu lv lw lx ly lz ma mb mc md me mf mg ij bi translated"><strong class="ln jq">博客</strong>:</p><div class="ip iq gp gr ir nt"><a href="https://blog.tensorflow.org/2020/09/introducing-tensorflow-recommenders.html?linkId=100309856" rel="noopener  ugc nofollow" target="_blank"><div class="nu ab fo"><div class="nv ab nw cl cj nx"><h2 class="bd jq gy z fp ny fr fs nz fu fw jp bi translated">TensorFlow推荐器简介</h2><div class="oa l"><h3 class="bd b gy z fp ny fr fs nz fu fw dk translated">2020年9月23日——由马切伊·库拉和詹姆斯·陈发布，谷歌大脑从推荐电影或餐馆到…</h3></div><div class="ob l"><p class="bd b dl z fp ny fr fs nz fu fw dk translated">blog.tensorflow.org</p></div></div><div class="od l"><div class="pv l of og oh od oi ix nt"/></div></div></a></div><p id="6ca1" class="pw-post-body-paragraph ll lm jg ln b lo lp kq lq lr ls kt lt lu lv lw lx ly lz ma mb mc md me mf mg ij bi translated"><strong class="ln jq"> GitHub </strong>:</p><div class="ip iq gp gr ir nt"><a href="https://github.com/tensorflow/recommenders" rel="noopener  ugc nofollow" target="_blank"><div class="nu ab fo"><div class="nv ab nw cl cj nx"><h2 class="bd jq gy z fp ny fr fs nz fu fw jp bi translated">tensor flow/推荐器</h2><div class="oa l"><h3 class="bd b gy z fp ny fr fs nz fu fw dk translated">TensorFlow Recommenders是一个使用TensorFlow构建推荐系统模型的库。它有助于充分…</h3></div><div class="ob l"><p class="bd b dl z fp ny fr fs nz fu fw dk translated">github.com</p></div></div><div class="od l"><div class="pw l of og oh od oi ix nt"/></div></div></a></div><h1 id="35f4" class="ol mr jg bd ms om pe oo mv op pf or my kv pg kw nb ky ph kz ne lb pi lc nh ov bi translated">X-LXMERT</h1><p id="ba43" class="pw-post-body-paragraph ll lm jg ln b lo ni kq lq lr nj kt lt lu nk lw lx ly nl ma mb mc nm me mf mg ij bi translated">在AI2，他们新的文本到图像的模型出来了:X-LXMERT。它根据文本提示生成图像。他们的结果有点超现实主义，有一种融化的时钟大理般的品质！在参与他们的演示之前，不要服用任何迷幻药:</p><div class="ip iq gp gr ir nt"><a href="https://vision-explorer.allenai.org/text_to_image_generation" rel="noopener  ugc nofollow" target="_blank"><div class="nu ab fo"><div class="nv ab nw cl cj nx"><h2 class="bd jq gy z fp ny fr fs nz fu fw jp bi translated">计算机视觉浏览器</h2><div class="oa l"><h3 class="bd b gy z fp ny fr fs nz fu fw dk translated">AI2计算机视觉浏览器提供了各种流行的模型演示-尝试，比较，并评估与您自己的…</h3></div><div class="ob l"><p class="bd b dl z fp ny fr fs nz fu fw dk translated">vision-explorer.allenai.org</p></div></div><div class="od l"><div class="px l of og oh od oi ix nt"/></div></div></a></div><p id="ed3a" class="pw-post-body-paragraph ll lm jg ln b lo lp kq lq lr ls kt lt lu lv lw lx ly lz ma mb mc md me mf mg ij bi translated"><strong class="ln jq">样本:</strong></p><figure class="nn no np nq gt is gh gi paragraph-image"><div role="button" tabindex="0" class="it iu di iv bf iw"><div class="gh gi oj"><img src="../Images/d95ea3cbb8c7a5860c6d90841c80b693.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*hHyfj7iRW2vBEwwy.png"/></div></div></figure><p id="abb7" class="pw-post-body-paragraph ll lm jg ln b lo lp kq lq lr ls kt lt lu lv lw lx ly lz ma mb mc md me mf mg ij bi translated"><strong class="ln jq">博客</strong>:</p><div class="ip iq gp gr ir nt"><a href="https://prior.allenai.org/projects/x-lxmert" rel="noopener  ugc nofollow" target="_blank"><div class="nu ab fo"><div class="nv ab nw cl cj nx"><h2 class="bd jq gy z fp ny fr fs nz fu fw jp bi translated">X-LXMERT:使用多模态变形器绘制、说明和回答问题</h2><div class="oa l"><h3 class="bd b gy z fp ny fr fs nz fu fw dk translated">最近的多模态变压器已经在各种多模态识别系统上实现了最先进的性能</h3></div><div class="ob l"><p class="bd b dl z fp ny fr fs nz fu fw dk translated">prior.allenai.org</p></div></div><div class="od l"><div class="py l of og oh od oi ix nt"/></div></div></a></div><p id="74ea" class="pw-post-body-paragraph ll lm jg ln b lo lp kq lq lr ls kt lt lu lv lw lx ly lz ma mb mc md me mf mg ij bi translated">【https://arxiv.org/pdf/2009.11278.pdf】纸 : <a class="ae jd" href="https://arxiv.org/pdf/2009.11278.pdf" rel="noopener ugc nofollow" target="_blank">纸</a></p><h1 id="930a" class="ol mr jg bd ms om pe oo mv op pf or my kv pg kw nb ky ph kz ne lb pi lc nh ov bi translated">荣誉奖</h1><h2 id="d31b" class="mq mr jg bd ms mt mu dn mv mw mx dp my lu mz na nb ly nc nd ne mc nf ng nh jm bi translated">当前视觉和语言研究的长期调查</h2><figure class="nn no np nq gt is"><div class="bz fp l di"><div class="ok ns l"/></div><figcaption class="iz ja gj gh gi jb jc bd b be z dk translated"><a class="ae jd" href="https://arxiv.org/pdf/1907.09358.pdf" rel="noopener ugc nofollow" target="_blank">链接</a></figcaption></figure><h2 id="6015" class="mq mr jg bd ms mt mu dn mv mw mx dp my lu mz na nb ly nc nd ne mc nf ng nh jm bi translated">COMET——机器翻译评估框架</h2><div class="ip iq gp gr ir nt"><a href="https://github.com/Unbabel/COMET" rel="noopener  ugc nofollow" target="_blank"><div class="nu ab fo"><div class="nv ab nw cl cj nx"><h2 class="bd jq gy z fp ny fr fs nz fu fw jp bi translated">无标签/彗星</h2><div class="oa l"><h3 class="bd b gy z fp ny fr fs nz fu fw dk translated">注意:这是预发布版本。我们目前正在研究WMT2020共享任务的结果，可能会…</h3></div><div class="ob l"><p class="bd b dl z fp ny fr fs nz fu fw dk translated">github.com</p></div></div><div class="od l"><div class="pz l of og oh od oi ix nt"/></div></div></a></div><h2 id="286f" class="mq mr jg bd ms mt mu dn mv mw mx dp my lu mz na nb ly nc nd ne mc nf ng nh jm bi translated">数据集制图</h2><figure class="nn no np nq gt is"><div class="bz fp l di"><div class="ok ns l"/></div><figcaption class="iz ja gj gh gi jb jc bd b be z dk translated"><a class="ae jd" href="https://arxiv.org/pdf/2009.10795.pdf" rel="noopener ugc nofollow" target="_blank">链接</a></figcaption></figure><h1 id="9a1a" class="ol mr jg bd ms om pe oo mv op pf or my kv pg kw nb ky ph kz ne lb pi lc nh ov bi translated">本周数据集:量化宽松</h1><h1 id="f30c" class="ol mr jg bd ms om pe oo mv op pf or my kv pg kw nb ky ph kz ne lb pi lc nh ov bi translated">这是什么？</h1><p id="bd6a" class="pw-post-body-paragraph ll lm jg ln b lo ni kq lq lr nj kt lt lu nk lw lx ly nl ma mb mc nm me mf mg ij bi translated">给定一个问题和一篇文章，QED将答案的解释表示为离散的、人类可解释的步骤的组合:句子选择、指称相等和谓词蕴涵。数据集是作为自然问题数据集的子集构建的。</p><h1 id="e579" class="ol mr jg bd ms om pe oo mv op pf or my kv pg kw nb ky ph kz ne lb pi lc nh ov bi translated">样本:</h1><figure class="nn no np nq gt is gh gi paragraph-image"><div role="button" tabindex="0" class="it iu di iv bf iw"><div class="gh gi qa"><img src="../Images/e005e9e05f5907d705f61882a51558c6.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*-enxeTdac42rQxj0.png"/></div></div></figure><h1 id="96c7" class="ol mr jg bd ms om pe oo mv op pf or my kv pg kw nb ky ph kz ne lb pi lc nh ov bi translated">它在哪里？</h1><div class="ip iq gp gr ir nt"><a href="https://github.com/google-research-datasets/QED" rel="noopener  ugc nofollow" target="_blank"><div class="nu ab fo"><div class="nv ab nw cl cj nx"><h2 class="bd jq gy z fp ny fr fs nz fu fw jp bi translated">谷歌研究数据集/量化宽松</h2><div class="oa l"><h3 class="bd b gy z fp ny fr fs nz fu fw dk translated">本页包含与论文相关的数据和评估脚本:https://arxiv.org/abs/2009.06354 QED:A…</h3></div><div class="ob l"><p class="bd b dl z fp ny fr fs nz fu fw dk translated">github.com</p></div></div><div class="od l"><div class="qb l of og oh od oi ix nt"/></div></div></a></div></div><div class="ab cl le lf hu lg" role="separator"><span class="lh bw bk li lj lk"/><span class="lh bw bk li lj lk"/><span class="lh bw bk li lj"/></div><div class="ij ik il im in"><blockquote class="qc"><p id="b11d" class="qd qe jg bd qf qg qh qi qj qk ql mg dk translated"><em class="qm">每周日，我们都会对来自世界各地研究人员的NLP新闻和代码进行一次每周综述。</em></p><p id="eaf3" class="qd qe jg bd qf qg qh qi qj qk ql mg dk translated"><em class="qm">完整报道，关注我们的推特:</em><a class="ae jd" href="http://twitter.com/Quantum_Stat" rel="noopener ugc nofollow" target="_blank"><em class="qm">@ Quantum _ Stat</em></a></p></blockquote><figure class="qo qp qq qr qs is gh gi paragraph-image"><div class="gh gi qn"><img src="../Images/a27c573be94cfa09225436a3fd7f51dd.png" data-original-src="https://miro.medium.com/v2/resize:fit:108/0*35-xm4hmCwbvOM9Z"/></div><figcaption class="iz ja gj gh gi jb jc bd b be z dk translated"><a class="ae jd" href="http://www.quantumstat.com/" rel="noopener ugc nofollow" target="_blank">www.quantumstat.com</a></figcaption></figure></div></div>    
</body>
</html>