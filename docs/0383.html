<html>
<head>
<title>Knowledge Graph Embeddings</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">知识图嵌入</h1>
<blockquote>原文：<a href="https://pub.towardsai.net/knowledge-graph-embeddings-dc9251bffa80?source=collection_archive---------0-----------------------#2020-04-01">https://pub.towardsai.net/knowledge-graph-embeddings-dc9251bffa80?source=collection_archive---------0-----------------------#2020-04-01</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><figure class="gl gn jr js jt ju gh gi paragraph-image"><div role="button" tabindex="0" class="jv jw di jx bf jy"><div class="gh gi jq"><img src="../Images/e749a58cfe4534e584b375687a4fd1f0.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*TtTw78PEmcGAdEDl"/></div></div><figcaption class="kb kc gj gh gi kd ke bd b be z dk translated">由<a class="ae kf" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上的<a class="ae kf" href="https://unsplash.com/@chuttersnap?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> chuttersnap </a>拍摄</figcaption></figure><p id="a71c" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">在之前的故事中，我们介绍了<a class="ae kf" href="https://medium.com/towards-artificial-intelligence/a-gentle-introduction-to-graph-embeddings-c7b3d1db0fa8" rel="noopener">图嵌入简介</a>，<a class="ae kf" href="https://medium.com/towards-artificial-intelligence/random-walk-in-node-embeddings-deepwalk-node2vec-line-and-graphsage-ca23df60e493" rel="noopener">节点嵌入中的随机游走</a>，<a class="ae kf" href="https://medium.com/towards-artificial-intelligence/4-graph-neural-networks-you-need-to-know-wlg-gcn-gat-gin-1bf10d29d836" rel="noopener"> 4图神经网络</a>，以及当GraphSAGE遇到Pinterest。</p><p id="db00" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">在本文中，我介绍了TRESCAL、HolE和SimplE在知识图嵌入中的应用。TRESCAL和HolE都是RESCAL的增强版本。作者使用了不同的方法来克服重新标度的局限性。</p><h1 id="a25b" class="le lf it bd lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma mb bi translated">特雷斯卡</h1><p id="87c7" class="pw-post-body-paragraph kg kh it ki b kj mc kl km kn md kp kq kr me kt ku kv mf kx ky kz mg lb lc ld im bi translated">TRESCAL (Chang等人，2014年)是RESCAL(Nickle等人，2011年)的增强版。作者考虑了实体的类型和关系，以消除不必要的计算，从而减少所需的训练时间，并提高模型精度。这是零钱:</p><ul class=""><li id="4b17" class="mh mi it ki b kj kk kn ko kr mj kv mk kz ml ld mm mn mo mp bi translated"><strong class="ki iu">领域知识</strong>:比如我们可以确认，如果R(关系)是“天生的”，而E1(头部实体)和E2(尾部实体)是一个人，则{E1，R，E2}无效。通过去除不相容的实体关系三元组，不仅减少了训练时间，而且改善了模型误差。</li><li id="2e90" class="mh mi it ki b kj mq kn mr kr ms kv mt kz mu ld mm mn mo mp bi translated"><strong class="ki iu">正则化</strong>:通过应用奇异值分解(SVD)，降低了计算复杂度。</li></ul><h1 id="4b38" class="le lf it bd lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma mb bi translated">孔</h1><p id="8766" class="pw-post-body-paragraph kg kh it ki b kj mc kl km kn md kp kq kr me kt ku kv mf kx ky kz mg lb lc ld im bi translated"><a class="ae kf" href="https://arxiv.org/pdf/1510.04935.pdf" rel="noopener ugc nofollow" target="_blank"> HolE </a> (Nickel et al .，2015)，又名全息嵌入，结合RESCAL(Nickle et al .，2011)和DistMult(Yang et al .，2015)，以更少的计算资源实现更好的结果。为了表示关系，RESCAL需要D的平方(维度的大小)，而HolE只需要D。另一方面，它利用循环相关性来计算关系，使得它可以支持非对称关系(即，有向图)。</p><h1 id="9cae" class="le lf it bd lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma mb bi translated">简单的</h1><p id="6f8c" class="pw-post-body-paragraph kg kh it ki b kj mc kl km kn md kp kq kr me kt ku kv mf kx ky kz mg lb lc ld im bi translated"><a class="ae kf" href="https://arxiv.org/pdf/1802.04868.pdf" rel="noopener ugc nofollow" target="_blank">简单的</a>(卡泽米和普尔，2018)，又名<code class="fe mv mw mx my b">Simple Embedding</code>，提出使用两个关系向量来学习实体嵌入。在链接预测中，我们总是有一个三元组(头实体、关系和尾实体)来训练模型。所以有四个实体嵌入(2头2尾)和一个关系嵌入。问题是，在不同的情况下，有两个嵌入来表示单个实体(分别是头部和尾部)。最终造成了业绩不佳。</p><p id="0427" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">作者建议使用两个关系嵌入而不是一个，这样它可以解决上述问题。将评分函数定义为:</p><blockquote class="mz"><p id="c262" class="na nb it bd nc nd ne nf ng nh ni ld dk translated">1/2(实体_ 1 _头*相关_a *实体_ 2 _尾+实体_ 1 _尾*相关_b *实体_ 2 _头)</p></blockquote><p id="4fec" class="pw-post-body-paragraph kg kh it ki b kj nj kl km kn nk kp kq kr nl kt ku kv nm kx ky kz nn lb lc ld im bi translated">换句话说，它同时计算头部和尾部实体嵌入。</p><h1 id="7243" class="le lf it bd lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma mb bi translated">延伸阅读</h1><ul class=""><li id="308e" class="mh mi it ki b kj mc kn md kr no kv np kz nq ld mm mn mo mp bi translated"><a class="ae kf" href="https://github.com/mnick/holographic-embeddings" rel="noopener ugc nofollow" target="_blank">洞</a>储存库</li><li id="6ca0" class="mh mi it ki b kj mq kn mr kr ms kv mt kz mu ld mm mn mo mp bi translated"><a class="ae kf" href="https://github.com/Mehran-k/SimplE" rel="noopener ugc nofollow" target="_blank">简单的</a>储存库</li></ul><h1 id="3305" class="le lf it bd lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma mb bi translated">参考</h1><ul class=""><li id="c149" class="mh mi it ki b kj mc kn md kr no kv np kz nq ld mm mn mo mp bi translated">K.张文伟、易文泰、杨炳良、米克良。<a class="ae kf" href="https://pdfs.semanticscholar.org/2a5d/9bfc8b1eb7cc19b611b17b81d6ce97f056ca.pdf" rel="noopener ugc nofollow" target="_blank">用于关系抽取的知识库的类型张量分解。</a> 2014年</li><li id="89b3" class="mh mi it ki b kj mq kn mr kr ms kv mt kz mu ld mm mn mo mp bi translated">米（meter的缩写））尼克尔、l .罗萨斯科和t .波吉奥。<a class="ae kf" href="https://arxiv.org/pdf/1510.04935.pdf" rel="noopener ugc nofollow" target="_blank">知识图的全息嵌入</a>。2015</li><li id="c454" class="mh mi it ki b kj mq kn mr kr ms kv mt kz mu ld mm mn mo mp bi translated">南卡泽米先生和普尔先生。<a class="ae kf" href="https://arxiv.org/pdf/1802.04868.pdf" rel="noopener ugc nofollow" target="_blank">知识图中链接预测的简单嵌入</a>。2018</li></ul></div></div>    
</body>
</html>