# 自动编码器平均距离——微软内部用于找出给定数据集之间相似性的经典方法

> 原文：<https://pub.towardsai.net/autoencoder-average-distance-a-classical-way-used-internally-at-microsoft-to-find-out-similarity-95b5fc440cec?source=collection_archive---------2----------------------->

自动编码器平均距离(AAD)使用一种更简单的方法来找出两个数据集之间的距离。神经自动编码器可以将任何数据项转换成数值向量。AAD 距离度量的思想是将两个源数据集转换为具有相同数值的严格数字向量，然后计算每个数据集中向量的平均值之间的差值。

这种计算数据集差异的技术是由 **J. McCaffrey** 和 **S. Chen** 开发的，并已在**微软公司**内部使用。

# 介绍

机器学习领域通常的特点是，从感兴趣的应用中获得的数据通常是稀缺的。换句话说，有相当多的数据可用于一般目的的实施，而用于专门调查的数据数量有限。由于这个原因，人们对开发能够在数据集和领域之间组合、调整和传递知识的方法产生了极大的兴趣。整个研究领域都致力于此，包括领域适应、迁移学习和元学习。这些也构成了机器学习领域中一些活跃的研究领域。

# 距离的概念

所有这些领域的一个基本概念是数据集之间的距离(或相似性)。为了确定两个给定数据集之间的相似性，我们倾向于计算它们之间的距离。例如，跨相似领域传递知识应该比跨遥远领域直观地更容易。同样，考虑到可以选择各种数据集来训练模型，选择与感兴趣的任务最接近的数据集似乎是很自然的。这最终会导致特定任务所需的数据量增加。

然而，这一概念仍然带来某些问题。例如，尽管数据集之间的距离很有用也很简单，但它是一个难以捉摸的概念，以有原则的方式有效地量化它在很大程度上仍然是一个悬而未决的问题。这样做需要解决各种挑战，这些挑战通常恰恰出现在这一概念最有用的环境中，比如上面提到的环境。例如，在受监督的机器学习设置中，数据集由特征和标签组成，虽然定义特征和标签之间的距离通常(但并不总是)很简单，但是为标签定义距离很远，尤其是如果两个任务的标签集不相同(就像现成的预训练模型一样)。

了解两个数据集之间的距离至少有两个原因。首先，数据集距离可用于迁移学习活动，例如使用在一个数据集上训练的预测模型来快速训练第二个数据集。其次，数据集之间的距离可用于扩充训练数据，从而创建可用于构建更准确预测模型的额外合成训练数据。

# 确定数据集距离的方法

有几种方法可以找出两个给定数据集之间的相似性。这些确实包括很好的数学计算水平，并依赖于更高的数学概念。因此，这些方法通常看起来是启发式的和复杂的。寻求量化数据集相似性的迁移学习方法包括多种方式。一种常见的方法是使用代理比较数据集。这些方法中的大多数缺乏保证，高度依赖于所使用的探针模型，并且需要在每个被比较的数据集上训练模型直到完成(例如，找到最佳参数)。

数据集相似性可以使用几种可用的技术来测量。在领域适应的背景下，已经提出了数据分布之间相似性的各种概念。这些包括使用**差异距离**、**数据集距离通过参数灵敏度**、T **最优传输理论**、**对抗验证、**和**寻找两个数据集之间的距离度量**。所有这些方法在它们自己的意义上是独特的，并且它们中的每一个都拥有自己的优点和缺点。

# 自动编码器平均距离(AAD)

虽然其他技术涉及高等数学，并且在实现和理解方面往往变得复杂，但自动编码器平均距离(AAD)使用相对简单的方法。

在这种方法中，我们使用一个**神经自动编码器**，并用它将数据项转换成一个**数值的矢量**。这个想法包括使用自动编码器将要比较的两个数据集转换成具有相同数量值的严格数字向量，然后计算每个数据集中向量的平均值之间的差异。然后，AAD 距离度量包括计算每个数据集中的平均值，然后比较两个平均值来计算距离。这让我们对两个数据集之间的相似性有了一个很好的了解。

例如，考虑 MNIST 数据集。我们将其转换为(0.3456，0.9821，.。。0.5318)。以另一个数据集为例，该数据集包含类似于(“男性”，31，$58，000.00，“销售”)的项，这些项转换为(0.1397，0.7382，.。。0.0458).一旦我们获得了具有相同数量值的各个数据集的数值向量，我们的下一个任务就是找出每个数据集的平均值，然后找出两个平均值之间的差异，以获得 MNIST 和其他给定数据集之间相似性的适当概念。

# AAD 的优点和缺点

其他方法通常具有坚实的数学基础和令人满意的数学特性，但是它们变得太复杂，在某些情况下无法使用。自动编码器平均距离(AAD)度量使用一种更简单的方法。因此，实现 AAD 变得容易多了。

AAD 的优点是 AAD 更容易计算，更容易理解，并且可以很容易地用于任何类型的数据，包括混合了数字和非数字预测变量的数据。

AAD 的主要缺点是它包含的信息不如其他方法多。因此，在某些情况下，它可能不会给出理想的结果。

# 在 Brats 数据集上实现 AAD 的思想

让我们尝试在两个脑瘤分割(Brats)数据集上实现 AAD 的思想。数据集可以使用下面给出的链接从 Kaggle 下载。

[](https://www.kaggle.com/datasets/ahmedhamada0/brain-tumor-detection) [## Br35H::脑瘤检测 2020

### 脑肿瘤检测

2020 脑瘤 Detectionwww.kaggle.com](https://www.kaggle.com/datasets/ahmedhamada0/brain-tumor-detection) [](https://www.kaggle.com/datasets/navoneel/brain-mri-images-for-brain-tumor-detection) [## 用于脑肿瘤检测的脑 MRI 图像

### Kaggle 是世界上最大的数据科学社区，拥有强大的工具和资源来帮助您实现您的数据…

www.kaggle.com](https://www.kaggle.com/datasets/navoneel/brain-mri-images-for-brain-tumor-detection) 

笔记本中提供了实现的代码，下面给出了链接。

[https://drive . Google . com/file/d/1 F3 bimv 6 eixq 5v 0 sqlcpkug 8 jlvxrcoud/view？usp=drivesdk](https://drive.google.com/file/d/1f3BiMv6eIxq5V0SQlcpKUG8jLvXrCuod/view?usp=drivesdk)

关于上面写的代码，一个有趣的事情是，它可以用于任何两个稍加修改的数据集。

请注意，AAD 的思想是以一种非常直观的方式在代码中实现的，它可能需要一定的即兴创作。这只是试图复制微软使用的 AAD 技术，并不严格。微软独自拥有所有的权利，以防后来发现该技术是由微软版权所有。上面写的这段代码是基于我自己对 Autoencoder 平均距离概念的理解，并不是一些标准化代码的任何复制，以防后来发现这项技术是微软的版权，不能在公共领域内使用。

# **结论**

距离的概念是如此基本和根本的概念，以至于它经常被用作其他工具和方法从中获得效用的原始概念。这里提出的 AAD 技术似乎拥有一个潜在的解决方案，来解决由于特殊数据的有限可用性而产生的问题。它最有可能被用作机器学习管道中的工具。这种技术的潜在影响前景似乎足够广阔，可以涵盖大多数基本使用机器学习的环境。这尤其是由于 AAD 概念相对简单。也许最直接的影响是通过它在迁移学习中的应用。这种方法的改进可以产生无数的结果，从社会到环境，无论是在机器学习社区内部还是外部。

[1] [计算机器学习数据集的相似度——纯 AI](https://pureai.com/articles/2020/12/01/dataset-distance.aspx#:~:text=The%20hybrid%20metric%20used%20in%20the%20%22Geometric%20Dataset,a%20variation%20called%202-Wasserstein%20rather%20than%20basic%201-Wasserstein.)

[2]【arxiv.org 【2002.02923】通过最优运输的几何数据集距离

[3] [自动编码器—维基百科](https://en.wikipedia.org/wiki/Autoencoder)