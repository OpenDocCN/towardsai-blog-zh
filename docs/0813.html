<html>
<head>
<title>Linear Regression Analysis on the Auto Dataset</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">汽车数据集的线性回归分析</h1>
<blockquote>原文：<a href="https://pub.towardsai.net/linear-regression-analysis-on-the-auto-dataset-3464654abde8?source=collection_archive---------1-----------------------#2020-08-17">https://pub.towardsai.net/linear-regression-analysis-on-the-auto-dataset-3464654abde8?source=collection_archive---------1-----------------------#2020-08-17</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><h2 id="84f5" class="ir is it bd b dl iu iv iw ix iy iz dk ja translated" aria-label="kicker paragraph"><a class="ae ep" href="https://towardsai.net/p/category/machine-learning" rel="noopener ugc nofollow" target="_blank">机器学习</a></h2><div class=""/><div class=""><h2 id="ebcf" class="pw-subtitle-paragraph jz jc it bd b ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq dk translated"><em class="kr">对《统计学习导论》一书中自动数据集的深入分析</em></h2></div><figure class="kt ku kv kw gt kx gh gi paragraph-image"><div role="button" tabindex="0" class="ky kz di la bf lb"><div class="gh gi ks"><img src="../Images/03571bac5c9634c15b9d49cd7b5a4b13.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*J7M9wyX0PlrEi2Lr"/></div></div><figcaption class="le lf gj gh gi lg lh bd b be z dk translated">照片由<a class="ae li" href="https://unsplash.com/@chuttersnap?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> chuttersnap </a>在<a class="ae li" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上拍摄</figcaption></figure><p id="6bd0" class="pw-post-body-paragraph lj lk it ll b lm ln kd lo lp lq kg lr ls lt lu lv lw lx ly lz ma mb mc md me im bi translated">Auto Dataset是一个非常受欢迎的数据集，它在试图了解机器学习算法的初学者中非常流行。<br/>它包含几个变量，如几辆汽车的马力、重量和加速度等，是我开始机器学习之旅的第一批数据集之一<br/>对于本文，我将实现一个线性回归模型来预测几个独立变量的“每加仑英里数”变量。所以让我们开始吧。</p><h1 id="4489" class="mf mg it bd mh mi mj mk ml mm mn mo mp ki mq kj mr kl ms km mt ko mu kp mv mw bi translated"><strong class="ak">将数据集导入Jupyter笔记本:</strong></h1><pre class="kt ku kv kw gt mx my mz na aw nb bi"><span id="dc44" class="nc mg it my b gy nd ne l nf ng">data = pd.read_csv('Auto (1).csv')<br/>data</span></pre><figure class="kt ku kv kw gt kx gh gi paragraph-image"><div role="button" tabindex="0" class="ky kz di la bf lb"><div class="gh gi nh"><img src="../Images/bde287c443e4887f1d771f08cf3f3b4f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*N_uB653rv6mnZA85WvCb5g.png"/></div></div><figcaption class="le lf gj gh gi lg lh bd b be z dk translated">自动数据集</figcaption></figure><p id="e018" class="pw-post-body-paragraph lj lk it ll b lm ln kd lo lp lq kg lr ls lt lu lv lw lx ly lz ma mb mc md me im bi translated">乍一看，我看到几个变量是典型汽车的属性，如每加仑英里数、气缸数、排量、马力、重量和加速度。</p><h1 id="485d" class="mf mg it bd mh mi mj mk ml mm mn mo mp ki mq kj mr kl ms km mt ko mu kp mv mw bi translated"><strong class="ak">分析数据集</strong></h1><p id="c53b" class="pw-post-body-paragraph lj lk it ll b lm ni kd lo lp nj kg lr ls nk lu lv lw nl ly lz ma nm mc md me im bi translated">让我们创建一个热图，看看这些变量是如何相互关联的。</p><pre class="kt ku kv kw gt mx my mz na aw nb bi"><span id="26d5" class="nc mg it my b gy nd ne l nf ng">plt.figure(figsize = (12,6))<br/>sns.heatmap(data.corr(),annot = True)</span></pre><figure class="kt ku kv kw gt kx gh gi paragraph-image"><div role="button" tabindex="0" class="ky kz di la bf lb"><div class="gh gi nn"><img src="../Images/6f32560624634468d43ff581050500cc.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Leg18b8LpA5-HJ_8Ao7Ikw.png"/></div></div><figcaption class="le lf gj gh gi lg lh bd b be z dk translated">数据集的热图</figcaption></figure><p id="36ed" class="pw-post-body-paragraph lj lk it ll b lm ln kd lo lp lq kg lr ls lt lu lv lw lx ly lz ma mb mc md me im bi translated">从热图来看，我发现每加仑<strong class="ll jd">英里数</strong>与重量、排量、气缸和马力高度相关。</p><p id="c4bf" class="pw-post-body-paragraph lj lk it ll b lm ln kd lo lp lq kg lr ls lt lu lv lw lx ly lz ma mb mc md me im bi translated">这确实有道理，因为气缸越多，燃烧的燃料就越多，因此里程就越少，重量越大，燃烧的燃料就越多。</p><p id="a130" class="pw-post-body-paragraph lj lk it ll b lm ln kd lo lp lq kg lr ls lt lu lv lw lx ly lz ma mb mc md me im bi translated">马力和排量也可以做同样的类比。</p><p id="0234" class="pw-post-body-paragraph lj lk it ll b lm ln kd lo lp lq kg lr ls lt lu lv lw lx ly lz ma mb mc md me im bi translated">但是有一件事我们必须考虑，那就是多重共线性。</p><p id="23f7" class="pw-post-body-paragraph lj lk it ll b lm ln kd lo lp lq kg lr ls lt lu lv lw lx ly lz ma mb mc md me im bi translated">这四个自变量即使与mpg高度相关，也彼此高度相关。这怎么会是个问题呢？</p><p id="b3a4" class="pw-post-body-paragraph lj lk it ll b lm ln kd lo lp lq kg lr ls lt lu lv lw lx ly lz ma mb mc md me im bi translated">多重共线性会给我们带来不可靠的系数和错误的P值，从而导致对模型的错误解释。</p><p id="0107" class="pw-post-body-paragraph lj lk it ll b lm ln kd lo lp lq kg lr ls lt lu lv lw lx ly lz ma mb mc md me im bi translated">更多细节请点击</p><p id="a035" class="pw-post-body-paragraph lj lk it ll b lm ln kd lo lp lq kg lr ls lt lu lv lw lx ly lz ma mb mc md me im bi translated">让我们看看结对图:</p><figure class="kt ku kv kw gt kx gh gi paragraph-image"><div role="button" tabindex="0" class="ky kz di la bf lb"><div class="gh gi no"><img src="../Images/d66d3b42bc2e0250aac75a67b9d96914.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*J9VRazYitOVr4hrFrpQ-lg.png"/></div></div><figcaption class="le lf gj gh gi lg lh bd b be z dk translated">数据集的配对图</figcaption></figure><p id="466f" class="pw-post-body-paragraph lj lk it ll b lm ln kd lo lp lq kg lr ls lt lu lv lw lx ly lz ma mb mc md me im bi translated">存在定量和定性变量的混合。</p><h1 id="fc24" class="mf mg it bd mh mi mj mk ml mm mn mo mp ki mq kj mr kl ms km mt ko mu kp mv mw bi translated"><strong class="ak">选择自变量</strong></h1><p id="0dad" class="pw-post-body-paragraph lj lk it ll b lm ni kd lo lp nj kg lr ls nk lu lv lw nl ly lz ma nm mc md me im bi translated">我如何选择独立变量？由于变量之间存在大量多重共线性，我可以使用<strong class="ll jd">正向选择</strong></p><p id="a02a" class="pw-post-body-paragraph lj lk it ll b lm ln kd lo lp lq kg lr ls lt lu lv lw lx ly lz ma mb mc md me im bi translated">从相关性最高的变量开始，一直到相关性最低的变量。</p><p id="bd55" class="pw-post-body-paragraph lj lk it ll b lm ln kd lo lp lq kg lr ls lt lu lv lw lx ly lz ma mb mc md me im bi translated">与<strong class="ll jd"> MPG </strong>相关性最高的变量是<strong class="ll jd">体重</strong>。</p><p id="2692" class="pw-post-body-paragraph lj lk it ll b lm ln kd lo lp lq kg lr ls lt lu lv lw lx ly lz ma mb mc md me im bi translated">我将X和y定义为:</p><pre class="kt ku kv kw gt mx my mz na aw nb bi"><span id="854d" class="nc mg it my b gy nd ne l nf ng">X = data['weight']<br/>y = data['mpg']</span></pre><p id="3471" class="pw-post-body-paragraph lj lk it ll b lm ln kd lo lp lq kg lr ls lt lu lv lw lx ly lz ma mb mc md me im bi translated">创建散点图:</p><pre class="kt ku kv kw gt mx my mz na aw nb bi"><span id="9bc3" class="nc mg it my b gy nd ne l nf ng">sns.scatterplot(X,y)</span></pre><figure class="kt ku kv kw gt kx gh gi paragraph-image"><div role="button" tabindex="0" class="ky kz di la bf lb"><div class="gh gi np"><img src="../Images/17883d5ba884503dedf16632ed7017a1.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*blIzH5KcCPXT6BQgTpwv8A.png"/></div></div><figcaption class="le lf gj gh gi lg lh bd b be z dk translated">mpg和重量散点图</figcaption></figure><p id="04cb" class="pw-post-body-paragraph lj lk it ll b lm ln kd lo lp lq kg lr ls lt lu lv lw lx ly lz ma mb mc md me im bi translated">散点图中似乎存在一些非线性，<strong class="ll jd">违反了</strong>线性回归的第一个假设<strong class="ll jd">线性。</strong></p><p id="984a" class="pw-post-body-paragraph lj lk it ll b lm ln kd lo lp lq kg lr ls lt lu lv lw lx ly lz ma mb mc md me im bi translated">我可以应用非线性变换，比如对数变换，来降低非线性度，不过我们以后再做吧。</p><p id="f6e5" class="pw-post-body-paragraph lj lk it ll b lm ln kd lo lp lq kg lr ls lt lu lv lw lx ly lz ma mb mc md me im bi translated">现在，让我们继续处理上面的变量。</p><p id="1be6" class="pw-post-body-paragraph lj lk it ll b lm ln kd lo lp lq kg lr ls lt lu lv lw lx ly lz ma mb mc md me im bi translated">我将变量分成测试和训练数据集</p><pre class="kt ku kv kw gt mx my mz na aw nb bi"><span id="e6b5" class="nc mg it my b gy nd ne l nf ng">X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)</span></pre><p id="8ca2" class="pw-post-body-paragraph lj lk it ll b lm ln kd lo lp lq kg lr ls lt lu lv lw lx ly lz ma mb mc md me im bi translated">从scikit学习库中导入线性回归模块，并使其适合训练数据。</p><pre class="kt ku kv kw gt mx my mz na aw nb bi"><span id="0166" class="nc mg it my b gy nd ne l nf ng">from sklearn.linear_model import LinearRegression<br/>LR = LinearRegression()<br/>LR.fit(X_train,y_train)</span></pre><p id="5b93" class="pw-post-body-paragraph lj lk it ll b lm ln kd lo lp lq kg lr ls lt lu lv lw lx ly lz ma mb mc md me im bi translated">使用训练好的模型进行预测</p><pre class="kt ku kv kw gt mx my mz na aw nb bi"><span id="a159" class="nc mg it my b gy nd ne l nf ng">pred = LR.predict(X_test)</span></pre><p id="bf37" class="pw-post-body-paragraph lj lk it ll b lm ln kd lo lp lq kg lr ls lt lu lv lw lx ly lz ma mb mc md me im bi translated">做出预测后，我想检查我的模型的性能指标，如R2分数和均方根误差</p><pre class="kt ku kv kw gt mx my mz na aw nb bi"><span id="62f6" class="nc mg it my b gy nd ne l nf ng">print(r2_score(pred,y_test))<br/>print(np.sqrt(mean_squared_error(pred,y_test)))<br/></span></pre><p id="a977" class="pw-post-body-paragraph lj lk it ll b lm ln kd lo lp lq kg lr ls lt lu lv lw lx ly lz ma mb mc md me im bi translated">我的RMSE得分为4.29，R2得分为0.59，这并不令人印象深刻。让我们看看我们的残差，看看是否满足<strong class="ll jd">同方差</strong>和<strong class="ll jd">正态性</strong>的条件？</p><pre class="kt ku kv kw gt mx my mz na aw nb bi"><span id="9e9d" class="nc mg it my b gy nd ne l nf ng">sns.scatterplot(pred1-y_train,y_train)<br/>plt.xlabel('fitted values')<br/>plt.ylabel('residuals')</span></pre><figure class="kt ku kv kw gt kx gh gi paragraph-image"><div role="button" tabindex="0" class="ky kz di la bf lb"><div class="gh gi np"><img src="../Images/58924aab80b6afc9a8bcb32db7204969.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*ZTGC5DN6VHyqgH_gRUVa5Q.png"/></div></div><figcaption class="le lf gj gh gi lg lh bd b be z dk translated">残差图</figcaption></figure><p id="eb03" class="pw-post-body-paragraph lj lk it ll b lm ln kd lo lp lq kg lr ls lt lu lv lw lx ly lz ma mb mc md me im bi translated">残差显示了<strong class="ll jd">非恒定方差</strong>，这表明<strong class="ll jd">同方差</strong>在我们的模型中不存在。</p><p id="198f" class="pw-post-body-paragraph lj lk it ll b lm ln kd lo lp lq kg lr ls lt lu lv lw lx ly lz ma mb mc md me im bi translated">让我们看看距离图，看看我们的残差是否有正态分布。</p><figure class="kt ku kv kw gt kx gh gi paragraph-image"><div role="button" tabindex="0" class="ky kz di la bf lb"><div class="gh gi nq"><img src="../Images/ee7d40fb301f96aa9b3fe17d6867fc2b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*ZvMYL9XcNWPmxIx-i6AFYQ.png"/></div></div><figcaption class="le lf gj gh gi lg lh bd b be z dk translated">我们残差的距离图</figcaption></figure><p id="835f" class="pw-post-body-paragraph lj lk it ll b lm ln kd lo lp lq kg lr ls lt lu lv lw lx ly lz ma mb mc md me im bi translated">残差确实显示了一个向右稍微倾斜的正态分布。但我们不能否认的是，该模型未能满足两个线性回归假设(<strong class="ll jd">同质性和一个线性度</strong>)，因此，该模型对于做出预测是不可靠的。</p><h1 id="d142" class="mf mg it bd mh mi mj mk ml mm mn mo mp ki mq kj mr kl ms km mt ko mu kp mv mw bi translated"><strong class="ak">我如何改进模型？</strong></h1><p id="c1fd" class="pw-post-body-paragraph lj lk it ll b lm ni kd lo lp nj kg lr ls nk lu lv lw nl ly lz ma nm mc md me im bi translated">有几种方法可以解决缺乏同性恋安全感的问题。</p><p id="9562" class="pw-post-body-paragraph lj lk it ll b lm ln kd lo lp lq kg lr ls lt lu lv lw lx ly lz ma mb mc md me im bi translated">最常见的方法是对因变量进行对数变换。例如:我可以尝试预测“英里每加仑”变量，而不是尝试预测“英里每加仑”的对数变换，只要残差符合<strong class="ll jd">同质性的条件。</strong></p><p id="41aa" class="pw-post-body-paragraph lj lk it ll b lm ln kd lo lp lq kg lr ls lt lu lv lw lx ly lz ma mb mc md me im bi translated"><strong class="ll jd">非线性</strong>可以用同样的方式处理。对独立变量进行对数变换可以使变量之间的关系更加线性。</p><p id="d053" class="pw-post-body-paragraph lj lk it ll b lm ln kd lo lp lq kg lr ls lt lu lv lw lx ly lz ma mb mc md me im bi translated">因此，让我们尝试一下日志转换</p><pre class="kt ku kv kw gt mx my mz na aw nb bi"><span id="ad4d" class="nc mg it my b gy nd ne l nf ng">X = np.log(data[['weight']]) <br/>X = X.join(data['ones'])<br/>y = np.log(data['mpg'])</span></pre><p id="bdfa" class="pw-post-body-paragraph lj lk it ll b lm ln kd lo lp lq kg lr ls lt lu lv lw lx ly lz ma mb mc md me im bi translated">再次创建散点图给我们:</p><figure class="kt ku kv kw gt kx gh gi paragraph-image"><div role="button" tabindex="0" class="ky kz di la bf lb"><div class="gh gi nr"><img src="../Images/32819a1ac1080b3c3b1ed2e92b117a3c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*SLs7Xdu2WHeaT_TYFQ5sQg.png"/></div></div><figcaption class="le lf gj gh gi lg lh bd b be z dk translated">对数转换变量的散点图</figcaption></figure><p id="1b11" class="pw-post-body-paragraph lj lk it ll b lm ln kd lo lp lq kg lr ls lt lu lv lw lx ly lz ma mb mc md me im bi translated">这种关系现在看起来更加线性。我将线性回归模型拟合到新拟合的对数转换变量，并检查性能指标。</p><pre class="kt ku kv kw gt mx my mz na aw nb bi"><span id="8d59" class="nc mg it my b gy nd ne l nf ng">print(r2_score(pred,y_test))<br/>print(np.sqrt(mean_squared_error(pred,y_test)))</span></pre><p id="a733" class="pw-post-body-paragraph lj lk it ll b lm ln kd lo lp lq kg lr ls lt lu lv lw lx ly lz ma mb mc md me im bi translated">r2分数从0.59提高到0.72，这是一个好现象。</p><p id="c1b4" class="pw-post-body-paragraph lj lk it ll b lm ln kd lo lp lq kg lr ls lt lu lv lw lx ly lz ma mb mc md me im bi translated">让我们检查残差图，看看<strong class="ll jd">非恒定方差</strong>是否已经减少。</p><figure class="kt ku kv kw gt kx gh gi paragraph-image"><div role="button" tabindex="0" class="ky kz di la bf lb"><div class="gh gi ns"><img src="../Images/e44d62d36260f393ed823db99e631b38.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*zQtNkNK7-7QfkoMUtQGVcQ.png"/></div></div><figcaption class="le lf gj gh gi lg lh bd b be z dk translated">残差与y _测试图</figcaption></figure><p id="549e" class="pw-post-body-paragraph lj lk it ll b lm ln kd lo lp lq kg lr ls lt lu lv lw lx ly lz ma mb mc md me im bi translated">方差变得更加稳定，看起来比之前的散点图好得多。让我们检查残差的距离图。</p><figure class="kt ku kv kw gt kx gh gi paragraph-image"><div role="button" tabindex="0" class="ky kz di la bf lb"><div class="gh gi nt"><img src="../Images/a69b6faab2840a18542de2c59f2b8f60.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*yjmdxnnSrb2UZSfCjt-N9Q.png"/></div></div><figcaption class="le lf gj gh gi lg lh bd b be z dk translated">对数变换残差的距离图</figcaption></figure><p id="7e7b" class="pw-post-body-paragraph lj lk it ll b lm ln kd lo lp lq kg lr ls lt lu lv lw lx ly lz ma mb mc md me im bi translated">distplot中不存在偏斜。</p><p id="1972" class="pw-post-body-paragraph lj lk it ll b lm ln kd lo lp lq kg lr ls lt lu lv lw lx ly lz ma mb mc md me im bi translated">对数转换确实改进了模型，并且比以前的模型更好地满足了线性回归假设。<br/>但是我只使用了一个变量，即权重变量，让我们继续使用<strong class="ll jd">前向选择</strong>技术，但是添加了其余的变量，看看得到了什么结果。</p><h1 id="e67c" class="mf mg it bd mh mi mj mk ml mm mn mo mp ki mq kj mr kl ms km mt ko mu kp mv mw bi translated"><strong class="ak">多元线性回归</strong></h1><pre class="kt ku kv kw gt mx my mz na aw nb bi"><span id="839d" class="nc mg it my b gy nd ne l nf ng">X = np.log(data[['weight','acceleration','year','origin']]) <br/>X = X.join(data['ones'])<br/>y = np.log(data['mpg'])</span></pre><p id="7e26" class="pw-post-body-paragraph lj lk it ll b lm ln kd lo lp lq kg lr ls lt lu lv lw lx ly lz ma mb mc md me im bi translated">将线性回归模型拟合到数据集</p><pre class="kt ku kv kw gt mx my mz na aw nb bi"><span id="35ce" class="nc mg it my b gy nd ne l nf ng">from sklearn.linear_model import LinearRegression<br/>LR = LinearRegression()<br/>LR.fit(X_train,y_train)<br/>pred = LR.predict(X_test)</span></pre><p id="37e8" class="pw-post-body-paragraph lj lk it ll b lm ln kd lo lp lq kg lr ls lt lu lv lw lx ly lz ma mb mc md me im bi translated">创建残差图:</p><figure class="kt ku kv kw gt kx gh gi paragraph-image"><div role="button" tabindex="0" class="ky kz di la bf lb"><div class="gh gi ns"><img src="../Images/748b0bbca2e24fa6af5a828d0380b6a3.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*HPQS1QDPHmMgyhwhFEZdWQ.png"/></div></div><figcaption class="le lf gj gh gi lg lh bd b be z dk translated">残差图多元线性回归</figcaption></figure><p id="d786" class="pw-post-body-paragraph lj lk it ll b lm ln kd lo lp lq kg lr ls lt lu lv lw lx ly lz ma mb mc md me im bi translated">计算性能指标</p><pre class="kt ku kv kw gt mx my mz na aw nb bi"><span id="a2a4" class="nc mg it my b gy nd ne l nf ng">print(r2_score(pred,y_test))<br/>print(np.sqrt(mean_squared_error(pred,y_test)))</span></pre><p id="5698" class="pw-post-body-paragraph lj lk it ll b lm ln kd lo lp lq kg lr ls lt lu lv lw lx ly lz ma mb mc md me im bi translated">我得到了0.874的R2分数，比之前0.72的模型分数好得多。<br/>现在，可能会有添加相关变量(排量、马力、气缸)的诱惑。<br/>虽然添加变量可以增加R2得分，但如果变量之间存在严重的多重共线性，它们会给出错误的系数值。<br/>但是我怎么知道现在的变量有可靠的系数？让我们检查一下。使用scipy库中的OLS方法，我得到了以下结果。</p><figure class="kt ku kv kw gt kx gh gi paragraph-image"><div role="button" tabindex="0" class="ky kz di la bf lb"><div class="gh gi nu"><img src="../Images/a4ec87b20547e6b40dc2aa0ed18e6a39.png" data-original-src="https://miro.medium.com/v2/resize:fit:1302/format:webp/1*Lu6aUWxp-x9Q5VK5rUx4Vw.png"/></div></div><figcaption class="le lf gj gh gi lg lh bd b be z dk translated">OLS回归综述</figcaption></figure><p id="5257" class="pw-post-body-paragraph lj lk it ll b lm ln kd lo lp lq kg lr ls lt lu lv lw lx ly lz ma mb mc md me im bi translated">我得到了0.874的R2分数，比之前的模型好得多。<br/>严重多重共线性的一个标志是系数的符号是错误的，但这里不是这种情况。<br/>热图和OLS回归的系数符号相同。</p><p id="9c5a" class="pw-post-body-paragraph lj lk it ll b lm ln kd lo lp lq kg lr ls lt lu lv lw lx ly lz ma mb mc md me im bi translated">但是一些变量具有高P值，这意味着它们与因变量没有显著的关系。<br/>这是因为多重共线性吗？P值可靠吗？</p><p id="0e4f" class="pw-post-body-paragraph lj lk it ll b lm ln kd lo lp lq kg lr ls lt lu lv lw lx ly lz ma mb mc md me im bi translated">通过计算可变通货膨胀系数，我可以挖掘得更深。<br/>但是如果我必须做出选择，我会选择这个模型，因为除了对多重共线性条件有一点怀疑之外，所有条件都已满足。</p><h1 id="75cd" class="mf mg it bd mh mi mj mk ml mm mn mo mp ki mq kj mr kl ms km mt ko mu kp mv mw bi translated"><strong class="ak">结论</strong></h1><p id="4310" class="pw-post-body-paragraph lj lk it ll b lm ni kd lo lp nj kg lr ls nk lu lv lw nl ly lz ma nm mc md me im bi translated">综上所述，我得出的结论是，对数变换在处理非线性和异方差方面非常有效，变量越多，R2得分越高，但我们必须小心多重共线性。</p><p id="032e" class="pw-post-body-paragraph lj lk it ll b lm ln kd lo lp lq kg lr ls lt lu lv lw lx ly lz ma mb mc md me im bi translated">[1]:加雷斯·詹姆斯..<em class="nv">统计学习概论<br/></em><a class="ae li" href="http://faculty.marshall.usc.edu/gareth-james/ISL/" rel="noopener ugc nofollow" target="_blank">http://faculty.marshall.usc.edu/gareth-james/ISL/</a></p></div></div>    
</body>
</html>