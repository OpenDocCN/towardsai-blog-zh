<html>
<head>
<title>DALL·E: Generate Images from Text Captions! Inspired by GPT-3 and Image-GPT from OpenAI</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">DALL E:从文本标题生成图像！灵感来自OpenAI的GPT-3和图像-GPT</h1>
<blockquote>原文：<a href="https://pub.towardsai.net/dall-e-generate-images-from-text-captions-inspired-by-gpt-3-and-image-gpt-from-openai-aacd7cd46e03?source=collection_archive---------1-----------------------#2021-01-06">https://pub.towardsai.net/dall-e-generate-images-from-text-captions-inspired-by-gpt-3-and-image-gpt-from-openai-aacd7cd46e03?source=collection_archive---------1-----------------------#2021-01-06</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><h2 id="f5b1" class="ir is it bd b dl iu iv iw ix iy iz dk ja translated" aria-label="kicker paragraph"><a class="ae ep" href="https://towardsai.net/p/category/computer-vision" rel="noopener ugc nofollow" target="_blank">计算机视觉</a>，<a class="ae ep" href="https://towardsai.net/p/category/nlp" rel="noopener ugc nofollow" target="_blank">自然语言处理</a></h2><div class=""/><div class=""><h2 id="420a" class="pw-subtitle-paragraph jz jc it bd b ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq dk translated">OpenAI成功训练了一个能够从文本字幕生成图像的网络。它与GPT 3号和GPT图像非常相似，产生了惊人的效果。</h2></div><figure class="kr ks kt ku gt kv"><div class="bz fp l di"><div class="kw kx l"/></div></figure><p id="6f59" class="pw-post-body-paragraph ky kz it la b lb lc kd ld le lf kg lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">DALL-E是OpenAI基于GPT-3开发的新型神经网络。<br/>事实上，它是GPT 3的缩小版，使用了120亿个参数，而不是1750亿个。但它经过专门训练，可以从文本描述中生成图像，使用文本图像对的数据集，而不是像GPT-3那样的非常广泛的数据集。它可以使用自然语言从文本字幕中创建图像，就像GPT 3创建网站和故事一样。</p><figure class="kr ks kt ku gt kv gh gi paragraph-image"><div role="button" tabindex="0" class="lv lw di lx bf ly"><div class="gh gi lu"><img src="../Images/62144c2fa146d7ee60e25aebdc4e3e4d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*O2FieNlug4hkZBqHoUQaUQ.png"/></div></div><figcaption class="mb mc gj gh gi md me bd b be z dk translated">图片经由<a class="ae mf" href="https://openai.com/blog/dall-e/" rel="noopener ugc nofollow" target="_blank">https://openai.com/blog/dall-e/</a></figcaption></figure><p id="3391" class="pw-post-body-paragraph ky kz it la b lb lc kd ld le lf kg lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">这是图像GPT和GPT-3的延续，我在以前的视频中都提到过，如果你还没有看过的话。</p><figure class="kr ks kt ku gt kv"><div class="bz fp l di"><div class="kw kx l"/></div></figure><figure class="kr ks kt ku gt kv"><div class="bz fp l di"><div class="kw kx l"/></div></figure><p id="48a9" class="pw-post-body-paragraph ky kz it la b lb lc kd ld le lf kg lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">DALL-E与GPT-3非常相似，因为它也是一个转换器语言模型，接收文本和图像作为输入，以多种形式输出最终的转换图像。它可以编辑图像中特定对象的属性，正如您在这里看到的。或者甚至同时控制多个对象及其属性。这是一项非常复杂的任务，因为网络必须理解对象之间的关系，并基于其理解创建图像。就拿这个例子来说，网络上出现了“一个戴着蓝色帽子、红色手套、绿色衬衫和黄色裤子的小企鹅表情符号”。所有这些组成部分都需要理解，物体，颜色，甚至物体的位置。这意味着手套必须是红色的，并且戴在企鹅的手上，其他地方也一样。考虑到任务的复杂性，结果是非常令人印象深刻的。</p><figure class="kr ks kt ku gt kv gh gi paragraph-image"><div role="button" tabindex="0" class="lv lw di lx bf ly"><div class="gh gi mg"><img src="../Images/37de576cf89f0610857ac2bc293072df.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*q7F4N51nJ78d7OyEG0OV_Q.png"/></div></div><figcaption class="mb mc gj gh gi md me bd b be z dk translated">图片来自<a class="ae mf" href="https://openai.com/blog/dall-e/" rel="noopener ugc nofollow" target="_blank">https://openai.com/blog/dall-e/</a></figcaption></figure><p id="3136" class="pw-post-body-paragraph ky kz it la b lb lc kd ld le lf kg lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">我们可以看到另一个更简单的例子，我们将“一个红色小块放在一个绿色大块上”输入网络。现在它只需要知道有两个块，它们的颜色，一个小一个大。这对我们来说似乎很简单，但是要做到这一点需要很高的理解水平。正如你所看到的，它仍然不完美，但是我们已经非常接近了！</p><figure class="kr ks kt ku gt kv gh gi paragraph-image"><div role="button" tabindex="0" class="lv lw di lx bf ly"><div class="gh gi mg"><img src="../Images/8a0a1d57fd719b22dd92ee02cf71f144.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*4HoD9dUY_7G2anNQGYWq4Q.png"/></div></div><figcaption class="mb mc gj gh gi md me bd b be z dk translated">图片来自<a class="ae mf" href="https://openai.com/blog/dall-e/" rel="noopener ugc nofollow" target="_blank">https://openai.com/blog/dall-e/</a></figcaption></figure><p id="0670" class="pw-post-body-paragraph ky kz it la b lb lc kd ld le lf kg lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">DALL-E还能够改变场景的视点。例如，在这里，我们发送了“一只山鹰的特写镜头”，这些是结果。</p><figure class="kr ks kt ku gt kv gh gi paragraph-image"><div role="button" tabindex="0" class="lv lw di lx bf ly"><div class="gh gi mg"><img src="../Images/bb29ec27ffee38bd98e4ad84cf1783bd.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*PrLRuWXUnl08BpYybeFH1g.png"/></div></div><figcaption class="mb mc gj gh gi md me bd b be z dk translated">图片来自<a class="ae mf" href="https://openai.com/blog/dall-e/" rel="noopener ugc nofollow" target="_blank">https://openai.com/blog/dall-e/</a></figcaption></figure><p id="6001" class="pw-post-body-paragraph ky kz it la b lb lc kd ld le lf kg lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">在这里，我们只是把鹰换成了狐狸，这就是生成的结果。</p><figure class="kr ks kt ku gt kv gh gi paragraph-image"><div role="button" tabindex="0" class="lv lw di lx bf ly"><div class="gh gi mh"><img src="../Images/e84be1becdcd9baeb5c8f263601d26f0.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*EPVkn9EEWwuyxtjKDzjdSw.png"/></div></div><figcaption class="mb mc gj gh gi md me bd b be z dk translated">图片来自https://openai.com/blog/dall-e/<a class="ae mf" href="https://openai.com/blog/dall-e/" rel="noopener ugc nofollow" target="_blank"/></figcaption></figure><p id="4c8c" class="pw-post-body-paragraph ky kz it la b lb lc kd ld le lf kg lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">当然，一个简单的标题可以产生无限的似是而非的图像，如果你想到一幅“日出时狐狸坐在田野里的画”，没有人知道你在想什么。有许多变量，如狐狸本身，它的颜色，它在看哪里，它的位置是什么，我们甚至没有谈论背景和绘画的风格。幸运的是，由于它与GPT-3非常相似，我们可以向输入文本添加细节，并生成更接近我们预期的东西，正如你在这里看到的不同风格的绘画一样。</p><figure class="kr ks kt ku gt kv gh gi paragraph-image"><div role="button" tabindex="0" class="lv lw di lx bf ly"><div class="gh gi mi"><img src="../Images/7aa3ea6f98d840c76b0bfdfa33ad09c1.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*DsgMrEmdiPLKHwdYCO04HQ.png"/></div></div><figcaption class="mb mc gj gh gi md me bd b be z dk translated">图片来自https://openai.com/blog/dall-e/<a class="ae mf" href="https://openai.com/blog/dall-e/" rel="noopener ugc nofollow" target="_blank"/></figcaption></figure><p id="cebd" class="pw-post-body-paragraph ky kz it la b lb lc kd ld le lf kg lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">它还可以使用彼此不相关的对象生成图像，如创建一个逼真的鳄梨椅，或生成新的表情符号等原始和看不见的插图。</p><div class="kr ks kt ku gt ab cb"><figure class="mj kv mk ml mm mn mo paragraph-image"><div role="button" tabindex="0" class="lv lw di lx bf ly"><img src="../Images/99bf093f539f0cd0211adb9856794afd.png" data-original-src="https://miro.medium.com/v2/resize:fit:1000/format:webp/1*3fTfYlv2WtRPhf0MKidRew.png"/></div></figure><figure class="mj kv mp ml mm mn mo paragraph-image"><div role="button" tabindex="0" class="lv lw di lx bf ly"><img src="../Images/1bee083700c9c0b758f3f82ec4d89ee6.png" data-original-src="https://miro.medium.com/v2/resize:fit:1002/format:webp/1*e3HaQJOUQ9OUwSLSf2-c5A.png"/></div><figcaption class="mb mc gj gh gi md me bd b be z dk mq di mr ms translated">图片经由<a class="ae mf" href="https://openai.com/blog/dall-e/" rel="noopener ugc nofollow" target="_blank">https://openai.com/blog/dall-e/</a></figcaption></figure></div><p id="cf61" class="pw-post-body-paragraph ky kz it la b lb lc kd ld le lf kg lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">简而言之，他们将DALL-E描述为一个简单的只有解码器的变换器。如果你不熟悉变形金刚，你一定要看看我做的关于它们的视频。</p><figure class="kr ks kt ku gt kv"><div class="bz fp l di"><div class="kw kx l"/></div></figure><p id="727d" class="pw-post-body-paragraph ky kz it la b lb lc kd ld le lf kg lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">正如我提到的，它接收文本和图像作为令牌形式的输入，就像GPT-3一样，以产生转换后的图像。正如我在之前的视频中所描述的，它使用自我注意力来理解文本的上下文和对图像的稀疏注意力。关于它是如何工作的，或者它到底是如何被训练的，没有太多的细节，但是他们将会发表一篇论文来解释他们的方法。简而言之，这个DALL-E网络表明，通过语言操纵视觉概念现在已经触手可及，我很兴奋地阅读他们即将发表的论文！</p><p id="9856" class="pw-post-body-paragraph ky kz it la b lb lc kd ld le lf kg lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">当然，这只是这个名为DALL-E的新OpenAI网络的概述。我强烈邀请你关注OpenAI关于即将到来的论文的新闻，以便更好地了解技术，或者订阅我的频道。它一发布我就一定会报道。</p></div><div class="ab cl mt mu hx mv" role="separator"><span class="mw bw bk mx my mz"/><span class="mw bw bk mx my mz"/><span class="mw bw bk mx my"/></div><div class="im in io ip iq"><p id="5467" class="pw-post-body-paragraph ky kz it la b lb lc kd ld le lf kg lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">如果你喜欢我的工作，并想了解最新的人工智能技术，你绝对应该在我的社交媒体频道上关注我。</p><ul class=""><li id="8a1f" class="na nb it la b lb lc le lf lh nc ll nd lp ne lt nf ng nh ni bi translated">支持我的最好方式就是在<a class="ae mf" href="https://medium.com/@whats-ai" rel="noopener"> <strong class="la jd">中</strong> </a>关注我。</li><li id="9652" class="na nb it la b lb nj le nk lh nl ll nm lp nn lt nf ng nh ni bi translated">订阅我的<a class="ae mf" href="https://www.youtube.com/channel/UCUzGQrN-lyyc0BWTYoJM_Sg" rel="noopener ugc nofollow" target="_blank"> <strong class="la jd"> YouTube频道</strong> </a>。</li><li id="e390" class="na nb it la b lb nj le nk lh nl ll nm lp nn lt nf ng nh ni bi translated">在<a class="ae mf" href="https://www.linkedin.com/in/whats-ai/" rel="noopener ugc nofollow" target="_blank"> <strong class="la jd"> LinkedIn </strong> </a> <strong class="la jd">上关注我的项目。</strong></li><li id="564e" class="na nb it la b lb nj le nk lh nl ll nm lp nn lt nf ng nh ni bi translated">一起学习AI，加入我们的<a class="ae mf" href="https://discord.gg/learnaitogether" rel="noopener ugc nofollow" target="_blank"> <strong class="la jd"> Discord社区</strong> </a>，<em class="no">分享你的项目、论文、最佳课程，寻找Kaggle队友，等等！</em></li><li id="214a" class="na nb it la b lb nj le nk lh nl ll nm lp nn lt nf ng nh ni bi translated">订阅我的<a class="ae mf" href="http://eepurl.com/huGLT5" rel="noopener ugc nofollow" target="_blank"> <strong class="la jd">简讯</strong> </a>！</li></ul></div><div class="ab cl mt mu hx mv" role="separator"><span class="mw bw bk mx my mz"/><span class="mw bw bk mx my mz"/><span class="mw bw bk mx my"/></div><div class="im in io ip iq"><h2 id="e4f5" class="np nq it bd nr ns nt dn nu nv nw dp nx lh ny nz oa ll ob oc od lp oe of og iz bi translated"><strong class="ak">参考文献</strong></h2><p id="495b" class="pw-post-body-paragraph ky kz it la b lb oh kd ld le oi kg lg lh oj lj lk ll ok ln lo lp ol lr ls lt im bi translated"><strong class="la jd"> OpenAI的博客链接</strong>:<a class="ae mf" href="https://openai.com/blog/dall-e/" rel="noopener ugc nofollow" target="_blank">https://openai.com/blog/dall-e/</a>，OpenAI，2021–01–05。</p><figure class="kr ks kt ku gt kv gh gi paragraph-image"><div role="button" tabindex="0" class="lv lw di lx bf ly"><div class="gh gi om"><img src="../Images/7a0b5ed9535b20f14230fab0b469b69a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*DOzxpwG4_tUjA0a06G3XNA.png"/></div></div><figcaption class="mb mc gj gh gi md me bd b be z dk translated"><a class="ae mf" href="https://youtu.be/nLzfDVwQxRU" rel="noopener ugc nofollow" target="_blank">https://youtu.be/nLzfDVwQxRU</a></figcaption></figure></div></div>    
</body>
</html>