<html>
<head>
<title>GAN: Is Diffusion All You Need?</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">甘:扩散就够了吗？</h1>
<blockquote>原文：<a href="https://pub.towardsai.net/gan-is-diffusion-all-you-need-5ef127fa4ca?source=collection_archive---------1-----------------------#2022-06-21">https://pub.towardsai.net/gan-is-diffusion-all-you-need-5ef127fa4ca?source=collection_archive---------1-----------------------#2022-06-21</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><figure class="gl gn jo jp jq jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi jn"><img src="../Images/0ecf58d20c6e9f3ee4b81b8f3771970e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*RDPhd2dvmHE4UrAP-QHb9w.png"/></div></div><figcaption class="jy jz gj gh gi ka kb bd b be z dk translated">猫图片上一个扩散过程的图解(改编自<strong class="bd kc">【4】</strong>)。</figcaption></figure><p id="9854" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">八年前，出现了一种最有前途的生成建模方法:生成对抗网络(GAN)<strong class="kf ir">【1】</strong>。从那以后，在工艺和所获得的结果方面取得了相当大的进展。这些模型从生成模糊的人脸到具有不同约束的高清现实图片。</p><figure class="lc ld le lf gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi lb"><img src="../Images/e2d7898e046519af1476cb2f07b88021.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*o8uAzPP_d2wRH8Hx4_GEbw.png"/></div></div><figcaption class="jy jz gj gh gi ka kb bd b be z dk translated">从模型生成的样本(<a class="ae lg" href="https://github.com/amazon-research/gan-control" rel="noopener ugc nofollow" target="_blank"> amazon-research/gan-control:这个包提供了“gan-control:显式可控gan”的pythorch实现，ICCV 2021。(github.com)</a>)<strong class="bd kc">【2】</strong></figcaption></figure><p id="d006" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">如果这些改进令人印象深刻，这种模型仍然没有准备好广泛的公共利用。事实上，要使这些模型成功，它们应该满足<em class="lh">生成学习三难困境</em><strong class="kf ir">【4】</strong><em class="lh">:</em></p><ul class=""><li id="6481" class="li lj iq kf b kg kh kk kl ko lk ks ll kw lm la ln lo lp lq bi translated">它们需要快速生成高质量的采样，例如GAN应用于图像合成。</li><li id="bcb9" class="li lj iq kf b kg lr kk ls ko lt ks lu kw lv la ln lo lp lq bi translated">他们需要良好的模式覆盖和样本多样性，因为这可以减少此类模式的负面社会影响。</li><li id="6095" class="li lj iq kf b kg lr kk ls ko lt ks lu kw lv la ln lo lp lq bi translated">例如，对于实时图像编辑或实时合成的应用，他们需要快速且廉价的采样。</li></ul><p id="9f7c" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">我将首先概述GAN由什么组成，以及这些模型的优点和不便之处。在第二部分，我将解释深度生成模型的一个新趋势:扩散模型。最后，我将重点介绍最近的研究成果，这些成果提出了一种混合GAN与扩散模型的新方法。</p><h1 id="9e89" class="lw lx iq bd kc ly lz ma mb mc md me mf mg mh mi mj mk ml mm mn mo mp mq mr ms bi translated">什么是甘？</h1><p id="493d" class="pw-post-body-paragraph kd ke iq kf b kg mt ki kj kk mu km kn ko mv kq kr ks mw ku kv kw mx ky kz la ij bi translated">GAN的目标是从特定的数据集中生成新的看不见的数据。它通过尝试从样本中学习真实的、未知的底层数据分布的模型来做到这一点。换句话说，这些网络是试图学习特定统计分布的隐式模型<strong class="kf ir">【6】</strong>。</p><p id="e971" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">甘的创新之处在于他们学习实现这一目标的方式。事实上，他们通过双人游戏学习隐式模型来生成数据。其结构如下:</p><ul class=""><li id="8677" class="li lj iq kf b kg kh kk kl ko lk ks ll kw lm la ln lo lp lq bi translated"><strong class="kf ir">学习区分真实数据和生成数据的鉴别器</strong></li><li id="f18c" class="li lj iq kf b kg lr kk ls ko lt ks lu kw lv la ln lo lp lq bi translated"><strong class="kf ir">一个学习生成数据的生成器</strong>骗过了鉴别器。</li></ul><figure class="lc ld le lf gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi my"><img src="../Images/7a99a7de47cab7482aa101284d06c161.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*910xmucpacUngWJcvv0ilA.png"/></div></div><figcaption class="jy jz gj gh gi ka kb bd b be z dk translated">带有向鉴频器提供输入的发生器的GAN原理图。</figcaption></figure><p id="ee64" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">换句话说，生成器必须设计一个高分辨率的图像，以便能够欺骗鉴别器，因为鉴别器就像一个教师网络。与autoencoder模型的一个很大的区别是，这些生成器没有使用任何分布作为输出来训练。</p><p id="905d" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">模型的损失函数可以分解为两项:</p><ul class=""><li id="71d9" class="li lj iq kf b kg kh kk kl ko lk ks ll kw lm la ln lo lp lq bi translated">量化鉴别器是否正确预测真实数据是真实的部分</li><li id="0ebe" class="li lj iq kf b kg lr kk ls ko lt ks lu kw lv la ln lo lp lq bi translated">生成正确预测生成数据的部分</li></ul><p id="336a" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">然后在最佳可能的鉴别器上最小化该损失函数:</p><figure class="lc ld le lf gt jr gh gi paragraph-image"><div class="gh gi mz"><img src="../Images/23b246d29faa010ccf3a6360f00b650d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1238/format:webp/1*JxAmmsQd7RwGwRuROf0VAg.png"/></div></figure><p id="cd88" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">因此，生成模型可以被视为距离最小化模型，并且如果鉴别器是最优的，则可以被视为真实分布和生成分布之间的散度最小化。在实践中，可以使用多种差异，并对GANs进行不同的培训。</p><p id="f197" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">然而，虽然GANs的损失函数可以容易地控制，但是很难跟随学习动态，因为它包括发生器和鉴别器之间的权衡。此外，没有保证学习的一致性。因此，训练GAN模型具有挑战性，因为经常会遇到诸如消失梯度和模式崩溃(当生成的样本中没有多样性时)之类的问题。</p><h1 id="dc85" class="lw lx iq bd kc ly lz ma mb mc md me mf mg mh mi mj mk ml mm mn mo mp mq mr ms bi translated">扩散模型</h1><p id="0da8" class="pw-post-body-paragraph kd ke iq kf b kg mt ki kj kk mu km kn ko mv kq kr ks mw ku kv kw mx ky kz la ij bi translated">扩散模型的设计目标是解决GANs训练收敛的问题。这些模型背后的思想是，扩散过程等同于由于噪声的逐渐介入(在扩散过程的每个时间步添加高斯噪声)而导致的信息损失。</p><p id="56c4" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">这种模型的目标是了解噪声对样本中可用信息的影响，或者换句话说，扩散过程在多大程度上减少了可用信息。如果一个模型可以学习这一点，那么它应该能够逆转发生的信息丢失，并检索原始样本。去噪扩散模型正是这样做的。它由两步过程组成:正向和反向扩散过程。在正向扩散过程中，连续引入高斯噪声(即扩散过程)，直到数据都是噪声<strong class="kf ir">【7】</strong>。<strong class="kf ir"> </strong>反向扩散过程然后训练神经网络来学习条件分布概率以反转噪声。</p><figure class="lc ld le lf gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi na"><img src="../Images/9f4fd1dc3ef07255a0f195d4349efb17.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*sZvg9iTkBb6o0CIQHZbMWw.png"/></div></div><figcaption class="jy jz gj gh gi ka kb bd b be z dk translated">具有正向和反向扩散过程的扩散模型示意图</figcaption></figure><p id="ea3c" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">这些类型的网络已经成功地解决了生成过程，如下图所示(模型来自<strong class="kf ir">【3】</strong>):</p><figure class="lc ld le lf gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi nb"><img src="../Images/e96c561fc4afa56a0616cdbfefd7c162.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*LZyhxaXTVLpDrAHwz9JK8A.png"/></div></div><figcaption class="jy jz gj gh gi ka kb bd b be z dk translated">使用来自<a class="ae lg" href="https://github.com/CompVis/latent-diffusion" rel="noopener ugc nofollow" target="_blank">CompVis/潜在扩散:使用潜在扩散模型的高分辨率图像合成(github.com)</a>的扩散模型，通过提示“画布上的龙”生成样本</figcaption></figure><p id="d95d" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">然而，为了产生样本，反向扩散链必须经过许多次。这在计算上非常昂贵，使得这些模型生成样本的效率很低。尽管它们能够生成高质量的真实图像，但它们在现实世界中的应用却受到了限制。</p><h1 id="4dd8" class="lw lx iq bd kc ly lz ma mb mc md me mf mg mh mi mj mk ml mm mn mo mp mq mr ms bi translated">扩散氮化镓</h1><p id="77e7" class="pw-post-body-paragraph kd ke iq kf b kg mt ki kj kk mu km kn ko mv kq kr ks mw ku kv kw mx ky kz la ij bi translated">已经提出了各种方法来降低基于扩散的模型的生成成本。减少这种成本的最直观的方法之一是减少扩散模型<strong class="kf ir">【4】</strong>的逆过程的去噪步骤的数量。生成扩散模型通常假设去噪分布可以由高斯分布来建模。问题是这种假设仅适用于小的去噪步骤，这导致生成过程中大量的去噪步骤，因此不实用。</p><p id="d196" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">最近的方法以如下方式结合了深度生成模型(GAN)和扩散模型。它不是在过程结束时最小化真实数据和扩散数据之间的差异，而是在几个时间步长<strong class="kf ir"> t </strong>内最小化扩散真实数据分布和扩散生成器分布之间的差异。换句话说，在训练过程中，通过先通过正向扩散链，然后通过鉴别器(下图)反向传播梯度来更新生成器。此外，Diffusion-GAN注入了基于扩散的高斯混合分布<strong class="kf ir">【5】</strong>，而不是注入一个简单的实例噪声来破坏发送到鉴频器的数据，从而允许去噪过程一次近似几个步骤。这种特定的训练过程导致了这样一个事实，即生成器只需一步就可以将噪声映射到生成的样本，这意味着扩散GAN生成样本的速度几乎与经典GAN一样快。使用去噪扩散GAN从噪声中生成样本。</p><figure class="lc ld le lf gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi nc"><img src="../Images/23ae818c5e9dacf83eaf12da29e79d77.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*dlE85hIjePzkw5NjsNP5aw.png"/></div></div><figcaption class="jy jz gj gh gi ka kb bd b be z dk translated">扩散GAN工艺示意图(图片来自<strong class="bd kc">【5】</strong>)</figcaption></figure><p id="1642" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">该技术允许GAN“通过将降噪分布随时间表示为多峰分布来学习加速的反向降噪过程”<strong class="kf ir">【8】</strong>。为了适应加速生成过程，通过将该过程分解成几个条件去噪步骤，鉴别器不太可能过度拟合，因为扩散过程将平滑数据分布。这种类型的模型表现出更好的训练稳定性以及采样多样性。这种扩散模型的变体在快速深度生成学习方面似乎非常有前途，并且不仅可以在图片和视频处理中找到实际用途，还可以在诸如药物发现的另一个领域中找到实际用途。</p><h1 id="5c08" class="lw lx iq bd kc ly lz ma mb mc md me mf mg mh mi mj mk ml mm mn mo mp mq mr ms bi translated">参考</h1><p id="dcf4" class="pw-post-body-paragraph kd ke iq kf b kg mt ki kj kk mu km kn ko mv kq kr ks mw ku kv kw mx ky kz la ij bi translated">[1]古德费勒，伊恩，等。“生成性对抗性网络。”<em class="lh">神经信息处理系统进展</em> 27 (2014)。</p><p id="869a" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">[2] Shoshan，Alon等，“Gan控制:显式可控Gan”IEEE/CVF国际计算机视觉会议论文集<em class="lh">。2021.</em></p><p id="9fc0" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">[3] Rombach，Robin等，“用潜在扩散模型合成高分辨率图像”IEEE/CVF计算机视觉和模式识别会议文集。2022.</p><p id="bf52" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">[4]肖、智胜、卡斯滕·克瑞斯和阿拉什·瓦赫达特。"用去噪扩散甘斯解决生成学习的三难问题."<em class="lh"> arXiv预印本arXiv:2112.07804 </em> (2021)。</p><p id="4f85" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">[5]王，振东，等.“扩散——甘:用扩散训练甘”<em class="lh"> arXiv预印本arXiv:2206.02262 </em> (2022)。</p><p id="4491" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">[6]深度思维x UCL |深度学习讲座| 9/12 |生成式对抗网络<a class="ae lg" href="https://youtu.be/wFsI2WqUfdA" rel="noopener ugc nofollow" target="_blank">https://youtu.be/wFsI2WqUfdA</a></p><p id="68d3" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">[7] <a class="ae lg" href="https://towardsdatascience.com/diffusion-models-made-easy-8414298ce4da" rel="noopener" target="_blank">扩散模型制作简单。了解去噪基础知识… |作者J. Rafid Siddiqui博士| 2022年5月|迈向数据科学</a></p><p id="c839" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">[8] <a class="ae lg" href="https://developer.nvidia.com/blog/improving-diffusion-models-as-an-alternative-to-gans-part-2/" rel="noopener ugc nofollow" target="_blank">改进扩散模型作为GANs的替代方案，第2部分| NVIDIA技术博客</a></p></div></div>    
</body>
</html>