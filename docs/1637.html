<html>
<head>
<title>Tips and Tricks in Machine Learning with Python to Avoid Data Leakage</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">使用Python进行机器学习以避免数据泄漏的技巧和诀窍</h1>
<blockquote>原文：<a href="https://pub.towardsai.net/tips-and-tricks-in-machine-learning-with-python-to-avoid-data-leakage-c3908fa4a0c9?source=collection_archive---------5-----------------------#2021-03-08">https://pub.towardsai.net/tips-and-tricks-in-machine-learning-with-python-to-avoid-data-leakage-c3908fa4a0c9?source=collection_archive---------5-----------------------#2021-03-08</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><h2 id="b2d2" class="ir is it bd b dl iu iv iw ix iy iz dk ja translated" aria-label="kicker paragraph"><a class="ae ep" href="https://towardsai.net/p/category/machine-learning" rel="noopener ugc nofollow" target="_blank">机器学习</a></h2><div class=""/><div class=""><h2 id="2e90" class="pw-subtitle-paragraph jz jc it bd b ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq dk translated">更有效地编写机器学习算法</h2></div><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi kr"><img src="../Images/9506cfe9a46617ef04fcc89122689132.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*XG1eZQ6WVIyzs-I-"/></div></div><figcaption class="ld le gj gh gi lf lg bd b be z dk translated"><a class="ae lh" href="https://unsplash.com/@freegraphictoday?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">absolute vision</a>在<a class="ae lh" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>拍摄的照片</figcaption></figure><p id="0296" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">这篇文章将成为非常有趣的一篇，我们将谈论机器学习中使用的技巧和窍门，以避免数据泄漏。很多初学者学习机器学习算法只是通过拆分数据，将训练数据馈送给分类器。哦！等等，这对初学者来说看起来简单多了，但是在我们建模之前，要弄清楚更多的事情是很难的。</p><p id="5226" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">在机器学习中，<strong class="lk jd"> <em class="me">数据泄露</em> </strong>是训练过程中与目标特征相关的共享信息或数据，即与目标特征高度相关的独立特征导致泄露。</p><p id="f4f1" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">它会降低真实世界数据的准确性。为了改善机器学习中的泄漏问题，有如下一些提示:</p><ul class=""><li id="1386" class="mf mg it lk b ll lm lo lp lr mh lv mi lz mj md mk ml mm mn bi translated">在对数据进行训练测试分割之前，不要进行数据预处理。</li><li id="e4ac" class="mf mg it lk b ll mo lo mp lr mq lv mr lz ms md mk ml mm mn bi translated">切勿使用fit_transform来测试集合。</li><li id="b004" class="mf mg it lk b ll mo lo mp lr mq lv mr lz ms md mk ml mm mn bi translated">我们应该在训练集和测试集上都使用转换。训练集的fit_transform和测试集的transform。</li><li id="933f" class="mf mg it lk b ll mo lo mp lr mq lv mr lz ms md mk ml mm mn bi translated">我们应该使用sklearn的管道，它在参数调整和交叉验证方面使用得很好。</li></ul><div class="mt mu gp gr mv mw"><a rel="noopener  ugc nofollow" target="_blank" href="/fully-explained-dbscan-clustering-algorithm-with-python-a568139ebff5"><div class="mx ab fo"><div class="my ab mz cl cj na"><h2 class="bd jd gy z fp nb fr fs nc fu fw jc bi translated">用Python全面解释DBScan聚类算法</h2><div class="nd l"><h3 class="bd b gy z fp nb fr fs nc fu fw dk translated">基于密度聚类的机器学习中的无监督学习</h3></div><div class="ne l"><p class="bd b dl z fp nb fr fs nc fu fw dk translated">pub.towardsai.net</p></div></div><div class="nf l"><div class="ng l nh ni nj nf nk lb mw"/></div></div></a></div><p id="318c" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated"><strong class="lk jd">python的例子</strong></p><p id="b456" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">在训练-测试分割之后，我们应该使用标准缩放。</p><pre class="ks kt ku kv gt nl nm nn no aw np bi"><span id="3f33" class="nq nr it nm b gy ns nt l nu nv">X_train, X_test, y_train, y_test = train_test_split(<br/>                     X, y, test_size=0.4, random_state=random_state)</span></pre><p id="f75f" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">现在是使用标准缩放的时候了</p><pre class="ks kt ku kv gt nl nm nn no aw np bi"><span id="f2cb" class="nq nr it nm b gy ns nt l nu nv">scaler = StandardScaler()<br/>X_train_transformed = scaler.fit_transform(X_train)<br/>model = LinearRegression().fit(X_train_transformed, y_train)<br/>mean_squared_error(y_test, model.predict(X_test))</span></pre><p id="41ea" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">在上面的例子中，我们注意到测试数据没有被转换，这可能会影响准确性。</p><pre class="ks kt ku kv gt nl nm nn no aw np bi"><span id="7e67" class="nq nr it nm b gy ns nt l nu nv">X_test_transformed = scaler.transform(X_test)<br/>mean_squared_error(y_test, model.predict(X_test_transformed))</span></pre><p id="02d8" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">分割后的训练集和测试集的分类数据也是如此。</p><pre class="ks kt ku kv gt nl nm nn no aw np bi"><span id="f2e8" class="nq nr it nm b gy ns nt l nu nv">one_hot_en = OneHotEncoder(handle_unknown='ignore', sparse=False)<br/>one_hot_cols_train = pd.DataFrame(one_hot_en.fit_transform(X_train[cat_cols]))<br/>one_hot_cols_test = pd.DataFrame(one_hot_en.transform(X_test[cat_cols]))<br/><br/># One-hot encoding removed index; put it back<br/>one_hot_cols_train.index = X_train.index<br/>one_hot_cols_test.index = X_test.index</span></pre><p id="4b56" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">在机器学习中使用流水线方法，以减少在转换中跳过某些步骤的机会。</p><pre class="ks kt ku kv gt nl nm nn no aw np bi"><span id="8f35" class="nq nr it nm b gy ns nt l nu nv">from sklearn.pipeline import make_pipeline<br/><br/>model = make_pipeline(StandardScaler(), LinearRegression())</span><span id="ee1f" class="nq nr it nm b gy nw nt l nu nv">----------------------------------------------------------------<br/>model.fit(X_train, y_train)<br/>#output:<br/>Pipeline(steps=[('standardscaler', StandardScaler()),<br/>                ('linearregression', LinearRegression())])</span><span id="f46e" class="nq nr it nm b gy nw nt l nu nv">----------------------------------------------------------------<br/>mean_squared_error(y_test, model.predict(X_test))</span></pre><div class="mt mu gp gr mv mw"><a rel="noopener  ugc nofollow" target="_blank" href="/fully-explained-gradient-boosting-technique-in-supervised-learning-d3e293ca70e1"><div class="mx ab fo"><div class="my ab mz cl cj na"><h2 class="bd jd gy z fp nb fr fs nc fu fw jc bi translated">监督学习中的梯度推进技术</h2><div class="nd l"><h3 class="bd b gy z fp nb fr fs nc fu fw dk translated">机器学习中的回归和分类方法</h3></div><div class="ne l"><p class="bd b dl z fp nb fr fs nc fu fw dk translated">pub.towardsai.net</p></div></div><div class="nf l"><div class="nx l nh ni nj nf nk lb mw"/></div></div></a></div><p id="2255" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated"><strong class="lk jd">更多提示</strong></p><ul class=""><li id="78c4" class="mf mg it lk b ll lm lo lp lr mh lv mi lz mj md mk ml mm mn bi translated">当我们保存模型时，我们使用pickle，但是当对象是一个非常大的numpy数组时，在某些情况下使用joblib方法。</li><li id="20f3" class="mf mg it lk b ll mo lo mp lr mq lv mr lz ms md mk ml mm mn bi translated">当我们处理分类数据时，我们应该在不同的情况下使用MAE得分来检查哪个情况得分更低，以获得更有效的算法。</li><li id="7cf8" class="mf mg it lk b ll mo lo mp lr mq lv mr lz ms md mk ml mm mn bi translated">热点图还显示了高度相关的要素，这些要素可能会导致渗漏问题。</li></ul><h2 id="dbff" class="nq nr it bd ny nz oa dn ob oc od dp oe lr of og oh lv oi oj ok lz ol om on iz bi translated">支持向量机技巧</h2><ul class=""><li id="d80c" class="mf mg it lk b ll oo lo op lr oq lv or lz os md mk ml mm mn bi translated">为了避免复制大量密集的输入数据，建议使用<code class="fe ot ou ov nm b">SGDClassifier</code>。</li><li id="c462" class="mf mg it lk b ll mo lo mp lr mq lv mr lz ms md mk ml mm mn bi translated">增加内核缓存的大小是一个很好的做法。</li><li id="dac7" class="mf mg it lk b ll mo lo mp lr mq lv mr lz ms md mk ml mm mn bi translated">建议设置正则化参数。</li><li id="18c3" class="mf mg it lk b ll mo lo mp lr mq lv mr lz ms md mk ml mm mn bi translated">SVM的不变性建议在建模前缩放数据。</li><li id="f060" class="mf mg it lk b ll mo lo mp lr mq lv mr lz ms md mk ml mm mn bi translated">为了缩短训练时间，我们应该使用收缩参数。</li></ul><h2 id="2c15" class="nq nr it bd ny nz oa dn ob oc od dp oe lr of og oh lv oi oj ok lz ol om on iz bi translated">K-最近邻中的提示</h2><ul class=""><li id="a79a" class="mf mg it lk b ll oo lo op lr oq lv or lz os md mk ml mm mn bi translated">选择一个好的搜索技巧。</li><li id="271a" class="mf mg it lk b ll mo lo mp lr mq lv mr lz ms md mk ml mm mn bi translated">选择距离度量，以便更好、更快地进行搜索。</li></ul><h2 id="db17" class="nq nr it bd ny nz oa dn ob oc od dp oe lr of og oh lv oi oj ok lz ol om on iz bi translated">K均值中的提示</h2><ul class=""><li id="eb75" class="mf mg it lk b ll oo lo op lr oq lv or lz os md mk ml mm mn bi translated">数据点应该基于相似性。</li><li id="0c63" class="mf mg it lk b ll mo lo mp lr mq lv mr lz ms md mk ml mm mn bi translated">用肘法选择合适的k值。</li></ul><div class="mt mu gp gr mv mw"><a href="https://amitprius.medium.com/how-my-single-thought-made-me-a-writer-on-medium-430061ff0803" rel="noopener follow" target="_blank"><div class="mx ab fo"><div class="my ab mz cl cj na"><h2 class="bd jd gy z fp nb fr fs nc fu fw jc bi translated">我的单一想法如何让我成为一个媒体作家</h2><div class="nd l"><h3 class="bd b gy z fp nb fr fs nc fu fw dk translated">作为一个作家，我们应该一直努力的事情</h3></div><div class="ne l"><p class="bd b dl z fp nb fr fs nc fu fw dk translated">amitprius.medium.com</p></div></div><div class="nf l"><div class="ow l nh ni nj nf nk lb mw"/></div></div></a></div><p id="bca3" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">我希望你喜欢这篇文章。通过我的<a class="ae lh" href="https://www.linkedin.com/in/data-scientist-95040a1ab/" rel="noopener ugc nofollow" target="_blank"> LinkedIn </a>和<a class="ae lh" href="https://twitter.com/amitprius" rel="noopener ugc nofollow" target="_blank"> twitter </a>联系我。</p><h1 id="536d" class="ox nr it bd ny oy oz pa ob pb pc pd oe ki pe kj oh kl pf km ok ko pg kp on ph bi translated">推荐文章</h1><ol class=""><li id="fe0d" class="mf mg it lk b ll oo lo op lr oq lv or lz os md pi ml mm mn bi translated"><a class="ae lh" href="https://medium.com/towards-artificial-intelligence/nlp-zero-to-hero-with-python-2df6fcebff6e?sk=2231d868766e96b13d1e9d7db6064df1" rel="noopener">NLP——用Python零到英雄</a></li></ol><p id="da7d" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">2.<a class="ae lh" href="https://medium.com/towards-artificial-intelligence/python-data-structures-data-types-and-objects-244d0a86c3cf?sk=42f4b462499f3fc3a160b21e2c94dba6" rel="noopener"> Python数据结构数据类型和对象</a></p><p id="f532" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">3.<a class="ae lh" rel="noopener ugc nofollow" target="_blank" href="/data-preprocessing-concepts-with-python-b93c63f14bb6?source=friends_link&amp;sk=5cc4ac66c6c02a6f02077fd43df9681a">使用Python的数据预处理概念</a></p><p id="de78" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">4.<a class="ae lh" rel="noopener ugc nofollow" target="_blank" href="/principal-component-analysis-in-dimensionality-reduction-with-python-1a613006d531?source=friends_link&amp;sk=3ed0671fdc04ba395dd36478bcea8a55">用Python进行主成分分析降维</a></p><p id="48e6" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">5.<a class="ae lh" href="https://medium.com/towards-artificial-intelligence/fully-explained-k-means-clustering-with-python-e7caa573176a?source=friends_link&amp;sk=9c5c613ceb10f2d203712634f3b6fb28" rel="noopener">用Python全面解释K-means聚类</a></p><p id="b8a9" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">6.<a class="ae lh" href="https://medium.com/towards-artificial-intelligence/fully-explained-linear-regression-with-python-fe2b313f32f3?source=friends_link&amp;sk=53c91a2a51347ec2d93f8222c0e06402" rel="noopener">用Python全面解释线性回归</a></p><p id="0788" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">7.<a class="ae lh" href="https://medium.com/towards-artificial-intelligence/fully-explained-logistic-regression-with-python-f4a16413ddcd?source=friends_link&amp;sk=528181f15a44e48ea38fdd9579241a78" rel="noopener">用Python全面解释逻辑回归</a></p><p id="818b" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">8.<a class="ae lh" href="https://medium.com/towards-artificial-intelligence/basic-of-time-series-with-python-a2f7cb451a76?source=friends_link&amp;sk=09d77be2d6b8779973e41ab54ebcf6c5" rel="noopener">Python时间序列基础</a></p><p id="e54d" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">9.<a class="ae lh" rel="noopener ugc nofollow" target="_blank" href="/data-wrangling-with-python-part-1-969e3cc81d69?source=friends_link&amp;sk=9c3649cf20f31a5c9ead51c50c89ba0b">与Python的数据争论—第1部分</a></p><p id="e2ea" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">10.<a class="ae lh" href="https://medium.com/analytics-vidhya/confusion-matrix-in-machine-learning-91b6e2b3f9af?source=friends_link&amp;sk=11c6531da0bab7b504d518d02746d4cc" rel="noopener">机器学习中的混淆矩阵</a></p></div></div>    
</body>
</html>