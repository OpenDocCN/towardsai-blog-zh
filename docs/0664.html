<html>
<head>
<title>An Insider’s guide to Cartoonization using Machine Learning</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">使用机器学习的卡通化内部指南</h1>
<blockquote>原文：<a href="https://pub.towardsai.net/an-insiders-guide-to-cartoonization-using-machine-learning-ce3648adfe8?source=collection_archive---------0-----------------------#2020-07-10">https://pub.towardsai.net/an-insiders-guide-to-cartoonization-using-machine-learning-ce3648adfe8?source=collection_archive---------0-----------------------#2020-07-10</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><h2 id="0af7" class="io ip iq bd b dl ir is it iu iv iw dk ix translated" aria-label="kicker paragraph"><a class="ae ep" href="https://towardsai.net/p/category/machine-learning/deep-learning" rel="noopener ugc nofollow" target="_blank">深度学习</a>，<a class="ae ep" href="https://towardsai.net/p/category/computer-vision" rel="noopener ugc nofollow" target="_blank">计算机视觉</a></h2><div class=""/><div class=""><h2 id="63a2" class="pw-subtitle-paragraph jw iz iq bd b jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn dk translated">实施白盒模型以“卡通化”真正的高质量图像。</h2></div><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div role="button" tabindex="0" class="ku kv di kw bf kx"><div class="gh gi ko"><img src="../Images/9376b9dd4333e998ab7ffdd7bacc773d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*PZ08Cyh9ynrb4OL5.png"/></div></div></figure><p id="4cb2" class="pw-post-body-paragraph la lb iq lc b ld le ka lf lg lh kd li lj lk ll lm ln lo lp lq lr ls lt lu lv ij bi translated">卡通化本身是一种经典艺术，但是，机器学习领域的发展几乎覆盖了每个领域。今天，在这篇文章中，我们将了解一种叫做“<strong class="lc ja">白盒卡通化”</strong>的新方法，它将照片重建为动画风格，专注于表情提取元素，使计划完全可控和灵活。</p><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div class="gh gi lw"><img src="../Images/ddb0bd19fcdfb2380185623b0e96fa9d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1120/format:webp/0*k37S2hmAhExkEJl6.jpg"/></div><figcaption class="lx ly gj gh gi lz ma bd b be z dk translated">使用“白盒卡通化”获得的结果，<a class="ae mb" href="https://gigazine.net/gsc_news/en/20200630-white-box-cartoonization/" rel="noopener ugc nofollow" target="_blank">来源</a></figcaption></figure><h1 id="bb9a" class="mc md iq bd me mf mg mh mi mj mk ml mm kf mn kg mo ki mp kj mq kl mr km ms mt bi translated">模型介绍</h1><p id="7c99" class="pw-post-body-paragraph la lb iq lc b ld mu ka lf lg mv kd li lj mw ll lm ln mx lp lq lr my lt lu lv ij bi translated">我敢打赌，每个人都一定喜欢卡通，它们也一定是你童年不可或缺的一部分。除了这些令人回味的回忆，这可能是我们中一些人的职业选择。</p><p id="ec69" class="pw-post-body-paragraph la lb iq lc b ld le ka lf lg lh kd li lj lk ll lm ln lo lp lq lr ls lt lu lv ij bi translated">但是机器学习是不断发展的，因此几乎扩展到了每个领域。由和于金泽完成的研究工作让我们只需要一点点训练就能制作出真正高质量的图像。</p><p id="5191" class="pw-post-body-paragraph la lb iq lc b ld le ka lf lg lh kd li lj lk ll lm ln lo lp lq lr ls lt lu lv ij bi translated">将现实生活中的高质量画面转换成实用的卡通场景的过程被称为<strong class="lc ja">卡通化</strong>。</p><p id="4e4f" class="pw-post-body-paragraph la lb iq lc b ld le ka lf lg lh kd li lj lk ll lm ln lo lp lq lr ls lt lu lv ij bi translated">提出相同方法的早期模型使用<strong class="lc ja">黑盒模型</strong>，前一种模型实现了很高的准确性，但降低了风格化质量，导致一些不好的情况。就像，每个卡通工作流程考虑不同的功能，这些变化对黑盒模型构成了相关的影响。</p><p id="58c8" class="pw-post-body-paragraph la lb iq lc b ld le ka lf lg lh kd li lj lk ll lm ln lo lp lq lr ls lt lu lv ij bi translated">为了克服以前模型的缺点，更加强调人类的绘画行为和不同风格的卡通形象，并开发了<strong class="lc ja">白盒模型</strong>。</p><p id="ce29" class="pw-post-body-paragraph la lb iq lc b ld le ka lf lg lh kd li lj lk ll lm ln lo lp lq lr ls lt lu lv ij bi translated">该模型将图像分解为三种不同的卡通表现形式，进一步指导网络优化以生成卡通化的图像。</p><ol class=""><li id="9852" class="mz na iq lc b ld le lg lh lj nb ln nc lr nd lv ne nf ng nh bi translated"><strong class="lc ja">表面表示:</strong>它有助于提取包含加权低频分量的图像的平滑表面，其中保留了颜色成分和表面纹理以及边缘、纹理和细节。</li><li id="dd9e" class="mz na iq lc b ld ni lg nj lj nk ln nl lr nm lv ne nf ng nh bi translated"><strong class="lc ja">结构表示</strong>:它有助于导出全局结构信息和稀疏色块，一旦完成，我们将实施自适应着色算法，如Felzenswalb算法，以开发结构表示，帮助我们为赛璐珞风格的卡通流程生成稀疏视觉效果。</li><li id="2c49" class="mz na iq lc b ld ni lg nj lj nk ln nl lr nm lv ne nf ng nh bi translated"><strong class="lc ja">纹理表现</strong>:它帮助我们保留绘画的细节和边缘。三维图像被转换为单通道强度图，这有助于保持像素强度，同时兼顾颜色和亮度，它遵循手工艺术家的方法，即首先绘制具有轮廓的线条草图，然后对其应用颜色。</li></ol><p id="b956" class="pw-post-body-paragraph la lb iq lc b ld le ka lf lg lh kd li lj lk ll lm ln lo lp lq lr ls lt lu lv ij bi translated">提取的输出被馈送到生成神经网络(GAN)框架，这有助于优化我们的问题，使解决方案更加灵活和多样化。</p><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div class="gh gi nn"><img src="../Images/c45b25711006f30bec89356f98c32c0d.png" data-original-src="https://miro.medium.com/v2/resize:fit:930/format:webp/0*MxmEmnORvL0yJo56.png"/></div><figcaption class="lx ly gj gh gi lz ma bd b be z dk translated"><a class="ae mb" href="https://openaccess.thecvf.com/content_CVPR_2020/papers/Wang_Learning_to_Cartoonize_Using_White-Box_Cartoon_Representations_CVPR_2020_paper.pdf" rel="noopener ugc nofollow" target="_blank">来源</a></figcaption></figure></div><div class="ab cl no np hu nq" role="separator"><span class="nr bw bk ns nt nu"/><span class="nr bw bk ns nt nu"/><span class="nr bw bk ns nt"/></div><div class="ij ik il im in"><h1 id="1eb8" class="mc md iq bd me mf nv mh mi mj nw ml mm kf nx kg mo ki ny kj mq kl nz km ms mt bi translated">提议的方法</h1><h2 id="8b3b" class="oa md iq bd me ob oc dn mi od oe dp mm lj of og mo ln oh oi mq lr oj ok ms iw bi translated">预处理</h2><p id="ba7d" class="pw-post-body-paragraph la lb iq lc b ld mu ka lf lg mv kd li lj mw ll lm ln mx lp lq lr my lt lu lv ij bi translated">除了提出的三步方法，预处理也是我们模型的一个重要部分。它有助于平滑图像，过滤特征，将其转换为草图，并将输出从一个领域转换到另一个领域。在实现了这些相关的工作之后，我们可以确信由我们的模型生成的输出将会给我们保留最高质量特征的最佳输出。</p><ul class=""><li id="b860" class="mz na iq lc b ld le lg lh lj nb ln nc lr nd lv ol nf ng nh bi translated"><strong class="lc ja">超像素和结构提取:</strong>该方法用于将图像划分成区域，并定义一个谓词来度量两个区域之间的边界。基于谓词分割，开发了一种算法，其决策基于贪婪技术，但仍有助于满足全局性质。在识别轮廓后，我们执行<strong class="lc ja"><em class="om"/></strong><em class="om"/>梯度上升，用粗略的聚类初始化图像，并迭代修改聚类直到收敛。为了推进我们的流程，我们使用<strong class="lc ja"><em class="om">Felzenszwalb算法</em> </strong>开发了一种类似卡通的分割方法，帮助我们获取全球内容信息，并为赛璐珞风格的卡通工作流程生成实际可用的结果。</li></ul><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div class="gh gi on"><img src="../Images/ddbdbfa8a4fb2720e8f85022a3e210cf.png" data-original-src="https://miro.medium.com/v2/resize:fit:1308/format:webp/0*YzSAjOZwmqZ8-T5l.png"/></div><figcaption class="lx ly gj gh gi lz ma bd b be z dk translated">前vs后，<a class="ae mb" href="http://people.cs.uchicago.edu/~pff/papers/seg-ijcv.pdf" rel="noopener ugc nofollow" target="_blank">来源</a></figcaption></figure><ul class=""><li id="3836" class="mz na iq lc b ld le lg lh lj nb ln nc lr nd lv ol nf ng nh bi translated"><strong class="lc ja">图像平滑</strong>:为了从图像中提取平滑且卡通似的表面，使用<strong class="lc ja"> <em class="om">导向滤波器</em> </strong>。导向过滤器是<strong class="lc ja"> <em class="om">双边过滤器</em> </strong>的高级版本，具有更好的边缘行为。目标仅仅是<em class="om">去除/显著降低</em>噪声并获得有用的图像结构。导向滤波器的滤波输出是输入图像的最佳线性变换。遵循双边滤波器的方法，它保留了平滑特性，此外，没有梯度反转伪影。</li></ul><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div class="gh gi oo"><img src="../Images/ca20f9cc60d35deefad30ae8ae3365e3.png" data-original-src="https://miro.medium.com/v2/resize:fit:1340/format:webp/0*Zi3kWxMYo5K0fTSd.png"/></div><figcaption class="lx ly gj gh gi lz ma bd b be z dk translated">原件vs导向过滤器vs双边过滤器，<a class="ae mb" href="http://kaiminghe.com/publications/eccv10guidedfilter.pdf" rel="noopener ugc nofollow" target="_blank">来源</a></figcaption></figure><ul class=""><li id="f277" class="mz na iq lc b ld le lg lh lj nb ln nc lr nd lv ol nf ng nh bi translated"><strong class="lc ja">非真实感渲染:</strong>它有助于将图像转换成艺术风格，如素描、绘画和水彩画。为了扩展其功能，我们将它与<strong class="lc ja"> <em class="om">神经风格转移方法</em> </strong>一起使用，这有助于总结一幅图像和另一幅图像的风格。组合的代码有助于标记语义边缘，同时分离图像细节。但是在“白盒卡通化”方法中，使用了单个图像，并从一组动画视觉效果中学习漫画家的特征，从而允许我们的模型在各种情况下产生高质量的输出。</li></ul><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div class="gh gi op"><img src="../Images/65492b02a51e81ba34c771279edc08eb.png" data-original-src="https://miro.medium.com/v2/resize:fit:440/format:webp/0*J1953G0frp9ij0xq.jpg"/></div><figcaption class="lx ly gj gh gi lz ma bd b be z dk translated">产量由NPR生产，<a class="ae mb" href="https://en.wikipedia.org/wiki/Non-photorealistic_rendering" rel="noopener ugc nofollow" target="_blank">来源</a></figcaption></figure><ul class=""><li id="b833" class="mz na iq lc b ld le lg lh lj nb ln nc lr nd lv ol nf ng nh bi translated"><strong class="lc ja">生成对抗网络:</strong>它是一个图像合成器，使用联合概率帮助生成新数据。为了生成新的图像，它使用生成器和鉴别器。生成器生成图像，鉴别器检查图像的真假，然后向生成器发送反馈，要求其生成更好的数据。两个网络训练得越多，我们得到的图像就越好。</li></ul><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div role="button" tabindex="0" class="ku kv di kw bf kx"><div class="gh gi oq"><img src="../Images/931613886446df44089e4059daa1daf4.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*dVMwa4cNqUmfrgLU.png"/></div></div><figcaption class="lx ly gj gh gi lz ma bd b be z dk translated">甘模型架构，<a class="ae mb" href="https://developers.google.com/machine-learning/gan/gan_structure" rel="noopener ugc nofollow" target="_blank">来源</a></figcaption></figure><ul class=""><li id="70b1" class="mz na iq lc b ld le lg lh lj nb ln nc lr nd lv ol nf ng nh bi translated"><strong class="lc ja">图像到图像的转换</strong>:GAN的缺点是，它只对给定的训练数据有效，但是成对的训练数据并不总是可用的。为了克服这个缺点，我们采用了cycleGAN，其目标是即使在没有成对训练数据的情况下，也将图像从源域X转换到目标域Y。</li></ul><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div class="gh gi or"><img src="../Images/749dd0734bc4a0a2b3473720664bae74.png" data-original-src="https://miro.medium.com/v2/resize:fit:1204/format:webp/0*Z63n5EfUPlwKcUZL.png"/></div><figcaption class="lx ly gj gh gi lz ma bd b be z dk translated">成对与不成对数据，<a class="ae mb" href="https://arxiv.org/pdf/1703.10593v6.pdf" rel="noopener ugc nofollow" target="_blank">来源</a></figcaption></figure><p id="415f" class="pw-post-body-paragraph la lb iq lc b ld le ka lf lg lh kd li lj lk ll lm ln lo lp lq lr ls lt lu lv ij bi translated">为了继续该过程，我们分离图像特征，这加强了网络学习具有单独目标的不同特征，使得该过程更加健壮。</p><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div role="button" tabindex="0" class="ku kv di kw bf kx"><div class="gh gi os"><img src="../Images/c207d0d9f14e2c1dbbd53c675c6d083d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*3wM8OLKOU1n5zJ7t.png"/></div></div><figcaption class="lx ly gj gh gi lz ma bd b be z dk translated">cycleGAN aka图像到图像转换的输出，<a class="ae mb" href="https://arxiv.org/pdf/1703.10593v6.pdf" rel="noopener ugc nofollow" target="_blank">来源</a></figcaption></figure><h1 id="7630" class="mc md iq bd me mf mg mh mi mj mk ml mm kf mn kg mo ki mp kj mq kl mr km ms mt bi translated">了解整个模型</h1><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div role="button" tabindex="0" class="ku kv di kw bf kx"><div class="gh gi ot"><img src="../Images/bbbe4f7612b1cd11e3874e7ad58ac809.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*8jW74HU2o0v9uJxc.png"/></div></div><figcaption class="lx ly gj gh gi lz ma bd b be z dk translated">模型布局，<a class="ae mb" href="https://openaccess.thecvf.com/content_CVPR_2020/papers/Wang_Learning_to_Cartoonize_Using_White-Box_Cartoon_Representations_CVPR_2020_paper.pdf" rel="noopener ugc nofollow" target="_blank">来源</a></figcaption></figure><p id="df51" class="pw-post-body-paragraph la lb iq lc b ld le ka lf lg lh kd li lj lk ll lm ln lo lp lq lr ls lt lu lv ij bi translated">输入图像被分解成三个部分:wiz <em class="om">表面表示、结构表示</em>和<em class="om">纹理表示。</em>介绍了一个带有生成器G和两个鉴别器Ds和Dt的GAN模型。Ds的目标是表征从模型输出和动画中提取的表面特征，而Dt负责从模型输出和动画中分离纹理信息。为了提取高级特征并对输出和提供的成对卡通之间的全局内容施加空间约束，我们使用预训练的<em class="om"> VGGNetwork </em>。</p><h1 id="ea77" class="mc md iq bd me mf mg mh mi mj mk ml mm kf mn kg mo ki mp kj mq kl mr km ms mt bi translated">工作流程</h1><ul class=""><li id="5e6f" class="mz na iq lc b ld mu lg mv lj ou ln ov lr ow lv ol nf ng nh bi translated">输入首先通过表面表示，其中结构和纹理特征被移除，一旦我们模仿卡通绘画风格和平滑的表面，输出就通过导向过滤器，以便保留平滑的边缘。提出了鉴别器<em class="om"> Ds </em>来验证结果和配对的卡通图像是否具有相似的表面，并调节生成器<em class="om"> G </em>来学习存储在提取的表面表示中的信息。</li><li id="1a37" class="mz na iq lc b ld ni lg nj lj nk ln nl lr nm lv ol nf ng nh bi translated">结构特征然后通过结构表示传递，该结构表示在细胞风格框架中清除边界，然后我们实现Felzenszwalb算法来分割区域。该算法帮助我们用平均像素值给每个片段着色。为了对输出和提供的成对卡通之间的全局内容施加空间约束，我们使用预训练的<em class="om"> VGGNetwork </em>。</li><li id="41fd" class="mz na iq lc b ld ni lg nj lj nk ln nl lr nm lv ol nf ng nh bi translated">如前所述，亮度和颜色信息的变化对模型来说是重要的问题，因此，我们选择随机颜色偏移算法来将三通道输入转换为坚持高质量特征的一维输出。然后提出鉴别器Dt来验证来自结果和配对卡通图像的文本特征，并调节发生器G来学习存储在提取的纹理表示中的信息。</li></ul><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div role="button" tabindex="0" class="ku kv di kw bf kx"><div class="gh gi ox"><img src="../Images/f7a0a29c5e6fd0db3d970ce479f1cc19.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*GJ5RRsAfvvsXg9Zr.png"/></div></div><figcaption class="lx ly gj gh gi lz ma bd b be z dk translated">我们模型的工作流程。</figcaption></figure><h1 id="c881" class="mc md iq bd me mf mg mh mi mj mk ml mm kf mn kg mo ki mp kj mq kl mr km ms mt bi translated">模型架构</h1><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div role="button" tabindex="0" class="ku kv di kw bf kx"><div class="gh gi oy"><img src="../Images/72eafa06159cd52536e8ed67e4a326b6.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*yWo4pnPWbMv_vtr7.png"/></div></div><figcaption class="lx ly gj gh gi lz ma bd b be z dk translated">模型架构，<a class="ae mb" href="https://openaccess.thecvf.com/content_CVPR_2020/papers/Wang_Learning_to_Cartoonize_Using_White-Box_Cartoon_Representations_CVPR_2020_paper.pdf" rel="noopener ugc nofollow" target="_blank">来源</a></figcaption></figure><p id="11a1" class="pw-post-body-paragraph la lb iq lc b ld le ka lf lg lh kd li lj lk ll lm ln lo lp lq lr ls lt lu lv ij bi translated">因为我们的模型是基于GAN的，所以在我们的模型中我们同时操作发生器和鉴别器。生成器是一个全卷积网络，跨距=2。网络进一步由三种层组成:卷积、泄漏ReLU和双线性调整层。</p><p id="c528" class="pw-post-body-paragraph la lb iq lc b ld le ka lf lg lh kd li lj lk ll lm ln lo lp lq lr ls lt lu lv ij bi translated">在鉴别器网络中，我们使用PatchGAN，其中最后一层是卷积层。输出特征图中的每个像素对应于输入图像中的一个斑块。每个面片大小用于验证该面片是属于卡通图像还是生成的输出。贴片GAN增强了甄别器的操作性，加快了训练。</p></div><div class="ab cl no np hu nq" role="separator"><span class="nr bw bk ns nt nu"/><span class="nr bw bk ns nt nu"/><span class="nr bw bk ns nt"/></div><div class="ij ik il im in"><h1 id="e9dd" class="mc md iq bd me mf nv mh mi mj nw ml mm kf nx kg mo ki ny kj mq kl nz km ms mt bi translated">输出</h1><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div role="button" tabindex="0" class="ku kv di kw bf kx"><div class="gh gi oz"><img src="../Images/88bd4824a0ae64ca147a72d48711ad7d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*f9cysgLCKXQYk9EZ.png"/></div></div><figcaption class="lx ly gj gh gi lz ma bd b be z dk translated">输出wiz不同的表示，<a class="ae mb" href="https://openaccess.thecvf.com/content_CVPR_2020/papers/Wang_Learning_to_Cartoonize_Using_White-Box_Cartoon_Representations_CVPR_2020_paper.pdf" rel="noopener ugc nofollow" target="_blank">源</a></figcaption></figure><div class="kp kq kr ks gt ab cb"><figure class="pa kt pb pc pd pe pf paragraph-image"><div role="button" tabindex="0" class="ku kv di kw bf kx"><img src="../Images/6173f4a25fa3dfcf467dc4078b983d30.png" data-original-src="https://miro.medium.com/v2/resize:fit:732/format:webp/1*XuYXqpkrkXASAqf8rfemHg.jpeg"/></div></figure><figure class="pa kt pg pc pd pe pf paragraph-image"><div role="button" tabindex="0" class="ku kv di kw bf kx"><img src="../Images/45c4be5c6e8d5a82dcb5f00c1ea14c7f.png" data-original-src="https://miro.medium.com/v2/resize:fit:728/format:webp/1*gqabwqDioI1DyCFJS8EsDw.jpeg"/></div></figure><figure class="pa kt ph pc pd pe pf paragraph-image"><div role="button" tabindex="0" class="ku kv di kw bf kx"><img src="../Images/0fcf9947c56c0119e84013c3dd329527.png" data-original-src="https://miro.medium.com/v2/resize:fit:542/format:webp/1*J32mOqeAd9T6O7ufGjyILg.jpeg"/></div><figcaption class="lx ly gj gh gi lz ma bd b be z dk pi di pj pk translated">由模型、源产生的输出</figcaption></figure></div><p id="4741" class="pw-post-body-paragraph la lb iq lc b ld le ka lf lg lh kd li lj lk ll lm ln lo lp lq lr ls lt lu lv ij bi translated"><strong class="lc ja">如果你喜欢这篇文章，请考虑订阅我的简讯:</strong> <a class="ae mb" href="https://mailchi.mp/b535943b5fff/daksh-trehan-weekly-newsletter" rel="noopener ugc nofollow" target="_blank"> <strong class="lc ja">达克什·特雷汉每周简讯</strong> </a> <strong class="lc ja">。</strong></p><h1 id="73da" class="mc md iq bd me mf mg mh mi mj mk ml mm kf mn kg mo ki mp kj mq kl mr km ms mt bi translated">密码</h1><p id="6d81" class="pw-post-body-paragraph la lb iq lc b ld mu ka lf lg mv kd li lj mw ll lm ln mx lp lq lr my lt lu lv ij bi translated">型号代码可在以下位置找到:</p><div class="pl pm gp gr pn po"><a href="https://github.com/dakshtrehan/White-box-Cartoonization" rel="noopener  ugc nofollow" target="_blank"><div class="pp ab fo"><div class="pq ab pr cl cj ps"><h2 class="bd ja gy z fp pt fr fs pu fu fw iz bi translated">dakshtrehan/白盒卡通化</h2><div class="pv l"><h3 class="bd b gy z fp pt fr fs pu fu fw dk translated">加入我在www.dakshtrehan.com；www.linkedin.com/in/dakshtrehan将测试图像存储在/test_code/test_images Run…</h3></div><div class="pw l"><p class="bd b dl z fp pt fr fs pu fu fw dk translated">github.com</p></div></div><div class="px l"><div class="py l pz qa qb px qc ky po"/></div></div></a></div><p id="79d5" class="pw-post-body-paragraph la lb iq lc b ld le ka lf lg lh kd li lj lk ll lm ln lo lp lq lr ls lt lu lv ij bi translated">和</p><div class="pl pm gp gr pn po"><a href="https://github.com/SystemErrorWang/White-box-Cartoonization" rel="noopener  ugc nofollow" target="_blank"><div class="pp ab fo"><div class="pq ab pr cl cj ps"><h2 class="bd ja gy z fp pt fr fs pu fu fw iz bi translated">系统错误王/白盒-卡通化</h2><div class="pv l"><h3 class="bd b gy z fp pt fr fs pu fu fw dk translated">CVPR2020论文“使用白盒卡通表示学习卡通化”的Tensorflow实现。</h3></div><div class="pw l"><p class="bd b dl z fp pt fr fs pu fu fw dk translated">github.com</p></div></div><div class="px l"><div class="qd l pz qa qb px qc ky po"/></div></div></a></div></div><div class="ab cl no np hu nq" role="separator"><span class="nr bw bk ns nt nu"/><span class="nr bw bk ns nt nu"/><span class="nr bw bk ns nt"/></div><div class="ij ik il im in"><h1 id="f0bc" class="mc md iq bd me mf nv mh mi mj nw ml mm kf nx kg mo ki ny kj mq kl nz km ms mt bi translated">结论</h1><p id="9984" class="pw-post-body-paragraph la lb iq lc b ld mu ka lf lg mv kd li lj mw ll lm ln mx lp lq lr my lt lu lv ij bi translated">希望这篇文章能帮助你以最好的方式理解使用机器学习的图像卡通化，并帮助你实际应用。</p><p id="61b0" class="pw-post-body-paragraph la lb iq lc b ld le ka lf lg lh kd li lj lk ll lm ln lo lp lq lr ls lt lu lv ij bi translated">一如既往，非常感谢您的阅读，如果您觉得这篇文章有用，请分享！</p></div><div class="ab cl no np hu nq" role="separator"><span class="nr bw bk ns nt nu"/><span class="nr bw bk ns nt nu"/><span class="nr bw bk ns nt"/></div><div class="ij ik il im in"><h1 id="de63" class="mc md iq bd me mf nv mh mi mj nw ml mm kf nx kg mo ki ny kj mq kl nz km ms mt bi translated">参考</h1><p id="794a" class="pw-post-body-paragraph la lb iq lc b ld mu ka lf lg mv kd li lj mw ll lm ln mx lp lq lr my lt lu lv ij bi translated">[1]王，辛锐，于，金泽。学习使用白盒卡通表现卡通化。<em class="om"> IEEE/CVF计算机视觉和模式识别会议(CVPR) </em>。2020年6月。</p><p id="cf81" class="pw-post-body-paragraph la lb iq lc b ld le ka lf lg lh kd li lj lk ll lm ln lo lp lq lr ls lt lu lv ij bi translated">[2]佩德罗·费尔曾兹瓦尔布和丹尼尔·胡滕洛赫。有效的基于图的图像分割。国际计算机视觉杂志，59(2):167–181，2004年。</p><p id="42df" class="pw-post-body-paragraph la lb iq lc b ld le ka lf lg lh kd li lj lk ll lm ln lo lp lq lr ls lt lu lv ij bi translated">[3]吴，，，，黄.快速端到端可训练制导滤波器。在<em class="om">IEEE计算机视觉和模式识别会议论文集</em>中，第1838–1847页，2018。</p><p id="23a5" class="pw-post-body-paragraph la lb iq lc b ld le ka lf lg lh kd li lj lk ll lm ln lo lp lq lr ls lt lu lv ij bi translated">[4]伊恩·古德菲勒、让·普吉-阿巴迪、迈赫迪·米尔扎、徐炳、戴维·沃德-法利、谢尔吉尔·奥泽尔、亚伦·库维尔和约舒阿·本吉奥。生成对抗网络。在<em class="om">神经信息处理系统进展</em>中，第2672–2680页，2014年。</p><p id="7301" class="pw-post-body-paragraph la lb iq lc b ld le ka lf lg lh kd li lj lk ll lm ln lo lp lq lr ls lt lu lv ij bi translated">[5]，何，，唐晓鸥。<em class="om">引导图像过滤</em>。香港中文大学信息工程系，微软亚洲研究院，中国科学院深圳先进技术研究院</p><p id="8882" class="pw-post-body-paragraph la lb iq lc b ld le ka lf lg lh kd li lj lk ll lm ln lo lp lq lr ls lt lu lv ij bi translated">[6] <a class="ae mb" href="https://en.wikipedia.org/wiki/Non-photorealistic_rendering" rel="noopener ugc nofollow" target="_blank">非真实感渲染</a></p><p id="41e1" class="pw-post-body-paragraph la lb iq lc b ld le ka lf lg lh kd li lj lk ll lm ln lo lp lq lr ls lt lu lv ij bi translated">[7] <a class="ae mb" href="https://towardsdatascience.com/cyclegan-how-machine-learning-learns-unpaired-image-to-image-translation-3fa8d9a6aa1d" rel="noopener" target="_blank"> CycleGAN:机器学习如何学习不成对的图像到图像的翻译</a></p><p id="d087" class="pw-post-body-paragraph la lb iq lc b ld le ka lf lg lh kd li lj lk ll lm ln lo lp lq lr ls lt lu lv ij bi translated">[8] <a class="ae mb" href="https://en.wikipedia.org/wiki/Minimum_spanning_tree-based_segmentation" rel="noopener ugc nofollow" target="_blank">基于最小生成树的分割</a></p><p id="8acf" class="pw-post-body-paragraph la lb iq lc b ld le ka lf lg lh kd li lj lk ll lm ln lo lp lq lr ls lt lu lv ij bi translated">[9] <a class="ae mb" href="https://developers.google.com/machine-learning/gan/gan_structure" rel="noopener ugc nofollow" target="_blank">氮化镓结构概述</a></p><p id="674b" class="pw-post-body-paragraph la lb iq lc b ld le ka lf lg lh kd li lj lk ll lm ln lo lp lq lr ls lt lu lv ij bi translated">[10]陆，，贾亚嘉.素描与色调相结合的铅笔画制作。在<em class="om">非真实感动画和渲染研讨会会议录</em>中，第65–73页。欧洲制图协会，2012年。</p></div><div class="ab cl no np hu nq" role="separator"><span class="nr bw bk ns nt nu"/><span class="nr bw bk ns nt nu"/><span class="nr bw bk ns nt"/></div><div class="ij ik il im in"><p id="94be" class="pw-post-body-paragraph la lb iq lc b ld le ka lf lg lh kd li lj lk ll lm ln lo lp lq lr ls lt lu lv ij bi translated">请随意连接:</p><blockquote class="qe qf qg"><p id="9e04" class="la lb om lc b ld le ka lf lg lh kd li qh lk ll lm qi lo lp lq qj ls lt lu lv ij bi translated"><em class="iq">LinkedIn ~</em><a class="ae mb" href="https://www.linkedin.com/in/dakshtrehan/" rel="noopener ugc nofollow" target="_blank"><em class="iq">https://www.linkedin.com/in/dakshtrehan/</em></a></p><p id="28ac" class="la lb om lc b ld le ka lf lg lh kd li qh lk ll lm qi lo lp lq qj ls lt lu lv ij bi translated"><em class="iq">insta gram ~</em><a class="ae mb" href="https://www.instagram.com/_daksh_trehan_/" rel="noopener ugc nofollow" target="_blank"><em class="iq">https://www.instagram.com/_daksh_trehan_/</em></a></p><p id="edd3" class="la lb om lc b ld le ka lf lg lh kd li qh lk ll lm qi lo lp lq qj ls lt lu lv ij bi translated"><em class="iq">Github ~</em><a class="ae mb" href="https://github.com/dakshtrehan" rel="noopener ugc nofollow" target="_blank"><em class="iq">https://github.com/dakshtrehan</em></a></p></blockquote><p id="a518" class="pw-post-body-paragraph la lb iq lc b ld le ka lf lg lh kd li lj lk ll lm ln lo lp lq lr ls lt lu lv ij bi translated">关注更多机器学习/深度学习博客。</p><blockquote class="qe qf qg"><p id="8e68" class="la lb om lc b ld le ka lf lg lh kd li qh lk ll lm qi lo lp lq qj ls lt lu lv ij bi translated"><em class="iq">中等~</em><a class="ae mb" href="https://medium.com/@dakshtrehan" rel="noopener"><em class="iq">https://medium.com/@dakshtrehan</em></a></p></blockquote><h1 id="e715" class="mc md iq bd me mf mg mh mi mj mk ml mm kf mn kg mo ki mp kj mq kl mr km ms mt bi translated">想了解更多？</h1><p id="5fff" class="pw-post-body-paragraph la lb iq lc b ld mu ka lf lg mv kd li lj mw ll lm ln mx lp lq lr my lt lu lv ij bi translated"><a class="ae mb" href="https://towardsdatascience.com/detecting-covid-19-using-deep-learning-262956b6f981" rel="noopener" target="_blank">利用深度学习检测新冠肺炎</a></p><p id="108b" class="pw-post-body-paragraph la lb iq lc b ld le ka lf lg lh kd li lj lk ll lm ln lo lp lq lr ls lt lu lv ij bi translated"><a class="ae mb" href="https://towardsdatascience.com/the-inescapable-ai-algorithm-tiktok-ad4c6fd981b8" rel="noopener" target="_blank">无法逃脱的人工智能算法:抖音</a></p><p id="e1ad" class="pw-post-body-paragraph la lb iq lc b ld le ka lf lg lh kd li lj lk ll lm ln lo lp lq lr ls lt lu lv ij bi translated">为什么你要为乔治·弗洛伊德的谋杀和德里的骚乱负责？</p><p id="3f7d" class="pw-post-body-paragraph la lb iq lc b ld le ka lf lg lh kd li lj lk ll lm ln lo lp lq lr ls lt lu lv ij bi translated"><a class="ae mb" href="https://medium.com/towards-artificial-intelligence/why-choose-random-forest-and-not-decision-trees-a28278daa5d" rel="noopener">为什么选择随机森林而不是决策树</a></p><p id="b876" class="pw-post-body-paragraph la lb iq lc b ld le ka lf lg lh kd li lj lk ll lm ln lo lp lq lr ls lt lu lv ij bi translated"><a class="ae mb" href="https://medium.com/@dakshtrehan/clustering-what-it-is-when-to-use-it-a612bbe95881" rel="noopener">聚类:是什么？什么时候用？</a></p><p id="80f1" class="pw-post-body-paragraph la lb iq lc b ld le ka lf lg lh kd li lj lk ll lm ln lo lp lq lr ls lt lu lv ij bi translated"><a class="ae mb" href="https://medium.com/@dakshtrehan/start-off-your-ml-journey-with-k-nearest-neighbors-f72a122f428" rel="noopener">从k近邻开始你的ML之旅</a></p><p id="07fa" class="pw-post-body-paragraph la lb iq lc b ld le ka lf lg lh kd li lj lk ll lm ln lo lp lq lr ls lt lu lv ij bi translated"><a class="ae mb" href="https://medium.com/swlh/things-you-never-knew-about-naive-bayes-eb84b6ee039a" rel="noopener">朴素贝叶斯解释了</a></p><p id="dd68" class="pw-post-body-paragraph la lb iq lc b ld le ka lf lg lh kd li lj lk ll lm ln lo lp lq lr ls lt lu lv ij bi translated"><a class="ae mb" href="https://medium.com/analytics-vidhya/activation-functions-explained-8690ea7bdec9" rel="noopener">激活功能说明</a></p><p id="0831" class="pw-post-body-paragraph la lb iq lc b ld le ka lf lg lh kd li lj lk ll lm ln lo lp lq lr ls lt lu lv ij bi translated"><a class="ae mb" href="https://towardsdatascience.com/parameters-optimization-explained-876561853de0" rel="noopener" target="_blank">参数优化解释</a></p><p id="7e8e" class="pw-post-body-paragraph la lb iq lc b ld le ka lf lg lh kd li lj lk ll lm ln lo lp lq lr ls lt lu lv ij bi translated"><a class="ae mb" href="https://towardsdatascience.com/gradient-descent-explained-9b953fc0d2c" rel="noopener" target="_blank">梯度下降解释</a></p><p id="eb9c" class="pw-post-body-paragraph la lb iq lc b ld le ka lf lg lh kd li lj lk ll lm ln lo lp lq lr ls lt lu lv ij bi translated"><a class="ae mb" href="https://towardsdatascience.com/logistic-regression-explained-ef1d816ea85a" rel="noopener" target="_blank">逻辑回归解释</a></p><p id="5f41" class="pw-post-body-paragraph la lb iq lc b ld le ka lf lg lh kd li lj lk ll lm ln lo lp lq lr ls lt lu lv ij bi translated"><a class="ae mb" href="https://medium.com/towards-artificial-intelligence/linear-regression-explained-f5cc85ae2c5c" rel="noopener">线性回归解释</a></p><p id="e377" class="pw-post-body-paragraph la lb iq lc b ld le ka lf lg lh kd li lj lk ll lm ln lo lp lq lr ls lt lu lv ij bi translated"><a class="ae mb" href="https://medium.com/datadriveninvestor/determining-perfect-fit-for-your-ml-model-339459eef670" rel="noopener">确定最适合您的ML模型</a></p><blockquote class="qe qf qg"><p id="0acb" class="la lb om lc b ld le ka lf lg lh kd li qh lk ll lm qi lo lp lq qj ls lt lu lv ij bi translated"><em class="iq">干杯！</em></p></blockquote></div></div>    
</body>
</html>