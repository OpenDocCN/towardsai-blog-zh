<html>
<head>
<title>Create a Home Price Prediction App with Plotly-Dash, Google BigQuery, and Machine Learning</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">使用Plotly-Dash、Google BigQuery和机器学习创建一个房屋价格预测应用程序</h1>
<blockquote>原文：<a href="https://pub.towardsai.net/create-a-home-price-prediction-app-with-plotly-dash-google-bigquery-and-machine-learning-c86b715f8f04?source=collection_archive---------1-----------------------#2021-06-07">https://pub.towardsai.net/create-a-home-price-prediction-app-with-plotly-dash-google-bigquery-and-machine-learning-c86b715f8f04?source=collection_archive---------1-----------------------#2021-06-07</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><h2 id="b192" class="ir is it bd b dl iu iv iw ix iy iz dk ja translated" aria-label="kicker paragraph"><a class="ae ep" href="https://towardsai.net/p/category/machine-learning" rel="noopener ugc nofollow" target="_blank">机器学习</a></h2><div class=""/><div class=""><h2 id="e064" class="pw-subtitle-paragraph jz jc it bd b ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq dk translated">使用实时销售数据通过XGBoost预测房价</h2></div><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi kr"><img src="../Images/32f5d0c55f52163e0a597f1f35d0d3c5.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*qwI_WMY9_1z-S84b"/></div></div><figcaption class="ld le gj gh gi lf lg bd b be z dk translated">由<a class="ae lh" href="https://unsplash.com/@tierramallorca?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Tierra Mallorca </a>在<a class="ae lh" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上拍摄的照片</figcaption></figure><p id="cb95" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">查看<a class="ae lh" href="https://dsprojectapp.herokuapp.com/" rel="noopener ugc nofollow" target="_blank"> <strong class="lk jd"> Web App </strong> </a>和我的<a class="ae lh" href="https://github.com/aaronzhuclover/Home-Price-Prediction-forPublic" rel="noopener ugc nofollow" target="_blank"> <strong class="lk jd"> GitHub </strong> </a>上的代码，如果有任何问题，请随时告诉我！</p><h1 id="4b5e" class="me mf it bd mg mh mi mj mk ml mm mn mo ki mp kj mq kl mr km ms ko mt kp mu mv bi translated"><strong class="ak">项目背景</strong></h1><p id="19bf" class="pw-post-body-paragraph li lj it lk b ll mw kd ln lo mx kg lq lr my lt lu lv mz lx ly lz na mb mc md im bi translated">无论你是买房还是卖房，房价的变化都会影响你的住房计划。密切关注房价可以让你知道，如果你打算近期买卖房子，会发生什么。</p><p id="599e" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">因此，在这个项目中，我想利用我的数据科学技能来创建一个有趣的应用程序，它可以跟踪房屋价格、销售量，并使用机器学习进行价格预测。更有趣的是，它还会告诉用户新上市的房子的价格是高还是低。</p><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi nb"><img src="../Images/cc8938232e32a097bceb25277359cd5a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*jkdwI3KTEdrn-2MAfQHmWg.png"/></div></div><figcaption class="ld le gj gh gi lf lg bd b be z dk translated">(作者创作)</figcaption></figure><h1 id="c0aa" class="me mf it bd mg mh mi mj mk ml mm mn mo ki mp kj mq kl mr km ms ko mt kp mu mv bi translated"><strong class="ak">后端:构建数据管道</strong></h1><p id="db9e" class="pw-post-body-paragraph li lj it lk b ll mw kd ln lo mx kg lq lr my lt lu lv mz lx ly lz na mb mc md im bi translated"><strong class="lk jd">收集redfin.com的销售数据</strong></p><p id="ec59" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">对于这个项目，我编写了一个Python脚本来从redfin.com下载房屋销售数据。该脚本将使用windows计算机中的任务计划程序每天自动运行。</p><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi nc"><img src="../Images/bb233c18f91c219f8db0fb7fb7acf38a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*OPtRNr5JrtvLRMWH"/></div></div><figcaption class="ld le gj gh gi lf lg bd b be z dk translated">redfin.com</figcaption></figure><p id="628c" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">在给定的redfin页面上，我们可以复制下载链接，如下所示。我们可以扭曲参数，比如“num_homes”。“region_id”和“sf”来下载我们感兴趣的数据集。</p><pre class="ks kt ku kv gt nd ne nf ng aw nh bi"><span id="a456" class="ni mf it ne b gy nj nk l nl nm"><a class="ae lh" href="https://www.redfin.com/stingray/api/gis-csv?al=1&amp;market=socal&amp;min_stories=1&amp;num_homes=350&amp;ord=redfin-recommended-asc&amp;page_number=1&amp;region_id=25415&amp;region_type=6&amp;sf=1,2,3,5,6,7&amp;status=9&amp;uipt=1,2,3,4,5,6,7,8&amp;v=8" rel="noopener ugc nofollow" target="_blank">https://www.redfin.com/stingray/api/gis-csv?al=1&amp;market=socal&amp;min_stories=1&amp;num_homes=350&amp;ord=redfin-recommended-asc&amp;page_number=1&amp;region_id=25415&amp;region_type=6&amp;sf=1,2,3,5,6,7&amp;status=9&amp;uipt=1,2,3,4,5,6,7,8&amp;v=8</a></span></pre><p id="64a2" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">使用Python中的“requests”库可以直接从redfin下载CSV格式的房屋销售数据。</p><pre class="ks kt ku kv gt nd ne nf ng aw nh bi"><span id="4821" class="ni mf it ne b gy nj nk l nl nm">import pandas as pd<br/>import requests</span><span id="b808" class="ni mf it ne b gy nn nk l nl nm">url = r’https://www.redfin.com/stingray/api/gis-csv?al=1&amp;market=socal&amp;min_stories=1&amp;num_homes=350&amp;ord=redfin-recommended-asc&amp;page_number=1&amp;region_id=25415&amp;region_type=6&amp;sf=1,2,3,5,6,7&amp;status=9&amp;uipt=1,2,3,4,5,6,7,8&amp;v=8’</span><span id="cbb6" class="ni mf it ne b gy nn nk l nl nm">file = requests.get(url, headers={‘User-Agent’: ‘Mozilla/5.0’}).content</span><span id="4414" class="ni mf it ne b gy nn nk l nl nm">df = pd.read_csv(io.StringIO(file.decode(‘utf-8’)))</span></pre><p id="d62d" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated"><strong class="lk jd"> Redfin API </strong></p><p id="9dcd" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">除了房屋销售数据之外，我们还可以在ML模型中包含其他控制个人房屋效应的解释变量。<a class="ae lh" href="https://pypi.org/project/redfin/" rel="noopener ugc nofollow" target="_blank"> Redfin API </a>为在redfin.com上市的资产提供附加数据，如学校评级、步行评分、交通评分和自行车评分。</p><pre class="ks kt ku kv gt nd ne nf ng aw nh bi"><span id="d51d" class="ni mf it ne b gy nj nk l nl nm">from redfin import Redfin</span><span id="ef29" class="ni mf it ne b gy nn nk l nl nm">client = Redfin()<br/>address = ‘628 Castlehill Dr, Walnut, CA 91789’<br/>response = client.search(address)<br/>url = response[‘payload’][‘exactMatch’][‘url’]<br/>initial_info = client.initial_info(url)<br/>property_id = initial_info[‘payload’][‘propertyId’]<br/>listing_id = initial_info[‘payload’][‘listingId’]<br/>mls_data = client.below_the_fold(property_id)<br/>schools_rating = mls_data[‘payload’][‘schoolsAndDistrictsInfo’][‘servingThisHomeSchools’]</span></pre><p id="f77b" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated"><strong class="lk jd">弗雷德API </strong></p><p id="feab" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">控制市场效应的宏观经济变量在ML模型中也很重要。引入这些外部经济因素，弗雷德·API派上了用场。对于这个项目，我使用了两个经济变量，S&amp;P/Case-Shiller CA-洛杉矶房价指数和30年期固定利率抵押贷款利率。</p><pre class="ks kt ku kv gt nd ne nf ng aw nh bi"><span id="6e81" class="ni mf it ne b gy nj nk l nl nm">from fredapi import Fred<br/>fred = Fred(api_key='3e45db934f364bc329aca420c85fa04e')<br/># extract S&amp;P/Case-Shiller CA-Los Angeles Home Price Index (LXXRNSA)<br/># <a class="ae lh" href="https://fred.stlouisfed.org/series/LXXRNSA" rel="noopener ugc nofollow" target="_blank">https://fred.stlouisfed.org/series/LXXRNSA</a><br/>la_hpi_raw = fred.get_series('LXXRNSA')<br/>la_hpi = la_hpi_raw.to_frame()<br/>la_hpi.columns = ['hpi']<br/>la_hpi['month'] = la_hpi.index<br/>la_hpi = la_hpi.reset_index(drop = True)<br/>la_hpi['month'] = la_hpi.apply(lambda x: x['month'].date(), axis = 1)<br/>weights = np.array([0.2, 0.3, 0.5])<br/>sum_weights = np.sum(weights)<br/># compute weighted MA from latest 3 months<br/>la_hpi['hpi'] = la_hpi['hpi'].rolling(3).apply(lambda x: np.sum(weights*x) / sum_weights, raw=False).reset_index(drop = True)<br/>month_diff = datetime.now().month - la_hpi['month'].max().month<br/># reset the month variable so that it can be merged with sales data<br/>la_hpi['month'] = la_hpi['month'] + pd.DateOffset(months=month_diff)<br/>la_hpi['month'] = la_hpi.apply(lambda x: x['month'].date(), axis = 1)<br/><br/># 30-Year Fixed Rate Mortgage Average in the United States (MORTGAGE30US)<br/># <a class="ae lh" href="https://fred.stlouisfed.org/series/MORTGAGE30US" rel="noopener ugc nofollow" target="_blank">https://fred.stlouisfed.org/series/MORTGAGE30US</a><br/>mort_rate_30yrs_raw = fred.get_series('MORTGAGE30US')<br/>mort_rate_30yrs = mort_rate_30yrs_raw.to_frame()<br/>mort_rate_30yrs.columns = ['mort_rate']<br/>mort_rate_30yrs['date'] = mort_rate_30yrs.index<br/>mort_rate_30yrs = mort_rate_30yrs.reset_index(drop = True)<br/>mort_rate_30yrs['date'] = mort_rate_30yrs.apply(lambda x: x['date'].date(), axis = 1)<br/>mort_rate_30yrs['year'] = mort_rate_30yrs.apply(lambda x: x['date'].year, axis = 1)<br/>mort_rate_30yrs['month'] = mort_rate_30yrs.apply(lambda x: x['date'].month, axis = 1)<br/>mort_rate_30yrs = mort_rate_30yrs.groupby(['year', 'month'])['mort_rate'].mean().reset_index()<br/>mort_rate_30yrs['month'] = mort_rate_30yrs.apply(lambda x: date(int(x['year']), int(x['month']), 1), axis = 1)<br/>mort_rate_30yrs = mort_rate_30yrs.drop(columns = ['year'])</span></pre><p id="dd7d" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated"><strong class="lk jd">用熊猫清理数据</strong></p><p id="7251" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">一旦收集了所有的数据，我就使用流行的数据操作库“Pandas”来清理、整合和聚集数据。</p><p id="2d04" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">在这个过程中，我删除了缺少“价格”、“销售日期”的数据，保留了我感兴趣的城市的销售数据。我还修正了公寓/合作公寓的“地段大小”。我从销售数据中提取的特征列表包括“床位数”、“浴室数”、“平方英尺”、“地段大小”、“年龄”、“HOA”、“房产类型”、“邮政编码”、“城市”和“销售月份”。</p><p id="2199" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">经济变量可能不会及时公布。例如，S&amp;P/Case-Shiller CA-Los Angeles 5月份的房价指数要到6月底才会公布。因此，没有必要将销售数据与经济变量加入同一个月。相反，我计算了最近3个月的加权移动平均值，并加入了本月的销售数据。</p><pre class="ks kt ku kv gt nd ne nf ng aw nh bi"><span id="d9aa" class="ni mf it ne b gy nj nk l nl nm">import pandas as pd</span><span id="0a60" class="ni mf it ne b gy nn nk l nl nm">data.rename(columns = {'URL (SEE <a class="ae lh" href="http://www.redfin.com/buy-a-home/comparative-market-analysis" rel="noopener ugc nofollow" target="_blank">http://www.redfin.com/buy-a-home/comparative-market-analysis</a> FOR INFO ON PRICING)':'URL'}, inplace = True)<br/>data = data[~data['CITY'].isnull()]<br/>data = data[data['CITY'].isin(['Irvine', 'Arcadia', 'El Monte', 'Walnut', 'Rowland Heights'])]<br/>data = data[data['PROPERTY TYPE'].str.contains('Single|Condo|Townhouse')]<br/>data = data[~data['SOLD DATE'].isnull()]<br/>data.rename(columns = {'ZIP OR POSTAL CODE': 'ZIP',<br/>                          'HOA/MONTH': 'HOA',<br/>                          'PROPERTY TYPE': 'PROPERTY_TYPE',<br/>                          'SQUARE FEET': 'SQUARE_FEET',<br/>                          'LOT SIZE': 'LOT_SIZE'<br/>                          }, inplace = True)<br/>data = data[~data['PRICE'].isnull()]<br/>data['PRICE'] = data['PRICE'].astype('int')<br/># SOLD DATE: month<br/>data['SOLD DATE2'] = pd.to_datetime(data['SOLD DATE'], format='%B-%d-%Y')<br/>data['year'] = pd.DatetimeIndex(data['SOLD DATE2']).year<br/>data['mth'] = pd.DatetimeIndex(data['SOLD DATE2']).month<br/>data['month'] = data.apply(lambda x: date(int(x['year']), int(x['mth']), 1), axis = 1)<br/># YEAR BUILT: age<br/>data['age'] = data['year'] - data['YEAR BUILT']<br/># HOA/MONTH: if nan, set it to be $0<br/>data['HOA'] = data.apply(lambda x: 0 if (np.isnan(x['HOA']) &amp; bool(re.findall('Single', x['PROPERTY_TYPE'])))  else  x['HOA'], axis =1)<br/># LOT SIZE: change LOT SIZE to be  SQUARE FEET for non-single house<br/>data['LOT_SIZE'] = data.apply(lambda x: x['LOT_SIZE'] if re.findall('Single', x['PROPERTY_TYPE']) else  x['SQUARE_FEET']    , axis =1)<br/># ZIP<br/>data = data[~data['ZIP'].isnull()]<br/>data['ZIP'] = data['ZIP'].astype('int')<br/>zip_keep = data['ZIP'].value_counts()<br/>zip_keep = zip_keep[zip_keep/len(data) &gt; 0.01].index<br/>data = data[data['ZIP'].isin(zip_keep)]<br/>data['ZIP'].value_counts(dropna = False)<br/>keep_var = ['PRICE', 'PROPERTY_TYPE', 'CITY', 'ZIP', 'BEDS', 'BATHS', 'SQUARE_FEET', 'LOT_SIZE', 'age', 'HOA', 'year', 'mth', 'month']<br/>data = data[keep_var]<br/>df = data.merge(mort_rate_30yrs, on = 'month', how = 'left')<br/>df = df.merge(la_hpi, on = 'month', how = 'left')<br/>df.columns = [i.lower()  for i in df.columns]</span></pre><p id="06d6" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated"><strong class="lk jd">在Google BigQuery中存储数据</strong></p><p id="c48d" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">一旦数据被清理和预处理，数据将被存储在Google BigQuery中，Python脚本将每天自动更新SQL数据库，以便我的应用程序可以访问最新的后端数据。</p><pre class="ks kt ku kv gt nd ne nf ng aw nh bi"><span id="54a3" class="ni mf it ne b gy nj nk l nl nm">from google.cloud import bigquery<br/>from google.oauth2 import service_account<br/>import json<br/>import tempfile<br/>from pandas_gbq import schema<br/>project = 'testpython-267102'<br/>credentials = service_account.Credentials.from_service_account_file(r'google_creds.json')<br/>client = bigquery.Client(credentials= credentials, project=project)<br/>sql = '''<br/> DROP TABLE IF EXISTS `sampledata.sales_data`;<br/> CREATE TABLE `sampledata.sales_data`(<br/>  property_type string,<br/>  address string,<br/>  city string,<br/>  zip FLOAT64,<br/>  price INT64,<br/>  beds FLOAT64,<br/>  baths FLOAT64,<br/>  sq_feet FLOAT64,<br/>  lot_size FLOAT64,<br/>  year_built FLOAT64<br/>  hoa FLOAT64<br/>  sold_date string<br/> );<br/> '''<br/>query = client.query(sql)<br/># insert using pd.to_gbq<br/># print(schema.generate_bq_schema(master))<br/>schema_ = schema.generate_bq_schema(data)['fields']<br/>data.to_gbq(destination_table = 'sampledata.sales_data',<br/>  project_id = project,<br/>  if_exists = 'append',<br/>  credentials = credentials,<br/>  table_schema=schema_<br/>)</span></pre><h1 id="f3ce" class="me mf it bd mg mh mi mj mk ml mm mn mo ki mp kj mq kl mr km ms ko mt kp mu mv bi translated"><strong class="ak">用XGBoost建模</strong></h1><p id="f2c7" class="pw-post-body-paragraph li lj it lk b ll mw kd ln lo mx kg lq lr my lt lu lv mz lx ly lz na mb mc md im bi translated">现在我们来看建模部分。在这个项目中，我使用了一个基于决策树的算法，<strong class="lk jd"> XGBoost </strong>。XGBoost提供了梯度增强的有效实现，可用于回归预测建模。一次添加几棵树，以校正先前模型产生的预测误差。</p><p id="51f4" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">为了调整超参数，在整个建模过程中应用了<strong class="lk jd">网格搜索</strong>以获得最佳参数集。</p><pre class="ks kt ku kv gt nd ne nf ng aw nh bi"><span id="2ce9" class="ni mf it ne b gy nj nk l nl nm">from sklearn.model_selection import GridSearchCV<br/>from xgboost import XGBRegressor<br/>from sklearn.metrics import mean_squared_error, mean_absolute_error, make_scorer, r2_score, mean_absolute_percentage_error</span><span id="4b0d" class="ni mf it ne b gy nn nk l nl nm"># split data into training and testing<br/>X_train,X_val,y_train,y_val = train_test_split(X,y,test_size=0.2,random_state=0)<br/>X_train.shape, X_val.shape</span><span id="f0e3" class="ni mf it ne b gy nn nk l nl nm"># need to create function to return accuracy of GridSearchCV<br/>def tuning_para(alg, tuning_para):<br/>    gsearch = GridSearchCV(estimator=alg,<br/>                           param_grid = tuning_para, <br/>                           scoring=make_scorer(mean_squared_error, squared=False, greater_is_better=False),<br/>                           #scoring=make_scorer(r2_score),<br/>                           n_jobs=-1, <br/>                           cv=5,<br/>                           verbose = 2)   <br/>    gsearch.fit(X_train, y_train)<br/>    predictions = gsearch.predict(X_val)<br/>    return gsearch</span><span id="417e" class="ni mf it ne b gy nn nk l nl nm">#################################    <br/># step 1: let's test learning rate and n_estimator first<br/>para_test = {'learning_rate':[0.01, 0.05, 0.1, 0.2],<br/>             'n_estimators':[100, 200, 300]}<br/>xgb_model = XGBRegressor(objective = 'reg:squarederror', random_state =27)<br/>xgb_model_deploy = tuning_para(xgb_model, para_test)<br/><br/># step 2: Tune max_depth and min_child_weight<br/>para_test = {<br/> 'max_depth':range(3,10,2), # max depth of each tree<br/> 'min_child_weight':range(1,6,2) # cover <br/>}<br/>xgb_model = XGBRegressor(objective = 'reg:squarederror', <br/>                         random_state =27,<br/>                         learning_rate = 0.05,<br/>                         n_estimators = 300<br/>                         )<br/>xgb_model_deploy = tuning_para(xgb_model, para_test)<br/><br/># Step 3: Tune gamma<br/>para_test= {<br/>    'gamma':[i/10.0 for i in range(0,5)] # the min gain requried to split<br/>}<br/>xgb_model = XGBRegressor(objective = 'reg:squarederror', <br/>                         random_state =27,<br/>                         learning_rate = 0.05,<br/>                         n_estimators = 300,<br/>                         max_depth = 7,<br/>                         min_child_weight = 1<br/>                         )<br/>xgb_model_deploy = tuning_para(xgb_model, para_test)</span><span id="4b60" class="ni mf it ne b gy nn nk l nl nm"># Step 4: Tune subsample and colsample_bytree<br/>para_test = {<br/> 'subsample':[i/10.0 for i in range(6,10)],  # number of samples allowed <br/> 'colsample_bytree':[i/10.0 for i in range(6,10)] # number of fields allowed in each tree<br/>}<br/>xgb_model = XGBRegressor(objective = 'reg:squarederror', <br/>                         random_state =27,<br/>                         learning_rate = 0.05,<br/>                         n_estimators = 300,<br/>                         max_depth = 7,<br/>                         min_child_weight = 1,<br/>                         gamma = 0<br/>                         )<br/>xgb_model_deploy = tuning_para(xgb_model, para_test)</span><span id="4dbe" class="ni mf it ne b gy nn nk l nl nm">#################################<br/># final model <br/>xgb_model = XGBRegressor(objective = 'reg:squarederror', <br/>                         random_state =27,<br/>                         learning_rate = 0.05,<br/>                         n_estimators = 300,<br/>                         max_depth = 7,<br/>                         min_child_weight = 1,<br/>                         gamma = 0,<br/>                         colsample_bytree = 0.8,<br/>                         subsample = 0.9<br/>                         )</span></pre><p id="d0dc" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">在回归问题中，XGBoost等机器学习模型会预测单个值，但不会给出该值的确定性。有时，能够测量<strong class="lk jd">预测</strong>的确定性水平是有用的。特别是，对于房屋价格预测模型，我没有包括单个房屋的特征，如游泳池、太阳能电池板、厨房改造、新屋顶、新地毯等。</p><p id="4e0d" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">为了计算<strong class="lk jd">预测区间</strong>，我们需要产生一个预测和该预测的估计误差。为了简化，我假设期望的预测遵循正态分布，并且正态分布的标准偏差是常数。因此，我们可以用RMSE来估计标准差。(实际上，误差并不总是恒定的。我还在最后的注释中包含了一个改进的模型)</p><pre class="ks kt ku kv gt nd ne nf ng aw nh bi"><span id="3308" class="ni mf it ne b gy nj nk l nl nm">xgb_model_deploy = xgb_model.fit(X_train.append(X_val), y_train.append(y_val))<br/>prediction  = xgb_model_deploy.predict(X_train.append(X_val))<br/>st_dev = (mean_squared_error(prediction, y_train.append(y_val)) ** 0.5 ).round(-3)</span></pre><p id="6fbe" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">我们可以将90%的预测区间计算为[预测-1.64*SD，预测+1.64*SD]。</p><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi no"><img src="../Images/ae7fced6b0bdbb95437706c75dcf8a09.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*EPeZJQpw-jjMESpO66DT2A.png"/></div></div><figcaption class="ld le gj gh gi lf lg bd b be z dk translated">预测间隔(由作者创建)</figcaption></figure><h1 id="e13a" class="me mf it bd mg mh mi mj mk ml mm mn mo ki mp kj mq kl mr km ms ko mt kp mu mv bi translated">前端:创建Web应用程序</h1><p id="7bbe" class="pw-post-body-paragraph li lj it lk b ll mw kd ln lo mx kg lq lr my lt lu lv mz lx ly lz na mb mc md im bi translated"><strong class="lk jd">打造Dash App </strong></p><p id="17aa" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">在“Dash”的帮助下，创建一个web应用程序变得很容易。<strong class="lk jd"> Dash </strong>让数据科学家能够在交互式网络应用中展示他们的分析，并扩展了传统“仪表板”的概念。它使用Dash核心组件、HTML组件、Bootstrap组件和回调来构建交互式应用。</p><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi np"><img src="../Images/41988c695983e704a5565244b0c1dfb7.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/1*o48t4m3jcdIGiBv6Sd2opw.gif"/></div></div><figcaption class="ld le gj gh gi lf lg bd b be z dk translated">(作者创作)</figcaption></figure><p id="5cf0" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">在这个项目中，我在本地windows机器上预处理数据和预训练模型。所以Dash app非常轻量级，速度也很快。它只需要请求并显示来自Google Bigquery的数据。</p><pre class="ks kt ku kv gt nd ne nf ng aw nh bi"><span id="d74a" class="ni mf it ne b gy nj nk l nl nm">import dash<br/>import dash_core_components as dcc<br/>import dash_html_components as html<br/>from dash.dependencies import Input, Output, State<br/>import dash_bootstrap_components as dbc</span><span id="0ddf" class="ni mf it ne b gy nn nk l nl nm">external_stylesheets = [dbc.themes.BOOTSTRAP]<br/>app = dash.Dash(__name__, external_stylesheets=external_stylesheets)<br/>app.title = 'Housing Price Dashboard'<br/>server = app.server<br/>app.layout = html.Div([<br/>dcc.Tabs(style = {'width': '100%'}, children=[<br/>        dcc.Tab(label='Housing Price Index', children = [<br/>        html.Div([<br/>        html.Br(),<br/>        dbc.Row([html.Div(children='Choose Year Range', style = {"margin-left": "30px"})]),<br/>        dbc.Row([<br/>            dbc.Col(<br/>            dcc.RangeSlider(<br/>            id='year-range-slider',<br/>            min=2000,<br/>            max=2021,<br/>            step=1,<br/>            value=[2020, 2021],<br/>            marks = {i: str(i) for i in range(2000,2022, 1)}<br/>            )<br/>            )<br/>        ]),<br/>        html.Br(),<br/>        dbc.Row([<br/>        dbc.Col(<br/>            dbc.Checklist(<br/>            id="checklist",<br/>            options=[{"label": x, "value": x} for x in all_locations],<br/>            value=all_locations,<br/>            labelStyle={'display': 'inline-block'},<br/>            labelCheckedStyle={"color": "red"},<br/>            inline=True, # arrange list horizontally<br/>            style={"justify-content":"space-between", "font-size":"24px", "margin-left": "100px"}<br/>            )<br/>        )]),<br/>        dbc.Row([<br/>            dbc.Col(html.Div(dcc.Graph(id='line-graph'), style = {'width': '100%'}))<br/>        ])<br/>        ])<br/>        ])<br/>    ], style = {'padding': '20px'})<br/><br/># create callback for line graph<br/><a class="ae lh" href="http://twitter.com/app" rel="noopener ugc nofollow" target="_blank">@app</a>.callback(<br/>Output('line-graph', 'figure'),<br/>Input('checklist', 'value'),<br/>Input('year-range-slider', 'value')<br/>)<br/>def update_line_graph (cities, year_range):<br/>    selected_df = df[df.location.isin(cities)]<br/>    selected_df = selected_df.query(f'year&gt;={year_range[0]} &amp; year&lt;={year_range[1]}')<br/>    fig = px.line(selected_df, x="month", y="price_med_ma6", color = 'location', title='6-Month Weighted Moving Average of Median Housing Price',<br/>    labels = {'price_med_ma6':'Media Housing Pirce ($/SF)', 'location': 'City', 'month': ''}, height=500<br/>)<br/># edit hover effects<br/>fig.update_traces(mode="lines", hovertemplate=None)<br/># update figure layout<br/>fig.update_layout(<br/>    title = {'x':0.5, 'xanchor': 'center', 'yanchor': 'top', 'font': {'size': 20}},<br/>    legend = {'orientation': 'h', 'yanchor': "top", 'xanchor': "left", 'x': 0, 'font': {'size': 20} },<br/>    legend_title='',<br/>    hovermode="x unified",<br/>    hoverlabel = {'font_size': 12, 'font_family': "Rockwell", 'namelength': 20}<br/>)<br/>return fig</span><span id="209a" class="ni mf it ne b gy nn nk l nl nm"># run the app<br/>if __name__ == '__main__':<br/>app.run_server(debug=True)</span></pre><p id="ecc8" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated"><strong class="lk jd">使用GitHub和Heroku部署应用</strong></p><p id="f9c7" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated"><strong class="lk jd"> Heroku </strong>与<strong class="lk jd"> GitHub </strong>集成，使得将GitHub上的代码部署到Heroku上托管的应用程序变得更加容易。当我们在GitHub上修改代码时，它会自动在Heroku上的app上部署更新。</p><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi nq"><img src="../Images/a089e4a29d14d98478ce0d13f28227b8.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*2u6PLKWyIfoY_ySZI1OZuQ.png"/></div></div><figcaption class="ld le gj gh gi lf lg bd b be z dk translated">(作者创作)</figcaption></figure><h1 id="c1d0" class="me mf it bd mg mh mi mj mk ml mm mn mo ki mp kj mq kl mr km ms ko mt kp mu mv bi translated">最终注释</h1><ul class=""><li id="7854" class="nr ns it lk b ll mw lo mx lr nt lv nu lz nv md nw nx ny nz bi translated">实际上，误差并不总是恒定的。为了改进模型，我们可以拟合一个模型来预测误差本身。直觉告诉我们，有更多房间、更大平方英尺或更好社区的房子往往会有更多的价格变化。</li><li id="e139" class="nr ns it lk b ll oa lo ob lr oc lv od lz oe md nw nx ny nz bi translated">Redfin API还提供了属性的文本描述。它将包括关键字，如，“安静的社区”，“新改建的厨房”，“新粉刷的外墙”，可以解释房价。为了将来的改进，我可以使用NLP模型，比如Word2Vec，将文本转换成ML模型中的特性。</li></ul><h1 id="b722" class="me mf it bd mg mh mi mj mk ml mm mn mo ki mp kj mq kl mr km ms ko mt kp mu mv bi translated">感谢您的阅读！！！</h1><p id="070d" class="pw-post-body-paragraph li lj it lk b ll mw kd ln lo mx kg lq lr my lt lu lv mz lx ly lz na mb mc md im bi translated">如果你喜欢这篇文章，并且想<strong class="lk jd">请我喝杯咖啡，</strong>请<a class="ae lh" href="https://ko-fi.com/aaronzhu" rel="noopener ugc nofollow" target="_blank">点击这里</a>。</p><p id="99d6" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">您可以注册一个<a class="ae lh" href="https://aaron-zhu.medium.com/membership" rel="noopener"> <strong class="lk jd">会员</strong> </a>来解锁我的文章的全部访问权限，并且可以无限制地访问介质上的所有内容。如果你想在我发表新文章时收到电子邮件通知，请<a class="ae lh" href="https://aaron-zhu.medium.com/subscribe" rel="noopener"> <strong class="lk jd">订阅。</strong></a></p></div></div>    
</body>
</html>