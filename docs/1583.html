<html>
<head>
<title>Paper Explained: TransGAN — Two Transformers can make One Strong GAN</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">论文解释:trans GAN——两个变压器可以组成一个强大的GAN</h1>
<blockquote>原文：<a href="https://pub.towardsai.net/paper-explained-transgan-two-transformers-can-make-one-strong-gan-515d24350fdb?source=collection_archive---------1-----------------------#2021-02-26">https://pub.towardsai.net/paper-explained-transgan-two-transformers-can-make-one-strong-gan-515d24350fdb?source=collection_archive---------1-----------------------#2021-02-26</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><h2 id="bb13" class="ir is it bd b dl iu iv iw ix iy iz dk ja translated" aria-label="kicker paragraph"><a class="ae ep" href="https://towardsai.net/p/category/computer-vision" rel="noopener ugc nofollow" target="_blank">计算机视觉</a>，<a class="ae ep" href="https://towardsai.net/p/category/machine-learning/deep-learning" rel="noopener ugc nofollow" target="_blank">深度学习</a></h2><div class=""/><div class=""><h2 id="aed9" class="pw-subtitle-paragraph jz jc it bd b ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq dk translated">一个无CNN的GAN网络</h2></div><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi kr"><img src="../Images/b84ffb510bcd3554d771351b4fc3a402.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*jJz5A7KcnJwi7FJmu6BZLQ.jpeg"/></div></div><figcaption class="ld le gj gh gi lf lg bd b be z dk translated">照片由<a class="ae lh" href="https://unsplash.com/@d_mccullough?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText" rel="noopener ugc nofollow" target="_blank">丹尼尔·麦卡洛</a>在<a class="ae lh" href="https://unsplash.com/s/photos/collage-frames?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上拍摄</figcaption></figure><p id="aaaf" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">目前，大多数NLP任务都是使用变压器网络或变压器网络的变体来解决的。在过去的几年中，变压器由于其可重复使用性，已经成为NLP生态系统的一个组成部分。一些多模态任务在某处使用变压器网络；尽管如此，这些都不是CNN免费的。任何与变形金刚结合的计算机视觉任务；还采用CNN作为特征提取的主干。但是使用<a class="ae lh" href="https://arxiv.org/pdf/2102.07074.pdf" rel="noopener ugc nofollow" target="_blank"> TransGAN </a>，开发了基于纯变压器网络的架构来训练GAN进行图像合成。研究人员的一个强烈动机是简化和统一各种任务管道，因此一个通用的模型套件可以被许多应用程序广泛重用，从而避免重新发明轮子的需要。</p><p id="79e2" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">GAN通常用于图像合成，众所周知，训练GAN进行高质量的图像合成非常困难，从数据、模型、训练方法和超参数调整开始的每个方面都需要非常积极地考虑，以构建高效的GAN。我们都同意这样一个事实，即图像中的对象用它的周围环境来表示它自己，并且基本上用卷积来表示，感受野是局部的，因此除非经过足够多的层，否则不能处理长程相关性。随着图层的增加，可能会损失要素分辨率，并且可能会丢失精细细节。</p><p id="0971" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">每个GAN网络分为两部分，</p><ol class=""><li id="ec09" class="me mf it lk b ll lm lo lp lr mg lv mh lz mi md mj mk ml mm bi translated">发电机</li><li id="a996" class="me mf it lk b ll mn lo mo lr mp lv mq lz mr md mj mk ml mm bi translated">鉴别器</li></ol><p id="d8d8" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">如前所述，gan主要用于图像合成；在训练之后，只有生成器部分被保持来基于一些输入生成图像。在本文中，大部分重点放在发电机部分。开发能够匹配GAN网络的当前SOTA基准的良好发电机网络的努力分为四个部分。</p><h1 id="2d97" class="ms mt it bd mu mv mw mx my mz na nb nc ki nd kj ne kl nf km ng ko nh kp ni nj bi translated">发电机</h1><h2 id="0023" class="nk mt it bd mu nl nm dn my nn no dp nc lr np nq ne lv nr ns ng lz nt nu ni iz bi translated">1.记忆友好生成器</h2><p id="ec08" class="pw-post-body-paragraph li lj it lk b ll nv kd ln lo nw kg lq lr nx lt lu lv ny lx ly lz nz mb mc md im bi translated">在训练变形金刚时，它们是巨大的内存饥渴野兽，在NLP中，每个单词都被当作输入，但相同的方法不能用于通过堆叠编码器块来逐像素地生成图像，因为对于小的<strong class="lk jd"><em class="oa">(32×32)</em></strong>图像，序列长度将变成<strong class="lk jd"> <em class="oa"> 1024 </em> </strong>，导致更昂贵的自关注计算。为了避免这种情况，TransGAN逐渐增加输入序列，减少嵌入。</p><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div class="gh gi ob"><img src="../Images/ead07ab219a59092b0ae408cbdd10743.png" data-original-src="https://miro.medium.com/v2/resize:fit:1298/format:webp/1*C5DWNd8VyONfl_z8aTRt1A.png"/></div><figcaption class="ld le gj gh gi lf lg bd b be z dk translated">图片来源— <a class="ae lh" href="https://arxiv.org/pdf/2102.07074.pdf" rel="noopener ugc nofollow" target="_blank">论文</a></figcaption></figure><p id="a54b" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">如图所示，TransGAN中的发电机网络有三级变压器组。每一级堆叠几个变压器编码器<em class="oa">(默认为5，2，2)</em>。特征图分辨率分三个阶段增加，直到与最终分辨率<em class="oa"> (HxW) </em>匹配。生成器将随机噪声作为输入，并通过多层感知器(MLP)将其传递给长度为<em class="oa"> H x W x C </em>的向量。然后向量被整形成一个<em class="oa"> H x W </em>分辨率的特征图，每个点一个<em class="oa"> C维</em>嵌入。接下来，该特征图被视为与可学习的位置编码相结合的<em class="oa"> C维</em>记号的<em class="oa">长度64 </em>序列。</p><p id="d345" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">变换器编码器将嵌入标记作为输入，并递归地计算每个标记之间的对应关系。在每一级之后，插入一个<em class="oa">整形</em>和<em class="oa"> pixelshuffle </em>模块，以将输出放大到更高的分辨率。该模块首先将<em class="oa"> 1-D序列</em>嵌入到<em class="oa"> 2-D特征图</em>中，然后使用<em class="oa"> pixelshuffle </em>模块对分辨率进行升级并对嵌入维度进行下采样，从而得到大小为<strong class="lk jd"><em class="oa">2H</em></strong><em class="oa">x</em><strong class="lk jd"><em class="oa">2W</em></strong><em class="oa">x</em><strong class="lk jd"><em class="oa">C/4</em>为了移动到下一阶段，<em class="oa">二维特征图</em>再次被整形为<em class="oa">一维序列</em>，序列长度为<strong class="lk jd"><em class="oa">4</em></strong><em class="oa">xHW</em>* *并且嵌入维度为<strong class="lk jd"><em class="oa">C</em></strong><em class="oa">/</em><strong class="lk jd"><em class="oa">4</em></strong>。因此，在每一级，分辨率变得2倍大，而嵌入维数减少到输入的四分之一。一旦达到期望的分辨率；嵌入标记被投影到嵌入维度3，并且获得RGB图像。尽管如此，这还不足以达到目前美国有线电视新闻网的甘的SOTA基准分数，因此第二阶段，第三阶段和第四阶段。</strong></p><h2 id="3025" class="nk mt it bd mu nl nm dn my nn no dp nc lr np nq ne lv nr ns ng lz nt nu ni iz bi translated">2.增加数据以提高效率</h2><p id="d371" class="pw-post-body-paragraph li lj it lk b ll nv kd ln lo nw kg lq lr nx lt lu lv ny lx ly lz nz mb mc md im bi translated">为任何NLP任务预先训练基于转换器的模型需要大量数据。总的来说，变形金刚非常需要数据。类似地，即使是基于CNN的GANs，也使用数据扩充来达到良好的基准分数。当使用增强数据训练时，TransGAN实现了惊人的大幅度改进。</p><h2 id="f9b9" class="nk mt it bd mu nl nm dn my nn no dp nc lr np nq ne lv nr ns ng lz nt nu ni iz bi translated">3.自我监督辅助任务的联合训练</h2><p id="c42d" class="pw-post-body-paragraph li lj it lk b ll nv kd ln lo nw kg lq lr nx lt lu lv ny lx ly lz nz mb mc md im bi translated">NLP doming中的变压器网络从多个预训练任务中受益匪浅。已经发现，向GAN添加自我监督的共同训练任务已经稳定了GAN训练。合练任务可以是轮换预测什么的。类似地，在跨g an训练中，超分辨率的辅助协同训练任务与GAN损失相关联。发电机损耗增加了一个辅助项<strong class="lk jd"><em class="oa">λ∫L(超分辨率)</em> </strong>，其中<em class="oa"> L(超分辨率)</em>为最后阶段得到的超分辨率图像和中间任意阶段的低分辨率图像的均方误差<em class="oa"> λ </em>经验设定为<em class="oa"> 50 </em>。这种联合培训方法对TransGAN基准测试有些许帮助。</p><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi oc"><img src="../Images/f5dee3b735e0ffcf2fbca476e562a6e1.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*D1cEK4zI-tdCMaSBizD6zA.png"/></div></div><figcaption class="ld le gj gh gi lf lg bd b be z dk translated">图片来源— <a class="ae lh" href="https://arxiv.org/pdf/2102.07074.pdf" rel="noopener ugc nofollow" target="_blank">纸张</a></figcaption></figure><h2 id="99a0" class="nk mt it bd mu nl nm dn my nn no dp nc lr np nq ne lv nr ns ng lz nt nu ni iz bi translated">4.自我关注的位置感知定位</h2><p id="dbce" class="pw-post-body-paragraph li lj it lk b ll nv kd ln lo nw kg lq lr nx lt lu lv ny lx ly lz nz mb mc md im bi translated">如上所述，卷积算子是局部可接受的，并且在生成的图像中有自然的平滑度。这是变压器所缺少的，为了实现这一点，自我关注可以被适当地热启动，而根本不改变纯变压器。</p><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi od"><img src="../Images/e6d168c16df8e9581a733abd575a7faf.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*b5UBsGAVm7Lb-1stjbAgcQ.png"/></div></div><figcaption class="ld le gj gh gi lf lg bd b be z dk translated">图片来源— <a class="ae lh" href="https://arxiv.org/pdf/2102.07074.pdf" rel="noopener ugc nofollow" target="_blank">纸张</a></figcaption></figure><p id="ed49" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">如图所示，引入了一个掩码，通过该掩码，查询只允许与其未被掩码的邻居进行交互。在训练TransGAN模型期间，掩蔽区域逐渐减小，并且在最后阶段，没有掩蔽，并且自我关注是完全全局的。这一策略源于一个观察，即局部的自我关注在早期训练阶段最有帮助，但会伤害后期训练阶段和最终可达到的表现。这将通过首先优先考虑本地邻域，然后更广泛地利用非本地交互，来加强TransGAN模型以学习图像生成。由此，在每个块中具有三个阶段和5、4和2个变换器编码器的TransGAN模型分别获得8.63的初始分数和11.89的FID分数。</p><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div class="gh gi oe"><img src="../Images/6655cb9fe4a750c08ed328cffe6eef53.png" data-original-src="https://miro.medium.com/v2/resize:fit:1316/format:webp/1*xj1a8fR5x1GBYBKECygvmg.png"/></div><figcaption class="ld le gj gh gi lf lg bd b be z dk translated">图片来源— <a class="ae lh" href="https://arxiv.org/pdf/2102.07074.pdf" rel="noopener ugc nofollow" target="_blank">纸张</a></figcaption></figure><h1 id="f13e" class="ms mt it bd mu mv mw mx my mz na nb nc ki nd kj ne kl nf km ng ko nh kp ni nj bi translated">鉴别器</h1><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div class="gh gi of"><img src="../Images/1682c512a80989e8d89a53ea7d12f08d.png" data-original-src="https://miro.medium.com/v2/resize:fit:892/format:webp/1*Q1-DZ2o271WVTzdnmu9ZWg.png"/></div><figcaption class="ld le gj gh gi lf lg bd b be z dk translated">图片来源— <a class="ae lh" href="https://arxiv.org/pdf/2102.07074.pdf" rel="noopener ugc nofollow" target="_blank">纸张</a></figcaption></figure><p id="eea1" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">鉴别器基于<a class="ae lh" href="https://arxiv.org/pdf/2010.11929.pdf" rel="noopener ugc nofollow" target="_blank">视觉转换器</a>，其中图像的8×8块被认为是一个单词，然后被转换为一维序列，并通过具有位置编码的转换器编码器，最后，分类头采用<code class="fe og oh oi oj b">[cls]</code>令牌来输出真/假预测。</p><p id="b675" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">来自TransGAN Generator的一些合成图像。</p><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi ok"><img src="../Images/41d696ad1d17eba1b87a7876012bb886.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*oTdYPP2AgMqYGChWW5XK3A.png"/></div></div><figcaption class="ld le gj gh gi lf lg bd b be z dk translated">图片来源— <a class="ae lh" href="https://arxiv.org/pdf/2102.07074.pdf" rel="noopener ugc nofollow" target="_blank">论文</a></figcaption></figure><p id="776e" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">总的来说，我们看到了如何使用不含CNN的纯变压器方法进行图像合成，对于基于变压器的计算机视觉模型来说，还有很长的路要走，还有很大的改进空间。</p></div></div>    
</body>
</html>