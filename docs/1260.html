<html>
<head>
<title>How I Use Docker To Train Rasa 2.1.x Bots On A GPU</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">我如何使用Docker在GPU上训练Rasa 2.1.x机器人</h1>
<blockquote>原文：<a href="https://pub.towardsai.net/how-i-use-docker-to-train-rasa-2-1-x-bots-on-a-gpu-442cd9d31d67?source=collection_archive---------0-----------------------#2020-12-15">https://pub.towardsai.net/how-i-use-docker-to-train-rasa-2-1-x-bots-on-a-gpu-442cd9d31d67?source=collection_archive---------0-----------------------#2020-12-15</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><h2 id="2331" class="ir is it bd b dl iu iv iw ix iy iz dk ja translated" aria-label="kicker paragraph"><a class="ae ep" href="https://towardsai.net/p/category/machine-learning" rel="noopener ugc nofollow" target="_blank">机器学习</a>，<a class="ae ep" href="https://towardsai.net/p/category/programming" rel="noopener ugc nofollow" target="_blank">编程</a></h2><div class=""/><figure class="gl gn ka kb kc kd gh gi paragraph-image"><div role="button" tabindex="0" class="ke kf di kg bf kh"><div class="gh gi jz"><img src="../Images/8161e9c1df9ee1980dbf8f3bb47c3111.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*i6jnXIuylwoJ9eN8r1d-xA.png"/></div></div></figure><h1 id="e26f" class="kk kl it bd km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh bi translated">介绍</h1><p id="53a7" class="pw-post-body-paragraph li lj it lk b ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma mb mc md me mf im bi translated">在本文中，我将分享一种基于Docker的方法，使用GPU来训练基于Rasa 2.1.x框架构建的聊天机器人。</p><p id="c257" class="pw-post-body-paragraph li lj it lk b ll mg ln lo lp mh lr ls lt mi lv lw lx mj lz ma mb mk md me mf im bi translated">设置环境的所有代码都可以在这里找到<a class="ae ml" href="https://github.com/hsm207/vscode_rasabot_gpu" rel="noopener ugc nofollow" target="_blank"/>。</p><p id="2fb4" class="pw-post-body-paragraph li lj it lk b ll mg ln lo lp mh lr ls lt mi lv lw lx mj lz ma mb mk md me mf im bi translated">本文建立在我的另一篇名为<a class="ae ml" href="https://medium.com/towards-artificial-intelligence/my-vs-code-setup-to-prototype-rasa-chatbots-2993062de90" rel="noopener">My VS Code Setup To Prototype Rasa Chatbots</a>的文章中所描述的设置之上，所以一定要查看更多的上下文。</p><h1 id="a79f" class="kk kl it bd km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh bi translated">动机</h1><p id="7661" class="pw-post-body-paragraph li lj it lk b ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma mb mc md me mf im bi translated">在图形处理器上训练Rasa机器人是Rasa论坛中的一个热门问题(例如，请参见此处的<a class="ae ml" href="https://forum.rasa.com/t/should-we-install-gpu-for-training/24203" rel="noopener ugc nofollow" target="_blank"/>、此处的<a class="ae ml" href="https://forum.rasa.com/t/using-gpu-for-rasa-core-model-training/13566" rel="noopener ugc nofollow" target="_blank"/>、此处的<a class="ae ml" href="https://forum.rasa.com/t/rasa-nlu-how-to-train-the-data-with-gpu/4314" rel="noopener ugc nofollow" target="_blank"/>和此处的<a class="ae ml" href="https://forum.rasa.com/t/rasa-train-rasa-1-9-x-tensorflow-2-on-gpu/27299" rel="noopener ugc nofollow" target="_blank"/>)。让事情正常运行的一个常见挑战是将TensorFlow安装与正确的NVIDIA驱动程序相匹配。</p><p id="4124" class="pw-post-body-paragraph li lj it lk b ll mg ln lo lp mh lr ls lt mi lv lw lx mj lz ma mb mk md me mf im bi translated">我更喜欢基于Docker的解决方案，以避免不得不修改机器的配置。我想保持我所有的驱动程序更新，而不是被迫降级，以便我可以使用一个库。如果你是同一个阵营，那么我希望这篇文章对你有所裨益。</p><h1 id="2322" class="kk kl it bd km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh bi translated">先决条件</h1><p id="82b8" class="pw-post-body-paragraph li lj it lk b ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma mb mc md me mf im bi translated">不言而喻，你需要一台安装了NVIDIA GPU的机器。你还需要安装Docker、docker-compose和<a class="ae ml" href="https://github.com/NVIDIA/nvidia-docker" rel="noopener ugc nofollow" target="_blank"> NVIDIA容器工具包</a>。我将在本文中使用的机器是一个AWS EC2实例，其规格如下:</p><ul class=""><li id="5b69" class="mm mn it lk b ll mg lp mh lt mo lx mp mb mq mf mr ms mt mu bi translated">实例类型:g4dn.xlarge</li><li id="cbd1" class="mm mn it lk b ll mv lp mw lt mx lx my mb mz mf mr ms mt mu bi translated">AMI:深度学习AMI (Ubuntu 18.04)版本38.0</li><li id="eb88" class="mm mn it lk b ll mv lp mw lt mx lx my mb mz mf mr ms mt mu bi translated">GPU:英伟达特斯拉T4</li></ul><p id="9984" class="pw-post-body-paragraph li lj it lk b ll mg ln lo lp mh lr ls lt mi lv lw lx mj lz ma mb mk md me mf im bi translated">这些是我安装的docker和docker-compose的版本:</p><figure class="nb nc nd ne gt kd gh gi paragraph-image"><div class="gh gi na"><img src="../Images/d62f63afe739a9273dcc7156e3704bb7.png" data-original-src="https://miro.medium.com/v2/resize:fit:654/format:webp/1*4OdHdq7EHH2ESP4UcNybGQ.png"/></div><figcaption class="nf ng gj gh gi nh ni bd b be z dk translated">图1:主机上的docker和Docker合成版本</figcaption></figure><p id="68c6" class="pw-post-body-paragraph li lj it lk b ll mg ln lo lp mh lr ls lt mi lv lw lx mj lz ma mb mk md me mf im bi translated">要验证您是否正确设置了所有内容，您可以运行以下命令:</p><p id="9696" class="pw-post-body-paragraph li lj it lk b ll mg ln lo lp mh lr ls lt mi lv lw lx mj lz ma mb mk md me mf im bi translated"><code class="fe nj nk nl nm b">docker run --gpus all --rm nvidia/cuda nvidia-smi</code></p><p id="eb8b" class="pw-post-body-paragraph li lj it lk b ll mg ln lo lp mh lr ls lt mi lv lw lx mj lz ma mb mk md me mf im bi translated">这将为您提供主机中GPU的详细信息的打印输出。例如，在我的机器上，它是:</p><figure class="nb nc nd ne gt kd gh gi paragraph-image"><div class="gh gi nn"><img src="../Images/76eda8bd9a741e625da1d73e43c984f5.png" data-original-src="https://miro.medium.com/v2/resize:fit:1124/format:webp/1*2Iv5K937cuv5mK-Jnn6lcg.png"/></div><figcaption class="nf ng gj gh gi nh ni bd b be z dk translated">图2:主机上的GPU</figcaption></figure><h1 id="6ff7" class="kk kl it bd km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh bi translated">设置</h1><h2 id="540e" class="no kl it bd km np nq dn kq nr ns dp ku lt nt nu ky lx nv nw lc mb nx ny lg iz bi translated">概观</h2><p id="5177" class="pw-post-body-paragraph li lj it lk b ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma mb mc md me mf im bi translated">和以前一样，我们将有一个docker compose文件来描述Rasa服务器和action服务器。动作服务器的规格将保持不变，而rasa服务器将被更新，以允许它使用主机的GPU。</p><p id="1183" class="pw-post-body-paragraph li lj it lk b ll mg ln lo lp mh lr ls lt mi lv lw lx mj lz ma mb mk md me mf im bi translated">完成后，我们可以使用docker compose来调用rasa服务器来执行训练命令，即<code class="fe nj nk nl nm b">rasa train</code>。</p><h2 id="789b" class="no kl it bd km np nq dn kq nr ns dp ku lt nt nu ky lx nv nw lc mb nx ny lg iz bi translated">定义Rasa服务器映像</h2><p id="7081" class="pw-post-body-paragraph li lj it lk b ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma mb mc md me mf im bi translated">让我们创建一个名为<code class="fe nj nk nl nm b">gpu.Dockerfile</code>的文件，它将描述将被用作rasa服务器的容器。这两行就足够了:</p><figure class="nb nc nd ne gt kd gh gi paragraph-image"><div role="button" tabindex="0" class="ke kf di kg bf kh"><div class="gh gi nz"><img src="../Images/2d27f67c09b243e179f05142e706e846.png" data-original-src="https://miro.medium.com/v2/resize:fit:678/format:webp/1*lQ3PEMpJ5ab4Iw29imllbg.png"/></div></div><figcaption class="nf ng gj gh gi nh ni bd b be z dk translated">图rasa服务器的图像</figcaption></figure><p id="47be" class="pw-post-body-paragraph li lj it lk b ll mg ln lo lp mh lr ls lt mi lv lw lx mj lz ma mb mk md me mf im bi translated">图1说取TensorFlow 2.3.1的GPU版本镜像，在里面安装Rasa 2.1.3。我们构建这个特定的TensorFlow映像，因为这是Rasa 2.1.3使用的版本，并且这个映像已经正确安装了所有必要的驱动程序。</p><h2 id="af08" class="no kl it bd km np nq dn kq nr ns dp ku lt nt nu ky lx nv nw lc mb nx ny lg iz bi translated">定义Rasa服务器服务</h2><p id="c560" class="pw-post-body-paragraph li lj it lk b ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma mb mc md me mf im bi translated">这就是在上一篇文章的<code class="fe nj nk nl nm b">docker-compsose.yml</code>中定义rasa服务器服务的方式:</p><figure class="nb nc nd ne gt kd gh gi paragraph-image"><div class="gh gi oa"><img src="../Images/ddd037d7952799c0d7ede2f9fce42f92.png" data-original-src="https://miro.medium.com/v2/resize:fit:624/format:webp/1*Ecm_HJKnYE3QLfymBSW0tw.png"/></div><figcaption class="nf ng gj gh gi nh ni bd b be z dk translated">图4:没有GPU支持的rasa服务器服务</figcaption></figure><p id="2bdc" class="pw-post-body-paragraph li lj it lk b ll mg ln lo lp mh lr ls lt mi lv lw lx mj lz ma mb mk md me mf im bi translated">我们基本上是获取最新的rasa映像(我们也可以指定一个特定的版本),并使用该映像作为rasa服务器。</p><p id="8dec" class="pw-post-body-paragraph li lj it lk b ll mg ln lo lp mh lr ls lt mi lv lw lx mj lz ma mb mk md me mf im bi translated">为了启用GPU支持，我们需要将rasa服务器服务的定义修改如下:</p><figure class="nb nc nd ne gt kd gh gi paragraph-image"><div class="gh gi ob"><img src="../Images/869945956f982986a01b42104d0e3bb6.png" data-original-src="https://miro.medium.com/v2/resize:fit:620/format:webp/1*jfFO2B9aTYNQGLhnln1QLg.png"/></div><figcaption class="nf ng gj gh gi nh ni bd b be z dk translated">图5:支持GPU的rasa服务器服务</figcaption></figure><p id="c070" class="pw-post-body-paragraph li lj it lk b ll mg ln lo lp mh lr ls lt mi lv lw lx mj lz ma mb mk md me mf im bi translated">现在，rasa服务器服务将基于我们在上一节定义的<code class="fe nj nk nl nm b">gpu.Dockerfile</code>构建，并使用NVIDIA运行时(第8行)。</p><h1 id="854b" class="kk kl it bd km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh bi translated">培养</h1><p id="8af8" class="pw-post-body-paragraph li lj it lk b ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma mb mc md me mf im bi translated">完成前面的步骤后，我们可以执行以下命令来训练机器人:</p><figure class="nb nc nd ne gt kd gh gi paragraph-image"><div class="gh gi oc"><img src="../Images/ce4d52ff19324be47b7d90740badacfd.png" data-original-src="https://miro.medium.com/v2/resize:fit:1248/format:webp/1*0QzORT0J3YRXJIrIDaoI9A.png"/></div><figcaption class="nf ng gj gh gi nh ni bd b be z dk translated">图6:训练机器人的命令</figcaption></figure><p id="9a0f" class="pw-post-body-paragraph li lj it lk b ll mg ln lo lp mh lr ls lt mi lv lw lx mj lz ma mb mk md me mf im bi translated">图4中的命令将导致rasa-server服务仅在线运行<code class="fe nj nk nl nm b">rasa train</code>命令。培训结束后，rasa-server容器将被移除。</p><p id="fae4" class="pw-post-body-paragraph li lj it lk b ll mg ln lo lp mh lr ls lt mi lv lw lx mj lz ma mb mk md me mf im bi translated">培训的输出将存储在<code class="fe nj nk nl nm b">models</code>文件夹中。</p><p id="790a" class="pw-post-body-paragraph li lj it lk b ll mg ln lo lp mh lr ls lt mi lv lw lx mj lz ma mb mk md me mf im bi translated">这种方法的一个缺点是<code class="fe nj nk nl nm b">models</code>文件夹的所有权会在训练后切换到root用户和组。幸运的是，修复只需运行以下命令:</p><figure class="nb nc nd ne gt kd gh gi paragraph-image"><div class="gh gi na"><img src="../Images/bebfee415daa2120b56ae9d565250ff8.png" data-original-src="https://miro.medium.com/v2/resize:fit:654/format:webp/1*Nbw9jGjDABm5cC4Z90EMCA.png"/></div><figcaption class="nf ng gj gh gi nh ni bd b be z dk translated">图7:将models文件夹重新分配给当前用户的命令</figcaption></figure><p id="1e9a" class="pw-post-body-paragraph li lj it lk b ll mg ln lo lp mh lr ls lt mi lv lw lx mj lz ma mb mk md me mf im bi translated">如果您发现自己经常这样做，那么您可以定义一个VS代码任务，它将在训练完成后自动重新分配文件夹的权限:</p><figure class="nb nc nd ne gt kd gh gi paragraph-image"><div role="button" tabindex="0" class="ke kf di kg bf kh"><div class="gh gi od"><img src="../Images/ca08012eb9a84a80ed14e6e091596807.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*sfpLzLDJgjP_dpFe_T447w.png"/></div></div><figcaption class="nf ng gj gh gi nh ni bd b be z dk translated">图8:训练机器人并修复模型文件夹权限的任务</figcaption></figure><h1 id="4c8d" class="kk kl it bd km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh bi translated">基准</h1><p id="990f" class="pw-post-body-paragraph li lj it lk b ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma mb mc md me mf im bi translated">我有一个机器人花了大约80分钟在一个<a class="ae ml" href="https://aws.amazon.com/ec2/instance-types/z1d/" rel="noopener ugc nofollow" target="_blank"> z1d.large </a> EC2实例上训练。同一个机器人在一个<a class="ae ml" href="https://aws.amazon.com/ec2/instance-types/g4/" rel="noopener ugc nofollow" target="_blank"> g4dn.xlarge </a> EC2实例上训练只花了10分钟。</p><p id="5394" class="pw-post-body-paragraph li lj it lk b ll mg ln lo lp mh lr ls lt mi lv lw lx mj lz ma mb mk md me mf im bi translated">在撰写本文时，z1d.large和g4d.xlarge实例的按需Linux成本分别为每小时0.186美元和0.526美元。</p><p id="beb3" class="pw-post-body-paragraph li lj it lk b ll mg ln lo lp mh lr ls lt mi lv lw lx mj lz ma mb mk md me mf im bi translated">因此，就总成本和培训时间而言，g4dn.xlarge显然是赢家。</p><p id="02a0" class="pw-post-body-paragraph li lj it lk b ll mg ln lo lp mh lr ls lt mi lv lw lx mj lz ma mb mk md me mf im bi translated">也就是说，我不确定哪个CPU实例可以与g4dn.xlarge实例相比较。请在评论中告诉我你的想法。</p><h1 id="2c72" class="kk kl it bd km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh bi translated">结论</h1><p id="8cca" class="pw-post-body-paragraph li lj it lk b ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma mb mc md me mf im bi translated">本文描述了一种使用Docker容器在GPU上训练基于Rasa 2.1.x框架构建的机器人的方法。我希望你已经发现这是有用的。</p></div></div>    
</body>
</html>