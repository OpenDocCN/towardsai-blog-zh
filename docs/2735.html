<html>
<head>
<title>2D Path Planning With CNN</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">CNN在2D的路径规划</h1>
<blockquote>原文：<a href="https://pub.towardsai.net/2d-path-planning-with-cnn-c7e3866b679d?source=collection_archive---------1-----------------------#2022-05-05">https://pub.towardsai.net/2d-path-planning-with-cnn-c7e3866b679d?source=collection_archive---------1-----------------------#2022-05-05</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><p id="783e" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">卷积神经网络(CNN)是一种用于解决图像分类、分割、对象检测等任务的流行模型。这是一个实验，以评估其应用，以解决简单的2D路径规划问题。使用的编程语言是Python，以PyTorch、NumPy、OpenCV为主库。你可以在我的<a class="ae kl" href="https://github.com/dcaffo98/path-planning-cnn" rel="noopener ugc nofollow" target="_blank"> GitHub </a>上找到源代码。</p><h1 id="ad72" class="km kn iq bd ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj bi translated">任务</h1><p id="8a9c" class="pw-post-body-paragraph jn jo iq jp b jq lk js jt ju ll jw jx jy lm ka kb kc ln ke kf kg lo ki kj kk ij bi translated">简单地说，给定一个占用栅格地图，2D路径规划是关于寻找从给定的起点到期望的目标位置(<em class="lp">目标</em>)的最短可能路径，避免轨迹中的任何障碍。机器人学是路径规划至关重要的主要领域之一。像A*、D*、D* lite这样的算法以及相关的变体就是为了解决这类问题而开发出来的。如今，人工智能(AI)，尤其是强化学习，被广泛用于解释这一点。事实上，CNN通常是一些强化学习算法的主干。这个实验试图使用<em class="lp">一个单独的卷积神经网络</em>来处理简单的路径规划实例。</p><h1 id="d17b" class="km kn iq bd ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj bi translated">数据集</h1><p id="dbab" class="pw-post-body-paragraph jn jo iq jp b jq lk js jt ju ll jw jx jy lm ka kb kc ln ke kf kg lo ki kj kk ij bi translated">我面临的主要问题是(在机器学习中总是如此)去哪里找数据。我已经通过制作随机的2d地图为路径规划创建了自己的数据集。创建地图的过程非常简单:</p><ul class=""><li id="b424" class="lq lr iq jp b jq jr ju jv jy ls kc lt kg lu kk lv lw lx ly bi translated">先说一个100x100像素的正方形空矩阵<em class="lp"> M </em>。</li><li id="b33b" class="lq lr iq jp b jq lz ju ma jy mb kc mc kg md kk lv lw lx ly bi translated">对于矩阵中的每一项(像素)，从均匀分布中抽取一个从0到1的随机数<em class="lp"> r </em>。如果<em class="lp"> r </em> &gt; <em class="lp"> diff </em>，则将该像素设置为1；否则，将其设置为0。这里的<em class="lp"> diff </em>是一个参数<em class="lp"> </em>，表示一个像素成为障碍(即不能穿越的位置)的概率，因此，它与在该地图上找到可行路径的难度成比例。</li><li id="210c" class="lq lr iq jp b jq lz ju ma jy mb kc mc kg md kk lv lw lx ly bi translated">然后，让我们利用<a class="ae kl" href="https://en.wikipedia.org/wiki/Opening_(morphology)" rel="noopener ugc nofollow" target="_blank">开形态学操作符</a>来获得一个“块状”效果，更好地类似于真实的占用栅格地图。通过改变形态学结构元素的大小和<em class="lp"> diff </em>参数，我们能够生成具有不同难度的地图。</li></ul><figure class="mf mg mh mi gt mj gh gi paragraph-image"><div role="button" tabindex="0" class="mk ml di mm bf mn"><div class="gh gi me"><img src="../Images/df56d2a83c5c834998981f34cc439200.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*_CwCUQQM8ocVp_8hQTD8Cw.png"/></div></div><figcaption class="mq mr gj gh gi ms mt bd b be z dk translated">一些示例地图是随机生成的。作者照片。</figcaption></figure><ul class=""><li id="a082" class="lq lr iq jp b jq jr ju jv jy ls kc lt kg lu kk lv lw lx ly bi translated">接下来，对于每张地图，我们必须选择2个不同的位置:起点<em class="lp"/>和目标<em class="lp">【g】</em>。这个选择也是随意的，但是这一次我们必须确保<em class="lp"> s </em>和<em class="lp"> g </em>之间的欧几里德距离大于给定的阈值，以使实例具有挑战性。否则，我们的网络不会从中学到很多东西。</li><li id="f6ba" class="lq lr iq jp b jq lz ju ma jy mb kc mc kg md kk lv lw lx ly bi translated">最后，我们需要找到从<em class="lp"> s </em>到<em class="lp"> g </em>的最短路径。这将是我们训练的基本事实。为此，我使用了流行的D* lite算法。特别是，我编写了一个自定义的实现，它约束解决方案，使其保持至少1个自由单元格不受任何障碍的影响。原因很简单，我正在做一个机器人项目，我们需要这样的修改，因为我们的机器人在遵循原始D* lite轨迹时经常撞到墙上。通过使用利润约束，我们能够克服这个问题。鉴于这个CNN(最初)被认为是用在同一个机器人上，我决定保留我们的自定义实现。</li></ul><p id="1337" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">该数据集包含大约23万个样本(17万个用于训练，5万个用于测试，1万5用于验证)。使用上述过程生成如此大量的数据在我的商品级笔记本电脑上是不可行的。这就是为什么我使用<a class="ae kl" href="https://www.boost.org/doc/libs/1_76_0/libs/python/doc/html/tutorial/index.html" rel="noopener ugc nofollow" target="_blank"> Boost </a> c++库将定制的D* lite实现重写为python扩展模块。我没有基准测试，但是使用扩展模块，我能够生成超过10k个样本/小时，而使用纯python实现，速率大约为1k个样本/小时(在我的旧的但却是金色的英特尔酷睿i7–6500 u，8GB RAM上)。定制的D* lite实现在<a class="ae kl" href="https://github.com/dcaffo98/dstar-lite-cpp" rel="noopener ugc nofollow" target="_blank">这里</a>可用。</p><p id="7e29" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">请注意，有时目标位置看起来像是放在一个障碍物上。在这些情况下，地面实况轨迹以最接近目标的最后可行位置(即，不是障碍的像元，矩阵图中的0)结束。这是与原始D* lite的另一个小差异。</p><p id="1379" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">我对数据做了一些简单的检查，比如删除余弦相似度非常高，起点和目标坐标过于接近的地图。</p><p id="dc48" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">我已经在<a class="ae kl" href="https://www.kaggle.com/datasets/dcaffo/2dpathplanningdataset" rel="noopener ugc nofollow" target="_blank"> kaggle </a>上传了数据集，在那里你也可以找到一个简单的<a class="ae kl" href="https://www.kaggle.com/code/dcaffo/demo-2d-path-planning-dataset" rel="noopener ugc nofollow" target="_blank">笔记本</a>展示如何访问样本。在<a class="ae kl" href="https://github.com/dcaffo98/path-planning-cnn" rel="noopener ugc nofollow" target="_blank"> GitHub </a>存储库中，您还可以找到一个方便的脚本，允许您从头开始构建自己的数据集。</p><h1 id="07fa" class="km kn iq bd ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj bi translated">模型架构</h1><p id="b2aa" class="pw-post-body-paragraph jn jo iq jp b jq lk js jt ju ll jw jx jy lm ka kb kc ln ke kf kg lo ki kj kk ij bi translated">该模型遵循编码器-解码器架构，共有20个卷积层，分为3个卷积块(编码部分)，后面是其他3个转置卷积块(解码部分)。每个块由3个3×3的卷积层组成，每个卷积层之间有批量归一化和ReLU激活。最后，还有其他两个conv层，加上输出层。从高层次的角度来看，编码器的目标是找到输入的压缩但相关的表示。然后，它将被馈送到解码器部分，解码器部分将尝试重建相同的输入图，但这次嵌入的有用信息将有助于找到从<em class="lp"> s </em>到<em class="lp"> g </em>的最佳路径。</p><p id="6812" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">该网络的预期输入为:</p><ul class=""><li id="56d4" class="lq lr iq jp b jq jr ju jv jy ls kc lt kg lu kk lv lw lx ly bi translated"><strong class="jp ir">图</strong>:一个表示占位网格图的[n，3，100，100]张量。此后，<em class="lp"> n </em>为<em class="lp">批量</em>。请注意，通道的数量是3，而不是简单的1。稍后将详细介绍。</li><li id="cceb" class="lq lr iq jp b jq lz ju ma jy mb kc mc kg md kk lv lw lx ly bi translated"><strong class="jp ir"> start </strong>:一个[n，2]张量，包含每个地图中起点<em class="lp"> s </em>的坐标</li><li id="e20c" class="lq lr iq jp b jq lz ju ma jy mb kc mc kg md kk lv lw lx ly bi translated"><strong class="jp ir">目标</strong>:一个[n，2]张量，包含目标点<em class="lp"> g </em>在每个地图中的坐标</li></ul><p id="afde" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">网络的输出层应用了<strong class="jp ir"> sigmoid </strong>函数，有效地提供了一个“得分图”，其中每一项的值都在0到1之间，与属于从<em class="lp"> s </em>到<em class="lp"> g </em>的最短路径的概率成比例。然后，您可以从<em class="lp"> s </em>开始重建路径，并迭代选择当前8邻域中得分最高的点。一旦找到与<em class="lp"> g </em>坐标相同的点，过程终止。为了提高效率，我使用了双向搜索算法。这个想法是受到这篇<a class="ae kl" href="https://www.frontiersin.org/articles/10.3389/fnbot.2020.600984/full" rel="noopener ugc nofollow" target="_blank">论文</a>的启发。</p><figure class="mf mg mh mi gt mj gh gi paragraph-image"><div class="gh gi mu"><img src="../Images/b777a2e970131850f52585d18304177b.png" data-original-src="https://miro.medium.com/v2/resize:fit:240/format:webp/1*CUTsS09aBKeIPP1k24KlXA.png"/></div><figcaption class="mq mr gj gh gi ms mt bd b be z dk translated">sigmoid函数</figcaption></figure><p id="e91b" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">在模型的编码器和解码器模块之间，我插入了两个跳跃连接。这个模型现在真的很像<a class="ae kl" href="https://doi.org/10.48550/arXiv.1505.04597" rel="noopener ugc nofollow" target="_blank"> U-Net </a>的架构(虽然小了很多)。跳过连接将给定隐藏层的输出注入到网络中更深的其他层中。当我们关心重建图像的细节时，就会用到它们(U-Net实际上是为医学图像分割开发的，在医学图像分割中细节是至关重要的)。在我们的任务中，我们关心的细节是<em class="lp"> s </em>、<em class="lp"> g、</em>的准确位置以及我们在轨迹中必须避开的所有障碍物。最初，我没有包括任何跳过连接，但后来我发现这大大提高了训练收敛性和模型的整体结果。</p><figure class="mf mg mh mi gt mj gh gi paragraph-image"><div role="button" tabindex="0" class="mk ml di mm bf mn"><div class="gh gi mv"><img src="../Images/342f2c88bc2f14bea027a44026df8a50.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*lvXoKMHoPJMKpKK7keZMEA.png"/></div></div><figcaption class="mq mr gj gh gi ms mt bd b be z dk translated">来自Olaf Ronneberger等人原始论文的U-Net架构</figcaption></figure><h1 id="5928" class="km kn iq bd ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj bi translated">培养</h1><p id="69ce" class="pw-post-body-paragraph jn jo iq jp b jq lk js jt ju ll jw jx jy lm ka kb kc ln ke kf kg lo ki kj kk ij bi translated">我已经在Google Colab上训练了大约15个小时或23个纪元的模型。采用的损失函数是模型提供的评分图和地面实况(GT)图之间的均方误差(MSE)。后者是通过创建充满零的100×100矩阵，然后在对应于属于用D* lite获得的路径的点的每个位置添加1而获得的。可能有比MSE更好的选择，但我坚持使用它，因为它简单易用。</p><p id="03ef" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated"><em class="lp">学习率</em>最初用<a class="ae kl" href="https://pytorch.org/docs/stable/generated/torch.optim.lr_scheduler.CosineAnnealingWarmRestarts.html" rel="noopener ugc nofollow" target="_blank">CosineAnnealingWithWarmRestart</a>s<em class="lp"/>调度程序设置为0.001(稍作修改，以便在每次重启后降低最大学习率)。批量大小设置为160个样本。</p><p id="5d27" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">至于正则化，我试着将高斯模糊应用于输入贴图，并在第一个卷积层应用一个小的下降。这些技术都没有带来任何相关的效果，所以我最终放弃了它们。</p><figure class="mf mg mh mi gt mj gh gi paragraph-image"><div role="button" tabindex="0" class="mk ml di mm bf mn"><div class="gh gi me"><img src="../Images/992a2d777c6a4c15eeba539a7c3eca4f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*d9mE25jfe0zRcmGQZom2zQ.png"/></div></div><figcaption class="mq mr gj gh gi ms mt bd b be z dk translated">训练后可视化模型原始输出。作者照片。</figcaption></figure><figure class="mf mg mh mi gt mj gh gi paragraph-image"><div role="button" tabindex="0" class="mk ml di mm bf mn"><div class="gh gi me"><img src="../Images/29d0295755245f01ba9b5218250d6716.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*OW2YN_DDoFJBRhWbVvbq9Q.png"/></div></div></figure><figure class="mf mg mh mi gt mj gh gi paragraph-image"><div role="button" tabindex="0" class="mk ml di mm bf mn"><div class="gh gi me"><img src="../Images/b850d65e13b7e74d086dfa2377512300.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*OlYo5rJVwXzsRLS1tJdMCA.png"/></div></div></figure><h1 id="a0ce" class="km kn iq bd ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj bi translated">卷积的问题是</h1><p id="bedd" class="pw-post-body-paragraph jn jo iq jp b jq lk js jt ju ll jw jx jy lm ka kb kc ln ke kf kg lo ki kj kk ij bi translated">首先，我按照原样使用占用网格地图来填充模型。也就是说，输入是一个形状为[n，1，100，100]的张量(加上起始和目标位置)。在这种设置下，我无法获得任何令人满意的结果。损失几乎立即停止下降。因此，重建的路径只是完全偏离目标位置并穿过障碍物的随机轨迹。</p><p id="f623" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">卷积算子的一个关键特征是它具有<strong class="jp ir">位置不变性</strong>。卷积滤波器学习的实际上是一种特定的像素模式，这种模式在它被训练的数据分布中是重复出现的。例如，图案可以表示拐角或垂直边缘。</p><figure class="mf mg mh mi gt mj gh gi paragraph-image"><div role="button" tabindex="0" class="mk ml di mm bf mn"><div class="gh gi me"><img src="../Images/e19dcbe4f180829deea308328afc4c93.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*SRtxWF_AtgMqzf85h3uNsw.png"/></div></div><figcaption class="mq mr gj gh gi ms mt bd b be z dk translated">训练后的第一层过滤器。作者照片。</figcaption></figure><p id="8457" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">无论过滤器学习什么模式，关键是它学习独立于它在图像中的位置来识别它。对于像图像分类这样的任务来说，这无疑是一个理想的特性，在图像分类中，表征目标类别的模式可以出现在图像中的任何位置。但是在我们的情况下，<strong class="jp ir">的地位是至关重要的！</strong>我们需要网络非常清楚预期轨迹的起点和终点。</p><h1 id="97da" class="km kn iq bd ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj bi translated">救援的位置编码</h1><p id="93f8" class="pw-post-body-paragraph jn jo iq jp b jq lk js jt ju ll jw jx jy lm ka kb kc ln ke kf kg lo ki kj kk ij bi translated">位置编码是一种通过嵌入(通常通过简单的求和)数据本身来注入数据位置信息的技术。它通常应用于自然语言处理(NLP)中，以使模型意识到单词在句子中的位置。我想类似的东西对我们的任务也会有帮助。</p><p id="a6e5" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">经典的位置编码(参见论文<a class="ae kl" href="https://doi.org/10.48550/arXiv.1706.03762" rel="noopener ugc nofollow" target="_blank">注意是你所需要的全部</a>)利用一系列正弦曲线对每个位置进行编码。</p><figure class="mf mg mh mi gt mj gh gi paragraph-image"><div class="gh gi mw"><img src="../Images/71978e73f5a982ae5b316c82cbb4cd45.png" data-original-src="https://miro.medium.com/v2/resize:fit:778/format:webp/1*R-G8V-161lCZZG5C7x3vaw.png"/></div><figcaption class="mq mr gj gh gi ms mt bd b be z dk translated">经典位置编码。作者照片。</figcaption></figure><p id="20ce" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">我做了一些实验，将这样的位置编码添加到输入占用地图中，但是效果并没有更好。可能是因为通过添加关于地图上每个可能位置的信息，我们违背了卷积滤波器的位置不变性。之前提出的滤波器现在没有用了，因为它们的权重应该被调整以考虑输入图像上的每个可能的不同位置。当然，这是不可行的。</p><p id="7ce4" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">我的想法是基于对路径规划的观察，我们对绝对 项中的位置并不真正感兴趣，而只对相对<strong class="jp ir"><em class="lp"/></strong>范围中的位置感兴趣。具体来说，我们感兴趣的是占用图中每个单元相对于起始点<em class="lp"> s </em>和目标点<em class="lp"> g </em>的位置。例如，取一个坐标为<em class="lp"> (x，y) </em>的单元格。我并不真的关心知道<em class="lp"> (x，y) </em>是否等于(45，89)而不是(0，5)。知道<em class="lp"> (x，y) </em>距离<em class="lp">s</em>34个单元格，距离<em class="lp">g</em>15个单元格应该更有用。</p><p id="f563" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">我所做的是为现在形状为[3，100，100]的每个占用网格图创建2个额外的通道(不考虑批量大小)。第一个频道是香草地图，和以前一样。第二个通道表示位置编码，它为每个像素分配一个相对于起始位置的值。第三个也是同样的情况，但是这次使用的是位置。这种编码是通过从分别以<em class="lp"> s </em>和<em class="lp"> g，</em>为中心的2d高斯函数创建2个特征图来进行的。适马被选为内核大小的五分之一(通常在高斯滤波器中)。在我们的例子中，sigma是20，因为内核大小等于图的边长，即100。</p><figure class="mf mg mh mi gt mj gh gi paragraph-image"><div class="gh gi mx"><img src="../Images/4a4fdbe61ab56cc79705c38712c47f17.png" data-original-src="https://miro.medium.com/v2/resize:fit:458/format:webp/1*K1eltgRFXYHa-DXoddTFkQ.png"/></div><figcaption class="mq mr gj gh gi ms mt bd b be z dk translated">2D高斯函数</figcaption></figure><p id="b0e3" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">这一次，在注入关于我们的轨迹的期望开始和最终位置的有用信息的同时，我们部分地恢复了与我们的过滤器的位置不变性的一致性。可学习的模式现在只依赖于相对于给定点的距离，而不是地图上每个可能的位置。距离<em class="lp"> s </em>或<em class="lp"> g </em>相同距离的2个相同图案现在将导致过滤器的相同激活。我发现这个小技巧在训练的衔接上非常有效。</p><figure class="mf mg mh mi gt mj gh gi paragraph-image"><div role="button" tabindex="0" class="mk ml di mm bf mn"><div class="gh gi me"><img src="../Images/c3fa6f0c774c11d3387ca8ad277e1509.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*lCzALbaiXdf6pqqiyymSRQ.png"/></div></div><figcaption class="mq mr gj gh gi ms mt bd b be z dk translated">一些样本的高斯位置编码示例。作者照片。</figcaption></figure><h1 id="a725" class="km kn iq bd ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj bi translated">结果和结论</h1><p id="acba" class="pw-post-body-paragraph jn jo iq jp b jq lk js jt ju ll jw jx jy lm ka kb kc ln ke kf kg lo ki kj kk ij bi translated">我已经在51103个样本上测试了训练好的模型。</p><ul class=""><li id="b17a" class="lq lr iq jp b jq jr ju jv jy ls kc lt kg lu kk lv lw lx ly bi translated">95%的测试样本能够使用双向搜索提供解决方案。也就是说，该算法使用模型给出的得分图，设法在48556个样本中找到了从<em class="lp"> s </em>到<em class="lp"> g </em>的路径，而它无法对剩余的2547个样本这样做。</li><li id="05ab" class="lq lr iq jp b jq lz ju ma jy mb kc mc kg md kk lv lw lx ly bi translated">87%的测试样本提供了有效的解决方案。即从<em class="lp"> s </em>到<em class="lp"> g </em>不穿越任何障碍物的轨迹(该值不考虑1个单元格的障碍物余量约束)。</li><li id="c474" class="lq lr iq jp b jq lz ju ma jy mb kc mc kg md kk lv lw lx ly bi translated">在有效样本上，地面真实路径和模型提供的解决方案之间的平均误差是33个单元。考虑到地图是100x100个单元，这已经很高了。误差范围从最小值0(即，在2491个样本中发现的地面真实路径的“完美”重建)到最大值…745个单元(好吧，这个模型肯定不会取代特斯拉的自动驾驶仪)</li></ul><p id="e4f3" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">马上，你会发现测试集的一些结果。图像的左侧描绘了由经过训练的网络提供的解决方案，而右侧显示了D* lite算法的解决方案。</p><figure class="mf mg mh mi gt mj gh gi paragraph-image"><div role="button" tabindex="0" class="mk ml di mm bf mn"><div class="gh gi my"><img src="../Images/66e5c1954b8c33c98c185a4b12146d7f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*HoJhbCt7j-9Sa3vihIrVTw.png"/></div></div></figure><div class="mf mg mh mi gt ab cb"><figure class="mz mj na nb nc nd ne paragraph-image"><div role="button" tabindex="0" class="mk ml di mm bf mn"><img src="../Images/73bb0abc5335526f12c05d69549fbd9c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1000/format:webp/1*6PMi-2dh6VjGaKiHNPveQg.png"/></div></figure><figure class="mz mj na nb nc nd ne paragraph-image"><div role="button" tabindex="0" class="mk ml di mm bf mn"><img src="../Images/2da640736424447a5c72bd8073be8bbd.png" data-original-src="https://miro.medium.com/v2/resize:fit:1000/format:webp/1*TZTZtQCXSNx-vJwmBJ26-w.png"/></div></figure></div><figure class="mf mg mh mi gt mj gh gi paragraph-image"><div role="button" tabindex="0" class="mk ml di mm bf mn"><div class="gh gi my"><img src="../Images/2b021203ba57eb9bf6f91a3693aa1266.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*uxhlju4etVCNkGSyR7xjnQ.png"/></div></div><figcaption class="mq mr gj gh gi ms mt bd b be z dk translated">网络提供的解决方案比D* lite给出的解决方案更短，但它至少在一点上违反了边界约束</figcaption></figure><figure class="mf mg mh mi gt mj gh gi paragraph-image"><div role="button" tabindex="0" class="mk ml di mm bf mn"><div class="gh gi my"><img src="../Images/3ccf2ea156375d92bf6b0d3793135390.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*SEM1MnOCKtNehLEmasvjKA.png"/></div></div></figure><div class="mf mg mh mi gt ab cb"><figure class="mz mj na nb nc nd ne paragraph-image"><div role="button" tabindex="0" class="mk ml di mm bf mn"><img src="../Images/ded43c1a2f435f7c53fd2470f5a390fc.png" data-original-src="https://miro.medium.com/v2/resize:fit:1000/format:webp/1*eGobTR7JsYHipcTZUJU_Bg.png"/></div></figure><figure class="mz mj na nb nc nd ne paragraph-image"><div role="button" tabindex="0" class="mk ml di mm bf mn"><img src="../Images/0d837407de98b8a964ffaa9358402673.png" data-original-src="https://miro.medium.com/v2/resize:fit:1000/format:webp/1*--ZxPodfsfwjUR7UhffpTQ.png"/></div></figure></div><div class="ab cb"><figure class="mz mj na nb nc nd ne paragraph-image"><div role="button" tabindex="0" class="mk ml di mm bf mn"><img src="../Images/18d6d0464453b26c3b8546f103457c66.png" data-original-src="https://miro.medium.com/v2/resize:fit:1000/format:webp/1*8r30o3ifl1BmdZpPhKqM1w.png"/></div></figure><figure class="mz mj na nb nc nd ne paragraph-image"><div role="button" tabindex="0" class="mk ml di mm bf mn"><img src="../Images/cab2eb99d1d0e5853569c18b852d9fde.png" data-original-src="https://miro.medium.com/v2/resize:fit:1000/format:webp/1*ENvGhzq0oUjrYIxX-2BeMA.png"/></div></figure></div><figure class="mf mg mh mi gt mj gh gi paragraph-image"><div role="button" tabindex="0" class="mk ml di mm bf mn"><div class="gh gi my"><img src="../Images/6b205f3070d1619e1aa5614d40992ecc.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Lpm7aDjlIe-0fcqkETuD1A.png"/></div></div></figure><div class="mf mg mh mi gt ab cb"><figure class="mz mj na nb nc nd ne paragraph-image"><div role="button" tabindex="0" class="mk ml di mm bf mn"><img src="../Images/be5c8f13fcdb0ceff90dbb0de028fd29.png" data-original-src="https://miro.medium.com/v2/resize:fit:1000/format:webp/1*jUGGAkea-ojKxPrJwyzDyA.png"/></div></figure><figure class="mz mj na nb nc nd ne paragraph-image"><div role="button" tabindex="0" class="mk ml di mm bf mn"><img src="../Images/e31f67de0cad36872d6111217eef21a5.png" data-original-src="https://miro.medium.com/v2/resize:fit:1000/format:webp/1*adTgiNdSZjJNBo2BiF04tg.png"/></div></figure></div><figure class="mf mg mh mi gt mj gh gi paragraph-image"><div role="button" tabindex="0" class="mk ml di mm bf mn"><div class="gh gi my"><img src="../Images/354f1eefe1b9d81769caf839cd013516.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*TSn-jMmNQgKMeE2xvmQQUg.png"/></div></div></figure><div class="mf mg mh mi gt ab cb"><figure class="mz mj na nb nc nd ne paragraph-image"><div role="button" tabindex="0" class="mk ml di mm bf mn"><img src="../Images/a5676b19b87ff9abf78baec30859db43.png" data-original-src="https://miro.medium.com/v2/resize:fit:1000/format:webp/1*rnT3RuyMYGM1I-jb4gTIFw.png"/></div></figure><figure class="mz mj na nb nc nd ne paragraph-image"><div role="button" tabindex="0" class="mk ml di mm bf mn"><img src="../Images/c76f5b9f6c28cd9e131905e4ce78ab68.png" data-original-src="https://miro.medium.com/v2/resize:fit:1000/format:webp/1*e0QYFMWl5FBy9sG1v5QwaQ.png"/></div></figure></div><figure class="mf mg mh mi gt mj gh gi paragraph-image"><div role="button" tabindex="0" class="mk ml di mm bf mn"><div class="gh gi my"><img src="../Images/141adc804633dae9e06d8214c2b6a72e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*s_EBN_bki1klqGeMbG83Hw.png"/></div></div><figcaption class="mq mr gj gh gi ms mt bd b be z dk translated">就是误差最大的那个:(</figcaption></figure><div class="mf mg mh mi gt ab cb"><figure class="mz mj na nb nc nd ne paragraph-image"><div role="button" tabindex="0" class="mk ml di mm bf mn"><img src="../Images/cf10eac62e14252acd42a718eae74793.png" data-original-src="https://miro.medium.com/v2/resize:fit:1000/format:webp/1*dSYWWRJIf_YcxWixpG7u0g.png"/></div></figure><figure class="mz mj na nb nc nd ne paragraph-image"><div role="button" tabindex="0" class="mk ml di mm bf mn"><img src="../Images/295b876883ba38b1776018c08e736b3c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1000/format:webp/1*Eqjb01ZGL5H6M0S3i1Qchg.png"/></div></figure></div><div class="ab cb"><figure class="mz mj na nb nc nd ne paragraph-image"><div role="button" tabindex="0" class="mk ml di mm bf mn"><img src="../Images/8b8db2783739b93817eabf34c1a9a730.png" data-original-src="https://miro.medium.com/v2/resize:fit:1000/format:webp/1*QPue3v6TPOvsBqmgNkW0aA.png"/></div></figure><figure class="mz mj na nb nc nd ne paragraph-image"><div role="button" tabindex="0" class="mk ml di mm bf mn"><img src="../Images/79e333ab320487cf27a683f52e75a97a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1000/format:webp/1*lI5nHylbrjRllgDJmLyyGQ.png"/></div><figcaption class="mq mr gj gh gi ms mt bd b be z dk nf di ng nh translated">作者照片。</figcaption></figure></div><p id="04b8" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">如果你已经做到这一步，让我感谢你的时间。正如你所看到的，这项工作离最先进的成果还很远，但是我在编码的时候得到了一些乐趣，我希望你也喜欢它。</p></div></div>    
</body>
</html>