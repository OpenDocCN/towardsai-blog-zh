<html>
<head>
<title>Synopsis: Multi-Attributed and Structured Text-to-Face Synthesis</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">概要:多属性和结构化的文本-人脸合成</h1>
<blockquote>原文：<a href="https://pub.towardsai.net/synopsis-multi-attributed-and-structured-text-to-face-synthesis-ec3755166ad0?source=collection_archive---------2-----------------------#2022-02-16">https://pub.towardsai.net/synopsis-multi-attributed-and-structured-text-to-face-synthesis-ec3755166ad0?source=collection_archive---------2-----------------------#2022-02-16</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><h2 id="e438" class="io ip iq bd b dl ir is it iu iv iw dk ix translated" aria-label="kicker paragraph"><a class="ae ep" href="https://rohanwadhawan.medium.com/byte-size-information-to-chew-on-ca1d02a9a5c1" rel="noopener">要咀嚼的字节大小的信息</a></h2><div class=""/><p id="3c95" class="pw-post-body-paragraph jw jx iq jy b jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ij bi translated"><strong class="jy ja">题目:</strong>多属性结构化文本人脸合成(2020)</p><p id="0c54" class="pw-post-body-paragraph jw jx iq jy b jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ij bi translated"><strong class="jy ja">作者:</strong> Rohan Wadhawan，Tanuj Drall，Shubham Singh，Shampa Chakraverty</p><p id="988c" class="pw-post-body-paragraph jw jx iq jy b jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ij bi translated"><strong class="jy ja">发布链接:</strong><a class="ae ku" href="https://ieeexplore.ieee.org/abstract/document/9557583" rel="noopener ugc nofollow" target="_blank">https://ieeexplore.ieee.org/abstract/document/9557583</a></p><p id="2c09" class="pw-post-body-paragraph jw jx iq jy b jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ij bi translated"><strong class="jy ja">预印链接:</strong><a class="ae ku" href="https://arxiv.org/abs/2108.11100" rel="noopener ugc nofollow" target="_blank">https://arxiv.org/abs/2108.11100</a></p><p id="0c07" class="pw-post-body-paragraph jw jx iq jy b jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ij bi translated"><strong class="jy ja">关键词:</strong>生成对抗网络，图像合成，文本到人脸合成，MAST数据集，多模态学习，弗雷歇初始距离</p><h1 id="199e" class="kv kw iq bd kx ky kz la lb lc ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls bi translated">摘要</h1><p id="f806" class="pw-post-body-paragraph jw jx iq jy b jz lt kb kc kd lu kf kg kh lv kj kk kl lw kn ko kp lx kr ks kt ij bi translated">这篇文章的结构如下:</p><ul class=""><li id="ada5" class="ly lz iq jy b jz ka kd ke kh ma kl mb kp mc kt md me mf mg bi translated"><a class="ae ku" href="#51ac" rel="noopener ugc nofollow">问题陈述</a></li><li id="746a" class="ly lz iq jy b jz mh kd mi kh mj kl mk kp ml kt md me mf mg bi translated"><a class="ae ku" href="#6a7e" rel="noopener ugc nofollow">论文投稿</a></li><li id="756e" class="ly lz iq jy b jz mh kd mi kh mj kl mk kp ml kt md me mf mg bi translated"><a class="ae ku" href="#f323" rel="noopener ugc nofollow">方法论概述</a></li><li id="8c4a" class="ly lz iq jy b jz mh kd mi kh mj kl mk kp ml kt md me mf mg bi translated"><a class="ae ku" href="#6cf8" rel="noopener ugc nofollow">结论</a></li><li id="850a" class="ly lz iq jy b jz mh kd mi kh mj kl mk kp ml kt md me mf mg bi translated"><a class="ae ku" href="#3b57" rel="noopener ugc nofollow">限制</a></li><li id="0c97" class="ly lz iq jy b jz mh kd mi kh mj kl mk kp ml kt md me mf mg bi translated"><a class="ae ku" href="#54a6" rel="noopener ugc nofollow">未来工作</a></li><li id="b050" class="ly lz iq jy b jz mh kd mi kh mj kl mk kp ml kt md me mf mg bi translated"><a class="ae ku" href="#ffbd" rel="noopener ugc nofollow">应用</a></li><li id="61bb" class="ly lz iq jy b jz mh kd mi kh mj kl mk kp ml kt md me mf mg bi translated"><a class="ae ku" href="#ff26" rel="noopener ugc nofollow">参考文献</a></li><li id="2a68" class="ly lz iq jy b jz mh kd mi kh mj kl mk kp ml kt md me mf mg bi translated"><a class="ae ku" href="#9721" rel="noopener ugc nofollow">附加资源</a></li></ul><p id="be2d" class="pw-post-body-paragraph jw jx iq jy b jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ij bi translated">对生成对抗网络(GAN) [ <a class="ae ku" href="https://arxiv.org/abs/1406.2661" rel="noopener ugc nofollow" target="_blank"> 1 </a> ]和图像合成等主题的详细分析超出了本文的范围。但我提供了相关资源的链接，在阅读论文时会派上用场。此外，这里分享的可视化是取自原始手稿。</p><h2 id="51ac" class="mm kw iq bd kx mn mo dn lb mp mq dp lf kh mr ms lj kl mt mu ln kp mv mw lr iw bi translated"><strong class="ak">问题陈述</strong></h2><p id="c19c" class="pw-post-body-paragraph jw jx iq jy b jz lt kb kc kd lu kf kg kh lv kj kk kl lw kn ko kp lx kr ks kt ij bi translated">开发一种使用文本描述作为输入来生成高保真度和多样性的人脸的技术。</p><h2 id="6a7e" class="mm kw iq bd kx mn mo dn lb mp mq dp lf kh mr ms lj kl mt mu ln kp mv mw lr iw bi translated"><strong class="ak">论文投稿</strong></h2><ul class=""><li id="5285" class="ly lz iq jy b jz lt kd lu kh mx kl my kp mz kt md me mf mg bi translated">提出使用生成对抗网络从结构化文本描述中合成人脸。</li><li id="b3e2" class="ly lz iq jy b jz mh kd mi kh mj kl mk kp ml kt md me mf mg bi translated">证明了在文本注释中增加面部属性的数量增强了生成的面部的多样性和保真度。</li><li id="55e4" class="ly lz iq jy b jz mh kd mi kh mj kl mk kp ml kt md me mf mg bi translated">通过用文本注释补充取自CelebA-HQ [ <a class="ae ku" href="https://arxiv.org/abs/1710.10196" rel="noopener ugc nofollow" target="_blank"> 3 </a> ]数据集的<strong class="jy ja"> 1993张人脸图像</strong>，合并了一个<strong class="jy ja">多属性和结构化的文本到人脸(MAST)[</strong><a class="ae ku" href="https://zenodo.org/record/3865238" rel="noopener ugc nofollow" target="_blank"><strong class="jy ja">2</strong></a><strong class="jy ja">]数据集</strong>。</li></ul><h2 id="f323" class="mm kw iq bd kx mn mo dn lb mp mq dp lf kh mr ms lj kl mt mu ln kp mv mw lr iw bi translated">方法概述</h2><ul class=""><li id="d286" class="ly lz iq jy b jz lt kd lu kh mx kl my kp mz kt md me mf mg bi translated">MAST数据集中的每个注释由可能的30个属性中的15个或更多个面部属性组成。其中，以下七项:脸型、眉毛大小、眉毛形状、眼睛颜色、眼睛大小、眼睛形状、皮肤肤色是通过作者进行的数据众包获得的[ <a class="ae ku" href="http://face-descriptions.herokuapp.com/" rel="noopener ugc nofollow" target="_blank"> 4 </a> ]。此外，从CelebA-HQ和微软API [ <a class="ae ku" href="https://azure.microsoft.com/en-in/services/cognitive-services/face/#overview" rel="noopener ugc nofollow" target="_blank"> 5 </a> ]中提取了八个或更多属性，如胡须、年龄、性别和配饰，总共有23种可能性。</li><li id="c3d8" class="ly lz iq jy b jz mh kd mi kh mj kl mk kp ml kt md me mf mg bi translated">结构化的文本描述只包括面部特征，没有标点符号、介词和助动词。作者通过随机连接这些属性来模拟经过处理的自由流动的文本，为每幅图像生成五个描述，如下所示。</li></ul><pre class="na nb nc nd gt ne nf ng nh aw ni bi"><span id="ebac" class="mm kw iq nf b gy nj nk l nl nm"><strong class="nf ja">Free flowing description - <br/></strong>An old man with gray hair and blue eyes. He is smiling</span><span id="2dd5" class="mm kw iq nf b gy nn nk l nl nm"><strong class="nf ja">Processed description that resembles description in MAST dataset -      <br/></strong>old man gray hair blue eyes smiling</span></pre><ul class=""><li id="64ae" class="ly lz iq jy b jz ka kd ke kh ma kl mb kp mc kt md me mf mg bi translated">AttnGan [ <a class="ae ku" href="https://arxiv.org/abs/1711.10485" rel="noopener ugc nofollow" target="_blank"> 6 </a> ]已经被用于从结构化文本数据中有条件地生成人脸。作者用嵌入层中的手套向量[ <a class="ae ku" href="https://nlp.stanford.edu/projects/glove/" rel="noopener ugc nofollow" target="_blank"> 7 </a> ]替换了原始技术中使用的预训练文本编码器。这些向量覆盖了大量的词汇，并呈现单词之间的语义关系。GAN架构如下所示。</li></ul><figure class="na nb nc nd gt np gh gi paragraph-image"><div role="button" tabindex="0" class="nq nr di ns bf nt"><div class="gh gi no"><img src="../Images/356e49ffeebe9a3bb44de5c08ab884ff.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*UQ1cGVhvtZLw_bv5Srau7w.png"/></div></div><figcaption class="nw nx gj gh gi ny nz bd b be z dk translated">具有手套文本嵌入的AttnGAN架构</figcaption></figure><ul class=""><li id="5d91" class="ly lz iq jy b jz ka kd ke kh ma kl mb kp mc kt md me mf mg bi translated">手套嵌入也有助于从嵌入空间中的词簇中采样看不见的属性值。例如，根据年龄属性值(如“老年人”和“老年”)训练的模型将能够理解新的类似值(如“成熟”)，如下所示。</li></ul><figure class="na nb nc nd gt np gh gi paragraph-image"><div role="button" tabindex="0" class="nq nr di ns bf nt"><div class="gh gi oa"><img src="../Images/22ac1428fb0d7f71476f6c74ce62a5c5.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*zwqX_y7PRvVMzmd6mfdnSQ.png"/></div></div><figcaption class="nw nx gj gh gi ny nz bd b be z dk translated">在手套嵌入空间中，具有相似含义的单词聚集在一起</figcaption></figure><ul class=""><li id="3902" class="ly lz iq jy b jz ka kd ke kh ma kl mb kp mc kt md me mf mg bi translated">在GAN训练过程中，鉴别器的单侧标号平滑[ <a class="ae ku" href="https://arxiv.org/abs/1606.03498" rel="noopener ugc nofollow" target="_blank"> 8 </a> ]和交替历元权重更新被用来解决由于鉴别器学习快于生成器而导致的梯度递减问题。</li><li id="2ed1" class="ly lz iq jy b jz mh kd mi kh mj kl mk kp ml kt md me mf mg bi translated">弗雷歇初始距离(FID) [ <a class="ae ku" href="https://arxiv.org/abs/1706.08500" rel="noopener ugc nofollow" target="_blank"> 9 </a> ]用于衡量生成人脸的质量，人脸语义距离(FSD)和人脸语义相似度(FSS) [ <a class="ae ku" href="https://arxiv.org/abs/1904.05729" rel="noopener ugc nofollow" target="_blank"> 10 </a> ]用于衡量生成人脸与真实人脸的相似度。</li></ul><h2 id="6cf8" class="mm kw iq bd kx mn mo dn lb mp mq dp lf kh mr ms lj kl mt mu ln kp mv mw lr iw bi translated"><strong class="ak">结论</strong></h2><ul class=""><li id="d507" class="ly lz iq jy b jz lt kd lu kh mx kl my kp mz kt md me mf mg bi translated">作者根据经验证明并说明了在文本描述中增加面部属性的数量，在可能的30个属性中增加15个或更多，有助于提高使用该文本生成的面部的保真度和多样性。</li></ul><div class="na nb nc nd gt ab cb"><figure class="ob np oc od oe of og paragraph-image"><div role="button" tabindex="0" class="nq nr di ns bf nt"><img src="../Images/66da7fac675e66eab6082b7b49924b9b.png" data-original-src="https://miro.medium.com/v2/resize:fit:662/format:webp/1*KyYB29DgqTgsUwwYUeBt3w.png"/></div></figure><figure class="ob np oh od oe of og paragraph-image"><div role="button" tabindex="0" class="nq nr di ns bf nt"><img src="../Images/107dc6832121f5520af1dae0cc1e51ae.png" data-original-src="https://miro.medium.com/v2/resize:fit:664/format:webp/1*YS00oH3JQ2DhhUwksdgZCQ.png"/></div></figure><figure class="ob np oi od oe of og paragraph-image"><div role="button" tabindex="0" class="nq nr di ns bf nt"><img src="../Images/7c90f258993f490020b1602707ea3561.png" data-original-src="https://miro.medium.com/v2/resize:fit:678/format:webp/1*adfOLAx9WdN0arXMzl0vhw.png"/></div><figcaption class="nw nx gj gh gi ny nz bd b be z dk oj di ok ol translated">从文本生成的面孔</figcaption></figure></div><ul class=""><li id="ed92" class="ly lz iq jy b jz ka kd ke kh ma kl mb kp mc kt md me mf mg bi translated">他们证明FID度量计算取决于数据集的大小，建议使用大型测试集来报告准确的值。</li></ul><figure class="na nb nc nd gt np gh gi paragraph-image"><div class="gh gi om"><img src="../Images/fb3e24d488ad61d68c6610c8ca47a608.png" data-original-src="https://miro.medium.com/v2/resize:fit:1032/format:webp/1*YnD5h4D33XqAqoRqVUNHlg.png"/></div></figure><h2 id="5b07" class="mm kw iq bd kx mn mo dn lb mp mq dp lf kh mr ms lj kl mt mu ln kp mv mw lr iw bi translated">限制</h2><p id="83d6" class="pw-post-body-paragraph jw jx iq jy b jz lt kb kc kd lu kf kg kh lv kj kk kl lw kn ko kp lx kr ks kt ij bi translated">GAN网络学习将文本属性与训练集中的人脸图像相关联。较小的训练集可能是潜在偏差的来源，并限制了模型可以生成的面部的多样性。</p><h2 id="54a6" class="mm kw iq bd kx mn mo dn lb mp mq dp lf kh mr ms lj kl mt mu ln kp mv mw lr iw bi translated"><strong class="ak">未来工作</strong></h2><ul class=""><li id="3b9c" class="ly lz iq jy b jz lt kd lu kh mx kl my kp mz kt md me mf mg bi translated">用于文本-人脸合成的新型GAN结构。</li><li id="ccee" class="ly lz iq jy b jz mh kd mi kh mj kl mk kp ml kt md me mf mg bi translated">直接测量跨模态生成的指标。</li><li id="7dcf" class="ly lz iq jy b jz mh kd mi kh mj kl mk kp ml kt md me mf mg bi translated">更大和更多样化的数据集，以进一步改善人脸生成。</li></ul><h2 id="ffbd" class="mm kw iq bd kx mn mo dn lb mp mq dp lf kh mr ms lj kl mt mu ln kp mv mw lr iw bi translated"><strong class="ak">应用</strong></h2><ul class=""><li id="91d6" class="ly lz iq jy b jz lt kd lu kh mx kl my kp mz kt md me mf mg bi translated">根据目击证人的描述，对嫌疑人进行可靠而详细的面部生成。</li><li id="d4a4" class="ly lz iq jy b jz mh kd mi kh mj kl mk kp ml kt md me mf mg bi translated">用视觉提示增强阅读体验。</li></ul><h2 id="ff26" class="mm kw iq bd kx mn mo dn lb mp mq dp lf kh mr ms lj kl mt mu ln kp mv mw lr iw bi translated"><strong class="ak">参考文献</strong></h2><ol class=""><li id="55c5" class="ly lz iq jy b jz lt kd lu kh mx kl my kp mz kt on me mf mg bi translated">I. Goodfellow，J. Pouget-Abadie，M. Mirza，B. Xu，D. Warde-Farley，S. Ozair，a .，Y. Bengio，“<a class="ae ku" href="https://arxiv.org/abs/1406.2661" rel="noopener ugc nofollow" target="_blank">生成对抗网络</a>”，载于《神经信息处理系统进展》，2014年，第2672-2680页。</li><li id="1c3e" class="ly lz iq jy b jz mh kd mi kh mj kl mk kp ml kt on me mf mg bi translated"><a class="ae ku" href="https://zenodo.org/record/3865238" rel="noopener ugc nofollow" target="_blank">主数据集</a></li><li id="00a5" class="ly lz iq jy b jz mh kd mi kh mj kl mk kp ml kt on me mf mg bi translated">T.Karras、T. Aila、S. Laine和J. Lehtinen，“<a class="ae ku" href="https://arxiv.org/abs/1710.10196" rel="noopener ugc nofollow" target="_blank">为提高质量、稳定性和变化而进行的gans渐进种植</a>，”arXiv预印本arXiv:1710.10196，2017年。</li><li id="37a8" class="ly lz iq jy b jz mh kd mi kh mj kl mk kp ml kt on me mf mg bi translated"><a class="ae ku" href="http://face-descriptions.herokuapp.com/" rel="noopener ugc nofollow" target="_blank">主数据集众包网站</a></li><li id="22d9" class="ly lz iq jy b jz mh kd mi kh mj kl mk kp ml kt on me mf mg bi translated"><a class="ae ku" href="https://azure.microsoft.com/en-in/services/cognitive-services/face/#overview" rel="noopener ugc nofollow" target="_blank">微软Azure Face API </a></li><li id="2fbb" class="ly lz iq jy b jz mh kd mi kh mj kl mk kp ml kt on me mf mg bi translated">T.Xu，P. Zhang，Q. Huang，H. Zhang，Z. Gan，X. Huang和X. He，“att ngan:<a class="ae ku" href="https://arxiv.org/abs/1711.10485" rel="noopener ugc nofollow" target="_blank">利用注意生成对抗网络进行细粒度文本到图像的生成</a>，”IEEE计算机视觉和模式识别会议论文集，2018年，第1316-1324页。</li><li id="f34d" class="ly lz iq jy b jz mh kd mi kh mj kl mk kp ml kt on me mf mg bi translated"><a class="ae ku" href="https://nlp.stanford.edu/projects/glove/" rel="noopener ugc nofollow" target="_blank">手套:单词表示的全局向量</a></li><li id="55f1" class="ly lz iq jy b jz mh kd mi kh mj kl mk kp ml kt on me mf mg bi translated">T.Salimans，I. Goodfellow，W. Zaremba，V. Cheung，a .，X. Chen，“<a class="ae ku" href="https://arxiv.org/abs/1606.03498" rel="noopener ugc nofollow" target="_blank">训练gans </a>的改进技术”，《神经信息处理系统进展》，第29卷，第2234–2242页，2016年。</li><li id="77df" class="ly lz iq jy b jz mh kd mi kh mj kl mk kp ml kt on me mf mg bi translated">米（meter的缩写））Heusel，H. Ramsauer，T. Unterthiner，B. Nessler和S. Hochreiter，“通过双时标更新规则训练的<a class="ae ku" href="https://arxiv.org/abs/1706.08500" rel="noopener ugc nofollow" target="_blank"> Gans收敛到局部纳什均衡</a>”,载于《神经信息处理系统进展》，2017年，第6626–6637页。</li><li id="fdd3" class="ly lz iq jy b jz mh kd mi kh mj kl mk kp ml kt on me mf mg bi translated">X.陈，L. Qing，X. He，X. Luo，和Y. Xu，<a class="ae ku" href="https://arxiv.org/abs/1904.05729" rel="noopener ugc nofollow" target="_blank"> Ftgan:一个用于面向文本生成的完全训练的生成对抗网络</a>，arXiv预印本arXiv:1904.05729，2019。</li></ol><h2 id="9721" class="mm kw iq bd kx mn mo dn lb mp mq dp lf kh mr ms lj kl mt mu ln kp mv mw lr iw bi translated">额外资源</h2><ul class=""><li id="b1b5" class="ly lz iq jy b jz lt kd lu kh mx kl my kp mz kt md me mf mg bi translated"><a class="ae ku" href="https://www.youtube.com/watch?v=9JpdAg6uMXs" rel="noopener ugc nofollow" target="_blank">Ian good fellow介绍GANs，NIPS 2016</a></li><li id="a146" class="ly lz iq jy b jz mh kd mi kh mj kl mk kp ml kt md me mf mg bi translated"><a class="ae ku" href="https://github.com/rohan598/Researsh-Papers-Artificial-Intelligence" rel="noopener ugc nofollow" target="_blank">https://github . com/rohan 598/research sh-Papers-Artificial-Intelligence</a></li><li id="6ae2" class="ly lz iq jy b jz mh kd mi kh mj kl mk kp ml kt md me mf mg bi translated"><a class="ae ku" href="https://www.coursera.org/specializations/generative-adversarial-networks-gans" rel="noopener ugc nofollow" target="_blank">Coursera-GANs专业化在线学习资源</a></li></ul></div><div class="ab cl oo op hu oq" role="separator"><span class="or bw bk os ot ou"/><span class="or bw bk os ot ou"/><span class="or bw bk os ot"/></div><div class="ij ik il im in"><p id="c97d" class="pw-post-body-paragraph jw jx iq jy b jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ij bi translated"><em class="ov">感谢您阅读本文！如果你觉得这篇文章增加了你的知识，请点击拍手图标来表达你的感激，并与你认为可能从中受益的人分享。如果您有任何问题或发现可能出现的错误，请在下面留下评论。</em></p><p id="707d" class="pw-post-body-paragraph jw jx iq jy b jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ij bi translated"><a class="ae ku" href="https://medium.com/@rohanwadhawan" rel="noopener"> <em class="ov">跟随我</em> </a> <em class="ov">在我开发AI研究心智地图的旅程中及其影响，在</em><a class="ae ku" href="https://www.rohanwadhawan.com/" rel="noopener ugc nofollow" target="_blank"><em class="ov">【www.rohanwadhawan.com】</em></a><em class="ov">了解我更多，在</em><a class="ae ku" href="https://www.linkedin.com/in/rohan-wadhawan/" rel="noopener ugc nofollow" target="_blank"><em class="ov">LinkedIn</em></a><em class="ov">联系我！</em></p></div></div>    
</body>
</html>