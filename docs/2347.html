<html>
<head>
<title>You Should Check Out This Effective Framework for Model Selection</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">你应该看看这个有效的模型选择框架</h1>
<blockquote>原文：<a href="https://pub.towardsai.net/a-framework-for-model-selection-ea4dcda2cb3a?source=collection_archive---------0-----------------------#2021-11-19">https://pub.towardsai.net/a-framework-for-model-selection-ea4dcda2cb3a?source=collection_archive---------0-----------------------#2021-11-19</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><figure class="gl gn jo jp jq jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi jn"><img src="../Images/2cb4e7b2cbb22b027cb6a0a020982fe2.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*20UGfabTmPWJzV4OZlz13Q.jpeg"/></div></div><figcaption class="jy jz gj gh gi ka kb bd b be z dk translated">在<a class="ae kc" href="https://unsplash.com/s/photos/selection?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上由<a class="ae kc" href="https://unsplash.com/@poleznova?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText" rel="noopener ugc nofollow" target="_blank"> vitamina poleznova </a>拍摄的照片</figcaption></figure><p id="95f6" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">在每个机器学习项目中，我们都需要选择一个模型来改善我们的起始基线。</p><p id="ae86" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">事实上，如果基线给了我们一个有用的起始模型来理解我们可以从一个非常简单的解决方案中期待什么，那么通过<strong class="kf ir">一个特定的方法论</strong>选择的模型帮助我们平稳地进入项目的优化阶段。</p><p id="717d" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">在这篇文章中，我将与你分享我的个人框架(和代码库),以有组织和结构化的方式进行模型选择。</p><h1 id="98ef" class="lb lc iq bd ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly bi translated">该方法</h1><p id="a9d1" class="pw-post-body-paragraph kd ke iq kf b kg lz ki kj kk ma km kn ko mb kq kr ks mc ku kv kw md ky kz la ij bi translated">假设我们有一个回归问题要解决。让我们从导入所需的库和配置日志机制开始</p><pre class="me mf mg mh gt mi mj mk ml aw mm bi"><span id="8c4e" class="mn lc iq mj b gy mo mp l mq mr"><strong class="mj ir">from</strong> <strong class="mj ir">sklearn</strong> <strong class="mj ir">import</strong> linear_model<br/><strong class="mj ir">from</strong> <strong class="mj ir">sklearn</strong> <strong class="mj ir">import</strong> ensemble<br/><strong class="mj ir">from</strong> <strong class="mj ir">sklearn</strong> <strong class="mj ir">import</strong> tree<br/><strong class="mj ir">from</strong> <strong class="mj ir">sklearn</strong> <strong class="mj ir">import</strong> svm<br/><strong class="mj ir">from</strong> <strong class="mj ir">sklearn</strong> <strong class="mj ir">import</strong> neighbors<br/><strong class="mj ir">from</strong> <strong class="mj ir">lightgbm</strong> <strong class="mj ir">import</strong> LGBMRegressor<br/><strong class="mj ir">from</strong> <strong class="mj ir">xgboost</strong> <strong class="mj ir">import</strong> XGBRegressor<br/><strong class="mj ir">import</strong> <strong class="mj ir">logging</strong></span><span id="cf5e" class="mn lc iq mj b gy ms mp l mq mr">logging.basicConfig(level=logging.INFO)</span></pre><p id="9b54" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">我遵循的思维模式如下:</p><ol class=""><li id="7339" class="mt mu iq kf b kg kh kk kl ko mv ks mw kw mx la my mz na nb bi translated">我们将创建一个空列表并用对(<em class="nc"> model_name </em>，<em class="nc"> model </em>)填充它</li><li id="bf80" class="mt mu iq kf b kg nd kk ne ko nf ks ng kw nh la my mz na nb bi translated">我们将通过Scikit-Learn KFold交叉验证来定义分割数据的参数</li><li id="5b83" class="mt mu iq kf b kg nd kk ne ko nf ks ng kw nh la my mz na nb bi translated">我们将创建一个for循环，交叉验证每个模型并保存其性能</li><li id="c16a" class="mt mu iq kf b kg nd kk ne ko nf ks ng kw nh la my mz na nb bi translated">我们将查看每个型号的性能，以便选择性能最佳的型号</li><li id="09e7" class="mt mu iq kf b kg nd kk ne ko nf ks ng kw nh la my mz na nb bi translated">我们定义一个列表并插入我们想要测试的模型。</li></ol><p id="1310" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">让我们定义一个列表，并插入我们想要测试的模型。</p><pre class="me mf mg mh gt mi mj mk ml aw mm bi"><span id="2983" class="mn lc iq mj b gy mo mp l mq mr">models = []<br/>models.append(('Lasso', linear_model.Lasso()))<br/>models.append(('Ridge', linear_model.Ridge()))<br/>models.append(('EN', linear_model.ElasticNet()))<br/>models.append(('RandomForest', ensemble.RandomForestRegressor()))<br/>models.append(('KNR', neighbors.KNeighborsRegressor()))<br/>models.append(('DT', tree.DecisionTreeRegressor()))<br/>models.append(('ET', tree.ExtraTreeRegressor()))<br/>models.append(('LGBM', LGBMRegressor()))<br/>models.append(('XGB', XGBRegressor()))<br/>models.append(('GBM', ensemble.GradientBoostingRegressor()))<br/>models.append(("SVR", svm.LinearSVR()))</span></pre><p id="a9f3" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">对于属于<em class="nc">模型的</em>列表中的每个模型，我们将通过<a class="ae kc" href="https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.KFold.html" rel="noopener ugc nofollow" target="_blank"> model_selection来评估其性能。KFold </a>。它的工作方式相当简单:我们的训练数据集(<em class="nc"> X_train，y_train </em>)将被分成相等的部分(称为<em class="nc"> folds </em>)，分别进行测试。因此，KFold交叉验证将<strong class="kf ir">提供每个分割的平均性能指标，而不是基于整个训练数据集的单一指标</strong>。这项技术非常有用，因为它允许您更精确地测量模型的性能。</p><p id="7068" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">由于这是一个回归问题，我们将使用均方差(MSE)度量。</p><p id="a6a0" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">让我们定义交叉验证的参数，并初始化循环的。</p><pre class="me mf mg mh gt mi mj mk ml aw mm bi"><span id="9c6f" class="mn lc iq mj b gy mo mp l mq mr">n_folds = <strong class="mj ir">5</strong> # number of splits <br/>results = [] # save the performances in this list<br/>names = [] # this list helps us save the model names for visualization<br/><br/># we begin the loop where we'll test each model in the models list<br/><strong class="mj ir">for</strong> name, model <strong class="mj ir">in</strong> models:<br/>    kfold = model_selection.KFold(n_splits=n_folds)<br/>    logging.INFO("Testing model:", name)</span><span id="a1b2" class="mn lc iq mj b gy ms mp l mq mr">    cv_results = model_selection.cross_val_score(<br/>        model, # the model picked from the list<br/>        X_train, # feature train set<br/>        y_train, # target train set<br/>        cv=kfold, # current split<br/>        scoring="neg_mean_squared_error", <br/>        verbose=<strong class="mj ir">0</strong>, <br/>        n_jobs=-<strong class="mj ir">1</strong>)</span><span id="7274" class="mn lc iq mj b gy ms mp l mq mr">    results.append(cv_results)<br/>    names.append(name)</span><span id="e14e" class="mn lc iq mj b gy ms mp l mq mr">    msg = "%s: %f (%f)" % (name, cv_results.mean(), cv_results.std())</span><span id="3b13" class="mn lc iq mj b gy ms mp l mq mr">    logging.INFO(msg+"<strong class="mj ir">\n</strong>")</span></pre><p id="5627" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">每个模型都将进行交叉验证和测试，其性能将保存在<em class="nc">结果</em>中。</p><p id="f09c" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">可视化非常简单，将通过箱线图来完成。</p><pre class="me mf mg mh gt mi mj mk ml aw mm bi"><span id="437c" class="mn lc iq mj b gy mo mp l mq mr"># Compare our models in a box plot<br/>fig = plt.figure(figsize=(<strong class="mj ir">12</strong>,<strong class="mj ir">7</strong>))<br/>fig.suptitle('Algorithm Comparison')<br/>ax = fig.add_subplot(<strong class="mj ir">111</strong>)<br/>plt.boxplot(results)<br/>ax.set_xticklabels(names)<br/>plt.show()</span></pre><h1 id="5505" class="lb lc iq bd ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly bi translated">最后的结果</h1><p id="c532" class="pw-post-body-paragraph kd ke iq kf b kg lz ki kj kk ma km kn ko mb kq kr ks mc ku kv kw md ky kz la ij bi translated">最终结果将是这样的:</p><figure class="me mf mg mh gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi ni"><img src="../Images/303621704a543ad26c19f761b7569576.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*BAvGRmcvECe9C4Ac2tTp3Q.png"/></div></div><figcaption class="jy jz gj gh gi ka kb bd b be z dk translated">我们的模型选择脚本的最终输出</figcaption></figure><p id="3d1e" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">从这里可以看出RandomForest和GradientBoostingMachine是如何表现最好的机型。然后，我们可以开始创建新的实验，并进一步测试这两个模型。</p><h1 id="a63d" class="lb lc iq bd ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly bi translated">把所有的放在一起</h1><p id="1811" class="pw-post-body-paragraph kd ke iq kf b kg lz ki kj kk ma km kn ko mb kq kr ks mc ku kv kw md ky kz la ij bi translated">这是用于模型选择的复制粘贴模板，我会在model_selection.py脚本中方便地使用它(我在这里讨论如何构建一个机器学习项目<a class="ae kc" href="https://medium.com/mlearning-ai/how-to-structure-your-machine-learning-project-62f8a1eef582" rel="noopener"/></p><figure class="me mf mg mh gt jr"><div class="bz fp l di"><div class="nj nk l"/></div><figcaption class="jy jz gj gh gi ka kb bd b be z dk translated">用于模型选择的复制-粘贴就绪模板</figcaption></figure><h1 id="217c" class="lb lc iq bd ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly bi translated">结论</h1><p id="3398" class="pw-post-body-paragraph kd ke iq kf b kg lz ki kj kk ma km kn ko mb kq kr ks mc ku kv kw md ky kz la ij bi translated">很高兴你来了。希望您会发现这篇文章很有用，并在您的代码库中实现其中的一些片段。</p><p id="1f63" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">如果你想支持我的内容创作活动，请随时关注我下面的推荐链接，并加入Medium的会员计划。我将获得你投资的一部分，你将能够以无缝的方式访问Medium的大量数据科学文章。</p><div class="nl nm gp gr nn no"><a href="https://medium.com/@theDrewDag/membership" rel="noopener follow" target="_blank"><div class="np ab fo"><div class="nq ab nr cl cj ns"><h2 class="bd ir gy z fp nt fr fs nu fu fw ip bi translated">通过我的推荐链接加入Medium-Andrew D # data science</h2><div class="nv l"><h3 class="bd b gy z fp nt fr fs nu fu fw dk translated">阅读Andrew D #datascience(以及媒体上成千上万的其他作者)的每一个故事。您的会员费直接…</h3></div><div class="nw l"><p class="bd b dl z fp nt fr fs nu fu fw dk translated">medium.com</p></div></div><div class="nx l"><div class="ny l nz oa ob nx oc jw no"/></div></div></a></div><p id="dc46" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">祝你愉快。留得安好👋</p></div></div>    
</body>
</html>