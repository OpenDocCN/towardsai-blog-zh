<html>
<head>
<title>Building a Machine Learning Recommendation Model from Scratch</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">从头开始构建机器学习推荐模型</h1>
<blockquote>原文：<a href="https://pub.towardsai.net/machine-learning-model-for-recommending-the-crew-size-for-cruise-ship-buyers-6dd478ad9900?source=collection_archive---------1-----------------------#2019-05-29">https://pub.towardsai.net/machine-learning-model-for-recommending-the-crew-size-for-cruise-ship-buyers-6dd478ad9900?source=collection_archive---------1-----------------------#2019-05-29</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="1377" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">用Python构建机器学习模型，为邮轮买家推荐船员规模</h2></div><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ki"><img src="../Images/46d3302488d925ccfa7e0935a97dd845.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*XhHthSm8amIYEIyDjXzrnw.jpeg"/></div></div><figcaption class="ku kv gj gh gi kw kx bd b be z dk translated">一艘嘉年华游轮。图片来源:<a class="ae kz" href="https://www.kaleidoscopeadventures.com/product/student-cruises/" rel="noopener ugc nofollow" target="_blank"><strong class="bd ky">https://www . kaleidoscope adventures . com/product/student-cruises/</strong></a><strong class="bd ky">。</strong></figcaption></figure><p id="ab28" class="pw-post-body-paragraph la lb it lc b ld le ju lf lg lh jx li lj lk ll lm ln lo lp lq lr ls lt lu lv im bi translated">在本教程中，我们使用cruise_ship_info.csv <a class="ae kz" href="https://github.com/bot13956/ML_Model_for_Predicting_Ships_Crew_Size" rel="noopener ugc nofollow" target="_blank">数据集</a>构建一个回归模型，为潜在的游轮买家推荐船员数量。本教程将重点介绍重要的数据科学和机器学习概念，例如:</p><p id="32fe" class="pw-post-body-paragraph la lb it lc b ld le ju lf lg lh jx li lj lk ll lm ln lo lp lq lr ls lt lu lv im bi translated">a)数据预处理和变量选择</p><p id="2a2f" class="pw-post-body-paragraph la lb it lc b ld le ju lf lg lh jx li lj lk ll lm ln lo lp lq lr ls lt lu lv im bi translated">b)基本回归模型构建</p><p id="7220" class="pw-post-body-paragraph la lb it lc b ld le ju lf lg lh jx li lj lk ll lm ln lo lp lq lr ls lt lu lv im bi translated">c)超参数调谐</p><p id="62d9" class="pw-post-body-paragraph la lb it lc b ld le ju lf lg lh jx li lj lk ll lm ln lo lp lq lr ls lt lu lv im bi translated">b)模型评估</p><p id="bdac" class="pw-post-body-paragraph la lb it lc b ld le ju lf lg lh jx li lj lk ll lm ln lo lp lq lr ls lt lu lv im bi translated">d)降维技术</p><p id="0127" class="pw-post-body-paragraph la lb it lc b ld le ju lf lg lh jx li lj lk ll lm ln lo lp lq lr ls lt lu lv im bi translated">构建这个推荐系统的代码可以在<a class="ae kz" href="https://github.com/bot13956/ML_Model_for_Predicting_Ships_Crew_Size" rel="noopener ugc nofollow" target="_blank"> GitHub </a>上找到。</p><h1 id="008d" class="lw lx it bd ky ly lz ma mb mc md me mf jz mg ka mh kc mi kd mj kf mk kg ml mm bi translated">1.导入必要的库</h1><pre class="kj kk kl km gt mn mo mp mq aw mr bi"><span id="74df" class="ms lx it mo b gy mt mu l mv mw">import numpy as np<br/>import pandas as pd<br/>import matplotlib.pyplot as plt<br/>import seaborn as sns</span></pre><h1 id="5d7f" class="lw lx it bd ky ly lz ma mb mc md me mf jz mg ka mh kc mi kd mj kf mk kg ml mm bi translated">2.读取数据集并显示列</h1><pre class="kj kk kl km gt mn mo mp mq aw mr bi"><span id="79d7" class="ms lx it mo b gy mt mu l mv mw">df=pd.read_csv("cruise_ship_info.csv")<br/>df.head()</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi mx"><img src="../Images/22f4cf489af08edca04614dee0d270f2.png" data-original-src="https://miro.medium.com/v2/resize:fit:1252/format:webp/1*UkMcJR8vfZBgQYsK94G9yg.png"/></div></figure><h1 id="4e76" class="lw lx it bd ky ly lz ma mb mc md me mf jz mg ka mh kc mi kd mj kf mk kg ml mm bi translated">3.计算数据集的基本汇总统计数据</h1><pre class="kj kk kl km gt mn mo mp mq aw mr bi"><span id="7e9e" class="ms lx it mo b gy mt mu l mv mw">df.describe()</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi my"><img src="../Images/1fb1c9ffb654b0bf51211015a11f562d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1248/format:webp/1*ze9M4ptXEKM-hTLl2fYC0A.png"/></div></figure><h1 id="b00f" class="lw lx it bd ky ly lz ma mb mc md me mf jz mg ka mh kc mi kd mj kf mk kg ml mm bi translated">4.生成散点对图</h1><pre class="kj kk kl km gt mn mo mp mq aw mr bi"><span id="0c4e" class="ms lx it mo b gy mt mu l mv mw">cols = ['Age', 'Tonnage', 'passengers', 'length', 'cabins','passenger_density','crew']<br/>sns.pairplot(df[cols], size=2.0)</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi mz"><img src="../Images/6b8c81da53da4819580a31ca4c58b946.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*YL6DMZ0mcsedfOtjWpDoZw.png"/></div></div></figure><p id="3d87" class="pw-post-body-paragraph la lb it lc b ld le ju lf lg lh jx li lj lk ll lm ln lo lp lq lr ls lt lu lv im bi translated"><strong class="lc iu">第四部分的观察结果:</strong></p><p id="ddc4" class="pw-post-body-paragraph la lb it lc b ld le ju lf lg lh jx li lj lk ll lm ln lo lp lq lr ls lt lu lv im bi translated">1)我们观察到变量在不同的尺度上，对于样本，年龄变量的范围从大约16岁到48岁，而吨位变量的范围从2到220岁。因此，当使用这些变量构建回归模型时，通过标准化或规范化数据使变量达到相同的范围是很重要的。</p><p id="28c8" class="pw-post-body-paragraph la lb it lc b ld le ju lf lg lh jx li lj lk ll lm ln lo lp lq lr ls lt lu lv im bi translated">2)我们还观察到，目标变量“船员”与4个预测变量，即“吨位”、“乘客”、“长度”和“船舱”有很好的相关性。</p><h1 id="7591" class="lw lx it bd ky ly lz ma mb mc md me mf jz mg ka mh kc mi kd mj kf mk kg ml mm bi translated">5.预测“机组”规模的变量选择</h1><h2 id="d111" class="ms lx it bd ky na nb dn mb nc nd dp mf lj ne nf mh ln ng nh mj lr ni nj ml nk bi translated">5a。协方差矩阵的计算</h2><pre class="kj kk kl km gt mn mo mp mq aw mr bi"><span id="4dee" class="ms lx it mo b gy mt mu l mv mw">cols = ['Age', 'Tonnage', 'passengers', 'length', 'cabins','passenger_density','crew']<br/>from sklearn.preprocessing import StandardScaler<br/>stdsc = StandardScaler()<br/>X_std = stdsc.fit_transform(df[cols].iloc[:,range(0,7)].values)</span><span id="5a0f" class="ms lx it mo b gy nl mu l mv mw">cov_mat =np.cov(X_std.T)<br/>plt.figure(figsize=(10,10))<br/>sns.set(font_scale=1.5)<br/>hm = sns.heatmap(cov_mat,<br/>                 cbar=True,<br/>                 annot=True,<br/>                 square=True,<br/>                 fmt='.2f',<br/>                 annot_kws={'size': 12},<br/>                 yticklabels=cols,<br/>                 xticklabels=cols)<br/>plt.title('Covariance matrix showing correlation coefficients')<br/>plt.tight_layout()<br/>plt.show()</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi nm"><img src="../Images/0c3ae1b1790085d0306b584279488b7f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1358/format:webp/1*G09iXsYPIFzk020kI00amA.png"/></div></figure><h2 id="e873" class="ms lx it bd ky na nb dn mb nc nd dp mf lj ne nf mh ln ng nh mj lr ni nj ml nk bi translated">5b。选择预测值和目标变量</h2><p id="c471" class="pw-post-body-paragraph la lb it lc b ld nn ju lf lg no jx li lj np ll lm ln nq lp lq lr nr lt lu lv im bi translated">从上面的协方差矩阵图中，我们看到“机组人员”变量与4个预测变量密切相关:“吨位”、“乘客”、“长度”和“客舱”。</p><pre class="kj kk kl km gt mn mo mp mq aw mr bi"><span id="6d23" class="ms lx it mo b gy mt mu l mv mw">cols_selected = ['Tonnage', 'passengers', 'length', 'cabins','crew']</span><span id="f97b" class="ms lx it mo b gy nl mu l mv mw">df[cols_selected].head()</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi ns"><img src="../Images/05bee9548935749a23adcfe8002b3620.png" data-original-src="https://miro.medium.com/v2/resize:fit:630/format:webp/1*6WQrok8OKWqaFN4CDpZmLQ.png"/></div></figure><pre class="kj kk kl km gt mn mo mp mq aw mr bi"><span id="1266" class="ms lx it mo b gy mt mu l mv mw">X = df[cols_selected].iloc[:,0:4].values    # features matrix <br/>y = df[cols_selected]['crew'].values        # target variable</span></pre><h1 id="7a04" class="lw lx it bd ky ly lz ma mb mc md me mf jz mg ka mh kc mi kd mj kf mk kg ml mm bi translated">6.将数据划分为训练集和测试集</h1><pre class="kj kk kl km gt mn mo mp mq aw mr bi"><span id="f08e" class="ms lx it mo b gy mt mu l mv mw">from sklearn.model_selection import train_test_split<br/>X = df[cols_selected].iloc[:,0:4].values     <br/>y = df[cols_selected]['crew']<br/>X_train, X_test, y_train, y_test = train_test_split( X, y, test_size=0.4, random_state=0)</span></pre><h1 id="c4c9" class="lw lx it bd ky ly lz ma mb mc md me mf jz mg ka mh kc mi kd mj kf mk kg ml mm bi translated">7.构建多元回归模型</h1><p id="57aa" class="pw-post-body-paragraph la lb it lc b ld nn ju lf lg no jx li lj np ll lm ln nq lp lq lr nr lt lu lv im bi translated">我们用于预测船只“船员”数量的机器学习回归模型可以表示为:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi nt"><img src="../Images/eecad79975c5077c73b3751c76ae8872.png" data-original-src="https://miro.medium.com/v2/resize:fit:782/format:webp/1*0Kr84XCGovVnBrjEQioqUg.png"/></div></figure><pre class="kj kk kl km gt mn mo mp mq aw mr bi"><span id="7172" class="ms lx it mo b gy mt mu l mv mw">from sklearn.linear_model import LinearRegression<br/>slr = LinearRegression()</span><span id="d051" class="ms lx it mo b gy nl mu l mv mw">slr.fit(X_train, y_train)<br/>y_train_pred = slr.predict(X_train)<br/>y_test_pred = slr.predict(X_test)</span><span id="1236" class="ms lx it mo b gy nl mu l mv mw">plt.scatter(y_train_pred,  y_train_pred - y_train,<br/>            c='steelblue', marker='o', edgecolor='white',<br/>            label='Training data')<br/>plt.scatter(y_test_pred,  y_test_pred - y_test,<br/>            c='limegreen', marker='s', edgecolor='white',<br/>            label='Test data')<br/>plt.xlabel('Predicted values')<br/>plt.ylabel('Residuals')<br/>plt.legend(loc='upper left')<br/>plt.hlines(y=0, xmin=-10, xmax=50, color='black', lw=2)<br/>plt.xlim([-10, 50])<br/>plt.tight_layout()<br/>plt.legend(loc='lower right')<br/>plt.show()</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi nu"><img src="../Images/70672c52f6ae8fb85e922797112c078e.png" data-original-src="https://miro.medium.com/v2/resize:fit:814/format:webp/1*jj8FzopZoRnC2OR8y_Ip6Q.png"/></div></figure><h2 id="dec9" class="ms lx it bd ky na nb dn mb nc nd dp mf lj ne nf mh ln ng nh mj lr ni nj ml nk bi translated">7a。回归模型的评估</h2><pre class="kj kk kl km gt mn mo mp mq aw mr bi"><span id="0541" class="ms lx it mo b gy mt mu l mv mw">from sklearn.metrics import r2_score<br/>from sklearn.metrics import mean_squared_error</span><span id="ccb8" class="ms lx it mo b gy nl mu l mv mw">print('MSE train: %.3f, test: %.3f' % (<br/>        mean_squared_error(y_train, y_train_pred),<br/>        mean_squared_error(y_test, y_test_pred)))<br/>print('R^2 train: %.3f, test: %.3f' % (<br/>        r2_score(y_train, y_train_pred),<br/>        r2_score(y_test, y_test_pred)))</span><span id="c0ac" class="ms lx it mo b gy nl mu l mv mw"><strong class="mo iu">MSE train: 0.955, test: 0.889<br/>R^2 train: 0.920, test: 0.928</strong></span></pre><h2 id="d2d5" class="ms lx it bd ky na nb dn mb nc nd dp mf lj ne nf mh ln ng nh mj lr ni nj ml nk bi translated">7b。回归系数</h2><pre class="kj kk kl km gt mn mo mp mq aw mr bi"><span id="c9c8" class="ms lx it mo b gy mt mu l mv mw">slr.fit(X_train, y_train).intercept_</span><span id="e12e" class="ms lx it mo b gy nl mu l mv mw"><strong class="mo iu">-0.7525074496158393</strong></span><span id="8874" class="ms lx it mo b gy nl mu l mv mw">slr.fit(X_train, y_train).coef_</span><span id="5ecb" class="ms lx it mo b gy nl mu l mv mw"><strong class="mo iu">array([ 0.01902703, -0.15001099,  0.37876395,  0.77613801])</strong></span></pre><h1 id="c1ea" class="lw lx it bd ky ly lz ma mb mc md me mf jz mg ka mh kc mi kd mj kf mk kg ml mm bi translated">8.功能标准化、交叉验证和超参数调整</h1><pre class="kj kk kl km gt mn mo mp mq aw mr bi"><span id="082c" class="ms lx it mo b gy mt mu l mv mw">from sklearn.metrics import r2_score<br/>from sklearn.model_selection import train_test_split<br/>X = df[cols_selected].iloc[:,0:4].values     <br/>y = df[cols_selected]['crew']  <br/>from sklearn.preprocessing import StandardScaler<br/>sc_y = StandardScaler()<br/>sc_x = StandardScaler()<br/>y_std = sc_y.fit_transform(y_train[:, np.newaxis]).flatten()</span><span id="8dec" class="ms lx it mo b gy nl mu l mv mw">train_score = []<br/>test_score = []</span><span id="320e" class="ms lx it mo b gy nl mu l mv mw">for i in range(10):<br/>    X_train, X_test, y_train, y_test = train_test_split( X, y, test_size=0.4, random_state=i)<br/>    y_train_std = sc_y.fit_transform(y_train[:, np.newaxis]).flatten()<br/>    from sklearn.preprocessing import StandardScaler<br/>    from sklearn.decomposition import PCA<br/>    from sklearn.linear_model import LinearRegression<br/>    from sklearn.pipeline import Pipeline<br/>    pipe_lr = Pipeline([('scl', StandardScaler()),('pca', PCA(n_components=4)),('slr', LinearRegression())])<br/>    pipe_lr.fit(X_train, y_train_std)<br/>    y_train_pred_std=pipe_lr.predict(X_train)<br/>    y_test_pred_std=pipe_lr.predict(X_test)<br/>    y_train_pred=sc_y.inverse_transform(y_train_pred_std)<br/>    y_test_pred=sc_y.inverse_transform(y_test_pred_std)<br/>    train_score = np.append(train_score, r2_score(y_train, y_train_pred))<br/>    test_score = np.append(test_score, r2_score(y_test, y_test_pred))</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi mx"><img src="../Images/c0c3b98f814760c3fd8a4aa826579b8b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1252/format:webp/1*cWadlrGTzEcMW4zI5hwLLw.png"/></div></figure><h1 id="9f6e" class="lw lx it bd ky ly lz ma mb mc md me mf jz mg ka mh kc mi kd mj kf mk kg ml mm bi translated">9.降维技术</h1><h2 id="4889" class="ms lx it bd ky na nb dn mb nc nd dp mf lj ne nf mh ln ng nh mj lr ni nj ml nk bi translated">9a。主成分分析</h2><pre class="kj kk kl km gt mn mo mp mq aw mr bi"><span id="e196" class="ms lx it mo b gy mt mu l mv mw">train_score = []<br/>test_score = []<br/>cum_variance = []</span><span id="b46f" class="ms lx it mo b gy nl mu l mv mw">for i in range(1,5):<br/>    X_train, X_test, y_train, y_test = train_test_split( X, y, test_size=0.4, random_state=0)<br/>    y_train_std = sc_y.fit_transform(y_train[:, np.newaxis]).flatten()<br/>    from sklearn.preprocessing import StandardScaler<br/>    from sklearn.decomposition import PCA<br/>    from sklearn.linear_model import LinearRegression<br/>    from sklearn.pipeline import Pipeline<br/>    pipe_lr = Pipeline([('scl', StandardScaler()),('pca', PCA(n_components=i)),('slr', LinearRegression())])<br/>    pipe_lr.fit(X_train, y_train_std)<br/>    y_train_pred_std=pipe_lr.predict(X_train)<br/>    y_test_pred_std=pipe_lr.predict(X_test)<br/>    y_train_pred=sc_y.inverse_transform(y_train_pred_std)<br/>    y_test_pred=sc_y.inverse_transform(y_test_pred_std)<br/>    train_score = np.append(train_score, r2_score(y_train, y_train_pred))<br/>    test_score = np.append(test_score, r2_score(y_test, y_test_pred))<br/>    cum_variance = np.append(cum_variance, np.sum(pipe_lr.fit(X_train, y_train).named_steps['pca'].explained_variance_ratio_))</span><span id="0a2a" class="ms lx it mo b gy nl mu l mv mw">plt.scatter(cum_variance,train_score, label = 'train_score')<br/>plt.plot(cum_variance, train_score)<br/>plt.scatter(cum_variance,test_score, label = 'test_score')<br/>plt.plot(cum_variance, test_score)<br/>plt.xlabel('cumulative variance')<br/>plt.ylabel('R2_score')<br/>plt.legend()<br/>plt.show()</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi nv"><img src="../Images/1335cd3535ca159a5bd86dc4e03756fa.png" data-original-src="https://miro.medium.com/v2/resize:fit:808/format:webp/1*x6cFmSpdua5wyXl-qMIFCQ.png"/></div></figure><p id="525e" class="pw-post-body-paragraph la lb it lc b ld le ju lf lg lh jx li lj lk ll lm ln lo lp lq lr ls lt lu lv im bi translated"><strong class="lc iu">第9a部分的观察结果:</strong></p><p id="ffcb" class="pw-post-body-paragraph la lb it lc b ld le ju lf lg lh jx li lj lk ll lm ln lo lp lq lr ls lt lu lv im bi translated">我们观察到，通过将主成分的数量从1增加到4，训练和测试分数提高了。这是因为，在组件较少的情况下，模型中存在较高的偏置误差，因为模型过于简化。随着主成分数量的增加，偏差误差会减小，但模型的复杂性会增加。</p><h2 id="d71e" class="ms lx it bd ky na nb dn mb nc nd dp mf lj ne nf mh ln ng nh mj lr ni nj ml nk bi translated">9b。正则化回归:套索</h2><pre class="kj kk kl km gt mn mo mp mq aw mr bi"><span id="00b7" class="ms lx it mo b gy mt mu l mv mw">from sklearn.model_selection import train_test_split<br/>X_train, X_test, y_train, y_test = train_test_split( X, y, test_size=0.4, random_state=0)<br/>y_train_std = sc_y.fit_transform(y_train[:, np.newaxis]).flatten()<br/>X_train_std = sc_x.fit_transform(X_train)<br/>X_test_std = sc_x.transform(X_test)</span><span id="7dc9" class="ms lx it mo b gy nl mu l mv mw">alpha = np.linspace(0.01,0.4,10) #lasso parameters</span><span id="3c3b" class="ms lx it mo b gy nl mu l mv mw">from sklearn.linear_model import Lasso<br/>lasso = Lasso(alpha=0.7)</span><span id="095f" class="ms lx it mo b gy nl mu l mv mw">r2_train=[]<br/>r2_test=[]<br/>norm = []<br/>for i in range(10):<br/>    lasso = Lasso(alpha=alpha[i])<br/>    lasso.fit(X_train_std,y_train_std)<br/>    y_train_std=lasso.predict(X_train_std)<br/>    y_test_std=lasso.predict(X_test_std)<br/>    r2_train=np.append(r2_train,r2_score(y_train,sc_y.inverse_transform(y_train_std)))<br/>    r2_test=np.append(r2_test,r2_score(y_test,sc_y.inverse_transform(y_test_std)))<br/>    norm= np.append(norm,np.linalg.norm(lasso.coef_))</span><span id="f4ac" class="ms lx it mo b gy nl mu l mv mw">plt.scatter(alpha,r2_train,label='r2_train')<br/>plt.plot(alpha,r2_train)<br/>plt.scatter(alpha,r2_test,label='r2_test')<br/>plt.plot(alpha,r2_test)<br/>plt.scatter(alpha,norm,label = 'norm')<br/>plt.plot(alpha,norm)<br/>plt.ylim(-0.1,1)<br/>plt.xlim(0,.43)<br/>plt.xlabel('alpha')<br/>plt.ylabel('R2_score')<br/>plt.legend()<br/>plt.show()</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi nw"><img src="../Images/739934f2c58023d864e489c090d4b624.png" data-original-src="https://miro.medium.com/v2/resize:fit:792/format:webp/1*noTJNGzpRsXvRN6W7mZ2eA.png"/></div></figure><p id="2351" class="pw-post-body-paragraph la lb it lc b ld le ju lf lg lh jx li lj lk ll lm ln lo lp lq lr ls lt lu lv im bi translated"><strong class="lc iu">来自第9b部分的观察:</strong></p><p id="0a9f" class="pw-post-body-paragraph la lb it lc b ld le ju lf lg lh jx li lj lk ll lm ln lo lp lq lr ls lt lu lv im bi translated">我们观察到，随着正则化参数α的增加，回归系数的范数变得越来越小。这意味着更多的回归系数被强制为零，这将增加偏差误差(过度简化)。平衡偏差-方差权衡的最佳值是当alpha保持较低时，比如alpha = 0.1或更低。</p><h1 id="eead" class="lw lx it bd ky ly lz ma mb mc md me mf jz mg ka mh kc mi kd mj kf mk kg ml mm bi translated">摘要</h1><p id="4704" class="pw-post-body-paragraph la lb it lc b ld nn ju lf lg no jx li lj np ll lm ln nq lp lq lr nr lt lu lv im bi translated">总之，我们已经展示了如何使用cruise_ship_info.csv <a class="ae kz" href="https://github.com/bot13956/ML_Model_for_Predicting_Ships_Crew_Size" rel="noopener ugc nofollow" target="_blank">数据集</a>构建一个简单的回归模型，为潜在的船舶买家预测船员数量。这个推荐系统的代码可以在<a class="ae kz" href="https://github.com/bot13956/ML_Model_for_Predicting_Ships_Crew_Size." rel="noopener ugc nofollow" target="_blank"> GitHub </a>上找到。</p><h1 id="779e" class="lw lx it bd ky ly lz ma mb mc md me mf jz mg ka mh kc mi kd mj kf mk kg ml mm bi translated"><strong class="ak">参考文献</strong></h1><ol class=""><li id="824a" class="nx ny it lc b ld nn lg no lj nz ln oa lr ob lv oc od oe of bi translated">拉什卡、塞巴斯蒂安和瓦希德·米尔贾利利<strong class="lc iu">。</strong> <em class="og"> Python机器学习，第二版</em>。帕克特出版社，2017年。</li><li id="6e14" class="nx ny it lc b ld oh lg oi lj oj ln ok lr ol lv oc od oe of bi translated">Benjamin O. Tayo，<em class="og">预测船只船员规模的机器学习模型</em>，<a class="ae kz" href="https://github.com/bot13956/ML_Model_for_Predicting_Ships_Crew_Size" rel="noopener ugc nofollow" target="_blank">https://github . com/bot 13956/ML _ Model _ for _ Predicting _ Ships _ Crew _ Size</a>。</li></ol></div></div>    
</body>
</html>