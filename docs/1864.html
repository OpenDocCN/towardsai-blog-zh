<html>
<head>
<title>Predicting Genres from Movie Dialogue</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">从电影对白中预测类型</h1>
<blockquote>原文：<a href="https://pub.towardsai.net/predicting-genres-from-movie-dialogue-c6bc872af33?source=collection_archive---------4-----------------------#2021-05-19">https://pub.towardsai.net/predicting-genres-from-movie-dialogue-c6bc872af33?source=collection_archive---------4-----------------------#2021-05-19</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><h2 id="5678" class="io ip iq bd b dl ir is it iu iv iw dk ix translated" aria-label="kicker paragraph"><a class="ae ep" href="https://towardsai.net/p/category/nlp" rel="noopener ugc nofollow" target="_blank">自然语言处理</a></h2><div class=""/><div class=""><h2 id="fdc0" class="pw-subtitle-paragraph jw iz iq bd b jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn dk translated">多标签自然语言处理分类</h2></div><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div role="button" tabindex="0" class="ku kv di kw bf kx"><div class="gh gi ko"><img src="../Images/2a7291479743f67a92deafcfe6337b30.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*gmXD21CsmqyT3QUU"/></div></div><figcaption class="la lb gj gh gi lc ld bd b be z dk translated">在<a class="ae le" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上由<a class="ae le" href="https://unsplash.com/@darya_kraplak?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Darya Kraplak </a>拍摄的照片</figcaption></figure><blockquote class="lf lg lh"><p id="2754" class="li lj lk ll b lm ln ka lo lp lq kd lr ls lt lu lv lw lx ly lz ma mb mc md me ij bi translated">“有一天，那一天可能永远不会到来，我会要求你为我做一个服务。但在那一天到来之前，就把这份正义当作我女儿结婚那天的礼物吧。”——堂·维托·柯里昂，《教父》(弗朗西斯·福特·科波拉，1972)</p></blockquote><p id="e8d6" class="pw-post-body-paragraph li lj iq ll b lm ln ka lo lp lq kd lr mf lt lu lv mg lx ly lz mh mb mc md me ij bi translated">任何对电影稍有兴趣的人都有可能识别出产生上述台词的电影，尤其是推断出它的类型。这就是一句好名言的力量。</p><p id="6cee" class="pw-post-body-paragraph li lj iq ll b lm ln ka lo lp lq kd lr mf lt lu lv mg lx ly lz mh mb mc md me ij bi translated">但是电影对白的威严是否也能在机器的耳朵里产生共鸣呢？本文旨在利用自然语言处理的特点建立一个分类模型，根据电影对白的交流来预测电影的类型。</p><p id="de0d" class="pw-post-body-paragraph li lj iq ll b lm ln ka lo lp lq kd lr mf lt lu lv mg lx ly lz mh mb mc md me ij bi translated">所产生的模型将是多标签分类器的例子，因为数据集中的每个实例可以同时被分配零个或多个标签的正类。注意，这不同于多类分类器，因为可能的类的向量仍然是二进制的。</p><p id="9ec4" class="pw-post-body-paragraph li lj iq ll b lm ln ka lo lp lq kd lr mf lt lu lv mg lx ly lz mh mb mc md me ij bi translated">基于<strong class="ll ja">概要</strong>预测电影类型是多标签NLP模型领域中一个相对常见的例子。然而，使用电影<strong class="ll ja">对话</strong>作为输入的作品很少甚至没有。因此，这篇文章背后的动机是探索是否可以在电影对话中发现文本模式，以作为电影类型的指标。</p><p id="a8a2" class="pw-post-body-paragraph li lj iq ll b lm ln ka lo lp lq kd lr mf lt lu lv mg lx ly lz mh mb mc md me ij bi translated">施工过程分为三个主要阶段:</p><ol class=""><li id="a026" class="mi mj iq ll b lm ln lp lq mf mk mg ml mh mm me mn mo mp mq bi translated">编译、清理和预处理训练数据集</li><li id="bacb" class="mi mj iq ll b lm mr lp ms mf mt mg mu mh mv me mn mo mp mq bi translated">训练数据的探索性分析</li><li id="85da" class="mi mj iq ll b lm mr lp ms mf mt mg mu mh mv me mn mo mp mq bi translated">建立和评估分类模型</li></ol></div><div class="ab cl mw mx hu my" role="separator"><span class="mz bw bk na nb nc"/><span class="mz bw bk na nb nc"/><span class="mz bw bk na nb"/></div><div class="ij ik il im in"><h1 id="b325" class="nd ne iq bd nf ng nh ni nj nk nl nm nn kf no kg np ki nq kj nr kl ns km nt nu bi translated">第一部分:汇编训练数据集</h1><p id="4d05" class="pw-post-body-paragraph li lj iq ll b lm nv ka lo lp nw kd lr mf nx lu lv mg ny ly lz mh nz mc md me ij bi translated">该项目的数据是通过康奈尔大学的出版物获得的(在致谢部分注明)。</p><p id="5f74" class="pw-post-body-paragraph li lj iq ll b lm ln ka lo lp lq kd lr mf lt lu lv mg lx ly lz mh mb mc md me ij bi translated">在提供的文件中，有三个数据集与项目相关:</p><ul class=""><li id="6b05" class="mi mj iq ll b lm ln lp lq mf mk mg ml mh mm me oa mo mp mq bi translated"><strong class="ll ja">电影对话:</strong>对话的交换被列为线路id和相应电影id的组合</li><li id="75a5" class="mi mj iq ll b lm mr lp ms mf mt mg mu mh mv me oa mo mp mq bi translated"><strong class="ll ja">电影台词:</strong>每行对白的文本及其对应的台词ID</li><li id="e141" class="mi mj iq ll b lm mr lp ms mf mt mg mu mh mv me oa mo mp mq bi translated"><strong class="ll ja">电影标题元数据:</strong>数据中包含的电影的属性，如标题和类型</li></ul><p id="43bd" class="pw-post-body-paragraph li lj iq ll b lm ln ka lo lp lq kd lr mf lt lu lv mg lx ly lz mh mb mc md me ij bi translated">为了从原始文件中编译一组分类的训练数据，我们需要提取必要的数据，将其转换成可工作的格式，并将其加载到数据库中，以便我们以后可以读取。</p><h2 id="70e1" class="ob ne iq bd nf oc od dn nj oe of dp nn mf og oh np mg oi oj nr mh ok ol nt iw bi translated">提取、转换和加载训练数据</h2><p id="76c1" class="pw-post-body-paragraph li lj iq ll b lm nv ka lo lp nw kd lr mf nx lu lv mg ny ly lz mh nz mc md me ij bi translated">用于产生最终训练集的ETL管道将包括以下步骤:</p><ol class=""><li id="f006" class="mi mj iq ll b lm ln lp lq mf mk mg ml mh mm me mn mo mp mq bi translated">将三个文本文件中的数据读入pandas数据帧</li><li id="aed2" class="mi mj iq ll b lm mr lp ms mf mt mg mu mh mv me mn mo mp mq bi translated">为会话数据集中包含的每个交换分配一个会话ID</li><li id="208d" class="mi mj iq ll b lm mr lp ms mf mt mg mu mh mv me mn mo mp mq bi translated">融合对话数据帧，使得每一行对话出现在具有相应对话ID的单独行上</li><li id="4842" class="mi mj iq ll b lm mr lp ms mf mt mg mu mh mv me mn mo mp mq bi translated">将融合的数据帧与行数据集结合，以检索每个行ID的实际文本</li><li id="ae24" class="mi mj iq ll b lm mr lp ms mf mt mg mu mh mv me mn mo mp mq bi translated">通过对话ID连接单独的行，以便每个交换的整体以文本格式出现在单独的行上</li><li id="be23" class="mi mj iq ll b lm mr lp ms mf mt mg mu mh mv me mn mo mp mq bi translated">最后，将文本对话的数据帧与电影元数据相结合，以检索每个文本文档的类型，并将最终的数据帧加载到SQLite数据库中</li></ol><p id="159a" class="pw-post-body-paragraph li lj iq ll b lm ln ka lo lp lq kd lr mf lt lu lv mg lx ly lz mh mb mc md me ij bi translated">一旦ETL管道已经在原始文件上运行，训练数据集将如下所示:</p><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div role="button" tabindex="0" class="ku kv di kw bf kx"><div class="gh gi om"><img src="../Images/bcc138e6a5bbc896be134b95ad5f88b5.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*4hPgkBiHYLuzPLIS0g7z0Q.png"/></div></div><figcaption class="la lb gj gh gi lc ld bd b be z dk translated">图1:训练数据的示例行</figcaption></figure><h2 id="d07b" class="ob ne iq bd nf oc od dn nj oe of dp nn mf og oh np mg oi oj nr mh ok ol nt iw bi translated">重新格式化目标变量</h2><p id="477d" class="pw-post-body-paragraph li lj iq ll b lm nv ka lo lp nw kd lr mf nx lu lv mg ny ly lz mh nz mc md me ij bi translated">考虑到建模阶段，我们需要将“流派”列重新格式化为一个目标变量，以便输入到机器学习算法中。</p><p id="13d5" class="pw-post-body-paragraph li lj iq ll b lm ln ka lo lp lq kd lr mf lt lu lv mg lx ly lz mh mb mc md me ij bi translated">“流派”列中的标签以逗号分隔的字符串形式列出，因此要创建目标变量，我们可以使用一种不同的一次性编码。这包括在数据帧中为每个独特的流派标签创建单独的列，以指示该标签是否包含在主流派列中，1表示是，0表示否</p><pre class="kp kq kr ks gt on oo op oq aw or bi"><span id="449c" class="ob ne iq oo b gy os ot l ou ov">genres = df['genres'].tolist()<br/>genres = ','.join(genres)<br/>genres = genres.split(',')<br/>genres = sorted(list(set(genres)))<br/>for genre in genres:<br/>    df[genre] = df['genres'].apply(lambda x: 1 if genre in x else 0)</span></pre><p id="fd1b" class="pw-post-body-paragraph li lj iq ll b lm ln ka lo lp lq kd lr mf lt lu lv mg lx ly lz mh mb mc md me ij bi translated">二进制类型列的集合将作为目标变量矩阵，其中每部电影可以被分配任意数量的24个唯一标签。</p></div><div class="ab cl mw mx hu my" role="separator"><span class="mz bw bk na nb nc"/><span class="mz bw bk na nb nc"/><span class="mz bw bk na nb"/></div><div class="ij ik il im in"><h1 id="f981" class="nd ne iq bd nf ng nh ni nj nk nl nm nn kf no kg np ki nq kj nr kl ns km nt nu bi translated">第二部分:对培训数据的探索性分析</h1><p id="0ea6" class="pw-post-body-paragraph li lj iq ll b lm nv ka lo lp nw kd lr mf nx lu lv mg ny ly lz mh nz mc md me ij bi translated">既然我们已经将数据重新加工成合适的格式，那么在构建模型之前，让我们开始一些探索以获得一些见解。我们可以先来看看每部电影被分配到的独立类型标签的数量:</p><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div role="button" tabindex="0" class="ku kv di kw bf kx"><div class="gh gi ow"><img src="../Images/23351add4b399a1d21ed566fa016d46d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*bJfEjuhQLk6EnxLaxDq4rA.png"/></div></div><figcaption class="la lb gj gh gi lc ld bd b be z dk translated">图2:每种类型标签的电影数量</figcaption></figure><p id="3352" class="pw-post-body-paragraph li lj iq ll b lm ln ka lo lp lq kd lr mf lt lu lv mg lx ly lz mh mb mc md me ij bi translated">我们数据集中的大多数电影都被分配了2-4个类型标签。当我们考虑总共有24个可能的标签时，这突出了我们可以预期我们的目标变量矩阵包含的负面分类比正面分类多得多。</p><p id="2374" class="pw-post-body-paragraph li lj iq ll b lm ln ka lo lp lq kd lr mf lt lu lv mg lx ly lz mh mb mc md me ij bi translated">这为建模阶段提供了有价值的见解，因为我们可以在训练数据中观察到显著的<strong class="ll ja">类不平衡</strong>。要从数字上评估这种不平衡:</p><pre class="kp kq kr ks gt on oo op oq aw or bi"><span id="1b1f" class="ob ne iq oo b gy os ot l ou ov">df[genres].mean().mean()<br/>&gt;&gt;&gt; 0.12317299038986919</span></pre><p id="3a2b" class="pw-post-body-paragraph li lj iq ll b lm ln ka lo lp lq kd lr mf lt lu lv mg lx ly lz mh mb mc md me ij bi translated">以上表明只有12%的数据集标签属于正类。在决定评估模型的方法时，应该特别注意这个因素。</p><p id="c0e4" class="pw-post-body-paragraph li lj iq ll b lm ln ka lo lp lq kd lr mf lt lu lv mg lx ly lz mh mb mc md me ij bi translated">让我们也评估一下每个流派标签的正面事例的数量:</p><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div role="button" tabindex="0" class="ku kv di kw bf kx"><div class="gh gi ow"><img src="../Images/acbfa0bcebf65546adeceecc4d211fbe.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*YmGoJzDapJOB4zRanwh8Gw.png"/></div></div><figcaption class="la lb gj gh gi lc ld bd b be z dk translated">图3:每个流派标签的正面实例计数</figcaption></figure><p id="3a52" class="pw-post-body-paragraph li lj iq ll b lm ln ka lo lp lq kd lr mf lt lu lv mg lx ly lz mh mb mc md me ij bi translated">除了之前确定的类别不平衡，上面的图表揭示了数据也有一个显著的<strong class="ll ja">标签不平衡</strong>，因为一些流派(如戏剧)比其他流派(如黑色电影)有更多的正面实例来训练模型。</p><p id="b018" class="pw-post-body-paragraph li lj iq ll b lm ln ka lo lp lq kd lr mf lt lu lv mg lx ly lz mh mb mc md me ij bi translated">这可能会对不同流派之间的模式成功产生影响。</p><h2 id="75a1" class="ob ne iq bd nf oc od dn nj oe of dp nn mf og oh np mg oi oj nr mh ok ol nt iw bi translated">讨论分析的结果</h2><p id="7bdd" class="pw-post-body-paragraph li lj iq ll b lm nv ka lo lp nw kd lr mf nx lu lv mg ny ly lz mh nz mc md me ij bi translated">上面的分析揭示了关于我们的训练数据的两个关键见解:</p><ol class=""><li id="56f9" class="mi mj iq ll b lm ln lp lq mf mk mg ml mh mm me mn mo mp mq bi translated">阶级分布严重不平衡，不利者占优势。</li></ol><p id="1387" class="pw-post-body-paragraph li lj iq ll b lm ln ka lo lp lq kd lr mf lt lu lv mg lx ly lz mh mb mc md me ij bi translated">在这种模式的背景下，阶级失衡是很难修正的。校正类不平衡的典型方法是合成过采样:创建特征值接近真实实例的少数类的新实例。</p><p id="7770" class="pw-post-body-paragraph li lj iq ll b lm ln ka lo lp lq kd lr mf lt lu lv mg lx ly lz mh mb mc md me ij bi translated">然而，这种方法通常不适用于多标签分类问题，因为任何可信的合成实例都会显示相同的问题。因此，类别不平衡反映了现实情况，因为一部电影只被分配了所有可能类型中的一小部分。</p><p id="d5f5" class="pw-post-body-paragraph li lj iq ll b lm ln ka lo lp lq kd lr mf lt lu lv mg lx ly lz mh mb mc md me ij bi translated">在选择评估模型的性能指标时，我们应该记住这一点。例如，如果我们基于<strong class="ll ja">准确性</strong>(正确分类占总分类的比例)来判断模型，我们可以简单地通过将每个实例预测为负面来获得大约88%的分数(考虑到只有12%的训练标签是正面的)。</p><p id="cd5d" class="pw-post-body-paragraph li lj iq ll b lm ln ka lo lp lq kd lr mf lt lu lv mg lx ly lz mh mb mc md me ij bi translated">像<strong class="ll ja">精度</strong>(被正确分类的实际阳性的比例)和<strong class="ll ja">召回</strong>(被正确分类的阳性的比例)这样的度量标准在这种情况下更合适。</p><p id="e1fe" class="pw-post-body-paragraph li lj iq ll b lm ln ka lo lp lq kd lr mf lt lu lv mg lx ly lz mh mb mc md me ij bi translated">2.<em class="lk">阳性类别在标签中的分布不平衡。</em></p><p id="2e10" class="pw-post-body-paragraph li lj iq ll b lm ln ka lo lp lq kd lr mf lt lu lv mg lx ly lz mh mb mc md me ij bi translated">如果我们要使用当前的数据集来训练模型，我们必须接受这样一个事实，即模型可能能够比其他类型更准确地分类一些类型，仅仅是因为数据可用性的增加。</p><p id="9fd6" class="pw-post-body-paragraph li lj iq ll b lm ln ka lo lp lq kd lr mf lt lu lv mg lx ly lz mh mb mc md me ij bi translated">处理这一问题的最有效方法可能是回到数据集汇编阶段，寻找更多的训练数据来源，以修正标签不平衡。这是在改进模型时可以考虑的事情。</p></div><div class="ab cl mw mx hu my" role="separator"><span class="mz bw bk na nb nc"/><span class="mz bw bk na nb nc"/><span class="mz bw bk na nb"/></div><div class="ij ik il im in"><h1 id="1072" class="nd ne iq bd nf ng nh ni nj nk nl nm nn kf no kg np ki nq kj nr kl ns km nt nu bi translated">第三部分:构建分类模型</h1><h2 id="7bea" class="ob ne iq bd nf oc od dn nj oe of dp nn mf og oh np mg oi oj nr mh ok ol nt iw bi translated">自然语言处理</h2><p id="466a" class="pw-post-body-paragraph li lj iq ll b lm nv ka lo lp nw kd lr mf nx lu lv mg ny ly lz mh nz mc md me ij bi translated">目前，我们模型特征的数据仍然是提供它的原始文本格式。为了将数据转换成适合机器学习的格式，我们需要使用一些NLP技术。</p><p id="397d" class="pw-post-body-paragraph li lj iq ll b lm ln ka lo lp lq kd lr mf lt lu lv mg lx ly lz mh mb mc md me ij bi translated">将文本文档集转换成数字特征矩阵所涉及的步骤如下:</p><ol class=""><li id="09eb" class="mi mj iq ll b lm ln lp lq mf mk mg ml mh mm me mn mo mp mq bi translated">清理文本以删除所有标点和特殊字符</li><li id="0c55" class="mi mj iq ll b lm mr lp ms mf mt mg mu mh mv me mn mo mp mq bi translated">将每个文档中的单个单词分成标记</li><li id="6124" class="mi mj iq ll b lm mr lp ms mf mt mg mu mh mv me mn mo mp mq bi translated">对文本进行词汇匹配(将屈折词组合在一起，例如将单词“learning”和“learned”替换为“learn”)</li><li id="702f" class="mi mj iq ll b lm mr lp ms mf mt mg mu mh mv me mn mo mp mq bi translated">从标记中删除空白，并将其设置为小写</li><li id="9d51" class="mi mj iq ll b lm mr lp ms mf mt mg mu mh mv me mn mo mp mq bi translated">删除所有停用词(如“the”、“and”、“of”等)</li><li id="0154" class="mi mj iq ll b lm mr lp ms mf mt mg mu mh mv me mn mo mp mq bi translated">将每个文档矢量化为字数</li><li id="a5df" class="mi mj iq ll b lm mr lp ms mf mt mg mu mh mv me mn mo mp mq bi translated">对每个文档执行词频-逆文档频率(TF-IDF)变换，以基于语料库中的词频平滑计数</li></ol><p id="69dd" class="pw-post-body-paragraph li lj iq ll b lm ln ka lo lp lq kd lr mf lt lu lv mg lx ly lz mh mb mc md me ij bi translated">我们可以将文本清理操作(步骤1–5)编写成一个函数:</p><pre class="kp kq kr ks gt on oo op oq aw or bi"><span id="710e" class="ob ne iq oo b gy os ot l ou ov">def tokenize(text):<br/>    text = re.sub('[^a-zA-Z0-9]', ' ', text)<br/>    tokens = word_tokenize(text)<br/>    lemmatizer = WordNetLemmatizer()<br/>    clean_tokens = (lemmatizer.lemmatize(token).lower().strip() for token in tokens if token \<br/>                    not in stopwords.words('english'))<br/>    return clean_tokens</span></pre><p id="d398" class="pw-post-body-paragraph li lj iq ll b lm ln ka lo lp lq kd lr mf lt lu lv mg lx ly lz mh mb mc md me ij bi translated">然后可以将它作为标记符传递给scikit-learn的<code class="fe ox oy oz oo b">CountVectorizer</code>函数(步骤6)，并用<code class="fe ox oy oz oo b">TfidfTransformer</code>函数结束这个过程(步骤7)。</p><h2 id="3799" class="ob ne iq bd nf oc od dn nj oe of dp nn mf og oh np mg oi oj nr mh ok ol nt iw bi translated">实现机器学习管道</h2><p id="4d04" class="pw-post-body-paragraph li lj iq ll b lm nv ka lo lp nw kd lr mf nx lu lv mg ny ly lz mh nz mc md me ij bi translated">特征变量需要经历NLP变换，然后才能被传递到分类算法中。如果我们要在整个数据集上运行转换，从技术上讲会导致<strong class="ll ja">数据泄漏</strong>，因为计数矢量化和TF-IDF转换将基于来自训练集和测试集的数据。</p><p id="e76e" class="pw-post-body-paragraph li lj iq ll b lm ln ka lo lp lq kd lr mf lt lu lv mg lx ly lz mh mb mc md me ij bi translated">为了解决这个问题，我们可以首先拆分数据，然后运行转换。然而，这将意味着对训练数据完成一次该过程，对测试数据再完成一次，对我们想要分类的任何看不见的数据再完成第三次，这将有些麻烦。</p><p id="81d7" class="pw-post-body-paragraph li lj iq ll b lm ln ka lo lp lq kd lr mf lt lu lv mg lx ly lz mh mb mc md me ij bi translated">规避这个问题的最有效方法是将NLP转换和分类器作为步骤包含在单个<strong class="ll ja">管道</strong>中。使用决策树分类器作为估计器，初始基线模型的管道如下:</p><pre class="kp kq kr ks gt on oo op oq aw or bi"><span id="f97d" class="ob ne iq oo b gy os ot l ou ov">pipeline = Pipeline([<br/>    ('vect', CountVectorizer(tokenizer=tokenize)),<br/>    ('tfidf', TfidfTransformer()),<br/>    ('clf', MultiOutputClassifier(DecisionTreeClassifier()))<br/>    ])</span></pre><p id="87bd" class="pw-post-body-paragraph li lj iq ll b lm ln ka lo lp lq kd lr mf lt lu lv mg lx ly lz mh mb mc md me ij bi translated">注意，我们需要将估计量指定为一个<code class="fe ox oy oz oo b">MultiOutputClassifier</code>。这是为了指示模型应该为每个实例的每个指定流派标签返回一个预测。</p><h2 id="998a" class="ob ne iq bd nf oc od dn nj oe of dp nn mf og oh np mg oi oj nr mh ok ol nt iw bi translated">评估基线模型</h2><p id="a43b" class="pw-post-body-paragraph li lj iq ll b lm nv ka lo lp nw kd lr mf nx lu lv mg ny ly lz mh nz mc md me ij bi translated">如前所述，在评估模型的性能时，需要考虑训练数据中的类别不平衡。为了说明这一点，让我们来看看基线模型的准确性。</p><p id="d29e" class="pw-post-body-paragraph li lj iq ll b lm ln ka lo lp lq kd lr mf lt lu lv mg lx ly lz mh mb mc md me ij bi translated">除了考虑类别不平衡，我们还需要调整一些评估指标，以适应多标签输出，因为与单标签分类不同，每个预测实例不再是严格的对或错。例如，模型对24个可能标签中的20个进行了正确分类的实例应该被认为比没有标签被正确分类的实例更成功。</p><p id="9820" class="pw-post-body-paragraph li lj iq ll b lm ln ka lo lp lq kd lr mf lt lu lv mg lx ly lz mh mb mc md me ij bi translated">对于有兴趣深入研究多标签分类模型评估方法的读者，我可以推荐<a class="ae le" href="http://proceedings.mlr.press/v70/wu17a/wu17a.pdf" rel="noopener ugc nofollow" target="_blank"> <em class="lk">多标签性能度量的统一视图(吴&amp;周，2017) </em> </a>。</p><p id="938f" class="pw-post-body-paragraph li lj iq ll b lm ln ka lo lp lq kd lr mf lt lu lv mg lx ly lz mh mb mc md me ij bi translated">在多标签分类中，一个公认的准确性度量是<strong class="ll ja">汉明损失</strong>:误分类的预测标签总数的分数。从1中减去汉明损失得到一个准确度分数:</p><pre class="kp kq kr ks gt on oo op oq aw or bi"><span id="bb4d" class="ob ne iq oo b gy os ot l ou ov">1 - hamming_loss(y_test, y_pred)<br/>&gt;&gt;&gt; 0.8667440038568157</span></pre><p id="e0b3" class="pw-post-body-paragraph li lj iq ll b lm ln ka lo lp lq kd lr mf lt lu lv mg lx ly lz mh mb mc md me ij bi translated">86.7%的准确率最初看起来是一个很好的结果。然而，在我们打包并认为该项目成功之前，我们需要考虑前面讨论的班级不平衡可能意味着这个分数过于慷慨。</p><p id="8d8e" class="pw-post-body-paragraph li lj iq ll b lm ln ka lo lp lq kd lr mf lt lu lv mg lx ly lz mh mb mc md me ij bi translated">让我们将海明损失与模型的精确度和召回率进行比较。要返回对每个标签的正面类别数进行加权的标签的平均分数，我们可以将<code class="fe ox oy oz oo b">average=’weighted’</code>作为参数传递给函数:</p><pre class="kp kq kr ks gt on oo op oq aw or bi"><span id="634e" class="ob ne iq oo b gy os ot l ou ov">precision_score(y_test, y_pred, average='weighted')<br/>&gt;&gt;&gt; 0.44485346325188513<br/>recall_score(y_test, y_pred, average='weighted')<br/>&gt;&gt;&gt; 0.39102002566871064</span></pre><p id="38d4" class="pw-post-body-paragraph li lj iq ll b lm ln ka lo lp lq kd lr mf lt lu lv mg lx ly lz mh mb mc md me ij bi translated">精确度和召回率的保守得多的结果可能描绘了模型能力的更真实的画面，并表明精确度测量的慷慨是由于真实否定的丰富性。</p><p id="8ac2" class="pw-post-body-paragraph li lj iq ll b lm ln ka lo lp lq kd lr mf lt lu lv mg lx ly lz mh mb mc md me ij bi translated">考虑到这一点，我们将使用<strong class="ll ja"> F1分数</strong>(精确度和召回率之间的调和平均值)作为评估模型的主要指标:</p><pre class="kp kq kr ks gt on oo op oq aw or bi"><span id="70be" class="ob ne iq oo b gy os ot l ou ov">f1_score(y_test, y_pred, average='weighted')<br/>&gt;&gt;&gt; 0.41478130331069335</span></pre><h2 id="04b4" class="ob ne iq bd nf oc od dn nj oe of dp nn mf og oh np mg oi oj nr mh ok ol nt iw bi translated">比较不同标签的性能</h2><p id="492a" class="pw-post-body-paragraph li lj iq ll b lm nv ka lo lp nw kd lr mf nx lu lv mg ny ly lz mh nz mc md me ij bi translated">当探索训练数据时，我们假设由于跨标签的正面类别分布的不平衡，该模型对于一些流派比其他流派表现得更有效。让我们通过找到每个流派标签的F1分数并将其与该流派的培训文档总数进行对比来确定是否是这种情况。</p><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div role="button" tabindex="0" class="ku kv di kw bf kx"><div class="gh gi ow"><img src="../Images/f3b3cb938156de1079b283fd9ae23ed6.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*TLcxt4Wo5DCFFu_jQ5Mn9Q.png"/></div></div><figcaption class="la lb gj gh gi lc ld bd b be z dk translated">图4:培训报价数量和F1基线得分之间的关系</figcaption></figure><p id="3ed6" class="pw-post-body-paragraph li lj iq ll b lm ln ka lo lp lq kd lr mf lt lu lv mg lx ly lz mh mb mc md me ij bi translated">在这里，我们可以观察到一个标签的F1分数与其训练文档总数之间存在相对较强的<strong class="ll ja">正相关</strong>(皮尔逊系数为0.7)，这证实了我们的怀疑。</p><p id="5c6b" class="pw-post-body-paragraph li lj iq ll b lm ln ka lo lp lq kd lr mf lt lu lv mg lx ly lz mh mb mc md me ij bi translated">如前所述，解决这个问题的最佳方法是在构建第二个版本的模型时收集更平衡的数据集。</p><h2 id="ee14" class="ob ne iq bd nf oc od dn nj oe of dp nn mf og oh np mg oi oj nr mh ok ol nt iw bi translated">改进模型:选择分类算法</h2><p id="e163" class="pw-post-body-paragraph li lj iq ll b lm nv ka lo lp nw kd lr mf nx lu lv mg ny ly lz mh nz mc md me ij bi translated">让我们测试一些其他分类算法，看看哪种算法对训练数据产生的结果最好。要做到这一点，我们可以遍历一个配备了处理多标签分类的模型列表，并打印每个模型的加权平均F1分数。</p><p id="1c81" class="pw-post-body-paragraph li lj iq ll b lm ln ka lo lp lq kd lr mf lt lu lv mg lx ly lz mh mb mc md me ij bi translated">在运行循环之前，我们给流水线增加一个额外的步骤:<strong class="ll ja">奇异值分解</strong> ( <code class="fe ox oy oz oo b">TruncatedSVD</code>)。这是一种降维形式，它识别特征矩阵中最有意义的属性，并删除剩余的内容。它类似于主成分分析(PCA)，但可以用于稀疏矩阵。</p><p id="7a47" class="pw-post-body-paragraph li lj iq ll b lm ln ka lo lp lq kd lr mf lt lu lv mg lx ly lz mh mb mc md me ij bi translated">我实际上发现，增加这一步稍微妨碍了模型的得分。然而，它极大地减少了计算运行时间，所以我认为这是一个值得的权衡。</p><p id="cea5" class="pw-post-body-paragraph li lj iq ll b lm ln ka lo lp lq kd lr mf lt lu lv mg lx ly lz mh mb mc md me ij bi translated">我们还应该从通过单次训练和测试分割来评估模型，切换到使用来自<strong class="ll ja">交叉验证</strong>的平均分数，因为这将提供更可靠的性能测量。</p><pre class="kp kq kr ks gt on oo op oq aw or bi"><span id="87ad" class="ob ne iq oo b gy os ot l ou ov">tree = DecisionTreeClassifier()<br/>forest = RandomForestClassifier()<br/>knn = KNeighborsClassifier()</span><span id="9d7a" class="ob ne iq oo b gy pa ot l ou ov">models = [tree, forest, knn]<br/>model_names = ['tree', 'forest', 'knn']</span><span id="67db" class="ob ne iq oo b gy pa ot l ou ov">for model in models:<br/>    pipeline = Pipeline([<br/>    ('vect', CountVectorizer(tokenizer=tokenize)),<br/>    ('tfidf', TfidfTransformer()),<br/>    ('svd', TruncatedSVD()),<br/>    ('clf', MultiOutputClassifier(model))<br/>    ])<br/>    cv_scores = cross_val_score(pipeline, X, y, scoring='f1_weighted', cv=4, n_jobs=-1)<br/>    score = round(np.mean(cv_scores), 4)<br/>    scores.append(score)</span><span id="45ce" class="ob ne iq oo b gy pa ot l ou ov">model_compare = pd.DataFrame({'model': model_names, 'score': scores})</span><span id="8348" class="ob ne iq oo b gy pa ot l ou ov">print(model_compare)<br/>&gt;&gt;&gt; model   score<br/>&gt;&gt;&gt; 0    tree  0.2930<br/>&gt;&gt;&gt; 1  forest  0.2274<br/>&gt;&gt;&gt; 2     knn  0.2284</span></pre><p id="38b4" class="pw-post-body-paragraph li lj iq ll b lm ln ka lo lp lq kd lr mf lt lu lv mg lx ly lz mh mb mc md me ij bi translated">令人惊讶的是，基线模型中使用的决策树实际上产生了所有测试模型中的最佳得分。在我们进行超参数调整时，我们将把它作为我们的估计值。</p><h2 id="049d" class="ob ne iq bd nf oc od dn nj oe of dp nn mf og oh np mg oi oj nr mh ok ol nt iw bi translated">改进模型:调整超参数</h2><p id="ea68" class="pw-post-body-paragraph li lj iq ll b lm nv ka lo lp nw kd lr mf nx lu lv mg ny ly lz mh nz mc md me ij bi translated">作为构建最佳模型的最后一步，我们可以运行交叉验证<strong class="ll ja">网格搜索</strong>来找到参数的最有效值。</p><p id="8ff1" class="pw-post-body-paragraph li lj iq ll b lm ln ka lo lp lq kd lr mf lt lu lv mg lx ly lz mh mb mc md me ij bi translated">因为我们使用管道来拟合模型，所以我们可以定义参数值，不仅测试估计器，还测试NLP阶段，如矢量器。</p><pre class="kp kq kr ks gt on oo op oq aw or bi"><span id="97f6" class="ob ne iq oo b gy os ot l ou ov">pipeline = Pipeline([<br/>    ('vect', CountVectorizer(tokenizer=tokenize)),<br/>    ('tfidf', TfidfTransformer()),<br/>    ('svd', TruncatedSVD()),<br/>    ('clf', MultiOutputClassifier(DecisionTreeClassifier()))<br/>    ])</span><span id="f19e" class="ob ne iq oo b gy pa ot l ou ov">parameters = {<br/>    'vect__ngram_range': [(1, 1), (1, 2)],<br/>    'clf__estimator__max_depth': [250, 500, 1000],<br/>    'clf__estimator__min_samples_split': [1, 2, 6]<br/>}</span><span id="7929" class="ob ne iq oo b gy pa ot l ou ov">cv = GridSearchCV(pipeline, param_grid=parameters, scoring='f1_weighted', cv=4, n_jobs=-1, verbose=10)<br/>cv.fit(X, y)</span></pre><p id="ef5c" class="pw-post-body-paragraph li lj iq ll b lm ln ka lo lp lq kd lr mf lt lu lv mg lx ly lz mh mb mc md me ij bi translated">网格搜索完成后，我们可以查看最终调整模型的参数和分数:</p><pre class="kp kq kr ks gt on oo op oq aw or bi"><span id="68be" class="ob ne iq oo b gy os ot l ou ov">print(cv.best_params_)<br/>&gt;&gt;&gt; {'clf__estimator__max_depth': 500, 'clf__estimator__min_samples_split': 2, 'vect__ngram_range': (1, 1)}<br/>print(cv.best_score_)<br/>&gt;&gt;&gt; 0.29404722954784424</span></pre><p id="3612" class="pw-post-body-paragraph li lj iq ll b lm ln ka lo lp lq kd lr mf lt lu lv mg lx ly lz mh mb mc md me ij bi translated">超参数调整让我们将该车型的性能略微提高了0.1个百分点，最终F1得分为29.4%。这意味着我们可以期望该模型能够正确地对不到三分之一的真阳性进行分类。</p></div><div class="ab cl mw mx hu my" role="separator"><span class="mz bw bk na nb nc"/><span class="mz bw bk na nb nc"/><span class="mz bw bk na nb"/></div><div class="ij ik il im in"><h1 id="aad3" class="nd ne iq bd nf ng nh ni nj nk nl nm nn kf no kg np ki nq kj nr kl ns km nt nu bi translated">结束语</h1><p id="2202" class="pw-post-body-paragraph li lj iq ll b lm nv ka lo lp nw kd lr mf nx lu lv mg ny ly lz mh nz mc md me ij bi translated">总之，我们能够建立一个模型，试图通过对话来预测电影的类型:</p><ol class=""><li id="180d" class="mi mj iq ll b lm ln lp lq mf mk mg ml mh mm me mn mo mp mq bi translated">操纵从康奈尔大学出版物获得的文本语料库以创建训练数据集</li><li id="c861" class="mi mj iq ll b lm mr lp ms mf mt mg mu mh mv me mn mo mp mq bi translated">采用NLP技术将文本数据转换成特征变量矩阵</li><li id="9fd5" class="mi mj iq ll b lm mr lp ms mf mt mg mu mh mv me mn mo mp mq bi translated">使用机器学习流水线构建基线分类器，并通过评估适用于具有显著类别不平衡的多标签分类环境的性能度量来改进模型</li></ol><p id="652b" class="pw-post-body-paragraph li lj iq ll b lm ln ka lo lp lq kd lr mf lt lu lv mg lx ly lz mh mb mc md me ij bi translated">最终模型可用于生成新对话交换的预测。下面的例子引用了《T2》中《灵魂的狂欢》(赫克·哈维，1962) 的一段话:</p><pre class="kp kq kr ks gt on oo op oq aw or bi"><span id="45f1" class="ob ne iq oo b gy os ot l ou ov">def predict_genres(text):<br/>    pred = pd.DataFrame(cv.predict([text]), columns=genres)<br/>    pred = pred.transpose().reset_index()<br/>    pred.columns = ['genre', 'prediction']<br/>    predictions = pred[pred['prediction']==1]['genre'].tolist()<br/>    return predictions</span><span id="9aaa" class="ob ne iq oo b gy pa ot l ou ov">line = "It's funny... the world is so different in the daylight. In the dark, your fantasies get so out of hand. \<br/>But in the daylight everything falls back into place again."</span><span id="50fb" class="ob ne iq oo b gy pa ot l ou ov">print(predict_genres(line))<br/>&gt;&gt;&gt; ['family', 'scifi', 'thriller']</span></pre><p id="41fb" class="pw-post-body-paragraph li lj iq ll b lm ln ka lo lp lq kd lr mf lt lu lv mg lx ly lz mh mb mc md me ij bi translated">最后的结论是什么？我们能向IMDb提议采用我们的模式作为自动分类的手段吗？现阶段，大概不会。然而，这篇文章中创建的模型应该是一个足够好的起点，有机会在未来的版本中进行改进，例如，编译一个更大的数据集，在不同类型之间更加平衡。</p><p id="51a3" class="pw-post-body-paragraph li lj iq ll b lm ln ka lo lp lq kd lr mf lt lu lv mg lx ly lz mh mb mc md me ij bi translated">对下载数据集、运行ETL管道或检查构建模型的代码感兴趣的读者可以在我的<a class="ae le" href="https://github.com/harryroper96/movie_dialogue_clf" rel="noopener ugc nofollow" target="_blank"> Github </a>的这个资源库中这样做。随时欢迎关于改进模型的反馈、问题和建议。</p></div><div class="ab cl mw mx hu my" role="separator"><span class="mz bw bk na nb nc"/><span class="mz bw bk na nb nc"/><span class="mz bw bk na nb"/></div><div class="ij ik il im in"><h1 id="be02" class="nd ne iq bd nf ng nh ni nj nk nl nm nn kf no kg np ki nq kj nr kl ns km nt nu bi translated">承认</h1><p id="0f62" class="pw-post-body-paragraph li lj iq ll b lm nv ka lo lp nw kd lr mf nx lu lv mg ny ly lz mh nz mc md me ij bi translated">克里斯蒂安·达内斯库-尼古列斯库-米齐尔。<a class="ae le" href="https://www.cs.cornell.edu/~cristian/Cornell_Movie-Dialogs_Corpus.html" rel="noopener ugc nofollow" target="_blank"> <em class="lk">康奈尔电影—对话文集</em> </a>。康奈尔大学2011</p><p id="fa0d" class="pw-post-body-paragraph li lj iq ll b lm ln ka lo lp lq kd lr mf lt lu lv mg lx ly lz mh mb mc md me ij bi translated">Xi-朱武和周志华。<a class="ae le" href="http://proceedings.mlr.press/v70/wu17a/wu17a.pdf" rel="noopener ugc nofollow" target="_blank"> <em class="lk">多标签绩效指标的统一视图</em> </a> <em class="lk">。</em> ICML青奥会</p></div></div>    
</body>
</html>