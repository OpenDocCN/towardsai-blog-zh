<html>
<head>
<title>StyleGAN Generated Face Classification with ResNexts</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">用ResNexts生成人脸分类</h1>
<blockquote>原文：<a href="https://pub.towardsai.net/stylegan-generated-face-classification-with-resnexts-19535ed1d91d?source=collection_archive---------0-----------------------#2019-09-28">https://pub.towardsai.net/stylegan-generated-face-classification-with-resnexts-19535ed1d91d?source=collection_archive---------0-----------------------#2019-09-28</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><h2 id="1af0" class="io ip iq bd b dl ir is it iu iv iw dk ix translated" aria-label="kicker paragraph">对AI使用带有StyleGAN | <a class="ae ep" href="https://towardsai.net" rel="noopener ugc nofollow" target="_blank">的ResNexts】</a></h2><div class=""/><figure class="gl gn jw jx jy jz"><div class="bz fp l di"><div class="ka kb l"/></div><figcaption class="kc kd gj gh gi ke kf bd b be z dk translated">https://generated.photos</figcaption></figure><p id="4bcd" class="pw-post-body-paragraph kg kh iq ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld ij bi translated">一两周前，一个团队发布了一个由10万张生成人脸图像组成的数据集，这些图像基于StyleGAN [ <em class="le"> Karras等人和NVIDIA] </em> <a class="ae lf" href="https://arxiv.org/pdf/1812.04948.pdf" rel="noopener ugc nofollow" target="_blank"> <em class="le">(见论文)</em> </a> <em class="le">。</em></p><p id="cfbd" class="pw-post-body-paragraph kg kh iq ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld ij bi translated">不久前，我们在<a class="ae lf" href="https://www.thispersondoesnotexist.com" rel="noopener ugc nofollow" target="_blank">https://www.thispersondoesnotexist.com</a>上看到类似的技术开放给公众互动，基本上为网站的每次访问生成一个全新的面孔。</p><p id="0008" class="pw-post-body-paragraph kg kh iq ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld ij bi translated">网络是健全的，工作令人印象深刻，这是肯定的。老实说，我们这些ML/DL领域的人，特别是如果你玩过GANs，熟悉计算机视觉的话，可以以某种方式检测出伪造。</p><p id="c20a" class="pw-post-body-paragraph kg kh iq ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld ij bi translated">无论如何，让我分享几个在大多数情况下生成图像的危险信号:</p><h2 id="f423" class="lg lh iq bd li lj lk dn ll lm ln dp lo kr lp lq lr kv ls lt lu kz lv lw lx iw bi translated">1.像素扰动</h2><p id="fcc7" class="pw-post-body-paragraph kg kh iq ki b kj ly kl km kn lz kp kq kr ma kt ku kv mb kx ky kz mc lb lc ld ij bi translated">许多几乎完美的生成图像有残缺的像素，看起来像<br/>“洞”。</p><figure class="me mf mg mh gt jz gh gi paragraph-image"><div role="button" tabindex="0" class="mi mj di mk bf ml"><div class="gh gi md"><img src="../Images/355e913d187fe32a1552c96b582860da.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*2-0i1Q-FKVduymcWoA_hnA.png"/></div></div><figcaption class="kc kd gj gh gi ke kf bd b be z dk translated">从https://generated.photos中检索</figcaption></figure><h2 id="f395" class="lg lh iq bd li lj lk dn ll lm ln dp lo kr lp lq lr kv ls lt lu kz lv lw lx iw bi translated">2.不对称</h2><p id="052d" class="pw-post-body-paragraph kg kh iq ki b kj ly kl km kn lz kp kq kr ma kt ku kv mb kx ky kz mc lb lc ld ij bi translated">物体是不对称的。在这种情况下，眼镜的两面是不同的。</p><figure class="me mf mg mh gt jz gh gi paragraph-image"><div role="button" tabindex="0" class="mi mj di mk bf ml"><div class="gh gi md"><img src="../Images/963db160c783bd3879471fcad139714e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*256-q4iPEYZDm2hdBlKDPg.png"/></div></div><figcaption class="kc kd gj gh gi ke kf bd b be z dk translated">从https://generated.photos中检索</figcaption></figure><h2 id="c50a" class="lg lh iq bd li lj lk dn ll lm ln dp lo kr lp lq lr kv ls lt lu kz lv lw lx iw bi translated">3.奇怪的侧物，不对称的牙齿。</h2><p id="22d0" class="pw-post-body-paragraph kg kh iq ki b kj ly kl km kn lz kp kq kr ma kt ku kv mb kx ky kz mc lb lc ld ij bi translated">为了防止图像上出现另一个物体，我们破坏了它的概念。在这幅图像中，我们看到了一个人的想法，但它似乎很怪异。</p><figure class="me mf mg mh gt jz gh gi paragraph-image"><div role="button" tabindex="0" class="mi mj di mk bf ml"><div class="gh gi md"><img src="../Images/d1adde1c60b16ba62d3883ea1c76e30e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*V_SBCkD4Vbb9NON7VOdJ5g.png"/></div></div><figcaption class="kc kd gj gh gi ke kf bd b be z dk translated">检索自<a class="ae lf" href="https://generated.photos" rel="noopener ugc nofollow" target="_blank">https://generated . photos</a></figcaption></figure><h2 id="c51e" class="lg lh iq bd li lj lk dn ll lm ln dp lo kr lp lq lr kv ls lt lu kz lv lw lx iw bi translated">4.不对称的牙齿，奇怪的侧物</h2><p id="5b1e" class="pw-post-body-paragraph kg kh iq ki b kj ly kl km kn lz kp kq kr ma kt ku kv mb kx ky kz mc lb lc ld ij bi translated">又是不对称和奇怪的物体，但在这种情况下，牙齿的不对称被清楚地展示出来，物体给我们的感觉就像我们知道它是什么，但不能描述它。</p><figure class="me mf mg mh gt jz gh gi paragraph-image"><div role="button" tabindex="0" class="mi mj di mk bf ml"><div class="gh gi md"><img src="../Images/568b285e6b0baaccbc3f4b8c71e1fd12.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*KZxLbMU9PC6WpBeP9JmAXA.png"/></div></div><figcaption class="kc kd gj gh gi ke kf bd b be z dk translated">检索自<a class="ae lf" href="https://generated.photos" rel="noopener ugc nofollow" target="_blank">https://generated . photos</a></figcaption></figure><h2 id="41da" class="lg lh iq bd li lj lk dn ll lm ln dp lo kr lp lq lr kv ls lt lu kz lv lw lx iw bi translated">5.人造皮肤</h2><p id="6ce8" class="pw-post-body-paragraph kg kh iq ki b kj ly kl km kn lz kp kq kr ma kt ku kv mb kx ky kz mc lb lc ld ij bi translated">生成的图像中的皮肤结构不良。过渡、高光和锐度很容易识别。</p><figure class="me mf mg mh gt jz gh gi paragraph-image"><div role="button" tabindex="0" class="mi mj di mk bf ml"><div class="gh gi mo"><img src="../Images/0a00f69416cd00c7474ca36acdaf1480.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*nTymJlaLqrS6dqOTQwHcwQ.jpeg"/></div></div><figcaption class="kc kd gj gh gi ke kf bd b be z dk translated">检索自<a class="ae lf" href="https://generated.photos" rel="noopener ugc nofollow" target="_blank">https://generated . photos</a></figcaption></figure><h2 id="a010" class="lg lh iq bd li lj lk dn ll lm ln dp lo kr lp lq lr kv ls lt lu kz lv lw lx iw bi translated">6.头发</h2><p id="db52" class="pw-post-body-paragraph kg kh iq ki b kj ly kl km kn lz kp kq kr ma kt ku kv mb kx ky kz mc lb lc ld ij bi translated">头发在大多数情况下是杂乱的，并且与不同的物体、皮肤或背景混合在一起。</p><figure class="me mf mg mh gt jz gh gi paragraph-image"><div role="button" tabindex="0" class="mi mj di mk bf ml"><div class="gh gi mo"><img src="../Images/f4e4e10467276d1def522561e9791a68.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*80h8nzqAMlTDO--Acw1Iqw.jpeg"/></div></div><figcaption class="kc kd gj gh gi ke kf bd b be z dk translated">检索自<a class="ae lf" href="https://generated.photos" rel="noopener ugc nofollow" target="_blank">https://generated . photos</a></figcaption></figure><h1 id="efb8" class="mp lh iq bd li mq mr ms ll mt mu mv lo mw mx my lr mz na nb lu nc nd ne lx nf bi translated"><em class="ng">数据使用义务</em></h1><p id="5cf6" class="pw-post-body-paragraph kg kh iq ki b kj ly kl km kn lz kp kq kr ma kt ku kv mb kx ky kz mc lb lc ld ij bi translated">嗯，当你看到一个免费的公开数据时，很难不去尝试一下。生成的图像可免费用于商业和研究目的<em class="le">，“只是为了链接回它们”</em>，如使用条款所述。</p><p id="323e" class="pw-post-body-paragraph kg kh iq ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld ij bi translated">说到<a class="ae lf" href="https://colab.research.google.com" rel="noopener ugc nofollow" target="_blank"><strong class="ki ja">Google Colab</strong></a><strong class="ki ja"/>依赖者，出于几个原因，收集全部数据确实很有挑战性，比如a .在添加到我的驱动器时没有完全访问权限。b .嗯，有100K的图像，<strong class="ki ja"> Colab </strong>在读/写(移动、复制)媒体文件的情况下确实很慢。</p><p id="6c23" class="pw-post-body-paragraph kg kh iq ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld ij bi translated">并且，我选择使用CelebA图像作为<strong class="ki ja">【True】</strong>类。<br/>所以:<em class="le">真实图像</em> : <strong class="ki ja">真</strong>，<em class="le">生成图像</em> : <strong class="ki ja">假</strong></p><p id="6b7c" class="pw-post-body-paragraph kg kh iq ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld ij bi translated">在分析数据集时，我注意到了一些差异和相似之处:</p><ol class=""><li id="a78d" class="nh ni iq ki b kj kk kn ko kr nj kv nk kz nl ld nm nn no np bi translated">嗯，—质量。CelebA对齐的图像是像素化的，质量较低，而StyleGAN生成的图像具有<strong class="ki ja">超分辨率(1024x1024) </strong></li><li id="bfd6" class="nh ni iq ki b kj nq kn nr kr ns kv nt kz nu ld nm nn no np bi translated">背景多样性CelebA图像中呈现了各种背景，如横幅、田野、汽车等。但是，在生成的情况下，我们有几乎相同的背景。</li><li id="441f" class="nh ni iq ki b kj nq kn nr kr ns kv nt kz nu ld nm nn no np bi translated">亮度——CelebA图像自然突出显示，而stylegan图像生成了合成光。</li></ol><figure class="me mf mg mh gt jz gh gi paragraph-image"><div role="button" tabindex="0" class="mi mj di mk bf ml"><div class="gh gi nv"><img src="../Images/c1ca7d5e2c48c9d8c0c12044657cc2ee.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*09WS9xTaPu1z-7tVyKoyTw.png"/></div></div></figure><p id="b74a" class="pw-post-body-paragraph kg kh iq ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld ij bi translated">在这种情况下，模型将很容易过度拟合数据，这是肯定的。<br/>说得更清楚一点——我并不是在构建一个最优的假脸检测器，只是试图对这些规格生成的图像进行分类。所以，一点点过度拟合不是一个大问题。</p><p id="9829" class="pw-post-body-paragraph kg kh iq ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld ij bi translated">我在PyTorch中工作，除了<strong class="ki ja"> <em class="le">水平/垂直翻转</em> </strong> <em class="le">和</em> <strong class="ki ja"> <em class="le">颜色抖动:</em> </strong></p><h2 id="36eb" class="lg lh iq bd li lj lk dn ll lm ln dp lo kr lp lq lr kv ls lt lu kz lv lw lx iw bi translated">Clache过滤(直方图均衡算法):</h2><p id="d9cb" class="pw-post-body-paragraph kg kh iq ki b kj ly kl km kn lz kp kq kr ma kt ku kv mb kx ky kz mc lb lc ld ij bi translated">我们取3个通道(LAB ),其中(L)通道表示图像上的白色强度，</p><p id="fcb6" class="pw-post-body-paragraph kg kh iq ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld ij bi translated">并且在黑色(0)和白色(100)之间计算。</p><p id="ecf9" class="pw-post-body-paragraph kg kh iq ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld ij bi translated">绿色(-)和红色(+)之间的通道</p><p id="640b" class="pw-post-body-paragraph kg kh iq ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld ij bi translated">b通道—介于蓝色(-)和黄色(+)之间</p><figure class="me mf mg mh gt jz gh gi paragraph-image"><div role="button" tabindex="0" class="mi mj di mk bf ml"><div class="gh gi nw"><img src="../Images/082037dc17a7e0a33eac8c8df33fe574.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*unJuGVaQfQLPWsL4IQJvpQ.png"/></div></div></figure><p id="423e" class="pw-post-body-paragraph kg kh iq ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld ij bi translated">并且，图像<em class="le"> g </em>的直方图均衡化将表示为</p><figure class="me mf mg mh gt jz gh gi paragraph-image"><div role="button" tabindex="0" class="mi mj di mk bf ml"><div class="gh gi nx"><img src="../Images/0f5aa191adfe98727d296ee7c4cdd27f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*tdJf2LSCwo8BNEdq0LLRxQ.png"/></div></div></figure><h2 id="68c4" class="lg lh iq bd li lj lk dn ll lm ln dp lo kr lp lq lr kv ls lt lu kz lv lw lx iw bi translated"><strong class="ak">亮度和对比度正常化</strong></h2><figure class="me mf mg mh gt jz gh gi paragraph-image"><div role="button" tabindex="0" class="mi mj di mk bf ml"><div class="gh gi nv"><img src="../Images/3660e240886ffebbd997cb7312f0edf3.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*6JoBaEIlA9zzMvqTGNCD5Q.png"/></div></div><figcaption class="kc kd gj gh gi ke kf bd b be z dk translated">CLACHE和B/C规范化</figcaption></figure><p id="91a6" class="pw-post-body-paragraph kg kh iq ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld ij bi translated">通过应用亮度和对比度标准化和CLACHE预处理的图像似乎可以区分图像的异常并使其尽可能清晰。<br/>图像被调整到<strong class="ki ja"> 299x299。</strong></p><h1 id="1b9d" class="mp lh iq bd li mq mr ms ll mt mu mv lo mw mx my lr mz na nb lu nc nd ne lx nf bi translated">ResNeXt</h1><p id="e167" class="pw-post-body-paragraph kg kh iq ki b kj ly kl km kn lz kp kq kr ma kt ku kv mb kx ky kz mc lb lc ld ij bi translated">想法是通过完成以下步骤使用torchvision预训练的ResNeXt-101模型:</p><ol class=""><li id="9d85" class="nh ni iq ki b kj kk kn ko kr nj kv nk kz nl ld nm nn no np bi translated">仅培训网络负责人[ <strong class="ki ja"> <em class="le"> lr=1e-3，SGD </em> </strong> ]</li><li id="5b7d" class="nh ni iq ki b kj nq kn nr kr ns kv nt kz nu ld nm nn no np bi translated">训练层4及以上[ <strong class="ki ja"> <em class="le"> lr=1e-3，SGD </em> </strong> ]</li><li id="af34" class="nh ni iq ki b kj nq kn nr kr ns kv nt kz nu ld nm nn no np bi translated">训练全网[ <strong class="ki ja"> <em class="le"> lr=1e-4，SGD </em> </strong> ]</li></ol><h1 id="c217" class="mp lh iq bd li mq mr ms ll mt mu mv lo mw mx my lr mz na nb lu nc nd ne lx nf bi translated">培训和结果</h1><pre class="me mf mg mh gt ny nz oa ob aw oc bi"><span id="27ef" class="lg lh iq nz b gy od oe l of og">Epoch 1 Train loss: 0.452.. Test loss: 0.495.. Test accuracy: 0.795 Epoch 1 Train loss: 0.363.. Test loss: 0.400.. Test accuracy: 0.827 Epoch 2 Train loss: 0.302.. Test loss: 0.331.. Test accuracy: 0.843 Epoch 2 Train loss: 0.166.. Test loss: 0.271.. Test accuracy: 0.880 Epoch 3 Train loss: 0.015.. Test loss: 0.252.. Test accuracy: 0.909 Epoch 3 Train loss: 0.062.. Test loss: 0.194.. Test accuracy: 0.911 Epoch 4 Train loss: 0.108.. Test loss: 0.183.. Test accuracy: 0.936 Epoch 4 Train loss: 0.029.. Test loss: 0.142.. Test accuracy: 0.964 Epoch 5 Train loss: 0.279.. Test loss: 0.135.. Test accuracy: 0.968 Epoch 5 Train loss: 0.119.. Test loss: 0.110.. Test accuracy: 0.973</span></pre><p id="91df" class="pw-post-body-paragraph kg kh iq ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld ij bi translated">该模型在测试集上显示了非常有希望的结果。而且，只要在大多数情况下，模型的表现与它们在测试集中表现的方式不同，这种情况的发生有很多原因:调优不佳、数据不规范等等。，我总是尝试在看不见的数据上手动测试它们。</p></div><div class="ab cl oh oi hu oj" role="separator"><span class="ok bw bk ol om on"/><span class="ok bw bk ol om on"/><span class="ok bw bk ol om"/></div><div class="ij ik il im in"><p id="85b7" class="pw-post-body-paragraph kg kh iq ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld ij bi translated">通过选择<strong class="ki ja"> <em class="le"> 100张真的</em> </strong>和<strong class="ki ja"> <em class="le"> 100张假的</em> </strong>图片进行手动验证，我最终只有3个错误，但在验证程序后预测我的社交媒体个人资料图片时，模型完全混乱了。</p></div><div class="ab cl oh oi hu oj" role="separator"><span class="ok bw bk ol om on"/><span class="ok bw bk ol om on"/><span class="ok bw bk ol om"/></div><div class="ij ik il im in"><p id="7585" class="pw-post-body-paragraph kg kh iq ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld ij bi translated">整篇文章的想法是鼓励人们测试自己的想法，尝试不同的方法来检测虚假生成的数据，即使你可能没有太多的时间来微调模型，以便在不同的领域进行研究。因为，你的工作可能会对其他人有所启发，我们真的可以看到令人印象深刻的GANs用于非法目的的潜在风险。</p><h2 id="440f" class="lg lh iq bd li lj lk dn ll lm ln dp lo kr lp lq lr kv ls lt lu kz lv lw lx iw bi translated">调整模型的链接:</h2><div class="oo op gp gr oq or"><a href="https://drive.google.com/drive/folders/1QRvun5knO4Awo2hcl0C1INPkHO5UdNMf?usp=sharing" rel="noopener  ugc nofollow" target="_blank"><div class="os ab fo"><div class="ot ab ou cl cj ov"><h2 class="bd ja gy z fp ow fr fs ox fu fw iz bi translated">ResNext101 - Google Drive</h2><div class="oy l"><h3 class="bd b gy z fp ow fr fs ox fu fw dk translated">编辑描述</h3></div><div class="oz l"><p class="bd b dl z fp ow fr fs ox fu fw dk translated">drive.google.com</p></div></div><div class="pa l"><div class="pb l pc pd pe pa pf mm or"/></div></div></a></div><p id="92b7" class="pw-post-body-paragraph kg kh iq ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld ij bi translated"><strong class="ki ja"> <em class="le">只需用torch.load()函数加载，声明classes = ['generated '，' groundtruth']，即可使用。</em>T12】</strong></p></div></div>    
</body>
</html>