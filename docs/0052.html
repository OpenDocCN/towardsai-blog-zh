<html>
<head>
<title>Importance of K-Fold Cross Validation in Machine Learning</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">K重交叉验证在机器学习中的重要性</h1>
<blockquote>原文：<a href="https://pub.towardsai.net/importance-of-k-fold-cross-validation-in-machine-learning-a0d76f49493e?source=collection_archive---------1-----------------------#2019-05-21">https://pub.towardsai.net/importance-of-k-fold-cross-validation-in-machine-learning-a0d76f49493e?source=collection_archive---------1-----------------------#2019-05-21</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><figure class="ip iq gp gr ir is gh gi paragraph-image"><div role="button" tabindex="0" class="it iu di iv bf iw"><div class="gh gi io"><img src="../Images/d617c5d24958f9c85e4047ea2af6d473.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*UqLLVbMTlPYJOnb7xfukLw.jpeg"/></div></div><figcaption class="iz ja gj gh gi jb jc bd b be z dk translated">图片来源:Unsplash</figcaption></figure><h2 id="f551" class="jd je jf bd b dl jg jh ji jj jk jl dk jm translated" aria-label="kicker paragraph">K-Fold交叉验证| <a class="ae ep" href="https://towardsai.net" rel="noopener ugc nofollow" target="_blank">朝向AI </a></h2><div class=""/><blockquote class="kl"><p id="37df" class="km kn jf bd ko kp kq kr ks kt ku kv dk translated"><em class="kw">将数据输入我们的模型之前最重要的步骤之一</em></p></blockquote><p id="7499" class="pw-post-body-paragraph kx ky jf kz b la lb lc ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt kv ij bi translated">在我们开始为数据训练模型之前，我们通常会进行交叉验证过程。对于机器学习流水线来说，这是非常重要的一点。</p><p id="ba7e" class="pw-post-body-paragraph kx ky jf kz b la lu lc ld le lv lg lh li lw lk ll lm lx lo lp lq ly ls lt kv ij bi translated">在本文中，我们将更详细地了解K折叠的重要性，以及通过各种随机样本来查看数据是一个多么重要的过程。</p><h1 id="da83" class="lz ma jf bd mb mc md me mf mg mh mi mj mk ml mm mn mo mp mq mr ms mt mu mv mw bi translated">什么是K-Fold交叉验证？</h1><blockquote class="mx my mz"><p id="5a28" class="kx ky na kz b la lu lc ld le lv lg lh nb lw lk ll nc lx lo lp nd ly ls lt kv ij bi translated">交叉验证是一种统计方法，用于评估机器学习模型的技能。交叉验证是一种重采样过程，用于在有限的数据样本上评估机器学习模型。</p></blockquote><p id="b26c" class="pw-post-body-paragraph kx ky jf kz b la lu lc ld le lv lg lh li lw lk ll lm lx lo lp lq ly ls lt kv ij bi translated">这是一种流行的方法，因为它易于理解，并且与其他方法(例如简单的训练/测试分割)相比，它通常会导致对模型技能的更少偏差或更少乐观的估计。</p><p id="61b2" class="pw-post-body-paragraph kx ky jf kz b la lu lc ld le lv lg lh li lw lk ll lm lx lo lp lq ly ls lt kv ij bi translated">KFold将提供训练/测试索引，将数据分成训练和测试集。它会将数据集分割成<strong class="kz jp"> k </strong>个连续的折叠(默认情况下没有洗牌)。然后，每个折叠被用作一次验证集，而剩余的<strong class="kz jp"> k-1 </strong>折叠形成训练集。</p><figure class="nf ng nh ni gt is gh gi paragraph-image"><div role="button" tabindex="0" class="it iu di iv bf iw"><div class="gh gi ne"><img src="../Images/3a28a2b946ec2d7b83fed3421313394b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*hSbO4bhAT4cnmQX8N2RYcQ.jpeg"/></div></div></figure><p id="858a" class="pw-post-body-paragraph kx ky jf kz b la lu lc ld le lv lg lh li lw lk ll lm lx lo lp lq ly ls lt kv ij bi translated">一般程序如下:</p><ol class=""><li id="b48c" class="nj nk jf kz b la lu le lv li nl lm nm lq nn kv no np nq nr bi translated">随机打乱数据集。</li><li id="a922" class="nj nk jf kz b la ns le nt li nu lm nv lq nw kv no np nq nr bi translated">将数据集分成k个组</li><li id="a621" class="nj nk jf kz b la ns le nt li nu lm nv lq nw kv no np nq nr bi translated">对于每个独特的组:</li><li id="7dec" class="nj nk jf kz b la ns le nt li nu lm nv lq nw kv no np nq nr bi translated">将该组作为维持或测试数据集</li><li id="0b5f" class="nj nk jf kz b la ns le nt li nu lm nv lq nw kv no np nq nr bi translated">将剩余的组作为训练数据集</li><li id="dfce" class="nj nk jf kz b la ns le nt li nu lm nv lq nw kv no np nq nr bi translated">在训练集上拟合模型，并在测试集上评估它</li><li id="a686" class="nj nk jf kz b la ns le nt li nu lm nv lq nw kv no np nq nr bi translated">保留评估分数并丢弃模型</li><li id="6899" class="nj nk jf kz b la ns le nt li nu lm nv lq nw kv no np nq nr bi translated">使用模型评估分数的样本总结模型的技巧</li></ol><figure class="nf ng nh ni gt is gh gi paragraph-image"><div role="button" tabindex="0" class="it iu di iv bf iw"><div class="gh gi nx"><img src="../Images/e582b537a27e2045c82e672e434b2931.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*kXiA1jnxwE7UoLCkHOg7Cw.png"/></div></div><figcaption class="iz ja gj gh gi jb jc bd b be z dk translated">K型褶皱的一般加工</figcaption></figure><h1 id="1c46" class="lz ma jf bd mb mc md me mf mg mh mi mj mk ml mm mn mo mp mq mr ms mt mu mv mw bi translated">K型褶皱的构型</h1><p id="b0b9" class="pw-post-body-paragraph kx ky jf kz b la ny lc ld le nz lg lh li oa lk ll lm ob lo lp lq oc ls lt kv ij bi translated">对于我们的数据样本，必须仔细选择k值。</p><p id="b3da" class="pw-post-body-paragraph kx ky jf kz b la lu lc ld le lv lg lh li lw lk ll lm lx lo lp lq ly ls lt kv ij bi translated">选择不当的k值可能会导致对模型技能的错误描述，如具有高方差的分数(可能会根据用于拟合模型的数据发生很大变化)，或高偏差(如对模型技能的高估)。</p><p id="9e35" class="pw-post-body-paragraph kx ky jf kz b la lu lc ld le lv lg lh li lw lk ll lm lx lo lp lq ly ls lt kv ij bi translated">现在，为<strong class="kz jp"> k </strong>选择一个值有三种常用策略，如下所示:</p><ul class=""><li id="ab06" class="nj nk jf kz b la lu le lv li nl lm nm lq nn kv od np nq nr bi translated"><strong class="kz jp">代表</strong>:选择k值，使每个训练/测试组的数据样本足够大，能够在统计上代表更广泛的数据集。</li><li id="3309" class="nj nk jf kz b la ns le nt li nu lm nv lq nw kv od np nq nr bi translated"><strong class="kz jp">k = 10</strong>:k的值固定为10，这是一个通过实验发现的值，通常会导致模型技能估计具有较低的偏差和适度的方差。</li><li id="3381" class="nj nk jf kz b la ns le nt li nu lm nv lq nw kv od np nq nr bi translated"><strong class="kz jp">k = n</strong>:k的值固定为n，其中n是数据集的大小，为每个测试样本提供在维持数据集中使用的机会。这种方法被称为留一交叉验证。</li></ul><h1 id="d9be" class="lz ma jf bd mb mc md me mf mg mh mi mj mk ml mm mn mo mp mq mr ms mt mu mv mw bi translated">K型褶皱的类型</h1><p id="226c" class="pw-post-body-paragraph kx ky jf kz b la ny lc ld le nz lg lh li oa lk ll lm ob lo lp lq oc ls lt kv ij bi translated"><strong class="kz jp">层状K褶皱:</strong></p><ul class=""><li id="0936" class="nj nk jf kz b la lu le lv li nl lm nm lq nn kv od np nq nr bi translated">StratifiedKFold是KFold的变体。首先，StratifiedKFold打乱我们的数据，之后将数据分割成<strong class="kz jp"> n_splits </strong>个部分并完成。现在，它将使用每个部分作为测试集。请注意，<strong class="kz jp">在分割之前，它只会并且总是将数据混洗一次</strong>。</li></ul><p id="afcd" class="pw-post-body-paragraph kx ky jf kz b la lu lc ld le lv lg lh li lw lk ll lm lx lo lp lq ly ls lt kv ij bi translated">使用<strong class="kz jp"> shuffle=True </strong>，数据被我们的random_state打乱。否则数据被<strong class="kz jp"> np.random </strong>洗牌(默认)。比如<strong class="kz jp"> n_splits= 4 </strong>，我们的数据对于y(因变量)有3类(标签)。4个测试集覆盖所有数据，没有任何重叠。</p><figure class="nf ng nh ni gt is gh gi paragraph-image"><div class="gh gi oe"><img src="../Images/d4c5a875a5e8f49affa4b86b52afe2c9.png" data-original-src="https://miro.medium.com/v2/resize:fit:1124/format:webp/1*KABnsLInvF3Yv2XBJduJng.png"/></div><figcaption class="iz ja gj gh gi jb jc bd b be z dk translated">层状K形褶皱在起作用</figcaption></figure><p id="d6ab" class="pw-post-body-paragraph kx ky jf kz b la lu lc ld le lv lg lh li lw lk ll lm lx lo lp lq ly ls lt kv ij bi translated"><strong class="kz jp">分层洗牌K倍:</strong></p><ul class=""><li id="2820" class="nj nk jf kz b la lu le lv li nl lm nm lq nn kv od np nq nr bi translated"><strong class="kz jp"> StratifiedShuffleSplit </strong>是ShuffleSplit的变种。首先，StratifiedShuffleSplit打乱了我们的数据，然后它还将数据拆分成n_splits个部分。然而，它还没有完成。在这一步之后，StratifiedShuffleSplit立即挑选一部分作为测试集。然后重复相同的过程n_splits-1次，以得到<strong class="kz jp"> n_splits-1 </strong>个其他测试集。如果我们看下面的图片，有相同的数据，4个测试集没有覆盖所有的数据，即测试集之间有重叠。</li></ul><figure class="nf ng nh ni gt is gh gi paragraph-image"><div class="gh gi of"><img src="../Images/64a94efb0987afd1c61e99c9958e476e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1166/format:webp/1*nj5iAv-WxXWF7g_-lKKS7g.png"/></div><figcaption class="iz ja gj gh gi jb jc bd b be z dk translated">层状褶皱</figcaption></figure><p id="1f3b" class="pw-post-body-paragraph kx ky jf kz b la lu lc ld le lv lg lh li lw lk ll lm lx lo lp lq ly ls lt kv ij bi translated">所以，这里的区别在于，StratifiedKFold <strong class="kz jp">只洗牌和拆分一次，因此测试集不会重叠</strong>，而StratifiedShuffleSplit <strong class="kz jp">每次洗牌后都会拆分</strong> n_splits <strong class="kz jp">次，这样测试集就可以重叠</strong>。</p><h1 id="22f1" class="lz ma jf bd mb mc md me mf mg mh mi mj mk ml mm mn mo mp mq mr ms mt mu mv mw bi translated">结论</h1><p id="8b24" class="pw-post-body-paragraph kx ky jf kz b la ny lc ld le nz lg lh li oa lk ll lm ob lo lp lq oc ls lt kv ij bi translated"><em class="na">在k重交叉验证中，存在与k的选择相关的偏差-方差权衡。我们使用</em> <strong class="kz jp"> <em class="na"> k = 5或k = 10 </em> </strong> <em class="na">进行k重交叉验证，因为这些值已经被经验地显示为产生测试误差率估计值，其既不遭受过高的偏差，也不遭受非常高的方差。</em></p><blockquote class="mx my mz"><p id="741a" class="kx ky na kz b la lu lc ld le lv lg lh nb lw lk ll nc lx lo lp nd ly ls lt kv ij bi translated">如果选择的k值没有平均分割数据样本，则一个组将包含剩余的示例。优选地，将数据样本分成k个具有相同样本数量的组，使得模型技能得分的样本全部相等。</p></blockquote><h1 id="dbf9" class="lz ma jf bd mb mc md me mf mg mh mi mj mk ml mm mn mo mp mq mr ms mt mu mv mw bi translated">进一步阅读</h1><div class="ip iq gp gr ir og"><a href="https://machinelearningmastery.com/k-fold-cross-validation/" rel="noopener  ugc nofollow" target="_blank"><div class="oh ab fo"><div class="oi ab oj cl cj ok"><h2 class="bd jp gy z fp ol fr fs om fu fw jo bi translated">k-fold交叉验证的简单介绍</h2><div class="on l"><h3 class="bd b gy z fp ol fr fs om fu fw dk translated">交叉验证是一种统计方法，用于评估机器学习模型的技能。它通常用于…</h3></div><div class="oo l"><p class="bd b dl z fp ol fr fs om fu fw dk translated">machinelearningmastery.com</p></div></div><div class="op l"><div class="oq l or os ot op ou ix og"/></div></div></a></div><div class="ip iq gp gr ir og"><a href="https://www.analyticsvidhya.com/blog/2018/05/improve-model-performance-cross-validation-in-python-r/" rel="noopener  ugc nofollow" target="_blank"><div class="oh ab fo"><div class="oi ab oj cl cj ok"><h2 class="bd jp gy z fp ol fr fs om fu fw jo bi translated">使用交叉验证(在Python和R中)提高模型性能</h2><div class="on l"><h3 class="bd b gy z fp ol fr fs om fu fw dk translated">数据科学黑客马拉松最有趣和最具挑战性的事情之一是在两个公共领域获得高分…</h3></div><div class="oo l"><p class="bd b dl z fp ol fr fs om fu fw dk translated">www.analyticsvidhya.com</p></div></div><div class="op l"><div class="ov l or os ot op ou ix og"/></div></div></a></div><p id="6c46" class="pw-post-body-paragraph kx ky jf kz b la lu lc ld le lv lg lh li lw lk ll lm lx lo lp lq ly ls lt kv ij bi translated"><em class="na">这一张就这么多了。</em></p><p id="0b33" class="pw-post-body-paragraph kx ky jf kz b la lu lc ld le lv lg lh li lw lk ll lm lx lo lp lq ly ls lt kv ij bi translated">下次见…！！</p></div></div>    
</body>
</html>