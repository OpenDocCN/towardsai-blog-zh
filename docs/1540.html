<html>
<head>
<title>Basic Math Skills for Data Science</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">数据科学的基本数学技能</h1>
<blockquote>原文：<a href="https://pub.towardsai.net/basic-math-skills-for-data-science-82368f6e2e63?source=collection_archive---------1-----------------------#2021-02-15">https://pub.towardsai.net/basic-math-skills-for-data-science-82368f6e2e63?source=collection_archive---------1-----------------------#2021-02-15</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><h2 id="c470" class="ir is it bd b dl iu iv iw ix iy iz dk ja translated" aria-label="kicker paragraph"><a class="ae ep" href="https://towardsai.net/p/category/data-science" rel="noopener ugc nofollow" target="_blank">数据科学</a>，<a class="ae ep" href="https://towardsai.net/p/category/mathematics" rel="noopener ugc nofollow" target="_blank">数学</a></h2><div class=""/><div class=""><h2 id="a035" class="pw-subtitle-paragraph jz jc it bd b ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq dk translated">数学技能将帮助你避免使用机器学习算法作为黑盒工具的陷阱</h2></div><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi kr"><img src="../Images/9481dc8be1e24bbc2383a9c31a270d09.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*H4BPvHMH1_fOxDv2"/></div></div><figcaption class="ld le gj gh gi lf lg bd b be z dk translated">照片由<a class="ae lh" href="https://unsplash.com/@roman_lazygeek?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">罗马法师</a>在<a class="ae lh" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上拍摄</figcaption></figure><p id="3134" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated"><em class="me">很少或没有数学背景的我能成为一名数据科学家吗？</em></p><p id="4989" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated"><em class="me">数据科学实践需要哪些基本的数学技能？</em></p><p id="38b8" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi mf translated">有这么多伟大的包或库可供数据科学家们执行他们的工作。一些最常见的描述性和预测性分析包包括:</p><ul class=""><li id="2e07" class="mo mp it lk b ll lm lo lp lr mq lv mr lz ms md mt mu mv mw bi translated"><em class="me"> Ggplot2 </em></li><li id="0585" class="mo mp it lk b ll mx lo my lr mz lv na lz nb md mt mu mv mw bi translated"><em class="me"> Matplotlib </em></li><li id="4f30" class="mo mp it lk b ll mx lo my lr mz lv na lz nb md mt mu mv mw bi translated"><em class="me"> Seaborn </em></li><li id="5788" class="mo mp it lk b ll mx lo my lr mz lv na lz nb md mt mu mv mw bi translated"><em class="me"> Scikit-learn </em></li><li id="2238" class="mo mp it lk b ll mx lo my lr mz lv na lz nb md mt mu mv mw bi translated"><em class="me">插入符号</em></li><li id="4a3d" class="mo mp it lk b ll mx lo my lr mz lv na lz nb md mt mu mv mw bi translated"><em class="me">张量流</em></li><li id="487f" class="mo mp it lk b ll mx lo my lr mz lv na lz nb md mt mu mv mw bi translated"><em class="me"> PyTorch </em></li><li id="5a9c" class="mo mp it lk b ll mx lo my lr mz lv na lz nb md mt mu mv mw bi translated"><em class="me"> Keras </em></li></ul><p id="7d22" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">然而，数学技能在数据科学和机器学习中仍然是必不可少的，因为这些包只是黑盒，如果没有坚实的数学基础，你将无法提出核心的分析问题。因此，良好的数学背景对于构建可靠的机器学习模型至关重要。它还将帮助你避免使用机器学习算法作为黑盒工具的陷阱。</p><p id="1035" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">本文将回顾一些对数据科学实践至关重要的基本数学技能。这个列表并不是包罗万象的，但至少它提供了你需要开始的基础知识。</p><h2 id="bd96" class="nc nd it bd ne nf ng dn nh ni nj dp nk lr nl nm nn lv no np nq lz nr ns nt iz bi translated">(一)统计和概率</h2><p id="6fd9" class="pw-post-body-paragraph li lj it lk b ll nu kd ln lo nv kg lq lr nw lt lu lv nx lx ly lz ny mb mc md im bi translated">统计和概率用于特征的可视化、数据预处理、特征转换、数据插补、降维、特征工程、模型评估等。以下是您需要熟悉的主题:</p><p id="4b1f" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">a)平均值</p><p id="daa1" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">b)中间值</p><p id="3c0a" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">c)模式</p><p id="9aef" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">d)标准偏差/方差</p><p id="d2e1" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">e)相关系数和协方差矩阵</p><p id="b2aa" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">f)概率分布(二项式、泊松、正态)</p><p id="5d74" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">g) p值</p><p id="535c" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">h) MSE(均方差)</p><p id="04f2" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">i) R2分数</p><p id="4f23" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">j) Baye定理(精确度、召回率、阳性预测值、阴性预测值、混淆矩阵、ROC曲线)</p><p id="00fe" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">k) A/B测试</p><p id="6b07" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">l)蒙特卡罗模拟</p><h2 id="bb6f" class="nc nd it bd ne nf ng dn nh ni nj dp nk lr nl nm nn lv no np nq lz nr ns nt iz bi translated">㈡多变量微积分</h2><p id="7e67" class="pw-post-body-paragraph li lj it lk b ll nu kd ln lo nv kg lq lr nw lt lu lv nx lx ly lz ny mb mc md im bi translated">大多数机器学习模型是用具有几个特征或预测器的数据集构建的。因此，熟悉多变量微积分对于建立机器学习模型极其重要。以下是您需要熟悉的主题:</p><p id="6436" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">a)几个变量的函数</p><p id="e8df" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">b)导数和梯度</p><p id="9601" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">c)阶跃函数、Sigmoid函数、Logit函数、ReLU(校正线性单位)函数</p><p id="eb97" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">d)成本函数</p><p id="5df3" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">e)绘制功能图</p><p id="faac" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">f)函数的最小值和最大值</p><h2 id="9a0b" class="nc nd it bd ne nf ng dn nh ni nj dp nk lr nl nm nn lv no np nq lz nr ns nt iz bi translated">㈢线性代数</h2><p id="1565" class="pw-post-body-paragraph li lj it lk b ll nu kd ln lo nv kg lq lr nw lt lu lv nx lx ly lz ny mb mc md im bi translated">线性代数是机器学习中最重要的数学技能。数据集被表示为矩阵。线性代数用于数据预处理、数据转换和模型评估。以下是您需要熟悉的主题:</p><p id="de14" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">a)矢量</p><p id="79f8" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">b)矩阵</p><p id="42d3" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">c)矩阵的转置</p><p id="748d" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">d)矩阵的逆矩阵</p><p id="4d76" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">e)矩阵的行列式</p><p id="dfee" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">f)点积</p><p id="b76c" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">g)特征值</p><p id="39a8" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">h)特征向量</p><h2 id="2fa1" class="nc nd it bd ne nf ng dn nh ni nj dp nk lr nl nm nn lv no np nq lz nr ns nt iz bi translated">㈣优化方法</h2><p id="0fbc" class="pw-post-body-paragraph li lj it lk b ll nu kd ln lo nv kg lq lr nw lt lu lv nx lx ly lz ny mb mc md im bi translated">大多数机器学习算法通过最小化目标函数来执行预测建模，从而学习为了获得预测标签而必须应用于测试数据的权重。以下是您需要熟悉的主题:</p><p id="b173" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">a)成本函数/目标函数</p><p id="869f" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">b)可能性函数</p><p id="d797" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">c)误差函数</p><p id="d1f6" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">d)梯度下降算法及其变体(例如随机梯度下降算法)</p><p id="2ab0" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">在这里了解更多关于梯度下降算法的信息:<a class="ae lh" href="https://medium.com/towards-artificial-intelligence/machine-learning-how-the-gradient-descent-algorithm-works-61682d8570b6" rel="noopener"> <strong class="lk jd">机器学习:梯度下降算法如何工作</strong> </a>。</p><h2 id="7bba" class="nc nd it bd ne nf ng dn nh ni nj dp nk lr nl nm nn lv no np nq lz nr ns nt iz bi translated">案例研究:使用梯度下降算法构建简单的线性回归器</h2><p id="dfb0" class="pw-post-body-paragraph li lj it lk b ll nu kd ln lo nv kg lq lr nw lt lu lv nx lx ly lz ny mb mc md im bi translated">在这个案例研究中，我们展示了在构建一个简单的机器学习算法时如何使用不同的数学概念。</p><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div class="gh gi nz"><img src="../Images/5a4baa8008d44031e89e6efc8b5ccc92.png" data-original-src="https://miro.medium.com/v2/resize:fit:1114/format:webp/0*CPw7GBFivO8niKfy.png"/></div><figcaption class="ld le gj gh gi lf lg bd b be z dk translated">基本线性回归引擎的工作流程。Benjamin O. Tayo的图片</figcaption></figure><p id="a2ab" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">我们描述了如何使用梯度下降法构建一个简单的python估算器来执行线性回归。假设我们有一个包含单个要素(X)和结果(y)的一维数据集，并假设数据集中有N个观测值:</p><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div class="gh gi oa"><img src="../Images/3bbab57c5350209688f9faac11c2e3fc.png" data-original-src="https://miro.medium.com/v2/resize:fit:258/format:webp/0*C55lX5yq8M5fUFp7.png"/></div></figure><p id="761c" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">拟合数据的线性模型如下所示:</p><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div class="gh gi ob"><img src="../Images/61c55648e7b71911163045e314f5b486.png" data-original-src="https://miro.medium.com/v2/resize:fit:478/format:webp/0*S5558Zhlf8WdjNUv.png"/></div></figure><p id="5c4f" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">其中w0和w1是算法在训练期间学习的权重。</p><h2 id="76b9" class="nc nd it bd ne nf ng dn nh ni nj dp nk lr nl nm nn lv no np nq lz nr ns nt iz bi translated">梯度下降算法</h2><p id="51bb" class="pw-post-body-paragraph li lj it lk b ll nu kd ln lo nv kg lq lr nw lt lu lv nx lx ly lz ny mb mc md im bi translated">如果我们假设模型中的误差是独立的且呈正态分布，则似然函数如下所示:</p><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div class="gh gi oc"><img src="../Images/adf461afb16c9e01299540b9d4255281.png" data-original-src="https://miro.medium.com/v2/resize:fit:1234/format:webp/0*pwzDzp0HpoOK9OFS.png"/></div></figure><p id="3d7d" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">为了最大化似然函数，我们最小化w0和w1的误差平方和(SSE ):</p><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div class="gh gi od"><img src="../Images/e7fb66c28d94aeadb19d230304b2d0d1.png" data-original-src="https://miro.medium.com/v2/resize:fit:1060/format:webp/0*C81dIioTSaKWr2aP.png"/></div></figure><p id="8bf3" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">目标函数或我们的SSE函数通常使用梯度下降(GD)算法来最小化。在GD方法中，权重根据以下程序更新:</p><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div class="gh gi oe"><img src="../Images/20fdd11aaa7105eb31fdccb032ade113.png" data-original-src="https://miro.medium.com/v2/resize:fit:544/format:webp/0*Gmv1EUEtYah9SG2V.png"/></div></figure><p id="5b77" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">即在与梯度相反的方向上。这里，eta是一个小的正常数，称为学习率。该等式可以用分量形式写成:</p><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div class="gh gi of"><img src="../Images/accca64bf3664a2c6767476bc3ab2251.png" data-original-src="https://miro.medium.com/v2/resize:fit:976/format:webp/0*bjzJseVvhY8qa2mG.png"/></div></figure><p id="6cf5" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">如果你想了解更多关于GD算法及其工作原理的信息，请参阅以下文章:<a class="ae lh" href="https://medium.com/@benjaminobi/machine-learning-how-the-gradient-descent-algorithm-works-61682d8570b6" rel="noopener">https://medium . com/@ Benjamin bi/machine-learning-how-the-gradient-descent-algorithm-works-61682d 8570 b 6</a></p><h2 id="f649" class="nc nd it bd ne nf ng dn nh ni nj dp nk lr nl nm nn lv no np nq lz nr ns nt iz bi translated">使用Python Estimator实现</h2><pre class="ks kt ku kv gt og oh oi oj aw ok bi"><span id="6f0e" class="nc nd it oh b gy ol om l on oo">import pandas as pd</span><span id="e3c2" class="nc nd it oh b gy op om l on oo">import numpy as np</span><span id="3730" class="nc nd it oh b gy op om l on oo">import matplotlib.pyplot as plt</span><span id="92c9" class="nc nd it oh b gy op om l on oo">class GradientDescent(object):<br/>    """Gradient descent optimizer.<br/>    Parameters<br/>    ------------<br/>    eta : float<br/>        Learning rate (between 0.0 and 1.0)<br/>    n_iter : int<br/>        Passes over the training dataset.<br/>        <br/>    Attributes<br/>    -----------<br/>    w_ : 1d-array<br/>        Weights after fitting.<br/>    errors_ : list<br/>        Error in every epoch.<br/>    """    def __init__(self, eta=0.01, n_iter=10):<br/>        self.eta = eta<br/>        self.n_iter = n_iter<br/>        <br/>    def fit(self, X, y):<br/>        """Fit the data.<br/>        <br/>        Parameters<br/>        ----------<br/>        X : {array-like}, shape = [n_points]<br/>        Independent variable or predictor.<br/>        y : array-like, shape = [n_points]<br/>        Outcome of prediction.<br/>        Returns<br/>        -------<br/>        self : object<br/>        """<br/>        self.w_ = np.zeros(2)<br/>        self.errors_ = []<br/>        <br/>        for i in range(self.n_iter):<br/>            errors = 0<br/>            for j in range(X.shape[0]):<br/>                self.w_[1:] += self.eta*X[j]*(y[j] - self.w_[0] -                     self.w_[1]*X[j])<br/>                self.w_[0] += self.eta*(y[j] - self.w_[0] - self.w_[1]*X[j])<br/>                errors += 0.5*(y[j] - self.w_[0] - self.w_[1]*X[j])**2<br/>            self.errors_.append(errors)<br/>        return self    def predict(self, X):<br/>        """Return predicted y values"""<br/>        return self.w_[0] + self.w_[1]*X</span></pre><h2 id="06db" class="nc nd it bd ne nf ng dn nh ni nj dp nk lr nl nm nn lv no np nq lz nr ns nt iz bi translated">Python估计器的应用</h2><p id="6b35" class="pw-post-body-paragraph li lj it lk b ll nu kd ln lo nv kg lq lr nw lt lu lv nx lx ly lz ny mb mc md im bi translated"><strong class="lk jd"> a)创建数据集</strong></p><pre class="ks kt ku kv gt og oh oi oj aw ok bi"><span id="ee0b" class="nc nd it oh b gy ol om l on oo">np.random.seed(1)</span><span id="b298" class="nc nd it oh b gy op om l on oo">X=np.linspace(0,1,10)</span><span id="0134" class="nc nd it oh b gy op om l on oo">y = 2*X + 1</span><span id="0b46" class="nc nd it oh b gy op om l on oo">y = y + np.random.normal(0,0.05,X.shape[0])</span></pre><p id="b6a3" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated"><strong class="lk jd"> b)拟合和预测</strong></p><pre class="ks kt ku kv gt og oh oi oj aw ok bi"><span id="c8f4" class="nc nd it oh b gy ol om l on oo">gda = GradientDescent(eta=0.1, n_iter=100)</span><span id="0fc3" class="nc nd it oh b gy op om l on oo">gda.fit(X,y)</span><span id="b324" class="nc nd it oh b gy op om l on oo">y_hat=gda.predict(X)</span></pre><p id="23ee" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated"><strong class="lk jd"> c)绘图输出</strong></p><pre class="ks kt ku kv gt og oh oi oj aw ok bi"><span id="3aaa" class="nc nd it oh b gy ol om l on oo">plt.figure()</span><span id="270e" class="nc nd it oh b gy op om l on oo">plt.scatter(X,y, marker='x',c='r',alpha=0.5,label='data')</span><span id="363f" class="nc nd it oh b gy op om l on oo">plt.plot(X,y_hat, marker='s',c='b',alpha=0.5,label='fit')</span><span id="1bf5" class="nc nd it oh b gy op om l on oo">plt.xlabel('x')</span><span id="bd9a" class="nc nd it oh b gy op om l on oo">plt.ylabel('y')</span><span id="7e4d" class="nc nd it oh b gy op om l on oo">plt.legend()</span></pre><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div class="gh gi oq"><img src="../Images/42babab8cf994c0eb23d6e213ca70e29.png" data-original-src="https://miro.medium.com/v2/resize:fit:1056/format:webp/0*zPURlGAyKFhRbquN.png"/></div><figcaption class="ld le gj gh gi lf lg bd b be z dk translated">基本线性回归的输出。Benjamin O. Tayo的图片</figcaption></figure><p id="fba5" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated"><strong class="lk jd"> d)计算R平方值</strong></p><pre class="ks kt ku kv gt og oh oi oj aw ok bi"><span id="9fe1" class="nc nd it oh b gy ol om l on oo">R_sq = 1-((y_hat - y)**2).sum()/((y-np.mean(y))**2).sum()</span><span id="f53b" class="nc nd it oh b gy op om l on oo">R_sq</span><span id="1b88" class="nc nd it oh b gy op om l on oo">0.991281901588877</span></pre><p id="534d" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">总之，我们已经展示了如何应用基本的数学技巧，使用GD算法构建一个简单的线性回归估计器。数学是数据科学和机器学习的支柱。扎实的数学背景能让你建立高效可靠的模型。它还将帮助你避免使用机器学习算法作为黑盒工具的陷阱。</p></div></div>    
</body>
</html>