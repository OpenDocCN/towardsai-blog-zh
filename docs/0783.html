<html>
<head>
<title>Tricks of Building an ML or DNN Model</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">构建ML或DNN模型的技巧</h1>
<blockquote>原文：<a href="https://pub.towardsai.net/tricks-of-building-an-ml-or-dnn-model-b2de54cf440a?source=collection_archive---------1-----------------------#2020-08-10">https://pub.towardsai.net/tricks-of-building-an-ml-or-dnn-model-b2de54cf440a?source=collection_archive---------1-----------------------#2020-08-10</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><h2 id="9a84" class="ir is it bd b dl iu iv iw ix iy iz dk ja translated" aria-label="kicker paragraph"><a class="ae ep" href="https://towardsai.net/p/category/machine-learning" rel="noopener ugc nofollow" target="_blank">机器学习</a></h2><div class=""/><figure class="gl gn ka kb kc kd gh gi paragraph-image"><div role="button" tabindex="0" class="ke kf di kg bf kh"><div class="gh gi jz"><img src="../Images/dcdd34392428305d7562a436f179facd.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*HVMTypOkx6z2ZGCL"/></div></div><figcaption class="kk kl gj gh gi km kn bd b be z dk translated"><a class="ae ko" href="https://unsplash.com/@makcedward?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">马志威</a>在<a class="ae ko" href="https://unsplash.com/?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上拍照</figcaption></figure><p id="baaa" class="pw-post-body-paragraph kp kq it kr b ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj lk ll lm im bi translated">每个人都可以轻松地将数据放入任何模型机器学习或深度学习框架中。遵循最佳实践可能有助于您区分他人。此外，您可以考虑以下技巧。以下是我在数据科学家之旅中应用的一些方法。</p><h1 id="93a5" class="ln lo it bd lp lq lr ls lt lu lv lw lx ly lz ma mb mc md me mf mg mh mi mj mk bi translated">目录</h1><p id="1a50" class="pw-post-body-paragraph kp kq it kr b ks ml ku kv kw mm ky kz la mn lc ld le mo lg lh li mp lk ll lm im bi translated"><strong class="kr jd"> <em class="mq">数据准备</em> </strong></p><ul class=""><li id="f630" class="mr ms it kr b ks kt kw kx la mt le mu li mv lm mw mx my mz bi translated">处理您自己的数据</li><li id="5cb7" class="mr ms it kr b ks na kw nb la nc le nd li ne lm mw mx my mz bi translated">使用张量</li><li id="72e9" class="mr ms it kr b ks na kw nb la nc le nd li ne lm mw mx my mz bi translated">数据扩充</li><li id="fa5e" class="mr ms it kr b ks na kw nb la nc le nd li ne lm mw mx my mz bi translated">采样相同的数据</li></ul><p id="991f" class="pw-post-body-paragraph kp kq it kr b ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj lk ll lm im bi translated"><strong class="kr jd"> <em class="mq">模特培训</em> </strong></p><ul class=""><li id="189a" class="mr ms it kr b ks kt kw kx la mt le mu li mv lm mw mx my mz bi translated">保存中间检查点</li><li id="b788" class="mr ms it kr b ks na kw nb la nc le nd li ne lm mw mx my mz bi translated">虚拟纪元</li><li id="50df" class="mr ms it kr b ks na kw nb la nc le nd li ne lm mw mx my mz bi translated">简单就是美</li><li id="10ab" class="mr ms it kr b ks na kw nb la nc le nd li ne lm mw mx my mz bi translated">简化问题</li></ul><p id="590d" class="pw-post-body-paragraph kp kq it kr b ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj lk ll lm im bi translated"><strong class="kr jd"> <em class="mq">调试</em> </strong></p><ul class=""><li id="6059" class="mr ms it kr b ks kt kw kx la mt le mu li mv lm mw mx my mz bi translated">简化问题</li><li id="1cce" class="mr ms it kr b ks na kw nb la nc le nd li ne lm mw mx my mz bi translated">使用评估模式进行培训</li><li id="d516" class="mr ms it kr b ks na kw nb la nc le nd li ne lm mw mx my mz bi translated">数据移位</li><li id="7ef0" class="mr ms it kr b ks na kw nb la nc le nd li ne lm mw mx my mz bi translated">解决拟合不足问题</li><li id="094c" class="mr ms it kr b ks na kw nb la nc le nd li ne lm mw mx my mz bi translated">解决过度拟合问题</li></ul><p id="3769" class="pw-post-body-paragraph kp kq it kr b ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj lk ll lm im bi translated"><strong class="kr jd"> <em class="mq">制作</em> </strong></p><ul class=""><li id="354e" class="mr ms it kr b ks kt kw kx la mt le mu li mv lm mw mx my mz bi translated">元数据关联</li><li id="701a" class="mr ms it kr b ks na kw nb la nc le nd li ne lm mw mx my mz bi translated">切换到推理模式</li><li id="323d" class="mr ms it kr b ks na kw nb la nc le nd li ne lm mw mx my mz bi translated">缩放成本</li><li id="e75d" class="mr ms it kr b ks na kw nb la nc le nd li ne lm mw mx my mz bi translated">无国籍的</li><li id="9af9" class="mr ms it kr b ks na kw nb la nc le nd li ne lm mw mx my mz bi translated">分批法</li><li id="7f32" class="mr ms it kr b ks na kw nb la nc le nd li ne lm mw mx my mz bi translated">使用C++</li></ul><h1 id="20d8" class="ln lo it bd lp lq lr ls lt lu lv lw lx ly lz ma mb mc md me mf mg mh mi mj mk bi translated">数据准备</h1><h2 id="91e5" class="nf lo it bd lp ng nh dn lt ni nj dp lx la nk nl mb le nm nn mf li no np mj iz bi translated">处理您自己的数据</h2><figure class="nr ns nt nu gt kd gh gi paragraph-image"><div role="button" tabindex="0" class="ke kf di kg bf kh"><div class="gh gi nq"><img src="../Images/39acc34b6a1f8016814f83a0946bcdb4.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*UDQBcrs4XsGtzNqI"/></div></div><figcaption class="kk kl gj gh gi km kn bd b be z dk translated"><a class="ae ko" href="https://unsplash.com/@4themorningshoot?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">奥利弗·黑尔</a>在<a class="ae ko" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上拍摄的照片</figcaption></figure><p id="a51b" class="pw-post-body-paragraph kp kq it kr b ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj lk ll lm im bi translated">建议在模型内(或预测服务内)处理数据。原因是消费者可能不知道如何做到这一点，并使特征工程对他们透明。</p><ul class=""><li id="0fcc" class="mr ms it kr b ks kt kw kx la mt le mu li mv lm mw mx my mz bi translated">以一个<strong class="kr jd"> <em class="mq">文本分类</em> </strong>问题为例，你正在使用<a class="ae ko" href="https://towardsdatascience.com/how-bert-leverage-attention-mechanism-and-transformer-to-learn-word-contextual-relations-5bbee1b6dbdb" rel="noopener" target="_blank"> BERT </a>进行分类。您不能要求您的客户端进行令牌化和功能对话(将文本转换为令牌ID)。</li><li id="b8e6" class="mr ms it kr b ks na kw nb la nc le nd li ne lm mw mx my mz bi translated">以一个<strong class="kr jd"> <em class="mq">回归问题</em> </strong>为例，日期(如10/31/2019)是特征之一。在您的初始模型中，您可能只使用一周中的某一天(即星期四)作为一个特性。经过几次迭代之后，星期几不再是一个好的特性，您希望只使用day(即31)。如果您的客户仅通过日期(即2019年10月31日)，而不是从第1天开始的一周中的某一天(即31日)，则您不需要为了推出新模型而更改API接口。</li><li id="dec0" class="mr ms it kr b ks na kw nb la nc le nd li ne lm mw mx my mz bi translated">以<strong class="kr jd"> <em class="mq">自动语音识别</em> </strong>为例，消费者只能向你发送音频，而不能发送梅尔频率倒谱系数(MFCC)等经典特征。</li></ul><p id="3158" class="pw-post-body-paragraph kp kq it kr b ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj lk ll lm im bi translated">因此，建议将数据预处理嵌入到您的管道中，而不是要求您的客户端去做。</p><h2 id="c07a" class="nf lo it bd lp ng nh dn lt ni nj dp lx la nk nl mb le nm nn mf li no np mj iz bi translated">使用张量</h2><p id="fd07" class="pw-post-body-paragraph kp kq it kr b ks ml ku kv kw mm ky kz la mn lc ld le mo lg lh li mp lk ll lm im bi translated">张量是一个N维数组，为多维计算而优化。它比使用Python字典或数组更快，深度学习框架(例如PyTorch或TensorFlow)的预期数据格式是张量。</p><h2 id="444d" class="nf lo it bd lp ng nh dn lt ni nj dp lx la nk nl mb le nm nn mf li no np mj iz bi translated">数据扩充</h2><p id="a2ed" class="pw-post-body-paragraph kp kq it kr b ks ml ku kv kw mm ky kz la mn lc ld le mo lg lh li mp lk ll lm im bi translated">缺乏标记数据是从业者通常处理的挑战之一。迁移学习是克服的方法之一。可以考虑用ResNet(计算机视觉)，BERT(自然语言处理)。另一方面，可以生成合成数据来增加标注数据。<a class="ae ko" href="https://github.com/albumentations-team/albumentations" rel="noopener ugc nofollow" target="_blank">图释</a>和<a class="ae ko" href="https://github.com/aleju/imgaug" rel="noopener ugc nofollow" target="_blank"> imgaug </a>帮助生成图像数据，而<a class="ae ko" href="https://github.com/makcedward/nlpaug" rel="noopener ugc nofollow" target="_blank"> nlpaug </a>生成文本数据。</p><p id="a7ac" class="pw-post-body-paragraph kp kq it kr b ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj lk ll lm im bi translated">如果你了解你的数据，你应该量身定做增强方法。请记住，数据科学的黄金法则是垃圾进垃圾出。</p><h2 id="379c" class="nf lo it bd lp ng nh dn lt ni nj dp lx la nk nl mb le nm nn mf li no np mj iz bi translated">采样相同的数据</h2><figure class="nr ns nt nu gt kd gh gi paragraph-image"><div role="button" tabindex="0" class="ke kf di kg bf kh"><div class="gh gi nv"><img src="../Images/b1118503268fa50ef9b6c66530b32629.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*0siaRlQHMRp2k9Pl"/></div></div><figcaption class="kk kl gj gh gi km kn bd b be z dk translated">杰里米·毕晓普在<a class="ae ko" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上拍摄的照片</figcaption></figure><p id="d380" class="pw-post-body-paragraph kp kq it kr b ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj lk ll lm im bi translated">大多数时候，我们希望随机抽取数据，以便保持样本数据在训练集、测试集和验证集中的分布。同时，您希望一直保持这种“随机”行为，这样您就可以获得相同的训练集、测试集和验证集。</p><ul class=""><li id="4610" class="mr ms it kr b ks kt kw kx la mt le mu li mv lm mw mx my mz bi translated">如果数据带有日期属性，您可以很容易地按该列拆分数据。</li><li id="f8e4" class="mr ms it kr b ks na kw nb la nc le nd li ne lm mw mx my mz bi translated">否则，您可以更改种子，以便获得一致的随机行为。</li></ul><pre class="nr ns nt nu gt nw nx ny nz aw oa bi"><span id="f616" class="nf lo it nx b gy ob oc l od oe">import torch<br/>import numpy as np<br/>import random</span><span id="b04b" class="nf lo it nx b gy of oc l od oe">seed = 1234<br/>random.seed(seed)<br/>np.random.seed(seed)<br/>torch.manual_seed(seed)<br/>torch.cuda.manual_seed(seed)</span></pre><h1 id="e2fb" class="ln lo it bd lp lq lr ls lt lu lv lw lx ly lz ma mb mc md me mf mg mh mi mj mk bi translated">模特培训</h1><h2 id="b2f0" class="nf lo it bd lp ng nh dn lt ni nj dp lx la nk nl mb le nm nn mf li no np mj iz bi translated">保存中间检查点</h2><p id="0f9d" class="pw-post-body-paragraph kp kq it kr b ks ml ku kv kw mm ky kz la mn lc ld le mo lg lh li mp lk ll lm im bi translated">重新升级到保存已训练的模型，一种更简单的方法是在完成整个训练过程后保存它。然而，有几个缺点。让我们一起经历吧。</p><ul class=""><li id="6bb2" class="mr ms it kr b ks kt kw kx la mt le mu li mv lm mw mx my mz bi translated">由于<strong class="kr jd"> <em class="mq">模型的复杂性、计算资源以及训练</em>数据</strong>的大小，整个模型训练过程可能需要几天或几周的时间。如果没有持久的中间检查点，那就太危险了，因为机器可能会被意外关闭。</li><li id="3f36" class="mr ms it kr b ks na kw nb la nc le nd li ne lm mw mx my mz bi translated">一般来说，较长的训练模型导致较好的结果(例如，较少的损失)。然而，过度拟合可能会发生。<strong class="kr jd"><em class="mq"/>e</strong>最后一个关卡在大部分时间里并没有交出最好的成绩。大多数时候，我们需要使用中间检查点进行生产。</li><li id="74bf" class="mr ms it kr b ks na kw nb la nc le nd li ne lm mw mx my mz bi translated"><strong class="kr jd"> <em class="mq">使用提前停止机制</em> </strong>省钱。注意到一个模型在几个时期内没有改进，我们可以更早地停止它以节省时间和资源。你可能会争辩说，最好的模型可能是在几个时代之后训练出来的。这是你如何平衡它。</li></ul><p id="a93c" class="pw-post-body-paragraph kp kq it kr b ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj lk ll lm im bi translated">那么我们能做到吗？理想情况下，您可以持久化所有检查点(例如，在每个时期后保存模型)，但是这需要大量存储。事实上，我们建议只保留最佳模型(或最佳三个模型)和最后一个模型。</p><h2 id="72ed" class="nf lo it bd lp ng nh dn lt ni nj dp lx la nk nl mb le nm nn mf li no np mj iz bi translated">虚拟纪元</h2><p id="966f" class="pw-post-body-paragraph kp kq it kr b ks ml ku kv kw mm ky kz la mn lc ld le mo lg lh li mp lk ll lm im bi translated">历元是模型训练中非常常见的参数。如果初始化不正确，可能会影响模型性能。</p><p id="b1c3" class="pw-post-body-paragraph kp kq it kr b ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj lk ll lm im bi translated">例如，如果我们有100万条记录，并且我们为训练设置了5个时期，则总共有500万(1M *5)个训练数据。三周后，我们又获得了50万张唱片。如果我们使用相同的历元(即5)进行模型训练，则总训练数据变成750万(1.5M *5)。这些问题是:</p><ul class=""><li id="804b" class="mr ms it kr b ks kt kw kx la mt le mu li mv lm mw mx my mz bi translated">可能不容易知道模型的改进是由增加唯一训练数据还是增加总训练数据引起的。</li><li id="a2c1" class="mr ms it kr b ks na kw nb la nc le nd li ne lm mw mx my mz bi translated">新的0.5M将训练时间延长到一个小时甚至几天。它增加了机器故障的风险。</li></ul><p id="1cd9" class="pw-post-body-paragraph kp kq it kr b ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj lk ll lm im bi translated">代替使用静态时期，建议使用虚拟时期来代替原始时期。虚拟时期可以基于训练数据的大小、期望时期、批量大小来计算。</p><p id="ae58" class="pw-post-body-paragraph kp kq it kr b ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj lk ll lm im bi translated">这是我们通常的设置:</p><pre class="nr ns nt nu gt nw nx ny nz aw oa bi"><span id="fabc" class="nf lo it nx b gy ob oc l od oe">#original<br/>num_data = 1000 * 1000<br/>batch_size = 100<br/>num_step = 14 * 1000 * 1000<br/>num_checkpoint = 20<br/>steps_per_epoch = num_step//num_checkpoint</span><span id="b775" class="nf lo it nx b gy of oc l od oe">#TensorFlow/ Keras<br/>model.fit(x, epoch=num_checkpoint, steps_per_epoch=steps_per_epoch,<br/>  batch_size=batch_size<br/>)</span></pre><p id="73ee" class="pw-post-body-paragraph kp kq it kr b ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj lk ll lm im bi translated">事实上，您可以使用以下设置:</p><pre class="nr ns nt nu gt nw nx ny nz aw oa bi"><span id="bae0" class="nf lo it nx b gy ob oc l od oe">num_data = 1000 * 1000<br/>num_total_data = 14 * 1000 * 1000<br/>batch_size = 100<br/>num_checkpoint = 20<br/>steps_per_epoch = num_total_data // (batch_size*num_checkpoint)</span><span id="6a09" class="nf lo it nx b gy of oc l od oe">#TensorFlow/ Keras<br/>model.fit(x, epoch=num_checkpoint, steps_per_epoch=steps_per_epoch,<br/>  batch_size=batch_size<br/>)</span></pre><h2 id="3d24" class="nf lo it bd lp ng nh dn lt ni nj dp lx la nk nl mb le nm nn mf li no np mj iz bi translated">简单就是美</h2><figure class="nr ns nt nu gt kd gh gi paragraph-image"><div role="button" tabindex="0" class="ke kf di kg bf kh"><div class="gh gi og"><img src="../Images/cc5574c6981e8672bc3e61cffd9afb54.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*a8VF3trrXT8At08b"/></div></div><figcaption class="kk kl gj gh gi km kn bd b be z dk translated"><a class="ae ko" href="https://unsplash.com/@lum3n?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> LUM3N </a>在<a class="ae ko" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上拍照</figcaption></figure><p id="283a" class="pw-post-body-paragraph kp kq it kr b ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj lk ll lm im bi translated">从业者打算使用最先进的模型来构建一个初始模型。事实上，总是建议构建一个足够简单的模型作为基线模型。原因是:</p><ul class=""><li id="1a3e" class="mr ms it kr b ks kt kw kx la mt le mu li mv lm mw mx my mz bi translated">我们总是需要一个<strong class="kr jd"> <em class="mq">基线模式</em> l </strong>来证明所提出的模型。很难告诉客户我们惊人的深度神经网络模型比其他模型更好。</li><li id="444b" class="mr ms it kr b ks na kw nb la nc le nd li ne lm mw mx my mz bi translated">基准模型在性能方面不需要很好，但必须是<strong class="kr jd"> <em class="mq">可解释</em> </strong>。商业用户总是想知道预测结果的原因。</li><li id="4131" class="mr ms it kr b ks na kw nb la nc le nd li ne lm mw mx my mz bi translated"><strong class="kr jd"> <em class="mq">容易实现</em> t </strong>很重要。客户不能为了得到一个足够好的模型而等待一年。我们需要建立一套模型，以便从投资者那里获得动力，在初始模型的基础上建立您的精彩模型。</li></ul><p id="674d" class="pw-post-body-paragraph kp kq it kr b ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj lk ll lm im bi translated">以下是不同领域的一些建议基线模型:</p><ul class=""><li id="c3e6" class="mr ms it kr b ks kt kw kx la mt le mu li mv lm mw mx my mz bi translated"><strong class="kr jd"> <em class="mq">声学</em> </strong>:您可以使用经典特征，例如梅尔倒谱系数(MFCC)或梅尔频谱图特征，而不是训练模型来获得矢量表示(即嵌入层)。将这些特征传递给单层长短期记忆(LSTM)或卷积神经网络(CNN)和完全连接的层，用于分类或预测。</li><li id="7e0a" class="mr ms it kr b ks na kw nb la nc le nd li ne lm mw mx my mz bi translated"><strong class="kr jd"> <em class="mq">计算机视觉</em> </strong> (CV): TODO</li><li id="afde" class="mr ms it kr b ks na kw nb la nc le nd li ne lm mw mx my mz bi translated"><strong class="kr jd"> <em class="mq">自然语言处理(NLP) </em> </strong>:使用<a class="ae ko" href="https://towardsdatascience.com/3-basic-approaches-in-bag-of-words-which-are-better-than-word-embeddings-c2cbc7398016" rel="noopener" target="_blank">单词袋</a>或<a class="ae ko" href="https://towardsdatascience.com/3-silver-bullets-of-word-embedding-in-nlp-10fa8f50cc5a" rel="noopener" target="_blank">经典单词嵌入</a>与LSTM是一个很好的起点，以后再转移到基于transformer的模型，如<a class="ae ko" href="https://towardsdatascience.com/how-bert-leverage-attention-mechanism-and-transformer-to-learn-word-contextual-relations-5bbee1b6dbdb" rel="noopener" target="_blank"> BERT </a>或<a class="ae ko" href="https://medium.com/dataseries/why-does-xlnet-outperform-bert-da98a8503d5b" rel="noopener"> XLNet </a>。</li></ul><h1 id="d1b1" class="ln lo it bd lp lq lr ls lt lu lv lw lx ly lz ma mb mc md me mf mg mh mi mj mk bi translated">排除故障</h1><h2 id="cf91" class="nf lo it bd lp ng nh dn lt ni nj dp lx la nk nl mb le nm nn mf li no np mj iz bi translated">简化问题</h2><p id="48e3" class="pw-post-body-paragraph kp kq it kr b ks ml ku kv kw mm ky kz la mn lc ld le mo lg lh li mp lk ll lm im bi translated">有时，分类问题包括1000个类别的100万个数据。当模型性能低于您的异常时，调试您的模型就太难了。糟糕的性能可能由<strong class="kr jd"> <em class="mq">模型复杂性、数据质量或</em></strong>bug造成。因此，建议简化问题，这样我们可以保证它没有bug。我们利用<strong class="kr jd"> <em class="mq">过拟合</em> </strong> <strong class="kr jd"> <em class="mq">问题</em> </strong>来实现这个目标。</p><p id="ef03" class="pw-post-body-paragraph kp kq it kr b ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj lk ll lm im bi translated">您可以对10个类别(每个类别100条记录)进行采样，并训练您的模型，而不是对1000个类别进行分类。通过使用相同的训练数据集(或子集)作为评估数据集，您应该能够<strong class="kr jd"> <em class="mq">过度拟合您的模型，并获得良好的</em>结果</strong>(例如，80甚至90+精度)。如果没有，你的模型开发可能存在一些bug。</p><h2 id="8968" class="nf lo it bd lp ng nh dn lt ni nj dp lx la nk nl mb le nm nn mf li no np mj iz bi translated">使用评估模式进行培训</h2><p id="7e00" class="pw-post-body-paragraph kp kq it kr b ks ml ku kv kw mm ky kz la mn lc ld le mo lg lh li mp lk ll lm im bi translated">如果评估设置精度在前几个时期没有变化，您可能会忘记在评估后重置“训练”模式</p><p id="3868" class="pw-post-body-paragraph kp kq it kr b ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj lk ll lm im bi translated">在<a class="ae ko" href="https://pytorch.org/docs/stable/nn.html?highlight=module%20eval#torch.nn.Module.eval" rel="noopener ugc nofollow" target="_blank"> PyTorch </a>中，训练和评估时需要切换<code class="fe oh oi oj nx b">train</code>和<code class="fe oh oi oj nx b">eval</code>模式。如果启用了训练模式，批标准化、丢弃或其他层将受到影响。有时，您可能会在评估后忘记启用它。</p><pre class="nr ns nt nu gt nw nx ny nz aw oa bi"><span id="64d0" class="nf lo it nx b gy ob oc l od oe">model = MyModel() # Default mode is training mode</span><span id="7257" class="nf lo it nx b gy of oc l od oe">for e in range(epoch):<br/>  # mode.train() # forget to enable train mode<br/>  logits = model(x_train)<br/>  loss = loss_func(logits, y_train)<br/>  model<strong class="nx jd">.</strong>zero_grad()<br/>  loss.backward()<br/>  optimizer.step()</span><span id="2ec6" class="nf lo it nx b gy of oc l od oe">mode.eval() # enable eval mode<br/>  with torch.no_grad():<br/>    eval_preds = model(x_val)</span></pre><h2 id="5e14" class="nf lo it bd lp ng nh dn lt ni nj dp lx la nk nl mb le nm nn mf li no np mj iz bi translated">数据移位</h2><p id="e56d" class="pw-post-body-paragraph kp kq it kr b ks ml ku kv kw mm ky kz la mn lc ld le mo lg lh li mp lk ll lm im bi translated">当训练数据集不同于评估/测试数据集时，会发生数据移动。在计算机视觉(CV)任务中，可能大多数训练数据是白天的图片，而测试数据是晚上的图片。</p><figure class="nr ns nt nu gt kd gh gi paragraph-image"><div class="gh gi ok"><img src="../Images/a1204fd0249113c297b7b3bcb9a8ffee.png" data-original-src="https://miro.medium.com/v2/resize:fit:1280/format:webp/0*5VITr7trOSsf5qYs.jpg"/></div><figcaption class="kk kl gj gh gi km kn bd b be z dk translated">日日夜夜在同一个地方(<a class="ae ko" href="https://petapixel.com/2015/11/17/a-time-lapse-of-hong-kong-that-bounces-between-day-and-night/" rel="noopener ugc nofollow" target="_blank">来源</a>)</figcaption></figure><p id="6415" class="pw-post-body-paragraph kp kq it kr b ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj lk ll lm im bi translated">如果您发现训练损失/准确性和测试损失/准确性之间有很大差异，您可以从两个数据集中随机选取一些样本进行检查。要解决这个问题，您可以考虑:</p><ol class=""><li id="a446" class="mr ms it kr b ks kt kw kx la mt le mu li mv lm ol mx my mz bi translated">确保<strong class="kr jd"> <em class="mq">在训练、测试和在线预测数据集之间的</em></strong>数据上保持相似的分布。</li><li id="d522" class="mr ms it kr b ks na kw nb la nc le nd li ne lm ol mx my mz bi translated">如有可能，添加<strong class="kr jd"> <em class="mq">更多训练数据</em>一个</strong>。</li><li id="126e" class="mr ms it kr b ks na kw nb la nc le nd li ne lm ol mx my mz bi translated">利用库添加<strong class="kr jd"> <em class="mq">合成数据</em>和</strong>。考虑使用<a class="ae ko" href="https://github.com/makcedward/nlpaug" rel="noopener ugc nofollow" target="_blank"> nlpaug </a>(用于自然语言处理和声学任务)和<a class="ae ko" href="https://github.com/aleju/imgaug" rel="noopener ugc nofollow" target="_blank"> imgaug </a>(用于计算机视觉任务)。</li></ol><h2 id="800c" class="nf lo it bd lp ng nh dn lt ni nj dp lx la nk nl mb le nm nn mf li no np mj iz bi translated">解决拟合不足问题</h2><p id="5263" class="pw-post-body-paragraph kp kq it kr b ks ml ku kv kw mm ky kz la mn lc ld le mo lg lh li mp lk ll lm im bi translated">欠拟合意味着训练误差大于预期误差。换句话说，模型不能达到预期的性能。造成大误差的因素很多。要解决这个问题，您可以从一个更简单的方法开始，看看它是否可以解决。如果这个问题能够在早期阶段得到解决，您可以节省更多的时间，因为它更容易减少人力。</p><ol class=""><li id="8703" class="mr ms it kr b ks kt kw kx la mt le mu li mv lm ol mx my mz bi translated">执行错误分析。<strong class="kr jd"> <em class="mq">通过<a class="ae ko" href="https://towardsdatascience.com/3-ways-to-interpretate-your-nlp-model-to-management-and-customer-5428bc07ce15" rel="noopener" target="_blank">石灰</a>、<a class="ae ko" href="https://towardsdatascience.com/interpreting-your-deep-learning-model-by-shap-e69be2b47893" rel="noopener" target="_blank"> SHAP </a>或<a class="ae ko" href="https://towardsdatascience.com/anchor-your-model-interpretation-by-anchors-aa4ed7104032" rel="noopener" target="_blank">主播</a>来解读你的模型</em>、T25，这样你就能对问题有所感悟。</strong></li><li id="bfa6" class="mr ms it kr b ks na kw nb la nc le nd li ne lm ol mx my mz bi translated">初始模型可能过于简单。<strong class="kr jd"> <em class="mq">增加模型复杂度</em> </strong>如增加长短期记忆(LSTM)层，卷积神经网络(CNN)层，或全连接(FC)层。</li><li id="febb" class="mr ms it kr b ks na kw nb la nc le nd li ne lm ol mx my mz bi translated">通过<strong class="kr jd"> <em class="mq">减少正则化图层</em> </strong>一点点过度拟合模型。脱落和重量衰减旨在防止过度拟合。你可以试着移除那些规则布局，看看是否能解决问题。</li><li id="c615" class="mr ms it kr b ks na kw nb la nc le nd li ne lm ol mx my mz bi translated">采用<strong class="kr jd"> <em class="mq">最先进的模型架构</em>。</strong>考虑在自然语言处理(NLP)中使用变形器(如<a class="ae ko" href="https://towardsdatascience.com/how-bert-leverage-attention-mechanism-and-transformer-to-learn-word-contextual-relations-5bbee1b6dbdb" rel="noopener" target="_blank"> BERT </a>或<a class="ae ko" href="https://medium.com/dataseries/why-does-xlnet-outperform-bert-da98a8503d5b" rel="noopener"> XLNet </a>)。</li><li id="c0cc" class="mr ms it kr b ks na kw nb la nc le nd li ne lm ol mx my mz bi translated"><strong class="kr jd"> <em class="mq">介绍合成数据</em> </strong>。生成更多数据有助于提高模型性能，无需任何人工操作。理论上，生成的数据应该共享同一个标签。它允许模型“看到”更多不同的数据，并最终提高稳健性。你可以利用<a class="ae ko" href="https://github.com/makcedward/nlpaug" rel="noopener ugc nofollow" target="_blank"> nlpaug </a>(用于自然语言处理和声学任务)和<a class="ae ko" href="https://github.com/aleju/imgaug" rel="noopener ugc nofollow" target="_blank"> imgaug </a>(用于计算机视觉任务)来执行<strong class="kr jd"> <em class="mq">数据增强</em> n </strong>。</li><li id="0131" class="mr ms it kr b ks na kw nb la nc le nd li ne lm ol mx my mz bi translated">分配更好的超参数和优化器。您可以考虑执行超参数调整，而不是使用默认/通用学习速率、时期、批量大小。考虑使用波束搜索、网格搜索或随机搜索来<strong class="kr jd"> <em class="mq">确定更好的超参数和优化器</em> </strong>。这种方法相对简单，只需改变超参数，但可能需要较长的时间。</li><li id="8356" class="mr ms it kr b ks na kw nb la nc le nd li ne lm ol mx my mz bi translated">重新访问您的数据并引入额外功能。</li></ol><h2 id="9aa4" class="nf lo it bd lp ng nh dn lt ni nj dp lx la nk nl mb le nm nn mf li no np mj iz bi translated">解决过度拟合问题</h2><p id="a3f1" class="pw-post-body-paragraph kp kq it kr b ks ml ku kv kw mm ky kz la mn lc ld le mo lg lh li mp lk ll lm im bi translated">除了拟合不足，你还可能面临拟合过度的问题。过度拟合意味着您的模型太适合您的训练，而对于其他数据不够一般化。换句话说，你的训练损失/准确性比验证损失/准确性更好。考虑以下方法来解决它</p><ol class=""><li id="a4b2" class="mr ms it kr b ks kt kw kx la mt le mu li mv lm ol mx my mz bi translated">执行错误分析。<strong class="kr jd"> <em class="mq">通过<a class="ae ko" href="https://towardsdatascience.com/3-ways-to-interpretate-your-nlp-model-to-management-and-customer-5428bc07ce15" rel="noopener" target="_blank">石灰</a>、<a class="ae ko" href="https://towardsdatascience.com/interpreting-your-deep-learning-model-by-shap-e69be2b47893" rel="noopener" target="_blank"> SHAP </a>，或者<a class="ae ko" href="https://towardsdatascience.com/anchor-your-model-interpretation-by-anchors-aa4ed7104032" rel="noopener" target="_blank">主播</a>来解读你的模型</em> </strong>这样你就能对问题有所感悟。</li><li id="d2f3" class="mr ms it kr b ks na kw nb la nc le nd li ne lm ol mx my mz bi translated">如果可能，添加更多培训数据。</li><li id="b708" class="mr ms it kr b ks na kw nb la nc le nd li ne lm ol mx my mz bi translated"><strong class="kr jd"> <em class="mq">介绍</em> </strong> <strong class="kr jd"> <em class="mq">正则化和归一化图层</em> </strong>。丢弃(正则化层)和批量归一化(归一化层)通过移除一些输入和平滑输入来帮助减少过度拟合。</li><li id="a716" class="mr ms it kr b ks na kw nb la nc le nd li ne lm ol mx my mz bi translated"><strong class="kr jd"> <em class="mq">介绍合成数据</em> </strong>。生成更多数据有助于提高模型性能，无需任何人工操作。理论上，生成的数据应该共享同一个标签。它允许模型“看到”更多不同的数据，并最终提高稳健性。你可以利用<a class="ae ko" href="https://github.com/makcedward/nlpaug" rel="noopener ugc nofollow" target="_blank"> nlpaug </a>(用于自然语言处理和声学任务)和<a class="ae ko" href="https://github.com/aleju/imgaug" rel="noopener ugc nofollow" target="_blank"> imaug </a>(用于计算机视觉任务)来执行<strong class="kr jd"> <em class="mq">数据扩充</em> n </strong>。</li><li id="0249" class="mr ms it kr b ks na kw nb la nc le nd li ne lm ol mx my mz bi translated">分配更好的超参数和优化器。您可以考虑执行超参数调整，而不是使用默认/通用学习速率、时期、批量大小。考虑使用波束搜索、网格搜索或随机搜索来<strong class="kr jd"> <em class="mq">确定更好的超参数和优化器</em> </strong>。这种方法相对简单，只需改变超参数，但可能需要较长的时间。</li><li id="2c1c" class="mr ms it kr b ks na kw nb la nc le nd li ne lm ol mx my mz bi translated">使用提前停止机制来寻找最佳模型。</li><li id="fb26" class="mr ms it kr b ks na kw nb la nc le nd li ne lm ol mx my mz bi translated"><strong class="kr jd"> <em class="mq">清除特征</em> </strong>。</li><li id="5ff2" class="mr ms it kr b ks na kw nb la nc le nd li ne lm ol mx my mz bi translated">模型可能过于复杂。<strong class="kr jd"> <em class="mq">减少</em> </strong> <strong class="kr jd"> <em class="mq">模型复杂度</em> </strong>。</li></ol><h1 id="a831" class="ln lo it bd lp lq lr ls lt lu lv lw lx ly lz ma mb mc md me mf mg mh mi mj mk bi translated">生产</h1><h2 id="d768" class="nf lo it bd lp ng nh dn lt ni nj dp lx la nk nl mb le nm nn mf li no np mj iz bi translated">元数据关联</h2><p id="5ae0" class="pw-post-body-paragraph kp kq it kr b ks ml ku kv kw mm ky kz la mn lc ld le mo lg lh li mp lk ll lm im bi translated">在你的模型被展示之后，你需要检查一些例外的情况。一种方法是生成ID并将其保存到数据库中。但是，它带来了几个问题，增加了故障排除的难度。以下是一些缺点:</p><ul class=""><li id="92e9" class="mr ms it kr b ks kt kw kx la mt le mu li mv lm mw mx my mz bi translated">耦合问题影响了系统的灵活性。从架构设计的角度来看，<strong class="kr jd"> <em class="mq">解耦是构建高灵活性系统</em> </strong>的途径之一。如果我们生成一个ID并将带有这个ID的预测结果传递给一个客户机，客户机需要将它保存在数据库中。如果我们改变了格式或数据类型，你需要通知所有消费者更新他们的数据库方案。</li><li id="f8dd" class="mr ms it kr b ks na kw nb la nc le nd li ne lm mw mx my mz bi translated">我们可能需要根据消费者的主键收集更多的元数据。额外的主键<strong class="kr jd"> <em class="mq">增加了连接复杂度和存储消耗</em> </strong>。相反。</li></ul><p id="13a4" class="pw-post-body-paragraph kp kq it kr b ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj lk ll lm im bi translated">为了克服这个问题，预测结果应该直接与消费者的主键相关联。</p><h2 id="4bb1" class="nf lo it bd lp ng nh dn lt ni nj dp lx la nk nl mb le nm nn mf li no np mj iz bi translated">切换到推理模式</h2><p id="976e" class="pw-post-body-paragraph kp kq it kr b ks ml ku kv kw mm ky kz la mn lc ld le mo lg lh li mp lk ll lm im bi translated">使用PyTorch时，在将模型部署到生产环境中时，有几个设置需要注意。前面提到的PyTorch中的<code class="fe oh oi oj nx b">eval</code>,它使那些层(例如dropout、BatchNorm)以推理模式工作，例如在推理时间不应用任何Dropout动作。它不仅加快了你的过程，而且将所有信息输入神经网络。<code class="fe oh oi oj nx b">detach</code>和<code class="fe oh oi oj nx b">torch.no_grad</code>将帮助你从一个图形中得到一个结果，并且使用更少的内存。</p><pre class="nr ns nt nu gt nw nx ny nz aw oa bi"><span id="3bb3" class="nf lo it nx b gy ob oc l od oe">mode.eval() # enable eval mode<br/>with torch.no_grad():<br/>  eval_preds = model(x_val)</span></pre><h2 id="7838" class="nf lo it bd lp ng nh dn lt ni nj dp lx la nk nl mb le nm nn mf li no np mj iz bi translated">缩放成本</h2><p id="70a1" class="pw-post-body-paragraph kp kq it kr b ks ml ku kv kw mm ky kz la mn lc ld le mo lg lh li mp lk ll lm im bi translated">当您尝试向外扩展API以处理更多吞吐量时，有时可以考虑使用GPU。GPU VM确实比CPU贵很多。但是GPU给你带来了一些优势，比如计算时间更少，维持同样的服务水平需要更少的VM。试着评价一下，看GPU是不是省点钱。</p><h2 id="247f" class="nf lo it bd lp ng nh dn lt ni nj dp lx la nk nl mb le nm nn mf li no np mj iz bi translated">无国籍的</h2><p id="c774" class="pw-post-body-paragraph kp kq it kr b ks ml ku kv kw mm ky kz la mn lc ld le mo lg lh li mp lk ll lm im bi translated">尽量让你的API无状态，这样你的API服务就可以很容易的伸缩。无状态意味着不在API服务器中保存任何中间结果(内存或本地存储)。只要保持API服务器简单，并将结果返回给客户机，而不在内存或本地存储中存储任何东西。</p><h2 id="8cca" class="nf lo it bd lp ng nh dn lt ni nj dp lx la nk nl mb le nm nn mf li no np mj iz bi translated">分批法</h2><p id="a983" class="pw-post-body-paragraph kp kq it kr b ks ml ku kv kw mm ky kz la mn lc ld le mo lg lh li mp lk ll lm im bi translated">预测一组记录通常比逐个记录要快。大多数现代机器学习或深度学习框架优化了预测性能(在速度方面)。您可能会注意到切换到批处理模式预测有很大的改进。</p><h2 id="348f" class="nf lo it bd lp ng nh dn lt ni nj dp lx la nk nl mb le nm nn mf li no np mj iz bi translated">使用C++</h2><p id="fc3f" class="pw-post-body-paragraph kp kq it kr b ks ml ku kv kw mm ky kz la mn lc ld le mo lg lh li mp lk ll lm im bi translated">虽然Python是机器学习领域的一等公民，但与C++等其他编程语言相比，它可能太慢了。如果你想要低延迟推理时间，你可以考虑使用<a class="ae ko" href="https://pytorch.org/docs/stable/jit.html" rel="noopener ugc nofollow" target="_blank"> TorchScript </a>。总的想法是，您仍然可以用Python训练您的模型，并通过使用它来生成C++兼容的模型。</p><h1 id="9ff8" class="ln lo it bd lp lq lr ls lt lu lv lw lx ly lz ma mb mc md me mf mg mh mi mj mk bi translated">参考</h1><ul class=""><li id="6765" class="mr ms it kr b ks ml kw mm la om le on li oo lm mw mx my mz bi translated"><a class="ae ko" href="https://medium.com/@lakshmanok/machine-learning-design-patterns-58e6ecb013d7" rel="noopener">机器学习设计模式</a></li><li id="0b42" class="mr ms it kr b ks na kw nb la nc le nd li ne lm mw mx my mz bi translated"><a class="ae ko" href="http://josh-tobin.com/assets/pdf/troubleshooting-deep-neural-networks-01-19.pdf" rel="noopener ugc nofollow" target="_blank">深度神经网络故障排除</a></li><li id="f732" class="mr ms it kr b ks na kw nb la nc le nd li ne lm mw mx my mz bi translated"><a class="ae ko" href="https://tarasmatsyk.com/posts/4-how-to-pytorch-in-production/" rel="noopener ugc nofollow" target="_blank"> PyTorch投入生产</a></li><li id="16bf" class="mr ms it kr b ks na kw nb la nc le nd li ne lm mw mx my mz bi translated"><a class="ae ko" href="https://github.com/makcedward/nlpaug" rel="noopener ugc nofollow" target="_blank"> NLP增强库</a></li></ul></div></div>    
</body>
</html>