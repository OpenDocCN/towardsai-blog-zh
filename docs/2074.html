<html>
<head>
<title>In-Depth Machine Learning HR Analysis Project with Python</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">使用Python的深度机器学习HR分析项目</h1>
<blockquote>原文：<a href="https://pub.towardsai.net/in-depth-machine-learning-hr-analysis-project-with-python-2bfcaac0ff24?source=collection_archive---------0-----------------------#2021-08-09">https://pub.towardsai.net/in-depth-machine-learning-hr-analysis-project-with-python-2bfcaac0ff24?source=collection_archive---------0-----------------------#2021-08-09</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><h2 id="c948" class="ir is it bd b dl iu iv iw ix iy iz dk ja translated" aria-label="kicker paragraph"><a class="ae ep" href="https://towardsai.net/p/category/machine-learning" rel="noopener ugc nofollow" target="_blank">机器学习</a></h2><div class=""/><div class=""><h2 id="5f4b" class="pw-subtitle-paragraph jz jc it bd b ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq dk translated">用于查找、筛选、招聘和培训求职者的分析</h2></div><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi kr"><img src="../Images/2e1ce46ae810a31c979ba9dac3f6d0a7.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*d2m_Yprq3d4A6U68"/></div></div><figcaption class="ld le gj gh gi lf lg bd b be z dk translated">由<a class="ae lh" href="https://unsplash.com/@officestock?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">塞巴斯蒂安·赫尔曼</a>在<a class="ae lh" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上拍摄的照片</figcaption></figure><p id="2389" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">人力资源是组织的一个部门，负责寻找、筛选、招聘和培训求职者，并管理员工福利计划。</p><p id="034a" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">这种管理是在任何组织中有效管理人员的战略方法，可以帮助他们的企业获得竞争优势。这项服务旨在提高员工的绩效。</p><p id="2ba7" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">因此，在这里，我们必须站在人力资源分析专家的角度，通过利用提供的数据，我们应该确定工资是如何随着其他重要因素而变化的。</p><p id="3c76" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">解决这个问题也有助于我们对人力资源行业有一个基本的了解，也有助于我们了解分析和数据科学在这个领域的实际应用。</p><h2 id="fa35" class="me mf it bd mg mh mi dn mj mk ml dp mm lr mn mo mp lv mq mr ms lz mt mu mv iz bi translated">问题陈述</h2><p id="1d87" class="pw-post-body-paragraph li lj it lk b ll mw kd ln lo mx kg lq lr my lt lu lv mz lx ly lz na mb mc md im bi translated">这里首先让我们通过导入所有需要的库来看看数据。</p><pre class="ks kt ku kv gt nb nc nd ne aw nf bi"><span id="6eee" class="me mf it nc b gy ng nh l ni nj">#Importing all the libraries needed for the process</span><span id="a589" class="me mf it nc b gy nk nh l ni nj">import numpy as np<br/>import pandas as pd<br/>import matplotlib.pyplot as plt<br/>import seaborn as sns</span><span id="9b2a" class="me mf it nc b gy nk nh l ni nj">import statsmodels.api as sm<br/>from statsmodels.stats.outliers_influence import <br/>                                variance_inflation_factor</span><span id="765f" class="me mf it nc b gy nk nh l ni nj">hr_data=pd.read_csv("HRdataset.csv")<br/>hr_data.head(10)</span></pre><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi nl"><img src="../Images/336ddf0282b26438030a7e1aa7d67380.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*A92_k2XxxSpPs3-exvZB1A.png"/></div></div></figure><p id="6bd4" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">其目的是确定工资如何随着其他重要因素而变化。</p><p id="b70c" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">所以，这里的格言是找到影响薪水栏的变量，这是一个回归问题。要遵循的步骤是</p><ol class=""><li id="515e" class="nm nn it lk b ll lm lo lp lr no lv np lz nq md nr ns nt nu bi translated">检查数据，分析见解。</li><li id="4086" class="nm nn it lk b ll nv lo nw lr nx lv ny lz nz md nr ns nt nu bi translated">必要时将进行数据清理和工程设计。</li><li id="bdf0" class="nm nn it lk b ll nv lo nw lr nx lv ny lz nz md nr ns nt nu bi translated">如果特性和目标之间存在线性关系，我们将进行线性回归。</li><li id="f462" class="nm nn it lk b ll nv lo nw lr nx lv ny lz nz md nr ns nt nu bi translated">如果数据不能呈现线性关系，则选择非线性回归模型。</li><li id="2a6e" class="nm nn it lk b ll nv lo nw lr nx lv ny lz nz md nr ns nt nu bi translated">将调整超参数并在必要时执行交叉验证。</li><li id="bb0e" class="nm nn it lk b ll nv lo nw lr nx lv ny lz nz md nr ns nt nu bi translated">用另一个模型检查该模型的行为。</li><li id="1f5f" class="nm nn it lk b ll nv lo nw lr nx lv ny lz nz md nr ns nt nu bi translated">哪个模型产生最好的分数将被计算在内。</li></ol><h2 id="fd44" class="me mf it bd mg mh mi dn mj mk ml dp mm lr mn mo mp lv mq mr ms lz mt mu mv iz bi translated"><strong class="ak">数据分析和可视化</strong></h2><pre class="ks kt ku kv gt nb nc nd ne aw nf bi"><span id="12db" class="me mf it nc b gy ng nh l ni nj">hr_data.hist(edgecolor='black', linewidth=1.2, figsize=(20, 20));</span></pre><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div class="gh gi oa"><img src="../Images/6440cb9a1af4acd3b910ef7a97839c87.png" data-original-src="https://miro.medium.com/v2/resize:fit:1236/format:webp/1*5hLQWgpfh4ogs_Bs_yUkKg.png"/></div></figure><pre class="ks kt ku kv gt nb nc nd ne aw nf bi"><span id="0b02" class="me mf it nc b gy ng nh l ni nj">hr_data.shape</span><span id="8770" class="me mf it nc b gy nk nh l ni nj">#output:<br/>(5049, 19)</span></pre><p id="8c0a" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">在这里，我将所有数字列可视化，以下是我们从图表中获得的见解:</p><ol class=""><li id="046c" class="nm nn it lk b ll lm lo lp lr no lv np lz nq md nr ns nt nu bi translated">商业专栏似乎只有0和1，0比1多。</li><li id="0b69" class="nm nn it lk b ll nv lo nw lr nx lv ny lz nz md nr ns nt nu bi translated">年龄一栏看起来有点像右偏数据。大多数年龄喜欢在30-50岁之间。</li><li id="99d7" class="nm nn it lk b ll nv lo nw lr nx lv ny lz nz md nr ns nt nu bi translated">工资栏是统一分配的。</li><li id="e69d" class="nm nn it lk b ll nv lo nw lr nx lv ny lz nz md nr ns nt nu bi translated">在该月的列中，大部分值接近0值且高于60。</li><li id="b6ed" class="nm nn it lk b ll nv lo nw lr nx lv ny lz nz md nr ns nt nu bi translated">unit_sales在20-30个值之间有一个峰值，从那时起有高点和低点。</li><li id="a6be" class="nm nn it lk b ll nv lo nw lr nx lv ny lz nz md nr ns nt nu bi translated">随着值的增加，音量逐渐减小。0–1000是开始值。也有异常值。</li><li id="6520" class="nm nn it lk b ll nv lo nw lr nx lv ny lz nz md nr ns nt nu bi translated">奖金的值只集中在0-500之间。1500年后没有显著的数值。这说明它有极端的价值观。</li><li id="c40f" class="nm nn it lk b ll nv lo nw lr nx lv ny lz nz md nr ns nt nu bi translated">大部分基本工资在10万到15万英镑之间。</li><li id="8edf" class="nm nn it lk b ll nv lo nw lr nx lv ny lz nz md nr ns nt nu bi translated">Unit_Price的大部分值都在0-100之间。然后600就没几个了。显然也有异常值。</li><li id="8a44" class="nm nn it lk b ll nv lo nw lr nx lv ny lz nz md nr ns nt nu bi translated">该卷的图形与奖金列相似。</li><li id="9368" class="nm nn it lk b ll nv lo nw lr nx lv ny lz nz md nr ns nt nu bi translated">期初余额、期末余额、最低价都有相同类型的图表。其中它们在开始时具有高值，并且随着x轴上的值的增加而减小。这些列也有极值。</li></ol><div class="ob oc gp gr od oe"><a rel="noopener  ugc nofollow" target="_blank" href="/8-active-learning-insights-of-python-collection-module-6c9e0cc16f6b"><div class="of ab fo"><div class="og ab oh cl cj oi"><h2 class="bd jd gy z fp oj fr fs ok fu fw jc bi translated">8 Python集合模块的主动学习见解</h2><div class="ol l"><h3 class="bd b gy z fp oj fr fs ok fu fw dk translated">数据收集容器</h3></div><div class="om l"><p class="bd b dl z fp oj fr fs ok fu fw dk translated">pub.towardsai.net</p></div></div><div class="on l"><div class="oo l op oq or on os lb oe"/></div></div></a></div><div class="ob oc gp gr od oe"><a href="https://medium.com/pythoneers/fully-explained-mean-shift-clustering-with-python-51aef7a17c5d" rel="noopener follow" target="_blank"><div class="of ab fo"><div class="og ab oh cl cj oi"><h2 class="bd jd gy z fp oj fr fs ok fu fw jc bi translated">用Python全面解释均值漂移聚类</h2><div class="ol l"><h3 class="bd b gy z fp oj fr fs ok fu fw dk translated">基于无监督质心的算法学习</h3></div><div class="om l"><p class="bd b dl z fp oj fr fs ok fu fw dk translated">medium.com</p></div></div><div class="on l"><div class="ot l op oq or on os lb oe"/></div></div></a></div><p id="5b33" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">seaborn库给出了散点图中每个特性及其关系的pairplot图。这里用一个配对图来显示数据。</p><pre class="ks kt ku kv gt nb nc nd ne aw nf bi"><span id="97e0" class="me mf it nc b gy ng nh l ni nj">sns.pairplot(hr_data)</span></pre><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi ou"><img src="../Images/fd414b190d0ba07db4ba29a544a11594.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*aFQRj-anG6o-vXJkI5u_Mg.png"/></div></div></figure><p id="fbc8" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">根据上面的配对图</p><ul class=""><li id="1c78" class="nm nn it lk b ll lm lo lp lr no lv np lz nq md ov ns nt nu bi translated">salary和数据集中的任何其他列之间没有线性关系。</li><li id="c279" class="nm nn it lk b ll nv lo nw lr nx lv ny lz nz md ov ns nt nu bi translated">opening_balance、closing_balance、low与Unit_Price列具有明显的线性关系。</li><li id="2709" class="nm nn it lk b ll nv lo nw lr nx lv ny lz nz md ov ns nt nu bi translated">期初余额与期末余额和下限成正线性关系。</li></ul><p id="ab7d" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">数据集中的任何其他列之间没有明显的关系。</p><p id="f650" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">现在，我将设想目标可变工资。</p><pre class="ks kt ku kv gt nb nc nd ne aw nf bi"><span id="8d45" class="me mf it nc b gy ng nh l ni nj">sns.histplot(x='Salary',data=hr_data)</span></pre><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div class="gh gi ow"><img src="../Images/bde722bbf7503e76724bd3b77679cd0c.png" data-original-src="https://miro.medium.com/v2/resize:fit:782/format:webp/1*J1LveqE7X4_4kmM9l9oMIw.png"/></div></figure><pre class="ks kt ku kv gt nb nc nd ne aw nf bi"><span id="8de1" class="me mf it nc b gy ng nh l ni nj">sns.boxplot(x='Salary',data=hr_data)</span></pre><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div class="gh gi ox"><img src="../Images/cd73b32f7570651e6b74e2d3a8f88d63.png" data-original-src="https://miro.medium.com/v2/resize:fit:730/format:webp/1*PiIOocapDpJuuAim_6OgbQ.png"/></div></figure><p id="c14a" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">可视化目标可变工资。它是均匀分布的，没有任何异常值。</p><p id="c3be" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">这里的分类列是性别、依赖关系、呼叫、类型、账单、总销售额和评级。尽管total_sales列看起来有数值，但它是作为分类值给出的。</p><p id="fb7f" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">我还可视化了数据集中的所有分类列。</p><pre class="ks kt ku kv gt nb nc nd ne aw nf bi"><span id="0e42" class="me mf it nc b gy ng nh l ni nj">sns.countplot(x="Gender",data=hr_data)<br/>sns.countplot(x='Dependencies',data=hr_data)<br/>sns.countplot(x='Calls',data=hr_data)<br/>sns.countplot(x='Type',data=hr_data)<br/>sns.countplot(x='Billing',data=hr_data)</span></pre><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi oy"><img src="../Images/871af8743da873b58dc9b0d3b1a65116.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*_WmHqizVSBQxhPOQer-8FQ.png"/></div></div></figure><div class="ob oc gp gr od oe"><a rel="noopener  ugc nofollow" target="_blank" href="/pandas-dealing-with-categorical-data-7547305582ff"><div class="of ab fo"><div class="og ab oh cl cj oi"><h2 class="bd jd gy z fp oj fr fs ok fu fw jc bi translated">熊猫:处理分类数据</h2><div class="ol l"><h3 class="bd b gy z fp oj fr fs ok fu fw dk translated">用python创建系列和数据帧</h3></div><div class="om l"><p class="bd b dl z fp oj fr fs ok fu fw dk translated">pub.towardsai.net</p></div></div><div class="on l"><div class="oz l op oq or on os lb oe"/></div></div></a></div><h2 id="d2a6" class="me mf it bd mg mh mi dn mj mk ml dp mm lr mn mo mp lv mq mr ms lz mt mu mv iz bi translated"><strong class="ak">数据清理</strong></h2><p id="c412" class="pw-post-body-paragraph li lj it lk b ll mw kd ln lo mx kg lq lr my lt lu lv mz lx ly lz na mb mc md im bi translated">将检查数据中的异常值。</p><pre class="ks kt ku kv gt nb nc nd ne aw nf bi"><span id="5b91" class="me mf it nc b gy ng nh l ni nj">for column in hr_data:<br/>    if hr_data[column].dtype in ['int64', 'float64']:<br/>        plt.figure()<br/>        hr_data.boxplot(column = [column])</span></pre><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi pa"><img src="../Images/8aad4c60360c686b97da8c23399171de.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*rbqEuaBaWsCxgLXmBuwkmQ.png"/></div></div></figure><p id="6059" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">“年龄”、“奖金”、“基本工资”、“单价”、“数量”、“期初余额”、“期末余额”和“下限”列有异常值。现在，我们必须处理离群值，以创建一个好的模型。</p><p id="bae2" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">让我们用中间值来代替异常值，使数据不那么扭曲。我们用中间值或平均值代替极值，但建议不要使用平均值，因为它很容易受到异常值的影响。</p><pre class="ks kt ku kv gt nb nc nd ne aw nf bi"><span id="14ec" class="me mf it nc b gy ng nh l ni nj">sns.boxplot(x='Bonus',data=hr_data)</span></pre><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div class="gh gi pb"><img src="../Images/38ee8edc6c56c132788a377998cededf.png" data-original-src="https://miro.medium.com/v2/resize:fit:746/format:webp/1*JI2ImWFT5ZY-flus55hMCw.png"/></div></figure><pre class="ks kt ku kv gt nb nc nd ne aw nf bi"><span id="8a5c" class="me mf it nc b gy ng nh l ni nj">print(hr_data['Bonus'].median())<br/>print(hr_data['Bonus'].quantile(0.75))</span><span id="d662" class="me mf it nc b gy nk nh l ni nj">hr_data['Bonus']=np.where(hr_data['Bonus']&gt;17176.63,10114.01,hr_data<br/>                                           ['Bonus'])</span><span id="692e" class="me mf it nc b gy nk nh l ni nj">sns.boxplot(x='Bonus',data=hr_data)</span><span id="68f7" class="me mf it nc b gy nk nh l ni nj">#output:<br/>10114.01<br/>17176.63</span></pre><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div class="gh gi pc"><img src="../Images/132181a2c9b63d93a8b65c4e3c31e571.png" data-original-src="https://miro.medium.com/v2/resize:fit:716/format:webp/1*ol3or5xYeSDGVcsCsihyGg.png"/></div></figure><pre class="ks kt ku kv gt nb nc nd ne aw nf bi"><span id="d0e1" class="me mf it nc b gy ng nh l ni nj">hr_data.skew()</span></pre><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div class="gh gi pd"><img src="../Images/e93705e33c56a0ffdc5cb9681346b58f.png" data-original-src="https://miro.medium.com/v2/resize:fit:708/format:webp/1*a1FZ6hOAPyd_dPEo8sJQRg.png"/></div></figure><p id="7bc1" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">当我们处理异常值时，偏斜度也降低了。众所周知，当我们处理极值时，甚至偏斜度也变得正常。</p><p id="f850" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">我们知道这一点</p><ul class=""><li id="1089" class="nm nn it lk b ll lm lo lp lr no lv np lz nq md ov ns nt nu bi translated">对于对称的，偏斜度在-0.5和0.5之间。</li><li id="0961" class="nm nn it lk b ll nv lo nw lr nx lv ny lz nz md ov ns nt nu bi translated">如果数据是中度偏斜的，那么偏斜度在-1到-0.5之间。</li><li id="b8c2" class="nm nn it lk b ll nv lo nw lr nx lv ny lz nz md ov ns nt nu bi translated">如果数据高度偏斜，那么偏斜度小于-1或大于1。</li></ul><p id="047b" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">这里，除了业务列之外，所有值都在0.5到-0.5之间。当我们仔细观察时，它只有0和1，也就是说，要么有业务，要么没有。因此，我们将把它转换成假人，以便于计算。因此，我们现在忽略它的偏斜度，因为它是一个分类值。</p><p id="2c86" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">现在，我们使用虚拟对象将分类值转换为连续值。</p><pre class="ks kt ku kv gt nb nc nd ne aw nf bi"><span id="69c7" class="me mf it nc b gy ng nh l ni nj">def dummies(x,hr_data):<br/>    temp = pd.get_dummies(hr_data[x], drop_first = True)<br/>    hr_data = pd.concat([hr_data, temp], axis = 1)<br/>    hr_data.drop([x], axis = 1, inplace = True)<br/>    return hr_data</span><span id="b3c4" class="me mf it nc b gy nk nh l ni nj">hr_data = dummies('Gender',hr_data)<br/>hr_data = dummies('Dependancies',hr_data)<br/>hr_data = dummies('Calls',hr_data)<br/>hr_data = dummies('Type',hr_data)<br/>hr_data= dummies('Billing',hr_data)<br/>hr_data = dummies('Rating',hr_data)<br/>hr_data=dummies('Business',hr_data)</span></pre><p id="99c4" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">现在，让我们看看将分类数据转换成虚拟变量后的数据。</p><pre class="ks kt ku kv gt nb nc nd ne aw nf bi"><span id="8a0c" class="me mf it nc b gy ng nh l ni nj">hr_data.head(10)</span></pre><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi nl"><img src="../Images/dcbdcb544b721c37a192cd5f79bf05d1.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Z8bqgv0VoaUj31SWlUdAZg.png"/></div></div></figure><p id="35ff" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">由于有许多列具有相同的名称是的，为了方便起见，我们将更改列名。</p><pre class="ks kt ku kv gt nb nc nd ne aw nf bi"><span id="00ad" class="me mf it nc b gy ng nh l ni nj">hr_data.columns = ['Age','Salary','Months','Unit_Sales','Total_Sales','Bonus'               'BasePay','Unit_Price','Volume','openingbalance','closingbalance',<br/>'low','Male','dep','calls','One year',<br/>'Two year','billing','rating','business']</span></pre><p id="df0c" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">使用热图检查列之间的相关性。</p><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi pe"><img src="../Images/69ad5457bec70938ab16701a67310515.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*CTMQviSGutsLr9p6W68ooQ.png"/></div></div></figure><p id="c30c" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">从上面的图可以清楚地看出，期初余额、期末余额和下限之间有更多的关系。那就是存在多重共线性。</p><p id="613f" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">多重共线性意味着一个要素与数据中的多个要素相关。数据集中的多重共线性会带来很多麻烦。所以，建议在我们训练一个模型之前先处理一下。</p><p id="5b71" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">现在，让我们将数据分成x和y，以便进一步处理。</p><pre class="ks kt ku kv gt nb nc nd ne aw nf bi"><span id="cf19" class="me mf it nc b gy ng nh l ni nj">y=hr_data['Salary']<br/>x=hr_data.drop(columns=['Salary'])</span></pre><p id="75e2" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">识别多重共线性的最佳方法是计算方差膨胀因子(VIF)。VIF判断自变量是否对数据集有贡献。更多的VIF是不可取的。它检测计算方差的回归模型中是否存在多重共线性。</p><p id="0382" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">而且最好去掉一些高度相关的自变量。</p><p id="33b8" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">因此，我们在这里计算训练数据集中每一列的方差。</p><pre class="ks kt ku kv gt nb nc nd ne aw nf bi"><span id="7cad" class="me mf it nc b gy ng nh l ni nj">vif = pd.DataFrame()<br/>vif["VIF Factor"] = [variance_inflation_factor(x.values, i) for i in range(x.shape[1])]<br/>vif["features"] = x.columns</span><span id="bc61" class="me mf it nc b gy nk nh l ni nj">vif.round(1)</span></pre><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div class="gh gi pf"><img src="../Images/2aae4879b23dd30a4904cd61c6da6266.png" data-original-src="https://miro.medium.com/v2/resize:fit:414/format:webp/1*2jT94RvUthl6y41cuJF2Mw.png"/></div></figure><p id="2816" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">VIF ~ 1:可以忽略|| 1 <vif :="" moderate="" vif=""> 5:极端</vif></p><p id="6f38" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">差异较大的列应被删除，以便使数据更可靠，更易于建模。这里我们有许多变化更大的列。</p><p id="f636" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">由于低列有最高的方差，我首先从集合中删除它。</p><pre class="ks kt ku kv gt nb nc nd ne aw nf bi"><span id="9fdc" class="me mf it nc b gy ng nh l ni nj">x=x.drop(columns=['low'],axis=1)</span><span id="bc81" class="me mf it nc b gy nk nh l ni nj">#Now again calculating the VIF to see the change in data.</span><span id="ff06" class="me mf it nc b gy nk nh l ni nj">vif = pd.DataFrame()<br/>vif["VIF Factor"] = [variance_inflation_factor(x.values, i) for i in range(x.shape[1])]<br/>vif["features"] = x.columns<br/>vif.round(1)</span></pre><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div class="gh gi pg"><img src="../Images/1dcfece38ee56a3d8626aafa57a4a0f9.png" data-original-src="https://miro.medium.com/v2/resize:fit:360/format:webp/1*iWKMEwfEAv9DNZK6xgglSA.png"/></div></figure><p id="6d9d" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">现在，让我们使用相关图来查看多重共线性是否在控制之中。</p><pre class="ks kt ku kv gt nb nc nd ne aw nf bi"><span id="851e" class="me mf it nc b gy ng nh l ni nj">plt.figure(figsize=[10,8])<br/>sns.heatmap(x.corr(),annot=True)</span></pre><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div class="gh gi ph"><img src="../Images/7bea89db9870f31a146ed5c0f921ae13.png" data-original-src="https://miro.medium.com/v2/resize:fit:1260/format:webp/1*cNARZESRNRfBs3yWwkPOlw.png"/></div></figure><p id="b494" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">现在，我们可以看到数据中没有多重共线性。因此，现在我们可以更进一步，对我们的数据进行建模。</p><h2 id="2cbe" class="me mf it bd mg mh mi dn mj mk ml dp mm lr mn mo mp lv mq mr ms lz mt mu mv iz bi translated">数据建模</h2><p id="7d83" class="pw-post-body-paragraph li lj it lk b ll mw kd ln lo mx kg lq lr my lt lu lv mz lx ly lz na mb mc md im bi translated">这里我们将使用决策树回归器，因为它是一个回归问题。选择决策树回归器，因为目标变量薪金和数据中的任何其他特征变量之间没有线性关系。当数据中存在非线性关系时，决策树回归器会带来最佳结果。它们可以很好地处理均匀分布的数据。</p><p id="45ce" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">我们将使用回归函数来拟合x_train和y_train。</p><pre class="ks kt ku kv gt nb nc nd ne aw nf bi"><span id="82f7" class="me mf it nc b gy ng nh l ni nj">from sklearn.model_selection import train_test_split<br/>x_train,x_test,y_train,y_test=train_test_split(x,y,test_size=0.2,random_state=1)</span><span id="be50" class="me mf it nc b gy nk nh l ni nj">from sklearn.tree import DecisionTreeRegressor<br/>regressor = DecisionTreeRegressor(random_state=100)<br/>regressor.fit(x_train, y_train)</span><span id="6960" class="me mf it nc b gy nk nh l ni nj">print(x_train.shape)<br/>print(x_test.shape)</span><span id="e37d" class="me mf it nc b gy nk nh l ni nj">#output:<br/>(4039, 10)<br/>(1010, 10)<br/>---------------------------------------------------------</span><span id="b439" class="me mf it nc b gy nk nh l ni nj">print(y_train.shape)<br/>print(y_test.shape)</span><span id="055f" class="me mf it nc b gy nk nh l ni nj">#output:<br/>(4039,)<br/>(1010,)</span></pre><p id="7c75" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">知道测试和训练数据的分数。</p><pre class="ks kt ku kv gt nb nc nd ne aw nf bi"><span id="054a" class="me mf it nc b gy ng nh l ni nj">print("Training score:",regressor.score(x_train,y_train))<br/>print("Testing score:",regressor.score(x_test,y_test))</span><span id="1a32" class="me mf it nc b gy nk nh l ni nj">#output:<br/>Training score: 1.0<br/>Testing score: -0.8967580213939657</span></pre><p id="a460" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">我们可以看到，该模型在训练数据集上表现良好，而在测试数据集上表现不佳，这表明该模型过度拟合。现在，让我们来看看指标。</p><pre class="ks kt ku kv gt nb nc nd ne aw nf bi"><span id="f8ea" class="me mf it nc b gy ng nh l ni nj">pred=regressor.predict(x_test)</span><span id="e157" class="me mf it nc b gy nk nh l ni nj">from sklearn import metrics<br/>print('Mean Absolute Error:', metrics.mean_absolute_error(y_test, <br/>                                    pred))</span><span id="7ca9" class="me mf it nc b gy nk nh l ni nj">print('Root Mean Squared Error of test dataset:',      <br/>                 np.sqrt(metrics.mean_squared_error(y_test, pred)))</span><span id="eb24" class="me mf it nc b gy nk nh l ni nj">#output:<br/>Mean Absolute Error: 64909.09488118812<br/>Root Mean Squared Error of test dataset: 80323.76501177333<br/>-----------------------------------------------------------------</span><span id="60ef" class="me mf it nc b gy nk nh l ni nj">from sklearn.metrics import r2_score<br/>r2 = r2_score(y_test,pred)<br/>print('r2 score for perfect model is', r2)</span><span id="9c97" class="me mf it nc b gy nk nh l ni nj">#output:<br/>r2 score for perfect model is -0.8967580213939657</span></pre><h2 id="9f70" class="me mf it bd mg mh mi dn mj mk ml dp mm lr mn mo mp lv mq mr ms lz mt mu mv iz bi translated">使用GridSearchCV进行超参数调整</h2><p id="645b" class="pw-post-body-paragraph li lj it lk b ll mw kd ln lo mx kg lq lr my lt lu lv mz lx ly lz na mb mc md im bi translated">GridSearchCV是一种从给定参数的网格中穷举搜索候选最佳参数的方法。需要为此交叉验证搜索方法提供搜索的目标估计值(模型)和参数。当我们为目标模型和数据集寻找最佳参数时，GridSearchCV非常有用。</p><p id="d82f" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">所以这里我使用GridSearchCV方法来为决策树回归器寻找最佳参数。</p><pre class="ks kt ku kv gt nb nc nd ne aw nf bi"><span id="d26a" class="me mf it nc b gy ng nh l ni nj">from sklearn.model_selection import GridSearchCV<br/>from sklearn.tree import DecisionTreeRegressor<br/>#making the instance<br/>model= DecisionTreeRegressor(random_state=1205)<br/>#Hyper Parameters Set<br/>params = {'max_features': ['auto', 'sqrt', 'log2'],<br/>          'min_samples_split': [2,3,4,5,6,7,8,9,10,11,12,13,14,15], <br/>          'min_samples_leaf':[1,2,3,4,5,6,7,8,9,10,11],<br/>          'random_state':[123]}<br/>#Making models with hyper parameters sets<br/>model = GridSearchCV(model, param_grid=params, n_jobs=-1)<br/>#Learning<br/>model.fit(x_train,y_train)<br/>#The best hyper parameters set<br/>print("Best Hyper Parameters:",model.best_params_)<br/>#Prediction<br/>grid_cv_prediction=model.predict(x_test)</span><span id="7fca" class="me mf it nc b gy nk nh l ni nj">#output:<br/>Best Hyper Parameters: {'max_features': 'sqrt', 'min_samples_leaf': 11, 'min_samples_split': 2, 'random_state': 123}</span></pre><p id="cb90" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">上面给出的是我们的模型的最佳参数。</p><pre class="ks kt ku kv gt nb nc nd ne aw nf bi"><span id="0b07" class="me mf it nc b gy ng nh l ni nj">print("Training score:",model.score(x_train,y_train))<br/>print("Testing score:",model.score(x_test,y_test))</span><span id="bd0b" class="me mf it nc b gy nk nh l ni nj">#output:<br/>Training score: 0.14876469974509265<br/>Testing score: -0.09869253838487135<br/>-------------------------------------------------------</span><span id="5171" class="me mf it nc b gy nk nh l ni nj">from sklearn import metrics<br/>print('Mean Absolute Error:', metrics.mean_absolute_error(y_test, grid_cv_prediction))<br/>print('Root Mean Squared Error of test dataset:', np.sqrt(metrics.mean_squared_error(y_test, grid_cv_prediction)))</span><span id="1e1d" class="me mf it nc b gy nk nh l ni nj">from sklearn.metrics import r2_score<br/>r2 = r2_score(y_test, grid_cv_prediction)<br/>print('r2 score for perfect model is', r2)</span><span id="90b1" class="me mf it nc b gy nk nh l ni nj">#output:<br/>Mean Absolute Error: 51684.006219741175<br/>Root Mean Squared Error of test dataset: 61133.06632846143<br/>r2 score for perfect model is -0.09869253838487135</span></pre><p id="fe71" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">我们现在正在用最好的参数创建一个最好的模型，即使现在我们也可以看到r2分数并不令人满意。</p><p id="45b5" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">正如我们所知，决策树回归器倾向于过度拟合数据。正如所看到的，很明显，它在训练模型上工作得很好，而不是在测试上，这意味着它是过度拟合的。所以，现在我们将使用随机森林来使模型更加可靠。</p><h2 id="8223" class="me mf it bd mg mh mi dn mj mk ml dp mm lr mn mo mp lv mq mr ms lz mt mu mv iz bi translated">这是随机森林回归模型。</h2><pre class="ks kt ku kv gt nb nc nd ne aw nf bi"><span id="3aa6" class="me mf it nc b gy ng nh l ni nj">from sklearn.ensemble import RandomForestRegressor<br/>rf_1_regressor = RandomForestRegressor(n_estimators = 100,<br/>                                                  random_state =1)<br/>rf_1_regressor.fit(x_train, y_train)</span><span id="b520" class="me mf it nc b gy nk nh l ni nj">print("Training score:",rf_1_regressor.score(x_train,y_train))<br/>print("Testing score:",rf_1_regressor.score(x_test,y_test))</span><span id="b829" class="me mf it nc b gy nk nh l ni nj">#output:<br/>Training score: 0.8474146255308276<br/>Testing score: -0.07967104711600737<br/>-----------------------------------------------------------</span><span id="ee00" class="me mf it nc b gy nk nh l ni nj">rf_1_prediction=rf_1_regressor.predict(x_test)</span><span id="a82b" class="me mf it nc b gy nk nh l ni nj">from sklearn import metrics<br/>print('Mean Absolute Error:', metrics.mean_absolute_error(y_test,<br/>                                                 rf_1_prediction))</span><span id="ecbc" class="me mf it nc b gy nk nh l ni nj">print('Root Mean Squared Error of test dataset:', np.sqrt(metrics.mean_squared_error(y_test, rf_1_prediction)))</span><span id="65a2" class="me mf it nc b gy nk nh l ni nj">from sklearn.metrics import r2_score<br/>r2 = r2_score(y_test, rf_1_prediction)<br/>print('r2 score for perfect model is', r2)</span><span id="f57f" class="me mf it nc b gy nk nh l ni nj">#output:<br/>Mean Absolute Error: 51464.25526891089<br/>Root Mean Squared Error of test dataset: 60601.56223728373<br/>r2 score for perfect model is -0.07967104711600737</span></pre><p id="3e8c" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">以下是随机森林模型的度量值。与决策树模型相比，MAE和RMSE的价值较低。这意味着随机森林比决策树工作得更好。</p><p id="64b6" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">为了获得更好的结果，我们还将调整随机森林中的超参数。</p><div class="ob oc gp gr od oe"><a rel="noopener  ugc nofollow" target="_blank" href="/hyper-parameters-randomseachcv-and-gridsearchcv-in-machine-learning-b7d091cf56f4"><div class="of ab fo"><div class="og ab oh cl cj oi"><h2 class="bd jd gy z fp oj fr fs ok fu fw jc bi translated">超参数:机器学习中的RandomSeachCV和GridSearchCV</h2><div class="ol l"><h3 class="bd b gy z fp oj fr fs ok fu fw dk translated">提高算法精确度的技术</h3></div><div class="om l"><p class="bd b dl z fp oj fr fs ok fu fw dk translated">pub.towardsai.net</p></div></div><div class="on l"><div class="pi l op oq or on os lb oe"/></div></div></a></div><h2 id="5905" class="me mf it bd mg mh mi dn mj mk ml dp mm lr mn mo mp lv mq mr ms lz mt mu mv iz bi translated">基于GridSearchCV方法的随机森林算法超参数调整</h2><pre class="ks kt ku kv gt nb nc nd ne aw nf bi"><span id="f179" class="me mf it nc b gy ng nh l ni nj">from sklearn.model_selection import GridSearchCV</span><span id="2eea" class="me mf it nc b gy nk nh l ni nj">param_grid = {'bootstrap': [True], 'max_depth': [5, 10, None], <br/>              'max_features': ['auto', 'log2']}<br/>              }</span><span id="f414" class="me mf it nc b gy nk nh l ni nj">rfr = RandomForestRegressor(random_state = 1)</span><span id="a441" class="me mf it nc b gy nk nh l ni nj">g_search.fit(x_train, y_train);<br/>print(g_search.best_params_)</span><span id="8b60" class="me mf it nc b gy nk nh l ni nj">#output:<br/>{'bootstrap': True, 'max_depth': 5, 'max_features': 'log2',<br/>                                            'n_estimators': 15}<br/>--------------------------------------------------------------</span></pre><p id="938b" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">这些是最好的参数。现在用这些参数建立一个模型。</p><pre class="ks kt ku kv gt nb nc nd ne aw nf bi"><span id="97ba" class="me mf it nc b gy ng nh l ni nj">from sklearn.ensemble import RandomForestRegressor<br/>  <br/>rfr = RandomForestRegressor(bootstrap= True, max_depth= 5,<br/>                            max_features='log2', n_estimators=15)</span><span id="e3e0" class="me mf it nc b gy nk nh l ni nj">rfr.fit(x_train, y_train)</span><span id="0ac2" class="me mf it nc b gy nk nh l ni nj">#output:<br/>RandomForestRegressor(max_depth=5, max_features='log2',<br/>                                          n_estimators=15)<br/>--------------------------------------------------------------</span><span id="ec98" class="me mf it nc b gy nk nh l ni nj">print("Training score:",rfr.score(x_train,y_train))<br/>print("Testing score:",rfr.score(x_test,y_test))</span><span id="a223" class="me mf it nc b gy nk nh l ni nj">#output:<br/>Training score: 0.03627401309472211<br/>Testing score: 0.0016225374683012106<br/>---------------------------------------------------------------</span><span id="3fac" class="me mf it nc b gy nk nh l ni nj">rfr_pred=rfr.predict(x_test)</span><span id="1fbe" class="me mf it nc b gy nk nh l ni nj">from sklearn import metrics<br/>print('Mean Absolute Error:', metrics.mean_absolute_error(y_test,<br/>                                                     rfr_pred))</span><span id="1522" class="me mf it nc b gy nk nh l ni nj">print('Root Mean Squared Error of test dataset:',<br/>              np.sqrt(metrics.mean_squared_error(y_test, rfr_pred)))</span><span id="ad8c" class="me mf it nc b gy nk nh l ni nj">from sklearn.metrics import r2_score<br/>r2 = r2_score(y_test, rfr_pred)<br/>print('r2 score for perfect model is', r2)</span><span id="3ce8" class="me mf it nc b gy nk nh l ni nj">#output:<br/>Mean Absolute Error: 50178.12205393546<br/>Root Mean Squared Error of test dataset: 58275.42863413414<br/>r2 score for perfect model is 0.0016225374683012106</span></pre><p id="9dba" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">我们得到了测试数据集的正分数，但我们也将尝试使用随机cv进行调整，看看是否有任何变化。</p><h2 id="6365" class="me mf it bd mg mh mi dn mj mk ml dp mm lr mn mo mp lv mq mr ms lz mt mu mv iz bi translated">随机森林的RandomizedSearchCV方法</h2><pre class="ks kt ku kv gt nb nc nd ne aw nf bi"><span id="9b96" class="me mf it nc b gy ng nh l ni nj">from sklearn.model_selection import RandomizedSearchCV</span><span id="2a36" class="me mf it nc b gy nk nh l ni nj">max_features = ['auto', 'log2']<br/>max_depth.append(None)<br/>bootstrap = [True, False]</span><span id="2167" class="me mf it nc b gy nk nh l ni nj">r_grid = {'n_estimators': n_estimators, 'max_features':<br/>         max_features,'max_depth': max_depth,'bootstrap': bootstrap}</span></pre><h2 id="3e2d" class="me mf it bd mg mh mi dn mj mk ml dp mm lr mn mo mp lv mq mr ms lz mt mu mv iz bi translated">现在，拟合模型3倍</h2><pre class="ks kt ku kv gt nb nc nd ne aw nf bi"><span id="23c7" class="me mf it nc b gy ng nh l ni nj">rfr_random = RandomizedSearchCV(estimator=rfr, param_distributions=r_grid, n_iter = 20,<br/>            scoring='neg_mean_absolute_error', cv = 3, verbose=2,<br/>            random_state=42, n_jobs=-1, return_train_score=True)</span><span id="1e21" class="me mf it nc b gy nk nh l ni nj">rfr_random.fit(x_train, y_train);</span><span id="0953" class="me mf it nc b gy nk nh l ni nj">#Fitting 3 folds for each of 20 candidates, totalling 60 fits</span><span id="0a7e" class="me mf it nc b gy nk nh l ni nj">print(rfr_random.best_params_)</span><span id="b157" class="me mf it nc b gy nk nh l ni nj">#output:<br/>{'n_estimators': 6, 'max_features': 'log2', 'max_depth': 5,<br/>                                           'bootstrap': True}</span></pre><p id="4706" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">这些是它的最佳参数。现在我将使用这些参数创建一个模型。</p><pre class="ks kt ku kv gt nb nc nd ne aw nf bi"><span id="aead" class="me mf it nc b gy ng nh l ni nj">from sklearn.ensemble import RandomForestRegressor<br/>rand_cv_rfr = RandomForestRegressor(n_estimators=6,    <br/>                    max_features='log2',max_depth=5, bootstrap=True)</span><span id="c6fc" class="me mf it nc b gy nk nh l ni nj">rand_cv_rfr.fit(x_train, y_train)</span><span id="5806" class="me mf it nc b gy nk nh l ni nj">#output:<br/>RandomForestRegressor(max_depth=5, max_features='log2', <br/>                                               n_estimators=6)<br/>------------------------------------------------------------------</span><span id="6899" class="me mf it nc b gy nk nh l ni nj">print("Training score:",rand_cv_rfr.score(x_train,y_train))<br/>print("Testing score:",rand_cv_rfr.score(x_test,y_test))</span><span id="37e3" class="me mf it nc b gy nk nh l ni nj">#output:<br/>Training score: 0.03377887516438849<br/>Testing score: 0.000352599003412557<br/>-----------------------------------------------------------------</span><span id="3909" class="me mf it nc b gy nk nh l ni nj">rand_predict=rand_cv_rfr.predict(x_test)</span><span id="ab88" class="me mf it nc b gy nk nh l ni nj">from sklearn import metrics<br/>print('Mean Absolute Error:', metrics.mean_absolute_error(y_test,<br/>                                                    rand_predict))</span><span id="d784" class="me mf it nc b gy nk nh l ni nj">print('Root Mean Squared Error of test dataset:', <br/>         np.sqrt(metrics.mean_squared_error(y_test,rand_predict)))</span><span id="1dd5" class="me mf it nc b gy nk nh l ni nj">from sklearn.metrics import r2_score<br/>r2 = r2_score(y_test, rand_predict)<br/>print('r2 score for perfect model is', r2)</span><span id="0af5" class="me mf it nc b gy nk nh l ni nj">#output:<br/>Mean Absolute Error: 50093.86614957989<br/>Root Mean Squared Error of test dataset: 58312.480096178886<br/>r2 score for perfect model is 0.000352599003412557</span></pre><p id="279b" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">同样，我们将检查2、4和5倍的分数。现在，让我们创建一个数据框，看看哪个模型能产生最佳值。</p><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div class="gh gi pj"><img src="../Images/7350d7ff996424bd9f1fdf01a385f1d2.png" data-original-src="https://miro.medium.com/v2/resize:fit:1054/format:webp/1*ZLpwtpRfbSUhAOGAhtPaow.png"/></div></figure><pre class="ks kt ku kv gt nb nc nd ne aw nf bi"><span id="c181" class="me mf it nc b gy ng nh l ni nj">df = pd.DataFrame(scores, columns = ['Model','MAE','RMSE','R2 value'])<br/>df</span></pre><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div class="gh gi pk"><img src="../Images/9480394d4f502c35e92024c8ce082fbb.png" data-original-src="https://miro.medium.com/v2/resize:fit:924/format:webp/1*cqhDobSHd0I9RMIwBChh0A.png"/></div></figure><p id="5aaf" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">如果r &gt; 0表示正相关。r &lt; 0 indicates a negative association. The weak linear relationship shows a ‘0’ value of r. When the r slides away from the ‘0’ value on either side of ‘1’ and ‘-1’ the strength of the linear relationship increases.</p><p id="10af" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">When we analyze the above values of the metrics for all the models, we trained the Random Forest with GRID CV technique has a good score compared to all others.</p><pre class="ks kt ku kv gt nb nc nd ne aw nf bi"><span id="7c6e" class="me mf it nc b gy ng nh l ni nj">MAE =50178.12 || RMSE=58275.42 || R2 value=0.001</span></pre><h2 id="3ba5" class="me mf it bd mg mh mi dn mj mk ml dp mm lr mn mo mp lv mq mr ms lz mt mu mv iz bi translated">Result and recommendations</h2><p id="1150" class="pw-post-body-paragraph li lj it lk b ll mw kd ln lo mx kg lq lr my lt lu lv mz lx ly lz na mb mc md im bi translated">Random Forest with GRID CV that has 3 folds gave us good values they are</p><pre class="ks kt ku kv gt nb nc nd ne aw nf bi"><span id="2c0c" class="me mf it nc b gy ng nh l ni nj">MSE:50178.12 || RMSE:58275.42 || R2 Value:0.001</span></pre><h2 id="35e5" class="me mf it bd mg mh mi dn mj mk ml dp mm lr mn mo mp lv mq mr ms lz mt mu mv iz bi translated">Conclusion:</h2><p id="b43d" class="pw-post-body-paragraph li lj it lk b ll mw kd ln lo mx kg lq lr my lt lu lv mz lx ly lz na mb mc md im bi translated">The decision trees and random forests work well when there is plenty of data. Hereafter removing the columns that had extremely high VIF values like base_pay, business, openingbalance, closingbalance, low was removed, the data got reduced to 10 columns. So if we had more columns that influence the salary then the model would have yielded much better R2 values.</p><p id="9a02" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">I hope you like the article. Reach me on my <a class="ae lh" href="https://www.linkedin.com/in/data-scientist-95040a1ab/" rel="noopener ugc nofollow" target="_blank"> LinkedIn </a>和<a class="ae lh" href="https://twitter.com/amitprius" rel="noopener ugc nofollow" target="_blank"> twitter </a>。</p><h1 id="c204" class="pl mf it bd mg pm pn po mj pp pq pr mm ki ps kj mp kl pt km ms ko pu kp mv pv bi translated">推荐文章</h1><p id="91cf" class="pw-post-body-paragraph li lj it lk b ll mw kd ln lo mx kg lq lr my lt lu lv mz lx ly lz na mb mc md im bi translated"><a class="ae lh" href="https://medium.com/towards-artificial-intelligence/nlp-zero-to-hero-with-python-2df6fcebff6e?sk=2231d868766e96b13d1e9d7db6064df1" rel="noopener"> 1。NLP —零到英雄与Python </a> <br/> 2。<a class="ae lh" rel="noopener ugc nofollow" target="_blank" href="/numpy-linear-algebra-on-images-ed3180978cdb?source=friends_link&amp;sk=d9afa4a1206971f9b1f64862f6291ac0"> NumPy:图像上的线性代数</a>T5】3。<a class="ae lh" rel="noopener ugc nofollow" target="_blank" href="/exception-handling-concepts-in-python-4d5116decac3?source=friends_link&amp;sk=a0ed49d9fdeaa67925eac34ecb55ea30">Python中的异常处理概念</a> <br/> 4。<a class="ae lh" rel="noopener ugc nofollow" target="_blank" href="/principal-component-analysis-in-dimensionality-reduction-with-python-1a613006d531?source=friends_link&amp;sk=3ed0671fdc04ba395dd36478bcea8a55">用Python进行主成分分析降维</a> <br/> 5。<a class="ae lh" href="https://medium.com/towards-artificial-intelligence/fully-explained-k-means-clustering-with-python-e7caa573176a?source=friends_link&amp;sk=9c5c613ceb10f2d203712634f3b6fb28" rel="noopener">用Python全面讲解K-means聚类</a> <br/> 6。<a class="ae lh" href="https://medium.com/towards-artificial-intelligence/fully-explained-linear-regression-with-python-fe2b313f32f3?source=friends_link&amp;sk=53c91a2a51347ec2d93f8222c0e06402" rel="noopener">用Python </a> <br/> 7全面讲解了线性回归。<a class="ae lh" href="https://medium.com/towards-artificial-intelligence/fully-explained-logistic-regression-with-python-f4a16413ddcd?source=friends_link&amp;sk=528181f15a44e48ea38fdd9579241a78" rel="noopener">用Python </a> <br/>充分解释了Logistic回归8。<a class="ae lh" rel="noopener ugc nofollow" target="_blank" href="/differences-between-concat-merge-and-join-with-python-1a6541abc08d?source=friends_link&amp;sk=3b37b694fb90db16275059ea752fc16a">concat()、merge()和join()与Python </a> <br/>的区别9。<a class="ae lh" rel="noopener ugc nofollow" target="_blank" href="/data-wrangling-with-python-part-1-969e3cc81d69?source=friends_link&amp;sk=9c3649cf20f31a5c9ead51c50c89ba0b">与Python的数据角力—第一部分</a> <br/> 10。<a class="ae lh" href="https://medium.com/analytics-vidhya/confusion-matrix-in-machine-learning-91b6e2b3f9af?source=friends_link&amp;sk=11c6531da0bab7b504d518d02746d4cc" rel="noopener">机器学习中的混淆矩阵</a></p></div></div>    
</body>
</html>