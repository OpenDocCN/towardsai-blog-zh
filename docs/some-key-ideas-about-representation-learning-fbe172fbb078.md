# 关于表征学习的一些重要观点

> 原文：<https://pub.towardsai.net/some-key-ideas-about-representation-learning-fbe172fbb078?source=collection_archive---------3----------------------->

## 每一个机器学习解决方案的基础部分。

![](img/7f5832a3a1f29e8f723c25919fc7f894.png)

来源:[https://synced review . com/2021/09/16/deep mind-pod racer-TPU-based-rl-frameworks-deliver-excellent-performance-at-low-cost-105/](https://syncedreview.com/2021/09/16/deepmind-podracer-tpu-based-rl-frameworks-deliver-exceptional-performance-at-low-cost-105/)

> 我最近创办了一份专注于人工智能的教育时事通讯，已经有超过 125，000 名订户。《序列》是一份无废话(意思是没有炒作，没有新闻等)的 ML 导向时事通讯，需要 5 分钟阅读。目标是让你与机器学习项目、研究论文和概念保持同步。请通过订阅以下内容来尝试一下:

[](https://thesequence.substack.com/) [## 序列

### 与机器学习、人工智能和数据发展保持同步的最佳资源…

thesequence.substack.com](https://thesequence.substack.com/) 

理解输入数据集的特征是机器学习算法的一项基本能力。给定特定的输入，机器学习模型需要推断关于数据的特定特征，以便执行一些目标动作。表示学习或特征学习是机器学习空间的子学科，处理提取特征或理解数据集的表示。

表征学习可以用一个非常简单的例子来说明。采用深度学习算法，尝试识别下图中的几何形状:

![](img/7b646aea3904b1d275c4089c6680125e.png)

为了将像素匹配到几何形状，算法首先需要理解数据的一些基本特征/表示，例如角的数量。这就是表征学习的作用。

![](img/c0eb833ffdd5ff2a8d2e7a96ce0e293b.png)

几十年来，表示学习已经成为机器学习领域的一个既定学科，但随着深度学习的出现，它的相关性最近大大增加了。虽然分类等传统机器学习技术通常处理数学上结构良好的数据集，但深度学习模型处理的是图像或声音等没有明确特征的数据。从这个意义上说，表征学习是大多数深度学习架构的关键要素。

表征学习的核心问题是确定输入数据的最佳表征。在深度学习的背景下，表征的质量主要取决于它在多大程度上促进了学习过程。在现实世界中，学习算法和模型的底层表示是直接相关的。

# 没有免费的午餐定理

如果模型的知识表示与其学习算法有关，那么选择正确的表示应该是微不足道的，对吗？我们只需选择与学习任务相关的知识表示，这将保证最佳性能。我希望事情就这么简单。在寻找最佳表象的过程中，我们很快找到了一个老朋友:不免费午餐定理(NFLT)。

NFLT 是困扰最务实的数据科学家和技术专家的数学悖论之一。简而言之，NFLT 指出，在所有可能的数据生成分布的平均值上，当处理先前未观察到的点时，每个机器学习算法具有近似相同的错误率(阅读我先前关于 NFLT 的文章)。换句话说，在给定足够广泛的数据集的情况下，没有任何机器学习算法比任何其他算法更好。

![](img/8ec734fedf50dbf47081fb9699d5dee8.png)

在表征学习的背景下，NFLT 证明了多重知识表征可以适用于学习任务。如果是这样，我们如何根据经验决定一种知识表示与另一种知识表示？答案是机器学习和深度学习模型中的核心技术之一，但经常被忽视:正则化。

# 正规化

机器学习算法的一个核心任务是在训练数据集以外的新输入下表现良好。优化该任务是正则化的作用。从概念上讲，正则化会导致对机器学习算法的修改，从而减少测试或泛化误差，而不影响训练误差。

现在让我们来一个完整的循环，看看正则化是如何与表示学习相关的。这种关系非常明显:知识表示的质量从根本上说与其有效概括知识的能力有关。换句话说，知识表示必须能够适应训练数据集之外的新输入。为了在新输入下表现良好并减少泛化误差，任何知识表示在正则化技术中都是有用的。因此，表征学习模型的质量直接受到其使用不同正则化策略的能力的影响。下一步是找出哪些正则化策略与表征学习特别相关。这将是未来帖子的主题。

既然我们知道正则化是一种改进知识表示的机制，下一步就是评估给定表示的质量。本质上，我们试图回答一个简单的问题:是什么让知识表现优于他人？

# 通过正则化提高知识

为了让术语更直截了当，正则化指的是模型在不影响训练误差的情况下减少其测试误差(生成误差)的能力。每一种知识表示都有某些特征，这些特征使得它更适合特定的正则化技术。人工智能杰出人物伊恩·古德费勒(Ian Goodfellow)和约舒阿·本吉奥(Yoshua Bengio)在正则化领域做了一些出色的工作。根据 Goodfellow 和 Bengio 的论文，有几个特征使得知识表示在正则化时更有效。我总结了以下五种我最喜欢的监管模式:

# 1 —解开因果因素

健壮知识表示的关键指标之一是其特征对应于训练数据的潜在原因的事实。此特征有助于区分制图表达中的哪些要素对应于输入数据集中的特定原因，从而有助于更好地区分某些要素和其他要素。

# 2 —平滑度

制图表达平滑度是假设输入数据集中相邻点之间的假设值不会发生剧烈变化。从数学上来说，平滑度意味着对于非常小的 e， *f(x+ed)≈ f(x)* 。这一特性允许知识表示在输入数据集中的封闭区域内更好地进行概括。

# 3 线性度

线性是一种正则化模式，是对平滑假设的补充。从概念上讲，这种特性假设一些输入变量之间的关系是线性的 *(f(x) = ax + b)* ，这使得即使当输入存在相对较大的变化时也能做出准确的预测。

# 4 —分层结构

基于层次的知识表示是许多正则化技术的理想选择。层次结构假设网络中的每一步都可以用之前的步骤来解释，这极大地有助于通过知识表示进行更好的推理。

# 5-流形表示

流形学习是机器学习最迷人、数学上最深厚的基础之一。从概念上讲，流形是完全连接点的高维区域。流形假设表明概率质量倾向于集中在输入数据的流形中。流形的伟大之处在于，它们相对容易从高维结构简化为更容易、更便宜操作的低维表示。许多正则化算法在检测和操纵流形方面特别有效。

尽管它很重要，但在深度学习领域，表征学习仍然是一个不太为人所知的学科。为了为任何给定的任务选择最佳的神经网络架构，理解基础数据集的特征和表示是至关重要的。本文中解释的一些特征为在深度学习解决方案的背景下考虑表征学习提供了一个简单的框架。