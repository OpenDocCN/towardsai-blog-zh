<html>
<head>
<title>How To Train Your BERT Model 5X Faster Than In Colab</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">如何训练你的伯特模型5X比在Colab更快</h1>
<blockquote>原文：<a href="https://pub.towardsai.net/how-to-train-your-bert-model-5x-faster-than-in-colab-27c8cef9a6b4?source=collection_archive---------0-----------------------#2022-06-14">https://pub.towardsai.net/how-to-train-your-bert-model-5x-faster-than-in-colab-27c8cef9a6b4?source=collection_archive---------0-----------------------#2022-06-14</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><figure class="gl gn jo jp jq jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi jn"><img src="../Images/6a0c865fc80997345db2413975763f3f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*n3CRR_VbWymDtJ6F"/></div></div><figcaption class="jy jz gj gh gi ka kb bd b be z dk translated"><a class="ae kc" href="https://unsplash.com/@sabrituzcu?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">萨布里·图兹库</a>在<a class="ae kc" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上的照片</figcaption></figure><h1 id="6c3e" class="kd ke iq bd kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la bi translated">示例笔记本</h1><p id="a718" class="pw-post-body-paragraph lb lc iq ld b le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly ij bi translated">在这篇文章中，我们将使用一个叫做TransferLearning的笔记本，它是用来自<a class="ae kc" href="https://alvinntnu.github.io/NTNU_ENC2045_LECTURES/temp/sentiment-analysis-using-bert-keras-movie-reviews.html" rel="noopener ugc nofollow" target="_blank">的文章</a>的代码创建的，作者是<a class="ae kc" href="https://alvinchen.myftp.org/" rel="noopener ugc nofollow" target="_blank"> Alvin Chen </a>。</p><p id="6a52" class="pw-post-body-paragraph lb lc iq ld b le lz lg lh li ma lk ll lm mb lo lp lq mc ls lt lu md lw lx ly ij bi translated">我们将使用拥抱脸变形金刚库建立一个带有预训练BERT模型的情感分类器。</p><p id="7836" class="pw-post-body-paragraph lb lc iq ld b le lz lg lh li ma lk ll lm mb lo lp lq mc ls lt lu md lw lx ly ij bi translated">以下是您自己下载和运行笔记本所需的文件:</p><ul class=""><li id="37e6" class="me mf iq ld b le lz li ma lm mg lq mh lu mi ly mj mk ml mm bi translated"><a class="ae kc" href="https://drive.google.com/file/d/1jCExDY-VUDbdVrJ3HcpSUO-9CgrwJykc/view?usp=sharing" rel="noopener ugc nofollow" target="_blank">笔记本</a></li><li id="b42e" class="me mf iq ld b le mn li mo lm mp lq mq lu mr ly mj mk ml mm bi translated">包含数据集(在单元格中下载)</li></ul></div><div class="ab cl ms mt hu mu" role="separator"><span class="mv bw bk mw mx my"/><span class="mv bw bk mw mx my"/><span class="mv bw bk mw mx"/></div><div class="ij ik il im in"><h1 id="8aef" class="kd ke iq bd kf kg mz ki kj kk na km kn ko nb kq kr ks nc ku kv kw nd ky kz la bi translated">转移学习复习</h1><p id="580a" class="pw-post-body-paragraph lb lc iq ld b le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly ij bi translated">迁移学习是一种可以用来加速新机器学习模型开发的方法。它的工作原理是利用在一个数据集上训练模型所获得的知识，并将其应用于另一个相关的数据集。</p><p id="0021" class="pw-post-body-paragraph lb lc iq ld b le lz lg lh li ma lk ll lm mb lo lp lq mc ls lt lu md lw lx ly ij bi translated">例如，如果数据科学家想要建立一个模型来识别图片中的狗，他们可以使用以前项目中用于训练模型识别猫的数据。当数据有限或需要快速构建模型时，这尤其有用。</p></div><div class="ab cl ms mt hu mu" role="separator"><span class="mv bw bk mw mx my"/><span class="mv bw bk mw mx my"/><span class="mv bw bk mw mx"/></div><div class="ij ik il im in"><h1 id="ca29" class="kd ke iq bd kf kg mz ki kj kk na km kn ko nb kq kr ks nc ku kv kw nd ky kz la bi translated">伯特复习者</h1><p id="2e2b" class="pw-post-body-paragraph lb lc iq ld b le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly ij bi translated">BERT是基于转换器的自然语言处理模型，于2018年提出，由谷歌开源。</p><p id="cdea" class="pw-post-body-paragraph lb lc iq ld b le lz lg lh li ma lk ll lm mb lo lp lq mc ls lt lu md lw lx ly ij bi translated">该模型在大型文本语料库(如维基百科)上进行训练，可用于问答和文本分类等各种任务。BERT可以很容易地在各种任务上进行微调，例如文本分类和命名实体识别。</p></div><div class="ab cl ms mt hu mu" role="separator"><span class="mv bw bk mw mx my"/><span class="mv bw bk mw mx my"/><span class="mv bw bk mw mx"/></div><div class="ij ik il im in"><h1 id="2dd2" class="kd ke iq bd kf kg mz ki kj kk na km kn ko nb kq kr ks nc ku kv kw nd ky kz la bi translated">基线性能</h1><p id="8243" class="pw-post-body-paragraph lb lc iq ld b le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly ij bi translated">由于微调BERT模型是本例中计算量最大的部分，我们将只关注训练单元(单元#18)。</p><p id="417e" class="pw-post-body-paragraph lb lc iq ld b le lz lg lh li ma lk ll lm mb lo lp lq mc ls lt lu md lw lx ly ij bi translated">在我们上一篇文章的<a class="ae kc" href="https://medium.com/towards-artificial-intelligence/how-to-speed-up-your-grid-search-60x-fec2a8250517" rel="noopener">中，我们使用了一台具有8个CPU内核和32gb RAM的笔记本电脑来获得基准性能。这个实验可能会在同一台笔记本电脑上运行，但它会花费不切实际的时间，所以我们将使用Google Colab。Colab提供免费的GPU访问，是深度学习的常用工作空间。</a></p><p id="f49a" class="pw-post-body-paragraph lb lc iq ld b le lz lg lh li ma lk ll lm mb lo lp lq mc ls lt lu md lw lx ly ij bi translated">然而，要记住的一点是，您无法预测或选择资源GPU的类型和RAM的数量将因每个会话而异。</p><p id="1f6b" class="pw-post-body-paragraph lb lc iq ld b le lz lg lh li ma lk ll lm mb lo lp lq mc ls lt lu md lw lx ly ij bi translated">在运行这个实验时，我们碰巧得到了一个T4 GPU(还不错！)搭配16 GB的GPU RAM和12 GB的普通RAM。伯特训练室用了17分17秒。</p><blockquote class="ne nf ng"><p id="c509" class="lb lc nh ld b le lz lg lh li ma lk ll ni mb lo lp nj mc ls lt nk md lw lx ly ij bi translated">🕰之前:17分17秒</p></blockquote></div><div class="ab cl ms mt hu mu" role="separator"><span class="mv bw bk mw mx my"/><span class="mv bw bk mw mx my"/><span class="mv bw bk mw mx"/></div><div class="ij ik il im in"><h1 id="0f76" class="kd ke iq bd kf kg mz ki kj kk na km kn ko nb kq kr ks nc ku kv kw nd ky kz la bi translated">我们的增强功能</h1><ol class=""><li id="eae6" class="me mf iq ld b le lf li lj lm nl lq nm lu nn ly no mk ml mm bi translated"><strong class="ld ir">使用混合精度</strong></li></ol><p id="9312" class="pw-post-body-paragraph lb lc iq ld b le lz lg lh li ma lk ll lm mb lo lp lq mc ls lt lu md lw lx ly ij bi translated">混合精度是一种用于提高机器学习模型性能的技术。它包括在训练和推理中使用低精度数据类型(如16位浮点)和高精度数据类型(如32位浮点)。</p><p id="c03e" class="pw-post-body-paragraph lb lc iq ld b le lz lg lh li ma lk ll lm mb lo lp lq mc ls lt lu md lw lx ly ij bi translated">混合精度的好处包括减少训练时间、减少内存使用和提高精度。</p><blockquote class="ne nf ng"><p id="53e7" class="lb lc nh ld b le lz lg lh li ma lk ll ni mb lo lp nj mc ls lt nk md lw lx ly ij bi translated">注意:并非所有硬件都支持混合精度，旧的GPU型号通常不支持。</p></blockquote><p id="40f8" class="pw-post-body-paragraph lb lc iq ld b le lz lg lh li ma lk ll lm mb lo lp lq mc ls lt lu md lw lx ly ij bi translated">因为我们使用较新的T4(不常见，因为Colab通常分配较旧的GPU)，所以我们可以利用混合精度。</p><p id="8b70" class="pw-post-body-paragraph lb lc iq ld b le lz lg lh li ma lk ll lm mb lo lp lq mc ls lt lu md lw lx ly ij bi translated">为此，我们添加了以下代码行:</p><pre class="np nq nr ns gt nt nu nv nw aw nx bi"><span id="0b88" class="ny ke iq nu b gy nz oa l ob oc">from tensorflow.keras import mixed_precision</span><span id="400d" class="ny ke iq nu b gy od oa l ob oc">mixed_precision.set_global_policy(‘mixed_float16’)</span></pre><p id="0b8b" class="pw-post-body-paragraph lb lc iq ld b le lz lg lh li ma lk ll lm mb lo lp lq mc ls lt lu md lw lx ly ij bi translated">我们再次运行该笔记本，它在大约8分钟内完成。</p><p id="810d" class="pw-post-body-paragraph lb lc iq ld b le lz lg lh li ma lk ll lm mb lo lp lq mc ls lt lu md lw lx ly ij bi translated"><strong class="ld ir"> 2。利用更新的GPU </strong></p><p id="8e3a" class="pw-post-body-paragraph lb lc iq ld b le lz lg lh li ma lk ll lm mb lo lp lq mc ls lt lu md lw lx ly ij bi translated">我们做的第二个增强是利用更新、更好的GPU模型。我们使用了一个V100 GPU，32 GB的GPU RAM和112 GB的常规RAM，成本为3.12美元/小时。</p><p id="9d7c" class="pw-post-body-paragraph lb lc iq ld b le lz lg lh li ma lk ll lm mb lo lp lq mc ls lt lu md lw lx ly ij bi translated">这一次，BERT训练单元在3分5秒内完成——比最初的实验加速了5倍多，而且只花了18美分！</p><blockquote class="ne nf ng"><p id="dc39" class="lb lc nh ld b le lz lg lh li ma lk ll ni mb lo lp nj mc ls lt nk md lw lx ly ij bi translated">🏎之后:3分5秒</p></blockquote></div><div class="ab cl ms mt hu mu" role="separator"><span class="mv bw bk mw mx my"/><span class="mv bw bk mw mx my"/><span class="mv bw bk mw mx"/></div><div class="ij ik il im in"><h1 id="9897" class="kd ke iq bd kf kg mz ki kj kk na km kn ko nb kq kr ks nc ku kv kw nd ky kz la bi translated">关键要点</h1><p id="779e" class="pw-post-body-paragraph lb lc iq ld b le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly ij bi translated">那么，在前进的道路上，我们应该记住什么？</p><ul class=""><li id="b116" class="me mf iq ld b le lz li ma lm mg lq mh lu mi ly mj mk ml mm bi translated">混合精度有许多引人注目的优势，例如减少处理时间和内存使用，但只有在您拥有现代GPU硬件的情况下才能使用。当使用提供免费计算资源的云服务时，请记住这一点——您可能只能访问低端GPU。有取舍！</li><li id="9361" class="me mf iq ld b le mn li mo lm mp lq mq lu mr ly mj mk ml mm bi translated">短时间内使用强大的资源可能会很便宜。付费服务和免费服务之间的认知摩擦可能比你实际花费的要多。您也许能够以不到一美元的成本获得显著的性能提升。</li><li id="056b" class="me mf iq ld b le mn li mo lm mp lq mq lu mr ly mj mk ml mm bi translated">像这样的例子通常坚持小规模以促进可重复性，但是提高性能的技术通常是通用的。在更大规模的项目中尝试它们！</li></ul></div><div class="ab cl ms mt hu mu" role="separator"><span class="mv bw bk mw mx my"/><span class="mv bw bk mw mx my"/><span class="mv bw bk mw mx"/></div><div class="ij ik il im in"><h1 id="60a7" class="kd ke iq bd kf kg mz ki kj kk na km kn ko nb kq kr ks nc ku kv kw nd ky kz la bi translated">如果你觉得这篇文章有帮助，我们也写过类似的文章！</h1><p id="2b6e" class="pw-post-body-paragraph lb lc iq ld b le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly ij bi translated">您可能会喜欢:</p><ul class=""><li id="d242" class="me mf iq ld b le lz li ma lm mg lq mh lu mi ly mj mk ml mm bi translated"><a class="ae kc" href="https://medium.com/towards-artificial-intelligence/how-to-speed-up-your-grid-search-60x-fec2a8250517" rel="noopener">如何加快你的网格搜索60x </a></li><li id="4019" class="me mf iq ld b le mn li mo lm mp lq mq lu mr ly mj mk ml mm bi translated"><a class="ae kc" href="https://medium.com/@optumi/scale-ml-experiments-from-jupyterlab-to-the-cloud-141bd645d8e9" rel="noopener">从JupyterLab到云的规模ML实验</a></li></ul><p id="35e6" class="pw-post-body-paragraph lb lc iq ld b le lz lg lh li ma lk ll lm mb lo lp lq mc ls lt lu md lw lx ly ij bi translated">请在下面留下你的掌声，这样媒体上的其他人就能看到，这样我们就知道要制作更多🙃👏</p></div><div class="ab cl ms mt hu mu" role="separator"><span class="mv bw bk mw mx my"/><span class="mv bw bk mw mx my"/><span class="mv bw bk mw mx"/></div><div class="ij ik il im in"><h1 id="3913" class="kd ke iq bd kf kg mz ki kj kk na km kn ko nb kq kr ks nc ku kv kw nd ky kz la bi translated">关于作者</h1><p id="f764" class="pw-post-body-paragraph lb lc iq ld b le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly ij bi translated">我主要写实用的数据科学和机器学习工作流挑战，并介绍解决它们的方法。</p><p id="e171" class="pw-post-body-paragraph lb lc iq ld b le lz lg lh li ma lk ll lm mb lo lp lq mc ls lt lu md lw lx ly ij bi translated">你可以在<a class="ae kc" href="https://medium.com/@optumi" rel="noopener"> Medium </a>或者<a class="ae kc" href="https://www.linkedin.com/in/chrismarrie/" rel="noopener ugc nofollow" target="_blank"> LinkedIn </a>上关注我。</p></div></div>    
</body>
</html>