<html>
<head>
<title/>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1/>
<blockquote>原文：<a href="https://pub.towardsai.net/this-new-and-completely-free-ai-model-can-fix-most-of-your-old-pictures-in-a-split-second-7a1ea3c676a7?source=collection_archive---------0-----------------------#2022-03-12">https://pub.towardsai.net/this-new-and-completely-free-ai-model-can-fix-most-of-your-old-pictures-in-a-split-second-7a1ea3c676a7?source=collection_archive---------0-----------------------#2022-03-12</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><h2 id="ced0" class="ir is it bd iu iv iw dn ix iy iz dp ja jb jc jd je jf jg jh ji jj jk jl jm jn bi translated">这个全新的完全免费的AI模型可以在一瞬间修复你的大部分旧图片！</h2><blockquote class="jo jp jq"><p id="c480" class="jr js jt ju b jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp im bi translated">最初发表于<a class="ae kq" href="https://www.louisbouchard.ai/gfp-gan/" rel="noopener ugc nofollow" target="_blank"> louisbouchard.ai </a>，前两天在<a class="ae kq" href="https://www.louisbouchard.ai/gfp-gan/" rel="noopener ugc nofollow" target="_blank">我的博客</a>上读到的！</p></blockquote><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div class="gh gi kr"><img src="../Images/6010814e13a4ae77e54e663a50cb81dd.png" data-original-src="https://miro.medium.com/v2/resize:fit:1366/format:webp/1*ts7tk5tst1NFpEut-1PR1A.jpeg"/></div><figcaption class="kz la gj gh gi lb lc bd b be z dk translated"><a class="ae kq" href="https://github.com/TencentARC/GFPGAN" rel="noopener ugc nofollow" target="_blank"> GFP-GAN </a>照片复原示例结果。由<a class="ae kq" href="https://github.com/TencentARC/GFPGAN" rel="noopener ugc nofollow" target="_blank">模型</a>产生的图像。</figcaption></figure><h2 id="a74c" class="ir is it bd iu iv iw dn ix iy iz dp ja jb jc jd je jf jg jh ji jj jk jl jm jn bi translated">观看视频了解更多结果:</h2><figure class="ks kt ku kv gt kw"><div class="bz fp l di"><div class="ld le l"/></div></figure><p id="6ca6" class="pw-post-body-paragraph jr js it ju b jv jw jx jy jz ka kb kc jb ke kf kg jf ki kj kk jj km kn ko kp im bi translated">你是否也有你自己的旧照片或亲密的旧照片，这些旧照片不是很旧，或者是你或你的父母在我们制作高质量图像之前拍摄的？是的，我觉得那些记忆被永远地破坏了。伙计，我错了！</p><p id="f910" class="pw-post-body-paragraph jr js it ju b jv jw jx jy jz ka kb kc jb ke kf kg jf ki kj kk jj km kn ko kp im bi translated">这个全新的完全免费的AI模型可以在一瞬间修复你的大部分旧图片。即使输入质量很低或很高，它也能很好地工作，这通常是一个很大的挑战。</p><p id="ec5f" class="pw-post-body-paragraph jr js it ju b jv jw jx jy jz ka kb kc jb ke kf kg jf ki kj kk jj km kn ko kp im bi translated">本周的论文名为“利用生成性面部先验实现真实世界的盲人面部恢复”,该论文解决了照片恢复任务，并取得了出色的结果。更酷的是，你可以自己尝试，用你喜欢的方式。他们已经开源了他们的代码，创建了一个演示和在线应用程序供你现在就尝试。如果你在上面看到的结果还不够有说服力，就看看视频，在评论里告诉我你的想法，我知道它会让你大吃一惊！</p><figure class="ks kt ku kv gt kw gh gi paragraph-image"><a href="http://eepurl.com/huGLT5"><div class="gh gi lf"><img src="../Images/66522f6a1e3c6d6175a92d3a20a49670.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*yLwPttxVxmXNLZyg.png"/></div></a></figure><p id="6c8c" class="pw-post-body-paragraph jr js it ju b jv jw jx jy jz ka kb kc jb ke kf kg jf ki kj kk jj km kn ko kp im bi translated">我提到该模型在低质量图像上工作良好。与其他方法相比，看看结果和详细程度就知道了…</p><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="lh li di lj bf lk"><div class="gh gi lg"><img src="../Images/c75ef50e7b049ed11adc5f2bad48a707.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*bwuP5wgU7ccIOQTW_6wSVw.jpeg"/></div></div><figcaption class="kz la gj gh gi lb lc bd b be z dk translated">与其他方法的结果比较。左侧为输入，右侧为GFP-GAN。图片来自<a class="ae kq" href="https://arxiv.org/pdf/2101.04061.pdf" rel="noopener ugc nofollow" target="_blank">论文</a>。</figcaption></figure><p id="7d30" class="pw-post-body-paragraph jr js it ju b jv jw jx jy jz ka kb kc jb ke kf kg jf ki kj kk jj km kn ko kp im bi translated">这些结果简直令人难以置信。它们并不代表实际的图像。重要的是要理解这些结果只是模型的猜测——看起来非常接近的猜测。对人类的眼睛来说，它看起来就像是代表这个人的同一幅图像。在不了解这个人的任何其他信息的情况下，我们无法猜测一个模型创造了更多的像素。</p><p id="af80" class="pw-post-body-paragraph jr js it ju b jv jw jx jy jz ka kb kc jb ke kf kg jf ki kj kk jj km kn ko kp im bi translated">因此，该模型尽最大努力理解图片中的内容，填补空白，或者在图像分辨率较低的情况下添加像素。但是它是如何工作的呢？人工智能模型如何理解图片中的内容，更令人印象深刻的是，如何理解不在图片中的内容，例如在这个划痕的地方有什么？</p><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div class="gh gi ll"><img src="../Images/54da7f6a3552a2b435172ac07a59b178.png" data-original-src="https://miro.medium.com/v2/resize:fit:1328/format:webp/1*SPDVXL7FP_fGA_qY-cNzmQ.jpeg"/></div><figcaption class="kz la gj gh gi lb lc bd b be z dk translated"><a class="ae kq" href="https://github.com/TencentARC/GFPGAN" rel="noopener ugc nofollow" target="_blank"> GFP-GAN </a>照片复原示例结果。由<a class="ae kq" href="https://github.com/TencentARC/GFPGAN" rel="noopener ugc nofollow" target="_blank">模型</a>产生的图像。</figcaption></figure><p id="7657" class="pw-post-body-paragraph jr js it ju b jv jw jx jy jz ka kb kc jb ke kf kg jf ki kj kk jj km kn ko kp im bi translated">你会看到，甘斯还没死！事实上，研究人员没有创造任何新东西。他们只是通过尽可能地帮助网络来最大化GANs的性能。还有什么比使用另一种GAN更有助于GAN架构呢？</p><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="lh li di lj bf lk"><div class="gh gi lm"><img src="../Images/92267fe4d8f830b2285f8fcaa3d33d38.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*J2qNufcAJGJfY1kg0J4Qjg.png"/></div></div><figcaption class="kz la gj gh gi lb lc bd b be z dk translated">图像生成的潜在空间中的脉冲优化过程。图片来自<a class="ae kq" href="https://arxiv.org/abs/2003.03808" rel="noopener ugc nofollow" target="_blank">纸</a>。</figcaption></figure><p id="75a2" class="pw-post-body-paragraph jr js it ju b jv jw jx jy jz ka kb kc jb ke kf kg jf ki kj kk jj km kn ko kp im bi translated">他们的模型被称为GFP-GAN是有原因的。GFP代表生成面部优先，我已经在多个视频中介绍过什么是面部优先，如果它听起来像另一种语言的话。例如，我去年介绍的一个名为PULSE的图像上采样模型使用了NVIDIA的StyleGAN-2等预训练的GAN，并在训练期间优化了称为潜在代码的编码，以提高重建质量。同样，如果这没有敲响任何钟，请花几分钟看一下<a class="ae kq" href="https://youtu.be/cgakyOI9r8M" rel="noopener ugc nofollow" target="_blank">我制作的关于PULSE模型的视频</a>。</p><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div class="gh gi ln"><img src="../Images/2a9ea8a04dd0ce1bb1cccd7399a11f7f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1024/1*gNx3UDw79U9x106oSSDjOw.gif"/></div><figcaption class="kz la gj gh gi lb lc bd b be z dk translated">脉冲示例。图片来自<a class="ae kq" href="https://arxiv.org/abs/2003.03808" rel="noopener ugc nofollow" target="_blank">论文</a>。</figcaption></figure><h2 id="1c54" class="ir is it bd iu iv iw dn ix iy iz dp ja jb jc jd je jf jg jh ji jj jk jl jm jn bi translated">绿色荧光蛋白-氮化镓模型…</h2><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="lh li di lj bf lk"><div class="gh gi lo"><img src="../Images/69ec8d3dae33282db19f9b14723169c3.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*CHwR94Ik-R3QwqXzQ6jXvQ.png"/></div></div><figcaption class="kz la gj gh gi lb lc bd b be z dk translated">GFP-GAN架构。图片来自<a class="ae kq" href="https://arxiv.org/pdf/2101.04061.pdf" rel="noopener ugc nofollow" target="_blank">纸张</a>。</figcaption></figure><p id="0f25" class="pw-post-body-paragraph jr js it ju b jv jw jx jy jz ka kb kc jb ke kf kg jf ki kj kk jj km kn ko kp im bi translated">然而，正如他们在论文中所述，“这些方法[*指脉冲*]通常产生低保真度的图像，因为低维潜在代码不足以指导恢复”。</p><p id="b07e" class="pw-post-body-paragraph jr js it ju b jv jw jx jy jz ka kb kc jb ke kf kg jf ki kj kk jj km kn ko kp im bi translated">相比之下，GFP-GAN并不像PULSE那样，简单地采用预先训练好的StyleGAN，并对其进行重新训练，以确定编码信息的方向。<br/>相反，GFP-GAN使用预训练的StyleGAN-2模型，在图像的编码过程中，在多个尺度上确定它们自己的生成模型的方向，下至潜在代码，上至重建。您可以在上面的绿色区域中看到它，在这里，我们使用通道分割SFT方法，将来自当前模型的信息与预先训练的GAN进行合并。你可以在下面链接的文章中找到更多关于他们如何合并两个模型中的信息的信息。</p><p id="5416" class="pw-post-body-paragraph jr js it ju b jv jw jx jy jz ka kb kc jb ke kf kg jf ki kj kk jj km kn ko kp im bi translated">在这种情况下，预训练的StyleGAN-2(绿色部分)是我们的先验知识，因为它已经知道如何处理图像，但用于不同的任务。这意味着他们将通过使用来自强大的预训练StyleGAN-2模型的先验信息来帮助他们的图像恢复模型更好地匹配每一步的特征，已知style gan-2模型用于创建有意义的编码并生成准确的图片。这将有助于模型获得逼真的结果，同时保持高保真度。</p><p id="28d0" class="pw-post-body-paragraph jr js it ju b jv jw jx jy jz ka kb kc jb ke kf kg jf ki kj kk jj km kn ko kp im bi translated">因此，使用我们来自GAN网络的鉴别器模型，而不是简单地基于生成的(伪)图像和预期的(真实)图像之间的差异来定向训练。我们还将有两个保存身份和面部组件的指标。这两个增加的指标，称为损失，将有助于增强面部细节，正如它所说，确保我们保持人的身份，或者至少我们尽最大努力这样做。见上图右侧。</p><p id="a203" class="pw-post-body-paragraph jr js it ju b jv jw jx jy jz ka kb kc jb ke kf kg jf ki kj kk jj km kn ko kp im bi translated">面部分量损失基本上与我们在经典GANs中发现的鉴别器对抗性损失相同，但是集中于结果图像的重要局部特征，如眼睛和嘴。</p><p id="2862" class="pw-post-body-paragraph jr js it ju b jv jw jx jy jz ka kb kc jb ke kf kg jf ki kj kk jj km kn ko kp im bi translated">身份保留损失使用预先训练的人脸识别模型来捕捉最重要的面部特征，并将它们与真实图像进行比较，以查看我们在生成的图像中是否仍然有同一个人。</p><p id="42c4" class="pw-post-body-paragraph jr js it ju b jv jw jx jy jz ka kb kc jb ke kf kg jf ki kj kk jj km kn ko kp im bi translated">瞧！我们使用来自不同损失的所有这些信息获得了这些奇妙的图像重建结果…(观看视频了解更多结果！)</p><figure class="ks kt ku kv gt kw gh gi paragraph-image"><a href="https://www.louisbouchard.ai/learnai/"><div class="gh gi lp"><img src="../Images/190d6f1cbebfc68e40870f64b83f1e84.png" data-original-src="https://miro.medium.com/v2/resize:fit:924/format:webp/0*2pOLGeHJTqVxlWDK.png"/></div></a></figure><p id="e901" class="pw-post-body-paragraph jr js it ju b jv jw jx jy jz ka kb kc jb ke kf kg jf ki kj kk jj km kn ko kp im bi translated">在<a class="ae kq" href="https://youtu.be/nLDVtzcSeqM" rel="noopener ugc nofollow" target="_blank">视频</a>中显示的结果都是使用他们模型的最新版本1.3产生的。你可以看到他们公开分享他们方法的弱点，这很酷。</p><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="lh li di lj bf lk"><div class="gh gi lq"><img src="../Images/dc24c6dde36f879b9f6cc0deefbfa69e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Aznk_NWixqgeDlGytpAvJg.png"/></div></div><figcaption class="kz la gj gh gi lb lc bd b be z dk translated">图片来自他们的<a class="ae kq" href="https://github.com/TencentARC/GFPGAN" rel="noopener ugc nofollow" target="_blank"> GitHub库</a>。</figcaption></figure><p id="2107" class="pw-post-body-paragraph jr js it ju b jv jw jx jy jz ka kb kc jb ke kf kg jf ki kj kk jj km kn ko kp im bi translated">而在这里我只想回到我之前提到的一些东西，这是第二个弱点:“在身份上有轻微的变化”。的确，这是会发生的，我们对此无能为力。我们可以限制这种偏移，但我们不能确定重建的图像将与原始图像完全相同。这根本不可能。从低清晰度图像中重建同一个人意味着我们确切地知道这个人当时的样子，但我们不知道。我们根据我们对人类的了解以及他们通常的样子来猜测模糊的图片，并创建数百个新像素。</p><div class="ks kt ku kv gt ab cb"><figure class="lr kw ls lt lu lv lw paragraph-image"><img src="../Images/034bce46c3b9f43ba4b98775775e7e14.png" data-original-src="https://miro.medium.com/v2/resize:fit:560/format:webp/1*TTmngF03Huc5UdQDq0YFig.png"/></figure><figure class="lr kw lx lt lu lv lw paragraph-image"><img src="../Images/2e5925cf160e1caf2de9417c3f173999.png" data-original-src="https://miro.medium.com/v2/resize:fit:1024/format:webp/1*ph-XooUd_Kjz-ER6dThfQw.png"/><figcaption class="kz la gj gh gi lb lc bd b be z dk ly di lz ma translated">使用GFP-GAN的爱因斯坦测试图像。图片来自<a class="ae kq" href="https://arxiv.org/pdf/2101.04061.pdf" rel="noopener ugc nofollow" target="_blank">纸张</a>。</figcaption></figure></div><p id="ae7b" class="pw-post-body-paragraph jr js it ju b jv jw jx jy jz ka kb kc jb ke kf kg jf ki kj kk jj km kn ko kp im bi translated">如果我们足够幸运的话，最终的图像看起来会像我们的祖父。但是它也可能看起来像一个完全陌生的人，当你使用这些类型的模型时，你需要考虑到这一点。尽管如此，结果还是很棒，非常接近现实。我强烈地邀请你玩它，并且创造你自己的模型和结果的想法。他们的代码、演示和应用程序的链接在下面的参考资料中。</p><p id="d58b" class="pw-post-body-paragraph jr js it ju b jv jw jx jy jz ka kb kc jb ke kf kg jf ki kj kk jj km kn ko kp im bi translated">让我知道你的想法，我希望你喜欢这篇文章！</p><p id="25a7" class="pw-post-body-paragraph jr js it ju b jv jw jx jy jz ka kb kc jb ke kf kg jf ki kj kk jj km kn ko kp im bi translated">在你离开之前，如果你对AI伦理学感兴趣；在接下来的几天里，我将发送下一期<a class="ae kq" href="http://eepurl.com/huGLT5" rel="noopener ugc nofollow" target="_blank">我们的简讯</a>,介绍Martina对这种技术的伦理考量的看法。敬请关注！</p></div><div class="ab cl mb mc hx md" role="separator"><span class="me bw bk mf mg mh"/><span class="me bw bk mf mg mh"/><span class="me bw bk mf mg"/></div><div class="im in io ip iq"><p id="4629" class="pw-post-body-paragraph jr js it ju b jv jw jx jy jz ka kb kc jb ke kf kg jf ki kj kk jj km kn ko kp im bi translated">如果你喜欢我的工作，并想与人工智能保持同步，你绝对应该关注我的其他社交媒体账户(<a class="ae kq" href="https://www.linkedin.com/in/whats-ai/" rel="noopener ugc nofollow" target="_blank"> LinkedIn </a>，<a class="ae kq" href="https://twitter.com/Whats_AI" rel="noopener ugc nofollow" target="_blank"> Twitter </a>)，并订阅我的每周人工智能<a class="ae kq" href="http://eepurl.com/huGLT5" rel="noopener ugc nofollow" target="_blank"> <strong class="ju mi">简讯</strong> </a>！</p><h2 id="e3bb" class="ir is it bd iu iv iw dn ix iy iz dp ja jb jc jd je jf jg jh ji jj jk jl jm jn bi translated">支持我:</h2><ul class=""><li id="93b3" class="mj mk it ju b jv ml jz mm jb mn jf mo jj mp kp mq mr ms mt bi translated">跟我来这里上<a class="ae kq" href="https://whats-ai.medium.com/" rel="noopener"> <strong class="ju mi">中</strong> </a> <strong class="ju mi">。</strong></li><li id="8a2f" class="mj mk it ju b jv mu jz mv jb mw jf mx jj my kp mq mr ms mt bi translated">想进入AI或者提升技能，<a class="ae kq" href="https://www.louisbouchard.ai/learnai/" rel="noopener ugc nofollow" target="_blank">看这个</a>！</li></ul><h2 id="5d0c" class="ir is it bd iu iv iw dn ix iy iz dp ja jb jc jd je jf jg jh ji jj jk jl jm jn bi translated">参考</h2><ul class=""><li id="fe11" class="mj mk it ju b jv ml jz mm jb mn jf mo jj mp kp mq mr ms mt bi translated">视频:<a class="ae kq" href="https://youtu.be/nLDVtzcSeqM" rel="noopener ugc nofollow" target="_blank">https://youtu.be/nLDVtzcSeqM</a></li><li id="eec5" class="mj mk it ju b jv mu jz mv jb mw jf mx jj my kp mq mr ms mt bi translated">脉搏视频:<a class="ae kq" href="https://youtu.be/cgakyOI9r8M" rel="noopener ugc nofollow" target="_blank">https://youtu.be/cgakyOI9r8M</a></li><li id="8219" class="mj mk it ju b jv mu jz mv jb mw jf mx jj my kp mq mr ms mt bi translated">王，李，杨，张，海，山，2021。基于生成人脸先验的真实世界盲人脸恢复。《IEEE/CVF计算机视觉和模式识别会议论文集》(第9168-9178页)，<a class="ae kq" href="https://arxiv.org/pdf/2101.04061.pdf" rel="noopener ugc nofollow" target="_blank">https://arxiv.org/pdf/2101.04061.pdf</a></li><li id="108d" class="mj mk it ju b jv mu jz mv jb mw jf mx jj my kp mq mr ms mt bi translated">代号:<a class="ae kq" href="https://github.com/TencentARC/GFPGAN" rel="noopener ugc nofollow" target="_blank">https://github.com/TencentARC/GFPGAN</a></li><li id="63af" class="mj mk it ju b jv mu jz mv jb mw jf mx jj my kp mq mr ms mt bi translated">使用:<a class="ae kq" href="https://app.baseten.co/applications/Q04Lz0d/operator_views/8qZG6Bg" rel="noopener ugc nofollow" target="_blank">https://app . baseten . co/applications/q 04 lz0d/operator _ views/8 qzg 6 BG</a></li></ul></div></div>    
</body>
</html>