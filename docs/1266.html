<html>
<head>
<title>Efficient Biomedical Segmentation When Only a Few Label Images Are Available @MICCAI2020</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">只有少量标签图像可用时的高效生物医学分割@MICCAI2020</h1>
<blockquote>原文：<a href="https://pub.towardsai.net/efficient-biomedical-segmentation-when-only-a-few-label-images-are-available-2e0b2513703d?source=collection_archive---------1-----------------------#2020-12-16">https://pub.towardsai.net/efficient-biomedical-segmentation-when-only-a-few-label-images-are-available-2e0b2513703d?source=collection_archive---------1-----------------------#2020-12-16</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><h2 id="be97" class="io ip iq bd b dl ir is it iu iv iw dk ix translated" aria-label="kicker paragraph">计算机视觉</h2><div class=""/><div class=""><h2 id="b462" class="pw-subtitle-paragraph jw iz iq bd b jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn dk translated">一种使用对比学习的最新无监督分割方案</h2></div><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div class="gh gi ko"><img src="../Images/06d216426ca21c50c63073096dea1c0c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1152/format:webp/1*u6fp0lRkCT9il_kykAK0ig.png"/></div><figcaption class="kw kx gj gh gi ky kz bd b be z dk translated">MICCAI 2020</figcaption></figure><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div role="button" tabindex="0" class="lb lc di ld bf le"><div class="gh gi la"><img src="../Images/e685794752e3c595b33f80147a5fb37c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*dlpb8oxxJkaf2jIa"/></div></div><figcaption class="kw kx gj gh gi ky kz bd b be z dk translated"><a class="ae lf" href="https://unsplash.com/@nci?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">国家癌症研究所</a>在<a class="ae lf" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上拍摄的照片</figcaption></figure><p id="13e6" class="pw-post-body-paragraph lg lh iq li b lj lk ka ll lm ln kd lo lp lq lr ls lt lu lv lw lx ly lz ma mb ij bi translated">在这个故事中，标签有效的多任务分割使用对比学习，由东京大学和首选网络，提出。这是作为MICCAI BrainLes 2020研讨会的技术论文发表的。针对只有少量标记数据的精确医学图像任务，提出了一种多任务分割模型，并使用对比学习来训练分割模型。我们首次通过实验展示了对比预测编码[Oord等人，2018年和H enaff等人，2019年]作为使用标记和未标记图像进行图像分割的正则化任务的有效性，结果为标记高效分割提供了新的方向。结果表明，当标注数据量有限时，它优于其他多任务方法，包括最先进的完全监督模型。实验表明，当标注的数据量有限时，使用未标记的数据可以提供最先进的性能。</p><p id="088b" class="pw-post-body-paragraph lg lh iq li b lj lk ka ll lm ln kd lo lp lq lr ls lt lu lv lw lx ly lz ma mb ij bi translated">让我们看看他们是如何做到的。我只解释ssCPCseg的精髓，所以如果你有兴趣阅读我的博客，请点击<a class="ae lf" href="https://arxiv.org/pdf/2009.11160.pdf" rel="noopener ugc nofollow" target="_blank"> <strong class="li ja"> ssCPCseg论文</strong> </a> <strong class="li ja">和</strong> <a class="ae lf" href="https://github.com/pfnet-research/label-efficient-brain-tumor-segmentation" rel="noopener ugc nofollow" target="_blank"> <strong class="li ja"> Github。</strong>T13】</a></p><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div role="button" tabindex="0" class="lb lc di ld bf le"><div class="gh gi mc"><img src="../Images/d9376af11c8513e349992056994546ee.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*MjwIlJzxC4LJDH4iEW9Ygg.png"/></div></div></figure></div><div class="ab cl md me hu mf" role="separator"><span class="mg bw bk mh mi mj"/><span class="mg bw bk mh mi mj"/><span class="mg bw bk mh mi"/></div><div class="ij ik il im in"><h1 id="9827" class="mk ml iq bd mm mn mo mp mq mr ms mt mu kf mv kg mw ki mx kj my kl mz km na nb bi translated">这篇论文说了什么？</h1><p id="78a7" class="pw-post-body-paragraph lg lh iq li b lj nc ka ll lm nd kd lo lp ne lr ls lt nf lv lw lx ng lz ma mb ij bi translated">获取诸如临床数据的3D医学图像的注释通常是昂贵的。另一方面，通常存在大量未标记的图像。因此，半监督学习方法在医学图像分割任务中有着广泛的应用。</p><p id="742e" class="pw-post-body-paragraph lg lh iq li b lj lk ka ll lm ln kd lo lp lq lr ls lt lu lv lw lx ly lz ma mb ij bi translated">自监督学习是一种表示学习方法，它从剩余输入数据中的未标记输入数据中预测缺失的输入数据。对比预测编码(CPC)已被提出作为一种自监督学习的方法，它可以应用于数据域中的小标签图像网络分类任务，它已被提出优于完全学习方法[H enaff等人，2019]，但CPC在分割任务中的有效性尚未得到研究。</p><p id="0b04" class="pw-post-body-paragraph lg lh iq li b lj lk ka ll lm ln kd lo lp lq lr ls lt lu lv lw lx ly lz ma mb ij bi translated">由于可以通过共享主分割任务和正则化子任务的参数来降低过拟合的风险，因此多任务学习被认为是用于小数据的有效方法。</p><p id="48e8" class="pw-post-body-paragraph lg lh iq li b lj lk ka ll lm ln kd lo lp lq lr ls lt lu lv lw lx ly lz ma mb ij bi translated">当标记数据量较小时，半监督CPCseg (ssCPCseg)优于所有其他正则化方法，包括VAEseg，一种完全监督的最新模型(表1)。因此，基于对比学习(CPC)的方法被整合到多任务分割模型任务中。</p><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div role="button" tabindex="0" class="lb lc di ld bf le"><div class="gh gi nh"><img src="../Images/f523365a119829de6b08d3aa933c7d2b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*9oTmgocoGs5E5A6inuP_nw.png"/></div></div></figure></div><div class="ab cl md me hu mf" role="separator"><span class="mg bw bk mh mi mj"/><span class="mg bw bk mh mi mj"/><span class="mg bw bk mh mi"/></div><div class="ij ik il im in"><h1 id="9419" class="mk ml iq bd mm mn mo mp mq mr ms mt mu kf mv kg mw ki mx kj my kl mz km na nb bi translated">方法学</h1><p id="69c3" class="pw-post-body-paragraph lg lh iq li b lj nc ka ll lm nd kd lo lp ne lr ls lt nf lv lw lx ng lz ma mb ij bi translated">如图1所示，本文中的医学图像分割网络是一个编码器/解码器结构，其中对比预测编码(CPC)分支在编码器块的末端与解码器块分支。编码器和解码器由类ResNet块(ResBlocks)组成，在编码器和解码器之间有跳跃连接。除了党支部之外，不同类型的正规化党支部，VAE支部和边界关注支部，都在本文中得到了实施，但我的博客只关注党支部。</p><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div role="button" tabindex="0" class="lb lc di ld bf le"><div class="gh gi ni"><img src="../Images/e1b898e44d7a990a2fb570b09d76dd0b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*NrF44573HYnUOoClrysr5w.png"/></div></div></figure><h2 id="7d49" class="nj ml iq bd mm nk nl dn mq nm nn dp mu lp no np mw lt nq nr my lx ns nt na iw bi translated">对比预测编码分支</h2><p id="bc83" class="pw-post-body-paragraph lg lh iq li b lj nc ka ll lm nd kd lo lp ne lr ls lt nf lv lw lx ng lz ma mb ij bi translated">首先，输入图像被分成16个32×32×32体素的重叠片。使用编码器-解码器架构中的编码器对每个分割的小块分别进行编码，进行空间平均，并聚合成单个特征向量<em class="nu"> z_i，j，k </em>。</p><p id="c574" class="pw-post-body-paragraph lg lh iq li b lj lk ka ll lm ln kd lo lp lq lr ls lt lu lv lw lx ly lz ma mb ij bi translated">然后将第八层ResBlock <em class="nu"> f_res8 </em>和线性层<em class="nu"> W </em>应用于这个特征向量的上半部分，预测特征向量的下半部分<em class="nu"> z_i，j，k_low </em>。此外，负样本<em class="nu"> z_l </em>随机取自同一图像的不同块中编码的其他特征向量。</p><p id="01ec" class="pw-post-body-paragraph lg lh iq li b lj lk ka ll lm ln kd lo lp lq lr ls lt lu lv lw lx ly lz ma mb ij bi translated"><em class="nu"> z^ </em>由以下等式表示。</p><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div class="gh gi nv"><img src="../Images/81e67d269dd3bf574ad20f44da3cd6e0.png" data-original-src="https://miro.medium.com/v2/resize:fit:696/format:webp/1*eZydqrW5_VDr6tcXaBQ5lA.png"/></div></figure><p id="b16c" class="pw-post-body-paragraph lg lh iq li b lj lk ka ll lm ln kd lo lp lq lr ls lt lu lv lw lx ly lz ma mb ij bi translated">从上面可以看出，CPC损失可以表示如下。</p><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div role="button" tabindex="0" class="lb lc di ld bf le"><div class="gh gi nw"><img src="../Images/b5c54767ebac229987235b6722d2b8b6.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*71OaoUy9_HIvQtgad9036A.png"/></div></div></figure></div><div class="ab cl md me hu mf" role="separator"><span class="mg bw bk mh mi mj"/><span class="mg bw bk mh mi mj"/><span class="mg bw bk mh mi"/></div><div class="ij ik il im in"><h1 id="51f1" class="mk ml iq bd mm mn mo mp mq mr ms mt mu kf mv kg mw ki mx kj my kl mz km na nb bi translated">结果</h1><p id="3908" class="pw-post-body-paragraph lg lh iq li b lj nc ka ll lm nd kd lo lp ne lr ls lt nf lv lw lx ng lz ma mb ij bi translated">在实验中，测量了四种模型的分割性能，以便比较不同的正则化效果:单独的编码器-解码器(EncDec)、具有VAE分支的enc dec(VAEseg)、具有边界注意分支的enc dec(Boundseg)和具有CPC分支的enc dec(CPC seg)。</p><p id="cec3" class="pw-post-body-paragraph lg lh iq li b lj lk ka ll lm ln kd lo lp lq lr ls lt lu lv lw lx ly lz ma mb ij bi translated">表4s中的结果表明，当标记数据量较小时，具有标记数据的正则化分支对分割性能的影响有限。半监督CPCseg (ssCPCseg)的分割结果显示，半监督方法优于完全监督方法(图4)，半监督CPCseg从标记和未标记数据中学习表示。此外，ssCPCseg在具有小标记数据的区域中优于所有其他正则化方法，包括完全监督的最新模型VAEseg。</p><p id="277d" class="pw-post-body-paragraph lg lh iq li b lj lk ka ll lm ln kd lo lp lq lr ls lt lu lv lw lx ly lz ma mb ij bi translated">这些结果表明，当标注数据量有限时，使用CPC分支的半监督方法可以提供最先进的性能。</p><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div role="button" tabindex="0" class="lb lc di ld bf le"><div class="gh gi nx"><img src="../Images/556f596a8a2e7ecf7098e9f95e79735c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*s_IveEOcM0pMPZwmEUFmaA.png"/></div></div></figure><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div role="button" tabindex="0" class="lb lc di ld bf le"><div class="gh gi ny"><img src="../Images/163b5a03235b581453566bc0cca60975.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*LNQtYx9kMx8VWdaPApjijQ.png"/></div></div></figure></div><div class="ab cl md me hu mf" role="separator"><span class="mg bw bk mh mi mj"/><span class="mg bw bk mh mi mj"/><span class="mg bw bk mh mi"/></div><div class="ij ik il im in"><h2 id="2bde" class="nj ml iq bd mm nk nl dn mq nm nn dp mu lp no np mw lt nq nr my lx ns nt na iw bi translated">参考</h2><p id="8359" class="pw-post-body-paragraph lg lh iq li b lj nc ka ll lm nd kd lo lp ne lr ls lt nf lv lw lx ng lz ma mb ij bi translated">【Oord et al .，2018】范·登·奥尔德，a .，李，y .，Vinyals，`:使用对比预测编码的表征学习，“arXiv e-prints arXiv:1807.03748(2018)</p><p id="c6c2" class="pw-post-body-paragraph lg lh iq li b lj lk ka ll lm ln kd lo lp lq lr ls lt lu lv lw lx ly lz ma mb ij bi translated">【H enaff et al .，2019】H enaff，O.J .，Srinivas，a .，德法乌，j .，Razavi，a .，Doersch，c .，Eslami，S.M.A .，van den Oord，`:使用对比预测编码的数据高效图像识别，“arXiv e-prints arXiv:1905.09272(2019)</p><p id="98df" class="pw-post-body-paragraph lg lh iq li b lj lk ka ll lm ln kd lo lp lq lr ls lt lu lv lw lx ly lz ma mb ij bi translated">[<a class="ae lf" href="https://arxiv.org/pdf/2009.11160.pdf" rel="noopener ugc nofollow" target="_blank">ssCPCseg</a>][<a class="ae lf" href="https://github.com/pfnet-research/label-efficient-brain-tumor-segmentation" rel="noopener ugc nofollow" target="_blank">Github</a>]j . Iwas awa，Y. Hirano和Y. Sugawara，“使用对比学习的标签高效多任务分割”，MICCAI BrainLes 2020研讨会</p></div><div class="ab cl md me hu mf" role="separator"><span class="mg bw bk mh mi mj"/><span class="mg bw bk mh mi mj"/><span class="mg bw bk mh mi"/></div><div class="ij ik il im in"><h1 id="9c2a" class="mk ml iq bd mm mn mo mp mq mr ms mt mu kf mv kg mw ki mx kj my kl mz km na nb bi translated">过去论文摘要列表</h1><h2 id="1d68" class="nj ml iq bd mm nk nl dn mq nm nn dp mu lp no np mw lt nq nr my lx ns nt na iw bi translated">深度学习方法</h2><p id="2ee6" class="pw-post-body-paragraph lg lh iq li b lj nc ka ll lm nd kd lo lp ne lr ls lt nf lv lw lx ng lz ma mb ij bi translated"><strong class="li ja">2020:[</strong><a class="ae lf" href="https://medium.com/towards-artificial-intelligence/lets-compress-the-cnn-training-like-a-jpeg-compression-ca8237c56f3c" rel="noopener"><strong class="li ja">DCTNet</strong></a><strong class="li ja">】</strong></p><h2 id="0939" class="nj ml iq bd mm nk nl dn mq nm nn dp mu lp no np mw lt nq nr my lx ns nt na iw bi translated">不确定性学习</h2><p id="5033" class="pw-post-body-paragraph lg lh iq li b lj nc ka ll lm nd kd lo lp ne lr ls lt nf lv lw lx ng lz ma mb ij bi translated"><strong class="li ja">2020:</strong><strong class="li ja"/><a class="ae lf" href="https://mako95.medium.com/cvpr2020-paper-summary-data-uncertainty-in-face-recognition-1f17547473a2" rel="noopener"><strong class="li ja">DUL</strong></a><strong class="li ja"/></p><h2 id="9a73" class="nj ml iq bd mm nk nl dn mq nm nn dp mu lp no np mw lt nq nr my lx ns nt na iw bi translated">异常检测</h2><p id="975d" class="pw-post-body-paragraph lg lh iq li b lj nc ka ll lm nd kd lo lp ne lr ls lt nf lv lw lx ng lz ma mb ij bi translated"><strong class="li ja"> 2020年:【</strong><a class="ae lf" href="https://medium.com/towards-artificial-intelligence/for-safety-reasons-self-driving-cars-must-not-miss-detecting-the-signs-bb26e65e721" rel="noopener"><strong class="li ja">FND</strong></a><strong class="li ja"/></p><h2 id="ff06" class="nj ml iq bd mm nk nl dn mq nm nn dp mu lp no np mw lt nq nr my lx ns nt na iw bi translated">一级分类</h2><p id="b343" class="pw-post-body-paragraph lg lh iq li b lj nc ka ll lm nd kd lo lp ne lr ls lt nf lv lw lx ng lz ma mb ij bi translated"><strong class="li ja">2019:【</strong><a class="ae lf" href="https://medium.com/swlh/paper-summary-deep-one-class-classification-doc-adc4368af75c" rel="noopener"><strong class="li ja">DOC</strong></a><strong class="li ja"/></p><p id="c4c4" class="pw-post-body-paragraph lg lh iq li b lj lk ka ll lm ln kd lo lp lq lr ls lt lu lv lw lx ly lz ma mb ij bi translated"><strong class="li ja">2020:【</strong><a class="ae lf" href="https://medium.com/the-shadow/exploring-important-feature-repressions-in-deep-one-class-classification-droc-d04a59558f9e" rel="noopener"><strong class="li ja">DROC</strong></a><strong class="li ja"/></p><h2 id="61dd" class="nj ml iq bd mm nk nl dn mq nm nn dp mu lp no np mw lt nq nr my lx ns nt na iw bi translated">图象分割法</h2><p id="c731" class="pw-post-body-paragraph lg lh iq li b lj nc ka ll lm nd kd lo lp ne lr ls lt nf lv lw lx ng lz ma mb ij bi translated"><strong class="li ja">2018:</strong><a class="ae lf" href="https://medium.com/swlh/paper-summary-biomedical-image-segmentation-and-object-detection-uolo-c1175ba5c8c4" rel="noopener"><strong class="li ja">【UOLO】</strong></a></p><p id="7424" class="pw-post-body-paragraph lg lh iq li b lj lk ka ll lm ln kd lo lp lq lr ls lt lu lv lw lx ly lz ma mb ij bi translated"><strong class="li ja">2020:【</strong><a class="ae lf" href="https://medium.com/towards-artificial-intelligence/efficient-biomedical-segmentation-when-only-a-few-label-images-are-available-2e0b2513703d" rel="noopener"><strong class="li ja">ssCPCseg</strong></a><strong class="li ja"/></p><h2 id="3929" class="nj ml iq bd mm nk nl dn mq nm nn dp mu lp no np mw lt nq nr my lx ns nt na iw bi translated">图像聚类</h2><p id="c3b3" class="pw-post-body-paragraph lg lh iq li b lj nc ka ll lm nd kd lo lp ne lr ls lt nf lv lw lx ng lz ma mb ij bi translated"><strong class="li ja">2020:</strong><a class="ae lf" href="https://medium.com/swlh/paper-deep-transfer-clustering-dtc-learning-to-discover-novel-visual-categories-ec5a26aea075" rel="noopener"><strong class="li ja">【DTC】</strong></a></p></div></div>    
</body>
</html>