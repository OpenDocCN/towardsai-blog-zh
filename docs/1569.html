<html>
<head>
<title>TensorFlow: Speed Up NumPy by over 10,000x with GPUs</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">TensorFlow:使用GPU将NumPy速度提高10，000倍以上</h1>
<blockquote>原文：<a href="https://pub.towardsai.net/tensorflow-accelerate-numpy-with-gpus-964e9087fdab?source=collection_archive---------0-----------------------#2021-02-23">https://pub.towardsai.net/tensorflow-accelerate-numpy-with-gpus-964e9087fdab?source=collection_archive---------0-----------------------#2021-02-23</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><figure class="is it gp gr iu iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi ir"><img src="../Images/78c2ef0d85cf761ed07f98053010e378.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*B9qgR3zS10ffBUco"/></div></div><figcaption class="jc jd gj gh gi je jf bd b be z dk translated">Marc-Olivier Jodoin 在<a class="ae jg" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上拍摄的照片</figcaption></figure><h2 id="aa57" class="jh ji jj bd b dl jk jl jm jn jo jp dk jq translated" aria-label="kicker paragraph"><a class="ae ep" href="https://towardsai.net/p/category/data-science" rel="noopener ugc nofollow" target="_blank">数据科学</a>，<a class="ae ep" href="https://towardsai.net/p/category/machine-learning" rel="noopener ugc nofollow" target="_blank">机器学习</a></h2><div class=""/><div class=""><h2 id="93d9" class="pw-subtitle-paragraph kp js jj bd b kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg dk translated">使用TensorFlow的实验API加速矩阵运算</h2></div><p id="d443" class="pw-post-body-paragraph lh li jj lj b lk ll kt lm ln lo kw lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">如果您曾经使用Python进行过任何数据处理，那么您很可能使用过NumPy(NumPy的缩写)。它提供了丰富的复杂数据类型和有效的矩阵操作函数。其矢量函数的C加速实现为其赢得了以闪电般的速度处理n维数组的声誉。但是我们能走得更快吗？</p><blockquote class="md"><p id="69f6" class="me mf jj bd mg mh mi mj mk ml mm mc dk translated">NumPy的可向量化函数的C加速实现使我们能够高效地处理大型多维数组</p></blockquote><p id="c75f" class="pw-post-body-paragraph lh li jj lj b lk mn kt lm ln mo kw lp lq mp ls lt lu mq lw lx ly mr ma mb mc im bi translated">接下来，TensorFlow将采用NumPy API。</p><p id="05c9" class="pw-post-body-paragraph lh li jj lj b lk ll kt lm ln lo kw lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">由于TensorFlow的GPU加速，我们现在可以比现在更快地运行NumPy <strong class="lj jt">甚至比闪电还快。更好的是，Tensorflow的NumPy还可以与TensorFlow的API和原始的NumPy API进行内部操作。这意味着我们可以将TensorFlow的<code class="fe ms mt mu mv b">ndarray</code>传递给<code class="fe ms mt mu mv b">tf.linalg</code>、<code class="fe ms mt mu mv b">tf.data</code>、<code class="fe ms mt mu mv b">tf.keras</code>、<code class="fe ms mt mu mv b">tf.signal</code>等下的其他Tensorflow函数。我们甚至可以用<code class="fe ms mt mu mv b">tf.distribute</code>进一步分配我们的工作量。</strong></p><blockquote class="md"><p id="13fe" class="me mf jj bd mg mh mi mj mk ml mm mc dk translated">TensorFlow的NumPy API试图通过GPU加速NumPy，同时还能访问其他TensorFlow API</p></blockquote><blockquote class="mw mx my"><p id="d7e7" class="lh li mz lj b lk mn kt lm ln mo kw lp na mp ls lt nb mq lw lx nc mr ma mb mc im bi translated">注意:这仍然是Tensorflow的一个实验性API，所以预计在不久的将来会有(显著的)变化。</p></blockquote><p id="0897" class="pw-post-body-paragraph lh li jj lj b lk ll kt lm ln lo kw lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">在这篇博客中，我们将看看到底有多快，以及在什么情况下我们应该使用Numpy或TensorFlow。我们将研究Numpy的4个非常常见的用例，我们作为数据科学家、软件工程师或机器学习实践者将在日常生活中使用这些用例:</p><ol class=""><li id="3214" class="nd ne jj lj b lk ll ln lo lq nf lu ng ly nh mc ni nj nk nl bi translated">整理</li><li id="e9d3" class="nd ne jj lj b lk nm ln nn lq no lu np ly nq mc ni nj nk nl bi translated">线性代数</li><li id="4050" class="nd ne jj lj b lk nm ln nn lq no lu np ly nq mc ni nj nk nl bi translated">数学函数</li><li id="6205" class="nd ne jj lj b lk nm ln nn lq no lu np ly nq mc ni nj nk nl bi translated">快速傅里叶变换</li></ol></div><div class="ab cl nr ns hx nt" role="separator"><span class="nu bw bk nv nw nx"/><span class="nu bw bk nv nw nx"/><span class="nu bw bk nv nw"/></div><div class="im in io ip iq"><h2 id="90a5" class="ny nz jj bd oa ob oc dn od oe of dp og lq oh oi oj lu ok ol om ly on oo op jp bi translated">密码</h2><p id="20c7" class="pw-post-body-paragraph lh li jj lj b lk oq kt lm ln or kw lp lq os ls lt lu ot lw lx ly ou ma mb mc im bi translated">为了确保数字在一定程度上可以被复制，这篇博客中的片段和数字可以在这个<a class="ae jg" href="https://colab.research.google.com/drive/15cDJUnUUebn7lbVEnYNx1LUhHH1kEbUa?usp=sharing" rel="noopener ugc nofollow" target="_blank"> Colab笔记本</a>中找到。</p></div><div class="ab cl nr ns hx nt" role="separator"><span class="nu bw bk nv nw nx"/><span class="nu bw bk nv nw nx"/><span class="nu bw bk nv nw"/></div><div class="im in io ip iq"><h2 id="9735" class="ny nz jj bd oa ob oc dn od oe of dp og lq oh oi oj lu ok ol om ly on oo op jp bi translated">张量流要求</h2><p id="e0c4" class="pw-post-body-paragraph lh li jj lj b lk oq kt lm ln or kw lp lq os ls lt lu ot lw lx ly ou ma mb mc im bi translated">NumPy API在TensorFlow 2.4中的<code class="fe ms mt mu mv b"><a class="ae jg" href="https://www.tensorflow.org/api_docs/python/tf/experimental/numpy" rel="noopener ugc nofollow" target="_blank">tensorflow.experimental.numpy</a></code>下提供。要安装它，我们可以运行以下命令:</p><pre class="ov ow ox oy gt oz mv pa pb aw pc bi"><span id="99bf" class="ny nz jj mv b gy pd pe l pf pg">pip install tensorflow&gt;=2.4</span></pre><p id="06f3" class="pw-post-body-paragraph lh li jj lj b lk ll kt lm ln lo kw lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">为了获得最佳性能，您还需要一个支持CUDA 11的Nvidia GPU。我们还需要安装Nvida驱动程序至少在450。关于gpu安装的详细说明，可以看一下<a class="ae jg" href="https://www.tensorflow.org/install/gpu" rel="noopener ugc nofollow" target="_blank">这里</a>。</p><p id="c06f" class="pw-post-body-paragraph lh li jj lj b lk ll kt lm ln lo kw lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">如果您有兼容的GPU，可以使用以下代码片段确保TensorFlow与GPU同步:</p><pre class="ov ow ox oy gt oz mv pa pb aw pc bi"><span id="5515" class="ny nz jj mv b gy pd pe l pf pg">with tf.device("/device:GPU:0"):</span><span id="5847" class="ny nz jj mv b gy ph pe l pf pg">    # put your workflow in this function<br/>    def f():<br/>        one = tnp.asarray(1)<br/>        tnp.sort(tnp_matrix)<br/>        with tf.device("CPU:0"):<br/>            tnp.copy(one)</span><span id="0e07" class="ny nz jj mv b gy ph pe l pf pg">    f()</span></pre></div><div class="ab cl nr ns hx nt" role="separator"><span class="nu bw bk nv nw nx"/><span class="nu bw bk nv nw nx"/><span class="nu bw bk nv nw"/></div><div class="im in io ip iq"><h2 id="994b" class="ny nz jj bd oa ob oc dn od oe of dp og lq oh oi oj lu ok ol om ly on oo op jp bi translated">数组排序</h2><p id="5ed9" class="pw-post-body-paragraph lh li jj lj b lk oq kt lm ln or kw lp lq os ls lt lu ot lw lx ly ou ma mb mc im bi translated">让我们从简单的事情开始:对数组进行排序。NumPy的<code class="fe ms mt mu mv b">sort</code>(在两个NumPy &amp; TensorFlow中)实际上支持不同的排序算法，具体取决于参数<code class="fe ms mt mu mv b">kind</code>。默认情况下，如果你的NumPy版本比1.12新，它将使用<code class="fe ms mt mu mv b">introsort</code> ( <a class="ae jg" href="https://en.wikipedia.org/wiki/Introsort" rel="noopener ugc nofollow" target="_blank">快速链接到维基</a>)或<code class="fe ms mt mu mv b">heapsort</code> ( <a class="ae jg" href="https://en.wikipedia.org/wiki/Heapsort" rel="noopener ugc nofollow" target="_blank">快速链接到维基</a>)，最坏情况下复杂度为<code class="fe ms mt mu mv b">O(n log(n))</code>。</p><p id="84f1" class="pw-post-body-paragraph lh li jj lj b lk ll kt lm ln lo kw lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated"><strong class="lj jt">接口:</strong></p><pre class="ov ow ox oy gt oz mv pa pb aw pc bi"><span id="7a6a" class="ny nz jj mv b gy pd pe l pf pg">import numpy as np<br/>import tensorflow.experimental.numpy as tnp</span><span id="7fe5" class="ny nz jj mv b gy ph pe l pf pg"># NumPy API</span><span id="0a3a" class="ny nz jj mv b gy ph pe l pf pg">np.sort(<br/>    <!-- -->a: <strong class="mv jt"><em class="mz">np.ndarray or tnp.ndarray</em></strong>, <br/>    axis: <strong class="mv jt"><em class="mz">int</em></strong> = -1, <br/>    kind: <strong class="mv jt"><em class="mz">str</em></strong> = 'quicksort', <br/>    <!-- -->direction: <strong class="mv jt"><em class="mz">str or list of str, optional</em></strong> <!-- -->= None<br/>)</span><span id="e047" class="ny nz jj mv b gy ph pe l pf pg"># TensorFlow's NumPy API</span><span id="0ff1" class="ny nz jj mv b gy ph pe l pf pg">tnp.sort(<br/>    <!-- -->a: <strong class="mv jt"><em class="mz">np.ndarray or tnp.ndarray</em></strong>, <br/>    axis: <strong class="mv jt"><em class="mz">int</em></strong> = -1, <br/>    kind: <strong class="mv jt"><em class="mz">str</em></strong> = 'quicksort', <br/>    <!-- -->direction: <strong class="mv jt"><em class="mz">str or list of str, optional</em></strong> <!-- -->= None<br/>)</span></pre><p id="0032" class="pw-post-body-paragraph lh li jj lj b lk ll kt lm ln lo kw lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated"><strong class="lj jt">实验设置:</strong></p><p id="75e8" class="pw-post-body-paragraph lh li jj lj b lk ll kt lm ln lo kw lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">我们将对一个预先生成的类型为<code class="fe ms mt mu mv b">ndarray</code>的向量进行排序，该向量在[0。, 1.).Introsort将用作排序算法。100次运行的平均时间将作为最终读数。</p><p id="d4d0" class="pw-post-body-paragraph lh li jj lj b lk ll kt lm ln lo kw lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated"><strong class="lj jt">性能:</strong></p><figure class="ov ow ox oy gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi pi"><img src="../Images/7f24cd00fd7f20d443fa779a12622add.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*4DUfReHlTutdbCTcdcjRkg.png"/></div></div><figcaption class="jc jd gj gh gi je jf bd b be z dk translated">排序的运行时比较-按作者排序的图像</figcaption></figure><figure class="ov ow ox oy gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi pi"><img src="../Images/48692694a39011e526b2a9f5453f967b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*GeC71G9VOcsbNNtf0HXVyQ.png"/></div></div><figcaption class="jc jd gj gh gi je jf bd b be z dk translated">排序速度比较—按作者排序的图像</figcaption></figure><figure class="ov ow ox oy gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi pj"><img src="../Images/0c9176275549fe750226741838888eb2.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*sWyjCdjlTydcdXsingaUZw.png"/></div></div><figcaption class="jc jd gj gh gi je jf bd b be z dk translated">用于排序的时间表-按作者排序的图像</figcaption></figure><figure class="ov ow ox oy gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi pk"><img src="../Images/eda1f52e685d44a6c0c61fc8ab6deaf8.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*DIy43Wu6Ewnrfu0Dq41fSA.png"/></div></div><figcaption class="jc jd gj gh gi je jf bd b be z dk translated">排序的相对速度—按作者排序的图像</figcaption></figure><p id="eb88" class="pw-post-body-paragraph lh li jj lj b lk ll kt lm ln lo kw lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">由于TensorFlow在调度操作时比NumPy有更多的开销，TensorFlow的NumPy API与NumPy相比将有明显更差的性能。根据经验，<a class="ae jg" href="https://www.tensorflow.org/guide/tf_numpy#performance_comparisons" rel="noopener ugc nofollow" target="_blank"> TensorFlow </a>建议使用NumPy的API，如果操作预计在10毫秒内完成。</p><p id="3ffe" class="pw-post-body-paragraph lh li jj lj b lk ll kt lm ln lo kw lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">事实上，TensorFlow的建议与我们在上面图表中的观察一致。TensorFlow与GPU会话的相对速度高于NumPy，因为数组长度会增加10，000到100，000个项目，具体取决于您是将<code class="fe ms mt mu mv b">np.ndarray</code>还是<code class="fe ms mt mu mv b">tnp.ndarray</code>传递给TensorFlow的NumPy API。</p><p id="e254" class="pw-post-body-paragraph lh li jj lj b lk ll kt lm ln lo kw lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">另一点不足为奇的是，从长远来看，带CPU会话的TensorFlow提供了最坏的时间复杂度。如果TensorFlow不能使用GPU来加速，它基本上是在NumPy自己可以利用的尽可能多的资源上运行。这还没有考虑到TensorFlow的开销会进一步降低整体吞吐量，并不出所料地使其排名垫底。</p></div><div class="ab cl nr ns hx nt" role="separator"><span class="nu bw bk nv nw nx"/><span class="nu bw bk nv nw nx"/><span class="nu bw bk nv nw"/></div><div class="im in io ip iq"><h2 id="6aac" class="ny nz jj bd oa ob oc dn od oe of dp og lq oh oi oj lu ok ol om ly on oo op jp bi translated">线性代数</h2><p id="7fcf" class="pw-post-body-paragraph lh li jj lj b lk oq kt lm ln or kw lp lq os ls lt lu ot lw lx ly ou ma mb mc im bi translated">我们每天都在使用的另一个非常常见的任务是多维矩阵的线性代数。在博客的这一部分，我们将探讨矩阵乘法的不同表现</p><p id="7690" class="pw-post-body-paragraph lh li jj lj b lk ll kt lm ln lo kw lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated"><strong class="lj jt">界面:</strong></p><pre class="ov ow ox oy gt oz mv pa pb aw pc bi"><span id="3d6d" class="ny nz jj mv b gy pd pe l pf pg">import numpy as np<br/>import tensorflow.experimental.numpy as tnp</span><span id="7266" class="ny nz jj mv b gy ph pe l pf pg"># NumPy API</span><span id="e6b2" class="ny nz jj mv b gy ph pe l pf pg">np.matmul(<br/>    <!-- -->x1: <strong class="mv jt"><em class="mz">np.ndarray or tnp.ndarray</em></strong>, <br/>    <!-- -->x2: <strong class="mv jt"><em class="mz">np.ndarray or tnp.ndarray</em></strong>,<br/>)</span><span id="191b" class="ny nz jj mv b gy ph pe l pf pg"># TensorFlow's NumPy API</span><span id="35a7" class="ny nz jj mv b gy ph pe l pf pg">tnp.matmul(<br/>    <!-- -->x1: <strong class="mv jt"><em class="mz">np.ndarray or tnp.ndarray</em></strong>, <br/>    <!-- -->x2: <strong class="mv jt"><em class="mz">np.ndarray or tnp.ndarray</em></strong>,<br/>)</span></pre><p id="65be" class="pw-post-body-paragraph lh li jj lj b lk ll kt lm ln lo kw lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">实际上还有额外的<code class="fe ms mt mu mv b">kwargs</code>可以传递给<code class="fe ms mt mu mv b">matmul</code>，但是它们通常不会被使用，除非你是超级用户并且想要覆盖<code class="fe ms mt mu mv b">ufunc</code>行为(例如，为非数字类型定义矩阵乘法)。</p><p id="e7ce" class="pw-post-body-paragraph lh li jj lj b lk ll kt lm ln lo kw lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated"><strong class="lj jt">实验设置:</strong></p><p id="a411" class="pw-post-body-paragraph lh li jj lj b lk ll kt lm ln lo kw lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">我们将把一个预先生成的类型为<code class="fe ms mt mu mv b">ndarray</code>的方阵与[0。, 1.)本身。100次运行的平均时间将作为最终读数。</p><p id="6931" class="pw-post-body-paragraph lh li jj lj b lk ll kt lm ln lo kw lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated"><strong class="lj jt">性能:</strong></p><figure class="ov ow ox oy gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi pi"><img src="../Images/e9f7a79801afd4c578271cbb1c5407a8.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*_zrAb-RUMiEFNS5tF7LUwQ.png"/></div></div><figcaption class="jc jd gj gh gi je jf bd b be z dk translated">矩阵乘法的运行时比较—作者图片</figcaption></figure><figure class="ov ow ox oy gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi pi"><img src="../Images/f2c025d888b2f01c502b269ade66188d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*tUvtdsx0NRdkoc6QoU1ucQ.png"/></div></div><figcaption class="jc jd gj gh gi je jf bd b be z dk translated">矩阵乘法的速度比较—图片由作者提供</figcaption></figure><figure class="ov ow ox oy gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi pk"><img src="../Images/7a3c29370992a7edb0f504a7f47efb0b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*aAnT4LKSW3K30fMJiBpPlA.png"/></div></div><figcaption class="jc jd gj gh gi je jf bd b be z dk translated">矩阵乘法的时间表-作者图片</figcaption></figure><figure class="ov ow ox oy gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi pl"><img src="../Images/428b4692792d8014ae42cdab8263ed79.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*frOEyI0KEn_PR4ZpuZ1wiQ.png"/></div></div><figcaption class="jc jd gj gh gi je jf bd b be z dk translated">矩阵乘法的相对速度—图片由作者提供</figcaption></figure><p id="49ed" class="pw-post-body-paragraph lh li jj lj b lk ll kt lm ln lo kw lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">在这个实验中，操作比我们之前的设置更简单，我们开始看到当方阵的维数为(5000，5000)时，TensorFlow如何以高达50，000倍于Numpy的速度遥遥领先于NumPy。TensorFlow开始领先的临界阈值在10，000到25，000个元素之间。</p><p id="1aaa" class="pw-post-body-paragraph lh li jj lj b lk ll kt lm ln lo kw lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">从第一个图表中，我们还可以注意到在使用TensorFlow的NumPy API时，使用互操作的<code class="fe ms mt mu mv b">np.ndarray</code>所带来的性能损失。由于Tensorflow需要在分派操作之前将其转换为TensorFlow兼容的类型，因此传递一个<code class="fe ms mt mu mv b">np.ndarray</code>而不是<code class="fe ms mt mu mv b">tnp.ndarray</code>会导致更大的开销并降低性能。</p><p id="8ad9" class="pw-post-body-paragraph lh li jj lj b lk ll kt lm ln lo kw lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">从前面的实验中也可以发现类似的观察结果，TensorFlow的NumPy API和CPU会话的性能最差。</p></div><div class="ab cl nr ns hx nt" role="separator"><span class="nu bw bk nv nw nx"/><span class="nu bw bk nv nw nx"/><span class="nu bw bk nv nw"/></div><div class="im in io ip iq"><h2 id="077c" class="ny nz jj bd oa ob oc dn od oe of dp og lq oh oi oj lu ok ol om ly on oo op jp bi translated">数学函数</h2><p id="b927" class="pw-post-body-paragraph lh li jj lj b lk oq kt lm ln or kw lp lq os ls lt lu ot lw lx ly ou ma mb mc im bi translated">在这个实验中，我们将研究应用神经网络中最常见的数学函数之一——双曲正切函数。对于那些不熟悉<code class="fe ms mt mu mv b">tanh</code>的人来说，你可以把它想成一个<code class="fe ms mt mu mv b">sigmoid</code>函数，但是取而代之的是一个(-1，1)的范围而不是<code class="fe ms mt mu mv b">sigmoid</code>的(0，1)，并且与<code class="fe ms mt mu mv b">sigmoid</code>相比，在零附近有一个更强的梯度。</p><figure class="ov ow ox oy gt iv gh gi paragraph-image"><div class="gh gi pm"><img src="../Images/5ea4b47ad9289dc1a5205f88f2d70e95.png" data-original-src="https://miro.medium.com/v2/resize:fit:1280/format:webp/0*83dGs1TM2M88OALl.png"/></div><figcaption class="jc jd gj gh gi je jf bd b be z dk translated">双曲正切——来源:<a class="ae jg" href="https://upload.wikimedia.org/wikipedia/commons/thumb/8/87/Hyperbolic_Tangent.svg/640px-Hyperbolic_Tangent.svg.png" rel="noopener ugc nofollow" target="_blank">维基百科</a></figcaption></figure><figure class="ov ow ox oy gt iv gh gi paragraph-image"><div class="gh gi pm"><img src="../Images/d1c9ab29d08fea3273f29a683e839caf.png" data-original-src="https://miro.medium.com/v2/resize:fit:1280/format:webp/0*Z4ZT6GnoiAW0MeEN.png"/></div><figcaption class="jc jd gj gh gi je jf bd b be z dk translated">乙状结肠——来源:<a class="ae jg" href="https://upload.wikimedia.org/wikipedia/commons/thumb/5/53/Sigmoid-function-2.svg/640px-Sigmoid-function-2.svg.png" rel="noopener ugc nofollow" target="_blank">维基百科</a></figcaption></figure><p id="750f" class="pw-post-body-paragraph lh li jj lj b lk ll kt lm ln lo kw lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated"><strong class="lj jt">接口:</strong></p><pre class="ov ow ox oy gt oz mv pa pb aw pc bi"><span id="27b5" class="ny nz jj mv b gy pd pe l pf pg">import numpy as np<br/>import tensorflow.experimental.numpy as tnp</span><span id="fe02" class="ny nz jj mv b gy ph pe l pf pg"># NumPy API</span><span id="7eae" class="ny nz jj mv b gy ph pe l pf pg">np.tanh(<br/>    <!-- -->x: <strong class="mv jt"><em class="mz">np.ndarray or tnp.ndarray</em></strong>,<br/>)</span><span id="46f3" class="ny nz jj mv b gy ph pe l pf pg"># TensorFlow's NumPy API</span><span id="f3c2" class="ny nz jj mv b gy ph pe l pf pg">tnp.tanh(<br/>    <!-- -->x: <strong class="mv jt"><em class="mz">np.ndarray or tnp.ndarray</em></strong>,<br/>)</span></pre><p id="79d1" class="pw-post-body-paragraph lh li jj lj b lk ll kt lm ln lo kw lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">同样，实际上还有额外的<code class="fe ms mt mu mv b">kwargs</code>可以传递给<code class="fe ms mt mu mv b">tanh</code>，用于覆盖<code class="fe ms mt mu mv b">ufunc</code>行为(例如，为非数字类型定义双曲正切)。</p><p id="af91" class="pw-post-body-paragraph lh li jj lj b lk ll kt lm ln lo kw lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated"><strong class="lj jt">实验设置:</strong></p><p id="7655" class="pw-post-body-paragraph lh li jj lj b lk ll kt lm ln lo kw lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">我们将计算一个类型为<code class="fe ms mt mu mv b">ndarray</code>的预生成向量的双曲正切值，该向量在[0。, 1.).100次运行的平均时间将作为最终读数。</p><p id="a5b0" class="pw-post-body-paragraph lh li jj lj b lk ll kt lm ln lo kw lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated"><strong class="lj jt">性能:</strong></p><figure class="ov ow ox oy gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi pi"><img src="../Images/03243178294db7ede6e256855965523b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*knBrTjzWhgLXoRvZkWlcaA.png"/></div></div><figcaption class="jc jd gj gh gi je jf bd b be z dk translated">双曲正切的运行时比较—图片由作者提供</figcaption></figure><figure class="ov ow ox oy gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi pi"><img src="../Images/44b9f58d24ddae399032db51840834a4.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*wN-Q10wwQsKKKL0-g21tmQ.png"/></div></div><figcaption class="jc jd gj gh gi je jf bd b be z dk translated">双曲正切速度比较—图片由作者提供</figcaption></figure><figure class="ov ow ox oy gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi pk"><img src="../Images/e4e6002ec6443166900e9aeab77bd7ca.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*jWDhB69BiW4VyHsR5cTfiw.png"/></div></div><figcaption class="jc jd gj gh gi je jf bd b be z dk translated">双曲正切时间表-作者图片</figcaption></figure><figure class="ov ow ox oy gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi pn"><img src="../Images/2cd7e5d9f16d518a393277844d16afc6.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*eNhd02qFSOYT5kbgjxppUg.png"/></div></div><figcaption class="jc jd gj gh gi je jf bd b be z dk translated">双曲正切的相对速度—图片由作者提供</figcaption></figure><p id="5125" class="pw-post-body-paragraph lh li jj lj b lk ll kt lm ln lo kw lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">在这个实验中，当我们使用GPU会话计算超过15，000个元素的向量的双曲正切时，TensorFlow开始领先。我们仍然可以观察到相同的模式，将<code class="fe ms mt mu mv b">np.ndarray</code>传递给TensorFlow的NumPy API比传递<code class="fe ms mt mu mv b">tnp.ndarray</code>提供了更差的性能。然而，与之前的实验不同，我们观察到，一旦数组超过100，000个元素，即使带CPU会话的TensorFlow也开始持续比NumPy运行得更快。</p></div><div class="ab cl nr ns hx nt" role="separator"><span class="nu bw bk nv nw nx"/><span class="nu bw bk nv nw nx"/><span class="nu bw bk nv nw"/></div><div class="im in io ip iq"><h2 id="478b" class="ny nz jj bd oa ob oc dn od oe of dp og lq oh oi oj lu ok ol om ly on oo op jp bi translated">快速傅里叶变换</h2><p id="3041" class="pw-post-body-paragraph lh li jj lj b lk oq kt lm ln or kw lp lq os ls lt lu ot lw lx ly ou ma mb mc im bi translated">让我们看看比上面更不常见的东西，作为博客的最后一个实验——快速傅立叶变换。对于不太熟悉快速傅立叶变换的人来说，你可以把它看作是把一个信号或一个时间序列分解成一组正弦波。一些过于简单的例子可以是，一段音乐由三个正弦波组成，一个为高音，一个为中音，另一个为低音，或者一个金融时间序列可以被分解为正弦波，分别代表年度趋势、月度趋势、周趋势和日趋势。这些正弦波中的每一个都有一个振幅，告诉你与其他正弦波相比，这个低音或每日趋势有多强。</p><figure class="ov ow ox oy gt iv gh gi paragraph-image"><div class="gh gi po"><img src="../Images/1f125ad77ba51acb8c5367672e5d9dac.png" data-original-src="https://miro.medium.com/v2/resize:fit:1080/format:webp/0*UTGNj_cuPWNtd6R6.png"/></div><figcaption class="jc jd gj gh gi je jf bd b be z dk translated">快速傅立叶变换的可视化图解—来源:<a class="ae jg" href="https://upload.wikimedia.org/wikipedia/commons/6/61/FFT-Time-Frequency-View.png" rel="noopener ugc nofollow" target="_blank">维基百科</a></figcaption></figure><p id="d7d0" class="pw-post-body-paragraph lh li jj lj b lk ll kt lm ln lo kw lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated"><strong class="lj jt">界面:</strong></p><pre class="ov ow ox oy gt oz mv pa pb aw pc bi"><span id="b4fb" class="ny nz jj mv b gy pd pe l pf pg">import numpy as np<br/>import tensorflow as tf<br/>import tensorflow.experimental.numpy as tnp</span><span id="b6bf" class="ny nz jj mv b gy ph pe l pf pg"># NumPy API</span><span id="766c" class="ny nz jj mv b gy ph pe l pf pg">np.tanh(<br/>    <!-- -->a: <strong class="mv jt"><em class="mz">np.ndarray or tnp.ndarray</em></strong><br/>)</span><span id="9cb5" class="ny nz jj mv b gy ph pe l pf pg"># TensorFlow's <strong class="mv jt">Signal</strong> API</span><span id="ef3c" class="ny nz jj mv b gy ph pe l pf pg">tf.signal.fft(<br/>    <!-- -->input: <strong class="mv jt"><em class="mz">np.ndarray or tnp.ndarray</em></strong><br/>)</span></pre><p id="0e44" class="pw-post-body-paragraph lh li jj lj b lk ll kt lm ln lo kw lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">对于<code class="fe ms mt mu mv b">np.fft</code>，您可以指定一些其他可选参数来微调快速傅立叶变换的范围。但是由于在<code class="fe ms mt mu mv b">tf.signal.fft</code>中不存在相同的内容，为了保持客观，我们将省略它们。</p><p id="b4a6" class="pw-post-body-paragraph lh li jj lj b lk ll kt lm ln lo kw lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated"><strong class="lj jt">实验设置:</strong></p><p id="0df9" class="pw-post-body-paragraph lh li jj lj b lk ll kt lm ln lo kw lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">我们将对预先生成的类型为<code class="fe ms mt mu mv b">ndarray</code>的向量进行快速傅立叶变换，该向量在[0。, 1.).100次运行的平均时间将作为最终读数。</p><p id="a044" class="pw-post-body-paragraph lh li jj lj b lk ll kt lm ln lo kw lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated"><strong class="lj jt">性能:</strong></p><figure class="ov ow ox oy gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi pi"><img src="../Images/9e73d2b5691fbaa6f847d88074b3f8e6.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*6S_rM4y2QhmPekNR6QoduQ.png"/></div></div><figcaption class="jc jd gj gh gi je jf bd b be z dk translated">快速傅立叶变换的运行时比较—图片由作者提供</figcaption></figure><figure class="ov ow ox oy gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi pi"><img src="../Images/910bd436cd55f55118aad645f7ae0e14.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*HX89qXnFSMmXCRVVtWOkgQ.png"/></div></div><figcaption class="jc jd gj gh gi je jf bd b be z dk translated">快速傅立叶变换的速度比较—图片由作者提供</figcaption></figure><figure class="ov ow ox oy gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi pp"><img src="../Images/13053d253a85642504270cd5d7c0ce7b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*IThHqDfPZjXPPVHhdJf7Vg.png"/></div></div><figcaption class="jc jd gj gh gi je jf bd b be z dk translated">快速傅立叶变换的时间表-作者图片</figcaption></figure><figure class="ov ow ox oy gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi pl"><img src="../Images/2993d62ec9e94a7dd2bd13f23e77c43d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*R7Nq7tOkZti62JZxsdnCiA.png"/></div></div><figcaption class="jc jd gj gh gi je jf bd b be z dk translated">快速傅立叶变换的相对速度—图片由作者提供</figcaption></figure><p id="f04f" class="pw-post-body-paragraph lh li jj lj b lk ll kt lm ln lo kw lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">这个决赛并没有偏离我们之前的理解和观察。当数组长度超过50，000时，带GPU的TensorFlow领先，通过<code class="fe ms mt mu mv b">tnf.ndarray</code>是更好的选择。同时，带CPU的Tensorflow运行速度还是比NumPy慢。</p></div><div class="ab cl nr ns hx nt" role="separator"><span class="nu bw bk nv nw nx"/><span class="nu bw bk nv nw nx"/><span class="nu bw bk nv nw"/></div><div class="im in io ip iq"><h2 id="73e4" class="ny nz jj bd oa ob oc dn od oe of dp og lq oh oi oj lu ok ol om ly on oo op jp bi translated">判决和结案陈词</h2><p id="e888" class="pw-post-body-paragraph lh li jj lj b lk oq kt lm ln or kw lp lq os ls lt lu ot lw lx ly ou ma mb mc im bi translated">经过四轮测试，我们可以有把握地说，TensorFlow的NumPy API在GPU会话中运行和处理相对较大的矩阵时，性能明显优于NumPy。为了获得最佳性能，请记住将<code class="fe ms mt mu mv b">tnf.ndarray</code>传递给任何TensorFlow APIs。</p><blockquote class="md"><p id="816a" class="me mf jj bd mg mh mi mj mk ml mm mc dk translated">如果您正在处理超过10，000个元素的数组，请在兼容的GPU上使用TensorFlow的NumPy API。</p></blockquote><p id="fc74" class="pw-post-body-paragraph lh li jj lj b lk mn kt lm ln mo kw lp lq mp ls lt lu mq lw lx ly mr ma mb mc im bi translated">但是，如果您没有兼容的GPU，请坚持使用NumPy。尽管TensorFlow在某些函数中的性能会更好，但性能的提升是有限的。另一个可能的解决方案是在Google Colab上工作，这将允许您在GPU上运行代码，从而充分利用TensorFlow的NumPy API。</p><blockquote class="md"><p id="8857" class="me mf jj bd mg mh mi mj mk ml mm mc dk translated">如果你没有GPU，使用NumPy或者在Google Colab上运行你的代码，在那里你可以免费启动GPU会话。</p></blockquote><p id="60ad" class="pw-post-body-paragraph lh li jj lj b lk mn kt lm ln mo kw lp lq mp ls lt lu mq lw lx ly mr ma mb mc im bi translated">到目前为止，我们在TensorFlow的NumPy API上的测试就是这样。由于它在TensorFlow 2.4中仍然是一个实验性的API，因此并不是NumPy的所有API都包含在这个版本中(例如<code class="fe ms mt mu mv b">np.fft</code> vs <code class="fe ms mt mu mv b">tf.signal.fft</code>)。未来可能会有变化，所以请保持关注！</p><p id="9585" class="pw-post-body-paragraph lh li jj lj b lk ll kt lm ln lo kw lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">我希望你觉得这个博客有用而且有趣。让我知道你对这个API的看法，以及我是否遗漏了任何重要的地方。如果你想了解更多关于Python、数据科学或机器学习的知识，你可能想看看这些帖子:</p><ul class=""><li id="4b94" class="nd ne jj lj b lk ll ln lo lq nf lu ng ly nh mc pq nj nk nl bi translated"><a class="ae jg" rel="noopener ugc nofollow" target="_blank" href="/3-common-problems-with-neural-network-initialisation-5e6cacfcd8e6">神经网络初始化的3个常见问题</a></li><li id="f7a5" class="nd ne jj lj b lk nm ln nn lq no lu np ly nq mc pq nj nk nl bi translated"><a class="ae jg" href="https://towardsdatascience.com/google-deepminds-rfa-approximating-softmax-attention-mechanism-in-transformers-d685345bbc18" rel="noopener" target="_blank">谷歌的RFA:近似于《变形金刚》中的Softmax注意力机制</a></li><li id="ee0a" class="nd ne jj lj b lk nm ln nn lq no lu np ly nq mc pq nj nk nl bi translated">熊猫数据帧上的高效条件逻辑</li><li id="a437" class="nd ne jj lj b lk nm ln nn lq no lu np ly nq mc pq nj nk nl bi translated"><a class="ae jg" href="https://towardsdatascience.com/7-easy-ways-for-improving-your-data-science-workflow-b2da81ea3b2" rel="noopener" target="_blank">改进数据科学工作流程的7种简单方法</a></li><li id="3a31" class="nd ne jj lj b lk nm ln nn lq no lu np ly nq mc pq nj nk nl bi translated"><a class="ae jg" href="https://towardsdatascience.com/memory-efficiency-of-common-python-data-structures-88f0f720421" rel="noopener" target="_blank">常见Python数据结构的内存效率</a></li><li id="e00e" class="nd ne jj lj b lk nm ln nn lq no lu np ly nq mc pq nj nk nl bi translated"><a class="ae jg" href="https://towardsdatascience.com/parallelism-with-python-part-1-196f0458ca14" rel="noopener" target="_blank">与Python并行</a></li><li id="ed32" class="nd ne jj lj b lk nm ln nn lq no lu np ly nq mc pq nj nk nl bi translated"><a class="ae jg" href="https://towardsdatascience.com/cookiecutter-plugin-for-jupyter-easily-organise-your-data-science-environment-a56f83140f72" rel="noopener" target="_blank">数据科学的基本Jupyter扩展设置</a></li><li id="7f84" class="nd ne jj lj b lk nm ln nn lq no lu np ly nq mc pq nj nk nl bi translated"><a class="ae jg" href="https://towardsdatascience.com/mastering-root-searching-algorithms-in-python-7120c335a2a8" rel="noopener" target="_blank">Python中高效的根搜索算法</a></li></ul><p id="92d9" class="pw-post-body-paragraph lh li jj lj b lk ll kt lm ln lo kw lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">如果你想了解更多关于如何将机器学习应用于交易和投资的信息，这里有一些你可能感兴趣的帖子:</p><ul class=""><li id="bb98" class="nd ne jj lj b lk ll ln lo lq nf lu ng ly nh mc pq nj nk nl bi translated"><a class="ae jg" rel="noopener ugc nofollow" target="_blank" href="/genetic-algorithm-for-trading-strategy-optimization-in-python-614eb660990d">Python中交易策略优化的遗传算法</a></li><li id="6dee" class="nd ne jj lj b lk nm ln nn lq no lu np ly nq mc pq nj nk nl bi translated"><a class="ae jg" href="https://medium.com/towards-artificial-intelligence/genetic-algorithm-stop-overfitting-trading-strategies-5df671d5cde1" rel="noopener">遗传算法——停止过度拟合交易策略</a></li><li id="e18e" class="nd ne jj lj b lk nm ln nn lq no lu np ly nq mc pq nj nk nl bi translated"><a class="ae jg" rel="noopener ugc nofollow" target="_blank" href="/ann-recommendation-system-for-stock-selection-c9751a3a0520">人工神经网络选股推荐系统</a></li></ul><figure class="ov ow ox oy gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi pr"><img src="../Images/59fad6764665d4d77efcc13cbf1e2709.png" data-original-src="https://miro.medium.com/v2/resize:fit:690/1*ZQOTw24seljdPG0hvnUnUQ.gif"/></div></div></figure></div><div class="ab cl nr ns hx nt" role="separator"><span class="nu bw bk nv nw nx"/><span class="nu bw bk nv nw nx"/><span class="nu bw bk nv nw"/></div><div class="im in io ip iq"><div class="ov ow ox oy gt ps"><a href="https://www.linkedin.com/in/louis-chan-b55b9287" rel="noopener  ugc nofollow" target="_blank"><div class="pt ab fo"><div class="pu ab pv cl cj pw"><h2 class="bd jt gy z fp px fr fs py fu fw js bi translated">Louis Chan—FTI Consulting | LinkedIn数据科学总监</h2><div class="pz l"><h3 class="bd b gy z fp px fr fs py fu fw dk translated">雄心勃勃的，好奇的和有创造力的个人，对分支知识和知识之间的相互联系有强烈的信念</h3></div><div class="qa l"><p class="bd b dl z fp px fr fs py fu fw dk translated">www.linkedin.com</p></div></div><div class="qb l"><div class="qc l qd qe qf qb qg ja ps"/></div></div></a></div><figure class="ov ow ox oy gt iv gh gi paragraph-image"><a href="https://www.buymeacoffee.com/louischan"><div class="gh gi qh"><img src="../Images/da3aff0c3084d4947b2ec1e61ca695a4.png" data-original-src="https://miro.medium.com/v2/resize:fit:340/format:webp/0*Cpr-p1u_iYtIzstu.png"/></div></a></figure></div></div>    
</body>
</html>