<html>
<head>
<title>Building Complex Image Augmentation Pipelines with Tensorflow</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">用Tensorflow构建复杂的图像增强管道</h1>
<blockquote>原文：<a href="https://pub.towardsai.net/building-complex-image-augmentation-pipelines-with-tensorflow-bed1914278d2?source=collection_archive---------2-----------------------#2020-11-03">https://pub.towardsai.net/building-complex-image-augmentation-pipelines-with-tensorflow-bed1914278d2?source=collection_archive---------2-----------------------#2020-11-03</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><h2 id="46b8" class="io ip iq bd b dl ir is it iu iv iw dk ix translated" aria-label="kicker paragraph"><a class="ae ep" href="https://towardsai.net/p/category/machine-learning" rel="noopener ugc nofollow" target="_blank">机器学习</a>，<a class="ae ep" href="https://towardsai.net/p/category/programming" rel="noopener ugc nofollow" target="_blank">编程</a></h2><div class=""/><div class=""><h2 id="89b6" class="pw-subtitle-paragraph jw iz iq bd b jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn dk translated">使用张量流数据模块构建复杂的图像增强管道。</h2></div><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div role="button" tabindex="0" class="ku kv di kw bf kx"><div class="gh gi ko"><img src="../Images/53108c1f8325e29ee8c633b9c806ac18.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*c2vxXt2WYrd_jZERm4380A.jpeg"/></div></div><figcaption class="la lb gj gh gi lc ld bd b be z dk translated">来源:https://www.kaggle.com/docs/tpu<a class="ae le" href="https://www.kaggle.com/docs/tpu" rel="noopener ugc nofollow" target="_blank"/></figcaption></figure><p id="216e" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi mb translated"><span class="l mc md me bm mf mg mh mi mj di">如果</span>您想用Tensorflow以最有效的方式训练您的模型，您可能应该使用<a class="ae le" href="https://www.tensorflow.org/tutorials/load_data/tfrecord" rel="noopener ugc nofollow" target="_blank"> TFRecords </a>和<a class="ae le" href="https://www.tensorflow.org/guide/data" rel="noopener ugc nofollow" target="_blank"> Tensorflow数据模块</a>来构建您的管道，但是根据您的应用程序的要求和约束，使用它们可能是必要的而不是可选的，好消息是Tensorflow已经使它们变得非常干净和易于使用。</p><blockquote class="mk"><p id="3c92" class="ml mm iq bd mn mo mp mq mr ms mt ma dk translated">在本文中，我们将使用Tensorflow数据模块，通过复杂的数据增强组合，以简单而高效的方式构建管道。</p></blockquote><p id="f867" class="pw-post-body-paragraph lf lg iq lh b li mu ka lk ll mv kd ln lo mw lq lr ls mx lu lv lw my ly lz ma ij bi translated">我提到的可以改善模型训练的一个选项是使用TFRecords，TFRecord是Tensorflow提供的一种简单的数据存储格式，我不打算详细介绍TFRecords，因为这不是本文的重点，但如果您想了解更多信息，请查看Tensorflow的教程。</p><p id="2ee1" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">此处提供的信息可应用于在任何硬件中使用Tensorflow训练模型，我将使用TPU作为目标硬件，因为如果您使用TPU，可能您已经在尝试充分利用您的资源，无论如何您都需要使用Tensorflow数据模块。</p><h1 id="c172" class="mz na iq bd nb nc nd ne nf ng nh ni nj kf nk kg nl ki nm kj nn kl no km np nq bi translated">Tensorflow数据增强</h1><p id="bc75" class="pw-post-body-paragraph lf lg iq lh b li nr ka lk ll ns kd ln lo nt lq lr ls nu lu lv lw nv ly lz ma ij bi translated">首先，我们将从Tensorflow 的<a class="ae le" href="https://www.tensorflow.org/tutorials/images/data_augmentation" rel="noopener ugc nofollow" target="_blank">官方数据扩充教程中了解数据扩充是如何完成的开始。</a></p><pre class="kp kq kr ks gt nw nx ny nz aw oa bi"><span id="2bbc" class="ob na iq nx b gy oc od l oe of"># Data augmentation function<br/>def augment(image, label):<br/>  image = tf.image.random_crop(image, size=[IMG_SIZE, IMG_SIZE, 3])<br/>  image = tf.image.random_brightness(image, max_delta=0.5)<br/>  image = tf.clip_by_value(image, 0, 1)<br/>  return image, label<br/></span><span id="e249" class="ob na iq nx b gy og od l oe of"># Tensorflow data pipeline<br/>train_ds = (<br/>    train_ds<br/>    .shuffle(1000)<br/>    .map(augment, num_parallel_calls=AUTOTUNE)<br/>    .batch(batch_size)<br/>    .prefetch(AUTOTUNE)<br/>)</span></pre><p id="dc24" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">正如我们在<strong class="lh ja">增强</strong>功能中看到的，它将对图像应用一系列变换，首先，它将进行随机裁剪，然后应用随机亮度，最后裁剪值以保持它们在0和1之间。</p><p id="1d5a" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">根据Tensorflow最佳实践，数据扩充功能通常通过<strong class="lh ja">映射</strong>操作应用于数据管道。</p><p id="2630" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">上述方法的问题是如何将变换应用于图像，你基本上只是按顺序堆叠它们，一般来说，你需要对应用什么和如何应用有一些控制，让我描述几个场景来说明我的观点。</p><h2 id="1854" class="ob na iq bd nb oh oi dn nf oj ok dp nj lo ol om nl ls on oo nn lw op oq np iw bi translated">场景1:</h2><p id="139a" class="pw-post-body-paragraph lf lg iq lh b li nr ka lk ll ns kd ln lo nt lq lr ls nu lu lv lw nv ly lz ma ij bi translated">您的数据可能会受益于先进的数据增强技术，如<a class="ae le" href="https://arxiv.org/pdf/1708.04552.pdf" rel="noopener ugc nofollow" target="_blank">剪切</a>、<a class="ae le" href="https://arxiv.org/pdf/1710.09412.pdf" rel="noopener ugc nofollow" target="_blank">混合</a>或<a class="ae le" href="https://arxiv.org/pdf/1905.04899.pdf" rel="noopener ugc nofollow" target="_blank">剪切混合</a>，如果您熟悉它们的工作方式，您会知道对于每个样本，您可能只会应用其中一种。</p><h2 id="9dc9" class="ob na iq bd nb oh oi dn nf oj ok dp nj lo ol om nl ls on oo nn lw op oq np iw bi translated">场景2:</h2><p id="7ddb" class="pw-post-body-paragraph lf lg iq lh b li nr ka lk ll ns kd ln lo nt lq lr ls nu lu lv lw nv ly lz ma ij bi translated">您可能希望使用许多“像素级”增强，像素级我指的是像亮度、伽玛调整、对比度或饱和度这样的变换，通常这些变换的较轻变化可以安全地用于许多不同的数据集，但一次使用所有这些可能会改变太多图像，并最终干扰模型训练。</p><h1 id="57e5" class="mz na iq bd nb nc nd ne nf ng nh ni nj kf nk kg nl ki nm kj nn kl no km np nq bi translated">那么，我们能做些什么呢？</h1><p id="1fb4" class="pw-post-body-paragraph lf lg iq lh b li nr ka lk ll ns kd ln lo nt lq lr ls nu lu lv lw nv ly lz ma ij bi translated">如果你熟悉计算机视觉任务的数据增强，你可能听说过像<a class="ae le" href="https://imgaug.readthedocs.io/" rel="noopener ugc nofollow" target="_blank"> Imgaug </a>或<a class="ae le" href="https://albumentations.readthedocs.io/en/latest/" rel="noopener ugc nofollow" target="_blank">albuminations</a>这样的库，如果没有，这里是来自albuminations库的<a class="ae le" href="https://github.com/albumentations-team/albumentations_examples/blob/master/notebooks/example.ipynb" rel="noopener ugc nofollow" target="_blank">两个例子</a>和<a class="ae le" href="https://albumentations.readthedocs.io/en/latest/examples.html" rel="noopener ugc nofollow" target="_blank">关于它如何进行数据增强:</a></p><pre class="kp kq kr ks gt nw nx ny nz aw oa bi"><span id="f053" class="ob na iq nx b gy oc od l oe of"><strong class="nx ja">def</strong> <!-- -->augment<!-- -->(p=0.5):<br/>    <strong class="nx ja">return</strong> Compose([<br/>        RandomRotate90(),<br/>        Flip(),<br/>        Transpose(),<br/>        OneOf([<br/>            IAAAdditiveGaussianNoise(),<br/>            GaussNoise(),<br/>        ], p=0.2),<br/>        OneOf([<br/>            MotionBlur(p=0.2),<br/>            MedianBlur(blur_limit=3, p=0.1),<br/>            Blur(blur_limit=3, p=0.1),<br/>        ], p=0.2),<br/>        OneOf([<br/>            OpticalDistortion(p=0.3),<br/>            GridDistortion(p=0.1),<br/>            IAAPiecewiseAffine(p=0.3),<br/>        ], p=0.2),<br/>        OneOf([<br/>            CLAHE(clip_limit=2),<br/>            IAASharpen(),<br/>            IAAEmboss(),<br/>            RandomBrightnessContrast(),<br/>        ], p=0.3),<br/>        HueSaturationValue(p=0.3),<br/>    ], p=p)<br/><br/><br/>augmented_image = augment(image=image)['image']</span></pre><p id="668c" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">我们可以清楚地看到，Albumentations提供了一种更有效的方式来对图像应用不同的变换。您可以按顺序应用它们，就像Tensorflow教程一样，但是您也可以使用像"<strong class="lh ja"> OneOf" </strong>这样的操作，并在一组要应用的变换中只选择一个，最重要的细节是，在这里您可以控制每个变换被应用的概率。<br/>值得注意的是，这些库使用的转换都经过了大量优化，以尽可能快地运行，Albumentations甚至有一个<a class="ae le" href="https://github.com/albumentations-team/albumentations#benchmarking-results" rel="noopener ugc nofollow" target="_blank">基准</a>。</p><p id="4729" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">如果我们能够使用像Albumentations这样非常高效的库，并且已经通过我们的Tensorflow数据管道实现了许多不同的<a class="ae le" href="https://github.com/albumentations-team/albumentations#pixel-level-transforms" rel="noopener ugc nofollow" target="_blank"/><a class="ae le" href="https://github.com/albumentations-team/albumentations#spatial-level-transforms" rel="noopener ugc nofollow" target="_blank">转换</a>，那么这将是两全其美的，但不幸的是，这是不可能的，所以我们能做什么呢？</p><h1 id="8bb9" class="mz na iq bd nb nc nd ne nf ng nh ni nj kf nk kg nl ki nm kj nn kl no km np nq bi translated">使用Tensorflow进行复杂数据扩充</h1><p id="25bf" class="pw-post-body-paragraph lf lg iq lh b li nr ka lk ll ns kd ln lo nt lq lr ls nu lu lv lw nv ly lz ma ij bi translated">实际上，如果我们发挥一些创造力，我们可以构建与Albumentation提供的功能非常接近的数据增强功能，并且只使用Tensorflow代码，因此它可以在与Tensorflow管道集成的TPU上运行，下面是一个简单的示例:</p><pre class="kp kq kr ks gt nw nx ny nz aw oa bi"><span id="46a5" class="ob na iq nx b gy oc od l oe of">def augment(image):<br/>    p_spatial = tf.random.uniform([], 0, 1.0, dtype=tf.float32)<br/>    p_rotate = tf.random.uniform([], 0, 1.0, dtype=tf.float32)<br/>    <br/>    <br/>    <em class="or"># Flips</em><br/>    if p_spatial &gt;= .2:<br/>        image = tf.image.random_flip_left_right(image)<br/>        image = tf.image.random_flip_up_down(image)<br/>        <br/>    <em class="or"># Rotates</em><br/>    if p_rotate &gt; .75:<br/>        image = tf.image.rot90(image, k=3) <em class="or"># rotate 270º</em><br/>    elif p_rotate &gt; .5:<br/>        image = tf.image.rot90(image, k=2) <em class="or"># rotate 180º</em><br/>    elif p_rotate &gt; .25:<br/>        image = tf.image.rot90(image, k=1) <em class="or"># rotate 90º</em><br/><br/>    return image</span></pre><p id="3b5f" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">太好了！这个函数有我们喜欢的关于白蛋白的所有东西，并且是纯张量流，让我们检查:<br/>—【x】依次应用变换。<br/>—【x】<strong class="lh ja"/>变换类型之一(分组)。<br/>—【x】控制应用变换的概率。</p><h2 id="4aea" class="ob na iq bd nb oh oi dn nf oj ok dp nj lo ol om nl ls on oo nn lw op oq np iw bi translated">让我们来分析一下这个函数是怎么回事。</h2><p id="a76e" class="pw-post-body-paragraph lf lg iq lh b li nr ka lk ll ns kd ln lo nt lq lr ls nu lu lv lw nv ly lz ma ij bi translated">首先，我们定义两个变量<strong class="lh ja"> p_spatial </strong>和<strong class="lh ja"> p_rotate </strong>，然后给它们分配概率，这些概率是从随机的<a class="ae le" href="https://en.wikipedia.org/wiki/Continuous_uniform_distribution" rel="noopener ugc nofollow" target="_blank">均匀分布</a>中抽样的，这意味着区间[0，1]中的所有数字都有相同的机会被抽样。<br/>然后我们要应用两种不同类型的转换，<strong class="lh ja">翻转</strong>和<strong class="lh ja">旋转</strong>，它们具有不同的语义，因此它们属于不同的组。<br/>对于<strong class="lh ja">翻转</strong>变换，如果<strong class="lh ja"> p_spatial </strong>大于<strong class="lh ja"> .2 </strong>我们将应用两个随机翻转变换，换句话说，有<strong class="lh ja"> 80%的机会</strong>应用这两个随机翻转。<br/>在<strong class="lh ja">旋转</strong>变换时，我们使用了更多的控制，这将类似于相册中的"<strong class="lh ja"> OneOf" </strong>"，因为我们只应用了其中一个变换，每个变换都有<strong class="lh ja"> 25%的机会</strong>被应用，并且还有<strong class="lh ja"> 25%的机会</strong>不应用任何东西，我们需要这种控制，因为没有必要将图像旋转90 <strong class="lh ja"> </strong>三次，然后</p><p id="449f" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">利用这个想法，你可以构建比这个复杂得多的数据增强函数，这里有一个我在<a class="ae le" href="https://www.kaggle.com/c/siim-isic-melanoma-classification" rel="noopener ugc nofollow" target="_blank"> SIIM-ISIC黑素瘤分类</a> Kaggle竞赛中使用的例子:</p><pre class="kp kq kr ks gt nw nx ny nz aw oa bi"><span id="c00d" class="ob na iq nx b gy oc od l oe of"><strong class="nx ja">def</strong> data_augment(image):<br/>    p_rotation = tf.random.uniform([], 0, 1.0, dtype=tf.float32)<br/>    p_rotate = tf.random.uniform([], 0, 1.0, dtype=tf.float32)<br/>    p_cutout = tf.random.uniform([], 0, 1.0, dtype=tf.float32)<br/>    p_shear = tf.random.uniform([], 0, 1.0, dtype=tf.float32)<br/>    p_crop = tf.random.uniform([], 0, 1.0, dtype=tf.float32)<br/>    <br/>    <br/>    <strong class="nx ja">if</strong> p_shear &gt; .2:<br/>        <strong class="nx ja">if</strong> p_shear &gt; .6:<br/>            image = transform_shear(image, config['HEIGHT'], shear=20.)<br/>        <strong class="nx ja">else</strong>:<br/>            image = transform_shear(image, config['HEIGHT'], shear=-20.)<br/>    <br/>    <strong class="nx ja">if</strong> p_rotation &gt; .2:<br/>        <strong class="nx ja">if</strong> p_rotation &gt; .6:<br/>            image = transform_rotation(image, config['HEIGHT'], rotation=45.)<br/>        <strong class="nx ja">else</strong>:<br/>            image = transform_rotation(image, config['HEIGHT'], rotation=-45.)<br/><br/>    <strong class="nx ja">if</strong> p_crop &gt; .2:<br/>        image = data_augment_crop(image)<br/><br/>    <strong class="nx ja">if</strong> p_rotate &gt; .2:<br/>        image = data_augment_rotate(image)<br/>        <br/>    image = data_augment_spatial(image)<br/>    <br/>    image = tf.image.random_saturation(image, 0.7, 1.3)<br/>    image = tf.image.random_contrast(image, 0.8, 1.2)<br/>    image = tf.image.random_brightness(image, 0.1)<br/>    <br/><em class="or">    if p_cutout &gt; .5:</em><br/><em class="or">        image = data_augment_cutout(image)</em><br/>    <br/>    <strong class="nx ja">return</strong> image<br/><br/><strong class="nx ja">def</strong> data_augment_spatial(image):<br/>    p_spatial = tf.random.uniform([], 0, 1.0, dtype=tf.float32)<br/><br/>    image = tf.image.random_flip_left_right(image)<br/>    image = tf.image.random_flip_up_down(image)<br/>    <strong class="nx ja">if</strong> p_spatial &gt; .75:<br/>        image = tf.image.transpose(image)<br/><br/>    <strong class="nx ja">return</strong> image<br/><br/><strong class="nx ja">def</strong> data_augment_rotate(image):<br/>    p_rotate = tf.random.uniform([], 0, 1.0, dtype=tf.float32)<br/>    <br/>    <strong class="nx ja">if</strong> p_rotate &gt; .66:<br/>        image = tf.image.rot90(image, k=3) <em class="or"># rotate 270º</em><br/>    <strong class="nx ja">elif</strong> p_rotate &gt; .33:<br/>        image = tf.image.rot90(image, k=2) <em class="or"># rotate 180º</em><br/>    <strong class="nx ja">else</strong>:<br/>        image = tf.image.rot90(image, k=1) <em class="or"># rotate 90º</em><br/><br/>    <strong class="nx ja">return</strong> image<br/><br/><strong class="nx ja">def</strong> data_augment_crop(image):<br/>    p_crop = tf.random.uniform([], 0, 1.0, dtype=tf.float32)<br/>    crop_size = tf.random.uniform([], int(config['HEIGHT']*.7), config['HEIGHT'], dtype=tf.int32)<br/>    <br/>    <strong class="nx ja">if</strong> p_crop &gt; .5:<br/>        image = tf.image.random_crop(image, size=[crop_size, crop_size, config['CHANNELS']])<br/>    <strong class="nx ja">else</strong>:<br/>        <strong class="nx ja">if</strong> p_crop &gt; .4:<br/>            image = tf.image.central_crop(image, central_fraction=.7)<br/>        <strong class="nx ja">elif</strong> p_crop &gt; .2:<br/>            image = tf.image.central_crop(image, central_fraction=.8)<br/>        <strong class="nx ja">else</strong>:<br/>            image = tf.image.central_crop(image, central_fraction=.9)<br/>    <br/>    image = tf.image.resize(image, size=[config['HEIGHT'], config['WIDTH']])<br/><br/>    <strong class="nx ja">return</strong> image</span></pre><p id="cd3f" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">我还将留下两个链接来完成使用类似方法的代码示例。<br/> — <a class="ae le" href="https://github.com/dimitreOliveira/melanoma-classification/blob/master/Model%20backlog/Train/136_melanoma_5fold_EfficientNetB5_512.ipynb" rel="noopener ugc nofollow" target="_blank">上例的完整代码</a>T5—<a class="ae le" href="https://www.kaggle.com/dimitreoliveira/flower-with-tpus-advanced-augmentations" rel="noopener ugc nofollow" target="_blank">tensor flow高级增强入门笔记本</a></p><p id="5aa6" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">如果你想了解如何在TPUs上建立一个完整的Tensorflow管道来训练模型，这里有一篇我写的很酷的文章“<a class="ae le" href="https://medium.com/swlh/efficiently-using-tpu-for-image-classification-ed20d2970893" rel="noopener">有效地使用TPU进行图像分类</a>”。</p><p id="2aad" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">要了解更多信息，请查看参考资料:<br/> — <a class="ae le" href="https://www.tensorflow.org/tutorials/load_data/tfrecord" rel="noopener ugc nofollow" target="_blank"> Tensorflow TFRecords教程</a> <br/> — <a class="ae le" href="https://www.tensorflow.org/api_docs/python/tf/data" rel="noopener ugc nofollow" target="_blank"> Tensorflow数据模块文档</a> <br/> — <a class="ae le" href="https://www.tensorflow.org/guide/data" rel="noopener ugc nofollow" target="_blank"> Tensorflow数据模块教程</a> <br/> — <a class="ae le" href="https://www.tensorflow.org/guide/data_performance" rel="noopener ugc nofollow" target="_blank">使用tf.data API提高性能</a> <br/> — <a class="ae le" href="https://www.tensorflow.org/tutorials/images/data_augmentation" rel="noopener ugc nofollow" target="_blank"> Tensorflow数据增强教程</a> <br/> — <a class="ae le" href="https://medium.com/swlh/efficiently-using-tpu-for-image-classification-ed20d2970893" rel="noopener">高效使用TPU进行图像分类</a><br/>—<br/></p></div></div>    
</body>
</html>