<html>
<head>
<title>Time-Series Analysis: Hands-On with SciKit-Learn Feature-Engineering</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">时间序列分析:SciKit实践-学习特征工程</h1>
<blockquote>原文：<a href="https://pub.towardsai.net/time-series-analysis-hands-on-with-scikit-learn-feature-engineering-1e958e6534da?source=collection_archive---------0-----------------------#2021-11-20">https://pub.towardsai.net/time-series-analysis-hands-on-with-scikit-learn-feature-engineering-1e958e6534da?source=collection_archive---------0-----------------------#2021-11-20</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><h2 id="bc96" class="ir is it bd b dl iu iv iw ix iy iz dk ja translated" aria-label="kicker paragraph"><a class="ae ep" href="https://towardsai.net/p/category/data-science" rel="noopener ugc nofollow" target="_blank">数据科学</a></h2><div class=""/><div class=""><h2 id="558c" class="pw-subtitle-paragraph jz jc it bd b ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq dk translated">Python和Google Colab项目</h2></div><blockquote class="kr ks kt"><p id="d5d5" class="ku kv kw kx b ky kz kd la lb lc kg ld le lf lg lh li lj lk ll lm ln lo lp lq im bi translated"><strong class="kx jd"> <em class="it">内容</em> </strong></p><p id="8aa6" class="ku kv kw kx b ky kz kd la lb lc kg ld le lf lg lh li lj lk ll lm ln lo lp lq im bi translated">0.简介<br/> 1。探索性数据分析<br/> 2。数据集分割和变量定义<br/> 3。梯度推进<br/> 4。朴素线性回归<br/> 5。时间步长分类<br/> 6。三角函数特征<br/> 7。周期性花键特征<br/> 8。特征对线性模型预测影响的定性分析<br/> 9。用样条和多项式特征模拟成对交互<br/> 10。用内核模拟非线性特征交互<br/>结论</p></blockquote><p id="3dbe" class="pw-post-body-paragraph ku kv it kx b ky kz kd la lb lc kg ld lr lf lg lh ls lj lk ll lt ln lo lp lq im bi translated"><strong class="kx jd">简介</strong></p><p id="3f65" class="pw-post-body-paragraph ku kv it kx b ky kz kd la lb lc kg ld lr lf lg lh ls lj lk ll lt ln lo lp lq im bi translated">时间就是金钱。尽管这种说法可能很老套，但事实是每个人都需要技能来理解与时间相关的事件。这种类型的分析已经使用了几个世纪，例如在行星运动或天气预测中。然而，有了实际的计算机能力和数据可用性，就有可能比以往做更多的事情。</p><p id="1e74" class="pw-post-body-paragraph ku kv it kx b ky kz kd la lb lc kg ld lr lf lg lh ls lj lk ll lt ln lo lp lq im bi translated">在时间序列分析(TSA)中，时间是中心变量，研究人员或分析人员需要了解时间“前后”发生了什么，以及这些事件如何随时间变化并受时间和其他变量的影响。通过这种方式，TSA的数据集通常由在一段时间间隔内收集的数据构建而成，并且应该包括大量的观察数据，以避免偏差，并为研究人员提供事件的真实表示。</p><p id="3a72" class="pw-post-body-paragraph ku kv it kx b ky kz kd la lb lc kg ld lr lf lg lh ls lj lk ll lt ln lo lp lq im bi translated">在这个数据分析的小项目中，我们将评估一年内以小时为单位的缺勤时间。我们的目标是分析趋势，帮助管理层预测未来的缺勤率。如果我们可以找到一个足够好的模型，我们就可以预测未来的行为，为我们的业务做准备。</p><p id="ca5b" class="pw-post-body-paragraph ku kv it kx b ky kz kd la lb lc kg ld lr lf lg lh ls lj lk ll lt ln lo lp lq im bi translated">我们将使用来自加州大学欧文分校(UCI)机器学习知识库的开放数据集。该数据集包含企业中雇主的缺勤时间数据，以及关于员工的一些其他变量，如服务时间、工作距离、工作量或儿子数量。</p><p id="b97e" class="pw-post-body-paragraph ku kv it kx b ky kz kd la lb lc kg ld lr lf lg lh ls lj lk ll lt ln lo lp lq im bi translated">对于这个项目，我们将在Google Colab环境中使用Python，并使用<a class="ae lu" href="https://scikit-learn.org/stable/auto_examples/applications/plot_cyclical_feature_engineering.html#trigonometric-features" rel="noopener ugc nofollow" target="_blank"> SciKit-Learn库进行与时间相关的特征工程</a>。</p><p id="422b" class="pw-post-body-paragraph ku kv it kx b ky kz kd la lb lc kg ld lr lf lg lh ls lj lk ll lt ln lo lp lq im bi translated">如果您不能直接从本文中复制所有代码，请不要担心，您可以在<a class="ae lu" href="https://github.com/cdanielaam/Time_Series_Analysis/blob/main/time_series.ipynb" rel="noopener ugc nofollow" target="_blank"> GitHub </a>上找到该项目中使用的确切代码。</p><p id="0e70" class="pw-post-body-paragraph ku kv it kx b ky kz kd la lb lc kg ld lr lf lg lh ls lj lk ll lt ln lo lp lq im bi translated">开始吧！</p><p id="1d78" class="pw-post-body-paragraph ku kv it kx b ky kz kd la lb lc kg ld lr lf lg lh ls lj lk ll lt ln lo lp lq im bi translated"><strong class="kx jd">探索性数据分析</strong></p><p id="d0eb" class="pw-post-body-paragraph ku kv it kx b ky kz kd la lb lc kg ld lr lf lg lh ls lj lk ll lt ln lo lp lq im bi translated">首先要做的是导入数据集并研究它。为了完成整个项目，我将使用谷歌Colab免费版，因为它已经安装了几个Python库，随时可以使用。这样我们可以避免在我们的机器上安装更多的包或者处理不同的版本。</p><p id="c37a" class="pw-post-body-paragraph ku kv it kx b ky kz kd la lb lc kg ld lr lf lg lh ls lj lk ll lt ln lo lp lq im bi translated">我还建议您将数据集导入到您的Google Drive，并从Google Colab访问它。通过这种方式，您可以避免在会话到期时上传数据集。要在Google Colab上安装Google Drive，请使用:</p><pre class="lv lw lx ly gt lz ma mb mc aw md bi"><span id="16fd" class="me mf it ma b gy mg mh l mi mj">from google.colab import drive #This code will mount Google Drive<br/>drive.mount('/content/drive')</span></pre><p id="a9d8" class="pw-post-body-paragraph ku kv it kx b ky kz kd la lb lc kg ld lr lf lg lh ls lj lk ll lt ln lo lp lq im bi translated">现在导入项目所需的库:</p><pre class="lv lw lx ly gt lz ma mb mc aw md bi"><span id="538f" class="me mf it ma b gy mg mh l mi mj">import pandas as pd<br/>import matplotlib.pyplot as plt<br/>import seaborn as sns<br/>import numpy as pd<br/>import statistics</span><span id="71b2" class="me mf it ma b gy mk mh l mi mj">#DataSet Split<br/>from sklearn.model_selection import TimeSeriesSplit</span><span id="44e5" class="me mf it ma b gy mk mh l mi mj">#Gradient Boosting<br/>from sklearn.pipeline import make_pipeline<br/>from sklearn.preprocessing import OrdinalEncoder<br/>from sklearn.compose import ColumnTransformer<br/>from sklearn.ensemble import HistGradientBoostingRegressor<br/>from sklearn.model_selection import cross_validate</span><span id="16e8" class="me mf it ma b gy mk mh l mi mj">#Naive Linear Regression<br/>from sklearn.preprocessing import OneHotEncoder<br/>from sklearn.preprocessing import MinMaxScaler<br/>from sklearn.linear_model import RidgeCV<br/>import numpy as np</span><span id="d9cb" class="me mf it ma b gy mk mh l mi mj">#Trigonometric features<br/>from sklearn.preprocessing import FunctionTransformer</span><span id="85e6" class="me mf it ma b gy mk mh l mi mj">#Periodic Spline Features<br/>from sklearn.preprocessing import SplineTransformer</span><span id="d3d9" class="me mf it ma b gy mk mh l mi mj">#Pairwise interactions with splines and polynomial features<br/>from sklearn.preprocessing import PolynomialFeatures<br/>from sklearn.pipeline import FeatureUnion</span><span id="115f" class="me mf it ma b gy mk mh l mi mj">#Non-Linear feature interactions with kernels<br/>from sklearn.kernel_approximation import Nystroem</span></pre><p id="035e" class="pw-post-body-paragraph ku kv it kx b ky kz kd la lb lc kg ld lr lf lg lh ls lj lk ll lt ln lo lp lq im bi translated">加载和检查数据集:</p><pre class="lv lw lx ly gt lz ma mb mc aw md bi"><span id="4091" class="me mf it ma b gy mg mh l mi mj">df = pd.read_csv('/content/drive/MyDrive/ColabNotebooks/time_series.csv')</span><span id="1c1e" class="me mf it ma b gy mk mh l mi mj">df #To see the tabular dataset<br/>print(df.columns) #Will print columns names</span></pre><figure class="lv lw lx ly gt mm gh gi paragraph-image"><div role="button" tabindex="0" class="mn mo di mp bf mq"><div class="gh gi ml"><img src="../Images/2c7f515083077b88fb14d20c22782246.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*0dqUbERpw1RVChCsW-lcbA.png"/></div></div></figure><figure class="lv lw lx ly gt mm gh gi paragraph-image"><div role="button" tabindex="0" class="mn mo di mp bf mq"><div class="gh gi mt"><img src="../Images/081a35043cdedb8f9440dadb18ba4677.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*FRVeMCRLmpcuUMdqB4rdsQ.png"/></div></div></figure><p id="8364" class="pw-post-body-paragraph ku kv it kx b ky kz kd la lb lc kg ld lr lf lg lh ls lj lk ll lt ln lo lp lq im bi translated">我们可以检查数值变量的最大值、最小值、平均值和标准差，并更好地理解我们的数据集。我们将从“旷工_时间_小时”开始，因为这是我们想要建模的变量。</p><pre class="lv lw lx ly gt lz ma mb mc aw md bi"><span id="5a99" class="me mf it ma b gy mg mh l mi mj">#Check max and min for some variables (columns) and their distribution:</span><span id="0f52" class="me mf it ma b gy mk mh l mi mj">print("Max absent time:", df["absenteeism_time_in_hours"].max())<br/>print("Min absent time:", df["absenteeism_time_in_hours"].min())</span><span id="7cf3" class="me mf it ma b gy mk mh l mi mj">print("Mean absent time: ", df["son"].mean())<br/>print("SD absent time: ", statistics.pstdev(df["son"]))</span><span id="c8ed" class="me mf it ma b gy mk mh l mi mj">sns.kdeplot(df["absenteeism_time_in_hours"], shade=True)</span></pre><figure class="lv lw lx ly gt mm gh gi paragraph-image"><div class="gh gi mu"><img src="../Images/e1555d00d2c46015bc452a1c9546c2fb.png" data-original-src="https://miro.medium.com/v2/resize:fit:648/format:webp/1*q_rZCjQ5i9yt9tX8yvLQkQ.png"/></div></figure><figure class="lv lw lx ly gt mm gh gi paragraph-image"><div class="gh gi mv"><img src="../Images/dc828cac0397318a84f55a5fd7ff76a3.png" data-original-src="https://miro.medium.com/v2/resize:fit:784/format:webp/1*Y9k_n3NNSjCDmg_ejGj1OQ.png"/></div></figure><p id="25cd" class="pw-post-body-paragraph ku kv it kx b ky kz kd la lb lc kg ld lr lf lg lh ls lj lk ll lt ln lo lp lq im bi translated">我们可以对其他数值变量做同样的处理，得到它们分布的密度图。最终结果将是这样的:</p><figure class="lv lw lx ly gt mm gh gi paragraph-image"><div role="button" tabindex="0" class="mn mo di mp bf mq"><div class="gh gi mw"><img src="../Images/4e4468bd1acd5e97dabfed3b18878a2b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*0ZJOSbOcphyzDUxTHc3iaA.png"/></div></div></figure><p id="6adb" class="pw-post-body-paragraph ku kv it kx b ky kz kd la lb lc kg ld lr lf lg lh ls lj lk ll lt ln lo lp lq im bi translated">一些分类变量被编码为数字，但是，我们可以重新编码一些然后构建条形图:</p><pre class="lv lw lx ly gt lz ma mb mc aw md bi"><span id="7817" class="me mf it ma b gy mg mh l mi mj">df["day_of_the_week"].value_counts()</span></pre><figure class="lv lw lx ly gt mm gh gi paragraph-image"><div class="gh gi mx"><img src="../Images/7e863f72d4a8a5a124032614e27f9993.png" data-original-src="https://miro.medium.com/v2/resize:fit:630/format:webp/1*F_M-LOXDtEzIPEjnj8CeVw.png"/></div></figure><p id="559b" class="pw-post-body-paragraph ku kv it kx b ky kz kd la lb lc kg ld lr lf lg lh ls lj lk ll lt ln lo lp lq im bi translated">并创建一个条形图:</p><pre class="lv lw lx ly gt lz ma mb mc aw md bi"><span id="a6af" class="me mf it ma b gy mg mh l mi mj">values = [161, 156, 154, 144, 125]<br/>days = ("Monday", "Tuesday", "Wednesday", "Thursday", "Friday")</span><span id="33e3" class="me mf it ma b gy mk mh l mi mj">plt.bar(days, values)<br/>plt.show()</span></pre><figure class="lv lw lx ly gt mm gh gi paragraph-image"><div class="gh gi my"><img src="../Images/6b0d2fb025d215b9b1047234699f6d92.png" data-original-src="https://miro.medium.com/v2/resize:fit:750/format:webp/1*DL6KIqKLj6QigGkO0j-0Ng.png"/></div></figure><p id="0a9e" class="pw-post-body-paragraph ku kv it kx b ky kz kd la lb lc kg ld lr lf lg lh ls lj lk ll lt ln lo lp lq im bi translated">这同样适用于“缺勤月份”和“命中目标”。</p><pre class="lv lw lx ly gt lz ma mb mc aw md bi"><span id="d4d4" class="me mf it ma b gy mg mh l mi mj">df["month_of_absence"].value_counts()</span><span id="6ade" class="me mf it ma b gy mk mh l mi mj">absence_hours = [53, 72, 87, 53, 64, 54, 67, 54, 53, 71, 63, 49]<br/>month = ("Jan", "Feb", "Mar", "Apr", "May", "Jun", "Jul", "Aug", "Sep", "Oct", "Nov", "Dec")</span><span id="f532" class="me mf it ma b gy mk mh l mi mj">plt.bar(month, absence_hours)<br/>plt.show()</span></pre><figure class="lv lw lx ly gt mm gh gi paragraph-image"><div class="gh gi mz"><img src="../Images/81d77ba4840b7279fe7a1eb86d0314ef.png" data-original-src="https://miro.medium.com/v2/resize:fit:736/format:webp/1*R7nRNJXk-y0nTdXSUxKc4g.png"/></div></figure><pre class="lv lw lx ly gt lz ma mb mc aw md bi"><span id="eab7" class="me mf it ma b gy mg mh l mi mj">df["hit_target"].value_counts()</span><span id="e052" class="me mf it ma b gy mk mh l mi mj">hit = [105, 102, 89, 79, 75, 75, 66, 45, 34, 28, 19, 12, 11]<br/>percent_target = ("93", "99", "97", "92", "96", "95", "98", "91",    "94", "88", "81", "87", "100")</span><span id="82e0" class="me mf it ma b gy mk mh l mi mj">plt.bar(percent_target, hit)<br/>plt.show()</span></pre><figure class="lv lw lx ly gt mm gh gi paragraph-image"><div class="gh gi my"><img src="../Images/6b37c5ba94c68c1df32c838e5a66db49.png" data-original-src="https://miro.medium.com/v2/resize:fit:750/format:webp/1*8hTF2AVkg-rta0cOxKljRQ.png"/></div></figure><p id="350f" class="pw-post-body-paragraph ku kv it kx b ky kz kd la lb lc kg ld lr lf lg lh ls lj lk ll lt ln lo lp lq im bi translated">具有较少类别的分类数据的另一个选项是将它们显示在作为缺勤时间的函数的箱线图中:</p><pre class="lv lw lx ly gt lz ma mb mc aw md bi"><span id="447b" class="me mf it ma b gy mg mh l mi mj">df["disciplinary_failure"].value_counts()<br/>sns.boxplot( x=df["disciplinary_failure"], y=df["absenteeism_time_in_hours"], showfliers = False)</span></pre><figure class="lv lw lx ly gt mm gh gi paragraph-image"><div class="gh gi na"><img src="../Images/d939319352c51607bfe79d96d7432ea7.png" data-original-src="https://miro.medium.com/v2/resize:fit:766/format:webp/1*Pdr9U4CQB9wbwAw6TZA6OA.png"/></div></figure><p id="eb88" class="pw-post-body-paragraph ku kv it kx b ky kz kd la lb lc kg ld lr lf lg lh ls lj lk ll lt ln lo lp lq im bi translated">其他分类变量也是如此:</p><figure class="lv lw lx ly gt mm gh gi paragraph-image"><div role="button" tabindex="0" class="mn mo di mp bf mq"><div class="gh gi nb"><img src="../Images/1e4dc15a45163963adee10e830ed1876.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*_VjsCAKP1aOW7rnwxUnhRQ.png"/></div></div></figure><p id="491f" class="pw-post-body-paragraph ku kv it kx b ky kz kd la lb lc kg ld lr lf lg lh ls lj lk ll lt ln lo lp lq im bi translated">变量之间的相关性可以基于<em class="kw">的专业知识</em>(鉴于人力资源的话题，这不是我的情况)，或者我们可以走简单的路线，建立一个相关图。首先，我们将删除带有分类变量“缺席月份”和“星期几:</p><pre class="lv lw lx ly gt lz ma mb mc aw md bi"><span id="cf13" class="me mf it ma b gy mg mh l mi mj">df_1 = df.drop("month_of_absence", axis="columns")<br/>df_2 = df_1.drop("day_of_the_week", axis="columns")</span></pre><p id="39b2" class="pw-post-body-paragraph ku kv it kx b ky kz kd la lb lc kg ld lr lf lg lh ls lj lk ll lt ln lo lp lq im bi translated">现在是相关矩阵:</p><pre class="lv lw lx ly gt lz ma mb mc aw md bi"><span id="c750" class="me mf it ma b gy mg mh l mi mj">corr_matrix=df_2.corr()</span><span id="4f2e" class="me mf it ma b gy mk mh l mi mj">mask = np.zeros_like(corr_matrix)<br/>mask[np.triu_indices_from(mask)] = True</span><span id="7690" class="me mf it ma b gy mk mh l mi mj">sns.heatmap(corr_matrix, mask=mask, square=True)</span></pre><figure class="lv lw lx ly gt mm gh gi paragraph-image"><div class="gh gi nc"><img src="../Images/a3dea103feb9de01bd25d4f6eb26ae0d.png" data-original-src="https://miro.medium.com/v2/resize:fit:930/format:webp/1*dog_WYUCZphdPzW2MFoqYw.png"/></div></figure><p id="fc19" class="pw-post-body-paragraph ku kv it kx b ky kz kd la lb lc kg ld lr lf lg lh ls lj lk ll lt ln lo lp lq im bi translated">检查我们数据的最后一步是一年中缺勤时间的图表:</p><pre class="lv lw lx ly gt lz ma mb mc aw md bi"><span id="c75d" class="me mf it ma b gy mg mh l mi mj">fig, ax = plt.subplots(figsize=(12, 4))</span><span id="7880" class="me mf it ma b gy mk mh l mi mj">week_demand = df.groupby(["month_of_absence", "day_of_the_week"]).count()["absenteeism_time_in_hours"]</span><span id="0dce" class="me mf it ma b gy mk mh l mi mj">week_demand.plot(ax=ax)<br/>_ = ax.set(<br/>          title="Hourly absence during the year",<br/>          xticks=[i * 5 for i in range(12)],<br/>          xticklabels=["jan", "feb", "mar", "apr", "may", "jun", "jul", "aug", "sep", "oct", "nov", "dec"],<br/>          xlabel="Month of Absence",<br/>          ylabel="Hours of Absence",<br/>)</span></pre><figure class="lv lw lx ly gt mm gh gi paragraph-image"><div role="button" tabindex="0" class="mn mo di mp bf mq"><div class="gh gi nd"><img src="../Images/8fd50729d632d560eaa03cf30c90ebba.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*jvQ_br7aedppnbllx9BKIg.png"/></div></div></figure><p id="3726" class="pw-post-body-paragraph ku kv it kx b ky kz kd la lb lc kg ld lr lf lg lh ls lj lk ll lt ln lo lp lq im bi translated"><strong class="kx jd">数据集分割和变量定义</strong></p><p id="d22e" class="pw-post-body-paragraph ku kv it kx b ky kz kd la lb lc kg ld lr lf lg lh ls lj lk ll lt ln lo lp lq im bi translated">正如在其他机器学习项目中一样，我们需要将数据分成训练和测试子样本。对于数据集分割，我们将使用SciKit-Learn的<strong class="kx jd"> TimeSeriesSplit </strong>函数，在训练集中随着数量的增加进行5次分割。这允许与前一组交叉验证，从而降低偏倚。我们将让函数自动选择每组的大小。</p><pre class="lv lw lx ly gt lz ma mb mc aw md bi"><span id="fb1f" class="me mf it ma b gy mg mh l mi mj">ts_cv = TimeSeriesSplit(<br/>         n_splits=5,  #Number of splits used<br/>         gap=0,  #No time needed between sets<br/>         max_train_size=None, #Auto train sample size <br/>         test_size=None, #Auto test sample size<br/>)</span></pre><p id="37b7" class="pw-post-body-paragraph ku kv it kx b ky kz kd la lb lc kg ld lr lf lg lh ls lj lk ll lt ln lo lp lq im bi translated">为了定义预测(X)和预测(y)变量，我们需要从表中删除“旷工时间小时数”列:</p><pre class="lv lw lx ly gt lz ma mb mc aw md bi"><span id="50f5" class="me mf it ma b gy mg mh l mi mj">y = df["absenteeism_time_in_hours"] / df["absenteeism_time_in_hours"].max()</span><span id="014a" class="me mf it ma b gy mk mh l mi mj">X = df.drop("absenteeism_time_in_hours", axis="columns")</span></pre><p id="570e" class="pw-post-body-paragraph ku kv it kx b ky kz kd la lb lc kg ld lr lf lg lh ls lj lk ll lt ln lo lp lq im bi translated">并检查我们新的<em class="kw"> y </em>变量(我们想要预测的变量)的分布:</p><pre class="lv lw lx ly gt lz ma mb mc aw md bi"><span id="6c09" class="me mf it ma b gy mg mh l mi mj">fig, ax = plt.subplots(figsize=(12, 4))<br/>y.hist(bins=30, ax=ax)</span><span id="b893" class="me mf it ma b gy mk mh l mi mj">_ = ax.set(<br/>    xlabel="Fraction of absenteeism time in hours",<br/>    ylabel="Number of hours",<br/>)</span></pre><figure class="lv lw lx ly gt mm gh gi paragraph-image"><div role="button" tabindex="0" class="mn mo di mp bf mq"><div class="gh gi ne"><img src="../Images/0de2859607f08b2498dd42819e5fb6a0.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*BtqiPgqPvQ6r6N-OBFiuaQ.png"/></div></div></figure><p id="9dcd" class="pw-post-body-paragraph ku kv it kx b ky kz kd la lb lc kg ld lr lf lg lh ls lj lk ll lt ln lo lp lq im bi translated">我们可以检查我们的5个拆分，看看它们看起来如何:</p><pre class="lv lw lx ly gt lz ma mb mc aw md bi"><span id="2948" class="me mf it ma b gy mg mh l mi mj">all_splits = list(ts_cv.split(X, y))</span><span id="ff0f" class="me mf it ma b gy mk mh l mi mj">train_0, test_0 = all_splits[0]<br/>X.iloc[test_0]<br/>X.iloc[train_0]</span><span id="d152" class="me mf it ma b gy mk mh l mi mj">[OUT]: 125 rows × 20 columns</span><span id="a171" class="me mf it ma b gy mk mh l mi mj">train_1, test_1 = all_splits[1]<br/>X.iloc[test_1]<br/>X.iloc[train_1]</span><span id="7a5b" class="me mf it ma b gy mk mh l mi mj">[OUT]: 248 rows × 20 columns</span><span id="edcd" class="me mf it ma b gy mk mh l mi mj">train_2, test_2 = all_splits[2]<br/>X.iloc[test_2]<br/>X.iloc[train_2]</span><span id="c1b7" class="me mf it ma b gy mk mh l mi mj">[OUT]: 371 rows × 20 columns</span><span id="f924" class="me mf it ma b gy mk mh l mi mj">train_3, test_3 = all_splits[3]<br/>X.iloc[test_3]<br/>X.iloc[train_3]</span><span id="9df6" class="me mf it ma b gy mk mh l mi mj">[OUT]: 494 rows × 20 columns</span><span id="b87b" class="me mf it ma b gy mk mh l mi mj">train_4, test_4 = all_splits[4]<br/>X.iloc[test_4]<br/>X.iloc[train_4]</span><span id="1bf3" class="me mf it ma b gy mk mh l mi mj">[OUT]: 617 rows × 20 columns</span></pre><p id="1cd6" class="pw-post-body-paragraph ku kv it kx b ky kz kd la lb lc kg ld lr lf lg lh ls lj lk ll lt ln lo lp lq im bi translated">在我们开始第一个模型之前，我们还需要做两件事:对分类变量“缺勤月份”和“星期几”进行编码:</p><pre class="lv lw lx ly gt lz ma mb mc aw md bi"><span id="80c8" class="me mf it ma b gy mg mh l mi mj">categorical_columns = [<br/>    "month_of_absence",<br/>    "day_of_the_week",<br/>]</span><span id="b41a" class="me mf it ma b gy mk mh l mi mj">categories = [<br/>    ["jan", "feb", "mar", "apr", "may", "jun", "jul", "aug", "sep", "oct", "nov", "dec"],<br/>    ["Monday", "Tuesday", "Wednesday", "Thursday", "Friday"],<br/>]</span><span id="d244" class="me mf it ma b gy mk mh l mi mj">ordinal_encoder = OrdinalEncoder(categories=categories)</span></pre><p id="8be8" class="pw-post-body-paragraph ku kv it kx b ky kz kd la lb lc kg ld lr lf lg lh ls lj lk ll lt ln lo lp lq im bi translated">并定义一个函数来评估我们的模型:</p><pre class="lv lw lx ly gt lz ma mb mc aw md bi"><span id="90f5" class="me mf it ma b gy mg mh l mi mj">def evaluate(model, X, y, cv):<br/>    cv_results = cross_validate(<br/>        model,<br/>        X,<br/>        y,<br/>        cv=cv,<br/>        scoring=["neg_mean_absolute_error", "neg_root_mean_squared_error"],<br/>    )<br/>    mae = -cv_results["test_neg_mean_absolute_error"]<br/>    rmse = -cv_results["test_neg_root_mean_squared_error"]<br/>    print(<br/>        f"Mean Absolute Error:     {mae.mean():.3f} +/- {mae.std():.3f}\n"<br/>        f"Root Mean Squared Error: {rmse.mean():.3f} +/- {rmse.std():.3f}"<br/>    )</span></pre><p id="6b55" class="pw-post-body-paragraph ku kv it kx b ky kz kd la lb lc kg ld lr lf lg lh ls lj lk ll lt ln lo lp lq im bi translated">准备开始！</p><p id="2e13" class="pw-post-body-paragraph ku kv it kx b ky kz kd la lb lc kg ld lr lf lg lh ls lj lk ll lt ln lo lp lq im bi translated"><strong class="kx jd">梯度增强</strong></p><p id="96af" class="pw-post-body-paragraph ku kv it kx b ky kz kd la lb lc kg ld lr lf lg lh ls lj lk ll lt ln lo lp lq im bi translated">梯度推进是一种机器学习技术，通常用于克服高维稀疏数据。梯度提升背后的主要思想是对训练数据执行连续的树生长。该过程产生树的集合，集合中的每棵树可以使用梯度增强来构建，并且反过来可以从集合中的前一棵树学习。集合中的下一棵树可以用不同的特征集来创建，并且集合中的每棵树在分类方面都是性能最好的。</p><p id="f97c" class="pw-post-body-paragraph ku kv it kx b ky kz kd la lb lc kg ld lr lf lg lh ls lj lk ll lt ln lo lp lq im bi translated">梯度增强还可以处理多类分类任务，这就是我们在可行示例中遇到的数值和分类变量的情况。要构建模型，请执行以下操作:</p><pre class="lv lw lx ly gt lz ma mb mc aw md bi"><span id="73d4" class="me mf it ma b gy mg mh l mi mj">gbrt_pipeline = make_pipeline(<br/>    ColumnTransformer(<br/>        transformers=[<br/>            ("categorical", ordinal_encoder, categorical_columns),<br/>        ],<br/>        remainder="passthrough",<br/>    ),<br/>    HistGradientBoostingRegressor(<br/>        categorical_features=range(2),<br/>    ),<br/>)</span></pre><p id="7835" class="pw-post-body-paragraph ku kv it kx b ky kz kd la lb lc kg ld lr lf lg lh ls lj lk ll lt ln lo lp lq im bi translated">并评估:</p><pre class="lv lw lx ly gt lz ma mb mc aw md bi"><span id="ca8c" class="me mf it ma b gy mg mh l mi mj">evaluate(gbrt_pipeline, X, y, cv=ts_cv)</span></pre><figure class="lv lw lx ly gt mm gh gi paragraph-image"><div class="gh gi nf"><img src="../Images/d024ba5e485ed5029b445987e0daf2ea.png" data-original-src="https://miro.medium.com/v2/resize:fit:790/format:webp/1*rJEP5Q1-dHM2miAnpZNHew.png"/></div></figure><p id="0486" class="pw-post-body-paragraph ku kv it kx b ky kz kd la lb lc kg ld lr lf lg lh ls lj lk ll lt ln lo lp lq im bi translated">还不错，可以看到我们有4%到7%的误差。</p><p id="5599" class="pw-post-body-paragraph ku kv it kx b ky kz kd la lb lc kg ld lr lf lg lh ls lj lk ll lt ln lo lp lq im bi translated"><strong class="kx jd">朴素线性回归</strong></p><p id="8512" class="pw-post-body-paragraph ku kv it kx b ky kz kd la lb lc kg ld lr lf lg lh ls lj lk ll lt ln lo lp lq im bi translated">下一个模型是简单线性回归。简单线性回归可用于模拟单个自变量和单个因变量之间的关系。它由著名的公式表示:</p><blockquote class="ng"><p id="df2f" class="nh ni it bd nj nk nl nm nn no np lq dk translated"><em class="nq"> y = m.x+b </em></p></blockquote><p id="182c" class="pw-post-body-paragraph ku kv it kx b ky nr kd la lb ns kg ld lr nt lg lh ls nu lk ll lt nv lo lp lq im bi translated">该模型由一条穿过数据点的直线组成。回归系数表示每个自变量如何影响因变量，因此系数越大表明变量之间的关系越强。简单线性回归是一种常见的技术，可以快速了解如何根据几个独立变量预测响应变量。然而，它不能很好地推广到高维数据，并且经常不能捕捉重要的非线性关系。</p><p id="3c68" class="pw-post-body-paragraph ku kv it kx b ky kz kd la lb lc kg ld lr lf lg lh ls lj lk ll lt ln lo lp lq im bi translated">当我们处理时间序列时，简单的线性回归是有意义的，因为数据点被假定为独立的观察值。此外，应考虑趋势，换句话说，趋势应包含在模型中。使用sci kit-学习构建模型:</p><pre class="lv lw lx ly gt lz ma mb mc aw md bi"><span id="fd81" class="me mf it ma b gy mg mh l mi mj">one_hot_encoder = OneHotEncoder(handle_unknown="ignore", sparse=False)<br/>alphas = np.logspace(-6, 6, 25)<br/>naive_linear_pipeline = make_pipeline(<br/>    ColumnTransformer(<br/>        transformers=[<br/>            ("categorical", one_hot_encoder, categorical_columns),<br/>        ],<br/>        remainder=MinMaxScaler(),<br/>    ),<br/>    RidgeCV(alphas=alphas),<br/>)</span></pre><p id="fb69" class="pw-post-body-paragraph ku kv it kx b ky kz kd la lb lc kg ld lr lf lg lh ls lj lk ll lt ln lo lp lq im bi translated">然后我们评估这个模型:</p><pre class="lv lw lx ly gt lz ma mb mc aw md bi"><span id="60a6" class="me mf it ma b gy mg mh l mi mj">evaluate(naive_linear_pipeline, X, y, cv=ts_cv)</span></pre><figure class="lv lw lx ly gt mm gh gi paragraph-image"><div class="gh gi nw"><img src="../Images/656572afe89ed1d6de1d64ead4b9966b.png" data-original-src="https://miro.medium.com/v2/resize:fit:722/format:webp/1*ApkbEe2_tFw4_E0AaMl3Sg.png"/></div></figure><p id="17f5" class="pw-post-body-paragraph ku kv it kx b ky kz kd la lb lc kg ld lr lf lg lh ls lj lk ll lt ln lo lp lq im bi translated">结果与梯度增强非常相似，平均绝对误差在4.2%和6.6%之间。</p><p id="4024" class="pw-post-body-paragraph ku kv it kx b ky kz kd la lb lc kg ld lr lf lg lh ls lj lk ll lt ln lo lp lq im bi translated"><strong class="kx jd">时间步长分类</strong></p><p id="6fb3" class="pw-post-body-paragraph ku kv it kx b ky kz kd la lb lc kg ld lr lf lg lh ls lj lk ll lt ln lo lp lq im bi translated">时间步长作为类别用于多元统计学习中的特征选择和后续分类。这种技术适用于包含低维趋势的时间序列，因为关于潜在趋势的信息被编码在系数中，并且系数的大小作为时间距离的函数而增加。</p><p id="6d41" class="pw-post-body-paragraph ku kv it kx b ky kz kd la lb lc kg ld lr lf lg lh ls lj lk ll lt ln lo lp lq im bi translated">然而，它在具有强非线性趋势的时间序列上表现不佳，因为没有办法将其从趋势中分离出来，因为回归在趋势中被强制为零。这种技术的另一个限制是，它考虑的特征数量取决于用于回归的时间步数。</p><p id="9d72" class="pw-post-body-paragraph ku kv it kx b ky kz kd la lb lc kg ld lr lf lg lh ls lj lk ll lt ln lo lp lq im bi translated">如果时间序列的持续时间比趋势的持续时间长，这种方法就很有效。在我们的数据集中，我们没有一个明确的趋势，所以这种技术应该会产生相当好的结果。用下面的代码来做:</p><pre class="lv lw lx ly gt lz ma mb mc aw md bi"><span id="7d2f" class="me mf it ma b gy mg mh l mi mj">one_hot_linear_pipeline = make_pipeline(<br/>    ColumnTransformer(<br/>        transformers=[<br/>            ("categorical", one_hot_encoder, categorical_columns),<br/>            ("one_hot_time", one_hot_encoder, ["month_of_absence", "day_of_the_week"]),<br/>        ],<br/>        remainder=MinMaxScaler(),<br/>    ),<br/>    RidgeCV(alphas=alphas),<br/>)</span></pre><p id="1aee" class="pw-post-body-paragraph ku kv it kx b ky kz kd la lb lc kg ld lr lf lg lh ls lj lk ll lt ln lo lp lq im bi translated">和评价:</p><pre class="lv lw lx ly gt lz ma mb mc aw md bi"><span id="86e1" class="me mf it ma b gy mg mh l mi mj">evaluate(one_hot_linear_pipeline, X, y, cv=ts_cv)</span></pre><figure class="lv lw lx ly gt mm gh gi paragraph-image"><div class="gh gi nx"><img src="../Images/005f18e406fd1c34d55a5f1350437e2c.png" data-original-src="https://miro.medium.com/v2/resize:fit:708/format:webp/1*iyy_-VYF-AYhzqSSFpxapQ.png"/></div></figure><p id="549a" class="pw-post-body-paragraph ku kv it kx b ky kz kd la lb lc kg ld lr lf lg lh ls lj lk ll lt ln lo lp lq im bi translated">平均绝对误差在4.4%和6.8%之间变化。</p><p id="82e2" class="pw-post-body-paragraph ku kv it kx b ky kz kd la lb lc kg ld lr lf lg lh ls lj lk ll lt ln lo lp lq im bi translated"><strong class="kx jd">三角函数特征</strong></p><p id="3354" class="pw-post-body-paragraph ku kv it kx b ky kz kd la lb lc kg ld lr lf lg lh ls lj lk ll lt ln lo lp lq im bi translated">三角特征是由时域中的一组正弦(sin)和余弦(cos)波形组成的序列。如果我们表示sin和cos函数，我们将得到以下结果:</p><figure class="lv lw lx ly gt mm gh gi paragraph-image"><div class="gh gi ny"><img src="../Images/ae58fc5989490a99e9559ff3b1276a4f.png" data-original-src="https://miro.medium.com/v2/resize:fit:774/format:webp/1*dOrjcz2QLF8vCpsLBfX4Lw.png"/></div><figcaption class="nz oa gj gh gi ob oc bd b be z dk translated">y = sin(x)</figcaption></figure><figure class="lv lw lx ly gt mm gh gi paragraph-image"><div class="gh gi od"><img src="../Images/5705ca00b12bbafbb3dd2f72b8c9eb8d.png" data-original-src="https://miro.medium.com/v2/resize:fit:782/format:webp/1*Fp3Wpp5N0nNjmzVXW5417A.png"/></div><figcaption class="nz oa gj gh gi ob oc bd b be z dk translated">y = cos(x)</figcaption></figure><p id="bcc7" class="pw-post-body-paragraph ku kv it kx b ky kz kd la lb lc kg ld lr lf lg lh ls lj lk ll lt ln lo lp lq im bi translated">如果我们观察一年中(或几个月中)缺席的小时数，我们可以看到a线像正弦或余弦函数一样上下波动。所以可以尝试用三角特征建模。我们开始定义<em class="kw"> sin </em>和<em class="kw"> cos </em>的变压器函数:</p><pre class="lv lw lx ly gt lz ma mb mc aw md bi"><span id="8e3e" class="me mf it ma b gy mg mh l mi mj">def sin_transformer(period):<br/>    return FunctionTransformer(lambda x: np.sin(x / period * 2 * np.pi))</span><span id="41ab" class="me mf it ma b gy mk mh l mi mj">def cos_transformer(period):<br/>    return FunctionTransformer(lambda x: np.cos(x / period * 2 * np.pi))</span></pre><p id="5618" class="pw-post-body-paragraph ku kv it kx b ky kz kd la lb lc kg ld lr lf lg lh ls lj lk ll lt ln lo lp lq im bi translated">我们将使用变量“季节”变量来使用三角函数进行转换:</p><pre class="lv lw lx ly gt lz ma mb mc aw md bi"><span id="cd80" class="me mf it ma b gy mg mh l mi mj">seasons_df = pd.DataFrame(<br/>    np.arange(26).reshape(-1, 1),<br/>    columns=["seasons"],<br/>)</span><span id="f227" class="me mf it ma b gy mk mh l mi mj">seasons_df["seasons_sin"] = sin_transformer(4).fit_transform(seasons_df)["seasons"]</span><span id="3bd1" class="me mf it ma b gy mk mh l mi mj">seasons_df["seasons_cos"] = cos_transformer(4).fit_transform(seasons_df)["seasons"]</span><span id="9ed5" class="me mf it ma b gy mk mh l mi mj">seasons_df.plot(x="seasons")_ = plt.title("Trigonometric encoding for the 'seasons' feature")</span></pre><p id="032a" class="pw-post-body-paragraph ku kv it kx b ky kz kd la lb lc kg ld lr lf lg lh ls lj lk ll lt ln lo lp lq im bi translated">注意我们用<em class="kw">sin _ transformer(</em><strong class="kx jd"><em class="kw">4</em></strong><em class="kw">)</em>和<em class="kw">cos _ transformer(</em><strong class="kx jd"><em class="kw">4</em></strong><em class="kw">)</em>因为我们有四季。</p><figure class="lv lw lx ly gt mm gh gi paragraph-image"><div class="gh gi oe"><img src="../Images/8fd5a85704db6f3a1122ba26984b2020.png" data-original-src="https://miro.medium.com/v2/resize:fit:772/format:webp/1*DU5zGSnVVBoer_brBYclkQ.png"/></div></figure><p id="8f4b" class="pw-post-body-paragraph ku kv it kx b ky kz kd la lb lc kg ld lr lf lg lh ls lj lk ll lt ln lo lp lq im bi translated">可视化所应用的转换的另一个选项是:</p><pre class="lv lw lx ly gt lz ma mb mc aw md bi"><span id="1596" class="me mf it ma b gy mg mh l mi mj">fig, ax = plt.subplots(figsize=(7, 5))</span><span id="a34a" class="me mf it ma b gy mk mh l mi mj">sp = ax.scatter(hour_df["seasons_sin"], seasons_df["seasons_cos"], c=seasons_df["seasons"])</span><span id="0e7a" class="me mf it ma b gy mk mh l mi mj">ax.set(<br/>      xlabel="sin(seasons)",<br/>     ylabel="cos(seasons)",<br/>)<br/>_ = fig.colorbar(sp)</span></pre><figure class="lv lw lx ly gt mm gh gi paragraph-image"><div class="gh gi of"><img src="../Images/403dd049dfe9b9d6d16ac9eef563d674.png" data-original-src="https://miro.medium.com/v2/resize:fit:862/format:webp/1*qte6EsfPBpo7v3PtUrbqMw.png"/></div></figure><p id="885e" class="pw-post-body-paragraph ku kv it kx b ky kz kd la lb lc kg ld lr lf lg lh ls lj lk ll lt ln lo lp lq im bi translated">现在我们可以建立模型了:</p><pre class="lv lw lx ly gt lz ma mb mc aw md bi"><span id="42bb" class="me mf it ma b gy mg mh l mi mj">cyclic_cossin_transformer = ColumnTransformer(<br/>    transformers=[<br/>        ("categorical", one_hot_encoder, categorical_columns),<br/>        ("seasons_sin", sin_transformer(4), ["seasons"]),<br/>        ("seasons_cos", cos_transformer(4), ["seasons"]),<br/>    ],<br/>    remainder=MinMaxScaler(),<br/>)</span><span id="2691" class="me mf it ma b gy mk mh l mi mj">cyclic_cossin_linear_pipeline = make_pipeline(<br/>    cyclic_cossin_transformer,<br/>    RidgeCV(alphas=alphas),<br/>)</span></pre><p id="09d5" class="pw-post-body-paragraph ku kv it kx b ky kz kd la lb lc kg ld lr lf lg lh ls lj lk ll lt ln lo lp lq im bi translated">并评估:</p><pre class="lv lw lx ly gt lz ma mb mc aw md bi"><span id="3b18" class="me mf it ma b gy mg mh l mi mj">evaluate(cyclic_cossin_linear_pipeline, X, y, cv=ts_cv)</span></pre><figure class="lv lw lx ly gt mm gh gi paragraph-image"><div class="gh gi og"><img src="../Images/7da1ae881600b1e245e616d37c2c5a7f.png" data-original-src="https://miro.medium.com/v2/resize:fit:716/format:webp/1*1f-MKFQA8NvStjpjeLktbQ.png"/></div></figure><p id="b713" class="pw-post-body-paragraph ku kv it kx b ky kz kd la lb lc kg ld lr lf lg lh ls lj lk ll lt ln lo lp lq im bi translated">该模型与之前的模型表现相似，平均误差在4%到6.6%之间。</p><p id="0551" class="pw-post-body-paragraph ku kv it kx b ky kz kd la lb lc kg ld lr lf lg lh ls lj lk ll lt ln lo lp lq im bi translated"><strong class="kx jd">周期性花键特征</strong></p><p id="62f2" class="pw-post-body-paragraph ku kv it kx b ky kz kd la lb lc kg ld lr lf lg lh ls lj lk ll lt ln lo lp lq im bi translated">样条函数是通过连接多项式函数构建的。几个多项式函数连接在一起的点叫做纽结。使用样条函数而不是简单的多项式函数允许我们保持多项式的低阶。当我们有一个非常动态的数据集用于建模时，使用这些类型的函数，我们使用一个结来建模一个区域，当数据在方向上有重大变化时，函数将假设下一个结。</p><p id="8007" class="pw-post-body-paragraph ku kv it kx b ky kz kd la lb lc kg ld lr lf lg lh ls lj lk ll lt ln lo lp lq im bi translated">我们将从定义样条函数开始:</p><pre class="lv lw lx ly gt lz ma mb mc aw md bi"><span id="d50f" class="me mf it ma b gy mg mh l mi mj">def periodic_spline_transformer(period, n_splines=None, degree=3):<br/>    if n_splines is None:<br/>        n_splines = period<br/>    n_knots = n_splines + 1  <br/>    return SplineTransformer(<br/>        degree=degree,<br/>        n_knots=n_knots,<br/>        knots=np.linspace(0, period, n_knots).reshape(n_knots, 1),<br/>        extrapolation="periodic",<br/>        include_bias=True,<br/>    )</span></pre><p id="959d" class="pw-post-body-paragraph ku kv it kx b ky kz kd la lb lc kg ld lr lf lg lh ls lj lk ll lt ln lo lp lq im bi translated">同样，我们将使用“季节”变量:</p><pre class="lv lw lx ly gt lz ma mb mc aw md bi"><span id="7cc2" class="me mf it ma b gy mg mh l mi mj">seasons_df = pd.DataFrame(<br/>    np.linspace(0, 26, 1000).reshape(-1, 1),<br/>    columns=["seasons"],<br/>)</span><span id="7365" class="me mf it ma b gy mk mh l mi mj">splines = periodic_spline_transformer(4, n_splines=4).fit_transform(seasons_df)</span><span id="2a86" class="me mf it ma b gy mk mh l mi mj">splines_df = pd.DataFrame(<br/>    splines,<br/>    columns=[f"spline_{i}" for i in range(splines.shape[1])],<br/>)</span><span id="8b56" class="me mf it ma b gy mk mh l mi mj">pd.concat([seasons_df, splines_df], axis="columns").plot(x="seasons", cmap=plt.cm.tab20b)</span><span id="9747" class="me mf it ma b gy mk mh l mi mj">_ = plt.title("Periodic spline-based encoding for the 'seasons' feature")</span></pre><figure class="lv lw lx ly gt mm gh gi paragraph-image"><div class="gh gi oh"><img src="../Images/7b670fd569a72c3b386e142e7c4bc67e.png" data-original-src="https://miro.medium.com/v2/resize:fit:746/format:webp/1*WIVm8SZb8ssAUevC98riJg.png"/></div></figure><p id="e8e7" class="pw-post-body-paragraph ku kv it kx b ky kz kd la lb lc kg ld lr lf lg lh ls lj lk ll lt ln lo lp lq im bi translated">最后建立模型:</p><pre class="lv lw lx ly gt lz ma mb mc aw md bi"><span id="e5aa" class="me mf it ma b gy mg mh l mi mj">cyclic_spline_transformer = ColumnTransformer(<br/>    transformers=[<br/>        ("categorical", one_hot_encoder, categorical_columns),<br/>        ("cyclic_seasons", periodic_spline_transformer(4, n_splines=4), ["seasons"]),<br/>    ],<br/>    remainder=MinMaxScaler(),<br/>)</span><span id="66fc" class="me mf it ma b gy mk mh l mi mj">cyclic_spline_linear_pipeline = make_pipeline(<br/>    cyclic_spline_transformer,<br/>    RidgeCV(alphas=alphas),<br/>)</span></pre><p id="9a9a" class="pw-post-body-paragraph ku kv it kx b ky kz kd la lb lc kg ld lr lf lg lh ls lj lk ll lt ln lo lp lq im bi translated">并评估模型:</p><pre class="lv lw lx ly gt lz ma mb mc aw md bi"><span id="f8ee" class="me mf it ma b gy mg mh l mi mj">evaluate(cyclic_spline_linear_pipeline, X, y, cv=ts_cv)</span></pre><figure class="lv lw lx ly gt mm gh gi paragraph-image"><div class="gh gi oi"><img src="../Images/37452e9ff7a057fc3375b06809d28fa9.png" data-original-src="https://miro.medium.com/v2/resize:fit:704/format:webp/1*prR4G8pSHe_Trnz44Uoc3A.png"/></div></figure><p id="d5b2" class="pw-post-body-paragraph ku kv it kx b ky kz kd la lb lc kg ld lr lf lg lh ls lj lk ll lt ln lo lp lq im bi translated">同样，我们的平均误差是0.052 +/- 0.012。</p><p id="da01" class="pw-post-body-paragraph ku kv it kx b ky kz kd la lb lc kg ld lr lf lg lh ls lj lk ll lt ln lo lp lq im bi translated"><strong class="kx jd">定性分析特征对线性模型预测的影响</strong></p><p id="17c6" class="pw-post-body-paragraph ku kv it kx b ky kz kd la lb lc kg ld lr lf lg lh ls lj lk ll lt ln lo lp lq im bi translated">现在我们已经建立了五个模型，是时候分析它们了。我们将测试我们创建的所有5个分割，并获得一个直观检查的图表。</p><pre class="lv lw lx ly gt lz ma mb mc aw md bi"><span id="ceb8" class="me mf it ma b gy mg mh l mi mj">#Create teh predicted values:<br/>naive_linear_pipeline.fit(X.iloc[train_0], y.iloc[train_0])<br/>naive_linear_predictions = naive_linear_pipeline.predict(X.iloc[test_0])</span><span id="9b78" class="me mf it ma b gy mk mh l mi mj">one_hot_linear_pipeline.fit(X.iloc[train_0], y.iloc[train_0])<br/>one_hot_linear_predictions = one_hot_linear_pipeline.predict(X.iloc[test_0])</span><span id="f2fe" class="me mf it ma b gy mk mh l mi mj">cyclic_cossin_linear_pipeline.fit(X.iloc[train_0], y.iloc[train_0])<br/>cyclic_cossin_linear_predictions = cyclic_cossin_linear_pipeline.predict(X.iloc[test_0])</span><span id="bafc" class="me mf it ma b gy mk mh l mi mj">cyclic_spline_linear_pipeline.fit(X.iloc[train_0], y.iloc[train_0])<br/>cyclic_spline_linear_predictions = cyclic_spline_linear_pipeline.predict(X.iloc[test_0])</span><span id="1221" class="me mf it ma b gy mk mh l mi mj">#Change "_0" with"_1", "_2", "_3" and "_4" for remaining splits</span><span id="9d79" class="me mf it ma b gy mk mh l mi mj">#Build the graph:</span><span id="8240" class="me mf it ma b gy mk mh l mi mj">last_days = slice(-100, None)<br/>fig, ax = plt.subplots(figsize=(12, 4))<br/>fig.suptitle("Predictions by linear models")<br/>ax.plot(<br/>    y.iloc[test_0].values[last_days], #Change "_0" with 1,2,3 and 4<br/>    "x-",<br/>    alpha=0.2,<br/>    label="Actual absenteeism in hours ",<br/>    color="black",<br/>)<br/>ax.plot(<br/>    naive_linear_predictions[last_days], <br/>    "x-", <br/>    label="Ordinal time features"<br/>)<br/>ax.plot(<br/>    cyclic_cossin_linear_predictions[last_days],<br/>    "x-",<br/>    label="Trigonometric time features",<br/>)<br/>ax.plot(<br/>    cyclic_spline_linear_predictions[last_days],<br/>    "x-",<br/>    label="Spline-based time features",<br/>)<br/>ax.plot(<br/>    one_hot_linear_predictions[last_days],<br/>    "x-",<br/>    label="One-hot time features",<br/>)<br/>_ = ax.legend()</span></pre><figure class="lv lw lx ly gt mm gh gi paragraph-image"><div role="button" tabindex="0" class="mn mo di mp bf mq"><div class="gh gi oj"><img src="../Images/fbbbb27d3ba5d2c1e8a1fe8cfd3540f6.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*SmVEokvIOx8AEuLlOv58Bw.png"/></div></div><figcaption class="nz oa gj gh gi ob oc bd b be z dk translated">拆分0</figcaption></figure><figure class="lv lw lx ly gt mm gh gi paragraph-image"><div role="button" tabindex="0" class="mn mo di mp bf mq"><div class="gh gi oj"><img src="../Images/bf689969bbc50bc6601bb36cd17918cf.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*QdKuXTmmYPQJKKS6_lbnZg.png"/></div></div><figcaption class="nz oa gj gh gi ob oc bd b be z dk translated">拆分1</figcaption></figure><figure class="lv lw lx ly gt mm gh gi paragraph-image"><div role="button" tabindex="0" class="mn mo di mp bf mq"><div class="gh gi oj"><img src="../Images/528528e1a29c1e96057fbd1bdf75f0c8.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*AsacE4vguUxA7WuGG3A1KQ.png"/></div></div><figcaption class="nz oa gj gh gi ob oc bd b be z dk translated">拆分2</figcaption></figure><figure class="lv lw lx ly gt mm gh gi paragraph-image"><div role="button" tabindex="0" class="mn mo di mp bf mq"><div class="gh gi ok"><img src="../Images/89c832724e2c56382ec27650f9777076.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*A8N6D55XNOciMsqUMVn-ug.png"/></div></div><figcaption class="nz oa gj gh gi ob oc bd b be z dk translated">分割3</figcaption></figure><figure class="lv lw lx ly gt mm gh gi paragraph-image"><div role="button" tabindex="0" class="mn mo di mp bf mq"><div class="gh gi oj"><img src="../Images/1c2f1ece87a4844eb95cd7596dbd74c2.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*xABhaILug22MMFMAyKW4Dw.png"/></div></div><figcaption class="nz oa gj gh gi ob oc bd b be z dk translated">拆分4</figcaption></figure><p id="804f" class="pw-post-body-paragraph ku kv it kx b ky kz kd la lb lc kg ld lr lf lg lh ls lj lk ll lt ln lo lp lq im bi translated">要获得每个模型中使用的特征数量:</p><pre class="lv lw lx ly gt lz ma mb mc aw md bi"><span id="dedf" class="me mf it ma b gy mg mh l mi mj">naive_linear_pipeline[:-1].transform(X).shape<br/>[OUT] (740, 35)</span><span id="34cf" class="me mf it ma b gy mk mh l mi mj">one_hot_linear_pipeline[:-1].transform(X).shape<br/>[OUT] (740, 52)</span><span id="306a" class="me mf it ma b gy mk mh l mi mj">cyclic_cossin_linear_pipeline[:-1].transform(X).shape<br/>[OUT] (740, 36)</span><span id="162e" class="me mf it ma b gy mk mh l mi mj">cyclic_spline_linear_pipeline[:-1].transform(X).shape<br/>[OUT] (740, 38)</span></pre><p id="63f6" class="pw-post-body-paragraph ku kv it kx b ky kz kd la lb lc kg ld lr lf lg lh ls lj lk ll lt ln lo lp lq im bi translated">我们也可以用预测值和真实值之间的散点图来评估我们的模型。但是，这可能不是我们数据的最佳选择:</p><pre class="lv lw lx ly gt lz ma mb mc aw md bi"><span id="f2fb" class="me mf it ma b gy mg mh l mi mj">fig, axes = plt.subplots(ncols=3, figsize=(12, 4), sharey=True)<br/>fig.suptitle("Non-linear regression models")<br/>predictions = [<br/>    cyclic_cossin_linear_predictions,<br/>    cyclic_spline_linear_predictions,<br/>    one_hot_linear_predictions,<br/>]<br/>labels = [<br/>    "cyclic_cossin_linear_predictions",<br/>    "Splines + polynomial kernel",<br/>    "Gradient Boosted Trees",<br/>]<br/>for ax, pred, label in zip(axes, predictions, labels):<br/>    ax.scatter(y.iloc[test_0].values, pred, alpha=0.3, label=label)<br/>    ax.plot([0, 0.125], [0, 0.125], "--", label="Perfect model")<br/>    ax.set(<br/>           xlim=(0, 0.125),<br/>           ylim=(0, 0.125),<br/>           xlabel="True absenteeism",<br/>           ylabel="Predicted absenteeism",<br/>    )<br/>    ax.legend()</span><span id="31f0" class="me mf it ma b gy mk mh l mi mj">#Change "test_0" with _1, _2, _3 or _4 to obtain graphical visualisations for the other splits.</span></pre><figure class="lv lw lx ly gt mm gh gi paragraph-image"><div role="button" tabindex="0" class="mn mo di mp bf mq"><div class="gh gi ol"><img src="../Images/ae4e3a4bf077cefb797f07ca1f11c04a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*ze_Co-jizKN3IvClhkrDPw.png"/></div></div><figcaption class="nz oa gj gh gi ob oc bd b be z dk translated">拆分0</figcaption></figure><figure class="lv lw lx ly gt mm gh gi paragraph-image"><div role="button" tabindex="0" class="mn mo di mp bf mq"><div class="gh gi ol"><img src="../Images/188504b397536946958f98b8e22ca22c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*hhD2ylrqSmnwW3lixodmDA.png"/></div></div><figcaption class="nz oa gj gh gi ob oc bd b be z dk translated">拆分1</figcaption></figure><figure class="lv lw lx ly gt mm gh gi paragraph-image"><div role="button" tabindex="0" class="mn mo di mp bf mq"><div class="gh gi ol"><img src="../Images/09506a652088720a01f5eabd3da7f0a4.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*RHSZGgTrYa2qXDu_ZSHADg.png"/></div></div><figcaption class="nz oa gj gh gi ob oc bd b be z dk translated">拆分2</figcaption></figure><figure class="lv lw lx ly gt mm gh gi paragraph-image"><div role="button" tabindex="0" class="mn mo di mp bf mq"><div class="gh gi ol"><img src="../Images/f4a7db282fd020fe33c8f371d6c1062f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*4yF5Jiv7Z0i68B-f1HFRLA.png"/></div></div><figcaption class="nz oa gj gh gi ob oc bd b be z dk translated">分割3</figcaption></figure><figure class="lv lw lx ly gt mm gh gi paragraph-image"><div role="button" tabindex="0" class="mn mo di mp bf mq"><div class="gh gi ol"><img src="../Images/c739a1b538979535bb62e2897967fa5f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*SD3ph2tIVTCwk4TImhyN8Q.png"/></div></div><figcaption class="nz oa gj gh gi ob oc bd b be z dk translated">拆分4</figcaption></figure><p id="820e" class="pw-post-body-paragraph ku kv it kx b ky kz kd la lb lc kg ld lr lf lg lh ls lj lk ll lt ln lo lp lq im bi translated"><strong class="kx jd">用样条和多项式特征模拟成对交互</strong></p><p id="ae16" class="pw-post-body-paragraph ku kv it kx b ky kz kd la lb lc kg ld lr lf lg lh ls lj lk ll lt ln lo lp lq im bi translated">我知道这是一项长期的工作，但是，如果我们对获得的结果不满意，我们可以尝试改进它的交互模型。在这个例子中，我将尝试季节和学科失败之间的相互作用，但是您可以尝试与您的数据进行多种相互作用，并检查哪个表现更好。</p><pre class="lv lw lx ly gt lz ma mb mc aw md bi"><span id="0ae7" class="me mf it ma b gy mg mh l mi mj">#Creating the interaction:</span><span id="9440" class="me mf it ma b gy mk mh l mi mj">seasons_month_interaction = make_pipeline(<br/>    ColumnTransformer(<br/>      [<br/>          ("cyclic_seasons", periodic_spline_transformer(4, n_splines=4), ["seasons"]),<br/>          ("disciplinary_failure", FunctionTransformer(), ["disciplinary_failure"]),<br/>      ]<br/>    ),<br/>    PolynomialFeatures(degree=2, interaction_only=False, include_bias=False),<br/>)</span></pre><p id="8497" class="pw-post-body-paragraph ku kv it kx b ky kz kd la lb lc kg ld lr lf lg lh ls lj lk ll lt ln lo lp lq im bi translated">建立这个模型:</p><pre class="lv lw lx ly gt lz ma mb mc aw md bi"><span id="9df4" class="me mf it ma b gy mg mh l mi mj">cyclic_spline_interactions_pipeline = make_pipeline(<br/>    FeatureUnion(<br/>       [<br/>          ("marginal", cyclic_spline_transformer),<br/>          ("interactions", seasons_month_interaction),<br/>       ]<br/>    ),<br/>    RidgeCV(alphas=alphas),<br/>)</span></pre><p id="3f3a" class="pw-post-body-paragraph ku kv it kx b ky kz kd la lb lc kg ld lr lf lg lh ls lj lk ll lt ln lo lp lq im bi translated">并评估模型:</p><pre class="lv lw lx ly gt lz ma mb mc aw md bi"><span id="7264" class="me mf it ma b gy mg mh l mi mj">evaluate(cyclic_spline_interactions_pipeline, X, y, cv=ts_cv)</span></pre><figure class="lv lw lx ly gt mm gh gi paragraph-image"><div class="gh gi nw"><img src="../Images/52bb80ac4121c9a265a5aeceb28f3410.png" data-original-src="https://miro.medium.com/v2/resize:fit:722/format:webp/1*9AeoK8FbRqECYYsQ9XfyRw.png"/></div></figure><p id="e78b" class="pw-post-body-paragraph ku kv it kx b ky kz kd la lb lc kg ld lr lf lg lh ls lj lk ll lt ln lo lp lq im bi translated">正如我们所看到的，在这种情况下，该模型并不比以前的模型更好。</p><p id="942a" class="pw-post-body-paragraph ku kv it kx b ky kz kd la lb lc kg ld lr lf lg lh ls lj lk ll lt ln lo lp lq im bi translated"><strong class="kx jd">用内核模拟非线性特征交互</strong></p><p id="2526" class="pw-post-body-paragraph ku kv it kx b ky kz kd la lb lc kg ld lr lf lg lh ls lj lk ll lt ln lo lp lq im bi translated">另一种选择是使用内核。核是一种将非线性函数转换成线性形式的方法，这样就可以在不丢失数据的情况下进行计算。核可以以两种不同的方式使用:一种是寻找数据的对齐方式，使序列之间的比较成为可能；另一种是通过构建数据的更高级表示来改变数据的结构，并使用这种新的表示来执行比较。</p><p id="c341" class="pw-post-body-paragraph ku kv it kx b ky kz kd la lb lc kg ld lr lf lg lh ls lj lk ll lt ln lo lp lq im bi translated">第一个选项:</p><pre class="lv lw lx ly gt lz ma mb mc aw md bi"><span id="72db" class="me mf it ma b gy mg mh l mi mj">cyclic_spline_poly_pipeline = make_pipeline(<br/>    cyclic_spline_transformer,<br/>    Nystroem(kernel="poly", degree=2, n_components=300, random_state=0),<br/>    RidgeCV(alphas=alphas),<br/>)</span><span id="c65d" class="me mf it ma b gy mk mh l mi mj">evaluate(cyclic_spline_poly_pipeline, X, y, cv=ts_cv)</span></pre><figure class="lv lw lx ly gt mm gh gi paragraph-image"><div class="gh gi om"><img src="../Images/daeaf4cde6448aee3a941c35cdd005f2.png" data-original-src="https://miro.medium.com/v2/resize:fit:702/format:webp/1*dTyfB83H4i7bYs2VwwPvCQ.png"/></div></figure><p id="baa0" class="pw-post-body-paragraph ku kv it kx b ky kz kd la lb lc kg ld lr lf lg lh ls lj lk ll lt ln lo lp lq im bi translated">第二个选择是:</p><pre class="lv lw lx ly gt lz ma mb mc aw md bi"><span id="8e9c" class="me mf it ma b gy mg mh l mi mj">one_hot_poly_pipeline = make_pipeline(<br/>    ColumnTransformer(<br/>        transformers=[<br/>            ("categorical", one_hot_encoder, categorical_columns),         <br/>            ("one_hot_time", one_hot_encoder, ["month_of_absence", "day_of_the_week"]),<br/>        ],<br/>        remainder="passthrough",<br/>    ),<br/>    Nystroem(kernel="poly", degree=2, n_components=300, random_state=0),<br/>    RidgeCV(alphas=alphas),<br/>)</span><span id="2557" class="me mf it ma b gy mk mh l mi mj">evaluate(one_hot_poly_pipeline, X, y, cv=ts_cv)</span></pre><figure class="lv lw lx ly gt mm gh gi paragraph-image"><div class="gh gi on"><img src="../Images/69cac4a9b871d887944c3be7a9e2ac18.png" data-original-src="https://miro.medium.com/v2/resize:fit:696/format:webp/1*FPO4_M7q5dD4-w9wHg81VQ.png"/></div></figure><p id="78f2" class="pw-post-body-paragraph ku kv it kx b ky kz kd la lb lc kg ld lr lf lg lh ls lj lk ll lt ln lo lp lq im bi translated">正如我们所看到的，这些模型似乎都没有比前一个模型表现得更好。我们仍然可以想象它们:</p><pre class="lv lw lx ly gt lz ma mb mc aw md bi"><span id="2406" class="me mf it ma b gy mg mh l mi mj">#This code is for split_0, use the same code for other splits:<br/>#Obtaining the predicted values:</span><span id="1910" class="me mf it ma b gy mk mh l mi mj">gbrt_pipeline.fit(X.iloc[train_0], y.iloc[train_0])<br/>gbrt_predictions = gbrt_pipeline.predict(X.iloc[test_0])</span><span id="b402" class="me mf it ma b gy mk mh l mi mj">one_hot_poly_pipeline.fit(X.iloc[train_0], y.iloc[train_0])<br/>one_hot_poly_predictions = one_hot_poly_pipeline.predict(X.iloc[test_0])</span><span id="a406" class="me mf it ma b gy mk mh l mi mj">cyclic_spline_poly_pipeline.fit(X.iloc[train_0], y.iloc[train_0])<br/>cyclic_spline_poly_predictions = cyclic_spline_poly_pipeline.predict(X.iloc[test_0])</span><span id="04c3" class="me mf it ma b gy mk mh l mi mj">#Building the graphical visualisation:</span><span id="43b7" class="me mf it ma b gy mk mh l mi mj">last_hours = slice(-100, None)<br/>fig, ax = plt.subplots(figsize=(12, 4))<br/>fig.suptitle("Predictions by non-linear regression models")<br/>ax.plot(<br/>    y.iloc[test_0].values[last_hours],<br/>    "x-",<br/>    alpha=0.2,<br/>    label="Actual absenteeism in hours",<br/>    color="black",<br/>)<br/>ax.plot(<br/>    gbrt_predictions[last_hours],<br/>    "x-",<br/>    label="Gradient Boosted Trees",<br/>)<br/>ax.plot(<br/>    one_hot_poly_predictions[last_hours],<br/>    "x-",<br/>    label="One-hot + polynomial kernel",<br/>)<br/>ax.plot(<br/>    cyclic_spline_poly_predictions[last_hours],<br/>    "x-",<br/>    label="Splines + polynomial kernel",<br/>)<br/>_ = ax.legend()</span></pre><figure class="lv lw lx ly gt mm gh gi paragraph-image"><div role="button" tabindex="0" class="mn mo di mp bf mq"><div class="gh gi oj"><img src="../Images/42d166a18184f40b799187441efd6394.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*TtWVO82BBHy7w7_wuvQmOA.png"/></div></div><figcaption class="nz oa gj gh gi ob oc bd b be z dk translated">拆分0</figcaption></figure><figure class="lv lw lx ly gt mm gh gi paragraph-image"><div role="button" tabindex="0" class="mn mo di mp bf mq"><div class="gh gi oj"><img src="../Images/e023612038dc67674115aa2cb1aacebe.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*tPTLVhnHOIKIBGk2IMFBTw.png"/></div></div><figcaption class="nz oa gj gh gi ob oc bd b be z dk translated">拆分1</figcaption></figure><figure class="lv lw lx ly gt mm gh gi paragraph-image"><div role="button" tabindex="0" class="mn mo di mp bf mq"><div class="gh gi oj"><img src="../Images/229edbb5b1b1f1cea08ff6e364762ec6.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*iuV-dD9oEb0ynJ9iBzeuOw.png"/></div></div><figcaption class="nz oa gj gh gi ob oc bd b be z dk translated">拆分2</figcaption></figure><figure class="lv lw lx ly gt mm gh gi paragraph-image"><div role="button" tabindex="0" class="mn mo di mp bf mq"><div class="gh gi oo"><img src="../Images/8cc86d3e1473b6fe1874467cea7f454b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*s1zHlviYbUyPUOGWE6kHLQ.png"/></div></div><figcaption class="nz oa gj gh gi ob oc bd b be z dk translated">分割3</figcaption></figure><figure class="lv lw lx ly gt mm gh gi paragraph-image"><div role="button" tabindex="0" class="mn mo di mp bf mq"><div class="gh gi oj"><img src="../Images/b6222d7fa43a5bbadb018650bb4e0931.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*n96X8bzvgPtf7-V4UnWO4A.png"/></div></div><figcaption class="nz oa gj gh gi ob oc bd b be z dk translated">拆分4</figcaption></figure><p id="cb19" class="pw-post-body-paragraph ku kv it kx b ky kz kd la lb lc kg ld lr lf lg lh ls lj lk ll lt ln lo lp lq im bi translated"><strong class="kx jd">结论</strong></p><p id="1a31" class="pw-post-body-paragraph ku kv it kx b ky kz kd la lb lc kg ld lr lf lg lh ls lj lk ll lt ln lo lp lq im bi translated">如果你还在读到这一点，恭喜你！这是一个漫长的旅程，但我相信现在您已经准备好将这些技术应用到您自己的数据中，构建您的模型并做出您的预测，这肯定会对您的业务有所帮助。</p><p id="71d9" class="pw-post-body-paragraph ku kv it kx b ky kz kd la lb lc kg ld lr lf lg lh ls lj lk ll lt ln lo lp lq im bi translated">如有反馈、修正或改进建议，请联系我或留下评论。谢谢你。</p><p id="bae3" class="pw-post-body-paragraph ku kv it kx b ky kz kd la lb lc kg ld lr lf lg lh ls lj lk ll lt ln lo lp lq im bi translated"><strong class="kx jd">如果:</strong>你喜欢这篇文章，别忘了关注我，这样你就能收到关于新出版物的所有更新。</p><p id="effe" class="pw-post-body-paragraph ku kv it kx b ky kz kd la lb lc kg ld lr lf lg lh ls lj lk ll lt ln lo lp lq im bi translated"><strong class="kx jd">否则如果:</strong>你想了解更多，你可以通过<a class="ae lu" href="https://cdanielaam.medium.com/membership" rel="noopener">我的推荐链接</a>订阅媒体会员。它不会花你更多的钱，但会给我一杯咖啡。</p><p id="6cfd" class="pw-post-body-paragraph ku kv it kx b ky kz kd la lb lc kg ld lr lf lg lh ls lj lk ll lt ln lo lp lq im bi translated"><strong class="kx jd">别的:</strong>坦克你！</p></div></div>    
</body>
</html>