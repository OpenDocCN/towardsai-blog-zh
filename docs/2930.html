<html>
<head>
<title>12 Speech Recognition Models in 2022; One of These Has 20k Stars on Github</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">2022年12款语音识别模型；其中一个在Github上有2万颗星星</h1>
<blockquote>原文：<a href="https://pub.towardsai.net/12-speech-recognition-models-in-2022-one-of-these-has-20k-stars-on-github-6ed989b24cb5?source=collection_archive---------0-----------------------#2022-07-12">https://pub.towardsai.net/12-speech-recognition-models-in-2022-one-of-these-has-20k-stars-on-github-6ed989b24cb5?source=collection_archive---------0-----------------------#2022-07-12</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="3841" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">了解12种更重要的语音识别引擎和API</h2></div><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ki"><img src="../Images/4ab9e3d574989669bb5344c1dc6ae744.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*bUGvAiefNTFX7_giw8A6ig.jpeg"/></div></div><figcaption class="ku kv gj gh gi kw kx bd b be z dk translated">Pexels的Matthew Hintz </figcaption></figure><p id="0603" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">在自然语言处理中，语音识别[11]是将口语单词转换成文本的过程。它也被称为自动语音识别或ASR。</p><h1 id="f4aa" class="lv lw it bd lx ly lz ma mb mc md me mf jz mg ka mh kc mi kd mj kf mk kg ml mm bi translated"><strong class="ak">语音识别的3个高级描述:</strong></h1><p id="5e8c" class="pw-post-body-paragraph kz la it lb b lc mn ju le lf mo jx lh li mp lk ll lm mq lo lp lq mr ls lt lu im bi translated">1.语音识别是将口语单词转换成文本的过程。</p><p id="3f06" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">2.语音识别系统使用声学和语言模型来识别口语单词。声学模型基于口语单词的声音，而语言模型基于语言的语法和结构。</p><p id="3f78" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">3.语音识别系统可用于听写和转录，也可用于命令和控制。</p><h1 id="5814" class="lv lw it bd lx ly lz ma mb mc md me mf jz mg ka mh kc mi kd mj kf mk kg ml mm bi translated"><strong class="ak">语音识别实施流程中要采取的3个一般步骤:</strong></h1><p id="fad8" class="pw-post-body-paragraph kz la it lb b lc mn ju le lf mo jx lh li mp lk ll lm mq lo lp lq mr ls lt lu im bi translated">1.预处理:该步骤清理原始音频信号，并为特征提取做准备。</p><p id="3cb4" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">2.特征提取:该步骤从预处理的音频信号中提取独特的特征，这些特征可用于识别所说的单词。</p><p id="086e" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">3.解码:这一步使用提取的特征将语音信号转换成文本。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ms"><img src="../Images/09acdd87563d785ed8b96ac34f5a2eec.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*j_0LNk5wYTgywQm_i3epUw.jpeg"/></div></div><figcaption class="ku kv gj gh gi kw kx bd b be z dk translated">来自Pexels的Amos Getanda</figcaption></figure><h1 id="f966" class="lv lw it bd lx ly lz ma mb mc md me mf jz mg ka mh kc mi kd mj kf mk kg ml mm bi translated"><strong class="ak">使用语音识别的8个用例:</strong></h1><p id="c4d4" class="pw-post-body-paragraph kz la it lb b lc mn ju le lf mo jx lh li mp lk ll lm mq lo lp lq mr ls lt lu im bi translated">1.自动语音识别可用于将音频文件转录到文本中；这个用例可以帮助转录会议笔记、讲座或其他音频记录。</p><p id="81f6" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">2.ASR可以用来为视频生成字幕。</p><p id="1e20" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><strong class="lb iu"> 3。用于创建录音的可搜索索引，以支持在大型音频文件中查找特定信息的用例。</strong></p><p id="02ca" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">4.用于识别录音的说话者。这对取证或其他应用很有帮助。</p><p id="4724" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">5.ASR可用于从一种语言翻译到另一种语言，这种使用案例对于与录音中的人说不同语言的人很有帮助。</p><p id="3adc" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">6.它可以用来创建一个虚拟助理来支持无数的任务，如设置提醒，发送电子邮件，通过电话系统提供客户服务，或搜索网页。</p><p id="3f18" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">7.用于控制计算机或其他设备。这对残障人士或免提操作非常有用。</p><p id="0a71" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><strong class="lb iu"> 8。ASR可用于为智能设备创建声控命令或控制。</strong></p><p id="1a60" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">隐马尔可夫模型(HMM)将在这篇文章中被多次提及。简单地说，HMM是一种统计模型，用于描述一系列观察到的事件和一组隐藏状态之间的关系。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi mt"><img src="../Images/97bce70dd32c91d03074a21acd8059da.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*gVY_YgcNGfVQAG0McJLU7g.jpeg"/></div></div><figcaption class="ku kv gj gh gi kw kx bd b be z dk translated">来自Pexels的Werner Pfennig</figcaption></figure><h1 id="ac4a" class="lv lw it bd lx ly lz ma mb mc md me mf jz mg ka mh kc mi kd mj kf mk kg ml mm bi translated"><strong class="ak"> 12语音学习实现:</strong></h1><p id="e930" class="pw-post-body-paragraph kz la it lb b lc mn ju le lf mo jx lh li mp lk ll lm mq lo lp lq mr ls lt lu im bi translated">1.Python的语音识别库。它支持多种API和算法引擎，全部在线或离线实现[13]。支持的一些API/引擎包括(1) CMU斯芬克斯(离线工作)；(2)谷歌云语音API(3)wit . ai；(4)微软必应语音识别；(5) IBM语音转文本；以及(6) Snowboy热门词检测(离线工作)[13]。</p><p id="d0af" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">2.Eesen:一个端到端的语音识别工具包。Eesen是一个基于神经网络的语音识别系统(基于训练单个递归神经网络[13])，它使用深度神经网络来模拟语音的声学模式。该系统被设计成端到端的，这意味着它不需要手工制作的功能或语音知识。Eesen在一个大型语音记录数据集上接受训练，可以学习识别任何声学环境中的语音。该系统还对背景噪声具有鲁棒性，并可用于实时语音识别。</p><p id="f27a" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><strong class="lb iu"> Eesen已经被证明在准确性和速度方面优于传统的语音识别系统。</strong></p><p id="f705" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">此外，该系统是可扩展的，可以用于大规模的语音识别任务。</p><p id="3e5d" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">3.TensorFlowASR:几乎是Tensorflow 2中最先进的ASR。TensorFlowASR是用于语音识别的自然语言处理工具。</p><p id="6663" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><strong class="lb iu">基于深度学习平台TensorFlow，可用于训练和部署语音识别模型。</strong></p><p id="d9ae" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">TensorFlowASR的一些使用方法包括:</p><blockquote class="mu mv mw"><p id="8e46" class="kz la mx lb b lc ld ju le lf lg jx lh my lj lk ll mz ln lo lp na lr ls lt lu im bi translated">—在大型数据集上训练语音识别模型</p><p id="6d59" class="kz la mx lb b lc ld ju le lf lg jx lh my lj lk ll mz ln lo lp na lr ls lt lu im bi translated">—在边缘设备上部署语音识别模型</p><p id="9558" class="kz la mx lb b lc ld ju le lf lg jx lh my lj lk ll mz ln lo lp na lr ls lt lu im bi translated">—构建定制的语音识别应用程序</p><p id="d3c4" class="kz la mx lb b lc ld ju le lf lg jx lh my lj lk ll mz ln lo lp na lr ls lt lu im bi translated">—针对特定领域微调语音识别模型</p><p id="0053" class="kz la mx lb b lc ld ju le lf lg jx lh my lj lk ll mz ln lo lp na lr ls lt lu im bi translated">—可视化和调试语音识别模型</p></blockquote><p id="8f0b" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">4.Vosk:适用于Android、iOS、Raspberry Pi以及使用Python、Java、C#和Node的服务器的离线语音识别API[15]。Vosk是一个用于语音识别的开源工具包，可用于开发新的语音识别模型。Vosk可用于为各种平台(包括移动设备)构建语音识别应用程序。它目前支持20多种语言的语音识别[15]，其路线图中还计划了更多。Vosk团队表示，他们模型不仅小(50 Mb) [15]，而且提供“具有流式API、可重新配置的词汇和说话者识别的零延迟响应”[15]。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi nb"><img src="../Images/9b90e6309d58c4ef538ea0019fb01790.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*C8EQweimfqOYRka3MGe81w.jpeg"/></div></div><figcaption class="ku kv gj gh gi kw kx bd b be z dk translated">来自Pexels的乔治·米尔顿</figcaption></figure><p id="2610" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">5.<strong class="lb iu">deep speech(Github上差不多20k星)</strong>:离线、设备上的语音转文本引擎。DeepSpeech是一个开源的语音识别引擎，可以用来处理语音并将其转换为文本。<strong class="lb iu">它使用深度神经网络来解析输入语音，并将其转换为文本[16]。【DeepSpeech可用于处理语音的一些方式包括:</strong></p><blockquote class="mu mv mw"><p id="89a9" class="kz la mx lb b lc ld ju le lf lg jx lh my lj lk ll mz ln lo lp na lr ls lt lu im bi translated">—将语音转换为文本:这对于转录语音或创建音频文件的文本转录非常有用。</p><p id="1cbb" class="kz la mx lb b lc ld ju le lf lg jx lh my lj lk ll mz ln lo lp na lr ls lt lu im bi translated">—语音识别支持语音转文本、语音识别和语音搜索应用程序。</p><p id="77b7" class="kz la mx lb b lc ld ju le lf lg jx lh my lj lk ll mz ln lo lp na lr ls lt lu im bi translated">—语音搜索:DeepSpeech可用于启用语音搜索，并支持使用语音而不是打字来搜索信息的用例。</p><p id="6864" class="kz la mx lb b lc ld ju le lf lg jx lh my lj lk ll mz ln lo lp na lr ls lt lu im bi translated">—用于创建合成语音或文本到语音转换应用程序的语音合成。</p><p id="c2a6" class="kz la mx lb b lc ld ju le lf lg jx lh my lj lk ll mz ln lo lp na lr ls lt lu im bi translated">—针对语音识别和语音生物识别等应用的语音识别。</p></blockquote><p id="6e69" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">6.CMUSphinx: CMUSphinx是一个用于移动和嵌入式设备的语音识别系统，可以快速适应新的语言和领域。它体积小，计算效率高，非常适合资源受限的环境。CMUSphinx使用各种声学和语言模型来实现高精度。CMUSphinx的工作原理是首先将音频信号翻译成声谱图，然后对声谱图运行隐马尔可夫模型(HMM) [2]来识别语言单元，最后将语言单元翻译成文本。CMUSphinx使用隐马尔可夫模型(HMM)从语音信号中识别单词，而软件首先从语音信号中识别音素[3]，然后将它们与HMM中的单词进行匹配。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi nc"><img src="../Images/d7af9d456caa5e8e2fd7a45e59dc67ed.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*gCHQ7K3-jdHdqmRyqcJR4Q.jpeg"/></div></div><figcaption class="ku kv gj gh gi kw kx bd b be z dk translated">由佩克斯的<a class="ae ky" href="https://www.pexels.com/@skitterphoto/" rel="noopener ugc nofollow" target="_blank">摄影师</a>拍摄</figcaption></figure><p id="22c6" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">7.卡耐基梅隆大学的语音识别系统。这是CMUSphinx的移动路径。Github上宣布不再对其进行进一步开发。在虚拟环境中安装Python模块的说明可以在这里找到[4]。</p><p id="d3c0" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">8.KoNLPy，或“Python中的朝鲜语NLP”[5]:朝鲜语的自然语言处理Python包。</p><p id="1c7e" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><strong class="lb iu">对韩语的独家关注使KoNLPy在各种用例中独树一帜，如语料库分析、文本分析、寻找搭配[6]、分块和随机文本生成(实验以告知关于后者的其他用例)。</strong></p><p id="d686" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">9.Madmom:音频信号处理库[8]用Python编码，专门研究音乐信息检索(MIR)用例，其根源是约翰尼斯·开普勒大学(奥地利林茨)和奥地利人工智能研究所(奥地利维也纳OFAI)。</p><p id="5048" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">10.Julius:一个大词汇量连续语音识别(LVCSR)解码器软件[9]，用于语音识别的研究和开发。在算法上，它基于隐马尔可夫模型[9]，并使用维特比算法进行解码。</p><p id="8098" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">11.HTK(隐马尔可夫模型工具包)是一个软件工具包，用于构建和部署基于隐马尔可夫模型的语音识别系统。它主要用于语音识别的研究[10]。</p><p id="4b1b" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">HTK是用C编程语言编写的，可以在多种平台上运行，包括Windows、Linux和Unix。HTK使用隐马尔可夫模型(HMM)来模拟语音的声学和语言特征。</p><p id="c452" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">12.Pysptk: Python语音工具包。Pysptk是一个用于处理语音的Python库，是由CMU Sphinx团队开发的一套语音处理工具包。它是用Python编写的，可以在各种平台上工作，包括Windows、macOS和Linux。它提供了一套语音分析和合成工具，包括语音转换、重新合成、语音识别器、说话人确认系统和文本到语音合成器[12]。Pysptk还提供了一个处理声学模型的工具包，比如训练和测试。</p></div><div class="ab cl nd ne hx nf" role="separator"><span class="ng bw bk nh ni nj"/><span class="ng bw bk nh ni nj"/><span class="ng bw bk nh ni"/></div><div class="im in io ip iq"><p id="1abc" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">如果您有任何编辑/修改建议或关于进一步扩展此主题的建议，请考虑与我分享您的想法。</p><h1 id="f8db" class="lv lw it bd lx ly lz ma mb mc md me mf jz mg ka mh kc mi kd mj kf mk kg ml mm bi translated"><strong class="ak">另外，请考虑订阅我的每周简讯:</strong></h1><div class="nk nl gp gr nm nn"><a href="https://pventures.substack.com/" rel="noopener  ugc nofollow" target="_blank"><div class="no ab fo"><div class="np ab nq cl cj nr"><h2 class="bd iu gy z fp ns fr fs nt fu fw is bi translated">周日报告#1</h2><div class="nu l"><h3 class="bd b gy z fp ns fr fs nt fu fw dk translated">设计思维与AI的共生关系设计思维能向AI揭示什么，AI又能如何拥抱…</h3></div><div class="nv l"><p class="bd b dl z fp ns fr fs nt fu fw dk translated">pventures.substack.com</p></div></div><div class="nw l"><div class="nx l ny nz oa nw ob ks nn"/></div></div></a></div><p id="12b8" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><em class="mx">参考文献:</em></p><p id="7039" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><em class="mx">【1】。CMUSphinx:</em><a class="ae ky" href="https://cmusphinx.github.io/wiki/about/" rel="noopener ugc nofollow" target="_blank"><em class="mx">https://cmusphinx.github.io/wiki/about/</em></a></p><p id="b740" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><em class="mx">【2】。界面嗯。</em><a class="ae ky" href="https://cmusphinx.github.io/doc/sphinx4/javadoc/edu/cmu/sphinx/linguist/acoustic/HMM.html" rel="noopener ugc nofollow" target="_blank"><em class="mx">https://cmusphinx . github . io/doc/sphinx 4/javadoc/edu/CMU/sphinx/语言学家/acoustic/HMM.html </em> </a></p><p id="32cf" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><em class="mx">【3】。音素识别(CMUSphinx)。</em><a class="ae ky" href="https://cmusphinx.github.io/wiki/phonemerecognition/" rel="noopener ugc nofollow" target="_blank">【https://cmusphinx.github.io/wiki/phonemerecognition/】T21</a></p><p id="05b6" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><em class="mx">【4】。pocket sphinx Github:</em><a class="ae ky" href="https://github.com/cmusphinx/pocketsphinx" rel="noopener ugc nofollow" target="_blank"><em class="mx">https://github.com/cmusphinx/pocketsphinx</em></a></p><p id="5514" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><em class="mx">【5】。康皮。</em><a class="ae ky" href="https://konlpy.org/en/latest/" rel="noopener ugc nofollow" target="_blank"><em class="mx">https://konlpy.org/en/latest/</em></a></p><p id="5a6d" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><em class="mx">【6】。KoNLPy示例任务。</em><a class="ae ky" href="https://konlpy.org/en/latest/examples/#contents" rel="noopener ugc nofollow" target="_blank"><em class="mx"/></a></p><p id="1834" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><em class="mx">【7】。妈妈。</em><a class="ae ky" href="https://www.findbestopensource.com/product/cpjku-madmom" rel="noopener ugc nofollow" target="_blank"><em class="mx">https://www.findbestopensource.com/product/cpjku-madmom</em></a></p><p id="5910" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><em class="mx">【8】。Github上的Madmom。</em><a class="ae ky" href="https://github.com/CPJKU/madmom" rel="noopener ugc nofollow" target="_blank"><em class="mx">https://github.com/CPJKU/madmom</em></a></p><p id="617b" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><em class="mx">【9】。Github上的Julius。</em><a class="ae ky" href="https://github.com/julius-speech/julius" rel="noopener ugc nofollow" target="_blank">【https://github.com/julius-speech/julius】T21</a></p><p id="31f2" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><em class="mx">【10】。HTK语音识别工具包。</em><a class="ae ky" href="https://htk.eng.cam.ac.uk/" rel="noopener ugc nofollow" target="_blank"><em class="mx">https://htk . eng . cam . AC . uk</em></a></p><p id="ddfa" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><em class="mx">【11】。Github上的自动语音识别主题。</em><a class="ae ky" href="https://github.com/topics/automatic-speech-recognition" rel="noopener ugc nofollow" target="_blank"><em class="mx">https://github.com/topics/automatic-speech-recognition</em></a></p><p id="fb05" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><em class="mx">【12】。Github上的Pysptk。</em><a class="ae ky" href="https://github.com/r9y9/pysptk" rel="noopener ugc nofollow" target="_blank"><em class="mx">https://github.com/r9y9/pysptk</em></a></p><p id="627f" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><em class="mx">【13】。演讲认知。</em><a class="ae ky" href="https://pypi.org/project/SpeechRecognition/" rel="noopener ugc nofollow" target="_blank"><em class="mx">https://pypi.org/project/SpeechRecognition/</em></a></p><p id="d6d8" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><em class="mx">【14】。Github上的Eesen。</em><a class="ae ky" href="https://github.com/srvk/eesen/" rel="noopener ugc nofollow" target="_blank"><em class="mx">https://github.com/srvk/eesen/</em></a></p><p id="5028" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><em class="mx">【15】。Github上的Vosk。</em><a class="ae ky" href="https://github.com/alphacep/vosk-api" rel="noopener ugc nofollow" target="_blank"><em class="mx">https://github.com/alphacep/vosk-api</em></a></p><p id="85d6" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><em class="mx">【16】。Github上的DeepSpeech。</em><a class="ae ky" href="https://github.com/mozilla/DeepSpeech" rel="noopener ugc nofollow" target="_blank"><em class="mx">https://github.com/mozilla/DeepSpeech</em></a></p></div></div>    
</body>
</html>