# PySyft 正在推进私人机器学习议程

> 原文：<https://pub.towardsai.net/pysyft-is-advancing-the-agenda-in-private-machine-learning-c31f7ae934fb?source=collection_archive---------0----------------------->

## [编程](https://towardsai.net/p/category/programming)

## PySyft 是一个开源框架，旨在支持私人机器学习工作流。

![](img/1f700d3b36af6f2465df040912b42dd6.png)

形象信誉:PySyft

> 我最近创办了一份以人工智能为重点的教育时事通讯，已经有超过 10 万的订阅者。该系列是一个没有 BS(意思是没有炒作，没有新闻等)面向 ML 的时事通讯，需要 5 分钟阅读。目标是让您了解最新的机器学习项目、研究论文和概念。请在下面订阅试试:

[](https://thesequence.substack.com/) [## 序列|子包

### 订阅最新的人工智能领域最相关的项目和研究论文。受到 11 万多人的信任…

thesequence.substack.com](https://thesequence.substack.com/) 

信任是实施深度学习应用程序的关键因素。从培训到优化，深度学习模型的生命周期与不同方之间的可信数据交换紧密相关。这种动态性对于实验室环境当然是有效的，但是结果容易受到各种各样的安全攻击，这些攻击操纵模型中不同参与者之间的信任关系。让我们以一个基于信用评分模型的例子为例，该模型使用金融交易对特定客户的信用风险进行分类。用于训练或优化模型的传统机制假定执行这些动作的实体将完全访问这些金融数据集，这为各种隐私风险打开了大门。随着深度学习的发展，对在数据集和模型的生命周期中实施隐私约束的机制的需求变得越来越重要。在试图应对这一巨大挑战的技术中, [PySyft](https://github.com/OpenMined/PySyft) 是一个最近的框架，在深度学习社区中稳步获得了关注。

隐私在深度学习应用中的重要性与分布式、多方模型的出现直接相关。深度学习解决方案的传统方法依赖于控制模型整个生命周期的集中各方，即使使用大型分布式计算基础设施。这是一个创建预测模型的组织的例子，该模型管理访问其网站的客户的偏好。然而，在移动或物联网(IOT)等依赖大量设备产生数据和执行模型的场景中，集中式深度学习拓扑已被证明是不切实际的。在这些场景中，分布式方不仅经常生成敏感数据集，而且还执行和评估深度学习模型的性能。这种动态要求负责创建、培训和执行深度学习模型的不同方之间建立双向隐私关系。

向更分布式架构的过渡是深度学习模型中对强隐私机制的需求背后的主要力量之一。这就是 PySyft 着手解决的挑战，但如果没有机器学习和分布式编程的几个研究领域的发展，这是不可能的。

# 促成因素

深度学习模型中的隐私多年来一直是一个众所周知的问题，但可以提供解决方案的技术现在才达到一定的可行性水平。在 PySyft 的例子中，该框架利用了过去十年中机器学习和密码学中最引人入胜的三项技术:

*安全多方计算*

*联邦学习*

*差分隐私*

# 安全多方计算

安全多方计算(sMPC)是一种加密技术，它允许不同方对输入执行计算，同时保持这些输入的私密性。在计算机科学理论中，sMPC 通常被视为著名的[姚百万富翁问题](https://en.wikipedia.org/wiki/Yao%27s_Millionaires%27_Problem)的解决方案，该问题由计算机科学家 [Andrew Yao](https://en.wikipedia.org/wiki/Andrew_Yao) 于 20 世纪 80 年代提出。这个问题描述了一个场景，在这个场景中，多个百万富翁想知道他们中谁更富有，而不透露他们的实际财富。百万富翁的问题存在于许多现实世界的场景中，如拍卖、选举或在线游戏。

从概念上讲，sMPC 提供了安全计算，取代了对可信中介的需求。在 sMPC 模型中，一组具有私有输入的参与方计算分布式功能，例如公平、隐私和正确性等安全属性被保留。

![](img/e2b6dcd384fea1fe2fa0b00ee733a507.png)

图片来源:PySyft

# 联合学习

联合学习是一种新的学习架构，适用于在高度分布式拓扑结构中运行的人工智能系统，如移动或物联网(IoT)系统。最初由谷歌研究实验室提出，联合学习代表了集中式人工智能训练的一种替代方案，在集中式人工智能训练中，共享的全球模型在中央服务器的协调下进行训练，来自参与设备的联盟。在该模型中，不同的设备可以为模型的训练和知识做出贡献，同时将大部分数据保留在设备中。

在联合学习模型中，一方下载深度学习模型，通过从给定设备上的数据中学习来改进它，然后将这些变化总结为小的有重点的更新。只有这个模型的更新被发送到云，使用加密的通信，在那里它立即与其他用户更新进行平均，以改进共享模型。所有训练数据都保留在原始设备上，没有单独的更新存储在云中。

![](img/6957d83583b08fc844f9e0334d94544e.png)

图片来源:PySyft

# 差异隐私

差异隐私是一种技术，用于限制统计算法对主体隐私的影响，这些主体的信息是更大数据集的一部分。粗略地说，如果一个观察者看到一个算法的输出时不能判断出计算中是否使用了某个特定个体的信息，那么这个算法就是差分私有的。差别隐私经常在识别其信息可能在数据库中的个人的上下文中被讨论。虽然它不直接涉及识别和再识别攻击，但差分私有算法可证明抵抗这种攻击。

![](img/085782c08f320071185e8a227e179469.png)

图片来源:PySyft

# PySyft

PySyft 是一个框架，可以在深度学习模型中实现安全、私有的计算。PySyft 将联邦学习、安全多方计算和差分隐私结合在一个编程模型中，集成到不同的深度学习框架中，如 PyTorch、Keras 或 TensorFlow。PySyft [的原理最初是在一篇研究论文](https://arxiv.org/abs/1811.04017)中概述的，它的[第一次实现是由 OpenMined](https://github.com/OpenMined/PySyft) 领导的，open mined 是领先的分散式人工智能平台之一。

![](img/0e4f7a6148965f86fa4cf7da9c19103e.png)

图片来源:PySyft

PySyft 的核心组件是一个叫做 SyftTensor 的抽象。SyftTensors 表示数据转换的状态，并且可以链接在一起。链式结构的头部总是有 PyTorch 张量，而 SyftTensors 所体现的状态转换使用子属性向下访问，使用父属性向上访问。

![](img/8156c463ba93ffc89a5c957e215307d6.png)

图片来源:PySyft

使用 PySyft 相对简单，与标准 PyTorch 或 Keras 程序没有太大区别。下面的动画演示了一个使用 PySyft 的简单分类模型。

![](img/6671b3261b522273d136601d00f9e733.png)

图片来源:PySyft

PSyft 代表了在深度学习程序中启用鲁棒隐私模型的首批尝试之一。随着空间的发展，隐私可能会成为下一代深度学习框架的基础构件之一。