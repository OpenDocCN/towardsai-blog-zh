<html>
<head>
<title>Creating a Touchless Interface with Tensorflow.js</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">用Tensorflow.js创建无触摸界面</h1>
<blockquote>原文：<a href="https://pub.towardsai.net/creating-a-touchless-interface-with-tensorflow-js-c3676582c1df?source=collection_archive---------3-----------------------#2021-11-03">https://pub.towardsai.net/creating-a-touchless-interface-with-tensorflow-js-c3676582c1df?source=collection_archive---------3-----------------------#2021-11-03</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><h2 id="07a8" class="io ip iq bd b dl ir is it iu iv iw dk ix translated" aria-label="kicker paragraph"><a class="ae ep" href="https://towardsai.net/p/category/machine-learning/deep-learning" rel="noopener ugc nofollow" target="_blank">深度学习</a></h2><div class=""/><p id="579e" class="pw-post-body-paragraph jw jx iq jy b jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ij bi translated">触摸屏是革命性的。然而，随着无线技术的出现和在表面上传播的高度传染性疾病，需要一种与应用程序交互的精细方式。引入无触摸界面。</p><figure class="kv kw kx ky gt kz gh gi paragraph-image"><div role="button" tabindex="0" class="la lb di lc bf ld"><div class="gh gi ku"><img src="../Images/8e5a05448ccebff5b8ebf83e466cd73a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*ajVASVDqAQt-djVX.jpeg"/></div></div><figcaption class="lg lh gj gh gi li lj bd b be z dk translated">来源:来自pexels.com<a class="ae lk" href="https://www.pexels.com/photo/photo-of-woman-wearing-turtleneck-top-2777898/" rel="noopener ugc nofollow" target="_blank">的</a><a class="ae lk" href="https://www.pexels.com/@alipazani" rel="noopener ugc nofollow" target="_blank">阿里·帕扎尼</a></figcaption></figure></div><div class="ab cl ll lm hu ln" role="separator"><span class="lo bw bk lp lq lr"/><span class="lo bw bk lp lq lr"/><span class="lo bw bk lp lq"/></div><div class="ij ik il im in"><h1 id="70b2" class="ls lt iq bd lu lv lw lx ly lz ma mb mc md me mf mg mh mi mj mk ml mm mn mo mp bi translated">介绍</h1><p id="7128" class="pw-post-body-paragraph jw jx iq jy b jz mq kb kc kd mr kf kg kh ms kj kk kl mt kn ko kp mu kr ks kt ij bi translated">无触摸界面在大量设备上运行良好，为许多平台上的现实世界实施打开了大门——从无触摸亭到VR游戏集成。</p><p id="b595" class="pw-post-body-paragraph jw jx iq jy b jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ij bi translated">这篇文章将介绍一个基于web的无触摸界面的代码，在这个界面中，来自任何平台的用户都可以通过手的移动与虚拟块进行交互。</p><h2 id="a09b" class="mv lt iq bd lu mw mx dn ly my mz dp mc kh na nb mg kl nc nd mk kp ne nf mo iw bi translated">有用的链接:</h2><ul class=""><li id="dedf" class="ng nh iq jy b jz mq kd mr kh ni kl nj kp nk kt nl nm nn no bi translated"><a class="ae lk" href="https://touchlessinterface.netlify.app/" rel="noopener ugc nofollow" target="_blank">无触摸界面</a>(网站)</li><li id="554a" class="ng nh iq jy b jz np kd nq kh nr kl ns kp nt kt nl nm nn no bi translated"><a class="ae lk" href="https://github.com/Hammaad-M/touchless-interface" rel="noopener ugc nofollow" target="_blank">无接触界面GitHub库</a></li><li id="037e" class="ng nh iq jy b jz np kd nq kh nr kl ns kp nt kt nl nm nn no bi translated"><a class="ae lk" href="https://github.com/Hammaad-M/isHandOpen" rel="noopener ugc nofollow" target="_blank"> isHandOpen GitHub库</a>(稍后讨论)</li></ul></div><div class="ab cl ll lm hu ln" role="separator"><span class="lo bw bk lp lq lr"/><span class="lo bw bk lp lq lr"/><span class="lo bw bk lp lq"/></div><div class="ij ik il im in"><h1 id="0521" class="ls lt iq bd lu lv lw lx ly lz ma mb mc md me mf mg mh mi mj mk ml mm mn mo mp bi translated">设置</h1><p id="c5ec" class="pw-post-body-paragraph jw jx iq jy b jz mq kb kc kd mr kf kg kh ms kj kk kl mt kn ko kp mu kr ks kt ij bi translated">在数据可以开始通过深度学习模型推送之前，有几项任务需要首先完成。</p><ol class=""><li id="e409" class="ng nh iq jy b jz ka kd ke kh nu kl nv kp nw kt nx nm nn no bi translated">正在加载Tensorflow.js</li><li id="f41b" class="ng nh iq jy b jz np kd nq kh nr kl ns kp nt kt nx nm nn no bi translated">加载手选模型</li><li id="e0be" class="ng nh iq jy b jz np kd nq kh nr kl ns kp nt kt nx nm nn no bi translated">设置网络摄像头</li><li id="c47a" class="ng nh iq jy b jz np kd nq kh nr kl ns kp nt kt nx nm nn no bi translated">创建随机生成的块</li></ol><p id="256d" class="pw-post-body-paragraph jw jx iq jy b jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ij bi translated">只需通过index.html文件中的cdn加载Tensorflow.js。Tensorflow.js的脚本标记放在本地JavaScript标记之前和所有UI元素之后，以允许UI首先加载Tensorflow.js，然后加载本地JavaScript。</p><p id="ec31" class="pw-post-body-paragraph jw jx iq jy b jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ij bi translated">出于与上述相同的原因，HandPose模型也是在Tensorflow.js之后通过cdn加载的。但是，加载HandPose模型还需要执行下面的异步命令:<code class="fe ny nz oa ob b">handpose.load()</code>。在无接触界面的代码中，步骤1-3被包装在对attempt()函数的调用中。下面是加载HandPose模型的attempt()函数:</p><pre class="kv kw kx ky gt oc ob od oe aw of bi"><span id="8dfe" class="mv lt iq ob b gy og oh l oi oj">// Load the MediaPipe handpose model.<br/>  const model = await attempt(<br/>    async () =&gt; await handpose.load(), <br/>    () =&gt; statusDisplay.textContent = "Setting up Webcam", <br/>    () =&gt; fail("Failed to Load Model"),<br/>  );</span></pre><p id="80bf" class="pw-post-body-paragraph jw jx iq jy b jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ij bi translated">attempt()函数接受3个函数参数。传递的第一个函数是要执行的函数。如果第一个函数没有任何错误地完成，则执行第二个函数。如果第一个函数出错，将执行最后一个函数。在这种情况下，如果<code class="fe ny nz oa ob b">await handpose.load()</code>运行没有任何错误，屏幕状态将更新到下一步，否则将执行失败回调以中止设置。</p><p id="19bc" class="pw-post-body-paragraph jw jx iq jy b jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ij bi translated">下一个任务是设置网络摄像头，它被提取到异步函数<code class="fe ny nz oa ob b">setupWebcam</code>中，并被打包到一个<code class="fe ny nz oa ob b">attempt()</code>调用中。<code class="fe ny nz oa ob b">setupWebcam</code>功能访问用户的网络摄像头，并将其设置为屏幕视频元素的来源。它还为摄像头的大小设置了全局变量，这对于从视频馈送中解密手的偏移是必不可少的。该函数还为视频元素设置了<code class="fe ny nz oa ob b">plays-inline</code>属性<code class="fe ny nz oa ob b">true</code>，以确保safari兼容性。</p><p id="04da" class="pw-post-body-paragraph jw jx iq jy b jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ij bi translated">最后一个设置任务是随机生成供用户交互的彩色块。这是在<code class="fe ny nz oa ob b">createObjects</code>函数中通过使用<code class="fe ny nz oa ob b">document.createElement</code>函数创建HTML元素来完成的，这些元素随后被随机应用到样式预设中。</p></div><div class="ab cl ll lm hu ln" role="separator"><span class="lo bw bk lp lq lr"/><span class="lo bw bk lp lq lr"/><span class="lo bw bk lp lq"/></div><div class="ij ik il im in"><h1 id="ac71" class="ls lt iq bd lu lv lw lx ly lz ma mb mc md me mf mg mh mi mj mk ml mm mn mo mp bi translated">跟踪手</h1><p id="2001" class="pw-post-body-paragraph jw jx iq jy b jz mq kb kc kd mr kf kg kh ms kj kk kl mt kn ko kp mu kr ks kt ij bi translated">完成初始设置后，剩下的代码将在应用程序的主循环中执行。跟踪用户手部的第一步是调用异步函数<code class="fe ny nz oa ob b">model.estimateHands(videoRef)</code>，该函数使用HandPose模型从视频元素预测手部，该视频元素正在传输用户的网络摄像头馈送。<code class="fe ny nz oa ob b">estimateHands</code>函数返回一个预测数组，其中第一个是最相关的。预测对象有很多重要的信息，比如手掌根部和每个手指上的关键点的坐标(x，y，z)。</p><p id="1c52" class="pw-post-body-paragraph jw jx iq jy b jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ij bi translated">第一个任务是根据手在摄像头中的位置移动屏幕上的目标元素。<code class="fe ny nz oa ob b">getHandCoords</code>函数接受<code class="fe ny nz oa ob b">prediction.annotations</code>作为输入，并使用它来检索手掌底部的x和y坐标。然后，它发回以下表达式的结果:</p><pre class="kv kw kx ky gt oc ob od oe aw of bi"><span id="f521" class="mv lt iq ob b gy og oh l oi oj">return [<br/>  ( palmX / webcamWidth ) * 100, <br/>  ( palmY / webcamHeight ) * 100<br/>];</span></pre><p id="5ef9" class="pw-post-body-paragraph jw jx iq jy b jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ij bi translated">手在视口中的位置被转换为百分比偏移，然后用于设置屏幕目标的<code class="fe ny nz oa ob b">right</code>和<code class="fe ny nz oa ob b">top</code>样式属性，以匹配手的位置。</p></div><div class="ab cl ll lm hu ln" role="separator"><span class="lo bw bk lp lq lr"/><span class="lo bw bk lp lq lr"/><span class="lo bw bk lp lq"/></div><div class="ij ik il im in"><h1 id="d258" class="ls lt iq bd lu lv lw lx ly lz ma mb mc md me mf mg mh mi mj mk ml mm mn mo mp bi translated">与用户界面交互</h1><p id="7b9d" class="pw-post-body-paragraph jw jx iq jy b jz mq kb kc kd mr kf kg kh ms kj kk kl mt kn ko kp mu kr ks kt ij bi translated">最后一步，也可能是最具挑战性的一步，是允许用户拾取、移动和丢弃随机生成的块。以下是对该概念的简要解释:</p><blockquote class="ok ol om"><p id="d547" class="jw jx on jy b jz ka kb kc kd ke kf kg oo ki kj kk op km kn ko oq kq kr ks kt ij bi translated"><em class="iq">当用户伸出手指，手掌平放在摄像机上时，屏幕上的目标应在不改变位置的情况下越过任何方块，并放下任何被按住的方块。</em></p><p id="fbdb" class="jw jx on jy b jz ka kb kc kd ke kf kg oo ki kj kk op km kn ko oq kq kr ks kt ij bi translated"><em class="iq">相比之下，当用户的手指卷曲，或者他们的手握拳时，任何被握住的块应该继续被移动。如果没有块被保持，用一只握紧的手经过一个块时，应该会拿起它，并沿着屏幕上的光标拖动它。</em></p></blockquote><h2 id="27ee" class="mv lt iq bd lu mw mx dn ly my mz dp mc kh na nb mg kl nc nd mk kp ne nf mo iw bi translated">isHandOpen库简介</h2><p id="cd65" class="pw-post-body-paragraph jw jx iq jy b jz mq kb kc kd mr kf kg kh ms kj kk kl mt kn ko kp mu kr ks kt ij bi translated">上述伪代码的实现依赖于准确地确定用户的手是否张开。为了有效地将这个组件提取到一个可重用的组件中，我编译了一个纯JavaScript库，它使用<code class="fe ny nz oa ob b">predictions.annotations</code>对象来返回一个<code class="fe ny nz oa ob b">true</code>或<code class="fe ny nz oa ob b">false</code>值，以表示用户的手是否张开。这里有一个<a class="ae lk" href="https://github.com/Hammaad-M/isHandOpen" rel="noopener ugc nofollow" target="_blank">链接</a>到存储库。值得注意的是，无接触界面存储库附带了isHandOpen。如果没有使用无接触界面的存储库，下载简化的isHandOpen JavaScript文件，并在任何本地JavaScript标签上方引用它<code class="fe ny nz oa ob b">&lt;script src="isHandOpen.min.js"&gt;&lt;/script&gt;</code>。这将定义带有两个参数的<code class="fe ny nz oa ob b">isHandOpen</code>函数:对象<code class="fe ny nz oa ob b">predictions.annotations</code>和可选的<code class="fe ny nz oa ob b">HAND_OPEN_BUFFER</code>。第二个参数控制在<code class="fe ny nz oa ob b">isHandOpen</code>函数返回<code class="fe ny nz oa ob b">true</code>之前，手在一行中应被检测为张开的次数。默认情况下，<code class="fe ny nz oa ob b">HAND_OPEN_BUFFER</code>是<code class="fe ny nz oa ob b">null</code>，这意味着函数每次都会准确地返回它所预测的结果。我在这种方法中发现的一个反复出现的错误是，当用户的手合拢时，应用程序会抛出阻塞。<code class="fe ny nz oa ob b">HAND_OPEN_BUFFER</code>有效地消除了误报的问题，代价是稍后<code class="fe ny nz oa ob b">HAND_OPEN_BUFFER</code>调用<code class="fe ny nz oa ob b">isHandOpen</code>时会丢失项目——在这种情况下只有几毫秒。</p><h2 id="e33c" class="mv lt iq bd lu mw mx dn ly my mz dp mc kh na nb mg kl nc nd mk kp ne nf mo iw bi translated">拖动项目</h2><p id="2ed8" class="pw-post-body-paragraph jw jx iq jy b jz mq kb kc kd mr kf kg kh ms kj kk kl mt kn ko kp mu kr ks kt ij bi translated">用<code class="fe ny nz oa ob b">predictions.annotations</code>对象和为2的<code class="fe ny nz oa ob b">HAND_OPEN_BUFFER</code>对<code class="fe ny nz oa ob b">isHandOpen</code>的简单调用返回一个布尔值，表示用户的手是否张开。下一步是允许用户移动屏幕上的块。为了拿起一个方块，用户的手必须合拢，光标或目标必须靠近该方块。如果手闭合并且当前没有拿着任何物品，则执行<code class="fe ny nz oa ob b">canGrabItem</code>功能，将目标的<code class="fe ny nz oa ob b">top</code>和<code class="fe ny nz oa ob b">right</code>样式值与屏幕上的每个物品进行比较，并找到可以拿起的最近的物体。如果该项足够接近，那么它会将其设置为当前持有项的全局变量的值。然后，在主循环的后续迭代中读取该值，主循环将其与目标光标一起移动—随着用户的手一起移动。</p></div><div class="ab cl ll lm hu ln" role="separator"><span class="lo bw bk lp lq lr"/><span class="lo bw bk lp lq lr"/><span class="lo bw bk lp lq"/></div><div class="ij ik il im in"><h1 id="257c" class="ls lt iq bd lu lv lw lx ly lz ma mb mc md me mf mg mh mi mj mk ml mm mn mo mp bi translated">摘要</h1><p id="ce66" class="pw-post-body-paragraph jw jx iq jy b jz mq kb kc kd mr kf kg kh ms kj kk kl mt kn ko kp mu kr ks kt ij bi translated">无触摸界面利用Tensorflow.js的HandPose模型从网络摄像头定位用户的手，并将其位置投影到屏幕光标上。然后它集成isHandOpen库来解密用户的手是否张开。这些信息然后被用来允许用户在他们的手指和手上抓取、移动和放下屏幕上的小部件。</p><h2 id="c439" class="mv lt iq bd lu mw mx dn ly my mz dp mc kh na nb mg kl nc nd mk kp ne nf mo iw bi translated">含义</h2><p id="0255" class="pw-post-body-paragraph jw jx iq jy b jz mq kb kc kd mr kf kg kh ms kj kk kl mt kn ko kp mu kr ks kt ij bi translated">浏览器中的无接触界面代表了这种技术的广泛应用。从公共区域的无触摸解决方案到新水平的软件沉浸，无触摸界面有能力彻底改变人类与计算机的交互方式。</p></div></div>    
</body>
</html>