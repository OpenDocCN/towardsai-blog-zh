<html>
<head>
<title>NLP News Cypher | 06.21.20</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">NLP新闻密码| 06.21.20</h1>
<blockquote>原文：<a href="https://pub.towardsai.net/nlp-news-cypher-06-21-20-cd86b327ad8d?source=collection_archive---------3-----------------------#2020-06-21">https://pub.towardsai.net/nlp-news-cypher-06-21-20-cd86b327ad8d?source=collection_archive---------3-----------------------#2020-06-21</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><figure class="ip iq gp gr ir is gh gi paragraph-image"><div role="button" tabindex="0" class="it iu di iv bf iw"><div class="gh gi io"><img src="../Images/a15ff20f60cba8782f10d885a88e9b0e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*K8kz2wcJ84fEme5s"/></div></div><figcaption class="iz ja gj gh gi jb jc bd b be z dk translated">扎克·卡斯蒂略在<a class="ae jd" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上的照片</figcaption></figure><h2 id="7fda" class="je jf jg bd b dl jh ji jj jk jl jm dk jn translated" aria-label="kicker paragraph">自然语言处理每周时事通讯</h2><div class=""/><div class=""><h2 id="6e38" class="pw-subtitle-paragraph km jp jg bd b kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld dk translated">勇敢的心</h2></div><p id="0082" class="pw-post-body-paragraph le lf jg lg b lh li kq lj lk ll kt lm ln lo lp lq lr ls lt lu lv lw lx ly lz ij bi translated">说到网络黑客，NSA是你需要关注的三个字母的机构。如果你想知道他们是如何破解我们的电子邮件的，那么，它涉及到时钟、质数和椭圆曲线🤯。在下面的视频中，将向您介绍用于创建随机数生成的数学方法，网络安全算法使用该方法对信用卡或电子邮件进行日常加密。</p><p id="a237" class="pw-post-body-paragraph le lf jg lg b lh li kq lj lk ll kt lm ln lo lp lq lr ls lt lu lv lw lx ly lz ij bi translated">安全软件之所以有效，是因为它们的加密“随机”数字序列，这使得它们不可预测，因此是安全的。但是，如果这些随机数的产生有一个后门，使它们变得可预测，那会怎么样呢？本质上，这是国家安全局发现的。为了看看他们是如何做到的，让我们进入兔子洞:</p><figure class="ma mb mc md gt is"><div class="bz fp l di"><div class="me mf l"/></div><figcaption class="iz ja gj gh gi jb jc bd b be z dk translated">解密的</figcaption></figure><h1 id="7605" class="mg mh jg bd mi mj mk ml mm mn mo mp mq kv mr kw ms ky mt kz mu lb mv lc mw mx bi translated">本周:</h1><blockquote class="my mz na"><p id="95e9" class="le lf nb lg b lh li kq lj lk ll kt lm nc lo lp lq nd ls lt lu ne lw lx ly lz ij bi translated">MMF多式联运框架</p><p id="70b1" class="le lf nb lg b lh li kq lj lk ll kt lm nc lo lp lq nd ls lt lu ne lw lx ly lz ij bi translated">结构化文档的信息检索</p><p id="83be" class="le lf nb lg b lh li kq lj lk ll kt lm nc lo lp lq nd ls lt lu ne lw lx ly lz ij bi translated">空间更新</p><p id="8f08" class="le lf nb lg b lh li kq lj lk ll kt lm nc lo lp lq nd ls lt lu ne lw lx ly lz ij bi translated">知识图表简介</p><p id="d642" class="le lf nb lg b lh li kq lj lk ll kt lm nc lo lp lq nd ls lt lu ne lw lx ly lz ij bi translated">长格式问题回答</p><p id="8700" class="le lf nb lg b lh li kq lj lk ll kt lm nc lo lp lq nd ls lt lu ne lw lx ly lz ij bi translated">TF Lite中的模型量化</p><p id="503b" class="le lf nb lg b lh li kq lj lk ll kt lm nc lo lp lq nd ls lt lu ne lw lx ly lz ij bi translated">生产中的深度学习</p><p id="21b4" class="le lf nb lg b lh li kq lj lk ll kt lm nc lo lp lq nd ls lt lu ne lw lx ly lz ij bi translated">本周数据集:TVQA</p></blockquote></div><div class="ab cl nf ng hu nh" role="separator"><span class="ni bw bk nj nk nl"/><span class="ni bw bk nj nk nl"/><span class="ni bw bk nj nk"/></div><div class="ij ik il im in"><h1 id="3e53" class="mg mh jg bd mi mj nm ml mm mn nn mp mq kv no kw ms ky np kz mu lb nq lc mw mx bi translated">MMF多式联运框架</h1><p id="6a74" class="pw-post-body-paragraph le lf jg lg b lh nr kq lj lk ns kt lm ln nt lp lq lr nu lt lu lv nv lx ly lz ij bi translated">嘿现在！脸书，更确切地说是PyTorch，发布了他们的多模态框架！它带有…</p><blockquote class="my mz na"><p id="c273" class="le lf nb lg b lh li kq lj lk ll kt lm nc lo lp lq nd ls lt lu ne lw lx ly lz ij bi translated">“最先进的视觉和语言预训练模型、大量现成的标准数据集、通用层和模型组件，以及训练和推理工具。”</p></blockquote><p id="72c7" class="pw-post-body-paragraph le lf jg lg b lh li kq lj lk ll kt lm ln lo lp lq lr ls lt lu lv lw lx ly lz ij bi translated">你可以使用MMF来完成几个不同的多模态任务:VQA，图像字幕，可视对话，仇恨探测等等。</p><figure class="ma mb mc md gt is gh gi paragraph-image"><div role="button" tabindex="0" class="it iu di iv bf iw"><div class="gh gi nw"><img src="../Images/9f0c606645d4a98c4292c7449d0ec140.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*Z7u6c7rve_N_shvf.png"/></div></div></figure><p id="ad1f" class="pw-post-body-paragraph le lf jg lg b lh li kq lj lk ll kt lm ln lo lp lq lr ls lt lu lv lw lx ly lz ij bi translated">当前可用型号列表:</p><ul class=""><li id="1f70" class="nx ny jg lg b lh li lk ll ln nz lr oa lv ob lz oc od oe of bi translated">针对TextVQA [ <a class="ae jd" href="https://arxiv.org/abs/1911.06258" rel="noopener ugc nofollow" target="_blank"> arXiv </a> ] [ <a class="ae jd" href="https://github.com/facebookresearch/mmf/tree/master/projects/m4c" rel="noopener ugc nofollow" target="_blank">项目</a> ]的M4C迭代答案预测</li><li id="6355" class="nx ny jg lg b lh og lk oh ln oi lr oj lv ok lz oc od oe of bi translated">ViLBERT ViLBERT:为视觉和语言任务预先训练与任务无关的视觉语言表示[ <a class="ae jd" href="https://arxiv.org/abs/1908.02265" rel="noopener ugc nofollow" target="_blank"> arXiv </a> ] [ <a class="ae jd" href="https://github.com/facebookresearch/mmf/tree/master/projects/vilbert" rel="noopener ugc nofollow" target="_blank">项目</a></li><li id="16ec" class="nx ny jg lg b lh og lk oh ln oi lr oj lv ok lz oc od oe of bi translated">视觉和语言的一个简单和可执行的基线[ <a class="ae jd" href="https://arxiv.org/abs/1908.03557" rel="noopener ugc nofollow" target="_blank"> arXiv </a> ] [ <a class="ae jd" href="https://arxiv.org/abs/1908.03557" rel="noopener ugc nofollow" target="_blank">项目</a></li><li id="38c7" class="nx ny jg lg b lh og lk oh ln oi lr oj lv ok lz oc od oe of bi translated">LoRRA走向可以阅读[ <a class="ae jd" href="https://arxiv.org/abs/1904.08920" rel="noopener ugc nofollow" target="_blank"> arXiv </a> ] [ <a class="ae jd" href="https://github.com/facebookresearch/mmf/tree/master/projects/lorra" rel="noopener ugc nofollow" target="_blank">项目</a>的VQA模型</li><li id="1963" class="nx ny jg lg b lh og lk oh ln oi lr oj lv ok lz oc od oe of bi translated">M4C字幕器TextCaps:一个用于阅读理解的图像字幕数据集[ <a class="ae jd" href="https://arxiv.org/abs/2003.12462" rel="noopener ugc nofollow" target="_blank"> arXiv </a> ] [ <a class="ae jd" href="https://github.com/facebookresearch/mmf/tree/master/projects/m4c_captioner" rel="noopener ugc nofollow" target="_blank">项目</a></li><li id="1891" class="nx ny jg lg b lh og lk oh ln oi lr oj lv ok lz oc od oe of bi translated">皮媞亚皮媞亚v0。vqa挑战赛2018的获奖作品[ <a class="ae jd" href="https://arxiv.org/abs/1807.09956" rel="noopener ugc nofollow" target="_blank"> arXiv </a> ] [ <a class="ae jd" href="https://github.com/facebookresearch/mmf/tree/master/projects/pythia" rel="noopener ugc nofollow" target="_blank">项目</a> ]</li><li id="d2d5" class="nx ny jg lg b lh og lk oh ln oi lr oj lv ok lz oc od oe of bi translated">但对图像字幕和视觉问题回答的关注是自下而上和自上而下的[<a class="ae jd" href="https://arxiv.org/abs/1707.07998" rel="noopener ugc nofollow" target="_blank">arXiv</a>][<a class="ae jd" href="https://github.com/facebookresearch/mmf/tree/master/projects/butd" rel="noopener ugc nofollow" target="_blank">project</a></li><li id="0149" class="nx ny jg lg b lh og lk oh ln oi lr oj lv ok lz oc od oe of bi translated">MMBT负责监督用于图像和文本分类的多模式双向转换器[ <a class="ae jd" href="https://arxiv.org/abs/1909.02950" rel="noopener ugc nofollow" target="_blank"> arXiv </a> ] [ <a class="ae jd" href="https://github.com/facebookresearch/mmf/tree/master/projects/mmbt" rel="noopener ugc nofollow" target="_blank">项目</a></li><li id="b411" class="nx ny jg lg b lh og lk oh ln oi lr oj lv ok lz oc od oe of bi translated">班双线性注意力网络[ <a class="ae jd" href="https://arxiv.org/abs/1805.07932" rel="noopener ugc nofollow" target="_blank"> arXiv </a> ] [ <a class="ae jd" href="https://github.com/facebookresearch/mmf/tree/master/projects/ban" rel="noopener ugc nofollow" target="_blank">项目</a> ]</li></ul><p id="eea7" class="pw-post-body-paragraph le lf jg lg b lh li kq lj lk ll kt lm ln lo lp lq lr ls lt lu lv lw lx ly lz ij bi translated"><strong class="lg jq">博客</strong>:</p><div class="ip iq gp gr ir ol"><a href="https://medium.com/pytorch/bootstrapping-a-multimodal-project-using-mmf-a-pytorch-powered-multimodal-framework-464f75164af7" rel="noopener follow" target="_blank"><div class="om ab fo"><div class="on ab oo cl cj op"><h2 class="bd jq gy z fp oq fr fs or fu fw jp bi translated">使用PyTorch驱动的多模态框架MMF引导多模态项目</h2><div class="os l"><h3 class="bd b gy z fp oq fr fs or fu fw dk translated">为你的下一个视觉和语言研究/制作项目打下坚实的基础</h3></div><div class="ot l"><p class="bd b dl z fp oq fr fs or fu fw dk translated">medium.com</p></div></div><div class="ou l"><div class="ov l ow ox oy ou oz ix ol"/></div></div></a></div><p id="6d7f" class="pw-post-body-paragraph le lf jg lg b lh li kq lj lk ll kt lm ln lo lp lq lr ls lt lu lv lw lx ly lz ij bi translated"><strong class="lg jq"> GitHub </strong>:</p><div class="ip iq gp gr ir ol"><a href="https://github.com/facebookresearch/mmf" rel="noopener  ugc nofollow" target="_blank"><div class="om ab fo"><div class="on ab oo cl cj op"><h2 class="bd jq gy z fp oq fr fs or fu fw jp bi translated">facebookresearch/mmf</h2><div class="os l"><h3 class="bd b gy z fp oq fr fs or fu fw dk translated">MMF是脸书人工智能研究所的视觉和语言多模态研究的模块化框架。MMF包含…</h3></div><div class="ot l"><p class="bd b dl z fp oq fr fs or fu fw dk translated">github.com</p></div></div><div class="ou l"><div class="pa l ow ox oy ou oz ix ol"/></div></div></a></div><h1 id="1cc8" class="mg mh jg bd mi mj mk ml mm mn mo mp mq kv mr kw ms ky mt kz mu lb mv lc mw mx bi translated">结构化文档的信息检索</h1><p id="581c" class="pw-post-body-paragraph le lf jg lg b lh nr kq lj lk ns kt lm ln nt lp lq lr nu lt lu lv nv lx ly lz ij bi translated">记得🧐光学字符识别吗？有些技术永远不会消亡，谷歌已经创建了一个从结构化文档中提取信息的模型。该架构使用OCR从pdf或扫描文档等文档中提取文本，然后使用候选生成器来匹配目标模式中的字段。最后，给字段一个可能性分数，对提取到的预期目标进行排序。</p><figure class="ma mb mc md gt is gh gi paragraph-image"><div class="gh gi pb"><img src="../Images/fc22c6c5127b2bcdc3b1c6a1c728b694.png" data-original-src="https://miro.medium.com/v2/resize:fit:1280/format:webp/0*HicjoO_Q7GWORh19.png"/></div></figure><p id="ce7c" class="pw-post-body-paragraph le lf jg lg b lh li kq lj lk ll kt lm ln lo lp lq lr ls lt lu lv lw lx ly lz ij bi translated"><strong class="lg jq">博客</strong>:</p><div class="ip iq gp gr ir ol"><a href="https://ai.googleblog.com/2020/06/extracting-structured-data-from.html" rel="noopener  ugc nofollow" target="_blank"><div class="om ab fo"><div class="on ab oo cl cj op"><h2 class="bd jq gy z fp oq fr fs or fu fw jp bi translated">从临时文档中提取结构化数据</h2><div class="os l"><h3 class="bd b gy z fp oq fr fs or fu fw dk translated">临时文档，如收据、账单、保险报价等，在一个企业中是非常常见和重要的</h3></div><div class="ot l"><p class="bd b dl z fp oq fr fs or fu fw dk translated">ai.googleblog.com</p></div></div><div class="ou l"><div class="pc l ow ox oy ou oz ix ol"/></div></div></a></div><h1 id="8782" class="mg mh jg bd mi mj mk ml mm mn mo mp mq kv mr kw ms ky mt kz mu lb mv lc mw mx bi translated">空间更新</h1><p id="20f9" class="pw-post-body-paragraph le lf jg lg b lh nr kq lj lk ns kt lm ln nt lp lq lr nu lt lu lv nv lx ly lz ij bi translated">SpaCy对其库进行了全新的更新，突出了新的语言和教程(以及更多！).他们增加了5种新语言:中文、日语、丹麦语、波兰语和罗马尼亚语。除了新语言之外，SpaCy还改进了模型加载时间，并在此处提供了新的在线课程:</p><p id="17d3" class="pw-post-body-paragraph le lf jg lg b lh li kq lj lk ll kt lm ln lo lp lq lr ls lt lu lv lw lx ly lz ij bi translated"><strong class="lg jq">教程</strong>:</p><div class="ip iq gp gr ir ol"><a href="https://course.spacy.io/en" rel="noopener  ugc nofollow" target="_blank"><div class="om ab fo"><div class="on ab oo cl cj op"><h2 class="bd jq gy z fp oq fr fs or fu fw jp bi translated">带空间的高级自然语言处理免费在线课程</h2><div class="os l"><h3 class="bd b gy z fp oq fr fs or fu fw dk translated">spaCy是一个用于工业级自然语言处理的现代Python库。在这个自由和互动的…</h3></div><div class="ot l"><p class="bd b dl z fp oq fr fs or fu fw dk translated">course.spacy.io</p></div></div><div class="ou l"><div class="pd l ow ox oy ou oz ix ol"/></div></div></a></div><p id="128a" class="pw-post-body-paragraph le lf jg lg b lh li kq lj lk ll kt lm ln lo lp lq lr ls lt lu lv lw lx ly lz ij bi translated"><strong class="lg jq">更新汇总:</strong></p><div class="ip iq gp gr ir ol"><a href="https://explosion.ai/blog/spacy-v2-3" rel="noopener  ugc nofollow" target="_blank"><div class="om ab fo"><div class="on ab oo cl cj op"><h2 class="bd jq gy z fp oq fr fs or fu fw jp bi translated">介绍spaCy v2.3爆炸</h2><div class="os l"><h3 class="bd b gy z fp oq fr fs or fu fw dk translated">spaCy现在会说中文，日语，丹麦语，波兰语和罗马尼亚语！spaCy自然语言处理的2.3版本…</h3></div><div class="ot l"><p class="bd b dl z fp oq fr fs or fu fw dk translated">explosion.ai</p></div></div><div class="ou l"><div class="pe l ow ox oy ou oz ix ol"/></div></div></a></div><h1 id="45d0" class="mg mh jg bd mi mj mk ml mm mn mo mp mq kv mr kw ms ky mt kz mu lb mv lc mw mx bi translated">知识图表简介</h1><p id="92f7" class="pw-post-body-paragraph le lf jg lg b lh nr kq lj lk ns kt lm ln nt lp lq lr nu lt lu lv nv lx ly lz ij bi translated">对知识图嵌入的一个很好的介绍，它简要地讨论了亚马逊的知识图库DGL-KE建立在深度图库(DGL)之上。</p><p id="0c8c" class="pw-post-body-paragraph le lf jg lg b lh li kq lj lk ll kt lm ln lo lp lq lr ls lt lu lv lw lx ly lz ij bi translated"><strong class="lg jq">博客</strong>:</p><div class="ip iq gp gr ir ol"><a href="https://towardsdatascience.com/introduction-to-knowledge-graph-embedding-with-dgl-ke-77ace6fb60ef" rel="noopener follow" target="_blank"><div class="om ab fo"><div class="on ab oo cl cj op"><h2 class="bd jq gy z fp oq fr fs or fu fw jp bi translated">用DGL-柯介绍知识图嵌入</h2><div class="os l"><h3 class="bd b gy z fp oq fr fs or fu fw dk translated">作者:Cyrus Vahid，AWS AI首席解决方案工程师</h3></div><div class="ot l"><p class="bd b dl z fp oq fr fs or fu fw dk translated">towardsdatascience.com</p></div></div><div class="ou l"><div class="pf l ow ox oy ou oz ix ol"/></div></div></a></div><p id="ceaf" class="pw-post-body-paragraph le lf jg lg b lh li kq lj lk ll kt lm ln lo lp lq lr ls lt lu lv lw lx ly lz ij bi translated"><strong class="lg jq">DGL-柯</strong></p><div class="ip iq gp gr ir ol"><a href="https://github.com/awslabs/dgl-ke" rel="noopener  ugc nofollow" target="_blank"><div class="om ab fo"><div class="on ab oo cl cj op"><h2 class="bd jq gy z fp oq fr fs or fu fw jp bi translated">aw slab/dgl-ke</h2><div class="os l"><h3 class="bd b gy z fp oq fr fs or fu fw dk translated">文档知识图是存储不同实体(节点)信息的数据结构</h3></div><div class="ot l"><p class="bd b dl z fp oq fr fs or fu fw dk translated">github.com</p></div></div><div class="ou l"><div class="pg l ow ox oy ou oz ix ol"/></div></div></a></div><h1 id="04b5" class="mg mh jg bd mi mj mk ml mm mn mo mp mq kv mr kw ms ky mt kz mu lb mv lc mw mx bi translated">长格式问题回答</h1><p id="50d1" class="pw-post-body-paragraph le lf jg lg b lh nr kq lj lk ns kt lm ln nt lp lq lr nu lt lu lv nv lx ly lz ij bi translated">拥抱脸最近发布了一个长形式问题回答的演示，它接受一个问题，从维基百科中获取段落，并对该问题写一个多句子的解释。意思是，这不是像小队模式那样的提取QA。相反，它使用稀疏模型(Elasticsearch)来检索与问题松散链接的顶级维基段落，然后使用密集模型(Faiss ),嵌入在ELI-5数据集上训练的问题/答案。最后，他们使用BART生成答案。相当酷和高效！</p><p id="f368" class="pw-post-body-paragraph le lf jg lg b lh li kq lj lk ll kt lm ln lo lp lq lr ls lt lu lv lw lx ly lz ij bi translated"><strong class="lg jq">博客/笔记本</strong>:</p><div class="ip iq gp gr ir ol"><a href="https://yjernite.github.io/lfqa.html" rel="noopener  ugc nofollow" target="_blank"><div class="om ab fo"><div class="on ab oo cl cj op"><h2 class="bd jq gy z fp oq fr fs or fu fw jp bi translated">long _ Form _ Question _ Answering _ with _ Eli 5 _ and _ Wikipedia</h2><div class="os l"><h3 class="bd b gy z fp oq fr fs or fu fw dk translated">想象一下，你突然渴望了解热带树木的果实是如何转化成……</h3></div><div class="ot l"><p class="bd b dl z fp oq fr fs or fu fw dk translated">yjernite.github.io</p></div></div></div></a></div><p id="9a67" class="pw-post-body-paragraph le lf jg lg b lh li kq lj lk ll kt lm ln lo lp lq lr ls lt lu lv lw lx ly lz ij bi translated"><strong class="lg jq">演示:</strong></p><div class="ip iq gp gr ir ol"><a href="https://huggingface.co/qa/" rel="noopener  ugc nofollow" target="_blank"><div class="om ab fo"><div class="on ab oo cl cj op"><h2 class="bd jq gy z fp oq fr fs or fu fw jp bi translated">细流</h2><div class="os l"><h3 class="bd b gy z fp oq fr fs or fu fw dk translated">编辑描述</h3></div><div class="ot l"><p class="bd b dl z fp oq fr fs or fu fw dk translated">huggingface.co</p></div></div></div></a></div><h1 id="a784" class="mg mh jg bd mi mj mk ml mm mn mo mp mq kv mr kw ms ky mt kz mu lb mv lc mw mx bi translated">TF Lite中的模型量化</h1><p id="a336" class="pw-post-body-paragraph le lf jg lg b lh nr kq lj lk ns kt lm ln nt lp lq lr nu lt lu lv nv lx ly lz ij bi translated">Sayak Paul发表了一篇关于模型量化的博客文章，该文章将用于移动设备等边缘设备。它清晰地介绍了量化(训练后量化和量化感知训练<strong class="lg jq"> ) </strong>以及它如何与TensorFlow Lite相适应。</p><p id="597a" class="pw-post-body-paragraph le lf jg lg b lh li kq lj lk ll kt lm ln lo lp lq lr ls lt lu lv lw lx ly lz ij bi translated"><strong class="lg jq">博客</strong>:</p><div class="ip iq gp gr ir ol"><a href="https://app.wandb.ai/sayakpaul/tale-of-quantization/reports/A-Tale-of-Model-Quantization-in-TF-Lite--Vmlldzo5MzQwMA" rel="noopener  ugc nofollow" target="_blank"><div class="om ab fo"><div class="on ab oo cl cj op"><h2 class="bd jq gy z fp oq fr fs or fu fw jp bi translated">TF Lite中模型量化的故事</h2><div class="os l"><h3 class="bd b gy z fp oq fr fs or fu fw dk translated">模型优化策略和量化技术，以帮助在资源中部署机器学习模型…</h3></div><div class="ot l"><p class="bd b dl z fp oq fr fs or fu fw dk translated">app.wandb.ai</p></div></div></div></a></div><p id="205b" class="pw-post-body-paragraph le lf jg lg b lh li kq lj lk ll kt lm ln lo lp lq lr ls lt lu lv lw lx ly lz ij bi translated"><strong class="lg jq"> GitHub </strong>:</p><div class="ip iq gp gr ir ol"><a href="https://github.com/sayakpaul/Adventures-in-TensorFlow-Lite" rel="noopener  ugc nofollow" target="_blank"><div class="om ab fo"><div class="on ab oo cl cj op"><h2 class="bd jq gy z fp oq fr fs or fu fw jp bi translated">sayak Paul/tensor flow-Lite历险记</h2><div class="os l"><h3 class="bd b gy z fp oq fr fs or fu fw dk translated">本资源库包含展示TensorFlow Lite用于量化深度神经网络的笔记本…</h3></div><div class="ot l"><p class="bd b dl z fp oq fr fs or fu fw dk translated">github.com</p></div></div><div class="ou l"><div class="ph l ow ox oy ou oz ix ol"/></div></div></a></div><h1 id="94f1" class="mg mh jg bd mi mj mk ml mm mn mo mp mq kv mr kw ms ky mt kz mu lb mv lc mw mx bi translated">生产中的深度学习</h1><p id="f0db" class="pw-post-body-paragraph le lf jg lg b lh nr kq lj lk ns kt lm ln nt lp lq lr nu lt lu lv nv lx ly lz ij bi translated">一些用于生产的人工智能模型的令人清醒的统计数据，例如“<strong class="lg jq">大多数公司(59%)没有在生产中优化他们的机器学习模型</strong>”(他们应该阅读quantization🧐的前一篇帖子)。如果你喜欢焦虑，那么看看这些新的调查结果，看看企业开发人员每天是如何紧张工作的。仅供参考，TensorFlow在制作上还是很受欢迎的。</p><div class="ip iq gp gr ir ol"><a href="https://neuralmagic.com/blog/deep-learning-survey-results/" rel="noopener  ugc nofollow" target="_blank"><div class="om ab fo"><div class="on ab oo cl cj op"><h2 class="bd jq gy z fp oq fr fs or fu fw jp bi translated">公司缺乏资源将深度学习模型投入生产[调查] -神经魔法</h2><div class="os l"><h3 class="bd b gy z fp oq fr fs or fu fw dk translated">公司通常在生产中有多少深度学习模型？比你想象的要少得多。84%的公司…</h3></div><div class="ot l"><p class="bd b dl z fp oq fr fs or fu fw dk translated">neuralmagic.com</p></div></div><div class="ou l"><div class="pi l ow ox oy ou oz ix ol"/></div></div></a></div><h1 id="24b1" class="mg mh jg bd mi mj mk ml mm mn mo mp mq kv mr kw ms ky mt kz mu lb mv lc mw mx bi translated">本周数据集:TVQA</h1><h1 id="11be" class="mg mh jg bd mi mj mk ml mm mn mo mp mq kv mr kw ms ky mt kz mu lb mv lc mw mx bi translated">这是什么？</h1><p id="430e" class="pw-post-body-paragraph le lf jg lg b lh nr kq lj lk ns kt lm ln nt lp lq lr nu lt lu lv nv lx ly lz ij bi translated">数据集用于视频问答，由来自21，793个剪辑的152，545个问答对组成，跨越460多个小时的视频。</p><h1 id="34ed" class="mg mh jg bd mi mj mk ml mm mn mo mp mq kv mr kw ms ky mt kz mu lb mv lc mw mx bi translated">样本:</h1><figure class="ma mb mc md gt is gh gi paragraph-image"><div role="button" tabindex="0" class="it iu di iv bf iw"><div class="gh gi pj"><img src="../Images/2e5259ad768d0d050e1e498a24a54dfc.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*eMF_SJNa5eOJfaFD.png"/></div></div></figure><h1 id="e9d3" class="mg mh jg bd mi mj mk ml mm mn mo mp mq kv mr kw ms ky mt kz mu lb mv lc mw mx bi translated">它在哪里？</h1><div class="ip iq gp gr ir ol"><a href="http://tvqa.cs.unc.edu/download_tvqa.html" rel="noopener  ugc nofollow" target="_blank"><div class="om ab fo"><div class="on ab oo cl cj op"><h2 class="bd jq gy z fp oq fr fs or fu fw jp bi translated">TVQA数据集</h2><div class="os l"><h3 class="bd b gy z fp oq fr fs or fu fw dk translated">下载链接:tvqa _ QA _ release . tar . gz[15MB]MD5 sum:7 f 751d 611848d 0756 ee4b 760446 ef 7 cf文件包含3个JSON行文件…</h3></div><div class="ot l"><p class="bd b dl z fp oq fr fs or fu fw dk translated">tvqa.cs.unc.edu</p></div></div><div class="ou l"><div class="pk l ow ox oy ou oz ix ol"/></div></div></a></div></div><div class="ab cl nf ng hu nh" role="separator"><span class="ni bw bk nj nk nl"/><span class="ni bw bk nj nk nl"/><span class="ni bw bk nj nk"/></div><div class="ij ik il im in"><blockquote class="pl"><p id="4e94" class="pm pn jg bd po pp pq pr ps pt pu lz dk translated">每周日，我们都会对来自世界各地研究人员的NLP新闻和代码进行一次每周综述。</p><p id="6e92" class="pm pn jg bd po pp pq pr ps pt pu lz dk translated">如果你喜欢这篇文章，请帮助我们并与朋友分享！</p><p id="1c86" class="pm pn jg bd po pp pq pr ps pt pu lz dk translated">如需完整报道，请关注我们的推特:<a class="ae jd" href="http://twitter.com/Quantum_Stat" rel="noopener ugc nofollow" target="_blank"> @Quantum_Stat </a></p></blockquote><figure class="pw px py pz qa is gh gi paragraph-image"><div class="gh gi pv"><img src="../Images/b360b1cd0ddfe26cfbed79252f902f75.png" data-original-src="https://miro.medium.com/v2/resize:fit:108/0*safm5dWXz_yeODbe"/></div><figcaption class="iz ja gj gh gi jb jc bd b be z dk translated">【www.quantumstat.com T4】</figcaption></figure></div></div>    
</body>
</html>