<html>
<head>
<title>Underwater Trash Detection using Opensource Monk Toolkit</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">使用开源Monk工具包进行水下垃圾检测</h1>
<blockquote>原文：<a href="https://pub.towardsai.net/underwater-trash-detection-using-opensource-monk-toolkit-ad902db26ea6?source=collection_archive---------2-----------------------#2020-08-28">https://pub.towardsai.net/underwater-trash-detection-using-opensource-monk-toolkit-ad902db26ea6?source=collection_archive---------2-----------------------#2020-08-28</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><h2 id="d9e4" class="io ip iq bd b dl ir is it iu iv iw dk ix translated" aria-label="kicker paragraph"><a class="ae ep" href="https://towardsai.net/p/category/computer-vision" rel="noopener ugc nofollow" target="_blank">计算机视觉</a></h2><div class=""/><div class=""><h2 id="4023" class="pw-subtitle-paragraph jw iz iq bd b jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn dk translated">这个应用程序的完整代码可以在Monk Object Detection库的<a class="ae ko" href="https://github.com/Tessellate-Imaging/Monk_Object_Detection/blob/master/application_model_zoo/Example%20-%20Underwater%20Trash%20Detection.ipynb" rel="noopener ugc nofollow" target="_blank">应用程序模型动物园</a>中找到</h2></div><h1 id="d748" class="kp kq iq bd kr ks kt ku kv kw kx ky kz kf la kg lb ki lc kj ld kl le km lf lg bi translated">介绍</h1><figure class="li lj lk ll gt lm gh gi paragraph-image"><div role="button" tabindex="0" class="ln lo di lp bf lq"><div class="gh gi lh"><img src="../Images/391cc64a9304b847c4cec687f351522e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/1*QhtCGYn-XAyE8JFto9VwuQ.gif"/></div></div></figure><p id="9d06" class="pw-post-body-paragraph lt lu iq lv b lw lx ka ly lz ma kd mb mc md me mf mg mh mi mj mk ml mm mn mo ij bi translated"><strong class="lv ja">水下垃圾</strong>是一个巨大的环境问题，严重影响水生栖息地。海洋废弃物包括<strong class="lv ja">塑料</strong>、不可生物降解<strong class="lv ja">工业废弃物</strong>、污水污泥、放射性物质堆等。</p><p id="cc0b" class="pw-post-body-paragraph lt lu iq lv b lw lx ka ly lz ma kd mb mc md me mf mg mh mi mj mk ml mm mn mo ij bi translated">根据在<a class="ae ko" href="https://www.condorferries.co.uk/marine-ocean-pollution-statistics-facts" rel="noopener ugc nofollow" target="_blank"> Condor Ferries </a> <br/> ★发表的统计，超过<strong class="lv ja"> 10万只海洋动物因塑料垃圾<br/>而死亡</strong>★据估计，我们的海洋中约有<strong class="lv ja"> 5.25万亿个塑料碎片</strong><br/>★<em class="mp">70%的垃圾碎片沉入海洋</em>，约15%漂浮，其余被冲上岸。</p><p id="98d6" class="pw-post-body-paragraph lt lu iq lv b lw lx ka ly lz ma kd mb mc md me mf mg mh mi mj mk ml mm mn mo ij bi translated"><a class="ae ko" href="https://www.azocleantech.com/article.aspx?ArticleID=1071" rel="noopener ugc nofollow" target="_blank"> <strong class="lv ja">大太平洋垃圾带</strong>，</a>也被称为太平洋垃圾漩涡，横跨夏威夷和加州之间大约617公里。而这还是整个海洋污染的一小部分。</p><p id="5976" class="pw-post-body-paragraph lt lu iq lv b lw lx ka ly lz ma kd mb mc md me mf mg mh mi mj mk ml mm mn mo ij bi translated">为了解决这个问题，许多倡议正在实施，如▹海洋清洁项目、▹清洁海洋项目、▹海滨项目等等！</p><p id="1e53" class="pw-post-body-paragraph lt lu iq lv b lw lx ka ly lz ma kd mb mc md me mf mg mh mi mj mk ml mm mn mo ij bi translated">这些项目的一个关键部分是使用机器人<strong class="lv ja"/><br/>★在比人工清理更短的时间内清理更大的区域。<br/> ★进入人类潜水员无法到达的区域</p><figure class="li lj lk ll gt lm gh gi paragraph-image"><div role="button" tabindex="0" class="ln lo di lp bf lq"><div class="gh gi mq"><img src="../Images/28b3b69465d8888614c20061d65a27c0.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*7iu-mkszqzVo69WvvRF_Hw.jpeg"/></div></div><figcaption class="mr ms gj gh gi mt mu bd b be z dk translated">从海底移除塑料的机器蟹。<a class="ae ko" href="https://www.asme.org/topics-resources/content/a-robot-crab-to-clean-the-ocean" rel="noopener ugc nofollow" target="_blank">学分</a></figcaption></figure><blockquote class="mv mw mx"><p id="6e0c" class="lt lu mp lv b lw lx ka ly lz ma kd mb my md me mf mz mh mi mj na ml mm mn mo ij bi translated"><strong class="lv ja">这些机器人的一个关键组成部分是识别不同的对象并采取相应的行动，这就是深度学习和机器视觉进入该领域的原因！！！</strong></p></blockquote></div><div class="ab cl nb nc hu nd" role="separator"><span class="ne bw bk nf ng nh"/><span class="ne bw bk nf ng nh"/><span class="ne bw bk nf ng"/></div><div class="ij ik il im in"><h1 id="3ff4" class="kp kq iq bd kr ks ni ku kv kw nj ky kz kf nk kg lb ki nl kj ld kl nm km lf lg bi translated">关于数据集和库</h1><p id="581f" class="pw-post-body-paragraph lt lu iq lv b lw nn ka ly lz no kd mb mc np me mf mg nq mi mj mk nr mm mn mo ij bi translated">让我们作为深度学习工程师投入进来，做出最少的贡献，让这个世界变得更美好</p><p id="e562" class="pw-post-body-paragraph lt lu iq lv b lw lx ka ly lz ma kd mb mc md me mf mg mh mi mj mk ml mm mn mo ij bi translated">为了创建一个检测器，我们使用了<a class="ae ko" href="https://conservancy.umn.edu/handle/11299/214366" rel="noopener ugc nofollow" target="_blank"> <strong class="lv ja"> Trash-ICRA19 </strong> </a> <strong class="lv ja">数据集</strong> <br/> *包含5K+训练图像和1K+测试图像<br/> *数据来自海洋废弃物<em class="mp"> J-EDI数据集</em> <br/> *该数据集标记有垃圾和海洋生物的边界框注释。(为了简单起见，我们只对垃圾数据进行训练)</p><p id="fb1e" class="pw-post-body-paragraph lt lu iq lv b lw lx ka ly lz ma kd mb mc md me mf mg mh mi mj mk ml mm mn mo ij bi translated">为了训练和推断，我们将使用<strong class="lv ja"> </strong> <a class="ae ko" href="https://github.com/Tessellate-Imaging/Monk_Object_Detection" rel="noopener ugc nofollow" target="_blank"> <strong class="lv ja"> Monk对象检测库</strong> </a> <br/> *它作为<em class="mp">低代码可轻松安装的包装器</em>用于主要的对象检测算法<br/> *在15+管道上选择的一个这样的算法是<a class="ae ko" href="https://github.com/open-mmlab/mmdetection" rel="noopener ugc nofollow" target="_blank"> <em class="mp"> MMdetection </em> </a></p><figure class="li lj lk ll gt lm gh gi paragraph-image"><div class="gh gi ns"><img src="../Images/15b52951576447f55792be2a2c34b1be.png" data-original-src="https://miro.medium.com/v2/resize:fit:1280/format:webp/1*2LKwtHBGyFLrmVDiq2906w.png"/></div><figcaption class="mr ms gj gh gi mt mu bd b be z dk translated"><strong class="bd kr">支持80多种不同型号的物体检测管道列表</strong></figcaption></figure><blockquote class="mv mw mx"><p id="1dd1" class="lt lu mp lv b lw lx ka ly lz ma kd mb my md me mf mz mh mi mj na ml mm mn mo ij bi translated"><strong class="lv ja"> Monk libraries通过<br/> </strong> ★ <strong class="lv ja">一步到位</strong>安装<br/> ★ <strong class="lv ja">低代码语法</strong> —在不到10行代码中训练<br/> ★ <strong class="lv ja">导出模型</strong>以便轻松推断<br/> ★轻松语法<strong class="lv ja">在任何对象检测管道中摄取自定义数据</strong>。克服更改代码和配置以插入自定义数据集进行训练的麻烦。</p></blockquote></div><div class="ab cl nb nc hu nd" role="separator"><span class="ne bw bk nf ng nh"/><span class="ne bw bk nf ng nh"/><span class="ne bw bk nf ng"/></div><div class="ij ik il im in"><h1 id="c98f" class="kp kq iq bd kr ks ni ku kv kw nj ky kz kf nk kg lb ki nl kj ld kl nm km lf lg bi translated">装置</h1><p id="a2d6" class="pw-post-body-paragraph lt lu iq lv b lw nn ka ly lz no kd mb mc np me mf mg nq mi mj mk nr mm mn mo ij bi translated">安装相当简单<strong class="lv ja"/><br/><em class="mp">*克隆库<br/> *运行安装脚本</em></p><p id="f115" class="pw-post-body-paragraph lt lu iq lv b lw lx ka ly lz ma kd mb mc md me mf mg mh mi mj mk ml mm mn mo ij bi translated">对<br/>▹python-3.6<br/>▹cuda-9.0、9.2、10.0、10.1、10.2 <br/> ▹ <em class="mp">的支持也在colab上运行！！！</em></p><figure class="li lj lk ll gt lm"><div class="bz fp l di"><div class="nt nu l"/></div></figure></div><div class="ab cl nb nc hu nd" role="separator"><span class="ne bw bk nf ng nh"/><span class="ne bw bk nf ng nh"/><span class="ne bw bk nf ng"/></div><div class="ij ik il im in"><h1 id="a7cc" class="kp kq iq bd kr ks ni ku kv kw nj ky kz kf nk kg lb ki nl kj ld kl nm km lf lg bi translated">数据准备</h1><p id="91fc" class="pw-post-body-paragraph lt lu iq lv b lw nn ka ly lz no kd mb mc np me mf mg nq mi mj mk nr mm mn mo ij bi translated">训练数据集按照Pascal VOC格式(XML文件)进行标记</p><figure class="li lj lk ll gt lm gh gi paragraph-image"><div class="gh gi nv"><img src="../Images/0bf43ea2d67c3db53b3c5a117ef784ef.png" data-original-src="https://miro.medium.com/v2/resize:fit:1040/format:webp/1*0RXxI7xIld_GvX9pbr61DQ.png"/></div><figcaption class="mr ms gj gh gi mt mu bd b be z dk translated">PASCAL-VOC格式。<a class="ae ko" href="https://github.com/Tessellate-Imaging/Monk_Object_Detection/blob/master/example_notebooks/sample_dataset/ship/voc/output-000000001.xml" rel="noopener ugc nofollow" target="_blank">学分</a></figcaption></figure><p id="380c" class="pw-post-body-paragraph lt lu iq lv b lw lx ka ly lz ma kd mb mc md me mf mg mh mi mj mk ml mm mn mo ij bi translated">并且训练引擎要求数据为COCO格式</p><figure class="li lj lk ll gt lm gh gi paragraph-image"><div class="gh gi nw"><img src="../Images/0a7c090dba8dd5c8a5041cd861aff09f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1012/format:webp/1*HlCWmkC9DGJwHy3enwAHig.png"/></div><figcaption class="mr ms gj gh gi mt mu bd b be z dk translated">COCO Json格式<a class="ae ko" href="https://github.com/Tessellate-Imaging/Monk_Object_Detection/blob/master/example_notebooks/sample_dataset/ship/annotations/instances_Images.json" rel="noopener ugc nofollow" target="_blank">学分</a></figcaption></figure><p id="7912" class="pw-post-body-paragraph lt lu iq lv b lw lx ka ly lz ma kd mb mc md me mf mg mh mi mj mk ml mm mn mo ij bi translated"><em class="mp">相同的代码(从下载到格式化数据集)可在本</em> <a class="ae ko" href="https://github.com/Tessellate-Imaging/Monk_Object_Detection/blob/master/application_model_zoo/Example%20-%20Underwater%20Trash%20Detection.ipynb" rel="noopener ugc nofollow" target="_blank"> <em class="mp"> Jupyter笔记本</em> </a>中获得</p></div><div class="ab cl nb nc hu nd" role="separator"><span class="ne bw bk nf ng nh"/><span class="ne bw bk nf ng nh"/><span class="ne bw bk nf ng"/></div><div class="ij ik il im in"><h1 id="01dd" class="kp kq iq bd kr ks ni ku kv kw nj ky kz kf nk kg lb ki nl kj ld kl nm km lf lg bi translated">培养</h1><p id="c8d0" class="pw-post-body-paragraph lt lu iq lv b lw nn ka ly lz no kd mb mc np me mf mg nq mi mj mk nr mm mn mo ij bi translated">使用原始的MMdetection库进行训练需要对配置文件和代码的参数进行大量修改。对于Monk，使用简单的pythonic语法更容易做到这一点。</p><p id="e994" class="pw-post-body-paragraph lt lu iq lv b lw lx ka ly lz ma kd mb mc md me mf mg mh mi mj mk ml mm mn mo ij bi translated"><em class="mp">完整代码可在本</em> <a class="ae ko" href="https://github.com/Tessellate-Imaging/Monk_Object_Detection/blob/master/application_model_zoo/Example%20-%20Underwater%20Trash%20Detection.ipynb" rel="noopener ugc nofollow" target="_blank"> <em class="mp"> jupyter笔记本</em> </a> <em class="mp">中找到。(下面提到的都是相同的重要片段)</em></p><figure class="li lj lk ll gt lm"><div class="bz fp l di"><div class="nt nu l"/></div></figure><p id="0d31" class="pw-post-body-paragraph lt lu iq lv b lw lx ka ly lz ma kd mb mc md me mf mg mh mi mj mk ml mm mn mo ij bi translated">★步骤1 —导入并启动培训引擎</p><figure class="li lj lk ll gt lm"><div class="bz fp l di"><div class="nt nu l"/></div></figure><p id="f6c8" class="pw-post-body-paragraph lt lu iq lv b lw lx ka ly lz ma kd mb mc md me mf mg mh mi mj mk ml mm mn mo ij bi translated">★步骤2 —将训练和验证数据集路径添加到检测器</p><figure class="li lj lk ll gt lm"><div class="bz fp l di"><div class="nt nu l"/></div></figure><p id="f788" class="pw-post-body-paragraph lt lu iq lv b lw lx ka ly lz ma kd mb mc md me mf mg mh mi mj mk ml mm mn mo ij bi translated">★步骤3 —设置数据集参数<br/> *注意:批量大小为8需要10 GB的RAM</p><figure class="li lj lk ll gt lm gh gi paragraph-image"><div class="gh gi nx"><img src="../Images/dd576484cb6a1f6ef2ace8d6c058df77.png" data-original-src="https://miro.medium.com/v2/resize:fit:1266/format:webp/1*7EjZUMXcoJbpo0Eqy-rOBg.png"/></div></figure><p id="13ec" class="pw-post-body-paragraph lt lu iq lv b lw lx ka ly lz ma kd mb mc md me mf mg mh mi mj mk ml mm mn mo ij bi translated">★步骤4 —从35种不同的型号中选择型号</p><p id="18ef" class="pw-post-body-paragraph lt lu iq lv b lw lx ka ly lz ma kd mb mc md me mf mg mh mi mj mk ml mm mn mo ij bi translated"><em class="mp">在本教程中，我们将使用retinanet_r50_fpn(关于此型号的更多详细信息，请参见附录)</em></p><figure class="li lj lk ll gt lm"><div class="bz fp l di"><div class="nt nu l"/></div></figure><p id="7899" class="pw-post-body-paragraph lt lu iq lv b lw lx ka ly lz ma kd mb mc md me mf mg mh mi mj mk ml mm mn mo ij bi translated">★步骤5—设置学习率和sgd优化器参数</p><p id="497f" class="pw-post-body-paragraph lt lu iq lv b lw lx ka ly lz ma kd mb mc md me mf mg mh mi mj mk ml mm mn mo ij bi translated">★步骤6——设置训练和验证的时期数</p><figure class="li lj lk ll gt lm gh gi paragraph-image"><div role="button" tabindex="0" class="ln lo di lp bf lq"><div class="gh gi ny"><img src="../Images/091641d688371e5dc2d65d6d2d01396a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*rIb6ae-DBrbp3o_KUH3VOA.png"/></div></div></figure><p id="722c" class="pw-post-body-paragraph lt lu iq lv b lw lx ka ly lz ma kd mb mc md me mf mg mh mi mj mk ml mm mn mo ij bi translated">★开始训练流程！！！</p><p id="fcd2" class="pw-post-body-paragraph lt lu iq lv b lw lx ka ly lz ma kd mb mc md me mf mg mh mi mj mk ml mm mn mo ij bi translated">一旦模型被训练，我们就在样本图像或视频上测试模型</p></div><div class="ab cl nb nc hu nd" role="separator"><span class="ne bw bk nf ng nh"/><span class="ne bw bk nf ng nh"/><span class="ne bw bk nf ng"/></div><div class="ij ik il im in"><h1 id="cf38" class="kp kq iq bd kr ks ni ku kv kw nj ky kz kf nk kg lb ki nl kj ld kl nm km lf lg bi translated">推理</h1><p id="9c41" class="pw-post-body-paragraph lt lu iq lv b lw nn ka ly lz no kd mb mc np me mf mg nq mi mj mk nr mm mn mo ij bi translated">使用Monk运行推理甚至更简单</p><figure class="li lj lk ll gt lm"><div class="bz fp l di"><div class="nt nu l"/></div></figure><p id="d76a" class="pw-post-body-paragraph lt lu iq lv b lw lx ka ly lz ma kd mb mc md me mf mg mh mi mj mk ml mm mn mo ij bi translated">★步骤1 —导入并启动推理机</p><figure class="li lj lk ll gt lm"><div class="bz fp l di"><div class="nt nu l"/></div></figure><p id="1358" class="pw-post-body-paragraph lt lu iq lv b lw lx ka ly lz ma kd mb mc md me mf mg mh mi mj mk ml mm mn mo ij bi translated">★步骤2 —加载训练好的模型</p><figure class="li lj lk ll gt lm"><div class="bz fp l di"><div class="nt nu l"/></div></figure><p id="b4f3" class="pw-post-body-paragraph lt lu iq lv b lw lx ka ly lz ma kd mb mc md me mf mg mh mi mj mk ml mm mn mo ij bi translated">★步骤3—对图像进行推理</p><figure class="li lj lk ll gt lm gh gi paragraph-image"><div role="button" tabindex="0" class="ln lo di lp bf lq"><div class="gh gi lh"><img src="../Images/8e4a98b12d4c5eb23c5b4ec1fd2bdd2d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*X0LzMOzwE2hbdwZlFNU8Og.png"/></div></div><figcaption class="mr ms gj gh gi mt mu bd b be z dk translated">最终输出可以以这种方式显示在jupyter笔记本中！！</figcaption></figure><p id="f8bb" class="pw-post-body-paragraph lt lu iq lv b lw lx ka ly lz ma kd mb mc md me mf mg mh mi mj mk ml mm mn mo ij bi translated">在Nvidia V-100 GPU上，检测器平均运行速度为15 fps。为了修剪和优化模型，需要将它输入TensorRT引擎，很快将会发布一个<em class="mp">教程。</em></p><p id="6fcf" class="pw-post-body-paragraph lt lu iq lv b lw lx ka ly lz ma kd mb mc md me mf mg mh mi mj mk ml mm mn mo ij bi translated">搞定了。！！同样的引擎<strong class="lv ja">可以部署在任何地方</strong>。<em class="mp">即将发布在raspi-board和Nvidia nano板上部署的教程。</em></p><p id="2378" class="pw-post-body-paragraph lt lu iq lv b lw lx ka ly lz ma kd mb mc md me mf mg mh mi mj mk ml mm mn mo ij bi translated">您可以使用该库来试验不同的模型，如级联RCNN或更快的RCNN；甚至可以从<a class="ae ko" href="https://github.com/Tessellate-Imaging/Monk_Object_Detection" rel="noopener ugc nofollow" target="_blank"> Monk对象检测库</a>中试验不同的管道，如Tensorflow对象检测API<a class="ae ko" href="https://github.com/Tessellate-Imaging/Monk_Object_Detection/tree/master/12_tf_obj_1" rel="noopener ugc nofollow" target="_blank">v 1.0</a>或<a class="ae ko" href="https://github.com/Tessellate-Imaging/Monk_Object_Detection/tree/master/13_tf_obj_2" rel="noopener ugc nofollow" target="_blank"> V2.0、</a>或<a class="ae ko" href="https://github.com/Tessellate-Imaging/Monk_Object_Detection/tree/master/7_yolov3" rel="noopener ugc nofollow" target="_blank"> YoloV3、</a>等</p><p id="c9a0" class="pw-post-body-paragraph lt lu iq lv b lw lx ka ly lz ma kd mb mc md me mf mg mh mi mj mk ml mm mn mo ij bi translated">编码快乐！</p></div><div class="ab cl nb nc hu nd" role="separator"><span class="ne bw bk nf ng nh"/><span class="ne bw bk nf ng nh"/><span class="ne bw bk nf ng"/></div><div class="ij ik il im in"><h1 id="3e06" class="kp kq iq bd kr ks ni ku kv kw nj ky kz kf nk kg lb ki nl kj ld kl nm km lf lg bi translated">附录— 1</h1><p id="e343" class="pw-post-body-paragraph lt lu iq lv b lw nn ka ly lz no kd mb mc np me mf mg nq mi mj mk nr mm mn mo ij bi translated">关于RetinaNet架构和培训细节</p><p id="09f3" class="pw-post-body-paragraph lt lu iq lv b lw lx ka ly lz ma kd mb mc md me mf mg mh mi mj mk ml mm mn mo ij bi translated">根据<a class="ae ko" href="https://keras.io/examples/vision/retinanet/" rel="noopener ugc nofollow" target="_blank"> Keras网站</a>上提供的信息</p><p id="07d4" class="pw-post-body-paragraph lt lu iq lv b lw lx ka ly lz ma kd mb mc md me mf mg mh mi mj mk ml mm mn mo ij bi translated"><strong class="lv ja"> RetinaNet </strong>是一个<br/> ★ <strong class="lv ja">单级</strong>检测器<br/> ★使用<strong class="lv ja">特征金字塔网络</strong>在多个尺度上高效检测物体<br/> ★引入了一个新的损失<strong class="lv ja">焦点损失函数</strong>，以缓解前景-背景类别极度不平衡的问题</p><p id="adb9" class="pw-post-body-paragraph lt lu iq lv b lw lx ka ly lz ma kd mb mc md me mf mg mh mi mj mk ml mm mn mo ij bi translated">作为基础网络，在本教程中，我们使用<strong class="lv ja"> Resnet50 </strong>模型从图像中提取特征</p><p id="c586" class="pw-post-body-paragraph lt lu iq lv b lw lx ka ly lz ma kd mb mc md me mf mg mh mi mj mk ml mm mn mo ij bi translated">关于retinanet的更多支持文献<br/> * <a class="ae ko" href="https://www.wandb.com/articles/object-detection-with-retinanet" rel="noopener ugc nofollow" target="_blank">使用Retinanet进行对象检测</a><br/>*<a class="ae ko" href="https://medium.com/@14prakash/the-intuition-behind-retinanet-eb636755607d" rel="noopener">retina net背后的直觉</a></p><p id="e264" class="pw-post-body-paragraph lt lu iq lv b lw lx ka ly lz ma kd mb mc md me mf mg mh mi mj mk ml mm mn mo ij bi translated">关于训练的附加细节使用<strong class="lv ja"> Resnet50 </strong>作为基础模型提取<br/>特征<br/> * <strong class="lv ja">焦点损失</strong>用于retinanet的分类分支<br/> * <strong class="lv ja"> L1回归损失</strong>用于FPN bbox估计器分支<br/> * <strong class="lv ja"> SGD </strong>具有动量功能的优化器用于训练<br/> * <strong class="lv ja">学习率</strong>预定<strong class="lv ja">每减少一个</strong></p></div><div class="ab cl nb nc hu nd" role="separator"><span class="ne bw bk nf ng nh"/><span class="ne bw bk nf ng nh"/><span class="ne bw bk nf ng"/></div><div class="ij ik il im in"><h1 id="6149" class="kp kq iq bd kr ks ni ku kv kw nj ky kz kf nk kg lb ki nl kj ld kl nm km lf lg bi translated">附录— 2</h1><p id="f243" class="pw-post-body-paragraph lt lu iq lv b lw nn ka ly lz no kd mb mc np me mf mg nq mi mj mk nr mm mn mo ij bi translated">更多关于僧库的信息</p><figure class="li lj lk ll gt lm gh gi paragraph-image"><div role="button" tabindex="0" class="ln lo di lp bf lq"><div class="gh gi nz"><img src="../Images/7d96706a615152128c44585082951f8b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*aeJLgRpDM4cfZ4E90Drigw.png"/></div></div></figure><p id="7882" class="pw-post-body-paragraph lt lu iq lv b lw lx ka ly lz ma kd mb mc md me mf mg mh mi mj mk ml mm mn mo ij bi translated"><strong class="lv ja">整套包括3个库:</strong></p><p id="c026" class="pw-post-body-paragraph lt lu iq lv b lw lx ka ly lz ma kd mb mc md me mf mg mh mi mj mk ml mm mn mo ij bi translated">★ <a class="ae ko" href="https://github.com/Tessellate-Imaging/monk_v1" rel="noopener ugc nofollow" target="_blank">和尚形象分类</a></p><figure class="li lj lk ll gt lm gh gi paragraph-image"><div class="gh gi oa"><img src="../Images/962e7cd3748f88e01e5c2791aac1c616.png" data-original-src="https://miro.medium.com/v2/resize:fit:1396/format:webp/1*2L9zHI2EDXTrTzejmLdAuw.png"/></div></figure><p id="2502" class="pw-post-body-paragraph lt lu iq lv b lw lx ka ly lz ma kd mb mc md me mf mg mh mi mj mk ml mm mn mo ij bi translated">★ <a class="ae ko" href="https://github.com/Tessellate-Imaging/Monk_Object_Detection" rel="noopener ugc nofollow" target="_blank">和尚物体检测</a></p><figure class="li lj lk ll gt lm gh gi paragraph-image"><div class="gh gi ob"><img src="../Images/a8ef95ad1870c81c3d558658178e2bae.png" data-original-src="https://miro.medium.com/v2/resize:fit:1042/format:webp/1*vNL-fgcR03-dQSUZfO00qg.png"/></div></figure><p id="eb2f" class="pw-post-body-paragraph lt lu iq lv b lw lx ka ly lz ma kd mb mc md me mf mg mh mi mj mk ml mm mn mo ij bi translated">★和尚工作室</p><figure class="li lj lk ll gt lm gh gi paragraph-image"><div role="button" tabindex="0" class="ln lo di lp bf lq"><div class="gh gi oc"><img src="../Images/b8ec5df40e8e5b80f7d334d76fb7c1e6.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*i0IJXlkAd2jU1H8fLR8-FQ.png"/></div></div></figure></div></div>    
</body>
</html>