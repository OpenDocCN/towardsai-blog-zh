<html>
<head>
<title>Google Stock Predictions using an LSTM Neural Network</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">使用LSTM神经网络的谷歌股票预测</h1>
<blockquote>原文：<a href="https://pub.towardsai.net/google-stock-predictions-using-an-lstm-neural-network-dbe785949a96?source=collection_archive---------0-----------------------#2020-05-13">https://pub.towardsai.net/google-stock-predictions-using-an-lstm-neural-network-dbe785949a96?source=collection_archive---------0-----------------------#2020-05-13</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><h2 id="f802" class="ir is it bd b dl iu iv iw ix iy iz dk ja translated" aria-label="kicker paragraph">深度学习</h2><div class=""/><div class=""><h2 id="66bf" class="pw-subtitle-paragraph jz jc it bd b ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq dk translated">使用香草LSTM进行股票预测</h2></div><p id="107f" class="pw-post-body-paragraph kr ks it kt b ku kv kd kw kx ky kg kz la lb lc ld le lf lg lh li lj lk ll lm im bi translated"><a class="ae ln" href="http://www.michelangiolo.best/" rel="noopener ugc nofollow" target="_blank"> <strong class="kt jd">点击这里了解我，我的项目，我的最新文章。</strong>T3】</a></p><p id="b577" class="pw-post-body-paragraph kr ks it kt b ku kv kd kw kx ky kg kz la lb lc ld le lf lg lh li lj lk ll lm im bi translated">时间序列是一种很难管理的数据格式。与横截面数据相比，预测时间序列的未来结果是一种可以直接应用机器学习算法而无需准备数据的数据格式，属于无监督学习的领域。</p><p id="35e8" class="pw-post-body-paragraph kr ks it kt b ku kv kd kw kx ky kg kz la lb lc ld le lf lg lh li lj lk ll lm im bi translated"><strong class="kt jd">* * *免责声明</strong>:尽管看起来令人兴奋，但这是一个金融分析模型的低分辨率模拟。现实世界的模型要复杂得多，需要多变量数据，并且不限于单个人工智能，而是一组人工智能一起工作。因此，只使用这个模型来训练建立神经网络:不要试图在真实交易中使用它，因为它不复杂，所以缺乏可靠性。</p><figure class="lp lq lr ls gt lt gh gi paragraph-image"><div role="button" tabindex="0" class="lu lv di lw bf lx"><div class="gh gi lo"><img src="../Images/7326a1dcc86d51fc654811fc955b9487.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*EdQvNGS9jXEVU0UCzL9q5A.png"/></div></div></figure><p id="79c2" class="pw-post-body-paragraph kr ks it kt b ku kv kd kw kx ky kg kz la lb lc ld le lf lg lh li lj lk ll lm im bi translated"><a class="ae ln" href="https://github.com/arditoibryan/GOOG-Stock-predictions" rel="noopener ugc nofollow" target="_blank"> <strong class="kt jd">完整代码</strong>可在我的存储库(包括。简历和笔记本)。</a> <a class="ae ln" href="https://gist.github.com/arditoibryan/1fd5fabf36512732ef00bce85d992132" rel="noopener ugc nofollow" target="_blank">如果您只想使用<strong class="kt jd">要点</strong>，请点击此链接。</a></p><h1 id="f6f5" class="ma mb it bd mc md me mf mg mh mi mj mk ki ml kj mm kl mn km mo ko mp kp mq mr bi translated">整个过程</h1><p id="8721" class="pw-post-body-paragraph kr ks it kt b ku ms kd kw kx mt kg kz la mu lc ld le mv lg lh li mw lk ll lm im bi translated">为了创建一个能够进行预测的神经网络，我将使用所谓的LSTM(长短期记忆模型)。如前所述，我们不能使用监督学习问题的相同方法。需要以适当的方式准备数据，以便LSTM能够处理这些数据:</p><figure class="lp lq lr ls gt lt gh gi paragraph-image"><div role="button" tabindex="0" class="lu lv di lw bf lx"><div class="gh gi mx"><img src="../Images/5b31258bb96a29bbe9c997ea38e569cb.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*NoGWA1CJoWXGasldp6o91g.png"/></div></div><figcaption class="my mz gj gh gi na nb bd b be z dk translated">我们将要构建的整个模型的可视化</figcaption></figure><p id="7bc0" class="pw-post-body-paragraph kr ks it kt b ku kv kd kw kx ky kg kz la lb lc ld le lf lg lh li lj lk ll lm im bi translated">流程中的步骤:</p><ol class=""><li id="f99c" class="nc nd it kt b ku kv kx ky la ne le nf li ng lm nh ni nj nk bi translated">导入模块</li><li id="258c" class="nc nd it kt b ku nl kx nm la nn le no li np lm nh ni nj nk bi translated">导入df</li><li id="8b77" class="nc nd it kt b ku nl kx nm la nn le no li np lm nh ni nj nk bi translated">测向预处理</li><li id="fe89" class="nc nd it kt b ku nl kx nm la nn le no li np lm nh ni nj nk bi translated">df转换为监督问题</li><li id="6cc2" class="nc nd it kt b ku nl kx nm la nn le no li np lm nh ni nj nk bi translated">df分为X_train、y_train、X_test、y_test</li><li id="cd29" class="nc nd it kt b ku nl kx nm la nn le no li np lm nh ni nj nk bi translated">将输入整形为[样本，n _输入_时间步长，n _特征]</li><li id="2789" class="nc nd it kt b ku nl kx nm la nn le no li np lm nh ni nj nk bi translated">创建LSTM模式</li><li id="304c" class="nc nd it kt b ku nl kx nm la nn le no li np lm nh ni nj nk bi translated">使用X_train，y_train拟合模型</li><li id="1459" class="nc nd it kt b ku nl kx nm la nn le no li np lm nh ni nj nk bi translated">对前进的每一步进行评估</li><li id="56f6" class="nc nd it kt b ku nl kx nm la nn le no li np lm nh ni nj nk bi translated">对输出进行反向预处理</li><li id="9f45" class="nc nd it kt b ku nl kx nm la nn le no li np lm nh ni nj nk bi translated">实数值的反向预处理</li><li id="9c4b" class="nc nd it kt b ku nl kx nm la nn le no li np lm nh ni nj nk bi translated">比较预测和估计</li></ol><h1 id="ced2" class="ma mb it bd mc md me mf mg mh mi mj mk ki ml kj mm kl mn km mo ko mp kp mq mr bi translated">tf _数据集_提取器</h1><p id="de3f" class="pw-post-body-paragraph kr ks it kt b ku ms kd kw kx mt kg kz la mu lc ld le mv lg lh li mw lk ll lm im bi translated">为了加快预处理速度，我将使用我的名为<a class="ae ln" href="https://github.com/arditoibryan/General" rel="noopener ugc nofollow" target="_blank"> tf_dataset_extractor的个人库，可以从这个链接获得。</a>该库包含两个用于快速预处理的类。如果您希望了解每个预处理步骤的细节，您可以简单地查看里面的代码。</p><pre class="lp lq lr ls gt nq nr ns nt aw nu bi"><span id="31e6" class="nv mb it nr b gy nw nx l ny nz">import sys<br/>sys.path.append('/content/drive/My Drive/Colab Notebooks/TensorFlow 2.0/modules')</span><span id="9dac" class="nv mb it nr b gy oa nx l ny nz">import pandas as pd<br/>import tf_dataset_extractor as e<br/>#import grapher_v1_1 as g<br/>#import LSTM_creator_v1_0 as l<br/>v = e.v<br/>l = e.l</span></pre><p id="af2c" class="pw-post-body-paragraph kr ks it kt b ku kv kd kw kx ky kg kz la lb lc ld le lf lg lh li lj lk ll lm im bi translated">我将从实例化tf_dataset_extractor中的两个类开始:</p><ul class=""><li id="20c6" class="nc nd it kt b ku kv kx ky la ne le nf li ng lm ob ni nj nk bi translated">“v”实例化了一个包含横截面数据预处理算法的类</li><li id="805d" class="nc nd it kt b ku nl kx nm la nn le no li np lm ob ni nj nk bi translated">“l”实例化一个包含时序数据预处理算法的类</li></ul><h1 id="409d" class="ma mb it bd mc md me mf mg mh mi mj mk ki ml kj mm kl mn km mo ko mp kp mq mr bi translated">GOOG股票</h1><pre class="lp lq lr ls gt nq nr ns nt aw nu bi"><span id="e685" class="nv mb it nr b gy nw nx l ny nz">#import dataset<br/>v.upload.online_csv('/content/drive/My Drive/Colab Notebooks/TensorFlow 2.0/csv/GOOG.csv')<br/>e.K = v.upload.make_backup()</span></pre><p id="d6c6" class="pw-post-body-paragraph kr ks it kt b ku kv kd kw kx ky kg kz la lb lc ld le lf lg lh li lj lk ll lm im bi translated">为了您的方便，我已经将谷歌股票(GOOG)1年的股票表现保存在一个. csv文件中，您可以在这里下载。因为我用的是Google Colab，所以会从我的个人硬盘加载。您可以下载。csv并从自己的路径导入。</p><h1 id="3c2a" class="ma mb it bd mc md me mf mg mh mi mj mk ki ml kj mm kl mn km mo ko mp kp mq mr bi translated">预处理</h1><p id="aaec" class="pw-post-body-paragraph kr ks it kt b ku ms kd kw kx mt kg kz la mu lc ld le mv lg lh li mw lk ll lm im bi translated">我们将需要我们将要创建的分区的两个副本。将只对原始副本进行规范化，而第二个副本将先进行规范化，然后进行标准化。保留两个副本的原因是，我们需要将输出重新转换为初始比例。到时候我会解释详细的程序。</p><h2 id="f3ef" class="nv mb it bd mc oc od dn mg oe of dp mk la og oh mm le oi oj mo li ok ol mq iz bi translated">仅标准化</h2><pre class="lp lq lr ls gt nq nr ns nt aw nu bi"><span id="f684" class="nv mb it nr b gy nw nx l ny nz">#preprocessing with normalization only<br/>v.upload.retrieve_backup(e.K)</span><span id="3e24" class="nv mb it nr b gy oa nx l ny nz">#dropping extra columns<br/>e.X = e.X.drop(['High', 'Low', 'Close', 'Adj Close', 'Volume'], axis=1)</span><span id="36d7" class="nv mb it nr b gy oa nx l ny nz">#preprocessing<br/>index = e.X.pop('Date')<br/>scaler, e.X = v.partition.scale('all_df', scaler='MinMaxScaler', df=e.X, to_float=True, return_df=True)<br/>e.X = e.X.set_index(index)<br/>e.X = l.preprocessing.series_to_supervised(e.X, 3, 1)</span><span id="9ff7" class="nv mb it nr b gy oa nx l ny nz">#X, y<br/>v.extract.labels(['var1(t)'])</span><span id="3e9c" class="nv mb it nr b gy oa nx l ny nz">#train, test<br/>X_train_, X_test_ = l.preprocessing.split(0.1, e.X)<br/>y_train_, y_test_ = l.preprocessing.split(0.1, e.y)<br/>e.X_ = e.X.copy()<br/>e.y_ = e.y.copy()<br/>print(X_train_.shape, X_test_.shape, y_train_.shape, y_test_.shape)</span></pre><p id="66a7" class="pw-post-body-paragraph kr ks it kt b ku kv kd kw kx ky kg kz la lb lc ld le lf lg lh li lj lk ll lm im bi translated">正如我们所看到的，我们存储的所有变量都有一个_作为后缀，以区别于其他变量。</p><pre class="lp lq lr ls gt nq nr ns nt aw nu bi"><span id="061c" class="nv mb it nr b gy nw nx l ny nz">import matplotlib.pyplot as plt<br/>fig=plt.figure(figsize=(20, 10), dpi= 80)<br/>fig=plt.plot(e.y)</span></pre><figure class="lp lq lr ls gt lt gh gi paragraph-image"><div role="button" tabindex="0" class="lu lv di lw bf lx"><div class="gh gi om"><img src="../Images/a20c2a433668f5e1c4adb66c8a657474.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*XfFFKfqMlWI7xgmfWrO1sA.png"/></div></div></figure><p id="3e6a" class="pw-post-body-paragraph kr ks it kt b ku kv kd kw kx ky kg kz la lb lc ld le lf lg lh li lj lk ll lm im bi translated">到目前为止，我们的数据只在从0到1的范围内进行了调整。</p><h2 id="f8a6" class="nv mb it bd mc oc od dn mg oe of dp mk la og oh mm le oi oj mo li ok ol mq iz bi translated">规范化+标准化</h2><pre class="lp lq lr ls gt nq nr ns nt aw nu bi"><span id="8c22" class="nv mb it nr b gy nw nx l ny nz">#preprocessing with normalization and standardization<br/>v.upload.retrieve_backup(e.K)</span><span id="43dd" class="nv mb it nr b gy oa nx l ny nz">#dropping extra columns<br/>e.X = e.X.drop(['High', 'Low', 'Close', 'Adj Close', 'Volume'], axis=1)</span><span id="d95d" class="nv mb it nr b gy oa nx l ny nz">#preprocessing<br/>index = e.X.pop('Date')<br/>scaler, e.X = v.partition.scale('all_df', scaler='MinMaxScaler', df=e.X, to_float=True, return_df=True)<br/>e.X = e.X.set_index(index)<br/>l.preprocessing.transform_to_stationary()<br/>e.X = l.preprocessing.series_to_supervised(e.X, 3, 1, drop_col=False)</span><span id="1b82" class="nv mb it nr b gy oa nx l ny nz">#X, y<br/>v.extract.labels(['var1(t)'])</span><span id="106b" class="nv mb it nr b gy oa nx l ny nz">#train, test<br/>X_train, X_test = l.preprocessing.split(0.1, e.X)<br/>y_train, y_test = l.preprocessing.split(0.1, e.y) #sembra non servire a nulla<br/>print(X_train.shape, X_test.shape, y_train.shape, y_test.shape)</span></pre><p id="fb37" class="pw-post-body-paragraph kr ks it kt b ku kv kd kw kx ky kg kz la lb lc ld le lf lg lh li lj lk ll lm im bi translated">以上所有变量都以no _为后缀。我们实际上不需要保存所有这些副本。实际上，这些代码中的大部分并不是真正必要的，但是对我来说解释起来会更容易。要知道我们将保留一个规范化的副本(在每个变量的末尾用_定义)和整个df的一个规范化+标准化的副本。</p><pre class="lp lq lr ls gt nq nr ns nt aw nu bi"><span id="922f" class="nv mb it nr b gy nw nx l ny nz">import matplotlib.pyplot as plt<br/>fig=plt.figure(figsize=(20, 10), dpi= 80)<br/>fig=plt.plot(e.y_)</span></pre><figure class="lp lq lr ls gt lt gh gi paragraph-image"><div role="button" tabindex="0" class="lu lv di lw bf lx"><div class="gh gi on"><img src="../Images/f56a3a63142a80612f8d6cd94611a129.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*e6VS4a_N1Z1zx6vpdiV52g.png"/></div></div></figure><p id="dffc" class="pw-post-body-paragraph kr ks it kt b ku kv kd kw kx ky kg kz la lb lc ld le lf lg lh li lj lk ll lm im bi translated">这就是一个规范化+标准化的预处理的样子。我们会把这些数据传送给LSTM，它会做出预测。</p><h1 id="9421" class="ma mb it bd mc md me mf mg mh mi mj mk ki ml kj mm kl mn km mo ko mp kp mq mr bi translated">输入和输出</h1><p id="6d4f" class="pw-post-body-paragraph kr ks it kt b ku ms kd kw kx mt kg kz la mu lc ld le mv lg lh li mw lk ll lm im bi translated">在预处理过程中，我们隔离了数据集e.y和e.X。如果我们在分割前查看这两个数据集，基本上我们得到的结果是:</p><ul class=""><li id="4d81" class="nc nd it kt b ku kv kx ky la ne le nf li ng lm ob ni nj nk bi translated">投入</li></ul><pre class="lp lq lr ls gt nq nr ns nt aw nu bi"><span id="e0a9" class="nv mb it nr b gy nw nx l ny nz">e.X.head()</span></pre><figure class="lp lq lr ls gt lt gh gi paragraph-image"><div class="gh gi oo"><img src="../Images/7da7821a6d0332c02cc399e619cf8f31.png" data-original-src="https://miro.medium.com/v2/resize:fit:708/format:webp/1*3F5rkfiRG6XI1iooyQ-zCg.png"/></div></figure><pre class="lp lq lr ls gt nq nr ns nt aw nu bi"><span id="d07c" class="nv mb it nr b gy nw nx l ny nz">import matplotlib.pyplot as plt<br/>fig=plt.figure(figsize=(20, 10), dpi= 80)<br/>fig=plt.plot(e.X)</span></pre><figure class="lp lq lr ls gt lt gh gi paragraph-image"><div role="button" tabindex="0" class="lu lv di lw bf lx"><div class="gh gi op"><img src="../Images/e35a3ab5fdeb58e84783350fdc424c0e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*hoZ3sIymp61F4ByxnR15Og.png"/></div></div></figure><p id="6711" class="pw-post-body-paragraph kr ks it kt b ku kv kd kw kx ky kg kz la lb lc ld le lf lg lh li lj lk ll lm im bi translated">我们只取了时间为0的股票数据集，我们移动了三次，将每次移动存储在不同的列中，结果得到了上图。这叫做<strong class="kt jd">滞后</strong>。LSTM将向后看三步，做出一步的未来预测。</p><ul class=""><li id="8934" class="nc nd it kt b ku kv kx ky la ne le nf li ng lm ob ni nj nk bi translated">输出</li></ul><pre class="lp lq lr ls gt nq nr ns nt aw nu bi"><span id="44ce" class="nv mb it nr b gy nw nx l ny nz">e.y.head()</span></pre><figure class="lp lq lr ls gt lt gh gi paragraph-image"><div class="gh gi oq"><img src="../Images/3d7bc57fd84b340518bd82f94e711969.png" data-original-src="https://miro.medium.com/v2/resize:fit:274/format:webp/1*UveK9tm31kbS1yWaapIWjQ.png"/></div></figure><p id="1e56" class="pw-post-body-paragraph kr ks it kt b ku kv kd kw kx ky kg kz la lb lc ld le lf lg lh li lj lk ll lm im bi translated">我们将使用标签来训练LSTM。在这种情况下，我们希望LSTM只着眼于未来的一步，因此只有一列。</p><h1 id="1c6b" class="ma mb it bd mc md me mf mg mh mi mj mk ki ml kj mm kl mn km mo ko mp kp mq mr bi translated">剧烈的</h1><p id="4778" class="pw-post-body-paragraph kr ks it kt b ku ms kd kw kx mt kg kz la mu lc ld le mv lg lh li mw lk ll lm im bi translated">正如你在上面的代码中看到的，我们的数据集将被分割成X_train，y_train，X_test，y_test。我们将使用训练集来训练我们的AI，X_test来进行预测，最后，y_test来比较估计值和真实数据。</p><h1 id="a20b" class="ma mb it bd mc md me mf mg mh mi mj mk ki ml kj mm kl mn km mo ko mp kp mq mr bi translated">为LSTM准备投入</h1><p id="04a1" class="pw-post-body-paragraph kr ks it kt b ku ms kd kw kx mt kg kz la mu lc ld le mv lg lh li mw lk ll lm im bi translated">作为输入，我们将使用我们的列var1(t)。因为它的原始形状是(225，3)，我们将需要以LSTM可以理解的形式重新塑造它:[samples，n_input_timesteps，n_features]。</p><pre class="lp lq lr ls gt nq nr ns nt aw nu bi"><span id="3adb" class="nv mb it nr b gy nw nx l ny nz">#reshape [samples, n_input_timesteps, n_features]<br/>X_train = X_train.reshape((225, 3, 1))<br/>y_train = y_train.reshape((225, 1, 1))<br/>print(X_train.shape, y_train.shape)<br/>#every individual sample has dimensions [1, 3, 1]</span></pre><p id="e4c6" class="pw-post-body-paragraph kr ks it kt b ku kv kd kw kx ky kg kz la lb lc ld le lf lg lh li lj lk ll lm im bi translated">每一个单独的样本，例如，第一行:</p><pre class="lp lq lr ls gt nq nr ns nt aw nu bi"><span id="8c98" class="nv mb it nr b gy nw nx l ny nz">X_train[0]<br/>array([[0.00970626], [0.00680232], [0.01252675]])</span></pre><p id="b338" class="pw-post-body-paragraph kr ks it kt b ku kv kd kw kx ky kg kz la lb lc ld le lf lg lh li lj lk ll lm im bi translated">将有维度(1，3，1)。</p><h1 id="e09d" class="ma mb it bd mc md me mf mg mh mi mj mk ki ml kj mm kl mn km mo ko mp kp mq mr bi translated">香草LSTM</h1><p id="f64d" class="pw-post-body-paragraph kr ks it kt b ku ms kd kw kx mt kg kz la mu lc ld le mv lg lh li mw lk ll lm im bi translated">我们终于可以为我们的神经网络创建模型了。我将使用的LSTM被称为香草LSTM，是一种用于单变量时间序列预测的简单形式的神经网络，它只包含一个密集层:</p><pre class="lp lq lr ls gt nq nr ns nt aw nu bi"><span id="1005" class="nv mb it nr b gy nw nx l ny nz">#LSTM<br/>%tensorflow_version 2.x<br/>import tensorflow as tf<br/>from tensorflow.keras import Sequential<br/>from tensorflow.keras import layers<br/>from tensorflow.keras.layers import Dense<br/>from tensorflow.keras.layers import LSTM</span><span id="e1eb" class="nv mb it nr b gy oa nx l ny nz">model = Sequential()<br/>model.add(LSTM(50, batch_input_shape=(1, 3, 1), stateful=True))<br/>model.add(Dense(1))<br/>model.compile(loss=’mean_squared_error’, optimizer=’adam’)</span><span id="ebdc" class="nv mb it nr b gy oa nx l ny nz">model.fit(X_train, y_train, epochs=3000, batch_size=1, verbose=2, shuffle=False)<br/>model.reset_states()<br/>X_test = X_test.reshape(24, 3, 1)<br/>y_test = y_test.reshape(24, 1, 1)<br/>print(X_test.shape, y_test.shape)</span><span id="58d7" class="nv mb it nr b gy oa nx l ny nz">...<br/>Epoch 2998/3000 225/225 - 0s - loss: 1.7274e-04 <br/>Epoch 2999/3000 225/225 - 0s - loss: 2.9163e-04 <br/>Epoch 3000/3000 225/225 - 0s - loss: 2.8836e-04 <br/>(24, 3, 1) (24, 1, 1)</span></pre><h1 id="f701" class="ma mb it bd mc md me mf mg mh mi mj mk ki ml kj mm kl mn km mo ko mp kp mq mr bi translated">预言；预测；预告</h1><p id="a643" class="pw-post-body-paragraph kr ks it kt b ku ms kd kw kx mt kg kz la mu lc ld le mv lg lh li mw lk ll lm im bi translated">我们可以将我们的预测存储在一个名为<em class="or"> yhat </em>的列表中:</p><pre class="lp lq lr ls gt nq nr ns nt aw nu bi"><span id="7173" class="nv mb it nr b gy nw nx l ny nz">#make a one-step forecast<br/>yhat = model.predict(X_test, verbose=2, batch_size=1) <br/>#without batch_size the model only accepts one input at a time<br/>yhat<br/>24/24 - 0s <br/>[<br/>[ 0.0721423 ]  <br/>[-0.13979942]  <br/>[ 0.02534528]  <br/>[-0.15360811]  <br/>[ 0.04295617]  <br/>[ 0.14269553]  <br/>[ 0.06470203]  <br/>[ 0.02760611]  <br/>[ 0.03455507]  <br/>[-0.13316691]  <br/>[ 0.03844658]  <br/>[-0.00989904]  <br/>[ 0.08717629]  <br/>[ 0.00703726]  <br/>[-0.05191287]  <br/>[ 0.00792047]  <br/>[-0.0025476 ]  <br/>[ 0.01022832]  <br/>[ 0.06648263]  <br/>[ 0.05616217]  <br/>[ 0.03048991]  <br/>[-0.02833473]  <br/>[ 0.00622515]  <br/>[-0.0042644 ]<br/>]</span></pre><p id="76a1" class="pw-post-body-paragraph kr ks it kt b ku kv kd kw kx ky kg kz la lb lc ld le lf lg lh li lj lk ll lm im bi translated">不幸的是，如前所述，我们的预测将得出相同比例的输入，这已经标准化，然后缩放。我们将不得不颠倒这些过程，以得到一个我们可以实际比较的数据尺度。</p><figure class="lp lq lr ls gt lt gh gi paragraph-image"><div role="button" tabindex="0" class="lu lv di lw bf lx"><div class="gh gi os"><img src="../Images/c5a366d787b55756075261ba35f54fdf.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*j1gUUfPSXh83MbxGeaI8rw.png"/></div></div></figure><p id="8eb1" class="pw-post-body-paragraph kr ks it kt b ku kv kd kw kx ky kg kz la lb lc ld le lf lg lh li lj lk ll lm im bi translated">为了反演数据，我们将需要y_test_和我们的预测的原始副本。y_test_ it是数据的真实版本，因此我们想要获得的比例(例如1300，现在它的对等数字是. 0009)。因为预测<em class="or"> yhat </em>已经被标准化，然后被固定化，它们只不过是一个缺口的集合。我们将把这些缺口添加到y_test_的规范化版本中。</p><pre class="lp lq lr ls gt nq nr ns nt aw nu bi"><span id="493a" class="nv mb it nr b gy nw nx l ny nz">#invert preprocessing on predicted data<br/>#remove stationary<br/>y_test = y_test.reshape(24, 1)</span><span id="dc09" class="nv mb it nr b gy oa nx l ny nz">var1 = y_test_    #original values<br/>var2 = yhat       #gaps<br/>var3 = list()     #</span><span id="a94e" class="nv mb it nr b gy oa nx l ny nz">#var1 = var1.values<br/>#var2 = var2.values</span><span id="8f76" class="nv mb it nr b gy oa nx l ny nz">var3.append(var1[0])<br/>for i in range(0, len(var2)):<br/>  values = var1[i] + var2[i]<br/>  var3.append(values)<br/>  var3</span></pre><p id="82ee" class="pw-post-body-paragraph kr ks it kt b ku kv kd kw kx ky kg kz la lb lc ld le lf lg lh li lj lk ll lm im bi translated">在这一点上，我们仍然有我们的预测的标准化版本。我们颠倒预处理，我们有数以千计的规模。</p><pre class="lp lq lr ls gt nq nr ns nt aw nu bi"><span id="bd69" class="nv mb it nr b gy nw nx l ny nz">#inverse scaling<br/>predicted = scaler.inverse_transform(var3)<br/>predicted<br/>array([<br/>[1350.19995824],        <br/>[1384.98480799],        <br/>[1209.65298139],        <br/>[1217.52072549],        <br/>[1185.93480519],        <br/>[1270.41216402],        <br/>[1194.80344785],        <br/>[1210.19733755],        <br/>[1109.31081349],        <br/>[1109.77145847],        <br/>[ 992.30088891],        <br/>[1111.58781353],        <br/>[1130.94699481],        <br/>[1103.35372615],        <br/>[1107.16316306],        <br/>[1101.43918236],        <br/>[1115.61908397],        <br/>[1124.44163555],        <br/>[1129.97183253],        <br/>[1179.35603071],        <br/>[1149.07968629],        <br/>[1112.96137088],        <br/>[1105.35280738],        <br/>[1141.00156137],        <br/>[1218.94379394]<br/>])</span></pre><h1 id="9230" class="ma mb it bd mc md me mf mg mh mi mj mk ki ml kj mm kl mn km mo ko mp kp mq mr bi translated">预期</h1><p id="583e" class="pw-post-body-paragraph kr ks it kt b ku ms kd kw kx mt kg kz la mu lc ld le mv lg lh li mw lk ll lm im bi translated">显示实际发生了什么的标记数据只是被规范化了(这就是为什么它有_作为后缀)。我们只需要使用我们从一开始就保存的<strong class="kt jd">缩放器</strong>将它恢复到正常比例。</p><pre class="lp lq lr ls gt nq nr ns nt aw nu bi"><span id="cfd2" class="nv mb it nr b gy nw nx l ny nz">#invert preprocessing on expected data<br/>#inverse scaling<br/>expected = scaler.inverse_transform(y_test_)<br/>expected<br/>array([<br/>[1350.2  ],        <br/>[1277.06 ],        <br/>[1205.3  ],        <br/>[1260.   ],        <br/>[1249.7  ],        <br/>[1126.   ],        <br/>[1179.   ],        <br/>[1096.   ],        <br/>[1093.11 ],        <br/>[1056.51 ],        <br/>[1093.05 ],        <br/>[1135.72 ],        <br/>[1061.32 ],        <br/>[1103.77 ],        <br/>[1126.47 ],        <br/>[1111.8  ],        <br/>[1125.67 ],        <br/>[1125.04 ],        <br/>[1147.3  ],        <br/>[1122.   ],        <br/>[1098.26 ],        <br/>[1119.015],        <br/>[1138.   ],        <br/>[1221.   ],        <br/>[1206.5  ]<br/>], dtype=float32)</span></pre><h1 id="4db1" class="ma mb it bd mc md me mf mg mh mi mj mk ki ml kj mm kl mn km mo ko mp kp mq mr bi translated">比较</h1><p id="8aba" class="pw-post-body-paragraph kr ks it kt b ku ms kd kw kx mt kg kz la mu lc ld le mv lg lh li mw lk ll lm im bi translated">我们准备将<strong class="kt jd">预测值</strong>与<strong class="kt jd">预期值</strong>进行比较，看看它们有多接近:</p><pre class="lp lq lr ls gt nq nr ns nt aw nu bi"><span id="49dc" class="nv mb it nr b gy nw nx l ny nz">for i in range(len(y_test_)):<br/>  print('iteration=%d, Predicted=%f, Expected=%f' % (i+1,   predicted[i], expected[i]))<br/>iteration=1, Predicted=1350.199958, Expected=1350.199951 iteration=2, Predicted=1384.984808, Expected=1277.060059 iteration=3, Predicted=1209.652981, Expected=1205.300049 iteration=4, Predicted=1217.520725, Expected=1260.000000 iteration=5, Predicted=1185.934805, Expected=1249.699951 iteration=6, Predicted=1270.412164, Expected=1126.000000 iteration=7, Predicted=1194.803448, Expected=1179.000000 iteration=8, Predicted=1210.197338, Expected=1096.000000 iteration=9, Predicted=1109.310813, Expected=1093.109985 iteration=10, Predicted=1109.771458, Expected=1056.510010 iteration=11, Predicted=992.300889, Expected=1093.050049 iteration=12, Predicted=1111.587814, Expected=1135.719971 iteration=13, Predicted=1130.946995, Expected=1061.319946 iteration=14, Predicted=1103.353726, Expected=1103.770020 iteration=15, Predicted=1107.163163, Expected=1126.469971 iteration=16, Predicted=1101.439182, Expected=1111.800049 iteration=17, Predicted=1115.619084, Expected=1125.670044 iteration=18, Predicted=1124.441636, Expected=1125.040039 iteration=19, Predicted=1129.971833, Expected=1147.300049 iteration=20, Predicted=1179.356031, Expected=1122.000000 iteration=21, Predicted=1149.079686, Expected=1098.260010 iteration=22, Predicted=1112.961371, Expected=1119.015015 iteration=23, Predicted=1105.352807, Expected=1138.000000 iteration=24, Predicted=1141.001561, Expected=1221.000000 iteration=25, Predicted=1218.943794, Expected=1206.500000</span></pre><h1 id="a636" class="ma mb it bd mc md me mf mg mh mi mj mk ki ml kj mm kl mn km mo ko mp kp mq mr bi translated">绘制图形</h1><pre class="lp lq lr ls gt nq nr ns nt aw nu bi"><span id="a4fd" class="nv mb it nr b gy nw nx l ny nz">import matplotlib.pyplot as plt</span><span id="2f12" class="nv mb it nr b gy oa nx l ny nz">fig=plt.figure(figsize=(20, 10), dpi=80)<br/>fig=plt.plot(expected)<br/>fig=plt.plot(predicted)</span></pre><figure class="lp lq lr ls gt lt gh gi paragraph-image"><div role="button" tabindex="0" class="lu lv di lw bf lx"><div class="gh gi lo"><img src="../Images/946f52c238af139b834599a2f1041c2f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*8_19J-sIc9TDO6_KhwA9jQ.png"/></div></div></figure><h1 id="d00b" class="ma mb it bd mc md me mf mg mh mi mj mk ki ml kj mm kl mn km mo ko mp kp mq mr bi translated">评估绩效</h1><p id="7341" class="pw-post-body-paragraph kr ks it kt b ku ms kd kw kx mt kg kz la mu lc ld le mv lg lh li mw lk ll lm im bi translated">正如我们所看到的，这个模型并不太准确。然而，在股票市场上，我们不能简单地根据单一变量进行预测，这是不现实的；这就是为什么我们需要更复杂的模型来进行估计。</p><pre class="lp lq lr ls gt nq nr ns nt aw nu bi"><span id="2ff6" class="nv mb it nr b gy nw nx l ny nz"># report performance<br/>from math import *<br/>from sklearn.metrics import mean_squared_error</span><span id="867f" class="nv mb it nr b gy oa nx l ny nz">rmse = sqrt(mean_squared_error(expected, predicted))<br/>print(‘Test RMSE: %.3f’ % rmse)<br/>Test RMSE: 58.232</span></pre></div></div>    
</body>
</html>