# 提高面向任务的对话式人工智能代理性能的 5 种方法

> 原文：<https://pub.towardsai.net/5-ways-to-improve-the-performance-of-your-task-based-conversational-ai-agent-1b3ae7db5f94?source=collection_archive---------2----------------------->

## [自然语言处理](https://towardsai.net/p/category/nlp)

## 根据我在 ConvAI 第二次 NLP 研讨会上学到的知识

![](img/56f632517ea02ec7c643b578d75995c0.png)

来源:https://sites.google.com/view/2ndnlp4convai/home

# 介绍

在本文中，我将总结 5 个想法来改进构成面向任务的对话代理的各种组件。我是在参加与 ACL 2020 一起举办的第二届对话式人工智能 NLP 研讨会时了解到这些想法的。

如果你对我在主要的 ACL 2020 会议上学到的想法感兴趣，请查看我在 ACL 2020 文章中学到的 [5 个机器学习想法。](https://medium.com/towards-artificial-intelligence/5-machine-learning-ideas-i-learned-at-acl-2020-781750387c53)

# 概观

以下是本文将涉及的观点:

1.  构建对自动语音识别(ASR)错误具有鲁棒性的嵌入
2.  一种构建对 ASR 错误具有鲁棒性的代理的数据扩充技术
3.  使用上下文信息来改进槽填充
4.  将元学习应用于意图分类和槽填充
5.  为意图分类构建计算高效的文本表示

# 主意

## 构建对自动语音识别(ASR)错误具有鲁棒性的嵌入

接受语音作为输入的代理通常具有 ASR 模块，该 ASR 模块将用户的话语从音频转录为文本，然后将其传递给自然语言理解(NLU)模块进行进一步处理，例如意图分类、槽填充、攻击性过滤等。

这种设置的挑战是 ASR 模块中的错误会传播到下游模块。一类特别令人烦恼的 ASR 错误是对声学上相似但语义上不同的单词的错误识别，例如“fare”被转录为“fair”。

[1]提出了一种新颖的微调方法来解决这个问题。他们的方法包括微调语境化的单词嵌入，例如带有附加损失项的 ELMo。该损失项被设计成使得发音相似的单词的余弦相似性最大化，从而 ASR 模块容易混淆的单词对将具有相似的向量表示。

在 ATIS 数据集(既有音频记录又有用户话语的手动转录文本)上的实验表明，当针对音频记录进行评估时，他们的方法优于不使用他们的微调方法的基线。当针对转录文本进行评估时，他们的方法产生了与基线模型相同的结果。

他们实现的代码在 [**Github**](https://github.com/MiuLab/SpokenVec) **上。**

## 一种构建对 ASR 错误具有鲁棒性的代理的数据扩充技术

当话语的音频记录可用时，在[1]中描述的用于减轻 ASR 错误的影响的方法工作良好。当情况并非如此时，可以考虑[2]提出的思路。

[2]基本上建立了一个模拟器来模拟 ASR 假设。然后将这些假设添加到训练数据中。ASR 假设模拟器的细节在[3]中描述。

这种方法的主要优点是不需要对代理的任何组件进行任何更改。因此，这种方法可以被视为其他方法的补充，以构建对 ASR 错误具有鲁棒性的代理。

此外，作者还表明，他们的方法将更有利于简单的模型架构，而不是复杂的架构，例如手套嵌入与 BERT。因此，当在受模型大小、计算能力或延迟限制的环境中构建代理时，这是一种很有前途的技术。

## 使用上下文信息来改进槽填充

槽填充任务通常被视为序列标记任务。如今，组成话语的文本使用语境化嵌入(如 ELMo、BERT)转换为向量。根据[4],在将上下文结合到嵌入中方面可以做得更多:

> …现有模型以受限的
> 方式使用上下文信息，例如使用自我关注。这些方法不能区分上下文对单词表示和单词标签的影响。

作者使用 BiLSTM 架构来生成用于执行槽填充任务的特征序列。为了将更多的上下文结合到生成的特征中，他们建议在多任务设置中使用以下辅助任务来训练模型:

1.  最大化话语中每个单词与其上下文的互信息
2.  仅使用其上下文来预测话语中每个单词的标签
3.  对于话语中的每个句子，使用 BiLSTM 层的输出来预测出现在句子中的标签。

在这种情况下，作者报告了在 SNIPS、ATIS 和 EditMe 数据集上的最新研究结果。他们的消融研究表明，辅助任务 2 对他们的模型性能的贡献最大。

## 将元学习应用于意图分类和槽填充

[5]提出了一种称为少量拍摄意图分类/槽填充的任务。他们基于 ATIS、TOPS 和 SNIPS 数据集为这项任务建立了一个基准。

他们研究的元学习方法是原型网络和模型不可知元学习(MAML)。被评估的模型是 BiLSTM 模型的变体，其中输入嵌入来自 GloVe、ELMo + GloVe 或 BERT 嵌入。

这篇论文的一个令人惊讶的结果是，作者试图微调 BERT 导致了较差的结果。

## 构建计算高效的文本表示

[6]是我在研讨会上最喜欢的论文，因为它的实用性和可重复性。

在本文中，作者将从通用句子编码器和转换模型获得的话语表示串联起来，冻结它们，并在其上训练一个多层感知器来执行意图分类。这种方法在 CLINC150、HWU64 和 BANKING 77 数据集上产生了最先进的结果。

BANKING 77 数据集是作者贡献的一个新数据集，它只覆盖了一个领域(银行业)，但具有非常细粒度的意图。它包括 13，083 个客户服务查询，标记有 77 个意向。

除了简单之外，这种方法还有以下好处:

*   少量拍摄设置中的卓越性能
*   对超参数的选择不变
*   能够在不使用 GPU 或 TPU 的情况下进行训练和推理

复制论文中描述的结果的代码是[这里是](https://github.com/PolyAI-LDN/polyai-models/tree/master/intent_detection)。

# 结论

本文总结了 5 个有助于提高面向任务的对话代理性能的想法。

如果你想了解更多，请查阅参考资料。

# 参考

[1] [学习 ASR——健壮的语境化嵌入用于口语理解](https://arxiv.org/abs/1909.10861)。黄和陈。2019

[2] [对语音识别错误稳健的训练对话模型的数据增强](https://arxiv.org/abs/2006.05635)。王等人。艾尔。2020

[3] [研究用于学习会话错误恢复的对话策略的错误模拟技术](https://arxiv.org/abs/1911.03378)。法泽尔-扎兰迪等人。艾尔。2019

[4] [利用上下文信息改进槽填充](https://arxiv.org/abs/1911.01680)。Veyseh 等人。艾尔。2019

[5] [学习对意图和槽标签进行分类，给出一些例子](https://arxiv.org/abs/2004.10793)。克朗等人。艾尔。2020

[6] [使用双语句编码器进行有效的意图检测](https://arxiv.org/abs/2003.04807)。卡萨努埃瓦等人。艾尔。2020