<html>
<head>
<title>Meta-Learning in Dialog Generation</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">对话生成中的元学习</h1>
<blockquote>原文：<a href="https://pub.towardsai.net/meta-learning-in-dialog-generation-41367e397086?source=collection_archive---------0-----------------------#2020-03-20">https://pub.towardsai.net/meta-learning-in-dialog-generation-41367e397086?source=collection_archive---------0-----------------------#2020-03-20</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="19a3" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">学会学习</h2></div><blockquote class="ki kj kk"><p id="a022" class="kl km kn ko b kp kq ju kr ks kt jx ku kv kw kx ky kz la lb lc ld le lf lg lh im bi translated">与众所周知的数据集不同，我们现实生活中的问题域总是只有很小的标记数据集，而我们可能无法在这种情况下训练出一个好的模型。<a class="ae li" href="https://towardsdatascience.com/data-augmentation-library-for-text-9661736b13ff" rel="noopener" target="_blank">数据扩充</a>是生成语法数据的方法之一，而元学习是解决这个问题的另一种方法。</p><p id="67d0" class="kl km kn ko b kp kq ju kr ks kt jx ku kv kw kx ky kz la lb lc ld le lf lg lh im bi translated">在这一系列的故事中，我们将经历不同的元学习方法。这项任务的动机之一是，即使是孩子也可以通过举一个例子来识别一个物体。模型不学习对特定类别进行分类，而是学习区分输入的模式。这一系列的元学习将涵盖NLP中的零镜头学习、一镜头学习、少镜头学习、元学习。</p></blockquote><figure class="lk ll lm ln gt lo gh gi paragraph-image"><div role="button" tabindex="0" class="lp lq di lr bf ls"><div class="gh gi lj"><img src="../Images/b8da281434461e8d7a84940a4dfa4280.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*tS0r_FBNv8lO4-la"/></div></div><figcaption class="lv lw gj gh gi lx ly bd b be z dk translated">由<a class="ae li" href="https://unsplash.com/@lucabravo?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">卢卡·布拉沃</a>在<a class="ae li" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上拍摄的照片</figcaption></figure><p id="a8e4" class="pw-post-body-paragraph kl km it ko b kp kq ju kr ks kt jx ku lz kw kx ky ma la lb lc mb le lf lg lh im bi translated">在这个故事中，我们将介绍两种在对话生成中应用元学习的方法。在客户服务领域，公司需要雇用一名客户服务代表来支持客户的需求。随着业务的增长，CS部门需要线性扩展。因此，对话系统被引入来解决这个问题。怎样才能建立一个对话系统，让它能自动和客户“聊天”？</p><p id="296c" class="pw-post-body-paragraph kl km it ko b kp kq ju kr ks kt jx ku lz kw kx ky ma la lb lc mb le lf lg lh im bi translated">作为元学习系列之一，我们将讨论元学习在对话生成中的应用。本文将介绍几种方法，包括<code class="fe mc md me mf b">Domain Adaptive Dialog Generation via Meta Learning</code>(钱、于，2019) <code class="fe mc md me mf b">Personalizing Dialogue Agents via Meta-Learning</code>(林等，2019)<code class="fe mc md me mf b">Memory-Augmented Recurrent Networks for Dialogue Coherence</code>(多纳休等，2019)</p><h1 id="092f" class="mg mh it bd mi mj mk ml mm mn mo mp mq jz mr ka ms kc mt kd mu kf mv kg mw mx bi translated"><code class="fe mc md me mf b">Domain Adaptive Dialog Generation via Meta Learning</code></h1><p id="9902" class="pw-post-body-paragraph kl km it ko b kp my ju kr ks mz jx ku lz na kx ky ma nb lb lc mb nc lf lg lh im bi translated">钱和于提出了基于元学习的领域自适应对话生成方法(<code class="fe mc md me mf b">DAML</code>)，扩展了模式不可知元学习<code class="fe mc md me mf b">(MAML)</code> (Finn et al .，2017)。<code class="fe mc md me mf b">DAML</code>它是通过利用多个单域对话数据，仅用少量训练样本就适应一个新的域来训练的。</p><blockquote class="ki kj kk"><p id="e483" class="kl km kn ko b kp kq ju kr ks kt jx ku kv kw kx ky kz la lb lc ld le lf lg lh im bi translated"><code class="fe mc md me mf b"><em class="it">Model-Agnostic Meta-Learning (MAML)</em></code>由Finn等人在2017年提出。这是一个与模型无关的框架。模型不可知意味着它不是特定于模型的。Finn等人在回归、分类和强化学习问题上对该框架进行了评估，结果令人满意。如果你不熟悉这个故事，你可以看看它的更多细节。</p></blockquote><p id="4d97" class="pw-post-body-paragraph kl km it ko b kp kq ju kr ks kt jx ku lz kw kx ky ma la lb lc mb le lf lg lh im bi translated">为了设置实验，作者使用3个领域数据(即，“餐馆”、“天气”和“公共汽车信息搜索”)来训练初始化模型并针对目标领域(即“电影信息搜索”)进行微调</p><p id="ec59" class="pw-post-body-paragraph kl km it ko b kp kq ju kr ks kt jx ku lz kw kx ky ma la lb lc mb le lf lg lh im bi translated">训练程序遵循<code class="fe mc md me mf b">MAML</code>的做法(Finn et al .，2017)。首先，计算损失(#2)并更新临时模型的局部梯度(#3)。对于每一批数据，它将计算损失并一次又一次地更新局部梯度。完成一批数据后，将计算最终损失(#5)以更新全局梯度(#7)。</p><figure class="lk ll lm ln gt lo gh gi paragraph-image"><div class="gh gi nd"><img src="../Images/b880c907477ad89e86965e98c6c55e6c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1010/format:webp/1*1fk3H6sCBmiRODAPRjJPIA.png"/></div><figcaption class="lv lw gj gh gi lx ly bd b be z dk translated">训练程序(钱，于，2019)</figcaption></figure><h1 id="4144" class="mg mh it bd mi mj mk ml mm mn mo mp mq jz mr ka ms kc mt kd mu kf mv kg mw mx bi translated">通过元学习个性化对话代理</h1><p id="bf09" class="pw-post-body-paragraph kl km it ko b kp my ju kr ks mz jx ku lz na kx ky ma nb lb lc mb nc lf lg lh im bi translated">林等(2019)提出将<code class="fe mc md me mf b">MAML</code> (Finn等，2017)应用于个性化对话代理问题。人物角色不可知的元学习(PAML)通过利用来自同一用户的少量对话样本来适应新的人物角色。</p><p id="97d9" class="pw-post-body-paragraph kl km it ko b kp kq ju kr ks kt jx ku lz kw kx ky ma la lb lc mb le lf lg lh im bi translated">模型输入是人物角色描述(每人几个句子)和对话(一组话语)，输出是回应。设置类似于DAML除了PAML包括人物描述。</p><figure class="lk ll lm ln gt lo gh gi paragraph-image"><div class="gh gi ne"><img src="../Images/6619be255debba70fbd556e62348db11.png" data-original-src="https://miro.medium.com/v2/resize:fit:1182/format:webp/1*501LGuylYWlNJGcErFc5mQ.png"/></div><figcaption class="lv lw gj gh gi lx ly bd b be z dk translated">输入(人物和对话)和输出(生成的响应)的例子(林等，2019)</figcaption></figure><p id="cd6a" class="pw-post-body-paragraph kl km it ko b kp kq ju kr ks kt jx ku lz kw kx ky ma la lb lc mb le lf lg lh im bi translated">训练程序遵循<code class="fe mc md me mf b">MAML</code> (Finn et al .，2017)的惯例。<code class="fe mc md me mf b">MAML</code> (Finn et al .，2017)和正常训练的主要区别是第4步到第8步。该模型评估该批数据，并随后更新优化器(即步骤9)。</p><figure class="lk ll lm ln gt lo gh gi paragraph-image"><div class="gh gi nf"><img src="../Images/810686cf97543b114e352af79631dfab.png" data-original-src="https://miro.medium.com/v2/resize:fit:1006/format:webp/1*r45W-acuIaog-zWWMbm3Ig.png"/></div><figcaption class="lv lw gj gh gi lx ly bd b be z dk translated">训练程序(林等，2019)</figcaption></figure><h1 id="6d0f" class="mg mh it bd mi mj mk ml mm mn mo mp mq jz mr ka ms kc mt kd mu kf mv kg mw mx bi translated">对话连贯性的记忆增强递归网络</h1><p id="5728" class="pw-post-body-paragraph kl km it ko b kp my ju kr ks mz jx ku lz na kx ky ma nb lb lc mb nc lf lg lh im bi translated">Donahue等人在应用记忆增强元学习来解决对话系统问题时，没有扩展MAML (Charles等人，2017)的方法。他们提出了两种架构，分别是<code class="fe mc md me mf b">Memory-augmented dialogue with dual NTMs (D-NTMS)</code>和<code class="fe mc md me mf b">Single-NTM language model dialogue system (NTM-LM)</code>。</p><blockquote class="ki kj kk"><p id="dd4e" class="kl km kn ko b kp kq ju kr ks kt jx ku kv kw kx ky kz la lb lc ld le lf lg lh im bi translated"><a class="ae li" href="https://arxiv.org/pdf/1410.5401.pdf" rel="noopener ugc nofollow" target="_blank">神经图灵机</a> (NTM)是Graves等人在2014年提出的。一个快速的总结是，模型的回复既取决于内部记忆(即RNN隐藏状态)又取决于外部记忆(即神经网络之外的记忆库)来决定输出。如果你不熟悉这个故事，你可以看看它的更多细节。</p></blockquote><p id="8488" class="pw-post-body-paragraph kl km it ko b kp kq ju kr ks kt jx ku lz kw kx ky ma la lb lc mb le lf lg lh im bi translated">直觉上，我们应该分开处理发言者，因为我们认为发言者应该有不同的角色、背景和其他属性。由于这种差异，如果在单个模型(在这种情况下是单个神经调音器)中处理所有扬声器，模型可能会受到影响并导致性能降级。因此，双重NTM建筑的灵感。不同的说话者的话语馈入特定的NTM以读取和更新外部记忆。</p><figure class="lk ll lm ln gt lo gh gi paragraph-image"><div role="button" tabindex="0" class="lp lq di lr bf ls"><div class="gh gi ng"><img src="../Images/19d1d650cf19aefeb4db6862903c7c1a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*5ewIOTF6mTzL6ZUdVsmAAw.png"/></div></div><figcaption class="lv lw gj gh gi lx ly bd b be z dk translated">采用双ntm的记忆增强对话架构(D-NTMS) (Donahue等人，2019年)</figcaption></figure><p id="3891" class="pw-post-body-paragraph kl km it ko b kp kq ju kr ks kt jx ku lz kw kx ky ma la lb lc mb le lf lg lh im bi translated">然而，Donahue等人发现，前述模型可能难以交换对话，并导致糟糕的性能。因此，提出了第二种方法。它利用GRU来处理多个序列问题，并且只使用一个NTM来进行外部存储器操作。</p><figure class="lk ll lm ln gt lo gh gi paragraph-image"><div role="button" tabindex="0" class="lp lq di lr bf ls"><div class="gh gi nh"><img src="../Images/1a7f74ab7f728b07e72fcad2140bbabe.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*7yrh8dxiUPdSC7gEJi5NHg.png"/></div></div><figcaption class="lv lw gj gh gi lx ly bd b be z dk translated">单一NTM语言模型对话系统(NTM-LM)架构(多纳休等人，2019年)</figcaption></figure><p id="5a78" class="pw-post-body-paragraph kl km it ko b kp kq ju kr ks kt jx ku lz kw kx ky ma la lb lc mb le lf lg lh im bi translated">从实验结果来看，NTM-LM的性能优于传统的Seq2Seq和D-NTMS结构。</p><figure class="lk ll lm ln gt lo gh gi paragraph-image"><div class="gh gi ni"><img src="../Images/780e8f27b2c7f57b06ebbf7676636344.png" data-original-src="https://miro.medium.com/v2/resize:fit:920/format:webp/1*xjCJhMNjhU4k_wwVeE2f-w.png"/></div><figcaption class="lv lw gj gh gi lx ly bd b be z dk translated">Ubuntu对话语料库数据集上的性能比较(Donahue et al .，2019)</figcaption></figure><h1 id="2d48" class="mg mh it bd mi mj mk ml mm mn mo mp mq jz mr ka ms kc mt kd mu kf mv kg mw mx bi translated">拿走</h1><ul class=""><li id="be6d" class="nj nk it ko b kp my ks mz lz nl ma nm mb nn lh no np nq nr bi translated">DAML通过多种丰富的资源数据进行训练，有针对性地快速学习新领域。</li><li id="4806" class="nj nk it ko b kp ns ks nt lz nu ma nv mb nw lh no np nq nr bi translated">PAML通过人物角色数据和目标来快速学习新的人物角色。</li><li id="c921" class="nj nk it ko b kp ns ks nt lz nu ma nv mb nw lh no np nq nr bi translated">单独处理发言者的发言可能不会产生好的结果。您可以在目标数据集上执行进一步的实验。</li></ul><h1 id="0a9d" class="mg mh it bd mi mj mk ml mm mn mo mp mq jz mr ka ms kc mt kd mu kf mv kg mw mx bi translated">喜欢学习？</h1><p id="49f6" class="pw-post-body-paragraph kl km it ko b kp my ju kr ks mz jx ku lz na kx ky ma nb lb lc mb nc lf lg lh im bi translated">我是湾区的数据科学家。关注数据科学的最新发展，尤其是NLP、数据扩充和平台相关领域。在<a class="ae li" href="https://www.linkedin.com/in/edwardma1026" rel="noopener ugc nofollow" target="_blank"> LinkedIn </a>或<a class="ae li" href="https://github.com/makcedward" rel="noopener ugc nofollow" target="_blank"> Github </a>上随时联系<a class="ae li" href="https://makcedward.github.io/" rel="noopener ugc nofollow" target="_blank"> me </a>。</p><h1 id="be7f" class="mg mh it bd mi mj mk ml mm mn mo mp mq jz mr ka ms kc mt kd mu kf mv kg mw mx bi translated">延伸阅读</h1><ul class=""><li id="00e4" class="nj nk it ko b kp my ks mz lz nl ma nm mb nn lh no np nq nr bi translated">模型不可知的元学习解释</li><li id="bc24" class="nj nk it ko b kp ns ks nt lz nu ma nv mb nw lh no np nq nr bi translated">记忆增强的元学习解释</li><li id="16db" class="nj nk it ko b kp ns ks nt lz nu ma nv mb nw lh no np nq nr bi translated">DAML实现(<a class="ae li" href="https://github.com/qbetterk/DAML" rel="noopener ugc nofollow" target="_blank"> PyTorch </a>)</li><li id="f2b1" class="nj nk it ko b kp ns ks nt lz nu ma nv mb nw lh no np nq nr bi translated">PAML实现(<a class="ae li" href="https://github.com/HLTCHKUST/PAML" rel="noopener ugc nofollow" target="_blank"> PyTorch </a>)</li></ul><h1 id="1470" class="mg mh it bd mi mj mk ml mm mn mo mp mq jz mr ka ms kc mt kd mu kf mv kg mw mx bi translated">参考</h1><ul class=""><li id="3b82" class="nj nk it ko b kp my ks mz lz nl ma nm mb nn lh no np nq nr bi translated">C.芬恩、p .阿贝耳和s .莱文。<a class="ae li" href="https://arxiv.org/pdf/1703.03400.pdf" rel="noopener ugc nofollow" target="_blank">用于深度网络快速适应的模型不可知元学习</a>。2017.</li><li id="8387" class="nj nk it ko b kp ns ks nt lz nu ma nv mb nw lh no np nq nr bi translated">K.钱与俞正声。<a class="ae li" href="https://arxiv.org/pdf/1906.03520.pdf" rel="noopener ugc nofollow" target="_blank">通过元学习的领域自适应对话生成</a>。2019.</li><li id="5dde" class="nj nk it ko b kp ns ks nt lz nu ma nv mb nw lh no np nq nr bi translated">Z.林，马多托，吴春生，冯佩凤。<a class="ae li" href="https://arxiv.org/pdf/1905.10033.pdf" rel="noopener ugc nofollow" target="_blank">通过元学习个性化对话代理</a>。2019.</li><li id="aed6" class="nj nk it ko b kp ns ks nt lz nu ma nv mb nw lh no np nq nr bi translated">D.多纳休、y .孟和a .拉姆斯基。<a class="ae li" href="https://arxiv.org/pdf/1910.10487.pdf" rel="noopener ugc nofollow" target="_blank">用于对话连贯性的记忆增强递归网络</a>。2019</li></ul></div></div>    
</body>
</html>