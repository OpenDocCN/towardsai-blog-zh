<html>
<head>
<title>Fully Explained OPTICS Clustering with Python Example</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">使用Python示例全面解释光学聚类</h1>
<blockquote>原文：<a href="https://pub.towardsai.net/fully-explained-optics-clustering-with-python-example-4553108fa04b?source=collection_archive---------0-----------------------#2021-08-17">https://pub.towardsai.net/fully-explained-optics-clustering-with-python-example-4553108fa04b?source=collection_archive---------0-----------------------#2021-08-17</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><h2 id="9818" class="ir is it bd b dl iu iv iw ix iy iz dk ja translated" aria-label="kicker paragraph"><a class="ae ep" href="https://towardsai.net/p/category/machine-learning" rel="noopener ugc nofollow" target="_blank">机器学习</a></h2><div class=""/><div class=""><h2 id="080a" class="pw-subtitle-paragraph jz jc it bd b ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq dk translated">无监督机器学习算法</h2></div><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div class="gh gi kr"><img src="../Images/dd35517adf0eac57209e68ff150d2481.png" data-original-src="https://miro.medium.com/v2/resize:fit:1334/format:webp/1*m-MnxwOGcrZMFWL6l-m5cA.png"/></div></figure><p id="fa28" class="pw-post-body-paragraph kz la it lb b lc ld kd le lf lg kg lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><strong class="lb jd">光学:聚类技术</strong></p><p id="0ab4" class="pw-post-body-paragraph kz la it lb b lc ld kd le lf lg kg lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">众所周知，聚类是一种强大的无监督知识发现工具，目前用于将我们的数据点划分为相似特征类型的组。然而，每种聚类算法都是根据参数来工作的。基于相似性的技术(K-means聚类算法工作基于数据点的相似性，其任务是指定多少个聚类可用，而分层聚类算法决定何时手动分配完成的聚类。通常使用的基于密度的聚类技术是DBSCAN，它需要两个关于它如何定义其核心点的参数，但是找到参数是一项极其困难的任务。</p><p id="d1b4" class="pw-post-body-paragraph kz la it lb b lc ld kd le lf lg kg lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">DBSCAN的相对算法叫做<strong class="lb jd">光学(排序点识别团簇结构)</strong>。它将创建一个可达性图，用于提取聚类，当输入时，最大ε可用于加速计算时间。</p><p id="6223" class="pw-post-body-paragraph kz la it lb b lc ld kd le lf lg kg lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><strong class="lb jd">算法的工作原理</strong></p><p id="ec9a" class="pw-post-body-paragraph kz la it lb b lc ld kd le lf lg kg lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">为了更好地理解光学，我们必须了解以下内容，如DBSCAN的工作原理、参数以及核心点和边界点之间的差异。</p><p id="deef" class="pw-post-body-paragraph kz la it lb b lc ld kd le lf lg kg lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><em class="lv">核心距离- </em>这是用于使一个独特点成为核心点的最小值。它是用于将一个点分类为核心点的半径的最小值。</p><p id="dccc" class="pw-post-body-paragraph kz la it lb b lc ld kd le lf lg kg lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><em class="lv">可达性距离- </em>这是一个物体‘p’与另一个物体点‘o’之间的最小距离，但不能小于点‘o’。</p><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div class="gh gi lw"><img src="../Images/3aaf49bf533e7945775dd83cc506562a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1248/format:webp/1*aevcIf5K7ChyYXaoq2GgEw.png"/></div><figcaption class="lx ly gj gh gi lz ma bd b be z dk translated">图像<a class="ae mb" href="https://towardsdatascience.com/clustering-using-optics-cac1d10ed7a7" rel="noopener" target="_blank">来源</a></figcaption></figure><p id="93c4" class="pw-post-body-paragraph kz la it lb b lc ld kd le lf lg kg lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">所有距离将以大致相同的速率缩放，因此当MinPts用于执行计算时，可能不会有太大影响。</p><p id="a7b3" class="pw-post-body-paragraph kz la it lb b lc ld kd le lf lg kg lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">核心距离可以在用于提取聚类的集合中的所有数据点上计算，然后我们将循环通过整个数据集，并更新可达性距离，每个点仅处理一次。没有被处理的数据点要被更新以得到可达距离，我们必须设置它的排序和它的可达距离。</p><p id="6b7f" class="pw-post-body-paragraph kz la it lb b lc ld kd le lf lg kg lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">处理完这些数据后，我们为流程选择下一个数据点，它可以基于最近的可达性距离来选择。这是算法的工作原理，以保持聚类在输出顺序中彼此靠近。</p><p id="ed65" class="pw-post-body-paragraph kz la it lb b lc ld kd le lf lg kg lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">例如，局部最小值和最大值用于搜索图中的山谷。</p><div class="mc md gp gr me mf"><a rel="noopener  ugc nofollow" target="_blank" href="/standardization-in-data-preprocessing-with-python-96ae89d2f658"><div class="mg ab fo"><div class="mh ab mi cl cj mj"><h2 class="bd jd gy z fp mk fr fs ml fu fw jc bi translated">用Python实现数据预处理的标准化</h2><div class="mm l"><h3 class="bd b gy z fp mk fr fs ml fu fw dk translated">机器学习和深度学习算法中的缩放方法</h3></div><div class="mn l"><p class="bd b dl z fp mk fr fs ml fu fw dk translated">pub.towardsai.net</p></div></div><div class="mo l"><div class="mp l mq mr ms mo mt kx mf"/></div></div></a></div><p id="69af" class="pw-post-body-paragraph kz la it lb b lc ld kd le lf lg kg lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><strong class="lb jd">光学与DBSCAN有何不同？</strong></p><p id="b0b9" class="pw-post-body-paragraph kz la it lb b lc ld kd le lf lg kg lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">光学和DBSCAN结果非常相似，但并不总是像标记外围和噪声点那样。每个第一个样本的可达性在每个密集区域点以及它们所在区域的数据点中更大。当相邻点被标记为外围点或噪声点时，这会影响相邻点的问题。</p><p id="88a7" class="pw-post-body-paragraph kz la it lb b lc ld kd le lf lg kg lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">据观察，对于任何单个eps值，DBSCAN将具有比光学器件更短的运行时间，但是对于在不同eps值下的重复运行，光学器件的单次运行可能比DBSCAN需要更少的运行时间。还观察到，只有当eps和max_eps接近时，OPTICS的输出才接近DBSCAN的输出。</p><p id="8709" class="pw-post-body-paragraph kz la it lb b lc ld kd le lf lg kg lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">下面给出了一些生成的样本数据、光学标签和可达性图。彩色点代表聚类，而灰色点代表噪声。</p><p id="fe07" class="pw-post-body-paragraph kz la it lb b lc ld kd le lf lg kg lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><strong class="lb jd">离群点检测</strong></p><p id="91f1" class="pw-post-body-paragraph kz la it lb b lc ld kd le lf lg kg lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">Optics算法的扩展用于异常值检测，称为OPTICS-of，其中OF代表异常值因子。它会给每个点一个异常值，这意味着与其最近的邻居进行比较，而不是整个集合。这是一种独特的离群点检测，因为它是基于局部原则。</p><p id="f129" class="pw-post-body-paragraph kz la it lb b lc ld kd le lf lg kg lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">首先，它创建了一个新的度量，局部可达性密度，它是关于MinPts-neighbors的计算点的平均可达性的倒数。一旦对每个点都做了，我们就能计算出异常值因子。为了计算异常值因子y，我们可以取该特定点的MinPts-neighbors比率的平均值。OPTICS-OF的关键是将它与其他离群点检测方法分开的局部分量，因为它基于特定选项的邻域工作。</p><p id="eaaf" class="pw-post-body-paragraph kz la it lb b lc ld kd le lf lg kg lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><strong class="lb jd">代号</strong></p><pre class="ks kt ku kv gt mu mv mw mx aw my bi"><span id="abd2" class="mz na it mv b gy nb nc l nd ne">from sklearn.cluster import OPTICS, cluster_optics_dbscan<br/>import matplotlib.gridspec as gridspec<br/>import matplotlib.pyplot as plt<br/>import numpy as np</span></pre><p id="35e9" class="pw-post-body-paragraph kz la it lb b lc ld kd le lf lg kg lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">matplotlib.gridspec作为gridspec用于需要在同一图形内进行子绘图的地方。Left、right、bottom、top、hspace和wspace都可以确定网格单元的位置。</p><pre class="ks kt ku kv gt mu mv mw mx aw my bi"><span id="edfa" class="mz na it mv b gy nb nc l nd ne"># Generate sample data</span><span id="366d" class="mz na it mv b gy nf nc l nd ne">np.random.seed(0)<br/>n_points_per_cluster = 250</span></pre><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div class="gh gi ng"><img src="../Images/cf2f69c203790e92fc7394f794720a86.png" data-original-src="https://miro.medium.com/v2/resize:fit:1220/format:webp/1*OGEDSTOAjXgB9Eq9K_2QDg.png"/></div></figure><pre class="ks kt ku kv gt mu mv mw mx aw my bi"><span id="a119" class="mz na it mv b gy nb nc l nd ne">clust = OPTICS(min_samples=50, xi=.05, min_cluster_size=.05)</span></pre><p id="4e06" class="pw-post-body-paragraph kz la it lb b lc ld kd le lf lg kg lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">当我们需要按行(垂直)堆叠数组时，使用np.vstack。</p><pre class="ks kt ku kv gt mu mv mw mx aw my bi"><span id="b544" class="mz na it mv b gy nb nc l nd ne"># Run the fit</span><span id="d2d6" class="mz na it mv b gy nf nc l nd ne">clust.fit(X)</span><span id="9690" class="mz na it mv b gy nf nc l nd ne">labels_050 = cluster_optics_dbscan(reachability=clust.reachability_,<br/>                               core_distances=clust.core_distances_,<br/>                               ordering=clust.ordering_, eps=0.5)</span><span id="9336" class="mz na it mv b gy nf nc l nd ne">labels_200 = cluster_optics_dbscan(reachability=clust.reachability_,<br/>                               core_distances=clust.core_distances_,<br/>                               ordering=clust.ordering_, eps=2)</span><span id="66dc" class="mz na it mv b gy nf nc l nd ne">space = np.arange(len(X))</span><span id="5a9b" class="mz na it mv b gy nf nc l nd ne">reachability = clust.reachability_[clust.ordering_]<br/>labels = clust.labels_[clust.ordering_]</span></pre><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div class="gh gi nh"><img src="../Images/f909d2d6f57b828c1f8645d01cf15658.png" data-original-src="https://miro.medium.com/v2/resize:fit:1364/format:webp/1*R7nkpFQL7igmIyPv4-5VwQ.png"/></div></figure><pre class="ks kt ku kv gt mu mv mw mx aw my bi"><span id="6808" class="mz na it mv b gy nb nc l nd ne"># Reachability plot</span><span id="cedb" class="mz na it mv b gy nf nc l nd ne">colors = [‘g.’, ‘r.’, ‘b.’, ‘y.’, ‘c.’]</span><span id="039f" class="mz na it mv b gy nf nc l nd ne">for klass, color in zip(range(0, 5), colors):<br/>    Xk = space[labels == klass]<br/>    Rk = reachability[labels == klass]<br/>    ax1.plot(Xk, Rk, color, alpha=0.3)</span><span id="a7a3" class="mz na it mv b gy nf nc l nd ne">ax1.plot(space[labels == -1], reachability[labels == -1], ‘k.’, alpha=0.3)</span><span id="3a77" class="mz na it mv b gy nf nc l nd ne">ax1.plot(space, np.full_like(space, 2., dtype=float), ‘k-’, alpha=0.5)</span><span id="9c3f" class="mz na it mv b gy nf nc l nd ne">ax1.plot(space, np.full_like(space, 0.5, dtype=float), ‘k-.’, alpha=0.5)</span><span id="071a" class="mz na it mv b gy nf nc l nd ne">ax1.set_ylabel(‘Reachability (epsilon distance)’)<br/>ax1.set_title(‘Reachability Plot’)</span></pre><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div class="gh gi ni"><img src="../Images/19a27d2b042afcf6943185ee3d76b055.png" data-original-src="https://miro.medium.com/v2/resize:fit:1314/format:webp/1*-PvSWh8NVG6VIZXmMjjOOw.png"/></div></figure><p id="15e6" class="pw-post-body-paragraph kz la it lb b lc ld kd le lf lg kg lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">Klass 利用python中的类对象，包括方法的自参数、继承和在超类上调用方法的能力。</p><div class="mc md gp gr me mf"><a href="https://medium.com/pythoneers/fully-explained-mean-shift-clustering-with-python-51aef7a17c5d" rel="noopener follow" target="_blank"><div class="mg ab fo"><div class="mh ab mi cl cj mj"><h2 class="bd jd gy z fp mk fr fs ml fu fw jc bi translated">用Python全面解释均值漂移聚类</h2><div class="mm l"><h3 class="bd b gy z fp mk fr fs ml fu fw dk translated">基于无监督质心的算法学习</h3></div><div class="mn l"><p class="bd b dl z fp mk fr fs ml fu fw dk translated">medium.com</p></div></div><div class="mo l"><div class="nj l mq mr ms mo mt kx mf"/></div></div></a></div><p id="61c4" class="pw-post-body-paragraph kz la it lb b lc ld kd le lf lg kg lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">#光学</p><pre class="ks kt ku kv gt mu mv mw mx aw my bi"><span id="2d9b" class="mz na it mv b gy nb nc l nd ne">ax2 = plt.subplot(G[1, 0])<br/>ax3 = plt.subplot(G[1, 1])<br/>ax4 = plt.subplot(G[1, 2])</span><span id="4732" class="mz na it mv b gy nf nc l nd ne">colors = [‘g.’, ‘r.’, ‘b.’, ‘y.’, ‘c.’]</span><span id="ee37" class="mz na it mv b gy nf nc l nd ne">for klass, color in zip(range(0, 5), colors):<br/>    Xk = X[clust.labels_ == klass]<br/>    ax2.plot(Xk[:, 0], Xk[:, 1], color, alpha=0.3)</span></pre><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="nl nm di nn bf no"><div class="gh gi nk"><img src="../Images/842435f07ce4f6d35c35557686923d7e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1328/format:webp/1*GpTK2qrbpGN1EMD94owcUQ.png"/></div></div></figure><pre class="ks kt ku kv gt mu mv mw mx aw my bi"><span id="9db5" class="mz na it mv b gy nb nc l nd ne"><br/>ax2.set_title(‘Automatic Clustering\nOPTICS’)</span><span id="9d7c" class="mz na it mv b gy nf nc l nd ne"># DBSCAN at 0.5</span><span id="5ddd" class="mz na it mv b gy nf nc l nd ne">for klass, color in zip(range(0, 6), colors):<br/>    Xk = X[labels_050 == klass]<br/>    ax3.plot(Xk[:, 0], Xk[:, 1], color, alpha=0.3, marker=’.’)</span></pre><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="nl nm di nn bf no"><div class="gh gi np"><img src="../Images/6cbeb97d372454ef966c5d01be3fae0f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1292/format:webp/1*mnSuG6p5FVdr-TDqz1-VUw.png"/></div></div></figure><pre class="ks kt ku kv gt mu mv mw mx aw my bi"><span id="f1e8" class="mz na it mv b gy nb nc l nd ne"><br/>ax3.set_title(‘Clustering at 0.5 epsilon cut\nDBSCAN’)</span><span id="3aa7" class="mz na it mv b gy nf nc l nd ne"># DBSCAN at 2.</span><span id="537f" class="mz na it mv b gy nf nc l nd ne">colors = [‘g.’, ‘m.’, ‘y.’, ‘c.’]</span><span id="c774" class="mz na it mv b gy nf nc l nd ne">for klass, color in zip(range(0, 4), colors):<br/>    Xk = X[labels_200 == klass]<br/>    ax4.plot(Xk[:, 0], Xk[:, 1], color, alpha=0.3)</span></pre><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div class="gh gi nq"><img src="../Images/2849795d6b8228969cb7bf315328879b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1320/format:webp/1*oodMfE2TNJ_sp2sf4hyudg.png"/></div></figure><pre class="ks kt ku kv gt mu mv mw mx aw my bi"><span id="04ed" class="mz na it mv b gy nb nc l nd ne"><br/>ax4.set_title(‘Clustering at 2.0 epsilon cut\nDBSCAN’)</span><span id="99a6" class="mz na it mv b gy nf nc l nd ne">plt.tight_layout()<br/>plt.show()</span></pre><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="nl nm di nn bf no"><div class="gh gi nr"><img src="../Images/bf138adf0f4d74b37062c3a0c7b95e03.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Cn3hKHnlx9JkXmiDKUm2TQ.png"/></div></div></figure><p id="eb91" class="pw-post-body-paragraph kz la it lb b lc ld kd le lf lg kg lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">请注意，在这个生成的示例中，有足够多的点被识别为噪声点。当我们达到更高的ε数时，聚类的形成正在改变，并且我们还看到，与其他聚类相比，自动聚类中的噪声也变得更少。在这种情况下，它显示了微调提取参数的好处。</p><p id="51c9" class="pw-post-body-paragraph kz la it lb b lc ld kd le lf lg kg lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><strong class="lb jd">缺点</strong></p><p id="b7d3" class="pw-post-body-paragraph kz la it lb b lc ld kd le lf lg kg lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">光学的一个缺点是不能处理重复值。假设多个或多个点占据相同的空间，那么它们的可达性距离都为0，这可能会在我们的局部异常值因子计算中产生问题。这个问题的解决方案之一是删除所有重复的值。</p><p id="bbec" class="pw-post-body-paragraph kz la it lb b lc ld kd le lf lg kg lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><strong class="lb jd">结论</strong></p><p id="5db6" class="pw-post-body-paragraph kz la it lb b lc ld kd le lf lg kg lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">光学是一种非常有趣的技术，与其他聚类技术相比，它得到了大量的讨论。光学的主要优点是通过很少的参数调整就能发现变化的密度。光学主要用于非常容易地在地理数据中找到基于密度的聚类。</p><p id="2a45" class="pw-post-body-paragraph kz la it lb b lc ld kd le lf lg kg lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">我希望你喜欢这篇文章。通过我的<a class="ae mb" href="https://www.linkedin.com/in/data-scientist-95040a1ab/" rel="noopener ugc nofollow" target="_blank"> LinkedIn </a>和<a class="ae mb" href="https://twitter.com/amitprius" rel="noopener ugc nofollow" target="_blank"> twitter </a>联系我。</p><h1 id="47ff" class="ns na it bd nt nu nv nw nx ny nz oa ob ki oc kj od kl oe km of ko og kp oh oi bi translated">推荐文章</h1><p id="9187" class="pw-post-body-paragraph kz la it lb b lc oj kd le lf ok kg lh li ol lk ll lm om lo lp lq on ls lt lu im bi translated">1.<a class="ae mb" rel="noopener ugc nofollow" target="_blank" href="/8-active-learning-insights-of-python-collection-module-6c9e0cc16f6b?source=friends_link&amp;sk=4a5c9f9ad552005636ae720a658281b1">8 Python的主动学习见解收集模块</a> <br/> 2。<a class="ae mb" rel="noopener ugc nofollow" target="_blank" href="/numpy-linear-algebra-on-images-ed3180978cdb?source=friends_link&amp;sk=d9afa4a1206971f9b1f64862f6291ac0"> NumPy:图像上的线性代数</a>T5】3。<a class="ae mb" rel="noopener ugc nofollow" target="_blank" href="/exception-handling-concepts-in-python-4d5116decac3?source=friends_link&amp;sk=a0ed49d9fdeaa67925eac34ecb55ea30">Python中的异常处理概念</a> <br/> 4。<a class="ae mb" rel="noopener ugc nofollow" target="_blank" href="/pandas-dealing-with-categorical-data-7547305582ff?source=friends_link&amp;sk=11c6809f6623dd4f6dd74d43727297cf">熊猫:处理分类数据</a> <br/> 5。<a class="ae mb" rel="noopener ugc nofollow" target="_blank" href="/hyper-parameters-randomseachcv-and-gridsearchcv-in-machine-learning-b7d091cf56f4?source=friends_link&amp;sk=cab337083fb09601114a6e466ec59689">超参数:机器学习中的RandomSeachCV和GridSearchCV</a><br/>6。<a class="ae mb" href="https://medium.com/towards-artificial-intelligence/fully-explained-linear-regression-with-python-fe2b313f32f3?source=friends_link&amp;sk=53c91a2a51347ec2d93f8222c0e06402" rel="noopener">用Python </a> <br/> 7全面讲解了线性回归。<a class="ae mb" href="https://medium.com/towards-artificial-intelligence/fully-explained-logistic-regression-with-python-f4a16413ddcd?source=friends_link&amp;sk=528181f15a44e48ea38fdd9579241a78" rel="noopener">用Python </a> <br/>充分解释了Logistic回归8。<a class="ae mb" rel="noopener ugc nofollow" target="_blank" href="/data-distribution-using-numpy-with-python-3b64aae6f9d6?source=friends_link&amp;sk=809e75802cbd25ddceb5f0f6496c9803">数据分发使用Numpy与Python </a> <br/> 9。<a class="ae mb" rel="noopener ugc nofollow" target="_blank" href="/decision-trees-vs-random-forests-in-machine-learning-be56c093b0f?source=friends_link&amp;sk=91377248a43b62fe7aeb89a69e590860">机器学习中的决策树vs随机森林</a> <br/> 10。<a class="ae mb" rel="noopener ugc nofollow" target="_blank" href="/standardization-in-data-preprocessing-with-python-96ae89d2f658?source=friends_link&amp;sk=f348435582e8fbb47407e9b359787e41">用Python实现数据预处理的标准化</a></p></div></div>    
</body>
</html>