<html>
<head>
<title>Fully Explained K-means Clustering with Python</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">充分解释了使用Python进行K-means聚类</h1>
<blockquote>原文：<a href="https://pub.towardsai.net/fully-explained-k-means-clustering-with-python-e7caa573176a?source=collection_archive---------0-----------------------#2021-01-25">https://pub.towardsai.net/fully-explained-k-means-clustering-with-python-e7caa573176a?source=collection_archive---------0-----------------------#2021-01-25</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><h2 id="38e9" class="ir is it bd b dl iu iv iw ix iy iz dk ja translated" aria-label="kicker paragraph"><a class="ae ep" href="https://towardsai.net/p/category/machine-learning" rel="noopener ugc nofollow" target="_blank">机器学习</a></h2><div class=""/><div class=""><h2 id="5f02" class="pw-subtitle-paragraph jz jc it bd b ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq dk translated">群体相似性机器学习中的非监督部分。</h2></div><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi kr"><img src="../Images/4b9cd8f59eee99d618e3ae8b8266951f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*JsfEdbXKwJw_Euprvx17KA.png"/></div></div><figcaption class="ld le gj gh gi lf lg bd b be z dk translated">k-均值聚类。作者的照片</figcaption></figure><p id="84ed" class="pw-post-body-paragraph lh li it lj b lk ll kd lm ln lo kg lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">K-means聚类是一种非常简单而有见地的方法，可以从分组的聚类的相似性中进行推断。这是一种无监督的学习，我们没有输出标签。如果我们谈论回归、分类和聚类算法，回归主要用于根据事物的增长预测事物，主要根据数值预测天气等。另一方面，学习者有时会对分类和聚类感到困惑，简单的区别是聚类没有标签输出，而是对相似性进行处理，而分类使用已知的输出标签将他们归入组中。</p><p id="5a04" class="pw-post-body-paragraph lh li it lj b lk ll kd lm ln lo kg lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">聚类算法没有分类算法复杂。在分类中，我们训练和测试数据，而在聚类中，我们不需要它。聚类分析中不使用训练测试分裂的注意事项。</p><ul class=""><li id="f0ff" class="md me it lj b lk ll ln lo lq mf lu mg ly mh mc mi mj mk ml bi translated">我们根据数据点的相似性进行分析。</li><li id="ecb1" class="md me it lj b lk mm ln mn lq mo lu mp ly mq mc mi mj mk ml bi translated">测试误差将更多地集中在大量的群集上，即每个群集的质心上。</li><li id="d617" class="md me it lj b lk mm ln mn lq mo lu mp ly mq mc mi mj mk ml bi translated">K-means度量以惯性应该较低的方式选择聚类，这里惯性表示聚类内数据点的平方和(WCSS)。</li></ul><p id="181e" class="pw-post-body-paragraph lh li it lj b lk ll kd lm ln lo kg lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">我们不应该急于确定算法中要使用的聚类数。有几点我们必须先观察。</p><ul class=""><li id="0749" class="md me it lj b lk ll ln lo lq mf lu mg ly mh mc mi mj mk ml bi translated">惯性思维非常快速且不可靠，即假设群体相似性是各向同性且凸的。各向同性意味着均匀的形状，而凸形意味着数据点更多地位于聚类的中间，而更少地位于聚类的边界。但是，现实世界的数据并不在这些假设上起作用，它们的形状和均匀性发生变化，它可以是不规则的形状，在一边被拉长。</li><li id="15b9" class="md me it lj b lk mm ln mn lq mo lu mp ly mq mc mi mj mk ml bi translated">数据集值的规范化。这意味着低惯性值是好的。但是在现实世界中，我们为聚类测量的数据点距离(无论是通过欧几里德距离测量还是曼哈顿距离测量)都可能被夸大。对此有一个术语叫做“维数灾难”。如果数据点有很大的变化，我们应该进行PCA和数据点的标准化。</li></ul><p id="189b" class="pw-post-body-paragraph lh li it lj b lk ll kd lm ln lo kg lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">K-means算法的工作流程</p><ul class=""><li id="4070" class="md me it lj b lk ll ln lo lq mf lu mg ly mh mc mi mj mk ml bi translated">如有必要，选择特征。</li><li id="a802" class="md me it lj b lk mm ln mn lq mo lu mp ly mq mc mi mj mk ml bi translated">用一个数字初始化集群。</li><li id="9ffe" class="md me it lj b lk mm ln mn lq mo lu mp ly mq mc mi mj mk ml bi translated">拟合数据。</li><li id="15a3" class="md me it lj b lk mm ln mn lq mo lu mp ly mq mc mi mj mk ml bi translated">预测适合的模型。</li></ul><div class="mr ms gp gr mt mu"><a href="https://medium.com/towards-artificial-intelligence/fully-explained-logistic-regression-with-python-f4a16413ddcd" rel="noopener follow" target="_blank"><div class="mv ab fo"><div class="mw ab mx cl cj my"><h2 class="bd jd gy z fp mz fr fs na fu fw jc bi translated">用Python全面解释逻辑回归</h2><div class="nb l"><h3 class="bd b gy z fp mz fr fs na fu fw dk translated">机器学习算法中的统计非线性方法</h3></div><div class="nc l"><p class="bd b dl z fp mz fr fs na fu fw dk translated">medium.com</p></div></div><div class="nd l"><div class="ne l nf ng nh nd ni lb mu"/></div></div></a></div><p id="658d" class="pw-post-body-paragraph lh li it lj b lk ll kd lm ln lo kg lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">这些是流程的高端，但是我们将逐步看到python的示例，我们还将看到如何选择要采用的正确集群数量。</p><h2 id="e648" class="nj nk it bd nl nm nn dn no np nq dp nr lq ns nt nu lu nv nw nx ly ny nz oa iz bi translated">步骤1:加载必要的库</h2><pre class="ks kt ku kv gt ob oc od oe aw of bi"><span id="6049" class="nj nk it oc b gy og oh l oi oj">import numpy as np<br/>import pandas as pd<br/>import matplotlib.pyplot as plt</span></pre><h2 id="839a" class="nj nk it bd nl nm nn dn no np nq dp nr lq ns nt nu lu nv nw nx ly ny nz oa iz bi translated">步骤2:将数据集载入jupyter笔记本</h2><pre class="ks kt ku kv gt ob oc od oe aw of bi"><span id="c98a" class="nj nk it oc b gy og oh l oi oj">dataset=pd.read_csv('Customers.csv')<br/>dataset.head()</span></pre><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div class="gh gi ok"><img src="../Images/cc01514bea9b07f2b52bcc422af86b97.png" data-original-src="https://miro.medium.com/v2/resize:fit:958/format:webp/1*gCBCwOPrzXTWldwtm9gFGA.png"/></div><figcaption class="ld le gj gh gi lf lg bd b be z dk translated">数据集视图。作者的照片</figcaption></figure><p id="8291" class="pw-post-body-paragraph lh li it lj b lk ll kd lm ln lo kg lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">为了知道数据集的形状</p><pre class="ks kt ku kv gt ob oc od oe aw of bi"><span id="d04c" class="nj nk it oc b gy og oh l oi oj">dataset.shape</span><span id="444a" class="nj nk it oc b gy ol oh l oi oj">#output:<br/>(200, 5)</span></pre><h2 id="9b60" class="nj nk it bd nl nm nn dn no np nq dp nr lq ns nt nu lu nv nw nx ly ny nz oa iz bi translated">步骤3:拟合弯头方法的数据</h2><pre class="ks kt ku kv gt ob oc od oe aw of bi"><span id="b003" class="nj nk it oc b gy og oh l oi oj">#elbow method to find the number of clusters</span><span id="d511" class="nj nk it oc b gy ol oh l oi oj">from sklearn.cluster import KMeans</span><span id="56a5" class="nj nk it oc b gy ol oh l oi oj">wcss=[]<br/>for i in range(1,11):<br/>    kmeans=KMeans(n_clusters=i, init='k-means++',random_state=0)<br/>    kmeans.fit(X)<br/>    wcss.append(kmeans.inertia_)</span><span id="15e5" class="nj nk it oc b gy ol oh l oi oj">plt.plot(range(1,11),wcss)<br/>plt.title('The Elbow Method')<br/>plt.xlabel('Number of Clusters')<br/>plt.ylabel('WCSS')<br/>plt.show()</span></pre><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div class="gh gi om"><img src="../Images/05dd38e09337a0b4596b981ac82f3837.png" data-original-src="https://miro.medium.com/v2/resize:fit:936/format:webp/1*WtmAAzvnYq1-YHjg1znbeA.png"/></div><figcaption class="ld le gj gh gi lf lg bd b be z dk translated">肘法图。作者的照片</figcaption></figure><p id="a5d0" class="pw-post-body-paragraph lh li it lj b lk ll kd lm ln lo kg lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">在上面的肘形图中可以看出，WCSS在第5组之前急剧下降。所以，选择簇的数目是光学数。</p><h2 id="6826" class="nj nk it bd nl nm nn dn no np nq dp nr lq ns nt nu lu nv nw nx ly ny nz oa iz bi translated">步骤4:将数据与适当数量的聚类相匹配</h2><pre class="ks kt ku kv gt ob oc od oe aw of bi"><span id="e975" class="nj nk it oc b gy og oh l oi oj">#Fitting K-MEans to the dataset<br/>kmeans=KMeans(n_clusters=5,init='k-means++',random_state=0)<br/>y_kmeans=kmeans.fit_predict(X)</span></pre><p id="5f95" class="pw-post-body-paragraph lh li it lj b lk ll kd lm ln lo kg lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">在上面的代码中，我们在<em class="on"> init </em>参数中选择了<em class="on">“k-means++”</em>。k-means++是一个默认设置，它用于将种子(质心)放置到一个合适的位置，这样所有的点都可以正确地收敛到质心。</p><h2 id="6715" class="nj nk it bd nl nm nn dn no np nq dp nr lq ns nt nu lu nv nw nx ly ny nz oa iz bi translated">步骤5:可视化集群</h2><pre class="ks kt ku kv gt ob oc od oe aw of bi"><span id="885e" class="nj nk it oc b gy og oh l oi oj">#Visualize the clusters</span><span id="7a96" class="nj nk it oc b gy ol oh l oi oj">plt.scatter(X[y_kmeans==0,0],X[y_kmeans==0,1],s=100,c='red',label=<br/>             'Cluster1')<br/>plt.scatter(X[y_kmeans==1,0],X[y_kmeans==1,1],s=100,c='blue',label=<br/>              'Cluster2')<br/>plt.scatter(X[y_kmeans==2,0],X[y_kmeans==2,1],s=100,c='green',label=<br/>              'Cluster3')<br/>plt.scatter(X[y_kmeans==3,0],X[y_kmeans==3,1],s=100,c='cyan',label=<br/>              'Cluster4')<br/>plt.scatter(X[y_kmeans==4,0],X[y_kmeans==4,1],s=100,c='magenta',<br/>               label='Cluster5')</span><span id="3433" class="nj nk it oc b gy ol oh l oi oj">plt.scatter(kmeans.cluster_centers_[:,0],kmeans.cluster_centers_[:,1<br/>             ],s=300,c='yellow',label='Centroids')</span><span id="2020" class="nj nk it oc b gy ol oh l oi oj">plt.title('Clusters of customers')<br/>plt.xlabel('Annual Income(K$)')<br/>plt.ylabel('Spending Score(1-100)')<br/>plt.legend()<br/>plt.show()</span></pre><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div class="gh gi oo"><img src="../Images/7f258f0fe6ff8cdb9055e523316bb721.png" data-original-src="https://miro.medium.com/v2/resize:fit:932/format:webp/1*aE347yP_z7F2zXZAIrvs9Q.png"/></div><figcaption class="ld le gj gh gi lf lg bd b be z dk translated">顾客群。作者的照片</figcaption></figure><p id="84aa" class="pw-post-body-paragraph lh li it lj b lk ll kd lm ln lo kg lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">从聚类图中我们可以得到有用的见解。</p><div class="mr ms gp gr mt mu"><a href="https://medium.com/towards-artificial-intelligence/become-a-data-scientist-in-2021-with-these-following-steps-5bf70a0fe0a1" rel="noopener follow" target="_blank"><div class="mv ab fo"><div class="mw ab mx cl cj my"><h2 class="bd jd gy z fp mz fr fs na fu fw jc bi translated">按照以下步骤，在2021年成为一名数据科学家</h2><div class="nb l"><h3 class="bd b gy z fp mz fr fs na fu fw dk translated">走上数据科学家之路需要具备的基本点</h3></div><div class="nc l"><p class="bd b dl z fp mz fr fs na fu fw dk translated">medium.com</p></div></div><div class="nd l"><div class="op l nf ng nh nd ni lb mu"/></div></div></a></div><blockquote class="oq or os"><p id="3871" class="lh li on lj b lk ll kd lm ln lo kg lp ot lr ls lt ou lv lw lx ov lz ma mb mc im bi translated"><strong class="lj jd"> <em class="it">结论:</em> </strong></p></blockquote><p id="f4f9" class="pw-post-body-paragraph lh li it lj b lk ll kd lm ln lo kg lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">聚类方法是预测有价值见解的非常有用的算法。虽然我遇到了一种算法，可以更好地处理大型数据集上的离群数据，但该算法的名称是聚类中的BIRCH。</p><p id="5369" class="pw-post-body-paragraph lh li it lj b lk ll kd lm ln lo kg lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">我希望你喜欢这篇文章。通过我的<a class="ae ow" href="https://www.linkedin.com/in/data-scientist-95040a1ab/" rel="noopener ugc nofollow" target="_blank"> LinkedIn </a>和<a class="ae ow" href="https://twitter.com/amitprius" rel="noopener ugc nofollow" target="_blank"> twitter </a>联系我。</p><h1 id="361a" class="ox nk it bd nl oy oz pa no pb pc pd nr ki pe kj nu kl pf km nx ko pg kp oa ph bi translated">推荐文章</h1><ol class=""><li id="7b58" class="md me it lj b lk pi ln pj lq pk lu pl ly pm mc pn mj mk ml bi translated"><a class="ae ow" href="https://medium.com/towards-artificial-intelligence/nlp-zero-to-hero-with-python-2df6fcebff6e?sk=2231d868766e96b13d1e9d7db6064df1" rel="noopener"> NLP —用Python从零到英雄</a></li></ol><p id="b3c4" class="pw-post-body-paragraph lh li it lj b lk ll kd lm ln lo kg lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">2.<a class="ae ow" href="https://medium.com/towards-artificial-intelligence/python-data-structures-data-types-and-objects-244d0a86c3cf?sk=42f4b462499f3fc3a160b21e2c94dba6" rel="noopener"> Python数据结构数据类型和对象</a></p><p id="26c0" class="pw-post-body-paragraph lh li it lj b lk ll kd lm ln lo kg lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">3.<a class="ae ow" href="https://medium.com/towards-artificial-intelligence/mysql-zero-to-hero-with-syntax-of-all-topics-92e700762c7b?source=friends_link&amp;sk=35a3f8dc1cf1ebd1c4d5008a5d12d6a3" rel="noopener"> MySQL:零到英雄</a></p><p id="cfec" class="pw-post-body-paragraph lh li it lj b lk ll kd lm ln lo kg lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">4.<a class="ae ow" href="https://medium.com/towards-artificial-intelligence/basic-of-time-series-with-python-a2f7cb451a76?source=friends_link&amp;sk=09d77be2d6b8779973e41ab54ebcf6c5" rel="noopener">Python时间序列基础</a></p><p id="979f" class="pw-post-body-paragraph lh li it lj b lk ll kd lm ln lo kg lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">5.<a class="ae ow" href="https://medium.com/towards-artificial-intelligence/numpy-zero-to-hero-with-python-d135f57d6082?source=friends_link&amp;sk=45c0921423cdcca2f5772f5a5c1568f1" rel="noopener"> NumPy:用Python零到英雄</a></p><p id="7937" class="pw-post-body-paragraph lh li it lj b lk ll kd lm ln lo kg lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">6.<a class="ae ow" href="https://medium.com/towards-artificial-intelligence/fundamentals-of-series-and-data-frame-in-pandas-with-python-6e0b8a168a0d?source=friends_link&amp;sk=955350bf43c7d1680be6e37b15b6628b" rel="noopener">用python实现熊猫系列和数据帧的基础</a></p></div></div>    
</body>
</html>