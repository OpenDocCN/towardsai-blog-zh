<html>
<head>
<title>De-Mystifying Neural Network Compression</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">去神秘化的神经网络压缩</h1>
<blockquote>原文：<a href="https://pub.towardsai.net/de-mystifying-neural-network-compression-9bbaf936cb57?source=collection_archive---------2-----------------------#2022-01-28">https://pub.towardsai.net/de-mystifying-neural-network-compression-9bbaf936cb57?source=collection_archive---------2-----------------------#2022-01-28</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><h2 id="e65a" class="ir is it bd b dl iu iv iw ix iy iz dk ja translated" aria-label="kicker paragraph"><a class="ae ep" href="https://towardsai.net/p/category/machine-learning/deep-learning" rel="noopener ugc nofollow" target="_blank">深度学习</a></h2><div class=""/><p id="7459" class="pw-post-body-paragraph jz ka it kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw im bi translated">理解修剪深度神经网络的具体细节</p><figure class="ky kz la lb gt lc gh gi paragraph-image"><div role="button" tabindex="0" class="ld le di lf bf lg"><div class="gh gi kx"><img src="../Images/1542d3e687a839785623fd296b4fa895.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*kolwgL5Xs3np7O4S14vetw.jpeg"/></div></div><figcaption class="lj lk gj gh gi ll lm bd b be z dk translated"><a class="ae ln" href="https://unsplash.com/@kirklai?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText" rel="noopener ugc nofollow" target="_blank"> 𝓴𝓘𝓡𝓚 𝕝𝔸𝕀 </a>在<a class="ae ln" href="https://unsplash.com/s/photos/mystery?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上拍照</figcaption></figure><h1 id="471c" class="lo lp it bd lq lr ls lt lu lv lw lx ly lz ma mb mc md me mf mg mh mi mj mk ml bi translated">议程</h1><p id="f199" class="pw-post-body-paragraph jz ka it kb b kc mm ke kf kg mn ki kj kk mo km kn ko mp kq kr ks mq ku kv kw im bi translated">极简主义的生活方式已经触及了神经网络。我们正在寻找方法来减小深度神经网络的大小，希望将它们托管在嵌入式设备中，而不是将它们放在巨大的服务器中，然后请求预测和分类。然而，在研究方法和实际实施之间存在知识差距。我们可以找到很多关于修剪神经网络的资源，但是很少有人解释它背后的代码。这篇文章是一步一步的<strong class="kb jd"> PyTorch为基础的</strong>使用常用技术修剪神经网络的指南。我使用了Oleg Polivin 的<a class="ae ln" href="https://olegpolivin.medium.com/experiments-in-neural-network-pruning-in-pytorch-c18d5b771d6d" rel="noopener">文章</a>作为参考资料之一。论文<a class="ae ln" href="https://arxiv.org/abs/2003.03033" rel="noopener ugc nofollow" target="_blank">神经网络剪枝是什么状态？</a>及其源代码<a class="ae ln" href="https://github.com/JJGO/shrinkbench" rel="noopener ugc nofollow" target="_blank"> shrinkbench </a>也提供了急需的指导。</p><h2 id="681b" class="mr lp it bd lq ms mt dn lu mu mv dp ly kk mw mx mc ko my mz mg ks na nb mk iz bi translated">背景</h2><p id="20d3" class="pw-post-body-paragraph jz ka it kb b kc mm ke kf kg mn ki kj kk mo km kn ko mp kq kr ks mq ku kv kw im bi translated">下面是非常流行的剪枝机制。你有一个有很多连接的神经网络。修剪是去除这些连接以减小网络规模的过程。从神经网络的角度来看，连接只不过是每个神经元的权重。(对于卷积层，它们是过滤器的值)。从数学表示的角度来看，这些权重仅仅是表示神经网络的矩阵中存在的值</p><figure class="ky kz la lb gt lc gh gi paragraph-image"><div role="button" tabindex="0" class="ld le di lf bf lg"><div class="gh gi nc"><img src="../Images/e3419c562d0e65958e7da51362832903.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*VjuLlWvek3MS1TxQaa9jeg.png"/></div></div><figcaption class="lj lk gj gh gi ll lm bd b be z dk translated">具有修剪权值的神经网络。图片作者。</figcaption></figure><p id="1a96" class="pw-post-body-paragraph jz ka it kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw im bi translated"><strong class="kb jd">神经元中权重的表示</strong></p><p id="3ad6" class="pw-post-body-paragraph jz ka it kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw im bi translated">让我们创建一个简单的神经网络来了解权重是如何存储在其中的。</p><figure class="ky kz la lb gt lc"><div class="bz fp l di"><div class="nd ne l"/></div><figcaption class="lj lk gj gh gi ll lm bd b be z dk translated">创建模型的类</figcaption></figure><p id="0e82" class="pw-post-body-paragraph jz ka it kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw im bi translated">上面是一个简单的代码来创建一个完全连接的4层神经网络。该模型可以如下初始化，并且可以检查其配置。</p><figure class="ky kz la lb gt lc"><div class="bz fp l di"><div class="nd ne l"/></div><figcaption class="lj lk gj gh gi ll lm bd b be z dk translated">显示模型配置</figcaption></figure><figure class="ky kz la lb gt lc gh gi paragraph-image"><div role="button" tabindex="0" class="ld le di lf bf lg"><div class="gh gi nf"><img src="../Images/23ec65a6e3a85fe3c38289f9f96c8329.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*AsPuRffPOiEE7UG07vhFrg.png"/></div></div><figcaption class="lj lk gj gh gi ll lm bd b be z dk translated">显示模型参数</figcaption></figure><p id="e001" class="pw-post-body-paragraph jz ka it kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw im bi translated">可以看出，该模型有4层，第一层有256个神经元，第二层有128个，第三层有64个，第四层有10个神经元。</p><figure class="ky kz la lb gt lc"><div class="bz fp l di"><div class="nd ne l"/></div><figcaption class="lj lk gj gh gi ll lm bd b be z dk translated">各层的具体情况、权重值</figcaption></figure><figure class="ky kz la lb gt lc gh gi paragraph-image"><div role="button" tabindex="0" class="ld le di lf bf lg"><div class="gh gi ng"><img src="../Images/93c06295251b590a543cf76d610cfe3b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*HT9Np28fZE5V_ZDGRvn0hw.png"/></div></div><figcaption class="lj lk gj gh gi ll lm bd b be z dk translated">每层的权重值</figcaption></figure><p id="c3da" class="pw-post-body-paragraph jz ka it kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw im bi translated">上图显示了每一层的权重值。它们是形状为256X784、128X256、64X128和10X64的矩阵。</p><h2 id="72e4" class="mr lp it bd lq ms mt dn lu mu mv dp ly kk mw mx mc ko my mz mg ks na nb mk iz bi translated">火车</h2><p id="70ef" class="pw-post-body-paragraph jz ka it kb b kc mm ke kf kg mn ki kj kk mo km kn ko mp kq kr ks mq ku kv kw im bi translated">为了应用剪枝，我们需要首先训练模型。使用PyTorch进行训练不像Keras那么直接，所以需要写一些函数。让我们把它分解成几个部分来理解它们。</p><figure class="ky kz la lb gt lc"><div class="bz fp l di"><div class="nd ne l"/></div><figcaption class="lj lk gj gh gi ll lm bd b be z dk translated">必要的进口</figcaption></figure><p id="1928" class="pw-post-body-paragraph jz ka it kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw im bi translated">我们将代码的下一部分(设置)分成3个部分——数据部分、评估部分和模型部分。</p><h1 id="d5a9" class="lo lp it bd lq lr ls lt lu lv lw lx ly lz ma mb mc md me mf mg mh mi mj mk ml bi translated">A.设置</h1><h2 id="bbcf" class="mr lp it bd lq ms mt dn lu mu mv dp ly kk mw mx mc ko my mz mg ks na nb mk iz bi translated"><strong class="ak"> 1。数据部分</strong></h2><figure class="ky kz la lb gt lc"><div class="bz fp l di"><div class="nd ne l"/></div><figcaption class="lj lk gj gh gi ll lm bd b be z dk translated">将数据加载到GPU/CPU的函数</figcaption></figure><p id="e93b" class="pw-post-body-paragraph jz ka it kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw im bi translated">不要担心上面的这些函数，它们是用于将数据传输到活动设备RAM/GPU的标准函数。</p><h2 id="41f4" class="mr lp it bd lq ms mt dn lu mu mv dp ly kk mw mx mc ko my mz mg ks na nb mk iz bi translated">2.评估</h2><figure class="ky kz la lb gt lc"><div class="bz fp l di"><div class="nd ne l"/></div></figure><p id="eb2f" class="pw-post-body-paragraph jz ka it kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw im bi translated">这些函数用于计算准确性指标。这将有助于了解模型的精度如何随着模型压缩率的增加而变化。</p><h2 id="bbb9" class="mr lp it bd lq ms mt dn lu mu mv dp ly kk mw mx mc ko my mz mg ks na nb mk iz bi translated">3.模型</h2><p id="aa32" class="pw-post-body-paragraph jz ka it kb b kc mm ke kf kg mn ki kj kk mo km kn ko mp kq kr ks mq ku kv kw im bi translated">最后，我们定义模型本身和拟合函数。在Pytorch中，需要将模型定义为实现了一些默认功能的类。</p><figure class="ky kz la lb gt lc"><div class="bz fp l di"><div class="nd ne l"/></div></figure><p id="44ed" class="pw-post-body-paragraph jz ka it kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw im bi translated">请注意，fit函数与类是分开的。它们被放在一起是为了保持连贯性。有了所有这些代码，我们现在就可以加载数据并训练模型了。</p><h1 id="8b3d" class="lo lp it bd lq lr ls lt lu lv lw lx ly lz ma mb mc md me mf mg mh mi mj mk ml bi translated">B.执行</h1><h2 id="2115" class="mr lp it bd lq ms mt dn lu mu mv dp ly kk mw mx mc ko my mz mg ks na nb mk iz bi translated">1.数据准备</h2><figure class="ky kz la lb gt lc"><div class="bz fp l di"><div class="nd ne l"/></div></figure><p id="08a4" class="pw-post-body-paragraph jz ka it kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw im bi translated">这一部分创建将用于训练模型的训练和测试数据集。Pytorch有一些加载数据的标准方法，这里已经使用过了。</p><h2 id="b318" class="mr lp it bd lq ms mt dn lu mu mv dp ly kk mw mx mc ko my mz mg ks na nb mk iz bi translated">2.培养</h2><figure class="ky kz la lb gt lc"><div class="bz fp l di"><div class="nd ne l"/></div></figure><figure class="ky kz la lb gt lc gh gi paragraph-image"><div role="button" tabindex="0" class="ld le di lf bf lg"><div class="gh gi nh"><img src="../Images/22edce92a882878f65112908236b80af.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*QRo9liWAu1iZNnjaTr-nbA.png"/></div></div></figure><p id="1470" class="pw-post-body-paragraph jz ka it kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw im bi translated">上面的代码片段为20个时期训练模型。</p><p id="8191" class="pw-post-body-paragraph jz ka it kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw im bi translated">既然训练已经完成，让我们看看重量的分布。还记得这篇文章的第一部分吗？在那一部分中，权重只不过是矩阵中的值。让我们重温一下。</p><figure class="ky kz la lb gt lc"><div class="bz fp l di"><div class="nd ne l"/></div><figcaption class="lj lk gj gh gi ll lm bd b be z dk translated">各层的具体情况、权重值</figcaption></figure><figure class="ky kz la lb gt lc gh gi paragraph-image"><div role="button" tabindex="0" class="ld le di lf bf lg"><div class="gh gi ni"><img src="../Images/2f0d697cc256588d136a96e09bdfbda3.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*f3HJ7CSRFZiVvJQUg5Weqw.png"/></div></div><figcaption class="lj lk gj gh gi ll lm bd b be z dk translated">修剪后的权重值</figcaption></figure><p id="bca8" class="pw-post-body-paragraph jz ka it kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw im bi translated">为了了解重量值分布，让我们绘制一个重量直方图。</p><figure class="ky kz la lb gt lc"><div class="bz fp l di"><div class="nd ne l"/></div></figure><p id="ea1b" class="pw-post-body-paragraph jz ka it kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw im bi translated">在这个代码片段中，我们遍历模型的每一层，并将权重存储在一个平面列表中。因此，我们将它们全部绘制成柱状图。</p><figure class="ky kz la lb gt lc gh gi paragraph-image"><div role="button" tabindex="0" class="ld le di lf bf lg"><div class="gh gi nj"><img src="../Images/ec6815fc780990080893fb0fe0685653.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*pbqolgwb30ZE0aDX2vQf-g.png"/></div></div><figcaption class="lj lk gj gh gi ll lm bd b be z dk translated">权重直方图</figcaption></figure><p id="91c7" class="pw-post-body-paragraph jz ka it kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw im bi translated">上图显示了经过<strong class="kb jd">训练的</strong>神经网络的权重分布。核心论点来源于这个情节。围绕0值有大量的权重，正如宋寒在他的开创性<a class="ae ln" href="https://arxiv.org/abs/1506.02626" rel="noopener ugc nofollow" target="_blank">作品</a>中所声称的，我们可以取消这些权重，保留更高量值的权重。让我们看看当我们这样做时会发生什么。</p><h2 id="be54" class="mr lp it bd lq ms mt dn lu mu mv dp ly kk mw mx mc ko my mz mg ks na nb mk iz bi translated">修剪方法</h2><p id="8162" class="pw-post-body-paragraph jz ka it kb b kc mm ke kf kg mn ki kj kk mo km kn ko mp kq kr ks mq ku kv kw im bi translated">有不同的方法来修剪网络的权重。我们要做的是取一个剪枝率(x)并乘以权重分布的标准偏差。这个值将成为我们的门槛。低于该阈值的所有权重将被设置为0。让我们看一下代码。</p><p id="bd69" class="pw-post-body-paragraph jz ka it kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw im bi translated">但是在我们做任何事情之前，让我们保存未修剪模型的权重并重新加载模型。</p><figure class="ky kz la lb gt lc"><div class="bz fp l di"><div class="nd ne l"/></div><figcaption class="lj lk gj gh gi ll lm bd b be z dk translated">保存模型权重，因为我们将很快修改模型</figcaption></figure><p id="5f8e" class="pw-post-body-paragraph jz ka it kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw im bi translated"><strong class="kb jd">修剪步骤</strong></p><ol class=""><li id="7b94" class="nk nl it kb b kc kd kg kh kk nm ko nn ks no kw np nq nr ns bi translated">得到剪枝率<em class="nt"> (p) </em></li><li id="c777" class="nk nl it kb b kc nu kg nv kk nw ko nx ks ny kw np nq nr ns bi translated">阈值<em class="nt"> (t) = p*stdev(所有权重)</em></li><li id="0b6c" class="nk nl it kb b kc nu kg nv kk nw ko nx ks ny kw np nq nr ns bi translated">将所有低于<em class="nt"> t </em>的重量设置为0</li></ol><p id="9d73" class="pw-post-body-paragraph jz ka it kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw im bi translated">下面的代码片段是针对步骤1和2的。</p><figure class="ky kz la lb gt lc"><div class="bz fp l di"><div class="nd ne l"/></div><figcaption class="lj lk gj gh gi ll lm bd b be z dk translated">步骤1和2</figcaption></figure><figure class="ky kz la lb gt lc gh gi paragraph-image"><div class="gh gi nz"><img src="../Images/9998ce968e408cef50847ca79b9a1f5d.png" data-original-src="https://miro.medium.com/v2/resize:fit:992/format:webp/1*hrwIJZj8mwCWG7cuz6NdJw.png"/></div><figcaption class="lj lk gj gh gi ll lm bd b be z dk translated">网络中存在的输出阈值和最小、最大权重</figcaption></figure><p id="59c0" class="pw-post-body-paragraph jz ka it kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw im bi translated">当修剪率选择为2.25时，结果阈值是0.0438。这意味着-0.0438和+0.0438之间的所有权重都将被移除。因此，最大正值和+0.0438之间的权重以及最大负值和-0.0438之间的权重将被保留。现在让我们执行第3步，删除权重。</p><figure class="ky kz la lb gt lc"><div class="bz fp l di"><div class="nd ne l"/></div></figure><p id="10de" class="pw-post-body-paragraph jz ka it kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw im bi translated">上面这段代码遍历各层，将绝对值低于阈值的所有权重设置为0。当我们打印重量时，可以看到效果。</p><figure class="ky kz la lb gt lc"><div class="bz fp l di"><div class="nd ne l"/></div><figcaption class="lj lk gj gh gi ll lm bd b be z dk translated">各层的具体情况、权重值</figcaption></figure><figure class="ky kz la lb gt lc gh gi paragraph-image"><div role="button" tabindex="0" class="ld le di lf bf lg"><div class="gh gi oa"><img src="../Images/8131e3e826e2ca2fcb9d9ce547f4a031.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Nsz0LwxxtNS0G_aBJ3wCYQ.png"/></div></div><figcaption class="lj lk gj gh gi ll lm bd b be z dk translated">权重变为0</figcaption></figure><p id="fa1d" class="pw-post-body-paragraph jz ka it kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw im bi translated">可以看到，很多权重都变成了0。特别是那些绝对值低于阈值0.0438的权重。使用以下代码可以在加权直方图中进一步看到这种效果。</p><figure class="ky kz la lb gt lc"><div class="bz fp l di"><div class="nd ne l"/></div></figure><figure class="ky kz la lb gt lc gh gi paragraph-image"><div role="button" tabindex="0" class="ld le di lf bf lg"><div class="gh gi nj"><img src="../Images/8c638d761d393c724a71f68f940818c8.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*uLyODupK_WROi1vpFffyEA.png"/></div></div><figcaption class="lj lk gj gh gi ll lm bd b be z dk translated">最大重量已变为0</figcaption></figure><p id="39be" class="pw-post-body-paragraph jz ka it kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw im bi translated">上图有点难理解。您可能期望中间有一个大洞，但是，您得到的是一个长条状图，显示了大量被设置为0的权重。让我们试着从可视化中移除0个权重。</p><figure class="ky kz la lb gt lc"><div class="bz fp l di"><div class="nd ne l"/></div><figcaption class="lj lk gj gh gi ll lm bd b be z dk translated">出于可视化目的，第8行从权重列表中过滤所有0</figcaption></figure><figure class="ky kz la lb gt lc gh gi paragraph-image"><div role="button" tabindex="0" class="ld le di lf bf lg"><div class="gh gi nj"><img src="../Images/103ff662f9efbf1fe1437e30fb7dacf7.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*0Ol9xlwFvRW_cThBlzwsyA.png"/></div></div><figcaption class="lj lk gj gh gi ll lm bd b be z dk translated">预期的</figcaption></figure><p id="23d4" class="pw-post-body-paragraph jz ka it kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw im bi translated">这个直方图和预期的一样。中间有一大块空间显示已经“无效”的权重。让我们试着计算修剪后模型的压缩和精度。</p><figure class="ky kz la lb gt lc"><div class="bz fp l di"><div class="nd ne l"/></div></figure><figure class="ky kz la lb gt lc gh gi paragraph-image"><div class="gh gi ob"><img src="../Images/dc47643e9a0594d12223393afd947c55.png" data-original-src="https://miro.medium.com/v2/resize:fit:1320/format:webp/1*1BgV3aScwovhnn4Bmh3UhQ.png"/></div><figcaption class="lj lk gj gh gi ll lm bd b be z dk translated">合成压缩和准确性</figcaption></figure><p id="2bfa" class="pw-post-body-paragraph jz ka it kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw im bi translated">所以模型理论上被压缩了90%，但是精度也降低了。这是修剪的第二部分——微调。文献上说，重新训练模型，同时保持0权重为0。这意味着需要存储器组件来记住哪些权重被设为0，因为在每批数据的每个优化步骤之后，神经网络的权重被改变。我们想要做的是，记住哪些权重被设为0，并且在每个优化步骤之后，将这些权重设置回0。在文献中很难找到对这一过程的明确解释。为了节省你的麻烦，我举例说明了使用屏蔽微调的常用方法。</p><p id="fb65" class="pw-post-body-paragraph jz ka it kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw im bi translated"><strong class="kb jd">掩蔽</strong></p><p id="ed80" class="pw-post-body-paragraph jz ka it kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw im bi translated">让我们回到修剪步骤。我们不是直接将权重值设置为0，而是维护一个单独的数据结构，其形状与权重的形状相同，我们称之为掩码。掩码在开始时被初始化为1。</p><p id="dd63" class="pw-post-body-paragraph jz ka it kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw im bi translated">我们简单地记下权重的大小小于阈值的指数。然后，我们转到掩码，在该特定索引处将其设置为0。</p><figure class="ky kz la lb gt lc"><div class="bz fp l di"><div class="nd ne l"/></div><figcaption class="lj lk gj gh gi ll lm bd b be z dk translated">设置遮罩。</figcaption></figure><figure class="ky kz la lb gt lc gh gi paragraph-image"><div role="button" tabindex="0" class="ld le di lf bf lg"><div class="gh gi oc"><img src="../Images/9b492c1478c892e1975c8a3f0b864aff.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*FZ5DOzM6MmAY5MDru-DwTA.png"/></div></div><figcaption class="lj lk gj gh gi ll lm bd b be z dk translated">掩码矩阵，0将强制权重为0，1将保留权重值</figcaption></figure><p id="68bc" class="pw-post-body-paragraph jz ka it kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw im bi translated">一旦面具制作完成，我们的工作就变得简单了。在每一批中，一旦权重被优化，我们就用权重乘以掩码，并确保已经变为0的权重保持为0。我们还需要一个函数来将模型权重与掩码结合起来，然后我们修改拟合函数，在每批之后添加矩阵乘法。</p><figure class="ky kz la lb gt lc"><div class="bz fp l di"><div class="nd ne l"/></div><figcaption class="lj lk gj gh gi ll lm bd b be z dk translated">5个时期的微调</figcaption></figure><p id="4834" class="pw-post-body-paragraph jz ka it kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw im bi translated">我们用<em class="nt"> fit_prune() </em>函数重新训练该模型5个时期。这几乎与<em class="nt"> fit() </em>函数相同，除了在第28行，就在权重优化之后，我们在模型上应用相同的掩码，因此，即使一些修剪的权重变为非零，apply_mask_model函数也将掩码与模型权重相乘，并将修剪的权重设置回0。因为模型已经被训练，所以训练在较少的时期内完成。</p><figure class="ky kz la lb gt lc gh gi paragraph-image"><div role="button" tabindex="0" class="ld le di lf bf lg"><div class="gh gi od"><img src="../Images/b19ad8f80f1eb911a3da2d9908c022ee.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*uNqcr1LvOvufkY67D-YeAg.png"/></div></div><figcaption class="lj lk gj gh gi ll lm bd b be z dk translated">与未修剪模型具有相同性能的修剪模型</figcaption></figure><p id="b9f1" class="pw-post-body-paragraph jz ka it kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw im bi translated">输出显示了即使当大量(90%)权重设置为0时，模型如何快速恢复到原始精度。</p><p id="a621" class="pw-post-body-paragraph jz ka it kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw im bi translated">我希望这给你一个进入网络修剪世界的起点。为了方便起见，本教程的源代码保存在<a class="ae ln" href="https://github.com/ashhadulislam/simplePyTorchPruning" rel="noopener ugc nofollow" target="_blank"> github </a>的一个笔记本中。如果你想讨论更多，请随时与我在ashhadulislam@gmail.com取得联系，因为这是我在论文中研究的领域之一。</p></div></div>    
</body>
</html>