<html>
<head>
<title>All About Support Vector Machine</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">关于支持向量机的一切</h1>
<blockquote>原文：<a href="https://pub.towardsai.net/all-about-support-vector-machine-cfd9320315e2?source=collection_archive---------0-----------------------#2022-03-27">https://pub.towardsai.net/all-about-support-vector-machine-cfd9320315e2?source=collection_archive---------0-----------------------#2022-03-27</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><p id="a19d" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">本文将探讨支持向量机并尝试回答以下问题:</p><ul class=""><li id="2291" class="kl km iq jp b jq jr ju jv jy kn kc ko kg kp kk kq kr ks kt bi translated">什么是支持向量机？</li><li id="a38b" class="kl km iq jp b jq ku ju kv jy kw kc kx kg ky kk kq kr ks kt bi translated">支持向量机中使用的术语有哪些？</li><li id="df14" class="kl km iq jp b jq ku ju kv jy kw kc kx kg ky kk kq kr ks kt bi translated">支持向量机如何解决分类问题？</li><li id="0698" class="kl km iq jp b jq ku ju kv jy kw kc kx kg ky kk kq kr ks kt bi translated">支持向量机对于回归问题是如何工作的？</li><li id="2797" class="kl km iq jp b jq ku ju kv jy kw kc kx kg ky kk kq kr ks kt bi translated">支持向量机的优缺点是什么？</li><li id="ed6d" class="kl km iq jp b jq ku ju kv jy kw kc kx kg ky kk kq kr ks kt bi translated">如何用Scikit-learn实现支持向量机？</li></ul><h1 id="2a8b" class="kz la iq bd lb lc ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw bi translated"><strong class="ak">什么是支持向量机？</strong></h1><p id="8d05" class="pw-post-body-paragraph jn jo iq jp b jq lx js jt ju ly jw jx jy lz ka kb kc ma ke kf kg mb ki kj kk ij bi translated">支持向量机是一种有监督的机器学习算法。这种算法广泛用于数据科学/机器学习问题，因为这种算法非常强大和通用。支持向量机可用于线性和非线性分类、回归，甚至离群点检测。尽管它在具有复杂的小型或中型数据集的分类问题中被大量使用。支持向量机是一种非概率线性分类器，它使用几何方法来区分数据集中的不同类别。</p><h1 id="6e54" class="kz la iq bd lb lc ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw bi translated"><strong class="ak">支持向量机中使用的术语有哪些？</strong></h1><p id="a5ff" class="pw-post-body-paragraph jn jo iq jp b jq lx js jt ju ly jw jx jy lz ka kb kc ma ke kf kg mb ki kj kk ij bi translated">我们知道什么是支持向量机。现在，我们将深入研究支持向量机中使用的核心概念和术语。</p><h2 id="c4f0" class="mc la iq bd lb md me dn lf mf mg dp lj jy mh mi ln kc mj mk lr kg ml mm lv mn bi translated"><strong class="ak">支持向量</strong></h2><p id="8ce7" class="pw-post-body-paragraph jn jo iq jp b jq lx js jt ju ly jw jx jy lz ka kb kc ma ke kf kg mb ki kj kk ij bi translated">向量是n维图上表示的数据点。例如，我们在像这样的2D图上表示一个点(x，y ),在像这样的3D图中表示一个点(x，y，z ),其中x，y，z是图的轴。</p><figure class="mp mq mr ms gt mt gh gi paragraph-image"><div class="gh gi mo"><img src="../Images/17cf39556e8cda8eb20859ff458209ca.png" data-original-src="https://miro.medium.com/v2/resize:fit:794/format:webp/1*lB3iVr2-4aKqmYorigpeOA.png"/></div><figcaption class="mw mx gj gh gi my mz bd b be z dk translated">支持向量</figcaption></figure><p id="4bb3" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">因此，支持向量是n维图上最接近超平面的点的向量，并且影响超平面的方向。通过这个支持向量，我们传递了超平面的正负边界。</p><h2 id="0f88" class="mc la iq bd lb md me dn lf mf mg dp lj jy mh mi ln kc mj mk lr kg ml mm lv mn bi translated"><strong class="ak">超平面</strong></h2><p id="fb20" class="pw-post-body-paragraph jn jo iq jp b jq lx js jt ju ly jw jx jy lz ka kb kc ma ke kf kg mb ki kj kk ij bi translated">超平面只不过是一个具有(n-1)维的决策边界，其中n是数据集中的列数。超平面分离不同类别的点/向量。<br/>例-1:在2D图形表示中，我们使用如下所示的线来分隔点。</p><figure class="mp mq mr ms gt mt gh gi paragraph-image"><div class="gh gi na"><img src="../Images/fff910f28c26b95c1b32fada933367ea.png" data-original-src="https://miro.medium.com/v2/resize:fit:772/format:webp/1*QSc14HkVBqmeoGeJuJhpvw.png"/></div><figcaption class="mw mx gj gh gi my mz bd b be z dk translated">2D的超平面</figcaption></figure><p id="33d8" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">图中表示的绿线充当超平面，这个超平面的方程将等于</p><figure class="mp mq mr ms gt mt gh gi paragraph-image"><div class="gh gi nb"><img src="../Images/a63fe8a9676eb490fdea9aad3fde9d55.png" data-original-src="https://miro.medium.com/v2/resize:fit:248/format:webp/1*Pfv0i-P-YezyCp5bYBJucw.png"/></div></figure><p id="d623" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">我们可以把它重写为</p><figure class="mp mq mr ms gt mt gh gi paragraph-image"><div class="gh gi nc"><img src="../Images/e86b86fb1a66146488490f958e63738c.png" data-original-src="https://miro.medium.com/v2/resize:fit:346/format:webp/1*J_i16za5n5IYJf2nqtOwLg.png"/></div></figure><p id="c8db" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">示例2:在3D图形表示中，我们使用如下所示的平面来分隔点。</p><figure class="mp mq mr ms gt mt gh gi paragraph-image"><div class="gh gi nd"><img src="../Images/883d1df3d24638d3b0651d3cd9fbdfbc.png" data-original-src="https://miro.medium.com/v2/resize:fit:1200/1*Z3Msm7PINQcol5hVWgKRFg.gif"/></div><figcaption class="mw mx gj gh gi my mz bd b be z dk translated">三维超平面</figcaption></figure><p id="140d" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">图中所表示的薄板作为超平面，这个超平面的方程将等于这个薄板的方程</p><figure class="mp mq mr ms gt mt gh gi paragraph-image"><div class="gh gi ne"><img src="../Images/3fdbaa1e99ffa0453185b103a8e47db6.png" data-original-src="https://miro.medium.com/v2/resize:fit:456/format:webp/1*c_gSKnegfW-ZgXHhAhvRcQ.png"/></div></figure><p id="dcfe" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">类似地，对于n维数据集，超平面方程将是:</p><figure class="mp mq mr ms gt mt gh gi paragraph-image"><div class="gh gi nf"><img src="../Images/45db4a917dc9b18bb5af286ea83d87ba.png" data-original-src="https://miro.medium.com/v2/resize:fit:722/format:webp/1*lMjWxBDYnnHPBkYziiQCZw.png"/></div></figure><p id="a86b" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">如果我们用向量的形式重写这个:</p><figure class="mp mq mr ms gt mt gh gi paragraph-image"><div class="gh gi ng"><img src="../Images/d638a444a788848d81f1bf159c81d84b.png" data-original-src="https://miro.medium.com/v2/resize:fit:276/format:webp/1*klDtLsSzwsolhDyw4TJn3g.png"/></div><figcaption class="mw mx gj gh gi my mz bd b be z dk translated">超平面的向量形式</figcaption></figure><h2 id="c267" class="mc la iq bd lb md me dn lf mf mg dp lj jy mh mi ln kc mj mk lr kg ml mm lv mn bi translated"><strong class="ak">内核</strong></h2><p id="d3d7" class="pw-post-body-paragraph jn jo iq jp b jq lx js jt ju ly jw jx jy lz ka kb kc ma ke kf kg mb ki kj kk ij bi translated">核是SVM使用的一种数学函数，用于将非线性数据转换为更高维的数据集，以便SVM可以通过使用超平面来分离数据的类别。在Scikit-learn中，SVM支持各种类型的内核，如<em class="nh">‘线性’，‘多边形’，‘RBF’，‘sigmoid’。此外，我们可以创建自己的内核，并在s </em> cikit-learn <em class="nh"> SVM中传递它。<br/> </em>现在让我们看一个例子来更好的理解内核的作用:<br/>下图代表了两种类型的数据点。</p><figure class="mp mq mr ms gt mt gh gi paragraph-image"><div class="gh gi ni"><img src="../Images/81b59dda881f15da2f259e7b10644aa6.png" data-original-src="https://miro.medium.com/v2/resize:fit:782/format:webp/1*MY3t2JtzvtDTWDb7jyWMJw.png"/></div><figcaption class="mw mx gj gh gi my mz bd b be z dk translated">非线性数据点</figcaption></figure><p id="dc1d" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">现在，如果我们想创建一个超平面，它会像这样。</p><figure class="mp mq mr ms gt mt gh gi paragraph-image"><div class="gh gi nj"><img src="../Images/18e0c2e20d6a28522fc7f0b24f0b844b.png" data-original-src="https://miro.medium.com/v2/resize:fit:776/format:webp/1*uJjpuRLPQ04eIFkj-mNKFg.png"/></div><figcaption class="mw mx gj gh gi my mz bd b be z dk translated">线性超平面</figcaption></figure><p id="ab6a" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">我们可以观察到它不能正确地分离所有的点。但是如果我们考虑径向基函数核。</p><figure class="mp mq mr ms gt mt gh gi paragraph-image"><div class="gh gi nk"><img src="../Images/7c8be862d04031601765ca1da1ab8df4.png" data-original-src="https://miro.medium.com/v2/resize:fit:796/format:webp/1*V0gqZ618HxpR0bZqVso7kw.png"/></div><figcaption class="mw mx gj gh gi my mz bd b be z dk translated">RBF核超平面</figcaption></figure><p id="fc68" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">它能够正确地分离所有的点。但问题是怎么做？实际上径向基函数核变换数据集如下图所示。</p><figure class="mp mq mr ms gt mt gh gi paragraph-image"><div class="gh gi nl"><img src="../Images/fd014a2680734e7b2ec31216d290f607.png" data-original-src="https://miro.medium.com/v2/resize:fit:706/format:webp/1*CykvoeZllfkBJAn3tJ3kEg.png"/></div></figure><p id="78b0" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">我们可以观察到，在3D中，我们可以绘制一个超平面来分隔这些点。这就是如何借助正确的内核SVM分类数据点。</p><h2 id="8e79" class="mc la iq bd lb md me dn lf mf mg dp lj jy mh mi ln kc mj mk lr kg ml mm lv mn bi translated">边缘</h2><p id="bd80" class="pw-post-body-paragraph jn jo iq jp b jq lx js jt ju ly jw jx jy lz ka kb kc ma ke kf kg mb ki kj kk ij bi translated">边距是穿过支持向量的线，它们总是平行于超平面。</p><figure class="mp mq mr ms gt mt gh gi paragraph-image"><div class="gh gi na"><img src="../Images/a8797a3ec4c1c21fb5d935dd752df0d9.png" data-original-src="https://miro.medium.com/v2/resize:fit:772/format:webp/1*Q6tJzCnEBfjzXTQ_cfzNag.png"/></div></figure><h1 id="a7de" class="kz la iq bd lb lc ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw bi translated"><strong class="ak">支持向量机如何处理分类问题？</strong></h1><p id="f916" class="pw-post-body-paragraph jn jo iq jp b jq lx js jt ju ly jw jx jy lz ka kb kc ma ke kf kg mb ki kj kk ij bi translated">SVM的主要任务是最大化边距之间的距离，使得没有点穿过边距。这也被称为“硬边际SVM”。<br/>在理想世界中，上述条件永远不会违反，距离可以计算为:</p><figure class="mp mq mr ms gt mt gh gi paragraph-image"><div class="gh gi nm"><img src="../Images/89023a027a20bc9a543018f4b72aad45.png" data-original-src="https://miro.medium.com/v2/resize:fit:144/format:webp/1*RUQS_MlMrMH7Kkev2PThyg.png"/></div><figcaption class="mw mx gj gh gi my mz bd b be z dk translated">边距之间的距离</figcaption></figure><p id="3f70" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">但是在现实世界中，我们总是得到带有一些异常值的不纯数据，如果我们遵循硬边界概念，那么我们将无法创建任何超平面。因此，引入了一个新概念，即“软边际SVM”。在这里，我们引入一个新元素，即“铰链损耗”。</p><figure class="mp mq mr ms gt mt gh gi paragraph-image"><div class="gh gi nn"><img src="../Images/87527813a259d233615f33e87a7f01b3.png" data-original-src="https://miro.medium.com/v2/resize:fit:400/format:webp/1*vKQAFFKbaXvmzrTgAFdxIg.png"/></div></figure><p id="2058" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">在软裕度中，SVM铰链函数是异常点和裕度之间距离的总和，然后乘以超参数“C”。</p><figure class="mp mq mr ms gt mt gh gi paragraph-image"><div class="gh gi no"><img src="../Images/5d3f0fc0eab0d7e10f81b2b4355001b6.png" data-original-src="https://miro.medium.com/v2/resize:fit:804/format:webp/1*itQ2EQdJJ_ws7USaxaNS-A.png"/></div><figcaption class="mw mx gj gh gi my mz bd b be z dk translated">使用铰链函数处理异常值</figcaption></figure><h1 id="60fb" class="kz la iq bd lb lc ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw bi translated">支持向量机对于回归问题是如何工作的？</h1><p id="f72d" class="pw-post-body-paragraph jn jo iq jp b jq lx js jt ju ly jw jx jy lz ka kb kc ma ke kf kg mb ki kj kk ij bi translated">在回归分析中，SVM采取了一种稍微不同的方法。这种方法可以用三行来解释。第一条线是最佳拟合回归线，另外两条线是表示误差范围的边界线。</p><p id="d762" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">换句话说，最佳拟合线(或超平面)将是穿过最大数量的数据点的线，并且选择误差边界以确保最大包含。</p><h1 id="75e8" class="kz la iq bd lb lc ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw bi translated"><strong class="ak">支持向量机的优缺点是什么？</strong></h1><h2 id="0985" class="mc la iq bd lb md me dn lf mf mg dp lj jy mh mi ln kc mj mk lr kg ml mm lv mn bi translated"><strong class="ak">优点:</strong></h2><ol class=""><li id="b9b1" class="kl km iq jp b jq lx ju ly jy np kc nq kg nr kk ns kr ks kt bi translated">SVM在高维空间是有效的。</li><li id="0a17" class="kl km iq jp b jq ku ju kv jy kw kc kx kg ky kk ns kr ks kt bi translated">它在维数大于样本数的情况下仍然有效</li><li id="8e9a" class="kl km iq jp b jq ku ju kv jy kw kc kx kg ky kk ns kr ks kt bi translated">SVM的记忆效率很高。</li></ol><h2 id="b22a" class="mc la iq bd lb md me dn lf mf mg dp lj jy mh mi ln kc mj mk lr kg ml mm lv mn bi translated"><strong class="ak">缺点:</strong></h2><ol class=""><li id="8491" class="kl km iq jp b jq lx ju ly jy np kc nq kg nr kk ns kr ks kt bi translated">如果特征的数量远大于样本的数量，那么它避免了在选择核函数时的过拟合。</li><li id="ca56" class="kl km iq jp b jq ku ju kv jy kw kc kx kg ky kk ns kr ks kt bi translated">SVM不像逻辑回归那样直接提供概率估计。</li></ol><h1 id="d32c" class="kz la iq bd lb lc ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw bi translated"><strong class="ak">如何用</strong> Scikit-learn <strong class="ak">实现支持向量机？</strong></h1><p id="44e5" class="pw-post-body-paragraph jn jo iq jp b jq lx js jt ju ly jw jx jy lz ka kb kc ma ke kf kg mb ki kj kk ij bi translated">SVM的实现非常简单和容易。我们只需要导入sklearn包。对于这个例子，我们使用一个已经存在于sklearn包中的玩具数据集，这个例子是一个分类问题。此外，我们将从python导入一些必要的包。</p><figure class="mp mq mr ms gt mt gh gi paragraph-image"><div role="button" tabindex="0" class="nu nv di nw bf nx"><div class="gh gi nt"><img src="../Images/dbda1e5f48996a5086a0120344d36dcc.png" data-original-src="https://miro.medium.com/v2/resize:fit:1296/format:webp/1*qAZPoZ3kDZh9lMzj_r0GoQ.png"/></div></div></figure><p id="8bf7" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">现在，提取数据</p><figure class="mp mq mr ms gt mt gh gi paragraph-image"><div class="gh gi ny"><img src="../Images/a24e91e0228f52d24a07b1f071b46794.png" data-original-src="https://miro.medium.com/v2/resize:fit:766/format:webp/1*JS6pInTqLYmGq1RlL0L7YA.png"/></div></figure><p id="33ff" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">我们正在使用乳腺癌威斯康星州(诊断)数据集。</p><pre class="mp mq mr ms gt nz oa ob oc aw od bi"><span id="5bcf" class="mc la iq oa b gy oe of l og oh">Data Set Characteristics:<br/><br/>    :Number of Instances: 569<br/><br/>    :Number of Attributes: 30 numeric, predictive attributes and the class<br/><br/>    :Attribute Information:<br/>        - radius (mean of distances from center to points on the perimeter)<br/>        - texture (standard deviation of gray-scale values)<br/>        - perimeter<br/>        - area<br/>        - smoothness (local variation in radius lengths)<br/>        - compactness (perimeter^2 / area - 1.0)<br/>        - concavity (severity of concave portions of the contour)<br/>        - concave points (number of concave portions of the contour)<br/>        - symmetry<br/>        - fractal dimension ("coastline approximation" - 1)<br/>- class:<br/>        - WDBC-Malignant<br/>        - WDBC-Benign</span></pre><p id="f984" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">将数据集分成训练集和测试集。</p><figure class="mp mq mr ms gt mt gh gi paragraph-image"><div role="button" tabindex="0" class="nu nv di nw bf nx"><div class="gh gi oi"><img src="../Images/6f146ae2f4de500c3a6cefebee60130e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*gaJ43qHm4KcvQVhh_z9_7g.png"/></div></div></figure><p id="415a" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">现在使用训练数据训练模型，然后预测测试数据的结果</p><blockquote class="oj ok ol"><p id="a2ef" class="jn jo nh jp b jq jr js jt ju jv jw jx om jz ka kb on kd ke kf oo kh ki kj kk ij bi translated">注意:SVC有许多超参数，我们可以调整它们以获得更好的结果。</p></blockquote><figure class="mp mq mr ms gt mt gh gi paragraph-image"><div role="button" tabindex="0" class="nu nv di nw bf nx"><div class="gh gi op"><img src="../Images/2a415cd7e6d908c1951550a9e526b19c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*7uURXAXdW-oYkdy8ExO7Qw.png"/></div></div></figure><p id="5fbf" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">最后使用混淆矩阵、准确度分数和F1分数来测量准确度</p><figure class="mp mq mr ms gt mt gh gi paragraph-image"><div class="gh gi oq"><img src="../Images/761c9e0c5b50b796760729bf09240b16.png" data-original-src="https://miro.medium.com/v2/resize:fit:1242/format:webp/1*iLICVz60Y6oQg0xvnFPfGA.png"/></div></figure><blockquote class="oj ok ol"><p id="a320" class="jn jo nh jp b jq jr js jt ju jv jw jx om jz ka kb on kd ke kf oo kh ki kj kk ij bi translated"><em class="iq">本文使用的笔记本链接:</em></p></blockquote><div class="or os gp gr ot ou"><a href="https://github.com/Akashdawari/Articles_Blogs_Content/blob/main/All%20About%20Support%20Vector%20Machine%20.ipynb" rel="noopener  ugc nofollow" target="_blank"><div class="ov ab fo"><div class="ow ab ox cl cj oy"><h2 class="bd ir gy z fp oz fr fs pa fu fw ip bi translated">关于支持向量机的文章_博客_内容/全部。ipynb在主…</h2><div class="pb l"><h3 class="bd b gy z fp oz fr fs pa fu fw dk translated">这个知识库包含了jupyter关于博客中发表的文章的笔记本。-文章_博客_内容/全部…</h3></div><div class="pc l"><p class="bd b dl z fp oz fr fs pa fu fw dk translated">github.com</p></div></div><div class="pd l"><div class="pe l pf pg ph pd pi mu ou"/></div></div></a></div><p id="2e1a" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">喜欢并分享如果你觉得这篇文章有帮助。还有，关注我的medium，了解更多机器学习和深度学习相关的内容。</p></div></div>    
</body>
</html>