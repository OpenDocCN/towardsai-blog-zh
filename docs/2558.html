<html>
<head>
<title>Tabular Learning — Gradient Boosting vs Deep Learning( Critical Review)</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">表格学习—梯度推进与深度学习(评论)</h1>
<blockquote>原文：<a href="https://pub.towardsai.net/tabular-learning-gradient-boosting-vs-deep-learning-critical-review-4871c99ee9a2?source=collection_archive---------0-----------------------#2022-02-19">https://pub.towardsai.net/tabular-learning-gradient-boosting-vs-deep-learning-critical-review-4871c99ee9a2?source=collection_archive---------0-----------------------#2022-02-19</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><p id="4f67" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi kl translated">得益于技术进步和经济实惠的计算，复杂的系统正在被开发出来，以分析指数级增长的数据并生成可操作的见解。作为这些复杂系统的核心，神经网络在同质(文本和图像)数据上表现出了非凡的性能。然而，直到最近，神经网络才被用于异构表格数据，这是最古老和最常见的数据形式。基于树的模型在表格数据上的竞争性能也可能是神经网络利用不足的一个因素。对于提出的各种模型，我们试图对它们进行分类，并为其中一些声称是最先进的模型提供一些基本的理解。这项工作试图回答已建立的基准的可用性，以及是否是时候从基于树的模型跳到基于神经网络的表格数据模型了。</p><figure class="kv kw kx ky gt kz gh gi paragraph-image"><div role="button" tabindex="0" class="la lb di lc bf ld"><div class="gh gi ku"><img src="../Images/760875cc055ec769ca3f163669d51da0.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*dPxIBxbzdbDc5pVw5Wix-w.png"/></div></div><figcaption class="lg lh gj gh gi li lj bd b be z dk translated">评论中的一些模型</figcaption></figure><h1 id="7a76" class="lk ll iq bd lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma mb mc md me mf mg mh bi translated">介绍</h1><p id="7c94" class="pw-post-body-paragraph jn jo iq jp b jq mi js jt ju mj jw jx jy mk ka kb kc ml ke kf kg mm ki kj kk ij bi translated">表格数据由固定长度向量(列作为特征)的样本(行)组成，可以存储在文本、CSV、TSV等平面文件中。这是数字时代之前收集的唯一形式的数据，使其成为现实世界应用中最古老和最常见的数据。Kaggle(2017)最近的一项调查报告称，关系数据是结构化数据或表格数据的一个细分，是业内最受欢迎的数据形式，在总共14，000名数据科学家中，至少有65%的人每天都在使用它[16]。从生物信息学、电子商务、医学、银行、金融到其他基于关系数据库的领域，它无处不在。一些问题包括客户流失预测、医疗诊断、风险分析、欺诈检测、用户和产品推荐等。</p><h2 id="8683" class="mn ll iq bd lm mo mp dn lq mq mr dp lu jy ms mt ly kc mu mv mc kg mw mx mg my bi translated">神经网络与梯度推进模型</h2><p id="8d5b" class="pw-post-body-paragraph jn jo iq jp b jq mi js jt ju mj jw jx jy mk ka kb kc ml ke kf kg mm ki kj kk ij bi translated">深度学习解决方案已被广泛用于涉及同质数据(如图像、语音和文本)的任务。它们出色的表现可以归因于它们独特的结构设计来模拟特定的数据模式，如CNN捕捉空间局部性和RNN模拟序列依赖性。虽然表格深度学习不是未知领域，但近年来仍未得到充分探索。尽管在理论上优于梯度推进树，但在大多数应用中，基于“浅”树的集成方法的变体仍然主导深度学习模型。这种较差的性能可能是由于数据集的不同统计属性或者缺乏关于数据集结构的先验知识。虽然改变一个对象需要许多像素，但是在表格数据的情况下，对输入的微小改变可能会改变标注或预测。基于树的模型最受欢迎的优点是它们的可解释性和可解释性，这是许多现实应用中的一个基本问题。然而，它们不适合流数据的连续训练，无监督的预训练和用图像和文本等其他形式的训练，这导致了近年来对表格深度学习的兴趣不断增加。</p><p id="b799" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">此外，神经网络是灵活的，并提供许多好处，例如减轻对手动分类编码和特征工程的需要，这是基于树的学习的一个基本方面。这些原因导致了几种基于深度学习的表格数据解决方案，同时新的解决方案也在不断开发。而其中的一些(AutoInt[14]，FT-Transformer[4]，TabNet[1]，TabTransformer[6]等。)声称优于基于树的模型，但由于缺乏既定的基准(如用于计算机视觉的ImageNet和用于NLP的GLUE)，它们使用不同的数据集和度量进行评估，这使得很难对算法进行排名或调查它们是否普遍优于基于树的算法[4]。虽然它们可以推动最先进的技术，但是在某些情况下，由于软件工程和实现的挑战，它们仍然没有被广泛采用。人们可以快速训练流行的基于树的模型(CatBoost、LightGBM、XGBoost等)。)在一条线上，对于，例如。</p><pre class="kv kw kx ky gt mz na nb nc aw nd bi"><span id="a2d9" class="mn ll iq na b gy ne nf l ng nh">Model = Model = CatBoost().f it(X, y)</span></pre><p id="7ffc" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">这与流行的基于表格深度学习的模型不同。像fasta.ai(让神经网络再次变得不酷)、Deep Tables(针对表格数据的深度学习工具包)和PyTorch Tabular这样的旨在让深度学习易于使用的库，给了未来一些希望。</p><h2 id="0728" class="mn ll iq bd lm mo mp dn lq mq mr dp lu jy ms mt ly kc mu mv mc kg mw mx mg my bi translated">方法学</h2><p id="c69c" class="pw-post-body-paragraph jn jo iq jp b jq mi js jt ju mj jw jx jy mk ka kb kc ml ke kf kg mm ki kj kk ij bi translated">如前所述，表格数据包含作为样本的行和作为特征的列。这些特征可以是相关的或独立的，可以有也可以没有关系，并且不遵循任何位置顺序。它们可以是连续的(数字的)也可以是离散的(分类的)，但在方式上是有挑战性的。虽然数字属性可能是多模态的或者可能不遵循任何已知的分布，但是离散特征是定性的。正如David M. Lane在他的定义[9]中所描述的，他们可以从有限的唯一的一组值中获取值，并且可以不遵循任何特定的顺序。在传统的机器学习模型中，特征处理或工程是必不可少的，这些模型使用领域知识来提取预测特征并将分类特征转换为数字特征。可以应用一维(一键编码、目标编码、二进制编码或留一编码)或多维编码技术，使得在类别或特征内不引入人工排序。当分类特征(基数)的不同值变得显著时，由于稀疏特征向量，它可能会增加整体大小。</p><h2 id="21f3" class="mn ll iq bd lm mo mp dn lq mq mr dp lu jy ms mt ly kc mu mv mc kg mw mx mg my bi translated">转换模型</h2><p id="daf4" class="pw-post-body-paragraph jn jo iq jp b jq mi js jt ju mj jw jx jy mk ka kb kc ml ke kf kg mm ki kj kk ij bi translated">受视觉神经科学启发的深度神经网络(DNNs)和卷积神经网络(CNN)在计算机视觉任务中表现出优异的性能。但是，由于缺少要素之间的空间关系，它们不适合用于表格数据。由于表格或结构化数据中的要素被认为是相互独立的，因此它们顺序的任何变化都不会影响数据。</p><h2 id="afaa" class="mn ll iq bd lm mo mp dn lq mq mr dp lu jy ms mt ly kc mu mv mc kg mw mx mg my bi translated">DeepInsight和IGTD</h2><p id="e8ae" class="pw-post-body-paragraph jn jo iq jp b jq mi js jt ju mj jw jx jy mk ka kb kc ml ke kf kg mm ki kj kk ij bi translated">最近的算法，如Deep Insight[12]和IGTD[17](表格数据的图像生成器)，建议在2-D空间中重新排列这些特征，以表示关系，并使用CNN[12，17]将表格数据转换为用于预测建模的图像。这种转变将消除特征工程，因为CNN可以通过隐藏层从图像中提取特征。这两种算法都建议重新排列特征以创建空间关系；然而，他们的方法并不相似。Deep Insight使用非线性降维技术，如t-SNE或核主成分分析(k-PCA)，以获得2-D平面和凸包算法，以找到包含所有点的最小矩形[12，17]。然后旋转矩形生成的图像，使其水平或垂直对齐，并通过CNN进行分类[12，17]。图1中还提供了流程的可视化表示。IGTD还旨在保持图像表示中的相似特征，但最小化特征距离排序和像素距离排序之间的差异[17]。作者还报告说，虽然Deep Insight从同一数据集生成图像的速度更快，但IGTD创建了更紧凑的图像表示，减少了内存消耗，并缩短了CNN的训练时间。IGTD似乎对不同的超参数也很稳健[17]。</p><figure class="kv kw kx ky gt kz gh gi paragraph-image"><div role="button" tabindex="0" class="la lb di lc bf ld"><div class="gh gi ni"><img src="../Images/d5c8d93cdb8713ae8a2716632b11e7f8.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*hXDxxntNz4YFm4v5W0sDxA.jpeg"/></div></div><figcaption class="lg lh gj gh gi li lj bd b be z dk translated">图1: DeepInsight pipeline包括(a)从特征向量到特征矩阵的转换，以及(b)将特征向量转换为图像像素的方法[12]。</figcaption></figure><h2 id="95d2" class="mn ll iq bd lm mo mp dn lq mq mr dp lu jy ms mt ly kc mu mv mc kg mw mx mg my bi translated">SuperTML</h2><p id="95d5" class="pw-post-body-paragraph jn jo iq jp b jq mi js jt ju mj jw jx jy mk ka kb kc ml ke kf kg mm ki kj kk ij bi translated">另一种方法SuperTML[16](超级表格数据机器学习)，也提出将表格/结构化数据转换为图像，但受超级字符[15]的启发，将文本转换为图像，并使用CNN对产生的问题执行图像分类[16]。图3和图2给出了SuperTML和超级字符的一个例子。SuperTML和Super Characters都将每个样本的内容(文本或特征行)转换为二维矩阵或图像，其中每个像素都表示为样本的每个特征[16，15]。然后，将在较大数据集上预训练的CNN应用于结果图像，用于图像分类问题，以实现更高的精度。虽然Deep Insight或IGTD算法在要素之间没有或几乎没有空间关系或相互独立时可能会失败，但SuperTML尚未报告任何此类限制。虽然上面提到的算法(IGTD、Deep Insight、SuperTML)在它们出现的数据集上表现良好，但在它们在一系列数据集上进行评估之前，不应推荐它们。</p><div class="kv kw kx ky gt ab cb"><figure class="nj kz nk nl nm nn no paragraph-image"><img src="../Images/077084f129426538f3735de1a89c3b03.png" data-original-src="https://miro.medium.com/v2/resize:fit:582/format:webp/1*nSu8vm-OgUjWHwH5FODxWw.jpeg"/></figure><figure class="nj kz np nl nm nn no paragraph-image"><div role="button" tabindex="0" class="la lb di lc bf ld"><img src="../Images/6db9147e0d4aa43166f59def77e35633.png" data-original-src="https://miro.medium.com/v2/resize:fit:1362/format:webp/1*NnItcZrhGS6o3mqvZzEfQw.jpeg"/></div><figcaption class="lg lh gj gh gi li lj bd b be z dk nq di nr ns translated">图2:一个超级角色的例子[15]。图3:一个将训练数据从表格转换成图像的例子，在表格数据中嵌入二维特征[16]。</figcaption></figure></div><h2 id="934f" class="mn ll iq bd lm mo mp dn lq mq mr dp lu jy ms mt ly kc mu mv mc kg mw mx mg my bi translated">混合模型</h2><p id="b905" class="pw-post-body-paragraph jn jo iq jp b jq mi js jt ju mj jw jx jy mk ka kb kc ml ke kf kg mm ki kj kk ij bi translated">混合模型融合了神经网络和基于树的模型，以获得两个世界的最佳效果-神经网络的自动特征工程和基于树的模型的表格数据的卓越性能。这些模型已被制成可区分的，以用于端到端的培训管道，并利用梯度优化。</p><h2 id="d59c" class="mn ll iq bd lm mo mp dn lq mq mr dp lu jy ms mt ly kc mu mv mc kg mw mx mg my bi translated">结节</h2><p id="d954" class="pw-post-body-paragraph jn jo iq jp b jq mi js jt ju mj jw jx jy mk ka kb kc ml ke kf kg mm ki kj kk ij bi translated">基于成功的梯度推进模型，CatBoost作者提出了NODE——使用entmax变换和软分裂的完全可微分决策树的集合。随着适当的实施，它在研究论文中提到的一些数据集上优于基于树的模型，这导致了它在行业中的采用[11]。图4给出了节点架构示意图。</p><figure class="kv kw kx ky gt kz gh gi paragraph-image"><div role="button" tabindex="0" class="la lb di lc bf ld"><div class="gh gi nt"><img src="../Images/468f4656e05663fe4573da3ac9bd609d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*178OhBrG7oGNdLjRMYuzWA.jpeg"/></div></div><figcaption class="lg lh gj gh gi li lj bd b be z dk translated">图4:节点架构，由密集连接的节点层组成。每一层包含几个树，它们的输出被连接起来，作为下一层的输入。通过平均所有层的所有树的输出来获得最终预测[11]。</figcaption></figure><h2 id="39d9" class="mn ll iq bd lm mo mp dn lq mq mr dp lu jy ms mt ly kc mu mv mc kg mw mx mg my bi translated">Wide&amp;Deep、DeepFM和DNN2LR</h2><p id="9626" class="pw-post-body-paragraph jn jo iq jp b jq mi js jt ju mj jw jx jy mk ka kb kc ml ke kf kg mm ki kj kk ij bi translated">Cheng等人在2016年提出了Wide&amp;Deep[2] —一种线性模型，它利用手工制作的特征逻辑表达式以及n维分类嵌入，并将它们与非线性层相结合[2]。宽、深和宽深模型的架构如图5所示。为了取代人工特征工程的需要，DeepFM中的Guo等人提出用学习分解机器来取代它们，这在学习高维稀疏数据中的关联方面是有效的[5]。Liu等人在DNN2LR中提出了一种自动特征交叉方法，该方法能够通过逻辑回归实现比复杂神经网络更高的性能[10]。</p><figure class="kv kw kx ky gt kz gh gi paragraph-image"><div role="button" tabindex="0" class="la lb di lc bf ld"><div class="gh gi nu"><img src="../Images/27f3e0ef5ed97e001c3a6e4e69b226c7.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*YOv8rXzRZ-tZE-6jnf3eNQ.jpeg"/></div></div><figcaption class="lg lh gj gh gi li lj bd b be z dk translated">图5:宽和深模型的光谱图[2]。</figcaption></figure><h2 id="6ab1" class="mn ll iq bd lm mo mp dn lq mq mr dp lu jy ms mt ly kc mu mv mc kg mw mx mg my bi translated">DeepGBM</h2><p id="2159" class="pw-post-body-paragraph jn jo iq jp b jq mi js jt ju mj jw jx jy mk ka kb kc ml ke kf kg mm ki kj kk ij bi translated">Ke等人提出的DeepGBM[8]是部分可微的，具有强大的学习能力，它结合了两个神经网络，用于处理稀疏分类特征的CatNN和用于密集数值特征的GBDT2NN。它在在线预测上优于梯度提升树的性能是值得称赞的；然而，它缺乏可解释性，并拥有一些数据相关的问题。DeepGBM模型的架构如图6所示。</p><figure class="kv kw kx ky gt kz gh gi paragraph-image"><div class="gh gi nv"><img src="../Images/a1c318b63b4ee2ced2f69f32bc212706.png" data-original-src="https://miro.medium.com/v2/resize:fit:1144/format:webp/1*jwMy2ZYAJS6QuRYvlaZCVQ.jpeg"/></div><figcaption class="lg lh gj gh gi li lj bd b be z dk translated">图DeepGBM的框架，包括两个组件，CatNN和GBDT2NN，分别处理稀疏分类和密集数字特征[8]。</figcaption></figure><h2 id="1388" class="mn ll iq bd lm mo mp dn lq mq mr dp lu jy ms mt ly kc mu mv mc kg mw mx mg my bi translated">基于变压器的模型</h2><p id="6b42" class="pw-post-body-paragraph jn jo iq jp b jq mi js jt ju mj jw jx jy mk ka kb kc ml ke kf kg mm ki kj kk ij bi translated">由于各种转换器(基于注意机制)在同质数据上的普遍成功，一些作者主张将它们用于表格学习。</p><h2 id="b5db" class="mn ll iq bd lm mo mp dn lq mq mr dp lu jy ms mt ly kc mu mv mc kg mw mx mg my bi translated"><strong class="ak"> TabNet </strong></h2><p id="2dad" class="pw-post-body-paragraph jn jo iq jp b jq mi js jt ju mj jw jx jy mk ka kb kc ml ke kf kg mm ki kj kk ij bi translated">TabNet[1]是首批基于注意力机制的深度表格学习模型之一，旨在提供卓越的性能和可解释性[1]。就像一个基于树的模型，其中每个决策步骤都是按层次顺序处理的，它在每个决策步骤都利用了一个子网络，该子网络使用顺序注意力特征选择[1]。最终预测是所有决策步骤输出的集合。它还可以通过自我监督学习利用未标记的数据来提高预测质量[1]。TabNet的编码器、解码器和特征转换器的架构如图7所示。</p><figure class="kv kw kx ky gt kz gh gi paragraph-image"><div role="button" tabindex="0" class="la lb di lc bf ld"><div class="gh gi nw"><img src="../Images/113daa794cc0032b5d0d4f7a290d16d5.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*IiMpl8uopjWQP7NrDevqhA.jpeg"/></div></div><figcaption class="lg lh gj gh gi li lj bd b be z dk translated">图7:(a)TabNet编码器，(b) TabNet解码和TabNet特性转换器模块的示例[1]。</figcaption></figure><h2 id="2352" class="mn ll iq bd lm mo mp dn lq mq mr dp lu jy ms mt ly kc mu mv mc kg mw mx mg my bi translated">tab-变压器</h2><figure class="kv kw kx ky gt kz gh gi paragraph-image"><div class="gh gi nx"><img src="../Images/05df89e2ca9efc1b616729495666900b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1110/format:webp/1*qjEmASxoRL-usG2XYE9G7A.jpeg"/></div><figcaption class="lg lh gj gh gi li lj bd b be z dk translated">图8:Tab-Transformer的架构[6]。</figcaption></figure><p id="05bb" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">与Tab-Net类似，TabTransformer[6]也提出了监督和自监督方法[6]。它使用多层感知器，输入是映射到上下文嵌入自我注意机制的数字特征和分类特征的组合[6]。无监督的预训练(对未标记的数据)使用基于多头注意力的转换器来创建对缺失和噪声数据鲁棒的上下文嵌入[6]。TabTransformer模型的架构如图8所示。</p><h2 id="9074" class="mn ll iq bd lm mo mp dn lq mq mr dp lu jy ms mt ly kc mu mv mc kg mw mx mg my bi translated">自动点火</h2><p id="5904" class="pw-post-body-paragraph jn jo iq jp b jq mi js jt ju mj jw jx jy mk ka kb kc ml ke kf kg mm ki kj kk ij bi translated">AutoInt[14]最初是为点击率(CTR)预测而提出的，基于自我注意机制，可以学习高阶特征交互及其相关性[14]。它使用多层具有剩余连接的多头自关注神经网络来模拟低维空间中的特征交互，在该低维空间中分类和数字特征都被映射[14]。AutoInt模型的架构如图9所示。</p><figure class="kv kw kx ky gt kz gh gi paragraph-image"><div class="gh gi ny"><img src="../Images/86f4d4767305536fa0d918dceea51702.png" data-original-src="https://miro.medium.com/v2/resize:fit:1036/format:webp/1*io7dSzfdOCGRNOTSU3wAhg.jpeg"/></div><figcaption class="lg lh gj gh gi li lj bd b be z dk translated">图AutoInt的架构[14]。</figcaption></figure><h2 id="4829" class="mn ll iq bd lm mo mp dn lq mq mr dp lu jy ms mt ly kc mu mv mc kg mw mx mg my bi translated">傅立叶变换变压器</h2><p id="87ef" class="pw-post-body-paragraph jn jo iq jp b jq mi js jt ju mj jw jx jy mk ka kb kc ml ke kf kg mm ki kj kk ij bi translated">FT-Transformer[4](Feature Tokenizer+Transformer)类似于AutoInt，但有一些关键的区别，这是其相对优越的性能的原因。它与AutoInt一样，将所有特性转换成嵌入，作为transformer层的输入[4]。此外，FT-Transformer的嵌入层也使用特征偏差，并且在Transformer的前范式变体中使用[CLS]令牌的最终表示用于推理机制[4]。然而，与其他深度学习方法相比，由于引入的开销，它被发现是缓慢的和计算昂贵的，这在较大的数据集中更明显可见[4]。FT-Transformer模型的架构如图10所示。</p><figure class="kv kw kx ky gt kz gh gi paragraph-image"><div role="button" tabindex="0" class="la lb di lc bf ld"><div class="gh gi nz"><img src="../Images/3cae360394bad7dd6bd511517d2c9b8b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*ptKMhEwXa4YemDOavS8t5Q.jpeg"/></div></div><figcaption class="lg lh gj gh gi li lj bd b be z dk translated">图10: (a)特征记号赋予器；在这个例子中，有三个数字特征和两个分类特征；一个变压器层[4]。</figcaption></figure><h2 id="6e04" class="mn ll iq bd lm mo mp dn lq mq mr dp lu jy ms mt ly kc mu mv mc kg mw mx mg my bi translated">规范和修改</h2><p id="f048" class="pw-post-body-paragraph jn jo iq jp b jq mi js jt ju mj jw jx jy mk ka kb kc ml ke kf kg mm ki kj kk ij bi translated">一些从业者还提出了对现有神经网络的正则化技术，以提高它们的性能。他们认为，基本架构，如多层感知器，可以调整到与梯度提升算法相当的性能，甚至在某些情况下超过它们。</p><h2 id="8575" class="mn ll iq bd lm mo mp dn lq mq mr dp lu jy ms mt ly kc mu mv mc kg mw mx mg my bi translated">正规化学习网络(RLN)</h2><p id="9927" class="pw-post-body-paragraph jn jo iq jp b jq mi js jt ju mj jw jx jy mk ka kb kc ml ke kf kg mm ki kj kk ij bi translated">在一项早期研究中，Ira Shavitt和Eran Segal引入了使用反事实损失进行微调的正则化学习网络[13]。由此产生的稀疏网络是可解释的，揭示了基本特征[13]。然而，该论文仅涉及数字特征，使得它们不太适合于一般用途。</p><h2 id="0428" class="mn ll iq bd lm mo mp dn lq mq mr dp lu jy ms mt ly kc mu mv mc kg mw mx mg my bi translated">规范化鸡尾酒</h2><p id="71f9" class="pw-post-body-paragraph jn jo iq jp b jq mi js jt ju mj jw jx jy mk ka kb kc ml ke kf kg mm ki kj kk ij bi translated">Kadra等人提出了“正则化鸡尾酒”，这是一种用于选择正则化技术子集及其附属超参数的优化范式[7]。该方法似乎是有效的，但是使用大量资源来寻找最佳参数和超参数。</p><h2 id="d5a8" class="mn ll iq bd lm mo mp dn lq mq mr dp lu jy ms mt ly kc mu mv mc kg mw mx mg my bi translated">MLP+</h2><p id="d781" class="pw-post-body-paragraph jn jo iq jp b jq mi js jt ju mj jw jx jy mk ka kb kc ml ke kf kg mm ki kj kk ij bi translated">James Fiedler也认为现有的网络没有得到充分利用，一些修改可以使简单的架构如多层感知器与其他模型和梯度提升树相竞争[3]。他创造了“MLP+区块”，即漏门、MLP子区块、跳过层和加权平均的组合[3]。漏门结合了基于元素的线性变换和LeakyReLU，有助于解释和特征选择[3]。受TabNet启发的Ghost batch norm (GBN)被用来代替批处理规范化，以提高泛化能力和训练速度[3]。原始MLP模块和被称为MLP+的修改后的MLP模块的架构如图11所示，修改以灰色背景标记。</p><figure class="kv kw kx ky gt kz gh gi paragraph-image"><div role="button" tabindex="0" class="la lb di lc bf ld"><div class="gh gi oa"><img src="../Images/b6e22b84941c69f00b04d29193d8f390.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*_NFqmFKi_2ZNfOEkEC4OeA.jpeg"/></div></div><figcaption class="lg lh gj gh gi li lj bd b be z dk translated">图11:MLP模型的原始版本和修改版本。修改被赋予灰色背景[3]</figcaption></figure><h2 id="0482" class="mn ll iq bd lm mo mp dn lq mq mr dp lu jy ms mt ly kc mu mv mc kg mw mx mg my bi translated">结论</h2><p id="33b1" class="pw-post-body-paragraph jn jo iq jp b jq mi js jt ju mj jw jx jy mk ka kb kc ml ke kf kg mm ki kj kk ij bi translated">该调查解释了表格数据，其受欢迎程度及其在行业中的广泛使用。它承认基于树的模型优于基于深度学习的表格数据解决方案，并解释了基于深度学习的解决方案必须提供的优势。最显著的好处是它们在端到端学习中与不同形式的数据一起使用，并减少了对特征工程的需求。我们讨论了利用CNN的模型，并通过将表格数据转换为图像从迁移学习中受益，然后讨论了混合模型，该模型将基于树的模型和神经网络相结合，以创建可区分的架构。基于注意力的体系结构在同质数据(文本和图像)上的成功，提出了一些用于异质表格数据的基于注意力的模型。我们还考虑了一些可以提高现有模型性能的正则化技术。表格数据现在开始得到应有的重视。尽管如此，缺乏既定的基准已经导致在各种数据集上评估不同的模型，从而导致不准确的比较。我们也看到一些模型在新数据集上表现不佳。由于没有基于深度学习的模型始终优于包括梯度推进模型在内的其他模型，基于树的模型仍然是一种有效的基线模型，具有在现实世界用例中必不可少的高解释性。现在还没有一个确定的模型。</p><h2 id="86d9" class="mn ll iq bd lm mo mp dn lq mq mr dp lu jy ms mt ly kc mu mv mc kg mw mx mg my bi translated">参考</h2><p id="dcd5" class="pw-post-body-paragraph jn jo iq jp b jq mi js jt ju mj jw jx jy mk ka kb kc ml ke kf kg mm ki kj kk ij bi translated">[1]塞尔詹·奥·阿里克和托马斯·菲斯特。TabNet:专注的可解释表格学习，2020。</p><p id="960d" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">[2]Cheng-Tze Cheng，Levent Koc，Jeremiah Harmsen，Tal Shaked，Tushar Chandra，Hrishi Aradhye，Glen Anderson，Greg Corrado，，Mustafa Ispir，Rohan Anil，Zakaria Haque，Hong，Jain，和Hemal Shah。推荐系统的宽深度学习，2016。</p><p id="2ee6" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">[3]詹姆斯·费德勒。改进表格神经网络的简单修改，2021。</p><p id="8a84" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">[4] Yury Gorishniy、Ivan Rubachev、Valentin Khrulkov和Artem Babenko。表格数据的深度学习模型再探，2021年。</p><p id="7910" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">[5]郭惠峰，唐瑞明，叶云明，，何秀强.Deepfm:基于因子分解机器的神经网络，用于ctr预测，2017。</p><p id="c6ae" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">[6]黄鑫、阿希什·赫坦、米兰·茨维特科维奇和佐哈尔·卡尔宁。Tabtransformer:使用上下文嵌入的表格数据建模，2020。</p><p id="b8d5" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">[7] Arlind Kadra、Marius Lindauer、Frank Hutter和Josif Grabocka。调整良好的简单网络在表格数据集上表现出色，2021。</p><p id="92db" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">[8]柯，徐，，，和。Deepgbm:由gbdt提炼的用于在线预测任务的深度学习框架。在2019年8月举行的第25届ACM SIGKDD知识发现数据挖掘国际会议上。</p><p id="85c4" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">[9]戴维·莱恩。2003年统计学导论。</p><p id="ce7b" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">[10]刘兆成、刘强、张和陈。Dnn2lr:现实世界表格数据的解释启发特征交叉，2021。</p><p id="4da2" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">[11]塞尔戈·波波夫、斯坦尼斯拉夫·莫罗佐夫和阿尔滕·巴本科。用于表格数据深度学习的神经遗忘决策集成，2019。</p><p id="e146" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">[12] Alok Sharma、Edwin Vans、Daichi Shigemizu、Keith Boroevich和Tatsuhiko Tsunoda。DeepInsight:一种将非图像数据转换为图像以用于卷积神经网络架构的方法。科学报告，2019年9月8日。</p><p id="49c9" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">13 Ira sha vitt和Eran Segal。正则化学习网络:表格数据集的深度学习，2018。</p><p id="5952" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">[14]，陈策士，肖志平，段志坚，，徐，，等.自动点火。2019年11月第28届ACM信息与知识管理国际会议论文集。</p><p id="973f" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">[15]孙宝华、、帕特里克·董、·张、贾森·董和查尔斯·杨。超级人物:从情感分类到图像分类的转换，2018。</p><p id="3812" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">[16]、、、张、、董、杨和董。SuperTML:结构化表格数据预测的二维单词嵌入，2019。</p><p id="8981" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">[17]朱、Thomas Brettin、夏方方、Alexander Partin、Maulik Shukla、Hyunseung Yoo、Yvonne Evrard、James Doroshow和Rick Stevens。用卷积神经网络将表格数据转换为深度学习的图像。科学报告，2021年5月11日。</p></div></div>    
</body>
</html>