<html>
<head>
<title>DeepMind’s New Algorithm is Able to Master Perfect and Imperfect Information Games</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">DeepMind的新算法能够掌握完美和不完美的信息游戏</h1>
<blockquote>原文：<a href="https://pub.towardsai.net/deepminds-new-algorithm-is-able-to-master-perfect-and-imperfect-information-games-1872396ad9b2?source=collection_archive---------1-----------------------#2021-12-20">https://pub.towardsai.net/deepminds-new-algorithm-is-able-to-master-perfect-and-imperfect-information-games-1872396ad9b2?source=collection_archive---------1-----------------------#2021-12-20</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><h2 id="513d" class="ir is it bd b dl iu iv iw ix iy iz dk ja translated" aria-label="kicker paragraph"><a class="ae ep" href="https://towardsai.net/p/category/machine-learning/deep-learning" rel="noopener ugc nofollow" target="_blank">深度学习</a></h2><div class=""/><div class=""><h2 id="d14e" class="pw-subtitle-paragraph jz jc it bd b ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq dk translated">《游戏玩家》结合了几种深度学习技术，在完美和不完美的信息游戏中都实现了超人的表现。</h2></div><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi kr"><img src="../Images/c968c4a7beb5d96f25d101d03e7722ab.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*hUm6WQsxiCvYtPSMqXNmKg.png"/></div></div><figcaption class="ld le gj gh gi lf lg bd b be z dk translated">来源:<a class="ae lh" href="https://dataphoenix.info/deepmind-claims-that-player-of-games-is-the-first-ai-system-that-can-play-poker-chess-go-etc/" rel="noopener ugc nofollow" target="_blank">https://data phoenix . info/deep mind-claims-the-player-of-games-is-the-first-ai-system-can-play-poker-chess-go-etc/</a></figcaption></figure><p id="0055" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">游戏一直是过去几年深度学习复兴的中心领域之一。考虑到为了模仿真实世界的场景，游戏是相对容易复制的环境，这并不特别令人惊讶。尽管游戏的ML有所进步，但它一直专注于完美或不完美的信息游戏，但从未同时专注于两者。精通国际象棋和围棋的模型与扑克等不完美的游戏作斗争。甚至像AlphaZero这样学会同时玩多种游戏的模型也受到完美信息环境的限制。这样做的原因显然是基于两种类型的游戏环境的内在动力。像国际象棋和扑克这样的完美信息游戏非常适合像自我游戏学习和问题空间树搜索这样的ML技术，而像扑克这样的不完美信息游戏依赖于游戏推理技术。几周前，DeepMind提出了一种能够掌握完美和不完美信息游戏的神经网络，挑战了这种传统方法。</p><p id="b826" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">游戏玩家(PoG)是一种算法，它结合了几种技术，以便在完美和不完美的信息环境中实现最先进的性能。毫不奇怪，PoG利用了在完美信息环境下工作良好的自我游戏学习和搜索等技术，以及在不完美信息环境下工作良好的博弈论推理。本质上，PoG能够将一个游戏分解成小的子游戏，这些子游戏能够以保持较大游戏的纳什均衡的方式来解决。</p><h1 id="9354" class="me mf it bd mg mh mi mj mk ml mm mn mo ki mp kj mq kl mr km ms ko mt kp mu mv bi translated">该算法</h1><p id="8241" class="pw-post-body-paragraph li lj it lk b ll mw kd ln lo mx kg lq lr my lt lu lv mz lx ly lz na mb mc md im bi translated">PoG的核心组件是一种算法，它能够迭代计算最佳游戏策略，而不需要大量计算资源。该算法本身是基于反事实后悔最小化(CFR)，这是一种在不完美信息环境中流行的技术。在高层次上，CFR关注于以最小化长期平均遗憾的方式定期计算每个玩家的策略。</p><p id="836b" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">PoG扩展了CFR的传统思想，以适应完美和不完美的信息环境。PoG的算法基于几个基本组件:</p><h2 id="0564" class="nb mf it bd mg nc nd dn mk ne nf dp mo lr ng nh mq lv ni nj ms lz nk nl mu iz bi translated">CVPN</h2><p id="e8e6" class="pw-post-body-paragraph li lj it lk b ll mw kd ln lo mx kg lq lr my lt lu lv mz lx ly lz na mb mc md im bi translated">反事实价值和政策网络(CVPN)是一种神经网络，它计算游戏中每个国家信念的反事实。这是在任何给定时间评估游戏不同版本的关键。</p><h2 id="96d3" class="nb mf it bd mg nc nd dn mk ne nf dp mo lr ng nh mq lv ni nj ms lz nk nl mu iz bi translated">GT-CFT</h2><p id="defc" class="pw-post-body-paragraph li lj it lk b ll mw kd ln lo mx kg lq lr my lt lu lv mz lx ly lz na mb mc md im bi translated">成长树CFR(GT-CFR)是CFR的一个变种，它是为游戏树而优化的，游戏树随着时间的推移而成长。GT-CFR基于两个基本阶段:</p><p id="4d48" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated"><strong class="lk jd">一、后悔更新阶段:</strong>该阶段针对博弈树的不同部分运行多个CFR算法。在任何给定的时间，该阶段使用CVPN网络来计算信念反事实，并将它们传递到扩展阶段。</p><p id="823e" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated"><strong class="lk jd">二世。扩展阶段:</strong>这个阶段从游戏树的根到叶子运行模拟，给游戏树添加新的状态。</p><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi nm"><img src="../Images/c5a60bfff1eb6c121ec52b3d3af67a31.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*lH2FVcv5zdDgm77vISu6Ig.png"/></div></div><figcaption class="ld le gj gh gi lf lg bd b be z dk translated">图片来源:DeepMind</figcaption></figure><h2 id="3c9c" class="nb mf it bd mg nc nd dn mk ne nf dp mo lr ng nh mq lv ni nj ms lz nk nl mu iz bi translated">数据生成</h2><p id="9f37" class="pw-post-body-paragraph li lj it lk b ll mw kd ln lo mx kg lq lr my lt lu lv mz lx ly lz na mb mc md im bi translated">PoG使用一种基于称为声音自播放的自播放的数据生成算法。该算法在每个决策点运行GT-CFR搜索，并产生潜在的动作和历史。该数据用于训练CVPN网络。</p><h2 id="dd6f" class="nb mf it bd mg nc nd dn mk ne nf dp mo lr ng nh mq lv ni nj ms lz nk nl mu iz bi translated">培训过程</h2><p id="e6d5" class="pw-post-body-paragraph li lj it lk b ll mw kd ln lo mx kg lq lr my lt lu lv mz lx ly lz na mb mc md im bi translated">PoG的一个关键组成部分是一个用于更新CVPN的巧妙培训流程。这个过程由许多使用声音自播放算法生成数据的并发参与者执行。数据由在分布式网络中运行的训练者收集，并定期重新训练CVPN。</p><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi nn"><img src="../Images/343e923aea47c0004d1ca4b759ec636b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*yf8k_vVtwUW1Qoo8f-uPPQ.png"/></div></div><figcaption class="ld le gj gh gi lf lg bd b be z dk translated">图片来源:DeepMind</figcaption></figure><h1 id="883b" class="me mf it bd mg mh mi mj mk ml mm mn mo ki mp kj mq kl mr km ms ko mt kp mu mv bi translated">结果呢</h1><p id="ec57" class="pw-post-body-paragraph li lj it lk b ll mw kd ln lo mx kg lq lr my lt lu lv mz lx ly lz na mb mc md im bi translated">DeepMind在完美和不完美的信息游戏中针对不同的基准对PoG进行了评估。该模型在国际象棋或围棋等完美游戏以及扑克或苏格兰场等不完美游戏中实现了超人的表现。除了在游戏中的应用，PoG还在构建ML模型方面迈出了一大步，这些模型可以适应现实世界的领域，如天气预报或结合完美和不完美信息的能源优化。我们应该期待PoG成为ML游戏研究下一波浪潮中的开创性算法。</p></div></div>    
</body>
</html>