<html>
<head>
<title>3 Practical Monitoring for tabular data practices ML-OPS Guide Series</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">3表格数据实践的实际监控ML-OPS指南系列</h1>
<blockquote>原文：<a href="https://pub.towardsai.net/practical-monitoring-for-tabular-data-practices-ml-ops-guide-series-3-86d33f3b8aef?source=collection_archive---------3-----------------------#2021-11-23">https://pub.towardsai.net/practical-monitoring-for-tabular-data-practices-ml-ops-guide-series-3-86d33f3b8aef?source=collection_archive---------3-----------------------#2021-11-23</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><h2 id="2ce2" class="io ip iq bd b dl ir is it iu iv iw dk ix translated" aria-label="kicker paragraph"><a class="ae ep" href="https://towardsai.net/ai/mlops" rel="noopener ugc nofollow" target="_blank"> MLOps </a></h2><div class=""/><p id="a33d" class="pw-post-body-paragraph jx jy iq jz b ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku ij bi translated"><em class="kv">概念漂移、数据漂移&amp;监控</em></p><p id="fc49" class="pw-post-body-paragraph jx jy iq jz b ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku ij bi translated"><em class="kv">在之前作为ML-Ops指南系列的一部分的博客中，我们讨论了什么是概念漂移、数据漂移&amp;监控作为ML生命周期一部分的重要性。现在，我们将了解如何从表格数据集的训练和测试数据中消除漂移。</em></p><figure class="kx ky kz la gt lb gh gi paragraph-image"><div role="button" tabindex="0" class="lc ld di le bf lf"><div class="gh gi kw"><img src="../Images/b86a66865e429e7700f84fe2e36df657.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*1rL7RkZ7_jEQOlXAbufamA.png"/></div></div><figcaption class="li lj gj gh gi lk ll bd b be z dk translated"><em class="jw">鸣谢:谷歌云</em></figcaption></figure><p id="1d6f" class="pw-post-body-paragraph jx jy iq jz b ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku ij bi translated"><em class="kv">大多数情况下，为了检测数据集比较中的漂移，需要一个参考分布，其中包含我们与生产数据分布进行比较的固定数据分布。例如，这可能是第一个月的训练数据或整个训练数据集。这取决于你试图检测漂移的背景和时间范围。但是显然，参考分布应该包含足够的样本来表示训练数据集。</em></p><p id="3007" class="pw-post-body-paragraph jx jy iq jz b ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku ij bi translated"><em class="kv">例如:为了简单起见，假设我们有一个包含20个特征的分类/回归模型。假设特性A和特性B是模型中贡献最大的特性。在这篇文章中，让我们来看看我们如何去尝试看看功能是否有数据漂移发生。</em></p><p id="6433" class="pw-post-body-paragraph jx jy iq jz b ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku ij bi translated"><em class="kv">为此，将对数据集计算一些不同的统计(正态性检验)技术，并讨论下一步的工作，</em></p><pre class="kx ky kz la gt lm ln lo lp aw lq bi"><span id="094c" class="lr ls iq ln b gy lt lu l lv lw">import pandas as pd<br/>import numpy as np<br/>df=pd.read_csv('../input/yahoo-data/MSFT.csv')<br/>df=df[['Date','Close']]</span></pre><p id="ffb3" class="pw-post-body-paragraph jx jy iq jz b ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku ij bi translated"><em class="kv">这里的文件包含了53周以来微软股票价格的数据。现在，我们想处理股票的回报，而不是价格本身，所以我们需要做一些数据处理</em></p><pre class="kx ky kz la gt lm ln lo lp aw lq bi"><span id="b559" class="lr ls iq ln b gy lt lu l lv lw">df['diff'] = pd.Series(np.diff(df['Close']))<br/>df['return'] = df['diff']/df['Close']<br/>df = df[['Date', 'return']].dropna()<br/>print(df.head(3))</span></pre></div><div class="ab cl lx ly hu lz" role="separator"><span class="ma bw bk mb mc md"/><span class="ma bw bk mb mc md"/><span class="ma bw bk mb mc"/></div><div class="ij ik il im in"><pre class="lm ln lo lp aw lq bi"><span id="c6dd" class="lr ls iq ln b gy me mf mg mh mi lu l lv lw">Date    return<br/>0  2018-01-01  0.015988<br/>1  2018-01-08  0.004464<br/>2  2018-01-15  0.045111</span></pre><p id="90be" class="pw-post-body-paragraph jx jy iq jz b ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku ij bi translated"><em class="kv">为了让数据更容易理解，特别是为什么我们将价格转换为回报，然后我们想使用Python测试其正态性，让我们使用直方图来可视化数据</em></p><pre class="kx ky kz la gt lm ln lo lp aw lq bi"><span id="1f69" class="lr ls iq ln b gy lt lu l lv lw">from matplotlib import pyplot as plt<br/><br/>plt.hist(df['return'])<br/>plt.show()</span></pre><figure class="kx ky kz la gt lb gh gi paragraph-image"><div role="button" tabindex="0" class="lc ld di le bf lf"><div class="gh gi mj"><img src="../Images/ad3800ac9a3f5a437a4bb110c703769a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*LEOzpfjFk_SofTO8j85ETw.jpeg"/></div></div></figure><p id="bf49" class="pw-post-body-paragraph jx jy iq jz b ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku ij bi translated"><em class="kv">如果你看到数据的分布在视觉上看起来有点像正态分布。但真的是这样吗？这就是我们要用不同的统计方法来回答的问题，</em></p><h1 id="de30" class="mk ls iq bd ml mm mn mo mp mq mr ms mt mu mv mw mx my mz na nb nc nd ne nf ng bi translated"><em class="jw"> Q-Q剧情测试</em></h1><p id="a210" class="pw-post-body-paragraph jx jy iq jz b ka nh kc kd ke ni kg kh ki nj kk kl km nk ko kp kq nl ks kt ku ij bi translated">我们将从一种更直观、更少数学的方法开始，分位数-分位数图。</p><p id="050d" class="pw-post-body-paragraph jx jy iq jz b ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku ij bi translated">什么是分位数-分位数图？该图显示了给定数据相对于正态分布的分布，即现有分位数相对于正态理论分位数。</p><p id="3212" class="pw-post-body-paragraph jx jy iq jz b ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku ij bi translated">让我们使用Python为我们的数据创建Q-Q图，然后解释结果。</p><pre class="kx ky kz la gt lm ln lo lp aw lq bi"><span id="a18a" class="lr ls iq ln b gy lt lu l lv lw">import pylab<br/>import scipy.stats as stats</span><span id="f6d2" class="lr ls iq ln b gy nm lu l lv lw">stats.probplot(df['return'], dist="norm", plot=pylab)<br/>pylab.show()</span></pre><figure class="kx ky kz la gt lb gh gi paragraph-image"><div role="button" tabindex="0" class="lc ld di le bf lf"><div class="gh gi nn"><img src="../Images/d8ca0c4d3ae48861e4114779344476fd.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*2-7SJ0lZLW8xK3hTku6R9w.jpeg"/></div></div></figure><p id="ba2c" class="pw-post-body-paragraph jx jy iq jz b ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku ij bi translated">看上面的图表，我们看到一个向上倾斜的线性关系。对于正态分布，观察值应该都出现在45度直线上。我们在上面看到这样的关系了吗？我们做了一部分。所以这可以告诉我们的是，我们正在研究的分布并不完全是正态分布，而是接近正态分布。</p><h1 id="0fc5" class="mk ls iq bd ml mm mn mo mp mq mr ms mt mu mv mw mx my mz na nb nc nd ne nf ng bi translated"><em class="jw">Jarque–Bera测试</em></h1><p id="56a4" class="pw-post-body-paragraph jx jy iq jz b ka nh kc kd ke ni kg kh ki nj kk kl km nk ko kp kq nl ks kt ku ij bi translated"><em class="kv"> Jarque-Bera是正态性检验的一种，具体来说是将偏度和峰度与正态分布的偏度和峰度相匹配的拟合优度检验。</em></p><p id="f4e6" class="pw-post-body-paragraph jx jy iq jz b ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku ij bi translated"><em class="kv">其统计量为非负，大值表示显著偏离正态分布。</em></p><p id="bf84" class="pw-post-body-paragraph jx jy iq jz b ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku ij bi translated"><em class="kv">Jarque-Bera的检验统计量JB定义如下:</em></p><figure class="kx ky kz la gt lb gh gi paragraph-image"><div class="gh gi no"><img src="../Images/40ba358e052a186a75b171e3c954a88e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1136/format:webp/1*NgziKaupUKSaCvvPg29Z6A.jpeg"/></div></figure><p id="ee8c" class="pw-post-body-paragraph jx jy iq jz b ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku ij bi translated"><em class="kv">其中𝑆为样本</em> <a class="ae np" href="https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.skew.html" rel="noopener ugc nofollow" target="_blank"> <em class="kv">偏度</em> </a> <em class="kv">，𝐾为样本</em> <a class="ae np" href="https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.kurtosis.html" rel="noopener ugc nofollow" target="_blank"> <em class="kv">峰度</em> </a> <em class="kv">，𝑛为样本大小。</em></p><p id="dceb" class="pw-post-body-paragraph jx jy iq jz b ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku ij bi translated"><em class="kv">假设:</em></p><p id="d76c" class="pw-post-body-paragraph jx jy iq jz b ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku ij bi translated"><em class="kv"> 𝐻0:sample 𝑆和样本𝐾没有显著不同于正态分布</em></p><p id="29ad" class="pw-post-body-paragraph jx jy iq jz b ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku ij bi translated"><em class="kv"> 𝐻1:sample 𝑆和样本𝐾显著不同于正态分布</em></p><p id="4bd5" class="pw-post-body-paragraph jx jy iq jz b ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku ij bi translated"><em class="kv">现在我们可以计算Jarque-Bera检验统计量，并找到相应的𝑝-value: </em></p><pre class="kx ky kz la gt lm ln lo lp aw lq bi"><span id="890d" class="lr ls iq ln b gy lt lu l lv lw">from scipy.stats import jarque_bera</span><span id="d454" class="lr ls iq ln b gy nm lu l lv lw">result = (jarque_bera(df['return']))</span><span id="9dde" class="lr ls iq ln b gy nm lu l lv lw">print(f"JB statistic: {result[0]}")<br/>print(f"p-value: {result[1]}")</span><span id="27bd" class="lr ls iq ln b gy nm lu l lv lw">JB statistic: 1.9374105196180924<br/>p-value: 0.37957417002404925</span></pre><p id="a713" class="pw-post-body-paragraph jx jy iq jz b ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku ij bi translated">查看这些结果，我们未能拒绝零假设，并得出样本数据遵循正态分布的结论。</p><p id="41d1" class="pw-post-body-paragraph jx jy iq jz b ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku ij bi translated"><em class="kv">注:Jarque-Bera检验在大样本(通常大于2000个观察值)中工作正常，其统计量具有2个自由度的卡方分布)</em></p><h1 id="f04d" class="mk ls iq bd ml mm mn mo mp mq mr ms mt mu mv mw mx my mz na nb nc nd ne nf ng bi translated"><em class="jw">科尔莫戈罗夫-斯米尔诺夫试验</em></h1><p id="6567" class="pw-post-body-paragraph jx jy iq jz b ka nh kc kd ke ni kg kh ki nj kk kl km nk ko kp kq nl ks kt ku ij bi translated">Kolmogorov-Smirnov检验(或K-S检验)是最常见的正态性检验之一。与其他检验相比，Kolmogorov-Smirnov检验的一个主要优点是非参数的，这意味着它是无分布的。</p><p id="f0cb" class="pw-post-body-paragraph jx jy iq jz b ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku ij bi translated">这里我们关注单样本Kolmogorov-Smirnov测试，因为我们希望将一维概率分布与理论上指定的分布(在我们的例子中是正态分布)进行比较。</p><p id="ab12" class="pw-post-body-paragraph jx jy iq jz b ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku ij bi translated"><em class="kv">Kolmogorov-Smirnov检验统计量测量样本的经验分布函数(ECDF)和参考分布的累积分布函数之间的距离。</em></p><p id="ad77" class="pw-post-body-paragraph jx jy iq jz b ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku ij bi translated"><em class="kv">在我们的例子中，经验分布函数将来自我们之前收集的回报数据。因为我们将它与正态分布进行比较，所以我们将使用正态分布的累积分布函数。</em></p><p id="4843" class="pw-post-body-paragraph jx jy iq jz b ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku ij bi translated">到目前为止，这听起来很专业，所以让我们试着把它分解并形象化，以便更好地理解。</p><p id="1c8c" class="pw-post-body-paragraph jx jy iq jz b ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku ij bi translated"><em class="kv">第一步:</em></p><p id="2d03" class="pw-post-body-paragraph jx jy iq jz b ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku ij bi translated"><em class="kv">让我们用收益数据的平均值和标准偏差创建一个正态分布值数组:</em></p><pre class="kx ky kz la gt lm ln lo lp aw lq bi"><span id="3f10" class="lr ls iq ln b gy lt lu l lv lw">data_norm = np.random.normal(np.mean(df['return']), np.std(df['return']), len(df))</span></pre><p id="300d" class="pw-post-body-paragraph jx jy iq jz b ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku ij bi translated"><em class="kv">使用</em><a class="ae np" href="https://numpy.org/doc/stable/reference/random/generated/numpy.random.normal.html" rel="noopener ugc nofollow" target="_blank"><em class="kv">NP . random . normal()</em></a><em class="kv">我们创建了data_norm，它是一个数组，具有与df['return']相同数量的观察值，还具有相同的均值和标准差。</em></p><p id="b49b" class="pw-post-body-paragraph jx jy iq jz b ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku ij bi translated"><em class="kv">这里的直觉是，如果我们假设分布的一些参数(平均值和标准偏差)，那么具有这些参数的数字将形成正态分布。</em></p><p id="d370" class="pw-post-body-paragraph jx jy iq jz b ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku ij bi translated"><em class="kv">第二步:</em></p><p id="5e73" class="pw-post-body-paragraph jx jy iq jz b ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku ij bi translated"><em class="kv">接下来，我们要做的是在两个数据集上使用</em><a class="ae np" href="https://numpy.org/doc/stable/reference/generated/numpy.histogram.html" rel="noopener ugc nofollow" target="_blank"><em class="kv">NP . histogram()</em></a><em class="kv">对它们进行排序，并将它们分配到箱:</em></p><pre class="kx ky kz la gt lm ln lo lp aw lq bi"><span id="a145" class="lr ls iq ln b gy lt lu l lv lw">values, base = np.histogram(df['return'])<br/>values_norm, base_norm = np.histogram(data_norm)</span></pre><p id="4589" class="pw-post-body-paragraph jx jy iq jz b ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku ij bi translated"><em class="kv">注意:默认情况下，该函数将使用bins = 10，您可以根据正在处理的数据进行调整。</em></p></div><div class="ab cl lx ly hu lz" role="separator"><span class="ma bw bk mb mc md"/><span class="ma bw bk mb mc md"/><span class="ma bw bk mb mc"/></div><div class="ij ik il im in"><p id="d021" class="pw-post-body-paragraph jx jy iq jz b ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku ij bi translated"><em class="kv">第三步:</em></p><p id="0fad" class="pw-post-body-paragraph jx jy iq jz b ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku ij bi translated"><em class="kv">使用</em><a class="ae np" href="https://numpy.org/doc/stable/reference/generated/numpy.cumsum.html" rel="noopener ugc nofollow" target="_blank"><em class="kv">NP . cumsum()</em></a><em class="kv">计算上面创建的数组的累计和:</em></p><pre class="kx ky kz la gt lm ln lo lp aw lq bi"><span id="7086" class="lr ls iq ln b gy lt lu l lv lw">cumulative = np.cumsum(values)<br/>cumulative_norm = np.cumsum(values_norm)</span></pre><p id="2a6b" class="pw-post-body-paragraph jx jy iq jz b ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku ij bi translated"><em class="kv">第四步:</em></p><p id="0d0a" class="pw-post-body-paragraph jx jy iq jz b ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku ij bi translated"><em class="kv">绘制累积分布函数:</em></p><pre class="kx ky kz la gt lm ln lo lp aw lq bi"><span id="9988" class="lr ls iq ln b gy lt lu l lv lw">plt.plot(base[:-1], cumulative, c='blue')<br/>plt.plot(base_norm[:-1], cumulative_norm, c='green')<br/>plt.show()</span></pre><figure class="kx ky kz la gt lb gh gi paragraph-image"><div role="button" tabindex="0" class="lc ld di le bf lf"><div class="gh gi nq"><img src="../Images/062c7861b4e34efedcc776b896db3b50.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Tv-AWHW8HVoy4WOk7wwn1Q.jpeg"/></div></div></figure><p id="d610" class="pw-post-body-paragraph jx jy iq jz b ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku ij bi translated"><em class="kv">其中蓝线是df['return']的ECDF(经验累积分布函数)，绿线是正态分布的CDF。</em></p><p id="ea9a" class="pw-post-body-paragraph jx jy iq jz b ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku ij bi translated"><em class="kv">第四步替代:</em></p><p id="b8be" class="pw-post-body-paragraph jx jy iq jz b ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku ij bi translated"><em class="kv">您可以使用seaborn更快地创建图形，并且只需要步骤1中的df['return']和data _ norm:</em></p><pre class="kx ky kz la gt lm ln lo lp aw lq bi"><span id="475a" class="lr ls iq ln b gy lt lu l lv lw">import seaborn as sns<br/>sns.ecdfplot(df['return'], c='blue')<br/>sns.ecdfplot(data_norm, c='green')</span></pre><figure class="kx ky kz la gt lb gh gi paragraph-image"><div role="button" tabindex="0" class="lc ld di le bf lf"><div class="gh gi nr"><img src="../Images/33d9cc67dc5c25ba86b64906f69c1678.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*tn7VWA-8Z3TatAzoMpCprQ.jpeg"/></div></div></figure><p id="3291" class="pw-post-body-paragraph jx jy iq jz b ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku ij bi translated"><em class="kv">现在，在可视化这两个累积分布函数之后，让我们回到Kolmogorov-Smirnov测试。Kolmogorov-Smirnov检验是基于这两条曲线(蓝绿色)之间的最大距离，假设如下:</em></p><p id="093e" class="pw-post-body-paragraph jx jy iq jz b ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku ij bi translated"><em class="kv"> 𝐻0:的两个样本来自同一个分布</em></p><p id="7d24" class="pw-post-body-paragraph jx jy iq jz b ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku ij bi translated"><em class="kv"> 𝐻1:的两个样本来自不同的分布</em></p><p id="30d7" class="pw-post-body-paragraph jx jy iq jz b ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku ij bi translated"><em class="kv">我们定义ECDF为:</em></p><figure class="kx ky kz la gt lb gh gi paragraph-image"><div class="gh gi ns"><img src="../Images/403cfb95932a084e44f0ef23a3392266.png" data-original-src="https://miro.medium.com/v2/resize:fit:1328/format:webp/1*qobJ1QpCQzJ-3ZX_5rwakw.jpeg"/></div></figure><p id="d864" class="pw-post-body-paragraph jx jy iq jz b ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku ij bi translated"><em class="kv">即统计样本观测值低于𝑥.水平的比例</em></p><p id="d4fa" class="pw-post-body-paragraph jx jy iq jz b ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku ij bi translated">我们定义一个给定的(理论上的)CDF为:𝐹(𝑥).在正态性检验的情况下，𝐹(𝑥)是正态分布的CDF。</p><p id="8351" class="pw-post-body-paragraph jx jy iq jz b ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku ij bi translated"><em class="kv">Kolmogorov-Smirnov统计量被定义为:</em></p><figure class="kx ky kz la gt lb gh gi paragraph-image"><div class="gh gi nt"><img src="../Images/3ed84130f175d211a7c5dd3c533f1fea.png" data-original-src="https://miro.medium.com/v2/resize:fit:1024/format:webp/1*hnqbQJ9Y6aLbMm12z1Tj9A.jpeg"/></div></figure><p id="d721" class="pw-post-body-paragraph jx jy iq jz b ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku ij bi translated"><em class="kv">直观上，该统计测量所有𝑥值的两个分布函数之间的最大绝对距离。</em></p><p id="4646" class="pw-post-body-paragraph jx jy iq jz b ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku ij bi translated">使用上面的图表，这是我估计的上确界:</p><figure class="kx ky kz la gt lb gh gi paragraph-image"><div role="button" tabindex="0" class="lc ld di le bf lf"><div class="gh gi nr"><img src="../Images/33d9cc67dc5c25ba86b64906f69c1678.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*tn7VWA-8Z3TatAzoMpCprQ.jpeg"/></div></div></figure><p id="8e57" class="pw-post-body-paragraph jx jy iq jz b ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku ij bi translated">这里蓝线表示上确界。计算𝐷𝑛的值，并将其与𝐷0.05的临界值(假设5%)进行比较，我们可以拒绝或无法拒绝零假设。</p><p id="53b8" class="pw-post-body-paragraph jx jy iq jz b ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku ij bi translated"><em class="kv">回到我们的例子，让我们对微软股票收益数据进行K-S检验:</em></p><pre class="kx ky kz la gt lm ln lo lp aw lq bi"><span id="7e86" class="lr ls iq ln b gy lt lu l lv lw">from scipy.stats import kstest</span><span id="5261" class="lr ls iq ln b gy nm lu l lv lw">result = (kstest(df['return'], cdf='norm'))</span><span id="46b8" class="lr ls iq ln b gy nm lu l lv lw">print(f"K-S statistic: {result[0]}")<br/>print(f"p-value: {result[1]}")</span><span id="6429" class="lr ls iq ln b gy nm lu l lv lw">K-S statistic: 0.46976096086398267<br/>p-value: 4.788934452701707e-11</span></pre><p id="cdaa" class="pw-post-body-paragraph jx jy iq jz b ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku ij bi translated"><em class="kv">由于𝑝-value显著小于0.05，我们拒绝零假设，接受另一个假设，即测试的两个样本不是来自同一个累积分布，这意味着微软股票的回报不是正态分布。</em></p><h1 id="c05a" class="mk ls iq bd ml mm mn mo mp mq mr ms mt mu mv mw mx my mz na nb nc nd ne nf ng bi translated"><em class="jw">安德森-达林测试</em></h1><p id="c249" class="pw-post-body-paragraph jx jy iq jz b ka nh kc kd ke ni kg kh ki nj kk kl km nk ko kp kq nl ks kt ku ij bi translated">安德森-达林试验(A-D试验)是对上述科尔莫戈罗夫-斯米尔诺夫试验的改进。它测试给定的观察样本是否来自给定的概率分布(在我们的例子中，来自正态分布)。</p><p id="3ff9" class="pw-post-body-paragraph jx jy iq jz b ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku ij bi translated"><em class="kv"> 𝐻0:数据来自指定的分布</em></p><p id="3da8" class="pw-post-body-paragraph jx jy iq jz b ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku ij bi translated"><em class="kv"> 𝐻1:数据不是来自指定的分布</em></p><p id="0306" class="pw-post-body-paragraph jx jy iq jz b ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku ij bi translated"><em class="kv">A-D检验比K-S检验更有效，因为它考虑了数据中的所有值，而不仅仅是产生最大距离的值(如K-S检验)。它还为拟合分布的尾部分配更多的权重。</em></p><p id="aebe" class="pw-post-body-paragraph jx jy iq jz b ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku ij bi translated"><em class="kv">该检验属于二次经验分布函数(EDF)统计，由以下公式给出:</em></p><figure class="kx ky kz la gt lb gh gi paragraph-image"><div class="gh gi nu"><img src="../Images/60fe688b5fb5e768dbf6caa8954cb7df.png" data-original-src="https://miro.medium.com/v2/resize:fit:1360/format:webp/1*lMEzXqSq5O4kxqDTXomOng.jpeg"/></div></figure><p id="dae1" class="pw-post-body-paragraph jx jy iq jz b ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku ij bi translated"><em class="kv">其中，𝐹是假设的分布(在我们的例子中是正态分布)，𝐹𝑛是ECDF(上一节讨论的计算)，𝑤(𝑥是加权函数。</em></p><p id="6ea6" class="pw-post-body-paragraph jx jy iq jz b ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku ij bi translated"><em class="kv">加权函数由下式给出:</em></p><figure class="kx ky kz la gt lb gh gi paragraph-image"><div role="button" tabindex="0" class="lc ld di le bf lf"><div class="gh gi nv"><img src="../Images/cd10be45b3105449dd1337d76cabe990.png" data-original-src="https://miro.medium.com/v2/resize:fit:1100/format:webp/1*q641pYGVS8UkG7aj4xqOoA.jpeg"/></div></div></figure><p id="83dd" class="pw-post-body-paragraph jx jy iq jz b ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku ij bi translated">允许在分布的尾部对观察值给予更多的权重。</p><p id="a3d3" class="pw-post-body-paragraph jx jy iq jz b ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku ij bi translated"><em class="kv">给定这样一个加权函数，检验统计量可以简化为:</em></p><figure class="kx ky kz la gt lb gh gi paragraph-image"><div class="gh gi nw"><img src="../Images/c2058fbf1c145720142ee2e0525c90e9.png" data-original-src="https://miro.medium.com/v2/resize:fit:1324/format:webp/1*ak3g5Yz-cDWjQcJgvvVHjw.jpeg"/></div></figure><p id="92b1" class="pw-post-body-paragraph jx jy iq jz b ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku ij bi translated"><em class="kv">假设我们有一个𝑋数据样本，我们想测试这个样本是否来自正态分布的累积分布函数(𝐹(𝑥)。</em></p><p id="8415" class="pw-post-body-paragraph jx jy iq jz b ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku ij bi translated"><em class="kv">我们需要对数据进行排序，以使𝑥1 &lt; 𝑥2 &lt; … &lt; 𝑥𝑛，然后计算𝐴2的统计数据为:</em></p><figure class="kx ky kz la gt lb gh gi paragraph-image"><div role="button" tabindex="0" class="lc ld di le bf lf"><div class="gh gi nx"><img src="../Images/628a963af6d13f356d2fb61287450046.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*MNg8V5jTYnoYku1Zbl-0mQ.jpeg"/></div></div></figure><p id="58fb" class="pw-post-body-paragraph jx jy iq jz b ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku ij bi translated"><em class="kv">回到我们的例子，让我们用Python对微软股票回报数据进行A-D测试:</em></p><pre class="kx ky kz la gt lm ln lo lp aw lq bi"><span id="4c05" class="lr ls iq ln b gy lt lu l lv lw">from scipy.stats import anderson</span><span id="847a" class="lr ls iq ln b gy nm lu l lv lw">result = (anderson(df['return'], dist='norm'))</span><span id="30a1" class="lr ls iq ln b gy nm lu l lv lw">print(f"A-D statistic: {result[0]}")<br/>print(f"Critical values: {result[1]}")<br/>print(f"Significance levels: {result[2]}")</span><span id="c739" class="lr ls iq ln b gy nm lu l lv lw">A-D statistic: 0.3693823006816217<br/>Critical values: [0.539 0.614 0.737 0.86  1.023]<br/>Significance levels: [15.  10.   5.   2.5  1. ]</span></pre><p id="d565" class="pw-post-body-paragraph jx jy iq jz b ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku ij bi translated"><em class="kv">输出的第一行是A-D检验统计量，在0.37左右；输出的第三行是具有不同显著性级别(从15%到1%)的列表；输出的第二行是相应显著性水平的临界值列表。</em></p><p id="6dcc" class="pw-post-body-paragraph jx jy iq jz b ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku ij bi translated"><em class="kv">假设我们要在5%的水平上测试我们的假设，这意味着我们将使用的临界值是0.737(来自上面的输出)。由于计算机A-D检验统计量(0.37)小于临界值(0.737)，我们无法拒绝零假设并得出微软股票收益的样本数据来自正态分布的结论。</em></p><h1 id="2366" class="mk ls iq bd ml mm mn mo mp mq mr ms mt mu mv mw mx my mz na nb nc nd ne nf ng bi translated"><em class="jw">夏皮罗-维尔克检验</em></h1><p id="9ede" class="pw-post-body-paragraph jx jy iq jz b ka nh kc kd ke ni kg kh ki nj kk kl km nk ko kp kq nl ks kt ku ij bi translated"><em class="kv">夏皮罗-维尔克检验(S-W检验)是统计学中的另一种正态性检验，假设如下:</em></p><p id="497e" class="pw-post-body-paragraph jx jy iq jz b ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku ij bi translated"><em class="kv">样本的𝐻0:分布与正态分布没有显著差异</em></p><p id="f085" class="pw-post-body-paragraph jx jy iq jz b ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku ij bi translated"><em class="kv">样本的𝐻1:分布明显不同于正态分布</em></p><p id="4139" class="pw-post-body-paragraph jx jy iq jz b ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku ij bi translated"><em class="kv">与Kolmogorov-Smirnov测试和Anderson-Darling测试不同，它的统计计算不是基于ECDF和CDF，而是使用从正态分布样本的矩生成的常数。</em></p><p id="39ed" class="pw-post-body-paragraph jx jy iq jz b ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku ij bi translated"><em class="kv">夏皮罗-维尔克检验统计量定义为:</em></p><figure class="kx ky kz la gt lb gh gi paragraph-image"><div class="gh gi ny"><img src="../Images/7408136c0a6f46aac9b83a2b543e983d.png" data-original-src="https://miro.medium.com/v2/resize:fit:924/format:webp/1*BDE9G1ZGwluzR1sKlQafQA.jpeg"/></div></figure><p id="ebf9" class="pw-post-body-paragraph jx jy iq jz b ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku ij bi translated"><em class="kv">其中𝑥(𝑖)是样本中𝑖th最小的数(𝑥1&lt;𝑥2&lt;……&lt;𝑥𝑛)；和𝑎𝑖是从正态分布样本的var，cov，mean生成的常数。</em></p><p id="6a32" class="pw-post-body-paragraph jx jy iq jz b ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku ij bi translated"><em class="kv">回到我们的例子，让我们用Python对微软股票回报数据执行S-W测试:</em></p><pre class="kx ky kz la gt lm ln lo lp aw lq bi"><span id="1c24" class="lr ls iq ln b gy lt lu l lv lw">from scipy.stats import shapiro<br/><br/>result = (shapiro(df['return']))<br/><br/>print(f"S-W statistic: {result[0]}")<br/>print(f"p-value: {result[1]}")</span><span id="9f15" class="lr ls iq ln b gy nm lu l lv lw">S-W statistic: 0.9772366881370544<br/>p-value: 0.41611215472221375</span></pre><p id="c414" class="pw-post-body-paragraph jx jy iq jz b ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku ij bi translated"><em class="kv">给定大于0.05 ( &gt; 0.05)的大𝑝-value (0.42)，我们无法拒绝零假设并得出样本与正态分布没有显著差异的结论。</em></p><p id="f3fd" class="pw-post-body-paragraph jx jy iq jz b ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku ij bi translated"><em class="kv">注意:该测试的最大限制之一是规模偏差，这意味着样本规模越大，您越有可能获得具有统计显著性的结果。</em></p><p id="6b1f" class="pw-post-body-paragraph jx jy iq jz b ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku ij bi translated"><em class="kv">要下载笔记本和数据集，请检查</em> <a class="ae np" href="https://github.com/rashmimarganiatgithub/normality-test" rel="noopener ugc nofollow" target="_blank"> <em class="kv"> Github </em> </a></p><p id="5c9b" class="pw-post-body-paragraph jx jy iq jz b ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku ij bi translated">注意:数据漂移和概念漂移是可以写一本新书的巨大话题。因此，其他一些有用的工具，探索作为一个参考，有一些更广泛和更深入的各种味道的数据集，如 <a class="ae np" href="https://torchdrift.org/" rel="noopener ugc nofollow" target="_blank"> <em class="kv">【火炬裂痕】</em></a><em class="kv"/><a class="ae np" href="https://evidentlyai.com/blog/evidently-001-open-source-tool-to-analyze-data-drift" rel="noopener ugc nofollow" target="_blank"><em class="kv">【证据】</em></a><a class="ae np" href="https://github.com/SeldonIO/alibi-detect" rel="noopener ugc nofollow" target="_blank">不在场证明检测</a><a class="ae np" href="https://github.com/online-ml/river" rel="noopener ugc nofollow" target="_blank">河</a>。</p><p id="c3ae" class="pw-post-body-paragraph jx jy iq jz b ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku ij bi translated">在接下来的系列文章中，我们将从不同的方面探讨如何实现一个有效的数据管道，这是ML系统开发阶段的一个关键部分。</p></div></div>    
</body>
</html>