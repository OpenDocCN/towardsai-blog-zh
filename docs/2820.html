<html>
<head>
<title>Databricks Linear Regression With Spark ML</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">带Spark ML的数据块线性回归</h1>
<blockquote>原文：<a href="https://pub.towardsai.net/databricks-linear-regression-with-spark-ml-6240180784e3?source=collection_archive---------0-----------------------#2022-06-06">https://pub.towardsai.net/databricks-linear-regression-with-spark-ml-6240180784e3?source=collection_archive---------0-----------------------#2022-06-06</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="1044" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">如何处理数据，拟合Spark ML线性回归模型，评估模型性能，保存模型，对新数据进行预测？</h2></div><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ki"><img src="../Images/f5a06af00d4f9dd0094954560990f85a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*il2LODpHQLswTjlB"/></div></div><figcaption class="ku kv gj gh gi kw kx bd b be z dk translated">照片由<a class="ae ky" href="https://unsplash.com/@atharva_tulsi?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Atharva Tulsi </a>在<a class="ae ky" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上拍摄</figcaption></figure><p id="dcca" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">Apache Spark为不同类型的机器学习模型提供了一个库。在本教程中，我们将讨论如何使用Databricks来实现spark ML线性回归模型。我们将涵盖:</p><ul class=""><li id="22fa" class="lv lw it lb b lc ld lf lg li lx lm ly lq lz lu ma mb mc md bi translated">Spark MLlib和Spark ML有什么区别？</li><li id="4817" class="lv lw it lb b lc me lf mf li mg lm mh lq mi lu ma mb mc md bi translated">如何以正确的格式处理数据？</li><li id="09bc" class="lv lw it lb b lc me lf mf li mg lm mh lq mi lu ma mb mc md bi translated">如何拟合一个Spark ML线性回归模型？</li><li id="4846" class="lv lw it lb b lc me lf mf li mg lm mh lq mi lu ma mb mc md bi translated">如何评价模型性能？</li><li id="1a06" class="lv lw it lb b lc me lf mf li mg lm mh lq mi lu ma mb mc md bi translated">如何保存模型？</li><li id="8c52" class="lv lw it lb b lc me lf mf li mg lm mh lq mi lu ma mb mc md bi translated">如何对新数据进行预测？</li></ul><p id="7d4c" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><strong class="lb iu">本帖资源:</strong></p><ul class=""><li id="d61b" class="lv lw it lb b lc ld lf lg li lx lm ly lq lz lu ma mb mc md bi translated">YouTube上这篇文章的视频教程<a class="ae ky" href="https://www.youtube.com/watch?v=ai8ubQYpllY&amp;list=PLVppujud2yJrb5CCEu0gqgI_W0YuCygIc&amp;index=9" rel="noopener ugc nofollow" target="_blank"/></li><li id="f765" class="lv lw it lb b lc me lf mf li mg lm mh lq mi lu ma mb mc md bi translated">点击<a class="ae ky" href="https://mailchi.mp/d093169f09b0/9a8dt5scel" rel="noopener ugc nofollow" target="_blank">此处</a>查看数据砖笔记本</li><li id="18ac" class="lv lw it lb b lc me lf mf li mg lm mh lq mi lu ma mb mc md bi translated">关于<a class="ae ky" href="https://www.youtube.com/playlist?list=PLVppujud2yJrb5CCEu0gqgI_W0YuCygIc" rel="noopener ugc nofollow" target="_blank"> Databricks和PySpark的更多视频教程</a></li><li id="0604" class="lv lw it lb b lc me lf mf li mg lm mh lq mi lu ma mb mc md bi translated">更多关于<a class="ae ky" href="https://medium.com/@AmyGrabNGoInfo/list/databricks-and-pyspark-7b59768e202d" rel="noopener"> Databricks和PySpark </a>的博客文章</li></ul><p id="4a5b" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">我们开始吧！</p></div><div class="ab cl mj mk hx ml" role="separator"><span class="mm bw bk mn mo mp"/><span class="mm bw bk mn mo mp"/><span class="mm bw bk mn mo"/></div><div class="im in io ip iq"><h1 id="3fa8" class="mq mr it bd ms mt mu mv mw mx my mz na jz nb ka nc kc nd kd ne kf nf kg ng nh bi translated">步骤0: Spark MLlib与Spark ML</h1><p id="fee6" class="pw-post-body-paragraph kz la it lb b lc ni ju le lf nj jx lh li nk lk ll lm nl lo lp lq nm ls lt lu im bi translated">首先说一下spark MLlib和spark ML的区别。</p><p id="2f4a" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><code class="fe nn no np nq b">spark.mllib</code>传统的机器学习API是建立在RDDs之上的吗？<code class="fe nn no np nq b">spark.ml</code>是基于dataframe的新机器学习API。</p><p id="c248" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">MLlib这个名称包括基于RDD的API和基于数据帧的API。基于RDD的API现在处于维护模式，所以不会有新的特性添加到基于RDD的API中。</p><p id="7c41" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">在本教程中，我们将使用基于dataframe的API，我建议您也使用它。</p><h1 id="599f" class="mq mr it bd ms mt nr mv mw mx ns mz na jz nt ka nc kc nu kd ne kf nv kg ng nh bi translated">步骤1:导入库</h1><p id="6109" class="pw-post-body-paragraph kz la it lb b lc ni ju le lf nj jx lh li nk lk ll lm nl lo lp lq nm ls lt lu im bi translated">在步骤1中，我们将导入库。<code class="fe nn no np nq b">pandas</code>是进行数据处理。<code class="fe nn no np nq b">make_regression</code>用于创建合成建模数据集。</p><p id="e63c" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">从pyspark.ml库中，我们导入了用于特征格式化的<code class="fe nn no np nq b">VectorAssembler</code>、用于模型训练的<code class="fe nn no np nq b">LinearRegression</code>、用于模型评估的<code class="fe nn no np nq b">RegressionEvaluator</code>、用于管道创建和加载的<code class="fe nn no np nq b">Pipeline</code>和<code class="fe nn no np nq b">PipelineModel</code>。</p><pre class="kj kk kl km gt nw nq nx ny aw nz bi"><span id="65cf" class="oa mr it nq b gy ob oc l od oe"># Data processing<br/>import pandas as pd</span><span id="502e" class="oa mr it nq b gy of oc l od oe"># Create synthetic dataset<br/>from sklearn.datasets import make_regression</span><span id="f7d4" class="oa mr it nq b gy of oc l od oe"># Modeling<br/>from pyspark.ml.feature import VectorAssembler<br/>from pyspark.ml.regression import LinearRegression<br/>from pyspark.ml.evaluation import RegressionEvaluator<br/>from pyspark.ml import Pipeline, PipelineModel</span></pre><h1 id="3c7a" class="mq mr it bd ms mt nr mv mw mx ns mz na jz nt ka nc kc nu kd ne kf nv kg ng nh bi translated">步骤2:为线性回归创建数据集</h1><p id="0ab6" class="pw-post-body-paragraph kz la it lb b lc ni ju le lf nj jx lh li nk lk ll lm nl lo lp lq nm ls lt lu im bi translated">在步骤2中，我们将为线性回归模型创建一个合成数据集。</p><p id="86e2" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">使用<code class="fe nn no np nq b">make_regression</code>，创建了一个包含一百万条记录的数据集。数据集有两个特征，偏差为2，一个数字相关变量和30%的噪声。random_state确保随机创建的数据集是可重复的。随机状态不一定是42。它可以是任何数字。</p><p id="c350" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><code class="fe nn no np nq b">make_regression</code>的输出是数组格式。我们把它转换成熊猫数据帧，然后再转换成火花数据帧。</p><p id="3abf" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><code class="fe nn no np nq b">summary()</code>给出了数据集的汇总统计数据。</p><pre class="kj kk kl km gt nw nq nx ny aw nz bi"><span id="82e5" class="oa mr it nq b gy ob oc l od oe"># Create a synthetic dataset<br/>X, y = make_regression(n_samples=1000000, n_features=2, noise=0.3, bias=2, random_state=42)</span><span id="6363" class="oa mr it nq b gy of oc l od oe"># Convert the data from numpy array to a pandas dataframe<br/>pdf = pd.DataFrame({'feature1': X[:, 0], 'feature2': X[:, 1], 'dependent_variable': y})</span><span id="5e45" class="oa mr it nq b gy of oc l od oe"># Convert pandas dataframe to spark dataframe<br/>sdf = spark.createDataFrame(pdf)</span><span id="4022" class="oa mr it nq b gy of oc l od oe"># Check data summary statistics<br/>display(sdf.summary())</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi og"><img src="../Images/0ce4467ec0c27d4b4122f578a745df2e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*No_MDnVkF7Mv_dkx.png"/></div></div><figcaption class="ku kv gj gh gi kw kx bd b be z dk translated">来自GrabNGoInfo.com的合成数据图像的汇总统计</figcaption></figure><h1 id="500d" class="mq mr it bd ms mt nr mv mw mx ns mz na jz nt ka nc kc nu kd ne kf nv kg ng nh bi translated">步骤3:训练测试分割</h1><p id="f8a5" class="pw-post-body-paragraph kz la it lb b lc ni ju le lf nj jx lh li nk lk ll lm nl lo lp lq nm ls lt lu im bi translated">在创建建模数据集之后，在步骤3中，我们将进行训练测试分割。</p><p id="5162" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">使用<code class="fe nn no np nq b">randomSplit</code>，我们将数据集分成80%的训练和20%的验证。<code class="fe nn no np nq b">seed=42</code>使随机分割结果可重复。但是，我们需要确保在复制分割时使用相同的集群和分区号。</p><pre class="kj kk kl km gt nw nq nx ny aw nz bi"><span id="a04a" class="oa mr it nq b gy ob oc l od oe"># Train test split<br/>trainDF, testDF = sdf.randomSplit([.8, .2], seed=42)</span><span id="8e42" class="oa mr it nq b gy of oc l od oe"># Print the number of records<br/>print(f'There are {trainDF.cache().count()} records in the training dataset.')<br/>print(f'There are {testDF.cache().count()} records in the testing dataset.')</span></pre><p id="be4b" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">分割后，我们在训练数据集中得到800，299，在测试数据集中得到199，701。</p><pre class="kj kk kl km gt nw nq nx ny aw nz bi"><span id="1a58" class="oa mr it nq b gy ob oc l od oe">There are 800299 records in the training dataset.<br/>There are 199701 records in the testing dataset.</span></pre><h1 id="f049" class="mq mr it bd ms mt nr mv mw mx ns mz na jz nt ka nc kc nu kd ne kf nv kg ng nh bi translated">步骤4:矢量汇编程序</h1><p id="e89c" class="pw-post-body-paragraph kz la it lb b lc ni ju le lf nj jx lh li nk lk ll lm nl lo lp lq nm ls lt lu im bi translated">线性回归需要一个矢量输入作为特征，因此在第4步中，我们将使用VectorAssembler将特征转换为矢量格式。</p><pre class="kj kk kl km gt nw nq nx ny aw nz bi"><span id="1d98" class="oa mr it nq b gy ob oc l od oe"># Linear regression expect a vector input<br/>vecAssembler = VectorAssembler(inputCols=['feature1', 'feature2'], outputCol="features")<br/>vecTrainDF = vecAssembler.transform(trainDF)</span><span id="f342" class="oa mr it nq b gy of oc l od oe"># Take a look at the data<br/>display(vecTrainDF)</span></pre><p id="53f9" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">我们可以看到，在新创建的名为“features”的列中，这两个特性以矢量格式列出。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi og"><img src="../Images/7180d623201fb29b0be379307e6412e9.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*yQSKnurLsQjZaa7T.png"/></div></div><figcaption class="ku kv gj gh gi kw kx bd b be z dk translated">Databricks Spark ML特征格式—图片来自GrabNGoInfo.com</figcaption></figure><h1 id="9044" class="mq mr it bd ms mt nr mv mw mx ns mz na jz nt ka nc kc nu kd ne kf nv kg ng nh bi translated">步骤5:拟合Spark ML线性回归模型</h1><p id="a6d2" class="pw-post-body-paragraph kz la it lb b lc ni ju le lf nj jx lh li nk lk ll lm nl lo lp lq nm ls lt lu im bi translated">在第5步中，我们将拟合线性回归模型。</p><p id="b4c6" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">首先，为线性回归指定特征列和标注列。</p><p id="9064" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">然后，在矢量化的训练数据集上拟合线性回归模型。</p><p id="2f4c" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">之后，打印模型截距和系数。</p><pre class="kj kk kl km gt nw nq nx ny aw nz bi"><span id="253b" class="oa mr it nq b gy ob oc l od oe"># Create linear regression<br/>lr = LinearRegression(featuresCol="features", labelCol="dependent_variable")</span><span id="3214" class="oa mr it nq b gy of oc l od oe"># Fit the linear regresssion model<br/>lrModel = lr.fit(vecTrainDF)</span><span id="8510" class="oa mr it nq b gy of oc l od oe"># Print model intercept and coefficients<br/>print(f'The intercept of the model is {lrModel.intercept:.2f} and the coefficients of the model are {lrModel.coefficients[0]:.2f} and {lrModel.coefficients[1]:.2f}')</span></pre><p id="5cff" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">我们可以看到，该模型的截距为2，两个特征的系数分别为82.09和35.03。</p><pre class="kj kk kl km gt nw nq nx ny aw nz bi"><span id="3774" class="oa mr it nq b gy ob oc l od oe">The intercept of the model is 2.00 and the coefficients of the model are 82.09 and 35.03</span></pre><p id="713b" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">或者，我们可以创建一个管道，并在管道上安装模型。流水线通常包括数据处理步骤和模型拟合步骤。</p><pre class="kj kk kl km gt nw nq nx ny aw nz bi"><span id="75c1" class="oa mr it nq b gy ob oc l od oe"># Create pipeline<br/>stages = [vecAssembler, lr]<br/>pipeline = Pipeline(stages=stages)</span><span id="d415" class="oa mr it nq b gy of oc l od oe"># Fit the pipeline model<br/>pipelineModel = pipeline.fit(trainDF)</span></pre><h1 id="7525" class="mq mr it bd ms mt nr mv mw mx ns mz na jz nt ka nc kc nu kd ne kf nv kg ng nh bi translated">步骤6:模型性能评估</h1><p id="7855" class="pw-post-body-paragraph kz la it lb b lc ni ju le lf nj jx lh li nk lk ll lm nl lo lp lq nm ls lt lu im bi translated">在步骤6中，我们将使用测试数据集评估模型性能。</p><p id="ba45" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">为了进行模型性能评估，我们需要首先对测试数据集进行预测。使用上一步中创建的<code class="fe nn no np nq b">pipelineModel</code>，我们可以用一行代码转换测试数据集并做出预测。</p><pre class="kj kk kl km gt nw nq nx ny aw nz bi"><span id="98fa" class="oa mr it nq b gy ob oc l od oe"># Make predictions on testing dataset<br/>predDF = pipelineModel.transform(testDF)</span><span id="5989" class="oa mr it nq b gy of oc l od oe"># Take a look at the output<br/>display(predDF.select("features", "dependent_variable", "prediction"))</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi og"><img src="../Images/0a674f5422706196f24c2d8ba7609378.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*tAbbtZ8Ib4haxx9J.png"/></div></div><figcaption class="ku kv gj gh gi kw kx bd b be z dk translated">Databricks Spark ML车型性能评估—图片来自GrabNGoInfo.com</figcaption></figure><p id="a09d" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">获得预测值后，我们将预测列名和实际值列名传递到<code class="fe nn no np nq b">RegressionEvaluator</code>。</p><p id="f320" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><code class="fe nn no np nq b">metricName</code>可以是下列值之一:</p><ul class=""><li id="31c4" class="lv lw it lb b lc ld lf lg li lx lm ly lq lz lu ma mb mc md bi translated"><code class="fe nn no np nq b">rmse</code>:均方根误差为默认值</li><li id="f89b" class="lv lw it lb b lc me lf mf li mg lm mh lq mi lu ma mb mc md bi translated"><code class="fe nn no np nq b">mse</code>:均方误差</li><li id="6b2c" class="lv lw it lb b lc me lf mf li mg lm mh lq mi lu ma mb mc md bi translated"><code class="fe nn no np nq b">r2</code> : R方形</li><li id="f540" class="lv lw it lb b lc me lf mf li mg lm mh lq mi lu ma mb mc md bi translated"><code class="fe nn no np nq b">mae</code>:平均绝对误差</li></ul><pre class="kj kk kl km gt nw nq nx ny aw nz bi"><span id="fbf8" class="oa mr it nq b gy ob oc l od oe"># Create regression evaluator<br/>regressionEvaluator = RegressionEvaluator(predictionCol="prediction", labelCol="dependent_variable", metricName="rmse")</span><span id="b4a8" class="oa mr it nq b gy of oc l od oe"># RMSE<br/>rmse = regressionEvaluator.evaluate(predDF)<br/>print(f"The RMSE for the linear regression model is {rmse:0.2f}")</span><span id="dbf5" class="oa mr it nq b gy of oc l od oe"># MSE<br/>mse = regressionEvaluator.setMetricName("mse").evaluate(predDF)<br/>print(f"The MSE for the linear regression model is {mse:0.2f}")</span><span id="d165" class="oa mr it nq b gy of oc l od oe"># R2<br/>r2 = regressionEvaluator.setMetricName("r2").evaluate(predDF)<br/>print(f"The R2 for the linear regression model is {r2:0.2f}")</span><span id="71d7" class="oa mr it nq b gy of oc l od oe"># MAE<br/>mae = regressionEvaluator.setMetricName("mae").evaluate(predDF)<br/>print(f"The MAE for the linear regression model is {mae:0.2f}")</span></pre><p id="4409" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">输出</p><pre class="kj kk kl km gt nw nq nx ny aw nz bi"><span id="0ad5" class="oa mr it nq b gy ob oc l od oe">The RMSE for the linear regression model is 0.30<br/>The MSE for the linear regression model is 0.09<br/>The R2 for the linear regression model is 1.00<br/>The MAE for the linear regression model is 0.24</span></pre><p id="f466" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">我们还可以创建一个散点图来直观地检查实际值和预测值之间的关系。要了解如何使用Databricks笔记本中的内置图表功能，请查看我之前关于<a class="ae ky" href="https://grabngoinfo.com/databricks-dashboard-for-big-data/" rel="noopener ugc nofollow" target="_blank">Data bricks Dashboard For Big Data</a>的教程。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi oh"><img src="../Images/92f7b0588a7a7d74b9b21cf93b0b62ed.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*KUIlzbhryIUZ9Oef.png"/></div></div><figcaption class="ku kv gj gh gi kw kx bd b be z dk translated">Databricks Spark ML线性回归实际值与预测值——图片来自GrabNGoInfo.com</figcaption></figure><h1 id="08cb" class="mq mr it bd ms mt nr mv mw mx ns mz na jz nt ka nc kc nu kd ne kf nv kg ng nh bi translated">步骤7:保存模型</h1><p id="375e" class="pw-post-body-paragraph kz la it lb b lc ni ju le lf nj jx lh li nk lk ll lm nl lo lp lq nm ls lt lu im bi translated">在第7步中，我们将把管道模型保存到AWS S3存储桶中。要了解如何将S3铲斗安装到数据块，请查看我以前的教程<a class="ae ky" href="https://grabngoinfo.com/databricks-mount-to-aws-s3-and-import-data/" rel="noopener ugc nofollow" target="_blank">数据块安装到AWS S3和导入数据</a>。</p><pre class="kj kk kl km gt nw nq nx ny aw nz bi"><span id="b145" class="oa mr it nq b gy ob oc l od oe"># Path to save the model<br/>pipelinePath = '/mnt/demo4tutorial/model/linear_regression_pipeline_model'</span><span id="4795" class="oa mr it nq b gy of oc l od oe"># Save the model to the path<br/>pipelineModel.write().overwrite().save(pipelinePath)</span></pre><p id="12de" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">在将模型保存到S3后，我们可以使用<code class="fe nn no np nq b">%fs ls</code>命令确认模型在桶中。</p><pre class="kj kk kl km gt nw nq nx ny aw nz bi"><span id="689a" class="oa mr it nq b gy ob oc l od oe"># Confirm the model is saved<br/>%fs ls '/mnt/demo4tutorial/model/linear_regression_pipeline_model'</span></pre><p id="1088" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">我们可以看到，为模型保存了管道阶段和元数据。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi og"><img src="../Images/4588ae2218dfcfe6510c0b7b7d472c2c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*-4XN2WQ1cou0bfOP.png"/></div></div><figcaption class="ku kv gj gh gi kw kx bd b be z dk translated">Databricks Spark ML存储模型—图片来自GrabNGoInfo.com</figcaption></figure><h1 id="93a1" class="mq mr it bd ms mt nr mv mw mx ns mz na jz nt ka nc kc nu kd ne kf nv kg ng nh bi translated">步骤8:对新数据进行预测</h1><p id="0e44" class="pw-post-body-paragraph kz la it lb b lc ni ju le lf nj jx lh li nk lk ll lm nl lo lp lq nm ls lt lu im bi translated">在第8步中，我们将回顾如何使用保存的模型对新数据进行预测。</p><p id="b761" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">我们首先创建一个包含1000条记录的新数据集。特征的数量、偏差和噪声与训练数据集相同，以确保新数据集遵循相同的分布。</p><pre class="kj kk kl km gt nw nq nx ny aw nz bi"><span id="a7df" class="oa mr it nq b gy ob oc l od oe"># Create a new synthetic dataset<br/>X_new, y_new = make_regression(n_samples=1000, n_features=2, bias=2, noise=0.3, random_state=0)</span><span id="2b4a" class="oa mr it nq b gy of oc l od oe"># Convert the data from numpy array to a pandas dataframe<br/>pdf_new = pd.DataFrame({'feature1': X_new[:, 0], 'feature2': X_new[:, 1], 'dependent_variable': y_new})</span><span id="b37c" class="oa mr it nq b gy of oc l od oe"># Convert pandas dataframe to spark dataframe<br/>sdf_new = spark.createDataFrame(pdf_new)</span><span id="27a6" class="oa mr it nq b gy of oc l od oe"># Check data summary statistics<br/>display(sdf_new.summary())</span></pre><p id="c5f4" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">然后，从S3桶加载管道模型，并对新数据集进行预测。</p><pre class="kj kk kl km gt nw nq nx ny aw nz bi"><span id="447b" class="oa mr it nq b gy ob oc l od oe"># Load the saved model<br/>loadedPipelineModel = PipelineModel.load(pipelinePath)</span><span id="9b06" class="oa mr it nq b gy of oc l od oe"># Make prediction for the new dataset<br/>predDF_new = loadedPipelineModel.transform(sdf_new)</span><span id="8a21" class="oa mr it nq b gy of oc l od oe"># Take a look at the data<br/>display(predDF_new.select("features", "dependent_variable", "prediction"))</span></pre><h1 id="d7ae" class="mq mr it bd ms mt nr mv mw mx ns mz na jz nt ka nc kc nu kd ne kf nv kg ng nh bi translated">步骤9:将所有代码放在一起</h1><pre class="kj kk kl km gt nw nq nx ny aw nz bi"><span id="7258" class="oa mr it nq b gy ob oc l od oe">###### Step 1: Import Libraries</span><span id="1af9" class="oa mr it nq b gy of oc l od oe"># Data processing<br/>import pandas as pd</span><span id="6acd" class="oa mr it nq b gy of oc l od oe"># Create synthetic dataset<br/>from sklearn.datasets import make_regression</span><span id="b362" class="oa mr it nq b gy of oc l od oe"># Modeling<br/>from pyspark.ml.feature import VectorAssembler<br/>from pyspark.ml.regression import LinearRegression<br/>from pyspark.ml.evaluation import RegressionEvaluator<br/>from pyspark.ml import Pipeline, PipelineModel<br/></span><span id="f0ad" class="oa mr it nq b gy of oc l od oe">###### Step 2: Create Dataset For Linear Regression</span><span id="50ae" class="oa mr it nq b gy of oc l od oe"># Create a synthetic dataset<br/>X, y = make_regression(n_samples=1000000, n_features=2, noise=0.3, bias=2, random_state=42)</span><span id="f455" class="oa mr it nq b gy of oc l od oe"># Convert the data from numpy array to a pandas dataframe<br/>pdf = pd.DataFrame({'feature1': X[:, 0], 'feature2': X[:, 1], 'dependent_variable': y})</span><span id="fdb2" class="oa mr it nq b gy of oc l od oe"># Convert pandas dataframe to spark dataframe<br/>sdf = spark.createDataFrame(pdf)</span><span id="ccfe" class="oa mr it nq b gy of oc l od oe"># Check data summary statistics<br/>display(sdf.summary())<br/></span><span id="5dc2" class="oa mr it nq b gy of oc l od oe">###### Step 3: Train Test Split</span><span id="5b81" class="oa mr it nq b gy of oc l od oe"># Train test split<br/>trainDF, testDF = sdf.randomSplit([.8, .2], seed=42)</span><span id="3993" class="oa mr it nq b gy of oc l od oe"># Print the number of records<br/>print(f'There are {trainDF.cache().count()} records in the training dataset.')<br/>print(f'There are {testDF.cache().count()} records in the testing dataset.')<br/></span><span id="66d5" class="oa mr it nq b gy of oc l od oe">###### Step 4: Vector Assembler</span><span id="c0a6" class="oa mr it nq b gy of oc l od oe"># Linear regression expect a vector input<br/>vecAssembler = VectorAssembler(inputCols=['feature1', 'feature2'], outputCol="features")<br/>vecTrainDF = vecAssembler.transform(trainDF)</span><span id="0ab1" class="oa mr it nq b gy of oc l od oe"># Take a look at the data<br/>display(vecTrainDF)<br/></span><span id="8a23" class="oa mr it nq b gy of oc l od oe">###### Step 5: Fit Spark ML Linear Regression Model</span><span id="9e97" class="oa mr it nq b gy of oc l od oe"># Create linear regression<br/>lr = LinearRegression(featuresCol="features", labelCol="dependent_variable")</span><span id="a910" class="oa mr it nq b gy of oc l od oe"># Fit the linear regresssion model<br/>lrModel = lr.fit(vecTrainDF)</span><span id="73f3" class="oa mr it nq b gy of oc l od oe"># Print model intercept and coefficients<br/>print(f'The intercept of the model is {lrModel.intercept:.2f} and the coefficients of the model are {lrModel.coefficients[0]:.2f} and {lrModel.coefficients[1]:.2f}')</span><span id="193b" class="oa mr it nq b gy of oc l od oe"># Create pipeline<br/>stages = [vecAssembler, lr]<br/>pipeline = Pipeline(stages=stages)</span><span id="aafc" class="oa mr it nq b gy of oc l od oe"># Fit the pipeline model<br/>pipelineModel = pipeline.fit(trainDF)<br/></span><span id="25e9" class="oa mr it nq b gy of oc l od oe">###### Step 6: Model Performance Evaluation</span><span id="561f" class="oa mr it nq b gy of oc l od oe"># Make predictions on testing dataset<br/>predDF = pipelineModel.transform(testDF)</span><span id="134d" class="oa mr it nq b gy of oc l od oe"># Take a look at the output<br/>display(predDF.select("features", "dependent_variable", "prediction"))</span><span id="4995" class="oa mr it nq b gy of oc l od oe"># Create regression evaluator<br/>regressionEvaluator = RegressionEvaluator(predictionCol="prediction", labelCol="dependent_variable", metricName="rmse")</span><span id="adf5" class="oa mr it nq b gy of oc l od oe"># RMSE<br/>rmse = regressionEvaluator.evaluate(predDF)<br/>print(f"The RMSE for the linear regression model is {rmse:0.2f}")</span><span id="509d" class="oa mr it nq b gy of oc l od oe"># MSE<br/>mse = regressionEvaluator.setMetricName("mse").evaluate(predDF)<br/>print(f"The MSE for the linear regression model is {mse:0.2f}")</span><span id="35b9" class="oa mr it nq b gy of oc l od oe"># R2<br/>r2 = regressionEvaluator.setMetricName("r2").evaluate(predDF)<br/>print(f"The R2 for the linear regression model is {r2:0.2f}")</span><span id="92e7" class="oa mr it nq b gy of oc l od oe"># MAE<br/>mae = regressionEvaluator.setMetricName("mae").evaluate(predDF)<br/>print(f"The MAE for the linear regression model is {mae:0.2f}")</span><span id="c015" class="oa mr it nq b gy of oc l od oe"># Visualize the data<br/>display(predDF.select("dependent_variable", "prediction"))<br/></span><span id="d9d2" class="oa mr it nq b gy of oc l od oe">###### Step 7: Save Model</span><span id="18e5" class="oa mr it nq b gy of oc l od oe"># Path to save the model<br/>pipelinePath = '/mnt/demo4tutorial/model/linear_regression_pipeline_model'</span><span id="fead" class="oa mr it nq b gy of oc l od oe"># Save the model to the path<br/>pipelineModel.write().overwrite().save(pipelinePath)</span><span id="b3b0" class="oa mr it nq b gy of oc l od oe"># Confirm the model is saved<br/>%fs ls '/mnt/demo4tutorial/model/linear_regression_pipeline_model'<br/></span><span id="27a2" class="oa mr it nq b gy of oc l od oe">###### Step 8: Make Predictions For New Data</span><span id="bd84" class="oa mr it nq b gy of oc l od oe"># Create a new synthetic dataset<br/>X_new, y_new = make_regression(n_samples=1000, n_features=2, bias=2, noise=0.3, random_state=0)</span><span id="8003" class="oa mr it nq b gy of oc l od oe"># Convert the data from numpy array to a pandas dataframe<br/>pdf_new = pd.DataFrame({'feature1': X_new[:, 0], 'feature2': X_new[:, 1], 'dependent_variable': y_new})</span><span id="672d" class="oa mr it nq b gy of oc l od oe"># Convert pandas dataframe to spark dataframe<br/>sdf_new = spark.createDataFrame(pdf_new)</span><span id="e364" class="oa mr it nq b gy of oc l od oe"># Check data summary statistics<br/>display(sdf_new.summary())</span><span id="810f" class="oa mr it nq b gy of oc l od oe"># Load the saved model<br/>loadedPipelineModel = PipelineModel.load(pipelinePath)</span><span id="6341" class="oa mr it nq b gy of oc l od oe"># Make prediction for the new dataset<br/>predDF_new = loadedPipelineModel.transform(sdf_new)</span><span id="59bc" class="oa mr it nq b gy of oc l od oe"># Take a look at the data<br/>display(predDF_new.select("features", "dependent_variable", "prediction"))</span><span id="bb86" class="oa mr it nq b gy of oc l od oe"># Actual vs. predicted<br/>display(predDF_new.select("dependent_variable", "prediction"))</span></pre></div><div class="ab cl mj mk hx ml" role="separator"><span class="mm bw bk mn mo mp"/><span class="mm bw bk mn mo mp"/><span class="mm bw bk mn mo"/></div><div class="im in io ip iq"><h1 id="3c0e" class="mq mr it bd ms mt mu mv mw mx my mz na jz nb ka nc kc nd kd ne kf nf kg ng nh bi translated">摘要</h1><p id="083b" class="pw-post-body-paragraph kz la it lb b lc ni ju le lf nj jx lh li nk lk ll lm nl lo lp lq nm ls lt lu im bi translated">在本教程中，我们介绍了如何使用数据块来实现spark ML线性回归模型。你已经学会了:</p><ul class=""><li id="deab" class="lv lw it lb b lc ld lf lg li lx lm ly lq lz lu ma mb mc md bi translated">Spark MLlib和Spark ML有什么区别？</li><li id="5dc0" class="lv lw it lb b lc me lf mf li mg lm mh lq mi lu ma mb mc md bi translated">如何以正确的格式处理数据？</li><li id="ee50" class="lv lw it lb b lc me lf mf li mg lm mh lq mi lu ma mb mc md bi translated">如何拟合一个Spark ML线性回归模型？</li><li id="155b" class="lv lw it lb b lc me lf mf li mg lm mh lq mi lu ma mb mc md bi translated">如何评价模型性能？</li><li id="7108" class="lv lw it lb b lc me lf mf li mg lm mh lq mi lu ma mb mc md bi translated">如何保存模型？</li><li id="bfe5" class="lv lw it lb b lc me lf mf li mg lm mh lq mi lu ma mb mc md bi translated">如何对新数据进行预测？</li></ul><p id="90be" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">更多教程可在GrabNGoInfo <a class="ae ky" href="https://www.youtube.com/channel/UCmbA7XB6Wb7bLwJw9ARPcYg" rel="noopener ugc nofollow" target="_blank"> YouTube频道</a>和<a class="ae ky" href="https://grabngoinfo.com/tutorials/" rel="noopener ugc nofollow" target="_blank">GrabNGoInfo.com</a>获得</p><h1 id="effe" class="mq mr it bd ms mt nr mv mw mx ns mz na jz nt ka nc kc nu kd ne kf nv kg ng nh bi translated">推荐给你</h1><ul class=""><li id="8e7b" class="lv lw it lb b lc ni lf nj li oi lm oj lq ok lu ma mb mc md bi translated"><a class="ae ky" href="https://medium.com/grabngoinfo/grabngoinfo-machine-learning-tutorials-inventory-9b9d78ebdd67" rel="noopener"> GrabNGoInfo机器学习教程盘点</a></li><li id="bc74" class="lv lw it lb b lc me lf mf li mg lm mh lq mi lu ma mb mc md bi translated"><a class="ae ky" href="https://medium.com/grabngoinfo/databricks-mount-to-aws-s3-and-import-data-4100621a63fd" rel="noopener">数据块安装到AWS S3并导入数据</a></li><li id="2a8a" class="lv lw it lb b lc me lf mf li mg lm mh lq mi lu ma mb mc md bi translated"><a class="ae ky" href="https://grabngoinfo.com/databricks-notebook-markdown-cheat-sheet/" rel="noopener ugc nofollow" target="_blank"> Databricks笔记本降价备忘单</a></li><li id="ee97" class="lv lw it lb b lc me lf mf li mg lm mh lq mi lu ma mb mc md bi translated"><a class="ae ky" href="https://grabngoinfo.com/five-ways-to-create-tables-in-databricks/" rel="noopener ugc nofollow" target="_blank">在数据块中创建表格的五种方法</a></li><li id="eee2" class="lv lw it lb b lc me lf mf li mg lm mh lq mi lu ma mb mc md bi translated"><a class="ae ky" href="https://grabngoinfo.com/databricks-dashboard-for-big-data/" rel="noopener ugc nofollow" target="_blank"> Databricks大数据仪表盘</a></li></ul><h1 id="69ef" class="mq mr it bd ms mt nr mv mw mx ns mz na jz nt ka nc kc nu kd ne kf nv kg ng nh bi translated">参考</h1><ul class=""><li id="ea8e" class="lv lw it lb b lc ni lf nj li oi lm oj lq ok lu ma mb mc md bi translated"><a class="ae ky" href="https://spark.apache.org/docs/latest/ml-guide.html" rel="noopener ugc nofollow" target="_blank"> Apache Spark机器学习库文档</a></li><li id="405d" class="lv lw it lb b lc me lf mf li mg lm mh lq mi lu ma mb mc md bi translated"><a class="ae ky" href="https://spark.apache.org/docs/latest/api/python/reference/api/pyspark.ml.evaluation.RegressionEvaluator.html" rel="noopener ugc nofollow" target="_blank"> Apache Spark回归评估器文档</a></li><li id="0db5" class="lv lw it lb b lc me lf mf li mg lm mh lq mi lu ma mb mc md bi translated"><a class="ae ky" href="https://scikit-learn.org/stable/modules/generated/sklearn.datasets.make_regression.html" rel="noopener ugc nofollow" target="_blank">关于合成回归数据集创建的Sklearn文档</a></li><li id="8d87" class="lv lw it lb b lc me lf mf li mg lm mh lq mi lu ma mb mc md bi translated"><a class="ae ky" href="https://academy.databricks.com/" rel="noopener ugc nofollow" target="_blank">数据砖学院</a></li></ul><div class="ol om gp gr on oo"><a href="https://medium.com/@AmyGrabNGoInfo/membership" rel="noopener follow" target="_blank"><div class="op ab fo"><div class="oq ab or cl cj os"><h2 class="bd iu gy z fp ot fr fs ou fu fw is bi translated">通过我的推荐链接加入媒体-艾米GrabNGoInfo</h2><div class="ov l"><h3 class="bd b gy z fp ot fr fs ou fu fw dk translated">作为一个媒体会员，你的会员费的一部分会给你阅读的作家，你可以完全接触到每一个故事…</h3></div><div class="ow l"><p class="bd b dl z fp ot fr fs ou fu fw dk translated">medium.com</p></div></div><div class="ox l"><div class="oy l oz pa pb ox pc ks oo"/></div></div></a></div></div></div>    
</body>
</html>