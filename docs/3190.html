<html>
<head>
<title>Inference Attacks — The SQL Injection of The Future</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">推理攻击—未来的SQL注入</h1>
<blockquote>原文：<a href="https://pub.towardsai.net/inference-attacks-the-sql-injection-of-the-future-ba6daa563682?source=collection_archive---------1-----------------------#2022-10-08">https://pub.towardsai.net/inference-attacks-the-sql-injection-of-the-future-ba6daa563682?source=collection_archive---------1-----------------------#2022-10-08</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="eadc" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">您对这种新的攻击媒介做好准备了吗？</h2></div><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ki"><img src="../Images/b4e20b4a0e230c51460339199582b9ca.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*0Y2C1t8kgSfoBe2x"/></div></div><figcaption class="ku kv gj gh gi kw kx bd b be z dk translated">杰佛森·桑多斯在<a class="ae ky" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上拍摄的照片</figcaption></figure><p id="6e3b" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><strong class="lb iu">你能猜到这是什么类型的攻击吗？</strong></p><ul class=""><li id="2514" class="lv lw it lb b lc ld lf lg li lx lm ly lq lz lu ma mb mc md bi translated">以应用层为目标</li><li id="4392" class="lv lw it lb b lc me lf mf li mg lm mh lq mi lu ma mb mc md bi translated">绕过传统防御</li><li id="782e" class="lv lw it lb b lc me lf mf li mg lm mh lq mi lu ma mb mc md bi translated">揭示应用程序和数据的内部工作原理</li><li id="a3c3" class="lv lw it lb b lc me lf mf li mg lm mh lq mi lu ma mb mc md bi translated">发生这种攻击的原因是应用程序在其消息中暴露了太多的信息。</li></ul><p id="d20f" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">如果你猜到了<strong class="lb iu"> SQL注入袭击，</strong>那么我很不愿意告诉你，但是你错了。</p><blockquote class="mj"><p id="3a7f" class="mk ml it bd mm mn mo mp mq mr ms lu dk translated">向针对人工智能和机器学习应用的推理攻击问好，这将成为明天的SQL注入攻击</p></blockquote><p id="3ea9" class="pw-post-body-paragraph kz la it lb b lc mt ju le lf mu jx lh li mv lk ll lm mw lo lp lq mx ls lt lu im bi translated">就像二十年前SQL注入对网络应用的攻击被证明是大多数网络安全团队的盲点一样；推理攻击将对基于人工智能的应用程序做同样的事情</p><p id="5fb9" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">就像SQL注入由于代码中的安全弱点而发生，需要在源代码级别进行修复；推理攻击的发生是由于底层的人工智能算法。</p><p id="15c1" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">你担心了吗？</p><h1 id="bbd8" class="my mz it bd na nb nc nd ne nf ng nh ni jz nj ka nk kc nl kd nm kf nn kg no np bi translated">那么什么是推理攻击呢</h1><p id="bfac" class="pw-post-body-paragraph kz la it lb b lc nq ju le lf nr jx lh li ns lk ll lm nt lo lp lq nu ls lt lu im bi translated">为了理解推理攻击，让我们看看人工智能和机器学习系统是如何工作的。</p><p id="b0bc" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">机器学习(ML)系统使用训练数据来随着时间积累知识，并做出决策或预测。输入的训练数据越多，这个决策就越准确。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi nv"><img src="../Images/e19c62beb4419629be8fc6cd1a4f1b15.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*i4PhLK_N1tU9h6qJ"/></div></div><figcaption class="ku kv gj gh gi kw kx bd b be z dk translated">来源:图片由作者提供</figcaption></figure><p id="f2e3" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">一旦进入生产阶段，ML系统通常会公开公共API，供用户和其他应用程序查询以访问它们的功能。</p><p id="b60c" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">这些模型可以部署在医疗保健和银行等行业，从而对持卡人数据或个人身份信息(PII)等敏感数据进行训练，这些数据对攻击者来说是黄金</p><p id="b1dd" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">作为一名攻击者，如果我有兴趣了解以下信息会怎么样:</p><ul class=""><li id="187a" class="lv lw it lb b lc ld lf lg li lx lm ly lq lz lu ma mb mc md bi translated"><strong class="lb iu">用什么样的数据来训练系统？</strong></li><li id="d044" class="lv lw it lb b lc me lf mf li mg lm mh lq mi lu ma mb mc md bi translated"><strong class="lb iu">ML系统如何做出这些决定？</strong></li></ul><p id="f895" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">这两者都不可用，这就是推理攻击的由来。</p><blockquote class="mj"><p id="d8d7" class="mk ml it bd mm mn mo mp mq mr ms lu dk translated">在推理攻击中，攻击者感兴趣的是获得模型被训练的数据..或者模型本身的工作。鉴于这些模型有时是根据高度敏感的数据训练的，价值数百万的知识产权；这些都可能是公司的灾难！</p></blockquote><p id="e771" class="pw-post-body-paragraph kz la it lb b lc mt ju le lf mu jx lh li mv lk ll lm mw lo lp lq mx ls lt lu im bi translated">最常见的推理攻击类型称为<strong class="lb iu">成员推理(MI)，</strong>攻击者试图重建用于训练模型的数据。</p><p id="ac79" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">ML模型通常以<strong class="lb iu">置信分数</strong>的形式提供回答，如果提供给它们的数据与它们被训练的数据相匹配，则给出更高的分数。</p><p id="927c" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">攻击者需要的只是访问API，他可以开始通过ML模型运行记录，并根据输出得分评估该模型是否在特定数据集上进行了训练。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi nv"><img src="../Images/d4cc886aa26f5485baeb55642d11b42b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*9dLdoEcTUc7hPaXw"/></div></div><figcaption class="ku kv gj gh gi kw kx bd b be z dk translated">来源:图片由作者提供</figcaption></figure><p id="8b5a" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">如果攻击者知道他在做什么，他就可以对模型进行逆向工程，并让它披露用来训练它的信息。如果机器学习模型是根据被认为敏感的数据训练的，这可能会产生严重的后果。</p><p id="6946" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><strong class="lb iu">让我们举几个例子来说明这种攻击是如何发生的:</strong></p><ul class=""><li id="b36d" class="lv lw it lb b lc ld lf lg li lx lm ly lq lz lu ma mb mc md bi translated"><em class="nw">攻击者可以查询带有名称或标识符的模型，以确定某人是否在医院的患者名单上或敏感医疗名单上。</em></li><li id="2a60" class="lv lw it lb b lc me lf mf li mg lm mh lq mi lu ma mb mc md bi translated"><em class="nw">攻击者可以发现患者是否正在接受某种药物治疗。</em></li><li id="4fb0" class="lv lw it lb b lc me lf mf li mg lm mh lq mi lu ma mb mc md bi translated"><em class="nw">攻击者可以向面部识别模型提供图像，以查明特定的面部是否用于训练。</em></li></ul><p id="e495" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">在更高级的攻击中，怀有恶意的人甚至可以窃取信用卡号和其他敏感信息，如社会安全号码！</p><h1 id="b4d1" class="my mz it bd na nb nc nd ne nf ng nh ni jz nj ka nk kc nl kd nm kf nn kg no np bi translated">ML即服务的兴起</h1><p id="4032" class="pw-post-body-paragraph kz la it lb b lc nq ju le lf nr jx lh li ns lk ll lm nt lo lp lq nu ls lt lu im bi translated">增加攻击面的一个因素是近年来机器学习即服务(MaaS)的流行。大多数公司不想经历从零开始构建模型的麻烦，可以从第一天开始就使用这些基于云的服务。</p><p id="74bf" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">云服务完成所有繁重的工作，只需提供训练数据。问题是，如果被发现，攻击者可以利用ML模型中的任何弱点来潜在地对多个公司进行成员推断攻击。</p><p id="aa2f" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><strong class="lb iu">遗憾的是，这并不是理论上的，因为康奈尔大学的研究人员</strong> <a class="ae ky" href="https://ieeexplore.ieee.org/document/7958568" rel="noopener ugc nofollow" target="_blank"> <strong class="lb iu">发表了</strong> </a> <strong class="lb iu">推理攻击的细节，可以利用这些细节来对付此类模型。</strong></p><h1 id="304e" class="my mz it bd na nb nc nd ne nf ng nh ni jz nj ka nk kc nl kd nm kf nn kg no np bi translated">新的攻击需要新的控制。</h1><p id="2a26" class="pw-post-body-paragraph kz la it lb b lc nq ju le lf nr jx lh li ns lk ll lm nt lo lp lq nu ls lt lu im bi translated">对AI和ML模型的攻击不同于传统的网络安全攻击，不能以相同的方式修复。没有修复算法的“补丁”,因为问题出在算法被训练的基础数据上。</p><p id="f2fe" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">就像应用安全从安全盲区演变成厂商行业(<strong class="lb iu">现在就买这个WAF</strong>！)到一个成熟的安全学科，毫无疑问，A.I .和机器学习攻击会遵循同样的路线。</p><p id="2bdb" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">但是，我们可以从过去的错误中吸取教训，并从今天开始实施一些控制措施:</p><ul class=""><li id="6dbd" class="lv lw it lb b lc ld lf lg li lx lm ly lq lz lu ma mb mc md bi translated"><strong class="lb iu">如果遇到训练数据，ML模型</strong>应该能够进行归纳，即先前看到的和未看到的数据分数应该相似，并且不会相差太大，从而不会将信息泄露给攻击者。</li><li id="b44d" class="lv lw it lb b lc me lf mf li mg lm mh lq mi lu ma mb mc md bi translated"><strong class="lb iu">ML</strong>模型的公开API应该具有节流特性，以检测攻击者是否出于恶意持续查询这些模型。想想一个IP的“失败登录”是如何触发网络安全团队的警报的</li><li id="1f73" class="lv lw it lb b lc me lf mf li mg lm mh lq mi lu ma mb mc md bi translated"><strong class="lb iu">AI和ML模型的Pen-test</strong>需要添加到常规的安全保证活动中，并开发具体的攻击案例。查看我在<a class="ae ky" href="https://infosecwriteups.com/how-to-start-penetration-testing-of-artificial-intelligence-c11e97b77dfa" rel="noopener ugc nofollow" target="_blank">和</a>的详细帖子。</li></ul><blockquote class="mj"><p id="591d" class="mk ml it bd mm mn nx ny nz oa ob lu dk translated">我希望你喜欢阅读这篇文章。如果你觉得这个话题有趣，那就去看看我的打折课程  <a class="ae ky" href="https://cloudsecguy.gumroad.com/l/aigovernance/1tojq7p?_gl=1*1c51k6t*_ga*MzQ0NDEyMjc4LjE2NDM3MTgwOTU.*_ga_6LJN6D94N6*MTY2MzA5NTE4Ni4yNzEuMS4xNjYzMDk1MTkzLjAuMC4w" rel="noopener ugc nofollow" target="_blank"> <strong class="ak"> <em class="oc">人工智能治理和网络安全</em> </strong> </a></p></blockquote><figure class="oe of og oh oi kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi od"><img src="../Images/7f2939d92bcde567dcf420cadefe2283.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*V0DMdDAie4NX19fI.png"/></div></div></figure><blockquote class="oj ok ol"><p id="2372" class="kz la nw lb b lc ld ju le lf lg jx lh om lj lk ll on ln lo lp oo lr ls lt lu im bi translated">Taimur Ijlal是一家获得多项奖项的信息安全领导者，在金融科技行业的网络安全和IT风险管理方面拥有20多年的国际经验。可以在LinkedIn 或他的博客上联系泰穆尔。他还有一个YouTube频道“<a class="ae ky" href="https://www.youtube.com/c/CloudSecurityGuy" rel="noopener ugc nofollow" target="_blank">云安全专家</a>”，在上面他定期发布关于云安全、人工智能和一般网络安全职业建议的帖子。</p><p id="d099" class="kz la nw lb b lc ld ju le lf lg jx lh om lj lk ll on ln lo lp oo lr ls lt lu im bi translated"><strong class="lb iu">如果你喜欢读这篇文章，那么考虑支持我，使用这个</strong> <a class="ae ky" href="https://taimurcloud123.medium.com/membership" rel="noopener"> <strong class="lb iu">链接</strong> </a>成为一个中等会员</p></blockquote></div></div>    
</body>
</html>