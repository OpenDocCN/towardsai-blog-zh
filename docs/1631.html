<html>
<head>
<title>NLP using Deep Learning Tutorials: Understand The “Perceptron”</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">使用深度学习教程的NLP:理解“感知机”</h1>
<blockquote>原文：<a href="https://pub.towardsai.net/nlp-using-deep-learning-tutorials-understand-the-perceptron-f2f20b324e63?source=collection_archive---------3-----------------------#2021-03-07">https://pub.towardsai.net/nlp-using-deep-learning-tutorials-understand-the-perceptron-f2f20b324e63?source=collection_archive---------3-----------------------#2021-03-07</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><h2 id="4148" class="ir is it bd b dl iu iv iw ix iy iz dk ja translated" aria-label="kicker paragraph"><a class="ae ep" href="https://towardsai.net/p/category/machine-learning/deep-learning" rel="noopener ugc nofollow" target="_blank">深度学习</a>，<a class="ae ep" href="https://towardsai.net/p/category/nlp" rel="noopener ugc nofollow" target="_blank">自然语言处理</a></h2><div class=""/><figure class="gl gn ka kb kc kd gh gi paragraph-image"><div role="button" tabindex="0" class="ke kf di kg bf kh"><div class="gh gi jz"><img src="../Images/3770a9deb884b21208ee0f187498c44f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*0NOue_j8ffzOfPAp5rVhzA.jpeg"/></div></div><figcaption class="kk kl gj gh gi km kn bd b be z dk translated">来自https://unsplash.com<a class="ae ko" href="https://unsplash.com" rel="noopener ugc nofollow" target="_blank">的免费图片</a></figcaption></figure><blockquote class="kp kq kr"><p id="0af5" class="ks kt ku kv b kw kx ky kz la lb lc ld le lf lg lh li lj lk ll lm ln lo lp lq im bi translated"><em class="it">这篇文章是我正在撰写的系列文章的一部分，在这里我将尝试解决在NLP中使用深度学习的主题。首先，我正在写一篇关于使用感知器进行文本分类的例子的文章，但我认为最好先复习一些基础知识，如激活和损失函数。</em></p></blockquote><p id="6d88" class="pw-post-body-paragraph ks kt it kv b kw kx ky kz la lb lc ld lr lf lg lh ls lj lk ll lt ln lo lp lq im bi translated">感知器是最简单的神经网络，也是最古老的网络之一。它最类似于生物神经元，因为它有输入和输出，“信号”从输入流向输出。感知器的计算图可以用下面的数学公式表示:</p><figure class="lv lw lx ly gt kd gh gi paragraph-image"><div class="gh gi lu"><img src="../Images/2fd0fc2fdb0e793d1d2223e705be7704.png" data-original-src="https://miro.medium.com/v2/resize:fit:876/format:webp/1*Npol1kCoKRzziQV8142Omg.png"/></div></figure><p id="e297" class="pw-post-body-paragraph ks kt it kv b kw kx ky kz la lb lc ld lr lf lg lh ls lj lk ll lt ln lo lp lq im bi translated"><strong class="kv jd"> <em class="ku">同:</em> </strong></p><ul class=""><li id="2c3b" class="lz ma it kv b kw kx la lb lr mb ls mc lt md lq me mf mg mh bi translated"><em class="ku"> x是输入</em></li><li id="cbe5" class="lz ma it kv b kw mi la mj lr mk ls ml lt mm lq me mf mg mh bi translated"><em class="ku"> y是输出</em></li><li id="40fc" class="lz ma it kv b kw mi la mj lr mk ls ml lt mm lq me mf mg mh bi translated"><em class="ku"> w是一组权重参数</em></li><li id="ddf6" class="lz ma it kv b kw mi la mj lr mk ls ml lt mm lq me mf mg mh bi translated"><em class="ku"> b是一个偏差参数。</em></li><li id="dd6c" class="lz ma it kv b kw mi la mj lr mk ls ml lt mm lq me mf mg mh bi translated">f是激活函数</li></ul><p id="eaf8" class="pw-post-body-paragraph ks kt it kv b kw kx ky kz la lb lc ld lr lf lg lh ls lj lk ll lt ln lo lp lq im bi translated">注意(w)和(b)是从数据中学习的，并且激活函数是根据目标输出和网络目的来定义的。</p><p id="e241" class="pw-post-body-paragraph ks kt it kv b kw kx ky kz la lb lc ld lr lf lg lh ls lj lk ll lt ln lo lp lq im bi translated">然而，一个神经网络可以有一个以上的输入，在这种情况下，我们可以使用向量来推广感知器:(x)和(w)将是向量，并且(x)和(w)的乘积被替换为点积。所以，公式保持不变。</p><p id="1ec6" class="pw-post-body-paragraph ks kt it kv b kw kx ky kz la lb lc ld lr lf lg lh ls lj lk ll lt ln lo lp lq im bi translated">为了更好地理解感知器的概念，我们还可以通过以下模式来展示它:</p><figure class="lv lw lx ly gt kd gh gi paragraph-image"><div role="button" tabindex="0" class="ke kf di kg bf kh"><div class="gh gi mn"><img src="../Images/8ff4785a1dc05b82505ba22ee9946947.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*DpOqS-oT9yCwIMdB2n_gpQ.png"/></div></div><figcaption class="kk kl gj gh gi km kn bd b be z dk translated">一个感知器模式说明了计算图形</figcaption></figure><p id="42df" class="pw-post-body-paragraph ks kt it kv b kw kx ky kz la lb lc ld lr lf lg lh ls lj lk ll lt ln lo lp lq im bi translated">最后，这是一个使用Pytorch实现的感知器:</p><figure class="lv lw lx ly gt kd"><div class="bz fp l di"><div class="mo mp l"/></div></figure><p id="067b" class="pw-post-body-paragraph ks kt it kv b kw kx ky kz la lb lc ld lr lf lg lh ls lj lk ll lt ln lo lp lq im bi translated">线性表达式“wx + b”，也称为“仿射变换”，在第12行使用模块torch.nn的“linear”类实现，该类处理权重和偏差参数。此外，我们使用“torch.sigmoid”(非线性)作为激活函数“f”。</p><h1 id="641d" class="mq mr it bd ms mt mu mv mw mx my mz na nb nc nd ne nf ng nh ni nj nk nl nm nn bi translated">结论:</h1><p id="385f" class="pw-post-body-paragraph ks kt it kv b kw no ky kz la np lc ld lr nq lg lh ls nr lk ll lt ns lo lp lq im bi translated">在本文中，我介绍了最古老的神经网络架构，即感知器。它很容易理解和实现，但与复杂的其他体系结构相比，它可以以良好的性能解决许多任务。这是我们将在我的系列文章“使用深度学习的NLP”的下一篇文章中看到的，在这篇文章中，我将介绍一个使用感知神经网络的文本情感分类器。</p><p id="d007" class="pw-post-body-paragraph ks kt it kv b kw kx ky kz la lb lc ld lr lf lg lh ls lj lk ll lt ln lo lp lq im bi translated"><strong class="kv jd">参考文献:</strong></p><ol class=""><li id="27a4" class="lz ma it kv b kw kx la lb lr mb ls mc lt md lq nt mf mg mh bi translated">《用Pytorch进行自然语言处理》一书(<a class="ae ko" href="https://www.amazon.fr/Natural-Language-Processing-Pytorch-Applications/dp/1491978236" rel="noopener ugc nofollow" target="_blank">https://www . Amazon . fr/Natural-Language-Processing-py torch-Applications/DP/1491978236</a>)</li></ol></div></div>    
</body>
</html>