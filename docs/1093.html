<html>
<head>
<title>9 Ways to Handle Missing Values in Machine Learning</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">机器学习中处理缺失值的9种方法</h1>
<blockquote>原文：<a href="https://pub.towardsai.net/9-ways-to-handle-missing-values-in-machine-learning-1bbda345699a?source=collection_archive---------3-----------------------#2020-10-28">https://pub.towardsai.net/9-ways-to-handle-missing-values-in-machine-learning-1bbda345699a?source=collection_archive---------3-----------------------#2020-10-28</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><figure class="is it gp gr iu iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi ir"><img src="../Images/31dbd330b894b2d206b4a2d27edd656a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*PUCdYJEk5go6KdAG"/></div></div><figcaption class="jc jd gj gh gi je jf bd b be z dk translated">菲利贝托·桑蒂兰在<a class="ae jg" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上拍摄的照片</figcaption></figure><h2 id="3297" class="jh ji jj bd b dl jk jl jm jn jo jp dk jq translated" aria-label="kicker paragraph"><a class="ae ep" href="https://towardsai.net/p/category/machine-learning" rel="noopener ugc nofollow" target="_blank">机器学习</a></h2><div class=""/><p id="42e4" class="pw-post-body-paragraph kp kq jj kr b ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj lk ll lm im bi ln translated">数据科学就是关于数据的。它是任何数据科学或机器学习项目的关键。在大多数情况下，当我们从不同的资源收集数据或从某个地方下载数据时，几乎有95%的可能会导致数据中缺少值。我们无法在包含缺失值的数据上分析或训练机器学习模型。这就是我们90%的时间花在数据预处理上的主要原因。有许多技术可以用来处理丢失的数据。在这篇博客中，我将分享9种处理丢失数据的方法，但首先让我们看看为什么会出现丢失数据，以及有多少类型的丢失数据。</p><h2 id="e303" class="lw lx jj bd ly lz ma dn mb mc md dp me la mf mg mh le mi mj mk li ml mm mn jp bi translated"><strong class="ak">不同类型的缺失值</strong></h2><p id="706f" class="pw-post-body-paragraph kp kq jj kr b ks mo ku kv kw mp ky kz la mq lc ld le mr lg lh li ms lk ll lm im bi translated">主要有三种类型的缺失值。</p><ol class=""><li id="f0e7" class="mt mu jj kr b ks kt kw kx la mv le mw li mx lm my mz na nb bi translated"><strong class="kr jt">完全随机缺失(MCAR): </strong>当数据为MCAR时，如果所有观测值的缺失概率相同，则变量完全随机缺失，这意味着数据缺失与数据集中任何其他观测值或缺失值之间完全没有关系。换句话说，那些丢失的数据点是数据集的随机子集。</li><li id="9162" class="mt mu jj kr b ks nc kw nd la ne le nf li ng lm my mz na nb bi translated"><strong class="kr jt">非随机缺失数据(MNAR): </strong>顾名思义它们将数据缺失和数据集中的任何其他值之间的某种关系联系起来。</li><li id="6be0" class="mt mu jj kr b ks nc kw nd la ne le nf li ng lm my mz na nb bi translated"><strong class="kr jt">随机缺失(MAR): </strong>表示数据点被遗漏的倾向与缺失数据无关，但与数据集中其他一些观察到的数据有关。</li></ol></div><div class="ab cl nh ni hx nj" role="separator"><span class="nk bw bk nl nm nn"/><span class="nk bw bk nl nm nn"/><span class="nk bw bk nl nm"/></div><div class="im in io ip iq"><p id="4d96" class="pw-post-body-paragraph kp kq jj kr b ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj lk ll lm im bi translated">数据集中缺少值的原因有很多。例如，在身高和年龄的数据集中，年龄列中会有更多的缺失值，因为女孩通常会隐藏她们的年龄。如果我们准备一个工资和经验的数据集，那么我们会有更多的工资缺失值，因为大多数男性不喜欢分享他们的工资信息。在一个更大的场景中，如准备人口、疾病、事故中死亡人数的数据，纳税人记录通常人们不愿意写下信息和隐藏真实数字。即使您从第三方资源下载数据，由于下载时文件中的一些损坏，仍然有可能丢失值。不管原因是什么，我们的数据集中有丢失的值，我们需要处理它们。让我们看看处理缺失值的9种方法。</p><blockquote class="no np nq"><p id="1605" class="kp kq nr kr b ks kt ku kv kw kx ky kz ns lb lc ld nt lf lg lh nu lj lk ll lm im bi translated"><strong class="kr jt">你可以在我的</strong> <a class="ae jg" href="https://github.com/Abhayparashar31/feature-engineering" rel="noopener ugc nofollow" target="_blank"> <strong class="kr jt"> <em class="jj"> Github资源库</em> </strong> </a> <strong class="kr jt">上找到所有的源代码。</strong></p></blockquote><blockquote class="nv"><p id="31b4" class="nw nx jj bd ny nz oa ob oc od oe lm dk translated"><strong class="ak">数据集:</strong><a class="ae jg" href="https://www.kaggle.com/c/titanic/data?select=train.csv" rel="noopener ugc nofollow" target="_blank"><strong class="ak"><em class="of">titanic . CSV</em></strong></a></p></blockquote><p id="df64" class="pw-post-body-paragraph kp kq jj kr b ks og ku kv kw oh ky kz la oi lc ld le oj lg lh li ok lk ll lm im bi translated">让我们从加载数据集并导入所有库开始。</p><figure class="ol om on oo gt iv"><div class="bz fp l di"><div class="op oq l"/></div></figure><p id="7b56" class="pw-post-body-paragraph kp kq jj kr b ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj lk ll lm im bi translated">运行上面的代码块后，您将看到年龄、客舱和上船包含空值。<strong class="kr jt"> Age包含所有的整数</strong> <strong class="kr jt">值，Cabin包含所有的分类值</strong>。</p><h1 id="91c1" class="or lx jj bd ly os ot ou mb ov ow ox me oy oz pa mh pb pc pd mk pe pf pg mn ph bi translated">1)均值/中值/模式替换</h1><p id="2301" class="pw-post-body-paragraph kp kq jj kr b ks mo ku kv kw mp ky kz la mq lc ld le mr lg lh li ms lk ll lm im bi translated">在这种技术中，我们用列中所有值的平均值/中值或众数来替换空值。<br/> <strong class="kr jt">均值:</strong> <em class="nr">所有值的平均值</em> <br/> <strong class="kr jt">中值:</strong> <em class="nr">所有值的中心值</em> <br/> <strong class="kr jt">众数:</strong> <em class="nr">最频繁值</em></p><p id="71d8" class="pw-post-body-paragraph kp kq jj kr b ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj lk ll lm im bi translated"><strong class="kr jt">优点<br/> 1。</strong>易于实现(对离群值鲁棒)<br/> 2。一种更快获得完整数据集的方法<br/> <strong class="kr jt">缺点<br/> </strong> 1 <strong class="kr jt">。</strong>原始方差的变化或扭曲<br/> 2。影响相关性<br/> 3。对于分类变量，我们需要应用模式。均值和中值都不行。</p><p id="3662" class="pw-post-body-paragraph kp kq jj kr b ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj lk ll lm im bi translated"><strong class="kr jt">的意思是</strong></p><pre class="ol om on oo gt pi pj pk pl aw pm bi"><span id="5f85" class="lw lx jj pj b gy pn po l pp pq">def impute_nan(df,column,mean):<br/>    df[column+'_mean']=df[column].fillna(mean) <strong class="pj jt">##NaN -&gt; mean</strong></span><span id="e96c" class="lw lx jj pj b gy pr po l pp pq">impute_nan(df,'Age',df.Age.mean()) <strong class="pj jt">##mean of Age(29.69)</strong></span></pre><p id="b2f8" class="pw-post-body-paragraph kp kq jj kr b ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj lk ll lm im bi translated"><strong class="kr jt">中值</strong></p><pre class="ol om on oo gt pi pj pk pl aw pm bi"><span id="f511" class="lw lx jj pj b gy pn po l pp pq">def impute_nan(df,column,median):<br/>    df[column+'_mean']=df[column].fillna(median)</span><span id="8a56" class="lw lx jj pj b gy pr po l pp pq">impute_nan(df,'Age',df.Age.median()) <strong class="pj jt">##median of Age(28.0)</strong></span></pre><p id="f596" class="pw-post-body-paragraph kp kq jj kr b ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj lk ll lm im bi translated"><strong class="kr jt">模式</strong></p><pre class="ol om on oo gt pi pj pk pl aw pm bi"><span id="c3da" class="lw lx jj pj b gy pn po l pp pq">def impute_nan(df,column,mode):<br/>    df[column+'_mean']=df[column].fillna(mode)</span><span id="1b08" class="lw lx jj pj b gy pr po l pp pq">impute_nan(df,'Age',df.Age.mode()) <strong class="pj jt">##mode of Age(24.0)</strong></span></pre><div class="ol om on oo gt ab cb"><figure class="ps iv pt pu pv pw px paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><img src="../Images/259a287df7d3c8fda20490e79255bf68.png" data-original-src="https://miro.medium.com/v2/resize:fit:672/format:webp/1*cl8OVBQwb9N3MeHVC4wItQ.png"/></div></figure><figure class="ps iv py pu pv pw px paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><img src="../Images/e1c1cb968a8f039ad6847f1121a3c81d.png" data-original-src="https://miro.medium.com/v2/resize:fit:666/format:webp/1*ElwM9LfBIe1vR54AFIu69Q.png"/></div></figure><figure class="ps iv pz pu pv pw px paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><img src="../Images/3ff8f6f948a20793f9e2f7b0fb575565.png" data-original-src="https://miro.medium.com/v2/resize:fit:664/format:webp/1*la2srpdnQYnyC0H4WlkuUQ.png"/></div><figcaption class="jc jd gj gh gi je jf bd b be z dk qa di qb qc translated">中位数vs均值vs众数</figcaption></figure></div><h1 id="ad79" class="or lx jj bd ly os ot ou mb ov ow ox me oy oz pa mh pb pc pd mk pe pf pg mn ph bi translated">2)随机样本插补</h1><p id="a5e3" class="pw-post-body-paragraph kp kq jj kr b ks mo ku kv kw mp ky kz la mq lc ld le mr lg lh li ms lk ll lm im bi translated">在这种技术中，我们用数据帧中的随机样本替换所有nan值。它用于估算数字数据。我们使用<code class="fe qd qe qf pj b">sample()</code>来获取数据的样本。在这种情况下，我们首先取一个数据样本来填充NaN值。然后改变索引并用与NaN值相同的索引替换它，最后，我们用随机样本替换所有NaN值。</p><p id="2d91" class="pw-post-body-paragraph kp kq jj kr b ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj lk ll lm im bi translated"><strong class="kr jt">优点<br/> 1。</strong>容易实现<br/> <strong class="kr jt"> 2。</strong>方差失真较小。<br/> <strong class="kr jt">缺点<br/> 1。我们不能在每种情况下都应用它</strong></p><p id="6a08" class="pw-post-body-paragraph kp kq jj kr b ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj lk ll lm im bi translated"><em class="nr">使用随机样本插补替换年龄列NaN值<br/> </em> <strong class="kr jt">代码:</strong></p><figure class="ol om on oo gt iv"><div class="bz fp l di"><div class="op oq l"/></div></figure><div class="ol om on oo gt ab cb"><figure class="ps iv qg pu pv pw px paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><img src="../Images/28e4d37ea0039ec089a515f40ba8f4c4.png" data-original-src="https://miro.medium.com/v2/resize:fit:660/format:webp/1*cl8OVBQwb9N3MeHVC4wItQ.png"/></div></figure><figure class="ps iv qh pu pv pw px paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><img src="../Images/68a1807caf3b754decb96317868083c8.png" data-original-src="https://miro.medium.com/v2/resize:fit:652/format:webp/1*la2srpdnQYnyC0H4WlkuUQ.png"/></div></figure><figure class="ps iv qi pu pv pw px paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><img src="../Images/8be8ef2cbd342caa9320dd6b9070e35a.png" data-original-src="https://miro.medium.com/v2/resize:fit:692/format:webp/1*_hOHdFcYuV_T4pCunT0fvg.png"/></div><figcaption class="jc jd gj gh gi je jf bd b be z dk qj di qk qc translated">中位数vs众数vs随机样本插补</figcaption></figure></div><h1 id="1cc4" class="or lx jj bd ly os ot ou mb ov ow ox me oy oz pa mh pb pc pd mk pe pf pg mn ph bi translated">3)用新特征捕获NAN值</h1><p id="03da" class="pw-post-body-paragraph kp kq jj kr b ks mo ku kv kw mp ky kz la mq lc ld le mr lg lh li ms lk ll lm im bi translated">当数据不是完全随机丢失时，这种技术最有效。在这种情况下，我们在数据集中添加一个新列，并用1替换所有NaN值。</p><p id="816d" class="pw-post-body-paragraph kp kq jj kr b ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj lk ll lm im bi translated"><strong class="kr jt">优势<br/> 1。</strong>容易实现<br/> <strong class="kr jt"> 2。</strong>抓住了楠价值观的重要性<br/> <strong class="kr jt">缺点<br/> 1。</strong>创建附加特征(维数灾难)</p><p id="8897" class="pw-post-body-paragraph kp kq jj kr b ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj lk ll lm im bi translated"><strong class="kr jt">代码:</strong></p><pre class="ol om on oo gt pi pj pk pl aw pm bi"><span id="ea45" class="lw lx jj pj b gy pn po l pp pq">import numpy as np<br/>df['age_nan']=np.where(df['Age'].isnull(),1,0)<br/><strong class="pj jt">## It will create one new column that contains value 1 in the rows where Age value is NaN, otherwise 0. </strong></span></pre><h1 id="aa1d" class="or lx jj bd ly os ot ou mb ov ow ox me oy oz pa mh pb pc pd mk pe pf pg mn ph bi translated">4)分发结束</h1><p id="6766" class="pw-post-body-paragraph kp kq jj kr b ks mo ku kv kw mp ky kz la mq lc ld le mr lg lh li ms lk ll lm im bi translated">在这种技术中，我们用第三个标准偏差值代替NaN值。它还用于从数据集中移除所有异常值。首先，我们使用<code class="fe qd qe qf pj b">std()</code>计算第三个标准差，然后填充值来代替NaN。<br/> <strong class="kr jt">优点<br/> 1。</strong>容易实现。<br/>2<strong class="kr jt">。</strong>抓住了错过的重要性(如果有的话)。<br/>T37】缺点<br/> 1。扭曲了变量的原始分布。<br/>2<strong class="kr jt">。</strong>若楠的数量大。它将掩盖分布中真正的异常值。<br/> <strong class="kr jt"> 3。</strong>如果NAN的数量很少，则被替换的NAN可被视为异常值，并在后续特征工程中进行预处理。</p><p id="8fc1" class="pw-post-body-paragraph kp kq jj kr b ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj lk ll lm im bi translated"><strong class="kr jt">代码:</strong></p><pre class="ol om on oo gt pi pj pk pl aw pm bi"><span id="d734" class="lw lx jj pj b gy pn po l pp pq">def impute_nan(df,variable,median,extreme):<br/>    df[variable+"_end_distribution"]=df[variable].fillna(extreme)</span><span id="07fb" class="lw lx jj pj b gy pr po l pp pq">extreme=df.Age.mean()+3*df.Age.std() ##<strong class="pj jt">73.27--&gt; 3rd std deviation </strong><br/>impute_nan(df,'Age',df.Age.median(),extreme)</span></pre><div class="ol om on oo gt ab cb"><figure class="ps iv ql pu pv pw px paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><img src="../Images/0920a77a899538ee0684a339d3082c8e.png" data-original-src="https://miro.medium.com/v2/resize:fit:626/format:webp/1*hLRH3zCL2-SHsT-woZq2qg.png"/></div></figure><figure class="ps iv qm pu pv pw px paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><img src="../Images/462b5d45bb2f614210057ccf7bd0d18e.png" data-original-src="https://miro.medium.com/v2/resize:fit:640/format:webp/1*mJqwHRg8Kei00-1ZNNjdWA.png"/></div></figure><figure class="ps iv qn pu pv pw px paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><img src="../Images/79b90b5d50e52f71429b26954c3d4cda.png" data-original-src="https://miro.medium.com/v2/resize:fit:736/format:webp/1*Pqc79WMpj98upI2yDMVGGQ.png"/></div><figcaption class="jc jd gj gh gi je jf bd b be z dk qo di qp qc translated">分布终点插补</figcaption></figure></div><h1 id="1ca5" class="or lx jj bd ly os ot ou mb ov ow ox me oy oz pa mh pb pc pd mk pe pf pg mn ph bi translated">5)任意值插补</h1><p id="872c" class="pw-post-body-paragraph kp kq jj kr b ks mo ku kv kw mp ky kz la mq lc ld le mr lg lh li ms lk ll lm im bi translated">在这种技术中，我们用一个任意值替换NaN值。该任意值不应更频繁地出现在数据集中。一般来说，我们选择最小的异常值或最后一个异常值作为任意值。</p><p id="72cd" class="pw-post-body-paragraph kp kq jj kr b ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj lk ll lm im bi translated"><strong class="kr jt">优点<br/> 1。</strong>容易实现的<br/> <strong class="kr jt"> 2。</strong>抓住了缺失的重要性，如果有一个<br/> <strong class="kr jt">缺点<br/> 1。</strong>必须手动决定该值。</p><p id="20a0" class="pw-post-body-paragraph kp kq jj kr b ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj lk ll lm im bi translated"><strong class="kr jt">代码:</strong></p><pre class="ol om on oo gt pi pj pk pl aw pm bi"><span id="d524" class="lw lx jj pj b gy pn po l pp pq">def impute_nan(df,var):<br/>    df[var+'_zero']=df[var].fillna(0) #<strong class="pj jt">Filling with 0(least outlier)</strong><br/>    df[var+'_hundred']=df[var].fillna(100) #<strong class="pj jt">Filling with 100(last)</strong></span><span id="89cb" class="lw lx jj pj b gy pr po l pp pq">impute_nan(df,'Age')</span></pre><div class="ol om on oo gt ab cb"><figure class="ps iv qq pu pv pw px paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><img src="../Images/fdff53b1df7dc654998e80c973d3b069.png" data-original-src="https://miro.medium.com/v2/resize:fit:950/format:webp/1*Kk6XYKJ4eQdLLSMq1vaqUQ.png"/></div></figure><figure class="ps iv qr pu pv pw px paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><img src="../Images/e26f9ae69057e1ecba22464af86892a1.png" data-original-src="https://miro.medium.com/v2/resize:fit:1052/format:webp/1*p6tUZugx8ITj53DUV6yBxQ.png"/></div><figcaption class="jc jd gj gh gi je jf bd b be z dk qs di qt qc translated">年龄与任意0的年龄和任意100的年龄</figcaption></figure></div><h1 id="3d1b" class="or lx jj bd ly os ot ou mb ov ow ox me oy oz pa mh pb pc pd mk pe pf pg mn ph bi translated">6)频繁的类别插补</h1><p id="d54b" class="pw-post-body-paragraph kp kq jj kr b ks mo ku kv kw mp ky kz la mq lc ld le mr lg lh li ms lk ll lm im bi translated">这种技术用于填充分类数据中缺失的值。在这里，我们用最频繁的标签替换NaN值。首先，我们找到最常用的标签，然后用它替换NaN。</p><p id="db6e" class="pw-post-body-paragraph kp kq jj kr b ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj lk ll lm im bi translated"><strong class="kr jt">优点<br/> 1。</strong>容易实现<br/> <strong class="kr jt">缺点<br/> 1。</strong>由于我们使用更频繁的标签，如果有许多n an值，它可能会以过度表示的方式使用它们。<br/> <strong class="kr jt"> 2。</strong>它扭曲了最频繁标签的关系。</p><p id="b4a8" class="pw-post-body-paragraph kp kq jj kr b ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj lk ll lm im bi translated"><strong class="kr jt">代码:</strong></p><pre class="ol om on oo gt pi pj pk pl aw pm bi"><span id="0c61" class="lw lx jj pj b gy pn po l pp pq">def impute_nan(df,variable):<br/>    most_frequent_category=df[variable].mode()[0] ##<strong class="pj jt"><em class="nr">Most Frequent</em></strong><br/>    df[variable].fillna(most_frequent_category,inplace=True) </span><span id="286c" class="lw lx jj pj b gy pr po l pp pq">for feature in ['<strong class="pj jt">Cabin</strong>']:           <em class="nr">##</em><strong class="pj jt"><em class="nr">List of Categorical Features</em></strong><br/>    impute_nan(df,feature)</span></pre><div class="ol om on oo gt ab cb"><figure class="ps iv qu pu pv pw px paragraph-image"><img src="../Images/14971e99e147a5472fede9f15b861346.png" data-original-src="https://miro.medium.com/v2/resize:fit:418/format:webp/1*hApobkEJihNxakKHoxK6DA.png"/></figure><figure class="ps iv qv pu pv pw px paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><img src="../Images/2215ae0c236d05b619994c7e54d38077.png" data-original-src="https://miro.medium.com/v2/resize:fit:1038/format:webp/1*FTCDISscpWjplqJHxYm7Rg.png"/></div></figure><figure class="ps iv qw pu pv pw px paragraph-image"><img src="../Images/8e5936cc13789aa23f0cd9aa9012a63b.png" data-original-src="https://miro.medium.com/v2/resize:fit:432/format:webp/1*vrrpr10n75iKBivhbGj_DA.png"/><figcaption class="jc jd gj gh gi je jf bd b be z dk qx di qy qc translated">客舱列的频繁类别插补</figcaption></figure></div><h1 id="4d44" class="or lx jj bd ly os ot ou mb ov ow ox me oy oz pa mh pb pc pd mk pe pf pg mn ph bi translated">7)把范畴的nan值当作一个新的范畴</h1><p id="a5a7" class="pw-post-body-paragraph kp kq jj kr b ks mo ku kv kw mp ky kz la mq lc ld le mr lg lh li ms lk ll lm im bi translated">在这种技术中，我们简单地用一个新的类别替换所有的NaN值，比如<strong class="kr jt">缺少</strong>。</p><pre class="ol om on oo gt pi pj pk pl aw pm bi"><span id="e604" class="lw lx jj pj b gy pn po l pp pq">df['Cabin']=df['Cabin'].fillna('Missing') ##<strong class="pj jt">NaN -&gt; Missing</strong></span></pre><h1 id="c997" class="or lx jj bd ly os ot ou mb ov ow ox me oy oz pa mh pb pc pd mk pe pf pg mn ph bi translated">8)使用KNN估算器</h1><p id="1d19" class="pw-post-body-paragraph kp kq jj kr b ks mo ku kv kw mp ky kz la mq lc ld le mr lg lh li ms lk ll lm im bi translated">在这项技术中，我们使用sklearn创建一个KNN估算模型，然后将该模型拟合到我们的数据中，并预测NaN值。它用于估算数值。这是一个5步的过程。</p><ol class=""><li id="4903" class="mt mu jj kr b ks kt kw kx la mv le mw li mx lm my mz na nb bi translated">创建列的列表(整数、浮点)</li><li id="c8d2" class="mt mu jj kr b ks nc kw nd la ne le nf li ng lm my mz na nb bi translated">导入估算值并确定n_neighbors。</li><li id="4187" class="mt mu jj kr b ks nc kw nd la ne le nf li ng lm my mz na nb bi translated">对数据进行拟合。</li><li id="c874" class="mt mu jj kr b ks nc kw nd la ne le nf li ng lm my mz na nb bi translated">转换数据</li><li id="d01e" class="mt mu jj kr b ks nc kw nd la ne le nf li ng lm my mz na nb bi translated">用转换后的数据创建新的数据帧。</li></ol><p id="488c" class="pw-post-body-paragraph kp kq jj kr b ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj lk ll lm im bi translated"><strong class="kr jt">优势<br/> 1。</strong>容易实现<br/> <strong class="kr jt"> 2。</strong>给出最佳结果<br/> <strong class="kr jt">缺点<br/> 1。</strong>仅适用于数值型数据</p><p id="6d41" class="pw-post-body-paragraph kp kq jj kr b ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj lk ll lm im bi translated"><strong class="kr jt">代码:</strong></p><pre class="ol om on oo gt pi pj pk pl aw pm bi"><span id="c569" class="lw lx jj pj b gy pn po l pp pq"><strong class="pj jt">#Step 1</strong><br/>num = [col for col in df.columns if df[col].dtypes != 'O']<br/><strong class="pj jt">## Step 2</strong><br/>from sklearn.impute import KNNImputer<br/>knn = KNNImputer(n_neighbors=5)<br/><strong class="pj jt">## Step 3</strong><br/>knn.fit(df[num])<br/><strong class="pj jt">## Step 4</strong><br/>knn.transform(df[num])<br/><strong class="pj jt">## Step 5</strong><br/>df2=pd.DataFrame(knn.transform(df[num]),columns=['Survived','Age'])</span></pre><h1 id="27da" class="or lx jj bd ly os ot ou mb ov ow ox me oy oz pa mh pb pc pd mk pe pf pg mn ph bi translated">9)丢弃所有NaN值</h1><p id="8475" class="pw-post-body-paragraph kp kq jj kr b ks mo ku kv kw mp ky kz la mq lc ld le mr lg lh li ms lk ll lm im bi translated">这是最容易使用和实现的技术之一。只有当NaN值小于10%时，我们才应该使用这种技术。</p><p id="f333" class="pw-post-body-paragraph kp kq jj kr b ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj lk ll lm im bi translated"><strong class="kr jt">优点:<br/> </strong> 1。易于实现<br/> 2。快速加工<strong class="kr jt"> <br/>缺点:<br/> </strong> 1。<strong class="kr jt"> </strong>巨量数据丢失</p><p id="1776" class="pw-post-body-paragraph kp kq jj kr b ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj lk ll lm im bi translated"><strong class="kr jt">代码</strong></p><pre class="ol om on oo gt pi pj pk pl aw pm bi"><span id="4720" class="lw lx jj pj b gy pn po l pp pq">df.dropna(inplace=True) ##<strong class="pj jt">Drop all the rows that contains NaN</strong></span></pre></div><div class="ab cl nh ni hx nj" role="separator"><span class="nk bw bk nl nm nn"/><span class="nk bw bk nl nm nn"/><span class="nk bw bk nl nm"/></div><div class="im in io ip iq"><h2 id="c914" class="lw lx jj bd ly lz ma dn mb mc md dp me la mf mg mh le mi mj mk li ml mm mn jp bi translated">结论</h2><p id="8a22" class="pw-post-body-paragraph kp kq jj kr b ks mo ku kv kw mp ky kz la mq lc ld le mr lg lh li ms lk ll lm im bi translated">还有更多其他处理缺失值的技术。我们的目标是找到最适合我们问题的技术，然后实现它。处理丢失的值总是一个更好的主意，但是有时我们不得不丢弃所有的值。这主要取决于数据的类型和数量。</p></div><div class="ab cl nh ni hx nj" role="separator"><span class="nk bw bk nl nm nn"/><span class="nk bw bk nl nm nn"/><span class="nk bw bk nl nm"/></div><div class="im in io ip iq"><h2 id="16a5" class="lw lx jj bd ly lz ma dn mb mc md dp me la mf mg mh le mi mj mk li ml mm mn jp bi translated">关于作者</h2><p id="25b9" class="pw-post-body-paragraph kp kq jj kr b ks mo ku kv kw mp ky kz la mq lc ld le mr lg lh li ms lk ll lm im bi translated">我是Abhay Parashar，一个迷上AI的python爱好者。我是一名计算机专业的学生。一个狂热的作家和程序员。我发布关于python，机器学习，NLP，以及更多与AI相关的文章。我也张贴不同种类的关于机器学习的端到端项目。</p></div><div class="ab cl nh ni hx nj" role="separator"><span class="nk bw bk nl nm nn"/><span class="nk bw bk nl nm nn"/><span class="nk bw bk nl nm"/></div><div class="im in io ip iq"><div class="ol om on oo gt qz"><a href="https://parasharabhay13.medium.com/different-feature-selection-techniques-f47ec43f71b8" rel="noopener follow" target="_blank"><div class="ra ab fo"><div class="rb ab rc cl cj rd"><h2 class="bd jt gy z fp re fr fs rf fu fw js bi translated">不同的特征选择技术</h2><div class="rg l"><h3 class="bd b gy z fp re fr fs rf fu fw dk translated">查找建模的最佳特征</h3></div><div class="rh l"><p class="bd b dl z fp re fr fs rf fu fw dk translated">parasharabhay13.medium.com</p></div></div><div class="ri l"><div class="rj l rk rl rm ri rn ja qz"/></div></div></a></div><h2 id="99ea" class="lw lx jj bd ly lz ma dn mb mc md dp me la mf mg mh le mi mj mk li ml mm mn jp bi translated">更多阅读</h2><p id="94e2" class="pw-post-body-paragraph kp kq jj kr b ks mo ku kv kw mp ky kz la mq lc ld le mr lg lh li ms lk ll lm im bi translated"><a class="ae jg" href="https://medium.com/10-minutes-data-science/learn-everything-about-open-cv-ed485a3007f1" rel="noopener"> <em class="nr"> OpenCV基础知识10分钟</em></a><em class="nr"><br/></em><a class="ae jg" href="https://parasharabhay13.medium.com/vgg-16-architecture-implementation-and-practical-use-e0fef1d14557" rel="noopener"><em class="nr">Vgg 16架构实现及实际使用</em></a><em class="nr"><br/></em><a class="ae jg" href="https://medium.com/swlh/basics-of-natural-language-processing-in-10-minutes-2ed51e6d5d32" rel="noopener"><em class="nr">NLP基础知识10分钟</em></a><em class="nr"><br/></em><a class="ae jg" href="https://towardsdatascience.com/build-deploy-diabetes-prediction-app-using-flask-ml-and-heroku-2de07cbd902d" rel="noopener" target="_blank"><em class="nr">糖尿病预测Web App使用Heroku</em></a><em class="nr"><br/></em><a class="ae jg" href="https://levelup.gitconnected.com/end-to-end-project-on-spam-classifier-from-training-to-deployment-fd9232cb1323" rel="noopener ugc nofollow" target="_blank"><em class="nr">端到端垃圾邮件分类器使用NLTK</em></a></p></div><div class="ab cl nh ni hx nj" role="separator"><span class="nk bw bk nl nm nn"/><span class="nk bw bk nl nm nn"/><span class="nk bw bk nl nm"/></div><div class="im in io ip iq"><p id="b792" class="pw-post-body-paragraph kp kq jj kr b ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj lk ll lm im bi translated"><strong class="kr jt">参考文献<br/></strong>【1】<a class="ae jg" href="https://www.youtube.com/user/krishnaik06" rel="noopener ugc nofollow" target="_blank">https://www.youtube.com/user/krishnaik06</a></p></div></div>    
</body>
</html>