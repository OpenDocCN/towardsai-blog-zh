<html>
<head>
<title>AnimeGAN Effect With Python</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">Python的动画效果</h1>
<blockquote>原文：<a href="https://pub.towardsai.net/animegan-effect-with-python-78225a2d75fe?source=collection_archive---------3-----------------------#2022-11-14">https://pub.towardsai.net/animegan-effect-with-python-78225a2d75fe?source=collection_archive---------3-----------------------#2022-11-14</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="f2a6" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">我将向您展示如何在您的媒体上轻松应用AnimeGAN效果，以获得漂亮的动画图片、视频或实时相机流</h2></div><figure class="ki kj kk kl gt km"><div class="bz fp l di"><div class="kn ko l"/></div></figure><p id="9d3f" class="pw-post-body-paragraph kp kq it kr b ks kt ju ku kv kw jx kx ky kz la lb lc ld le lf lg lh li lj lk im bi translated"><strong class="kr iu">您见过的最先进的数据科学路线图！附带数以千计的免费学习资源和ChatGPT集成！</strong><a class="ae ll" href="https://87v9.short.gy/K93jZA" rel="noopener ugc nofollow" target="_blank"><strong class="kr iu">https://aigents.co/learn/roadmaps/intro</strong></a></p><p id="ede6" class="pw-post-body-paragraph kp kq it kr b ks kt ju ku kv kw jx kx ky kz la lb lc ld le lf lg lh li lj lk im bi translated">在之前的教程中，我们已经介绍了如何移除背景，就像Zoom、MS Teams、Google Meet或Skype一样。此外，我们还学习了如何识别人脸，以及如何对那张脸进行面部识别。然后我们继续用纯粹的OpenCV实现了一个“铅笔”草图效果，但是当我们谈到一个真实的人的铅笔草图时，它并不完美。因此，我来到了我们将在我们的媒体上测试<a class="ae ll" href="https://github.com/TachibanaYoshino/AnimeGANv2" rel="noopener ugc nofollow" target="_blank"> AnimeGAN </a>效果，以获得美丽的动画图片、视频或实时相机流，如果你有GPU来实时处理它的话。</p><p id="1302" class="pw-post-body-paragraph kp kq it kr b ks kt ju ku kv kw jx kx ky kz la lb lc ld le lf lg lh li lj lk im bi translated">在本教程结束时，我们将能够从我们的图像中获得以下动画效果:</p><figure class="ki kj kk kl gt km gh gi paragraph-image"><div class="ab gu cl lm"><img src="../Images/8f92c58b7d8cfd5ca324fe827d43c842.png" data-original-src="https://miro.medium.com/v2/format:webp/1*rOVYeRlBZR_DckE3uxgQdw.jpeg"/></div><figcaption class="lp lq gj gh gi lr ls bd b be z dk translated">作者图片</figcaption></figure><p id="ac36" class="pw-post-body-paragraph kp kq it kr b ks kt ju ku kv kw jx kx ky kz la lb lc ld le lf lg lh li lj lk im bi translated">或者这种素描效果:</p><figure class="ki kj kk kl gt km gh gi paragraph-image"><div class="ab gu cl lm"><img src="../Images/c5d19f9915d8b6bea95768c9fbfa0515.png" data-original-src="https://miro.medium.com/v2/format:webp/1*SEIVcoa6K4zQChzLTHitLA.jpeg"/></div><figcaption class="lp lq gj gh gi lr ls bd b be z dk translated">作者图片</figcaption></figure><p id="1af6" class="pw-post-body-paragraph kp kq it kr b ks kt ju ku kv kw jx kx ky kz la lb lc ld le lf lg lh li lj lk im bi translated">像以前一样，我将为这个任务创建一个单独的对象，我将命名为<code class="fe lt lu lv lw b">animegan.py.</code>。它将与我的其他人脸检测、人脸识别、背景移除等具有相同的结构。，对象。当我们调用我们的对象时，我们给出一个返回处理过的帧的帧。以下是完整的AnimeGan对象代码:</p><figure class="ki kj kk kl gt km"><div class="bz fp l di"><div class="lx ko l"/></div></figure><p id="342a" class="pw-post-body-paragraph kp kq it kr b ks kt ju ku kv kw jx kx ky kz la lb lc ld le lf lg lh li lj lk im bi translated">在本教程中，我不打算深入这项技术，它是如何制作的，如何训练模型，等等。我的重点是向你展示使用它是多么简单。我已经将模型从TensorFlow转换为<code class="fe lt lu lv lw b">.ONNX</code>类型。它们保存在我的模型文件夹中，分别是<code class="fe lt lu lv lw b">Shinkai_53.onnx</code>、<code class="fe lt lu lv lw b">AnimeGANv3_PortraitSketch_25.onnx</code>和其他。原始权重可以从原始的<a class="ae ll" href="https://github.com/TachibanaYoshino/AnimeGANv2" rel="noopener ugc nofollow" target="_blank"> AnimeGANv2 GitHub库</a>下载。</p><p id="82e0" class="pw-post-body-paragraph kp kq it kr b ks kt ju ku kv kw jx kx ky kz la lb lc ld le lf lg lh li lj lk im bi translated">该对象用于根据官方要求处理图像的所有预处理和后处理。</p><p id="3ccb" class="pw-post-body-paragraph kp kq it kr b ks kt ju ku kv kw jx kx ky kz la lb lc ld le lf lg lh li lj lk im bi translated">好吧，但是如何使用它，你可能会问，对不对？让我们创建<code class="fe lt lu lv lw b">main.py</code>脚本，用"<code class="fe lt lu lv lw b">Shinkai_53.onnx</code>"模型对我们的图像进行推理:</p><figure class="ki kj kk kl gt km"><div class="bz fp l di"><div class="lx ko l"/></div></figure><p id="3824" class="pw-post-body-paragraph kp kq it kr b ks kt ju ku kv kw jx kx ky kz la lb lc ld le lf lg lh li lj lk im bi translated">这只有几行代码，将生成下面的动画图像:</p><figure class="ki kj kk kl gt km gh gi paragraph-image"><div class="ab gu cl lm"><img src="../Images/5edc8569b14c8cee9cb2d6d0d9f9c24c.png" data-original-src="https://miro.medium.com/v2/format:webp/1*_6sDBVibEXwIUx8-QCr1ZA.jpeg"/></div><figcaption class="lp lq gj gh gi lr ls bd b be z dk translated">作者图片</figcaption></figure><p id="7a1a" class="pw-post-body-paragraph kp kq it kr b ks kt ju ku kv kw jx kx ky kz la lb lc ld le lf lg lh li lj lk im bi translated">我不知道你怎么样，但我看不出有什么显著的不同，但肯定的是，这是不同的。</p><p id="2731" class="pw-post-body-paragraph kp kq it kr b ks kt ju ku kv kw jx kx ky kz la lb lc ld le lf lg lh li lj lk im bi translated">在官方的AnimeGANv2实现中，找到从哪里下载权重是相当困难的。因此，为了简单起见，我添加了代码描述的链接。我把它们都放在我的模型的文件夹里，我们将用我的一张哈士奇照片来测试它们；我们将选择最好的一个。以下是用于该目的的代码:</p><figure class="ki kj kk kl gt km"><div class="bz fp l di"><div class="lx ko l"/></div></figure><p id="9846" class="pw-post-body-paragraph kp kq it kr b ks kt ju ku kv kw jx kx ky kz la lb lc ld le lf lg lh li lj lk im bi translated">如果您试图向此AnimeGan模型提供高分辨率图像，可能会超出您的内存资源。如果是这样，你必须在AnimeGan对象中设置一个<code class="fe lt lu lv lw b">downsize_ratio</code>参数。但除此之外，结果相当令人兴奋。以下是每种型号的四种不同输出:您可以选择最适合您的方式:</p><figure class="ki kj kk kl gt km gh gi paragraph-image"><div class="ab gu cl lm"><img src="../Images/4b536686adeb880f8b7f597bf177be51.png" data-original-src="https://miro.medium.com/v2/format:webp/1*UeC0ePqBbGi8dPCY2xTXhA.jpeg"/></div><figcaption class="lp lq gj gh gi lr ls bd b be z dk translated">作者图片</figcaption></figure><p id="bac6" class="pw-post-body-paragraph kp kq it kr b ks kt ju ku kv kw jx kx ky kz la lb lc ld le lf lg lh li lj lk im bi translated">处理这些结果花了一些时间，而且非常耗费资源。但是尝试一下还是值得的。此外，在我的<a class="ae ll" href="https://youtu.be/UN-zTa0LNrc" rel="noopener ugc nofollow" target="_blank"> YouTube </a>视频教程中，你可能会看到我在一个实时视频流上测试了它，因为我有GPU，可以在上面运行。看看吧！</p><p id="1e5d" class="pw-post-body-paragraph kp kq it kr b ks kt ju ku kv kw jx kx ky kz la lb lc ld le lf lg lh li lj lk im bi translated">下面是几行代码，它将处理您的网络摄像头流并为您显示结果:</p><figure class="ki kj kk kl gt km"><div class="bz fp l di"><div class="lx ko l"/></div></figure><p id="ac32" class="pw-post-body-paragraph kp kq it kr b ks kt ju ku kv kw jx kx ky kz la lb lc ld le lf lg lh li lj lk im bi translated">如果你看完了我的<a class="ae ll" href="https://youtu.be/UN-zTa0LNrc" rel="noopener ugc nofollow" target="_blank"> YouTube </a>视频，你应该会看到用上面的代码，我从我的相机流中得到了相当惊人的动画效果。我对这些结果感到兴奋。</p><h1 id="09da" class="ly lz it bd ma mb mc md me mf mg mh mi jz mj ka mk kc ml kd mm kf mn kg mo mp bi translated">结论:</h1><p id="fc9c" class="pw-post-body-paragraph kp kq it kr b ks mq ju ku kv mr jx kx ky ms la lb lc mt le lf lg mu li lj lk im bi translated">尽管很难找到这种动漫效果的真实用途，但尝试一下真的很有趣。我认为最好的目的是为社交网络创建动画图像或视频，为自己或他人创造一些乐趣。但是我们了解到，它很容易实现到图像，视频，或网络摄像头流！玩得开心！</p><p id="39a9" class="pw-post-body-paragraph kp kq it kr b ks kt ju ku kv kw jx kx ky kz la lb lc ld le lf lg lh li lj lk im bi translated">感谢阅读！一如既往，本教程给出的所有代码都可以在我的<a class="ae ll" href="https://github.com/pythonlessons/background_removal" rel="noopener ugc nofollow" target="_blank"> GitHub </a>页面上找到，并且免费使用！</p></div><div class="ab cl mv mw hx mx" role="separator"><span class="my bw bk mz na nb"/><span class="my bw bk mz na nb"/><span class="my bw bk mz na"/></div><div class="im in io ip iq"><p id="d0c6" class="pw-post-body-paragraph kp kq it kr b ks kt ju ku kv kw jx kx ky kz la lb lc ld le lf lg lh li lj lk im bi translated"><em class="nc">原载于</em><a class="ae ll" href="https://pylessons.com/animegan-effect" rel="noopener ugc nofollow" target="_blank"><em class="nc">https://pylessons.com/animegan-effect</em></a></p></div></div>    
</body>
</html>