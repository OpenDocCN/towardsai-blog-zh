<html>
<head>
<title>Meta’s Data2vec is a New Self-Supervised Model that Works for Speech, Vision, and Text</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">Meta的Data2vec是一个新的自我监督模型，适用于语音、视觉和文本</h1>
<blockquote>原文：<a href="https://pub.towardsai.net/metas-data2vec-is-a-new-self-supervised-model-that-works-for-speech-vision-and-text-7a12bba0d01f?source=collection_archive---------1-----------------------#2022-01-24">https://pub.towardsai.net/metas-data2vec-is-a-new-self-supervised-model-that-works-for-speech-vision-and-text-7a12bba0d01f?source=collection_archive---------1-----------------------#2022-01-24</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><h2 id="0b48" class="ir is it bd b dl iu iv iw ix iy iz dk ja translated" aria-label="kicker paragraph"><a class="ae ep" href="https://towardsai.net/p/category/nlp" rel="noopener ugc nofollow" target="_blank">自然语言处理</a></h2><div class=""/><div class=""><h2 id="116f" class="pw-subtitle-paragraph jz jc it bd b ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq dk translated">这是第一个可以跨不同领域工作的SSL模型，是空间领域最大的突破之一。</h2></div><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi kr"><img src="../Images/f45c4b8c35f1cc2c55b28d78d366371c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*KIrJFFCxSQBTdvA2.jpg"/></div></div><figcaption class="ld le gj gh gi lf lg bd b be z dk translated">来源:<a class="ae lh" href="https://www.techslang.com/definition/what-is-self-supervised-learning/" rel="noopener ugc nofollow" target="_blank">https://www . tech slang . com/definition/what-is-self-supervised-learning/</a></figcaption></figure><blockquote class="li lj lk"><p id="8b35" class="ll lm ln lo b lp lq kd lr ls lt kg lu lv lw lx ly lz ma mb mc md me mf mg mh im bi translated">我最近创办了一份专注于人工智能的教育时事通讯，已经有超过10万名订户。《序列》是一份无废话(意思是没有炒作，没有新闻等)的ML导向时事通讯，需要5分钟阅读。目标是让你与机器学习项目、研究论文和概念保持同步。请通过订阅以下内容来尝试一下:</p></blockquote><div class="mi mj gp gr mk ml"><a href="https://thesequence.substack.com/" rel="noopener  ugc nofollow" target="_blank"><div class="mm ab fo"><div class="mn ab mo cl cj mp"><h2 class="bd jd gy z fp mq fr fs mr fu fw jc bi translated">序列</h2><div class="ms l"><h3 class="bd b gy z fp mq fr fs mr fu fw dk translated">订阅人工智能世界中最相关的项目和研究论文。受到110，000+的信任…</h3></div><div class="mt l"><p class="bd b dl z fp mq fr fs mr fu fw dk translated">thesequence.substack.com</p></div></div><div class="mu l"><div class="mv l mw mx my mu mz lb ml"/></div></div></a></div><p id="d8cd" class="pw-post-body-paragraph ll lm it lo b lp lq kd lr ls lt kg lu na lw lx ly nb ma mb mc nc me mf mg mh im bi translated">自我监督学习(SSL)是深度学习中最令人兴奋的领域之一。SSL的核心思想是开发通过观察进行学习的模型，而不依赖于大型标记数据集。这些学习动力非常类似于婴儿如何开始发展他们周围世界的表征。尽管令人兴奋，但SSL的大多数进步都局限于在非常特定的领域中掌握一项任务。这主要是因为SSL技术在计算机视觉、语音或语言等领域看起来非常不同。最近，Meta(脸书)AI Research(FAIR)推出了data2vec，这是一个SSL模型，在多个领域实现了最先进的性能。</p><p id="9032" class="pw-post-body-paragraph ll lm it lo b lp lq kd lr ls lt kg lu na lw lx ly nb ma mb mc nc me mf mg mh im bi translated">到目前为止，绝大多数SSL方法都集中在预测每个模态的特定单元上。例如，SSL语言模型针对预测句子中的下一个单词进行了优化，而SSL计算机视觉模型则专注于预测给定向量空间中的像素。结果是SSL模型已经发展成为每个特定领域的高度专门化的方法。这与人类固有的多领域认知形成强烈对比。</p><h1 id="02db" class="nd ne it bd nf ng nh ni nj nk nl nm nn ki no kj np kl nq km nr ko ns kp nt nu bi translated">Data2vec方法</h1><p id="75e1" class="pw-post-body-paragraph ll lm it lo b lp nv kd lr ls nw kg lu na nx lx ly nb ny mb mc nc nz mf mg mh im bi translated">Data2vec试图通过训练模型来消除专门化的级别，这些模型预测它们自己的数据表示，而不是预测特定的标记。通过关注表示，data2vec消除了对特定领域学习目标的依赖。</p><p id="d921" class="pw-post-body-paragraph ll lm it lo b lp lq kd lr ls lt kg lu na lw lx ly nb ma mb mc nc me mf mg mh im bi translated">公平SSL方法使用基于学生和教师网络的双重网络架构。教师网络计算文本、图像或语音的表示。学生网络获取该输出，并试图预测潜在的表示反馈给老师。这两个神经网络几乎相同。</p><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi oa"><img src="../Images/0112712f8aec700d2a087ba4cf5d175d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*NBZsCrgR-HzWwOs7"/></div></div><figcaption class="ld le gj gh gi lf lg bd b be z dk translated">来源:元人工智能研究</figcaption></figure><p id="599d" class="pw-post-body-paragraph ll lm it lo b lp lq kd lr ls lt kg lu na lw lx ly nb ma mb mc nc me mf mg mh im bi translated">FAIR团队在不同的基准上测试了data2vec。在语言领域，data2vec胜过RoBERTa等已建立的模型。</p><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi ob"><img src="../Images/a7cd430f42400fbb29c020f5cb1e948f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*eVu82PHTaKOnouPi"/></div></div><figcaption class="ld le gj gh gi lf lg bd b be z dk translated">来源:元人工智能研究</figcaption></figure><p id="8df4" class="pw-post-body-paragraph ll lm it lo b lp lq kd lr ls lt kg lu na lw lx ly nb ma mb mc nc me mf mg mh im bi translated">在计算机视觉领域，data2vec的表现优于各种最先进的模型。</p><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi ob"><img src="../Images/5d52fcfdfce99ced1f1568a0b80acbd7.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*Lk6hY5b3xPQZ9Njl"/></div></div><figcaption class="ld le gj gh gi lf lg bd b be z dk translated">来源:元人工智能研究</figcaption></figure><p id="9fba" class="pw-post-body-paragraph ll lm it lo b lp lq kd lr ls lt kg lu na lw lx ly nb ma mb mc nc me mf mg mh im bi translated">在语音领域，data2vec胜过了诸如<a class="ae lh" href="https://ai.facebook.com/blog/wav2vec-20-learning-the-structure-of-speech-from-raw-audio/" rel="noopener ugc nofollow" target="_blank"> wav2vec 2.0 </a>或<a class="ae lh" href="https://ai.facebook.com/blog/hubert-self-supervised-representation-learning-for-speech-recognition-generation-and-compression/" rel="noopener ugc nofollow" target="_blank">休伯特</a>等技术。</p><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi ob"><img src="../Images/bf4956c4b0a501f7b3969c68b0d355a1.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*JsrHeW5rHTZfnc0C"/></div></div><figcaption class="ld le gj gh gi lf lg bd b be z dk translated">来源:元人工智能研究</figcaption></figure><p id="c591" class="pw-post-body-paragraph ll lm it lo b lp lq kd lr ls lt kg lu na lw lx ly nb ma mb mc nc me mf mg mh im bi translated">Data2vec是SSL中最令人兴奋的新发展之一，它使我们更接近它最初的承诺。人类的认知不仅是自我监督的，而且是多感官的。Data2vec是第一个跨不同域验证SSL能力的模型。</p></div></div>    
</body>
</html>