<html>
<head>
<title>3D Models from Text!</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">来自文本的3D模型！</h1>
<blockquote>原文：<a href="https://pub.towardsai.net/3d-models-from-text-762673fa1fec?source=collection_archive---------2-----------------------#2022-10-16">https://pub.towardsai.net/3d-models-from-text-762673fa1fec?source=collection_archive---------2-----------------------#2022-10-16</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="adeb" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">DreamFusion解释</h2></div><blockquote class="ki kj kk"><p id="040f" class="kl km kn ko b kp kq ju kr ks kt jx ku kv kw kx ky kz la lb lc ld le lf lg lh im bi translated">最初发表于<a class="ae li" href="https://www.louisbouchard.ai/dreamfusion/" rel="noopener ugc nofollow" target="_blank"> louisbouchard.ai </a>，前两天在<a class="ae li" href="https://www.louisbouchard.ai/dreamfusion/" rel="noopener ugc nofollow" target="_blank">我的博客上读到的！</a></p></blockquote><h2 id="bcac" class="lj lk it bd ll lm ln dn lo lp lq dp lr ls lt lu lv lw lx ly lz ma mb mc md me bi translated">观看视频</h2><figure class="mf mg mh mi gt mj"><div class="bz fp l di"><div class="mk ml l"/></div></figure><p id="ae08" class="pw-post-body-paragraph kl km it ko b kp kq ju kr ks kt jx ku ls kw kx ky lw la lb lc ma le lf lg lh im bi translated">我们已经看到模型能够接受一个句子，然后<a class="ae li" href="https://youtu.be/RGBNdD3Wn-g" rel="noopener ugc nofollow" target="_blank">生成图像</a>。</p><p id="a577" class="pw-post-body-paragraph kl km it ko b kp kq ju kr ks kt jx ku ls kw kx ky lw la lb lc ma le lf lg lh im bi translated">然后，其他<a class="ae li" href="https://youtu.be/f3oXa7_SYek" rel="noopener ugc nofollow" target="_blank">方法通过学习特定的概念，如物体或特定的风格，来处理生成的图像</a>。</p><p id="7ee1" class="pw-post-body-paragraph kl km it ko b kp kq ju kr ks kt jx ku ls kw kx ky lw la lb lc ma le lf lg lh im bi translated">上周Meta发布了我报道过的<a class="ae li" href="https://youtu.be/MWwESVyHWto" rel="noopener ugc nofollow" target="_blank"> Make-A-Video model </a>，它允许你从一个文本句子生成一个短视频。结果还不完美，但自去年以来我们在该领域取得的进展令人难以置信。</p><p id="8a5f" class="pw-post-body-paragraph kl km it ko b kp kq ju kr ks kt jx ku ls kw kx ky lw la lb lc ma le lf lg lh im bi translated">本周我们又向前迈进了一步。</p><p id="586e" class="pw-post-body-paragraph kl km it ko b kp kq ju kr ks kt jx ku ls kw kx ky lw la lb lc ma le lf lg lh im bi translated">这是DreamFusion，一个新的谷歌研究模型，它可以理解一个句子，足以生成它的3D模型。</p><p id="ee50" class="pw-post-body-paragraph kl km it ko b kp kq ju kr ks kt jx ku ls kw kx ky lw la lb lc ma le lf lg lh im bi translated">你可以将此视为一个<a class="ae li" href="https://youtu.be/rdGVbPI42sA" rel="noopener ugc nofollow" target="_blank"> DALLE </a>或<a class="ae li" href="https://youtu.be/RGBNdD3Wn-g" rel="noopener ugc nofollow" target="_blank">稳定扩散</a>但在3D中。</p><p id="630e" class="pw-post-body-paragraph kl km it ko b kp kq ju kr ks kt jx ku ls kw kx ky lw la lb lc ma le lf lg lh im bi translated">多酷啊。！我们真的不能让它变得更酷。</p><p id="1ca5" class="pw-post-body-paragraph kl km it ko b kp kq ju kr ks kt jx ku ls kw kx ky lw la lb lc ma le lf lg lh im bi translated">但更令人着迷的是它是如何工作的。让我们深入研究一下。</p><figure class="mf mg mh mi gt mj gh gi paragraph-image"><div class="gh gi mm"><img src="../Images/9cdbfaa66eeb472d3167dfed6b8d61b7.png" data-original-src="https://miro.medium.com/v2/resize:fit:1024/1*CbKMz3Ify9tqzOQgZlYtag.gif"/></div><figcaption class="mp mq gj gh gi mr ms bd b be z dk translated">[……]一只扮成医生的老虎。使用DreamFusion生成的3D模型。</figcaption></figure><p id="7c59" class="pw-post-body-paragraph kl km it ko b kp kq ju kr ks kt jx ku ls kw kx ky lw la lb lc ma le lf lg lh im bi translated">如果你一直在关注我的工作，DreamFusion相当简单。</p><p id="ce0b" class="pw-post-body-paragraph kl km it ko b kp kq ju kr ks kt jx ku ls kw kx ky lw la lb lc ma le lf lg lh im bi translated">它基本上使用了我已经介绍过的两个模型:<a class="ae li" href="https://youtu.be/88Pl9zD1Z78" rel="noopener ugc nofollow" target="_blank"> NeRFs </a>和一个文本到图像模型。在他们的例子中，它是<a class="ae li" href="https://youtu.be/qhtYPhPWCsI" rel="noopener ugc nofollow" target="_blank"> Imagen模型</a>，但是任何模型都可以，比如稳定扩散。</p><p id="2924" class="pw-post-body-paragraph kl km it ko b kp kq ju kr ks kt jx ku ls kw kx ky lw la lb lc ma le lf lg lh im bi translated">如你所知，如果你是一个好学生，并且看过前面的视频，NeRFs是一种用于渲染3D场景的模型，通过从一个或多个对象图像中生成神经辐射场。</p><figure class="mf mg mh mi gt mj gh gi paragraph-image"><div class="ab gu cl mt"><img src="../Images/79a1b649a9c6a529e899bf3b1acd6543.png" data-original-src="https://miro.medium.com/v2/format:webp/1*K3MTTsjayip7_X0--zx1lg.png"/></div><figcaption class="mp mq gj gh gi mr ms bd b be z dk translated">NeRF方法。图片来自NeRF <a class="ae li" href="https://arxiv.org/pdf/2003.08934.pdf" rel="noopener ugc nofollow" target="_blank">论文</a>。</figcaption></figure><p id="b6f5" class="pw-post-body-paragraph kl km it ko b kp kq ju kr ks kt jx ku ls kw kx ky lw la lb lc ma le lf lg lh im bi translated">但是，如果NeRF模型只适用于图像，那么如何从文本生成3D渲染呢？</p><p id="8d60" class="pw-post-body-paragraph kl km it ko b kp kq ju kr ks kt jx ku ls kw kx ky lw la lb lc ma le lf lg lh im bi translated">嗯，我们使用Imagen，另一个人工智能，从想要的文本中生成图像变体！</p><p id="dd25" class="pw-post-body-paragraph kl km it ko b kp kq ju kr ks kt jx ku ls kw kx ky lw la lb lc ma le lf lg lh im bi translated">为什么我们要这样做，而不是直接从文本中生成3D模型？因为它需要巨大的3D数据集以及相关的标题来训练我们的模型，这是非常困难的。相反，我们使用一个预训练的文本到图像的模型，收集更简单的数据，并使其适应3D！所以它不需要任何3D数据来训练，只需要一个预先存在的人工智能来生成图像！当我们以不同的方式解释问题时，我们可以为这样的新任务重用强大的技术，这真的很酷。</p><p id="1e57" class="pw-post-body-paragraph kl km it ko b kp kq ju kr ks kt jx ku ls kw kx ky lw la lb lc ma le lf lg lh im bi translated">所以如果我们从头开始:我们有一个NeRF模型。</p><figure class="mf mg mh mi gt mj gh gi paragraph-image"><div role="button" tabindex="0" class="mv mw di mx bf my"><div class="gh gi mu"><img src="../Images/4b918e49762e7a768e1f57d37f17c78c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*mVM98rSoLTm7hRNJOLZ9qg.png"/></div></div><figcaption class="mp mq gj gh gi mr ms bd b be z dk translated">方法概述。图片来自DreamFusion论文。</figcaption></figure><p id="11f9" class="pw-post-body-paragraph kl km it ko b kp kq ju kr ks kt jx ku ls kw kx ky lw la lb lc ma le lf lg lh im bi translated">正如我在以前的视频中解释的那样，这种类型的模型通过图像来预测每个新视图中的像素，通过从具有不同视点的同一对象的图像对中学习来创建3D模型。在我们的例子中，我们不直接从图像开始。我们从文本开始，对我们想要生成的随机视图方向进行采样。基本上，我们试图通过生成相机可以覆盖的所有可能角度的图像，环视物体，并猜测像素的颜色、密度、光反射等来创建3D模型。让它看起来真实所需的一切。</p><p id="c3aa" class="pw-post-body-paragraph kl km it ko b kp kq ju kr ks kt jx ku ls kw kx ky lw la lb lc ma le lf lg lh im bi translated">因此，我们从一个标题开始，并根据我们想要生成的随机摄像机视点对其进行小的调整。例如，我们可能想要生成一个前视图，以便将“前视图”附加到标题上。</p><p id="acc2" class="pw-post-body-paragraph kl km it ko b kp kq ju kr ks kt jx ku ls kw kx ky lw la lb lc ma le lf lg lh im bi translated">另一方面，我们使用相同的角度和相机参数为我们的初始，未经训练，NeRF模型来预测第一次渲染。</p><figure class="mf mg mh mi gt mj gh gi paragraph-image"><a href="http://eepurl.com/huGLT5"><div class="gh gi mz"><img src="../Images/83113c87f9f921172f531320da445118.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*g9e5Resq9wOtlWDt.png"/></div></a></figure><p id="0eca" class="pw-post-body-paragraph kl km it ko b kp kq ju kr ks kt jx ku ls kw kx ky lw la lb lc ma le lf lg lh im bi translated">然后，我们使用Imagen(我们预训练的文本到图像模型)根据我们的标题和初始渲染生成一个图像版本，如果你想知道它是如何做到的，我在我的Imagen视频中进一步解释了这一点。</p><p id="0490" class="pw-post-body-paragraph kl km it ko b kp kq ju kr ks kt jx ku ls kw kx ky lw la lb lc ma le lf lg lh im bi translated">因此，我们的Imagen模型将由文本输入以及添加了噪声的对象的当前渲染来指导。这里，我们添加噪声，因为这是Imagen模型可以接受的输入。它需要成为它所理解的噪声分布的一部分。然后，我们使用该模型生成更高质量的图像。添加用于生成它的图像，并删除我们手动添加的噪声，以使用该结果来指导和改进我们的NeRF模型，以进行下一步。</p><p id="74b9" class="pw-post-body-paragraph kl km it ko b kp kq ju kr ks kt jx ku ls kw kx ky lw la lb lc ma le lf lg lh im bi translated">我们这样做是为了更好地理解NeRF模型应该将注意力集中在图像中的什么地方，以便在下一步中产生更好的结果。</p><p id="a81c" class="pw-post-body-paragraph kl km it ko b kp kq ju kr ks kt jx ku ls kw kx ky lw la lb lc ma le lf lg lh im bi translated">我们重复这一切，直到三维模型足够令人满意！</p><p id="6e43" class="pw-post-body-paragraph kl km it ko b kp kq ju kr ks kt jx ku ls kw kx ky lw la lb lc ma le lf lg lh im bi translated">然后，您可以将该模型导出到网格，并在您选择的场景中使用它！</p><figure class="mf mg mh mi gt mj gh gi paragraph-image"><div class="gh gi na"><img src="../Images/9732e66833064d79f0a998b54476b6c9.png" data-original-src="https://miro.medium.com/v2/resize:fit:1200/1*BMzycLVoUTmElQJauzg4Qg.gif"/></div></figure><p id="0708" class="pw-post-body-paragraph kl km it ko b kp kq ju kr ks kt jx ku ls kw kx ky lw la lb lc ma le lf lg lh im bi translated">在你们中的一些人问之前，不，你不必重新训练图像生成器模型——正如他们在论文中说得很好的那样:它只是充当预测图像空间编辑的冷冻评论家。</p><p id="c31c" class="pw-post-body-paragraph kl km it ko b kp kq ju kr ks kt jx ku ls kw kx ky lw la lb lc ma le lf lg lh im bi translated">瞧！</p><p id="f06e" class="pw-post-body-paragraph kl km it ko b kp kq ju kr ks kt jx ku ls kw kx ky lw la lb lc ma le lf lg lh im bi translated">这就是DreamFusion如何从文本输入生成3D渲染。如果你想对这种方法有更深入的了解，可以看看我关于NeRFs和Imagen的视频。我也邀请你阅读他们的论文，以获得更多关于这种特定方法的细节。</p><p id="4093" class="pw-post-body-paragraph kl km it ko b kp kq ju kr ks kt jx ku ls kw kx ky lw la lb lc ma le lf lg lh im bi translated">谢谢你看完整篇文章。我邀请您也观看文章顶部的视频，以查看更多示例！下周我会带着另一篇精彩的论文来看你！</p></div><div class="ab cl nb nc hx nd" role="separator"><span class="ne bw bk nf ng nh"/><span class="ne bw bk nf ng nh"/><span class="ne bw bk nf ng"/></div><div class="im in io ip iq"><h2 id="e1ec" class="lj lk it bd ll lm ln dn lo lp lq dp lr ls lt lu lv lw lx ly lz ma mb mc md me bi translated">参考</h2><p id="41cf" class="pw-post-body-paragraph kl km it ko b kp ni ju kr ks nj jx ku ls nk kx ky lw nl lb lc ma nm lf lg lh im bi translated">阅读全文:<a class="ae li" href="https://www.louisbouchard.ai/dreamfusion/" rel="noopener ugc nofollow" target="_blank">https://www.louisbouchard.ai/dreamfusion/</a>T2【Poole，b .，Jain，a .，Barron，J.T .和Mildenhall，b .，2022。DreamFusion:使用2D扩散将文本转换为3D。arXiv预印本arXiv:2209.14988。<br/>项目网站:【https://dreamfusion3d.github.io/】T4T6】我的时事通讯(一个新的人工智能应用每周向你的电子邮件解释！):<a class="ae li" href="https://www.louisbouchard.ai/newsletter/" rel="noopener ugc nofollow" target="_blank">https://www.louisbouchard.ai/newsletter/</a></p></div></div>    
</body>
</html>