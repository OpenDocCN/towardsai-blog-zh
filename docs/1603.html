<html>
<head>
<title>We Don’t Need To Worry About Overfitting Anymore</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">我们不再需要担心过度拟合</h1>
<blockquote>原文：<a href="https://pub.towardsai.net/we-dont-need-to-worry-about-overfitting-anymore-9fb31a154c81?source=collection_archive---------0-----------------------#2021-03-03">https://pub.towardsai.net/we-dont-need-to-worry-about-overfitting-anymore-9fb31a154c81?source=collection_archive---------0-----------------------#2021-03-03</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><h2 id="2e18" class="io ip iq bd b dl ir is it iu iv iw dk ix translated" aria-label="kicker paragraph"><a class="ae ep" href="https://towardsai.net/p/category/machine-learning" rel="noopener ugc nofollow" target="_blank">机器学习</a></h2><div class=""/><figure class="gl gn jx jy jz ka gh gi paragraph-image"><div role="button" tabindex="0" class="kb kc di kd bf ke"><div class="gh gi jw"><img src="../Images/cf03dc1a1ca4f94e178e2eae5ce2920c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*GM9KUapE9hpKiiHa"/></div></div><figcaption class="kh ki gj gh gi kj kk bd b be z dk translated">照片由<a class="ae kl" href="https://unsplash.com/@coopery?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText" rel="noopener ugc nofollow" target="_blank">穆罕默德·诺哈西</a>在<a class="ae kl" href="https://unsplash.com/s/photos/joy?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上拍摄</figcaption></figure><blockquote class="km kn ko"><p id="be8c" class="kp kq kr ks b kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj lk ll lm ln ij bi translated">受先前工作的启发，我们引入了一种新颖、有效的方法来同时最小化损失值和损失锐度。特别地，我们的过程，<br/>锐度感知最小化(SAM ),寻找位于具有一致低损耗的邻居<br/>罩中的参数；这个公式导致一个最小-最大优化问题，在这个问题上可以有效地执行梯度下降。我们提出的实证结果表明，SAM提高了各种基准数据集的模型泛化能力[1]</p></blockquote><p id="c4c1" class="pw-post-body-paragraph kp kq iq ks b kt ku kv kw kx ky kz la lo lc ld le lp lg lh li lq lk ll lm ln ij bi translated">来源:清晰度意识最小化论文[1]</p><p id="81d5" class="pw-post-body-paragraph kp kq iq ks b kt ku kv kw kx ky kz la lo lc ld le lp lg lh li lq lk ll lm ln ij bi translated">在深度学习中，我们使用SGD/Adam等优化算法来实现我们模型的收敛，这导致找到全局最小值，即训练数据集损失较低的点。但是几种研究如<a class="ae kl" href="https://arxiv.org/abs/1611.03530" rel="noopener ugc nofollow" target="_blank"> <em class="kr">张等人</em> </a>已经表明，许多网络可以很容易地记忆训练数据，并有能力很容易地过拟合，为了防止这个问题并增加更多的泛化，Google的研究人员发表了一篇名为Sharpness Awareness Minimization的新论文，提供了CIFAR10和其他数据集的最新结果。</p><p id="5d6f" class="pw-post-body-paragraph kp kq iq ks b kt ku kv kw kx ky kz la lo lc ld le lp lg lh li lq lk ll lm ln ij bi translated">在本文中，我们将研究为什么SAM可以实现更好的泛化，以及我们如何在Pytorch中实现SAM。</p></div><div class="ab cl lr ls hu lt" role="separator"><span class="lu bw bk lv lw lx"/><span class="lu bw bk lv lw lx"/><span class="lu bw bk lv lw"/></div><div class="ij ik il im in"><h1 id="f6b4" class="ly lz iq bd ma mb mc md me mf mg mh mi mj mk ml mm mn mo mp mq mr ms mt mu mv bi translated">山姆为什么工作！？</h1><p id="0f2e" class="pw-post-body-paragraph kp kq iq ks b kt mw kv kw kx mx kz la lo my ld le lp mz lh li lq na ll lm ln ij bi translated">在梯度下降或任何其他优化算法中，我们的目标是找到一个具有低损失值的参数</p><p id="e514" class="pw-post-body-paragraph kp kq iq ks b kt ku kv kw kx ky kz la lo lc ld le lp lg lh li lq lk ll lm ln ij bi translated">但是SAM通过将<strong class="ks ja">集中在寻找位于具有一致低损失值的邻域中的参数(而不是仅自身具有低损失值的参数)</strong>而实现了比任何其他正常优化方法更好的泛化</p><p id="c65a" class="pw-post-body-paragraph kp kq iq ks b kt ku kv kw kx ky kz la lo lc ld le lp lg lh li lq lk ll lm ln ij bi translated">由于除了计算单个参数之外，还计算邻域参数，因此与其他优化方法相比，损失情况更加平坦，这反过来增加了模型的通用性。</p><figure class="nc nd ne nf gt ka gh gi paragraph-image"><div role="button" tabindex="0" class="kb kc di kd bf ke"><div class="gh gi nb"><img src="../Images/fee08255327fdc485337bdfac6b324a3.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*zmW0sFpRHjhIQc6XvKf98Q.jpeg"/></div></div><figcaption class="kh ki gj gh gi kj kk bd b be z dk translated">(左))用SGD训练的ResNet收敛到的锐最小值。(右)与SAM一起训练的ResNet收敛到的宽最小值。图片来源:<a class="ae kl" href="https://arxiv.org/pdf/2010.01412.pdf" rel="noopener ugc nofollow" target="_blank">山姆纸</a> [1]</figcaption></figure><p id="0974" class="pw-post-body-paragraph kp kq iq ks b kt ku kv kw kx ky kz la lo lc ld le lp lg lh li lq lk ll lm ln ij bi translated"><em class="kr">注意:SAM不是一个新的优化器，它与任何其他常见的优化器一起使用，如SGD/Adam </em></p></div><div class="ab cl lr ls hu lt" role="separator"><span class="lu bw bk lv lw lx"/><span class="lu bw bk lv lw lx"/><span class="lu bw bk lv lw"/></div><div class="ij ik il im in"><h1 id="de30" class="ly lz iq bd ma mb mc md me mf mg mh mi mj mk ml mm mn mo mp mq mr ms mt mu mv bi translated">在Pytorch中实现SAM:</h1><p id="143e" class="pw-post-body-paragraph kp kq iq ks b kt mw kv kw kx mx kz la lo my ld le lp mz lh li lq na ll lm ln ij bi translated">在Pytorch中实现SAM非常简单明了</p><figure class="nc nd ne nf gt ka"><div class="bz fp l di"><div class="ng nh l"/></div><figcaption class="kh ki gj gh gi kj kk bd b be z dk translated">代码取自非官方的Pytorch实现[2]</figcaption></figure><p id="892d" class="pw-post-body-paragraph kp kq iq ks b kt ku kv kw kx ky kz la lo lc ld le lp lg lh li lq lk ll lm ln ij bi translated">代码解释，</p><ul class=""><li id="5322" class="ni nj iq ks b kt ku kx ky lo nk lp nl lq nm ln nn no np nq bi translated">首先，我们从Pytorch的optimizer类继承来创建一个优化器，虽然SAM不是一个新的优化器，但是为了在每一步更新梯度(在基本优化器的帮助下),我们需要继承那个类</li><li id="2055" class="ni nj iq ks b kt nr kx ns lo nt lp nu lq nv ln nn no np nq bi translated">该类接受模型参数、基本优化器和rho，rho是用于计算最大损失的邻域的大小</li><li id="e3e9" class="ni nj iq ks b kt nr kx ns lo nt lp nu lq nv ln nn no np nq bi translated">在进入下一步之前，让我们先看看文中提到的伪代码，这将有助于我们在没有数学知识的情况下理解上面的代码。</li></ul><figure class="nc nd ne nf gt ka gh gi paragraph-image"><div role="button" tabindex="0" class="kb kc di kd bf ke"><div class="gh gi nw"><img src="../Images/8577c8f32a92b92ce9fa299638fc0c5b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*h8ft8a59pvB5uVZIUhJkTQ.jpeg"/></div></div><figcaption class="kh ki gj gh gi kj kk bd b be z dk translated">图片来源:<a class="ae kl" href="https://arxiv.org/pdf/2010.01412.pdf" rel="noopener ugc nofollow" target="_blank">山姆论文【1】</a></figcaption></figure><ul class=""><li id="d0aa" class="ni nj iq ks b kt ku kx ky lo nk lp nl lq nm ln nn no np nq bi translated">正如我们在伪代码中看到的，在计算第一次反向传递后，我们计算ε并将其添加到参数中，这些步骤在上述python代码的方法<em class="kr"> first_step </em>中实现</li><li id="da77" class="ni nj iq ks b kt nr kx ns lo nt lp nu lq nv ln nn no np nq bi translated">现在，在计算完第一步之后，我们必须回到之前的权重，以计算基本优化器的实际步骤，这些步骤在函数<em class="kr"> second_step </em>中实现</li><li id="0831" class="ni nj iq ks b kt nr kx ns lo nt lp nu lq nv ln nn no np nq bi translated">函数<em class="kr"> _grad_norm </em>用于返回矩阵向量的范数，如伪代码的第10行所示</li><li id="dccb" class="ni nj iq ks b kt nr kx ns lo nt lp nu lq nv ln nn no np nq bi translated">构建了这个类之后，你可以简单地使用它来完成你的深度学习项目，只需按照下面训练函数中的代码片段。</li></ul><figure class="nc nd ne nf gt ka"><div class="bz fp l di"><div class="ng nh l"/></div><figcaption class="kh ki gj gh gi kj kk bd b be z dk translated">代码取自非官方的Pytorch实现[2]</figcaption></figure></div><div class="ab cl lr ls hu lt" role="separator"><span class="lu bw bk lv lw lx"/><span class="lu bw bk lv lw lx"/><span class="lu bw bk lv lw"/></div><div class="ij ik il im in"><h1 id="9508" class="ly lz iq bd ma mb mc md me mf mg mh mi mj mk ml mm mn mo mp mq mr ms mt mu mv bi translated">整理想法:</h1><p id="a9ac" class="pw-post-body-paragraph kp kq iq ks b kt mw kv kw kx mx kz la lo my ld le lp mz lh li lq na ll lm ln ij bi translated">虽然SAM实现了更好的泛化，但是这种方法的主要缺点是，它需要两倍的训练时间，因为它计算两次向前和向后传递来计算锐度感知梯度。除此之外，SAM还在最近发布的NFNETS上证明了它的效果，这是ImageNet的当前技术状态，在未来，我们可以期待越来越多的论文利用这种技术来实现更好的推广。</p><p id="4f2e" class="pw-post-body-paragraph kp kq iq ks b kt ku kv kw kx ky kz la lo lc ld le lp lg lh li lq lk ll lm ln ij bi translated">如果你喜欢这篇文章或者有任何问题，请随时联系我</p></div><div class="ab cl lr ls hu lt" role="separator"><span class="lu bw bk lv lw lx"/><span class="lu bw bk lv lw lx"/><span class="lu bw bk lv lw"/></div><div class="ij ik il im in"><h1 id="1b39" class="ly lz iq bd ma mb mc md me mf mg mh mi mj mk ml mm mn mo mp mq mr ms mt mu mv bi translated">参考资料:</h1><p id="80b7" class="pw-post-body-paragraph kp kq iq ks b kt mw kv kw kx mx kz la lo my ld le lp mz lh li lq na ll lm ln ij bi translated">[1] <a class="ae kl" href="https://arxiv.org/abs/2010.01412" rel="noopener ugc nofollow" target="_blank">有效提高泛化能力的清晰度感知最小化</a></p><p id="63fa" class="pw-post-body-paragraph kp kq iq ks b kt ku kv kw kx ky kz la lo lc ld le lp lg lh li lq lk ll lm ln ij bi translated">[2]<a class="ae kl" href="https://github.com/moskomule/sam.pytorch" rel="noopener ugc nofollow" target="_blank">Hataya Ryu Ichiro的SAM非正式实现</a></p></div></div>    
</body>
</html>