<html>
<head>
<title>Car Brand Classification in Deep Learning with Python</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">基于Python深度学习的汽车品牌分类</h1>
<blockquote>原文：<a href="https://pub.towardsai.net/car-brand-classification-in-deep-learning-with-python-d08c54add941?source=collection_archive---------1-----------------------#2021-05-19">https://pub.towardsai.net/car-brand-classification-in-deep-learning-with-python-d08c54add941?source=collection_archive---------1-----------------------#2021-05-19</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><h2 id="36da" class="ir is it bd b dl iu iv iw ix iy iz dk ja translated" aria-label="kicker paragraph"><a class="ae ep" href="https://towardsai.net/p/category/machine-learning/deep-learning" rel="noopener ugc nofollow" target="_blank">深度学习</a></h2><div class=""/><div class=""><h2 id="1762" class="pw-subtitle-paragraph jz jc it bd b ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq dk translated">使用Keras迁移学习VGG16和Resnet 50</h2></div><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi kr"><img src="../Images/077726077e7448270077876b00f13418.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*pHol5iPZWnDA9ECp"/></div></div><figcaption class="ld le gj gh gi lf lg bd b be z dk translated">照片由<a class="ae lh" href="https://unsplash.com/@teslafans?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">在<a class="ae lh" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上击败Jau </a></figcaption></figure><h2 id="7dd4" class="li lj it bd lk ll lm dn ln lo lp dp lq lr ls lt lu lv lw lx ly lz ma mb mc iz bi translated">介绍</h2><p id="7ef8" class="pw-post-body-paragraph md me it mf b mg mh kd mi mj mk kg ml lr mm mn mo lv mp mq mr lz ms mt mu mv im bi translated">在本文中，我们将使用三个品牌的汽车图像实现汽车品牌分类:梅赛德斯、奥迪和兰博基尼。</p><p id="7671" class="pw-post-body-paragraph md me it mf b mg mw kd mi mj mx kg ml lr my mn mo lv mz mq mr lz na mt mu mv im bi translated">VGG-16是一个16层深度卷积神经网络，可以将图像分为1000个对象类别。</p><p id="ed09" class="pw-post-body-paragraph md me it mf b mg mw kd mi mj mx kg ml lr my mn mo lv mz mq mr lz na mt mu mv im bi translated">该数据集包括用于品牌分类的汽车图像。这里，我们有两个文件夹，即train和test，每个文件夹都有三个名为兰博基尼、奥迪和奔驰的文件夹。</p><p id="036b" class="pw-post-body-paragraph md me it mf b mg mw kd mi mj mx kg ml lr my mn mo lv mz mq mr lz na mt mu mv im bi translated">我在这里使用迁移学习是因为它非常有用，因为大多数现实世界的问题通常没有数百万个标记的数据点来训练如此复杂的模型。</p><p id="16d0" class="pw-post-body-paragraph md me it mf b mg mw kd mi mj mx kg ml lr my mn mo lv mz mq mr lz na mt mu mv im bi translated">现在让我们导入所有需要的库</p><p id="2edf" class="pw-post-body-paragraph md me it mf b mg mw kd mi mj mx kg ml lr my mn mo lv mz mq mr lz na mt mu mv im bi translated">在这里，我们使用Keras，因为它支持深度神经网络的快速实验。我们将在Resnet 50的帮助下建立我们的模型，因为它可以训练具有许多层的深度神经网络。</p><p id="61ee" class="pw-post-body-paragraph md me it mf b mg mw kd mi mj mx kg ml lr my mn mo lv mz mq mr lz na mt mu mv im bi translated">我们需要从现有的训练样本中创建新的训练样本，这个过程称为图像增强。这可以使用图像数据生成器来执行。</p><p id="b477" class="pw-post-body-paragraph md me it mf b mg mw kd mi mj mx kg ml lr my mn mo lv mz mq mr lz na mt mu mv im bi translated">使用的数据集可以从这里下载:<a class="ae lh" href="https://www.kaggle.com/ritesh2000/car-brand-images-dataset" rel="noopener ugc nofollow" target="_blank">汽车品牌图片数据集| Kaggle </a></p><pre class="ks kt ku kv gt nb nc nd ne aw nf bi"><span id="e1a9" class="li lj it nc b gy ng nh l ni nj"><strong class="nc jd"># import the required libraries</strong></span><span id="d4ef" class="li lj it nc b gy nk nh l ni nj">from tensorflow.keras.layers import Input, Lambda, Dense, Flatten<br/>from tensorflow.keras.models import Model<br/>from tensorflow.keras.applications.resnet50 import ResNet50</span><span id="669d" class="li lj it nc b gy nk nh l ni nj"><em class="nl">#import VGG16<br/></em>from tensorflow.keras.applications.resnet50 <br/>import preprocess_input<br/>from tensorflow.keras.preprocessing import image<br/>from tensorflow.keras.preprocessing.image import<br/>                                ImageDataGenerator,load_img</span><span id="693a" class="li lj it nc b gy nk nh l ni nj">from tensorflow.keras.models import Sequential</span><span id="d068" class="li lj it nc b gy nk nh l ni nj">import numpy as np<br/>import matplotlib.pyplot as plt</span><span id="94b8" class="li lj it nc b gy nk nh l ni nj">from glob import glob</span></pre><p id="3cae" class="pw-post-body-paragraph md me it mf b mg mw kd mi mj mx kg ml lr my mn mo lv mz mq mr lz na mt mu mv im bi translated">将所有图像的大小调整为[224，224]并创建一个包含两个独立文件夹的目录，分别命名为train和test。这些文件夹将包含分类所需的汽车图像。</p><pre class="ks kt ku kv gt nb nc nd ne aw nf bi"><span id="1adf" class="li lj it nc b gy ng nh l ni nj"><em class="nl"># re-size all the images to this</em></span><span id="2d27" class="li lj it nc b gy nk nh l ni nj">IMAGE_SIZE = [224, 224]</span><span id="387e" class="li lj it nc b gy nk nh l ni nj">train_path = 'Datasets/train'<br/>valid_path = 'Datasets/test'</span></pre><p id="d521" class="pw-post-body-paragraph md me it mf b mg mw kd mi mj mx kg ml lr my mn mo lv mz mq mr lz na mt mu mv im bi translated">我们使用imagenet权重，因为不需要从头开始训练神经网络。</p><pre class="ks kt ku kv gt nb nc nd ne aw nf bi"><span id="8c35" class="li lj it nc b gy ng nh l ni nj"><em class="nl"># Use imagenet weights</em></span><span id="50b3" class="li lj it nc b gy nk nh l ni nj">resnet = ResNet50(input_shape=IMAGE_SIZE + [3], weights='imagenet',<br/>                  include_top=<strong class="nc jd">False</strong>)</span></pre><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi nm"><img src="../Images/cd4ffc95ee3846e8f4ff1142c1179916.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*MSaMdnlLg-eXDaloEy4Uhg.png"/></div></div><figcaption class="ld le gj gh gi lf lg bd b be z dk translated">作者的照片</figcaption></figure><p id="48a5" class="pw-post-body-paragraph md me it mf b mg mw kd mi mj mx kg ml lr my mn mo lv mz mq mr lz na mt mu mv im bi translated">这里我们使用Resnet是因为Resnet<strong class="mf jd"><em class="nl"/></strong>的根本突破是，它允许我们成功地训练具有150+层的极深度神经网络。</p><pre class="ks kt ku kv gt nb nc nd ne aw nf bi"><span id="0f06" class="li lj it nc b gy ng nh l ni nj"><em class="nl"># don't train existing weights</em></span><span id="ca65" class="li lj it nc b gy nk nh l ni nj"><strong class="nc jd">for</strong> layer <strong class="nc jd">in</strong> resnet.layers:<br/>    layer.trainable = <strong class="nc jd">False</strong></span><span id="d721" class="li lj it nc b gy nk nh l ni nj"><em class="nl"># This helps to get number of output classes<br/></em>folders = glob('Datasets/train/*')</span><span id="ac7c" class="li lj it nc b gy nk nh l ni nj"><em class="nl"># Our Layers<br/></em>x = Flatten()(resnet.output)</span><span id="cf72" class="li lj it nc b gy nk nh l ni nj">prediction = Dense(len(folders), activation='softmax')(x)</span><span id="6de6" class="li lj it nc b gy nk nh l ni nj"><em class="nl"># creating object model</em></span><span id="b6d7" class="li lj it nc b gy nk nh l ni nj">model = Model(inputs=resnet.input, outputs=prediction)<br/>model.summary()</span></pre><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi nn"><img src="../Images/7ff3bb6f1275f525416e72ec37707158.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*hOVqME92PVTdcqr0ilzO1g.png"/></div></div><figcaption class="ld le gj gh gi lf lg bd b be z dk translated">模型总结。作者的照片</figcaption></figure><p id="4229" class="pw-post-body-paragraph md me it mf b mg mw kd mi mj mx kg ml lr my mn mo lv mz mq mr lz na mt mu mv im bi translated">这里我们使用的是<em class="nl">分类交叉熵</em>是一个损失函数，用于多类分类任务。</p><pre class="ks kt ku kv gt nb nc nd ne aw nf bi"><span id="8618" class="li lj it nc b gy ng nh l ni nj"><em class="nl"># compile the model</em></span><span id="805e" class="li lj it nc b gy nk nh l ni nj">model.compile(loss='categorical_crossentropy', optimizer='adam',<br/>              metrics=['accuracy'])</span><span id="3326" class="li lj it nc b gy nk nh l ni nj"><em class="nl"># Using the Image Data Generator</em></span><span id="c338" class="li lj it nc b gy nk nh l ni nj"><strong class="nc jd">from</strong> <strong class="nc jd">tensorflow.keras.preprocessing.image</strong> <strong class="nc jd">import</strong> ImageDataGenerator</span><span id="2f22" class="li lj it nc b gy nk nh l ni nj">train_datagen = ImageDataGenerator(rescale = 1./255, shear_range =<br/>                      0.2, zoom_range = 0.2, horizontal_flip = <strong class="nc jd">True</strong>)</span><span id="f5cf" class="li lj it nc b gy nk nh l ni nj">test_datagen = ImageDataGenerator(rescale = 1./255)</span><span id="e036" class="li lj it nc b gy nk nh l ni nj">training_set = train_datagen.flow_from_directory('Datasets/train',<br/>                                         target_size = (224, 224),<br/>                                         batch_size = 32,<br/>                                         class_mode = 'categorical')</span><span id="4c50" class="li lj it nc b gy nk nh l ni nj">#output:<br/>Found 64 images belonging to 3 classes.<br/></span><span id="4059" class="li lj it nc b gy nk nh l ni nj">test_set = test_datagen.flow_from_directory(‘Datasets/test’,<br/>                                        target_size = (224, 224),<br/>                                        batch_size = 32,<br/>                                        class_mode = ‘categorical’)</span><span id="c4d9" class="li lj it nc b gy nk nh l ni nj">#output:<br/>Found 58 images belonging to 3 classes.</span><span id="d0e4" class="li lj it nc b gy nk nh l ni nj"><em class="nl"># fit the model</em></span><span id="6511" class="li lj it nc b gy nk nh l ni nj">r = model.fit_generator(training_set, validation_data=test_set,<br/>                       epochs=50, steps_per_epoch=len(training_set),<br/>                       validation_steps=len(test_set))</span></pre><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi no"><img src="../Images/a205f99dda895f1128ab790e6ae2b95f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*767CzYIXTJkg3hZYescGzg.png"/></div></div><figcaption class="ld le gj gh gi lf lg bd b be z dk translated">模型的训练。作者的照片</figcaption></figure><div class="np nq gp gr nr ns"><a rel="noopener  ugc nofollow" target="_blank" href="/bitcoin-price-prediction-with-rnn-and-lstm-in-python-f912d57c483e"><div class="nt ab fo"><div class="nu ab nv cl cj nw"><h2 class="bd jd gy z fp nx fr fs ny fu fw jc bi translated">用Python实现RNN和LSTM的比特币价格预测</h2><div class="nz l"><h3 class="bd b gy z fp nx fr fs ny fu fw dk translated">使用深度学习预测比特币价格</h3></div><div class="oa l"><p class="bd b dl z fp nx fr fs ny fu fw dk translated">pub.towardsai.net</p></div></div><div class="ob l"><div class="oc l od oe of ob og lb ns"/></div></div></a></div><p id="957f" class="pw-post-body-paragraph md me it mf b mg mw kd mi mj mx kg ml lr my mn mo lv mz mq mr lz na mt mu mv im bi translated">现在，绘制损失图</p><pre class="ks kt ku kv gt nb nc nd ne aw nf bi"><span id="fc47" class="li lj it nc b gy ng nh l ni nj"><em class="nl"># ploting the loss</em></span><span id="f500" class="li lj it nc b gy nk nh l ni nj">plt.plot(r.history['loss'], label='train loss')<br/>plt.plot(r.history['val_loss'], label='val loss')<br/>plt.legend()<br/>plt.show()<br/>plt.savefig('LossVal_loss')</span><span id="2d2a" class="li lj it nc b gy nk nh l ni nj"><em class="nl"># ploting the accuracy</em></span><span id="78d8" class="li lj it nc b gy nk nh l ni nj">plt.plot(r.history['accuracy'], label='train acc')<br/>plt.plot(r.history['val_accuracy'], label='val acc')<br/>plt.legend()<br/>plt.show()<br/>plt.savefig('AccVal_acc')</span></pre><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi oh"><img src="../Images/d1763870b0962850c9751d90e8785d70.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*qL60Rt2EwxqPVR5If-_jsw.png"/></div></div><figcaption class="ld le gj gh gi lf lg bd b be z dk translated">损失和准确度图。作者的照片</figcaption></figure><p id="74bc" class="pw-post-body-paragraph md me it mf b mg mw kd mi mj mx kg ml lr my mn mo lv mz mq mr lz na mt mu mv im bi translated">从上面的图中，我们可以推断验证损失高于训练损失，训练精度高于验证精度。</p><p id="bba3" class="pw-post-body-paragraph md me it mf b mg mw kd mi mj mx kg ml lr my mn mo lv mz mq mr lz na mt mu mv im bi translated">现在我们需要以h5文件格式保存我们的模型，以便进一步测试模型。</p><pre class="ks kt ku kv gt nb nc nd ne aw nf bi"><span id="0251" class="li lj it nc b gy ng nh l ni nj"><em class="nl"># </em>save it as a h5 file</span><span id="6276" class="li lj it nc b gy nk nh l ni nj"><strong class="nc jd">from</strong> <strong class="nc jd">tensorflow.keras.models</strong> <strong class="nc jd">import</strong> load_model<br/>model.save('model_resnet50.h5')</span></pre><p id="3ea8" class="pw-post-body-paragraph md me it mf b mg mw kd mi mj mx kg ml lr my mn mo lv mz mq mr lz na mt mu mv im bi translated">加载模型后，让我们对测试集进行预测。</p><pre class="ks kt ku kv gt nb nc nd ne aw nf bi"><span id="0cd6" class="li lj it nc b gy ng nh l ni nj">y_pred = model.predict(test_set)<br/>y_pred</span></pre><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div class="gh gi oi"><img src="../Images/5fc2d3c838ef7cb8ec65445a4bf8c68c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1134/format:webp/1*Ux9JkCeSvXzum1kIyldeaA.png"/></div><figcaption class="ld le gj gh gi lf lg bd b be z dk translated">预测值。作者的照片</figcaption></figure><p id="8a74" class="pw-post-body-paragraph md me it mf b mg mw kd mi mj mx kg ml lr my mn mo lv mz mq mr lz na mt mu mv im bi translated">这里使用Np.argmax()从数组中获取最大元素的索引。</p><pre class="ks kt ku kv gt nb nc nd ne aw nf bi"><span id="5456" class="li lj it nc b gy ng nh l ni nj">y_pred = np.argmax(y_pred, axis=1)<br/>y_pred</span></pre><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div class="gh gi oj"><img src="../Images/403d2e41d394cd87c0c2804f189edfd3.png" data-original-src="https://miro.medium.com/v2/resize:fit:1202/format:webp/1*IM52ShQuZb6n2Yae2U8rIw.png"/></div><figcaption class="ld le gj gh gi lf lg bd b be z dk translated">作者的照片</figcaption></figure><pre class="ks kt ku kv gt nb nc nd ne aw nf bi"><span id="6664" class="li lj it nc b gy ng nh l ni nj"><strong class="nc jd">from</strong> <strong class="nc jd">tensorflow.keras.models</strong> <strong class="nc jd">import</strong> load_model</span><span id="2e50" class="li lj it nc b gy nk nh l ni nj">#Load the h5 file in the model<br/>model=load_model('model_resnet50.h5')</span></pre><p id="f4eb" class="pw-post-body-paragraph md me it mf b mg mw kd mi mj mx kg ml lr my mn mo lv mz mq mr lz na mt mu mv im bi translated">现在，我们将在来自测试数据的任意随机图像上测试该模型。</p><pre class="ks kt ku kv gt nb nc nd ne aw nf bi"><span id="b978" class="li lj it nc b gy ng nh l ni nj">img=image.load_img('Datasets/Test/lamborghini/11.jpg',target_size=<br/>                    (224,224))</span><span id="b5c8" class="li lj it nc b gy nk nh l ni nj">x=image.img_to_array(img)<br/>x</span></pre><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div class="gh gi ok"><img src="../Images/6a0feb4b6bee1599c3908b091b6cc295.png" data-original-src="https://miro.medium.com/v2/resize:fit:646/format:webp/1*akaxp4a0NVWZ2NLpWQLhcA.png"/></div><figcaption class="ld le gj gh gi lf lg bd b be z dk translated">作者的照片</figcaption></figure><pre class="ks kt ku kv gt nb nc nd ne aw nf bi"><span id="4e6b" class="li lj it nc b gy ng nh l ni nj">#Shape of the image<br/>x.shape</span><span id="3814" class="li lj it nc b gy nk nh l ni nj">#output:<br/>(224, 224, 3)</span><span id="eba2" class="li lj it nc b gy nk nh l ni nj">#Normalizing the image pixels values<br/>x=x/255</span><span id="04c6" class="li lj it nc b gy nk nh l ni nj">#Expand the Dimensions of the image</span><span id="f922" class="li lj it nc b gy nk nh l ni nj">x=np.expand_dims(x,axis=0)<br/>img_data=preprocess_input(x)<br/>img_data.shape</span><span id="fc2e" class="li lj it nc b gy nk nh l ni nj">#output:<br/>(1, 224, 224, 3)</span></pre><p id="cc49" class="pw-post-body-paragraph md me it mf b mg mw kd mi mj mx kg ml lr my mn mo lv mz mq mr lz na mt mu mv im bi translated">现在，让我们对img_data执行预测</p><pre class="ks kt ku kv gt nb nc nd ne aw nf bi"><span id="ff40" class="li lj it nc b gy ng nh l ni nj">model.predict(img_data)</span><span id="0e54" class="li lj it nc b gy nk nh l ni nj">#output:<br/>array([[0.01513638, 0.01566849, 0.9691952 ]], dtype=float32)</span><span id="7825" class="li lj it nc b gy nk nh l ni nj">a=np.argmax(model.predict(img_data), axis=1)<br/>a==1</span><span id="3a06" class="li lj it nc b gy nk nh l ni nj">#output:<br/>array([ True])</span></pre><p id="912c" class="pw-post-body-paragraph md me it mf b mg mw kd mi mj mx kg ml lr my mn mo lv mz mq mr lz na mt mu mv im bi translated">这就是我们如何对数据集进行图像分类。</p><h2 id="251c" class="li lj it bd lk ll lm dn ln lo lp dp lq lr ls lt lu lv lw lx ly lz ma mb mc iz bi translated">结论:</h2><p id="667a" class="pw-post-body-paragraph md me it mf b mg mh kd mi mj mk kg ml lr mm mn mo lv mp mq mr lz ms mt mu mv im bi translated">本文给出了一种实用的汽车品牌图像分类方法。该模型可以通过使用“<strong class="mf jd"><em class="nl">【H5】</em></strong>文件来预测汽车品牌。</p><p id="8b47" class="pw-post-body-paragraph md me it mf b mg mw kd mi mj mx kg ml lr my mn mo lv mz mq mr lz na mt mu mv im bi translated">我希望你喜欢这篇文章。通过我的<a class="ae lh" href="https://www.linkedin.com/in/data-scientist-95040a1ab/" rel="noopener ugc nofollow" target="_blank"> LinkedIn </a>和<a class="ae lh" href="https://twitter.com/amitprius" rel="noopener ugc nofollow" target="_blank"> twitter </a>联系我。</p><h1 id="0257" class="ol lj it bd lk om on oo ln op oq or lq ki os kj lu kl ot km ly ko ou kp mc ov bi translated">推荐文章</h1><p id="bf2e" class="pw-post-body-paragraph md me it mf b mg mh kd mi mj mk kg ml lr mm mn mo lv mp mq mr lz ms mt mu mv im bi translated"><a class="ae lh" href="https://medium.com/towards-artificial-intelligence/nlp-zero-to-hero-with-python-2df6fcebff6e?sk=2231d868766e96b13d1e9d7db6064df1" rel="noopener"> 1。NLP —零到英雄与Python </a> <br/> 2。<a class="ae lh" href="https://medium.com/towards-artificial-intelligence/python-data-structures-data-types-and-objects-244d0a86c3cf?sk=42f4b462499f3fc3a160b21e2c94dba6" rel="noopener"> Python数据结构数据类型和对象</a>T5】3 .<a class="ae lh" rel="noopener ugc nofollow" target="_blank" href="/exception-handling-concepts-in-python-4d5116decac3?source=friends_link&amp;sk=a0ed49d9fdeaa67925eac34ecb55ea30">Python中的异常处理概念</a> <br/> 4。<a class="ae lh" rel="noopener ugc nofollow" target="_blank" href="/deep-learning-88e218b74a14?source=friends_link&amp;sk=540bf9088d31859d50dbddab7524ba35">为什么LSTM在深度学习方面比RNN更有用？</a> <br/> 5。<a class="ae lh" rel="noopener ugc nofollow" target="_blank" href="/neural-networks-the-rise-of-recurrent-neural-networks-df740252da88?source=friends_link&amp;sk=6844935e3de14e478ce00f0b22e419eb">神经网络:递归神经网络的兴起</a> <br/> 6。<a class="ae lh" href="https://medium.com/towards-artificial-intelligence/fully-explained-linear-regression-with-python-fe2b313f32f3?source=friends_link&amp;sk=53c91a2a51347ec2d93f8222c0e06402" rel="noopener">用Python </a> <br/> 7全面讲解了线性回归。<a class="ae lh" href="https://medium.com/towards-artificial-intelligence/fully-explained-logistic-regression-with-python-f4a16413ddcd?source=friends_link&amp;sk=528181f15a44e48ea38fdd9579241a78" rel="noopener">用Python </a> <br/>充分解释了Logistic回归8。<a class="ae lh" rel="noopener ugc nofollow" target="_blank" href="/differences-between-concat-merge-and-join-with-python-1a6541abc08d?source=friends_link&amp;sk=3b37b694fb90db16275059ea752fc16a">concat()、merge()和join()与Python </a> <br/>的区别9。<a class="ae lh" rel="noopener ugc nofollow" target="_blank" href="/data-wrangling-with-python-part-1-969e3cc81d69?source=friends_link&amp;sk=9c3649cf20f31a5c9ead51c50c89ba0b">与Python的数据角力—第一部分</a> <br/> 10。<a class="ae lh" href="https://medium.com/analytics-vidhya/confusion-matrix-in-machine-learning-91b6e2b3f9af?source=friends_link&amp;sk=11c6531da0bab7b504d518d02746d4cc" rel="noopener">机器学习中的混淆矩阵</a></p></div></div>    
</body>
</html>