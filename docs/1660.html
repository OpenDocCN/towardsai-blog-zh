<html>
<head>
<title>L1 and L2 Norms and Regularization</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">L1和L2规范和正规化</h1>
<blockquote>原文：<a href="https://pub.towardsai.net/l1-and-l2-norms-and-regularization-c50353e6423?source=collection_archive---------4-----------------------#2021-03-12">https://pub.towardsai.net/l1-and-l2-norms-and-regularization-c50353e6423?source=collection_archive---------4-----------------------#2021-03-12</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><h2 id="560c" class="ir is it bd b dl iu iv iw ix iy iz dk ja translated" aria-label="kicker paragraph"><a class="ae ep" href="https://towardsai.net/p/category/data-science" rel="noopener ugc nofollow" target="_blank">数据科学</a></h2><div class=""/><div class=""><h2 id="1a37" class="pw-subtitle-paragraph jz jc it bd b ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq dk translated">了解什么是l1和l2向量范数，以及它们与l1和l2正则化的关系</h2></div><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi kr"><img src="../Images/5427f86bc2d92f94a866100d64dfe737.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*vX6tYv-D8FXj4T0k"/></div></div><figcaption class="ld le gj gh gi lf lg bd b be z dk translated">由<a class="ae lh" href="https://unsplash.com/@markusspiske?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">马库斯·斯皮斯克</a>在<a class="ae lh" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上拍摄的照片</figcaption></figure><p id="e0bb" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">大多数(如果不是全部)数据科学家都熟悉l1和l2正则化。然而，可能不太明显的是，为什么它们被称为l1和l2正则化，以及它们到底是如何工作的。</p><p id="3a24" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">在本文中，我们将了解l1和l2向量范数，并简要讨论它们如何与正则化回归中的l1和l2正则化相关。</p></div><div class="ab cl me mf hx mg" role="separator"><span class="mh bw bk mi mj mk"/><span class="mh bw bk mi mj mk"/><span class="mh bw bk mi mj"/></div><div class="im in io ip iq"><h2 id="aeb8" class="ml mm it bd mn mo mp dn mq mr ms dp mt lr mu mv mw lv mx my mz lz na nb nc iz bi translated">向量范数</h2><p id="a0ed" class="pw-post-body-paragraph li lj it lk b ll nd kd ln lo ne kg lq lr nf lt lu lv ng lx ly lz nh mb mc md im bi translated">向量范数指的是可以测量向量大小的不同方法。例如，假设我们正在处理一个具有一个特征的线性回归问题，<strong class="lk jd"> β1 </strong>。因此，这个问题有两个参数:<strong class="lk jd"> β0 </strong>(截距)，和<strong class="lk jd"> β1 </strong>。让我们给这两个参数赋值1。这些参数的值在一个二维向量中，<strong class="lk jd"> β </strong>:</p><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div class="gh gi ni"><img src="../Images/67012ba8ae8a573d6854bfa75bcef990.png" data-original-src="https://miro.medium.com/v2/resize:fit:814/format:webp/1*YpXstDAYCjufAAvRdyiucA.png"/></div></figure></div><div class="ab cl me mf hx mg" role="separator"><span class="mh bw bk mi mj mk"/><span class="mh bw bk mi mj mk"/><span class="mh bw bk mi mj"/></div><div class="im in io ip iq"><p id="20f3" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated"><em class="nj">关于线性代数概念的复习，请查看:</em></p><div class="nk nl gp gr nm nn"><a href="https://towardsdatascience.com/linear-algebra-for-machine-learning-22f1d8aea83c" rel="noopener follow" target="_blank"><div class="no ab fo"><div class="np ab nq cl cj nr"><h2 class="bd jd gy z fp ns fr fs nt fu fw jc bi translated">用于机器学习的线性代数</h2><div class="nu l"><h3 class="bd b gy z fp ns fr fs nt fu fw dk translated">用于机器学习的线性代数概念综述</h3></div><div class="nv l"><p class="bd b dl z fp ns fr fs nt fu fw dk translated">towardsdatascience.com</p></div></div><div class="nw l"><div class="nx l ny nz oa nw ob lb nn"/></div></div></a></div></div><div class="ab cl me mf hx mg" role="separator"><span class="mh bw bk mi mj mk"/><span class="mh bw bk mi mj mk"/><span class="mh bw bk mi mj"/></div><div class="im in io ip iq"><h2 id="acc5" class="ml mm it bd mn mo mp dn mq mr ms dp mt lr mu mv mw lv mx my mz lz na nb nc iz bi translated">l2规范</h2><p id="2399" class="pw-post-body-paragraph li lj it lk b ll nd kd ln lo ne kg lq lr nf lt lu lv ng lx ly lz nh mb mc md im bi translated">测量矢量大小最常用的方法是取其l2范数，也称为欧几里德范数。这种方法也是我们最熟悉的，因为它测量的是从原点到矢量顶点的笛卡尔距离。<em class="nj">这类似于用勾股定理求直角三角形斜边的长度。</em></p><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div class="gh gi oc"><img src="../Images/a3e8d91248427a02171e2e6ba69d1484.png" data-original-src="https://miro.medium.com/v2/resize:fit:500/format:webp/1*bG1DtIK_ECukJbbodZBKyw.png"/></div></figure><p id="3503" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">为了找到上述n维向量的l2范数，我们使用以下等式:</p><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div class="gh gi od"><img src="../Images/2832190d552a5aa73da257991d580ba8.png" data-original-src="https://miro.medium.com/v2/resize:fit:928/format:webp/1*vOaBXwxSLDajcfHbuLpM2g.png"/></div></figure><blockquote class="oe of og"><p id="6da3" class="li lj nj lk b ll lm kd ln lo lp kg lq oh ls lt lu oi lw lx ly oj ma mb mc md im bi translated">注意l2范数的符号，它包括向量名称两边的双条，以及数字2下标。</p></blockquote></div><div class="ab cl me mf hx mg" role="separator"><span class="mh bw bk mi mj mk"/><span class="mh bw bk mi mj mk"/><span class="mh bw bk mi mj"/></div><div class="im in io ip iq"><p id="6028" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">因此，我们上面的二维参数向量<strong class="lk jd"> β </strong>的l2范数如下，其包括用于<strong class="lk jd"> β0 </strong>和<strong class="lk jd"> β1 </strong>的参数值1:</p><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi ok"><img src="../Images/8b160d2143bf21d24c1c6a9c1c0c98b5.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Y-YO2e3MULl1XVDc7rMqhw.png"/></div></div></figure></div><div class="ab cl me mf hx mg" role="separator"><span class="mh bw bk mi mj mk"/><span class="mh bw bk mi mj mk"/><span class="mh bw bk mi mj"/></div><div class="im in io ip iq"><p id="a50f" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">从原点到向量的距离，或其l2范数，是2的平方根。如果我们用l2范数等于2的平方根来画每一个向量，我们最终得到一个圆，半径等于2的平方根。</p><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div class="gh gi ol"><img src="../Images/8ca89e2985b407067795787c2a5cc0b0.png" data-original-src="https://miro.medium.com/v2/resize:fit:884/format:webp/1*Pq_HXStIh-8pYFw6AXZtbw.png"/></div></figure><blockquote class="oe of og"><p id="08d2" class="li lj nj lk b ll lm kd ln lo lp kg lq oh ls lt lu oi lw lx ly oj ma mb mc md im bi translated">这应该是有意义的，因为以原点为圆心的圆有等式:<br/> a + b = c，其中c是半径。</p></blockquote></div><div class="ab cl me mf hx mg" role="separator"><span class="mh bw bk mi mj mk"/><span class="mh bw bk mi mj mk"/><span class="mh bw bk mi mj"/></div><div class="im in io ip iq"><h2 id="d413" class="ml mm it bd mn mo mp dn mq mr ms dp mt lr mu mv mw lv mx my mz lz na nb nc iz bi translated">l1范数</h2><p id="24e5" class="pw-post-body-paragraph li lj it lk b ll nd kd ln lo ne kg lq lr nf lt lu lv ng lx ly lz nh mb mc md im bi translated">另一种计算矢量大小的方法是取其l1范数，也称为曼哈顿范数。</p><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div class="gh gi oc"><img src="../Images/a3e8d91248427a02171e2e6ba69d1484.png" data-original-src="https://miro.medium.com/v2/resize:fit:500/format:webp/1*bG1DtIK_ECukJbbodZBKyw.png"/></div></figure><p id="becd" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">为了找到n维向量的l1范数，我们将所有向量参数的绝对值求和如下:</p><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div class="gh gi om"><img src="../Images/1ac5cc5eab66a0cac1b0c4eb8547d488.png" data-original-src="https://miro.medium.com/v2/resize:fit:1248/format:webp/1*jL8Wm_h6i16ncvPIzIajUg.png"/></div></figure><blockquote class="oe of og"><p id="f1ba" class="li lj nj lk b ll lm kd ln lo lp kg lq oh ls lt lu oi lw lx ly oj ma mb mc md im bi translated">注意l1范数的符号，它包括向量名称两边的双条，以及数字1下标。</p></blockquote></div><div class="ab cl me mf hx mg" role="separator"><span class="mh bw bk mi mj mk"/><span class="mh bw bk mi mj mk"/><span class="mh bw bk mi mj"/></div><div class="im in io ip iq"><p id="93d5" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">因此，上面我们的二维参数向量<strong class="lk jd"> β </strong>的l1范数，以及两个参数<strong class="lk jd"> β0 </strong>和<strong class="lk jd"> β1 </strong>的值1，如下所示:</p><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div class="gh gi on"><img src="../Images/fa99a720ce8be27e26916c7d2c8c4e1e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1028/format:webp/1*XN20E-TvBegUkX-HBcWQ1g.png"/></div></figure></div><div class="ab cl me mf hx mg" role="separator"><span class="mh bw bk mi mj mk"/><span class="mh bw bk mi mj mk"/><span class="mh bw bk mi mj"/></div><div class="im in io ip iq"><p id="d569" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">正如我们在上面看到的，l1范数等于2。如果我们用l1范数等于2来绘制每个向量，我们最终会得到一个菱形。</p><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div class="gh gi oo"><img src="../Images/c99f3dde63901bc90417dbfeb348c5a5.png" data-original-src="https://miro.medium.com/v2/resize:fit:796/format:webp/1*_yqAiYRgTSDWzUC1EG130g.png"/></div></figure></div><div class="ab cl me mf hx mg" role="separator"><span class="mh bw bk mi mj mk"/><span class="mh bw bk mi mj mk"/><span class="mh bw bk mi mj"/></div><div class="im in io ip iq"><h2 id="38c9" class="ml mm it bd mn mo mp dn mq mr ms dp mt lr mu mv mw lv mx my mz lz na nb nc iz bi translated">l1和l2规范与l1和l2正则化的关系</h2><p id="0a5c" class="pw-post-body-paragraph li lj it lk b ll nd kd ln lo ne kg lq lr nf lt lu lv ng lx ly lz nh mb mc md im bi translated">正则化是一种用于减少过度拟合的技术。换句话说，在低偏差的情况下，当模型过度适应训练数据时，方差将会很高(由于偏差-方差的权衡)，因为模型不会很好地推广到看不见的数据。正则化技术，如l1和l2正则化，将降低模型的复杂性，从而减少过拟合。</p></div><div class="ab cl me mf hx mg" role="separator"><span class="mh bw bk mi mj mk"/><span class="mh bw bk mi mj mk"/><span class="mh bw bk mi mj"/></div><div class="im in io ip iq"><p id="d014" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">例如，在普通最小二乘(OLS)回归中，目标是最小化残差的平方:</p><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div class="gh gi op"><img src="../Images/22caca7af4b6da12aae247f761fb628b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1052/format:webp/1*8dxs9a_8Ndrragf2eeBJsw.png"/></div></figure><blockquote class="oe of og"><p id="ab92" class="li lj nj lk b ll lm kd ln lo lp kg lq oh ls lt lu oi lw lx ly oj ma mb mc md im bi translated">注意平方和基本上是如何取残差的l2范数平方的。</p></blockquote></div><div class="ab cl me mf hx mg" role="separator"><span class="mh bw bk mi mj mk"/><span class="mh bw bk mi mj mk"/><span class="mh bw bk mi mj"/></div><div class="im in io ip iq"><p id="b858" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">在正则化回归中，代价函数中增加了一个惩罚项。换句话说，增加了一些约束。要么参数向量的l1范数被约束(如在l1或lasso回归中)，要么参数向量的l2范数被约束(如在l2或岭回归中)。因此，它们被称为l1和l2正则化。</p></div><div class="ab cl me mf hx mg" role="separator"><span class="mh bw bk mi mj mk"/><span class="mh bw bk mi mj mk"/><span class="mh bw bk mi mj"/></div><div class="im in io ip iq"><p id="be19" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated"><em class="nj">注意:推导这些约束优化问题的以下lasso和ridge回归目标函数涉及拉格朗日乘数的使用，这可能会在以后的文章中介绍。</em></p></div><div class="ab cl me mf hx mg" role="separator"><span class="mh bw bk mi mj mk"/><span class="mh bw bk mi mj mk"/><span class="mh bw bk mi mj"/></div><div class="im in io ip iq"><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div class="gh gi oq"><img src="../Images/3a73e046a6c72b273c1209196aa2879f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1224/format:webp/1*EAI8K92Q5VwGdL9zsIU3MQ.png"/></div></figure><p id="6918" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">在l1回归(也称为lasso回归)中，约束条件是我们希望参数向量(包括我们的参数)的l1范数等于或低于特定值。换句话说，我们希望最小化成本函数，<strong class="lk jd">，只要</strong>作为l1范数低于某个值。</p><blockquote class="oe of og"><p id="63bc" class="li lj nj lk b ll lm kd ln lo lp kg lq oh ls lt lu oi lw lx ly oj ma mb mc md im bi translated">正如我们之前看到的，绘制特定l1模值的所有向量会给出一个菱形。因此，我们的参数值必须在这个菱形上或之内。</p></blockquote></div><div class="ab cl me mf hx mg" role="separator"><span class="mh bw bk mi mj mk"/><span class="mh bw bk mi mj mk"/><span class="mh bw bk mi mj"/></div><div class="im in io ip iq"><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi or"><img src="../Images/0ab254a6a2c810fa3383e1a5264e2840.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*cmyB-2JQJAvodLCso6T93A.png"/></div></div></figure><p id="8543" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">在l2正则化中，我们希望参数向量的l2范数被约束在某个值或低于某个值。因此，参数向量必须在圆上或圆内(如上所示)。</p><blockquote class="oe of og"><p id="69b7" class="li lj nj lk b ll lm kd ln lo lp kg lq oh ls lt lu oi lw lx ly oj ma mb mc md im bi translated">注意:当只有两个参数时，不应使用l1和l2正则化。这里的目标只是简单直观地理解它们与l1和l2规范的关系。</p></blockquote></div><div class="ab cl me mf hx mg" role="separator"><span class="mh bw bk mi mj mk"/><span class="mh bw bk mi mj mk"/><span class="mh bw bk mi mj"/></div><div class="im in io ip iq"><p id="e05d" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">如果你喜欢阅读这样的故事，并想支持我成为一名作家，考虑注册成为一名媒体会员。每月5美元，你可以无限制地阅读媒体上的故事。如果你用我的 <a class="ae lh" href="https://lmatalka90.medium.com/membership" rel="noopener"> <em class="nj">链接</em> </a> <em class="nj">注册，我会赚一小笔佣金。</em></p><div class="nk nl gp gr nm nn"><a href="https://lmatalka90.medium.com/membership" rel="noopener follow" target="_blank"><div class="no ab fo"><div class="np ab nq cl cj nr"><h2 class="bd jd gy z fp ns fr fs nt fu fw jc bi translated">通过我的推荐链接加入媒体——卢艾·马塔尔卡</h2><div class="nu l"><h3 class="bd b gy z fp ns fr fs nt fu fw dk translated">阅读卢艾·马塔尔卡的每一个故事(以及媒体上成千上万的其他作家)。您的会员费直接支持…</h3></div><div class="nv l"><p class="bd b dl z fp ns fr fs nt fu fw dk translated">lmatalka90.medium.com</p></div></div><div class="nw l"><div class="os l ny nz oa nw ob lb nn"/></div></div></a></div></div><div class="ab cl me mf hx mg" role="separator"><span class="mh bw bk mi mj mk"/><span class="mh bw bk mi mj mk"/><span class="mh bw bk mi mj"/></div><div class="im in io ip iq"><p id="41c5" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated"><em class="nj">了解什么是l1和l2规范将为真正理解l1和l2正则化希望实现的目标奠定基础。感谢您的阅读！</em></p></div></div>    
</body>
</html>