<html>
<head>
<title>Machine Learning Modeling Data with Python</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">使用Python对数据进行机器学习建模</h1>
<blockquote>原文：<a href="https://pub.towardsai.net/machine-learning-modeling-data-with-python-92bfebfe4052?source=collection_archive---------0-----------------------#2021-05-27">https://pub.towardsai.net/machine-learning-modeling-data-with-python-92bfebfe4052?source=collection_archive---------0-----------------------#2021-05-27</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><h2 id="65d5" class="ir is it bd b dl iu iv iw ix iy iz dk ja translated" aria-label="kicker paragraph"><a class="ae ep" href="https://towardsai.net/p/category/machine-learning" rel="noopener ugc nofollow" target="_blank">机器学习</a></h2><div class=""/><div class=""><h2 id="52be" class="pw-subtitle-paragraph jz jc it bd b ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq dk translated">回归和分类算法</h2></div><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi kr"><img src="../Images/bc2d836c7d92d8a88e8b4d9e5908505b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*EQhSOcFp2n_KYYww9NOSYg.png"/></div></div><figcaption class="ld le gj gh gi lf lg bd b be z dk translated">作者的照片</figcaption></figure><p id="b7c4" class="pw-post-body-paragraph lh li it lj b lk ll kd lm ln lo kg lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">在本文中，我们将分析校园安置数据，以深入了解数据中学生被安置的因素。由于数据非常少，有点不平衡，我们尝试做EDA和机器学习建模，以获得更好的结果。</p><p id="17fe" class="pw-post-body-paragraph lh li it lj b lk ll kd lm ln lo kg lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">数据集包含百分比、分数、课程专业、经验等。有两个输出列，即对于回归，我们可以将工资作为输出，对于分类，我们可以将状态作为输出。</p><p id="1f07" class="pw-post-body-paragraph lh li it lj b lk ll kd lm ln lo kg lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">让我们导入所有需要的库。</p><pre class="ks kt ku kv gt md me mf mg aw mh bi"><span id="60f0" class="mi mj it me b gy mk ml l mm mn"><em class="mo"># Import Libraries</em><br/><br/><strong class="me jd">import</strong> <strong class="me jd">pandas</strong> <strong class="me jd">as</strong> <strong class="me jd">pd</strong><br/><br/><strong class="me jd">import</strong> <strong class="me jd">matplotlib.pyplot</strong> <strong class="me jd">as</strong> <strong class="me jd">plt</strong><br/><strong class="me jd">import</strong> <strong class="me jd">numpy</strong> <strong class="me jd">as</strong> <strong class="me jd">np</strong><br/><strong class="me jd">from</strong> <strong class="me jd">sklearn.metrics</strong> <strong class="me jd">import</strong> log_loss, confusion_matrix<br/><strong class="me jd">import</strong> <strong class="me jd">seaborn</strong> <strong class="me jd">as</strong> <strong class="me jd">sns</strong><br/><br/><strong class="me jd">from</strong> <strong class="me jd">sklearn.neighbors</strong> <strong class="me jd">import</strong> KNeighborsClassifier<br/><br/><strong class="me jd">from</strong> <strong class="me jd">sklearn.metrics</strong> <strong class="me jd">import</strong> roc_curve, auc , precision_score , classification_report<br/><br/><br/><strong class="me jd">from</strong> <strong class="me jd">sklearn.tree</strong> <strong class="me jd">import</strong> DecisionTreeClassifier<br/><br/><strong class="me jd">import</strong> <strong class="me jd">warnings</strong><br/>warnings.filterwarnings('ignore')<br/><br/><strong class="me jd">from</strong> <strong class="me jd">sklearn.metrics</strong> <strong class="me jd">import</strong> confusion_matrix<br/><br/><strong class="me jd">from</strong> <strong class="me jd">sklearn.multiclass</strong> <strong class="me jd">import</strong> OneVsRestClassifier</span></pre><p id="73fe" class="pw-post-body-paragraph lh li it lj b lk ll kd lm ln lo kg lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">阅读并查看数据集。</p><pre class="ks kt ku kv gt md me mf mg aw mh bi"><span id="d8fd" class="mi mj it me b gy mk ml l mm mn">df = pd.read_csv('Placement_Data_Full_Class.csv')<br/>df</span></pre><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi mp"><img src="../Images/b2bf5bea242b6828495096de11bf50b8.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*6oFREiM0yFuciNn4ntJDkw.png"/></div></div><figcaption class="ld le gj gh gi lf lg bd b be z dk translated">作者的照片</figcaption></figure><p id="d487" class="pw-post-body-paragraph lh li it lj b lk ll kd lm ln lo kg lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">现在，我们将做一些探索性的数据分析。</p><pre class="ks kt ku kv gt md me mf mg aw mh bi"><span id="2b5c" class="mi mj it me b gy mk ml l mm mn">df.info()</span><span id="3dc8" class="mi mj it me b gy mq ml l mm mn">#output:<br/>&lt;class 'pandas.core.frame.DataFrame'&gt;<br/>RangeIndex: 215 entries, 0 to 214<br/>Data columns (total 15 columns):<br/> #   Column          Non-Null Count  Dtype  <br/>---  ------          --------------  -----  <br/> 0   sl_no           215 non-null    int64  <br/> 1   gender          215 non-null    object <br/> 2   ssc_p           215 non-null    float64<br/> 3   ssc_b           215 non-null    object <br/> 4   hsc_p           215 non-null    float64<br/> 5   hsc_b           215 non-null    object <br/> 6   hsc_s           215 non-null    object <br/> 7   degree_p        215 non-null    float64<br/> 8   degree_t        215 non-null    object <br/> 9   workex          215 non-null    object <br/> 10  etest_p         215 non-null    float64<br/> 11  specialisation  215 non-null    object <br/> 12  mba_p           215 non-null    float64<br/> 13  status          215 non-null    object <br/> 14  salary          148 non-null    float64<br/>dtypes: float64(6), int64(1), object(8)<br/>memory usage: 25.3+ KB</span></pre><p id="4bc6" class="pw-post-body-paragraph lh li it lj b lk ll kd lm ln lo kg lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">映射集群的状态列</p><pre class="ks kt ku kv gt md me mf mg aw mh bi"><span id="e2d8" class="mi mj it me b gy mk ml l mm mn">#replacing status column categories to 0 and 1<br/>df['status'] = df['status'].map({"Placed":1, "Not Placed":0})<br/><br/>#filling null values in salary with 0<br/>df.salary.fillna(0,inplace=<strong class="me jd">True</strong>)<br/><br/>df.head()</span></pre><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi mr"><img src="../Images/d2f7729aeea3a3a983e85da5a3b24ac4.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*3uixIsjWWW8Aj_p0iRunzQ.png"/></div></div><figcaption class="ld le gj gh gi lf lg bd b be z dk translated">作者的照片</figcaption></figure><p id="51b0" class="pw-post-body-paragraph lh li it lj b lk ll kd lm ln lo kg lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">检查数据集中缺失的值</p><pre class="ks kt ku kv gt md me mf mg aw mh bi"><span id="1497" class="mi mj it me b gy mk ml l mm mn"><em class="mo">#missing values</em><br/>df.isna().sum()</span><span id="921d" class="mi mj it me b gy mq ml l mm mn">#output:<br/>sl_no             0<br/>gender            0<br/>ssc_p             0<br/>ssc_b             0<br/>hsc_p             0<br/>hsc_b             0<br/>hsc_s             0<br/>degree_p          0<br/>degree_t          0<br/>workex            0<br/>etest_p           0<br/>specialisation    0<br/>mba_p             0<br/>status            0<br/>salary            0<br/>dtype: int64</span></pre><p id="d1a0" class="pw-post-body-paragraph lh li it lj b lk ll kd lm ln lo kg lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">检查分类的状态列</p><pre class="ks kt ku kv gt md me mf mg aw mh bi"><span id="425b" class="mi mj it me b gy mk ml l mm mn">sns.countplot(x="status", palette="dark", data=df);</span></pre><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div class="gh gi ms"><img src="../Images/768885ec0e628e68418ea896749452ec.png" data-original-src="https://miro.medium.com/v2/resize:fit:800/format:webp/1*PpnMwB7BgigMmToMNoPNDQ.png"/></div><figcaption class="ld le gj gh gi lf lg bd b be z dk translated">作者的照片</figcaption></figure><p id="401d" class="pw-post-body-paragraph lh li it lj b lk ll kd lm ln lo kg lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">使用seaborn库的pairplot对数据进行可视化检查</p><pre class="ks kt ku kv gt md me mf mg aw mh bi"><span id="c0cd" class="mi mj it me b gy mk ml l mm mn">sns.pairplot(data=df, kind="reg");</span></pre><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi mt"><img src="../Images/cec6f0d78cb70316ab8269207fb58bae.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*nCAhBbGOY6CcHshOzWuZpQ.png"/></div></div><figcaption class="ld le gj gh gi lf lg bd b be z dk translated">作者的照片</figcaption></figure><p id="95f1" class="pw-post-body-paragraph lh li it lj b lk ll kd lm ln lo kg lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">基于性别检查工资</p><pre class="ks kt ku kv gt md me mf mg aw mh bi"><span id="7f75" class="mi mj it me b gy mk ml l mm mn">placed = df[df["status"]==1][["gender","salary", "workex"]]<br/><br/>sns.catplot(y="salary", x="gender", kind="swarm", palette="dark"<br/>                                                  ,data=placed);</span></pre><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div class="gh gi mu"><img src="../Images/29952b03af821491bfdb3447e2a378cc.png" data-original-src="https://miro.medium.com/v2/resize:fit:822/format:webp/1*po0X5Zs1C4AJQz1rtuxxSQ.png"/></div><figcaption class="ld le gj gh gi lf lg bd b be z dk translated">猫图。作者的照片</figcaption></figure><p id="d37e" class="pw-post-body-paragraph lh li it lj b lk ll kd lm ln lo kg lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">男性似乎比女性更倾向于高薪。</p><div class="mv mw gp gr mx my"><a rel="noopener  ugc nofollow" target="_blank" href="/machine-learning-16c8ccc2c7b8"><div class="mz ab fo"><div class="na ab nb cl cj nc"><h2 class="bd jd gy z fp nd fr fs ne fu fw jc bi translated">无监督学习中不同类型的聚类方法</h2><div class="nf l"><p class="bd b dl z fp nd fr fs ne fu fw dk translated">pub.towardsai.net</p></div></div><div class="ng l"><div class="nh l ni nj nk ng nl lb my"/></div></div></a></div><h2 id="432f" class="mi mj it bd nm nn no dn np nq nr dp ns lq nt nu nv lu nw nx ny ly nz oa ob iz bi translated">数据预处理</h2><p id="a44e" class="pw-post-body-paragraph lh li it lj b lk oc kd lm ln od kg lp lq oe ls lt lu of lw lx ly og ma mb mc im bi translated">需要对分类特征进行标签编码</p><pre class="ks kt ku kv gt md me mf mg aw mh bi"><span id="40be" class="mi mj it me b gy mk ml l mm mn"><strong class="me jd">from</strong> <strong class="me jd">sklearn.preprocessing</strong> <strong class="me jd">import</strong> LabelEncoder<br/>le=LabelEncoder()<br/><strong class="me jd">for</strong> i <strong class="me jd">in</strong> categorical:<br/>    df[i]=le.fit_transform(df[i])</span><span id="3f12" class="mi mj it me b gy mq ml l mm mn">df</span></pre><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi oh"><img src="../Images/9eaad3ad1ef93f7243193de5e371dd20.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*EdxWV1eq4XCOmfb4ucqWrQ.png"/></div></div><figcaption class="ld le gj gh gi lf lg bd b be z dk translated">作者的照片</figcaption></figure><p id="ba11" class="pw-post-body-paragraph lh li it lj b lk ll kd lm ln lo kg lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">我们可以在上面的数据中看到，特征已经被标注，准备进入机器学习建模。</p><h2 id="a893" class="mi mj it bd nm nn no dn np nq nr dp ns lq nt nu nv lu nw nx ny ly nz oa ob iz bi translated">回归</h2><pre class="ks kt ku kv gt md me mf mg aw mh bi"><span id="62cc" class="mi mj it me b gy mk ml l mm mn">df_reg_x = df.drop(['sl_no','salary'],1)<br/>df_reg_y = df.salary</span><span id="1611" class="mi mj it me b gy mq ml l mm mn"><strong class="me jd">from</strong> <strong class="me jd">sklearn.model_selection</strong> <strong class="me jd">import</strong> train_test_split<br/>X_train, X_test, y_train, y_test = train_test_split(df_reg_x, df_reg_y, test_size = 0.15)</span><span id="73ab" class="mi mj it me b gy mq ml l mm mn"><strong class="me jd">from</strong> <strong class="me jd">sklearn.preprocessing</strong> <strong class="me jd">import</strong> StandardScaler<br/>sc = StandardScaler()<br/>X_train = sc.fit_transform(X_train)<br/>X_test = sc.transform(X_test)</span><span id="5bd3" class="mi mj it me b gy mq ml l mm mn">sc_y = StandardScaler()</span><span id="2904" class="mi mj it me b gy mq ml l mm mn">y_train = sc_y.fit_transform(np.array(y_train).reshape(-1,1))</span><span id="2382" class="mi mj it me b gy mq ml l mm mn">y_test = sc_y.transform(np.array(y_test).reshape(-1,1))</span></pre><ol class=""><li id="27a3" class="oi oj it lj b lk ll ln lo lq ok lu ol ly om mc on oo op oq bi translated">线性回归</li></ol><pre class="ks kt ku kv gt md me mf mg aw mh bi"><span id="c8d5" class="mi mj it me b gy mk ml l mm mn"><strong class="me jd">from</strong> <strong class="me jd">sklearn.linear_model</strong> <strong class="me jd">import</strong> LinearRegression</span><span id="3f57" class="mi mj it me b gy mq ml l mm mn">model1 = LinearRegression()<br/>model1.fit(X_train,y_train)<br/>y_pred = model1.predict(X_test)</span><span id="6bb1" class="mi mj it me b gy mq ml l mm mn"><strong class="me jd">from</strong> <strong class="me jd">sklearn.metrics</strong> <strong class="me jd">import</strong> mean_squared_error, r2_score</span><span id="bad3" class="mi mj it me b gy mq ml l mm mn">print('MSE of Linear Regressor Model---&gt;' ,<br/>                             mean_squared_error(y_test,y_pred))<br/>print('r2_score of Linear Model---&gt;' , r2_score(y_test,y_pred))</span><span id="c566" class="mi mj it me b gy mq ml l mm mn">#output:<br/>MSE of Linear Regressor Model---&gt; 0.06942385507687932<br/>r2_score of Linear Model---&gt; 0.9073385898967523</span></pre><p id="2674" class="pw-post-body-paragraph lh li it lj b lk ll kd lm ln lo kg lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">2.近邻回归量</p><pre class="ks kt ku kv gt md me mf mg aw mh bi"><span id="791a" class="mi mj it me b gy mk ml l mm mn"><strong class="me jd">from</strong> <strong class="me jd">sklearn.neighbors</strong> <strong class="me jd">import</strong> KNeighborsRegressor</span><span id="0df5" class="mi mj it me b gy mq ml l mm mn">neigh = KNeighborsRegressor(n_neighbors=11)<br/>neigh.fit(X_train, y_train)<br/>y_pred = neigh.predict(X_test)</span><span id="7925" class="mi mj it me b gy mq ml l mm mn"><strong class="me jd">from</strong> <strong class="me jd">sklearn.metrics</strong> <strong class="me jd">import</strong> mean_squared_error, r2_score</span><span id="4087" class="mi mj it me b gy mq ml l mm mn">print('MSE of KNeighbors Regressor Model---&gt;' ,<br/>                       mean_squared_error(y_test,y_pred))<br/>print('r2_score of Linear Model---&gt;' , r2_score(y_test,y_pred))</span><span id="6bb5" class="mi mj it me b gy mq ml l mm mn">#output:<br/>MSE of KNeighbors Regressor Model---&gt; 0.29273900427438526<br/>r2_score of Linear Model---&gt; 0.6092753867061032</span></pre><p id="319d" class="pw-post-body-paragraph lh li it lj b lk ll kd lm ln lo kg lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">3.决策树回归器</p><pre class="ks kt ku kv gt md me mf mg aw mh bi"><span id="da24" class="mi mj it me b gy mk ml l mm mn"><strong class="me jd">from</strong> <strong class="me jd">sklearn.tree</strong> <strong class="me jd">import</strong> DecisionTreeRegressor</span><span id="0fee" class="mi mj it me b gy mq ml l mm mn">regressor = DecisionTreeRegressor()<br/>regressor.fit(X_train, y_train)<br/>y_pred = regressor.predict(X_test)</span><span id="dcf5" class="mi mj it me b gy mq ml l mm mn">print('MSE of DecisionTree Regressor Model---&gt;' , <br/>                     mean_squared_error(y_test,y_pred))<br/>print('r2_score of Linear Model---&gt;' , r2_score(y_test,y_pred))</span><span id="45ee" class="mi mj it me b gy mq ml l mm mn">#output:<br/>MSE of DecisionTree Regressor Model---&gt; 0.13344250885495113<br/>r2_score of Linear Model---&gt; 0.8218916102466214</span></pre><h2 id="b68c" class="mi mj it bd nm nn no dn np nq nr dp ns lq nt nu nv lu nw nx ny ly nz oa ob iz bi translated">分类</h2><pre class="ks kt ku kv gt md me mf mg aw mh bi"><span id="d86c" class="mi mj it me b gy mk ml l mm mn">df_class_x = df.drop(['salary','sl_no','status'],1)<br/>df_class_y = df.status</span><span id="8ddc" class="mi mj it me b gy mq ml l mm mn"><strong class="me jd">from</strong> <strong class="me jd">sklearn.model_selection</strong> <strong class="me jd">import</strong> train_test_split<br/>X_train, X_test, y_train, y_test = train_test_split(df_class_x,<br/>           df_class_y, stratify=df_class_y, test_size = 0.15)</span></pre><ol class=""><li id="157c" class="oi oj it lj b lk ll ln lo lq ok lu ol ly om mc on oo op oq bi translated">逻辑回归</li></ol><pre class="ks kt ku kv gt md me mf mg aw mh bi"><span id="3fa3" class="mi mj it me b gy mk ml l mm mn"><strong class="me jd">from</strong> <strong class="me jd">sklearn.linear_model</strong> <strong class="me jd">import</strong> LogisticRegression<br/><strong class="me jd">from</strong> <strong class="me jd">sklearn.metrics</strong> <strong class="me jd">import</strong> roc_auc_score<br/><strong class="me jd">from</strong> <strong class="me jd">sklearn.model_selection</strong> <strong class="me jd">import</strong> GridSearchCV</span><span id="ae1e" class="mi mj it me b gy mq ml l mm mn">parameters = [{'C': [10**x <strong class="me jd">for</strong> x <strong class="me jd">in</strong> range(-4,5)]}]<br/>K =[10**x <strong class="me jd">for</strong> x <strong class="me jd">in</strong> range(-4,5)]<br/>K = np.log10(K)<br/><br/>log= LogisticRegression(penalty='l2')<br/>clf = GridSearchCV(log, parameters, cv=5, scoring='roc_auc',return_train_score=<strong class="me jd">True</strong>)<br/>clf.fit(X_train, y_train)<br/><br/>train_auc= clf.cv_results_['mean_train_score']<br/>train_auc_std= clf.cv_results_['std_train_score']<br/>cv_auc = clf.cv_results_['mean_test_score'] <br/>cv_auc_std= clf.cv_results_['std_test_score']<br/>lamb= clf.best_params_<br/>lamb = list(lamb.values())[0]<br/>plt.figure(figsize=(10, 7))<br/><br/>plt.plot(K, train_auc, label='Train AUC')<br/><br/>plt.gca().fill_between(K,train_auc - train_auc_std,train_auc + train_auc_std,alpha=0.2,color='darkblue')<br/><br/>plt.plot(K, cv_auc, label='CV AUC')<br/><br/>plt.gca().fill_between(K,cv_auc - cv_auc_std,cv_auc + cv_auc_std,alpha=0.2,color='darkorange')<br/>plt.scatter(K, train_auc, label='Train AUC points')<br/>plt.scatter(K, cv_auc, label='CV AUC points')<br/>plt.grid(<strong class="me jd">True</strong>)<br/>plt.legend()<br/>plt.xlabel("C: hyperparameter")<br/>plt.ylabel("AUC")<br/>plt.title("ERROR PLOTS")<br/>plt.show()<br/>print('The best value of C is : ' , lamb)</span></pre><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div class="gh gi or"><img src="../Images/f777991b9005819856066a564fbe586e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1286/format:webp/1*P4xQUBkh1XV103eNbJObMw.png"/></div><figcaption class="ld le gj gh gi lf lg bd b be z dk translated">训练和测试AUR曲线。作者的照片</figcaption></figure><p id="efac" class="pw-post-body-paragraph lh li it lj b lk ll kd lm ln lo kg lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">C的最佳值是:0.1</p><p id="1cbd" class="pw-post-body-paragraph lh li it lj b lk ll kd lm ln lo kg lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">最佳超参数拟合模型</p><pre class="ks kt ku kv gt md me mf mg aw mh bi"><span id="c46c" class="mi mj it me b gy mk ml l mm mn">log= LogisticRegression(penalty='l2',C = 0.001)<br/>log.fit(X_train,y_train)<br/>train_fpr, train_tpr, thresholds = roc_curve(y_train, <br/>                             log.predict_proba(X_train)[:,1])<br/>test_fpr, test_tpr, thresholds = roc_curve(y_test,<br/>                             log.predict_proba(X_test)[:,1])<br/>plt.plot(train_fpr, train_tpr, label="train AUC <br/>                      ="+str(auc(train_fpr, train_tpr)))<br/>plt.plot(test_fpr, test_tpr, label="test AUC ="+str(auc(test_fpr,<br/>                                      test_tpr)))<br/>plt.legend()<br/>plt.grid(<strong class="me jd">True</strong>)<br/>plt.xlabel("False Positive Rate")<br/>plt.ylabel("True Positive Rate")<br/>plt.title("ROC Curve")<br/>plt.plot([0, 1], [0, 1],'r--')<br/>plt.xlim([0, 1])<br/>plt.ylim([0, 1])<br/>plt.show()</span></pre><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div class="gh gi os"><img src="../Images/330f970436a3f044acc7da3d9855f521.png" data-original-src="https://miro.medium.com/v2/resize:fit:814/format:webp/1*P94vwp9lFsJS_cx2dijAgQ.png"/></div><figcaption class="ld le gj gh gi lf lg bd b be z dk translated">ROC曲线。作者的照片</figcaption></figure><p id="92ec" class="pw-post-body-paragraph lh li it lj b lk ll kd lm ln lo kg lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">打印分类报告</p><pre class="ks kt ku kv gt md me mf mg aw mh bi"><span id="e14d" class="mi mj it me b gy mk ml l mm mn">y_pred = log.predict(X_test)<br/>print (classification_report(y_test,y_pred))</span></pre><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div class="gh gi ot"><img src="../Images/b89b5d5f590c17028bbcf8e2130c419b.png" data-original-src="https://miro.medium.com/v2/resize:fit:880/format:webp/1*P86oQzOeDcZA2GcDcdRLyQ.png"/></div><figcaption class="ld le gj gh gi lf lg bd b be z dk translated">作者的照片</figcaption></figure><p id="1d30" class="pw-post-body-paragraph lh li it lj b lk ll kd lm ln lo kg lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">混淆矩阵</p><pre class="ks kt ku kv gt md me mf mg aw mh bi"><span id="91fa" class="mi mj it me b gy mk ml l mm mn">heatmap(confusion_matrix(y_test,y_pred),<br/>                         annot=<strong class="me jd">True</strong>,fmt="d",cmap='Blues')</span></pre><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div class="gh gi ou"><img src="../Images/157fd9dc30083a1cace69c623670f248.png" data-original-src="https://miro.medium.com/v2/resize:fit:722/format:webp/1*AQzfR9suNSdimIKyP8ouMw.png"/></div><figcaption class="ld le gj gh gi lf lg bd b be z dk translated">作者的照片</figcaption></figure><h2 id="c265" class="mi mj it bd nm nn no dn np nq nr dp ns lq nt nu nv lu nw nx ny ly nz oa ob iz bi translated">结论:</h2><p id="600e" class="pw-post-body-paragraph lh li it lj b lk oc kd lm ln od kg lp lq oe ls lt lu of lw lx ly og ma mb mc im bi translated">在校正不平衡的数据集之后，可以应用回归和分类算法。</p><p id="f09e" class="pw-post-body-paragraph lh li it lj b lk ll kd lm ln lo kg lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">我希望你喜欢这篇文章。通过我的<a class="ae ov" href="https://www.linkedin.com/in/data-scientist-95040a1ab/" rel="noopener ugc nofollow" target="_blank"> LinkedIn </a>和<a class="ae ov" href="https://twitter.com/amitprius" rel="noopener ugc nofollow" target="_blank"> twitter </a>联系我。</p><h1 id="172c" class="ow mj it bd nm ox oy oz np pa pb pc ns ki pd kj nv kl pe km ny ko pf kp ob pg bi translated">推荐文章</h1><p id="d281" class="pw-post-body-paragraph lh li it lj b lk oc kd lm ln od kg lp lq oe ls lt lu of lw lx ly og ma mb mc im bi translated"><a class="ae ov" href="https://medium.com/towards-artificial-intelligence/nlp-zero-to-hero-with-python-2df6fcebff6e?sk=2231d868766e96b13d1e9d7db6064df1" rel="noopener"> 1。NLP —零到英雄与Python </a> <br/> 2。<a class="ae ov" href="https://medium.com/towards-artificial-intelligence/python-data-structures-data-types-and-objects-244d0a86c3cf?sk=42f4b462499f3fc3a160b21e2c94dba6" rel="noopener"> Python数据结构数据类型和对象</a>T5】3 .<a class="ae ov" rel="noopener ugc nofollow" target="_blank" href="/exception-handling-concepts-in-python-4d5116decac3?source=friends_link&amp;sk=a0ed49d9fdeaa67925eac34ecb55ea30">Python中的异常处理概念</a> <br/> 4。<a class="ae ov" rel="noopener ugc nofollow" target="_blank" href="/deep-learning-88e218b74a14?source=friends_link&amp;sk=540bf9088d31859d50dbddab7524ba35">为什么LSTM在深度学习方面比RNN更有用？</a> <br/> 5。<a class="ae ov" rel="noopener ugc nofollow" target="_blank" href="/neural-networks-the-rise-of-recurrent-neural-networks-df740252da88?source=friends_link&amp;sk=6844935e3de14e478ce00f0b22e419eb">神经网络:递归神经网络的兴起</a> <br/> 6。<a class="ae ov" href="https://medium.com/towards-artificial-intelligence/fully-explained-linear-regression-with-python-fe2b313f32f3?source=friends_link&amp;sk=53c91a2a51347ec2d93f8222c0e06402" rel="noopener">用Python </a> <br/> 7全面讲解了线性回归。<a class="ae ov" href="https://medium.com/towards-artificial-intelligence/fully-explained-logistic-regression-with-python-f4a16413ddcd?source=friends_link&amp;sk=528181f15a44e48ea38fdd9579241a78" rel="noopener">用Python </a> <br/>充分解释了Logistic回归8。<a class="ae ov" rel="noopener ugc nofollow" target="_blank" href="/differences-between-concat-merge-and-join-with-python-1a6541abc08d?source=friends_link&amp;sk=3b37b694fb90db16275059ea752fc16a">concat()、merge()和join()与Python </a> <br/>的区别9。<a class="ae ov" rel="noopener ugc nofollow" target="_blank" href="/data-wrangling-with-python-part-1-969e3cc81d69?source=friends_link&amp;sk=9c3649cf20f31a5c9ead51c50c89ba0b">与Python的数据角力—第一部分</a> <br/> 10。<a class="ae ov" href="https://medium.com/analytics-vidhya/confusion-matrix-in-machine-learning-91b6e2b3f9af?source=friends_link&amp;sk=11c6531da0bab7b504d518d02746d4cc" rel="noopener">机器学习中的混淆矩阵</a></p></div></div>    
</body>
</html>