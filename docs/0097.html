<html>
<head>
<title>Text Classification by XGBoost &amp; Others: A Case Study Using BBC News Articles</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">XGBoost等人的文本分类:以BBC新闻文章为例</h1>
<blockquote>原文：<a href="https://pub.towardsai.net/text-classification-by-xgboost-others-a-case-study-using-bbc-news-articles-5d88e94a9f8?source=collection_archive---------0-----------------------#2019-07-03">https://pub.towardsai.net/text-classification-by-xgboost-others-a-case-study-using-bbc-news-articles-5d88e94a9f8?source=collection_archive---------0-----------------------#2019-07-03</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><h2 id="910f" class="ir is it bd b dl iu iv iw ix iy iz dk ja translated" aria-label="kicker paragraph"><a class="ae ep" href="https://towardsai.net/p/category/machine-learning" rel="noopener ugc nofollow" target="_blank">机器学习</a></h2><div class=""/><div class=""><h2 id="9d41" class="pw-subtitle-paragraph jz jc it bd b ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq dk translated">不同向量空间模型的比较研究XGBoost等文本分类技术</h2></div><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi kr"><img src="../Images/30c512c8c44b1244faec35aebd6364b0.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*p-rEOVLgykm5wG9Ehexe1A.jpeg"/></div></div></figure><p id="8877" class="pw-post-body-paragraph ld le it lf b lg lh kd li lj lk kg ll lm ln lo lp lq lr ls lt lu lv lw lx ly im bi translated">在本文中，我们将讨论不同的文本分类技术来解决<em class="lz"> BBC新文章分类</em>问题。我们还将讨论不同的向量空间模型来表示文本数据。</p><p id="f0bc" class="pw-post-body-paragraph ld le it lf b lg lh kd li lj lk kg ll lm ln lo lp lq lr ls lt lu lv lw lx ly im bi translated">我们将使用<em class="lz"> Python、Sci-kit-learn、Gensim和Xgboost </em>库来解决这个问题。</p><h1 id="8de0" class="ma mb it bd mc md me mf mg mh mi mj mk ki ml kj mm kl mn km mo ko mp kp mq mr bi translated">获取数据</h1><p id="52bb" class="pw-post-body-paragraph ld le it lf b lg ms kd li lj mt kg ll lm mu lo lp lq mv ls lt lu mw lw lx ly im bi translated">这个问题的数据可以从<a class="ae mx" href="https://www.kaggle.com/yufengdev/bbc-fulltext-and-category" rel="noopener ugc nofollow" target="_blank"> Kaggle </a>中找到。该数据集包含两列CSV格式的BBC新闻文本及其类别。让我们看看那里有什么</p><figure class="ks kt ku kv gt kw"><div class="bz fp l di"><div class="my mz l"/></div></figure><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi na"><img src="../Images/b0a76dcb127f13bfd06375afbc396c7f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*f78QV5PNVPGUCSb7gKgikQ.png"/></div></div><figcaption class="nb nc gj gh gi nd ne bd b be z dk translated">图1</figcaption></figure><p id="4413" class="pw-post-body-paragraph ld le it lf b lg lh kd li lj lk kg ll lm ln lo lp lq lr ls lt lu lv lw lx ly im bi translated">看起来像是长文本。我们将在后面的章节中看到这一点。这里的问题是:如果给定一个‘文本’，我们就要预测它的‘类别’。肯定是一个多类文本分类问题。</p><h1 id="1a64" class="ma mb it bd mc md me mf mg mh mi mj mk ki ml kj mm kl mn km mo ko mp kp mq mr bi translated">数据探索和可视化</h1><p id="bb16" class="pw-post-body-paragraph ld le it lf b lg ms kd li lj mt kg ll lm mu lo lp lq mv ls lt lu mw lw lx ly im bi translated">首先，我们会看到有多少类别</p><figure class="ks kt ku kv gt kw"><div class="bz fp l di"><div class="my mz l"/></div></figure><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi gj"><img src="../Images/41239b6a9e6bb181c49138689580749d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*lCOrCKTpieAmPqeWjLNayQ.png"/></div></div><figcaption class="nb nc gj gh gi nd ne bd b be z dk translated">图2</figcaption></figure><p id="0eab" class="pw-post-body-paragraph ld le it lf b lg lh kd li lj lk kg ll lm ln lo lp lq lr ls lt lu lv lw lx ly im bi translated">因此，有5个不同的类别。我们可以称这些为“类”。从图中可以明显看出，阶级分布没有那么多偏斜。</p><p id="a4e2" class="pw-post-body-paragraph ld le it lf b lg lh kd li lj lk kg ll lm ln lo lp lq lr ls lt lu lv lw lx ly im bi translated">下一步，我们必须查看数据集的“文本”字段中有什么类型的内容。为此，我们必须先清理文本。</p><p id="4f6e" class="pw-post-body-paragraph ld le it lf b lg lh kd li lj lk kg ll lm ln lo lp lq lr ls lt lu lv lw lx ly im bi translated">典型的文本清理过程包括以下步骤</p><ol class=""><li id="aa76" class="nf ng it lf b lg lh lj lk lm nh lq ni lu nj ly nk nl nm nn bi translated">转换成小写</li><li id="b574" class="nf ng it lf b lg no lj np lm nq lq nr lu ns ly nk nl nm nn bi translated">删除标点符号</li><li id="335c" class="nf ng it lf b lg no lj np lm nq lq nr lu ns ly nk nl nm nn bi translated">整数、数字的移除</li><li id="6379" class="nf ng it lf b lg no lj np lm nq lq nr lu ns ly nk nl nm nn bi translated">移除多余的空格</li><li id="6cd4" class="nf ng it lf b lg no lj np lm nq lq nr lu ns ly nk nl nm nn bi translated">移除标签(如、<p>等)</p></li><li id="ca56" class="nf ng it lf b lg no lj np lm nq lq nr lu ns ly nk nl nm nn bi translated">删除停用词(如“and”、“to”、“the”等)</li><li id="067f" class="nf ng it lf b lg no lj np lm nq lq nr lu ns ly nk nl nm nn bi translated">词干(将单词转换成词根形式)</li></ol><p id="6e5f" class="pw-post-body-paragraph ld le it lf b lg lh kd li lj lk kg ll lm ln lo lp lq lr ls lt lu lv lw lx ly im bi translated">我们将使用Python ' <strong class="lf jd"> gensim </strong>'库来清理所有文本。</p><figure class="ks kt ku kv gt kw"><div class="bz fp l di"><div class="my mz l"/></div></figure><p id="e9b2" class="pw-post-body-paragraph ld le it lf b lg lh kd li lj lk kg ll lm ln lo lp lq lr ls lt lu lv lw lx ly im bi translated">我们可以使用这个'<em class="lz"> clean_text' </em>函数来完成这项工作。</p><p id="5143" class="pw-post-body-paragraph ld le it lf b lg lh kd li lj lk kg ll lm ln lo lp lq lr ls lt lu lv lw lx ly im bi translated">让我们打印一条记录的文本字段的第一个内容</p><pre class="ks kt ku kv gt nt nu nv nw aw nx bi"><span id="6ede" class="ny mb it nu b gy nz oa l ob oc">bbc_text_df.iloc[2,1]</span></pre><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi od"><img src="../Images/9eb6056c9ee118209ef89f26c6d698e2.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*4rJ2f7H6ijww1FswjG1QvQ.png"/></div></div><figcaption class="nb nc gj gh gi nd ne bd b be z dk translated">图3</figcaption></figure><p id="3fec" class="pw-post-body-paragraph ld le it lf b lg lh kd li lj lk kg ll lm ln lo lp lq lr ls lt lu lv lw lx ly im bi translated">清洁后</p><pre class="ks kt ku kv gt nt nu nv nw aw nx bi"><span id="3ed3" class="ny mb it nu b gy nz oa l ob oc">clean_text(bbc_text_df.iloc[2,1])</span></pre><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi oe"><img src="../Images/29219033e891be402755d607fbba3479.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Dtbg7OaHTfSZdmcHgqLSBQ.png"/></div></div><figcaption class="nb nc gj gh gi nd ne bd b be z dk translated">图4</figcaption></figure><p id="2369" class="pw-post-body-paragraph ld le it lf b lg lh kd li lj lk kg ll lm ln lo lp lq lr ls lt lu lv lw lx ly im bi translated">这篇课文变得有点不合语法，但它是理解所必需的。</p><p id="4427" class="pw-post-body-paragraph ld le it lf b lg lh kd li lj lk kg ll lm ln lo lp lq lr ls lt lu lv lw lx ly im bi translated">我们将编写一个函数，将“文本”内容可视化为“单词云”</p><figure class="ks kt ku kv gt kw"><div class="bz fp l di"><div class="my mz l"/></div></figure><p id="c616" class="pw-post-body-paragraph ld le it lf b lg lh kd li lj lk kg ll lm ln lo lp lq lr ls lt lu lv lw lx ly im bi translated">我们必须连接所有文本，并将其传递给该函数</p><pre class="ks kt ku kv gt nt nu nv nw aw nx bi"><span id="afee" class="ny mb it nu b gy nz oa l ob oc">texts = ''<br/>for index, item in bbc_text_df.iterrows():<br/>    texts = texts + ' ' + clean_text(item['text'])<br/>    <br/>plot_word_cloud(texts)</span></pre><p id="f0f3" class="pw-post-body-paragraph ld le it lf b lg lh kd li lj lk kg ll lm ln lo lp lq lr ls lt lu lv lw lx ly im bi translated">我们现在就去</p><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div class="gh gi of"><img src="../Images/464d552fd035415eee92e56fe8cba2ee.png" data-original-src="https://miro.medium.com/v2/resize:fit:1180/format:webp/1*RvOq22Aa2N4G9ixrxshQtg.png"/></div><figcaption class="nb nc gj gh gi nd ne bd b be z dk translated">图5</figcaption></figure><p id="d3c4" class="pw-post-body-paragraph ld le it lf b lg lh kd li lj lk kg ll lm ln lo lp lq lr ls lt lu lv lw lx ly im bi translated">更大的单词表示“更频繁”。所以，'<em class="lz">年'，'时间'，'人'</em>等是最常用的词。</p><p id="1dd0" class="pw-post-body-paragraph ld le it lf b lg lh kd li lj lk kg ll lm ln lo lp lq lr ls lt lu lv lw lx ly im bi translated">现在，我们将看到更有意义的见解:特定“类别”的“文本”的“词云”。</p><p id="b785" class="pw-post-body-paragraph ld le it lf b lg lh kd li lj lk kg ll lm ln lo lp lq lr ls lt lu lv lw lx ly im bi translated">我们将为此编写一个通用函数</p><figure class="ks kt ku kv gt kw"><div class="bz fp l di"><div class="my mz l"/></div></figure><p id="bfa8" class="pw-post-body-paragraph ld le it lf b lg lh kd li lj lk kg ll lm ln lo lp lq lr ls lt lu lv lw lx ly im bi translated">我们将看到“类别”“技术”的“词云”</p><pre class="ks kt ku kv gt nt nu nv nw aw nx bi"><span id="892c" class="ny mb it nu b gy nz oa l ob oc">plot_word_cloud_for_category(bbc_text_df,'tech')</span></pre><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div class="gh gi of"><img src="../Images/1612e5e4fc15e4f3f8ceeea1969e33fe.png" data-original-src="https://miro.medium.com/v2/resize:fit:1180/format:webp/1*sgI495g51PqjqTUoCpNlgg.png"/></div><figcaption class="nb nc gj gh gi nd ne bd b be z dk translated">图6</figcaption></figure><p id="4576" class="pw-post-body-paragraph ld le it lf b lg lh kd li lj lk kg ll lm ln lo lp lq lr ls lt lu lv lw lx ly im bi translated">因此，对于“技术”类别，最常见的词是“peopl”、“techlog”、“game”等。</p><p id="6f0b" class="pw-post-body-paragraph ld le it lf b lg lh kd li lj lk kg ll lm ln lo lp lq lr ls lt lu lv lw lx ly im bi translated">“运动”也是如此</p><pre class="ks kt ku kv gt nt nu nv nw aw nx bi"><span id="eeb6" class="ny mb it nu b gy nz oa l ob oc">plot_word_cloud_for_category(bbc_text_df,'sport')</span></pre><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div class="gh gi of"><img src="../Images/b17bc657a90562761ae5caf604331646.png" data-original-src="https://miro.medium.com/v2/resize:fit:1180/format:webp/1*TJDDPHlxGhRURQOPivsIVg.png"/></div><figcaption class="nb nc gj gh gi nd ne bd b be z dk translated">图7</figcaption></figure><p id="1f4b" class="pw-post-body-paragraph ld le it lf b lg lh kd li lj lk kg ll lm ln lo lp lq lr ls lt lu lv lw lx ly im bi translated">最常用的词是“比赛”、“游戏”、“玩家”、“胜利”、“比赛”、“英格兰”等</p><p id="ff9e" class="pw-post-body-paragraph ld le it lf b lg lh kd li lj lk kg ll lm ln lo lp lq lr ls lt lu lv lw lx ly im bi translated">对于“政治”类别</p><pre class="ks kt ku kv gt nt nu nv nw aw nx bi"><span id="ca8f" class="ny mb it nu b gy nz oa l ob oc">plot_word_cloud_for_category(bbc_text_df,'politics')</span></pre><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div class="gh gi of"><img src="../Images/ea4a5e2832cb0b3933aecb280f244b20.png" data-original-src="https://miro.medium.com/v2/resize:fit:1180/format:webp/1*0TloduUL1lQN6RrNCxl2cA.png"/></div><figcaption class="nb nc gj gh gi nd ne bd b be z dk translated">图8</figcaption></figure><p id="181e" class="pw-post-body-paragraph ld le it lf b lg lh kd li lj lk kg ll lm ln lo lp lq lr ls lt lu lv lw lx ly im bi translated">“治理”、“人民”、“布莱尔”、“国家”、“部长”是最常用的词。</p><blockquote class="og oh oi"><p id="2084" class="ld le lz lf b lg lh kd li lj lk kg ll oj ln lo lp ok lr ls lt ol lv lw lx ly im bi translated">毫无疑问，每个类别都有一些区别于其他类别的词。或者可能是这样的:每一个“文本”都在推断一些决定其类别的上下文</p><p id="b3bb" class="ld le lz lf b lg lh kd li lj lk kg ll oj ln lo lp ok lr ls lt ol lv lw lx ly im bi translated">我们需要进行向量空间分析，并在模型中使用它来确认上述事实</p></blockquote><h1 id="5d64" class="ma mb it bd mc md me mf mg mh mi mj mk ki ml kj mm kl mn km mo ko mp kp mq mr bi translated">向量空间建模&amp;构建管道</h1><p id="8aa6" class="pw-post-body-paragraph ld le it lf b lg ms kd li lj mt kg ll lm mu lo lp lq mv ls lt lu mw lw lx ly im bi translated">向量空间建模对于任何NLP问题都是必不可少的。我们将尝试两个最流行的向量空间模型:“Doc2Vec”和“Tf-Idf”。首先，我们将把数据分成特征和类别。</p><pre class="ks kt ku kv gt nt nu nv nw aw nx bi"><span id="78e6" class="ny mb it nu b gy nz oa l ob oc">df_x = bbc_text_df['text']<br/>df_y = bbc_text_df['category']</span></pre><h2 id="3d6f" class="ny mb it bd mc om on dn mg oo op dp mk lm oq or mm lq os ot mo lu ou ov mq iz bi translated">Doc2Vec</h2><p id="9f0b" class="pw-post-body-paragraph ld le it lf b lg ms kd li lj mt kg ll lm mu lo lp lq mv ls lt lu mw lw lx ly im bi translated">我们将使用'<em class="lz"> gensim </em>'库的Doc2Vec API，并编写一个通用的' Doc2VecTransfoemer '</p><figure class="ks kt ku kv gt kw"><div class="bz fp l di"><div class="my mz l"/></div></figure><p id="9a23" class="pw-post-body-paragraph ld le it lf b lg lh kd li lj lk kg ll lm ln lo lp lq lr ls lt lu lv lw lx ly im bi translated">我们将通过应用这个转换器来看看“Doc2Vec”是什么样子的</p><pre class="ks kt ku kv gt nt nu nv nw aw nx bi"><span id="b7aa" class="ny mb it nu b gy nz oa l ob oc">doc2vec_trf = Doc2VecTransformer()<br/>doc2vec_features = doc2vec_trf.fit(df_x).transform(df_x)<br/>doc2vec_features</span></pre><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi ow"><img src="../Images/3ce86a2177350b122a0fab4f47fd74e8.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*-llv8yszgwMWdMqjbaADag.png"/></div></div><figcaption class="nb nc gj gh gi nd ne bd b be z dk translated">图9</figcaption></figure><p id="642f" class="pw-post-body-paragraph ld le it lf b lg lh kd li lj lk kg ll lm ln lo lp lq lr ls lt lu lv lw lx ly im bi translated">因此，它是文本数据的数字表示。我们可以在任何机器学习算法中使用这些数字特征。我们将尝试与<em class="lz">物流回收，随机森林&amp; XGBoost </em></p><blockquote class="og oh oi"><p id="dfd8" class="ld le lz lf b lg lh kd li lj lk kg ll oj ln lo lp ok lr ls lt ol lv lw lx ly im bi translated">对于每种情况，我们将使用数据集对模型进行5重交叉验证，并对其进行测试。准确度分数将是5倍的平均值。</p></blockquote><p id="0729" class="pw-post-body-paragraph ld le it lf b lg lh kd li lj lk kg ll lm ln lo lp lq lr ls lt lu lv lw lx ly im bi translated"><strong class="lf jd"> Doc2Vec &amp;物流回收管道</strong></p><figure class="ks kt ku kv gt kw"><div class="bz fp l di"><div class="my mz l"/></div></figure><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi ox"><img src="../Images/63250d07985cf2b2be87d7a2cda350f1.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*EH8AEfOLOkzCjEAGpLPKxg.png"/></div></div><figcaption class="nb nc gj gh gi nd ne bd b be z dk translated">图10</figcaption></figure><p id="fdf0" class="pw-post-body-paragraph ld le it lf b lg lh kd li lj lk kg ll lm ln lo lp lq lr ls lt lu lv lw lx ly im bi translated">准确度非常低！！</p><p id="185e" class="pw-post-body-paragraph ld le it lf b lg lh kd li lj lk kg ll lm ln lo lp lq lr ls lt lu lv lw lx ly im bi translated">我们会看到其他的分类器</p><p id="0fa6" class="pw-post-body-paragraph ld le it lf b lg lh kd li lj lk kg ll lm ln lo lp lq lr ls lt lu lv lw lx ly im bi translated"><strong class="lf jd"> Doc2Vec &amp; RandomForest管道</strong></p><figure class="ks kt ku kv gt kw"><div class="bz fp l di"><div class="my mz l"/></div></figure><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi oy"><img src="../Images/a7c9b04d62510dd209c84b21ae9fdc40.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*aS1kz_ZhKfl0Q5b__sAxsA.png"/></div></div><figcaption class="nb nc gj gh gi nd ne bd b be z dk translated">图11</figcaption></figure><p id="0832" class="pw-post-body-paragraph ld le it lf b lg lh kd li lj lk kg ll lm ln lo lp lq lr ls lt lu lv lw lx ly im bi translated">又不好了！！</p><p id="11b8" class="pw-post-body-paragraph ld le it lf b lg lh kd li lj lk kg ll lm ln lo lp lq lr ls lt lu lv lw lx ly im bi translated"><strong class="lf jd"> Doc2Vec &amp; XGBoost管道</strong></p><figure class="ks kt ku kv gt kw"><div class="bz fp l di"><div class="my mz l"/></div></figure><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi oz"><img src="../Images/81808bc4bd6c9bfe12da7e96c87ee75b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*0YvP1TmC81DIhz4N-B6QFQ.png"/></div></div><figcaption class="nb nc gj gh gi nd ne bd b be z dk translated">图12</figcaption></figure><p id="3c59" class="pw-post-body-paragraph ld le it lf b lg lh kd li lj lk kg ll lm ln lo lp lq lr ls lt lu lv lw lx ly im bi translated">没多大改善。</p><p id="befc" class="pw-post-body-paragraph ld le it lf b lg lh kd li lj lk kg ll lm ln lo lp lq lr ls lt lu lv lw lx ly im bi translated">“Doc2Vec”进展不顺利。</p><p id="8f58" class="pw-post-body-paragraph ld le it lf b lg lh kd li lj lk kg ll lm ln lo lp lq lr ls lt lu lv lw lx ly im bi translated">我们将看到“Tf-Idf”向量空间模型</p><h2 id="90a0" class="ny mb it bd mc om on dn mg oo op dp mk lm oq or mm lq os ot mo lu ou ov mq iz bi translated">Tf-Idf</h2><p id="8f1b" class="pw-post-body-paragraph ld le it lf b lg ms kd li lj mt kg ll lm mu lo lp lq mv ls lt lu mw lw lx ly im bi translated">我们也将为“Tf-Idf”编写一个类似的转换器</p><figure class="ks kt ku kv gt kw"><div class="bz fp l di"><div class="my mz l"/></div></figure><p id="3a78" class="pw-post-body-paragraph ld le it lf b lg lh kd li lj lk kg ll lm ln lo lp lq lr ls lt lu lv lw lx ly im bi translated">我们将会看到，它是如何改变文本的</p><pre class="ks kt ku kv gt nt nu nv nw aw nx bi"><span id="5388" class="ny mb it nu b gy nz oa l ob oc">tfidf_transformer = Text2TfIdfTransformer()<br/>tfidf_vectors = tfidf_transformer.fit(df_x).transform(df_x)</span></pre><p id="82e8" class="pw-post-body-paragraph ld le it lf b lg lh kd li lj lk kg ll lm ln lo lp lq lr ls lt lu lv lw lx ly im bi translated">打印其尺寸</p><pre class="ks kt ku kv gt nt nu nv nw aw nx bi"><span id="fa17" class="ny mb it nu b gy nz oa l ob oc">tfidf_vectors.shape</span></pre><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div class="gh gi pa"><img src="../Images/89290ed630fc3803987d92c943098c3f.png" data-original-src="https://miro.medium.com/v2/resize:fit:484/format:webp/1*nUiLI489msfUzOARCARYMw.png"/></div><figcaption class="nb nc gj gh gi nd ne bd b be z dk translated">图13</figcaption></figure><p id="6dbc" class="pw-post-body-paragraph ld le it lf b lg lh kd li lj lk kg ll lm ln lo lp lq lr ls lt lu lv lw lx ly im bi translated">总共有18754个代币</p><pre class="ks kt ku kv gt nt nu nv nw aw nx bi"><span id="4c42" class="ny mb it nu b gy nz oa l ob oc">print(tfidf_vectors)</span></pre><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div class="gh gi pb"><img src="../Images/66c2327d40c99dca6e50677df0770608.png" data-original-src="https://miro.medium.com/v2/resize:fit:1396/format:webp/1*pi71gzoHC7ojNWr6SKl7PA.png"/></div><figcaption class="nb nc gj gh gi nd ne bd b be z dk translated">图14</figcaption></figure><p id="ae90" class="pw-post-body-paragraph ld le it lf b lg lh kd li lj lk kg ll lm ln lo lp lq lr ls lt lu lv lw lx ly im bi translated">现在，我们将在实际的ML模型中使用这个模型</p><p id="98a5" class="pw-post-body-paragraph ld le it lf b lg lh kd li lj lk kg ll lm ln lo lp lq lr ls lt lu lv lw lx ly im bi translated"><strong class="lf jd"> Tf-Idf &amp;后勤返回</strong></p><figure class="ks kt ku kv gt kw"><div class="bz fp l di"><div class="my mz l"/></div></figure><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi pc"><img src="../Images/c7bf236b7937ce6eefc33fd8a4216f52.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*4I0D3C9NTrJ4ml2ejtdIRg.png"/></div></div><figcaption class="nb nc gj gh gi nd ne bd b be z dk translated">图15</figcaption></figure><p id="0bce" class="pw-post-body-paragraph ld le it lf b lg lh kd li lj lk kg ll lm ln lo lp lq lr ls lt lu lv lw lx ly im bi translated">Tf-Idf给出了很好的准确性！！</p><p id="a3d9" class="pw-post-body-paragraph ld le it lf b lg lh kd li lj lk kg ll lm ln lo lp lq lr ls lt lu lv lw lx ly im bi translated"><strong class="lf jd">Tf-Idf&amp;random forest</strong></p><figure class="ks kt ku kv gt kw"><div class="bz fp l di"><div class="my mz l"/></div></figure><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi pd"><img src="../Images/545e348c3b96bfef30c56a4cbe3a73e7.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*MGR5jCXD_pM1I5NH2dHRTg.png"/></div></div><figcaption class="nb nc gj gh gi nd ne bd b be z dk translated">图16</figcaption></figure><p id="c064" class="pw-post-body-paragraph ld le it lf b lg lh kd li lj lk kg ll lm ln lo lp lq lr ls lt lu lv lw lx ly im bi translated"><strong class="lf jd"> Tf-Idf &amp; XGBoost </strong></p><figure class="ks kt ku kv gt kw"><div class="bz fp l di"><div class="my mz l"/></div></figure><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi pe"><img src="../Images/255bc9fc0a234970620aa1a3e26157f2.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*uMXoB1aK-10DJZCFlWBSxw.png"/></div></div><figcaption class="nb nc gj gh gi nd ne bd b be z dk translated">图17</figcaption></figure><p id="7eb0" class="pw-post-body-paragraph ld le it lf b lg lh kd li lj lk kg ll lm ln lo lp lq lr ls lt lu lv lw lx ly im bi translated">所以，最好的终于来了！！</p><blockquote class="og oh oi"><p id="d141" class="ld le lz lf b lg lh kd li lj lk kg ll oj ln lo lp ok lr ls lt ol lv lw lx ly im bi translated"><strong class="lf jd">当然，Tf-Idf &amp; XGBoost组合将是我们解决这个问题的选择</strong></p></blockquote><h1 id="c944" class="ma mb it bd mc md me mf mg mh mi mj mk ki ml kj mm kl mn km mo ko mp kp mq mr bi translated">结果的解释</h1><p id="60ef" class="pw-post-body-paragraph ld le it lf b lg ms kd li lj mt kg ll lm mu lo lp lq mv ls lt lu mw lw lx ly im bi translated">虽然“Doc2Vec”是NLP中比“Tf-Idf”更高级的模型，但在我们的情况下，它仍然没有给出正确的结果。我们分别尝试了基于线性、bagging和boosting的分类器。</p><p id="0235" class="pw-post-body-paragraph ld le it lf b lg lh kd li lj lk kg ll lm ln lo lp lq lr ls lt lu lv lw lx ly im bi translated">这个原因可以解释。在我们的数据集中，每个“文本”字段包含几个确定其类别的单词/标记，这些单词/标记的出现频率相当高。因此，建立一个上下文敏感的模型可能会使情况变得过于复杂，或者淡化这些信息。由于某些标记在某些文本类别中的出现频率很高，因此它在确定“Tf-Idf”时贡献了足够大的值。此外，“文本”是特定领域的。</p><blockquote class="og oh oi"><p id="6dc5" class="ld le lz lf b lg lh kd li lj lk kg ll oj ln lo lp ok lr ls lt ol lv lw lx ly im bi translated">例如，极有可能‘布莱尔’一词将出现在‘政治’类别中，而不是‘体育’类别中。所以这种存在有助于“Tf-Idf”。</p><p id="b4f0" class="ld le lz lf b lg lh kd li lj lk kg ll oj ln lo lp ok lr ls lt ol lv lw lx ly im bi translated">此外,“Doc2Vec”模式更适合写得非常好的语法正确的文本。在我们的例子中，文本在本质上是相当粗糙的。</p><p id="d1cd" class="ld le lz lf b lg lh kd li lj lk kg ll oj ln lo lp ok lr ls lt ol lv lw lx ly im bi translated">语法正确的文本的一个例子可以是“维基百科”文本。</p><p id="347f" class="ld le lz lf b lg lh kd li lj lk kg ll oj ln lo lp ok lr ls lt ol lv lw lx ly im bi translated"><strong class="lf jd">在各种例子和数据科学家的实验中也证明，虽然“Tf-Idf”模型不如“Doc2Vec ”,但它在分类非常特定领域的文本时仍然给出更好的结果。</strong></p></blockquote><h1 id="656a" class="ma mb it bd mc md me mf mg mh mi mj mk ki ml kj mm kl mn km mo ko mp kp mq mr bi translated">结论</h1><p id="5b1d" class="pw-post-body-paragraph ld le it lf b lg ms kd li lj mt kg ll lm mu lo lp lq mv ls lt lu mw lw lx ly im bi translated">现在该结束了。我们测试了分类器和向量空间模型的所有组合。这个Jupyter笔记本可以在<a class="ae mx" href="https://github.com/avisheknag17/public_ml_models/blob/master/bbc_articles_text_classification/notebook/text_classification_xgboost_others.ipynb" rel="noopener ugc nofollow" target="_blank"> GitHub </a>上找到。</p><div class="pf pg gp gr ph pi"><a href="https://github.com/avisheknag17/public_ml_models/blob/master/bbc_articles_text_classification/notebook/text_classification_xgboost_others.ipynb" rel="noopener  ugc nofollow" target="_blank"><div class="pj ab fo"><div class="pk ab pl cl cj pm"><h2 class="bd jd gy z fp pn fr fs po fu fw jc bi translated">avisheknag17/public_ml_models</h2><div class="pp l"><h3 class="bd b gy z fp pn fr fs po fu fw dk translated">在GitHub上创建一个帐户，为avisheknag17/public_ml_models开发做出贡献。</h3></div><div class="pq l"><p class="bd b dl z fp pn fr fs po fu fw dk translated">github.com</p></div></div><div class="pr l"><div class="ps l pt pu pv pr pw lb pi"/></div></div></a></div><p id="c1d6" class="pw-post-body-paragraph ld le it lf b lg lh kd li lj lk kg ll lm ln lo lp lq lr ls lt lu lv lw lx ly im bi translated">最近，我写了一本关于ML(<a class="ae mx" href="https://twitter.com/bpbonline/status/1256146448346988546" rel="noopener ugc nofollow" target="_blank">https://twitter.com/bpbonline/status/1256146448346988546</a>)的书</p></div></div>    
</body>
</html>