<html>
<head>
<title>CityNeRF: 3D Rendering at City Scale!</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">CityNeRF:城市比例的3D渲染！</h1>
<blockquote>原文：<a href="https://pub.towardsai.net/technology-fcb0fbfa9c00?source=collection_archive---------2-----------------------#2021-12-20">https://pub.towardsai.net/technology-fcb0fbfa9c00?source=collection_archive---------2-----------------------#2021-12-20</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><h2 id="7fe2" class="ir is it bd b dl iu iv iw ix iy iz dk ja translated" aria-label="kicker paragraph"><a class="ae ep" href="https://towardsai.net/p/category/technology" rel="noopener ugc nofollow" target="_blank">技术</a></h2><div class=""/><div class=""><h2 id="b5be" class="pw-subtitle-paragraph jz jc it bd b ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq dk translated">以任何比例生成具有高质量细节的城市级3D场景！</h2></div><blockquote class="kr ks kt"><p id="0501" class="ku kv kw kx b ky kz kd la lb lc kg ld le lf lg lh li lj lk ll lm ln lo lp lq im bi translated">原载于<a class="ae lr" href="https://www.louisbouchard.ai/citynerf/" rel="noopener ugc nofollow" target="_blank"> louisbouchard.ai </a>，前两天在<a class="ae lr" href="https://www.louisbouchard.ai/citynerf/" rel="noopener ugc nofollow" target="_blank">我的博客</a>上看到的！</p></blockquote><figure class="ls lt lu lv gt lw"><div class="bz fp l di"><div class="lx ly l"/></div></figure><p id="3b83" class="pw-post-body-paragraph ku kv it kx b ky kz kd la lb lc kg ld lz lf lg lh ma lj lk ll mb ln lo lp lq im bi translated">去年，我们看到NeRF、NeRV和其他网络能够使用人工智能从图像中创建3D模型和小场景。现在，我们正在迈出一小步，生成一个更复杂的模型:整个城市。是的，你没听错，本周的文章是关于在任何比例下生成具有高质量细节的城市级3D场景。它从卫星视角到地面，用一个模型就能工作。多神奇啊。！我们在一年内从一个看起来还可以的物体变成了整个城市！接下来是什么！？我都不敢想象。</p><figure class="ls lt lu lv gt lw gh gi paragraph-image"><div class="gh gi mc"><img src="../Images/b8d66d93723844d154364ebcdd729e9c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1280/1*ysOqLN2awAfgWapEG-NSWQ.gif"/></div><figcaption class="mf mg gj gh gi mh mi bd b be z dk translated">地球尺度的曼哈顿。图片来自<a class="ae lr" href="https://city-super.github.io/citynerf/" rel="noopener ugc nofollow" target="_blank"> CityNeRF的网站</a>。</figcaption></figure><p id="4f5c" class="pw-post-body-paragraph ku kv it kx b ky kz kd la lb lc kg ld lz lf lg lh ma lj lk ll mb ln lo lp lq im bi translated">这个模型被称为CityNeRF，它是从NeRF发展而来的，我之前在我的频道中介绍过。NeRF是首批使用辐射场和机器学习从图像中构建3D模型的模型之一。但是NeRF并不是那么有效，而且只适用于单一规模。在这里，CityNeRF同时应用于卫星和地面图像，为任何视点生成各种3D模型比例。简而言之，他们将NeRF带到了城市规模。但是怎么做呢？</p><figure class="ls lt lu lv gt lw gh gi paragraph-image"><a href="http://eepurl.com/huGLT5"><div class="gh gi mj"><img src="../Images/887ba5f0342edcd9c1ea39e658e41380.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*n_jdn2ImX6HWoKy0.png"/></div></a></figure><p id="70ab" class="pw-post-body-paragraph ku kv it kx b ky kz kd la lb lc kg ld lz lf lg lh ma lj lk ll mb ln lo lp lq im bi translated">如果你还没有听说过这个模型的话，我将不会讨论NeRF是如何工作的，因为我已经在文章<a class="ae lr" href="https://medium.com/what-is-artificial-intelligence/generate-a-complete-3d-scene-under-arbitrary-lighting-conditions-from-a-set-of-input-images-9d2fbce63243" rel="noopener">中讨论过了。相反，我将主要介绍不同之处，以及CityNeRF为最初的NeRF方法带来了什么，使其具有多种规模。</a></p><figure class="ls lt lu lv gt lw gh gi paragraph-image"><div role="button" tabindex="0" class="ml mm di mn bf mo"><div class="gh gi mk"><img src="../Images/8a77400ab0d5314e5791354cf6ddd889.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*3ZmRWYVSMYeExgktAEUJ3g.png"/></div></div><figcaption class="mf mg gj gh gi mh mi bd b be z dk translated">NeRF概述。图片来自<a class="ae lr" href="https://arxiv.org/pdf/2003.08934.pdf" rel="noopener ugc nofollow" target="_blank">纸张</a>。</figcaption></figure><p id="6293" class="pw-post-body-paragraph ku kv it kx b ky kz kd la lb lc kg ld lz lf lg lh ma lj lk ll mb ln lo lp lq im bi translated">在这里，他们不是拥有相距几厘米的不同照片，而是拥有相距数千公里的照片，从卫星到路上拍摄的照片。如你所见，NeRF一个人无法使用如此截然不同的图片来重建场景。简而言之，使用多层感知器的权重，一个基本的神经网络，NeRF将处理所有预先知道其视点位置的图像。NeRF将使用来自相机的光线找到每个像素的颜色和密度。因此，它知道相机的方向，并可以使用所有阵列来了解深度和相应的颜色。然后，使用损失函数针对神经网络的收敛对该过程进行优化，该损失函数将使我们在训练时更接近地面真实情况，这是我们旨在实现的真实3D模型。</p><figure class="ls lt lu lv gt lw gh gi paragraph-image"><div role="button" tabindex="0" class="ml mm di mn bf mo"><div class="gh gi mp"><img src="../Images/252b2de03d3cda919b648f08dd21a93a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*uaHlYRsuXwy4x7zmuCYBfA.png"/></div></div><figcaption class="mf mg gj gh gi mh mi bd b be z dk translated">图片来自<a class="ae lr" href="https://city-super.github.io/citynerf/" rel="noopener ugc nofollow" target="_blank"> CityNeRF的论文</a>。</figcaption></figure><p id="bdf1" class="pw-post-body-paragraph ku kv it kx b ky kz kd la lb lc kg ld lz lf lg lh ma lj lk ll mb ln lo lp lq im bi translated">正如您在上面看到的，问题是渲染场景的质量是在最具代表性的距离上平均化的，这使得特定的视点看起来模糊不清。尤其是因为我们通常可以获得比近景更多的卫星图像。我们可以尝试通过独立地用不同的尺度训练算法来解决这个问题，但正如他们解释的那样，这导致了连续尺度之间的显著差异。所以你不可能一直放大并拥有流畅好看的3D场景。</p><figure class="ls lt lu lv gt lw gh gi paragraph-image"><div role="button" tabindex="0" class="ml mm di mn bf mo"><div class="gh gi mq"><img src="../Images/f158f91338f2a0c36edc3d4c274239f3.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*GNW-gNuFuPz1N1ai1DDdMQ.png"/></div></div><figcaption class="mf mg gj gh gi mh mi bd b be z dk translated">与使用L变量的秤的区别。图片来自<a class="ae lr" href="https://city-super.github.io/citynerf/" rel="noopener ugc nofollow" target="_blank"> CityNeRF的论文</a>。</figcaption></figure><p id="d2f2" class="pw-post-body-paragraph ku kv it kx b ky kz kd la lb lc kg ld lz lf lg lh ma lj lk ll mb ln lo lp lq im bi translated">相反，他们以渐进的方式训练他们的模型。这意味着他们在多个步骤中独立地训练他们的模型，其中每个新步骤都从前一步骤的学习参数开始。这些步骤适用于基于相机与感兴趣对象的距离的特定分辨率，这里用l。</p><p id="23c8" class="pw-post-body-paragraph ku kv it kx b ky kz kd la lb lc kg ld lz lf lg lh ma lj lk ll mb ln lo lp lq im bi translated">因此，每一步都有其预处理过的图像包，这些图像包将被后续步骤训练和进一步改进。从远处的卫星图像到越来越多的放大图像，模型可以添加细节，并随着时间的推移建立更好的基础。</p><figure class="ls lt lu lv gt lw gh gi paragraph-image"><div role="button" tabindex="0" class="ml mm di mn bf mo"><div class="gh gi mr"><img src="../Images/63bc5a37b6cc10ad0ff1224789c4962d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Oni_zTpWXL5wROZV4g-1YQ.png"/></div></div><figcaption class="mf mg gj gh gi mh mi bd b be z dk translated">渐进式多尺度训练概述。图片来自<a class="ae lr" href="https://city-super.github.io/citynerf/" rel="noopener ugc nofollow" target="_blank"> CityNeRF的论文</a>。</figcaption></figure><p id="754d" class="pw-post-body-paragraph ku kv it kx b ky kz kd la lb lc kg ld lz lf lg lh ma lj lk ll mb ln lo lp lq im bi translated">如此处所示，他们首先在L1(最远的视图)上训练模型，并以地面图像结束，总是添加到网络中，并从学习到的参数步骤到不同的比例对模型进行微调。因此，这个简单的变量L控制细节层次，模型的其余部分在每个阶段保持不变，而不是像我们通常看到的那样，每个比例都有一个金字塔状的架构。该模型的其余部分基本上是针对这一任务的NeRF的改进和改编版本。</p><p id="3a38" class="pw-post-body-paragraph ku kv it kx b ky kz kd la lb lc kg ld lz lf lg lh ma lj lk ll mb ln lo lp lq im bi translated">你可以在下面链接的伟大论文中了解更多关于实现的细节和与NeRF的区别！如果您感兴趣的话，很快就可以试用这些代码了。</p><figure class="ls lt lu lv gt lw gh gi paragraph-image"><div class="gh gi ms"><img src="../Images/daf0c69dcdc17057dbc3551a5ba2cd6b.png" data-original-src="https://miro.medium.com/v2/resize:fit:960/1*TgUPBer4EPi6rRxljv9DGg.gif"/></div><figcaption class="mf mg gj gh gi mh mi bd b be z dk translated">洛杉矶。图片来自<a class="ae lr" href="https://city-super.github.io/citynerf/" rel="noopener ugc nofollow" target="_blank"> CityNeRF的网站</a>。</figcaption></figure><p id="bd16" class="pw-post-body-paragraph ku kv it kx b ky kz kd la lb lc kg ld lz lf lg lh ma lj lk ll mb ln lo lp lq im bi translated">瞧！这就是他们如何使<a class="ae lr" href="https://medium.com/what-is-artificial-intelligence/generate-a-complete-3d-scene-under-arbitrary-lighting-conditions-from-a-set-of-input-images-9d2fbce63243" rel="noopener"> NeRF </a>应用于城市规模的场景并产生惊人的效果！它具有不可思议的工业潜力，我希望很快看到更多这方面的工作！感谢您的阅读，如果您还没有跟上我，请考虑点击这个小按钮。这是免费的，你会学到很多东西！我保证；p</p><p id="2237" class="pw-post-body-paragraph ku kv it kx b ky kz kd la lb lc kg ld lz lf lg lh ma lj lk ll mb ln lo lp lq im bi translated">今年年底，我将分享一些特别的文章。</p><p id="a49f" class="pw-post-body-paragraph ku kv it kx b ky kz kd la lb lc kg ld lz lf lg lh ma lj lk ll mb ln lo lp lq im bi translated">敬请期待！</p><figure class="ls lt lu lv gt lw gh gi paragraph-image"><a href="https://www.louisbouchard.ai/learnai/"><div class="gh gi mt"><img src="../Images/851f810faaaee9adb73f73c67e4e4395.png" data-original-src="https://miro.medium.com/v2/resize:fit:924/format:webp/0*3SQzL1OrCq34Mdey.png"/></div></a></figure></div><div class="ab cl mu mv hx mw" role="separator"><span class="mx bw bk my mz na"/><span class="mx bw bk my mz na"/><span class="mx bw bk my mz"/></div><div class="im in io ip iq"><p id="f132" class="pw-post-body-paragraph ku kv it kx b ky kz kd la lb lc kg ld lz lf lg lh ma lj lk ll mb ln lo lp lq im bi translated">如果你喜欢我的工作，并想了解人工智能的最新动态，你绝对应该关注我的其他社交媒体账户(<a class="ae lr" href="https://www.linkedin.com/in/whats-ai/" rel="noopener ugc nofollow" target="_blank"> LinkedIn </a>，<a class="ae lr" href="https://twitter.com/Whats_AI" rel="noopener ugc nofollow" target="_blank"> Twitter </a>)，并订阅我的每周人工智能<a class="ae lr" href="http://eepurl.com/huGLT5" rel="noopener ugc nofollow" target="_blank"> <strong class="kx jd">简讯</strong> </a>！</p><h2 id="bcfd" class="nb nc it bd nd ne nf dn ng nh ni dp nj lz nk nl nm ma nn no np mb nq nr ns iz bi translated">支持我:</h2><ul class=""><li id="9ffd" class="nt nu it kx b ky nv lb nw lz nx ma ny mb nz lq oa ob oc od bi translated">支持我的最好方式是成为这个网站<strong class="kx jd"> </strong>的成员，或者如果你喜欢视频格式，在<strong class="kx jd"> YouTube </strong>上订阅我的频道<strong class="kx jd"> </strong>。</li><li id="3bbf" class="nt nu it kx b ky oe lb of lz og ma oh mb oi lq oa ob oc od bi translated">跟我来这里上<a class="ae lr" href="https://whats-ai.medium.com/" rel="noopener"> <strong class="kx jd">中</strong> </a></li><li id="3c9a" class="nt nu it kx b ky oe lb of lz og ma oh mb oi lq oa ob oc od bi translated">想进入AI或者提升技能，<a class="ae lr" href="https://www.louisbouchard.ai/learnai/" rel="noopener ugc nofollow" target="_blank">看这个</a>！</li></ul><h2 id="58f9" class="nb nc it bd nd ne nf dn ng nh ni dp nj lz nk nl nm ma nn no np mb nq nr ns iz bi translated">参考</h2><ul class=""><li id="cb5c" class="nt nu it kx b ky nv lb nw lz nx ma ny mb nz lq oa ob oc od bi translated">、杨、徐、林、潘、赵、饶、戴、林，2021。城市NeRF:在城市尺度上建造NeRF。<a class="ae lr" href="https://arxiv.org/pdf/2112.05504.pdf" rel="noopener ugc nofollow" target="_blank">https://arxiv.org/pdf/2112.05504.pdf</a></li><li id="86b5" class="nt nu it kx b ky oe lb of lz og ma oh mb oi lq oa ob oc od bi translated">项目链接:<a class="ae lr" href="https://city-super.github.io/citynerf/" rel="noopener ugc nofollow" target="_blank">https://city-super.github.io/citynerf/</a></li><li id="c83e" class="nt nu it kx b ky oe lb of lz og ma oh mb oi lq oa ob oc od bi translated">代码(即将发布):https://city-super.github.io/citynerf/</li></ul></div></div>    
</body>
</html>