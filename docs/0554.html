<html>
<head>
<title>Image Classification with Ensemble of Deep Neural Networks using TensorFlow + TPUs</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">基于TensorFlow + TPUs的深度神经网络集成图像分类</h1>
<blockquote>原文：<a href="https://pub.towardsai.net/image-classification-with-ensemble-of-deep-neural-networks-using-tensorflow-tpus-24d40d42d74b?source=collection_archive---------0-----------------------#2020-06-05">https://pub.towardsai.net/image-classification-with-ensemble-of-deep-neural-networks-using-tensorflow-tpus-24d40d42d74b?source=collection_archive---------0-----------------------#2020-06-05</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><h2 id="7d64" class="ir is it bd b dl iu iv iw ix iy iz dk ja translated" aria-label="kicker paragraph">深度学习</h2><div class=""/><div class=""><h2 id="0ad6" class="pw-subtitle-paragraph jz jc it bd b ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq dk translated">基于集成深度神经网络的苹果叶部病害检测。</h2></div><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi kr"><img src="../Images/2da4ef0fd7f77482bc2c3e7eee5f5b41.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*fNt25roZOCxAY6tjfcBtng.png"/></div></div><figcaption class="ld le gj gh gi lf lg bd b be z dk translated">来源:谷歌云TPUv3 Pod</figcaption></figure><p id="6284" class="pw-post-body-paragraph lh li it lj b lk ll kd lm ln lo kg lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi md translated"><span class="l me mf mg bm mh mi mj mk ml di"> H </span> ello各位，欢迎来到TensorFlow和Keras的深度学习实用系列。我认为我们大多数人都经历过这样的情况:用海量图像训练一个最先进的深度学习模型需要花费很长时间。这是大多数读者最喜欢的图像分类步骤。你能猜出来吗？。是的，有助于避免模型过度拟合的非常著名的技术是图像增强。随着图像增强，图像的数量会增加一倍、三倍、甚至四倍或更多，这甚至会导致大量的训练时间。本文将帮助您了解如何使用TPU执行多标签图像分类。说了这么多，让我们开始学习吧。</p><h1 id="b045" class="mm mn it bd mo mp mq mr ms mt mu mv mw ki mx kj my kl mz km na ko nb kp nc nd bi translated">什么是TPU？</h1><p id="df84" class="pw-post-body-paragraph lh li it lj b lk ne kd lm ln nf kg lp lq ng ls lt lu nh lw lx ly ni ma mb mc im bi translated">张量处理单元(<strong class="lj jd"> TPU </strong>)是谷歌专门为神经网络机器学习开发的AI加速器专用集成电路(ASIC)，特别是使用谷歌自己的TensorFlow软件。[1]</p><h1 id="e222" class="mm mn it bd mo mp mq mr ms mt mu mv mw ki mx kj my kl mz km na ko nb kp nc nd bi translated">CPU vs. GPU vs. TPU</h1><p id="de94" class="pw-post-body-paragraph lh li it lj b lk ne kd lm ln nf kg lp lq ng ls lt lu nh lw lx ly ni ma mb mc im bi translated"><strong class="lj jd"> CPU: </strong></p><ul class=""><li id="412d" class="nj nk it lj b lk ll ln lo lq nl lu nm ly nn mc no np nq nr bi translated">被称为中央处理器的CPU以闪电般的速度执行算术运算。</li><li id="8504" class="nj nk it lj b lk ns ln nt lq nu lu nv ly nw mc no np nq nr bi translated"><strong class="lj jd">低延迟</strong>，从而加快计算速度。</li><li id="5c51" class="nj nk it lj b lk ns ln nt lq nu lu nv ly nw mc no np nq nr bi translated"><strong class="lj jd">低吞吐量</strong>。</li></ul><p id="d19d" class="pw-post-body-paragraph lh li it lj b lk ll kd lm ln lo kg lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated"><strong class="lj jd">图形处理器:</strong></p><ul class=""><li id="1459" class="nj nk it lj b lk ll ln lo lq nl lu nm ly nn mc no np nq nr bi translated">GPU被称为图形处理单元，以并行处理架构而闻名。</li><li id="22fe" class="nj nk it lj b lk ns ln nt lq nu lu nv ly nw mc no np nq nr bi translated"><strong class="lj jd">高延迟</strong>即与CPU相比，计算速度稍慢。</li><li id="642d" class="nj nk it lj b lk ns ln nt lq nu lu nv ly nw mc no np nq nr bi translated"><strong class="lj jd">高吞吐量</strong>。</li></ul><p id="67d2" class="pw-post-body-paragraph lh li it lj b lk ll kd lm ln lo kg lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated"><strong class="lj jd"> TPU: </strong></p><ul class=""><li id="f6a5" class="nj nk it lj b lk ll ln lo lq nl lu nm ly nn mc no np nq nr bi translated">张量处理单元是Google开发的，特别是用于机器学习的。</li></ul><p id="090d" class="pw-post-body-paragraph lh li it lj b lk ll kd lm ln lo kg lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">所以，现在让我们深入了解一下这个过程，弄清楚计算是如何进行的。</p><p id="b6ae" class="pw-post-body-paragraph lh li it lj b lk ll kd lm ln lo kg lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated"><strong class="lj jd">举例:</strong>考虑你要乘以两个张量，假设[1，2，3]和[4，5，6]。首先，当您使用CPU时，它按顺序执行(1*4)、(2*5)、(3*6)，而如果您使用GPU，它以并行方式执行计算，即所有三个乘法同时执行，无需等待并按顺序进行。</p><p id="6f35" class="pw-post-body-paragraph lh li it lj b lk ll kd lm ln lo kg lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">现在，我要问你一个问题，哪个处理单元花费的时间更少，也就是说，CPU快还是GPU快？。是的，CPU执行速度比GPU快，因为它的延迟低，而GPU的延迟高。那么你可能会问一个问题“嘿，GPU比CPU快对吧？”。完全正确，假设CPU在2ns内执行，如果我们用2ns乘以<strong class="lj jd"> 3( </strong> (1*4)，(2*5)，(3*6) <strong class="lj jd"> ) </strong>，那么总时间是6ns，另一方面，GPU在4ns内执行所有三次乘法。</p><p id="59f2" class="pw-post-body-paragraph lh li it lj b lk ll kd lm ln lo kg lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">这是由谷歌开发的TPUs，旨在与TensorFlow一起使用，具有比(GPU + CPU)更高的处理能力。TPU v3拥有420万亿次浮点运算能力，这意味着它一次可以执行420万亿次浮点运算。</p><p id="5b7f" class="pw-post-body-paragraph lh li it lj b lk ll kd lm ln lo kg lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">假设，我们正在处理包含高分辨率图像的图像数据集，如果我们将它输入到一些最先进的模型中，如EfficientNetB7(以其众多参数和深度而闻名)，与TPUs相比，使用支持GPU的机器会显著增加训练时间。TPU是为人工智能目的而设计的，可以在任何时间内执行复杂的矩阵计算。</p><h1 id="a6b1" class="mm mn it bd mo mp mq mr ms mt mu mv mw ki mx kj my kl mz km na ko nb kp nc nd bi translated">资料组</h1><p id="58f8" class="pw-post-body-paragraph lh li it lj b lk ne kd lm ln nf kg lp lq ng ls lt lu nh lw lx ly ni ma mb mc im bi translated">我们将使用Kaggle植物病理学竞赛数据集。它包含受四种独特类型的叶部疾病影响的苹果树的图片，任务是分类和识别苹果树中的叶部疾病；更多信息可以在<a class="ae nx" href="https://www.kaggle.com/c/plant-pathology-2020-fgvc7" rel="noopener ugc nofollow" target="_blank"> Kaggle </a>上找到。</p><blockquote class="ny"><p id="de67" class="nz oa it bd ob oc od oe of og oh mc dk translated">我们开始吧！</p></blockquote></div><div class="ab cl oi oj hx ok" role="separator"><span class="ol bw bk om on oo"/><span class="ol bw bk om on oo"/><span class="ol bw bk om on"/></div><div class="im in io ip iq"><p id="3d85" class="pw-post-body-paragraph lh li it lj b lk ll kd lm ln lo kg lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">这篇文章是我为植物病理学竞赛提交的内核的演练。我建议你使用Kaggle内核或Google Colab，因为它们提供免费的TPU。😃</p><h1 id="20c1" class="mm mn it bd mo mp mq mr ms mt mu mv mw ki mx kj my kl mz km na ko nb kp nc nd bi translated">初始设置</h1><p id="9a62" class="pw-post-body-paragraph lh li it lj b lk ne kd lm ln nf kg lp lq ng ls lt lu nh lw lx ly ni ma mb mc im bi translated">导入必要的库…</p><figure class="ks kt ku kv gt kw"><div class="bz fp l di"><div class="op oq l"/></div></figure><h1 id="7351" class="mm mn it bd mo mp mq mr ms mt mu mv mw ki mx kj my kl mz km na ko nb kp nc nd bi translated">TPU设置</h1><p id="c404" class="pw-post-body-paragraph lh li it lj b lk ne kd lm ln nf kg lp lq ng ls lt lu nh lw lx ly ni ma mb mc im bi translated">确保您的机器支持TPU。如果你正在使用谷歌Colab，检查你的笔记本设置并启用TPU，或者如果你正在使用Kaggle笔记本检查加速器窗口下的TPU。</p><figure class="ks kt ku kv gt kw"><div class="bz fp l di"><div class="op oq l"/></div></figure><p id="fe31" class="pw-post-body-paragraph lh li it lj b lk ll kd lm ln lo kg lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">可以把它看作配置TPU的样板代码，这样您的模型就可以利用它们。<strong class="lj jd"> TPUClusterResolver() </strong>检查TPU环境并应用分发策略。分布式训练策略就像一种使模型利用TPU的高计算能力的方法。</p><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi or"><img src="../Images/853186e4b4ddc175a553d9ba4dbe0de5.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*TOZT-Qt3Cnwq-StT.png"/></div></div><figcaption class="ld le gj gh gi lf lg bd b be z dk translated">显示TPU数量的输出。</figcaption></figure><p id="9e6e" class="pw-post-body-paragraph lh li it lj b lk ll kd lm ln lo kg lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated"><strong class="lj jd"> get_gcs_path() </strong>获取位于父目录/工作目录中的数据集的路径。</p><h1 id="f431" class="mm mn it bd mo mp mq mr ms mt mu mv mw ki mx kj my kl mz km na ko nb kp nc nd bi translated">读取数据集</h1><figure class="ks kt ku kv gt kw"><div class="bz fp l di"><div class="op oq l"/></div></figure><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi os"><img src="../Images/2202ff5d18214fc6c82b18d4ea117845.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*35nhTAjdhC8n7t33QVq9BQ.png"/></div></div><figcaption class="ld le gj gh gi lf lg bd b be z dk translated">数据集:Train.csv(图片由作者提供)</figcaption></figure><p id="47a6" class="pw-post-body-paragraph lh li it lj b lk ll kd lm ln lo kg lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">Kaggle提供的train，test (CSV)文件包含<strong class="lj jd"> image_id </strong>列下的叶子图像。我们将利用lambda函数并添加<strong class="lj jd">(。jpg) </strong>以便模特可以阅读图片。</p><h1 id="02c0" class="mm mn it bd mo mp mq mr ms mt mu mv mw ki mx kj my kl mz km na ko nb kp nc nd bi translated">数据的加载和扩充</h1><p id="246a" class="pw-post-body-paragraph lh li it lj b lk ne kd lm ln nf kg lp lq ng ls lt lu nh lw lx ly ni ma mb mc im bi translated">当我们处理TPU时，应该使用<strong class="lj jd"> tf.data.Dataset来加载输入数据。</strong>一旦将数据加载到<strong class="lj jd"> tf.data.Dataset </strong>中，API就会提供大量功能，我们可以使用这些功能来训练神经网络。</p><figure class="ks kt ku kv gt kw"><div class="bz fp l di"><div class="op oq l"/></div></figure><p id="2d7c" class="pw-post-body-paragraph lh li it lj b lk ll kd lm ln lo kg lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">最后，我们将数据集映射到<strong class="lj jd"> decode_image() </strong>函数，该函数将加载文件并将其解码为实际数据。<strong class="lj jd"> data_augment() </strong>函数读取每一幅图像并执行放大，这里我们将水平和垂直翻转图像，从而减少过拟合问题并增加数据的方差。</p><h1 id="1b13" class="mm mn it bd mo mp mq mr ms mt mu mv mw ki mx kj my kl mz km na ko nb kp nc nd bi translated"><strong class="ak">学习率调度器</strong></h1><p id="997b" class="pw-post-body-paragraph lh li it lj b lk ne kd lm ln nf kg lp lq ng ls lt lu nh lw lx ly ni ma mb mc im bi translated">深度学习模型调整与其特征相关联的权重，以使损失最小化。在模型训练的过程中，梯度损失被计算，该梯度损失乘以学习率。最后，用旧权值与学习率和梯度损失乘积之差来更新和替换神经网络的权值。学习率被认为是超参数，以便我们可以调整和调整模型性能。</p><figure class="ks kt ku kv gt kw"><div class="bz fp l di"><div class="op oq l"/></div></figure><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi ot"><img src="../Images/a5272e37c684d773e244871f1fc62667.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*owQ-vMdTBLyoT30dmf99kg.png"/></div></div><figcaption class="ld le gj gh gi lf lg bd b be z dk translated">学习率时间表(图片由作者提供)</figcaption></figure><h1 id="be4d" class="mm mn it bd mo mp mq mr ms mt mu mv mw ki mx kj my kl mz km na ko nb kp nc nd bi translated">为什么我们需要集成深度神经网络？</h1><p id="a193" class="pw-post-body-paragraph lh li it lj b lk ne kd lm ln nf kg lp lq ng ls lt lu nh lw lx ly ni ma mb mc im bi translated"><strong class="lj jd">集成学习</strong>将来自多个机器学习模型的预测进行组合，以减少预测的方差和泛化误差。</p><p id="d193" class="pw-post-body-paragraph lh li it lj b lk ll kd lm ln lo kg lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">每个深度学习模型都具有一定的优势，例如，考虑使用<strong class="lj jd"> VGG16 </strong>模型进行特征提取，该模型做得很好，但是已经注意到，在相当大的深度之后，模型的性能开始下降，这实际上是VGG16的瓶颈。这个消失梯度问题由<strong class="lj jd"> ResNet </strong>模型解决。因此，当我们制作这种神经网络的集成时，它有助于减少预测的误差或方差，从而提高准确性。</p><p id="af05" class="pw-post-body-paragraph lh li it lj b lk ll kd lm ln lo kg lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">我们将集合四种网络架构</p><ol class=""><li id="3d6e" class="nj nk it lj b lk ll ln lo lq nl lu nm ly nn mc ou np nq nr bi translated">效率网7。</li><li id="81ef" class="nj nk it lj b lk ns ln nt lq nu lu nv ly nw mc ou np nq nr bi translated"><a class="ae nx" href="https://keras.io/api/applications/efficientnet/#efficientnetb6-function" rel="noopener ugc nofollow" target="_blank">效率网B6 </a></li><li id="8f81" class="nj nk it lj b lk ns ln nt lq nu lu nv ly nw mc ou np nq nr bi translated"><a class="ae nx" href="https://keras.io/api/applications/resnet/#resnet152v2-function" rel="noopener ugc nofollow" target="_blank"> ResNet152V2 </a>。</li><li id="e3e2" class="nj nk it lj b lk ns ln nt lq nu lu nv ly nw mc ou np nq nr bi translated"><a class="ae nx" href="https://keras.io/api/applications/inceptionresnetv2/" rel="noopener ugc nofollow" target="_blank"> InceptionResNetV2 </a>。</li></ol><figure class="ks kt ku kv gt kw"><div class="bz fp l di"><div class="op oq l"/></div></figure><h1 id="7f3f" class="mm mn it bd mo mp mq mr ms mt mu mv mw ki mx kj my kl mz km na ko nb kp nc nd bi translated">培养</h1><figure class="ks kt ku kv gt kw"><div class="bz fp l di"><div class="op oq l"/></div></figure><p id="c781" class="pw-post-body-paragraph lh li it lj b lk ll kd lm ln lo kg lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">当我们使用TPU时，确保通过示波器应用<strong class="lj jd">策略</strong>(在上面的<strong class="lj jd"> TPU设置</strong>模块中定义)，以便模型利用TPU进行训练。因此，必须在<strong class="lj jd">战略范围()内定义模型。</strong>重复上述功能，替换不同的模型并编译、拟合它们。</p><h1 id="3cfc" class="mm mn it bd mo mp mq mr ms mt mu mv mw ki mx kj my kl mz km na ko nb kp nc nd bi translated">预言；预测；预告</h1><p id="df98" class="pw-post-body-paragraph lh li it lj b lk ne kd lm ln nf kg lp lq ng ls lt lu nh lw lx ly ni ma mb mc im bi translated">最后，使用模型对<strong class="lj jd"> test_dataset </strong>执行预测，您可以简单地对所有模型的预测进行平均，并使用它进行评估或乘以一个数字，如图所示(同样，没有使用特定的数字，这只是一种获得最佳分数的调整)</p><figure class="ks kt ku kv gt kw"><div class="bz fp l di"><div class="op oq l"/></div></figure><h1 id="038f" class="mm mn it bd mo mp mq mr ms mt mu mv mw ki mx kj my kl mz km na ko nb kp nc nd bi translated">结论</h1><p id="7d13" class="pw-post-body-paragraph lh li it lj b lk ne kd lm ln nf kg lp lq ng ls lt lu nh lw lx ly ni ma mb mc im bi translated">我希望这篇文章能够帮助您以更加高效和优雅的方式训练您的模型。如果你有任何问题，欢迎在下面的评论中提出来，或者通过<a class="ae nx" href="https://www.linkedin.com/in/vishnudarshan/" rel="noopener ugc nofollow" target="_blank"> LinkedIn </a>联系我。</p><h1 id="e95d" class="mm mn it bd mo mp mq mr ms mt mu mv mw ki mx kj my kl mz km na ko nb kp nc nd bi translated">参考</h1><ol class=""><li id="ab98" class="nj nk it lj b lk ne ln nf lq ov lu ow ly ox mc ou np nq nr bi translated">https://en.wikipedia.org/wiki/Tensor_processing_unit<a class="ae nx" href="https://en.wikipedia.org/wiki/Tensor_processing_unit" rel="noopener ugc nofollow" target="_blank">。</a></li><li id="0e8c" class="nj nk it lj b lk ns ln nt lq nu lu nv ly nw mc ou np nq nr bi translated"><a class="ae nx" href="https://machinelearningmastery.com/ensemble-methods-for-deep-learning-neural-networks/" rel="noopener ugc nofollow" target="_blank">https://machine learning mastery . com/ensemble-methods-for-deep-learning-neural-networks/</a></li></ol><p id="debe" class="pw-post-body-paragraph lh li it lj b lk ll kd lm ln lo kg lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">我希望这篇文章已经帮助你完成了集成深度学习模型的过程。如果你有任何问题，请在下面的评论中提出来，或者通过LinkedIn 联系我。</p><p id="4cc0" class="pw-post-body-paragraph lh li it lj b lk ll kd lm ln lo kg lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">在那之前，我会在下一个里抓住你！😺</p></div></div>    
</body>
</html>