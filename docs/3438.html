<html>
<head>
<title>YouTube Dislikes Prediction in Real-time — Working With a Combination of Data; A Practical Guide</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">YouTube不喜欢实时预测——处理数据组合；实用指南</h1>
<blockquote>原文：<a href="https://pub.towardsai.net/youtube-dislikes-prediction-in-real-time-working-with-a-combination-of-data-a-practical-guide-fb7e88b0b445?source=collection_archive---------3-----------------------#2022-12-23">https://pub.towardsai.net/youtube-dislikes-prediction-in-real-time-working-with-a-combination-of-data-a-practical-guide-fb7e88b0b445?source=collection_archive---------3-----------------------#2022-12-23</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/></div><div class="ab cl jn jo hu jp" role="separator"><span class="jq bw bk jr js jt"/><span class="jq bw bk jr js jt"/><span class="jq bw bk jr js"/></div><div class="ij ik il im in"><p id="4c31" class="pw-post-body-paragraph ju jv iq jw b jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ij bi translated">大家好，这是一个有趣话题的实用指南；今天，我们将讨论如何处理混合数据的组合。当我们浏览数据集时，我们都经历过它，并且有不同数据类型的特征，并且想知道我们如何将两种类型结合起来，并使用它们来训练单个机器学习模型。今天，你有了简单的引导式答案。此外，为了让事情变得有趣，我们将训练一个机器学习模型，实时预测youtube不喜欢的东西。一年前，youtube删除了它的不喜欢计数功能，这已经不足为奇了，也许我解决这个问题有点晚了，但我们今天使用的数据集肯定会满足我们今天的学习需求。请记住，由于youtube不喜欢是一个数字，我们正在解决一个<strong class="jw ir">回归问题</strong>。🙂</p><p id="61f3" class="pw-post-body-paragraph ju jv iq jw b jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ij bi translated"><strong class="jw ir">目录</strong></p><ol class=""><li id="f32a" class="ks kt iq jw b jx jy kb kc kf ku kj kv kn kw kr kx ky kz la bi translated"><a class="ae lb" href="#cf4c" rel="noopener ugc nofollow">加载数据</a></li><li id="1a03" class="ks kt iq jw b jx lc kb ld kf le kj lf kn lg kr kx ky kz la bi translated"><a class="ae lb" href="#ecae" rel="noopener ugc nofollow">数据预处理</a></li><li id="f2e8" class="ks kt iq jw b jx lc kb ld kf le kj lf kn lg kr kx ky kz la bi translated"><a class="ae lb" href="#66e8" rel="noopener ugc nofollow">建模和训练</a></li><li id="b47c" class="ks kt iq jw b jx lc kb ld kf le kj lf kn lg kr kx ky kz la bi translated"><a class="ae lb" href="#7647" rel="noopener ugc nofollow">评估</a></li><li id="13b7" class="ks kt iq jw b jx lc kb ld kf le kj lf kn lg kr kx ky kz la bi translated"><a class="ae lb" href="#e52c" rel="noopener ugc nofollow">实时预测</a></li></ol><p id="4c16" class="pw-post-body-paragraph ju jv iq jw b jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ij bi translated"><strong class="jw ir">你将学到什么</strong></p><ul class=""><li id="8394" class="ks kt iq jw b jx jy kb kc kf ku kj kv kn kw kr lh ky kz la bi translated">处理混合数据</li><li id="e983" class="ks kt iq jw b jx lc kb ld kf le kj lf kn lg kr lh ky kz la bi translated">清除文本数据</li><li id="85ba" class="ks kt iq jw b jx lc kb ld kf le kj lf kn lg kr lh ky kz la bi translated">处理文本和数字数据</li><li id="b7dd" class="ks kt iq jw b jx lc kb ld kf le kj lf kn lg kr lh ky kz la bi translated">Keras TensorFlow功能API</li><li id="47d1" class="ks kt iq jw b jx lc kb ld kf le kj lf kn lg kr lh ky kz la bi translated">LSTM (RNN)</li><li id="1e80" class="ks kt iq jw b jx lc kb ld kf le kj lf kn lg kr lh ky kz la bi translated">创建同时处理不同类型数据的模型</li><li id="be86" class="ks kt iq jw b jx lc kb ld kf le kj lf kn lg kr lh ky kz la bi translated">如何检查回归模型的准确性</li><li id="37b2" class="ks kt iq jw b jx lc kb ld kf le kj lf kn lg kr lh ky kz la bi translated">Youtube API</li></ul><p id="eb3d" class="pw-post-body-paragraph ju jv iq jw b jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ij bi translated"><strong class="jw ir"> <em class="li">现实</em> </strong> <em class="li">:在youtube中，一个视频能够获得的浏览量、喜欢和不喜欢取决于很多东西，比如创作者的受欢迎程度、视频的质量、SEO、用户份额，以及其他很多超出我们可用数据集的大腿。不管怎样，让我们尽力发挥我们所拥有的一切😁</em></p><p id="2214" class="pw-post-body-paragraph ju jv iq jw b jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ij bi translated"><strong class="jw ir"> <em class="li">注:</em> </strong> <em class="li">在整个教程中，如果我错过了什么，我会提到你可以做什么和如何做来改进这个模型，以及我在创建这个模型时错过的东西。说到添加库，我们将按需添加，而不是一次性导入所有库</em></p><p id="952c" class="pw-post-body-paragraph ju jv iq jw b jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ij bi translated"><strong class="jw ir">我们开始吧……</strong></p><p id="21a3" class="pw-post-body-paragraph ju jv iq jw b jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ij bi translated">您可以在<a class="ae lb" href="https://www.kaggle.com/datasets/dmitrynikolaev/youtube-dislikes-dataset" rel="noopener ugc nofollow" target="_blank">https://www . ka ggle . com/datasets/dmitrynikolaev/YouTube-unlesses-dataset</a>获取数据集</p><p id="29bc" class="pw-post-body-paragraph ju jv iq jw b jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ij bi translated">请下载数据集并将其提取到您的工作目录中。该数据集是一个包含37422个唯一raw的混合语言数据集，我们将通过使用数据集提供的视频id将其缩短为只有英语，这使得我们的数据集在处理前总共有15835个唯一raw。这实际上是非常少的数据量。要解决这样的问题，请尝试通过处理其他语言来增加数据量，这肯定有助于提高模型的准确性。</p><p id="5729" class="pw-post-body-paragraph ju jv iq jw b jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ij bi translated"><strong class="jw ir"> <em class="li">注意:</em> </strong> <em class="li">该数据集最后一次更新是在2021年13月12日，因此我们将假设这是提取该数据的日期，因为我们将使用该数据来处理时间段</em></p><h2 id="cf4c" class="lj lk iq bd ll lm ln dn lo lp lq dp lr kf ls lt lu kj lv lw lx kn ly lz ma mb bi translated"><strong class="ak">加载数据集并收集我们需要的特征</strong></h2><p id="86a5" class="pw-post-body-paragraph ju jv iq jw b jx mc jz ka kb md kd ke kf me kh ki kj mf kl km kn mg kp kq kr ij bi translated">希望你有。csv文件在您的工作目录中，那么让我们使用pandas加载它，并将其缩短到只有英文，并从数据集中获得更多可用功能的详细信息。</p><p id="cb71" class="pw-post-body-paragraph ju jv iq jw b jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ij bi translated">导入一些库来开始</p><pre class="mh mi mj mk gt ml mm mn bn mo mp bi"><span id="557b" class="mq lk iq mm b be mr ms l mt mu">import numpy as np<br/>import pandas as pd<br/>import tensorflow as tf</span></pre><p id="f281" class="pw-post-body-paragraph ju jv iq jw b jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ij bi translated">加载数据集</p><pre class="mh mi mj mk gt ml mm mn bn mo mp bi"><span id="f67f" class="mq lk iq mm b be mr ms l mt mu">dataset = pd.read_csv('youtube_dislike_dataset.csv')<br/>dataset.head()</span></pre><p id="aed0" class="pw-post-body-paragraph ju jv iq jw b jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ij bi translated">仅收集英文数据</p><pre class="mh mi mj mk gt ml mm mn bn mo mp bi"><span id="9044" class="mq lk iq mm b be mr ms l mt mu">file_US_ids = open("video_IDs/unique_ids_US.txt", "r")<br/>US_ids = file_US_ids.read().splitlines()<br/>dataset = dataset[dataset['video_id'].isin(US_ids)]<br/>dataset.shape </span></pre><p id="5160" class="pw-post-body-paragraph ju jv iq jw b jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ij bi translated">检查数据集的更多详细信息，例如要素的数据类型</p><pre class="mh mi mj mk gt ml mm mn bn mo mp bi"><span id="9fb9" class="mq lk iq mm b be mr ms l mt mu">dataset.info()</span></pre><figure class="mh mi mj mk gt mw gh gi paragraph-image"><div role="button" tabindex="0" class="mx my di mz bf na"><div class="gh gi mv"><img src="../Images/974fd11b77a7ea6c6e3d64251175e14f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*PrAfLbrGE9pULzZirmn4YA.png"/></div></div><figcaption class="nd ne gj gh gi nf ng bd b be z dk translated">作者图片</figcaption></figure><p id="6501" class="pw-post-body-paragraph ju jv iq jw b jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ij bi translated">数据集包含12个要素。我们将只使用其中的7个功能。这些功能描述如下:</p><p id="ef73" class="pw-post-body-paragraph ju jv iq jw b jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ij bi translated"><strong class="jw ir"> Video_id: </strong>唯一视频id<br/><strong class="jw ir">Title:</strong>YouTube视频标题<br/> <strong class="jw ir"> Channel_id: </strong>发布者频道id<br/><strong class="jw ir">Channel _ Title:</strong>频道名称<br/> <strong class="jw ir">发布时间:</strong>视频发布日期<br/> <strong class="jw ir"> View_count: </strong>视频在一段时间内获得的浏览量<br/> <strong class="jw ir"> 时间<br/> <strong class="jw ir"> Comment_count: </strong>视频有<br/> <strong class="jw ir">标签的评论数</strong>:视频标签为字符串<br/> <strong class="jw ir">描述:</strong>视频描述<br/> <strong class="jw ir">评论:</strong>视频评论列表为字符串</strong></p><p id="2119" class="pw-post-body-paragraph ju jv iq jw b jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ij bi translated">好了，这里有所有可用的功能，现在让我们选择一些我们将在本实用指南中使用的功能。</p><p id="574d" class="pw-post-body-paragraph ju jv iq jw b jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ij bi translated">我们将使用以下7个功能:<br/> <em class="li">查看计数，发布计数，喜欢，评论计数，标签，描述，不喜欢</em></p><pre class="mh mi mj mk gt ml mm mn bn mo mp bi"><span id="62bb" class="mq lk iq mm b be mr ms l mt mu">dataset = dataset[['view_count', 'published_at','likes', 'comment_count','tags','description','dislikes']]</span></pre><p id="85df" class="pw-post-body-paragraph ju jv iq jw b jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ij bi translated">在预处理阶段，我们将再创建一个特征，并从这里删除一个特征。老实说，使用标题和频道名称对模型来说是一个很大的改进，你可以试试。🙂</p><h2 id="ecae" class="lj lk iq bd ll lm ln dn lo lp lq dp lr kf ls lt lu kj lv lw lx kn ly lz ma mb bi translated">数据预处理</h2><p id="8cec" class="pw-post-body-paragraph ju jv iq jw b jx mc jz ka kb md kd ke kf me kh ki kj mf kl km kn mg kp kq kr ij bi translated">让我们从处理数据开始，在这一阶段，我们对数据集做了许多重要的事情，例如处理缺失值、创建相关的时间字段，以及清理和标记文本数据。我边做边多解释一下。</p><p id="2ff6" class="pw-post-body-paragraph ju jv iq jw b jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ij bi translated"><strong class="jw ir">处理缺失值</strong></p><p id="74a0" class="pw-post-body-paragraph ju jv iq jw b jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ij bi translated">数据集是相当棘手的，如果你只是寻找丢失的值(<strong class="jw ir"> nan </strong>)你不会找到任何东西，这是因为在某种程度上，数据集没有任何丢失的值，因为所有的字段都填充了一个空字符串，所以处理这种情况下，我们将检查空字符串字段，其中没有一个单词，并将其转换为一个<strong class="jw ir"> nan </strong>值，并再次检查，我敢肯定，我们现在会得到大量的空值。你猜怎么着？我们将删除它们，这将使我们的数据集总共达到13536 raws，这是相当小的😂</p><figure class="mh mi mj mk gt mw gh gi paragraph-image"><div class="gh gi nh"><img src="../Images/bc83c0581ffd30aa1c6f6d16243a2ae4.png" data-original-src="https://miro.medium.com/v2/resize:fit:1268/format:webp/1*BZ4OV_GVK1Dr2cElB1e_7Q.png"/></div><figcaption class="nd ne gj gh gi nf ng bd b be z dk translated">作者图片</figcaption></figure><p id="3639" class="pw-post-body-paragraph ju jv iq jw b jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ij bi translated"><strong class="jw ir">创建新功能—处理时间</strong></p><p id="471f" class="pw-post-body-paragraph ju jv iq jw b jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ij bi translated">上面，我提到我们将假设数据是在2021年13月12日提取的，这是日期开始起作用的时间。</p><p id="3281" class="pw-post-body-paragraph ju jv iq jw b jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ij bi translated">我们将创建一个名为<strong class="jw ir"> timesec </strong>的新特性，计算视频发布日期和提取时间之间的时间，以分钟为单位。</p><p id="d131" class="pw-post-body-paragraph ju jv iq jw b jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ij bi translated">所以基本上:<em class="li"> timesec =提取日期-发布日期</em></p><p id="9ef8" class="pw-post-body-paragraph ju jv iq jw b jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ij bi translated">首先，我们将编写一个函数来计算两点之间的时间(以分钟为单位),并使用pandas apply方法来创建新要素。</p><p id="9c2b" class="pw-post-body-paragraph ju jv iq jw b jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ij bi translated">用于计算以下时间间隔的函数:</p><pre class="mh mi mj mk gt ml mm mn bn mo mp bi"><span id="4b5a" class="mq lk iq mm b be mr ms l mt mu">from datetime import datetime<br/>def calTime(time):<br/>  start = datetime.strptime(time, '%Y-%m-%d %H:%M:%S')<br/>  end =   datetime.strptime('13/12/2021 00:00:00', '%d/%m/%Y %H:%M:%S') # assuming this is the date that this dataset was extracted<br/>  return np.round((end - start).total_seconds() / 60, 2)</span></pre><p id="df10" class="pw-post-body-paragraph ju jv iq jw b jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ij bi translated">使用pandas apply方法运行函数并创建新特征</p><pre class="mh mi mj mk gt ml mm mn bn mo mp bi"><span id="c905" class="mq lk iq mm b be mr ms l mt mu">dataset['timesec'] = dataset['published_at'].apply(calTime)</span></pre><p id="b3f9" class="pw-post-body-paragraph ju jv iq jw b jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ij bi translated"><strong class="jw ir">清理文本特征</strong></p><p id="f877" class="pw-post-body-paragraph ju jv iq jw b jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ij bi translated">我们将创建一个函数来清理我们的文本数据，然后执行一系列步骤来从中获取正确和重要的含义。</p><p id="20c3" class="pw-post-body-paragraph ju jv iq jw b jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ij bi translated">基本上，该功能将删除任何不必要的网址，标点符号，数字，停用词，并随机词，不在字典将被删除。它还将处理缩略词，并将单词词条化，最后，将全部转换为小写并返回处理后的字符串。我们将在一些库的帮助下完成这项工作，所以让我们从导入这些库开始。</p><p id="b9ef" class="pw-post-body-paragraph ju jv iq jw b jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ij bi translated">为此导入所需的库</p><pre class="mh mi mj mk gt ml mm mn bn mo mp bi"><span id="f418" class="mq lk iq mm b be mr ms l mt mu">import re<br/>from string import punctuation <br/>from bs4 import BeautifulSoup<br/>import nltk<br/>nltk.download('stopwords')<br/>nltk.download('wordnet')<br/>nltk.download('omw-1.4')<br/>nltk.download('words')<br/><br/>from nltk.corpus import stopwords<br/>from nltk.stem import WordNetLemmatizer</span></pre><p id="318f" class="pw-post-body-paragraph ju jv iq jw b jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ij bi translated">缩略词词典将有助于将两个词的组合转换成它们单独的词根。(这不是全部，还有更多)</p><pre class="mh mi mj mk gt ml mm mn bn mo mp bi"><span id="aa80" class="mq lk iq mm b be mr ms l mt mu">contraction_map={<br/>    "ain't": "is not",<br/>    "aren't": "are not",<br/>    "can't": "cannot",<br/>...<br/>}</span></pre><p id="1ccd" class="pw-post-body-paragraph ju jv iq jw b jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ij bi translated">我们创建的清理文本的函数</p><pre class="mh mi mj mk gt ml mm mn bn mo mp bi"><span id="ced7" class="mq lk iq mm b be mr ms l mt mu"><br/>lemmatizer = WordNetLemmatizer()<br/>in_words = set(nltk.corpus.words.words())<br/>def clean_text(text):<br/>    text = str(text)<br/>    text = BeautifulSoup(text, "lxml").text<br/>    text = re.sub(r'\([^)]*\)', '', text)<br/>    text = re.sub('"','', text)<br/>    text = ' '.join([contraction_map[t] if t in contraction_map else t for t in text.split(" ")])<br/>    text = re.sub(r"'s\b","",text)<br/>    text = re.sub("[^a-zA-Z]", " ", text)<br/>    text = " ".join(w for w in nltk.wordpunct_tokenize(text) if w.lower() in in_words or not w.isalpha())<br/><br/>    text = [word for word in text.split( ) if word not in stopwords.words('english')]<br/>    text = [lemmatizer.lemmatize(word) for word in text]<br/>    text = " ".join(text)<br/>    text = text.lower()<br/>    return text</span></pre><p id="dc78" class="pw-post-body-paragraph ju jv iq jw b jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ij bi translated">最后，在运行该函数后，创建两个新列，并清除其中的文本</p><pre class="mh mi mj mk gt ml mm mn bn mo mp bi"><span id="0bde" class="mq lk iq mm b be mr ms l mt mu">%time dataset['clean_description'] = dataset['description'].apply(clean_text)<br/>%time dataset['clean_tags'] = dataset['tags'].apply(clean_text)</span></pre><p id="1097" class="pw-post-body-paragraph ju jv iq jw b jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ij bi translated"><strong class="jw ir">拆分数据</strong></p><p id="97c7" class="pw-post-body-paragraph ju jv iq jw b jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ij bi translated">因为我们使用不同的数据类型，所以使用通常的train_test_split函数并不理想，所以我们将首先通过训练和测试在切片的帮助下分割数据，然后我们将从训练和测试数据中分离X和Y，然后将文本和数字特征分离，我们将保持标签和描述分离，但将所有数字特征保持为一个。这可能会令人困惑，让我们看看代码，这将使事情变得清晰。</p><p id="5d4a" class="pw-post-body-paragraph ju jv iq jw b jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ij bi translated"><strong class="jw ir"> <em class="li">注:</em> </strong> <em class="li"> Y是厌恶特征，也是我们的目标变量。而X将是视图计数、喜欢、评论计数、时间间隔、清理标签、清理描述。我们不需要published_at特性。</em></p><p id="f77f" class="pw-post-body-paragraph ju jv iq jw b jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ij bi translated">切片来训练和测试</p><pre class="mh mi mj mk gt ml mm mn bn mo mp bi"><span id="48cc" class="mq lk iq mm b be mr ms l mt mu"># Slicing to train and test<br/>dataset_train = dataset.iloc[:12500,:]<br/>dataset_test = dataset.iloc[12501:,:]<br/><br/># Creating X and Y variables of train dataset<br/>X_train = dataset_train.loc[:, dataset.columns != 'dislikes']<br/>Y_train = dataset_train['dislikes'].values<br/><br/>#Creating X and Y variables of the test dataset<br/>X_test = dataset_test.loc[:, dataset.columns != 'dislikes']<br/>Y_test = dataset_test['dislikes'].values<br/><br/># Splitting and organizing the features of train data<br/>X_train_numaric = X_train[['view_count', 'likes', 'comment_count', 'timesec']].values<br/>X_train_tags = X_train['clean_tags'].values<br/>X_train_desc = X_train['clean_description'].values<br/><br/># Splitting and organizing the features of the test data<br/>X_test_numaric = X_test[['view_count', 'likes', 'comment_count', 'timesec']].values<br/>X_test_tags = X_test['clean_tags'].values<br/>X_test_desc = X_test['clean_description'].values<br/></span></pre><p id="bc56" class="pw-post-body-paragraph ju jv iq jw b jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ij bi translated"><strong class="jw ir">文本标记化——处理文本</strong></p><p id="ea57" class="pw-post-body-paragraph ju jv iq jw b jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ij bi translated">在这里，我们将创建一个函数来标记化函数，以处理我们的文本特征。该函数将创建一个标记器并标记单词，并将向其添加100的填充，并将返回一组有用的信息，如已处理的测试和训练数据、最大单词数、词汇及其大小，以及我们稍后将用于进行实时预测的标记器本身。<br/>我们将不得不在标签和描述功能上使用它。</p><p id="0348" class="pw-post-body-paragraph ju jv iq jw b jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ij bi translated">让我们来看看代码。🙂</p><p id="bd9f" class="pw-post-body-paragraph ju jv iq jw b jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ij bi translated">为此导入所需的库</p><pre class="mh mi mj mk gt ml mm mn bn mo mp bi"><span id="ddc2" class="mq lk iq mm b be mr ms l mt mu">from tensorflow.keras.preprocessing.text import Tokenizer <br/>from tensorflow.keras.preprocessing.sequence import pad_sequences</span></pre><p id="4c32" class="pw-post-body-paragraph ju jv iq jw b jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ij bi translated">进行处理的函数</p><pre class="mh mi mj mk gt ml mm mn bn mo mp bi"><span id="750b" class="mq lk iq mm b be mr ms l mt mu">def Tokenizer_func(train,test, max_words_length=0, max_seq_len=100):<br/>    tokenizer = Tokenizer()<br/>    tokenizer.fit_on_texts(train)<br/>    <br/>    max_words = 0<br/>    if max_words_length &gt; 0:<br/>        max_words = max_words_length<br/>    else:<br/>        max_words = len(tokenizer.word_counts.items())<br/><br/>    tokenizer = Tokenizer(num_words=max_words)<br/>    tokenizer.fit_on_texts(train)<br/><br/>    train_sequences = tokenizer.texts_to_sequences(train)<br/>    test_sequences = tokenizer.texts_to_sequences(test)<br/>    <br/>    train = pad_sequences(train_sequences,maxlen=max_seq_len, padding='post')<br/>    test = pad_sequences(test_sequences,maxlen=max_seq_len, padding='post')<br/>    <br/>    voc = tokenizer.num_words +1<br/>    return {'train': train, 'test': test, 'voc': voc, 'max_words':max_words, 'tokenizer': tokenizer}</span></pre><p id="fe77" class="pw-post-body-paragraph ju jv iq jw b jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ij bi translated">为标签调用函数</p><pre class="mh mi mj mk gt ml mm mn bn mo mp bi"><span id="d5a9" class="mq lk iq mm b be mr ms l mt mu">X_tags_processed = Tokenizer_func(X_train_tags,X_test_tags)<br/># Extracting data from it…<br/>X_train_tags,X_test_tags,x_tags_voc,x_tags_max_words,x_tag_tok = X_tags_processed['train'], X_tags_processed['test'],X_tags_processed['voc'],X_tags_processed['max_words'],X_tags_processed['tokenizer']</span></pre><p id="5b5d" class="pw-post-body-paragraph ju jv iq jw b jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ij bi translated">调用函数进行描述</p><pre class="mh mi mj mk gt ml mm mn bn mo mp bi"><span id="e87b" class="mq lk iq mm b be mr ms l mt mu">X_desc_processed = Tokenizer_func(X_train_desc,X_test_desc)<br/># Extracting data from it…<br/>X_train_desc, X_test_desc,x_desc_voc,x_desc_max_words,x_desc_tok = X_desc_processed['train'], X_desc_processed['test'],X_desc_processed['voc'],X_desc_processed['max_words'],X_desc_processed['tokenizer']</span></pre><p id="88b7" class="pw-post-body-paragraph ju jv iq jw b jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ij bi translated">在结束本教程的处理步骤之前，我们还有一件事要做。</p><p id="6be2" class="pw-post-body-paragraph ju jv iq jw b jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ij bi translated"><strong class="jw ir">数值数据规范化</strong></p><p id="eff2" class="pw-post-body-paragraph ju jv iq jw b jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ij bi translated">为此，我们将使用StandardScaler来标准化训练和测试数据。好吧，让我们看看代码。<br/>导入库，创建缩放器，并使用它处理数字数据</p><pre class="mh mi mj mk gt ml mm mn bn mo mp bi"><span id="17ae" class="mq lk iq mm b be mr ms l mt mu">from sklearn.preprocessing import StandardScaler<br/>Sc = StandardScaler()<br/>X_train_numaric = Sc.fit_transform(X_train_numaric)<br/>X_test_numaric = Sc.transform(X_test_numaric)</span></pre><p id="3e22" class="pw-post-body-paragraph ju jv iq jw b jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ij bi translated"><strong class="jw ir">耶..</strong>我们已经完成了一半…数据预处理到此结束。🎉🎉🎉</p><h2 id="66e8" class="lj lk iq bd ll lm ln dn lo lp lq dp lr kf ls lt lu kj lv lw lx kn ly lz ma mb bi translated">创建模型和培训</h2><p id="d023" class="pw-post-body-paragraph ju jv iq jw b jx mc jz ka kb md kd ke kf me kh ki kj mf kl km kn mg kp kq kr ij bi translated">在这里，我们将使用Keras functional API来创建一个机器学习模型，我们将构建一种称为LSTM的RNN来处理文本数据，然后将其连接到带有数值数据的MLP。我不打算在这里解释LSTM，因为我已经在之前的一篇文章中介绍过了，链接在这里…</p><div class="ni nj gp gr nk nl"><a href="https://medium.com/@nafiu.dev/stock-market-prediction-using-lstm-will-the-price-go-up-tomorrow-practical-guide-d1df2d54a517" rel="noopener follow" target="_blank"><div class="nm ab fo"><div class="nn ab no cl cj np"><h2 class="bd ir gy z fp nq fr fs nr fu fw ip bi translated">用LSTM预测股票市场:明天价格会上涨吗？实用指南</h2><div class="ns l"><h3 class="bd b gy z fp nq fr fs nr fu fw dk translated">本教程的目标是创建一个机器学习模型来预测股票交易的未来价值</h3></div><div class="nt l"><p class="bd b dl z fp nq fr fs nr fu fw dk translated">medium.com</p></div></div><div class="nu l"><div class="nv l nw nx ny nu nz nb nl"/></div></div></a></div><p id="699e" class="pw-post-body-paragraph ju jv iq jw b jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ij bi translated"><strong class="jw ir">请允许我在这里解释一下我们的模型:</strong></p><p id="912c" class="pw-post-body-paragraph ju jv iq jw b jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ij bi translated">模型中有3个输入:标签输入、输入形状为none的描述输入和输入大小为4的数值输入，因为我们有4个数值特征。标签和描述都以嵌入层开始，然后是两个单位为100的LSTM层(记得我们添加了100作为填充)，随后是每个LSTM之后的归一化层。对于这两个要素，第一个LSTM图层的落差为0.2，返回序列设置为true，第二个图层的落差为0.4，返回序列设置为false。在通过这些层之后，标签和描述都与数字数据输入相结合，然后通过4个密集层，单位为256、128、32和1，前3层具有<strong class="jw ir"> relu </strong>激活函数，最后一层具有线性激活函数(因为问题是回归)。接下来，使用<strong class="jw ir"> model.compile() </strong>方法编译整个模型，将mean_squared_error设置为损失函数，将mean_absolute_error设置为矩阵，将adam设置为优化器，因为adam函数的学习率降低到0.001。然后最后我们可以使用<strong class="jw ir"> model.summary() </strong>方法查看模型的概要。</p><p id="716d" class="pw-post-body-paragraph ju jv iq jw b jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ij bi translated">让我们查看代码…</p><p id="f4fd" class="pw-post-body-paragraph ju jv iq jw b jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ij bi translated">为此导入所需的库。</p><pre class="mh mi mj mk gt ml mm mn bn mo mp bi"><span id="dd36" class="mq lk iq mm b be mr ms l mt mu">from keras.models import Model<br/>from tensorflow.keras.layers import Input, LSTM, Embedding, Dense, concatenate,LayerNormalization<br/>from keras.optimizers import Adam<br/>from keras.callbacks import EarlyStopping</span></pre><p id="8bd1" class="pw-post-body-paragraph ju jv iq jw b jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ij bi translated">创建模型</p><pre class="mh mi mj mk gt ml mm mn bn mo mp bi"><span id="ea2c" class="mq lk iq mm b be mr ms l mt mu">tagsInput = Input(shape=(None,), name='tags')<br/>descInput = Input(shape=(None,), name='desc')<br/>numaricInput = Input(shape=(4,), name='numaric')<br/><br/>tags = Embedding(input_dim=x_tags_voc,output_dim=8,input_length=x_tags_max_words)(tagsInput)<br/>tags = LSTM(100,dropout=0.2, return_sequences=True)(tags)<br/>tags = LayerNormalization()(tags)<br/>tags = LSTM(100,dropout=0.4, return_sequences=False)(tags)<br/>tags = LayerNormalization()(tags)<br/><br/>desc = Embedding(input_dim=x_desc_voc,output_dim=8,input_length=x_desc_max_words)(descInput)<br/>desc = LSTM(100,dropout=0.2, return_sequences=True)(desc)<br/>desc = LayerNormalization()(desc)<br/>desc = LSTM(100,dropout=0.4, return_sequences=False)(desc)<br/>desc = LayerNormalization()(desc)<br/><br/>combined = concatenate([tags, desc,numaricInput])<br/>x = Dense(256,activation='relu')(combined)<br/>x = Dense(128,activation='relu')(x)<br/>x = Dense(32,activation='relu')(x)<br/>x = Dense(1,use_bias=True,activation='linear')(x)<br/>model = Model([tagsInput, descInput,numaricInput], x)</span></pre><p id="427f" class="pw-post-body-paragraph ju jv iq jw b jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ij bi translated">编译模型</p><pre class="mh mi mj mk gt ml mm mn bn mo mp bi"><span id="11e2" class="mq lk iq mm b be mr ms l mt mu">model.compile(loss='mean_squared_error', optimizer=Adam(learning_rate=0.001, decay=0.001 / 20), metrics=['mae'])</span></pre><p id="0d1e" class="pw-post-body-paragraph ju jv iq jw b jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ij bi translated">现在让我们使用model.sumary()方法来查看模型的概要</p><figure class="mh mi mj mk gt mw gh gi paragraph-image"><div role="button" tabindex="0" class="mx my di mz bf na"><div class="gh gi oa"><img src="../Images/d236d7c67b6171f9c4085e59ef013068.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*pkTp7ifq4eWyz1-b9Gzumw.png"/></div></div><figcaption class="nd ne gj gh gi nf ng bd b be z dk translated">作者图片</figcaption></figure><p id="51c3" class="pw-post-body-paragraph ju jv iq jw b jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ij bi translated">现在是时候训练我们的模型了。我们将在500个时期下训练我们的模型，批量大小为25，验证分割为2 %,因为我们在它接近500个时期之前可能已经完成了训练。</p><p id="6118" class="pw-post-body-paragraph ju jv iq jw b jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ij bi translated">在开始训练我们的模型之前，还有一件事我们必须做。LSTM支持三维数据，但我们的数据是二维的，所以我们必须在开始训练前将其转换成三维数据</p><p id="5209" class="pw-post-body-paragraph ju jv iq jw b jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ij bi translated">初始化EarlyStopping以避免在训练模型时过度拟合</p><pre class="mh mi mj mk gt ml mm mn bn mo mp bi"><span id="3623" class="mq lk iq mm b be mr ms l mt mu">es = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=20)</span></pre><p id="7a84" class="pw-post-body-paragraph ju jv iq jw b jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ij bi translated">将数据整形为三维数据</p><pre class="mh mi mj mk gt ml mm mn bn mo mp bi"><span id="75c1" class="mq lk iq mm b be mr ms l mt mu">X_train_tags = np.reshape(X_train_tags,(X_train_tags.shape[0],X_train_tags.shape[1],1))<br/>X_train_desc = np.reshape(X_train_desc,(X_train_desc.shape[0],X_train_desc.shape[1],1))<br/>X_train_tags.shape, X_train_desc.shape, X_train_numaric.shape</span></pre><figure class="mh mi mj mk gt mw gh gi paragraph-image"><div role="button" tabindex="0" class="mx my di mz bf na"><div class="gh gi ob"><img src="../Images/ee6e73e6f20e2d59a4daa823e0618b36.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*jnNwGXZQvfDjcbhBNVj5Ng.png"/></div></div><figcaption class="nd ne gj gh gi nf ng bd b be z dk translated">作者图片</figcaption></figure><p id="d1b2" class="pw-post-body-paragraph ju jv iq jw b jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ij bi translated">训练模型</p><pre class="mh mi mj mk gt ml mm mn bn mo mp bi"><span id="5473" class="mq lk iq mm b be mr ms l mt mu">history = model.fit(<br/>                    x=[X_train_tags, X_train_desc,X_train_numaric],<br/>                    y=Y_train,<br/>                    epochs=500, <br/>                    batch_size=25,<br/>                    validation_split=0.2,<br/>                    verbose=1,<br/>                    callbacks=[es]<br/>                  )</span></pre><figure class="mh mi mj mk gt mw gh gi paragraph-image"><div role="button" tabindex="0" class="mx my di mz bf na"><div class="gh gi oc"><img src="../Images/187a3c5644f067e2bbdc725a35c6f539.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*xKG_S1TsZpgkRGyoMEu2rQ.png"/></div></div><figcaption class="nd ne gj gh gi nf ng bd b be z dk translated">作者图片</figcaption></figure><p id="c917" class="pw-post-body-paragraph ju jv iq jw b jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ij bi translated">在这里，我们可以看到我们的模型在达到26个纪元后就停止了训练。</p><h2 id="7647" class="lj lk iq bd ll lm ln dn lo lp lq dp lr kf ls lt lu kj lv lw lx kn ly lz ma mb bi translated">评估我们的模型</h2><p id="e1db" class="pw-post-body-paragraph ju jv iq jw b jx mc jz ka kb md kd ke kf me kh ki kj mf kl km kn mg kp kq kr ij bi translated">现在，我们的模型已经完成了训练，是时候检查结果了，但在此之前，让我们回答一个简单的问题，并了解一些重要的事情。<br/> <strong class="jw ir">如何检查回归模型的准确性？</strong></p><p id="6afe" class="pw-post-body-paragraph ju jv iq jw b jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ij bi translated"><strong class="jw ir">残差</strong> —预测值与实际值之差。</p><p id="8183" class="pw-post-body-paragraph ju jv iq jw b jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ij bi translated"><strong class="jw ir">平均绝对误差</strong> —预测值与实际值之间的残差的平均值。</p><ul class=""><li id="7264" class="ks kt iq jw b jx jy kb kc kf ku kj kv kn kw kr lh ky kz la bi translated">MAE越低，模型越好。</li><li id="650f" class="ks kt iq jw b jx lc kb ld kf le kj lf kn lg kr lh ky kz la bi translated"><strong class="jw ir"> MAE </strong>通过添加残差并除以数据集(测试数据)的长度来计算</li><li id="62d9" class="ks kt iq jw b jx lc kb ld kf le kj lf kn lg kr lh ky kz la bi translated">描述平均而言预测值与实际值的接近程度。</li></ul><p id="ae35" class="pw-post-body-paragraph ju jv iq jw b jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ij bi translated"><strong class="jw ir">均方误差</strong> —显示回归线与一组数据点的接近程度</p><p id="655b" class="pw-post-body-paragraph ju jv iq jw b jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ij bi translated"><strong class="jw ir">均方根误差</strong>——是所有误差平方值的平均值的平方根</p><ul class=""><li id="936b" class="ks kt iq jw b jx jy kb kc kf ku kj kv kn kw kr lh ky kz la bi translated">指示模型相对于给定数据的绝对拟合度</li><li id="446e" class="ks kt iq jw b jx lc kb ld kf le kj lf kn lg kr lh ky kz la bi translated"><strong class="jw ir"> RMSE </strong>与<strong class="jw ir">梅伊</strong>有关系</li><li id="137b" class="ks kt iq jw b jx lc kb ld kf le kj lf kn lg kr lh ky kz la bi translated">如果<strong class="jw ir">的RMSE </strong>值远远高于<strong class="jw ir">的MAE </strong>，则意味着数据集中一些较大误差的结果。</li></ul><p id="a155" class="pw-post-body-paragraph ju jv iq jw b jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ij bi translated"><strong class="jw ir"> R平方</strong> —显示数据与模型的吻合程度</p><ul class=""><li id="64a5" class="ks kt iq jw b jx jy kb kc kf ku kj kv kn kw kr lh ky kz la bi translated">输出0到1范围内的值</li><li id="13a6" class="ks kt iq jw b jx lc kb ld kf le kj lf kn lg kr lh ky kz la bi translated">R2<strong class="jw ir">越高，模型越好</strong></li><li id="8412" class="ks kt iq jw b jx lc kb ld kf le kj lf kn lg kr lh ky kz la bi translated"><strong class="jw ir"> R2 </strong>分数值可用于通过乘以数值* 100得到与分类模型相同的模型的精确度</li></ul><p id="b860" class="pw-post-body-paragraph ju jv iq jw b jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ij bi translated"><strong class="jw ir">要点:</strong></p><ul class=""><li id="1805" class="ks kt iq jw b jx jy kb kc kf ku kj kv kn kw kr lh ky kz la bi translated"><strong class="jw ir"> R2 </strong>肯定高</li><li id="e5c5" class="ks kt iq jw b jx lc kb ld kf le kj lf kn lg kr lh ky kz la bi translated">MSE越低，模型越好</li><li id="ca40" class="ks kt iq jw b jx lc kb ld kf le kj lf kn lg kr lh ky kz la bi translated">MAE越低，模型越好</li><li id="7ec4" class="ks kt iq jw b jx lc kb ld kf le kj lf kn lg kr lh ky kz la bi translated">RMSE越低，模型越好</li><li id="eaf9" class="ks kt iq jw b jx lc kb ld kf le kj lf kn lg kr lh ky kz la bi translated"><strong class="jw ir"> MAE </strong>应低于<strong class="jw ir"> RMSE </strong></li></ul><p id="3912" class="pw-post-body-paragraph ju jv iq jw b jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ij bi translated">现在让我们在我们的项目中实现这些，看看模型的结果。我们可以通过使用下面的代码来做到这一点</p><pre class="mh mi mj mk gt ml mm mn bn mo mp bi"><span id="6bda" class="mq lk iq mm b be mr ms l mt mu">pprydd = model.predict([X_test_tags, X_test_desc, X_test_numaric])<br/>from sklearn import metrics<br/>print("Mean Absolute Error (MAE) - Test data : ", metrics.mean_absolute_error(Y_test, pprydd))<br/>print("Mean Squared Error (MSE) - Test data : ", metrics.mean_squared_error(Y_test, pprydd))<br/>print("Root Mean Squared Error (RMSE) - Test data : ", np.sqrt(metrics.mean_squared_error(Y_test, pprydd)))<br/>print("Co-efficient of determination (R2 Score): ", metrics.r2_score(Y_test, pprydd))</span></pre><p id="0f89" class="pw-post-body-paragraph ju jv iq jw b jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ij bi translated">我们可以看到我们的模型的<strong class="jw ir"> R2 </strong>得分为0.82 (82%)，但是我们也可以看到我们的<strong class="jw ir"> MSE </strong>非常高，这不是一个好的迹象😥。我们可以看到<strong class="jw ir"> MAE </strong>和<strong class="jw ir"> RMSE </strong>与<strong class="jw ir"> MSE、</strong>相比都非常低，这很好，但是<strong class="jw ir"> RMSE </strong>高于<strong class="jw ir"> MAE、</strong>，这实际上表明了我们数据集中一些错误的结果🤕…不是世界上最好的模型，但在我看来，与我们现有的可用数据相比，这已经不错了。</p><p id="6a1d" class="pw-post-body-paragraph ju jv iq jw b jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ij bi translated">注意:你可以通过对这个领域做更多的研究来尝试改进这个模型，比如当你对视频越来越不喜欢的时候，你需要依赖什么，并关注它。此外，尝试使用我们在本教程中没有使用的功能…无论如何，让我们继续。</p><h2 id="e52c" class="lj lk iq bd ll lm ln dn lo lp lq dp lr kf ls lt lu kj lv lw lx kn ly lz ma mb bi translated">实时预测</h2><p id="5e04" class="pw-post-body-paragraph ju jv iq jw b jx mc jz ka kb md kd ke kf me kh ki kj mf kl km kn mg kp kq kr ij bi translated">现在，我们都在等待实时预测youtube不喜欢的部分。为此，我们将使用youtube API按id获取目标视频数据，并从中收集所需的数据，对其进行处理并通过模型运行。为了使事情变得简单，我们将编写一个函数来使这一切同时发生。<br/>让我们看看代码。:)</p><p id="29a6" class="pw-post-body-paragraph ju jv iq jw b jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ij bi translated">导入所需的库</p><pre class="mh mi mj mk gt ml mm mn bn mo mp bi"><span id="b961" class="mq lk iq mm b be mr ms l mt mu">import googleapiclient.discovery</span></pre><p id="fe4f" class="pw-post-body-paragraph ju jv iq jw b jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ij bi translated">创建youtube客户端</p><pre class="mh mi mj mk gt ml mm mn bn mo mp bi"><span id="2894" class="mq lk iq mm b be mr ms l mt mu">DEVELOPER_KEY = 'YOUR_API_KEY' <br/>youtube_client = googleapiclient.discovery.build('youtube', 'v3', developerKey=DEVELOPER_KEY)</span></pre><p id="15fa" class="pw-post-body-paragraph ju jv iq jw b jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ij bi translated">该写函数了。让我解释一下这是如何工作的。<br/>一旦收到数据，我们将从中提取所需的字段</p><p id="76a7" class="pw-post-body-paragraph ju jv iq jw b jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ij bi translated">对于这两个文本字段，文本将使用之前创建的清理函数进行清理，然后通过我们之前创建的标记器进行处理，最后，填充将被添加到文本中。</p><p id="1030" class="pw-post-body-paragraph ju jv iq jw b jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ij bi translated">将使用next函数计算timesec字段。在这个函数中，它将获取目标视频发布日期和今天之间的时间段(以分钟为单位)。</p><p id="578c" class="pw-post-body-paragraph ju jv iq jw b jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ij bi translated">接下来，所有数字特征将通过缩放器进行归一化。一旦处理完成，那么我们将通过传递模型来预测对视频的不喜欢程度，该函数将在一些其他有用的信息中返回预测的不喜欢数量。</p><pre class="mh mi mj mk gt ml mm mn bn mo mp bi"><span id="2f2e" class="mq lk iq mm b be mr ms l mt mu">def realtime(youtube,video_id):<br/>  def calTimesss(time):<br/>    start = datetime.strptime(time, '%Y-%m-%dT%H:%M:%S%z')<br/>    end =   datetime.now()<br/>    return np.round((end - start.replace(tzinfo=end.tzinfo)).total_seconds() / 60, 2)<br/>  request = youtube.videos().list(part="snippet, statistics",id=video_id)<br/>  response = request.execute()<br/><br/>  desc = response['items'][0]['snippet']['description']<br/>  desc  =[clean_text(desc)]<br/>  desc = x_desc_tok.texts_to_sequences(desc)<br/>  desc = pad_sequences(desc,maxlen=100, padding='post')<br/>  <br/>  tags = response['items'][0]['snippet']['tags']<br/>  tags=(" ".join(tags))<br/>  tags  =[clean_text(tags)]<br/>  tags = x_tag_tok.texts_to_sequences(tags)<br/>  tags = pad_sequences(tags,maxlen=100, padding='post')<br/><br/>  publishedAt = response['items'][0]['snippet']['publishedAt']<br/>  timesec = calTimesss(publishedAt)<br/>  viewcount = response['items'][0]['statistics']['viewCount']<br/>  likeCount = response['items'][0]['statistics']['likeCount']<br/>  commentCount = response['items'][0]['statistics']['commentCount']<br/>  numaricdata = [[viewcount, likeCount,commentCount,timesec]]<br/>  numaricdata = Sc.transform(numaricdata)<br/><br/>  pryd = model.predict([tags, desc, numaricdata])<br/><br/>  return {"predicted": int(pryd[0][0]), "info": {<br/>      "video_id": video_id,<br/>      "likes": likeCount,<br/>      "commentCount": commentCount,<br/>      "viewCount": viewcount,<br/>      "publishedAt": publishedAt,<br/>      "dislike": int(pryd[0][0]),<br/>  }}</span></pre><p id="8a1b" class="pw-post-body-paragraph ju jv iq jw b jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ij bi translated">现在让我们运行它，让我们看看结果…</p><pre class="mh mi mj mk gt ml mm mn bn mo mp bi"><span id="b41d" class="mq lk iq mm b be mr ms l mt mu">video_id = "videoid"<br/>realtime(youtube_client, video_id)</span></pre><figure class="mh mi mj mk gt mw gh gi paragraph-image"><div class="gh gi od"><img src="../Images/0a27606e0a68fb10fae1d0f5564b1eaa.png" data-original-src="https://miro.medium.com/v2/resize:fit:1178/format:webp/1*MWMPV3B89rpnB0v6UwQiog.png"/></div><figcaption class="nd ne gj gh gi nf ng bd b be z dk translated">作者图片</figcaption></figure><p id="5793" class="pw-post-body-paragraph ju jv iq jw b jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ij bi translated"><strong class="jw ir">哈哈</strong>，成功了😂 🎉。根据模型，这个视频有<em class="li"> 1231 </em>个磁盘。<strong class="jw ir">哎哟</strong>，很多讨厌的人😟</p></div><div class="ab cl jn jo hu jp" role="separator"><span class="jq bw bk jr js jt"/><span class="jq bw bk jr js jt"/><span class="jq bw bk jr js"/></div><div class="ij ik il im in"><p id="b626" class="pw-post-body-paragraph ju jv iq jw b jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ij bi translated">好了，这是关于使用组合数据的教程的结尾，很有趣，希望你喜欢。也希望你会尝试改善这种模式…继续学习🙂</p><p id="3ce2" class="pw-post-body-paragraph ju jv iq jw b jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ij bi translated"><strong class="jw ir">链接GitHub repo</strong>:<a class="ae lb" href="https://github.com/nafiu-dev/boolean_image_classifier_FAST-" rel="noopener ugc nofollow" target="_blank"/><a class="ae lb" href="https://github.com/nafiu-dev/youtube_dislike_prediction_practice" rel="noopener ugc nofollow" target="_blank">https://GitHub . com/na FIU-dev/YouTube _ dislike _ prediction _ practice</a></p><p id="b647" class="pw-post-body-paragraph ju jv iq jw b jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ij bi translated"><strong class="jw ir">你可以在这里和我联系:</strong></p><p id="2770" class="pw-post-body-paragraph ju jv iq jw b jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ij bi translated"><a class="ae lb" href="https://www.instagram.com/nafiu.dev" rel="noopener ugc nofollow" target="_blank">https://www.instagram.com/nafiu.dev</a></p><p id="c0eb" class="pw-post-body-paragraph ju jv iq jw b jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ij bi translated"><strong class="jw ir">领英</strong>:<a class="ae lb" href="https://www.linkedin.com/in/nafiu-nizar-93a16720b" rel="noopener ugc nofollow" target="_blank">https://www.linkedin.com/in/nafiu-nizar-93a16720b</a></p><p id="3110" class="pw-post-body-paragraph ju jv iq jw b jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ij bi translated">我的其他帖子:</p><div class="ni nj gp gr nk nl"><a href="https://medium.com/@nafiu.dev/end-to-end-full-stack-project-from-backend-frontend-and-machine-learning-to-ethical-hacking-series-3e53779e5aff" rel="noopener follow" target="_blank"><div class="nm ab fo"><div class="nn ab no cl cj np"><h2 class="bd ir gy z fp nq fr fs nr fu fw ip bi translated">从后端、前端和机器学习到道德黑客的端到端全栈项目…</h2><div class="ns l"><h3 class="bd b gy z fp nq fr fs nr fu fw dk translated">嗨，欢迎大家参加这个从后端开发、前端开发到构建端到端项目的系列</h3></div><div class="nt l"><p class="bd b dl z fp nq fr fs nr fu fw dk translated">medium.com</p></div></div><div class="nu l"><div class="oe l nw nx ny nu nz nb nl"/></div></div></a></div><div class="ni nj gp gr nk nl"><a rel="noopener  ugc nofollow" target="_blank" href="/create-a-boolean-image-classifier-fast-with-any-data-set-with-a-brief-explanation-of-the-4b1265b5b33f"><div class="nm ab fo"><div class="nn ab no cl cj np"><h2 class="bd ir gy z fp nq fr fs nr fu fw ip bi translated">创建一个布尔图像分类器快速与任何数据集，并简要说明了…</h2><div class="ns l"><h3 class="bd b gy z fp nq fr fs nr fu fw dk translated">大家好，在本帖中，我们将探讨一种叫做卷积神经网络的神经网络…</h3></div><div class="nt l"><p class="bd b dl z fp nq fr fs nr fu fw dk translated">pub.towardsai.net</p></div></div><div class="nu l"><div class="of l nw nx ny nu nz nb nl"/></div></div></a></div><div class="ni nj gp gr nk nl"><a href="https://medium.com/@nafiu.dev/highlighting-the-most-popular-machine-learning-algorithms-implementing-it-4bf18b645163" rel="noopener follow" target="_blank"><div class="nm ab fo"><div class="nn ab no cl cj np"><h2 class="bd ir gy z fp nq fr fs nr fu fw ip bi translated">突出最流行的机器学习算法；实施它</h2><div class="ns l"><h3 class="bd b gy z fp nq fr fs nr fu fw dk translated">概述最流行的机器学习模型，使用iris数据集实现和比较准确性</h3></div><div class="nt l"><p class="bd b dl z fp nq fr fs nr fu fw dk translated">medium.com</p></div></div><div class="nu l"><div class="og l nw nx ny nu nz nb nl"/></div></div></a></div></div></div>    
</body>
</html>