<html>
<head>
<title>A Probabilistic Algorithm to Reduce Dimensions: t — Distributed Stochastic Neighbor Embedding (t-SNE)</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">一种概率降维算法:t-分布式随机邻居嵌入(t-SNE)</h1>
<blockquote>原文：<a href="https://pub.towardsai.net/a-probabilistic-algorithm-to-reduce-dimensions-t-distributed-stochastic-neighbor-embedding-23ff457fbc8a?source=collection_archive---------1-----------------------#2020-09-18">https://pub.towardsai.net/a-probabilistic-algorithm-to-reduce-dimensions-t-distributed-stochastic-neighbor-embedding-23ff457fbc8a?source=collection_archive---------1-----------------------#2020-09-18</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><h2 id="1e98" class="io ip iq bd b dl ir is it iu iv iw dk ix translated" aria-label="kicker paragraph"><a class="ae ep" href="https://towardsai.net/p/category/data-visualization" rel="noopener ugc nofollow" target="_blank">数据可视化</a></h2><div class=""/><div class=""><h2 id="4695" class="pw-subtitle-paragraph jw iz iq bd b jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn dk translated">基于概率得分降低维度和可视化数据的最佳技术之一。</h2></div><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div class="gh gi ko"><img src="../Images/b854cbdce829bfc3bd1d4fdef3b7d53b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1396/0*m39rCay41fPCv0av"/></div><figcaption class="kw kx gj gh gi ky kz bd b be z dk translated">来源:<a class="ae la" href="https://medium.com/@jwu2/improving-collaborative-filtering-with-dimensionality-reduction-a99d08585dab" rel="noopener">媒体</a></figcaption></figure><p id="3b3a" class="pw-post-body-paragraph lb lc iq ld b le lf ka lg lh li kd lj lk ll lm ln lo lp lq lr ls lt lu lv lw ij bi translated">数据可视化在实时机器学习应用中起着至关重要的作用。在许多情况下，可视化数据使了解、解释和分类数据变得更加容易和方便。有一些技术可以帮助可视化数据并降低数据集的维度。</p><p id="72a8" class="pw-post-body-paragraph lb lc iq ld b le lf ka lg lh li kd lj lk ll lm ln lo lp lq lr ls lt lu lv lw ij bi translated">在我之前的<a class="ae la" href="https://medium.com/@rajviishah/dimensionality-reduction-using-principal-component-analysis-pca-41e364615766" rel="noopener">文章</a>中，我给出了主成分分析(PCA)的概述，并解释了如何实现它。主成分分析是降低维数和绘制数据的基本技术。使用主成分分析有一些局限性，它不能将相似的类组合在一起，而只是一种将点转化为线性表示的方法，使人们更容易理解数据。而t-SNE旨在克服这一挑战，以便它能够<strong class="ld ja">将相似的对象分组在一起</strong>，即使在<strong class="ld ja">缺乏线性</strong>的情况下。</p><p id="7473" class="pw-post-body-paragraph lb lc iq ld b le lf ka lg lh li kd lj lk ll lm ln lo lp lq lr ls lt lu lv lw ij bi translated">本文分为以下几个部分:</p><ol class=""><li id="efee" class="lx ly iq ld b le lf lh li lk lz lo ma ls mb lw mc md me mf bi translated">什么是SNE霸王龙？</li><li id="f125" class="lx ly iq ld b le mg lh mh lk mi lo mj ls mk lw mc md me mf bi translated">t-SNE的需求/优势</li><li id="3a9a" class="lx ly iq ld b le mg lh mh lk mi lo mj ls mk lw mc md me mf bi translated">SNE霸王龙的缺点</li><li id="72f3" class="lx ly iq ld b le mg lh mh lk mi lo mj ls mk lw mc md me mf bi translated">SNE霸王龙的应用——什么时候用，什么时候不用？</li><li id="b82d" class="lx ly iq ld b le mg lh mh lk mi lo mj ls mk lw mc md me mf bi translated">使用Python实现t-SNE到MNIST数据集</li><li id="6c60" class="lx ly iq ld b le mg lh mh lk mi lo mj ls mk lw mc md me mf bi translated">结论</li></ol><h1 id="3afb" class="ml mm iq bd mn mo mp mq mr ms mt mu mv kf mw kg mx ki my kj mz kl na km nb nc bi translated"><strong class="ak">什么是SNE霸王龙？</strong></h1><p id="8944" class="pw-post-body-paragraph lb lc iq ld b le nd ka lg lh ne kd lj lk nf lm ln lo ng lq lr ls nh lu lv lw ij bi translated">这是一种尝试<strong class="ld ja">保持数据点的局部结构</strong>的技术，从而降低维度。</p><p id="33db" class="pw-post-body-paragraph lb lc iq ld b le lf ka lg lh li kd lj lk ll lm ln lo lp lq lr ls lt lu lv lw ij bi translated">让我们从名称(t-分布式随机邻居嵌入)来理解这个概念:想象一下，所有的数据点被绘制在d维(高)空间中，并且一个数据点被相同类别的其他数据点包围，另一个数据点被相同类别的相似数据点包围，并且对于所有类别都是如此。现在，如果我们取任意一个数据点(x ),那么周围的数据点(y，z，等等)。)被称为该数据点的邻域，计算任何数据点(x)的邻域，使得它与该邻域数据点(y或z)在几何上<strong class="ld ja">接近</strong>，即通过计算两个数据点之间的距离。因此，基本上，x的邻域包含更接近x的点。该技术仅尝试<strong class="ld ja">保持邻域的距离</strong>。</p><p id="8863" class="pw-post-body-paragraph lb lc iq ld b le lf ka lg lh li kd lj lk ll lm ln lo lp lq lr ls lt lu lv lw ij bi translated"><strong class="ld ja">什么是嵌入？</strong>在d维中绘制的数据点被嵌入到2D中，使得所有数据点的邻域都试图保持在d维中。基本上，对于高维空间中的每一个点，在低维空间中都有一个对应的点，具有t-SNE的邻域概念。</p><p id="82ca" class="pw-post-body-paragraph lb lc iq ld b le lf ka lg lh li kd lj lk ll lm ln lo lp lq lr ls lt lu lv lw ij bi translated">t-SNE使用高斯分布创建了一个<strong class="ld ja">概率分布</strong>，定义了高维空间中各点之间的关系。</p><p id="1efe" class="pw-post-body-paragraph lb lc iq ld b le lf ka lg lh li kd lj lk ll lm ln lo lp lq lr ls lt lu lv lw ij bi translated">它是随机的，因为在<strong class="ld ja">中，每次运行其输出都会改变</strong>，也就是说，它不是确定性的。</p><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div role="button" tabindex="0" class="nj nk di nl bf nm"><div class="gh gi ni"><img src="../Images/479ab22c246ec91811069bfc7bfa93ef.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*EmV08YYHhNfQVq7A"/></div></div><figcaption class="kw kx gj gh gi ky kz bd b be z dk translated">参考:<a class="ae la" href="https://pt.slideshare.net/ssuserb667a8/visualization-data-using-tsne" rel="noopener ugc nofollow" target="_blank">幻灯片</a></figcaption></figure><h1 id="249a" class="ml mm iq bd mn mo mp mq mr ms mt mu mv kf mw kg mx ki my kj mz kl na km nb nc bi translated">我们为什么需要SNE霸王龙？</h1><ul class=""><li id="73b8" class="lx ly iq ld b le nd lh ne lk nn lo no ls np lw nq md me mf bi translated"><strong class="ld ja">处理非线性:</strong>说到降维，PCA因其易于使用和直观理解而被广泛使用。它试图通过保持数据点的分布(方差)来保持数据集的线性。PCA是一种线性算法。它创建的主成分是现有特征的线性组合。因此，它不能解释特征之间复杂的多项式关系。所以，如果变量之间的关系是非线性的，它表现很差。另一方面，t-SNE在非线性数据上工作得很好。t-SNE的主要目标是保持数据点的非线性，这有助于克服PCA在某些应用中的挑战。</li><li id="71c0" class="lx ly iq ld b le mg lh mh lk mi lo mj ls mk lw nq md me mf bi translated"><strong class="ld ja">保留局部和全局结构:</strong> t-SNE能够保留数据的局部和全局结构。粗略地说，这意味着高维数据集中彼此接近的点在低维中将倾向于彼此接近。另一方面，主成分分析发现了解释数据中大部分差异的新维度。所以，它不像SNE霸王龙那样关心附近的邻居。</li></ul><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div class="gh gi nr"><img src="../Images/92a45b9cf5cccec3dee7b7bb816b174b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1394/0*vjdfyxgY-kFr9Ruj"/></div></figure><p id="995f" class="pw-post-body-paragraph lb lc iq ld b le lf ka lg lh li kd lj lk ll lm ln lo lp lq lr ls lt lu lv lw ij bi translated">上图显示了实施PCA后MNIST数据集的最终输出。</p><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div role="button" tabindex="0" class="nj nk di nl bf nm"><div class="gh gi ns"><img src="../Images/5d7ce1cc9b2bfb9047bb64e498df2b23.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*___ihL_mCG1czYym"/></div></div><figcaption class="kw kx gj gh gi ky kz bd b be z dk translated">参考:<a class="ae la" href="http://colah.github.io/posts/2014-10-Visualizing-MNIST/" rel="noopener ugc nofollow" target="_blank"> Colah </a></figcaption></figure><p id="3352" class="pw-post-body-paragraph lb lc iq ld b le lf ka lg lh li kd lj lk ll lm ln lo lp lq lr ls lt lu lv lw ij bi translated">上图描绘了实施t-SNE后MNIST数据集的最终输出。</p><h1 id="4c7c" class="ml mm iq bd mn mo mp mq mr ms mt mu mv kf mw kg mx ki my kj mz kl na km nb nc bi translated"><strong class="ak">t-SNE的弊端</strong></h1><ul class=""><li id="b34e" class="lx ly iq ld b le nd lh ne lk nn lo no ls np lw nq md me mf bi translated"><strong class="ld ja">拥挤问题:</strong>让我们假设一个由点a、b、c和d组成的正方形，长度为x，表示在2D，现在应用t-SNE，一个人想把维数减少到1D，首先a表示在一条线上，现在点b表示在点a的左边x距离处，点c绘制在点的右边x距离处。这里，a的邻域保持不变，但不能保持b点和c点之间的距离。</li></ul><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div class="gh gi nt"><img src="../Images/2745420b538f2f0862aa70d6518f93f9.png" data-original-src="https://miro.medium.com/v2/resize:fit:1164/0*acSr8ePvnd3y6--o"/></div><figcaption class="kw kx gj gh gi ky kz bd b be z dk translated">参考:<a class="ae la" href="https://medium.com/@ranasinghiitkgp/t-sne-visualization-of-high-dimension-mnist-dataset-48fb23d1bafd" rel="noopener">培养基</a></figcaption></figure><ul class=""><li id="e98c" class="lx ly iq ld b le lf lh li lk lz lo ma ls mb lw nq md me mf bi translated"><strong class="ld ja">计算复杂:</strong> t-SNE涉及大量的计算和运算，因为它为每个数据点计算成对的条件概率，并试图最小化更高维度和更低维度上的概率差之和。</li><li id="77aa" class="lx ly iq ld b le mg lh mh lk mi lo mj ls mk lw nq md me mf bi translated"><strong class="ld ja">超参数的选择:</strong>困惑和步骤(将在本文后面介绍)</li><li id="4d4f" class="lx ly iq ld b le mg lh mh lk mi lo mj ls mk lw nq md me mf bi translated"><strong class="ld ja">集群大小:</strong> t-SNE不考虑任何类的集群大小。</li></ul><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div role="button" tabindex="0" class="nj nk di nl bf nm"><div class="gh gi nu"><img src="../Images/56d602d7c529dc7b9b3530146466c818.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*8I_1XCiQw-ZEux25"/></div></div><figcaption class="kw kx gj gh gi ky kz bd b be z dk translated">参考:<a class="ae la" href="https://distill.pub/2016/misread-tsne/" rel="noopener ugc nofollow" target="_blank">distilt-pub</a></figcaption></figure><h1 id="5bd2" class="ml mm iq bd mn mo mp mq mr ms mt mu mv kf mw kg mx ki my kj mz kl na km nb nc bi translated"><strong class="ak">t-SNE的应用</strong></h1><p id="dfb0" class="pw-post-body-paragraph lb lc iq ld b le nd ka lg lh ne kd lj lk nf lm ln lo ng lq lr ls nh lu lv lw ij bi translated">t-SNE可以用于高维数据，然后这些维度的输出成为其他分类模型的输入。同样，t-SNE可以用于<strong class="ld ja">调查</strong>、<strong class="ld ja">学习</strong>或<strong class="ld ja">评估分割</strong>。人们经常在建模之前选择分段的数量<strong class="ld ja">或者在结果之后迭代</strong>。SNE霸王龙经常在数据中显示出明显的分离。这可以在使用您的分段模型选择聚类数之前使用，或者在评估您的分段实际上是否成立之后使用。然而，t-SNE不是一种聚类方法，因为它不像PCA那样保留输入，并且值可能经常在运行之间改变，所以它纯粹是为了探索。它用于解释深度神经网络输出，在<a class="ae la" href="https://ai.googleblog.com/2016/12/open-sourcing-embedding-projector-tool.html" rel="noopener ugc nofollow" target="_blank">tensor flow Embedding Projector</a>和<a class="ae la" href="https://www.tensorflow.org/versions/r1.2/get_started/embedding_viz" rel="noopener ugc nofollow" target="_blank"> TensorBoard </a>等工具中，tSNE的一个强大功能是揭示不同尺度的高维数据点集群，同时只需要对其参数进行最小的调整。广泛用于<strong class="ld ja">深度学习应用</strong>。</p><h1 id="a594" class="ml mm iq bd mn mo mp mq mr ms mt mu mv kf mw kg mx ki my kj mz kl na km nb nc bi translated"><strong class="ak">使用Python实现t-SNE到MNIST数据集</strong></h1><p id="6a10" class="pw-post-body-paragraph lb lc iq ld b le nd ka lg lh ne kd lj lk nf lm ln lo ng lq lr ls nh lu lv lw ij bi translated">从<a class="ae la" href="https://www.kaggle.com/c/digit-recognizer/data?select=train.csv" rel="noopener ugc nofollow" target="_blank">数据</a>下载MNIST数据集。首先，我们将加载以及<strong class="ld ja">理解</strong>列和数据点。此外，将标签列从CSV文件中分离出来，并将其存储在另一个数据帧中。</p><figure class="kp kq kr ks gt kt"><div class="bz fp l di"><div class="nv nw l"/></div></figure><p id="5b5c" class="pw-post-body-paragraph lb lc iq ld b le lf ka lg lh li kd lj lk ll lm ln lo lp lq lr ls lt lu lv lw ij bi translated">现在，作为数据预处理的一部分，我们将<strong class="ld ja">标准化</strong>数据如下:</p><figure class="kp kq kr ks gt kt"><div class="bz fp l di"><div class="nv nw l"/></div></figure><p id="d735" class="pw-post-body-paragraph lb lc iq ld b le lf ka lg lh li kd lj lk ll lm ln lo lp lq lr ls lt lu lv lw ij bi translated">下一步是使用Sk-learn实现t-SNE。</p><p id="f31b" class="pw-post-body-paragraph lb lc iq ld b le lf ka lg lh li kd lj lk ll lm ln lo lp lq lr ls lt lu lv lw ij bi translated">这里，我们将使用SNE霸王龙的前1000个标准化数据点。并使用一些默认参数从sklearn模块中准备一个SNE霸王龙模型。建议应用不同的困惑度、学习率来以更好的方式分类标签。此外，我们将拟合和转换t-SNE模型，并使用seaborn绘制如下图:</p><figure class="kp kq kr ks gt kt"><div class="bz fp l di"><div class="nv nw l"/></div></figure><p id="44f7" class="pw-post-body-paragraph lb lc iq ld b le lf ka lg lh li kd lj lk ll lm ln lo lp lq lr ls lt lu lv lw ij bi translated">输出:</p><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div class="gh gi nx"><img src="../Images/c59d6d970a8a2d3ec49b3107b724a33c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1334/0*Gko2qo_T99mW70v5"/></div></figure><p id="d79b" class="pw-post-body-paragraph lb lc iq ld b le lf ka lg lh li kd lj lk ll lm ln lo lp lq lr ls lt lu lv lw ij bi translated">困惑地尝试= 50；</p><figure class="kp kq kr ks gt kt"><div class="bz fp l di"><div class="nv nw l"/></div></figure><p id="f9a1" class="pw-post-body-paragraph lb lc iq ld b le lf ka lg lh li kd lj lk ll lm ln lo lp lq lr ls lt lu lv lw ij bi translated">输出:这个看起来和上面困惑= 30的剧情很像。</p><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div class="gh gi ny"><img src="../Images/d0637409a861f3f6f3f5a38e1ee3c57b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1346/0*vyLPRmo2epsnPtbN"/></div></figure><p id="b52f" class="pw-post-body-paragraph lb lc iq ld b le lf ka lg lh li kd lj lk ll lm ln lo lp lq lr ls lt lu lv lw ij bi translated">用5000次迭代而不是1000次迭代来尝试t-SNE；</p><figure class="kp kq kr ks gt kt"><div class="bz fp l di"><div class="nv nw l"/></div></figure><p id="9623" class="pw-post-body-paragraph lb lc iq ld b le lf ka lg lh li kd lj lk ll lm ln lo lp lq lr ls lt lu lv lw ij bi translated">输出:</p><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div role="button" tabindex="0" class="nj nk di nl bf nm"><div class="gh gi nz"><img src="../Images/f6ffbbee8a882986f906a1c6a6720817.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*c2YX7ofLcXnez5VW"/></div></div></figure><p id="2209" class="pw-post-body-paragraph lb lc iq ld b le lf ka lg lh li kd lj lk ll lm ln lo lp lq lr ls lt lu lv lw ij bi translated">现在，困惑= 2</p><figure class="kp kq kr ks gt kt"><div class="bz fp l di"><div class="nv nw l"/></div></figure><p id="b77e" class="pw-post-body-paragraph lb lc iq ld b le lf ka lg lh li kd lj lk ll lm ln lo lp lq lr ls lt lu lv lw ij bi translated">输出:所有信息丢失，所有数据点随机分布如下:</p><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div class="gh gi oa"><img src="../Images/491ef1c322710c88566bb300ec5df075.png" data-original-src="https://miro.medium.com/v2/resize:fit:1340/0*m3SNQ-_Ey99_eggB"/></div></figure><h1 id="49b4" class="ml mm iq bd mn mo mp mq mr ms mt mu mv kf mw kg mx ki my kj mz kl na km nb nc bi translated">结论</h1><p id="14fd" class="pw-post-body-paragraph lb lc iq ld b le nd ka lg lh ne kd lj lk nf lm ln lo ng lq lr ls nh lu lv lw ij bi translated">为了找到最佳解决方案，我们需要尝试不同的困惑值和迭代次数。尝试用所有数据点实现t-SNE(这将需要一些时间来执行)。</p></div><div class="ab cl ob oc hu od" role="separator"><span class="oe bw bk of og oh"/><span class="oe bw bk of og oh"/><span class="oe bw bk of og"/></div><div class="ij ik il im in"><p id="b699" class="pw-post-body-paragraph lb lc iq ld b le lf ka lg lh li kd lj lk ll lm ln lo lp lq lr ls lt lu lv lw ij bi translated">你可以从<a class="ae la" href="https://github.com/rajviishah/t-SNE" rel="noopener ugc nofollow" target="_blank"> Github </a>中找到源代码</p><p id="97ba" class="pw-post-body-paragraph lb lc iq ld b le lf ka lg lh li kd lj lk ll lm ln lo lp lq lr ls lt lu lv lw ij bi translated">如果你对这个库的任何函数/类有任何疑惑，那么我请求你查看文档。</p><p id="af86" class="pw-post-body-paragraph lb lc iq ld b le lf ka lg lh li kd lj lk ll lm ln lo lp lq lr ls lt lu lv lw ij bi translated">如果有任何更正和改进的范围，或者如果您有任何疑问，请通过<a class="ae la" href="mailto:rajvishah2309@gmail.com" rel="noopener ugc nofollow" target="_blank">邮件</a> / <a class="ae la" href="https://www.linkedin.com/in/rajviishah/" rel="noopener ugc nofollow" target="_blank"> LinkedIn </a>告诉我。</p></div><div class="ab cl ob oc hu od" role="separator"><span class="oe bw bk of og oh"/><span class="oe bw bk of og oh"/><span class="oe bw bk of og"/></div><div class="ij ik il im in"><p id="294b" class="pw-post-body-paragraph lb lc iq ld b le lf ka lg lh li kd lj lk ll lm ln lo lp lq lr ls lt lu lv lw ij bi translated">要详细了解缺点，请查看:<a class="ae la" href="https://distill.pub/2016/misread-tsne/" rel="noopener ugc nofollow" target="_blank">https://distill.pub/2016/misread-tsne/</a></p><p id="2dba" class="pw-post-body-paragraph lb lc iq ld b le lf ka lg lh li kd lj lk ll lm ln lo lp lq lr ls lt lu lv lw ij bi translated">关于t-SNE的应用，请查看:<a class="ae la" href="https://ai.googleblog.com/2018/06/realtime-tsne-visualizations-with.html" rel="noopener ugc nofollow" target="_blank">https://ai . Google blog . com/2018/06/real time-tsne-visualizations-with . html</a></p><h2 id="6695" class="oi mm iq bd mn oj ok dn mr ol om dp mv lk on oo mx lo op oq mz ls or os nb iw bi translated"><strong class="ak">参考文献:</strong></h2><ul class=""><li id="2eb1" class="lx ly iq ld b le nd lh ne lk nn lo no ls np lw nq md me mf bi translated"><a class="ae la" href="https://mlexplained.com/2018/09/14/paper-dissected-visualizing-data-using-t-sne-explained/#:~:text=It%20uses%20the%20local%20relationships,points%20in%20high%2Ddimensional%20space" rel="noopener ugc nofollow" target="_blank">https://ml explained . com/2018/09/14/paper-parsed-visualizing-data-using-t-SNE-explained/#:~:text = It % 20 uses % 20 local % 20 relationships，points % 20 in % 20 high % 2d dimensional % 20 space</a>。</li><li id="aa4a" class="lx ly iq ld b le mg lh mh lk mi lo mj ls mk lw nq md me mf bi translated"><a class="ae la" href="http://theprofessionalspoint.blogspot.com/2019/03/advantages-and-disadvantages-of-t-sne.html" rel="noopener ugc nofollow" target="_blank">http://the professionals point . blogspot . com/2019/03/advantages-and-lessons-of-t-SNE . html</a></li><li id="5283" class="lx ly iq ld b le mg lh mh lk mi lo mj ls mk lw nq md me mf bi translated"><a class="ae la" href="https://towardsdatascience.com/an-introduction-to-t-sne-with-python-example-5a3a293108d1" rel="noopener" target="_blank">https://towards data science . com/an-introduction-to-t-SNE-with-python-example-5a3a 293108 D1</a></li><li id="a39c" class="lx ly iq ld b le mg lh mh lk mi lo mj ls mk lw nq md me mf bi translated"><a class="ae la" href="https://scikit-learn.org/stable/modules/generated/sklearn.manifold.TSNE.html" rel="noopener ugc nofollow" target="_blank">https://sci kit-learn . org/stable/modules/generated/sk learn . manifold . tsne . html</a></li><li id="ffeb" class="lx ly iq ld b le mg lh mh lk mi lo mj ls mk lw nq md me mf bi translated"><a class="ae la" href="https://www.appliedaicourse.com/lecture/11/applied-machine-learning-online-course/2900/geometric-intuition-of-t-sne/2/module-2-data-science-exploratory-data-analysis-and-data-visualization" rel="noopener ugc nofollow" target="_blank">https://www . applied ai course . com/lecture/11/applied-machine-learning-online-course/2900/geometric-intuition-of-t-SNE/2/module-2-data-science-explorative-data-analysis-and-data-visualization</a></li></ul></div></div>    
</body>
</html>