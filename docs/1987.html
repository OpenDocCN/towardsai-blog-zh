<html>
<head>
<title>Standardization in Data Preprocessing with Python</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">用Python实现数据预处理的标准化</h1>
<blockquote>原文：<a href="https://pub.towardsai.net/standardization-in-data-preprocessing-with-python-96ae89d2f658?source=collection_archive---------0-----------------------#2021-07-16">https://pub.towardsai.net/standardization-in-data-preprocessing-with-python-96ae89d2f658?source=collection_archive---------0-----------------------#2021-07-16</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><h2 id="6ef5" class="ir is it bd b dl iu iv iw ix iy iz dk ja translated" aria-label="kicker paragraph"><a class="ae ep" href="https://towardsai.net/p/category/machine-learning" rel="noopener ugc nofollow" target="_blank">机器学习</a></h2><div class=""/><div class=""><h2 id="d47e" class="pw-subtitle-paragraph jz jc it bd b ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq dk translated">机器学习和深度学习算法中的缩放方法</h2></div><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi kr"><img src="../Images/d6a64b5d189ef67579b0cbcf4c8f6bc4.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*PJ-SPI1RfWY8smKb"/></div></div><figcaption class="ld le gj gh gi lf lg bd b be z dk translated">由<a class="ae lh" href="https://unsplash.com/@saltsup?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">皮雷特·伊尔弗</a>在<a class="ae lh" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上拍摄</figcaption></figure><p id="7a80" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">标准化和规范化是机器学习和深度学习项目中大量使用的数据预处理技术。</p><p id="8e4f" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated"><strong class="lk jd">这些技术的主要作用</strong></p><ul class=""><li id="372f" class="me mf it lk b ll lm lo lp lr mg lv mh lz mi md mj mk ml mm bi translated">以相似的格式缩放所有数据，使模型的学习过程变得容易。</li><li id="c54f" class="me mf it lk b ll mn lo mo lr mp lv mq lz mr md mj mk ml mm bi translated">数据中的奇数值被缩放或归一化，表现得像数据的一部分。</li></ul><p id="bd5d" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">我们将通过python例子深入讨论这两个概念。</p><blockquote class="ms mt mu"><p id="6fbf" class="li lj mv lk b ll lm kd ln lo lp kg lq mw ls lt lu mx lw lx ly my ma mb mc md im bi translated"><strong class="lk jd"> <em class="it">标准化</em> </strong></p></blockquote><p id="4fd8" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">数据的基本缩放是使其标准化，以便所有值都在共同的范围内。在标准化中，数据的平均值和方差分别为零和一。它总是试图对数据进行正态分布。</p><p id="3719" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">标准化的公式如下所示:</p><p id="e90c" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated"><strong class="lk jd"> z =(列值—平均值)/标准差</strong></p><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div class="gh gi mz"><img src="../Images/9039c63992a968dffdd6aeac4f2282ce.png" data-original-src="https://miro.medium.com/v2/resize:fit:1342/format:webp/1*ooobvod71cCc4m4tma3rmA.png"/></div><figcaption class="ld le gj gh gi lf lg bd b be z dk translated">典型的均匀分布。一张由<a class="ae lh" rel="noopener ugc nofollow" target="_blank" href="/data-preprocessing-concepts-with-python-b93c63f14bb6?source=friends_link&amp;sk=5cc4ac66c6c02a6f02077fd43df9681a">作者</a>拍摄的照片</figcaption></figure><p id="d396" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">机器学习中的一些算法试图感觉数据具有正态分布。但是，如果一个特征具有较大的方差，而其他特征具有较小的方差或单位方差，那么模型的学习将是不正确的，因为从一个特征到另一个特征的方差不同。</p><p id="ee69" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">如上所述，标准标度的范围是“0”平均值和“1”单位方差。</p></div><div class="ab cl na nb hx nc" role="separator"><span class="nd bw bk ne nf ng"/><span class="nd bw bk ne nf ng"/><span class="nd bw bk ne nf"/></div><div class="im in io ip iq"><p id="51ca" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated"><strong class="lk jd">我们如何使用标准缩放？</strong></p><p id="bb26" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">要使用标准缩放，我们需要从预处理类导入它，如下所示:</p><pre class="ks kt ku kv gt nh ni nj nk aw nl bi"><span id="5968" class="nm nn it ni b gy no np l nq nr">from sklearn.preprocessing import StandardScaler<br/>                     or<br/>from sklearn import preprocessing<br/>scaler = preprocessing.StandardScaler()</span></pre></div><div class="ab cl na nb hx nc" role="separator"><span class="nd bw bk ne nf ng"/><span class="nd bw bk ne nf ng"/><span class="nd bw bk ne nf"/></div><div class="im in io ip iq"><p id="9545" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated"><strong class="lk jd">使用标准缩放的正确步骤是什么？</strong></p><p id="194a" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">我们可以在训练测试分割后使用标准缩放，因为如果我们在此之前使用，可能会出现数据泄漏的问题，从而导致模型不太可靠。如果我们在分割之前进行缩放，那么从训练中学习的过程也可以在测试集上进行，这是我们不想要的。你可以在这篇<a class="ae lh" rel="noopener ugc nofollow" target="_blank" href="/tips-and-tricks-in-machine-learning-with-python-to-avoid-data-leakage-c3908fa4a0c9?source=friends_link&amp;sk=ebd984646cc74aad31cb9ccf7e4273b0">文章</a>中看到更多关于数据泄露的信息。</p><p id="5279" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">让我们借助sklearn库来看看拆分过程</p><pre class="ks kt ku kv gt nh ni nj nk aw nl bi"><span id="ef61" class="nm nn it ni b gy no np l nq nr">from sklearn.model_selection import train_test_split</span><span id="9ada" class="nm nn it ni b gy ns np l nq nr">X_train, X_test, y_train, y_test = train_test_split(x,<br/>                   y, train_size = 0.20, random_state = 42)</span></pre><p id="b99e" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">在此之后，我们可以使用标准缩放</p><pre class="ks kt ku kv gt nh ni nj nk aw nl bi"><span id="eece" class="nm nn it ni b gy no np l nq nr">from sklearn.preprocessing import StandardScaler<br/>sc = StandardScaler()<br/>X_train = sc.fit_transform(X_train)<br/>X_test = sc.transform(X_test)</span></pre><p id="44c2" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">我们举一个python的例子。</p><pre class="ks kt ku kv gt nh ni nj nk aw nl bi"><span id="1ef7" class="nm nn it ni b gy no np l nq nr">from sklearn import preprocessing<br/>import numpy as np</span><span id="e320" class="nm nn it ni b gy ns np l nq nr">#creating a training data<br/>X_train = np.array([[ 4., -3.,  2.], <br/>                    [ 2.,  2.,  0.], <br/>                    [ 0.,  -6., 7.]])</span><span id="7289" class="nm nn it ni b gy ns np l nq nr">#fit the training data<br/>scaler = preprocessing.StandardScaler().fit(X_train)<br/>scaler</span><span id="0248" class="nm nn it ni b gy ns np l nq nr"><strong class="ni jd">#output:</strong><br/>StandardScaler()</span></pre><p id="0a59" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">现在，我们将检查训练数据中每个特征的平均值和比例。</p><pre class="ks kt ku kv gt nh ni nj nk aw nl bi"><span id="f992" class="nm nn it ni b gy no np l nq nr">scaler.mean_</span><span id="f616" class="nm nn it ni b gy ns np l nq nr"><strong class="ni jd">#output:</strong><br/>array([ 2., -2.33333333, 3.])</span><span id="aaee" class="nm nn it ni b gy ns np l nq nr">scaler.scale_</span><span id="c93e" class="nm nn it ni b gy ns np l nq nr"><strong class="ni jd">#output:</strong><br/>array([1.63299316, 3.29983165, 2.94392029])</span></pre><p id="4618" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated"><code class="fe nt nu nv ni b">scale_</code>属性查找要素之间的相对比例，以获得标准比例，即零均值和单位方差。用于计算每个要素平均值的<code class="fe nt nu nv ni b">mean_</code>属性。</p><p id="7a7d" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">现在，我们将转换我们的缩放数据</p><pre class="ks kt ku kv gt nh ni nj nk aw nl bi"><span id="dfde" class="nm nn it ni b gy no np l nq nr">X_scaled = scaler.transform(X_train)<br/>X_scaled</span><span id="0d46" class="nm nn it ni b gy ns np l nq nr"><strong class="ni jd">#output:</strong><br/>array([[ 1.22474487, -0.20203051, -0.33968311],<br/>       [ 0.        ,  1.31319831, -1.01904933],<br/>       [-1.22474487, -1.1111678 ,  1.35873244]])</span></pre><p id="281c" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">要检查要素的零均值和单位方差，我们将找到均值和标准差。</p><pre class="ks kt ku kv gt nh ni nj nk aw nl bi"><span id="8ba5" class="nm nn it ni b gy no np l nq nr">X_scaled.mean(axis=0)</span><span id="dfc3" class="nm nn it ni b gy ns np l nq nr"><strong class="ni jd">#output:</strong><br/>array([0., 0., 0.])</span><span id="cefc" class="nm nn it ni b gy ns np l nq nr">X_scaled.std(axis=0)</span><span id="deae" class="nm nn it ni b gy ns np l nq nr"><strong class="ni jd">#output:</strong><br/>array([1., 1., 1.])</span></pre><p id="9833" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">我们还可以在<code class="fe nt nu nv ni b">MinMaxScaler</code>和<code class="fe nt nu nv ni b">MaxAbsScaler</code>的帮助下进行范围缩放。</p><p id="fd14" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">有时，我们在影响算法建模的数据中有异常值，并且标准缩放器受到异常值的影响，并且像min-max和max-abs缩放器这样的其他方法使数据在某个范围内。</p></div><div class="ab cl na nb hx nc" role="separator"><span class="nd bw bk ne nf ng"/><span class="nd bw bk ne nf ng"/><span class="nd bw bk ne nf"/></div><div class="im in io ip iq"><h2 id="5722" class="nm nn it bd nw nx ny dn nz oa ob dp oc lr od oe of lv og oh oi lz oj ok ol iz bi translated">最小最大缩放器</h2><p id="284f" class="pw-post-body-paragraph li lj it lk b ll om kd ln lo on kg lq lr oo lt lu lv op lx ly lz oq mb mc md im bi translated"><code class="fe nt nu nv ni b">MinMaxScaler</code>是在[0，1]范围内缩放数据的另一种方法。它保持数据的原始形态，保留有价值的信息，较少受离群值的影响。</p><p id="7723" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">python示例如下所示:</p><pre class="ks kt ku kv gt nh ni nj nk aw nl bi"><span id="87ee" class="nm nn it ni b gy no np l nq nr">from sklearn import preprocessing<br/>import numpy as np</span><span id="a5c6" class="nm nn it ni b gy ns np l nq nr">#creating a training data<br/>X_train = np.array([[ 4., -3.,  2.], <br/>                    [ 2.,  2.,  0.], <br/>                    [ 0.,  -6., 7.]])</span><span id="411d" class="nm nn it ni b gy ns np l nq nr">min_max_scaler = preprocessing.MinMaxScaler()<br/>X_train_minmax = min_max_scaler.fit_transform(X_train)<br/>X_train_minmax</span><span id="54d1" class="nm nn it ni b gy ns np l nq nr"><strong class="ni jd">#output:</strong><br/>array([[1.        , 0.375     , 0.28571429],<br/>       [0.5       , 1.        , 0.        ],<br/>       [0.        , 0.        , 1.        ]])</span></pre><p id="d5ec" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">使用<code class="fe nt nu nv ni b">MinMaxScaler</code>缩放后，我们可以看到数据在“0”到“1”的范围内。</p><div class="or os gp gr ot ou"><a rel="noopener  ugc nofollow" target="_blank" href="/data-preprocessing-concepts-with-python-b93c63f14bb6"><div class="ov ab fo"><div class="ow ab ox cl cj oy"><h2 class="bd jd gy z fp oz fr fs pa fu fw jc bi translated">Python中的数据预处理概念</h2><div class="pb l"><h3 class="bd b gy z fp oz fr fs pa fu fw dk translated">一种为机器学习估值器准备数据的稳健方法</h3></div><div class="pc l"><p class="bd b dl z fp oz fr fs pa fu fw dk translated">pub.towardsai.net</p></div></div><div class="pd l"><div class="pe l pf pg ph pd pi lb ou"/></div></div></a></div><div class="or os gp gr ot ou"><a rel="noopener  ugc nofollow" target="_blank" href="/different-data-splitting-cross-validation-strategies-with-python-ec7cd93764ac"><div class="ov ab fo"><div class="ow ab ox cl cj oy"><h2 class="bd jd gy z fp oz fr fs pa fu fw jc bi translated">使用Python的不同数据分割交叉验证策略</h2><div class="pb l"><h3 class="bd b gy z fp oz fr fs pa fu fw dk translated">机器学习中的训练集、验证集和测试集</h3></div><div class="pc l"><p class="bd b dl z fp oz fr fs pa fu fw dk translated">pub.towardsai.net</p></div></div><div class="pd l"><div class="pj l pf pg ph pd pi lb ou"/></div></div></a></div></div><div class="ab cl na nb hx nc" role="separator"><span class="nd bw bk ne nf ng"/><span class="nd bw bk ne nf ng"/><span class="nd bw bk ne nf"/></div><div class="im in io ip iq"><h2 id="bd7e" class="nm nn it bd nw nx ny dn nz oa ob dp oc lr od oe of lv og oh oi lz oj ok ol iz bi translated">MaxAbsScaler</h2><p id="74fa" class="pw-post-body-paragraph li lj it lk b ll om kd ln lo on kg lq lr oo lt lu lv op lx ly lz oq mb mc md im bi translated">这是另一种缩放方法，其中数据在[-1，1]的范围内。这种缩放的好处是，它不会移动数据或使数据居中，并保持数据的稀疏性。</p><p id="cf8d" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">python示例如下所示:</p><pre class="ks kt ku kv gt nh ni nj nk aw nl bi"><span id="4a8c" class="nm nn it ni b gy no np l nq nr">from sklearn import preprocessing<br/>import numpy as np</span><span id="17a0" class="nm nn it ni b gy ns np l nq nr">#creating a training data<br/>X_train = np.array([[ 4., -3.,  2.], <br/>                    [ 2.,  2.,  0.], <br/>                    [ 0.,  -6., 7.]])</span><span id="7019" class="nm nn it ni b gy ns np l nq nr">max_abs_scaler = preprocessing.MaxAbsScaler()<br/>X_train_maxabs = max_abs_scaler.fit_transform(X_train)<br/>X_train_maxabs</span><span id="6f74" class="nm nn it ni b gy ns np l nq nr"><strong class="ni jd">#output:</strong><br/>array([[ 1.        , -0.5       ,  0.28571429],<br/>       [ 0.5       ,  0.33333333,  0.        ],<br/>       [ 0.        , -1.        ,  1.        ]])</span></pre><p id="84b2" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">我们可以看到用<code class="fe nt nu nv ni b">MaxAbsScaler</code>缩放后的数据在'-1 '到' 1 '的范围内。</p><blockquote class="ms mt mu"><p id="4b7f" class="li lj mv lk b ll lm kd ln lo lp kg lq mw ls lt lu mx lw lx ly my ma mb mc md im bi translated"><strong class="lk jd"> <em class="it">结论</em> </strong></p></blockquote><p id="5ad8" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">数据的缩放是机器学习或深度学习非常重要的一部分。在本文中，<code class="fe nt nu nv ni b">MaxAbsScaler</code>在稀疏数据中很有用，而另一方面，标准缩放也可以用于稀疏数据，但也会因为过多的内存分配而产生值错误。</p></div><div class="ab cl na nb hx nc" role="separator"><span class="nd bw bk ne nf ng"/><span class="nd bw bk ne nf ng"/><span class="nd bw bk ne nf"/></div><div class="im in io ip iq"><p id="8976" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">我希望你喜欢这篇文章。通过我的<a class="ae lh" href="https://www.linkedin.com/in/data-scientist-95040a1ab/" rel="noopener ugc nofollow" target="_blank"> LinkedIn </a>和<a class="ae lh" href="https://twitter.com/amitprius" rel="noopener ugc nofollow" target="_blank"> twitter </a>联系我。</p><h1 id="e013" class="pk nn it bd nw pl pm pn nz po pp pq oc ki pr kj of kl ps km oi ko pt kp ol pu bi translated">推荐文章</h1><p id="9c7a" class="pw-post-body-paragraph li lj it lk b ll om kd ln lo on kg lq lr oo lt lu lv op lx ly lz oq mb mc md im bi translated"><a class="ae lh" href="https://medium.com/towards-artificial-intelligence/nlp-zero-to-hero-with-python-2df6fcebff6e?sk=2231d868766e96b13d1e9d7db6064df1" rel="noopener"> 1。NLP —零到英雄与Python </a> <br/> 2。<a class="ae lh" href="https://medium.com/towards-artificial-intelligence/python-data-structures-data-types-and-objects-244d0a86c3cf?sk=42f4b462499f3fc3a160b21e2c94dba6" rel="noopener"> Python数据结构数据类型和对象</a>T5】3 .<a class="ae lh" rel="noopener ugc nofollow" target="_blank" href="/exception-handling-concepts-in-python-4d5116decac3?source=friends_link&amp;sk=a0ed49d9fdeaa67925eac34ecb55ea30">Python中的异常处理概念</a> <br/> 4。<a class="ae lh" rel="noopener ugc nofollow" target="_blank" href="/principal-component-analysis-in-dimensionality-reduction-with-python-1a613006d531?source=friends_link&amp;sk=3ed0671fdc04ba395dd36478bcea8a55">用Python进行主成分分析降维</a> <br/> 5。<a class="ae lh" href="https://medium.com/towards-artificial-intelligence/fully-explained-k-means-clustering-with-python-e7caa573176a?source=friends_link&amp;sk=9c5c613ceb10f2d203712634f3b6fb28" rel="noopener">用Python全面讲解K-means聚类</a> <br/> 6。<a class="ae lh" href="https://medium.com/towards-artificial-intelligence/fully-explained-linear-regression-with-python-fe2b313f32f3?source=friends_link&amp;sk=53c91a2a51347ec2d93f8222c0e06402" rel="noopener">用Python </a> <br/> 7全面讲解了线性回归。<a class="ae lh" href="https://medium.com/towards-artificial-intelligence/fully-explained-logistic-regression-with-python-f4a16413ddcd?source=friends_link&amp;sk=528181f15a44e48ea38fdd9579241a78" rel="noopener">用Python </a> <br/>充分解释了Logistic回归8。<a class="ae lh" rel="noopener ugc nofollow" target="_blank" href="/differences-between-concat-merge-and-join-with-python-1a6541abc08d?source=friends_link&amp;sk=3b37b694fb90db16275059ea752fc16a">concat()、merge()和join()与Python </a> <br/>的区别9。<a class="ae lh" rel="noopener ugc nofollow" target="_blank" href="/data-wrangling-with-python-part-1-969e3cc81d69?source=friends_link&amp;sk=9c3649cf20f31a5c9ead51c50c89ba0b">与Python的数据角力—第一部分</a> <br/> 10。<a class="ae lh" href="https://medium.com/analytics-vidhya/confusion-matrix-in-machine-learning-91b6e2b3f9af?source=friends_link&amp;sk=11c6531da0bab7b504d518d02746d4cc" rel="noopener">机器学习中的混淆矩阵</a></p></div></div>    
</body>
</html>