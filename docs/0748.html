<html>
<head>
<title>This AI Can Generate the Other Half of a Picture Using a GPT Model</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">这个人工智能可以使用GPT模型生成另一半图片</h1>
<blockquote>原文：<a href="https://pub.towardsai.net/this-ai-can-generate-the-pixels-of-half-of-a-picture-from-nothing-using-a-nlp-model-7d7ba14b5522?source=collection_archive---------0-----------------------#2020-08-01">https://pub.towardsai.net/this-ai-can-generate-the-pixels-of-half-of-a-picture-from-nothing-using-a-nlp-model-7d7ba14b5522?source=collection_archive---------0-----------------------#2020-08-01</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><h2 id="8c62" class="ir is it bd b dl iu iv iw ix iy iz dk ja translated" aria-label="kicker paragraph"><a class="ae ep" href="https://towardsai.net/p/category/nlp" rel="noopener ugc nofollow" target="_blank">自然语言处理</a></h2><div class=""/><div class=""><h2 id="5291" class="pw-subtitle-paragraph jz jc it bd b ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq dk translated">一个好的人工智能，如Gmail中使用的人工智能，可以生成连贯的文本并完成你的短语。这一个使用相同的原则为了完成一幅图像！所有这些都是在无人监督的训练中完成的，根本不需要任何标签！</h2></div><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi kr"><img src="../Images/ddd96b30a17c19fcebd52f92adc90fb5.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/1*dgSI1JovVJd55PY_yGvB_g.gif"/></div></div></figure><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div class="gh gi ld"><img src="../Images/c0c2f3551171632e8ed98e00fb746270.png" data-original-src="https://miro.medium.com/v2/resize:fit:1358/format:webp/1*UEOQiHKafoe71bzlYWfAcQ.png"/></div></figure><p id="42e4" class="pw-post-body-paragraph le lf it lg b lh li kd lj lk ll kg lm ln lo lp lq lr ls lt lu lv lw lx ly lz im bi translated">OpenAI最近分享了一篇名为“从像素生成预训练”的新论文，该论文用于预测像素，而不需要结合二维图像结构的知识。他们想看看主要用于自然语言处理的架构是否也可以用于图片来“重建”图像。就像Gmail预测你邮件的结尾一样，这个AI可以预测一个图像的结尾！</p><p id="c30b" class="pw-post-body-paragraph le lf it lg b lh li kd lj lk ll kg lm ln lo lp lq lr ls lt lu lv lw lx ly lz im bi translated">他们使用谷歌开发的用于自然语言处理预训练的流行的来自变压器的双向编码器表示(BERT)技术。应用GPT-2序列转换器架构来预测像素而不是语言标记。伯特和GPT-2这两种变换器模型是领域不可知的，这意味着它们可以直接应用于任何形式的一维序列，例如像素序列而不是单词和字母。他们发现该模型甚至可以理解二维图像特征，如物体外观和类别！</p><div class="ks kt ku kv gt ab cb"><figure class="ma kw mb mc md me mf paragraph-image"><img src="../Images/399eb1bc1e2153cf2dbf8a071a0bc92a.png" data-original-src="https://miro.medium.com/v2/resize:fit:520/format:webp/1*TdHP5E2IjNAkdcjtecRyxw.png"/></figure><figure class="ma kw mg mc md me mf paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><img src="../Images/67518c1d9f58e0908abc9799cc704c12.png" data-original-src="https://miro.medium.com/v2/resize:fit:1432/format:webp/1*lzmihkh6BG2RqrWJZ7OT-g.png"/></div></figure></div><p id="b0f6" class="pw-post-body-paragraph le lf it lg b lh li kd lj lk ll kg lm ln lo lp lq lr ls lt lu lv lw lx ly lz im bi translated">如果你想了解这两个重要概念的更多信息，我在下面链接了伯特和GPT-2的论文。</p><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi mh"><img src="../Images/e88f60c220575662fb9184663834a503.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*TpsT6Si3Lc9MzA2FO--W8A.png"/></div></div></figure><p id="ad8c" class="pw-post-body-paragraph le lf it lg b lh li kd lj lk ll kg lm ln lo lp lq lr ls lt lu lv lw lx ly lz im bi translated">这里的挑战是，在自然语言处理中，单词序列遵循语法规则，这有助于网络预测接下来会发生什么。例如，一个问题之后肯定会有答案。相比之下，像素序列并不清楚地包含它们所属图像的标签。让他们认为在图像上使用GPT-2可以工作的是，如果你使用足够大的变压器，训练下一个像素预测，最终可以学习生成不同的现实样本。<br/>然后，通过优化GPT-2模型的生成能力，他们可以实现它。</p><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div class="gh gi mi"><img src="../Images/e110ad30a5c019d16032f67ea905adee.png" data-original-src="https://miro.medium.com/v2/resize:fit:1378/format:webp/1*w4TDwDp8YrzaJWl-7u7tKQ.png"/></div></figure><p id="8d03" class="pw-post-body-paragraph le lf it lg b lh li kd lj lk ll kg lm ln lo lp lq lr ls lt lu lv lw lx ly lz im bi translated">让我们再多谈谈这种方法。预训练模型经常用于支持训练的初始化。他们使用这个BERT预训练模型作为特征提取器，使用给定的X和Y，其中X是图像，Y是标签，它产生特征fx，然后将其发送到使用这些特征(fx)和它们的标签(Y)训练的线性分类器，而不使用图像(X)本身。这种线性探测抓住了直觉，即好的特征应该线性地将类分开。然后，变形金刚解码器出场。它用于线性探头的微调和特征提取。提取用于线性探测的固定特征遵循类似于微调的过程，除了平均汇集不总是在最终层。</p><div class="ks kt ku kv gt ab cb"><figure class="ma kw mj mc md me mf paragraph-image"><img src="../Images/0b122644ffae6913bb6841d8ddd847c3.png" data-original-src="https://miro.medium.com/v2/resize:fit:244/format:webp/1*arYC8orCFZ9FbdKhrs9QZg.png"/></figure><figure class="ma kw mk mc md me mf paragraph-image"><img src="../Images/69147b13bd31f378ca0bfc211c7aa583.png" data-original-src="https://miro.medium.com/v2/resize:fit:1212/format:webp/1*Tv8Dnca00LAgo13cG_NnWA.png"/></figure></div><p id="230f" class="pw-post-body-paragraph le lf it lg b lh li kd lj lk ll kg lm ln lo lp lq lr ls lt lu lv lw lx ly lz im bi translated">虽然它在向网络提供如此少的信息的情况下显示了惊人的结果，但它仍然有一些局限性。他们说，这需要大量的计算，大约是ImageNet分类挑战中最先进的检测/分割算法的40倍。</p><div class="ks kt ku kv gt ab cb"><figure class="ma kw ml mc md me mf paragraph-image"><img src="../Images/5a56effdb25ef10faaecb307e8f183dd.png" data-original-src="https://miro.medium.com/v2/resize:fit:246/format:webp/1*AHzi2jdM3lhVU_uI5mkoVw.png"/></figure><figure class="ma kw mm mc md me mf paragraph-image"><img src="../Images/abc6bd8dbb07b0333915accac6f00e1a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1214/format:webp/1*Rz1emjc0G7hm6VjWwQg5Cg.png"/></figure></div><p id="c863" class="pw-post-body-paragraph le lf it lg b lh li kd lj lk ll kg lm ln lo lp lq lr ls lt lu lv lw lx ly lz im bi translated">但是，他们的主要目标是对基于大型转换器的语言模型在新领域中学习无监督表示的能力进行概念证明，如本例中的无监督图像分类，而不需要硬编码的领域知识。然而，他们认为基于卷积神经网络的方法在视觉领域的实际应用中更实用。</p><div class="ks kt ku kv gt ab cb"><figure class="ma kw mn mc md me mf paragraph-image"><img src="../Images/45f116bf35364bc68e34ee5f2a090d4f.png" data-original-src="https://miro.medium.com/v2/resize:fit:246/format:webp/1*o4mUnhPSSc18bs9IWEF48g.png"/></figure><figure class="ma kw mo mc md me mf paragraph-image"><img src="../Images/2aa36bc00cface2147d6964f144a54f1.png" data-original-src="https://miro.medium.com/v2/resize:fit:1208/format:webp/1*XQw_H0JIfsZkL9onFK05sg.png"/></figure></div><p id="5fd3" class="pw-post-body-paragraph le lf it lg b lh li kd lj lk ll kg lm ln lo lp lq lr ls lt lu lv lw lx ly lz im bi translated">我还是觉得这篇论文挺有意思的，和我们平时看到的不太一样。他们尝试了一种不同的方法，并测量发生了什么，这是我认为更多的人应该做的，而不是简单地微调最先进的方法，以获得小的改善。</p><p id="adb8" class="pw-post-body-paragraph le lf it lg b lh li kd lj lk ll kg lm ln lo lp lq lr ls lt lu lv lw lx ly lz im bi translated"><strong class="lg jd">查看视频中更多例子:</strong></p><figure class="ks kt ku kv gt kw"><div class="bz fp l di"><div class="mp mq l"/></div></figure></div><div class="ab cl mr ms hx mt" role="separator"><span class="mu bw bk mv mw mx"/><span class="mu bw bk mv mw mx"/><span class="mu bw bk mv mw"/></div><div class="im in io ip iq"><p id="00f7" class="pw-post-body-paragraph le lf it lg b lh li kd lj lk ll kg lm ln lo lp lq lr ls lt lu lv lw lx ly lz im bi translated">如果你喜欢我的工作并想支持我，我会非常感谢你在我的社交媒体频道上关注我:</p><ul class=""><li id="9c06" class="my mz it lg b lh li lk ll ln na lr nb lv nc lz nd ne nf ng bi translated">支持我的最好方式就是跟随我上<a class="ae nh" href="https://medium.com/@whats_ai" rel="noopener"><strong class="lg jd"/></a>。</li><li id="c5e6" class="my mz it lg b lh ni lk nj ln nk lr nl lv nm lz nd ne nf ng bi translated">订阅我<a class="ae nh" href="https://www.youtube.com/channel/UCUzGQrN-lyyc0BWTYoJM_Sg" rel="noopener ugc nofollow" target="_blank"> <strong class="lg jd"> YouTube频道</strong> </a>。</li><li id="4bff" class="my mz it lg b lh ni lk nj ln nk lr nl lv nm lz nd ne nf ng bi translated">在<a class="ae nh" href="https://www.linkedin.com/company/what-is-artificial-intelligence" rel="noopener ugc nofollow" target="_blank"> <strong class="lg jd"> LinkedIn </strong> </a>上关注我的项目</li><li id="804b" class="my mz it lg b lh ni lk nj ln nk lr nl lv nm lz nd ne nf ng bi translated">一起学AI，加入我们的<a class="ae nh" href="https://discord.gg/SVse4Sr" rel="noopener ugc nofollow" target="_blank"> <strong class="lg jd"> Discord社区</strong> </a>，<em class="nn">分享你的项目、论文、最佳课程，寻找Kaggle队友，等等！</em></li></ul></div><div class="ab cl mr ms hx mt" role="separator"><span class="mu bw bk mv mw mx"/><span class="mu bw bk mv mw mx"/><span class="mu bw bk mv mw"/></div><div class="im in io ip iq"><p id="f5f5" class="pw-post-body-paragraph le lf it lg b lh li kd lj lk ll kg lm ln lo lp lq lr ls lt lu lv lw lx ly lz im bi translated"><strong class="lg jd">参考文献</strong></p><p id="a7bb" class="pw-post-body-paragraph le lf it lg b lh li kd lj lk ll kg lm ln lo lp lq lr ls lt lu lv lw lx ly lz im bi translated">项目:<a class="ae nh" href="https://openai.com/blog/image-gpt/" rel="noopener ugc nofollow" target="_blank">https://openai.com/blog/image-gpt/</a><br/>伯特:<a class="ae nh" href="https://arxiv.org/abs/1810.04805" rel="noopener ugc nofollow" target="_blank">https://arxiv.org/abs/1810.04805</a><br/>GPT-2:<a class="ae nh" href="https://d4mucfpksywv.cloudfront.net/better-language-models/language-models.pdf" rel="noopener ugc nofollow" target="_blank">https://D4 mucfpksywv . cloudfront . net/better-language-models/language-models . pdf</a></p></div></div>    
</body>
</html>