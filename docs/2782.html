<html>
<head>
<title>NLP Using Deepleaning Tutorials: A Sentiment Classifier Based on Perceptron (Part 2/4)</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">使用深度学习教程的NLP:基于感知器的情感分类器(第2/4部分)</h1>
<blockquote>原文：<a href="https://pub.towardsai.net/nlp-using-deepleaning-tutorials-a-sentiment-classifier-based-on-perceptron-part-2-4-f9b90b3a06bd?source=collection_archive---------2-----------------------#2022-05-24">https://pub.towardsai.net/nlp-using-deepleaning-tutorials-a-sentiment-classifier-based-on-perceptron-part-2-4-f9b90b3a06bd?source=collection_archive---------2-----------------------#2022-05-24</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><figure class="gl gn jr js jt ju gh gi paragraph-image"><div role="button" tabindex="0" class="jv jw di jx bf jy"><div class="gh gi jq"><img src="../Images/200e6d7dac3e16f02cac84b56f94998b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*NUQOe7vzOgOa-UBwyaZ0pQ.jpeg"/></div></div><figcaption class="kb kc gj gh gi kd ke bd b be z dk translated">该图像从<a class="ae kf" href="https://hackernoon.com/drafts/523x232ih.png" rel="noopener ugc nofollow" target="_blank">源</a>上传</figcaption></figure><p id="52a0" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">自然语言处理是机器学习中最复杂的领域之一，基本上是由于语言的复杂性和模糊性。然而，它也是最成功的领域之一，有许多我们每天都在使用的真实应用，像搜索引擎、翻译工具等等。</p><p id="b010" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">有时最复杂的任务可以用最简单的技术解决。在这篇文章中，我将尝试探索这种说法。所以，我将基于最简单的神经网络“感知器”提出一个完整的情感分析解决方案，使用一个真实世界的任务和数据集:对Yelp上的餐厅评论进行正面或负面分类。</p><p id="6e0f" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">为此，我将本文分为以下四个部分:</p><ol class=""><li id="b134" class="le lf it ki b kj kk kn ko kr lg kv lh kz li ld lj lk ll lm bi translated">Yelp数据集评论(<a class="ae kf" rel="noopener ugc nofollow" target="_blank" href="/nlp-using-deepleaning-tutorials-a-sentiment-classifier-based-on-perceptron-part-1-4-712eefe20899">链接</a></li><li id="38e1" class="le lf it ki b kj ln kn lo kr lp kv lq kz lr ld lj lk ll lm bi translated"><strong class="ki iu">词汇和矢量器(本文关注这部分)</strong></li><li id="7b4a" class="le lf it ki b kj ln kn lo kr lp kv lq kz lr ld lj lk ll lm bi translated">训练程序</li><li id="3a77" class="le lf it ki b kj ln kn lo kr lp kv lq kz lr ld lj lk ll lm bi translated">评估和推理</li></ol><blockquote class="ls lt lu"><p id="d88b" class="kg kh lv ki b kj kk kl km kn ko kp kq lw ks kt ku lx kw kx ky ly la lb lc ld im bi translated"><strong class="ki iu">提前感谢大家的支持。如果你决定注册成为灵媒会员，这里是我的订阅页面</strong>:<a class="ae kf" href="https://abdelkader-rhouati.medium.com/membership" rel="noopener">https://abdelkader-rhouati.medium.com/membership</a></p></blockquote></div><div class="ab cl lz ma hx mb" role="separator"><span class="mc bw bk md me mf"/><span class="mc bw bk md me mf"/><span class="mc bw bk md me"/></div><div class="im in io ip iq"><h1 id="e28a" class="mg mh it bd mi mj mk ml mm mn mo mp mq mr ms mt mu mv mw mx my mz na nb nc nd bi translated">第2部分:<strong class="ak">词汇表和矢量器</strong></h1><p id="b729" class="pw-post-body-paragraph kg kh it ki b kj ne kl km kn nf kp kq kr ng kt ku kv nh kx ky kz ni lb lc ld im bi translated">每个文本都是单词或字符的集合，这些单词或字符被称为标记。因此，预处理管道的第一步是通过python字典变量将每个标记映射到其自身的数字版本。这使得使用文本作为基于数学方程的神经网络的输入成为可能。</p><h1 id="7093" class="mg mh it bd mi mj nj ml mm mn nk mp mq mr nl mt mu mv nm mx my mz nn nb nc nd bi translated">积累词汇</h1><p id="3b8f" class="pw-post-body-paragraph kg kh it ki b kj ne kl km kn nf kp kq kr ng kt ku kv nh kx ky kz ni lb lc ld im bi translated">在这个例子中，我们将在记号和整数之间使用双射，这意味着有两个字典变量。两个主要的词汇类函数是<strong class="ki iu"> lookup_tooken() </strong>和<strong class="ki iu"> lookup_index() </strong>，分别检索给定标记的索引和对应于给定索引的标记</p><p id="994b" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">除了处理这种双射，词汇类还允许通过自动增加索引来添加新的标记:<strong class="ki iu"> add_token() </strong>函数。</p><p id="26ec" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">即使有最大的语料库，词汇量也总是有限的。这就是为什么我们的词汇表需要处理一个叫做<strong class="ki iu"> <em class="lv"> UNK(未知)的特定令牌。通过使用UNK，我们处理了在训练数据集上看不到的新标记。</em> </strong></p><p id="e81b" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">词汇课的内容是:</p><figure class="no np nq nr gt ju"><div class="bz fp l di"><div class="ns nt l"/></div><figcaption class="kb kc gj gh gi kd ke bd b be z dk translated">词汇表. py文件的内容</figcaption></figure><h1 id="952c" class="mg mh it bd mi mj nj ml mm mn nk mp mq mr nl mt mu mv nm mx my mz nn nb nc nd bi translated"><strong class="ak">对文本进行矢量化</strong></h1><p id="4dac" class="pw-post-body-paragraph kg kh it ki b kj ne kl km kn nf kp kq kr ng kt ku kv nh kx ky kz ni lb lc ld im bi translated"><strong class="ki iu">矢量器</strong>类封装了<strong class="ki iu">词汇</strong>特性。因此，它提供了一种机制，通过<strong class="ki iu"> from_dataframe </strong>()函数，基于特定的数据语料库(通常语料库对应于训练数据集)来构建个性化词汇表。该函数遍历Pandas数据帧的行，首先计算数据集中出现的每个标记的频率，然后创建词汇表(配对标记和索引的列表)。一个好的做法是通过忽略不常用的标记来限制词汇量。这通过定义<strong class="ki iu">切断</strong>参数来完成。</p><p id="7487" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">除了创建词汇表，<strong class="ki iu">矢量化</strong>()函数还返回文本输入的矢量化表示(=数值向量)。在这项工作中，我们使用了<strong class="ki iu">折叠的一个热点表示</strong>。这种表示创建了一个二进制向量，其长度相当于词汇表的大小。二进制向量在对应于文本中单词的位置上有1。这具有与未被处理的文本中的单词顺序相关的限制，并且出现多次的标记仅被考虑一次</p><p id="726d" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated"><strong class="ki iu">矢量器类</strong>的内容是:</p><figure class="no np nq nr gt ju"><div class="bz fp l di"><div class="ns nt l"/></div><figcaption class="kb kc gj gh gi kd ke bd b be z dk translated">内容审查_矢量器. py文件</figcaption></figure><h1 id="ba3e" class="mg mh it bd mi mj nj ml mm mn nk mp mq mr nl mt mu mv nm mx my mz nn nb nc nd bi translated"><strong class="ak">使用数据加载器生成小批量。</strong></h1><p id="49f2" class="pw-post-body-paragraph kg kh it ki b kj ne kl km kn nf kp kq kr ng kt ku kv nh kx ky kz ni lb lc ld im bi translated">最后一步是将矢量化数据分组为小批量。这是训练神经网络的重要部分。为此，Pytorch提供了一个名为DataLoaer的内置类([2]了解更多细节)。</p><p id="260a" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">生成小批量的功能是:</p><figure class="no np nq nr gt ju"><div class="bz fp l di"><div class="ns nt l"/></div></figure><p id="4b7b" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated"><strong class="ki iu">参考文献:</strong></p><ol class=""><li id="3864" class="le lf it ki b kj kk kn ko kr lg kv lh kz li ld lj lk ll lm bi translated">《用Pytorch进行自然语言处理》一书(<a class="ae kf" href="https://www.amazon.fr/Natural-Language-Processing-Pytorch-Applications/dp/1491978236" rel="noopener ugc nofollow" target="_blank">https://www . Amazon . fr/Natural-Language-Processing-py torch-Applications/DP/1491978236</a>)</li><li id="65af" class="le lf it ki b kj ln kn lo kr lp kv lq kz lr ld lj lk ll lm bi translated"><a class="ae kf" href="https://pytorch.org/tutorials/beginner/basics/data_tutorial.html?highlight=dataloader" rel="noopener ugc nofollow" target="_blank">https://py torch . org/tutorials/beginner/basics/data _ tutorial . html？高亮显示=数据加载器</a></li></ol></div></div>    
</body>
</html>