<html>
<head>
<title>NLP Using Deepleaning Tutorials: A Sentiment Classifier Based on Perceptron (Part 3/4)</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">使用深度学习教程的NLP:基于感知器的情感分类器(第3/4部分)</h1>
<blockquote>原文：<a href="https://pub.towardsai.net/nlp-using-deepleaning-tutorials-a-sentiment-classifier-based-on-perceptron-part-3-4-88fd202dba2c?source=collection_archive---------5-----------------------#2022-05-31">https://pub.towardsai.net/nlp-using-deepleaning-tutorials-a-sentiment-classifier-based-on-perceptron-part-3-4-88fd202dba2c?source=collection_archive---------5-----------------------#2022-05-31</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><figure class="gl gn jr js jt ju gh gi paragraph-image"><div class="gh gi jq"><img src="../Images/6c8c05e2e3bc5422a45420f25b0b78e0.png" data-original-src="https://miro.medium.com/v2/resize:fit:1332/format:webp/1*z9EW0EI5VrLSY7AQx7rtVg.png"/></div><figcaption class="jx jy gj gh gi jz ka bd b be z dk translated">该图像从<a class="ae kb" href="https://cdn.brandmentions.com/blog/wp-content/uploads/2019/05/sentiment-analysys-brandmentions.png" rel="noopener ugc nofollow" target="_blank">源</a>上传</figcaption></figure><p id="1801" class="pw-post-body-paragraph kc kd it ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz im bi translated">自然语言处理是机器学习中最复杂的领域之一，基本上是由于语言的复杂性和模糊性。然而，它也是最成功的领域之一，有许多我们每天都在使用的真实应用，像搜索引擎、翻译工具等等。</p><p id="b010" class="pw-post-body-paragraph kc kd it ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz im bi translated">有时最复杂的任务可以用最简单的技术解决。在这篇文章中，我将尝试探索这种说法。所以，我将基于最简单的神经网络“感知器”提出一个完整的情感分析解决方案，使用一个真实世界的任务和数据集:对Yelp上的餐厅评论进行正面或负面分类。</p><p id="6e0f" class="pw-post-body-paragraph kc kd it ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz im bi translated">为此，我将本文分为以下四个部分:</p><ol class=""><li id="b134" class="la lb it ke b kf kg kj kk kn lc kr ld kv le kz lf lg lh li bi translated">Yelp数据集评论(<a class="ae kb" rel="noopener ugc nofollow" target="_blank" href="/nlp-using-deepleaning-tutorials-a-sentiment-classifier-based-on-perceptron-part-1-4-712eefe20899">链接</a></li><li id="38e1" class="la lb it ke b kf lj kj lk kn ll kr lm kv ln kz lf lg lh li bi translated">词汇和矢量器(<a class="ae kb" rel="noopener ugc nofollow" target="_blank" href="/nlp-using-deepleaning-tutorials-a-sentiment-classifier-based-on-perceptron-part-2-4-f9b90b3a06bd">链接</a>)</li><li id="7b4a" class="la lb it ke b kf lj kj lk kn ll kr lm kv ln kz lf lg lh li bi translated"><strong class="ke iu">训练套路(当前文章关注这部分)</strong></li><li id="3a77" class="la lb it ke b kf lj kj lk kn ll kr lm kv ln kz lf lg lh li bi translated">评估和推理</li></ol><blockquote class="lo lp lq"><p id="075c" class="kc kd lr ke b kf kg kh ki kj kk kl km ls ko kp kq lt ks kt ku lu kw kx ky kz im bi translated"><strong class="ke iu">提前感谢大家的支持。如果你决定注册成为灵媒会员，这里是我的订阅页面</strong>:<a class="ae kb" href="https://abdelkader-rhouati.medium.com/membership" rel="noopener">https://abdelkader-rhouati.medium.com/membership</a></p></blockquote></div><div class="ab cl lv lw hx lx" role="separator"><span class="ly bw bk lz ma mb"/><span class="ly bw bk lz ma mb"/><span class="ly bw bk lz ma"/></div><div class="im in io ip iq"><h1 id="7842" class="mc md it bd me mf mg mh mi mj mk ml mm mn mo mp mq mr ms mt mu mv mw mx my mz bi translated">第3部分:<strong class="ak">训练程序</strong></h1><p id="a0b4" class="pw-post-body-paragraph kc kd it ke b kf na kh ki kj nb kl km kn nc kp kq kr nd kt ku kv ne kx ky kz im bi translated">在这篇文章中，我们将概述日常训练的步骤。它负责实例化模型、迭代数据集、计算输出、计算损失(误差函数)以及调整模型参数以提高其性能。这个例程是通用的。你需要改变一些地方来适应新的模型，这样它就会成为习惯，并且容易开发新的深度学习过程。</p><h1 id="1614" class="mc md it bd me mf nf mh mi mj ng ml mm mn nh mp mq mr ni mt mu mv nj mx my mz bi translated">二元分类器</h1><p id="960d" class="pw-post-body-paragraph kc kd it ke b kf na kh ki kj nb kl km kn nc kp kq kr nd kt ku kv ne kx ky kz im bi translated">我们使用的模型是感知器分类器的重新实现。要了解更多细节，你可以通过链接参考我以前写的一篇关于这个主题的文章:“<a class="ae kb" rel="noopener ugc nofollow" target="_blank" href="/nlp-using-deep-learning-tutorials-understand-the-perceptron-f2f20b324e63"> NLP使用深度学习教程:理解感知器</a>”。感知器模型是最简单的神经网络，也是最古老的网络之一。但是在某些情况下仍然有效。</p><p id="c3f2" class="pw-post-body-paragraph kc kd it ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz im bi translated">由于我们希望将每个评论分类为负面或正面，因此我们的模型是一个二元分类器。因此，正如您在下面的代码中所看到的，模型“ReviewClassifier”继承了Pytorch模型，并为负类或正类创建了单个线性布局和单个输出。sigmoid函数用作最终非线性度。这就是我在文章《<a class="ae kb" rel="noopener ugc nofollow" target="_blank" href="/nlp-using-deep-learning-tutorials-understand-the-activation-function-8f62613e32d2"> NLP使用深度学习教程:了解激活函数</a>》中详细谈到的激活函数。</p><p id="2ae3" class="pw-post-body-paragraph kc kd it ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz im bi translated">二进制分类代码:</p><figure class="nk nl nm nn gt ju"><div class="bz fp l di"><div class="no np l"/></div></figure><h1 id="6434" class="mc md it bd me mf nf mh mi mj ng ml mm mn nh mp mq mr ni mt mu mv nj mx my mz bi translated">为培训做准备</h1><p id="e9c5" class="pw-post-body-paragraph kc kd it ke b kf na kh ki kj nb kl km kn nc kp kq kr nd kt ku kv ne kx ky kz im bi translated">为了处理关于模型如何工作的高度决策，建议初始化一个args对象来集中协调所有决策。如下所示，我们定义了关于数据集和训练步骤的所有模型参数，也称为超参数。</p><p id="70bb" class="pw-post-body-paragraph kc kd it ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz im bi translated">感知器二元分类器的超参数和选项；</p><figure class="nk nl nm nn gt ju"><div class="bz fp l di"><div class="no np l"/></div></figure><p id="d212" class="pw-post-body-paragraph kc kd it ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz im bi translated">为了跟踪关于训练进度的信息(时期索引、训练损失列表、训练准确度、验证损失、验证准确度、测试损失和测试准确度)，我们使用一个小的python字典变量，如下所示:</p><figure class="nk nl nm nn gt ju"><div class="bz fp l di"><div class="no np l"/></div></figure><p id="a355" class="pw-post-body-paragraph kc kd it ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz im bi translated">接下来的步骤实例化以下项目</p><ul class=""><li id="1704" class="la lb it ke b kf kg kj kk kn lc kr ld kv le kz nq lg lh li bi translated">指示我们使用GPU还是CPU的设备变量</li><li id="a0bb" class="la lb it ke b kf lj kj lk kn ll kr lm kv ln kz nq lg lh li bi translated">数据集，从CSV文件加载数据</li><li id="e897" class="la lb it ke b kf lj kj lk kn ll kr lm kv ln kz nq lg lh li bi translated">将文本项转换成数字向量的矢量器类</li><li id="401a" class="la lb it ke b kf lj kj lk kn ll kr lm kv ln kz nq lg lh li bi translated">分类器模型，我们把它移动到GPU或CPU设备</li><li id="d3b7" class="la lb it ke b kf lj kj lk kn ll kr lm kv ln kz nq lg lh li bi translated">作为损失函数的“BCEWithLogitsLoss”</li><li id="0468" class="la lb it ke b kf lj kj lk kn ll kr lm kv ln kz nq lg lh li bi translated">还有ADAM optimizer，和其他优化器竞争激烈。(详见参考文件【3】)</li></ul><p id="f33a" class="pw-post-body-paragraph kc kd it ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz im bi translated">用于实例化的代码是:</p><figure class="nk nl nm nn gt ju"><div class="bz fp l di"><div class="no np l"/></div></figure><h1 id="0c8b" class="mc md it bd me mf nf mh mi mj ng ml mm mn nh mp mq mr ni mt mu mv nj mx my mz bi translated">训练循环</h1><p id="e2cf" class="pw-post-body-paragraph kc kd it ke b kf na kh ki kj nb kl km kn nc kp kq kr nd kt ku kv ne kx ky kz im bi translated">训练循环使用来自前一阶段的对象来更新模型参数，以便提高其性能和准确性。训练循环是在两个主要循环上完成的:一个是对数据集中的小批进行的内部循环，另一个是将内部循环重复多次的外部循环，称为epochs。历元的数量控制训练应该在数据集上进行多少遍。</p><p id="289f" class="pw-post-body-paragraph kc kd it ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz im bi translated">在外部循环的顶部，我们为epoch索引和批处理生成器添加了一些实例。我们还使用方法“classifier.train()”将模型切换到“训练模式”。这是更新超参数所必需的。</p><p id="cfe4" class="pw-post-body-paragraph kc kd it ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz im bi translated">内部循环包含更新模型参数的基本操作。这分5步完成:</p><ul class=""><li id="4549" class="la lb it ke b kf kg kj kk kn lc kr ld kv le kz nq lg lh li bi translated">步骤1:使用optimizer.zero_grad()重置优化器的梯度</li><li id="9399" class="la lb it ke b kf lj kj lk kn ll kr lm kv ln kz nq lg lh li bi translated">步骤2:输出是模型中的计算机</li><li id="5018" class="la lb it ke b kf lj kj lk kn ll kr lm kv ln kz nq lg lh li bi translated">步骤3:损失函数用于计算模型输出和监督目标(数据集上的真实类别标签)之间的损失</li><li id="ef17" class="la lb it ke b kf lj kj lk kn ll kr lm kv ln kz nq lg lh li bi translated">步骤#4:使用“loss.backward()”将梯度反向传播到每个参数</li><li id="79d0" class="la lb it ke b kf lj kj lk kn ll kr lm kv ln kz nq lg lh li bi translated">第5步:最后一步使用“optimize.step()”方法更新模型的参数。</li></ul><p id="76f9" class="pw-post-body-paragraph kc kd it ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz im bi translated">最后，我们将每个时期的损失和准确性跟踪到变量“train_states”中</p><p id="6942" class="pw-post-body-paragraph kc kd it ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz im bi translated">以下是培训路线的代码:</p><figure class="nk nl nm nn gt ju"><div class="bz fp l di"><div class="no np l"/></div></figure><p id="f228" class="pw-post-body-paragraph kc kd it ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz im bi translated">在运行下一个时期的训练之前，我们在验证数据上添加一个循环，如下面的代码所示。目标是衡量模型对训练期间模型看不到的数据的执行情况。为此，我们使用方法“classifier.eval()”使模型参数不可变，并禁用梯度损失和传播的计算。这很重要，因为我们不希望模型根据验证数据调整其参数。</p><p id="4183" class="pw-post-body-paragraph kc kd it ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz im bi translated">模型验证的代码:</p><figure class="nk nl nm nn gt ju"><div class="bz fp l di"><div class="no np l"/></div></figure><p id="7304" class="pw-post-body-paragraph kc kd it ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz im bi translated"><strong class="ke iu">结论</strong>:</p><p id="6a75" class="pw-post-body-paragraph kc kd it ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz im bi translated">在本文中，我们已经涵盖了我们工作的核心，即我们的机器学习模型的设计和训练。我们已经看到了如何定义一个基于感知器原理的二元分类器。我们创建了代码来训练分类器，并使用验证数据集测量其性能。</p><p id="5cd1" class="pw-post-body-paragraph kc kd it ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz im bi translated">在下一篇文章，也是本系列的最后一篇文章中，我们将展示模型的推理部分，并以一个综合来结束，该综合恢复了所展示模型的一些可能的改进</p><p id="a839" class="pw-post-body-paragraph kc kd it ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz im bi translated"><strong class="ke iu">参考文献:</strong></p><ol class=""><li id="425e" class="la lb it ke b kf kg kj kk kn lc kr ld kv le kz lf lg lh li bi translated">《用Pytorch进行自然语言处理》一书(<a class="ae kb" href="https://www.amazon.fr/Natural-Language-Processing-Pytorch-Applications/dp/1491978236" rel="noopener ugc nofollow" target="_blank">https://www . Amazon . fr/Natural-Language-Processing-py torch-Applications/DP/1491978236</a>)</li><li id="264a" class="la lb it ke b kf lj kj lk kn ll kr lm kv ln kz lf lg lh li bi translated"><a class="ae kb" href="https://pytorch.org/tutorials/beginner/basics/data_tutorial.html?highlight=dataloader" rel="noopener ugc nofollow" target="_blank">https://py torch . org/tutorials/beginner/basics/data _ tutorial . html？高亮显示=数据加载器</a></li><li id="38ef" class="la lb it ke b kf lj kj lk kn ll kr lm kv ln kz lf lg lh li bi translated"><a class="ae kb" href="https://medium.com/mlearning-ai/optimizers-in-deep-learning-7bf81fed78a0" rel="noopener">https://medium . com/mlearning-ai/optimizer-in-deep-learning-7 BF 81 fed 78 a 0</a></li><li id="bc0b" class="la lb it ke b kf lj kj lk kn ll kr lm kv ln kz lf lg lh li bi translated"><a class="ae kb" rel="noopener ugc nofollow" target="_blank" href="/nlp-using-deep-learning-tutorials-understand-the-perceptron-f2f20b324e63">https://pub . toward sai . net/NLP-using-deep-learning-tutorials-understand-the-perceptron-f2f 20b 324 e 63</a></li><li id="47ac" class="la lb it ke b kf lj kj lk kn ll kr lm kv ln kz lf lg lh li bi translated"><a class="ae kb" rel="noopener ugc nofollow" target="_blank" href="/nlp-using-deep-learning-tutorials-understand-loss-function-2aaf73ec6c2b">https://pub . toward sai . net/NLP-using-deep-learning-tutorials-understand-loss-function-2 AAF 73 EC 6 C2 b</a></li><li id="fd85" class="la lb it ke b kf lj kj lk kn ll kr lm kv ln kz lf lg lh li bi translated"><a class="ae kb" rel="noopener ugc nofollow" target="_blank" href="/nlp-using-deep-learning-tutorials-understand-the-activation-function-8f62613e32d2">https://pub . toward sai . net/NLP-using-deep-learning-tutorials-understand-the-activation-function-8f 62613 e32d 2</a></li></ol></div></div>    
</body>
</html>