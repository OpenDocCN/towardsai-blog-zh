<html>
<head>
<title>Tuning Pytorch hyperparameters with Optuna</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">使用Optuna调整Pytorch超参数</h1>
<blockquote>原文：<a href="https://pub.towardsai.net/tuning-pytorch-hyperparameters-with-optuna-470edcfd4dc?source=collection_archive---------0-----------------------#2021-07-18">https://pub.towardsai.net/tuning-pytorch-hyperparameters-with-optuna-470edcfd4dc?source=collection_archive---------0-----------------------#2021-07-18</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><h2 id="0575" class="ir is it bd b dl iu iv iw ix iy iz dk ja translated" aria-label="kicker paragraph"><a class="ae ep" href="https://towardsai.net/p/category/machine-learning" rel="noopener ugc nofollow" target="_blank">机器学习</a></h2><div class=""/><figure class="gl gn ka kb kc kd gh gi paragraph-image"><div role="button" tabindex="0" class="ke kf di kg bf kh"><div class="gh gi jz"><img src="../Images/7707f52a2e44122a3e011d1ea1a8af9e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*GXDvJcKQS-E_bUY4GgMHtw.png"/></div></div><figcaption class="kk kl gj gh gi km kn bd b be z dk translated">作者插图</figcaption></figure><p id="125c" class="pw-post-body-paragraph ko kp it kq b kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj lk ll im bi translated"><em class="lm">这篇文章是Pytorch构建深度学习模型系列指南的第五篇。下面，是全系列:</em></p><ol class=""><li id="2ce6" class="ln lo it kq b kr ks kv kw kz lp ld lq lh lr ll ls lt lu lv bi translated"><a class="ae lw" rel="noopener ugc nofollow" target="_blank" href="/pytorch-tutorial-for-beginners-8331afc552c4"> <em class="lm"> Pytorch初学者教程</em> </a></li><li id="2c7e" class="ln lo it kq b kr lx kv ly kz lz ld ma lh mb ll ls lt lu lv bi translated"><a class="ae lw" href="https://medium.com/mlearning-ai/manipulating-pytorch-datasets-c58487ab113f?sk=5d4cf7bd62d527d7c968b8db696b633f" rel="noopener"> <em class="lm">操纵Pytorch数据集</em> </a></li><li id="7c45" class="ln lo it kq b kr lx kv ly kz lz ld ma lh mb ll ls lt lu lv bi translated"><a class="ae lw" rel="noopener ugc nofollow" target="_blank" href="/understanding-tensor-dimensions-in-deep-learning-models-with-pytorch-4ee828693826"> <em class="lm">理解DL模型中的张量维度</em> </a></li><li id="8f77" class="ln lo it kq b kr lx kv ly kz lz ld ma lh mb ll ls lt lu lv bi translated"><a class="ae lw" href="https://medium.com/dataseries/visualizing-the-feature-maps-and-filters-by-convolutional-neural-networks-e1462340518e" rel="noopener"> <em class="lm"> CNN &amp;功能可视化</em> </a></li><li id="8d26" class="ln lo it kq b kr lx kv ly kz lz ld ma lh mb ll ls lt lu lv bi translated"><em class="lm">用Optuna调整超参数(本帖)</em></li><li id="0714" class="ln lo it kq b kr lx kv ly kz lz ld ma lh mb ll ls lt lu lv bi translated"><a class="ae lw" href="https://medium.com/dataseries/k-fold-cross-validation-with-pytorch-and-sklearn-d094aa00105f" rel="noopener"> <em class="lm"> K折交叉验证</em> </a></li><li id="d3fc" class="ln lo it kq b kr lx kv ly kz lz ld ma lh mb ll ls lt lu lv bi translated"><a class="ae lw" href="https://medium.com/dataseries/convolutional-autoencoder-in-pytorch-on-mnist-dataset-d65145c132ac" rel="noopener"> <em class="lm">卷积自动编码器</em> </a></li><li id="e645" class="ln lo it kq b kr lx kv ly kz lz ld ma lh mb ll ls lt lu lv bi translated"><a class="ae lw" href="https://ai.plainenglish.io/denoising-autoencoder-in-pytorch-on-mnist-dataset-a76b8824e57e" rel="noopener ugc nofollow" target="_blank"> <em class="lm">去噪自动编码器</em> </a></li><li id="6123" class="ln lo it kq b kr lx kv ly kz lz ld ma lh mb ll ls lt lu lv bi translated"><a class="ae lw" href="https://medium.com/dataseries/variational-autoencoder-with-pytorch-2d359cbf027b" rel="noopener"> <em class="lm">变分自动编码器</em> </a></li></ol><p id="7d57" class="pw-post-body-paragraph ko kp it kq b kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj lk ll im bi translated"><em class="lm">本系列的目标是通过实现示例尽可能使Pytorch更直观、更容易理解。互联网上有许多教程可以使用Pytorch构建多种类型的具有挑战性的模型，但同时也会令人困惑，因为当您从一个教程转到另一个教程时，总会有轻微的差异。在这个系列中，我想从最简单的主题开始，到更高级的主题。</em></p></div><div class="ab cl mc md hx me" role="separator"><span class="mf bw bk mg mh mi"/><span class="mf bw bk mg mh mi"/><span class="mf bw bk mg mh"/></div><div class="im in io ip iq"><h1 id="3d1f" class="mj mk it bd ml mm mn mo mp mq mr ms mt mu mv mw mx my mz na nb nc nd ne nf ng bi translated">奥普图纳</h1><p id="5fe1" class="pw-post-body-paragraph ko kp it kq b kr nh kt ku kv ni kx ky kz nj lb lc ld nk lf lg lh nl lj lk ll im bi translated"><a class="ae lw" href="https://optuna.org/" rel="noopener ugc nofollow" target="_blank"> Optuna </a>是一个自动化超参数搜索的超参数优化框架，可应用于机器学习和深度学习模型。由于它使用采样和修剪算法来优化超参数，所以它非常快速和高效。此外，它允许以直观的方式动态构建超参数搜索空间。在这篇文章中，我将结合Pytorch和Optuna来寻找MNIST数据集上表现最好的CNN模型。我将一步一步地展示要优化的函数和超参数，它们都是应用Optuna所需要的。</p><h1 id="5bc8" class="mj mk it bd ml mm nm mo mp mq nn ms mt mu no mw mx my np na nb nc nq ne nf ng bi translated">带Optuna的MNIST分类器</h1><p id="f8e3" class="pw-post-body-paragraph ko kp it kq b kr nh kt ku kv ni kx ky kz nj lb lc ld nk lf lg lh nl lj lk ll im bi translated">我们首先需要安装库Optuna来使它工作:</p><figure class="nr ns nt nu gt kd"><div class="bz fp l di"><div class="nv nw l"/></div></figure><p id="33ba" class="pw-post-body-paragraph ko kp it kq b kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj lk ll im bi translated">之后，让我们导入库和数据集:</p><figure class="nr ns nt nu gt kd"><div class="bz fp l di"><div class="nv nw l"/></div></figure><p id="d88c" class="pw-post-body-paragraph ko kp it kq b kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj lk ll im bi translated">下一步是一起定义卷积神经网络的超参数来调整。</p><figure class="nr ns nt nu gt kd"><div class="bz fp l di"><div class="nv nw l"/></div></figure><p id="e071" class="pw-post-body-paragraph ko kp it kq b kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj lk ll im bi translated">在Optuna中，目标是最小化/最大化目标函数，该函数将一组超参数作为输入，并返回一个验证分数。对于每个超参数，我们考虑不同范围的值。</p><p id="b612" class="pw-post-body-paragraph ko kp it kq b kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj lk ll im bi translated">优化的过程被称为研究，而目标函数的每次评估被称为试验。在模型架构中调用“建议API ”,为每个试验动态生成超参数。</p><p id="db54" class="pw-post-body-paragraph ko kp it kq b kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj lk ll im bi translated">有许多函数来定义超参数的范围:</p><ul class=""><li id="a249" class="ln lo it kq b kr ks kv kw kz lp ld lq lh lr ll nx lt lu lv bi translated"><code class="fe ny nz oa ob b">suggest_int</code>为第二个全连接层的输入单元建议整数值</li><li id="cf3d" class="ln lo it kq b kr lx kv ly kz lz ld ma lh mb ll nx lt lu lv bi translated"><code class="fe ny nz oa ob b">suggest_float</code>建议丢弃率的浮点值，作为第二个卷积层(步长为0.1时为0–0.5)和第一个线性层(步长为0.1时为0–0.3)后的超参数引入。</li><li id="5a6a" class="ln lo it kq b kr lx kv ly kz lz ld ma lh mb ll nx lt lu lv bi translated"><code class="fe ny nz oa ob b">suggest_categorical</code>为优化器建议分类值，这将在后面显示</li></ul><p id="85e0" class="pw-post-body-paragraph ko kp it kq b kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj lk ll im bi translated">如果你想检查其他功能，你应该看文档<a class="ae lw" href="https://optuna.readthedocs.io/en/v1.4.0/reference/trial.html" rel="noopener ugc nofollow" target="_blank">这里</a>。</p><p id="ef70" class="pw-post-body-paragraph ko kp it kq b kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj lk ll im bi translated">我还定义了一个函数来尝试训练集中batch_size的不同值。它将训练数据集和批量大小(稍后将在目标函数中定义)作为输入，并返回训练和验证加载器对象。</p><figure class="nr ns nt nu gt kd"><div class="bz fp l di"><div class="nv nw l"/></div></figure><h1 id="cfc4" class="mj mk it bd ml mm nm mo mp mq nn ms mt mu no mw mx my np na nb nc nq ne nf ng bi translated">最佳化</h1><p id="3870" class="pw-post-body-paragraph ko kp it kq b kr nh kt ku kv ni kx ky kz nj lb lc ld nk lf lg lh nl lj lk ll im bi translated">最重要的步骤是定义目标函数，它使用抽样程序来选择每个试验中超参数的值，并返回该试验中获得的验证准确度。</p><figure class="nr ns nt nu gt kd"><div class="bz fp l di"><div class="nv nw l"/></div></figure><p id="3fa8" class="pw-post-body-paragraph ko kp it kq b kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj lk ll im bi translated">之后，我们可以最终创建一个<code class="fe ny nz oa ob b">study</code>对象来最大化目标函数。我们用<code class="fe ny nz oa ob b">study.optimize(objective,n_trials = 20)</code>进行研究，我们将试验次数固定为20次。你可以根据问题的复杂程度来改变它。</p><figure class="nr ns nt nu gt kd"><div class="bz fp l di"><div class="nv nw l"/></div></figure><p id="2399" class="pw-post-body-paragraph ko kp it kq b kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj lk ll im bi translated">为了更容易地可视化最近5次试验中选择的超参数，我们可以构建一个DataFrame对象:</p><figure class="nr ns nt nu gt kd"><div class="bz fp l di"><div class="nv nw l"/></div></figure><figure class="nr ns nt nu gt kd gh gi paragraph-image"><div role="button" tabindex="0" class="ke kf di kg bf kh"><div class="gh gi oc"><img src="../Images/afd0b57500f423f28c2ec14f7729cc54.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*J1cd8HxNQRGrFpWPdywfgw.png"/></div></div></figure><p id="a3be" class="pw-post-body-paragraph ko kp it kq b kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj lk ll im bi translated">很明显，表现最好的模型在第20次试验中获得了98.9%的验证准确率。此外，您可以看到在该试验中选择的超参数值。</p><h1 id="f147" class="mj mk it bd ml mm nm mo mp mq nn ms mt mu no mw mx my np na nb nc nq ne nf ng bi translated">使用Optuna进行可视化</h1><p id="be09" class="pw-post-body-paragraph ko kp it kq b kr nh kt ku kv ni kx ky kz nj lb lc ld nk lf lg lh nl lj lk ll im bi translated">有许多有趣的可视化方法有助于观察优化的不同方面。我们可以看到随着试验次数的增加，客观值是如何增加的。</p><figure class="nr ns nt nu gt kd"><div class="bz fp l di"><div class="nv nw l"/></div></figure><figure class="nr ns nt nu gt kd gh gi paragraph-image"><div role="button" tabindex="0" class="ke kf di kg bf kh"><div class="gh gi od"><img src="../Images/9f166e747e1af689709bb8f4b0124549.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*e8amUDsYDj8yIX_q0yh5Rg.png"/></div></div></figure><p id="e159" class="pw-post-body-paragraph ko kp it kq b kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj lk ll im bi translated">在x轴上，我们有试验，而在y轴上有客观值，它对应于验证的准确性。仅用20次试验，我们就可以看到我们达到了90%以上的好成绩。</p><p id="ebca" class="pw-post-body-paragraph ko kp it kq b kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj lk ll im bi translated">我们还可以展示不同超参数之间的关系。在这种情况下，我们只关注批量大小和学习率:</p><figure class="nr ns nt nu gt kd"><div class="bz fp l di"><div class="nv nw l"/></div></figure><figure class="nr ns nt nu gt kd gh gi paragraph-image"><div role="button" tabindex="0" class="ke kf di kg bf kh"><div class="gh gi oe"><img src="../Images/94743ab6b1243c656aba1e074df9c114.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*CsFAw_0QUsfsiEbEZOAGsQ.png"/></div></div></figure><p id="53b3" class="pw-post-body-paragraph ko kp it kq b kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj lk ll im bi translated">等高线图是3D图，其中第三维由目标值构成。从中间的聚类(它以浅蓝色着色，表示有非常高的验证准确性),我们可以观察到这些结果是在中等学习率(介于0.001和0.01之间)和低/中等批量的情况下获得的。</p><p id="50da" class="pw-post-body-paragraph ko kp it kq b kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj lk ll im bi translated">通过平行坐标图，我们可以观察到所有的优化历史，这些优化历史被认为是:</p><figure class="nr ns nt nu gt kd"><div class="bz fp l di"><div class="nv nw l"/></div></figure><figure class="nr ns nt nu gt kd gh gi paragraph-image"><div role="button" tabindex="0" class="ke kf di kg bf kh"><div class="gh gi of"><img src="../Images/264092fa068ec0ead7b5cae9b37b0052.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*BQ8zmn6bgo6ASfFS18BCXA.png"/></div></div></figure><p id="bbca" class="pw-post-body-paragraph ko kp it kq b kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj lk ll im bi translated">另一个有用的表示由超参数重要性构成。因此，我们有兴趣了解哪些超参数对模型性能的影响最大。</p><figure class="nr ns nt nu gt kd"><div class="bz fp l di"><div class="nv nw l"/></div></figure><figure class="nr ns nt nu gt kd gh gi paragraph-image"><div role="button" tabindex="0" class="ke kf di kg bf kh"><div class="gh gi og"><img src="../Images/322a0535bd79c9cbff456c1c3a35d105.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*4DzfsvvAjo116L9cyaDEDA.png"/></div></div></figure><p id="b425" class="pw-post-body-paragraph ko kp it kq b kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj lk ll im bi translated">从图中可以看出，学习率对目标值的影响最大，而其余的超参数对学习率的影响很小。辍学率对性能有很小的影响，但仍然需要降低过度拟合的风险。</p></div><div class="ab cl mc md hx me" role="separator"><span class="mf bw bk mg mh mi"/><span class="mf bw bk mg mh mi"/><span class="mf bw bk mg mh"/></div><div class="im in io ip iq"><h1 id="d17b" class="mj mk it bd ml mm mn mo mp mq mr ms mt mu mv mw mx my mz na nb nc nd ne nf ng bi translated">最终想法:</h1><p id="f048" class="pw-post-body-paragraph ko kp it kq b kr nh kt ku kv ni kx ky kz nj lb lc ld nk lf lg lh nl lj lk ll im bi translated">我希望这篇文章能帮助你对Optuna有一个大致的了解。我发现相对于其他方法，如光线调节，它非常直观和快速。这里的GitHub代码是<a class="ae lw" href="https://github.com/eugeniaring/Medium-Articles/blob/main/Pytorch/cnn_optuna.ipynb" rel="noopener ugc nofollow" target="_blank"/>。感谢阅读。祝您愉快！</p></div><div class="ab cl mc md hx me" role="separator"><span class="mf bw bk mg mh mi"/><span class="mf bw bk mg mh mi"/><span class="mf bw bk mg mh"/></div><div class="im in io ip iq"><p id="cc55" class="pw-post-body-paragraph ko kp it kq b kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj lk ll im bi translated">你喜欢我的文章吗？<a class="ae lw" href="https://eugenia-anello.medium.com/membership" rel="noopener"> <em class="lm">成为会员</em> </a> <em class="lm">每天无限获取数据科学新帖！这是一种间接的支持我的方式，不会给你带来任何额外的费用。如果您已经是会员，</em> <a class="ae lw" href="https://eugenia-anello.medium.com/subscribe" rel="noopener"> <em class="lm">订阅</em> </a> <em class="lm">每当我发布新的数据科学和python指南时，您都会收到电子邮件！</em></p></div></div>    
</body>
</html>