<html>
<head>
<title>Graph Neural Networks for Fraud Detection in Crypto Transactions</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">用于密码交易欺诈检测的图形神经网络</h1>
<blockquote>原文：<a href="https://pub.towardsai.net/graph-neural-networks-for-fraud-detection-in-crypto-transactions-6b252325633f?source=collection_archive---------1-----------------------#2022-09-01">https://pub.towardsai.net/graph-neural-networks-for-fraud-detection-in-crypto-transactions-6b252325633f?source=collection_archive---------1-----------------------#2022-09-01</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><p id="41d3" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">在本教程中，我们将应用图卷积网络(GCN)和图注意力网络(GAT)来检测欺诈性比特币交易。还有，我们会比较他们的表现。</p><figure class="km kn ko kp gt kq gh gi paragraph-image"><div role="button" tabindex="0" class="kr ks di kt bf ku"><div class="gh gi kl"><img src="../Images/e13ff2a37c94ef2fcf914955bee49f03.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*Pm52TpYX9oa65UX9"/></div></div><figcaption class="kx ky gj gh gi kz la bd b be z dk translated">照片由<a class="ae lb" href="https://unsplash.com/@deepmind?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> DeepMind </a>在<a class="ae lb" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上拍摄</figcaption></figure><h2 id="6a44" class="lc ld iq bd le lf lg dn lh li lj dp lk jy ll lm ln kc lo lp lq kg lr ls lt lu bi translated">目录</h2><ul class=""><li id="0c71" class="lv lw iq jp b jq lx ju ly jy lz kc ma kg mb kk mc md me mf bi translated">介绍</li><li id="e418" class="lv lw iq jp b jq mg ju mh jy mi kc mj kg mk kk mc md me mf bi translated">基于频谱的卷积GNN</li><li id="af45" class="lv lw iq jp b jq mg ju mh jy mi kc mj kg mk kk mc md me mf bi translated">基于注意力的空间卷积GNN</li><li id="631a" class="lv lw iq jp b jq mg ju mh jy mi kc mj kg mk kk mc md me mf bi translated">资料组</li><li id="9626" class="lv lw iq jp b jq mg ju mh jy mi kc mj kg mk kk mc md me mf bi translated">使用PyTorch几何(PyG)的GCN/GAT节点分类</li><li id="2337" class="lv lw iq jp b jq mg ju mh jy mi kc mj kg mk kk mc md me mf bi translated">参考</li></ul><h2 id="a90a" class="lc ld iq bd le lf lg dn lh li lj dp lk jy ll lm ln kc lo lp lq kg lr ls lt lu bi translated">介绍</h2><p id="b632" class="pw-post-body-paragraph jn jo iq jp b jq lx js jt ju ly jw jx jy ml ka kb kc mm ke kf kg mn ki kj kk ij bi translated">尽管在诸如计算机视觉、自然语言/音频处理、时间序列预测等深度学习领域取得了重大进展。大多数问题与非欧几里德几何数据一起工作，并且作为这种数据的一个例子，社交网络连接、物联网传感器拓扑、分子、基因表达数据等等。数据的非欧几里得性质意味着欧几里得向量空间<strong class="jp ir"> R^n </strong>的所有性质不能应用于这样的数据样本；例如，对于卷积神经网络(CNN)来说，平移不变性是一个重要的属性，但它并没有拯救她。在[1]中，作者解释了如何使用图结构的谱卷积表示将卷积运算转化到非欧几里德域。目前，图形神经网络(GNN)已经在许多领域得到了应用:</p><ul class=""><li id="9a12" class="lv lw iq jp b jq jr ju jv jy mo kc mp kg mq kk mc md me mf bi translated">物理学(粒子系统模拟、机器人学、物体轨迹预测)</li><li id="5160" class="lv lw iq jp b jq mg ju mh jy mi kc mj kg mk kk mc md me mf bi translated">化学和生物学(药物和蛋白质相互作用、蛋白质界面预测、癌症亚型检测、分子指纹、化学反应预测)</li><li id="6225" class="lv lw iq jp b jq mg ju mh jy mi kc mj kg mk kk mc md me mf bi translated">组合优化(用于解决<a class="ae lb" href="https://en.wikipedia.org/wiki/NP-hardness" rel="noopener ugc nofollow" target="_blank"> NP难问题</a>，如<a class="ae lb" href="https://en.wikipedia.org/wiki/Travelling_salesman_problem#:~:text=The%20travelling%20salesman%20problem%20(also,an%20NP%2Dhard%20problem%20in" rel="noopener ugc nofollow" target="_blank">旅行商问题</a>、<a class="ae lb" href="https://en.wikipedia.org/wiki/Minimum_spanning_tree#:~:text=A%20minimum%20spanning%20tree%20(MST,minimum%20possible%20total%20edge%20weight." rel="noopener ugc nofollow" target="_blank">最小生成树</a></li><li id="2d1a" class="lv lw iq jp b jq mg ju mh jy mi kc mj kg mk kk mc md me mf bi translated">交通网络(交通预测、出租车需求问题)</li><li id="ce14" class="lv lw iq jp b jq mg ju mh jy mi kc mj kg mk kk mc md me mf bi translated">推荐系统(用户和内容项目之间的链接预测，社交网络推荐)</li><li id="e226" class="lv lw iq jp b jq mg ju mh jy mi kc mj kg mk kk mc md me mf bi translated">计算机视觉(场景图形生成、点云分类、动作识别、语义分割、少镜头图像分类、视觉推理)</li><li id="65b0" class="lv lw iq jp b jq mg ju mh jy mi kc mj kg mk kk mc md me mf bi translated">自然语言处理(文本分类、序列标记、神经机器翻译、关系提取、问题回答)</li></ul><p id="eab7" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">在最新的gnn类别中，我们可以将它们区分为递归gnn、卷积gnn、图形自动编码器、生成gnn和时空gnn。</p><p id="213e" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">在本教程中，我们将考虑使用图卷积网络和图注意网络的半监督节点分类问题，并在包含加密交易数据的椭圆数据集上比较它们的性能。此外，我们将强调他们的积木概念，这来自基于频谱和基于空间的卷积表示。</p><h2 id="164e" class="lc ld iq bd le lf lg dn lh li lj dp lk jy ll lm ln kc lo lp lq kg lr ls lt lu bi translated">基于频谱的卷积GNN</h2><p id="aee9" class="pw-post-body-paragraph jn jo iq jp b jq lx js jt ju ly jw jx jy ml ka kb kc mm ke kf kg mn ki kj kk ij bi translated">基于频谱的模型的数学基础来自图形信号处理领域；已知的模型有切布内、GCN、AGCN和DGCN。为了理解这类模型的原理，让我们考虑谱卷积的概念[2，3]。</p><p id="587a" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">假设我们有一个来自<strong class="jp ir"> R^n的图信号<strong class="jp ir"> x </strong>，</strong>它是一个图的所有节点的特征向量，x_i是第I个节点<strong class="jp ir">的值。</strong>通过应用傅立叶变换进行卷积运算，该图形信号首先被变换到频谱域。卷积后，使用逆图傅立叶变换将结果信号转换回来。这些变换定义为:</p><figure class="km kn ko kp gt kq gh gi paragraph-image"><div class="gh gi mr"><img src="../Images/e08694b0a293339296ceadd5f188e14a.png" data-original-src="https://miro.medium.com/v2/resize:fit:480/format:webp/1*DYhVks2fDViJM6n6c1GmJw.png"/></div></figure><p id="14c7" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">这里<strong class="jp ir"> U </strong>是归一化图拉普拉斯的特征向量矩阵</p><figure class="km kn ko kp gt kq gh gi paragraph-image"><div role="button" tabindex="0" class="kr ks di kt bf ku"><div class="gh gi ms"><img src="../Images/2ef027a77d7f3546ad6ed5df268f2ed4.png" data-original-src="https://miro.medium.com/v2/resize:fit:688/format:webp/1*Q8yNKur9NJrZ2t8X2JMm0g.png"/></div></div></figure><p id="73f3" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">其中<strong class="jp ir"> D </strong>为度矩阵，<strong class="jp ir"> A </strong>为图的邻接矩阵，<strong class="jp ir"> I_ <em class="mt"> N </em> </strong>为单位矩阵。归一化图拉普拉斯算子可以分解为</p><figure class="km kn ko kp gt kq gh gi paragraph-image"><div class="gh gi mu"><img src="../Images/d68300f9f7f376bb893237613cdbf11e.png" data-original-src="https://miro.medium.com/v2/resize:fit:364/format:webp/1*6tW8hFCxm-14e03FHcWiaA.png"/></div></figure><p id="9014" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">基于卷积定理，滤波器<strong class="jp ir"> g </strong>的卷积运算可定义为:</p><figure class="km kn ko kp gt kq gh gi paragraph-image"><div class="gh gi mv"><img src="../Images/0dd6d2526d504016ae0e5c16e189928b.png" data-original-src="https://miro.medium.com/v2/resize:fit:892/format:webp/1*ZbCaL9w15o6iawlee8Pn3A.png"/></div></figure><p id="6c2b" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">如果我们将滤波器表示为<strong class="jp ir"> g </strong>作为<strong class="jp ir"> U^T </strong> * <strong class="jp ir"> g </strong>的可学习对角矩阵，那么我们得到</p><figure class="km kn ko kp gt kq gh gi paragraph-image"><div class="gh gi mw"><img src="../Images/0bd27000e8f4b90af212b859e35d792e.png" data-original-src="https://miro.medium.com/v2/resize:fit:596/format:webp/1*jBu4b2Kme3kJqxleqmOQTw.png"/></div></figure><p id="79a0" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">我们可以把<strong class="jp ir"> g_w </strong>理解为<strong class="jp ir"> L </strong>的特征值的函数。与特征向量矩阵<strong class="jp ir"> U </strong>相乘的评估需要O(N)时间复杂度；为了克服这个问题，在契布内和GCN的论文中，使用了切比雪夫多项式。对于ChebNet，谱卷积运算表示如下。</p><figure class="km kn ko kp gt kq gh gi paragraph-image"><div class="gh gi mx"><img src="../Images/22f38523073628a980f61d40a6c5f63a.png" data-original-src="https://miro.medium.com/v2/resize:fit:852/format:webp/1*Cpo4ynP4I7EZKaF44ZuhfA.png"/></div></figure><figure class="km kn ko kp gt kq gh gi paragraph-image"><div class="gh gi my"><img src="../Images/c6f974c5f90b4798c2fbd12aa203f2a6.png" data-original-src="https://miro.medium.com/v2/resize:fit:496/format:webp/1*FPFHEQ9o0_NCTV_mj53FSA.png"/></div></figure><p id="3c75" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">为了避免过拟合的问题，在<strong class="jp ir"> GCN </strong>中，使用了K=1和λ_ max = 2的切比雪夫近似。卷积运算符将变成如下形式。</p><figure class="km kn ko kp gt kq gh gi paragraph-image"><div role="button" tabindex="0" class="kr ks di kt bf ku"><div class="gh gi mz"><img src="../Images/888664d307a054008a58b2a2efbc7ceb.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*R0Np7KtVZmSBRB8Z1zv-bw.png"/></div></div></figure><p id="aba6" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">假设，w = w_0 = -w_1，我们得到</p><figure class="km kn ko kp gt kq gh gi paragraph-image"><div class="gh gi na"><img src="../Images/894c3584ea11c1ea5c476a00f4bd9b13.png" data-original-src="https://miro.medium.com/v2/resize:fit:1028/format:webp/1*wzetgmjC7dpuyrByK7f2nQ.png"/></div></figure><p id="f746" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">GCN进一步引入了一个归一化技巧来解决爆炸/消失梯度问题</p><figure class="km kn ko kp gt kq gh gi paragraph-image"><div class="gh gi nb"><img src="../Images/66342bf429c2a4e3ff6c79079de7f1ff.png" data-original-src="https://miro.medium.com/v2/resize:fit:1008/format:webp/1*W5U4hyc9yr07AIiTiQzSJA.png"/></div></figure><figure class="km kn ko kp gt kq gh gi paragraph-image"><div class="gh gi nc"><img src="../Images/ee9b5e024d1c49d18473c25f398f2231.png" data-original-src="https://miro.medium.com/v2/resize:fit:396/format:webp/1*_S17giANf_kqhndOBUG3uw.png"/></div></figure><figure class="km kn ko kp gt kq gh gi paragraph-image"><div class="gh gi nd"><img src="../Images/981d2c0a4539c6de7bab367d7730f7bf.png" data-original-src="https://miro.medium.com/v2/resize:fit:440/format:webp/1*biCc6tcBiGihnpiVPDUskw.png"/></div></figure><p id="b8c1" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">最后，GCN的紧凑形式被定义为</p><figure class="km kn ko kp gt kq gh gi paragraph-image"><div class="gh gi ne"><img src="../Images/412fc8a60d4c552cccd9bb2fc3e9ef2d.png" data-original-src="https://miro.medium.com/v2/resize:fit:724/format:webp/1*2xUv_SLJJ2U1YPxUlSNfFg.png"/></div></figure><p id="1eed" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">这里<strong class="jp ir"> X </strong>是<strong class="jp ir"> </strong>输入特征矩阵，dim( <strong class="jp ir"> X </strong> ) = N x F^0，n是节点数，每个节点输入特征的F^0数；</p><p id="1d32" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated"><strong class="jp ir"> A </strong>是邻接矩阵，dim(<strong class="jp ir">A</strong>)= N×N；</p><p id="d031" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated"><strong class="jp ir"> W </strong>为权重矩阵，dim(<strong class="jp ir">W</strong>)= F×F’，F为输入特征数，F’为输出特征数；</p><p id="0f07" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated"><strong class="jp ir"> H </strong>代表图神经网络的一个隐层，dim(<strong class="jp ir">H</strong>)= N x F’。</p><p id="3d8d" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">在每个第I层<strong class="jp ir"> H_i </strong>处，使用传播规则f(例如sigmoid/relu)聚合特征以形成下一层的特征，因此特征在每个连续层处变得越来越抽象，这提醒了CNN的原理。</p><h2 id="e620" class="lc ld iq bd le lf lg dn lh li lj dp lk jy ll lm ln kc lo lp lq kg lr ls lt lu bi translated">基于注意力的空间卷积GNN</h2><p id="db92" class="pw-post-body-paragraph jn jo iq jp b jq lx js jt ju ly jw jx jy ml ka kb kc mm ke kf kg mn ki kj kk ij bi translated">在基于空间的卷积GNN模型中，以下模型广为人知:GraphSage、GAT、MoNet、GAAN、DiffPool等。工作原理类似于CNN卷积运算符应用于图像数据，除了空间方法将卷积应用于图形的不同大小的节点邻居。</p><p id="c3e5" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">由于在NLP任务中使用的模型，注意机制获得了广泛的流行(例如，注意的LSTM，变形金刚)。在GNN具有注意机制的情况下，相邻节点对所考虑节点的贡献既不相同也不预先定义，例如在GraphSage或GCN模型中。</p><p id="c0f7" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">我们来看看GAT的注意机制[4]；该模型的标准化关注系数可通过以下公式计算:</p><figure class="km kn ko kp gt kq gh gi paragraph-image"><div role="button" tabindex="0" class="kr ks di kt bf ku"><div class="gh gi nf"><img src="../Images/134614ca950c0ad9609abc53c01691de.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*BXtxXGwaBMNgK86q9B2ZDA.png"/></div></div></figure><p id="75ac" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">这里，<em class="mt"> T </em>表示换位，||是串联运算；</p><p id="b1d1" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated"><strong class="jp ir"> h </strong>是一组节点特征(N是节点数，F是每个节点中的特征数)</p><figure class="km kn ko kp gt kq gh gi paragraph-image"><div class="gh gi ng"><img src="../Images/486beace5ebf5b460a33843a57f24e5c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1104/format:webp/1*ARv3H5g_q2uqMbeRadAQ3A.png"/></div></figure><p id="77a6" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated"><strong class="jp ir"> W </strong>是权重矩阵(线性变换为a特征)，dim(<strong class="jp ir">W</strong>)= F’x F</p><p id="7874" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">向量<strong class="jp ir"> a </strong>是单层前馈神经网络的权重向量</p><figure class="km kn ko kp gt kq gh gi paragraph-image"><div class="gh gi nh"><img src="../Images/46d9c6d42d5d786203abac6b4be238c3.png" data-original-src="https://miro.medium.com/v2/resize:fit:324/format:webp/1*4Nu1nmo4uecXvDC3q5xvIg.png"/></div></figure><p id="33bd" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">softmax函数确保关注权重总计为第I个节点的一个整体邻居。</p><p id="700f" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">最后，使用这些标准化的关注系数来计算与其对应的特征的线性组合，以作为每个节点的最终输出特征。</p><figure class="km kn ko kp gt kq gh gi paragraph-image"><div class="gh gi ni"><img src="../Images/21b990903cff55ed05538eddf88ada7f.png" data-original-src="https://miro.medium.com/v2/resize:fit:940/format:webp/1*rX1M2vWMmSY7MEXgcXpZsQ.png"/></div></figure><p id="18d3" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">使用单个自我注意会导致不稳定性，在这种情况下，使用具有K个独立注意机制的多头注意</p><figure class="km kn ko kp gt kq gh gi paragraph-image"><div class="gh gi nj"><img src="../Images/773e1720d4cd3f72a86bb71e00a53fb9.png" data-original-src="https://miro.medium.com/v2/resize:fit:1064/format:webp/1*EvUM_D-pO6HgTtihTCYxUg.png"/></div></figure><h2 id="6297" class="lc ld iq bd le lf lg dn lh li lj dp lk jy ll lm ln kc lo lp lq kg lr ls lt lu bi translated">资料组</h2><p id="642d" class="pw-post-body-paragraph jn jo iq jp b jq lx js jt ju ly jw jx jy ml ka kb kc mm ke kf kg mn ki kj kk ij bi translated">这里，对于节点分类任务，我们将使用<a class="ae lb" href="https://www.kaggle.com/datasets/ellipticco/elliptic-data-set" rel="noopener ugc nofollow" target="_blank">椭圆数据集</a>。数据集由203 769个节点和234 355条边组成。有三类节点:“合法”、“非法”或“未知”。如果相应的交易是由属于合法的实体(交易所、钱包提供商、矿工、金融服务提供商等)创建的，则节点被视为“合法”/“非法”。)或非法(骗局、恶意软件、恐怖组织、勒索软件、庞氏骗局等。)类别。该数据集的详细描述可在下面的文章中获得，“椭圆数据集:在区块链上开启机器学习”。</p><h2 id="69ce" class="lc ld iq bd le lf lg dn lh li lj dp lk jy ll lm ln kc lo lp lq kg lr ls lt lu bi translated">使用PyTorch几何(PyG)的GCN/GAT节点分类</h2><p id="fefd" class="pw-post-body-paragraph jn jo iq jp b jq lx js jt ju ly jw jx jy ml ka kb kc mm ke kf kg mn ki kj kk ij bi translated">这里我们将考虑使用PyG库的半监督节点分类问题，其中节点将是事务，边将是事务流。</p><figure class="km kn ko kp gt kq"><div class="bz fp l di"><div class="nk nl l"/></div></figure><p id="d4b1" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">您可以简单地使用下面的说明从PyG预安装的数据集中导入椭圆比特币数据集，但为了清楚起见，让我们自己构建PyG数据集对象。原始数据可以通过<a class="ae lb" href="https://www.kaggle.com/datasets/ellipticco/elliptic-data-set" rel="noopener ugc nofollow" target="_blank">这个链接</a>下载。</p><pre class="km kn ko kp gt nm nn no np aw nq bi"><span id="7097" class="lc ld iq nn b gy nr ns l nt nu">from torch_geometric.datasets import EllipticBitcoinDataset</span><span id="98b4" class="lc ld iq nn b gy nv ns l nt nu">dataset = EllipticBitcoinDataset(root=’./data/elliptic-bitcoin-dataset’)</span></pre><figure class="km kn ko kp gt kq"><div class="bz fp l di"><div class="nk nl l"/></div></figure><p id="9c49" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated"><strong class="jp ir">数据加载/准备</strong></p><p id="2292" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">为了数据准备，我用了这个<a class="ae lb" href="https://www.kaggle.com/code/divyareddyyeruva/elliptic-gcn-pyg" rel="noopener ugc nofollow" target="_blank"> Kaggle笔记本</a>作为基础。</p><figure class="km kn ko kp gt kq"><div class="bz fp l di"><div class="nk nl l"/></div></figure><pre class="km kn ko kp gt nm nn no np aw nq bi"><span id="cda2" class="lc ld iq nn b gy nr ns l nt nu"># here column 0 stands for node_id, column 1 is the time axis<br/>df_features.head()</span></pre><figure class="km kn ko kp gt kq gh gi paragraph-image"><div role="button" tabindex="0" class="kr ks di kt bf ku"><div class="gh gi nw"><img src="../Images/9fd4c7b00bcc17a897355270c73be7b3.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*nL_Ph3Ngsrhb4KOAtyAWwg.png"/></div></div></figure><pre class="km kn ko kp gt nm nn no np aw nq bi"><span id="c875" class="lc ld iq nn b gy nr ns l nt nu">df_edges.head()</span></pre><figure class="km kn ko kp gt kq gh gi paragraph-image"><div class="gh gi nx"><img src="../Images/e0257fc3f9ac8bf411eb0073496cafdc.png" data-original-src="https://miro.medium.com/v2/resize:fit:740/format:webp/1*O5iFBskduZgsd91DCTjN-Q.png"/></div></figure><pre class="km kn ko kp gt nm nn no np aw nq bi"><span id="e50b" class="lc ld iq nn b gy nr ns l nt nu">df_classes.head()</span></pre><figure class="km kn ko kp gt kq gh gi paragraph-image"><div class="gh gi ny"><img src="../Images/47d5af440035ae78eef96fa79505452b.png" data-original-src="https://miro.medium.com/v2/resize:fit:588/format:webp/1*Js1IfK-9lCx5b4aVnfXB2Q.png"/></div></figure><p id="5b22" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">0 —合法<br/> 1 —欺诈<br/> 2 —未知类别</p><pre class="km kn ko kp gt nm nn no np aw nq bi"><span id="40c8" class="lc ld iq nn b gy nr ns l nt nu">df_classes['class'].value_counts()</span></pre><figure class="km kn ko kp gt kq gh gi paragraph-image"><div class="gh gi nz"><img src="../Images/48c45c8905e7f82fddb09a284cb0565a.png" data-original-src="https://miro.medium.com/v2/resize:fit:832/format:webp/1*zYG_n8cv1e-QBegHtw7K-w.png"/></div></figure><figure class="km kn ko kp gt kq"><div class="bz fp l di"><div class="nk nl l"/></div></figure><p id="8aa9" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated"><strong class="jp ir">准备边缘</strong></p><figure class="km kn ko kp gt kq"><div class="bz fp l di"><div class="nk nl l"/></div></figure><pre class="km kn ko kp gt nm nn no np aw nq bi"><span id="b686" class="lc ld iq nn b gy nr ns l nt nu">Total amount of edges in DAG: torch.Size([2, 234355])</span></pre><p id="7c9f" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated"><strong class="jp ir">准备节点</strong></p><p id="d0cb" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">让我们忽略时间轴，考虑欺诈检测的静态情况。</p><figure class="km kn ko kp gt kq"><div class="bz fp l di"><div class="nk nl l"/></div></figure><p id="c514" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated"><strong class="jp ir"> PyG数据集</strong></p><figure class="km kn ko kp gt kq"><div class="bz fp l di"><div class="nk nl l"/></div></figure><pre class="km kn ko kp gt nm nn no np aw nq bi"><span id="e800" class="lc ld iq nn b gy nr ns l nt nu">Number of nodes: 203769<br/>Number of node features: 165<br/>Number of edges: 234355<br/>Number of edge features: 165<br/>Average node degree: 1.15<br/>Number of classes: 2<br/>Has isolated nodes: False<br/>Has self loops: False<br/>Is directed: True</span></pre><figure class="km kn ko kp gt kq"><div class="bz fp l di"><div class="nk nl l"/></div></figure><pre class="km kn ko kp gt nm nn no np aw nq bi"><span id="5580" class="lc ld iq nn b gy nr ns l nt nu">Train dataset size: 39579<br/>Validation dataset size: 6985<br/>Test dataset size: 157205</span></pre><p id="9895" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated"><strong class="jp ir">型号</strong></p><figure class="km kn ko kp gt kq"><div class="bz fp l di"><div class="nk nl l"/></div></figure><p id="ea90" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated"><strong class="jp ir">培训/测试助手</strong></p><figure class="km kn ko kp gt kq"><div class="bz fp l di"><div class="nk nl l"/></div></figure><p id="88c3" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated"><strong class="jp ir">火车GCN </strong></p><figure class="km kn ko kp gt kq"><div class="bz fp l di"><div class="nk nl l"/></div></figure><pre class="km kn ko kp gt nm nn no np aw nq bi"><span id="7070" class="lc ld iq nn b gy nr ns l nt nu">Epoch   0 | Train Loss: 0.759 | Train Acc:  62.16% | Val Loss: 0.73 | Val Acc: 64.07%<br/>Saving model for best loss<br/>Epoch  10 | Train Loss: 0.307 | Train Acc:  86.43% | Val Loss: 0.30 | Val Acc: 87.16%<br/>Saving model for best loss<br/>Epoch  20 | Train Loss: 0.258 | Train Acc:  89.52% | Val Loss: 0.25 | Val Acc: 89.61%<br/>Saving model for best loss<br/>Epoch  30 | Train Loss: 0.244 | Train Acc:  90.49% | Val Loss: 0.24 | Val Acc: 90.32%<br/>Saving model for best loss<br/>Epoch  40 | Train Loss: 0.230 | Train Acc:  91.32% | Val Loss: 0.22 | Val Acc: 91.40%<br/>Saving model for best loss<br/>Epoch  50 | Train Loss: 0.219 | Train Acc:  91.85% | Val Loss: 0.22 | Val Acc: 91.77%<br/>Saving model for best loss<br/>Epoch  60 | Train Loss: 0.214 | Train Acc:  92.35% | Val Loss: 0.21 | Val Acc: 92.61%<br/>Saving model for best loss<br/>Epoch  70 | Train Loss: 0.210 | Train Acc:  92.60% | Val Loss: 0.21 | Val Acc: 92.80%<br/>Saving model for best loss<br/>Epoch  80 | Train Loss: 0.201 | Train Acc:  92.86% | Val Loss: 0.20 | Val Acc: 92.81%<br/>Saving model for best loss<br/>Epoch  90 | Train Loss: 0.195 | Train Acc:  93.15% | Val Loss: 0.20 | Val Acc: 92.81%<br/>Saving model for best loss<br/>Epoch 100 | Train Loss: 0.194 | Train Acc:  93.25% | Val Loss: 0.19 | Val Acc: 93.53%<br/>Saving model for best loss</span></pre><p id="b2e4" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated"><strong class="jp ir">测试GCN </strong></p><figure class="km kn ko kp gt kq"><div class="bz fp l di"><div class="nk nl l"/></div></figure><figure class="km kn ko kp gt kq gh gi paragraph-image"><div role="button" tabindex="0" class="kr ks di kt bf ku"><div class="gh gi oa"><img src="../Images/02cd849e3c07ff0b81fe19dc070d8130.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*hWnNZ-SjdBEBkWDUTcTS8A.png"/></div></div></figure><p id="f61a" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated"><strong class="jp ir">火车GAT </strong></p><figure class="km kn ko kp gt kq"><div class="bz fp l di"><div class="nk nl l"/></div></figure><pre class="km kn ko kp gt nm nn no np aw nq bi"><span id="4e94" class="lc ld iq nn b gy nr ns l nt nu">Epoch   0 | Train Loss: 1.176 | Train Acc:  68.34% | Val Loss: 1.01 | Val Acc: 68.33%<br/>Saving model for best loss<br/>Epoch  10 | Train Loss: 0.509 | Train Acc:  88.63% | Val Loss: 0.48 | Val Acc: 88.70%<br/>Saving model for best loss<br/>Epoch  20 | Train Loss: 0.489 | Train Acc:  90.09% | Val Loss: 0.49 | Val Acc: 89.94%<br/>Epoch  30 | Train Loss: 0.465 | Train Acc:  89.87% | Val Loss: 0.48 | Val Acc: 89.76%<br/>Saving model for best loss<br/>Epoch  40 | Train Loss: 0.448 | Train Acc:  89.81% | Val Loss: 0.44 | Val Acc: 90.15%<br/>Saving model for best loss<br/>Epoch  50 | Train Loss: 0.445 | Train Acc:  90.04% | Val Loss: 0.44 | Val Acc: 89.89%<br/>Epoch  60 | Train Loss: 0.443 | Train Acc:  90.22% | Val Loss: 0.44 | Val Acc: 90.45%<br/>Epoch  70 | Train Loss: 0.439 | Train Acc:  90.38% | Val Loss: 0.43 | Val Acc: 90.16%<br/>Saving model for best loss<br/>Epoch  80 | Train Loss: 0.426 | Train Acc:  90.57% | Val Loss: 0.43 | Val Acc: 90.41%<br/>Saving model for best loss<br/>Epoch  90 | Train Loss: 0.423 | Train Acc:  90.72% | Val Loss: 0.42 | Val Acc: 90.38%<br/>Saving model for best loss<br/>Epoch 100 | Train Loss: 0.418 | Train Acc:  90.72% | Val Loss: 0.42 | Val Acc: 90.74%<br/>Saving model for best loss</span></pre><p id="b7f1" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated"><strong class="jp ir">测试门</strong></p><figure class="km kn ko kp gt kq"><div class="bz fp l di"><div class="nk nl l"/></div></figure><figure class="km kn ko kp gt kq gh gi paragraph-image"><div role="button" tabindex="0" class="kr ks di kt bf ku"><div class="gh gi ob"><img src="../Images/aafd311c4de76585c7a195f01bb03f01.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*gwDndNCapFEJvAs5_WFtsQ.png"/></div></div></figure><p id="a832" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">👉🏻完整的代码也可以通过我的GitHub获得。</p><p id="6f2b" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated"><strong class="jp ir">结论</strong></p><p id="22b8" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">从计算结果可以看出，GAT模型与GCN相比收敛较慢，训练/验证精度略低于GCN。然而，从验证数据(标记数据)构建的混淆矩阵显示，召回度量从0.45 (GCN)提高到0.67 (GAT)。因此，GAT模型比GCN模型更清楚地识别欺诈者，但对合法案件也更严格。对包含157205个样本的未标记数据的测试表明，在GCN的情况下，只有6 %的欺诈案件，而在GAT的情况下，这一数量约为18 %。</p></div><div class="ab cl oc od hu oe" role="separator"><span class="of bw bk og oh oi"/><span class="of bw bk og oh oi"/><span class="of bw bk og oh"/></div><div class="ij ik il im in"><h2 id="5d1a" class="lc ld iq bd le lf lg dn lh li lj dp lk jy ll lm ln kc lo lp lq kg lr ls lt lu bi translated"><strong class="ak">参考文献</strong></h2><ol class=""><li id="c087" class="lv lw iq jp b jq lx ju ly jy lz kc ma kg mb kk oj md me mf bi translated">布朗斯坦m .等人，几何深度学习:超越欧几里德数据(2017)，IEEE SIG PROC MAG，【https://arxiv.org/pdf/1611.08097.pdf T2】</li><li id="dbbc" class="lv lw iq jp b jq mg ju mh jy mi kc mj kg mk kk oj md me mf bi translated">Kipf T. N .，Welling M .利用图卷积网络的半监督分类(2017)，https://arxiv.org/pdf/1609.02907.pdf<a class="ae lb" href="https://arxiv.org/pdf/1609.02907.pdf" rel="noopener ugc nofollow" target="_blank">ICLR</a></li><li id="9505" class="lv lw iq jp b jq mg ju mh jy mi kc mj kg mk kk oj md me mf bi translated">周军等，图形神经网络:方法与应用综述(2020)，人工智能开放，第1卷，<a class="ae lb" href="https://doi.org/10.1016/j.aiopen.2021.01.001" rel="noopener ugc nofollow" target="_blank">https://doi.org/10.1016/j.aiopen.2021.01.001</a></li><li id="69d3" class="lv lw iq jp b jq mg ju mh jy mi kc mj kg mk kk oj md me mf bi translated">Velickovic P .等人，图形注意力网络(2018)，https://arxiv.org/pdf/1710.10903.pdf ICLR<a class="ae lb" href="https://arxiv.org/pdf/1710.10903.pdf" rel="noopener ugc nofollow" target="_blank"/></li></ol></div></div>    
</body>
</html>