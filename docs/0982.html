<html>
<head>
<title>Summarization with Simple Transformers</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">简单变压器总结</h1>
<blockquote>原文：<a href="https://pub.towardsai.net/summarization-with-simple-transformers-14d158686faa?source=collection_archive---------3-----------------------#2020-09-27">https://pub.towardsai.net/summarization-with-simple-transformers-14d158686faa?source=collection_archive---------3-----------------------#2020-09-27</a></blockquote><div><div class="fc ii ij ik il im"/><div class="in io ip iq ir"><h2 id="d05a" class="is it iu bd b dl iv iw ix iy iz ja dk jb translated" aria-label="kicker paragraph"><a class="ae ep" href="https://towardsai.net/p/category/nlp" rel="noopener ugc nofollow" target="_blank">自然语言处理</a></h2><div class=""/><div class=""><h2 id="a8b5" class="pw-subtitle-paragraph ka jd iu bd b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr dk translated">使用简单的转换器生成摘要的实践指南</h2></div><figure class="kt ku kv kw gu kx gi gj paragraph-image"><div role="button" tabindex="0" class="ky kz di la bf lb"><div class="gi gj ks"><img src="../Images/8a5f0399c5fc8b9591956da1f7d6abd5.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*P9prjH_5UI6jP1i5"/></div></div><figcaption class="le lf gk gi gj lg lh bd b be z dk translated">在<a class="ae li" href="https://unsplash.com/photos/uPuh-VwJRM0" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上由<a class="ae li" href="https://unsplash.com/@tetrakiss" rel="noopener ugc nofollow" target="_blank"> Arseny Togulev </a>拍照</figcaption></figure><p id="cc63" class="pw-post-body-paragraph lj lk iu ll b lm ln ke lo lp lq kh lr ls lt lu lv lw lx ly lz ma mb mc md me in bi translated">Simpletransformers库建立在Huggingface的变形金刚之上。我都用过，发现简单的变压器非常容易使用和直观。它帮助我们解决诸如分类、问题回答、语言建模、用于摘要的Seq2Seq模型等问题。在这篇文章中，我们将致力于文本摘要。你应该探究他们的<a class="ae li" href="https://github.com/ThilinaRajapakse/simpletransformers" rel="noopener ugc nofollow" target="_blank"> GitHub repo </a>和<a class="ae li" href="https://simpletransformers.ai/" rel="noopener ugc nofollow" target="_blank">文档</a>以获得更多细节。</p></div><div class="ab cl mf mg hy mh" role="separator"><span class="mi bw bk mj mk ml"/><span class="mi bw bk mj mk ml"/><span class="mi bw bk mj mk"/></div><div class="in io ip iq ir"><h1 id="901d" class="mm mn iu bd mo mp mq mr ms mt mu mv mw kj mx kk my km mz kn na kp nb kq nc nd bi translated">导入库和数据集</h1><p id="2295" class="pw-post-body-paragraph lj lk iu ll b lm ne ke lo lp nf kh lr ls ng lu lv lw nh ly lz ma ni mc md me in bi translated">将数据集从Kaggle下载到Colab。从你的Kaggle个人资料导航到<code class="fe nj nk nl nm b">My Account &gt; API</code>，然后点击<code class="fe nj nk nl nm b">Create New API Token.</code>，这将下载<code class="fe nj nk nl nm b">kaggle.json</code>文件。一旦你有了这个文件，运行下面的代码。在执行过程中，它会提示您上传一个JSON文件，以便您可以上传<code class="fe nj nk nl nm b">kaggle.json</code>文件。此外，我们将从Kaggle下载BBC新闻文章并解压</p><pre class="kt ku kv kw gu nn nm no np aw nq bi"><span id="9651" class="nr mn iu nm b gz ns nt l nu nv">from google.colab import files<br/>files.upload()<br/>!pip install -q kaggle<br/>!mkdir ~/.kaggle<br/>!cp kaggle.json ~/.kaggle/<br/>!chmod 600 ~/.kaggle/kaggle.json<br/>!kaggle datasets download -d pariza/bbc-news-summary<br/>!unzip bbc-news-summary.zip</span></pre><p id="796e" class="pw-post-body-paragraph lj lk iu ll b lm ln ke lo lp lq kh lr ls lt lu lv lw lx ly lz ma mb mc md me in bi translated">因为Google Colab预装了变形金刚，所以让我们升级变形金刚库，这样我们就有了它的最新版本，然后安装简单的变形金刚:</p><pre class="kt ku kv kw gu nn nm no np aw nq bi"><span id="8e20" class="nr mn iu nm b gz ns nt l nu nv">!pip install --upgrade transformers<br/>!pip install simpletransformers</span></pre><p id="ea8b" class="pw-post-body-paragraph lj lk iu ll b lm ln ke lo lp lq kh lr ls lt lu lv lw lx ly lz ma mb mc md me in bi translated">现在，导入所有必需的库:</p><pre class="kt ku kv kw gu nn nm no np aw nq bi"><span id="35e6" class="nr mn iu nm b gz ns nt l nu nv">import logging<br/>import pandas as pd<br/>from sklearn.model_selection import train_test_split<br/>from simpletransformers.seq2seq import Seq2SeqModel, Seq2SeqArgs</span></pre><h1 id="7c34" class="mm mn iu bd mo mp nw mr ms mt nx mv mw kj ny kk my km nz kn na kp oa kq nc nd bi translated">预处理</h1><p id="924c" class="pw-post-body-paragraph lj lk iu ll b lm ne ke lo lp nf kh lr ls ng lu lv lw nh ly lz ma ni mc md me in bi translated">BBC新闻文章数据集对每个类别都有不同的文件夹——商业、娱乐、政治、体育和科技。但是为了简单起见，我们在这里只考虑业务类别。但是，您可以自由地在这些文件夹或您选择的任何数据集上尝试摘要。请注意，总结的准确性取决于我们在模型构建中使用的预训练和微调数据集。</p><p id="a59c" class="pw-post-body-paragraph lj lk iu ll b lm ln ke lo lp lq kh lr ls lt lu lv lw lx ly lz ma mb mc md me in bi translated">从下面的代码中，我们只提取商业文章及其摘要。</p><pre class="kt ku kv kw gu nn nm no np aw nq bi"><span id="a058" class="nr mn iu nm b gz ns nt l nu nv">all_articles = []<br/>all_files1 = []<br/>base_path = ‘/content/BBC News Summary/News Articles/business’<br/>for filename in os.listdir(base_path):<br/>    with open(os.path.join(base_path, filename), ‘r’) as f:<br/>    all_articles.append(f.read())<br/>    all_files1.append(filename)</span><span id="76cd" class="nr mn iu nm b gz ob nt l nu nv">all_summaries = []<br/>all_files2 = []<br/>base_path = ‘/content/BBC News Summary/Summaries/business’<br/>for filename in os.listdir(base_path):<br/>    with open(os.path.join(base_path, filename), ‘r’) as f:<br/>    all_summaries.append(f.read())<br/>    all_files2.append(filename)</span></pre><p id="13c9" class="pw-post-body-paragraph lj lk iu ll b lm ln ke lo lp lq kh lr ls lt lu lv lw lx ly lz ma mb mc md me in bi translated">然后我们用<code class="fe nj nk nl nm b">input_text</code>和<code class="fe nj nk nl nm b">target_text</code>(摘要)创建一个数据帧。由于我们不需要<code class="fe nj nk nl nm b">filename</code>列，我们将在继续之前删除它。</p><pre class="kt ku kv kw gu nn nm no np aw nq bi"><span id="ab02" class="nr mn iu nm b gz ns nt l nu nv">df = pd.DataFrame()<br/>df[‘filename’] = all_files1<br/>df[‘input_text’] = all_articles<br/>df[‘target_text’] = all_summaries<br/>df.head()</span></pre><figure class="kt ku kv kw gu kx gi gj paragraph-image"><div role="button" tabindex="0" class="ky kz di la bf lb"><div class="gi gj oc"><img src="../Images/e1a0a0d386f25915975253d25664be34.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*l5iQRvYnvHJ5xHv13oG1qA.png"/></div></div></figure><pre class="kt ku kv kw gu nn nm no np aw nq bi"><span id="e4b4" class="nr mn iu nm b gz ns nt l nu nv">df.drop([‘filename’], axis=1, inplace=True)</span></pre><p id="cc88" class="pw-post-body-paragraph lj lk iu ll b lm ln ke lo lp lq kh lr ls lt lu lv lw lx ly lz ma mb mc md me in bi translated">我们将保留最后10条记录作为测试数据集，剩余的数据集将用于训练模型。</p><pre class="kt ku kv kw gu nn nm no np aw nq bi"><span id="3c08" class="nr mn iu nm b gz ns nt l nu nv">test_df = df[-10:]<br/>df = df[:-10]<br/>train_df, eval_df = train_test_split(df, test_size=0.05, random_state=42)</span></pre><h1 id="c5e5" class="mm mn iu bd mo mp nw mr ms mt nx mv mw kj ny kk my km nz kn na kp oa kq nc nd bi translated">初始化Seq2Seq模型</h1><p id="ab6d" class="pw-post-body-paragraph lj lk iu ll b lm ne ke lo lp nf kh lr ls ng lu lv lw nh ly lz ma ni mc md me in bi translated">对于汇总任务，<code class="fe nj nk nl nm b">encoder_decoder_type</code>必须是<code class="fe nj nk nl nm b"><a class="ae li" href="https://simpletransformers.ai/docs/seq2seq-model/#bart-models" rel="noopener ugc nofollow" target="_blank">bart</a></code>，<code class="fe nj nk nl nm b">encoder_decoder_name</code>可以从<a class="ae li" href="https://huggingface.co/transformers/pretrained_models.html" rel="noopener ugc nofollow" target="_blank">这里</a>的标准预训练模型列表中选择。在下面的例子中，我们使用的是<code class="fe nj nk nl nm b">facebook/bart-large</code>。</p><p id="92a6" class="pw-post-body-paragraph lj lk iu ll b lm ln ke lo lp lq kh lr ls lt lu lv lw lx ly lz ma mb mc md me in bi translated">此外，Seq2Seq函数有许多参数可以微调。但是在这里，我只使用下面的参数。如有必要，请随意尝试其他参数。</p><pre class="kt ku kv kw gu nn nm no np aw nq bi"><span id="7f61" class="nr mn iu nm b gz ns nt l nu nv">model_args = Seq2SeqArgs()<br/>model_args.num_train_epochs = 5<br/>model_args.no_save = True<br/>model_args.evaluate_generated_text = True<br/>model_args.evaluate_during_training = True<br/>model_args.evaluate_during_training_verbose = True<br/>model_args.overwrite_output_dir = True</span><span id="9b4e" class="nr mn iu nm b gz ob nt l nu nv">model = Seq2SeqModel(<br/>encoder_decoder_type=”bart”,<br/>encoder_decoder_name=”facebook/bart-large”,<br/>args=model_args,<br/>use_cuda=True,<br/>)</span></pre><h1 id="236e" class="mm mn iu bd mo mp nw mr ms mt nx mv mw kj ny kk my km nz kn na kp oa kq nc nd bi translated">训练模型</h1><p id="70a2" class="pw-post-body-paragraph lj lk iu ll b lm ne ke lo lp nf kh lr ls ng lu lv lw nh ly lz ma ni mc md me in bi translated"><code class="fe nj nk nl nm b">train_model()</code>方法使用<code class="fe nj nk nl nm b">train_df</code>数据帧训练模型。这将运行10个时期，因为我们已经将<code class="fe nj nk nl nm b">num_train_epoch</code>设置为10。</p><pre class="kt ku kv kw gu nn nm no np aw nq bi"><span id="8814" class="nr mn iu nm b gz ns nt l nu nv">model.train_model(train_df, eval_data=eval_df)</span></pre><h1 id="e8f7" class="mm mn iu bd mo mp nw mr ms mt nx mv mw kj ny kk my km nz kn na kp oa kq nc nd bi translated">评估模型</h1><p id="04ad" class="pw-post-body-paragraph lj lk iu ll b lm ne ke lo lp nf kh lr ls ng lu lv lw nh ly lz ma ni mc md me in bi translated"><code class="fe nj nk nl nm b">eval_model()</code>方法将使用<code class="fe nj nk nl nm b">eval_df</code>数据框架评估模型，并返回评估结果。</p><pre class="kt ku kv kw gu nn nm no np aw nq bi"><span id="7cd3" class="nr mn iu nm b gz ns nt l nu nv">model.eval_model(eval_df)</span></pre><h1 id="a365" class="mm mn iu bd mo mp nw mr ms mt nx mv mw kj ny kk my km nz kn na kp oa kq nc nd bi translated">预言；预测；预告</h1><p id="97af" class="pw-post-body-paragraph lj lk iu ll b lm ne ke lo lp nf kh lr ls ng lu lv lw nh ly lz ma ni mc md me in bi translated">您现在可以在我们上面为10条记录创建的测试数据集<code class="fe nj nk nl nm b">(test_df)</code>上生成(预测)摘要。然后比较实际摘要和预测摘要。如果结果不好，您可以尝试不同的模型，也可以尝试微调Seq2Seq参数，直到结果令人满意。</p><pre class="kt ku kv kw gu nn nm no np aw nq bi"><span id="7ad1" class="nr mn iu nm b gz ns nt l nu nv">results = model.predict(test_df[‘input_text’])</span></pre><p id="bf82" class="pw-post-body-paragraph lj lk iu ll b lm ln ke lo lp lq kh lr ls lt lu lv lw lx ly lz ma mb mc md me in bi translated">您可以在下面找到完整的代码:</p><figure class="kt ku kv kw gu kx"><div class="bz fq l di"><div class="od oe l"/></div></figure><h1 id="49c0" class="mm mn iu bd mo mp nw mr ms mt nx mv mw kj ny kk my km nz kn na kp oa kq nc nd bi translated">结论</h1><p id="98b3" class="pw-post-body-paragraph lj lk iu ll b lm ne ke lo lp nf kh lr ls ng lu lv lw nh ly lz ma ni mc md me in bi translated">希望你喜欢阅读本教程，并理解如何使用简单的变压器总结任务。</p><p id="ef96" class="pw-post-body-paragraph lj lk iu ll b lm ln ke lo lp lq kh lr ls lt lu lv lw lx ly lz ma mb mc md me in bi translated"><em class="of">阅读更多关于Python和数据科学的此类有趣文章，</em> <a class="ae li" href="https://pythonsimplified.com/" rel="noopener ugc nofollow" target="_blank"> <strong class="ll je"> <em class="of">订阅</em> </strong> </a> <em class="of">到我的博客</em><a class="ae li" href="http://www.pythonsimplified.com/" rel="noopener ugc nofollow" target="_blank"><strong class="ll je"><em class="of">www.pythonsimplified.com</em></strong></a><strong class="ll je"><em class="of">。</em> </strong>你也可以通过<a class="ae li" href="https://www.linkedin.com/in/chetanambi/" rel="noopener ugc nofollow" target="_blank"> <strong class="ll je"> LinkedIn </strong> </a>联系我。</p></div><div class="ab cl mf mg hy mh" role="separator"><span class="mi bw bk mj mk ml"/><span class="mi bw bk mj mk ml"/><span class="mi bw bk mj mk"/></div><div class="in io ip iq ir"><h1 id="fddc" class="mm mn iu bd mo mp mq mr ms mt mu mv mw kj mx kk my km mz kn na kp nb kq nc nd bi translated">参考</h1><div class="og oh gq gs oi oj"><a href="https://simpletransformers.ai/" rel="noopener  ugc nofollow" target="_blank"><div class="ok ab fp"><div class="ol ab om cl cj on"><h2 class="bd je gz z fq oo fs ft op fv fx jd bi translated">简单变压器</h2><div class="oq l"><h3 class="bd b gz z fq oo fs ft op fv fx dk translated">使用变压器模型从未如此简单！内置支持:文本分类令牌分类…</h3></div><div class="or l"><p class="bd b dl z fq oo fs ft op fv fx dk translated">simpletransformers.ai</p></div></div><div class="os l"><div class="ot l ou ov ow os ox lc oj"/></div></div></a></div></div></div>    
</body>
</html>