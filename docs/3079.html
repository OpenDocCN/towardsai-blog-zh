<html>
<head>
<title>EfficientNet — An Elegant, Powerful CNN.</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">高效网——一个优雅、强大的CNN。</h1>
<blockquote>原文：<a href="https://pub.towardsai.net/efficientnet-an-elegant-powerful-cnn-6e2a8d528ae3?source=collection_archive---------2-----------------------#2022-08-30">https://pub.towardsai.net/efficientnet-an-elegant-powerful-cnn-6e2a8d528ae3?source=collection_archive---------2-----------------------#2022-08-30</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><blockquote class="jn jo jp"><p id="c787" class="jq jr js jt b ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko ij bi translated">没有奇特的技术，但效果非常好。</p><p id="b488" class="jq jr js jt b ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko ij bi translated"><strong class="jt ir">优于ResNet、ResNeXt、DenseNet、InceptionNet、seNet、AmoebaNet，效率更高。</strong></p></blockquote><h1 id="9cf2" class="kp kq iq bd kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj lk ll lm bi translated">📖目录</h1><p id="a29d" class="pw-post-body-paragraph jq jr iq jt b ju ln jw jx jy lo ka kb lp lq ke kf lr ls ki kj lt lu km kn ko ij bi translated"><a class="ae lv" href="#1a51" rel="noopener ugc nofollow">⭐️introduction</a><br/><a class="ae lv" href="#ad49" rel="noopener ugc nofollow">⭐intuition</a><br/><a class="ae lv" href="#bb2c" rel="noopener ugc nofollow">⭐复合缩放法</a> <br/> ∘ <a class="ae lv" href="#06f9" rel="noopener ugc nofollow"> ⭐ MBConv块</a> <br/> <a class="ae lv" href="#e6d9" rel="noopener ugc nofollow"> ⭐表演</a> <br/> <a class="ae lv" href="#b522" rel="noopener ugc nofollow">实现</a> <br/> <a class="ae lv" href="#430f" rel="noopener ugc nofollow">引用</a></p><figure class="lx ly lz ma gt mb gh gi paragraph-image"><div role="button" tabindex="0" class="mc md di me bf mf"><div class="gh gi lw"><img src="../Images/179790e0b183027c172b32cd2264455f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*l7lT6CdV3g6xwG9R"/></div></div><figcaption class="mi mj gj gh gi mk ml bd b be z dk translated">照片由<a class="ae lv" href="https://unsplash.com/@erol?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Erol Ahmed </a>在<a class="ae lv" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上拍摄</figcaption></figure></div><div class="ab cl mm mn hu mo" role="separator"><span class="mp bw bk mq mr ms"/><span class="mp bw bk mq mr ms"/><span class="mp bw bk mq mr"/></div><div class="ij ik il im in"><h1 id="1a51" class="kp kq iq bd kr ks mt ku kv kw mu ky kz la mv lc ld le mw lg lh li mx lk ll lm bi translated">⭐ ️Introduction</h1><p id="e85e" class="pw-post-body-paragraph jq jr iq jt b ju ln jw jx jy lo ka kb lp lq ke kf lr ls ki kj lt lu km kn ko ij bi translated">高效，通俗地说就是不用付出很高的成本就能达到很好的效果的能力。</p><p id="0d40" class="pw-post-body-paragraph jq jr iq jt b ju jv jw jx jy jz ka kb lp kd ke kf lr kh ki kj lt kl km kn ko ij bi translated">虽然最先进的(SOTA)深度学习模型努力实现更高的性能，但同时它们的训练成本也越来越高。</p><p id="0c33" class="pw-post-body-paragraph jq jr iq jt b ju jv jw jx jy jz ka kb lp kd ke kf lr kh ki kj lt kl km kn ko ij bi translated">然而，有时我们甚至不需要2100M+数量的参数来达到同样的结果。我们只需要找到一种更有效率的方法。</p><figure class="lx ly lz ma gt mb gh gi paragraph-image"><div role="button" tabindex="0" class="mc md di me bf mf"><div class="gh gi my"><img src="../Images/0307d1617c206d10280fba5b3a22d0e5.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*wwzGehl9Z-LKDaGTgegubw.png"/></div></div><figcaption class="mi mj gj gh gi mk ml bd b be z dk translated">图1:高效网系列不仅胜过许多“大牌”CNN，而且使用的计算量也少得多。</figcaption></figure></div><div class="ab cl mm mn hu mo" role="separator"><span class="mp bw bk mq mr ms"/><span class="mp bw bk mq mr ms"/><span class="mp bw bk mq mr"/></div><div class="ij ik il im in"><h1 id="ad49" class="kp kq iq bd kr ks mt ku kv kw mu ky kz la mv lc ld le mw lg lh li mx lk ll lm bi translated">⭐Intuition</h1><p id="9058" class="pw-post-body-paragraph jq jr iq jt b ju ln jw jx jy lo ka kb lp lq ke kf lr ls ki kj lt lu km kn ko ij bi translated">在神经网络中，有几个属性:</p><ul class=""><li id="8b72" class="mz na iq jt b ju jv jy jz lp nb lr nc lt nd ko ne nf ng nh bi translated"><strong class="jt ir">深度(<em class="js"> d </em> ) </strong>:层数(包括输出但不包括输入。例如，101)。网络越深，就越有可能经历爆炸或消失的梯度，但它会更复杂，也许更具性能。</li><li id="5ce0" class="mz na iq jt b ju ni jy nj lp nk lr nl lt nm ko ne nf ng nh bi translated"><strong class="jt ir">宽度(<em class="js"> w </em> ) </strong>:卷积核(通道)的最高数量。正如Zagoruyko和Komodakis所指出的，“更宽的网络往往能够捕捉到更细粒度的特征，也更容易训练。”然而，太宽和太浅的模型将难以捕捉更高级的特征(例如，1024)。</li><li id="e9fe" class="mz na iq jt b ju ni jy nj lp nk lr nl lt nm ko ne nf ng nh bi translated"><strong class="jt ir">分辨率(<em class="js"> r </em> ): </strong>输入图像的尺寸(图像高度*图像宽度。例如256×256)。分辨率越高，CNN就越有可能捕获精细的模式，但是对于非常高的分辨率(例如，560×560)，精度增益会降低。</li></ul><p id="f512" class="pw-post-body-paragraph jq jr iq jt b ju jv jw jx jy jz ka kb lp kd ke kf lr kh ki kj lt kl km kn ko ij bi translated">在2020年，Tan等人发现，现有的网络架构，如ResNet，通常是先发展其基线，然后通过简单地增加<strong class="jt ir">深度</strong>(层数)来<strong class="jt ir">扩大</strong>，如从ResNet-18到ResNet-200。其他网络可能会随机扩大其他属性。</p><p id="8881" class="pw-post-body-paragraph jq jr iq jt b ju jv jw jx jy jz ka kb lp kd ke kf lr kh ki kj lt kl km kn ko ij bi translated">然而，EfficientNet的作者指出这是错误的。具体来说，<strong class="jt ir">这种任意缩放需要繁琐的手动调整，并经常导致次优效率。</strong></p><p id="63e7" class="pw-post-body-paragraph jq jr iq jt b ju jv jw jx jy jz ka kb lp kd ke kf lr kh ki kj lt kl km kn ko ij bi translated"><strong class="jt ir"> ❗️Also，放大任何属性(宽度、深度、分辨率)都会提高精度，但对于更大的模型，精度增益会降低。</strong></p><p id="e191" class="pw-post-body-paragraph jq jr iq jt b ju jv jw jx jy jz ka kb lp kd ke kf lr kh ki kj lt kl km kn ko ij bi translated">作者发现，在这些网络的属性之间有一种固定的关系(将在中详细阐述),并且有一种更有效的方式来扩展网络，因此人们不太担心使用笨重的模型，而是担心糟糕的性能。</p><p id="6c1e" class="pw-post-body-paragraph jq jr iq jt b ju jv jw jx jy jz ka kb lp kd ke kf lr kh ki kj lt kl km kn ko ij bi translated">方法是<strong class="jt ir">复合缩放法。</strong></p><figure class="lx ly lz ma gt mb gh gi paragraph-image"><div role="button" tabindex="0" class="mc md di me bf mf"><div class="gh gi nn"><img src="../Images/ef2d78e46a2268055da4aea67a1fe588.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Tg741Dk0vrsmmnUZosQIdQ.png"/></div></div><figcaption class="mi mj gj gh gi mk ml bd b be z dk translated">图2:复合缩放方法(e)与其他方法的比较</figcaption></figure></div><div class="ab cl mm mn hu mo" role="separator"><span class="mp bw bk mq mr ms"/><span class="mp bw bk mq mr ms"/><span class="mp bw bk mq mr"/></div><div class="ij ik il im in"><h1 id="bb2c" class="kp kq iq bd kr ks mt ku kv kw mu ky kz la mv lc ld le mw lg lh li mx lk ll lm bi translated">⭐ <strong class="ak">复合缩放法</strong></h1><p id="77b0" class="pw-post-body-paragraph jq jr iq jt b ju ln jw jx jy lo ka kb lp lq ke kf lr ls ki kj lt lu km kn ko ij bi translated">不同的网络属性相互依赖。例如，当增加模型的分辨率(输入尺寸)时，<strong class="jt ir">深度</strong>和<strong class="jt ir">宽度</strong>也应增加，以利用图片中的更多信息(更大的感受野)并捕捉具有更多像素的更精细的图案。</p><p id="dbae" class="pw-post-body-paragraph jq jr iq jt b ju jv jw jx jy jz ka kb lp kd ke kf lr kh ki kj lt kl km kn ko ij bi translated">然而，<strong class="jt ir">其他属性应该如何响应一个属性的改变而改变呢？</strong></p><p id="679e" class="pw-post-body-paragraph jq jr iq jt b ju jv jw jx jy jz ka kb lp kd ke kf lr kh ki kj lt kl km kn ko ij bi translated">没有什么比看一些数学更直接的了。别担心。我会确保你读的是简明英语。</p><p id="b51b" class="pw-post-body-paragraph jq jr iq jt b ju jv jw jx jy jz ka kb lp kd ke kf lr kh ki kj lt kl km kn ko ij bi translated">让我们假设:</p><ul class=""><li id="c281" class="mz na iq jt b ju jv jy jz lp nb lr nc lt nd ko ne nf ng nh bi translated"><strong class="jt ir">深度= <em class="js"> d </em> </strong> <em class="js"> ^ϕ </em></li><li id="3103" class="mz na iq jt b ju ni jy nj lp nk lr nl lt nm ko ne nf ng nh bi translated"><strong class="jt ir">宽度</strong> = <strong class="jt ir"> <em class="js">宽度</em> </strong> <em class="js"> ^ϕ </em></li><li id="e35a" class="mz na iq jt b ju ni jy nj lp nk lr nl lt nm ko ne nf ng nh bi translated"><strong class="jt ir">分辨率= <em class="js"> r^ </em> </strong> <em class="js"> ϕ </em></li></ul><p id="89e7" class="pw-post-body-paragraph jq jr iq jt b ju jv jw jx jy jz ka kb lp kd ke kf lr kh ki kj lt kl km kn ko ij bi translated"><strong class="jt ir"> d、w、r </strong>为常量，在固定<em class="js"> ϕ=1、</em>的同时，通过进行<strong class="jt ir">随机网格搜索</strong>对其进行优化，并约束如下</p><ul class=""><li id="e793" class="mz na iq jt b ju jv jy jz lp nb lr nc lt nd ko ne nf ng nh bi translated"><em class="js"> d * w * r ≈ 2 </em></li><li id="2228" class="mz na iq jt b ju ni jy nj lp nk lr nl lt nm ko ne nf ng nh bi translated"><strong class="jt ir"><em class="js"/></strong><em class="js">≥1，</em><strong class="jt ir"><em class="js">w</em></strong><em class="js">≥1，</em><strong class="jt ir"><em class="js">r</em></strong><em class="js">≥1</em></li></ul><blockquote class="jn jo jp"><p id="9dcd" class="jq jr js jt b ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko ij bi translated"><strong class="jt ir">T71】🔥所以现在，为了扩大规模，你只需要改变ϕ的值。您不再需要同时调整深度、宽度和分辨率等属性。🔥T75】</strong></p></blockquote><p id="b086" class="pw-post-body-paragraph jq jr iq jt b ju jv jw jx jy jz ka kb lp kd ke kf lr kh ki kj lt kl km kn ko ij bi translated">他们设计了这个等式，使得对于任何值的<em class="js"> ϕ，</em>总的<strong class="jt ir"> FLOPS </strong> ( <em class="js">每秒浮点运算，这里测量训练的速度</em>)将大约增加2^ <em class="js"> ϕ.</em></p><p id="8788" class="pw-post-body-paragraph jq jr iq jt b ju jv jw jx jy jz ka kb lp kd ke kf lr kh ki kj lt kl km kn ko ij bi translated">图3示出了通过改变模型的不同属性，模型的注意力显著改变，但是只有复合缩放示出了模型具有“最正确”的注意力。</p><figure class="lx ly lz ma gt mb gh gi paragraph-image"><div role="button" tabindex="0" class="mc md di me bf mf"><div class="gh gi no"><img src="../Images/c275f0e617d11dd98361855c0736e275.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*VbGkypYFZz_-deUOcpyXKQ.png"/></div></div><figcaption class="mi mj gj gh gi mk ml bd b be z dk translated">图3:模型的注意力可视化使用GradCAM对不同的属性变化。第1栏:原始投入。第3–5列:更改三种不同的属性。第六栏:作者使用方法的注意事项。如图所示，新网络更有效，因为注意力比其他方法的注意力更“正确”。</figcaption></figure><p id="db86" class="pw-post-body-paragraph jq jr iq jt b ju jv jw jx jy jz ka kb lp kd ke kf lr kh ki kj lt kl km kn ko ij bi translated">已知<strong class="jt ir"> d，w，</strong>和<strong class="jt ir"> r </strong>，<strong class="jt ir"> EfficientNet-B0 </strong>被提出。</p><figure class="lx ly lz ma gt mb gh gi paragraph-image"><div class="gh gi np"><img src="../Images/3f34c1b0e293a0a753e1c3ab8924c5f6.png" data-original-src="https://miro.medium.com/v2/resize:fit:948/format:webp/1*P9kLYAQe0tNUCXYWTdgtrA.png"/></div><figcaption class="mi mj gj gh gi mk ml bd b be z dk translated">图4: EfficientNet-B0架构总结。MBConv[N]表示扩展因子为N的MBConv(即初始1 X 1卷积接收c个通道，返回n*c个通道)[4]</figcaption></figure><p id="55a2" class="pw-post-body-paragraph jq jr iq jt b ju jv jw jx jy jz ka kb lp kd ke kf lr kh ki kj lt kl km kn ko ij bi translated"><strong class="jt ir"> MBConv </strong>是具有深度方向可分离卷积的反向残差瓶颈块。我先详细解释一下这个。</p><h2 id="06f9" class="nq kq iq bd kr nr ns dn kv nt nu dp kz lp nv nw ld lr nx ny lh lt nz oa ll ob bi translated">⭐ <strong class="ak"> MBConv模块</strong></h2><p id="218b" class="pw-post-body-paragraph jq jr iq jt b ju ln jw jx jy lo ka kb lp lq ke kf lr ls ki kj lt lu km kn ko ij bi translated">传统上，3×3卷积运算只是简单地对具有深度D1的输入运行(3，3)大小的核，并产生具有深度D2的输出。</p><p id="1815" class="pw-post-body-paragraph jq jr iq jt b ju jv jw jx jy jz ka kb lp kd ke kf lr kh ki kj lt kl km kn ko ij bi translated">然而，对于正常的剩余瓶颈块，输入的深度首先通过1x1卷积来减小。然后，将3×3卷积应用于深度减小的输入。最后，通过1x1卷积重新扩展深度。图4中示出了图解说明。</p><p id="0170" class="pw-post-body-paragraph jq jr iq jt b ju jv jw jx jy jz ka kb lp kd ke kf lr kh ki kj lt kl km kn ko ij bi translated">这种奇特的操作被称为<strong class="jt ir">深度方向可分离卷积</strong>。事实上，它将简单的3×3卷积分解为1×1压缩、3×3压缩和1×1扩展过程。</p><p id="0e6d" class="pw-post-body-paragraph jq jr iq jt b ju jv jw jx jy jz ka kb lp kd ke kf lr kh ki kj lt kl km kn ko ij bi translated">然后，将初始和结束特征图添加到网络中，可以学习更多样的特征。</p><p id="7496" class="pw-post-body-paragraph jq jr iq jt b ju jv jw jx jy jz ka kb lp kd ke kf lr kh ki kj lt kl km kn ko ij bi translated">这种奇特的操作使用的参数少得多，计算效率也更高。</p><figure class="lx ly lz ma gt mb gh gi paragraph-image"><div role="button" tabindex="0" class="mc md di me bf mf"><div class="gh gi oc"><img src="../Images/f3c5e606fa5bdacadb292e6d3bc604c3.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*E3V_gY8BezM8x1fI2P0ZdQ.png"/></div></div><figcaption class="mi mj gj gh gi mk ml bd b be z dk translated">图MobileNet论文中的残余瓶颈。</figcaption></figure><p id="68cd" class="pw-post-body-paragraph jq jr iq jt b ju jv jw jx jy jz ka kb lp kd ke kf lr kh ki kj lt kl km kn ko ij bi translated">对于反转的残差块，深度改变方案是“反转的”，如图6所示。于是，从<strong class="jt ir">宽→窄→宽</strong>到<strong class="jt ir">窄→宽→窄</strong>。</p><figure class="lx ly lz ma gt mb gh gi paragraph-image"><div role="button" tabindex="0" class="mc md di me bf mf"><div class="gh gi od"><img src="../Images/de139789b822d6fababf1b539012a349.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*05ViDhMY5S9dX9wPxoIDzQ.png"/></div></div><figcaption class="mi mj gj gh gi mk ml bd b be z dk translated">图6:来自MobileNetV2纸的倒置剩余块。</figcaption></figure><p id="0cae" class="pw-post-body-paragraph jq jr iq jt b ju jv jw jx jy jz ka kb lp kd ke kf lr kh ki kj lt kl km kn ko ij bi translated"><strong class="jt ir">反转版本被证明工作得更好，内存效率更高</strong>，因为它现在可以移除窄层中的非线性，从而具有更好的表示能力(<em class="js">我知道这听起来很难理解原因，所以如果你不理解，也不用担心</em>)。</p></div><div class="ab cl mm mn hu mo" role="separator"><span class="mp bw bk mq mr ms"/><span class="mp bw bk mq mr ms"/><span class="mp bw bk mq mr"/></div><div class="ij ik il im in"><h1 id="e6d9" class="kp kq iq bd kr ks mt ku kv kw mu ky kz la mv lc ld le mw lg lh li mx lk ll lm bi translated">⭐表演</h1><p id="0463" class="pw-post-body-paragraph jq jr iq jt b ju ln jw jx jy lo ka kb lp lq ke kf lr ls ki kj lt lu km kn ko ij bi translated">B7的EfficientNet B0实现了卓越的性能。</p><p id="c230" class="pw-post-body-paragraph jq jr iq jt b ju jv jw jx jy jz ka kb lp kd ke kf lr kh ki kj lt kl km kn ko ij bi translated">图7显示了与其他型号相比，高效网-B0至高效网-B7的详细性能数据。正如你所看到的，EfficientNet同时实现了速度和性能。这就是它“高效”的原因</p><figure class="lx ly lz ma gt mb gh gi paragraph-image"><div role="button" tabindex="0" class="mc md di me bf mf"><div class="gh gi oe"><img src="../Images/82db65a1b4e7da4834cf3928d1634507.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*5VVF7cbqhgUj0t1G-dx3Yg.png"/></div></div><figcaption class="mi mj gj gh gi mk ml bd b be z dk translated">图8</figcaption></figure><p id="6c89" class="pw-post-body-paragraph jq jr iq jt b ju jv jw jx jy jz ka kb lp kd ke kf lr kh ki kj lt kl km kn ko ij bi translated"><strong class="jt ir">然而，EfficientNet走得更远。接下来我们要说的是</strong><a class="ae lv" href="https://arxiv.org/abs/2104.00298" rel="noopener ugc nofollow" target="_blank"><strong class="jt ir">efficient net v2</strong></a><strong class="jt ir">，这个更厉害。</strong></p></div><div class="ab cl mm mn hu mo" role="separator"><span class="mp bw bk mq mr ms"/><span class="mp bw bk mq mr ms"/><span class="mp bw bk mq mr"/></div><div class="ij ik il im in"><p id="72ba" class="pw-post-body-paragraph jq jr iq jt b ju jv jw jx jy jz ka kb lp kd ke kf lr kh ki kj lt kl km kn ko ij bi translated"><strong class="jt ir">谢谢！❤️ <br/>我们可以恳求你考虑给我们一些掌声吗！❤️ </strong></p></div><div class="ab cl mm mn hu mo" role="separator"><span class="mp bw bk mq mr ms"/><span class="mp bw bk mq mr ms"/><span class="mp bw bk mq mr"/></div><div class="ij ik il im in"><h1 id="b522" class="kp kq iq bd kr ks mt ku kv kw mu ky kz la mv lc ld le mw lg lh li mx lk ll lm bi translated">履行</h1><p id="04ab" class="pw-post-body-paragraph jq jr iq jt b ju ln jw jx jy lo ka kb lp lq ke kf lr ls ki kj lt lu km kn ko ij bi translated"><a class="ae lv" href="https://github.com/keras-team/keras/blob/v2.9.0/keras/applications/efficientnet.py#L564-L587" rel="noopener ugc nofollow" target="_blank">tensor flow中的官方EfficientNet实施</a></p><h1 id="430f" class="kp kq iq bd kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj lk ll lm bi translated">参考</h1><p id="070e" class="pw-post-body-paragraph jq jr iq jt b ju ln jw jx jy lo ka kb lp lq ke kf lr ls ki kj lt lu km kn ko ij bi translated">[1] <a class="ae lv" href="https://arxiv.org/abs/1905.11946?context=stat.ML" rel="noopener ugc nofollow" target="_blank"> EfficientNet:反思卷积神经网络的模型缩放</a><br/>【2】<a class="ae lv" href="https://arxiv.org/pdf/1801.04381.pdf" rel="noopener ugc nofollow" target="_blank">mobilenetv 2:反向残差和线性瓶颈</a><br/>【3】<a class="ae lv" href="https://arxiv.org/pdf/1704.04861.pdf" rel="noopener ugc nofollow" target="_blank">MobileNets:用于移动视觉应用的高效卷积神经网络</a><br/>【4】<a class="ae lv" href="https://python.plainenglish.io/implementing-efficientnet-in-pytorch-part-3-mbconv-squeeze-and-excitation-and-more-4ca9fd62d302" rel="noopener ugc nofollow" target="_blank">https://python . plain English . io/implementing-efficent net-in-py torch-part-3-MB conv-squeeze-and-excitation-and-more-4c a9 FD 62d 32</a></p><div class="of og gp gr oh oi"><a href="https://medium.com/mlearning-ai/mlearning-ai-submission-suggestions-b51e2b130bfb" rel="noopener follow" target="_blank"><div class="oj ab fo"><div class="ok ab ol cl cj om"><h2 class="bd ir gy z fp on fr fs oo fu fw ip bi translated">Mlearning.ai提交建议</h2><div class="op l"><h3 class="bd b gy z fp on fr fs oo fu fw dk translated">如何成为Mlearning.ai上的作家</h3></div><div class="oq l"><p class="bd b dl z fp on fr fs oo fu fw dk translated">medium.com</p></div></div><div class="or l"><div class="os l ot ou ov or ow mg oi"/></div></div></a></div></div></div>    
</body>
</html>