<html>
<head>
<title>REGRESSION — HOW, WHY, AND WHEN?</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">回归——如何回归，为什么回归，何时回归？</h1>
<blockquote>原文：<a href="https://pub.towardsai.net/regression-how-why-and-when-1e0e8dd67c58?source=collection_archive---------4-----------------------#2022-12-01">https://pub.towardsai.net/regression-how-why-and-when-1e0e8dd67c58?source=collection_archive---------4-----------------------#2022-12-01</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><div class=""><h2 id="7915" class="pw-subtitle-paragraph jn ip iq bd b jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke dk translated">监督机器学习—第二部分</h2></div><h2 id="6c41" class="kf kg iq bd kh ki kj dn kk kl km dp kn ko kp kq kr ks kt ku kv kw kx ky kz la bi translated">回归:</h2><figure class="lc ld le lf gt lg gh gi paragraph-image"><div role="button" tabindex="0" class="lh li di lj bf lk"><div class="gh gi lb"><img src="../Images/5f947a42e95637c573b5d48d9be3bcda.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*l51uDTPn43znEkYF"/></div></div><figcaption class="ln lo gj gh gi lp lq bd b be z dk translated">图片来源:作者</figcaption></figure><p id="4b4f" class="pw-post-body-paragraph lr ls iq lt b lu lv jr lw lx ly ju lz ko ma mb mc ks md me mf kw mg mh mi mj ij bi translated">正如我们之前看到的，机器学习的监督部分分为两个类别，从这两个类别中，我们已经进入了<a class="ae mk" href="https://medium.com/towards-artificial-intelligence/world-of-classification-in-machine-learning-a3c1f008b1fc" rel="noopener"> <strong class="lt ir"> <em class="ml">分类</em> </strong> </a>以及分类过程中采用的许多算法的领域。回归是同一枚硬币的另一面，我们利用回归技术来揭示或建立独立因素、特征和因变量以及结果之间的关系。</p><p id="adca" class="pw-post-body-paragraph lr ls iq lt b lu lv jr lw lx ly ju lz ko ma mb mc ks md me mf kw mg mh mi mj ij bi translated">回归程序允许您安全地决定哪些元素是最重要的，哪些可能被忽略，以及某些因素如何相互影响。</p><p id="3623" class="pw-post-body-paragraph lr ls iq lt b lu lv jr lw lx ly ju lz ko ma mb mc ks md me mf kw mg mh mi mj ij bi translated">最终的目标是把很多事情理顺，这样你就可以对你想要建立的东西充满信心，或者找到解决问题的方法。</p><p id="ae00" class="pw-post-body-paragraph lr ls iq lt b lu lv jr lw lx ly ju lz ko ma mb mc ks md me mf kw mg mh mi mj ij bi translated"><strong class="lt ir">简单线性回归用公式表示:</strong></p><p id="6b1d" class="pw-post-body-paragraph lr ls iq lt b lu lv jr lw lx ly ju lz ko ma mb mc ks md me mf kw mg mh mi mj ij bi translated"><strong class="lt ir"> y = β0 + β1 x. </strong></p><figure class="lc ld le lf gt lg gh gi paragraph-image"><div class="gh gi mm"><img src="../Images/ba022af857d1d4396add270fc1a3a151.png" data-original-src="https://miro.medium.com/v2/resize:fit:1080/0*jNjdxv_Y7Kgq1e7P"/></div><figcaption class="ln lo gj gh gi lp lq bd b be z dk translated">来源:<a class="ae mk" href="https://giphy.com/" rel="noopener ugc nofollow" target="_blank">https://giphy.com/</a></figcaption></figure><h2 id="efee" class="kf kg iq bd kh ki kj dn kk kl km dp kn ko kp kq kr ks kt ku kv kw kx ky kz la bi translated">现实生活中的回归例子:</h2><ol class=""><li id="8a53" class="mn mo iq lt b lu mp lx mq ko mr ks ms kw mt mj mu mv mw mx bi translated">在鲁莽驾驶和一年内频繁发生的事故之间画点。</li><li id="4cc2" class="mn mo iq lt b lu my lx mz ko na ks nb kw nc mj mu mv mw mx bi translated">预测公司特定产品的销售。</li><li id="5802" class="mn mo iq lt b lu my lx mz ko na ks nb kw nc mj mu mv mw mx bi translated">医学研究人员经常使用线性回归来检验药物剂量和患者血压之间的关系。</li><li id="d074" class="mn mo iq lt b lu my lx mz ko na ks nb kw nc mj mu mv mw mx bi translated">股票预测是通过检查股票价格和趋势的历史数据来发现模式。还有更多。</li></ol><h2 id="e125" class="kf kg iq bd kh ki kj dn kk kl km dp kn ko kp kq kr ks kt ku kv kw kx ky kz la bi translated">那么确切地说，回归和分类有什么不同呢？</h2><p id="c37d" class="pw-post-body-paragraph lr ls iq lt b lu mp jr lw lx mq ju lz ko nd mb mc ks ne me mf kw nf mh mi mj ij bi translated">当我们讨论分类困难时，我们指的是重要的分类值，这意味着输出是离散的。</p><p id="75cb" class="pw-post-body-paragraph lr ls iq lt b lu lv jr lw lx ly ju lz ko ma mb mc ks md me mf kw mg mh mi mj ij bi translated">然而，在回归的情况下，情况正好相反；在这里，重要的值是数字，输出是连续的而不是离散的。</p><p id="50a7" class="pw-post-body-paragraph lr ls iq lt b lu lv jr lw lx ly ju lz ko ma mb mc ks md me mf kw mg mh mi mj ij bi translated">这两种方法之间的另一个重要区别是，正如我们在上一篇博客(即<a class="ae mk" href="https://medium.com/towards-artificial-intelligence/world-of-classification-in-machine-learning-a3c1f008b1fc" rel="noopener"> <strong class="lt ir"> <em class="ml">分类的世界</em> </strong> </a>)中看到的，我们使用分类技术来确定决策边界，并将整个大型数据集分成两个不同的类。</p><p id="0ef6" class="pw-post-body-paragraph lr ls iq lt b lu lv jr lw lx ly ju lz ko ma mb mc ks md me mf kw mg mh mi mj ij bi translated">然而，如前所述，在回归分析中，我们并不将数据集分成两组，而是确定能够正确预测结果的最佳拟合线。</p><figure class="lc ld le lf gt lg gh gi paragraph-image"><div class="gh gi ng"><img src="../Images/a3fbff6fa56924a9840e042ebf00d74d.png" data-original-src="https://miro.medium.com/v2/resize:fit:960/0*vIP_Tza3IE2g7F-r"/></div><figcaption class="ln lo gj gh gi lp lq bd b be z dk translated">来源:<a class="ae mk" href="https://giphy.com/" rel="noopener ugc nofollow" target="_blank">https://giphy.com/</a></figcaption></figure><p id="34f8" class="pw-post-body-paragraph lr ls iq lt b lu lv jr lw lx ly ju lz ko ma mb mc ks md me mf kw mg mh mi mj ij bi translated">最后，这两种技术之间的另一个重要区别是，分类算法通常处理与自然语言处理或计算机视觉、深度学习(如人脸检测、语音识别、图片分割、DNA序列分类等)相关的问题。</p><p id="b3d9" class="pw-post-body-paragraph lr ls iq lt b lu lv jr lw lx ly ju lz ko ma mb mc ks md me mf kw mg mh mi mj ij bi translated">当我们谈到回归算法时，它通常解决与销售、增长、市场评估、消费者需求等元素相关的问题，以及许多其他问题，如房价预测、未来股票价格预测、加密货币价格预测等。</p><p id="cb68" class="pw-post-body-paragraph lr ls iq lt b lu lv jr lw lx ly ju lz ko ma mb mc ks md me mf kw mg mh mi mj ij bi translated">我们谈了很多理论，让我们进入实践领域，以便更好地理解事情:</p><figure class="lc ld le lf gt lg gh gi paragraph-image"><div role="button" tabindex="0" class="lh li di lj bf lk"><div class="gh gi nh"><img src="../Images/0697d0f989958bcfefd0c6a8656ee400.png" data-original-src="https://miro.medium.com/v2/resize:fit:600/0*axk0TpxEHRH4ZbIC"/></div></div><figcaption class="ln lo gj gh gi lp lq bd b be z dk translated">来源:https://giphy.com/</figcaption></figure><h2 id="c705" class="kf kg iq bd kh ki kj dn kk kl km dp kn ko kp kq kr ks kt ku kv kw kx ky kz la bi translated">为了解决问题，回归是如何实现的？</h2><h2 id="f0b0" class="kf kg iq bd kh ki kj dn kk kl km dp kn ko kp kq kr ks kt ku kv kw kx ky kz la bi translated">简单线性回归:</h2><p id="b251" class="pw-post-body-paragraph lr ls iq lt b lu mp jr lw lx mq ju lz ko nd mb mc ks ne me mf kw nf mh mi mj ij bi translated"><strong class="lt ir">问题陈述:</strong></p><p id="174c" class="pw-post-body-paragraph lr ls iq lt b lu lv jr lw lx ly ju lz ko ma mb mc ks md me mf kw mg mh mi mj ij bi translated">给定的数据具有汽车的各种属性，因此现在我们将使用线性回归方法，结合收集的特征来估计汽车的价格。</p><p id="9674" class="pw-post-body-paragraph lr ls iq lt b lu lv jr lw lx ly ju lz ko ma mb mc ks md me mf kw mg mh mi mj ij bi translated">在我们处理实际实现时，需要记住一些术语。</p><ol class=""><li id="d754" class="mn mo iq lt b lu lv lx ly ko ni ks nj kw nk mj mu mv mw mx bi translated"><strong class="lt ir">价格</strong>——汽车的成本</li><li id="7ac2" class="mn mo iq lt b lu my lx mz ko na ks nb kw nc mj mu mv mw mx bi translated"><strong class="lt ir">可靠性</strong> —确定车辆可靠性的中间测量。</li><li id="9429" class="mn mo iq lt b lu my lx mz ko na ks nb kw nc mj mu mv mw mx bi translated"><strong class="lt ir">里程</strong> —车辆的燃油里程。</li><li id="2e22" class="mn mo iq lt b lu my lx mz ko na ks nb kw nc mj mu mv mw mx bi translated"><strong class="lt ir">类型</strong> —分类变量定义汽车所属的类别。</li><li id="6049" class="mn mo iq lt b lu my lx mz ko na ks nb kw nc mj mu mv mw mx bi translated"><strong class="lt ir">重量</strong> —汽车的重量</li><li id="96cd" class="mn mo iq lt b lu my lx mz ko na ks nb kw nc mj mu mv mw mx bi translated"><strong class="lt ir">排量</strong> —代表汽车的发动机排量</li><li id="0f85" class="mn mo iq lt b lu my lx mz ko na ks nb kw nc mj mu mv mw mx bi translated"><strong class="lt ir"> HP </strong> —车辆的马力，测量其功率的单位。</li></ol><h2 id="1810" class="kf kg iq bd kh ki kj dn kk kl km dp kn ko kp kq kr ks kt ku kv kw kx ky kz la bi translated">数据读取:</h2><p id="b5f5" class="pw-post-body-paragraph lr ls iq lt b lu mp jr lw lx mq ju lz ko nd mb mc ks ne me mf kw nf mh mi mj ij bi translated"><strong class="lt ir">数据读取的重要性:</strong></p><p id="f6e1" class="pw-post-body-paragraph lr ls iq lt b lu lv jr lw lx ly ju lz ko ma mb mc ks md me mf kw mg mh mi mj ij bi translated">为了确保干净且有组织的数据可用于进一步训练模型，并避免在处理大型数据集时的任何误解，有必要预处理并开始数据的清理，即将原始数据转换为干净的数据。<br/>读取数据对于开发模型和继续前进至关重要。</p><pre class="lc ld le lf gt nl nm nn bn no np bi"><span id="e277" class="nq kg iq nm b be nr ns l nt nu">getwd()<br/><br/>## Load the data<br/>cars_data  &lt;- read.csv(file = "cars.csv")</span></pre><h2 id="4be5" class="kf kg iq bd kh ki kj dn kk kl km dp kn ko kp kq kr ks kt ku kv kw kx ky kz la bi translated">数据理解:</h2><p id="1372" class="pw-post-body-paragraph lr ls iq lt b lu mp jr lw lx mq ju lz ko nd mb mc ks ne me mf kw nf mh mi mj ij bi translated">在这个阶段，我们将检查发生的观察和属性的数量。对自变量和因变量进行分类。</p><p id="5b02" class="pw-post-body-paragraph lr ls iq lt b lu lv jr lw lx ly ju lz ko ma mb mc ks md me mf kw mg mh mi mj ij bi translated">注:在线性回归中，因变量是连续变量。</p><p id="9583" class="pw-post-body-paragraph lr ls iq lt b lu lv jr lw lx ly ju lz ko ma mb mc ks md me mf kw mg mh mi mj ij bi translated">这里，我们将用一个自变量来预测因变量。</p><p id="e712" class="pw-post-body-paragraph lr ls iq lt b lu lv jr lw lx ly ju lz ko ma mb mc ks md me mf kw mg mh mi mj ij bi translated"><strong class="lt ir">举例:</strong>我们将价格视为因变量，汽车的排量视为自变量。</p><pre class="lc ld le lf gt nl nm nn bn no np bi"><span id="3bc4" class="nq kg iq nm b be nr ns l nt nu">dim(cars_data)<br/><br/>str(cars_data)<br/><br/>head(cars_data)<br/><br/>tail(cars_data)<br/><br/>summary(cars_data)</span></pre><h2 id="86db" class="kf kg iq bd kh ki kj dn kk kl km dp kn ko kp kq kr ks kt ku kv kw kx ky kz la bi translated">数据类型转换:</h2><p id="0901" class="pw-post-body-paragraph lr ls iq lt b lu mp jr lw lx mq ju lz ko nd mb mc ks ne me mf kw nf mh mi mj ij bi translated">属性值可以隐式或显式转换。用户不知道隐式转换。SQL Server立即将数据从一种数据类型转换为另一种数据类型。例如，当比较小整型和整型时，在执行比较之前，小整型被隐式地转换成整型。</p><pre class="lc ld le lf gt nl nm nn bn no np bi"><span id="95f4" class="nq kg iq nm b be nr ns l nt nu">#Convert "Reliability" to factor variable<br/>cars_data[, "Reliability"] &lt;- as.factor(as.character(cars_data[, "Reliability"]))<br/><br/>cars_data[, "Country"] &lt;- as.factor(as.character(cars_data[, "Country"]))<br/>cars_data[, "Type"] &lt;- as.factor(as.character(cars_data[, "Type"]))<br/><br/>str(cars_data)</span></pre><h2 id="dac5" class="kf kg iq bd kh ki kj dn kk kl km dp kn ko kp kq kr ks kt ku kv kw kx ky kz la bi translated">处理值:</h2><p id="eb12" class="pw-post-body-paragraph lr ls iq lt b lu mp jr lw lx mq ju lz ko nd mb mc ks ne me mf kw nf mh mi mj ij bi translated">这样我们就不会有任何空白空间在我们的模型中制造混乱。</p><pre class="lc ld le lf gt nl nm nn bn no np bi"><span id="cf5c" class="nq kg iq nm b be nr ns l nt nu">## Look for Missing Values<br/>sum(is.na(cars_data))<br/><br/>colSums(is.na(cars_data))<br/><br/>#Install the DMwR2 package incase you haven't.<br/>install.packages("DMwR2", dependencies=TRUE)<br/><br/>## Imputing missing values<br/>library(DMwR2)<br/>cars_data=centralImputation(cars_data)<br/><br/>sum(is.na(cars_data))<br/><br/>sum(is.na(cars_data))</span></pre><h2 id="a9f5" class="kf kg iq bd kh ki kj dn kk kl km dp kn ko kp kq kr ks kt ku kv kw kx ky kz la bi translated">数据探索性分析:</h2><p id="d130" class="pw-post-body-paragraph lr ls iq lt b lu mp jr lw lx mq ju lz ko nd mb mc ks ne me mf kw nf mh mi mj ij bi translated">探索性数据分析是对数据进行初步调查的关键过程，目的是提高检测率，识别异常情况，测试假设，并使用统计结果和可视化验证假设。</p><pre class="lc ld le lf gt nl nm nn bn no np bi"><span id="afea" class="nq kg iq nm b be nr ns l nt nu">#Plot the Dependent and  Independent variables<br/># _*Scatter Plot*_ helps to view the relationship between two continuous variables<br/> <br/>options(repr.plot.width = 10, repr.plot.height = 10)<br/>par(mfrow = c(2,2)) # Splits the plotting pane 2*2<br/> <br/>plot(cars_data$Weight, cars_data$Price, xlab = "Weight",<br/>    ylab = "Price", main = "Weight vs Price")<br/> <br/>plot(cars_data$Mileage, cars_data$Price, xlab = "Mileage",<br/>    ylab = "Price", main = "Mileage vs Price")<br/> <br/>plot(cars_data$Disp., cars_data$Price, xlab = "Displacement",<br/>    ylab = "Price", main = "Displacement vs Price")<br/> <br/>plot(cars_data$HP, cars_data$Price, xlab = "Horse Power",<br/>    ylab = "Price", main = "Horse Power vs Price")<br/></span></pre><h2 id="2559" class="kf kg iq bd kh ki kj dn kk kl km dp kn ko kp kq kr ks kt ku kv kw kx ky kz la bi translated">将数据分为训练集和验证集:</h2><p id="0617" class="pw-post-body-paragraph lr ls iq lt b lu mp jr lw lx mq ju lz ko nd mb mc ks ne me mf kw nf mh mi mj ij bi translated">将数据集划分为一个验证集的主要目标是避免我们的模型过度拟合，当算法在对测试数据集中的项目进行分类时非常有效，但难以对以前没有遇到的数据概括实践和知识预测时，就会发生这种情况。</p><pre class="lc ld le lf gt nl nm nn bn no np bi"><span id="d859" class="nq kg iq nm b be nr ns l nt nu">1:100<br/><br/>sample(1:100,size=10)<br/><br/>cars_data[c(1,10),]<br/><br/>## Split row numbers into 2 sets<br/>set.seed(1)<br/>train_rows = sample(1:nrow(cars_data), size=0.7*nrow(cars_data))<br/>validation_rows = setdiff(1:nrow(cars_data),train_rows)<br/><br/>train_rows<br/><br/>validation_rows<br/><br/>## Subset into Train and Validation sets<br/>train_data &lt;- cars_data[train_rows,]<br/>validation_data &lt;- cars_data[validation_rows,]<br/><br/>## View the dimensions of the data<br/>dim(cars_data)<br/>dim(train_data)<br/>dim(validation_data)</span></pre><h2 id="5e27" class="kf kg iq bd kh ki kj dn kk kl km dp kn ko kp kq kr ks kt ku kv kw kx ky kz la bi translated">现在让我们建立一个模型:</h2><pre class="lc ld le lf gt nl nm nn bn no np bi"><span id="5775" class="nq kg iq nm b be nr ns l nt nu">names(train_data)<br/><br/># lm function is used to fit linear models<br/>LinReg = lm(Price ~ Disp., data = train_data)<br/><br/>## Summary of the linear model<br/>summary(LinReg)</span></pre><h2 id="3fc4" class="kf kg iq bd kh ki kj dn kk kl km dp kn ko kp kq kr ks kt ku kv kw kx ky kz la bi translated">GITHUB GIST ❤️</h2><p id="a15b" class="pw-post-body-paragraph lr ls iq lt b lu mp jr lw lx mq ju lz ko nd mb mc ks ne me mf kw nf mh mi mj ij bi translated"><strong class="lt ir">如果你想运行代码并解释结果:</strong></p><figure class="lc ld le lf gt lg"><div class="bz fp l di"><div class="nv nw l"/></div><figcaption class="ln lo gj gh gi lp lq bd b be z dk translated">来源:Github gist作者</figcaption></figure><h2 id="3a23" class="kf kg iq bd kh ki kj dn kk kl km dp kn ko kp kq kr ks kt ku kv kw kx ky kz la bi translated">2.多元线性回归:</h2><p id="37a3" class="pw-post-body-paragraph lr ls iq lt b lu mp jr lw lx mq ju lz ko nd mb mc ks ne me mf kw nf mh mi mj ij bi translated">正如我们在简单线性回归中看到的，简单线性回归中的计算是计算因变量“Y”和自变量“X”之间的距离。</p><p id="e8f9" class="pw-post-body-paragraph lr ls iq lt b lu lv jr lw lx ly ju lz ko ma mb mc ks md me mf kw mg mh mi mj ij bi translated">当我们谈论多元线性回归时，概念几乎是相同的，或者我们可以说它是简单线性回归的扩展，其中我们不是找到因变量和自变量之间的关系，而是找到因变量“Y”和解释变量“p”之间的关系</p><p id="c511" class="pw-post-body-paragraph lr ls iq lt b lu lv jr lw lx ly ju lz ko ma mb mc ks md me mf kw mg mh mi mj ij bi translated">多元线性回归由以下公式表示:</p><figure class="lc ld le lf gt lg gh gi paragraph-image"><div role="button" tabindex="0" class="lh li di lj bf lk"><div class="gh gi nx"><img src="../Images/97f5cac568f5d86b80f358d04f90dac7.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*hlzhGuZmruSX8Cxd"/></div></div><figcaption class="ln lo gj gh gi lp lq bd b be z dk translated">来源:<a class="ae mk" href="https://hummedia.manchester.ac.uk/institutes/cmist/archive-publications/working-papers/2008/2008-19-multiple-linear-regression.pdf" rel="noopener ugc nofollow" target="_blank">https://hummedia . Manchester . AC . uk/institutes/cmist/archive-publications/working-papers/2008/2008-19-multiple-linear-regression . pdf</a></figcaption></figure><h2 id="9cb6" class="kf kg iq bd kh ki kj dn kk kl km dp kn ko kp kq kr ks kt ku kv kw kx ky kz la bi translated">符号:</h2><p id="743d" class="pw-post-body-paragraph lr ls iq lt b lu mp jr lw lx mq ju lz ko nd mb mc ks ne me mf kw nf mh mi mj ij bi translated"><strong class="lt ir"> β0 </strong> =常数项</p><p id="646e" class="pw-post-body-paragraph lr ls iq lt b lu lv jr lw lx ly ju lz ko ma mb mc ks md me mf kw mg mh mi mj ij bi translated"><strong class="lt ir"> β1和βP </strong> =解释变量</p><h2 id="4f00" class="kf kg iq bd kh ki kj dn kk kl km dp kn ko kp kq kr ks kt ku kv kw kx ky kz la bi translated">有趣的花絮:</h2><p id="a0d4" class="pw-post-body-paragraph lr ls iq lt b lu mp jr lw lx mq ju lz ko nd mb mc ks ne me mf kw nf mh mi mj ij bi translated">我们在多元线性回归中使用术语“线性”,因为我们总是相信当我们使用回归时,“Y”与解释变量“P”的线性组合直接相关。</p><h2 id="18d2" class="kf kg iq bd kh ki kj dn kk kl km dp kn ko kp kq kr ks kt ku kv kw kx ky kz la bi translated">我们使用多元线性回归的真实例子:</h2><ol class=""><li id="9984" class="mn mo iq lt b lu mp lx mq ko mr ks ms kw mt mj mu mv mw mx bi translated">试图根据各种社会人口统计变量来预测一个人的收入。</li><li id="e107" class="mn mo iq lt b lu my lx mz ko na ks nb kw nc mj mu mv mw mx bi translated">试图基于16范围内的一组考试结果的值来预测“A”级学生的总评估成功。</li><li id="9c98" class="mn mo iq lt b lu my lx mz ko na ks nb kw nc mj mu mv mw mx bi translated">试图根据社会、经济和生活方式因素(就业、饮酒、吸烟、年龄等)计算收缩压或舒张压。).</li></ol><h2 id="f1d4" class="kf kg iq bd kh ki kj dn kk kl km dp kn ko kp kq kr ks kt ku kv kw kx ky kz la bi translated">让我们来看看一些案例研究的实际实现，让事情变得更清楚:</h2><figure class="lc ld le lf gt lg"><div class="bz fp l di"><div class="nv nw l"/></div><figcaption class="ln lo gj gh gi lp lq bd b be z dk translated">来源:Github gist作者</figcaption></figure><h2 id="e28d" class="kf kg iq bd kh ki kj dn kk kl km dp kn ko kp kq kr ks kt ku kv kw kx ky kz la bi translated">3.逻辑回归:</h2><p id="d3a6" class="pw-post-body-paragraph lr ls iq lt b lu mp jr lw lx mq ju lz ko nd mb mc ks ne me mf kw nf mh mi mj ij bi translated">逻辑回归是一种统计分析方法，它使用原始数据集预先存在的数据来估计二元结果，如是或否。逻辑回归模型通过检查一个或多个现有自变量之间的关系来预测因变量。</p><figure class="lc ld le lf gt lg gh gi paragraph-image"><div role="button" tabindex="0" class="lh li di lj bf lk"><div class="gh gi ny"><img src="../Images/99e5da88b4d01ac2b38ca0a22eca70f1.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*GcWs5LIKajYRW7bv"/></div></div><figcaption class="ln lo gj gh gi lp lq bd b be z dk translated">来源；<a class="ae mk" href="https://twitter.com/NickSinghTech/status/1580660958112157696" rel="noopener ugc nofollow" target="_blank">https://Twitter . com/NickSinghTech/status/1580660958112157696</a></figcaption></figure><p id="ada5" class="pw-post-body-paragraph lr ls iq lt b lu lv jr lw lx ly ju lz ko ma mb mc ks md me mf kw mg mh mi mj ij bi translated">我们之前在<a class="ae mk" href="https://medium.com/towards-artificial-intelligence/world-of-classification-in-machine-learning-a3c1f008b1fc" rel="noopener"> <em class="ml">分类博客</em> </a>里看到了很多关于logistic回归的内容；如果你想进行快速复习，请转到分类算法类型的第一项技术，以了解更多信息。</p><p id="aefc" class="pw-post-body-paragraph lr ls iq lt b lu lv jr lw lx ly ju lz ko ma mb mc ks md me mf kw mg mh mi mj ij bi translated"><strong class="lt ir">就逻辑回归类型而言，逻辑回归有三个主要的子类型:</strong></p><h2 id="7f80" class="kf kg iq bd kh ki kj dn kk kl km dp kn ko kp kq kr ks kt ku kv kw kx ky kz la bi translated">1.二元逻辑回归:</h2><p id="d1a4" class="pw-post-body-paragraph lr ls iq lt b lu mp jr lw lx mq ju lz ko nd mb mc ks ne me mf kw nf mh mi mj ij bi translated">当我们考虑二元逻辑回归时，首先想到的也是唯一想到的是0和1(二进制数)，而这正是它。响应有两种可能的结果:0或1。</p><p id="f6fa" class="pw-post-body-paragraph lr ls iq lt b lu lv jr lw lx ly ju lz ko ma mb mc ks md me mf kw mg mh mi mj ij bi translated">这是三种方法中最常见的一种。</p><h2 id="e8f3" class="kf kg iq bd kh ki kj dn kk kl km dp kn ko kp kq kr ks kt ku kv kw kx ky kz la bi translated">2.多项逻辑回归；</h2><p id="deed" class="pw-post-body-paragraph lr ls iq lt b lu mp jr lw lx mq ju lz ko nd mb mc ks ne me mf kw nf mh mi mj ij bi translated">当使用多项式逻辑回归技术时，感兴趣的变量可以有三个以上的结果，并且顺序是不固定的，并且如先前所建立的，结果不必是二进制整数。</p><p id="1fc5" class="pw-post-body-paragraph lr ls iq lt b lu lv jr lw lx ly ju lz ko ma mb mc ks md me mf kw mg mh mi mj ij bi translated"><strong class="lt ir">示例</strong>:如果网飞希望对11月份十大最受欢迎的趋势节目进行分类，逻辑回归将帮助网飞确定每个节目在某个地区或国家的观看时间。那么网飞可以通过对观看时间最多的前十个系列做广告来开始营销。</p><h2 id="6735" class="kf kg iq bd kh ki kj dn kk kl km dp kn ko kp kq kr ks kt ku kv kw kx ky kz la bi translated">3.有序逻辑回归:</h2><p id="f995" class="pw-post-body-paragraph lr ls iq lt b lu mp jr lw lx mq ju lz ko nd mb mc ks ne me mf kw nf mh mi mj ij bi translated">最后一种技术是有序逻辑回归，其中模型包含一个具有三种或更多种可能性的因变量，但与不指定顺序的多项逻辑回归不同，有序逻辑回归中的值具有明确的顺序。</p><p id="30a6" class="pw-post-body-paragraph lr ls iq lt b lu lv jr lw lx ly ju lz ko ma mb mc ks md me mf kw mg mh mi mj ij bi translated"><strong class="lt ir">举例</strong>:大学根据A到d的分数来分配成绩。</p><h2 id="4a40" class="kf kg iq bd kh ki kj dn kk kl km dp kn ko kp kq kr ks kt ku kv kw kx ky kz la bi translated">通过理解案例研究在实践中实施:</h2><figure class="lc ld le lf gt lg"><div class="bz fp l di"><div class="nv nw l"/></div><figcaption class="ln lo gj gh gi lp lq bd b be z dk translated">来源:Github gist作者</figcaption></figure><p id="2bf7" class="pw-post-body-paragraph lr ls iq lt b lu lv jr lw lx ly ju lz ko ma mb mc ks md me mf kw mg mh mi mj ij bi translated"><strong class="lt ir">学习回归有乐趣吗？因为我们为你们写歌很开心！</strong></p><figure class="lc ld le lf gt lg gh gi paragraph-image"><div class="gh gi nz"><img src="../Images/6fc9a2580900215ac74779937972a58a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1000/0*2KXcU9sRlZvZ2ong"/></div><figcaption class="ln lo gj gh gi lp lq bd b be z dk translated">资料来源:https://giphy.com/</figcaption></figure><p id="2385" class="pw-post-body-paragraph lr ls iq lt b lu lv jr lw lx ly ju lz ko ma mb mc ks md me mf kw mg mh mi mj ij bi translated"><strong class="lt ir">关注我们，享受学习数据科学博客和文章的乐趣:💙</strong></p><p id="2d9b" class="pw-post-body-paragraph lr ls iq lt b lu lv jr lw lx ly ju lz ko ma mb mc ks md me mf kw mg mh mi mj ij bi translated"><strong class="lt ir">领英</strong>:<a class="ae mk" href="https://www.linkedin.com/company/dsmcs/" rel="noopener ugc nofollow" target="_blank">https://www.linkedin.com/company/dsmcs/</a></p><p id="cb5f" class="pw-post-body-paragraph lr ls iq lt b lu lv jr lw lx ly ju lz ko ma mb mc ks md me mf kw mg mh mi mj ij bi translated"><strong class="lt ir">insta gram</strong>:【https://www.instagram.com/datasciencemeetscybersecurity/? T2】hl=en </p><p id="0ccc" class="pw-post-body-paragraph lr ls iq lt b lu lv jr lw lx ly ju lz ko ma mb mc ks md me mf kw mg mh mi mj ij bi translated">GITHUB:<a class="ae mk" href="https://github.com/Vidhi1290" rel="noopener ugc nofollow" target="_blank">https://github.com/Vidhi1290</a></p><p id="a8e8" class="pw-post-body-paragraph lr ls iq lt b lu lv jr lw lx ly ju lz ko ma mb mc ks md me mf kw mg mh mi mj ij bi translated"><strong class="lt ir">推特</strong>:<a class="ae mk" href="https://twitter.com/VidhiWaghela" rel="noopener ugc nofollow" target="_blank">https://twitter.com/VidhiWaghela</a></p><p id="2e19" class="pw-post-body-paragraph lr ls iq lt b lu lv jr lw lx ly ju lz ko ma mb mc ks md me mf kw mg mh mi mj ij bi translated"><strong class="lt ir">中等</strong>:<a class="ae mk" href="https://medium.com/@datasciencemeetscybersecurity-" rel="noopener">https://medium.com/@datasciencemeetscybersecurity-</a></p><p id="3f51" class="pw-post-body-paragraph lr ls iq lt b lu lv jr lw lx ly ju lz ko ma mb mc ks md me mf kw mg mh mi mj ij bi translated"><strong class="lt ir">网站</strong>:<a class="ae mk" href="https://datasciencemeetscybersecurity.blogspot.com/" rel="noopener ugc nofollow" target="_blank">https://www.datasciencemeetscybersecurity.com/</a></p><p id="ac1b" class="pw-post-body-paragraph lr ls iq lt b lu lv jr lw lx ly ju lz ko ma mb mc ks md me mf kw mg mh mi mj ij bi translated">—团队数据科学与网络安全❤️相遇💙</p></div></div>    
</body>
</html>