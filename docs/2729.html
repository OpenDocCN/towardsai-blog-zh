<html>
<head>
<title>AI Researchers Are Constantly Trying To Recreate These Cognitive Functions of the Human Brain</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">人工智能研究人员正在不断尝试重建人脑的这些认知功能</h1>
<blockquote>原文：<a href="https://pub.towardsai.net/ai-researchers-are-constantly-trying-to-recreate-these-cognitive-functions-of-the-human-brain-10a905577ecc?source=collection_archive---------0-----------------------#2022-05-03">https://pub.towardsai.net/ai-researchers-are-constantly-trying-to-recreate-these-cognitive-functions-of-the-human-brain-10a905577ecc?source=collection_archive---------0-----------------------#2022-05-03</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="419d" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">注意力、记忆、想象力、推理和持续学习是人类大脑的认知功能，处于人工智能研究的前沿。</h2></div><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ki"><img src="../Images/9b468b740fded24dbb2b19b819e8051d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*Dw-GC1RYO150Mck3.jpg"/></div></div><figcaption class="ku kv gj gh gi kw kx bd b be z dk translated">来源:<a class="ae ky" href="https://www.wsj.com/articles/should-artificial-intelligence-copy-the-human-brain-1533355265" rel="noopener ugc nofollow" target="_blank">https://www . wsj . com/articles/should-artificial-intelligence-copy-the-human-brain-153355265</a></figcaption></figure><blockquote class="kz la lb"><p id="28c6" class="lc ld le lf b lg lh ju li lj lk jx ll lm ln lo lp lq lr ls lt lu lv lw lx ly im bi translated">我最近创办了一份专注于人工智能的教育时事通讯，已经有超过125，000名订户。《序列》是一份无废话(意思是没有炒作，没有新闻等)的ML导向时事通讯，需要5分钟阅读。目标是让你与机器学习项目、研究论文和概念保持同步。请通过订阅以下内容来尝试一下:</p></blockquote><div class="lz ma gp gr mb mc"><a href="https://thesequence.substack.com/" rel="noopener  ugc nofollow" target="_blank"><div class="md ab fo"><div class="me ab mf cl cj mg"><h2 class="bd iu gy z fp mh fr fs mi fu fw is bi translated">序列</h2><div class="mj l"><h3 class="bd b gy z fp mh fr fs mi fu fw dk translated">与机器学习、人工智能和数据发展保持同步的最佳资源…</h3></div><div class="mk l"><p class="bd b dl z fp mh fr fs mi fu fw dk translated">thesequence.substack.com</p></div></div><div class="ml l"><div class="mm l mn mo mp ml mq ks mc"/></div></div></a></div><p id="2b27" class="pw-post-body-paragraph lc ld it lf b lg lh ju li lj lk jx ll mr ln lo lp ms lr ls lt mt lv lw lx ly im bi translated">大脑一直被认为是人工智能(AI)领域的主要灵感。对于许多人工智能研究人员来说，人工智能的最终目标是模拟大脑的能力。这似乎是一个不错的说法，但考虑到神经科学家仍在努力理解为我们大脑的魔力提供动力的认知机制，这是一项令人难以置信的艰巨任务。尽管存在挑战，但我们更经常地看到人工智能研究和实现算法受到人脑中特定认知机制的启发，并产生了令人难以置信的有前途的结果。2017年，DeepMind团队<a class="ae ky" href="http://www.cell.com/neuron/fulltext/S0896-6273(17)30509-3" rel="noopener ugc nofollow" target="_blank">发表了一篇关于神经科学启发的人工智能</a>的论文，总结了人工智能和神经科学研究之间的影响圈。</p><p id="2055" class="pw-post-body-paragraph lc ld it lf b lg lh ju li lj lk jx ll mr ln lo lp ms lr ls lt mt lv lw lx ly im bi translated">你可能想知道这个话题有什么新鲜的？众所周知，人工智能中的大多数基础概念，如神经网络，都是受人类大脑架构的启发。然而，在那种高层次的说法之外，我们每天使用的流行的AI/深度学习模型与神经科学研究之间的关系并不那么明显。让我们快速回顾一下在最新一代深度学习方法中留下足迹的一些大脑过程。</p><h1 id="ef37" class="mu mv it bd mw mx my mz na nb nc nd ne jz nf ka ng kc nh kd ni kf nj kg nk nl bi translated">注意力</h1><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi nm"><img src="../Images/a0fafedfa519512a2e0eaba3fb01bcb7.png" data-original-src="https://miro.medium.com/v2/resize:fit:822/format:webp/0*1KcCwDZZow3cTFFt.png"/></div><figcaption class="ku kv gj gh gi kw kx bd b be z dk translated">来源:<a class="ae ky" href="https://www.cell.com/neuron/fulltext/S0896-6273%2817%2930509-3" rel="noopener ugc nofollow" target="_blank">https://www . cell . com/neuron/full text/s 0896-6273% 2817% 2930509-3</a></figcaption></figure><p id="e4eb" class="pw-post-body-paragraph lc ld it lf b lg lh ju li lj lk jx ll mr ln lo lp ms lr ls lt mt lv lw lx ly im bi translated">注意力是人类大脑的神奇能力之一，我们对此并不十分了解。什么样的大脑机制让我们专注于一项特定的任务，而忽略了环境的其余部分？注意力机制已经成为深度学习模型(如卷积神经网络(CNN)或深度生成模型)的最新灵感来源。例如，现代CNN模型已经能够获得输入的示意图，并忽略不相关的信息，从而提高了它们对图片中的对象进行分类的能力。</p><h1 id="3d49" class="mu mv it bd mw mx my mz na nb nc nd ne jz nf ka ng kc nh kd ni kf nj kg nk nl bi translated">情景记忆</h1><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi nn"><img src="../Images/90b68f4fedc81bab2907a948820f7961.png" data-original-src="https://miro.medium.com/v2/resize:fit:1190/format:webp/0*-17mH7PzwL_dFisL.png"/></div><figcaption class="ku kv gj gh gi kw kx bd b be z dk translated">来源:<a class="ae ky" href="https://www.cell.com/neuron/fulltext/S0896-6273%2817%2930509-3" rel="noopener ugc nofollow" target="_blank">https://www . cell . com/neuron/full text/s 0896-6273% 2817% 2930509-3</a></figcaption></figure><p id="5d0b" class="pw-post-body-paragraph lc ld it lf b lg lh ju li lj lk jx ll mr ln lo lp ms lr ls lt mt lv lw lx ly im bi translated">当你回忆自传体事件，比如事件或地点时，我们使用的是一种被称为情景记忆的大脑功能。这种机制通常与内侧颞叶中的回路有关，主要包括海马体。最近，人工智能研究人员试图将情景记忆启发的方法融入情景控制的强化学习(RL)算法中。这些网络存储特定体验(例如，与特定Atari游戏屏幕相关联的动作和奖励结果)，并且基于当前情况输入和存储在存储器中的先前事件之间的相似性来选择新的动作，同时考虑与那些先前事件相关联的奖励。</p><h1 id="9418" class="mu mv it bd mw mx my mz na nb nc nd ne jz nf ka ng kc nh kd ni kf nj kg nk nl bi translated">持续学习</h1><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi no"><img src="../Images/408677a90375eb1bcf7f7c538638a22c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1048/format:webp/0*9EcpYO9B9k-xofbe.png"/></div><figcaption class="ku kv gj gh gi kw kx bd b be z dk translated">来源:<a class="ae ky" href="https://www.cell.com/neuron/fulltext/S0896-6273%2817%2930509-3" rel="noopener ugc nofollow" target="_blank">https://www . cell . com/neuron/full text/s 0896-6273% 2817% 2930509-3</a></figcaption></figure><p id="0c2a" class="pw-post-body-paragraph lc ld it lf b lg lh ju li lj lk jx ll mr ln lo lp ms lr ls lt mt lv lw lx ly im bi translated">作为人类，我们有能力学习新的任务，而不会忘记以前的知识。相比之下，神经网络则遭遇了所谓的灾难性遗忘问题。例如，当神经网络参数朝着执行两个连续任务中的第二个任务的最佳状态移动，覆盖了允许它们执行第一个任务的配置时，就会发生这种情况。</p><p id="e23b" class="pw-post-body-paragraph lc ld it lf b lg lh ju li lj lk jx ll mr ln lo lp ms lr ls lt mt lv lw lx ly im bi translated">受持续学习领域的启发，最近的深度学习技术之一被称为“弹性”权重整合(EWC)。这种新方法通过减缓在被识别为对先前任务重要的网络权重子集中的学习来起作用，从而将这些参数锚定到先前找到的解决方案。这允许在不增加网络容量的情况下学习多个任务，在具有相关结构的任务之间有效地共享权重。通过这种方式，EWC算法允许深度RL网络支持大规模的连续学习。</p><h1 id="3ddf" class="mu mv it bd mw mx my mz na nb nc nd ne jz nf ka ng kc nh kd ni kf nj kg nk nl bi translated">想象力和计划</h1><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi np"><img src="../Images/83831f94c9374a02a6dea8d3a3d8144e.png" data-original-src="https://miro.medium.com/v2/resize:fit:656/format:webp/0*WI9tSY7Sg15zJFJt.png"/></div><figcaption class="ku kv gj gh gi kw kx bd b be z dk translated">来源:<a class="ae ky" href="https://www.cell.com/neuron/fulltext/S0896-6273%2817%2930509-3" rel="noopener ugc nofollow" target="_blank">https://www . cell . com/neuron/full text/s 0896-6273% 2817% 2930509-3</a></figcaption></figure><p id="e5df" class="pw-post-body-paragraph lc ld it lf b lg lh ju li lj lk jx ll mr ln lo lp ms lr ls lt mt lv lw lx ly im bi translated">我最喜欢的意识定义之一与人类(和其他物种)预测和思考未来的能力有关。大多数深度学习系统仍然以令人难以置信的反应模式运行，这使得不可能对长期结果进行规划。人工智能研究的新领域集中于应用于深度生成模型的基于模拟的规划。特别地，最近的工作已经引入了新的体系结构，该体系结构具有生成时间上一致的所生成样本序列的能力，该序列反映了新经历的现实环境的几何布局，提供了与海马体在将多个组件结合在一起以创建空间和时间上一致的想象体验中的功能的相似性。</p><h1 id="1331" class="mu mv it bd mw mx my mz na nb nc nd ne jz nf ka ng kc nh kd ni kf nj kg nk nl bi translated">推理</h1><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi nq"><img src="../Images/6d4d99d16603096ec6ac7e38a5d0aa48.png" data-original-src="https://miro.medium.com/v2/resize:fit:1276/format:webp/0*08eGagAo0_lSrgi0.png"/></div><figcaption class="ku kv gj gh gi kw kx bd b be z dk translated">来源:<a class="ae ky" href="https://bair.berkeley.edu/blog/2017/07/18/learning-to-learn/" rel="noopener ugc nofollow" target="_blank">https://bair . Berkeley . edu/blog/2017/07/18/learning-to-learn/</a></figcaption></figure><p id="81f6" class="pw-post-body-paragraph lc ld it lf b lg lh ju li lj lk jx ll mr ln lo lp ms lr ls lt mt lv lw lx ly im bi translated">人类的认知因其通过归纳推理从以前的知识中汲取灵感来学习新概念的能力而臭名昭著。与此相反，深度学习系统依靠大量的训练数据来掌握最简单的任务。最近在结构化概率方法和深度生成模型方面的工作已经开始在人工智能程序中纳入大脑启发的推理机制。尽管缺乏数据，但模型的类别可以对新概念做出推断，并从单个示例概念中生成新样本，元学习的快速增长领域是受人脑推理能力启发的另一个人工智能研究领域。</p></div></div>    
</body>
</html>