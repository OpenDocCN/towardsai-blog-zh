<html>
<head>
<title>Introduction to CNNs — Without using MNIST!</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">CNN简介——不使用MNIST！</h1>
<blockquote>原文：<a href="https://pub.towardsai.net/introduction-to-cnns-without-using-mnist-ea62040341d0?source=collection_archive---------2-----------------------#2020-10-04">https://pub.towardsai.net/introduction-to-cnns-without-using-mnist-ea62040341d0?source=collection_archive---------2-----------------------#2020-10-04</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><h2 id="f701" class="io ip iq bd b dl ir is it iu iv iw dk ix translated" aria-label="kicker paragraph"><a class="ae ep" href="https://towardsai.net/p/category/computer-vision" rel="noopener ugc nofollow" target="_blank">计算机视觉</a>，<a class="ae ep" href="https://towardsai.net/p/category/machine-learning/deep-learning" rel="noopener ugc nofollow" target="_blank">深度学习</a></h2><div class=""/><div class=""><h2 id="86c5" class="pw-subtitle-paragraph jw iz iq bd b jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn dk translated">CNN简介，为深度学习的初学者提供易于访问的数据集。</h2></div><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div role="button" tabindex="0" class="ku kv di kw bf kx"><div class="gh gi ko"><img src="../Images/f233683867007dac73db061898d4aea5.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*077Q3n_z1PnkqC2bnp006Q.jpeg"/></div></div><figcaption class="la lb gj gh gi lc ld bd b be z dk translated"><a class="ae le" href="https://quickdraw.withgoogle.com" rel="noopener ugc nofollow" target="_blank">来源</a></figcaption></figure><h1 id="764b" class="lf lg iq bd lh li lj lk ll lm ln lo lp kf lq kg lr ki ls kj lt kl lu km lv lw bi translated">介绍🍵</h1><p id="b620" class="pw-post-body-paragraph lx ly iq lz b ma mb ka mc md me kd mf mg mh mi mj mk ml mm mn mo mp mq mr ms ij bi translated">MNIST数据集是开始影像分类时使用最频繁的数据集。Yann LeCun在1998年引入的由10类手写数字组成的MNIST数据集在科学论文、博客帖子等中反复出现。它包含手写数字的28×28(也是32×32)灰度图像，每个图像包含0到9之间的整数。</p><p id="0263" class="pw-post-body-paragraph lx ly iq lz b ma mt ka mc md mu kd mf mg mv mi mj mk mw mm mn mo mx mq mr ms ij bi translated">MNIST如此受欢迎的原因与其规模有关，它允许深度学习实践者快速检查、训练和发布他们的算法。MNIST有一定的变化和局限性。</p><p id="fa2e" class="pw-post-body-paragraph lx ly iq lz b ma mt ka mc md mu kd mf mg mv mi mj mk mw mm mn mo mx mq mr ms ij bi translated">主要目标是提出一个新的数据集来理解使用CNN的图像分类。</p><h1 id="822d" class="lf lg iq bd lh li lj lk ll lm ln lo lp kf lq kg lr ki ls kj lt kl lu km lv lw bi translated">如果不是MNIST，那是什么？🤔</h1><p id="966a" class="pw-post-body-paragraph lx ly iq lz b ma mb ka mc md me kd mf mg mh mi mj mk ml mm mn mo mp mq mr ms ij bi translated">出于简单解释的目的，我选择了谷歌的快速绘制图像。这些图像是在人工智能实验中生成的涂鸦。</p><p id="0f6c" class="pw-post-body-paragraph lx ly iq lz b ma mt ka mc md mu kd mf mg mv mi mj mk mw mm mn mo mx mq mr ms ij bi translated">从这个视频中了解更多关于数据集的信息，</p><figure class="kp kq kr ks gt kt"><div class="bz fp l di"><div class="my mz l"/></div><figcaption class="la lb gj gh gi lc ld bd b be z dk translated"><a class="ae le" href="https://www.youtube.com/channel/UCJS9pqu9BzkAMNTmzNMNhvg" rel="noopener ugc nofollow" target="_blank">谷歌云平台</a></figcaption></figure><p id="ecf0" class="pw-post-body-paragraph lx ly iq lz b ma mt ka mc md mu kd mf mg mv mi mj mk mw mm mn mo mx mq mr ms ij bi translated">你也可以在这里自己尝试快速绘图，</p><div class="na nb gp gr nc nd"><a href="https://quickdraw.withgoogle.com" rel="noopener  ugc nofollow" target="_blank"><div class="ne ab fo"><div class="nf ab ng cl cj nh"><h2 class="bd ja gy z fp ni fr fs nj fu fw iz bi translated">快，画！</h2><div class="nk l"><h3 class="bd b gy z fp ni fr fs nj fu fw dk translated">这是一个用机器学习构建的游戏。你画画，神经网络试图猜测你在画什么。的…</h3></div><div class="nl l"><p class="bd b dl z fp ni fr fs nj fu fw dk translated">quickdraw.withgoogle.com</p></div></div><div class="nm l"><div class="nn l no np nq nm nr ky nd"/></div></div></a></div><p id="4381" class="pw-post-body-paragraph lx ly iq lz b ma mt ka mc md mu kd mf mg mv mi mj mk mw mm mn mo mx mq mr ms ij bi translated">数据被格式化成各种类型。我用过NumPy版本(。npy文件)。这些已被渲染成NumPy格式的28x28灰度位图。通过下面分享的文档了解更多信息，</p><div class="na nb gp gr nc nd"><a href="https://github.com/googlecreativelab/quickdraw-dataset" rel="noopener  ugc nofollow" target="_blank"><div class="ne ab fo"><div class="nf ab ng cl cj nh"><h2 class="bd ja gy z fp ni fr fs nj fu fw iz bi translated">Google creative lab/quick draw-dataset</h2><div class="nk l"><h3 class="bd b gy z fp ni fr fs nj fu fw dk translated">快速抽奖数据集是由游戏玩家提供的345个类别的5000万张图片的集合…</h3></div><div class="nl l"><p class="bd b dl z fp ni fr fs nj fu fw dk translated">github.com</p></div></div><div class="nm l"><div class="ns l no np nq nm nr ky nd"/></div></div></a></div><h1 id="23bf" class="lf lg iq bd lh li lj lk ll lm ln lo lp kf lq kg lr ki ls kj lt kl lu km lv lw bi translated">🧐使用的图像和类别</h1><p id="e3ca" class="pw-post-body-paragraph lx ly iq lz b ma mb ka mc md me kd mf mg mh mi mj mk ml mm mn mo mp mq mr ms ij bi translated">数据集很大，类别也很广。为了演示的目的，我使用了<strong class="lz ja"> 10个类</strong>和大约<strong class="lz ja"> 60，000张图片</strong>。本来数据集就很大。如果您使用Colab，那么它可能会在执行操作时崩溃。以下是所考虑的10个类别的直观表示。</p><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div class="gh gi nt"><img src="../Images/d008e804c7a060b012bb03354c15bda3.png" data-original-src="https://miro.medium.com/v2/resize:fit:1114/format:webp/1*OvVrzeikpm2nKMbb9poNcw.png"/></div><figcaption class="la lb gj gh gi lc ld bd b be z dk translated">来源:<a class="ae le" href="https://github.com/pr2tik1/blog/blob/master/_notebooks/2020-09-08-Sketch-Recognition.ipynb" rel="noopener ugc nofollow" target="_blank"> Jupyter笔记本</a></figcaption></figure><p id="c0e3" class="pw-post-body-paragraph lx ly iq lz b ma mt ka mc md mu kd mf mg mv mi mj mk mw mm mn mo mx mq mr ms ij bi translated">这些类别是:</p><pre class="kp kq kr ks gt nu nv nw nx aw ny bi"><span id="bae3" class="nz lg iq nv b gy oa ob l oc od">'cloud', 'sun', 'pants', 'umbrella', 'table', 'ladder', 'eyeglasses', 'clock', 'scissors', 'cup'</span></pre><p id="365b" class="pw-post-body-paragraph lx ly iq lz b ma mt ka mc md mu kd mf mg mv mi mj mk mw mm mn mo mx mq mr ms ij bi translated">我将分享完整的代码和脚本，以改变图像和类的数量。请在这篇文章的结尾找到它。</p><p id="8d52" class="pw-post-body-paragraph lx ly iq lz b ma mt ka mc md mu kd mf mg mv mi mj mk mw mm mn mo mx mq mr ms ij bi translated">您可能会注意到，这与MNIST的数据有些相似，</p><ul class=""><li id="bcbc" class="oe of iq lz b ma mt md mu mg og mk oh mo oi ms oj ok ol om bi translated">它有灰度图像(没有RGB通道)</li><li id="8e32" class="oe of iq lz b ma on md oo mg op mk oq mo or ms oj ok ol om bi translated">28 x 28尺寸的图像</li><li id="b64e" class="oe of iq lz b ma on md oo mg op mk oq mo or ms oj ok ol om bi translated">它有10个班级，而MNIST有0-9个班级。</li></ul><h1 id="cc36" class="lf lg iq bd lh li lj lk ll lm ln lo lp kf lq kg lr ki ls kj lt kl lu km lv lw bi translated">卷积神经网络💪</h1><p id="9dee" class="pw-post-body-paragraph lx ly iq lz b ma mb ka mc md me kd mf mg mh mi mj mk ml mm mn mo mp mq mr ms ij bi translated">与传统的线性和非线性分类算法相比,<strong class="lz ja"> CNN </strong>在图像分类中产生更好的结果。这是因为它们减少了要学习的参数数量。</p><p id="71f9" class="pw-post-body-paragraph lx ly iq lz b ma mt ka mc md mu kd mf mg mv mi mj mk mw mm mn mo mx mq mr ms ij bi translated">CNN使用图像和滤波器的卷积来提取每一层的复杂不变特征。提取的特征的复杂性随着层的深度而增加。它们成功地捕捉了图像中的空间和时间相关性。</p><p id="0e2e" class="pw-post-body-paragraph lx ly iq lz b ma mt ka mc md mu kd mf mg mv mi mj mk mw mm mn mo mx mq mr ms ij bi translated">特征的复杂性—</p><ul class=""><li id="373e" class="oe of iq lz b ma mt md mu mg og mk oh mo oi ms oj ok ol om bi translated">第1层:边缘</li><li id="314d" class="oe of iq lz b ma on md oo mg op mk oq mo or ms oj ok ol om bi translated">第2层:形状</li><li id="7ff5" class="oe of iq lz b ma on md oo mg op mk oq mo or ms oj ok ol om bi translated">第三层:形状图案</li><li id="be5b" class="oe of iq lz b ma on md oo mg op mk oq mo or ms oj ok ol om bi">….</li><li id="3745" class="oe of iq lz b ma on md oo mg op mk oq mo or ms oj ok ol om bi translated">输出</li></ul><p id="95f2" class="pw-post-body-paragraph lx ly iq lz b ma mt ka mc md mu kd mf mg mv mi mj mk mw mm mn mo mx mq mr ms ij bi translated">要了解更多关于各层之间实际发生的情况，</p><div class="na nb gp gr nc nd"><a href="https://distill.pub/2018/building-blocks/" rel="noopener  ugc nofollow" target="_blank"><div class="ne ab fo"><div class="nf ab ng cl cj nh"><h2 class="bd ja gy z fp ni fr fs nj fu fw iz bi translated">可解释性的基石</h2><div class="nk l"><h3 class="bd b gy z fp ni fr fs nj fu fw dk translated">随着神经网络的日益成功，相应地需要能够解释它们的决定…</h3></div><div class="nl l"><p class="bd b dl z fp ni fr fs nj fu fw dk translated">蒸馏. pub</p></div></div><div class="nm l"><div class="os l no np nq nm nr ky nd"/></div></div></a></div><h1 id="ac99" class="lf lg iq bd lh li lj lk ll lm ln lo lp kf lq kg lr ki ls kj lt kl lu km lv lw bi translated">🛠有线电视新闻网的组成部分</h1><p id="fa65" class="pw-post-body-paragraph lx ly iq lz b ma mb ka mc md me kd mf mg mh mi mj mk ml mm mn mo mp mq mr ms ij bi translated">以下是卷积神经网络的特征，</p><h2 id="853f" class="nz lg iq bd lh ot ou dn ll ov ow dp lp mg ox oy lr mk oz pa lt mo pb pc lv iw bi translated">1.回旋</h2><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div class="gh gi pd"><img src="../Images/334265920b1b81953d91ddf6e2d908cd.png" data-original-src="https://miro.medium.com/v2/resize:fit:962/1*KHrMyqucI8mc5WaOqGIFTQ.gif"/></div><figcaption class="la lb gj gh gi lc ld bd b be z dk translated"><a class="ae le" href="https://arxiv.org/abs/1603.07285" rel="noopener ugc nofollow" target="_blank">一个标准卷积</a></figcaption></figure><p id="1f76" class="pw-post-body-paragraph lx ly iq lz b ma mt ka mc md mu kd mf mg mv mi mj mk mw mm mn mo mx mq mr ms ij bi translated">卷积是一种矩阵运算，由一个核(一个小的权重矩阵)组成，它在输入数据上滑动，与输入数据所在的部分执行逐元素乘法，然后将结果相加得到一个输出。</p><p id="db13" class="pw-post-body-paragraph lx ly iq lz b ma mt ka mc md mu kd mf mg mv mi mj mk mw mm mn mo mx mq mr ms ij bi translated">这些基本上是合并两组信息。数学上，卷积是指两个函数的组合产生第三个函数。在CNN的情况下，卷积是将滤波器/内核应用于输入图像，导致激活。</p><h2 id="97e1" class="nz lg iq bd lh ot ou dn ll ov ow dp lp mg ox oy lr mk oz pa lt mo pb pc lv iw bi translated">2.联营</h2><p id="c52a" class="pw-post-body-paragraph lx ly iq lz b ma mb ka mc md me kd mf mg mh mi mj mk ml mm mn mo mp mq mr ms ij bi translated">池图层通过汇总要素地图的图片中要素的存在情况，提供了一种对要素地图进行缩减采样的方法。两种常见的联营方法是平均联营和最大联营。</p><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div class="gh gi pe"><img src="../Images/7ff48c0374b4c87540619dd4203b7dcb.png" data-original-src="https://miro.medium.com/v2/resize:fit:1034/format:webp/0*NzcojpeVNkM-jhQ4.png"/></div><figcaption class="la lb gj gh gi lc ld bd b be z dk translated"><a class="ae le" href="https://arxiv.org/abs/1603.07285" rel="noopener ugc nofollow" target="_blank">T5【最大池】和CNNT7【平均池】</a></figcaption></figure><h1 id="0852" class="lf lg iq bd lh li lj lk ll lm ln lo lp kf lq kg lr ki ls kj lt kl lu km lv lw bi translated">PyTorch实现💻</h1><p id="15cd" class="pw-post-body-paragraph lx ly iq lz b ma mb ka mc md me kd mf mg mh mi mj mk ml mm mn mo mp mq mr ms ij bi translated">编码部分使用PyTorch完成。它可以分为:</p><ul class=""><li id="5dca" class="oe of iq lz b ma mt md mu mg og mk oh mo oi ms oj ok ol om bi translated">定义模型</li><li id="b6be" class="oe of iq lz b ma on md oo mg op mk oq mo or ms oj ok ol om bi translated">定义超参数</li><li id="c948" class="oe of iq lz b ma on md oo mg op mk oq mo or ms oj ok ol om bi translated">培训和测试</li></ul><h2 id="34ac" class="nz lg iq bd lh ot ou dn ll ov ow dp lp mg ox oy lr mk oz pa lt mo pb pc lv iw bi translated">1.定义模型</h2><p id="8a88" class="pw-post-body-paragraph lx ly iq lz b ma mb ka mc md me kd mf mg mh mi mj mk ml mm mn mo mp mq mr ms ij bi translated">我们使用PyTorch的NN模块定义一个模型或CNN架构。以下是具有两个卷积层和两个全连接层的神经网络架构。</p><pre class="kp kq kr ks gt nu nv nw nx aw ny bi"><span id="f4d6" class="nz lg iq nv b gy oa ob l oc od"><strong class="nv ja">class</strong> <strong class="nv ja">CNN(</strong>nn<strong class="nv ja">.</strong>Module<strong class="nv ja">):</strong><br/>    <strong class="nv ja">def</strong> __init__<strong class="nv ja">(</strong><em class="pg">self</em><strong class="nv ja">,</strong> input_size<strong class="nv ja">,</strong> n_feature<strong class="nv ja">,</strong> output_size<strong class="nv ja">):</strong><br/>        <em class="pg">super</em><strong class="nv ja">(</strong>CNN<strong class="nv ja">,</strong> <em class="pg">self</em><strong class="nv ja">).</strong>__init__<strong class="nv ja">()</strong><br/>        <em class="pg">self</em><strong class="nv ja">.</strong>n_feature <strong class="nv ja">=</strong> n_feature<br/>        <em class="pg">self</em><strong class="nv ja">.</strong>conv1 <strong class="nv ja">=</strong> nn<strong class="nv ja">.</strong>Conv2d<strong class="nv ja">(</strong>in_channels<strong class="nv ja">=</strong>1<strong class="nv ja">,</strong> <br/>                               out_channels<strong class="nv ja">=</strong>n_feature<strong class="nv ja">,</strong> <br/>                               kernel_size<strong class="nv ja">=</strong>5<strong class="nv ja">)</strong><br/>        <em class="pg">self</em><strong class="nv ja">.</strong>conv2 <strong class="nv ja">=</strong> nn<strong class="nv ja">.</strong>Conv2d<strong class="nv ja">(</strong>n_feature<strong class="nv ja">,</strong> n_feature<strong class="nv ja">,</strong> kernel_size<strong class="nv ja">=</strong>5<strong class="nv ja">)</strong><br/>        <em class="pg">self</em><strong class="nv ja">.</strong>fc1 <strong class="nv ja">=</strong> nn<strong class="nv ja">.</strong>Linear<strong class="nv ja">(</strong>n_feature<strong class="nv ja">*</strong>4<strong class="nv ja">*</strong>4<strong class="nv ja">,</strong> 50<strong class="nv ja">)</strong><br/>        <em class="pg">self</em><strong class="nv ja">.</strong>fc2 <strong class="nv ja">=</strong> nn<strong class="nv ja">.</strong>Linear<strong class="nv ja">(</strong>50<strong class="nv ja">,</strong> 10<strong class="nv ja">)</strong><br/>        <br/>    <strong class="nv ja">def</strong> <strong class="nv ja">forward(</strong><em class="pg">self</em><strong class="nv ja">,</strong> x<strong class="nv ja">,</strong> verbose<strong class="nv ja">=False):</strong><br/>        x <strong class="nv ja">=</strong> F<strong class="nv ja">.</strong>relu<strong class="nv ja">(</strong><em class="pg">self</em><strong class="nv ja">.</strong>conv1<strong class="nv ja">(</strong>x<strong class="nv ja">))</strong><br/>        x <strong class="nv ja">=</strong> F<strong class="nv ja">.</strong>max_pool2d<strong class="nv ja">(</strong>x<strong class="nv ja">,</strong> kernel_size<strong class="nv ja">=</strong>2<strong class="nv ja">)</strong><br/>        x <strong class="nv ja">=</strong> F<strong class="nv ja">.</strong>relu<strong class="nv ja">(</strong><em class="pg">self</em><strong class="nv ja">.</strong>conv2<strong class="nv ja">(</strong>x<strong class="nv ja">))</strong><br/>        x <strong class="nv ja">=</strong> F<strong class="nv ja">.</strong>max_pool2d<strong class="nv ja">(</strong>x<strong class="nv ja">,</strong> kernel_size<strong class="nv ja">=</strong>2<strong class="nv ja">)</strong><br/>        x <strong class="nv ja">=</strong> x<strong class="nv ja">.</strong>view<strong class="nv ja">(-</strong>1<strong class="nv ja">,</strong> <em class="pg">self</em><strong class="nv ja">.</strong>n_feature<strong class="nv ja">*</strong>4<strong class="nv ja">*</strong>4<strong class="nv ja">)</strong><br/>        x <strong class="nv ja">=</strong> F<strong class="nv ja">.</strong>relu<strong class="nv ja">(</strong><em class="pg">self</em><strong class="nv ja">.</strong>fc1<strong class="nv ja">(</strong>x<strong class="nv ja">))</strong><br/>        x <strong class="nv ja">=</strong> F<strong class="nv ja">.</strong>log_softmax<strong class="nv ja">(</strong>x<strong class="nv ja">,</strong> dim<strong class="nv ja">=</strong>1<strong class="nv ja">)</strong><br/>        <strong class="nv ja">return</strong> x</span></pre><h2 id="0e99" class="nz lg iq bd lh ot ou dn ll ov ow dp lp mg ox oy lr mk oz pa lt mo pb pc lv iw bi translated">2.定义超参数</h2><p id="00d0" class="pw-post-body-paragraph lx ly iq lz b ma mb ka mc md me kd mf mg mh mi mj mk ml mm mn mo mp mq mr ms ij bi translated">采用的模型尺寸取决于所考虑的输入和输出。CNN将把784(= 28x28)作为输入，并产生10个类。</p><p id="4720" class="pw-post-body-paragraph lx ly iq lz b ma mt ka mc md mu kd mf mg mv mi mj mk mw mm mn mo mx mq mr ms ij bi translated">我选择的损失函数是负对数似然损失。优化函数是随机梯度下降。这将更新我们网络的权重和偏好。我把学习率设为0.03，动量设为0.9。</p><pre class="kp kq kr ks gt nu nv nw nx aw ny bi"><span id="91be" class="nz lg iq nv b gy oa ob l oc od">model <strong class="nv ja">=</strong> CNN<strong class="nv ja">(</strong>784<strong class="nv ja">,</strong> 24<strong class="nv ja">,</strong> 10<strong class="nv ja">)</strong><br/>model <strong class="nv ja">=</strong> model<strong class="nv ja">.</strong>to<strong class="nv ja">(</strong>device<strong class="nv ja">)</strong><br/><br/><em class="pg">#Loss criterian</em><br/>criterion <strong class="nv ja">=</strong> nn<strong class="nv ja">.</strong>NLLLoss<strong class="nv ja">()</strong><br/><br/><em class="pg">#Optimization Function/Weights and Bias Updating Rule</em><br/>optimizer <strong class="nv ja">=</strong> optim<strong class="nv ja">.</strong>SGD<strong class="nv ja">(</strong>model<strong class="nv ja">.</strong>parameters<strong class="nv ja">(),</strong> lr<strong class="nv ja">=</strong>0.03<strong class="nv ja">,</strong> momentum<strong class="nv ja">=</strong>0.9<strong class="nv ja">)</strong></span></pre><h2 id="7aea" class="nz lg iq bd lh ot ou dn ll ov ow dp lp mg ox oy lr mk oz pa lt mo pb pc lv iw bi translated">3.培训和测试</h2><p id="1e7a" class="pw-post-body-paragraph lx ly iq lz b ma mb ka mc md me kd mf mg mh mi mj mk ml mm mn mo mp mq mr ms ij bi translated">如需培训和测试，请关注以下分享的博客帖子。在这里，我对网络进行了训练和测试。这是我的个人博客网站，在这里我分享了完整的代码和Jupyter笔记本。此外，我还探索了降维技术。</p><p id="f022" class="pw-post-body-paragraph lx ly iq lz b ma mt ka mc md mu kd mf mg mv mi mj mk mw mm mn mo mx mq mr ms ij bi translated">我的网络运行良好，准确率为96.7%，损耗为0.122%，T2为0.3%。您还可以通过Colab运行并测试自己的实现。</p><div class="na nb gp gr nc nd"><a href="https://pr2tik1.github.io/blog/pytorch/cnn/pca/t-sne/2020/09/08/Sketch-Recognition.html" rel="noopener  ugc nofollow" target="_blank"><div class="ne ab fo"><div class="nf ab ng cl cj nh"><h2 class="bd ja gy z fp ni fr fs nj fu fw iz bi translated">基于PyTorch的涂鸦图像分类</h2><div class="nk l"><h3 class="bd b gy z fp ni fr fs nj fu fw dk translated">在这本笔记本中，我实现了LeNet-5的修改版本，这是一个神经网络模型，包括…</h3></div><div class="nl l"><p class="bd b dl z fp ni fr fs nj fu fw dk translated">pr2tik1.github.io</p></div></div><div class="nm l"><div class="ph l no np nq nm nr ky nd"/></div></div></a></div><h1 id="aafc" class="lf lg iq bd lh li lj lk ll lm ln lo lp kf lq kg lr ki ls kj lt kl lu km lv lw bi translated">资源和参考资料📚</h1><ol class=""><li id="1878" class="oe of iq lz b ma mb md me mg pi mk pj mo pk ms pl ok ol om bi translated"><a class="ae le" href="https://cs231n.github.io" rel="noopener ugc nofollow" target="_blank"> CS231n </a></li><li id="71a8" class="oe of iq lz b ma on md oo mg op mk oq mo or ms pl ok ol om bi translated"><a class="ae le" href="https://github.com/pr2tik1/blog/blob/master/_notebooks/2020-09-08-Sketch-Recognition.ipynb" rel="noopener ugc nofollow" target="_blank"> Jupyter笔记本</a> —代码</li><li id="fe31" class="oe of iq lz b ma on md oo mg op mk oq mo or ms pl ok ol om bi translated"><a class="ae le" href="https://pr2tik1.github.io/blog/pytorch/cnn/pca/t-sne/2020/09/08/Sketch-Recognition.html" rel="noopener ugc nofollow" target="_blank">博文</a> —涂鸦图片分类完整说明。</li></ol><h1 id="a43d" class="lf lg iq bd lh li lj lk ll lm ln lo lp kf lq kg lr ki ls kj lt kl lu km lv lw bi translated">谢谢大家！😇</h1><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div role="button" tabindex="0" class="ku kv di kw bf kx"><div class="gh gi pm"><img src="../Images/638a07dd0a1bdcb76085d9d56758d127.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*XiytKN4O0Oqh8_di"/></div></div><figcaption class="la lb gj gh gi lc ld bd b be z dk translated">照片由<a class="ae le" href="https://unsplash.com/@nicklbaert?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Niclas Illg </a>在<a class="ae le" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上拍摄</figcaption></figure><p id="5c43" class="pw-post-body-paragraph lx ly iq lz b ma mt ka mc md mu kd mf mg mv mi mj mk mw mm mn mo mx mq mr ms ij bi translated">希望你喜欢。谢谢你阅读这篇文章！请务必检查上面共享的存储库，如果需要解释，请联系。要了解更多关于我的信息，请访问我的投资组合网站<a class="ae le" href="https://pr2tik1.github.io" rel="noopener ugc nofollow" target="_blank">这里。</a></p><p id="cf0c" class="pw-post-body-paragraph lx ly iq lz b ma mt ka mc md mu kd mf mg mv mi mj mk mw mm mn mo mx mq mr ms ij bi translated">总之，我们已经研究了CNN及其实现。此外，您可以探索胶囊网络和rnn。</p><p id="6747" class="pw-post-body-paragraph lx ly iq lz b ma mt ka mc md mu kd mf mg mv mi mj mk mw mm mn mo mx mq mr ms ij bi translated">你也可以关注我分享的博文，在那里我也研究了t-SNE和PCA对这些数据的表示。如果你对这篇文章有任何疑问，请随时联系我。</p><p id="9b81" class="pw-post-body-paragraph lx ly iq lz b ma mt ka mc md mu kd mf mg mv mi mj mk mw mm mn mo mx mq mr ms ij bi translated"><strong class="lz ja"> <em class="pg">谢谢！</em>T19】</strong></p></div><div class="ab cl pn po hu pp" role="separator"><span class="pq bw bk pr ps pt"/><span class="pq bw bk pr ps pt"/><span class="pq bw bk pr ps"/></div><div class="ij ik il im in"><h1 id="a672" class="lf lg iq bd lh li pu lk ll lm pv lo lp kf pw kg lr ki px kj lt kl py km lv lw bi translated">更多来自作者:</h1><div class="na nb gp gr nc nd"><a href="https://towardsdatascience.com/understanding-kaplan-meier-estimator-68258e26a3e4" rel="noopener follow" target="_blank"><div class="ne ab fo"><div class="nf ab ng cl cj nh"><h2 class="bd ja gy z fp ni fr fs nj fu fw iz bi translated">了解卡普兰-迈耶估计量</h2><div class="nk l"><h3 class="bd b gy z fp ni fr fs nj fu fw dk translated">一种生存分析技术的介绍。</h3></div><div class="nl l"><p class="bd b dl z fp ni fr fs nj fu fw dk translated">towardsdatascience.com</p></div></div><div class="nm l"><div class="pz l no np nq nm nr ky nd"/></div></div></a></div><div class="na nb gp gr nc nd"><a href="https://pr2tik1.medium.com/what-happens-to-programmers-in-2020-d04a6bd7452f" rel="noopener follow" target="_blank"><div class="ne ab fo"><div class="nf ab ng cl cj nh"><h2 class="bd ja gy z fp ni fr fs nj fu fw iz bi translated">开发者趋势</h2><div class="nk l"><h3 class="bd b gy z fp ni fr fs nj fu fw dk translated">根据调查数据分析开发人员和编程趋势。</h3></div><div class="nl l"><p class="bd b dl z fp ni fr fs nj fu fw dk translated">pr2tik1.medium.com</p></div></div><div class="nm l"><div class="qa l no np nq nm nr ky nd"/></div></div></a></div><div class="na nb gp gr nc nd"><a href="https://medium.com/towards-artificial-intelligence/neural-networks-from-scratch-a-brief-introduction-for-beginners-d3776599aaac" rel="noopener follow" target="_blank"><div class="ne ab fo"><div class="nf ab ng cl cj nh"><h2 class="bd ja gy z fp ni fr fs nj fu fw iz bi translated">探索神经网络(第一部分)</h2><div class="nk l"><h3 class="bd b gy z fp ni fr fs nj fu fw dk translated">理解深度学习的概念以及使用Python和它的神经网络的实现…</h3></div><div class="nl l"><p class="bd b dl z fp ni fr fs nj fu fw dk translated">medium.com</p></div></div><div class="nm l"><div class="qb l no np nq nm nr ky nd"/></div></div></a></div><div class="na nb gp gr nc nd"><a href="https://towardsdatascience.com/explore-new-github-readme-feature-7d5cc21bf02f" rel="noopener follow" target="_blank"><div class="ne ab fo"><div class="nf ab ng cl cj nh"><h2 class="bd ja gy z fp ni fr fs nj fu fw iz bi translated">如何创建令人敬畏的Github个人资料-自述文件！</h2><div class="nk l"><h3 class="bd b gy z fp ni fr fs nj fu fw dk translated">探索展示你作为开发者或开源贡献者的“GitHub简历”的新方法。每一个开源…</h3></div><div class="nl l"><p class="bd b dl z fp ni fr fs nj fu fw dk translated">towardsdatascience.com</p></div></div><div class="nm l"><div class="qc l no np nq nm nr ky nd"/></div></div></a></div></div></div>    
</body>
</html>