# 不平衡数据及其平衡方法

> 原文：<https://pub.towardsai.net/imbalanced-data-and-how-to-balance-it-d7c85321d3cb?source=collection_archive---------8----------------------->

## 机器学习

![](img/aa51e28bc59a9a477e84258cb8f1c0c0.png)

图像由罗马卡夫在 Unsplash

最近，考虑到大部分时间都花在清理和预处理数据上，处理数据已经成为一项乏味的工作。现实世界中的数据通常不符合我们的预期。它有很多不规则性，处理这样的数据很有挑战性。处理这些数据的一个主要障碍是数据不平衡。值得注意的是，数据的结构是这样的，目标特征(特别是分类问题)在一个类中占大多数，而第二个类中几乎没有训练样本。第二，对于多类分类问题，在目标特征中，某一类的训练样本比其他类的样本在很大程度上超出。这妨碍了模型的性能。下面列出了一些方法，可以避免这种问题，并确保您的模型能够有效地处理您的数据。

1.  欠采样
2.  过采样
3.  设置模型的权重超参数。
4.  将训练测试分割设置为分层属性。

## 欠采样

欠采样指的是从属于目标特征类别的数据中移除训练样本，该目标特征类别在其他类别中占多数。然而，这种方法有它的优点和缺点。优点:您可以加快模型的训练速度，因为模型需要训练的样本相对较少，数据集也同样均衡。缺点是，随着训练样本数量的减少，模型(高效模型)将无法对未知数据进行很好的概括，有时可能会导致过度拟合。正如所言，模型看到的数据越多，它对未知数据的预测就越准确。

## 过采样

![](img/8159652eee7b47ed72226b1e3b466290.png)

作者图片

过采样是一种技术，其中少数类的训练样本的数量增加，以便平衡多数类和少数类的样本数量。这只适用于只有两个类的二元分类问题。在多类分类的情况下，增加少数类的样本数。用于过采样的关键技术之一称为 SMOTE(合成少数过采样技术)。

在该方法中，从少数类中选择随机训练样本，并使用 K-最近邻，将最接近所选样本(通常 k=5)的训练样本考虑在内。从这些选择的样本中，选择一个随机样本。考虑到这个样本和属于少数类的样本，使用 SMOTE 方法生成合成训练样本。通过应用过采样，您的模型可能能够很好地对新数据进行归纳。要考虑的一个缺点是，具有大量训练样本的数据集不是过采样的好选择。这是因为大量的样本减缓了手头模型的训练过程。

## 设置模型的“权重”超参数。

一般来说，如果你考虑一个像随机森林分类器这样的初级机器学习模型，你可以微调一个称为`sample_weight`的超参数。例如，在二元分类问题中，如果目标类别 1 超过目标类别 0 的 3 倍，那么您可以将这个超参数设置为`sample_weight=[np.array[3 if i==0 else 1 if i==1]`。类似地，对于 Catboost 分类器，我们有`class_weights`超参数，它可以根据我们的类分布来设置。在这个方法中，你需要确定每个类的比例。例如，如果类 0 贡献了 70%的训练样本，剩余的 30%属于类 1，那么您可以设置类似`class_weights=[0.3,0.7]`的参数。由此，我们推断，由于类 0 具有 70 %的训练样本，因此我们将值 0.3 赋给它，以使比率相等，从而使数据平衡。第 1 类样品的情况也是如此。

## 设置 train_test_split 分层属性。

![](img/167bd83b1ea94e19c1d5bc81eb9fbefb.png)

图片由 Alexandre Van Thuan 在 Unsplash 上提供

在这里，让我们来看看一个直接而简单的方法，通过它来平衡数据是尽可能简单的。在将数据集拆分为定型集和测试集的过程中，可以指定函数的“分层”属性，以平衡不平衡的数据集。使用此属性，train_test_split 以这样一种方式拆分原始数据集，即在定型集和验证集中保留两个类(二元分类)的比例。例如，如果您以 80:20 的比例分发原始数据，`train_test_split(X,y,test_size=0.2,stratify=y)`它将在训练集和测试集中保持 80:20 的比例。这是一个简单的方法；然而，您可以使用任何方法，这反过来有助于模型的整体性能。

## 参考

Scikit 学习官方文档。作者图片。图片来自 Unsplash。

## 结论

现实世界的数据通常是非结构化的和不平衡的。因此，处理数据不平衡是数据预处理过程中应该考虑的主要问题之一。我希望已经提供了关于不平衡数据集处理的有价值的信息。最后，最近一个处理不平衡的方法是 Andreas Mueller 的[集合重采样方法](https://amueller.github.io/ml-training-advanced/slides/04-imbalanced-data.html#15)。请随意查看这些和上面的数据处理方法。