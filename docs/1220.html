<html>
<head>
<title>Big-Data Pipelines with SparkML</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">使用SparkML的大数据管道</h1>
<blockquote>原文：<a href="https://pub.towardsai.net/big-data-pipelines-with-sparkml-8207c86fc995?source=collection_archive---------2-----------------------#2020-12-06">https://pub.towardsai.net/big-data-pipelines-with-sparkml-8207c86fc995?source=collection_archive---------2-----------------------#2020-12-06</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><h2 id="4626" class="io ip iq bd b dl ir is it iu iv iw dk ix translated" aria-label="kicker paragraph"><a class="ae ep" href="https://towardsai.net/p/category/data-analysis" rel="noopener ugc nofollow" target="_blank">数据分析</a>、<a class="ae ep" href="https://towardsai.net/p/category/data-science" rel="noopener ugc nofollow" target="_blank">数据科学</a>、<a class="ae ep" href="https://towardsai.net/p/category/machine-learning" rel="noopener ugc nofollow" target="_blank">机器学习</a></h2><div class=""/><div class=""><h2 id="debd" class="pw-subtitle-paragraph jw iz iq bd b jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn dk translated">为大数据分析创建Apache Spark ML管道</h2></div><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div role="button" tabindex="0" class="ku kv di kw bf kx"><div class="gh gi ko"><img src="../Images/b398aad92b2f0c38210a486178ed39d0.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*g3Yv_GuiGq99-nkdLWyZRA.jpeg"/></div></div><figcaption class="la lb gj gh gi lc ld bd b be z dk translated">照片由<a class="ae le" href="https://unsplash.com/@frostroomhead?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText" rel="noopener ugc nofollow" target="_blank"> Rodion Kutsaev </a>在<a class="ae le" href="https://unsplash.com/s/photos/pipelines?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上拍摄</figcaption></figure><p id="e0b4" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated"><strong class="lh ja">管道</strong>是一种保持数据预处理和建模代码有组织的简单方法。具体来说，管道捆绑了预处理和建模步骤，因此您可以像使用单个步骤一样使用整个捆绑包。</p><blockquote class="mb"><p id="b1c3" class="mc md iq bd me mf mg mh mi mj mk ma dk translated">许多数据科学家在没有管道的情况下拼凑模型… ( <a class="ae le" href="https://www.kaggle.com/alexisbcook/pipelines" rel="noopener ugc nofollow" target="_blank"> Kaggle </a>)</p></blockquote><p id="cd5a" class="pw-post-body-paragraph lf lg iq lh b li ml ka lk ll mm kd ln lo mn lq lr ls mo lu lv lw mp ly lz ma ij bi translated">Kaggle还说管道有一些重要的好处，例如:</p><ol class=""><li id="e08e" class="mq mr iq lh b li lj ll lm lo ms ls mt lw mu ma mv mw mx my bi translated"><strong class="lh ja">更清晰的代码:</strong>在预处理的每一步对数据进行统计都会变得混乱。有了管道，您就不需要手动跟踪每一步的培训和验证数据。</li><li id="436a" class="mq mr iq lh b li mz ll na lo nb ls nc lw nd ma mv mw mx my bi translated"><strong class="lh ja">更少的错误:</strong>错误应用某个步骤或忘记某个预处理步骤的机会更少。</li><li id="ac6c" class="mq mr iq lh b li mz ll na lo nb ls nc lw nd ma mv mw mx my bi translated">更容易生产:将一个模型从原型转变成可大规模部署的东西可能会出人意料地困难，但管道可以提供帮助。</li><li id="7717" class="mq mr iq lh b li mz ll na lo nb ls nc lw nd ma mv mw mx my bi translated"><strong class="lh ja">模型验证的更多选项:</strong>我们可以轻松地将交叉验证和其他技术应用到我们的管道中。</li></ol><p id="1ce1" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">因此，流水线是设计我们的数据预处理和机器学习流程的便利过程。在真正的ML开始之前，我们必须完成某些步骤。这些步骤被称为<em class="ne">数据预处理</em>和/或<em class="ne">特征工程。</em></p><h2 id="4912" class="nf ng iq bd nh ni nj dn nk nl nm dp nn lo no np nq ls nr ns nt lw nu nv nw iw bi translated">一些流水线步骤包括:</h2><ul class=""><li id="e34a" class="mq mr iq lh b li nx ll ny lo nz ls oa lw ob ma oc mw mx my bi translated">将分类值转换为名义值和数值</li><li id="9635" class="mq mr iq lh b li mz ll na lo nb ls nc lw nd ma oc mw mx my bi translated">标准化每个维度的值的范围</li><li id="bb7f" class="mq mr iq lh b li mz ll na lo nb ls nc lw nd ma oc mw mx my bi translated">一次性编码分类值和…</li><li id="c8d1" class="mq mr iq lh b li mz ll na lo nb ls nc lw nd ma oc mw mx my bi translated">建模…我们在那里训练我们的ML算法。</li></ul><p id="664a" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">管道的总体思想是，我们可以将完整的数据处理流程融合到一个单独的管道中，并且可以在下游进一步使用这个单独的管道。</p><h2 id="4f9d" class="nf ng iq bd nh ni nj dn nk nl nm dp nn lo no np nq ls nr ns nt lw nu nv nw iw bi translated">一些管道方法:</h2><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div role="button" tabindex="0" class="ku kv di kw bf kx"><div class="gh gi od"><img src="../Images/34cec4810e221ee7e7aefc2f18e6f740.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*o8aYIkVtqQixX0D6Wj8Lug.jpeg"/></div></div><figcaption class="la lb gj gh gi lc ld bd b be z dk translated">图片来自IBM <a class="ae le" href="https://www.coursera.org/learn/machine-learning-big-data-apache-spark/home/welcome" rel="noopener ugc nofollow" target="_blank">使用apache-spark的大数据可扩展机器学习</a></figcaption></figure><p id="7efa" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">流水线作为机器学习算法有以下方法…</p><ul class=""><li id="6a43" class="mq mr iq lh b li lj ll lm lo ms ls mt lw mu ma oc mw mx my bi translated"><strong class="lh ja">飞度</strong>:飞度基本开始训练</li><li id="589f" class="mq mr iq lh b li mz ll na lo nb ls nc lw nd ma oc mw mx my bi translated"><strong class="lh ja">评分</strong>:评分反馈预测值。</li><li id="6c56" class="mq mr iq lh b li mz ll na lo nb ls nc lw nd ma oc mw mx my bi translated"><strong class="lh ja">评估</strong>:评估验证数据的模型性能。</li></ul><p id="4167" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">管道的一个额外优势是我们可以<em class="ne">交叉验证</em>，也就是说，使用完全相同的管道尝试很多很多的参数。而这确实加速了算法的优化。</p><p id="32c2" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">因此，总而言之，管道正在促进我们在机器学习方面的日常工作，因为我们可以从预定义的数据处理步骤中提取数据，我们确保一切都是一致的，我们可以根据需要切换和交换我们的算法。</p><blockquote class="oe of og"><p id="645c" class="lf lg ne lh b li lj ka lk ll lm kd ln oh lp lq lr oi lt lu lv oj lx ly lz ma ij bi translated">虽然有大量的材料涵盖了机器学习的管道，但今天我们将使用<strong class="lh ja"><em class="iq">Apache SparkML</em></strong>来关注大数据上的机器学习管道。</p></blockquote><h1 id="a4ee" class="ok ng iq bd nh ol om on nk oo op oq nn kf or kg nq ki os kj nt kl ot km nw ou bi translated">1.简介:</h1><p id="0a6e" class="pw-post-body-paragraph lf lg iq lh b li nx ka lk ll ny kd ln lo ov lq lr ls ow lu lv lw ox ly lz ma ij bi translated">在这个练习中，我们将使用<a class="ae le" href="https://github.com/wchill/HMP_Dataset.git" rel="noopener ugc nofollow" target="_blank"> <strong class="lh ja"> HMP </strong>数据集</a>。它基本上是附着在人体上的加速度计传感器的加速度计记录。这些数据记录了人类进行活动时的传感器，如刷牙、梳头、T21、喝汤、等等。</p><p id="d58d" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">因此，我们应该为机器学习任务预处理这个数据集。首先，手动，然后我们将建立一个SparkML管道，为我们自动预处理数据集。这个管道可以应用于未来的数据集。</p><p id="593e" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">我使用Colab进行数据探索。如果你需要帮助在Colab中启动Pyspark，请看这个<a class="ae le" href="https://colab.research.google.com/github/Lawrence-Krukrubo/Advanced-Data-Science/blob/master/Spark_on_Colaboratory.ipynb" rel="noopener ugc nofollow" target="_blank"> <em class="ne">链接</em> </a>。</p><p id="830a" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">所以首先，我们在Colab建立了Pyspark</p><figure class="kp kq kr ks gt kt"><div class="bz fp l di"><div class="oy oz l"/></div></figure><h1 id="c743" class="ok ng iq bd nh ol om on nk oo op oq nn kf or kg nq ki os kj nt kl ot km nw ou bi translated">2.数据析取</h1><p id="0121" class="pw-post-body-paragraph lf lg iq lh b li nx ka lk ll ny kd ln lo ov lq lr ls ow lu lv lw ox ly lz ma ij bi translated">请注意，数据采用的是拼花文件格式。Parquet使用压缩和列存储，将数据布局映射到Apache Spark钨内存布局。</p><figure class="kp kq kr ks gt kt"><div class="bz fp l di"><div class="oy oz l"/></div></figure><p id="fc8e" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">因此，我们可以看到在这个HMP数据集中有不同的文件夹。代表不同活动的文件夹，如<em class="ne">刷牙</em>、<em class="ne">喝水</em>、<em class="ne">起床睡觉</em>、<em class="ne">倒水</em>、<em class="ne">使用电话</em>。</p><p id="3598" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">例如，查看<em class="ne">Brush _ tooths</em>文件夹中的文本文件，我们可以看到用三个数字列表示的加速度计数据，我们可以称之为<em class="ne"> X、Y、Z </em>。</p><pre class="kp kq kr ks gt pa pb pc pd aw pe bi"><span id="bc14" class="nf ng iq pb b gy pf pg l ph pi"><strong class="pb ja">!head HMP_Dataset/Brush_teeth/Accelerometer-2011-04-11-13-28-18-brush_teeth-f1.txt</strong></span><span id="1f3a" class="nf ng iq pb b gy pj pg l ph pi">&gt;&gt;<br/><strong class="pb ja">22 49 35 <br/>22 49 35 <br/>22 52 35 <br/>22 52 35 <br/>21 52 34</strong></span></pre><p id="b928" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">让我们递归遍历HMP数据集中的这些文件夹，并从这些文本文件创建一个Apache spark数据帧。然后，我们将所有数据帧&lt;<em class="ne"> df.union(df2) &gt; </em>合并成一个包含所有数据的整体数据帧。</p><p id="0420" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">首先，让我们定义下面的数据框的模式。</p><figure class="kp kq kr ks gt kt"><div class="bz fp l di"><div class="oy oz l"/></div><figcaption class="la lb gj gh gi lc ld bd b be z dk translated"><em class="pk">struct type构造函数定义Spark数据帧的模式，指定StructField和DataType。</em></figcaption></figure><p id="1459" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">现在让我们使用操作系统库遍历数据。</p><figure class="kp kq kr ks gt kt"><div class="bz fp l di"><div class="oy oz l"/></div></figure><p id="bbed" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">让我们从文件列表中删除非活动文件夹。这些文件夹通常名称中没有下划线。</p><figure class="kp kq kr ks gt kt"><div class="bz fp l di"><div class="oy oz l"/></div></figure><p id="e532" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">好的，我们将所有包含数据的文件夹放在一个数组中。现在我们可以迭代这个数组。</p><figure class="kp kq kr ks gt kt"><div class="bz fp l di"><div class="oy oz l"/></div></figure><p id="6f08" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">因此，根据上面的要点，首先，我们定义一个空的数据帧，并为进度条导入<a class="ae le" href="https://github.com/tqdm/tqdm" rel="noopener ugc nofollow" target="_blank"> tqdm </a>。接下来，我们导入lit库，它帮助我们将字符串列写入Apache Spark数据帧。</p><p id="1985" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">此时，我们所做的就是使用操作系统库遍历每个文件，将三个数字列添加到我们之前定义的<em class="ne"> X，Y，Z </em>模式中，将它们添加到DataFrame中，并添加两个字符串列，一个用于加速度计读数的类别，另一个用于读数的源文件。</p><p id="7271" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">让我们看看数据框架的模式…</p><pre class="kp kq kr ks gt pa pb pc pd aw pe bi"><span id="709a" class="nf ng iq pb b gy pf pg l ph pi"><strong class="pb ja">df.printSchema()</strong></span><span id="8026" class="nf ng iq pb b gy pj pg l ph pi">&gt;&gt;<br/><strong class="pb ja">root  <br/>|-- x: integer (nullable = true)  <br/>|-- y: integer (nullable = true)  <br/>|-- z: integer (nullable = true)  <br/>|-- class: string (nullable = false)  <br/>|-- source: string (nullable = false)</strong></span></pre><p id="2348" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">让我们看看数据帧的前10行。这需要一点时间来运行，因为正如我们所知，Apache Spark中的数据帧总是很懒…</p><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div class="gh gi pl"><img src="../Images/a3771d00df547566263fef8fee77e2a9.png" data-original-src="https://miro.medium.com/v2/resize:fit:1130/format:webp/1*3HW4syZhQfpFdZXV_k-7mg.jpeg"/></div></figure><h1 id="3820" class="ok ng iq bd nh ol om on nk oo op oq nn kf or kg nq ki os kj nt kl ot km nw ou bi translated">3.数据转换</h1><p id="ae65" class="pw-post-body-paragraph lf lg iq lh b li nx ka lk ll ny kd ln lo ov lq lr ls ow lu lv lw ox ly lz ma ij bi translated">现在我们需要转换数据并创建类列的整数表示，因为ML算法不能处理字符串。因此，我们将使用<em class="ne"> StringIndexer </em>模块将该类转换成多个整数。</p><figure class="kp kq kr ks gt kt"><div class="bz fp l di"><div class="oy oz l"/></div></figure><p id="33e9" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated"><em class="ne"> StringIndexer </em>是一个同时具有拟合和变换方法的估计器。所以我们创建一个<em class="ne"> StringIndexer </em>对象(<em class="ne">索引器</em>)，将“<em class="ne"> class </em>列作为<em class="ne"> inputCol </em>传递，将“<em class="ne"> classIndex </em>作为<em class="ne"> outputCol </em>。然后，我们将数据帧适配到<em class="ne">索引器</em>，并转换数据帧。这创建了一个全新的DataFrame ( <strong class="lh ja"> <em class="ne">索引</em> </strong>)，我们可以在上面看到，它包含了<em class="ne"> classIndex </em>附加列。</p><h1 id="4d33" class="ok ng iq bd nh ol om on nk oo op oq nn kf or kg nq ki os kj nt kl ot km nw ou bi translated">4.一键编码:</h1><p id="867b" class="pw-post-body-paragraph lf lg iq lh b li nx ka lk ll ny kd ln lo ov lq lr ls ow lu lv lw ox ly lz ma ij bi translated">有了类索引列，我们现在可以在Pyspark中进行<a class="ae le" href="https://www.kaggle.com/dansbecker/using-categorical-data-with-one-hot-encoding" rel="noopener ugc nofollow" target="_blank"> <strong class="lh ja">一次热编码</strong></a>…</p><figure class="kp kq kr ks gt kt"><div class="bz fp l di"><div class="oy oz l"/></div></figure><p id="099b" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">与<em class="ne"> StringIndexer </em>不同，<em class="ne"> OneHotEncoder </em>是一个纯粹的transformer，只有transform方法。它使用了与我们在StringIndexer中看到的'<em class="ne"> inputCol </em>和'<em class="ne"> outputCol </em>相同的语法。我们分别传递'<em class="ne"> classIndex </em>'和'<em class="ne"> categoryVec </em>'值。<em class="ne"> OneHotEncoder </em>还创建了一个全新的DataFrame ( <strong class="lh ja"> <em class="ne">编码</em> </strong>)，将<em class="ne">'</em><strong class="lh ja"><em class="ne">category _ vec</em></strong>列添加到之前的DataFrame( <em class="ne">索引</em>)。</p><blockquote class="oe of og"><p id="7d39" class="lf lg ne lh b li lj ka lk ll lm kd ln oh lp lq lr oi lt lu lv oj lx ly lz ma ij bi translated">还有一点需要注意的是，在上面的Git gist中调用<strong class="lh ja"> encoded.show(10，False) </strong>，保证显示10行，<strong class="lh ja"> False </strong>保证每个列元素都是完全展开的，cos正常情况下SparkML压缩列单元格。</p></blockquote><p id="1a0f" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">最后，众所周知，SparkML中的<em class="ne"> OneHotEncoder </em>不会返回几个只包含0和1的列...相反，它返回一个稀疏向量，如<em class="ne"> categoryVec </em>列所示。因此，对于上面的'<em class="ne"> Drink_glass </em>'类，SparkML返回一个稀疏向量，基本上表示有13个元素，在位置2，类值存在(1.0)。</p><h1 id="c632" class="ok ng iq bd nh ol om on nk oo op oq nn kf or kg nq ki os kj nt kl ot km nw ou bi translated">5.向量汇编器:</h1><p id="f44d" class="pw-post-body-paragraph lf lg iq lh b li nx ka lk ll ny kd ln lo ov lq lr ls ow lu lv lw ox ly lz ma ij bi translated">我们需要做的下一件事是将数字列X，Y，Z转换成向量，因为sparkML只能处理向量对象。所以让我们导入<em class="ne">向量</em>和<em class="ne">向量汇编器</em>库</p><figure class="kp kq kr ks gt kt"><div class="bz fp l di"><div class="oy oz l"/></div></figure><p id="53ad" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">使用我们在<em class="ne"> StringIndexer </em>和<em class="ne"> OneHotEncoder </em>中使用的相同语法来初始化<em class="ne"> VectorAssembler </em>对象。我们将列表<strong class="lh ja"> ['x '，' y '，' z'] </strong>传递给<em class="ne"> inputCols，</em>并指定<em class="ne"> outputCol = 'features '。</em>这也是和<em class="ne"> OneHotEncoder </em>一样的纯变压器。因此，我们将上一步的数据帧(<em class="ne">编码</em>)转换为新的数据帧<em class="ne"> ( </em> <strong class="lh ja"> <em class="ne">特征_矢量化</em> </strong> <em class="ne"> ) </em>，并添加了<em class="ne">特征</em>列。</p><blockquote class="mb"><p id="bca4" class="mc md iq bd me mf mg mh mi mj mk ma dk translated">SparkML语法的一致性令人印象深刻，它缩短了大数据爱好者的学习曲线…</p></blockquote><h1 id="6306" class="ok ng iq bd nh ol om on nk oo op oq nn kf pm kg nq ki pn kj nt kl po km nw ou bi translated">5.标准化数据集:</h1><p id="6971" class="pw-post-body-paragraph lf lg iq lh b li nx ka lk ll ny kd ln lo ov lq lr ls ow lu lv lw ox ly lz ma ij bi translated">因此，下一步是标准化数据集。这使得数据集中所有数值列的值范围介于0和1之间或-1和1之间。这个想法是让所有的特征数据都在同一范围内，这样就不会互相影响。</p><figure class="kp kq kr ks gt kt"><div class="bz fp l di"><div class="oy oz l"/></div></figure><p id="5680" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">我们现在肯定已经习惯了，<em class="ne"> StringIndexer </em>，<em class="ne"> OneHotEncoder </em>，<em class="ne"> VectorAssembler，</em>和<em class="ne">规格化器</em>都有一致的语法。再看<em class="ne">规格化器</em>对象，它包含参数<a class="ae le" href="https://spark.apache.org/docs/1.4.1/ml-features.html" rel="noopener ugc nofollow" target="_blank"><strong class="lh ja"><em class="ne">p = 1.0</em></strong></a>。注意Pyspark <em class="ne">规格化器</em>的缺省范数值是<a class="ae le" href="https://spark.apache.org/docs/1.4.1/ml-features.html" rel="noopener ugc nofollow" target="_blank"><strong class="lh ja"><em class="ne">p = 2.0</em></strong></a>。</p><blockquote class="oe of og"><p id="7988" class="lf lg ne lh b li lj ka lk ll lm kd ln oh lp lq lr oi lt lu lv oj lx ly lz ma ij bi translated"><strong class="lh ja"> p=1.0 </strong>表示基于<a class="ae le" href="https://www.sciencedirect.com/topics/mathematics/manhattan-distance#:~:text=The%20Manhattan%20distance%20between%20two,the%20%E2%80%9Ctaxi%20cab%E2%80%9D%20metric." rel="noopener ugc nofollow" target="_blank"> <strong class="lh ja">曼哈顿距离</strong> </a>对特征进行归一化。两点之间的曼哈顿距离或<strong class="lh ja"> taxi-cab </strong>距离是这两点在特征向量中对应坐标的绝对差之和。因此，这些特征基于该度量被标准化。</p></blockquote><p id="815a" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">当……</p><blockquote class="oe of og"><p id="95d8" class="lf lg ne lh b li lj ka lk ll lm kd ln oh lp lq lr oi lt lu lv oj lx ly lz ma ij bi translated"><strong class="lh ja"> p=2.0 </strong>表示基于<a class="ae le" href="https://en.wikipedia.org/wiki/Euclidean_distance" rel="noopener ugc nofollow" target="_blank"> <strong class="lh ja">欧氏距离</strong> </a>对特征进行归一化。两点之间的欧几里得距离与计算连接这两点的向量的大小完全相同。</p></blockquote><p id="03c7" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">注意，这些是聚类算法使用的相同方法，例如<em class="ne"> KNN </em>和<em class="ne"> K-means，</em>。</p><blockquote class="mb"><p id="4dce" class="mc md iq bd me mf mg mh mi mj mk ma dk translated"><strong class="ak">这是中级线性代数的基础，我对初露头角的数据科学家的建议是……不要追逐你听说过的每一个花哨、闪亮的算法，而是花时间为数据科学建立一个坚实的基础，基于线性代数、统计学、概率和微积分……</strong></p></blockquote><h1 id="9314" class="ok ng iq bd nh ol om on nk oo op oq nn kf pm kg nq ki pn kj nt kl po km nw ou bi translated">6.创建管道:</h1><p id="59a2" class="pw-post-body-paragraph lf lg iq lh b li nx ka lk ll ny kd ln lo ov lq lr ls ow lu lv lw ox ly lz ma ij bi translated">下面的管道构造函数接受我们传递给它的管道阶段数组。在这里，我们按照正确的顺序，一个接一个地通过了上面的4个阶段。</p><figure class="kp kq kr ks gt kt"><div class="bz fp l di"><div class="oy oz l"/></div></figure><blockquote class="mb"><p id="b0a2" class="mc md iq bd me mf pp pq pr ps pt ma dk translated">就是这样！在Apache SparkML中创建管道就像直尺一样简单…</p></blockquote><p id="3acd" class="pw-post-body-paragraph lf lg iq lh b li ml ka lk ll mm kd ln lo mn lq lr ls mo lu lv lw mp ly lz ma ij bi translated">我们定义步骤或阶段，并按逻辑顺序将它们传递给管道构造器。</p><p id="a01d" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">现在，让我们将管道对象与原始数据框相匹配…</p><pre class="kp kq kr ks gt pa pb pc pd aw pe bi"><span id="78a8" class="nf ng iq pb b gy pf pg l ph pi"><strong class="pb ja">data_model = pipeline.fit(df)</strong></span></pre><p id="95c3" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">最后，让我们使用Pipeline对象来转换我们的数据框架。</p><pre class="kp kq kr ks gt pa pb pc pd aw pe bi"><span id="649b" class="nf ng iq pb b gy pf pg l ph pi"><strong class="pb ja">pipelined_data = data_model.transform(df)</strong></span></pre><p id="d264" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">让我们看看前十排…</p><figure class="kp kq kr ks gt kt"><div class="bz fp l di"><div class="oy oz l"/></div></figure><p id="bde3" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">因此，我们可以看到，已经使用管道功能创建了与之前从各个阶段创建的数据帧完全相同的数据帧。现在，我们可以一次性适应和转换我们的数据。这是一个非常方便的功能。</p><p id="2773" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">因此，在这一点上，我们只需删除我们不需要的其他列…</p><figure class="kp kq kr ks gt kt"><div class="bz fp l di"><div class="oy oz l"/></div></figure><p id="1bab" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">我们使用列表理解来选择我们需要的列(<em class="ne"> categoryVec </em>和<em class="ne"> features_norm </em>)，并简单地用这些列创建一个新的数据框架。</p><p id="cd0c" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">最后，我们有我们的<em class="ne"> categoryVec </em>列，这是目标变量，还有我们的<em class="ne"> features_norm </em>列，这是我们一直准备训练的机器学习算法的特征集...</p><h1 id="2182" class="ok ng iq bd nh ol om on nk oo op oq nn kf or kg nq ki os kj nt kl ot km nw ou bi translated">总结…</h1><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div role="button" tabindex="0" class="ku kv di kw bf kx"><div class="gh gi pu"><img src="../Images/777830991796f40ca58f52f8405144b1.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*yct5nV6uR322v0i9jWmqhg.jpeg"/></div></div><figcaption class="la lb gj gh gi lc ld bd b be z dk translated">照片由<a class="ae le" href="https://unsplash.com/@lucabravo?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText" rel="noopener ugc nofollow" target="_blank">卢卡·布拉沃</a>在<a class="ae le" href="https://unsplash.com/s/photos/data-pipelines?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上拍摄</figcaption></figure><p id="bfcc" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">我们已经看到了如何从数据集创建Apache spark ML管道。走出去，使用这些知识来构建更强大的数据和机器学习解决方案。</p><p id="e473" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">完整的笔记本可以在Github 上找到<a class="ae le" href="https://github.com/Lawrence-Krukrubo/Advanced-Data-Science/blob/master/spark_ml_pipelines.ipynb" rel="noopener ugc nofollow" target="_blank">。</a></p><p id="167b" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated"><em class="ne">Coursera的IBM高级数据科学团队功不可没……</em></p><p id="3267" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated"><strong class="lh ja">干杯！！</strong></p><h1 id="5b00" class="ok ng iq bd nh ol om on nk oo op oq nn kf or kg nq ki os kj nt kl ot km nw ou bi translated">关于我:</h1><p id="3ef8" class="pw-post-body-paragraph lf lg iq lh b li nx ka lk ll ny kd ln lo ov lq lr ls ow lu lv lw ox ly lz ma ij bi translated">劳伦斯是技术层的数据专家，对公平和可解释的人工智能和数据科学充满热情。我相信分享知识和经验是最好的学习方式。我同时持有IBM的 <strong class="lh ja"> <em class="ne">数据科学专业</em> </strong> <em class="ne">和</em> <strong class="lh ja"> <em class="ne">高级数据科学专业</em> </strong> <em class="ne">证书和来自Udacity的</em><strong class="lh ja"><em class="ne">IBM</em></strong><em class="ne"/><strong class="lh ja"><em class="ne">数据科学讲解徽章、</em> </strong> <em class="ne">以及</em> <strong class="lh ja"> <em class="ne">人工智能纳米学位<strong class="lh ja">我已经使用ML和DL库进行了几个项目。我喜欢尽可能多地编写我的函数。最后，我从未停止学习和探索，是的，我写过几篇强烈推荐的文章。</strong></em></strong></p><p id="a594" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">请随时在以下网址找到我</p><p id="3003" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated"><a class="ae le" href="https://github.com/Lawrence-Krukrubo" rel="noopener ugc nofollow" target="_blank">T51】GithubT53】</a></p><p id="6496" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated"><a class="ae le" href="https://www.linkedin.com/in/lawrencekrukrubo/" rel="noopener ugc nofollow" target="_blank"> <strong class="lh ja">领英</strong> </a></p><p id="68e2" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated"><a class="ae le" href="https://twitter.com/LKrukrubo" rel="noopener ugc nofollow" target="_blank"> <strong class="lh ja">推特</strong> </a></p></div></div>    
</body>
</html>