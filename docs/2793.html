<html>
<head>
<title>How To Visually Inspect The Quality Of Your Chatbot’s NLU Model</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">如何目测检查你的聊天机器人的NLU模型的质量</h1>
<blockquote>原文：<a href="https://pub.towardsai.net/how-to-visually-inspect-the-quality-of-your-chatbots-nlu-model-cecc52a2b23b?source=collection_archive---------0-----------------------#2022-05-28">https://pub.towardsai.net/how-to-visually-inspect-the-quality-of-your-chatbots-nlu-model-cecc52a2b23b?source=collection_archive---------0-----------------------#2022-05-28</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="a37e" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">使用PCA和交互式图表</h2></div><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ki"><img src="../Images/3e9e980b51f155a589e84327e816782d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*qLTKYGAepA-u3w1f4zuRLw.png"/></div></div></figure><h1 id="9640" class="ku kv it bd kw kx ky kz la lb lc ld le jz lf ka lg kc lh kd li kf lj kg lk ll bi translated">介绍</h1><p id="bf42" class="pw-post-body-paragraph lm ln it lo b lp lq ju lr ls lt jx lu lv lw lx ly lz ma mb mc md me mf mg mh im bi translated">在本文中，我将分享一个视觉评估聊天机器人NLU模型质量的想法。目标是帮助bot开发团队中没有ML背景的人参与改进模型的性能。</p><p id="d836" class="pw-post-body-paragraph lm ln it lo b lp mi ju lr ls mj jx lu lv mk lx ly lz ml mb mc md mm mf mg mh im bi translated">重现结果的代码在<a class="ae mn" href="https://github.com/hsm207/rasa-viz-diet" rel="noopener ugc nofollow" target="_blank">这个回购</a>中。</p><p id="0f2c" class="pw-post-body-paragraph lm ln it lo b lp mi ju lr ls mj jx lu lv mk lx ly lz ml mb mc md mm mf mg mh im bi translated">我们将使用<a class="ae mn" href="https://rasa.com/docs/" rel="noopener ugc nofollow" target="_blank"> rasa </a>(以及它的默认机器人“moodbot”)来演示这个想法，但它确实适用于任何使用机器学习进行意图分类的聊天机器人平台，只要它们允许你查看引擎盖下的内容。</p><h1 id="e6a4" class="ku kv it bd kw kx ky kz la lb lc ld le jz lf ka lg kc lh kd li kf lj kg lk ll bi translated">这个想法</h1><p id="fdc7" class="pw-post-body-paragraph lm ln it lo b lp lq ju lr ls lt jx lu lv lw lx ly lz ma mb mc md me mf mg mh im bi translated">rasa中的默认意图分类器是<a class="ae mn" href="https://arxiv.org/pdf/2004.09936.pdf" rel="noopener ugc nofollow" target="_blank">饮食分类器</a>。它获取一段文本，将其转换为密集向量(默认:256维)，并使用该向量表示将文本分类到给定的意图标签之一。</p><p id="4223" class="pw-post-body-paragraph lm ln it lo b lp mi ju lr ls mj jx lu lv mk lx ly lz ml mb mc md mm mf mg mh im bi translated">我们可以采用训练集的矢量表示，并将其投影到2D空间，以将其可视化为散点图。这些点可以用不同的颜色来表示它们的意图标签。</p><p id="3527" class="pw-post-body-paragraph lm ln it lo b lp mi ju lr ls mj jx lu lv mk lx ly lz ml mb mc md mm mf mg mh im bi translated">如果散点图是一个交互式图表，那么我们可以轻松地在2D特征空间中移动(平移、放大/缩小),感受一下模型“看到”了什么。一般来说，如果有n个意图标签，那么我们会期望n个不同的集群。与这一期望的偏差可能表明标签错误或措辞不当(例如含糊不清)的例子。</p><h1 id="2002" class="ku kv it bd kw kx ky kz la lb lc ld le jz lf ka lg kc lh kd li kf lj kg lk ll bi translated">方法</h1><h2 id="fb2a" class="mo kv it bd kw mp mq dn la mr ms dp le lv mt mu lg lz mv mw li md mx my lk mz bi translated">提取矢量表示</h2><p id="98ae" class="pw-post-body-paragraph lm ln it lo b lp lq ju lr ls lt jx lu lv lw lx ly lz ma mb mc md me mf mg mh im bi translated">下图显示了构成饮食分类器的组件:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi na"><img src="../Images/6d6a1c32cb2e6cbc3d411f84326144ba.png" data-original-src="https://miro.medium.com/v2/resize:fit:1208/format:webp/1*n5dKo50ZG5lxnV2KIVTcvg.png"/></div><figcaption class="nb nc gj gh gi nd ne bd b be z dk translated">图1:来自https://arxiv.org/pdf/2004.09936.pdf的饮食结构示意图</figcaption></figure><p id="b73f" class="pw-post-body-paragraph lm ln it lo b lp mi ju lr ls mj jx lu lv mk lx ly lz ml mb mc md mm mf mg mh im bi translated">我们感兴趣的是在_CLS_令牌通过变换器层之后得到它的矢量表示。这很容易通过解析在<a class="ae mn" href="https://github.com/RasaHQ/rasa/blob/0698b83662a638b2543c5a5bee12dc38c618dc12/CHANGELOG.mdx#230---2021-02-11" rel="noopener ugc nofollow" target="_blank">版本2.3.0 </a>中引入的消息对象的<code class="fe nf ng nh ni b">diagnostic_data</code>字段来完成。</p><h2 id="2a49" class="mo kv it bd kw mp mq dn la mr ms dp le lv mt mu lg lz mv mw li md mx my lk mz bi translated">投影到2D空间</h2><p id="17a2" class="pw-post-body-paragraph lm ln it lo b lp lq ju lr ls lt jx lu lv lw lx ly lz ma mb mc md me mf mg mh im bi translated">有许多方法可以将高维向量投影到低维向量中。</p><p id="feaa" class="pw-post-body-paragraph lm ln it lo b lp mi ju lr ls mj jx lu lv mk lx ly lz ml mb mc md mm mf mg mh im bi translated">我们就用<a class="ae mn" href="https://scikit-learn.org/stable/modules/generated/sklearn.decomposition.PCA.html" rel="noopener ugc nofollow" target="_blank">主成分分析</a>吧。</p><h2 id="605c" class="mo kv it bd kw mp mq dn la mr ms dp le lv mt mu lg lz mv mw li md mx my lk mz bi translated">制作交互式散点图</h2><p id="6069" class="pw-post-body-paragraph lm ln it lo b lp lq ju lr ls lt jx lu lv lw lx ly lz ma mb mc md me mf mg mh im bi translated">我们将使用<a class="ae mn" href="https://altair-viz.github.io/" rel="noopener ugc nofollow" target="_blank"> altair </a>库来构建交互式散点图。</p><h1 id="8d17" class="ku kv it bd kw kx ky kz la lb lc ld le jz lf ka lg kc lh kd li kf lj kg lk ll bi translated">结果</h1><h2 id="bbff" class="mo kv it bd kw mp mq dn la mr ms dp le lv mt mu lg lz mv mw li md mx my lk mz bi translated">概观</h2><p id="0962" class="pw-post-body-paragraph lm ln it lo b lp lq ju lr ls lt jx lu lv lw lx ly lz ma mb mc md me mf mg mh im bi translated">我们将使用4种饮食配置来可视化moodbot的训练集在2D特征空间中的外观，以帮助可视化超参数调整的影响。</p><p id="09a1" class="pw-post-body-paragraph lm ln it lo b lp mi ju lr ls mj jx lu lv mk lx ly lz ml mb mc md mm mf mg mh im bi translated">我们将这些配置称为基本、大、更大和最大。下图详细描述了各自的配置:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi nj"><img src="../Images/ac8c5f7ae346b556f4bf8900661bbbd5.png" data-original-src="https://miro.medium.com/v2/resize:fit:544/format:webp/1*UFB_fBbOADFj8ZTiJaWM9g.png"/></div><figcaption class="nb nc gj gh gi nd ne bd b be z dk translated">图2:“基本”配置</figcaption></figure><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi nk"><img src="../Images/0d811c81da07054044c3ea0fc5dd9a27.png" data-original-src="https://miro.medium.com/v2/resize:fit:508/format:webp/1*vJVBX4hfqJ7zawVlyWu9UQ.png"/></div><figcaption class="nb nc gj gh gi nd ne bd b be z dk translated">图3:“大”配置</figcaption></figure><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi nl"><img src="../Images/01261c1d8ce2119138638cbf595bfba3.png" data-original-src="https://miro.medium.com/v2/resize:fit:522/format:webp/1*XxCCrfdA_OTSM57agi19wg.png"/></div><figcaption class="nb nc gj gh gi nd ne bd b be z dk translated">图4:更大的配置</figcaption></figure><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi nm"><img src="../Images/564d677372d7d2593fab882eaf61007b.png" data-original-src="https://miro.medium.com/v2/resize:fit:526/format:webp/1*1qqQaTqc7Wdknfjo9Lin6w.png"/></div><figcaption class="nb nc gj gh gi nd ne bd b be z dk translated">图5:最大的配置</figcaption></figure><p id="05cb" class="pw-post-body-paragraph lm ln it lo b lp mi ju lr ls mj jx lu lv mk lx ly lz ml mb mc md mm mf mg mh im bi translated">注意,“最大”配置和“更大”配置之间的唯一区别是前者使用BERT嵌入作为附加特性。</p><h2 id="21a3" class="mo kv it bd kw mp mq dn la mr ms dp le lv mt mu lg lz mv mw li md mx my lk mz bi translated">形象化</h2><p id="23f7" class="pw-post-body-paragraph lm ln it lo b lp lq ju lr ls lt jx lu lv lw lx ly lz ma mb mc md me mf mg mh im bi translated">让我们在每个配置下训练一个模型3次，并可视化结果:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi nn"><img src="../Images/88f89bb515a60bd13f9a618c450f040d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1300/format:webp/1*8iRokYvQkOJuIuSeutjCaQ.png"/></div><figcaption class="nb nc gj gh gi nd ne bd b be z dk translated">图6:使用“基本”配置的2D特征空间中的训练集</figcaption></figure><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi no"><img src="../Images/c4d7f4738269308c232977bd0870dfab.png" data-original-src="https://miro.medium.com/v2/resize:fit:1310/format:webp/1*V9AIR3OdiNk3DqCml1HyvQ.png"/></div></div><figcaption class="nb nc gj gh gi nd ne bd b be z dk translated">图7:使用“大”配置的2D特征空间中的训练集</figcaption></figure><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi no"><img src="../Images/c8a66e5b633b1a4e7ac0576529676464.png" data-original-src="https://miro.medium.com/v2/resize:fit:1310/format:webp/1*1umRcVeXzB2f-iob3ZnyDg.png"/></div></div><figcaption class="nb nc gj gh gi nd ne bd b be z dk translated">图8:使用“更大”配置的2D特征空间中的训练集</figcaption></figure><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi no"><img src="../Images/648f4dcb57e96646926f602064d02fbe.png" data-original-src="https://miro.medium.com/v2/resize:fit:1310/format:webp/1*mkwbtNr2XybLern-Bc8GHQ.png"/></div></div><figcaption class="nb nc gj gh gi nd ne bd b be z dk translated">图9:使用“最大”配置的2D特征空间中的训练集</figcaption></figure><h2 id="31cc" class="mo kv it bd kw mp mq dn la mr ms dp le lv mt mu lg lz mv mw li md mx my lk mz bi translated">分析</h2><p id="0978" class="pw-post-body-paragraph lm ln it lo b lp lq ju lr ls lt jx lu lv lw lx ly lz ma mb mc md me mf mg mh im bi translated">Moodbot有7个意图。从图6(“基本”配置)中可以清楚地看到，有7个不同的集群，但是这些集群并没有紧密地打包和分离。随着我们增加模型的复杂性，这种情况会发生变化。</p><p id="7067" class="pw-post-body-paragraph lm ln it lo b lp mi ju lr ls mj jx lu lv mk lx ly lz ml mb mc md mm mf mg mh im bi translated">以下是每种配置的交叉验证结果:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi np"><img src="../Images/2d00e484ba8240675e64573b6a906ee4.png" data-original-src="https://miro.medium.com/v2/resize:fit:550/format:webp/1*-FZik9Q1EgZhHP7clzP8MA.png"/></div><figcaption class="nb nc gj gh gi nd ne bd b be z dk translated">图10:每个配置的交叉验证结果</figcaption></figure><p id="b7b6" class="pw-post-body-paragraph lm ln it lo b lp mi ju lr ls mj jx lu lv mk lx ly lz ml mb mc md mm mf mg mh im bi translated">直观上，聚类越明显和分离，模型就越容易使用更简单的几何图形“绘制”其决策边界，并避免过度适应训练集。</p><p id="96fd" class="pw-post-body-paragraph lm ln it lo b lp mi ju lr ls mj jx lu lv mk lx ly lz ml mb mc md mm mf mg mh im bi translated">另一个有趣的观察是，有一个从“大”配置开始的持久模式:有一个意图“再见”(青色)的例子离它的集群很远。这是为什么呢？</p><p id="84fa" class="pw-post-body-paragraph lm ln it lo b lp mi ju lr ls mj jx lu lv mk lx ly lz ml mb mc md mm mf mg mh im bi translated">这就是交互式图表变得有价值的地方。我们可以放大该区域，以了解该数据点与其集群中的其他成员有何不同:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi nq"><img src="../Images/5931174ecb5805af87e5e4f6e577e9b3.png" data-original-src="https://miro.medium.com/v2/resize:fit:1224/1*pcCEWsuECcr0fdukhaIOZw.gif"/></div><figcaption class="nb nc gj gh gi nd ne bd b be z dk translated">图11:使用交互式数据可视化技术研究有趣的模式</figcaption></figure><p id="0b59" class="pw-post-body-paragraph lm ln it lo b lp mi ju lr ls mj jx lu lv mk lx ly lz ml mb mc md mm mf mg mh im bi translated">图11显示了离群值的文本是“下午好”，这显然与“再见”意图中的其他示例不相似，例如“cu”、“稍后见”、“拜拜”等。因此，“下午好”被投射到远离其他标有“再见”意图的点是有意义的。通常，这是一个话语被贴错标签的迹象。在这种情况下，这真的是一个贴错标签的例子，正如在这个<a class="ae mn" href="https://github.com/RasaHQ/rasa/pull/8497" rel="noopener ugc nofollow" target="_blank">公关</a>中可以看到的。</p><h1 id="c0ad" class="ku kv it bd kw kx ky kz la lb lc ld le jz lf ka lg kc lh kd li kf lj kg lk ll bi translated">真实数据</h1><p id="680f" class="pw-post-body-paragraph lm ln it lo b lp lq ju lr ls lt jx lu lv lw lx ly lz ma mb mc md me mf mg mh im bi translated">一个真正的聊天机器人可以有数十种意图。</p><p id="ef7b" class="pw-post-body-paragraph lm ln it lo b lp mi ju lr ls mj jx lu lv mk lx ly lz ml mb mc md mm mf mg mh im bi translated">将它们同时可视化是不可行的，因为图表会被各种颜色和/或点形状弄得杂乱无章，以表示意图。此外，真实的数据是杂乱的，一个刚刚开始chatbot开发之旅的团队可能会犯许多错误，这只会混淆模型，并使散点图看起来一片混乱。</p><p id="6b64" class="pw-post-body-paragraph lm ln it lo b lp mi ju lr ls mj jx lu lv mk lx ly lz ml mb mc md mm mf mg mh im bi translated">尽管如此，我仍然发现这种方法很有用，因为它可以帮助聊天机器人开发人员看到他们的数据注释工作与模型性能之间的联系，快速识别令人困惑或糟糕的示例，并说服他们停止进行超参数调整，转而专注于提高数据质量。</p><h1 id="3c01" class="ku kv it bd kw kx ky kz la lb lc ld le jz lf ka lg kc lh kd li kf lj kg lk ll bi translated">结论</h1><p id="708a" class="pw-post-body-paragraph lm ln it lo b lp lq ju lr ls lt jx lu lv lw lx ly lz ma mb mc md me mf mg mh im bi translated">本文展示了如何使用交互式图表和降维方法来帮助直观地评估训练集的质量和ML模型的性能。</p><p id="6c66" class="pw-post-body-paragraph lm ln it lo b lp mi ju lr ls mj jx lu lv mk lx ly lz ml mb mc md mm mf mg mh im bi translated">我希望你已经发现这是有用的。</p></div></div>    
</body>
</html>