<html>
<head>
<title>Web Scraping Yelp, Part 1: mining reviews with Pyhton using Beautifulsoup</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">网页抓取Yelp，第1部分:用Pyhton使用Beautifulsoup挖掘评论</h1>
<blockquote>原文：<a href="https://pub.towardsai.net/part-1-scraping-yelp-reviews-with-pyhton-using-beautifulsoup-a014867a1d2c?source=collection_archive---------0-----------------------#2021-08-19">https://pub.towardsai.net/part-1-scraping-yelp-reviews-with-pyhton-using-beautifulsoup-a014867a1d2c?source=collection_archive---------0-----------------------#2021-08-19</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><h2 id="8f41" class="ir is it bd b dl iu iv iw ix iy iz dk ja translated" aria-label="kicker paragraph"><a class="ae ep" href="https://towardsai.net/p/category/web-scraping" rel="noopener ugc nofollow" target="_blank">网页抓取</a></h2><div class=""/><div class=""><h2 id="90fc" class="pw-subtitle-paragraph jz jc it bd b ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq dk translated">执行餐馆评论的网络搜集。完整的代码<a class="ae kr" href="https://github.com/arditoibryan/Projects/tree/master/20210813_yelp_webscraping" rel="noopener ugc nofollow" target="_blank">可在我的回购</a>。</h2></div><p id="59f9" class="pw-post-body-paragraph ks kt it ku b kv kw kd kx ky kz kg la lb lc ld le lf lg lh li lj lk ll lm ln im bi translated">使用python时，Web抓取是我最喜欢面对的挑战之一。网络抓取是一种允许程序员使用代码连接到网站，然后提取网站上托管的HTML和javascript的技术。然后使用一些库对代码进行分析，这些库可以帮助提取我们想要的信息。</p><figure class="lp lq lr ls gt lt gh gi paragraph-image"><div role="button" tabindex="0" class="lu lv di lw bf lx"><div class="gh gi lo"><img src="../Images/db070012cc8d9facb0d7723e02d07503.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*44D1VaM_ckw-TsxP"/></div></div><figcaption class="ma mb gj gh gi mc md bd b be z dk translated">照片由<a class="ae kr" href="https://unsplash.com/@jckbck?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">雅各布·久巴克</a>在<a class="ae kr" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>拍摄</figcaption></figure><p id="fae6" class="pw-post-body-paragraph ks kt it ku b kv kw kd kx ky kz kg la lb lc ld le lf lg lh li lj lk ll lm ln im bi translated">通过python这样的编程语言使用web scraping的好处是，我们不局限于从单个页面中提取信息，但是如果网站的逻辑足够一致，我们可以迭代网站的所有页面，以挖掘尽可能多的数据。</p><h2 id="6bbe" class="me mf it bd mg mh mi dn mj mk ml dp mm lb mn mo mp lf mq mr ms lj mt mu mv iz bi translated">网页抓取的局限性</h2><p id="0ef3" class="pw-post-body-paragraph ks kt it ku b kv mw kd kx ky mx kg la lb my ld le lf mz lh li lj na ll lm ln im bi translated">然而，网络搜集并不是一个可靠的方法。像所有其他工具一样，它要么存在局限性，要么存在无法正常工作的情况。如果我们足够幸运，我们在采矿时可能不需要面对这些问题。每个网站都有自己独特的结构和自己的保护方法，因此这是一个全新的挑战。</p><ul class=""><li id="d024" class="nb nc it ku b kv kw ky kz lb nd lf ne lj nf ln ng nh ni nj bi translated">Beautifulsoup无法下载所有代码</li></ul><p id="5aae" class="pw-post-body-paragraph ks kt it ku b kv kw kd kx ky kz kg la lb lc ld le lf lg lh li lj lk ll lm ln im bi translated">可能发生的情况是，网站启用了阻止beautifulsoup获得连接的保护。事实上，如果一些网站了解到您试图在不使用浏览器界面的情况下发送GET请求，它们可能会阻止您。不幸的是，当这个问题出现时，没有机会找到解决方法，至少不能使用代码。令人怀疑的是，任何其他图书馆将在同样的情况下工作。</p><ul class=""><li id="76d9" class="nb nc it ku b kv kw ky kz lb nd lf ne lj nf ln ng nh ni nj bi translated">无法解析代码</li></ul><p id="6d91" class="pw-post-body-paragraph ks kt it ku b kv kw kd kx ky kz kg la lb lc ld le lf lg lh li lj lk ll lm ln im bi translated">其他时候，软件仍然可以访问HTML，由于某种原因，代码不能被解析和转换成结构化的beautifulsoup对象。如果我们不能解析它，我们就不能使用beautifulsoup库提供的任何方法来提取信息，这使得自动化过程变得不可能。</p><ul class=""><li id="606d" class="nb nc it ku b kv kw ky kz lb nd lf ne lj nf ln ng nh ni nj bi translated">网站结构没有逻辑</li></ul><p id="239e" class="pw-post-body-paragraph ks kt it ku b kv kw kd kx ky kz kg la lb lc ld le lf lg lh li lj lk ll lm ln im bi translated">有时您可能会发现，即使代码已经被正确地访问、下载和解析，网站的设计也可能很糟糕，以至于无法在相似的页面中找到共同的结构。当然，这种情况很少发生，但是我不得不处理这个问题几次，结果导致几条信息丢失，因为检索过程不能正确地自动化。</p><ul class=""><li id="6516" class="nb nc it ku b kv kw ky kz lb nd lf ne lj nf ln ng nh ni nj bi translated">这太难了</li></ul><p id="6b6a" class="pw-post-body-paragraph ks kt it ku b kv kw kd kx ky kz kg la lb lc ld le lf lg lh li lj lk ll lm ln im bi translated">我希望你永远不会遇到这个问题，然而，一些网站只是能够用如此大量的代码淹没你，这是不可能正确破译。有时，信息被嵌套在javascript和哈希隐藏的结构中，即使您需要的所有信息都隐藏在代码中，您也无法找到简单提取它们的方法。</p><h2 id="4f40" class="me mf it bd mg mh mi dn mj mk ml dp mm lb mn mo mp lf mq mr ms lj mt mu mv iz bi translated">刮Yelp</h2><p id="855b" class="pw-post-body-paragraph ks kt it ku b kv mw kd kx ky mx kg la lb my ld le lf mz lh li lj na ll lm ln im bi translated">在这篇文章中，我将重点刮这个确切的餐馆的评论<a class="ae kr" href="https://www.yelp.com/biz/the-cortez-raleigh?osq=Restaurants&amp;start=280&amp;sort_by=rating_asc" rel="noopener ugc nofollow" target="_blank">。</a></p><figure class="lp lq lr ls gt lt gh gi paragraph-image"><div role="button" tabindex="0" class="lu lv di lw bf lx"><div class="gh gi nk"><img src="../Images/5b2587206be02d8623729b6d35337074.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*eCWyNEyhGy3wywankF3r-Q.png"/></div></div><figcaption class="ma mb gj gh gi mc md bd b be z dk translated">Yelp页面我会用python刮</figcaption></figure><p id="aacc" class="pw-post-body-paragraph ks kt it ku b kv kw kd kx ky kz kg la lb lc ld le lf lg lh li lj lk ll lm ln im bi translated">为了执行正确的网页抓取，我通常遵循以下步骤:</p><ol class=""><li id="8aad" class="nb nc it ku b kv kw ky kz lb nd lf ne lj nf ln nl nh ni nj bi translated">检查我是否能下载一页的HTML</li><li id="e40d" class="nb nc it ku b kv nm ky nn lb no lf np lj nq ln nl nh ni nj bi translated">检查网站中是否有允许迭代的逻辑</li><li id="588f" class="nb nc it ku b kv nm ky nn lb no lf np lj nq ln nl nh ni nj bi translated">刮掉第一页</li><li id="302e" class="nb nc it ku b kv nm ky nn lb no lf np lj nq ln nl nh ni nj bi translated">找到我们想要提取的信息</li><li id="fbec" class="nb nc it ku b kv nm ky nn lb no lf np lj nq ln nl nh ni nj bi translated">提取信息并把它们放在一个列表上</li><li id="fc12" class="nb nc it ku b kv nm ky nn lb no lf np lj nq ln nl nh ni nj bi translated">为将同一算法应用于若干页的循环创建</li><li id="fff7" class="nb nc it ku b kv nm ky nn lb no lf np lj nq ln nl nh ni nj bi translated">导出结果</li></ol><p id="71da" class="pw-post-body-paragraph ks kt it ku b kv kw kd kx ky kz kg la lb lc ld le lf lg lh li lj lk ll lm ln im bi translated">这个过程非常直观，可以这样总结:在我们检查我们是否可以实际执行web抓取之前，如果可以，我们在单个页面上执行，然后我们将代码扩展到几个页面(如果需要，甚至几百个)。</p><h2 id="237b" class="me mf it bd mg mh mi dn mj mk ml dp mm lb mn mo mp lf mq mr ms lj mt mu mv iz bi translated">检查HTML是否可以下载</h2><figure class="lp lq lr ls gt lt gh gi paragraph-image"><div role="button" tabindex="0" class="lu lv di lw bf lx"><div class="gh gi nr"><img src="../Images/281e7a3500a751b6d5005aeca66bf164.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*i_lnOZUmg_mEscvvxxeA1A.png"/></div></div><figcaption class="ma mb gj gh gi mc md bd b be z dk translated">用python下载的乱码</figcaption></figure><p id="5206" class="pw-post-body-paragraph ks kt it ku b kv kw kd kx ky kz kg la lb lc ld le lf lg lh li lj lk ll lm ln im bi translated">一开始，我以为没有希望了。我花了一段时间才明白，所有的评论都包含在我必须分析的那一行HTML代码中。</p><h2 id="88bf" class="me mf it bd mg mh mi dn mj mk ml dp mm lb mn mo mp lf mq mr ms lj mt mu mv iz bi translated">检查网站是否有任何逻辑</h2><p id="912c" class="pw-post-body-paragraph ks kt it ku b kv mw kd kx ky mx kg la lb my ld le lf mz lh li lj na ll lm ln im bi translated">下一个挑战是看看是否有任何逻辑证据允许我遍历关于同一家餐馆的不同页面。</p><pre class="lp lq lr ls gt ns nt nu nv aw nw bi"><span id="4a5a" class="me mf it nt b gy nx ny l nz oa"><a class="ae kr" href="https://www.yelp.com/biz/the-cortez-raleigh?osq=Restaurants&amp;start=280&amp;sort_by=rating_asc" rel="noopener ugc nofollow" target="_blank">https://www.yelp.com/biz/the-cortez-raleigh?osq=Restaurants&amp;start=280&amp;sort_by=rating_asc</a></span></pre><p id="a828" class="pw-post-body-paragraph ks kt it ku b kv kw kd kx ky kz kg la lb lc ld le lf lg lh li lj lk ll lm ln im bi translated">幸运的是，逻辑很简单。一旦确定了我想搜索的餐馆，我可以改变链接中除以10的唯一数字，作为包含评论的页面的指示。遍历不同的页面是小菜一碟。</p><figure class="lp lq lr ls gt lt gh gi paragraph-image"><div class="gh gi ob"><img src="../Images/00030e61006d3cb9aa709c25d8c8cb25.png" data-original-src="https://miro.medium.com/v2/resize:fit:1358/format:webp/1*F4aKfC_q4oBOylKOyX62gw.png"/></div><figcaption class="ma mb gj gh gi mc md bd b be z dk translated">我将要下载的评论截图</figcaption></figure><h1 id="6190" class="oc mf it bd mg od oe of mj og oh oi mm ki oj kj mp kl ok km ms ko ol kp mv om bi translated">编码</h1><p id="45d0" class="pw-post-body-paragraph ks kt it ku b kv mw kd kx ky mx kg la lb my ld le lf mz lh li lj na ll lm ln im bi translated">python中的代码如下:</p><h2 id="258b" class="me mf it bd mg mh mi dn mj mk ml dp mm lb mn mo mp lf mq mr ms lj mt mu mv iz bi translated">导入库</h2><pre class="lp lq lr ls gt ns nt nu nv aw nw bi"><span id="4947" class="me mf it nt b gy nx ny l nz oa">import requests<br/>from bs4 import BeautifulSoup<br/>import time</span></pre><h2 id="3cd3" class="me mf it bd mg mh mi dn mj mk ml dp mm lb mn mo mp lf mq mr ms lj mt mu mv iz bi translated">遍历整个网站</h2><pre class="lp lq lr ls gt ns nt nu nv aw nw bi"><span id="d4f2" class="me mf it nt b gy nx ny l nz oa">comment_list = list()<br/>for pag in range(1, 29):<br/>  time.sleep(5)</span><span id="0eac" class="me mf it nt b gy on ny l nz oa">URL = "<a class="ae kr" href="https://www.yelp.com/biz/the-cortez-raleigh?osq=Restaurants&amp;start=" rel="noopener ugc nofollow" target="_blank">https://www.yelp.com/biz/the-cortez-raleigh?osq=Restaurants&amp;start=</a>"+str(pag*10)+"&amp;sort_by=rating_asc"<br/>  print('downloading page ', pag*10)<br/>  page = requests.get(URL)</span><span id="735b" class="me mf it nt b gy on ny l nz oa">#next step: parsing<br/>  soup = BeautifulSoup(page.content, 'lxml')<br/>  soup</span></pre><h2 id="c243" class="me mf it bd mg mh mi dn mj mk ml dp mm lb mn mo mp lf mq mr ms lj mt mu mv iz bi translated">提取评论并把它们放在一个列表中</h2><pre class="lp lq lr ls gt ns nt nu nv aw nw bi"><span id="1d98" class="me mf it nt b gy nx ny l nz oa">for comm in soup.find("yelp-react-root").find_all("p", {"class" : "comment__373c0__Nsutg css-n6i4z7"}):<br/>    comment_list.append(comm.find("span").decode_contents())<br/>    print(comm.find("span").decode_contents())</span></pre><p id="ee03" class="pw-post-body-paragraph ks kt it ku b kv kw kd kx ky kz kg la lb lc ld le lf lg lh li lj lk ll lm ln im bi translated">下载数据时，代码会向我们显示进度和目前下载的数据。</p><figure class="lp lq lr ls gt lt gh gi paragraph-image"><div role="button" tabindex="0" class="lu lv di lw bf lx"><div class="gh gi oo"><img src="../Images/f0acad1d6941dac5e8cd001be566e394.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*xCcsqHBmbvY1ltp8NCE7-g.png"/></div></div><figcaption class="ma mb gj gh gi mc md bd b be z dk translated">输出的屏幕截图</figcaption></figure><h2 id="f254" class="me mf it bd mg mh mi dn mj mk ml dp mm lb mn mo mp lf mq mr ms lj mt mu mv iz bi translated">导出结果</h2><p id="8867" class="pw-post-body-paragraph ks kt it ku b kv mw kd kx ky mx kg la lb my ld le lf mz lh li lj na ll lm ln im bi translated">从列表中导出结果非常简单。我们可以通过文本文件来实现，但我更喜欢使用CSV来方便信息通过其他软件的移动。</p><pre class="lp lq lr ls gt ns nt nu nv aw nw bi"><span id="26f1" class="me mf it nt b gy nx ny l nz oa">import pandas as pd</span><span id="bccf" class="me mf it nt b gy on ny l nz oa">pd.DataFrame([comment_list]).T.to_csv(‘yelp.csv’)</span></pre><p id="09ef" class="pw-post-body-paragraph ks kt it ku b kv kw kd kx ky kz kg la lb lc ld le lf lg lh li lj lk ll lm ln im bi translated">从截图中我们可以看到，我们已经成功地将所有评论导出到一个CSV文件中。</p><figure class="lp lq lr ls gt lt gh gi paragraph-image"><div role="button" tabindex="0" class="lu lv di lw bf lx"><div class="gh gi op"><img src="../Images/41150c580c2c8ed68542f60e85df7e2e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*0Ppgd4cvPZvBCJhlDIpv5g.png"/></div></div><figcaption class="ma mb gj gh gi mc md bd b be z dk translated">CSV的截图</figcaption></figure><h2 id="9176" class="me mf it bd mg mh mi dn mj mk ml dp mm lb mn mo mp lf mq mr ms lj mt mu mv iz bi translated">现在怎么办？</h2><p id="2a1c" class="pw-post-body-paragraph ks kt it ku b kv mw kd kx ky mx kg la lb my ld le lf mz lh li lj na ll lm ln im bi translated">我们可以做很多很酷的事情来充分利用我们刚刚下载的数据。我们可以清理数据，然后对数据进行情感分析。然后，我们可以从多个餐馆下载数据，并可视化该地区最好的地方，这完全取决于我们的想象力。</p></div></div>    
</body>
</html>