<html>
<head>
<title>Explain Your Machine Learning Predictions With Tree SHAP (Tree Explainer)</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">用树SHAP解释你的机器学习预测</h1>
<blockquote>原文：<a href="https://pub.towardsai.net/how-to-explain-your-machine-learning-predictions-with-shap-values-a8332c3e5a11?source=collection_archive---------0-----------------------#2020-11-20">https://pub.towardsai.net/how-to-explain-your-machine-learning-predictions-with-shap-values-a8332c3e5a11?source=collection_archive---------0-----------------------#2020-11-20</a></blockquote><div><div class="fc ii ij ik il im"/><div class="in io ip iq ir"><h2 id="b522" class="is it iu bd b dl iv iw ix iy iz ja dk jb translated" aria-label="kicker paragraph"><a class="ae ep" href="https://towardsai.net/p/category/data-science" rel="noopener ugc nofollow" target="_blank">数据科学</a>，<a class="ae ep" href="https://towardsai.net/p/category/machine-learning" rel="noopener ugc nofollow" target="_blank">机器学习</a></h2><div class=""/><div class=""><h2 id="0dbd" class="pw-subtitle-paragraph ka jd iu bd b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr dk translated">SHapley加法解释</h2></div><figure class="kt ku kv kw gu kx gi gj paragraph-image"><div role="button" tabindex="0" class="ky kz di la bf lb"><div class="gi gj ks"><img src="../Images/aa4f169355ac3dd84b33a8c9f545405a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*yMiaa0HCjOdI6mQ-dha2jg.png"/></div></div><figcaption class="le lf gk gi gj lg lh bd b be z dk translated">来源:<a class="ae li" href="https://github.com/slundberg/shap" rel="noopener ugc nofollow" target="_blank"> SHAP </a></figcaption></figure></div><div class="ab cl lj lk hy ll" role="separator"><span class="lm bw bk ln lo lp"/><span class="lm bw bk ln lo lp"/><span class="lm bw bk ln lo"/></div><div class="in io ip iq ir"><p id="a64a" class="pw-post-body-paragraph lq lr iu ls b lt lu ke lv lw lx kh ly lz ma mb mc md me mf mg mh mi mj mk ml in bi translated">可解释人工智能(XAI)是人工智能领域的一个热门话题。它指的是可以用来让任何黑盒机器学习被人类专家理解的工具和技术。市场上有很多这样的工具，如LIME、SHAP、ELI5、Interpretml等。</p><p id="c9a1" class="pw-post-body-paragraph lq lr iu ls b lt lu ke lv lw lx kh ly lz ma mb mc md me mf mg mh mi mj mk ml in bi translated">本文的目的是了解什么是沙普利价值，SHAP价值是如何从沙普利价值中产生的。然后，我们将使用SHAP值来解释和说明任何机器学习预测。让我们开始吧。</p></div><div class="ab cl lj lk hy ll" role="separator"><span class="lm bw bk ln lo lp"/><span class="lm bw bk ln lo lp"/><span class="lm bw bk ln lo"/></div><div class="in io ip iq ir"><h1 id="7c77" class="mm mn iu bd mo mp mq mr ms mt mu mv mw kj mx kk my km mz kn na kp nb kq nc nd bi translated">什么是SHAP</h1><p id="62ff" class="pw-post-body-paragraph lq lr iu ls b lt ne ke lv lw nf kh ly lz ng mb mc md nh mf mg mh ni mj mk ml in bi translated">正如作者在<a class="ae li" href="https://github.com/slundberg/shap" rel="noopener ugc nofollow" target="_blank"> Github </a>页面— <em class="nj">上所说，“SHAP(SHapley Additive explaints)是一种解释任何机器学习模型输出的博弈论方法。它使用博弈论的经典Shapley值及其相关扩展将最优信用分配与本地解释联系起来。</em></p><h2 id="b8c9" class="nk mn iu bd mo nl nm dn ms nn no dp mw lz np nq my md nr ns na mh nt nu nc ja bi translated">沙普利值</h2><p id="4b7a" class="pw-post-body-paragraph lq lr iu ls b lt ne ke lv lw nf kh ly lz ng mb mc md nh mf mg mh ni mj mk ml in bi translated">如上所述，沙普利值是基于经典博弈论。有许多游戏类型，如合作/非合作、对称/非对称、零和/非零和等。但是Shapley值是基于合作(联盟)博弈理论的。</p><p id="8a51" class="pw-post-body-paragraph lq lr iu ls b lt lu ke lv lw lx kh ly lz ma mb mc md me mf mg mh mi mj mk ml in bi translated">在联盟博弈理论中，一群玩家聚集在一起创造一些价值。你可以想象一群人一起成立一个公司来创造一些利润。Shapley值是一种在玩家之间分配利润的方法。我们希望根据玩家的贡献在他们之间公平分配利润。</p><h2 id="29bb" class="nk mn iu bd mo nl nm dn ms nn no dp mw lz np nq my md nr ns na mh nt nu nc ja bi translated"><strong class="ak">通过示例了解Shapley值</strong></h2><p id="b824" class="pw-post-body-paragraph lq lr iu ls b lt ne ke lv lw nf kh ly lz ng mb mc md nh mf mg mh ni mj mk ml in bi translated">假设您已经训练了模型来预测房价。例如，该模型预测房价为10万美元。房子的大小是2400平方英尺，位于HSR布局，有3间卧室。现在，我们的目标是解释这个预测。假设$85，000是给定数据集的平均房价。Shapley值解释了与平均预测相比，每个特征值对预测的贡献有多大？</p><p id="eea5" class="pw-post-body-paragraph lq lr iu ls b lt lu ke lv lw lx kh ly lz ma mb mc md me mf mg mh mi mj mk ml in bi translated">在上面的例子中，特征值<code class="fe nv nw nx ny b">Size</code>、<code class="fe nv nw nx ny b">Area</code>、<code class="fe nv nw nx ny b">City,</code>、<code class="fe nv nw nx ny b">BedRooms</code>一起工作以实现100，000美元的预测。目标是解释实际预测值(100，000美元)和平均预测值(85，000美元)之间的差异:15，000美元的差异。一种可能的解释是，<code class="fe nv nw nx ny b">size</code>贡献了3万美元，<code class="fe nv nw nx ny b">Area</code>贡献了2.5万美元，<code class="fe nv nw nx ny b">City</code>贡献了-2.5万美元，<code class="fe nv nw nx ny b">BedRooms</code>贡献了-1.5万美元。捐款加起来是15，000美元——这只不过是最终预测减去平均预测房价。</p><p id="f015" class="pw-post-body-paragraph lq lr iu ls b lt lu ke lv lw lx kh ly lz ma mb mc md me mf mg mh mi mj mk ml in bi translated">如何计算一个特征的Shapley值？</p><blockquote class="nz oa ob"><p id="844c" class="lq lr nj ls b lt lu ke lv lw lx kh ly oc ma mb mc od me mf mg oe mi mj mk ml in bi translated">Shapley值是一个特性值在所有可能的联合中的平均边际贡献。</p></blockquote><p id="5888" class="pw-post-body-paragraph lq lr iu ls b lt lu ke lv lw lx kh ly lz ma mb mc md me mf mg mh mi mj mk ml in bi translated">对于这个例子，我们将研究特性<code class="fe nv nw nx ny b">Bedrooms</code>在添加到<code class="fe nv nw nx ny b">Size</code>、<code class="fe nv nw nx ny b">Area</code>和<code class="fe nv nw nx ny b">City</code>特性的联合中时的贡献。我们模拟只有<code class="fe nv nw nx ny b">Size</code>、<code class="fe nv nw nx ny b">Area</code>、<code class="fe nv nw nx ny b">City</code>和<code class="fe nv nw nx ny b">Bedrooms</code>是一个联盟。</p><p id="0cdc" class="pw-post-body-paragraph lq lr iu ls b lt lu ke lv lw lx kh ly lz ma mb mc md me mf mg mh mi mj mk ml in bi translated"><strong class="ls je">第一步:</strong>第一步，我们从数据中随机抽取一个实例，不使用<code class="fe nv nw nx ny b">Bedrooms</code>特征计算房价。我们可以多次执行此活动，然后取平均值。</p><p id="e1ad" class="pw-post-body-paragraph lq lr iu ls b lt lu ke lv lw lx kh ly lz ma mb mc md me mf mg mh mi mj mk ml in bi translated"><strong class="ls je">第二步:</strong>第二步，我们取所有特征<code class="fe nv nw nx ny b">Size</code>、<code class="fe nv nw nx ny b">Area</code>、<code class="fe nv nw nx ny b">City</code>、<code class="fe nv nw nx ny b">Bedrooms</code>时的房价平均值。在这里，我们也可以多次执行采样步骤并取平均值。</p><p id="1168" class="pw-post-body-paragraph lq lr iu ls b lt lu ke lv lw lx kh ly lz ma mb mc md me mf mg mh mi mj mk ml in bi translated">我们对所有可能的联盟重复这两个步骤。您可能已经注意到，如果要素数量增加，计算时间会呈指数增长。你如何处理这个问题？解决这个问题的一个方法是从每个联盟的数据中抽取一些样本。这样我们可以控制计算时间。</p><p id="eb14" class="pw-post-body-paragraph lq lr iu ls b lt lu ke lv lw lx kh ly lz ma mb mc md me mf mg mh mi mj mk ml in bi translated">以下列表显示了当考虑<code class="fe nv nw nx ny b">Size</code>、<code class="fe nv nw nx ny b">Area</code>、<code class="fe nv nw nx ny b">City</code>和<code class="fe nv nw nx ny b">Bedrooms</code>联合时，确定<code class="fe nv nw nx ny b">Bedrooms</code>的Shapley值所需的所有特征值联合。</p><ul class=""><li id="5303" class="of og iu ls b lt lu lw lx lz oh md oi mh oj ml ok ol om on bi translated">没有特征值</li><li id="b6f9" class="of og iu ls b lt oo lw op lz oq md or mh os ml ok ol om on bi translated">大小</li><li id="82f6" class="of og iu ls b lt oo lw op lz oq md or mh os ml ok ol om on bi translated">面积</li><li id="ee9d" class="of og iu ls b lt oo lw op lz oq md or mh os ml ok ol om on bi translated">城市</li><li id="fae7" class="of og iu ls b lt oo lw op lz oq md or mh os ml ok ol om on bi translated">尺寸+面积</li><li id="9f1b" class="of og iu ls b lt oo lw op lz oq md or mh os ml ok ol om on bi translated">大小+城市</li><li id="0485" class="of og iu ls b lt oo lw op lz oq md or mh os ml ok ol om on bi translated">区域+城市</li><li id="b099" class="of og iu ls b lt oo lw op lz oq md or mh os ml ok ol om on bi translated">规模+面积+城市</li></ul><p id="6a74" class="pw-post-body-paragraph lq lr iu ls b lt lu ke lv lw lx kh ly lz ma mb mc md me mf mg mh mi mj mk ml in bi translated">对于这些联盟中的每一个，边际贡献是通过计算有和没有特色价值卧室的房价之间的差异来计算的。最后，通过加权平均计算Shapley值。我们对所有的特征重复这个过程以获得Shapley值。</p><p id="7f23" class="pw-post-body-paragraph lq lr iu ls b lt lu ke lv lw lx kh ly lz ma mb mc md me mf mg mh mi mj mk ml in bi translated">这是Shapley值如何用于解释模型预测的核心概念。然而，SHAP库的实现方式可能会有一些变化。对于好奇的读者，我建议您浏览一下实现细节或各自的研究论文。</p><h2 id="07f1" class="nk mn iu bd mo nl nm dn ms nn no dp mw lz np nq my md nr ns na mh nt nu nc ja bi translated"><strong class="ak">从沙普利值到SHAP值</strong></h2><p id="4b2c" class="pw-post-body-paragraph lq lr iu ls b lt ne ke lv lw nf kh ly lz ng mb mc md nh mf mg mh ni mj mk ml in bi translated">SHAP值基于沙普利值。受几种方法的启发，SHAP的作者提出了一种解释模型预测的统一方法。请注意，在计算SHAP值时，沙普利值的核心概念仍然保持不变。对于好奇的读者来说，数学形式的细节可以在<a class="ae li" href="https://papers.nips.cc/paper/2017/file/8a20a8621978632d76c43dfd28b67767-Paper.pdf" rel="noopener ugc nofollow" target="_blank">这里</a>和<a class="ae li" href="https://christophm.github.io/interpretable-ml-book/shap.html" rel="noopener ugc nofollow" target="_blank">这里</a>找到。</p><p id="d4ab" class="pw-post-body-paragraph lq lr iu ls b lt lu ke lv lw lx kh ly lz ma mb mc md me mf mg mh mi mj mk ml in bi translated">因此，简而言之，SHAP的目标是通过计算每个特征对预测的贡献来解释任何机器学习模型实例的预测。</p><p id="02fc" class="pw-post-body-paragraph lq lr iu ls b lt lu ke lv lw lx kh ly lz ma mb mc md me mf mg mh mi mj mk ml in bi translated">既然我们已经理解了联盟博弈论，它与沙普利值和SHAP值的关系，以及它如何帮助机器学习模型的可解释性，现在是动手的时候了。</p><h1 id="2044" class="mm mn iu bd mo mp ot mr ms mt ou mv mw kj ov kk my km ow kn na kp ox kq nc nd bi translated">装置</h1><pre class="kt ku kv kw gu oy ny oz pa aw pb bi"><span id="b985" class="nk mn iu ny b gz pc pd l pe pf">pip install shap<br/><strong class="ny je">Or</strong><br/>conda install -c conda-forge shap</span></pre><h1 id="a73e" class="mm mn iu bd mo mp ot mr ms mt ou mv mw kj ov kk my km ow kn na kp ox kq nc nd bi translated">使用</h1><p id="c003" class="pw-post-body-paragraph lq lr iu ls b lt ne ke lv lw nf kh ly lz ng mb mc md nh mf mg mh ni mj mk ml in bi translated">下面是SHAP的用法示例。我们将不得不使用不同的解释方法或情节类型。</p><pre class="kt ku kv kw gu oy ny oz pa aw pb bi"><span id="301c" class="nk mn iu ny b gz pc pd l pe pf">import shap<br/>explainer = shap.<strong class="ny je"><em class="nj">TreeExplainer</em></strong>(model)<br/>shap_values = explainer.shap_values(X)</span><span id="8e5e" class="nk mn iu ny b gz pg pd l pe pf">shap.<strong class="ny je"><em class="nj">force_plot</em></strong>(explainer.expected_value, shap_values[0,:], X.iloc[0,:])</span></pre><p id="5256" class="pw-post-body-paragraph lq lr iu ls b lt lu ke lv lw lx kh ly lz ma mb mc md me mf mg mh mi mj mk ml in bi translated">SHAP提供了以下计算SHAP值的方法/算法。每种方法都适合于你试图得到解释的模型类型。</p><ul class=""><li id="1d98" class="of og iu ls b lt lu lw lx lz oh md oi mh oj ml ok ol om on bi translated"><strong class="ls je"> TreeExplainer — </strong>该方法<strong class="ls je"> </strong>实现了<strong class="ls je"> </strong> TreeSHAP算法，适用于决策树、随机森林等基于树的算法。</li><li id="58ce" class="of og iu ls b lt oo lw op lz oq md or mh os ml ok ol om on bi translated"><strong class="ls je"> DeepExplainer — </strong>该方法实现了DeepLIFT算法，用于深度学习模型。</li><li id="0133" class="of og iu ls b lt oo lw op lz oq md or mh os ml ok ol om on bi translated"><strong class="ls je"> GradientExplainer — </strong>此方法使用预期梯度来逼近SHAP值，用于深度学习模型。</li><li id="2c14" class="of og iu ls b lt oo lw op lz oq md or mh os ml ok ol om on bi translated"><strong class="ls je"> LinearExplainer — </strong>顾名思义，这种方法非常适合线性模型。</li><li id="d047" class="of og iu ls b lt oo lw op lz oq md or mh os ml ok ol om on bi translated"><strong class="ls je"> KernelExplainer — </strong>这个方法是一个模型不可知的方法。意味着它可以用于解释任何模型——线性模型、树模型或深度学习模型。</li></ul><h1 id="2558" class="mm mn iu bd mo mp ot mr ms mt ou mv mw kj ov kk my km ow kn na kp ox kq nc nd bi translated">例子</h1><p id="480d" class="pw-post-body-paragraph lq lr iu ls b lt ne ke lv lw nf kh ly lz ng mb mc md nh mf mg mh ni mj mk ml in bi translated">让我们试着去理解TreeExplainer和在SHAP可用于解释模型预测的不同绘图。请参考<a class="ae li" href="https://github.com/slundberg/shap#sample-notebooks" rel="noopener ugc nofollow" target="_blank">此处的</a>获取官方样品笔记本。</p><figure class="kt ku kv kw gu kx"><div class="bz fq l di"><div class="ph pi l"/></div></figure><h2 id="3b6c" class="nk mn iu bd mo nl nm dn ms nn no dp mw lz np nq my md nr ns na mh nt nu nc ja bi translated">力图</h2><p id="380c" class="pw-post-body-paragraph lq lr iu ls b lt ne ke lv lw nf kh ly lz ng mb mc md nh mf mg mh ni mj mk ml in bi translated">力图用于解释个别情况的预测。以下示例显示了测试数据集中第三个实例的力图。</p><pre class="kt ku kv kw gu oy ny oz pa aw pb bi"><span id="db48" class="nk mn iu ny b gz pc pd l pe pf"># load JS visualization code to notebook<br/>shap.initjs()</span><span id="744a" class="nk mn iu ny b gz pg pd l pe pf"># visualize the first prediction’s explanation<br/>shap.force_plot(explainer.expected_value, shap_values[2,:], X.iloc[2,:])</span></pre><figure class="kt ku kv kw gu kx gi gj paragraph-image"><div role="button" tabindex="0" class="ky kz di la bf lb"><div class="gi gj pj"><img src="../Images/beeb19b20abd4c8316bafd210537c8ff.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*GuTu-2HrIeKloSP7c7DJDQ.png"/></div></div></figure><ul class=""><li id="853b" class="of og iu ls b lt lu lw lx lz oh md oi mh oj ml ok ol om on bi translated"><code class="fe nv nw nx ny b">f(x)</code>是模型预测(24.73)。</li><li id="4de8" class="of og iu ls b lt oo lw op lz oq md or mh os ml ok ol om on bi translated"><code class="fe nv nw nx ny b">base value</code>是整个测试数据集的平均预测值。这是在我们不知道当前输出的任何特征的情况下预测的值。</li><li id="14e4" class="of og iu ls b lt oo lw op lz oq md or mh os ml ok ol om on bi translated">将预测值推高的要素显示为红色，将预测值推低的要素显示为蓝色。</li><li id="3f01" class="of og iu ls b lt oo lw op lz oq md or mh os ml ok ol om on bi translated"><code class="fe nv nw nx ny b">LSTAT</code>特征对房价有很高的正面影响，推动预测正确。推动房价上涨的其他重要因素还有<code class="fe nv nw nx ny b">TAX</code> &amp; <code class="fe nv nw nx ny b">NOX</code>。<em class="nj">您还可以注意到，这三个值高于它们在训练数据中的平均值。</em></li><li id="5115" class="of og iu ls b lt oo lw op lz oq md or mh os ml ok ol om on bi translated"><code class="fe nv nw nx ny b">RM</code>特征对房价有较高的负面影响，其次是<code class="fe nv nw nx ny b">DIS</code>特征。</li></ul><p id="d476" class="pw-post-body-paragraph lq lr iu ls b lt lu ke lv lw lx kh ly lz ma mb mc md me mf mg mh mi mj mk ml in bi translated">上面的图是一个例子。如果我们采用如上所示的许多解释，将它们旋转90度，然后水平堆叠，我们可以看到整个数据集的解释如下<em class="nj">(注意，该图在笔记本中是交互式的)。</em></p><pre class="kt ku kv kw gu oy ny oz pa aw pb bi"><span id="860d" class="nk mn iu ny b gz pc pd l pe pf"># load JS visualization code to notebook<br/>shap.initjs()</span><span id="635c" class="nk mn iu ny b gz pg pd l pe pf"># visualize the training set predictions<br/>shap.force_plot(explainer.expected_value, shap_values, X)</span></pre><figure class="kt ku kv kw gu kx gi gj paragraph-image"><div role="button" tabindex="0" class="ky kz di la bf lb"><div class="gi gj pk"><img src="../Images/abca02635a76a6d88dff9ac5e9b5cc8c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Sc49lKXIftIKputWc7n3Ag.png"/></div></div></figure><h2 id="830a" class="nk mn iu bd mo nl nm dn ms nn no dp mw lz np nq my md nr ns na mh nt nu nc ja bi translated">依赖图</h2><p id="c6dd" class="pw-post-body-paragraph lq lr iu ls b lt ne ke lv lw nf kh ly lz ng mb mc md nh mf mg mh ni mj mk ml in bi translated">为了理解单个特征如何影响模型的输出，可以使用依赖图。部分相关图说明了一个或多个特征与目标变量之间的关系。这种关系可以是线性的或非线性的(指数、二次等)。).注意，<code class="fe nv nw nx ny b">dependence_plot()</code>方法会自动添加另一个与给定特性交互最多的特性。</p><p id="ba2e" class="pw-post-body-paragraph lq lr iu ls b lt lu ke lv lw lx kh ly lz ma mb mc md me mf mg mh mi mj mk ml in bi translated">在下图中，<code class="fe nv nw nx ny b">LSTAT</code>特征与<code class="fe nv nw nx ny b">CRIM</code>特征交互最多。从图中还可以看出,<code class="fe nv nw nx ny b">LSTAT</code>和目标变量之间存在线性关系(负)。</p><pre class="kt ku kv kw gu oy ny oz pa aw pb bi"><span id="7dbd" class="nk mn iu ny b gz pc pd l pe pf">shap.dependence_plot('LSTAT', shap_values, X_train)</span></pre><figure class="kt ku kv kw gu kx gi gj paragraph-image"><div class="gi gj pl"><img src="../Images/0279bf414f5b6e792b0407167e41c821.png" data-original-src="https://miro.medium.com/v2/resize:fit:1230/format:webp/1*CmVyeuFTDLASqiNse_4J2g.png"/></div></figure><h2 id="47a6" class="nk mn iu bd mo nl nm dn ms nn no dp mw lz np nq my md nr ns na mh nt nu nc ja bi translated">汇总图</h2><p id="cf62" class="pw-post-body-paragraph lq lr iu ls b lt ne ke lv lw nf kh ly lz ng mb mc md nh mf mg mh ni mj mk ml in bi translated">摘要图用于找出对模型最重要的特征。在下面的示例中，我们绘制了每个样本的每个要素的SHAP值。然后，根据所有样本的SHAP值的总和对该图进行排序。</p><pre class="kt ku kv kw gu oy ny oz pa aw pb bi"><span id="454c" class="nk mn iu ny b gz pc pd l pe pf">shap.summary_plot(shap_values, X_train)</span></pre><figure class="kt ku kv kw gu kx gi gj paragraph-image"><div class="gi gj pm"><img src="../Images/4815ab9eb8ee74a62d8afb891b9f63d0.png" data-original-src="https://miro.medium.com/v2/resize:fit:1306/format:webp/1*ZyOlelZDF-_NZivHznIVVA.png"/></div></figure><ul class=""><li id="b588" class="of og iu ls b lt lu lw lx lz oh md oi mh oj ml ok ol om on bi translated">特征按<code class="fe nv nw nx ny b">feature importance</code>降序排列。</li><li id="905b" class="of og iu ls b lt oo lw op lz oq md or mh os ml ok ol om on bi translated"><code class="fe nv nw nx ny b">Color</code>表示该变量在该观察中是高(红色)还是低(蓝色)。</li><li id="942b" class="of og iu ls b lt oo lw op lz oq md or mh os ml ok ol om on bi translated">每个特征水平线上的每个点显示了该值<em class="nj">的影响是与更高(红色)还是更低(蓝色)的预测</em>相关联。</li><li id="999d" class="of og iu ls b lt oo lw op lz oq md or mh os ml ok ol om on bi translated">我们还可以看到每个特征和目标变量之间的<code class="fe nv nw nx ny b">correlation</code>。一个<em class="nj">高</em>水平的“RM”对房价有着高<em class="nj">正</em>的影响。请注意，“高”来自红色，而“积极”影响显示在X轴上。同样，我们可以说“DIS”的高值与目标变量负相关。</li></ul><p id="0d34" class="pw-post-body-paragraph lq lr iu ls b lt lu ke lv lw lx kh ly lz ma mb mc md me mf mg mh mi mj mk ml in bi translated">带<code class="fe nv nw nx ny b">plot_type='bar'</code>的汇总图将给出变量重要性图。预测能力高的特征显示在顶部，预测能力低的特征显示在底部。</p><pre class="kt ku kv kw gu oy ny oz pa aw pb bi"><span id="a08e" class="nk mn iu ny b gz pc pd l pe pf">shap.summary_plot(shap_values, X_train, plot_type='bar')</span></pre><figure class="kt ku kv kw gu kx gi gj paragraph-image"><div class="gi gj pn"><img src="../Images/04a9a75def3d1e7ee86133c8b8b1e1f2.png" data-original-src="https://miro.medium.com/v2/resize:fit:1368/format:webp/1*CKn4wJKjbjKqgppuuXvkkw.png"/></div></figure><p id="a1b1" class="pw-post-body-paragraph lq lr iu ls b lt lu ke lv lw lx kh ly lz ma mb mc md me mf mg mh mi mj mk ml in bi translated">这里，我们只是通过TreeExplainer方法来解释模型。您可以探索其余的方法/算法— DeepExplainer、kernelExplainer、LinearExplainer和GradientExplainer。</p><h1 id="abf9" class="mm mn iu bd mo mp ot mr ms mt ou mv mw kj ov kk my km ow kn na kp ox kq nc nd bi translated">完全码</h1><p id="a56a" class="pw-post-body-paragraph lq lr iu ls b lt ne ke lv lw nf kh ly lz ng mb mc md nh mf mg mh ni mj mk ml in bi translated">您可以在下面找到完整的代码。请注意，下面的代码中加载了一些可视化效果，因为它需要加载javascript。</p><figure class="kt ku kv kw gu kx"><div class="bz fq l di"><div class="po pi l"/></div></figure><h1 id="61bf" class="mm mn iu bd mo mp ot mr ms mt ou mv mw kj ov kk my km ow kn na kp ox kq nc nd bi translated">结论</h1><p id="8745" class="pw-post-body-paragraph lq lr iu ls b lt ne ke lv lw nf kh ly lz ng mb mc md nh mf mg mh ni mj mk ml in bi translated">在这篇文章中，你已经理解了一个流行的可解释的人工智能框架SHAP。在这个过程中，你已经理解了它是如何与联盟博弈论、Shapley值、Shap值等联系起来的。对于好奇的读者，我建议你进一步探索SHAP图书馆以获得最大的收获，并浏览参考资料部分提到的链接。</p><p id="7732" class="pw-post-body-paragraph lq lr iu ls b lt lu ke lv lw lx kh ly lz ma mb mc md me mf mg mh mi mj mk ml in bi translated"><em class="nj">阅读更多关于Python和数据科学的此类有趣文章，</em> <a class="ae li" href="https://pythonsimplified.com/" rel="noopener ugc nofollow" target="_blank"> <strong class="ls je"> <em class="nj">订阅</em> </strong> </a> <em class="nj">到我的博客</em><a class="ae li" href="http://www.pythonsimplified.com" rel="noopener ugc nofollow" target="_blank"><strong class="ls je"><em class="nj">www.pythonsimplified.com</em></strong></a><strong class="ls je"><em class="nj">。</em> </strong>你也可以通过<a class="ae li" href="https://www.linkedin.com/in/chetanambi/" rel="noopener ugc nofollow" target="_blank"> <strong class="ls je"> LinkedIn </strong> </a>联系我。</p></div><div class="ab cl lj lk hy ll" role="separator"><span class="lm bw bk ln lo lp"/><span class="lm bw bk ln lo lp"/><span class="lm bw bk ln lo"/></div><div class="in io ip iq ir"><p id="20a0" class="pw-post-body-paragraph lq lr iu ls b lt lu ke lv lw lx kh ly lz ma mb mc md me mf mg mh mi mj mk ml in bi translated">为了节省你的时间，我列出了你可能会感兴趣的相同主题的文章，即可解释的人工智能。</p><div class="pp pq gq gs pr ps"><a href="https://towardsdatascience.com/5-explainable-ai-xai-frameworks-92359b661e33" rel="noopener follow" target="_blank"><div class="pt ab fp"><div class="pu ab pv cl cj pw"><h2 class="bd je gz z fq px fs ft py fv fx jd bi translated">5个可解释的人工智能(XAI)框架</h2><div class="pz l"><h3 class="bd b gz z fq px fs ft py fv fx dk translated">…您可以开始在您的机器学习项目中使用</h3></div><div class="qa l"><p class="bd b dl z fq px fs ft py fv fx dk translated">towardsdatascience.com</p></div></div><div class="qb l"><div class="qc l qd qe qf qb qg lc ps"/></div></div></a></div><div class="pp pq gq gs pr ps"><a href="https://medium.com/towards-artificial-intelligence/lime-explaining-any-machine-learning-prediction-d663c457a740" rel="noopener follow" target="_blank"><div class="pt ab fp"><div class="pu ab pv cl cj pw"><h2 class="bd je gz z fq px fs ft py fv fx jd bi translated">LIME解释任何机器学习预测</h2><div class="pz l"><h3 class="bd b gz z fq px fs ft py fv fx dk translated">用石灰向可解释的人工智能迈出第一步</h3></div><div class="qa l"><p class="bd b dl z fq px fs ft py fv fx dk translated">medium.com</p></div></div><div class="qb l"><div class="qh l qd qe qf qb qg lc ps"/></div></div></a></div></div><div class="ab cl lj lk hy ll" role="separator"><span class="lm bw bk ln lo lp"/><span class="lm bw bk ln lo lp"/><span class="lm bw bk ln lo"/></div><div class="in io ip iq ir"><h1 id="30b8" class="mm mn iu bd mo mp mq mr ms mt mu mv mw kj mx kk my km mz kn na kp nb kq nc nd bi translated">参考</h1><div class="pp pq gq gs pr ps"><a href="https://christophm.github.io/interpretable-ml-book/shap.html" rel="noopener  ugc nofollow" target="_blank"><div class="pt ab fp"><div class="pu ab pv cl cj pw"><h2 class="bd je gz z fq px fs ft py fv fx jd bi translated">5.10 SHAP (SHapley附加解释)|可解释的机器学习</h2><div class="pz l"><h3 class="bd b gz z fq px fs ft py fv fx dk translated">本章目前仅在此网络版本中可用。电子书和印刷品将紧随其后。SHAP(沙普利添加剂…</h3></div><div class="qa l"><p class="bd b dl z fq px fs ft py fv fx dk translated">christophm.github.io</p></div></div><div class="qb l"><div class="qi l qd qe qf qb qg lc ps"/></div></div></a></div><div class="pp pq gq gs pr ps"><a href="https://github.com/slundberg/shap" rel="noopener  ugc nofollow" target="_blank"><div class="pt ab fp"><div class="pu ab pv cl cj pw"><h2 class="bd je gz z fq px fs ft py fv fx jd bi translated">slundberg/shap</h2><div class="pz l"><h3 class="bd b gz z fq px fs ft py fv fx dk translated">SHAP是一种博弈论的方法来解释任何机器学习模型的输出…</h3></div><div class="qa l"><p class="bd b dl z fq px fs ft py fv fx dk translated">github.com</p></div></div><div class="qb l"><div class="qj l qd qe qf qb qg lc ps"/></div></div></a></div></div></div>    
</body>
</html>