<html>
<head>
<title>The NLP Cypher | 11.29.20</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">NLP密码| 11.29.20</h1>
<blockquote>原文：<a href="https://pub.towardsai.net/the-nlp-cypher-11-29-20-1a82e2749e2f?source=collection_archive---------3-----------------------#2020-11-29">https://pub.towardsai.net/the-nlp-cypher-11-29-20-1a82e2749e2f?source=collection_archive---------3-----------------------#2020-11-29</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><figure class="ip iq gp gr ir is gh gi paragraph-image"><div role="button" tabindex="0" class="it iu di iv bf iw"><div class="gh gi io"><img src="../Images/940579551fe093e3ed4338bda44492ad.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*GUvBAnkusODRHTn0"/></div></div><figcaption class="iz ja gj gh gi jb jc bd b be z dk translated">在<a class="ae jd" href="https://twitter.com/vboykis" rel="noopener ugc nofollow" target="_blank"> @vboykis </a>的推特上找到的</figcaption></figure><h2 id="f8f1" class="je jf jg bd b dl jh ji jj jk jl jm dk jn translated" aria-label="kicker paragraph">自然语言处理每周时事通讯</h2><div class=""/><div class=""><h2 id="01fe" class="pw-subtitle-paragraph km jp jg bd b kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld dk translated">上帝之手</h2></div></div><div class="ab cl le lf hu lg" role="separator"><span class="lh bw bk li lj lk"/><span class="lh bw bk li lj lk"/><span class="lh bw bk li lj"/></div><div class="ij ik il im in"><p id="60ae" class="pw-post-body-paragraph ll lm jg ln b lo lp kq lq lr ls kt lt lu lv lw lx ly lz ma mb mc md me mf mg ij bi mh translated"><span class="l mi mj mk bm ml mm mn mo mp di"> H </span> ey，欢迎回来，刚度假回来。庆祝感恩节快乐。鉴于假期休息，这是一个缓慢的一周，所以时事通讯会比平时短一点，但这并不意味着我们不能讨论外星人的巨石…</p><p id="d3b9" class="pw-post-body-paragraph ll lm jg ln b lo lp kq lq lr ls kt lt lu lv lw lx ly lz ma mb mc md me mf mg ij bi translated">如果你还没听说，在犹他州的一个国家公园里，发现了一块未知的巨石。目前，没有人知道它是从哪里来的。</p><figure class="mr ms mt mu gt is gh gi paragraph-image"><div role="button" tabindex="0" class="it iu di iv bf iw"><div class="gh gi mq"><img src="../Images/ea903c188309d3eb86debabfb16f338c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*1C-nb8ynEpHWb3vi.jpeg"/></div></div><figcaption class="iz ja gj gh gi jb jc bd b be z dk">👽</figcaption></figure><p id="a642" class="pw-post-body-paragraph ll lm jg ln b lo lp kq lq lr ls kt lt lu lv lw lx ly lz ma mb mc md me mf mg ij bi translated">没多久就有人洗劫了它😭。</p><figure class="mr ms mt mu gt is gh gi paragraph-image"><div role="button" tabindex="0" class="it iu di iv bf iw"><div class="gh gi mv"><img src="../Images/a164179ebfa0edf01bba25a6ddca1058.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*dCi15Pa0eYqy3RUW.jpg"/></div></div><figcaption class="iz ja gj gh gi jb jc bd b be z dk">👽</figcaption></figure><h2 id="44d5" class="mw mx jg bd my mz na dn nb nc nd dp ne lu nf ng nh ly ni nj nk mc nl nm nn jm bi translated">软件更新</h2><p id="8bbb" class="pw-post-body-paragraph ll lm jg ln b lo no kq lq lr np kt lt lu nq lw lx ly nr ma mb mc ns me mf mg ij bi translated">法国南部（French Southern Territories的缩写）</p><div class="ip iq gp gr ir nt"><a href="https://github.com/tensorflow/tensorflow/releases/tag/v2.4.0-rc3" rel="noopener  ugc nofollow" target="_blank"><div class="nu ab fo"><div class="nv ab nw cl cj nx"><h2 class="bd jq gy z fp ny fr fs nz fu fw jp bi translated">发布tensor flow 2 . 4 . 0-rc3 tensor flow/tensor flow</h2><div class="oa l"><h3 class="bd b gy z fp ny fr fs nz fu fw dk translated">tf.distribute引入了对Keras模型异步训练的实验性支持。</h3></div><div class="ob l"><p class="bd b dl z fp ny fr fs nz fu fw dk translated">github.com</p></div></div><div class="oc l"><div class="od l oe of og oc oh ix nt"/></div></div></a></div><p id="3776" class="pw-post-body-paragraph ll lm jg ln b lo lp kq lq lr ls kt lt lu lv lw lx ly lz ma mb mc md me mf mg ij bi">&amp;</p><p id="70d7" class="pw-post-body-paragraph ll lm jg ln b lo lp kq lq lr ls kt lt lu lv lw lx ly lz ma mb mc md me mf mg ij bi translated">您现在可以在Transformers库上并行化模型了！</p><figure class="mr ms mt mu gt is gh gi paragraph-image"><div role="button" tabindex="0" class="it iu di iv bf iw"><div class="gh gi oi"><img src="../Images/b0a79157aebab9de5c050334f0ff7b10.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*mznQHnSbvPGWip7f"/></div></div></figure></div><div class="ab cl le lf hu lg" role="separator"><span class="lh bw bk li lj lk"/><span class="lh bw bk li lj lk"/><span class="lh bw bk li lj"/></div><div class="ij ik il im in"><p id="ba6c" class="pw-post-body-paragraph ll lm jg ln b lo lp kq lq lr ls kt lt lu lv lw lx ly lz ma mb mc md me mf mg ij bi translated">顺便说一下，本周早些时候，我们向<a class="ae jd" href="https://datasets.quantumstat.com/" rel="noopener ugc nofollow" target="_blank">大坏NLP数据库</a>添加了50个新数据集:亮点包括IndoNLU基准测试和来自EMNLP的几个数据集，感谢Ulrich Schä fer和Neea Rusch的贡献！</p><p id="02fd" class="pw-post-body-paragraph ll lm jg ln b lo lp kq lq lr ls kt lt lu lv lw lx ly lz ma mb mc md me mf mg ij bi translated">附:如果你喜欢今天的文章，请不要犹豫，给一个👏👏！谢谢大家！</p></div><div class="ab cl le lf hu lg" role="separator"><span class="lh bw bk li lj lk"/><span class="lh bw bk li lj lk"/><span class="lh bw bk li lj"/></div><div class="ij ik il im in"><h1 id="ec4a" class="oj mx jg bd my ok ol om nb on oo op ne kv oq kw nh ky or kz nk lb os lc nn ot bi translated">GNN图书</h1><p id="130b" class="pw-post-body-paragraph ll lm jg ln b lo no kq lq lr np kt lt lu nq lw lx ly nr ma mb mc ns me mf mg ij bi translated">嘿，想要一个关于图形神经网络的精彩介绍吗？发现了威廉·哈密顿的“图形表示学习”书的出版前版本。</p><p id="1f78" class="pw-post-body-paragraph ll lm jg ln b lo lp kq lq lr ls kt lt lu lv lw lx ly lz ma mb mc md me mf mg ij bi translated">它写得非常好，用优雅的简单性说明了机器学习中这个新兴的话题。</p><p id="15c4" class="pw-post-body-paragraph ll lm jg ln b lo lp kq lq lr ls kt lt lu lv lw lx ly lz ma mb mc md me mf mg ij bi translated"><strong class="ln jq">目录</strong></p><ul class=""><li id="2b00" class="ou ov jg ln b lo lp lr ls lu ow ly ox mc oy mg oz pa pb pc bi translated">第一章:引言和动机<a class="ae jd" href="https://www.cs.mcgill.ca/~wlh/grl_book/files/GRL_Book-Chapter_1-Intro.pdf" rel="noopener ugc nofollow" target="_blank">【草稿。2020年9月更新。】</a></li><li id="ee44" class="ou ov jg ln b lo pd lr pe lu pf ly pg mc ph mg oz pa pb pc bi translated">第2章:背景和传统方法<a class="ae jd" href="https://www.cs.mcgill.ca/~wlh/grl_book/files/GRL_Book-Chapter_2-Background.pdf" rel="noopener ugc nofollow" target="_blank">【草案。2020年9月更新。] </a></li></ul><p id="ffe4" class="pw-post-body-paragraph ll lm jg ln b lo lp kq lq lr ls kt lt lu lv lw lx ly lz ma mb mc md me mf mg ij bi translated"><strong class="ln jq">第一部分:节点嵌入</strong></p><ul class=""><li id="f359" class="ou ov jg ln b lo lp lr ls lu ow ly ox mc oy mg oz pa pb pc bi translated">第三章:邻域重建方法<a class="ae jd" href="https://www.cs.mcgill.ca/~wlh/grl_book/files/GRL_Book-Chapter_3-Node_Embeddings.pdf" rel="noopener ugc nofollow" target="_blank">【草稿。2020年9月更新。】</a></li><li id="b1c2" class="ou ov jg ln b lo pd lr pe lu pf ly pg mc ph mg oz pa pb pc bi translated">第4章:多关系数据和知识图<a class="ae jd" href="https://www.cs.mcgill.ca/~wlh/grl_book/files/GRL_Book-Chapter_4-Knowledge_Graphs.pdf" rel="noopener ugc nofollow" target="_blank">【草稿。2020年9月更新。】</a></li></ul><p id="b971" class="pw-post-body-paragraph ll lm jg ln b lo lp kq lq lr ls kt lt lu lv lw lx ly lz ma mb mc md me mf mg ij bi translated"><strong class="ln jq">第二部分:图形神经网络</strong></p><ul class=""><li id="1397" class="ou ov jg ln b lo lp lr ls lu ow ly ox mc oy mg oz pa pb pc bi translated">第五章:图形神经网络模型<a class="ae jd" href="https://www.cs.mcgill.ca/~wlh/grl_book/files/GRL_Book-Chapter_5-GNNs.pdf" rel="noopener ugc nofollow" target="_blank">【草案】。2020年9月更新。] </a></li><li id="f3aa" class="ou ov jg ln b lo pd lr pe lu pf ly pg mc ph mg oz pa pb pc bi translated">第六章:实践中的图形神经网络。2020年9月更新。] </li><li id="d29b" class="ou ov jg ln b lo pd lr pe lu pf ly pg mc ph mg oz pa pb pc bi translated">第七章:理论动机<a class="ae jd" href="https://www.cs.mcgill.ca/~wlh/grl_book/files/GRL_Book-Chapter_7-GNN_Theory.pdf" rel="noopener ugc nofollow" target="_blank">【草稿。2020年9月更新。] </a></li></ul><p id="df7a" class="pw-post-body-paragraph ll lm jg ln b lo lp kq lq lr ls kt lt lu lv lw lx ly lz ma mb mc md me mf mg ij bi translated"><strong class="ln jq">第三部分:生成图模型</strong></p><ul class=""><li id="befa" class="ou ov jg ln b lo lp lr ls lu ow ly ox mc oy mg oz pa pb pc bi translated">第八章:传统图形生成方法<a class="ae jd" href="https://www.cs.mcgill.ca/~wlh/grl_book/files/GRL_Book-Chapter_8-Traditional_Graph_Generation.pdf" rel="noopener ugc nofollow" target="_blank">【草稿】。2020年9月更新。] </a></li><li id="4841" class="ou ov jg ln b lo pd lr pe lu pf ly pg mc ph mg oz pa pb pc bi translated">第九章:深度生成模型<a class="ae jd" href="https://www.cs.mcgill.ca/~wlh/grl_book/files/GRL_Book-Chapter_9-Deep_Graph_Generation.pdf" rel="noopener ugc nofollow" target="_blank">【草稿。2020年9月更新。】</a></li></ul><div class="ip iq gp gr ir nt"><a href="https://www.cs.mcgill.ca/~wlh/grl_book/" rel="noopener  ugc nofollow" target="_blank"><div class="nu ab fo"><div class="nv ab nw cl cj nx"><h2 class="bd jq gy z fp ny fr fs nz fu fw jp bi translated">图形表示学习手册</h2><div class="oa l"><h3 class="bd b gy z fp ny fr fs nz fu fw dk translated">在过去的七年里，图形表示学习领域以令人难以置信的(有时甚至是笨拙的)速度发展</h3></div><div class="ob l"><p class="bd b dl z fp ny fr fs nz fu fw dk translated">www.cs.mcgill.ca</p></div></div></div></a></div><p id="5f1f" class="pw-post-body-paragraph ll lm jg ln b lo lp kq lq lr ls kt lt lu lv lw lx ly lz ma mb mc md me mf mg ij bi translated">PDF <a class="ae jd" href="https://www.cs.mcgill.ca/~wlh/grl_book/files/GRL_Book.pdf" rel="noopener ugc nofollow" target="_blank">图形表示学习</a></p><h1 id="51df" class="oj mx jg bd my ok pi om nb on pj op ne kv pk kw nh ky pl kz nk lb pm lc nn ot bi translated">语言解释</h1><p id="1c76" class="pw-post-body-paragraph ll lm jg ln b lo no kq lq lr np kt lt lu nq lw lx ly nr ma mb mc ns me mf mg ij bi translated">语言能帮助我们更好地训练模型吗？</p><blockquote class="pn po pp"><p id="62a0" class="ll lm pq ln b lo lp kq lq lr ls kt lt pr lv lw lx ps lz ma mb pt md me mf mg ij bi translated">“同样，我们可以采用输入x，并提取特征(例如，某些单词的存在)来训练模型，我们可以使用解释来提供附加特征。”</p></blockquote><p id="99cb" class="pw-post-body-paragraph ll lm jg ln b lo lp kq lq lr ls kt lt lu lv lw lx ly lz ma mb mc md me mf mg ij bi translated">在斯坦福人工智能的一篇新博客文章中，他们讨论了为什么通过语言教授模型知识如此困难的问题，以及从NLP角度(即他们讨论了今年早些时候的ExpBERT论文)和计算机视觉角度(即他们的视觉感知论文)的可能解决方案</p><div class="ip iq gp gr ir nt"><a href="http://ai.stanford.edu/blog/learning-from-language/" rel="noopener  ugc nofollow" target="_blank"><div class="nu ab fo"><div class="nv ab nw cl cj nx"><h2 class="bd jq gy z fp ny fr fs nz fu fw jp bi translated">从语言解释中学习</h2><div class="oa l"><h3 class="bd b gy z fp ny fr fs nz fu fw dk translated">假设你是一个机器学习从业者，你想解决一些分类问题，比如分类…</h3></div><div class="ob l"><p class="bd b dl z fp ny fr fs nz fu fw dk translated">ai.stanford.edu</p></div></div><div class="oc l"><div class="pu l oe of og oc oh ix nt"/></div></div></a></div><p id="7e2e" class="pw-post-body-paragraph ll lm jg ln b lo lp kq lq lr ls kt lt lu lv lw lx ly lz ma mb mc md me mf mg ij bi translated"><strong class="ln jq"> ExpBERT在博客中讨论的GitHub</strong>:</p><div class="ip iq gp gr ir nt"><a href="https://github.com/MurtyShikhar/ExpBERT" rel="noopener  ugc nofollow" target="_blank"><div class="nu ab fo"><div class="nv ab nw cl cj nx"><h2 class="bd jq gy z fp ny fr fs nz fu fw jp bi translated">MurtyShikhar/ExpBERT</h2><div class="oa l"><h3 class="bd b gy z fp ny fr fs nz fu fw dk translated">这个库包含代码、脚本、数据和检查点，用于运行以下论文中的实验</h3></div><div class="ob l"><p class="bd b dl z fp ny fr fs nz fu fw dk translated">github.com</p></div></div><div class="oc l"><div class="pv l oe of og oc oh ix nt"/></div></div></a></div><h1 id="f44a" class="oj mx jg bd my ok pi om nb on pj op ne kv pk kw nh ky pl kz nk lb pm lc nn ot bi translated">数据加载器PyTorch</h1><p id="7fee" class="pw-post-body-paragraph ll lm jg ln b lo no kq lq lr np kt lt lu nq lw lx ly nr ma mb mc ns me mf mg ij bi translated">来自PaperSpace的有趣的博客文章讨论了PyTorch中的DataLoader类。如果您对使用预先存在的数据集感兴趣，或者甚至对在数字或文本数据上使用您自己的自定义数据集感兴趣，他们在PyTorch中总结了这个方便的类。目录:</p><ul class=""><li id="8e7c" class="ou ov jg ln b lo lp lr ls lu ow ly ox mc oy mg oz pa pb pc bi translated">处理数据集</li><li id="d4cb" class="ou ov jg ln b lo pd lr pe lu pf ly pg mc ph mg oz pa pb pc bi translated">PyTorch中的数据加载</li><li id="3300" class="ou ov jg ln b lo pd lr pe lu pf ly pg mc ph mg oz pa pb pc bi translated">深入查看MNIST数据集</li><li id="0ffb" class="ou ov jg ln b lo pd lr pe lu pf ly pg mc ph mg oz pa pb pc bi translated">转换和重新调整数据</li><li id="21d2" class="ou ov jg ln b lo pd lr pe lu pf ly pg mc ph mg oz pa pb pc bi translated">在PyTorch中创建自定义数据集</li></ul><p id="ef14" class="pw-post-body-paragraph ll lm jg ln b lo lp kq lq lr ls kt lt lu lv lw lx ly lz ma mb mc md me mf mg ij bi translated"><strong class="ln jq">博客</strong>:</p><div class="ip iq gp gr ir nt"><a href="https://blog.paperspace.com/dataloaders-abstractions-pytorch/" rel="noopener  ugc nofollow" target="_blank"><div class="nu ab fo"><div class="nv ab nw cl cj nx"><h2 class="bd jq gy z fp ny fr fs nz fu fw jp bi translated">PyTorch | Paperspace博客中的DataLoader类的完整指南</h2><div class="oa l"><h3 class="bd b gy z fp ny fr fs nz fu fw dk translated">在这篇文章中，我们将处理机器学习和深度学习领域最具挑战性的问题之一…</h3></div><div class="ob l"><p class="bd b dl z fp ny fr fs nz fu fw dk translated">blog.paperspace.com</p></div></div><div class="oc l"><div class="pw l oe of og oc oh ix nt"/></div></div></a></div><h1 id="4471" class="oj mx jg bd my ok pi om nb on pj op ne kv pk kw nh ky pl kz nk lb pm lc nn ot bi translated">回购密码👨‍💻</h1><h2 id="ab94" class="mw mx jg bd my mz na dn nb nc nd dp ne lu nf ng nh ly ni nj nk mc nl nm nn jm bi translated">一组最近发布的回购文件引起了我们的关注👁</h2></div><div class="ab cl le lf hu lg" role="separator"><span class="lh bw bk li lj lk"/><span class="lh bw bk li lj lk"/><span class="lh bw bk li lj"/></div><div class="ij ik il im in"><h2 id="8cb0" class="mw mx jg bd my mz na dn nb nc nd dp ne lu nf ng nh ly ni nj nk mc nl nm nn jm bi translated">神经声学</h2><blockquote class="pn po pp"><p id="818c" class="ll lm pq ln b lo lp kq lq lr ls kt lt pr lv lw lx ps lz ma mb pt md me mf mg ij bi translated">一个使用转换器为带有不同口音的英语语音数据建模的库。</p></blockquote><div class="ip iq gp gr ir nt"><a href="https://github.com/Bartelds/neural-acoustic-distance" rel="noopener  ugc nofollow" target="_blank"><div class="nu ab fo"><div class="nv ab nw cl cj nx"><h2 class="bd jq gy z fp ny fr fs nz fu fw jp bi translated">巴特尔兹/神经声学距离</h2><div class="oa l"><h3 class="bd b gy z fp ny fr fs nz fu fw dk translated">与论文相关的代码:模拟英语语音变化的神经表征。git克隆…</h3></div><div class="ob l"><p class="bd b dl z fp ny fr fs nz fu fw dk translated">github.com</p></div></div><div class="oc l"><div class="px l oe of og oc oh ix nt"/></div></div></a></div><p id="a185" class="pw-post-body-paragraph ll lm jg ln b lo lp kq lq lr ls kt lt lu lv lw lx ly lz ma mb mc md me mf mg ij bi translated"><a class="ae jd" href="http://accent.gmu.edu/" rel="noopener ugc nofollow" target="_blank"><strong class="ln jq"/>演讲口音档案</a></p><h2 id="d31f" class="mw mx jg bd my mz na dn nb nc nd dp ne lu nf ng nh ly ni nj nk mc nl nm nn jm bi translated">RELVM</h2><blockquote class="pn po pp"><p id="fe5f" class="ll lm pq ln b lo lp kq lq lr ls kt lt pr lv lw lx ps lz ma mb pt md me mf mg ij bi translated">Repo用于在实体和实体出现的上下文(即句子)对上训练潜在变量生成模型。他们的模型可用于执行提及级别和配对级别的分类。</p></blockquote><div class="ip iq gp gr ir nt"><a href="https://github.com/BenevolentAI/RELVM" rel="noopener  ugc nofollow" target="_blank"><div class="nu ab fo"><div class="nv ab nw cl cj nx"><h2 class="bd jq gy z fp ny fr fs nz fu fw jp bi translated">BenevolentAI/RELVM</h2><div class="oa l"><h3 class="bd b gy z fp ny fr fs nz fu fw dk translated">这个知识库包含了论文“学习生物医学关系的信息表示……</h3></div><div class="ob l"><p class="bd b dl z fp ny fr fs nz fu fw dk translated">github.com</p></div></div><div class="oc l"><div class="py l oe of og oc oh ix nt"/></div></div></a></div><p id="b43f" class="pw-post-body-paragraph ll lm jg ln b lo lp kq lq lr ls kt lt lu lv lw lx ly lz ma mb mc md me mf mg ij bi translated"><a class="ae jd" href="https://arxiv.org/pdf/2011.09658.pdf" rel="noopener ugc nofollow" target="_blank"> <strong class="ln jq">纸</strong> </a></p><h2 id="0273" class="mw mx jg bd my mz na dn nb nc nd dp ne lu nf ng nh ly ni nj nk mc nl nm nn jm bi translated">GLGE基准</h2><blockquote class="pn po pp"><p id="102f" class="ll lm pq ln b lo lp kq lq lr ls kt lt pr lv lw lx ps lz ma mb pt md me mf mg ij bi translated">一个新的自然语言生成(NLG)基准，由8个语言生成任务组成，包括抽象文本摘要(CNN/DailyMail，Gigaword，XSUM，MSNews)，答案感知问题生成(SQuAD 1.1，MSQG)，对话式问题回答(CoQA)，个性化对话(Personachat)。</p></blockquote><div class="ip iq gp gr ir nt"><a href="https://github.com/microsoft/glge" rel="noopener  ugc nofollow" target="_blank"><div class="nu ab fo"><div class="nv ab nw cl cj nx"><h2 class="bd jq gy z fp ny fr fs nz fu fw jp bi translated">微软/通用电气</h2><div class="oa l"><h3 class="bd b gy z fp ny fr fs nz fu fw dk translated">这个库包含关于通用语言生成评估基准GLGE的信息，它由…</h3></div><div class="ob l"><p class="bd b dl z fp ny fr fs nz fu fw dk translated">github.com</p></div></div><div class="oc l"><div class="pz l oe of og oc oh ix nt"/></div></div></a></div><p id="b92d" class="pw-post-body-paragraph ll lm jg ln b lo lp kq lq lr ls kt lt lu lv lw lx ly lz ma mb mc md me mf mg ij bi translated">此外，</p><blockquote class="pn po pp"><p id="5025" class="ll lm pq ln b lo lp kq lq lr ls kt lt pr lv lw lx ps lz ma mb pt md me mf mg ij bi translated">微软强调了一个新的预训练语言模型，称为ProphetNet，用于序列到序列学习，具有一个新的自我监督目标，称为未来n-gram预测。</p></blockquote><div class="ip iq gp gr ir nt"><a href="https://github.com/microsoft/ProphetNet" rel="noopener  ugc nofollow" target="_blank"><div class="nu ab fo"><div class="nv ab nw cl cj nx"><h2 class="bd jq gy z fp ny fr fs nz fu fw jp bi translated">微软/预言网</h2><div class="oa l"><h3 class="bd b gy z fp ny fr fs nz fu fw dk translated">这个报告提供了代码，以重现ProphetNet中的实验:预测未来的N-gram为…</h3></div><div class="ob l"><p class="bd b dl z fp ny fr fs nz fu fw dk translated">github.com</p></div></div><div class="oc l"><div class="qa l oe of og oc oh ix nt"/></div></div></a></div><h2 id="6fbf" class="mw mx jg bd my mz na dn nb nc nd dp ne lu nf ng nh ly ni nj nk mc nl nm nn jm bi translated">OpenTQA</h2><blockquote class="pn po pp"><p id="9706" class="ll lm pq ln b lo lp kq lq lr ls kt lt pr lv lw lx ps lz ma mb pt md me mf mg ij bi translated">OPENTQA是教科书问答任务的开放框架。教科书式的问题回答(TQA)是在一个由大量文章和图表组成的多模态背景下，回答一个图表/非图表问题。</p></blockquote><figure class="mr ms mt mu gt is gh gi paragraph-image"><div role="button" tabindex="0" class="it iu di iv bf iw"><div class="gh gi qb"><img src="../Images/1790d3ce175e448cda3e5a10670f637b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*EStNpd7CNKzK8rla.png"/></div></div></figure><div class="ip iq gp gr ir nt"><a href="https://github.com/keep-smile-001/opentqa" rel="noopener  ugc nofollow" target="_blank"><div class="nu ab fo"><div class="nv ab nw cl cj nx"><h2 class="bd jq gy z fp ny fr fs nz fu fw jp bi translated">保持微笑-001/opentqa</h2><div class="oa l"><h3 class="bd b gy z fp ny fr fs nz fu fw dk translated">OPENTQA是一个开放的教科书问题回答框架。</h3></div><div class="ob l"><p class="bd b dl z fp ny fr fs nz fu fw dk translated">github.com</p></div></div><div class="oc l"><div class="qc l oe of og oc oh ix nt"/></div></div></a></div><h1 id="2eb1" class="oj mx jg bd my ok pi om nb on pj op ne kv pk kw nh ky pl kz nk lb pm lc nn ot bi translated">本周数据集:人工智能问答(鹌鹑)</h1><h2 id="1396" class="mw mx jg bd my mz na dn nb nc nd dp ne lu nf ng nh ly ni nj nk mc nl nm nn jm bi translated">这是什么？</h2><p id="5c15" class="pw-post-body-paragraph ll lm jg ln b lo no kq lq lr np kt lt lu nq lw lx ly nr ma mb mc ns me mf mg ij bi translated">QuAIL包含15K多项选择题，文本长度为300-350个标记，跨越4个领域(新闻、用户故事、小说、博客)。</p><h2 id="7ce9" class="mw mx jg bd my mz na dn nb nc nd dp ne lu nf ng nh ly ni nj nk mc nl nm nn jm bi translated">样品</h2><figure class="mr ms mt mu gt is gh gi paragraph-image"><div role="button" tabindex="0" class="it iu di iv bf iw"><div class="gh gi qd"><img src="../Images/f5189cd80da8bdcf2034856a56ca9d15.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*2Tra5RqVfGckEueE.png"/></div></div></figure><h2 id="c112" class="mw mx jg bd my mz na dn nb nc nd dp ne lu nf ng nh ly ni nj nk mc nl nm nn jm bi translated">它在哪里？</h2><div class="ip iq gp gr ir nt"><a href="https://github.com/text-machine-lab/quail/" rel="noopener  ugc nofollow" target="_blank"><div class="nu ab fo"><div class="nv ab nw cl cj nx"><h2 class="bd jq gy z fp ny fr fs nz fu fw jp bi translated">文本-机器-实验室/鹌鹑</h2><div class="oa l"><h3 class="bd b gy z fp ny fr fs nz fu fw dk translated">这个库包含鹌鹑阅读理解数据集的主要数据和挑战数据。鹌鹑含有15K…</h3></div><div class="ob l"><p class="bd b dl z fp ny fr fs nz fu fw dk translated">github.com</p></div></div><div class="oc l"><div class="qe l oe of og oc oh ix nt"/></div></div></a></div></div><div class="ab cl le lf hu lg" role="separator"><span class="lh bw bk li lj lk"/><span class="lh bw bk li lj lk"/><span class="lh bw bk li lj"/></div><div class="ij ik il im in"><figure class="mr ms mt mu gt is gh gi paragraph-image"><div class="gh gi qf"><img src="../Images/e0c8e7378cc353573ad99797b9d795f2.png" data-original-src="https://miro.medium.com/v2/resize:fit:1292/0*PCbIXqPuyPGfsv-B"/></div><figcaption class="iz ja gj gh gi jb jc bd b be z dk translated">神话；传奇</figcaption></figure></div><div class="ab cl le lf hu lg" role="separator"><span class="lh bw bk li lj lk"/><span class="lh bw bk li lj lk"/><span class="lh bw bk li lj"/></div><div class="ij ik il im in"><blockquote class="qg"><p id="f8ac" class="qh qi jg bd qj qk ql qm qn qo qp mg dk translated">每周日，我们都会对来自世界各地研究人员的NLP新闻和代码进行一次每周综述。</p><p id="ae89" class="qh qi jg bd qj qk ql qm qn qo qp mg dk translated">如需完整报道，请关注我们的Twitter: <a class="ae jd" href="http://twitter.com/Quantum_Stat" rel="noopener ugc nofollow" target="_blank"> @Quantum_Stat </a></p></blockquote><figure class="qr qs qt qu qv is gh gi paragraph-image"><div class="gh gi qq"><img src="../Images/57b723ac2e55f809c5d41ff2bf260783.png" data-original-src="https://miro.medium.com/v2/resize:fit:108/0*EcgP3TbUXhk2J3f4"/></div><figcaption class="iz ja gj gh gi jb jc bd b be z dk translated"><a class="ae jd" href="https://quantumstat.com" rel="noopener ugc nofollow" target="_blank">量子统计</a></figcaption></figure></div></div>    
</body>
</html>