<html>
<head>
<title>AI Generates 3D high-resolution reconstructions of people from 2D images | Introduction to PIFuHD</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">人工智能从2D图像中生成人的3D高分辨率重建</h1>
<blockquote>原文：<a href="https://pub.towardsai.net/ai-generates-3d-high-resolution-reconstructions-of-people-from-2d-images-introduction-to-pifuhd-d4aa515a482a?source=collection_archive---------1-----------------------#2020-07-04">https://pub.towardsai.net/ai-generates-3d-high-resolution-reconstructions-of-people-from-2d-images-introduction-to-pifuhd-d4aa515a482a?source=collection_archive---------1-----------------------#2020-07-04</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><h2 id="62f9" class="ir is it bd b dl iu iv iw ix iy iz dk ja translated" aria-label="kicker paragraph"><a class="ae ep" href="https://towardsai.net/p/category/computer-vision" rel="noopener ugc nofollow" target="_blank">计算机视觉</a></h2><div class=""/><div class=""><h2 id="fb53" class="pw-subtitle-paragraph jz jc it bd b ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq dk translated">这个人工智能从2D图像中生成人的3D高分辨率重建！它只需要一张你的照片就能生成一个看起来和你一模一样的3D头像，甚至从背后看也是如此！</h2></div><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div class="gh gi kr"><img src="../Images/24cff7e073e79a2fc9b422aef95046da.png" data-original-src="https://miro.medium.com/v2/resize:fit:1024/1*WihdSidAZCo8c1w_4LMZZQ.gif"/></div></figure><p id="3914" class="pw-post-body-paragraph kz la it lb b lc ld kd le lf lg kg lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">这篇新论文最酷的一点是，他们在google colab上做了一个演示，你可以很容易地在自己身上尝试，正如我将在本文中展示的那样！但首先，让我们看看他们是如何做到的。</p><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div class="gh gi lv"><img src="../Images/1c9bc02504dc26c9ac793225f22dfa45.png" data-original-src="https://miro.medium.com/v2/resize:fit:984/format:webp/1*a1IbuZu-uWlMdSRVVi8w8g.png"/></div></figure><p id="fe64" class="pw-post-body-paragraph kz la it lb b lc ld kd le lf lg kg lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">脸书和南加州大学的研究人员最近发表了一篇名为“PIFuHD:高分辨率3D人体数字化的多级像素对齐隐函数”的新论文。简而言之，它使用某人的2D图像来重建同一个人的3D高分辨率版本。主要目标是实现穿着衣服的人的高保真三维重建，包括手指、面部特征和衣服褶皱等详细信息，正如我们在这张图片中看到的。因为当前的方法不使用完整的高分辨率图像，所以它们由于存储器要求而缩小图像，并且丢失了重要的信息来创建3D的这种高分辨率细节。</p><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="lx ly di lz bf ma"><div class="gh gi lw"><img src="../Images/027bbf591bfd068c059b00cfe2d1cbd0.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*_1UsP1pgxJyS0s5Pm-BZug.png"/></div></div></figure><p id="22cc" class="pw-post-body-paragraph kz la it lb b lc ld kd le lf lg kg lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">皮福德通过将问题公式化为两个步骤来实现这一点。首先，该模型在较低分辨率、缩小的整张图像上进行训练，以专注于整体推理。这样，它可以覆盖图片的更大的空间背景。然后，使用该上下文信息，该模型通过在较高分辨率上观察图像和该第一输出来估计该人的详细几何形状。粗略级别通过对图像进行下采样并将其馈送到皮夫模型中来捕获全局3D结构，而高分辨率细节则通过在类似的轻量级皮夫网络中使用那些第一3D输出作为高分辨率输入来添加。因为精细级别将来自第一级别的特征作为3d嵌入，所以它不需要以更高的分辨率看到整个图像，从而允许在没有背景的情况下馈送这个人的高分辨率图像的可能性。具有较低分辨率的背景信息和较高分辨率的模型解决了先前方法遇到的计算时间问题。</p><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div class="gh gi mb"><img src="../Images/784f5e63737da72937932457d0117504.png" data-original-src="https://miro.medium.com/v2/resize:fit:1122/format:webp/1*6QCq5AIP1K41TGKKnpSjkw.png"/></div></figure><p id="93de" class="pw-post-body-paragraph kz la it lb b lc ld kd le lf lg kg lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">正如您在此图中所看到的，需要多级皮夫来获得高分辨率的3D模型，而单级皮夫可以在需要时更快地创建精确的模型。这种新方法是精确的，使用这种双向模型使得今天的内存限制成为可能。以下是使用这种技术得到的一些更令人印象深刻的结果…</p><div class="ks kt ku kv gt ab cb"><figure class="mc kw md me mf mg mh paragraph-image"><img src="../Images/96d04498dac3006b12382204547d75a9.png" data-original-src="https://miro.medium.com/v2/resize:fit:646/format:webp/1*8HizQlytGkqLzIR1MniO7g.png"/></figure><figure class="mc kw md me mf mg mh paragraph-image"><img src="../Images/0d35bc27c040d1abc6dbfc78d6789149.png" data-original-src="https://miro.medium.com/v2/resize:fit:646/format:webp/1*IhTmf0pYGXE_NDr-t7_10A.png"/></figure><figure class="mc kw md me mf mg mh paragraph-image"><img src="../Images/4bff290e602dbeef7299ecb432432349.png" data-original-src="https://miro.medium.com/v2/resize:fit:646/format:webp/1*Sxr06sMYwuQu0q3cGfxMeQ.png"/></figure></div><div class="ab cb"><figure class="mc kw mi me mf mg mh paragraph-image"><img src="../Images/88ddb755389de81ef172d8567a886742.png" data-original-src="https://miro.medium.com/v2/resize:fit:646/format:webp/1*TjSUWwDKt6J6pp3Hzt7lzg.png"/></figure><figure class="mc kw mi me mf mg mh paragraph-image"><img src="../Images/77a7858f7b0928286798c46d7dd4abdf.png" data-original-src="https://miro.medium.com/v2/resize:fit:646/format:webp/1*8PKIGNnI77HA7Rmb35wXTg.png"/></figure><figure class="mc kw mj me mf mg mh paragraph-image"><img src="../Images/a5594c0772a14b7392ff9108f3367969.png" data-original-src="https://miro.medium.com/v2/resize:fit:648/format:webp/1*f2WZIq_4xeQpFVft4GlqjA.png"/></figure></div><p id="e67a" class="pw-post-body-paragraph kz la it lb b lc ld kd le lf lg kg lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">你甚至可以在自己身上试试！他们做了一个公开演示，你可以简单地上传你的图片，并在google colab上看到结果，而不需要任何GPU！只需要一分钟左右。如果你还怀疑的话，就自己试试看。下面是该演示的链接。令人难以置信的是，除了这张二维图像，他们没有任何其他知识就能做到这一点。当然，这只是这篇新论文的一个简单概述。我强烈建议阅读这篇文章，并尝试演示和/或代码，更多信息请访问下面的链接。</p><figure class="ks kt ku kv gt kw"><div class="bz fp l di"><div class="mk ml l"/></div></figure></div><div class="ab cl mm mn hx mo" role="separator"><span class="mp bw bk mq mr ms"/><span class="mp bw bk mq mr ms"/><span class="mp bw bk mq mr"/></div><div class="im in io ip iq"><p id="7be9" class="pw-post-body-paragraph kz la it lb b lc ld kd le lf lg kg lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><strong class="lb jd">论文</strong>:<a class="ae mt" href="https://arxiv.org/pdf/2004.00452.pdf" rel="noopener ugc nofollow" target="_blank">https://arxiv.org/pdf/2004.00452.pdf</a><br/>T5】演示:<a class="ae mt" href="https://colab.research.google.com/drive/11z58bl3meSzo6kFqkahMa35G5jmh2Wgt" rel="noopener ugc nofollow" target="_blank">https://colab . research . Google . com/drive/11z 58 bl 3 meszo 6 kfqkahma 35g 5 JM H2 wgt</a><br/><strong class="lb jd">GitHub代码</strong>:<a class="ae mt" href="https://github.com/facebookresearch/pifuhd" rel="noopener ugc nofollow" target="_blank">https://github.com/facebookresearch/pifuhd</a></p></div></div>    
</body>
</html>