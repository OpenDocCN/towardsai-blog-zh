<html>
<head>
<title>COVID-19: Face Mask Detection Using Deep Learning and OpenCV</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">新冠肺炎:使用深度学习和OpenCV的人脸面具检测</h1>
<blockquote>原文：<a href="https://pub.towardsai.net/covid-19-face-mask-detection-using-deep-learning-and-opencv-9e554c380e23?source=collection_archive---------1-----------------------#2020-07-23">https://pub.towardsai.net/covid-19-face-mask-detection-using-deep-learning-and-opencv-9e554c380e23?source=collection_archive---------1-----------------------#2020-07-23</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><h2 id="1479" class="io ip iq bd b dl ir is it iu iv iw dk ix translated" aria-label="kicker paragraph"><a class="ae ep" href="https://towardsai.net/p/category/computer-vision" rel="noopener ugc nofollow" target="_blank">计算机视觉</a>、<a class="ae ep" href="https://towardsai.net/p/category/machine-learning/deep-learning" rel="noopener ugc nofollow" target="_blank">深度学习、</a>、<a class="ae ep" href="https://medium.com/towards-data-science/data-science-in-the-real-world/home" rel="noopener">现实世界中的数据科学</a></h2><div class=""/><div class=""><h2 id="b297" class="pw-subtitle-paragraph jw iz iq bd b jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn dk translated">构建一个CNN模型，实时检查一个人是否戴着面具</h2></div><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div role="button" tabindex="0" class="ku kv di kw bf kx"><div class="gh gi ko"><img src="../Images/f16f31fbffe15ea50996883ed552ae1a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Jnl0cN6-rgkmvn3A8x9JBg.jpeg"/></div></div><figcaption class="la lb gj gh gi lc ld bd b be z dk translated">图片来自<a class="ae le" href="https://www.pexels.com/photo/health-workers-wearing-face-mask-3957987/?utm_content=attributionCopyText&amp;utm_medium=referral&amp;utm_source=pexels" rel="noopener ugc nofollow" target="_blank"> <strong class="bd lf">像素</strong> </a></figcaption></figure><p id="9edb" class="pw-post-body-paragraph lg lh iq li b lj lk ka ll lm ln kd lo lp lq lr ls lt lu lv lw lx ly lz ma mb ij bi translated">新冠肺炎严重影响了整个世界。它对我们的日常生活产生了巨大的影响，这种危机与日俱增。在不久的将来，似乎很难彻底根除这种病毒。</p><p id="90f2" class="pw-post-body-paragraph lg lh iq li b lj lk ka ll lm ln kd lo lp lq lr ls lt lu lv lw lx ly lz ma mb ij bi translated">为了对抗这种病毒，口罩已经成为我们生活中不可或缺的一部分。这些口罩能够阻止这种致命病毒的传播，这将有助于控制传播。随着我们开始在这个“新常态”的世界中前进，口罩的必要性增加了。因此，在这里，我们将建立一个模型，将能够分类的人是否戴着面具。这种模式可以用在拥挤的地方，如商场、公交车站和其他公共场所。</p><h1 id="e76d" class="mc md iq bd lf me mf mg mh mi mj mk ml kf mm kg mn ki mo kj mp kl mq km mr ms bi translated">让我们从面罩检测器开始:</h1><p id="02e0" class="pw-post-body-paragraph lg lh iq li b lj mt ka ll lm mu kd lo lp mv lr ls lt mw lv lw lx mx lz ma mb ij bi translated"><strong class="li ja">步骤1:导入要使用的库:</strong></p><pre class="kp kq kr ks gt my mz na nb aw nc bi"><span id="29ef" class="nd md iq mz b gy ne nf l ng nh">import cv2,os<br/>import numpy as np<br/>from keras.utils import np_utils<br/>from keras.models import Sequential<br/>from keras.layers import  Dense, Activation, Dropout, Conv2D, Flatten, MaxPooling2D</span><span id="ecaf" class="nd md iq mz b gy ni nf l ng nh">from keras.callbacks import ModelCheckpoint<br/>from sklearn.model_selection import train_test_split<br/>from matplotlib import pyplot as plt<br/>from keras.models import load_model</span></pre><p id="95fe" class="pw-post-body-paragraph lg lh iq li b lj lk ka ll lm ln kd lo lp lq lr ls lt lu lv lw lx ly lz ma mb ij bi translated"><strong class="li ja">第二步:添加数据路径并标记类别:</strong></p><p id="b8f8" class="pw-post-body-paragraph lg lh iq li b lj lk ka ll lm ln kd lo lp lq lr ls lt lu lv lw lx ly lz ma mb ij bi translated">为了建立这个模型，我们将使用由<a class="ae le" href="https://www.linkedin.com/feed/update/urn%3Ali%3Aactivity%3A6655711815361761280/" rel="noopener ugc nofollow" target="_blank">般若班达瑞</a>提供的面具数据集。它由大约<strong class="li ja"><em class="nj">1376张</em> </strong>图像与<strong class="li ja"> <em class="nj"> 690张</em> </strong>图像包含带面具的人和<strong class="li ja"> <em class="nj"> 686张</em> </strong>图像包含不带面具的人组成。</p><pre class="kp kq kr ks gt my mz na nb aw nc bi"><span id="55ad" class="nd md iq mz b gy ne nf l ng nh">#<em class="nj">use the file path where your dataset is stored</em><br/>data_path = r'C:\Users\admin\Desktop\face mask detection\face-mask-detector\dataset'</span><span id="5329" class="nd md iq mz b gy ni nf l ng nh">categories = os.listdir(data_path)<br/>labels = [i for i in range(len(categories))]</span><span id="e6ef" class="nd md iq mz b gy ni nf l ng nh">label_dict = dict(zip(categories,labels))<br/>print(label_dict)<br/>print(categories)<br/>print(labels)</span></pre><p id="7c7d" class="pw-post-body-paragraph lg lh iq li b lj lk ka ll lm ln kd lo lp lq lr ls lt lu lv lw lx ly lz ma mb ij bi translated"><em class="nj">输出:- </em></p><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div class="gh gi nk"><img src="../Images/54ffab08e8c8ab3f5dc99d0e575f598b.png" data-original-src="https://miro.medium.com/v2/resize:fit:826/format:webp/1*HshJde9W8yqS1T4cNGK8rw.png"/></div><figcaption class="la lb gj gh gi lc ld bd b be z dk translated">(作者供图)</figcaption></figure><p id="9c58" class="pw-post-body-paragraph lg lh iq li b lj lk ka ll lm ln kd lo lp lq lr ls lt lu lv lw lx ly lz ma mb ij bi translated"><strong class="li ja">第三步:列出数据和目标:</strong></p><pre class="kp kq kr ks gt my mz na nb aw nc bi"><span id="f96b" class="nd md iq mz b gy ne nf l ng nh">img_size = 150<br/>data = []<br/>target = []</span><span id="4e97" class="nd md iq mz b gy ni nf l ng nh">for category in categories:<br/>    folder_path = os.path.join(data_path,category) <br/>    img_names = os.listdir(folder_path)<br/>    <br/>    for img_name in img_names:<br/>        img_path = os.path.join(folder_path,img_name)<br/>        img = cv2.imread(img_path)<br/>        try:<br/>            gray = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)<br/>            resized = cv2.resize(gray,(img_size,img_size))<br/>            data.append(resized)<br/>            target.append(label_dict[category])<br/>        <br/>        except Exception as e:<br/>            print("Exception: ",e)</span></pre><p id="3afd" class="pw-post-body-paragraph lg lh iq li b lj lk ka ll lm ln kd lo lp lq lr ls lt lu lv lw lx ly lz ma mb ij bi translated">形成的列表(数据和目标)被转换成NumPy数组，以便于数据预处理。数据阵列被重新整形，以便它可以作为输入提供给神经网络结构。之后，这些文件被保存为. npy文件。</p><pre class="kp kq kr ks gt my mz na nb aw nc bi"><span id="6e07" class="nd md iq mz b gy ne nf l ng nh">data = np.array(data)/255.0  #<em class="nj">data values are normalized</em></span><span id="999d" class="nd md iq mz b gy ni nf l ng nh">#<em class="nj">reshaping of data                                                </em>data = np.reshape(data,(data.shape[0],img_size,img_size,1))</span><span id="18d4" class="nd md iq mz b gy ni nf l ng nh">target = np.array(target)<br/>new_target = np_utils.to_categorical(target)</span><span id="613a" class="nd md iq mz b gy ni nf l ng nh">#saving the files                                np.save('data',data)<br/>np.save('target',new_target)</span></pre><p id="a647" class="pw-post-body-paragraph lg lh iq li b lj lk ka ll lm ln kd lo lp lq lr ls lt lu lv lw lx ly lz ma mb ij bi translated"><strong class="li ja">第四步:建立神经网络模型:</strong></p><p id="a9b1" class="pw-post-body-paragraph lg lh iq li b lj lk ka ll lm ln kd lo lp lq lr ls lt lu lv lw lx ly lz ma mb ij bi translated">首先，我们将从上一步创建的文件中加载数据。然后我们正在使用卷积层和最大池层制作一个神经网络。最后，输出被平坦化，并被馈送到具有50个神经元的完全连接的密集层中，最后被馈送到具有2个神经元的层中，因为它将分别输出一个人戴面具或不戴面具的概率。</p><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div role="button" tabindex="0" class="ku kv di kw bf kx"><div class="gh gi nl"><img src="../Images/74750f588b428a15ffbf6a897a434710.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*9LS4XQW8fBu9ewdSqp5AWw.png"/></div></div><figcaption class="la lb gj gh gi lc ld bd b be z dk translated">使用的神经网络模型(作者提供照片)</figcaption></figure><pre class="kp kq kr ks gt my mz na nb aw nc bi"><span id="e8f8" class="nd md iq mz b gy ne nf l ng nh">data = np.load('data.npy')<br/>target = np.load('target.npy')</span><span id="ebac" class="nd md iq mz b gy ni nf l ng nh">model = Sequential()<br/>model.add(Conv2D(200,(3,3),input_shape=data.shape[1:]))<br/>model.add(Activation('relu'))<br/>model.add(MaxPooling2D(pool_size=(2,2)))</span><span id="a237" class="nd md iq mz b gy ni nf l ng nh">model.add(Conv2D(100,(3,3)))<br/>model.add(Activation('relu'))<br/>model.add(MaxPooling2D(pool_size=(2,2)))</span><span id="3b64" class="nd md iq mz b gy ni nf l ng nh">model.add(Flatten())<br/>model.add(Dropout(0.5))<br/>model.add(Dense(50,activation='relu'))<br/>model.add(Dense(2,activation='softmax'))</span><span id="5efe" class="nd md iq mz b gy ni nf l ng nh">model.compile(optimizer='adam', loss='categorical_crossentropy', metrics = ['acc'])</span><span id="ec53" class="nd md iq mz b gy ni nf l ng nh">model.summary()</span></pre><p id="8fbe" class="pw-post-body-paragraph lg lh iq li b lj lk ka ll lm ln kd lo lp lq lr ls lt lu lv lw lx ly lz ma mb ij bi translated">模型总结如下:</p><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div role="button" tabindex="0" class="ku kv di kw bf kx"><div class="gh gi nm"><img src="../Images/76be44fa4ae441251e7bdc0146a48fbe.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*EE6JnLiBFWN9Ydwr0OrQMg.png"/></div></div><figcaption class="la lb gj gh gi lc ld bd b be z dk translated">模型摘要(作者照片)</figcaption></figure><p id="f4a5" class="pw-post-body-paragraph lg lh iq li b lj lk ka ll lm ln kd lo lp lq lr ls lt lu lv lw lx ly lz ma mb ij bi translated"><strong class="li ja">第四步:拆分数据和目标并放入模型:</strong></p><p id="c0e5" class="pw-post-body-paragraph lg lh iq li b lj lk ka ll lm ln kd lo lp lq lr ls lt lu lv lw lx ly lz ma mb ij bi translated">然后将数据和目标划分为训练数据，测试数据保留10%的数据作为测试数据，90%作为训练数据。</p><pre class="kp kq kr ks gt my mz na nb aw nc bi"><span id="d691" class="nd md iq mz b gy ne nf l ng nh">train_data, test_data, train_target, test_target = train_test_split(data, target, test_size=0.1)</span></pre><p id="443d" class="pw-post-body-paragraph lg lh iq li b lj lk ka ll lm ln kd lo lp lq lr ls lt lu lv lw lx ly lz ma mb ij bi translated">创建一个检查点，它将保存模型，这将具有最小的验证损失。然后将训练数据拟合到模型中，以便在未来进行预测。</p><pre class="kp kq kr ks gt my mz na nb aw nc bi"><span id="01ca" class="nd md iq mz b gy ne nf l ng nh">checkpoint=ModelCheckpoint('model-{epoch:03d}.model', monitor='val_loss', verbose = 0, save_best_only = True,mode='auto')</span><span id="7d81" class="nd md iq mz b gy ni nf l ng nh">history = model.fit(train_data,train_target,epochs = 20, callbacks = [checkpoint], validation_split = 0.2)</span></pre><p id="b3a5" class="pw-post-body-paragraph lg lh iq li b lj lk ka ll lm ln kd lo lp lq lr ls lt lu lv lw lx ly lz ma mb ij bi translated">拟合模型后，绘制训练和验证数据的准确性和损失图表</p><pre class="kp kq kr ks gt my mz na nb aw nc bi"><span id="6e05" class="nd md iq mz b gy ne nf l ng nh">plt.plot(history.history['acc'],'r',label='training accuracy')<br/>plt.plot(history.history['val_acc'],'b',label='validation accuracy')<br/>plt.xlabel('epochs')<br/>plt.ylabel('accuracy')<br/>plt.legend()<br/>plt.show()</span><span id="4325" class="nd md iq mz b gy ni nf l ng nh">plt.plot(history.history['loss'],'r',label='training loss')<br/>plt.plot(history.history['val_loss'],'b',label='validation loss')<br/>plt.xlabel('epochs')<br/>plt.ylabel('loss')<br/>plt.legend()<br/>plt.show()</span></pre><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div class="gh gi nn"><img src="../Images/2247b88d660569a206e05e67c30f67d7.png" data-original-src="https://miro.medium.com/v2/resize:fit:1102/format:webp/1*iDJ4ggHwJ-PkF6EWhW_lbQ.png"/></div><figcaption class="la lb gj gh gi lc ld bd b be z dk translated">准确度图(作者提供照片)</figcaption></figure><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div class="gh gi no"><img src="../Images/3018a0472afb51661bf753e0a2c9ff59.png" data-original-src="https://miro.medium.com/v2/resize:fit:1334/format:webp/1*Xwn3QDdHUZD-g9jV65EUIg.png"/></div><figcaption class="la lb gj gh gi lc ld bd b be z dk translated">损失图(作者照片)</figcaption></figure><p id="bb4d" class="pw-post-body-paragraph lg lh iq li b lj lk ka ll lm ln kd lo lp lq lr ls lt lu lv lw lx ly lz ma mb ij bi translated">我们可以看到一些过度拟合的迹象，可以通过调整参数来解决。否则，这个模型在实时情况下也能很好地工作。</p><p id="b609" class="pw-post-body-paragraph lg lh iq li b lj lk ka ll lm ln kd lo lp lq lr ls lt lu lv lw lx ly lz ma mb ij bi translated"><strong class="li ja">注意:- </strong>不用自己做神经网络arch，可以使用互联网上的arch，像ResNets，MobileNetV2等。他们一定会表现得很好。</p><p id="d539" class="pw-post-body-paragraph lg lh iq li b lj lk ka ll lm ln kd lo lp lq lr ls lt lu lv lw lx ly lz ma mb ij bi translated">现在，根据测试数据评估模型:</p><pre class="kp kq kr ks gt my mz na nb aw nc bi"><span id="d0db" class="nd md iq mz b gy ne nf l ng nh">print(model.evaluate(test_data,test_target))</span></pre><p id="4b23" class="pw-post-body-paragraph lg lh iq li b lj lk ka ll lm ln kd lo lp lq lr ls lt lu lv lw lx ly lz ma mb ij bi translated"><em class="nj">输出:</em></p><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div class="gh gi np"><img src="../Images/44f8cd4d481ef649d872b3f73ba30627.png" data-original-src="https://miro.medium.com/v2/resize:fit:1290/format:webp/1*wcMiXMow_SAhPL5zmxt5Yw.png"/></div><figcaption class="la lb gj gh gi lc ld bd b be z dk translated">模型对测试数据的评估(作者照片)</figcaption></figure><p id="7d2d" class="pw-post-body-paragraph lg lh iq li b lj lk ka ll lm ln kd lo lp lq lr ls lt lu lv lw lx ly lz ma mb ij bi translated">我们可以看到，该模型对测试数据的准确率约为93%，损失为0.309。</p><p id="4d85" class="pw-post-body-paragraph lg lh iq li b lj lk ka ll lm ln kd lo lp lq lr ls lt lu lv lw lx ly lz ma mb ij bi translated">现在我们可以实时应用这个模型了。</p><p id="7c81" class="pw-post-body-paragraph lg lh iq li b lj lk ka ll lm ln kd lo lp lq lr ls lt lu lv lw lx ly lz ma mb ij bi translated"><strong class="li ja">第六步:通过网络摄像头实时使用模型:</strong></p><p id="d06f" class="pw-post-body-paragraph lg lh iq li b lj lk ka ll lm ln kd lo lp lq lr ls lt lu lv lw lx ly lz ma mb ij bi translated">首先，通过回调加载保存为最佳模型的模型。现在我们将使用Haar Cascade分类器在视频的每一帧中查找人脸(<em class="nj">使用您存储XML文件的路径)。</em>另外，为两个不同的类别制作标签和颜色字典，即蒙版和无蒙版。</p><p id="1155" class="pw-post-body-paragraph lg lh iq li b lj lk ka ll lm ln kd lo lp lq lr ls lt lu lv lw lx ly lz ma mb ij bi translated">可以从下面的<a class="ae le" href="https://github.com/opencv/opencv/blob/master/data/haarcascades/haarcascade_frontalface_default.xml" rel="noopener ugc nofollow" target="_blank"> <em class="nj">链接</em> </a> <em class="nj">下载XML文件。</em></p><pre class="kp kq kr ks gt my mz na nb aw nc bi"><span id="8f9d" class="nd md iq mz b gy ne nf l ng nh">model = load_model('model-017.model') <em class="nj">#load the best model</em></span><span id="288a" class="nd md iq mz b gy ni nf l ng nh">faceCascade=cv2.CascadeClassifier(r'C:\Users\admin\Desktop\capstone\HaarCascade\haarcascade_frontalface_default.xml')</span><span id="c2c4" class="nd md iq mz b gy ni nf l ng nh">video_capture = cv2.VideoCapture(0)  <em class="nj">#starts the webcam</em><br/>labels_dict = {0:'NO MASK',1:'MASK'}<br/>color_dict  = { 0:(0,0,255),1:(0,255,0)}</span></pre><p id="99a7" class="pw-post-body-paragraph lg lh iq li b lj lk ka ll lm ln kd lo lp lq lr ls lt lu lv lw lx ly lz ma mb ij bi translated">在一个无限循环中，从视频流中捕获每一帧，并将其转换为灰度以便更好地处理，然后应用级联来找到ROI(感兴趣的区域)，在我们的case- faces中。调整每个ROI图像的大小并使其正常化，然后将其交给模型进行预测。通过这个，你将得到有无屏蔽的概率。选择概率较高的一个。在脸部周围画一个框，也表示一个人有没有戴面具。要关闭网络摄像头，请按Esc按钮。</p><pre class="kp kq kr ks gt my mz na nb aw nc bi"><span id="84b2" class="nd md iq mz b gy ne nf l ng nh">while(True):<br/>    ret,frame = video_capture.read()<br/>    gray = cv2.cvtColor(frame,cv2.COLOR_BGR2GRAY)<br/>    faces = faceCascade.detectMultiScale(gray,1.3,5)<br/>    <br/>    for x,y,w,h in faces:<br/>        face_img = gray[y:y+w,x:x+h]<br/>        resized = cv2.resize(face_img,(img_size,img_size))<br/>        normalized = resized/255.0<br/>        reshaped = np.reshape(normalized,(1,img_size,img_size,1))<br/>        result = model.predict(reshaped)<br/>        <br/>        label = np.argmax(result,axis=1)[0]<br/>        cv2.rectangle(frame,(x,y),(x+w,y+h),color_dict[label],2)<br/>        cv2.putText(frame,labels_dict[label],(x,y-10),cv2.FONT_HERSHEY_SIMPLEX,0.8,(255,255,255),2)<br/>        <br/>    cv2.imshow('Video',frame)<br/>    key=cv2.waitKey(1)<br/>    <br/>    if(key==27):<br/>        break;<br/>        <br/>cv2.destroyAllWindows()<br/>video_capture.release()</span></pre><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div class="gh gi nq"><img src="../Images/7973f0dc151bbd5f2ba7211b2788ec98.png" data-original-src="https://miro.medium.com/v2/resize:fit:582/format:webp/1*2wXhE5w3WZEC6_ZRLOiocA.jpeg"/></div><figcaption class="la lb gj gh gi lc ld bd b be z dk translated">模型的样本输出</figcaption></figure><p id="8e3b" class="pw-post-body-paragraph lg lh iq li b lj lk ka ll lm ln kd lo lp lq lr ls lt lu lv lw lx ly lz ma mb ij bi translated">万岁！！我们开发了一个模型，可以描述一个人是否戴了面具。这些类型的模型可以在公共场所实施，这将有助于当局容易地监测情况。我希望你喜欢制作这个模型，并愿意在未来看到更多…:)</p></div></div>    
</body>
</html>