<html>
<head>
<title>Part 2: Scaling the Yelp downloading algorithm</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">第2部分:缩放Yelp下载算法</h1>
<blockquote>原文：<a href="https://pub.towardsai.net/web-scraping-yelp-part-2-scaling-the-yelp-downloading-algorithm-909356d206b8?source=collection_archive---------2-----------------------#2021-08-23">https://pub.towardsai.net/web-scraping-yelp-part-2-scaling-the-yelp-downloading-algorithm-909356d206b8?source=collection_archive---------2-----------------------#2021-08-23</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><h2 id="aa3c" class="ir is it bd b dl iu iv iw ix iy iz dk ja translated" aria-label="kicker paragraph"><a class="ae ep" href="https://towardsai.net/p/category/web-scraping" rel="noopener ugc nofollow" target="_blank">网页抓取</a></h2><div class=""/><div class=""><h2 id="3a2a" class="pw-subtitle-paragraph jz jc it bd b ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq dk translated">改进我之前写的关于如何下载Yelp评论的算法。完整的算法<a class="ae kr" href="https://github.com/arditoibryan/Projects/blob/master/20210813_yelp_webscraping/web_scraping_yelp_advanced.ipynb" rel="noopener ugc nofollow" target="_blank">可在我的回购</a>。</h2></div><p id="21c2" class="pw-post-body-paragraph ks kt it ku b kv kw kd kx ky kz kg la lb lc ld le lf lg lh li lj lk ll lm ln im bi translated">在<a class="ae kr" rel="noopener ugc nofollow" target="_blank" href="/part-1-scraping-yelp-reviews-with-pyhton-using-beautifulsoup-a014867a1d2c?source=your_stories_page-------------------------------------">的上一期文章</a>中，我花了一些时间解释如何对Yelp网站上一家餐馆的评论进行基本的网络搜集。然而，因为Yelp的网站上列出了无数的餐馆，我将创建一个算法，给出我们想要搜索的餐馆的信息，能够到达无限的页面并下载他们主持的所有评论。</p><figure class="lp lq lr ls gt lt gh gi paragraph-image"><div role="button" tabindex="0" class="lu lv di lw bf lx"><div class="gh gi lo"><img src="../Images/6de1e86086fc3cac3a491cecef896e8a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*k62bzm55xy00szEy"/></div></div><figcaption class="ma mb gj gh gi mc md bd b be z dk translated">照片由<a class="ae kr" href="https://unsplash.com/@joicekelly?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Joice Kelly </a>在<a class="ae kr" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上拍摄</figcaption></figure><p id="1fc0" class="pw-post-body-paragraph ks kt it ku b kv kw kd kx ky kz kg la lb lc ld le lf lg lh li lj lk ll lm ln im bi translated">我想用第二部分来详细解释这个算法是如何工作的，因为它太复杂了，无法用一个单独的算法来管理。我的意图是让你知道构建结构化算法的步骤。构建复杂的算法通常需要以下步骤:</p><ul class=""><li id="5b10" class="me mf it ku b kv kw ky kz lb mg lf mh lj mi ln mj mk ml mm bi translated">我们从一个简单的算法开始，这个算法处理一个可管理的问题</li><li id="28f1" class="me mf it ku b kv mn ky mo lb mp lf mq lj mr ln mj mk ml mm bi translated">我们将它扩展到应用于同一问题的多个实例</li><li id="d405" class="me mf it ku b kv mn ky mo lb mp lf mq lj mr ln mj mk ml mm bi translated">我们增加了算法的复杂性</li></ul><p id="f9db" class="pw-post-body-paragraph ks kt it ku b kv kw kd kx ky kz kg la lb lc ld le lf lg lh li lj lk ll lm ln im bi translated">当这些步骤完成后，您可以逐渐添加内容，甚至可以添加其他工具，如机器学习、探索性数据分析或洞察力提取以及可视化。</p><h2 id="f170" class="ms mt it bd mu mv mw dn mx my mz dp na lb nb nc nd lf ne nf ng lj nh ni nj iz bi translated">基本算法</h2><p id="e057" class="pw-post-body-paragraph ks kt it ku b kv nk kd kx ky nl kg la lb nm ld le lf nn lh li lj no ll lm ln im bi translated">为了让你知道我用什么算法在Yelp的一个页面上抓取所有评论，这是我一直使用的代码。</p><pre class="lp lq lr ls gt np nq nr ns aw nt bi"><span id="74ab" class="ms mt it nq b gy nu nv l nw nx">import requests<br/>from bs4 import BeautifulSoup<br/>import time</span><span id="d30c" class="ms mt it nq b gy ny nv l nw nx">comment_list = list()<br/>for pag in range(1, 29):<br/>  time.sleep(5)<br/>URL = "<a class="ae kr" href="https://www.yelp.com/biz/the-cortez-raleigh?osq=Restaurants&amp;start=" rel="noopener ugc nofollow" target="_blank">https://www.yelp.com/biz/the-cortez-raleigh?osq=Restaurants&amp;start=</a>"+str(pag*10)+"&amp;sort_by=rating_asc"<br/>  print('downloading page ', pag*10)<br/>  page = requests.get(URL)<br/>#next step: parsing<br/>  soup = BeautifulSoup(page.content, 'lxml')<br/>  soup</span><span id="15cb" class="ms mt it nq b gy ny nv l nw nx">for comm in soup.find("yelp-react-root").find_all("p", {"class" : "comment__373c0__Nsutg css-n6i4z7"}):<br/>    comment_list.append(comm.find("span").decode_contents())<br/>    print(comm.find("span").decode_contents())</span></pre><p id="0a2d" class="pw-post-body-paragraph ks kt it ku b kv kw kd kx ky kz kg la lb lc ld le lf lg lh li lj lk ll lm ln im bi translated">正如您所注意到的，如果您对Python和它的一些库至少有一些经验的话，它非常小而且容易理解。</p><h2 id="45be" class="ms mt it bd mu mv mw dn mx my mz dp na lb nb nc nd lf ne nf ng lj nh ni nj iz bi translated">指导算法</h2><p id="6dae" class="pw-post-body-paragraph ks kt it ku b kv nk kd kx ky nl kg la lb nm ld le lf nn lh li lj no ll lm ln im bi translated">如上所述，我想建立一个控制面板，能够从一个窗口控制整个过程。以这种方式构建代码，我需要什么？</p><ul class=""><li id="469d" class="me mf it ku b kv kw ky kz lb mg lf mh lj mi ln mj mk ml mm bi translated">算法将尝试连接的链接列表</li><li id="c170" class="me mf it ku b kv mn ky mo lb mp lf mq lj mr ln mj mk ml mm bi translated">控制算法参数的函数</li></ul><p id="2622" class="pw-post-body-paragraph ks kt it ku b kv kw kd kx ky kz kg la lb lc ld le lf lg lh li lj lk ll lm ln im bi translated">同时，算法本身必须按照最佳编程实践编写:</p><ul class=""><li id="aff2" class="me mf it ku b kv kw ky kz lb mg lf mh lj mi ln mj mk ml mm bi translated">导入库</li><li id="3230" class="me mf it ku b kv mn ky mo lb mp lf mq lj mr ln mj mk ml mm bi translated">添加变量</li><li id="276c" class="me mf it ku b kv mn ky mo lb mp lf mq lj mr ln mj mk ml mm bi translated">设置功能</li><li id="0e76" class="me mf it ku b kv mn ky mo lb mp lf mq lj mr ln mj mk ml mm bi translated">运行算法</li><li id="6407" class="me mf it ku b kv mn ky mo lb mp lf mq lj mr ln mj mk ml mm bi translated">分析/导出结果</li></ul><h2 id="d061" class="ms mt it bd mu mv mw dn mx my mz dp na lb nb nc nd lf ne nf ng lj nh ni nj iz bi translated">导入库</h2><p id="bc01" class="pw-post-body-paragraph ks kt it ku b kv nk kd kx ky nl kg la lb nm ld le lf nn lh li lj no ll lm ln im bi translated">我们要采取的第一步，就像在每一个值得尊敬的算法中一样，是将一小部分代码专用于我们将在整个代码中使用的库。我不需要用pip安装任何东西，因为代码中的所有库都已经在Python包中提供了。</p><pre class="lp lq lr ls gt np nq nr ns aw nt bi"><span id="b740" class="ms mt it nq b gy nu nv l nw nx">import requests<br/>from bs4 import BeautifulSoup<br/>import time<br/>from textblob import TextBlob<br/>import pandas as pd</span></pre><h2 id="bac1" class="ms mt it bd mu mv mw dn mx my mz dp na lb nb nc nd lf ne nf ng lj nh ni nj iz bi translated">添加变量</h2><p id="b37c" class="pw-post-body-paragraph ks kt it ku b kv nk kd kx ky nl kg la lb nm ld le lf nn lh li lj no ll lm ln im bi translated">有了这组变量，我就可以控制使用beautifulsoup下载哪些网站。为了提供一个简单的例子，我只用了两个。正如你注意到的，我需要使用大量的信息来正确地指挥我的铲运机。我需要每家餐厅的链接来建立连接，我想要抓取的评论页面的数量，以及要放入数据集中的餐厅名称。</p><p id="cdcd" class="pw-post-body-paragraph ks kt it ku b kv kw kd kx ky kz kg la lb lc ld le lf lg lh li lj lk ll lm ln im bi translated">存储这些信息的最佳方式是通过嵌套列表或字典(相当于一个javascript对象，如果你愿意，可以称之为NoSQL)。一旦你习惯了使用字典，它们可以简化你的大部分工作，让你的代码更容易理解。总的来说，我将有一个字典列表。</p><pre class="lp lq lr ls gt np nq nr ns aw nt bi"><span id="43a9" class="ms mt it nq b gy nu nv l nw nx">rest_dict = [<br/>              {  "name"   : "the-cortez-raleigh",<br/>                  "link"  : "<a class="ae kr" href="https://www.yelp.com/biz/the-cortez-raleigh?osq=Restaurants&amp;start=" rel="noopener ugc nofollow" target="_blank">https://www.yelp.com/biz/the-cortez-raleigh?osq=Restaurants&amp;start=</a>",<br/>                  "pages" : 3<br/>              },<br/>              {  "name"   : "rosewater-kitchen-and-bar-raleigh",<br/>                  "link"  : "<a class="ae kr" href="https://www.yelp.com/biz/rosewater-kitchen-and-bar-raleigh?osq=Restaurants&amp;start=" rel="noopener ugc nofollow" target="_blank">https://www.yelp.com/biz/rosewater-kitchen-and-bar-raleigh?osq=Restaurants&amp;start=</a>",<br/>                  "pages" : 3<br/>              }<br/>]</span></pre><h2 id="fb75" class="ms mt it bd mu mv mw dn mx my mz dp na lb nb nc nd lf ne nf ng lj nh ni nj iz bi translated">设置功能</h2><p id="54ff" class="pw-post-body-paragraph ks kt it ku b kv nk kd kx ky nl kg la lb nm ld le lf nn lh li lj no ll lm ln im bi translated">因为我希望解释这个函数的每一个细节，如果你只是想访问代码，我建议你直接从我的repo 中获取代码<a class="ae kr" href="https://github.com/arditoibryan/Projects/blob/master/20210813_yelp_webscraping/web_scraping_yelp_advanced.ipynb" rel="noopener ugc nofollow" target="_blank">，当你点击一下就可以完成的时候，将这些单独的代码行组合并粘贴到你的IDE中将是一种折磨。</a></p><p id="1a5c" class="pw-post-body-paragraph ks kt it ku b kv kw kd kx ky kz kg la lb lc ld le lf lg lh li lj lk ll lm ln im bi translated">现在我已经有了所有的信息，我可以设置我的算法，我将cape <strong class="ku jd">刮刀</strong>。逻辑很简单，因为代码将经历一系列步骤:</p><pre class="lp lq lr ls gt np nq nr ns aw nt bi"><span id="6f37" class="ms mt it nq b gy nu nv l nw nx">def scraper(rest_list):<br/>  all_comment_list = list()<br/>  for rest in rest_list:<br/>    comment_list = list()</span></pre><p id="6cba" class="pw-post-body-paragraph ks kt it ku b kv kw kd kx ky kz kg la lb lc ld le lf lg lh li lj lk ll lm ln im bi translated">它将首先遍历列表中的每一个字典。</p><pre class="lp lq lr ls gt np nq nr ns aw nt bi"><span id="8a76" class="ms mt it nq b gy nu nv l nw nx">    for pag in range(1, rest['pages']):</span></pre><p id="a39d" class="pw-post-body-paragraph ks kt it ku b kv kw kd kx ky kz kg la lb lc ld le lf lg lh li lj lk ll lm ln im bi translated">我还添加了一个try语句，以便在代码中出现错误或连接故障导致算法停止时，我们不必从头开始。因为在网页抓取过程中错误是很常见的，因为它们非常依赖于我们自己没有建立的网站的结构，所以我们需要采取措施来防止我们的算法停止。如果发生这种情况，我们要么需要花更多的时间来了解算法在哪里停止并调整抓取参数，因为我们到目前为止已经能够保存信息，要么从头开始。相信我，没有一种选择是令人愉快的。</p><pre class="lp lq lr ls gt np nq nr ns aw nt bi"><span id="c624" class="ms mt it nq b gy nu nv l nw nx">      try:</span></pre><p id="77e8" class="pw-post-body-paragraph ks kt it ku b kv kw kd kx ky kz kg la lb lc ld le lf lg lh li lj lk ll lm ln im bi translated">我会在开始请求前强制等待5秒钟，以避免我们的IP被拒绝。通常，当运行太多查询时，网站理解我们不可能是人类，并决定阻止连接请求。除非我们有try语句，否则算法会抛出错误。</p><pre class="lp lq lr ls gt np nq nr ns aw nt bi"><span id="097c" class="ms mt it nq b gy nu nv l nw nx">        time.sleep(5)</span></pre><p id="196d" class="pw-post-body-paragraph ks kt it ku b kv kw kd kx ky kz kg la lb lc ld le lf lg lh li lj lk ll lm ln im bi translated">连接到Yelp并提取HTML，然后按照指定的页数重复这个过程。</p><pre class="lp lq lr ls gt np nq nr ns aw nt bi"><span id="6b82" class="ms mt it nq b gy nu nv l nw nx"><a class="ae kr" href="https://www.yelp.com/biz/the-cortez-raleigh?osq=Restaurants&amp;start=" rel="noopener ugc nofollow" target="_blank">osq=Restaurants&amp;start=</a>"+str(pag*10)+"&amp;sort_by=rating_asc"<br/>        URL = rest['link']+str(pag*10)<br/>        print(rest['name'], 'downloading page ', pag*10)<br/>        page = requests.get(URL)</span></pre><p id="dd07" class="pw-post-body-paragraph ks kt it ku b kv kw kd kx ky kz kg la lb lc ld le lf lg lh li lj lk ll lm ln im bi translated">将HTML解析成可以被beautifulsoup读取的代码。这是最相关的工作程序，因为这是我们可以使用本库提供的方法提取信息的唯一方式。</p><pre class="lp lq lr ls gt np nq nr ns aw nt bi"><span id="ce28" class="ms mt it nq b gy nu nv l nw nx">#next step: parsing<br/>        soup = BeautifulSoup(page.content, 'lxml')<br/>        soup</span></pre><p id="3a03" class="pw-post-body-paragraph ks kt it ku b kv kw kd kx ky kz kg la lb lc ld le lf lg lh li lj lk ll lm ln im bi translated">从这千行字符串中提取评论。经过对代码的深入研究，我能够理解哪些HTML元素驻留在评论中。这段代码将准确提取这些元素的内容。</p><pre class="lp lq lr ls gt np nq nr ns aw nt bi"><span id="d351" class="ms mt it nq b gy nu nv l nw nx">for comm in soup.find("yelp-react-root").find_all("p", {"class" : "comment__373c0__Nsutg css-n6i4z7"}):</span></pre><p id="44a4" class="pw-post-body-paragraph ks kt it ku b kv kw kd kx ky kz kg la lb lc ld le lf lg lh li lj lk ll lm ln im bi translated">我现在将把单个餐馆的内容保存在一个列表中，该列表包含与餐馆名称匹配的每个评论，名为<strong class="ku jd"> comment_list </strong>。</p><pre class="lp lq lr ls gt np nq nr ns aw nt bi"><span id="2d6e" class="ms mt it nq b gy nu nv l nw nx">          comment_list.append(comm.find("span").decode_contents())<br/>          print(comm.find("span").decode_contents())<br/>      except:<br/>        print("could not work properly!")</span></pre><p id="eb07" class="pw-post-body-paragraph ks kt it ku b kv kw kd kx ky kz kg la lb lc ld le lf lg lh li lj lk ll lm ln im bi translated">在抓取下一页之前，我会将保存在<strong class="ku jd"> comment_list </strong>中的评论保存到一个总列表中，该列表将包含所有名为<strong class="ku jd"> all_comment_list </strong>的评论。从下一次迭代开始，<strong class="ku jd"> comment_list </strong>将被重置。</p><pre class="lp lq lr ls gt np nq nr ns aw nt bi"><span id="af08" class="ms mt it nq b gy nu nv l nw nx"><br/>    all_comment_list.append([comment_list, rest['name']])<br/>  return all_comment_list</span></pre><p id="c67f" class="pw-post-body-paragraph ks kt it ku b kv kw kd kx ky kz kg la lb lc ld le lf lg lh li lj lk ll lm ln im bi translated">最后，我可以用一行代码运行该算法，并将其所有值存储在一个名为reviews的列表中。</p><pre class="lp lq lr ls gt np nq nr ns aw nt bi"><span id="7edf" class="ms mt it nq b gy nu nv l nw nx">reviews = scraper(rest_dict)</span></pre><p id="12f2" class="pw-post-body-paragraph ks kt it ku b kv kw kd kx ky kz kg la lb lc ld le lf lg lh li lj lk ll lm ln im bi translated">在下一部分中，我将从评论中生成一个结构化数据集，并应用自然语言处理技术来更好地理解我下载的内容。</p></div></div>    
</body>
</html>