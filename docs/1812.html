<html>
<head>
<title>The NLP Cypher | 05.02.21</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">NLP密码| 05.02.21</h1>
<blockquote>原文：<a href="https://pub.towardsai.net/the-nlp-cypher-05-02-21-ebfd55dc8e8a?source=collection_archive---------2-----------------------#2021-05-03">https://pub.towardsai.net/the-nlp-cypher-05-02-21-ebfd55dc8e8a?source=collection_archive---------2-----------------------#2021-05-03</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><figure class="ip iq gp gr ir is gh gi paragraph-image"><div class="gh gi io"><img src="../Images/0be271e1e56c46864cce522d0bb8dade.png" data-original-src="https://miro.medium.com/v2/resize:fit:1080/0*jFbXNrxAsKhdgsoH"/></div><figcaption class="iv iw gj gh gi ix iy bd b be z dk translated">当心美丽的女巫|欧玛利</figcaption></figure><h2 id="f33a" class="iz ja jb bd b dl jc jd je jf jg jh dk ji translated" aria-label="kicker paragraph">自然语言处理每周时事通讯</h2><div class=""/><div class=""><h2 id="2868" class="pw-subtitle-paragraph kh jk jb bd b ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky dk translated">NLP指数</h2></div></div><div class="ab cl kz la hu lb" role="separator"><span class="lc bw bk ld le lf"/><span class="lc bw bk ld le lf"/><span class="lc bw bk ld le"/></div><div class="ij ik il im in"><p id="afac" class="pw-post-body-paragraph lg lh jb li b lj lk kl ll lm ln ko lo lp lq lr ls lt lu lv lw lx ly lz ma mb ij bi translated">作为一名应用机器学习工程师(又名黑客👨‍💻又名飞行忍者🐱‍👤)，我一直在寻找更好更快的方法来保持在深度学习和软件开发电路的顶端。在比较了研究、代码和应用的各种来源之后。我发现大量出色的NLP代码不在arXiv上，也不是所有的NLP研究都在GitHub上。为了获得更广泛的当前NLP研究和代码，我创建了NLP索引！一个包含超过3，000个NLP存储库的搜索引擎(每周更新)🔥。该索引包含研究论文、相关论文图表的ConnectedPapers链接及其GitHub repo。</p><div class="ip iq gp gr ir mc"><a href="https://index.quantumstat.com/" rel="noopener  ugc nofollow" target="_blank"><div class="md ab fo"><div class="me ab mf cl cj mg"><h2 class="bd jl gy z fp mh fr fs mi fu fw jk bi translated">NLP指数</h2><div class="mj l"><h3 class="bd b gy z fp mh fr fs mi fu fw dk translated">顶级NLP代码库- Quantum Stat</h3></div><div class="mk l"><p class="bd b dl z fp mh fr fs mi fu fw dk translated">index.quantumstat.com</p></div></div><div class="ml l"><div class="mm l mn mo mp ml mq it mc"/></div></div></a></div><p id="e5d5" class="pw-post-body-paragraph lg lh jb li b lj lk kl ll lm ln ko lo lp lq lr ls lt lu lv lw lx ly lz ma mb ij bi translated">这个平台的目的是让研究人员和黑客快速、全面地获取关于NLP的所有信息。不仅仅是来自研究论文，而是来自基于这项研究开发的令人敬畏的应用程序。</p><p id="8e8f" class="pw-post-body-paragraph lg lh jb li b lj lk kl ll lm ln ko lo lp lq lr ls lt lu lv lw lx ly lz ma mb ij bi translated">由于主题领域之间的相互依赖性，我们已经包括了开放搜索的选项(而不是只提供预定义的类别)。这意味着，有时一篇论文/报告可能同时与“知识图表”和“数据集”有关，很难将主题离散化。我们更喜欢给用户开放的选择，同时搜索所有领域/部门的数据库。为了方便起见，我们还通过侧栏在NLP中包含了几十个主题的预定义查询。</p><p id="8375" class="pw-post-body-paragraph lg lh jb li b lj lk kl ll lm ln ko lo lp lq lr ls lt lu lv lw lx ly lz ma mb ij bi translated">索引有几个属性，例如:键入时搜索、允许输入错误和同义词检测。</p><p id="f992" class="pw-post-body-paragraph lg lh jb li b lj lk kl ll lm ln ko lo lp lq lr ls lt lu lv lw lx ly lz ma mb ij bi translated"><strong class="li jl">同义词检测</strong></p><p id="af57" class="pw-post-body-paragraph lg lh jb li b lj lk kl ll lm ln ko lo lp lq lr ls lt lu lv lw lx ly lz ma mb ij bi translated">例如，如果您搜索“数据集”，数据库还将同时搜索“语料库”和“语料库”文本，以确保搜索到所有资产。🤟</p><p id="bf09" class="pw-post-body-paragraph lg lh jb li b lj lk kl ll lm ln ko lo lp lq lr ls lt lu lv lw lx ly lz ma mb ij bi translated"><strong class="li jl">错别字容忍度</strong></p><p id="a93e" class="pw-post-body-paragraph lg lh jb li b lj lk kl ll lm ln ko lo lp lq lr ls lt lu lv lw lx ly lz ma mb ij bi translated">如果你搜索“gpt2”，它也会包括“gpt-2”</p><p id="6f38" class="pw-post-body-paragraph lg lh jb li b lj lk kl ll lm ln ko lo lp lq lr ls lt lu lv lw lx ly lz ma mb ij bi translated"><strong class="li jl">一边输入一边搜索</strong></p><p id="47ab" class="pw-post-body-paragraph lg lh jb li b lj lk kl ll lm ln ko lo lp lq lr ls lt lu lv lw lx ly lz ma mb ij bi translated">它会在你输入时实时输出每个字符的结果，只需要几毫秒。(谢谢内存映射🙈)</p></div><div class="ab cl kz la hu lb" role="separator"><span class="lc bw bk ld le lf"/><span class="lc bw bk ld le lf"/><span class="lc bw bk ld le"/></div><div class="ij ik il im in"><p id="bbb4" class="pw-post-body-paragraph lg lh jb li b lj lk kl ll lm ln ko lo lp lq lr ls lt lu lv lw lx ly lz ma mb ij bi translated">还想提一下<a class="ae mr" href="https://datasets.quantumstat.com/" rel="noopener ugc nofollow" target="_blank">大坏NLP数据库</a>已经和NLP索引合并了！对于NLP数据集的最新概要，您可以转到侧边栏的“数据”部分，然后单击数据集或公开搜索特定的数据集/任务。最终，我将关闭BBND的URL，并最终将其重定向到索引。</p></div><div class="ab cl kz la hu lb" role="separator"><span class="lc bw bk ld le lf"/><span class="lc bw bk ld le lf"/><span class="lc bw bk ld le"/></div><div class="ij ik il im in"><p id="e254" class="pw-post-body-paragraph lg lh jb li b lj lk kl ll lm ln ko lo lp lq lr ls lt lu lv lw lx ly lz ma mb ij bi translated">我要感谢在直播NLP指数后的过去一周中我得到的所有支持。感谢Philip Vollet与数百个NLP repos分享他的数据集。你可以在“未知领域”找到他的帖子。</p><p id="f05a" class="pw-post-body-paragraph lg lh jb li b lj lk kl ll lm ln ko lo lp lq lr ls lt lu lv lw lx ly lz ma mb ij bi translated">更多功能即将推出。敬请关注。🙉</p></div><div class="ab cl kz la hu lb" role="separator"><span class="lc bw bk ld le lf"/><span class="lc bw bk ld le lf"/><span class="lc bw bk ld le"/></div><div class="ij ik il im in"><h1 id="701c" class="ms mt jb bd mu mv mw mx my mz na nb nc kq nd kr ne kt nf ku ng kw nh kx ni nj bi translated">伯特，解释一下！</h1><p id="4f4a" class="pw-post-body-paragraph lg lh jb li b lj nk kl ll lm nl ko lo lp nm lr ls lt nn lv lw lx no lz ma mb ij bi translated">发现为什么伯特使用<a class="ae mr" href="https://shap.readthedocs.io/en/latest/index.html" rel="noopener ugc nofollow" target="_blank"> SHAP </a>(沙普利附加解释)做出推论；一种博弈论方法来解释任何机器学习模型的输出。它利用了变形金刚管道。</p><figure class="nq nr ns nt gt is gh gi paragraph-image"><div role="button" tabindex="0" class="nu nv di nw bf nx"><div class="gh gi np"><img src="../Images/a2d47eb679e6d3dfa3a8f17dbe153fd8.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*w_7FldMYvtmmOJbT.png"/></div></div></figure><div class="ip iq gp gr ir mc"><a href="https://github.com/ml6team/quick-tips/tree/main/nlp/2021_04_22_shap_for_huggingface_transformers?utm_campaign=NLPTip&amp;utm_content=164566347&amp;utm_medium=social&amp;utm_source=twitter&amp;hss_channel=tw-895765746583732225" rel="noopener  ugc nofollow" target="_blank"><div class="md ab fo"><div class="me ab mf cl cj mg"><h2 class="bd jl gy z fp mh fr fs mi fu fw jk bi translated">ml6团队/快速提示</h2><div class="mj l"><h3 class="bd b gy z fp mh fr fs mi fu fw dk translated">自从变形金刚模型登上NLP的宝座已经有两年多了🏅，但直到最近他们还不知道…</h3></div><div class="mk l"><p class="bd b dl z fp mh fr fs mi fu fw dk translated">github.com</p></div></div><div class="ml l"><div class="ny l mn mo mp ml mq it mc"/></div></div></a></div><h2 id="d140" class="nz mt jb bd mu oa ob dn my oc od dp nc lp oe of ne lt og oh ng lx oi oj ni jh bi translated">本周可乐</h2><div class="ip iq gp gr ir mc"><a href="https://colab.research.google.com/github/ml6team/quick-tips/blob/main/nlp/2021_04_22_shap_for_huggingface_transformers/explainable_transformers_using_shap.ipynb" rel="noopener  ugc nofollow" target="_blank"><div class="md ab fo"><div class="me ab mf cl cj mg"><h2 class="bd jl gy z fp mh fr fs mi fu fw jk bi translated">谷歌联合实验室</h2><div class="mj l"><h3 class="bd b gy z fp mh fr fs mi fu fw dk translated">编辑描述</h3></div><div class="mk l"><p class="bd b dl z fp mh fr fs mi fu fw dk translated">colab.research.google.com</p></div></div><div class="ml l"><div class="ok l mn mo mp ml mq it mc"/></div></div></a></div><h1 id="593b" class="ms mt jb bd mu mv ol mx my mz om nb nc kq on kr ne kt oo ku ng kw op kx ni nj bi translated">可解释的人工智能备忘单</h1><p id="6913" class="pw-post-body-paragraph lg lh jb li b lj nk kl ll lm nl ko lo lp nm lr ls lt nn lv lw lx no lz ma mb ij bi translated">包括图片，YouTube视频，和一些讨论可解释人工智能的论文/书籍的链接。</p><div class="ip iq gp gr ir mc"><a href="https://ex.pegg.io/" rel="noopener  ugc nofollow" target="_blank"><div class="md ab fo"><div class="me ab mf cl cj mg"><h2 class="bd jl gy z fp mh fr fs mi fu fw jk bi translated">可解释的人工智能指南</h2><div class="mj l"><h3 class="bd b gy z fp mh fr fs mi fu fw dk translated">简要概述了可解释的人工智能备忘单和例子。</h3></div><div class="mk l"><p class="bd b dl z fp mh fr fs mi fu fw dk translated">例如，钉住io</p></div></div></div></a></div><h1 id="3fe6" class="ms mt jb bd mu mv ol mx my mz om nb nc kq on kr ne kt oo ku ng kw op kx ni nj bi translated">StyleCLIP太好玩了！</h1><p id="8a59" class="pw-post-body-paragraph lg lh jb li b lj nk kl ll lm nl ko lo lp nm lr ls lt nn lv lw lx no lz ma mb ij bi translated">来自Max Woolf关于使用StyleCLIP(通过Colab笔记本)通过文本提示操作头像照片的精彩介绍。你甚至可以添加自己的图片，质量相当不错。例如，看看文本提示后的生成:“使用NLP索引后的人脸”👇 😭😭</p><figure class="nq nr ns nt gt is gh gi paragraph-image"><div role="button" tabindex="0" class="nu nv di nw bf nx"><div class="gh gi oq"><img src="../Images/618360f1d3f9e45357280d88305e1262.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*_W1BBWOPnQBBzSle"/></div></div></figure><div class="ip iq gp gr ir mc"><a href="https://minimaxir.com/2021/04/styleclip/" rel="noopener  ugc nofollow" target="_blank"><div class="md ab fo"><div class="me ab mf cl cj mg"><h2 class="bd jl gy z fp mh fr fs mi fu fw jk bi translated">使用StyleCLIP轻松将人物肖像转换为人工智能像差| Max Woolf的博客</h2><div class="mj l"><h3 class="bd b gy z fp mh fr fs mi fu fw dk translated">生成性对抗网络GANs如今风靡一时，用于创建基于人工智能的图像。你可能已经看过…</h3></div><div class="mk l"><p class="bd b dl z fp mh fr fs mi fu fw dk translated">minimaxir.com</p></div></div><div class="ml l"><div class="or l mn mo mp ml mq it mc"/></div></div></a></div><h1 id="5e34" class="ms mt jb bd mu mv ol mx my mz om nb nc kq on kr ne kt oo ku ng kw op kx ni nj bi translated">软件更新</h1><h2 id="6914" class="nz mt jb bd mu oa ob dn my oc od dp nc lp oe of ne lt og oh ng lx oi oj ni jh bi translated">适配器Hub</h2><p id="ff65" class="pw-post-body-paragraph lg lh jb li b lj nk kl ll lm nl ko lo lp nm lr ls lt nn lv lw lx no lz ma mb ij bi translated">新版本包括巴特和GPT-2模型🚨</p><div class="ip iq gp gr ir mc"><a href="https://adapterhub.ml/blog/2021/04/adapters-for-generative-and-seq2seq-models-in-nlp/" rel="noopener  ugc nofollow" target="_blank"><div class="md ab fo"><div class="me ab mf cl cj mg"><h2 class="bd jl gy z fp mh fr fs mi fu fw jk bi translated">NLP中用于创成式和Seq2Seq模型的适配器</h2><div class="mj l"><h3 class="bd b gy z fp mh fr fs mi fu fw dk translated">适配器在NLP的机器学习中变得越来越重要。例如，它们使我们能够高效地…</h3></div><div class="mk l"><p class="bd b dl z fp mh fr fs mi fu fw dk translated">adapterhub.ml</p></div></div><div class="ml l"><div class="os l mn mo mp ml mq it mc"/></div></div></a></div><h2 id="15b4" class="nz mt jb bd mu oa ob dn my oc od dp nc lp oe of ne lt og oh ng lx oi oj ni jh bi translated">贝尔托皮奇</h2><p id="d2a2" class="pw-post-body-paragraph lg lh jb li b lj nk kl ll lm nl ko lo lp nm lr ls lt nn lv lw lx no lz ma mb ij bi translated">利用UMAP的监督选项进行(半)监督主题建模</p><ul class=""><li id="4aec" class="ot ou jb li b lj lk lm ln lp ov lt ow lx ox mb oy oz pa pb bi translated"><code class="fe pc pd pe pf b">model.fit(docs, y=target_classes)</code></li></ul><p id="f812" class="pw-post-body-paragraph lg lh jb li b lj lk kl ll lm ln ko lo lp lq lr ls lt lu lv lw lx ly lz ma mb ij bi translated">后端:</p><ul class=""><li id="08a1" class="ot ou jb li b lj lk lm ln lp ov lt ow lx ox mb oy oz pa pb bi translated">添加了空间、Gensim、使用(TFHub)</li><li id="ada6" class="ot ou jb li b lj pg lm ph lp pi lt pj lx pk mb oy oz pa pb bi translated">对文档嵌入和单词嵌入使用不同的后端</li><li id="84df" class="ot ou jb li b lj pg lm ph lp pi lt pj lx pk mb oy oz pa pb bi translated">使用<code class="fe pc pd pe pf b">bertopic.backend.BaseEmbedder</code>创建您自己的后端</li><li id="f0f6" class="ot ou jb li b lj pg lm ph lp pi lt pj lx pk mb oy oz pa pb bi translated">点击<a class="ae mr" href="https://maartengr.github.io/BERTopic/tutorial/embeddings/embeddings.html" rel="noopener ugc nofollow" target="_blank">此处</a>查看所有新后端的概述</li></ul><p id="edbf" class="pw-post-body-paragraph lg lh jb li b lj lk kl ll lm ln ko lo lp lq lr ls lt lu lv lw lx ly lz ma mb ij bi translated">计算并可视化每节课的主题</p><ul class=""><li id="0d8f" class="ot ou jb li b lj lk lm ln lp ov lt ow lx ox mb oy oz pa pb bi translated">算:<code class="fe pc pd pe pf b">topics_per_class = topic_model.topics_per_class(docs, topics, classes)</code></li></ul><p id="2df2" class="pw-post-body-paragraph lg lh jb li b lj lk kl ll lm ln ko lo lp lq lr ls lt lu lv lw lx ly lz ma mb ij bi translated">视觉化:<code class="fe pc pd pe pf b">topic_model.visualize_topics_per_class(topics_per_class)</code></p><div class="ip iq gp gr ir mc"><a href="https://github.com/MaartenGr/BERTopic/releases/tag/v0.7.0" rel="noopener  ugc nofollow" target="_blank"><div class="md ab fo"><div class="me ab mf cl cj mg"><h2 class="bd jl gy z fp mh fr fs mi fu fw jk bi translated">发布主版本v0.7 MaartenGr/BERTopic</h2><div class="mj l"><h3 class="bd b gy z fp mh fr fs mi fu fw dk translated">两个主要特性是(半)监督主题建模和几个后端来代替Flair和…</h3></div><div class="mk l"><p class="bd b dl z fp mh fr fs mi fu fw dk translated">github.com</p></div></div><div class="ml l"><div class="pl l mn mo mp ml mq it mc"/></div></div></a></div></div><div class="ab cl kz la hu lb" role="separator"><span class="lc bw bk ld le lf"/><span class="lc bw bk ld le lf"/><span class="lc bw bk ld le"/></div><div class="ij ik il im in"><h1 id="516f" class="ms mt jb bd mu mv mw mx my mz na nb nc kq nd kr ne kt nf ku ng kw nh kx ni nj bi translated">回购密码👨‍💻</h1><h2 id="3da0" class="nz mt jb bd mu oa ob dn my oc od dp nc lp oe of ne lt og oh ng lx oi oj ni jh bi translated">一组最近发布的回购引起了我们的关注👁</h2></div><div class="ab cl kz la hu lb" role="separator"><span class="lc bw bk ld le lf"/><span class="lc bw bk ld le lf"/><span class="lc bw bk ld le"/></div><div class="ij ik il im in"><h2 id="affe" class="nz mt jb bd mu oa ob dn my oc od dp nc lp oe of ne lt og oh ng lx oi oj ni jh bi translated">针对文本转换器的基于梯度的对抗性攻击</h2><blockquote class="pm pn po"><p id="0b57" class="lg lh pp li b lj lk kl ll lm ln ko lo pq lq lr ls pr lu lv lw ps ly lz ma mb ij bi translated">一个通用框架，GBDA(基于梯度的分布式攻击)，用于基于梯度的对抗性攻击，并将其应用于文本数据上的变压器模型。</p></blockquote><div class="ip iq gp gr ir mc"><a href="https://github.com/facebookresearch/text-adversarial-attack" rel="noopener  ugc nofollow" target="_blank"><div class="md ab fo"><div class="me ab mf cl cj mg"><h2 class="bd jl gy z fp mh fr fs mi fu fw jk bi translated">Facebook研究/文本-敌对-攻击</h2><div class="mj l"><h3 class="bd b gy z fp mh fr fs mi fu fw dk translated">安装hugging face dependencies conda install-c hugging face transformers pip安装数据集(可选)攻击…</h3></div><div class="mk l"><p class="bd b dl z fp mh fr fs mi fu fw dk translated">github.com</p></div></div><div class="ml l"><div class="pt l mn mo mp ml mq it mc"/></div></div></a></div><p id="57f1" class="pw-post-body-paragraph lg lh jb li b lj lk kl ll lm ln ko lo lp lq lr ls lt lu lv lw lx ly lz ma mb ij bi translated"><a class="ae mr" href="https://www.connectedpapers.com/main/59c2b4ef91d4ce23cd4f270c8750a00de9054ec2/arxiv" rel="noopener ugc nofollow" target="_blank"> <strong class="li jl">连接论文</strong> </a> <strong class="li jl">📈</strong></p></div><div class="ab cl kz la hu lb" role="separator"><span class="lc bw bk ld le lf"/><span class="lc bw bk ld le lf"/><span class="lc bw bk ld le"/></div><div class="ij ik il im in"><h2 id="2cbe" class="nz mt jb bd mu oa ob dn my oc od dp nc lp oe of ne lt og oh ng lx oi oj ni jh bi translated">简单高效的变压器</h2><blockquote class="pm pn po"><p id="d74c" class="lg lh pp li b lj lk kl ll lm ln ko lo pq lq lr ls pr lu lv lw ps ly lz ma mb ij bi translated">Pytorch推理插件，用于模型尺寸大、序列长的变形金刚。目前支持GPT-2和伯特模型。</p></blockquote><div class="ip iq gp gr ir mc"><a href="https://github.com/NetEase-FuXi/EET" rel="noopener  ugc nofollow" target="_blank"><div class="md ab fo"><div class="me ab mf cl cj mg"><h2 class="bd jl gy z fp mh fr fs mi fu fw jk bi translated">网易-伏羲/EET</h2><div class="mj l"><h3 class="bd b gy z fp mh fr fs mi fu fw dk translated">EET(简单有效的变压器)是一个有效的Pytorch推理插件，专注于基于变压器的模型，具有…</h3></div><div class="mk l"><p class="bd b dl z fp mh fr fs mi fu fw dk translated">github.com</p></div></div><div class="ml l"><div class="pu l mn mo mp ml mq it mc"/></div></div></a></div><p id="9290" class="pw-post-body-paragraph lg lh jb li b lj lk kl ll lm ln ko lo lp lq lr ls lt lu lv lw lx ly lz ma mb ij bi translated"><a class="ae mr" href="https://www.connectedpapers.com/main/72d4e7e02070f1f0b88d99bc799a94e56576b79a/arxiv" rel="noopener ugc nofollow" target="_blank"> <strong class="li jl">连接论文</strong> </a> <strong class="li jl">📈</strong></p></div><div class="ab cl kz la hu lb" role="separator"><span class="lc bw bk ld le lf"/><span class="lc bw bk ld le lf"/><span class="lc bw bk ld le"/></div><div class="ij ik il im in"><h2 id="b2bc" class="nz mt jb bd mu oa ob dn my oc od dp nc lp oe of ne lt og oh ng lx oi oj ni jh bi translated">MDETR:用于端到端多模态理解的调制检测</h2><blockquote class="pm pn po"><p id="e207" class="lg lh pp li b lj lk kl ll lm ln ko lo pq lq lr ls pr lu lv lw ps ly lz ma mb ij bi translated">MDETR(调制DETR)的预训练模型的代码和链接，用于对具有对齐文本和带有方框注释的图像的数据进行预训练，以及对需要精细理解图像和文本的任务进行微调。</p></blockquote><figure class="nq nr ns nt gt is gh gi paragraph-image"><div role="button" tabindex="0" class="nu nv di nw bf nx"><div class="gh gi pv"><img src="../Images/8dd02d5f53454b646891c3f4fbf99324.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*-Zlepu2o7a74P2uq.png"/></div></div></figure><div class="ip iq gp gr ir mc"><a href="https://github.com/ashkamath/mdetr" rel="noopener  ugc nofollow" target="_blank"><div class="md ab fo"><div class="me ab mf cl cj mg"><h2 class="bd jl gy z fp mh fr fs mi fu fw jk bi translated">ashkamath/mdetr</h2><div class="mj l"><h3 class="bd b gy z fp mh fr fs mi fu fw dk translated">该存储库包含MDETR(调制DETR)预训练模型的代码和链接，用于数据预训练…</h3></div><div class="mk l"><p class="bd b dl z fp mh fr fs mi fu fw dk translated">github.com</p></div></div><div class="ml l"><div class="pw l mn mo mp ml mq it mc"/></div></div></a></div><p id="8d3e" class="pw-post-body-paragraph lg lh jb li b lj lk kl ll lm ln ko lo lp lq lr ls lt lu lv lw lx ly lz ma mb ij bi translated"><a class="ae mr" href="https://www.connectedpapers.com/main/6a674fc4935441cbb1817f8c0804be29fe8efd72/arxiv" rel="noopener ugc nofollow" target="_blank"> <strong class="li jl">连接论文</strong> </a> <strong class="li jl">📈</strong></p></div><div class="ab cl kz la hu lb" role="separator"><span class="lc bw bk ld le lf"/><span class="lc bw bk ld le lf"/><span class="lc bw bk ld le"/></div><div class="ij ik il im in"><h2 id="febb" class="nz mt jb bd mu oa ob dn my oc od dp nc lp oe of ne lt og oh ng lx oi oj ni jh bi translated">XLM-T——Twitter的多语言语言模型工具包</h2><blockquote class="pm pn po"><p id="fe5c" class="lg lh pp li b lj lk kl ll lm ln ko lo pq lq lr ls pr lu lv lw ps ly lz ma mb ij bi translated">继续以XLM-罗伯塔模型为基础，在多种语言的Twitter大型语料库上进行预训练。包括4台colab笔记本电脑。</p></blockquote><div class="ip iq gp gr ir mc"><a href="https://github.com/cardiffnlp/xlm-t" rel="noopener  ugc nofollow" target="_blank"><div class="md ab fo"><div class="me ab mf cl cj mg"><h2 class="bd jl gy z fp mh fr fs mi fu fw jk bi translated">cardiffnlp/xlm-t</h2><div class="mj l"><h3 class="bd b gy z fp mh fr fs mi fu fw dk translated">这是XLM-T知识库，包括Twitter的数据、代码和预先训练的多语言模型。作为…</h3></div><div class="mk l"><p class="bd b dl z fp mh fr fs mi fu fw dk translated">github.com</p></div></div><div class="ml l"><div class="px l mn mo mp ml mq it mc"/></div></div></a></div><p id="f6f8" class="pw-post-body-paragraph lg lh jb li b lj lk kl ll lm ln ko lo lp lq lr ls lt lu lv lw lx ly lz ma mb ij bi translated"><a class="ae mr" href="https://www.connectedpapers.com/main/72d4e7e02070f1f0b88d99bc799a94e56576b79a/arxiv" rel="noopener ugc nofollow" target="_blank"> <strong class="li jl">连接论文</strong> </a> <strong class="li jl">📈</strong></p></div><div class="ab cl kz la hu lb" role="separator"><span class="lc bw bk ld le lf"/><span class="lc bw bk ld le lf"/><span class="lc bw bk ld le"/></div><div class="ij ik il im in"><h2 id="29a7" class="nz mt jb bd mu oa ob dn my oc od dp nc lp oe of ne lt og oh ng lx oi oj ni jh bi translated">弗兰克:真实性评估基准</h2><blockquote class="pm pn po"><p id="f185" class="lg lh pp li b lj lk kl ll lm ln ko lo pq lq lr ls pr lu lv lw ps ly lz ma mb ij bi translated">用于摘要系统中真实性的细粒度分析的事实错误的类型。</p></blockquote><div class="ip iq gp gr ir mc"><a href="https://github.com/artidoro/frank" rel="noopener  ugc nofollow" target="_blank"><div class="md ab fo"><div class="me ab mf cl cj mg"><h2 class="bd jl gy z fp mh fr fs mi fu fw jk bi translated">阿蒂多罗/弗兰克</h2><div class="mj l"><h3 class="bd b gy z fp mh fr fs mi fu fw dk translated">该存储库包含用于真实性评估指标的弗兰克基准的数据(参见我们的NAACL 2021论文…</h3></div><div class="mk l"><p class="bd b dl z fp mh fr fs mi fu fw dk translated">github.com</p></div></div><div class="ml l"><div class="py l mn mo mp ml mq it mc"/></div></div></a></div><p id="3953" class="pw-post-body-paragraph lg lh jb li b lj lk kl ll lm ln ko lo lp lq lr ls lt lu lv lw lx ly lz ma mb ij bi translated"><a class="ae mr" href="https://www.connectedpapers.com/main/7fa846dbfec30f8c92793344b8bf907ee1008c3e/arxiv" rel="noopener ugc nofollow" target="_blank"> <strong class="li jl">连接论文</strong> </a> <strong class="li jl">📈</strong></p></div><div class="ab cl kz la hu lb" role="separator"><span class="lc bw bk ld le lf"/><span class="lc bw bk ld le lf"/><span class="lc bw bk ld le"/></div><div class="ij ik il im in"><h2 id="e330" class="nz mt jb bd mu oa ob dn my oc od dp nc lp oe of ne lt og oh ng lx oi oj ni jh bi translated">法律文件相似性</h2><blockquote class="pm pn po"><p id="a154" class="lg lh pp li b lj lk kl ll lm ln ko lo pq lq lr ls pr lu lv lw ps ly lz ma mb ij bi translated">用于检索语义相关的美国案例法任务的一组最先进的文档表示方法。探索了基于文本(如fastText、Transformers)、基于引用(如DeepWalk、Poincaré)和<br/>的混合方法。</p></blockquote><div class="ip iq gp gr ir mc"><a href="https://github.com/malteos/legal-document-similarity" rel="noopener  ugc nofollow" target="_blank"><div class="md ab fo"><div class="me ab mf cl cj mg"><h2 class="bd jl gy z fp mh fr fs mi fu fw jk bi translated">malteos/法律文档相似性</h2><div class="mj l"><h3 class="bd b gy z fp mh fr fs mi fu fw dk translated">实现，训练模型和结果数据的论文评估文件表示的内容为基础的…</h3></div><div class="mk l"><p class="bd b dl z fp mh fr fs mi fu fw dk translated">github.com</p></div></div><div class="ml l"><div class="pz l mn mo mp ml mq it mc"/></div></div></a></div><p id="af93" class="pw-post-body-paragraph lg lh jb li b lj lk kl ll lm ln ko lo lp lq lr ls lt lu lv lw lx ly lz ma mb ij bi translated"><a class="ae mr" href="https://www.connectedpapers.com/main/4a219fb004ed1bffdb377040a953bbdf347aac06/arxiv" rel="noopener ugc nofollow" target="_blank"> <strong class="li jl">连接论文</strong> </a> <strong class="li jl">📈</strong></p></div><div class="ab cl kz la hu lb" role="separator"><span class="lc bw bk ld le lf"/><span class="lc bw bk ld le lf"/><span class="lc bw bk ld le"/></div><div class="ij ik il im in"><h1 id="ff81" class="ms mt jb bd mu mv mw mx my mz na nb nc kq nd kr ne kt nf ku ng kw nh kx ni nj bi translated">本周数据集:Shellcode_IA32👩‍💻</h1><h2 id="80c7" class="nz mt jb bd mu oa ob dn my oc od dp nc lp oe of ne lt og oh ng lx oi oj ni jh bi translated">这是什么？</h2><p id="e7dc" class="pw-post-body-paragraph lg lh jb li b lj nk kl ll lm nl ko lo lp nm lr ls lt nn lv lw lx no lz ma mb ij bi translated">Shellcode_IA32是一个数据集，包含20年来各种来源的外壳代码，是迄今为止汇编中最大的外壳代码集合。该数据集由3，200个汇编语言指令示例组成，这些指令用于公开发布的安全漏洞中的<em class="pp">IA-32</em>(x86英特尔架构的32位版本)。数据集用于自动生成shell代码(代码生成任务)。收集了用于从<a class="ae mr" href="https://www.exploit-db.com/shellcodes?platform=linux_x86" rel="noopener ugc nofollow" target="_blank"> exploit-db </a>和<a class="ae mr" href="http://shell-storm.org/shellcode/" rel="noopener ugc nofollow" target="_blank"> shell-storm </a>生成外壳代码的汇编程序。</p><p id="0e74" class="pw-post-body-paragraph lg lh jb li b lj lk kl ll lm ln ko lo lp lq lr ls lt lu lv lw lx ly lz ma mb ij bi translated"><a class="ae mr" href="https://arxiv.org/pdf/2104.13100.pdf" rel="noopener ugc nofollow" target="_blank"> <strong class="li jl">论文</strong> </a></p><h2 id="e700" class="nz mt jb bd mu oa ob dn my oc od dp nc lp oe of ne lt og oh ng lx oi oj ni jh bi translated">它在哪里？</h2><div class="ip iq gp gr ir mc"><a href="https://github.com/dessertlab/Shellcode_IA32" rel="noopener  ugc nofollow" target="_blank"><div class="md ab fo"><div class="me ab mf cl cj mg"><h2 class="bd jl gy z fp mh fr fs mi fu fw jk bi translated">dessertlab/Shellcode_IA32</h2><div class="mj l"><h3 class="bd b gy z fp mh fr fs mi fu fw dk translated">Shellcode_IA32是一个数据集，由具有挑战性但常见的汇编指令组成，收集自真实的shellcode…</h3></div><div class="mk l"><p class="bd b dl z fp mh fr fs mi fu fw dk translated">github.com</p></div></div><div class="ml l"><div class="qa l mn mo mp ml mq it mc"/></div></div></a></div></div><div class="ab cl kz la hu lb" role="separator"><span class="lc bw bk ld le lf"/><span class="lc bw bk ld le lf"/><span class="lc bw bk ld le"/></div><div class="ij ik il im in"><blockquote class="qb"><p id="b330" class="qc qd jb bd qe qf qg qh qi qj qk mb dk translated">每周日，我们都会对来自世界各地研究人员的NLP新闻和代码进行一次每周综述。</p><p id="8639" class="qc qd jb bd qe qf qg qh qi qj qk mb dk translated">如需完整报道，请关注我们的Twitter: <a class="ae mr" href="http://twitter.com/Quantum_Stat" rel="noopener ugc nofollow" target="_blank"> @Quantum_Stat </a></p></blockquote><figure class="qm qn qo qp qq is gh gi paragraph-image"><div class="gh gi ql"><img src="../Images/605d15bdf547bb10223a0601abc84af6.png" data-original-src="https://miro.medium.com/v2/resize:fit:108/0*vgf45g9haG4f6VcH"/></div><figcaption class="iv iw gj gh gi ix iy bd b be z dk translated"><a class="ae mr" href="https://quantumstat.com/" rel="noopener ugc nofollow" target="_blank">量子统计</a></figcaption></figure></div></div>    
</body>
</html>