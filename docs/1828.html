<html>
<head>
<title>Different Types of Clustering Methods in Unsupervised Learning</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">无监督学习中不同类型的聚类方法</h1>
<blockquote>原文：<a href="https://pub.towardsai.net/machine-learning-16c8ccc2c7b8?source=collection_archive---------0-----------------------#2021-05-08">https://pub.towardsai.net/machine-learning-16c8ccc2c7b8?source=collection_archive---------0-----------------------#2021-05-08</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><h2 id="7652" class="ir is it bd b dl iu iv iw ix iy iz dk ja translated" aria-label="kicker paragraph"><a class="ae ep" href="https://towardsai.net/p/category/machine-learning" rel="noopener ugc nofollow" target="_blank">机器学习</a></h2><div class=""/><div class=""><h2 id="fc8a" class="pw-subtitle-paragraph jz jc it bd b ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq dk translated">机器学习聚类算法</h2></div><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div class="gh gi kr"><img src="../Images/92fec1bd9ea75054da5b5d1049e1586a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1314/format:webp/1*mVEyWW05ZC0gLIG3BDxT1w.png"/></div><figcaption class="kz la gj gh gi lb lc bd b be z dk translated">无监督聚类方法。作者的照片</figcaption></figure><p id="1a6a" class="pw-post-body-paragraph ld le it lf b lg lh kd li lj lk kg ll lm ln lo lp lq lr ls lt lu lv lw lx ly im bi translated">在本文中，我们将分析无监督机器学习中不同类型的聚类算法。这些算法将通过参数、可伸缩性、用例以及几何来区分。</p><p id="2f06" class="pw-post-body-paragraph ld le it lf b lg lh kd li lj lk kg ll lm ln lo lp lq lr ls lt lu lv lw lx ly im bi translated">这些方法的主要焦点是利用一些距离测量公式来发现数据中的聚类或组。聚类方法很简单，因为在这些方法中我们很少进行训练和测试。</p><p id="9d3a" class="pw-post-body-paragraph ld le it lf b lg lh kd li lj lk kg ll lm ln lo lp lq lr ls lt lu lv lw lx ly im bi translated">不使用训练和测试集的原因是因为这些方法使用基于距离度量的数据相似性、基于密集数据的分组、基于特征树的方法等。</p><h2 id="7e9b" class="lz ma it bd mb mc md dn me mf mg dp mh lm mi mj mk lq ml mm mn lu mo mp mq iz bi translated">不同类型的聚类算法</h2><blockquote class="mr ms mt"><p id="a9e5" class="ld le mu lf b lg lh kd li lj lk kg ll mv ln lo lp mw lr ls lt mx lv lw lx ly im bi translated"><strong class="lf jd"><em class="it">K-均值聚类</em> </strong></p></blockquote><p id="8953" class="pw-post-body-paragraph ld le it lf b lg lh kd li lj lk kg ll lm ln lo lp lq lr ls lt lu lv lw lx ly im bi translated">该方法基于距离度量和具有相等方差的数据相似性。</p><ul class=""><li id="bc0f" class="my mz it lf b lg lh lj lk lm na lq nb lu nc ly nd ne nf ng bi translated"><strong class="lf jd">参数:</strong>该方法需要指定聚类数。</li><li id="f56c" class="my mz it lf b lg nh lj ni lm nj lq nk lu nl ly nd ne nf ng bi translated"><strong class="lf jd">可扩展性:</strong>k-means适用于大量样本，在mini-batch的帮助下，它也适用于中等数量的聚类。</li><li id="0613" class="my mz it lf b lg nh lj ni lm nj lq nk lu nl ly nd ne nf ng bi translated"><strong class="lf jd">用例:</strong>它用于偶数簇，它有一个平坦的几何图形，有簇数的限制。</li><li id="d667" class="my mz it lf b lg nh lj ni lm nj lq nk lu nl ly nd ne nf ng bi translated"><strong class="lf jd">几何:</strong>它使用距离度量来寻找数据中的组相似性。</li></ul><blockquote class="mr ms mt"><p id="8f6b" class="ld le mu lf b lg lh kd li lj lk kg ll mv ln lo lp mw lr ls lt mx lv lw lx ly im bi translated"><strong class="lf jd"> <em class="it">亲和传播聚类</em> </strong></p></blockquote><p id="20e8" class="pw-post-body-paragraph ld le it lf b lg lh kd li lj lk kg ll lm ln lo lp lq lr ls lt lu lv lw lx ly im bi translated">该方法基于发送到数据对的消息，该数据对更新直到用于最终聚类的最终样本。</p><ul class=""><li id="8c77" class="my mz it lf b lg lh lj lk lm na lq nb lu nc ly nd ne nf ng bi translated"><strong class="lf jd">参数:</strong>该方法需要两个参数，第一个是控制样本数量的偏好，第二个是阻尼，以避免消息中的振荡。</li><li id="e860" class="my mz it lf b lg nh lj ni lm nj lq nk lu nl ly nd ne nf ng bi translated"><strong class="lf jd">可扩展性:</strong>不随样本数量而扩展。</li><li id="8aca" class="my mz it lf b lg nh lj ni lm nj lq nk lu nl ly nd ne nf ng bi translated"><strong class="lf jd">使用案例:</strong>它用于不均匀的集群大小，它具有非平坦的几何形状，它采用归纳法工作，即从想法的数量到它们的最终关系。</li><li id="cc18" class="my mz it lf b lg nh lj ni lm nj lq nk lu nl ly nd ne nf ng bi translated"><strong class="lf jd">几何:</strong>它使用图距离度量来寻找最近邻。</li></ul><blockquote class="mr ms mt"><p id="86ab" class="ld le mu lf b lg lh kd li lj lk kg ll mv ln lo lp mw lr ls lt mx lv lw lx ly im bi translated"><strong class="lf jd"> <em class="it">均值漂移聚类</em> </strong></p></blockquote><p id="98ac" class="pw-post-body-paragraph ld le it lf b lg lh kd li lj lk kg ll lm ln lo lp lq lr ls lt lu lv lw lx ly im bi translated">该方法基于blob方法，以该区域中的点的平均值来寻找聚类。</p><ul class=""><li id="086b" class="my mz it lf b lg lh lj lk lm na lq nb lu nc ly nd ne nf ng bi translated"><strong class="lf jd">参数:</strong>该方法需要带宽来检测区域的大小。</li><li id="d59f" class="my mz it lf b lg nh lj ni lm nj lq nk lu nl ly nd ne nf ng bi translated"><strong class="lf jd">可扩展性:</strong>它不随样本数量而扩展，即它需要更多的最近邻多重搜索。</li><li id="004c" class="my mz it lf b lg nh lj ni lm nj lq nk lu nl ly nd ne nf ng bi translated"><strong class="lf jd">使用案例:</strong>它用于不均匀的集群大小，它具有非平坦的几何形状，它采用归纳法工作，即从想法的数量到它们的最终关系。与亲和法相同。</li><li id="20e6" class="my mz it lf b lg nh lj ni lm nj lq nk lu nl ly nd ne nf ng bi translated"><strong class="lf jd">几何:</strong>它使用距离度量来发现数据中的组相似性。</li></ul><blockquote class="mr ms mt"><p id="7423" class="ld le mu lf b lg lh kd li lj lk kg ll mv ln lo lp mw lr ls lt mx lv lw lx ly im bi translated"><strong class="lf jd"> <em class="it">桦树集群</em> </strong></p></blockquote><p id="f4ef" class="pw-post-body-paragraph ld le it lf b lg lh kd li lj lk kg ll lm ln lo lp lq lr ls lt lu lv lw lx ly im bi translated">这种方法是基于层次聚类特征树(CFT)和处理噪声很好。</p><ul class=""><li id="472d" class="my mz it lf b lg lh lj lk lm na lq nb lu nc ly nd ne nf ng bi translated"><strong class="lf jd">参数:</strong>该方法参数基于分支因子，如使用树和全局聚类。</li><li id="ad90" class="my mz it lf b lg nh lj ni lm nj lq nk lu nl ly nd ne nf ng bi translated"><strong class="lf jd">可伸缩性:</strong>BIRCH可以处理大量样本，也可以处理中等数量的聚类。</li><li id="86e7" class="my mz it lf b lg nh lj ni lm nj lq nk lu nl ly nd ne nf ng bi translated"><strong class="lf jd">使用案例:</strong>它用于不均匀的集群大小，它具有扁平的几何形状，它以归纳的方法工作，即从想法的数量到它们的最终关系。它在剔除异常值和减少数据方面表现良好。</li><li id="c35b" class="my mz it lf b lg nh lj ni lm nj lq nk lu nl ly nd ne nf ng bi translated"><strong class="lf jd">几何:</strong>它使用欧几里德距离度量来进行聚类。</li></ul><div class="nm nn gp gr no np"><a rel="noopener  ugc nofollow" target="_blank" href="/fully-explained-birch-clustering-for-outliers-with-python-2ad6243f126b"><div class="nq ab fo"><div class="nr ab ns cl cj nt"><h2 class="bd jd gy z fp nu fr fs nv fu fw jc bi translated">用Python对异常值进行BIRCH聚类的完整解释</h2><div class="nw l"><h3 class="bd b gy z fp nu fr fs nv fu fw dk translated">聚类中的无监督学习为数据建立树</h3></div><div class="nx l"><p class="bd b dl z fp nu fr fs nv fu fw dk translated">pub.towardsai.net</p></div></div><div class="ny l"><div class="nz l oa ob oc ny od kx np"/></div></div></a></div><blockquote class="mr ms mt"><p id="35aa" class="ld le mu lf b lg lh kd li lj lk kg ll mv ln lo lp mw lr ls lt mx lv lw lx ly im bi translated"><strong class="lf jd"> <em class="it"> DBSCAN聚类</em> </strong></p></blockquote><p id="9f78" class="pw-post-body-paragraph ld le it lf b lg lh kd li lj lk kg ll lm ln lo lp lq lr ls lt lu lv lw lx ly im bi translated">该方法基于数据点的密度，用半径和最小点信息覆盖最大数据点。</p><ul class=""><li id="5e31" class="my mz it lf b lg lh lj lk lm na lq nb lu nc ly nd ne nf ng bi translated"><strong class="lf jd">参数:</strong>该方法参数基于邻域大小。</li><li id="2a6f" class="my mz it lf b lg nh lj ni lm nj lq nk lu nl ly nd ne nf ng bi translated"><strong class="lf jd">可伸缩性:</strong>DBS can可以处理大量的样本，也可以处理中等数量的集群。</li><li id="008f" class="my mz it lf b lg nh lj ni lm nj lq nk lu nl ly nd ne nf ng bi translated"><strong class="lf jd">用例:</strong>它用于不均匀的聚类大小，它具有非平坦的几何形状，它基于直推方法工作，即它用于未标记的点进行聚类。</li><li id="6684" class="my mz it lf b lg nh lj ni lm nj lq nk lu nl ly nd ne nf ng bi translated"><strong class="lf jd">几何:</strong>它使用到最近点的距离度量来进行聚类。</li></ul><div class="nm nn gp gr no np"><a rel="noopener  ugc nofollow" target="_blank" href="/fully-explained-dbscan-clustering-algorithm-with-python-a568139ebff5"><div class="nq ab fo"><div class="nr ab ns cl cj nt"><h2 class="bd jd gy z fp nu fr fs nv fu fw jc bi translated">用Python全面解释DBScan聚类算法</h2><div class="nw l"><h3 class="bd b gy z fp nu fr fs nv fu fw dk translated">基于密度聚类的机器学习中的无监督学习</h3></div><div class="nx l"><p class="bd b dl z fp nu fr fs nv fu fw dk translated">pub.towardsai.net</p></div></div><div class="ny l"><div class="oe l oa ob oc ny od kx np"/></div></div></a></div><div class="nm nn gp gr no np"><a rel="noopener  ugc nofollow" target="_blank" href="/data-preprocessing-concepts-with-python-b93c63f14bb6"><div class="nq ab fo"><div class="nr ab ns cl cj nt"><h2 class="bd jd gy z fp nu fr fs nv fu fw jc bi translated">Python中的数据预处理概念</h2><div class="nw l"><h3 class="bd b gy z fp nu fr fs nv fu fw dk translated">一种为机器学习估值器准备数据的稳健方法</h3></div><div class="nx l"><p class="bd b dl z fp nu fr fs nv fu fw dk translated">pub.towardsai.net</p></div></div><div class="ny l"><div class="of l oa ob oc ny od kx np"/></div></div></a></div><blockquote class="mr ms mt"><p id="b2ad" class="ld le mu lf b lg lh kd li lj lk kg ll mv ln lo lp mw lr ls lt mx lv lw lx ly im bi translated"><strong class="lf jd"> <em class="it">光学聚类</em> </strong></p></blockquote><p id="42d8" class="pw-post-body-paragraph ld le it lf b lg lh kd li lj lk kg ll lm ln lo lp lq lr ls lt lu lv lw lx ly im bi translated">该方法基于范围值来获得可达性距离并对属性进行排序。</p><ul class=""><li id="ef52" class="my mz it lf b lg lh lj lk lm na lq nb lu nc ly nd ne nf ng bi translated"><strong class="lf jd">参数:</strong>该方法参数基于最小聚类成员。</li><li id="2b9f" class="my mz it lf b lg nh lj ni lm nj lq nk lu nl ly nd ne nf ng bi translated"><strong class="lf jd">可扩展性:</strong>光学系统可以处理大量样本，也可以处理中等数量的集群。</li><li id="a8da" class="my mz it lf b lg nh lj ni lm nj lq nk lu nl ly nd ne nf ng bi translated"><strong class="lf jd">用例:</strong>它用于不均匀的聚类大小，它具有非平坦的几何形状，它基于直推方法工作，即它用于未标记点的聚类。它也适用于不同规模的集群。</li><li id="5ea7" class="my mz it lf b lg nh lj ni lm nj lq nk lu nl ly nd ne nf ng bi translated"><strong class="lf jd">几何:</strong>它使用点与点之间的距离度量。</li></ul><blockquote class="mr ms mt"><p id="893f" class="ld le mu lf b lg lh kd li lj lk kg ll mv ln lo lp mw lr ls lt mx lv lw lx ly im bi translated"><strong class="lf jd"> <em class="it">集聚聚类</em> </strong></p></blockquote><p id="c5f8" class="pw-post-body-paragraph ld le it lf b lg lh kd li lj lk kg ll lm ln lo lp lq lr ls lt lu lv lw lx ly im bi translated">这种方法基于分层聚类，将聚类合并到另一个聚类中。</p><ul class=""><li id="cccb" class="my mz it lf b lg lh lj lk lm na lq nb lu nc ly nd ne nf ng bi translated"><strong class="lf jd">参数:</strong>该方法需要连接准则来合并聚类。</li><li id="95cd" class="my mz it lf b lg nh lj ni lm nj lq nk lu nl ly nd ne nf ng bi translated"><strong class="lf jd">可伸缩性:</strong>agglomerate对大量的样本和集群进行处理。</li><li id="67c8" class="my mz it lf b lg nh lj ni lm nj lq nk lu nl ly nd ne nf ng bi translated"><strong class="lf jd">用例:</strong>它已用于许多集群大小，它有一个连接性约束，并在直推方法上工作，即它用于未标记点的聚类。</li><li id="2ff9" class="my mz it lf b lg nh lj ni lm nj lq nk lu nl ly nd ne nf ng bi translated"><strong class="lf jd">几何:</strong>它使用成对的距离度量来进行聚类。</li></ul><div class="nm nn gp gr no np"><a rel="noopener  ugc nofollow" target="_blank" href="/data-preprocessing-concepts-with-python-b93c63f14bb6"><div class="nq ab fo"><div class="nr ab ns cl cj nt"><h2 class="bd jd gy z fp nu fr fs nv fu fw jc bi translated">Python中的数据预处理概念</h2><div class="nw l"><h3 class="bd b gy z fp nu fr fs nv fu fw dk translated">一种为机器学习估值器准备数据的稳健方法</h3></div><div class="nx l"><p class="bd b dl z fp nu fr fs nv fu fw dk translated">pub.towardsai.net</p></div></div><div class="ny l"><div class="of l oa ob oc ny od kx np"/></div></div></a></div><p id="89b3" class="pw-post-body-paragraph ld le it lf b lg lh kd li lj lk kg ll lm ln lo lp lq lr ls lt lu lv lw lx ly im bi translated">我希望你喜欢这篇文章。通过我的<a class="ae og" href="https://www.linkedin.com/in/data-scientist-95040a1ab/" rel="noopener ugc nofollow" target="_blank"> LinkedIn </a>和<a class="ae og" href="https://twitter.com/amitprius" rel="noopener ugc nofollow" target="_blank"> twitter </a>联系我。</p><h1 id="1890" class="oh ma it bd mb oi oj ok me ol om on mh ki oo kj mk kl op km mn ko oq kp mq or bi translated">推荐文章</h1><p id="b243" class="pw-post-body-paragraph ld le it lf b lg os kd li lj ot kg ll lm ou lo lp lq ov ls lt lu ow lw lx ly im bi translated"><a class="ae og" href="https://medium.com/towards-artificial-intelligence/nlp-zero-to-hero-with-python-2df6fcebff6e?sk=2231d868766e96b13d1e9d7db6064df1" rel="noopener"> 1。NLP —零到英雄与Python </a> <br/> 2。<a class="ae og" href="https://medium.com/towards-artificial-intelligence/python-data-structures-data-types-and-objects-244d0a86c3cf?sk=42f4b462499f3fc3a160b21e2c94dba6" rel="noopener"> Python数据结构数据类型和对象</a>T5】3 .<a class="ae og" rel="noopener ugc nofollow" target="_blank" href="/exception-handling-concepts-in-python-4d5116decac3?source=friends_link&amp;sk=a0ed49d9fdeaa67925eac34ecb55ea30">Python中的异常处理概念</a> <br/> 4。<a class="ae og" rel="noopener ugc nofollow" target="_blank" href="/principal-component-analysis-in-dimensionality-reduction-with-python-1a613006d531?source=friends_link&amp;sk=3ed0671fdc04ba395dd36478bcea8a55">用Python进行主成分分析降维</a> <br/> 5。<a class="ae og" href="https://medium.com/towards-artificial-intelligence/fully-explained-k-means-clustering-with-python-e7caa573176a?source=friends_link&amp;sk=9c5c613ceb10f2d203712634f3b6fb28" rel="noopener">用Python全面讲解K-means聚类</a> <br/> 6。<a class="ae og" href="https://medium.com/towards-artificial-intelligence/fully-explained-linear-regression-with-python-fe2b313f32f3?source=friends_link&amp;sk=53c91a2a51347ec2d93f8222c0e06402" rel="noopener">用Python </a> <br/> 7全面讲解了线性回归。<a class="ae og" href="https://medium.com/towards-artificial-intelligence/fully-explained-logistic-regression-with-python-f4a16413ddcd?source=friends_link&amp;sk=528181f15a44e48ea38fdd9579241a78" rel="noopener">用Python </a> <br/>充分解释了Logistic回归8。<a class="ae og" rel="noopener ugc nofollow" target="_blank" href="/differences-between-concat-merge-and-join-with-python-1a6541abc08d?source=friends_link&amp;sk=3b37b694fb90db16275059ea752fc16a">concat()、merge()和join()与Python </a> <br/>的区别9。<a class="ae og" rel="noopener ugc nofollow" target="_blank" href="/data-wrangling-with-python-part-1-969e3cc81d69?source=friends_link&amp;sk=9c3649cf20f31a5c9ead51c50c89ba0b">与Python的数据角力—第一部分</a> <br/> 10。<a class="ae og" href="https://medium.com/analytics-vidhya/confusion-matrix-in-machine-learning-91b6e2b3f9af?source=friends_link&amp;sk=11c6531da0bab7b504d518d02746d4cc" rel="noopener">机器学习中的混淆矩阵</a></p></div></div>    
</body>
</html>