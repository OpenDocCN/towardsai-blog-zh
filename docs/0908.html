<html>
<head>
<title>Deep Learning for Dog Breed Classification</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">用于狗品种分类的深度学习</h1>
<blockquote>原文：<a href="https://pub.towardsai.net/deep-learning-for-dog-breed-classification-77ef182a2509?source=collection_archive---------1-----------------------#2020-09-09">https://pub.towardsai.net/deep-learning-for-dog-breed-classification-77ef182a2509?source=collection_archive---------1-----------------------#2020-09-09</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><h2 id="c713" class="io ip iq bd b dl ir is it iu iv iw dk ix translated" aria-label="kicker paragraph"><a class="ae ep" href="https://towardsai.net/p/category/machine-learning/deep-learning" rel="noopener ugc nofollow" target="_blank">深度学习</a></h2><div class=""/><div class=""><h2 id="ab49" class="pw-subtitle-paragraph jw iz iq bd b jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn dk translated">一步一步的指南来分类115个品种的狗图片！</h2></div><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div role="button" tabindex="0" class="ku kv di kw bf kx"><div class="gh gi ko"><img src="../Images/77128c0042fd05706042088373dd82b9.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*2M1YzdF1QhqU_OMEQCE04w.png"/></div></div></figure><p id="bd4a" class="pw-post-body-paragraph la lb iq lc b ld le ka lf lg lh kd li lj lk ll lm ln lo lp lq lr ls lt lu lv ij bi translated">被困在付费墙后面？点击<a class="ae lw" href="https://medium.com/@D3nii/deep-learning-for-dog-breed-classification-77ef182a2509?sk=75f557ce9311099549cb8909a4dff6cb" rel="noopener">这里</a>阅读完整故事与我的朋友链接！</p><p id="df0e" class="pw-post-body-paragraph la lb iq lc b ld le ka lf lg lh kd li lj lk ll lm ln lo lp lq lr ls lt lu lv ij bi translated">根据dogtime.com<a class="ae lw" href="https://dogtime.com/dog-breeds/profiles" rel="noopener ugc nofollow" target="_blank">的说法，世界上有266种不同的狗，光是想想这个数字，我就害怕去区分它们。而大部分人，如果正常的话，只知道5-10个品种，因为你没有看到学士课程中的章节<strong class="lc ja"><em class="lx">【266种不同犬种】</em> </strong>。</a></p></div><div class="ab cl ly lz hu ma" role="separator"><span class="mb bw bk mc md me"/><span class="mb bw bk mc md me"/><span class="mb bw bk mc md"/></div><div class="ij ik il im in"><h1 id="1c2f" class="mf mg iq bd mh mi mj mk ml mm mn mo mp kf mq kg mr ki ms kj mt kl mu km mv mw bi translated">概观</h1><p id="0a5f" class="pw-post-body-paragraph la lb iq lc b ld mx ka lf lg my kd li lj mz ll lm ln na lp lq lr nb lt lu lv ij bi translated">这个项目的主要目的是建立一个算法来从数据集中分类不同的狗品种。</p><p id="0e19" class="pw-post-body-paragraph la lb iq lc b ld le ka lf lg lh kd li lj lk ll lm ln lo lp lq lr ls lt lu lv ij bi translated">这似乎是一个简单的任务，但当我们想到机器学习时，它就不是了！这些图像是随机排列的，在图像中的随机空间有狗，这些图像是以不同的亮度拍摄的，没有对数据进行预处理，它只是一个包含简单狗图片的数据集。</p><p id="4249" class="pw-post-body-paragraph la lb iq lc b ld le ka lf lg lh kd li lj lk ll lm ln lo lp lq lr ls lt lu lv ij bi translated">所以，第一步是看一下数据集。</p><h1 id="916a" class="mf mg iq bd mh mi nc mk ml mm nd mo mp kf ne kg mr ki nf kj mt kl ng km mv mw bi translated">环境和工具</h1><ul class=""><li id="25fd" class="nh ni iq lc b ld mx lg my lj nj ln nk lr nl lv nm nn no np bi translated"><a class="ae lw" href="https://scikit-learn.org/stable/" rel="noopener ugc nofollow" target="_blank"> scikit-learn </a></li><li id="64bf" class="nh ni iq lc b ld nq lg nr lj ns ln nt lr nu lv nm nn no np bi translated"><a class="ae lw" href="https://keras.io/" rel="noopener ugc nofollow" target="_blank"> Keras </a></li><li id="6499" class="nh ni iq lc b ld nq lg nr lj ns ln nt lr nu lv nm nn no np bi translated"><a class="ae lw" href="https://www.numpy.org/" rel="noopener ugc nofollow" target="_blank">数字价格</a></li><li id="6332" class="nh ni iq lc b ld nq lg nr lj ns ln nt lr nu lv nm nn no np bi translated"><a class="ae lw" href="https://pandas.pydata.org/" rel="noopener ugc nofollow" target="_blank">熊猫</a></li><li id="0f0c" class="nh ni iq lc b ld nq lg nr lj ns ln nt lr nu lv nm nn no np bi translated"><a class="ae lw" href="https://matplotlib.org/" rel="noopener ugc nofollow" target="_blank"> matplotlib </a></li></ul><h1 id="3fd7" class="mf mg iq bd mh mi nc mk ml mm nd mo mp kf ne kg mr ki nf kj mt kl ng km mv mw bi translated">数据</h1><p id="b049" class="pw-post-body-paragraph la lb iq lc b ld mx ka lf lg my kd li lj mz ll lm ln na lp lq lr nb lt lu lv ij bi translated">这个项目使用的数据集是<a class="ae lw" href="http://vision.stanford.edu/aditya86/ImageNetDogs/main.html" rel="noopener ugc nofollow" target="_blank">斯坦福狗数据集</a>。该数据集包含120种不同狗品种的总共20，580张图像。</p><blockquote class="nv nw nx"><p id="1429" class="la lb lx lc b ld le ka lf lg lh kd li ny lk ll lm nz lo lp lq oa ls lt lu lv ij bi translated">斯坦福狗数据集包含来自世界各地的120种狗的图像。这个数据集是使用ImageNet中的图像和注释构建的，用于细粒度的图像分类任务。</p></blockquote><h2 id="9640" class="ob mg iq bd mh oc od dn ml oe of dp mp lj og oh mr ln oi oj mt lr ok ol mv iw bi translated">导入库</h2><pre class="kp kq kr ks gt om on oo op aw oq bi"><span id="6353" class="ob mg iq on b gy or os l ot ou">import os<br/>import sys<br/>import keras<br/>import tarfile<br/>import numpy as np<br/>import tensorflow as tf<br/>import matplotlib.pyplot as plt</span><span id="8486" class="ob mg iq on b gy ov os l ot ou">from keras.models import Sequential<br/>from keras.engine.training import Model<br/>from sklearn.preprocessing import LabelBinarizer<br/>from keras.preprocessing.image import ImageDataGenerator<br/>from keras.layers import Add, Dropout, Flatten, Dense, Activation</span></pre><h2 id="faad" class="ob mg iq bd mh oc od dn ml oe of dp mp lj og oh mr ln oi oj mt lr ok ol mv iw bi translated">数据预处理</h2><p id="ed83" class="pw-post-body-paragraph la lb iq lc b ld mx ka lf lg my kd li lj mz ll lm ln na lp lq lr nb lt lu lv ij bi translated">我发现5个目录是不可用的，因此，没有使用它们。所以，我一共进口了115个品种。</p><pre class="kp kq kr ks gt om on oo op aw oq bi"><span id="52ac" class="ob mg iq on b gy or os l ot ou">import cv2</span><span id="f7e5" class="ob mg iq on b gy ov os l ot ou">BASEPATH = './Images'<br/>LABELS = set()<br/>paths = []</span><span id="0f22" class="ob mg iq on b gy ov os l ot ou">for d in os.listdir(BASEPATH):<br/>LABELS.add(d)<br/>paths.append((BASEPATH + '/' + d, d))</span><span id="40e6" class="ob mg iq on b gy ov os l ot ou"># resizing and converting to RGB<br/>def load_and_preprocess_image(path):<br/>image = cv2.imread(path)<br/>image = cv2.resize(image, (224, 224))<br/>image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)<br/>return image</span><span id="e3b3" class="ob mg iq on b gy ov os l ot ou">X, y = [], []<br/>i = 0</span><span id="8068" class="ob mg iq on b gy ov os l ot ou">for path, label in paths:<br/>i += 1</span><span id="3596" class="ob mg iq on b gy ov os l ot ou"># Faulty Directories<br/>if i == 18 or i == 23 or i == 41 or i == 49 or i == 90: continue <br/>if path == "./Images/.DS_Store": continue</span><span id="9cdf" class="ob mg iq on b gy ov os l ot ou">for image_path in os.listdir(path):<br/>image = load_and_preprocess_image(path + "/" + image_path)<br/>X.append(image)<br/>y.append(label)</span></pre><p id="3ba1" class="pw-post-body-paragraph la lb iq lc b ld le ka lf lg lh kd li lj lk ll lm ln lo lp lq lr ls lt lu lv ij bi translated">现在，文件夹的名称是这个模式<em class="lx">‘n 8725563753-Husky’</em>，因此，我们需要清理它，以保留名称的<em class="lx">‘Husky’</em>部分。</p><pre class="kp kq kr ks gt om on oo op aw oq bi"><span id="b5c1" class="ob mg iq on b gy or os l ot ou">Y = []</span><span id="bddb" class="ob mg iq on b gy ov os l ot ou"># Cleaning the names of the directories/targets<br/>for i in y:<br/>Y.append(i.split('-')[1])</span></pre><h2 id="b500" class="ob mg iq bd mh oc od dn ml oe of dp mp lj og oh mr ln oi oj mt lr ok ol mv iw bi translated">标签二值化器</h2><p id="f928" class="pw-post-body-paragraph la lb iq lc b ld mx ka lf lg my kd li lj mz ll lm ln na lp lq lr nb lt lu lv ij bi translated">这个依赖来自于<em class="lx"> sklearn.preprocessing </em>，用于获得字符串的二进制表示。<em class="lx">我们为什么要在这里使用它？</em>我们不能在模型中使用<em class="lx">‘哈士奇’</em>作为目标，我们需要把它转换成可用的数据类型，<em class="lx">数字</em>。因此，我们使用这个。</p><pre class="kp kq kr ks gt om on oo op aw oq bi"><span id="8767" class="ob mg iq on b gy or os l ot ou">encoder = LabelBinarizer()</span><span id="daf4" class="ob mg iq on b gy ov os l ot ou">y = encoder.fit_transform(np.array(y))</span></pre><h2 id="8aa2" class="ob mg iq bd mh oc od dn ml oe of dp mp lj og oh mr ln oi oj mt lr ok ol mv iw bi translated">拆分数据</h2><p id="7556" class="pw-post-body-paragraph la lb iq lc b ld mx ka lf lg my kd li lj mz ll lm ln na lp lq lr nb lt lu lv ij bi translated">我们正在使用来自<em class="lx">sk learn . model _ selection</em>的<a class="ae lw" href="https://www.google.com/url?sa=t&amp;rct=j&amp;q=&amp;esrc=s&amp;source=web&amp;cd=&amp;cad=rja&amp;uact=8&amp;ved=2ahUKEwjNl_SCxq_rAhXkzIUKHUdoA1kQFjAAegQIAxAB&amp;url=http%3A%2F%2Fscikit-learn.org%2Fstable%2Fmodules%2Fgenerated%2Fsklearn.model_selection.train_test_split.html&amp;usg=AOvVaw0VvM_hdQkS03aadJz9AKKA" rel="noopener ugc nofollow" target="_blank"><em class="lx">train _ test _ split</em></a>依赖项。</p><blockquote class="nv nw nx"><p id="65a7" class="la lb lx lc b ld le ka lf lg lh kd li ny lk ll lm nz lo lp lq oa ls lt lu lv ij bi translated"><code class="fe ow ox oy on b"><em class="iq">train_test_split</em></code>是<strong class="lc ja"> Sklearn模型选择</strong>中的一个函数，用于将数据组分成<strong class="lc ja">两个子集</strong>:训练数据和测试数据。有了这个函数，就不需要手动划分数据集了。</p><p id="06e0" class="la lb lx lc b ld le ka lf lg lh kd li ny lk ll lm nz lo lp lq oa ls lt lu lv ij bi translated">默认情况下，sk learn<strong class="lc ja">train _ test _ split</strong>会对这两个子集进行随机分区。但是，您也可以为操作指定随机状态。</p></blockquote><pre class="kp kq kr ks gt om on oo op aw oq bi"><span id="9242" class="ob mg iq on b gy or os l ot ou">from sklearn.model_selection import train_test_split</span><span id="f048" class="ob mg iq on b gy ov os l ot ou">X = np.array(X)</span><span id="c3c6" class="ob mg iq on b gy ov os l ot ou">x_train, x_test, y_train, y_test = train_test_split(X, Y, test_size=0.25, random_state=87)</span></pre><p id="bfd7" class="pw-post-body-paragraph la lb iq lc b ld le ka lf lg lh kd li lj lk ll lm ln lo lp lq lr ls lt lu lv ij bi translated">现在，在此之后，我们将<em class="lx"> x_train </em>和<em class="lx"> x_test </em>设置转换为'<a class="ae lw" href="https://www.google.com/url?sa=t&amp;rct=j&amp;q=&amp;esrc=s&amp;source=web&amp;cd=&amp;cad=rja&amp;uact=8&amp;ved=2ahUKEwim7frZxq_rAhUHxoUKHS8KAG0QFjAAegQIAhAB&amp;url=https%3A%2F%2Fen.wikipedia.org%2Fwiki%2FSingle-precision_floating-point_format&amp;usg=AOvVaw3DqSYfqL4CmisjyXTtDMSU" rel="noopener ugc nofollow" target="_blank"> float32 </a>'和<a class="ae lw" href="https://www.google.com/url?sa=t&amp;rct=j&amp;q=&amp;esrc=s&amp;source=web&amp;cd=&amp;cad=rja&amp;uact=8&amp;ved=2ahUKEwiq543fxq_rAhUKyxoKHXItBdgQFjABegQIERAE&amp;url=https%3A%2F%2Fwww.merriam-webster.com%2Fdictionary%2Fnormalize&amp;usg=AOvVaw2iiqm4mxvTiS1Q-BZelFQ2" rel="noopener ugc nofollow" target="_blank"> normalize </a>。</p><pre class="kp kq kr ks gt om on oo op aw oq bi"><span id="fe25" class="ob mg iq on b gy or os l ot ou">x_train = x_train.astype("float32") / 255.0<br/>x_test = x_test.astype("float32") / 255.0</span></pre><h2 id="0e5d" class="ob mg iq bd mh oc od dn ml oe of dp mp lj og oh mr ln oi oj mt lr ok ol mv iw bi translated">最初查看数据</h2><p id="563d" class="pw-post-body-paragraph la lb iq lc b ld mx ka lf lg my kd li lj mz ll lm ln na lp lq lr nb lt lu lv ij bi translated">这些是我们要让我们的模型学习的图片。</p><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div role="button" tabindex="0" class="ku kv di kw bf kx"><div class="gh gi oz"><img src="../Images/0cce06b8009862bac850329b904f6acf.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*fM8kFpF2DnHg3oBAO-SWaQ.png"/></div></div></figure><h1 id="7d82" class="mf mg iq bd mh mi nc mk ml mm nd mo mp kf ne kg mr ki nf kj mt kl ng km mv mw bi translated">迁移学习</h1><p id="b477" class="pw-post-body-paragraph la lb iq lc b ld mx ka lf lg my kd li lj mz ll lm ln na lp lq lr nb lt lu lv ij bi translated">现在，迁移学习可能是一个需要单独解释的完整主题，但我在这里只触及冰山一角。</p><blockquote class="nv nw nx"><p id="4d6c" class="la lb lx lc b ld le ka lf lg lh kd li ny lk ll lm nz lo lp lq oa ls lt lu lv ij bi translated">迁移学习是一种机器学习技术，其中在一个任务上训练的模型被重新用于第二个相关的任务。</p></blockquote><p id="1efe" class="pw-post-body-paragraph la lb iq lc b ld le ka lf lg lh kd li lj lk ll lm ln lo lp lq lr ls lt lu lv ij bi translated"><strong class="lc ja"> <em class="lx">我们为什么要使用迁移学习？</em> </strong>你不想训练一个有数百万节点的模型，一次又一次地在你的项目中使用，因此你有这个概念。迁移学习的概念是，你使用一个预先训练好的模型，只需重新训练一些层来适应你的要求。</p><pre class="kp kq kr ks gt om on oo op aw oq bi"><span id="b509" class="ob mg iq on b gy or os l ot ou">from keras.applications import inception_v3</span><span id="2b67" class="ob mg iq on b gy ov os l ot ou">input_size = 224<br/>num_classes = 115</span><span id="5951" class="ob mg iq on b gy ov os l ot ou">inception_bottleneck = inception_v3.InceptionV3(weights='imagenet', include_top=False, pooling='avg')</span><span id="c57b" class="ob mg iq on b gy ov os l ot ou">temp_train = inception_bottleneck.predict(x_train, batch_size=32, verbose=1)<br/>temp_test = inception_bottleneck.predict(x_test, batch_size=32, verbose=1)</span><span id="150f" class="ob mg iq on b gy ov os l ot ou">print('InceptionV3 train bottleneck features shape: {} size: {:,}'.format(temp_train.shape, temp_train.size))<br/>print('InceptionV3 test bottleneck features shape: {} size: {:,}'.format(temp_test.shape, temp_test.size))</span></pre><p id="7c8c" class="pw-post-body-paragraph la lb iq lc b ld le ka lf lg lh kd li lj lk ll lm ln lo lp lq lr ls lt lu lv ij bi translated">我们将<code class="fe ow ox oy on b"><em class="lx">include_top</em></code> <em class="lx"> </em>参数设置为False，这意味着我们不会导入最后一层，即密集层，我们会使用自己的层来调整模型以适应我们的数据集。</p><div class="pa pb gp gr pc pd"><a href="https://medium.com/analytics-vidhya/what-is-transfer-learning-weight-initialization-a997d83963bb" rel="noopener follow" target="_blank"><div class="pe ab fo"><div class="pf ab pg cl cj ph"><h2 class="bd ja gy z fp pi fr fs pj fu fw iz bi translated">什么是迁移学习和权重初始化？</h2><div class="pk l"><h3 class="bd b gy z fp pi fr fs pj fu fw dk translated">欢迎大家！这是我在一个月内完成深度学习Nanodegree的旅程中的第七篇文章！我已经…</h3></div><div class="pl l"><p class="bd b dl z fp pi fr fs pj fu fw dk translated">medium.com</p></div></div><div class="pm l"><div class="pn l po pp pq pm pr ky pd"/></div></div></a></div><h2 id="55e4" class="ob mg iq bd mh oc od dn ml oe of dp mp lj og oh mr ln oi oj mt lr ok ol mv iw bi translated">致密层</h2><p id="5de1" class="pw-post-body-paragraph la lb iq lc b ld mx ka lf lg my kd li lj mz ll lm ln na lp lq lr nb lt lu lv ij bi translated">在这之后，我们添加3个<a class="ae lw" href="https://www.google.com/url?sa=t&amp;rct=j&amp;q=&amp;esrc=s&amp;source=web&amp;cd=&amp;cad=rja&amp;uact=8&amp;ved=2ahUKEwjy_vqcya_rAhWQzIUKHRSMAugQFjABegQIDRAD&amp;url=https%3A%2F%2Fwww.tutorialspoint.com%2Fkeras%2Fkeras_dense_layer.htm&amp;usg=AOvVaw0URJwEDmeThpxsnyoLRBA-" rel="noopener ugc nofollow" target="_blank">密集层</a>到深度为1024、512和115的模型中，类别数。</p><pre class="kp kq kr ks gt om on oo op aw oq bi"><span id="d233" class="ob mg iq on b gy or os l ot ou">model = Sequential()</span><span id="bbe6" class="ob mg iq on b gy ov os l ot ou">model.add(Flatten())</span><span id="4df8" class="ob mg iq on b gy ov os l ot ou">model.add(Dense(1024, activation='elu'))<br/>model.add(Dropout(0.45))<br/>model.add(Dense(512, activation='elu'))<br/>model.add(Dropout(0.35))</span><span id="78d1" class="ob mg iq on b gy ov os l ot ou">model.add(Dense(num_classes, activation='softmax'))</span></pre><p id="1bb6" class="pw-post-body-paragraph la lb iq lc b ld le ka lf lg lh kd li lj lk ll lm ln lo lp lq lr ls lt lu lv ij bi translated">然后，我们编译这个。</p><pre class="kp kq kr ks gt om on oo op aw oq bi"><span id="95e7" class="ob mg iq on b gy or os l ot ou">model.compile(optimizer=’adam’,<br/>loss=’categorical_crossentropy’, metrics=[‘accuracy’])</span></pre><p id="15d5" class="pw-post-body-paragraph la lb iq lc b ld le ka lf lg lh kd li lj lk ll lm ln lo lp lq lr ls lt lu lv ij bi translated">然后，最后，训练。</p><pre class="kp kq kr ks gt om on oo op aw oq bi"><span id="b5f6" class="ob mg iq on b gy or os l ot ou">history = model.fit(temp_train, Y_train,<br/>epochs = 15,<br/>batch_size = 32,<br/>validation_data = (temp_test, Y_test))</span></pre><p id="24cd" class="pw-post-body-paragraph la lb iq lc b ld le ka lf lg lh kd li lj lk ll lm ln lo lp lq lr ls lt lu lv ij bi translated"><strong class="lc ja"> <em class="lx">现在，你看到了吗？</em> </strong>我们这里用<code class="fe ow ox oy on b"><em class="lx">temp_train</em></code> <em class="lx"> </em>和<code class="fe ow ox oy on b"><em class="lx">temp_test</em></code> <em class="lx"> </em>代替<code class="fe ow ox oy on b"><em class="lx">x_train</em></code> <em class="lx"> </em>和<code class="fe ow ox oy on b"><em class="lx">x_test</em></code> <em class="lx">。这是因为我们想扩展我们的初始模型，不使用这种顺序模型从零开始训练。</em></p><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div role="button" tabindex="0" class="ku kv di kw bf kx"><div class="gh gi ps"><img src="../Images/938d90cfa54849b2761492bf20ad118f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*6qfzH28KSMu2AEJLgCzTuQ.png"/></div></div></figure><h2 id="a6c9" class="ob mg iq bd mh oc od dn ml oe of dp mp lj og oh mr ln oi oj mt lr ok ol mv iw bi translated">损失图</h2><pre class="kp kq kr ks gt om on oo op aw oq bi"><span id="790b" class="ob mg iq on b gy or os l ot ou">score = model.evaluate(temp_test, Y_test, verbose=0)<br/>print("%s: %.2f%%" % (model.metrics_names[1], score[1]*100))</span><span id="a8fc" class="ob mg iq on b gy ov os l ot ou"># summarize history for accuracy</span><span id="59d6" class="ob mg iq on b gy ov os l ot ou">plt.subplot(211)<br/>plt.plot(history.history['accuracy'])<br/>plt.plot(history.history['val_accuracy'])<br/>plt.title('model accuracy')<br/>plt.ylabel('accuracy')<br/>plt.xlabel('epoch')<br/>plt.legend(['train', 'test'], loc='upper left')</span><span id="746d" class="ob mg iq on b gy ov os l ot ou"># summarize history for loss</span><span id="25ce" class="ob mg iq on b gy ov os l ot ou">plt.subplot(212)<br/>plt.plot(history.history['loss'])<br/>plt.plot(history.history['val_loss'])<br/>plt.title('model loss')<br/>plt.ylabel('loss')<br/>plt.xlabel('epoch')<br/>plt.legend(['train', 'test'], loc='upper left')</span><span id="2307" class="ob mg iq on b gy ov os l ot ou">plt.subplots_adjust(right=3, top=3)</span><span id="151c" class="ob mg iq on b gy ov os l ot ou">plt.show()</span></pre><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div role="button" tabindex="0" class="ku kv di kw bf kx"><div class="gh gi pt"><img src="../Images/32bea82e515c145c26fe8cba07c0ecca.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*yu_U5C76Pu2Es3-BpC5igQ.png"/></div></div></figure><h1 id="6a6f" class="mf mg iq bd mh mi nc mk ml mm nd mo mp kf ne kg mr ki nf kj mt kl ng km mv mw bi translated">结果和结论</h1><p id="e417" class="pw-post-body-paragraph la lb iq lc b ld mx ka lf lg my kd li lj mz ll lm ln na lp lq lr nb lt lu lv ij bi translated">所以，经过这一切，我们达到了<strong class="lc ja"> <em class="lx"> 77.31% </em> </strong>的准确率，老实说，考虑到有115个不同的类，这个模型做得相当不错。</p><h2 id="09eb" class="ob mg iq bd mh oc od dn ml oe of dp mp lj og oh mr ln oi oj mt lr ok ol mv iw bi translated">可视化结果</h2><pre class="kp kq kr ks gt om on oo op aw oq bi"><span id="832c" class="ob mg iq on b gy or os l ot ou">for i in range(9):<br/>pyplot.subplot(330 + 1 + i)<br/>pyplot.xlabel("Actual: " + y_test[i] + ", Predicted: " + results[i])<br/>pyplot.imshow(x_test[i], cmap=pyplot.get_cmap('gray'))</span><span id="ff61" class="ob mg iq on b gy ov os l ot ou">plt.subplots_adjust(right=3, top=3)</span><span id="a1b5" class="ob mg iq on b gy ov os l ot ou">pyplot.show()</span></pre><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div role="button" tabindex="0" class="ku kv di kw bf kx"><div class="gh gi pu"><img src="../Images/0c6d20673ffeb9b2da5c4a68369884e2.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*UT-Ky06bBZkJWsF8BiEBDQ.png"/></div></div></figure><p id="cd51" class="pw-post-body-paragraph la lb iq lc b ld le ka lf lg lh kd li lj lk ll lm ln lo lp lq lr ls lt lu lv ij bi translated">幸运的是，这是数据的一个子集，没有分类错误。<em class="lx">呵呵</em></p></div><div class="ab cl ly lz hu ma" role="separator"><span class="mb bw bk mc md me"/><span class="mb bw bk mc md me"/><span class="mb bw bk mc md"/></div><div class="ij ik il im in"><h2 id="6faf" class="ob mg iq bd mh oc od dn ml oe of dp mp lj og oh mr ln oi oj mt lr ok ol mv iw bi translated">可以做出的改进</h2><p id="d7fb" class="pw-post-body-paragraph la lb iq lc b ld mx ka lf lg my kd li lj mz ll lm ln na lp lq lr nb lt lu lv ij bi translated">我仍然认为，增加一个更密集的层可以有所不同，预处理数据肯定会有所帮助，但我们稍后会尝试一下。:D</p><p id="c71d" class="pw-post-body-paragraph la lb iq lc b ld le ka lf lg lh kd li lj lk ll lm ln lo lp lq lr ls lt lu lv ij bi translated">好了，我希望这篇文章能帮助你。我们上<a class="ae lw" href="https://www.linkedin.com/in/d3ni/" rel="noopener ugc nofollow" target="_blank"> <em class="lx"> Linkedin </em> </a>连线吧！</p></div><div class="ab cl ly lz hu ma" role="separator"><span class="mb bw bk mc md me"/><span class="mb bw bk mc md me"/><span class="mb bw bk mc md"/></div><div class="ij ik il im in"><h1 id="d6bb" class="mf mg iq bd mh mi mj mk ml mm mn mo mp kf mq kg mr ki ms kj mt kl mu km mv mw bi translated">进一步阅读</h1><div class="pa pb gp gr pc pd"><a href="https://medium.com/towards-artificial-intelligence/deep-learning-for-house-number-detection-25a45e62c8e5" rel="noopener follow" target="_blank"><div class="pe ab fo"><div class="pf ab pg cl cj ph"><h2 class="bd ja gy z fp pi fr fs pj fu fw iz bi translated">用于门牌号检测的深度学习</h2><div class="pk l"><h3 class="bd b gy z fp pi fr fs pj fu fw dk translated">让我带你走一遍。</h3></div><div class="pl l"><p class="bd b dl z fp pi fr fs pj fu fw dk translated">medium.com</p></div></div><div class="pm l"><div class="pv l po pp pq pm pr ky pd"/></div></div></a></div><div class="pa pb gp gr pc pd"><a href="https://medium.com/swlh/a-guide-to-generative-adversarial-networks-gans-b3e445c34933" rel="noopener follow" target="_blank"><div class="pe ab fo"><div class="pf ab pg cl cj ph"><h2 class="bd ja gy z fp pi fr fs pj fu fw iz bi translated">生成对抗网络指南</h2><div class="pk l"><h3 class="bd b gy z fp pi fr fs pj fu fw dk translated">第18天</h3></div><div class="pl l"><p class="bd b dl z fp pi fr fs pj fu fw dk translated">medium.com</p></div></div><div class="pm l"><div class="pw l po pp pq pm pr ky pd"/></div></div></a></div><div class="pa pb gp gr pc pd"><a href="https://medium.com/analytics-vidhya/lets-discuss-encoders-and-style-transfer-c0494aca6090" rel="noopener follow" target="_blank"><div class="pe ab fo"><div class="pf ab pg cl cj ph"><h2 class="bd ja gy z fp pi fr fs pj fu fw iz bi translated">让我们讨论编码器和风格转换</h2><div class="pk l"><h3 class="bd b gy z fp pi fr fs pj fu fw dk translated">自动编码器和风格转移小指南。</h3></div><div class="pl l"><p class="bd b dl z fp pi fr fs pj fu fw dk translated">medium.com</p></div></div><div class="pm l"><div class="px l po pp pq pm pr ky pd"/></div></div></a></div><h1 id="c6ad" class="mf mg iq bd mh mi nc mk ml mm nd mo mp kf ne kg mr ki nf kj mt kl ng km mv mw bi translated">联系人</h1><p id="524d" class="pw-post-body-paragraph la lb iq lc b ld mx ka lf lg my kd li lj mz ll lm ln na lp lq lr nb lt lu lv ij bi translated">如果你想了解我最新的文章和项目<a class="ae lw" href="/@D3nii" rel="noopener ugc nofollow" target="_blank">，请关注我的媒体</a>。以下是我的一些联系人详细信息:</p><ul class=""><li id="3ff9" class="nh ni iq lc b ld le lg lh lj py ln pz lr qa lv nm nn no np bi translated"><a class="ae lw" href="https://www.linkedin.com/in/d3ni/" rel="noopener ugc nofollow" target="_blank">领英</a></li><li id="1893" class="nh ni iq lc b ld nq lg nr lj ns ln nt lr nu lv nm nn no np bi translated"><a class="ae lw" href="https://github.com/D3nii?tab=repositories" rel="noopener ugc nofollow" target="_blank"> GitHub </a></li><li id="ee0d" class="nh ni iq lc b ld nq lg nr lj ns ln nt lr nu lv nm nn no np bi translated"><a class="ae lw" href="https://twitter.com/danyal0_o" rel="noopener ugc nofollow" target="_blank">推特</a></li></ul><blockquote class="qb"><p id="e7be" class="qc qd iq bd qe qf qg qh qi qj qk lv dk translated">快乐学习。:)</p></blockquote></div></div>    
</body>
</html>