<html>
<head>
<title>Interpretability and Performance in a Single Model</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">单一模型中的可解释性和性能</h1>
<blockquote>原文：<a href="https://pub.towardsai.net/interpretability-and-performance-in-a-single-model-1b5246b595e7?source=collection_archive---------0-----------------------#2021-03-23">https://pub.towardsai.net/interpretability-and-performance-in-a-single-model-1b5246b595e7?source=collection_archive---------0-----------------------#2021-03-23</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><h2 id="d6b4" class="ir is it bd b dl iu iv iw ix iy iz dk ja translated" aria-label="kicker paragraph"><a class="ae ep" href="https://towardsai.net/p/category/machine-learning" rel="noopener ugc nofollow" target="_blank">机器学习</a></h2><div class=""/><div class=""><h2 id="3640" class="pw-subtitle-paragraph jz jc it bd b ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq dk translated">IBM Research发表了一些聪明的研究来构建模型复杂且可解释的模型。</h2></div><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi kr"><img src="../Images/0e8dd755a19d433e87561330cb612af8.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*W2vIFz8JYDT2H6v0r_76Bg.png"/></div></div><figcaption class="ld le gj gh gi lf lg bd b be z dk translated">来源:<a class="ae lh" href="https://www.experfy.com/blog/ai-ml/guide-to-interpretable-machine-learning/" rel="noopener ugc nofollow" target="_blank">https://www . exper fy . com/blog/ai-ml/guide-to-interpretable-machine-learning/</a></figcaption></figure><blockquote class="li lj lk"><p id="a334" class="ll lm ln lo b lp lq kd lr ls lt kg lu lv lw lx ly lz ma mb mc md me mf mg mh im bi translated">我最近创办了一份专注于人工智能的教育时事通讯，已经有超过70，000名订户。《序列》是一份无废话(意思是没有炒作，没有新闻等)的ML导向时事通讯，需要5分钟阅读。目标是让你与机器学习项目、研究论文和概念保持同步。请通过订阅以下内容来尝试一下:</p></blockquote><div class="mi mj gp gr mk ml"><a href="https://thesequence.substack.com/" rel="noopener  ugc nofollow" target="_blank"><div class="mm ab fo"><div class="mn ab mo cl cj mp"><h2 class="bd jd gy z fp mq fr fs mr fu fw jc bi translated">序列</h2><div class="ms l"><h3 class="bd b gy z fp mq fr fs mr fu fw dk translated">该序列解释了主要的机器学习概念，让你与最相关的项目和最新的…</h3></div><div class="mt l"><p class="bd b dl z fp mq fr fs mr fu fw dk translated">thesequence.substack.com</p></div></div><div class="mu l"><div class="mv l mw mx my mu mz lb ml"/></div></div></a></div><p id="9f26" class="pw-post-body-paragraph ll lm it lo b lp lq kd lr ls lt kg lu na lw lx ly nb ma mb mc nc me mf mg mh im bi translated">机器学习是一门充满摩擦和权衡的学科，但没有比准确性和可解释性之间的平衡更重要的了。原则上，深度神经网络等高度精确的机器学习模型往往很难解释，而决策树等简单模型在许多复杂的场景中表现不佳。传统的机器学习智慧告诉我们，准确性和可解释性是模型架构中相反的力量，但事实总是如此？我们能建立既高性能又易于理解的模型吗？来自IBM的研究人员最近发表了<a class="ae lh" href="https://arxiv.org/abs/1807.07506" rel="noopener ugc nofollow" target="_blank">一篇论文，提出了一种利用更复杂模型的知识来提高简单机器学习模型性能的统计方法</a>。</p><p id="a9e8" class="pw-post-body-paragraph ll lm it lo b lp lq kd lr ls lt kg lu na lw lx ly nb ma mb mc nc me mf mg mh im bi translated">在机器学习模型中找到性能和可解释性之间的平衡绝非易事。从心理学上来说，我们更容易被我们能够解释的事情所吸引，而我们内心的经济人更喜欢给定问题最好的结果。许多真实世界的数据科学场景可以使用简单和高度复杂的机器学习模型来解决。在这些场景中，简单性和可解释性的优势往往超过性能的优势。</p><h1 id="0046" class="nd ne it bd nf ng nh ni nj nk nl nm nn ki no kj np kl nq km nr ko ns kp nt nu bi translated">机器学习简单的优势</h1><p id="b29c" class="pw-post-body-paragraph ll lm it lo b lp nv kd lr ls nw kg lu na nx lx ly nb ny mb mc nc nz mf mg mh im bi translated">透明度和性能之间的平衡可以描述为研究和现实世界应用之间的关系。如今，大多数人工智能(AI)研究都集中在超级复杂的学科上，如强化学习或生成模型。然而，当涉及到实际应用时，对更简单的机器学习模型的信任往往占上风。我们一直看到计算生物学和经济学中的复杂场景使用简单的稀疏线性模型或复杂的仪器化领域(如使用决策树解决的半导体制造)来解决。机器学习模型的简单性有许多实际优势，在你面对真实世界的场景之前，这些优势不会被轻易忽视。以下是我最喜欢的一些:</p><p id="096b" class="pw-post-body-paragraph ll lm it lo b lp lq kd lr ls lt kg lu na lw lx ly nb ma mb mc nc me mf mg mh im bi translated"><strong class="lo jd">小数据集:</strong>公司通常为其业务问题收集有限的可用数据。因此，简单模型在这里更受青睐，因为它们不太可能过度拟合数据，此外还能提供有用的见解。</p><p id="5957" class="pw-post-body-paragraph ll lm it lo b lp lq kd lr ls lt kg lu na lw lx ly nb ma mb mc nc me mf mg mh im bi translated"><strong class="lo jd">资源有限的环境:</strong>简单模型在有功率和内存限制的环境中也很有用。</p><p id="74d1" class="pw-post-body-paragraph ll lm it lo b lp lq kd lr ls lt kg lu na lw lx ly nb ma mb mc nc me mf mg mh im bi translated"><strong class="lo jd">信任:</strong>更简单的模型激发了对领域专家的信任，这些专家通常对模型的结果负责。</p><p id="47ca" class="pw-post-body-paragraph ll lm it lo b lp lq kd lr ls lt kg lu na lw lx ly nb ma mb mc nc me mf mg mh im bi translated">尽管机器学习模型的简单性具有显著的优势，但我们不能简单地忽视顶级性能模型的好处。然而，如果我们可以使用来自更复杂的替代方案的知识来提高更简单的机器学习模型的性能，会怎么样呢？这是IBM研究人员决定采用一种叫做ProfWeight的新方法的途径。</p><h1 id="cde1" class="nd ne it bd nf ng nh ni nj nk nl nm nn ki no kj np kl nq km nr ko ns kp nt nu bi translated">重量</h1><p id="390e" class="pw-post-body-paragraph ll lm it lo b lp nv kd lr ls nw kg lu na nx lx ly nb ny mb mc nc nz mf mg mh im bi translated">ProfWeight背后的想法令人难以置信地富有创造性，以至于对许多机器学习专家来说是反直觉的。从概念上讲，ProfWeight将信息从具有高测试精度的预训练深度神经网络转移到更简单的可解释模型或低复杂性和先验低测试精度的非常浅的网络。在这种情况下，ProfWeight使用复杂的深度学习模型作为高绩效教师，这些课程可用于教授简单、可解释但通常表现不佳的学生模型。</p><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi oa"><img src="../Images/17cf9dae8e79b6c2368d23ada18d14a0.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*2wziCLash9iTTnb5zdpMfQ.png"/></div></div><figcaption class="ld le gj gh gi lf lg bd b be z dk translated">来源:<a class="ae lh" href="https://arxiv.org/abs/1807.07506" rel="noopener ugc nofollow" target="_blank">https://arxiv.org/abs/1807.07506</a></figcaption></figure><p id="fe7b" class="pw-post-body-paragraph ll lm it lo b lp lq kd lr ls lt kg lu na lw lx ly nb ma mb mc nc me mf mg mh im bi translated">为了实现教师模型和学生模型之间的知识传递，ProfWeight引入了探针，探针根据网络的难易程度对样本进行加权分类。每个探头从其中一个隐藏层获取输入，并通过一个完全连接的层进行处理，该层附有一个网络输出大小的softmax层。特定层中的探测器充当分类器，仅使用直到该层的网络前缀。尽管复杂，但ProfWeight可以总结为四个主要步骤:</p><p id="fcf9" class="pw-post-body-paragraph ll lm it lo b lp lq kd lr ls lt kg lu na lw lx ly nb ma mb mc nc me mf mg mh im bi translated">1)在高性能神经网络的中间表示上附加和训练探针。</p><p id="a2c7" class="pw-post-body-paragraph ll lm it lo b lp lq kd lr ls lt kg lu na lw lx ly nb ma mb mc nc me mf mg mh im bi translated">2)在原始数据集上训练简单模型。</p><p id="4a14" class="pw-post-body-paragraph ll lm it lo b lp lq kd lr ls lt kg lu na lw lx ly nb ma mb mc nc me mf mg mh im bi translated">3)学习作为简单模型和探针的函数的数据集中的例子的权重。</p><p id="1629" class="pw-post-body-paragraph ll lm it lo b lp lq kd lr ls lt kg lu na lw lx ly nb ma mb mc nc me mf mg mh im bi translated">4)在最终加权数据集上重新训练简单模型。</p><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi ob"><img src="../Images/eacd39d36e80f075c352ce993aa36330.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*pw9faLTH-je2d1YufP0Wmg.png"/></div></div><figcaption class="ld le gj gh gi lf lg bd b be z dk translated">来源:https://arxiv.org/abs/1807.07506</figcaption></figure><p id="928a" class="pw-post-body-paragraph ll lm it lo b lp lq kd lr ls lt kg lu na lw lx ly nb ma mb mc nc me mf mg mh im bi translated">整个ProfWeight模型可以被视为一个探测、获取置信度权重和重新训练的管道。为了计算权重，IBM团队使用了不同的技术，如曲线下面积(AUC)或校正线性单位(ReLu)。</p><h1 id="d363" class="nd ne it bd nf ng nh ni nj nk nl nm nn ki no kj np kl nq km nr ko ns kp nt nu bi translated">结果呢</h1><p id="66d6" class="pw-post-body-paragraph ll lm it lo b lp nv kd lr ls nw kg lu na nx lx ly nb ny mb mc nc nz mf mg mh im bi translated">IBM在不同的场景中测试了ProfWeight，并根据传统模型对结果进行了基准测试。其中一个实验集中在测量制造工厂生产的金属质量。输入数据集由金属制造过程中的不同测量值组成，例如酸浓度、电气读数、金属沉积量、蚀刻时间、自上次清洁以来的时间、玻璃雾化以及各种气体流量和压力。ProfWeight使用的简单模型是决策树算法。对于复杂的教师模型，IBM使用了一个深度神经网络，它具有一个输入层和五个完全连接的隐藏层，大小为1024，在这个特定的场景中显示出超过90%的准确性。使用不同的ProfWeight变量，决策树模型的准确性从74%提高到87%以上，同时保持了相同水平的可解释性。</p><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi oc"><img src="../Images/e0d79d918fa986c69cd5353afb9b5ea0.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*TLYZfeeLE7iE5Oxh86TJ9A.png"/></div></div><figcaption class="ld le gj gh gi lf lg bd b be z dk translated">来源:https://arxiv.org/abs/1807.07506<a class="ae lh" href="https://arxiv.org/abs/1807.07506" rel="noopener ugc nofollow" target="_blank"/></figcaption></figure><p id="afc6" class="pw-post-body-paragraph ll lm it lo b lp lq kd lr ls lt kg lu na lw lx ly nb ma mb mc nc me mf mg mh im bi translated">ProfWeight是我见过的最具创造性的方法之一，它试图解决机器学习模型中透明度和性能之间的困境。ProfWeight的结果表明，利用复杂备选方案的知识来提高较简单的机器学习模型的性能是可能的。这项工作可能是弥合深度学习和统计模型等机器学习中不同思想流派的基础。</p></div></div>    
</body>
</html>