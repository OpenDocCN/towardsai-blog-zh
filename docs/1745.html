<html>
<head>
<title>Will Transformers Replace CNNs in Computer Vision?</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">变形金刚会取代计算机视觉中的CNN吗？</h1>
<blockquote>原文：<a href="https://pub.towardsai.net/will-transformers-replace-cnns-in-computer-vision-55657a196833?source=collection_archive---------0-----------------------#2021-04-08">https://pub.towardsai.net/will-transformers-replace-cnns-in-computer-vision-55657a196833?source=collection_archive---------0-----------------------#2021-04-08</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><h2 id="9ae5" class="ir is it bd b dl iu iv iw ix iy iz dk ja translated" aria-label="kicker paragraph"><a class="ae ep" href="https://towardsai.net/p/category/computer-vision" rel="noopener ugc nofollow" target="_blank">计算机视觉</a></h2><div class=""/><div class=""><h2 id="613e" class="pw-subtitle-paragraph jz jc it bd b ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq dk translated">在不到5分钟的时间内，您将通过一篇名为Swin transformer的新论文了解如何将Transformer架构应用于计算机视觉</h2></div><blockquote class="kr ks kt"><p id="cc65" class="ku kv kw kx b ky kz kd la lb lc kg ld le lf lg lh li lj lk ll lm ln lo lp lq im bi translated">原载于<a class="ae lr" href="https://www.louisbouchard.ai/will-transformers-replace-cnns-for-vision/" rel="noopener ugc nofollow" target="_blank"> louisbouchard.ai </a>，前两天在<a class="ae lr" href="https://www.louisbouchard.ai/tag/artificial-intelligence/" rel="noopener ugc nofollow" target="_blank">我的博客</a>上看到的！</p></blockquote><figure class="lt lu lv lw gt lx gh gi paragraph-image"><a href="https://youtu.be/QcCJJOLCeJQ"><div class="gh gi ls"><img src="../Images/e562da711694668ef077306103d016cf.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*zI2WxslE1X61fMWl4Iuy_Q.png"/></div></a><figcaption class="ma mb gj gh gi mc md bd b be z dk translated">图片由作者提供。</figcaption></figure><figure class="lt lu lv lw gt lx"><div class="bz fp l di"><div class="me mf l"/></div></figure><p id="98d8" class="pw-post-body-paragraph ku kv it kx b ky kz kd la lb lc kg ld mg lf lg lh mh lj lk ll mi ln lo lp lq im bi translated">这篇文章很可能是关于所有计算机视觉应用的下一代神经网络:transformer架构。你肯定已经听说过自然语言处理(NLP)领域的这种架构，主要是在2020年制造了很多噪音的GPT3。变压器可以用作许多不同应用的通用主干，而不仅仅是NLP。几分钟后，你就会知道如何将变压器架构应用于计算机视觉，这是微软研究院的泽·莉雅等人发表的一篇名为Swin Transformer的新论文[1]。</p><p id="a288" class="pw-post-body-paragraph ku kv it kx b ky kz kd la lb lc kg ld mg lf lg lh mh lj lk ll mi ln lo lp lq im bi translated">这篇文章可能没有通常的那么华丽，因为它并没有真正展示一个精确应用的实际结果。相反，研究人员[1]展示了如何将变形金刚的架构从文本输入调整为图像，超越了计算机视觉最先进的卷积神经网络，在我看来，这比精确度的轻微提高更令人兴奋。当然，他们会提供代码让你自己实现！链接在下面的参考资料中。</p><figure class="lt lu lv lw gt lx gh gi paragraph-image"><a href="https://www.louisbouchard.ai/learnai/"><div class="gh gi mj"><img src="../Images/d6d4f598ae72cf7f2fb082a3e0a0d220.png" data-original-src="https://miro.medium.com/v2/resize:fit:924/format:webp/0*fqRa4yjYoXrzncvQ.png"/></div></a></figure><h2 id="65ef" class="mk ml it bd mm mn mo dn mp mq mr dp ms mg mt mu mv mh mw mx my mi mz na nb iz bi translated">为什么用变形金刚而不用CNN？</h2><p id="73c0" class="pw-post-body-paragraph ku kv it kx b ky nc kd la lb nd kg ld mg ne lg lh mh nf lk ll mi ng lo lp lq im bi translated">但是，为什么我们要尝试在计算机视觉应用中取代卷积神经网络呢？这是因为变压器可以有效地使用更多的内存，并且在处理复杂任务时更加强大。这当然是根据你有数据训练它的事实。变形金刚还使用了2017年论文<a class="ae lr" href="https://arxiv.org/abs/1706.03762" rel="noopener ugc nofollow" target="_blank">中介绍的注意力机制</a>【3】。注意力允许transformer架构以并行方式进行计算。</p><figure class="lt lu lv lw gt lx gh gi paragraph-image"><div role="button" tabindex="0" class="ni nj di nk bf nl"><div class="gh gi nh"><img src="../Images/333e21bc2108a3ede29565b98cee8d03.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/1*g6BxnLOK7FEcU1VYGxkE2Q.gif"/></div></div><figcaption class="ma mb gj gh gi mc md bd b be z dk translated">自然语言处理中的自我注意过程。图片由<a class="ae lr" href="https://towardsdatascience.com/transformers-an-exciting-revolution-from-text-to-videos-dc70a15e617b" rel="noopener" target="_blank"> Davide Coccomini </a>经许可转贴。</figcaption></figure><p id="03af" class="pw-post-body-paragraph ku kv it kx b ky kz kd la lb lc kg ld mg lf lg lh mh lj lk ll mi ln lo lp lq im bi translated">与CNN相比，它可以同时从输入及其相互关系中提取我们需要的所有信息。CNN更加本地化，使用小过滤器将信息压缩成一个通用的答案。虽然这种体系结构对于一般的分类任务来说是强大的，但是它不具有许多任务(例如实例识别)所必需的空间信息。这是因为卷积不考虑距离像素关系。</p><div class="lt lu lv lw gt ab cb"><figure class="nm lx nn no np nq nr paragraph-image"><div role="button" tabindex="0" class="ni nj di nk bf nl"><img src="../Images/f7081842ce34e68a1ffc157f986ee269.png" data-original-src="https://miro.medium.com/v2/resize:fit:1000/1*W5VG0i1RC4XjPKPPMGdTFw.gif"/></div></figure><figure class="nm lx nn no np nq nr paragraph-image"><div role="button" tabindex="0" class="ni nj di nk bf nl"><img src="../Images/9cbf7b4a08107c9f1451f5214523e4b7.png" data-original-src="https://miro.medium.com/v2/resize:fit:1000/1*Nap8kC3vrYyMJD9JNB1dVQ.gif"/></div><figcaption class="ma mb gj gh gi mc md bd b be z dk ns di nt nu translated">NLP(左)和计算机视觉(右)的变形金刚中的自我关注示例。图片由作者提供。</figcaption></figure></div><p id="89db" class="pw-post-body-paragraph ku kv it kx b ky kz kd la lb lc kg ld mg lf lg lh mh lj lk ll mi ln lo lp lq im bi translated">在NLP中，典型的输入类型是计算机视觉案例中的一个句子和一幅图像。为了快速介绍注意力的概念，让我们举一个简单的NLP例子，发送一个句子，将其翻译成transformer网络。在这种情况下，注意力基本上是测量输入句子中的每个单词如何与输出翻译句子中的每个单词相关联。同样，也有我们所谓的自我关注，它可以被看作是对同一个句子中一个特定单词对所有其他单词的影响的测量。这个相同的过程可以应用于图像，计算图像块的注意力和它们彼此之间的关系，我们将在文章中进一步讨论。</p><figure class="lt lu lv lw gt lx gh gi paragraph-image"><a href="http://eepurl.com/huGLT5"><div class="gh gi nv"><img src="../Images/76e3b32bdc5e9fe271eaa029481512bb.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*wSHLIym4FpCpAZjdJMPMQw.png"/></div></a></figure><h2 id="efe4" class="mk ml it bd mm mn mo dn mp mq mr dp ms mg mt mu mv mh mw mx my mi mz na nb iz bi translated">计算机视觉中的变形金刚</h2><p id="cc60" class="pw-post-body-paragraph ku kv it kx b ky nc kd la lb nd kg ld mg ne lg lh mh nf lk ll mi ng lo lp lq im bi translated">现在我们知道变形金刚非常有趣，但在计算机视觉应用方面还有一个问题。事实上，就像流行的说法“一张图片胜过千言万语”，图片包含的信息比句子多得多，因此我们必须调整基本transformer的架构，以有效地处理图像。这就是本文的内容。</p><figure class="lt lu lv lw gt lx gh gi paragraph-image"><div class="gh gi nw"><img src="../Images/8bec6e737685056232d861499619563b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/1*JS21YKMUuZ6i24Y9ozpNQQ.gif"/></div><figcaption class="ma mb gj gh gi mc md bd b be z dk translated">视觉变形金刚的复杂性。图片由<a class="ae lr" href="https://towardsdatascience.com/transformers-an-exciting-revolution-from-text-to-videos-dc70a15e617b" rel="noopener" target="_blank">大卫·考科米尼</a>经许可转贴。</figcaption></figure><p id="2f8c" class="pw-post-body-paragraph ku kv it kx b ky kz kd la lb lc kg ld mg lf lg lh mh lj lk ll mi ln lo lp lq im bi translated">这是由于其自我关注的计算复杂度与图像大小成二次关系。从而增加了计算时间和内存需求。相反，研究人员用图像大小的线性计算复杂度代替了这种二次计算复杂度。</p><figure class="lt lu lv lw gt lx gh gi paragraph-image"><div role="button" tabindex="0" class="ni nj di nk bf nl"><div class="gh gi nx"><img src="../Images/7c7c6653792c87ea718719903cbbfe39.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/1*nzaAUXFzsKIr2t0u3SOPHQ.gif"/></div></div><figcaption class="ma mb gj gh gi mc md bd b be z dk translated">Swin Transformer架构的第一步，图像标记化。图片由作者提供。</figcaption></figure><h2 id="077d" class="mk ml it bd mm mn mo dn mp mq mr dp ms mg mt mu mv mh mw mx my mi mz na nb iz bi translated">Swin变压器[1] [2]</h2><p id="e754" class="pw-post-body-paragraph ku kv it kx b ky nc kd la lb nd kg ld mg ne lg lh mh nf lk ll mi ng lo lp lq im bi translated">实现这一点的过程非常简单。首先，像大多数计算机视觉任务一样，一幅RGB图像被发送到网络。该图像被分割成小块，每个小块被视为一个令牌。这些记号的特征是像素本身的RGB值。与NLP相比，您可以将此视为整体图像是句子，每个补丁是该句子的单词。自我关注被应用在每个补丁上，这里被称为窗口。然后，窗口被移动，导致新的窗口配置来再次应用自我注意。这允许在窗口之间创建连接，同时保持这种窗口结构的计算效率。与卷积神经网络相比，这是非常有趣的，因为它允许出现长距离像素关系。</p><figure class="lt lu lv lw gt lx gh gi paragraph-image"><div role="button" tabindex="0" class="ni nj di nk bf nl"><div class="gh gi nx"><img src="../Images/c64afd6bfb5c15901fb72035a18f88b4.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/1*TYCkhBVqx_5xl4phQQUy8g.gif"/></div></div><figcaption class="ma mb gj gh gi mc md bd b be z dk translated">自我关注在windows上的应用。图片由作者提供。</figcaption></figure><p id="c32a" class="pw-post-body-paragraph ku kv it kx b ky kz kd la lb lc kg ld mg lf lg lh mh lj lk ll mi ln lo lp lq im bi translated">这只是第一阶段。第二阶段非常类似，但是将每组两个相邻面片的特征连接起来，将分辨率下采样为原来的两倍。这个过程在阶段3和4中重复两次，产生与典型卷积网络(如雷斯网和VGG)相同的特征映射分辨率。</p><p id="9bb6" class="pw-post-body-paragraph ku kv it kx b ky kz kd la lb lc kg ld mg lf lg lh mh lj lk ll mi ln lo lp lq im bi translated">你可能会说这与卷积架构和使用点积的滤波器非常相似。嗯，是也不是。</p><figure class="lt lu lv lw gt lx gh gi paragraph-image"><div role="button" tabindex="0" class="ni nj di nk bf nl"><div class="gh gi nx"><img src="../Images/4321f8379f7bf9882bf098466a1cfad3.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/1*8GPsf622HvOTyEoBGyhYlw.gif"/></div></div><figcaption class="ma mb gj gh gi mc md bd b be z dk translated">卷积过程与自我注意。图片由作者提供。</figcaption></figure><p id="bc9a" class="pw-post-body-paragraph ku kv it kx b ky kz kd la lb lc kg ld mg lf lg lh mh lj lk ll mi ln lo lp lq im bi translated">卷积的强大之处在于，滤波器全局使用固定权重，从而实现了卷积的平移不变性，使其成为一种强大的广义卷积。在自我关注中，权重不是全局固定的。相反，它们依赖于当地环境本身。因此，自我关注考虑了每个像素，也考虑了它与其他像素的关系。</p><figure class="lt lu lv lw gt lx gh gi paragraph-image"><div role="button" tabindex="0" class="ni nj di nk bf nl"><div class="gh gi nx"><img src="../Images/35f702bb883330a543e0a2dbba1bf2ad.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/1*uLnL2r-4LlhxacY5fLJqcA.gif"/></div></div><figcaption class="ma mb gj gh gi mc md bd b be z dk translated">移位窗长程关系问题。图片由作者提供。</figcaption></figure><p id="d397" class="pw-post-body-paragraph ku kv it kx b ky kz kd la lb lc kg ld mg lf lg lh mh lj lk ll mi ln lo lp lq im bi translated">此外，他们的移位窗口技术允许出现长距离像素关系。不幸的是，这些长程关系只出现在相邻的窗口中。因此，失去了非常长距离的关系，表明当涉及到计算机视觉时，变压器架构仍有改进的空间。</p><h2 id="95c6" class="mk ml it bd mm mn mo dn mp mq mr dp ms mg mt mu mv mh mw mx my mi mz na nb iz bi translated">结论</h2><p id="db0d" class="pw-post-body-paragraph ku kv it kx b ky nc kd la lb nd kg ld mg ne lg lh mh nf lk ll mi ng lo lp lq im bi translated">正如他们在论文中所说:</p><blockquote class="kr ks kt"><p id="83f7" class="ku kv kw kx b ky kz kd la lb lc kg ld le lf lg lh li lj lk ll lm ln lo lp lq im bi translated">我们相信，跨计算机视觉和自然语言处理的统一架构可以使这两个领域受益，因为它将促进视觉和文本信号的联合建模，并且来自这两个领域的建模知识可以更深入地共享。[1]第2页</p></blockquote><p id="6958" class="pw-post-body-paragraph ku kv it kx b ky kz kd la lb lc kg ld mg lf lg lh mh lj lk ll mi ln lo lp lq im bi translated">我完全同意。我认为为自然语言处理和计算机视觉使用相似的架构可以大大加快研究进程。当然，变形金刚仍然高度依赖数据，没有人能说它是否会是NLP或计算机视觉的未来。尽管如此，这无疑是这两个领域向前迈出的重要一步！</p><p id="5ebf" class="pw-post-body-paragraph ku kv it kx b ky kz kd la lb lc kg ld mg lf lg lh mh lj lk ll mi ln lo lp lq im bi translated">我希望这篇文章能给你一个很好的介绍变形金刚，以及如何将它们应用到计算机视觉应用中。</p><p id="957d" class="pw-post-body-paragraph ku kv it kx b ky kz kd la lb lc kg ld mg lf lg lh mh lj lk ll mi ln lo lp lq im bi translated">感谢您的阅读！在<a class="ae lr" href="https://www.louisbouchard.me/ganverse3d/" rel="noopener ugc nofollow" target="_blank">我的博客</a>上找到更多像这样的文章，在它们被分享到媒体上之前阅读它们！</p></div><div class="ab cl ny nz hx oa" role="separator"><span class="ob bw bk oc od oe"/><span class="ob bw bk oc od oe"/><span class="ob bw bk oc od"/></div><div class="im in io ip iq"><p id="8237" class="pw-post-body-paragraph ku kv it kx b ky kz kd la lb lc kg ld mg lf lg lh mh lj lk ll mi ln lo lp lq im bi translated">如果你喜欢我的工作，并想与人工智能保持同步，你绝对应该关注我的其他社交媒体账户(<a class="ae lr" href="https://www.linkedin.com/in/whats-ai/" rel="noopener ugc nofollow" target="_blank"> LinkedIn </a>、<a class="ae lr" href="https://twitter.com/Whats_AI" rel="noopener ugc nofollow" target="_blank"> Twitter </a>)，并订阅我的每周人工智能<a class="ae lr" href="http://eepurl.com/huGLT5" rel="noopener ugc nofollow" target="_blank"> <strong class="kx jd">简讯</strong> </a>！</p><h2 id="cda9" class="mk ml it bd mm mn mo dn mp mq mr dp ms mg mt mu mv mh mw mx my mi mz na nb iz bi translated">支持我:</h2><ul class=""><li id="4d01" class="of og it kx b ky nc lb nd mg oh mh oi mi oj lq ok ol om on bi translated">支持我的最好方式是在<a class="ae lr" href="https://medium.com/@whats-ai" rel="noopener"> <strong class="kx jd">媒体</strong> </a> <strong class="kx jd"> </strong>上关注我，或者如果你喜欢视频格式，在<a class="ae lr" href="https://www.youtube.com/channel/UCUzGQrN-lyyc0BWTYoJM_Sg" rel="noopener ugc nofollow" target="_blank"><strong class="kx jd">YouTube</strong></a><strong class="kx jd"/>上订阅我的频道<strong class="kx jd"> </strong>。</li><li id="f325" class="of og it kx b ky oo lb op mg oq mh or mi os lq ok ol om on bi translated">支持我在<a class="ae lr" href="https://www.patreon.com/whatsai" rel="noopener ugc nofollow" target="_blank"> <strong class="kx jd">上的工作</strong></a></li><li id="f548" class="of og it kx b ky oo lb op mg oq mh or mi os lq ok ol om on bi translated">加入我们的<a class="ae lr" href="https://discord.gg/learnaitogether" rel="noopener ugc nofollow" target="_blank"> <strong class="kx jd"> Discord社区:</strong> <strong class="kx jd">一起学AI</strong></a>和<em class="kw">分享你的项目、论文、最佳课程、寻找Kaggle队友等等！</em></li></ul></div><div class="ab cl ny nz hx oa" role="separator"><span class="ob bw bk oc od oe"/><span class="ob bw bk oc od oe"/><span class="ob bw bk oc od"/></div><div class="im in io ip iq"><h2 id="dec8" class="mk ml it bd mm mn mo dn mp mq mr dp ms mg mt mu mv mh mw mx my mi mz na nb iz bi translated">参考</h2><p id="ed4b" class="pw-post-body-paragraph ku kv it kx b ky nc kd la lb nd kg ld mg ne lg lh mh nf lk ll mi ng lo lp lq im bi translated">[1]刘，z .等，2021，<a class="ae lr" href="https://arxiv.org/abs/2103.14030v1" rel="noopener ugc nofollow" target="_blank"> Swin Transformer:使用移位窗口的分级视觉Transformer</a>，<em class="kw"> arXiv预印本</em> <a class="ae lr" href="https://www.youtube.com/redirect?q=https%3A%2F%2Farxiv.org%2Fabs%2F2103.14030v1&amp;redir_token=QUFFLUhqbWs5elJBa2FkM0lmaHl5dTg1c0hQeVJTMFZPQXxBQ3Jtc0trMXRsUVpya2Qtb01vazY4NnktMWVldTZYRXQxaHZqamNpcGhDNzFrdTk1SGlzQzNsNnBuYXh2Y1J3dUJsSjZKY2lnQWhHU3RKcEpGSGV1VEV2TUM5N0s4Ni1JSXZuRUlSNm81dC1kcXZ4Z1FQakJwdw%3D%3D&amp;event=comments&amp;stzid=UgxsfplcSCH4gNnmBx14AaABAg" rel="noopener ugc nofollow" target="_blank">，</a></p><p id="77ec" class="pw-post-body-paragraph ku kv it kx b ky kz kd la lb lc kg ld mg lf lg lh mh lj lk ll mi ln lo lp lq im bi translated">[2] <a class="ae lr" href="https://github.com/microsoft/Swin-Transformer" rel="noopener ugc nofollow" target="_blank"> Swin Transformer </a>、莉雅、z等人、GitHub code、【https://github.com/microsoft/Swin-Transformer】T2</p><p id="8ad8" class="pw-post-body-paragraph ku kv it kx b ky kz kd la lb lc kg ld mg lf lg lh mh lj lk ll mi ln lo lp lq im bi translated">[3]瓦斯瓦尼，a .等人，2017年。【https://arxiv.org/abs/1706.03762，<em class="kw"> arXiv预印本<a class="ae lr" href="https://arxiv.org/abs/1706.03762" rel="noopener ugc nofollow" target="_blank">，</a>。</em></p></div></div>    
</body>
</html>