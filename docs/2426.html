<html>
<head>
<title>Profiling Neural Networks to improve model training and inference speed</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">剖析神经网络以提高模型训练和推理速度</h1>
<blockquote>原文：<a href="https://pub.towardsai.net/profiling-neural-networks-to-improve-model-training-and-inference-speed-22be473492bf?source=collection_archive---------1-----------------------#2021-12-16">https://pub.towardsai.net/profiling-neural-networks-to-improve-model-training-and-inference-speed-22be473492bf?source=collection_archive---------1-----------------------#2021-12-16</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><h2 id="f34a" class="io ip iq bd b dl ir is it iu iv iw dk ix translated" aria-label="kicker paragraph"><a class="ae ep" href="https://towardsai.net/p/category/machine-learning/deep-learning" rel="noopener ugc nofollow" target="_blank">深度学习</a></h2><div class=""/><figure class="gl gn jx jy jz ka gh gi paragraph-image"><div role="button" tabindex="0" class="kb kc di kd bf ke"><div class="gh gi jw"><img src="../Images/7f80911b54df074d8d51d50cce3911c8.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*8pzRnb4Zjy5vNHFX"/></div></div><figcaption class="kh ki gj gh gi kj kk bd b be z dk translated">由<a class="ae kl" href="https://unsplash.com/@nhoizey?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">尼古拉斯·霍伊泽</a>在<a class="ae kl" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上拍摄的照片</figcaption></figure><p id="e093" class="pw-post-body-paragraph km kn iq ko b kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">在之前的一篇<a class="ae kl" href="https://programmablerobots.substack.com/p/teaching-a-robot-to-read-sign-language-133d4a553eeb" rel="noopener ugc nofollow" target="_blank">帖子</a>中，我们研究了如何教会Anki矢量机器人识别人类手语。具体来说，我们用从Vector的相机中拍摄的8500幅人体标志图像的<a class="ae kl" href="https://www.kaggle.com/amitabhabanerjee/training-a-robot-to-understand-sign-language" rel="noopener ugc nofollow" target="_blank">标记数据集</a>训练了一个定制的卷积神经网络(CNN)。在这个视频中，我们演示了如何使用经过训练的CNN来检测人体信号。我们还探索了小型定制CNN模型和大规模公认的RESNET模型之间的权衡。其他研究人员也做了类似的努力；比如教Anki Cozmo学习人类手语的努力。</p><p id="7331" class="pw-post-body-paragraph km kn iq ko b kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">在这篇文章中，我们将根据训练模型所需的时间(训练速度)，以及使用该模型对图像进行分类所需的时间(推理速度)，找出优化该模型的方法。我们可以把这个过程分成几个步骤。</p><ol class=""><li id="9a47" class="lk ll iq ko b kp kq kt ku kx lm lb ln lf lo lj lp lq lr ls bi translated"><strong class="ko ja">描述您现有的模型，并寻找改进的机会。</strong></li><li id="ef21" class="lk ll iq ko b kp lt kt lu kx lv lb lw lf lx lj lp lq lr ls bi translated"><strong class="ko ja">对您的模型进行相应的更改，以实现预期的改进</strong></li><li id="f9ac" class="lk ll iq ko b kp lt kt lu kx lv lb lw lf lx lj lp lq lr ls bi translated"><strong class="ko ja">重新运行您的培训管道，重新描述，并评估您是否有所改进。</strong></li></ol><p id="f85a" class="pw-post-body-paragraph km kn iq ko b kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated"><strong class="ko ja">性能分析</strong></p><p id="1f91" class="pw-post-body-paragraph km kn iq ko b kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">如果您的项目基于Tensorflow，则分析模型的最简单方法是使用TensorBoard Profiler。PyTorch也有类似的<a class="ae kl" href="https://pytorch.org/blog/introducing-pytorch-profiler-the-new-and-improved-performance-tool/" rel="noopener ugc nofollow" target="_blank">性能分析器</a>。<a class="ae kl" href="https://www.tensorflow.org/guide/gpu_performance_analysis" rel="noopener ugc nofollow" target="_blank">这篇</a>文章向你展示了尝试优化GPU性能的步骤。在我们的具体案例中，我们将分析RESNET模型的性能，该模型被训练来学习人类手语识别语言。这个<a class="ae kl" href="https://colab.research.google.com/drive/1zDFm6qpvwbmMa1wxtDK3DXXCPrhQl7fk?usp=sharing" rel="noopener ugc nofollow" target="_blank"> Colab笔记本</a>演示了如何在训练RESNET的同时运行TensorBoard profiler。简而言之，我们对RESNET进行了5个纪元的训练，取得了94%的准确率；同时，我们收集档案，以了解训练模型的性能。</p><p id="e717" class="pw-post-body-paragraph km kn iq ko b kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">这是分析器的一个快照。</p><figure class="lz ma mb mc gt ka gh gi paragraph-image"><div role="button" tabindex="0" class="kb kc di kd bf ke"><div class="gh gi ly"><img src="../Images/2a71b5739f2c413729f55f097f9a1f7f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*atwRTJmgO5RKZvXBsNSKSw.png"/></div></div><figcaption class="kh ki gj gh gi kj kk bd b be z dk translated">图TensorBoard分析器的输出</figcaption></figure><p id="dc8d" class="pw-post-body-paragraph km kn iq ko b kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">从上述情况可以得出一些重要的观察结果。</p><ol class=""><li id="229f" class="lk ll iq ko b kp kq kt ku kx lm lb ln lf lo lj lp lq lr ls bi translated">训练一个模型的每一步需要631毫秒。<strong class="ko ja">一个步骤包括基于一段训练数据更新神经网络模型参数的一次迭代。</strong>对于训练神经网络模型的每一步，CPU都需要将模型参数卸载到GPU并启动计算。换句话说，对模型参数进行一轮更新所花费的时间是631毫秒。</li><li id="3f70" class="lk ll iq ko b kp lt kt lu kx lv lb lw lf lx lj lp lq lr ls bi translated"><strong class="ko ja">大部分时间(~590 ms)属于设备计算时间</strong>(参见浅绿色曲线)，这是GPU计算矩阵乘法以得出误差和导数以得出误差曲线梯度所花费的时间(如果您不了解CNN如何为该练习进行训练的细节，这没关系)。</li><li id="06f4" class="lk ll iq ko b kp lt kt lu kx lv lb lw lf lx lj lp lq lr ls bi translated"><strong class="ko ja">大约23毫秒(3.7%)属于内核启动时间范畴。</strong>这是CPU将数据卸载到GPU所需的时间。TensorBoard Profile指出了在此步骤中可以进行的优化。我们将在后面讨论这种优化。</li><li id="4f6a" class="lk ll iq ko b kp lt kt lu kx lv lb lw lf lx lj lp lq lr ls bi translated">TensorBoard Profile <strong class="ko ja">注意到没有一个计算是基于浮点16 (FP16)算法</strong>(黑色圆圈中的注释)。这为改进提供了一个成熟的基础，我们将在这篇文章的下一部分讨论如何进行这种改进，以及它所带来的折衷。</li></ol><p id="faf6" class="pw-post-body-paragraph km kn iq ko b kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated"><strong class="ko ja">混合精度算术</strong></p><p id="7f18" class="pw-post-body-paragraph km kn iq ko b kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">让我们先了解一下浮点16 (FP16)和浮点32 (FP32)运算的区别。</p><p id="9de5" class="pw-post-body-paragraph km kn iq ko b kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated"><strong class="ko ja"> FP16 vs FP32运算</strong></p><p id="7737" class="pw-post-body-paragraph km kn iq ko b kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">使用FP16为我们带来了两个显著的计算优势</p><ol class=""><li id="75e6" class="lk ll iq ko b kp kq kt ku kx lm lb ln lf lo lj lp lq lr ls bi translated">在FP16上操作的计算速度(比如说将两个FP16数相乘)比FP32算法快很多倍。有两个原因:(I)您需要做的工作减少了4倍，以及(ii)许多处理器(如Nvidia的处理器)都有专门的单元来处理FP16。</li><li id="078d" class="lk ll iq ko b kp lt kt lu kx lv lb lw lf lx lj lp lq lr ls bi translated">我们在访问FP16数据时消耗的内存带宽要少得多，从而降低了在遇到计算瓶颈之前遇到内存访问瓶颈的可能性。</li></ol><p id="07ff" class="pw-post-body-paragraph km kn iq ko b kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">然而，使用FP16的后果是精度较低。因此，如果我们简单地使用FP16来表示神经网络的系数，由于数据精度的损失，训练阶段很可能不会收敛。</p><p id="e8e6" class="pw-post-body-paragraph km kn iq ko b kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">这导致了<strong class="ko ja">混合精度训练</strong>的引入。在混合精度训练中，我们在FP16中执行大多数操作，但在FP32中保留网络的一些核心部分(通常模型激活和梯度使用16位浮点格式存储，而模型权重和优化器状态使用32位精度<a class="ae kl" href="https://programmablerobots.substack.com/#footnote-1" rel="noopener ugc nofollow" target="_blank"> 1 </a>)，以便最大限度地减少信息损失。NVIDIA的文档显示了混合精度训练如何实现3倍的速度提升，同时在训练时收敛到相同的精度水平。</p><p id="907f" class="pw-post-body-paragraph km kn iq ko b kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated"><strong class="ko ja"> ML库支持混合精度训练</strong></p><p id="ddfd" class="pw-post-body-paragraph km kn iq ko b kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">大多数ML库都内置了对混合精度的支持。例如，在Tensorflow中，启用混合精度训练只需添加以下行:</p><pre class="lz ma mb mc gt md me mf mg aw mh bi"><span id="612c" class="mi mj iq me b gy mk ml l mm mn">from tensorflow.keras import mixed_precision<br/>policy = mixed_precision.Policy('mixed_float16')<br/>mixed_precision.set_global_policy(policy)</span></pre><p id="3eee" class="pw-post-body-paragraph km kn iq ko b kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">在上面几行代码中，我们设置了一个全局策略来使用FP16的混合精度。一个解释Tensorflow复杂性的详细文档可以在<a class="ae kl" href="https://www.tensorflow.org/guide/mixed_precision" rel="noopener ugc nofollow" target="_blank">这里</a>找到。现在，我们需要衡量上述代码更改的效果。</p><p id="2170" class="pw-post-body-paragraph km kn iq ko b kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated"><strong class="ko ja">量化模型变化</strong></p><p id="86cb" class="pw-post-body-paragraph km kn iq ko b kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">以下是一些关于如何科学地量化模型变化的原则:</p><ol class=""><li id="c302" class="lk ll iq ko b kp kq kt ku kx lm lb ln lf lo lj lp lq lr ls bi translated"><strong class="ko ja">进行比较:</strong>确保你完全了解和理解你正在比较的东西。背景中经常会发生微妙的变化，这可能会影响我们在两个实验之间进行的任何比较。在这项工作的背景下，重要的是要检查训练是在相同类型的GPU上、在相同的训练数据集上、针对相同数量的时期执行的。</li><li id="2767" class="lk ll iq ko b kp lt kt lu kx lv lb lw lf lx lj lp lq lr ls bi translated"><strong class="ko ja">小心每次运行的变化:</strong>当我们运行两个实验时，最终结果很少相同。这种差异是由系统中经常发生的多种随机过程造成的。因此，重要的是不要从一次实验来判断实验结果。相反，人们应该多次进行实验。多次实验得出的结果给了读者更高程度的信心。</li><li id="0cf9" class="lk ll iq ko b kp lt kt lu kx lv lb lw lf lx lj lp lq lr ls bi translated"><strong class="ko ja">使用多个数据点来比较和对比结果。</strong><strong class="ko ja"/>一旦我们获得了多次实验的结果，我们需要使用不同的方法来解释这些结果。通常，结果的平均值被用作唯一的比较点。然而，通常意味着是不够的。可用于比较的其他度量是I)标准偏差，ii)中值，iii)百分位数:例如第90百分位数。</li></ol><p id="b808" class="pw-post-body-paragraph km kn iq ko b kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated"><strong class="ko ja">了解混合精度训练的效果</strong></p><p id="7f0b" class="pw-post-body-paragraph km kn iq ko b kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">现在我们已经了解了如何比较实验结果，让我们比较RESNET模型在人类手语识别数据集上的训练性能。在这种情况下，我们希望比较以下内容:</p><ol class=""><li id="4ea2" class="lk ll iq ko b kp kq kt ku kx lm lb ln lf lo lj lp lq lr ls bi translated">使用默认的32位精度为RESNET定型</li><li id="82f9" class="lk ll iq ko b kp lt kt lu kx lv lb lw lf lx lj lp lq lr ls bi translated">混合精度训练RESNET。</li></ol><p id="4f00" class="pw-post-body-paragraph km kn iq ko b kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">训练在5个时期终止。(如果我们实际上正在训练一个部署在生产环境中的模型，我们将训练更多的历元，直到精度收敛。但是对于性能比较，5个纪元就足够了)我们在这个<a class="ae kl" href="https://colab.research.google.com/drive/1zDFm6qpvwbmMa1wxtDK3DXXCPrhQl7fk?usp=sharing" rel="noopener ugc nofollow" target="_blank"> Google Colab笔记本</a>的帮助下，对每组实验运行了五次迭代。这是结果。</p><figure class="lz ma mb mc gt ka gh gi paragraph-image"><div role="button" tabindex="0" class="kb kc di kd bf ke"><div class="gh gi mo"><img src="../Images/7990847155712803ba2981692eb6bc48.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*4zzeAEsCicFiQUe3m1K50w.png"/></div></div><figcaption class="kh ki gj gh gi kj kk bd b be z dk translated">图2:将模型训练到5个时期的时间的盒须图</figcaption></figure><figure class="lz ma mb mc gt ka gh gi paragraph-image"><div role="button" tabindex="0" class="kb kc di kd bf ke"><div class="gh gi mo"><img src="../Images/4e636acc57e19eede7d2b30a5b520f3a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*lV4pnT4DvN6yvRkBY3kDOw.png"/></div></div><figcaption class="kh ki gj gh gi kj kk bd b be z dk translated">图3:经过5个时期的训练后，模型在验证数据集上的准确度的盒须图</figcaption></figure><p id="24af" class="pw-post-body-paragraph km kn iq ko b kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">这些图通常被称为<a class="ae kl" href="https://datavizcatalogue.com/methods/box_plot.html" rel="noopener ugc nofollow" target="_blank">盒须图</a>。顶部和底部的条形表示最大值和最小值，而图中的彩色区域表示上四分位数(75%)和下四分位数(25%)之间的范围。借助这些图，我们可以得出以下结论。</p><ol class=""><li id="eaf0" class="lk ll iq ko b kp kq kt ku kx lm lb ln lf lo lj lp lq lr ls bi translated">混合精度训练使得模型的训练时间更快，并且训练时间的方差更低。如果我们将平均值作为比较指标，混合精度训练要快6%。</li><li id="ddda" class="lk ll iq ko b kp lt kt lu kx lv lb lw lf lx lj lp lq lr ls bi translated">混合精度训练在模型的精度上具有大得多的差异。在最坏的情况下，模型的准确度可能显著更差(与32位训练的5个时期后的86%准确度相比，5个时期后的66%准确度的最坏情况)。更差的精度可能意味着模型需要训练到更高的历元数，或者模型重新训练…这两种选择都会增加训练时间。</li></ol><p id="5593" class="pw-post-body-paragraph km kn iq ko b kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">顺便说一下，用混合精度训练的模型也将有更少的推理时间…但是我们将在随后的帖子中讨论这个问题。</p><figure class="lz ma mb mc gt ka gh gi paragraph-image"><div class="gh gi mp"><img src="../Images/fbd4d13bc70d1cec315dd7412d44ac4a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1034/format:webp/1*oagh9MZBMw_Ky8Y6Ej86Dg.png"/></div></figure><p id="0374" class="pw-post-body-paragraph km kn iq ko b kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">如果你有任何问题或想法，请在下面的评论中留下。更多有趣的文章请关注我的刊物:<a class="ae kl" href="https://medium.com/programming-robots" rel="noopener">编程机器人</a>。我也有一门借助Vector教授人工智能的在线课程，可以在:【https://robotics.thinkific.com】T2找到，我将为有你这样的学生而感到荣幸。</p></div></div>    
</body>
</html>