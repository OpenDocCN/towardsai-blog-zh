<html>
<head>
<title>BRIO: Bringing Order to Abstractive Summarization (Paper Review/Described)</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">BRIO:给抽象概括带来秩序</h1>
<blockquote>原文：<a href="https://pub.towardsai.net/brio-bringing-order-to-abstractive-summarization-paper-review-described-62690ff4aa9d?source=collection_archive---------2-----------------------#2022-04-25">https://pub.towardsai.net/brio-bringing-order-to-abstractive-summarization-paper-review-described-62690ff4aa9d?source=collection_archive---------2-----------------------#2022-04-25</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><p id="d446" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated"><em class="ko">CNN/DM和XSum数据集上的文本摘要任务的最新成果。它使用对比学习对候选人进行排名。</em></p><figure class="kq kr ks kt gt ku gh gi paragraph-image"><div role="button" tabindex="0" class="kv kw di kx bf ky"><div class="gh gi kp"><img src="../Images/daaaafba3d49efa92be77b99074b43e1.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*JarbJmT3RIn4tq59pxkTNQ.png"/></div></div><figcaption class="lb lc gj gh gi ld le bd b be z dk translated">图一。显示了seq2seq架构中使用的传统MLE损耗与无基准电压源对比损耗之间的差异。(图片来自[1])</figcaption></figure><p id="3bad" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">在我写了关于<a class="ae lf" href="https://medium.com/towards-artificial-intelligence/simcls-a-simple-framework-for-contrastive-learning-of-abstractive-summarization-review-explained-87f9d394c620" rel="noopener"> SimCLS </a> [2】(之前的SOTA)的论文后不久，一个关于抽象文本摘要任务的最新(SOTA)结果发表了。有趣的是，他们在提到的论文的基础上加入了对比学习范式。(这并不奇怪，因为他们有相同的作者)该实验为CNN/DM数据集<strong class="js iu">两次</strong>创造了新的SOTA胭脂评分。一次是通过引入具有47.78 R1分数的“BRIO-Mul”网络，并进一步将其在“BRIO-Loop”模型中的性能提高到48.01。让我们看看他们的方法是什么…</p></div><div class="ab cl lg lh hx li" role="separator"><span class="lj bw bk lk ll lm"/><span class="lj bw bk lk ll lm"/><span class="lj bw bk lk ll"/></div><div class="im in io ip iq"><h1 id="3116" class="ln lo it bd lp lq lr ls lt lu lv lw lx ly lz ma mb mc md me mf mg mh mi mj mk bi translated">本文想解决什么问题？</h1><p id="a74b" class="pw-post-body-paragraph jq jr it js b jt ml jv jw jx mm jz ka kb mn kd ke kf mo kh ki kj mp kl km kn im bi translated">我们通常使用最大似然估计(MLE)损失来训练<a class="ae lf" rel="noopener ugc nofollow" target="_blank" href="/a-full-introduction-on-text-summarization-using-deep-learning-with-sample-code-ft-huggingface-d21e0336f50c"> seq2seq </a>模型。本文认为，我们正在使用损失函数，对于一个实际上可能有多个正确输出(非确定性)的任务，该函数会将零分配给一个“正确”输出(单点/确定性)。在训练和推理过程之间也存在差异，其中模型是基于其自身在生成期间的先前预测步骤而不是目标概要来调节的。当模型在推理过程中开始偏离目标(变得更加混乱)时，就会造成困难。(称为“曝光偏差”)</p><h1 id="a8be" class="ln lo it bd lp lq mq ls lt lu mr lw lx ly ms ma mb mc mt me mf mg mu mi mj mk bi translated">贡献</h1><p id="4296" class="pw-post-body-paragraph jq jr it js b jt ml jv jw jx mm jz ka kb mn kd ke kf mo kh ki kj mp kl km kn im bi translated">他们提出了纳入评估指标的想法(例如，ROUGE、BERTScore等)，以便模型可以学习如何对摘要进行排序。这是通过使用不同的波束搜索并为每篇文章生成多个候选项(本文中为16个)来实现的。设计了一个两级流水线，使用预先训练的网络(BART)生成候选，并从中选择最佳的一个。</p><p id="a723" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated"><strong class="js iu">对比损失</strong> (ctr)负责指导模型学习它应该如何对给定文章的多个候选项进行排序。它将在微调过程中用于改善<strong class="js iu">序列级协调</strong>。讨论了仅基于对比损失的微调模型不能用于生成摘要。因此，上述损失的加权值与<strong class="js iu">交叉熵</strong> (xnet)损失相加，以保证<strong class="js iu">令牌级预测精度</strong>。(图2)它被称为多任务微调损失(mul ),这导致了被描述为“双重角色”模型的<em class="ko"> BRIO-Mul </em>。这是一个既能<strong class="js iu">生成</strong>摘要又能<strong class="js iu">评估</strong>所生成候选的质量的单一模型，这对于上述两阶段流水线是必要的。</p><figure class="kq kr ks kt gt ku gh gi paragraph-image"><div class="gh gi mv"><img src="../Images/a41bcd0f8b690b8dbef2c5e9ae8cdc32.png" data-original-src="https://miro.medium.com/v2/resize:fit:1096/format:webp/1*RpqVewxSGI512CQz5QHQkA.png"/></div><figcaption class="lb lc gj gh gi ld le bd b be z dk translated">图二。多任务微调损失目标。(图片来自[1])</figcaption></figure><p id="f51a" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">变量gamma (γ)控制对比损失对最终损失的贡献。使用不同伽马值(0、0.1、1、2等)的研究。)表明，数字越大，收敛越快。此外，100是报告的最佳gamma值，导致最高的胭脂分数。</p><figure class="kq kr ks kt gt ku gh gi paragraph-image"><div role="button" tabindex="0" class="kv kw di kx bf ky"><div class="gh gi mw"><img src="../Images/7c76ccd5ad7861117a495f735d81319e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*xXQ9wmS-8AfV1lZy5Yipcw.png"/></div></div><figcaption class="lb lc gj gh gi ld le bd b be z dk translated">图3。BRIO环路微调方案。(图片来自[1])</figcaption></figure><p id="f5db" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">如前所述，本研究在生成阶段使用BART预训练模型。然而，使用BRIO-Mul模型是合乎逻辑的，因为它已经超越了BART的性能。(如图3所示)该循环可以进一步提高ROUGE分数。</p><h1 id="28c6" class="ln lo it bd lp lq mq ls lt lu mr lw lx ly ms ma mb mc mt me mf mg mu mi mj mk bi translated">结果</h1><p id="8ebc" class="pw-post-body-paragraph jq jr it js b jt ml jv jw jx mm jz ka kb mn kd ke kf mo kh ki kj mp kl km kn im bi translated">BRIO方法为三个抽象概括数据集设置了新的SOTA结果:CNN/DailyMail、XSum和NYT。(参见图4)这表明该方法对于具有长摘要和短摘要的数据集都能很好地执行。同样值得注意的是，BRIO-Loop模型只在CNN/DM上进行了测试，并将R-1评分提高到了48.01。</p><figure class="kq kr ks kt gt ku gh gi paragraph-image"><div role="button" tabindex="0" class="kv kw di kx bf ky"><div class="gh gi mx"><img src="../Images/808bd2bb91b103280bfe87e059c9f3f7.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*GdNSXDRhBPB7RqKTaUhSgA.png"/></div></div><figcaption class="lb lc gj gh gi ld le bd b be z dk translated">图4。BRIO-Mul与之前的SOTA车型的ROUGE评分比较。(图片来自[1])</figcaption></figure><p id="7f9c" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">我们来谈谈论文中的两个观察结果。<em class="ko">1)</em>BRIO[1]和SimCLR [2](之前的SOTA)模型之间的主要区别是使用单一模型进行生成和评分，最大化BRIO中的参数共享，而后者使用RoBERTa作为评估模型。XSum基准使用PEGASUS作为基础模型(而不是BART)，这表明该方法可以独立于模型的选择而使用。</p><h1 id="2bd4" class="ln lo it bd lp lq mq ls lt lu mr lw lx ly ms ma mb mc mt me mf mg mu mi mj mk bi translated">分析</h1><p id="7248" class="pw-post-body-paragraph jq jr it js b jt ml jv jw jx mm jz ka kb mn kd ke kf mo kh ki kj mp kl km kn im bi translated">作者们做了大量的工作来分析和支持他们的观点。有深入的调查，以获得更多的了解引进的模式。我在下面的段落中[简要地]提到了其中的一些。</p><ul class=""><li id="c2d2" class="my mz it js b jt ju jx jy kb na kf nb kj nc kn nd ne nf ng bi translated"><strong class="js iu">增加波束宽度</strong>:k值越高，提出的模型性能越好。(特别是k=100)与使用k=4产生最佳输出的原始BART不同。</li><li id="276c" class="my mz it js b jt nh jx ni kb nj kf nk kj nl kn nd ne nf ng bi translated"><strong class="js iu">少量微调</strong>:在CNN/DM数据集上仅用100个(随机选择的)样本，BRIO-少数就能胜过BART，在XSum上用1000个样本，胜过PEGASUS。</li><li id="725e" class="my mz it js b jt nh jx ni kb nj kf nk kj nl kn nd ne nf ng bi translated"><strong class="js iu">新颖的n-grams </strong>:与BART相比，BRIO在摘要中生成更多新颖的n-grams</li></ul><p id="d96e" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">文中还有更多像<strong class="js iu">令牌级校准</strong>、<strong class="js iu">异度训练</strong>、<strong class="js iu">过滤推理噪声</strong>的分析，我就不一一赘述了，但强烈推荐大家阅读。</p><h1 id="2f61" class="ln lo it bd lp lq mq ls lt lu mr lw lx ly ms ma mb mc mt me mf mg mu mi mj mk bi translated">最后的话，</h1><p id="9449" class="pw-post-body-paragraph jq jr it js b jt ml jv jw jx mm jz ka kb mn kd ke kf mo kh ki kj mp kl km kn im bi translated">作者能够用写得很好的分析部分和论文来支持他们的主张。我希望我们能看到更多像这样容易理解和遵循的论文。他们还在<a class="ae lf" href="https://github.com/yixinL7/BRIO" rel="noopener ugc nofollow" target="_blank"> GitHub </a>上发布了代码，帮助我了解了一些方面。总的来说，这是一个伟大的阅读。</p><blockquote class="nm"><p id="a1aa" class="nn no it bd np nq nr ns nt nu nv kn dk translated">我每周给NLP的书呆子发一份时事通讯。如果您想了解自然语言处理的最新发展，可以考虑订阅。<br/> <a class="ae lf" href="https://nlpiation.github.io/" rel="noopener ugc nofollow" target="_blank">阅读更多，订阅</a> —加入酷孩子俱乐部，立即报名！</p></blockquote><h2 id="4551" class="nw lo it bd lp nx ny dn lt nz oa dp lx kb ob oc mb kf od oe mf kj of og mj oh bi translated">参考</h2><p id="2cfc" class="pw-post-body-paragraph jq jr it js b jt ml jv jw jx mm jz ka kb mn kd ke kf mo kh ki kj mp kl km kn im bi translated">[1]刘，杨，刘，p .拉杰夫，d .，&amp;纽比格，G. (2022)。BRIO:给抽象概括带来秩序。<em class="ko"> arXiv预印本arXiv:2203.16804 </em>。<br/>【2】刘，杨，&amp;刘，P. (2021)。Simcls:抽象概括对比学习的简单框架。arXiv预印本arXiv:2106.01890。</p></div></div>    
</body>
</html>