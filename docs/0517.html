<html>
<head>
<title>Understanding Bias in the Simplest Plausible Way</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">用最简单的方式理解偏见</h1>
<blockquote>原文：<a href="https://pub.towardsai.net/understanding-bias-in-the-simplest-plausible-way-ad58f9eb1ddf?source=collection_archive---------1-----------------------#2020-05-23">https://pub.towardsai.net/understanding-bias-in-the-simplest-plausible-way-ad58f9eb1ddf?source=collection_archive---------1-----------------------#2020-05-23</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><h2 id="7d61" class="io ip iq bd b dl ir is it iu iv iw dk ix translated" aria-label="kicker paragraph">人工智能</h2><div class=""/><p id="5625" class="pw-post-body-paragraph jw jx iq jy b jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ij bi translated">我最近开始探索神经网络，我遇到了术语激活功能和偏见。激活函数对我来说有点意义，但我发现很难得到神经网络中偏差的确切本质。</p><p id="ef64" class="pw-post-body-paragraph jw jx iq jy b jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ij bi translated">我研究了各种来源，他们只有-</p><blockquote class="ku kv kw"><p id="1ab9" class="jw jx kx jy b jz ka kb kc kd ke kf kg ky ki kj kk kz km kn ko la kq kr ks kt ij bi translated">神经网络中的偏差可以被认为类似于线性回归中截距的作用。</p></blockquote><p id="a74a" class="pw-post-body-paragraph jw jx iq jy b jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ij bi translated">但是这到底意味着什么呢？我非常理解<strong class="jy ja">截距</strong>是直线与y轴相交的点。如果我们没有截距，那么我们的线会一直穿过原点，但现实世界中不是这样，所以我们用截距来增加一些灵活性。</p><blockquote class="ku kv kw"><p id="0edd" class="jw jx kx jy b jz ka kb kc kd ke kf kg ky ki kj kk kz km kn ko la kq kr ks kt ij bi translated"><strong class="jy ja">那么偏见是如何给神经网络增加灵活性的呢？</strong></p></blockquote><p id="6e0d" class="pw-post-body-paragraph jw jx iq jy b jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ij bi translated">在这篇文章的结尾你会找到这个问题的答案。</p><p id="0380" class="pw-post-body-paragraph jw jx iq jy b jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ij bi translated">上面引用的定义是我们谈论偏见时遇到的最常见的定义。所以我想，让我们忽略我上面的问题，继续这个关于偏见的平庸解释(这没有任何意义)。因为任何人，当被问及偏见时，这都是抢答。但是后来我看到了下面这张图片，它深深地打动了我。</p><figure class="lc ld le lf gt lg gh gi paragraph-image"><div class="gh gi lb"><img src="../Images/ec95debdc6dda4ef420bc992ac525d8b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1342/format:webp/1*E34jIOHmJzlTnAzh0BTY_g.png"/></div><figcaption class="lj lk gj gh gi ll lm bd b be z dk translated"><a class="ae ln" href="https://talgroupinc.files.wordpress.com/2016/07/careerlesson_explainitto6yearold.png?w=768" rel="noopener ugc nofollow" target="_blank">来源</a></figcaption></figure><p id="0ce9" class="pw-post-body-paragraph jw jx iq jy b jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ij bi translated">如果我不能向一个六岁的孩子解释偏见，那么我想甚至我也没有理解它(这确实是事实)。所以我开始查阅更多的资料，最后，偏见开始变得有意义了。让我们借助感知器来理解偏见。</p><h1 id="2335" class="lo lp iq bd lq lr ls lt lu lv lw lx ly lz ma mb mc md me mf mg mh mi mj mk ml bi translated">感知器</h1><p id="8583" class="pw-post-body-paragraph jw jx iq jy b jz mm kb kc kd mn kf kg kh mo kj kk kl mp kn ko kp mq kr ks kt ij bi translated">感知器可以被想象成接受一些二进制输入x1，x2，…并产生一个二进制输出的东西。</p><figure class="lc ld le lf gt lg gh gi paragraph-image"><div class="gh gi mr"><img src="../Images/bcc205a1be18fe8ccc84fc0a02dd31d5.png" data-original-src="https://miro.medium.com/v2/resize:fit:1290/format:webp/1*YPguig_eDkgWi5cgvWiUBg.png"/></div><figcaption class="lj lk gj gh gi ll lm bd b be z dk translated">感知器模型</figcaption></figure><p id="0dcf" class="pw-post-body-paragraph jw jx iq jy b jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ij bi translated">权重对应于输入的重要性，也称为特征。输出，即0或1，取决于权重和输入的加权和是否大于某个<strong class="jy ja"> <em class="kx">阈值。</em>T11】</strong></p><p id="a0f8" class="pw-post-body-paragraph jw jx iq jy b jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ij bi translated">算术地</p><figure class="lc ld le lf gt lg gh gi paragraph-image"><div class="gh gi ms"><img src="../Images/48debe00861c221617671b556edc3321.png" data-original-src="https://miro.medium.com/v2/resize:fit:642/format:webp/1*qshvofOK3_kAl26xjERFeQ.png"/></div><figcaption class="lj lk gj gh gi ll lm bd b be z dk translated">感知器方程</figcaption></figure><p id="7184" class="pw-post-body-paragraph jw jx iq jy b jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ij bi translated">让我们考虑一个例子，假设你喜欢一个人，你想决定是否应该告诉那个人你的感觉。你可能会根据下面的问题做出最后的决定。</p><ol class=""><li id="2665" class="mt mu iq jy b jz ka kd ke kh mv kl mw kp mx kt my mz na nb bi translated">我是真的爱那个人，还是只是单纯的迷恋？</li><li id="4a36" class="mt mu iq jy b jz nc kd nd kh ne kl nf kp ng kt my mz na nb bi translated">如果我说出我的心声会毁了我和那个人的关系呢？</li><li id="e2f0" class="mt mu iq jy b jz nc kd nd kh ne kl nf kp ng kt my mz na nb bi translated">这真的值得吗(会对你的职业生涯产生负面影响吗)</li></ol><p id="618f" class="pw-post-body-paragraph jw jx iq jy b jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ij bi translated">我知道可能还有许多其他问题，但这些都是常见的问题。所以你决定是否说出你的心声取决于上面的问题。</p><p id="1ab1" class="pw-post-body-paragraph jw jx iq jy b jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ij bi translated">所以让我们把x1、x2和x3看作你的3个问题，如果是迷恋，x1 = 0，如果不是，x1 = 1。类似地，如果不会破坏你的等式，x2 = 0；如果你觉得不值得，x3 = 0。</p><p id="058d" class="pw-post-body-paragraph jw jx iq jy b jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ij bi translated">可能发生的情况是，上述问题并不都同等重要。你可以做的是根据问题的重要性/相关性给所有问题分配一些数字。这些数字只不过是重量。</p><p id="f328" class="pw-post-body-paragraph jw jx iq jy b jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ij bi translated">假设您分配权重，w1 = 3，w2 = 2，w3 = 7，其中w1、w2、w3分别代表问题1、2和3的权重。这意味着你更关心它是否值得，因为你想专注于你的职业生涯，你承受不起分心(因为w3有更高的量级)。你将阈值设置为6，所以如果加权和大于6，那么你会说出你的心声。但是从上面的权重值可以看出，你并不担心这是不是迷恋，也不担心这是否会毁了事情，因为即使x1 = 1，x2 = 1，也不会对你的决定有多大帮助，因为它们的权重更小。所以看阈值和w3，我们可以说决定因素是x3(问题3)。</p><p id="30ee" class="pw-post-body-paragraph jw jx iq jy b jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ij bi translated">让我们考虑一个不同的场景，假设权重w1 = 10，w2 = 3，w3 = 5。所以在这里是不是一种迷恋比什么都重要。假设现在你把阈值保持在2，那么你会很快得出肯定的结论。假设x1 = 0，x2 = 1，x3 = 0。在这种情况下，即使x1和x3为0，加权和也大于阈值。所以即使x1有较大的权重，但由于门槛太低，也起不到决定因素的作用。这意味着你更渴望通过设置更低的门槛来说出自己的心声。</p><p id="dd98" class="pw-post-body-paragraph jw jx iq jy b jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ij bi translated">所以改变权重和阈值也会改变决策。</p><p id="be25" class="pw-post-body-paragraph jw jx iq jy b jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ij bi translated">想象一下这样一种情况，我们没有阈值，所以只要加权和大于0，您就会得到“是”。但我们不希望这种情况发生。我们想根据加权和的大小得出结论。如果加权和超过某个阈值，那么输出应该是Yes，否则应该是No。因此我们需要一个阈值。</p><p id="0176" class="pw-post-body-paragraph jw jx iq jy b jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ij bi translated">让我们通过将阈值放在左侧来简化等式。</p><figure class="lc ld le lf gt lg gh gi paragraph-image"><div class="gh gi nh"><img src="../Images/8143fb002bc0a30f5d981a6c55a6f674.png" data-original-src="https://miro.medium.com/v2/resize:fit:716/format:webp/1*7_qih6BbLyPUIh_RLEraqA.png"/></div><figcaption class="lj lk gj gh gi ll lm bd b be z dk translated">LHS的门槛(左侧)</figcaption></figure><p id="dfac" class="pw-post-body-paragraph jw jx iq jy b jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ij bi translated">类似地，当我们的加权和大于特定阈值时，我们希望我们的神经元被激活。如果我们不使用阈值，只要加权和大于0，神经元就会被激活。</p><p id="6e55" class="pw-post-body-paragraph jw jx iq jy b jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ij bi translated">所以bias<strong class="jy ja"><em class="kx">b = threshold</em></strong><em class="kx"/>并且用bias代替threshold，我们得到一个熟悉的等式。</p><figure class="lc ld le lf gt lg gh gi paragraph-image"><div class="gh gi ni"><img src="../Images/997eca6c3913f1e93c29ad4013f537bd.png" data-original-src="https://miro.medium.com/v2/resize:fit:558/format:webp/1*iGNzkaYD2z63cyfqAs0akQ.png"/></div><figcaption class="lj lk gj gh gi ll lm bd b be z dk translated">有偏差的感知器</figcaption></figure><p id="c858" class="pw-post-body-paragraph jw jx iq jy b jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ij bi translated">这里<em class="kx">σwixi</em>写成<em class="kx">w . x =σwixi，</em>其中w和x是向量，它们的分量分别是权重和输入。</p><p id="f4a0" class="pw-post-body-paragraph jw jx iq jy b jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ij bi translated">我们可以认为，<strong class="jy ja">偏差用于不活动，</strong>神经元只有在加权和大于阈值时才会被激活，因为<strong class="jy ja"> <em class="kx"> b=阈值</em> </strong>概念有点颠倒。之前，我们说过阈值越大，要激活的神经元的加权和就应该越大，但是现在由于偏差是阈值的倒数，偏差越大，激活神经元所需的加权和就越小。</p><blockquote class="ku kv kw"><p id="ba08" class="jw jx kx jy b jz ka kb kc kd ke kf kg ky ki kj kk kz km kn ko la kq kr ks kt ij bi translated">通过这种方式，bias通过决定何时激活神经元来增加神经网络的灵活性。</p></blockquote><p id="95fb" class="pw-post-body-paragraph jw jx iq jy b jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ij bi translated">显然，感知机与人类做出复杂决策的方式并不完全相似，但这个例子有助于以更简单的方式理解偏见。</p><p id="8063" class="pw-post-body-paragraph jw jx iq jy b jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ij bi translated">我希望我已经用最简单合理的方式解释了什么是偏见。欢迎在下面留下评论或问题，你可以在<a class="ae ln" href="https://www.linkedin.com/in/anirudh-dayma-457861144/" rel="noopener ugc nofollow" target="_blank"> Linkedin </a>上找到我。</p></div></div>    
</body>
</html>