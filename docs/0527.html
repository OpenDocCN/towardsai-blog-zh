<html>
<head>
<title>Artificial Neural Network Ship Crew size Prediction Model</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">人工神经网络船舶船员人数预测模型</h1>
<blockquote>原文：<a href="https://pub.towardsai.net/artificial-neural-network-ship-crew-size-prediction-model-c04017c7b6fa?source=collection_archive---------1-----------------------#2020-05-26">https://pub.towardsai.net/artificial-neural-network-ship-crew-size-prediction-model-c04017c7b6fa?source=collection_archive---------1-----------------------#2020-05-26</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><h2 id="8b1e" class="ir is it bd b dl iu iv iw ix iy iz dk ja translated" aria-label="kicker paragraph">机器学习</h2><div class=""/><div class=""><h2 id="d95b" class="pw-subtitle-paragraph jz jc it bd b ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq dk translated">本文的目的是设计一个神经网络模型来预测船舶船员人数。这个模型的本质将是一种回归。</h2></div><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi kr"><img src="../Images/03e93374f980eae00096ec6c34bec87c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*4PQOnabj78avPB2Mikk5GQ.jpeg"/></div></div><figcaption class="ld le gj gh gi lf lg bd b be z dk translated">人工神经网络架构</figcaption></figure><p id="3c85" class="pw-post-body-paragraph lh li it lj b lk ll kd lm ln lo kg lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">输入数据集包含9列，其中8列用作独立要素，最后一列是从属要素。你可以在<a class="ae md" href="https://gist.github.com/viv07/6994bf1f07f3b0c4816c6e57d879bf71" rel="noopener ugc nofollow" target="_blank"> <strong class="lj jd"> Github </strong> </a>上找到数据集。</p><h1 id="42b4" class="me mf it bd mg mh mi mj mk ml mm mn mo ki mp kj mq kl mr km ms ko mt kp mu mv bi translated">1.导入先决条件:</h1><pre class="ks kt ku kv gt mw mx my mz aw na bi"><span id="855d" class="nb mf it mx b gy nc nd l ne nf">import pandas as pd<br/>from sklearn.model_selection import train_test_split<br/>import matplotlib.pyplot as plt<br/>from sklearn.preprocessing import StandardScaler</span><span id="ae35" class="nb mf it mx b gy ng nd l ne nf">#import Neural network libraries<br/>import keras<br/>from keras.models import Sequential<br/>from keras.layers import Dense<br/>from keras.layers import LeakyReLU,PReLU,ELU</span><span id="9824" class="nb mf it mx b gy ng nd l ne nf">from sklearn.metrics import mean_squared_error ,mean_absolute_error,r2_score<br/>import numpy as np</span></pre><blockquote class="nh"><p id="ace8" class="ni nj it bd nk nl nm nn no np nq mc dk translated">Keras库用于设计和训练神经网络。</p></blockquote><h1 id="e5af" class="me mf it bd mg mh mi mj mk ml mm mn mo ki nr kj mq kl ns km ms ko nt kp mu mv bi translated">2.数据管理/争论</h1><pre class="ks kt ku kv gt mw mx my mz aw na bi"><span id="5080" class="nb mf it mx b gy nc nd l ne nf">ship_df=pd.read_csv(‘D:\python_coding\pyspark_tutorial\Linear regression\cruise_ship_info.csv’)</span><span id="7a59" class="nb mf it mx b gy ng nd l ne nf">ship_df.columns<br/>#Index(['Ship_name', 'Cruise_line', 'Age', 'Tonnage', 'passengers', 'length',        'cabins', 'passenger_density', 'crew'],       dtype='object')</span><span id="5559" class="nb mf it mx b gy ng nd l ne nf">ship_df.head(10)</span></pre><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div class="gh gi nu"><img src="../Images/70aac8d8fe1ccafec407f3b8cdba13b1.png" data-original-src="https://miro.medium.com/v2/resize:fit:1286/format:webp/1*E5u-9Nf_xRnJ9CvUSDhxEQ.png"/></div><figcaption class="ld le gj gh gi lf lg bd b be z dk translated">资料组</figcaption></figure><h2 id="b1ec" class="nb mf it bd mg nv nw dn mk nx ny dp mo lq nz oa mq lu ob oc ms ly od oe mu iz bi translated">检查数据集中的空值:</h2><pre class="ks kt ku kv gt mw mx my mz aw na bi"><span id="4ff7" class="nb mf it mx b gy nc nd l ne nf">ship_df.isna()<br/>#data doesn't have any NULL</span></pre><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div class="gh gi of"><img src="../Images/9a4b64495f19546ebc3b4a8e6a89db84.png" data-original-src="https://miro.medium.com/v2/resize:fit:1298/format:webp/1*NxT6OUGOsZ4-w_7hgy0x7A.png"/></div><figcaption class="ld le gj gh gi lf lg bd b be z dk translated">零检查</figcaption></figure><h1 id="03db" class="me mf it bd mg mh mi mj mk ml mm mn mo ki mp kj mq kl mr km ms ko mt kp mu mv bi translated">3.检查相关性</h1><p id="d983" class="pw-post-body-paragraph lh li it lj b lk og kd lm ln oh kg lp lq oi ls lt lu oj lw lx ly ok ma mb mc im bi translated">相关性是对两个特征之间的关联性或依赖性的度量，即<strong class="lj jd"> Y </strong>会随着<strong class="lj jd"> X </strong>的变化而变化多少。我们将使用的相关方法是<strong class="lj jd">皮尔逊相关</strong>。</p><p id="a898" class="pw-post-body-paragraph lh li it lj b lk ll kd lm ln lo kg lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated"><strong class="lj jd">皮尔逊相关系数</strong>是衡量相关性最流行的方法；值的范围从-1到1不等。</p><pre class="ks kt ku kv gt mw mx my mz aw na bi"><span id="16be" class="nb mf it mx b gy nc nd l ne nf">corr=ship_df.corr(method=’pearson’)<br/>corr</span></pre><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div class="gh gi ol"><img src="../Images/5655f8f7c7ce1b8a137f9190379da8ce.png" data-original-src="https://miro.medium.com/v2/resize:fit:1354/format:webp/1*oORBIJ-kCncdaWStLnqLsA.png"/></div><figcaption class="ld le gj gh gi lf lg bd b be z dk translated">相互关系</figcaption></figure><h2 id="d395" class="nb mf it bd mg nv nw dn mk nx ny dp mo lq nz oa mq lu ob oc ms ly od oe mu iz bi translated">将相关性可视化</h2><pre class="ks kt ku kv gt mw mx my mz aw na bi"><span id="66fa" class="nb mf it mx b gy nc nd l ne nf">import seaborn as sb<br/>sb.heatmap(corr, xticklabels=corr.columns, yticklabels=corr.columns,<br/> cmap=’RdBu_r’, annot=True, linewidth=0.5)</span></pre><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div class="gh gi om"><img src="../Images/3e184242a553635bbabc9799d5921137.png" data-original-src="https://miro.medium.com/v2/resize:fit:914/format:webp/1*2y-NxqL8KxSzinAHpStr2A.png"/></div><figcaption class="ld le gj gh gi lf lg bd b be z dk translated">相关热图</figcaption></figure><p id="09cd" class="pw-post-body-paragraph lh li it lj b lk ll kd lm ln lo kg lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">深栗色显示高度相关的特征。</p><h1 id="b401" class="me mf it bd mg mh mi mj mk ml mm mn mo ki mp kj mq kl mr km ms ko mt kp mu mv bi translated">4.数据集准备</h1><pre class="ks kt ku kv gt mw mx my mz aw na bi"><span id="35b5" class="nb mf it mx b gy nc nd l ne nf">df=ship_df[[‘Age’, ‘Tonnage’, ‘passengers’, ‘length’,<br/> ‘cabins’, ‘passenger_density’, ‘crew’]]</span><span id="bea5" class="nb mf it mx b gy ng nd l ne nf">X = df.iloc[:,df.columns !=’crew’]<br/>Y = df.iloc[:, 6]</span><span id="cfc3" class="nb mf it mx b gy ng nd l ne nf">X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.15, random_state= 0)</span><span id="9cfe" class="nb mf it mx b gy ng nd l ne nf">print(X_train.shape, X_test.shape, Y_train.shape, Y_test.shape)<br/>#Output: (134, 6) (24, 6) (134,) (24,)</span></pre><h1 id="ae0c" class="me mf it bd mg mh mi mj mk ml mm mn mo ki mp kj mq kl mr km ms ko mt kp mu mv bi translated">5.特征缩放</h1><p id="b99a" class="pw-post-body-paragraph lh li it lj b lk og kd lm ln oh kg lp lq oi ls lt lu oj lw lx ly ok ma mb mc im bi translated">这是一种标准化独立输入特征的技术。进行特征缩放是为了避免一个特征优于另一个特征，并且有助于防止预测结果。</p><pre class="ks kt ku kv gt mw mx my mz aw na bi"><span id="fccb" class="nb mf it mx b gy nc nd l ne nf">from sklearn.preprocessing import StandardScaler<br/>sc = StandardScaler()<br/>X_train = sc.fit_transform(X_train)<br/>X_test = sc.fit_transform(X_test)</span></pre><h1 id="8975" class="me mf it bd mg mh mi mj mk ml mm mn mo ki mp kj mq kl mr km ms ko mt kp mu mv bi translated">6.神经网络构建和模型训练:</h1><pre class="ks kt ku kv gt mw mx my mz aw na bi"><span id="a450" class="nb mf it mx b gy nc nd l ne nf">#create linear regression model object<br/>lr_model=Sequential()</span><span id="df23" class="nb mf it mx b gy ng nd l ne nf"># Add the first hidden layer<br/>lr_model.add(Dense(output_dim=16, activation='relu',input_dim=6))</span><span id="e87c" class="nb mf it mx b gy ng nd l ne nf"># Adding the second hidden layer<br/>lr_model.add(Dense(output_dim=16, activation='relu'))</span><span id="fe08" class="nb mf it mx b gy ng nd l ne nf"># Adding the output layer<br/>lr_model.add(Dense(output_dim=1, activation='relu'))</span></pre><p id="9455" class="pw-post-body-paragraph lh li it lj b lk ll kd lm ln lo kg lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated"><strong class="lj jd"> input_dim </strong>指输入/独立特征的数量。</p><p id="f512" class="pw-post-body-paragraph lh li it lj b lk ll kd lm ln lo kg lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated"><strong class="lj jd"> activation_function </strong>:激活函数通过计算加权和并进一步加上偏置来决定是否激活一个神经元。激活功能的目的是<strong class="lj jd">将非线性</strong>引入神经元的输出。</p><pre class="ks kt ku kv gt mw mx my mz aw na bi"><span id="1663" class="nb mf it mx b gy nc nd l ne nf">lr_model.compile(loss=’mean_squared_error’, optimizer=’sgd’, metrics = [‘mae’,’accuracy’])</span><span id="2a6d" class="nb mf it mx b gy ng nd l ne nf">#Model Training</span><span id="2df1" class="nb mf it mx b gy ng nd l ne nf">#Model is trained over 100 Epochs<br/>lrmodel_hist=lr_model.fit(X_train, Y_train ,validation_split=0.33, batch_size = 10, nb_epoch = 100)</span></pre><p id="6d49" class="pw-post-body-paragraph lh li it lj b lk ll kd lm ln lo kg lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">一个<strong class="lj jd">时期</strong>是前向和后向传播的组合，对于每一步，在优化器和学习率变量的帮助下调整权重，以最小化损失函数。</p><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi on"><img src="../Images/4ec24d2e22db6933048b9135dc0a7116.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*3H-abMeToSJ3MoZbKhjOdA.png"/></div></div><figcaption class="ld le gj gh gi lf lg bd b be z dk translated">模特培训</figcaption></figure><p id="b8ff" class="pw-post-body-paragraph lh li it lj b lk ll kd lm ln lo kg lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">正如我们所看到的，在第100个<strong class="lj jd">纪元</strong>时，损耗被最小化了，精确度也提高了。</p><pre class="ks kt ku kv gt mw mx my mz aw na bi"><span id="5eb8" class="nb mf it mx b gy nc nd l ne nf">#evaluate model<br/>lr_model.evaluate(X_test,Y_test)[1]</span><span id="f07c" class="nb mf it mx b gy ng nd l ne nf">#output: 0.9130942225456238</span><span id="6cf7" class="nb mf it mx b gy ng nd l ne nf">#making predictions from trained model<br/>y_pred = lr_model.predict(X_test)</span></pre><h2 id="fc1f" class="nb mf it bd mg nv nw dn mk nx ny dp mo lq nz oa mq lu ob oc ms ly od oe mu iz bi translated">绘制实际值与预测值:</h2><pre class="ks kt ku kv gt mw mx my mz aw na bi"><span id="bf7c" class="nb mf it mx b gy nc nd l ne nf">fig, ax = plt.subplots()<br/>ax.scatter(Y_test, y_pred)<br/>plt.style.use(‘ggplot’)<br/>ax.plot([Y_test.min(), Y_test.max()], [Y_test.min(), Y_test.max()], ‘k — ‘, lw=4)<br/>ax.set_xlabel(‘Actual’)<br/>ax.set_ylabel(‘Predicted’)<br/>plt.show()</span></pre><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div class="gh gi oo"><img src="../Images/a6d97fc5265c520b3648b91694d60e54.png" data-original-src="https://miro.medium.com/v2/resize:fit:832/format:webp/1*MLGONAJaT5ulbMMbsRw-oA.png"/></div><figcaption class="ld le gj gh gi lf lg bd b be z dk translated">实际与预测</figcaption></figure><h2 id="4910" class="nb mf it bd mg nv nw dn mk nx ny dp mo lq nz oa mq lu ob oc ms ly od oe mu iz bi translated">RMSE(均方根误差)</h2><p id="5704" class="pw-post-body-paragraph lh li it lj b lk og kd lm ln oh kg lp lq oi ls lt lu oj lw lx ly ok ma mb mc im bi translated">均方根误差是残差的标准偏差，它衡量数据点与回归的距离。或者简单地说，数据点在最佳拟合线周围的集中程度。</p><pre class="ks kt ku kv gt mw mx my mz aw na bi"><span id="3d98" class="nb mf it mx b gy nc nd l ne nf">import numpy as np<br/>print('Root Mean Squared Error:', np.sqrt(mean_squared_error(Y_test, y_pred)))</span><span id="662a" class="nb mf it mx b gy ng nd l ne nf">#output: Root Mean Squared Error: 0.9909468213027769</span></pre><p id="8b26" class="pw-post-body-paragraph lh li it lj b lk ll kd lm ln lo kg lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated"><strong class="lj jd"> R2或r平方误差</strong></p><p id="5d56" class="pw-post-body-paragraph lh li it lj b lk ll kd lm ln lo kg lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">r2或R2分数在0到100%之间变化。</p><p id="4379" class="pw-post-body-paragraph lh li it lj b lk ll kd lm ln lo kg lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated"><strong class="lj jd">R2得分的数学公式:(y_test[i] — y_pred[i]) **2 </strong></p><pre class="ks kt ku kv gt mw mx my mz aw na bi"><span id="0662" class="nb mf it mx b gy nc nd l ne nf">print(‘R2: ‘, r2_score(Y_test, y_pred))<br/>#output R2:  0.8577843971939547</span></pre><p id="fe00" class="pw-post-body-paragraph lh li it lj b lk ll kd lm ln lo kg lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">我们的模型看起来很棒，有着惊人的统计数据。</p><h1 id="3ce8" class="me mf it bd mg mh mi mj mk ml mm mn mo ki mp kj mq kl mr km ms ko mt kp mu mv bi translated">总结:</h1><p id="0267" class="pw-post-body-paragraph lh li it lj b lk og kd lm ln oh kg lp lq oi ls lt lu oj lw lx ly ok ma mb mc im bi translated">人工神经网络架构。</p><p id="efd8" class="pw-post-body-paragraph lh li it lj b lk ll kd lm ln lo kg lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">Keras库实现人工神经网络。</p><p id="e21f" class="pw-post-body-paragraph lh li it lj b lk ll kd lm ln lo kg lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">数据争论/管理</p><p id="4936" class="pw-post-body-paragraph lh li it lj b lk ll kd lm ln lo kg lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">神经网络层构建</p><p id="a0f1" class="pw-post-body-paragraph lh li it lj b lk ll kd lm ln lo kg lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">激活功能</p><p id="3e8f" class="pw-post-body-paragraph lh li it lj b lk ll kd lm ln lo kg lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">向前和向后传播，损失函数</p><p id="3320" class="pw-post-body-paragraph lh li it lj b lk ll kd lm ln lo kg lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">RMSE和R2误差</p><p id="b0d5" class="pw-post-body-paragraph lh li it lj b lk ll kd lm ln lo kg lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">模型精度</p><p id="1e24" class="pw-post-body-paragraph lh li it lj b lk ll kd lm ln lo kg lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">感谢大家阅读我的文章。如果您喜欢我的内容和解释，请在Medium上关注我并分享您的反馈，这将始终帮助我们所有人提高我们的知识。</p><p id="530b" class="pw-post-body-paragraph lh li it lj b lk ll kd lm ln lo kg lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">谢谢</p><p id="cc60" class="pw-post-body-paragraph lh li it lj b lk ll kd lm ln lo kg lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">Vivek Chaudhary</p></div></div>    
</body>
</html>