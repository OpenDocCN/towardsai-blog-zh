<html>
<head>
<title>NLP News Cypher | 08.09.20</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">NLP新闻密码| 08.09.20</h1>
<blockquote>原文：<a href="https://pub.towardsai.net/nlp-news-cypher-08-09-20-366ccffc3c83?source=collection_archive---------2-----------------------#2020-08-09">https://pub.towardsai.net/nlp-news-cypher-08-09-20-366ccffc3c83?source=collection_archive---------2-----------------------#2020-08-09</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><figure class="ip iq gp gr ir is gh gi paragraph-image"><div role="button" tabindex="0" class="it iu di iv bf iw"><div class="gh gi io"><img src="../Images/bb5a8a3efc18cf374b41f306227699aa.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*_mGADUJCPGuKbu3e"/></div></div><figcaption class="iz ja gj gh gi jb jc bd b be z dk translated">库纳尔·辛德在<a class="ae jd" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上拍摄的照片</figcaption></figure><h2 id="98b8" class="je jf jg bd b dl jh ji jj jk jl jm dk jn translated" aria-label="kicker paragraph">自然语言处理每周时事通讯</h2><div class=""/><div class=""><h2 id="6334" class="pw-subtitle-paragraph km jp jg bd b kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld dk translated">伪造</h2></div></div><div class="ab cl le lf hu lg" role="separator"><span class="lh bw bk li lj lk"/><span class="lh bw bk li lj lk"/><span class="lh bw bk li lj"/></div><div class="ij ik il im in"><p id="946f" class="pw-post-body-paragraph ll lm jg ln b lo lp kq lq lr ls kt lt lu lv lw lx ly lz ma mb mc md me mf mg ij bi mh translated">我们到了吗？NLP是什么状态？我们到了我们想去的地方了吗？GPT-3炒作很酷，但需要微调，以接近生产就绪。那些图表在哪里？下游任务在企业中是如何使用的？稀疏网络呢？为什么那么多AI项目失败？深度学习和语义解析，我们还关心信息提取吗？变形金刚是圣杯吗？莱克斯·弗里德曼(和他的深色西装)在哪里？那些常识推理演示在哪里？</p><p id="dedd" class="pw-post-body-paragraph ll lm jg ln b lo lp kq lq lr ls kt lt lu lv lw lx ly lz ma mb mc md me mf mg ij bi translated">那么…我们在哪里…</p><p id="fe5b" class="pw-post-body-paragraph ll lm jg ln b lo lp kq lq lr ls kt lt lu lv lw lx ly lz ma mb mc md me mf mg ij bi translated">埃隆？</p><figure class="mq mr ms mt gt is"><div class="bz fp l di"><div class="mu mv l"/></div></figure><p id="3fd3" class="pw-post-body-paragraph ll lm jg ln b lo lp kq lq lr ls kt lt lu lv lw lx ly lz ma mb mc md me mf mg ij bi translated">做大，进入国家安全局…从这里开始👇</p><div class="ip iq gp gr ir mw"><a href="https://cryptohack.org/" rel="noopener  ugc nofollow" target="_blank"><div class="mx ab fo"><div class="my ab mz cl cj na"><h2 class="bd jq gy z fp nb fr fs nc fu fw jp bi translated">CryptoHack - Home</h2><div class="nd l"><h3 class="bd b gy z fp nb fr fs nc fu fw dk translated">一个有趣的平台，通过解决挑战和破解不安全的代码来学习密码学。你能到达顶端吗…</h3></div><div class="ne l"><p class="bd b dl z fp nb fr fs nc fu fw dk translated">cryptohack.org</p></div></div><div class="nf l"><div class="ng l nh ni nj nf nk ix mw"/></div></div></a></div><p id="e27e" class="pw-post-body-paragraph ll lm jg ln b lo lp kq lq lr ls kt lt lu lv lw lx ly lz ma mb mc md me mf mg ij bi translated">NLP索引的索引:</p><div class="ip iq gp gr ir mw"><a href="https://github.com/ivan-bilan/The-NLP-Pandect" rel="noopener  ugc nofollow" target="_blank"><div class="mx ab fo"><div class="my ab mz cl cj na"><h2 class="bd jq gy z fp nb fr fs nc fu fw jp bi translated">伊凡-比兰/The-NLP-总论</h2><div class="nd l"><h3 class="bd b gy z fp nb fr fs nc fu fw dk translated">这本百科全书(πανδέκτης在古希腊语中是百科全书的意思)旨在帮助你找到几乎所有与……相关的东西</h3></div><div class="ne l"><p class="bd b dl z fp nb fr fs nc fu fw dk translated">github.com</p></div></div><div class="nf l"><div class="nl l nh ni nj nf nk ix mw"/></div></div></a></div></div><div class="ab cl le lf hu lg" role="separator"><span class="lh bw bk li lj lk"/><span class="lh bw bk li lj lk"/><span class="lh bw bk li lj"/></div><div class="ij ik il im in"><h1 id="0e89" class="nm nn jg bd no np nq nr ns nt nu nv nw kv nx kw ny ky nz kz oa lb ob lc oc od bi translated">本周</h1><blockquote class="oe of og"><p id="35ec" class="ll lm oh ln b lo lp kq lq lr ls kt lt oi lv lw lx oj lz ma mb ok md me mf mg ij bi translated">欢乐变形金刚</p><p id="ed1e" class="ll lm oh ln b lo lp kq lq lr ls kt lt oi lv lw lx oj lz ma mb ok md me mf mg ij bi translated">超越英语的NLP</p><p id="784f" class="ll lm oh ln b lo lp kq lq lr ls kt lt oi lv lw lx oj lz ma mb ok md me mf mg ij bi translated">节更新</p><p id="efb0" class="ll lm oh ln b lo lp kq lq lr ls kt lt oi lv lw lx oj lz ma mb ok md me mf mg ij bi translated">PyKEEN:知识图嵌入库</p><p id="dcaa" class="ll lm oh ln b lo lp kq lq lr ls kt lt oi lv lw lx oj lz ma mb ok md me mf mg ij bi translated">大鸟</p><p id="1f39" class="ll lm oh ln b lo lp kq lq lr ls kt lt oi lv lw lx oj lz ma mb ok md me mf mg ij bi translated">ONNXT5</p><p id="f65a" class="ll lm oh ln b lo lp kq lq lr ls kt lt oi lv lw lx oj lz ma mb ok md me mf mg ij bi translated">风筝自动完成</p><p id="67b7" class="ll lm oh ln b lo lp kq lq lr ls kt lt oi lv lw lx oj lz ma mb ok md me mf mg ij bi translated">本周数据集:SPLASH</p></blockquote></div><div class="ab cl le lf hu lg" role="separator"><span class="lh bw bk li lj lk"/><span class="lh bw bk li lj lk"/><span class="lh bw bk li lj"/></div><div class="ij ik il im in"><h1 id="6d27" class="nm nn jg bd no np nq nr ns nt nu nv nw kv nx kw ny ky nz kz oa lb ob lc oc od bi translated">欢乐变形金刚</h1><p id="d23b" class="pw-post-body-paragraph ll lm jg ln b lo ol kq lq lr om kt lt lu on lw lx ly oo ma mb mc op me mf mg ij bi translated">DeLighT transformer库让我们对NLP中最流行的模型——transformer有了新的认识。新的架构除了使模型更深入之外，还有助于减少参数大小。这意味着这种新的架构可以与传统的变压器架构相匹配或实现更好的结果，但要轻得多。目前，该架构可以帮助语言建模和机器翻译。据作者称，更多的任务正在进行中。</p><p id="300a" class="pw-post-body-paragraph ll lm jg ln b lo lp kq lq lr ls kt lt lu lv lw lx ly lz ma mb mc md me mf mg ij bi translated"><strong class="ln jq">论文</strong>:<a class="ae jd" href="https://arxiv.org/pdf/2008.00623v1.pdf" rel="noopener ugc nofollow" target="_blank">https://arxiv.org/pdf/2008.00623v1.pdf</a></p><p id="618f" class="pw-post-body-paragraph ll lm jg ln b lo lp kq lq lr ls kt lt lu lv lw lx ly lz ma mb mc md me mf mg ij bi translated"><strong class="ln jq"> GitHub </strong>:</p><div class="ip iq gp gr ir mw"><a href="https://github.com/sacmehta/delight" rel="noopener  ugc nofollow" target="_blank"><div class="mx ab fo"><div class="my ab mz cl cj na"><h2 class="bd jq gy z fp nb fr fs nc fu fw jp bi translated">sacmehta/delight</h2><div class="nd l"><h3 class="bd b gy z fp nb fr fs nc fu fw dk translated">这个库包含了我们构建高效序列模型的源代码:定义(ICLR 20)和…</h3></div><div class="ne l"><p class="bd b dl z fp nb fr fs nc fu fw dk translated">github.com</p></div></div><div class="nf l"><div class="oq l nh ni nj nf nk ix mw"/></div></div></a></div><h1 id="d26e" class="nm nn jg bd no np or nr ns nt os nv nw kv ot kw ny ky ou kz oa lb ov lc oc od bi translated">超越英语的NLP</h1><p id="6101" class="pw-post-body-paragraph ll lm jg ln b lo ol kq lq lr om kt lt lu on lw lx ly oo ma mb mc op me mf mg ij bi translated">Sebastian Ruder对NLP的状态发表了意见，特别是，我们对低资源语言的限制是我们应该关注的一个更大的问题。他的博客文章讨论了缺乏这些数据集从社会到认知障碍的不同影响领域。以下是博客中关于你能做些什么的要点。</p><h2 id="e314" class="ow nn jg bd no ox oy dn ns oz pa dp nw lu pb pc ny ly pd pe oa mc pf pg oc jm bi translated">你能做什么</h2><p id="6cf4" class="pw-post-body-paragraph ll lm jg ln b lo ol kq lq lr om kt lt lu on lw lx ly oo ma mb mc op me mf mg ij bi translated"><strong class="ln jq">"数据集</strong>如果你创建一个新的数据集，保留一半的注释预算，用于用另一种语言创建相同大小的数据集。</p><p id="bf8e" class="pw-post-body-paragraph ll lm jg ln b lo lp kq lq lr ls kt lt lu lv lw lx ly lz ma mb mc md me mf mg ij bi translated"><strong class="ln jq">评估</strong>如果你对某个特定的任务感兴趣，可以考虑用不同的语言在相同的任务上评估你的模型。对于一些任务的概述，请参见<a class="ae jd" href="http://nlpprogress.com/" rel="noopener ugc nofollow" target="_blank"> NLP进度</a>或我们的<a class="ae jd" href="https://sites.research.google/xtreme" rel="noopener ugc nofollow" target="_blank"> XTREME基准</a>。</p><p id="4abd" class="pw-post-body-paragraph ll lm jg ln b lo lp kq lq lr ls kt lt lu lv lw lx ly lz ma mb mc md me mf mg ij bi translated"><strong class="ln jq">本德法则</strong> <a class="ae jd" href="https://thegradient.pub/the-benderrule-on-naming-the-languages-we-study-and-why-it-matters/" rel="noopener ugc nofollow" target="_blank">陈述你正在使用的语言</a>。</p><p id="8fb8" class="pw-post-body-paragraph ll lm jg ln b lo lp kq lq lr ls kt lt lu lv lw lx ly lz ma mb mc md me mf mg ij bi translated"><strong class="ln jq">假设</strong>明确了你的模型使用的信号和它做出的假设。考虑哪些是你正在学习的语言特有的，哪些可能更普遍。</p><p id="4b8d" class="pw-post-body-paragraph ll lm jg ln b lo lp kq lq lr ls kt lt lu lv lw lx ly lz ma mb mc md me mf mg ij bi translated"><strong class="ln jq">语言多样性</strong>估计你正在学习的语言样本的语言多样性(<a class="ae jd" href="https://arxiv.org/abs/2005.00333" rel="noopener ugc nofollow" target="_blank"> Ponti et al .，2020 </a>)。</p><p id="f98d" class="pw-post-body-paragraph ll lm jg ln b lo lp kq lq lr ls kt lt lu lv lw lx ly lz ma mb mc md me mf mg ij bi translated">研究解决低资源语言挑战的方法。在下一篇帖子中，我将概述多语言NLP中有趣的研究方向和机会。"</p><p id="f138" class="pw-post-body-paragraph ll lm jg ln b lo lp kq lq lr ls kt lt lu lv lw lx ly lz ma mb mc md me mf mg ij bi translated"><strong class="ln jq">博客</strong>:</p><div class="ip iq gp gr ir mw"><a href="https://ruder.io/nlp-beyond-english/" rel="noopener  ugc nofollow" target="_blank"><div class="mx ab fo"><div class="my ab mz cl cj na"><h2 class="bd jq gy z fp nb fr fs nc fu fw jp bi translated">为什么你应该做超越英语的自然语言处理</h2><div class="nd l"><h3 class="bd b gy z fp nb fr fs nc fu fw dk translated">自然语言处理(NLP)研究主要集中在开发适用于英语的方法上</h3></div><div class="ne l"><p class="bd b dl z fp nb fr fs nc fu fw dk translated">ruder.io</p></div></div><div class="nf l"><div class="ph l nh ni nj nf nk ix mw"/></div></div></a></div><h1 id="3ca2" class="nm nn jg bd no np or nr ns nt os nv nw kv ot kw ny ky ou kz oa lb ov lc oc od bi translated">节更新</h1><p id="6c41" class="pw-post-body-paragraph ll lm jg ln b lo ol kq lq lr om kt lt lu on lw lx ly oo ma mb mc op me mf mg ij bi translated">斯坦福大学的Stanza更新了其图书馆，增加了对医学/临床领域的支持，包括:</p><ol class=""><li id="88ba" class="pi pj jg ln b lo lp lr ls lu pk ly pl mc pm mg pn po pp pq bi translated">生物管道和NER模型，专门处理生物医学文献文本；</li><li id="7c94" class="pi pj jg ln b lo pr lr ps lu pt ly pu mc pv mg pn po pp pq bi translated">专门处理临床文本的临床管道和NER模型。</li></ol><p id="ee5e" class="pw-post-body-paragraph ll lm jg ln b lo lp kq lq lr ls kt lt lu lv lw lx ly lz ma mb mc md me mf mg ij bi translated">演示:<a class="ae jd" href="http://stanza.run/bio" rel="noopener ugc nofollow" target="_blank">http://stanza.run/bio</a></p><figure class="mq mr ms mt gt is"><div class="bz fp l di"><div class="mu mv l"/></div></figure><h1 id="aa6b" class="nm nn jg bd no np or nr ns nt os nv nw kv ot kw ny ky ou kz oa lb ov lc oc od bi translated">PyKEEN:知识图嵌入库</h1><p id="27d5" class="pw-post-body-paragraph ll lm jg ln b lo ol kq lq lr om kt lt lu on lw lx ly oo ma mb mc op me mf mg ij bi translated">这个新的图形库包含了模型和数据集。它附带了一个方便的管道API，真正简化了模型和数据集的初始化。目前有13个数据集和23个模型可供使用。</p><p id="7f27" class="pw-post-body-paragraph ll lm jg ln b lo lp kq lq lr ls kt lt lu lv lw lx ly lz ma mb mc md me mf mg ij bi translated">这里有一个简单的例子:</p><pre class="mq mr ms mt gt pw px py pz aw qa bi"><span id="e9e0" class="ow nn jg px b gy qb qc l qd qe">from pykeen.pipeline import pipeline<br/>result = pipeline(<br/>    model='TransE',<br/>    dataset='nations',<br/>)</span></pre><p id="87ab" class="pw-post-body-paragraph ll lm jg ln b lo lp kq lq lr ls kt lt lu lv lw lx ly lz ma mb mc md me mf mg ij bi translated"><strong class="ln jq"> GitHub </strong>:</p><div class="ip iq gp gr ir mw"><a href="https://github.com/pykeen/pykeen?utm_campaign=Graph%20Machine%20Learning%20News&amp;utm_medium=email&amp;utm_source=Revue%20newsletter" rel="noopener  ugc nofollow" target="_blank"><div class="mx ab fo"><div class="my ab mz cl cj na"><h2 class="bd jq gy z fp nb fr fs nc fu fw jp bi translated">皮肯/皮肯</h2><div class="nd l"><h3 class="bd b gy z fp nb fr fs nc fu fw dk translated">py keen(Python Knowl Edge embedding in GS)是一个Python包，旨在训练和评估知识图嵌入…</h3></div><div class="ne l"><p class="bd b dl z fp nb fr fs nc fu fw dk translated">github.com</p></div></div><div class="nf l"><div class="qf l nh ni nj nf nk ix mw"/></div></div></a></div><p id="6dd5" class="pw-post-body-paragraph ll lm jg ln b lo lp kq lq lr ls kt lt lu lv lw lx ly lz ma mb mc md me mf mg ij bi translated"><strong class="ln jq">论文</strong>:<a class="ae jd" href="https://arxiv.org/pdf/2007.14175.pdf" rel="noopener ugc nofollow" target="_blank">https://arxiv.org/pdf/2007.14175.pdf</a></p><h1 id="5f39" class="nm nn jg bd no np or nr ns nt os nv nw kv ot kw ny ky ou kz oa lb ov lc oc od bi translated">大鸟</h1><p id="1ba7" class="pw-post-body-paragraph ll lm jg ln b lo ol kq lq lr om kt lt lu on lw lx ly oo ma mb mc op me mf mg ij bi translated">我们都知道伯特512令牌限制的硬停。而这种烦恼正是大鸟被创造出来的主要原因之一。</p><p id="69fc" class="pw-post-body-paragraph ll lm jg ln b lo lp kq lq lr ls kt lt lu lv lw lx ly lz ma mb mc md me mf mg ij bi translated">这种新设计有助于将性能“扩展到标准硬件(16GB内存)上更长的序列长度(8倍)以适应大尺寸型号。”🧐</p><p id="7b06" class="pw-post-body-paragraph ll lm jg ln b lo lp kq lq lr ls kt lt lu lv lw lx ly lz ma mb mc md me mf mg ij bi translated">BigBird的酷之处在于，它利用了一个稀疏注意力框架，可以用更少的资源做更多的事情。也就是说，它的内存开销更少(即使与其他长上下文模型如Longformer相比也是如此)。</p><p id="1271" class="pw-post-body-paragraph ll lm jg ln b lo lp kq lq lr ls kt lt lu lv lw lx ly lz ma mb mc md me mf mg ij bi translated">本文展示了它在仅有编码器和编码器-解码器两种情况下的性能。</p><p id="2ced" class="pw-post-body-paragraph ll lm jg ln b lo lp kq lq lr ls kt lt lu lv lw lx ly lz ma mb mc md me mf mg ij bi translated">在性能方面，它提供了问答和长文档摘要方面的SOTA。</p><figure class="mq mr ms mt gt is"><div class="bz fp l di"><div class="qg mv l"/></div><figcaption class="iz ja gj gh gi jb jc bd b be z dk translated"><a class="ae jd" href="https://arxiv.org/pdf/2007.14062.pdf" rel="noopener ugc nofollow" target="_blank">链接</a></figcaption></figure><h1 id="cb8e" class="nm nn jg bd no np or nr ns nt os nv nw kv ot kw ny ky ou kz oa lb ov lc oc od bi translated">ONNXT5</h1><p id="c1a5" class="pw-post-body-paragraph ll lm jg ln b lo ol kq lq lr om kt lt lu on lw lx ly oo ma mb mc op me mf mg ij bi translated">有人帮助用ONNX桥接T5模型(为了推理加速)😎。只要保持相对较短的上下文长度(大约在&lt;500 words).</p><p id="ef9b" class="pw-post-body-paragraph ll lm jg ln b lo lp kq lq lr ls kt lt lu lv lw lx ly lz ma mb mc md me mf mg ij bi translated"><strong class="ln jq"> GitHub </strong>左右)，你可以获得比PyTorch快4倍的速度提升:</p><div class="ip iq gp gr ir mw"><a href="https://github.com/abelriboulot/onnxt5" rel="noopener  ugc nofollow" target="_blank"><div class="mx ab fo"><div class="my ab mz cl cj na"><h2 class="bd jq gy z fp nb fr fs nc fu fw jp bi translated">abelriboulot/onnxt5</h2><div class="nd l"><h3 class="bd b gy z fp nb fr fs nc fu fw dk translated">使用在ONNX中实现的T5版本，以极快的速度进行摘要、翻译、问答、文本生成等操作。这个…</h3></div><div class="ne l"><p class="bd b dl z fp nb fr fs nc fu fw dk translated">github.com</p></div></div><div class="nf l"><div class="qh l nh ni nj nf nk ix mw"/></div></div></a></div><h1 id="5f00" class="nm nn jg bd no np or nr ns nt os nv nw kv ot kw ny ky ou kz oa lb ov lc oc od bi translated">风筝自动完成</h1><p id="389d" class="pw-post-body-paragraph ll lm jg ln b lo ol kq lq lr om kt lt lu on lw lx ly oo ma mb mc op me mf mg ij bi translated">对于所有的Jupyter笔记本爱好者，风筝代码自动完成现在得到支持！</p><div class="ip iq gp gr ir mw"><a href="https://venturebeat.com/2020/08/04/kite-brings-its-ai-powered-code-completions-to-jupyter-notebooks/" rel="noopener  ugc nofollow" target="_blank"><div class="mx ab fo"><div class="my ab mz cl cj na"><h2 class="bd jq gy z fp nb fr fs nc fu fw jp bi translated">Kite将其人工智能驱动的代码完成功能引入Jupyter笔记本电脑</h2><div class="nd l"><h3 class="bd b gy z fp nb fr fs nc fu fw dk translated">为开发者实时提供代码片段建议的Kite，今天首次与JupyterLab和support……</h3></div><div class="ne l"><p class="bd b dl z fp nb fr fs nc fu fw dk translated">venturebeat.com</p></div></div><div class="nf l"><div class="qi l nh ni nj nf nk ix mw"/></div></div></a></div><figure class="mq mr ms mt gt is gh gi paragraph-image"><div role="button" tabindex="0" class="it iu di iv bf iw"><div class="gh gi qj"><img src="../Images/b914d0e216b6dab0604217313008f57d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*Gj5A3D1omwm9hTFn"/></div></div><figcaption class="iz ja gj gh gi jb jc bd b be z dk translated">解密的</figcaption></figure><h1 id="c1b0" class="nm nn jg bd no np or nr ns nt os nv nw kv ot kw ny ky ou kz oa lb ov lc oc od bi translated">本周数据集:SPLASH</h1><p id="1db4" class="pw-post-body-paragraph ll lm jg ln b lo ol kq lq lr om kt lt lu on lw lx ly oo ma mb mc op me mf mg ij bi translated"><strong class="ln jq">什么事？</strong></p><p id="978b" class="pw-post-body-paragraph ll lm jg ln b lo lp kq lq lr ls kt lt lu lv lw lx ly lz ma mb mc md me mf mg ij bi translated">SPLASH是一个数据集，用于带有自然语言反馈的语义解析校正任务。</p><p id="5cbf" class="pw-post-body-paragraph ll lm jg ln b lo lp kq lq lr ls kt lt lu lv lw lx ly lz ma mb mc md me mf mg ij bi translated"><strong class="ln jq">行动中的任务</strong></p><figure class="mq mr ms mt gt is gh gi paragraph-image"><div class="gh gi qk"><img src="../Images/f6901d990267fda5ec2f30e817b7460d.png" data-original-src="https://miro.medium.com/v2/resize:fit:860/format:webp/1*TZd5HZ0S0KTObLRLxWl2Fw.png"/></div></figure><p id="4151" class="pw-post-body-paragraph ll lm jg ln b lo lp kq lq lr ls kt lt lu lv lw lx ly lz ma mb mc md me mf mg ij bi translated"><strong class="ln jq">在哪里？</strong></p><p id="0ebd" class="pw-post-body-paragraph ll lm jg ln b lo lp kq lq lr ls kt lt lu lv lw lx ly lz ma mb mc md me mf mg ij bi translated">(数据集/代码还没掉，注意)</p><div class="ip iq gp gr ir mw"><a href="https://github.com/MSR-LIT/Splash" rel="noopener  ugc nofollow" target="_blank"><div class="mx ab fo"><div class="my ab mz cl cj na"><h2 class="bd jq gy z fp nb fr fs nc fu fw jp bi translated">MSR-点燃/飞溅</h2><div class="nd l"><h3 class="bd b gy z fp nb fr fs nc fu fw dk translated">SPLASH是用于带有自然语言反馈的语义解析校正任务的数据集。任务、数据集以及…</h3></div><div class="ne l"><p class="bd b dl z fp nb fr fs nc fu fw dk translated">github.com</p></div></div><div class="nf l"><div class="ql l nh ni nj nf nk ix mw"/></div></div></a></div></div><div class="ab cl le lf hu lg" role="separator"><span class="lh bw bk li lj lk"/><span class="lh bw bk li lj lk"/><span class="lh bw bk li lj"/></div><div class="ij ik il im in"><blockquote class="qm"><p id="c688" class="qn qo jg bd qp qq qr qs qt qu qv mg dk translated"><em class="qw">每周日，我们都会对来自全球研究人员的NLP新闻和代码进行一次每周综述。</em></p><p id="aeb0" class="qn qo jg bd qp qq qr qs qt qu qv mg dk translated"><em class="qw">如果您喜欢这篇文章，请帮助我们并与朋友分享！</em></p><p id="bd2d" class="qn qo jg bd qp qq qr qs qt qu qv mg dk translated"><em class="qw">完整报道，关注我们的推特:</em><a class="ae jd" href="http://twitter.com/Quantum_Stat" rel="noopener ugc nofollow" target="_blank"><em class="qw">@ Quantum _ Stat</em></a></p></blockquote><figure class="qy qz ra rb rc is gh gi paragraph-image"><div class="gh gi qx"><img src="../Images/565f30c79e09ddf34c713bcc7ad7ad33.png" data-original-src="https://miro.medium.com/v2/resize:fit:108/0*KMJD-TIhdcS2iqal"/></div><figcaption class="iz ja gj gh gi jb jc bd b be z dk translated"><a class="ae jd" href="http://www.quantumstat.com/" rel="noopener ugc nofollow" target="_blank">www.quantumstat.com</a></figcaption></figure></div></div>    
</body>
</html>