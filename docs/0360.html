<html>
<head>
<title>Let’s Flip Some Coins, or How Randomness Can Help with Proving Theorems</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">让我们掷硬币，或者随机性如何帮助证明定理</h1>
<blockquote>原文：<a href="https://pub.towardsai.net/lets-flip-some-coins-or-how-randomness-can-help-with-proving-theorems-bbc789ab7d6a?source=collection_archive---------1-----------------------#2020-03-15">https://pub.towardsai.net/lets-flip-some-coins-or-how-randomness-can-help-with-proving-theorems-bbc789ab7d6a?source=collection_archive---------1-----------------------#2020-03-15</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><h2 id="b382" class="ir is it bd b dl iu iv iw ix iy iz dk ja translated" aria-label="kicker paragraph"><a class="ae ep" href="https://towardsai.net/p/category/mathematics" rel="noopener ugc nofollow" target="_blank">数学</a>，<a class="ae ep" href="https://towardsai.net/p/category/probability" rel="noopener ugc nofollow" target="_blank">概率</a></h2><div class=""/><blockquote class="jz ka kb"><p id="690f" class="kc kd ke kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la im bi translated">本文介绍了在无向切割中切割的概率方法。虽然我们会深入证明的细节，但需要最少的数学背景。</p></blockquote><h1 id="880c" class="lb lc it bd ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly bi translated">介绍</h1><p id="55d3" class="pw-post-body-paragraph kc kd it kf b kg lz ki kj kk ma km kn mb mc kq kr md me ku kv mf mg ky kz la im bi translated">假设我们有一个无向图 <em class="ke"> G = (V，E) </em>，其中顶点集<em class="ke"> V </em>的大小为<em class="ke"> N </em>，边集<em class="ke"> E </em>的大小为<em class="ke"> M </em>。这种图的一个<a class="ae mh" href="https://en.wikipedia.org/wiki/Cut_(graph_theory)" rel="noopener ugc nofollow" target="_blank">割</a>是将<em class="ke"> V </em>分割成两组<em class="ke"> A </em>和<em class="ke"> B </em>，割的大小是被割的边数，即一个端点在<em class="ke"> A </em>和一个端点在<em class="ke"> B </em>的边数。为了理解这个定义，这里有一个简单的图的例子，它有5个顶点和6条边，以及一个相应的尺寸为5的切割。</p><figure class="mj mk ml mm gt mn gh gi paragraph-image"><div class="gh gi mi"><img src="../Images/dd55946c5f406a1acc6ff00a58544faa.png" data-original-src="https://miro.medium.com/v2/resize:fit:1052/format:webp/1*M32KAg4_n-KrDIYZHNTPyg.png"/></div><figcaption class="mq mr gj gh gi ms mt bd b be z dk translated">一个切割在图中的样子的例子。【来源:Stephan Eidenbenz的图片，在此找到:<a class="ae mh" href="https://www.researchgate.net/figure/An-illustration-of-the-MaxCut-problem_fig19_324472130" rel="noopener ugc nofollow" target="_blank">https://www . research gate . net/figure/An-illustration-of-the-max cut-problem _ fig 19 _ 324472130】</a></figcaption></figure><p id="9c16" class="pw-post-body-paragraph kc kd it kf b kg kh ki kj kk kl km kn mb kp kq kr md kt ku kv mf kx ky kz la im bi translated">我们现在提出以下要求。</p><figure class="mj mk ml mm gt mn gh gi paragraph-image"><div role="button" tabindex="0" class="mv mw di mx bf my"><div class="gh gi mu"><img src="../Images/ccc6ab4e52b95064a3dde93f9261000d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*bZBEC4uBZgBcXcD4OOxW0w@2x.png"/></div></div></figure><p id="cbac" class="pw-post-body-paragraph kc kd it kf b kg kh ki kj kk kl km kn mb kp kq kr md kt ku kv mf kx ky kz la im bi translated">有许多方法来证明这种说法，特别是，有一个贪婪的程序，总是计算这样的划分；这为上述主张提供了一个建设性的证据。今天，我们将讨论一个利用随机性的证明。基本的想法很简单，但是很聪明。我们首先观察所讨论的对象集(即顶点集<em class="ke"> V </em>的所有可能的二分)是有限的；特别是，我们有</p><figure class="mj mk ml mm gt mn gh gi paragraph-image"><div role="button" tabindex="0" class="mv mw di mx bf my"><div class="gh gi mz"><img src="../Images/e885d8f252d0a4a9eb63535404bb6121.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*xU_92hYzlyTrJ_hxO1vHFw@2x.png"/></div></div></figure><p id="5d42" class="pw-post-body-paragraph kc kd it kf b kg kh ki kj kk kl km kn mb kp kq kr md kt ku kv mf kx ky kz la im bi translated">既然没有明显的理由来争论所有这些削减，随机性就来了。如果我们简单地选择一个图的随机切割，并计算在这样一个随机切割中期望切割的边的数量，会怎么样？</p><p id="f2cf" class="pw-post-body-paragraph kc kd it kf b kg kh ki kj kk kl km kn mb kp kq kr md kt ku kv mf kx ky kz la im bi translated">让我们先来看看为什么这实际上会有帮助。假设，不知何故，我们可以计算从所有切片中随机均匀采样的切片<a class="ae mh" href="https://en.wikipedia.org/wiki/Discrete_uniform_distribution" rel="noopener ugc nofollow" target="_blank"><strong class="kf jd"/></a><strong class="kf jd"/>的<a class="ae mh" href="https://en.wikipedia.org/wiki/Expected_value" rel="noopener ugc nofollow" target="_blank"> <strong class="kf jd">预期</strong> </a>尺寸<em class="ke"> T </em>，此外，让我们假设<em class="ke"> T </em>至少是<em class="ke"> M/2 </em>。那是什么意思？这意味着，如果我们查看所有可能的切割，将它们的尺寸相加(即每次切割中切割的边数)，然后用其项数对该总和进行平均，则得到的数目至少为<em class="ke"> M/2 </em>。让我们试着扩展一下。如上所述，不同的二分的数量是<em class="ke"> 2^N </em>。嗯，如果我们假设<em class="ke"> V </em>的二分图是有序对<em class="ke"> (A，B) </em>，那就是真的。但是，很容易看出，在分区<em class="ke"> (A，B) </em>中切割的边的数量与在分区<em class="ke"> (B，A) </em>中切割的边的数量相同。因此，我们可以假设分区<em class="ke"> A，B </em>是无序的，因此我们得出结论，不同的可能切割的数量是</p><figure class="mj mk ml mm gt mn gh gi paragraph-image"><div class="gh gi na"><img src="../Images/dcc092468418722936532d9657926cb8.png" data-original-src="https://miro.medium.com/v2/resize:fit:1032/format:webp/1*CNVCsXYQxZs4WDX1VsIavQ@2x.png"/></div></figure><p id="6774" class="pw-post-body-paragraph kc kd it kf b kg kh ki kj kk kl km kn mb kp kq kr md kt ku kv mf kx ky kz la im bi translated">现在让<em class="ke"> t(1)，…，t(q) </em>表示在所有这些不同分区中切割的边的数量。从前面的讨论中，我们了解到</p><figure class="mj mk ml mm gt mn gh gi paragraph-image"><div role="button" tabindex="0" class="mv mw di mx bf my"><div class="gh gi nb"><img src="../Images/65bef5a144ff937fc76b79325d72f99b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*MqEsT4R6aL8Mns9P2wTBOg@2x.png"/></div></div></figure><p id="e8fd" class="pw-post-body-paragraph kc kd it kf b kg kh ki kj kk kl km kn mb kp kq kr md kt ku kv mf kx ky kz la im bi translated">并且这个数字被假定(目前)至少是<em class="ke"> M/2 </em>。我们现在声称，这已经表明，一定存在一个至少为<em class="ke"> M/2 </em>的项<em class="ke"> t(i) </em>。为了看到这一点，假设相反，即假设对于每一个<em class="ke"> j = 1，…，q </em>，t(j) &lt; M/2 。这意味着</p><figure class="mj mk ml mm gt mn gh gi paragraph-image"><div role="button" tabindex="0" class="mv mw di mx bf my"><div class="gh gi nc"><img src="../Images/7c145c60fe95267752bdbc509dae2960.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*ZlLI_JVmK9iu6W1TnP6UkA@2x.png"/></div></div></figure><p id="ba83" class="pw-post-body-paragraph kc kd it kf b kg kh ki kj kk kl km kn mb kp kq kr md kt ku kv mf kx ky kz la im bi translated">所以我们得到了一个矛盾！我们刚刚展示的只是一般的观察，如果一个<a class="ae mh" href="https://en.wikipedia.org/wiki/Random_variable" rel="noopener ugc nofollow" target="_blank">随机变量</a>的平均值/期望值等于某个值<em class="ke"> Z </em>，那么一定存在一个事件对应于至少是<em class="ke"> Z </em>的随机变量。</p><p id="0527" class="pw-post-body-paragraph kc kd it kf b kg kh ki kj kk kl km kn mb kp kq kr md kt ku kv mf kx ky kz la im bi translated">到目前为止，整个讨论表明，如果我们计算随机均匀采样的切割的预期尺寸，并且该预期尺寸结果是至少<em class="ke"> M/2 </em>，那么这确定性地表明，即总是存在尺寸至少为<em class="ke"> M/2 </em>的切割。换句话说，我们只是用随机性和期望来证明一个断言是<strong class="kf jd">总是</strong>真！这是现在被称为<a class="ae mh" href="https://en.wikipedia.org/wiki/Probabilistic_method" rel="noopener ugc nofollow" target="_blank"> <strong class="kf jd">概率方法</strong> </a> <strong class="kf jd">背后令人惊讶的简单想法，由伟大的</strong> <a class="ae mh" href="https://en.wikipedia.org/wiki/Paul_Erd%C5%91s" rel="noopener ugc nofollow" target="_blank"> <strong class="kf jd">保罗·鄂尔多斯</strong> </a>推广。</p><h1 id="d309" class="lb lc it bd ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly bi translated">更多的细节</h1><p id="ebfe" class="pw-post-body-paragraph kc kd it kf b kg lz ki kj kk ma km kn mb mc kq kr md me ku kv mf mg ky kz la im bi translated">然而，还有一个潜在的大问题。我们如何计算随机切割的预期尺寸？事实证明，有一种非常简单的方法可以做到这一点！我们将使用<a class="ae mh" href="https://en.wikipedia.org/wiki/Bernoulli_trial" rel="noopener ugc nofollow" target="_blank"> <strong class="kf jd">独立随机掷硬币</strong> </a> <strong class="kf jd">！</strong></p><figure class="mj mk ml mm gt mn gh gi paragraph-image"><div class="gh gi nd"><img src="../Images/522899a0c0be5be394e724fe54114026.png" data-original-src="https://miro.medium.com/v2/resize:fit:710/format:webp/1*4RKAzVjie_cIF5YKftp3wA.png"/></div></figure><p id="01a0" class="pw-post-body-paragraph kc kd it kf b kg kh ki kj kk kl km kn mb kp kq kr md kt ku kv mf kx ky kz la im bi translated">更准确地说，我们将看到如何使用独立的随机硬币来“生成”所有可能的二分分布<em class="ke"> {A，B} </em>。如上所述，这种二分的总数是<em class="ke"> q = 2^(N-1) </em>。下面是一个简单的方法:</p><ul class=""><li id="bdba" class="ne nf it kf b kg kh kk kl mb ng md nh mf ni la nj nk nl nm bi translated">对于<em class="ke"> V </em>的每个顶点<em class="ke"> u </em>，我们抛一个独立的无偏硬币，如果是正面，我们将顶点<em class="ke"> u </em>添加到集合<em class="ke"> A </em>中，否则，如果得到反面，我们将顶点<em class="ke"> u </em>添加到集合<em class="ke"> B </em>中。</li></ul><p id="d1ea" class="pw-post-body-paragraph kc kd it kf b kg kh ki kj kk kl km kn mb kp kq kr md kt ku kv mf kx ky kz la im bi translated">我们现在做一个健全性检查。来固定一个二分<em class="ke"> {A，B} </em>。如果对于<em class="ke"> A </em>中的每个顶点<em class="ke"> u </em>，相应的硬币投掷结果是正面，并且对于<em class="ke"> B </em>中的每个顶点<em class="ke"> v </em>，相应的硬币投掷结果是反面，则上述随机过程产生这种精确的二分。因为所有的硬币投掷都是无偏和独立的，所以产生给定的二分图<em class="ke"> {A，B} </em>的概率正好是</p><figure class="mj mk ml mm gt mn gh gi paragraph-image"><div role="button" tabindex="0" class="mv mw di mx bf my"><div class="gh gi nn"><img src="../Images/bd92e51f1c8f1f4db69349021181e73e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*KN2s00ANVhQcDT35X-E9UA@2x.png"/></div></div></figure><p id="6bcf" class="pw-post-body-paragraph kc kd it kf b kg kh ki kj kk kl km kn mb kp kq kr md kt ku kv mf kx ky kz la im bi translated">等等，这不是我们想要的。嗯，和前面类似(计算<em class="ke"> q) </em>时)，以上是我们得到二分图<em class="ke"> {A，B} </em>为有序二分图<em class="ke"> (A，B) </em>的概率。如前所述，顺序并不重要，因此我们也可以得到相同的二分图<em class="ke"> {A，B} </em>，如果对顶点<em class="ke"> A </em>的所有掷硬币结果都是反面，对顶点<em class="ke"> B </em>的所有掷硬币结果都是正面。因此，得到{ <em class="ke"> A，B} </em>的结果概率是上面计算的概率的<em class="ke"> 2 </em>倍，因此它正好等于<em class="ke"> 1/q </em>。我们的结论是，上述随机过程在图的所有切割中生成了一个统一的样本！</p><p id="ebfc" class="pw-post-body-paragraph kc kd it kf b kg kh ki kj kk kl km kn mb kp kq kr md kt ku kv mf kx ky kz la im bi translated">然而，目前还不清楚上述抛硬币的方法会有什么帮助。我们声称现在很容易计算随机切割的预期尺寸。为此，我们使用了指示器随机变量这一极其有用的概念。设<em class="ke"> X </em>表示从上述掷硬币过程中随机抽取的切割尺寸。注意<em class="ke"> X </em>是随机变量，<em class="ke"> E[X] = T </em>，其中<em class="ke"> E[X] </em>表示随机变量X的期望值，我们现在对图的边任意排序。设<em class="ke"> e(1)，…，e(M) </em>是这样一个排序。对于图的每条边<em class="ke"> e(i) </em>，我们进一步定义了随机变量<em class="ke"> X(i) </em>，如果边被切割，则等于<em class="ke"> 1 </em>，否则等于<em class="ke"> 0 </em>。现在很容易看出这一点</p><figure class="mj mk ml mm gt mn gh gi paragraph-image"><div role="button" tabindex="0" class="mv mw di mx bf my"><div class="gh gi no"><img src="../Images/3c3e40d9b2d302460d70980188603f02.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*q7mqVi5a8YOweoIXKdHX1w@2x.png"/></div></div></figure><p id="814b" class="pw-post-body-paragraph kc kd it kf b kg kh ki kj kk kl km kn mb kp kq kr md kt ku kv mf kx ky kz la im bi translated">快到了！我们现在将使用期望值的极其有用的属性，它被称为<a class="ae mh" href="https://en.wikipedia.org/wiki/Expected_value#Basic_properties" rel="noopener ugc nofollow" target="_blank"> <strong class="kf jd">期望值的线性度</strong> </a>。这只是说两个随机变量(不一定独立)之和的期望值总是等于这两个随机变量的期望值之和(假设对应的期望值存在，我们的例子就是这种情况，我们很快就会看到)。把它应用到我们的案例中，我们得到了</p><figure class="mj mk ml mm gt mn gh gi paragraph-image"><div role="button" tabindex="0" class="mv mw di mx bf my"><div class="gh gi np"><img src="../Images/a669105be4bbd995f0d466bb4a545e7c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*ERYx0Iw6ZU97DfIRN93OQQ@2x.png"/></div></div></figure><p id="8f46" class="pw-post-body-paragraph kc kd it kf b kg kh ki kj kk kl km kn mb kp kq kr md kt ku kv mf kx ky kz la im bi translated">所以，我们现在不得不担心在上面的总和中计算每个期望值。我们声称所有这些项都是相同的，并且等于<em class="ke"> 1/2 </em>。为了看到这一点，让我们固定图的一条边<em class="ke"> e=(u，v) </em>。边缘被切割的概率有多大？嗯，为了切边，<em class="ke"> u </em>必须在<em class="ke"> A </em>中，<em class="ke"> v </em>在<em class="ke"> B </em>中，或者<em class="ke"> u </em>必须在<em class="ke"> B </em>中，<em class="ke"> v </em>在<em class="ke"> A </em>中。<em class="ke"> u </em>在<em class="ke"> A </em>而<em class="ke"> v </em>在<em class="ke"> B </em>的概率有多大？很容易看出是<em class="ke"> (1/2)(1/2) = 1/4，</em>因为抛硬币是独立的。同理，<em class="ke"> u </em>在<em class="ke"> B </em>中，<em class="ke"> v </em>在<em class="ke"> A </em>中的概率为<em class="ke"> 1/4 </em>。因此，边缘<em class="ke"> e </em>被切割的概率为<em class="ke"> 1/2 </em>。这意味着如果<em class="ke"> X(e) </em>是对应于边缘<em class="ke"> e </em>的随机0/1变量，那么</p><figure class="mj mk ml mm gt mn gh gi paragraph-image"><div role="button" tabindex="0" class="mv mw di mx bf my"><div class="gh gi nq"><img src="../Images/6afea0a4f6ade8a6415a12847e755121.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*c9TLyV8-0m4MMrK4zTebKg@2x.png"/></div></div></figure><p id="2d31" class="pw-post-body-paragraph kc kd it kf b kg kh ki kj kk kl km kn mb kp kq kr md kt ku kv mf kx ky kz la im bi translated">因为我们没有假设任何关于边<em class="ke"> e </em>的细节，所以上面的论证适用于图的每一条边。我们的结论是</p><figure class="mj mk ml mm gt mn gh gi paragraph-image"><div class="gh gi nr"><img src="../Images/a4e7473e2c505cae567763bf3d796496.png" data-original-src="https://miro.medium.com/v2/resize:fit:1088/format:webp/1*ON2MOyL_g9kGCfhWGPZKoQ@2x.png"/></div></figure><p id="13e8" class="pw-post-body-paragraph kc kd it kf b kg kh ki kj kk kl km kn mb kp kq kr md kt ku kv mf kx ky kz la im bi translated">把所有的东西放在一起，我们证明了如果我们随机均匀地抽样一个随机切口，切口的期望尺寸是<em class="ke"> M/2 </em>，因此，一定存在一个尺寸至少为<em class="ke"> M/2 </em>的切口。索赔终于被证明了！</p><p id="0aee" class="pw-post-body-paragraph kc kd it kf b kg kh ki kj kk kl km kn mb kp kq kr md kt ku kv mf kx ky kz la im bi translated"><em class="ke">注意:使用均匀分布对于该方法的应用不是必需的。但在许多情况下，它确实使分析变得更简单，就像这里的情况一样。</em></p><h1 id="2127" class="lb lc it bd ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly bi translated">结论</h1><p id="f4e1" class="pw-post-body-paragraph kc kd it kf b kg lz ki kj kk ma km kn mb mc kq kr md me ku kv mf mg ky kz la im bi translated">以上是简单而巧妙的概率方法的一个例子。这种方法有许多应用，在证明离散数学中许多有趣的结果时，它被证明是极其有用的。如果你有兴趣了解更多关于这种方法的知识，标准的参考资料是诺加·阿隆和乔尔·h·斯潘塞的美丽的书，名为“概率方法”！</p><p id="bd45" class="pw-post-body-paragraph kc kd it kf b kg kh ki kj kk kl km kn mb kp kq kr md kt ku kv mf kx ky kz la im bi translated">在未来的文章中，我们会给出一些稍微复杂一点的例子。</p><figure class="mj mk ml mm gt mn gh gi paragraph-image"><div class="gh gi ns"><img src="../Images/d51bd799b085365441077b136caf50ae.png" data-original-src="https://miro.medium.com/v2/resize:fit:1114/format:webp/1*_VOh1bO7xShJt4SHtZnvvQ.jpeg"/></div><figcaption class="mq mr gj gh gi ms mt bd b be z dk translated">《概率方法》书的部分封面，上面有保罗·鄂尔多斯的照片。</figcaption></figure><p id="078f" class="pw-post-body-paragraph kc kd it kf b kg kh ki kj kk kl km kn mb kp kq kr md kt ku kv mf kx ky kz la im bi translated"><strong class="kf jd">参考文献</strong></p><ul class=""><li id="f852" class="ne nf it kf b kg kh kk kl mb ng md nh mf ni la nj nk nl nm bi translated"><a class="ae mh" href="https://en.wikipedia.org/wiki/Probabilistic_method" rel="noopener ugc nofollow" target="_blank">https://en.wikipedia.org/wiki/Probabilistic_method</a></li><li id="fbbe" class="ne nf it kf b kg nt kk nu mb nv md nw mf nx la nj nk nl nm bi translated"><a class="ae mh" href="https://en.wikipedia.org/wiki/Maximum_cut" rel="noopener ugc nofollow" target="_blank">https://en.wikipedia.org/wiki/Maximum_cut</a></li><li id="7471" class="ne nf it kf b kg nt kk nu mb nv md nw mf nx la nj nk nl nm bi translated">乔尔·h·斯潘塞:概率方法，第三版。威利2008，国际标准书号978–0–470–17020–5</li></ul></div></div>    
</body>
</html>