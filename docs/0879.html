<html>
<head>
<title>Deploying ML Models in Production: Model Export &amp; System Architecture</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">在生产中部署ML模型:模型导出和系统架构</h1>
<blockquote>原文：<a href="https://pub.towardsai.net/deploying-ml-models-in-production-model-export-system-architecture-e64acb3b6e6d?source=collection_archive---------1-----------------------#2020-09-02">https://pub.towardsai.net/deploying-ml-models-in-production-model-export-system-architecture-e64acb3b6e6d?source=collection_archive---------1-----------------------#2020-09-02</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><h2 id="dc3b" class="io ip iq bd b dl ir is it iu iv iw dk ix translated" aria-label="kicker paragraph"><a class="ae ep" href="https://towardsai.net/p/category/machine-learning" rel="noopener ugc nofollow" target="_blank">机器学习</a></h2><div class=""/><div class=""><h2 id="e1f9" class="pw-subtitle-paragraph jw iz iq bd b jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn dk translated">理解模型导出机制、轻量级集成、离线和在线模型托管技术</h2></div><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div role="button" tabindex="0" class="ku kv di kw bf kx"><div class="gh gi ko"><img src="../Images/05239eeb69b6a850d499ac08d183ed1e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*tGZB_O3qDTqtxj_-"/></div></div><figcaption class="la lb gj gh gi lc ld bd b be z dk translated">由<a class="ae le" href="https://unsplash.com/@markusspiske?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">马库斯·斯皮斯克</a>在<a class="ae le" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上拍摄的照片</figcaption></figure><p id="c3b2" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi mb translated"><span class="l mc md me bm mf mg mh mi mj di">我们</span>经常看到这里讨论的许多技术&amp;关于用ML解决问题。但当涉及到将它们全部投入生产时，我们看不到太大的吸引力，人们仍然需要依赖一些公共云提供商或开源软件。在本文中，我们将讨论在生产中使用的ML模型，以及支持它的系统架构。我们将了解如何在没有任何公共云提供商的情况下做到这一点。</p></div><div class="ab cl mk ml hu mm" role="separator"><span class="mn bw bk mo mp mq"/><span class="mn bw bk mo mp mq"/><span class="mn bw bk mo mp"/></div><div class="ij ik il im in"><h1 id="a99d" class="mr ms iq bd mt mu mv mw mx my mz na nb kf nc kg nd ki ne kj nf kl ng km nh ni bi translated">模型导出</h1><p id="83e2" class="pw-post-body-paragraph lf lg iq lh b li nj ka lk ll nk kd ln lo nl lq lr ls nm lu lv lw nn ly lz ma ij bi translated">几乎所有的ML模型都是数学表达式、方程或数据结构(树或图)。数学表达式有系数、一些变量、一些常数、一些概率分布的参数(特定于分布的参数、标准偏差或平均值)。让我们举一个简单的线性回归模型的例子:</p><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div class="gh gi no"><img src="../Images/0ab7db6a251a30e5e70ee02e3ca45e2b.png" data-original-src="https://miro.medium.com/v2/resize:fit:504/1*s6o9TfvVj9nh8ECzJDWYNQ.gif"/></div></figure><p id="1f55" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">它有多少信息？3对系数值&amp;特征名称和一个常数。这七个值肯定可以写在一个文件中。</p><p id="08ac" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">因此，模型导出只不过是将模型的元数据信息写入文件或数据存储中。这是保存模型以备将来使用所必需的。</p><h2 id="df74" class="np ms iq bd mt nq nr dn mx ns nt dp nb lo nu nv nd ls nw nx nf lw ny nz nh iw bi translated"><strong class="ak">平台独立模型导出</strong></h2><p id="0f59" class="pw-post-body-paragraph lf lg iq lh b li nj ka lk ll nk kd ln lo nl lq lr ls nm lu lv lw nn ly lz ma ij bi translated">ML模型使用不同的技术栈进行训练，如Python、Java、.网等。在Python中，有不同的框架，如sci-kit-learn、PyTorch、TensorFlow等等。显然需要一种独立于平台的模型导出机制。大多数时候，模型的典型用法是跨平台的。模型可以在Python平台中设计，但是出于高可用性的原因，它可以由Java平台提供。我们将在后面的章节中详细讨论这一点。在此之前，让我们讨论两种不同的模型导出格式。</p><p id="7b71" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated"><strong class="lh ja"> PMML: </strong> PMML代表<em class="oa">预测模型标记语言</em>。这是一个基于XML的标准，它有一个预定义的<a class="ae le" href="http://dmg.org/pmml/v4-1/GeneralStructure.html" rel="noopener ugc nofollow" target="_blank">模式</a>。模型被导出为XML文件。</p><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div class="gh gi ob"><img src="../Images/cf7e062b338fb9494851521948688c5b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1282/format:webp/1*XPuef--DkdbgqXLv-eyDMQ.png"/></div><figcaption class="la lb gj gh gi lc ld bd b be z dk translated">PMML文件的示例部分</figcaption></figure><p id="29e2" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">以上PMML内容是针对线性回归模型的。我们可以看到，它包含了模型类型(在上面的例子中为<em class="oa">回归</em>)、预处理步骤(在上面的例子中为<em class="oa">标准缩放器</em>)、特征名称以及许多其他信息。</p><blockquote class="oc od oe"><p id="0719" class="lf lg oa lh b li lj ka lk ll lm kd ln of lp lq lr og lt lu lv oh lx ly lz ma ij bi translated">PMML饱受规模问题的困扰。太多的特性会产生非常大的XML，特别是对于NLP模型。</p></blockquote><p id="9c33" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">因此，有时将PMML内容转换成JSON很方便。</p><p id="5d95" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated"><strong class="lh ja"> ONNX: </strong>代表<a class="ae le" href="https://onnx.ai/" rel="noopener ugc nofollow" target="_blank"> <em class="oa">开放式神经网络交换</em> </a> <em class="oa">。</em>非常适合深度学习模型。它生成一个以二进制文件序列化的网络图。像往常一样，图表包含隐藏和输出层权重和连接信息。与PMML不同，它不生成XML。</p><p id="3e22" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">这两种格式都可以跨平台移植(尤其是PMML)。</p><h2 id="4e2e" class="np ms iq bd mt nq nr dn mx ns nt dp nb lo nu nv nd ls nw nx nf lw ny nz nh iw bi translated">模型消费和便携性</h2><p id="e95d" class="pw-post-body-paragraph lf lg iq lh b li nj ka lk ll nk kd ln lo nl lq lr ls nm lu lv lw nn ly lz ma ij bi translated">使用上述格式导出的模型可以在实际使用中使用。模型训练包括确定其参数&amp;超参数的迭代过程。但是，一旦训练好了，模型消费就是一步到位的过程。比方说，我们在高性能机器中使用随机梯度下降训练了一个线性回归模型。产生的模型是系数、特征名称和预处理信息的集合。它必须使用任何格式保存在某个地方，以便我们可以在以后加载和使用它。</p><blockquote class="oc od oe"><p id="0f70" class="lf lg oa lh b li lj ka lk ll lm kd ln of lp lq lr og lt lu lv oh lx ly lz ma ij bi translated">要使用该模型，我们只需将来自输入数据实例的特征与系数相乘，加上截距并返回结果。</p></blockquote><p id="935a" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">因此，模型是在哪个平台上设计和构建的并不重要。在基于ML的生产系统中，开发的组件可以在不同的平台上使用是很自然的。有了适当的模型导出支持，用Python设计的模型可以在Android应用程序中使用。</p><blockquote class="oc od oe"><p id="de3a" class="lf lg oa lh b li lj ka lk ll lm kd ln of lp lq lr og lt lu lv oh lx ly lz ma ij bi translated">一般来说，ML模型消费逻辑必须在消费平台内部开发。我们可以称之为存根。</p></blockquote><p id="3a3a" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">下图解释了这种情况</p><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div class="gh gi oi"><img src="../Images/72b91b4440dd0344570cd7ff1652c94b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1142/format:webp/1*JzPUkVpwQ2bhLT3Bxyu3HQ.jpeg"/></div><figcaption class="la lb gj gh gi lc ld bd b be z dk translated">跨平台模型导出</figcaption></figure><p id="155a" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">在不同的Python框架(scikit-learn、PyTorch、TensorFlow)或Apache Spark/Flink等大数据堆栈中设计的模型可以以任何定义的格式(PMML/ONNX)导出，并且可以由不同的客户端应用程序(Java、Python或。网)。所以，这是一个多对多的情况。</p><blockquote class="oc od oe"><p id="ae46" class="lf lg oa lh b li lj ka lk ll lm kd ln of lp lq lr og lt lu lv oh lx ly lz ma ij bi translated">客户端应用程序解析模型文件，并提取必要的参数来构建模型的内存版本。</p></blockquote><p id="f6f3" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">除了依赖PMML/ONNX或任何标准格式，还可以为一些非常具体的要求定义用户定义的自定义格式(如图所示)。在任何情况下，目标都是“<em class="oa">让模型可以跨平台移植</em></p></div><div class="ab cl mk ml hu mm" role="separator"><span class="mn bw bk mo mp mq"/><span class="mn bw bk mo mp mq"/><span class="mn bw bk mo mp"/></div><div class="ij ik il im in"><h1 id="dec2" class="mr ms iq bd mt mu mv mw mx my mz na nb kf nc kg nd ki ne kj nf kl ng km nh ni bi translated">模型部署和系统架构</h1><p id="e728" class="pw-post-body-paragraph lf lg iq lh b li nj ka lk ll nk kd ln lo nl lq lr ls nm lu lv lw nn ly lz ma ij bi translated">大多数时候，数据科学活动是使用上面讨论的标准库在Python中完成的。但是，它不是一个非常可扩展的选项。我们需要一个强大的数据工程和生产级系统部署平台。大数据在这里发挥了很大的作用。模型可以用Spark、Hadoop、Flink等大数据平台中的Pb级数据进行训练。事实上，这些在生产系统中总是首选的。</p><p id="2cda" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">设计架构有两个挑战。关于Python，上面已经提到了一个挑战。另一个是大数据平台本身。</p><blockquote class="oc od oe"><p id="189f" class="lf lg oa lh b li lj ka lk ll lm kd ln of lp lq lr og lt lu lv oh lx ly lz ma ij bi translated">Apache Spark/Flink不适合同步集成，它们以离线/批处理/异步模式运行。</p></blockquote><p id="d9c3" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">因此，通过REST直接公开Spark/Hadoop层预测API对于具有高/中等吞吐量预期的面向客户端的系统来说是非常危险的。即使吞吐量要求很低，也不建议使用同步集成。使用PMML/ONNX或其他格式的模型导出机制解决了这个问题。</p><p id="e1c8" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">该模型应使用大数据堆栈进行训练，然后导出并存储在模型注册表中。它应该支持增量/迭代培训过程的版本化和历史机制。该流程本质上是循环的，如下所示:</p><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div class="gh gi oj"><img src="../Images/f270ef5c5077a161863aaf4c959ce34c.png" data-original-src="https://miro.medium.com/v2/resize:fit:502/format:webp/1*cVeBBD-SbdOYhdhOGnKZxw.jpeg"/></div><figcaption class="la lb gj gh gi lc ld bd b be z dk translated">模型版本控制</figcaption></figure><p id="5565" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">然后，一个预测引擎应该使用该模型并返回结果。这个引擎应该精通模型导出格式。这样，预测和训练过程变得完全脱节和松散耦合。</p><blockquote class="oc od oe"><p id="9475" class="lf lg oa lh b li lj ka lk ll lm kd ln of lp lq lr og lt lu lv oh lx ly lz ma ij bi translated">即使在一些假设的情况下，如果使用Python框架为小数据集而不是大数据堆栈训练模型，预测引擎也不需要更新。这是这种设计的一大优点。</p></blockquote><p id="399f" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">现在，我们将使用上面描述的概念来讨论模型部署的三种不同的系统架构。</p><h2 id="d700" class="np ms iq bd mt nq nr dn mx ns nt dp nb lo nu nv nd ls nw nx nf lw ny nz nh iw bi translated">按需云(模型即服务)部署</h2><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div role="button" tabindex="0" class="ku kv di kw bf kx"><div class="gh gi ok"><img src="../Images/47c86f8854b3dac5af706e4387751dca.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*sq7AXMP4TLRG0cqphRqqNw.jpeg"/></div></div><figcaption class="la lb gj gh gi lc ld bd b be z dk translated">按需云(模型即服务)部署</figcaption></figure><p id="f747" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">从上图中，我们可以看到模型以离线的方式被训练并被推送到模型注册中心(虚线表示<em class="oa">离线过程</em>)。这种训练是一个周期性的&amp;异步过程。预测引擎接受来自面向客户端的UI/App的请求，并执行模型以获得结果。这是一个按需同步过程，与模型训练引擎无关。</p><blockquote class="oc od oe"><p id="7260" class="lf lg oa lh b li lj ka lk ll lm kd ln of lp lq lr og lt lu lv oh lx ly lz ma ij bi translated">模型在这里作为服务托管(通过REST API ),并给出实时预测。大多数公共云ML提供商都遵循这种架构。</p></blockquote><h2 id="4ca7" class="np ms iq bd mt nq nr dn mx ns nt dp nb lo nu nv nd ls nw nx nf lw ny nz nh iw bi translated">离线云部署</h2><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div role="button" tabindex="0" class="ku kv di kw bf kx"><div class="gh gi ol"><img src="../Images/054623de46eee8533f09103403db1176.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*NNUsQQ8UygMg2AEisGUnTg.jpeg"/></div></div><figcaption class="la lb gj gh gi lc ld bd b be z dk translated">离线云部署</figcaption></figure><p id="ca06" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">这里，预测引擎在模型训练引擎的范围内工作，并且预测过程也与训练一起以离线方式工作。预测存储在数据存储中。一个分析引擎处理来自UI/App的同步请求，并返回预存的预测。这里，模型注册不必支持所有相关的模型导出格式，因为预测是在大数据引擎的范围内完成的。</p><blockquote class="oc od oe"><p id="b10c" class="lf lg oa lh b li lj ka lk ll lm kd ln of lp lq lr og lt lu lv oh lx ly lz ma ij bi translated">这种架构在利用模型以离线方式生成分析报告或一组建议的情况下非常有用。</p></blockquote><h2 id="27ab" class="np ms iq bd mt nq nr dn mx ns nt dp nb lo nu nv nd ls nw nx nf lw ny nz nh iw bi translated">打包部署</h2><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div class="gh gi om"><img src="../Images/9b8c8d7ba482a0b1a9e8c0041ef563d6.png" data-original-src="https://miro.medium.com/v2/resize:fit:1194/format:webp/1*rMy6nLvgrkCunPxKTnfwuw.jpeg"/></div><figcaption class="la lb gj gh gi lc ld bd b be z dk translated">打包部署</figcaption></figure><p id="9135" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">这适用于典型的移动应用程序或没有公共/私有云连接的情况。预测引擎打包在面向客户端的UI/App/设备中。它必须非常轻便，因为许多设备上可能存在内存限制。模型训练和注册应该作为一个离线过程。即使没有互联网连接，这种架构也应该可以工作，因为预测是在应用程序/设备中进行的。</p><blockquote class="oc od oe"><p id="aff5" class="lf lg oa lh b li lj ka lk ll lm kd ln of lp lq lr og lt lu lv oh lx ly lz ma ij bi translated">它也非常适合在断开连接的服务器或基于机器人的应用程序中运行。</p></blockquote><p id="b709" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">上述架构可能是昂贵的公共云ML服务提供商的内部替代方案。我们所需要的是系统设计和机器学习的良好知识。</p><blockquote class="oc od oe"><p id="8275" class="lf lg oa lh b li lj ka lk ll lm kd ln of lp lq lr og lt lu lv oh lx ly lz ma ij bi translated">注意:最近我写了一本关于ML(<a class="ae le" href="https://twitter.com/bpbonline/status/1256146448346988546" rel="noopener ugc nofollow" target="_blank">https://twitter.com/bpbonline/status/1256146448346988546</a>)的书</p></blockquote></div></div>    
</body>
</html>