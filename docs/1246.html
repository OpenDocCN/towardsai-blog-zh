<html>
<head>
<title>AutoSIRDS — Using single image depth estimation to create Single Image Random Dot Stereograms</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">auto irds—使用单一图像深度估计来创建单一图像随机点立体图</h1>
<blockquote>原文：<a href="https://pub.towardsai.net/autosirds-using-single-image-depth-estimation-to-create-single-image-random-dot-stereograms-110c070858c6?source=collection_archive---------1-----------------------#2020-12-12">https://pub.towardsai.net/autosirds-using-single-image-depth-estimation-to-create-single-image-random-dot-stereograms-110c070858c6?source=collection_archive---------1-----------------------#2020-12-12</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><h2 id="441c" class="io ip iq bd b dl ir is it iu iv iw dk ix translated" aria-label="kicker paragraph"><a class="ae ep" href="https://towardsai.net/p/category/computer-vision" rel="noopener ugc nofollow" target="_blank">应用计算机视觉</a></h2><div class=""/><div class=""><h2 id="c22e" class="pw-subtitle-paragraph jw iz iq bd b jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn dk translated">使用Google Colab和TF Hub的完整游乐场</h2></div><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div role="button" tabindex="0" class="ku kv di kw bf kx"><div class="gh gi ko"><img src="../Images/f4c9d8dd493f7ace20b5aaf600632b10.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*2f_Qd2LAyoOOF8t4ITsmdw.png"/></div></div></figure><p id="e7ec" class="pw-post-body-paragraph la lb iq lc b ld le ka lf lg lh kd li lj lk ll lm ln lo lp lq lr ls lt lu lv ij bi lw translated"><span class="l lx ly lz bm ma mb mc md me di">当我还是个孩子的时候，我就对3D很着迷——这在90年代初VR眼镜或AR出现之前很难得到。我曾经非常喜欢收集蜘蛛侠卡片，其中一种是全息图，我曾经认为这是最神奇的东西。我也曾经<em class="mf">喜欢</em>我曾经在科学杂志上看到的红色和蓝色3D立体图像。我清楚地记得虫子和恐龙。在拜访我叔叔的时候，我被介绍认识了SIRDs，他的墙上有一个SIRDs尽管我不知道它叫这个名字。这是一个沉没的百宝箱，以鲨鱼为秘密图像，但我认为这是最酷的事情。直到最近，我才意识到，直到大约一两周前，我实际上仍然不知道它们是如何工作的——在第一次看到它们的25年后，我仍然不知道。嗯，这是足够的动机想知道更多。一旦我知道了它们是如何工作的，我就有了结合使用机器学习的单幅图像深度估计来将任何图像变成SIRD的想法，这在其他地方我没有见过。公平的警告，结果是击中和错过的基础上，单一的图像深度估计结果，但有些工作真的很好。我创建了一个Twitter机器人，如果你想关注它，它会发布一个SIRD，@ AutoSIRD。</span></p></div><div class="ab cl mg mh hu mi" role="separator"><span class="mj bw bk mk ml mm"/><span class="mj bw bk mk ml mm"/><span class="mj bw bk mk ml"/></div><div class="ij ik il im in"><p id="546e" class="pw-post-body-paragraph la lb iq lc b ld le ka lf lg lh kd li lj lk ll lm ln lo lp lq lr ls lt lu lv ij bi lw translated"><span class="l lx ly lz bm ma mb mc md me di"> F </span>一、什么是单幅图像随机点立体图？</p><p id="9415" class="pw-post-body-paragraph la lb iq lc b ld le ka lf lg lh kd li lj lk ll lm ln lo lp lq lr ls lt lu lv ij bi translated">立体图是3D图像/表面的<strong class="lc ja"> <em class="mf">错觉</em> </strong>。它们是编码立体信息的2D图像，因此当正确观看时，它们显示隐藏的3D图像[1]。有不同类型的立体图，但我将重点介绍的可能是最常见的，即“眼窝”或平行会聚型[2]。我不会进入大量的细节，但请检查我的参考资料，因为有一些非常好的资源，详细解释了一些基本原理，在这个项目中帮助了我。本质上，这个想法是通过改变左右眼看到的像素位移来创建一个感知的3D图像——大脑基本上完成了所有其余的工作。</p><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div role="button" tabindex="0" class="ku kv di kw bf kx"><div class="gh gi mn"><img src="../Images/97ab5c1826a797ce7f8b90f40866f218.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*9PF8u2IopPatu_X1LXFOeA.png"/></div></div><figcaption class="mo mp gj gh gi mq mr bd b be z dk translated">图片来自[1]。演示两种类型的立体图。在这篇文章中，我们关注的是发散型。</figcaption></figure><p id="f090" class="pw-post-body-paragraph la lb iq lc b ld le ka lf lg lh kd li lj lk ll lm ln lo lp lq lr ls lt lu lv ij bi translated">要创建这些图像，需要一些数组操作来移动像素，还需要一个深度图像来知道这些像素要移动多少。这里是最简单的情况，白色方块会出现在灰色方块的前面。我们使用重复的随机点模式来创建正确的图像，其中两个正方形区域中的像素被移动一定量:</p><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div class="gh gi ms"><img src="../Images/b05d66c2dac9be50a6ee6da767951d03.png" data-original-src="https://miro.medium.com/v2/resize:fit:454/format:webp/1*PfhFi5qTuVUlVqApY90OrA.png"/></div><figcaption class="mo mp gj gh gi mq mr bd b be z dk translated">最简单的情况是显示两个正方形的深度图，其中白色越多，像素应该出现在前面，并且立体图对在正确观察时，将显示白色正方形出现在灰色正方形的前面。</figcaption></figure><p id="942f" class="pw-post-body-paragraph la lb iq lc b ld le ka lf lg lh kd li lj lk ll lm ln lo lp lq lr ls lt lu lv ij bi translated">这可以扩展到更复杂和更大的图像，其中图像是一条一条地构建的。我们也可以用一个图案来代替随机的黑白点。重要的是纹理要重复，并有足够的细节和对比度，我们的眼睛可以确定哪些像素被移动了以及移动了多少:</p><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div class="gh gi mt"><img src="../Images/45f7610f4dbc48e9a1702fc7f701b98e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1316/format:webp/1*73jH_rpn4PZfwhdufJAHbA.png"/></div><figcaption class="mo mp gj gh gi mq mr bd b be z dk translated">图片来自[3]一个示例，概述了如何使用2D正弦深度图和重复纹理图像创建单幅图像立体图。</figcaption></figure><p id="d49b" class="pw-post-body-paragraph la lb iq lc b ld le ka lf lg lh kd li lj lk ll lm ln lo lp lq lr ls lt lu lv ij bi translated">创建条带时，每个条带都需要相对于相邻条带从左向右移动。这使得每个左右对是其自己的立体图，并且当编辑在一起时，形成拼接的图像。使用下面的公式来计算像素移动的量，以将灰度深度图转换为向右移动的一定数量的像素，其中假设坐标范围在[0，0]和[1，1]之间:</p><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div role="button" tabindex="0" class="ku kv di kw bf kx"><div class="gh gi mu"><img src="../Images/5a63cb6065df9bf704986729bdc4743a.png" data-original-src="https://miro.medium.com/v2/resize:fit:836/format:webp/1*KxO9E61vS25r3OQijI-dIw.png"/></div></div><figcaption class="mo mp gj gh gi mq mr bd b be z dk translated">来自[3]等式的图像，用于确定如何将深度图图像转换为移位纹理图像。</figcaption></figure><p id="2115" class="pw-post-body-paragraph la lb iq lc b ld le ka lf lg lh kd li lj lk ll lm ln lo lp lq lr ls lt lu lv ij bi translated">这部分不太难。我使用了Numpy数组操作，虽然你也可以使用着色器，我认为这是最初的意图。仅仅使用上面的信息和任何深度图像，你就可以创建像这样的SIRDs:</p><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div role="button" tabindex="0" class="ku kv di kw bf kx"><div class="gh gi mv"><img src="../Images/220f3baa45befa3e15f0e68e3fd24e47.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*SjU2WHB3vZ4804ti8e7ebw.png"/></div></div><figcaption class="mo mp gj gh gi mq mr bd b be z dk translated">显示鲨鱼的单个图像随机点立体图的示例。深度图像显示灰度越白，纹理贴图中的像素移动越多。</figcaption></figure><p id="3829" class="pw-post-body-paragraph la lb iq lc b ld le ka lf lg lh kd li lj lk ll lm ln lo lp lq lr ls lt lu lv ij bi lw translated">但是现在问题来了，如何获得深度图像呢？有许多方法；使用你自己的3D渲染软件，比如Blender，创建一个模型就是其中之一。你甚至可以使用MS paint来给物体上色，根据它们在前景(白色)或背景(黑色)以及两者之间的程度。另一种方法是使用<strong class="lc ja"> <em class="mf">机器学习</em> </strong>。在这种情况下，我们可以使用TF Hub上可用的名为<a class="ae mw" href="https://hub.tensorflow.google.cn/intel/midas/v2/2" rel="noopener ugc nofollow" target="_blank"> Midas (v2) </a>的模型，它被训练为从单个图像输入输出深度图。我们现在可以从任何图像输入中创建任何深度图。这是原始论文[4]，他们用它来制作本·伯恩斯效果动画，这是视频<a class="ae mw" href="https://www.youtube.com/watch?v=3JroOSnBuAk" rel="noopener ugc nofollow" target="_blank">的补充资料。</a></p><p id="34e7" class="pw-post-body-paragraph la lb iq lc b ld le ka lf lg lh kd li lj lk ll lm ln lo lp lq lr ls lt lu lv ij bi translated">我把它做成一个带有表格的谷歌笔记本，这样你就可以自己玩了。如果你使用下拉列表的例子，我有几个好的。</p><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div class="gh gi mx"><img src="../Images/ef0aa76c37df24569f313dd72ddd8c8f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1396/format:webp/1*KPBnUdpHw9EeJXU3nr4oAA.png"/></div><figcaption class="mo mp gj gh gi mq mr bd b be z dk translated">在谷歌Colab深度图输入图像</figcaption></figure><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div class="gh gi my"><img src="../Images/552a69ce327bffb3b4e25f43edf93c74.png" data-original-src="https://miro.medium.com/v2/resize:fit:1002/format:webp/1*zVqu-j_KO3xD64peiT8z7w.png"/></div></figure><p id="d21f" class="pw-post-body-paragraph la lb iq lc b ld le ka lf lg lh kd li lj lk ll lm ln lo lp lq lr ls lt lu lv ij bi translated">这是一本高水平的笔记本。<br/>首先，我们通过预先训练的网络传递任何图像，以产生深度图。正如你所看到的，我们丢失了深度图的细节，这使得效果时好时坏。它需要是一个容易识别和简单的形状。在这种情况下，我认为霸王龙工作得很好，因为大多数人知道它是什么，当他们看到剪影。</p><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div role="button" tabindex="0" class="ku kv di kw bf kx"><div class="gh gi mz"><img src="../Images/897b831d69732f5f2045944b73f25e49.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*qA_N4Qq38GSoVa9YDo4wwg.png"/></div></div><figcaption class="mo mp gj gh gi mq mr bd b be z dk translated">用于输入纹理图和SIRD参数的用户界面</figcaption></figure><p id="d26e" class="pw-post-body-paragraph la lb iq lc b ld le ka lf lg lh kd li lj lk ll lm ln lo lp lq lr ls lt lu lv ij bi translated">接下来，我们找到一个纹理。为此，我使用了<a class="ae mw" href="https://www.colourlovers.com/" rel="noopener ugc nofollow" target="_blank"> ColorLovers </a>，它有一个API，我可以随机获得纹理，或者我可以获得单一图案的链接。png，然后我用它来形成重复的纹理图像。我已经编码，所以你可以提供一个图像链接，一个纹理链接，或者只是抓取一个随机纹理。在上面的图片中，我有一个链接，链接到一个我喜欢的纹理。输入参数(如depth_factor和num_strips)与SIRD相关，而参数scale_factor将减小输入图像的大小。根据显示器的尺寸，通常有一个最合适的尺寸和条数，所以你可能需要自己摸索。它还取决于纹理和我们的眼睛能形成立体图的程度。</p><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div role="button" tabindex="0" class="ku kv di kw bf kx"><div class="gh gi ko"><img src="../Images/51d2b01d292deaec0a6049b130828971.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*tl9R-fGuAiOPRHJvAKvZ-g.png"/></div></div><figcaption class="mo mp gj gh gi mq mr bd b be z dk translated">穿着SIRD的霸王龙——使用了来自http://www.colourlovers.com/pattern/5913220/Why_not<a class="ae mw" href="http://www.colourlovers.com/pattern/5913220/Why_not" rel="noopener ugc nofollow" target="_blank">的纹理</a>...</figcaption></figure><p id="c4a6" class="pw-post-body-paragraph la lb iq lc b ld le ka lf lg lh kd li lj lk ll lm ln lo lp lq lr ls lt lu lv ij bi translated">就是这样！如果你想看代码，我鼓励你去看看Colab。这里有更多有趣的例子！尽情享受吧！</p><p id="fcaf" class="pw-post-body-paragraph la lb iq lc b ld le ka lf lg lh kd li lj lk ll lm ln lo lp lq lr ls lt lu lv ij bi translated">我创建了一个Twitter机器人，如果你想关注它，它会发布一个SIRD</p></div><div class="ab cl mg mh hu mi" role="separator"><span class="mj bw bk mk ml mm"/><span class="mj bw bk mk ml mm"/><span class="mj bw bk mk ml"/></div><div class="ij ik il im in"><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div role="button" tabindex="0" class="ku kv di kw bf kx"><div class="gh gi na"><img src="../Images/bc7f27e536c6273c7b2fb44cc27c38c5.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*67eBq8eX0a1uL7F2OQhoQA.png"/></div></div><figcaption class="mo mp gj gh gi mq mr bd b be z dk translated">图片来自作者</figcaption></figure><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div role="button" tabindex="0" class="ku kv di kw bf kx"><div class="gh gi nb"><img src="../Images/96cb0304e042bbca231f1a7463a2df06.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*NiV4uocprlmh7uY5KJ1gxg.png"/></div></div><figcaption class="mo mp gj gh gi mq mr bd b be z dk translated">图片来自作者</figcaption></figure><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div class="gh gi nc"><img src="../Images/791658168949b0b473f075c9d6afd62b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1306/format:webp/1*w_7dF9qbbJiWplBxYpXz0A.png"/></div><figcaption class="mo mp gj gh gi mq mr bd b be z dk translated">图片来自作者</figcaption></figure><p id="493b" class="pw-post-body-paragraph la lb iq lc b ld le ka lf lg lh kd li lj lk ll lm ln lo lp lq lr ls lt lu lv ij bi translated">参考资料:</p><p id="8c81" class="pw-post-body-paragraph la lb iq lc b ld le ka lf lg lh kd li lj lk ll lm ln lo lp lq lr ls lt lu lv ij bi translated">[1] Júlio M. Otuyama，立体图教程。<a class="ae mw" href="https://www.ime.usp.br/~otuyama/stereogram/basic/index.html" rel="noopener ugc nofollow" target="_blank">https://www.ime.usp.br/~otuyama/stereogram/basic/index.html</a>T2【2】维基百科。自动立体图。<a class="ae mw" href="https://en.wikipedia.org/wiki/Autostereogram" rel="noopener ugc nofollow" target="_blank">https://en.wikipedia.org/wiki/Autostereogram</a>T5【3】<em class="mf">法比奥【波利卡波】</em>第四十一章。实时立体图。<a class="ae mw" href="https://developer.nvidia.com/sites/all/modules/custom/gpugems/books/GPUGems/gpugems_ch41.html" rel="noopener ugc nofollow" target="_blank">https://developer . NVIDIA . com/sites/all/modules/custom/GPU gems/books/GPU gems/GPU gems _ ch 41 . html</a><br/>【4】ran ftl等人的《走向鲁棒的单目深度估计:混合数据集进行零炮跨数据集传输<a class="ae mw" href="https://arxiv.org/abs/1907.01341" rel="noopener ugc nofollow" target="_blank">https://arxiv.org/abs/1907.01341</a></p></div></div>    
</body>
</html>