<html>
<head>
<title>Step by Step Guide to Make Inferences from a Deep Learning at the Edge</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">一步一步的指导在边缘深度学习中举一反三</h1>
<blockquote>原文：<a href="https://pub.towardsai.net/step-by-step-guide-to-make-inferences-from-a-deep-learning-at-the-edge-c1b18ee8ba2c?source=collection_archive---------3-----------------------#2020-09-17">https://pub.towardsai.net/step-by-step-guide-to-make-inferences-from-a-deep-learning-at-the-edge-c1b18ee8ba2c?source=collection_archive---------3-----------------------#2020-09-17</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><h2 id="9caa" class="ir is it bd b dl iu iv iw ix iy iz dk ja translated" aria-label="kicker paragraph"><a class="ae ep" href="https://towardsai.net/p/category/machine-learning/deep-learning" rel="noopener ugc nofollow" target="_blank">深度学习</a></h2><div class=""/><div class=""><h2 id="daa1" class="pw-subtitle-paragraph jz jc it bd b ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq dk translated">了解使用TPU USB加速器在边缘部署深度学习模型的步骤</h2></div><p id="bae5" class="pw-post-body-paragraph kr ks it kt b ku kv kd kw kx ky kg kz la lb lc ld le lf lg lh li lj lk ll lm im bi translated"><strong class="kt jd"> <em class="ln">在本文中，您将学习在Tensorflow中创建深度学习模型，创建一个训练后量化的tflite模型，然后为一个Edge TPU设备进行编译。</em> </strong></p><p id="45ab" class="pw-post-body-paragraph kr ks it kt b ku kv kd kw kx ky kg kz la lb lc ld le lf lg lh li lj lk ll lm im bi translated">随着工厂或社区中使用的物联网设备的出现，我们正处于一个以信息为中心的时代。从这些物联网设备生成的数据成倍增加了对计算能力和近实时推理的需求。</p><p id="6fb6" class="pw-post-body-paragraph kr ks it kt b ku kv kd kw kx ky kg kz la lb lc ld le lf lg lh li lj lk ll lm im bi translated"><a class="ae lo" href="https://towardsdatascience.com/edge-computation-101-2c1823656940" rel="noopener" target="_blank"> <strong class="kt jd">边缘计算</strong> </a> <strong class="kt jd">直接在生成数据的设备上完成，这降低了对网络的依赖性，从而减少了延迟。数据也是安全的，因为它不会传输到其他设备或网络进行处理。</strong></p><p id="aee6" class="pw-post-body-paragraph kr ks it kt b ku kv kd kw kx ky kg kz la lb lc ld le lf lg lh li lj lk ll lm im bi translated">这里使用的数据集是来自Kaggle的<a class="ae lo" href="https://www.kaggle.com/puneet6060/intel-image-classification/version/2" rel="noopener ugc nofollow" target="_blank">英特尔图像分类</a></p><p id="3a48" class="pw-post-body-paragraph kr ks it kt b ku kv kd kw kx ky kg kz la lb lc ld le lf lg lh li lj lk ll lm im bi translated">数据集有6类:<strong class="kt jd">建筑、森林、冰川、山脉、海洋和街道</strong></p><p id="ea94" class="pw-post-body-paragraph kr ks it kt b ku kv kd kw kx ky kg kz la lb lc ld le lf lg lh li lj lk ll lm im bi translated">简而言之，我们将按照这些<strong class="kt jd">步骤在边缘TPU设备</strong>上部署模型</p><figure class="lq lr ls lt gt lu gh gi paragraph-image"><div class="gh gi lp"><img src="../Images/84803d1042d3b25a90ec12d5f7e437bc.png" data-original-src="https://miro.medium.com/v2/resize:fit:1074/format:webp/1*_G_4aPOCyaHWySeMqFlFAA.png"/></div></figure><ol class=""><li id="2ecf" class="lx ly it kt b ku kv kx ky la lz le ma li mb lm mc md me mf bi translated"><strong class="kt jd">创建模型</strong></li><li id="8078" class="lx ly it kt b ku mg kx mh la mi le mj li mk lm mc md me mf bi translated"><strong class="kt jd">训练模型</strong></li><li id="094b" class="lx ly it kt b ku mg kx mh la mi le mj li mk lm mc md me mf bi translated"><strong class="kt jd">保存模型</strong></li><li id="c73c" class="lx ly it kt b ku mg kx mh la mi le mj li mk lm mc md me mf bi translated"><strong class="kt jd">应用培训后量化</strong></li><li id="ce04" class="lx ly it kt b ku mg kx mh la mi le mj li mk lm mc md me mf bi translated"><strong class="kt jd">将模型转换为TensorFlow Lite版本</strong></li><li id="fc35" class="lx ly it kt b ku mg kx mh la mi le mj li mk lm mc md me mf bi translated"><strong class="kt jd">使用edge TPU编译器编译tflite模型，用于Coral Dev board等Edge TPU设备到TPU USB加速器</strong></li><li id="6695" class="lx ly it kt b ku mg kx mh la mi le mj li mk lm mc md me mf bi translated"><strong class="kt jd">在边缘部署模型进行推理</strong></li></ol><p id="f11f" class="pw-post-body-paragraph kr ks it kt b ku kv kd kw kx ky kg kz la lb lc ld le lf lg lh li lj lk ll lm im bi translated"><strong class="kt jd">通过两个选项可以对TPU进行边缘推断</strong></p><ol class=""><li id="e8c4" class="lx ly it kt b ku kv kx ky la lz le ma li mb lm mc md me mf bi translated"><strong class="kt jd">边缘TPU API或</strong></li><li id="d80f" class="lx ly it kt b ku mg kx mh la mi le mj li mk lm mc md me mf bi translated"><strong class="kt jd"> TensorFlow Lite API </strong></li></ol><p id="b77a" class="pw-post-body-paragraph kr ks it kt b ku kv kd kw kx ky kg kz la lb lc ld le lf lg lh li lj lk ll lm im bi translated"><strong class="kt jd">T41】</strong></p><h2 id="8bdd" class="ml mm it bd mn mo mp dn mq mr ms dp mt la mu mv mw le mx my mz li na nb nc iz bi translated"><strong class="ak">第一步:使用TensorFlow 1.15或更高版本创建深度学习模型。</strong></h2><p id="e975" class="pw-post-body-paragraph kr ks it kt b ku nd kd kw kx ne kg kz la nf lc ld le ng lg lh li nh lk ll lm im bi translated"><strong class="kt jd">导入所需的库</strong></p><pre class="lq lr ls lt gt ni nj nk nl aw nm bi"><span id="1378" class="ml mm it nj b gy nn no l np nq">from numpy.random import seed<br/>import random</span><span id="ed77" class="ml mm it nj b gy nr no l np nq"><strong class="nj jd">import numpy as np<br/>import pandas as pd<br/>import os <br/>import glob<br/>import shutil</strong></span><span id="dc68" class="ml mm it nj b gy nr no l np nq"><strong class="nj jd">from PIL import Image<br/>import tensorflow as tf<br/>from tensorflow.keras.models import Sequential<br/>from tensorflow.keras.layers import Dense, Conv2D, Flatten, Dropout, MaxPooling2D, BatchNormalization<br/>from tensorflow.keras.preprocessing.image import ImageDataGenerator, img_to_array, load_img, array_to_img<br/>from tensorflow.keras.models import load_model<br/>from tensorflow.keras import optimizers, callbacks<br/>import tensorflow_model_optimization as tfmot</strong></span></pre><p id="ed7c" class="pw-post-body-paragraph kr ks it kt b ku kv kd kw kx ky kg kz la lb lc ld le lf lg lh li lj lk ll lm im bi translated"><strong class="kt jd">创建训练和验证数据集</strong></p><pre class="lq lr ls lt gt ni nj nk nl aw nm bi"><span id="9cfa" class="ml mm it nj b gy nn no l np nq">#setting the train, test and val directories<br/><strong class="nj jd">train_dir = r'\Intel_Images\seg_train\seg_train'<br/>test_dir = r'\Intel_Images\seg_pred'<br/>val_dir = r'\Intel_Images\seg_test\seg_test'</strong></span><span id="15a4" class="ml mm it nj b gy nr no l np nq">#setting basic parameters for the model<br/><strong class="nj jd">IMG_WIDTH=100<br/>IMG_HEIGHT=100<br/>IMG_DIM = (IMG_HEIGHT, IMG_WIDTH)<br/>input_shape = (IMG_HEIGHT, IMG_WIDTH ,3)<br/>batch_size = 4<br/>epochs = 25</strong></span><span id="6c1a" class="ml mm it nj b gy nr no l np nq">#Apply image Augmentation to the Training dataset<br/>#will generate batches of tensor image data with real-time data augmentation<br/><strong class="nj jd">image_gen_train = ImageDataGenerator(rescale=1./255,                                     zoom_range=0.3, rotation_range=25,                                    shear_range=0.1,featurewise_std_normalization=False)</strong></span><span id="b914" class="ml mm it nj b gy nr no l np nq"><strong class="nj jd">train_data_gen = image_gen_train.flow_from_directory(batch_size=batch_size,                                                     directory=train_dir,                                                     shuffle=True,                                                     target_size=IMG_DIM,                                                     class_mode='sparse')</strong></span><span id="8f5f" class="ml mm it nj b gy nr no l np nq">#Generate the validation dataset<br/><strong class="nj jd">image_gen_val = ImageDataGenerator(rescale=1./255)</strong></span><span id="3ebd" class="ml mm it nj b gy nr no l np nq"><strong class="nj jd">val_data_gen = image_gen_val.flow_from_directory(batch_size=batch_size,<br/>directory=val_dir,                                                 target_size=IMG_DIM,                                                 class_mode='sparse')</strong></span></pre><p id="da43" class="pw-post-body-paragraph kr ks it kt b ku kv kd kw kx ky kg kz la lb lc ld le lf lg lh li lj lk ll lm im bi translated">打印类名和类索引</p><pre class="lq lr ls lt gt ni nj nk nl aw nm bi"><span id="1022" class="ml mm it nj b gy nn no l np nq"><strong class="nj jd">class_names = list(train_data_gen.class_indices.keys())<br/>print(train_data_gen.class_indices)</strong></span></pre><figure class="lq lr ls lt gt lu gh gi paragraph-image"><div role="button" tabindex="0" class="nt nu di nv bf nw"><div class="gh gi ns"><img src="../Images/aacd26c309699c8fcd8f41f0e1e13198.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*xF5pdSQBzHqGVfHedTSVSw.png"/></div></div></figure><h2 id="773c" class="ml mm it bd mn mo mp dn mq mr ms dp mt la mu mv mw le mx my mz li na nb nc iz bi translated">步骤2:创建模型，编译和训练模型</h2><pre class="lq lr ls lt gt ni nj nk nl aw nm bi"><span id="4d77" class="ml mm it nj b gy nn no l np nq">#Create the deep learning model for 6 classes<strong class="nj jd"><br/>model = Sequential()<br/>model.add(Conv2D(16, kernel_size=(3, 3), activation='relu', <br/>                 input_shape=(IMG_HEIGHT, IMG_WIDTH ,3)))<br/>model.add(MaxPooling2D(pool_size=(2, 2)))<br/>model.add(Conv2D(64, kernel_size=(3, 3), activation='relu'))<br/>model.add(MaxPooling2D(pool_size=(2, 2)))<br/>model.add(Dropout(0.2))<br/>model.add(Conv2D(128, kernel_size=(3, 3), activation='relu'))<br/>model.add(MaxPooling2D(pool_size=(2, 2)))<br/>model.add(Flatten())<br/>model.add(Dense(128, activation='relu'))<br/>model.add(Dropout(0.2))<br/>model.add(Dense(6, activation='softmax'))</strong></span><span id="e74e" class="ml mm it nj b gy nr no l np nq">#Compile the model using Adam optimizer<br/><strong class="nj jd">model.compile(optimizer=optimizers.Adam(lr=0.0001),<br/>              loss='sparse_categorical_crossentropy',<br/>              metrics=['accuracy'])</strong></span><span id="e91a" class="ml mm it nj b gy nr no l np nq"># Train the model<br/><strong class="nj jd">history = model.fit_generator(<br/>    train_data_gen,<br/>    steps_per_epoch=len(train_data_gen)/batch_size,<br/>    epochs=10,<br/>    validation_data=val_data_gen,<br/>    validation_steps=len(val_data_gen)/batch_size<br/>)</strong></span></pre><p id="79c0" class="pw-post-body-paragraph kr ks it kt b ku kv kd kw kx ky kg kz la lb lc ld le lf lg lh li lj lk ll lm im bi translated">我已经训练这个模型50个纪元了。</p><p id="31dd" class="pw-post-body-paragraph kr ks it kt b ku kv kd kw kx ky kg kz la lb lc ld le lf lg lh li lj lk ll lm im bi translated">可视化50个时期的训练和验证数据集的准确性。</p><pre class="lq lr ls lt gt ni nj nk nl aw nm bi"><span id="a649" class="ml mm it nj b gy nn no l np nq"><strong class="nj jd">acc = history.history['acc']<br/>val_acc = history.history['val_acc']</strong></span><span id="dce6" class="ml mm it nj b gy nr no l np nq"><strong class="nj jd">loss = history.history['loss']<br/>val_loss = history.history['val_loss']</strong></span><span id="1a2b" class="ml mm it nj b gy nr no l np nq"><strong class="nj jd">epochs_range = range(epochs)</strong></span><span id="0f25" class="ml mm it nj b gy nr no l np nq"><strong class="nj jd">plt.figure(figsize=(8, 8))<br/>plt.subplot(1, 2, 1)<br/>plt.plot(epochs_range, acc, label='Training Accuracy')<br/>plt.plot(epochs_range, val_acc, label='Validation Accuracy')<br/>plt.legend(loc='lower right')<br/>plt.title('Training and Validation Accuracy')</strong></span></pre><figure class="lq lr ls lt gt lu gh gi paragraph-image"><div class="gh gi nx"><img src="../Images/3c7bdc1cbc7dd17f666ab2578b28ff24.png" data-original-src="https://miro.medium.com/v2/resize:fit:804/format:webp/1*B2vcgY8YSwMzXWTkGz0HyA.png"/></div></figure><p id="dbce" class="pw-post-body-paragraph kr ks it kt b ku kv kd kw kx ky kg kz la lb lc ld le lf lg lh li lj lk ll lm im bi translated"><strong class="kt jd">使用测试数据集测试模型，使用一些随机图像</strong></p><pre class="lq lr ls lt gt ni nj nk nl aw nm bi"><span id="fbd6" class="ml mm it nj b gy nn no l np nq">#printing class names<br/><strong class="nj jd">class_names = list(train_data_gen.class_indices.keys())</strong></span><span id="9055" class="ml mm it nj b gy nr no l np nq"># Creating the test dataset<br/><strong class="nj jd">test_data_gen = image_gen_val.flow_from_directory(batch_size=1,<br/>                                                 directory=test_dir,<br/>                                               target_size=IMG_DIM,<br/>                                               class_mode='sparse')</strong></span></pre><p id="80c4" class="pw-post-body-paragraph kr ks it kt b ku kv kd kw kx ky kg kz la lb lc ld le lf lg lh li lj lk ll lm im bi translated"><strong class="kt jd">预测来自测试数据生成器的前10幅图像</strong></p><pre class="lq lr ls lt gt ni nj nk nl aw nm bi"><span id="9994" class="ml mm it nj b gy nn no l np nq"><strong class="nj jd">#predicting 10 images from test_data_gen<br/>nb_samples = 10<br/>predict = model.predict_generator(test_data_gen,steps = nb_samples)</strong></span><span id="7379" class="ml mm it nj b gy nr no l np nq"><strong class="nj jd">pred_idx = []<br/>for index, result in enumerate(predict, 0):<br/>    pred_idx.append(class_names[np.argmax(predict[index])])<br/>    print("Pred==",class_names[np.argmax(predict[index])] + "  Filename: " + test_data_gen.filenames[index])</strong></span></pre><figure class="lq lr ls lt gt lu gh gi paragraph-image"><div class="gh gi ny"><img src="../Images/cd4406b694bae3500d03bd014cd0a834.png" data-original-src="https://miro.medium.com/v2/resize:fit:1190/format:webp/1*K1d82jBN7AkalXKoj5GJeA.png"/></div></figure><h2 id="f77c" class="ml mm it bd mn mo mp dn mq mr ms dp mt la mu mv mw le mx my mz li na nb nc iz bi translated"><strong class="ak">第三步:保存模型</strong></h2><p id="8c43" class="pw-post-body-paragraph kr ks it kt b ku nd kd kw kx ne kg kz la nf lc ld le ng lg lh li nh lk ll lm im bi translated">保存的模型在单个文件中序列化模型的架构、权重和偏差以及训练配置。保存的模型可以很容易地用于共享或部署模型。</p><pre class="lq lr ls lt gt ni nj nk nl aw nm bi"><span id="0bf2" class="ml mm it nj b gy nn no l np nq"><strong class="nj jd">model.save('Intel_epoch50_batch16.h5')</strong></span></pre><p id="1a8f" class="pw-post-body-paragraph kr ks it kt b ku kv kd kw kx ky kg kz la lb lc ld le lf lg lh li lj lk ll lm im bi translated"><strong class="kt jd">步骤4:应用训练后量化</strong></p><p id="84d7" class="pw-post-body-paragraph kr ks it kt b ku kv kd kw kx ky kg kz la lb lc ld le lf lg lh li lj lk ll lm im bi translated">我们将量化应用于模型，因为边缘的模型需要轻量级以实现低延迟。轻量级模型减少了进行推理所需的计算量。</p><p id="472d" class="pw-post-body-paragraph kr ks it kt b ku kv kd kw kx ky kg kz la lb lc ld le lf lg lh li lj lk ll lm im bi translated"><strong class="kt jd"> TFlite量化模型</strong></p><ul class=""><li id="eec2" class="lx ly it kt b ku kv kx ky la lz le ma li mb lm nz md me mf bi translated"><strong class="kt jd">在边缘设备上占用更少空间。</strong></li><li id="cbce" class="lx ly it kt b ku mg kx mh la mi le mj li mk lm nz md me mf bi translated"><strong class="kt jd">在带宽较低的网络上下载速度较快</strong></li><li id="01ba" class="lx ly it kt b ku mg kx mh la mi le mj li mk lm nz md me mf bi translated"><strong class="kt jd">占用更少的内存，让模型更快地做出推论</strong></li></ul><p id="bf7b" class="pw-post-body-paragraph kr ks it kt b ku kv kd kw kx ky kg kz la lb lc ld le lf lg lh li lj lk ll lm im bi translated"><strong class="kt jd">T19】</strong></p><p id="1ca8" class="pw-post-body-paragraph kr ks it kt b ku kv kd kw kx ky kg kz la lb lc ld le lf lg lh li lj lk ll lm im bi translated">TensorFlow保存的模型存储了包含计算操作、激活函数、权重和偏差的图表。激活函数、权重和偏差是32位浮点。</p><p id="1313" class="pw-post-body-paragraph kr ks it kt b ku kv kd kw kx ky kg kz la lb lc ld le lf lg lh li lj lk ll lm im bi translated"><strong class="kt jd">量化将用于表示张量流模型不同参数的数字的精度从float 32(32位浮点)降低到int(8位)，这使得模型变得轻量级</strong></p><p id="302d" class="pw-post-body-paragraph kr ks it kt b ku kv kd kw kx ky kg kz la lb lc ld le lf lg lh li lj lk ll lm im bi translated"><strong class="kt jd">权重和激活都可以通过转换为整数来量化，这将提供低延迟、更小的尺寸和降低的功耗。</strong></p><p id="7819" class="pw-post-body-paragraph kr ks it kt b ku kv kd kw kx ky kg kz la lb lc ld le lf lg lh li lj lk ll lm im bi translated">下面的决策树将指导您了解哪种培训后量化最适合您的用例</p><figure class="lq lr ls lt gt lu gh gi paragraph-image"><div role="button" tabindex="0" class="nt nu di nv bf nw"><div class="gh gi oa"><img src="../Images/11457aac62186389da227034552fafeb.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*F78YM0aX4o9PbR-mlMlcww.png"/></div></div><figcaption class="ob oc gj gh gi od oe bd b be z dk translated">来源:<a class="ae lo" href="https://www.tensorflow.org/lite/performance/post_training_quantization#full_integer_quantization_of_weights_and_activations" rel="noopener ugc nofollow" target="_blank">https://www . tensor flow . org/lite/performance/post _ training _ quantization # full _ integer _ quantization _ of _ weights _ and _ activations</a></figcaption></figure><p id="3f3b" class="pw-post-body-paragraph kr ks it kt b ku kv kd kw kx ky kg kz la lb lc ld le lf lg lh li lj lk ll lm im bi translated">我们将创建一个代表性数据集，并对输入和输出实施全整数量化。</p><p id="4e2d" class="pw-post-body-paragraph kr ks it kt b ku kv kd kw kx ky kg kz la lb lc ld le lf lg lh li lj lk ll lm im bi translated">代表性数据集有助于获得准确的激活动态范围。为了支持多个输入，每个代表性数据点都是一个列表，列表中的每个元素都根据其索引提供给模型</p><pre class="lq lr ls lt gt ni nj nk nl aw nm bi"><span id="08c6" class="ml mm it nj b gy nn no l np nq"><strong class="nj jd">def representative_data_gen():<br/>  dataset_list = tf.data.Dataset.list_files(test_dir + '\\*')<br/>  for i in range(100):<br/>    image = next(iter(dataset_list))<br/>    image = tf.io.read_file(image)<br/>    image = tf.io.decode_jpeg(image, channels=3)<br/>    image = tf.image.resize(image, (100,100))<br/>    image = tf.cast(image / 255., tf.float32)<br/>    image = tf.expand_dims(image, 0)</strong></span><span id="5b2a" class="ml mm it nj b gy nr no l np nq"># Model has only one input so each data point has one element<br/>    <strong class="nj jd">yield [image]</strong></span></pre><h2 id="e79b" class="ml mm it bd mn mo mp dn mq mr ms dp mt la mu mv mw le mx my mz li na nb nc iz bi translated">步骤5:转换为Tflite版本</h2><pre class="lq lr ls lt gt ni nj nk nl aw nm bi"><span id="c639" class="ml mm it nj b gy nn no l np nq"><strong class="nj jd">keras_model='Intel_epoch50_batch16.h5'</strong></span><span id="32c7" class="ml mm it nj b gy nr no l np nq">#For loading the saved model and tf.compat.v1 is for compatibility with TF1.15<strong class="nj jd"><br/>converter=tf.compat.v1.lite.TFLiteConverter.from_keras_model_file(keras_model)  </strong></span><span id="8368" class="ml mm it nj b gy nr no l np nq"># This enables quantization<br/><strong class="nj jd">converter.optimizations = [tf.lite.Optimize.DEFAULT]</strong></span><span id="6c21" class="ml mm it nj b gy nr no l np nq"># This ensures that if any ops can't be quantized, the converter throws an error<br/><strong class="nj jd">converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS_INT8]</strong></span><span id="717b" class="ml mm it nj b gy nr no l np nq"># Set the input and output tensors to uint8<br/><strong class="nj jd">converter.inference_input_type = tf.uint8<br/>converter.inference_output_type = tf.uint8</strong></span><span id="4dfa" class="ml mm it nj b gy nr no l np nq"># set the representative dataset for the converter so we can quantize the activations<br/><strong class="nj jd">converter.representative_dataset = representative_data_gen<br/>tflite_model = converter.convert()</strong></span><span id="6743" class="ml mm it nj b gy nr no l np nq">#write the quantized tflite model to a file<br/><strong class="nj jd">with open('Intel_class.tflite', 'wb') as f:<br/>  f.write(tflite_model)</strong></span><span id="dc5d" class="ml mm it nj b gy nr no l np nq">with open('Intel_epoch50_batch16.tflite', 'wb') as f:<br/>  f.write(tflite_model)</span></pre><figure class="lq lr ls lt gt lu gh gi paragraph-image"><div role="button" tabindex="0" class="nt nu di nv bf nw"><div class="gh gi of"><img src="../Images/3489483c566a505391c26bdb8f37fb07.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*pKFQAXPRNkXBq0hsNQJwLg.png"/></div></div></figure><p id="ab5f" class="pw-post-body-paragraph kr ks it kt b ku kv kd kw kx ky kg kz la lb lc ld le lf lg lh li lj lk ll lm im bi translated">您可以看到保存的Keras模型和tflite模型之间巨大的大小差异</p><h2 id="f0ee" class="ml mm it bd mn mo mp dn mq mr ms dp mt la mu mv mw le mx my mz li na nb nc iz bi translated">步骤6:使用edge TPU编译器编译tflite模型</h2><p id="eb69" class="pw-post-body-paragraph kr ks it kt b ku nd kd kw kx ne kg kz la nf lc ld le ng lg lh li nh lk ll lm im bi translated">为了给<a class="ae lo" href="https://coral.ai/docs/edgetpu/api-intro/#install-the-library-and-examples" rel="noopener ugc nofollow" target="_blank"> Edge TPU </a>编译Tflite模型，我们需要完成以下安装。</p><pre class="lq lr ls lt gt ni nj nk nl aw nm bi"><span id="f220" class="ml mm it nj b gy nn no l np nq"># Install compiler<br/><strong class="nj jd">! curl https://packages.cloud.google.com/apt/doc/apt-key.gpg | sudo apt-key add -</strong></span><span id="08c0" class="ml mm it nj b gy nr no l np nq"><strong class="nj jd">! echo "deb https://packages.cloud.google.com/apt coral-edgetpu-stable main" | sudo tee /etc/apt/sources.list.d/coral-edgetpu.list</strong></span><span id="d0f9" class="ml mm it nj b gy nr no l np nq"><strong class="nj jd">! sudo apt-get update</strong></span><span id="5b5c" class="ml mm it nj b gy nr no l np nq"><strong class="nj jd">! sudo apt-get install edgetpu-compiler</strong></span></pre><p id="b625" class="pw-post-body-paragraph kr ks it kt b ku kv kd kw kx ky kg kz la lb lc ld le lf lg lh li lj lk ll lm im bi translated">然后使用Edge TPU编译器编译TFlite模型</p><figure class="lq lr ls lt gt lu gh gi paragraph-image"><div role="button" tabindex="0" class="nt nu di nv bf nw"><div class="gh gi og"><img src="../Images/3e0f513d9c421af4881baaf5e3b3804a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*IrEyY_6g_p32QCr84Wqkew.png"/></div></div></figure><p id="5bdf" class="pw-post-body-paragraph kr ks it kt b ku kv kd kw kx ky kg kz la lb lc ld le lf lg lh li lj lk ll lm im bi translated">这将生成两个文件，一个Edgetpu tflite和一个日志文件。</p><figure class="lq lr ls lt gt lu gh gi paragraph-image"><div role="button" tabindex="0" class="nt nu di nv bf nw"><div class="gh gi oh"><img src="../Images/e241d5d492afb8989996e0130a5473f7.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*_wYt3AJ9Q6pwL89iIAs6nA.png"/></div></div></figure><p id="1e9e" class="pw-post-body-paragraph kr ks it kt b ku kv kd kw kx ky kg kz la lb lc ld le lf lg lh li lj lk ll lm im bi translated">日志文件将提到有多少操作将在TPU上执行，有多少操作将在CPU上运行。</p><figure class="lq lr ls lt gt lu gh gi paragraph-image"><div role="button" tabindex="0" class="nt nu di nv bf nw"><div class="gh gi oi"><img src="../Images/6da75090a54d233c341406c8cba5c514.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*v0x1Edv8VHWuBf3gBDXorQ.png"/></div></div><figcaption class="ob oc gj gh gi od oe bd b be z dk translated">Edgetpu日志文件</figcaption></figure><p id="88c4" class="pw-post-body-paragraph kr ks it kt b ku kv kd kw kx ky kg kz la lb lc ld le lf lg lh li lj lk ll lm im bi translated"><strong class="kt jd">步骤7:在边缘部署模型进行推理</strong></p><pre class="lq lr ls lt gt ni nj nk nl aw nm bi"><span id="ddb8" class="ml mm it nj b gy nn no l np nq"><strong class="nj jd">import tflite_runtime.interpreter as tflite<br/>from tflite_runtime.interpreter import Interpreter<br/>from tflite_runtime.interpreter import load_delegate</strong><br/><strong class="nj jd"><br/>compute='TPU'<br/>test_dir=r'\images'<br/>intel_class=['buildings', 'forest', 'glacier', 'mountain', ' sea', 'street']</strong></span><span id="1a5b" class="ml mm it nj b gy nr no l np nq"><strong class="nj jd">def set_input_tensor(interpreter, input):<br/>  input_details = interpreter.get_input_details()[0]<br/>  tensor_index = input_details['index']<br/>  input_tensor = interpreter.tensor(tensor_index)()[0]<br/>  scale, zero_point = input_details['quantization']<br/>  input_tensor[:, :] = np.uint8(input / scale + zero_point)</strong><br/>  <br/><strong class="nj jd">def classify_image(interpreter, input):<br/>  set_input_tensor(interpreter, input)<br/>  interpreter.invoke()<br/>  output_details = interpreter.get_output_details()[0]<br/>  output = interpreter.get_tensor(output_details['index'])<br/>  # Outputs from the TFLite model are uint8, so we dequantize the results:<br/>  scale, zero_point = output_details['quantization']<br/>  output = scale * (output - zero_point)<br/>  top_1 = np.argmax(output)<br/>  return top_1, output</strong></span><span id="ce7d" class="ml mm it nj b gy nr no l np nq"><strong class="nj jd">for file in os.listdir(test_dir):<br/>    <br/>    image_file = os.path.join(test_dir,  file)<br/>    test_imgs=img_to_array(load_img(image_file, target_size=(100,100,3)))<br/>    test_imgs = np.array(test_imgs)<br/>    test_imgs = test_imgs.astype('float32')<br/>    test_imgs = tf.cast(test_imgs / 255., tf.float32)    <br/>    #test_imgs = tf.expand_dims(test_imgs, 0)<br/>   <br/>    if compute=='TPU': <br/>       interpreter = tflite.Interpreter('Intel_epoch50_batch16_edgetpu.tflite',<br/>                                 experimental_delegates=[tflite.load_delegate('edgetpu.dll')])<br/>    else:<br/>        interpreter = tflite.Interpreter('Intel_epoch50_batch16.tflite')<br/>    interpreter.allocate_tensors()<br/>    interpreter.get_input_details()<br/>    prediction, results = classify_image(interpreter,test_imgs )<br/>    print("File :", file, " Prediction ", intel_class[prediction])</strong></span></pre><figure class="lq lr ls lt gt lu gh gi paragraph-image"><div role="button" tabindex="0" class="nt nu di nv bf nw"><div class="gh gi oj"><img src="../Images/3ff56390a8c1484310d13f721491b4c9.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*iTR3o92goEsf9Rwyp-DU7A.png"/></div></div><figcaption class="ob oc gj gh gi od oe bd b be z dk translated">输入图像</figcaption></figure><figure class="lq lr ls lt gt lu gh gi paragraph-image"><div class="gh gi ok"><img src="../Images/7f991dcd96aac9e8d478e045fbaf1a4c.png" data-original-src="https://miro.medium.com/v2/resize:fit:832/format:webp/1*CvYvglSRplK2h0va8Sq-yQ.png"/></div><figcaption class="ob oc gj gh gi od oe bd b be z dk translated">来自边缘TPU的预测</figcaption></figure><h2 id="6214" class="ml mm it bd mn mo mp dn mq mr ms dp mt la mu mv mw le mx my mz li na nb nc iz bi translated">参考资料:</h2><div class="ol om gp gr on oo"><a href="https://www.tensorflow.org/model_optimization/guide/quantization/post_training" rel="noopener  ugc nofollow" target="_blank"><div class="op ab fo"><div class="oq ab or cl cj os"><h2 class="bd jd gy z fp ot fr fs ou fu fw jc bi translated">训练后量化|张量流模型优化</h2><div class="ov l"><h3 class="bd b gy z fp ot fr fs ou fu fw dk translated">训练后量化包括一般技术，以减少CPU和硬件加速器的延迟，处理…</h3></div><div class="ow l"><p class="bd b dl z fp ot fr fs ou fu fw dk translated">www.tensorflow.org</p></div></div><div class="ox l"><div class="oy l oz pa pb ox pc lv oo"/></div></div></a></div><div class="ol om gp gr on oo"><a href="https://www.tensorflow.org/lite/performance/post_training_integer_quant" rel="noopener  ugc nofollow" target="_blank"><div class="op ab fo"><div class="oq ab or cl cj os"><h2 class="bd jd gy z fp ot fr fs ou fu fw jc bi translated">训练后整数量化| TensorFlow Lite</h2><div class="ov l"><h3 class="bd b gy z fp ot fr fs ou fu fw dk translated">TensorFlow Lite现在支持在转换时将所有模型值(权重和激活)转换为8位整数…</h3></div><div class="ow l"><p class="bd b dl z fp ot fr fs ou fu fw dk translated">www.tensorflow.org</p></div></div><div class="ox l"><div class="pd l oz pa pb ox pc lv oo"/></div></div></a></div><div class="ol om gp gr on oo"><a href="https://coral.ai/docs/edgetpu/api-intro/#install-the-library-and-examples" rel="noopener  ugc nofollow" target="_blank"><div class="op ab fo"><div class="oq ab or cl cj os"><h2 class="bd jd gy z fp ot fr fs ou fu fw jc bi translated">边缘TPU Python API概述| Coral</h2><div class="ov l"><h3 class="bd b gy z fp ot fr fs ou fu fw dk translated">目前，我们提供了两种在边缘TPU上执行推理的独立方式:使用边缘TPU API或使用…</h3></div><div class="ow l"><p class="bd b dl z fp ot fr fs ou fu fw dk translated">coral.ai</p></div></div><div class="ox l"><div class="pe l oz pa pb ox pc lv oo"/></div></div></a></div><p id="497e" class="pw-post-body-paragraph kr ks it kt b ku kv kd kw kx ky kg kz la lb lc ld le lf lg lh li lj lk ll lm im bi translated"><a class="ae lo" href="https://colab.research.google.com/github/google-coral/tutorials/blob/master/retrain_classification_ptq_tf2.ipynb#scrollTo=w9ydAmHGHUZl" rel="noopener ugc nofollow" target="_blank">https://colab . research . Google . com/github/Google-coral/tutorials/blob/master/retrain _ classification _ ptq _ tf2 . ipynb # scroll to = w9 ydamhghuzl</a></p></div></div>    
</body>
</html>