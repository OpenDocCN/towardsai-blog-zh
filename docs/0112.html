<html>
<head>
<title>Unified Language Model Pre-training for Natural Language Understanding and Generation</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">面向自然语言理解和生成的统一语言模型预训练</h1>
<blockquote>原文：<a href="https://pub.towardsai.net/unified-language-model-pre-training-for-natural-language-understanding-and-generation-f87dc226aa2?source=collection_archive---------0-----------------------#2019-07-21">https://pub.towardsai.net/unified-language-model-pre-training-for-natural-language-understanding-and-generation-f87dc226aa2?source=collection_archive---------0-----------------------#2019-07-21</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><h2 id="f65b" class="ir is it bd b dl iu iv iw ix iy iz dk ja translated" aria-label="kicker paragraph">用UNILM拦截NLU和NLG | <a class="ae ep" href="https://towardsai.net" rel="noopener ugc nofollow" target="_blank">向AI </a></h2><div class=""/><div class=""><h2 id="c5c3" class="pw-subtitle-paragraph jz jc it bd b ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq dk translated">使用UNILM解决自然语言理解(NLU)和自然语言生成(NLG)</h2></div><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi kr"><img src="../Images/cbb85ae17c0bc71713c46d218db6dfaa.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*zF3WCaS44C91pO0d"/></div></div><figcaption class="ld le gj gh gi lf lg bd b be z dk translated">由<a class="ae lh" href="https://unsplash.com/@louishansel?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">路易·汉瑟</a>在<a class="ae lh" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>拍摄的照片</figcaption></figure><p id="ed00" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">最近最先进的NLP预训练模型也使用语言模型来学习上下文化的文本表示。从埃尔莫(彼得等人，2018)，GPT(拉德福德等人，2018)到伯特(德夫林等人，2018)，他们都使用语言模型(LM)来达到更好的结果。</p><p id="fce6" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">董等人提出了一种新的模型，UNILM，用于解决由英文维基百科和图书语料库训练的自然语言理解和自然语言生成问题。与埃尔莫(彼得等，2018)、GPT(拉德福德等，2018)和伯特(德夫林等，2018)不同，UNILM针对不同的任务实现单向语言模型(LM)、双向语言模型(LM)和序列到序列语言模型(LM)。</p><p id="f323" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">下图显示了模型的架构。ELMo应用单向(从左到右和从右到左)LSTM。GPT使用从左到右的转换器，而伯特使用双向转换器来学习文本表示。</p><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div class="gh gi me"><img src="../Images/a12e274a62462a3bffd11fd89903af1e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1000/format:webp/1*aXMe_cuUzP6_MAUZI01SUQ.png"/></div><figcaption class="ld le gj gh gi lf lg bd b be z dk translated">自然语言处理模型的比较(董等，2019)</figcaption></figure><h1 id="3f41" class="mf mg it bd mh mi mj mk ml mm mn mo mp ki mq kj mr kl ms km mt ko mu kp mv mw bi translated">体系结构</h1><p id="be93" class="pw-post-body-paragraph li lj it lk b ll mx kd ln lo my kg lq lr mz lt lu lv na lx ly lz nb mb mc md im bi translated">UNILM使用Transformer (Vaswani等人，2017年)作为主干网络，它为不同的NLP下游任务提供了三个语言模型(LM)目标。</p><h2 id="097a" class="nc mg it bd mh nd ne dn ml nf ng dp mp lr nh ni mr lv nj nk mt lz nl nm mv iz bi translated">输入表示</h2><p id="44e7" class="pw-post-body-paragraph li lj it lk b ll mx kd ln lo my kg lq lr mz lt lu lv na lx ly lz nb mb mc md im bi translated">与BERT一样，输入序列(文本)将被转换为标记嵌入、位置嵌入和段嵌入。</p><p id="93bb" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">对于令牌嵌入，<code class="fe nn no np nq b">SOS</code>将被插入作为输入的开始，而<code class="fe nn no np nq b">EOS</code>将被插入作为段的结尾。对于位置嵌入，它是指特定段的标记位置，而段可以是0(第一段)或1(第二段)。</p><h2 id="7073" class="nc mg it bd mh nd ne dn ml nf ng dp mp lr nh ni mr lv nj nk mt lz nl nm mv iz bi translated">变压器</h2><p id="539d" class="pw-post-body-paragraph li lj it lk b ll mx kd ln lo my kg lq lr mz lt lu lv na lx ly lz nb mb mc md im bi translated">该模型通过上述特征使用多层转换器来学习上下文化的文本表示。根据使用情况，您可以为不同的下游任务选择单向LM、双向LM、序列到序列LM。</p><p id="0418" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">为了训练该模型，它从文本中随机选取一个单词并进行屏蔽。模型训练的目标是通过其他标记来预测这个被屏蔽的单词。对于双向LM，训练将使用除屏蔽令牌之外的所有令牌作为功能。对于从左到右LM，左侧的所有标记都将成为输入要素。对于序列到序列LM，第一句中的所有标记和第二句中左边的所有标记成为特征。</p><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi nr"><img src="../Images/4f4f40bf1f70640ca27c1f0212059054.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*C1QVNKG4IGQUoXVv3q_mYQ.png"/></div></div><figcaption class="ld le gj gh gi lf lg bd b be z dk translated">UNILM模型架构(董等，2019)</figcaption></figure><h2 id="0513" class="nc mg it bd mh nd ne dn ml nf ng dp mp lr nh ni mr lv nj nk mt lz nl nm mv iz bi translated">三个LM目标</h2><p id="ed9c" class="pw-post-body-paragraph li lj it lk b ll mx kd ln lo my kg lq lr mz lt lu lv na lx ly lz nb mb mc md im bi translated">根据下游任务，您可以从UINLM中选择任何一种体系结构。可用的LM目标有双向LM、单向LM和序列到序列LM。</p><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi ns"><img src="../Images/1c7bf56e34929f94c86fc96f435a5197.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*ImNauqMI1aw7nOZ6IJUh7g.png"/></div></div><figcaption class="ld le gj gh gi lf lg bd b be z dk translated">各种LM目标(董等，2019)</figcaption></figure><h2 id="8f6b" class="nc mg it bd mh nd ne dn ml nf ng dp mp lr nh ni mr lv nj nk mt lz nl nm mv iz bi translated">微调模型</h2><p id="44c9" class="pw-post-body-paragraph li lj it lk b ll mx kd ln lo my kg lq lr mz lt lu lv na lx ly lz nb mb mc md im bi translated">与其他著名的NLP模型一样，最好根据您的领域数据对广义预训练模型进行微调，以获得更好的结果。由于它是由非常大的语料库训练的，所以你只需要提供一个相对较小的数据集。</p><h1 id="08a4" class="mf mg it bd mh mi mj mk ml mm mn mo mp ki mq kj mr kl ms km mt ko mu kp mv mw bi translated">实验</h1><p id="1e20" class="pw-post-body-paragraph li lj it lk b ll mx kd ln lo my kg lq lr mz lt lu lv na lx ly lz nb mb mc md im bi translated">UNILM在SQuAD、CoQA和GLUE结果方面达到了最先进的水平。</p><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div class="gh gi nt"><img src="../Images/33f2562da506c8294682530af52964af.png" data-original-src="https://miro.medium.com/v2/resize:fit:696/format:webp/1*L4kvWBddusGzPr-DjUxJ0g.png"/></div><figcaption class="ld le gj gh gi lf lg bd b be z dk translated">模特队伍成绩(董等，2019)</figcaption></figure><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div class="gh gi nu"><img src="../Images/a9dbeb861029d909ce746bfb58f651cd.png" data-original-src="https://miro.medium.com/v2/resize:fit:694/format:webp/1*tqMQGY8mvaMxkgpMJSd63w.png"/></div><figcaption class="ld le gj gh gi lf lg bd b be z dk translated">模型间的CoQA结果(董等，2019)</figcaption></figure><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi nv"><img src="../Images/f21b87c59dd953c52b8f9e7af486c50d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*mg7nfWZXB_KAx7lj-ng9KQ.png"/></div></div><figcaption class="ld le gj gh gi lf lg bd b be z dk translated">模型间的粘合结果(董等，2019)</figcaption></figure><h1 id="94ec" class="mf mg it bd mh mi mj mk ml mm mn mo mp ki mq kj mr kl ms km mt ko mu kp mv mw bi translated">喜欢学习？</h1><p id="49f6" class="pw-post-body-paragraph li lj it lk b ll mx kd ln lo my kg lq lr mz lt lu lv na lx ly lz nb mb mc md im bi translated">我是湾区的数据科学家。专注于数据科学、人工智能，尤其是NLP和平台相关领域的最新发展。欢迎在<a class="ae lh" href="https://www.linkedin.com/in/edwardma1026" rel="noopener ugc nofollow" target="_blank"> LinkedIn </a>上与<a class="ae lh" href="https://makcedward.github.io/" rel="noopener ugc nofollow" target="_blank"> me </a>联系，或者在<a class="ae lh" href="http://medium.com/@makcedward/" rel="noopener"> Medium </a>或<a class="ae lh" href="https://github.com/makcedward" rel="noopener ugc nofollow" target="_blank"> Github </a>上关注我。</p><h1 id="be7f" class="mf mg it bd mh mi mj mk ml mm mn mo mp ki mq kj mr kl ms km mt ko mu kp mv mw bi translated">延伸阅读</h1><ul class=""><li id="a617" class="nw nx it lk b ll mx lo my lr ny lv nz lz oa md ob oc od oe bi translated"><a class="ae lh" href="https://towardsdatascience.com/how-bert-leverage-attention-mechanism-and-transformer-to-learn-word-contextual-relations-5bbee1b6dbdb" rel="noopener" target="_blank">伯特</a></li></ul><h1 id="1470" class="mf mg it bd mh mi mj mk ml mm mn mo mp ki mq kj mr kl ms km mt ko mu kp mv mw bi translated">参考</h1><ul class=""><li id="a5d0" class="nw nx it lk b ll mx lo my lr ny lv nz lz oa md ob oc od oe bi translated">长度董，杨恩伟，王文伟，魏福荣，刘小玲，王玉英，高军，周明军，洪海伟<a class="ae lh" href="https://arxiv.org/pdf/1905.03197.pdf" rel="noopener ugc nofollow" target="_blank">面向自然语言理解和生成的统一语言模型预训练</a>。2019</li><li id="0313" class="nw nx it lk b ll of lo og lr oh lv oi lz oj md ob oc od oe bi translated">A.瓦斯瓦尼，n .沙泽尔，n .帕马尔，j .乌兹科雷特，l .琼斯，A. N .戈麦斯，l .凯泽。<a class="ae lh" href="https://arxiv.org/pdf/1706.03762.pdf" rel="noopener ugc nofollow" target="_blank">注意力是你所需要的全部</a>。2017</li></ul></div></div>    
</body>
</html>