<html>
<head>
<title>Web Scraping Yelp, Part 3: performing an EDA on Yelp scraped data</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">Web抓取Yelp，第3部分:对Yelp抓取的数据执行EDA</h1>
<blockquote>原文：<a href="https://pub.towardsai.net/web-scraping-yelp-part-3-performing-an-eda-on-yelp-scraped-data-176d38fee302?source=collection_archive---------3-----------------------#2021-08-26">https://pub.towardsai.net/web-scraping-yelp-part-3-performing-an-eda-on-yelp-scraped-data-176d38fee302?source=collection_archive---------3-----------------------#2021-08-26</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><h2 id="4b22" class="ir is it bd b dl iu iv iw ix iy iz dk ja translated" aria-label="kicker paragraph"><a class="ae ep" href="https://towardsai.net/p/category/nlp" rel="noopener ugc nofollow" target="_blank">自然语言处理</a></h2><div class=""/><div class=""><h2 id="fb99" class="pw-subtitle-paragraph jz jc it bd b ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq dk translated">使用自然语言处理从餐馆评论中提取相关信息。完整的代码<a class="ae kr" href="https://github.com/arditoibryan/Projects/blob/master/20210813_yelp_webscraping/web_scraping_yelp_advanced.ipynb" rel="noopener ugc nofollow" target="_blank">可在我的回购</a>。</h2></div><p id="1884" class="pw-post-body-paragraph ks kt it ku b kv kw kd kx ky kz kg la lb lc ld le lf lg lh li lj lk ll lm ln im bi translated">这是一系列文章的第三篇(这里是<a class="ae kr" rel="noopener ugc nofollow" target="_blank" href="/part-1-scraping-yelp-reviews-with-pyhton-using-beautifulsoup-a014867a1d2c">第一部分</a>、<a class="ae kr" rel="noopener ugc nofollow" target="_blank" href="/web-scraping-yelp-part-2-scaling-the-yelp-downloading-algorithm-909356d206b8">第二部分</a>)，这些文章使用beautifulsoup从Yelp中抓取餐馆评论，然后应用机器学习，目的是从数据中提取洞察力。</p><figure class="lp lq lr ls gt lt gh gi paragraph-image"><div role="button" tabindex="0" class="lu lv di lw bf lx"><div class="gh gi lo"><img src="../Images/5ba632704cccf387af5f2b8a3034e051.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*Q67ngxNbPyOVQoEN"/></div></div><figcaption class="ma mb gj gh gi mc md bd b be z dk translated">照片由<a class="ae kr" href="https://unsplash.com/@therachelstory?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">雷切尔·帕克</a>在<a class="ae kr" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上拍摄</figcaption></figure><p id="19e2" class="pw-post-body-paragraph ks kt it ku b kv kw kd kx ky kz kg la lb lc ld le lf lg lh li lj lk ll lm ln im bi translated">在上一篇文章中，我一直使用这段代码将所有评论提取到一个嵌套列表中。这篇文章深入解释了这些代码。</p><pre class="lp lq lr ls gt me mf mg mh aw mi bi"><span id="9304" class="mj mk it mf b gy ml mm l mn mo">import requests<br/>from bs4 import BeautifulSoup<br/>import time<br/>from textblob import TextBlob<br/>import pandas as pd</span><span id="95d1" class="mj mk it mf b gy mp mm l mn mo">#we use these argument to scrape the website<br/>rest_dict = [<br/>              {  "name"   : "the-cortez-raleigh",<br/>                  "link"  : "<a class="ae kr" href="https://www.yelp.com/biz/the-cortez-raleigh?osq=Restaurants&amp;start=" rel="noopener ugc nofollow" target="_blank">https://www.yelp.com/biz/the-cortez-raleigh?osq=Restaurants&amp;start=</a>",<br/>                  "pages" : 3<br/>              },<br/>              {  "name"   : "rosewater-kitchen-and-bar-raleigh",<br/>                  "link"  : "<a class="ae kr" href="https://www.yelp.com/biz/rosewater-kitchen-and-bar-raleigh?osq=Restaurants&amp;start=" rel="noopener ugc nofollow" target="_blank">https://www.yelp.com/biz/rosewater-kitchen-and-bar-raleigh?osq=Restaurants&amp;start=</a>",<br/>                  "pages" : 3<br/>              }<br/>]</span><span id="bef8" class="mj mk it mf b gy mp mm l mn mo">#scraping function<br/>def scrape(rest_list):<br/>  all_comment_list = list()<br/>  for rest in rest_list:<br/>    comment_list = list()<br/>    for pag in range(1, rest['pages']):<br/>      try:<br/>        time.sleep(5)</span><span id="ea0a" class="mj mk it mf b gy mp mm l mn mo">#URL = "<a class="ae kr" href="https://www.yelp.com/biz/the-cortez-raleigh?osq=Restaurants&amp;start=" rel="noopener ugc nofollow" target="_blank">https://www.yelp.com/biz/the-cortez-raleigh?osq=Restaurants&amp;start=</a>"+str(pag*10)+"&amp;sort_by=rating_asc"<br/>        URL = rest['link']+str(pag*10)<br/>        print(rest['name'], 'downloading page ', pag*10)<br/>        page = requests.get(URL)</span><span id="b1d2" class="mj mk it mf b gy mp mm l mn mo">#next step: parsing<br/>        soup = BeautifulSoup(page.content, 'lxml')<br/>        soup</span><span id="c485" class="mj mk it mf b gy mp mm l mn mo">for comm in soup.find("yelp-react-root").find_all("p", {"class" : "comment__373c0__Nsutg css-n6i4z7"}):<br/>          comment_list.append(comm.find("span").decode_contents())<br/>          print(comm.find("span").decode_contents())<br/>      except:<br/>        print("could not work properly!")<br/>    all_comment_list.append([comment_list, rest['name']])<br/>  return all_comment_list</span><span id="f618" class="mj mk it mf b gy mp mm l mn mo">#store all reviews in a list<br/>reviews = scrape(rest_dict)</span></pre><p id="77c4" class="pw-post-body-paragraph ks kt it ku b kv kw kd kx ky kz kg la lb lc ld le lf lg lh li lj lk ll lm ln im bi translated">正如您在代码的列表行中看到的，函数的输出已经存储在一个名为reviews的变量中。打印变量时，结果如下。</p><figure class="lp lq lr ls gt lt gh gi paragraph-image"><div role="button" tabindex="0" class="lu lv di lw bf lx"><div class="gh gi mq"><img src="../Images/2a37adcc99f712f4e39c18f127188606.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*BLocOU98bVd2Qwz9D3PFVw.png"/></div></div><figcaption class="ma mb gj gh gi mc md bd b be z dk translated">输出的屏幕截图</figcaption></figure><p id="1dae" class="pw-post-body-paragraph ks kt it ku b kv kw kd kx ky kz kg la lb lc ld le lf lg lh li lj lk ll lm ln im bi translated">嵌套列表的结构遵循以下模式:</p><pre class="lp lq lr ls gt me mf mg mh aw mi bi"><span id="ad31" class="mj mk it mf b gy ml mm l mn mo">[[[review1, review2], restaurant1], [[review1, review2], restaurant2]]</span></pre><p id="1951" class="pw-post-body-paragraph ks kt it ku b kv kw kd kx ky kz kg la lb lc ld le lf lg lh li lj lk ll lm ln im bi translated">我现在将使用熊猫将其转换成数据帧。</p><h2 id="1936" class="mj mk it bd mr ms mt dn mu mv mw dp mx lb my mz na lf nb nc nd lj ne nf ng iz bi translated">将数据转换成数据帧</h2><p id="1c58" class="pw-post-body-paragraph ks kt it ku b kv nh kd kx ky ni kg la lb nj ld le lf nk lh li lj nl ll lm ln im bi translated">现在我已经创建了一个包含评论及其对应餐馆的列表，我需要创建一个适当的数据框架来保存所有信息。</p><pre class="lp lq lr ls gt me mf mg mh aw mi bi"><span id="38ac" class="mj mk it mf b gy ml mm l mn mo">df = pd.DataFrame(reviews)</span></pre><figure class="lp lq lr ls gt lt gh gi paragraph-image"><div role="button" tabindex="0" class="lu lv di lw bf lx"><div class="gh gi nm"><img src="../Images/20b707f2a31b2adaac8a0244889fdef3.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*67r3bv7Rj7NpeYRrbkPMTQ.png"/></div></div><figcaption class="ma mb gj gh gi mc md bd b be z dk translated">从评论到df的直接转换的输出</figcaption></figure><p id="58d0" class="pw-post-body-paragraph ks kt it ku b kv kw kd kx ky kz kg la lb lc ld le lf lg lh li lj lk ll lm ln im bi translated">但是，正如您所看到的，如果我试图将这个嵌套列表直接转换成DataFrame，我将得到一列完整的列表，另一列只有一个餐馆名称。为了正确地编辑数据，我将使用一个名为explode的函数，该函数将为应用该函数的列表中的每个元素指定一行，在本例中是第0列。</p><figure class="lp lq lr ls gt lt gh gi paragraph-image"><div class="gh gi nn"><img src="../Images/339b0beebbe75e37f4f51790ade235fc.png" data-original-src="https://miro.medium.com/v2/resize:fit:776/format:webp/0*x4jehvMfeo6Pgv9d.png"/></div><figcaption class="ma mb gj gh gi mc md bd b be z dk translated">explode如何工作，有关数据转换的完整列表<a class="ae kr" rel="noopener ugc nofollow" target="_blank" href="/complete-list-of-data-manipulation-or-data-transformation-techniques-e1f693508083">请参见此链接</a></figcaption></figure><pre class="lp lq lr ls gt me mf mg mh aw mi bi"><span id="a526" class="mj mk it mf b gy ml mm l mn mo">df = df.explode(0)</span></pre><p id="5893" class="pw-post-body-paragraph ks kt it ku b kv kw kd kx ky kz kg la lb lc ld le lf lg lh li lj lk ll lm ln im bi translated">正如您从图像中看到的，数据集现在结构正确。每个评论都有对应的餐厅。</p><figure class="lp lq lr ls gt lt gh gi paragraph-image"><div role="button" tabindex="0" class="lu lv di lw bf lx"><div class="gh gi no"><img src="../Images/afe16d1e648cab13032812579f6d6228.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*fA8ki0h06um3CrWk-H7F7g.png"/></div></div><figcaption class="ma mb gj gh gi mc md bd b be z dk translated">使用分解功能后的数据帧</figcaption></figure><p id="4bf0" class="pw-post-body-paragraph ks kt it ku b kv kw kd kx ky kz kg la lb lc ld le lf lg lh li lj lk ll lm ln im bi translated">剩下要做的唯一事情是重置索引，因为当前样本仅用0和1编号。</p><pre class="lp lq lr ls gt me mf mg mh aw mi bi"><span id="1a81" class="mj mk it mf b gy ml mm l mn mo">df = df.reset_index(drop=True)<br/>df[0:10]</span></pre><figure class="lp lq lr ls gt lt gh gi paragraph-image"><div role="button" tabindex="0" class="lu lv di lw bf lx"><div class="gh gi np"><img src="../Images/426d428d3cd0d7ced934e6d22c6341e0.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*P01I5neREP5Owg17IBHYZA.png"/></div></div><figcaption class="ma mb gj gh gi mc md bd b be z dk translated">最终数据集的屏幕截图</figcaption></figure><h2 id="1118" class="mj mk it bd mr ms mt dn mu mv mw dp mx lb my mz na lf nb nc nd lj ne nf ng iz bi translated">执行情感分析以对评论进行分类</h2><p id="8e83" class="pw-post-body-paragraph ks kt it ku b kv nh kd kx ky ni kg la lb nj ld le lf nk lh li lj nl ll lm ln im bi translated">网站上的每一篇评论都已经有了一些星级来量化它，但是，我没能刮到它。为了找到丢失数据的解决方案，我将尝试执行情感分析。NLP模型的值推断将作为每次评论的星级数的替代。当然，这是一个对数据进行处理的实验，情感分析高度依赖于我们使用的模型，因为它并不总是准确的。</p><p id="a9b2" class="pw-post-body-paragraph ks kt it ku b kv kw kd kx ky kz kg la lb lc ld le lf lg lh li lj lk ll lm ln im bi translated">我将使用一个名为TextBlob的简单库，它已经有了一个针对该场合的预训练算法。因为我需要将它应用到每个评论中，所以我将首先创建一个函数，给定一个文本，它将返回从-1到1的估计情感。</p><pre class="lp lq lr ls gt me mf mg mh aw mi bi"><span id="39ad" class="mj mk it mf b gy ml mm l mn mo">def perform_sentiment(x):<br/>  testimonial = TextBlob(x)<br/>  #testimonial.sentiment (polarity, subjectvity)<br/>  testimonial.sentiment.polarity<br/>  #sentiment_list.append([sentence, testimonial.sentiment.polarity, testimonial.subjectivity])<br/>  return testimonial.sentiment.polarity</span></pre><p id="b966" class="pw-post-body-paragraph ks kt it ku b kv kw kd kx ky kz kg la lb lc ld le lf lg lh li lj lk ll lm ln im bi translated">一旦构建了函数，我就可以使用pandas上可用的apply方法来创建数据集的新列，其中包含情感分析的结果。然后，我将使用sort_values方法从负面评论开始对所有评论进行排序。</p><pre class="lp lq lr ls gt me mf mg mh aw mi bi"><span id="bed8" class="mj mk it mf b gy ml mm l mn mo">df[2] = df[0].apply(lambda x : perform_sentiment(x))<br/>df = df.sort_values(2, ascending=False)<br/>df</span></pre><p id="5f65" class="pw-post-body-paragraph ks kt it ku b kv kw kd kx ky kz kg la lb lc ld le lf lg lh li lj lk ll lm ln im bi translated">如你所见，这是最终的数据集。</p><figure class="lp lq lr ls gt lt gh gi paragraph-image"><div role="button" tabindex="0" class="lu lv di lw bf lx"><div class="gh gi nq"><img src="../Images/71f99368d16610dc6daf199c07b1dc43.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Ckxx2_qiWrQBz57vXUz_Eg.png"/></div></div><figcaption class="ma mb gj gh gi mc md bd b be z dk translated">带有相应情绪的所有评论的屏幕截图</figcaption></figure><h2 id="01bb" class="mj mk it bd mr ms mt dn mu mv mw dp mx lb my mz na lf nb nc nd lj ne nf ng iz bi translated">提取词频</h2><p id="03bf" class="pw-post-body-paragraph ks kt it ku b kv nh kd kx ky ni kg la lb nj ld le lf nk lh li lj nl ll lm ln im bi translated">为了继续我的实验，我现在将提取在数据集的一个分区中使用最频繁的单词。然而，有一个问题。有些单词有相同的词根，比如“吃”和“吃了”，但算法不会自动把它们放在同一个类别下，因为转换成二进制时它们是不同的。作为这个问题的解决方案，我将使用一种叫做词汇化的NLP预处理技术。</p><p id="2a77" class="pw-post-body-paragraph ks kt it ku b kv kw kd kx ky kz kg la lb lc ld le lf lg lh li lj lk ll lm ln im bi translated">词汇化可以提取每个现有单词的词根，排除可能的变化，并允许标准化数据。旅鼠是简单的模型，你不能自己建立，他们必须预先训练。我将使用spacy库来导入一个lemmatizer。</p><pre class="lp lq lr ls gt me mf mg mh aw mi bi"><span id="b0f8" class="mj mk it mf b gy ml mm l mn mo">!pip install spacy</span></pre><p id="01dd" class="pw-post-body-paragraph ks kt it ku b kv kw kd kx ky kz kg la lb lc ld le lf lg lh li lj lk ll lm ln im bi translated">Spacy是一个开源的NLP库，可以包含几个预训练的模型，包括一个lemmatizer。该函数将对单个文本中出现的所有单词进行词条排序，并返回文本中所有单词的频率(它们被使用的次数)。我将按升序对结果进行排序，以显示哪些词在评论集中使用得最多。</p><pre class="lp lq lr ls gt me mf mg mh aw mi bi"><span id="22a3" class="mj mk it mf b gy ml mm l mn mo">def top_frequent(text, num_words):<br/>  #frequency of most common words<br/>  import spacy<br/>  from collections import Counter</span><span id="1570" class="mj mk it mf b gy mp mm l mn mo">nlp = spacy.load("en")<br/>  text = text<br/>  <br/>  #lemmatization<br/>  doc = nlp(text)<br/>  token_list = list()<br/>  for token in doc:<br/>    #print(token, token.lemma_)<br/>    token_list.append(token.lemma_)<br/>  token_list<br/>  lemmatized = ''<br/>  for _ in token_list:<br/>    lemmatized = lemmatized + ' ' + _<br/>  lemmatized</span><span id="b192" class="mj mk it mf b gy mp mm l mn mo">#remove stopwords and punctuations<br/>  doc = nlp(lemmatized)<br/>  words = [token.text for token in doc if token.is_stop != True and token.is_punct != True]<br/>  word_freq = Counter(words)<br/>  common_words = word_freq.most_common(num_words)<br/>  return common_words</span></pre><p id="cc07" class="pw-post-body-paragraph ks kt it ku b kv kw kd kx ky kz kg la lb lc ld le lf lg lh li lj lk ll lm ln im bi translated">我不会从整个评论列表中提取最常用的词，而是只从最差的评论中提取。数据库已经排序，将最差的评论放在最上面，所以剩下要做的唯一事情就是创建一个包含所有评论的唯一字符串。我将使用一个连接函数将评论列表转换成一个字符串。</p><pre class="lp lq lr ls gt me mf mg mh aw mi bi"><span id="c304" class="mj mk it mf b gy ml mm l mn mo">text = ' '.join(list(df[0].values[0:20]))<br/>text</span><span id="1d18" class="mj mk it mf b gy mp mm l mn mo">top_frequent(text, 100)</span><span id="203d" class="mj mk it mf b gy mp mm l mn mo">[('great', 22),<br/> ('&lt;', 21),<br/> ('come', 16),<br/> ('order', 16),<br/> ('place', 14),<br/> ('little', 10),<br/> ('try', 10),<br/> ('nice', 10),<br/> ('food', 10),<br/> ('restaurant', 10),<br/> ('menu', 10),<br/> ('day', 10),<br/> ('butter', 9),<br/> ('drink', 9),<br/> ('dinner', 8),<br/> ...</span></pre></div></div>    
</body>
</html>