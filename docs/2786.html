<html>
<head>
<title>Complete Detailed Tutorial on Linear Regression in Python for Beginners</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">针对初学者的Python线性回归完整详细教程</h1>
<blockquote>原文：<a href="https://pub.towardsai.net/complete-detailed-tutorial-on-linear-regression-in-python-for-beginners-f9fa3f65faca?source=collection_archive---------0-----------------------#2022-05-26">https://pub.towardsai.net/complete-detailed-tutorial-on-linear-regression-in-python-for-beginners-f9fa3f65faca?source=collection_archive---------0-----------------------#2022-05-26</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><figure class="is it gp gr iu iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi ir"><img src="../Images/6bea4bf36921f6f4f57eaedc475505df.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*OFw4UqV3F4z21B83"/></div></div><figcaption class="jc jd gj gh gi je jf bd b be z dk translated">照片由<a class="ae jg" href="https://unsplash.com/@szutsi?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">加博尔·szűts</a>在<a class="ae jg" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上拍摄</figcaption></figure><div class=""/><div class=""><h2 id="80c8" class="pw-subtitle-paragraph kg ji jj bd b kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx dk translated">线性回归Scikit-Learn中的基本、简单和多元线性回归实现</h2></div><p id="8c49" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">线性回归是最基本的机器学习类型。它是基于我们在中学都学过的简单直线公式。虽然有很多其他更复杂和有效的机器学习算法，但从一开始就很好地学习线性回归仍然是一个好主意。因为很多其他流行的机器学习和深度学习算法都是建立在线性回归的基础上的。</p><p id="ff85" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">在本文中:</p><p id="453a" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">1.我们将讨论线性回归是如何工作的</p><p id="5aa0" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">2.使用Python的scikit-learn库处理简单的线性回归问题</p><p id="4d78" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">3.使用Scikit-learn库中的真实数据集处理多元线性回归问题。</p><blockquote class="lu"><p id="489a" class="lv lw jj bd lx ly lz ma mb mc md lt dk translated">如果您想了解如何在没有任何库的情况下用普通Python从头开始开发线性回归，请查看本页末尾的链接。</p></blockquote><h2 id="3e1c" class="me mf jj bd mg mh mi dn mj mk ml dp mm lh mn mo mp ll mq mr ms lp mt mu mv mw bi translated">先决条件</h2><p id="9150" class="pw-post-body-paragraph ky kz jj la b lb mx kk ld le my kn lg lh mz lj lk ll na ln lo lp nb lr ls lt im bi translated">你至少应该了解初级水平的python。还有，需要了解入门级别的熊猫和Matplotlib库，才能入门机器学习。</p><h2 id="ddb4" class="me mf jj bd mg mh nc dn mj mk nd dp mm lh ne mo mp ll nf mr ms lp ng mu mv mw bi translated">什么是线性回归？</h2><p id="eeef" class="pw-post-body-paragraph ky kz jj la b lb mx kk ld le my kn lg lh mz lj lk ll na ln lo lp nb lr ls lt im bi translated">用简单的语言来说，线性回归描述了因变量和自变量之间的关系。它通过拟合直线来描述这种关系。这就是为什么它是线性回归。让我们用一个数据集来理解它。看看这个数据集，我们有两个变量:体重(磅)和身高(英寸)。</p><figure class="ni nj nk nl gt iv gh gi paragraph-image"><div class="gh gi nh"><img src="../Images/8cdb2b31c4be983759d49a4e5c60dab8.png" data-original-src="https://miro.medium.com/v2/resize:fit:444/format:webp/1*LqKs_K75KK7GYoIFT7lFJg.jpeg"/></div></figure><p id="bc77" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">让我们把重量放在X轴上，把高度放在y轴上，把它们画出来。</p><figure class="ni nj nk nl gt iv gh gi paragraph-image"><div class="gh gi nm"><img src="../Images/ab5adc7bfb1195a585528dd9b6d73d96.png" data-original-src="https://miro.medium.com/v2/resize:fit:1004/format:webp/1*WF8Tcg15TTWFY9a8t2Qm7g.jpeg"/></div></figure><p id="6207" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">我们得到了点。然后如果我们通过这些点画一条最符合这些点的直线，如果我们有了体重信息，我们就可以预测身高。比如体重160 lbs，我们可以简单的从这160个点画一条直线，从同一点到y轴再画一条直线，如下图所示。这样我们就可以找到大约66英寸的高度(英寸)。</p><figure class="ni nj nk nl gt iv gh gi paragraph-image"><div class="gh gi nn"><img src="../Images/7f9bcc8eda401095ed135fb0c612c4e8.png" data-original-src="https://miro.medium.com/v2/resize:fit:982/format:webp/1*9ApG2C696C5wLYdeZTmheQ.jpeg"/></div></figure><p id="4e08" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">这里体重是自变量，身高是因变量。</p><p id="68dc" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">下面是直线公式作为复习:</p><p id="9399" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">Y = mX + C</p><p id="b109" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">在哪里，</p><p id="4ff6" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">Y是因变量(上图中高度是Y)</p><p id="1c3a" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">X是独立变量(上图中权重是X)</p><p id="7ff5" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">m是直线的斜率</p><p id="384d" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">c是Y轴截距</p><p id="50d0" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">线性回归的任务是找出“m”和“C ”,使直线最好地代表所有的点。所以，m和C称为线性回归的训练参数。对于不同的机器学习算法，训练参数是不同的。</p><p id="3e6a" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">这是线性回归基础的视频版本:</p><figure class="ni nj nk nl gt iv"><div class="bz fp l di"><div class="no np l"/></div></figure><h2 id="0d7a" class="me mf jj bd mg mh nc dn mj mk nd dp mm lh ne mo mp ll nf mr ms lp ng mu mv mw bi translated">线性回归的假设</h2><ol class=""><li id="41d5" class="nq nr jj la b lb mx le my lh ns ll nt lp nu lt nv nw nx ny bi translated">观察值是独立的:数据集中的观察值应该是使用有效的采样方法获得的，并且它们是相互独立的。</li><li id="cb7f" class="nq nr jj la b lb nz le oa lh ob ll oc lp od lt nv nw nx ny bi translated">线性相关:线性回归也需要因变量和自变量线性相关，如上图所示。如果没有，那么我们需要尝试其他的机器学习方法。</li></ol><p id="1396" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">3.正态性:数据遵循正态分布。尽管如果我们有足够大的数据集，我们不再担心正态性。</p><h2 id="0560" class="me mf jj bd mg mh nc dn mj mk nd dp mm lh ne mo mp ll nf mr ms lp ng mu mv mw bi translated">简单线性回归示例</h2><p id="73ce" class="pw-post-body-paragraph ky kz jj la b lb mx kk ld le my kn lg lh mz lj lk ll na ln lo lp nb lr ls lt im bi translated">让我们来看一个例子。对于这个例子，我将使用Seaborn著名的“iris”数据集。为此，我需要首先导入seaborn库。然后使用seaborn库中的load_dataset函数加载iris数据集。</p><pre class="ni nj nk nl gt oe of og oh aw oi bi"><span id="0352" class="me mf jj of b gy oj ok l ol om">import seaborn as sns<br/>iris = sns.load_dataset('iris')<br/>iris</span></pre><figure class="ni nj nk nl gt iv gh gi paragraph-image"><div class="gh gi on"><img src="../Images/2fd2135824159a050da5883fffb068da.png" data-original-src="https://miro.medium.com/v2/resize:fit:858/format:webp/1*flu60ZlaHmQA7Trrp7Sw_w.jpeg"/></div></figure><p id="a296" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">如您所见，iris数据集中有几个变量。对于简单的线性回归，我们只需要两个变量，我将只保留花瓣长度和花瓣宽度。</p><pre class="ni nj nk nl gt oe of og oh aw oi bi"><span id="0f07" class="me mf jj of b gy oj ok l ol om">iris = iris[['petal_length', 'petal_width']]</span></pre><p id="09cd" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">这是虹膜数据集现在的样子:</p><figure class="ni nj nk nl gt iv gh gi paragraph-image"><div class="gh gi oo"><img src="../Images/6f7e3cbae53c2c349bf02822fba2f1f1.png" data-original-src="https://miro.medium.com/v2/resize:fit:414/format:webp/1*w4bNRKbUxQlwDCDfv4Zopw.jpeg"/></div></figure><p id="c4b2" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">让我们把花瓣_长度看作自变量，花瓣_宽度看作因变量。如果我们将其与上面讨论的直线公式进行比较，花瓣长度是X，花瓣宽度是y。</p><pre class="ni nj nk nl gt oe of og oh aw oi bi"><span id="6098" class="me mf jj of b gy oj ok l ol om">X = iris['petal_length']<br/>y = iris['petal_width']</span></pre><p id="af74" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">在进入线性回归之前，我们应该检查我们的X和y是否线性相关。我将使用Matplotlib库来绘制散点图:</p><pre class="ni nj nk nl gt oe of og oh aw oi bi"><span id="b0bf" class="me mf jj of b gy oj ok l ol om">import matplotlib.pyplot as plt<br/>plt.scatter(X, y)<br/>plt.xlabel("petal length")<br/>plt.ylabel("petal width")</span></pre><figure class="ni nj nk nl gt iv gh gi paragraph-image"><div class="gh gi op"><img src="../Images/4d4c34a8bdebbb6a8f977d702f71dae9.png" data-original-src="https://miro.medium.com/v2/resize:fit:786/format:webp/1*T7xZT3y79ZP1oakMW52yQw.jpeg"/></div></figure><p id="df05" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">它表明变量之间的关系是线性的。</p><p id="20ac" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">在机器学习中，我们不使用整个数据集来开发模型。我们将数据集分成两部分。一部分用于建立称为训练集的模型，另一部分用于评估称为测试数据集的模型。</p><p id="1e69" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">保留数据集的一部分用于测试非常重要。因为我们的目标是建立一个模型，这个模型能够概括以前没有见过的数据，并且能够很好地处理这些数据。</p><p id="dd07" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">为此，我们将使用scikit-learn库中的train_test_split方法。</p><pre class="ni nj nk nl gt oe of og oh aw oi bi"><span id="359a" class="me mf jj of b gy oj ok l ol om">from sklearn.model_selection import train_test_split<br/>X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.4, random_state = 23)</span></pre><p id="ffa3" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">这里test_size 0.4意味着它将保留40%的数据用于测试目的。</p><p id="4edd" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">random_state = 23意味着如果我们使用相同的数据集并使用random_state 23，它将再次重新创建相同的训练测试分割。Random_state可以是任何其他整数。</p><p id="e81e" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">让我们来看看X_train:</p><pre class="ni nj nk nl gt oe of og oh aw oi bi"><span id="a42b" class="me mf jj of b gy oj ok l ol om">X_train</span></pre><p id="c8e7" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">输出:</p><pre class="ni nj nk nl gt oe of og oh aw oi bi"><span id="fa10" class="me mf jj of b gy oj ok l ol om">77     5.0<br/>29     1.6<br/>92     4.0<br/>23     1.7<br/>128    5.6<br/>      ... <br/>39     1.5<br/>91     4.6<br/>31     1.5<br/>40     1.3<br/>83     5.1<br/>Name: petal_length, Length: 90, dtype: float64</span></pre><p id="e7d7" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">如你所见，X_train是一个一维序列。<strong class="la jk">sk learn库中的机器学习模型以二维数据为训练特征。</strong>所以X总是需要二维，y需要一维。</p><p id="18da" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">所以，我们需要让X是二维的。这可以通过下面的简单代码来实现:</p><pre class="ni nj nk nl gt oe of og oh aw oi bi"><span id="e22c" class="me mf jj of b gy oj ok l ol om">import numpy as np<br/>X_train = np.array(X_train).reshape(-1, 1)<br/>X_train</span></pre><p id="ab18" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">这是现在X_train的一部分:</p><pre class="ni nj nk nl gt oe of og oh aw oi bi"><span id="376e" class="me mf jj of b gy oj ok l ol om">array([[5. ],<br/>       [1.6],<br/>       [4. ],<br/>       [1.7],<br/>       [5.6],<br/>       [4. ],<br/>       [4.8],<br/>       [5.6],<br/>       [5.1],<br/>       [4.9],<br/>       [1.4],<br/>       [1.6],<br/>       [5.6],<br/>       [1.4],<br/>       [1.6],<br/>       [5.5],<br/>       [5.1],<br/>       [4. ],<br/>       [1.4],</span></pre><p id="e05b" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">我们需要以同样的方式改变X_test:</p><pre class="ni nj nk nl gt oe of og oh aw oi bi"><span id="2134" class="me mf jj of b gy oj ok l ol om">X_test = np.array(X_test).reshape(-1, 1)<br/>X_test</span></pre><p id="1877" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">输出:</p><pre class="ni nj nk nl gt oe of og oh aw oi bi"><span id="d8e5" class="me mf jj of b gy oj ok l ol om">array([[5.4],<br/>       [6. ],<br/>       [4.1],<br/>       [1.5],<br/>       [5. ],<br/>       [4.9],<br/>       [1.7],<br/>       [5.5],<br/>       [1.7],<br/>       [3.6],<br/>       [4.7],<br/>       [1.6],<br/>       [5.9],<br/>       [1.5],<br/>       [1.5],<br/>       [5.1],<br/>       [4.5],<br/>       [4.7],<br/>       [6.1],<br/>       [1.4],<br/>       [5.3],<br/>       [1.4],<br/>       [1.6],<br/>       [1.3],<br/>       [5.6],</span></pre><p id="97ca" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">我们的数据准备好了。我们需要首先从scikit-learn库中导入线性回归模型。</p><pre class="ni nj nk nl gt oe of og oh aw oi bi"><span id="94f5" class="me mf jj of b gy oj ok l ol om">from sklearn.linear_model import LinearRegression</span></pre><p id="16d8" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">我将把模型的实例保存在一个变量中:</p><pre class="ni nj nk nl gt oe of og oh aw oi bi"><span id="dad5" class="me mf jj of b gy oj ok l ol om">lr = LinearRegression()</span></pre><p id="994a" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">下一步是将训练数据拟合到线性回归模型。</p><pre class="ni nj nk nl gt oe of og oh aw oi bi"><span id="a367" class="me mf jj of b gy oj ok l ol om">lr.fit(X_train, y_train)</span></pre><p id="3dbb" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">模型拟合完成。我们应该有训练参数m和C，这里是截距C:</p><pre class="ni nj nk nl gt oe of og oh aw oi bi"><span id="9445" class="me mf jj of b gy oj ok l ol om">c = lr.intercept_<br/>c</span></pre><p id="a257" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">输出:</p><pre class="ni nj nk nl gt oe of og oh aw oi bi"><span id="fa8e" class="me mf jj of b gy oj ok l ol om">-0.3511327422143744</span></pre><p id="607d" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">在机器学习语言中，我们不使用术语斜率。相反，它被称为x的系数。这是该模型的系数:</p><pre class="ni nj nk nl gt oe of og oh aw oi bi"><span id="ec61" class="me mf jj of b gy oj ok l ol om">m = lr.coef_<br/>m</span></pre><p id="29db" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">输出:</p><pre class="ni nj nk nl gt oe of og oh aw oi bi"><span id="b5f0" class="me mf jj of b gy oj ok l ol om">array([0.41684538])</span></pre><p id="8ce8" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">现在我们可以用直线公式，用X来预测' y '，因为我们的X是二维的，所以输出也是二维的。我将展平输出，使其成为一维，以便向您展示:</p><pre class="ni nj nk nl gt oe of og oh aw oi bi"><span id="1ddf" class="me mf jj of b gy oj ok l ol om">Y_pred_train = m*X_train + c<br/>Y_pred_train.flatten()</span></pre><p id="8ac8" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">输出:</p><pre class="ni nj nk nl gt oe of og oh aw oi bi"><span id="345f" class="me mf jj of b gy oj ok l ol om">array([1.73309416, 0.31581987, 1.31624878, 0.3575044 , 1.98320139,<br/>       1.31624878, 1.64972508, 1.98320139, 1.7747787 , 1.69140962,<br/>       0.23245079, 0.31581987, 1.98320139, 0.23245079, 0.31581987,<br/>       1.94151685, 1.7747787 , 1.31624878, 0.23245079, 1.35793332,<br/>       1.85814777, 1.52467147, 2.06657046, 2.40004677, 1.44130239,<br/>       0.19076625, 1.31624878, 1.69140962, 1.69140962, 1.31624878,<br/>       0.27413533, 1.52467147, 1.52467147, 1.27456424, 1.73309416,<br/>       1.64972508, 1.2328797 , 1.7747787 , 2.27499315, 2.19162408,<br/>       0.14908171, 2.02488593, 0.8994034 , 0.27413533, 2.108255  ,<br/>       1.64972508, 0.23245079, 1.52467147, 1.39961786, 1.81646324,<br/>       0.19076625, 0.06571264, 1.10782609, 0.10739718, 1.60804055,<br/>       1.39961786, 0.14908171, 2.06657046, 1.44130239, 1.52467147,<br/>       0.31581987, 2.52510038, 1.56635601, 1.7747787 , 1.98320139,<br/>       1.60804055, 0.27413533, 0.31581987, 1.94151685, 2.06657046,<br/>       1.48298693, 0.19076625, 1.81646324, 1.02445701, 2.02488593,<br/>       1.10782609, 0.19076625, 0.27413533, 0.27413533, 1.7747787 ,<br/>       0.23245079, 0.23245079, 1.69140962, 0.23245079, 1.48298693,<br/>       0.27413533, 1.56635601, 0.27413533, 0.19076625, 1.7747787 ])</span></pre><p id="8388" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">这是使用我们从模型中找到的训练参数预测的输出。</p><p id="d1ab" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">但是我们不必使用训练参数和使用公式计算输出。我们可以简单地使用预测方法来实现:</p><pre class="ni nj nk nl gt oe of og oh aw oi bi"><span id="15be" class="me mf jj of b gy oj ok l ol om">y_pred_train1 = lr.predict(X_train)<br/>y_pred_train1</span></pre><p id="950a" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">输出:</p><pre class="ni nj nk nl gt oe of og oh aw oi bi"><span id="e7fd" class="me mf jj of b gy oj ok l ol om">array([1.73309416, 0.31581987, 1.31624878, 0.3575044 , 1.98320139,<br/>       1.31624878, 1.64972508, 1.98320139, 1.7747787 , 1.69140962,<br/>       0.23245079, 0.31581987, 1.98320139, 0.23245079, 0.31581987,<br/>       1.94151685, 1.7747787 , 1.31624878, 0.23245079, 1.35793332,<br/>       1.85814777, 1.52467147, 2.06657046, 2.40004677, 1.44130239,<br/>       0.19076625, 1.31624878, 1.69140962, 1.69140962, 1.31624878,<br/>       0.27413533, 1.52467147, 1.52467147, 1.27456424, 1.73309416,<br/>       1.64972508, 1.2328797 , 1.7747787 , 2.27499315, 2.19162408,<br/>       0.14908171, 2.02488593, 0.8994034 , 0.27413533, 2.108255  ,<br/>       1.64972508, 0.23245079, 1.52467147, 1.39961786, 1.81646324,<br/>       0.19076625, 0.06571264, 1.10782609, 0.10739718, 1.60804055,<br/>       1.39961786, 0.14908171, 2.06657046, 1.44130239, 1.52467147,<br/>       0.31581987, 2.52510038, 1.56635601, 1.7747787 , 1.98320139,<br/>       1.60804055, 0.27413533, 0.31581987, 1.94151685, 2.06657046,<br/>       1.48298693, 0.19076625, 1.81646324, 1.02445701, 2.02488593,<br/>       1.10782609, 0.19076625, 0.27413533, 0.27413533, 1.7747787 ,<br/>       0.23245079, 0.23245079, 1.69140962, 0.23245079, 1.48298693,<br/>       0.27413533, 1.56635601, 0.27413533, 0.19076625, 1.7747787 ])</span></pre><p id="9614" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">让我们检查一下预测是否正确。我们可以用可视化来检查。我将在上面的花瓣长度和花瓣宽度散点图上添加X和预测的y的线图。</p><pre class="ni nj nk nl gt oe of og oh aw oi bi"><span id="37b0" class="me mf jj of b gy oj ok l ol om">import matplotlib.pyplot as plt<br/>plt.scatter(X_train, y_train)<br/>plt.plot(X_train, y_pred_train1, color ='red')<br/>plt.xlabel("petal length")<br/>plt.ylabel("petal width")</span></pre><figure class="ni nj nk nl gt iv gh gi paragraph-image"><div class="gh gi oq"><img src="../Images/672f2a1ac4f22cedda56644d3d378607.png" data-original-src="https://miro.medium.com/v2/resize:fit:798/format:webp/1*jKtXi3thUPceaVb4e8EFUg.jpeg"/></div></figure><p id="ff05" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">如图所示，预测的“y”非常符合这些点！但是我们使用训练数据进行预测，我们的模型是根据训练数据训练的。</p><p id="45dd" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">我们的目标是训练该模型，以便该模型也可以处理其他数据，而不仅仅是相同的训练数据。这就是为什么我们保留测试数据来测试模型是否也能在测试数据上工作。</p><p id="425f" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">所以，这里我会用X_test来预测y_test。</p><pre class="ni nj nk nl gt oe of og oh aw oi bi"><span id="393a" class="me mf jj of b gy oj ok l ol om">y_pred_test1 = lr.predict(X_test)<br/>y_pred_test1</span></pre><p id="2641" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">输出:</p><pre class="ni nj nk nl gt oe of og oh aw oi bi"><span id="5ff8" class="me mf jj of b gy oj ok l ol om">array([1.89983231, 2.14993954, 1.35793332, 0.27413533, 1.73309416,<br/>       1.69140962, 0.3575044 , 1.94151685, 0.3575044 , 1.14951063,<br/>       1.60804055, 0.31581987, 2.108255  , 0.27413533, 0.27413533,<br/>       1.7747787 , 1.52467147, 1.60804055, 2.19162408, 0.23245079,<br/>       1.85814777, 0.23245079, 0.31581987, 0.19076625, 1.98320139,<br/>       0.23245079, 0.44087348, 1.64972508, 1.48298693, 1.27456424,<br/>       0.27413533, 1.27456424, 0.19076625, 2.44173131, 0.27413533,<br/>       0.3575044 , 1.56635601, 1.02445701, 1.39961786, 2.14993954,<br/>       2.02488593, 0.44087348, 1.19119517, 0.23245079, 1.48298693,<br/>       1.73309416, 1.52467147, 2.31667769, 0.27413533, 1.35793332,<br/>       2.19162408, 1.89983231, 0.23245079, 1.98320139, 1.52467147,<br/>       1.60804055, 2.44173131, 1.39961786, 0.23245079, 1.7747787 ])</span></pre><p id="af93" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">我们应该检查这个预测是否也符合这些点以及训练数据:</p><pre class="ni nj nk nl gt oe of og oh aw oi bi"><span id="cdf1" class="me mf jj of b gy oj ok l ol om">import matplotlib.pyplot as plt<br/>plt.scatter(X_test, y_test)<br/>plt.plot(X_test, y_pred_test1, color ='red')<br/>plt.xlabel("petal length")<br/>plt.ylabel("petal width")</span></pre><figure class="ni nj nk nl gt iv gh gi paragraph-image"><div class="gh gi or"><img src="../Images/27f7bb69f802a48c29d93c76f1606b5d.png" data-original-src="https://miro.medium.com/v2/resize:fit:814/format:webp/1*6Bf_MRfPE1mMzI0XUHnYGw.jpeg"/></div></figure><p id="434a" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">如你所见，预测的y与数据吻合得很好。现在，如果我们有一个花瓣长度，我们将能够使用这个模型预测花瓣宽度。预测的花瓣宽度可能与原始值不完全相同。但应该够近了。</p><p id="bcc1" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">这是简单线性回归教程的视频版本:</p><figure class="ni nj nk nl gt iv"><div class="bz fp l di"><div class="no np l"/></div></figure><h2 id="770a" class="me mf jj bd mg mh nc dn mj mk nd dp mm lh ne mo mp ll nf mr ms lp ng mu mv mw bi translated">多元线性回归示例</h2><p id="c69c" class="pw-post-body-paragraph ky kz jj la b lb mx kk ld le my kn lg lh mz lj lk ll na ln lo lp nb lr ls lt im bi translated">在最后一个例子中，我们只有一个变量来预测花瓣宽度。但是在现实世界中，大部分时间我们使用几个训练特征。在这里，我们将致力于一个类似于现实世界的项目。</p><p id="f6d7" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">在这个演示中，我们将使用Kaggle的保险数据集。请随意从以下链接下载数据集:</p><div class="is it gp gr iu os"><a href="https://www.kaggle.com/datasets/awaiskaggler/insurance-csv" rel="noopener  ugc nofollow" target="_blank"><div class="ot ab fo"><div class="ou ab ov cl cj ow"><h2 class="bd jk gy z fp ox fr fs oy fu fw ji bi translated">保险Csv</h2><div class="oz l"><h3 class="bd b gy z fp ox fr fs oy fu fw dk translated">Kaggle是世界上最大的数据科学社区，拥有强大的工具和资源来帮助您实现您的数据…</h3></div><div class="pa l"><p class="bd b dl z fp ox fr fs oy fu fw dk translated">www.kaggle.com</p></div></div><div class="pb l"><div class="pc l pd pe pf pb pg ja os"/></div></div></a></div><p id="916e" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">在这个数据集中，我们总共有7列。让我们先来看看数据集:</p><pre class="ni nj nk nl gt oe of og oh aw oi bi"><span id="13cb" class="me mf jj of b gy oj ok l ol om">import pandas as pd<br/>df = pd.read_csv('insurance.csv')<br/>df</span></pre><figure class="ni nj nk nl gt iv gh gi paragraph-image"><div class="gh gi ph"><img src="../Images/5359ae60f4e34dfe36b3b19a7a4bc9fa.png" data-original-src="https://miro.medium.com/v2/resize:fit:886/format:webp/1*Ge0lLjrY32wdhu1hdtOcVg.jpeg"/></div></figure><p id="0307" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">这是保险数据集，其中最后一列是费用，我们还有另外6列。<strong class="la jk">任务将是使用其他6列来预测费用。</strong>我们称这6个其他列为特征或变量。</p><p id="50b1" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated"><strong class="la jk">线性回归公式是如何处理这么多特征的？</strong></p><p id="1415" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">当我们有多个特征时，直线公式Y = mX + C变成这样:</p><p id="3c51" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">Y = m1X1 + m2X2 + m3X3 + …。mnXn</p><p id="a501" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">正如您在公式中看到的，每个特征都有其单独的系数。因此，在这个项目中，我们有6个特征，我们也将有6个系数。</p><p id="5690" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">我们不能像简单的线性回归那样，用y对X作图。因为我们现在有太多的变数。所以，它不再是二维的了。它有如此多的维度。</p><p id="83d9" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">如果您查看数据集，它有几个具有字符串值的分类变量。sklearn库中的机器学习算法无法处理字符串值。它需要数值。因此，我将把这些分类值转换成数值。</p><pre class="ni nj nk nl gt oe of og oh aw oi bi"><span id="db60" class="me mf jj of b gy oj ok l ol om">df['sex']  =df['sex'].astype('category')<br/>df['sex'] = df['sex'].cat.codes</span><span id="c57c" class="me mf jj of b gy pi ok l ol om">df['smoker']  =df['smoker'].astype('category')<br/>df['smoker'] = df['smoker'].cat.codes</span><span id="b470" class="me mf jj of b gy pi ok l ol om">df['region']  =df['region'].astype('category')<br/>df['region'] = df['region'].cat.codes</span></pre><figure class="ni nj nk nl gt iv gh gi paragraph-image"><div class="gh gi pj"><img src="../Images/4e1751a1711506a1568bc72ab3390c0b.png" data-original-src="https://miro.medium.com/v2/resize:fit:828/format:webp/1*Nnxe-2tGAGOABXqMrFPiiQ.jpeg"/></div></figure><p id="5e8d" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">看看现在的‘df’。“性别”特征是一个分类变量，其值为“男性”或“女性”。他们现在变成了1或0。其他分类变量也以同样的方式改变。</p><p id="25c9" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">这也是检查我们是否有空值的一个好主意。因为如果数据中有空值，我们在训练模型时就会出错。</p><pre class="ni nj nk nl gt oe of og oh aw oi bi"><span id="07ea" class="me mf jj of b gy oj ok l ol om">df.isnull().sum()</span></pre><p id="9db1" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">输出:</p><pre class="ni nj nk nl gt oe of og oh aw oi bi"><span id="3131" class="me mf jj of b gy oj ok l ol om">age         0<br/>sex         0<br/>bmi         0<br/>children    0<br/>smoker      0<br/>region      0<br/>charges     0<br/>dtype: int64</span></pre><p id="5d0c" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">我们在任何列中都没有空值。</p><p id="510d" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">现在将X和y分开，因为我们将使用6个其他变量来预测“电荷”，所以我们的X将是这6个变量的总和。从数据集中，如果我们删除“价格”列，我们将得到我们的X:</p><pre class="ni nj nk nl gt oe of og oh aw oi bi"><span id="89dc" class="me mf jj of b gy oj ok l ol om">X = df.drop(columns = 'charges')<br/>X</span></pre><figure class="ni nj nk nl gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi pk"><img src="../Images/087b280b21c8d4c0ca745bfe99bd7519.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*3UrS7_PNc6rqTNmhod6_3w.jpeg"/></div></div></figure><p id="2c34" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">因为我们将预测“价格”，所以我们的“y”将是“价格”列。</p><pre class="ni nj nk nl gt oe of og oh aw oi bi"><span id="6315" class="me mf jj of b gy oj ok l ol om">y = df['charges']</span></pre><p id="c7d7" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">使用train_test_split获取训练和测试数据:</p><pre class="ni nj nk nl gt oe of og oh aw oi bi"><span id="56b4" class="me mf jj of b gy oj ok l ol om">from sklearn.model_selection import train_test_split<br/>X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3, random_state = 23)</span></pre><p id="25d2" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">我们之前已经导入了线性回归模型。所以，我们现在可以简单地使用它。现在，我将把线性回归模型保存在一个名为lr_multiple的不同变量中，并将定型数据拟合到模型中。</p><pre class="ni nj nk nl gt oe of og oh aw oi bi"><span id="c8cd" class="me mf jj of b gy oj ok l ol om">lr_multiple = LinearRegression()<br/>lr_multiple.fit(X_train, y_train)</span></pre><p id="bb8d" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">模特训练完成。现在来看看训练参数。以下是截取的内容:</p><pre class="ni nj nk nl gt oe of og oh aw oi bi"><span id="e27f" class="me mf jj of b gy oj ok l ol om">c = lr_multiple.intercept_<br/>c</span></pre><p id="2eec" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">输出:</p><pre class="ni nj nk nl gt oe of og oh aw oi bi"><span id="d345" class="me mf jj of b gy oj ok l ol om">-11827.733141795668</span></pre><p id="071e" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">斜率或系数:</p><pre class="ni nj nk nl gt oe of og oh aw oi bi"><span id="0c55" class="me mf jj of b gy oj ok l ol om">m = lr_multiple.coef_<br/>m</span></pre><p id="8001" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">输出:</p><pre class="ni nj nk nl gt oe of og oh aw oi bi"><span id="b8c6" class="me mf jj of b gy oj ok l ol om">array([  256.5772619 ,   -49.39232379,   329.02381564,   479.08499828, 23400.28378787,  -276.31576201])</span></pre><p id="242a" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">正如我之前提到的，我们得到了6个系数。</p><p id="9944" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">让我们预测训练数据和测试数据的价格:</p><pre class="ni nj nk nl gt oe of og oh aw oi bi"><span id="f585" class="me mf jj of b gy oj ok l ol om">y_pred_train = lr_multiple.predict(X_train)<br/>y_pred_test = lr_multiple.predict(X_test)</span></pre><p id="8381" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">这次我们不打算绘图，因为我们有6个特征。但我会介绍另一种评价方法。那是R2分数。</p><p id="dde5" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated"><strong class="la jk"> R2分数表示拟合度。它告诉你你的训练特征在多大程度上可以解释标签中的差异。</strong>该值可能介于0和1之间。r2_score越接近1，模型性能越好。</p><p id="dd29" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">我们需要首先导入r2_score，然后计算r2_score。它采用原始“y”值和预测“y”值。由于我们对测试数据进行预测，原始值将是y_test:</p><pre class="ni nj nk nl gt oe of og oh aw oi bi"><span id="214a" class="me mf jj of b gy oj ok l ol om">from sklearn.metrics import r2_score<br/>r2_score(y_test, y_pred_test)</span></pre><p id="a711" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">输出:</p><pre class="ni nj nk nl gt oe of og oh aw oi bi"><span id="4902" class="me mf jj of b gy oj ok l ol om">0.7911113876316933</span></pre><p id="8c23" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">我们的r2 _评分是0.79。所以，我们可以说这个模型相当强大。</p><p id="cf38" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">以下是多元线性回归教程视频版的链接:</p><figure class="ni nj nk nl gt iv"><div class="bz fp l di"><div class="no np l"/></div></figure><h2 id="6e52" class="me mf jj bd mg mh nc dn mj mk nd dp mm lh ne mo mp ll nf mr ms lp ng mu mv mw bi translated">结论</h2><p id="a09c" class="pw-post-body-paragraph ky kz jj la b lb mx kk ld le my kn lg lh mz lj lk ll na ln lo lp nb lr ls lt im bi translated">我希望，这对你来说是个好的开始。如果您对学习如何从头开始开发线性回归和其他流行的机器学习算法更感兴趣，请随时查看此链接:</p><div class="is it gp gr iu os"><a href="https://towardsdatascience.com/a-full-length-machine-learning-course-in-python-for-free-f2732954f35f" rel="noopener follow" target="_blank"><div class="ot ab fo"><div class="ou ab ov cl cj ow"><h2 class="bd jk gy z fp ox fr fs oy fu fw ji bi translated">免费的Python全长机器学习课程</h2><div class="oz l"><h3 class="bd b gy z fp ox fr fs oy fu fw dk translated">吴恩达用Python写的机器学习教程</h3></div><div class="pa l"><p class="bd b dl z fp ox fr fs oy fu fw dk translated">towardsdatascience.com</p></div></div><div class="pb l"><div class="pl l pd pe pf pb pg ja os"/></div></div></a></div><p id="7f76" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">我希望它有帮助。</p><p id="8c28" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">欢迎在推特上关注我，喜欢我的T2脸书页面。</p><h2 id="2f38" class="me mf jj bd mg mh nc dn mj mk nd dp mm lh ne mo mp ll nf mr ms lp ng mu mv mw bi translated">更多阅读</h2><div class="is it gp gr iu os"><a href="https://towardsdatascience.com/complete-explanation-on-sql-joins-and-unions-with-examples-in-postgresql-cbd868fe9e95" rel="noopener follow" target="_blank"><div class="ot ab fo"><div class="ou ab ov cl cj ow"><h2 class="bd jk gy z fp ox fr fs oy fu fw ji bi translated">用PostgreSQL中的例子完整解释SQL连接和联合</h2><div class="oz l"><h3 class="bd b gy z fp ox fr fs oy fu fw dk translated">所有常用的连接类型和一些有趣的类型</h3></div><div class="pa l"><p class="bd b dl z fp ox fr fs oy fu fw dk translated">towardsdatascience.com</p></div></div><div class="pb l"><div class="pm l pd pe pf pb pg ja os"/></div></div></a></div><div class="is it gp gr iu os"><a href="https://towardsdatascience.com/how-to-make-animated-and-racing-bar-plots-in-python-c5c7c3c648f7" rel="noopener follow" target="_blank"><div class="ot ab fo"><div class="ou ab ov cl cj ow"><h2 class="bd jk gy z fp ox fr fs oy fu fw ji bi translated">如何用Python制作动画和赛车条形图</h2><div class="oz l"><h3 class="bd b gy z fp ox fr fs oy fu fw dk translated">完整的工作代码</h3></div><div class="pa l"><p class="bd b dl z fp ox fr fs oy fu fw dk translated">towardsdatascience.com</p></div></div><div class="pb l"><div class="pn l pd pe pf pb pg ja os"/></div></div></a></div><div class="is it gp gr iu os"><a href="https://towardsdatascience.com/a-complete-guide-for-detecting-and-dealing-with-outliers-bad26b1e92b6" rel="noopener follow" target="_blank"><div class="ot ab fo"><div class="ou ab ov cl cj ow"><h2 class="bd jk gy z fp ox fr fs oy fu fw ji bi translated">检测和处理异常值的完整指南</h2><div class="oz l"><h3 class="bd b gy z fp ox fr fs oy fu fw dk translated">6种检测异常值的方法和4种处理异常值的方法</h3></div><div class="pa l"><p class="bd b dl z fp ox fr fs oy fu fw dk translated">towardsdatascience.com</p></div></div><div class="pb l"><div class="po l pd pe pf pb pg ja os"/></div></div></a></div><div class="is it gp gr iu os"><a rel="noopener  ugc nofollow" target="_blank" href="/an-overview-of-the-major-sql-query-clauses-and-most-commonly-used-functions-60720e2a20d7"><div class="ot ab fo"><div class="ou ab ov cl cj ow"><h2 class="bd jk gy z fp ox fr fs oy fu fw ji bi translated">SQL查询子句和函数概述</h2><div class="oz l"><h3 class="bd b gy z fp ox fr fs oy fu fw dk translated">可以用作SQL的备忘单</h3></div><div class="pa l"><p class="bd b dl z fp ox fr fs oy fu fw dk translated">pub.towardsai.net</p></div></div><div class="pb l"><div class="pp l pd pe pf pb pg ja os"/></div></div></a></div></div></div>    
</body>
</html>