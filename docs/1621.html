<html>
<head>
<title>Titanic Survival Prediction — II</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">泰坦尼克号生存预测-II</h1>
<blockquote>原文：<a href="https://pub.towardsai.net/titanic-survival-prediction-ii-551a9b44efa3?source=collection_archive---------6-----------------------#2021-03-05">https://pub.towardsai.net/titanic-survival-prediction-ii-551a9b44efa3?source=collection_archive---------6-----------------------#2021-03-05</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><h2 id="ac28" class="io ip iq bd b dl ir is it iu iv iw dk ix translated" aria-label="kicker paragraph"><a class="ae ep" href="https://towardsai.net/p/category/data-science" rel="noopener ugc nofollow" target="_blank">数据科学</a></h2><div class=""/><div class=""><h2 id="39c0" class="pw-subtitle-paragraph jw iz iq bd b jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn dk translated">预测谁在沉船中幸存！</h2></div><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div role="button" tabindex="0" class="ku kv di kw bf kx"><div class="gh gi ko"><img src="../Images/24d5e2c8e41b810dfd3c6947d703d52d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*M5vjzmA9VyC03qVhWbnbSA.png"/></div></div><figcaption class="la lb gj gh gi lc ld bd b be z dk translated"><a class="ae le" href="http://fireart-d.dribbble.com/" rel="noopener ugc nofollow" target="_blank">图片来源</a></figcaption></figure><p id="e66c" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">在之前的<a class="ae le" href="https://hiraakram88.medium.com/titanic-survival-prediction-i-bf5a04afff46" rel="noopener">文章</a>中，我们讨论了探索性数据分析、数据可视化和原始数据预处理的基本技术。我们还建立了对从原始数据集设计复杂新特征的方法的理解。此外，还介绍了常见的数据准备实践，如要素编码和标准缩放。</p><p id="90e8" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">在本文中，让我们简要讨论一些广泛用于二元分类的算法，以及它们在Titanic数据集上的性能。此外，我们将根据不同的指标来训练、测试和评估我们的生存预测。</p></div><div class="ab cl mb mc hu md" role="separator"><span class="me bw bk mf mg mh"/><span class="me bw bk mf mg mh"/><span class="me bw bk mf mg"/></div><div class="ij ik il im in"><h1 id="fb08" class="mi mj iq bd mk ml mm mn mo mp mq mr ms kf mt kg mu ki mv kj mw kl mx km my mz bi translated"><strong class="ak">“<em class="na">垃圾进，垃圾出</em>”有多真实？</strong></h1><p id="f3be" class="pw-post-body-paragraph lf lg iq lh b li nb ka lk ll nc kd ln lo nd lq lr ls ne lu lv lw nf ly lz ma ij bi translated">虽然建立机器学习模型并不强调选择哪种算法，而是主要关注EDA和数据挖掘，因为它们起着非常关键的作用。有时候，尽管插入了不同的算法，你的模型还是会持续给出相同的性能；不要从一种算法跳到另一种算法，建议采用以下方法:</p><ol class=""><li id="932d" class="ng nh iq lh b li lj ll lm lo ni ls nj lw nk ma nl nm nn no bi translated">使用SQL、Excel或Python/R进行一些基本的EDA，但是首选。</li><li id="2dfb" class="ng nh iq lh b li np ll nq lo nr ls ns lw nt ma nl nm nn no bi translated">估算缺失值。</li><li id="9c2b" class="ng nh iq lh b li np ll nq lo nr ls ns lw nt ma nl nm nn no bi translated">画出被认为重要的特征，并试图找到潜在的模式。</li><li id="b686" class="ng nh iq lh b li np ll nq lo nr ls ns lw nt ma nl nm nn no bi translated">对分类特征进行编码，并对连续特征进行标准化/规范化。</li><li id="818a" class="ng nh iq lh b li np ll nq lo nr ls ns lw nt ma nl nm nn no bi translated">选择一个简单的算法，直接训练模型。</li><li id="122b" class="ng nh iq lh b li np ll nq lo nr ls ns lw nt ma nl nm nn no bi translated">如果你幸运的话，你可能第一次就得到你想要的结果。在这种情况下，请重新运行模型来验证您的结果。</li><li id="a0fc" class="ng nh iq lh b li np ll nq lo nr ls ns lw nt ma nl nm nn no bi translated">如果你对第一次运行感到失望，观察模型的表现，以及你是否需要收集更多的数据或添加新的功能等。</li></ol><p id="4cdf" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated"><strong class="lh ja">注意</strong>:如果你给任何算法提供了正确的数据，你更有可能得到你想要的结果，而不必来回奔波。</p><h1 id="48d9" class="mi mj iq bd mk ml nu mn mo mp nv mr ms kf nw kg mu ki nx kj mw kl ny km my mz bi translated">二元分类器</h1><p id="2146" class="pw-post-body-paragraph lf lg iq lh b li nb ka lk ll nc kd ln lo nd lq lr ls ne lu lv lw nf ly lz ma ij bi translated">我们的目标是根据给定的特征识别乘客，如<em class="nz">年龄、SibSp、Pclass、票价</em>等。谁更有可能在沉船事故中幸存。对于这个二元分类问题，让我们训练五个分类器，并比较它们在训练数据集上的性能。</p><p id="c919" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">我们将使用以下监督学习算法，这些算法可以帮助我们在Titanic数据集上进行生存预测:</p><ul class=""><li id="f56c" class="ng nh iq lh b li lj ll lm lo ni ls nj lw nk ma oa nm nn no bi translated">随机森林分类器</li><li id="71de" class="ng nh iq lh b li np ll nq lo nr ls ns lw nt ma oa nm nn no bi translated">逻辑回归</li><li id="8944" class="ng nh iq lh b li np ll nq lo nr ls ns lw nt ma oa nm nn no bi translated">梯度推进分类器</li><li id="5877" class="ng nh iq lh b li np ll nq lo nr ls ns lw nt ma oa nm nn no bi translated">支持向量机</li><li id="9e3b" class="ng nh iq lh b li np ll nq lo nr ls ns lw nt ma oa nm nn no bi translated">朴素贝叶斯分类器</li></ul><blockquote class="ob oc od"><p id="56ba" class="lf lg nz lh b li lj ka lk ll lm kd ln oe lp lq lr of lt lu lv og lx ly lz ma ij bi translated"><strong class="lh ja"> <em class="iq">随机森林分类器</em> </strong></p></blockquote><p id="92e8" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">随机森林是一种非常灵活的集成学习算法，可用于使用bagging范式解决分类和回归问题。该算法使用替换进行随机采样，并创建数据集的多个副本。因此，在分类问题的情况下，可以通过对回归树的采样预测取平均值或者通过多数表决来获得新的预测。</p><p id="b85e" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">在我们的例子中，这个模型的整体性能在训练数据集上看起来相当不错。有了相当数量的正确预测，我们能够获得令人满意的召回和f1分数。下图是从该分类器获得的混淆矩阵:</p><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div class="gh gi oh"><img src="../Images/e3a186e2716d66f66068b84c43254d2d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1040/format:webp/1*f6gYmv6fy3HLHkiiRqvk6g.png"/></div></figure><figure class="kp kq kr ks gt kt"><div class="bz fp l di"><div class="oi oj l"/></div></figure><blockquote class="ob oc od"><p id="287a" class="lf lg nz lh b li lj ka lk ll lm kd ln oe lp lq lr of lt lu lv og lx ly lz ma ij bi translated"><strong class="lh ja"> <em class="iq">逻辑回归</em> </strong></p></blockquote><p id="da4a" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">逻辑回归属于监督学习算法类。与名称所暗示的相反，这种算法专门用于进行分类预测。它旨在输出两个可能的值，基于这两个值来定义类。一个这样的数学函数在我们期望的区间内赋值，即[0，1]被称为sigmoid。如果这个函数返回一个更接近于0的预测，我们声明它是一个负类，而如果预测更接近于1，它被认为是正的，因此是我们的目标类。</p><p id="13ab" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">通过这个模型，我们得到了一个有些相似的结果。然而，准确性确实出现了轻微的下降。有了更多的真阳性，我们的模型的精度显著提高<em class="nz">。</em>下图显示了从该模型获得的混淆矩阵:</p><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div class="gh gi oh"><img src="../Images/7d646ccc7f73534c383c37ddd5d879a4.png" data-original-src="https://miro.medium.com/v2/resize:fit:1040/format:webp/1*VEYDiwGVc9PB5wEZEY6Tlw.png"/></div></figure><figure class="kp kq kr ks gt kt"><div class="bz fp l di"><div class="oi oj l"/></div></figure><blockquote class="ob oc od"><p id="e058" class="lf lg nz lh b li lj ka lk ll lm kd ln oe lp lq lr of lt lu lv og lx ly lz ma ij bi translated"><strong class="lh ja"> <em class="iq">梯度提升分类器</em> </strong></p></blockquote><p id="4c5f" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">移动到下一个分类器，这是一种有效的集成学习算法，但与随机森林不同，该算法利用了提升技术。</p><p id="1ecd" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">从下图中可以看出，我们正确地预测了大量的真阴性和真阳性，并且该模型在precious方面也表现出色。此外，它还提供了令人惊讶的低数量的假阳性:</p><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div class="gh gi oh"><img src="../Images/17bfaf58b6cdaafe707fe83845384798.png" data-original-src="https://miro.medium.com/v2/resize:fit:1040/format:webp/1*DxphAXRBfGoegZTiwGdqOg.png"/></div></figure><figure class="kp kq kr ks gt kt"><div class="bz fp l di"><div class="oi oj l"/></div></figure><blockquote class="ob oc od"><p id="95c4" class="lf lg nz lh b li lj ka lk ll lm kd ln oe lp lq lr of lt lu lv og lx ly lz ma ij bi translated"><strong class="lh ja"> <em class="iq">支持向量机</em> </strong></p></blockquote><p id="c7f7" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">由于其潜在的数学原理，支持向量机也被称为大间隔分类器。被决策边界分开的正例和反例之间有很大的距离。因此，这个决策边界有助于更好地概括未来的例子。</p><p id="9dc2" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">如下图所示，存在大量错误预测的标签，因此在我们的情况下，该模型未能做出可接受的预测:</p><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div class="gh gi oh"><img src="../Images/468996b8216980033f2d472af75cd86f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1040/format:webp/1*-hd6O0XVYgEgTlAFfDRWyQ.png"/></div></figure><figure class="kp kq kr ks gt kt"><div class="bz fp l di"><div class="oi oj l"/></div></figure><blockquote class="ob oc od"><p id="9a25" class="lf lg nz lh b li lj ka lk ll lm kd ln oe lp lq lr of lt lu lv og lx ly lz ma ij bi translated"><strong class="lh ja"> <em class="iq">朴素贝叶斯分类器</em> </strong></p></blockquote><p id="152f" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">最后，我们使用朴素贝叶斯分类器训练数据，朴素贝叶斯分类器是一种超级简单的监督学习算法。这种分类技术背后的基本概念是假设每个特征在统计上反映了贝叶斯定理，即一个类中的每个特征彼此独立。</p><p id="38ac" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">根据从该模型得出的结果，我们观察到它不仅不能保持准确性，而且在其他指标方面效率也特别低。这从混淆矩阵和<em class="nz">图-1: </em>中可以明显看出</p><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div class="gh gi oh"><img src="../Images/570e4ca3ccccae43aea58b4c25135422.png" data-original-src="https://miro.medium.com/v2/resize:fit:1040/format:webp/1*tU2zSICa6Q27Lb3f4ildgg.png"/></div></figure><figure class="kp kq kr ks gt kt"><div class="bz fp l di"><div class="oi oj l"/></div></figure></div><div class="ab cl mb mc hu md" role="separator"><span class="me bw bk mf mg mh"/><span class="me bw bk mf mg mh"/><span class="me bw bk mf mg"/></div><div class="ij ik il im in"><h1 id="9cad" class="mi mj iq bd mk ml mm mn mo mp mq mr ms kf mt kg mu ki mv kj mw kl mx km my mz bi translated">性能比较</h1><p id="e5ac" class="pw-post-body-paragraph lf lg iq lh b li nb ka lk ll nc kd ln lo nd lq lr ls ne lu lv lw nf ly lz ma ij bi translated">通常情况下，分类器会根据各种度量标准进行评估，如精确度、召回率、F1值、准确度等等。这些帮助我们决定模型的表现如何。具体来说，如果我们只考虑一个<em class="nz"> </em>单一指标作为我们的决定因素，那么我们可能会得出不同的结论，并且总是存在一个权衡。</p><p id="ecf0" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">此外，重要的是通过多个决定因素来分析分类，以便我们对我们的选择更有信心。之前，我们分别检查了每个模型的混淆矩阵，以获得关于正确预测标签的直观视图。现在，让我们看看其他几个因素，以得出更准确的结论。从下图中可以看出，我们已经考虑了训练和测试数据集的准确性、精确度、召回率和每个模型的f1分数。然而，这些结果表明，在每种情况下，准确性数字都是相对可接受的，但当考虑其他因素时，显然'<em class="nz">随机森林分类器</em>'总体上表现更好。</p><p id="d8d7" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">下图显示了到目前为止我们训练的所有五个模型之间的完整比较:</p><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div role="button" tabindex="0" class="ku kv di kw bf kx"><div class="gh gi ok"><img src="../Images/f294fcc22d3e0f35b085f1b88fcea9dd.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*rvGbZdxtlto7yOY41dOskg.png"/></div></div><figcaption class="la lb gj gh gi lc ld bd b be z dk translated"><strong class="bd mk"> <em class="na">图-1 </em> </strong></figcaption></figure><h1 id="0d8c" class="mi mj iq bd mk ml nu mn mo mp nv mr ms kf nw kg mu ki nx kj mw kl ny km my mz bi translated">结论</h1><p id="f195" class="pw-post-body-paragraph lf lg iq lh b li nb ka lk ll nc kd ln lo nd lq lr ls ne lu lv lw nf ly lz ma ij bi translated">现在我们已经完成了模型选择，让我们继续测试阶段。随机森林还为我们提供了一个选项，将我们自己限制在对确定数据趋势有重要价值的特性上。以下是重要功能的列表:</p><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div role="button" tabindex="0" class="ku kv di kw bf kx"><div class="gh gi ol"><img src="../Images/7aa7c62a442d6ff64ac8ab919b0794cc.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*YsmzGd4lpQ98z7eB7K3LOA.png"/></div></div></figure><pre class="kp kq kr ks gt om on oo op aw oq bi"><span id="34e8" class="or mj iq on b gy os ot l ou ov">features = pd.Series(rfc.feature_importances_, index=X_train.columns).sort_values()</span><span id="4a0c" class="or mj iq on b gy ow ot l ou ov">features.plot(kind='barh', cmap='Pastel1')</span></pre><p id="3ad2" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">让我们只利用值≥ 0.06的那些，以便我们基于对在我们的数据集中搜索隐藏模式具有更高影响的特征来重新训练我们的模型。这里有一个<a class="ae le" href="https://github.com/h-i-r/Kaggle-Titanic-Survival-Competition" rel="noopener ugc nofollow" target="_blank"> GitHub </a>项目的链接供参考。</p><p id="e7dd" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">感谢阅读！^_^</p></div></div>    
</body>
</html>