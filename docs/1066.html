<html>
<head>
<title>Text Augmentation for Detecting Spear-phishing Emails</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">用于检测鱼叉式网络钓鱼电子邮件的文本增强</h1>
<blockquote>原文：<a href="https://pub.towardsai.net/text-augmentation-for-detecting-spear-phishing-emails-19c2e0623f40?source=collection_archive---------1-----------------------#2020-10-20">https://pub.towardsai.net/text-augmentation-for-detecting-spear-phishing-emails-19c2e0623f40?source=collection_archive---------1-----------------------#2020-10-20</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><h2 id="a973" class="ir is it bd b dl iu iv iw ix iy iz dk ja translated" aria-label="kicker paragraph"><a class="ae ep" href="https://towardsai.net/p/category/nlp" rel="noopener ugc nofollow" target="_blank">自然语言处理</a></h2><div class=""/><div class=""><h2 id="4f2d" class="pw-subtitle-paragraph jz jc it bd b ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq dk translated">用于网络钓鱼电子邮件检测的文本增强技术</h2></div><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi kr"><img src="../Images/74d2516e3d8a897779c7eecaee335f5a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*l0e_aLwg-eNdwexv"/></div></div><figcaption class="ld le gj gh gi lf lg bd b be z dk translated">由<a class="ae lh" href="https://unsplash.com/@souvenirpixels?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">詹姆斯·惠勒</a>在<a class="ae lh" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>拍摄的照片</figcaption></figure><p id="5704" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">信息安全对任何组织都非常重要。赔钱是小问题，严重的是企业制度。但是，与普通电子邮件相比，欺诈电子邮件和网络钓鱼电子邮件只占一小部分数据。增加欺诈和网络钓鱼邮件是解决这个问题的一种方法。</p><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi me"><img src="../Images/c2cfa64e0e3001d71aa2c2075ff5874d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*GDdeqEd_oSXMvOf5sPbbQA.png"/></div></div><figcaption class="ld le gj gh gi lf lg bd b be z dk translated">CEO欺诈邮件示例(Regina等人，2020年)</figcaption></figure><p id="bfdc" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">因此，Regina等人提出了三种不同的方法来生成用于模型训练的合成数据。由于合成数据是一种“假”数据，一些低质量的数据可能会损害模型性能。需要验证以保持高质量的合成数据。此外，还有一些假设:</p><ul class=""><li id="95ee" class="mf mg it lk b ll lm lo lp lr mh lv mi lz mj md mk ml mm mn bi translated">合成数据应该与原始文本共享相同的标签。例如，合成数据应该从正标签变为负标签(对于二元分类器)。</li><li id="5842" class="mf mg it lk b ll mo lo mp lr mq lv mr lz ms md mk ml mm mn bi translated">合成数据不应该是多余的。换句话说，扩充的文本不应该与原始文本几乎相同。</li></ul><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi mt"><img src="../Images/f5cc28c747ebfe5d96c7af4ed4782779.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*4yn-CBQpQW_sp8KUWjg13w.png"/></div></div><figcaption class="ld le gj gh gi lf lg bd b be z dk translated">上图:原文。下图:增补文本(Regina等人，2020年)</figcaption></figure><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div class="gh gi mu"><img src="../Images/c7f8b40866c41f599a73f002891bca4c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1184/format:webp/1*sAxFljgMsXOhoL6c3bTM-Q.png"/></div><figcaption class="ld le gj gh gi lf lg bd b be z dk translated">进行替换(Regina等人，2020年)</figcaption></figure><h1 id="10ea" class="mv mw it bd mx my mz na nb nc nd ne nf ki ng kj nh kl ni km nj ko nk kp nl nm bi translated">单词替换</h1><h2 id="c487" class="nn mw it bd mx no np dn nb nq nr dp nf lr ns nt nh lv nu nv nj lz nw nx nl iz bi translated">缩写替换</h2><p id="0b5b" class="pw-post-body-paragraph li lj it lk b ll ny kd ln lo nz kg lq lr oa lt lu lv ob lx ly lz oc mb mc md im bi translated">缩略语在日常会话中很常见。它让演讲者和听众能更容易地交流。比如“F/W”，“FW”就是“前进”的意思。然而，有一些模糊的场景，我们需要上下文来解释缩写。例如，“项目经理”可以解释为“项目经理”和“总理”。</p><p id="1891" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">虽然这种方法易于理解和实现，但缺点是需要逐个定义转换或映射。</p><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div class="gh gi od"><img src="../Images/1075435c870aa2795c6e556c6f6dde8d.png" data-original-src="https://miro.medium.com/v2/resize:fit:424/format:webp/1*aw6XNGgFLb_5Ur0c2bKw0A.png"/></div><figcaption class="ld le gj gh gi lf lg bd b be z dk translated">缩写替换示例</figcaption></figure><h2 id="7283" class="nn mw it bd mx no np dn nb nq nr dp nf lr ns nt nh lv nu nv nj lz nw nx nl iz bi translated">拼写错误替换</h2><p id="b74c" class="pw-post-body-paragraph li lj it lk b ll ny kd ln lo nz kg lq lr oa lt lu lv ob lx ly lz oc mb mc md im bi translated">虽然自动完成有助于纠正拼写错误，但电子邮件和社交媒体中仍然存在拼写错误。比如“bargin”就是“讨价还价”的错别字。Regina等人提到拼写错误很重要，因为:</p><ul class=""><li id="f529" class="mf mg it lk b ll lm lo lp lr mh lv mi lz mj md mk ml mm mn bi translated">拼写错误会传达一种紧迫感</li><li id="1055" class="mf mg it lk b ll mo lo mp lr mq lv mr lz ms md mk ml mm mn bi translated">拼写错误可以欺骗基于文本分析的安全技术。</li></ul><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi oe"><img src="../Images/b44a488ab82b740202f733f568b5a803.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*4bBzBEVmqweEenFbI5Zqrw.png"/></div></div><figcaption class="ld le gj gh gi lf lg bd b be z dk translated">拼写错误替换示例。</figcaption></figure><p id="47b7" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">这种方法有助于在推理时处理潜在的看不见的文本，因为模型可以用那些拼写错误的标记来训练。</p><h2 id="70ad" class="nn mw it bd mx no np dn nb nq nr dp nf lr ns nt nh lv nu nv nj lz nw nx nl iz bi translated">同义词替换</h2><p id="cd72" class="pw-post-body-paragraph li lj it lk b ll ny kd ln lo nz kg lq lr oa lt lu lv ob lx ly lz oc mb mc md im bi translated">通过替换意义相近的词，可以成为模型的新训练。Regina等人同时使用WordNet和BERT来查找同义词或近义词。比如，“<strong class="lk jd"><em class="of"/></strong>敏捷的棕色狐狸跳过懒狗。”还有“<strong class="lk jd">T5】小 </strong>敏捷的棕色狐狸跳过懒狗。”有类似的意思。第二句话是伯特模型生成的。</p><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div class="gh gi og"><img src="../Images/75e3130c010fd4be2bcf07b656c0fc69.png" data-original-src="https://miro.medium.com/v2/resize:fit:738/format:webp/1*WFDYv-aTIkhi8z--OwknQg.png"/></div><figcaption class="ld le gj gh gi lf lg bd b be z dk translated">近义词替换的例子。</figcaption></figure><p id="e904" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">利用WordNet是生成synthetic的典型方式，而利用BERT查找近义词是实现这一点的更好方式。原因是:</p><ul class=""><li id="b2f2" class="mf mg it lk b ll lm lo lp lr mh lv mi lz mj md mk ml mm mn bi translated">BERT或上下文单词嵌入模型可以生成近义词。它引入了更多的合成数据，无需预先定义同义词列表(即WordNet)</li><li id="b06f" class="mf mg it lk b ll mo lo mp lr mq lv mr lz ms md mk ml mm mn bi translated">由于BERT可以针对特定领域的知识进行训练，因此它可以应用于特定领域的数据。</li></ul><h1 id="142f" class="mv mw it bd mx my mz na nb nc nd ne nf ki ng kj nh kl ni km nj ko nk kp nl nm bi translated">拿走</h1><ul class=""><li id="6cd9" class="mf mg it lk b ll ny lo nz lr oh lv oi lz oj md mk ml mm mn bi translated">生成训练数据有助于解决资源不足的问题。但是，请记住，您应该选择适当的方法来生成合成数据。</li><li id="defd" class="mf mg it lk b ll mo lo mp lr mq lv mr lz ms md mk ml mm mn bi translated">一些免费的开源库提供了一种生成合成数据的简单方法。nlpaug 是可以通过几行代码生成数据的例子之一。</li></ul><h1 id="7d81" class="mv mw it bd mx my mz na nb nc nd ne nf ki ng kj nh kl ni km nj ko nk kp nl nm bi translated">关于我</h1><p id="0915" class="pw-post-body-paragraph li lj it lk b ll ny kd ln lo nz kg lq lr oa lt lu lv ob lx ly lz oc mb mc md im bi translated">我是湾区的数据科学家。专注于数据科学、人工智能，尤其是NLP和平台相关领域的最新工作。欢迎在<a class="ae lh" href="https://www.linkedin.com/in/edwardma1026" rel="noopener ugc nofollow" target="_blank"> LinkedIn </a>上与<a class="ae lh" href="https://makcedward.github.io/" rel="noopener ugc nofollow" target="_blank"> me </a>联系，或者在<a class="ae lh" href="https://medium.com/@makcedward/" rel="noopener"> Medium </a>或<a class="ae lh" href="https://github.com/makcedward" rel="noopener ugc nofollow" target="_blank"> Github </a>上关注我。</p><h1 id="05c8" class="mv mw it bd mx my mz na nb nc nd ne nf ki ng kj nh kl ni km nj ko nk kp nl nm bi translated">延伸阅读</h1><ul class=""><li id="50b3" class="mf mg it lk b ll ny lo nz lr oh lv oi lz oj md mk ml mm mn bi translated">NLP的数据扩充库</li></ul><h1 id="d9a7" class="mv mw it bd mx my mz na nb nc nd ne nf ki ng kj nh kl ni km nj ko nk kp nl nm bi translated">参考</h1><ul class=""><li id="652f" class="mf mg it lk b ll ny lo nz lr oh lv oi lz oj md mk ml mm mn bi translated">米（meter的缩写））里贾纳，M .迈耶和s .古塔尔。<a class="ae lh" href="https://arxiv.org/pdf/2007.02033.pdf" rel="noopener ugc nofollow" target="_blank">文本数据增强:更好地检测鱼叉式网络钓鱼邮件</a>。2020</li></ul></div></div>    
</body>
</html>