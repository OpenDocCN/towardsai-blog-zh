<html>
<head>
<title>Transfer Learning using a Pre-trained Model</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">使用预先训练的模型进行迁移学习</h1>
<blockquote>原文：<a href="https://pub.towardsai.net/transfer-learning-using-a-pre-trained-model-c599e353bbe3?source=collection_archive---------0-----------------------#2020-08-20">https://pub.towardsai.net/transfer-learning-using-a-pre-trained-model-c599e353bbe3?source=collection_archive---------0-----------------------#2020-08-20</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><h2 id="ba3b" class="io ip iq bd b dl ir is it iu iv iw dk ix translated" aria-label="kicker paragraph"><a class="ae ep" href="https://towardsai.net/p/category/deep-learning" rel="noopener ugc nofollow" target="_blank">深度学习</a></h2><div class=""/><div class=""><h2 id="d8c8" class="pw-subtitle-paragraph jw iz iq bd b jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn dk translated">探索VGG16在图像分类中的应用</h2></div><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div class="gh gi ko"><img src="../Images/e9b19e77b1da07eaa88d0cc11fcaa754.png" data-original-src="https://miro.medium.com/v2/resize:fit:1240/format:webp/0*Dxd8wLUM-sfKorPF.jpg"/></div><figcaption class="kw kx gj gh gi ky kz bd b be z dk translated">来源:<a class="ae la" href="https://channeldrive.in/netapp-gives-customers-the-freedom-to-choice-for-any-cloud-with-one-experience/" rel="noopener ugc nofollow" target="_blank">渠道驱动</a></figcaption></figure><h1 id="20b0" class="lb lc iq bd ld le lf lg lh li lj lk ll kf lm kg ln ki lo kj lp kl lq km lr ls bi translated">什么是迁移学习？</h1><p id="20a9" class="pw-post-body-paragraph lt lu iq lv b lw lx ka ly lz ma kd mb mc md me mf mg mh mi mj mk ml mm mn mo ij bi translated"><strong class="lv ja">迁移学习</strong>是机器学习中的一个研究问题，专注于存储在解决一个问题时获得的知识，并将其应用于另一个不同但相关的问题。</p><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div role="button" tabindex="0" class="mq mr di ms bf mt"><div class="gh gi mp"><img src="../Images/225e2e184aebcb9c7285f8c2c5456913.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*PJbdbGFaM_AOKfaQ-llC0A.png"/></div></div><figcaption class="kw kx gj gh gi ky kz bd b be z dk translated">传统机器学习VS迁移学习(来源:<a class="ae la" href="https://towardsdatascience.com/a-comprehensive-hands-on-guide-to-transfer-learning-with-real-world-applications-in-deep-learning-212bf3b2f27a" rel="noopener" target="_blank"> Dipanjan Sarkar </a></figcaption></figure><p id="fdfd" class="pw-post-body-paragraph lt lu iq lv b lw mu ka ly lz mv kd mb mc mw me mf mg mx mi mj mk my mm mn mo ij bi translated">传统的机器学习方法基于从训练数据中学习到的模式来概括看不见的数据，而对于迁移学习，它<strong class="lv ja">从先前学习的模式开始，以解决不同的任务</strong>。</p><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div role="button" tabindex="0" class="mq mr di ms bf mt"><div class="gh gi mz"><img src="../Images/c03107bebc2d9b18ed5fc3043d631049.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*vqgRU2QEmOIfLjrCWzpjAg.png"/></div></div><figcaption class="kw kx gj gh gi ky kz bd b be z dk translated">迁移学习的基本思想(来源:<a class="ae la" href="https://medium.com/the-official-integrate-ai-blog/transfer-learning-explained-7d275c1e34e2" rel="noopener"> Integrate.ai </a>)</figcaption></figure><h2 id="7386" class="na lc iq bd ld nb nc dn lh nd ne dp ll mc nf ng ln mg nh ni lp mk nj nk lr iw bi translated">有两种常见的迁移学习方法:</h2><ol class=""><li id="552a" class="nl nm iq lv b lw lx lz ma mc nn mg no mk np mo nq nr ns nt bi translated"><strong class="lv ja">开发模型方法:</strong>开发比简单模型更好的模型，以确保已经执行了一些特征学习。为感兴趣的任务重用和调整开发的模型。</li><li id="74c4" class="nl nm iq lv b lw nu lz nv mc nw mg nx mk ny mo nq nr ns nt bi translated"><strong class="lv ja">预训练模型方法:</strong>从可用模型中选择一个预训练源模型进行重用和微调。</li></ol><p id="500b" class="pw-post-body-paragraph lt lu iq lv b lw mu ka ly lz mv kd mb mc mw me mf mg mx mi mj mk my mm mn mo ij bi translated">在这篇文章中，我们将重点关注预训练模型方法，因为它通常用于深度学习领域。</p><h1 id="e205" class="lb lc iq bd ld le lf lg lh li lj lk ll kf lm kg ln ki lo kj lp kl lq km lr ls bi translated">什么是预训练模型？</h1><p id="6630" class="pw-post-body-paragraph lt lu iq lv b lw lx ka ly lz ma kd mb mc md me mf mg mh mi mj mk ml mm mn mo ij bi translated">预训练模型是一个<strong class="lv ja">保存的网络，之前在大型数据集</strong>上训练过，通常是在大规模图像分类任务上。人们可以使用预先训练的模型，或者使用迁移学习来定制该模型以用于给定的任务。</p><p id="703e" class="pw-post-body-paragraph lt lu iq lv b lw mu ka ly lz mv kd mb mc mw me mf mg mx mi mj mk my mm mn mo ij bi translated">迁移学习背后的直觉是<strong class="lv ja">如果一个模型在一个足够大和足够一般的数据集上被训练，这个模型将有效地充当视觉世界的通用模型</strong>。然后，我们可以利用这些学习到的特征地图，而不必通过在大型数据集上训练大型模型来从头开始。</p><p id="6754" class="pw-post-body-paragraph lt lu iq lv b lw mu ka ly lz mv kd mb mc mw me mf mg mx mi mj mk my mm mn mo ij bi translated">让我们来深入了解一下<strong class="lv ja">vgg 16</strong>——2014年提交给<a class="ae la" href="http://www.image-net.org/challenges/LSVRC/2014/results" rel="noopener ugc nofollow" target="_blank">大规模视觉识别挑战赛</a>的一个著名的预训练模型。</p><h1 id="83bc" class="lb lc iq bd ld le lf lg lh li lj lk ll kf lm kg ln ki lo kj lp kl lq km lr ls bi translated">VGG16架构</h1><p id="c06a" class="pw-post-body-paragraph lt lu iq lv b lw lx ka ly lz ma kd mb mc md me mf mg mh mi mj mk ml mm mn mo ij bi translated">Simonyan和Zisserman在他们2014年的论文<a class="ae la" href="https://arxiv.org/abs/1409.1556" rel="noopener ugc nofollow" target="_blank">用于大规模图像识别的甚深卷积网络</a> <em class="nz">中介绍了VGG网络架构。</em>该模型在ImageNet中获得了92.7%的前5名测试准确率，ImageNet是一个包含1000个类别的1400多万张图像的数据集。VGG16中的数字“16”是指它的16层，这些层具有权重。该网络相当大，大约有1.38亿个参数。</p><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div role="button" tabindex="0" class="mq mr di ms bf mt"><div class="gh gi oa"><img src="../Images/4281ea965e52d8caed3b13575d7b23a9.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*GzEK7Gt22OVwKok4.png"/></div></div></figure><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div role="button" tabindex="0" class="mq mr di ms bf mt"><div class="gh gi ob"><img src="../Images/bc1ad1550a9a62cbb3c8df0f5549358f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*rQO2iPEOtA5WmaJH.png"/></div></div><figcaption class="kw kx gj gh gi ky kz bd b be z dk translated">VGG16的架构(来源:<a class="ae la" href="https://neurohive.io/en/popular-networks/vgg16/" rel="noopener ugc nofollow" target="_blank"> Neurohive </a>)</figcaption></figure><p id="86fb" class="pw-post-body-paragraph lt lu iq lv b lw mu ka ly lz mv kd mb mc mw me mf mg mx mi mj mk my mm mn mo ij bi translated">conv1层的<strong class="lv ja">输入是固定大小的224 x 224 RGB图像。图像通过一叠卷积层，在卷积层中，滤波器使用非常小的感受野:3×3(这是捕捉左/右、上/下、中心概念的最小尺寸)。在其中一种配置中，它还利用1×1卷积滤波器，可视为输入通道的线性变换(后跟非线性)。</strong></p><p id="4405" class="pw-post-body-paragraph lt lu iq lv b lw mu ka ly lz mv kd mb mc mw me mf mg mx mi mj mk my mm mn mo ij bi translated"><strong class="lv ja">卷积步幅</strong>固定为1个像素；卷积层输入的空间填充使得在卷积后保持空间分辨率，即对于3×3卷积层，填充是1像素。<strong class="lv ja">空间池</strong>由五个最大池层执行，它们遵循一些卷积层(并非所有卷积层都遵循最大池)。<strong class="lv ja">最大池化</strong>在2×2像素窗口上执行，步长为2。</p><p id="9692" class="pw-post-body-paragraph lt lu iq lv b lw mu ka ly lz mv kd mb mc mw me mf mg mx mi mj mk my mm mn mo ij bi translated"><strong class="lv ja">三个完全连接的层</strong>跟随一堆卷积层(在不同的架构中具有不同的深度):前两个每个具有4096个信道，第三个执行1000路ILSVRC分类，因此包含1000个信道(每个类一个)。最后一层是<strong class="lv ja">软最大层</strong>。全连接层的配置在所有网络中都是相同的。</p><p id="93f7" class="pw-post-body-paragraph lt lu iq lv b lw mu ka ly lz mv kd mb mc mw me mf mg mx mi mj mk my mm mn mo ij bi translated">所有隐藏层都配有<strong class="lv ja">校正(ReLU)非线性。</strong>还要注意的是，没有一个网络(除了一个)包含局部响应归一化(LRN)，这种归一化不会提高数据集的性能，但会导致内存消耗和计算时间增加。</p><p id="8957" class="pw-post-body-paragraph lt lu iq lv b lw mu ka ly lz mv kd mb mc mw me mf mg mx mi mj mk my mm mn mo ij bi translated">我们将探讨一个问题陈述，并探索使用预训练模型进行迁移学习的基本原理，如何微调超参数以提高模型性能，并解释学习曲线。</p><h1 id="af5b" class="lb lc iq bd ld le lf lg lh li lj lk ll kf lm kg ln ki lo kj lp kl lq km lr ls bi translated">问题陈述:使用迁移学习，建立一个卷积神经网络(“CNN”)模型，将神奇宝贝分类到各自的类别中。</h1><h1 id="6833" class="lb lc iq bd ld le lf lg lh li lj lk ll kf lm kg ln ki lo kj lp kl lq km lr ls bi translated">让我们编码并抓住他们！</h1><figure class="kp kq kr ks gt kt"><div class="bz fp l di"><div class="oc od l"/></div></figure><h1 id="5069" class="lb lc iq bd ld le lf lg lh li lj lk ll kf lm kg ln ki lo kj lp kl lq km lr ls bi translated">数据准备</h1><p id="bf9a" class="pw-post-body-paragraph lt lu iq lv b lw lx ka ly lz ma kd mb mc md me mf mg mh mi mj mk ml mm mn mo ij bi translated">我从<a class="ae la" href="https://www.kaggle.com/thedagger/pokemon-generation-one" rel="noopener ugc nofollow" target="_blank">神奇宝贝数据集</a>中选择了5类神奇宝贝。加载这些图像并绘制一个条形图，以了解每个类中有多少图像。</p><figure class="kp kq kr ks gt kt"><div class="bz fp l di"><div class="oc od l"/></div></figure><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div role="button" tabindex="0" class="mq mr di ms bf mt"><div class="gh gi oe"><img src="../Images/64fe8df0137330af0cafdae3056d0ddc.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*JXX2FXJ0hdGu7HTJAxqPLw.png"/></div></div></figure><figure class="kp kq kr ks gt kt"><div class="bz fp l di"><div class="oc od l"/></div></figure><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div role="button" tabindex="0" class="mq mr di ms bf mt"><div class="gh gi of"><img src="../Images/990fa480855e72a837a86b5f9d2d7cdc.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*mSgby8nC9yn-cEdpBWAD8g.png"/></div></div></figure><p id="8a11" class="pw-post-body-paragraph lt lu iq lv b lw mu ka ly lz mv kd mb mc mw me mf mg mx mi mj mk my mm mn mo ij bi translated">根据上面的条形图，每个神奇宝贝类至少有280个图像，这是一个很好的平均大小。由于硬件限制，我们将使用128 X 128的输入图像尺寸，而不是VGG16模型中使用的原始224 X 224。我们将继续阅读、调整和缩放这些图像用于训练。</p><figure class="kp kq kr ks gt kt"><div class="bz fp l di"><div class="oc od l"/></div></figure><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div class="gh gi og"><img src="../Images/c8684ffed95bbe5f3a3b51c412276ee6.png" data-original-src="https://miro.medium.com/v2/resize:fit:442/format:webp/1*xI7zQivxrBs3_Fvd16QrFw.png"/></div><figcaption class="kw kx gj gh gi ky kz bd b be z dk translated">总共1，429张图像，输入尺寸为128 X 128 X 3</figcaption></figure><p id="825c" class="pw-post-body-paragraph lt lu iq lv b lw mu ka ly lz mv kd mb mc mw me mf mg mx mi mj mk my mm mn mo ij bi translated">加载并拆分数据集，用于CNN模型的训练和测试。使用了0.2 的<strong class="lv ja">测试规模，这意味着数据集的80%将用于训练目的，而剩余的20%用作测试组件。然后，我们使用标签y <em class="nz">、</em>作为类别标签，以<strong class="lv ja">分层</strong>的方式分割数据集。在分割之前，数据集也被<strong class="lv ja">混洗</strong>，以增强概率采样的随机性。<strong class="lv ja">随机状态</strong>控制在应用分割之前应用于数据的混洗。此参数中传递了一个整数，以便在多个函数调用中进行可再现的输出。</strong></p><figure class="kp kq kr ks gt kt"><div class="bz fp l di"><div class="oc od l"/></div></figure><h1 id="167f" class="lb lc iq bd ld le lf lg lh li lj lk ll kf lm kg ln ki lo kj lp kl lq km lr ls bi translated">利用迁移学习创建CNN模型</h1><p id="9e0c" class="pw-post-body-paragraph lt lu iq lv b lw lx ka ly lz ma kd mb mc md me mf mg mh mi mj mk ml mm mn mo ij bi translated">通过冻结模型的“深层”并仅重新训练分类层来应用迁移学习。</p><p id="f96b" class="pw-post-body-paragraph lt lu iq lv b lw mu ka ly lz mv kd mb mc mw me mf mg mx mi mj mk my mm mn mo ij bi translated">我们选择使用<a class="ae la" href="https://www.tensorflow.org/api_docs/python/tf/keras/optimizers/Adam" rel="noopener ugc nofollow" target="_blank"> <strong class="lv ja"> Adam优化</strong> </a>，这是一种基于一阶和二阶矩自适应估计的随机梯度下降方法。</p><p id="5353" class="pw-post-body-paragraph lt lu iq lv b lw mu ka ly lz mv kd mb mc mw me mf mg mx mi mj mk my mm mn mo ij bi translated">根据<a class="ae la" href="http://arxiv.org/abs/1412.6980" rel="noopener ugc nofollow" target="_blank"> Kingma et al .，2014 </a>，该方法为</p><blockquote class="oh oi oj"><p id="0a10" class="lt lu nz lv b lw mu ka ly lz mv kd mb ok mw me mf ol mx mi mj om my mm mn mo ij bi translated">计算效率高，几乎不需要内存，对梯度的对角线重新缩放不变，非常适合数据/参数较大的问题</p></blockquote><figure class="kp kq kr ks gt kt"><div class="bz fp l di"><div class="oc od l"/></div></figure><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div role="button" tabindex="0" class="mq mr di ms bf mt"><div class="gh gi on"><img src="../Images/c4b2804e1e9a269fb24500b539e42ad3.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*AsPEsXefX_COk913kNsKYg.png"/></div></div></figure><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div role="button" tabindex="0" class="mq mr di ms bf mt"><div class="gh gi on"><img src="../Images/f9b47354cfb82dd147b52ebce4f5f0fd.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*bA2KktEMLEMfend86vQ6qw.png"/></div></div></figure><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div role="button" tabindex="0" class="mq mr di ms bf mt"><div class="gh gi oo"><img src="../Images/34117543b66997d7779e02bb1986deea.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*pNtZ-rshsyr40Reat1O3NA.png"/></div></div></figure><h1 id="2512" class="lb lc iq bd ld le lf lg lh li lj lk ll kf lm kg ln ki lo kj lp kl lq km lr ls bi translated">模特培训</h1><figure class="kp kq kr ks gt kt"><div class="bz fp l di"><div class="oc od l"/></div></figure><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div role="button" tabindex="0" class="mq mr di ms bf mt"><div class="gh gi op"><img src="../Images/e4d6505a9756009d754eb9f101fecdf4.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Lb8EZEwWH2s_aSOuoFSNlw.png"/></div></div></figure><h1 id="56c3" class="lb lc iq bd ld le lf lg lh li lj lk ll kf lm kg ln ki lo kj lp kl lq km lr ls bi translated">学习曲线</h1><p id="6fec" class="pw-post-body-paragraph lt lu iq lv b lw lx ka ly lz ma kd mb mc md me mf mg mh mi mj mk ml mm mn mo ij bi translated">学习曲线<strong class="lv ja">是模型学习性能随经验或时间变化的曲线图</strong>。学习曲线是机器学习中广泛使用的诊断工具，用于从训练数据集增量学习的算法。在训练期间的每次更新之后，可以在训练数据集和验证数据集上评估该模型，并且创建测量的性能的图以反映学习曲线。</p><p id="5c95" class="pw-post-body-paragraph lt lu iq lv b lw mu ka ly lz mv kd mb mc mw me mf mg mx mi mj mk my mm mn mo ij bi translated">在训练期间检查模型的学习曲线可用于诊断学习的问题，例如欠拟合或过拟合模型，以及训练和验证数据集是否具有适当的代表性。</p><ul class=""><li id="0ca8" class="nl nm iq lv b lw mu lz mv mc oq mg or mk os mo ot nr ns nt bi translated"><strong class="lv ja">训练学习曲线</strong>:从训练数据集中计算出的学习曲线，给出了模型学习情况的想法。</li><li id="761b" class="nl nm iq lv b lw nu lz nv mc nw mg nx mk ny mo ot nr ns nt bi translated"><strong class="lv ja">验证学习曲线</strong>:从验证数据集中计算出的学习曲线，给出了模型泛化能力的概念。</li></ul><p id="77a0" class="pw-post-body-paragraph lt lu iq lv b lw mu ka ly lz mv kd mb mc mw me mf mg mx mi mj mk my mm mn mo ij bi translated">让我们绘制训练和验证准确性/损失的学习曲线。</p><figure class="kp kq kr ks gt kt"><div class="bz fp l di"><div class="oc od l"/></div></figure><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div role="button" tabindex="0" class="mq mr di ms bf mt"><div class="gh gi ou"><img src="../Images/fff909a5ac17d053d0e23d0b1357907b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*RlFZTdKQ7tYoOo5fcXG8Kw.png"/></div></div></figure><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div role="button" tabindex="0" class="mq mr di ms bf mt"><div class="gh gi ov"><img src="../Images/58e6da92f9f4e75f15bcd384fb430afa.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*0V32ohojuUiwcXoTsW-QMA.png"/></div></div></figure><p id="88db" class="pw-post-body-paragraph lt lu iq lv b lw mu ka ly lz mv kd mb mc mw me mf mg mx mi mj mk my mm mn mo ij bi translated">根据绘制的学习曲线，观察到学习算法的良好拟合。<strong class="lv ja">良好拟合</strong>由<strong class="lv ja">识别，训练和验证精度/损失降低到稳定点，两个最终精度/损失值之间的差距最小。</strong></p><p id="9b6a" class="pw-post-body-paragraph lt lu iq lv b lw mu ka ly lz mv kd mb mc mw me mf mg mx mi mj mk my mm mn mo ij bi translated">模型的准确性在训练数据集上将总是比验证数据集<strong class="lv ja">高</strong>，反之亦然，模型的损失在训练数据集上将几乎总是比验证数据集<strong class="lv ja">低</strong>。这意味着我们应该预期在训练和验证损失学习曲线之间会有一个<a class="ae la" href="https://ai.googleblog.com/2019/07/predicting-generalization-gap-in-deep.html" rel="noopener ugc nofollow" target="_blank">推广缺口</a>。</p><p id="0e40" class="pw-post-body-paragraph lt lu iq lv b lw mu ka ly lz mv kd mb mc mw me mf mg mx mi mj mk my mm mn mo ij bi translated">学习曲线图示出了良好的拟合，如果:</p><ul class=""><li id="cfce" class="nl nm iq lv b lw mu lz mv mc oq mg or mk os mo ot nr ns nt bi translated">训练精度/损失的曲线将增加/减少到一个稳定点。</li><li id="8889" class="nl nm iq lv b lw nu lz nv mc nw mg nx mk ny mo ot nr ns nt bi translated">验证准确度/损失的曲线将增加/减少到稳定点，并且与训练准确度/损失有小的差距。</li></ul><p id="67a6" class="pw-post-body-paragraph lt lu iq lv b lw mu ka ly lz mv kd mb mc mw me mf mg mx mi mj mk my mm mn mo ij bi translated">然而，任何持续的良好适应训练都可能导致过度适应。</p><h1 id="e62b" class="lb lc iq bd ld le lf lg lh li lj lk ll kf lm kg ln ki lo kj lp kl lq km lr ls bi translated">超参数微调</h1><p id="c663" class="pw-post-body-paragraph lt lu iq lv b lw lx ka ly lz ma kd mb mc md me mf mg mh mi mj mk ml mm mn mo ij bi translated">接下来，我们将通过使用低得多的学习速率来微调超参数，以提高模型性能。</p><figure class="kp kq kr ks gt kt"><div class="bz fp l di"><div class="oc od l"/></div></figure><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div role="button" tabindex="0" class="mq mr di ms bf mt"><div class="gh gi ow"><img src="../Images/a79cf8e07d1be39c5a003d6b32301095.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*YzVJPEDclrQMyZoEW5SL3g.png"/></div></div></figure><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div role="button" tabindex="0" class="mq mr di ms bf mt"><div class="gh gi ox"><img src="../Images/168aed93bdbec5c798425c3b58413f10.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*eYZajt8IpUZRRX3gXJ9H2Q.png"/></div></div></figure><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div role="button" tabindex="0" class="mq mr di ms bf mt"><div class="gh gi oy"><img src="../Images/5608a7be340dbb2ae84c2611ba5e68d8.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Ouz3OSq5A1a7iv0bTL-6QA.png"/></div></div></figure><p id="48ed" class="pw-post-body-paragraph lt lu iq lv b lw mu ka ly lz mv kd mb mc mw me mf mg mx mi mj mk my mm mn mo ij bi translated">通过增加训练时期的数量并减少批次大小来继续训练模型，以提高测试准确性和测试损失。</p><figure class="kp kq kr ks gt kt"><div class="bz fp l di"><div class="oc od l"/></div></figure><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div role="button" tabindex="0" class="mq mr di ms bf mt"><div class="gh gi oz"><img src="../Images/94ea39f283f6d5866670b6e471df8c28.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*3XiWryOyQSb60jjX48lX3Q.png"/></div></div></figure><h1 id="9dd8" class="lb lc iq bd ld le lf lg lh li lj lk ll kf lm kg ln ki lo kj lp kl lq km lr ls bi translated">微调后的学习曲线</h1><p id="1c24" class="pw-post-body-paragraph lt lu iq lv b lw lx ka ly lz ma kd mb mc md me mf mg mh mi mj mk ml mm mn mo ij bi translated">绘制训练和验证准确性的学习曲线以及微调后的损失，以便更好地可视化模型的学习效果。</p><figure class="kp kq kr ks gt kt"><div class="bz fp l di"><div class="oc od l"/></div></figure><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div role="button" tabindex="0" class="mq mr di ms bf mt"><div class="gh gi pa"><img src="../Images/485ee9bdb3c091e3d02cb7c1c94d9d6e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*YNHZhMJHN6DLHqBeUnnzmw.png"/></div></div></figure><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div role="button" tabindex="0" class="mq mr di ms bf mt"><div class="gh gi pb"><img src="../Images/a70841f174b4db8cfcf6a9eee1ffe7e5.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*o8ufsbOWYgRvv3byOaO1Sg.png"/></div></div></figure><p id="4a64" class="pw-post-body-paragraph lt lu iq lv b lw mu ka ly lz mv kd mb mc mw me mf mg mx mi mj mk my mm mn mo ij bi translated">通过使用较慢的学习速率，有助于提高验证准确性和降低验证损失。请注意，训练和验证准确度/损失学习曲线之间的泛化差距已经显著最小化。</p><h1 id="d5e9" class="lb lc iq bd ld le lf lg lh li lj lk ll kf lm kg ln ki lo kj lp kl lq km lr ls bi translated">结果评估</h1><p id="3183" class="pw-post-body-paragraph lt lu iq lv b lw lx ka ly lz ma kd mb mc md me mf mg mh mi mj mk ml mm mn mo ij bi translated">为了提供对训练模型的独立评估，通过从互联网上选择每一类的随机图像来创建未看见数据的测试数据集。</p><figure class="kp kq kr ks gt kt"><div class="bz fp l di"><div class="oc od l"/></div></figure><figure class="kp kq kr ks gt kt"><div class="bz fp l di"><div class="oc od l"/></div></figure><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div role="button" tabindex="0" class="mq mr di ms bf mt"><div class="gh gi pc"><img src="../Images/4f46fb73928dd4d49d2939f2f86554f2.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*4alXcR_aDbbO6HXRuOR5ZA.png"/></div></div></figure><p id="ee9a" class="pw-post-body-paragraph lt lu iq lv b lw mu ka ly lz mv kd mb mc mw me mf mg mx mi mj mk my mm mn mo ij bi translated">上述结果表明，在正确地将每个神奇宝贝识别到其各自的类别方面，训练模型具有良好的性能。好吧，除了可怜的大侦探皮卡丘，它不幸以58.9%的预测率被认定为Mewtwo。也许Mewtwo已经决定反击，因为它的电影- <a class="ae la" href="https://en.wikipedia.org/wiki/Pok%C3%A9mon:_Mewtwo_Strikes_Back%E2%80%94Evolution" rel="noopener ugc nofollow" target="_blank">神奇宝贝:Mewtwo反击-进化</a>。</p><h1 id="3148" class="lb lc iq bd ld le lf lg lh li lj lk ll kf lm kg ln ki lo kj lp kl lq km lr ls bi translated">结论</h1><p id="20ae" class="pw-post-body-paragraph lt lu iq lv b lw lx ka ly lz ma kd mb mc md me mf mg mh mi mj mk ml mm mn mo ij bi translated">总的来说，使用迁移学习成功地建立了一个CNN模型来对神奇宝贝数据集进行分类。</p><p id="fcb8" class="pw-post-body-paragraph lt lu iq lv b lw mu ka ly lz mv kd mb mc mw me mf mg mx mi mj mk my mm mn mo ij bi translated">为了进一步提高具有背景噪声的图像的精度水平，可以在用足够大和通用的数据集训练CNN模型的地方进行改进。迁移学习的使用使人们能够利用先前学习的特征图，而不必通过在大数据集上训练大模型而从头开始。</p></div><div class="ab cl pd pe hu pf" role="separator"><span class="pg bw bk ph pi pj"/><span class="pg bw bk ph pi pj"/><span class="pg bw bk ph pi"/></div><div class="ij ik il im in"><h1 id="3680" class="lb lc iq bd ld le pk lg lh li pl lk ll kf pm kg ln ki pn kj lp kl po km lr ls bi translated"><strong class="ak">参考文献</strong></h1><ol class=""><li id="4f87" class="nl nm iq lv b lw lx lz ma mc nn mg no mk np mo nq nr ns nt bi translated"><a class="ae la" href="https://machinelearningmastery.com/transfer-learning-for-deep-learning/" rel="noopener ugc nofollow" target="_blank">深度学习迁移学习的温和介绍</a></li><li id="092e" class="nl nm iq lv b lw nu lz nv mc nw mg nx mk ny mo nq nr ns nt bi translated"><a class="ae la" href="https://www.tensorflow.org/tutorials/images/transfer_learning" rel="noopener ugc nofollow" target="_blank">迁移学习和微调</a></li><li id="39f7" class="nl nm iq lv b lw nu lz nv mc nw mg nx mk ny mo nq nr ns nt bi translated"><a class="ae la" href="https://neurohive.io/en/popular-networks/vgg16/" rel="noopener ugc nofollow" target="_blank"> VGG16 —用于分类和检测的卷积网络</a></li><li id="5da6" class="nl nm iq lv b lw nu lz nv mc nw mg nx mk ny mo nq nr ns nt bi translated"><a class="ae la" href="https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html" rel="noopener ugc nofollow" target="_blank"> Scikit学习—训练、测试、分割</a></li><li id="ce2a" class="nl nm iq lv b lw nu lz nv mc nw mg nx mk ny mo nq nr ns nt bi translated"><a class="ae la" href="https://www.tensorflow.org/api_docs/python/tf/keras/optimizers/Adam" rel="noopener ugc nofollow" target="_blank">tensor flow中的Adam优化器</a></li><li id="8914" class="nl nm iq lv b lw nu lz nv mc nw mg nx mk ny mo nq nr ns nt bi translated"><a class="ae la" href="https://machinelearningmastery.com/learning-curves-for-diagnosing-machine-learning-model-performance/" rel="noopener ugc nofollow" target="_blank">如何使用学习曲线诊断机器学习模型性能</a></li></ol></div></div>    
</body>
</html>