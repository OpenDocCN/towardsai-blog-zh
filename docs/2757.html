<html>
<head>
<title>An In-Depth Tutorial on the F-Score For NER</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">关于NER分数的深度教程</h1>
<blockquote>原文：<a href="https://pub.towardsai.net/an-in-depth-tutorial-on-the-f-score-for-ner-55e944bd28ce?source=collection_archive---------3-----------------------#2022-05-12">https://pub.towardsai.net/an-in-depth-tutorial-on-the-f-score-for-ner-55e944bd28ce?source=collection_archive---------3-----------------------#2022-05-12</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="ea71" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">以及推理的有效实现</h2></div><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ki"><img src="../Images/1acc1f0430b5d3f845c39452b1f7c8e4.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*OHRdWC184aj5vQyCYny20Q.png"/></div></div><figcaption class="ku kv gj gh gi kw kx bd b be z dk translated">编辑过的照片。原创感谢来自<a class="ae ky" href="https://unsplash.com/photos/askpr0s66Rg" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>的<a class="ae ky" href="https://unsplash.com/@anniespratt" rel="noopener ugc nofollow" target="_blank">安妮·斯普拉特</a>。</figcaption></figure><p id="f974" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">F分数对于分类算法来说是一个非常有用的指标，可以平衡假阳性(通过<a class="ae ky" href="https://en.wikipedia.org/wiki/Precision_and_recall" rel="noopener ugc nofollow" target="_blank">精度</a>)和假阴性(通过<a class="ae ky" href="https://en.wikipedia.org/wiki/Precision_and_recall" rel="noopener ugc nofollow" target="_blank">召回</a>)。然而，虽然它在经典分类任务中的实现相对简单，但它在命名实体识别(NER)中涉及更多，其中真阳性(TP)、假阳性(FP)和假阴性(FN)不仅仅是真标签与来自模型的输出张量的argmax的比较。</p><p id="10e5" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">本文简要介绍了NER类型的问题，概述了TP、FP和FN的计算方法(包括这与基于transformer的模型有何不同)，最后介绍了PyTorch中利用GPU的F分数的高效实现。没有预先的自然语言处理知识，但是以前的自然语言处理经验将是有用的。</p></div><div class="ab cl lv lw hx lx" role="separator"><span class="ly bw bk lz ma mb"/><span class="ly bw bk lz ma mb"/><span class="ly bw bk lz ma"/></div><div class="im in io ip iq"><h1 id="14c3" class="mc md it bd me mf mg mh mi mj mk ml mm jz mn ka mo kc mp kd mq kf mr kg ms mt bi translated">作为分类任务的NER</h1><p id="4950" class="pw-post-body-paragraph kz la it lb b lc mu ju le lf mv jx lh li mw lk ll lm mx lo lp lq my ls lt lu im bi translated">在NER，目标是预测一段文本中的哪些元素是“命名实体”，例如，人(PER)，组织(ORG)，地点(GEO)。一个好的NER模型应该能够识别命名实体，如下所示:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi mz"><img src="../Images/d59e36ada3c4273940383b3566315871.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*avnWOAxJRRnQZcW32eOjGQ.png"/></div></div><figcaption class="ku kv gj gh gi kw kx bd b be z dk translated">请注意，非NER单词表示为“其他”。稍后将详细介绍。</figcaption></figure><p id="3e47" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">为了做到这一点，首先将文本表示为一个整数向量。它被分割成更小的组件(<a class="ae ky" href="https://www.analyticsvidhya.com/blog/2020/05/what-is-tokenization-nlp/" rel="noopener ugc nofollow" target="_blank">标记化</a>)，每个组件都根据它们所属的实体类型被赋予一个相关联的标签。为了给模型更多关于实体的信息，开始标记被赋予不同的标签(你可以在这里和这里阅读其他的标签策略)。因此，如果我们进行简单的空白符号化，上面的句子将表示如下:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi na"><img src="../Images/f2c730234174ddec35659896120ae409.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*ga4t6yuBww-zuj509MVHJw.png"/></div></div><figcaption class="ku kv gj gh gi kw kx bd b be z dk translated">这里我们使用了生物表示法。任何实体类型的开头都标记为' B-'，其他的标记为' I-'(表示内部)。任何非实体词都标为‘O’。</figcaption></figure><p id="d4e3" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">对于这个特殊的句子，我们的输入是一个1x13的向量，我们的输出是一个相应的1x13的向量。任务是将13个单词中的每一个分类为7个唯一标签之一{O，B-PER，I-PER，B-GEO，I-GEO，B-ORG，I-ORG}。这意味着我们的模型输出将是大小为1x13x7的，其中最后一个维度表示那个<strong class="lb iu">单词i </strong> (i=1…13)属于<strong class="lb iu">类j </strong> (j=1…5)的概率。现在，在一个标准的分类任务中，我们将简单地获取最后一个维度的argmax，从而获得每个单词的预测标签。然后，我们可以获得标签的宏观F1分数，从而为我们提供模型表现如何的度量:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi nb"><img src="../Images/26c4bcae28ae44403f11099db9a0398f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1120/format:webp/1*fEw1IVGVyWdkkYdZRq6uPw.png"/></div></figure><p id="32e2" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">然而，这在NER的背景下是错误的，它大大高估了模型的性能。这是因为在NER，我们不关心每个<strong class="lb iu">个体</strong>标记的好坏，相反，我们感兴趣的是NER标记的每个<strong class="lb iu">序列</strong>标记的好坏。除此之外，将宏F1直接应用于模型输出将衡量我们的模型相对于标签{O，B-PER，I-PER，B-GEO，I-GEO，B-ORG，I-ORG}的表现如何。但是回想一下，生物表征是我们用来提高训练的东西，但这不是我们在推理过程中感兴趣的。相反，我们关心哪些项目被分类为{O、PER、GEO和ORG}。这意味着我们需要将输出张量映射回我们的原始类标签，从而给我们一个缩减的输出张量<strong class="lb iu"> 1x13x4 </strong>。在下一节中，我们将详细说明F1分数如何应用于<strong class="lb iu">序列</strong>级别，而不是<strong class="lb iu">单个</strong>标记级别。</p><blockquote class="nc nd ne"><p id="5576" class="kz la nf lb b lc ld ju le lf lg jx lh ng lj lk ll nh ln lo lp ni lr ls lt lu im bi translated"><strong class="lb iu">关于transformers的一个注意事项:</strong>使用transformers时，额外的复杂性是所使用的记号赋予器通常按子词而不是简单地按空白分割。比如‘苹果’可能会拆分成‘App’和‘le’。这增加了四个额外的复杂性:1)我们应该考虑训练/推理的子话题吗？2)如何标注子音？3)在确定类别标签时，如何从子音聚合回单词？4)我们需要删除特殊字符(CLS，9月)。这里给出了关于这些的更多细节<a class="ae ky" href="https://github.com/namiyousef/argument-mining" rel="noopener ugc nofollow" target="_blank">。一旦处理了这些问题，问题就和上面描述的一样了，因此下面的步骤也适用于基于变压器的模型。</a></p></blockquote><h1 id="3ca1" class="mc md it bd me mf nj mh mi mj nk ml mm jz nl ka mo kc nm kd mq kf nn kg ms mt bi translated">定义NER的TP、FP和FN</h1><p id="9a69" class="pw-post-body-paragraph kz la it lb b lc mu ju le lf mv jx lh li mw lk ll lm mx lo lp lq my ls lt lu im bi translated">由于我们对预测<strong class="lb iu">序列</strong>的正确性感兴趣，我们需要调整TP、FP和FN的定义，以应用于序列级而不是令牌级。这给出了以下定义:</p><ul class=""><li id="4520" class="no np it lb b lc ld lf lg li nq lm nr lq ns lu nt nu nv nw bi translated">目标记号序列{ti，… tn}和预测记号序列{yi，… yn}之间的完美匹配</li></ul><blockquote class="nc nd ne"><p id="f4f4" class="kz la nf lb b lc ld ju le lf lg jx lh ng lj lk ll nh ln lo lp ni lr ls lt lu im bi translated"><strong class="lb iu">举例:</strong>约翰·史密斯<strong class="lb iu"> → </strong>真实标签<strong class="lb iu"> : </strong> {PER，PER}，预测标签:{PER，PER}</p></blockquote><ul class=""><li id="cbdf" class="no np it lb b lc ld lf lg li nq lm nr lq ns lu nt nu nv nw bi translated"><strong class="lb iu"> FN: </strong>没有完全匹配的预测序列{yi，… yn}的目标序列{ti，… tn}</li></ul><blockquote class="nc nd ne"><p id="3e2e" class="kz la nf lb b lc ld ju le lf lg jx lh ng lj lk ll nh ln lo lp ni lr ls lt lu im bi translated"><strong class="lb iu">示例:</strong> John Smith →真实标签:{PER，PER}，预测标签:{ORG，ORG}</p></blockquote><ul class=""><li id="d29d" class="no np it lb b lc ld lf lg li nq lm nr lq ns lu nt nu nv nw bi translated"><strong class="lb iu"> FP: </strong>没有完全匹配的目标序列{yi，… yn}的预测序列{yi，… yn}</li></ul><blockquote class="nc nd ne"><p id="ce6c" class="kz la nf lb b lc ld ju le lf lg jx lh ng lj lk ll nh ln lo lp ni lr ls lt lu im bi translated"><strong class="lb iu">示例:</strong>美国→预测标签:{ORG，ORG}，真实标签:{ORG}(美国)</p></blockquote><p id="c470" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">当试图确定F值时，这带来了许多挑战:</p><ol class=""><li id="c757" class="no np it lb b lc ld lf lg li nq lm nr lq ns lu nx nu nv nw bi translated"><strong class="lb iu">不同长度:</strong>我们的黄金标签可能是(John Smith，PER)但是模型可能预测(John Smith He，PER)。</li><li id="25f2" class="no np it lb b lc ny lf nz li oa lm ob lq oc lu nx nu nv nw bi translated"><strong class="lb iu"> Missing targets: </strong>我们的金牌标签可能是(Apple，ORG)，但我们的模型可能不会预测整个句子的任何ORG。</li><li id="004a" class="no np it lb b lc ny lf nz li oa lm ob lq oc lu nx nu nv nw bi translated"><strong class="lb iu">遗漏预测:</strong>对于一个特定的句子，我们可能没有任何ORG标记，但是我们的模型可以预测一系列标记上的ORG</li></ol><p id="054a" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">另一个考虑是，有时我们对完美的比赛不感兴趣，但我们会对势均力敌的比赛感到满意。这是典型的情况，其中NER任务是在较长的序列上，例如，从专利中提取权利要求，从文章中提取论点，等等</p><p id="8282" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">在这种情况下，我们可以为匹配定义一个可接受的<strong class="lb iu">阈值</strong>，例如两个序列的50%必须匹配。这意味着，如果我们有黄金标签(John Smith，PER)和预测(Smith He，PER ),那么它仍将被视为匹配，因为两个示例的匹配重叠为50%。</p><p id="a394" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">下一节将更详细地描述该算法。</p></div><div class="ab cl lv lw hx lx" role="separator"><span class="ly bw bk lz ma mb"/><span class="ly bw bk lz ma mb"/><span class="ly bw bk lz ma"/></div><div class="im in io ip iq"><h1 id="45a9" class="mc md it bd me mf mg mh mi mj mk ml mm jz mn ka mo kc mp kd mq kf mr kg ms mt bi translated">算法:一步一步来</h1><p id="e525" class="pw-post-body-paragraph kz la it lb b lc mu ju le lf mv jx lh li mw lk ll lm mx lo lp lq my ls lt lu im bi translated">我将展示在两个文档上工作的算法，以涵盖所有边缘情况。我还将使用一个基于transformer的模型来展示算法的完整范围。如果你对这些不熟悉，我建议从<strong class="lb iu">步骤5 </strong>开始(但也强烈鼓励你学习变形金刚，因为它们是NLP中的Step)).</p><p id="5fbc" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">步骤1和2与如何准备数据有关。步骤3和4与模型预测相关。从第5步开始就是严格的推理。</p><p id="d600" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">输入数据如下所示:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi od"><img src="../Images/5952b7f8a0c77657568c97932bbcafcd.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*TJnbBZ_yZP20EnXcnLJQ8A.png"/></div></div></figure><h2 id="d97b" class="oe md it bd me of og dn mi oh oi dp mm li oj ok mo lm ol om mq lq on oo ms op bi translated">第一步:贴标签</h2><p id="9293" class="pw-post-body-paragraph kz la it lb b lc mu ju le lf mv jx lh li mw lk ll lm mx lo lp lq my ls lt lu im bi translated">标签是使用标签方案创建的。这里用的是BIO。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi oq"><img src="../Images/3154006144be1883450e2da441067657.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*4GiTw27EsKfrFWNDL38c-g.png"/></div></div></figure><h2 id="6131" class="oe md it bd me of og dn mi oh oi dp mm li oj ok mo lm ol om mq lq on oo ms op bi translated">第二步:符号化</h2><p id="a11c" class="pw-post-body-paragraph kz la it lb b lc mu ju le lf mv jx lh li mw lk ll lm mx lo lp lq my ls lt lu im bi translated">现在标签已经创建，文档通过<a class="ae ky" href="https://huggingface.co/" rel="noopener ugc nofollow" target="_blank">贴合面</a>标记器。子标记也必须被标记。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi or"><img src="../Images/ac80c96466a4b6dbef2ddd523ef63a85.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*T_MbA4xzYDgPU-mpJW3r9w.png"/></div></div><figcaption class="ku kv gj gh gi kw kx bd b be z dk translated">请注意，文档1中的“Unit”和“ed”以及文档2中的“John”和“ny”具有相同的word _ ids，表明它们来自同一个单词。在这种情况下，子发音“ed”和“ny”被赋予了相同的标签“I-{ENT}”(您也可以赋予它们起始子发音的标签)。最后，特殊标记[CLS]、[SEP]和[PAD]被赋予-100的标签，以便在损失计算和推断中忽略它们。</figcaption></figure><blockquote class="nc nd ne"><p id="7b6b" class="kz la nf lb b lc ld ju le lf lg jx lh ng lj lk ll nh ln lo lp ni lr ls lt lu im bi translated"><strong class="lb iu">注意:</strong>这里的标记化是任意的。选择了15的<strong class="lb iu">最大长度</strong>。attention_mask被省略，并且添加了一个<strong class="lb iu"> word_ids </strong>张量来反映记号所属的单词。</p></blockquote><h2 id="3516" class="oe md it bd me of og dn mi oh oi dp mm li oj ok mo lm ol om mq lq on oo ms op bi translated">第三步:预测</h2><p id="a872" class="pw-post-body-paragraph kz la it lb b lc mu ju le lf mv jx lh li mw lk ll lm mx lo lp lq my ls lt lu im bi translated">输入被传递到一个拥抱脸模型中，并给出每一类的预测。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi os"><img src="../Images/293fbd7ca5a31cf5ac58628807d1759b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*fqVMQCMQ8_v0rEhTVUyAnA.png"/></div></div><figcaption class="ku kv gj gh gi kw kx bd b be z dk translated">对于每个标记，模型输出每个类别的概率(每个标记的较高值以<strong class="bd me">粗体显示，在图像中</strong>仅针对<strong class="bd me">文档1 </strong>显示)。通常，简单地采用argmax函数会给出最可能的类。然而，对于需要聚合回单词的子单词，argmax操作是未定义的。例如，取' Unit '和' ed '的argmax分别给出类3和0。但是我们如何给“曼联”分类呢？请注意，在这一点上，我们忽略了对特殊标记[CLS]、[SEP]和[PAD](灰显)的预测。</figcaption></figure><h2 id="910a" class="oe md it bd me of og dn mi oh oi dp mm li oj ok mo lm ol om mq lq on oo ms op bi translated">第四步:聚合回单词</h2><p id="27ca" class="pw-post-body-paragraph kz la it lb b lc mu ju le lf mv jx lh li mw lk ll lm mx lo lp lq my ls lt lu im bi translated">使用每个子发音的预测，我们需要聚合回单词，以确定单词的类别标签。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ot"><img src="../Images/337b53c759cff977811626482907d9e5.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*mTIt9cYpOAYkjvMcZdvRUg.png"/></div></div><figcaption class="ku kv gj gh gi kw kx bd b be z dk translated">上图显示了如何为<strong class="bd me">文档1 </strong>处理不明确的术语。显示了三种聚合策略:第一，平均值和最大值。<strong class="bd me"> First </strong>只考虑第一个子发音的概率。<strong class="bd me">表示</strong>取所有子音的平均值，<strong class="bd me"> max </strong>取最大值。这显示在图像的上半部分。在下半部分，使用first聚合策略显示了两个文档的完整预测标签。</figcaption></figure><h2 id="c499" class="oe md it bd me of og dn mi oh oi dp mm li oj ok mo lm ol om mq lq on oo ms op bi translated">第五步:减少到金色标签</h2><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ou"><img src="../Images/eebd65fb1ec3c54e500ed05731c19bea.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*ORmm41MUDP9yIACqky5OlA.png"/></div></div><figcaption class="ku kv gj gh gi kw kx bd b be z dk translated">用于训练的扩展类(例如B-{ENT}，I-{ENT})被减少到仅它们的核心标签(例如ENT)。这在上面有图示。</figcaption></figure><h2 id="e820" class="oe md it bd me of og dn mi oh oi dp mm li oj ok mo lm ol om mq lq on oo ms op bi translated">步骤6:获取连续的文本片段</h2><p id="87e2" class="pw-post-body-paragraph kz la it lb b lc mu ju le lf mv jx lh li mw lk ll lm mx lo lp lq my ls lt lu im bi translated">对于预测和基本事实，连续文本段的数据帧(如类标签所示)被创建。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ov"><img src="../Images/84216ce12d0220ab59e50d983d9fab9b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Sc5GNPKlthuIkX2q2hyMUg.png"/></div></div><figcaption class="ku kv gj gh gi kw kx bd b be z dk translated">地面实况数据帧包含连续的文本段(基于类别标签)。值得注意的是，单词位置是比较段所必需的。这是因为一个文本文档可以有多个相同的文本段，但出现在不同的位置。</figcaption></figure><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ow"><img src="../Images/e910d46bd9be12a609455d01bc8daa28.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*e5i6c7h2-yMJR_SPAgSHQQ.png"/></div></div><figcaption class="ku kv gj gh gi kw kx bd b be z dk translated">预测数据框。您可以看到这个数据帧有更多的行，因为预测非常不一致。值得注意的是，对于文档1 (doc_id=0 ),我们有一个没有出现在基础事实中的对类3的预测。类似地，对于文件2，我们有一个没有出现在地面真理中的对类2的预测。最后，在文件2中，我们可以看到，没有对0类的预测，即使地面真相有这些项目。在下一节中，我们将看到这些是如何处理的。</figcaption></figure><h2 id="47d5" class="oe md it bd me of og dn mi oh oi dp mm li oj ok mo lm ol om mq lq on oo ms op bi translated">第七步:获得真正的肯定</h2><p id="fe5d" class="pw-post-body-paragraph kz la it lb b lc mu ju le lf mv jx lh li mw lk ll lm mx lo lp lq my ls lt lu im bi translated">为了确定连续文本段之间的重叠，在(doc_id，class)上进行完全连接。然后，比较每对位置段。使用下面的等式，可以找到基础事实与预测的重叠以及预测与基础事实的重叠:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ox"><img src="../Images/8168731091092cf0ddc3fb83838b1120.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*kdSIq9273DoDT6D5b-OoTw.png"/></div></div></figure><p id="c21c" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">如果<strong class="lb iu">和</strong>都超过一个阈值(这里为0.5)，则表明该对片段是真阳性:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi oy"><img src="../Images/bd5f1de1d7b4c59905a4c0d5786bc6d7.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*eaYmnhgkskJnAHaUbBrUNg.png"/></div></div></figure><p id="2084" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">比较和重叠显示在以下示例中:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi oz"><img src="../Images/12f940735ef5bcdc6f16f6dcf8a8d9e3.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*SIqF0BsVeIBGkzJN0F7Ijw.png"/></div></div><figcaption class="ku kv gj gh gi kw kx bd b be z dk translated">索引<strong class="bd me"> gt_index </strong>和<strong class="bd me"> pred_index </strong>指的是合并前每个数据帧的索引。这是必要的，以确保我们只计算每个项目一次。我们可以在<strong class="bd me"> gt_segment </strong>和<strong class="bd me"> pred_segment </strong>中看到一些空白项。这些分别表示预测过高/过低。例如，在文档1中，我们有一个{2}预测为类别3 ( <strong class="bd me">过度预测</strong>)，但是在基本事实中没有类别3的实例。因此<strong class="bd me"> gt_segment </strong>为空，而<strong class="bd me"> gt_index </strong>的值为<strong class="bd me"> NaN </strong>。另一方面，在文件2中，我们将{0}、{2}和{5，6，7}都作为地面真值表中的类0，但是没有相应的预测(<strong class="bd me"> underprediction </strong>)。因此<strong class="bd me">预解码段</strong>为空，并且<strong class="bd me">预解码索引</strong>取值为<strong class="bd me"> NaN </strong>。</figcaption></figure><h2 id="4604" class="oe md it bd me of og dn mi oh oi dp mm li oj ok mo lm ol om mq lq on oo ms op bi translated">第八步:获得假阳性和假阴性</h2><p id="62f2" class="pw-post-body-paragraph kz la it lb b lc mu ju le lf mv jx lh li mw lk ll lm mx lo lp lq my ls lt lu im bi translated">首先，来自真阳性的所有基础事实和预测片段被忽略。这是为了确保我们不会重复计算。</p><p id="c8a7" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">接下来，所有不匹配的地面事实被宣布为<strong class="lb iu">假阴性</strong>，而不匹配的预测被宣布为<strong class="lb iu">假阳性</strong>。这花了我一段时间来理解，所以我希望下面的数字有所帮助。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi pa"><img src="../Images/94b77f37e763b3f019ebbd8bf2606c99.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*bsJ1ZS1mb8oiA17sJdFD4g.png"/></div></div><figcaption class="ku kv gj gh gi kw kx bd b be z dk translated">在左侧，您可以看到步骤7中的重叠表。所有被视为匹配的项目(例如，真阳性)都已变灰。任何不匹配的事实都用红色圈出，而所有不匹配的预测都用蓝色圈出。重复项变灰(例如，文档1中的{4，5，6，7})。在右边，您可以在不同的表格中看到真阳性、假阴性和假阳性！</figcaption></figure><h2 id="d1be" class="oe md it bd me of og dn mi oh oi dp mm li oj ok mo lm ol om mq lq on oo ms op bi translated">第九步:分组</h2><p id="497b" class="pw-post-body-paragraph kz la it lb b lc mu ju le lf mv jx lh li mw lk ll lm mx lo lp lq my ls lt lu im bi translated">现在我们有了所有的TP、FP和FN，我们可以按类对它们进行分组，并计算F1分数。我们还可以计算任何使用TP-FP-FN的度量。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi pb"><img src="../Images/7f220deff4128ec79e43d2b87fa9e748.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*2L-9opWPHJcOYDuLzuU5tg.png"/></div></div></figure><p id="aadd" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">然后，我们可以通过计算<strong class="lb iu">宏观得分</strong>来确定整体模型性能。在这种情况下，宏F1只是整个模型中F1分数的平均值。因此我们得到<strong class="lb iu">宏F1=0.465 </strong>。</p><blockquote class="nc nd ne"><p id="633f" class="kz la nf lb b lc ld ju le lf lg jx lh ng lj lk ll nh ln lo lp ni lr ls lt lu im bi translated">N <strong class="lb iu">注:</strong>在实际执行中，我们通常在最后计算F-Score。这是因为输入将被分批，因此我们在计算F分数之前收集每批的数据框架。</p></blockquote></div><div class="ab cl lv lw hx lx" role="separator"><span class="ly bw bk lz ma mb"/><span class="ly bw bk lz ma mb"/><span class="ly bw bk lz ma"/></div><div class="im in io ip iq"><h1 id="e7d0" class="mc md it bd me mf mg mh mi mj mk ml mm jz mn ka mo kc mp kd mq kf mr kg ms mt bi translated">高效PyTorch实施</h1><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="pc pd l"/></div></figure><blockquote class="nc nd ne"><p id="c264" class="kz la nf lb b lc ld ju le lf lg jx lh ng lj lk ll nh ln lo lp ni lr ls lt lu im bi translated"><strong class="lb iu">注意:</strong>上面的代码块有很多本文没有讨论的实现细节(比如批处理)。我把它放在这里，这样你可以从这篇文章中了解到不同的部分是如何组合在一起的。可以在<a class="ae ky" href="https://github.com/namiyousef/argument-mining" rel="noopener ugc nofollow" target="_blank"> ArgMiner </a>的评估模块下找到完整代码。</p></blockquote></div><div class="ab cl lv lw hx lx" role="separator"><span class="ly bw bk lz ma mb"/><span class="ly bw bk lz ma mb"/><span class="ly bw bk lz ma"/></div><div class="im in io ip iq"><h1 id="e6a6" class="mc md it bd me mf mg mh mi mj mk ml mm jz mn ka mo kc mp kd mq kf mr kg ms mt bi translated">结束语</h1><h2 id="e0a6" class="oe md it bd me of og dn mi oh oi dp mm li oj ok mo lm ol om mq lq on oo ms op bi translated">关键要点</h2><ul class=""><li id="92ff" class="no np it lb b lc mu lf mv li pe lm pf lq pg lu nt nu nv nw bi translated">F-Score是一种广泛使用的度量标准，用于确定分类性能。它适用于NER，并进行修正，以确保它适用于<strong class="lb iu">序列</strong>级，而不是<strong class="lb iu">令牌</strong>级。</li><li id="02ca" class="no np it lb b lc ny lf nz li oa lm ob lq oc lu nt nu nv nw bi translated">它的计算伴随着寻找正确的真阳性、假阳性和假阴性的挑战</li><li id="643b" class="no np it lb b lc ny lf nz li oa lm ob lq oc lu nt nu nv nw bi translated"><strong class="lb iu">真阳性</strong>是超过用户指定的<strong class="lb iu">阈值</strong>的预测序列和基本真实序列之间的匹配</li><li id="96b1" class="no np it lb b lc ny lf nz li oa lm ob lq oc lu nt nu nv nw bi translated"><strong class="lb iu">假阳性</strong>是没有匹配基础真实序列的预测序列</li><li id="5c8f" class="no np it lb b lc ny lf nz li oa lm ob lq oc lu nt nu nv nw bi translated"><strong class="lb iu">假阴性</strong>是没有匹配预测序列的基础真实序列</li><li id="1bf9" class="no np it lb b lc ny lf nz li oa lm ob lq oc lu nt nu nv nw bi translated">对于短序列预测任务(例如NER ),阈值<strong class="lb iu">通常非常高(接近1 ),但对于较长序列预测任务(例如参数挖掘)则较低(接近0.5)</strong></li><li id="2224" class="no np it lb b lc ny lf nz li oa lm ob lq oc lu nt nu nv nw bi translated">变压器模型给计算过程增加了挑战，因为它们需要将<strong class="lb iu">子符号</strong>聚合<strong class="lb iu">回单词。</strong></li></ul><h2 id="ce0e" class="oe md it bd me of og dn mi oh oi dp mm li oj ok mo lm ol om mq lq on oo ms op bi translated">实施说明:</h2><ul class=""><li id="2d4d" class="no np it lb b lc mu lf mv li pe lm pf lq pg lu nt nu nv nw bi translated">如果对开箱即用的代码感兴趣，可以在<a class="ae ky" href="https://github.com/namiyousef/argument-mining" rel="noopener ugc nofollow" target="_blank"> ArgMiner </a>的评估模块下找到一个<strong class="lb iu">早期访问发布</strong>版本</li><li id="5b4d" class="no np it lb b lc ny lf nz li oa lm ob lq oc lu nt nu nv nw bi translated">虽然代码的编写是为了提高效率，但我希望通过再次访问这些步骤来检查冗余，从而提高推理速度。我也在考虑使用cuDF来加快计算速度，因为主要的瓶颈来自熊猫。如果你对此感兴趣，请留意<a class="ae ky" href="https://github.com/namiyousef/argument-mining" rel="noopener ugc nofollow" target="_blank"> ArgMiner </a>的变化。此外，请留意<a class="ae ky" href="https://github.com/namiyousef/ml-utils" rel="noopener ugc nofollow" target="_blank"> mlutils/torchtools </a>，因为我可能会在那里重构部分推理代码以供通用(例如，不与ArgMiner绑定)。</li></ul><div class="ph pi gp gr pj pk"><a href="https://github.com/namiyousef/argument-mining" rel="noopener  ugc nofollow" target="_blank"><div class="pl ab fo"><div class="pm ab pn cl cj po"><h2 class="bd iu gy z fp pp fr fs pq fu fw is bi translated">GitHub-Nami yousef/argument-mining:NLP项目的存储库。当我们决定更改名称时…</h2><div class="pr l"><h3 class="bd b gy z fp pp fr fs pq fu fw dk translated">argminer是一个基于PyTorch的包，用于在最先进的数据集上进行参数挖掘。它为…提供了一个高级API</h3></div><div class="ps l"><p class="bd b dl z fp pp fr fs pq fu fw dk translated">github.com</p></div></div><div class="pt l"><div class="pu l pv pw px pt py ks pk"/></div></div></a></div><div class="ph pi gp gr pj pk"><a href="https://github.com/namiyousef/ml-utils" rel="noopener  ugc nofollow" target="_blank"><div class="pl ab fo"><div class="pm ab pn cl cj po"><h2 class="bd iu gy z fp pp fr fs pq fu fw is bi translated">GitHub - namiyousef/ml-utils:有用的ML util函数</h2><div class="pr l"><h3 class="bd b gy z fp pp fr fs pq fu fw dk translated">此时您不能执行该操作。您已使用另一个标签页或窗口登录。您已在另一个选项卡中注销，或者…</h3></div><div class="ps l"><p class="bd b dl z fp pp fr fs pq fu fw dk translated">github.com</p></div></div><div class="pt l"><div class="pz l pv pw px pt py ks pk"/></div></div></a></div></div><div class="ab cl lv lw hx lx" role="separator"><span class="ly bw bk lz ma mb"/><span class="ly bw bk lz ma mb"/><span class="ly bw bk lz ma"/></div><div class="im in io ip iq"><h1 id="9c02" class="mc md it bd me mf mg mh mi mj mk ml mm jz mn ka mo kc mp kd mq kf mr kg ms mt bi translated">参考</h1><ol class=""><li id="0792" class="no np it lb b lc mu lf mv li pe lm pf lq pg lu nx nu nv nw bi translated">我在NER语境下对TP、FN和FP的定义是基于对<a class="ae ky" href="https://www.kaggle.com/competitions/feedback-prize-2021/overview/evaluation" rel="noopener ugc nofollow" target="_blank"> Kaggle </a>的反馈奖竞赛的评价。</li></ol><p id="7eed" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><em class="nf">所有图片均由作者提供，除非另有说明</em></p></div></div>    
</body>
</html>