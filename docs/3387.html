<html>
<head>
<title>Galactica: How to (Responsibly) Use the Controversial Language Model Everyone Is Talking About</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">卡拉狄加:如何(负责任地)使用大家都在谈论的有争议的语言模型</h1>
<blockquote>原文：<a href="https://pub.towardsai.net/galactica-how-to-responsibly-use-the-language-model-everyone-is-talking-about-31882a7c7339?source=collection_archive---------2-----------------------#2022-12-10">https://pub.towardsai.net/galactica-how-to-responsibly-use-the-language-model-everyone-is-talking-about-31882a7c7339?source=collection_archive---------2-----------------------#2022-12-10</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><figure class="gl gn jr js jt ju gh gi paragraph-image"><div role="button" tabindex="0" class="jv jw di jx bf jy"><div class="gh gi jq"><img src="../Images/97982329125afc384504ba0a364826e7.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*y2LF9lSWr-1UiBiW"/></div></div><figcaption class="kb kc gj gh gi kd ke bd b be z dk translated">安妮·斯普拉特在<a class="ae kf" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上的照片</figcaption></figure><h1 id="319f" class="kg kh it bd ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld bi translated">介绍</h1><p id="9273" class="pw-post-body-paragraph le lf it lg b lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma mb im bi translated">也许你已经读过很多关于MetaAI在11月发布的语言模型Galactica的文章。在最初的论文中，作者声称卡拉狄加可以通过提供一个能够“理解”科学的模型来帮助管理科学知识的爆炸。他们声称，像Galactica这样的系统能够整合来自不同来源的知识，并找到它们之间有趣的关系，从而与普通搜索引擎相比，提高了返回的结果。但是它到了吗？</p><p id="dc6c" class="pw-post-body-paragraph le lf it lg b lh mc lj lk ll md ln lo lp me lr ls lt mf lv lw lx mg lz ma mb im bi translated">在这篇文章中，我将解释什么是卡拉狄加以及围绕它的争议和戏剧，这些争议和戏剧最终导致了可用的<a class="ae kf" href="https://galactica.org/" rel="noopener ugc nofollow" target="_blank">免费演示</a>的取消(MetaAI的董事总经理Joelle Pineau在演示网站上发表了一篇短文，解释了演示取消的原因)。但是……如果你能一直陪我到这篇文章结束，我将向你展示如何用最少的Python知识自己使用这个模型！最后，我将提出我自己对此事的一些拙见。</p><p id="92f2" class="pw-post-body-paragraph le lf it lg b lh mc lj lk ll md ln lo lp me lr ls lt mf lv lw lx mg lz ma mb im bi translated">这篇文章还提供了一个<strong class="lg iu">小挑战</strong>:整篇文章中有<em class="mh">一小段</em>(只有一个，我发誓)是在卡拉狄加的帮助下写的。如果你能找到它，请在评论中告诉我！</p><h1 id="0ed7" class="kg kh it bd ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld bi translated">卡拉狄加是什么？</h1><p id="6a38" class="pw-post-body-paragraph le lf it lg b lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma mb im bi translated">Galactica就是通常所说的大型语言模型(LLM)，一种能够模拟人类语言复杂概念的人工智能算法，并生成(理论上)有意义的文本。在过去的十年中，LLM对自然语言处理的许多领域产生了重大影响，包括机器翻译、问题回答、自然语言推理和语言建模。这些模型是在大量文本语料库上训练的。许多法律硕士还会多种语言，这意味着他们接受的是用多种语言编写的文本培训。</p><figure class="mi mj mk ml gt ju"><div class="bz fp l di"><div class="mm mn l"/></div><figcaption class="kb kc gj gh gi kd ke bd b be z dk translated">卡拉狄加模型的介绍</figcaption></figure><p id="ecd2" class="pw-post-body-paragraph le lf it lg b lh mc lj lk ll md ln lo lp me lr ls lt mf lv lw lx mg lz ma mb im bi translated">根据MetaAI自己的首席人工智能Yann LeCun的话，我们可以将它视为“自动完成一切”，这是一种可以帮助生成新的科学著作的工具，但仍然依赖于人的干预来实际策划生成的文本。论文的以下摘录完美地总结了这一观点:</p><blockquote class="mo mp mq"><p id="5fb8" class="le lf mh lg b lh mc lj lk ll md ln lo mr me lr ls ms mf lv lw mt mg lz ma mb im bi translated">Galactica被用来帮助撰写本文，包括推荐遗漏的引文、引言和相关工作中要讨论的主题、推荐进一步的工作，以及帮助撰写摘要和结论。</p></blockquote><p id="3dd8" class="pw-post-body-paragraph le lf it lg b lh mc lj lk ll md ln lo lp me lr ls lt mf lv lw lx mg lz ma mb im bi translated">卡拉狄加<em class="mh">帮</em>写了自己的论文！这是一件好事吗？这将有助于在未来产生更好的科学作品。或者这是一件坏事，一个只会被用来传播错误信息和虚假事实的启示录式人工智能？但更重要的是，它真的准备好被任何科学领域的研究人员使用了吗？我们能在多大程度上信任这个模型的输出？这个模型是一个可以用来更好地自动化错误信息传播的工具吗？</p><p id="bc9c" class="pw-post-body-paragraph le lf it lg b lh mc lj lk ll md ln lo lp me lr ls lt mf lv lw lx mg lz ma mb im bi translated">让我们先试着理解这个模型的能力和局限性。</p><h2 id="33cf" class="mu kh it bd ki mv mw dn km mx my dp kq lp mz na ku lt nb nc ky lx nd ne lc nf bi translated">文章和论文生成</h2><p id="686b" class="pw-post-body-paragraph le lf it lg b lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma mb im bi translated">这种模式最广为人知的特点之一是它能够生成整篇论文或维基百科文章。用户将插入一个标题(例如，“关于科学著作生成的大型语言模型的调查”)，模型将生成一个完整的文本，包括摘要、章节、数学公式，甚至引用！</p><p id="8074" class="pw-post-body-paragraph le lf it lg b lh mc lj lk ll md ln lo lp me lr ls lt mf lv lw lx mg lz ma mb im bi translated">因为该模型是用各种主题(机器学习、生物学、计算机科学等)的论文训练的，所以理论上它可以生成专注于其中一个主题的文本，甚至可以找到跨主题的关系。</p><h2 id="a19b" class="mu kh it bd ki mv mw dn km mx my dp kq lp mz na ku lt nb nc ky lx nd ne lc nf bi translated">引用提议</h2><p id="62c6" class="pw-post-body-paragraph le lf it lg b lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma mb im bi translated">引用是向读者表明你所展示的信息来自其他来源的一种方式。在科学论文中，这通常用括号中的数字来表示([1]、[13])，它引用了论文末尾包含的列表。卡拉狄加实际上可以推荐几个句子的引用。为了让它工作，用户需要在他们的句子中插入文本[START_REF](例如，“LLMs like Galactica [START_REF]”)，Galactica将自动完成与句子内容相关的论文名称。</p><h2 id="003b" class="mu kh it bd ki mv mw dn km mx my dp kq lp mz na ku lt nb nc ky lx nd ne lc nf bi translated">太久了，没看(TLDR)</h2><p id="9ac8" class="pw-post-body-paragraph le lf it lg b lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma mb im bi translated">卡拉狄加可以生成TLDR，即大段文字的小摘要。这并不新鲜，有很多模型可以生成TLDR，但这仍然是一个有趣的特性，显示了模型的灵活性。</p><h2 id="f408" class="mu kh it bd ki mv mw dn km mx my dp kq lp mz na ku lt nb nc ky lx nd ne lc nf bi translated">论证</h2><p id="c81f" class="pw-post-body-paragraph le lf it lg b lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma mb im bi translated">卡拉狄加接受了一系列推理任务的训练，能够解决基本的物理问题，比如计算以特定加速度移动特定质量所需的力。</p><h2 id="0d27" class="mu kh it bd ki mv mw dn km mx my dp kq lp mz na ku lt nb nc ky lx nd ne lc nf bi translated">常见语言任务</h2><p id="4a3d" class="pw-post-body-paragraph le lf it lg b lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma mb im bi translated">这项工作最有趣的一个方面是，尽管它是在主要由科学论文组成的数据集上训练的，但根据作者的说法，它可以在普通自然语言处理任务上胜过以前的工作！作者认为这是因为他们使用的数据集的质量，声称在训练这些类型的模型时，质量比数量更好。</p><h2 id="a9f4" class="mu kh it bd ki mv mw dn km mx my dp kq lp mz na ku lt nb nc ky lx nd ne lc nf bi translated">毒性和偏见</h2><p id="8638" class="pw-post-body-paragraph le lf it lg b lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma mb im bi translated">LLM的一个常见问题是，它们是使用人类生成的文本进行训练的，因此，它们可能容易出现种族主义、刻板印象和偏见。因为消除训练数据集的所有这些邪恶态度实际上是不可能的，所以研究人员开发了测试和基准来衡量一个训练过的模型实际上有多有害。在本文中，Galactica的作者测量了它的毒性，并将其与其他语言模型进行了比较。他们的结论是，卡拉狄加比其他型号更好，尽管我们必须记住，这并不意味着它没有毒性。但事实上，它们比现有的基准有所改进，这仍然是引人注目的。同样，作者认为这是他们用来训练模型的数据集质量的直接原因。</p><h2 id="ca20" class="mu kh it bd ki mv mw dn km mx my dp kq lp mz na ku lt nb nc ky lx nd ne lc nf bi translated">未来的工作</h2><p id="5bff" class="pw-post-body-paragraph le lf it lg b lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma mb im bi translated">作者想要探索的一个有趣的补充是捕捉图像中包含的信息的方法(对于一个声称是为组织科学知识而量身定制的模型来说，这是一个自然的下一步)。</p><p id="9704" class="pw-post-body-paragraph le lf it lg b lh mc lj lk ll md ln lo lp me lr ls lt mf lv lw lx mg lz ma mb im bi translated">作者还强调需要改进这种人工智能算法的验证过程，以确保生成的数据不仅听起来权威，看起来正确，而且实际上T2是正确和可信的。根据尝试过之前可用演示的Twitter用户的强烈反对，这似乎是作者应该努力的主要主题。</p><h2 id="b3e1" class="mu kh it bd ki mv mw dn km mx my dp kq lp mz na ku lt nb nc ky lx nd ne lc nf bi translated">限制</h2><p id="fda8" class="pw-post-body-paragraph le lf it lg b lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma mb im bi translated">当然，卡拉狄加是<strong class="lg iu">而不是</strong>一个全能的模型，能够独立进行科学研究，<strong class="lg iu">也不是</strong>它能够始终提供科学上准确的信息。在本文的结尾有一个完整的部分，其中提供了限制和警告。</p><p id="cbf1" class="pw-post-body-paragraph le lf it lg b lh mc lj lk ll md ln lo lp me lr ls lt mf lv lw lx mg lz ma mb im bi translated">首先，该模型仅使用开放获取的论文进行训练，这些论文仅包含整个可用科学知识的一小部分:随着更多来源的增加，性能和泛化能力应该会提高。</p><p id="3893" class="pw-post-body-paragraph le lf it lg b lh mc lj lk ll md ln lo lp me lr ls lt mf lv lw lx mg lz ma mb im bi translated">作者还建议不要使用该模型来生成关于诸如“的首都是什么”等问题的常识答案的文本，因为尽管卡拉狄加可能知道答案，但它没有受过这方面的训练。</p><p id="2779" class="pw-post-body-paragraph le lf it lg b lh mc lj lk ll md ln lo lp me lr ls lt mf lv lw lx mg lz ma mb im bi translated">包含公开演示的网页也提供了一些限制:</p><ul class=""><li id="efb2" class="ng nh it lg b lh mc ll md lp ni lt nj lx nk mb nl nm nn no bi translated">LLM容易产生幻觉！你不应该在未经核实的情况下听从LLM的建议！</li><li id="a767" class="ng nh it lg b lh np ll nq lp nr lt ns lx nt mb nl nm nn no bi translated">Galactica倾向于生成与被大量引用的概念相关的内容，所以如果你生成关于不太为人知的主题的文本，要小心。</li><li id="08f7" class="ng nh it lg b lh np ll nq lp nr lt ns lx nt mb nl nm nn no bi translated">更重要的警告是:“<em class="mh">卡拉狄加生成的一些文本可能看起来非常真实、非常自信，但在一些重要方面可能存在微妙的错误。</em>”</li></ul><h1 id="fc51" class="kg kh it bd ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld bi translated">围绕它的争议(和戏剧)</h1><p id="35ab" class="pw-post-body-paragraph le lf it lg b lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma mb im bi translated">尽管所有这些之前的功能看起来都非常有前途，但Galactica 的<a class="ae kf" href="https://galactica.org/" rel="noopener ugc nofollow" target="_blank">公开演示受到了谨慎的对待，在几个小时的测试后，完全被拒绝。</a></p><p id="2899" class="pw-post-body-paragraph le lf it lg b lh mc lj lk ll md ln lo lp me lr ls lt mf lv lw lx mg lz ma mb im bi translated">演示一上线，Twitter用户和来自世界各地的研究人员就前往网站尝试该模型。这个演示用来生成各种输出，有些是准确的，有些是有问题的。这个社区很快分成了两个截然不同的团体:一个支持这个模型，另一个声称这个模型很危险，不应该公开。</p><p id="2fce" class="pw-post-body-paragraph le lf it lg b lh mc lj lk ll md ln lo lp me lr ls lt mf lv lw lx mg lz ma mb im bi translated">该模型的批评者引用最多的推文之一是马克斯·普朗克智能系统研究所所长迈克尔·布莱克的观点。</p><figure class="mi mj mk ml gt ju"><div class="bz fp l di"><div class="mm mn l"/></div><figcaption class="kb kc gj gh gi kd ke bd b be z dk translated">迈克尔·布莱克的担忧</figcaption></figure><p id="ccdc" class="pw-post-body-paragraph le lf it lg b lh mc lj lk ll md ln lo lp me lr ls lt mf lv lw lx mg lz ma mb im bi translated">反对卡拉狄加的论点倾向于围绕这个模型可能的误用。赞同这一观点的用户表达了他们的担忧，即卡拉狄加发表的文章可能让<em class="mh">听起来</em>自信，让<em class="mh">看起来</em>像真正的科学著作，但包含虚假信息。他们还声称，这种模式的广泛使用甚至可以使虚假信息不被审稿人发现，从而发表具有误导内容的论文。</p><p id="df20" class="pw-post-body-paragraph le lf it lg b lh mc lj lk ll md ln lo lp me lr ls lt mf lv lw lx mg lz ma mb im bi translated">卡拉狄加保卫者一方由真正的扬·勒昆领导，他声称这种LLM可能产生的谎言和误导性事实与人类可以编造的谎言没有什么不同，并为卡拉狄加的创造者辩护:</p><figure class="mi mj mk ml gt ju"><div class="bz fp l di"><div class="mm mn l"/></div><figcaption class="kb kc gj gh gi kd ke bd b be z dk translated">Yann LeCun为整个LLMs辩护</figcaption></figure><figure class="mi mj mk ml gt ju"><div class="bz fp l di"><div class="mm mn l"/></div><figcaption class="kb kc gj gh gi kd ke bd b be z dk translated">扬·勒昆为《卡拉狄加》的作者辩护</figcaption></figure><p id="f500" class="pw-post-body-paragraph le lf it lg b lh mc lj lk ll md ln lo lp me lr ls lt mf lv lw lx mg lz ma mb im bi translated">虽然这个讨论是从卡拉狄加开始的，但它已经扩展到了其他模型，比如ChatGPT和LLMs。</p><h2 id="9c98" class="mu kh it bd ki mv mw dn km mx my dp kq lp mz na ku lt nb nc ky lx nd ne lc nf bi translated">动手！</h2><p id="0c78" class="pw-post-body-paragraph le lf it lg b lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma mb im bi translated">也许你已经在我以前的文章中看到了，但是我喜欢提供代码的文章，这样你就可以自己测试了。尽管曾经有一个界面很好的网站来测试这个模型，但正如前面所讨论的，由于社区的强烈反对，这个网站被关闭了。但这只是针对普通大众:如果你懂一点Python，实际上有一个<a class="ae kf" href="https://github.com/paperswithcode/galai" rel="noopener ugc nofollow" target="_blank"> GitHub库</a>解释如何下载模型的不同版本，以及如何使用它生成文本！</p><p id="24a1" class="pw-post-body-paragraph le lf it lg b lh mc lj lk ll md ln lo lp me lr ls lt mf lv lw lx mg lz ma mb im bi translated">首先，也是最重要的:如果你想使用这个现成的，你需要在你的电脑上安装一个GPU和CUDA工具包。我不会进入安装细节，因为网上已经有很多关于这个问题的优秀教程。所以让我们开始吧:</p><figure class="mi mj mk ml gt ju"><div class="bz fp l di"><div class="nu mn l"/></div></figure><p id="fd4b" class="pw-post-body-paragraph le lf it lg b lh mc lj lk ll md ln lo lp me lr ls lt mf lv lw lx mg lz ma mb im bi translated">此示例向您展示了自己运行模型所需的最低要求。首先，我们导入<em class="mh">加莱</em>包和<em class="mh">火炬</em>包。然后，我们加载一个公开的卡拉狄加模型。这里我们有5种不同的型号可供选择，每种型号都有自己的尺寸，正如报纸上报道的:<em class="mh">迷你</em>、<em class="mh">底座</em>、<em class="mh">标准</em>、<em class="mh">大型</em>和<em class="mh">巨型</em>。最后，我们查询模型，告诉它生成200个标记(字符),并插入我们希望它生成的字符串的开头。结果将是一个200个字符长的Markdown字符串，带有(希望)一些与我们作为输入插入的字符串相关的有用信息。</p><p id="1398" class="pw-post-body-paragraph le lf it lg b lh mc lj lk ll md ln lo lp me lr ls lt mf lv lw lx mg lz ma mb im bi translated">现在，因为模型的输出是Markdown格式，所以需要做一点格式化，以便能够以漂亮的格式在这里呈现它。格式化之后，我向你展示基本的Galactica模型在被问到我以前的一篇文章的主题<a class="ae kf" href="https://medium.com/towards-data-science/accelerating-neural-networks-on-hardware-baa3c14cd5ba" rel="noopener">时生成的输出:</a></p><figure class="mi mj mk ml gt ju gh gi paragraph-image"><div class="gh gi nv"><img src="../Images/22bf5f5aa07a76dc50f8d5926ccfc912.png" data-original-src="https://miro.medium.com/v2/resize:fit:1174/format:webp/1*8RCIciTBmFvqHSQ1Sd7IWg.png"/></div><figcaption class="kb kc gj gh gi kd ke bd b be z dk translated">由Galactica为提示“标题:基于脉动阵列的硬件加速器调查”生成的摘要\n\n作者:John Smith\n\n</figcaption></figure><p id="b330" class="pw-post-body-paragraph le lf it lg b lh mc lj lk ll md ln lo lp me lr ls lt mf lv lw lx mg lz ma mb im bi translated">我不得不承认，它对我来说看起来相当不错，尽管我不认为任何人会使用这种现成的输出来开始他们期望发表的实际论文。不管怎样，有趣的是它知道脉动阵列是相互通信的元素的集合。它也知道这种加速器在不同类型的应用中使用，它提到的一些优点也是正确的。也许在巨大的模型上运行相同的提示可以获得更好的结果。</p><p id="248b" class="pw-post-body-paragraph le lf it lg b lh mc lj lk ll md ln lo lp me lr ls lt mf lv lw lx mg lz ma mb im bi translated">让我们尝试一些不同的东西，并请Galactica生成一篇关于使用强化学习玩1v1游戏的维基百科文章，这是我之前的另一篇文章的主题<a class="ae kf" href="https://medium.com/towards-data-science/how-deepmind-discovered-new-ways-of-multiplying-matrices-using-ai-a04557e9f861" rel="noopener">:</a></p><figure class="mi mj mk ml gt ju gh gi paragraph-image"><div role="button" tabindex="0" class="jv jw di jx bf jy"><div class="gh gi nw"><img src="../Images/f9ceba56f58a80bb2464005562f28858.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*XFLwNkAcZkkJhF8A8Fv6Eg.png"/></div></div><figcaption class="kb kc gj gh gi kd ke bd b be z dk translated">卡拉狄加为提示“#使用强化学习玩游戏”生成的维基百科文章</figcaption></figure><p id="8918" class="pw-post-body-paragraph le lf it lg b lh mc lj lk ll md ln lo lp me lr ls lt mf lv lw lx mg lz ma mb im bi translated">这里有太多要说的了！看起来卡拉狄加声称发明了一个框架，并通过玩不同的游戏进行了测试。它对突破Atari游戏和训练程序进行了非常详细的描述，甚至引用了与这个虚构框架进行比较的论文(如果你在问自己这些论文是否存在，是的，它们都存在，是的，甚至连作者姓名都写对了)。但是…突破规则是完全错误的。</p><h2 id="0658" class="mu kh it bd ki mv mw dn km mx my dp kq lp mz na ku lt nb nc ky lx nd ne lc nf bi translated">个人愚见</h2><p id="1de2" class="pw-post-body-paragraph le lf it lg b lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma mb im bi translated">在阅读了该模型产生的大量输出结果，并查看了双方提出的论点后，我注意到大多数争议都围绕着Galactica的论文生成能力，而很少有人讨论它的其他功能，如引文生成/建议和TLDR。尽管在该模型的文本生成功能方面仍有工作要做(正如作者在论文的“未来工作”一节中所述)，但我看到了一种工具的许多未来，这种工具能够提出给定特定概念或想法的特定引用。但作为辅助工具，它的输出仍然需要<strong class="lg iu"><em class="mh"/></strong>人工审核。</p><p id="7391" class="pw-post-body-paragraph le lf it lg b lh mc lj lk ll md ln lo lp me lr ls lt mf lv lw lx mg lz ma mb im bi translated">卡拉狄加有没有可能排除某些引用结果？还是为了错过推荐一篇不太知名论文的机会？当然啦！该模型并不完美，作者在论文中解决了这两个问题。正如作者所说:</p><blockquote class="mo mp mq"><p id="82c3" class="le lf mh lg b lh mc lj lk ll md ln lo mr me lr ls ms mf lv lw mt mg lz ma mb im bi translated">我们的终极愿景是为科学任务提供动力的单一神经网络。我们相信这将是人类获取科学知识的下一个界面，我们从本文开始。</p></blockquote><p id="4cf1" class="pw-post-body-paragraph le lf it lg b lh mc lj lk ll md ln lo lp me lr ls lt mf lv lw lx mg lz ma mb im bi translated">这是一个工具的第一次迭代，这个工具应该帮助科学家们生成<strong class="lg iu"> <em class="mh">更</em> </strong>的科学，而不是为他们生成<strong class="lg iu"><em class="mh"/></strong>。我相信这是朝着正确方向迈出的一步，尽管还需要做一些工作来限制在这项工作的未来版本中被误用的机会。</p></div><div class="ab cl nx ny hx nz" role="separator"><span class="oa bw bk ob oc od"/><span class="oa bw bk ob oc od"/><span class="oa bw bk ob oc"/></div><div class="im in io ip iq"><p id="24e8" class="pw-post-body-paragraph le lf it lg b lh mc lj lk ll md ln lo lp me lr ls lt mf lv lw lx mg lz ma mb im bi translated">我想以迈克尔·布莱克关于LLMs的一些想法来结束这篇文章，你可以在<a class="ae kf" href="https://twitter.com/Michael_J_Black/status/1594945693524938752" rel="noopener ugc nofollow" target="_blank">这个</a> Twitter对话中找到。我发现他们真的很有见地，所以我想与你分享:</p><ul class=""><li id="06dd" class="ng nh it lg b lh mc ll md lp ni lt nj lx nk mb nl nm nn no bi translated">如果一篇论文使用了LLM，也许LLM应该被认为是作者。这是非常不切实际的，因为如果论文的内容受到质疑，作者应该能够为其辩护。逻辑思维模式能够解释他们在写一个特定的句子或段落时使用的“思维”过程吗？</li><li id="a2b1" class="ng nh it lg b lh np ll nq lp nr lt ns lx nt mb nl nm nn no bi translated">科学建立在人民和政府的信任之上，这为学术研究提供了所需的资金。如果这些模型产生的虚假论文开始通过审查程序并被发表，在社会比以往任何时候都更需要科学的时候，对科学的信任将会下降，从而减少资金。</li><li id="7208" class="ng nh it lg b lh np ll nq lp nr lt ns lx nt mb nl nm nn no bi translated">LLM模型的传播应该是负责任的，考虑到所涉及的风险，并开发“解毒剂”来反击这些模型可能产生的伪科学。甚至可能在这些LLM旁边提供模型，可以区分LLM生成的文本和人类生成的文本。</li></ul></div><div class="ab cl nx ny hx nz" role="separator"><span class="oa bw bk ob oc od"/><span class="oa bw bk ob oc od"/><span class="oa bw bk ob oc"/></div><div class="im in io ip iq"><p id="0ffc" class="pw-post-body-paragraph le lf it lg b lh mc lj lk ll md ln lo lp me lr ls lt mf lv lw lx mg lz ma mb im bi translated">欢迎在<a class="ae kf" href="https://twitter.com/PecciaF" rel="noopener ugc nofollow" target="_blank"> Twitter </a>或<a class="ae kf" href="https://www.linkedin.com/in/fpecc/" rel="noopener ugc nofollow" target="_blank"> LinkedIn </a>上关注我，让我知道你对这篇文章的看法，或者<a class="ae kf" href="https://www.buymeacoffee.com/pecciaf" rel="noopener ugc nofollow" target="_blank">请我喝杯咖啡</a>，如果你真的喜欢它！</p><p id="dc4d" class="pw-post-body-paragraph le lf it lg b lh mc lj lk ll md ln lo lp me lr ls lt mf lv lw lx mg lz ma mb im bi translated">感谢阅读！</p></div><div class="ab cl nx ny hx nz" role="separator"><span class="oa bw bk ob oc od"/><span class="oa bw bk ob oc od"/><span class="oa bw bk ob oc"/></div><div class="im in io ip iq"><h2 id="a25d" class="mu kh it bd ki mv mw dn km mx my dp kq lp mz na ku lt nb nc ky lx nd ne lc nf bi translated"><strong class="ak">参考文献</strong></h2><p id="2439" class="pw-post-body-paragraph le lf it lg b lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma mb im bi translated">原始纸张:</p><ul class=""><li id="3673" class="ng nh it lg b lh mc ll md lp ni lt nj lx nk mb nl nm nn no bi translated"><a class="ae kf" href="https://galactica.org/static/paper.pdf" rel="noopener ugc nofollow" target="_blank">泰勒等人《卡拉狄加:科学的大语言模型》。2022.</a></li></ul><p id="72cb" class="pw-post-body-paragraph le lf it lg b lh mc lj lk ll md ln lo lp me lr ls lt mf lv lw lx mg lz ma mb im bi translated">关于这个话题的有趣的YouTube视频:</p><ul class=""><li id="98fb" class="ng nh it lg b lh mc ll md lp ni lt nj lx nk mb nl nm nn no bi translated"><a class="ae kf" href="https://www.youtube.com/watch?v=ZTs_mXwMCs8&amp;t=2638s" rel="noopener ugc nofollow" target="_blank">卡拉狄加:科学的大型语言模型(戏剧&amp;论文综述)</a></li></ul><p id="b413" class="pw-post-body-paragraph le lf it lg b lh mc lj lk ll md ln lo lp me lr ls lt mf lv lw lx mg lz ma mb im bi translated">迈克尔·布莱克对LLMs的看法:</p><ul class=""><li id="cdcc" class="ng nh it lg b lh mc ll md lp ni lt nj lx nk mb nl nm nn no bi translated"><a class="ae kf" href="https://perceiving-systems.blog/en/news/peer-review-plagiarism-and-authorship-in-the-age-of-large-language-models" rel="noopener ugc nofollow" target="_blank">大型语言模型时代的同行评议、抄袭和作者身份</a></li></ul></div></div>    
</body>
</html>