<html>
<head>
<title>Hands-on Random Forest with Python</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">使用Python实践随机森林</h1>
<blockquote>原文：<a href="https://pub.towardsai.net/hands-on-random-forest-with-python-58a67cfb8448?source=collection_archive---------0-----------------------#2022-07-06">https://pub.towardsai.net/hands-on-random-forest-with-python-58a67cfb8448?source=collection_archive---------0-----------------------#2022-07-06</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><div class=""><h2 id="c8f9" class="pw-subtitle-paragraph jn ip iq bd b jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke dk translated">如何使用scikit-learn通过网格搜索技术实现随机森林的实用指南。</h2></div><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi kf"><img src="../Images/a974eea0eabf276875749f3ad7ffedbf.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*vqa_sBQhdOLTFReD"/></div></div><figcaption class="kr ks gj gh gi kt ku bd b be z dk translated"><a class="ae kv" href="https://unsplash.com/@lsc122746?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">刘思成</a>在<a class="ae kv" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上拍照</figcaption></figure><p id="44c9" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">一个模型可能会做出错误的预测。但如果把几个模型的预测合二为一，就能做出更好的预测。这个概念叫做集成学习。集成是组合多个模型来构建更强大的模型的方法。集合方法在过去的十年中获得了巨大的普及。基于决策树的集成模型有两种:随机森林和梯度增强。在这篇文章中，我将谈论以下话题:</p><ul class=""><li id="99a9" class="ls lt iq ky b kz la lc ld lf lu lj lv ln lw lr lx ly lz ma bi translated">什么是随机森林？</li><li id="b4c0" class="ls lt iq ky b kz mb lc mc lf md lj me ln mf lr lx ly lz ma bi translated">随机森林的一些优点和缺点</li><li id="9175" class="ls lt iq ky b kz mb lc mc lf md lj me ln mf lr lx ly lz ma bi translated">如何用真实数据集实现随机森林？</li></ul><p id="f923" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">让我们开始吧！</p><div class="mg mh gp gr mi mj"><a href="https://www.youtube.com/c/TirendazAcademy/videos" rel="noopener  ugc nofollow" target="_blank"><div class="mk ab fo"><div class="ml ab mm cl cj mn"><h2 class="bd ir gy z fp mo fr fs mp fu fw ip bi translated">蒂伦达兹学院</h2><div class="mq l"><h3 class="bd b gy z fp mo fr fs mp fu fw dk translated">Tirendaz Academy是一个在线教育平台，在数据科学、人工智能、机器…</h3></div><div class="mr l"><p class="bd b dl z fp mo fr fs mp fu fw dk translated">www.youtube.com</p></div></div><div class="ms l"><div class="mt l mu mv mw ms mx kp mj"/></div></div></a></div><h1 id="978f" class="my mz iq bd na nb nc nd ne nf ng nh ni jw nj jx nk jz nl ka nm kc nn kd no np bi translated">什么是随机森林？</h1><p id="2efb" class="pw-post-body-paragraph kw kx iq ky b kz nq jr lb lc nr ju le lf ns lh li lj nt ll lm ln nu lp lq lr ij bi translated">随机森林是一种监督机器学习算法，广泛用于分类和回归问题。你可以把一个随机的森林想象成一群决策树。决策树模型倾向于过度拟合训练数据。你可以使用随机森林来克服过度适应的问题。</p><p id="30cf" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">要实现随机森林，您需要构建许多决策树。随机森林由一组决策树组成。随机森林中的每棵树都与其他树略有不同。这些树被选择为不同的特征子集。请注意，这些功能是随机选择的。当进行最终预测时，所有树的预测被组合，并且这些预测被平均。由于您使用了许多树，因此可以减少过度拟合的数量。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi nv"><img src="../Images/0b383d402d26dc77cb13fc52f873dbfc.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/1*EhAkkl6EpSYDak3dMEhOFQ.gif"/></div></div><figcaption class="kr ks gj gh gi kt ku bd b be z dk translated"><a class="ae kv" href="https://1.bp.blogspot.com/-Ax59WK4DE8w/YK6o9bt_9jI/AAAAAAAAEQA/9KbBf9cdL6kOFkJnU39aUn4m8ydThPenwCLcBGAsYHQ/s0/Random%2BForest%2B03.gif" rel="noopener ugc nofollow" target="_blank">随机森林投票的结果。</a></figcaption></figure><h1 id="8082" class="my mz iq bd na nb nc nd ne nf ng nh ni jw nj jx nk jz nl ka nm kc nn kd no np bi translated">随机森林的一些优点</h1><p id="25e0" class="pw-post-body-paragraph kw kx iq ky b kz nq jr lb lc nr ju le lf ns lh li lj nt ll lm ln nu lp lq lr ij bi translated">我们来看看随机森林的一些优点。</p><ul class=""><li id="2015" class="ls lt iq ky b kz la lc ld lf lu lj lv ln lw lr lx ly lz ma bi translated">您可以将随机森林用于分类和回归任务。</li><li id="b8ea" class="ls lt iq ky b kz mb lc mc lf md lj me ln mf lr lx ly lz ma bi translated">随机森林通常工作得很好，不需要对超参数进行大量调整。</li><li id="3b15" class="ls lt iq ky b kz mb lc mc lf md lj me ln mf lr lx ly lz ma bi translated">你不需要缩放数据。</li><li id="e1a7" class="ls lt iq ky b kz mb lc mc lf md lj me ln mf lr lx ly lz ma bi translated">随机森林可以提供比决策树更好的准确性，因为它克服了过拟合问题。</li></ul><h1 id="6951" class="my mz iq bd na nb nc nd ne nf ng nh ni jw nj jx nk jz nl ka nm kc nn kd no np bi translated">随机森林的一些缺点</h1><p id="e293" class="pw-post-body-paragraph kw kx iq ky b kz nq jr lb lc nr ju le lf ns lh li lj nt ll lm ln nu lp lq lr ij bi translated">随机森林有一些缺点。让我们来看看这些缺点。</p><ul class=""><li id="eb30" class="ls lt iq ky b kz la lc ld lf lu lj lv ln lw lr lx ly lz ma bi translated">随机森林不能很好地处理非常高维的稀疏数据，如文本数据。</li><li id="9a88" class="ls lt iq ky b kz mb lc mc lf md lj me ln mf lr lx ly lz ma bi translated">随机森林不容易解释，因为它使用比决策树更深的树。</li></ul><p id="fb3c" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">所以你看到了随机森林的一些优点和缺点。现在让我们来看看如何用scikit learn实现随机森林。</p><h1 id="e7c4" class="my mz iq bd na nb nc nd ne nf ng nh ni jw nj jx nk jz nl ka nm kc nn kd no np bi translated">如何用Scikit-Learn实现随机森林？</h1><p id="e195" class="pw-post-body-paragraph kw kx iq ky b kz nq jr lb lc nr ju le lf ns lh li lj nt ll lm ln nu lp lq lr ij bi translated">为了展示如何实现随机森林，我将使用威斯康星乳腺癌数据集。在加载数据集之前，让我导入熊猫。</p><pre class="kg kh ki kj gt nw nx ny nz aw oa bi"><span id="f152" class="ob mz iq nx b gy oc od l oe of">import pandas as pd</span></pre><p id="cf87" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">让我们加载数据集。</p><pre class="kg kh ki kj gt nw nx ny nz aw oa bi"><span id="d42f" class="ob mz iq nx b gy oc od l oe of">df = pd.read_csv( “breast_cancer_wisconsin.csv”)</span></pre><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi og"><img src="../Images/4f32814c1ba857c7f49e66c95c599f3a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*6GGxp4_w7pBFqO-q"/></div></div><figcaption class="kr ks gj gh gi kt ku bd b be z dk translated">照片由<a class="ae kv" href="https://unsplash.com/es/@nci?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">国家癌症研究所</a>在<a class="ae kv" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上拍摄</figcaption></figure><p id="2443" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">你可以在这里找到笔记本和数据集<a class="ae kv" href="https://www.kaggle.com/datasets/uciml/breast-cancer-wisconsin-data" rel="noopener ugc nofollow" target="_blank">。让我们看一下数据集的前五行。</a></p><pre class="kg kh ki kj gt nw nx ny nz aw oa bi"><span id="c674" class="ob mz iq nx b gy oc od l oe of">df.head()</span></pre><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi oh"><img src="../Images/00faca6c5c091532dfec6446b39c2656.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*CS-dI62Zt219z8oZ-RcQPw.png"/></div></div><figcaption class="kr ks gj gh gi kt ku bd b be z dk translated">乳腺癌数据集的前五行</figcaption></figure><p id="bfd1" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">该数据集由恶性和良性肿瘤细胞的样本组成。数据集中的第一列显示唯一的ID号，第二列显示诊断，假设M表示恶性，B表示良性。其余栏目是我们的特色。让我们来看看数据集的形状。</p><pre class="kg kh ki kj gt nw nx ny nz aw oa bi"><span id="9837" class="ob mz iq nx b gy oc od l oe of">df.shape</span><span id="7d4c" class="ob mz iq nx b gy oi od l oe of">#Output:<br/>(569, 33)</span></pre><h1 id="4c72" class="my mz iq bd na nb nc nd ne nf ng nh ni jw nj jx nk jz nl ka nm kc nn kd no np bi translated">数据预处理</h1><p id="7bcf" class="pw-post-body-paragraph kw kx iq ky b kz nq jr lb lc nr ju le lf ns lh li lj nt ll lm ln nu lp lq lr ij bi translated">数据预处理是数据分析最重要的阶段之一。现在，让我们创建输入和输出变量。为此，我将使用<code class="fe oj ok ol nx b">loc</code>方法。首先，让我创建我们的目标变量。</p><pre class="kg kh ki kj gt nw nx ny nz aw oa bi"><span id="4959" class="ob mz iq nx b gy oc od l oe of">y = df.loc[:,"diagnosis"].values</span></pre><p id="e8e7" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">让我们创建我们的特征变量并删除不必要的列。为此，我将使用<code class="fe oj ok ol nx b">drop</code>方法。</p><pre class="kg kh ki kj gt nw nx ny nz aw oa bi"><span id="887e" class="ob mz iq nx b gy oc od l oe of">X = df.drop(["diagnosis","id","Unnamed: 32"],axis=1).values</span></pre><p id="9b51" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">注意，我们的目标变量有两个类别，M和b。让我们用标签编码器对目标变量进行编码。首先，我要导入这个类。</p><pre class="kg kh ki kj gt nw nx ny nz aw oa bi"><span id="e2d1" class="ob mz iq nx b gy oc od l oe of">from sklearn.preprocessing import LabelEncoder</span></pre><p id="b9c8" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">现在，我要从这个类创建一个对象。</p><pre class="kg kh ki kj gt nw nx ny nz aw oa bi"><span id="3c88" class="ob mz iq nx b gy oc od l oe of">le = LabelEncoder()</span></pre><p id="5303" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">让我们拟合并转换我们的目标变量。</p><pre class="kg kh ki kj gt nw nx ny nz aw oa bi"><span id="c37d" class="ob mz iq nx b gy oc od l oe of">y = le.fit_transform(y)</span></pre><p id="9ed2" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">在构建模型之前，让我们将数据集分为训练集和测试集。为此，我将使用<code class="fe oj ok ol nx b">train_test_split</code>功能。首先，让我导入这个函数。</p><pre class="kg kh ki kj gt nw nx ny nz aw oa bi"><span id="7c42" class="ob mz iq nx b gy oc od l oe of">from sklearn.model_selection import train_test_split</span></pre><p id="2916" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">让我们使用这个函数分割数据集。</p><pre class="kg kh ki kj gt nw nx ny nz aw oa bi"><span id="e977" class="ob mz iq nx b gy oc od l oe of">X_train,X_test,y_train,y_test=train_test_split(X, y, <br/>                                               stratify=y, <br/>                                               random_state=0)</span></pre><p id="5d1e" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">酷毙了。我们的数据集已经可以分析了。</p><h1 id="eda5" class="my mz iq bd na nb nc nd ne nf ng nh ni jw nj jx nk jz nl ka nm kc nn kd no np bi translated">构建随机森林模型</h1><p id="c177" class="pw-post-body-paragraph kw kx iq ky b kz nq jr lb lc nr ju le lf ns lh li lj nt ll lm ln nu lp lq lr ij bi translated">为了在Scikit-Learn中使用随机森林，我们需要从ensemble模块中导入<code class="fe oj ok ol nx b">RandomForestClassifier</code>类。首先，让我们导入这个类。</p><pre class="kg kh ki kj gt nw nx ny nz aw oa bi"><span id="7345" class="ob mz iq nx b gy oc od l oe of">from sklearn.ensemble import RandomForestClassifier</span></pre><p id="1a11" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">现在，我要从这个类创建一个对象。在这里，我将只使用默认值</p><pre class="kg kh ki kj gt nw nx ny nz aw oa bi"><span id="f42f" class="ob mz iq nx b gy oc od l oe of">rf = RandomForestClassifier(random_state = 0)</span></pre><p id="79a3" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">接下来，让我们建立我们的模型。为此，我将对训练集使用<code class="fe oj ok ol nx b">fit</code>方法。</p><pre class="kg kh ki kj gt nw nx ny nz aw oa bi"><span id="724f" class="ob mz iq nx b gy oc od l oe of">rf.fit(X_train, y_train)</span></pre><p id="ded6" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">太棒了。我们的模型可以预测。让我们使用训练和测试集来评估我们的模型。</p><pre class="kg kh ki kj gt nw nx ny nz aw oa bi"><span id="d9f7" class="ob mz iq nx b gy oc od l oe of">y_train_pred = rf.predict(X_train)<br/>y_test_pred = rf.predict(X_test)</span></pre><p id="4503" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">现在，让我们看看我们的模型在数据集上的性能。为此，我将使用<code class="fe oj ok ol nx b">accuracy_score</code>功能。首先，让我导入这个函数。</p><pre class="kg kh ki kj gt nw nx ny nz aw oa bi"><span id="c5f1" class="ob mz iq nx b gy oc od l oe of">from sklearn.metrics import accuracy_score</span></pre><p id="ed37" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">之后，让我们看看训练集和测试集的准确性分数。</p><pre class="kg kh ki kj gt nw nx ny nz aw oa bi"><span id="e82e" class="ob mz iq nx b gy oc od l oe of">rf_train = accuracy_score(y_train, y_train_pred)<br/>rf_test = accuracy_score(y_test, y_test_pred)</span></pre><p id="86a6" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">现在，让我们打印这些分数。</p><pre class="kg kh ki kj gt nw nx ny nz aw oa bi"><span id="8704" class="ob mz iq nx b gy oc od l oe of">print(f’Random forest train/test accuracies: {rf_train: .3f}/{rf_test:.3f}’)</span><span id="60de" class="ob mz iq nx b gy oi od l oe of">#Output:<br/>Random forest train/test accuracies:1.000/0.958</span></pre><p id="11cb" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">太棒了，分数打印出来了。如您所见，训练集上的分数是100%，测试集上的分数是95%。这意味着模型存在过拟合问题。注意，这个随机森林模型很好地学习了训练集。所以，它只是记住了结果。但是，模型不能一概而论。为了克服过拟合问题，我们控制模型的复杂性。</p><h1 id="1539" class="my mz iq bd na nb nc nd ne nf ng nh ni jw nj jx nk jz nl ka nm kc nn kd no np bi translated">网格搜索超参数调谐</h1><p id="0f68" class="pw-post-body-paragraph kw kx iq ky b kz nq jr lb lc nr ju le lf ns lh li lj nt ll lm ln nu lp lq lr ij bi translated">由于模型的复杂性，我们需要使用不同的参数来调整模型。为此，我将使用网格搜索技术。网格搜索是一种模型超参数优化技术。在scikit-learn中，<code class="fe oj ok ol nx b">GridSearchCV</code>类提供了这种技术。让我们导入这个类。</p><pre class="kg kh ki kj gt nw nx ny nz aw oa bi"><span id="1141" class="ob mz iq nx b gy oc od l oe of">from sklearn.model_selection import GridSearchCV</span></pre><p id="511e" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">现在，我将从<code class="fe oj ok ol nx b">RandomForestClassifier</code>类中创建一个用于网格搜索的对象。</p><pre class="kg kh ki kj gt nw nx ny nz aw oa bi"><span id="cf0c" class="ob mz iq nx b gy oc od l oe of">rf = RandomForestClassifier(random_state = 42)</span></pre><p id="c2af" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">当构造<code class="fe oj ok ol nx b">GridSearchCV</code>类时，您需要提供一个超参数字典来评估<code class="fe oj ok ol nx b">param_grid</code>参数。这是一个模型参数名称和一组要尝试的值的映射。现在，让我创建一个包含参数值的参数变量。</p><pre class="kg kh ki kj gt nw nx ny nz aw oa bi"><span id="8797" class="ob mz iq nx b gy oc od l oe of">parameters = {'max_depth':[5,10,20],                           (1)<br/>              'n_estimators':[i for i in range(10, 100, 10)],  (2)<br/>              'min_samples_leaf:[i for i in range(1, 10)],     (3)<br/>              'criterion' :['gini', 'entropy'],                (4)<br/>              'max_features': ['auto', 'sqrt', 'log2']}        (5)</span></pre><p id="bb75" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">(1)树的最大深度。如果没有，那么节点被扩展，直到所有叶子都是纯的，或者直到所有叶子包含少于<code class="fe oj ok ol nx b">min_samples_split</code>的样本。</p><p id="5f3e" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">(2)要建立随机森林模型，需要决定树的数量。这里，我将为<code class="fe oj ok ol nx b">n_estimators</code>参数创建值。此参数指定林中的树的数量。在这个参数中，我使用了一个for循环来确定森林中的树的数量。</p><p id="1cb6" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">(3)<code class="fe oj ok ol nx b">min_leaf_size</code>参数用于指定叶节点中样本的最小数量。我还为这个参数再次使用了循环的<em class="om"> a。</em></p><p id="dd0f" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">(4)我使用两个参数作为标准参数。</p><p id="5fed" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">(5)最后，我设置如何选择特征。注意，随机森林技术中的一个关键参数是<code class="fe oj ok ol nx b">max_features</code>。我们在寻找最佳分割时使用该参数。</p><p id="1be2" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">因此，我们指定了参数的值。为了找到最佳参数，我将从<code class="fe oj ok ol nx b">GridSearchCV</code>类创建一个对象。</p><pre class="kg kh ki kj gt nw nx ny nz aw oa bi"><span id="8519" class="ob mz iq nx b gy oc od l oe of">clf = GridSearchCV(rf, parameters, n_jobs= -1)</span></pre><p id="4030" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">接下来，我要用训练集来拟合我们的模型。</p><pre class="kg kh ki kj gt nw nx ny nz aw oa bi"><span id="f81f" class="ob mz iq nx b gy oc od l oe of">clf.fit(X_train, y_train)</span></pre><p id="9ab2" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">最后，为了查看最佳参数，我将使用<code class="fe oj ok ol nx b">best_params_</code>属性。</p><pre class="kg kh ki kj gt nw nx ny nz aw oa bi"><span id="a52f" class="ob mz iq nx b gy oc od l oe of">print(clf.best_params_)</span><span id="728a" class="ob mz iq nx b gy oi od l oe of">#Output: <br/>{'criterion': 'entropy', 'max_depth': 5, 'max_features': 'log2', 'min_samples_leaf': 3, 'n_estimators': 10}</span></pre><p id="90b9" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">当我们执行这个单元时，你可以看到最好的参数。</p><h1 id="2d04" class="my mz iq bd na nb nc nd ne nf ng nh ni jw nj jx nk jz nl ka nm kc nn kd no np bi translated">评估随机森林模型</h1><p id="0059" class="pw-post-body-paragraph kw kx iq ky b kz nq jr lb lc nr ju le lf ns lh li lj nt ll lm ln nu lp lq lr ij bi translated">现在，我将预测训练集和测试集的值。注意，我们不需要再次训练我们的模型。因为找到最佳参数后，就用这些参数来训练模型。所以可以直接用clf模型进行预测。让我们用这个模型来预测值。</p><pre class="kg kh ki kj gt nw nx ny nz aw oa bi"><span id="4f82" class="ob mz iq nx b gy oc od l oe of">y_train_pred=clf.predict(X_train)<br/>y_test_pred=clf.predict(X_test)<br/>rf_train = accuracy_score(y_train, y_train_pred)<br/>rf_test = accuracy_score(y_test, y_test_pred)<br/>print(f’Random forest train/test accuracies: {rf_train: .3f}/{rf_test:.3f}’)</span><span id="9b45" class="ob mz iq nx b gy oi od l oe of">#Output:<br/>Random forest train/test accuracies:0.993/0.965</span></pre><p id="325b" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">根据最佳参数打印准确度分数。该模型在训练集和测试集上的性能都较好。请注意，我们的模型在训练集上的得分接近测试集上的得分。此外，两者的准确度分数都接近1。因此，我们找到了最佳参数，并预测了训练集和测试集的值。</p><h1 id="ad44" class="my mz iq bd na nb nc nd ne nf ng nh ni jw nj jx nk jz nl ka nm kc nn kd no np bi translated">结论</h1><p id="3378" class="pw-post-body-paragraph kw kx iq ky b kz nq jr lb lc nr ju le lf ns lh li lj nt ll lm ln nu lp lq lr ij bi translated">在这篇文章中，我谈到了随机森林以及如何用scikit learn实现这项技术。随机森林由多个决策树组成。此方法对所有树的结果进行平均，以输出模型。所以你可以用这种方法克服过度拟合的问题。您可以使用此方法执行分类和回归任务。就是这样。感谢阅读。我希望你喜欢它。</p><p id="646c" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">请不要忘记在YouTube上关注我们。</p><div class="mg mh gp gr mi mj"><a href="https://medium.com/geekculture/top-8-machine-learning-algorithms-df30277b2056" rel="noopener follow" target="_blank"><div class="mk ab fo"><div class="ml ab mm cl cj mn"><h2 class="bd ir gy z fp mo fr fs mp fu fw ip bi translated">8种最佳机器学习算法</h2><div class="mq l"><h3 class="bd b gy z fp mo fr fs mp fu fw dk translated">数据科学家和机器学习工程师应该知道的最好的机器学习算法。</h3></div><div class="mr l"><p class="bd b dl z fp mo fr fs mp fu fw dk translated">medium.com</p></div></div><div class="ms l"><div class="on l mu mv mw ms mx kp mj"/></div></div></a></div><div class="mg mh gp gr mi mj"><a href="https://levelup.gitconnected.com/7-differences-between-deep-learning-and-machine-learning-b5f2ff0ae00a" rel="noopener  ugc nofollow" target="_blank"><div class="mk ab fo"><div class="ml ab mm cl cj mn"><h2 class="bd ir gy z fp mo fr fs mp fu fw ip bi translated">深度学习和机器学习的7个区别</h2><div class="mq l"><h3 class="bd b gy z fp mo fr fs mp fu fw dk translated">深度学习与机器学习——有什么区别？</h3></div><div class="mr l"><p class="bd b dl z fp mo fr fs mp fu fw dk translated">levelup.gitconnected.com</p></div></div><div class="ms l"><div class="oo l mu mv mw ms mx kp mj"/></div></div></a></div><p id="1354" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">如果这篇文章有帮助，请点击拍手👏按钮几下，以示支持👇</p></div></div>    
</body>
</html>