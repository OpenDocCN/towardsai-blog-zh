<html>
<head>
<title>Deep Dive Into Confusion Matrix</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">深入混乱矩阵</h1>
<blockquote>原文：<a href="https://pub.towardsai.net/deep-dive-into-confusion-matrix-6b8111d5c3f7?source=collection_archive---------3-----------------------#2022-09-26">https://pub.towardsai.net/deep-dive-into-confusion-matrix-6b8111d5c3f7?source=collection_archive---------3-----------------------#2022-09-26</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><h2 id="0322" class="io ip iq bd b dl ir is it iu iv iw dk ix translated" aria-label="kicker paragraph">模型评估</h2><div class=""/><div class=""><h2 id="4aef" class="pw-subtitle-paragraph jw iz iq bd b jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn dk translated">精确度(TPR)，召回率(PPV)，TNR，FPR，FNR，净现值，F1得分，准确度，平衡准确度，LR+，LR-</h2></div><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div role="button" tabindex="0" class="ku kv di kw bf kx"><div class="gh gi ko"><img src="../Images/1aa83ada499b035839c2931eb028fad3.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*9I7ltQWSvREKlG7_0npX-A.png"/></div></div><figcaption class="la lb gj gh gi lc ld bd b be z dk translated">作者图片</figcaption></figure><p id="367d" class="pw-post-body-paragraph le lf iq lg b lh li ka lj lk ll kd lm ln lo lp lq lr ls lt lu lv lw lx ly lz ij bi translated">在数据科学领域，模型评估是培训生命周期的关键组成部分。有许多度量来评估分类模型，但是经常使用准确性度量。然而，由于类别不平衡，准确性可能无法给出模型的正确描述，在这种情况下，将使用混淆矩阵进行评估。</p><p id="aaea" class="pw-post-body-paragraph le lf iq lg b lh li ka lj lk ll kd lm ln lo lp lq lr ls lt lu lv lw lx ly lz ij bi translated">混淆矩阵非常重要，因为许多指标都是从它衍生出来的，无论是精确度、召回率、F1分数还是准确度。</p><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div role="button" tabindex="0" class="ku kv di kw bf kx"><div class="gh gi ko"><img src="../Images/946d5f919452bff84021983e5ff7914c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*g9Y7xQgzIMmeFJlPwOW3OA.png"/></div></div><figcaption class="la lb gj gh gi lc ld bd b be z dk translated">困惑矩阵|作者图片</figcaption></figure><p id="b940" class="pw-post-body-paragraph le lf iq lg b lh li ka lj lk ll kd lm ln lo lp lq lr ls lt lu lv lw lx ly lz ij bi translated">让我们理解从混淆矩阵中得出的指标</p><p id="1a32" class="pw-post-body-paragraph le lf iq lg b lh li ka lj lk ll kd lm ln lo lp lq lr ls lt lu lv lw lx ly lz ij bi translated"><strong class="lg ja">真阳性(TP) </strong>是实际类为阳性时的正确预测数。</p><p id="a8db" class="pw-post-body-paragraph le lf iq lg b lh li ka lj lk ll kd lm ln lo lp lq lr ls lt lu lv lw lx ly lz ij bi translated"><strong class="lg ja">真阴性(TN) </strong>是实际类别为阴性时的正确预测数。</p><p id="61de" class="pw-post-body-paragraph le lf iq lg b lh li ka lj lk ll kd lm ln lo lp lq lr ls lt lu lv lw lx ly lz ij bi translated"><strong class="lg ja">假阳性(FP) </strong>是实际类为阳性时的错误预测数，也称为<strong class="lg ja">I类错误</strong>。</p><p id="53ed" class="pw-post-body-paragraph le lf iq lg b lh li ka lj lk ll kd lm ln lo lp lq lr ls lt lu lv lw lx ly lz ij bi translated"><strong class="lg ja">假阴性(FN) </strong>是实际类别为阴性时的错误预测数，也称为<strong class="lg ja">类型II错误</strong>。</p><pre class="kp kq kr ks gt ma mb mc md aw me bi"><span id="644a" class="mf mg iq mb b gy mh mi l mj mk">from sklearn.datasets import load_breast_cancer<br/>from sklearn.model_selection import train_test_split <br/>from sklearn.linear_model import LogisticRegression<br/>from . import confusion_matrix</span><span id="91af" class="mf mg iq mb b gy ml mi l mj mk">X, y = load_breast_cancer(return_X_y=True)<br/>X_train, X_test, y_train, y_test = train_test_split(X, y,<br/>                                                    test_size=0.33,<br/>                                                    random_state=42)<br/>lr= LogisticRegression()<br/>lr.fit(X_train,y_train) <br/>y_pred=lr.predict(X_test)</span><span id="f690" class="mf mg iq mb b gy ml mi l mj mk">conf_mat = confusion_matrix(y_test, y_pred, plot=False)<br/>TP = conf_mat[0,0]<br/>TN = conf_mat[1,1]<br/>FP = conf_mat[1,0]<br/>FN = conf_mat[0,1]</span><span id="ebac" class="mf mg iq mb b gy ml mi l mj mk">print("TP: ", TP)<br/>print("TN: ", TN)<br/>print("FP: ", FP)<br/>print("FN: ", FN)</span><span id="8d9e" class="mf mg iq mb b gy ml mi l mj mk"><strong class="mb ja">Output:<br/></strong>TP:  63<br/>TN:  118<br/>FP:  3<br/>FN:  4</span></pre><p id="d73d" class="pw-post-body-paragraph le lf iq lg b lh li ka lj lk ll kd lm ln lo lp lq lr ls lt lu lv lw lx ly lz ij bi translated"><strong class="lg ja">真阳性率(TPR)、灵敏度、回忆:</strong>是一个人检测呈阳性而患有某种疾病的概率。换句话说，召回率是模型预测的属于特定类别的实例的比例。</p><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div class="gh gi mm"><img src="../Images/d2c595e38a4b98daf2e5dea574549ce1.png" data-original-src="https://miro.medium.com/v2/resize:fit:466/format:webp/1*Ihsfoltdur1PW6Vg76EfnA.jpeg"/></div></figure><pre class="kp kq kr ks gt ma mb mc md aw me bi"><span id="4c52" class="mf mg iq mb b gy mh mi l mj mk">from sklearn.metrics import recall_score<br/>recall_score(y_test, y_pred)</span><span id="3412" class="mf mg iq mb b gy ml mi l mj mk"><strong class="mb ja">Output:<br/></strong>0.9752066115702479</span></pre><p id="047e" class="pw-post-body-paragraph le lf iq lg b lh li ka lj lk ll kd lm ln lo lp lq lr ls lt lu lv lw lx ly lz ij bi translated"><strong class="lg ja">真阳性率(TPR)，特异性:</strong>是一个人检测阴性但没有患病的概率。</p><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div class="gh gi mn"><img src="../Images/74f18c864d1cfd946790f164fe5bd929.png" data-original-src="https://miro.medium.com/v2/resize:fit:468/format:webp/1*7tCv-vg08NMc1o2OP_uokA.jpeg"/></div></figure><p id="b59a" class="pw-post-body-paragraph le lf iq lg b lh li ka lj lk ll kd lm ln lo lp lq lr ls lt lu lv lw lx ly lz ij bi translated"><strong class="lg ja">假阳性率(FPR)，脱落:</strong>它是一个人检测呈阳性而没有患病的概率。</p><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div class="gh gi mo"><img src="../Images/790570076df7028388be9c4a15b15ec4.png" data-original-src="https://miro.medium.com/v2/resize:fit:470/format:webp/1*J_0WU4xiNgdOcD7d0hJX9Q.jpeg"/></div></figure><p id="dad7" class="pw-post-body-paragraph le lf iq lg b lh li ka lj lk ll kd lm ln lo lp lq lr ls lt lu lv lw lx ly lz ij bi translated"><strong class="lg ja">假阴性率(FNR)，漏检率:</strong>是检测阴性的人确实患有疾病的概率。</p><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div class="gh gi mp"><img src="../Images/4d42056ff01fb5f8b85c1e10d7e2cd85.png" data-original-src="https://miro.medium.com/v2/resize:fit:480/format:webp/1*1psxjpR51z1WvvWihwcKnw.jpeg"/></div></figure><pre class="kp kq kr ks gt ma mb mc md aw me bi"><span id="1596" class="mf mg iq mb b gy mh mi l mj mk">TNR = TN/(TN+FP)<br/>print("Specificity: ", TNR) <br/>FPR = FP/(TN+FP)<br/>print("FPR: ", FPR)<br/>FNR = FN/(TP+FN)<br/>print("FNR: ", FNR)</span><span id="dc6e" class="mf mg iq mb b gy ml mi l mj mk"><strong class="mb ja">Output:<br/></strong>Specificity:  0.9752066115702479<br/>FPR:  0.024793388429752067<br/>FNR:  0.05970149253731343</span></pre><p id="30d1" class="pw-post-body-paragraph le lf iq lg b lh li ka lj lk ll kd lm ln lo lp lq lr ls lt lu lv lw lx ly lz ij bi translated"><strong class="lg ja">阳性预测值(PPV)，精度:</strong>是一个人患病检测呈阳性的概率。换句话说，精度就是所有预测中正确预测的比例。</p><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div class="gh gi mq"><img src="../Images/afe98b4d0fa6096d1ba9cf3b8c330843.png" data-original-src="https://miro.medium.com/v2/resize:fit:464/format:webp/1*KKPyJ4SobJZmEP_aB1-Dog.jpeg"/></div></figure><pre class="kp kq kr ks gt ma mb mc md aw me bi"><span id="5d69" class="mf mg iq mb b gy mh mi l mj mk">from sklearn.metrics import precision_score<br/>precision_score(y_test, y_pred)</span><span id="9eed" class="mf mg iq mb b gy ml mi l mj mk"><strong class="mb ja">Output:<br/></strong>0.9672131147540983</span></pre><p id="41f9" class="pw-post-body-paragraph le lf iq lg b lh li ka lj lk ll kd lm ln lo lp lq lr ls lt lu lv lw lx ly lz ij bi translated"><strong class="lg ja">阴性预测值(NPV): </strong>是一个人没有患病但检测为阴性的概率。</p><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div class="gh gi mr"><img src="../Images/62fcd992579f3ab4e13de13f3e169749.png" data-original-src="https://miro.medium.com/v2/resize:fit:484/format:webp/1*sZEz0MvBGtfGKzc-2jILQw.jpeg"/></div></figure><p id="1b51" class="pw-post-body-paragraph le lf iq lg b lh li ka lj lk ll kd lm ln lo lp lq lr ls lt lu lv lw lx ly lz ij bi translated"><strong class="lg ja">阳性似然比(LR+): </strong></p><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div class="gh gi ms"><img src="../Images/47ec342337f8b72c0a3548a375e6d909.png" data-original-src="https://miro.medium.com/v2/resize:fit:266/format:webp/1*34Pc7Dil0VmNz-VkRltIrg.jpeg"/></div></figure><p id="3a75" class="pw-post-body-paragraph le lf iq lg b lh li ka lj lk ll kd lm ln lo lp lq lr ls lt lu lv lw lx ly lz ij bi translated"><strong class="lg ja">负似然比(LR-): </strong></p><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div class="gh gi mt"><img src="../Images/a788b0b6f3ea9c37dd4d73b67e993e89.png" data-original-src="https://miro.medium.com/v2/resize:fit:262/format:webp/1*_zAiE5T6xyjaYxr_G0NH-g.jpeg"/></div></figure><pre class="kp kq kr ks gt ma mb mc md aw me bi"><span id="5928" class="mf mg iq mb b gy mh mi l mj mk">TNR = TP/(TP+FN)<br/>NPV = TN/(TN+FN)<br/>print("NPV: ", NPV) <br/>LRp = TPR/FPR<br/>print("LR+: ", LRp)<br/>LRn = FNR/TNR<br/>print("LR-: ", LRn)</span><span id="802e" class="mf mg iq mb b gy ml mi l mj mk"><strong class="mb ja">Output:<br/></strong>NPV:  0.9672131147540983<br/>LR+:  37.92537313432836<br/>LR-:  0.06349206349206349</span></pre><p id="090a" class="pw-post-body-paragraph le lf iq lg b lh li ka lj lk ll kd lm ln lo lp lq lr ls lt lu lv lw lx ly lz ij bi translated"><strong class="lg ja">准确率:</strong>准确率是样本被正确分类的比例。更准确地说，是正确预测数占总病例数的比率。</p><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div class="gh gi mu"><img src="../Images/05e798e459541e1fce5b38e53d0c8ebb.png" data-original-src="https://miro.medium.com/v2/resize:fit:874/format:webp/1*Emu62NIZqq45SPaqasyWEg.jpeg"/></div></figure><pre class="kp kq kr ks gt ma mb mc md aw me bi"><span id="112f" class="mf mg iq mb b gy mh mi l mj mk">from sklearn.metrics import accuracy_score<br/>accuracy_score(y_test, y_pred)</span><span id="b021" class="mf mg iq mb b gy ml mi l mj mk"><strong class="mb ja">Output:<br/></strong>0.9627659574468085</span></pre><p id="5529" class="pw-post-body-paragraph le lf iq lg b lh li ka lj lk ll kd lm ln lo lp lq lr ls lt lu lv lw lx ly lz ij bi translated"><strong class="lg ja">均衡精度:</strong>是TPR和TNR的算术平均值。在数据不平衡的情况下，平衡精度会发挥作用。</p><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div role="button" tabindex="0" class="ku kv di kw bf kx"><div class="gh gi mv"><img src="../Images/a6dc7f8d9d6daa45db1ec840f8f2db3f.png" data-original-src="https://miro.medium.com/v2/resize:fit:666/format:webp/1*vWsoSBA1fhF7ic_12vq-CA.jpeg"/></div></div></figure><pre class="kp kq kr ks gt ma mb mc md aw me bi"><span id="88ad" class="mf mg iq mb b gy mh mi l mj mk">from sklearn.metrics import balanced_accuracy_score<br/>balanced_accuracy_score(y_test, y_pred)</span><span id="7bde" class="mf mg iq mb b gy ml mi l mj mk"><strong class="mb ja">Output:<br/></strong>0.9577525595164673</span></pre><p id="f039" class="pw-post-body-paragraph le lf iq lg b lh li ka lj lk ll kd lm ln lo lp lq lr ls lt lu lv lw lx ly lz ij bi translated"><strong class="lg ja"> F1得分:</strong>它是精确度和召回率的调和平均值，因此它是对分类器预测质量的总体度量。对于大多数人来说，它通常是首选的度量标准，因为它同时兼顾了精确度和召回率。它会在数据不平衡时找到自己的路。</p><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div class="gh gi mw"><img src="../Images/4826446645bff2d2d13b084034c36bb9.png" data-original-src="https://miro.medium.com/v2/resize:fit:536/format:webp/1*QKSugyjTaFa3PDKQ8IAWZg.jpeg"/></div></figure><pre class="kp kq kr ks gt ma mb mc md aw me bi"><span id="ffb3" class="mf mg iq mb b gy mh mi l mj mk">from sklearn.metrics import f1_score<br/>f1_score(y_test, y_pred)</span><span id="777e" class="mf mg iq mb b gy ml mi l mj mk"><strong class="mb ja">Output:<br/></strong>0.9711934156378601</span></pre><h2 id="e60f" class="mf mg iq bd mx my mz dn na nb nc dp nd ln ne nf ng lr nh ni nj lv nk nl nm iw bi translated">F1和平衡精度有什么区别？</h2><p id="b195" class="pw-post-body-paragraph le lf iq lg b lh nn ka lj lk no kd lm ln np lp lq lr nq lt lu lv nr lx ly lz ij bi translated">F1不考虑用于评估模型的真阴性，而平衡准确度考虑所有四个TP、TN、FP和FN。</p><p id="989a" class="pw-post-body-paragraph le lf iq lg b lh li ka lj lk ll kd lm ln lo lp lq lr ls lt lu lv lw lx ly lz ij bi translated">F1是考虑精确度和召回率的复合指标。还有其他复合指标，如精确度-召回率曲线、ROC和AUC，它们对评估任何分类模型都很重要。要了解更多关于这些曲线的信息，请访问<a class="ae ns" rel="noopener ugc nofollow" target="_blank" href="/precision-recall-curve-26f9e7984add"> <strong class="lg ja">精确回忆和ROC曲线</strong> </a>。</p><p id="019c" class="pw-post-body-paragraph le lf iq lg b lh li ka lj lk ll kd lm ln lo lp lq lr ls lt lu lv lw lx ly lz ij bi translated"><em class="nt">下面的代码类似于sklearn的分类报告，它将给出二进制分类的混淆矩阵中的所有指标。</em></p><figure class="kp kq kr ks gt kt"><div class="bz fp l di"><div class="nu nv l"/></div></figure><pre class="kp kq kr ks gt ma mb mc md aw me bi"><span id="facf" class="mf mg iq mb b gy mh mi l mj mk">report = binary_classification_report(y_test, y_pred)<br/>report</span><span id="db00" class="mf mg iq mb b gy ml mi l mj mk"><strong class="mb ja">Output:<br/></strong>{'TP': 118,<br/> 'TN': 63,<br/> 'FP': 4,<br/> 'FN': 3,<br/> 'TPR': 0.9752066115702479,<br/> 'Recall': 0.9752066115702479,<br/> 'Sensitivity': 0.9752066115702479,<br/> 'TNR': 0.9402985074626866,<br/> 'Specificity': 0.9402985074626866,<br/> 'FPR': 0.05970149253731343,<br/> 'FNR': 0.024793388429752067,<br/> 'PPV': 0.9672131147540983,<br/> 'Precision': 0.9672131147540983,<br/> 'Accuracy': 0.9627659574468085,<br/> 'Balaced Accuracy': 0.9577525595164673,<br/> 'F1 Score': 0.9711934156378601}</span></pre><p id="3d2e" class="pw-post-body-paragraph le lf iq lg b lh li ka lj lk ll kd lm ln lo lp lq lr ls lt lu lv lw lx ly lz ij bi translated"><strong class="lg ja"> <em class="nt">注:</em> </strong> <em class="nt">博客中提到的以上代码均为二进制分类，</em></p><p id="dc73" class="pw-post-body-paragraph le lf iq lg b lh li ka lj lk ll kd lm ln lo lp lq lr ls lt lu lv lw lx ly lz ij bi translated"><em class="nt">在这篇博客中，我们了解了二元分类的混淆矩阵。但是，如果您对多类感兴趣，请参考</em> <a class="ae ns" rel="noopener ugc nofollow" target="_blank" href="/multi-class-model-evaluation-with-confusion-matrix-and-classification-report-c92a74d5e908"> <strong class="lg ja"> <em class="nt">多类模型评估与混淆矩阵和分类报告</em></strong></a><strong class="lg ja"><em class="nt"/></strong><em class="nt">如果您对“从。导入混淆_矩阵”请参考</em> <a class="ae ns" rel="noopener ugc nofollow" target="_blank" href="/introduction-to-confusion-matrix-50676f2756ee"> <strong class="lg ja"> <em class="nt">混淆矩阵介绍</em> </strong> </a> <em class="nt">获取Python方法。</em></p><p id="4b92" class="pw-post-body-paragraph le lf iq lg b lh li ka lj lk ll kd lm ln lo lp lq lr ls lt lu lv lw lx ly lz ij bi translated"><strong class="lg ja">参考文献:</strong></p><p id="f643" class="pw-post-body-paragraph le lf iq lg b lh li ka lj lk ll kd lm ln lo lp lq lr ls lt lu lv lw lx ly lz ij bi translated">[1] sklearn度量API。<a class="ae ns" href="https://scikit-learn.org/stable/modules/classes.html#module-sklearn.metrics" rel="noopener ugc nofollow" target="_blank">https://sci kit-learn . org/stable/modules/classes . html # module-sk learn . metrics</a></p></div></div>    
</body>
</html>