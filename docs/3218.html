<html>
<head>
<title>Google’s Audiolm: Generating Music by Hearing a Song’s Snippet</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">谷歌的Audiolm:通过听一首歌的片段来产生音乐</h1>
<blockquote>原文：<a href="https://pub.towardsai.net/googles-audiolm-generating-music-by-hearing-a-song-s-snippet-c9512a9290cd?source=collection_archive---------2-----------------------#2022-10-15">https://pub.towardsai.net/googles-audiolm-generating-music-by-hearing-a-song-s-snippet-c9512a9290cd?source=collection_archive---------2-----------------------#2022-10-15</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><div class=""><h2 id="7b74" class="pw-subtitle-paragraph jn ip iq bd b jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke dk translated">无论是音乐还是语音，谷歌的新模式都可以继续播放所听到的内容。</h2></div><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi kf"><img src="../Images/c71188a5951f2279f41b492042742408.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*J_52VlbdIAU5rvg6"/></div></div><figcaption class="kr ks gj gh gi kt ku bd b be z dk translated">马里乌斯·马萨拉尔在unsplash.com拍摄的照片</figcaption></figure><p id="2277" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">AudioLM是谷歌的新型号，能够生成与提示相同风格的音乐。该模型还能够产生复杂的声音，如钢琴音乐或人们的谈话。结果令人震惊。事实上，它似乎和原作没有什么区别。</p><p id="9309" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated"><strong class="ky ir">为什么创作音乐很难？</strong></p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi kf"><img src="../Images/ebd46f65e13019035a122a2a80a7fbb7.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*4kQoiwTCqRHpWobj"/></div></div><figcaption class="kr ks gj gh gi kt ku bd b be z dk translated">在unsplash.com由<a class="ae kv" href="https://unsplash.com/@dolodol" rel="noopener ugc nofollow" target="_blank"> Dolo Iglesias </a>拍摄的图片</figcaption></figure><p id="f3a9" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">创作音乐不是一件容易的事情。事实上，生成音频信号(音乐、环境声音、人们的讲话)需要多个抽象尺度。例如，音乐有一个需要长时间分析的结构，也是由无数相互作用的信号组成的。甚至个人语音本身也可以在不同的层面进行分析，可以是简单的声音信号或语音，也可以是韵律、句法、语法或语义。</p><p id="23bb" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">之前已经进行了几次尝试。第一次尝试生成音乐的重点是生成MIDI文件(他们为钢琴生成MIDI音乐的有趣项目是在2018年使用转换器创建的<a class="ae kv" href="https://magenta.tensorflow.org/music-transformer" rel="noopener ugc nofollow" target="_blank">)。此外，一些研究侧重于诸如</a><a class="ae kv" href="https://ai.googleblog.com/2017/12/tacotron-2-generating-human-like-speech.html" rel="noopener ugc nofollow" target="_blank">文本到语音</a>的任务，其中语音是从抄本生成的。问题是，所有不在抄本中的内容都没有翻译成音频文件。几项研究解释了在人类交流中，停顿和变调以及其他信号是多么的重要。</p><p id="2b0d" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">例如，那些使用Alexa或其他扬声器的人已经注意到声音听起来不自然。尤其是早期，无论发音多么正确，听起来都不自然，给人一种诡异的效果。</p><p id="22b7" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated"><strong class="ky ir"> AudioLM，谷歌新机型</strong></p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi kf"><img src="../Images/046f90a6a8bba2d1dea2adcd0c5fcc97.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*ZCgZMc1vt-jBebVR"/></div></div><figcaption class="kr ks gj gh gi kt ku bd b be z dk translated">图片由普里西拉·杜·普里兹在unsplash.com拍摄</figcaption></figure><p id="baba" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">日前，谷歌宣布发布新模型:“<a class="ae kv" href="https://arxiv.org/abs/2209.03143" rel="noopener ugc nofollow" target="_blank"> AudioLM:音频生成的语言建模方法</a>”。新模型能够仅通过听音频来生成音频(例如真实的音乐和语音)。</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="ls lt l"/></div></figure><p id="9b73" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">正如他们在博客中所写的，近年来，自然语言处理领域有了很大的进步。事实上，语言模型已经被证明在许多任务中非常有效。这些系统中的许多都是基于使用<a class="ae kv" href="https://en.wikipedia.org/wiki/Transformer_(machine_learning_model)" rel="noopener ugc nofollow" target="_blank">转换器</a>，使用过它们的人都知道，最初的预处理步骤之一是标记化(将文本分解成较小的单元，这些单元被赋予一个数值)。</p><blockquote class="lu"><p id="e166" class="lv lw iq bd lx ly lz ma mb mc md lr dk translated">AudioLM背后的关键直觉是利用语言建模中的这种进步来生成音频，而无需经过带注释数据的训练。— <a class="ae kv" href="https://ai.googleblog.com/2022/10/audiolm-language-modeling-approach-to.html" rel="noopener ugc nofollow" target="_blank">谷歌人工智能博客</a></p></blockquote><p id="58d4" class="pw-post-body-paragraph kw kx iq ky b kz me jr lb lc mf ju le lf mg lh li lj mh ll lm ln mi lp lq lr ij bi translated">AudioLM不需要转录或标记。作者收集了一个声音数据库，并直接输入到模型中。该模型将声音文件压缩成一系列片段(类似于标记)。然后使用这些标记，就好像它们是NLP模型一样(该模型以这种方式使用相同的方法来学习各种音频片段之间的模式和关系)。与文本生成模型一样，AudioLM通过提示生成声音。</p><p id="c1d7" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">结果很有意思，声音自然多了。AudioLM似乎能够找到并再现人类音乐中存在的某些模式(如钢琴键被敲击时每个音符中包含的细微振动)。在下面的链接中，谷歌提供了一些例子，如果你有兴趣听的话:</p><div class="mj mk gp gr ml mm"><a href="https://google-research.github.io/seanet/audiolm/examples/" rel="noopener  ugc nofollow" target="_blank"><div class="mn ab fo"><div class="mo ab mp cl cj mq"><h2 class="bd ir gy z fp mr fr fs ms fu fw ip bi translated">有声电影</h2><div class="mt l"><h3 class="bd b gy z fp mr fr fs ms fu fw dk translated">扎兰·博尔索斯、拉斐尔·马里尼尔、达米安·文森特、尤金·哈利托诺夫、奥利维尔·皮特奎因、马特·沙里菲、奥利维尔·特布尔……</h3></div><div class="mu l"><p class="bd b dl z fp mr fr fs ms fu fw dk translated">google-research.github.io</p></div></div></div></a></div><p id="dcb2" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">AudioLM已经在一个巨大的声音库中接受了训练，其中不仅包括音乐，还包括人声。出于这个原因，该模型可以生成由人类生成的句子。该模型能够识别说话者的口音，并添加停顿和感叹词。虽然该模型生成的许多句子没有意义，但结果令人印象深刻。</p><p id="305b" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">事实上，将声音序列视为单词序列似乎是一种聪明的方法，尽管如此，仍然存在一些困难:</p><blockquote class="mv mw mx"><p id="2f27" class="kw kx my ky b kz la jr lb lc ld ju le mz lg lh li na lk ll lm nb lo lp lq lr ij bi translated">首先，我们必须应对音频的数据速率明显更高的事实，从而导致更长的序列——虽然一个书面句子可以由几十个字符表示，但其音频<a class="ae kv" href="https://en.wikipedia.org/wiki/Waveform" rel="noopener ugc nofollow" target="_blank">波形</a>通常包含数十万个值。第二，文本和音频是一对多的关系。这意味着同一句话可以由不同的说话人以不同的说话风格、情感内容和录音条件进行渲染。— <a class="ae kv" href="https://ai.googleblog.com/2022/10/audiolm-language-modeling-approach-to.html" rel="noopener ugc nofollow" target="_blank">谷歌人工智能博客</a></p></blockquote><p id="dcb6" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">更详细地说，音频标记化方法已经由<a class="ae kv" href="https://openai.com/blog/jukebox/" rel="noopener ugc nofollow" target="_blank"> OpenAI Jukebox </a>尝试过，只是该模型产生了更多的伪像，并且声音听起来不自然。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi nc"><img src="../Images/4e84b179a423cc2a5a7b92a22129a19b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*0JkcgjI5j4Fu5IakTUnPgA.png"/></div></div><figcaption class="kr ks gj gh gi kt ku bd b be z dk translated">AudioLM中使用的记号赋予器概述。图片来自原纸(<a class="ae kv" href="https://arxiv.org/pdf/2209.03143.pdf" rel="noopener ugc nofollow" target="_blank">此处</a>)</figcaption></figure><p id="d8e2" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">如作者所述，该模型由三部分组成:</p><ul class=""><li id="b0d3" class="nd ne iq ky b kz la lc ld lf nf lj ng ln nh lr ni nj nk nl bi translated"><strong class="ky ir">一个记号赋予器模型</strong>，它将一个声音序列映射成一个离散的记号序列。这一步还减小了序列的大小(采样率减小了大约300倍)。</li><li id="ae7a" class="nd ne iq ky b kz nm lc nn lf no lj np ln nq lr ni nj nk nl bi translated"><strong class="ky ir">一个只有解码器的变换器</strong>(一个经典语言模型)，最大化预测序列中下一个记号的可能性。该模型包含12层，16个注意头，嵌入维数为1024，前馈层维数为4096</li><li id="cadf" class="nd ne iq ky b kz nm lc nn lf no lj np ln nq lr ni nj nk nl bi translated"><strong class="ky ir">去爆震器模型</strong>，其将预测的记号转换成音频记号。</li></ul><p id="fc0d" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">该模型接受了60，000小时的英语语音和40，000小时的钢琴实验音乐的训练。</p><blockquote class="mv mw mx"><p id="6866" class="kw kx my ky b kz la jr lb lc ld ju le mz lg lh li na lk ll lm nb lo lp lq lr ij bi translated">为此，我们在40k小时钢琴音乐的内部数据集上重新训练了AudioLM的所有组件，该数据集包括从初学者到专家级别的玩家，并展示了广泛的不同声学条件，内容从钢琴音阶练习到著名作品。— <em class="iq">来源</em> <a class="ae kv" href="https://arxiv.org/pdf/2209.03143.pdf" rel="noopener ugc nofollow" target="_blank"> <em class="iq">原文</em> </a></p></blockquote><p id="609c" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">你也可以在这个短片中看到结果:</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="nr lt l"/></div></figure><p id="715f" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">作者报告说，听AudioLM结果的人没有注意到与人类讲话原始记录的差异。由于该模型可以用于对抗人工智能原理(恶意应用程序、深度伪造等)，作者已经建立了一个分类器，可以识别用AudioLM制作的音频，并正在研究音频“水印”技术</p><p id="c10b" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated"><strong class="ky ir">离别的思念</strong></p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi ns"><img src="../Images/7506bd5b0bf41085235693ba2d322b85.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*92QgKu4wBi8rF8DVLBOj8w.png"/></div></div><figcaption class="kr ks gj gh gi kt ku bd b be z dk translated">使用<a class="ae kv" href="https://openai.com/dall-e-2/" rel="noopener ugc nofollow" target="_blank"> OpenAI Dall-E 2 </a>生成的图像</figcaption></figure><p id="f899" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">最近几个月，我们已经看到了几个模型如何能够生成图像(<a class="ae kv" href="https://arxiv.org/abs/2102.12092" rel="noopener ugc nofollow" target="_blank"> DALL-E、</a> <a class="ae kv" href="https://ommer-lab.com/research/latent-diffusion-models/" rel="noopener ugc nofollow" target="_blank">稳定扩散</a>)，还有像<a class="ae kv" href="https://arxiv.org/abs/2005.14165" rel="noopener ugc nofollow" target="_blank"> GPT3 </a>这样的模型能够生成文本序列。生成音频序列带来了一些额外的困难，但似乎我们很快就会在这方面看到一些更大的进步。</p><p id="8c82" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">事实上，谷歌刚刚推出了AudioLM，一种能够使用音频提示(语音或钢琴)并生成延续的模型。另一方面，呈现稳定扩散的同一组刚刚呈现了<a class="ae kv" href="https://github.com/Harmonai-org/" rel="noopener ugc nofollow" target="_blank"> Harmonai </a>(它实际上使用了稳定扩散的类似算法)。</p><p id="3569" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">这些技术在未来可以用作视频和演示的背景音乐，更好地应用于医疗保健或互联网接入。另一方面，这些技术可能被用于深度伪造、错误信息传播、诈骗等等。</p><h1 id="97f5" class="nt nu iq bd nv nw nx ny nz oa ob oc od jw oe jx of jz og ka oh kc oi kd oj ok bi translated">如果你觉得有趣:</h1><p id="ffd8" class="pw-post-body-paragraph kw kx iq ky b kz ol jr lb lc om ju le lf on lh li lj oo ll lm ln op lp lq lr ij bi translated">你可以寻找我的其他文章，也可以<a class="ae kv" href="https://salvatore-raieli.medium.com/subscribe" rel="noopener"> <strong class="ky ir">订阅</strong> </a>获取我发布文章的通知，也可以在<strong class="ky ir"/><a class="ae kv" href="https://www.linkedin.com/in/salvatore-raieli/" rel="noopener ugc nofollow" target="_blank"><strong class="ky ir">LinkedIn</strong></a><strong class="ky ir">上连接或联系我。</strong>感谢大家的支持！</p><p id="6c04" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">这是我的GitHub知识库的链接，我计划在这里收集代码和许多与机器学习、人工智能等相关的资源。</p><div class="mj mk gp gr ml mm"><a href="https://github.com/SalvatoreRa/tutorial" rel="noopener  ugc nofollow" target="_blank"><div class="mn ab fo"><div class="mo ab mp cl cj mq"><h2 class="bd ir gy z fp mr fr fs ms fu fw ip bi translated">GitHub - SalvatoreRa/tutorial:关于机器学习、人工智能、数据科学的教程…</h2><div class="mt l"><h3 class="bd b gy z fp mr fr fs ms fu fw dk translated">关于机器学习、人工智能、数据科学的教程，包括数学解释和可重复使用的代码(python…</h3></div><div class="mu l"><p class="bd b dl z fp mr fr fs ms fu fw dk translated">github.com</p></div></div><div class="oq l"><div class="or l os ot ou oq ov kp mm"/></div></div></a></div><p id="56f8" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">或者随意查看我在Medium上的其他文章:</p><div class="mj mk gp gr ml mm"><a href="https://towardsdatascience.com/how-artificial-intelligence-could-save-the-amazon-rainforest-688fa505c455" rel="noopener follow" target="_blank"><div class="mn ab fo"><div class="mo ab mp cl cj mq"><h2 class="bd ir gy z fp mr fr fs ms fu fw ip bi translated">人工智能如何拯救亚马逊雨林</h2><div class="mt l"><h3 class="bd b gy z fp mr fr fs ms fu fw dk translated">亚马逊正处于危险之中，人工智能可以帮助保护它</h3></div><div class="mu l"><p class="bd b dl z fp mr fr fs ms fu fw dk translated">towardsdatascience.com</p></div></div><div class="oq l"><div class="ow l os ot ou oq ov kp mm"/></div></div></a></div><div class="mj mk gp gr ml mm"><a href="https://medium.com/mlearning-ai/nobel-prize-cyberpunk-e1803aa0e087" rel="noopener follow" target="_blank"><div class="mn ab fo"><div class="mo ab mp cl cj mq"><h2 class="bd ir gy z fp mr fr fs ms fu fw ip bi translated">诺贝尔奖赛博朋克</h2><div class="mt l"><h3 class="bd b gy z fp mr fr fs ms fu fw dk translated">科学发现中人工智能最重要奖项的计算视角</h3></div><div class="mu l"><p class="bd b dl z fp mr fr fs ms fu fw dk translated">medium.com</p></div></div><div class="oq l"><div class="ox l os ot ou oq ov kp mm"/></div></div></a></div><div class="mj mk gp gr ml mm"><a href="https://towardsdatascience.com/alphafold2-year-1-did-it-change-the-world-499a5a38130a" rel="noopener follow" target="_blank"><div class="mn ab fo"><div class="mo ab mp cl cj mq"><h2 class="bd ir gy z fp mr fr fs ms fu fw ip bi translated">AlphaFold2第一年:它改变了世界吗？</h2><div class="mt l"><h3 class="bd b gy z fp mr fr fs ms fu fw dk translated">DeepMind向我们承诺了一场革命，它发生了吗？</h3></div><div class="mu l"><p class="bd b dl z fp mr fr fs ms fu fw dk translated">towardsdatascience.com</p></div></div><div class="oq l"><div class="oy l os ot ou oq ov kp mm"/></div></div></a></div><div class="mj mk gp gr ml mm"><a href="https://towardsdatascience.com/blending-the-power-of-ai-with-the-delicacy-of-poetry-3671f82d2e1" rel="noopener follow" target="_blank"><div class="mn ab fo"><div class="mo ab mp cl cj mq"><h2 class="bd ir gy z fp mr fr fs ms fu fw ip bi translated">融合人工智能的力量和诗歌的细腻</h2><div class="mt l"><h3 class="bd b gy z fp mr fr fs ms fu fw dk translated">人工智能现在能够从文本中生成图像，如果我们给它们提供伟大诗人的话语会怎么样？梦幻之旅…</h3></div><div class="mu l"><p class="bd b dl z fp mr fr fs ms fu fw dk translated">towardsdatascience.com</p></div></div><div class="oq l"><div class="oz l os ot ou oq ov kp mm"/></div></div></a></div></div></div>    
</body>
</html>