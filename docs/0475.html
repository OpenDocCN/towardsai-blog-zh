<html>
<head>
<title>Introduction to Bayesian Inference</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">贝叶斯推理简介</h1>
<blockquote>原文：<a href="https://pub.towardsai.net/bayesian-inference-estimating-model-overfit-risk-24e1e068822a?source=collection_archive---------1-----------------------#2020-05-09">https://pub.towardsai.net/bayesian-inference-estimating-model-overfit-risk-24e1e068822a?source=collection_archive---------1-----------------------#2020-05-09</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><h2 id="8c79" class="ir is it bd b dl iu iv iw ix iy iz dk ja translated" aria-label="kicker paragraph">数据科学</h2><div class=""/><div class=""><h2 id="f056" class="pw-subtitle-paragraph jz jc it bd b ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq dk translated">第4部分:如何估计模型的过度拟合风险</h2></div><h1 id="79b4" class="kr ks it bd kt ku kv kw kx ky kz la lb ki lc kj ld kl le km lf ko lg kp lh li bi translated">介绍</h1><p id="4a29" class="pw-post-body-paragraph lj lk it ll b lm ln kd lo lp lq kg lr ls lt lu lv lw lx ly lz ma mb mc md me im bi translated">在本文中，我将展示广泛适用的信息标准(WAIC)如何量化一个模型能够推广到看不见的数据的程度。</p><p id="d1d0" class="pw-post-body-paragraph lj lk it ll b lm mf kd lo lp mg kg lr ls mh lu lv lw mi ly lz ma mj mc md me im bi translated">重现结果和数字的代码可在<a class="ae mk" href="https://github.com/hsm207/statrethinking-julia/blob/master/book/07_Information_Theory/model_evaluation-explained.ipynb" rel="noopener ugc nofollow" target="_blank">本</a>笔记本中找到。</p><h1 id="48dc" class="kr ks it bd kt ku kv kw kx ky kz la lb ki lc kj ld kl le km lf ko lg kp lh li bi translated">动机</h1><p id="d8ca" class="pw-post-body-paragraph lj lk it ll b lm ln kd lo lp lq kg lr ls lt lu lv lw lx ly lz ma mb mc md me im bi translated">假设您有一个如下所示的训练和测试集:</p><figure class="mm mn mo mp gt mq gh gi paragraph-image"><div role="button" tabindex="0" class="mr ms di mt bf mu"><div class="gh gi ml"><img src="../Images/bb4dfb974c9e0aebd4bf2783b61b4ddf.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*R5Kkiz8YKXCeM-xlw7RSfw.png"/></div></div><figcaption class="mx my gj gh gi mz na bd b be z dk translated">图1:模拟训练和测试集</figcaption></figure><p id="395b" class="pw-post-body-paragraph lj lk it ll b lm mf kd lo lp mg kg lr ls mh lu lv lw mi ly lz ma mj mc md me im bi translated">目标是用x预测y，你提出了两个模型，如下所示:</p><figure class="mm mn mo mp gt mq gh gi paragraph-image"><div role="button" tabindex="0" class="mr ms di mt bf mu"><div class="gh gi nb"><img src="../Images/773c92fee178151afc2a0b494907ac18.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*lwrZp8RcCWiikM13Y0LOgQ.png"/></div></div><figcaption class="mx my gj gh gi mz na bd b be z dk translated">图2:基于图1中模拟数据的两个模型</figcaption></figure><p id="a542" class="pw-post-body-paragraph lj lk it ll b lm mf kd lo lp mg kg lr ls mh lu lv lw mi ly lz ma mj mc md me im bi translated">你认为哪个模型会对看不见的数据做出更好的预测？很明显，这是模型1，因为模型2在测试集上的表现清楚地表明它已经过度适应了训练集。</p><p id="0133" class="pw-post-body-paragraph lj lk it ll b lm mf kd lo lp mg kg lr ls mh lu lv lw mi ly lz ma mj mc md me im bi translated">但是在现实世界中，数据可能非常稀缺，以至于您没有足够的数据来构建一个像样的测试集。在本例中，您可以绘制模型在训练集上的性能，如图2所示，并得出结论:模型1可能比模型2更好，因为模型2适合训练集中的大量噪声。</p><p id="9376" class="pw-post-body-paragraph lj lk it ll b lm mf kd lo lp mg kg lr ls mh lu lv lw mi ly lz ma mj mc md me im bi translated">在现实世界中，您可能希望将y建模为几个x的函数，如x₁、x₂等。所以不可能做出如图2所示的图。我们将看到WAIC指标如何应对这一挑战。</p><h1 id="14c6" class="kr ks it bd kt ku kv kw kx ky kz la lb ki lc kj ld kl le km lf ko lg kp lh li bi translated">资料组</h1><p id="6ae5" class="pw-post-body-paragraph lj lk it ll b lm ln kd lo lp lq kg lr ls lt lu lv lw lx ly lz ma mb mc md me im bi translated">本文的其余部分将使用以下数据集来训练两个线性模型:</p><figure class="mm mn mo mp gt mq gh gi paragraph-image"><div class="gh gi nc"><img src="../Images/c88d01f58608f6c48dec9a77f75bbcec.png" data-original-src="https://miro.medium.com/v2/resize:fit:714/format:webp/1*k0SxkXrqwpDqyk4g--cm2g.png"/></div><figcaption class="mx my gj gh gi mz na bd b be z dk translated">图3:虚拟数据集</figcaption></figure><p id="5c64" class="pw-post-body-paragraph lj lk it ll b lm mf kd lo lp mg kg lr ls mh lu lv lw mi ly lz ma mj mc md me im bi translated">x是随机产生的，而y定义为:</p><figure class="mm mn mo mp gt mq gh gi paragraph-image"><div class="gh gi nd"><img src="../Images/97abb0200ecfea1b9664bf9bbc486a9a.png" data-original-src="https://miro.medium.com/v2/resize:fit:290/format:webp/1*n4HS1vK-24Pn11-XHuHKKA.png"/></div></figure><p id="f5b6" class="pw-post-body-paragraph lj lk it ll b lm mf kd lo lp mg kg lr ls mh lu lv lw mi ly lz ma mj mc md me im bi translated">其中加入了一些随机噪声。</p><p id="c92c" class="pw-post-body-paragraph lj lk it ll b lm mf kd lo lp mg kg lr ls mh lu lv lw mi ly lz ma mj mc md me im bi translated">我们将生成一个训练集和测试集，每个包含20个观察值。</p><h1 id="6719" class="kr ks it bd kt ku kv kw kx ky kz la lb ki lc kj ld kl le km lf ko lg kp lh li bi translated">模型</h1><p id="5e74" class="pw-post-body-paragraph lj lk it ll b lm ln kd lo lp lq kg lr ls lt lu lv lw lx ly lz ma mb mc md me im bi translated">我们将使用贝叶斯方法构建两个线性模型。有关该方法的更多详细信息，请参考[1]。</p><p id="2284" class="pw-post-body-paragraph lj lk it ll b lm mf kd lo lp mg kg lr ls mh lu lv lw mi ly lz ma mj mc md me im bi translated">这两个模型的主要区别在于，模型1将y建模为x1和x2的函数，而模型2将y建模为x1、x2、x3和x4的函数。</p><p id="6ee0" class="pw-post-body-paragraph lj lk it ll b lm mf kd lo lp mg kg lr ls mh lu lv lw mi ly lz ma mj mc md me im bi translated">因此，模型2将有过度适应训练集的趋势。</p><p id="e3cc" class="pw-post-body-paragraph lj lk it ll b lm mf kd lo lp mg kg lr ls mh lu lv lw mi ly lz ma mj mc md me im bi translated">我们的目标是避免在没有查看任一模型在测试集上的性能的情况下选择模型2。</p><h1 id="f953" class="kr ks it bd kt ku kv kw kx ky kz la lb ki lc kj ld kl le km lf ko lg kp lh li bi translated">如何衡量准确度</h1><p id="fd30" class="pw-post-body-paragraph lj lk it ll b lm ln kd lo lp lq kg lr ls lt lu lv lw lx ly lz ma mb mc md me im bi translated">由于我们正在处理一个预测任务，RMSE是一个很好的选择来衡量我们的模型的准确性。但是，有一个更好的准确性度量标准，它考虑了模型预测中固有的不确定性。</p><p id="3d4b" class="pw-post-body-paragraph lj lk it ll b lm mf kd lo lp mg kg lr ls mh lu lv lw mi ly lz ma mj mc md me im bi translated">该指标称为对数逐点预测密度(lppd ),定义如下:</p><figure class="mm mn mo mp gt mq gh gi paragraph-image"><div class="gh gi ne"><img src="../Images/4d69e5b5449507dc9907160d79ba8cd9.png" data-original-src="https://miro.medium.com/v2/resize:fit:968/format:webp/1*DtXG_uH8E_xyUim3ivUUGw.png"/></div><figcaption class="mx my gj gh gi mz na bd b be z dk translated">图lppd的定义</figcaption></figure><p id="0a93" class="pw-post-body-paragraph lj lk it ll b lm mf kd lo lp mg kg lr ls mh lu lv lw mi ly lz ma mj mc md me im bi translated">图4显示，给定观测值y的向量和由θ参数化的模型，lppd是所有采样参数的平均密度的每个观测值的对数之和。</p><p id="1678" class="pw-post-body-paragraph lj lk it ll b lm mf kd lo lp mg kg lr ls mh lu lv lw mi ly lz ma mj mc md me im bi translated">下一节将对正在发生的事情进行直观的解释。</p><h1 id="a435" class="kr ks it bd kt ku kv kw kx ky kz la lb ki lc kj ld kl le km lf ko lg kp lh li bi translated">lppd如何测量精度</h1><p id="de02" class="pw-post-body-paragraph lj lk it ll b lm ln kd lo lp lq kg lr ls lt lu lv lw lx ly lz ma mb mc md me im bi translated">回想一下[1],贝叶斯方法建立模型的结果是给定数据的模型参数的联合分布，即xs。我们称这种联合分布为后验分布。</p><p id="c221" class="pw-post-body-paragraph lj lk it ll b lm mf kd lo lp mg kg lr ls mh lu lv lw mi ly lz ma mj mc md me im bi translated">为了在给定x的情况下进行实际预测，我们从后验分布中采样参数，并将它们插入到描述y的模型中，例如，y～n(β₁x，1)其中β₁是采样参数。</p><p id="12bf" class="pw-post-body-paragraph lj lk it ll b lm mf kd lo lp mg kg lr ls mh lu lv lw mi ly lz ma mj mc md me im bi translated">例如，考虑下图:</p><figure class="mm mn mo mp gt mq gh gi paragraph-image"><div role="button" tabindex="0" class="mr ms di mt bf mu"><div class="gh gi nf"><img src="../Images/65742c06000049949470ff42bb93b9cc.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*YAyW2zatdh07kOOiWAwf-A.png"/></div></div><figcaption class="mx my gj gh gi mz na bd b be z dk translated">图5:坏模型的Lppd</figcaption></figure><p id="31c4" class="pw-post-body-paragraph lj lk it ll b lm mf kd lo lp mg kg lr ls mh lu lv lw mi ly lz ma mj mc md me im bi translated">图5显示了一个模型，它试图预测给定x = 5时y = 10。y被建模为正态分布，平均值为βx，标准偏差为0.2。</p><p id="2cfc" class="pw-post-body-paragraph lj lk it ll b lm mf kd lo lp mg kg lr ls mh lu lv lw mi ly lz ma mj mc md me im bi translated">图5中的左图显示了参数β的可能后验分布。这个后验分布的平均值为2.5。</p><p id="b06a" class="pw-post-body-paragraph lj lk it ll b lm mf kd lo lp mg kg lr ls mh lu lv lw mi ly lz ma mj mc md me im bi translated">图5中的右图显示了基于每个采样β构建的正态分布。正如所料，大多数正态分布将集中在y = 5处，这意味着y = 10处的大多数正态分布的密度将接近0。这就是为什么这个观察的lppd评分很低(-7.0)。</p><p id="b3ad" class="pw-post-body-paragraph lj lk it ll b lm mf kd lo lp mg kg lr ls mh lu lv lw mi ly lz ma mj mc md me im bi translated">将图5与下图进行对比:</p><figure class="mm mn mo mp gt mq gh gi paragraph-image"><div role="button" tabindex="0" class="mr ms di mt bf mu"><div class="gh gi ng"><img src="../Images/e56fdc70519be1f3d0f6a4b972379dd3.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*3f4-V3_Nphi0izH_kFFa5A.png"/></div></div><figcaption class="mx my gj gh gi mz na bd b be z dk translated">图6:更好模型的lppd</figcaption></figure><p id="b24e" class="pw-post-body-paragraph lj lk it ll b lm mf kd lo lp mg kg lr ls mh lu lv lw mi ly lz ma mj mc md me im bi translated">图5和图6之间的唯一区别是图6中的后验分布的平均值为5.0，这解释了为什么从该后验分布构建的正态分布与y = 10有更多的重叠，因此lppd得分更高(-1.3)。</p><p id="bc1f" class="pw-post-body-paragraph lj lk it ll b lm mf kd lo lp mg kg lr ls mh lu lv lw mi ly lz ma mj mc md me im bi translated">本节的关键是:</p><ul class=""><li id="ed06" class="nh ni it ll b lm mf lp mg ls nj lw nk ma nl me nm nn no np bi translated">lppd对模型后验分布中的采样参数将产生质量接近实际值的预测分布的程度进行评分。</li><li id="f62a" class="nh ni it ll b lm nq lp nr ls ns lw nt ma nu me nm nn no np bi translated">较高的lppd分数意味着较高的准确性</li></ul><h1 id="6338" class="kr ks it bd kt ku kv kw kx ky kz la lb ki lc kj ld kl le km lf ko lg kp lh li bi translated">使用lppd</h1><p id="5dfd" class="pw-post-body-paragraph lj lk it ll b lm ln kd lo lp lq kg lr ls lt lu lv lw lx ly lz ma mb mc md me im bi translated">以下是模型1和模型2的lppd值:</p><figure class="mm mn mo mp gt mq gh gi paragraph-image"><div class="gh gi nv"><img src="../Images/872d7388fe533282fb5fad9ab7a5ca7b.png" data-original-src="https://miro.medium.com/v2/resize:fit:416/format:webp/1*gtVgUV8AjY4-F2QbTgZvlA.png"/></div><figcaption class="mx my gj gh gi mz na bd b be z dk translated">图7:模型1和模型2的lppd值</figcaption></figure><p id="56f5" class="pw-post-body-paragraph lj lk it ll b lm mf kd lo lp mg kg lr ls mh lu lv lw mi ly lz ma mj mc md me im bi translated">正如所料，模型1在训练集和测试集上具有相似的lppd值，而模型2在测试集上的准确性比训练集差得多。</p><p id="a91b" class="pw-post-body-paragraph lj lk it ll b lm mf kd lo lp mg kg lr ls mh lu lv lw mi ly lz ma mj mc md me im bi translated">现在，假设我们没有一个测试集来计算每个模型的lppd。我们可以选择模型1而不是模型2，因为前者的lppd比后者高吗？不，因为这种差异可能只是由于随机的机会。</p><h1 id="1383" class="kr ks it bd kt ku kv kw kx ky kz la lb ki lc kj ld kl le km lf ko lg kp lh li bi translated">仅使用训练集估计过度拟合风险</h1><p id="4799" class="pw-post-body-paragraph lj lk it ll b lm ln kd lo lp lq kg lr ls lt lu lv lw lx ly lz ma mb mc md me im bi translated">事实证明，可以修改训练集上的lppd来估计测试集上的lppd。我们只需对其应用惩罚项，计算方法是根据后验分布的采样参数，对每个观测值的对数密度的方差求和:</p><figure class="mm mn mo mp gt mq gh gi paragraph-image"><div class="gh gi nw"><img src="../Images/5ad954c84e36009c85ec8b68d6c36931.png" data-original-src="https://miro.medium.com/v2/resize:fit:888/format:webp/1*E4fBgvM1sU_VBLn2cupKCQ.png"/></div><figcaption class="mx my gj gh gi mz na bd b be z dk translated">图8:罚款期限</figcaption></figure><p id="02c1" class="pw-post-body-paragraph lj lk it ll b lm mf kd lo lp mg kg lr ls mh lu lv lw mi ly lz ma mj mc md me im bi translated">直观地说，这个惩罚项惩罚的是非常准确但只是在极少数情况下或者到处都在做预测的模型。这意味着大部分采样参数产生的模型不准确，进而意味着模型对其参数敏感，这是过拟合的标志！</p><p id="0621" class="pw-post-body-paragraph lj lk it ll b lm mf kd lo lp mg kg lr ls mh lu lv lw mi ly lz ma mj mc md me im bi translated">下图将有助于阐明这一点:</p><figure class="mm mn mo mp gt mq gh gi paragraph-image"><div class="gh gi nx"><img src="../Images/3c49f65e88cb3018bba1a918a17bf83e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1392/format:webp/1*fXLJRQDtwisJa-BkxaC6VA.png"/></div><figcaption class="mx my gj gh gi mz na bd b be z dk translated">图9:训练集中所选点的预测密度分布</figcaption></figure><p id="80b8" class="pw-post-body-paragraph lj lk it ll b lm mf kd lo lp mg kg lr ls mh lu lv lw mi ly lz ma mj mc md me im bi translated">图8显示了用于计算观测值16至20的lppd的密度分布。很明显，相对于模型1，模型2的预测更加分散。因此，我们应该期待模型2有一个更高的惩罚条款。实际上，模型1的惩罚项是1.13，而模型2是19.30。</p><p id="f9af" class="pw-post-body-paragraph lj lk it ll b lm mf kd lo lp mg kg lr ls mh lu lv lw mi ly lz ma mj mc md me im bi translated">综上所述，测试集的估计lppd由下式给出:</p><figure class="mm mn mo mp gt mq gh gi paragraph-image"><div role="button" tabindex="0" class="mr ms di mt bf mu"><div class="gh gi ny"><img src="../Images/4d18e12668b773e76f92b86c25398f84.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*luZtDtZZF3fCjX3QAgOG4g.png"/></div></div><figcaption class="mx my gj gh gi mz na bd b be z dk translated">图10:如何在测试集上估计lppd</figcaption></figure><p id="a171" class="pw-post-body-paragraph lj lk it ll b lm mf kd lo lp mg kg lr ls mh lu lv lw mi ly lz ma mj mc md me im bi translated">图10中的公式也被称为WAIC。还有另一种将它乘以-2的变体，但是在本文中我们将坚持这个版本。</p><h1 id="786e" class="kr ks it bd kt ku kv kw kx ky kz la lb ki lc kj ld kl le km lf ko lg kp lh li bi translated">使用WAIC</h1><p id="82f2" class="pw-post-body-paragraph lj lk it ll b lm ln kd lo lp lq kg lr ls lt lu lv lw lx ly lz ma mb mc md me im bi translated">以下是WAIC与lppd在测试集上的对比:</p><figure class="mm mn mo mp gt mq gh gi paragraph-image"><div class="gh gi nz"><img src="../Images/a979e58d30837b44fcfa8c2957f3b905.png" data-original-src="https://miro.medium.com/v2/resize:fit:450/format:webp/1*aq59EGhIH7kvIlKR7tUJaA.png"/></div><figcaption class="mx my gj gh gi mz na bd b be z dk translated">图11:在测试集上比较WAIC和lppd</figcaption></figure><p id="5fd2" class="pw-post-body-paragraph lj lk it ll b lm mf kd lo lp mg kg lr ls mh lu lv lw mi ly lz ma mj mc md me im bi translated">WAIC和lppd序列之间的关系与两种模型的lppd测试和lppd序列之间的关系相同。因此，基于WAIC的模型选择与基于模型在测试集上的准确性的决定是一样的。</p><p id="febc" class="pw-post-body-paragraph lj lk it ll b lm mf kd lo lp mg kg lr ls mh lu lv lw mi ly lz ma mj mc md me im bi translated">在某种程度上，看不见的数据遵循与训练集相同的数据生成过程，我们更有信心模型1将概括得更好，因为它的WAIC值与它在训练集上的lppd相似。</p><h1 id="b64a" class="kr ks it bd kt ku kv kw kx ky kz la lb ki lc kj ld kl le km lf ko lg kp lh li bi translated">WAIC的稳健性</h1><p id="92e6" class="pw-post-body-paragraph lj lk it ll b lm ln kd lo lp lq kg lr ls lt lu lv lw lx ly lz ma mb mc md me im bi translated">我们是不是很幸运，因为我们有一个训练样本，它的WAIC值恰好接近测试集上的lppd？</p><p id="9f7c" class="pw-post-body-paragraph lj lk it ll b lm mf kd lo lp mg kg lr ls mh lu lv lw mi ly lz ma mj mc md me im bi translated">为了找出答案，我们可以随机生成一对训练集和测试集，每组20个观察值(使用相同的数据生成过程)，然后计算每对的lppd和WAIC值。这是用模型1进行10次模拟的结果:</p><figure class="mm mn mo mp gt mq gh gi paragraph-image"><div class="gh gi oa"><img src="../Images/d18ed9d55364af24e31569d691658408.png" data-original-src="https://miro.medium.com/v2/resize:fit:1342/format:webp/1*hScO4_zuPoOvRC3NuNlv8g.png"/></div><figcaption class="mx my gj gh gi mz na bd b be z dk translated">图12:模型1的lppd和WAIC分布</figcaption></figure><p id="6feb" class="pw-post-body-paragraph lj lk it ll b lm mf kd lo lp mg kg lr ls mh lu lv lw mi ly lz ma mj mc md me im bi translated">我们看到，WAIC的分布与lppd在测试集上的分布非常接近，即使在只有20个观测值的样本量上也是如此。</p><p id="e0e1" class="pw-post-body-paragraph lj lk it ll b lm mf kd lo lp mg kg lr ls mh lu lv lw mi ly lz ma mj mc md me im bi translated">一般来说，WAIC提供了样本外lppd的近似，它收敛于大样本中的留一交叉验证近似[2]。我还没想明白为什么会这样。好奇的读者可能希望参考[3]和[4]以获得更多的见解。</p><h1 id="1422" class="kr ks it bd kt ku kv kw kx ky kz la lb ki lc kj ld kl le km lf ko lg kp lh li bi translated">结论</h1><p id="d493" class="pw-post-body-paragraph lj lk it ll b lm ln kd lo lp lq kg lr ls lt lu lv lw lx ly lz ma mb mc md me im bi translated">本文展示了在缺乏独立测试集的情况下，WAIC度量如何指导模型选择。与进行交叉验证相比，在计算上实现起来要便宜得多。</p><p id="7ad7" class="pw-post-body-paragraph lj lk it ll b lm mf kd lo lp mg kg lr ls mh lu lv lw mi ly lz ma mj mc md me im bi translated">如果你知道为什么WAIC使用留一交叉验证法收敛于样本外lppd，请在评论中告诉我。</p><h1 id="7562" class="kr ks it bd kt ku kv kw kx ky kz la lb ki lc kj ld kl le km lf ko lg kp lh li bi translated">参考</h1><p id="5e13" class="pw-post-body-paragraph lj lk it ll b lm ln kd lo lp lq kg lr ls lt lu lv lw lx ly lz ma mb mc md me im bi translated">[1] <a class="ae mk" href="https://medium.com/towards-artificial-intelligence/bayesian-inference-how-linear-models-work-6ceb120adc84" rel="noopener">贝叶斯推理介绍第三部分:线性模型如何工作</a>。___.2020.</p><p id="4ff8" class="pw-post-body-paragraph lj lk it ll b lm mf kd lo lp mg kg lr ls mh lu lv lw mi ly lz ma mj mc md me im bi translated">[2]用R和Stan中的例子进行统计再思考。麦克尔瑞斯。2020</p><p id="482f" class="pw-post-body-paragraph lj lk it ll b lm mf kd lo lp mg kg lr ls mh lu lv lw mi ly lz ma mj mc md me im bi translated"><a class="ae mk" href="http://www.jmlr.org/papers/volume14/watanabe13a/watanabe13a.pdf" rel="noopener ugc nofollow" target="_blank">【3】一种广泛适用的贝叶斯信息准则</a>。渡边。2013</p><p id="00e9" class="pw-post-body-paragraph lj lk it ll b lm mf kd lo lp mg kg lr ls mh lu lv lw mi ly lz ma mj mc md me im bi translated">[4] <a class="ae mk" href="http://www.jmlr.org/papers/volume11/watanabe10a/watanabe10a.pdf" rel="noopener ugc nofollow" target="_blank">贝叶斯交叉验证的渐近等价性和奇异学习理论中广泛适用的信息准则</a>。渡边。2010</p></div></div>    
</body>
</html>