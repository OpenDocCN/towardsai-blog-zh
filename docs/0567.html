<html>
<head>
<title>Sentiment Analysis on Movie Reviews with NLP Achieving 95% Accuracy</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">基于自然语言处理的电影评论情感分析准确率达到95%</h1>
<blockquote>原文：<a href="https://pub.towardsai.net/sentiment-analysis-on-movie-reviews-with-nlp-achieving-95-accuracy-91eef597e0f7?source=collection_archive---------1-----------------------#2020-06-08">https://pub.towardsai.net/sentiment-analysis-on-movie-reviews-with-nlp-achieving-95-accuracy-91eef597e0f7?source=collection_archive---------1-----------------------#2020-06-08</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><h2 id="ebe6" class="ir is it bd b dl iu iv iw ix iy iz dk ja translated" aria-label="kicker paragraph">自然语言处理</h2><div class=""/><div class=""><h2 id="817a" class="pw-subtitle-paragraph jz jc it bd b ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq dk translated">在我的Github库中可以找到完整的代码。一手货源在<a class="ae kr" href="https://www.kaggle.com/nltkdata/movie-review?select=movie_review.csv" rel="noopener ugc nofollow" target="_blank"> Kaggle </a>上有</h2></div><p id="f930" class="pw-post-body-paragraph ks kt it ku b kv kw kd kx ky kz kg la lb lc ld le lf lg lh li lj lk ll lm ln im bi translated">几天前，我发表了一篇文章，使用相同的机器学习模块对推特数据集进行了<a class="ae kr" href="https://medium.com/towards-artificial-intelligence/sentiment-analysis-on-tweets-with-nlp-achieving-96-accuracy-8b63f0bcee99" rel="noopener">情感分析，准确率达到96%</a>。现在是增加复杂性和处理更复杂问题的时候了。这个实验的一个完美数据集是电影评论数据集，你可以在Kaggle上下载(见上面的链接)。</p><figure class="lp lq lr ls gt lt gh gi paragraph-image"><div role="button" tabindex="0" class="lu lv di lw bf lx"><div class="gh gi lo"><img src="../Images/4ab8c4a3f96ebe07a6f82ccdf2aeb48f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*GfxRHErIsPGOtMbaCVyMDw.jpeg"/></div></div><figcaption class="ma mb gj gh gi mc md bd b be z dk translated">死亡池2，2018，漫威</figcaption></figure><h2 id="7960" class="me mf it bd mg mh mi dn mj mk ml dp mm lb mn mo mp lf mq mr ms lj mt mu mv iz bi translated">机器学习与深度学习</h2><p id="abc1" class="pw-post-body-paragraph ks kt it ku b kv mw kd kx ky mx kg la lb my ld le lf mz lh li lj na ll lm ln im bi translated">为什么我没有使用深度学习来完成这些任务？如果我必须使用Tensorflow，我会使用嵌入式神经网络。不幸的是，这个数据集只包含2000条评论。与Keras中包含50，000条评论的标准电影评论相比，可能没有足够的数据供神经网络在其顶端执行。只有当数据量足够大时，深度学习的表现才会优于机器学习。</p><h1 id="e046" class="nb mf it bd mg nc nd ne mj nf ng nh mm ki ni kj mp kl nj km ms ko nk kp mv nl bi translated">nltk模块</h1><p id="74ef" class="pw-post-body-paragraph ks kt it ku b kv mw kd kx ky mx kg la lb my ld le lf mz lh li lj na ll lm ln im bi translated">我将使用专门用于NLP的机器学习库，称为nltk。我更喜欢使用scikit-learn来创建机器学习模型，但它是一个专门用于表格数据的库，而不是自然语言处理。</p><h1 id="095d" class="nb mf it bd mg nc nd ne mj nf ng nh mm ki ni kj mp kl nj km ms ko nk kp mv nl bi translated">步伐</h1><p id="b441" class="pw-post-body-paragraph ks kt it ku b kv mw kd kx ky mx kg la lb my ld le lf mz lh li lj na ll lm ln im bi translated">在本文中，我将遵循以下步骤。与上一篇文章的Twitter情感分析相比，数据的预处理会麻烦很多。</p><ol class=""><li id="1487" class="nm nn it ku b kv kw ky kz lb no lf np lj nq ln nr ns nt nu bi translated">导入模块</li><li id="9c04" class="nm nn it ku b kv nv ky nw lb nx lf ny lj nz ln nr ns nt nu bi translated">看着这些数据</li><li id="4ce9" class="nm nn it ku b kv nv ky nw lb nx lf ny lj nz ln nr ns nt nu bi translated">创建要素和标签(编码)</li><li id="8c8a" class="nm nn it ku b kv nv ky nw lb nx lf ny lj nz ln nr ns nt nu bi translated">创建训练和测试(分割)</li><li id="bc5a" class="nm nn it ku b kv nv ky nw lb nx lf ny lj nz ln nr ns nt nu bi translated">使用模型:朴素贝叶斯分类器</li><li id="9bb5" class="nm nn it ku b kv nv ky nw lb nx lf ny lj nz ln nr ns nt nu bi translated">性能赋值</li></ol><p id="fab0" class="pw-post-body-paragraph ks kt it ku b kv kw kd kx ky kz kg la lb lc ld le lf lg lh li lj lk ll lm ln im bi translated">我将使用一种特殊的编码:不是将单词转换成数字，而是将它们存储到字典中。然后，我将把这个字典提供给模型。</p><h1 id="ec29" class="nb mf it bd mg nc nd ne mj nf ng nh mm ki ni kj mp kl nj km ms ko nk kp mv nl bi translated">1.导入模块</h1><pre class="lp lq lr ls gt oa ob oc od aw oe bi"><span id="a48c" class="me mf it ob b gy of og l oh oi">!pip install nltk<br/>import nltk<br/>#per risolvere un bug, altrimenti da errore<br/>nltk.download('punkt')</span></pre><p id="b742" class="pw-post-body-paragraph ks kt it ku b kv kw kd kx ky kz kg la lb lc ld le lf lg lh li lj lk ll lm ln im bi translated">除了我将使用的主要模块(不仅用于机器学习，还用于设置分词器)，我还必须创建我的分词工具。这个函数将把评论的每个句子分解成单独的字符串，并将每个单词放入python字典中。</p><pre class="lp lq lr ls gt oa ob oc od aw oe bi"><span id="e8b1" class="me mf it ob b gy of og l oh oi">#tokenizer<br/>def format_sentence(sent):<br/>  return({word: True for word in nltk.word_tokenize(sent)})</span><span id="5a7e" class="me mf it ob b gy oj og l oh oi">#example<br/>format_sentence('how are you')<br/>{'are': True, 'how': True, 'you': True}</span></pre><h1 id="a49e" class="nb mf it bd mg nc nd ne mj nf ng nh mm ki ni kj mp kl nj km ms ko nk kp mv nl bi translated">2.看着这些数据</h1><pre class="lp lq lr ls gt oa ob oc od aw oe bi"><span id="ce72" class="me mf it ob b gy of og l oh oi">import pandas as pd<br/>total = pd.read_csv('/content/drive/My Drive/Colab Notebooks/Projects/20200602_Twitter_Sentiment_Analysis/movie_review.csv')<br/>total</span></pre><p id="0da0" class="pw-post-body-paragraph ks kt it ku b kv kw kd kx ky kz kg la lb lc ld le lf lg lh li lj lk ll lm ln im bi translated">正如我们在导入数据集后可以立即看到的，我们遇到了一个大问题。这些评论是按句子存储的，同一篇评论的许多部分存放在不止一行中。我将需要从文本块分组的评论，然后将它们标记为积极或消极。</p><p id="2654" class="pw-post-body-paragraph ks kt it ku b kv kw kd kx ky kz kg la lb lc ld le lf lg lh li lj lk ll lm ln im bi translated">* * *这可能不会对使用机器学习工具产生太大影响，但如果我们决定使用深度学习，我们可能希望将所有评论捆绑在一起。从两方面来看，这都是一个需要解决的有指导意义的问题。</p><figure class="lp lq lr ls gt lt gh gi paragraph-image"><div role="button" tabindex="0" class="lu lv di lw bf lx"><div class="gh gi ok"><img src="../Images/882c32cd8321f91376ccc9c341aaa440.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*tKD-TapfGAbRptdG3LGqLg.png"/></div></div></figure><p id="2638" class="pw-post-body-paragraph ks kt it ku b kv kw kd kx ky kz kg la lb lc ld le lf lg lh li lj lk ll lm ln im bi translated">我将使用pandas的函数groupby通过html_id聚集行，然后将它们转换成一个列表。</p><pre class="lp lq lr ls gt oa ob oc od aw oe bi"><span id="a298" class="me mf it ob b gy of og l oh oi">#group by html_id<br/>total = total.groupby('html_id').agg(lambda x: x.tolist())<br/>total = total.reset_index()<br/>total</span></pre><figure class="lp lq lr ls gt lt gh gi paragraph-image"><div role="button" tabindex="0" class="lu lv di lw bf lx"><div class="gh gi ol"><img src="../Images/96adf6e447ae91b874920562792b7b4f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*4-BF04nyAuGmHedaTLRlNA.png"/></div></div></figure><p id="f59b" class="pw-post-body-paragraph ks kt it ku b kv kw kd kx ky kz kg la lb lc ld le lf lg lh li lj lk ll lm ln im bi translated">所有的评论都被合并在文本栏下。我现在将删除多余的列。</p><pre class="lp lq lr ls gt oa ob oc od aw oe bi"><span id="6f27" class="me mf it ob b gy of og l oh oi">#drop other columns: only conserve text<br/>total.columns<br/>total = total.drop(['html_id', 'fold_id', 'cv_tag', 'sent_id'], axis=1)<br/>total</span></pre><figure class="lp lq lr ls gt lt gh gi paragraph-image"><div role="button" tabindex="0" class="lu lv di lw bf lx"><div class="gh gi om"><img src="../Images/e2eafd817c6978f58b37ea4abe6a9959.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*pcz-NqLSu0luSj9wpzaWFg.png"/></div></div></figure><pre class="lp lq lr ls gt oa ob oc od aw oe bi"><span id="15f4" class="me mf it ob b gy of og l oh oi">#the result is a separated chunks for every reviews: <br/>#chunk1, chunk2, ..., sentiment<br/>total.values</span></pre><figure class="lp lq lr ls gt lt gh gi paragraph-image"><div role="button" tabindex="0" class="lu lv di lw bf lx"><div class="gh gi on"><img src="../Images/1a2a4d10d718854aebec5bdc38601ec6.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*jU5cuLvPtKA-Z5lI8JYArQ.png"/></div></div></figure><p id="53d9" class="pw-post-body-paragraph ks kt it ku b kv kw kd kx ky kz kg la lb lc ld le lf lg lh li lj lk ll lm ln im bi translated">我现在将重新创建一个数据集，在一列中包含完整的评论，在另一列中包含一个观点，而不是每行一个观点列表。</p><pre class="lp lq lr ls gt oa ob oc od aw oe bi"><span id="3166" class="me mf it ob b gy of og l oh oi">#we merge the chunks together and we obtain: <br/>#review, sentiment<br/>total_text = list()<br/>for lists in total.values:<br/>  combines_text = ''<br/>  for _ in lists[0]:<br/>    combines_text = combines_text + _<br/>  total_text.append([combines_text, lists[1][0]])</span><span id="e26a" class="me mf it ob b gy oj og l oh oi">#total_text<br/>total_text = pd.DataFrame(total_text)<br/>total_text</span></pre><figure class="lp lq lr ls gt lt gh gi paragraph-image"><div class="gh gi oo"><img src="../Images/2293b44a49ea6aaea1f60a27f6f040de.png" data-original-src="https://miro.medium.com/v2/resize:fit:1236/format:webp/1*dHeE31-IedsNuyTUlhBdlw.png"/></div></figure><p id="3135" class="pw-post-body-paragraph ks kt it ku b kv kw kd kx ky kz kg la lb lc ld le lf lg lh li lj lk ll lm ln im bi translated">这是最终的列表:一个数据集中所有正面和负面评论的组合。</p><h2 id="055b" class="me mf it bd mg mh mi dn mj mk ml dp mm lb mn mo mp lf mq mr ms lj mt mu mv iz bi translated">隔离正面评论</h2><pre class="lp lq lr ls gt oa ob oc od aw oe bi"><span id="4e31" class="me mf it ob b gy of og l oh oi">total_positive = total_text.copy()<br/>total_positive.columns<br/>total_positive = total_positive.loc[total_positive[1] == 'pos']<br/>#total_positive = total_positive.pop('text')<br/>#total_positive = total_positive.drop(['fold_id', 'cv_tag', 'html_id', 'sent_id'], axis=1)<br/>total_positive</span></pre><figure class="lp lq lr ls gt lt gh gi paragraph-image"><div class="gh gi op"><img src="../Images/4575fb143645dc338ab04fa33ae82fce.png" data-original-src="https://miro.medium.com/v2/resize:fit:836/format:webp/1*HypEcu_Fx8YBRikyO0T9eA.png"/></div></figure><h2 id="18b2" class="me mf it bd mg mh mi dn mj mk ml dp mm lb mn mo mp lf mq mr ms lj mt mu mv iz bi translated">隔离负面评论</h2><pre class="lp lq lr ls gt oa ob oc od aw oe bi"><span id="593f" class="me mf it ob b gy of og l oh oi">total_negative = total_text.copy()<br/>total_negative.columns<br/>total_negative = total_negative.loc[total_negative[1] == 'neg']<br/>#total_negative = total_negative.pop('text')<br/>#total_negative = total_negative.drop(['fold_id', 'cv_tag', 'html_id', 'sent_id'], axis=1)<br/>total_negative</span></pre><figure class="lp lq lr ls gt lt gh gi paragraph-image"><div class="gh gi oq"><img src="../Images/dfaa666447b4f2ae41e8eb71382d6fa5.png" data-original-src="https://miro.medium.com/v2/resize:fit:844/format:webp/1*Um7EPKZBWhhjSE6b0A4w2w.png"/></div></figure><h1 id="13a6" class="nb mf it bd mg nc nd ne mj nf ng nh mm ki ni kj mp kl nj km ms ko nk kp mv nl bi translated">3.创建要素和标签(编码)</h1><p id="7bf2" class="pw-post-body-paragraph ks kt it ku b kv mw kd kx ky mx kg la lb my ld le lf mz lh li lj na ll lm ln im bi translated">为了训练一个监督学习的人工智能，我需要为朴素贝叶斯分类器模型准备好我的数据。</p><pre class="lp lq lr ls gt oa ob oc od aw oe bi"><span id="010e" class="me mf it ob b gy of og l oh oi">#   tokenizer<br/>def create_dict(total_positive, total_negative):<br/>  <br/>  positive_reviews = list()<br/>  #word tokenization<br/>  for sentence in list(total_positive.values):<br/>    positive_reviews.append([format_sentence(sentence[0]), 'pos'])<br/>    #saves the sentence in format: [{tokenized sentence}, 'pos]<br/>  <br/>  negative_reviews = list()<br/>  #word tokenization<br/>  for sentence in list(total_negative.values):<br/>    #print(sentence)<br/>    negative_reviews.append([format_sentence(sentence[0]), 'neg'])<br/>    #saves the sentence in format: [{tokenized sentence}, 'pos]<br/>  <br/>  return positive_reviews, negative_reviews</span><span id="1f8b" class="me mf it ob b gy oj og l oh oi">Xy_pos, Xy_neg = create_dict(total_positive, total_negative)</span></pre><p id="cb30" class="pw-post-body-paragraph ks kt it ku b kv kw kd kx ky kz kg la lb lc ld le lf lg lh li lj lk ll lm ln im bi translated">让我看一下数据的结构。这是存储在正面评论列表中的第一个词典。</p><pre class="lp lq lr ls gt oa ob oc od aw oe bi"><span id="e5b3" class="me mf it ob b gy of og l oh oi">Xy_pos[0]<br/>[{'!': True,<br/>  '&amp;': True,<br/>  "'d": True,<br/>  "'s": True,<br/>  "'ve": True,<br/>  ...<br/>  '.women': True,<br/>  'with': True,<br/>  'without': True,<br/>  'women': True,<br/>  'words': True,<br/>  'would': True,<br/>  'you': True,<br/>  'yourself': True},<br/> 'pos']</span></pre><p id="018b" class="pw-post-body-paragraph ks kt it ku b kv kw kd kx ky kz kg la lb lc ld le lf lg lh li lj lk ll lm ln im bi translated">我想看看数据集的图表，看看正面和负面评论的比例。</p><pre class="lp lq lr ls gt oa ob oc od aw oe bi"><span id="77e1" class="me mf it ob b gy of og l oh oi">X = pd.concat([total_positive, total_negative], axis=0)<br/>X.columns = ['text', 'sentiment']</span><span id="2ea2" class="me mf it ob b gy oj og l oh oi">import seaborn as sns<br/>sns.countplot(x='sentiment', data=X)</span><span id="d635" class="me mf it ob b gy oj og l oh oi">y = pd.DataFrame(X.pop('sentiment'))</span></pre><figure class="lp lq lr ls gt lt gh gi paragraph-image"><div class="gh gi or"><img src="../Images/49056d681c27ed9c6647bf3f60b6c065.png" data-original-src="https://miro.medium.com/v2/resize:fit:794/format:webp/1*5IMJls7GmvqMkeAuFPs6QA.png"/></div><figcaption class="ma mb gj gh gi mc md bd b be z dk translated">1000个正面评价，1000个负面评价</figcaption></figure><h1 id="520d" class="nb mf it bd mg nc nd ne mj nf ng nh mm ki ni kj mp kl nj km ms ko nk kp mv nl bi translated">4.创建训练和测试(分割)</h1><pre class="lp lq lr ls gt oa ob oc od aw oe bi"><span id="8bfd" class="me mf it ob b gy of og l oh oi">def split(pos, neg, ratio):<br/>  train = pos[:int((1-ratio)*len(pos))] + neg[:int((1-ratio)*len(neg))]<br/>  test = pos[int((ratio)*len(pos)):] + neg[int((ratio)*len(neg)):]<br/>  return train, test</span><span id="faf1" class="me mf it ob b gy oj og l oh oi">Xy_train, Xy_test = split(Xy_pos, Xy_neg, 0.1)</span></pre><p id="9ce7" class="pw-post-body-paragraph ks kt it ku b kv kw kd kx ky kz kg la lb lc ld le lf lg lh li lj lk ll lm ln im bi translated">我现在可以准备训练和数据集的测试比例来训练NLP模型。</p><h1 id="3c7f" class="nb mf it bd mg nc nd ne mj nf ng nh mm ki ni kj mp kl nj km ms ko nk kp mv nl bi translated">5.使用模型:朴素贝叶斯分类器</h1><p id="7bc0" class="pw-post-body-paragraph ks kt it ku b kv mw kd kx ky mx kg la lb my ld le lf mz lh li lj na ll lm ln im bi translated">最后，我可以创建朴素贝叶斯分类器模型。我将使用数据集的Xy_train比例来填充模型。</p><pre class="lp lq lr ls gt oa ob oc od aw oe bi"><span id="b7fb" class="me mf it ob b gy of og l oh oi">from nltk.classify import NaiveBayesClassifier</span><span id="60f4" class="me mf it ob b gy oj og l oh oi">#training the model<br/>classifier = NaiveBayesClassifier.train(Xy_train)<br/>classifier.show_most_informative_features()<br/>ost Informative Features                insulting = True              neg : pos    =     17.7 : 1.0                ludicrous = True              neg : pos    =     13.4 : 1.0                   avoids = True              pos : neg    =     12.3 : 1.0              outstanding = True              pos : neg    =     12.3 : 1.0                   regard = True              pos : neg    =     11.7 : 1.0                animators = True              pos : neg    =     10.3 : 1.0              fascination = True              pos : neg    =     10.3 : 1.0                    .yeah = True              neg : pos    =     10.3 : 1.0                     3000 = True              neg : pos    =     10.3 : 1.0                    sucks = True              neg : pos    =      9.8 : 1.0</span></pre><p id="45d4" class="pw-post-body-paragraph ks kt it ku b kv kw kd kx ky kz kg la lb lc ld le lf lg lh li lj lk ll lm ln im bi translated">该模型将一个值与数据集中的每个单词相关联。它将对每篇评论中包含的所有单词进行计算，然后做出评估:正面或负面。</p><h1 id="fe55" class="nb mf it bd mg nc nd ne mj nf ng nh mm ki ni kj mp kl nj km ms ko nk kp mv nl bi translated">6.性能赋值</h1><pre class="lp lq lr ls gt oa ob oc od aw oe bi"><span id="5b6e" class="me mf it ob b gy of og l oh oi">from nltk.classify.util import accuracy<br/>print(accuracy(classifier, Xy_test))<br/>0.9477777777777778</span></pre><p id="191e" class="pw-post-body-paragraph ks kt it ku b kv kw kd kx ky kz kg la lb lc ld le lf lg lh li lj lk ll lm ln im bi translated">我们的准确度是94.7%，我们可以近似超过95%。惊人的结果！</p></div></div>    
</body>
</html>