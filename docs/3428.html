<html>
<head>
<title>Text Recognition With TensorFlow and CTC Network</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">基于TensorFlow和CTC网络的文本识别</h1>
<blockquote>原文：<a href="https://pub.towardsai.net/text-recognition-with-tensorflow-and-ctc-network-15b2925f3171?source=collection_archive---------3-----------------------#2022-12-21">https://pub.towardsai.net/text-recognition-with-tensorflow-and-ctc-network-15b2925f3171?source=collection_archive---------3-----------------------#2022-12-21</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="fc93" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">在本教程中，我们将探讨如何通过神经网络模型使用张量流和CTC损失从图像中识别文本。</h2></div><figure class="ki kj kk kl gt km"><div class="bz fp l di"><div class="kn ko l"/></div></figure><p id="ed2c" class="pw-post-body-paragraph kp kq it kr b ks kt ju ku kv kw jx kx ky kz la lb lc ld le lf lg lh li lj lk im bi translated"><strong class="kr iu">您见过的最先进的数据科学路线图！附带数以千计的免费学习资源和ChatGPT集成！</strong><a class="ae ll" href="https://87v9.short.gy/K93jZA" rel="noopener ugc nofollow" target="_blank"><strong class="kr iu"/></a></p><p id="a8dd" class="pw-post-body-paragraph kp kq it kr b ks kt ju ku kv kw jx kx ky kz la lb lc ld le lf lg lh li lj lk im bi translated">如果您读过这篇文章，您应该知道从图像中提取文本是一个复杂的问题。从图像中提取不同大小、形状和方向的文本是许多环境中的基本问题，特别是在增强现实辅助系统、电子商务和社交媒体平台上的内容审核中。为了解决这个问题，我们需要准确地从图像中提取文本。</p><p id="2d58" class="pw-post-body-paragraph kp kq it kr b ks kt ju ku kv kw jx kx ky kz la lb lc ld le lf lg lh li lj lk im bi translated">有两种最流行的方法可以用来从图像中提取文本:</p><ul class=""><li id="f736" class="lm ln it kr b ks kt kv kw ky lo lc lp lg lq lk lr ls lt lu bi translated">我们可以使用文本检测器或分割技术定位图像中的文本，然后提取定位的文本(更简单的方法)；</li><li id="311a" class="lm ln it kr b ks lv kv lw ky lx lc ly lg lz lk lr ls lt lu bi translated">我们可以训练一个在单个模型中实现文本检测和识别的模型(硬方法)；</li></ul><p id="2ca4" class="pw-post-body-paragraph kp kq it kr b ks kt ju ku kv kw jx kx ky kz la lb lc ld le lf lg lh li lj lk im bi translated">在本教程中，我将只关注整个OCR流程中的单词提取部分:</p><figure class="ki kj kk kl gt km gh gi paragraph-image"><div class="ab gu cl ma"><img src="../Images/4a2a4eab73744c725de1548478444049.png" data-original-src="https://miro.medium.com/v2/format:webp/1*6m0RzueUBP96YK-d2YxLXA.png"/></div><figcaption class="md me gj gh gi mf mg bd b be z dk translated">作者图片，OCR管道</figcaption></figure><p id="2902" class="pw-post-body-paragraph kp kq it kr b ks kt ju ku kv kw jx kx ky kz la lb lc ld le lf lg lh li lj lk im bi translated">但是，了解当今最流行的ocr的管道是有价值的。正如我所说的，大多数管道包含一个文本检测步骤和文本识别步骤:</p><ul class=""><li id="3be0" class="lm ln it kr b ks kt kv kw ky lo lc lp lg lq lk lr ls lt lu bi translated"><strong class="kr iu">文本检测</strong>帮助您识别包含文本的图像的位置。它接受一幅图像作为输入，给出带有坐标的盒子作为输出；</li><li id="4f2c" class="lm ln it kr b ks lv kv lw ky lx lc ly lg lz lk lr ls lt lu bi translated"><strong class="kr iu">文本识别</strong>使用从文本检测模型导出的边界框从输入图像中提取文本。它使用来自检测器的边界框输入带有裁剪图像部分的图像，并输出原始文本。</li></ul><p id="4cb1" class="pw-post-body-paragraph kp kq it kr b ks kt ju ku kv kw jx kx ky kz la lb lc ld le lf lg lh li lj lk im bi translated">文本检测非常类似于对象检测任务，其中需要检测的对象只是文本。在这一领域已经进行了大量的研究来准确地从图像中检测文本，并且许多检测器在单词级别检测文本。然而，单词级检测器的问题是它们不能检测任意形状的单词(旋转、弯曲、拉伸等)。).</p><p id="827d" class="pw-post-body-paragraph kp kq it kr b ks kt ju ku kv kw jx kx ky kz la lb lc ld le lf lg lh li lj lk im bi translated">但事实证明，我们可以通过使用各种分割技术而不是使用检测器来获得更好的结果。探索每个字符和字符之间的间距有助于检测各种形状的文本。[ <a class="ae ll" href="https://openaccess.thecvf.com/content_CVPR_2019/papers/Baek_Character_Region_Awareness_for_Text_Detection_CVPR_2019_paper.pdf" rel="noopener ugc nofollow" target="_blank"> 1 </a></p><p id="7734" class="pw-post-body-paragraph kp kq it kr b ks kt ju ku kv kw jx kx ky kz la lb lc ld le lf lg lh li lj lk im bi translated">对于文本检测，您可以选择其他流行的技术。但是，正如我已经提到的，这将是太复杂和广泛的教程，以涵盖两者。因此，我将着重解释文本识别的CTC网络。</p><p id="4555" class="pw-post-body-paragraph kp kq it kr b ks kt ju ku kv kw jx kx ky kz la lb lc ld le lf lg lh li lj lk im bi translated">我注意到在开发各种东西时，我必须重新实现我已经反复使用的东西。那么为什么不通过创建一个库来保存所有这些东西来简化它呢？有了这个教程，我将开始一个新的MLTU(机器学习训练实用程序)库，我将在<a class="ae ll" href="https://github.com/pythonlessons/mltu" rel="noopener ugc nofollow" target="_blank"> GitHub </a>上开源，在那里我将保存所有的教程代码。</p><h2 id="adbb" class="mh mi it bd mj mk ml dn mm mn mo dp mp ky mq mr ms lc mt mu mv lg mw mx my mz bi translated">文本识别管道:</h2><figure class="ki kj kk kl gt km gh gi paragraph-image"><div class="ab gu cl ma"><img src="../Images/226093add9860f3b285fd1c67ce866d6.png" data-original-src="https://miro.medium.com/v2/format:webp/1*vBMj5wcbtcE1kX3pp27tbA.png"/></div><figcaption class="md me gj gh gi mf mg bd b be z dk translated">图片由作者，文字识别与CNN+MSTM网络和CTC损失</figcaption></figure><p id="af2f" class="pw-post-body-paragraph kp kq it kr b ks kt ju ku kv kw jx kx ky kz la lb lc ld le lf lg lh li lj lk im bi translated">在文本定位步骤之后，包含文本的区域被裁剪并通过CNN层发送以提取图像特征。这些特征后来被输入到多对多LSTM架构中，该架构通过字典输出softmax概率。这些不同时间步长的输出被提供给CTC解码器，以从图像中获得原始文本。我将在本教程的以下部分详细介绍每个步骤。</p><p id="98ef" class="pw-post-body-paragraph kp kq it kr b ks kt ju ku kv kw jx kx ky kz la lb lc ld le lf lg lh li lj lk im bi translated">首先，让我们看看我的张量流模型，以了解我们如何连接CNN层和LSTM层。这个教程不是初级的，所以我只会循序渐进的覆盖一些部分，这里只贴一部分代码，更深入的代码部分，你可以看看我的<a class="ae ll" href="https://github.com/pythonlessons/mltu" rel="noopener ugc nofollow" target="_blank"> <strong class="kr iu"> GitHub </strong> </a>资源库。</p><p id="4058" class="pw-post-body-paragraph kp kq it kr b ks kt ju ku kv kw jx kx ky kz la lb lc ld le lf lg lh li lj lk im bi translated">本教程的文件可以在<a class="ae ll" href="https://github.com/pythonlessons/mltu/tree/main/Tutorials/01_image_to_word" rel="noopener ugc nofollow" target="_blank">https://github . com/python lessons/mltu/tree/main/Tutorials/01 _ image _ to _ word</a>链接上找到。要运行本教程，您必须安装我的带有pip的“mltu”0 . 1 . 3版本包:</p><p id="9999" class="pw-post-body-paragraph kp kq it kr b ks kt ju ku kv kw jx kx ky kz la lb lc ld le lf lg lh li lj lk im bi translated"><code class="fe na nb nc nd b">pip install mltu==0.1.3</code></p><p id="d595" class="pw-post-body-paragraph kp kq it kr b ks kt ju ku kv kw jx kx ky kz la lb lc ld le lf lg lh li lj lk im bi translated">以下是在TensorFlow中构建模型的代码:</p><figure class="ki kj kk kl gt km"><div class="bz fp l di"><div class="ne ko l"/></div></figure><p id="9c36" class="pw-post-body-paragraph kp kq it kr b ks kt ju ku kv kw jx kx ky kz la lb lc ld le lf lg lh li lj lk im bi translated">我使用ResNet模型中的一个原理来构建残差块，帮助我们的模型学习更好的细节。我会将所有输入图像的大小调整为32×128像素。有了这个大小，我们的模型摘要将如下所示:</p><figure class="ki kj kk kl gt km"><div class="bz fp l di"><div class="ne ko l"/></div></figure><p id="623f" class="pw-post-body-paragraph kp kq it kr b ks kt ju ku kv kw jx kx ky kz la lb lc ld le lf lg lh li lj lk im bi translated">如果您不熟悉TensorFlow，这可能会为您提供有限的信息，但这里的想法是为我们的CTC损失函数创建一个具有正确输出的模型。为此，我们必须从CNN过渡到LSTM层。为了做到这一点，我使用了一个重塑CNN最后一层删除一个维度，这将是伟大的LSTM输入。</p><p id="093a" class="pw-post-body-paragraph kp kq it kr b ks kt ju ku kv kw jx kx ky kz la lb lc ld le lf lg lh li lj lk im bi translated">为了使一切正常，我们必须确保最后一层满足CTC损失函数的要求。这里我有63个。在我的单词数据集中，我知道我有62个不同的字符，但是我们需要将它递增1(分隔标记)。我也有256；正如您在这里看到的，我们必须确保这个值大于我们的数据集中的最大单词长度，在我的数据集中是23。在我们的预测中，这一个将被视为间隔；稍后详细介绍。</p><p id="2e05" class="pw-post-body-paragraph kp kq it kr b ks kt ju ku kv kw jx kx ky kz la lb lc ld le lf lg lh li lj lk im bi translated">首先，让我们理解感受野的概念，以便更容易理解CNN模型的特征是如何转移到LSTM网络的。</p><h2 id="4129" class="mh mi it bd mj mk ml dn mm mn mo dp mp ky mq mr ms lc mt mu mv lg mw mx my mz bi translated">CNN特写到LSTM图层:</h2><figure class="ki kj kk kl gt km gh gi paragraph-image"><div class="ab gu cl ma"><img src="../Images/0254d1c2e91e2899a6531c147aa67dbd.png" data-original-src="https://miro.medium.com/v2/format:webp/1*5_1OnGSEBfXquy5UMSzjCw.png"/></div></figure><p id="3775" class="pw-post-body-paragraph kp kq it kr b ks kt ju ku kv kw jx kx ky kz la lb lc ld le lf lg lh li lj lk im bi translated">上图显示了一个图像(32x128大小)通过卷积层发送。层被设计成使得，结果，我们获得形状的特征图(无，8，32，64)。这里的“无”是可以取任何值的批量大小。</p><p id="5912" class="pw-post-body-paragraph kp kq it kr b ks kt ju ku kv kw jx kx ky kz la lb lc ld le lf lg lh li lj lk im bi translated">(None，8，32，64)可以很容易地整形为(None，256，64)，256对应的是时间步长的个数，64不过是每个时间步长的特征个数。人们可以将这与训练具有单词嵌入的任何LSTM模型联系起来，并且输入形状通常是(batch_size，no_time_steps，word_embedding_dimension)。</p><figure class="ki kj kk kl gt km gh gi paragraph-image"><div class="ab gu cl ma"><img src="../Images/f8dd666d20a690309db70684c8232690.png" data-original-src="https://miro.medium.com/v2/format:webp/1*sDtK-aIMqoMdHyxZpqUXwQ.png"/></div></figure><p id="77b2" class="pw-post-body-paragraph kp kq it kr b ks kt ju ku kv kw jx kx ky kz la lb lc ld le lf lg lh li lj lk im bi translated">之后，这些特征图被输入到LSTM模型中，如上图所示。您现在可能会想，众所周知，LSTM模型处理的是序列数据，而要素地图是如何排序的。但这里的想法是，CNN层重塑序列，同时改变其层的视图。</p><p id="66c1" class="pw-post-body-paragraph kp kq it kr b ks kt ju ku kv kw jx kx ky kz la lb lc ld le lf lg lh li lj lk im bi translated">结果，对于每个时间步长，我们从LSTM模型获得词汇的软最大概率，即256。现在，让我们转到教程中激动人心的部分，计算这种架构设置的损耗值。</p><h2 id="d900" class="mh mi it bd mj mk ml dn mm mn mo dp mp ky mq mr ms lc mt mu mv lg mw mx my mz bi translated">什么是CTC损失，我们为什么要使用它:</h2><p id="675e" class="pw-post-body-paragraph kp kq it kr b ks nf ju ku kv ng jx kx ky nh la lb lc ni le lf lg nj li lj lk im bi translated">这是一个广泛的主题，我可以为它创建另一个完整的解释教程。但是因为已经有大量关于CTC损失的文章，我将只提及整个想法。</p><p id="bc22" class="pw-post-body-paragraph kp kq it kr b ks kt ju ku kv kw jx kx ky kz la lb lc ld le lf lg lh li lj lk im bi translated">当然，我们可以创建一个包含文本字符串图像的数据集，然后为每个水平图像位置指定相应的符号。我们可以使用分类交叉熵作为损失来训练NN输出每个水平位置的字符得分。然而，这种解决方案存在一些问题:</p><ul class=""><li id="b754" class="lm ln it kr b ks kt kv kw ky lo lc lp lg lq lk lr ls lt lu bi translated">在字符级别注释一个数据集是非常耗时(并且乏味)的；</li><li id="580e" class="lm ln it kr b ks lv kv lw ky lx lc ly lg lz lk lr ls lt lu bi translated">我们只得到字符分数，需要进一步处理才能得到最终文本。我们需要删除所有重复的字符。单个符号可以跨越多个水平位置；例如，我们可以得到“Heeloo”，因为“e”或“e”是宽的。但是如果被识别的文本是“好”的呢？那么去掉所有重复的“0”会给我们一个不正确的结果。怎么处理？</li><li id="9d1e" class="lm ln it kr b ks lv kv lw ky lx lc ly lg lz lk lr ls lt lu bi translated">提到的CTC损失也适用于语音到文本的应用。音频信号和相应的文本可用作训练数据，并且不存在像第一个字符被朗读“x”毫秒或从“x1”到“x2”毫秒朗读字符“z”这样的映射。按时间顺序注释每个角色的发音单词是不可能的。</li></ul><p id="fdf2" class="pw-post-body-paragraph kp kq it kr b ks kt ju ku kv kw jx kx ky kz la lb lc ld le lf lg lh li lj lk im bi translated">CTC为我们解决了所有这些问题:</p><ol class=""><li id="e53a" class="lm ln it kr b ks kt kv kw ky lo lc lp lg lq lk nk ls lt lu bi translated">在用CTC损失函数训练模型时，我们只需要知道图像中的确切单词。因此，我们忽略图像或音频频谱图中符号的位置和宽度；</li><li id="a796" class="lm ln it kr b ks lv kv lw ky lx lc ly lg lz lk nk ls lt lu bi translated">识别的文本不需要进一步处理。</li></ol><p id="12bf" class="pw-post-body-paragraph kp kq it kr b ks kt ju ku kv kw jx kx ky kz la lb lc ld le lf lg lh li lj lk im bi translated">为了区分两个连续的标记和重复的标记，我们使用了一个“分离”标记，我之前已经提到过。理解其工作原理的最佳方式是想象我们正在处理表示“家”这个词的声音数据:</p><figure class="ki kj kk kl gt km gh gi paragraph-image"><div class="ab gu cl ma"><img src="../Images/6aabcd94000c2cf14d1513a746a7e004.png" data-original-src="https://miro.medium.com/v2/format:webp/1*bLf6WH9zftnz5-D1WfkktQ.png"/></div><figcaption class="md me gj gh gi mf mg bd b be z dk translated">图片作者，字“好”解码有CTC丢失</figcaption></figure><p id="e78a" class="pw-post-body-paragraph kp kq it kr b ks kt ju ku kv kw jx kx ky kz la lb lc ld le lf lg lh li lj lk im bi translated">我们使用一种巧妙的编码方案来解决重复字符的问题。在对文本进行编码时，我们可以在任何地方插入任意数量的空白，解码时这些空白将被删除。此外，我们可以多次重复每个字符。但是，我们需要在重复的符号之间插入一个空格，比如“你好”。</p><p id="b7ba" class="pw-post-body-paragraph kp kq it kr b ks kt ju ku kv kw jx kx ky kz la lb lc ld le lf lg lh li lj lk im bi translated">我们可以举几个例子:</p><ul class=""><li id="345d" class="lm ln it kr b ks kt kv kw ky lo lc lp lg lq lk lr ls lt lu bi translated">从word Home→“H-o-m-e”“H-ooo-m-ee”“-HHHHHHo-m-e”等。；</li><li id="799b" class="lm ln it kr b ks lv kv lw ky lx lc ly lg lz lk lr ls lt lu bi translated">从word Good→“G-o-o-d”、“GGGo-od”、“G-oooo-oooo-dddd”等。；</li></ul><p id="0a32" class="pw-post-body-paragraph kp kq it kr b ks kt ju ku kv kw jx kx ky kz la lb lc ld le lf lg lh li lj lk im bi translated">正如您所看到的，这种技术还允许我们轻松地创建精确文本的不同对齐方式，例如，“H-o-m-e”、“H-ooo-m-ee”、“HHHHHHo-m-e”都代表实际的文本(Home)，但对图像有不同的对齐方式。神经网络已经被训练输出加扰文本(在NN softmax输出中编码)。</p><p id="c1d3" class="pw-post-body-paragraph kp kq it kr b ks kt ju ku kv kw jx kx ky kz la lb lc ld le lf lg lh li lj lk im bi translated">一旦我们有了一个经过训练的神经网络，我们通常希望用它来识别我们的模型从未见过的图像中的文本。一种简单且非常快速的算法是“最佳路径解码”，包括两个步骤:</p><ol class=""><li id="10b9" class="lm ln it kr b ks kt kv kw ky lo lc lp lg lq lk nk ls lt lu bi translated">它根据每个时间步长最可能的符号计算最佳路径；</li><li id="3c59" class="lm ln it kr b ks lv kv lw ky lx lc ly lg lz lk nk ls lt lu bi translated">它通过删除路径中的重复字符和所有空格来撤消编码。剩下的代表已识别的文本！</li></ol><p id="5160" class="pw-post-body-paragraph kp kq it kr b ks kt ju ku kv kw jx kx ky kz la lb lc ld le lf lg lh li lj lk im bi translated">这是一个简短的关于CTC损失没有进入数学的封面，但如果你有兴趣了解和研究数学是如何工作的，我发现了<a class="ae ll" href="https://ogunlao.github.io/blog/2020/07/17/breaking-down-ctc-loss.html" rel="noopener ugc nofollow" target="_blank">这篇很棒的文章</a>一步一步地解释了它。</p><h2 id="8ea5" class="mh mi it bd mj mk ml dn mm mn mo dp mp ky mq mr ms lc mt mu mv lg mw mx my mz bi translated">CTC损失代码:</h2><p id="3504" class="pw-post-body-paragraph kp kq it kr b ks nf ju ku kv ng jx kx ky nh la lb lc ni le lf lg nj li lj lk im bi translated">让我们回到编码部分。我只会编写一些之前提到的数学计算的代码。我们可以使用“<code class="fe na nb nc nd b">keras.backend.ctc_batch_cost</code>”函数来计算CTC损失，下面是定义了自定义CTC层的相同代码，用于训练和评估部分。要将它用作损失函数，我们需要构造一个继承对象来实现:</p><figure class="ki kj kk kl gt km"><div class="bz fp l di"><div class="ne ko l"/></div></figure><p id="8467" class="pw-post-body-paragraph kp kq it kr b ks kt ju ku kv kw jx kx ky kz la lb lc ld le lf lg lh li lj lk im bi translated">现在，当我们构建和编译我们的模型时，我们将其用作常规损失函数:</p><figure class="ki kj kk kl gt km"><div class="bz fp l di"><div class="ne ko l"/></div></figure><p id="e0d2" class="pw-post-body-paragraph kp kq it kr b ks kt ju ku kv kw jx kx ky kz la lb lc ld le lf lg lh li lj lk im bi translated">就是这样；我们的模型已经准备好接受图像和注释，并接受训练。但是你可能注意到我使用了一些CWER指标。没错！在训练单词、语音和句子识别模型时，仅仅依靠验证损失不是一个好的做法。知道我们的模型在验证数据集中犯了多少错误更好。这样，我们将能够增强我们的模型架构以获得更好的结果。</p><p id="cc53" class="pw-post-body-paragraph kp kq it kr b ks kt ju ku kv kw jx kx ky kz la lb lc ld le lf lg lh li lj lk im bi translated">为了不浪费我们的资源，我将它实现为一个TensorFlow度量，在它训练时运行。</p><p id="4be3" class="pw-post-body-paragraph kp kq it kr b ks kt ju ku kv kw jx kx ky kz la lb lc ld le lf lg lh li lj lk im bi translated">字符错误率(CER)衡量转录或翻译的准确性，通常用于语音识别或自然语言处理。它将基本事实转录或翻译(正确版本)与系统产生的实际转录或翻译进行比较，并计算输出中的错误百分比。</p><p id="e912" class="pw-post-body-paragraph kp kq it kr b ks kt ju ku kv kw jx kx ky kz la lb lc ld le lf lg lh li lj lk im bi translated">为了计算CER，我们首先计算地面真相转录或翻译中的字符总数，包括空格。然后，我们计算将输出转录或翻译转换为基本事实所需的字符插入、替换和删除的数量。然后，CER计算为这些误差的总和除以字符总数，以百分比表示。</p><p id="0104" class="pw-post-body-paragraph kp kq it kr b ks kt ju ku kv kw jx kx ky kz la lb lc ld le lf lg lh li lj lk im bi translated">换句话说，CER测量输出转录或翻译中相对于基本事实中字符总数的错误数量。它会考虑拼写或语法错误，但也会考虑缺少或多余的空格、大写错误和其他轻微的转录不匹配。</p><p id="4772" class="pw-post-body-paragraph kp kq it kr b ks kt ju ku kv kw jx kx ky kz la lb lc ld le lf lg lh li lj lk im bi translated">例如，假设我们有下面的基本事实转录:“这是一个测试句子。”</p><p id="6fa8" class="pw-post-body-paragraph kp kq it kr b ks kt ju ku kv kw jx kx ky kz la lb lc ld le lf lg lh li lj lk im bi translated">假设我们有以下由语音识别系统产生的输出转录:“这是一个测试句子。”</p><p id="7d8f" class="pw-post-body-paragraph kp kq it kr b ks kt ju ku kv kw jx kx ky kz la lb lc ld le lf lg lh li lj lk im bi translated">在这种情况下，输出转录与地面实况相同，因此没有错误。CER将为0%。</p><p id="64c9" class="pw-post-body-paragraph kp kq it kr b ks kt ju ku kv kw jx kx ky kz la lb lc ld le lf lg lh li lj lk im bi translated">另一方面，如果我们有以下输出转录:“这是一个测试句子。”</p><p id="a992" class="pw-post-body-paragraph kp kq it kr b ks kt ju ku kv kw jx kx ky kz la lb lc ld le lf lg lh li lj lk im bi translated">有一个单字符错误(句尾多了一个“e”)，所以CER就是1/23 = 4.3%。</p><h2 id="ef11" class="mh mi it bd mj mk ml dn mm mn mo dp mp ky mq mr ms lc mt mu mv lg mw mx my mz bi translated">培训回访:</h2><p id="8744" class="pw-post-body-paragraph kp kq it kr b ks nf ju ku kv ng jx kx ky nh la lb lc ni le lf lg nj li lj lk im bi translated">你可能已经注意到我在GitHub的代码中使用了几个回调函数。回调是在培训过程的特定阶段实现的功能组。这些回调允许您在训练期间观察模型的统计数据和内部状态。</p><p id="ba04" class="pw-post-body-paragraph kp kq it kr b ks kt ju ku kv kw jx kx ky kz la lb lc ld le lf lg lh li lj lk im bi translated">我倾向于在几乎所有的可训练模型中使用回调。"</p><figure class="ki kj kk kl gt km"><div class="bz fp l di"><div class="ne ko l"/></div></figure><p id="5374" class="pw-post-body-paragraph kp kq it kr b ks kt ju ku kv kw jx kx ky kz la lb lc ld le lf lg lh li lj lk im bi translated">我们可以数出六种不同的回调来说明问题，正如你可能看到的，我没有跟踪验证损失，而是跟踪验证CER(“瓦尔_CER”)！</p><p id="bf8f" class="pw-post-body-paragraph kp kq it kr b ks kt ju ku kv kw jx kx ky kz la lb lc ld le lf lg lh li lj lk im bi translated">我们大多数人训练这些模型部署在我们不想使用TensorFlow的地方。因此，我创建了一个“Model2onxx”回调，在培训结束时，它将模型转换为。onnx格式，没有这个庞大的TensorFlow库也可以用，而且通常情况下，运行速度快两倍！</p><h2 id="8767" class="mh mi it bd mj mk ml dn mm mn mo dp mp ky mq mr ms lc mt mu mv lg mw mx my mz bi translated">准备数据集:</h2><p id="7347" class="pw-post-body-paragraph kp kq it kr b ks nf ju ku kv ng jx kx ky nh la lb lc ni le lf lg nj li lj lk im bi translated">这是另一个广泛的话题，我将通过仅提及最基本的方面来快速涵盖。因此，在本教程中，我们将创建一个模型来从简单的文本图像中识别文本。我发现了一个巨大的“<a class="ae ll" href="https://www.robots.ox.ac.uk/~vgg/data/text/#sec-synth" rel="noopener ugc nofollow" target="_blank">文本识别数据</a>数据库，让我们这样做。</p><figure class="ki kj kk kl gt km gh gi paragraph-image"><div class="ab gu cl ma"><img src="../Images/4c46b30d00deda9fc38d5c7940fd7b2d.png" data-original-src="https://miro.medium.com/v2/format:webp/1*aBH5LQ5q51PXnUNtmX7vPw.png"/></div><figcaption class="md me gj gh gi mf mg bd b be z dk translated">按作者分类的图像:数据集中的示例图像</figcaption></figure><p id="e8b2" class="pw-post-body-paragraph kp kq it kr b ks kt ju ku kv kw jx kx ky kz la lb lc ld le lf lg lh li lj lk im bi translated">这个数据集由<strong class="kr iu">900万张图像</strong>组成，覆盖<strong class="kr iu"> 90k个英语单词</strong>，包括我们工作中使用的训练、验证和测试分割。</p><p id="603c" class="pw-post-body-paragraph kp kq it kr b ks kt ju ku kv kw jx kx ky kz la lb lc ld le lf lg lh li lj lk im bi translated">如果您正在学习我的教程，请下载这个10 GB的数据集，并将其解压缩到“<strong class="kr iu"> Datasets/90kDICT32px </strong>”文件夹中。</p><p id="e956" class="pw-post-body-paragraph kp kq it kr b ks kt ju ku kv kw jx kx ky kz la lb lc ld le lf lg lh li lj lk im bi translated">使用下面的代码，我们将读取训练和验证数据集的所有路径:</p><figure class="ki kj kk kl gt km"><div class="bz fp l di"><div class="ne ko l"/></div></figure><p id="a5a8" class="pw-post-body-paragraph kp kq it kr b ks kt ju ku kv kw jx kx ky kz la lb lc ld le lf lg lh li lj lk im bi translated">这是一个简单的for循环，在每次循环中，读取文件路径并提取单词的实际标签。此外，我们正在收集词汇和尽可能长的单词。这两个参数稍后用于为我们的任务构建一个合适的模型。</p><p id="d5f5" class="pw-post-body-paragraph kp kq it kr b ks kt ju ku kv kw jx kx ky kz la lb lc ld le lf lg lh li lj lk im bi translated">好了，接下来，我们将使用我的“mltu”包中的基本DataProvider模型来构造我们的训练和验证数据提供者:</p><figure class="ki kj kk kl gt km"><div class="bz fp l di"><div class="ne ko l"/></div></figure><p id="b178" class="pw-post-body-paragraph kp kq it kr b ks kt ju ku kv kw jx kx ky kz la lb lc ld le lf lg lh li lj lk im bi translated">我创建这个对象是为了使用不同的数据预处理程序、增强器或转换器为任何数据类型提供数据。</p><p id="10c8" class="pw-post-body-paragraph kp kq it kr b ks kt ju ku kv kw jx kx ky kz la lb lc ld le lf lg lh li lj lk im bi translated">特别是对于一个图像到文本的任务，我使用一个简单的OpenCV“ImageReader”预处理器。然后我用变形金刚来规范我们的形象和标签；首先，我们将所有图像调整到相同的大小。接下来，我们将字符串标签转换为索引，因为我们的模型不理解字符串；它必须是数值。最后一步，我们用未知值填充单词，这样我们的输入就能满足精确的形状要求。</p><h2 id="fdf7" class="mh mi it bd mj mk ml dn mm mn mo dp mp ky mq mr ms lc mt mu mv lg mw mx my mz bi translated">训练模型:</h2><p id="f358" class="pw-post-body-paragraph kp kq it kr b ks nf ju ku kv ng jx kx ky nh la lb lc ni le lf lg nj li lj lk im bi translated">我们到了最终训练模型的时候了。因为在我的1080TI GPU上完成一个纪元都需要一个多小时，所以我没有展示整个训练过程。但是因为我们很棒的回调，我们可以查看我们的训练日志和Tensorboard日志。</p><p id="78b1" class="pw-post-body-paragraph kp kq it kr b ks kt ju ku kv kw jx kx ky kz la lb lc ld le lf lg lh li lj lk im bi translated">这是我们用来创建模式、编译它、定义回调和启动模型训练过程的代码:</p><figure class="ki kj kk kl gt km"><div class="bz fp l di"><div class="ne ko l"/></div></figure><p id="ac09" class="pw-post-body-paragraph kp kq it kr b ks kt ju ku kv kw jx kx ky kz la lb lc ld le lf lg lh li lj lk im bi translated">现在，我可以通过在终端中发出以下命令来打开Tensorboard仪表板，其中包含我训练的模型日志的路径:</p><p id="3925" class="pw-post-body-paragraph kp kq it kr b ks kt ju ku kv kw jx kx ky kz la lb lc ld le lf lg lh li lj lk im bi translated"><code class="fe na nb nc nd b">tensorboard --logdir Models/1_image_to_word/202211270035/logs</code></p><p id="c5ee" class="pw-post-body-paragraph kp kq it kr b ks kt ju ku kv kw jx kx ky kz la lb lc ld le lf lg lh li lj lk im bi translated">因为我们的数据集很大，它在第一个时期学习的大多数东西，所以当它完成第一个训练时期时，我们的CER会给我们很好的结果:</p><figure class="ki kj kk kl gt km gh gi paragraph-image"><div class="ab gu cl ma"><img src="../Images/f2b17986a09afc72468f5ee5882355a1.png" data-original-src="https://miro.medium.com/v2/format:webp/1*k1lgmKf4FBYIlmrd-yBJrQ.png"/></div><figcaption class="md me gj gh gi mf mg bd b be z dk translated">图片由作者提供:每个时期的张量板字符错误率</figcaption></figure><p id="2cec" class="pw-post-body-paragraph kp kq it kr b ks kt ju ku kv kw jx kx ky kz la lb lc ld le lf lg lh li lj lk im bi translated">正如我们所看到的，在每一个时代，我们的CER率都在下降。这就是我们所期待的！</p><p id="ad9d" class="pw-post-body-paragraph kp kq it kr b ks kt ju ku kv kw jx kx ky kz la lb lc ld le lf lg lh li lj lk im bi translated">当我们的训练过程结束时，保存了两个模型:默认的. h5 Keras模型和。onnx格式模型。因此，让我们对保存的模型进行推理。</p><h2 id="0ac6" class="mh mi it bd mj mk ml dn mm mn mo dp mp ky mq mr ms lc mt mu mv lg mw mx my mz bi translated">测试模型:</h2><p id="4675" class="pw-post-body-paragraph kp kq it kr b ks nf ju ku kv ng jx kx ky nh la lb lc ni le lf lg nj li lj lk im bi translated">现在，每个人都知道如何在默认的“. H5”Keras模型上运行推理，但通常，当我们想在某个地方部署我们的解决方案时，这不是最佳选择。这就是我将模型转换为。onnx格式。这是一种轻量级的模型格式，通常速度更快，并且不需要安装庞大的库。</p><p id="d186" class="pw-post-body-paragraph kp kq it kr b ks kt ju ku kv kw jx kx ky kz la lb lc ld le lf lg lh li lj lk im bi translated">首先，我将创建一个对象来加载。onnx "模型并处理所有的数据预处理和后处理。为此，我的对象从“OnnxInferenceModel”对象继承:</p><figure class="ki kj kk kl gt km"><div class="bz fp l di"><div class="ne ko l"/></div></figure><p id="7ec7" class="pw-post-body-paragraph kp kq it kr b ks kt ju ku kv kw jx kx ky kz la lb lc ld le lf lg lh li lj lk im bi translated">在创建对象时，我们唯一需要传递给ImageToWordModel的是词汇表。这就是为什么在训练模型时序列化和保存配置很重要。</p><p id="3aaa" class="pw-post-body-paragraph kp kq it kr b ks kt ju ku kv kw jx kx ky kz la lb lc ld le lf lg lh li lj lk im bi translated">现在，让我们编写一段代码，对验证数据集中的每幅图像进行推理，并检查字符错误率是多少:</p><figure class="ki kj kk kl gt km"><div class="bz fp l di"><div class="ne ko l"/></div></figure><p id="9f2e" class="pw-post-body-paragraph kp kq it kr b ks kt ju ku kv kw jx kx ky kz la lb lc ld le lf lg lh li lj lk im bi translated">我可以运行1000个例子，我会收到以下结果:</p><p id="e9bb" class="pw-post-body-paragraph kp kq it kr b ks kt ju ku kv kw jx kx ky kz la lb lc ld le lf lg lh li lj lk im bi translated"><code class="fe na nb nc nd b">Average CER: 0.07760155677655678</code></p><p id="cd37" class="pw-post-body-paragraph kp kq it kr b ks kt ju ku kv kw jx kx ky kz la lb lc ld le lf lg lh li lj lk im bi translated">这意味着在1000个例子中，我的模型有7%的CER；这很好，知道我们的训练和验证数据集可以更好！</p><p id="6306" class="pw-post-body-paragraph kp kq it kr b ks kt ju ku kv kw jx kx ky kz la lb lc ld le lf lg lh li lj lk im bi translated">这里有几个例子:</p><figure class="ki kj kk kl gt km gh gi paragraph-image"><div class="ab gu cl ma"><img src="../Images/fb8877545cf642508f31378b3b3dd6b3.png" data-original-src="https://miro.medium.com/v2/format:webp/1*C8qoY5PDkFXIeiim_IkA2Q.png"/></div></figure><p id="f147" class="pw-post-body-paragraph kp kq it kr b ks kt ju ku kv kw jx kx ky kz la lb lc ld le lf lg lh li lj lk im bi translated">我在这里只展示了几个例子。你可以用更多的例子来验证这一点。</p><h1 id="77e8" class="nl mi it bd mj nm nn no mm np nq nr mp jz ns ka ms kc nt kd mv kf nu kg my nv bi translated">结论:</h1><p id="992f" class="pw-post-body-paragraph kp kq it kr b ks nf ju ku kv ng jx kx ky nh la lb lc ni le lf lg nj li lj lk im bi translated">总之，从图像中提取文本是一个复杂的问题，在各种背景下都很重要，包括增强现实、电子商务和内容审核。从图像中提取文本有两种主要方法:使用文本检测器或分割技术来定位文本，以及训练执行文本检测和识别的单个模型。本教程侧重于后一种方法，将CNN和LSTM层与CTC损失函数相结合，从图像中提取文本。该教程还介绍了一个新的开源库，名为MLTU(机器学习训练实用程序)，将用于存储未来教程中的代码。</p><p id="11ca" class="pw-post-body-paragraph kp kq it kr b ks kt ju ku kv kw jx kx ky kz la lb lc ld le lf lg lh li lj lk im bi translated">在本教程中，我尽量简短，只解释最重要的部分。更深入地说，它可以扩展成几个不同的教程，但我仍然需要做更多的工作。在本教程的最后，我们终于有了一个可以从图像中识别文本的自定义OCR模型。</p><p id="3825" class="pw-post-body-paragraph kp kq it kr b ks kt ju ku kv kw jx kx ky kz la lb lc ld le lf lg lh li lj lk im bi translated">这是我的教程系列的第一部分，在这里我们学习了如何训练我们的自定义OCR来识别图像中的文本。从现在开始，我们可以转向其他更具挑战性的任务。</p><p id="40cc" class="pw-post-body-paragraph kp kq it kr b ks kt ju ku kv kw jx kx ky kz la lb lc ld le lf lg lh li lj lk im bi translated">我希望这篇教程对你有帮助，你可以在你的项目中使用我的代码，甚至我的新“mltu”库。下期教程再见！</p><p id="8f53" class="pw-post-body-paragraph kp kq it kr b ks kt ju ku kv kw jx kx ky kz la lb lc ld le lf lg lh li lj lk im bi translated">我训练的模型<a class="ae ll" href="https://drive.google.com/drive/folders/180mJBpSNfeLCTZ2OuBZnLNxl2i0_LcEr?usp=share_link" rel="noopener ugc nofollow" target="_blank">可以从这个链接</a>下载(放在Models文件夹中)。玩得开心！</p><h2 id="9bde" class="mh mi it bd mj mk ml dn mm mn mo dp mp ky mq mr ms lc mt mu mv lg mw mx my mz bi translated">参考:</h2><p id="9433" class="pw-post-body-paragraph kp kq it kr b ks nf ju ku kv ng jx kx ky nh la lb lc ni le lf lg nj li lj lk im bi translated">[1] <a class="ae ll" href="https://openaccess.thecvf.com/content_CVPR_2019/papers/Baek_Character_Region_Awareness_for_Text_Detection_CVPR_2019_paper.pdf" rel="noopener ugc nofollow" target="_blank">白永明等，“用于文本检测的字符区域意识”IEEE/CVF计算机视觉和模式识别会议录。2019.</a></p></div><div class="ab cl nw nx hx ny" role="separator"><span class="nz bw bk oa ob oc"/><span class="nz bw bk oa ob oc"/><span class="nz bw bk oa ob"/></div><div class="im in io ip iq"><p id="ca31" class="pw-post-body-paragraph kp kq it kr b ks kt ju ku kv kw jx kx ky kz la lb lc ld le lf lg lh li lj lk im bi translated">【https://pylessons.com/ctc-text-recognition】原载于<a class="ae ll" href="https://pylessons.com/ctc-text-recognition" rel="noopener ugc nofollow" target="_blank"><em class="od"/></a></p></div></div>    
</body>
</html>