<html>
<head>
<title>Multi-Label Text Classification Using Scikit-multilearn: a Case Study with StackOverflow Questions</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">使用Scikit-multilearn的多标签文本分类:StackOverflow问题的案例研究</h1>
<blockquote>原文：<a href="https://pub.towardsai.net/multi-label-text-classification-using-scikit-multilearn-case-study-with-stackoverflow-questions-768cb487ad12?source=collection_archive---------0-----------------------#2019-06-30">https://pub.towardsai.net/multi-label-text-classification-using-scikit-multilearn-case-study-with-stackoverflow-questions-768cb487ad12?source=collection_archive---------0-----------------------#2019-06-30</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><h2 id="13d8" class="ir is it bd b dl iu iv iw ix iy iz dk ja translated" aria-label="kicker paragraph"><a class="ae ep" href="https://towardsai.net/p/category/machine-learning" rel="noopener ugc nofollow" target="_blank">机器学习</a></h2><div class=""/><div class=""><h2 id="c738" class="pw-subtitle-paragraph jz jc it bd b ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq dk translated">设计一个多标签文本分类模型，该模型有助于用不同主题标记stackoverflow.com问题</h2></div><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi kr"><img src="../Images/b7ed0416a7c707afb851a22ce8ea352e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*HTczjsfQiliG-hxyIK-I8A.jpeg"/></div></div></figure><p id="200e" class="pw-post-body-paragraph ld le it lf b lg lh kd li lj lk kg ll lm ln lo lp lq lr ls lt lu lv lw lx ly im bi translated">stackoverflow.com<strong class="lf jd">的日常用户发布了许多技术问题，这些问题都被贴上了不同主题的标签。在本文中，我们将讨论一个分类模型，它可以自动判断哪些标签可以附加到未回答的问题上。</strong></p><p id="fa65" class="pw-post-body-paragraph ld le it lf b lg lh kd li lj lk kg ll lm ln lo lp lq lr ls lt lu lv lw lx ly im bi translated">显然，一个问题可以关联多个标签。因此，最终这个问题变成了“对问题进行分类并给它贴上类别标签”。根据机器学习理论，这是一个“多标签分类”问题。</p><p id="32dd" class="pw-post-body-paragraph ld le it lf b lg lh kd li lj lk kg ll lm ln lo lp lq lr ls lt lu lv lw lx ly im bi translated">我们已经在下面的文章中讨论了多标签模型所需的不同理论技术和准确性度量。</p><div class="lz ma gp gr mb mc"><a href="https://medium.com/towards-artificial-intelligence/understanding-multi-label-classification-model-and-accuracy-metrics-1b2a8e2648ca" rel="noopener follow" target="_blank"><div class="md ab fo"><div class="me ab mf cl cj mg"><h2 class="bd jd gy z fp mh fr fs mi fu fw jc bi translated">了解多标签分类模型和准确性指标</h2><div class="mj l"><h3 class="bd b gy z fp mh fr fs mi fu fw dk translated">多标签/多标记模型背后的理论、不同的伞式分类方案和准确性度量分析</h3></div><div class="mk l"><p class="bd b dl z fp mh fr fs mi fu fw dk translated">medium.com</p></div></div><div class="ml l"><div class="mm l mn mo mp ml mq lb mc"/></div></div></a></div><p id="09a7" class="pw-post-body-paragraph ld le it lf b lg lh kd li lj lk kg ll lm ln lo lp lq lr ls lt lu lv lw lx ly im bi translated">以上是当前讨论的先决条件。在这篇文章之前，读者需要浏览一下。</p><p id="955f" class="pw-post-body-paragraph ld le it lf b lg lh kd li lj lk kg ll lm ln lo lp lq lr ls lt lu lv lw lx ly im bi translated">我们将在工作中使用scikit-multilearn、gensim &amp; scikit-learn。</p><h1 id="9ebc" class="mr ms it bd mt mu mv mw mx my mz na nb ki nc kj nd kl ne km nf ko ng kp nh ni bi translated">获取数据和探索</h1><p id="145b" class="pw-post-body-paragraph ld le it lf b lg nj kd li lj nk kg ll lm nl lo lp lq nm ls lt lu nn lw lx ly im bi translated">这篇文章的数据可以从<a class="ae no" href="https://www.kaggle.com/stackoverflow/statsquestions" rel="noopener ugc nofollow" target="_blank"> Kaggle </a>找到。它包含我们讨论所需的“Questions.csv”和“Tags.csv”。</p><p id="89f3" class="pw-post-body-paragraph ld le it lf b lg lh kd li lj lk kg ll lm ln lo lp lq lr ls lt lu lv lw lx ly im bi translated">让我们研究一下这些文件</p><pre class="ks kt ku kv gt np nq nr ns aw nt bi"><span id="a5a5" class="nu ms it nq b gy nv nw l nx ny">import pandas as pd</span><span id="7c1d" class="nu ms it nq b gy nz nw l nx ny">tag_df = pd.read_csv('../data/Tags.csv')<br/>tag_df.head()</span></pre><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div class="gh gi oa"><img src="../Images/7901e2fa2503d9c754b4866af96228ce.png" data-original-src="https://miro.medium.com/v2/resize:fit:580/format:webp/1*Bc8mSbYbJXOkJqdqAawwig.png"/></div><figcaption class="ob oc gj gh gi od oe bd b be z dk translated">图1</figcaption></figure><pre class="ks kt ku kv gt np nq nr ns aw nt bi"><span id="9aeb" class="nu ms it nq b gy nv nw l nx ny">questions_df = pd.read_csv('../data/Questions.csv', encoding = "ISO-8859-1")<br/>questions_df.head()</span></pre><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi of"><img src="../Images/d829b8257f64d4f71a1eb7bf7aae8912.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*jhNC3KndvQth6tdHxiv9jg.png"/></div></div><figcaption class="ob oc gj gh gi od oe bd b be z dk translated">图2</figcaption></figure><p id="fe5e" class="pw-post-body-paragraph ld le it lf b lg lh kd li lj lk kg ll lm ln lo lp lq lr ls lt lu lv lw lx ly im bi translated">所以，每个问题都以“正文”和“标题”为主要内容。我们需要理解这些，从那里我们必须预测一个未回答问题的标签。</p><p id="4bce" class="pw-post-body-paragraph ld le it lf b lg lh kd li lj lk kg ll lm ln lo lp lq lr ls lt lu lv lw lx ly im bi translated">我们可以看到，这些文件的数据与“id ”(即“问题Id ”)相关联。所以，我们可以把这两者结合起来，得到一个统一的观点。对于每个“正文”和“标题”,我们将以逗号分隔的方式连接标签。</p><figure class="ks kt ku kv gt kw"><div class="bz fp l di"><div class="og oh l"/></div></figure><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi oi"><img src="../Images/57044b63f88f4fa69301e8a46ecc8c04.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*7EDVd29Y7nZqs6DY1QgRgA.png"/></div></div><figcaption class="ob oc gj gh gi od oe bd b be z dk translated">图3</figcaption></figure><p id="bf80" class="pw-post-body-paragraph ld le it lf b lg lh kd li lj lk kg ll lm ln lo lp lq lr ls lt lu lv lw lx ly im bi translated">总共有1316种不同类型的标签(在前一篇文章中给出了分析)</p><p id="b37f" class="pw-post-body-paragraph ld le it lf b lg lh kd li lj lk kg ll lm ln lo lp lq lr ls lt lu lv lw lx ly im bi translated">现在，让我们看看最少出现次数为3的标签是什么(例如，该标签至少出现在三个问题中)</p><pre class="ks kt ku kv gt np nq nr ns aw nt bi"><span id="a171" class="nu ms it nq b gy nv nw l nx ny">tags_count_df = tag_df.groupby(['Tag']).count()<br/>tags_count_df_asc = tags_count_df.sort_values(by=['Id'])<br/>tags_count_df_asc.query('Id &gt;= 3').head()</span></pre><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div class="gh gi oj"><img src="../Images/9a481f3973a60e1e6495b540ffa924c3.png" data-original-src="https://miro.medium.com/v2/resize:fit:764/format:webp/1*yMozcFuyyCiwMd5htSFynw.png"/></div><figcaption class="ob oc gj gh gi od oe bd b be z dk translated">图3</figcaption></figure><p id="f5cc" class="pw-post-body-paragraph ld le it lf b lg lh kd li lj lk kg ll lm ln lo lp lq lr ls lt lu lv lw lx ly im bi translated">和反向或最频繁的标签</p><pre class="ks kt ku kv gt np nq nr ns aw nt bi"><span id="2a59" class="nu ms it nq b gy nv nw l nx ny">tags_count_df_desc = tags_count_df.sort_values(by=['Id'], ascending=False)<br/>tags_count_df_desc.head()</span></pre><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div class="gh gi ok"><img src="../Images/b9efa5e1363c21e4306ef60233b8933c.png" data-original-src="https://miro.medium.com/v2/resize:fit:696/format:webp/1*plCZMp-ZHyNlmtLMQRnIjA.png"/></div><figcaption class="ob oc gj gh gi od oe bd b be z dk translated">图4</figcaption></figure><h2 id="a90e" class="nu ms it bd mt ol om dn mx on oo dp nb lm op oq nd lq or os nf lu ot ou nh iz bi translated"><strong class="ak">可视化“正文”内容&amp;“标题”内容</strong></h2><p id="d97c" class="pw-post-body-paragraph ld le it lf b lg nj kd li lj nk kg ll lm nl lo lp lq nm ls lt lu nn lw lx ly im bi translated">现在，让我们看看单词云表示中问题的“正文”和“标题”的内容。为此，我们可以定义一个函数</p><figure class="ks kt ku kv gt kw"><div class="bz fp l di"><div class="og oh l"/></div></figure><p id="f2cc" class="pw-post-body-paragraph ld le it lf b lg lh kd li lj lk kg ll lm ln lo lp lq lr ls lt lu lv lw lx ly im bi translated">探索词云中“标签”的内容</p><pre class="ks kt ku kv gt np nq nr ns aw nt bi"><span id="d935" class="nu ms it nq b gy nv nw l nx ny">tags = ''<br/>for index, row in input_df.iterrows():<br/>    tags = tags + ',' + row['Tag']<br/>    <br/>plot_word_cloud(tags)</span></pre><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div class="gh gi ov"><img src="../Images/d8dd21282c774f4a0d7543c17f717cda.png" data-original-src="https://miro.medium.com/v2/resize:fit:1180/format:webp/1*2frUbK06exmNj7KgwKKoEg.png"/></div><figcaption class="ob oc gj gh gi od oe bd b be z dk translated">图5</figcaption></figure><p id="7a2c" class="pw-post-body-paragraph ld le it lf b lg lh kd li lj lk kg ll lm ln lo lp lq lr ls lt lu lv lw lx ly im bi translated">我们可以看到，像“机器学习”、“时间序列”等标签是最常见的。</p><p id="4310" class="pw-post-body-paragraph ld le it lf b lg lh kd li lj lk kg ll lm ln lo lp lq lr ls lt lu lv lw lx ly im bi translated"><strong class="lf jd">进一步勘探的数据预处理</strong></p><p id="6f02" class="pw-post-body-paragraph ld le it lf b lg lh kd li lj lk kg ll lm ln lo lp lq lr ls lt lu lv lw lx ly im bi translated">我们应该将数据分为输入内容和目标变量。在我们的例子中，目标变量是“Tag”</p><pre class="ks kt ku kv gt np nq nr ns aw nt bi"><span id="9f3c" class="nu ms it nq b gy nv nw l nx ny">df_x = input_df[['Title','Body']]<br/>df_y = input_df[['Tag']]</span></pre><p id="a8f3" class="pw-post-body-paragraph ld le it lf b lg lh kd li lj lk kg ll lm ln lo lp lq lr ls lt lu lv lw lx ly im bi translated">为了分析“Body”和“Tag”的内容，我们需要进行基本的文本预处理。</p><p id="2fdd" class="pw-post-body-paragraph ld le it lf b lg lh kd li lj lk kg ll lm ln lo lp lq lr ls lt lu lv lw lx ly im bi translated">步骤如下</p><ol class=""><li id="a09b" class="ow ox it lf b lg lh lj lk lm oy lq oz lu pa ly pb pc pd pe bi translated">转换成小写</li><li id="b574" class="ow ox it lf b lg pf lj pg lm ph lq pi lu pj ly pb pc pd pe bi translated">删除标点符号</li><li id="335c" class="ow ox it lf b lg pf lj pg lm ph lq pi lu pj ly pb pc pd pe bi translated">整数、数字的移除</li><li id="6379" class="ow ox it lf b lg pf lj pg lm ph lq pi lu pj ly pb pc pd pe bi translated">移除多余的空格</li><li id="6cd4" class="ow ox it lf b lg pf lj pg lm ph lq pi lu pj ly pb pc pd pe bi translated">移除标签(如、<p>等)</p></li><li id="ca56" class="ow ox it lf b lg pf lj pg lm ph lq pi lu pj ly pb pc pd pe bi translated">删除停用词(如“and”、“to”、“the”等)</li><li id="067f" class="ow ox it lf b lg pf lj pg lm ph lq pi lu pj ly pb pc pd pe bi translated">词干(将单词转换成词根形式)</li></ol><p id="6e5f" class="pw-post-body-paragraph ld le it lf b lg lh kd li lj lk kg ll lm ln lo lp lq lr ls lt lu lv lw lx ly im bi translated">我们将使用Python ' <strong class="lf jd"> gensim </strong>'库来清理所有文本。</p><p id="facb" class="pw-post-body-paragraph ld le it lf b lg lh kd li lj lk kg ll lm ln lo lp lq lr ls lt lu lv lw lx ly im bi translated">让我们先为此编写函数</p><figure class="ks kt ku kv gt kw"><div class="bz fp l di"><div class="og oh l"/></div></figure><p id="5532" class="pw-post-body-paragraph ld le it lf b lg lh kd li lj lk kg ll lm ln lo lp lq lr ls lt lu lv lw lx ly im bi translated">我们将通过一个例子来看这个函数在“正文”和“标题”上的应用效果</p><p id="fd74" class="pw-post-body-paragraph ld le it lf b lg lh kd li lj lk kg ll lm ln lo lp lq lr ls lt lu lv lw lx ly im bi translated">“标题”的内容</p><pre class="ks kt ku kv gt np nq nr ns aw nt bi"><span id="c5a8" class="nu ms it nq b gy nv nw l nx ny">input_df.iloc[0,0]</span></pre><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi pk"><img src="../Images/7b7d9c9873dfce192650aa08781fb4cf.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*1A1U5etU8DEIkHcLBSi5nQ.png"/></div></div><figcaption class="ob oc gj gh gi od oe bd b be z dk translated">图6</figcaption></figure><p id="a62e" class="pw-post-body-paragraph ld le it lf b lg lh kd li lj lk kg ll lm ln lo lp lq lr ls lt lu lv lw lx ly im bi translated">清洁后</p><pre class="ks kt ku kv gt np nq nr ns aw nt bi"><span id="92e3" class="nu ms it nq b gy nv nw l nx ny">clean_text(input_df.iloc[0,0])</span></pre><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div class="gh gi pl"><img src="../Images/d2cf3664673fed8d3d98bf2d93213311.png" data-original-src="https://miro.medium.com/v2/resize:fit:1080/format:webp/1*oZ0QmJZvyrSVi0Pyu42fmA.png"/></div><figcaption class="ob oc gj gh gi od oe bd b be z dk translated">图7</figcaption></figure><p id="ba13" class="pw-post-body-paragraph ld le it lf b lg lh kd li lj lk kg ll lm ln lo lp lq lr ls lt lu lv lw lx ly im bi translated">“主体”的内容</p><pre class="ks kt ku kv gt np nq nr ns aw nt bi"><span id="f4a7" class="nu ms it nq b gy nv nw l nx ny">input_df.iloc[0,1]</span></pre><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi pm"><img src="../Images/1204abee050d4d81685e499d2e7c6f13.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*XMkudNcDiNv29Ccmsz0kGw.png"/></div></div><figcaption class="ob oc gj gh gi od oe bd b be z dk translated">图8</figcaption></figure><p id="42ea" class="pw-post-body-paragraph ld le it lf b lg lh kd li lj lk kg ll lm ln lo lp lq lr ls lt lu lv lw lx ly im bi translated">清洁后</p><pre class="ks kt ku kv gt np nq nr ns aw nt bi"><span id="2523" class="nu ms it nq b gy nv nw l nx ny">clean_text(input_df.iloc[0,1])</span></pre><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi pn"><img src="../Images/ad65638c9e00bc4ea23f466b5a00f611.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*8rRo1Eb6m4ELUjHQnW66iQ.png"/></div></div><figcaption class="ob oc gj gh gi od oe bd b be z dk translated">图9</figcaption></figure><p id="b308" class="pw-post-body-paragraph ld le it lf b lg lh kd li lj lk kg ll lm ln lo lp lq lr ls lt lu lv lw lx ly im bi translated">虽然清洗后的内容看起来有点笨拙，但这些需要进一步处理</p><p id="63e9" class="pw-post-body-paragraph ld le it lf b lg lh kd li lj lk kg ll lm ln lo lp lq lr ls lt lu lv lw lx ly im bi translated">现在，我们来看看所有清理过的‘标题’的字云。我们将使用上面定义的"<strong class="lf jd"> clean_text" </strong>函数进行清洗。</p><pre class="ks kt ku kv gt np nq nr ns aw nt bi"><span id="0d2c" class="nu ms it nq b gy nv nw l nx ny">titles = ''<br/>for index, row in input_df.iterrows():<br/>    titles = titles + ' ' + clean_text(row['Title'])<br/>    <br/>plot_word_cloud(titles)</span></pre><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div class="gh gi ov"><img src="../Images/fcbef4a567266abe214b717af04d5a60.png" data-original-src="https://miro.medium.com/v2/resize:fit:1180/format:webp/1*pL5HoxYcAWmdG5Ji-cdDoA.png"/></div><figcaption class="ob oc gj gh gi od oe bd b be z dk translated">图10</figcaption></figure><p id="8480" class="pw-post-body-paragraph ld le it lf b lg lh kd li lj lk kg ll lm ln lo lp lq lr ls lt lu lv lw lx ly im bi translated">因此，“数据”、“差异”、“价值”等是“标题”内容中最常见的标记</p><p id="ed4b" class="pw-post-body-paragraph ld le it lf b lg lh kd li lj lk kg ll lm ln lo lp lq lr ls lt lu lv lw lx ly im bi translated">所有已清理“正文”内容的相同词云图</p><pre class="ks kt ku kv gt np nq nr ns aw nt bi"><span id="d0ee" class="nu ms it nq b gy nv nw l nx ny">bodies = ''<br/>for index, row in input_df.iterrows():<br/>    bodies = bodies + ' ' + clean_text(row['Body'])<br/>    <br/>plot_word_cloud(bodies)</span></pre><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div class="gh gi ov"><img src="../Images/fb6b2eaa42b6ee0f339d57aa8f97b905.png" data-original-src="https://miro.medium.com/v2/resize:fit:1180/format:webp/1*F4iDyXVNh2L1QLsk4L5P_A.png"/></div><figcaption class="ob oc gj gh gi od oe bd b be z dk translated">图11</figcaption></figure><p id="41e0" class="pw-post-body-paragraph ld le it lf b lg lh kd li lj lk kg ll lm ln lo lp lq lr ls lt lu lv lw lx ly im bi translated">know、exampl、case等是Body中最常用的标记</p><p id="5889" class="pw-post-body-paragraph ld le it lf b lg lh kd li lj lk kg ll lm ln lo lp lq lr ls lt lu lv lw lx ly im bi translated">我们还可以看到与特定标签相对应的“主体”内容。为此，让我们定义一个函数</p><figure class="ks kt ku kv gt kw"><div class="bz fp l di"><div class="og oh l"/></div></figure><p id="9b64" class="pw-post-body-paragraph ld le it lf b lg lh kd li lj lk kg ll lm ln lo lp lq lr ls lt lu lv lw lx ly im bi translated">带有“matlab”标签的问题的词云</p><pre class="ks kt ku kv gt np nq nr ns aw nt bi"><span id="9751" class="nu ms it nq b gy nv nw l nx ny">plot_word_cloud_of_body_for_tag('matlab')</span></pre><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div class="gh gi ov"><img src="../Images/1edd8cb2284060a2ffc000aa7cd5855b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1180/format:webp/1*V3k2IdDktXfBQ8y3rGHyCA.png"/></div><figcaption class="ob oc gj gh gi od oe bd b be z dk translated">图12</figcaption></figure><p id="4407" class="pw-post-body-paragraph ld le it lf b lg lh kd li lj lk kg ll lm ln lo lp lq lr ls lt lu lv lw lx ly im bi translated">显而易见,“matlab”将是最常见的标记之一。</p><p id="4d60" class="pw-post-body-paragraph ld le it lf b lg lh kd li lj lk kg ll lm ln lo lp lq lr ls lt lu lv lw lx ly im bi translated">标签“概率”也是如此</p><pre class="ks kt ku kv gt np nq nr ns aw nt bi"><span id="c917" class="nu ms it nq b gy nv nw l nx ny">plot_word_cloud_of_body_for_tag('probability')</span></pre><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div class="gh gi ov"><img src="../Images/d9ffc6688b3eee4f3e982930a25c1e6e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1180/format:webp/1*0osDLoihsVk6gdoGeujNyw.png"/></div><figcaption class="ob oc gj gh gi od oe bd b be z dk translated">图13</figcaption></figure><h1 id="4654" class="mr ms it bd mt mu mv mw mx my mz na nb ki nc kj nd kl ne km nf ko ng kp nh ni bi translated">构建机器学习模型和管道</h1><p id="d31d" class="pw-post-body-paragraph ld le it lf b lg nj kd li lj nk kg ll lm nl lo lp lq nm ls lt lu nn lw lx ly im bi translated">在所有的数据探索之后，现在让我们集中精力构建实际的模型。由于这是一个多标签分类，我们需要将我们的目标标签转换为一个二进制向量，其中多个位设置为1。</p><p id="505a" class="pw-post-body-paragraph ld le it lf b lg lh kd li lj lk kg ll lm ln lo lp lq lr ls lt lu lv lw lx ly im bi translated">“scikit-learn”的“multilabel binarizer”可以做到这一点</p><figure class="ks kt ku kv gt kw"><div class="bz fp l di"><div class="og oh l"/></div></figure><p id="5f53" class="pw-post-body-paragraph ld le it lf b lg lh kd li lj lk kg ll lm ln lo lp lq lr ls lt lu lv lw lx ly im bi translated">因为我们正在处理文本数据。我们需要把它转换成向量空间模型。我们将使用'<a class="ae no" href="https://skymind.ai/wiki/word2vec" rel="noopener ugc nofollow" target="_blank"> Doc2Vec </a>'模型进行转换。</p><p id="e755" class="pw-post-body-paragraph ld le it lf b lg lh kd li lj lk kg ll lm ln lo lp lq lr ls lt lu lv lw lx ly im bi translated">我们将使用python的“<strong class="lf jd"> gensim </strong>”库编写一个自定义的“Doc2VecTransformer”</p><figure class="ks kt ku kv gt kw"><div class="bz fp l di"><div class="og oh l"/></div></figure><p id="4a31" class="pw-post-body-paragraph ld le it lf b lg lh kd li lj lk kg ll lm ln lo lp lq lr ls lt lu lv lw lx ly im bi translated">这个类将字段名作为输入(在我们的例子中分别是“Body”和“Title ”),并将文本转换成数字特征的数组</p><p id="b0b0" class="pw-post-body-paragraph ld le it lf b lg lh kd li lj lk kg ll lm ln lo lp lq lr ls lt lu lv lw lx ly im bi translated">我们将把数据分为“训练”和“测试”</p><pre class="ks kt ku kv gt np nq nr ns aw nt bi"><span id="230e" class="nu ms it nq b gy nv nw l nx ny">from sklearn.model_selection import train_test_split</span><span id="5f18" class="nu ms it nq b gy nz nw l nx ny">train_x, test_x, train_y, test_y = train_test_split(df_x, encoded_y)</span></pre><blockquote class="po pp pq"><p id="7912" class="ld le pr lf b lg lh kd li lj lk kg ll ps ln lo lp pt lr ls lt pu lv lw lx ly im bi translated">在使用<strong class="lf jd"> scikit-learn </strong>的<strong class="lf jd"> FeatureUnion </strong>进行“<strong class="lf jd"> Doc2Vec </strong>”转换后，我们需要将两个字段“Body”和“Title”合并到一个特性中。</p></blockquote><figure class="ks kt ku kv gt kw"><div class="bz fp l di"><div class="og oh l"/></div></figure><blockquote class="po pp pq"><p id="cbb7" class="ld le pr lf b lg lh kd li lj lk kg ll ps ln lo lp pt lr ls lt pu lv lw lx ly im bi translated">从“多标签”模型的概念出发，我们将尝试使用“<strong class="lf jd">二元相关性</strong>”&amp;”<strong class="lf jd">分类器链</strong>作为我们的伞式分类方案<strong class="lf jd">(参考前面提到的文章)</strong>，并将使用“<strong class="lf jd"> RandomForest </strong>”作为我们的基础二元分类器。</p><p id="9dc8" class="ld le pr lf b lg lh kd li lj lk kg ll ps ln lo lp pt lr ls lt pu lv lw lx ly im bi translated">因为有1316个不同的标签，所以里面会有1316个分解的和独立的二元分类器。</p></blockquote><p id="3d01" class="pw-post-body-paragraph ld le it lf b lg lh kd li lj lk kg ll lm ln lo lp lq lr ls lt lu lv lw lx ly im bi translated">我们将比较两种伞式方案的准确性。</p><p id="efc3" class="pw-post-body-paragraph ld le it lf b lg lh kd li lj lk kg ll lm ln lo lp lq lr ls lt lu lv lw lx ly im bi translated"><strong class="lf jd">二元相关性</strong></p><p id="aa5f" class="pw-post-body-paragraph ld le it lf b lg lh kd li lj lk kg ll lm ln lo lp lq lr ls lt lu lv lw lx ly im bi translated">我们的管道应该在“RandomForest”分类器之上包含“FeatureUnion”步骤和“BinaryRelevance”步骤。我们将使用'<strong class="lf jd"> scikit-multilearn </strong>'库中的'<strong class="lf jd"> BinaryRelevance </strong>类。</p><figure class="ks kt ku kv gt kw"><div class="bz fp l di"><div class="og oh l"/></div></figure><p id="3476" class="pw-post-body-paragraph ld le it lf b lg lh kd li lj lk kg ll lm ln lo lp lq lr ls lt lu lv lw lx ly im bi translated">为了测试我们模型的准确性，让我们定义一个函数来计算'<strong class="lf jd">汉明损失</strong>'(参考上一篇文章)</p><figure class="ks kt ku kv gt kw"><div class="bz fp l di"><div class="og oh l"/></div></figure><p id="5210" class="pw-post-body-paragraph ld le it lf b lg lh kd li lj lk kg ll lm ln lo lp lq lr ls lt lu lv lw lx ly im bi translated">让我们训练和测试“二元相关性”模型</p><pre class="ks kt ku kv gt np nq nr ns aw nt bi"><span id="7acf" class="nu ms it nq b gy nv nw l nx ny">multi_label_rf_br_model.fit(train_x, train_y)<br/>print('Hamming loss for test data :', hamming_loss(multi_label_rf_br_model,train_x,train_y,test_x,test_y))</span></pre><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi pv"><img src="../Images/000ad45e85d2e196e7dfae9962ddffb1.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Deh4waTVSSi46aDh1XwjUg.png"/></div></div><figcaption class="ob oc gj gh gi od oe bd b be z dk translated">图14</figcaption></figure><p id="a594" class="pw-post-body-paragraph ld le it lf b lg lh kd li lj lk kg ll lm ln lo lp lq lr ls lt lu lv lw lx ly im bi translated">这意味着几乎0.02%的损失，或者我们可以说99.98%的准确性！！</p><p id="ab89" class="pw-post-body-paragraph ld le it lf b lg lh kd li lj lk kg ll lm ln lo lp lq lr ls lt lu lv lw lx ly im bi translated"><strong class="lf jd">分类器链</strong></p><p id="96dc" class="pw-post-body-paragraph ld le it lf b lg lh kd li lj lk kg ll lm ln lo lp lq lr ls lt lu lv lw lx ly im bi translated">同样，我们可以训练和测试“分类器链”。<strong class="lf jd"> scikit-multilearn </strong>为此提供了一个类</p><figure class="ks kt ku kv gt kw"><div class="bz fp l di"><div class="og oh l"/></div></figure><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi pw"><img src="../Images/45847bf1649c10eceba3576c89c56114.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*1yAwRFpWam3Iz08a-3jK5w.png"/></div></div><figcaption class="ob oc gj gh gi od oe bd b be z dk translated">图15</figcaption></figure><p id="9ad0" class="pw-post-body-paragraph ld le it lf b lg lh kd li lj lk kg ll lm ln lo lp lq lr ls lt lu lv lw lx ly im bi translated">几乎一样的精度！！</p><p id="2c3d" class="pw-post-body-paragraph ld le it lf b lg lh kd li lj lk kg ll lm ln lo lp lq lr ls lt lu lv lw lx ly im bi translated"><strong class="lf jd">单个分类器的进一步精度分析</strong></p><p id="4072" class="pw-post-body-paragraph ld le it lf b lg lh kd li lj lk kg ll lm ln lo lp lq lr ls lt lu lv lw lx ly im bi translated">由于有两个以上的分类器，不可能检查每个人的表现和准确性，但我们将看到其中3个分类器的ROC曲线。让我们为此写一个函数。</p><figure class="ks kt ku kv gt kw"><div class="bz fp l di"><div class="og oh l"/></div></figure><p id="eed9" class="pw-post-body-paragraph ld le it lf b lg lh kd li lj lk kg ll lm ln lo lp lq lr ls lt lu lv lw lx ly im bi translated">现在，我们将看到三个标签的“ROC曲线”:“正态分布”、“数据可视化”和“估计”</p><pre class="ks kt ku kv gt np nq nr ns aw nt bi"><span id="79de" class="nu ms it nq b gy nv nw l nx ny">plot_roc_curve(x=test_x, y=test_y, classes=['normal-distribution','data-visualization','estimation'], <br/>               title='ROC curve')</span></pre><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi gj"><img src="../Images/1fe97c52da880816e4fae15c0f64bc14.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*qLPF27GgtFG_IRpHdefJZw.png"/></div></div><figcaption class="ob oc gj gh gi od oe bd b be z dk translated">图16</figcaption></figure><p id="7e5d" class="pw-post-body-paragraph ld le it lf b lg lh kd li lj lk kg ll lm ln lo lp lq lr ls lt lu lv lw lx ly im bi translated">类似的ROC曲线也可以通过该函数为其他标签绘制。读者可以自行尝试。</p><h1 id="df4b" class="mr ms it bd mt mu mv mw mx my mz na nb ki nc kj nd kl ne km nf ko ng kp nh ni bi translated">结论</h1><p id="ac4c" class="pw-post-body-paragraph ld le it lf b lg nj kd li lj nk kg ll lm nl lo lp lq nm ls lt lu nn lw lx ly im bi translated">这都是为了解决问题。通过使用不同的二元分类器或使用超参数对其进行调整，可以实现进一步的改进。这篇文章的读者可以自己尝试一下。本文的源代码可以在Github中找到。</p><div class="lz ma gp gr mb mc"><a href="https://github.com/avisheknag17/public_ml_models/blob/master/multi_label_classification_understanding/notebook/multi_label_text_classification_scikit_multilearn.ipynb" rel="noopener  ugc nofollow" target="_blank"><div class="md ab fo"><div class="me ab mf cl cj mg"><h2 class="bd jd gy z fp mh fr fs mi fu fw jc bi translated">avisheknag17/public_ml_models</h2><div class="mj l"><h3 class="bd b gy z fp mh fr fs mi fu fw dk translated">在GitHub上创建一个帐户，为avisheknag17/public_ml_models开发做出贡献。</h3></div><div class="mk l"><p class="bd b dl z fp mh fr fs mi fu fw dk translated">github.com</p></div></div><div class="ml l"><div class="px l mn mo mp ml mq lb mc"/></div></div></a></div><p id="629a" class="pw-post-body-paragraph ld le it lf b lg lh kd li lj lk kg ll lm ln lo lp lq lr ls lt lu lv lw lx ly im bi translated">最近，我写了一本关于ML(<a class="ae no" href="https://twitter.com/bpbonline/status/1256146448346988546" rel="noopener ugc nofollow" target="_blank">https://twitter.com/bpbonline/status/1256146448346988546</a>)的书</p></div></div>    
</body>
</html>