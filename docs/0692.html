<html>
<head>
<title>Chest X-Ray Abnormality Classification Using Monk AI</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">基于Monk AI的胸部X线异常分类</h1>
<blockquote>原文：<a href="https://pub.towardsai.net/chest-x-ray-abnormality-classification-using-monk-ai-df4b5db7f4a4?source=collection_archive---------2-----------------------#2020-07-18">https://pub.towardsai.net/chest-x-ray-abnormality-classification-using-monk-ai-df4b5db7f4a4?source=collection_archive---------2-----------------------#2020-07-18</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><h2 id="831a" class="ir is it bd b dl iu iv iw ix iy iz dk ja translated" aria-label="kicker paragraph"><a class="ae ep" href="https://towardsai.net/p/category/artificial-intelligence" rel="noopener ugc nofollow" target="_blank">人工智能</a>，<a class="ae ep" href="https://towardsai.net/p/category/computer-vision" rel="noopener ugc nofollow" target="_blank">计算机视觉</a></h2><div class=""/><div class=""><h2 id="a631" class="pw-subtitle-paragraph jz jc it bd b ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq dk translated">使用Monk，低代码深度学习工具和计算机视觉的统一包装器，使计算机视觉变得简单。</h2></div><h1 id="7dcc" class="kr ks it bd kt ku kv kw kx ky kz la lb ki lc kj ld kl le km lf ko lg kp lh li bi translated">关键任务</h1><p id="83ef" class="pw-post-body-paragraph lj lk it ll b lm ln kd lo lp lq kg lr ls lt lu lv lw lx ly lz ma mb mc md me im bi translated">在这篇博文中，我们将执行三项主要任务</p><ul class=""><li id="66a4" class="mf mg it ll b lm mh lp mi ls mj lw mk ma ml me mm mn mo mp bi translated">以创建二元分类器来将胸部x射线图像分类为正常/异常。</li><li id="9429" class="mf mg it ll b lm mq lp mr ls ms lw mt ma mu me mm mn mo mp bi translated">比较三种深度神经网络架构。</li><li id="1207" class="mf mg it ll b lm mq lp mr ls ms lw mt ma mu me mm mn mo mp bi translated">以创建多标签分类器来生成14个疾病标签和相应的置信度得分。</li></ul><p id="328a" class="pw-post-body-paragraph lj lk it ll b lm mh kd lo lp mi kg lr ls mv lu lv lw mw ly lz ma mx mc md me im bi translated">我使用的三种深度神经网络架构是Vgg16、Resnet50和MobileNet。</p><h1 id="4123" class="kr ks it bd kt ku kv kw kx ky kz la lb ki lc kj ld kl le km lf ko lg kp lh li bi translated">目录</h1><h2 id="7a02" class="my ks it bd kt mz na dn kx nb nc dp lb ls nd ne ld lw nf ng lf ma nh ni lh iz bi translated">1.安装Monk</h2><h2 id="ec09" class="my ks it bd kt mz na dn kx nb nc dp lb ls nd ne ld lw nf ng lf ma nh ni lh iz bi translated">2.下载数据集</h2><h2 id="6953" class="my ks it bd kt mz na dn kx nb nc dp lb ls nd ne ld lw nf ng lf ma nh ni lh iz bi translated">3.导入框架和库</h2><h2 id="28c6" class="my ks it bd kt mz na dn kx nb nc dp lb ls nd ne ld lw nf ng lf ma nh ni lh iz bi translated">4.可视化和探索数据集提供的样本</h2><h2 id="1460" class="my ks it bd kt mz na dn kx nb nc dp lb ls nd ne ld lw nf ng lf ma nh ni lh iz bi translated">5.可视化和探索数据集提供的样本</h2><h2 id="8868" class="my ks it bd kt mz na dn kx nb nc dp lb ls nd ne ld lw nf ng lf ma nh ni lh iz bi translated">6.比较</h2><h2 id="e72e" class="my ks it bd kt mz na dn kx nb nc dp lb ls nd ne ld lw nf ng lf ma nh ni lh iz bi translated">7.暗示</h2></div><div class="ab cl nj nk hx nl" role="separator"><span class="nm bw bk nn no np"/><span class="nm bw bk nn no np"/><span class="nm bw bk nn no"/></div><div class="im in io ip iq"><h1 id="fd60" class="kr ks it bd kt ku nq kw kx ky nr la lb ki ns kj ld kl nt km lf ko nu kp lh li bi translated">安装Monk</h1><p id="3022" class="pw-post-body-paragraph lj lk it ll b lm ln kd lo lp lq kg lr ls lt lu lv lw lx ly lz ma mb mc md me im bi translated">我们将从设置Monk AI toolkit及其对您正在使用的平台的依赖开始，我使用Google Colab作为我的环境。</p><pre class="nv nw nx ny gt nz oa ob oc aw od bi"><span id="be88" class="my ks it oa b gy oe of l og oh">!git clone <a class="ae oi" href="https://github.com/Tessellate-Imaging/monk_v1.git" rel="noopener ugc nofollow" target="_blank">https://github.com/Tessellate-Imaging/monk_v1.git</a><br/>!cd monk_v1/installation/Misc &amp;&amp; pip install -r requirements_colab.txt</span></pre><h1 id="262b" class="kr ks it bd kt ku kv kw kx ky kz la lb ki lc kj ld kl le km lf ko lg kp lh li bi translated">下载数据集</h1><p id="8404" class="pw-post-body-paragraph lj lk it ll b lm ln kd lo lp lq kg lr ls lt lu lv lw lx ly lz ma mb mc md me im bi translated">设置好Monk toolkit后，下一步是安装Kaggle，并从Kaggle下载NIH胸部X射线数据集到我们的Colab笔记本上。</p><pre class="nv nw nx ny gt nz oa ob oc aw od bi"><span id="ca2a" class="my ks it oa b gy oe of l og oh">! pip install -q kaggle</span></pre><p id="6018" class="pw-post-body-paragraph lj lk it ll b lm mh kd lo lp mi kg lr ls mv lu lv lw mw ly lz ma mx mc md me im bi translated">要从Kaggle下载任何数据集，我们需要首先通过前往kaggle上的<strong class="ll jd"> MyAccount </strong>下载kaggle.json文件，并下载一个新的API。然后我们将JSON文件上传到我们的Colab笔记本上。</p><pre class="nv nw nx ny gt nz oa ob oc aw od bi"><span id="4e83" class="my ks it oa b gy oe of l og oh"><strong class="oa jd">from</strong> <strong class="oa jd">google.colab</strong> <strong class="oa jd">import</strong> files</span><span id="68e3" class="my ks it oa b gy oj of l og oh">files.upload()</span></pre><p id="d711" class="pw-post-body-paragraph lj lk it ll b lm mh kd lo lp mi kg lr ls mv lu lv lw mw ly lz ma mx mc md me im bi translated">现在我们可以从Kaggle下载数据集的zip文件并解压缩。</p><pre class="nv nw nx ny gt nz oa ob oc aw od bi"><span id="427d" class="my ks it oa b gy oe of l og oh">! mkdir ~/.kaggle<br/>! cp kaggle.json ~/.kaggle/<br/>! chmod 600 ~/.kaggle/kaggle.json<br/>! kaggle datasets download -d 'nih-chest-xrays/sample'<br/>! unzip -qq sample.zip</span></pre><p id="145b" class="pw-post-body-paragraph lj lk it ll b lm mh kd lo lp mi kg lr ls mv lu lv lw mw ly lz ma mx mc md me im bi translated">数据集共有15个类别(14个疾病类别和1个“无发现”类别)。</p><figure class="nv nw nx ny gt ol gh gi paragraph-image"><div role="button" tabindex="0" class="om on di oo bf op"><div class="gh gi ok"><img src="../Images/30914691e95cf45c00f5aa65f3548a17.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*lwfHLyjQKXfrxlzDEnrTPw.png"/></div></div><figcaption class="os ot gj gh gi ou ov bd b be z dk translated">来自Kaggle的NIH胸部X线数据集的胸部X线图像</figcaption></figure><h1 id="6508" class="kr ks it bd kt ku kv kw kx ky kz la lb ki lc kj ld kl le km lf ko lg kp lh li bi translated">导入框架和库</h1><p id="75b0" class="pw-post-body-paragraph lj lk it ll b lm ln kd lo lp lq kg lr ls lt lu lv lw lx ly lz ma mb mc md me im bi translated">Monk为我们提供了三个主要的工作框架，即Keras、Pytorch和Mxnet。我们在这个项目中使用Keras框架，Pandas库用于可视化和探索数据集。为了建立一个项目的工作目录，我们为正在使用的框架初始化一个原型。</p><pre class="nv nw nx ny gt nz oa ob oc aw od bi"><span id="695b" class="my ks it oa b gy oe of l og oh"><strong class="oa jd">from</strong> <strong class="oa jd">keras_prototype</strong> <strong class="oa jd">import</strong> prototype<br/><strong class="oa jd">import</strong> <strong class="oa jd">pandas</strong> <strong class="oa jd">as</strong> <strong class="oa jd">pd</strong></span></pre><h1 id="0448" class="kr ks it bd kt ku kv kw kx ky kz la lb ki lc kj ld kl le km lf ko lg kp lh li bi translated">可视化和探索数据集提供的样本</h1><p id="3095" class="pw-post-body-paragraph lj lk it ll b lm ln kd lo lp lq kg lr ls lt lu lv lw lx ly lz ma mb mc md me im bi translated">制作了两个数据帧，一个具有由14个疾病类别和1个“未发现”类别组成的多标记目标值，对于图像的二进制分类，通过分别用<strong class="ll jd">异常</strong>和<strong class="ll jd">正常</strong>替换疾病类别和“未发现”类别来形成另一个数据帧</p><pre class="nv nw nx ny gt nz oa ob oc aw od bi"><span id="6ab2" class="my ks it oa b gy oe of l og oh">$ df=pd.read_csv('sample/sample_labels.csv')</span><span id="19fc" class="my ks it oa b gy oj of l og oh">$ for i in range(len(df)):<br/>          df["Finding Labels"][i] = df["Finding Labels"][i].replace("|", ",");</span><span id="4a7e" class="my ks it oa b gy oj of l og oh">$ df.to_csv("sample/kush1.csv", index=False)</span><span id="4763" class="my ks it oa b gy oj of l og oh">$ for i in range(len(df)):</span><span id="b23e" class="my ks it oa b gy oj of l og oh">if df["Finding Labels"][i] == "No Finding":</span><span id="73f0" class="my ks it oa b gy oj of l og oh">df["Finding Labels"][i] = "Normal";</span><span id="f5f4" class="my ks it oa b gy oj of l og oh">else:<br/>               df["Finding Labels"][i] = "Abnormal";</span><span id="bdc0" class="my ks it oa b gy oj of l og oh">$ df.to_csv("sample/kush2.csv",index=False)</span></pre><h1 id="247c" class="kr ks it bd kt ku kv kw kx ky kz la lb ki lc kj ld kl le km lf ko lg kp lh li bi translated">设置模型、选择参数和训练</h1><p id="95da" class="pw-post-body-paragraph lj lk it ll b lm ln kd lo lp lq kg lr ls lt lu lv lw lx ly lz ma mb mc md me im bi translated">我们已经导入了Keras框架，现在我们将通过选择三个模型来创建一个新项目和这个项目中的三个新实验。</p><h2 id="8eee" class="my ks it bd kt mz na dn kx nb nc dp lb ls nd ne ld lw nf ng lf ma nh ni lh iz bi translated">Vgg16</h2><pre class="nv nw nx ny gt nz oa ob oc aw od bi"><span id="bc4e" class="my ks it oa b gy oe of l og oh">gtf = prototype(verbose=1);<br/>gtf.Prototype("Pilot", "keras_vgg16");</span></pre><p id="5ebe" class="pw-post-body-paragraph lj lk it ll b lm mh kd lo lp mi kg lr ls mv lu lv lw mw ly lz ma mx mc md me im bi translated">为了获得原型中可用的模型，我们使用List_Models函数</p><pre class="nv nw nx ny gt nz oa ob oc aw od bi"><span id="7025" class="my ks it oa b gy oe of l og oh">gtf.List_Models();</span></pre><p id="448b" class="pw-post-body-paragraph lj lk it ll b lm mh kd lo lp mi kg lr ls mv lu lv lw mw ly lz ma mx mc md me im bi translated">VGG16是本项目中使用的第一个CNN架构，在创建实验文件后，我们设置了数据集和标签路径。然后建立Vgg16模型，并给出历元数。我们将freeze_base_network初始化为false，以使模型中的所有层都成为可训练层。</p><pre class="nv nw nx ny gt nz oa ob oc aw od bi"><span id="98eb" class="my ks it oa b gy oe of l og oh">gtf.Default(dataset_path="sample/images", <br/>            path_to_csv = "sample/kush2.csv",<br/>            model_name="vgg16", <br/>            freeze_base_network=<strong class="oa jd">False</strong>,<br/>            delimiter = ",",<br/>            num_epochs=5);</span></pre><p id="3b4a" class="pw-post-body-paragraph lj lk it ll b lm mh kd lo lp mi kg lr ls mv lu lv lw mw ly lz ma mx mc md me im bi translated">建立好模型之后，接下来就是训练了。</p><pre class="nv nw nx ny gt nz oa ob oc aw od bi"><span id="434c" class="my ks it oa b gy oe of l og oh">gtf.Train();</span></pre><p id="3928" class="pw-post-body-paragraph lj lk it ll b lm mh kd lo lp mi kg lr ls mv lu lv lw mw ly lz ma mx mc md me im bi translated">类似于Vgg16，我们使用Resnet50和MobileNet作为CNN架构创建了另外两个实验。模型的设置类似于Vgg16，只有模型名称被相应地改变，并且一旦模型被设置，它就在训练数据集上被训练。</p><p id="8e42" class="pw-post-body-paragraph lj lk it ll b lm mh kd lo lp mi kg lr ls mv lu lv lw mw ly lz ma mx mc md me im bi translated"><strong class="ll jd"> Resnet50 </strong></p><p id="1c4c" class="pw-post-body-paragraph lj lk it ll b lm mh kd lo lp mi kg lr ls mv lu lv lw mw ly lz ma mx mc md me im bi translated">实验文件保存在项目文件夹中。</p><pre class="nv nw nx ny gt nz oa ob oc aw od bi"><span id="cbc8" class="my ks it oa b gy oe of l og oh">gtf=prototype(verbose=1);<br/>gtf.Prototype("Pilot", "keras_resnet50");</span></pre><p id="9322" class="pw-post-body-paragraph lj lk it ll b lm mh kd lo lp mi kg lr ls mv lu lv lw mw ly lz ma mx mc md me im bi translated">然后建立模型并进行训练。</p><pre class="nv nw nx ny gt nz oa ob oc aw od bi"><span id="5445" class="my ks it oa b gy oe of l og oh">gtf.Default(dataset_path="sample/images", <br/>            path_to_csv = "sample/kush2.csv",<br/>            model_name="resnet50", <br/>            freeze_base_network=<strong class="oa jd">False</strong>,<br/>            delimiter = ",",<br/>            num_epochs=5);</span><span id="6b42" class="my ks it oa b gy oj of l og oh">gtf.Train();</span></pre><p id="a2b5" class="pw-post-body-paragraph lj lk it ll b lm mh kd lo lp mi kg lr ls mv lu lv lw mw ly lz ma mx mc md me im bi translated"><strong class="ll jd"> MobileNet </strong></p><p id="023c" class="pw-post-body-paragraph lj lk it ll b lm mh kd lo lp mi kg lr ls mv lu lv lw mw ly lz ma mx mc md me im bi translated">创建实验文件</p><pre class="nv nw nx ny gt nz oa ob oc aw od bi"><span id="4adb" class="my ks it oa b gy oe of l og oh">gtf=prototype(verbose=1);<br/>gtf.Prototype("Pilot", "keras_mobilenet");</span></pre><p id="2a16" class="pw-post-body-paragraph lj lk it ll b lm mh kd lo lp mi kg lr ls mv lu lv lw mw ly lz ma mx mc md me im bi translated">建立和训练模型</p><pre class="nv nw nx ny gt nz oa ob oc aw od bi"><span id="9191" class="my ks it oa b gy oe of l og oh">gtf.Default(dataset_path="sample/images", <br/>            path_to_csv = "sample/kush2.csv",<br/>            model_name="mobilenet", <br/>            freeze_base_network=<strong class="oa jd">False</strong>,<br/>            delimiter = ",",<br/>            num_epochs=5);</span><span id="d4e3" class="my ks it oa b gy oj of l og oh">gtf.Train();</span></pre><h1 id="77e5" class="kr ks it bd kt ku kv kw kx ky kz la lb ki lc kj ld kl le km lf ko lg kp lh li bi translated">比较</h1><p id="8b4c" class="pw-post-body-paragraph lj lk it ll b lm ln kd lo lp lq kg lr ls lt lu lv lw lx ly lz ma mb mc md me im bi translated">训练完所有三个模型后，我们继续下一个任务，比较这三个模型。</p><p id="9cbc" class="pw-post-body-paragraph lj lk it ll b lm mh kd lo lp mi kg lr ls mv lu lv lw mw ly lz ma mx mc md me im bi translated">我们可以使用比较原型来比较这三个模型。</p><pre class="nv nw nx ny gt nz oa ob oc aw od bi"><span id="2800" class="my ks it oa b gy oe of l og oh"><strong class="oa jd">from</strong> <strong class="oa jd">compare_prototype</strong> <strong class="oa jd">import</strong> compare<br/>gtf = compare(verbose=1);<br/>gtf.Comparison("Comparison")</span></pre><p id="b4ec" class="pw-post-body-paragraph lj lk it ll b lm mh kd lo lp mi kg lr ls mv lu lv lw mw ly lz ma mx mc md me im bi translated">添加要比较的实验。</p><pre class="nv nw nx ny gt nz oa ob oc aw od bi"><span id="00dd" class="my ks it oa b gy oe of l og oh">gtf.Add_Experiment("Pilot", "keras_vgg16");<br/>gtf.Add_Experiment("Pilot", "keras_resnet50");<br/>gtf.Add_Experiment("Pilot", "keras_mobilenet");</span></pre><p id="b829" class="pw-post-body-paragraph lj lk it ll b lm mh kd lo lp mi kg lr ls mv lu lv lw mw ly lz ma mx mc md me im bi translated">生成统计数据</p><pre class="nv nw nx ny gt nz oa ob oc aw od bi"><span id="559b" class="my ks it oa b gy oe of l og oh">gtf.Generate_Statistics();</span></pre><p id="276a" class="pw-post-body-paragraph lj lk it ll b lm mh kd lo lp mi kg lr ls mv lu lv lw mw ly lz ma mx mc md me im bi translated">这将生成一个CSV文件和各种图形。</p><figure class="nv nw nx ny gt ol gh gi paragraph-image"><div role="button" tabindex="0" class="om on di oo bf op"><div class="gh gi ow"><img src="../Images/1b164747ed3b3a7ac3c74f5aec7b050d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*jIrxnKDLQvPLYnid12u_JA.png"/></div></div><figcaption class="os ot gj gh gi ou ov bd b be z dk translated">训练准确度曲线</figcaption></figure><figure class="nv nw nx ny gt ol gh gi paragraph-image"><div role="button" tabindex="0" class="om on di oo bf op"><div class="gh gi ox"><img src="../Images/4ce86430d3cfbc2f1b4d3d614b5e5afd.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*-ObITY1u8uG6_s9Fh2Yl4A.png"/></div></div><figcaption class="os ot gj gh gi ou ov bd b be z dk translated">验证准确度曲线</figcaption></figure><figure class="nv nw nx ny gt ol gh gi paragraph-image"><div role="button" tabindex="0" class="om on di oo bf op"><div class="gh gi oy"><img src="../Images/ba56b96888cd235d75105a2041c85d94.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*vPY6ksSSmLTUSazX-dzG-g.png"/></div></div><figcaption class="os ot gj gh gi ou ov bd b be z dk translated">最佳验证准确度图</figcaption></figure><h2 id="5973" class="my ks it bd kt mz na dn kx nb nc dp lb ls nd ne ld lw nf ng lf ma nh ni lh iz bi translated">比较得出的结论</h2><p id="032a" class="pw-post-body-paragraph lj lk it ll b lm ln kd lo lp lq kg lr ls lt lu lv lw lx ly lz ma mb mc md me im bi translated">从上面的图表中，我们可以得出结论，Mobilenet给了我们最好的验证精度，而Resnet50在训练5个时期时给了我们最好的训练精度。</p><p id="66db" class="pw-post-body-paragraph lj lk it ll b lm mh kd lo lp mi kg lr ls mv lu lv lw mw ly lz ma mx mc md me im bi translated">从训练精度曲线可以清楚地看出，Vgg16的性能过早饱和，其原因是Resnet50在执行身份映射时克服了消失梯度问题。</p><h1 id="13fd" class="kr ks it bd kt ku kv kw kx ky kz la lb ki lc kj ld kl le km lf ko lg kp lh li bi translated">暗示</h1><p id="ee0a" class="pw-post-body-paragraph lj lk it ll b lm ln kd lo lp lq kg lr ls lt lu lv lw lx ly lz ma mb mc md me im bi translated">为了进行多标签分类并预测所有14种疾病的置信分数，我们以评估模式加载实验。</p><pre class="nv nw nx ny gt nz oa ob oc aw od bi"><span id="41f7" class="my ks it oa b gy oe of l og oh">gpf = prototype(verbose=1)</span><span id="3b55" class="my ks it oa b gy oj of l og oh">gpf.Prototype("Pilot-1", "keras_resnet50", eval_infer=True);</span><span id="b3ea" class="my ks it oa b gy oj of l og oh">prediction=gpf.Infer(img_name="sample/images/00000013_005.png",return_raw=True)</span></pre><figure class="nv nw nx ny gt ol gh gi paragraph-image"><div role="button" tabindex="0" class="om on di oo bf op"><div class="gh gi ok"><img src="../Images/30914691e95cf45c00f5aa65f3548a17.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*lwfHLyjQKXfrxlzDEnrTPw.png"/></div></div><figcaption class="os ot gj gh gi ou ov bd b be z dk translated">来自Kaggle的x射线图像用作推断输入</figcaption></figure><figure class="nv nw nx ny gt ol gh gi paragraph-image"><div role="button" tabindex="0" class="om on di oo bf op"><div class="gh gi oz"><img src="../Images/e389ebfcf72157534ee8497bd245b399.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*oeagvibhRp-IGt-XS9s3DA.png"/></div></div><figcaption class="os ot gj gh gi ou ov bd b be z dk translated">推理的结果</figcaption></figure></div><div class="ab cl nj nk hx nl" role="separator"><span class="nm bw bk nn no np"/><span class="nm bw bk nn no np"/><span class="nm bw bk nn no"/></div><div class="im in io ip iq"><p id="3dd8" class="pw-post-body-paragraph lj lk it ll b lm mh kd lo lp mi kg lr ls mv lu lv lw mw ly lz ma mx mc md me im bi translated">Monk使我们的工作不那么单调乏味，而且更加高效，我们用比选择传统方法更少的代码行完成了所有三项任务。我们甚至可以针对同一个分类示例使用其他模型，并尝试获得理想的结果。</p></div></div>    
</body>
</html>