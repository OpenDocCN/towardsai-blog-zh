<html>
<head>
<title>Neural Entity Linking at JPMorgan Chase</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">摩根大通的神经实体链接</h1>
<blockquote>原文：<a href="https://pub.towardsai.net/neural-entity-linking-in-jpmorgan-chase-29b7f0b7373e?source=collection_archive---------1-----------------------#2022-08-02">https://pub.towardsai.net/neural-entity-linking-in-jpmorgan-chase-29b7f0b7373e?source=collection_archive---------1-----------------------#2022-08-02</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><div class=""><h2 id="77e2" class="pw-subtitle-paragraph jn ip iq bd b jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke dk translated"><em class="kf"> JPMC在2021年发表了一篇</em><a class="ae kg" href="https://ojs.aaai.org/index.php/AAAI/article/view/17796" rel="noopener ugc nofollow" target="_blank"><em class="kf"/></a><em class="kf">的论文，突出强调了他们对</em> <strong class="ak"> <em class="kf">实体的衔接</em> </strong> <em class="kf">。本文总结了问题陈述、解决方案和论文的其他关键技术组成部分</em></h2></div><figure class="ki kj kk kl gt km gh gi paragraph-image"><div role="button" tabindex="0" class="kn ko di kp bf kq"><div class="gh gi kh"><img src="../Images/d28c064d2724052a000b7dad985040e0.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*qmV9pcxY3hKhGvMAEkGYkQ.png"/></div></div></figure></div><div class="ab cl kt ku hu kv" role="separator"><span class="kw bw bk kx ky kz"/><span class="kw bw bk kx ky kz"/><span class="kw bw bk kx ky"/></div><div class="ij ik il im in"><h1 id="22eb" class="la lb iq bd lc ld le lf lg lh li lj lk jw ll jx lm jz ln ka lo kc lp kd lq lr bi translated">什么是实体链接？</h1><p id="7707" class="pw-post-body-paragraph ls lt iq lu b lv lw jr lx ly lz ju ma mb mc md me mf mg mh mi mj mk ml mm mn ij bi translated">它的任务是给文本中不明确提到的<strong class="lu ir">命名实体</strong>分配一个<strong class="lu ir">唯一标识</strong>。</p><figure class="ki kj kk kl gt km gh gi paragraph-image"><div class="gh gi mo"><img src="../Images/32607506d34a621c6a5b6071893bc461.png" data-original-src="https://miro.medium.com/v2/resize:fit:800/format:webp/0*CHmylOzCVwrrAPBL.png"/></div><figcaption class="mp mq gj gh gi mr ms bd b be z dk translated">从维基百科链接的实体的例子</figcaption></figure><p id="d860" class="pw-post-body-paragraph ls lt iq lu b lv mt jr lx ly mu ju ma mb mv md me mf mw mh mi mj mx ml mm mn ij bi translated">在这里，文本中的“<em class="my"> Paris </em>”通过一个URL(最常见的类型<strong class="lu ir">URI</strong>)”<em class="my">wikipedia.org/wiki/Paris</em>)被赋予了一个唯一的身份。注意，用于标识所提到的实体的URI的类型唯一地依赖于域。例如，如果我们要从文本中识别书籍，我们可以使用ISBNs而不是网址。</p><figure class="ki kj kk kl gt km gh gi paragraph-image"><div role="button" tabindex="0" class="kn ko di kp bf kq"><div class="gh gi mz"><img src="../Images/3e003f01fb46b48d1fcafa60d7102d88.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*iHN_V90IsykXYVA667gqSA.png"/></div></div></figure><p id="eae4" class="pw-post-body-paragraph ls lt iq lu b lv mt jr lx ly mu ju ma mb mv md me mf mw mh mi mj mx ml mm mn ij bi translated">JPMC感兴趣的是:</p><blockquote class="na nb nc"><p id="a874" class="ls lt my lu b lv mt jr lx ly mu ju ma nd mv md me ne mw mh mi nf mx ml mm mn ij bi translated"><strong class="lu ir">从<strong class="lu ir">新闻文章</strong>到存储在其内部知识库中的实体<strong class="lu ir"> ( </strong>存储为<strong class="lu ir">知识图)</strong>映射金融机构</strong></p></blockquote><p id="3eea" class="pw-post-body-paragraph ls lt iq lu b lv mt jr lx ly mu ju ma mb mv md me mf mw mh mi mj mx ml mm mn ij bi translated">下面显示了一个示例:</p><figure class="ki kj kk kl gt km gh gi paragraph-image"><div role="button" tabindex="0" class="kn ko di kp bf kq"><div class="gh gi ng"><img src="../Images/d163714ff84184f0fbda6dd0fef12e3e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*hDvBCsgyTbtZEEaagjfMyQ.png"/></div></div><figcaption class="mp mq gj gh gi mr ms bd b be z dk translated">论文中的实体链接示例</figcaption></figure><p id="8804" class="pw-post-body-paragraph ls lt iq lu b lv mt jr lx ly mu ju ma mb mv md me mf mw mh mi mj mx ml mm mn ij bi translated">必须定义两个子问题:</p><ol class=""><li id="eadf" class="nh ni iq lu b lv mt ly mu mb nj mf nk mj nl mn nm nn no np bi translated"><strong class="lu ir">识别</strong> : <br/>从财经新闻文章中提取提及。JPMC为此使用了空间。</li><li id="919d" class="nh ni iq lu b lv nq ly nr mb ns mf nt mj nu mn nm nn no np bi translated"><strong class="lu ir">链接:<br/> </strong>从内部知识图中选择正确的实体链接到上一步提取的提及。本文讨论了这一步骤。</li></ol><p id="da72" class="pw-post-body-paragraph ls lt iq lu b lv mt jr lx ly mu ju ma mb mv md me mf mw mh mi mj mx ml mm mn ij bi translated">这种情况的图示如下所示:</p><figure class="ki kj kk kl gt km gh gi paragraph-image"><div role="button" tabindex="0" class="kn ko di kp bf kq"><div class="gh gi nv"><img src="../Images/af4d83d0bea54acd2e26db16aaa41861.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*gVIgRcoixCbykk5YAoHBzA.png"/></div></div><figcaption class="mp mq gj gh gi mr ms bd b be z dk translated">(图片由作者提供)作为整体解决方案一部分的子问题</figcaption></figure><figure class="ki kj kk kl gt km gh gi paragraph-image"><div role="button" tabindex="0" class="kn ko di kp bf kq"><div class="gh gi nw"><img src="../Images/5d574dd07f513a6e9f34791cf35274b4.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*dZPI17SuHJVIcDSobQWY6Q.png"/></div></div></figure><ol class=""><li id="6289" class="nh ni iq lu b lv mt ly mu mb nj mf nk mj nl mn nm nn no np bi translated"><strong class="lu ir">字符串匹配<br/> </strong>这些方法捕捉实体名称的“形态”结构。团队用<br/>(a)<strong class="lu ir">【JAC card】</strong><br/>(b)<strong class="lu ir">Levenshtein</strong><br/>(c)<strong class="lu ir">Ratcliff-Obershelp</strong>(也称为<em class="my">完形-模式匹配</em>)<strong class="lu ir"><br/></strong>(d)<strong class="lu ir">Jaro Winkler<br/></strong>(e)<strong class="lu ir">N-Gram余弦相似度</strong></li></ol><p id="23ea" class="pw-post-body-paragraph ls lt iq lu b lv mt jr lx ly mu ju ma mb mv md me mf mw mh mi mj mx ml mm mn ij bi translated">这些方法的缺点是它们只关注名称的语法，而不是语义。失败案例的一个例子是“Lumier”和“Lumier”的匹配。尽管它们完全相同，但它们指的是两个不同的实体。</p><p id="dc7a" class="pw-post-body-paragraph ls lt iq lu b lv mt jr lx ly mu ju ma mb mv md me mf mw mh mi mj mx ml mm mn ij bi translated"><strong class="lu ir"> 2。上下文相似性方法<br/> </strong>这些方法采用提及和实体周围的上下文来给出相似性分数。<br/>“提及”的上下文是提及左边和右边的文本，而<br/>“实体”的上下文是存储在KG中该实体的所有数据。<br/>最后，余弦相似度/雅克卡相似度可以用在上下文向量之上。</p><p id="c097" class="pw-post-body-paragraph ls lt iq lu b lv mt jr lx ly mu ju ma mb mv md me mf mw mh mi mj mx ml mm mn ij bi translated"><strong class="lu ir"> 3。最大似然分类<br/> </strong>朴素贝叶斯、逻辑回归和SVM在(提及、实体)对上被训练，以找到应该被链接的那些</p><p id="969f" class="pw-post-body-paragraph ls lt iq lu b lv mt jr lx ly mu ju ma mb mv md me mf mw mh mi mj mx ml mm mn ij bi translated"><strong class="lu ir"> 4。学习排列方法(LTR) <br/> </strong>这些模型与ML方法协同工作，这可能给我们多个(提及，实体)对作为解决方案。LTR方法只是缩小到最可能的解决方案。</p><figure class="ki kj kk kl gt km gh gi paragraph-image"><div role="button" tabindex="0" class="kn ko di kp bf kq"><div class="gh gi nx"><img src="../Images/d805b20465b952d2e8f4682109de7404.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*vxTWtKjqYvUoBVEkctGGrw.png"/></div></div></figure><p id="4381" class="pw-post-body-paragraph ls lt iq lu b lv mt jr lx ly mu ju ma mb mv md me mf mw mh mi mj mx ml mm mn ij bi translated">其思想是捕获姓名之间的语义距离(语义距离)和句法距离，并使用对比损失函数来训练模型。</p><figure class="ki kj kk kl gt km gh gi paragraph-image"><div role="button" tabindex="0" class="kn ko di kp bf kq"><div class="gh gi ny"><img src="../Images/3f5eb55b1b6527c87020f6d70e442ccf.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*_BMCtCbwgrquAolYfUqzNw.png"/></div></div></figure><p id="fe67" class="pw-post-body-paragraph ls lt iq lu b lv mt jr lx ly mu ju ma mb mv md me mf mw mh mi mj mx ml mm mn ij bi translated">我们将在下面看到这两个距离是如何逐步计算的。</p><h1 id="e0aa" class="la lb iq bd lc ld nz lf lg lh oa lj lk jw ob jx lm jz oc ka lo kc od kd lq lr bi translated">步骤1:获取实体和提及的嵌入</h1><p id="8c93" class="pw-post-body-paragraph ls lt iq lu b lv lw jr lx ly lz ju ma mb mc md me mf mg mh mi mj mk ml mm mn ij bi translated">为了得出这两个距离，作者建议在KG中使用<em class="my">提及</em>以及<em class="my">实体</em>的嵌入。</p><p id="d6d1" class="pw-post-body-paragraph ls lt iq lu b lv mt jr lx ly mu ju ma mb mv md me mf mw mh mi mj mx ml mm mn ij bi translated">为了获得<strong class="lu ir"> <em class="my">实体</em>嵌入</strong>，作者使用了一个<strong class="lu ir">三重损失函数</strong>(如下所示)</p><figure class="ki kj kk kl gt km gh gi paragraph-image"><div role="button" tabindex="0" class="kn ko di kp bf kq"><div class="gh gi oe"><img src="../Images/7dfbe10440888c2c2b9f7befc3891400.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*85uveF8KElyOCKfBYwnMVw.png"/></div></div><figcaption class="mp mq gj gh gi mr ms bd b be z dk translated">三重损失函数</figcaption></figure><p id="8501" class="pw-post-body-paragraph ls lt iq lu b lv mt jr lx ly mu ju ma mb mv md me mf mw mh mi mj mx ml mm mn ij bi translated">对于每个实体，他们使用10个阳性和10个阴性样本，使得<strong class="lu ir"> 10个&lt;实体、阳性词、阴性词&gt;三个一组</strong>。</p><figure class="ki kj kk kl gt km gh gi paragraph-image"><div role="button" tabindex="0" class="kn ko di kp bf kq"><div class="gh gi of"><img src="../Images/b95b31069d5775266d1d06b17deb33d9.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*BzDHnlChuHktMWhDoj-ZsA.png"/></div></div><figcaption class="mp mq gj gh gi mr ms bd b be z dk translated">实体嵌入模型</figcaption></figure><p id="f189" class="pw-post-body-paragraph ls lt iq lu b lv mt jr lx ly mu ju ma mb mv md me mf mw mh mi mj mx ml mm mn ij bi translated">与他们预先计算的<em class="my">实体</em>嵌入不同，<strong class="lu ir"><em class="my">提及</em>嵌入</strong>使用实时嵌入方法进行训练，其中嵌入矩阵是在训练过程中学习的。</p><h1 id="aa4e" class="la lb iq bd lc ld nz lf lg lh oa lj lk jw ob jx lm jz oc ka lo kc od kd lq lr bi translated">步骤2:计算句法距离得分</h1><p id="f7ad" class="pw-post-body-paragraph ls lt iq lu b lv lw jr lx ly lz ju ma mb mc md me mf mg mh mi mj mk ml mm mn ij bi translated">在更进一步之前，值得一提的是谷歌在2016年推出的<strong class="lu ir">“宽&amp;深】架构</strong>。你可以在这里找到他们的官方博客<a class="ae kg" href="https://ai.googleblog.com/2016/06/wide-deep-learning-better-together-with.html" rel="noopener ugc nofollow" target="_blank">。我们不会深入细节，但总结一下，这是一个包含两个组件的体系结构——宽组件和深组件。</a></p><figure class="ki kj kk kl gt km gh gi paragraph-image"><div role="button" tabindex="0" class="kn ko di kp bf kq"><div class="gh gi og"><img src="../Images/469dc3bd0ba82c3cdb8ee5a9de587608.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*juVEQwlx7eelwW4YdMJA6Q.png"/></div></div><figcaption class="mp mq gj gh gi mr ms bd b be z dk translated">图片来自<a class="ae kg" href="https://arxiv.org/pdf/1606.07792.pdf" rel="noopener ugc nofollow" target="_blank">谷歌论文</a> |宽深度模型谱</figcaption></figure><p id="6484" class="pw-post-body-paragraph ls lt iq lu b lv mt jr lx ly mu ju ma mb mv md me mf mw mh mi mj mx ml mm mn ij bi translated"><strong class="lu ir">句法</strong> <strong class="lu ir">距离</strong>分数计算使用宽部分完成，宽部分由一个<strong class="lu ir">线性连体网络组成。</strong></p><figure class="ki kj kk kl gt km gh gi paragraph-image"><div role="button" tabindex="0" class="kn ko di kp bf kq"><div class="gh gi oh"><img src="../Images/a395834be5614bd2e3e45a0caf7d07e9.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*ccZTh7Kr1zV4dd7gEyS-nQ.png"/></div></div><figcaption class="mp mq gj gh gi mr ms bd b be z dk translated">句法距离得分的计算</figcaption></figure><p id="182b" class="pw-post-body-paragraph ls lt iq lu b lv mt jr lx ly mu ju ma mb mv md me mf mw mh mi mj mx ml mm mn ij bi translated">暹罗网络的输出是针对<em class="my">实体</em>和<em class="my">提及</em>的向量，然后对其进行比较以找到欧几里德距离。</p><figure class="ki kj kk kl gt km gh gi paragraph-image"><div class="ab gu cl oi"><img src="../Images/de1851a7d3281153c0f4d0d57345008c.png" data-original-src="https://miro.medium.com/v2/format:webp/1*qGToxmm18eD4uJMCUGKnAg.png"/></div></figure><h1 id="79f6" class="la lb iq bd lc ld nz lf lg lh oa lj lk jw ob jx lm jz oc ka lo kc od kd lq lr bi translated">步骤3:计算语义距离得分</h1><p id="b0a5" class="pw-post-body-paragraph ls lt iq lu b lv lw jr lx ly lz ju ma mb mc md me mf mg mh mi mj mk ml mm mn ij bi translated"><strong class="lu ir">语义</strong> <strong class="lu ir">距离</strong>得分计算是使用深度部分完成的</p><figure class="ki kj kk kl gt km gh gi paragraph-image"><div role="button" tabindex="0" class="kn ko di kp bf kq"><div class="gh gi oj"><img src="../Images/9907ca9771cab0121b751b441f13de4e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*5y-h1JTIpfKGzAWhhg5WCw.png"/></div></div><figcaption class="mp mq gj gh gi mr ms bd b be z dk translated">语义距离得分的计算</figcaption></figure><p id="bc05" class="pw-post-body-paragraph ls lt iq lu b lv mt jr lx ly mu ju ma mb mv md me mf mw mh mi mj mx ml mm mn ij bi translated"><strong class="lu ir"> eₖ </strong>是步骤1中计算的“Apache Corp”的预训练嵌入。为了获得对<em class="my">提及</em>的嵌入，它的左右上下文单词被输入到训练嵌入的双LSTM网络中。<em class="my">提及</em><strong class="lu ir">【vₘ】</strong>和<em class="my">实体</em> ( <strong class="lu ir"> Vₑ) </strong>的嵌入向量随后被用于寻找欧几里德距离:</p><figure class="ki kj kk kl gt km gh gi paragraph-image"><div class="gh gi ok"><img src="../Images/0c3118bf85bb3e03de07f407b359ee8d.png" data-original-src="https://miro.medium.com/v2/resize:fit:808/format:webp/1*zULLB7DBUffngEU_z4WNRA.png"/></div></figure><h1 id="7ba2" class="la lb iq bd lc ld nz lf lg lh oa lj lk jw ob jx lm jz oc ka lo kc od kd lq lr bi translated">步骤4:计算对比损失</h1><p id="4268" class="pw-post-body-paragraph ls lt iq lu b lv lw jr lx ly lz ju ma mb mc md me mf mg mh mi mj mk ml mm mn ij bi translated">句法距离和语义距离以如下加权方式组合:</p><figure class="ki kj kk kl gt km gh gi paragraph-image"><div role="button" tabindex="0" class="kn ko di kp bf kq"><div class="gh gi ol"><img src="../Images/131fac18d85665617f53ec8e7a64ba55.png" data-original-src="https://miro.medium.com/v2/resize:fit:594/format:webp/1*GGJty9pCBxGY-xxntv6Qrw.png"/></div></div></figure><p id="fb9a" class="pw-post-body-paragraph ls lt iq lu b lv mt jr lx ly mu ju ma mb mv md me mf mw mh mi mj mx ml mm mn ij bi translated">对比损失函数然后被组合如下:</p><figure class="ki kj kk kl gt km gh gi paragraph-image"><div class="gh gi om"><img src="../Images/ce03e233a2f2b207c55a6a88a53e1252.png" data-original-src="https://miro.medium.com/v2/resize:fit:930/format:webp/1*f4o8w6qFI4EI9uHnk8V_Wg.png"/></div><figcaption class="mp mq gj gh gi mr ms bd b be z dk translated">对比损失函数</figcaption></figure><p id="da4b" class="pw-post-body-paragraph ls lt iq lu b lv mt jr lx ly mu ju ma mb mv md me mf mw mh mi mj mx ml mm mn ij bi translated">其中Y是基础真值，值1表示提及m和实体e匹配，否则为0。</p><p id="f284" class="pw-post-body-paragraph ls lt iq lu b lv mt jr lx ly mu ju ma mb mv md me mf mw mh mi mj mx ml mm mn ij bi translated">结合所有的部分，最终的模型框架如下所示:</p><figure class="ki kj kk kl gt km gh gi paragraph-image"><div role="button" tabindex="0" class="kn ko di kp bf kq"><div class="gh gi on"><img src="../Images/28c9562a5ce5bc1c68b1fc28dbb95c32.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*9KKcT0tuGLAOtOUiktub8Q.png"/></div></div><figcaption class="mp mq gj gh gi mr ms bd b be z dk translated">JEL模型框架</figcaption></figure><figure class="ki kj kk kl gt km gh gi paragraph-image"><div class="gh gi oo"><img src="../Images/9111a15ea48d143ec09a21cc815f46bd.png" data-original-src="https://miro.medium.com/v2/resize:fit:1370/format:webp/1*lmn3wEI7YQadaFDl1QB3bA.png"/></div></figure><p id="4458" class="pw-post-body-paragraph ls lt iq lu b lv mt jr lx ly mu ju ma mb mv md me mf mw mh mi mj mx ml mm mn ij bi translated">在撰写本文时，JPMC仍在部署该模型，一旦完成，将有助于支持JPMC各地的用户发现对其业务至关重要的相关和精选新闻。</p><p id="af54" class="pw-post-body-paragraph ls lt iq lu b lv mt jr lx ly mu ju ma mb mv md me mf mw mh mi mj mx ml mm mn ij bi translated">从成本的角度来看，并不是所有的提及都通过JEL框架，因为这将是计算上昂贵的。JPMC设置了另一个阻挡层来过滤那些与实体内部KGs共享不到2个二元模型的提及。</p><p id="e21c" class="pw-post-body-paragraph ls lt iq lu b lv mt jr lx ly mu ju ma mb mv md me mf mw mh mi mj mx ml mm mn ij bi translated">再次声明，如果你想阅读全文，这里的是论文链接。</p></div><div class="ab cl kt ku hu kv" role="separator"><span class="kw bw bk kx ky kz"/><span class="kw bw bk kx ky kz"/><span class="kw bw bk kx ky"/></div><div class="ij ik il im in"><p id="1a98" class="pw-post-body-paragraph ls lt iq lu b lv mt jr lx ly mu ju ma mb mv md me mf mw mh mi mj mx ml mm mn ij bi translated"><em class="my">跟随</em> <a class="ae kg" href="https://intuitiveshorts.substack.com/" rel="noopener ugc nofollow" target="_blank"> <em class="my">直观短讯</em> </a> <em class="my">(我的Substack简讯)，快速直观的阅读ML/NLP/DS概念的摘要。</em></p></div></div>    
</body>
</html>