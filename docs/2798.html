<html>
<head>
<title>Binary Image Classification with Tensorflow</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">基于张量流的二值图像分类</h1>
<blockquote>原文：<a href="https://pub.towardsai.net/binary-image-classification-with-tensorflow-2cc6555e55e8?source=collection_archive---------0-----------------------#2022-05-30">https://pub.towardsai.net/binary-image-classification-with-tensorflow-2cc6555e55e8?source=collection_archive---------0-----------------------#2022-05-30</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="d490" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated"><em class="ki">在Tensorflow中使用卷积神经网络对猫和狗的图像进行分类</em></h2></div><figure class="kk kl km kn gt ko gh gi paragraph-image"><div role="button" tabindex="0" class="kp kq di kr bf ks"><div class="gh gi kj"><img src="../Images/a7f6894f4b5e7a18eade3200add07689.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*nKQY6DsMqdp-L6T6.jpeg"/></div></div><figcaption class="kv kw gj gh gi kx ky bd b be z dk translated">照片由<a class="ae kz" href="https://unsplash.com/@majomaya?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText" rel="noopener ugc nofollow" target="_blank">颜劳里切塞</a>在<a class="ae kz" href="https://unsplash.com/s/visual/cda11df6-ab49-42a1-a32d-7b6d08b60889?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上拍摄</figcaption></figure><p id="210c" class="pw-post-body-paragraph la lb it lc b ld le ju lf lg lh jx li lj lk ll lm ln lo lp lq lr ls lt lu lv im bi translated">在这篇文章中，我们将看到如何用Tensorflow建立一个二元分类模型来区分图像中的狗和猫。从<a class="ae kz" href="https://www.kaggle.com/competitions/dogs-vs-cats" rel="noopener ugc nofollow" target="_blank"> Kaggle和它的数据集</a>上的一个著名竞赛中得到启示，我们将使用这个任务来学习如何做</p><ul class=""><li id="7984" class="lw lx it lc b ld le lg lh lj ly ln lz lr ma lv mb mc md me bi translated">从web导入压缩数据集</li><li id="1244" class="lw lx it lc b ld mf lg mg lj mh ln mi lr mj lv mb mc md me bi translated">使用卷积图层和最大池构建分类模型</li><li id="588c" class="lw lx it lc b ld mf lg mg lj mh ln mi lr mj lv mb mc md me bi translated">使用ImageDataGenerator创建图像生成器，以有效地管理训练和验证图像</li><li id="7666" class="lw lx it lc b ld mf lg mg lj mh ln mi lr mj lv mb mc md me bi translated">编译和训练模型</li><li id="0927" class="lw lx it lc b ld mf lg mg lj mh ln mi lr mj lv mb mc md me bi translated">在神经网络的各个层中可视化应用于图像的变换</li><li id="5ebf" class="lw lx it lc b ld mf lg mg lj mh ln mi lr mj lv mb mc md me bi translated">对从未见过的图像进行预测</li></ul><p id="c0fe" class="pw-post-body-paragraph la lb it lc b ld le ju lf lg lh jx li lj lk ll lm ln lo lp lq lr ls lt lu lv im bi translated">由于深度学习不是任何家用PC都能负担得起的，我们将使用运行时设置为GPU的Google Colab。</p><h1 id="dcc7" class="mk ml it bd mm mn mo mp mq mr ms mt mu jz mv ka mw kc mx kd my kf mz kg na nb bi translated">从web导入压缩数据集</h1><p id="9268" class="pw-post-body-paragraph la lb it lc b ld nc ju lf lg nd jx li lj ne ll lm ln nf lp lq lr ng lt lu lv im bi translated">我们将使用从Kaggle著名的25000幅图像数据集中提取的3000幅猫和狗的精简数据集。完整的数据集重量超过500MB，将它们上传/下载到Colab可能会令人沮丧。我们将使用这个精简版本，无论如何，它将允许我们有效地测试我们的模型。</p><p id="873b" class="pw-post-body-paragraph la lb it lc b ld le ju lf lg lh jx li lj lk ll lm ln lo lp lq lr ls lt lu lv im bi translated">数据集的URL是:</p><p id="3374" class="pw-post-body-paragraph la lb it lc b ld le ju lf lg lh jx li lj lk ll lm ln lo lp lq lr ls lt lu lv im bi translated"><a class="ae kz" href="https://storage.googleapis.com/mledu-datasets/cats_and_dogs_filtered.zip" rel="noopener ugc nofollow" target="_blank">https://storage . Google APIs . com/mledu-datasets/cats _ and _ dogs _ filtered . zip</a></p><p id="23ba" class="pw-post-body-paragraph la lb it lc b ld le ju lf lg lh jx li lj lk ll lm ln lo lp lq lr ls lt lu lv im bi translated">我们使用<em class="nh"> wget </em>命令将压缩文件下载到我们的文件系统:</p><figure class="kk kl km kn gt ko"><div class="bz fp l di"><div class="ni nj l"/></div></figure><p id="c0c0" class="pw-post-body-paragraph la lb it lc b ld le ju lf lg lh jx li lj lk ll lm ln lo lp lq lr ls lt lu lv im bi translated">通过使用wget命令以及os和zip文件包，我们能够高效地下载和组织我们的培训文件。我们现在有了一种指向带有特定变量的文件的方法，我们将在Tensorflow的<em class="nh"> ImageDataGenerator </em>中使用这些变量。</p><p id="9bc5" class="pw-post-body-paragraph la lb it lc b ld le ju lf lg lh jx li lj lk ll lm ln lo lp lq lr ls lt lu lv im bi translated">让我们看一组图像，以便了解我们要分类的内容。</p><figure class="kk kl km kn gt ko gh gi paragraph-image"><div role="button" tabindex="0" class="kp kq di kr bf ks"><div class="gh gi nk"><img src="../Images/8d9d1c7e841b7bc710a50c03faaf53a1.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*UWlWkz67-Usc7eZb.png"/></div></div><figcaption class="kv kw gj gh gi kx ky bd b be z dk translated">我们将要分类的狗和猫的图片的例子。图片作者。</figcaption></figure><p id="5fe7" class="pw-post-body-paragraph la lb it lc b ld le ju lf lg lh jx li lj lk ll lm ln lo lp lq lr ls lt lu lv im bi translated">我们看到这些图像彼此之间是多么的不同，以及有时像人或其他物体这样的外来实体是如何出现在图像中的。我们将建立一个深度学习模型，能够有效区分猫和狗<strong class="lc iu">，尽管有这些外来因素</strong>。</p><p id="1ee8" class="pw-post-body-paragraph la lb it lc b ld le ju lf lg lh jx li lj lk ll lm ln lo lp lq lr ls lt lu lv im bi translated">如果我们使用<em class="nh">len(OS . listdir(train _ cats _ dir))</em>来计算各个文件夹中的图像数量，我们看到它们的数量总计为3000，其中分别有1000张训练中的狗和猫的图像以及500张用于验证的图像。</p><h1 id="eb56" class="mk ml it bd mm mn mo mp mq mr ms mt mu jz mv ka mw kc mx kd my kf mz kg na nb bi translated">卷积和池的简要介绍</h1><p id="8caa" class="pw-post-body-paragraph la lb it lc b ld nc ju lf lg nd jx li lj ne ll lm ln nf lp lq lr ng lt lu lv im bi translated">在我们即将看到的模型中，我们将使用卷积层和池。这两层都广泛用于计算机视觉任务，因为它们应用于输入图像的变换，并有利于神经网络，因为它们通过强调模式中存在的基本特征来帮助它<strong class="lc iu">识别模式。</strong></p><h2 id="7020" class="nl ml it bd mm nm nn dn mq no np dp mu lj nq nr mw ln ns nt my lr nu nv na nw bi translated">盘旋</h2><p id="b2b4" class="pw-post-body-paragraph la lb it lc b ld nc ju lf lg nd jx li lj ne ll lm ln nf lp lq lr ng lt lu lv im bi translated">卷积本质上是一种应用于图像的滤镜。考虑到<strong class="lc iu">像素</strong>级别，也就是我们在讨论图像时要转换的实体，卷积查看其值和其<strong class="lc iu">相邻像素的值，并使用映射到每个像素的网格值来转换目标像素，考虑</strong> d. ‍</p><p id="7a1d" class="pw-post-body-paragraph la lb it lc b ld le ju lf lg lh jx li lj lk ll lm ln lo lp lq lr ls lt lu lv im bi translated">例如，如果我们使用3x3的网格，那么我们将考虑目标像素的所有相邻像素。当我们应用卷积时，目标像素被转换，并取对应于所考虑的每个像素的原始值与卷积网格中相应值的乘积的值。最终值对应于每个乘积的总和。一张图片将有助于更好地理解这个概念:</p><figure class="kk kl km kn gt ko gh gi paragraph-image"><div role="button" tabindex="0" class="kp kq di kr bf ks"><div class="gh gi nx"><img src="../Images/2ed1c72fa51bdd953e328815a90428f0.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*fcWEKrjEHBC-0_-L083bqA.png"/></div></div><figcaption class="kv kw gj gh gi kx ky bd b be z dk translated">卷积在像素上的应用。截图来自Coursera.org。</figcaption></figure><p id="058f" class="pw-post-body-paragraph la lb it lc b ld le ju lf lg lh jx li lj lk ll lm ln lo lp lq lr ls lt lu lv im bi translated">考虑值为192的目标像素，然后应用于它的卷积将认为它周围的所有像素都是邻居，并且它的新值将如下:</p><figure class="kk kl km kn gt ko gh gi paragraph-image"><div class="gh gi ny"><img src="../Images/ab20332bb5a567b6ea157ab3fa6bd20a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1232/format:webp/1*Fxb-L0IM8_JnOWw7Bu_rbA.png"/></div><figcaption class="kv kw gj gh gi kx ky bd b be z dk translated">如何计算新像素值。截图来自Coursera.org。</figcaption></figure><p id="a143" class="pw-post-body-paragraph la lb it lc b ld le ju lf lg lh jx li lj lk ll lm ln lo lp lq lr ls lt lu lv im bi translated">卷积背后的想法是突出图像的特征，例如边缘和轮廓，并使它们比背景更突出。</p><figure class="kk kl km kn gt ko gh gi paragraph-image"><div role="button" tabindex="0" class="kp kq di kr bf ks"><div class="gh gi nz"><img src="../Images/0939cb086c1493b62b815f6ac7951930.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*7etaNb-bjcxoDBKD.png"/></div></div><figcaption class="kv kw gj gh gi kx ky bd b be z dk translated">显示图像中元素的垂直边缘的卷积。截图来自Coursera.org。</figcaption></figure><p id="5018" class="pw-post-body-paragraph la lb it lc b ld le ju lf lg lh jx li lj lk ll lm ln lo lp lq lr ls lt lu lv im bi translated">卷积通常伴随着<em class="nh">池化</em>，这允许神经网络压缩图像并提取其中真正显著的元素。</p><p id="b4af" class="pw-post-body-paragraph la lb it lc b ld le ju lf lg lh jx li lj lk ll lm ln lo lp lq lr ls lt lu lv im bi translated">在Tensorflow中，典型的卷积层应用了<code class="fe oa ob oc od b">tf.keras.layers.Conv2D(filters, kernel_size, activation, **kwargs)</code>。在<em class="nh">过滤器</em>中，我们将插入要应用的卷积过滤器的数量，相反，我们将使用<em class="nh">内核大小</em>指示网格的大小。对于激活，我们将指定激活函数。参数很多，我建议读者最好研究一下<a class="ae kz" href="https://www.tensorflow.org/api_docs/python/tf/keras/layers/Conv2D" rel="noopener ugc nofollow" target="_blank">官方Tensorflow文档</a>上的材料。</p><h2 id="eaee" class="nl ml it bd mm nm nn dn mq no np dp mu lj nq nr mw ln ns nt my lr nu nv na nw bi translated">联营</h2><p id="815f" class="pw-post-body-paragraph la lb it lc b ld nc ju lf lg nd jx li lj ne ll lm ln nf lp lq lr ng lt lu lv im bi translated">汇集意味着对图像进行压缩。例如，如果我们想用Tensorflow应用2D池图层，这将意味着采用目标像素，它下面的一个和它左边的两个，来形成一个四值网格。<strong class="lc iu">这些值中，只有最大值被保留</strong>。</p><figure class="kk kl km kn gt ko gh gi paragraph-image"><div role="button" tabindex="0" class="kp kq di kr bf ks"><div class="gh gi oe"><img src="../Images/c4fd037942c6b8f31ca6d1adb0dcc9ed.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*zXhsJtAS3aDskYos.png"/></div></div><figcaption class="kv kw gj gh gi kx ky bd b be z dk translated">2D统筹机制的一个例子。截图来自Coursera.org。</figcaption></figure><p id="ea31" class="pw-post-body-paragraph la lb it lc b ld le ju lf lg lh jx li lj lk ll lm ln lo lp lq lr ls lt lu lv im bi translated">仔细观察这幅图像，我们可以看到池化是如何将一幅16像素的图像缩减为一幅4像素的图像，以4个像素为一组，取最大的像素，然后重复这个过程。</p><p id="ff94" class="pw-post-body-paragraph la lb it lc b ld le ju lf lg lh jx li lj lk ll lm ln lo lp lq lr ls lt lu lv im bi translated">这种机制在卷积之后<em class="nh">被应用，从而保留了它所突出的特征<strong class="lc iu">并进一步放大了这种效果</strong>。池化也减少了图像的大小，从而加快了神经网络更高级层的训练。</em></p><p id="861e" class="pw-post-body-paragraph la lb it lc b ld le ju lf lg lh jx li lj lk ll lm ln lo lp lq lr ls lt lu lv im bi translated">通常通过取最大值来应用池化，但也有其他逻辑，例如基于平均值和总和的逻辑。</p><p id="22ea" class="pw-post-body-paragraph la lb it lc b ld le ju lf lg lh jx li lj lk ll lm ln lo lp lq lr ls lt lu lv im bi translated">在Tensorflow中，一个典型的池层应用了<code class="fe oa ob oc od b">tf.keras.layers.MaxPooling2D(pool_size, **kwargs)</code>。在<em class="nh"> pool_size </em>中，我们将输入网格的大小。参数很多，我建议读者最好研究一下<a class="ae kz" href="https://keras.io/api/layers/pooling_layers/max_pooling2d/" rel="noopener ugc nofollow" target="_blank">官方Keras文档</a>上的资料。</p><h1 id="306e" class="mk ml it bd mm mn mo mp mq mr ms mt mu jz mv ka mw kc mx kd my kf mz kg na nb bi translated">使用Tensorflow创建模型</h1><p id="7a49" class="pw-post-body-paragraph la lb it lc b ld nc ju lf lg nd jx li lj ne ll lm ln nf lp lq lr ng lt lu lv im bi translated">现在对卷积和池化有了一点了解，让我们继续使用Tensorflow创建一个二进制分类模型，该模型可以利用使狗和猫可识别的特征。我们将使用Tensorflow的顺序API，因为它易于理解和实现。</p><h2 id="7ff2" class="nl ml it bd mm nm nn dn mq no np dp mu lj nq nr mw ln ns nt my lr nu nv na nw bi translated">关于输入形状的一个注记</h2><p id="c3d0" class="pw-post-body-paragraph la lb it lc b ld nc ju lf lg nd jx li lj ne ll lm ln nf lp lq lr ng lt lu lv im bi translated">需要注意的是，我们应该向模型提供<strong class="lc iu">统一尺寸的图像。这个大小是任意的，对于这个模型，我们将使用150x150像素的大小。Tensorflow会将每个图像的大小调整为正方形。既然我们使用彩色图像，我们也应该提供这些信息。因此，input_shape将是(150，150，3)，其中3代表对颜色进行编码的三位信息。我们将很快看到如何通过<em class="nh"> ImageDataGenerator </em>来确保我们的图像是这个尺寸。</strong></p><p id="85bc" class="pw-post-body-paragraph la lb it lc b ld le ju lf lg lh jx li lj lk ll lm ln lo lp lq lr ls lt lu lv im bi translated">让我们看看如何实现神经网络架构。</p><figure class="kk kl km kn gt ko"><div class="bz fp l di"><div class="ni nj l"/></div></figure><p id="a4b4" class="pw-post-body-paragraph la lb it lc b ld le ju lf lg lh jx li lj lk ll lm ln lo lp lq lr ls lt lu lv im bi translated">如前所述，卷积和池化经常一起进行。然而，它们的数量是任意的，我们的工作就是测试最佳组合。也许通过增加或减少层数，性能会提高。理解这一点的唯一方法是通过实验。</p><p id="2602" class="pw-post-body-paragraph la lb it lc b ld le ju lf lg lh jx li lj lk ll lm ln lo lp lq lr ls lt lu lv im bi translated">最后一个神经元的输出最终被馈送到<em class="nh"> sigmoid </em>激活函数，该函数返回0或1。</p><p id="98d5" class="pw-post-body-paragraph la lb it lc b ld le ju lf lg lh jx li lj lk ll lm ln lo lp lq lr ls lt lu lv im bi translated">我们现在使用<em class="nh"> model.summary() </em>来理解神经网络如何转换数据，以及如何将其转换为二进制类。</p><figure class="kk kl km kn gt ko gh gi paragraph-image"><div class="gh gi of"><img src="../Images/b96453efe594e38c4eb6c6d21d1b6706.png" data-original-src="https://miro.medium.com/v2/resize:fit:1268/format:webp/0*rFUd3qMajxE87Qep.png"/></div><figcaption class="kv kw gj gh gi kx ky bd b be z dk translated">model.summary()的结果。图片作者。</figcaption></figure><p id="0c56" class="pw-post-body-paragraph la lb it lc b ld le ju lf lg lh jx li lj lk ll lm ln lo lp lq lr ls lt lu lv im bi translated">让我们看看如何以级联的方式，我们的图像通过卷积被缩小，然后通过合并被进一步压缩。我们必须特别注意输出Shape列，因为它向我们显示了数据在网络中的路径。让我们看看在第一个conv2d层中，输出形状是148，148，64。让我们更深入地分析一下这些信息。为什么如果我们的图像是150x150，神经网络会将148x148的图像作为输入？答案是，我们使用的卷积使用的是3x3的网格。<strong class="lc iu">图像周围的前几个像素没有相邻像素，因此不能应用滤镜</strong>。然后，X和Y轴上的一个像素被移除，图像边距减少1个像素。64代表应用于图像的卷积数。</p><figure class="kk kl km kn gt ko gh gi paragraph-image"><div role="button" tabindex="0" class="kp kq di kr bf ks"><div class="gh gi og"><img src="../Images/e909ee76023c9a3ad65ff47e716a418c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*IIpXeMKCLipQ74yQ.png"/></div></div><figcaption class="kv kw gj gh gi kx ky bd b be z dk translated">卷积从图像中移除1像素的外部边距。这张截图来自Coursera.org。</figcaption></figure><p id="d2b7" class="pw-post-body-paragraph la lb it lc b ld le ju lf lg lh jx li lj lk ll lm ln lo lp lq lr ls lt lu lv im bi translated">在第一次卷积之后，我们可以看到max pooling层如何缩小图像的大小，正好缩小一半。这个过程一直继续，直到我们到达<em class="nh">展平</em>层，它将该点的输出展平成一个矢量。这被馈送到一个由512个神经元组成的密集层，然后到达网络的末端，只有一个输出，0或1。</p><p id="5691" class="pw-post-body-paragraph la lb it lc b ld le ju lf lg lh jx li lj lk ll lm ln lo lp lq lr ls lt lu lv im bi translated">为了告诉Tensorflow模型架构已经完成，我们需要使用<em class="nh"> compile </em>命令。我们将使用Adam优化器(一种二元交叉熵损失函数)和准确性作为性能指标。</p><figure class="kk kl km kn gt ko"><div class="bz fp l di"><div class="ni nj l"/></div></figure><p id="11db" class="pw-post-body-paragraph la lb it lc b ld le ju lf lg lh jx li lj lk ll lm ln lo lp lq lr ls lt lu lv im bi translated">现在让我们继续编写要提供给模型的<strong class="lc iu">图像预处理管道</strong>。</p><h1 id="1ec2" class="mk ml it bd mm mn mo mp mq mr ms mt mu jz mv ka mw kc mx kd my kf mz kg na nb bi translated">图像预处理</h1><p id="18d0" class="pw-post-body-paragraph la lb it lc b ld nc ju lf lg nd jx li lj ne ll lm ln nf lp lq lr ng lt lu lv im bi translated">下一步是预处理图像，以确保它们在形状上是一致的。<strong class="lc iu">无论原始大小如何，它们都将被调整大小</strong>，转换为float64，并与它们的标签(狗或猫)相关联。这些信息将被传递给模型。我们将创建两个生成器:一个用于训练，一个用于验证。此外，其中的每一个都将图像转换成0到255之间的标准化数值。255是像素的最大值，因此强度为255的像素将变为1，而“关”像素将为0，并且将包括每个中间值。介于0和1之间。</p><p id="7879" class="pw-post-body-paragraph la lb it lc b ld le ju lf lg lh jx li lj lk ll lm ln lo lp lq lr ls lt lu lv im bi translated">酷的是，这都是在内存中完成的，所以我们在磁盘上的原始图像不会受到影响。</p><p id="a03f" class="pw-post-body-paragraph la lb it lc b ld le ju lf lg lh jx li lj lk ll lm ln lo lp lq lr ls lt lu lv im bi translated">在Tensorflow中，所有这些都是用<strong class="lc iu"><em class="nh">imagedata generator</em></strong>完成的。ImageDataGenerator如此强大的一个特点是，它根据包含图像的文件夹的层次结构和命名方式，自动为我们的图像生成标签。</p><figure class="kk kl km kn gt ko gh gi paragraph-image"><div role="button" tabindex="0" class="kp kq di kr bf ks"><div class="gh gi oh"><img src="../Images/082a08cf4f1077bc1855b50ab506a191.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*cbaL0CYQBn3oBp_R.png"/></div></div><figcaption class="kv kw gj gh gi kx ky bd b be z dk translated">ImageDataGenerator根据图像在专用文件夹中的位置自动为图像分配标签。截图来自Coursera.org。</figcaption></figure><p id="7248" class="pw-post-body-paragraph la lb it lc b ld le ju lf lg lh jx li lj lk ll lm ln lo lp lq lr ls lt lu lv im bi translated">让我们看看如何用Python实现这些生成器。这些现在将用于训练模型，但我们不应该担心手动调整图像或做标记。这都是Tensorflow做的；)</p><figure class="kk kl km kn gt ko"><div class="bz fp l di"><div class="ni nj l"/></div></figure><h1 id="eb5c" class="mk ml it bd mm mn mo mp mq mr ms mt mu jz mv ka mw kc mx kd my kf mz kg na nb bi translated">模特培训</h1><p id="95b1" class="pw-post-body-paragraph la lb it lc b ld nc ju lf lg nd jx li lj ne ll lm ln nf lp lq lr ng lt lu lv im bi translated">我们将在2000张图像上训练模型，并在1000张图像上验证它。我们将这样做15个时期。</p><figure class="kk kl km kn gt ko"><div class="bz fp l di"><div class="ni nj l"/></div></figure><p id="5b91" class="pw-post-body-paragraph la lb it lc b ld le ju lf lg lh jx li lj lk ll lm ln lo lp lq lr ls lt lu lv im bi translated"><em class="nh"> Steps_per_epoch </em>表示为一个epoch选择的批次数量。如果选择500个步骤，网络将使用500个批次来完成一个时期。让我们看看模特在训练时的表现。</p><figure class="kk kl km kn gt ko gh gi paragraph-image"><div role="button" tabindex="0" class="kp kq di kr bf ks"><div class="gh gi oi"><img src="../Images/2f6bd813e35cb8952361d621544e60ef.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*ZSHTdhyoKED0WbnZ.png"/></div></div><figcaption class="kv kw gj gh gi kx ky bd b be z dk translated">模型训练结果。图片作者。</figcaption></figure><p id="6650" class="pw-post-body-paragraph la lb it lc b ld le ju lf lg lh jx li lj lk ll lm ln lo lp lq lr ls lt lu lv im bi translated">让我们看看我们的模型在验证集上的准确率是如何达到71%左右的。不错，但也不太好——在这样一个小数据集上，71%在我看来是令人满意的！增加图像的数量肯定会给出更可靠的结果。</p><h1 id="1002" class="mk ml it bd mm mn mo mp mq mr ms mt mu jz mv ka mw kc mx kd my kf mz kg na nb bi translated">可视化神经表征</h1><p id="89b0" class="pw-post-body-paragraph la lb it lc b ld nc ju lf lg nd jx li lj ne ll lm ln nf lp lq lr ng lt lu lv im bi translated">最有趣的事情之一是看看卷积神经网络如何从图像中提取重要信息，并在图像通过各层时将其表示出来。我们将使用一个Keras模型来完成这项工作，并将之前训练的卷积模型的输入传递给它。这段代码有点高级，所以可以随意跳过它或者直接运行它以获得输出(这非常酷！)</p><figure class="kk kl km kn gt ko"><div class="bz fp l di"><div class="ni nj l"/></div></figure><p id="1e5d" class="pw-post-body-paragraph la lb it lc b ld le ju lf lg lh jx li lj lk ll lm ln lo lp lq lr ls lt lu lv im bi translated">这是结果</p><figure class="kk kl km kn gt ko gh gi paragraph-image"><div role="button" tabindex="0" class="kp kq di kr bf ks"><div class="gh gi oj"><img src="../Images/3b7754765d401410a2a48b760161b3a5.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*gdGAkcoVUO-afofz.png"/></div></div><figcaption class="kv kw gj gh gi kx ky bd b be z dk translated">神经网络中卷积和汇集的中间表示。图片作者。</figcaption></figure><p id="aa95" class="pw-post-body-paragraph la lb it lc b ld le ju lf lg lh jx li lj lk ll lm ln lo lp lq lr ls lt lu lv im bi translated">我们看到最显著的特征是如何从一层传递到另一层的。我们注意到耳朵、眼睛和口鼻是如何突出并构成了狗的特征。这些特征在层中的所有(或几乎所有)表示中保持，并用于使神经网络理解狗的样子。很有意思！</p><p id="4ebb" class="pw-post-body-paragraph la lb it lc b ld le ju lf lg lh jx li lj lk ll lm ln lo lp lq lr ls lt lu lv im bi translated">这种可视化神经网络表示的技术是有用的，因为它帮助我们理解卷积和池化带来了什么。如果有问题，这是第一个要找的地方。例如，网络可能会突出非固有特征，导致其误读预测。在这种情况下，手动分析是必须的，我们应该对网络架构采取行动。</p><h1 id="7eb7" class="mk ml it bd mm mn mo mp mq mr ms mt mu jz mv ka mw kc mx kd my kf mz kg na nb bi translated">模型评估</h1><p id="b4e9" class="pw-post-body-paragraph la lb it lc b ld nc ju lf lg nd jx li lj ne ll lm ln nf lp lq lr ng lt lu lv im bi translated">在继续对新的、看不见的图像进行预测之前，让我们编写一些代码来绘制模型评估指标——损失和准确性。</p><figure class="kk kl km kn gt ko"><div class="bz fp l di"><div class="ni nj l"/></div></figure><p id="3f57" class="pw-post-body-paragraph la lb it lc b ld le ju lf lg lh jx li lj lk ll lm ln lo lp lq lr ls lt lu lv im bi translated">下面是结果——<strong class="lc iu">在训练集中肯定有一些过度配合</strong>。如前所述，这是因为数据集很小。在第二个历元之后，训练准确度已经快速达到95–99%之间的准确度。当一个模型暴露于太少的例子<strong class="lc iu">时，过度拟合就会发生，因为它学习的模式不能推广到新的数据</strong>——也就是当模型开始使用不相关的特征来进行预测的时候。</p><p id="4c2c" class="pw-post-body-paragraph la lb it lc b ld le ju lf lg lh jx li lj lk ll lm ln lo lp lq lr ls lt lu lv im bi translated">过度适应是机器学习中的头号问题，这是一个你在这个领域会经常遇到的术语。作为分析师，我们的首要目标是避免过度拟合，并使模型尽可能通用。</p><figure class="kk kl km kn gt ko gh gi paragraph-image"><div class="gh gi ok"><img src="../Images/1565c18e0a1bea4515cb2fc3c303ab4f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1220/format:webp/0*e1mJ1OQ1qVZrmaqh.png"/></div><figcaption class="kv kw gj gh gi kx ky bd b be z dk translated">训练和验证集中的损失和准确性趋势。图片作者。</figcaption></figure><h1 id="d4c6" class="mk ml it bd mm mn mo mp mq mr ms mt mu jz mv ka mw kc mx kd my kf mz kg na nb bi translated">新图像的预测</h1><p id="748e" class="pw-post-body-paragraph la lb it lc b ld nc ju lf lg nd jx li lj ne ll lm ln nf lp lq lr ng lt lu lv im bi translated">我们得出了这篇文章的结论。感谢您的关注！如果你喜欢，记得留下评论或与同事分享这篇文章:)现在让我们看看如何将图像上传到Colab，并使用我们的预测模型使用它进行分类。</p><p id="599d" class="pw-post-body-paragraph la lb it lc b ld le ju lf lg lh jx li lj lk ll lm ln lo lp lq lr ls lt lu lv im bi translated">我们将使用这张拉布拉多小狗的图片来测试模型。</p><figure class="kk kl km kn gt ko gh gi paragraph-image"><div role="button" tabindex="0" class="kp kq di kr bf ks"><div class="gh gi kj"><img src="../Images/61b0711d80196e3ff703f0de705ed1d3.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*kwQEu89wwhCTC9US.jpeg"/></div></div><figcaption class="kv kw gj gh gi kx ky bd b be z dk translated">测试模型的图像。</figcaption></figure><p id="5fde" class="pw-post-body-paragraph la lb it lc b ld le ju lf lg lh jx li lj lk ll lm ln lo lp lq lr ls lt lu lv im bi translated">这是代码</p><figure class="kk kl km kn gt ko"><div class="bz fp l di"><div class="ni nj l"/></div></figure><p id="80ce" class="pw-post-body-paragraph la lb it lc b ld le ju lf lg lh jx li lj lk ll lm ln lo lp lq lr ls lt lu lv im bi translated">最后，这是我们模型的正确预测！</p><figure class="kk kl km kn gt ko gh gi paragraph-image"><div class="gh gi ol"><img src="../Images/d05b00eeffe27f49522e7d1c861e21e0.png" data-original-src="https://miro.medium.com/v2/resize:fit:1366/format:webp/0*DSUIvss4OAAKo4_m.png"/></div><figcaption class="kv kw gj gh gi kx ky bd b be z dk translated">该图像被正确地分类为一只狗。图片由作者提供。</figcaption></figure><div class="om on gp gr oo op"><a href="https://medium.com/mlearning-ai/mlearning-ai-submission-suggestions-b51e2b130bfb" rel="noopener follow" target="_blank"><div class="oq ab fo"><div class="or ab os cl cj ot"><h2 class="bd iu gy z fp ou fr fs ov fu fw is bi translated">Mlearning.ai提交建议</h2><div class="ow l"><h3 class="bd b gy z fp ou fr fs ov fu fw dk translated">如何成为Mlearning.ai上的作家</h3></div><div class="ox l"><p class="bd b dl z fp ou fr fs ov fu fw dk translated">medium.com</p></div></div><div class="oy l"><div class="oz l pa pb pc oy pd kt op"/></div></div></a></div></div></div>    
</body>
</html>