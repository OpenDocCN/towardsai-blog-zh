<html>
<head>
<title>Introduction to Bayesian Inference</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">贝叶斯推理简介</h1>
<blockquote>原文：<a href="https://pub.towardsai.net/bayesian-inference-how-missing-values-causes-biased-estimates-31d31c4aaf25?source=collection_archive---------0-----------------------#2020-09-29">https://pub.towardsai.net/bayesian-inference-how-missing-values-causes-biased-estimates-31d31c4aaf25?source=collection_archive---------0-----------------------#2020-09-29</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><h2 id="5e61" class="ir is it bd b dl iu iv iw ix iy iz dk ja translated" aria-label="kicker paragraph"><a class="ae ep" href="https://towardsai.net/p/category/data-science" rel="noopener ugc nofollow" target="_blank">数据科学</a></h2><div class=""/><div class=""><h2 id="9567" class="pw-subtitle-paragraph jz jc it bd b ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq dk translated">第6部分:当缺失数据导致有偏差的估计时</h2></div><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi kr"><img src="../Images/04cbecf61b6c9580fa36659e30e2649a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*74pcn8IBbG-Ik4FjAB-rkA.png"/></div></div></figure><h1 id="2a3e" class="ld le it bd lf lg lh li lj lk ll lm ln ki lo kj lp kl lq km lr ko ls kp lt lu bi translated">介绍</h1><p id="9794" class="pw-post-body-paragraph lv lw it lx b ly lz kd ma mb mc kg md me mf mg mh mi mj mk ml mm mn mo mp mq im bi translated">在本文中，我将通过在缺失值机制不同的4个场景中处理一个公共数据集，展示缺失值如何导致有偏差的估计。本文内容基于[1]中的第15章。</p><p id="adff" class="pw-post-body-paragraph lv lw it lx b ly mr kd ma mb ms kg md me mt mg mh mi mu mk ml mm mv mo mp mq im bi translated">重现本文结果的代码可以在这个<a class="ae mw" href="https://github.com/hsm207/statrethinking-julia/blob/master/book/15_Missing_Data/missing.ipynb" rel="noopener ugc nofollow" target="_blank">笔记本</a>中找到。</p><p id="8522" class="pw-post-body-paragraph lv lw it lx b ly mr kd ma mb ms kg md me mt mg mh mi mu mk ml mm mv mo mp mq im bi translated">我假设读者熟悉构建广义线性模型(glm)和使用有向无环图(Dag)来说明因果关系。</p><h1 id="cd11" class="ld le it bd lf lg lh li lj lk ll lm ln ki lo kj lp kl lq km lr ko ls kp lt lu bi translated">资料组</h1><p id="a651" class="pw-post-body-paragraph lv lw it lx b ly lz kd ma mb mc kg md me mf mg mh mi mj mk ml mm mn mo mp mq im bi translated">假设我们要研究学生勤奋程度和作业质量的影响。让我们想象一下，我们能够以某种方式分配一个实数来衡量学生的勤奋程度，家庭作业的质量以10分制来衡量，从0到10。</p><p id="058a" class="pw-post-body-paragraph lv lw it lx b ly mr kd ma mb ms kg md me mt mg mh mi mu mk ml mm mv mo mp mq im bi translated">换句话说，我们的数据集看起来像这样:</p><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div class="gh gi mx"><img src="../Images/24f9270bf47be74f11264f5743747038.png" data-original-src="https://miro.medium.com/v2/resize:fit:514/format:webp/1*PrqIU5lAlP8OHEd0uLkjcg.png"/></div><figcaption class="my mz gj gh gi na nb bd b be z dk translated">图1:样本合成数据集</figcaption></figure><p id="fd9d" class="pw-post-body-paragraph lv lw it lx b ly mr kd ma mb ms kg md me mt mg mh mi mu mk ml mm mv mo mp mq im bi translated">学生的学生成绩只是从标准正态分布中抽取的随机变量。</p><p id="2ee0" class="pw-post-body-paragraph lv lw it lx b ly mr kd ma mb ms kg md me mt mg mh mi mu mk ml mm mv mo mp mq im bi translated">学生的家庭作业分数是学生分数的函数。具体来说，就是:</p><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div class="gh gi nc"><img src="../Images/c3e984fc0b86270438a76b1ecaf094a6.png" data-original-src="https://miro.medium.com/v2/resize:fit:1146/format:webp/1*lr3GhD6NKHBrLAzNOSIE8w.png"/></div><figcaption class="my mz gj gh gi na nb bd b be z dk translated">图2:学生成绩和作业成绩之间的关系</figcaption></figure><p id="5eb0" class="pw-post-body-paragraph lv lw it lx b ly mr kd ma mb ms kg md me mt mg mh mi mu mk ml mm mv mo mp mq im bi translated">其中f(x)即链接函数是逻辑函数。</p><p id="3c50" class="pw-post-body-paragraph lv lw it lx b ly mr kd ma mb ms kg md me mt mg mh mi mu mk ml mm mv mo mp mq im bi translated">基于图2中的数据生成过程，我们可以对问题建模如下:</p><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div class="gh gi nd"><img src="../Images/15a2bfaba2b83daccafc71d8445f8755.png" data-original-src="https://miro.medium.com/v2/resize:fit:1386/format:webp/1*t-wiC4ZI8NRE1sCMaX4bcQ.png"/></div><figcaption class="my mz gj gh gi na nb bd b be z dk translated">图3:对图2中的数据生成过程建模</figcaption></figure><p id="97d6" class="pw-post-body-paragraph lv lw it lx b ly mr kd ma mb ms kg md me mt mg mh mi mu mk ml mm mv mo mp mq im bi translated">其中α是截距，βstudent是学生分数的系数。设置正确，推理步骤会给出α = 0，βstudent = 1。</p><p id="9402" class="pw-post-body-paragraph lv lw it lx b ly mr kd ma mb ms kg md me mt mg mh mi mu mk ml mm mv mo mp mq im bi translated">我们的数据集由10，000个观察值组成。</p><h1 id="c8ce" class="ld le it bd lf lg lh li lj lk ll lm ln ki lo kj lp kl lq km lr ko ls kp lt lu bi translated">缺失值场景</h1><p id="17d4" class="pw-post-body-paragraph lv lw it lx b ly lz kd ma mb mc kg md me mf mg mh mi mj mk ml mm mn mo mp mq im bi translated">让我们假设每个学生都有一只狗，这只狗将代表缺失的价值机制。具体来说，一个学生会写作业，然后狗可能会吃也可能不会吃，这取决于各种因素。</p><p id="3101" class="pw-post-body-paragraph lv lw it lx b ly mr kd ma mb ms kg md me mt mg mh mi mu mk ml mm mv mo mp mq im bi translated">如果作业被吃了，那么从我们的角度来说，学生的作业是缺失的。否则，我们将观察学生的作业，并能够相应地评分。</p><h2 id="8bed" class="ne le it bd lf nf ng dn lj nh ni dp ln me nj nk lp mi nl nm lr mm nn no lt iz bi translated">场景一:狗狗随意吃作业</h2><p id="0373" class="pw-post-body-paragraph lv lw it lx b ly lz kd ma mb mc kg md me mf mg mh mi mj mk ml mm mn mo mp mq im bi translated">以下DAG描述了这种情况:</p><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div class="gh gi np"><img src="../Images/4f25434cf853082dfb7a42aa3804dc8a.png" data-original-src="https://miro.medium.com/v2/resize:fit:262/format:webp/1*SuKI2f3teTVtDMOQGRwX3Q.png"/></div><figcaption class="my mz gj gh gi na nb bd b be z dk translated">图4:场景1的DAG。来源:[1]</figcaption></figure><p id="0a35" class="pw-post-body-paragraph lv lw it lx b ly mr kd ma mb ms kg md me mt mg mh mi mu mk ml mm mv mo mp mq im bi translated">其中:</p><ul class=""><li id="e4b6" class="nq nr it lx b ly mr mb ms me ns mi nt mm nu mq nv nw nx ny bi translated">学生成绩</li><li id="da19" class="nq nr it lx b ly nz mb oa me ob mi oc mm od mq nv nw nx ny bi translated">h:家庭作业分数</li><li id="821b" class="nq nr it lx b ly nz mb oa me ob mi oc mm od mq nv nw nx ny bi translated">H*:观察到的家庭作业分数</li><li id="520a" class="nq nr it lx b ly nz mb oa me ob mi oc mm od mq nv nw nx ny bi translated">那只狗</li></ul><p id="d9e4" class="pw-post-body-paragraph lv lw it lx b ly mr kd ma mb ms kg md me mt mg mh mi mu mk ml mm mv mo mp mq im bi translated">图4的要点是D吃不吃作业完全不依赖于H和s。</p><p id="20c2" class="pw-post-body-paragraph lv lw it lx b ly mr kd ma mb ms kg md me mt mg mh mi mu mk ml mm mv mo mp mq im bi translated">如果我们假设有50:50的几率狗会吃掉一份作业，那么我们将有大约5000个完整的观察值(H*，观察到的作业分数，另一半会缺失)。</p><p id="2b67" class="pw-post-body-paragraph lv lw it lx b ly mr kd ma mb ms kg md me mt mg mh mi mu mk ml mm mv mo mp mq im bi translated">如果我们基于H的值执行推断步骤，即我们假设狗没有吃任何作业，我们得到:</p><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div class="gh gi oe"><img src="../Images/24b0f415105285c05a54d29fd195083d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1250/format:webp/1*uq6W_rqnzVPtXDTdK611Dw.png"/></div><figcaption class="my mz gj gh gi na nb bd b be z dk translated">图5:场景1中对H的推断结果</figcaption></figure><p id="de56" class="pw-post-body-paragraph lv lw it lx b ly mr kd ma mb ms kg md me mt mg mh mi mu mk ml mm mv mo mp mq im bi translated">正如所料，我们可以恢复α和β学生的真实参数值(分别为0.0038和0.9918)。</p><p id="cf93" class="pw-post-body-paragraph lv lw it lx b ly mr kd ma mb ms kg md me mt mg mh mi mu mk ml mm mv mo mp mq im bi translated">如果我们基于5000个完整的观察值执行推断步骤，即我们回归S上H*的非缺失值，我们得到:</p><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div class="gh gi of"><img src="../Images/58b334e644450249c3f5708ba6bda2a7.png" data-original-src="https://miro.medium.com/v2/resize:fit:1222/format:webp/1*zXP6hMpzKR66aJstO8a_cQ.png"/></div><figcaption class="my mz gj gh gi na nb bd b be z dk translated">图6:场景1中删除缺失值时的推断结果</figcaption></figure><p id="0b6c" class="pw-post-body-paragraph lv lw it lx b ly mr kd ma mb ms kg md me mt mg mh mi mu mk ml mm mv mo mp mq im bi translated">我们仍然可以恢复真实的参数值！图6和图5的区别在于前者比后者有更多的不确定性。这是可以预料的，因为前者用5000个观察值进行推断步骤，而后者使用10000个观察值。</p><p id="d834" class="pw-post-body-paragraph lv lw it lx b ly mr kd ma mb ms kg md me mt mg mh mi mu mk ml mm mv mo mp mq im bi translated">在这种情况下，缺失值可以被视为一种烦恼，我们可以通过简单地收集更多的数据来克服它。我们不需要诉诸估算价值。</p><h2 id="2b6a" class="ne le it bd lf nf ng dn lj nh ni dp ln me nj nk lp mi nl nm lr mm nn no lt iz bi translated">场景二:狗吃高分学生作业</h2><p id="3854" class="pw-post-body-paragraph lv lw it lx b ly lz kd ma mb mc kg md me mf mg mh mi mj mk ml mm mn mo mp mq im bi translated">假设S影响D，即:</p><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div class="gh gi og"><img src="../Images/c3046ef95eafe4b45ca714717e234a13.png" data-original-src="https://miro.medium.com/v2/resize:fit:266/format:webp/1*bW4hL1q6vduP25XOfrjqmw.png"/></div><figcaption class="my mz gj gh gi na nb bd b be z dk translated">图7:场景2的DAG。来源:[1]</figcaption></figure><p id="e24b" class="pw-post-body-paragraph lv lw it lx b ly mr kd ma mb ms kg md me mt mg mh mi mu mk ml mm mv mo mp mq im bi translated">让我们想象一下，一只狗吃了高于平均水平的学生做的作业，即学生分数大于0的学生。</p><p id="8b6c" class="pw-post-body-paragraph lv lw it lx b ly mr kd ma mb ms kg md me mt mg mh mi mu mk ml mm mv mo mp mq im bi translated">在这种情况下，我们最终也会有5，000个完整案例。对该子集执行推理步骤给出:</p><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi oh"><img src="../Images/10af5109e3b6dc6441734b11e5f935ea.png" data-original-src="https://miro.medium.com/v2/resize:fit:1212/format:webp/1*dz9mIEAxbmuhBHfYdSoCng.png"/></div></div><figcaption class="my mz gj gh gi na nb bd b be z dk translated">图8:场景2中删除缺失值时的推断结果</figcaption></figure><p id="866c" class="pw-post-body-paragraph lv lw it lx b ly mr kd ma mb ms kg md me mt mg mh mi mu mk ml mm mv mo mp mq im bi translated">我们可以恢复真实的参数，就像我们在场景1中所做的那样。然而，场景2不像场景1那样良性。</p><p id="e36e" class="pw-post-body-paragraph lv lw it lx b ly mr kd ma mb ms kg md me mt mg mh mi mu mk ml mm mv mo mp mq im bi translated">在场景2的这个特定示例中，我们假设不管S的值如何，S和H之间的关系都是相同的。如果我们修改了这个示例，使其在S &gt; 0时具有不同的关系，那么我们得到的结果是非常误导的，并且再多的探索性数据分析也无法检测到这一点，因为对于S &gt; 0的学生，H*将具有缺失值！</p><p id="36cf" class="pw-post-body-paragraph lv lw it lx b ly mr kd ma mb ms kg md me mt mg mh mi mu mk ml mm mv mo mp mq im bi translated">这个场景表明，考虑丢失值产生的机制是很重要的。</p><h2 id="cf09" class="ne le it bd lf nf ng dn lj nh ni dp ln me nj nk lp mi nl nm lr mm nn no lt iz bi translated">场景3:影响作业分数和Dog的中间变量</h2><p id="765e" class="pw-post-body-paragraph lv lw it lx b ly lz kd ma mb mc kg md me mf mg mh mi mj mk ml mm mn mo mp mq im bi translated">假设有一个中间且未观察到的变量X影响S和D:</p><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div class="gh gi oi"><img src="../Images/30a427b26e952f21b378521624686c56.png" data-original-src="https://miro.medium.com/v2/resize:fit:270/format:webp/1*SJi_Yji5JxrjmOVZVg5TDw.png"/></div><figcaption class="my mz gj gh gi na nb bd b be z dk translated">图9:场景3的DAG。来源:[1]</figcaption></figure><p id="b628" class="pw-post-body-paragraph lv lw it lx b ly mr kd ma mb ms kg md me mt mg mh mi mu mk ml mm mv mo mp mq im bi translated">例如，设X为学生家中的噪音水平，则:</p><ol class=""><li id="4601" class="nq nr it lx b ly mr mb ms me ns mi nt mm nu mq oj nw nx ny bi translated">如果家里的噪音水平很高，学生的作业就会很糟糕</li><li id="93f9" class="nq nr it lx b ly nz mb oa me ob mi oc mm od mq oj nw nx ny bi translated">如果家里的噪音水平很高，狗就会吃作业</li></ol><p id="4263" class="pw-post-body-paragraph lv lw it lx b ly mr kd ma mb ms kg md me mt mg mh mi mu mk ml mm mv mo mp mq im bi translated">在这种情况下，让我们将X建模为一个遵循标准正态分布的随机变量。学生分数和家庭作业分数之间的关系变成:</p><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi ok"><img src="../Images/f3da6bf95bedb369fba77f1c9f5b9246.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*t2Z4HAUqen04liMHHUPGoA.png"/></div></div><figcaption class="my mz gj gh gi na nb bd b be z dk translated">图10:场景3中学生分数和家庭作业分数之间的关系</figcaption></figure><p id="49cb" class="pw-post-body-paragraph lv lw it lx b ly mr kd ma mb ms kg md me mt mg mh mi mu mk ml mm mv mo mp mq im bi translated">这意味着我们有:</p><ul class=""><li id="72fe" class="nq nr it lx b ly mr mb ms me ns mi nt mm nu mq nv nw nx ny bi">α = 2</li><li id="3ec2" class="nq nr it lx b ly nz mb oa me ob mi oc mm od mq nv nw nx ny bi translated">β学生= 1</li><li id="aae1" class="nq nr it lx b ly nz mb oa me ob mi oc mm od mq nv nw nx ny bi translated">β噪声= -2</li></ul><p id="282f" class="pw-post-body-paragraph lv lw it lx b ly mr kd ma mb ms kg md me mt mg mh mi mu mk ml mm mv mo mp mq im bi translated">让我们稍微偏离一下话题，假设没有丢失值，并且噪声水平是可观察到的，即在S和x上回归H，结果如下:</p><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div class="gh gi ol"><img src="../Images/18698c726e4e5b0565b4b03466fc4507.png" data-original-src="https://miro.medium.com/v2/resize:fit:1210/format:webp/1*nC_9iNpAMVV4hRvWJNo2-w.png"/></div><figcaption class="my mz gj gh gi na nb bd b be z dk translated">图11:场景3的推断结果，假设有可观察到的噪声并且没有丢失值</figcaption></figure><p id="1def" class="pw-post-body-paragraph lv lw it lx b ly mr kd ma mb ms kg md me mt mg mh mi mu mk ml mm mv mo mp mq im bi translated">不出所料，我们可以恢复真实参数。</p><p id="bb8b" class="pw-post-body-paragraph lv lw it lx b ly mr kd ma mb ms kg md me mt mg mh mi mu mk ml mm mv mo mp mq im bi translated">如果我们假设没有丢失值，但噪声不可观测，会发生以下情况:</p><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div class="gh gi om"><img src="../Images/77f420f6e8041af1e76378268b8ad843.png" data-original-src="https://miro.medium.com/v2/resize:fit:1236/format:webp/1*IuGL8i691eb1A3ABLuIpLQ.png"/></div><figcaption class="my mz gj gh gi na nb bd b be z dk translated">图12:场景3的推断结果，假设不可观察的噪声和没有丢失的值</figcaption></figure><p id="3e46" class="pw-post-body-paragraph lv lw it lx b ly mr kd ma mb ms kg md me mt mg mh mi mu mk ml mm mv mo mp mq im bi translated">我们无法恢复S的真实参数值，尽管图9中的DAG清楚地显示没有从H到S的后门！</p><p id="251d" class="pw-post-body-paragraph lv lw it lx b ly mr kd ma mb ms kg md me mt mg mh mi mu mk ml mm mv mo mp mq im bi translated">怎么回事？这是GLMs的一个局限性，在[1]的第10.2.3节中有详细讨论。随附的笔记本显示，如果我们将问题重新表述为简单的线性模型，即不具有链接函数的线性模型，无论噪声水平的可观测性如何，我们仍然可以恢复真实参数。</p><p id="4d42" class="pw-post-body-paragraph lv lw it lx b ly mr kd ma mb ms kg md me mt mg mh mi mu mk ml mm mv mo mp mq im bi translated">总之，回到最初的场景。如果推理即使在没有丢失值的情况下也表现不佳，那么在有丢失值的情况下肯定也会表现不佳，对吗？</p><p id="ab55" class="pw-post-body-paragraph lv lw it lx b ly mr kd ma mb ms kg md me mt mg mh mi mu mk ml mm mv mo mp mq im bi translated">让我们假设，如果噪音水平大于1，那么狗将吃掉作业，导致作业分数的值缺失。这给出了一个只有15.80 %缺失值的数据集。对完整的观察值进行推理步骤给出:</p><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div class="gh gi on"><img src="../Images/6dac67123db8c3293c28288ef3ac0e52.png" data-original-src="https://miro.medium.com/v2/resize:fit:1226/format:webp/1*yuGjNU7u0CgXxVqpkqXNTg.png"/></div><figcaption class="my mz gj gh gi na nb bd b be z dk translated">图13:假设不可观察的噪声和缺失值，对场景3结果的推断</figcaption></figure><p id="c367" class="pw-post-body-paragraph lv lw it lx b ly mr kd ma mb ms kg md me mt mg mh mi mu mk ml mm mv mo mp mq im bi translated">我们无法恢复S的真实参数值，但至少与图12中的结果相比偏差较小(0.8305比0.6740)。但是，这只是生成缺失值的函数的产物，而不是DAG的属性。请看随附的笔记本，其中缺失值函数的结果是估计值0.6387。</p><p id="4816" class="pw-post-body-paragraph lv lw it lx b ly mr kd ma mb ms kg md me mt mg mh mi mu mk ml mm mv mo mp mq im bi translated">这种情况的要点是，混淆变量并不是有偏见的估计的唯一原因。车型的选择，例如GLM vs LM，也会起到一定的作用。</p><h2 id="bfa4" class="ne le it bd lf nf ng dn lj nh ni dp ln me nj nk lp mi nl nm lr mm nn no lt iz bi translated">场景4:作业影响狗</h2><p id="7aa4" class="pw-post-body-paragraph lv lw it lx b ly lz kd ma mb mc kg md me mf mg mh mi mj mk ml mm mn mo mp mq im bi translated">假设H以某种方式影响了D:</p><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div class="gh gi np"><img src="../Images/2d0188747aac95f763d0ae34a7979ea1.png" data-original-src="https://miro.medium.com/v2/resize:fit:262/format:webp/1*Vet5yQ6-bEPIBxcGO_dNUA.png"/></div><figcaption class="my mz gj gh gi na nb bd b be z dk translated">图14:场景4的DAG。来源:[1]</figcaption></figure><p id="9a92" class="pw-post-body-paragraph lv lw it lx b ly mr kd ma mb ms kg md me mt mg mh mi mu mk ml mm mv mo mp mq im bi translated">比如作业分数低于5分，那么狗就要吃了。这给出了约44%的缺失值的观察值。</p><p id="7715" class="pw-post-body-paragraph lv lw it lx b ly mr kd ma mb ms kg md me mt mg mh mi mu mk ml mm mv mo mp mq im bi translated">显然，如果我们在S上回归H，那么我们将能够恢复βstudent的真实参数值。详见随附的笔记本。</p><p id="7baa" class="pw-post-body-paragraph lv lw it lx b ly mr kd ma mb ms kg md me mt mg mh mi mu mk ml mm mv mo mp mq im bi translated">如果我们试图在S上回归H*，那么我们会遇到一个问题，因为有一条通向H*的后门路径，即S → H → D → H*。</p><p id="ebe4" class="pw-post-body-paragraph lv lw it lx b ly mr kd ma mb ms kg md me mt mg mh mi mu mk ml mm mv mo mp mq im bi translated">我们要么想出一种方法来阻止狗吃学生的作业，即采取更好的测量方法，要么将缺失值机制纳入推理步骤，假设我们对此有所了解。后者将是未来文章的主题。</p><h1 id="af0a" class="ld le it bd lf lg lh li lj lk ll lm ln ki lo kj lp kl lq km lr ko ls kp lt lu bi translated">经验教训</h1><p id="f9a0" class="pw-post-body-paragraph lv lw it lx b ly lz kd ma mb mc kg md me mf mg mh mi mj mk ml mm mn mo mp mq im bi translated">本文关于处理缺失值的关键要点是，我们应该起草一个我们认为代表数据生成过程的DAG。</p><p id="7b1b" class="pw-post-body-paragraph lv lw it lx b ly mr kd ma mb ms kg md me mt mg mh mi mu mk ml mm mv mo mp mq im bi translated">基于DAG，我们可以确定处理丢失值的最佳操作。例如，如果缺失值机制类似于场景1，那么如果我们希望获得更好的估计，我们可以安全地忽略它们或者收集更多的数据。没有必要应用任何花哨的插补方法。</p><p id="8f23" class="pw-post-body-paragraph lv lw it lx b ly mr kd ma mb ms kg md me mt mg mh mi mu mk ml mm mv mo mp mq im bi translated">我们还应该基于我们创建的DAG来模拟数据，以查看我们提出的建模方法将如何表现。这将让我们深入了解我们方法的任何局限性，就像场景3中一样。</p><h1 id="fc4f" class="ld le it bd lf lg lh li lj lk ll lm ln ki lo kj lp kl lq km lr ko ls kp lt lu bi translated">结论</h1><p id="b8de" class="pw-post-body-paragraph lv lw it lx b ly lz kd ma mb mc kg md me mf mg mh mi mj mk ml mm mn mo mp mq im bi translated">本文展示了不同的缺失值机制如何需要不同的策略，以及为什么总是默认删除缺失值的观察结果会在某些情况下导致糟糕的估计。</p><p id="6089" class="pw-post-body-paragraph lv lw it lx b ly mr kd ma mb ms kg md me mt mg mh mi mu mk ml mm mv mo mp mq im bi translated">我希望你已经发现这是有用的。</p><h1 id="6dac" class="ld le it bd lf lg lh li lj lk ll lm ln ki lo kj lp kl lq km lr ko ls kp lt lu bi translated">参考</h1><p id="abea" class="pw-post-body-paragraph lv lw it lx b ly lz kd ma mb mc kg md me mf mg mh mi mj mk ml mm mn mo mp mq im bi translated">[1]统计学再思考:贝叶斯课程与实例，R和Stan，第2版。麦克尔瑞斯。2020</p></div></div>    
</body>
</html>