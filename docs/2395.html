<html>
<head>
<title>Active Learning builds a valuable dataset from scratch</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">主动学习从零开始构建有价值的数据集</h1>
<blockquote>原文：<a href="https://pub.towardsai.net/active-learning-builds-a-valuable-dataset-from-scratch-cb4f66ff902c?source=collection_archive---------2-----------------------#2021-12-04">https://pub.towardsai.net/active-learning-builds-a-valuable-dataset-from-scratch-cb4f66ff902c?source=collection_archive---------2-----------------------#2021-12-04</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><h2 id="4690" class="io ip iq bd b dl ir is it iu iv iw dk ix translated" aria-label="kicker paragraph"><a class="ae ep" href="https://towardsai.net/p/category/machine-learning" rel="noopener ugc nofollow" target="_blank">机器学习</a></h2><div class=""/><div class=""><h2 id="f854" class="pw-subtitle-paragraph jw iz iq bd b jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn dk translated">主动学习导论</h2></div><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div role="button" tabindex="0" class="ku kv di kw bf kx"><div class="gh gi ko"><img src="../Images/9c6e26ffcd597ca710e4307889838d4a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*PJD48sf1u-_lGHkI"/></div></div><figcaption class="la lb gj gh gi lc ld bd b be z dk translated"><a class="ae le" href="https://unsplash.com/@mimithian?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">米米·蒂安</a>在<a class="ae le" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上的照片</figcaption></figure><p id="8bf6" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated"><strong class="lh ja">主动学习</strong>是一种让学习者(如学生)主动参与学习过程的教学策略。与传统的学习过程相比，学习者不仅仅是坐着听，而是与教师一起互动。学习进度可以根据学习者的反馈进行调整。所以，主动学习的周期很重要。</p><p id="1b87" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">如果你已经熟悉主动学习，可以跳到最后一节如何使用<a class="ae le" href="https://github.com/makcedward/nlpatl" rel="noopener ugc nofollow" target="_blank"> NLPatl </a> (NLP主动学习)python包来实现。</p><h1 id="405f" class="mb mc iq bd md me mf mg mh mi mj mk ml kf mm kg mn ki mo kj mp kl mq km mr ms bi translated">目标</h1><p id="a4be" class="pw-post-body-paragraph lf lg iq lh b li mt ka lk ll mu kd ln lo mv lq lr ls mw lu lv lw mx ly lz ma ij bi translated">我们能把这个框架应用到机器学习领域吗？这是可能的，但我们需要澄清什么是主动学习的目标。在训练分类模型时，我们通常在最开始就缺乏标记数据。当然，我们可以随机选择记录并贴上标签，但这太贵了。</p><p id="2127" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">主动学习的假设是，我们可以通过某些方式估计代表性记录，并由主题专家(SME)对其进行标记。因为我们只需要最有代表性的记录，所以不需要大量的标记数据。机器学习模型应该能够从那些有价值的记录中发现模式。获取足够的数据来训练你惊人的模型可以节省金钱和时间。</p><p id="b18e" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">因此，关键点是估算代表记录的<strong class="lh ja">策略</strong>和来自中小企业<strong class="lh ja">的输入</strong>。</p><h1 id="6f3c" class="mb mc iq bd md me mf mg mh mi mj mk ml kf mm kg mn ki mo kj mp kl mq km mr ms bi translated">战略</h1><p id="7921" class="pw-post-body-paragraph lf lg iq lh b li mt ka lk ll mu kd ln lo mv lq lr ls mw lu lv lw mx ly lz ma ij bi translated">有很多评估记录价值的策略。我将从引入主动学习的三种方法开始。我将首先介绍这个想法，然后逐一举例说明。<strong class="lh ja">边际抽样</strong>是指计算最高概率和次高概率之间的差值。<strong class="lh ja">熵抽样</strong>旨在利用所有概率输出(<strong class="lh ja">边际抽样</strong>仅使用最大的两个结果)来识别最不确定的记录。最后一种方法不同于前面提到的方法，因为它使用无监督学习来识别最有价值的记录。你可以称之为<strong class="lh ja">整群抽样</strong>。</p><p id="fcd8" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">从解释开始，我们有下面的样本记录。假设我们有一个分类模型并预测了概率。</p><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div class="gh gi my"><img src="../Images/1015af7a76ce01b1ca3da29f14edb7ca.png" data-original-src="https://miro.medium.com/v2/resize:fit:1128/format:webp/1*3FiYypLV1jLvpM8zC9-3Nw.png"/></div><figcaption class="la lb gj gh gi lc ld bd b be z dk translated">资料组</figcaption></figure><h2 id="3861" class="mz mc iq bd md na nb dn mh nc nd dp ml lo ne nf mn ls ng nh mp lw ni nj mr iw bi translated">边际抽样</h2><p id="201a" class="pw-post-body-paragraph lf lg iq lh b li mt ka lk ll mu kd ln lo mv lq lr ls mw lu lv lw mx ly lz ma ij bi translated"><strong class="lh ja">边际抽样</strong>是指计算最高概率和次高概率之间的差值。假设如果两个最高概率之间的差异大，则分类模型具有更高的不确定性。从上面的例子来看，记录2具有更高的值(0.3 = 0。6-0.3)，而不是记录1(0.984 = 0.99–0.006)。因此，边际抽样方法选择记录2而不是记录1来标记。</p><h2 id="addc" class="mz mc iq bd md na nb dn mh nc nd dp ml lo ne nf mn ls ng nh mp lw ni nj mr iw bi translated"><strong class="ak">熵采样</strong></h2><p id="eb26" class="pw-post-body-paragraph lf lg iq lh b li mt ka lk ll mu kd ln lo mv lq lr ls mw lu lv lw mx ly lz ma ij bi translated"><strong class="lh ja">熵抽样</strong>旨在利用所有概率输出来识别最不确定的记录。而不仅仅是计算最高概率的差异。这种方法通过利用所有概率来计算熵。根据上面的示例，记录2的值(0.898)高于记录1的值(0.063)。因此，熵采样方法选择记录2而不是记录1来标记。</p><h2 id="1bc2" class="mz mc iq bd md na nb dn mh nc nd dp ml lo ne nf mn ls ng nh mp lw ni nj mr iw bi translated">聚类抽样</h2><p id="6237" class="pw-post-body-paragraph lf lg iq lh b li mt ka lk ll mu kd ln lo mv lq lr ls mw lu lv lw mx ly lz ma ij bi translated"><strong class="lh ja">聚类抽样</strong>与上述策略不同。<strong class="lh ja">边缘采样</strong>和<strong class="lh ja">熵采样</strong>的前提是有一个初始标记的数据集和训练一个简单的分类模型。如果开始时没有任何带标签的数据集，可以考虑使用这种方法。基本上，它利用迁移学习将文本转换为嵌入(或向量)，并适合无监督算法，以找到最具代表性的记录。例如，您可以应用KMeans来查找集群并标记它们。</p><h1 id="fccc" class="mb mc iq bd md me mf mg mh mi mj mk ml kf mm kg mn ki mo kj mp kl mq km mr ms bi translated">NLPatl编写的Python代码</h1><p id="c13e" class="pw-post-body-paragraph lf lg iq lh b li mt ka lk ll mu kd ln lo mv lq lr ls mw lu lv lw mx ly lz ma ij bi translated">幸运的是，您不需要自己实现这个框架，但是<a class="ae le" href="https://github.com/makcedward/nlpatl" rel="noopener ugc nofollow" target="_blank"> NLPatl </a> python包已经可以使用了。有了主动学习的想法，然后准备动手。我将用几行代码演示如何在NLP中应用主动学习。你可以访问这本<a class="ae le" href="https://colab.research.google.com/drive/1dr1GY_vO_oOMixj4clzcMR7jLsNpbbvg#scrollTo=YCK94D1X7KBm" rel="noopener ugc nofollow" target="_blank">笔记本</a>获取完整版本的代码。</p><p id="9444" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">下面的示例代码显示了如何使用<strong class="lh ja">熵采样</strong>来估计最有价值的记录。</p><pre class="kp kq kr ks gt nk nl nm nn aw no bi"><span id="84da" class="mz mc iq nl b gy np nq l nr ns"># Initialize entropy sampling apporach to estimate the most valuable data for labeling<br/>learning = EntropyLearning(<br/>  embeddings_model=embeddings_model,<br/>  classification_model=classification_model)</span><span id="a1a4" class="mz mc iq nl b gy nt nq l nr ns"># Train sample classification model first<br/>learning.learn(train_texts, train_labels)</span><span id="c1d3" class="mz mc iq nl b gy nt nq l nr ns"># Label data in notebook interactively<br/>learning.explore_educate_in_notebook(train_texts, num_sample=2)</span></pre><p id="8af6" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">下面的示例代码显示了如何使用<strong class="lh ja">聚类抽样</strong>来估计最有价值的记录。</p><pre class="kp kq kr ks gt nk nl nm nn aw no bi"><span id="963e" class="mz mc iq nl b gy np nq l nr ns"># Initialize clustering sampling apporach to estimate the most valuable data for labeling<br/>learning = ClusteringLearning(<br/>  embeddings_model=embeddings_model,<br/>  clustering_model=clustering_model)</span><span id="9b40" class="mz mc iq nl b gy nt nq l nr ns"># Label data in notebook interactively<br/>learning.explore_educate_in_notebook(train_texts, num_sample=2)</span></pre><h1 id="c26d" class="mb mc iq bd md me mf mg mh mi mj mk ml kf mm kg mn ki mo kj mp kl mq km mr ms bi translated">参考</h1><ul class=""><li id="6fdc" class="nu nv iq lh b li mt ll mu lo nw ls nx lw ny ma nz oa ob oc bi translated">z舒扬，T海特托拉，T维尔塔宁。<a class="ae le" href="https://trepo.tuni.fi/bitstream/handle/10024/129132/MALR_TUTCRIS.pdf?sequence=1" rel="noopener ugc nofollow" target="_blank">通过聚类未标记数据进行声音事件分类的主动学习</a>。2017</li></ul><h1 id="eb77" class="mb mc iq bd md me mf mg mh mi mj mk ml kf mm kg mn ki mo kj mp kl mq km mr ms bi translated">喜欢学习？</h1><p id="5e90" class="pw-post-body-paragraph lf lg iq lh b li mt ka lk ll mu kd ln lo mv lq lr ls mw lu lv lw mx ly lz ma ij bi translated">我是湾区的数据科学家。专注于数据科学、人工智能，尤其是NLP和平台相关领域的最新发展。在<a class="ae le" href="https://www.linkedin.com/in/edwardma1026" rel="noopener ugc nofollow" target="_blank"> LinkedIn </a>或<a class="ae le" href="https://github.com/makcedward" rel="noopener ugc nofollow" target="_blank"> Github </a>上随时联系<a class="ae le" href="https://makcedward.github.io/" rel="noopener ugc nofollow" target="_blank"> me </a>。</p></div></div>    
</body>
</html>