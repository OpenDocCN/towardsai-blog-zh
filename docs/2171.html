<html>
<head>
<title>Bank Churn Modeling with Neural Networks</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">基于神经网络的银行流失建模</h1>
<blockquote>原文：<a href="https://pub.towardsai.net/bank-churn-modeling-with-neural-networks-31881eee6112?source=collection_archive---------0-----------------------#2021-09-10">https://pub.towardsai.net/bank-churn-modeling-with-neural-networks-31881eee6112?source=collection_archive---------0-----------------------#2021-09-10</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><h2 id="4918" class="ir is it bd b dl iu iv iw ix iy iz dk ja translated" aria-label="kicker paragraph"><a class="ae ep" href="https://towardsai.net/p/category/machine-learning/deep-learning" rel="noopener ugc nofollow" target="_blank">深度学习</a></h2><div class=""/><div class=""><h2 id="17f6" class="pw-subtitle-paragraph jz jc it bd b ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq dk translated">在google Colab中使用Keras的人工神经网络</h2></div><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div class="gh gi kr"><img src="../Images/8e794df53ea712d7ddcad95aca0b34b0.png" data-original-src="https://miro.medium.com/v2/resize:fit:1280/format:webp/1*RAeucVCKyFGXArObBsYnrw.png"/></div><figcaption class="kz la gj gh gi lb lc bd b be z dk translated">图片<a class="ae ld" href="https://www.kaggle.com/kmalit/bank-customer-churn-prediction" rel="noopener ugc nofollow" target="_blank">来源</a></figcaption></figure><p id="eeff" class="pw-post-body-paragraph le lf it lg b lh li kd lj lk ll kg lm ln lo lp lq lr ls lt lu lv lw lx ly lz im bi translated">在本文中，我们将使用google colab中的人工神经网络来预测客户流失或流失。目标不是用模型得到好的精度，重要的是用不同的技术和算法得到好的模型。</p><p id="43b8" class="pw-post-body-paragraph le lf it lg b lh li kd lj lk ll kg lm ln lo lp lq lr ls lt lu lv lw lx ly lz im bi translated">流失分析是一个分类问题，因为标签列只有二进制值。客户对每个公司和机构都非常重要，客户流失是分析的一部分。</p><p id="92f4" class="pw-post-body-paragraph le lf it lg b lh li kd lj lk ll kg lm ln lo lp lq lr ls lt lu lv lw lx ly lz im bi translated">这里，我们将使用神经网络根据输入特征和目标列来预测客户流失，如下所示:</p><p id="af1d" class="pw-post-body-paragraph le lf it lg b lh li kd lj lk ll kg lm ln lo lp lq lr ls lt lu lv lw lx ly lz im bi translated"><strong class="lg jd">输入的特征有</strong> <em class="ma">姓氏、积分、地理、……..，IsActiveMember，EstimatedSalary。</em></p><p id="87d6" class="pw-post-body-paragraph le lf it lg b lh li kd lj lk ll kg lm ln lo lp lq lr ls lt lu lv lw lx ly lz im bi translated"><strong class="lg jd">目标列为</strong> <em class="ma">退出</em></p><p id="30e8" class="pw-post-body-paragraph le lf it lg b lh li kd lj lk ll kg lm ln lo lp lq lr ls lt lu lv lw lx ly lz im bi translated">该数据集在kaggle上很容易获得。</p><p id="b40d" class="pw-post-body-paragraph le lf it lg b lh li kd lj lk ll kg lm ln lo lp lq lr ls lt lu lv lw lx ly lz im bi translated">让我们从google colab中的python代码开始。</p><p id="cb62" class="pw-post-body-paragraph le lf it lg b lh li kd lj lk ll kg lm ln lo lp lq lr ls lt lu lv lw lx ly lz im bi translated">首先，我们需要用colab挂载驱动器，这样我们就可以直接从驱动器访问数据。为此，下面给出了一个简单的命令:</p><pre class="ks kt ku kv gt mb mc md me aw mf bi"><span id="0b44" class="mg mh it mc b gy mi mj l mk ml">from google.colab import drive<br/>drive.mount('/content/drive/')</span></pre><p id="5266" class="pw-post-body-paragraph le lf it lg b lh li kd lj lk ll kg lm ln lo lp lq lr ls lt lu lv lw lx ly lz im bi translated">运行该命令后，我们将获得一个链接，用于连接带有colab的驱动器，如下所示:</p><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div class="gh gi mm"><img src="../Images/ae72a9d517c86e66c4806aa00dd8c072.png" data-original-src="https://miro.medium.com/v2/resize:fit:1230/format:webp/1*m5A5QSAlLOS2y_uRVXUCrA.png"/></div></figure><p id="811b" class="pw-post-body-paragraph le lf it lg b lh li kd lj lk ll kg lm ln lo lp lq lr ls lt lu lv lw lx ly lz im bi translated">我们需要点击链接，用Gmail登录，然后从那里复制链接并粘贴到上面的框中。</p><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div class="gh gi mn"><img src="../Images/31e0e6abf958b165fed194f17d94711f.png" data-original-src="https://miro.medium.com/v2/resize:fit:644/format:webp/1*w0eecWITu7ElioJttUQuqg.png"/></div><figcaption class="kz la gj gh gi lb lc bd b be z dk translated">驱动器已安装。作者的照片</figcaption></figure><p id="aeba" class="pw-post-body-paragraph le lf it lg b lh li kd lj lk ll kg lm ln lo lp lq lr ls lt lu lv lw lx ly lz im bi translated">现在，导入colab中所有需要的库。</p><pre class="ks kt ku kv gt mb mc md me aw mf bi"><span id="f7f5" class="mg mh it mc b gy mi mj l mk ml">import numpy as np <br/>import pandas as pd <br/>import matplotlib.pyplot as plt</span><span id="db98" class="mg mh it mc b gy mo mj l mk ml">import keras<br/>from keras.models import Sequential<br/>from keras.layers import Dense, Activation, Embedding, Flatten,<br/>                                  BatchNormalization, Dropout</span><span id="5b14" class="mg mh it mc b gy mo mj l mk ml">from keras.activations import relu, sigmoid<br/>from keras.layers import LeakyReLU</span></pre><p id="bff3" class="pw-post-body-paragraph le lf it lg b lh li kd lj lk ll kg lm ln lo lp lq lr ls lt lu lv lw lx ly lz im bi translated">现在，我们将从驱动器中读取数据。</p><pre class="ks kt ku kv gt mb mc md me aw mf bi"><span id="1ed1" class="mg mh it mc b gy mi mj l mk ml">bank_df = pd.read_csv('/content/drive/MyDrive/Colab<br/>                                     Notebooks/Churn_Modelling.csv')</span><span id="47f1" class="mg mh it mc b gy mo mj l mk ml">bank_df.head()</span></pre><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="mq mr di ms bf mt"><div class="gh gi mp"><img src="../Images/9b539f34d37d48efcf2a7711d826e5e8.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*P0J8OrlsmFOSKvwXj0CW9Q.png"/></div></div><figcaption class="kz la gj gh gi lb lc bd b be z dk translated">客户数据。作者的照片</figcaption></figure><div class="mu mv gp gr mw mx"><a rel="noopener  ugc nofollow" target="_blank" href="/types-of-kernels-in-machine-learning-291cf85fcdd0"><div class="my ab fo"><div class="mz ab na cl cj nb"><h2 class="bd jd gy z fp nc fr fs nd fu fw jc bi translated">机器学习中的核类型</h2><div class="ne l"><h3 class="bd b gy z fp nc fr fs nd fu fw dk translated">使用线性函数解决非线性问题</h3></div><div class="nf l"><p class="bd b dl z fp nc fr fs nd fu fw dk translated">pub.towardsai.net</p></div></div><div class="ng l"><div class="nh l ni nj nk ng nl kx mx"/></div></div></a></div><div class="mu mv gp gr mw mx"><a rel="noopener  ugc nofollow" target="_blank" href="/understand-feature-selection-in-machine-learning-with-python-a0e99dbb7426"><div class="my ab fo"><div class="mz ab na cl cj nb"><h2 class="bd jd gy z fp nc fr fs nd fu fw jc bi translated">理解Python机器学习中的特征选择</h2><div class="ne l"><h3 class="bd b gy z fp nc fr fs nd fu fw dk translated">从数据中选择最佳特征集的技术</h3></div><div class="nf l"><p class="bd b dl z fp nc fr fs nd fu fw dk translated">pub.towardsai.net</p></div></div><div class="ng l"><div class="nm l ni nj nk ng nl kx mx"/></div></div></a></div><p id="8d98" class="pw-post-body-paragraph le lf it lg b lh li kd lj lk ll kg lm ln lo lp lq lr ls lt lu lv lw lx ly lz im bi translated">现在，我们将数据分为输入特征和目标特征，分别为X和y。</p><pre class="ks kt ku kv gt mb mc md me aw mf bi"><span id="54af" class="mg mh it mc b gy mi mj l mk ml">X = bank_df.iloc[:, 3:13].values<br/>y = bank_df.iloc[:, 13].values</span></pre><p id="b358" class="pw-post-body-paragraph le lf it lg b lh li kd lj lk ll kg lm ln lo lp lq lr ls lt lu lv lw lx ly lz im bi translated">输入特征从第4列到第12列，目标特征是第13列，即退出列。</p><p id="1252" class="pw-post-body-paragraph le lf it lg b lh li kd lj lk ll kg lm ln lo lp lq lr ls lt lu lv lw lx ly lz im bi translated">特性中有两个类别列，我们必须将它们转换成数字形式，以便于训练。这里，我们使用了一个标签编码器来获取数字形式的类别。</p><pre class="ks kt ku kv gt mb mc md me aw mf bi"><span id="694f" class="mg mh it mc b gy mi mj l mk ml"># Encoding categorical data<br/>from sklearn.preprocessing import LabelEncoder</span><span id="77ca" class="mg mh it mc b gy mo mj l mk ml">labelencoder_X_1 = LabelEncoder()<br/>X[:, 1] = labelencoder_X_1.fit_transform(X[:, 1])</span><span id="26c2" class="mg mh it mc b gy mo mj l mk ml">labelencoder_X_2 = LabelEncoder()<br/>X[:, 2] = labelencoder_X_2.fit_transform(X[:, 2])</span></pre><p id="fa83" class="pw-post-body-paragraph le lf it lg b lh li kd lj lk ll kg lm ln lo lp lq lr ls lt lu lv lw lx ly lz im bi translated">现在，我们将使用一个热编码器来获取categories列。</p><pre class="ks kt ku kv gt mb mc md me aw mf bi"><span id="cf54" class="mg mh it mc b gy mi mj l mk ml">from sklearn.preprocessing import OneHotEncoder<br/>from sklearn.compose import ColumnTransformer</span><span id="6e92" class="mg mh it mc b gy mo mj l mk ml">ct = ColumnTransformer(<br/>[('one_hot_encoder', OneHotEncoder(categories='auto'), [1])],<br/>remainder='passthrough')</span><span id="025b" class="mg mh it mc b gy mo mj l mk ml">X = ct.fit_transform(X)<br/>X = X[:, 1:]</span></pre><p id="f4ec" class="pw-post-body-paragraph le lf it lg b lh li kd lj lk ll kg lm ln lo lp lq lr ls lt lu lv lw lx ly lz im bi translated">列转移是一种估计器，其中列的向量值被转换以生成特征。</p><p id="c96b" class="pw-post-body-paragraph le lf it lg b lh li kd lj lk ll kg lm ln lo lp lq lr ls lt lu lv lw lx ly lz im bi translated">是时候将特性分为训练集和测试集了。</p><pre class="ks kt ku kv gt mb mc md me aw mf bi"><span id="bae0" class="mg mh it mc b gy mi mj l mk ml"># dividing features into training and testing sets.<br/>from sklearn.model_selection import train_test_split</span><span id="2fc3" class="mg mh it mc b gy mo mj l mk ml">Xtrain, Xtest, ytrain, ytest = train_test_split(X, y, test_size<br/>                                           = 0.2, random_state = 0)</span></pre><p id="f975" class="pw-post-body-paragraph le lf it lg b lh li kd lj lk ll kg lm ln lo lp lq lr ls lt lu lv lw lx ly lz im bi translated">现在，我们将一个功能缩放，使所有的变化数据进入一些相等的范围。</p><pre class="ks kt ku kv gt mb mc md me aw mf bi"><span id="aedf" class="mg mh it mc b gy mi mj l mk ml"># Feature Scaling</span><span id="5da4" class="mg mh it mc b gy mo mj l mk ml">from sklearn.preprocessing import StandardScaler<br/>sc = StandardScaler()<br/>Xtrain = sc.fit_transform(Xtrain)<br/>Xtest = sc.transform(Xtest)</span></pre><p id="5990" class="pw-post-body-paragraph le lf it lg b lh li kd lj lk ll kg lm ln lo lp lq lr ls lt lu lv lw lx ly lz im bi translated">现在，导入Keras分类器和网格搜索cv来调整参数。</p><pre class="ks kt ku kv gt mb mc md me aw mf bi"><span id="2276" class="mg mh it mc b gy mi mj l mk ml">from keras.wrappers.scikit_learn import KerasClassifier<br/>from sklearn.model_selection import GridSearchCV</span></pre><p id="4874" class="pw-post-body-paragraph le lf it lg b lh li kd lj lk ll kg lm ln lo lp lq lr ls lt lu lv lw lx ly lz im bi translated">是时候创建一个函数来制作一个具有不同隐层的神经网络了。</p><pre class="ks kt ku kv gt mb mc md me aw mf bi"><span id="667a" class="mg mh it mc b gy mi mj l mk ml">def create_model(layers, activation):<br/>    model = Sequential()<br/>    for i, nodes in enumerate(layers):<br/>        if i==0:<br/>            model.add(Dense(nodes, input_dim=Xtrain.shape[1]))<br/>            model.add(Activation(activation))<br/>        else:<br/>            model.add(Dense(nodes))<br/>            model.add(Activation(activation))</span><span id="3f97" class="mg mh it mc b gy mo mj l mk ml">    model.add(Dense(1))<br/>    model.compile(optimizer='adam', loss = 'binary_crossentropy',<br/>                                       metrics=['accuracy'])<br/>    return model</span><span id="a616" class="mg mh it mc b gy mo mj l mk ml">model=KerasClassifier(build_fn=create_model, verbose=0)</span></pre><p id="d285" class="pw-post-body-paragraph le lf it lg b lh li kd lj lk ll kg lm ln lo lp lq lr ls lt lu lv lw lx ly lz im bi translated">在这里，我们给出了不同的层数和激活函数来选择最好的作为GridSearchCV的一部分。</p><pre class="ks kt ku kv gt mb mc md me aw mf bi"><span id="21b7" class="mg mh it mc b gy mi mj l mk ml">layers = [[15], [35, 25], [40, 25, 15]]<br/>activations = ['sigmoid', 'relu']</span><span id="92bd" class="mg mh it mc b gy mo mj l mk ml">param_grid = dict(layers = layers, activation = activations,<br/>                  batch_size = [128, 256], epochs=[30])</span><span id="8c51" class="mg mh it mc b gy mo mj l mk ml">grid = GridSearchCV(estimator=model, param_grid=param_grid)</span></pre><p id="1b31" class="pw-post-body-paragraph le lf it lg b lh li kd lj lk ll kg lm ln lo lp lq lr ls lt lu lv lw lx ly lz im bi translated">下一步，我们正在训练模型并获得最佳参数。</p><pre class="ks kt ku kv gt mb mc md me aw mf bi"><span id="e862" class="mg mh it mc b gy mi mj l mk ml">grid_result = grid.fit(Xtrain, ytrain)</span></pre><p id="0d31" class="pw-post-body-paragraph le lf it lg b lh li kd lj lk ll kg lm ln lo lp lq lr ls lt lu lv lw lx ly lz im bi translated">编写以下命令，为我们的人工神经网络获取最佳参数。</p><pre class="ks kt ku kv gt mb mc md me aw mf bi"><span id="ad9d" class="mg mh it mc b gy mi mj l mk ml">[grid_result.best_score_, grid_result.best_params_]</span><span id="26bc" class="mg mh it mc b gy mo mj l mk ml">#output:<br/>[0.8505000114440918,<br/> {'activation': 'relu',<br/>  'batch_size': 256,<br/>  'epochs': 30,<br/>  'layers': [40, 25, 15]}]</span></pre><p id="f1f4" class="pw-post-body-paragraph le lf it lg b lh li kd lj lk ll kg lm ln lo lp lq lr ls lt lu lv lw lx ly lz im bi translated">现在，我们将使用这些最佳参数进行预测。</p><pre class="ks kt ku kv gt mb mc md me aw mf bi"><span id="7470" class="mg mh it mc b gy mi mj l mk ml">pred_y = grid.predict(Xtest)</span></pre><p id="2c2a" class="pw-post-body-paragraph le lf it lg b lh li kd lj lk ll kg lm ln lo lp lq lr ls lt lu lv lw lx ly lz im bi translated">为了评估，我们正在检查混淆矩阵。</p><pre class="ks kt ku kv gt mb mc md me aw mf bi"><span id="9105" class="mg mh it mc b gy mi mj l mk ml">from sklearn.metrics import confusion_matrix<br/>cm = confusion_matrix(ytest, ypred)<br/>cm</span><span id="fd1d" class="mg mh it mc b gy mo mj l mk ml">#output:<br/>array([[1517,   78],<br/>       [ 202,  203]])</span></pre><p id="b029" class="pw-post-body-paragraph le lf it lg b lh li kd lj lk ll kg lm ln lo lp lq lr ls lt lu lv lw lx ly lz im bi translated">是时候得到我们上面创建的人工神经网络的准确度分数了。</p><pre class="ks kt ku kv gt mb mc md me aw mf bi"><span id="12b6" class="mg mh it mc b gy mi mj l mk ml">from sklearn.metrics import accuracy_score<br/>score = accuracy_score(ytest, ypred)<br/>score</span><span id="f5de" class="mg mh it mc b gy mo mj l mk ml">#output:<br/>0.86</span></pre><p id="6e75" class="pw-post-body-paragraph le lf it lg b lh li kd lj lk ll kg lm ln lo lp lq lr ls lt lu lv lw lx ly lz im bi translated">这些参数为模型提供了86%的准确性。</p><blockquote class="nn no np"><p id="9907" class="le lf ma lg b lh li kd lj lk ll kg lm nq lo lp lq nr ls lt lu ns lw lx ly lz im bi translated"><strong class="lg jd"> <em class="it">结论</em> </strong></p></blockquote><p id="d2f2" class="pw-post-body-paragraph le lf it lg b lh li kd lj lk ll kg lm ln lo lp lq lr ls lt lu lv lw lx ly lz im bi translated">这是一个非常简单的分类人工神经网络，对初学者非常有用。</p><p id="39d5" class="pw-post-body-paragraph le lf it lg b lh li kd lj lk ll kg lm ln lo lp lq lr ls lt lu lv lw lx ly lz im bi translated">我希望你喜欢这篇文章。通过我的<a class="ae ld" href="https://www.linkedin.com/in/data-scientist-95040a1ab/" rel="noopener ugc nofollow" target="_blank"> LinkedIn </a>和<a class="ae ld" href="https://twitter.com/amitprius" rel="noopener ugc nofollow" target="_blank"> twitter </a>联系我。</p><h1 id="4d9f" class="nt mh it bd nu nv nw nx ny nz oa ob oc ki od kj oe kl of km og ko oh kp oi oj bi translated">推荐文章</h1><p id="d6b8" class="pw-post-body-paragraph le lf it lg b lh ok kd lj lk ol kg lm ln om lp lq lr on lt lu lv oo lx ly lz im bi translated">1.<a class="ae ld" rel="noopener ugc nofollow" target="_blank" href="/8-active-learning-insights-of-python-collection-module-6c9e0cc16f6b?source=friends_link&amp;sk=4a5c9f9ad552005636ae720a658281b1">8 Python的主动学习见解收集模块</a> <br/> 2。<a class="ae ld" rel="noopener ugc nofollow" target="_blank" href="/numpy-linear-algebra-on-images-ed3180978cdb?source=friends_link&amp;sk=d9afa4a1206971f9b1f64862f6291ac0"> NumPy:图像上的线性代数</a>T5】3。<a class="ae ld" rel="noopener ugc nofollow" target="_blank" href="/exception-handling-concepts-in-python-4d5116decac3?source=friends_link&amp;sk=a0ed49d9fdeaa67925eac34ecb55ea30">Python中的异常处理概念</a> <br/> 4。<a class="ae ld" rel="noopener ugc nofollow" target="_blank" href="/pandas-dealing-with-categorical-data-7547305582ff?source=friends_link&amp;sk=11c6809f6623dd4f6dd74d43727297cf">熊猫:处理分类数据</a> <br/> 5。<a class="ae ld" rel="noopener ugc nofollow" target="_blank" href="/hyper-parameters-randomseachcv-and-gridsearchcv-in-machine-learning-b7d091cf56f4?source=friends_link&amp;sk=cab337083fb09601114a6e466ec59689">超参数:机器学习中的RandomSeachCV和GridSearchCV</a><br/>6。<a class="ae ld" href="https://medium.com/towards-artificial-intelligence/fully-explained-linear-regression-with-python-fe2b313f32f3?source=friends_link&amp;sk=53c91a2a51347ec2d93f8222c0e06402" rel="noopener">用Python </a> <br/> 7全面讲解了线性回归。<a class="ae ld" href="https://medium.com/towards-artificial-intelligence/fully-explained-logistic-regression-with-python-f4a16413ddcd?source=friends_link&amp;sk=528181f15a44e48ea38fdd9579241a78" rel="noopener">用Python </a> <br/>充分解释了Logistic回归8。<a class="ae ld" rel="noopener ugc nofollow" target="_blank" href="/data-distribution-using-numpy-with-python-3b64aae6f9d6?source=friends_link&amp;sk=809e75802cbd25ddceb5f0f6496c9803">数据分发使用Numpy与Python </a> <br/> 9。<a class="ae ld" rel="noopener ugc nofollow" target="_blank" href="/decision-trees-vs-random-forests-in-machine-learning-be56c093b0f?source=friends_link&amp;sk=91377248a43b62fe7aeb89a69e590860">机器学习中的决策树vs随机森林</a> <br/> 10。<a class="ae ld" rel="noopener ugc nofollow" target="_blank" href="/standardization-in-data-preprocessing-with-python-96ae89d2f658?source=friends_link&amp;sk=f348435582e8fbb47407e9b359787e41">用Python实现数据预处理的标准化</a></p></div></div>    
</body>
</html>