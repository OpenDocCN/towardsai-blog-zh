<html>
<head>
<title>Supervised Learning: 31 of the Most Important Models; 5 are a Must-learn</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">监督学习:31个最重要的模型:5是必须学习的</h1>
<blockquote>原文：<a href="https://pub.towardsai.net/supervised-learning-31-of-the-most-important-models-5-are-a-must-learn-9c62444905fa?source=collection_archive---------1-----------------------#2022-07-14">https://pub.towardsai.net/supervised-learning-31-of-the-most-important-models-5-are-a-must-learn-9c62444905fa?source=collection_archive---------1-----------------------#2022-07-14</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="16f7" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">我概述了31个关键的监督学习模型，并揭示了必须学习的前5个模型</h2></div><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ki"><img src="../Images/53a596cf7e306b4197bc66ca94fb4763.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*wGHUM9DQ0eKg1QiG_OTosA.jpeg"/></div></div><figcaption class="ku kv gj gh gi kw kx bd b be z dk translated">由来自Pexels的<a class="ae ky" href="https://www.pexels.com/@pixabay/" rel="noopener ugc nofollow" target="_blank"> Pixabay </a></figcaption></figure><h1 id="01de" class="kz la it bd lb lc ld le lf lg lh li lj jz lk ka ll kc lm kd ln kf lo kg lp lq bi translated">机器学习的介绍性定义</h1><p id="538d" class="pw-post-body-paragraph lr ls it lt b lu lv ju lw lx ly jx lz ma mb mc md me mf mg mh mi mj mk ml mm im bi translated">简单来说，机器学习是计算系统通过从数据中学习来更好地做事的一种方式。更严格地说，机器学习是一个计算机科学领域，涉及创建可以从数据中学习并对数据进行预测的算法。</p><h1 id="c657" class="kz la it bd lb lc ld le lf lg lh li lj jz lk ka ll kc lm kd ln kf lo kg lp lq bi translated">什么是监督模型？</h1><p id="7988" class="pw-post-body-paragraph lr ls it lt b lu lv ju lw lx ly jx lz ma mb mc md me mf mg mh mi mj mk ml mm im bi translated">非定量定义:监督学习是一种通过向机器展示大量例子来教授它们的方法，或者是一种给你一些例子来学习的学习类型。更专业地说，计算系统被给予一组训练数据，其包括输入数据和每个数据的正确输出。系统使用这个特定的训练数据来学习如何为新的输入数据产生正确的结果。</p><h1 id="802f" class="kz la it bd lb lc ld le lf lg lh li lj jz lk ka ll kc lm kd ln kf lo kg lp lq bi translated">监督学习面临的三大挑战</h1><h2 id="356f" class="mn la it bd lb mo mp dn lf mq mr dp lj ma ms mt ll me mu mv ln mi mw mx lp my bi translated">简单的3:</h2><p id="7e4f" class="pw-post-body-paragraph lr ls it lt b lu lv ju lw lx ly jx lz ma mb mc md me mf mg mh mi mj mk ml mm im bi translated">1.找到足够的数据来训练模型</p><p id="4b41" class="pw-post-body-paragraph lr ls it lt b lu mz ju lw lx na jx lz ma nb mc md me nc mg mh mi nd mk ml mm im bi translated">2.确保数据的准确性和高质量</p><p id="4776" class="pw-post-body-paragraph lr ls it lt b lu mz ju lw lx na jx lz ma nb mc md me nc mg mh mi nd mk ml mm im bi translated">3.防止模型过度拟合，这意味着确保它不会将训练数据记忆得过于紧密，以至于不能很好地推广到新数据[37]</p><h2 id="6dba" class="mn la it bd lb mo mp dn lf mq mr dp lj ma ms mt ll me mu mv ln mi mw mx lp my bi translated">更技术性的3:</h2><p id="db74" class="pw-post-body-paragraph lr ls it lt b lu lv ju lw lx ly jx lz ma mb mc md me mf mg mh mi mj mk ml mm im bi translated">1.数据通常是不平衡的，一类样本比另一类样本多。这对于一些假设类是平衡的学习算法来说可能是一个问题。</p><p id="6a72" class="pw-post-body-paragraph lr ls it lt b lu mz ju lw lx na jx lz ma nb mc md me nc mg mh mi nd mk ml mm im bi translated">2.很难标记数据，因为这需要人工操作。</p><p id="5564" class="pw-post-body-paragraph lr ls it lt b lu mz ju lw lx na jx lz ma nb mc md me nc mg mh mi nd mk ml mm im bi translated">3.一些学习算法需要大量的数据才能很好地工作。</p><h1 id="006c" class="kz la it bd lb lc ld le lf lg lh li lj jz lk ka ll kc lm kd ln kf lo kg lp lq bi translated">何时使用监督学习需要考虑的三种方法</h1><p id="d6a5" class="pw-post-body-paragraph lr ls it lt b lu lv ju lw lx ly jx lz ma mb mc md me mf mg mh mi mj mk ml mm im bi translated">1.分类:这是当计算系统被给定一组数据点时，需要学习将它们分类到不同的组中。例如，假设给某人一组不同动物的图片。在这种情况下，可以给计算系统一个用例，将它们分成不同的类别，例如两栖动物、爬行动物和哺乳动物。</p><p id="7690" class="pw-post-body-paragraph lr ls it lt b lu mz ju lw lx na jx lz ma nb mc md me nc mg mh mi nd mk ml mm im bi translated">2.回归:基于特定的数据点，计算系统学习预测每个数据点的连续值。例如，一个一年级学生可能会得到一组代表不同人身高的数据点；计算机系统将会根据这些信息来预测一个人的身高。</p><p id="9f7a" class="pw-post-body-paragraph lr ls it lt b lu mz ju lw lx na jx lz ma nb mc md me nc mg mh mi nd mk ml mm im bi translated">3.群集:计算系统会将数据分组到不同的群集中。例如，考虑代表不同物体颜色的数据点；计算系统需要学会将它们分成不同的颜色组。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ne"><img src="../Images/63f2d8b3a09c4ae04781d7868ffa0828.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*XSaxUP8WLnIM2SOdY9E1Tw.jpeg"/></div></div><figcaption class="ku kv gj gh gi kw kx bd b be z dk translated">来自Pexels的<a class="ae ky" href="https://www.pexels.com/@pixabay/" rel="noopener ugc nofollow" target="_blank">皮克斯贝</a></figcaption></figure><h1 id="8283" class="kz la it bd lb lc ld le lf lg lh li lj jz lk ka ll kc lm kd ln kf lo kg lp lq bi translated">前31个监督学习模型</h1><p id="8307" class="pw-post-body-paragraph lr ls it lt b lu lv ju lw lx ly jx lz ma mb mc md me mf mg mh mi mj mk ml mm im bi translated">1.线性回归</p><p id="8260" class="pw-post-body-paragraph lr ls it lt b lu mz ju lw lx na jx lz ma nb mc md me nc mg mh mi nd mk ml mm im bi translated">2.逻辑回归</p><p id="cd1f" class="pw-post-body-paragraph lr ls it lt b lu mz ju lw lx na jx lz ma nb mc md me nc mg mh mi nd mk ml mm im bi translated">3.支持向量机[2]</p><p id="6756" class="pw-post-body-paragraph lr ls it lt b lu mz ju lw lx na jx lz ma nb mc md me nc mg mh mi nd mk ml mm im bi translated">4.决策树[3]</p><p id="dc8a" class="pw-post-body-paragraph lr ls it lt b lu mz ju lw lx na jx lz ma nb mc md me nc mg mh mi nd mk ml mm im bi translated">5.随机森林[4]</p><p id="d1a5" class="pw-post-body-paragraph lr ls it lt b lu mz ju lw lx na jx lz ma nb mc md me nc mg mh mi nd mk ml mm im bi translated">6.AdaBoost [5]</p><p id="75c4" class="pw-post-body-paragraph lr ls it lt b lu mz ju lw lx na jx lz ma nb mc md me nc mg mh mi nd mk ml mm im bi translated">7.梯度推进[6]</p><p id="c800" class="pw-post-body-paragraph lr ls it lt b lu mz ju lw lx na jx lz ma nb mc md me nc mg mh mi nd mk ml mm im bi translated">8.k-最近邻[7]</p><p id="77c2" class="pw-post-body-paragraph lr ls it lt b lu mz ju lw lx na jx lz ma nb mc md me nc mg mh mi nd mk ml mm im bi translated">9.随机梯度下降[8]</p><p id="442a" class="pw-post-body-paragraph lr ls it lt b lu mz ju lw lx na jx lz ma nb mc md me nc mg mh mi nd mk ml mm im bi translated">10.朴素贝叶斯[9]</p><p id="f886" class="pw-post-body-paragraph lr ls it lt b lu mz ju lw lx na jx lz ma nb mc md me nc mg mh mi nd mk ml mm im bi translated">11.感知器[10]</p><p id="abfb" class="pw-post-body-paragraph lr ls it lt b lu mz ju lw lx na jx lz ma nb mc md me nc mg mh mi nd mk ml mm im bi translated">12.最近质心[10]</p><p id="6f5c" class="pw-post-body-paragraph lr ls it lt b lu mz ju lw lx na jx lz ma nb mc md me nc mg mh mi nd mk ml mm im bi translated">13.线性判别分析[11]</p><p id="df60" class="pw-post-body-paragraph lr ls it lt b lu mz ju lw lx na jx lz ma nb mc md me nc mg mh mi nd mk ml mm im bi translated">14.二次判别分析[12]</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi nf"><img src="../Images/b34ce9093b298609d63b263ba80494a8.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*aXaF5RGTfNs2_E4coPIVlg.jpeg"/></div></div><figcaption class="ku kv gj gh gi kw kx bd b be z dk translated">来自pexels的https://www . Pexels . com/photo/office-writing-vintage-technology-12199413/</figcaption></figure><p id="b672" class="pw-post-body-paragraph lr ls it lt b lu mz ju lw lx na jx lz ma nb mc md me nc mg mh mi nd mk ml mm im bi translated">15.手推车[13]</p><p id="3b47" class="pw-post-body-paragraph lr ls it lt b lu mz ju lw lx na jx lz ma nb mc md me nc mg mh mi nd mk ml mm im bi translated">16.卡方自动交互检测[14]</p><p id="4377" class="pw-post-body-paragraph lr ls it lt b lu mz ju lw lx na jx lz ma nb mc md me nc mg mh mi nd mk ml mm im bi translated">17.隔离森林[15]</p><p id="95e0" class="pw-post-body-paragraph lr ls it lt b lu mz ju lw lx na jx lz ma nb mc md me nc mg mh mi nd mk ml mm im bi translated">18.一级SVM [16]</p><p id="fc11" class="pw-post-body-paragraph lr ls it lt b lu mz ju lw lx na jx lz ma nb mc md me nc mg mh mi nd mk ml mm im bi translated">19.额外的树分类器[17][18][19]</p><p id="33b5" class="pw-post-body-paragraph lr ls it lt b lu mz ju lw lx na jx lz ma nb mc md me nc mg mh mi nd mk ml mm im bi translated">20.特征集聚[20]</p><p id="d23b" class="pw-post-body-paragraph lr ls it lt b lu mz ju lw lx na jx lz ma nb mc md me nc mg mh mi nd mk ml mm im bi translated">21.多项式NB [21]</p><p id="b3e5" class="pw-post-body-paragraph lr ls it lt b lu mz ju lw lx na jx lz ma nb mc md me nc mg mh mi nd mk ml mm im bi translated">22.被动攻击性分类器[23][24]</p><p id="6623" class="pw-post-body-paragraph lr ls it lt b lu mz ju lw lx na jx lz ma nb mc md me nc mg mh mi nd mk ml mm im bi translated">23.伯努利NB [1]</p><p id="0adb" class="pw-post-body-paragraph lr ls it lt b lu mz ju lw lx na jx lz ma nb mc md me nc mg mh mi nd mk ml mm im bi translated">24.脊形分类器〔25〕</p><p id="7cd8" class="pw-post-body-paragraph lr ls it lt b lu mz ju lw lx na jx lz ma nb mc md me nc mg mh mi nd mk ml mm im bi translated">25.内核SVM [2]</p><p id="fef1" class="pw-post-body-paragraph lr ls it lt b lu mz ju lw lx na jx lz ma nb mc md me nc mg mh mi nd mk ml mm im bi translated">26.拉索回归[26]</p><p id="8ca2" class="pw-post-body-paragraph lr ls it lt b lu mz ju lw lx na jx lz ma nb mc md me nc mg mh mi nd mk ml mm im bi translated">27.岭回归[27]</p><p id="41d0" class="pw-post-body-paragraph lr ls it lt b lu mz ju lw lx na jx lz ma nb mc md me nc mg mh mi nd mk ml mm im bi translated">28.弹性网络回归[28]</p><p id="a5ca" class="pw-post-body-paragraph lr ls it lt b lu mz ju lw lx na jx lz ma nb mc md me nc mg mh mi nd mk ml mm im bi translated">29.最小二乘回归[29]</p><p id="1ebf" class="pw-post-body-paragraph lr ls it lt b lu mz ju lw lx na jx lz ma nb mc md me nc mg mh mi nd mk ml mm im bi translated">30.贝叶斯岭回归[30][31][32]</p><p id="cbf1" class="pw-post-body-paragraph lr ls it lt b lu mz ju lw lx na jx lz ma nb mc md me nc mg mh mi nd mk ml mm im bi translated">31.胡伯回归量[32]</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ng"><img src="../Images/e311255b1556bd7e4d9c6bca759473a3.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*FS1yuPPKBC_XxZHpZI83ug.jpeg"/></div></div><figcaption class="ku kv gj gh gi kw kx bd b be z dk translated">由<a class="ae ky" href="https://www.pexels.com/@padrinan/" rel="noopener ugc nofollow" target="_blank">米盖尔Á。来自Pexels的padrián</a></figcaption></figure><h1 id="4643" class="kz la it bd lb lc ld le lf lg lh li lj jz lk ka ll kc lm kd ln kf lo kg lp lq bi translated">五大必学知识的分类</h1><p id="da7b" class="pw-post-body-paragraph lr ls it lt b lu lv ju lw lx ly jx lz ma mb mc md me mf mg mh mi mj mk ml mm im bi translated">由于他们的绩效结果，这些将会出现无数次，无论是在你早期的学习中，还是在你整个职业生涯中不断进步。它们是:</p><p id="3c7a" class="pw-post-body-paragraph lr ls it lt b lu mz ju lw lx na jx lz ma nb mc md me nc mg mh mi nd mk ml mm im bi translated">1.线性回归</p><p id="8d75" class="pw-post-body-paragraph lr ls it lt b lu mz ju lw lx na jx lz ma nb mc md me nc mg mh mi nd mk ml mm im bi translated">2.支持向量机</p><p id="0265" class="pw-post-body-paragraph lr ls it lt b lu mz ju lw lx na jx lz ma nb mc md me nc mg mh mi nd mk ml mm im bi translated">3.逻辑回归</p><p id="0a3a" class="pw-post-body-paragraph lr ls it lt b lu mz ju lw lx na jx lz ma nb mc md me nc mg mh mi nd mk ml mm im bi translated">4.决策树</p><p id="89b2" class="pw-post-body-paragraph lr ls it lt b lu mz ju lw lx na jx lz ma nb mc md me nc mg mh mi nd mk ml mm im bi translated">5.集成方法</p><p id="c4fc" class="pw-post-body-paragraph lr ls it lt b lu mz ju lw lx na jx lz ma nb mc md me nc mg mh mi nd mk ml mm im bi translated">线性回归是一种监督学习算法，它基于输入要素的线性组合来预测实值输出。它实现起来更简单，并且可以应用于各种各样的问题领域。例如，如果你曾经在Zillow上查看过房价预测，这就是一切开始的地方(通过线性回归)。</p><p id="bce8" class="pw-post-body-paragraph lr ls it lt b lu mz ju lw lx na jx lz ma nb mc md me nc mg mh mi nd mk ml mm im bi translated">支持向量机是另一种公认的用于回归和分类任务的监督学习算法。该算法依赖于找到一个在特征空间中最大地分离数据点的超平面[2]。此外，它被设计为接收和处理噪声[2]，并可以处理非线性，使其成为机器学习任务的通用工具。</p><p id="d92d" class="pw-post-body-paragraph lr ls it lt b lu mz ju lw lx na jx lz ma nb mc md me nc mg mh mi nd mk ml mm im bi translated">逻辑回归是一种监督学习算法，通常用于分类任务。该算法预测实例属于特定类的概率，然后可以实现该算法来预测新的实例。</p><p id="cded" class="pw-post-body-paragraph lr ls it lt b lu mz ju lw lx na jx lz ma nb mc md me nc mg mh mi nd mk ml mm im bi translated">决策树可用于回归和分类[39]任务。该算法从训练数据中构建一个决策规则树，然后可以用它来预测新的实例。此外，决策树更易于解释和理解，这使得它们在数据挖掘和机器学习应用中易于使用。</p><p id="eb14" class="pw-post-body-paragraph lr ls it lt b lu mz ju lw lx na jx lz ma nb mc md me nc mg mh mi nd mk ml mm im bi translated">集成方法(如AdaBoost [5])是监督学习算法，它将多个单独模型的预测结合起来，以产生更准确的整体预测。集合方法通常用于精确的情况，目标是在给定的任务上达到最高的可能精度。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi nh"><img src="../Images/c315afcea7b2f97fa8a52a8aeba97d4a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*LvwH5QtQXa65Eutphl52KQ.jpeg"/></div></div><figcaption class="ku kv gj gh gi kw kx bd b be z dk translated">来自Pexels的安吉拉·罗玛</figcaption></figure><h1 id="2dcc" class="kz la it bd lb lc ld le lf lg lh li lj jz lk ka ll kc lm kd ln kf lo kg lp lq bi translated">逻辑回归和线性回归有什么不同？</h1><p id="417a" class="pw-post-body-paragraph lr ls it lt b lu lv ju lw lx ly jx lz ma mb mc md me mf mg mh mi mj mk ml mm im bi translated">1.线性回归用于预测连续结果，而逻辑回归用于预测二元结果[32]。</p><p id="5033" class="pw-post-body-paragraph lr ls it lt b lu mz ju lw lx na jx lz ma nb mc md me nc mg mh mi nd mk ml mm im bi translated">2.线性回归使用最小二乘法来优化模型，而逻辑回归使用最大似然法[35]。</p><p id="ca6a" class="pw-post-body-paragraph lr ls it lt b lu mz ju lw lx na jx lz ma nb mc md me nc mg mh mi nd mk ml mm im bi translated">3.线性回归假设预测值[38]和结果变量之间存在线性关系，而逻辑回归不做这种假设[32]。</p><p id="4948" class="pw-post-body-paragraph lr ls it lt b lu mz ju lw lx na jx lz ma nb mc md me nc mg mh mi nd mk ml mm im bi translated">4.线性回归不需要将数据转换成虚拟变量，而逻辑回归需要[33]。</p><p id="b49b" class="pw-post-body-paragraph lr ls it lt b lu mz ju lw lx na jx lz ma nb mc md me nc mg mh mi nd mk ml mm im bi translated">5.线性回归会受到异常值的影响，而逻辑回归对异常值不太敏感[34]。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ni"><img src="../Images/72cb8eed782542f07754b832f946a856.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*daNJljJfJWARbIg0M1FJkA.jpeg"/></div></div><figcaption class="ku kv gj gh gi kw kx bd b be z dk translated">来自佩克斯的安·H·T3</figcaption></figure><h1 id="f3a2" class="kz la it bd lb lc ld le lf lg lh li lj jz lk ka ll kc lm kd ln kf lo kg lp lq bi translated">监督学习最佳实践概述</h1><p id="c010" class="pw-post-body-paragraph lr ls it lt b lu lv ju lw lx ly jx lz ma mb mc md me mf mg mh mi mj mk ml mm im bi translated">1.数据预处理:数据预处理是任何机器学习管道中的关键步骤。在将数据输入模型之前，对其进行清理和格式化是非常重要的。这包括处理缺失值、异常值和数据规范化。</p><p id="33c5" class="pw-post-body-paragraph lr ls it lt b lu mz ju lw lx na jx lz ma nb mc md me nc mg mh mi nd mk ml mm im bi translated">2.交叉验证:这是一种用于评估机器学习模型准确性的技术。我们将数据分成两组，一组用于训练，另一组用于测试。以这种方式拆分数据有助于避免过度拟合训练数据。</p><p id="74f4" class="pw-post-body-paragraph lr ls it lt b lu mz ju lw lx na jx lz ma nb mc md me nc mg mh mi nd mk ml mm im bi translated">3.选择正确的模型:如此处所示，有许多不同类型的监督学习模型可用。为数据选择合适的模型对于获得良好的结果至关重要。选择模型时需要考虑几个因素，例如数据类型、手头的任务和可用资源。</p><p id="5fc8" class="pw-post-body-paragraph lr ls it lt b lu mz ju lw lx na jx lz ma nb mc md me nc mg mh mi nd mk ml mm im bi translated">4.训练/测试分割:训练/测试分割是另一种用于评估机器学习模型准确性的技术。它包括将数据分成两组，在第一组上训练模型，并在第二组上测试它。这种方法有助于避免过度拟合训练数据。</p><p id="4f87" class="pw-post-body-paragraph lr ls it lt b lu mz ju lw lx na jx lz ma nb mc md me nc mg mh mi nd mk ml mm im bi translated">5.参数调整:参数调整是机器学习中必不可少的过程；这是您调整模型的超参数以优化其性能的地方。参数调整有许多不同的方法，如网格搜索和随机搜索[35]。</p><p id="2fd3" class="pw-post-body-paragraph lr ls it lt b lu mz ju lw lx na jx lz ma nb mc md me nc mg mh mi nd mk ml mm im bi translated">6.特征工程:特征工程从现有数据创建新特征。这个过程可以通过组合现有元素、转换功能或使用领域知识创建新功能来完成。特征工程是任何机器学习管道中的功能关键步骤。</p><p id="b0db" class="pw-post-body-paragraph lr ls it lt b lu mz ju lw lx na jx lz ma nb mc md me nc mg mh mi nd mk ml mm im bi translated">7.正则化:正则化是一种用于防止机器学习模型过度拟合的技术。它通过在损失函数中增加一个惩罚项来惩罚模型的复杂性。有许多类型的正规化，如L1和L2 [36]。</p><p id="3c1e" class="pw-post-body-paragraph lr ls it lt b lu mz ju lw lx na jx lz ma nb mc md me nc mg mh mi nd mk ml mm im bi translated">8.偏差/方差权衡:偏差/方差权衡是机器学习中的一个基本概念。它是指拥有一个过于简单(高偏差)的模型和拥有一个过于复杂(高方差)的模型之间的交换。找到正确的平衡对于获得好的结果至关重要。</p><p id="0f09" class="pw-post-body-paragraph lr ls it lt b lu mz ju lw lx na jx lz ma nb mc md me nc mg mh mi nd mk ml mm im bi translated">9.集成:集成是一种用于组合多个机器学习模型以创建单个更准确的模型的技术。这项技术可以通过在不同的数据子集上训练多个模型，然后对它们的预测进行平均，或者通过在不同版本的数据上引入多个模型来完成。</p><p id="c137" class="pw-post-body-paragraph lr ls it lt b lu mz ju lw lx na jx lz ma nb mc md me nc mg mh mi nd mk ml mm im bi translated">10评估指标:选择合适的评估指标对于评估机器学习模型的性能至关重要。有许多不同的评估指标可用，如准确度、精确度、召回率和F1分数。</p></div><div class="ab cl nj nk hx nl" role="separator"><span class="nm bw bk nn no np"/><span class="nm bw bk nn no np"/><span class="nm bw bk nn no"/></div><div class="im in io ip iq"><p id="89e8" class="pw-post-body-paragraph lr ls it lt b lu mz ju lw lx na jx lz ma nb mc md me nc mg mh mi nd mk ml mm im bi translated">如果您有任何编辑/修改建议或关于进一步扩展此主题的建议，请考虑与我分享您的想法。</p><h1 id="662e" class="kz la it bd lb lc ld le lf lg lh li lj jz lk ka ll kc lm kd ln kf lo kg lp lq bi translated">另外，请考虑订阅我的每周简讯:</h1><div class="nq nr gp gr ns nt"><a href="https://pventures.substack.com/" rel="noopener  ugc nofollow" target="_blank"><div class="nu ab fo"><div class="nv ab nw cl cj nx"><h2 class="bd iu gy z fp ny fr fs nz fu fw is bi translated">周日报告#1</h2><div class="oa l"><h3 class="bd b gy z fp ny fr fs nz fu fw dk translated">设计思维与AI的共生关系设计思维能向AI揭示什么，AI又能如何拥抱…</h3></div><div class="ob l"><p class="bd b dl z fp ny fr fs nz fu fw dk translated">pventures.substack.com</p></div></div><div class="oc l"><div class="od l oe of og oc oh ks nt"/></div></div></a></div><h1 id="d223" class="kz la it bd lb lc ld le lf lg lh li lj jz lk ka ll kc lm kd ln kf lo kg lp lq bi translated"><strong class="ak">我写了以下与这篇文章相关的内容；他们可能与你有相似的兴趣:</strong></h1><p id="3ae8" class="pw-post-body-paragraph lr ls it lt b lu lv ju lw lx ly jx lz ma mb mc md me mf mg mh mi mj mk ml mm im bi translated">除了这篇关于监督学习的文章，我之前提到过<strong class="lt iu">半监督学习</strong>:</p><div class="nq nr gp gr ns nt"><a href="https://medium.com/@AnilTilbe/semi-supervised-learning-guide-3-models-rise-on-top-4b03f86cdd52" rel="noopener follow" target="_blank"><div class="nu ab fo"><div class="nv ab nw cl cj nx"><h2 class="bd iu gy z fp ny fr fs nz fu fw is bi translated">半监督学习指南；3款车型拔得头筹</h2><div class="oa l"><h3 class="bd b gy z fp ny fr fs nz fu fw dk translated">我揭示了半监督学习的挑战，最佳实践，9项技术，16个基本模型，以及如何3…</h3></div><div class="ob l"><p class="bd b dl z fp ny fr fs nz fu fw dk translated">medium.com</p></div></div><div class="oc l"><div class="oi l oe of og oc oh ks nt"/></div></div></a></div><p id="c7cf" class="pw-post-body-paragraph lr ls it lt b lu mz ju lw lx na jx lz ma nb mc md me nc mg mh mi nd mk ml mm im bi translated">这是我关于<strong class="lt iu">监督学习的帖子:</strong></p><div class="nq nr gp gr ns nt"><a rel="noopener  ugc nofollow" target="_blank" href="/unsupervised-learning-14-of-the-most-important-algorithms-b3e9e07350c9"><div class="nu ab fo"><div class="nv ab nw cl cj nx"><h2 class="bd iu gy z fp ny fr fs nz fu fw is bi translated">无监督学习:14种最重要的算法</h2><div class="oa l"><h3 class="bd b gy z fp ny fr fs nz fu fw dk translated">14种算法及其使用案例的细分。</h3></div><div class="ob l"><p class="bd b dl z fp ny fr fs nz fu fw dk translated">pub.towardsai.net</p></div></div><div class="oc l"><div class="oj l oe of og oc oh ks nt"/></div></div></a></div><p id="8d28" class="pw-post-body-paragraph lr ls it lt b lu mz ju lw lx na jx lz ma nb mc md me nc mg mh mi nd mk ml mm im bi translated">如果您对<strong class="lt iu"> NLP指南</strong>感兴趣，您可以在这里找到它:</p><div class="nq nr gp gr ns nt"><a rel="noopener  ugc nofollow" target="_blank" href="/16-open-source-nlp-models-for-sentiment-analysis-one-rises-on-top-b5867e247116"><div class="nu ab fo"><div class="nv ab nw cl cj nx"><h2 class="bd iu gy z fp ny fr fs nz fu fw is bi translated">16个用于情感分析的开源NLP模型；一个在顶端升起</h2><div class="oa l"><h3 class="bd b gy z fp ny fr fs nz fu fw dk translated">介绍16款车型，深入了解风格。</h3></div><div class="ob l"><p class="bd b dl z fp ny fr fs nz fu fw dk translated">pub.towardsai.net</p></div></div><div class="oc l"><div class="ok l oe of og oc oh ks nt"/></div></div></a></div><p id="5999" class="pw-post-body-paragraph lr ls it lt b lu mz ju lw lx na jx lz ma nb mc md me nc mg mh mi nd mk ml mm im bi translated"><em class="ol">参考文献:</em></p><p id="0efc" class="pw-post-body-paragraph lr ls it lt b lu mz ju lw lx na jx lz ma nb mc md me nc mg mh mi nd mk ml mm im bi translated"><em class="ol"> 1。</em><a class="ae ky" href="https://scikit-learn.org/stable/modules/generated/sklearn.naive_bayes.BernoulliNB.html" rel="noopener ugc nofollow" target="_blank"><em class="ol">https://sci kit-learn . org/stable/modules/generated/sk learn . naive _ Bayes。BernoulliNB.html</em></a></p><p id="ebec" class="pw-post-body-paragraph lr ls it lt b lu mz ju lw lx na jx lz ma nb mc md me nc mg mh mi nd mk ml mm im bi translated"><em class="ol"> 2。</em><a class="ae ky" href="https://scikit-learn.org/stable/modules/svm.html" rel="noopener ugc nofollow" target="_blank"><em class="ol"/></a></p><p id="2cc0" class="pw-post-body-paragraph lr ls it lt b lu mz ju lw lx na jx lz ma nb mc md me nc mg mh mi nd mk ml mm im bi translated"><em class="ol"> 3。</em><a class="ae ky" href="https://www.kdnuggets.com/2020/01/decision-tree-algorithm-explained.html" rel="noopener ugc nofollow" target="_blank"><em class="ol">https://www . kdnuggets . com/2020/01/decision-tree-algorithm-explained . html</em></a></p><p id="4b21" class="pw-post-body-paragraph lr ls it lt b lu mz ju lw lx na jx lz ma nb mc md me nc mg mh mi nd mk ml mm im bi translated"><em class="ol"> 4。</em><a class="ae ky" href="https://www.ibm.com/cloud/learn/random-forest" rel="noopener ugc nofollow" target="_blank"><em class="ol">https://www.ibm.com/cloud/learn/random-forest</em></a></p><p id="852f" class="pw-post-body-paragraph lr ls it lt b lu mz ju lw lx na jx lz ma nb mc md me nc mg mh mi nd mk ml mm im bi translated"><em class="ol"> 5。</em><a class="ae ky" href="https://www.mygreatlearning.com/blog/adaboost-algorithm/" rel="noopener ugc nofollow" target="_blank">【https://www.mygreatlearning.com/blog/adaboost-algorithm/】T21</a></p><p id="5cc9" class="pw-post-body-paragraph lr ls it lt b lu mz ju lw lx na jx lz ma nb mc md me nc mg mh mi nd mk ml mm im bi translated"><em class="ol"> 6。</em><a class="ae ky" href="https://machine-learning.paperspace.com/wiki/gradient-boosting" rel="noopener ugc nofollow" target="_blank"><em class="ol">https://machine-learning . paper space . com/wiki/gradient-boosting</em></a></p><p id="980d" class="pw-post-body-paragraph lr ls it lt b lu mz ju lw lx na jx lz ma nb mc md me nc mg mh mi nd mk ml mm im bi translated"><em class="ol"> 7。</em><a class="ae ky" href="https://www.codecademy.com/learn/introduction-to-supervised-learning-skill-path/modules/k-nearest-neighbors-skill-path/cheatsheet" rel="noopener ugc nofollow" target="_blank"><em class="ol">https://www . codecademy . com/learn/introduction-to-supervised-learning-skill-path/modules/k-nearest-neighbors-skill-path/cheat sheet</em></a></p><p id="8609" class="pw-post-body-paragraph lr ls it lt b lu mz ju lw lx na jx lz ma nb mc md me nc mg mh mi nd mk ml mm im bi translated"><em class="ol"> 8。</em><a class="ae ky" href="https://realpython.com/gradient-descent-algorithm-python/" rel="noopener ugc nofollow" target="_blank"><em class="ol">https://realpython.com/gradient-descent-algorithm-python/</em></a></p><p id="e56f" class="pw-post-body-paragraph lr ls it lt b lu mz ju lw lx na jx lz ma nb mc md me nc mg mh mi nd mk ml mm im bi translated"><em class="ol"> 9。</em><a class="ae ky" href="https://highdemandskills.com/naive-bayes-supervised/" rel="noopener ugc nofollow" target="_blank"><em class="ol">https://highdemandskills.com/naive-bayes-supervised/</em></a></p><p id="5f84" class="pw-post-body-paragraph lr ls it lt b lu mz ju lw lx na jx lz ma nb mc md me nc mg mh mi nd mk ml mm im bi translated"><em class="ol"> 10。</em><a class="ae ky" href="https://idc9.github.io/stor390/notes/classification/classification.html" rel="noopener ugc nofollow" target="_blank"><em class="ol">https://IDC 9 . github . io/stor 390/notes/classification/class ification . html</em></a></p><p id="c25b" class="pw-post-body-paragraph lr ls it lt b lu mz ju lw lx na jx lz ma nb mc md me nc mg mh mi nd mk ml mm im bi translated"><em class="ol"> 11。</em><a class="ae ky" href="https://machinelearningmastery.com/linear-discriminant-analysis-for-machine-learning/" rel="noopener ugc nofollow" target="_blank"><em class="ol">https://machine learning mastery . com/linear-discriminal-analysis-for-machine-learning/</em></a></p><p id="a4c5" class="pw-post-body-paragraph lr ls it lt b lu mz ju lw lx na jx lz ma nb mc md me nc mg mh mi nd mk ml mm im bi translated"><em class="ol"> 12。</em><a class="ae ky" href="https://scikit-learn.org/stable/modules/lda_qda.html" rel="noopener ugc nofollow" target="_blank"><em class="ol">https://scikit-learn.org/stable/modules/lda_qda.html</em></a></p><p id="e5cc" class="pw-post-body-paragraph lr ls it lt b lu mz ju lw lx na jx lz ma nb mc md me nc mg mh mi nd mk ml mm im bi translated">13。<a class="ae ky" href="https://machinelearningmastery.com/classification-and-regression-trees-for-machine-learning/" rel="noopener ugc nofollow" target="_blank"><em class="ol">https://machine learning mastery . com/class ification-and-regression-trees-for-machine-learning/</em></a></p><p id="f100" class="pw-post-body-paragraph lr ls it lt b lu mz ju lw lx na jx lz ma nb mc md me nc mg mh mi nd mk ml mm im bi translated">14。<a class="ae ky" href="https://select-statistics.co.uk/blog/chaid-chi-square-automatic-interaction-detector/" rel="noopener ugc nofollow" target="_blank"><em class="ol">https://select-statistics . co . uk/blog/chaid-chi-square-automatic-interaction-detector/</em></a></p><p id="6a7b" class="pw-post-body-paragraph lr ls it lt b lu mz ju lw lx na jx lz ma nb mc md me nc mg mh mi nd mk ml mm im bi translated"><em class="ol"> 15。</em><a class="ae ky" href="https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.IsolationForest.html" rel="noopener ugc nofollow" target="_blank"><em class="ol">https://sci kit-learn . org/stable/modules/generated/sk learn . ensemble . isolation forest . html</em></a></p><p id="9f1d" class="pw-post-body-paragraph lr ls it lt b lu mz ju lw lx na jx lz ma nb mc md me nc mg mh mi nd mk ml mm im bi translated"><em class="ol"> 16。</em><a class="ae ky" href="https://scikit-learn.org/stable/auto_examples/svm/plot_oneclass.html" rel="noopener ugc nofollow" target="_blank"><em class="ol">https://scikit-learn . org/stable/auto _ examples/SVM/plot _ one class . html</em></a></p><p id="116b" class="pw-post-body-paragraph lr ls it lt b lu mz ju lw lx na jx lz ma nb mc md me nc mg mh mi nd mk ml mm im bi translated">17。<a class="ae ky" href="https://machinelearningmastery.com/extra-trees-ensemble-with-python/" rel="noopener ugc nofollow" target="_blank"><em class="ol">https://machine learning mastery . com/extra-trees-ensemble-with-python/</em></a></p><p id="f8fc" class="pw-post-body-paragraph lr ls it lt b lu mz ju lw lx na jx lz ma nb mc md me nc mg mh mi nd mk ml mm im bi translated">18。<a class="ae ky" href="https://www.geeksforgeeks.org/ml-extra-tree-classifier-for-feature-selection/" rel="noopener ugc nofollow" target="_blank"><em class="ol">https://www . geeks forgeeks . org/ml-extra-tree-classifier-for-feature-selection/</em></a></p><p id="1789" class="pw-post-body-paragraph lr ls it lt b lu mz ju lw lx na jx lz ma nb mc md me nc mg mh mi nd mk ml mm im bi translated">19。<a class="ae ky" href="https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.ExtraTreesClassifier.html" rel="noopener ugc nofollow" target="_blank"><em class="ol">https://scikit-learn . org/stable/modules/generated/sk learn . ensemble . extractreesclassifier . html</em></a></p><p id="3773" class="pw-post-body-paragraph lr ls it lt b lu mz ju lw lx na jx lz ma nb mc md me nc mg mh mi nd mk ml mm im bi translated"><em class="ol"> 20。</em><a class="ae ky" href="https://scikit-learn.org/stable/modules/generated/sklearn.cluster.FeatureAgglomeration.html" rel="noopener ugc nofollow" target="_blank"><em class="ol">https://scikit-learn . org/stable/modules/generated/sk learn . cluster . feature agglomeration . html</em></a></p><p id="9508" class="pw-post-body-paragraph lr ls it lt b lu mz ju lw lx na jx lz ma nb mc md me nc mg mh mi nd mk ml mm im bi translated"><em class="ol"> 21。</em><a class="ae ky" href="https://nlp.stanford.edu/IR-book/html/htmledition/naive-bayes-text-classification-1.html" rel="noopener ugc nofollow" target="_blank"><em class="ol">https://NLP . Stanford . edu/IR-book/html/html edition/naive-Bayes-text-class ification-1 . html</em></a></p><p id="890a" class="pw-post-body-paragraph lr ls it lt b lu mz ju lw lx na jx lz ma nb mc md me nc mg mh mi nd mk ml mm im bi translated"><em class="ol"> 22。</em><a class="ae ky" href="https://arxiv.org/pdf/1904.07496.pdf" rel="noopener ugc nofollow" target="_blank"><em class="ol">https://arxiv.org/pdf/1904.07496.pdf</em></a></p><p id="bb90" class="pw-post-body-paragraph lr ls it lt b lu mz ju lw lx na jx lz ma nb mc md me nc mg mh mi nd mk ml mm im bi translated"><em class="ol"> 23。</em><a class="ae ky" href="https://www.geeksforgeeks.org/passive-aggressive-classifiers/" rel="noopener ugc nofollow" target="_blank"><em class="ol">https://www . geeks forgeeks . org/passive-aggressional-classifiers/</em></a></p><p id="012f" class="pw-post-body-paragraph lr ls it lt b lu mz ju lw lx na jx lz ma nb mc md me nc mg mh mi nd mk ml mm im bi translated"><em class="ol"> 24。</em><a class="ae ky" href="https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.PassiveAggressiveClassifier.html" rel="noopener ugc nofollow" target="_blank"><em class="ol">https://scikit-learn . org/stable/modules/generated/sk learn . linear _ model。PassiveAggressiveClassifier.html</em></a></p><p id="dec2" class="pw-post-body-paragraph lr ls it lt b lu mz ju lw lx na jx lz ma nb mc md me nc mg mh mi nd mk ml mm im bi translated">25。<a class="ae ky" href="https://scikit-learn.org/stable/modules/linear_model.html#ridge-regression-and-classification" rel="noopener ugc nofollow" target="_blank"><em class="ol">https://scikit-learn . org/stable/modules/linear _ model . html # ridge-regression-and-class ification</em></a></p><p id="226d" class="pw-post-body-paragraph lr ls it lt b lu mz ju lw lx na jx lz ma nb mc md me nc mg mh mi nd mk ml mm im bi translated"><em class="ol"> 26。</em><a class="ae ky" href="https://www.youtube.com/watch?v=Y1EBH1Tv1Gw" rel="noopener ugc nofollow" target="_blank"><em class="ol">https://www.youtube.com/watch?v=Y1EBH1Tv1Gw</em></a></p><p id="44ea" class="pw-post-body-paragraph lr ls it lt b lu mz ju lw lx na jx lz ma nb mc md me nc mg mh mi nd mk ml mm im bi translated"><em class="ol"> 27。</em><a class="ae ky" href="https://www.mygreatlearning.com/blog/what-is-ridge-regression/" rel="noopener ugc nofollow" target="_blank"><em class="ol">https://www . mygreatlearning . com/blog/what-is-ridge-regression/</em></a></p><p id="0bfc" class="pw-post-body-paragraph lr ls it lt b lu mz ju lw lx na jx lz ma nb mc md me nc mg mh mi nd mk ml mm im bi translated">28。<a class="ae ky" href="https://www.analyticssteps.com/blogs/linear-lasso-ridge-and-elastic-net-regression-overview" rel="noopener ugc nofollow" target="_blank"><em class="ol">https://www . analyticssteps . com/blogs/linear-lasso-ridge-and-elastic-net-regression-overview</em></a></p><p id="df14" class="pw-post-body-paragraph lr ls it lt b lu mz ju lw lx na jx lz ma nb mc md me nc mg mh mi nd mk ml mm im bi translated"><em class="ol"> 29。</em><a class="ae ky" href="https://www.edureka.co/blog/least-square-regression/" rel="noopener ugc nofollow" target="_blank"><em class="ol">https://www.edureka.co/blog/least-square-regression/</em></a></p><p id="fa4e" class="pw-post-body-paragraph lr ls it lt b lu mz ju lw lx na jx lz ma nb mc md me nc mg mh mi nd mk ml mm im bi translated">三十。<a class="ae ky" href="https://alpopkes.com/posts/machine_learning/bayesian_linear_regression/" rel="noopener ugc nofollow" target="_blank"><em class="ol">https://alpopkes . com/posts/machine _ learning/Bayesian _ linear _ regression/</em></a></p><p id="6b52" class="pw-post-body-paragraph lr ls it lt b lu mz ju lw lx na jx lz ma nb mc md me nc mg mh mi nd mk ml mm im bi translated"><em class="ol"> 31。</em><a class="ae ky" href="https://stats.stackexchange.com/questions/551424/bayesian-machine-learning-for-supervised-learning" rel="noopener ugc nofollow" target="_blank"><em class="ol">https://stats . stack exchange . com/questions/551424/Bayesian-machine-learning-for-supervised-learning</em></a></p><p id="90a3" class="pw-post-body-paragraph lr ls it lt b lu mz ju lw lx na jx lz ma nb mc md me nc mg mh mi nd mk ml mm im bi translated"><em class="ol"> 32。</em><a class="ae ky" href="https://scikit-learn-extra.readthedocs.io/en/stable/modules/robust.html" rel="noopener ugc nofollow" target="_blank"><em class="ol">https://scikit-learn-extra . readthedocs . io/en/stable/modules/robust . html</em></a></p><p id="939f" class="pw-post-body-paragraph lr ls it lt b lu mz ju lw lx na jx lz ma nb mc md me nc mg mh mi nd mk ml mm im bi translated"><em class="ol"> 33。</em><a class="ae ky" href="https://www.theanalysisfactor.com/odds-ratio-categorical-predictor/" rel="noopener ugc nofollow" target="_blank"><em class="ol">https://www . the analysis factor . com/odds-ratio-categorial-predictor/</em></a></p><p id="d788" class="pw-post-body-paragraph lr ls it lt b lu mz ju lw lx na jx lz ma nb mc md me nc mg mh mi nd mk ml mm im bi translated"><em class="ol"> 34。</em><a class="ae ky" href="https://stats.stackexchange.com/questions/279010/how-does-outlier-impact-logistic-regression" rel="noopener ugc nofollow" target="_blank"><em class="ol">https://stats . stack exchange . com/questions/279010/how-does-outlier-impact-logistic-regression</em></a></p><p id="d562" class="pw-post-body-paragraph lr ls it lt b lu mz ju lw lx na jx lz ma nb mc md me nc mg mh mi nd mk ml mm im bi translated">35。<a class="ae ky" href="https://machinelearningmastery.com/hyperparameter-optimization-with-random-search-and-grid-search/" rel="noopener ugc nofollow" target="_blank"><em class="ol">https://machine learning mastery . com/hyperparameter-optimization-with-random-search-and-grid-search/</em></a></p><p id="fe87" class="pw-post-body-paragraph lr ls it lt b lu mz ju lw lx na jx lz ma nb mc md me nc mg mh mi nd mk ml mm im bi translated">36。<a class="ae ky" href="https://neptune.ai/blog/fighting-overfitting-with-l1-or-l2-regularization" rel="noopener ugc nofollow" target="_blank"><em class="ol">https://Neptune . ai/blog/fighting-over fitting-with-L1-or-L2-正则化</em> </a></p><p id="a404" class="pw-post-body-paragraph lr ls it lt b lu mz ju lw lx na jx lz ma nb mc md me nc mg mh mi nd mk ml mm im bi translated"><em class="ol"> 37。什么是机器学习管道，为什么它们很重要？。</em><a class="ae ky" href="https://www.akkio.com/post/what-are-machine-learning-pipelines-and-why-are-they-important" rel="noopener ugc nofollow" target="_blank"><em class="ol">https://www . akkio . com/post/what-are-machine-learning-pipelines-and-why-are-they-important</em></a></p><p id="53fa" class="pw-post-body-paragraph lr ls it lt b lu mz ju lw lx na jx lz ma nb mc md me nc mg mh mi nd mk ml mm im bi translated"><em class="ol"> 38。第四章线性回归|动手机器学习与r .</em><a class="ae ky" href="https://bradleyboehmke.github.io/HOML/linear-regression.html" rel="noopener ugc nofollow" target="_blank"><em class="ol">https://bradleyboehmke . github . io/HOML/Linear-Regression . html</em></a></p><p id="596d" class="pw-post-body-paragraph lr ls it lt b lu mz ju lw lx na jx lz ma nb mc md me nc mg mh mi nd mk ml mm im bi translated">39。11–8 . docx——决策树是一种什么样的树，它可以如何用于…<a class="ae ky" href="https://www.coursehero.com/file/76877217/11-8docx/" rel="noopener ugc nofollow" target="_blank"><em class="ol">https://www.coursehero.com/file/76877217/11-8docx/</em></a></p></div></div>    
</body>
</html>