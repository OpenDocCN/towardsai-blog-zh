<html>
<head>
<title>The Ethics of AI and Autonomous Vehicles</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">人工智能和自动驾驶汽车的伦理</h1>
<blockquote>原文：<a href="https://pub.towardsai.net/the-ethics-of-ai-and-autonomous-vehicles-5ddfa0fa2726?source=collection_archive---------3-----------------------#2020-07-14">https://pub.towardsai.net/the-ethics-of-ai-and-autonomous-vehicles-5ddfa0fa2726?source=collection_archive---------3-----------------------#2020-07-14</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><figure class="is it gp gr iu iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi ir"><img src="../Images/79d06a2b160e85e4b60b392a4af2c36a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*hHOekVIZXlgXA70P"/></div></div></figure><h2 id="2056" class="jc jd je bd b dl jf jg jh ji jj jk dk jl translated" aria-label="kicker paragraph"><a class="ae ep" href="https://towardsai.net/p/category/ethics" rel="noopener ugc nofollow" target="_blank">伦理</a>、<a class="ae ep" href="https://towardsai.net/p/category/opinion" rel="noopener ugc nofollow" target="_blank">观点</a>、<a class="ae ep" href="https://towardsai.net/p/category/self-driving-cars" rel="noopener ugc nofollow" target="_blank">自动驾驶汽车</a></h2><div class=""/><div class=""><h2 id="0053" class="pw-subtitle-paragraph kk jn je bd b kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb dk translated">在一个完美的世界中，人工智能应该被开发以避免不道德的问题，但这可能是不太可能的，因为这些问题并不总是可以预测的。在自动化社会，人类将比今天更有责任互相支持和保护。</h2></div><p id="5aa8" class="pw-post-body-paragraph lc ld je le b lf lg ko lh li lj kr lk ll lm ln lo lp lq lr ls lt lu lv lw lx im bi translated">在最多样化的社会部门，人工智能(AI)正在发挥重要作用。</p><p id="46b3" class="pw-post-body-paragraph lc ld je le b lf lg ko lh li lj kr lk ll lm ln lo lp lq lr ls lt lu lv lw lx im bi translated">我们没有回归点，人工智能将融入我们的日常生活，无论是职业还是社交，融入我们的未来。</p><p id="7e31" class="pw-post-body-paragraph lc ld je le b lf lg ko lh li lj kr lk ll lm ln lo lp lq lr ls lt lu lv lw lx im bi translated">随着新月体技术的采用，一些伦理问题由“会思考的计算机”的概念引起，它可以像人类一样做决定。</p><p id="43f7" class="pw-post-body-paragraph lc ld je le b lf lg ko lh li lj kr lk ll lm ln lo lp lq lr ls lt lu lv lw lx im bi translated">必须研究和检查人工智能采用的实际方法，本文开始探索智能和自主系统使用的伦理准则。</p><p id="4f8e" class="pw-post-body-paragraph lc ld je le b lf lg ko lh li lj kr lk ll lm ln lo lp lq lr ls lt lu lv lw lx im bi translated">人工智能(AI)已经在我们中间广泛应用，对人类有潜在的巨大好处，但与此同时，关于人工智能的不道德使用的一些担忧正在增长。</p><p id="0977" class="pw-post-body-paragraph lc ld je le b lf lg ko lh li lj kr lk ll lm ln lo lp lq lr ls lt lu lv lw lx im bi translated">在一个理想的世界中，人们应该配置AI以避免不道德的策略，但这可能是不切实际的，因为它无法预先定义。研究可以用来帮助监管者、执法人员和其他人识别可能在大型战略室中丢失的问题敏感解决方案。</p><p id="3d38" class="pw-post-body-paragraph lc ld je le b lf lg ko lh li lj kr lk ll lm ln lo lp lq lr ls lt lu lv lw lx im bi translated">这也表明，重新思考人工智能如何在广阔的战略空间中工作，可能适合明确拒绝学习过程中不道德的结果。</p><figure class="lz ma mb mc gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi ly"><img src="../Images/3b15a6cac452919852f51731aec010c6.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*L7udSoWb6EoUMznj"/></div></div><figcaption class="md me gj gh gi mf mg bd b be z dk translated">来源:<a class="ae mh" href="https://steamcommunity.com/sharedfiles/filedetails/?id=208332246" rel="noopener ugc nofollow" target="_blank">https://steamcommunity.com/sharedfiles/filedetails/?id=208332246 </a></figcaption></figure><h1 id="081d" class="mi mj je bd mk ml mm mn mo mp mq mr ms kt mt ku mu kw mv kx mw kz mx la my mz bi translated">从阿西莫夫和超越</h1><p id="7365" class="pw-post-body-paragraph lc ld je le b lf na ko lh li nb kr lk ll nc ln lo lp nd lr ls lt ne lv lw lx im bi translated">随着人工智能的发展，它越来越多地应用于各个领域，给我们带来了巨大的潜力来改善我们的环境，改变我们的日常生活，并使地球更加成功。与此同时，随着人工智能变得越来越主流，很难忽视机器人领域伦理和道德专家的问题。当人工智能只是科幻作品中的一个概念时，许多人质疑其应用的局限性。著名作家兼哲学家<a class="ae mh" href="https://en.wikipedia.org/wiki/Isaac_Asimov" rel="noopener ugc nofollow" target="_blank">艾萨克·阿西莫夫</a>在他的论文中创造了“<a class="ae mh" href="https://en.wikipedia.org/wiki/Three_Laws_of_Robotics" rel="noopener ugc nofollow" target="_blank">机器人三定律</a>”，旨在使人类和智能机器人共存成为可能:</p><blockquote class="nf ng nh"><p id="609b" class="lc ld ni le b lf lg ko lh li lj kr lk nj lm ln lo nk lq lr ls nl lu lv lw lx im bi translated">第一定律:机器人不得伤害人类，也不得坐视人类受到伤害。</p><p id="2f63" class="lc ld ni le b lf lg ko lh li lj kr lk nj lm ln lo nk lq lr ls nl lu lv lw lx im bi translated">第二定律:机器人必须服从人类的命令，除非这些命令与第一定律相冲突。</p><p id="8e35" class="lc ld ni le b lf lg ko lh li lj kr lk nj lm ln lo nk lq lr ls nl lu lv lw lx im bi translated">第三定律:机器人必须保护自己的存在，只要这种保护与第一或第二定律不冲突。</p></blockquote><p id="6744" class="pw-post-body-paragraph lc ld je le b lf lg ko lh li lj kr lk ll lm ln lo lp lq lr ls lt lu lv lw lx im bi translated">阿西莫夫后来补充了“零定律”，它高于其他定律，并规定:</p><blockquote class="nf ng nh"><p id="56af" class="lc ld ni le b lf lg ko lh li lj kr lk nj lm ln lo nk lq lr ls nl lu lv lw lx im bi translated">一个机器人可能不会伤害人类，除非他找到一种方法来证明所造成的伤害最终会造福全人类！</p></blockquote><p id="d865" class="pw-post-body-paragraph lc ld je le b lf lg ko lh li lj kr lk ll lm ln lo lp lq lr ls lt lu lv lw lx im bi translated">关于面对伦理道德问题如何“对话”人工智能的讨论非常全面。在一个完美的世界中，人工智能应该被开发以避免不道德的问题，但是这可能是不太可能的，因为那些问题不能被预先定义。</p><figure class="lz ma mb mc gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi nm"><img src="../Images/5720ff721402ae0414dfa74afaf363c4.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*jgRoHMc2ODinUycg.jpg"/></div></div><figcaption class="md me gj gh gi mf mg bd b be z dk translated">资料来源:西蒙·兰德莱因</figcaption></figure><h1 id="e588" class="mi mj je bd mk ml mm mn mo mp mq mr ms kt mt ku mu kw mv kx mw kz mx la my mz bi translated">一些伦理问题和自动驾驶汽车困境的例子</h1><p id="dd02" class="pw-post-body-paragraph lc ld je le b lf na ko lh li nb kr lk ll nc ln lo lp nd lr ls lt ne lv lw lx im bi translated">如果有任何可能导致一些人死亡，自动驾驶车辆应该怎么办？唯一的另一个选择是悬崖，那么这辆车在做什么？多年来，哲学家们一直在讨论类似的道德困境。尽管如此，随着自动驾驶汽车的出现，这一讨论有了新的实际应用，预计自动驾驶汽车将在未来几年成为道路上的标准。</p><p id="f7aa" class="pw-post-body-paragraph lc ld je le b lf lg ko lh li lj kr lk ll lm ln lo lp lq lr ls lt lu lv lw lx im bi translated">另一个备受讨论的问题是<strong class="le jo">无轨电车问题</strong>:想象一下，一辆给定的自动驾驶汽车有六到五名乘客，你必须拉动操纵杆才能切换到另一条车道，在这条车道上只有一个人。你会为了救他们五个而杀人吗？</p><p id="eaf6" class="pw-post-body-paragraph lc ld je le b lf lg ko lh li lj kr lk ll lm ln lo lp lq lr ls lt lu lv lw lx im bi translated">其他情况会加重这种道德责任。比如你在马路对面的人行天桥上，可以看到一辆五人车。你身后有一个大个子，你知道他的体重足以让车停下来。为了救那五个人把他赶下桥是道德的事情吗？</p><p id="9556" class="pw-post-body-paragraph lc ld je le b lf lg ko lh li lj kr lk ll lm ln lo lp lq lr ls lt lu lv lw lx im bi translated">我知道这些问题不容易回答。当非哲学人士被问及无人驾驶汽车应该如何应对乘客或司机死亡迫在眉睫的情况时，大多数人表示，汽车应该被设计成防止乘客受伤。你可以在这里阅读更多关于它的信息</p><p id="1fb7" class="pw-post-body-paragraph lc ld je le b lf lg ko lh li lj kr lk ll lm ln lo lp lq lr ls lt lu lv lw lx im bi translated">由图卢兹经济学院心理学家Jean-Fran ois bonne fon领导的研究人员在他们的<a class="ae mh" href="https://www.nature.com/articles/s41586-018-0637-6.epdf?sharing_token=TGwC6RnBlLTWcbw42PZwKdRgN0jAjWel9jnR3ZoTv0OR8PKa5Kws8ZzsJ9c7-2Qpul1Vc1F8wY0eIbuOUfmConm9MpvB9JNjnmyrCoj2uOCRbTFI3tmUdV2tYqE2L6ify1SZts3Cab8akrcYXippa3cy4tK1fym-RW4nmcUaeIs1bLH-k1CI_SLsScR2FRE8_TNMpVKFZvm3lLwkIOol58Nxp3Q5Ig6GRBHC6DAs7VoAvKDUT-4BdRHQdXlTMCNQXROh0xU95qwb24i2UjIgnGDcUwC71cUbs67m4dp4SzMpnFVTLdmAFC5sBjOneMasJvLsFcQn85Eb1rJMjco9rp-fNcIM2YoTSEWJmzr1VXM%3D&amp;tracking_referrer=www.technologyreview.com" rel="noopener ugc nofollow" target="_blank">道德机器实验</a>中，这是一个在线实验平台，旨在探索自动驾驶汽车面临的道德困境。</p><p id="53ac" class="pw-post-body-paragraph lc ld je le b lf lg ko lh li lj kr lk ll lm ln lo lp lq lr ls lt lu lv lw lx im bi translated">该平台收集了来自233个国家数百万人的10种语言的4000万个决定，表明这些差异与现代制度和深层文化特征相关。</p><p id="a002" class="pw-post-body-paragraph lc ld je le b lf lg ko lh li lj kr lk ll lm ln lo lp lq lr ls lt lu lv lw lx im bi translated">当谈到自动驾驶汽车时，该实验向900多名参与者展示了一系列碰撞场景，得出的结论是，75%的人认为汽车总是会偏离并摧毁乘客，即使只是为了拯救一名路人。</p><p id="3eef" class="pw-post-body-paragraph lc ld je le b lf lg ko lh li lj kr lk ll lm ln lo lp lq lr ls lt lu lv lw lx im bi translated">我相信好的活动能给人们带来最大的快乐。基于这一逻辑，应该采取任何可能拯救最大数量的人的行动。</p><p id="034c" class="pw-post-body-paragraph lc ld je le b lf lg ko lh li lj kr lk ll lm ln lo lp lq lr ls lt lu lv lw lx im bi translated">当谈到自动驾驶汽车时，如果有大量的人因即将发生的碰撞而处于危险之中，那么继续行驶可能是一个道德和理性的决定，即使这意味着伤害无辜的行人。</p><p id="7d00" class="pw-post-body-paragraph lc ld je le b lf lg ko lh li lj kr lk ll lm ln lo lp lq lr ls lt lu lv lw lx im bi translated">一些反对电车问题的哲学家认为，在这样一个复杂的问题面前，这种方法过于简单化，因为这个问题需要对行为的后果及其道德归属进行广泛的评估。</p><p id="4b41" class="pw-post-body-paragraph lc ld je le b lf lg ko lh li lj kr lk ll lm ln lo lp lq lr ls lt lu lv lw lx im bi translated">正如<a class="ae mh" href="https://www.helenfrowe.com/" rel="noopener ugc nofollow" target="_blank">斯德哥尔摩大学实用哲学教授Helen Frowe </a>曾经说过的，自动驾驶汽车制造商必须制造汽车来保护无辜的乘客，考虑到汽车中的人无论如何都应该被认为在事故发生时“更”有责任，因为他们负责决定汽车应该去哪里以及何时去。</p><figure class="lz ma mb mc gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi nn"><img src="../Images/14a0ac30ae045c98cb02696a0111045f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*KG5Id9IsbQVpOXKJ.jpg"/></div></div><figcaption class="md me gj gh gi mf mg bd b be z dk translated"><a class="ae mh" href="https://www.theverge.com/2018/10/22/18008828/self-driving-school-bus-nhtsa-transdev-stopped" rel="noopener ugc nofollow" target="_blank">https://www . the verge . com/2018/10/22/18008828/自驾-校车-nhtsa-transdev-stopped </a></figcaption></figure><h1 id="8c7b" class="mi mj je bd mk ml mm mn mo mp mq mr ms kt mt ku mu kw mv kx mw kz mx la my mz bi translated">儿童和自动驾驶汽车呢？</h1><p id="e223" class="pw-post-body-paragraph lc ld je le b lf na ko lh li nb kr lk ll nc ln lo lp nd lr ls lt ne lv lw lx im bi translated">我知道这是个热门话题。我在这里再提出一个伦理问题:让我们考虑一下，一辆自动驾驶汽车可以在后座上容纳四名乘客或两名儿童。按照我之前的想法，如果车辆乘客都是成年人，就应该负责避让一个行人。</p><p id="0b0f" class="pw-post-body-paragraph lc ld je le b lf lg ko lh li lj kr lk ll lm ln lo lp lq lr ls lt lu lv lw lx im bi translated">但是如果车内唯一的乘客是早上上学的孩子<a class="ae mh" href="https://www.theverge.com/2018/10/22/18008828/self-driving-school-bus-nhtsa-transdev-stopped" rel="noopener ugc nofollow" target="_blank"/>会发生什么？用同样的逻辑，我们能认为这些孩子在致命事故中负有道德责任吗？或者换个角度，比如说，为了救两个孩子的命，在街上杀死一个老人，我们应该觉得道德上可以接受吗？</p><p id="30ae" class="pw-post-body-paragraph lc ld je le b lf lg ko lh li lj kr lk ll lm ln lo lp lq lr ls lt lu lv lw lx im bi translated">有些人应该争辩说，在只有成年人在车上的情况下，我们应该拯救大量的人，使一名乘客的死亡合乎伦理、道德和可以接受。</p><figure class="lz ma mb mc gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi nm"><img src="../Images/03973f192e0f3ec233862f3b673cb863.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*pyvesrN9xK_Se5A2.jpg"/></div></div></figure><h1 id="652c" class="mi mj je bd mk ml mm mn mo mp mq mr ms kt mt ku mu kw mv kx mw kz mx la my mz bi translated">人类是可预测的吗？</h1><p id="1d2c" class="pw-post-body-paragraph lc ld je le b lf na ko lh li nb kr lk ll nc ln lo lp nd lr ls lt ne lv lw lx im bi translated">如果一名行人行为不负责任，将自己放在自动驾驶汽车前面，意图使其偏离，导致乘客死亡，该怎么办？考虑到自动驾驶汽车不会判断骑自行车的人和骑自行车的人的行为，这一法律方面将很难考虑在内。</p><p id="c8b9" class="pw-post-body-paragraph lc ld je le b lf lg ko lh li lj kr lk ll lm ln lo lp lq lr ls lt lu lv lw lx im bi translated">尽管有数百篇文章涉及每一个伦理细节，哲学家们还远未找到解决方案。例如，按照道德应该优化满意度的规范观念，故意让一个路人的车转向，是否比什么都不做而让车到达一群人那里更不道德？</p><p id="4aee" class="pw-post-body-paragraph lc ld je le b lf lg ko lh li lj kr lk ll lm ln lo lp lq lr ls lt lu lv lw lx im bi translated">老实说，我认为人类有责任支持和保护他人。故意造成伤害或死亡的行为在伦理上比任何可能阻止它们的行为都更糟糕。</p><p id="6d49" class="pw-post-body-paragraph lc ld je le b lf lg ko lh li lj kr lk ll lm ln lo lp lq lr ls lt lu lv lw lx im bi translated">自动驾驶汽车只能在只有两条行动路线的情况下很少相遇。总有一天，该系统将不得不选择是伤害一名路人还是一名司机，这远非不可能。</p><p id="fa4d" class="pw-post-body-paragraph lc ld je le b lf lg ko lh li lj kr lk ll lm ln lo lp lq lr ls lt lu lv lw lx im bi translated">当然，汽车只能在只有两种行动的情况下很少相遇，并且车辆可以100 %确信任何决定都会导致死亡。但这些车辆可能有一天不得不选择是伤害路人还是司机。我们必须设计新的软件、系统和算法，考虑这些问题并做出符合伦理的决定。</p><p id="9f0e" class="pw-post-body-paragraph lc ld je le b lf lg ko lh li lj kr lk ll lm ln lo lp lq lr ls lt lu lv lw lx im bi translated">汽车制造商可能在这个问题上负有最大的责任。全球市场中的大多数顶级参与者仍在“等待”对这些道德问题发表看法，这可能是因为鉴于在这些问题上缺乏一致意见，找到满意的答案似乎很复杂。</p><figure class="lz ma mb mc gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi no"><img src="../Images/cfdc7d23ba3bf2aecdeb7cf971886726.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*2UUmUZpxRDAJAWQl.jpg"/></div></div></figure><h1 id="cb32" class="mi mj je bd mk ml mm mn mo mp mq mr ms kt mt ku mu kw mv kx mw kz mx la my mz bi translated">人工智能伦理问题和我们负责任的未来。</h1><p id="561a" class="pw-post-body-paragraph lc ld je le b lf na ko lh li nb kr lk ll nc ln lo lp nd lr ls lt ne lv lw lx im bi translated">计算机的决策为法律矛盾和错误留下了空间。</p><p id="d6c8" class="pw-post-body-paragraph lc ld je le b lf lg ko lh li lj kr lk ll lm ln lo lp lq lr ls lt lu lv lw lx im bi translated">人工智能法律争议中有几个问题。许多国家急于以多种方式发展工业和军事技术，而伦理委员会和机构则负责对人工智能进行限制和监管，以使其处于控制之下。</p><p id="e587" class="pw-post-body-paragraph lc ld je le b lf lg ko lh li lj kr lk ll lm ln lo lp lq lr ls lt lu lv lw lx im bi translated">专门小组可以审查并在某些情况下阻止学术界和私营公司的提案，但在不阻碍技术进步的情况下应对新技术威胁的合理方式是通过国会专家共识。</p><p id="fdf1" class="pw-post-body-paragraph lc ld je le b lf lg ko lh li lj kr lk ll lm ln lo lp lq lr ls lt lu lv lw lx im bi translated">最近，欧盟公布了一份文件，透露该协会正在考虑在公共场所禁止面部识别三到五年。今年，微软和IBM已经同意走这条路。同时，我希望需要更严格的规则。</p><figure class="lz ma mb mc gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi np"><img src="../Images/56329cb5c81f4bb0bcd1cfc9d0b5a300.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*seAWsXrcNhOMaV2O.jpg"/></div></div></figure><h1 id="3165" class="mi mj je bd mk ml mm mn mo mp mq mr ms kt mt ku mu kw mv kx mw kz mx la my mz bi translated">结论</h1><p id="f60c" class="pw-post-body-paragraph lc ld je le b lf na ko lh li nb kr lk ll nc ln lo lp nd lr ls lt ne lv lw lx im bi translated">人类正开始广泛使用人工智能(AI)，这可能会带来巨大的好处。然而，关于人工智能不道德使用的问题正在增加。</p><p id="1a12" class="pw-post-body-paragraph lc ld je le b lf lg ko lh li lj kr lk ll lm ln lo lp lq lr ls lt lu lv lw lx im bi translated">在一个完美的世界中，人工智能应该被开发以避免不道德的问题，但是这可能是不太可能的，因为那些问题不能被预先定义。</p><p id="4bf9" class="pw-post-body-paragraph lc ld je le b lf lg ko lh li lj kr lk ll lm ln lo lp lq lr ls lt lu lv lw lx im bi translated">关于伦理的研究可以帮助决策者、合规官员和其他机构找到在我们社会的大部分领域缺乏的对问题敏感的方法。</p><p id="a8ee" class="pw-post-body-paragraph lc ld je le b lf lg ko lh li lj kr lk ll lm ln lo lp lq lr ls lt lu lv lw lx im bi translated">无人驾驶汽车预计将在未来几年成为道路上的标准，这项技术也无法避免监管矛盾和道德问题。</p><p id="c84f" class="pw-post-body-paragraph lc ld je le b lf lg ko lh li lj kr lk ll lm ln lo lp lq lr ls lt lu lv lw lx im bi translated">在自动化社会中，人类将比今天更有责任相互支持和保护，人工智能驱动的故意造成伤害或死亡的行为将被认为在道德上比任何可能阻止它们的行为都更糟糕。我们需要现在就开始考虑这个问题！</p><p id="3ec2" class="pw-post-body-paragraph lc ld je le b lf lg ko lh li lj kr lk ll lm ln lo lp lq lr ls lt lu lv lw lx im bi translated">贾伊尔·里贝罗</p><figure class="lz ma mb mc gt iv gh gi paragraph-image"><div class="gh gi nq"><img src="../Images/66bccd3ac444c994cac04a92a8967a76.png" data-original-src="https://miro.medium.com/v2/resize:fit:834/format:webp/0*PqzufLdd4DnAL-Ev.png"/></div><figcaption class="md me gj gh gi mf mg bd b be z dk translated"><a class="ae mh" href="https://www.thinkers360.com/tl/jairribeiro" rel="noopener ugc nofollow" target="_blank">https://www.thinkers360.com/tl/jairribeiro</a></figcaption></figure></div></div>    
</body>
</html>