<html>
<head>
<title>DeepMind’s New Game to Improve Cooperation in Multi-Agent Models</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">DeepMind改进多智能体模型合作的新游戏</h1>
<blockquote>原文：<a href="https://pub.towardsai.net/deepminds-new-game-to-improve-cooperation-in-multi-agent-models-f4253bc2e376?source=collection_archive---------0-----------------------#2022-01-10">https://pub.towardsai.net/deepminds-new-game-to-improve-cooperation-in-multi-agent-models-f4253bc2e376?source=collection_archive---------0-----------------------#2022-01-10</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><h2 id="5883" class="ir is it bd b dl iu iv iw ix iy iz dk ja translated" aria-label="kicker paragraph"><a class="ae ep" href="https://towardsai.net/p/category/artificial-intelligence" rel="noopener ugc nofollow" target="_blank">人工智能</a></h2><div class=""/><div class=""><h2 id="f8b6" class="pw-subtitle-paragraph jz jc it bd b ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq dk translated">隐藏议程是一个社会行为游戏，优化了强化学习模型中的合作行为。</h2></div><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi kr"><img src="../Images/d1a9602d6aa8cd2fb7fef1747c6246ee.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*WrIEiPuw-3jO-bK5g7lvcw.png"/></div></div><figcaption class="ld le gj gh gi lf lg bd b be z dk translated">图片来源:DeepMind</figcaption></figure><blockquote class="lh li lj"><p id="92ce" class="lk ll lm ln b lo lp kd lq lr ls kg lt lu lv lw lx ly lz ma mb mc md me mf mg im bi translated">我最近创办了一份专注于人工智能的教育时事通讯，已经有超过10万名订户。《序列》是一份无废话(意思是没有炒作，没有新闻等)的ML导向时事通讯，需要5分钟阅读。目标是让你与机器学习项目、研究论文和概念保持同步。请通过订阅以下内容来尝试一下:</p></blockquote><div class="mh mi gp gr mj mk"><a href="https://thesequence.substack.com/" rel="noopener  ugc nofollow" target="_blank"><div class="ml ab fo"><div class="mm ab mn cl cj mo"><h2 class="bd jd gy z fp mp fr fs mq fu fw jc bi translated">序列|子堆栈</h2><div class="mr l"><h3 class="bd b gy z fp mp fr fs mq fu fw dk translated">订阅人工智能世界中最相关的项目和研究论文。受到110，000+的信任…</h3></div><div class="ms l"><p class="bd b dl z fp mp fr fs mq fu fw dk translated">thesequence.substack.com</p></div></div><div class="mt l"><div class="mu l mv mw mx mt my lb mk"/></div></div></a></div><p id="16d1" class="pw-post-body-paragraph lk ll it ln b lo lp kd lq lr ls kg lt mz lv lw lx na lz ma mb nb md me mf mg im bi translated">在多智能体模型中，合作是最难解决的问题之一，比如那些由强化学习技术驱动的模型。多智能体中有效的合作动态有两个主要方面:</p><p id="27d7" class="pw-post-body-paragraph lk ll it ln b lo lp kd lq lr ls kg lt mz lv lw lx na lz ma mb nb md me mf mg im bi translated"><em class="lm"> 1) </em></p><p id="c5bd" class="pw-post-body-paragraph lk ll it ln b lo lp kd lq lr ls kg lt mz lv lw lx na lz ma mb nb md me mf mg im bi translated"><em class="lm"> 2) </em> <em class="lm">与哪些代理商合作合适？</em></p><p id="09d9" class="pw-post-body-paragraph lk ll it ln b lo lp kd lq lr ls kg lt mz lv lw lx na lz ma mb nb md me mf mg im bi translated">虽然有许多定量技术可用于解决第一点，但第二点仍未得到充分探索。最近，来自DeepMind和哈佛大学<a class="ae nc" href="https://arxiv.org/abs/2201.01816" rel="noopener ugc nofollow" target="_blank">的研究人员发表了一篇论文，提出了隐藏议程</a>，这是一个2D社会演绎游戏，旨在改善多智能体模型中的合作动态。</p><p id="fd2f" class="pw-post-body-paragraph lk ll it ln b lo lp kd lq lr ls kg lt mz lv lw lx na lz ma mb nb md me mf mg im bi translated">多智能体模型中的合作挑战是非常复杂的，因为它取决于合作机制中每个智能体的机制。不同的ML代理可以共享目标，但是通常具有冲突的目标，这些目标对于环境是不可见的，因此难以量化。当在不完善的信息环境中运作时，这一挑战甚至更加突出。社会演绎游戏已经成为在不确定条件下模拟合作的流行机制。一个社交推演游戏的本质是帮助玩家推演对方隐藏的目标。</p><p id="c0b3" class="pw-post-body-paragraph lk ll it ln b lo lp kd lq lr ls kg lt mz lv lw lx na lz ma mb nb md me mf mg im bi translated">隐藏议程是一个基于两个基本群体的多个玩家的社会演绎游戏:</p><p id="f6de" class="pw-post-body-paragraph lk ll it ln b lo lp kd lq lr ls kg lt mz lv lw lx na lz ma mb nb md me mf mg im bi translated"><em class="lm">一、</em> <strong class="ln jd"> <em class="lm">船员:</em> </strong> <em class="lm">具有数量优势的队伍。他们的目标是使用分散在环境中的能源燃料电池为他们的飞船补充燃料。</em></p><p id="8707" class="pw-post-body-paragraph lk ll it ln b lo lp kd lq lr ls kg lt mz lv lw lx na lz ma mb nb md me mf mg im bi translated"><em class="lm">二。</em> <strong class="ln jd"> <em class="lm">冒名顶替者:</em> </strong> <em class="lm">具有信息优势的团队。他们的目标是通过短距离冷冻光束来阻止船员实现他们的目标。</em></p><p id="4805" class="pw-post-body-paragraph lk ll it ln b lo lp kd lq lr ls kg lt mz lv lw lx na lz ma mb nb md me mf mg im bi translated">游戏被组织成包含能量燃料电池的房间和可以存放这些电池的中央房间。隐藏议程分为两个阶段:</p><p id="a390" class="pw-post-body-paragraph lk ll it ln b lo lp kd lq lr ls kg lt mz lv lw lx na lz ma mb nb md me mf mg im bi translated"><em class="lm"> a) </em> <strong class="ln jd"> <em class="lm">情境阶段:</em> </strong> <em class="lm">在此阶段，智能体可以在环境中移动收集燃料电池。</em></p><p id="f4e4" class="pw-post-body-paragraph lk ll it ln b lo lp kd lq lr ls kg lt mz lv lw lx na lz ma mb nb md me mf mg im bi translated"><em class="lm"> b) </em></p><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div class="gh gi nd"><img src="../Images/68d3b7eb81d713d3f87bca57144d6bd0.png" data-original-src="https://miro.medium.com/v2/resize:fit:1330/format:webp/1*_5vAEB6eWWOPx0mcm4RVfA.png"/></div><figcaption class="ld le gj gh gi lf lg bd b be z dk translated">图片来源:DeepMind</figcaption></figure><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi ne"><img src="../Images/8743d5722df9ba02e29460ad7f596335.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*oUon5DndFB8iQar4D0OEBw.png"/></div></div><figcaption class="ld le gj gh gi lf lg bd b be z dk translated">图片来源:DeepMind</figcaption></figure><p id="ee36" class="pw-post-body-paragraph lk ll it ln b lo lp kd lq lr ls kg lt mz lv lw lx na lz ma mb nb md me mf mg im bi translated">通过观察其余群体的投票，代理可以开始调整他们的合作行为。对于训练和评估，DeepMind使用了标准的异步优势行动者-批评家(A3C)架构。该架构基于两层CNN，之后是基于MLP模型的前馈网络。MLP的输出被传递到LSTM层。此外，该架构还包括一个用于评估代理所使用的正确策略的层。</p><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div class="gh gi nf"><img src="../Images/151a046bec2dcf660aa9d29571655c51.png" data-original-src="https://miro.medium.com/v2/resize:fit:1000/format:webp/1*p-kbPPB6mi4WTnpp9WnQ6A.png"/></div><figcaption class="ld le gj gh gi lf lg bd b be z dk translated">图片来源:DeepMind</figcaption></figure><p id="0ae8" class="pw-post-body-paragraph lk ll it ln b lo lp kd lq lr ls kg lt mz lv lw lx na lz ma mb nb md me mf mg im bi translated">隐藏议程是一个非常有趣的游戏环境，可以在多智能体模型中实现合作行为。根据定义，隐藏议程包括使用隐藏的动机(投票)和需要将该信息纳入代理的政策。我们应该看到隐藏议程已经成为DeepMind训练多智能体强化学习模型的重要组成部分。</p></div></div>    
</body>
</html>