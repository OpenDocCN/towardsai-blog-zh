<html>
<head>
<title>Fully Explained Hierarchical Clustering with Python</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">用Python全面解释了层次聚类</h1>
<blockquote>原文：<a href="https://pub.towardsai.net/fully-explained-hierarchical-clustering-with-python-ebb256317b50?source=collection_archive---------0-----------------------#2021-05-28">https://pub.towardsai.net/fully-explained-hierarchical-clustering-with-python-ebb256317b50?source=collection_archive---------0-----------------------#2021-05-28</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><h2 id="f68e" class="ir is it bd b dl iu iv iw ix iy iz dk ja translated" aria-label="kicker paragraph"><a class="ae ep" href="https://towardsai.net/p/category/programming" rel="noopener ugc nofollow" target="_blank">编程</a></h2><div class=""/><div class=""><h2 id="087d" class="pw-subtitle-paragraph jz jc it bd b ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq dk translated">无监督机器学习中的凝聚聚类</h2></div><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi kr"><img src="../Images/cf2d4eaa46055b8197c14a3f39b6b7a4.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*cLofDia-J3cCfHIS6MPS3Q.png"/></div></div><figcaption class="ld le gj gh gi lf lg bd b be z dk translated">分层聚类。作者的照片</figcaption></figure><p id="01f5" class="pw-post-body-paragraph lh li it lj b lk ll kd lm ln lo kg lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">在本文中，我们将讨论无监督机器学习中的层次聚类算法。该算法基于嵌套聚类的分裂和合并。基于距离度量合并聚类的链接标准如下所示，采用自下而上的方法。</p><ul class=""><li id="906b" class="md me it lj b lk ll ln lo lq mf lu mg ly mh mc mi mj mk ml bi translated"><strong class="lj jd"> <em class="mm">沃德联动:</em> </strong>用分层的方法使数据中的方差最小化。</li><li id="89bf" class="md me it lj b lk mn ln mo lq mp lu mq ly mr mc mi mj mk ml bi translated"><strong class="lj jd"> <em class="mm">最大关联:</em> </strong>用于最小化聚类数据点的最大距离。</li><li id="8827" class="md me it lj b lk mn ln mo lq mp lu mq ly mr mc mi mj mk ml bi translated"><strong class="lj jd"> <em class="mm">平均联动:</em> </strong>用于平均聚类的数据点的距离。</li><li id="865a" class="md me it lj b lk mn ln mo lq mp lu mq ly mr mc mi mj mk ml bi translated"><strong class="lj jd"> <em class="mm">单联动:</em> </strong>用于最小化聚类中数据点的最近距离。</li></ul><p id="2c80" class="pw-post-body-paragraph lh li it lj b lk ll kd lm ln lo kg lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">树状图将显示层次聚类的可视化</p><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div class="gh gi ms"><img src="../Images/3dcae7c45edea4b67f4df4a6dff9cbc7.png" data-original-src="https://miro.medium.com/v2/resize:fit:1230/format:webp/1*_UeFTsxDueO_AsXZW0OWDA.png"/></div><figcaption class="ld le gj gh gi lf lg bd b be z dk translated">图像<a class="ae mt" href="https://www.researchgate.net/post/How_to_interpret_Dendrogram_and_relevance_of_clustering" rel="noopener ugc nofollow" target="_blank">来源</a></figcaption></figure><p id="b6b6" class="pw-post-body-paragraph lh li it lj b lk ll kd lm ln lo kg lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">链接标准以不同的时间速度给出不同的聚类。单个连锁在有噪声的数据中是不好的，并且ward连锁不能给出适当的聚类，因为距离没有变化，因此在适当平衡的聚类中是好的，并且如果我们不考虑欧几里德连锁，那么平均连锁可以用于聚类。</p><p id="7ef5" class="pw-post-body-paragraph lh li it lj b lk ll kd lm ln lo kg lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">下一个参数是<strong class="lj jd"> <em class="mm">连接</em> </strong>，它根据连接矩阵连接或合并集群。</p><p id="8142" class="pw-post-body-paragraph lh li it lj b lk ll kd lm ln lo kg lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated"><strong class="lj jd"> <em class="mm">亲和度</em> </strong>参数用于计算集群中的链接。当我们使用沃德连接时，我们只能使用欧几里得距离度量。</p><p id="aea5" class="pw-post-body-paragraph lh li it lj b lk ll kd lm ln lo kg lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">用python对层次聚类建模</p><pre class="ks kt ku kv gt mu mv mw mx aw my bi"><span id="4e66" class="mz na it mv b gy nb nc l nd ne">#importing the libraries<br/>import numpy as np<br/>import pandas as pd<br/>import matplotlib.pyplot as plt</span></pre><p id="4d3b" class="pw-post-body-paragraph lh li it lj b lk ll kd lm ln lo kg lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">读取记录商场顾客的数据集。</p><pre class="ks kt ku kv gt mu mv mw mx aw my bi"><span id="59fc" class="mz na it mv b gy nb nc l nd ne">#importing the dataset<br/>dataset = pd.read_csv('Mall_Customers.csv')</span></pre><p id="d2d1" class="pw-post-body-paragraph lh li it lj b lk ll kd lm ln lo kg lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">数据集的视图。</p><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div class="gh gi nf"><img src="../Images/563edd56f2bf44741cfe2672c3c30880.png" data-original-src="https://miro.medium.com/v2/resize:fit:946/format:webp/1*-j7-h7qW_XvDxmiznW7kmA.png"/></div><figcaption class="ld le gj gh gi lf lg bd b be z dk translated">作者的照片</figcaption></figure><p id="c0ae" class="pw-post-body-paragraph lh li it lj b lk ll kd lm ln lo kg lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">列号3和4将用于聚类，即年收入和支出得分。</p><pre class="ks kt ku kv gt mu mv mw mx aw my bi"><span id="aa2f" class="mz na it mv b gy nb nc l nd ne">x = dataset.iloc[:,[3,4]].values</span></pre><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div class="gh gi ng"><img src="../Images/95b0ed38ebd310418c55ea80895aab69.png" data-original-src="https://miro.medium.com/v2/resize:fit:336/format:webp/1*maBC13MKH_NWkf6Bo2mTZg.png"/></div><figcaption class="ld le gj gh gi lf lg bd b be z dk translated">作者的照片</figcaption></figure><p id="2902" class="pw-post-body-paragraph lh li it lj b lk ll kd lm ln lo kg lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">现在，我们将生成数据的树状图。</p><pre class="ks kt ku kv gt mu mv mw mx aw my bi"><span id="03e6" class="mz na it mv b gy nb nc l nd ne">#using the dendrogram and determine the number of clusters</span><span id="2bdc" class="mz na it mv b gy nh nc l nd ne">import scipy.cluster.hierarchy as sch</span><span id="39e4" class="mz na it mv b gy nh nc l nd ne">dendrogram = sch.dendrogram(sch.linkage(x, method = 'ward'))</span><span id="9f9c" class="mz na it mv b gy nh nc l nd ne">plt.title('Dendrogram')<br/>plt.xlabel('Customers')<br/>plt.ylabel('Euclidean Distance')</span><span id="4596" class="mz na it mv b gy nh nc l nd ne">plt.show()</span></pre><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div class="gh gi ni"><img src="../Images/6f86b3878265d020d6e744605088b872.png" data-original-src="https://miro.medium.com/v2/resize:fit:862/format:webp/1*NLEKa7YyYT61NXC_iKnWyg.png"/></div><figcaption class="ld le gj gh gi lf lg bd b be z dk translated">树形图。作者的照片</figcaption></figure><p id="962c" class="pw-post-body-paragraph lh li it lj b lk ll kd lm ln lo kg lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">该树状图显示了基于欧几里德距离的行数据点的分层聚类。它还告诉了在树状图中不同颜色的聚类的合适数目。但是聚类的最佳选择可以基于树状图中的水平线，即聚类的数量应该是5。</p><pre class="ks kt ku kv gt mu mv mw mx aw my bi"><span id="67ce" class="mz na it mv b gy nb nc l nd ne">#create the model to fit the hierarchical means clustering</span><span id="0f2e" class="mz na it mv b gy nh nc l nd ne">from sklearn.cluster import AgglomerativeClustering<br/>hc = AgglomerativeClustering(n_clusters = 5, affinity = "euclidean",<br/>                             linkage = 'ward')</span><span id="c8f7" class="mz na it mv b gy nh nc l nd ne">hc_pred = hc.fit_predict(x)</span></pre><p id="51b6" class="pw-post-body-paragraph lh li it lj b lk ll kd lm ln lo kg lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">现在绘制数据点来可视化集群。</p><pre class="ks kt ku kv gt mu mv mw mx aw my bi"><span id="1391" class="mz na it mv b gy nb nc l nd ne">#visualizing the clusters</span><span id="24ff" class="mz na it mv b gy nh nc l nd ne">plt.scatter(x[hc_pred==0,0], x[hc_pred==0,1], s = 100, c = 'red',<br/>                                              label ='Cluster1')<br/>plt.scatter(x[hc_pred==1,0], x[hc_pred==1,1], s = 100, c = 'blue',<br/>                                              label ='Cluster2')<br/>plt.scatter(x[hc_pred==2,0], x[yhc_pred==2,1], s = 100, c = 'green',<br/>                                            label = 'Cluster3')<br/>plt.scatter(x[hc_pred==3,0], x[hc_pred==3,1], s = 100, c = 'cyan',<br/>                                             label ='Cluster4')<br/>plt.scatter(x[hc_pred==4,0], x[hc_pred==4,1], s = 100, c = <br/>                                    'magenta',label = 'Cluster5')</span><span id="0491" class="mz na it mv b gy nh nc l nd ne">plt.title('Clusters of the customers')<br/>plt.xlabel('Annual income (k$)')<br/>plt.ylabel('Spending SCore (1 - 100)')<br/>plt.legend()</span><span id="a00d" class="mz na it mv b gy nh nc l nd ne">plt.show()</span></pre><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div class="gh gi nj"><img src="../Images/e888538b9485b482aa81445097c7bae1.png" data-original-src="https://miro.medium.com/v2/resize:fit:920/format:webp/1*g1flaFP0n-wQORTWpZUCIA.png"/></div><figcaption class="ld le gj gh gi lf lg bd b be z dk translated">聚类数。作者的照片</figcaption></figure><p id="4bda" class="pw-post-body-paragraph lh li it lj b lk ll kd lm ln lo kg lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">结论:</p><p id="a0a7" class="pw-post-body-paragraph lh li it lj b lk ll kd lm ln lo kg lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">这种算法用于数据挖掘和统计中，以产生相似的对象聚类。有时候这个算法会因为O(n)的时间复杂度而变得很慢，并且需要更多的内存。</p><p id="9ffa" class="pw-post-body-paragraph lh li it lj b lk ll kd lm ln lo kg lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">我希望你喜欢这篇文章。通过我的<a class="ae mt" href="https://www.linkedin.com/in/data-scientist-95040a1ab/" rel="noopener ugc nofollow" target="_blank"> LinkedIn </a>和<a class="ae mt" href="https://twitter.com/amitprius" rel="noopener ugc nofollow" target="_blank"> twitter </a>联系我。</p><h1 id="8b3f" class="nk na it bd nl nm nn no np nq nr ns nt ki nu kj nv kl nw km nx ko ny kp nz oa bi translated">推荐文章</h1><p id="3d1e" class="pw-post-body-paragraph lh li it lj b lk ob kd lm ln oc kg lp lq od ls lt lu oe lw lx ly of ma mb mc im bi translated"><a class="ae mt" href="https://medium.com/towards-artificial-intelligence/nlp-zero-to-hero-with-python-2df6fcebff6e?sk=2231d868766e96b13d1e9d7db6064df1" rel="noopener"> 1。NLP —零到英雄用Python </a> <br/> 2。<a class="ae mt" href="https://medium.com/towards-artificial-intelligence/python-data-structures-data-types-and-objects-244d0a86c3cf?sk=42f4b462499f3fc3a160b21e2c94dba6" rel="noopener"> Python数据结构数据类型和对象</a> <br/> 3。<a class="ae mt" rel="noopener ugc nofollow" target="_blank" href="/exception-handling-concepts-in-python-4d5116decac3?source=friends_link&amp;sk=a0ed49d9fdeaa67925eac34ecb55ea30">Python中的异常处理概念</a> <br/> 4。<a class="ae mt" rel="noopener ugc nofollow" target="_blank" href="/deep-learning-88e218b74a14?source=friends_link&amp;sk=540bf9088d31859d50dbddab7524ba35">为什么LSTM在深度学习方面比RNN更有用？</a> <br/> 5。<a class="ae mt" rel="noopener ugc nofollow" target="_blank" href="/neural-networks-the-rise-of-recurrent-neural-networks-df740252da88?source=friends_link&amp;sk=6844935e3de14e478ce00f0b22e419eb">神经网络:递归神经网络的兴起</a> <br/> 6。<a class="ae mt" href="https://medium.com/towards-artificial-intelligence/fully-explained-linear-regression-with-python-fe2b313f32f3?source=friends_link&amp;sk=53c91a2a51347ec2d93f8222c0e06402" rel="noopener">用Python充分解释了线性回归</a> <br/> 7。<a class="ae mt" href="https://medium.com/towards-artificial-intelligence/fully-explained-logistic-regression-with-python-f4a16413ddcd?source=friends_link&amp;sk=528181f15a44e48ea38fdd9579241a78" rel="noopener">用Python </a> <br/>充分解释了Logistic回归8。<a class="ae mt" rel="noopener ugc nofollow" target="_blank" href="/differences-between-concat-merge-and-join-with-python-1a6541abc08d?source=friends_link&amp;sk=3b37b694fb90db16275059ea752fc16a">concat()、merge()和join()与Python </a> <br/> 9的区别。<a class="ae mt" rel="noopener ugc nofollow" target="_blank" href="/data-wrangling-with-python-part-1-969e3cc81d69?source=friends_link&amp;sk=9c3649cf20f31a5c9ead51c50c89ba0b">与Python的数据角力—第一部分</a> <br/> 10。<a class="ae mt" href="https://medium.com/analytics-vidhya/confusion-matrix-in-machine-learning-91b6e2b3f9af?source=friends_link&amp;sk=11c6531da0bab7b504d518d02746d4cc" rel="noopener">机器学习中的混淆矩阵</a></p></div></div>    
</body>
</html>