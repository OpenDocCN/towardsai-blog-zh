<html>
<head>
<title>Airbnb Data Exploration with K-Means Clustering from Scratch</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">从零开始使用K-Means聚类的Airbnb数据探索</h1>
<blockquote>原文：<a href="https://pub.towardsai.net/airbnb-data-exploration-with-k-means-clustering-from-scratch-cc2688476272?source=collection_archive---------2-----------------------#2020-11-20">https://pub.towardsai.net/airbnb-data-exploration-with-k-means-clustering-from-scratch-cc2688476272?source=collection_archive---------2-----------------------#2020-11-20</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><h2 id="e411" class="io ip iq bd b dl ir is it iu iv iw dk ix translated" aria-label="kicker paragraph"><a class="ae ep" href="https://towardsai.net/p/category/machine-learning" rel="noopener ugc nofollow" target="_blank">机器学习</a></h2><div class=""/><h1 id="69e0" class="jw jx iq bd jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt bi translated">k-均值聚类——它是什么？</h1><figure class="kv kw kx ky gt kz gh gi paragraph-image"><div role="button" tabindex="0" class="la lb di lc bf ld"><div class="gh gi ku"><img src="../Images/ffa48c3c744fe18eb657d538fe2dae7d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*DYDpyyn3o0liqVi1JMNKrA.png"/></div></div><figcaption class="lg lh gj gh gi li lj bd b be z dk translated">由<a class="ae lk" href="https://hub.packtpub.com/wp-content/uploads/2018/03/164-Cover-Image.png" rel="noopener ugc nofollow" target="_blank">分组枢纽</a>拍摄</figcaption></figure><p id="48a8" class="pw-post-body-paragraph ll lm iq ln b lo lp lq lr ls lt lu lv lw lx ly lz ma mb mc md me mf mg mh mi ij bi translated">在我们深入研究Airbnb数据集和我们的发现之前，让我们对K-Means聚类算法做一个深入的回顾。</p><p id="c390" class="pw-post-body-paragraph ll lm iq ln b lo lp lq lr ls lt lu lv lw lx ly lz ma mb mc md me mf mg mh mi ij bi translated">一个<em class="mj">无监督学习器</em>接收未标记的训练数据，并对看不见的点进行预测。<em class="mj">聚类分析</em>属于无监督学习。<em class="mj">群集</em>是同一组中彼此相似(或相关)的数据对象的集合，<em class="mj">或</em>与其他组中的对象不相似(或不相关)。“好的”聚类将具有以下特征:高的类内相似性(在聚类内的内聚性<em class="mj">)和低的类间相似性(在</em>聚类之间的独特的<em class="mj">)。</em></p><p id="420b" class="pw-post-body-paragraph ll lm iq ln b lo lp lq lr ls lt lu lv lw lx ly lz ma mb mc md me mf mg mh mi ij bi translated"><strong class="ln ja"> K-Means算法</strong>是常见的一种聚类分析。它使用一种<em class="mj">分区方法</em>，其中各种分区被构建，然后通过某种标准进行评估，例如最小化误差平方和。</p><p id="e304" class="pw-post-body-paragraph ll lm iq ln b lo lp lq lr ls lt lu lv lw lx ly lz ma mb mc md me mf mg mh mi ij bi translated"><em class="mj">分割方法</em> —将n个对象的数据点D的集合分割成一组K个簇，使得距离平方和最小化。换句话说，给定K，找到优化所选划分标准的K个簇的划分。</p><p id="7000" class="pw-post-body-paragraph ll lm iq ln b lo lp lq lr ls lt lu lv lw lx ly lz ma mb mc md me mf mg mh mi ij bi translated">在K-Means(也称为劳埃德算法)中，每个聚类由该聚类的中心或<em class="mj">质心</em>来表示。让我们进入步骤:</p><p id="78df" class="pw-post-body-paragraph ll lm iq ln b lo lp lq lr ls lt lu lv lw lx ly lz ma mb mc md me mf mg mh mi ij bi translated"><strong class="ln ja">算法:</strong></p><ol class=""><li id="accc" class="mk ml iq ln b lo lp ls lt lw mm ma mn me mo mi mp mq mr ms bi translated">初始化群集质心</li><li id="6341" class="mk ml iq ln b lo mt ls mu lw mv ma mw me mx mi mp mq mr ms bi translated">随机选择K个点，并将其指定为质心</li><li id="ffa5" class="mk ml iq ln b lo mt ls mu lw mv ma mw me mx mi mp mq mr ms bi translated">在集群分配保持不变的情况下重复</li></ol><ul class=""><li id="acd2" class="mk ml iq ln b lo lp ls lt lw mm ma mn me mo mi my mq mr ms bi translated">使用距离度量将每个点分配到最近的质心</li><li id="9240" class="mk ml iq ln b lo mt ls mu lw mv ma mw me mx mi my mq mr ms bi translated">计算新分配中所有点的平均值作为新的聚类质心<em class="mj"> k </em></li></ul><p id="fece" class="pw-post-body-paragraph ll lm iq ln b lo lp lq lr ls lt lu lv lw lx ly lz ma mb mc md me mf mg mh mi ij bi translated"><strong class="ln ja">强项</strong>:</p><ul class=""><li id="ca60" class="mk ml iq ln b lo lp ls lt lw mm ma mn me mo mi my mq mr ms bi translated">容易理解</li><li id="13f9" class="mk ml iq ln b lo mt ls mu lw mv ma mw me mx mi my mq mr ms bi translated">简单实现</li><li id="cf91" class="mk ml iq ln b lo mt ls mu lw mv ma mw me mx mi my mq mr ms bi translated">效率</li><li id="cfa4" class="mk ml iq ln b lo mt ls mu lw mv ma mw me mx mi my mq mr ms bi translated">经常终止于局部最优</li><li id="202b" class="mk ml iq ln b lo mt ls mu lw mv ma mw me mx mi my mq mr ms bi translated">已经被证明在实践中工作良好</li></ul><p id="5472" class="pw-post-body-paragraph ll lm iq ln b lo lp lq lr ls lt lu lv lw lx ly lz ma mb mc md me mf mg mh mi ij bi translated"><strong class="ln ja">弱点</strong>:</p><ul class=""><li id="39e9" class="mk ml iq ln b lo lp ls lt lw mm ma mn me mo mi my mq mr ms bi translated">需要预先指定K(先验数据直觉可以帮助选择这个值)</li><li id="901d" class="mk ml iq ln b lo mt ls mu lw mv ma mw me mx mi my mq mr ms bi translated">对异常值和噪声数据敏感</li><li id="b4d9" class="mk ml iq ln b lo mt ls mu lw mv ma mw me mx mi my mq mr ms bi translated">仅适用于连续n维空间中的对象</li><li id="371b" class="mk ml iq ln b lo mt ls mu lw mv ma mw me mx mi my mq mr ms bi translated">仅对数字数据进行操作(通过使用欧几里德距离)</li></ul><h1 id="1bc1" class="jw jx iq bd jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt bi translated">纽约Airbnb数据</h1><p id="b42e" class="pw-post-body-paragraph ll lm iq ln b lo mz lq lr ls na lu lv lw nb ly lz ma nc mc md me nd mg mh mi ij bi translated">来自<a class="ae lk" href="https://www.kaggle.com/dgomonov/new-york-city-airbnb-open-data" rel="noopener ugc nofollow" target="_blank"> Kaggle </a>的这个数据集包含了2019年以来纽约市的数千个Airbnb房源。这是一个有趣的数据探索数据集——我们可以从中提取大量的想法和信息。我们可以了解哪些主人最受欢迎及其原因，哪些社区最贵，哪些房间类型最受欢迎，等等。</p><p id="a120" class="pw-post-body-paragraph ll lm iq ln b lo lp lq lr ls lt lu lv lw lx ly lz ma mb mc md me mf mg mh mi ij bi translated">让我们从使用Python库可视化数据集(并下载shapefile)开始:geopandas、descartes和shapely。</p><figure class="kv kw kx ky gt kz gh gi paragraph-image"><div role="button" tabindex="0" class="la lb di lc bf ld"><div class="gh gi ne"><img src="../Images/578cae7ee5b7a03bde442f630fcf8ca3.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*rxa_A386ygGttF8RDpsAiw.png"/></div></div><figcaption class="lg lh gj gh gi li lj bd b be z dk translated">纽约Airbnb房源</figcaption></figure><h1 id="db78" class="jw jx iq bd jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt bi translated"><strong class="ak">K-意味着从零开始</strong></h1><p id="96de" class="pw-post-body-paragraph ll lm iq ln b lo mz lq lr ls na lu lv lw nb ly lz ma nc mc md me nd mg mh mi ij bi translated">我们将从头开始构建算法。让我们从读入数据并过滤到所需的子集开始。在本例中，我们有兴趣探索更多关于斯塔滕岛附近的“全屋/公寓”房型的信息。我们希望探究评论的数量如何与列表的价格相关联。</p><pre class="kv kw kx ky gt nf ng nh ni aw nj bi"><span id="5155" class="nk jx iq ng b gy nl nm l nn no">import pandas as pd</span><span id="9f84" class="nk jx iq ng b gy np nm l nn no">df = pd.read_csv('data/new-york-city-airbnb-open-data/AB_NYC_2019.csv')</span><span id="6bc3" class="nk jx iq ng b gy np nm l nn no"># Entire Home / Apartment - Listings for Staten Island<br/>df = df[df['room_type'] == 'Entire home/apt']<br/>df = df[df['neighbourhood_group'] == 'Staten Island']<br/>df = df[['price_normalized', 'number_of_reviews']]</span></pre><h2 id="436f" class="nk jx iq bd jy nq nr dn kc ns nt dp kg lw nu nv kk ma nw nx ko me ny nz ks iw bi translated"><strong class="ak">记得预处理！</strong></h2><p id="2ea6" class="pw-post-body-paragraph ll lm iq ln b lo mz lq lr ls na lu lv lw nb ly lz ma nc mc md me nd mg mh mi ij bi translated">注意:在运行算法之前，记住对数据进行相应的预处理是很重要的，因为K-Means对异常值很敏感。筛选出异常值的一个简单方法是使用统计学中的分位数方法。</p><pre class="kv kw kx ky gt nf ng nh ni aw nj bi"><span id="4e96" class="nk jx iq ng b gy nl nm l nn no">import pandas.api.types as ptypes</span><span id="f3e6" class="nk jx iq ng b gy np nm l nn no">low = .10 #.05<br/>    high = .90 #.95<br/>    quant_df = df.quantile([low, high])<br/>    for col_name in list(df.columns):<br/>        if ptypes.is_numeric_dtype(df[col_name]):<br/>             df = df[(df[col_name] &gt; quant_df.loc[low, col_name]) &amp;<br/>\<br/>             (df[col_name] &lt; quant_df.loc[high, col_name])]</span></pre><p id="d488" class="pw-post-body-paragraph ll lm iq ln b lo lp lq lr ls lt lu lv lw lx ly lz ma mb mc md me mf mg mh mi ij bi translated">让我们把熊猫数据帧转换成一个矩阵。</p><pre class="kv kw kx ky gt nf ng nh ni aw nj bi"><span id="52c6" class="nk jx iq ng b gy nl nm l nn no">data = df.values <br/>m = data.shape[0] # num training examples<br/>n = data.shape[1] # num of features</span></pre><p id="7ef2" class="pw-post-body-paragraph ll lm iq ln b lo lp lq lr ls lt lu lv lw lx ly lz ma mb mc md me mf mg mh mi ij bi translated">现在让我们初始化我们的质心，并将它们存储在一个数组中:</p><pre class="kv kw kx ky gt nf ng nh ni aw nj bi"><span id="96d2" class="nk jx iq ng b gy nl nm l nn no">temp_centroids = np.array([]).reshape(self.n, 0)<br/>    for i in range(self.K):<br/>        rand = rd.randint(0, self.m-1)<br/>        temp_centroids = np.c_[temp_centroids, self.data[rand]]</span></pre><p id="3c10" class="pw-post-body-paragraph ll lm iq ln b lo lp lq lr ls lt lu lv lw lx ly lz ma mb mc md me mf mg mh mi ij bi translated">接下来，我们将使用欧几里德距离度量开始迭代。我们将这些距离存储在一个数组中，并在每次迭代中更新它们。</p><pre class="kv kw kx ky gt nf ng nh ni aw nj bi"><span id="6d00" class="nk jx iq ng b gy nl nm l nn no">EucDist = np.array([]).reshape(self.m, 0)<br/>    for k in range(self.K):<br/>        dist = np.sum((self.data - self.centroids[:,k])**2, axis=1)<br/>        EucDist = np.c_[EucDist, dist]</span></pre><h2 id="0739" class="nk jx iq bd jy nq nr dn kc ns nt dp kg lw nu nv kk ma nw nx ko me ny nz ks iw bi translated"><strong class="ak">结果</strong></h2><figure class="kv kw kx ky gt kz gh gi paragraph-image"><div role="button" tabindex="0" class="la lb di lc bf ld"><div class="gh gi oa"><img src="../Images/14f3864af187f86ffaeb582fc4c81edd.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*z2qjBJaaSctliMeRdT4CUg.png"/></div></div></figure><p id="004c" class="pw-post-body-paragraph ll lm iq ln b lo lp lq lr ls lt lu lv lw lx ly lz ma mb mc md me mf mg mh mi ij bi translated">正如我们所看到的，有各种各样的价格和评论。一般来说，斯塔滕岛价格在每晚20-80美元之间的“全屋/公寓”的房源评论数量最多。随着越贵的商品越不受欢迎，评论的数量也在减少。</p><h2 id="aa63" class="nk jx iq bd jy nq nr dn kc ns nt dp kg lw nu nv kk ma nw nx ko me ny nz ks iw bi translated"><strong class="ak">使用肘法</strong></h2><p id="597a" class="pw-post-body-paragraph ll lm iq ln b lo mz lq lr ls na lu lv lw nb ly lz ma nc mc md me nd mg mh mi ij bi translated">肘方法是一种我们可以用来确定k值的技术。当没有关于如何选择k的先验数据直觉时，这就很方便了。需要注意的是，如果数据不是非常聚类，肘方法不会产生好的结果。</p><figure class="kv kw kx ky gt kz gh gi paragraph-image"><div class="gh gi ob"><img src="../Images/b48a020d9beed29f909ff7fb1aca4f8f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1228/format:webp/1*XXhjTCzcS2R1v44i7N2xdg.png"/></div><figcaption class="lg lh gj gh gi li lj bd b be z dk translated">照片由<a class="ae lk" href="https://medium.com/ai-in-plain-english/what-is-k-means-clustering-3060791cb589" rel="noopener">纳夫乔特·辛格</a>拍摄</figcaption></figure><p id="b14d" class="pw-post-body-paragraph ll lm iq ln b lo lp lq lr ls lt lu lv lw lx ly lz ma mb mc md me mf mg mh mi ij bi translated">该方法将使用一系列的<em class="mj"> k </em>值来测试哪一个是最佳的。对于每个<em class="mj"> k </em>值，计算<strong class="ln ja">类内平方和(WCSS) </strong>。该度量被定义为聚类中的每个点与其各自质心之间的平方距离之和。我们选择曲线弯曲处的<em class="mj"> k </em>值作为最佳聚类数K——这就是该方法的名称。对于下图，肘方法告诉我们最佳K值是2。</p><pre class="kv kw kx ky gt nf ng nh ni aw nj bi"><span id="91a7" class="nk jx iq ng b gy nl nm l nn no">wcss_vals = np.array([])<br/>for k_val in range(1, self.K):<br/>    results, centroids = self.predict()<br/>    wcss=0<br/>        for k in range(k_val):<br/>            wcss += np.sum((results[k+1] - centroids[k,:])**2)<br/>        wcss_vals = np.append(wcss_vals, wcss)</span></pre><figure class="kv kw kx ky gt kz gh gi paragraph-image"><div class="gh gi oc"><img src="../Images/ef246d505c83b2b5b1d24cceac30a171.png" data-original-src="https://miro.medium.com/v2/resize:fit:802/format:webp/1*hXja7Cmz7jtjGNR2HxkeoQ.png"/></div></figure><h2 id="8894" class="nk jx iq bd jy nq nr dn kc ns nt dp kg lw nu nv kk ma nw nx ko me ny nz ks iw bi translated">展望未来</h2><p id="316c" class="pw-post-body-paragraph ll lm iq ln b lo mz lq lr ls na lu lv lw nb ly lz ma nc mc md me nd mg mh mi ij bi translated">K-Means是一种常见的探索算法，用于识别数据中的潜在结构和模式。它用于几个不同的领域，包括文档分割、欺诈检测、异常值分析、营销/销售等。</p><p id="a43b" class="pw-post-body-paragraph ll lm iq ln b lo lp lq lr ls lt lu lv lw lx ly lz ma mb mc md me mf mg mh mi ij bi translated">同样明显的是，对于这个特定的数据子集，K-均值可能不会揭示强信号，因为聚类似乎没有高的类内相似性和低的类间相似性。你可能在第一次的时候没有发现任何突出的东西——这没关系！这就是数据探索(和数据科学)的意义所在。</p><p id="b340" class="pw-post-body-paragraph ll lm iq ln b lo lp lq lr ls lt lu lv lw lx ly lz ma mb mc md me mf mg mh mi ij bi translated">改进算法的其他方法包括使用K++和K-Medoids。访问my <a class="ae lk" href="https://github.com/hsayedi/K-Means-Clustering-From-Scratch" rel="noopener ugc nofollow" target="_blank"> GitHub </a>查看完整代码。</p></div></div>    
</body>
</html>