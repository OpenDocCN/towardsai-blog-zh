<html>
<head>
<title>Interpretation of Isolation Forest with SHAP</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">用SHAP解读《隔离林》</h1>
<blockquote>原文：<a href="https://pub.towardsai.net/interpretation-of-isolation-forest-with-shap-d1b6af93ae71?source=collection_archive---------0-----------------------#2021-05-30">https://pub.towardsai.net/interpretation-of-isolation-forest-with-shap-d1b6af93ae71?source=collection_archive---------0-----------------------#2021-05-30</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><h2 id="5aab" class="ir is it bd b dl iu iv iw ix iy iz dk ja translated" aria-label="kicker paragraph"><a class="ae ep" href="https://towardsai.net/p/category/data-science" rel="noopener ugc nofollow" target="_blank">数据科学</a></h2><div class=""/><div class=""><h2 id="9f59" class="pw-subtitle-paragraph jz jc it bd b ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq dk translated">了解异常检测最重要功能的简单方法</h2></div><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi kr"><img src="../Images/81e5f58d002c448817f5108f508f3ef9.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*dL-txNGIgAV9sG2brAW_Zw.png"/></div></div><figcaption class="ld le gj gh gi lf lg bd b be z dk translated">作者插图</figcaption></figure><p id="6e09" class="pw-post-body-paragraph lh li it lj b lk ll kd lm ln lo kg lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">隔离林是检测数据异常最常用的技术之一。它基于树的“森林”,其中每个隔离树将异常观察与其余数据点隔离开来。尽管它简单、快速、直观，但也有一个缺点。缺乏解释。为什么特定的观察被算法认为是异常的？如何解释输出？</p><p id="9732" class="pw-post-body-paragraph lh li it lj b lk ll kd lm ln lo kg lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">有两种可能的解释，全局的和局部的。<strong class="lj jd">全局</strong>因为目标是从整体上解释模型，并理解哪些特性在通用模型中有更重要的作用。另一方面，我们需要局部地查看模型<strong class="lj jd"/>，以了解影响模型特定预测的特性。这些特征可以从局部解释到全局解释变化，反之亦然。</p><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi md"><img src="../Images/7b5723ad56d3ef7850345fda62838e9e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*gJUcXWoKvp0olP8wsO7AxA.png"/></div></div><figcaption class="ld le gj gh gi lf lg bd b be z dk translated">如何解释模型？作者插图。</figcaption></figure><p id="309b" class="pw-post-body-paragraph lh li it lj b lk ll kd lm ln lo kg lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">为了解释隔离森林，我将使用SHAP，这是Lundberg和Lee在2017年的论文“<a class="ae me" href="https://arxiv.org/abs/1705.07874" rel="noopener ugc nofollow" target="_blank">解释模型预测的统一方法</a>中提出的框架。SHAP主张沙普利附加解释。它是基于沙普利值，建立在博弈论的概念。其目的是解释每个预测因子对模型输出的贡献。怎么才能算出来？通过比较感兴趣的预测和平均预测，这是可能的。</p><p id="49bb" class="pw-post-body-paragraph lh li it lj b lk ll kd lm ln lo kg lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">在本文中，我将展示如何理解隔离林在检测数据异常时所采取的决策。使用SHAP提供的数据可视化，这是可能的。对于<em class="mf">全局解释</em>，您将看到汇总图和全局条形图，而对于<em class="mf">局部解释</em>，两个最常用的图形是力图、瀑布图和分散/相关性图。</p><pre class="ks kt ku kv gt mg mh mi mj aw mk bi"><span id="d6e3" class="ml mm it mh b gy mn mo l mp mq"><strong class="mh jd">Table of Contents:</strong></span><span id="9843" class="ml mm it mh b gy mr mo l mp mq"><strong class="mh jd">1.</strong> <a class="ae me" href="#5e2c" rel="noopener ugc nofollow"><strong class="mh jd">Shapley value</strong></a></span><span id="8852" class="ml mm it mh b gy mr mo l mp mq"><strong class="mh jd">2. </strong><a class="ae me" href="#0985" rel="noopener ugc nofollow"><strong class="mh jd">Train Isolation Forest</strong></a></span><span id="7d01" class="ml mm it mh b gy mr mo l mp mq"><strong class="mh jd">3. </strong><a class="ae me" href="#c8e1" rel="noopener ugc nofollow"><strong class="mh jd">Compute SHAP values</strong></a></span><span id="6048" class="ml mm it mh b gy mr mo l mp mq"><strong class="mh jd">4. </strong><a class="ae me" href="#4a47" rel="noopener ugc nofollow"><strong class="mh jd">Explain Single Prediction</strong></a></span><span id="88f6" class="ml mm it mh b gy mr mo l mp mq"><strong class="mh jd">5. </strong><a class="ae me" href="#8633" rel="noopener ugc nofollow"><strong class="mh jd">Explain Single Feature</strong></a></span><span id="f946" class="ml mm it mh b gy mr mo l mp mq"><strong class="mh jd">6. </strong><a class="ae me" href="#8fbb" rel="noopener ugc nofollow"><strong class="mh jd">Global Interpretability</strong></a></span><span id="7767" class="ml mm it mh b gy mr mo l mp mq"><strong class="mh jd">7. </strong><a class="ae me" href="#5ffe" rel="noopener ugc nofollow"><strong class="mh jd">Save SHAP’s objects with Pickle</strong></a></span><span id="395c" class="ml mm it mh b gy mr mo l mp mq"><strong class="mh jd">8. </strong><a class="ae me" href="#0ad2" rel="noopener ugc nofollow"><strong class="mh jd">Undersampling the dataset</strong></a></span></pre></div><div class="ab cl ms mt hx mu" role="separator"><span class="mv bw bk mw mx my"/><span class="mv bw bk mw mx my"/><span class="mv bw bk mw mx"/></div><div class="im in io ip iq"><h1 id="5e2c" class="mz mm it bd na nb nc nd ne nf ng nh ni ki nj kj nk kl nl km nm ko nn kp no np bi translated">1.沙普利值</h1><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi nq"><img src="../Images/d58bb4b4f9a408db075f480285a95d83.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*i3a_umBwfClyXlyj9P5ceA.png"/></div></div></figure><p id="b5fc" class="pw-post-body-paragraph lh li it lj b lk ll kd lm ln lo kg lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">沙普利值是由著名数学家和经济学家沙普利在1953年创造的。解决的问题如下:</p><blockquote class="nr ns nt"><p id="8afe" class="lh li mf lj b lk ll kd lm ln lo kg lp nu lr ls lt nv lv lw lx nw lz ma mb mc im bi translated"><em class="it">一群不同技能的参与者为了集体奖励而相互合作。奖励应该如何在小组中公平分配？</em></p></blockquote><p id="5088" class="pw-post-body-paragraph lh li it lj b lk ll kd lm ln lo kg lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">每个玩家对游戏的贡献都不一样，有些人贡献多，有些人贡献少。n是玩家总数，S是玩家子集，I是特定玩家，v是游戏。</p><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi nx"><img src="../Images/68f0fc53b9f8aa722357288a132e7610.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*VvmeWRJmHe13DbE0uPgxmA.png"/></div></div></figure><p id="a169" class="pw-post-body-paragraph lh li it lj b lk ll kd lm ln lo kg lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">在模型的背景下，我们的游戏是模型的结果，而玩家是数据集的特征。然后，<em class="mf">Shapley值量化每个特征对模型预测的贡献。</em></p><p id="2472" class="pw-post-body-paragraph lh li it lj b lk ll kd lm ln lo kg lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">我们可以将这个等式分成多个部分:</p><ul class=""><li id="aeb8" class="ny nz it lj b lk ll ln lo lq oa lu ob ly oc mc od oe of og bi translated">特征i 的<strong class="lj jd">边际贡献由下式表示:</strong></li></ul><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi oh"><img src="../Images/edcc87b9a3d17d4e25235bf9be166492.png" data-original-src="https://miro.medium.com/v2/resize:fit:660/format:webp/1*PZPJGhqxp8iaU_z0468S4w.png"/></div></div></figure><ul class=""><li id="e197" class="ny nz it lj b lk ll ln lo lq oa lu ob ly oc mc od oe of og bi translated">如果我们取|N|-1个特征，其中我们把特征I排除在外，我们能用它们组成多少个大小为|S|的群？</li></ul><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div class="gh gi oi"><img src="../Images/ca2c4f68af905798691747556f2c6d43.png" data-original-src="https://miro.medium.com/v2/resize:fit:1048/format:webp/1*wjIWn_mMzXz6k3fcJKxYgQ.png"/></div></figure><p id="c7d9" class="pw-post-body-paragraph lh li it lj b lk ll kd lm ln lo kg lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">该公式允许获得每个子集大小的排列数，如果我们可以的话，不包括特征I。一旦计算出该数，它将用于划分特征I对所有大小|S|的组的边际贡献。</p><ul class=""><li id="3c7d" class="ny nz it lj b lk ll ln lo lq oa lu ob ly oc mc od oe of og bi translated">最终目标是了解特征I独立于特征数量|N|的贡献大小。然后我们用|N|除前面所有的项。</li></ul></div><div class="ab cl ms mt hx mu" role="separator"><span class="mv bw bk mw mx my"/><span class="mv bw bk mw mx my"/><span class="mv bw bk mw mx"/></div><div class="im in io ip iq"><h1 id="0985" class="mz mm it bd na nb nc nd ne nf ng nh ni ki nj kj nk kl nl km nm ko nn kp no np bi translated">2.火车隔离林</h1><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div class="gh gi oj"><img src="../Images/bf9c0d9d755164cda5f121512e923b46.png" data-original-src="https://miro.medium.com/v2/resize:fit:1174/format:webp/1*-TANPVnrnxPo-p2cnZpPHQ.png"/></div><figcaption class="ld le gj gh gi lf lg bd b be z dk translated">隔离树。作者插图。</figcaption></figure><p id="c072" class="pw-post-body-paragraph lh li it lj b lk ll kd lm ln lo kg lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">首先，让我们安装shap库:</p><pre class="ks kt ku kv gt mg mh mi mj aw mk bi"><span id="167a" class="ml mm it mh b gy mn mo l mp mq">!pip install shap</span></pre><p id="2180" class="pw-post-body-paragraph lh li it lj b lk ll kd lm ln lo kg lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">现在，我们可以导入库和数据集。我们将使用需要安装的sklearn库和shap库中的波士顿房价数据集。</p><figure class="ks kt ku kv gt kw"><div class="bz fp l di"><div class="ok ol l"/></div></figure><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi om"><img src="../Images/3cfc3408429f9747570ea80a91c59e6b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*3vA1edwTHAd6JwTc.png"/></div></div></figure><p id="73cf" class="pw-post-body-paragraph lh li it lj b lk ll kd lm ln lo kg lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">它包含波士顿周围的506个邻近区域。典型的任务是预测业主自住房屋的中值，但在这种情况下，我们希望训练隔离林将数据集分为正常和异常观察。该数据集中有13个要素和目标变量:</p><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi on"><img src="../Images/350ee8fc1d2207aea30c2547c5398e8d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*IyRZDQ5WCWareIlTnCPrXQ.png"/></div></div></figure><p id="b0fd" class="pw-post-body-paragraph lh li it lj b lk ll kd lm ln lo kg lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">数据集最初不是为异常检测任务设计的，但是让我们假设有异常数据条目。例如，在列表中，我们可以在波士顿市中心买到价格非常低的房子，相对于同一地区的建筑来说有点太便宜了。然后，目标是将这些异常情况与正常情况区分开来。</p><p id="f9e2" class="pw-post-body-paragraph lh li it lj b lk ll kd lm ln lo kg lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">对于这个异常检测问题，我们将使用隔离林。使用这种模型有一些优点。首先，它是无监督的，我们不需要目标标签(我们没有)来训练模型。第二，有两个有用的属性被考虑用于检测异常:</p><ul class=""><li id="c323" class="ny nz it lj b lk ll ln lo lq oa lu ob ly oc mc od oe of og bi translated">异常在数量上很少，所以它构成了一个少数类</li><li id="c509" class="ny nz it lj b lk oo ln op lq oq lu or ly os mc od oe of og bi translated">异常观察的特征在于具有与实例非常不同的特征值。</li></ul><p id="1787" class="pw-post-body-paragraph lh li it lj b lk ll kd lm ln lo kg lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">其思想是，隔离过程应该快速隔离小深度的异常值，而正常实例通常在树的底部。对于所有这些属性，波士顿住房数据集中考虑了隔离树。</p><p id="ba89" class="pw-post-body-paragraph lh li it lj b lk ll kd lm ln lo kg lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">让我们使用sklearn库中的IsolationForest函数来创建模型。我们将固定随机状态等于42，以便每次都再现相同的输出。我们的数据集中异常的比例由参数“污染”指定，并且将被自动确定。典型值为0.1，通常取决于数据集的维度。</p><figure class="ks kt ku kv gt kw"><div class="bz fp l di"><div class="ok ol l"/></div></figure><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi ot"><img src="../Images/71d04fd393a5d7e5a0ec8556695c4f5d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*6mzuF6x7vjAHIn2biry_lw.png"/></div></div></figure><p id="5604" class="pw-post-body-paragraph lh li it lj b lk ll kd lm ln lo kg lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">为了训练模型，我们将使用所有数据集，因为我们没有异常观察的先验知识。所以，这是一个无人监管的问题。一旦模型经过训练，我们就可以进行预测，并将其保存在一个名为anomaly_label的列中。它将-1分配给异常观察值，1分配给内部值。</p><h1 id="c8e1" class="mz mm it bd na nb ou nd ne nf ov nh ni ki ow kj nk kl ox km nm ko oy kp no np bi translated">3.计算SHAP值</h1><p id="4762" class="pw-post-body-paragraph lh li it lj b lk oz kd lm ln pa kg lp lq pb ls lt lu pc lw lx ly pd ma mb mc im bi translated">SHAP提供了利用沙普利值的解释的实现。用于基于树的模型的TreeExplainer，用于神经网络的DeepExplainer和GradientExplainer。最后，KernelExplainer和Explainer适用于任何类型的模型。</p><p id="09c7" class="pw-post-body-paragraph lh li it lj b lk ll kd lm ln lo kg lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">即使它是基于树的模型，TreeExplainer也不能很好地与隔离林一起工作。所以，我将应用<strong class="lj jd">解释器</strong>函数。</p><p id="7ac1" class="pw-post-body-paragraph lh li it lj b lk ll kd lm ln lo kg lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">现在，我将展示神奇的代码行，让您发现模型输出的秘密。</p><figure class="ks kt ku kv gt kw"><div class="bz fp l di"><div class="ok ol l"/></div></figure><p id="7755" class="pw-post-body-paragraph lh li it lj b lk ll kd lm ln lo kg lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">瞧。首先，我们定义了explainer对象，使用函数Explainer通过预测方法执行隔离森林。一旦创建了这个对象，就可以获得Shapley值[2]。在开始显示SHAP的图之前，您需要加载Javascript库:</p><figure class="ks kt ku kv gt kw"><div class="bz fp l di"><div class="ok ol l"/></div></figure><h1 id="4a47" class="mz mm it bd na nb ou nd ne nf ov nh ni ki ow kj nk kl ox km nm ko oy kp no np bi translated">4.解释单一预测</h1><p id="69b4" class="pw-post-body-paragraph lh li it lj b lk oz kd lm ln pa kg lp lq pb ls lt lu pc lw lx ly pd ma mb mc im bi translated">我们可以从解释我们模型的单个预测开始。观察每个特征在模型结果中的贡献的一个清晰方法是显示<strong class="lj jd">力图</strong>。<strong class="lj jd"> </strong>我将展示第142项的结果，之前被算法归类为异常。</p><figure class="ks kt ku kv gt kw"><div class="bz fp l di"><div class="ok ol l"/></div></figure><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi pe"><img src="../Images/ea38edfc3851fddd031259777983a17c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*e7QZDD6_puwv99BbK_0MIQ.png"/></div></div></figure><p id="de76" class="pw-post-body-paragraph lh li it lj b lk ll kd lm ln lo kg lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">这个情节有三个重要方面:</p><ul class=""><li id="80d7" class="ny nz it lj b lk ll ln lo lq oa lu ob ly oc mc od oe of og bi translated"><strong class="lj jd">预测的</strong> <strong class="lj jd">值f(x) </strong>是-1，意味着我们出现了异常。在正常情况下，输出值应该等于1。</li><li id="119f" class="ny nz it lj b lk oo ln op lq oq lu or ly os mc od oe of og bi translated"><strong class="lj jd">基值</strong>，即目标变量在数据集所有行中的平均值，为0.64。您可以看到特征值如何增加或减少预测。双箭头表示每个特性相对于基线0.64的影响[3]。</li><li id="a70f" class="ny nz it lj b lk oo ln op lq oq lu or ly os mc od oe of og bi translated">红色的<strong class="lj jd"> </strong>特征显示了它们如何有助于增加预测值[4]。蓝色表示特征如何有助于降低预测。在这种情况下，蓝色的特征是发现异常项目的决定因素，而变量ZN的贡献不足以将该观察分类为正常。每个箭头的长度表示该特征对预测的影响。</li></ul><p id="351f" class="pw-post-body-paragraph lh li it lj b lk ll kd lm ln lo kg lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">图中显示了第142行的特征值，如您在数据框中选择的观察值所示:</p><figure class="ks kt ku kv gt kw"><div class="bz fp l di"><div class="ok ol l"/></div></figure><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div class="gh gi pf"><img src="../Images/3c35117014a0da0b259be4c1d7033113.png" data-original-src="https://miro.medium.com/v2/resize:fit:1198/format:webp/1*tSSMvdsP50VBplqyEL89-Q.png"/></div></figure><p id="3333" class="pw-post-body-paragraph lh li it lj b lk ll kd lm ln lo kg lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">现在，我们可以看到一个被归类为正常的观察的例子:</p><figure class="ks kt ku kv gt kw"><div class="bz fp l di"><div class="ok ol l"/></div></figure><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi pg"><img src="../Images/74ce41938c75fb8a691e4ef38b8f3e28.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*EPwPB3QhD913MEV2iL0Llg.png"/></div></div></figure><p id="9b91" class="pw-post-body-paragraph lh li it lj b lk ll kd lm ln lo kg lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">在这个例子中，有许多红色的特征增加了结果，然后该项目被认为是正常的。</p><p id="9eb1" class="pw-post-body-paragraph lh li it lj b lk ll kd lm ln lo kg lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">一个更容易理解的图表是<strong class="lj jd">瀑布图</strong>。我们不是将所有的变量放在一行中，而是将每个特性放在一行中。最重要的特征以降序列出，基于该观测中每个特征的绝对Shapley值。</p><figure class="ks kt ku kv gt kw"><div class="bz fp l di"><div class="ok ol l"/></div></figure><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi ph"><img src="../Images/43e65eec08aa742727ec6c3e4758b2cd.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*vA-wuSqgwX8nYku2O7g9Lw.png"/></div></div></figure><p id="1e66" class="pw-post-body-paragraph lh li it lj b lk ll kd lm ln lo kg lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">与力图不同的是，瀑布图提供了一个更优雅的图表来直观地显示预测的输出是如何获得的，给出了每个特性的贡献。更明显的是，每个变量的正(红色标记)和负(蓝色标记)贡献如何将底部的基础值移动到顶部的模型输出。</p><h1 id="8633" class="mz mm it bd na nb ou nd ne nf ov nh ni ki ow kj nk kl ox km nm ko oy kp no np bi translated">5.解释单一特征</h1><p id="fb1b" class="pw-post-body-paragraph lh li it lj b lk oz kd lm ln pa kg lp lq pb ls lt lu pc lw lx ly pd ma mb mc im bi translated">在前面的内容中，您看到了最相关的特征在观测预测中的作用。但是检查单个特征可能会更好，以便更好地理解它们对结果的影响。使用<strong class="lj jd">散点图</strong>可以做到这一点。也叫依赖情节。</p><figure class="ks kt ku kv gt kw"><div class="bz fp l di"><div class="ok ol l"/></div></figure><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div class="gh gi pi"><img src="../Images/2c8fb44e7cb408ac99b8f528613d5de1.png" data-original-src="https://miro.medium.com/v2/resize:fit:1316/format:webp/1*eNIziQxbffP5dXt-OygU3A.png"/></div></figure><p id="cbad" class="pw-post-body-paragraph lh li it lj b lk ll kd lm ln lo kg lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">你可以看到当一氧化氮浓度增加时，预测是如何变化的。较高的NOX值意味着出现异常项目的风险较高。</p><h1 id="8fbb" class="mz mm it bd na nb ou nd ne nf ov nh ni ki ow kj nk kl ox km nm ko oy kp no np bi translated">6.全局可解释性</h1><p id="59b5" class="pw-post-body-paragraph lh li it lj b lk oz kd lm ln pa kg lp lq pb ls lt lu pc lw lx ly pd ma mb mc im bi translated">最后，我们可以从整个数据集的角度对预测的特征重要性进行概述。事实上，这个图表叫做<strong class="lj jd">概要图</strong>:</p><figure class="ks kt ku kv gt kw"><div class="bz fp l di"><div class="ok ol l"/></div></figure><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div class="gh gi pj"><img src="../Images/58622acfddf19a671cbf5e77c35fa24b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1386/format:webp/1*-KODCWDTFmOdbL3nKkYr3g.png"/></div></figure><p id="4ffe" class="pw-post-body-paragraph lh li it lj b lk ll kd lm ln lo kg lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">需要注意一些相关特征:</p><ul class=""><li id="27fb" class="ny nz it lj b lk ll ln lo lq oa lu ob ly oc mc od oe of og bi translated">基于数据中每个特征的绝对Shapley值的总和<strong class="lj jd">对特征进行排序。然后，顶部特征对模型输出的贡献更大，因为它们具有最大的绝对值。</strong></li><li id="7011" class="ny nz it lj b lk oo ln op lq oq lu or ly os mc od oe of og bi translated">不同的颜色表示数据集中要素的值。例如，如果您查看一氧化氮(NOX)的浓度，很明显，该特性的高值意味着我们有一个异常项目，而较低的值则意味着一个正常项目。</li></ul><p id="5a13" class="pw-post-body-paragraph lh li it lj b lk ll kd lm ln lo kg lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">我们还可以显示一个条形图，称为<strong class="lj jd">全局特征重要性图</strong>，其中的特征按照全局重要性递减排序。每个要素的全局重要性计算为该要素在数据集的所有给定行中的平均绝对值。我们指定max_display来显示数据集的所有特征。</p><figure class="ks kt ku kv gt kw"><div class="bz fp l di"><div class="ok ol l"/></div></figure><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi pk"><img src="../Images/91eebb836ab68209c948c5356398fbfe.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*-yBrpwC6GsBKuKPRG4Zq8A.png"/></div></div></figure><p id="62ed" class="pw-post-body-paragraph lh li it lj b lk ll kd lm ln lo kg lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">最重要的变量是CHAS、ZN、B、CRIM和年龄。然后，它们在预测中扮演相关的角色。</p></div><div class="ab cl ms mt hx mu" role="separator"><span class="mv bw bk mw mx my"/><span class="mv bw bk mw mx my"/><span class="mv bw bk mw mx"/></div><div class="im in io ip iq"><h1 id="5ffe" class="mz mm it bd na nb nc nd ne nf ng nh ni ki nj kj nk kl nl km nm ko nn kp no np bi translated">7.用泡菜保存沙普利值</h1><p id="cef5" class="pw-post-body-paragraph lh li it lj b lk oz kd lm ln pa kg lp lq pb ls lt lu pc lw lx ly pd ma mb mc im bi translated">即使SHAP提供了一种解释你的模型的方法，实际上它也是计算密集型和耗时的。为了避免每次都计算explainer和Shapley值，最好将它们保存到两个不同的文件中。做这件事的一个工具是<a class="ae me" href="https://docs.python.org/2/library/pickle.html" rel="noopener ugc nofollow" target="_blank"> pickle </a>，这是一个序列化/反序列化Python对象结构的强大算法。</p><figure class="ks kt ku kv gt kw"><div class="bz fp l di"><div class="ok ol l"/></div></figure><p id="7fc5" class="pw-post-body-paragraph lh li it lj b lk ll kd lm ln lo kg lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">因此，pickle模块提供了保存和加载许多Python对象的方法，包括Explainer和Shapley值。</p><h1 id="0ad2" class="mz mm it bd na nb ou nd ne nf ov nh ni ki ow kj nk kl ox km nm ko oy kp no np bi translated">8.数据集采样不足</h1><p id="d725" class="pw-post-body-paragraph lh li it lj b lk oz kd lm ln pa kg lp lq pb ls lt lu pc lw lx ly pd ma mb mc im bi translated">由于数据集不平衡，SHAP运行非常慢，并且目标是检测异常，一个更快的解决方案是对数据集进行欠采样。SHAP允许对数据集进行采样，但是在我们的例子中，我们只想对正常的观测值进行欠采样，同时保留所有的异常值。我在sample和shuffle函数中都包含了随机种子，以便在运行代码时每次都能获得相同的结果。我还重置了索引，以记忆之前显示的异常数据点的索引。</p><figure class="ks kt ku kv gt kw"><div class="bz fp l di"><div class="ok ol l"/></div></figure><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi pl"><img src="../Images/247bd291fca71c54286635ce626643fb.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*SfEw6SXCckLCazYS5eycKQ.png"/></div></div></figure><p id="18a8" class="pw-post-body-paragraph lh li it lj b lk ll kd lm ln lo kg lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">我们可以再次计算SHAP值，但这次使用的数据较少:</p><figure class="ks kt ku kv gt kw"><div class="bz fp l di"><div class="ok ol l"/></div></figure><p id="b4ca" class="pw-post-body-paragraph lh li it lj b lk ll kd lm ln lo kg lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">让我们再来看看概要情节:</p><figure class="ks kt ku kv gt kw"><div class="bz fp l di"><div class="ok ol l"/></div></figure><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div class="gh gi pm"><img src="../Images/54648d92f51d1e048d066b7606a82bb0.png" data-original-src="https://miro.medium.com/v2/resize:fit:1380/format:webp/1*InbkEh_83eS5scmQgbGpXQ.png"/></div><figcaption class="ld le gj gh gi lf lg bd b be z dk translated">欠采样汇总图</figcaption></figure><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div class="gh gi pn"><img src="../Images/111f64970222a012222c296b0e524b1d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1362/format:webp/1*wi0_0oieIXZhIwCzLk4pvA.png"/></div><figcaption class="ld le gj gh gi lf lg bd b be z dk translated">包含所有数据集的汇总图</figcaption></figure><p id="9650" class="pw-post-body-paragraph lh li it lj b lk ll kd lm ln lo kg lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">差别很小，你不觉得吗？让我们试着再次解释以前观察到的同样的反常现象。我们可以通过使用索引列进行过滤来找到观察结果，我们直接显示瀑布图，因为它比力图更具可读性:</p><figure class="ks kt ku kv gt kw"><div class="bz fp l di"><div class="ok ol l"/></div></figure><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi po"><img src="../Images/e0e192847c71e083578de5d86f95619f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*KyExwftXoguEh-HAslIrvg.png"/></div></div><figcaption class="ld le gj gh gi lf lg bd b be z dk translated">欠采样的局部可解释性</figcaption></figure><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi ph"><img src="../Images/43e65eec08aa742727ec6c3e4758b2cd.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*vA-wuSqgwX8nYku2O7g9Lw.png"/></div></div><figcaption class="ld le gj gh gi lf lg bd b be z dk translated">所有数据集的本地可解释性</figcaption></figure><p id="9768" class="pw-post-body-paragraph lh li it lj b lk ll kd lm ln lo kg lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">通过所有数据集获得的局部可解释性与通过欠采样获得的局部可解释性之间存在更多差异。数据集E[f(X)]的所有行的目标变量的平均值是所有数据达到的平均值的一半，因为我们删除了60%的正常项。这些特征的影响会减小或增大。特征CHAS仍然是最重要的，而其他变量根据重要性改变顺序。NOX以一半的重量从第二名升至第四名，而PRATIO变得更加重要。我们可以说每个特征的贡献值发生了变化，但同时权重为负或正的特征保持不变。</p></div><div class="ab cl ms mt hx mu" role="separator"><span class="mv bw bk mw mx my"/><span class="mv bw bk mw mx my"/><span class="mv bw bk mw mx"/></div><div class="im in io ip iq"><h1 id="fd22" class="mz mm it bd na nb nc nd ne nf ng nh ni ki nj kj nk kl nl km nm ko nn kp no np bi translated">最终想法:</h1><p id="8fc5" class="pw-post-body-paragraph lh li it lj b lk oz kd lm ln pa kg lp lq pb ls lt lu pc lw lx ly pd ma mb mc im bi translated">恭喜你！你已经解释了隔离林的结果。有趣的见解，你不觉得吗？您已经看到了解释您的模型是如何帮助理解您真正在做什么，以及对模型的结果贡献最大的特性是什么。一个没有任何解释可能性的有效模型是不够的。你需要更多关于你的模型的信息。</p><p id="4a0a" class="pw-post-body-paragraph lh li it lj b lk ll kd lm ln lo kg lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">我希望这篇教程能帮助你对SHAP有一个大致的了解。它可以应用于任何机器学习和深度学习模型。每种类型的模型都有不同的解释器，所以在第3步要小心。你可以在<a class="ae me" href="https://github.com/eugeniaring/Medium-Articles/blob/main/Anomaly%20Detection/iforestwithshap.ipynb" rel="noopener ugc nofollow" target="_blank"> Github </a>上找到代码。</p><p id="d0e9" class="pw-post-body-paragraph lh li it lj b lk ll kd lm ln lo kg lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">我还应该指出，这种方法的唯一缺点是计算量很大。如果您有一个非常大的数据集，一个解决方案可能是只使用样本计算Shapley，而不是整个数据集，如我所示。这不是一个完美的方法，但它比等待太多时间来执行代码要好。</p><p id="9ff7" class="pw-post-body-paragraph lh li it lj b lk ll kd lm ln lo kg lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">感谢阅读。祝你有愉快的一天。</p></div><div class="ab cl ms mt hx mu" role="separator"><span class="mv bw bk mw mx my"/><span class="mv bw bk mw mx my"/><span class="mv bw bk mw mx"/></div><div class="im in io ip iq"><p id="ee0d" class="pw-post-body-paragraph lh li it lj b lk ll kd lm ln lo kg lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated"><strong class="lj jd">参考文献:</strong></p><p id="ef6a" class="pw-post-body-paragraph lh li it lj b lk ll kd lm ln lo kg lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">[1]https://arxiv.org/pdf/1705.07874.pdf<a class="ae me" href="https://arxiv.org/pdf/1705.07874.pdf" rel="noopener ugc nofollow" target="_blank"/></p><p id="9d62" class="pw-post-body-paragraph lh li it lj b lk ll kd lm ln lo kg lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">[2]<a class="ae me" href="https://towardsdatascience.com/explain-any-models-with-the-shap-values-use-the-kernelexplainer-79de9464897a" rel="noopener" target="_blank">https://towards data science . com/explain-any-models-with-the-shap-values-use-the-kernel explainer-79de 9464897 a</a></p><p id="bd6d" class="pw-post-body-paragraph lh li it lj b lk ll kd lm ln lo kg lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">[3]<a class="ae me" href="https://towardsdatascience.com/shap-how-to-interpret-machine-learning-models-with-python-2323f5af4be9" rel="noopener" target="_blank">https://towards data science . com/shap-how-to-interpret-machine-learning-models-with-python-2323 F5 a F4 be 9</a></p><p id="3268" class="pw-post-body-paragraph lh li it lj b lk ll kd lm ln lo kg lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">[4]<a class="ae me" href="https://towardsdatascience.com/introducing-shap-decision-plots-52ed3b4a1cba" rel="noopener" target="_blank">https://towards data science . com/introducing-shap-decision-plots-52 ed 3 B4 a1 CBA</a></p></div><div class="ab cl ms mt hx mu" role="separator"><span class="mv bw bk mw mx my"/><span class="mv bw bk mw mx my"/><span class="mv bw bk mw mx"/></div><div class="im in io ip iq"><p id="e046" class="pw-post-body-paragraph lh li it lj b lk ll kd lm ln lo kg lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">你喜欢我的文章吗？<a class="ae me" href="https://eugenia-anello.medium.com/membership" rel="noopener"> <em class="mf">成为会员</em> </a> <em class="mf">每天无限获取数据科学新帖！这是一种间接的支持我的方式，不会给你带来任何额外的费用。如果您已经是会员，</em> <a class="ae me" href="https://eugenia-anello.medium.com/subscribe" rel="noopener"> <em class="mf">订阅</em> </a> <em class="mf">每当我发布新的数据科学和python指南时，您都会收到电子邮件！</em></p></div></div>    
</body>
</html>