<html>
<head>
<title>Can Julia replace Python? A Data Comparison</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">朱莉娅能取代Python吗？数据比较</h1>
<blockquote>原文：<a href="https://pub.towardsai.net/programming-dc4d40c3e083?source=collection_archive---------0-----------------------#2022-02-24">https://pub.towardsai.net/programming-dc4d40c3e083?source=collection_archive---------0-----------------------#2022-02-24</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><h2 id="a64a" class="io ip iq bd b dl ir is it iu iv iw dk ix translated" aria-label="kicker paragraph"><a class="ae ep" href="https://towardsai.net/p/category/programming" rel="noopener ugc nofollow" target="_blank">编程</a></h2><div class=""/><p id="890b" class="pw-post-body-paragraph jw jx iq jy b jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ij bi translated">Julia语言的创造者声称Julia非常快，性能出色，因为它不像Python那样遵循两种语言理论，它是一种编译语言，而Python是编译和解释的融合。深入了解这两种语言在幕后是如何运作的会很有意思，但是这篇博客的目的并不是深入研究这些差异的理论细节。</p><figure class="kv kw kx ky gt kz gh gi paragraph-image"><div role="button" tabindex="0" class="la lb di lc bf ld"><div class="gh gi ku"><img src="../Images/c9218ea42f8b3338802c153906113f58.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*0FRPyxeSTL0XLeVx5GlyVA.png"/></div></div></figure><p id="48f2" class="pw-post-body-paragraph jw jx iq jy b jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ij bi translated">作为一名数据工程师，我与生俱来的行为就是理解Julia在被GBs或TBs的数据集轰炸时是如何表现的。因为我谈论的是几千兆或几千兆的数据集，所以很明显我不能马上将python与Julia或甚至丰富的Pandas库进行比较，因为我们都知道处理永远不会完成，因为Python非常慢。所以这个博客的范围是在Julia和PySpark之间做比较，我知道对一些人来说这是不公平的，但是请原谅我。博客背后的灵感是发生在2022年1月的关于朱莉娅的推特播客。</p><blockquote class="lg lh li"><p id="f668" class="jw jx lj jy b jz ka kb kc kd ke kf kg lk ki kj kk ll km kn ko lm kq kr ks kt ij bi translated"><strong class="jy ja">#注:我是在我的个人笔记本电脑上做的，这样两种语言的性能可以在相同的基础上进行测量。</strong></p></blockquote><p id="1cc2" class="pw-post-body-paragraph jw jx iq jy b jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ij bi translated"><strong class="jy ja">我的系统配置:</strong></p><figure class="kv kw kx ky gt kz gh gi paragraph-image"><div role="button" tabindex="0" class="la lb di lc bf ld"><div class="gh gi gj"><img src="../Images/96dcf017c40f73073c82b8110c396e28.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*BJ1X_k27ee3az7Wt_-obdw.png"/></div></div></figure><p id="14ab" class="pw-post-body-paragraph jw jx iq jy b jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ij bi translated"><strong class="jy ja">演示中使用的软件:</strong></p><p id="83d0" class="pw-post-body-paragraph jw jx iq jy b jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ij bi translated">我使用了一个6.5 GB大小的CSV文件，<strong class="jy ja"> python 3.6 </strong>和<strong class="jy ja"> spark 2.3.3 </strong>，以及<strong class="jy ja"> Julia 1.7.1 </strong>所有的软件都安装在我的本地系统上。</p><p id="4f92" class="pw-post-body-paragraph jw jx iq jy b jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ij bi translated">在这个分析中，没有执行任何数据操作，只有基本的读/写操作以保持简单明了。</p><ol class=""><li id="e1d0" class="ln lo iq jy b jz ka kd ke kh lp kl lq kp lr kt ls lt lu lv bi translated"><strong class="jy ja"> Pyspark </strong></li></ol><pre class="kv kw kx ky gt lw lx ly lz aw ma bi"><span id="eebe" class="mb mc iq lx b gy md me l mf mg"><em class="lj"><br/>#import libraries and connect to spark session</em><br/>from datetime import datetime<br/>t1 = datetime.now() <br/>import findspark findspark.init(‘D:\spark-2.3.3-bin-hadoop2.7’) import pyspark from pyspark.sql <br/>import SparkSession <br/>print(‘modules imported’) <br/>spark= SparkSession.builder.appName(‘BigData’).getOrCreate() </span><span id="307a" class="mb mc iq lx b gy mh me l mf mg">print(‘app created’) </span><span id="1e7d" class="mb mc iq lx b gy mh me l mf mg"><em class="lj">#read the source dataset</em> <br/>sales_df= spark.read.csv(r”D:\python_coding\Sales Data\sales_data.csv”, inferSchema=True) </span><span id="0ae8" class="mb mc iq lx b gy mh me l mf mg">sales_df.show(10) <em class="lj">#write dataset to target csv file</em> sales_df.write.format(‘csv’) \ <br/>        .option(‘header’,’true’) \ <br/>        .save(‘D:\python_coding\Sales Data\spark_emp.csv’, mode=’overwrite’) </span><span id="363f" class="mb mc iq lx b gy mh me l mf mg">t2 = datetime.now() </span><span id="2ce6" class="mb mc iq lx b gy mh me l mf mg">print(str((t2 — t1).total_seconds() * 1000) + ‘ milliseconds’) </span><span id="b496" class="mb mc iq lx b gy mh me l mf mg"><em class="lj">#Time taken by Pyspark for Read Write operation of 6.5GB csv file: 344340.066 milliseconds</em></span></pre><p id="8822" class="pw-post-body-paragraph jw jx iq jy b jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ij bi translated"><strong class="jy ja">输出:</strong></p><figure class="kv kw kx ky gt kz gh gi paragraph-image"><div role="button" tabindex="0" class="la lb di lc bf ld"><div class="gh gi mi"><img src="../Images/2530b1b498e2d9911981267a55fd1af7.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*m8ihGGiLUHKFr0ZCIAKjgA.png"/></div></div></figure><p id="cae7" class="pw-post-body-paragraph jw jx iq jy b jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ij bi translated"><strong class="jy ja"> 2。朱莉娅</strong></p><pre class="kv kw kx ky gt lw lx ly lz aw ma bi"><span id="140d" class="mb mc iq lx b gy md me l mf mg"><em class="lj"><br/>#import libraries</em> <br/>using CSV <br/>using DataFrames <br/>using Dates  </span><span id="00bf" class="mb mc iq lx b gy mh me l mf mg">d1=now() </span><span id="58ca" class="mb mc iq lx b gy mh me l mf mg"><em class="lj">#read the source dataset<br/></em>sales=CSV.read("D:\\python_coding\\Sales Data\\sales_data.csv",DataFrame) </span><span id="b5db" class="mb mc iq lx b gy mh me l mf mg"><em class="lj">#print first 10 rows of julia dataframe</em><br/>first(sales,10)</span><span id="57b6" class="mb mc iq lx b gy mh me l mf mg"><em class="lj">#write dataframe as csv file</em> <br/>CSV.write("D:\\python_coding\\Sales Data\\julia_sale.csv.csv", sales) <br/>d2=now() </span><span id="7fcf" class="mb mc iq lx b gy mh me l mf mg">print(d2-d1) <br/><em class="lj">#Time taken by Julia for Read Write operation of 6.5GB csv file: 453396 milliseconds</em></span></pre><p id="48a2" class="pw-post-body-paragraph jw jx iq jy b jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ij bi translated"><strong class="jy ja">输出:</strong></p><figure class="kv kw kx ky gt kz gh gi paragraph-image"><div role="button" tabindex="0" class="la lb di lc bf ld"><div class="gh gi mi"><img src="../Images/4ddf2574aac2cd736d55f5a0a355f935.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*ii68rRdR91U2pmW5oQaZQw.png"/></div></div></figure><p id="1657" class="pw-post-body-paragraph jw jx iq jy b jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ij bi translated">Julia处理6.5GB数据的时间约为<strong class="jy ja"> 453396毫秒</strong>，而Pyspark的处理时间为<strong class="jy ja"> 344340.066毫秒</strong>。</p><p id="df2f" class="pw-post-body-paragraph jw jx iq jy b jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ij bi translated">时间差大约在109055.934毫秒或109.055934秒或2分钟左右，这似乎相当不错，因为<strong class="jy ja"> Julia </strong>几乎已经接近并行计算框架<strong class="jy ja"> Pyspark的性能速度。</strong></p><p id="2534" class="pw-post-body-paragraph jw jx iq jy b jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ij bi translated">而且谁知道未来的子宫里有什么，有一天<strong class="jy ja"> Julia </strong>可能会成为<strong class="jy ja"> Spark </strong>处理大数据的替代品。一切皆有可能，可能性无穷无尽。</p><p id="f02f" class="pw-post-body-paragraph jw jx iq jy b jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ij bi translated">我希望我已经用这个特定用例的事实和数据以理性的方式表达了我的观点。如果我错过了什么，请分享您的反馈，我将非常乐意包括这些要点。</p><p id="255f" class="pw-post-body-paragraph jw jx iq jy b jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ij bi translated">总结一下:</p><ul class=""><li id="e585" class="ln lo iq jy b jz ka kd ke kh lp kl lq kp lr kt mj lt lu lv bi translated">使用的软件:Python 3.6，spark 2.3.3，Julia 1.7.1。</li><li id="aba4" class="ln lo iq jy b jz mk kd ml kh mm kl mn kp mo kt mj lt lu lv bi translated">数据集大小为6.5GB。</li></ul><blockquote class="lg lh li"><p id="2f86" class="jw jx lj jy b jz ka kb kc kd ke kf kg lk ki kj kk ll km kn ko lm kq kr ks kt ij bi translated">笔记本和数据集的Github链接:<a class="ae mp" href="https://github.com/viv07/PythonDataEngg/tree/main/PythonVSJulia" rel="noopener ugc nofollow" target="_blank">https://github . com/VIV 07/python dataengg/tree/main/python vsjulia</a></p></blockquote><p id="a92f" class="pw-post-body-paragraph jw jx iq jy b jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ij bi translated">礼遇:<a class="ae mp" href="https://letscodewithvivek.blogspot.com/2022/02/julia-vs-python-data-comparison.html" rel="noopener ugc nofollow" target="_blank">https://letscodewithvivek . blogspot . com/2022/02/Julia-vs-python-data-comparison . html</a></p><p id="9f1d" class="pw-post-body-paragraph jw jx iq jy b jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ij bi translated">请关注我的博客@【https://letscodewithvivek.blogspot.com/】T5T7】</p></div></div>    
</body>
</html>