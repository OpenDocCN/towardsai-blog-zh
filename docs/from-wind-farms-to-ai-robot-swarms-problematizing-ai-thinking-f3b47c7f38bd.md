# 从风力农场到人工智能机器人群——将人工智能思维问题化

> 原文：<https://pub.towardsai.net/from-wind-farms-to-ai-robot-swarms-problematizing-ai-thinking-f3b47c7f38bd?source=collection_archive---------1----------------------->

## 将自我怀疑的心理训练应用于人工智能开发

![](img/8d777ea3a5e3b00f288187c2df3e86cb.png)

黑色大黄蜂纳米无人机前视红外系统

在科学与工程中，假设研究方法已经使人类朝着科技进步迈进了一大步，这在十年前似乎是不真实的。

这种“科幻般”的人工智能研究的最近一个例子是布法罗大学的 Chowdhury 教授正在实施的一项计划，他的团队最近从 DARPA 获得了[31.6 万美元的资助，用于复制游戏玩家头脑中的数据，以训练一个可以控制多达](https://futurism.com/the-byte/darpa-gamers-brain-waves-train-robots-swarms)[250 个自动化军用机器人](http://www.buffalo.edu/ubnow/stories/2020/01/robot-swarms-video-games.html)的人工智能。

> 该团队将使用这些数据来创建人工智能算法，以指导自主空中和地面机器人的行为。
> 
> *“我们不希望 AI 系统只是模仿人类的行为；我们希望它能对人类行为的动机形成更深刻的理解。这将导致更先进的人工智能，”乔杜里说。*

现在，从表面上看，使用“克拉彭综合”标准中的“T10”人，任何非科学家都可能认为这一动机相当邪恶。协调 250 个空中和地面军用机器人来做什么？我们希望对人类行为的动机有更深入的了解。

WTF？让机器人群体追踪人类？

然而，从工程学的角度来看，这一点也不邪恶。只是在追求一个研究问题。

> *“这个项目是机器智能系统如何处理复杂、大规模异构* ***规划*** *任务的一个例子，*

引人注目的是，工程和科学思维可以追求*和*解决最令人反感的研究问题而完全不受惩罚，并通过以技术进步的名义合理化怀疑，将伦理自我(如果有的话)与科学自我拉开距离。虽然技术在伦理上是中立的，但它的发明者和管理者却不是。

具有讽刺意味的是，乔杜里教授的[谷歌引用索引](https://scholar.google.com/citations?hl=en&user=9UojRnIAAAAJ&view_op=list_works)列出了许多关于风力发电场优化的研究。他为什么要搬到机器人群里？人工智能研究的研究资助和价值化的经济学？

## 科学家是怎么知道的？

优化不仅是这类科学家和工程师的思考方式，而且*知道*。

最优化的研究问题也可以认为是一个关于通过最优化来认识*的认识论问题。*

科学家们的潜意识内心对话或逻辑可能会遵循这样的思路:

> 为了知道，我提出问题，通过研究，我将获得知识。因此，通过寻求优化风力涡轮机或机器人群体或任何东西的安排的问题，我不仅会回答这个问题，我还会完成一个认识论的认识圈。我的工作就是知道，否则我就不是工程师或科学家。我不是在做人体研究，所以如果我的任何发明伤害了人，都与我无关。

这种作为认识论结果的逻辑是一种反信仰的思维模式，伯特兰·罗素曾如此雄辩地表达过[1]:

*“想要的不是相信的意愿，而是发现的愿望，这恰恰相反。”*

哈拉里博士在他的历史书《智人》(第 254 页)中谈到了过去 300 年对超人秩序的信仰的兴起，同时后来推测智人要么被人工超级智能(ASI)消灭，要么根据他目前在未来生命研究所的研究项目进化到 H+:

> *“问问科学家为什么要研究基因组，或者试着把大脑和电脑连接起来。十有八九你会得到相同的答案:我们这样做是为了治病救人。尽管在计算机中创造思维(ASI)的意义远比治愈精神疾病更具戏剧性，但这是给出的标准理由，因为没有人能对此提出异议。”*
> 
> *智人 p464。*

如果拉塞尔博士今天还活着，他会因为人工智能对智人构成的生存威胁而修改他的反信仰认识论吗？

## 优化的替代方案

哈拉里博士概述的这种情况正在发生，这是由 Chowdhury 教授等人的研究推动的，这一切都是因为优化认识论已经成为主要的认识方式，这是由于可以获得经济和价格稳定的回报。在这种情况下，我们面临着一个真正的威胁，那就是通过优化从“知道”中产生的发明。

人类擅长解决问题，但似乎不擅长制定高尚的目标。

也许我们可以用来挑战最优化认识论的一个更好的方法是自我怀疑的辩证方法或苏格拉底方法，其“……本质……是说服对话者，尽管他认为他知道一些事情，但事实上，他不知道。”

在人工智能发展的话语中，事实上任何计算系统的发展都隐含着发明和创造一种傀儡的行为，这种傀儡对输入做出反应并产生多种输出。人工智能系统越来越擅长模仿人类的行为，包括口头行为(如 Mitsuku 或 Siri 或 Alexa)和视觉行为(如灵魂机器)。优化这些发明的行动是显而易见的。

另一种认识方式是，带着对研究人工制品是否有效的自我怀疑来追求发明过程，如果研究人工制品是不优雅和不道德的，则放弃所有假设，而不是遵循一个过程来优化这些种类的发明，以达到创造关于如何创造人类的综合表现的知识的目标。

在这种情况下，优化的内在声音将被自我怀疑所取代:

> 嗯，我知道强化学习神经网络是有效的，但由于我不确定它是如何做到的，这是不雅的，也许另一种数学更合适。嗯，”

诚然，这是一个非常困难的立场，因为人工智能魔像的吸引力和吸引力在于它们有效地“说话”，证明优化过程是有效的。

丑陋和不道德的，尽管有效的研究比比皆是。AlphaGoZero 击败大师李·塞多；Realbotix 人工智能性爱娃娃；MelNet 启用了 DeepFakes 中国的社会信用评分制度，以及用于终身面部识别、人口控制和监控的多种技术，如上图中的 FLIR 无人机。

## 在另一个星球上

在另一个假设的星球上，同样先进的智人保留了格言“不要制造虚假的偶像”，这个星球仍然相信善和恶，并利用计算的本质来做这件事——测量和计算——而不是创造合成智能，因为智能是人类的天赋，认为任何机器都可以或应该拥有智能是丑陋和淫秽的。 自我怀疑的认识论将允许一个团体质疑任何出现在*的魔像类型的神器的有效性，因为它是不优雅的*，并且取消或者甚至不恢复经济和价格激励来追求制造魔像的研究过程，因为所有的人工智能魔像都是丑陋的。

然而，在这个星球上，或者至少是我们所知道的唯一有生命的星球上，由于对超人秩序的信仰，我们试图将编码发明提升到与人类同等的地位。因为我们的超人性，优化的代码无法打败人类。但他们已经(像 DeepBlue 和 DeepMind)并将继续取代人类代理(像 Mitsuku 甚至 Waymo)，经济和稳定化[2]奖励证明了优化认识论是正确的。

当丹尼特博士的亮光通过，并且没有声音质疑这些魔像的方向和性质时，会发生什么？

正如哈拉里博士总结的那样，“我们唯一能尝试做的事情就是影响科学家们正在采取的方向”，正如这里所建议的那样，将人工智能研究思维问题化是目前明智而明智的事情，因为为军事目的研究丑陋的人工智能机器人群体对克拉彭公共汽车上的人来说似乎是不道德和疯狂的。

## 脚注

[1]伯特兰·罗素的《自由思想和官方宣传》——古腾堡计划电子书

[2]例如，史蒂夫·沃斯维克赢得了一项世界纪录或者埃隆·马斯克成为了[皇家学会的会员](https://royalsociety.org/people/elon-musk-13829/)。