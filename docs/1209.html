<html>
<head>
<title>Application of Uncertainty Modeling to Face Recognition</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">不确定性建模在人脸识别中的应用</h1>
<blockquote>原文：<a href="https://pub.towardsai.net/cvpr2020-paper-summary-data-uncertainty-in-face-recognition-1f17547473a2?source=collection_archive---------4-----------------------#2020-12-03">https://pub.towardsai.net/cvpr2020-paper-summary-data-uncertainty-in-face-recognition-1f17547473a2?source=collection_archive---------4-----------------------#2020-12-03</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><h2 id="765d" class="io ip iq bd b dl ir is it iu iv iw dk ix translated" aria-label="kicker paragraph"><a class="ae ep" href="https://towardsai.net/p/category/computer-vision" rel="noopener ugc nofollow" target="_blank">计算机视觉</a></h2><div class=""/><figure class="gl gn jx jy jz ka gh gi paragraph-image"><div class="gh gi jw"><img src="../Images/cbf65646a53a4089dcb29b5547e628fe.png" data-original-src="https://miro.medium.com/v2/resize:fit:1200/format:webp/1*OyCEDGS5f_oLfIOE5Ujrmw.jpeg"/></div><figcaption class="kd ke gj gh gi kf kg bd b be z dk translated"><a class="ae kh" href="http://cvpr2020.thecvf.com/" rel="noopener ugc nofollow" target="_blank"> IEEE CVPR会议</a></figcaption></figure><p id="d3e2" class="pw-post-body-paragraph ki kj iq kk b kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf ij bi lg translated"><span class="l lh li lj bm lk ll lm ln lo di">在</span>这个故事中，介绍了旷视科技公司和中国科学技术大学在人脸识别中的数据不确定性学习。这是作为CVPR 2020年技术报告发表的。你可能已经知道，<a class="ae kh" href="https://en.megvii.com/" rel="noopener ugc nofollow" target="_blank">旷视科技公司</a>以面部识别而闻名。本文在人脸识别中很少探索数据不确定性学习在人脸识别中的应用。</p><p id="5710" class="pw-post-body-paragraph ki kj iq kk b kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf ij bi translated">他们甚至在Github<a class="ae kh" href="https://github.com/Ontheway361/dul-pytorch" rel="noopener ugc nofollow" target="_blank">上向所有人公开了代码！让我们看看他们是如何做到的。</a></p><figure class="lq lr ls lt gt ka gh gi paragraph-image"><div role="button" tabindex="0" class="lu lv di lw bf lx"><div class="gh gi lp"><img src="../Images/c6a1b907158e98eb0fa5fb2030414a9d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*WeYnM9wrwkqOpscw7RawRQ.png"/></div></div><figcaption class="kd ke gj gh gi kf kg bd b be z dk translated">(A)确定性模型在不考虑数据不确定性的情况下给出点嵌入；(b)概率模型给出用估计平均值和估计方差参数化的分布估计。<a class="ae kh" href="https://openaccess.thecvf.com/content_ICCV_2019/papers/Shi_Probabilistic_Face_Embeddings_ICCV_2019_paper.pdf" rel="noopener ugc nofollow" target="_blank"> PFE </a>利用预先训练的点嵌入作为均值，只学习每个样本的不确定性σ；(c)作者的方法同时学习σ以及，导致在潜在空间中更好的类内紧密性和类间可分性。不同的类别被标记为蓝色或红色。最好是彩色的。</figcaption></figure><p id="1e61" class="pw-post-body-paragraph ki kj iq kk b kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf ij bi translated">不确定性建模很重要，但在人脸识别中很少考虑。先前的研究(PFE [1])通过将人脸图像中的特征建模为高斯分布来考虑不确定性。然而，在这种情况下，尚不清楚数据不确定性如何影响特征学习。</p><p id="0c92" class="pw-post-body-paragraph ki kj iq kk b kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf ij bi translated">本文提出了数据不确定性学习(DUL)算法，通过同时学习特征空间的均值和方差，将数据不确定性估计理论应用于人脸识别领域。</p><p id="fceb" class="pw-post-body-paragraph ki kj iq kk b kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf ij bi translated">DUL算法有两种训练模式(DUL_cls和DUL_rgs)，DUL_cls和DUL_rgs都学习不确定性表示<em class="ly"> σ </em>以及恒等式表示<em class="ly"> μ </em>，因此预测<em class="ly"> μ </em>可以直接用常用的匹配度量来评估。因此，DUL算法对训练集中的噪声数据具有鲁棒性，并能有效降低脏样本对模型训练的负面影响。</p></div><div class="ab cl lz ma hu mb" role="separator"><span class="mc bw bk md me mf"/><span class="mc bw bk md me mf"/><span class="mc bw bk md me"/></div><div class="ij ik il im in"><h1 id="24ac" class="mg mh iq bd mi mj mk ml mm mn mo mp mq mr ms mt mu mv mw mx my mz na nb nc nd bi translated">概述</h1><ol class=""><li id="f6f8" class="ne nf iq kk b kl ng kp nh kt ni kx nj lb nk lf nl nm nn no bi translated"><strong class="kk ja">深度学习中的不确定性</strong></li><li id="03e5" class="ne nf iq kk b kl np kp nq kt nr kx ns lb nt lf nl nm nn no bi translated"><strong class="kk ja">人脸识别中的数据不确定性学习</strong></li><li id="63b8" class="ne nf iq kk b kl np kp nq kt nr kx ns lb nt lf nl nm nn no bi translated"><strong class="kk ja">基于分类的人脸识别DUL (DUL_cls) </strong></li><li id="4e93" class="ne nf iq kk b kl np kp nq kt nr kx ns lb nt lf nl nm nn no bi translated"><strong class="kk ja">基于回归的面部识别DUL (DUL_rgs) </strong></li><li id="e618" class="ne nf iq kk b kl np kp nq kt nr kx ns lb nt lf nl nm nn no bi translated"><strong class="kk ja">实验结果</strong></li></ol></div><div class="ab cl lz ma hu mb" role="separator"><span class="mc bw bk md me mf"/><span class="mc bw bk md me mf"/><span class="mc bw bk md me"/></div><div class="ij ik il im in"><h1 id="ff0b" class="mg mh iq bd mi mj mk ml mm mn mo mp mq mr ms mt mu mv mw mx my mz na nb nc nd bi translated"><strong class="ak"> 1。深度学习的不确定性</strong></h1><p id="430d" class="pw-post-body-paragraph ki kj iq kk b kl ng kn ko kp nh kr ks kt nu kv kw kx nv kz la lb nw ld le lf ij bi translated">近年来，不确定性在深度学习中受到了很多关注。已经提出了几种方法来研究不确定性在深度神经网络中的具体表现[2，3，4，5]。数据的不确定性源于数据中的“噪音”。具体来说，在深度不确定性学习中，不确定性可以分为模型不确定性和数据不确定性，模型不确定性捕获深度神经网络中的参数噪声，数据不确定性测量给定训练数据中固有的噪声。在诸如人脸识别的计算机视觉应用中，这种不确定性建模是基本的，因为噪声在图像中广泛存在。</p></div><div class="ab cl lz ma hu mb" role="separator"><span class="mc bw bk md me mf"/><span class="mc bw bk md me mf"/><span class="mc bw bk md me"/></div><div class="ij ik il im in"><h1 id="fd71" class="mg mh iq bd mi mj mk ml mm mn mo mp mq mr ms mt mu mv mw mx my mz na nb nc nd bi translated">2.人脸识别中的数据不确定性学习</h1><p id="1302" class="pw-post-body-paragraph ki kj iq kk b kl ng kn ko kp nh kr ks kt nu kv kw kx nv kz la lb nw ld le lf ij bi translated">对于由连续映射空间<em class="ly"> X → Y </em>组成的人脸数据集，假设含噪图像集(<em class="ly"> y_i ∈ Y </em>)被噪声<em class="ly"> n(x_i) </em>退化，则无噪图像集<em class="ly"> (x_i ∈ X) </em>退化。所以这个映射空间本身就承载了数据的不确定性。这意味着每个被观察对象可以表示为<em class="ly"> y_i = f(x_i) + ϵ σ(x_i)，</em>其中σ ~ N <em class="ly"> (0，I)，</em>其中<em class="ly"> f( ) </em>是感兴趣数据的嵌入函数。</p><p id="2e90" class="pw-post-body-paragraph ki kj iq kk b kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf ij bi translated">传统的回归模型仅被训练成在给定<em class="ly"> f(x_i)的情况下逼近输入<em class="ly"> x_i </em>。</em>然而，使用数据不确定性学习的回归模型也估计<em class="ly"> σ(x_i) </em>，它代表预测的不确定性<em class="ly"> f(x_i) </em>(见(a))。</p><figure class="lq lr ls lt gt ka gh gi paragraph-image"><div role="button" tabindex="0" class="lu lv di lw bf lx"><div class="gh gi lp"><img src="../Images/8f21698198bf5f7f533f90a36304fd33.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*-76TPTiliyBPtA2xgJiF7A.png"/></div></div><figcaption class="kd ke gj gh gi kf kg bd b be z dk translated">(a):观测数据对(红点)中的目标y被x相关噪声破坏。数据不确定性回归将给出超出特定预测值(绿线)的“噪声水平”(绿色阴影)；(b):标记有相同ID的样品出现在每一行中。与其他类内样本相比，带有红框的样本被视为噪声数据。</figcaption></figure></div><div class="ab cl lz ma hu mb" role="separator"><span class="mc bw bk md me mf"/><span class="mc bw bk md me mf"/><span class="mc bw bk md me"/></div><div class="ij ik il im in"><h1 id="2ffa" class="mg mh iq bd mi mj mk ml mm mn mo mp mq mr ms mt mu mv mw mx my mz na nb nc nd bi translated"><strong class="ak"> 3。基于分类的面部识别DUL ( </strong> DUL_cls <strong class="ak"> ) </strong></h1><p id="fd50" class="pw-post-body-paragraph ki kj iq kk b kl ng kn ko kp nh kr ks kt nu kv kw kx nv kz la lb nw ld le lf ij bi translated">引入基于分类的数据不确定性学习(DUL)DUL cls来训练人脸分类模型中的数据不确定性。DUL_cls在目标函数上类似于变分信息瓶颈(VIB) [6]，其中VIB是输入数据<em class="ly"> X </em>到潜在表示<em class="ly"> Z </em>的概率。VIB根据信息瓶颈推导出这个目标函数。相比之下，DUL_cls从数据不确定性的角度推导出它，该数据不确定性与具有足够能力预测标签<em class="ly"> Y </em>同时保持<em class="ly"> Z </em>尽可能简洁的基本权衡有关。</p><figure class="lq lr ls lt gt ka gh gi paragraph-image"><div role="button" tabindex="0" class="lu lv di lw bf lx"><div class="gh gi nx"><img src="../Images/27fbc3da79be3ee0aacf4451f0ec5ab2.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*JxI7F6BgbAsR6CL_tlPawg.png"/></div></div><figcaption class="kd ke gj gh gi kf kg bd b be z dk translated">提议的DUL cls FR模型概述</figcaption></figure><p id="0841" class="pw-post-body-paragraph ki kj iq kk b kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf ij bi translated">DUL_cls的总代价函数可以表示为:<em class="ly"> L </em> _KL在算法中起平衡器的作用，<em class="ly"> L </em> _softmax最小化softmax损失用于图像分类。</p><figure class="lq lr ls lt gt ka gh gi paragraph-image"><div class="gh gi ny"><img src="../Images/d3f0fc508768a69ee3e93f1294dba569.png" data-original-src="https://miro.medium.com/v2/resize:fit:588/format:webp/1*UDNIXZllnFYUvRKHftL2Zw.png"/></div><figcaption class="kd ke gj gh gi kf kg bd b be z dk translated"><strong class="bd mi"> DUL_cls损失函数</strong></figcaption></figure><h2 id="0c8f" class="nz mh iq bd mi oa ob dn mm oc od dp mq kt oe of mu kx og oh my lb oi oj nc iw bi translated">3.1分配代表性</h2><p id="b7f9" class="pw-post-body-paragraph ki kj iq kk b kl ng kn ko kp nh kr ks kt nu kv kw kx nv kz la lb nw ld le lf ij bi translated">将样本<em class="ly"> x </em>在潜在空间<em class="ly"> z </em>中的表示定义为高斯分布。高斯分布的两个参数(均值和方差)取决于输入，由不同的CNN预测，其中<em class="ly"> μ </em>可视为人脸的判别特征，<em class="ly"> σ </em>指预测的<em class="ly"> μ </em>的不确定性。</p><p id="8d4a" class="pw-post-body-paragraph ki kj iq kk b kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf ij bi translated">每个样本的表示<em class="ly"> p(z_i|x_i) </em>不是确定性的点嵌入，是从潜在空间采样的随机嵌入。</p><figure class="lq lr ls lt gt ka gh gi paragraph-image"><div class="gh gi ok"><img src="../Images/55959f251d85953fbb35bd7996a7acbc.png" data-original-src="https://miro.medium.com/v2/resize:fit:956/format:webp/1*SttJ1M9k717XGv_3wPNmQA.png"/></div><figcaption class="kd ke gj gh gi kf kg bd b be z dk translated">表示概率</figcaption></figure><p id="2b22" class="pw-post-body-paragraph ki kj iq kk b kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf ij bi translated">等式1中的采样操作是不可微的，因此在模型训练期间不能控制梯度流。在方程2中，使用变分贝叶斯[7]的自动编码来确保模型照常渐变。具体来说，首先，从独立于模型参数的正态分布中对随机噪声<em class="ly"> ϵ </em>进行采样，并生成<em class="ly"> s </em>作为等效采样表示。这获得了等同于采样操作的随机嵌入属性。</p><figure class="lq lr ls lt gt ka gh gi paragraph-image"><div class="gh gi ol"><img src="../Images/78da9aa359a4395d7a09019fed7e57fb.png" data-original-src="https://miro.medium.com/v2/resize:fit:1024/format:webp/1*huIb-DTQFVaxrI-Ci7ooMg.png"/></div><figcaption class="kd ke gj gh gi kf kg bd b be z dk translated">取样操作</figcaption></figure><h2 id="73b6" class="nz mh iq bd mi oa ob dn mm oc od dp mq kt oe of mu kx og oh my lb oi oj nc iw bi translated">3.2分类损失</h2><p id="4d5e" class="pw-post-body-paragraph ki kj iq kk b kl ng kn ko kp nh kr ks kt nu kv kw kx nv kz la lb nw ld le lf ij bi translated">因为采样表示s是样本(图像数据)<em class="ly"> x </em>的最终表示，所以最小化用于图像分类的采样表示s的softmax损失。<em class="ly"> L_ </em> softmax也有softmax的不同变种，如AMSoftMax、ArcFace和L2SoftMax。</p><figure class="lq lr ls lt gt ka gh gi paragraph-image"><div class="gh gi om"><img src="../Images/e1a52684fe1af54be383afe8a2f35776.png" data-original-src="https://miro.medium.com/v2/resize:fit:1064/format:webp/1*1uN0entdROp4nzfV0Ur_Ew.png"/></div><figcaption class="kd ke gj gh gi kf kg bd b be z dk translated">分类损失函数</figcaption></figure><h2 id="7532" class="nz mh iq bd mi oa ob dn mm oc od dp mq kt oe of mu kx og oh my lb oi oj nc iw bi translated">3.3 KL-散度正则化</h2><p id="b40a" class="pw-post-body-paragraph ki kj iq kk b kl ng kn ko kp nh kr ks kt nu kv kw kx nv kz la lb nw ld le lf ij bi translated"><em class="ly"> L </em> _kl用方程3充当了一个很好的平衡器，受变分信息瓶颈的启发，本文在优化过程中引入了一个归一化项。它利用约束模型将分布<em class="ly"> N (μ，σ) </em>逼近为正态分布<em class="ly"> N (0，1) </em>。在这一章中，使用库尔贝克-莱布勒散度(KLD)，将测量两个分布之间的“距离”。</p><figure class="lq lr ls lt gt ka gh gi paragraph-image"><div class="gh gi on"><img src="../Images/072e2da87bfae44c9a116cc9f61eb199.png" data-original-src="https://miro.medium.com/v2/resize:fit:1040/format:webp/1*eN1iq-ZJRqWcOBHbuIu7lw.png"/></div><figcaption class="kd ke gj gh gi kf kg bd b be z dk translated">KL-散度正则化损失</figcaption></figure></div><div class="ab cl lz ma hu mb" role="separator"><span class="mc bw bk md me mf"/><span class="mc bw bk md me mf"/><span class="mc bw bk md me"/></div><div class="ij ik il im in"><h1 id="7049" class="mg mh iq bd mi mj mk ml mm mn mo mp mq mr ms mt mu mv mw mx my mz na nb nc nd bi translated"><strong class="ak"> 4。基于回归的面部识别DUL (DUL_rgs) </strong></h1><p id="3987" class="pw-post-body-paragraph ki kj iq kk b kl ng kn ko kp nh kr ks kt nu kv kw kx nv kz la lb nw ld le lf ij bi translated">这里，提出了数据的数据不确定性回归(DUL_rgs)，它使用数据不确定性学习(DUL)来改进现有的人脸识别模型，DUL_rgs的模型被训练来衰减由于低质量样本导致的模糊<em class="ly"> μ </em>的影响。DUL rgs将传统的最小二乘回归技术解释为具有数据不确定性回归模型的最大似然估计。</p><p id="068d" class="pw-post-body-paragraph ki kj iq kk b kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf ij bi translated">DUL_rgs基于连续映射空间<em class="ly"> X→Y </em>中数据不确定性回归的思想。一个困难但重要的挑战是，离散目标空间<em class="ly"> Y </em>由离散变量组成，在人脸识别任务中不能近似为连续目标向量。</p><p id="ab3f" class="pw-post-body-paragraph ki kj iq kk b kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf ij bi translated">本文针对这一问题，构造了一个新的连续映射空间<em class="ly"> (X→W) </em>来进行预测。这个空间大致相当于原来的离散目标空间<em class="ly"> Y </em>。具体地，使用预训练的人脸识别模型提取的分类层(DUL_cls)的权重矩阵<em class="ly"> W </em>是新的连续映射空间<em class="ly"> (X→W) </em>。</p><figure class="lq lr ls lt gt ka gh gi paragraph-image"><div role="button" tabindex="0" class="lu lv di lw bf lx"><div class="gh gi lp"><img src="../Images/c51b0805e202b0a159164ce9d864f031.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*fHfAEnVTQ-klmQcWfZ3MeQ.png"/></div></div><figcaption class="kd ke gj gh gi kf kg bd b be z dk translated">卷积层中的所有参数由确定性面部识别模型预先训练，并且在DUL_rgs的训练期间是固定的。</figcaption></figure><h2 id="1ba5" class="nz mh iq bd mi oa ob dn mm oc od dp mq kt oe of mu kx og oh my lb oi oj nc iw bi translated">4.1分配代表性</h2><p id="4877" class="pw-post-body-paragraph ki kj iq kk b kl ng kn ko kp nh kr ks kt nu kv kw kx nv kz la lb nw ld le lf ij bi translated">对于连续的目标空间<em class="ly"> W </em>，空间<em class="ly"> X </em>使等式5的概率最大化</p><figure class="lq lr ls lt gt ka gh gi paragraph-image"><div class="gh gi oo"><img src="../Images/cf7e8b8d4fc8c8607d0e5659d48854c0.png" data-original-src="https://miro.medium.com/v2/resize:fit:1168/format:webp/1*OW87TsiEDsAMOSPT27n6dg.png"/></div><figcaption class="kd ke gj gh gi kf kg bd b be z dk translated">等式5的概率</figcaption></figure><p id="02e0" class="pw-post-body-paragraph ki kj iq kk b kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf ij bi translated">等式5的对数似然性由等式6表示。该等式是不确定性得分，其中学习的方差<em class="ly"> σ_i </em>是学习的身份嵌入信息<em class="ly"> μ_i </em>属于第c类的置信度的度量。</p><figure class="lq lr ls lt gt ka gh gi paragraph-image"><div class="gh gi op"><img src="../Images/d493df23160b1fa6fb3ba54c8ca201a4.png" data-original-src="https://miro.medium.com/v2/resize:fit:1272/format:webp/1*7dpTVou7BMSVfqodb4g13g.png"/></div><figcaption class="kd ke gj gh gi kf kg bd b be z dk translated">等式5的对数似然</figcaption></figure><p id="ad87" class="pw-post-body-paragraph ki kj iq kk b kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf ij bi translated">训练神经网络预测对数方差以稳定随机优化过程中的数字。通过最大化可能性来最小化成本函数。</p><figure class="lq lr ls lt gt ka gh gi paragraph-image"><div class="gh gi oq"><img src="../Images/d98739f731d3e02b5ce6d00fbeb5b01f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1284/format:webp/1*le2j3sTh8fZv2LeAyHxYxQ.png"/></div><figcaption class="kd ke gj gh gi kf kg bd b be z dk translated">最小化成本函数</figcaption></figure></div><div class="ab cl lz ma hu mb" role="separator"><span class="mc bw bk md me mf"/><span class="mc bw bk md me mf"/><span class="mc bw bk md me"/></div><div class="ij ik il im in"><h1 id="8f58" class="mg mh iq bd mi mj mk ml mm mn mo mp mq mr ms mt mu mv mw mx my mz na nb nc nd bi translated">5.实验结果</h1><p id="c4f7" class="pw-post-body-paragraph ki kj iq kk b kl ng kn ko kp nh kr ks kt nu kv kw kx nv kz la lb nw ld le lf ij bi translated">提供定性和定量分析，以调查获取的数据中不确定性的重要性，以及数据不确定性的学习如何影响人脸模型的学习。在噪声数据集上的实验表明，该方法更加可靠。</p><p id="1101" class="pw-post-body-paragraph ki kj iq kk b kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf ij bi translated">结果显示了DUL与LFW，YTF，MegaFace (MF)和CFP-FP数据集的当前最佳实践的比较。</p><figure class="lq lr ls lt gt ka gh gi paragraph-image"><div role="button" tabindex="0" class="lu lv di lw bf lx"><div class="gh gi ca"><img src="../Images/86a0e653dbed2ff272830b25f1f4bc98.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*bP7WAzvsTbvlO2ae3UabcA.png"/></div></div><figcaption class="kd ke gj gh gi kf kg bd b be z dk translated">结果与LFW、YTF、MegaFace (MF)和CFP-FP数据集的当前最佳实践进行了比较。</figcaption></figure><p id="56ec" class="pw-post-body-paragraph ki kj iq kk b kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf ij bi translated">高斯模糊以各种比率应用于MS-Celeb-1M面部训练集样本以创建降级样本。实验结果表明，DUL方法和PFE都取得了比基线模型更稳健的结果。</p><figure class="lq lr ls lt gt ka gh gi paragraph-image"><div role="button" tabindex="0" class="lu lv di lw bf lx"><div class="gh gi or"><img src="../Images/15a637933ab76588018aab8b0af209f3.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*JFvDqHsrckLXeloCms--bg.png"/></div></div><figcaption class="kd ke gj gh gi kf kg bd b be z dk translated">结果对比目前最好的方法IJB-C数据集，主干:ResNet64。</figcaption></figure><p id="6422" class="pw-post-body-paragraph ki kj iq kk b kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf ij bi translated">与基线模型相比，DUL cls在简单和半硬样本中显示出相对较少的失败案例。已经表明，与DUL cls相比，基线模型在具有极端噪声的硬样本中具有较少的坏情况。这表明，具有数据不确定性学习的网络专注于训练应该正确分类的样本，同时“放弃”有害样本，而不是过度拟合它们。</p><figure class="lq lr ls lt gt ka gh gi paragraph-image"><div role="button" tabindex="0" class="lu lv di lw bf lx"><div class="gh gi os"><img src="../Images/a9845852463ccbf3fca76e1371c7a6ee.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*iiXAwf4YVYJCYPbs08DYDA.png"/></div></div><figcaption class="kd ke gj gh gi kf kg bd b be z dk translated">基线模型和DUL cls之间的不良案例分析。</figcaption></figure></div><div class="ab cl lz ma hu mb" role="separator"><span class="mc bw bk md me mf"/><span class="mc bw bk md me mf"/><span class="mc bw bk md me"/></div><div class="ij ik il im in"><h1 id="a907" class="mg mh iq bd mi mj mk ml mm mn mo mp mq mr ms mt mu mv mw mx my mz na nb nc nd bi translated">参考</h1><p id="b4e9" class="pw-post-body-paragraph ki kj iq kk b kl ng kn ko kp nh kr ks kt nu kv kw kx nv kz la lb nw ld le lf ij bi translated">[1]史宜春、阿尼尔·K·贾恩和内森·D·卡尔卡。“概率人脸嵌入”，2019年IEEE计算机视觉国际会议论文集。</p><p id="e1c7" class="pw-post-body-paragraph ki kj iq kk b kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf ij bi translated">[2]查尔斯·布伦德尔、朱利安·科尔内比塞、科雷·卡武克库奥卢和金奎大·威斯特拉。“神经网络中的权重不确定性”，arXiv预印本arXiv:1505.05424，2015年。</p><p id="9774" class="pw-post-body-paragraph ki kj iq kk b kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf ij bi translated">[3]亚林·加尔。《深度学习中的不确定性》，博士论文，剑桥大学，2016年。</p><p id="2bd6" class="pw-post-body-paragraph ki kj iq kk b kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf ij bi translated">[4]亚林·加尔和邹斌·格拉马尼。“作为贝叶斯近似的辍学:表示深度学习中的模型不确定性”，国际机器学习会议，第1050-1059页，2016年。</p><p id="f2f2" class="pw-post-body-paragraph ki kj iq kk b kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf ij bi translated">[5]亚历克斯·肯德尔和亚林·加尔。“在用于计算机视觉的贝叶斯深度学习中，我们需要哪些不确定性？“神经信息处理系统进展，第5574–5584页，2017年”。</p><p id="30a8" class="pw-post-body-paragraph ki kj iq kk b kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf ij bi translated">[6]亚历山大·阿莱米、伊恩·费希尔、约书亚·V·狄龙和凯文·墨菲。“深度变化的信息瓶颈”，载于2017年国际学习表征会议论文集。</p><p id="d9ce" class="pw-post-body-paragraph ki kj iq kk b kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf ij bi translated">[7]迪德里克·P·金马和马克斯·韦林。“自动编码变分贝叶斯”，ICLR，2014年。</p><h1 id="117d" class="mg mh iq bd mi mj ot ml mm mn ou mp mq mr ov mt mu mv ow mx my mz ox nb nc nd bi translated">过去论文摘要列表</h1><h2 id="aceb" class="nz mh iq bd mi oa ob dn mm oc od dp mq kt oe of mu kx og oh my lb oi oj nc iw bi translated">数据不确定性学习</h2><p id="1fd2" class="pw-post-body-paragraph ki kj iq kk b kl ng kn ko kp nh kr ks kt nu kv kw kx nv kz la lb nw ld le lf ij bi translated">2020年: [ <a class="ae kh" href="https://mako95.medium.com/cvpr2020-paper-summary-data-uncertainty-in-face-recognition-1f17547473a2" rel="noopener"> DUL </a></p><h2 id="8d7b" class="nz mh iq bd mi oa ob dn mm oc od dp mq kt oe of mu kx og oh my lb oi oj nc iw bi translated">一级分类</h2><p id="fa7c" class="pw-post-body-paragraph ki kj iq kk b kl ng kn ko kp nh kr ks kt nu kv kw kx nv kz la lb nw ld le lf ij bi translated"><strong class="kk ja"> 2019: </strong> [ <a class="ae kh" href="https://medium.com/swlh/paper-summary-deep-one-class-classification-doc-adc4368af75c" rel="noopener"> DOC </a> ]</p><p id="4e60" class="pw-post-body-paragraph ki kj iq kk b kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf ij bi translated"><strong class="kk ja"> 2020: </strong> [ <a class="ae kh" href="https://medium.com/the-shadow/exploring-important-feature-repressions-in-deep-one-class-classification-droc-d04a59558f9e" rel="noopener"> DROC </a> ]</p><h2 id="f07a" class="nz mh iq bd mi oa ob dn mm oc od dp mq kt oe of mu kx og oh my lb oi oj nc iw bi translated">生物医学图像分割</h2><p id="ed21" class="pw-post-body-paragraph ki kj iq kk b kl ng kn ko kp nh kr ks kt nu kv kw kx nv kz la lb nw ld le lf ij bi translated"><strong class="kk ja">2018:</strong><a class="ae kh" href="https://medium.com/swlh/paper-summary-biomedical-image-segmentation-and-object-detection-uolo-c1175ba5c8c4" rel="noopener">【UOLO】</a></p><h2 id="b84f" class="nz mh iq bd mi oa ob dn mm oc od dp mq kt oe of mu kx og oh my lb oi oj nc iw bi translated">图像聚类</h2><p id="fef6" class="pw-post-body-paragraph ki kj iq kk b kl ng kn ko kp nh kr ks kt nu kv kw kx nv kz la lb nw ld le lf ij bi translated"><strong class="kk ja">2020:</strong><a class="ae kh" href="https://medium.com/swlh/paper-deep-transfer-clustering-dtc-learning-to-discover-novel-visual-categories-ec5a26aea075" rel="noopener">【DTC】</a></p></div></div>    
</body>
</html>