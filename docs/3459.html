<html>
<head>
<title>The Ever-evolving Pre-training Tasks for Language Models</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">不断发展的语言模型预训练任务</h1>
<blockquote>原文：<a href="https://pub.towardsai.net/the-ever-evolving-pre-training-tasks-for-language-models-14dc5e27d523?source=collection_archive---------2-----------------------#2022-12-28">https://pub.towardsai.net/the-ever-evolving-pre-training-tasks-for-language-models-14dc5e27d523?source=collection_archive---------2-----------------------#2022-12-28</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><p id="cf83" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">自我监督学习(SSL)是基于transformer的预训练语言模型的支柱，这种范式涉及解决帮助建模自然语言的预训练任务(PT)。这篇文章是关于把所有流行的培训前的任务一目了然。</p><p id="70c3" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated"><strong class="jp ir">SSL中的损失函数<br/> </strong>这里的损失函数简单来说就是模型被训练的各个预训练任务的损失的加权和。</p><figure class="km kn ko kp gt kq gh gi paragraph-image"><div role="button" tabindex="0" class="kr ks di kt bf ku"><div class="gh gi kl"><img src="../Images/fc53c63deb4aa35dd5a00f444831fb0c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*0m3kPFBZjCQCkDbHFKfyCQ.png"/></div></div></figure><p id="fec9" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">以伯特为例，损失将是MLM(掩蔽语言建模)和NSP(下一句预测)的加权和</p><figure class="km kn ko kp gt kq gh gi paragraph-image"><div class="gh gi kx"><img src="../Images/aa0698fd1dc644e5f600eaaab4cee53d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1046/format:webp/1*KpgZwK7sjCxyubj7kZceJQ.png"/></div></figure><p id="75d7" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">这些年来，出现了许多解决具体问题的训练前任务。我们将回顾10个有趣且受欢迎的函数及其相应的损失函数:</p><ol class=""><li id="33c5" class="ky kz iq jp b jq jr ju jv jy la kc lb kg lc kk ld le lf lg bi translated">因果语言造型(<strong class="jp ir"> CLM </strong>)</li><li id="f631" class="ky kz iq jp b jq lh ju li jy lj kc lk kg ll kk ld le lf lg bi translated">蒙面语言造型(<strong class="jp ir"> MLM </strong>)</li><li id="55db" class="ky kz iq jp b jq lh ju li jy lj kc lk kg ll kk ld le lf lg bi translated">替换令牌检测(<strong class="jp ir"> RTD </strong>)</li><li id="1695" class="ky kz iq jp b jq lh ju li jy lj kc lk kg ll kk ld le lf lg bi translated">混洗令牌检测(<strong class="jp ir"> STD </strong>)</li><li id="5c0f" class="ky kz iq jp b jq lh ju li jy lj kc lk kg ll kk ld le lf lg bi translated">随机代币替换(<strong class="jp ir"> RTS </strong>)</li><li id="60fd" class="ky kz iq jp b jq lh ju li jy lj kc lk kg ll kk ld le lf lg bi translated">交换语言建模(<strong class="jp ir"> SLM) </strong></li><li id="2906" class="ky kz iq jp b jq lh ju li jy lj kc lk kg ll kk ld le lf lg bi translated">翻译语言造型(<strong class="jp ir"> TLM </strong>)</li><li id="3578" class="ky kz iq jp b jq lh ju li jy lj kc lk kg ll kk ld le lf lg bi translated">替代语言建模(<strong class="jp ir"> ALM </strong>)</li><li id="033c" class="ky kz iq jp b jq lh ju li jy lj kc lk kg ll kk ld le lf lg bi translated">句子边界目标(<strong class="jp ir"> SBO </strong>)</li><li id="689a" class="ky kz iq jp b jq lh ju li jy lj kc lk kg ll kk ld le lf lg bi translated">下一句预测(<strong class="jp ir"> NSP </strong>)</li></ol><p id="1118" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated"><em class="lm">(每个任务和内容的损失函数大量借用</em> <a class="ae ln" href="https://arxiv.org/abs/2108.05542" rel="noopener ugc nofollow" target="_blank"> <em class="lm"> AMMUS:自然语言处理中基于变压器的预训练模型综述</em> </a> <em class="lm"> ) </em></p><figure class="km kn ko kp gt kq gh gi paragraph-image"><div role="button" tabindex="0" class="kr ks di kt bf ku"><div class="gh gi lo"><img src="../Images/b27d2be571174e83a89bec0185bfe657.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*4jpQ-bA8veBsB2jctZFFQQ.png"/></div></div></figure><ul class=""><li id="8eab" class="ky kz iq jp b jq jr ju jv jy la kc lb kg lc kk lp le lf lg bi translated">它只是一个单向的语言模型，在给定上下文的情况下预测下一个单词。</li><li id="28fc" class="ky kz iq jp b jq lh ju li jy lj kc lk kg ll kk lp le lf lg bi translated">在GPT-1中被用作训练前的任务</li><li id="08f4" class="ky kz iq jp b jq lh ju li jy lj kc lk kg ll kk lp le lf lg bi translated">CLM的损失定义为:</li></ul><figure class="km kn ko kp gt kq gh gi paragraph-image"><div role="button" tabindex="0" class="kr ks di kt bf ku"><div class="gh gi lq"><img src="../Images/0ae1e3e84d93630e022e3a0a65cc6139.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Rn0kCN2WSIcUt0H9Vw3GWA.png"/></div></div></figure><figure class="km kn ko kp gt kq gh gi paragraph-image"><div role="button" tabindex="0" class="kr ks di kt bf ku"><div class="gh gi lr"><img src="../Images/433770d3c3fd2502cfa73f72e76dd881.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*5N-dR_35Sz0XxKV9gdTKRQ.png"/></div></div></figure><ul class=""><li id="3594" class="ky kz iq jp b jq jr ju jv jy la kc lb kg lc kk lp le lf lg bi translated">对因果语言模型(CLM)的改进，因为CLM在预测文本时只考虑单向语境，而MLM使用双向语境。</li><li id="5649" class="ky kz iq jp b jq lh ju li jy lj kc lk kg ll kk lp le lf lg bi translated">它最初是在BERT中作为预训练任务使用的</li></ul><figure class="km kn ko kp gt kq gh gi paragraph-image"><div role="button" tabindex="0" class="kr ks di kt bf ku"><div class="gh gi ls"><img src="../Images/8b86910233618ea5ecf2b08a618472fe.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*NTWqtZbXNLumalw4JTsxnw.png"/></div></div></figure><figure class="km kn ko kp gt kq gh gi paragraph-image"><div role="button" tabindex="0" class="kr ks di kt bf ku"><div class="gh gi lt"><img src="../Images/49588143cbe99596e68740c59b95580a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*xwa_8IWAldCegA1XS7yI_w.png"/></div></div></figure><ul class=""><li id="e66e" class="ky kz iq jp b jq jr ju jv jy la kc lb kg lc kk lp le lf lg bi translated">RTD不是用[MASK]屏蔽令牌，而是用不同的令牌替换令牌(使用<strong class="jp ir">生成器模型</strong>)，并训练该模型来分类给定令牌是实际令牌还是替换令牌(使用<strong class="jp ir">鉴别器模型</strong></li><li id="379e" class="ky kz iq jp b jq lh ju li jy lj kc lk kg ll kk lp le lf lg bi translated">改进了MLM的以下两个缺点:</li></ul><p id="76ac" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated"><strong class="jp ir">缺点1:<br/></strong>【MASK】token在预训练时出现，但在微调时不出现——这造成了两种场景之间的不匹配。<br/> RTD克服了这个问题，因为它不使用任何遮罩</p><p id="3a1f" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated"><strong class="jp ir">缺点2: <br/> </strong>在MLM，训练信号仅由15%的令牌给出，因为损耗是仅使用这些屏蔽令牌计算的，但是在RTD，信号由所有令牌给出，因为它们中的每一个都被分类为“替换”或“原始”</p><ul class=""><li id="f423" class="ky kz iq jp b jq jr ju jv jy la kc lb kg lc kk lp le lf lg bi translated">RTD在ELECTRA中被用作预训练任务。ELECTRA架构如下所示:</li></ul><figure class="km kn ko kp gt kq gh gi paragraph-image"><div role="button" tabindex="0" class="kr ks di kt bf ku"><div class="gh gi lu"><img src="../Images/fb10fa1b61e8511e42cce98b3a01d8c5.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*BvJH8lcnevmtDX_GMyRfQQ.png"/></div></div><figcaption class="lv lw gj gh gi lx ly bd b be z dk translated">电子建筑</figcaption></figure><figure class="km kn ko kp gt kq gh gi paragraph-image"><div role="button" tabindex="0" class="kr ks di kt bf ku"><div class="gh gi lz"><img src="../Images/3447d8da0a6e25e4cc27efc1f4615b2e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*3pYlYmP2OCV9uV5H_f0KDA.png"/></div></div></figure><figure class="km kn ko kp gt kq gh gi paragraph-image"><div role="button" tabindex="0" class="kr ks di kt bf ku"><div class="gh gi ma"><img src="../Images/364b1dbaf37ccd03badc5ea46a024392.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*2VDWkdv0-y0s9uNZ6CUoRA.png"/></div></div></figure><ul class=""><li id="3535" class="ky kz iq jp b jq jr ju jv jy la kc lb kg lc kk lp le lf lg bi translated">类似于RTD，但是这里的令牌被分类为是否被洗牌，而不是被替换或不被替换(如下所示)</li></ul><figure class="km kn ko kp gt kq gh gi paragraph-image"><div role="button" tabindex="0" class="kr ks di kt bf ku"><div class="gh gi mb"><img src="../Images/c05fb7087beb7f657f077761c6c6ce14.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*jzihEI6AWRb0p72YuJzS_Q.png"/></div></div><figcaption class="lv lw gj gh gi lx ly bd b be z dk translated">STD插图(来自<a class="ae ln" href="https://aclanthology.org/2021.naacl-srw.12.pdf" rel="noopener ugc nofollow" target="_blank">论文</a></figcaption></figure><ul class=""><li id="d949" class="ky kz iq jp b jq jr ju jv jy la kc lb kg lc kk lp le lf lg bi translated">与MLM相比，在RTD实现了类似的采样效率</li><li id="5523" class="ky kz iq jp b jq lh ju li jy lj kc lk kg ll kk lp le lf lg bi translated">损失的定义是:</li></ul><figure class="km kn ko kp gt kq gh gi paragraph-image"><div role="button" tabindex="0" class="kr ks di kt bf ku"><div class="gh gi mc"><img src="../Images/cb488cb48f0ce75cf444022a32320858.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*ftKw3Pkl5OoTFpuWsPLpCQ.png"/></div></div></figure><figure class="km kn ko kp gt kq gh gi paragraph-image"><div role="button" tabindex="0" class="kr ks di kt bf ku"><div class="gh gi md"><img src="../Images/f0e6856b6dece130d0af001c400e4907.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*-2C3DWMk-Y0PazPGxnVRbw.png"/></div></div></figure><ul class=""><li id="fbe9" class="ky kz iq jp b jq jr ju jv jy la kc lb kg lc kk lp le lf lg bi translated">RTD使用生成器来破坏句子，这在计算上是昂贵的。<br/> RTS通过简单地使用词汇表中的标记替换15%的标记来绕过这种复杂性，同时实现与MLM类似的准确性，如这里的<a class="ae ln" href="https://arxiv.org/pdf/2104.09694.pdf" rel="noopener ugc nofollow" target="_blank">所示</a>。</li></ul><figure class="km kn ko kp gt kq gh gi paragraph-image"><div role="button" tabindex="0" class="kr ks di kt bf ku"><div class="gh gi me"><img src="../Images/cb0f24d4db7ad7175e9f0aef9e12db52.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*pmBxNyS3Lv7xvrNWh4hvDQ.png"/></div></div></figure><figure class="km kn ko kp gt kq gh gi paragraph-image"><div role="button" tabindex="0" class="kr ks di kt bf ku"><div class="gh gi mf"><img src="../Images/2e9c741a9bc4cff140b0821782556901.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*E1ECbuAST2RE4grMTSN0YQ.png"/></div></div></figure><ul class=""><li id="6ce6" class="ky kz iq jp b jq jr ju jv jy la kc lb kg lc kk lp le lf lg bi translated">SLM通过用随机记号替换15%的记号来破坏序列。</li><li id="30fd" class="ky kz iq jp b jq lh ju li jy lj kc lk kg ll kk lp le lf lg bi translated">在尝试预测损坏的令牌方面，它类似于MLM，但不是使用[掩码]，而是使用随机令牌进行掩码</li><li id="6972" class="ky kz iq jp b jq lh ju li jy lj kc lk kg ll kk lp le lf lg bi translated">就使用随机令牌来破坏而言，它类似于RTS，但与RTS不同，它不是非常有效，因为只有15%的令牌用于提供训练信号。</li></ul><figure class="km kn ko kp gt kq gh gi paragraph-image"><div role="button" tabindex="0" class="kr ks di kt bf ku"><div class="gh gi mg"><img src="../Images/af5fb3e5220210ac44d3044220faef63.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Fuu847l351dDeEN--_vY0w.png"/></div></div></figure><figure class="km kn ko kp gt kq gh gi paragraph-image"><div role="button" tabindex="0" class="kr ks di kt bf ku"><div class="gh gi mh"><img src="../Images/e87886a446ccc012a0aa6669ab67f24a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*SPfHvYfQkahhaZzRaE8rLg.png"/></div></div></figure><ul class=""><li id="6afb" class="ky kz iq jp b jq jr ju jv jy la kc lb kg lc kk lp le lf lg bi translated">TLM也被称为跨语言MLM，其中输入是一对平行句子(来自两种不同语言的句子),标记被屏蔽，就像在MLM一样</li><li id="93c0" class="ky kz iq jp b jq lh ju li jy lj kc lk kg ll kk lp le lf lg bi translated">它被用作<strong class="jp ir"> XLM </strong>中的预训练任务，这是一个学习跨语言映射的跨语言模型。</li></ul><figure class="km kn ko kp gt kq gh gi paragraph-image"><div role="button" tabindex="0" class="kr ks di kt bf ku"><div class="gh gi mi"><img src="../Images/4e3e5ca8c6ac46e392260b034b8ce648.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*5IKU3geYOu8bvru2a9iBwg.png"/></div></div><figcaption class="lv lw gj gh gi lx ly bd b be z dk translated">TLM的插图(来自<a class="ae ln" href="https://arxiv.org/pdf/1901.07291.pdf" rel="noopener ugc nofollow" target="_blank">论文</a></figcaption></figure><ul class=""><li id="a0a2" class="ky kz iq jp b jq jr ju jv jy la kc lb kg lc kk lp le lf lg bi translated">TLM的损失类似于MLM的损失:</li></ul><figure class="km kn ko kp gt kq gh gi paragraph-image"><div role="button" tabindex="0" class="kr ks di kt bf ku"><div class="gh gi mj"><img src="../Images/2f36caa3639be911246382df0ec8dd87.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*qsDAQWiLhzoK0p9e3fLuZQ.png"/></div></div></figure><figure class="km kn ko kp gt kq gh gi paragraph-image"><div role="button" tabindex="0" class="kr ks di kt bf ku"><div class="gh gi mk"><img src="../Images/8d6e6e46223db646ceb32c55c5fc66bd.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*DAM958_8N701AMiDs9XIpg.png"/></div></div></figure><ul class=""><li id="5ba3" class="ky kz iq jp b jq jr ju jv jy la kc lb kg lc kk lp le lf lg bi translated">学习一个<strong class="jp ir">跨语言语言模型</strong>是一项任务，就像TLM一样，平行句是<strong class="jp ir">语码转换的，</strong>如下图:</li></ul><figure class="km kn ko kp gt kq gh gi paragraph-image"><div class="gh gi ml"><img src="../Images/eaa791fa898199d6a3ecb4844c6cf0f3.png" data-original-src="https://miro.medium.com/v2/resize:fit:982/format:webp/1*FH4uCBYGIEj_MYxsPzWNMQ.png"/></div><figcaption class="lv lw gj gh gi lx ly bd b be z dk translated">ALM图解:第一步:来自x的令牌被来自y的令牌替换；第二步:获得的样本然后被遮蔽，类似于MLM(图像来自<a class="ae ln" href="https://ojs.aaai.org//index.php/AAAI/article/view/6480" rel="noopener ugc nofollow" target="_blank">纸</a></figcaption></figure><p id="9d40" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">在语码转换时，x的一些短语被y替换，这样得到的样本被用来训练模型。</p><ul class=""><li id="2335" class="ky kz iq jp b jq jr ju jv jy la kc lb kg lc kk lp le lf lg bi translated">掩蔽策略类似于MLM。</li></ul><figure class="km kn ko kp gt kq gh gi paragraph-image"><div role="button" tabindex="0" class="kr ks di kt bf ku"><div class="gh gi mm"><img src="../Images/60e91db19af6437174dc413f1fca6b36.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*jTInj0k3bGTMWR2XPlANYw.png"/></div></div></figure><figure class="km kn ko kp gt kq gh gi paragraph-image"><div role="button" tabindex="0" class="kr ks di kt bf ku"><div class="gh gi mn"><img src="../Images/c7270bc8a808c495503a075a144b00d1.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*u5qQn0_wHZiYU6BZJ4v9uQ.png"/></div></div></figure><ul class=""><li id="9d29" class="ky kz iq jp b jq jr ju jv jy la kc lb kg lc kk lp le lf lg bi translated">包括掩蔽句子中连续范围的记号，然后使用该模型基于边界记号的输出表示来预测被掩蔽的记号</li></ul><figure class="km kn ko kp gt kq gh gi paragraph-image"><div role="button" tabindex="0" class="kr ks di kt bf ku"><div class="gh gi mf"><img src="../Images/b2c0ecdd788cd4d101f2f7fc273fc337.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*CBLVelo_5f5nCDMY3n6Z5g.png"/></div></div><figcaption class="lv lw gj gh gi lx ly bd b be z dk translated">步骤1:标记x5至x8被屏蔽；步骤2:边界记号(x4和x9)的输出表示用于预测从x5到x9的记号(来自<a class="ae ln" href="https://arxiv.org/pdf/1907.10529.pdf" rel="noopener ugc nofollow" target="_blank">纸</a>的图像)</figcaption></figure><ul class=""><li id="b10c" class="ky kz iq jp b jq jr ju jv jy la kc lb kg lc kk lp le lf lg bi translated">在<strong class="jp ir">斯潘伯特</strong>中被用作预训练任务</li><li id="1278" class="ky kz iq jp b jq lh ju li jy lj kc lk kg ll kk lp le lf lg bi translated">损失的定义是:</li></ul><figure class="km kn ko kp gt kq gh gi paragraph-image"><div role="button" tabindex="0" class="kr ks di kt bf ku"><div class="gh gi mo"><img src="../Images/e90ed141ccb31dfc14bb2a26cf37306a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*4PRZiRMIxOplUFBg2V8jTg.png"/></div></div></figure><figure class="km kn ko kp gt kq gh gi paragraph-image"><div role="button" tabindex="0" class="kr ks di kt bf ku"><div class="gh gi mp"><img src="../Images/b0eca643b5a1fb368d1593c46f1414b5.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*j7p2HsuHCNtYJSvcOU0bnA.png"/></div></div></figure><ul class=""><li id="1d4a" class="ky kz iq jp b jq jr ju jv jy la kc lb kg lc kk lp le lf lg bi translated">这是一个句子级别的任务，帮助模型学习句子之间的关系。</li><li id="5c72" class="ky kz iq jp b jq lh ju li jy lj kc lk kg ll kk lp le lf lg bi translated">这是一个二元分类任务，包括使用[CLS]令牌的输出表示来识别两个句子是否连续。</li><li id="6e13" class="ky kz iq jp b jq lh ju li jy lj kc lk kg ll kk lp le lf lg bi translated">使用50%正样本和50%负样本来完成训练，其中第二句与第一句不连续。</li></ul><figure class="km kn ko kp gt kq gh gi paragraph-image"><div role="button" tabindex="0" class="kr ks di kt bf ku"><div class="gh gi mq"><img src="../Images/4f0625745e71080faca0bcfbb22ec950.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*fwqvKJseYpz0VN5jEE0yCg.png"/></div></div></figure></div><div class="ab cl mr ms hu mt" role="separator"><span class="mu bw bk mv mw mx"/><span class="mu bw bk mv mw mx"/><span class="mu bw bk mv mw"/></div><div class="ij ik il im in"><p id="4695" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated"><em class="lm">还有很多其他有趣的任务在</em> <a class="ae ln" href="https://arxiv.org/abs/2108.05542" rel="noopener ugc nofollow" target="_blank"> <em class="lm"> AMMUS </em> </a> <em class="lm">中有总结！！向作者致敬，如果你觉得有趣，请读一读)</em></p></div></div>    
</body>
</html>