<html>
<head>
<title>Ship Detection on Sentinel-2 Images with Mask R-CNN Model</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">基于掩模R-CNN模型的Sentinel-2图像舰船检测</h1>
<blockquote>原文：<a href="https://pub.towardsai.net/ship-detection-on-sentinel-2-images-with-mask-r-cnn-model-eb8dc9bfc80?source=collection_archive---------1-----------------------#2021-11-29">https://pub.towardsai.net/ship-detection-on-sentinel-2-images-with-mask-r-cnn-model-eb8dc9bfc80?source=collection_archive---------1-----------------------#2021-11-29</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><h2 id="0860" class="io ip iq bd b dl ir is it iu iv iw dk ix translated" aria-label="kicker paragraph"><a class="ae ep" href="https://towardsai.net/p/category/machine-learning/deep-learning" rel="noopener ugc nofollow" target="_blank">深度学习</a></h2><div class=""/><div class=""><h2 id="6d02" class="pw-subtitle-paragraph jw iz iq bd b jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn dk translated">基于PyTorch和open数据的海上交通时间分析</h2></div><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div role="button" tabindex="0" class="ku kv di kw bf kx"><div class="gh gi ko"><img src="../Images/dc0736ca7ab6b0fc0e6b17695dee2577.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*wSwKpyvpsAfeb__3UAQkzg.jpeg"/></div></div><figcaption class="la lb gj gh gi lc ld bd b be z dk translated">照片由<a class="ae le" href="https://unsplash.com/@srd?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText" rel="noopener ugc nofollow" target="_blank">史蒂夫·多伊格</a>在<a class="ae le" href="https://unsplash.com/s/photos/port?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上拍摄</figcaption></figure><p id="280d" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">作为更大的ML项目的一部分，我们决定探索使用公开的卫星图像评估海上交通的可能性。特别是，我们的目标是估计一个时间序列，该时间序列代表在给定区域内随时间观察到的海上交通流量。在本文中，我们将讨论<strong class="lh ja">方法和获得的结果</strong>。</p></div><div class="ab cl mb mc hu md" role="separator"><span class="me bw bk mf mg mh"/><span class="me bw bk mf mg mh"/><span class="me bw bk mf mg"/></div><div class="ij ik il im in"><p id="6632" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated"><strong class="lh ja">注</strong>:以下讨论的所有代码都可以在我位于<a class="ae le" href="https://github.com/andrea-ci/s2-ship-detection" rel="noopener ugc nofollow" target="_blank">https://github.com/andrea-ci/s2-ship-detection</a>的个人GitHub上获得。</p></div><div class="ab cl mb mc hu md" role="separator"><span class="me bw bk mf mg mh"/><span class="me bw bk mf mg mh"/><span class="me bw bk mf mg"/></div><div class="ij ik il im in"><h1 id="6ed9" class="mi mj iq bd mk ml mm mn mo mp mq mr ms kf mt kg mu ki mv kj mw kl mx km my mz bi translated">为什么是卫星数据</h1><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div role="button" tabindex="0" class="ku kv di kw bf kx"><div class="gh gi na"><img src="../Images/0f99b83d17eb03615e83ca23271601f4.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*dgEJqwJziQdgXdo6uOYEKg.jpeg"/></div></div><figcaption class="la lb gj gh gi lc ld bd b be z dk translated">Matthijs van Heerikhuize 在<a class="ae le" href="https://unsplash.com/s/photos/satellite?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上拍摄的照片</figcaption></figure><blockquote class="nb nc nd"><p id="70d6" class="lf lg ne lh b li lj ka lk ll lm kd ln nf lp lq lr ng lt lu lv nh lx ly lz ma ij bi translated">卫星升上天空了诸如此类的事情快把我逼疯了我看了一会儿我喜欢看电视节目</p><p id="14a3" class="lf lg ne lh b li lj ka lk ll lm kd ln nf lp lq lr ng lt lu lv nh lx ly lz ma ij bi translated">卢·里德，“爱情的卫星”</p></blockquote><p id="2126" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">在过去的几年里，遥感发生了巨大的变化，其他领域也是如此，如计算机视觉和机器学习。此外，越来越多的卫星图像已经公开。著名的例子包括地球资源探测卫星和T21哨兵-2星座图像。</p><p id="87ad" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">卫星对用户来说有三个基本优势:</p><ul class=""><li id="e2e6" class="ni nj iq lh b li lj ll lm lo nk ls nl lw nm ma nn no np nq bi translated">它们允许获取通常难以通过其他方式获得的信息；</li><li id="ddde" class="ni nj iq lh b li nr ll ns lo nt ls nu lw nv ma nn no np nq bi translated">它们提供全球地理覆盖；</li><li id="dd05" class="ni nj iq lh b li nr ll ns lo nt ls nu lw nv ma nn no np nq bi translated">它们以高时间分辨率周期性地收集信息(所谓的<a class="ae le" href="https://en.wikipedia.org/wiki/Satellite_revisit_period" rel="noopener ugc nofollow" target="_blank">重访期</a>)。</li></ul><p id="8349" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">此外，图像的空间分辨率，即区分两个接近物体的能力，正在不断提高，从而能够实现越来越多的新应用。市场研究公司[1]给出了一个著名的例子，他们最近利用卫星图像来统计停放在停车场的汽车数量，以估计零售需求。原则上，类似的方法也可以用于社会和行政目的的应用，例如测量城市交通或计算政治集会的人群。</p></div><div class="ab cl mb mc hu md" role="separator"><span class="me bw bk mf mg mh"/><span class="me bw bk mf mg mh"/><span class="me bw bk mf mg"/></div><div class="ij ik il im in"><h1 id="4bb4" class="mi mj iq bd mk ml mm mn mo mp mq mr ms kf mt kg mu ki mv kj mw kl mx km my mz bi translated">哨兵-2任务</h1><p id="c032" class="pw-post-body-paragraph lf lg iq lh b li nw ka lk ll nx kd ln lo ny lq lr ls nz lu lv lw oa ly lz ma ij bi translated">在这个实验中，我们考虑ESA Sentinel-2任务。Sentinel-2卫星配备了一个多光谱仪器(MSI)，该仪器使用<a class="ae le" href="https://sentinels.copernicus.eu/web/sentinel/user-guides/sentinel-2-msi/resolutions/spatial" rel="noopener ugc nofollow" target="_blank"> 13个波段以3种不同的分辨率</a>收集数据:10米、20米和60米。为了获得最佳可用分辨率，我们使用了<strong class="lh ja"> B02、B03和B04波段</strong>，这些波段位于可见光谱中，提供10米的分辨率。</p><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div class="gh gi ob"><img src="../Images/38d139d6dd6a1e90d26bcedc357736f3.png" data-original-src="https://miro.medium.com/v2/resize:fit:1278/format:webp/1*gI5VtxS6_2RQJsdiA3N7SQ.png"/></div><figcaption class="la lb gj gh gi lc ld bd b be z dk translated">分辨率为10米的Sentinel-2波段—来源:<a class="ae le" href="https://sentinels.copernicus.eu/web/sentinel/user-guides/sentinel-2-msi/resolutions/spatial" rel="noopener ugc nofollow" target="_blank">https://sentinels . Copernicus . eu</a></figcaption></figure><p id="2b05" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">可以通过不同方式访问Sentinel-2图像，包括:</p><ul class=""><li id="37dd" class="ni nj iq lh b li lj ll lm lo nk ls nl lw nm ma nn no np nq bi translated"><a class="ae le" href="https://scihub.copernicus.eu/" rel="noopener ugc nofollow" target="_blank">哥白尼开放访问中心</a>，欧空局的一个网站，提供对Sentinel-1、Sentinel-2、Sentinel-3和Sentinel-5P用户产品的免费和开放访问；</li><li id="3652" class="ni nj iq lh b li nr ll ns lo nt ls nu lw nv ma nn no np nq bi translated">来自亚马逊AWS的<a class="ae le" href="https://registry.opendata.aws/" rel="noopener ugc nofollow" target="_blank">开放数据注册表</a>；</li><li id="c135" class="ni nj iq lh b li nr ll ns lo nt ls nu lw nv ma nn no np nq bi translated"><a class="ae le" href="https://www.sentinel-hub.com/" rel="noopener ugc nofollow" target="_blank"> Sentinel HUB </a>，一个用于卫星图像的云API，也有一个方便的Python库<a class="ae le" href="https://sentinelhub-py.readthedocs.io/en/latest/index.html" rel="noopener ugc nofollow" target="_blank"> <strong class="lh ja"> sentinelhub </strong> </a>。</li></ul><h1 id="c7bc" class="mi mj iq bd mk ml oc mn mo mp od mr ms kf oe kg mu ki of kj mw kl og km my mz bi translated">建模方法</h1><p id="1941" class="pw-post-body-paragraph lf lg iq lh b li nw ka lk ll nx kd ln lo ny lq lr ls nz lu lv lw oa ly lz ma ij bi translated">检测图像上的船只是一项艰巨的任务，因为通过构造，正样本(即属于船只的像素)的数量与负样本的数量相比非常小。因此，我没有尝试语义分类任务，而是选择了一种<strong class="lh ja">对象检测方法</strong>。</p><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div role="button" tabindex="0" class="ku kv di kw bf kx"><div class="gh gi oh"><img src="../Images/d7db93c35c74c3da10498fa8e89e77f4.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*WcTwdiJbH-gak0J_1RaWkg.png"/></div></div><figcaption class="la lb gj gh gi lc ld bd b be z dk translated">处理工作流程-按作者分类的图像</figcaption></figure><p id="ab7a" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">作为基线，已经考虑了预训练的<a class="ae le" href="https://arxiv.org/abs/1703.06870" rel="noopener ugc nofollow" target="_blank">掩模R-CNN </a>模型。该模型为<a class="ae le" href="https://arxiv.org/abs/1506.01497" rel="noopener ugc nofollow" target="_blank">更快的R-CNN </a>模型增加了一个额外的分支，该模型反过来基于Resnet的架构，在“<a class="ae le" href="https://arxiv.org/abs/1512.03385" rel="noopener ugc nofollow" target="_blank">图像识别的深度残差学习</a>中介绍。</p><p id="cb8b" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">Resnet代表<strong class="lh ja">残差网络</strong>，因为该网络引入了残差学习的概念。残差学习是一种旨在提高深度卷积神经网络分类和识别任务性能的方法。一般来说，深度网络通过它们的层来学习低、中和高水平的特征。残差网络通过使用图层之间的快捷连接来学习残差，即要素之间的差异。这种方法已被证明可以使训练更容易，获得更好的精度值。Resnet型号有5种型号，分别包含18、34、50、101和152层。</p><p id="247a" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">对于深度学习的实现，我已经使用了<strong class="lh ja"> PyTorch </strong>和<strong class="lh ja"> TorchVision提供的Mask R-CNN模型。</strong>自带50层，在<a class="ae le" href="https://cocodataset.org/#home" rel="noopener ugc nofollow" target="_blank"> COCO数据集</a>上进行预训练。</p><p id="35c0" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">现在是微调模型的时候了。</p></div><div class="ab cl mb mc hu md" role="separator"><span class="me bw bk mf mg mh"/><span class="me bw bk mf mg mh"/><span class="me bw bk mf mg"/></div><div class="ij ik il im in"><h1 id="4d1d" class="mi mj iq bd mk ml mm mn mo mp mq mr ms kf mt kg mu ki mv kj mw kl mx km my mz bi translated">模型微调:数据和训练</h1><p id="c508" class="pw-post-body-paragraph lf lg iq lh b li nw ka lk ll nx kd ln lo ny lq lr ls nz lu lv lw oa ly lz ma ij bi translated">为了微调模型，我使用了Kaggle <a class="ae le" href="https://www.kaggle.com/c/airbus-ship-detection" rel="noopener ugc nofollow" target="_blank"> <strong class="lh ja">空中客车船舶探测挑战赛</strong> </a>的比赛数据。</p><p id="f2a7" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">这个数据集由192556幅图像组成，其中只有42556幅包含至少一艘船(占总数的22%)。而且，它们中的大多数(大约60%)包含<em class="ne">恰好</em>一艘船。因此，数据集非常不平衡，阳性样本的数量非常有限。</p><p id="aea0" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">更困难的是，图像中包含的船只在大小上可能有很大差异，它们可能位于公海或码头和码头，例如靠近陆地的地方。</p><p id="0d41" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">数据集附带一个CSV文件，其中船舶掩码由<a class="ae le" href="https://en.wikipedia.org/wiki/Run-length_encoding" rel="noopener ugc nofollow" target="_blank">游程编码</a>表示。由于大多数图像不包含任何船只，我将它们从数据集中删除。对于剩余的，生成<strong class="lh ja">掩模</strong>,因此它们可用于模型目标的创建。</p><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div role="button" tabindex="0" class="ku kv di kw bf kx"><div class="gh gi oi"><img src="../Images/86b2c7a720a3c81c582aa50c5db749e3.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*obgQLLeHCUgnumqEKanppw.png"/></div></div><figcaption class="la lb gj gh gi lc ld bd b be z dk translated">准备训练数据-按作者分类的图像</figcaption></figure><p id="e0fc" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">遮罩是基于整数的2D阵列，这意味着对于任何像素<em class="ne"> x: </em></p><ul class=""><li id="cfa7" class="ni nj iq lh b li lj ll lm lo nk ls nl lw nm ma nn no np nq bi translated"><em class="ne"> x=0，</em>如果不代表船；</li><li id="1d63" class="ni nj iq lh b li nr ll ns lo nt ls nu lw nv ma nn no np nq bi translated"><em class="ne"> x=1，</em>如果是第一艘船的一部分；</li><li id="23ef" class="ni nj iq lh b li nr ll ns lo nt ls nu lw nv ma nn no np nq bi translated"><em class="ne"> x=2，</em>如果是第二艘船的一部分；</li><li id="30be" class="ni nj iq lh b li nr ll ns lo nt ls nu lw nv ma nn no np nq bi translated">诸如此类。</li></ul><p id="501c" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">需要像素编号来识别图像中包含的任何最终船只，因为模型返回对象(船只),并且每个对象由唯一的边界框来表征。</p><p id="9f98" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">因此，遵循TorchVision 提供的优秀教程<a class="ae le" href="https://pytorch.org/tutorials/intermediate/torchvision_tutorial.html" rel="noopener ugc nofollow" target="_blank">，我已经为<strong class="lh ja">空中客车数据集</strong>准备了代码，如下一个片段所示。</a></p><pre class="kp kq kr ks gt oj ok ol om aw on bi"><span id="6d4d" class="oo mj iq ok b gy op oq l or os">class AirbusShipDetection(Dataset):</span><span id="2dc1" class="oo mj iq ok b gy ot oq l or os">    def __init__(self, image_ids, dir_images, dir_masks, transforms = None):</span><span id="b08f" class="oo mj iq ok b gy ot oq l or os">        self.image_ids = image_ids<br/>        self.dir_images = dir_images<br/>        self.dir_masks = dir_masks<br/>        self._transforms = transforms</span><span id="13b3" class="oo mj iq ok b gy ot oq l or os">    def __getitem__(self, idx):</span><span id="ff31" class="oo mj iq ok b gy ot oq l or os">        # Read the RGB image.<br/>        fn_image = f'{self.image_ids[idx]}.jpg'<br/>        path_image = path.join(self.dir_images, fn_image)<br/>        image = Image.open(path_image).convert("RGB")</span><span id="33b4" class="oo mj iq ok b gy ot oq l or os">        # Read the integer-based mask.<br/>        fn_mask = f'{self.image_ids[idx]}_mask.png'<br/>        path_mask = path.join(self.dir_masks, fn_mask)<br/>        mask = np.array(Image.open(path_mask))</span><span id="e339" class="oo mj iq ok b gy ot oq l or os">        # Instances are encoded with different integers.<br/>        obj_ids = np.unique(mask)</span><span id="43fa" class="oo mj iq ok b gy ot oq l or os">        # We remove the background (id=0) from the mask.<br/>        obj_ids = obj_ids[1:]<br/>        num_objs = len(obj_ids)</span><span id="99df" class="oo mj iq ok b gy ot oq l or os">        # Split the mask into a set of binary masks<br/>        # masks.shape[0] = number of istances<br/>        masks = mask == obj_ids[:, None, None]</span><span id="94d5" class="oo mj iq ok b gy ot oq l or os">        # Get bounding box of each mask.<br/>        boxes = []<br/>        for mask in masks:</span><span id="b2b8" class="oo mj iq ok b gy ot oq l or os">            pos = np.where(mask)</span><span id="dd99" class="oo mj iq ok b gy ot oq l or os">            xmin = np.min(pos[1])<br/>            xmax = np.max(pos[1])<br/>            ymin = np.min(pos[0])<br/>            ymax = np.max(pos[0])</span><span id="60b1" class="oo mj iq ok b gy ot oq l or os">            # Enforce a positive area.<br/>            if xmax - xmin &lt; 1:<br/>                xmax += 1<br/>            if ymax - ymin &lt; 1:<br/>                ymax += 1</span><span id="a4ea" class="oo mj iq ok b gy ot oq l or os">            boxes.append([xmin, ymin, xmax, ymax])</span><span id="3dd3" class="oo mj iq ok b gy ot oq l or os">        boxes = torch.as_tensor(boxes, dtype = torch.float32)</span><span id="64f0" class="oo mj iq ok b gy ot oq l or os">        # Compute the area.<br/>        area = (boxes[:, 3] - boxes[:, 1]) * (boxes[:, 2] - boxes[:, 0])</span><span id="d07e" class="oo mj iq ok b gy ot oq l or os">        # Only one class (ships).<br/>        labels = torch.ones((num_objs,), dtype = torch.int64)<br/>        masks = torch.as_tensor(masks, dtype = torch.uint8)</span><span id="74ed" class="oo mj iq ok b gy ot oq l or os">        # Crowd flag not applicable here.<br/>        iscrowd = torch.zeros((num_objs,), dtype=torch.int64)</span><span id="6f76" class="oo mj iq ok b gy ot oq l or os">        image_id = torch.tensor([idx])</span><span id="e97c" class="oo mj iq ok b gy ot oq l or os">        target = {}<br/>        target['boxes'] = boxes<br/>        target['labels'] = labels<br/>        target['masks'] = masks<br/>        target['image_id'] = image_id<br/>        target['area'] = area<br/>        target['iscrowd'] = iscrowd</span><span id="d89d" class="oo mj iq ok b gy ot oq l or os">        # Apply image augmentation.<br/>        if self._transforms:<br/>            image, target = self._transforms(image, target)</span><span id="e9d7" class="oo mj iq ok b gy ot oq l or os">        return image, target</span><span id="ef99" class="oo mj iq ok b gy ot oq l or os">    def __len__(self):<br/>        # return length of<br/>        return len(self.image_ids)</span></pre><p id="5469" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">这里可以清楚地看到模型输出的结构:它由一个字典组成，其中包含与模型检测到的对象相关的信息。</p></div><div class="ab cl mb mc hu md" role="separator"><span class="me bw bk mf mg mh"/><span class="me bw bk mf mg mh"/><span class="me bw bk mf mg"/></div><div class="ij ik il im in"><p id="ac3d" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">在10个训练时期之后，评估度量表现出可接受的值，从而可以终止训练，并且模型最终准备好应用于Sentinel-2图像。</p><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div class="gh gi ou"><img src="../Images/025793854830a044987fb25c0a6d299a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1146/format:webp/1*42ao6Ki0ZFeUhtz5RYAl3Q.png"/></div><figcaption class="la lb gj gh gi lc ld bd b be z dk translated">模型评估—作者提供的图片</figcaption></figure></div><div class="ab cl mb mc hu md" role="separator"><span class="me bw bk mf mg mh"/><span class="me bw bk mf mg mh"/><span class="me bw bk mf mg"/></div><div class="ij ik il im in"><h1 id="c245" class="mi mj iq bd mk ml mm mn mo mp mq mr ms kf mt kg mu ki mv kj mw kl mx km my mz bi translated">对哨兵-2数据的推断</h1><p id="27a3" class="pw-post-body-paragraph lf lg iq lh b li nw ka lk ll nx kd ln lo ny lq lr ls nz lu lv lw oa ly lz ma ij bi translated">在实验中，我将注意力集中在意大利撒丁岛奥尔比亚市<strong class="lh ja">港口周围的一小块区域</strong>。这个港口是从意大利半岛来的渡船进入该岛的主要入口之一，尤其是在暑假期间。</p><p id="82aa" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">已经考虑了从<strong class="lh ja"> 2017到2020 </strong>之间的时间段，并且每个月以固定的时间间隔采集了两幅图像。因此，模型输入由一系列<strong class="lh ja"> 96幅原始RGB图像</strong>组成。不幸的是，其中一些导致了畸形，要么是因为下载期间的API问题，要么是因为它们没有通过Sentinel-2处理链的质量检查，因此它们必须被丢弃。</p></div><div class="ab cl mb mc hu md" role="separator"><span class="me bw bk mf mg mh"/><span class="me bw bk mf mg mh"/><span class="me bw bk mf mg"/></div><div class="ij ik il im in"><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div role="button" tabindex="0" class="ku kv di kw bf kx"><div class="gh gi ov"><img src="../Images/045439aa5b3a9874488a95a54b09671b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*j7GDiAeb3v5V0qFlkVMJeg.png"/></div></div><figcaption class="la lb gj gh gi lc ld bd b be z dk translated">根据Sentinel-2快照推断——作者提供的图片</figcaption></figure><p id="e740" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">模型对图像序列进行处理，并将检测结果保存到<strong class="lh ja"> CSV文件中:</strong>报告每幅图像的采集日期和检测到的船只数量。此外，船只占据的总面积也包括在内，尽管它不用于此分析。</p><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div role="button" tabindex="0" class="ku kv di kw bf kx"><div class="gh gi ow"><img src="../Images/14d1a252be2ae8526330c7cfc0f39c74.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*siszqHp7JXi8jXs4qLvonA.png"/></div></div><figcaption class="la lb gj gh gi lc ld bd b be z dk translated">检测结果—作者提供的图片</figcaption></figure></div><div class="ab cl mb mc hu md" role="separator"><span class="me bw bk mf mg mh"/><span class="me bw bk mf mg mh"/><span class="me bw bk mf mg"/></div><div class="ij ik il im in"><h1 id="5619" class="mi mj iq bd mk ml mm mn mo mp mq mr ms kf mt kg mu ki mv kj mw kl mx km my mz bi translated">结果分析</h1><p id="ad6d" class="pw-post-body-paragraph lf lg iq lh b li nw ka lk ll nx kd ln lo ny lq lr ls nz lu lv lw oa ly lz ma ij bi translated">使用<strong class="lh ja"> Pandas </strong>很容易从CSV文件中提取和可视化时间序列。文件中报告的计数按月平均，以获得参考月份每天观察到的船只的时间序列。</p><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div role="button" tabindex="0" class="ku kv di kw bf kx"><div class="gh gi ox"><img src="../Images/96ce70863d1087b642138fb4509901fa.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*hSjICv6e0ASPreFmHcM5IQ.png"/></div></div></figure><p id="cebe" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">该时间序列显示出很强的季节性。这种现象很可能是由几个不同的原因造成的:</p><ul class=""><li id="93ae" class="ni nj iq lh b li lj ll lm lo nk ls nl lw nm ma nn no np nq bi translated">港口的活动以<strong class="lh ja">旅游型</strong>为主，夏季游客流量较大；</li><li id="959a" class="ni nj iq lh b li nr ll ns lo nt ls nu lw nv ma nn no np nq bi translated">夏季的天气条件有利于获取更清晰的图像(即低云量)，从而允许更多的船只被正确检测到。</li></ul><p id="da7b" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">这两个因素导致夏季交通量最大，然后逐渐减少，直到冬季达到最小值。</p><p id="7e5d" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">据当地报纸[2]报道，2020年夏季，奥尔比亚港的交通量<strong class="lh ja">比2019年<strong class="lh ja"> </strong>减少了约15% </strong>，原因是疫情的限制影响了整个国家。</p><p id="e1fd" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">考虑到夏季期间(即4月至9月，包括4月和9月)获得的计数总和，获得的数据与此声明一致，因为它们表明<strong class="lh ja">的交通量在2020年减少了约16.28%。</strong></p><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div role="button" tabindex="0" class="ku kv di kw bf kx"><div class="gh gi oy"><img src="../Images/f91254d7944a01877c8dfb0e68750134.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*CwTWmmwA54nupLsEc3U3hQ.png"/></div></div><figcaption class="la lb gj gh gi lc ld bd b be z dk translated">作者图片</figcaption></figure></div><div class="ab cl mb mc hu md" role="separator"><span class="me bw bk mf mg mh"/><span class="me bw bk mf mg mh"/><span class="me bw bk mf mg"/></div><div class="ij ik il im in"><h1 id="907e" class="mi mj iq bd mk ml mm mn mo mp mq mr ms kf mt kg mu ki mv kj mw kl mx km my mz bi translated">结论</h1><p id="8eb6" class="pw-post-body-paragraph lf lg iq lh b li nw ka lk ll nx kd ln lo ny lq lr ls nz lu lv lw oa ly lz ma ij bi translated">可见光谱中的卫星图像对天气条件高度敏感，必须根据具体的项目要求(例如，感兴趣的区域、重访周期、图像分辨率)仔细评估其用途。然而，从原则上来说，应用它们来提取海事活动的替代措施似乎是可能的。</p></div><div class="ab cl mb mc hu md" role="separator"><span class="me bw bk mf mg mh"/><span class="me bw bk mf mg mh"/><span class="me bw bk mf mg"/></div><div class="ij ik il im in"><h1 id="47b3" class="mi mj iq bd mk ml mm mn mo mp mq mr ms kf mt kg mu ki mv kj mw kl mx km my mz bi translated">参考</h1><p id="b24e" class="pw-post-body-paragraph lf lg iq lh b li nw ka lk ll nx kd ln lo ny lq lr ls nz lu lv lw oa ly lz ma ij bi translated">[1]<a class="ae le" href="https://internationalbanker.com/brokerage/how-satellite-imagery-is-helping-hedge-funds-outperform/" rel="noopener ugc nofollow" target="_blank">https://international banker . com/brokerage/how-satellite-imagery-is-helping-hedge-funds-perform/</a></p><p id="3c04" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">[2]<a class="ae le" href="https://www.lanuovasardegna.it/olbia/cronaca/2021/08/19/news/e-ripartito-anche-il-porto-aumentano-i-passeggeri-1.40616298" rel="noopener ugc nofollow" target="_blank">https://www . lanuovasardegna . it/ol bia/crona ca/2021/08/19/news/e-ripartito-车安-il-Porto-aumentano-I-passeggeri-1.40616298</a></p><p id="c970" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated"><a class="ae le" href="https://sentinel.esa.int/web/sentinel/missions/sentinel-2" rel="noopener ugc nofollow" target="_blank">https://sentinel.esa.int/web/sentinel/missions/sentinel-2</a></p><p id="a798" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated"><a class="ae le" href="https://scihub.copernicus.eu/" rel="noopener ugc nofollow" target="_blank">https://scihub.copernicus.eu/</a></p><p id="8c96" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated"><a class="ae le" href="https://sentinelhub-py.readthedocs.io/en/latest/index.html" rel="noopener ugc nofollow" target="_blank">https://sentinelhub-py.readthedocs.io/en/latest/index.html</a></p><p id="1d9e" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">[6]<a class="ae le" href="https://pytorch.org/tutorials/intermediate/torchvision_tutorial.html" rel="noopener ugc nofollow" target="_blank">https://py torch . org/tutorials/intermediate/torch vision _ tutorial . html</a></p><p id="ba54" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated"><a class="ae le" href="https://www.kaggle.com/c/airbus-ship-detection" rel="noopener ugc nofollow" target="_blank">https://www.kaggle.com/c/airbus-ship-detection</a></p></div></div>    
</body>
</html>