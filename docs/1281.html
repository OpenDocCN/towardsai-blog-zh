<html>
<head>
<title>2020: A Year Full of Amazing AI Papers — A Review</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">2020:充满惊人人工智能论文的一年——综述</h1>
<blockquote>原文：<a href="https://pub.towardsai.net/2020-a-year-full-of-amazing-ai-papers-a-review-c42fa07aff4b?source=collection_archive---------0-----------------------#2020-12-21">https://pub.towardsai.net/2020-a-year-full-of-amazing-ai-papers-a-review-c42fa07aff4b?source=collection_archive---------0-----------------------#2020-12-21</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><h2 id="4df9" class="ir is it bd b dl iu iv iw ix iy iz dk ja translated" aria-label="kicker paragraph"><a class="ae ep" href="https://towardsai.net/p/category/artificial-intelligence" rel="noopener ugc nofollow" target="_blank">人工智能</a>，<a class="ae ep" href="https://towardsai.net/p/category/research" rel="noopener ugc nofollow" target="_blank">研究</a></h2><div class=""/><div class=""><h2 id="e3f1" class="pw-subtitle-paragraph jz jc it bd b ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq dk translated">按发布日期排列的<strong class="ak">在人工智能领域的最新突破列表<strong class="ak">带有</strong>清晰的视频解释<strong class="ak">，链接到更深入的文章</strong>，以及<strong class="ak">代码</strong></strong></h2></div><blockquote class="kr ks kt"><p id="846c" class="ku kv kw kx b ky kz kd la lb lc kg ld le lf lg lh li lj lk ll lm ln lo lp lq im bi translated">最初发表在<a class="ae lr" href="https://www.louisbouchard.ai/2020-a-year-full-of-amazing-ai-papers-a-review/" rel="noopener ugc nofollow" target="_blank"> louisbouchard.ai </a>上，前两天在<a class="ae lr" href="https://www.louisbouchard.ai/tag/artificial-intelligence/" rel="noopener ugc nofollow" target="_blank">我的博客</a>上看过！</p></blockquote><figure class="lt lu lv lw gt lx gh gi paragraph-image"><div role="button" tabindex="0" class="ly lz di ma bf mb"><div class="gh gi ls"><img src="../Images/5b18829daee70ca21d5cb3d84e0ec785.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*bFiVHSRQUNdURCGw"/></div></div><figcaption class="me mf gj gh gi mg mh bd b be z dk translated">由<a class="ae lr" href="https://unsplash.com/@kellysikkema?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Kelly Sikkema </a>在<a class="ae lr" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上拍摄的照片</figcaption></figure><p id="3439" class="pw-post-body-paragraph ku kv it kx b ky kz kd la lb lc kg ld mi lf lg lh mj lj lk ll mk ln lo lp lq im bi translated">即使今年世界上发生了这么多事情，我们仍然有机会看到许多惊人的研究成果问世。尤其是在人工智能领域。此外，今年还强调了许多重要的方面，如伦理方面、重要的偏见等等。人工智能和我们对人脑及其与人工智能的联系的理解正在不断发展，在不久的将来显示出有前途的应用。</p><p id="ae6f" class="pw-post-body-paragraph ku kv it kx b ky kz kd la lb lc kg ld mi lf lg lh mj lj lk ll mk ln lo lp lq im bi translated">这里是今年最有趣的研究论文，以防你错过其中的任何一篇。简而言之，它基本上是一个按发布日期排列的<strong class="kx jd">人工智能和数据科学最新突破的精选列表，带有<strong class="kx jd">清晰的视频解释</strong>，<strong class="kx jd">指向更深入文章的链接</strong>，以及<strong class="kx jd">代码</strong>(如果适用)。享受阅读，如果我错过了任何重要的论文，请在评论中告诉我，或者直接在LinkedIn上联系我！</strong></p><p id="d866" class="pw-post-body-paragraph ku kv it kx b ky kz kd la lb lc kg ld mi lf lg lh mj lj lk ll mk ln lo lp lq im bi translated">本文末尾列出了每篇论文的完整参考资料。</p><p id="94f8" class="pw-post-body-paragraph ku kv it kx b ky kz kd la lb lc kg ld mi lf lg lh mj lj lk ll mk ln lo lp lq im bi translated"><a class="ae lr" href="https://github.com/louisfb01/Best_AI_paper_2020" rel="noopener ugc nofollow" target="_blank">访问GitHub仓库中的完整列表</a> <a class="ae lr" href="https://github.com/louisfb01/Best_AI_paper_2020" rel="noopener ugc nofollow" target="_blank">仓库</a></p><p id="8be2" class="pw-post-body-paragraph ku kv it kx b ky kz kd la lb lc kg ld mi lf lg lh mj lj lk ll mk ln lo lp lq im bi translated"><strong class="kx jd"> <em class="kw">在</em></strong><a class="ae lr" href="https://twitter.com/Whats_AI" rel="noopener ugc nofollow" target="_blank"><strong class="kx jd"><em class="kw">Twitter(@ Whats _ AI)</em></strong></a><strong class="kx jd"><em class="kw">或</em></strong><a class="ae lr" href="https://www.linkedin.com/in/whats-ai/" rel="noopener ugc nofollow" target="_blank"><strong class="kx jd"><em class="kw">LinkedIn(Louis(What ' s AI)</em></strong></a><strong class="kx jd"><em class="kw">如有分享文章！</em> </strong></p><h1 id="33fd" class="ml mm it bd mn mo mp mq mr ms mt mu mv ki mw kj mx kl my km mz ko na kp nb nc bi translated">在15分钟内观看完整的2020年倒带</h1><figure class="lt lu lv lw gt lx"><div class="bz fp l di"><div class="nd ne l"/></div></figure></div><div class="ab cl nf ng hx nh" role="separator"><span class="ni bw bk nj nk nl"/><span class="ni bw bk nj nk nl"/><span class="ni bw bk nj nk"/></div><div class="im in io ip iq"><h1 id="b05b" class="ml mm it bd mn mo nm mq mr ms nn mu mv ki no kj mx kl np km mz ko nq kp nb nc bi translated"><a class="ae lr" href="https://arxiv.org/abs/2004.10934" rel="noopener ugc nofollow" target="_blank"> YOLOv4:物体检测的最佳速度和精度</a> [1]</h1><p id="6399" class="pw-post-body-paragraph ku kv it kx b ky nr kd la lb ns kg ld mi nt lg lh mj nu lk ll mk nv lo lp lq im bi translated">这个第四版最近在2020年4月由Alexey Bochkovsky等人在论文“YOLOv4:物体检测的最佳速度和精度”中介绍。该算法的主要目标是制造一个在准确性方面具有高质量的超快速对象检测器。</p><figure class="lt lu lv lw gt lx"><div class="bz fp l di"><div class="nd ne l"/></div></figure><div class="nw nx gp gr ny nz"><a href="https://medium.com/what-is-artificial-intelligence/the-yolov4-algorithm-introduction-to-you-only-look-once-version-4-real-time-object-detection-5fd8a608b0fa" rel="noopener follow" target="_blank"><div class="oa ab fo"><div class="ob ab oc cl cj od"><h2 class="bd jd gy z fp oe fr fs of fu fw jc bi translated">YOLOv4算法|只看一次的介绍，第4版|实时对象检测</h2><div class="og l"><h3 class="bd b gy z fp oe fr fs of fu fw dk translated">我最近发表了一篇文章，解释了“你只看一次”的基本原理，也就是众所周知的YOLO算法。还有…</h3></div><div class="oh l"><p class="bd b dl z fp oe fr fs of fu fw dk translated">medium.com</p></div></div><div class="oi l"><div class="oj l ok ol om oi on mc nz"/></div></div></a></div><p id="48b6" class="pw-post-body-paragraph ku kv it kx b ky kz kd la lb lc kg ld mi lf lg lh mj lj lk ll mk ln lo lp lq im bi translated"><a class="ae lr" href="https://github.com/AlexeyAB/darknet" rel="noopener ugc nofollow" target="_blank">点击此处获取Yolo v4代码</a></p></div><div class="ab cl nf ng hx nh" role="separator"><span class="ni bw bk nj nk nl"/><span class="ni bw bk nj nk nl"/><span class="ni bw bk nj nk"/></div><div class="im in io ip iq"><h1 id="48d6" class="ml mm it bd mn mo nm mq mr ms nn mu mv ki no kj mx kl np km mz ko nq kp nb nc bi translated"><a class="ae lr" href="http://geometrylearning.com/paper/DeepFaceDrawing.pdf" rel="noopener ugc nofollow" target="_blank"> DeepFaceDrawing:从草图深度生成人脸图像</a><strong class="ak">【2】</strong></h1><p id="fc54" class="pw-post-body-paragraph ku kv it kx b ky nr kd la lb ns kg ld mi nt lg lh mj nu lk ll mk nv lo lp lq im bi translated">您现在可以使用这种新的图像到图像的翻译技术，从粗糙甚至不完整的草图中生成高质量的人脸图像，而无需任何绘图技能！如果你的绘画技巧和我一样差，你甚至可以调整眼睛、嘴巴和鼻子对最终图像的影响！让我们看看它是否真的有效，以及他们是如何做到的。</p><figure class="lt lu lv lw gt lx"><div class="bz fp l di"><div class="nd ne l"/></div></figure><div class="nw nx gp gr ny nz"><a href="https://medium.com/what-is-artificial-intelligence/ai-generates-real-faces-from-sketches-8ccbac5d2b2e" rel="noopener follow" target="_blank"><div class="oa ab fo"><div class="ob ab oc cl cj od"><h2 class="bd jd gy z fp oe fr fs of fu fw jc bi translated">AI从草图生成真实人脸！</h2><div class="og l"><h3 class="bd b gy z fp oe fr fs of fu fw dk translated">您现在可以使用……从粗糙甚至不完整的草图生成高质量的人脸图像，而无需任何绘图技能</h3></div><div class="oh l"><p class="bd b dl z fp oe fr fs of fu fw dk translated">medium.com</p></div></div><div class="oi l"><div class="oo l ok ol om oi on mc nz"/></div></div></a></div><p id="f189" class="pw-post-body-paragraph ku kv it kx b ky kz kd la lb lc kg ld mi lf lg lh mj lj lk ll mk ln lo lp lq im bi translated"><a class="ae lr" href="https://github.com/IGLICT/DeepFaceDrawing-Jittor" rel="noopener ugc nofollow" target="_blank">点击此处获取深度绘制代码</a></p></div><div class="ab cl nf ng hx nh" role="separator"><span class="ni bw bk nj nk nl"/><span class="ni bw bk nj nk nl"/><span class="ni bw bk nj nk"/></div><div class="im in io ip iq"><h1 id="99fb" class="ml mm it bd mn mo nm mq mr ms nn mu mv ki no kj mx kl np km mz ko nq kp nb nc bi translated"><a class="ae lr" href="https://arxiv.org/pdf/2005.12126.pdf" rel="noopener ugc nofollow" target="_blank">学习用GameGAN模拟动态环境</a>【3】</h1><figure class="lt lu lv lw gt lx"><div class="bz fp l di"><div class="nd ne l"/></div></figure><div class="nw nx gp gr ny nz"><a href="https://blogs.nvidia.com/blog/2020/05/22/gamegan-research-pacman-anniversary/" rel="noopener  ugc nofollow" target="_blank"><div class="oa ab fo"><div class="ob ab oc cl cj od"><h2 class="bd jd gy z fp oe fr fs of fu fw jc bi translated">英伟达研究人员用人工智能重现吃豆人|英伟达博客</h2><div class="og l"><h3 class="bd b gy z fp oe fr fs of fu fw dk translated">自从《吃豆人》第一次出现在日本的游戏厅，并开始大嚼一条通往全球明星之路的40年后的今天,…</h3></div><div class="oh l"><p class="bd b dl z fp oe fr fs of fu fw dk translated">blogs.nvidia.com</p></div></div><div class="oi l"><div class="op l ok ol om oi on mc nz"/></div></div></a></div><p id="406e" class="pw-post-body-paragraph ku kv it kx b ky kz kd la lb lc kg ld mi lf lg lh mj lj lk ll mk ln lo lp lq im bi translated"><a class="ae lr" href="https://github.com/nv-tlabs/GameGAN_code" rel="noopener ugc nofollow" target="_blank">点击这里获取GameGAN代码</a></p></div><div class="ab cl nf ng hx nh" role="separator"><span class="ni bw bk nj nk nl"/><span class="ni bw bk nj nk nl"/><span class="ni bw bk nj nk"/></div><div class="im in io ip iq"><h1 id="e9ad" class="ml mm it bd mn mo nm mq mr ms nn mu mv ki no kj mx kl np km mz ko nq kp nb nc bi translated"><a class="ae lr" href="https://arxiv.org/abs/2003.03808" rel="noopener ugc nofollow" target="_blank">脉冲:通过生成模型的潜在空间探索进行自我监督的照片上采样</a>【4】</h1><p id="09ad" class="pw-post-body-paragraph ku kv it kx b ky nr kd la lb ns kg ld mi nt lg lh mj nu lk ll mk nv lo lp lq im bi translated">这种新算法将模糊图像转换成高分辨率图像！<br/>它可以拍摄超低分辨率的16x16图像，并将其变成1080p高清人脸！你不相信我？然后你可以像我一样做，在一分钟之内在自己身上试试！但首先，让我们看看他们是如何做到的。</p><figure class="lt lu lv lw gt lx"><div class="bz fp l di"><div class="nd ne l"/></div></figure><div class="nw nx gp gr ny nz"><a href="https://medium.com/what-is-artificial-intelligence/this-ai-makes-blurry-faces-look-60-times-sharper-7fcd3b820910" rel="noopener follow" target="_blank"><div class="oa ab fo"><div class="ob ab oc cl cj od"><h2 class="bd jd gy z fp oe fr fs of fu fw jc bi translated">这种人工智能使模糊的脸看起来清晰60倍</h2><div class="og l"><h3 class="bd b gy z fp oe fr fs of fu fw dk translated">这种新算法将模糊图像转换成高分辨率图像！它可以拍摄超低分辨率的16x16图像…</h3></div><div class="oh l"><p class="bd b dl z fp oe fr fs of fu fw dk translated">medium.com</p></div></div><div class="oi l"><div class="oq l ok ol om oi on mc nz"/></div></div></a></div><p id="d414" class="pw-post-body-paragraph ku kv it kx b ky kz kd la lb lc kg ld mi lf lg lh mj lj lk ll mk ln lo lp lq im bi translated"><a class="ae lr" href="https://github.com/adamian98/pulse" rel="noopener ugc nofollow" target="_blank">点击此处获取脉冲代码</a></p></div><div class="ab cl nf ng hx nh" role="separator"><span class="ni bw bk nj nk nl"/><span class="ni bw bk nj nk nl"/><span class="ni bw bk nj nk"/></div><div class="im in io ip iq"><h2 id="6146" class="or mm it bd mn os ot dn mr ou ov dp mv mi ow ox mx mj oy oz mz mk pa pb nb iz bi translated"><a class="ae lr" href="https://arxiv.org/abs/2006.03511" rel="noopener ugc nofollow" target="_blank">编程语言的无监督翻译</a>【5】</h2><p id="efc9" class="pw-post-body-paragraph ku kv it kx b ky nr kd la lb ns kg ld mi nt lg lh mj nu lk ll mk nv lo lp lq im bi translated">这个新的模型将代码从一种编程语言转换成另一种编程语言，没有任何监督！它可以把一个Python函数翻译成C++函数，反之亦然，不需要任何先前的例子！它理解每种语言的语法，因此可以推广到任何编程语言！让我们看看他们是怎么做到的。</p><figure class="lt lu lv lw gt lx"><div class="bz fp l di"><div class="nd ne l"/></div></figure><div class="nw nx gp gr ny nz"><a href="https://medium.com/what-is-artificial-intelligence/this-ai-translates-code-from-a-programming-language-to-another-facebook-transcoder-explained-3017d052f4fd" rel="noopener follow" target="_blank"><div class="oa ab fo"><div class="ob ab oc cl cj od"><h2 class="bd jd gy z fp oe fr fs of fu fw jc bi translated">这个人工智能将代码从一种编程语言翻译成另一种语言|脸书转码器解释道</h2><div class="og l"><h3 class="bd b gy z fp oe fr fs of fu fw dk translated">这个新的模型将代码从一种编程语言转换成另一种编程语言，没有任何监督！它可以带一条蟒蛇…</h3></div><div class="oh l"><p class="bd b dl z fp oe fr fs of fu fw dk translated">medium.com</p></div></div><div class="oi l"><div class="pc l ok ol om oi on mc nz"/></div></div></a></div><p id="c95e" class="pw-post-body-paragraph ku kv it kx b ky kz kd la lb lc kg ld mi lf lg lh mj lj lk ll mk ln lo lp lq im bi translated"><a class="ae lr" href="https://github.com/facebookresearch/TransCoder?utm_source=catalyzex.com" rel="noopener ugc nofollow" target="_blank">点击此处获取代码转换器代码</a></p></div><div class="ab cl nf ng hx nh" role="separator"><span class="ni bw bk nj nk nl"/><span class="ni bw bk nj nk nl"/><span class="ni bw bk nj nk"/></div><div class="im in io ip iq"><h1 id="98de" class="ml mm it bd mn mo nm mq mr ms nn mu mv ki no kj mx kl np km mz ko nq kp nb nc bi translated"><a class="ae lr" href="https://arxiv.org/pdf/2004.00452.pdf" rel="noopener ugc nofollow" target="_blank"> PIFuHD:用于高分辨率3D人体数字化的多级像素对齐隐函数</a>【6】</h1><p id="36e1" class="pw-post-body-paragraph ku kv it kx b ky nr kd la lb ns kg ld mi nt lg lh mj nu lk ll mk nv lo lp lq im bi translated">这个人工智能从2D图像中生成人的3D高分辨率重建！它只需要一张你的照片就能生成一个看起来和你一模一样的3D头像，甚至从背后看也是如此！</p><figure class="lt lu lv lw gt lx"><div class="bz fp l di"><div class="nd ne l"/></div></figure><div class="nw nx gp gr ny nz"><a href="https://medium.com/towards-artificial-intelligence/ai-generates-3d-high-resolution-reconstructions-of-people-from-2d-images-introduction-to-pifuhd-d4aa515a482a" rel="noopener follow" target="_blank"><div class="oa ab fo"><div class="ob ab oc cl cj od"><h2 class="bd jd gy z fp oe fr fs of fu fw jc bi translated">人工智能从2D图像中生成人的3D高分辨率重建</h2><div class="og l"><h3 class="bd b gy z fp oe fr fs of fu fw dk translated">这个人工智能从2D图像中生成人的3D高分辨率重建！只需要一张你的照片…</h3></div><div class="oh l"><p class="bd b dl z fp oe fr fs of fu fw dk translated">medium.com</p></div></div><div class="oi l"><div class="pd l ok ol om oi on mc nz"/></div></div></a></div><p id="0b16" class="pw-post-body-paragraph ku kv it kx b ky kz kd la lb lc kg ld mi lf lg lh mj lj lk ll mk ln lo lp lq im bi translated"><a class="ae lr" href="https://github.com/facebookresearch/pifuhd" rel="noopener ugc nofollow" target="_blank">点击此处获取PiFuHD代码</a></p></div><div class="ab cl nf ng hx nh" role="separator"><span class="ni bw bk nj nk nl"/><span class="ni bw bk nj nk nl"/><span class="ni bw bk nj nk"/></div><div class="im in io ip iq"><h1 id="768f" class="ml mm it bd mn mo nm mq mr ms nn mu mv ki no kj mx kl np km mz ko nq kp nb nc bi translated"><a class="ae lr" href="https://studios.disneyresearch.com/2020/06/29/high-resolution-neural-face-swapping-for-visual-effects/" rel="noopener ugc nofollow" target="_blank">视觉效果的高分辨率神经面部交换</a>【7】</h1><p id="aeca" class="pw-post-body-paragraph ku kv it kx b ky nr kd la lb ns kg ld mi nt lg lh mj nu lk ll mk nv lo lp lq im bi translated">迪士尼的研究人员在同名论文中开发了一种新的高分辨率面部交换算法，用于视觉效果。它能够以百万像素的分辨率呈现照片般逼真的效果。为迪士尼工作，他们无疑是这项工作的最佳团队。他们的目标是从源演员交换目标演员的脸，同时保持演员的表演。这非常具有挑战性，并且在许多情况下非常有用，例如改变角色的年龄，当演员不可用时，或者甚至当它涉及对主要演员来说太危险而不能表演的特技场景时。目前的方法需要专业人员进行大量的逐帧动画和后期处理。</p><figure class="lt lu lv lw gt lx"><div class="bz fp l di"><div class="nd ne l"/></div></figure><div class="nw nx gp gr ny nz"><a href="https://medium.com/what-is-artificial-intelligence/disneys-new-high-resolution-face-swapping-algorithm-new-2020-face-swap-technology-explained-da7dc8caa2f2" rel="noopener follow" target="_blank"><div class="oa ab fo"><div class="ob ab oc cl cj od"><h2 class="bd jd gy z fp oe fr fs of fu fw jc bi translated">迪士尼新的高分辨率人脸交换算法| 2020年新的人脸交换技术解释</h2><div class="og l"><h3 class="bd b gy z fp oe fr fs of fu fw dk translated">迪斯尼的研究人员开发了一种新的高分辨率人脸交换算法，用于视觉效果</h3></div><div class="oh l"><p class="bd b dl z fp oe fr fs of fu fw dk translated">medium.com</p></div></div><div class="oi l"><div class="pe l ok ol om oi on mc nz"/></div></div></a></div></div><div class="ab cl nf ng hx nh" role="separator"><span class="ni bw bk nj nk nl"/><span class="ni bw bk nj nk nl"/><span class="ni bw bk nj nk"/></div><div class="im in io ip iq"><h1 id="25a2" class="ml mm it bd mn mo nm mq mr ms nn mu mv ki no kj mx kl np km mz ko nq kp nb nc bi translated"><a class="ae lr" href="https://arxiv.org/abs/2007.00653" rel="noopener ugc nofollow" target="_blank">交换自动编码器进行深度图像处理</a> [8]</h1><p id="8e96" class="pw-post-body-paragraph ku kv it kx b ky nr kd la lb ns kg ld mi nt lg lh mj nu lk ll mk nv lo lp lq im bi translated">这种新技术可以改变任何图片的纹理，同时使用完全无监督的训练保持逼真！结果看起来甚至比GANs更快的时候所能达到的还要好！它甚至可以被用来创建deepfakes！</p><figure class="lt lu lv lw gt lx"><div class="bz fp l di"><div class="nd ne l"/></div></figure><div class="nw nx gp gr ny nz"><a href="https://medium.com/what-is-artificial-intelligence/texture-swapping-ai-beats-gans-for-image-manipulation-e05700782183" rel="noopener follow" target="_blank"><div class="oa ab fo"><div class="ob ab oc cl cj od"><h2 class="bd jd gy z fp oe fr fs of fu fw jc bi translated">纹理交换人工智能在图像处理方面击败了甘斯！</h2><div class="og l"><h3 class="bd b gy z fp oe fr fs of fu fw dk translated">这种新技术可以改变任何图片的纹理，同时保持现实使用一个完全无人监督的…</h3></div><div class="oh l"><p class="bd b dl z fp oe fr fs of fu fw dk translated">medium.com</p></div></div><div class="oi l"><div class="pf l ok ol om oi on mc nz"/></div></div></a></div><p id="84d7" class="pw-post-body-paragraph ku kv it kx b ky kz kd la lb lc kg ld mi lf lg lh mj lj lk ll mk ln lo lp lq im bi translated"><a class="ae lr" href="https://github.com/rosinality/swapping-autoencoder-pytorch?utm_source=catalyzex.com" rel="noopener ugc nofollow" target="_blank">点击此处获取交换自动编码器代码</a></p></div><div class="ab cl nf ng hx nh" role="separator"><span class="ni bw bk nj nk nl"/><span class="ni bw bk nj nk nl"/><span class="ni bw bk nj nk"/></div><div class="im in io ip iq"><h1 id="8b81" class="ml mm it bd mn mo nm mq mr ms nn mu mv ki no kj mx kl np km mz ko nq kp nb nc bi translated"><a class="ae lr" href="https://arxiv.org/pdf/2005.14165.pdf" rel="noopener ugc nofollow" target="_blank"> GPT-3:语言模型是一次性学习者</a> [9]</h1><p id="1701" class="pw-post-body-paragraph ku kv it kx b ky nr kd la lb ns kg ld mi nt lg lh mj nu lk ll mk nv lo lp lq im bi translated">当前最先进的NLP系统很难推广到不同的任务。它们需要在成千上万个例子的数据集上进行微调，而人类只需要看到几个例子就可以完成一项新的语言任务。这是GPT-3背后的目标，改善语言模型的任务不可知特性。</p><figure class="lt lu lv lw gt lx"><div class="bz fp l di"><div class="nd ne l"/></div></figure><div class="nw nx gp gr ny nz"><a href="https://medium.com/towards-artificial-intelligence/can-gpt-3-really-help-you-and-your-company-84dac3c5b58a" rel="noopener follow" target="_blank"><div class="oa ab fo"><div class="ob ab oc cl cj od"><h2 class="bd jd gy z fp oe fr fs of fu fw jc bi translated">GPT-3真的能帮助你和你的公司吗？</h2><div class="og l"><h3 class="bd b gy z fp oe fr fs of fu fw dk translated">如果你曾经想知道什么是GPT-3，它如何对你或你的公司有用，这是你…</h3></div><div class="oh l"><p class="bd b dl z fp oe fr fs of fu fw dk translated">medium.com</p></div></div><div class="oi l"><div class="pg l ok ol om oi on mc nz"/></div></div></a></div><p id="4f0a" class="pw-post-body-paragraph ku kv it kx b ky kz kd la lb lc kg ld mi lf lg lh mj lj lk ll mk ln lo lp lq im bi translated"><a class="ae lr" href="https://github.com/openai/gpt-3" rel="noopener ugc nofollow" target="_blank">点击这里查看GPT 3的GitHub页面</a></p></div><div class="ab cl nf ng hx nh" role="separator"><span class="ni bw bk nj nk nl"/><span class="ni bw bk nj nk nl"/><span class="ni bw bk nj nk"/></div><div class="im in io ip iq"><h1 id="6c3d" class="ml mm it bd mn mo nm mq mr ms nn mu mv ki no kj mx kl np km mz ko nq kp nb nc bi translated"><a class="ae lr" href="https://arxiv.org/abs/2007.10247" rel="noopener ugc nofollow" target="_blank">学习视频修复的联合时空变换</a>【10】</h1><p id="1762" class="pw-post-body-paragraph ku kv it kx b ky nr kd la lb ns kg ld mi nt lg lh mj nu lk ll mk nv lo lp lq im bi translated">这种人工智能可以填充移动物体背后的缺失像素，并以比当前最先进的方法更准确、更少模糊的方式重建整个视频！</p><figure class="lt lu lv lw gt lx"><div class="bz fp l di"><div class="nd ne l"/></div></figure><div class="nw nx gp gr ny nz"><a href="https://medium.com/towards-artificial-intelligence/this-ai-takes-a-video-and-fills-the-missing-pixels-behind-an-object-video-inpainting-9be38e141f46" rel="noopener follow" target="_blank"><div class="oa ab fo"><div class="ob ab oc cl cj od"><h2 class="bd jd gy z fp oe fr fs of fu fw jc bi translated">这个AI拍摄一个视频，并填充一个对象后面缺失的像素！</h2><div class="og l"><h3 class="bd b gy z fp oe fr fs of fu fw dk translated">视频修复—微软研究院</h3></div><div class="oh l"><p class="bd b dl z fp oe fr fs of fu fw dk translated">medium.com</p></div></div><div class="oi l"><div class="ph l ok ol om oi on mc nz"/></div></div></a></div><p id="a627" class="pw-post-body-paragraph ku kv it kx b ky kz kd la lb lc kg ld mi lf lg lh mj lj lk ll mk ln lo lp lq im bi translated"><a class="ae lr" href="https://github.com/researchmm/STTN?utm_source=catalyzex.com" rel="noopener ugc nofollow" target="_blank">点击此处获取该视频修复代码</a></p></div><div class="ab cl nf ng hx nh" role="separator"><span class="ni bw bk nj nk nl"/><span class="ni bw bk nj nk nl"/><span class="ni bw bk nj nk"/></div><div class="im in io ip iq"><h1 id="5220" class="ml mm it bd mn mo nm mq mr ms nn mu mv ki no kj mx kl np km mz ko nq kp nb nc bi translated"><a class="ae lr" href="https://openai.com/blog/image-gpt/" rel="noopener ugc nofollow" target="_blank">图像GPT——从像素生成的预训练</a> [11]</h1><p id="a39c" class="pw-post-body-paragraph ku kv it kx b ky nr kd la lb ns kg ld mi nt lg lh mj nu lk ll mk nv lo lp lq im bi translated">一个好的人工智能，如Gmail中使用的人工智能，可以生成连贯的文本并完成你的短语。这一个使用相同的原则为了完成一幅图像！所有这些都是在无人监督的训练中完成的，根本不需要任何标签！</p><figure class="lt lu lv lw gt lx"><div class="bz fp l di"><div class="nd ne l"/></div></figure><div class="nw nx gp gr ny nz"><a href="https://medium.com/towards-artificial-intelligence/this-ai-can-generate-the-pixels-of-half-of-a-picture-from-nothing-using-a-nlp-model-7d7ba14b5522" rel="noopener follow" target="_blank"><div class="oa ab fo"><div class="ob ab oc cl cj od"><h2 class="bd jd gy z fp oe fr fs of fu fw jc bi translated">这个人工智能可以使用GPT模型生成另一半图片</h2><div class="og l"><h3 class="bd b gy z fp oe fr fs of fu fw dk translated">一个好的人工智能，如Gmail中使用的人工智能，可以生成连贯的文本并完成你的短语。这一个使用相同的…</h3></div><div class="oh l"><p class="bd b dl z fp oe fr fs of fu fw dk translated">medium.com</p></div></div><div class="oi l"><div class="pi l ok ol om oi on mc nz"/></div></div></a></div><p id="2ca9" class="pw-post-body-paragraph ku kv it kx b ky kz kd la lb lc kg ld mi lf lg lh mj lj lk ll mk ln lo lp lq im bi translated"><a class="ae lr" href="https://github.com/openai/image-gpt" rel="noopener ugc nofollow" target="_blank">点击此处获取OpenAI的图像GPT代码</a></p></div><div class="ab cl nf ng hx nh" role="separator"><span class="ni bw bk nj nk nl"/><span class="ni bw bk nj nk nl"/><span class="ni bw bk nj nk"/></div><div class="im in io ip iq"><h1 id="3fad" class="ml mm it bd mn mo nm mq mr ms nn mu mv ki no kj mx kl np km mz ko nq kp nb nc bi translated"><a class="ae lr" href="https://systemerrorwang.github.io/White-box-Cartoonization/paper/06791.pdf" rel="noopener ugc nofollow" target="_blank">学习使用白盒卡通表现来卡通化</a>【12】</h1><p id="f491" class="pw-post-body-paragraph ku kv it kx b ky nr kd la lb ns kg ld mi nt lg lh mj nu lk ll mk nv lo lp lq im bi translated">这个人工智能可以将你输入的任何图片或视频卡通化成你想要的卡通风格！让我们看看它是如何做到这一点的，以及一些惊人的例子。你甚至可以像我为自己做的那样，在他们创建的网站上自己尝试一下！</p><figure class="lt lu lv lw gt lx"><div class="bz fp l di"><div class="nd ne l"/></div></figure><div class="nw nx gp gr ny nz"><a href="https://medium.com/what-is-artificial-intelligence/this-ai-can-cartoonize-any-picture-or-video-you-feed-it-paper-introduction-results-examples-d7e400d8c3e8" rel="noopener follow" target="_blank"><div class="oa ab fo"><div class="ob ab oc cl cj od"><h2 class="bd jd gy z fp oe fr fs of fu fw jc bi translated">这个人工智能可以将你输入的任何图片或视频卡通化！论文介绍和结果示例</h2><div class="og l"><h3 class="bd b gy z fp oe fr fs of fu fw dk translated">这个人工智能可以将你输入的任何图片或视频卡通化成你想要的卡通风格！让我们看看它是如何做到这一点的…</h3></div><div class="oh l"><p class="bd b dl z fp oe fr fs of fu fw dk translated">medium.com</p></div></div><div class="oi l"><div class="pj l ok ol om oi on mc nz"/></div></div></a></div><p id="c1ae" class="pw-post-body-paragraph ku kv it kx b ky kz kd la lb lc kg ld mi lf lg lh mj lj lk ll mk ln lo lp lq im bi translated"><a class="ae lr" href="https://github.com/SystemErrorWang/White-box-Cartoonization" rel="noopener ugc nofollow" target="_blank">点击此处获取卡通化代码</a></p></div><div class="ab cl nf ng hx nh" role="separator"><span class="ni bw bk nj nk nl"/><span class="ni bw bk nj nk nl"/><span class="ni bw bk nj nk"/></div><div class="im in io ip iq"><h1 id="77de" class="ml mm it bd mn mo nm mq mr ms nn mu mv ki no kj mx kl np km mz ko nq kp nb nc bi translated"><a class="ae lr" href="https://arxiv.org/pdf/2002.10964.pdf" rel="noopener ugc nofollow" target="_blank">冻结:冻结鉴别器:微调GANs的简单基线</a> [13]</h1><p id="a83b" class="pw-post-body-paragraph ku kv it kx b ky nr kd la lb ns kg ld mi nt lg lh mj nu lk ll mk nv lo lp lq im bi translated">这种人脸生成模型能够将普通人脸照片转换成独特的风格，如李马尔尼翁的卡通风格，辛普森一家，艺术，甚至狗！这项新技术最大的优点是它超级简单，并且明显优于以前在GANs中使用的技术。</p><figure class="lt lu lv lw gt lx"><div class="bz fp l di"><div class="nd ne l"/></div></figure><div class="nw nx gp gr ny nz"><a href="https://medium.com/what-is-artificial-intelligence/this-face-generating-model-transfers-real-face-photographs-into-distinctive-cartoon-styles-33dde907737a" rel="noopener follow" target="_blank"><div class="oa ab fo"><div class="ob ab oc cl cj od"><h2 class="bd jd gy z fp oe fr fs of fu fw jc bi translated">这个人脸生成模型将真实的人脸照片转换成独特的卡通风格</h2><div class="og l"><h3 class="bd b gy z fp oe fr fs of fu fw dk translated">这种人脸生成模型能够将普通的人脸照片转换成独特的风格，如李马尔尼翁的…</h3></div><div class="oh l"><p class="bd b dl z fp oe fr fs of fu fw dk translated">medium.com</p></div></div><div class="oi l"><div class="pk l ok ol om oi on mc nz"/></div></div></a></div><p id="6d6e" class="pw-post-body-paragraph ku kv it kx b ky kz kd la lb lc kg ld mi lf lg lh mj lj lk ll mk ln lo lp lq im bi translated"><a class="ae lr" href="https://github.com/sangwoomo/freezeD?utm_source=catalyzex.com" rel="noopener ugc nofollow" target="_blank">点击此处获取冻结代码</a></p></div><div class="ab cl nf ng hx nh" role="separator"><span class="ni bw bk nj nk nl"/><span class="ni bw bk nj nk nl"/><span class="ni bw bk nj nk"/></div><div class="im in io ip iq"><h1 id="2af0" class="ml mm it bd mn mo nm mq mr ms nn mu mv ki no kj mx kl np km mz ko nq kp nb nc bi translated"><a class="ae lr" href="http://gvv.mpi-inf.mpg.de/projects/NHRR/data/1415.pdf" rel="noopener ugc nofollow" target="_blank">从单一图像中对人类进行神经再现</a>【14】</h1><p id="5104" class="pw-post-body-paragraph ku kv it kx b ky nr kd la lb ns kg ld mi nt lg lh mj nu lk ll mk nv lo lp lq im bi translated">该算法将人体姿态和形状表示为一个参数网格，该网格可以从单幅图像中重建并易于存储。给定一个人的图像，他们能够从另一个输入图像中获得不同姿势或穿着不同衣服的人的合成图像。</p><figure class="lt lu lv lw gt lx"><div class="bz fp l di"><div class="nd ne l"/></div></figure><div class="nw nx gp gr ny nz"><a href="https://medium.com/dataseries/transfer-clothes-between-photos-using-ai-from-a-single-image-4430a291afd7" rel="noopener follow" target="_blank"><div class="oa ab fo"><div class="ob ab oc cl cj od"><h2 class="bd jd gy z fp oe fr fs of fu fw jc bi translated">使用AI在照片之间转移衣服。从单个图像！</h2><div class="og l"><h3 class="bd b gy z fp oe fr fs of fu fw dk translated">这个AI在照片之间转移衣服！该算法将人体姿态和形状表示为一个参数化网格，可以有效地模拟人体姿态和形状</h3></div><div class="oh l"><p class="bd b dl z fp oe fr fs of fu fw dk translated">medium.com</p></div></div><div class="oi l"><div class="pl l ok ol om oi on mc nz"/></div></div></a></div></div><div class="ab cl nf ng hx nh" role="separator"><span class="ni bw bk nj nk nl"/><span class="ni bw bk nj nk nl"/><span class="ni bw bk nj nk"/></div><div class="im in io ip iq"><h1 id="9a95" class="ml mm it bd mn mo nm mq mr ms nn mu mv ki no kj mx kl np km mz ko nq kp nb nc bi translated"><a class="ae lr" href="https://www.catalyzex.com/paper/arxiv:2008.03713?fbclid=IwAR1pQGBhIwO4gW4mVZm1UEtyPLyZInsLZMyq3EoANaWxGO0CZ00Sj3ViM7I" rel="noopener ugc nofollow" target="_blank"> <strong class="ak"> I2L-MeshNet:图像到像素预测网络，用于从单个RGB图像进行精确的3D人体姿态和网格估计</strong></a><strong class="ak"/>【15】</h1><p id="678e" class="pw-post-body-paragraph ku kv it kx b ky nr kd la lb ns kg ld mi nt lg lh mj nu lk ll mk nv lo lp lq im bi translated">他们的目标是提出一种新的技术，用于从单个RGB图像中估计3D人体姿态和网格。他们称之为I2L-MeshNet。其中I2L代表图像到像素。就像一个体素，体积+像素，是三维空间中的一个量子化的单元，他们把lixel，一条线，像素，定义为一维空间中的一个量子化的单元。他们的方法优于以前的方法，并且代码是公开的！</p><figure class="lt lu lv lw gt lx"><div class="bz fp l di"><div class="nd ne l"/></div></figure><div class="nw nx gp gr ny nz"><a href="https://medium.com/dataseries/accurate-3d-human-pose-and-mesh-estimation-from-a-single-rgb-image-with-code-publicly-avaibable-b7cc995bcf2a" rel="noopener follow" target="_blank"><div class="oa ab fo"><div class="ob ab oc cl cj od"><h2 class="bd jd gy z fp oe fr fs of fu fw jc bi translated">从一个单一的RGB图像精确的三维人体姿态和网格估计！代码是公开的！</h2><div class="og l"><h3 class="bd b gy z fp oe fr fs of fu fw dk translated">随着ECCV会议即将召开，我们有大量与计算机视觉相关的惊人论文问世。这里有一个…</h3></div><div class="oh l"><p class="bd b dl z fp oe fr fs of fu fw dk translated">medium.com</p></div></div><div class="oi l"><div class="pm l ok ol om oi on mc nz"/></div></div></a></div><p id="b878" class="pw-post-body-paragraph ku kv it kx b ky kz kd la lb lc kg ld mi lf lg lh mj lj lk ll mk ln lo lp lq im bi translated"><a class="ae lr" href="https://github.com/mks0601/I2L-MeshNet_RELEASE" rel="noopener ugc nofollow" target="_blank">点击此处获取I2L-MeshNet代码</a></p></div><div class="ab cl nf ng hx nh" role="separator"><span class="ni bw bk nj nk nl"/><span class="ni bw bk nj nk nl"/><span class="ni bw bk nj nk"/></div><div class="im in io ip iq"><h1 id="86af" class="ml mm it bd mn mo nm mq mr ms nn mu mv ki no kj mx kl np km mz ko nq kp nb nc bi translated"><a class="ae lr" href="https://arxiv.org/pdf/2004.02857.pdf" rel="noopener ugc nofollow" target="_blank">导航图之外:连续环境中的视觉和语言导航</a>【16】</h1><p id="721a" class="pw-post-body-paragraph ku kv it kx b ky nr kd la lb ns kg ld mi nt lg lh mj nu lk ll mk nv lo lp lq im bi translated">语言导航是一个广泛研究的领域，也是一个非常复杂的领域。事实上，对于一个人来说，穿过一栋房子去拿你放在床头柜上的咖啡似乎很简单。但对于代理来说，这是一个完全不同的故事，它是一个自主的<a class="ae lr" href="http://becominghuman.ai/" rel="noopener ugc nofollow" target="_blank"> AI </a>驱动的系统，使用<a class="ae lr" href="https://becominghuman.ai/cheat-sheets-for-ai-neural-networks-machine-learning-deep-learning-big-data-678c51b4b463" rel="noopener ugc nofollow" target="_blank">深度学习</a>来执行任务。</p><figure class="lt lu lv lw gt lx"><div class="bz fp l di"><div class="nd ne l"/></div></figure><div class="nw nx gp gr ny nz"><a href="https://becominghuman.ai/language-guided-navigation-in-a-3d-environment-e3cf4102fb89" rel="noopener  ugc nofollow" target="_blank"><div class="oa ab fo"><div class="ob ab oc cl cj od"><h2 class="bd jd gy z fp oe fr fs of fu fw jc bi translated">3D环境中的语言导航</h2><div class="og l"><h3 class="bd b gy z fp oe fr fs of fu fw dk translated">脸书人工智能研究所的ECCV2020论文(代码已公开！)</h3></div><div class="oh l"><p class="bd b dl z fp oe fr fs of fu fw dk translated">becominghuman.ai</p></div></div><div class="oi l"><div class="pn l ok ol om oi on mc nz"/></div></div></a></div><p id="390c" class="pw-post-body-paragraph ku kv it kx b ky kz kd la lb lc kg ld mi lf lg lh mj lj lk ll mk ln lo lp lq im bi translated"><a class="ae lr" href="https://github.com/jacobkrantz/VLN-CE" rel="noopener ugc nofollow" target="_blank">点击此处获取VLN-CE代码</a></p></div><div class="ab cl nf ng hx nh" role="separator"><span class="ni bw bk nj nk nl"/><span class="ni bw bk nj nk nl"/><span class="ni bw bk nj nk"/></div><div class="im in io ip iq"><h1 id="d89c" class="ml mm it bd mn mo nm mq mr ms nn mu mv ki no kj mx kl np km mz ko nq kp nb nc bi translated"><a class="ae lr" href="https://arxiv.org/pdf/2003.12039.pdf" rel="noopener ugc nofollow" target="_blank"> RAFT:用于光流的循环全对场变换</a>【17】</h1><p id="351d" class="pw-post-body-paragraph ku kv it kx b ky nr kd la lb ns kg ld mi nt lg lh mj nu lk ll mk nv lo lp lq im bi translated">普林斯顿团队获得ECCV 2020年最佳论文奖。他们为光流开发了一种新的端到端可训练模型。他们的方法在多个数据集上击败了最先进的架构的准确性，并且更加高效。他们甚至在Github上向所有人开放代码！</p><figure class="lt lu lv lw gt lx"><div class="bz fp l di"><div class="nd ne l"/></div></figure><div class="nw nx gp gr ny nz"><a href="https://medium.com/towards-artificial-intelligence/eccv-2020-best-paper-award-a-new-architecture-for-optical-flow-3298c8a40dc7" rel="noopener follow" target="_blank"><div class="oa ab fo"><div class="ob ab oc cl cj od"><h2 class="bd jd gy z fp oe fr fs of fu fw jc bi translated">ECCV 2020最佳论文奖|光流的新架构</h2><div class="og l"><h3 class="bd b gy z fp oe fr fs of fu fw dk translated">普林斯顿团队获得ECCV 2020年最佳论文奖。他们为光流开发了一个新的端到端可训练模型…</h3></div><div class="oh l"><p class="bd b dl z fp oe fr fs of fu fw dk translated">medium.com</p></div></div><div class="oi l"><div class="po l ok ol om oi on mc nz"/></div></div></a></div><p id="f111" class="pw-post-body-paragraph ku kv it kx b ky kz kd la lb lc kg ld mi lf lg lh mj lj lk ll mk ln lo lp lq im bi translated"><a class="ae lr" href="https://github.com/princeton-vl/RAFT" rel="noopener ugc nofollow" target="_blank">点击此处获取筏码</a></p></div><div class="ab cl nf ng hx nh" role="separator"><span class="ni bw bk nj nk nl"/><span class="ni bw bk nj nk nl"/><span class="ni bw bk nj nk"/></div><div class="im in io ip iq"><h1 id="961a" class="ml mm it bd mn mo nm mq mr ms nn mu mv ki no kj mx kl np km mz ko nq kp nb nc bi translated"><a class="ae lr" href="https://research.cs.cornell.edu/crowdplenoptic/" rel="noopener ugc nofollow" target="_blank">众数采样全光照功能</a>【18】</h1><p id="2787" class="pw-post-body-paragraph ku kv it kx b ky nr kd la lb ns kg ld mi nt lg lh mj nu lk ll mk nv lo lp lq im bi translated">使用游客从互联网上公开的照片，他们能够重建一个场景的多个视点，保存真实的阴影和照明！这是真实感场景渲染技术的一个巨大进步，它们的效果简直令人惊叹。</p><figure class="lt lu lv lw gt lx"><div class="bz fp l di"><div class="nd ne l"/></div></figure><div class="nw nx gp gr ny nz"><a href="https://medium.com/towards-artificial-intelligence/reconstruct-photorealistic-scenes-from-tourists-public-photos-on-the-internet-bb9ad39c96f3" rel="noopener follow" target="_blank"><div class="oa ab fo"><div class="ob ab oc cl cj od"><h2 class="bd jd gy z fp oe fr fs of fu fw jc bi translated">从游客在网上公开的照片中重建出真实感场景！</h2><div class="og l"><h3 class="bd b gy z fp oe fr fs of fu fw dk translated">使用游客从互联网上公开的照片，他们能够重建一个场景的观点保存…</h3></div><div class="oh l"><p class="bd b dl z fp oe fr fs of fu fw dk translated">medium.com</p></div></div><div class="oi l"><div class="pp l ok ol om oi on mc nz"/></div></div></a></div><p id="68e1" class="pw-post-body-paragraph ku kv it kx b ky kz kd la lb lc kg ld mi lf lg lh mj lj lk ll mk ln lo lp lq im bi translated"><a class="ae lr" href="https://github.com/zhengqili/Crowdsampling-the-Plenoptic-Function" rel="noopener ugc nofollow" target="_blank">点击这里获取众数采样代码</a></p></div><div class="ab cl nf ng hx nh" role="separator"><span class="ni bw bk nj nk nl"/><span class="ni bw bk nj nk nl"/><span class="ni bw bk nj nk"/></div><div class="im in io ip iq"><h1 id="a430" class="ml mm it bd mn mo nm mq mr ms nn mu mv ki no kj mx kl np km mz ko nq kp nb nc bi translated"><a class="ae lr" href="https://arxiv.org/pdf/2009.07047.pdf" rel="noopener ugc nofollow" target="_blank">通过深层潜在空间转换修复旧照片</a>【19】</h1><p id="adb4" class="pw-post-body-paragraph ku kv it kx b ky nr kd la lb ns kg ld mi nt lg lh mj nu lk ll mk nv lo lp lq im bi translated">想象一下，你有你祖母18岁时的旧的，折叠的，甚至撕破的高清照片，没有任何瑕疵。这被称为旧照片恢复，这篇论文刚刚开辟了一条全新的途径，使用深度学习方法来解决这个问题。</p><figure class="lt lu lv lw gt lx"><div class="bz fp l di"><div class="nd ne l"/></div></figure><div class="nw nx gp gr ny nz"><a href="https://medium.com/towards-artificial-intelligence/old-photo-restoration-using-deep-learning-47d4ab1bdc4d" rel="noopener follow" target="_blank"><div class="oa ab fo"><div class="ob ab oc cl cj od"><h2 class="bd jd gy z fp oe fr fs of fu fw jc bi translated">使用深度学习的旧照片恢复</h2><div class="og l"><h3 class="bd b gy z fp oe fr fs of fu fw dk translated">想象一下，拥有你祖母18岁时的旧的、折叠的、甚至撕破的高清照片…</h3></div><div class="oh l"><p class="bd b dl z fp oe fr fs of fu fw dk translated">medium.com</p></div></div><div class="oi l"><div class="pq l ok ol om oi on mc nz"/></div></div></a></div><p id="9596" class="pw-post-body-paragraph ku kv it kx b ky kz kd la lb lc kg ld mi lf lg lh mj lj lk ll mk ln lo lp lq im bi translated"><a class="ae lr" href="https://github.com/microsoft/Bringing-Old-Photos-Back-to-Life?utm_source=catalyzex.com" rel="noopener ugc nofollow" target="_blank">点击此处获取旧照片复原码</a></p></div><div class="ab cl nf ng hx nh" role="separator"><span class="ni bw bk nj nk nl"/><span class="ni bw bk nj nk nl"/><span class="ni bw bk nj nk"/></div><div class="im in io ip iq"><h1 id="0dad" class="ml mm it bd mn mo nm mq mr ms nn mu mv ki no kj mx kl np km mz ko nq kp nb nc bi translated"><a class="ae lr" href="https://www.nature.com/articles/s42256-020-00237-3.epdf?sharing_token=xHsXBg2SoR9l8XdbXeGSqtRgN0jAjWel9jnR3ZoTv0PbS_e49wmlSXvnXIRQ7wyir5MOFK7XBfQ8sxCtVjc7zD1lWeQB5kHoRr4BAmDEU0_1-UN5qHD5nXYVQyq5BrRV_tFa3_FZjs4LBHt-yebsG4eQcOnNsG4BenK3CmBRFLk%3D" rel="noopener ugc nofollow" target="_blank">启用可审计自主性的神经回路策略</a>【20】</h1><p id="8896" class="pw-post-body-paragraph ku kv it kx b ky nr kd la lb ns kg ld mi nt lg lh mj nu lk ll mk nv lo lp lq im bi translated">来自澳大利亚IST大学和麻省理工学院的研究人员使用一种新的人工智能系统成功训练了一辆自动驾驶汽车，该系统基于微小动物的大脑，如蛲虫。与流行的深度神经网络(如Inceptions、Resnets或VGG)所需的数百万个神经元相比，他们只需要几个神经元就能控制自动驾驶汽车。他们的网络能够只用75 000个参数完全控制一辆汽车，由19个控制神经元组成，而不是数百万个！</p><figure class="lt lu lv lw gt lx"><div class="bz fp l di"><div class="nd ne l"/></div></figure><div class="nw nx gp gr ny nz"><a href="https://medium.com/towards-artificial-intelligence/a-new-brain-inspired-intelligent-system-drives-a-car-using-only-19-control-neurons-1ed127107db9" rel="noopener follow" target="_blank"><div class="oa ab fo"><div class="ob ab oc cl cj od"><h2 class="bd jd gy z fp oe fr fs of fu fw jc bi translated">一个新的大脑启发的智能系统只用19个控制神经元来驾驶汽车！</h2><div class="og l"><h3 class="bd b gy z fp oe fr fs of fu fw dk translated">模仿线虫的神经系统有效地处理信息，这种新的智能系统更强大…</h3></div><div class="oh l"><p class="bd b dl z fp oe fr fs of fu fw dk translated">medium.com</p></div></div><div class="oi l"><div class="pr l ok ol om oi on mc nz"/></div></div></a></div><p id="5d5b" class="pw-post-body-paragraph ku kv it kx b ky kz kd la lb lc kg ld mi lf lg lh mj lj lk ll mk ln lo lp lq im bi translated"><a class="ae lr" href="https://github.com/mlech26l/keras-ncp" rel="noopener ugc nofollow" target="_blank">点击此处获取NCP代码</a></p></div><div class="ab cl nf ng hx nh" role="separator"><span class="ni bw bk nj nk nl"/><span class="ni bw bk nj nk nl"/><span class="ni bw bk nj nk"/></div><div class="im in io ip iq"><h1 id="22df" class="ml mm it bd mn mo nm mq mr ms nn mu mv ki no kj mx kl np km mz ko nq kp nb nc bi translated"><a class="ae lr" href="https://arxiv.org/pdf/2003.09764.pdf" rel="noopener ugc nofollow" target="_blank">寿命年龄转换合成</a>【21】</h1><p id="bd68" class="pw-post-body-paragraph ku kv it kx b ky nr kd la lb ns kg ld mi nt lg lh mj nu lk ll mk nv lo lp lq im bi translated">Adobe Research的一组研究人员开发了一种新的技术，仅基于一张个人照片进行年龄转换合成。它可以从你发给它的任何图片中生成寿命图片。</p><figure class="lt lu lv lw gt lx"><div class="bz fp l di"><div class="nd ne l"/></div></figure><div class="nw nx gp gr ny nz"><a href="https://medium.com/towards-artificial-intelligence/generate-younger-older-versions-of-yourself-1a87f970f3da" rel="noopener follow" target="_blank"><div class="oa ab fo"><div class="ob ab oc cl cj od"><h2 class="bd jd gy z fp oe fr fs of fu fw jc bi translated">生成更年轻和更老版本的自己！</h2><div class="og l"><h3 class="bd b gy z fp oe fr fs of fu fw dk translated">给定一张你在任何年龄的照片，这个模型可以生成一个现实的、相当精确的…</h3></div><div class="oh l"><p class="bd b dl z fp oe fr fs of fu fw dk translated">medium.com</p></div></div><div class="oi l"><div class="ps l ok ol om oi on mc nz"/></div></div></a></div><p id="4c94" class="pw-post-body-paragraph ku kv it kx b ky kz kd la lb lc kg ld mi lf lg lh mj lj lk ll mk ln lo lp lq im bi translated"><a class="ae lr" href="https://github.com/royorel/Lifespan_Age_Transformation_Synthesis" rel="noopener ugc nofollow" target="_blank">点击此处获取寿命年龄转换合成代码</a></p></div><div class="ab cl nf ng hx nh" role="separator"><span class="ni bw bk nj nk nl"/><span class="ni bw bk nj nk nl"/><span class="ni bw bk nj nk"/></div><div class="im in io ip iq"><h1 id="2565" class="ml mm it bd mn mo nm mq mr ms nn mu mv ki no kj mx kl np km mz ko nq kp nb nc bi translated"><a class="ae lr" href="https://github.com/jantic/DeOldify" rel="noopener ugc nofollow" target="_blank">解除锁定</a>【22】</h1><p id="371e" class="pw-post-body-paragraph ku kv it kx b ky nr kd la lb ns kg ld mi nt lg lh mj nu lk ll mk nv lo lp lq im bi translated">DeOldify是一种彩色化和恢复旧黑白图像甚至电影胶片的技术。它是由一个人Jason Antic开发并更新的。这是现在最先进的黑白图像彩色化方法，一切都是开源的，但是我们一会儿会回到这个话题。</p><figure class="lt lu lv lw gt lx"><div class="bz fp l di"><div class="nd ne l"/></div></figure><div class="nw nx gp gr ny nz"><a href="https://medium.com/towards-artificial-intelligence/this-ai-can-colorize-your-black-white-photos-with-full-photorealistic-renders-deoldify-bf1eed5cb02a" rel="noopener follow" target="_blank"><div class="oa ab fo"><div class="ob ab oc cl cj od"><h2 class="bd jd gy z fp oe fr fs of fu fw jc bi translated">这个人工智能可以为你的黑白照片着色，呈现出真实的照片效果！(解密)</h2><div class="og l"><h3 class="bd b gy z fp oe fr fs of fu fw dk translated">这种方法被称为DeOldify，几乎适用于任何图片。如果你不相信我，你甚至可以尝试一下…</h3></div><div class="oh l"><p class="bd b dl z fp oe fr fs of fu fw dk translated">medium.com</p></div></div><div class="oi l"><div class="pt l ok ol om oi on mc nz"/></div></div></a></div><p id="7e55" class="pw-post-body-paragraph ku kv it kx b ky kz kd la lb lc kg ld mi lf lg lh mj lj lk ll mk ln lo lp lq im bi translated"><a class="ae lr" href="https://github.com/jantic/DeOldify" rel="noopener ugc nofollow" target="_blank">点击此处获取解除代码</a></p></div><div class="ab cl nf ng hx nh" role="separator"><span class="ni bw bk nj nk nl"/><span class="ni bw bk nj nk nl"/><span class="ni bw bk nj nk"/></div><div class="im in io ip iq"><h1 id="86b4" class="ml mm it bd mn mo nm mq mr ms nn mu mv ki no kj mx kl np km mz ko nq kp nb nc bi translated"><a class="ae lr" href="https://arxiv.org/pdf/2011.00597.pdf" rel="noopener ugc nofollow" target="_blank"> COOT:用于视频-文本表示学习的合作分层转换器</a>【23】</h1><p id="8513" class="pw-post-body-paragraph ku kv it kx b ky nr kd la lb ns kg ld mi nt lg lh mj nu lk ll mk nv lo lp lq im bi translated">顾名思义，它使用转换器为视频的每个序列生成准确的文本描述，将视频和视频的一般描述作为输入。</p><figure class="lt lu lv lw gt lx"><div class="bz fp l di"><div class="nd ne l"/></div></figure><div class="nw nx gp gr ny nz"><a href="https://medium.com/towards-artificial-intelligence/video-to-text-description-using-deep-learning-and-transformers-coot-e05b8d0db110" rel="noopener follow" target="_blank"><div class="oa ab fo"><div class="ob ab oc cl cj od"><h2 class="bd jd gy z fp oe fr fs of fu fw jc bi translated">使用深度学习和变形金刚的视频到文本描述</h2><div class="og l"><h3 class="bd b gy z fp oe fr fs of fu fw dk translated">在NeurIPS2020会议上发布的这一新模型使用变形金刚来生成准确的文本描述…</h3></div><div class="oh l"><p class="bd b dl z fp oe fr fs of fu fw dk translated">medium.com</p></div></div><div class="oi l"><div class="pu l ok ol om oi on mc nz"/></div></div></a></div><p id="8db9" class="pw-post-body-paragraph ku kv it kx b ky kz kd la lb lc kg ld mi lf lg lh mj lj lk ll mk ln lo lp lq im bi translated"><a class="ae lr" href="https://github.com/gingsi/coot-videotext" rel="noopener ugc nofollow" target="_blank">点击此处查看首席运营官代码</a></p></div><div class="ab cl nf ng hx nh" role="separator"><span class="ni bw bk nj nk nl"/><span class="ni bw bk nj nk nl"/><span class="ni bw bk nj nk"/></div><div class="im in io ip iq"><h1 id="78f4" class="ml mm it bd mn mo nm mq mr ms nn mu mv ki no kj mx kl np km mz ko nq kp nb nc bi translated"><a class="ae lr" href="https://arxiv.org/abs/2011.08114" rel="noopener ugc nofollow" target="_blank">风格化的神经绘画</a>【24】</h1><p id="d713" class="pw-post-body-paragraph ku kv it kx b ky nr kd la lb ns kg ld mi nt lg lh mj nu lk ll mk nv lo lp lq im bi translated">这种图像到绘画的翻译方法使用新颖的方法模拟多种风格的真实画家，不涉及任何GAN架构，不同于所有当前最先进的方法！</p><figure class="lt lu lv lw gt lx"><div class="bz fp l di"><div class="nd ne l"/></div></figure><div class="nw nx gp gr ny nz"><a href="https://medium.com/towards-artificial-intelligence/image-to-painting-translation-with-style-transfer-508618596409" rel="noopener follow" target="_blank"><div class="oa ab fo"><div class="ob ab oc cl cj od"><h2 class="bd jd gy z fp oe fr fs of fu fw jc bi translated">风格转换下的图像转绘画翻译</h2><div class="og l"><h3 class="bd b gy z fp oe fr fs of fu fw dk translated">这种图像到绘画的翻译方法使用一种新颖的方法来模拟多种风格的真实画家</h3></div><div class="oh l"><p class="bd b dl z fp oe fr fs of fu fw dk translated">medium.com</p></div></div><div class="oi l"><div class="pv l ok ol om oi on mc nz"/></div></div></a></div><p id="f1e5" class="pw-post-body-paragraph ku kv it kx b ky kz kd la lb lc kg ld mi lf lg lh mj lj lk ll mk ln lo lp lq im bi translated"><a class="ae lr" href="https://github.com/jiupinjia/stylized-neural-painting" rel="noopener ugc nofollow" target="_blank">点击这里查看风格化神经绘画代码</a></p></div><div class="ab cl nf ng hx nh" role="separator"><span class="ni bw bk nj nk nl"/><span class="ni bw bk nj nk nl"/><span class="ni bw bk nj nk"/></div><div class="im in io ip iq"><h1 id="ec06" class="ml mm it bd mn mo nm mq mr ms nn mu mv ki no kj mx kl np km mz ko nq kp nb nc bi translated">实时人像抠图真的需要绿色屏幕吗？【25】</h1><p id="d21b" class="pw-post-body-paragraph ku kv it kx b ky nr kd la lb ns kg ld mi nt lg lh mj nu lk ll mk nv lo lp lq im bi translated">人体抠图是一项非常有趣的任务，目标是找到照片中的任何人，并从照片中移除背景。由于任务的复杂性，这真的很难实现，必须找到具有完美轮廓的人。在这篇文章中，我回顾了多年来使用的最佳技术和2020年11月29日发表的一种新颖的方法。许多技术正在使用基本的计算机视觉算法来完成这项任务，例如GrabCut算法，它速度极快，但不是很精确。</p><figure class="lt lu lv lw gt lx"><div class="bz fp l di"><div class="nd ne l"/></div></figure><div class="nw nx gp gr ny nz"><a href="https://medium.com/datadriveninvestor/high-quality-background-removal-without-green-screens-8e61c69de63" rel="noopener follow" target="_blank"><div class="oa ab fo"><div class="ob ab oc cl cj od"><h2 class="bd jd gy z fp oe fr fs of fu fw jc bi translated">没有绿屏的高质量背景消除</h2><div class="og l"><h3 class="bd b gy z fp oe fr fs of fu fw dk translated">这种新的背景去除技术可以从单个输入图像中提取一个人，而不需要绿色的…</h3></div><div class="oh l"><p class="bd b dl z fp oe fr fs of fu fw dk translated">medium.com</p></div></div><div class="oi l"><div class="pw l ok ol om oi on mc nz"/></div></div></a></div><p id="a3c9" class="pw-post-body-paragraph ku kv it kx b ky kz kd la lb lc kg ld mi lf lg lh mj lj lk ll mk ln lo lp lq im bi translated"><a class="ae lr" href="https://github.com/ZHKKKe/MODNet" rel="noopener ugc nofollow" target="_blank">点击此处获取MODNet代码</a></p></div><div class="ab cl nf ng hx nh" role="separator"><span class="ni bw bk nj nk nl"/><span class="ni bw bk nj nk nl"/><span class="ni bw bk nj nk"/></div><div class="im in io ip iq"><h1 id="575a" class="ml mm it bd mn mo nm mq mr ms nn mu mv ki no kj mx kl np km mz ko nq kp nb nc bi translated"><a class="ae lr" href="https://arxiv.org/abs/2006.06676" rel="noopener ugc nofollow" target="_blank"> ADA:用有限数据训练生成性对抗网络</a>【26】</h1><p id="f236" class="pw-post-body-paragraph ku kv it kx b ky nr kd la lb ns kg ld mi nt lg lh mj nu lk ll mk nv lo lp lq im bi translated">通过NVIDIA开发的这种新的训练方法，你可以用十分之一的图像训练出一个强大的生成模型！使得许多无法访问如此多图像的应用成为可能！</p><figure class="lt lu lv lw gt lx"><div class="bz fp l di"><div class="nd ne l"/></div></figure><div class="nw nx gp gr ny nz"><a href="https://medium.com/towards-artificial-intelligence/gan-training-breakthrough-for-limited-data-applications-new-nvidia-program-nvidia-research-3652c4c172e6" rel="noopener follow" target="_blank"><div class="oa ab fo"><div class="ob ab oc cl cj od"><h2 class="bd jd gy z fp oe fr fs of fu fw jc bi translated">有限数据应用的GAN培训突破&amp;新NVIDIA计划！英伟达研究</h2><div class="og l"><h3 class="bd b gy z fp oe fr fs of fu fw dk translated">使用NVIDIA开发的这种新的训练方法，您可以用十分之一的时间训练出强大的生成模型…</h3></div><div class="oh l"><p class="bd b dl z fp oe fr fs of fu fw dk translated">medium.com</p></div></div><div class="oi l"><div class="px l ok ol om oi on mc nz"/></div></div></a></div><p id="bfa8" class="pw-post-body-paragraph ku kv it kx b ky kz kd la lb lc kg ld mi lf lg lh mj lj lk ll mk ln lo lp lq im bi translated"><a class="ae lr" href="https://github.com/NVlabs/stylegan2-ada" rel="noopener ugc nofollow" target="_blank">点击此处获取ADA代码</a></p></div><div class="ab cl nf ng hx nh" role="separator"><span class="ni bw bk nj nk nl"/><span class="ni bw bk nj nk nl"/><span class="ni bw bk nj nk"/></div><div class="im in io ip iq"><h1 id="95a5" class="ml mm it bd mn mo nm mq mr ms nn mu mv ki no kj mx kl np km mz ko nq kp nb nc bi translated"><a class="ae lr" href="https://agupubs.onlinelibrary.wiley.com/doi/10.1029/2020MS002109" rel="noopener ugc nofollow" target="_blank">在立方体球体上使用深度卷积神经网络改进数据驱动的全球天气预测</a>【27】</h1><p id="f732" class="pw-post-body-paragraph ku kv it kx b ky nr kd la lb ns kg ld mi nt lg lh mj nu lk ll mk nv lo lp lq im bi translated">目前传统的天气预报方法使用我们称之为“数值天气预报”的模型。它使用大气和海洋的数学模型，根据当前条件预测天气。它于20世纪20年代首次推出，并于20世纪50年代使用计算机模拟产生了现实的结果。这些数学模型用于预测短期和长期预测。但它的计算量很大，并且不能像深度神经网络那样基于大量数据进行预测。这是它如此有前途的部分原因。这些当前的数值天气预测模型已经使用机器学习作为后处理工具来改进预测。天气预报正受到机器学习研究人员越来越多的关注，已经产生了令人鼓舞的结果。</p><figure class="lt lu lv lw gt lx"><div class="bz fp l di"><div class="nd ne l"/></div></figure><div class="nw nx gp gr ny nz"><a href="https://medium.com/towards-artificial-intelligence/ai-is-predicting-faster-and-more-accurate-weather-forecasts-5d99a1d9c4f" rel="noopener follow" target="_blank"><div class="oa ab fo"><div class="ob ab oc cl cj od"><h2 class="bd jd gy z fp oe fr fs of fu fw jc bi translated">人工智能正在预测更快、更准确的天气预报</h2><div class="og l"><h3 class="bd b gy z fp oe fr fs of fu fw dk translated">如果我们可以通过分析过去40年的天气模式，用人工智能取代这一切，那会怎么样</h3></div><div class="oh l"><p class="bd b dl z fp oe fr fs of fu fw dk translated">medium.com</p></div></div><div class="oi l"><div class="py l ok ol om oi on mc nz"/></div></div></a></div><p id="bf6b" class="pw-post-body-paragraph ku kv it kx b ky kz kd la lb lc kg ld mi lf lg lh mj lj lk ll mk ln lo lp lq im bi translated"><a class="ae lr" href="https://github.com/jweyn/DLWP-CS" rel="noopener ugc nofollow" target="_blank">点击此处获取天气预报代码</a></p></div><div class="ab cl nf ng hx nh" role="separator"><span class="ni bw bk nj nk nl"/><span class="ni bw bk nj nk nl"/><span class="ni bw bk nj nk"/></div><div class="im in io ip iq"><h1 id="edc3" class="ml mm it bd mn mo nm mq mr ms nn mu mv ki no kj mx kl np km mz ko nq kp nb nc bi translated"><a class="ae lr" href="https://people.eecs.berkeley.edu/~pratul/nerv/" rel="noopener ugc nofollow" target="_blank">神经:用于重新照明和视图合成的神经反射和可见度场<br/></a>【28】</h1><p id="3805" class="pw-post-body-paragraph ku kv it kx b ky nr kd la lb ns kg ld mi nt lg lh mj nu lk ll mk nv lo lp lq im bi translated">这种新方法能够生成完整的三维场景，并具有决定场景照明的能力。与以前的方法相比，所有这些只需要非常有限的计算成本和惊人的结果。</p><figure class="lt lu lv lw gt lx"><div class="bz fp l di"><div class="nd ne l"/></div></figure><div class="nw nx gp gr ny nz"><a href="https://medium.com/what-is-artificial-intelligence/generate-a-complete-3d-scene-under-arbitrary-lighting-conditions-from-a-set-of-input-images-9d2fbce63243" rel="noopener follow" target="_blank"><div class="oa ab fo"><div class="ob ab oc cl cj od"><h2 class="bd jd gy z fp oe fr fs of fu fw jc bi translated">从一组输入图像生成任意光照条件下的完整3D场景</h2><div class="og l"><h3 class="bd b gy z fp oe fr fs of fu fw dk translated">这种新方法能够生成一个完整的三维场景，并且能够决定场景的光照</h3></div><div class="oh l"><p class="bd b dl z fp oe fr fs of fu fw dk translated">medium.com</p></div></div><div class="oi l"><div class="pz l ok ol om oi on mc nz"/></div></div></a></div><p id="fbbc" class="pw-post-body-paragraph ku kv it kx b ky kz kd la lb lc kg ld mi lf lg lh mj lj lk ll mk ln lo lp lq im bi translated"><a class="ae lr" href="https://people.eecs.berkeley.edu/~pratul/nerv/" rel="noopener ugc nofollow" target="_blank">点击此处获取神经代码<em class="kw">(即将推出)</em> </a></p></div><div class="ab cl nf ng hx nh" role="separator"><span class="ni bw bk nj nk nl"/><span class="ni bw bk nj nk nl"/><span class="ni bw bk nj nk"/></div><div class="im in io ip iq"><h1 id="12f6" class="ml mm it bd mn mo nm mq mr ms nn mu mv ki no kj mx kl np km mz ko nq kp nb nc bi translated">结论</h1><p id="a97a" class="pw-post-body-paragraph ku kv it kx b ky nr kd la lb ns kg ld mi nt lg lh mj nu lk ll mk nv lo lp lq im bi translated">正如你所看到的，这是人工智能极具洞察力的一年，我非常期待看到2021年将会发生什么！我一定会报道最令人兴奋和有趣的报纸，如果你能参加这次冒险，我会很高兴的！如果你喜欢我的工作，并想了解人工智能的最新动态，你绝对应该关注我的其他社交媒体账户(<a class="ae lr" href="https://www.linkedin.com/in/whats-ai/" rel="noopener ugc nofollow" target="_blank"> LinkedIn </a>、<a class="ae lr" href="https://twitter.com/Whats_AI" rel="noopener ugc nofollow" target="_blank"> Twitter </a>)，并订阅我的每周人工智能<a class="ae lr" href="http://eepurl.com/huGLT5" rel="noopener ugc nofollow" target="_blank"> <strong class="kx jd">简讯</strong> </a>！</p><h2 id="cda9" class="or mm it bd mn os ot dn mr ou ov dp mv mi ow ox mx mj oy oz mz mk pa pb nb iz bi translated">支持我:</h2><ul class=""><li id="4d01" class="qa qb it kx b ky nr lb ns mi qc mj qd mk qe lq qf qg qh qi bi translated">支持我的最好方式是在<a class="ae lr" href="https://medium.com/@whats-ai" rel="noopener"> <strong class="kx jd">媒体</strong> </a> <strong class="kx jd"> </strong>上关注我，或者如果你喜欢视频格式，在<a class="ae lr" href="https://www.youtube.com/channel/UCUzGQrN-lyyc0BWTYoJM_Sg" rel="noopener ugc nofollow" target="_blank"><strong class="kx jd">YouTube</strong></a><strong class="kx jd"/>上订阅我的频道<strong class="kx jd"> </strong>。</li><li id="f325" class="qa qb it kx b ky qj lb qk mi ql mj qm mk qn lq qf qg qh qi bi translated">支持我在<a class="ae lr" href="https://www.patreon.com/whatsai" rel="noopener ugc nofollow" target="_blank"> <strong class="kx jd">上的工作</strong></a></li><li id="fd81" class="qa qb it kx b ky qj lb qk mi ql mj qm mk qn lq qf qg qh qi bi translated">加入我们的<a class="ae lr" href="https://discord.gg/learnaitogether" rel="noopener ugc nofollow" target="_blank"> <strong class="kx jd"> Discord社区:</strong> <strong class="kx jd">一起学习AI</strong></a>和<em class="kw">分享你的项目、论文、最佳课程、寻找Kaggle队友等等！</em></li></ul><p id="7ab3" class="pw-post-body-paragraph ku kv it kx b ky kz kd la lb lc kg ld mi lf lg lh mj lj lk ll mk ln lo lp lq im bi translated"><a class="ae lr" href="https://github.com/louisfb01/Best_AI_paper_2020" rel="noopener ugc nofollow" target="_blank"> <strong class="kx jd"> <em class="kw">访问GitHub库中的完整列表</em> </strong> </a></p><p id="9218" class="pw-post-body-paragraph ku kv it kx b ky kz kd la lb lc kg ld mi lf lg lh mj lj lk ll mk ln lo lp lq im bi translated"><strong class="kx jd"> <em class="kw">在</em></strong><a class="ae lr" href="https://twitter.com/Whats_AI" rel="noopener ugc nofollow" target="_blank"><strong class="kx jd"><em class="kw">Twitter(@ Whats _ AI)</em></strong></a><strong class="kx jd"><em class="kw">或</em></strong><a class="ae lr" href="https://www.linkedin.com/in/whats-ai/" rel="noopener ugc nofollow" target="_blank"><strong class="kx jd"><em class="kw">LinkedIn(Louis(What ' s AI)</em></strong></a><strong class="kx jd"><em class="kw">如果分享文章！</em>T55】</strong></p></div><div class="ab cl nf ng hx nh" role="separator"><span class="ni bw bk nj nk nl"/><span class="ni bw bk nj nk nl"/><span class="ni bw bk nj nk"/></div><div class="im in io ip iq"><h1 id="385a" class="ml mm it bd mn mo nm mq mr ms nn mu mv ki no kj mx kl np km mz ko nq kp nb nc bi translated">如果你对人工智能研究感兴趣，这里有另一篇很棒的文章给你:</h1><div class="nw nx gp gr ny nz"><a href="https://whats-ai.medium.com/top-10-computer-vision-papers-2020-aa606985f688" rel="noopener follow" target="_blank"><div class="oa ab fo"><div class="ob ab oc cl cj od"><h2 class="bd jd gy z fp oe fr fs of fu fw jc bi translated">2020年十大计算机视觉论文</h2><div class="og l"><h3 class="bd b gy z fp oe fr fs of fu fw dk translated">2020年十大计算机视觉论文，包括视频演示、文章、代码和论文参考。</h3></div><div class="oh l"><p class="bd b dl z fp oe fr fs of fu fw dk translated">whats-ai.medium.com</p></div></div><div class="oi l"><div class="qo l ok ol om oi on mc nz"/></div></div></a></div></div><div class="ab cl nf ng hx nh" role="separator"><span class="ni bw bk nj nk nl"/><span class="ni bw bk nj nk nl"/><span class="ni bw bk nj nk"/></div><div class="im in io ip iq"><h1 id="2ce7" class="ml mm it bd mn mo nm mq mr ms nn mu mv ki no kj mx kl np km mz ko nq kp nb nc bi translated">论文参考</h1><p id="fd3c" class="pw-post-body-paragraph ku kv it kx b ky nr kd la lb ns kg ld mi nt lg lh mj nu lk ll mk nv lo lp lq im bi translated">[1] A. Bochkovskiy，C.-Y. Wang，和H.-Y. M .廖，Yolov4:物体探测的最佳速度和精度，2020 .arXiv:2004.10934 [cs。简历】。</p><p id="d50e" class="pw-post-body-paragraph ku kv it kx b ky kz kd la lb lc kg ld mi lf lg lh mj lj lk ll mk ln lo lp lq im bi translated">[2]陈世友、苏文伟、高、夏、傅，“深度人脸绘制:从草图深度生成人脸图像”，《美国计算机图形学学报》(2020年美国计算机图形学学报)，第39卷，第4期，72:1–72:16，2020。</p><p id="ff7f" class="pw-post-body-paragraph ku kv it kx b ky kz kd la lb lc kg ld mi lf lg lh mj lj lk ll mk ln lo lp lq im bi translated">[3] S. W. Kim，Y. Zhou，J. Philion，A. Torralba和S. Fidler，“用GameGAN学习模拟动态环境”，IEEE计算机视觉和模式识别会议(CVPR)，2020年6月。</p><p id="47ed" class="pw-post-body-paragraph ku kv it kx b ky kz kd la lb lc kg ld mi lf lg lh mj lj lk ll mk ln lo lp lq im bi translated">[4] S. Menon，A. Damian，S. Hu，N. Ravi和C. Rudin，Pulse:通过生成模型的潜在空间探索进行自我监督的照片上采样，2020年。arXiv:2003.03808 [cs。简历】。</p><p id="4288" class="pw-post-body-paragraph ku kv it kx b ky kz kd la lb lc kg ld mi lf lg lh mj lj lk ll mk ln lo lp lq im bi translated">[5] M.-A. Lachaux，B. Roziere，L. Chanussot，G. Lample，程序设计语言的无监督翻译，2020年。arXiv:2006.03511 [cs。CL】。</p><p id="e704" class="pw-post-body-paragraph ku kv it kx b ky kz kd la lb lc kg ld mi lf lg lh mj lj lk ll mk ln lo lp lq im bi translated">[6] S. Saito，T. Simon，J. Saragih，和H. Joo，Pifuhd:用于高分辨率3d人体数字化的多级像素对齐隐函数，2020年。arXiv:2004.00452 [cs。简历】。</p><p id="019a" class="pw-post-body-paragraph ku kv it kx b ky kz kd la lb lc kg ld mi lf lg lh mj lj lk ll mk ln lo lp lq im bi translated">[7] J. Naruniec，L. Helminger，C. Schroers和R. Weber，“视觉效果的高分辨率神经面部交换”，《计算机图形论坛》，第39卷，第173-184页，2020年7月。</p><p id="8649" class="pw-post-body-paragraph ku kv it kx b ky kz kd la lb lc kg ld mi lf lg lh mj lj lk ll mk ln lo lp lq im bi translated">[8] T. Park，J.-Y. Zhu，O. Wang，J. Lu，E. Shechtman，A. A. Efros，和R. Zhang，用于深度图像处理的交换自动编码器，2020年。arXiv:2007.00653 [cs。简历】。</p><p id="a364" class="pw-post-body-paragraph ku kv it kx b ky kz kd la lb lc kg ld mi lf lg lh mj lj lk ll mk ln lo lp lq im bi translated">[9]布朗、曼恩、赖德、苏比亚、卡普兰、达里瓦尔、尼拉坎坦、希亚姆、萨斯特里、阿斯克尔、阿加瓦尔、赫伯特-沃斯、克鲁格、亨尼根、蔡尔德、拉梅什、齐格勒、吴、温特、黑塞、陈、西格勒、利特温、格雷arXiv:2005.14165 [cs。CL】。</p><p id="4624" class="pw-post-body-paragraph ku kv it kx b ky kz kd la lb lc kg ld mi lf lg lh mj lj lk ll mk ln lo lp lq im bi translated">[10]曾玉燕，傅俊杰，赵海峰，学习视频嵌入的联合时空变换，2020 .arXiv:2007.10247 [cs。简历】。</p><p id="7868" class="pw-post-body-paragraph ku kv it kx b ky kz kd la lb lc kg ld mi lf lg lh mj lj lk ll mk ln lo lp lq im bi translated">[11] M. Chen，a .，R. Child，J. Wu，H. Jun，D. Luan和I. Sutskever，“从像素进行生成性预训练”，载于第37届机器学习国际会议论文集，H. D. III和A. Singh编辑。，爵士。机器学习研究会议录，第119卷，虚拟:PMLR，2020年7月13-18日，第1691-1703页。【在线】。可查:http://proceedings . MLR . press/v 119/Chen 20s . html</p><p id="1831" class="pw-post-body-paragraph ku kv it kx b ky kz kd la lb lc kg ld mi lf lg lh mj lj lk ll mk ln lo lp lq im bi translated">[12]和于金泽，“学习使用白盒卡通表示法进行卡通化”，<em class="kw"> IEEE计算机视觉与模式识别会议</em>，2020年6月。</p><p id="8e2d" class="pw-post-body-paragraph ku kv it kx b ky kz kd la lb lc kg ld mi lf lg lh mj lj lk ll mk ln lo lp lq im bi translated">[13] S. Mo、M. Cho和J. Shin，冻结鉴别器:微调gans的简单基线，2020年。arXiv:2002.10964 [cs。简历】。</p><p id="ef25" class="pw-post-body-paragraph ku kv it kx b ky kz kd la lb lc kg ld mi lf lg lh mj lj lk ll mk ln lo lp lq im bi translated">[14] K. Sarkar、D. Mehta、W. Xu、V. Golyanik和C. Theobalt，“从单个图像对人类进行神经再现”，欧洲计算机视觉会议(ECCV)，2020年。</p><p id="5437" class="pw-post-body-paragraph ku kv it kx b ky kz kd la lb lc kg ld mi lf lg lh mj lj lk ll mk ln lo lp lq im bi translated">[15] G. Moon和K. M. Lee，“I2l-meshnet:从单一rgb图像进行精确3d人体姿态和网格估计的图像到像素预测网络”，欧洲计算机视觉会议(ECCV)，2020年</p><p id="5f5f" class="pw-post-body-paragraph ku kv it kx b ky kz kd la lb lc kg ld mi lf lg lh mj lj lk ll mk ln lo lp lq im bi translated">[16] J. Krantz、E. Wijmans、A. Majumdar、D. Batra和S. Lee，“超越导航图:连续环境中的视觉和语言导航”，2020年。arXiv:2004.02857 [cs。简历】。</p><p id="025d" class="pw-post-body-paragraph ku kv it kx b ky kz kd la lb lc kg ld mi lf lg lh mj lj lk ll mk ln lo lp lq im bi translated">[17] Z. Teed和J. Deng，Raft:用于光流的循环所有对场变换，2020年。arXiv:2003.12039 [cs。简历】。</p><p id="38a6" class="pw-post-body-paragraph ku kv it kx b ky kz kd la lb lc kg ld mi lf lg lh mj lj lk ll mk ln lo lp lq im bi translated">[18] Z. Li，W. Xian，A. Davis和N. Snavely，“众数采样全光函数”，中华人民共和国。2020年欧洲计算机视觉会议(ECCV)。</p><p id="620f" class="pw-post-body-paragraph ku kv it kx b ky kz kd la lb lc kg ld mi lf lg lh mj lj lk ll mk ln lo lp lq im bi translated">[19]万，张，陈，张平，陈，廖，文，2020 .arXiv:2009.07047 [cs。简历】。</p><p id="8ec5" class="pw-post-body-paragraph ku kv it kx b ky kz kd la lb lc kg ld mi lf lg lh mj lj lk ll mk ln lo lp lq im bi translated">[20] Lechner，m .，Hasani，r .，Amini，A. <em class="kw">等</em>实现可审计自主性的神经回路策略。<em class="kw">国家机器智能</em> <strong class="kx jd"> 2、</strong>642–652(2020)。<a class="ae lr" href="https://doi.org/10.1038/s42256-020-00237-3" rel="noopener ugc nofollow" target="_blank">https://doi.org/10.1038/s42256-020-00237-3</a></p><p id="ed2e" class="pw-post-body-paragraph ku kv it kx b ky kz kd la lb lc kg ld mi lf lg lh mj lj lk ll mk ln lo lp lq im bi translated">[21] R. Or-El、S. Sengupta、O. Fried、E. Shechtman和I. Kemelmacher-Shlizerman，“生命跨度变换合成”，欧洲计算机视觉会议(ECCV)会议录，2020年。</p><p id="ee10" class="pw-post-body-paragraph ku kv it kx b ky kz kd la lb lc kg ld mi lf lg lh mj lj lk ll mk ln lo lp lq im bi translated">[22]杰森·安蒂奇，DeOldify的创造者，<a class="ae lr" href="https://github.com/jantic/DeOldify" rel="noopener ugc nofollow" target="_blank">https://github.com/jantic/DeOldify</a></p><p id="74b1" class="pw-post-body-paragraph ku kv it kx b ky kz kd la lb lc kg ld mi lf lg lh mj lj lk ll mk ln lo lp lq im bi translated">[23] S. Ging，M. Zolfaghari，H. Pirsiavash和T. Brox，“Coot:用于视频-文本表示学习的合作式分层转换器”，神经信息处理系统会议，2020年。</p><p id="cbfb" class="pw-post-body-paragraph ku kv it kx b ky kz kd la lb lc kg ld mi lf lg lh mj lj lk ll mk ln lo lp lq im bi translated">[24]邹，史，邱，袁，史，风格化神经绘画，2020。arXiv:2011.08114[cs。简历】。</p><p id="5c9f" class="pw-post-body-paragraph ku kv it kx b ky kz kd la lb lc kg ld mi lf lg lh mj lj lk ll mk ln lo lp lq im bi translated">[25]柯正光，李，周，吴，毛，严正光，刘瑞伟，“实时人像抠图真的需要绿屏吗？”ArXiv，第abs/2011.11961卷，2020年。</p><p id="39c5" class="pw-post-body-paragraph ku kv it kx b ky kz kd la lb lc kg ld mi lf lg lh mj lj lk ll mk ln lo lp lq im bi translated">[26] T. Karras，M. Aittala，J. Hellsten，S. Laine，J. Lehtinen和T. Aila，用有限数据训练生成性对抗网络，2020年。arXiv:2006.06676 [cs。简历】。</p><p id="cacb" class="pw-post-body-paragraph ku kv it kx b ky kz kd la lb lc kg ld mi lf lg lh mj lj lk ll mk ln lo lp lq im bi translated">[27] <em class="kw"> J. A. Weyn、D. R. Durran和R. Caruana，“使用立方体球体上的深度卷积神经网络改进数据驱动的全球天气预测”，《地球系统建模进展杂志》，第12卷，第9期，2020年9月，ISSN:1942–2466 . doi:10.1029/2020 ms 002109</em></p><p id="7de5" class="pw-post-body-paragraph ku kv it kx b ky kz kd la lb lc kg ld mi lf lg lh mj lj lk ll mk ln lo lp lq im bi translated">[28] P. P. Srinivasan、B. Deng、X. Zhang、M. Tancik、B. Mildenhall和J. T. Barron，“Nerv:用于重新照明和视图合成的神经反射和可见度场”，载于arXiv，2020年。</p></div></div>    
</body>
</html>