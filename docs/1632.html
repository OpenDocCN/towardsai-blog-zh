<html>
<head>
<title>Step-by-Step Basic Understanding of Neural Networks with Keras in Python</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">使用Python中的Keras逐步基本了解神经网络</h1>
<blockquote>原文：<a href="https://pub.towardsai.net/step-by-step-basic-understanding-of-neural-networks-with-keras-in-python-94f4afd026e5?source=collection_archive---------0-----------------------#2021-03-08">https://pub.towardsai.net/step-by-step-basic-understanding-of-neural-networks-with-keras-in-python-94f4afd026e5?source=collection_archive---------0-----------------------#2021-03-08</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><h2 id="a119" class="ir is it bd b dl iu iv iw ix iy iz dk ja translated" aria-label="kicker paragraph"><a class="ae ep" href="https://towardsai.net/p/category/machine-learning/deep-learning" rel="noopener ugc nofollow" target="_blank">深度学习</a></h2><div class=""/><div class=""><h2 id="f6b0" class="pw-subtitle-paragraph jz jc it bd b ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq dk translated">具有定义的神经网络的学习</h2></div><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div class="gh gi kr"><img src="../Images/e68665e2ff9250d32e0b3e0359f156e5.png" data-original-src="https://miro.medium.com/v2/resize:fit:1342/format:webp/1*qiEKcgNw695U-V5-KfMt8Q.png"/></div><figcaption class="kz la gj gh gi lb lc bd b be z dk translated">人工神经网络。作者的照片</figcaption></figure><p id="6a48" class="pw-post-body-paragraph ld le it lf b lg lh kd li lj lk kg ll lm ln lo lp lq lr ls lt lu lv lw lx ly im bi translated">在本文中，我们将讨论简单的神经网络及其定义与Keras的例子。在传统机器学习的基础上使用神经网络，以获得更高的准确性和更大的复杂数据。</p><h2 id="c43e" class="lz ma it bd mb mc md dn me mf mg dp mh lm mi mj mk lq ml mm mn lu mo mp mq iz bi translated">涵盖的主题:</h2><ol class=""><li id="be62" class="mr ms it lf b lg mt lj mu lm mv lq mw lu mx ly my mz na nb bi translated">神经网络导论</li><li id="e10d" class="mr ms it lf b lg nc lj nd lm ne lq nf lu ng ly my mz na nb bi translated">权重和偏差</li><li id="cefe" class="mr ms it lf b lg nc lj nd lm ne lq nf lu ng ly my mz na nb bi translated">不同类型的层</li><li id="a1b4" class="mr ms it lf b lg nc lj nd lm ne lq nf lu ng ly my mz na nb bi translated">激活功能</li><li id="5fb0" class="mr ms it lf b lg nc lj nd lm ne lq nf lu ng ly my mz na nb bi translated">梯度下降和随机梯度下降</li><li id="a708" class="mr ms it lf b lg nc lj nd lm ne lq nf lu ng ly my mz na nb bi translated">反向传播</li><li id="067a" class="mr ms it lf b lg nc lj nd lm ne lq nf lu ng ly my mz na nb bi translated">使用python的Keras示例</li></ol><div class="nh ni gp gr nj nk"><a rel="noopener  ugc nofollow" target="_blank" href="/become-a-data-scientist-in-2021-with-these-following-steps-5bf70a0fe0a1"><div class="nl ab fo"><div class="nm ab nn cl cj no"><h2 class="bd jd gy z fp np fr fs nq fu fw jc bi translated">按照以下步骤，在2021年成为一名数据科学家</h2><div class="nr l"><h3 class="bd b gy z fp np fr fs nq fu fw dk translated">走上数据科学家之路需要具备的基本点</h3></div><div class="ns l"><p class="bd b dl z fp np fr fs nq fu fw dk translated">pub.towardsai.net</p></div></div><div class="nt l"><div class="nu l nv nw nx nt ny kx nk"/></div></div></a></div><blockquote class="nz oa ob"><p id="b98c" class="ld le oc lf b lg lh kd li lj lk kg ll od ln lo lp oe lr ls lt of lv lw lx ly im bi translated"><strong class="lf jd"> <em class="it">神经网络简介</em> </strong></p></blockquote><p id="1071" class="pw-post-body-paragraph ld le it lf b lg lh kd li lj lk kg ll lm ln lo lp lq lr ls lt lu lv lw lx ly im bi translated">神经网络正在全球各行业蓬勃发展。是关于回归、分类、聚类等传统的机器学习算法。当我们得到大量复杂的数据时，准确性、过度拟合以及测试和训练的时间都会出现问题。</p><p id="333c" class="pw-post-body-paragraph ld le it lf b lg lh kd li lj lk kg ll lm ln lo lp lq lr ls lt lu lv lw lx ly im bi translated">神经网络的基本类型</p><ul class=""><li id="1596" class="mr ms it lf b lg lh lj lk lm og lq oh lu oi ly oj mz na nb bi translated">人工神经网络</li><li id="f12e" class="mr ms it lf b lg nc lj nd lm ne lq nf lu ng ly oj mz na nb bi translated">卷积神经网络</li><li id="2aba" class="mr ms it lf b lg nc lj nd lm ne lq nf lu ng ly oj mz na nb bi translated">递归神经网络</li></ul><p id="1e09" class="pw-post-body-paragraph ld le it lf b lg lh kd li lj lk kg ll lm ln lo lp lq lr ls lt lu lv lw lx ly im bi translated">对于易于处理的非线性数据，神经网络是非常好的算法。</p><p id="62d3" class="pw-post-body-paragraph ld le it lf b lg lh kd li lj lk kg ll lm ln lo lp lq lr ls lt lu lv lw lx ly im bi translated">术语<strong class="lf jd"> <em class="oc">感知器</em> </strong>是弗兰克·罗森布拉特在1957年创造的。在机器学习中，感知器是二进制状态的线性分类器，在深度学习中，感知器是人工神经元。</p><p id="1569" class="pw-post-body-paragraph ld le it lf b lg lh kd li lj lk kg ll lm ln lo lp lq lr ls lt lu lv lw lx ly im bi translated">神经元的概念来源于人脑中的神经元，并试图通过人工神经元模仿自然神经元的动作来适应和学习周围环境。</p><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div class="gh gi ok"><img src="../Images/c8aef9b7dd922abe489239f023369e33.png" data-original-src="https://miro.medium.com/v2/resize:fit:894/format:webp/1*1F8KbS4CjC1k6bPLOqt9bw.png"/></div><figcaption class="kz la gj gh gi lb lc bd b be z dk translated">人造神经元。作者的照片</figcaption></figure><p id="9170" class="pw-post-body-paragraph ld le it lf b lg lh kd li lj lk kg ll lm ln lo lp lq lr ls lt lu lv lw lx ly im bi translated">对于深度学习中的任何模型，都必须有输入和输出神经元。</p><blockquote class="nz oa ob"><p id="22a7" class="ld le oc lf b lg lh kd li lj lk kg ll od ln lo lp oe lr ls lt of lv lw lx ly im bi translated"><strong class="lf jd"> <em class="it">权重和偏差</em> </strong></p></blockquote><p id="af02" class="pw-post-body-paragraph ld le it lf b lg lh kd li lj lk kg ll lm ln lo lp lq lr ls lt lu lv lw lx ly im bi translated">权重和偏差是神经网络中的两个学习参数，信息通过它们传递到下一层。</p><p id="40a7" class="pw-post-body-paragraph ld le it lf b lg lh kd li lj lk kg ll lm ln lo lp lq lr ls lt lu lv lw lx ly im bi translated">在天然神经元中，信息通过电脉冲从一端传递到另一端，而在人工神经元中，信息是借助重量传递的。</p><p id="37f6" class="pw-post-body-paragraph ld le it lf b lg lh kd li lj lk kg ll lm ln lo lp lq lr ls lt lu lv lw lx ly im bi translated">偏差值用于使数据更灵活，更接近实际动作。</p><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div class="gh gi ol"><img src="../Images/fed1c98bde57302c451273747736e89d.png" data-original-src="https://miro.medium.com/v2/resize:fit:992/format:webp/1*vV4bVJkOVfaxLGwg6NQrGQ.png"/></div><figcaption class="kz la gj gh gi lb lc bd b be z dk translated">信息从输入到输出的传递。作者的照片</figcaption></figure><p id="b2b8" class="pw-post-body-paragraph ld le it lf b lg lh kd li lj lk kg ll lm ln lo lp lq lr ls lt lu lv lw lx ly im bi translated">一个简单的带权重和偏差的神经网络模型</p><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div class="gh gi om"><img src="../Images/898a8a88e41ef24bbfc97b64a37e6277.png" data-original-src="https://miro.medium.com/v2/resize:fit:1026/format:webp/1*KhfHpZs6tteM4CRIbxAvBA.png"/></div><figcaption class="kz la gj gh gi lb lc bd b be z dk translated">作者的照片</figcaption></figure><p id="e51a" class="pw-post-body-paragraph ld le it lf b lg lh kd li lj lk kg ll lm ln lo lp lq lr ls lt lu lv lw lx ly im bi translated">有输入的权重和偏差公式。</p><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div class="gh gi on"><img src="../Images/ecea5b03954eafcad0fb2574ae0802c5.png" data-original-src="https://miro.medium.com/v2/resize:fit:838/format:webp/1*0QzBTtcSSzJqXRsaFmeUHg.png"/></div></figure><blockquote class="nz oa ob"><p id="8f05" class="ld le oc lf b lg lh kd li lj lk kg ll od ln lo lp oe lr ls lt of lv lw lx ly im bi translated"><strong class="lf jd"> <em class="it">不同类型的图层</em> </strong></p></blockquote><p id="4658" class="pw-post-body-paragraph ld le it lf b lg lh kd li lj lk kg ll lm ln lo lp lq lr ls lt lu lv lw lx ly im bi translated">在神经网络中，层由神经元定义，信息通过神经元传递到下一层神经元。三层描述如下:</p><ul class=""><li id="060f" class="mr ms it lf b lg lh lj lk lm og lq oh lu oi ly oj mz na nb bi translated">输入层:这一层根据我们数据集中独立特征的数量包含神经元的数量。</li><li id="8883" class="mr ms it lf b lg nc lj nd lm ne lq nf lu ng ly oj mz na nb bi translated">隐藏层:该层位于输入层和输出层之间。它也称为计算层，采用带权重和偏差的非线性输入，并使用激活函数将其计算到下一层。</li><li id="fce7" class="mr ms it lf b lg nc lj nd lm ne lq nf lu ng ly oj mz na nb bi translated">输出层:这一层包含分类问题的输出。它可能有一个节点或神经元或多个神经元。</li></ul><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div class="gh gi oo"><img src="../Images/3f7ed921da464c661b86a1b10f11edc7.png" data-original-src="https://miro.medium.com/v2/resize:fit:946/format:webp/1*OWmZ7ZXrODD5I_fNRuqwbA.png"/></div><figcaption class="kz la gj gh gi lb lc bd b be z dk translated">神经网络中层的类型。作者的照片</figcaption></figure><blockquote class="nz oa ob"><p id="332e" class="ld le oc lf b lg lh kd li lj lk kg ll od ln lo lp oe lr ls lt of lv lw lx ly im bi translated"><strong class="lf jd"> <em class="it">激活功能</em> </strong></p></blockquote><p id="eb6d" class="pw-post-body-paragraph ld le it lf b lg lh kd li lj lk kg ll lm ln lo lp lq lr ls lt lu lv lw lx ly im bi translated">神经网络中的激活函数对来自输入层的输出进行比较计算，并决定某个阈值进行分类。</p><p id="8cf5" class="pw-post-body-paragraph ld le it lf b lg lh kd li lj lk kg ll lm ln lo lp lq lr ls lt lu lv lw lx ly im bi translated">神经网络中使用了许多激活函数，如下所示:</p><ol class=""><li id="7779" class="mr ms it lf b lg lh lj lk lm og lq oh lu oi ly my mz na nb bi translated">阈值函数:简单来说就是阶跃函数或者说二元函数。在多类问题中就没那么有用了。</li><li id="0ac5" class="mr ms it lf b lg nc lj nd lm ne lq nf lu ng ly my mz na nb bi translated">线性激活函数:这个函数非常适合回归类问题。这个函数的问题是不要在反向传播中使用，因为导数是相同的。</li><li id="74b9" class="mr ms it lf b lg nc lj nd lm ne lq nf lu ng ly my mz na nb bi translated">非线性函数:它们适用于非线性数据，其中一些如下所示:</li></ol><ul class=""><li id="fba2" class="mr ms it lf b lg lh lj lk lm og lq oh lu oi ly oj mz na nb bi translated"><strong class="lf jd"> <em class="oc"> Sigmoid函数:</em> </strong>对渐变很有帮助但对高低值不好。计算的过程也很高。范围在0到1之间。</li><li id="d126" class="mr ms it lf b lg nc lj nd lm ne lq nf lu ng ly oj mz na nb bi translated"><strong class="lf jd"> <em class="oc">双曲正切(tanh): </em> </strong>它有点像sigmoid，但不同的是，它在负值时也表现良好。范围在-1到1之间。</li><li id="ae20" class="mr ms it lf b lg nc lj nd lm ne lq nf lu ng ly oj mz na nb bi translated"><strong class="lf jd"> <em class="oc">整流线性(ReLu): </em> </strong>收敛良好，适用于非线性。但是它在反向传播的学习中不是很有用，并且对于负值或达到零值，梯度变为零。</li><li id="eb3c" class="mr ms it lf b lg nc lj nd lm ne lq nf lu ng ly oj mz na nb bi translated"><strong class="lf jd"> <em class="oc">漏ReLu: </em> </strong>这克服了反向传播中的ReLu问题，但预测精度较低。</li><li id="b05b" class="mr ms it lf b lg nc lj nd lm ne lq nf lu ng ly oj mz na nb bi translated"><strong class="lf jd"> <em class="oc">参数ReLu: </em> </strong>这个非常适合做反向传播，学习负值的东西。</li><li id="164f" class="mr ms it lf b lg nc lj nd lm ne lq nf lu ng ly oj mz na nb bi translated"><strong class="lf jd"> <em class="oc"> Softmax函数:</em> </strong>它对输入的许多类别进行分类非常有用，所以，它用在输出层。</li><li id="5b09" class="mr ms it lf b lg nc lj nd lm ne lq nf lu ng ly oj mz na nb bi translated"><strong class="lf jd"> <em class="oc"> Swish函数:</em> </strong>这是一种新方法，比ReLu好，准确率提高了0.5%。</li></ul><div class="nh ni gp gr nj nk"><a rel="noopener  ugc nofollow" target="_blank" href="/fully-explained-k-nearest-neighbors-with-python-ebbe27f93ba9"><div class="nl ab fo"><div class="nm ab nn cl cj no"><h2 class="bd jd gy z fp np fr fs nq fu fw jc bi translated">用Python完整解释K近邻</h2><div class="nr l"><h3 class="bd b gy z fp np fr fs nq fu fw dk translated">数据科学中解决真实案例的机器学习分类算法研究。</h3></div><div class="ns l"><p class="bd b dl z fp np fr fs nq fu fw dk translated">pub.towardsai.net</p></div></div><div class="nt l"><div class="op l nv nw nx nt ny kx nk"/></div></div></a></div><blockquote class="nz oa ob"><p id="1fae" class="ld le oc lf b lg lh kd li lj lk kg ll od ln lo lp oe lr ls lt of lv lw lx ly im bi translated"><strong class="lf jd"> <em class="it">梯度下降和</em> </strong>随机梯度下降</p></blockquote><p id="2752" class="pw-post-body-paragraph ld le it lf b lg lh kd li lj lk kg ll lm ln lo lp lq lr ls lt lu lv lw lx ly im bi translated">梯度下降的主要目的是最小化成本(损失)。当我们用实际结果评估我们的模型结果时，损失就来了。这里，权重的更新过程从模型中所有层和节点的反向开始。权重的改变依赖于对w.r.t .权重的偏导数来找到全局最小值。</p><p id="f9fb" class="pw-post-body-paragraph ld le it lf b lg lh kd li lj lk kg ll lm ln lo lp lq lr ls lt lu lv lw lx ly im bi translated">在梯度下降之前，我们可以使用许多权重值的蛮力来找到损失最小的位置。但是，这个过程非常昂贵和耗时。</p><p id="e316" class="pw-post-body-paragraph ld le it lf b lg lh kd li lj lk kg ll lm ln lo lp lq lr ls lt lu lv lw lx ly im bi translated">在本主题中，我们将讨论如下所示的两种优化方法:</p><ul class=""><li id="15c3" class="mr ms it lf b lg lh lj lk lm og lq oh lu oi ly oj mz na nb bi translated">梯度下降:在这种方法中，梯度(斜率)用于知道正负方向。在全局最小值处，斜率变为零，这意味着这是精确权重值的点。梯度下降法的问题是，当有多个局部极小值时，它不能找到全局极小值，因此，我们不能得到适当优化的权重。梯度下降将所有输入作为一个批次进行分析。</li><li id="9861" class="mr ms it lf b lg nc lj nd lm ne lq nf lu ng ly oj mz na nb bi translated">随机梯度下降:为了克服得不到全局最小值的问题，SGD出现了。在这种方法中，输入中的行逐行获取，并逐行更新权重。它也被称为小批量梯度下降法。</li></ul><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div class="gh gi oq"><img src="../Images/b38782988e4adf936884910dd24b9fa4.png" data-original-src="https://miro.medium.com/v2/resize:fit:996/format:webp/1*1oGTjeDw7JidZqKTHe8fGA.png"/></div><figcaption class="kz la gj gh gi lb lc bd b be z dk translated">神经网络中的学习速率。作者的照片</figcaption></figure><blockquote class="nz oa ob"><p id="1ab7" class="ld le oc lf b lg lh kd li lj lk kg ll od ln lo lp oe lr ls lt of lv lw lx ly im bi translated"><strong class="lf jd"><em class="it"/></strong></p></blockquote><p id="3ac4" class="pw-post-body-paragraph ld le it lf b lg lh kd li lj lk kg ll lm ln lo lp lq lr ls lt lu lv lw lx ly im bi translated">这是一个借助梯度下降法更新模型中权重的过程。</p><blockquote class="nz oa ob"><p id="dcb1" class="ld le oc lf b lg lh kd li lj lk kg ll od ln lo lp oe lr ls lt of lv lw lx ly im bi translated"><strong class="lf jd"> <em class="it">用python举例</em> </strong></p></blockquote><p id="f640" class="pw-post-body-paragraph ld le it lf b lg lh kd li lj lk kg ll lm ln lo lp lq lr ls lt lu lv lw lx ly im bi translated">这是一个银行数据集流失分析的例子。</p><p id="50b4" class="pw-post-body-paragraph ld le it lf b lg lh kd li lj lk kg ll lm ln lo lp lq lr ls lt lu lv lw lx ly im bi translated">导入必要的库</p><pre class="ks kt ku kv gt or os ot ou aw ov bi"><span id="a7e1" class="lz ma it os b gy ow ox l oy oz">import numpy as np <br/>import pandas as pd pd.read_csv)<br/>import matplotlib.pyplot as plt</span></pre><p id="833f" class="pw-post-body-paragraph ld le it lf b lg lh kd li lj lk kg ll lm ln lo lp lq lr ls lt lu lv lw lx ly im bi translated">现在，使用pandas read方法导入数据集，并将数据分为独立特征和从属特征。</p><pre class="ks kt ku kv gt or os ot ou aw ov bi"><span id="e2df" class="lz ma it os b gy ow ox l oy oz">dataset = pd.read_csv('Churn_Modelling.csv')</span><span id="010f" class="lz ma it os b gy pa ox l oy oz">X = dataset.iloc[:,3:13].values <br/>y = dataset.iloc[:, 13].values </span><span id="756c" class="lz ma it os b gy pa ox l oy oz"><br/>print(X.shape)<br/>print(y.shape)</span><span id="7bd1" class="lz ma it os b gy pa ox l oy oz">#output:<br/>(10000, 10)<br/>(10000,)</span></pre><p id="122b" class="pw-post-body-paragraph ld le it lf b lg lh kd li lj lk kg ll lm ln lo lp lq lr ls lt lu lv lw lx ly im bi translated">我们在数据中有两个类别特征，即国家和性别。所以，我们将使用一个标签编码器来使它们成为数字浮点数据。标签编码后，我们将使用一键编码来创建我们在国家和性别特征中标记编码的新特征列。</p><pre class="ks kt ku kv gt or os ot ou aw ov bi"><span id="b26b" class="lz ma it os b gy ow ox l oy oz">from sklearn.preprocessing import LabelEncoder, OneHotEncoder<br/><br/>labelencoder_X_1 = LabelEncoder()<br/>X[:, 1] = labelencoder_X_1.fit_transform(X[:, 1])<br/>labelencoder_X_2 = LabelEncoder()<br/>X[:, 2] = labelencoder_X_2.fit_transform(X[:, 2])<br/><br/>onehotencoder = OneHotEncoder(categorical_features=[1])<br/>X = onehotencoder.fit_transform(X).toarray()</span><span id="f909" class="lz ma it os b gy pa ox l oy oz">X = X[:, 1:]  #new updated independent features after encoding</span></pre><p id="d3d6" class="pw-post-body-paragraph ld le it lf b lg lh kd li lj lk kg ll lm ln lo lp lq lr ls lt lu lv lw lx ly im bi translated">现在，我们将把独立数据和相关数据分成训练集和测试集。</p><pre class="ks kt ku kv gt or os ot ou aw ov bi"><span id="57f2" class="lz ma it os b gy ow ox l oy oz">from sklearn.model_selection import train_test_split<br/><br/>X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)</span></pre><p id="da63" class="pw-post-body-paragraph ld le it lf b lg lh kd li lj lk kg ll lm ln lo lp lq lr ls lt lu lv lw lx ly im bi translated">拆分后，我们将使用标准化，以便高值和低值数据的变化在一定范围内成为标准。</p><pre class="ks kt ku kv gt or os ot ou aw ov bi"><span id="e9f8" class="lz ma it os b gy ow ox l oy oz">from sklearn.preprocessing import StandardScaler<br/><br/>sc = StandardScaler()<br/>X_train = sc.fit_transform(X_train)<br/>X_test = sc.transform(X_test)</span></pre><p id="6a54" class="pw-post-body-paragraph ld le it lf b lg lh kd li lj lk kg ll lm ln lo lp lq lr ls lt lu lv lw lx ly im bi translated">在另一篇文章中，我讲述了<strong class="lf jd"> <em class="oc"> fit_transform </em> </strong>和<strong class="lf jd"><em class="oc">transform</em></strong><em class="oc"/>的区别，链接如下。</p><div class="nh ni gp gr nj nk"><a rel="noopener  ugc nofollow" target="_blank" href="/fully-explained-svm-classification-with-python-eda124997bcd"><div class="nl ab fo"><div class="nm ab nn cl cj no"><h2 class="bd jd gy z fp np fr fs nq fu fw jc bi translated">用Python全面解释了SVM分类</h2><div class="nr l"><h3 class="bd b gy z fp np fr fs nq fu fw dk translated">如何用一个真实的例子解决分类问题。</h3></div><div class="ns l"><p class="bd b dl z fp np fr fs nq fu fw dk translated">pub.towardsai.net</p></div></div><div class="nt l"><div class="pb l nv nw nx nt ny kx nk"/></div></div></a></div><p id="c57f" class="pw-post-body-paragraph ld le it lf b lg lh kd li lj lk kg ll lm ln lo lp lq lr ls lt lu lv lw lx ly im bi translated">现在，我们的数据已经准备好作为人工神经网络的输入。我们将使用Keras框架构建ANN。</p><p id="b318" class="pw-post-body-paragraph ld le it lf b lg lh kd li lj lk kg ll lm ln lo lp lq lr ls lt lu lv lw lx ly im bi translated">为ANN导入库</p><pre class="ks kt ku kv gt or os ot ou aw ov bi"><span id="554b" class="lz ma it os b gy ow ox l oy oz">import Keras<br/>from keras.models import Sequential<br/>from keras.layers import Dense</span></pre><p id="d652" class="pw-post-body-paragraph ld le it lf b lg lh kd li lj lk kg ll lm ln lo lp lq lr ls lt lu lv lw lx ly im bi translated">顺序用于初始化人工神经网络，密集用于添加人工神经网络中的层。</p><p id="c3f1" class="pw-post-body-paragraph ld le it lf b lg lh kd li lj lk kg ll lm ln lo lp lq lr ls lt lu lv lw lx ly im bi translated">初始化人工神经网络</p><pre class="ks kt ku kv gt or os ot ou aw ov bi"><span id="f03c" class="lz ma it os b gy ow ox l oy oz">classifier = Sequential()</span></pre><p id="aab9" class="pw-post-body-paragraph ld le it lf b lg lh kd li lj lk kg ll lm ln lo lp lq lr ls lt lu lv lw lx ly im bi translated">在ANN中添加层</p><pre class="ks kt ku kv gt or os ot ou aw ov bi"><span id="78a6" class="lz ma it os b gy ow ox l oy oz">classifier.add(Dense(input_dim = 11, activation = 'relu', units=6, kernel_initializer='uniform'))</span></pre><p id="63f6" class="pw-post-body-paragraph ld le it lf b lg lh kd li lj lk kg ll lm ln lo lp lq lr ls lt lu lv lw lx ly im bi translated">这里，我们初始化输入神经元和隐藏层神经元的数量，即分别为11和6。</p><p id="5d81" class="pw-post-body-paragraph ld le it lf b lg lh kd li lj lk kg ll lm ln lo lp lq lr ls lt lu lv lw lx ly im bi translated">现在增加一个隐藏的6层神经元。</p><pre class="ks kt ku kv gt or os ot ou aw ov bi"><span id="24c8" class="lz ma it os b gy ow ox l oy oz">classifier.add(Dense(activation = 'relu', units=6, kernel_initializer='uniform'))</span></pre><p id="748c" class="pw-post-body-paragraph ld le it lf b lg lh kd li lj lk kg ll lm ln lo lp lq lr ls lt lu lv lw lx ly im bi translated">现在添加输出层。</p><pre class="ks kt ku kv gt or os ot ou aw ov bi"><span id="99ec" class="lz ma it os b gy ow ox l oy oz">classifier.add(Dense(activation = 'sigmoid', units=1, kernel_initializer='uniform'))</span></pre><p id="7f49" class="pw-post-body-paragraph ld le it lf b lg lh kd li lj lk kg ll lm ln lo lp lq lr ls lt lu lv lw lx ly im bi translated">是时候用优化器和损耗参数来编译我们的ANN了。由于我们的输出层具有sigmoid函数，因此我们应该选择与之相关的损耗值。</p><pre class="ks kt ku kv gt or os ot ou aw ov bi"><span id="951d" class="lz ma it os b gy ow ox l oy oz">classifier.compile(optimizer='adam', loss = 'binary_crossentropy', metrics=['accuracy'])</span></pre><p id="b92f" class="pw-post-body-paragraph ld le it lf b lg lh kd li lj lk kg ll lm ln lo lp lq lr ls lt lu lv lw lx ly im bi translated">现在，我们将使用批量大小和纪元数量来拟合我们的模型。</p><pre class="ks kt ku kv gt or os ot ou aw ov bi"><span id="5da3" class="lz ma it os b gy ow ox l oy oz">classifier.fit(X_train, y_train, batch_size=10, epochs=100)</span></pre><p id="6d5d" class="pw-post-body-paragraph ld le it lf b lg lh kd li lj lk kg ll lm ln lo lp lq lr ls lt lu lv lw lx ly im bi translated">经过100个周期后，我们得到了接近86%的准确率。</p><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div class="gh gi pc"><img src="../Images/8bb099ed60cd869ec79da3e8c236acaa.png" data-original-src="https://miro.medium.com/v2/resize:fit:930/format:webp/1*zwFWtjENbj0pFbaS1Xr6Mw.png"/></div></figure><p id="96ca" class="pw-post-body-paragraph ld le it lf b lg lh kd li lj lk kg ll lm ln lo lp lq lr ls lt lu lv lw lx ly im bi translated">是时候为测试集预测我们的模型了。</p><pre class="ks kt ku kv gt or os ot ou aw ov bi"><span id="4d9b" class="lz ma it os b gy ow ox l oy oz">y_pred = classifier.predict(X_test)</span><span id="7b51" class="lz ma it os b gy pa ox l oy oz">#we will use a threshold to know the exactly true and false values.<br/>y_pred = (y_pred &gt; 0.5)</span><span id="198a" class="lz ma it os b gy pa ox l oy oz">#output:<br/>[[False]<br/> [False]<br/> [False]<br/> ...<br/> [False]<br/> [False]<br/> [False]]</span></pre><blockquote class="nz oa ob"><p id="64ec" class="ld le oc lf b lg lh kd li lj lk kg ll od ln lo lp oe lr ls lt of lv lw lx ly im bi translated"><strong class="lf jd"> <em class="it">结论:</em> </strong></p></blockquote><p id="addc" class="pw-post-body-paragraph ld le it lf b lg lh kd li lj lk kg ll lm ln lo lp lq lr ls lt lu lv lw lx ly im bi translated">它是关于人工神经网络的介绍性文章，给出了方法的概述。深度学习类型的模型非常庞大，速度也更快。</p><div class="nh ni gp gr nj nk"><a rel="noopener  ugc nofollow" target="_blank" href="/become-a-data-scientist-in-2021-with-these-following-steps-5bf70a0fe0a1"><div class="nl ab fo"><div class="nm ab nn cl cj no"><h2 class="bd jd gy z fp np fr fs nq fu fw jc bi translated">按照以下步骤，在2021年成为一名数据科学家</h2><div class="nr l"><h3 class="bd b gy z fp np fr fs nq fu fw dk translated">走上数据科学家之路需要具备的基本点</h3></div><div class="ns l"><p class="bd b dl z fp np fr fs nq fu fw dk translated">pub.towardsai.net</p></div></div><div class="nt l"><div class="nu l nv nw nx nt ny kx nk"/></div></div></a></div><p id="4315" class="pw-post-body-paragraph ld le it lf b lg lh kd li lj lk kg ll lm ln lo lp lq lr ls lt lu lv lw lx ly im bi translated">我希望你喜欢这篇文章。通过我的<a class="ae pd" href="https://www.linkedin.com/in/data-scientist-95040a1ab/" rel="noopener ugc nofollow" target="_blank"> LinkedIn </a>和<a class="ae pd" href="https://twitter.com/amitprius" rel="noopener ugc nofollow" target="_blank"> twitter </a>联系我。</p><h1 id="536d" class="pe ma it bd mb pf pg ph me pi pj pk mh ki pl kj mk kl pm km mn ko pn kp mq po bi translated">推荐文章</h1><p id="fe0d" class="pw-post-body-paragraph ld le it lf b lg mt kd li lj mu kg ll lm pp lo lp lq pq ls lt lu pr lw lx ly im bi translated"><a class="ae pd" href="https://medium.com/towards-artificial-intelligence/nlp-zero-to-hero-with-python-2df6fcebff6e?sk=2231d868766e96b13d1e9d7db6064df1" rel="noopener"> 1。NLP —零到英雄与Python </a> <br/> 2。<a class="ae pd" href="https://medium.com/towards-artificial-intelligence/python-data-structures-data-types-and-objects-244d0a86c3cf?sk=42f4b462499f3fc3a160b21e2c94dba6" rel="noopener"> Python数据结构数据类型和对象</a>T5】3 .<a class="ae pd" rel="noopener ugc nofollow" target="_blank" href="/data-preprocessing-concepts-with-python-b93c63f14bb6?source=friends_link&amp;sk=5cc4ac66c6c02a6f02077fd43df9681a">数据预处理概念同Python </a> <br/> 4。<a class="ae pd" rel="noopener ugc nofollow" target="_blank" href="/principal-component-analysis-in-dimensionality-reduction-with-python-1a613006d531?source=friends_link&amp;sk=3ed0671fdc04ba395dd36478bcea8a55">用Python进行主成分分析降维</a> <br/> 5。<a class="ae pd" href="https://medium.com/towards-artificial-intelligence/fully-explained-k-means-clustering-with-python-e7caa573176a?source=friends_link&amp;sk=9c5c613ceb10f2d203712634f3b6fb28" rel="noopener">用Python全面讲解K-means聚类</a> <br/> 6。<a class="ae pd" href="https://medium.com/towards-artificial-intelligence/fully-explained-linear-regression-with-python-fe2b313f32f3?source=friends_link&amp;sk=53c91a2a51347ec2d93f8222c0e06402" rel="noopener">用Python </a> <br/> 7全面讲解了线性回归。<a class="ae pd" href="https://medium.com/towards-artificial-intelligence/fully-explained-logistic-regression-with-python-f4a16413ddcd?source=friends_link&amp;sk=528181f15a44e48ea38fdd9579241a78" rel="noopener">用Python </a> <br/>充分解释了Logistic回归8。<a class="ae pd" href="https://medium.com/towards-artificial-intelligence/basic-of-time-series-with-python-a2f7cb451a76?source=friends_link&amp;sk=09d77be2d6b8779973e41ab54ebcf6c5" rel="noopener">用Python实现时间序列的基础知识</a> <br/> 9。<a class="ae pd" rel="noopener ugc nofollow" target="_blank" href="/data-wrangling-with-python-part-1-969e3cc81d69?source=friends_link&amp;sk=9c3649cf20f31a5c9ead51c50c89ba0b">与Python的数据角力—第一部分</a> <br/> 10。<a class="ae pd" href="https://medium.com/analytics-vidhya/confusion-matrix-in-machine-learning-91b6e2b3f9af?source=friends_link&amp;sk=11c6531da0bab7b504d518d02746d4cc" rel="noopener">机器学习中的混淆矩阵</a></p></div></div>    
</body>
</html>