<html>
<head>
<title>Tweet Topic Modeling: Cleaning and Preprocessing Tweets</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">Tweet主题建模:清理和预处理tweet</h1>
<blockquote>原文：<a href="https://pub.towardsai.net/tweet-topic-modeling-part-2-cleaning-and-preprocessing-tweets-e3a08a8b1770?source=collection_archive---------1-----------------------#2021-01-18">https://pub.towardsai.net/tweet-topic-modeling-part-2-cleaning-and-preprocessing-tweets-e3a08a8b1770?source=collection_archive---------1-----------------------#2021-01-18</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><h2 id="5072" class="ir is it bd b dl iu iv iw ix iy iz dk ja translated" aria-label="kicker paragraph"><a class="ae ep" href="https://towardsai.net/p/category/web-scraping" rel="noopener ugc nofollow" target="_blank">网页抓取</a>、<a class="ae ep" href="https://towardsai.net/p/category/programming" rel="noopener ugc nofollow" target="_blank">编程</a>、<a class="ae ep" href="https://towardsai.net/p/category/nlp" rel="noopener ugc nofollow" target="_blank">自然语言处理</a></h2><div class=""/><div class=""><h2 id="dcc3" class="pw-subtitle-paragraph jz jc it bd b ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq dk translated">这是一个多部分的系列，展示了如何为任何tweets集合收集、预处理、应用和可视化短文本主题建模</h2></div><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div class="gh gi kr"><img src="../Images/8dffe7a9481d6311a622427075d1202f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1218/format:webp/1*uiwNL8ReWla6rnergTHucg.jpeg"/></div></figure><p id="4b91" class="pw-post-body-paragraph kz la it lb b lc ld kd le lf lg kg lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><strong class="lb jd"> <em class="lv">免责声明:</em> </strong> <em class="lv">本文仅出于教育目的。我们不鼓励任何人抓取网站，尤其是那些可能有条款和条件反对此类行为的网站。</em></p></div><div class="ab cl lw lx hx ly" role="separator"><span class="lz bw bk ma mb mc"/><span class="lz bw bk ma mb mc"/><span class="lz bw bk ma mb"/></div><div class="im in io ip iq"><h1 id="439c" class="md me it bd mf mg mh mi mj mk ml mm mn ki mo kj mp kl mq km mr ko ms kp mt mu bi translated">介绍</h1><p id="ec8d" class="pw-post-body-paragraph kz la it lb b lc mv kd le lf mw kg lh li mx lk ll lm my lo lp lq mz ls lt lu im bi translated">主题建模是一种无监督的机器学习方法，目标是找到文本文档集合(语料库)中的“隐藏”主题(或聚类)。它真正的优势在于，你不需要带标签或带注释的数据，而是只接受原始文本数据作为输入，这也是它不受监督的原因。换句话说，模型在看到数据时并不知道主题是什么，而是使用所有文档中单词之间的统计关系来生成它们。</p><p id="35c2" class="pw-post-body-paragraph kz la it lb b lc ld kd le lf lg kg lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">最流行的主题建模方法之一是<strong class="lb jd">潜在狄利克雷分配(LDA) </strong>，这是一种生成概率模型算法，揭示了管理文档语义的潜在变量，这些变量代表抽象主题。LDA(以及一般的主题建模)的典型应用是将其应用于一组新闻文章，以识别共同的主题或话题，如科学、政治、金融等。然而，LDA的一个缺点是它不能很好地处理较短的文本，如<strong class="lb jd"> tweets。</strong>这是最近的<strong class="lb jd">短文本主题建模(STTM) </strong>的方法，其中一些建立在LDA之上，派上用场并且表现更好！</p><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div class="gh gi kr"><img src="../Images/8dffe7a9481d6311a622427075d1202f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1218/format:webp/1*uiwNL8ReWla6rnergTHucg.jpeg"/></div><figcaption class="na nb gj gh gi nc nd bd b be z dk translated">拥有健康专用Twitter账户的主要新闻来源(<em class="ne">作者图片</em>)</figcaption></figure><p id="595a" class="pw-post-body-paragraph kz la it lb b lc ld kd le lf lg kg lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">这一系列帖子旨在展示和解释如何使用Python来执行和应用特定的STTM方法(<strong class="lb jd">Gibbs Sampling Dirichlet Mixture Model</strong>或<strong class="lb jd"> GSDMM </strong>)来处理Twitter上的健康推文。它将是数据搜集/清理、编程、数据可视化和机器学习的结合。我将在接下来的4篇文章中依次讨论所有主题:</p><blockquote class="nf ng nh"><p id="a92d" class="kz la lv lb b lc ld kd le lf lg kg lh ni lj lk ll nj ln lo lp nk lr ls lt lu im bi translated"><a class="ae nl" href="https://medium.com/towards-artificial-intelligence/tweet-topic-modeling-using-twint-to-scrape-tweets-part-1-a9274e5199d2" rel="noopener">第1部分:从Twitter上抓取推文</a></p><p id="5ea8" class="kz la lv lb b lc ld kd le lf lg kg lh ni lj lk ll nj ln lo lp nk lr ls lt lu im bi translated"><strong class="lb jd"> <em class="it">第二部分:清理和预处理推文</em> </strong></p></blockquote><p id="cce5" class="pw-post-body-paragraph kz la it lb b lc ld kd le lf lg kg lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><a class="ae nl" href="https://medium.com/towards-artificial-intelligence/tweet-topic-modeling-part-3-using-short-text-topic-modeling-on-tweets-bc969a827fef" rel="noopener"> <em class="lv">第三部分:应用短文本主题建模</em> </a></p><p id="75a1" class="pw-post-body-paragraph kz la it lb b lc ld kd le lf lg kg lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><a class="ae nl" href="https://medium.com/towards-artificial-intelligence/tweet-topic-modeling-part-4-visualizing-topic-modeling-results-with-plotly-66d5dbaaf7fb" rel="noopener"> <em class="lv">第四部分:可视化主题建模结果</em> </a></p><p id="6538" class="pw-post-body-paragraph kz la it lb b lc ld kd le lf lg kg lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">这些文章不会深入到LDA或STTM的细节，而是解释他们的直觉和需要知道的关键概念。鼓励有兴趣对LDA有更透彻的统计理解的读者查看这些伟大的文章和资源<a class="ae nl" href="http://www.cs.columbia.edu/~blei/papers/Blei2012.pdf" rel="noopener ugc nofollow" target="_blank"> <strong class="lb jd">这里</strong> </a>和<a class="ae nl" href="https://ldabook.com/index.html" rel="noopener ugc nofollow" target="_blank"> <strong class="lb jd">这里</strong> </a>。</p><p id="ebb2" class="pw-post-body-paragraph kz la it lb b lc ld kd le lf lg kg lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">作为先决条件，确保你的电脑上安装了<a class="ae nl" href="https://jupyter.readthedocs.io/en/latest/install.html" rel="noopener ugc nofollow" target="_blank"> Jupyter Notebook </a>、<a class="ae nl" href="https://www.python.org/downloads/" rel="noopener ugc nofollow" target="_blank"> Python </a>、&amp;、<a class="ae nl" href="https://git-scm.com/downloads" rel="noopener ugc nofollow" target="_blank"> Git </a>。</p><p id="057c" class="pw-post-body-paragraph kz la it lb b lc ld kd le lf lg kg lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">好吧，我们继续！</p></div><div class="ab cl lw lx hx ly" role="separator"><span class="lz bw bk ma mb mc"/><span class="lz bw bk ma mb mc"/><span class="lz bw bk ma mb"/></div><div class="im in io ip iq"><h1 id="8536" class="md me it bd mf mg mh mi mj mk ml mm mn ki mo kj mp kl mq km mr ko ms kp mt mu bi translated">第2部分:清理和预处理Tweets</h1><p id="7492" class="pw-post-body-paragraph kz la it lb b lc mv kd le lf mw kg lh li mx lk ll lm my lo lp lq mz ls lt lu im bi translated">在我们的<a class="ae nl" href="https://medium.com/towards-artificial-intelligence/tweet-topic-modeling-using-twint-to-scrape-tweets-part-1-a9274e5199d2" rel="noopener">上一篇文章</a>中，我们使用<a class="ae nl" href="https://github.com/twintproject/twint" rel="noopener ugc nofollow" target="_blank"> Twint </a>从Twitter上搜集了一些推文，并将所有原始数据合并成一个csv文件。刮刀给我们的数据格式没有任何改动。如果您刚刚加入我们的第2部分，此处提供的csv供您参考。</p><p id="6cd9" class="pw-post-body-paragraph kz la it lb b lc ld kd le lf lg kg lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">本文将重点关注原始推文的预处理。这一步很重要，因为未经预处理的原始推文是高度非结构化的，包含冗余和经常有问题的信息。根据我们的目标，推文中有很多我们可能不需要或不想要的噪音:</p><blockquote class="nm"><p id="d44e" class="nn no it bd np nq nr ns nt nu nv lu dk translated">如何在社交疏远时不练习情感疏远？@哈佛健康<a class="ae nl" href="https://t.co/dSXhPqwywW" rel="noopener ugc nofollow" target="_blank">https://t.co/dSXhPqwywW</a>#哈佛健康<a class="ae nl" href="https://t.co/H9tfffNAo0" rel="noopener ugc nofollow" target="_blank">https://t.co/H9tfffNAo0'</a></p></blockquote><p id="4110" class="pw-post-body-paragraph kz la it lb b lc nw kd le lf nx kg lh li ny lk ll lm nz lo lp lq oa ls lt lu im bi translated">例如，上面的标签、链接和@ handle引用对于我们的主题建模方法来说可能不是必需的，因为这些术语并没有真正为从tweet中发现固有主题提供有意义的上下文。另外，如果我们希望保留标签，因为它们可以为我们的另一个分析目的服务，我们很快就会看到在我们的原始数据中已经有一个<code class="fe ob oc od oe b">hashtags</code>列将它们保存在一个列表中。</p><h2 id="b834" class="of me it bd mf og oh dn mj oi oj dp mn li ok ol mp lm om on mr lq oo op mt iz bi translated"><strong class="ak">删除不必要的专栏和重复的推文</strong></h2><p id="e4b1" class="pw-post-body-paragraph kz la it lb b lc mv kd le lf mw kg lh li mx lk ll lm my lo lp lq mz ls lt lu im bi translated">首先，我们将把搜集到的tweets加载到一个数据框中。从Twint提供的原始抓取数据有许多列，其中少数包含<strong class="lb jd"> </strong> null <strong class="lb jd"> </strong>或<code class="fe ob oc od oe b">NaN</code>值。我们将删除这些内容，并查看所有tweets的实际值保留在哪些列中。</p><pre class="ks kt ku kv gt oq oe or os aw ot bi"><span id="c6e3" class="of me it oe b gy ou ov l ow ox">import pandas as pd<br/>tweets_df = pd.read_csv(‘data/health_tweets.csv’)<br/>tweets_df.dropna(axis='columns', inplace=True)<br/>tweets_df.columns</span></pre><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div class="gh gi oy"><img src="../Images/ccf1c8b7d5eef2e29e075a5b4ea0daf6.png" data-original-src="https://miro.medium.com/v2/resize:fit:1178/format:webp/1*iT9V8f3Vz8mvQdziTFhO_w.jpeg"/></div><figcaption class="na nb gj gh gi nc nd bd b be z dk translated">移除具有空值的列后，数据框中剩余的列</figcaption></figure><p id="f59f" class="pw-post-body-paragraph kz la it lb b lc ld kd le lf lg kg lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">现在我们有了一个精简的列集，可以选择保留哪些列。我将保留那些对主题建模或探索性目的最有用或最具描述性的，但您的列表可能会根据您的目标而有所不同。</p><pre class="ks kt ku kv gt oq oe or os aw ot bi"><span id="630f" class="of me it oe b gy ou ov l ow ox">tweets_df = tweets_df[['date', 'timezone', 'tweet', <br/>                       'hashtags', 'username', 'name', <br/>                       'day', 'hour', 'retweet', 'nlikes', <br/>                       'nreplies', 'nretweets']]</span></pre><p id="3329" class="pw-post-body-paragraph kz la it lb b lc ld kd le lf lg kg lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">作为一个健全的检查——我总是喜欢删除任何重复的内容，以防同一条推文被多次发布或意外地被多次删除！</p><pre class="ks kt ku kv gt oq oe or os aw ot bi"><span id="3322" class="of me it oe b gy ou ov l ow ox">tweets_df.drop_duplicates(inplace=True, subset="tweet")</span></pre><h2 id="6f18" class="of me it bd mf og oh dn mj oi oj dp mn li ok ol mp lm om on mr lq oo op mt iz bi translated"><strong class="ak">预处理实际的推文</strong></h2><p id="0117" class="pw-post-body-paragraph kz la it lb b lc mv kd le lf mw kg lh li mx lk ll lm my lo lp lq mz ls lt lu im bi translated">接下来，我们要清理数据帧中每条记录的实际<code class="fe ob oc od oe b">tweet</code>，并移除我们不想要的任何额外的“噪音”。我们需要做的第一件事是导入(如果需要，安装)一些Python模块。我们还将定义一串<code class="fe ob oc od oe b">punctuation</code>符号；这代表我们想要从tweet中删除的任何符号或字符，因为我们只关心单词。</p><pre class="ks kt ku kv gt oq oe or os aw ot bi"><span id="fb11" class="of me it oe b gy ou ov l ow ox">import pandas as pd<br/>import re<br/>import gensim<br/>from nltk.stem import WordNetLemmatizer</span><span id="77bd" class="of me it oe b gy oz ov l ow ox">punctuation = ‘!”$%&amp;\’()*+,-./:;&lt;=&gt;?[\\]^_`{|}~•@’</span></pre><p id="858e" class="pw-post-body-paragraph kz la it lb b lc ld kd le lf lg kg lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">使用上面的模块，我发现创建负责特定预处理任务的各种函数是最容易的。这样，您可以轻松地将它们重新用于您可能正在处理的任何数据集。</p><p id="f3fd" class="pw-post-body-paragraph kz la it lb b lc ld kd le lf lg kg lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">要删除任何链接、用户、标签或音频/视频标签，我们可以使用以下使用<a class="ae nl" href="https://docs.python.org/3/library/re.html" rel="noopener ugc nofollow" target="_blank">正则表达式(Regex) </a>的函数。</p><figure class="ks kt ku kv gt kw"><div class="bz fp l di"><div class="pa pb l"/></div></figure><p id="f074" class="pw-post-body-paragraph kz la it lb b lc ld kd le lf lg kg lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">为了应用必要的自然语言处理(NLP)技术，例如标记化和词条化，我们可以使用下面的函数。</p><p id="b81e" class="pw-post-body-paragraph kz la it lb b lc ld kd le lf lg kg lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><strong class="lb jd">记号化</strong>是将文档(一条推文)分解成单词、标点符号、数字等的过程。<strong class="lb jd">词条释义</strong>是利用词汇和词形分析，将单词转换为其<em class="lv">词条</em>或词典形式的方法。例如，单词<strong class="lb jd">研究</strong>、<strong class="lb jd">研究</strong>和<strong class="lb jd">研究</strong>将被转换为<strong class="lb jd">研究</strong>。</p><figure class="ks kt ku kv gt kw"><div class="bz fp l di"><div class="pa pb l"/></div></figure><p id="818d" class="pw-post-body-paragraph kz la it lb b lc ld kd le lf lg kg lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">作为标记化过程的一部分，最佳实践是删除<strong class="lb jd">停用词</strong>，这些停用词基本上是一组常用词，本身并不能提供多少有意义的上下文。这让我们可以专注于重要的单词。一个例子是单词<em class="lv">、</em>等等。我们使用上面来自<a class="ae nl" href="https://radimrehurek.com/gensim/parsing/preprocessing.html" rel="noopener ugc nofollow" target="_blank"> Gensim </a>的预定义列表，排除少于3个字符的任何单词。</p><p id="6e10" class="pw-post-body-paragraph kz la it lb b lc ld kd le lf lg kg lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">接下来，我们的主函数<code class="fe ob oc od oe b">preprocess_tweet<strong class="lb jd"> </strong></code>除了在tweet中应用小写和去除标点符号、额外的空格或数字之外，还应用了上面定义的所有函数。它返回一个干净的令牌列表，这些令牌已经针对给定的tweet进行了词汇化。<em class="lv">此外，我们还定义了一个</em> <code class="fe ob oc od oe b"><em class="lv">basic_clean</em><strong class="lb jd"><em class="lv"> </em></strong></code> <em class="lv">函数，该函数只清理tweet，而不对可能要求所有单词完整的用例应用记号化或词条化。</em></p><figure class="ks kt ku kv gt kw"><div class="bz fp l di"><div class="pa pb l"/></div></figure><p id="b92b" class="pw-post-body-paragraph kz la it lb b lc ld kd le lf lg kg lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">为了使事情变得更简单，并能够在您正在处理的任何文件中根据需要重用函数，我创建了一个单独的文件来存储所有函数，我们可以轻松地导入这些函数，并使用它们在一次代码运行中返回预处理的数据框。最棒的是，它可以用于任何文本数据集合，如Reddit帖子、文章标题等。！</p><p id="22b6" class="pw-post-body-paragraph kz la it lb b lc ld kd le lf lg kg lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><strong class="lb jd">完整的Tweet预处理器代码</strong></p><figure class="ks kt ku kv gt kw"><div class="bz fp l di"><div class="pa pb l"/></div></figure><p id="4c3c" class="pw-post-body-paragraph kz la it lb b lc ld kd le lf lg kg lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">现在，让我们尝试将我们定义的所有预处理步骤应用到数据框中，并查看结果。</p><pre class="ks kt ku kv gt oq oe or os aw ot bi"><span id="0bcf" class="of me it oe b gy ou ov l ow ox">from tweet_preprocessor import tokenize_tweets<br/>tweets_df = tokenize_tweets(tweets_df)<br/>tweets_df.head(5)</span></pre><p id="ad3e" class="pw-post-body-paragraph kz la it lb b lc ld kd le lf lg kg lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">我们可以看到增加了一个新的<code class="fe ob oc od oe b">tokens</code> <strong class="lb jd"> </strong>栏目，看起来不错！</p><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="pd pe di pf bf pg"><div class="gh gi pc"><img src="../Images/21599b2635afe7afe2d065ca556eba01.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*7XVKV3xonTqMGGKYoGPfGw.jpeg"/></div></div></figure><p id="7101" class="pw-post-body-paragraph kz la it lb b lc ld kd le lf lg kg lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">在我们结束之前，让我们确保将预处理数据集保存到一个csv文件中。你也可以在这里找到它的副本<a class="ae nl" href="https://github.com/bicachu/short-text-topic-modeling-tutorial/blob/main/data/preprocessed_tweets.csv" rel="noopener ugc nofollow" target="_blank">。</a></p><pre class="ks kt ku kv gt oq oe or os aw ot bi"><span id="3c4c" class="of me it oe b gy ou ov l ow ox">tweets_df.to_csv(r’data/preprocessed_tweets.csv’, index = False,   <br/>                 header=True)</span></pre><p id="06eb" class="pw-post-body-paragraph kz la it lb b lc ld kd le lf lg kg lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">在本系列的<a class="ae nl" href="https://medium.com/towards-artificial-intelligence/tweet-topic-modeling-part-3-using-short-text-topic-modeling-on-tweets-bc969a827fef" rel="noopener">下一部分</a>中，我们将开始做有趣的事情，开始分析推文并运行我们的短文主题建模算法，以查看我们收集的推文中存在哪些趋势和主题健康问题！</p><div class="ph pi gp gr pj pk"><a rel="noopener  ugc nofollow" target="_blank" href="/tweet-topic-modeling-part-3-using-short-text-topic-modeling-on-tweets-bc969a827fef"><div class="pl ab fo"><div class="pm ab pn cl cj po"><h2 class="bd jd gy z fp pp fr fs pq fu fw jc bi translated">Tweet主题建模第3部分:在tweet上使用短文本主题建模</h2><div class="pr l"><h3 class="bd b gy z fp pp fr fs pq fu fw dk translated">这是一个多部分的系列，展示了如何为任何集合抓取、预处理、应用和可视化短文本主题建模…</h3></div><div class="ps l"><p class="bd b dl z fp pp fr fs pq fu fw dk translated">pub.towardsai.net</p></div></div><div class="pt l"><div class="pu l pv pw px pt py kx pk"/></div></div></a></div><p id="7250" class="pw-post-body-paragraph kz la it lb b lc ld kd le lf lg kg lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><strong class="lb jd">参考资料和其他有用资源</strong></p><ul class=""><li id="df87" class="pz qa it lb b lc ld lf lg li qb lm qc lq qd lu qe qf qg qh bi translated"><a class="ae nl" href="https://blog.bitext.com/what-is-the-difference-between-stemming-and-lemmatization/" rel="noopener ugc nofollow" target="_blank">词汇化和词干差异的详细说明</a></li><li id="39bb" class="pz qa it lb b lc qi lf qj li qk lm ql lq qm lu qe qf qg qh bi translated"><a class="ae nl" href="https://kavita-ganesan.com/what-are-stop-words/#.X9aTPthKiUk" rel="noopener ugc nofollow" target="_blank">停止字的解释</a></li><li id="d5bf" class="pz qa it lb b lc qi lf qj li qk lm ql lq qm lu qe qf qg qh bi translated"><a class="ae nl" href="https://gist.github.com/bicachu/09cc71bb4b0e3711eaf1556b12fa7ad7" rel="noopener ugc nofollow" target="_blank">预处理代码</a>，可用于任何一组文本数据</li></ul></div></div>    
</body>
</html>