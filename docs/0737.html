<html>
<head>
<title>Web Scraping Using Python: Stock Market Example</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">使用Python进行网络搜集:股票市场示例</h1>
<blockquote>原文：<a href="https://pub.towardsai.net/web-scraping-using-python-stock-market-example-b50e787c2d08?source=collection_archive---------1-----------------------#2020-07-30">https://pub.towardsai.net/web-scraping-using-python-stock-market-example-b50e787c2d08?source=collection_archive---------1-----------------------#2020-07-30</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><h2 id="6534" class="ir is it bd b dl iu iv iw ix iy iz dk ja translated" aria-label="kicker paragraph"><a class="ae ep" href="https://towardsai.net/p/category/data-mining" rel="noopener ugc nofollow" target="_blank">数据挖掘</a>，<a class="ae ep" href="https://towardsai.net/p/category/programming" rel="noopener ugc nofollow" target="_blank">编程</a>，<a class="ae ep" href="https://towardsai.net/p/category/programming/python" rel="noopener ugc nofollow" target="_blank"> Python </a></h2><div class=""/><div class=""><h2 id="09dd" class="pw-subtitle-paragraph jz jc it bd b ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq dk translated">有了BeautifulSoup库，你可以从任何网站获取任何数据。</h2></div><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div class="gh gi kr"><img src="../Images/f08e9b19e146968d2aedf52c41f3b0ec.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*ep1UxlJWDUfpEoUSqwZMMw.jpeg"/></div><figcaption class="kz la gj gh gi lb lc bd b be z dk translated">照片由<a class="ae ld" href="https://unsplash.com/@roadtripwithraj?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">公路旅行与Raj </a>在<a class="ae ld" href="https://unsplash.com/?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上拍摄</figcaption></figure><h1 id="9b37" class="le lf it bd lg lh li lj lk ll lm ln lo ki lp kj lq kl lr km ls ko lt kp lu lv bi translated">什么是网页抓取？</h1><p id="c650" class="pw-post-body-paragraph lw lx it ly b lz ma kd mb mc md kg me mf mg mh mi mj mk ml mm mn mo mp mq mr im bi translated">网站大多是用HTML或XML构建的，这些标记语言有一定的顺序。从该布局中提取数据的过程称为<strong class="ly jd">数据抓取</strong>。在某些来源中，它可以被称为<strong class="ly jd">网收获</strong>或<strong class="ly jd">网提取</strong>。</p><p id="4149" class="pw-post-body-paragraph lw lx it ly b lz ms kd mb mc mt kg me mf mu mh mi mj mv ml mm mn mw mp mq mr im bi translated"><strong class="ly jd">我们为什么要刮数据？</strong></p><p id="c9b5" class="pw-post-body-paragraph lw lx it ly b lz ms kd mb mc mt kg me mf mu mh mi mj mv ml mm mn mw mp mq mr im bi translated">这有很多原因。主要目标是找到、编辑和制作对我们网站有益的数据。如果我们需要持续地这样做，那么我们<strong class="ly jd">需要自动化</strong>数据搜集。</p><p id="255d" class="pw-post-body-paragraph lw lx it ly b lz ms kd mb mc mt kg me mf mu mh mi mj mv ml mm mn mw mp mq mr im bi translated"><strong class="ly jd">刮取数据的步骤</strong></p><p id="542d" class="pw-post-body-paragraph lw lx it ly b lz ms kd mb mc mt kg me mf mu mh mi mj mv ml mm mn mw mp mq mr im bi translated">在我们开始收集数据之前，确定我们的目的是非常重要的。</p><ul class=""><li id="f5fe" class="mx my it ly b lz ms mc mt mf mz mj na mn nb mr nc nd ne nf bi translated">我们想要提取什么数据？</li><li id="0833" class="mx my it ly b lz ng mc nh mf ni mj nj mn nk mr nc nd ne nf bi translated">数据的格式是什么？我如何能到达它？</li><li id="1a3a" class="mx my it ly b lz ng mc nh mf ni mj nj mn nk mr nc nd ne nf bi translated">我将从哪些来源获得数据？我的资源固定吗？他们能改变吗？</li><li id="c7fd" class="mx my it ly b lz ng mc nh mf ni mj nj mn nk mr nc nd ne nf bi translated">在我得到数据后，我需要清理和处理这些数据吗？</li><li id="63c3" class="mx my it ly b lz ng mc nh mf ni mj nj mn nk mr nc nd ne nf bi translated">我要把数据保存在哪里？</li></ul><p id="29a8" class="pw-post-body-paragraph lw lx it ly b lz ms kd mb mc mt kg me mf mu mh mi mj mv ml mm mn mw mp mq mr im bi translated">如果能给我们很好的回答这些问题，有工具和流程会在某种程度上帮助我们，很容易克服。需要采取的步骤简单如下:</p><p id="8be6" class="pw-post-body-paragraph lw lx it ly b lz ms kd mb mc mt kg me mf mu mh mi mj mv ml mm mn mw mp mq mr im bi translated"><strong class="ly jd">第一步:</strong>识别<strong class="ly jd">网站</strong>抓取数据，找到有你想要的数据的页面。</p><p id="c7f2" class="pw-post-body-paragraph lw lx it ly b lz ms kd mb mc mt kg me mf mu mh mi mj mv ml mm mn mw mp mq mr im bi translated">第二步:为网页抓取创建你的<strong class="ly jd">机器人</strong>。编码哪个代码块进入页面的哪个部分。</p><p id="c574" class="pw-post-body-paragraph lw lx it ly b lz ms kd mb mc mt kg me mf mu mh mi mj mv ml mm mn mw mp mq mr im bi translated"><strong class="ly jd">第三步:</strong> <strong class="ly jd">处理、清理、隐藏</strong>你提取的数据。</p><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div class="gh gi nl"><img src="../Images/e886539d7c799c0464243388cfa08409.png" data-original-src="https://miro.medium.com/v2/resize:fit:472/format:webp/1*utQDfN-ehKSYSFtZDJK9qA.png"/></div></figure><h1 id="f8c2" class="le lf it bd lg lh li lj lk ll lm ln lo ki lp kj lq kl lr km ls ko lt kp lu lv bi translated">Python BeautifulSoup库的一个例子</h1><p id="b5bd" class="pw-post-body-paragraph lw lx it ly b lz ma kd mb mc md kg me mf mg mh mi mj mk ml mm mn mo mp mq mr im bi translated">Python BeautifulSoup库是一个为数据抓取而创建的实用工具。在我们将要进行的研究中使用这个库，我们将采取我在文章的前一部分提到的前两个步骤。</p><blockquote class="nm nn no"><p id="9435" class="lw lx np ly b lz ms kd mb mc mt kg me nq mu mh mi nr mv ml mm ns mw mp mq mr im bi translated">我们的项目:通过访问<strong class="ly jd"> KAP </strong>网站，获取在<strong class="ly jd"> Borsa伊斯坦布尔—土耳其股票市场</strong>交易的<strong class="ly jd"> </strong>公司的股票代码。(Kod列→ AVOD，A1CAP)</p></blockquote><pre class="ks kt ku kv gt nt nu nv nw aw nx bi"><span id="0194" class="ny lf it nu b gy nz oa l ob oc"><a class="ae ld" href="https://www.kap.org.tr/tr/bist-sirketler'" rel="noopener ugc nofollow" target="_blank">https://www.kap.org.tr/tr/bist-sirketler</a></span></pre><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div class="gh gi kr"><img src="../Images/8e8d4e91669c209d467e2bb5960565c6.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*2JPSq3n8UqHM_E0MJpc5DQ.png"/></div></figure><p id="2d93" class="pw-post-body-paragraph lw lx it ly b lz ms kd mb mc mt kg me mf mu mh mi mj mv ml mm mn mw mp mq mr im bi translated"><strong class="ly jd">开始编码吧！</strong></p><p id="ce0b" class="pw-post-body-paragraph lw lx it ly b lz ms kd mb mc mt kg me mf mu mh mi mj mv ml mm mn mw mp mq mr im bi translated">1-让我们下载我们的库。</p><pre class="ks kt ku kv gt nt nu nv nw aw nx bi"><span id="226f" class="ny lf it nu b gy nz oa l ob oc">import requests<br/>from bs4 import BeautifulSoup<br/>import re</span></pre><p id="8157" class="pw-post-body-paragraph lw lx it ly b lz ms kd mb mc mt kg me mf mu mh mi mj mv ml mm mn mw mp mq mr im bi translated"><strong class="ly jd">请求</strong> =发送一个<strong class="ly jd">请求</strong>到一个网页，就像点击一个网站。我们将使用它向我们确定的网站发送请求。</p><p id="00ff" class="pw-post-body-paragraph lw lx it ly b lz ms kd mb mc mt kg me mf mu mh mi mj mv ml mm mn mw mp mq mr im bi translated"><strong class="ly jd">re</strong>= Python中为<strong class="ly jd">正则表达式</strong>创建的模块。我们将使用它来获得我们想要的文本中的某些表达式。</p><p id="aa4b" class="pw-post-body-paragraph lw lx it ly b lz ms kd mb mc mt kg me mf mu mh mi mj mv ml mm mn mw mp mq mr im bi translated"><strong class="ly jd"> 2-有了请求，让我们将请求发送到我们的网站并连接。</strong></p><p id="ba88" class="pw-post-body-paragraph lw lx it ly b lz ms kd mb mc mt kg me mf mu mh mi mj mv ml mm mn mw mp mq mr im bi translated">我们将请求的答案嵌入到页面变量中。</p><pre class="ks kt ku kv gt nt nu nv nw aw nx bi"><span id="24f5" class="ny lf it nu b gy nz oa l ob oc">URL = ‘<a class="ae ld" href="https://www.kap.org.tr/tr/bist-sirketler'" rel="noopener ugc nofollow" target="_blank">https://www.kap.org.tr/tr/bist-sirketler'</a><br/>page = requests.get(URL)</span></pre><p id="a9e5" class="pw-post-body-paragraph lw lx it ly b lz ms kd mb mc mt kg me mf mu mh mi mj mv ml mm mn mw mp mq mr im bi translated">我们用HTML解析器解析页面变量中的内容。</p><pre class="ks kt ku kv gt nt nu nv nw aw nx bi"><span id="0d56" class="ny lf it nu b gy nz oa l ob oc">soup = BeautifulSoup(page.content, ‘html.parser’)</span></pre><p id="a19d" class="pw-post-body-paragraph lw lx it ly b lz ms kd mb mc mt kg me mf mu mh mi mj mv ml mm mn mw mp mq mr im bi translated">当我们看一看我们的Soup变量时，我们可以看到，到目前为止，我们完成的过程下载了页面的整个HTML代码。</p><pre class="ks kt ku kv gt nt nu nv nw aw nx bi"><span id="7acd" class="ny lf it nu b gy nz oa l ob oc">print(soup)</span></pre><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div class="gh gi kr"><img src="../Images/1f375eba6e21033c27c7bb3d7508e3fa.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Ii0ncQFePFvFktn6SmtVdg.png"/></div></figure><p id="709b" class="pw-post-body-paragraph lw lx it ly b lz ms kd mb mc mt kg me mf mu mh mi mj mv ml mm mn mw mp mq mr im bi translated">我们只是用我们想要的数据来解析这个块。</p><pre class="ks kt ku kv gt nt nu nv nw aw nx bi"><span id="b334" class="ny lf it nu b gy nz oa l ob oc">results = soup.findAll(“div”, {“class”: “comp-cell _04 vtable”})</span></pre><p id="a8e1" class="pw-post-body-paragraph lw lx it ly b lz ms kd mb mc mt kg me mf mu mh mi mj mv ml mm mn mw mp mq mr im bi translated">我们要取的块在名为"<strong class="ly jd"> comp-cell _04 </strong>"的类中。我们来到相关网站，在浏览器中说“<strong class="ly jd"> review </strong>”，在正确的区域或通过查看下面的HTML代码找到了它。</p><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div class="gh gi od"><img src="../Images/93669b9abc1a1ad476932c700114adce.png" data-original-src="https://miro.medium.com/v2/resize:fit:730/format:webp/1*dPzn-bGJu-8EwvCfcuO6eg.png"/></div></figure><p id="1c5e" class="pw-post-body-paragraph lw lx it ly b lz ms kd mb mc mt kg me mf mu mh mi mj mv ml mm mn mw mp mq mr im bi translated">当我们看结果变量时，我们分配结果；我们看到，我们正在采取进一步措施，以获得正确的公司股票代码。但是<strong class="ly jd">数据还是喜忧参半</strong>。</p><pre class="ks kt ku kv gt nt nu nv nw aw nx bi"><span id="6da8" class="ny lf it nu b gy nz oa l ob oc">print(results)</span></pre><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div class="gh gi kr"><img src="../Images/2545017c3c157d63b66103a36a56a74f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*TJ7xjAc6S37Jj11Jjy0mNw.png"/></div></figure><p id="fa44" class="pw-post-body-paragraph lw lx it ly b lz ms kd mb mc mt kg me mf mu mh mi mj mv ml mm mn mw mp mq mr im bi translated">让我们开始数据清理过程。</p><p id="49a3" class="pw-post-body-paragraph lw lx it ly b lz ms kd mb mc mt kg me mf mu mh mi mj mv ml mm mn mw mp mq mr im bi translated">在我们想要的代码周围有许多我们不想要的HTML字符，例如AVOD、ADEL。我们需要<strong class="ly jd">消灭</strong>他们。</p><p id="f635" class="pw-post-body-paragraph lw lx it ly b lz ms kd mb mc mt kg me mf mu mh mi mj mv ml mm mn mw mp mq mr im bi translated">为此，我们在代码中分别做了以下工作；</p><p id="0c75" class="pw-post-body-paragraph lw lx it ly b lz ms kd mb mc mt kg me mf mu mh mi mj mv ml mm mn mw mp mq mr im bi translated">a-我们将结果转换成<strong class="ly jd">字符串</strong>。处理这个文本对我们来说很重要。</p><p id="b2bb" class="pw-post-body-paragraph lw lx it ly b lz ms kd mb mc mt kg me mf mu mh mi mj mv ml mm mn mw mp mq mr im bi translated">b-我们移除<strong class="ly jd">缺口</strong>。</p><p id="4303" class="pw-post-body-paragraph lw lx it ly b lz ms kd mb mc mt kg me mf mu mh mi mj mv ml mm mn mw mp mq mr im bi translated">c-我们提取正则表达式和<strong class="ly jd">&gt;&lt;/a&gt;</strong>之间的共享代码，我们把它扔给单词变量。</p><p id="9f26" class="pw-post-body-paragraph lw lx it ly b lz ms kd mb mc mt kg me mf mu mh mi mj mv ml mm mn mw mp mq mr im bi translated">我们创建一个空列表。我们以后会用到这个。</p><p id="aff6" class="pw-post-body-paragraph lw lx it ly b lz ms kd mb mc mt kg me mf mu mh mi mj mv ml mm mn mw mp mq mr im bi translated">e-我们创建的for循环帮助我们丢弃字符<strong class="ly jd">、&gt;、&lt; / a】和“、</strong>”。它通过扫描每个元素来工作。</p><p id="f2c3" class="pw-post-body-paragraph lw lx it ly b lz ms kd mb mc mt kg me mf mu mh mi mj mv ml mm mn mw mp mq mr im bi translated">f-有些公司的股票代码是以<strong class="ly jd"> A1CAP </strong>、<strong class="ly jd"> ACP </strong>的形式并排的。为了提取它，我们将它一个接一个地添加到包含多个代码的行(元素)的列表中。</p><pre class="ks kt ku kv gt nt nu nv nw aw nx bi"><span id="6247" class="ny lf it nu b gy nz oa l ob oc">results = str(results)<br/>results = results.replace(‘ ‘,’’)<br/>words = re.findall(r’&gt;\S+&lt;/a&gt;’,results)<br/>list1=[]<br/>for i in words:<br/> i = i.replace(‘&gt;’,’’)<br/> i = i.replace(‘&lt;/a’,’’)<br/> i = i.split(“,”)<br/> if len(i)&gt;1:<br/> for x in range(len(i)):<br/> list1.append(i[x])<br/> else:<br/> list1.append(i[0])</span></pre><p id="c31f" class="pw-post-body-paragraph lw lx it ly b lz ms kd mb mc mt kg me mf mu mh mi mj mv ml mm mn mw mp mq mr im bi translated">让我们看看我们准备的数据。</p><p id="915b" class="pw-post-body-paragraph lw lx it ly b lz ms kd mb mc mt kg me mf mu mh mi mj mv ml mm mn mw mp mq mr im bi translated">现在股票代码上下波动。已经完全腐烂了。</p><pre class="ks kt ku kv gt nt nu nv nw aw nx bi"><span id="42fd" class="ny lf it nu b gy nz oa l ob oc">print(list1)</span></pre><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="oe of di og bf oh"><div class="gh gi kr"><img src="../Images/8958441b23b373901b11c56d6b3b66d9.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*hBNooPD5WujD6TqYxETKLw.png"/></div></div></figure><h1 id="9211" class="le lf it bd lg lh li lj lk ll lm ln lo ki lp kj lq kl lr km ls ko lt kp lu lv bi translated">结论</h1><p id="24d6" class="pw-post-body-paragraph lw lx it ly b lz ma kd mb mc md kg me mf mg mh mi mj mk ml mm mn mo mp mq mr im bi translated">通过<strong class="ly jd"> Beautifulsoup，</strong>我们从一个样本网站上获得了我们想要的数据。我们的目标是<strong class="ly jd">提取公司的股票代码</strong>。我们先去了网站。我们下载了HTML格式的内容。我们发现了我们想要的区域所在的HTML块。然后，我们完成了数据删除步骤，这比提取数据更具挑战性。</p><p id="29ea" class="pw-post-body-paragraph lw lx it ly b lz ms kd mb mc mt kg me mf mu mh mi mj mv ml mm mn mw mp mq mr im bi translated">我打算在另一个项目中使用这些共享代码作为<strong class="ly jd">参数</strong>。Python <strong class="ly jd"> yfinance </strong>库能够吸引指定份额的每日即时库存值。我们可以通过KAP中不断更新的共享代码，将yfinance模块中的数据自动化，而不是指定一个手动的共享代码。通过一个简单的循环，我们可以从BIST中的所有共享中提取数据。</p><p id="a337" class="pw-post-body-paragraph lw lx it ly b lz ms kd mb mc mt kg me mf mu mh mi mj mv ml mm mn mw mp mq mr im bi translated">我希望我们用<strong class="ly jd"> beautifulsoup </strong>做的这个例子有所帮助。</p><p id="4536" class="pw-post-body-paragraph lw lx it ly b lz ms kd mb mc mt kg me mf mu mh mi mj mv ml mm mn mw mp mq mr im bi translated">感谢阅读！</p></div></div>    
</body>
</html>