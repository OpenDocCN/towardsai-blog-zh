<html>
<head>
<title>Top 10 Computer Vision Papers 2020</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">2020年十大计算机视觉论文</h1>
<blockquote>原文：<a href="https://pub.towardsai.net/top-10-computer-vision-papers-2020-aa606985f688?source=collection_archive---------0-----------------------#2020-12-31">https://pub.towardsai.net/top-10-computer-vision-papers-2020-aa606985f688?source=collection_archive---------0-----------------------#2020-12-31</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><h2 id="0440" class="ir is it bd b dl iu iv iw ix iy iz dk ja translated" aria-label="kicker paragraph"><a class="ae ep" href="https://towardsai.net/p/category/computer-vision" rel="noopener ugc nofollow" target="_blank">计算机视觉</a>，<a class="ae ep" href="https://towardsai.net/p/category/research" rel="noopener ugc nofollow" target="_blank">研究</a></h2><div class=""/><div class=""><h2 id="d228" class="pw-subtitle-paragraph jz jc it bd b ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq dk translated">2020年十大计算机视觉论文，包括视频演示、文章、代码和论文参考。</h2></div><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi kr"><img src="../Images/e5b6186dfff10d215a81a6e29c62f2f1.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*wYX5F2UKDoAvx6bZmHzV_w.png"/></div></div></figure><p id="a45f" class="pw-post-body-paragraph ld le it lf b lg lh kd li lj lk kg ll lm ln lo lp lq lr ls lt lu lv lw lx ly im bi translated">即使今年世界上发生了这么多事情，我们仍然有机会看到许多惊人的研究成果问世。尤其是在人工智能领域，更准确地说是计算机视觉领域。此外，今年还强调了许多重要的方面，如伦理方面、重要的偏见等等。人工智能和我们对人脑及其与人工智能的联系的理解正在不断发展，在不久的将来显示出有前途的应用，这一点我肯定会谈到。</p><p id="ae6f" class="pw-post-body-paragraph ld le it lf b lg lh kd li lj lk kg ll lm ln lo lp lq lr ls lt lu lv lw lx ly im bi translated">这里是我今年在计算机视觉领域最有趣的10篇研究论文，以防你错过其中的任何一篇。简而言之，它基本上是一个由<strong class="lf jd">在人工智能和CV </strong>方面的最新突破组成的列表，带有<strong class="lf jd">清晰的视频解释</strong>、<strong class="lf jd">链接到更深入的文章</strong>，以及<strong class="lf jd">代码</strong>(如果适用)。享受阅读，如果我错过了任何重要的论文，请在评论中告诉我，或者直接在<a class="ae lz" href="https://www.linkedin.com/in/whats-ai/" rel="noopener ugc nofollow" target="_blank"> LinkedIn </a>上联系我！</p><p id="d866" class="pw-post-body-paragraph ld le it lf b lg lh kd li lj lk kg ll lm ln lo lp lq lr ls lt lu lv lw lx ly im bi translated">本文末尾列出了每篇论文的完整参考资料。</p><p id="94f8" class="pw-post-body-paragraph ld le it lf b lg lh kd li lj lk kg ll lm ln lo lp lq lr ls lt lu lv lw lx ly im bi translated"><a class="ae lz" href="https://github.com/louisfb01/Top-10-Computer-Vision-Papers-2020" rel="noopener ugc nofollow" target="_blank"> <strong class="lf jd"> <em class="ma">访问GitHub资源库中的完整列表</em> </strong> </a></p><p id="8be2" class="pw-post-body-paragraph ld le it lf b lg lh kd li lj lk kg ll lm ln lo lp lq lr ls lt lu lv lw lx ly im bi translated"><strong class="lf jd"> <em class="ma">在</em></strong><a class="ae lz" href="https://twitter.com/Whats_AI" rel="noopener ugc nofollow" target="_blank"><strong class="lf jd"><em class="ma">Twitter(@ Whats _ AI)</em></strong></a><strong class="lf jd"><em class="ma">或</em></strong><a class="ae lz" href="https://www.linkedin.com/in/whats-ai/" rel="noopener ugc nofollow" target="_blank"><strong class="lf jd"><em class="ma">LinkedIn(Louis(What ' s AI)</em></strong></a><strong class="lf jd"><em class="ma">如果分享文章！</em>T45】</strong></p><h1 id="4e98" class="mb mc it bd md me mf mg mh mi mj mk ml ki mm kj mn kl mo km mp ko mq kp mr ms bi translated">在5分钟内观看完整的计算机视觉2020倒带</h1><figure class="ks kt ku kv gt kw"><div class="bz fp l di"><div class="mt mu l"/></div></figure></div><div class="ab cl mv mw hx mx" role="separator"><span class="my bw bk mz na nb"/><span class="my bw bk mz na nb"/><span class="my bw bk mz na"/></div><div class="im in io ip iq"><h1 id="cb99" class="mb mc it bd md me nc mg mh mi nd mk ml ki ne kj mn kl nf km mp ko ng kp mr ms bi translated"><a class="ae lz" href="https://openaccess.thecvf.com/content_CVPR_2019/papers/Akkaynak_Sea-Thru_A_Method_for_Removing_Water_From_Underwater_Images_CVPR_2019_paper.pdf" rel="noopener ugc nofollow" target="_blank">海透:一种从水下图像中去除水分的方法【1】</a></h1><p id="efb9" class="pw-post-body-paragraph ld le it lf b lg nh kd li lj ni kg ll lm nj lo lp lq nk ls lt lu nl lw lx ly im bi translated">你有没有想过没有水的海洋会是什么样子？去掉水下照片的蓝绿色，仍然保留着珊瑚礁的真实颜色。好吧，使用计算机视觉和机器学习算法，海法大学的研究人员能够做到这一点！</p><figure class="ks kt ku kv gt kw"><div class="bz fp l di"><div class="mt mu l"/></div></figure><div class="nm nn gp gr no np"><a href="https://medium.com/towards-artificial-intelligence/this-ai-removes-the-water-from-underwater-images-d277281bcd0f" rel="noopener follow" target="_blank"><div class="nq ab fo"><div class="nr ab ns cl cj nt"><h2 class="bd jd gy z fp nu fr fs nv fu fw jc bi translated">这个人工智能从水下图像中移除水！</h2><div class="nw l"><h3 class="bd b gy z fp nu fr fs nv fu fw dk translated">你有没有想过没有水的海洋会是什么样子？研究人员最近通过使用…</h3></div><div class="nx l"><p class="bd b dl z fp nu fr fs nv fu fw dk translated">medium.com</p></div></div><div class="ny l"><div class="nz l oa ob oc ny od lb np"/></div></div></a></div><p id="9aa4" class="pw-post-body-paragraph ld le it lf b lg lh kd li lj lk kg ll lm ln lo lp lq lr ls lt lu lv lw lx ly im bi translated"><a class="ae lz" href="https://github.com/jgibson2/sea-thru" rel="noopener ugc nofollow" target="_blank">点击此处获取海运代码</a></p></div><div class="ab cl mv mw hx mx" role="separator"><span class="my bw bk mz na nb"/><span class="my bw bk mz na nb"/><span class="my bw bk mz na"/></div><div class="im in io ip iq"><h1 id="742c" class="mb mc it bd md me nc mg mh mi nd mk ml ki ne kj mn kl nf km mp ko ng kp mr ms bi translated"><a class="ae lz" href="https://www.nature.com/articles/s42256-020-00237-3.epdf?sharing_token=xHsXBg2SoR9l8XdbXeGSqtRgN0jAjWel9jnR3ZoTv0PbS_e49wmlSXvnXIRQ7wyir5MOFK7XBfQ8sxCtVjc7zD1lWeQB5kHoRr4BAmDEU0_1-UN5qHD5nXYVQyq5BrRV_tFa3_FZjs4LBHt-yebsG4eQcOnNsG4BenK3CmBRFLk%3D" rel="noopener ugc nofollow" target="_blank">支持可审计自治的神经回路策略</a> [2]</h1><p id="8896" class="pw-post-body-paragraph ld le it lf b lg nh kd li lj ni kg ll lm nj lo lp lq nk ls lt lu nl lw lx ly im bi translated">来自澳大利亚IST大学和麻省理工学院的研究人员使用一种新的人工智能系统成功训练了一辆自动驾驶汽车，该系统基于微小动物的大脑，如蛲虫。与流行的深度神经网络(如Inceptions、Resnets或VGG)所需的数百万个神经元相比，他们只需要几个神经元就能控制自动驾驶汽车。他们的网络能够只用75 000个参数完全控制一辆汽车，由19个控制神经元组成，而不是数百万个！</p><figure class="ks kt ku kv gt kw"><div class="bz fp l di"><div class="mt mu l"/></div></figure><div class="nm nn gp gr no np"><a href="https://medium.com/towards-artificial-intelligence/a-new-brain-inspired-intelligent-system-drives-a-car-using-only-19-control-neurons-1ed127107db9" rel="noopener follow" target="_blank"><div class="nq ab fo"><div class="nr ab ns cl cj nt"><h2 class="bd jd gy z fp nu fr fs nv fu fw jc bi translated">一个新的大脑启发的智能系统只用19个控制神经元来驾驶汽车！</h2><div class="nw l"><h3 class="bd b gy z fp nu fr fs nv fu fw dk translated">模仿线虫的神经系统有效地处理信息，这种新的智能系统更强大…</h3></div><div class="nx l"><p class="bd b dl z fp nu fr fs nv fu fw dk translated">medium.com</p></div></div><div class="ny l"><div class="oe l oa ob oc ny od lb np"/></div></div></a></div><p id="5d5b" class="pw-post-body-paragraph ld le it lf b lg lh kd li lj lk kg ll lm ln lo lp lq lr ls lt lu lv lw lx ly im bi translated"><a class="ae lz" href="https://github.com/mlech26l/keras-ncp" rel="noopener ugc nofollow" target="_blank">点击此处获取NCP代码</a></p></div><div class="ab cl mv mw hx mx" role="separator"><span class="my bw bk mz na nb"/><span class="my bw bk mz na nb"/><span class="my bw bk mz na"/></div><div class="im in io ip iq"><h1 id="5404" class="mb mc it bd md me nc mg mh mi nd mk ml ki ne kj mn kl nf km mp ko ng kp mr ms bi translated"><a class="ae lz" href="https://people.eecs.berkeley.edu/~pratul/nerv/" rel="noopener ugc nofollow" target="_blank">神经:神经反射和可见度场<br/>用于重新照明和视图合成</a>【3】</h1><p id="3805" class="pw-post-body-paragraph ld le it lf b lg nh kd li lj ni kg ll lm nj lo lp lq nk ls lt lu nl lw lx ly im bi translated">这种新方法能够生成完整的三维场景，并具有决定场景照明的能力。与以前的方法相比，所有这些只需要非常有限的计算成本和惊人的结果。</p><figure class="ks kt ku kv gt kw"><div class="bz fp l di"><div class="mt mu l"/></div></figure><div class="nm nn gp gr no np"><a href="https://medium.com/what-is-artificial-intelligence/generate-a-complete-3d-scene-under-arbitrary-lighting-conditions-from-a-set-of-input-images-9d2fbce63243" rel="noopener follow" target="_blank"><div class="nq ab fo"><div class="nr ab ns cl cj nt"><h2 class="bd jd gy z fp nu fr fs nv fu fw jc bi translated">从一组输入图像生成任意光照条件下的完整3D场景</h2><div class="nw l"><h3 class="bd b gy z fp nu fr fs nv fu fw dk translated">这种新方法能够生成一个完整的三维场景，并且能够决定场景的光照</h3></div><div class="nx l"><p class="bd b dl z fp nu fr fs nv fu fw dk translated">medium.com</p></div></div><div class="ny l"><div class="of l oa ob oc ny od lb np"/></div></div></a></div><p id="fbbc" class="pw-post-body-paragraph ld le it lf b lg lh kd li lj lk kg ll lm ln lo lp lq lr ls lt lu lv lw lx ly im bi translated"><a class="ae lz" href="https://people.eecs.berkeley.edu/~pratul/nerv/" rel="noopener ugc nofollow" target="_blank">点击此处查看神经代码<em class="ma">(即将推出)</em> </a></p></div><div class="ab cl mv mw hx mx" role="separator"><span class="my bw bk mz na nb"/><span class="my bw bk mz na nb"/><span class="my bw bk mz na"/></div><div class="im in io ip iq"><h1 id="a122" class="mb mc it bd md me nc mg mh mi nd mk ml ki ne kj mn kl nf km mp ko ng kp mr ms bi translated"><a class="ae lz" href="https://arxiv.org/abs/2004.10934" rel="noopener ugc nofollow" target="_blank"> YOLOv4:物体检测的最佳速度和精度</a> [4]</h1><p id="6399" class="pw-post-body-paragraph ld le it lf b lg nh kd li lj ni kg ll lm nj lo lp lq nk ls lt lu nl lw lx ly im bi translated">这个第四版最近在2020年4月由Alexey Bochkovsky等人在论文“YOLOv4:物体检测的最佳速度和精度”中介绍。该算法的主要目标是制造一个在准确性方面具有高质量的超快速对象检测器。</p><figure class="ks kt ku kv gt kw"><div class="bz fp l di"><div class="mt mu l"/></div></figure><div class="nm nn gp gr no np"><a href="https://medium.com/what-is-artificial-intelligence/the-yolov4-algorithm-introduction-to-you-only-look-once-version-4-real-time-object-detection-5fd8a608b0fa" rel="noopener follow" target="_blank"><div class="nq ab fo"><div class="nr ab ns cl cj nt"><h2 class="bd jd gy z fp nu fr fs nv fu fw jc bi translated">YOLOv4算法|只看一次的介绍，第4版|实时对象检测</h2><div class="nw l"><h3 class="bd b gy z fp nu fr fs nv fu fw dk translated">我最近发表了一篇文章，解释了“你只看一次”的基本原理，也就是众所周知的YOLO算法。还有…</h3></div><div class="nx l"><p class="bd b dl z fp nu fr fs nv fu fw dk translated">medium.com</p></div></div><div class="ny l"><div class="og l oa ob oc ny od lb np"/></div></div></a></div><p id="48b6" class="pw-post-body-paragraph ld le it lf b lg lh kd li lj lk kg ll lm ln lo lp lq lr ls lt lu lv lw lx ly im bi translated"><a class="ae lz" href="https://github.com/AlexeyAB/darknet" rel="noopener ugc nofollow" target="_blank">点击此处获取Yolo v4代码</a></p></div><div class="ab cl mv mw hx mx" role="separator"><span class="my bw bk mz na nb"/><span class="my bw bk mz na nb"/><span class="my bw bk mz na"/></div><div class="im in io ip iq"><h1 id="fe28" class="mb mc it bd md me nc mg mh mi nd mk ml ki ne kj mn kl nf km mp ko ng kp mr ms bi translated"><a class="ae lz" href="https://arxiv.org/abs/2003.03808" rel="noopener ugc nofollow" target="_blank">脉冲:通过生成模型的潜在空间探索进行自我监督的照片上采样</a> [5]</h1><p id="09ad" class="pw-post-body-paragraph ld le it lf b lg nh kd li lj ni kg ll lm nj lo lp lq nk ls lt lu nl lw lx ly im bi translated">这种新算法将模糊图像转换成高分辨率图像！<br/>它可以拍摄超低分辨率的16x16图像，并将其变成1080p高清人脸！你不相信我？然后你可以像我一样做，在一分钟之内在自己身上试试！但首先，让我们看看他们是如何做到的。</p><figure class="ks kt ku kv gt kw"><div class="bz fp l di"><div class="mt mu l"/></div></figure><div class="nm nn gp gr no np"><a href="https://medium.com/what-is-artificial-intelligence/this-ai-makes-blurry-faces-look-60-times-sharper-7fcd3b820910" rel="noopener follow" target="_blank"><div class="nq ab fo"><div class="nr ab ns cl cj nt"><h2 class="bd jd gy z fp nu fr fs nv fu fw jc bi translated">这种人工智能使模糊的脸看起来清晰60倍</h2><div class="nw l"><h3 class="bd b gy z fp nu fr fs nv fu fw dk translated">这种新算法将模糊图像转换成高分辨率图像！它可以拍摄超低分辨率的16x16图像…</h3></div><div class="nx l"><p class="bd b dl z fp nu fr fs nv fu fw dk translated">medium.com</p></div></div><div class="ny l"><div class="oh l oa ob oc ny od lb np"/></div></div></a></div><p id="d414" class="pw-post-body-paragraph ld le it lf b lg lh kd li lj lk kg ll lm ln lo lp lq lr ls lt lu lv lw lx ly im bi translated"><a class="ae lz" href="https://github.com/adamian98/pulse" rel="noopener ugc nofollow" target="_blank">点击此处获取脉冲代码</a></p></div><div class="ab cl mv mw hx mx" role="separator"><span class="my bw bk mz na nb"/><span class="my bw bk mz na nb"/><span class="my bw bk mz na"/></div><div class="im in io ip iq"><h1 id="66ad" class="mb mc it bd md me nc mg mh mi nd mk ml ki ne kj mn kl nf km mp ko ng kp mr ms bi translated"><a class="ae lz" href="https://openai.com/blog/image-gpt/" rel="noopener ugc nofollow" target="_blank">图像GPT——从像素生成的预训练</a> [6]</h1><p id="a39c" class="pw-post-body-paragraph ld le it lf b lg nh kd li lj ni kg ll lm nj lo lp lq nk ls lt lu nl lw lx ly im bi translated">一个好的人工智能，如Gmail中使用的人工智能，可以生成连贯的文本并完成你的短语。这一个使用相同的原则为了完成一幅图像！所有这些都是在无人监督的训练中完成的，根本不需要任何标签！</p><figure class="ks kt ku kv gt kw"><div class="bz fp l di"><div class="mt mu l"/></div></figure><div class="nm nn gp gr no np"><a href="https://medium.com/towards-artificial-intelligence/this-ai-can-generate-the-pixels-of-half-of-a-picture-from-nothing-using-a-nlp-model-7d7ba14b5522" rel="noopener follow" target="_blank"><div class="nq ab fo"><div class="nr ab ns cl cj nt"><h2 class="bd jd gy z fp nu fr fs nv fu fw jc bi translated">这个人工智能可以使用GPT模型生成另一半图片</h2><div class="nw l"><h3 class="bd b gy z fp nu fr fs nv fu fw dk translated">一个好的人工智能，如Gmail中使用的人工智能，可以生成连贯的文本并完成你的短语。这一个使用相同的…</h3></div><div class="nx l"><p class="bd b dl z fp nu fr fs nv fu fw dk translated">medium.com</p></div></div><div class="ny l"><div class="oi l oa ob oc ny od lb np"/></div></div></a></div><p id="2ca9" class="pw-post-body-paragraph ld le it lf b lg lh kd li lj lk kg ll lm ln lo lp lq lr ls lt lu lv lw lx ly im bi translated"><a class="ae lz" href="https://github.com/openai/image-gpt" rel="noopener ugc nofollow" target="_blank">点击此处获取OpenAI的图像GPT代码</a></p></div><div class="ab cl mv mw hx mx" role="separator"><span class="my bw bk mz na nb"/><span class="my bw bk mz na nb"/><span class="my bw bk mz na"/></div><div class="im in io ip iq"><h1 id="fcc3" class="mb mc it bd md me nc mg mh mi nd mk ml ki ne kj mn kl nf km mp ko ng kp mr ms bi translated"><a class="ae lz" href="http://geometrylearning.com/paper/DeepFaceDrawing.pdf" rel="noopener ugc nofollow" target="_blank"> DeepFaceDrawing:从草图深度生成人脸图像</a>【7】</h1><p id="fc54" class="pw-post-body-paragraph ld le it lf b lg nh kd li lj ni kg ll lm nj lo lp lq nk ls lt lu nl lw lx ly im bi translated">您现在可以使用这种新的图像到图像的翻译技术，从粗糙甚至不完整的草图中生成高质量的人脸图像，而无需任何绘图技能！如果你的绘画技巧和我一样差，你甚至可以调整眼睛、嘴巴和鼻子对最终图像的影响！让我们看看它是否真的有效，以及他们是如何做到的。</p><figure class="ks kt ku kv gt kw"><div class="bz fp l di"><div class="mt mu l"/></div></figure><div class="nm nn gp gr no np"><a href="https://medium.com/what-is-artificial-intelligence/ai-generates-real-faces-from-sketches-8ccbac5d2b2e" rel="noopener follow" target="_blank"><div class="nq ab fo"><div class="nr ab ns cl cj nt"><h2 class="bd jd gy z fp nu fr fs nv fu fw jc bi translated">AI从草图生成真实人脸！</h2><div class="nw l"><h3 class="bd b gy z fp nu fr fs nv fu fw dk translated">您现在可以使用……从粗糙甚至不完整的草图生成高质量的人脸图像，而无需任何绘图技能</h3></div><div class="nx l"><p class="bd b dl z fp nu fr fs nv fu fw dk translated">medium.com</p></div></div><div class="ny l"><div class="oj l oa ob oc ny od lb np"/></div></div></a></div><p id="f189" class="pw-post-body-paragraph ld le it lf b lg lh kd li lj lk kg ll lm ln lo lp lq lr ls lt lu lv lw lx ly im bi translated"><a class="ae lz" href="https://github.com/IGLICT/DeepFaceDrawing-Jittor" rel="noopener ugc nofollow" target="_blank">点击此处获取深度绘制代码</a></p></div><div class="ab cl mv mw hx mx" role="separator"><span class="my bw bk mz na nb"/><span class="my bw bk mz na nb"/><span class="my bw bk mz na"/></div><div class="im in io ip iq"><h1 id="7d7c" class="mb mc it bd md me nc mg mh mi nd mk ml ki ne kj mn kl nf km mp ko ng kp mr ms bi translated"><a class="ae lz" href="https://arxiv.org/pdf/2004.00452.pdf" rel="noopener ugc nofollow" target="_blank"> PIFuHD:用于高分辨率3D人体数字化的多级像素对齐隐函数</a>【8】</h1><p id="36e1" class="pw-post-body-paragraph ld le it lf b lg nh kd li lj ni kg ll lm nj lo lp lq nk ls lt lu nl lw lx ly im bi translated">这个人工智能从2D图像中生成人的3D高分辨率重建！它只需要一张你的照片就能生成一个看起来和你一模一样的3D头像，甚至从背后看也是如此！</p><figure class="ks kt ku kv gt kw"><div class="bz fp l di"><div class="mt mu l"/></div></figure><div class="nm nn gp gr no np"><a href="https://medium.com/towards-artificial-intelligence/ai-generates-3d-high-resolution-reconstructions-of-people-from-2d-images-introduction-to-pifuhd-d4aa515a482a" rel="noopener follow" target="_blank"><div class="nq ab fo"><div class="nr ab ns cl cj nt"><h2 class="bd jd gy z fp nu fr fs nv fu fw jc bi translated">人工智能从2D图像中生成人的3D高分辨率重建</h2><div class="nw l"><h3 class="bd b gy z fp nu fr fs nv fu fw dk translated">这个人工智能从2D图像中生成人的3D高分辨率重建！只需要一张你的照片…</h3></div><div class="nx l"><p class="bd b dl z fp nu fr fs nv fu fw dk translated">medium.com</p></div></div><div class="ny l"><div class="ok l oa ob oc ny od lb np"/></div></div></a></div><p id="0b16" class="pw-post-body-paragraph ld le it lf b lg lh kd li lj lk kg ll lm ln lo lp lq lr ls lt lu lv lw lx ly im bi translated"><a class="ae lz" href="https://github.com/facebookresearch/pifuhd" rel="noopener ugc nofollow" target="_blank">点击此处获取PiFuHD代码</a></p></div><div class="ab cl mv mw hx mx" role="separator"><span class="my bw bk mz na nb"/><span class="my bw bk mz na nb"/><span class="my bw bk mz na"/></div><div class="im in io ip iq"><h1 id="62fa" class="mb mc it bd md me nc mg mh mi nd mk ml ki ne kj mn kl nf km mp ko ng kp mr ms bi translated"><a class="ae lz" href="https://arxiv.org/pdf/2003.12039.pdf" rel="noopener ugc nofollow" target="_blank"> RAFT:用于光流的循环全对场变换</a>【9】</h1><p id="351d" class="pw-post-body-paragraph ld le it lf b lg nh kd li lj ni kg ll lm nj lo lp lq nk ls lt lu nl lw lx ly im bi translated">普林斯顿团队获得ECCV 2020年最佳论文奖。他们为光流开发了一种新的端到端可训练模型。他们的方法在多个数据集上击败了最先进的架构的准确性，并且更加高效。他们甚至在Github上向所有人开放代码！</p><figure class="ks kt ku kv gt kw"><div class="bz fp l di"><div class="mt mu l"/></div></figure><div class="nm nn gp gr no np"><a href="https://medium.com/towards-artificial-intelligence/eccv-2020-best-paper-award-a-new-architecture-for-optical-flow-3298c8a40dc7" rel="noopener follow" target="_blank"><div class="nq ab fo"><div class="nr ab ns cl cj nt"><h2 class="bd jd gy z fp nu fr fs nv fu fw jc bi translated">ECCV 2020最佳论文奖|光流的新架构</h2><div class="nw l"><h3 class="bd b gy z fp nu fr fs nv fu fw dk translated">普林斯顿团队获得ECCV 2020年最佳论文奖。他们为光流开发了一个新的端到端可训练模型…</h3></div><div class="nx l"><p class="bd b dl z fp nu fr fs nv fu fw dk translated">medium.com</p></div></div><div class="ny l"><div class="ol l oa ob oc ny od lb np"/></div></div></a></div><p id="f111" class="pw-post-body-paragraph ld le it lf b lg lh kd li lj lk kg ll lm ln lo lp lq lr ls lt lu lv lw lx ly im bi translated"><a class="ae lz" href="https://github.com/princeton-vl/RAFT" rel="noopener ugc nofollow" target="_blank">点击此处获取RAFT代码</a></p></div><div class="ab cl mv mw hx mx" role="separator"><span class="my bw bk mz na nb"/><span class="my bw bk mz na nb"/><span class="my bw bk mz na"/></div><div class="im in io ip iq"><h1 id="0148" class="mb mc it bd md me nc mg mh mi nd mk ml ki ne kj mn kl nf km mp ko ng kp mr ms bi translated"><a class="ae lz" href="https://arxiv.org/abs/2007.10247" rel="noopener ugc nofollow" target="_blank">学习视频修复的联合时空变换</a>【10】</h1><p id="1762" class="pw-post-body-paragraph ld le it lf b lg nh kd li lj ni kg ll lm nj lo lp lq nk ls lt lu nl lw lx ly im bi translated">这种人工智能可以填充移动物体背后的缺失像素，并以比当前最先进的方法更准确、更少模糊的方式重建整个视频！</p><figure class="ks kt ku kv gt kw"><div class="bz fp l di"><div class="mt mu l"/></div></figure><div class="nm nn gp gr no np"><a href="https://medium.com/towards-artificial-intelligence/this-ai-takes-a-video-and-fills-the-missing-pixels-behind-an-object-video-inpainting-9be38e141f46" rel="noopener follow" target="_blank"><div class="nq ab fo"><div class="nr ab ns cl cj nt"><h2 class="bd jd gy z fp nu fr fs nv fu fw jc bi translated">这个AI拍摄一个视频，并填充一个对象后面缺失的像素！</h2><div class="nw l"><h3 class="bd b gy z fp nu fr fs nv fu fw dk translated">视频修复—微软研究院</h3></div><div class="nx l"><p class="bd b dl z fp nu fr fs nv fu fw dk translated">medium.com</p></div></div><div class="ny l"><div class="om l oa ob oc ny od lb np"/></div></div></a></div><p id="a627" class="pw-post-body-paragraph ld le it lf b lg lh kd li lj lk kg ll lm ln lo lp lq lr ls lt lu lv lw lx ly im bi translated"><a class="ae lz" href="https://github.com/researchmm/STTN?utm_source=catalyzex.com" rel="noopener ugc nofollow" target="_blank">点击此处获取此视频修复代码</a></p></div><div class="ab cl mv mw hx mx" role="separator"><span class="my bw bk mz na nb"/><span class="my bw bk mz na nb"/><span class="my bw bk mz na"/></div><div class="im in io ip iq"><h1 id="9b63" class="mb mc it bd md me nc mg mh mi nd mk ml ki ne kj mn kl nf km mp ko ng kp mr ms bi translated"><a class="ae lz" href="https://arxiv.org/pdf/2009.07047.pdf" rel="noopener ugc nofollow" target="_blank">通过深层潜在空间平移修复旧照片</a>【加成1】</h1><p id="adb4" class="pw-post-body-paragraph ld le it lf b lg nh kd li lj ni kg ll lm nj lo lp lq nk ls lt lu nl lw lx ly im bi translated">想象一下，你有你祖母18岁时的旧的，折叠的，甚至撕破的高清照片，没有任何瑕疵。这被称为旧照片恢复，这篇论文刚刚开辟了一条全新的途径，使用深度学习方法来解决这个问题。</p><figure class="ks kt ku kv gt kw"><div class="bz fp l di"><div class="mt mu l"/></div></figure><div class="nm nn gp gr no np"><a href="https://medium.com/towards-artificial-intelligence/old-photo-restoration-using-deep-learning-47d4ab1bdc4d" rel="noopener follow" target="_blank"><div class="nq ab fo"><div class="nr ab ns cl cj nt"><h2 class="bd jd gy z fp nu fr fs nv fu fw jc bi translated">使用深度学习的旧照片恢复</h2><div class="nw l"><h3 class="bd b gy z fp nu fr fs nv fu fw dk translated">想象一下，拥有你祖母18岁时的旧的、折叠的、甚至撕破的高清照片…</h3></div><div class="nx l"><p class="bd b dl z fp nu fr fs nv fu fw dk translated">medium.com</p></div></div><div class="ny l"><div class="on l oa ob oc ny od lb np"/></div></div></a></div><p id="9596" class="pw-post-body-paragraph ld le it lf b lg lh kd li lj lk kg ll lm ln lo lp lq lr ls lt lu lv lw lx ly im bi translated"><a class="ae lz" href="https://github.com/microsoft/Bringing-Old-Photos-Back-to-Life?utm_source=catalyzex.com" rel="noopener ugc nofollow" target="_blank">点击此处获取旧照片复原码</a></p></div><div class="ab cl mv mw hx mx" role="separator"><span class="my bw bk mz na nb"/><span class="my bw bk mz na nb"/><span class="my bw bk mz na"/></div><div class="im in io ip iq"><h1 id="7748" class="mb mc it bd md me nc mg mh mi nd mk ml ki ne kj mn kl nf km mp ko ng kp mr ms bi translated"><a class="ae lz" href="https://arxiv.org/pdf/2011.11961.pdf" rel="noopener ugc nofollow" target="_blank">实时人像抠图真的需要绿色屏幕吗？</a>【加成2】</h1><p id="d21b" class="pw-post-body-paragraph ld le it lf b lg nh kd li lj ni kg ll lm nj lo lp lq nk ls lt lu nl lw lx ly im bi translated">人体抠图是一项非常有趣的任务，目标是找到照片中的任何人，并从照片中移除背景。由于任务的复杂性，这真的很难实现，必须找到具有完美轮廓的人。在这篇文章中，我回顾了多年来使用的最佳技术和2020年11月29日发表的一种新颖的方法。许多技术正在使用基本的计算机视觉算法来完成这项任务，例如GrabCut算法，它速度极快，但不是很精确。</p><figure class="ks kt ku kv gt kw"><div class="bz fp l di"><div class="mt mu l"/></div></figure><div class="nm nn gp gr no np"><a href="https://medium.com/datadriveninvestor/high-quality-background-removal-without-green-screens-8e61c69de63" rel="noopener follow" target="_blank"><div class="nq ab fo"><div class="nr ab ns cl cj nt"><h2 class="bd jd gy z fp nu fr fs nv fu fw jc bi translated">没有绿屏的高质量背景消除</h2><div class="nw l"><h3 class="bd b gy z fp nu fr fs nv fu fw dk translated">这种新的背景去除技术可以从单个输入图像中提取一个人，而不需要绿色的…</h3></div><div class="nx l"><p class="bd b dl z fp nu fr fs nv fu fw dk translated">medium.com</p></div></div><div class="ny l"><div class="oo l oa ob oc ny od lb np"/></div></div></a></div><p id="a3c9" class="pw-post-body-paragraph ld le it lf b lg lh kd li lj lk kg ll lm ln lo lp lq lr ls lt lu lv lw lx ly im bi translated"><a class="ae lz" href="https://github.com/ZHKKKe/MODNet" rel="noopener ugc nofollow" target="_blank">点击这里获取MODNet代码</a></p></div><div class="ab cl mv mw hx mx" role="separator"><span class="my bw bk mz na nb"/><span class="my bw bk mz na nb"/><span class="my bw bk mz na"/></div><div class="im in io ip iq"><h1 id="790e" class="mb mc it bd md me nc mg mh mi nd mk ml ki ne kj mn kl nf km mp ko ng kp mr ms bi translated">解除锁定【奖励3】</h1><p id="371e" class="pw-post-body-paragraph ld le it lf b lg nh kd li lj ni kg ll lm nj lo lp lq nk ls lt lu nl lw lx ly im bi translated">DeOldify是一种彩色化和恢复旧黑白图像甚至电影胶片的技术。它是由一个人Jason Antic开发并更新的。这是现在最先进的黑白图像彩色化方法，一切都是开源的，但是我们一会儿会回到这个话题。</p><figure class="ks kt ku kv gt kw"><div class="bz fp l di"><div class="mt mu l"/></div></figure><div class="nm nn gp gr no np"><a href="https://medium.com/towards-artificial-intelligence/this-ai-can-colorize-your-black-white-photos-with-full-photorealistic-renders-deoldify-bf1eed5cb02a" rel="noopener follow" target="_blank"><div class="nq ab fo"><div class="nr ab ns cl cj nt"><h2 class="bd jd gy z fp nu fr fs nv fu fw jc bi translated">这个人工智能可以为你的黑白照片着色，呈现出真实的照片效果！(解密)</h2><div class="nw l"><h3 class="bd b gy z fp nu fr fs nv fu fw dk translated">这种方法被称为DeOldify，几乎适用于任何图片。如果你不相信我，你甚至可以尝试一下…</h3></div><div class="nx l"><p class="bd b dl z fp nu fr fs nv fu fw dk translated">medium.com</p></div></div><div class="ny l"><div class="op l oa ob oc ny od lb np"/></div></div></a></div><p id="7e55" class="pw-post-body-paragraph ld le it lf b lg lh kd li lj lk kg ll lm ln lo lp lq lr ls lt lu lv lw lx ly im bi translated"><a class="ae lz" href="https://github.com/jantic/DeOldify" rel="noopener ugc nofollow" target="_blank">点击此处获取解除代码</a></p></div><div class="ab cl mv mw hx mx" role="separator"><span class="my bw bk mz na nb"/><span class="my bw bk mz na nb"/><span class="my bw bk mz na"/></div><div class="im in io ip iq"><h1 id="f244" class="mb mc it bd md me nc mg mh mi nd mk ml ki ne kj mn kl nf km mp ko ng kp mr ms bi translated">结论</h1><p id="a97a" class="pw-post-body-paragraph ld le it lf b lg nh kd li lj ni kg ll lm nj lo lp lq nk ls lt lu nl lw lx ly im bi translated">如你所见，对于计算机视觉来说，这是极具洞察力的一年。我一定会报道2021年最令人兴奋和有趣的论文，如果你能参加这次冒险，我会很高兴的！如果你喜欢我的工作，并想了解最新的人工智能技术，你绝对应该在我的社交媒体频道上关注我。</p><ul class=""><li id="9cb2" class="oq or it lf b lg lh lj lk lm os lq ot lu ou ly ov ow ox oy bi translated">支持我的最好方式就是在<a class="ae lz" href="https://medium.com/@whats-ai" rel="noopener"> <strong class="lf jd">中</strong> </a>关注我。</li><li id="9652" class="oq or it lf b lg oz lj pa lm pb lq pc lu pd ly ov ow ox oy bi translated">订阅我的<a class="ae lz" href="https://www.youtube.com/channel/UCUzGQrN-lyyc0BWTYoJM_Sg" rel="noopener ugc nofollow" target="_blank"> <strong class="lf jd"> YouTube频道</strong> </a>。</li><li id="e390" class="oq or it lf b lg oz lj pa lm pb lq pc lu pd ly ov ow ox oy bi translated">在<a class="ae lz" href="https://www.linkedin.com/in/whats-ai/" rel="noopener ugc nofollow" target="_blank"><strong class="lf jd">LinkedIn</strong></a><strong class="lf jd">上关注我的项目。</strong></li><li id="564e" class="oq or it lf b lg oz lj pa lm pb lq pc lu pd ly ov ow ox oy bi translated">一起学习AI，加入我们的<a class="ae lz" href="https://discord.gg/learnaitogether" rel="noopener ugc nofollow" target="_blank"> <strong class="lf jd"> Discord社区</strong> </a>，<em class="ma">分享你的项目、论文、最佳课程，寻找Kaggle队友，等等！</em></li><li id="fd81" class="oq or it lf b lg oz lj pa lm pb lq pc lu pd ly ov ow ox oy bi translated">订阅我的<a class="ae lz" href="http://eepurl.com/huGLT5" rel="noopener ugc nofollow" target="_blank"> <strong class="lf jd">简讯</strong> </a>！</li></ul><p id="7ab3" class="pw-post-body-paragraph ld le it lf b lg lh kd li lj lk kg ll lm ln lo lp lq lr ls lt lu lv lw lx ly im bi translated"><a class="ae lz" href="https://github.com/louisfb01/Top-10-Computer-Vision-Papers-2020" rel="noopener ugc nofollow" target="_blank"> <strong class="lf jd"> <em class="ma">访问GitHub存储库中的完整列表</em> </strong> </a></p><p id="9218" class="pw-post-body-paragraph ld le it lf b lg lh kd li lj lk kg ll lm ln lo lp lq lr ls lt lu lv lw lx ly im bi translated"><strong class="lf jd"> <em class="ma">在</em></strong><a class="ae lz" href="https://twitter.com/Whats_AI" rel="noopener ugc nofollow" target="_blank"><strong class="lf jd"><em class="ma">Twitter(@ Whats _ AI)</em></strong></a><strong class="lf jd"><em class="ma">或</em></strong><a class="ae lz" href="https://www.linkedin.com/in/whats-ai/" rel="noopener ugc nofollow" target="_blank"><strong class="lf jd"><em class="ma">LinkedIn(Louis(What ' s AI)</em></strong></a><strong class="lf jd"><em class="ma">如果分享文章！</em> </strong></p></div><div class="ab cl mv mw hx mx" role="separator"><span class="my bw bk mz na nb"/><span class="my bw bk mz na nb"/><span class="my bw bk mz na"/></div><div class="im in io ip iq"><h1 id="41fe" class="mb mc it bd md me nc mg mh mi nd mk ml ki ne kj mn kl nf km mp ko ng kp mr ms bi translated">如果你对人工智能研究感兴趣，这里有另一篇很棒的文章给你:</h1><div class="nm nn gp gr no np"><a href="https://medium.com/towards-artificial-intelligence/2020-a-year-full-of-amazing-ai-papers-a-review-c42fa07aff4b" rel="noopener follow" target="_blank"><div class="nq ab fo"><div class="nr ab ns cl cj nt"><h2 class="bd jd gy z fp nu fr fs nv fu fw jc bi translated">2020:充满惊人人工智能论文的一年——综述</h2><div class="nw l"><h3 class="bd b gy z fp nu fr fs nv fu fw dk translated">按发布日期排列的人工智能最新突破的精选列表，带有清晰的视频解释，链接到更多…</h3></div><div class="nx l"><p class="bd b dl z fp nu fr fs nv fu fw dk translated">medium.com</p></div></div><div class="ny l"><div class="pe l oa ob oc ny od lb np"/></div></div></a></div></div><div class="ab cl mv mw hx mx" role="separator"><span class="my bw bk mz na nb"/><span class="my bw bk mz na nb"/><span class="my bw bk mz na"/></div><div class="im in io ip iq"><h1 id="2ce7" class="mb mc it bd md me nc mg mh mi nd mk ml ki ne kj mn kl nf km mp ko ng kp mr ms bi translated">论文参考</h1><p id="899a" class="pw-post-body-paragraph ld le it lf b lg nh kd li lj ni kg ll lm nj lo lp lq nk ls lt lu nl lw lx ly im bi translated">[1] Akkaynak，Derya &amp; Treibitz，程昕婷。(2019).一种从水下图像中去除水分的方法。1682–1691.10.1109/CVPR</p><p id="44e1" class="pw-post-body-paragraph ld le it lf b lg lh kd li lj lk kg ll lm ln lo lp lq lr ls lt lu lv lw lx ly im bi translated">[2] Lechner，m .，Hasani，r .，Amini，A. <em class="ma">等</em>启用可审计自主性的神经回路策略。<em class="ma">国家机器智能</em> <strong class="lf jd"> 2，</strong>642–652(2020)。<a class="ae lz" href="https://doi.org/10.1038/s42256-020-00237-3" rel="noopener ugc nofollow" target="_blank">https://doi.org/10.1038/s42256-020-00237-3</a></p><p id="9406" class="pw-post-body-paragraph ld le it lf b lg lh kd li lj lk kg ll lm ln lo lp lq lr ls lt lu lv lw lx ly im bi translated">[3] P. P. Srinivasan、B. Deng、X. Zhang、M. Tancik、B. Mildenhall和J. T. Barron，“Nerv:用于重新照明和视图合成的神经反射和可见度场”，arXiv，2020年。</p><p id="1922" class="pw-post-body-paragraph ld le it lf b lg lh kd li lj lk kg ll lm ln lo lp lq lr ls lt lu lv lw lx ly im bi translated">[4] A. Bochkovskiy，C.-Y. Wang，和H.-Y. M .廖，Yolov4:物体探测的最佳速度和精度，2020年。arXiv:2004.10934 [cs。简历】。</p><p id="0890" class="pw-post-body-paragraph ld le it lf b lg lh kd li lj lk kg ll lm ln lo lp lq lr ls lt lu lv lw lx ly im bi translated">[5] S. Menon，A. Damian，S. Hu，N. Ravi和C. Rudin，Pulse:通过生成模型的潜在空间探索进行自我监督的照片上采样，2020年。arXiv:2003.03808 [cs。简历】。</p><p id="e682" class="pw-post-body-paragraph ld le it lf b lg lh kd li lj lk kg ll lm ln lo lp lq lr ls lt lu lv lw lx ly im bi translated">[6] M. Chen，a .，R. Child，J. Wu，H. Jun，D. Luan和I. Sutskever，“从像素进行生成性预训练”，载于第37届机器学习国际会议论文集，H. D. III和A. Singh编辑。，爵士。机器学习研究会议录，第119卷，虚拟:PMLR，2020年7月13-18日，第1691-1703页。【在线】。</p><p id="d50e" class="pw-post-body-paragraph ld le it lf b lg lh kd li lj lk kg ll lm ln lo lp lq lr ls lt lu lv lw lx ly im bi translated">[7]陈世友、苏文伟、高、夏、傅，“深度人脸绘制:从草图深度生成人脸图像”，《美国计算机图形学学报》(2020年美国计算机图形学学报)，第39卷，第4期，72:1–72:16，2020。可查:http://proceedings . MLR . press/v 119/Chen 20s . html</p><p id="e704" class="pw-post-body-paragraph ld le it lf b lg lh kd li lj lk kg ll lm ln lo lp lq lr ls lt lu lv lw lx ly im bi translated">[8] S. Saito，T. Simon，J. Saragih，和H. Joo，Pifuhd:用于高分辨率3d人体数字化的多级像素对齐隐函数，2020年。arXiv:2004.00452 [cs。简历】。</p><p id="fb5d" class="pw-post-body-paragraph ld le it lf b lg lh kd li lj lk kg ll lm ln lo lp lq lr ls lt lu lv lw lx ly im bi translated">[9] Z. Teed和J. Deng，Raft:用于光流的循环所有对场变换，2020年。arXiv:2003.12039 [cs。简历】。</p><p id="ef25" class="pw-post-body-paragraph ld le it lf b lg lh kd li lj lk kg ll lm ln lo lp lq lr ls lt lu lv lw lx ly im bi translated">[10]曾玉燕，傅俊杰，赵海峰，学习视频嵌入的联合时空变换，2020 .arXiv:2007.10247 [cs。简历】。</p><p id="9b65" class="pw-post-body-paragraph ld le it lf b lg lh kd li lj lk kg ll lm ln lo lp lq lr ls lt lu lv lw lx ly im bi translated">[附加1]万，张，陈，张，陈，廖，文，2020。arXiv:2009.07047 [cs。简历】。</p><p id="c8ed" class="pw-post-body-paragraph ld le it lf b lg lh kd li lj lk kg ll lm ln lo lp lq lr ls lt lu lv lw lx ly im bi translated">[附加信息2]柯志群、李克强、周永源、吴清源、毛晓东、严清源和刘瑞伟，“实时人像抠图真的需要绿色屏幕吗？”ArXiv，第abs/2011.11961卷，2020年。</p><p id="ee10" class="pw-post-body-paragraph ld le it lf b lg lh kd li lj lk kg ll lm ln lo lp lq lr ls lt lu lv lw lx ly im bi translated">[奖金3]贾森·安蒂奇，DeOldify，<a class="ae lz" href="https://github.com/jantic/DeOldify" rel="noopener ugc nofollow" target="_blank">https://github.com/jantic/DeOldify</a>的创造者</p></div></div>    
</body>
</html>