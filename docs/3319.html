<html>
<head>
<title>Building a Recommender System Using TFRS</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">利用TFRS构建推荐系统</h1>
<blockquote>原文：<a href="https://pub.towardsai.net/building-a-recommender-system-using-tfrs-4043db00ab79?source=collection_archive---------2-----------------------#2022-11-17">https://pub.towardsai.net/building-a-recommender-system-using-tfrs-4043db00ab79?source=collection_archive---------2-----------------------#2022-11-17</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="8afb" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">第1部分:简介、导入和清理数据集</h2></div><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ki"><img src="../Images/4368f79511d1594d756b1603866f6c11.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*5vEoLc-KQbfOStU8"/></div></div><figcaption class="ku kv gj gh gi kw kx bd b be z dk translated">Alesia Kazantceva 在<a class="ae ky" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上拍摄的照片</figcaption></figure><p id="5b2e" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">不知道接下来看什么电影，看什么文章，或者买什么产品？有数以百万计的产品和服务可供选择，如今的客户比以往任何时候都更容易受到选择过多的困扰，这就是推荐系统拯救世界的地方，它们能够不断地向客户推荐有利可图的节目和产品。如今，许多公司都在花费小笔财富来构建和不断改进他们自己的推荐系统，因此毫不奇怪，对于一些公司来说，他们创造的大部分收入完全是由这种复杂的系统带来的。那么推荐系统的其他好处是什么呢？有哪些著名的公司使用这种系统呢？</p><h1 id="12dc" class="lv lw it bd lx ly lz ma mb mc md me mf jz mg ka mh kc mi kd mj kf mk kg ml mm bi translated">推荐系统的好处</h1><h1 id="9337" class="lv lw it bd lx ly lz ma mb mc md me mf jz mg ka mh kc mi kd mj kf mk kg ml mm bi translated">1-增加销售动力</h1><p id="0745" class="pw-post-body-paragraph kz la it lb b lc mn ju le lf mo jx lh li mp lk ll lm mq lo lp lq mr ls lt lu im bi translated">随着向用户提供个性化的产品和服务，预计将产生更多的销售，客户更有可能购买与他们以前购买的产品味道相似的产品。</p><h1 id="4302" class="lv lw it bd lx ly lz ma mb mc md me mf jz mg ka mh kc mi kd mj kf mk kg ml mm bi translated">2-提供更好的用户体验</h1><p id="9af6" class="pw-post-body-paragraph kz la it lb b lc mn ju le lf mo jx lh li mp lk ll lm mq lo lp lq mr ls lt lu im bi translated">推荐系统通过不断地向客户提供他们自己的个性化销售人员，为客户提供独特的关怀感和优质体验，这些销售人员在什么产品或服务适合客户口味方面具有丰富的专业知识。</p><h1 id="6ad1" class="lv lw it bd lx ly lz ma mb mc md me mf jz mg ka mh kc mi kd mj kf mk kg ml mm bi translated">3-提高客户参与度</h1><p id="2162" class="pw-post-body-paragraph kz la it lb b lc mn ju le lf mo jx lh li mp lk ll lm mq lo lp lq mr ls lt lu im bi translated">通过不断地引导顾客到他们喜欢的产品、展览、文章等等，顾客不太可能因为有大量的选择而感到困惑。这种指导将使客户对特定服务提供的内容更感兴趣。</p><h1 id="1b43" class="lv lw it bd lx ly lz ma mb mc md me mf jz mg ka mh kc mi kd mj kf mk kg ml mm bi translated">现实生活中的推荐系统示例</h1><ol class=""><li id="2326" class="ms mt it lb b lc mn lf mo li mu lm mv lq mw lu mx my mz na bi translated">油管（国外视频网站）</li></ol><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi nb"><img src="../Images/3afb8762fa651b8b921e14122d8daeee.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*T5_0cFAnuCpA5Ced"/></div></div><figcaption class="ku kv gj gh gi kw kx bd b be z dk translated">Youtube推荐系统的图片(<a class="ae ky" href="https://www.socialnationnow.com/youtubes-recommendation-system/" rel="noopener ugc nofollow" target="_blank">来源</a>)</figcaption></figure><p id="eb5a" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">最大的推荐系统用户之一是在线视频分享和社交媒体平台Youtube。Youtube的收入主要来自其先进的推荐算法，该算法根据每个客户的独特偏好不断推荐热门视频。这种偏好可以包括相同类别的相似视频、同一创作者的视频、高度喜欢的视频等等。</p><p id="c514" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">2.亚马孙</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi nc"><img src="../Images/1ac2a94384627b9d41cbf771cf3dc1a3.png" data-original-src="https://miro.medium.com/v2/resize:fit:1150/0*4fhVCdAJIwG9dnd-"/></div><figcaption class="ku kv gj gh gi kw kx bd b be z dk translated">亚马逊推荐系统的图片(<a class="ae ky" href="https://www.rejoiner.com/resources/amazon-recommendations-secret-selling-online" rel="noopener ugc nofollow" target="_blank">来源</a>)</figcaption></figure><p id="3c7e" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">电子商务世界的另一个巨头亚马逊充分利用推荐系统，不断推荐新产品供客户选择，让客户保持稳定。</p><h1 id="183b" class="lv lw it bd lx ly lz ma mb mc md me mf jz mg ka mh kc mi kd mj kf mk kg ml mm bi translated">张量流和TFRS</h1><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi nd"><img src="../Images/e6e6ddbe05b2fed70e27b43bb20d5a6b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*bN_3FEZtVtuQ-p_g"/></div></div><figcaption class="ku kv gj gh gi kw kx bd b be z dk translated">张量流图像(<a class="ae ky" href="https://analyticsindiamag.com/tensorflow-tfrs-recommenders-package/" rel="noopener ugc nofollow" target="_blank">来源</a></figcaption></figure><p id="d485" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">由著名的张量框架创建的<a class="ae ky" href="https://www.tensorflow.org/recommenders" rel="noopener ugc nofollow" target="_blank">张量流推荐器</a>或TFRS是专门为构建推荐系统模型而创建的。除了相当容易学习之外，TensorFlow推荐框架还有助于整个推荐系统构建过程，从数据收集到评估和部署。在本文的教程部分，我们将把TensorFlow推荐系统集成到我们的推荐系统模型中，同时解释我们的模型的结构，并简要说明代码中的每个步骤。</p><h1 id="d9c4" class="lv lw it bd lx ly lz ma mb mc md me mf jz mg ka mh kc mi kd mj kf mk kg ml mm bi translated">我们的模型想要实现什么？</h1><p id="d6a5" class="pw-post-body-paragraph kz la it lb b lc mn ju le lf mo jx lh li mp lk ll lm mq lo lp lq mr ls lt lu im bi translated">在本文的实践部分，我们将提供一个机器学习模型，能够向用户建议新的Reddit帖子。我们将给出所使用的数据集，以及如何构建所需模型的分步指南。您可以使用Kaggle或GoogleColab等网站，这些网站为其用户提供了能够编译python代码的云资源和托管笔记本。</p><h1 id="d18f" class="lv lw it bd lx ly lz ma mb mc md me mf jz mg ka mh kc mi kd mj kf mk kg ml mm bi translated">资料组</h1><p id="4c9f" class="pw-post-body-paragraph kz la it lb b lc mn ju le lf mo jx lh li mp lk ll lm mq lo lp lq mr ls lt lu im bi translated">作为任何机器学习模型最重要的部分之一，我们有自己的数据集。要找到本教程中使用的数据集，请查看以下链接:<a class="ae ky" href="https://www.kaggle.com/code/gauthierhaas/tensorflow-subreddit-recommender-system/notebook" rel="noopener ugc nofollow" target="_blank"> Reddit数据</a>。这个数据集包含了数百万的Reddit帖子，以及这些帖子的用户名、帖子类别和时间戳。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ne"><img src="../Images/c8d7d08eccc355b9147a9ced168f4f64.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*6j_8U7QhA6gsQe84"/></div></div><figcaption class="ku kv gj gh gi kw kx bd b be z dk translated">Reddit数据集的图像(<a class="ae ky" href="https://www.kaggle.com/code/gauthierhaas/tensorflow-subreddit-recommender-system/data" rel="noopener ugc nofollow" target="_blank">来源</a>)</figcaption></figure><h1 id="5ee3" class="lv lw it bd lx ly lz ma mb mc md me mf jz mg ka mh kc mi kd mj kf mk kg ml mm bi translated">辅导的</h1><h1 id="0ca6" class="lv lw it bd lx ly lz ma mb mc md me mf jz mg ka mh kc mi kd mj kf mk kg ml mm bi translated">步骤1:导入所需的库</h1><p id="a49e" class="pw-post-body-paragraph kz la it lb b lc mn ju le lf mo jx lh li mp lk ll lm mq lo lp lq mr ls lt lu im bi translated">至于任何机器学习模型，我们都必须从下载我们的库和包开始。首先，我们有我们的随机包，它可以用来生成随机数。接下来，我们将使用熊猫在我们的模型中绘制不同的图形。这些图表将用于可视化，以便更好地理解模型。最后，我们有了NumPy库，它为我们提供了所需的代数函数。</p><pre class="kj kk kl km gt nf ng nh bn ni nj bi"><span id="8ebf" class="nk lw it ng b be nl nm l nn no">import random<br/>import pandas as pd<br/>import numpy as np</span></pre><p id="4182" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">步骤2:定义所需的方法</p><p id="b75f" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">在这一部分，我们将定义一些必需的方法。我们的第一个方法是<strong class="lb iu"> chunks(l，n) </strong>，它将数据集分成多个组块或片段。</p><pre class="kj kk kl km gt nf ng nh bn ni nj bi"><span id="78d8" class="nk lw it ng b be nl nm l nn no">def chunks(l, n):<br/>  n = max(1, n)<br/>return (l[i:i+n] for i in range(0, len(l), n))</span></pre><p id="d710" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">normalize(lst)方法将执行数据规范化的过程。一般来说，规范化是将数据集中的数值列的值转换为使用通用比例，而不会扭曲值范围的差异或丢失信息的过程。</p><pre class="kj kk kl km gt nf ng nh bn ni nj bi"><span id="3679" class="nk lw it ng b be nl nm l nn no">def normalize(lst):<br/>  s = sum(lst)<br/>  normed = [itm/s for itm in lst]<br/>  normed[-1] = (normed[-1] + (1-sum(normed)))#pad last value with whatever difference needed to make sum to exactly 1<br/>return normed</span></pre><p id="ddb5" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">步骤3:导入和读取我们的数据集</p><p id="5a3f" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">下载Reddit数据集后，我们将使用read_csv函数来读取存储在其中的数据。我们将使用head(100，000)方法仅获取前100，000个帖子。</p><pre class="kj kk kl km gt nf ng nh bn ni nj bi"><span id="e77e" class="nk lw it ng b be nl nm l nn no">df = pd.read_csv(“../input/reddit_data.csv”).head(100000) #reduce dataset size to first 100,000 comments</span></pre><p id="d608" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">然后，我们将计算subreddit列中唯一值的数量，还将计算每个唯一值出现的次数。之后我们会计算每个数据点的逆概率。</p><pre class="kj kk kl km gt nf ng nh bn ni nj bi"><span id="f51f" class="nk lw it ng b be nl nm l nn no">vocab_counts = df[“subreddit”].value_counts()<br/>tmp_vocab = list(vocab_counts.keys())<br/>total_counts = sum(vocab_counts.values)<br/>inv_prob = [total_counts/vocab_counts[sub] for sub in tmp_vocab]<br/>vocab = ["Unseen-Sub"] + tmp_vocab #build place holder, Unseen-Sub, for all subs not in vocab<br/>tmp_vocab_probs = normalize(inv_prob)<br/>#force probs sum to 1 by adding difference to "Unseen-sub" probability<br/>vocab_probs = [1-sum(tmp_vocab_probs)] + tmp_vocab_probs</span></pre><p id="48f7" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">在下一部分中，我们将进一步清理数据集，训练和评估模型。敬请期待！</p></div></div>    
</body>
</html>