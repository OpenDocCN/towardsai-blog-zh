<html>
<head>
<title>Clustering: What Is It and When To use it?</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">集群:什么是集群，何时使用集群？</h1>
<blockquote>原文：<a href="https://pub.towardsai.net/clustering-what-it-is-when-to-use-it-a612bbe95881?source=collection_archive---------0-----------------------#2020-06-28">https://pub.towardsai.net/clustering-what-it-is-when-to-use-it-a612bbe95881?source=collection_archive---------0-----------------------#2020-06-28</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><h2 id="1678" class="io ip iq bd b dl ir is it iu iv iw dk ix translated" aria-label="kicker paragraph"><a class="ae ep" href="https://towardsai.net/p/category/machine-learning" rel="noopener ugc nofollow" target="_blank">机器学习</a>，数据科学</h2><div class=""/><div class=""><h2 id="f2cb" class="pw-subtitle-paragraph jw iz iq bd b jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn dk translated">K-Means、K-Means++和DBSCAN综合指南。</h2></div><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div role="button" tabindex="0" class="ku kv di kw bf kx"><div class="gh gi ko"><img src="../Images/1cf2639a40f2d79bfa92a44c64413d75.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*marcjAOKogUKaOLMTtwYEg.png"/></div></div></figure><p id="3667" class="pw-post-body-paragraph la lb iq lc b ld le ka lf lg lh kd li lj lk ll lm ln lo lp lq lr ls lt lu lv ij bi translated">聚类是一种机器学习技术，其目的是将具有<strong class="lc ja">相似属性和/或特征</strong>的数据点分组，而不同组中的数据点应该具有非常不同的属性和/或特征。</p><h1 id="0ab1" class="lw lx iq bd ly lz ma mb mc md me mf mg kf mh kg mi ki mj kj mk kl ml km mm mn bi translated">目录</h1><p id="1f9f" class="pw-post-body-paragraph la lb iq lc b ld mo ka lf lg mp kd li lj mq ll lm ln mr lp lq lr ms lt lu lv ij bi translated">1.<strong class="lc ja">K-表示</strong></p><p id="985e" class="pw-post-body-paragraph la lb iq lc b ld le ka lf lg lh kd li lj lk ll lm ln lo lp lq lr ls lt lu lv ij bi translated">⦁<em class="mt">k-means简介</em></p><p id="6573" class="pw-post-body-paragraph la lb iq lc b ld le ka lf lg lh kd li lj lk ll lm ln lo lp lq lr ls lt lu lv ij bi translated"><em class="mt"> ⦁如何K-means工作？</em></p><p id="71d9" class="pw-post-body-paragraph la lb iq lc b ld le ka lf lg lh kd li lj lk ll lm ln lo lp lq lr ls lt lu lv ij bi translated"><em class="mt"> ⦁ Sci-kit实现K-means </em></p><p id="f964" class="pw-post-body-paragraph la lb iq lc b ld le ka lf lg lh kd li lj lk ll lm ln lo lp lq lr ls lt lu lv ij bi translated"><em class="mt">⦁k-means的利弊</em></p><p id="c265" class="pw-post-body-paragraph la lb iq lc b ld le ka lf lg lh kd li lj lk ll lm ln lo lp lq lr ls lt lu lv ij bi translated">2.<strong class="lc ja"> K-means ++ </strong></p><p id="6ecd" class="pw-post-body-paragraph la lb iq lc b ld le ka lf lg lh kd li lj lk ll lm ln lo lp lq lr ls lt lu lv ij bi translated"><em class="mt">⦁k-means ++是如何工作的？</em></p><p id="352e" class="pw-post-body-paragraph la lb iq lc b ld le ka lf lg lh kd li lj lk ll lm ln lo lp lq lr ls lt lu lv ij bi translated"><em class="mt">k-means ++的⦁ Sci-kit实现</em></p><p id="e7bb" class="pw-post-body-paragraph la lb iq lc b ld le ka lf lg lh kd li lj lk ll lm ln lo lp lq lr ls lt lu lv ij bi translated">3.DBSCAN </p><ul class=""><li id="bbc6" class="mu mv iq lc b ld le lg lh lj mw ln mx lr my lv mz na nb nc bi translated"><em class="mt">DBS can如何工作？</em></li><li id="5957" class="mu mv iq lc b ld nd lg ne lj nf ln ng lr nh lv mz na nb nc bi translated">DBSCAN的伪代码</li><li id="2746" class="mu mv iq lc b ld nd lg ne lj nf ln ng lr nh lv mz na nb nc bi translated"><em class="mt">数据库扫描的Sci-kit实现</em></li><li id="81e3" class="mu mv iq lc b ld nd lg ne lj nf ln ng lr nh lv mz na nb nc bi translated"><em class="mt">DBS can的利弊</em></li></ul></div><div class="ab cl ni nj hu nk" role="separator"><span class="nl bw bk nm nn no"/><span class="nl bw bk nm nn no"/><span class="nl bw bk nm nn"/></div><div class="ij ik il im in"><h1 id="7d9f" class="lw lx iq bd ly lz np mb mc md nq mf mg kf nr kg mi ki ns kj mk kl nt km mm mn bi translated">k均值</h1><h2 id="6e3c" class="nu lx iq bd ly nv nw dn mc nx ny dp mg lj nz oa mi ln ob oc mk lr od oe mm iw bi translated">K-means简介</h2><p id="dc3c" class="pw-post-body-paragraph la lb iq lc b ld mo ka lf lg mp kd li lj mq ll lm ln mr lp lq lr ms lt lu lv ij bi translated">K-means来自一个<strong class="lc ja">无监督学习</strong>算法家族，其中输入是无标签的，这与监督学习算法不同。</p><p id="17c4" class="pw-post-body-paragraph la lb iq lc b ld le ka lf lg lh kd li lj lk ll lm ln lo lp lq lr ls lt lu lv ij bi translated">K-means的最终目标是<strong class="lc ja">聚类</strong>，让我们深入研究聚类。</p><p id="42fb" class="pw-post-body-paragraph la lb iq lc b ld le ka lf lg lh kd li lj lk ll lm ln lo lp lq lr ls lt lu lv ij bi translated">有时我们只想组织数据，这就是集群发挥作用的地方。它既可用于标记数据，也可用于未标记数据。</p><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div role="button" tabindex="0" class="ku kv di kw bf kx"><div class="gh gi of"><img src="../Images/8e5cdbf822d8b78494c16f78babfe14f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*59sa5iddtTDKLCFu"/></div></div><figcaption class="og oh gj gh gi oi oj bd b be z dk translated">照片由<a class="ae ok" href="https://unsplash.com/@thibaultpenin?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Thibault Penin </a>在<a class="ae ok" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上拍摄</figcaption></figure><p id="d09e" class="pw-post-body-paragraph la lb iq lc b ld le ka lf lg lh kd li lj lk ll lm ln lo lp lq lr ls lt lu lv ij bi translated">每个人都听说过网飞和它永无止境的内容汇编。</p><p id="12ec" class="pw-post-body-paragraph la lb iq lc b ld le ka lf lg lh kd li lj lk ll lm ln lo lp lq lr ls lt lu lv ij bi translated">内容按照不同的类型组织得很好，如喜剧、戏剧、惊悚片等。</p><p id="c9d0" class="pw-post-body-paragraph la lb iq lc b ld le ka lf lg lh kd li lj lk ll lm ln lo lp lq lr ls lt lu lv ij bi translated">现在假设有一天你登录到网飞，档案是杂乱和模糊的。那会有多麻烦。</p><p id="f080" class="pw-post-body-paragraph la lb iq lc b ld le ka lf lg lh kd li lj lk ll lm ln lo lp lq lr ls lt lu lv ij bi translated">这就是聚类的概念，将所有的并行数据点分组到一个聚类中，以获得更好的编目体验。</p><p id="b7b7" class="pw-post-body-paragraph la lb iq lc b ld le ka lf lg lh kd li lj lk ll lm ln lo lp lq lr ls lt lu lv ij bi translated">这正是K-means的工作原理。</p><p id="1cea" class="pw-post-body-paragraph la lb iq lc b ld le ka lf lg lh kd li lj lk ll lm ln lo lp lq lr ls lt lu lv ij bi translated">聚类经常出现在<em class="mt">数据分析、客户细分、推荐系统、搜索引擎、半监督学习、维度缩减等领域。</em></p><p id="e841" class="pw-post-body-paragraph la lb iq lc b ld le ka lf lg lh kd li lj lk ll lm ln lo lp lq lr ls lt lu lv ij bi translated">K-means算法是<strong class="lc ja">硬聚类</strong>的一部分，对应每个点只属于一个聚类。</p><h2 id="91d3" class="nu lx iq bd ly nv nw dn mc nx ny dp mg lj nz oa mi ln ob oc mk lr od oe mm iw bi translated">K-如何意味着工作？</h2><p id="05d1" class="pw-post-body-paragraph la lb iq lc b ld mo ka lf lg mp kd li lj mq ll lm ln mr lp lq lr ms lt lu lv ij bi translated">K-Means中的<em class="mt">“K”</em>表示簇的<strong class="lc ja">数。这个算法在一些迭代之后必定会<strong class="lc ja">收敛</strong>到一个解。</strong></p><p id="fc65" class="pw-post-body-paragraph la lb iq lc b ld le ka lf lg lh kd li lj lk ll lm ln lo lp lq lr ls lt lu lv ij bi translated"><strong class="lc ja">目标</strong>:在“K”个簇中划分数据。</p><ol class=""><li id="8eba" class="mu mv iq lc b ld le lg lh lj mw ln mx lr my lv ol na nb nc bi translated">初始化K点。</li><li id="61ff" class="mu mv iq lc b ld nd lg ne lj nf ln ng lr nh lv ol na nb nc bi translated">将每一项按其最接近含义分类。</li><li id="a0eb" class="mu mv iq lc b ld nd lg ne lj nf ln ng lr nh lv ol na nb nc bi translated">更新平均值的坐标，这是迄今为止按平均值分类的项目的平均值。</li><li id="ce87" class="mu mv iq lc b ld nd lg ne lj nf ln ng lr nh lv ol na nb nc bi translated">重复以上步骤，直到我们的算法收敛。</li></ol><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div role="button" tabindex="0" class="ku kv di kw bf kx"><div class="gh gi om"><img src="../Images/f82813670c3b5f8814bb266329ba4569.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*DOdoiBpRk_rhp5mR.gif"/></div></div></figure><p id="7a53" class="pw-post-body-paragraph la lb iq lc b ld le ka lf lg lh kd li lj lk ll lm ln lo lp lq lr ls lt lu lv ij bi translated">成本函数是:</p><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div class="gh gi on"><img src="../Images/ba2aed2f57deb7c3122f70624c4806bc.png" data-original-src="https://miro.medium.com/v2/resize:fit:1096/format:webp/0*dYQQyh6_OH9uo9kr.png"/></div></figure><blockquote class="oo"><p id="01fa" class="op oq iq bd or os ot ou ov ow ox lv dk translated">其中m =所有点</p><p id="b828" class="op oq iq bd or os oy oz pa pb pc lv dk translated">K =所有集群</p><p id="0c05" class="op oq iq bd or os oy oz pa pb pc lv dk translated">如果第I个属于聚类<em class="pd"> k </em>，则数据点的wik = 1；</p><p id="89ef" class="op oq iq bd or os oy oz pa pb pc lv dk translated">否则，wik=0。</p></blockquote><p id="f819" class="pw-post-body-paragraph la lb iq lc b ld pe ka lf lg pf kd li lj pg ll lm ln ph lp lq lr pi lt lu lv ij bi translated">为了减少损失，我们实施<strong class="lc ja">坐标下降</strong>。在K-means <strong class="lc ja">中遇到的损失不是凸函数</strong>，因此可能存在多个局部最小值。</p><p id="d850" class="pw-post-body-paragraph la lb iq lc b ld le ka lf lg lh kd li lj lk ll lm ln lo lp lq lr ls lt lu lv ij bi translated">这是两部分的最小化问题:</p><p id="d0a4" class="pw-post-body-paragraph la lb iq lc b ld le ka lf lg lh kd li lj lk ll lm ln lo lp lq lr ls lt lu lv ij bi translated">我们首先最小化J . w . r . t . wik，并处理μk固定。然后我们最小化J . w . r . t .μk并处理wik固定。</p><ol class=""><li id="df30" class="mu mv iq lc b ld le lg lh lj mw ln mx lr my lv ol na nb nc bi translated"><strong class="lc ja"> E-step </strong>:我们首先区分J w r t wik并更新集群分配(<em class="mt"> E-step </em>)。</li></ol><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div role="button" tabindex="0" class="ku kv di kw bf kx"><div class="gh gi pj"><img src="../Images/aa3c4e1a15e3429e547af044be169166.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*t0jBTP_QY68JavPg.png"/></div></div></figure><p id="2bf2" class="pw-post-body-paragraph la lb iq lc b ld le ka lf lg lh kd li lj lk ll lm ln lo lp lq lr ls lt lu lv ij bi translated">我们将数据点xi分配给最近的聚类，该聚类通过其与聚类质心的欧几里德距离来评估。</p><p id="5a0d" class="pw-post-body-paragraph la lb iq lc b ld le ka lf lg lh kd li lj lk ll lm ln lo lp lq lr ls lt lu lv ij bi translated"><strong class="lc ja"> 2。m-步骤</strong>:然后我们对J . w . r . t .μk进行微分，并根据上一步的聚类分配重新计算质心。</p><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div role="button" tabindex="0" class="ku kv di kw bf kx"><div class="gh gi pk"><img src="../Images/192e731905f469f39115f115398e9892.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*iZpMTmxfp3MPw8lW.png"/></div></div></figure><p id="3061" class="pw-post-body-paragraph la lb iq lc b ld le ka lf lg lh kd li lj lk ll lm ln lo lp lq lr ls lt lu lv ij bi translated">简而言之，首先，我们将使用E-step获取wik，它会将该点分类为0或1。如果wik =1，那么我们将转移到M步，并且使用μk，我们得到所有点的平均值，以得到更新的聚类中心。</p><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div class="gh gi pl"><img src="../Images/68003c9eeab287fbaa4d77c7dc7a0dfc.png" data-original-src="https://miro.medium.com/v2/resize:fit:896/format:webp/1*xIe7AE3QplCO9GY8aFEbDA.png"/></div></figure><h2 id="9088" class="nu lx iq bd ly nv nw dn mc nx ny dp mg lj nz oa mi ln ob oc mk lr od oe mm iw bi translated"><strong class="ak"> <em class="pd"> Sci-kit实现的K-means </em> </strong></h2><figure class="kp kq kr ks gt kt"><div class="bz fp l di"><div class="pm pn l"/></div></figure><p id="70f9" class="pw-post-body-paragraph la lb iq lc b ld le ka lf lg lh kd li lj lk ll lm ln lo lp lq lr ls lt lu lv ij bi translated">要指定簇的数量，有两种方法:</p><ol class=""><li id="a062" class="mu mv iq lc b ld le lg lh lj mw ln mx lr my lv ol na nb nc bi translated"><strong class="lc ja">直接法:</strong>只要把数据点标出来，看有没有给你提示。</li><li id="6057" class="mu mv iq lc b ld nd lg ne lj nf ln ng lr nh lv ol na nb nc bi translated"><strong class="lc ja">惯性值:</strong>好的聚类背后的思想是具有小的惯性值和少量的聚类。</li></ol><p id="b517" class="pw-post-body-paragraph la lb iq lc b ld le ka lf lg lh kd li lj lk ll lm ln lo lp lq lr ls lt lu lv ij bi translated">惯性的值与簇的数量成反比。所以，这是一个权衡。经验法则:惯性图中的肘点是最佳选择，因为在此之后，惯性值的变化是不相关的。</p><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div role="button" tabindex="0" class="ku kv di kw bf kx"><div class="gh gi po"><img src="../Images/209bb6c0a542e08938b2245e09431526.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*ohsUPJbU9RPY_cpxRHj9CA.png"/></div></div></figure><h2 id="75de" class="nu lx iq bd ly nv nw dn mc nx ny dp mg lj nz oa mi ln ob oc mk lr od oe mm iw bi translated">K均值的利与弊</h2><p id="8245" class="pw-post-body-paragraph la lb iq lc b ld mo ka lf lg mp kd li lj mq ll lm ln mr lp lq lr ms lt lu lv ij bi translated"><strong class="lc ja">优点</strong>:</p><ol class=""><li id="db8e" class="mu mv iq lc b ld le lg lh lj mw ln mx lr my lv ol na nb nc bi translated">容易实现。</li><li id="c78b" class="mu mv iq lc b ld nd lg ne lj nf ln ng lr nh lv ol na nb nc bi translated">可扩展用于大数据</li><li id="2271" class="mu mv iq lc b ld nd lg ne lj nf ln ng lr nh lv ol na nb nc bi translated">确保趋同。</li></ol><p id="857b" class="pw-post-body-paragraph la lb iq lc b ld le ka lf lg lh kd li lj lk ll lm ln lo lp lq lr ls lt lu lv ij bi translated"><strong class="lc ja">缺点</strong>:</p><ol class=""><li id="b784" class="mu mv iq lc b ld le lg lh lj mw ln mx lr my lv ol na nb nc bi translated">对异常值敏感。</li><li id="66f3" class="mu mv iq lc b ld nd lg ne lj nf ln ng lr nh lv ol na nb nc bi translated">挑选集群的数量是一项单调乏味的工作。</li><li id="ae33" class="mu mv iq lc b ld nd lg ne lj nf ln ng lr nh lv ol na nb nc bi translated">初始化是随机的。</li><li id="f3d5" class="mu mv iq lc b ld nd lg ne lj nf ln ng lr nh lv ol na nb nc bi translated">不适用于非线性数据。</li></ol></div><div class="ab cl ni nj hu nk" role="separator"><span class="nl bw bk nm nn no"/><span class="nl bw bk nm nn no"/><span class="nl bw bk nm nn"/></div><div class="ij ik il im in"><h1 id="4c61" class="lw lx iq bd ly lz np mb mc md nq mf mg kf nr kg mi ki ns kj mk kl nt km mm mn bi translated">k-表示++的意思</h1><h2 id="2ba6" class="nu lx iq bd ly nv nw dn mc nx ny dp mg lj nz oa mi ln ob oc mk lr od oe mm iw bi translated">K-means++简介</h2><p id="fc11" class="pw-post-body-paragraph la lb iq lc b ld mo ka lf lg mp kd li lj mq ll lm ln mr lp lq lr ms lt lu lv ij bi translated">K-means++是K-means的<strong class="lc ja">扩展变体</strong>。K-means的缺点是，它使用了<strong class="lc ja">随机初始化技术</strong>，这通常会导致算法功能失调，因为一旦随机选择质心，就有陷入<strong class="lc ja">局部最小值的高风险。</strong></p><p id="0ae0" class="pw-post-body-paragraph la lb iq lc b ld le ka lf lg lh kd li lj lk ll lm ln lo lp lq lr ls lt lu lv ij bi translated">K-means++通过选择统计上<strong class="lc ja">接近</strong>真实中心的质心来避免这种阻碍。</p><blockquote class="pp pq pr"><p id="ba41" class="la lb mt lc b ld le ka lf lg lh kd li ps lk ll lm pt lo lp lq pu ls lt lu lv ij bi translated">Sci-kit learn默认使用k-means++。</p></blockquote><h2 id="0068" class="nu lx iq bd ly nv nw dn mc nx ny dp mg lj nz oa mi ln ob oc mk lr od oe mm iw bi translated">K-means++的Sci-kit实现</h2><figure class="kp kq kr ks gt kt"><div class="bz fp l di"><div class="pm pn l"/></div></figure><blockquote class="pp pq pr"><p id="a276" class="la lb mt lc b ld le ka lf lg lh kd li ps lk ll lm pt lo lp lq pu ls lt lu lv ij bi translated">但是，K-means++仍然不适合非线性数据点。</p></blockquote></div><div class="ab cl ni nj hu nk" role="separator"><span class="nl bw bk nm nn no"/><span class="nl bw bk nm nn no"/><span class="nl bw bk nm nn"/></div><div class="ij ik il im in"><h1 id="c04f" class="lw lx iq bd ly lz np mb mc md nq mf mg kf nr kg mi ki ns kj mk kl nt km mm mn bi translated">带噪声应用的基于密度的空间聚类</h1><h2 id="5e69" class="nu lx iq bd ly nv nw dn mc nx ny dp mg lj nz oa mi ln ob oc mk lr od oe mm iw bi translated">DBSCAN简介</h2><p id="f99d" class="pw-post-body-paragraph la lb iq lc b ld mo ka lf lg mp kd li lj mq ll lm ln mr lp lq lr ms lt lu lv ij bi translated">DBSCAN是一种针对<strong class="lc ja">非线性数据点的聚类解决方案。</strong></p><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div class="gh gi pv"><img src="../Images/0889087ed0933308456e14849aa950d3.png" data-original-src="https://miro.medium.com/v2/resize:fit:714/format:webp/0*RMZeFF74QfNklNmM.png"/></div></figure><p id="c1e2" class="pw-post-body-paragraph la lb iq lc b ld le ka lf lg lh kd li lj lk ll lm ln lo lp lq lr ls lt lu lv ij bi translated">它基于这样一个想法，一个星团是一个被T4低密度区域包围的T2高密度区域T3。</p><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div role="button" tabindex="0" class="ku kv di kw bf kx"><div class="gh gi po"><img src="../Images/1434dfa7c8f0c681c74f7951ce901b28.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*ZJYeWcuQU3KRNakB7wSh2A.png"/></div></div></figure><p id="c071" class="pw-post-body-paragraph la lb iq lc b ld le ka lf lg lh kd li lj lk ll lm ln lo lp lq lr ls lt lu lv ij bi translated">它从探索小区域开始，如果该区域的密度足够大，它被认为是簇的一部分，并探索邻居以增加簇的空间区域。</p><p id="78db" class="pw-post-body-paragraph la lb iq lc b ld le ka lf lg lh kd li lj lk ll lm ln lo lp lq lr ls lt lu lv ij bi translated">它根据一个规则工作:如果邻居的<strong class="lc ja">距离&lt;阈值距离</strong>，那么它被添加到家族中。</p><h2 id="0a19" class="nu lx iq bd ly nv nw dn mc nx ny dp mg lj nz oa mi ln ob oc mk lr od oe mm iw bi translated"><strong class="ak">DBS can的伪代码</strong></h2><ol class=""><li id="f936" class="mu mv iq lc b ld mo lg mp lj pw ln px lr py lv ol na nb nc bi translated">找到eps内的所有邻居点，并为每个核心未分配点创建一个新的集群。</li><li id="c104" class="mu mv iq lc b ld nd lg ne lj nf ln ng lr nh lv ol na nb nc bi translated">递归地找到其所有密度连接点，并将它们添加到与核心点(质心)相同的簇中。</li><li id="563c" class="mu mv iq lc b ld nd lg ne lj nf ln ng lr nh lv ol na nb nc bi translated">对未分配的邻居重复该过程。</li></ol><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div role="button" tabindex="0" class="ku kv di kw bf kx"><div class="gh gi pz"><img src="../Images/1f7ffe89b13f5ccc12b0cb695f4a34c2.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*QlwtXsgvSg7xR-47.png"/></div></div><figcaption class="og oh gj gh gi oi oj bd b be z dk translated">K-means与DBSCAN聚类</figcaption></figure><h2 id="7212" class="nu lx iq bd ly nv nw dn mc nx ny dp mg lj nz oa mi ln ob oc mk lr od oe mm iw bi translated">Sci-kit实施</h2><figure class="kp kq kr ks gt kt"><div class="bz fp l di"><div class="pm pn l"/></div></figure><p id="3920" class="pw-post-body-paragraph la lb iq lc b ld le ka lf lg lh kd li lj lk ll lm ln lo lp lq lr ls lt lu lv ij bi translated"><strong class="lc ja">接受的参数:</strong></p><p id="a661" class="pw-post-body-paragraph la lb iq lc b ld le ka lf lg lh kd li lj lk ll lm ln lo lp lq lr ls lt lu lv ij bi translated"><strong class="lc ja"> <em class="mt"> eps </em> </strong>:决定点之间应该有多近，才能被认为是聚类的一部分。它充当一个阈值。</p><p id="3c49" class="pw-post-body-paragraph la lb iq lc b ld le ka lf lg lh kd li lj lk ll lm ln lo lp lq lr ls lt lu lv ij bi translated"><strong class="lc ja"> <em class="mt"> minPoints </em> </strong>:形成密集区域的最小点数，例如，如果我们将minPoints参数设置为8，那么我们至少需要8个点来形成密集区域(集群)。</p><h2 id="1402" class="nu lx iq bd ly nv nw dn mc nx ny dp mg lj nz oa mi ln ob oc mk lr od oe mm iw bi translated">DBSCAN的利与弊</h2><p id="ef5b" class="pw-post-body-paragraph la lb iq lc b ld mo ka lf lg mp kd li lj mq ll lm ln mr lp lq lr ms lt lu lv ij bi translated">DBSCAN的优点:</p><ul class=""><li id="deb9" class="mu mv iq lc b ld le lg lh lj mw ln mx lr my lv mz na nb nc bi translated">非常适合在给定的数据集中区分高密度聚类和低密度聚类。</li><li id="1816" class="mu mv iq lc b ld nd lg ne lj nf ln ng lr nh lv mz na nb nc bi translated">对异常值不太敏感。</li></ul><p id="a7e4" class="pw-post-body-paragraph la lb iq lc b ld le ka lf lg lh kd li lj lk ll lm ln lo lp lq lr ls lt lu lv ij bi translated"><strong class="lc ja">DBS can的缺点:</strong></p><ul class=""><li id="b6ae" class="mu mv iq lc b ld le lg lh lj mw ln mx lr my lv mz na nb nc bi translated">DBSCAN与相似密度的集群进行斗争<em class="mt">。</em></li><li id="f4a0" class="mu mv iq lc b ld nd lg ne lj nf ln ng lr nh lv mz na nb nc bi translated">DBSCAN对于高维数据效率不高。</li><li id="60da" class="mu mv iq lc b ld nd lg ne lj nf ln ng lr nh lv mz na nb nc bi translated">比K均值慢。</li></ul></div><div class="ab cl ni nj hu nk" role="separator"><span class="nl bw bk nm nn no"/><span class="nl bw bk nm nn no"/><span class="nl bw bk nm nn"/></div><div class="ij ik il im in"><h1 id="148a" class="lw lx iq bd ly lz np mb mc md nq mf mg kf nr kg mi ki ns kj mk kl nt km mm mn bi translated">结论</h1><p id="c2b8" class="pw-post-body-paragraph la lb iq lc b ld mo ka lf lg mp kd li lj mq ll lm ln mr lp lq lr ms lt lu lv ij bi translated">希望这篇文章能帮助您以最佳方式理解集群，并帮助您实际使用它。</p><p id="cd26" class="pw-post-body-paragraph la lb iq lc b ld le ka lf lg lh kd li lj lk ll lm ln lo lp lq lr ls lt lu lv ij bi translated">一如既往，非常感谢你的阅读，如果你觉得这篇文章有用，请分享！</p></div><div class="ab cl ni nj hu nk" role="separator"><span class="nl bw bk nm nn no"/><span class="nl bw bk nm nn no"/><span class="nl bw bk nm nn"/></div><div class="ij ik il im in"><p id="e2e7" class="pw-post-body-paragraph la lb iq lc b ld le ka lf lg lh kd li lj lk ll lm ln lo lp lq lr ls lt lu lv ij bi translated">请随意连接:</p><blockquote class="pp pq pr"><p id="ea0f" class="la lb mt lc b ld le ka lf lg lh kd li ps lk ll lm pt lo lp lq pu ls lt lu lv ij bi translated"><em class="iq">LinkedIn ~</em><a class="ae ok" href="https://www.linkedin.com/in/dakshtrehan/" rel="noopener ugc nofollow" target="_blank"><em class="iq">https://www.linkedin.com/in/dakshtrehan/</em></a></p><p id="5da0" class="la lb mt lc b ld le ka lf lg lh kd li ps lk ll lm pt lo lp lq pu ls lt lu lv ij bi translated"><em class="iq">Instagram ~</em><a class="ae ok" href="https://www.instagram.com/_daksh_trehan_/" rel="noopener ugc nofollow" target="_blank"><em class="iq">https://www.instagram.com/_daksh_trehan_/</em></a></p><p id="3e42" class="la lb mt lc b ld le ka lf lg lh kd li ps lk ll lm pt lo lp lq pu ls lt lu lv ij bi translated"><em class="iq">Github ~</em><a class="ae ok" href="https://github.com/dakshtrehan" rel="noopener ugc nofollow" target="_blank"><em class="iq">https://github.com/dakshtrehan</em>T43】</a></p></blockquote><p id="7f4c" class="pw-post-body-paragraph la lb iq lc b ld le ka lf lg lh kd li lj lk ll lm ln lo lp lq lr ls lt lu lv ij bi translated">关注更多机器学习/深度学习博客。</p><blockquote class="pp pq pr"><p id="253b" class="la lb mt lc b ld le ka lf lg lh kd li ps lk ll lm pt lo lp lq pu ls lt lu lv ij bi translated"><em class="iq">中等~</em><a class="ae ok" href="https://medium.com/@dakshtrehan" rel="noopener"><em class="iq">https://medium.com/@dakshtrehan</em></a></p></blockquote><h2 id="34ac" class="nu lx iq bd ly nv nw dn mc nx ny dp mg lj nz oa mi ln ob oc mk lr od oe mm iw bi translated">想了解更多？</h2><div class="qa qb gp gr qc qd"><a href="https://towardsdatascience.com/the-inescapable-ai-algorithm-tiktok-ad4c6fd981b8" rel="noopener follow" target="_blank"><div class="qe ab fo"><div class="qf ab qg cl cj qh"><h2 class="bd ja gy z fp qi fr fs qj fu fw iz bi translated">无法逃脱的人工智能算法:抖音</h2><div class="qk l"><h3 class="bd b gy z fp qi fr fs qj fu fw dk translated">描述一个抖音用来吸引用户的渐进式推荐系统！</h3></div><div class="ql l"><p class="bd b dl z fp qi fr fs qj fu fw dk translated">towardsdatascience.com</p></div></div><div class="qm l"><div class="qn l qo qp qq qm qr ky qd"/></div></div></a></div><div class="qa qb gp gr qc qd"><a href="https://medium.com/@dakshtrehan/why-are-you-responsible-for-george-floyds-murder-delhi-communal-riots-4c1edb7acbc5" rel="noopener follow" target="_blank"><div class="qe ab fo"><div class="qf ab qg cl cj qh"><h2 class="bd ja gy z fp qi fr fs qj fu fw iz bi translated">为什么你要为乔治·弗洛伊德的谋杀和德里社区骚乱负责！！</h2><div class="qk l"><h3 class="bd b gy z fp qi fr fs qj fu fw dk translated">一个ML爱好者改变世界的方法。</h3></div><div class="ql l"><p class="bd b dl z fp qi fr fs qj fu fw dk translated">medium.com</p></div></div><div class="qm l"><div class="qs l qo qp qq qm qr ky qd"/></div></div></a></div><div class="qa qb gp gr qc qd"><a href="https://towardsdatascience.com/detecting-covid-19-using-deep-learning-262956b6f981" rel="noopener follow" target="_blank"><div class="qe ab fo"><div class="qf ab qg cl cj qh"><h2 class="bd ja gy z fp qi fr fs qj fu fw iz bi translated">使用深度学习检测新冠肺炎</h2><div class="qk l"><h3 class="bd b gy z fp qi fr fs qj fu fw dk translated">一个实用的方法来帮助医生帮助我们对抗新冠肺炎</h3></div><div class="ql l"><p class="bd b dl z fp qi fr fs qj fu fw dk translated">towardsdatascience.com</p></div></div><div class="qm l"><div class="qt l qo qp qq qm qr ky qd"/></div></div></a></div><div class="qa qb gp gr qc qd"><a href="https://medium.com/@dakshtrehan/start-off-your-ml-journey-with-k-nearest-neighbors-f72a122f428" rel="noopener follow" target="_blank"><div class="qe ab fo"><div class="qf ab qg cl cj qh"><h2 class="bd ja gy z fp qi fr fs qj fu fw iz bi translated">从K个最近的邻居开始你的ML之旅！</h2><div class="qk l"><h3 class="bd b gy z fp qi fr fs qj fu fw dk translated">详细的理论解释和scikit-用例子学习实现！</h3></div><div class="ql l"><p class="bd b dl z fp qi fr fs qj fu fw dk translated">medium.com</p></div></div><div class="qm l"><div class="qu l qo qp qq qm qr ky qd"/></div></div></a></div><div class="qa qb gp gr qc qd"><a href="https://medium.com/swlh/things-you-never-knew-about-naive-bayes-eb84b6ee039a" rel="noopener follow" target="_blank"><div class="qe ab fo"><div class="qf ab qg cl cj qh"><h2 class="bd ja gy z fp qi fr fs qj fu fw iz bi translated">关于朴素贝叶斯你不知道的事情！！</h2><div class="qk l"><h3 class="bd b gy z fp qi fr fs qj fu fw dk translated">朴素贝叶斯快速指南，帮助你开发垃圾邮件过滤系统！</h3></div><div class="ql l"><p class="bd b dl z fp qi fr fs qj fu fw dk translated">medium.com</p></div></div><div class="qm l"><div class="qv l qo qp qq qm qr ky qd"/></div></div></a></div><div class="qa qb gp gr qc qd"><a href="https://medium.com/analytics-vidhya/activation-functions-explained-8690ea7bdec9" rel="noopener follow" target="_blank"><div class="qe ab fo"><div class="qf ab qg cl cj qh"><h2 class="bd ja gy z fp qi fr fs qj fu fw iz bi translated">解释激活功能</h2><div class="qk l"><h3 class="bd b gy z fp qi fr fs qj fu fw dk translated">阶跃，Sigmoid，双曲正切，Softmax，ReLU，Leaky ReLU解释</h3></div><div class="ql l"><p class="bd b dl z fp qi fr fs qj fu fw dk translated">medium.com</p></div></div><div class="qm l"><div class="qw l qo qp qq qm qr ky qd"/></div></div></a></div><div class="qa qb gp gr qc qd"><a href="https://towardsdatascience.com/parameters-optimization-explained-876561853de0" rel="noopener follow" target="_blank"><div class="qe ab fo"><div class="qf ab qg cl cj qh"><h2 class="bd ja gy z fp qi fr fs qj fu fw iz bi translated">解释参数优化</h2><div class="qk l"><h3 class="bd b gy z fp qi fr fs qj fu fw dk translated">梯度下降的简要描述指南，ADAM，ADAGRAD，RMSProp</h3></div><div class="ql l"><p class="bd b dl z fp qi fr fs qj fu fw dk translated">towardsdatascience.com</p></div></div><div class="qm l"><div class="qx l qo qp qq qm qr ky qd"/></div></div></a></div><div class="qa qb gp gr qc qd"><a href="https://towardsdatascience.com/gradient-descent-explained-9b953fc0d2c" rel="noopener follow" target="_blank"><div class="qe ab fo"><div class="qf ab qg cl cj qh"><h2 class="bd ja gy z fp qi fr fs qj fu fw iz bi translated">梯度下降解释</h2><div class="qk l"><h3 class="bd b gy z fp qi fr fs qj fu fw dk translated">梯度下降综合指南</h3></div><div class="ql l"><p class="bd b dl z fp qi fr fs qj fu fw dk translated">towardsdatascience.com</p></div></div><div class="qm l"><div class="qy l qo qp qq qm qr ky qd"/></div></div></a></div><div class="qa qb gp gr qc qd"><a href="https://towardsdatascience.com/logistic-regression-explained-ef1d816ea85a" rel="noopener follow" target="_blank"><div class="qe ab fo"><div class="qf ab qg cl cj qh"><h2 class="bd ja gy z fp qi fr fs qj fu fw iz bi translated">逻辑回归解释</h2><div class="qk l"><h3 class="bd b gy z fp qi fr fs qj fu fw dk translated">尽可能简单地解释逻辑回归。</h3></div><div class="ql l"><p class="bd b dl z fp qi fr fs qj fu fw dk translated">towardsdatascience.com</p></div></div><div class="qm l"><div class="qz l qo qp qq qm qr ky qd"/></div></div></a></div><div class="qa qb gp gr qc qd"><a href="https://medium.com/towards-artificial-intelligence/linear-regression-explained-f5cc85ae2c5c" rel="noopener follow" target="_blank"><div class="qe ab fo"><div class="qf ab qg cl cj qh"><h2 class="bd ja gy z fp qi fr fs qj fu fw iz bi translated">线性回归解释</h2><div class="qk l"><h3 class="bd b gy z fp qi fr fs qj fu fw dk translated">尽可能简单地解释线性回归。</h3></div><div class="ql l"><p class="bd b dl z fp qi fr fs qj fu fw dk translated">medium.com</p></div></div><div class="qm l"><div class="ra l qo qp qq qm qr ky qd"/></div></div></a></div><blockquote class="pp pq pr"><p id="2243" class="la lb mt lc b ld le ka lf lg lh kd li ps lk ll lm pt lo lp lq pu ls lt lu lv ij bi translated">干杯！</p></blockquote></div></div>    
</body>
</html>