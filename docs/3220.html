<html>
<head>
<title>Few-shot Financial Sentiment Classification — Does It Work?</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">少数金融情绪分类——有用吗？</h1>
<blockquote>原文：<a href="https://pub.towardsai.net/few-shot-financial-sentiment-classification-does-it-work-353cff279afd?source=collection_archive---------1-----------------------#2022-10-16">https://pub.towardsai.net/few-shot-financial-sentiment-classification-does-it-work-353cff279afd?source=collection_archive---------1-----------------------#2022-10-16</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><figure class="gl gn jr js jt ju gh gi paragraph-image"><div role="button" tabindex="0" class="jv jw di jx bf jy"><div class="gh gi jq"><img src="../Images/afc80556867b8ed92faeafbf85943057.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*6LSG1d2sBw3rTYMfqhJN0Q.png"/></div></div></figure><p id="28da" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">到目前为止，我的数据科学生涯中最困难的事情不是建模，跟上最新的研究，甚至是向非技术人员展示复杂的想法，而是清理数据和正确标记数据——这是一项吃力不讨好的工作，但对模型的训练和工作至关重要。这就是为什么我对了解<a class="ae kz" href="https://arxiv.org/abs/2209.11055" rel="noopener ugc nofollow" target="_blank"> SetFit </a>感到兴奋，这是由<a class="ae kz" href="https://huggingface.co/blog/setfit" rel="noopener ugc nofollow" target="_blank">抱抱脸</a> / <a class="ae kz" href="https://community.intel.com/t5/Blogs/Tech-Innovation/Artificial-Intelligence-AI/Sentence-Transformer-Fine-Tuning-SetFit/post/1407712" rel="noopener ugc nofollow" target="_blank">英特尔</a> / <a class="ae kz" href="https://github.com/UKPLab" rel="noopener ugc nofollow" target="_blank"> UKP实验室</a>推出的一种少数镜头文本分类机制。</p><figure class="lb lc ld le gt ju gh gi paragraph-image"><div role="button" tabindex="0" class="jv jw di jx bf jy"><div class="gh gi la"><img src="../Images/ccdafe013ba725e1147a3cbca9022ec5.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*b03-w9wXBETb-lobjVfx2A.png"/></div></div><figcaption class="lf lg gj gh gi lh li bd b be z dk translated">来源:<a class="ae kz" href="https://arxiv.org/abs/2209.11055" rel="noopener ugc nofollow" target="_blank">https://arxiv.org/abs/2209.11055</a></figcaption></figure><p id="6da6" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">自BERT以来，已经有许多创新，但这一个突出的是它的实际优势——在一些拍摄设置中胜过GPT3，同时体积小1600倍，速度快得足以在CPU上训练！</p><p id="787b" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">少量学习在金融领域至关重要，因为标记的数据通常是训练好模型的瓶颈——准确标记数据可能会很昂贵、棘手和乏味。因此，如果我们只用几个标签就能获得良好的性能，我们就可以节省时间，专注于仔细管理数据，使其准确无误。</p><p id="53b7" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">我在这里试驾了一下<a class="ae kz" href="https://github.com/neoyipeng2018/FinancialPhraseBank-v1.0/blob/main/SetFit.ipynb" rel="noopener ugc nofollow" target="_blank"/>，有3个问题我想回答:</p><ol class=""><li id="2fed" class="lj lk it kd b ke kf ki kj km ll kq lm ku ln ky lo lp lq lr bi translated"><strong class="kd iu">少镜头学习对金融情绪分类有用吗？没有强有力的理由不应该这样做，因为它在SST-5等其他情感分类任务中表现很好。我确实想知道我们能否在论文中获得巨大的收益，以及需要多少数据点才能很好地对金融情绪进行分类，由于金融环境/模糊性，这可能很棘手。</strong></li><li id="f905" class="lj lk it kd b ke ls ki lt km lu kq lv ku lw ky lo lp lq lr bi translated"><strong class="kd iu">没有金融句子转换器，那么一个标准的</strong><a class="ae kz" href="https://huggingface.co/sentence-transformers/all-mpnet-base-v2" rel="noopener ugc nofollow" target="_blank"><strong class="kd iu">MPnet</strong></a><strong class="kd iu">句子转换器会比FinBERT工作得更好吗？</strong>这是一个已经在语义相似性上训练过的嵌入和更“理解”金融的金融嵌入之间的权衡问题。我最初的假设是，金融不像医学领域那样深奥，所以一个通用的预先训练的句子转换器可能比使用一个没有在语义相似性上训练过的FinBERT更好。</li><li id="830d" class="lj lk it kd b ke ls ki lt km lu kq lv ku lw ky lo lp lq lr bi translated"><strong class="kd iu">最后，如果我们用所有可能的数据对SetFit进行微调，它能跑赢FinBERT吗？</strong>本质上，我们在问:( 1)句子转换器作为情感分类的基础是否优于一般的预训练模型;( 2)两阶段过程是否适用于整个数据集。</li></ol><h1 id="992e" class="lx ly it bd lz ma mb mc md me mf mg mh mi mj mk ml mm mn mo mp mq mr ms mt mu bi translated">0.为什么它会起作用呢？</h1><p id="f776" class="pw-post-body-paragraph kb kc it kd b ke mv kg kh ki mw kk kl km mx ko kp kq my ks kt ku mz kw kx ky im bi translated">在我们开始实验之前，让我们先想想为什么它会起作用。</p><p id="e140" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated"><strong class="kd iu">预训练模型</strong>:我们从句子转换器(ST)开始，这是一个坚实的预训练基线，具有基于相似性的句子的良好语义表示。最近<a class="ae kz" href="https://jfds.pm-research.com/content/early/2022/06/10/jfds.2022.1.095" rel="noopener ugc nofollow" target="_blank">的一篇论文</a>直接针对情绪对ST进行了微调，发现它比<a class="ae kz" href="https://github.com/ProsusAI/finBERT" rel="noopener ugc nofollow" target="_blank">芬伯特</a>略好。</p><p id="3750" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated"><strong class="kd iu">对比学习</strong>:因为训练数据非常少，我们需要尽可能地从它们身上榨取一切——采样和配对正负数据允许建模过程创建更多的例子，供模型在ST微调阶段学习。这种重采样在一定程度上起作用，直到配对本身重复得太频繁，并且模型过拟合(作者推荐1个历元和20次重采样或迭代)。</p><h1 id="fa4f" class="lx ly it bd lz ma mb mc md me mf mg mh mi mj mk ml mm mn mo mp mq mr ms mt mu bi translated">1.SetFit是如何对金融情绪进行开箱即用的？</h1><p id="afd3" class="pw-post-body-paragraph kb kc it kd b ke mv kg kh ki mw kk kl km mx ko kp kq my ks kt ku mz kw kx ky im bi translated">自然地，我遵从的数据集是Malo等人的金融短语bank。事实上，我们看到SetFit在少量拍摄的基础上工作得比在少量拍摄的情况下纯粹微调基础FinBERT好得多。正如一位作者在<a class="ae kz" href="https://github.com/huggingface/setfit/issues/86" rel="noopener ugc nofollow" target="_blank">中提到的</a>，20个样本似乎是一个很好的选择，在此之后，改进速度会有所放缓。也可能是因为设置的迭代次数(也是20)。肯定是要测试的东西。</p><p id="cdfe" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">也就是说，即使在每个标签上训练30个样本后，与完整模型仍有相对较大的差距(~5%)。与论文的例子相比，在20个样本后，SetFit接近完整模型的精度。但这可能是由于数据集中存在潜在的模糊性，因此需要更多的例子来实现体面的结果。</p><figure class="lb lc ld le gt ju gh gi paragraph-image"><div role="button" tabindex="0" class="jv jw di jx bf jy"><div class="gh gi jq"><img src="../Images/943eba78a486cef3a90dd9ca30b107c9.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*jv0favmMl2dYkA6qSNJNAw.png"/></div></div></figure><h1 id="4602" class="lx ly it bd lz ma mb mc md me mf mg mh mi mj mk ml mm mn mo mp mq mr ms mt mu bi translated">2.我们可以通过转向财务骨干来改善SetFit吗？</h1><p id="986f" class="pw-post-body-paragraph kb kc it kd b ke mv kg kh ki mw kk kl km mx ko kp kq my ks kt ku mz kw kx ky im bi translated">当前句子转换器的局限性之一是没有一个已经在金融/商业领域句子上训练过的。这可能是一个问题，因为金融/商业术语可能具有与典型术语不同的含义。</p><figure class="lb lc ld le gt ju gh gi paragraph-image"><div role="button" tabindex="0" class="jv jw di jx bf jy"><div class="gh gi jq"><img src="../Images/afc80556867b8ed92faeafbf85943057.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*6LSG1d2sBw3rTYMfqhJN0Q.png"/></div></div></figure><p id="3828" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">使用SetFit设置运行一个<a class="ae kz" href="https://huggingface.co/yiyanghkust/finbert-pretrain" rel="noopener ugc nofollow" target="_blank">预训练的FinBERT </a>，该FinBERT在新闻、分析师报告和文档方面受过训练，产生的结果介于SetFit和FinBERT之间。两条意见:</p><p id="9fea" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">(1)set fit两步训练过程优于低数据状态下的正常微调设置。</p><p id="5038" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">(2)金融/业务领域预培训没有嵌入预培训的句子重要。金融词汇可能在预训练语料库中覆盖得足够好，因此专门针对金融文本进行微调不会有太多好处。这也可能是我们的目标语料库的结果，它集中在</p><h1 id="fd22" class="lx ly it bd lz ma mb mc md me mf mg mh mi mj mk ml mm mn mo mp mq mr ms mt mu bi translated">3.结论</h1><p id="68bb" class="pw-post-body-paragraph kb kc it kd b ke mv kg kh ki mw kk kl km mx ko kp kq my ks kt ku mz kw kx ky im bi translated">使用<strong class="kd iu"> SetFit-MPNet </strong>可能是在低数据范围内进行一般金融情绪分类的最佳方法。我喜欢这种方法的简单性，它突出了句子转换器的强大功能，不仅适用于语义任务，还适用于分类。</p><p id="48b0" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">如果您在自己的数据集上尝试了我的<a class="ae kz" href="https://github.com/neoyipeng2018/FinancialPhraseBank-v1.0/blob/main/SetFit.ipynb" rel="noopener ugc nofollow" target="_blank">代码</a>，并看到了任何不同，请告诉我。</p><p id="5fcd" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">PS:我没有耐心/计算去做#3，但是<a class="ae kz" href="https://jfds.pm-research.com/content/early/2022/06/10/jfds.2022.1.095" rel="noopener ugc nofollow" target="_blank">这些人</a>做了类似的事情，发现句子变形金刚更好。</p></div></div>    
</body>
</html>