<html>
<head>
<title>The Confusion Matrix for Classification</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">分类的混淆矩阵</h1>
<blockquote>原文：<a href="https://pub.towardsai.net/the-confusion-matrix-for-classification-eb3bcf3064c7?source=collection_archive---------0-----------------------#2019-08-19">https://pub.towardsai.net/the-confusion-matrix-for-classification-eb3bcf3064c7?source=collection_archive---------0-----------------------#2019-08-19</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><h2 id="268e" class="io ip iq bd b dl ir is it iu iv iw dk ix translated" aria-label="kicker paragraph">潜入混乱矩阵进行分类| <a class="ae ep" href="https://towardsai.net" rel="noopener ugc nofollow" target="_blank">走向AI </a></h2><div class=""/><div class=""><h2 id="704c" class="pw-subtitle-paragraph jw iz iq bd b jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn dk translated">了解准确性、召回率、精确度、ROC、AUC和F1分数</h2></div><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div class="gh gi ko"><img src="../Images/057ec8a1a1f7a0424562b3b3ef39b34b.png" data-original-src="https://miro.medium.com/v2/resize:fit:600/format:webp/1*XLoimHdeg9XNK3twOZgg0w.jpeg"/></div><figcaption class="kw kx gj gh gi ky kz bd b be z dk translated">对混淆矩阵感到困惑？</figcaption></figure><p id="1493" class="pw-post-body-paragraph la lb iq lc b ld le ka lf lg lh kd li lj lk ll lm ln lo lp lq lr ls lt lu lv ij bi translated">混淆矩阵产生了用于评估分类算法(如逻辑回归或决策树)性能的最理想的度量套件。它通常用于二进制分类问题，但也可以通过简单的<a class="ae lw" href="https://scikit-learn.org/stable/auto_examples/model_selection/plot_roc.html" rel="noopener ugc nofollow" target="_blank"> <strong class="lc ja"> <em class="lx">二进制化输出</em> </strong> </a>来用于多标签分类问题。</p><p id="7edf" class="pw-post-body-paragraph la lb iq lc b ld le ka lf lg lh kd li lj lk ll lm ln lo lp lq lr ls lt lu lv ij bi translated">如果没有修辞，混淆矩阵当然可以告诉我们分类模型的<strong class="lc ja"><em class="lx"/></strong><strong class="lc ja"><em class="lx"/></strong><strong class="lc ja"><em class="lx">精度、ROC、AUC、</em> </strong>以及<strong class="lc ja"> <em class="lx"> F1-score </em> </strong>。</p><p id="a5b4" class="pw-post-body-paragraph la lb iq lc b ld le ka lf lg lh kd li lj lk ll lm ln lo lp lq lr ls lt lu lv ij bi translated">我们将在几分钟内仔细查看这些指标…</p><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div role="button" tabindex="0" class="lz ma di mb bf mc"><div class="gh gi ly"><img src="../Images/a218e3548d45ee64a576b2eb796d156b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Xu-UN7eSBobpfMkary5tJQ.png"/></div></div><figcaption class="kw kx gj gh gi ky kz bd b be z dk translated"><strong class="bd md">混淆矩阵的单元格汇总。</strong></figcaption></figure><h2 id="6bf6" class="me mf iq bd md mg mh dn mi mj mk dp ml lj mm mn mo ln mp mq mr lr ms mt mu iw bi translated">让我们检查混淆矩阵的单元:</h2><p id="89ab" class="pw-post-body-paragraph la lb iq lc b ld mv ka lf lg mw kd li lj mx ll lm ln my lp lq lr mz lt lu lv ij bi translated">假设我们正在构建一个二元分类模型，将患者分为<strong class="lc ja">糖尿病患者(1) </strong>或<strong class="lc ja">非糖尿病患者(0) </strong>。</p><p id="0541" class="pw-post-body-paragraph la lb iq lc b ld le ka lf lg lh kd li lj lk ll lm ln lo lp lq lr ls lt lu lv ij bi translated"><strong class="lc ja">真阳性(1归类为1): </strong></p><p id="15a4" class="pw-post-body-paragraph la lb iq lc b ld le ka lf lg lh kd li lj lk ll lm ln lo lp lq lr ls lt lu lv ij bi translated">这是储存被正确分类为阳性的阳性病例数<strong class="lc ja"><em class="lx"/></strong>的单元格。换句话说，有多少糖尿病患者被恰当地归类为糖尿病患者。</p><p id="3f54" class="pw-post-body-paragraph la lb iq lc b ld le ka lf lg lh kd li lj lk ll lm ln lo lp lq lr ls lt lu lv ij bi translated"><strong class="lc ja">假阳性(0分类为1): </strong></p><p id="0d25" class="pw-post-body-paragraph la lb iq lc b ld le ka lf lg lh kd li lj lk ll lm ln lo lp lq lr ls lt lu lv ij bi translated">这是储存不正确分类为阳性的阴性病例数<strong class="lc ja"><em class="lx"/></strong>的单元格。也就是说，非糖尿病患者被不恰当地归类为糖尿病患者的数量。</p><p id="7f0b" class="pw-post-body-paragraph la lb iq lc b ld le ka lf lg lh kd li lj lk ll lm ln lo lp lq lr ls lt lu lv ij bi translated"><strong class="lc ja">真阴性(0分类为0): </strong></p><p id="dc39" class="pw-post-body-paragraph la lb iq lc b ld le ka lf lg lh kd li lj lk ll lm ln lo lp lq lr ls lt lu lv ij bi translated">这是储存阴性病例数的单元格<strong class="lc ja"> <em class="lx">正确分类为阴性的</em> </strong>。因此，将非糖尿病患者的数量适当地归类为非糖尿病患者。</p><p id="4eef" class="pw-post-body-paragraph la lb iq lc b ld le ka lf lg lh kd li lj lk ll lm ln lo lp lq lr ls lt lu lv ij bi translated"><strong class="lc ja">假阴性(1归类为0): </strong></p><p id="fe63" class="pw-post-body-paragraph la lb iq lc b ld le ka lf lg lh kd li lj lk ll lm ln lo lp lq lr ls lt lu lv ij bi translated">最后，这是储存阳性病例数<strong class="lc ja"> <em class="lx">不正确地</em> </strong>分类为阴性的细胞……不正确地分类为非糖尿病的糖尿病患者数。</p><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div role="button" tabindex="0" class="lz ma di mb bf mc"><div class="gh gi na"><img src="../Images/2ba418c60b6e76fcf297145451142508.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*RCaHXwXAsTBkgzqBo-ATlg.jpeg"/></div></div><figcaption class="kw kx gj gh gi ky kz bd b be z dk translated">训练一个模型| <a class="ae lw" href="https://www.google.com/url?sa=i&amp;source=images&amp;cd=&amp;ved=2ahUKEwja7YmS3_jjAhUCSxoKHeIbBmUQjRx6BAgBEAQ&amp;url=https%3A%2F%2Fwww.cogitotech.com%2Fblog%2Fwhat-are-the-various-types-of-data-sets-used-in-machine-learning%2F&amp;psig=AOvVaw36gyBJZeVBmFCg_HzlN-rn&amp;ust=1565541225859382" rel="noopener ugc nofollow" target="_blank"> img_credit </a></figcaption></figure><h2 id="93d2" class="me mf iq bd md mg mh dn mi mj mk dp ml lj mm mn mo ln mp mq mr lr ms mt mu iw bi translated">让我们玩一些现实生活中的数据…</h2><p id="1d66" class="pw-post-body-paragraph la lb iq lc b ld mv ka lf lg mw kd li lj mx ll lm ln my lp lq lr mz lt lu lv ij bi translated">让我们构建一个二叉决策树分类器，将患者分为<strong class="lc ja">糖尿病患者(1) </strong>和<strong class="lc ja">非糖尿病患者(0)。</strong></p><p id="074b" class="pw-post-body-paragraph la lb iq lc b ld le ka lf lg lh kd li lj lk ll lm ln lo lp lq lr ls lt lu lv ij bi translated">我们将使用由加州大学信息与计算机科学学院出版的<em class="lx">皮马印第安人糖尿病数据集的数据模拟生成的数据集。</em></p><p id="e74f" class="pw-post-body-paragraph la lb iq lc b ld le ka lf lg lh kd li lj lk ll lm ln lo lp lq lr ls lt lu lv ij bi translated">参见<em class="lx"> </em> <a class="ae lw" href="https://raw.githubusercontent.com/Blackman9t/Machine_Learning/master/diabetes.csv" rel="noopener ugc nofollow" target="_blank"> <strong class="lc ja"> <em class="lx">链接</em> </strong> </a> <em class="lx"> </em>到患者原始CSV文件和<a class="ae lw" href="https://raw.githubusercontent.com/Blackman9t/Machine_Learning/master/doctors.csv" rel="noopener ugc nofollow" target="_blank"> <strong class="lc ja"> <em class="lx">链接</em></strong></a><strong class="lc ja"><em class="lx"/></strong>到医师数据集。</p><p id="3b51" class="pw-post-body-paragraph la lb iq lc b ld le ka lf lg lh kd li lj lk ll lm ln lo lp lq lr ls lt lu lv ij bi translated">让我们导入需要的模块</p><pre class="kp kq kr ks gt nb nc nd ne aw nf bi"><span id="26ae" class="me mf iq nc b gy ng nh l ni nj"><strong class="nc ja">print(__doc__)</strong></span><span id="b8dc" class="me mf iq nc b gy nk nh l ni nj"><strong class="nc ja">import numpy as np<br/>import matplotlib.pyplot as plt<br/>import seaborn as sns<br/>import pandas as pd<br/>import itertools<br/></strong># for plotting the ROC Curve<br/><strong class="nc ja">from sklearn.metrics import roc_curve, auc</strong></span></pre><p id="620f" class="pw-post-body-paragraph la lb iq lc b ld le ka lf lg lh kd li lj lk ll lm ln lo lp lq lr ls lt lu lv ij bi translated">让我们从GitHub导入数据集，并读入熊猫数据框</p><pre class="kp kq kr ks gt nb nc nd ne aw nf bi"><span id="9c40" class="me mf iq nc b gy ng nh l ni nj"><strong class="nc ja">data_link = '</strong><a class="ae lw" href="https://raw.githubusercontent.com/Blackman9t/Machine_Learning/master/diabetes.csv'" rel="noopener ugc nofollow" target="_blank"><strong class="nc ja">https://raw.githubusercontent.com/Blackman9t/Machine_Learning/master/diabetes.csv'</strong></a></span><span id="d7fa" class="me mf iq nc b gy nk nh l ni nj"><strong class="nc ja">diabetes_df = pd.read_csv(data_link)</strong></span><span id="8a4c" class="me mf iq nc b gy nk nh l ni nj"><strong class="nc ja">diabetes_df.head()</strong></span></pre><p id="c382" class="pw-post-body-paragraph la lb iq lc b ld le ka lf lg lh kd li lj lk ll lm ln lo lp lq lr ls lt lu lv ij bi translated">让我们检查形状和缺失数据计数。</p><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div role="button" tabindex="0" class="lz ma di mb bf mc"><div class="gh gi nl"><img src="../Images/2d34e150a9b6d3f2e09173f4a1a0cf2e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*0aECRM4T6d9jr18UmIfUQA.png"/></div></div><figcaption class="kw kx gj gh gi ky kz bd b be z dk translated">我们可以看到前5行。数据集有15000行和10列。它没有缺失值。</figcaption></figure><p id="3098" class="pw-post-body-paragraph la lb iq lc b ld le ka lf lg lh kd li lj lk ll lm ln lo lp lq lr ls lt lu lv ij bi translated">对于一个分类问题，我们需要关注数据集。让我们看看我们的特征矩阵的分布。这可以帮助我们选择最理想的特征归一化方法。首先，让我们定义一种绘制每个特征分布的方法。</p><p id="d8f8" class="pw-post-body-paragraph la lb iq lc b ld le ka lf lg lh kd li lj lk ll lm ln lo lp lq lr ls lt lu lv ij bi translated">在这里看到方法<a class="ae lw" href="https://github.com/Blackman9t/Machine_Learning/blob/master/Understanding_Confusion_Matrix1.ipynb" rel="noopener ugc nofollow" target="_blank"> <strong class="lc ja"> <em class="lx">的链接</em> </strong> </a>，因为它相当冗长。</p><p id="7685" class="pw-post-body-paragraph la lb iq lc b ld le ka lf lg lh kd li lj lk ll lm ln lo lp lq lr ls lt lu lv ij bi translated">所以让我们在上面定义的<em class="lx">糖尿病_df </em>数据帧上调用方法。这将创建每个独立变量的历史图。</p><pre class="kp kq kr ks gt nb nc nd ne aw nf bi"><span id="2720" class="me mf iq nc b gy ng nh l ni nj"><strong class="nc ja">plot_features(diabetes_df)</strong></span><span id="8173" class="me mf iq nc b gy nk nh l ni nj">&gt;&gt;</span></pre><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div role="button" tabindex="0" class="lz ma di mb bf mc"><div class="gh gi nm"><img src="../Images/3f1c661ad6f0c0f1383f8ff4d1ad4780.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*ut_PgKKPgDrleCVocx43Jg.png"/></div></div></figure><p id="6fa3" class="pw-post-body-paragraph la lb iq lc b ld le ka lf lg lh kd li lj lk ll lm ln lo lp lq lr ls lt lu lv ij bi translated">我们可以看到变量的分布:-年龄，怀孕，血清白蛋白和糖尿病是相似的。它是不对称的单峰的。一开始有一个由许多低值组成的主导模式。然后是一些中到高的值，这些值会使形状向右倾斜。</p><p id="707e" class="pw-post-body-paragraph la lb iq lc b ld le ka lf lg lh kd li lj lk ll lm ln lo lp lq lr ls lt lu lv ij bi translated">其他变量如血糖、糖化血红蛋白、肱三头肌厚度和身体质量指数似乎具有大致对称的正态分布。身体质量指数非常有趣，在20和40值附近呈双峰分布，在25-55范围内呈钟形正态分布。</p><p id="91e8" class="pw-post-body-paragraph la lb iq lc b ld le ka lf lg lh kd li lj lk ll lm ln lo lp lq lr ls lt lu lv ij bi translated">有一点很清楚，该数据集中的大部分值分布在下限内。</p><p id="cfce" class="pw-post-body-paragraph la lb iq lc b ld le ka lf lg lh kd li lj lk ll lm ln lo lp lq lr ls lt lu lv ij bi translated">让我们试着使不对称变量的分布正常化。我们将使用一种简单的特征工程技术，只需将这些值转换成它们的对数值。</p><p id="023d" class="pw-post-body-paragraph la lb iq lc b ld le ka lf lg lh kd li lj lk ll lm ln lo lp lq lr ls lt lu lv ij bi translated">本质是使我们的模型适当地一般化，而不偏向任何特定的倾斜值集。</p><pre class="kp kq kr ks gt nb nc nd ne aw nf bi"><span id="37bd" class="me mf iq nc b gy ng nh l ni nj"><strong class="nc ja">for i in diabetes_df.columns:<br/>    if i in ['Age', 'DiabetesPedigree', 'BMI', 'SerumInsulin']:<br/>        print(i)<br/>        diabetes_df[i] = diabetes_df[i].apply(np.log)<br/></strong>&gt;&gt;</span><span id="ea1c" class="me mf iq nc b gy nk nh l ni nj">SerumInsulin <br/>BMI <br/>DiabetesPedigree <br/>Age</span></pre><p id="5972" class="pw-post-body-paragraph la lb iq lc b ld le ka lf lg lh kd li lj lk ll lm ln lo lp lq lr ls lt lu lv ij bi translated">我们再来看看分布的形状。</p><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div role="button" tabindex="0" class="lz ma di mb bf mc"><div class="gh gi nn"><img src="../Images/5c346736de04338f6c9bbe563afd2128.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*hQ4RwGjQHMxSjvXY2Ee5pw.png"/></div></div><figcaption class="kw kx gj gh gi ky kz bd b be z dk translated">我们可以看到糖尿病、身体质量指数、血清白蛋白的分布有所改善，年龄分布也略有改善。</figcaption></figure><p id="6b5a" class="pw-post-body-paragraph la lb iq lc b ld le ka lf lg lh kd li lj lk ll lm ln lo lp lq lr ls lt lu lv ij bi translated">记住有两个数据集，一个是病人的数据，另一个是医生的数据。让我们看看医生的数据集，检查它的形状以及是否存在缺失值。</p><pre class="kp kq kr ks gt nb nc nd ne aw nf bi"><span id="6bef" class="me mf iq nc b gy ng nh l ni nj"><strong class="nc ja">doctors_link = '</strong><a class="ae lw" href="https://raw.githubusercontent.com/Blackman9t/Machine_Learning/master/doctors.csv'" rel="noopener ugc nofollow" target="_blank"><strong class="nc ja">https://raw.githubusercontent.com/Blackman9t/Machine_Learning/master/doctors.csv'</strong></a></span><span id="bb6d" class="me mf iq nc b gy nk nh l ni nj"><strong class="nc ja">doctors_df = pd.read_csv(doctors_link, encoding='latin-1')</strong><br/># Note the above code line throws a UnicodeDecodeError except we encode the string in latin-1 as shown above.</span><span id="961e" class="me mf iq nc b gy nk nh l ni nj"><strong class="nc ja">doctors_df.head()</strong></span></pre><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div role="button" tabindex="0" class="lz ma di mb bf mc"><div class="gh gi nl"><img src="../Images/8c9335a9aac87a80817ac91850f791e1.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*PbQCfWgD3StgowrFHXnqFQ.png"/></div></div><figcaption class="kw kx gj gh gi ky kz bd b be z dk translated"><strong class="bd md">我们可以看到医生数据集的前5行。它有14895行和2列。它没有缺失值。</strong></figcaption></figure><p id="3245" class="pw-post-body-paragraph la lb iq lc b ld le ka lf lg lh kd li lj lk ll lm ln lo lp lq lr ls lt lu lv ij bi translated">接下来，我们需要连接两个数据集，这样我们就可以看到哪个医生治疗了哪个病人。由于两个数据集有相同的PatientID列，我们将在这个列上连接它们，使用病人数据集的左外连接(或左连接)和右边的医生数据集。</p><p id="ef87" class="pw-post-body-paragraph la lb iq lc b ld le ka lf lg lh kd li lj lk ll lm ln lo lp lq lr ls lt lu lv ij bi translated">这将确保所有患者的记录都完好无损，即使有些医生的记录可能会丢失。因为我们有15000名患者和14895名医生的记录。</p><pre class="kp kq kr ks gt nb nc nd ne aw nf bi"><span id="2413" class="me mf iq nc b gy ng nh l ni nj"># let's merge both datasets into a new dataframe and check the shape and if missing values exist.<br/><strong class="nc ja">diabetes_doctor_df = pd.merge(diabetes_df, doctors_df, how='left', on='PatientID' )</strong></span><span id="fcac" class="me mf iq nc b gy nk nh l ni nj"><strong class="nc ja">diabetes_doctor_df.head()</strong></span></pre><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div role="button" tabindex="0" class="lz ma di mb bf mc"><div class="gh gi no"><img src="../Images/71bc3be981eb2826efb481509420ac93.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*HKApg36NRpCFc_CpMJYluw.png"/></div></div><figcaption class="kw kx gj gh gi ky kz bd b be z dk translated"><strong class="bd md">我们可以看到合并后的数据集。现在，通过合并PatientID列，我们知道哪个医生治疗了哪个病人。它也没有丢失值。</strong></figcaption></figure><p id="905f" class="pw-post-body-paragraph la lb iq lc b ld le ka lf lg lh kd li lj lk ll lm ln lo lp lq lr ls lt lu lv ij bi translated">但是等等……等等，我们在一个数据集中有14895个条目，与另一个有15000个条目的数据集合并，但是pandas告诉我们没有丢失值？？</p><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div class="gh gi np"><img src="../Images/77caaf3d67fbf6b2573894c35c4668e6.png" data-original-src="https://miro.medium.com/v2/resize:fit:844/format:webp/1*Y3ylDsSSOD6rDzjr_yJfLg.jpeg"/></div><figcaption class="kw kx gj gh gi ky kz bd b be z dk translated"><a class="ae lw" href="https://img.freepik.com/free-vector/thinking-emoji-with-sunglasses_1319-541.jpg?size=338&amp;ext=jpg" rel="noopener ugc nofollow" target="_blank"> <strong class="bd md"> img_credit </strong> </a></figcaption></figure><blockquote class="nq nr ns"><p id="4d85" class="la lb lx lc b ld le ka lf lg lh kd li nt lk ll lm nu lo lp lq nv ls lt lu lv ij bi translated">拥有健康的好奇心是数据科学课程无法教给你的一项极其重要的技能。我们需要每天认真地、有意识地发展这种技能。</p></blockquote><p id="7370" class="pw-post-body-paragraph la lb iq lc b ld le ka lf lg lh kd li lj lk ll lm ln lo lp lq lr ls lt lu lv ij bi translated">让我们来看看数据集中独特的医生的数量。</p><pre class="kp kq kr ks gt nb nc nd ne aw nf bi"><span id="cad7" class="me mf iq nc b gy ng nh l ni nj"><strong class="nc ja">diabetes_doctor_df.Physician.nunique()<br/></strong>&gt;&gt;<strong class="nc ja"><br/>109</strong></span></pre><p id="33ec" class="pw-post-body-paragraph la lb iq lc b ld le ka lf lg lh kd li lj lk ll lm ln lo lp lq lr ls lt lu lv ij bi translated">这告诉我们只有<strong class="lc ja"> 109个独特的医生。</strong></p><p id="d5f5" class="pw-post-body-paragraph la lb iq lc b ld le ka lf lg lh kd li lj lk ll lm ln lo lp lq lr ls lt lu lv ij bi translated">让我们看看数据集中独特患者的数量。</p><pre class="kp kq kr ks gt nb nc nd ne aw nf bi"><span id="e3a2" class="me mf iq nc b gy ng nh l ni nj"><strong class="nc ja">diabetes_doctor_df.PatientID.nunique()</strong><br/>&gt;&gt;<br/>  <strong class="nc ja">14895</strong></span></pre><p id="fdd0" class="pw-post-body-paragraph la lb iq lc b ld le ka lf lg lh kd li lj lk ll lm ln lo lp lq lr ls lt lu lv ij bi translated"><strong class="lc ja"> <em class="lx">现在有意义了，</em> </strong> <br/>有14895个独特的患者，而医生的记录正好有14895个患者的条目。<br/>患者数据集有15000个条目的事实仅仅是因为一些患者有多个条目。<br/>由于我们合并了PatientID列上的医生和患者，合并正确地将每个医生分配给他们治疗的患者，即使我们只有109个不同的医生。</p><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div class="gh gi np"><img src="../Images/54cacdb37995142b62dcacc99163518c.png" data-original-src="https://miro.medium.com/v2/resize:fit:844/format:webp/1*Hs1y0XNsZthC1ZOnx90zkQ.jpeg"/></div><figcaption class="kw kx gj gh gi ky kz bd b be z dk translated"><strong class="bd md">爽！！| </strong> <a class="ae lw" href="https://image.freepik.com/free-vector/smiling-face-with-sunglasses-emoji_1319-432.jpg" rel="noopener ugc nofollow" target="_blank"> <strong class="bd md"> img_credit </strong> </a></figcaption></figure><p id="4241" class="pw-post-body-paragraph la lb iq lc b ld le ka lf lg lh kd li lj lk ll lm ln lo lp lq lr ls lt lu lv ij bi translated">这就解释了。</p><p id="aa48" class="pw-post-body-paragraph la lb iq lc b ld le ka lf lg lh kd li lj lk ll lm ln lo lp lq lr ls lt lu lv ij bi translated"><strong class="lc ja">为机器学习准备数据集:</strong></p><p id="b620" class="pw-post-body-paragraph la lb iq lc b ld le ka lf lg lh kd li lj lk ll lm ln lo lp lq lr ls lt lu lv ij bi translated">正如机器学习的常见情况一样，在我们可以使用数据训练模型之前，需要进行一些数据准备。<br/>我们将对特征进行归一化，以便具有大值的特征不会支配训练。</p><p id="37c6" class="pw-post-body-paragraph la lb iq lc b ld le ka lf lg lh kd li lj lk ll lm ln lo lp lq lr ls lt lu lv ij bi translated">存在一些数据标准化方法，如<strong class="lc ja"> <em class="lx">简单特征缩放</em> </strong>、<strong class="lc ja"> <em class="lx">最小最大方法</em> </strong>和<strong class="lc ja"> <em class="lx"> Z分数</em> </strong>或<strong class="lc ja"> <em class="lx">标准分数</em> </strong>。</p><p id="32c7" class="pw-post-body-paragraph la lb iq lc b ld le ka lf lg lh kd li lj lk ll lm ln lo lp lq lr ls lt lu lv ij bi translated">查看每个特征的分布形状，具有大致正态分布钟形的特征将使用<strong class="lc ja"> <em class="lx"> Zscore方法</em> </strong>进行归一化。<br/>而具有变化的大值和低值的那些将使用<strong class="lc ja"> <em class="lx">最小-最大方法</em> </strong>进行归一化。关于这个见<a class="ae lw" href="https://github.com/Blackman9t/Machine_Learning/blob/master/DAT263x-Lab1.pdf" rel="noopener ugc nofollow" target="_blank"> <strong class="lc ja"> <em class="lx">微软Azure ML </em> </strong> </a>的链接。</p><blockquote class="nq nr ns"><p id="15e1" class="la lb lx lc b ld le ka lf lg lh kd li nt lk ll lm nu lo lp lq nv ls lt lu lv ij bi translated"><strong class="lc ja"> 1。z分或标准分:</strong> <br/> <em class="iq">这里的每个值，我们减去平均值或均值… </em> <br/> <em class="iq">然后除以标准差。</em> <br/> <em class="iq">这给出了一个介于-3和3之间的范围，但可以更大或更小</em></p><p id="a8e7" class="la lb lx lc b ld le ka lf lg lh kd li nt lk ll lm nu lo lp lq nv ls lt lu lv ij bi translated">Xnew= Xold均值/标准差(σ)</p><p id="c6a0" class="la lb lx lc b ld le ka lf lg lh kd li nt lk ll lm nu lo lp lq nv ls lt lu lv ij bi translated"><strong class="lc ja"> <em class="iq"> 2。最小-最大方法:</em> </strong> <br/> <em class="iq">该方法取每个值，减去最小值，然后除以范围(Max-min)……</em><br/><em class="iq">结果值的范围在零(0)和一(1)之间</em></p><p id="de8d" class="la lb lx lc b ld le ka lf lg lh kd li nt lk ll lm nu lo lp lq nv ls lt lu lv ij bi translated">xnew = Xold Xmin/Xmax Xmin</p></blockquote><p id="3aee" class="pw-post-body-paragraph la lb iq lc b ld le ka lf lg lh kd li lj lk ll lm ln lo lp lq lr ls lt lu lv ij bi translated">因此，让我们将这些方法应用于所选的列。</p><pre class="kp kq kr ks gt nb nc nd ne aw nf bi"><span id="0c05" class="me mf iq nc b gy ng nh l ni nj"># First select the features only and iterate through each one<br/><strong class="nc ja">for i in diabetes_doctor_df.columns[:-2]:<br/>    mean = diabetes_doctor_df[i].mean()<br/>    std = diabetes_doctor_df[i].std()<br/>    mini = diabetes_doctor_df[i].min()<br/>    maxi = diabetes_doctor_df[i].max()</strong><br/>    <br/>    # if columns are not Age or Pregnancies, apply the Z_score norm method<br/>    <strong class="nc ja">if i not in ['Age', 'Pregnancies']:<br/>        diabetes_doctor_df[i] = diabetes_doctor_df[i].apply(lambda x: (x - mean) / std)</strong><br/>    <br/>    # Else if columns are either Age or Pregnancies, then apply the Min-Max norm method<br/>    <strong class="nc ja">else:<br/>        diabetes_doctor_df[i] = diabetes_doctor_df[i].apply(lambda x: (x - mini) / (maxi - mini))</strong></span></pre><p id="7846" class="pw-post-body-paragraph la lb iq lc b ld le ka lf lg lh kd li lj lk ll lm ln lo lp lq lr ls lt lu lv ij bi translated">让我们来看看数据集</p><pre class="kp kq kr ks gt nb nc nd ne aw nf bi"><span id="f9fd" class="me mf iq nc b gy ng nh l ni nj"><strong class="nc ja">diabetes_doctor_df.head()</strong></span></pre><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div role="button" tabindex="0" class="lz ma di mb bf mc"><div class="gh gi nw"><img src="../Images/25c579106f9195359c7bc32c05cdce5c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*XNEa10G4e5IcX3zxtr4TQg.png"/></div></div><figcaption class="kw kx gj gh gi ky kz bd b be z dk translated"><strong class="bd md">归一化数据集的前5行。</strong></figcaption></figure><p id="14e3" class="pw-post-body-paragraph la lb iq lc b ld le ka lf lg lh kd li lj lk ll lm ln lo lp lq lr ls lt lu lv ij bi translated">现在我们已经准备好了数据集，我们将使用它来训练和评估分类器机器学习模型。我们将数据分成训练集和测试集，用它们来验证由训练模型生成的预测。</p><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div class="gh gi nx"><img src="../Images/ba6b980ee178640b93ff8255a3b9c805.png" data-original-src="https://miro.medium.com/v2/resize:fit:1312/format:webp/1*5DAklsV7oBhRyM2CQ6NAcg.jpeg"/></div><figcaption class="kw kx gj gh gi ky kz bd b be z dk translated"><strong class="bd md">在我们开始组装和训练模型之前，让我们确认最后一件事……</strong></figcaption></figure><h2 id="31ab" class="me mf iq bd md mg mh dn mi mj mk dp ml lj mm mn mo ln mp mq mr lr ms mt mu iw bi translated">数据集的类别分布是什么？</h2><p id="8632" class="pw-post-body-paragraph la lb iq lc b ld mv ka lf lg mw kd li lj mx ll lm ln my lp lq lr mz lt lu lv ij bi translated">简而言之……在15，000个观察结果中，有多少属于每个类别？</p><pre class="kp kq kr ks gt nb nc nd ne aw nf bi"><span id="d33e" class="me mf iq nc b gy ng nh l ni nj"><strong class="nc ja">diabetes_doctor_df.Diabetic.value_counts()</strong></span><span id="3793" class="me mf iq nc b gy nk nh l ni nj">&gt;&gt;<br/><strong class="nc ja">0 10000<br/>1 5000</strong></span><span id="f8bf" class="me mf iq nc b gy nk nh l ni nj"><strong class="nc ja"># Class 0 or Non-Diabetics has 10,000 observations<br/># Class 1 or Diabetics has 5,000 observations</strong></span></pre><p id="1064" class="pw-post-body-paragraph la lb iq lc b ld le ka lf lg lh kd li lj lk ll lm ln lo lp lq lr ls lt lu lv ij bi translated">这是一个问题，因为我们的模型将使用一个数据集进行训练，该数据集的一类观察值的数量是另一类的两倍。这意味着我们的模型将学习0级或非糖尿病患者的特征，远胜于学习如何对糖尿病患者进行分类。这可不好。</p><pre class="kp kq kr ks gt nb nc nd ne aw nf bi"><span id="7bb4" class="me mf iq nc b gy ng nh l ni nj"># Let's visualize the current class-distribution</span><span id="2216" class="me mf iq nc b gy nk nh l ni nj"><strong class="nc ja">plt.figure(figsize=(8, 8))</strong></span><span id="608c" class="me mf iq nc b gy nk nh l ni nj"><strong class="nc ja">x = diabetes_doctor_df.Diabetic.replace(to_replace=[0, 1], value=['Non-Diabetics','Diabetics'])<br/>sns.countplot(x)<br/>plt.title('Count of Diabetics and Non-Diabetics')<br/>plt.show()</strong></span></pre><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div class="gh gi ny"><img src="../Images/e1902357a4036cf515e20ab0d426f09a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1206/format:webp/1*iuICtdnJOS08agH2H1DSEQ.png"/></div><figcaption class="kw kx gj gh gi ky kz bd b be z dk translated"><strong class="bd md">糖尿病患者和非糖尿病患者的阶层分布</strong></figcaption></figure><h2 id="22d3" class="me mf iq bd md mg mh dn mi mj mk dp ml lj mm mn mo ln mp mq mr lr ms mt mu iw bi translated">平衡数据集:</h2><p id="b4f9" class="pw-post-body-paragraph la lb iq lc b ld mv ka lf lg mw kd li lj mx ll lm ln my lp lq lr mz lt lu lv ij bi translated">如前所述，不平衡的数据集使得分类器对于优势类具有高识别率<strong class="lc ja"> ( <em class="lx">灵敏度</em> ) </strong>。在不平衡的数据集中，模型的F1值可能不可靠。<a class="ae lw" href="https://sebastianraschka.com/faq/docs/computing-the-f1-score.html" rel="noopener ugc nofollow" target="_blank"> <strong class="lc ja"> <em class="lx">链接</em> </strong> </a></p><p id="6940" class="pw-post-body-paragraph la lb iq lc b ld le ka lf lg lh kd li lj lk ll lm ln lo lp lq lr ls lt lu lv ij bi translated">让我们继续使用SMOTE <strong class="lc ja"> <em class="lx">(合成少数过采样</em> </strong> <a class="ae lw" href="https://imbalanced-learn.readthedocs.io/en/stable/generated/imblearn.over_sampling.SMOTE.html" rel="noopener ugc nofollow" target="_blank"> <strong class="lc ja"> <em class="lx">技术</em> </strong> </a> <strong class="lc ja"> <em class="lx">)来平衡数据集。</em> </strong>注其他技术也可用于处理不平衡数据。详见本<a class="ae lw" href="https://towardsdatascience.com/handling-imbalanced-datasets-in-machine-learning-7a0e84220f28" rel="noopener" target="_blank"> <strong class="lc ja"> <em class="lx">丰富文章</em> </strong> </a>。</p><p id="824a" class="pw-post-body-paragraph la lb iq lc b ld le ka lf lg lh kd li lj lk ll lm ln lo lp lq lr ls lt lu lv ij bi translated">SMOTE将通过综合创建少数类的更多观察值来平衡数据集，以等同于优势类。在这种情况下，将创建额外的5，000个观察值并将其添加到糖尿病类，这样每个类就有10，000个观察值，总共有20，000个观察值。</p><pre class="kp kq kr ks gt nb nc nd ne aw nf bi"><span id="81c1" class="me mf iq nc b gy ng nh l ni nj"><strong class="nc ja">from imblearn.over_sampling import SMOTE<br/>sm = SMOTE(sampling_strategy='minority', random_state=19, k_neighbors=5)</strong></span><span id="1dcf" class="me mf iq nc b gy nk nh l ni nj"># Let's pass the features and label to the SMOTE object.</span><span id="7c9a" class="me mf iq nc b gy nk nh l ni nj"><strong class="nc ja">over_sampled_features, over_sampled_label = sm.fit_resample(feature_matrix, label)</strong></span><span id="34a1" class="me mf iq nc b gy nk nh l ni nj"># Let's print out the shape of the over_sampled object</span><span id="964b" class="me mf iq nc b gy nk nh l ni nj"><strong class="nc ja">print('Shape of resampled feature set is:',over_sampled_features.shape)<br/>print('Shape of resampled target data is:',over_sampled_label.shape)</strong></span><span id="0f2e" class="me mf iq nc b gy nk nh l ni nj">&gt;&gt;<br/><strong class="nc ja">Shape of resampled feature set is: (20000, 8) <br/>Shape of resampled target data is: (20000,)</strong></span><span id="7e47" class="me mf iq nc b gy nk nh l ni nj"># we now have 20,000 observations divided equally between classes Diabetics and Non-Diabetics</span></pre><p id="7fc8" class="pw-post-body-paragraph la lb iq lc b ld le ka lf lg lh kd li lj lk ll lm ln lo lp lq lr ls lt lu lv ij bi translated">我们可以想象新的阶级分布。</p><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div role="button" tabindex="0" class="lz ma di mb bf mc"><div class="gh gi nz"><img src="../Images/e8b7ac5faa98e1698b7a5efc40d967e0.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*7u11D0Yzpi2PmhQNGVCFqg.png"/></div></div><figcaption class="kw kx gj gh gi ky kz bd b be z dk translated"><strong class="bd md">观测值的等类分布。这意味着我们现在有20，000个观察值。</strong></figcaption></figure><p id="d12b" class="pw-post-body-paragraph la lb iq lc b ld le ka lf lg lh kd li lj lk ll lm ln lo lp lq lr ls lt lu lv ij bi translated">好了，让我们导入所需的库来分割数据集。</p><pre class="kp kq kr ks gt nb nc nd ne aw nf bi"><span id="19b8" class="me mf iq nc b gy ng nh l ni nj"># we shall import train_test_split module to split the dataset<br/><strong class="nc ja">from sklearn.model_selection import train_test_split</strong></span></pre><p id="af58" class="pw-post-body-paragraph la lb iq lc b ld le ka lf lg lh kd li lj lk ll lm ln lo lp lq lr ls lt lu lv ij bi translated">现在，我们可以继续将数据集分为训练集和测试集，其中70%用于训练，30%用于测试。通过设置参数<em class="lx"> test_size=0.3。</em>参见下面的代码</p><pre class="kp kq kr ks gt nb nc nd ne aw nf bi"><span id="6ffd" class="me mf iq nc b gy ng nh l ni nj"><strong class="nc ja">X_train, X_test, y_train, y_test = train_test_split(over_sampled_df.iloc[:,:-1], over_sampled_df.Diabetic, test_size=0.3, random_state=1234)</strong></span><span id="74e5" class="me mf iq nc b gy nk nh l ni nj"># let's print out the shapes of the training and testing datasets<br/><strong class="nc ja">print('X_train shape is',X_train.shape)<br/>print('X_test shape is',X_test.shape)<br/>print('y_train shape is',y_train.shape)<br/>print('y_test shape is',y_test.shape)</strong></span><span id="1cbc" class="me mf iq nc b gy nk nh l ni nj">&gt;&gt; This prints out<br/><strong class="nc ja">X_train shape is (14000, 8) <br/>X_test shape is (6000, 8) <br/>y_train shape is (14000,) <br/>y_test shape is (6000,)</strong></span></pre><p id="efbc" class="pw-post-body-paragraph la lb iq lc b ld le ka lf lg lh kd li lj lk ll lm ln lo lp lq lr ls lt lu lv ij bi translated">所以我们有14000个训练观察和6000个测试观察。</p><h2 id="7b02" class="me mf iq bd md mg mh dn mi mj mk dp ml lj mm mn mo ln mp mq mr lr ms mt mu iw bi translated">定义混淆矩阵指标:</h2><p id="7a66" class="pw-post-body-paragraph la lb iq lc b ld mv ka lf lg mw kd li lj mx ll lm ln my lp lq lr mz lt lu lv ij bi translated">如前所述，混淆矩阵产生了评估分类器模型的最理想的度量。它显示了<strong class="lc ja"><em class="lx"/></strong>和<strong class="lc ja"> <em class="lx">真阴性(TN) </em> </strong>，<em class="lx">这些是正确分类的</em> <em class="lx">病例</em>和<strong class="lc ja"> <em class="lx">假阳性(FP) </em> </strong>和<strong class="lc ja"> <em class="lx">假阴性(FN) </em> </strong>，<em class="lx">这些是错误分类的病例</em></p><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div role="button" tabindex="0" class="lz ma di mb bf mc"><div class="gh gi ly"><img src="../Images/a218e3548d45ee64a576b2eb796d156b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Xu-UN7eSBobpfMkary5tJQ.png"/></div></div></figure><blockquote class="nq nr ns"><p id="4689" class="la lb lx lc b ld le ka lf lg lh kd li nt lk ll lm nu lo lp lq nv ls lt lu lv ij bi translated">在<a class="ae lw" href="https://en.wikipedia.org/wiki/Binary_classification" rel="noopener ugc nofollow" target="_blank"> <strong class="lc ja">二元分类</strong> </a>中，<strong class="lc ja">精度</strong>(也叫<a class="ae lw" href="https://en.wikipedia.org/wiki/Positive_predictive_value" rel="noopener ugc nofollow" target="_blank"> <strong class="lc ja">正向预测值</strong> </a>)是相关实例在检索到的实例中所占的比例…</p><p id="5311" class="la lb lx lc b ld le ka lf lg lh kd li nt lk ll lm nu lo lp lq nv ls lt lu lv ij bi translated">而<strong class="lc ja"> recall </strong>(也称为<a class="ae lw" href="https://en.wikipedia.org/wiki/Sensitivity_and_specificity" rel="noopener ugc nofollow" target="_blank"> sensitivity </a>)是已经检索到的相关实例占相关实例总数的比例。</p><p id="5ab6" class="la lb lx lc b ld le ka lf lg lh kd li nt lk ll lm nu lo lp lq nv ls lt lu lv ij bi translated">因此，精确度和召回率都基于对<a class="ae lw" href="https://en.wikipedia.org/wiki/Relevance" rel="noopener ugc nofollow" target="_blank"> <strong class="lc ja">相关性</strong> </a> <strong class="lc ja">的理解和度量。参见</strong> <a class="ae lw" href="https://en.wikipedia.org/wiki/Precision_and_recall" rel="noopener ugc nofollow" target="_blank"> <strong class="lc ja">链接</strong> </a></p></blockquote><h2 id="7068" class="me mf iq bd md mg mh dn mi mj mk dp ml lj mm mn mo ln mp mq mr lr ms mt mu iw bi translated"><strong class="ak"> 1。准确度:</strong></h2><p id="87be" class="pw-post-body-paragraph la lb iq lc b ld mv ka lf lg mw kd li lj mx ll lm ln my lp lq lr mz lt lu lv ij bi translated">准确性仅仅是正确分类的案例的分数。例如，如果我们的模型正确地将10，000名<strong class="lc ja"><em class="lx"/></strong>糖尿病患者中的<strong class="lc ja"> <em class="lx"> 7，000人和10，000名<strong class="lc ja"><em class="lx"/></strong>非糖尿病患者中的<strong class="lc ja"/></em></strong>8，000人分类，这意味着:-</p><p id="1e4b" class="pw-post-body-paragraph la lb iq lc b ld le ka lf lg lh kd li lj lk ll lm ln lo lp lq lr ls lt lu lv ij bi translated"><strong class="lc ja"><em class="lx">TP = 7000，FN = 3,000，TN = 8,000，FP = 2000</em>T45】。</strong></p><p id="8ccb" class="pw-post-body-paragraph la lb iq lc b ld le ka lf lg lh kd li lj lk ll lm ln lo lp lq lr ls lt lu lv ij bi translated">这意味着我们的模型有一个<strong class="lc ja"><em class="lx"/></strong><strong class="lc ja"><em class="lx">的75% </em>。</strong></p><p id="1d9b" class="pw-post-body-paragraph la lb iq lc b ld le ka lf lg lh kd li lj lk ll lm ln lo lp lq lr ls lt lu lv ij bi translated"><strong class="lc ja">准确度= (TP + TN) / (TP + TN + FP + FN) </strong></p><p id="7a06" class="pw-post-body-paragraph la lb iq lc b ld le ka lf lg lh kd li lj lk ll lm ln lo lp lq lr ls lt lu lv ij bi translated"><strong class="lc ja">精度=(7000+8000)/(7000+8000+2000+3000)= 0.75</strong></p><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div role="button" tabindex="0" class="lz ma di mb bf mc"><div class="gh gi oa"><img src="../Images/c45c4dae8e4edc58297206ba64e0c740.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*TaaqqJoQIbKm5wL9OesKbw.jpeg"/></div></div><figcaption class="kw kx gj gh gi ky kz bd b be z dk translated"><strong class="bd md">通过混淆矩阵计算准确度</strong></figcaption></figure><p id="b46d" class="pw-post-body-paragraph la lb iq lc b ld le ka lf lg lh kd li lj lk ll lm ln lo lp lq lr ls lt lu lv ij bi translated">对于分类模型来说，准确性本身并不是一个可靠的衡量标准。原因很简单:-使用我们的不平衡数据集，例如，想象该模型对所有的<strong class="lc ja"><em class="lx"/></strong>10，000个非糖尿病病例进行正确分类<strong class="lc ja"><em class="lx">【100%】</em></strong>，并且仅对5，000个 糖尿病病例中的<strong class="lc ja"> <em class="lx"> 2，000个进行正确分类<strong class="lc ja"><em class="lx">(40%)</em><em class="lx">模型将是:-</em></strong></em></strong></p><p id="8467" class="pw-post-body-paragraph la lb iq lc b ld le ka lf lg lh kd li lj lk ll lm ln lo lp lq lr ls lt lu lv ij bi translated"><strong class="lc ja"><em class="lx">(10000+2000)/15000 = 80%准确</em> </strong>。</p><p id="d567" class="pw-post-body-paragraph la lb iq lc b ld le ka lf lg lh kd li lj lk ll lm ln lo lp lq lr ls lt lu lv ij bi translated">然而，这种模型在将糖尿病患者归类为<strong class="lc ja"> <em class="lx">时几乎毫无用处，60% </em> </strong>的病例会被错误归类。</p><h2 id="aafa" class="me mf iq bd md mg mh dn mi mj mk dp ml lj mm mn mo ln mp mq mr lr ms mt mu iw bi translated"><strong class="ak"> 2。回忆或敏感度或真阳性率:</strong></h2><p id="ac28" class="pw-post-body-paragraph la lb iq lc b ld mv ka lf lg mw kd li lj mx ll lm ln my lp lq lr mz lt lu lv ij bi translated">召回仅仅是从数据集中真实阳性案例的总数中正确分类的阳性案例的分数。例如，如果有<strong class="lc ja"> <em class="lx"> 10，000个</em> </strong> <strong class="lc ja"> <em class="lx">真实或真实阳性</em> </strong>糖尿病病例，并且我们的模型正确地将<strong class="lc ja"><em class="lx">7，000个</em></strong>归类为糖尿病患者<strong class="lc ja"><em class="lx"/></strong>，这意味着<strong class="lc ja"> <em class="lx"> 3000个</em> </strong>被错误地归类为非糖尿病患者<strong class="lc ja"> <em class="lx"> (FN) </em> </strong>。如果我们的模型也正确地将<strong class="lc ja"><em class="lx">8000</em><em class="lx">10000</em></strong>非糖尿病人<strong class="lc ja"><em class="lx"/></strong>分类，这就意味着<strong class="lc ja"> <em class="lx"> 2000 </em> </strong>非糖尿病人被错误地分类为<strong class="lc ja"> <em class="lx"> (FP)。</em> </strong></p><p id="c975" class="pw-post-body-paragraph la lb iq lc b ld le ka lf lg lh kd li lj lk ll lm ln lo lp lq lr ls lt lu lv ij bi translated">因此<strong class="lc ja"><em class="lx">TP = 7000，FN = 3,000，TN = 8,000，FP = 2000</em></strong>。</p><p id="fc7d" class="pw-post-body-paragraph la lb iq lc b ld le ka lf lg lh kd li lj lk ll lm ln lo lp lq lr ls lt lu lv ij bi translated">这意味着我们的型号有<strong class="lc ja">召回</strong>的<strong class="lc ja">70%<em class="lx">。</em></strong></p><p id="6e92" class="pw-post-body-paragraph la lb iq lc b ld le ka lf lg lh kd li lj lk ll lm ln lo lp lq lr ls lt lu lv ij bi translated"><strong class="lc ja">召回= TP / (TP + FN) </strong></p><p id="66e2" class="pw-post-body-paragraph la lb iq lc b ld le ka lf lg lh kd li lj lk ll lm ln lo lp lq lr ls lt lu lv ij bi translated"><strong class="lc ja">召回= 7000 / (7000 + 3000) = 0.7 </strong></p><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div role="button" tabindex="0" class="lz ma di mb bf mc"><div class="gh gi oa"><img src="../Images/1361c2539e883017c5222e8ef42aab42.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Khk2SrGHR8GOaILrzeRx5Q.jpeg"/></div></div><figcaption class="kw kx gj gh gi ky kz bd b be z dk translated"><strong class="bd md">通过混淆矩阵计算召回率</strong></figcaption></figure><h2 id="2521" class="me mf iq bd md mg mh dn mi mj mk dp ml lj mm mn mo ln mp mq mr lr ms mt mu iw bi translated"><strong class="ak"> 3。精度或正预测值:</strong></h2><p id="b336" class="pw-post-body-paragraph la lb iq lc b ld mv ka lf lg mw kd li lj mx ll lm ln my lp lq lr mz lt lu lv ij bi translated">精确度只是模型识别为阳性的案例总数中正确分类的阳性案例的分数。例如，如果有<strong class="lc ja"> <em class="lx"> 10，000个真实或真实阳性的</em> </strong>糖尿病病例，并且我们的模型正确地将<strong class="lc ja"><em class="lx"/></strong>7，000个归类为糖尿病患者<strong class="lc ja"><em class="lx">【TP】</em></strong>，这意味着<strong class="lc ja"> <em class="lx"> 3，000个</em> </strong>被错误地归类为<strong class="lc ja"><em class="lx">(T79)如果我们的模型也正确地将<strong class="lc ja"><em class="lx">8000</em></strong>从<strong class="lc ja"><em class="lx">10000</em></strong>非糖尿病人<strong class="lc ja"><em class="lx">【TN】</em></strong>中分类出来，这就意味着<strong class="lc ja"> <em class="lx"> 2000 </em> </strong>非糖尿病人被错误地分类为<strong class="lc ja"> <em class="lx"> (FP)。</em>T101】</strong></em></strong></p><p id="fe48" class="pw-post-body-paragraph la lb iq lc b ld le ka lf lg lh kd li lj lk ll lm ln lo lp lq lr ls lt lu lv ij bi translated">因此<strong class="lc ja"><em class="lx">TP = 7000，FN = 3,000，TN = 8,000，FP = 2000</em></strong>。</p><p id="072b" class="pw-post-body-paragraph la lb iq lc b ld le ka lf lg lh kd li lj lk ll lm ln lo lp lq lr ls lt lu lv ij bi translated">这意味着我们的模型有一个<strong class="lc ja"><em class="lx"/></strong><strong class="lc ja"><em class="lx"/>的78%。</strong></p><p id="895a" class="pw-post-body-paragraph la lb iq lc b ld le ka lf lg lh kd li lj lk ll lm ln lo lp lq lr ls lt lu lv ij bi translated"><strong class="lc ja">精度= TP / (TP + FP) </strong></p><p id="148c" class="pw-post-body-paragraph la lb iq lc b ld le ka lf lg lh kd li lj lk ll lm ln lo lp lq lr ls lt lu lv ij bi translated"><strong class="lc ja">精度= 7000 / (7000 + 2000) = 0.78 </strong></p><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div role="button" tabindex="0" class="lz ma di mb bf mc"><div class="gh gi oa"><img src="../Images/3d14d5757945a0dd28ec0bc38364fb04.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*tDZ-ERI6_2BtY0FfnvAENw.jpeg"/></div></div><figcaption class="kw kx gj gh gi ky kz bd b be z dk translated"><strong class="bd md">通过混淆矩阵计算精度</strong></figcaption></figure><blockquote class="nq nr ns"><p id="00b6" class="la lb lx lc b ld le ka lf lg lh kd li nt lk ll lm nu lo lp lq nv ls lt lu lv ij bi translated">在分类任务中，对于糖尿病类来说，1.0的完美精度分数意味着被标记为属于糖尿病类的每个项目确实属于糖尿病类。而1.0的召回意味着来自糖尿病类的每个项目都被标记为属于糖尿病类。</p></blockquote><h2 id="a3e3" class="me mf iq bd md mg mh dn mi mj mk dp ml lj mm mn mo ln mp mq mr lr ms mt mu iw bi translated"><strong class="ak">精确度和召回率之间的权衡:</strong></h2><p id="5a46" class="pw-post-body-paragraph la lb iq lc b ld mv ka lf lg mw kd li lj mx ll lm ln my lp lq lr mz lt lu lv ij bi translated"><strong class="lc ja">让我们暂时用脑癌代替糖尿病……</strong></p><p id="7264" class="pw-post-body-paragraph la lb iq lc b ld le ka lf lg lh kd li lj lk ll lm ln lo lp lq lr ls lt lu lv ij bi translated">通常，精确度和召回率之间存在反比关系，有可能以降低另一个为代价来提高一个。</p><p id="1762" class="pw-post-body-paragraph la lb iq lc b ld le ka lf lg lh kd li lj lk ll lm ln lo lp lq lr ls lt lu lv ij bi translated">考虑一个脑外科医生，他的任务是从病人的大脑中移除一个癌症肿瘤。外科医生需要切除所有的肿瘤细胞，因为任何残留的癌细胞都会使肿瘤再生。</p><p id="be29" class="pw-post-body-paragraph la lb iq lc b ld le ka lf lg lh kd li lj lk ll lm ln lo lp lq lr ls lt lu lv ij bi translated">相反，外科医生不得移除健康的脑细胞，因为这会使患者的大脑功能受损。外科医生可能在他切除的大脑区域更加自由，以确保他已经提取了所有的癌细胞。这个决定增加了召回率，但降低了精确度。</p><p id="4d74" class="pw-post-body-paragraph la lb iq lc b ld le ka lf lg lh kd li lj lk ll lm ln lo lp lq lr ls lt lu lv ij bi translated">另一方面，外科医生在切除大脑时可能会更加保守，以确保只提取癌细胞。这个决定增加了精确度，但是降低了召回率。</p><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div role="button" tabindex="0" class="lz ma di mb bf mc"><div class="gh gi ob"><img src="../Images/7e5fc089f21f5c3cd5ff65cfa4996f7a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Skjscb6UI0PDToB_bw9-tw.jpeg"/></div></div><figcaption class="kw kx gj gh gi ky kz bd b be z dk translated"><strong class="bd md">精确度和召回率的权衡</strong></figcaption></figure><blockquote class="nq nr ns"><p id="976c" class="la lb lx lc b ld le ka lf lg lh kd li nt lk ll lm nu lo lp lq nv ls lt lu lv ij bi translated">也就是说，更大的召回增加了清除健康细胞<strong class="lc ja">(阴性结果)</strong>的几率，增加了清除所有癌细胞<strong class="lc ja">(阳性结果)</strong>的几率。</p><p id="0686" class="la lb lx lc b ld le ka lf lg lh kd li nt lk ll lm nu lo lp lq nv ls lt lu lv ij bi translated">更高的精度会降低移除健康细胞的几率<strong class="lc ja">(阳性结果)</strong>，但也会降低移除所有癌细胞的几率<strong class="lc ja">(阴性结果)</strong>。</p></blockquote><h2 id="254d" class="me mf iq bd md mg mh dn mi mj mk dp ml lj mm mn mo ln mp mq mr lr ms mt mu iw bi translated">4.f1-分数或谐波-平均值:</h2><p id="b5a5" class="pw-post-body-paragraph la lb iq lc b ld mv ka lf lg mw kd li lj mx ll lm ln my lp lq lr mz lt lu lv ij bi translated">通常，精度和召回分数被组合成一个单一的度量，它立即告诉我们，我们的模型执行得有多好。F1-Score(精确度和召回率的加权<a class="ae lw" href="https://en.wikipedia.org/wiki/Harmonic_mean" rel="noopener ugc nofollow" target="_blank"> <strong class="lc ja"> <em class="lx">调和平均值</em> </strong> </a>)就是这样一个度量。</p><blockquote class="nq nr ns"><p id="1272" class="la lb lx lc b ld le ka lf lg lh kd li nt lk ll lm nu lo lp lq nv ls lt lu lv ij bi translated">完美的F1分数是1.0或100%。越接近1.0，模型越好。</p></blockquote><p id="99ab" class="pw-post-body-paragraph la lb iq lc b ld le ka lf lg lh kd li lj lk ll lm ln lo lp lq lr ls lt lu lv ij bi translated">从上面的例子中，我们得到了0.78的精确度和0.7的召回率</p><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div class="gh gi oc"><img src="../Images/9093315d254af77c94fccf06a674c3bf.png" data-original-src="https://miro.medium.com/v2/resize:fit:1270/format:webp/1*o7L1XFosYd2DbO4CNnQ2EA.jpeg"/></div></figure><p id="fff7" class="pw-post-body-paragraph la lb iq lc b ld le ka lf lg lh kd li lj lk ll lm ln lo lp lq lr ls lt lu lv ij bi translated"><strong class="lc ja"> <em class="lx">因此:F1 = 2 *(0.78 * 0.7)/(0.78+0.7)= 0.74</em></strong></p><h1 id="fd98" class="od mf iq bd md oe of og mi oh oi oj ml kf ok kg mo ki ol kj mr kl om km mu on bi translated">回到我们的分类任务…</h1><p id="0677" class="pw-post-body-paragraph la lb iq lc b ld mv ka lf lg mw kd li lj mx ll lm ln my lp lq lr mz lt lu lv ij bi translated">有了上述指标，我们有望很好地解释，让我们继续我们的任务，将临床患者的<strong class="lc ja"><em class="lx"/></strong>15000个观察结果分类为<strong class="lc ja"> <em class="lx">【糖尿病(1) </em> </strong>或<strong class="lc ja"> <em class="lx">非糖尿病(0) </em> </strong>。我们刚刚完成了一个SMOTE数据平衡活动，创建了<strong class="lc ja"> <em class="lx"> 5，000个</em> </strong>附加观察值，给我们一个<strong class="lc ja"> <em class="lx">总计20，000个</em> </strong>观察值，平均分成两个类。</p><p id="7f3b" class="pw-post-body-paragraph la lb iq lc b ld le ka lf lg lh kd li lj lk ll lm ln lo lp lq lr ls lt lu lv ij bi translated">然后我们把数据拆分成<strong class="lc ja"><em class="lx">14000个</em> </strong>训练集和<strong class="lc ja"><em class="lx">6000个</em> </strong>测试集。</p><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div role="button" tabindex="0" class="lz ma di mb bf mc"><div class="gh gi oo"><img src="../Images/a1acdb666ec50dc6389d9e93e34c0326.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*7FZaiHzpsN_tsx9kAkE04g.png"/></div></div></figure><p id="6844" class="pw-post-body-paragraph la lb iq lc b ld le ka lf lg lh kd li lj lk ll lm ln lo lp lq lr ls lt lu lv ij bi translated">让我们构建决策树分类器，并导入用于计算F1分数、混淆矩阵和Log_loss的模块</p><pre class="kp kq kr ks gt nb nc nd ne aw nf bi"><span id="0ec6" class="me mf iq nc b gy ng nh l ni nj">from sklearn.tree import DecisionTreeClassifier<br/>from sklearn import metrics<br/>from sklearn.metrics import f1_score<br/>from sklearn.metrics import confusion_matrix<br/>from sklearn.metrics import log_loss</span></pre><h2 id="3580" class="me mf iq bd md mg mh dn mi mj mk dp ml lj mm mn mo ln mp mq mr lr ms mt mu iw bi translated">我们将定义三种方法:-</h2><ol class=""><li id="9e6b" class="op oq iq lc b ld mv lg mw lj or ln os lr ot lv ou ov ow ox bi translated">绘制混淆矩阵，并给它传递一些参数</li><li id="71e4" class="op oq iq lc b ld oy lg oz lj pa ln pb lr pc lv ou ov ow ox bi translated">用于绘制ROC图</li><li id="c533" class="op oq iq lc b ld oy lg oz lj pa ln pb lr pc lv ou ov ow ox bi translated">用于创建最大深度范围从1到100的最佳决策树分类器或模型。</li></ol><pre class="kp kq kr ks gt nb nc nd ne aw nf bi"><span id="b7c4" class="me mf iq nc b gy ng nh l ni nj"><strong class="nc ja">1. plot_confusion_matrix(cm, classes,<br/>                          normalize=False,<br/>                          title='Confusion matrix',<br/>                          cmap=plt.cm.Blues):</strong></span><span id="26bb" class="me mf iq nc b gy nk nh l ni nj"><strong class="nc ja">2. plot_roc_chart(model)</strong></span><span id="7252" class="me mf iq nc b gy nk nh l ni nj"><strong class="nc ja">3. best_decision_tree_classifier(X_train, X_test, y_train, y_test)</strong></span></pre><p id="e6e9" class="pw-post-body-paragraph la lb iq lc b ld le ka lf lg lh kd li lj lk ll lm ln lo lp lq lr ls lt lu lv ij bi translated">为了避免冗长，我不会在这里完整地复制和粘贴这些方法。但是可以跟着笔记本一起上<a class="ae lw" href="https://github.com/Blackman9t/Machine_Learning/blob/master/Understanding_Confusion_Matrix1.ipynb" rel="noopener ugc nofollow" target="_blank"><strong class="lc ja"><em class="lx">Github</em></strong></a>。</p><h2 id="3314" class="me mf iq bd md mg mh dn mi mj mk dp ml lj mm mn mo ln mp mq mr lr ms mt mu iw bi translated">混淆矩阵分析:</h2><ol class=""><li id="bca4" class="op oq iq lc b ld mv lg mw lj or ln os lr ot lv ou ov ow ox bi translated"><strong class="lc ja">评估不平衡数据集:</strong></li></ol><p id="1a92" class="pw-post-body-paragraph la lb iq lc b ld le ka lf lg lh kd li lj lk ll lm ln lo lp lq lr ls lt lu lv ij bi translated">如果我们没有平衡数据集(<strong class="lc ja"> <em class="lx"> 10，000 </em> </strong> class-0和<strong class="lc ja"> <em class="lx"> 5，000 </em> </strong> class-1)并使用它为模型训练上述三种方法的确切参数，请参见下面的结果:</p><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div role="button" tabindex="0" class="lz ma di mb bf mc"><div class="gh gi pd"><img src="../Images/ad720131c3f791765b9946513c2587c3.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*axyaj3eE3CJN2-gFuoHzRA.jpeg"/></div></div><figcaption class="kw kx gj gh gi ky kz bd b be z dk translated"><strong class="bd md">不平衡数据集混淆矩阵</strong></figcaption></figure><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div role="button" tabindex="0" class="lz ma di mb bf mc"><div class="gh gi pe"><img src="../Images/086501aad70824be1f286747dbd5dbcf.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*UeH30aWhIOMVUxzUptF31A.jpeg"/></div></div><figcaption class="kw kx gj gh gi ky kz bd b be z dk translated"><strong class="bd md">不平衡数据集指标得分</strong></figcaption></figure><p id="b831" class="pw-post-body-paragraph la lb iq lc b ld le ka lf lg lh kd li lj lk ll lm ln lo lp lq lr ls lt lu lv ij bi translated"><strong class="lc ja"> 2。评估平衡数据集:</strong></p><p id="b712" class="pw-post-body-paragraph la lb iq lc b ld le ka lf lg lh kd li lj lk ll lm ln lo lp lq lr ls lt lu lv ij bi translated">让我们也来看看平衡数据集的混淆矩阵，使用上面定义的与不平衡数据集完全相同的方法。</p><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div role="button" tabindex="0" class="lz ma di mb bf mc"><div class="gh gi pf"><img src="../Images/1a569802d5e9b7fb46b5faf65a68eb5b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Hz4S7yON70nE-3a8WSP6og.jpeg"/></div></div><figcaption class="kw kx gj gh gi ky kz bd b be z dk translated"><strong class="bd md">平衡数据集混淆矩阵</strong></figcaption></figure><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div role="button" tabindex="0" class="lz ma di mb bf mc"><div class="gh gi pg"><img src="../Images/3fde3d46e926d3bbdd7a9ad156f9c7aa.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*NcpUIWtyf6NCoYAxGiwx9A.png"/></div></div><figcaption class="kw kx gj gh gi ky kz bd b be z dk translated"><strong class="bd md">平衡数据集指标得分</strong></figcaption></figure><p id="17d9" class="pw-post-body-paragraph la lb iq lc b ld le ka lf lg lh kd li lj lk ll lm ln lo lp lq lr ls lt lu lv ij bi translated">我们可以清楚地看到，通过简单地平衡我们的数据集，该模型能够在对患者进行分类方面表现得更好。所有指标都比<strong class="lc ja"> <em class="lx">召回率、精确度、F1分数和AUC分数</em> </strong>有所提高。请参见下表:-</p><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div role="button" tabindex="0" class="lz ma di mb bf mc"><div class="gh gi ph"><img src="../Images/998d9006c8c4ac3b97a6f3ac2ddb2643.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*ueciHcpS02RRQY7FG2lJig.png"/></div></div><figcaption class="kw kx gj gh gi ky kz bd b be z dk translated"><strong class="bd md">比较不平衡数据集和平衡数据集的指标</strong></figcaption></figure><p id="0090" class="pw-post-body-paragraph la lb iq lc b ld le ka lf lg lh kd li lj lk ll lm ln lo lp lq lr ls lt lu lv ij bi translated">该模型在平衡数据集方面做得很好。在所有关键指标中得分至少为92%。这在涉及患者实际分类的真实场景中非常重要。</p><p id="af00" class="pw-post-body-paragraph la lb iq lc b ld le ka lf lg lh kd li lj lk ll lm ln lo lp lq lr ls lt lu lv ij bi translated">请记住，该模型不仅返回0或1，它实际上还返回一个介于0和1之间的数字，显示每个患者的概率得分。</p><pre class="kp kq kr ks gt nb nc nd ne aw nf bi"><span id="4a1b" class="me mf iq nc b gy ng nh l ni nj"># getting the probability of the predicted observations.</span><span id="2805" class="me mf iq nc b gy nk nh l ni nj"><strong class="nc ja">probs = model.predict_proba(X_test)</strong></span></pre><p id="9e0b" class="pw-post-body-paragraph la lb iq lc b ld le ka lf lg lh kd li lj lk ll lm ln lo lp lq lr ls lt lu lv ij bi translated">这意味着被分类为非糖尿病(0)的患者可能具有接近糖尿病阈值的概率得分。因此，使用好的分类器模型，医疗从业者将更好地被告知建议和管理这样的患者。</p><h2 id="431c" class="me mf iq bd md mg mh dn mi mj mk dp ml lj mm mn mo ln mp mq mr lr ms mt mu iw bi translated">最后，让我们看看ROC曲线和AUC-Score:</h2><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div class="gh gi pi"><img src="../Images/777b54099b368b3203c99f93d3199e59.png" data-original-src="https://miro.medium.com/v2/resize:fit:890/format:webp/1*VLgNdyW2V8WP1DMaTHJPYQ.jpeg"/></div><figcaption class="kw kx gj gh gi ky kz bd b be z dk translated"><strong class="bd md">ROC曲线和AUC测度| </strong> <a class="ae lw" href="https://www.google.com/url?sa=i&amp;source=images&amp;cd=&amp;ved=2ahUKEwiw46_7qI_kAhVOJhoKHRV6CmgQjRx6BAgBEAQ&amp;url=https%3A%2F%2Ftowardsdatascience.com%2Funderstanding-auc-roc-curve-68b2303cc9c5&amp;psig=AOvVaw3NnO2RRX-xsk2sBTtYetJp&amp;ust=1566317248928586" rel="noopener ugc nofollow" target="_blank"> img_credit </a></figcaption></figure><p id="73bc" class="pw-post-body-paragraph la lb iq lc b ld le ka lf lg lh kd li lj lk ll lm ln lo lp lq lr ls lt lu lv ij bi translated">简单来说，<strong class="lc ja">受试者工作特性曲线或</strong> ROC曲线显示了<strong class="lc ja"><em class="lx"/></strong><em class="lx">(正确分类的阳性病例)</em>和<strong class="lc ja"><em class="lx"/></strong><em class="lx">(错误分类的阳性病例)</em>之间的权衡</p><p id="e8df" class="pw-post-body-paragraph la lb iq lc b ld le ka lf lg lh kd li lj lk ll lm ln lo lp lq lr ls lt lu lv ij bi translated">让我们定义一些绘制ROC曲线时要考虑的指标。</p><ol class=""><li id="15fe" class="op oq iq lc b ld le lg lh lj pj ln pk lr pl lv ou ov ow ox bi translated"><strong class="lc ja">真阳性率</strong> : <em class="lx">又名回忆，又名灵敏度</em>。这只是我们之前定义的召回。它告诉我们从数据集中的阳性病例总数中正确识别为<strong class="lc ja"><em class="lx">【TP】</em></strong>的阳性病例的比例。</li></ol><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div class="gh gi pm"><img src="../Images/7296e3f9bd79a88da1e7fa3c5b1c3ca3.png" data-original-src="https://miro.medium.com/v2/resize:fit:1020/format:webp/1*gO4wUTjylFUxsg4KIckpfw.jpeg"/></div></figure><p id="252b" class="pw-post-body-paragraph la lb iq lc b ld le ka lf lg lh kd li lj lk ll lm ln lo lp lq lr ls lt lu lv ij bi translated">2.<strong class="lc ja">真阴性率</strong> : <strong class="lc ja"> </strong> <em class="lx">又名特异性，又名选择性。</em>这只是从数据集中的阴性病例总数中测量被正确识别为<strong class="lc ja"><em class="lx">【TN】</em></strong>的阴性病例的比例</p><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div class="gh gi pn"><img src="../Images/d056b155b6a5819d69c3d6f9fdfdf561.png" data-original-src="https://miro.medium.com/v2/resize:fit:810/format:webp/1*q7Kp4G5puV5Pp4tliOGNVg.jpeg"/></div></figure><p id="d300" class="pw-post-body-paragraph la lb iq lc b ld le ka lf lg lh kd li lj lk ll lm ln lo lp lq lr ls lt lu lv ij bi translated">3.<strong class="lc ja">假阳性率</strong>:这是数据集中实际阴性病例总数中，被错误分类为阳性的阴性病例数的分数<strong class="lc ja"><em class="lx">【FP】</em></strong>。</p><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div class="gh gi po"><img src="../Images/5be29d8e579f310b96ef8a85a27979d1.png" data-original-src="https://miro.medium.com/v2/resize:fit:948/format:webp/1*02DyTkq-rZMfj3HkqTWJRw.jpeg"/></div></figure><p id="09b0" class="pw-post-body-paragraph la lb iq lc b ld le ka lf lg lh kd li lj lk ll lm ln lo lp lq lr ls lt lu lv ij bi translated">所以事实是，如果我们绘制一张图表，将所有对应的<strong class="lc ja"> <em class="lx">真阳性率</em> </strong>的值放在Y轴上，将所有对应的<strong class="lc ja"> <em class="lx">假阳性率</em> </strong>的值放在X轴上，结果将是ROC曲线。</p><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div class="gh gi pi"><img src="../Images/777b54099b368b3203c99f93d3199e59.png" data-original-src="https://miro.medium.com/v2/resize:fit:890/format:webp/1*VLgNdyW2V8WP1DMaTHJPYQ.jpeg"/></div><figcaption class="kw kx gj gh gi ky kz bd b be z dk translated"><strong class="bd md"> ROC曲线:TPR和FPR所有对应值的曲线图</strong></figcaption></figure><p id="e0c0" class="pw-post-body-paragraph la lb iq lc b ld le ka lf lg lh kd li lj lk ll lm ln lo lp lq lr ls lt lu lv ij bi translated">ROC曲线下的<strong class="lc ja">面积</strong>或<strong class="lc ja"> AUC </strong>是真阳性率和假阳性率之间的权衡。</p><blockquote class="nq nr ns"><p id="675c" class="la lb lx lc b ld le ka lf lg lh kd li nt lk ll lm nu lo lp lq nv ls lt lu lv ij bi translated">一个完美的分类器将具有1.0 的<strong class="lc ja"> AUC，表明在真阳性率和假阳性率之间没有折衷。因此，ROC曲线越靠近左上位置(1，1)，AUC得分越好。参见<a class="ae lw" href="https://github.com/Blackman9t/Machine_Learning/blob/master/DAT263x-Lab1.pdf" rel="noopener ugc nofollow" target="_blank">链接</a></strong>链接</p></blockquote><p id="fba7" class="pw-post-body-paragraph la lb iq lc b ld le ka lf lg lh kd li lj lk ll lm ln lo lp lq lr ls lt lu lv ij bi translated">让我们看看不平衡数据集和平衡数据集的ROC曲线。</p><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div role="button" tabindex="0" class="lz ma di mb bf mc"><div class="gh gi pp"><img src="../Images/eb62d621b7309bf69ef4592590d86a83.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*dMx9DjMM4jOUNMp3dnvKkg.jpeg"/></div></div><figcaption class="kw kx gj gh gi ky kz bd b be z dk translated"><strong class="bd md">不平衡数据集的ROC曲线。AUC = 0.89</strong><strong class="bd md">| log _ loss = 3.4616 | val _ ACC = 0.8998</strong></figcaption></figure><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div role="button" tabindex="0" class="lz ma di mb bf mc"><div class="gh gi pq"><img src="../Images/70f558f7ab2bc5d20317234afac166c1.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*ARRxX7eHm7D8QIsB2xvSUA.jpeg"/></div></div><figcaption class="kw kx gj gh gi ky kz bd b be z dk translated"><strong class="bd md">平衡数据集的ROC曲线。AUC = 0.92</strong><strong class="bd md">| log _ loss = 2.7056 | val _ ACC = 0.9217</strong></figcaption></figure><h2 id="5439" class="me mf iq bd md mg mh dn mi mj mk dp ml lj mm mn mo ln mp mq mr lr ms mt mu iw bi translated">总结:</h2><p id="ae82" class="pw-post-body-paragraph la lb iq lc b ld mv ka lf lg mw kd li lj mx ll lm ln my lp lq lr mz lt lu lv ij bi translated">这是一次颇有见地的会议，感谢您耐心阅读。我们学习了如何使用历史图检查分类任务的数据集。我们还解释了历史图和数据的分布，以便根据每个特征分布选择理想的特征归一化技术。</p><p id="cab8" class="pw-post-body-paragraph la lb iq lc b ld le ka lf lg lh kd li lj lk ll lm ln lo lp lq lr ls lt lu lv ij bi translated">然后使用SMOTE技术检查类分布并平衡数据集。我们继续为机器学习准备数据集，并深入挖掘混淆矩阵的单元和各种指标。</p><p id="efd0" class="pw-post-body-paragraph la lb iq lc b ld le ka lf lg lh kd li lj lk ll lm ln lo lp lq lr ls lt lu lv ij bi translated">最后，我们进行了分类，并比较了模型在不平衡数据集和平衡数据集上的性能。然后我们学习了ROC曲线和AUC分数。</p><p id="4294" class="pw-post-body-paragraph la lb iq lc b ld le ka lf lg lh kd li lj lk ll lm ln lo lp lq lr ls lt lu lv ij bi translated">原始数据集(<a class="ae lw" href="https://raw.githubusercontent.com/Blackman9t/Machine_Learning/master/diabetes.csv" rel="noopener ugc nofollow" target="_blank"> <strong class="lc ja"> <em class="lx">患者</em> </strong> </a>和<a class="ae lw" href="https://raw.githubusercontent.com/Blackman9t/Machine_Learning/master/doctors.csv" rel="noopener ugc nofollow" target="_blank"> <strong class="lc ja"> <em class="lx">医师</em> </strong> </a>)和<a class="ae lw" href="https://github.com/Blackman9t/Machine_Learning/blob/master/Understanding_Confusion_Matrix1.ipynb" rel="noopener ugc nofollow" target="_blank"> <strong class="lc ja"> <em class="lx">笔记本</em> </strong> </a>都在Github上。</p><p id="eea0" class="pw-post-body-paragraph la lb iq lc b ld le ka lf lg lh kd li lj lk ll lm ln lo lp lq lr ls lt lu lv ij bi translated">如果你需要复习统计学，一定要去看看斯坦福大学<strong class="lc ja"><em class="lx"/></strong><a class="ae lw" href="https://lagunita.stanford.edu/courses/course-v1:OLI+ProbStat+Open_Jan2017/about" rel="noopener ugc nofollow" target="_blank"><strong class="lc ja"><em class="lx">提供的免费课程</em></strong></a></p><p id="b081" class="pw-post-body-paragraph la lb iq lc b ld le ka lf lg lh kd li lj lk ll lm ln lo lp lq lr ls lt lu lv ij bi translated"><strong class="lc ja">干杯！</strong></p><h2 id="aae6" class="me mf iq bd md mg mh dn mi mj mk dp ml lj mm mn mo ln mp mq mr lr ms mt mu iw bi translated">关于我:</h2><p id="2a6d" class="pw-post-body-paragraph la lb iq lc b ld mv ka lf lg mw kd li lj mx ll lm ln my lp lq lr mz lt lu lv ij bi translated">劳伦斯是技术层的数据专家，对公平和可解释的人工智能和数据科学充满热情。我持有IBM的 <strong class="lc ja"> <em class="lx">数据科学专业</em> </strong> <em class="lx">和</em> <strong class="lc ja"> <em class="lx">高级数据科学专业</em> </strong> <em class="lx">证书。我已经使用ML和DL库进行了几个项目，我喜欢尽可能多地编写函数代码，即使现有的库比比皆是。最后，我从未停止学习和实验，是的，我拥有几个数据科学和人工智能认证，并且我已经写了几篇强烈推荐的文章。</em></p><p id="2aed" class="pw-post-body-paragraph la lb iq lc b ld le ka lf lg lh kd li lj lk ll lm ln lo lp lq lr ls lt lu lv ij bi translated">请随时在以下网址找到我</p><p id="31dd" class="pw-post-body-paragraph la lb iq lc b ld le ka lf lg lh kd li lj lk ll lm ln lo lp lq lr ls lt lu lv ij bi translated"><a class="ae lw" href="https://github.com/Lawrence-Krukrubo" rel="noopener ugc nofollow" target="_blank"> <strong class="lc ja"> Github </strong> </a></p><p id="f239" class="pw-post-body-paragraph la lb iq lc b ld le ka lf lg lh kd li lj lk ll lm ln lo lp lq lr ls lt lu lv ij bi translated"><a class="ae lw" href="https://www.linkedin.com/in/lawrencekrukrubo/" rel="noopener ugc nofollow" target="_blank"> <strong class="lc ja">领英</strong> </a></p><p id="4257" class="pw-post-body-paragraph la lb iq lc b ld le ka lf lg lh kd li lj lk ll lm ln lo lp lq lr ls lt lu lv ij bi translated"><a class="ae lw" href="https://twitter.com/LKrukrubo" rel="noopener ugc nofollow" target="_blank"> <strong class="lc ja">推特</strong> </a></p></div></div>    
</body>
</html>