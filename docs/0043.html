<html>
<head>
<title>Face Aging Using Conditional GANs</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">使用条件GANs的人脸老化</h1>
<blockquote>原文：<a href="https://pub.towardsai.net/face-aging-using-conditional-gans-an-introduction-to-age-cgans-machine-learning-8a4a6a100201?source=collection_archive---------1-----------------------#2019-05-13">https://pub.towardsai.net/face-aging-using-conditional-gans-an-introduction-to-age-cgans-machine-learning-8a4a6a100201?source=collection_archive---------1-----------------------#2019-05-13</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><h2 id="b589" class="io ip iq bd b dl ir is it iu iv iw dk ix translated" aria-label="kicker paragraph">Age-cGANs向AI解释|<a class="ae ep" href="https://pub.towardsai.net" rel="noopener ugc nofollow" target="_blank"/></h2><div class=""/><div class=""><h2 id="d7c7" class="pw-subtitle-paragraph jw iz iq bd b jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn dk translated">Age-cgan简介</h2></div><h1 id="33e3" class="ko kp iq bd kq kr ks kt ku kv kw kx ky kf kz kg la ki lb kj lc kl ld km le lf bi translated">介绍</h1><p id="2b6b" class="pw-post-body-paragraph lg lh iq li b lj lk ka ll lm ln kd lo lp lq lr ls lt lu lv lw lx ly lz ma mb ij bi translated"><strong class="li ja">条件GANs </strong> ( <a class="ae mc" href="https://arxiv.org/abs/1411.1784" rel="noopener ugc nofollow" target="_blank"> <strong class="li ja"> CGANs </strong> </a>)是GANs模型的扩展。你可以在我之前的帖子<a class="ae mc" href="https://medium.com/datadriveninvestor/an-introduction-to-conditional-gans-cgans-727d1f5bb011" rel="noopener">这里</a>阅读<strong class="li ja">条件句</strong>。在这篇文章中，我将尝试解释我们如何实现一个<strong class="li ja"> CGANs </strong>来执行自动人脸老化。<strong class="li ja">人脸衰老cGAN(Age-cGANs) </strong>由Grigory Antipov、Moez Baccouche和Jean-Luc Dugelay等人提出，在他们题为<a class="ae mc" href="https://arxiv.org/pdf/1702.01983.pdf" rel="noopener ugc nofollow" target="_blank"> <strong class="li ja"> <em class="md">的论文中提出人脸衰老与条件生成对抗网络</em> </strong> </a> <strong class="li ja"> <em class="md">。</em>T25】</strong></p><h1 id="691c" class="ko kp iq bd kq kr ks kt ku kv kw kx ky kf kz kg la ki lb kj lc kl ld km le lf bi translated">高级CGANs的架构图</h1><figure class="me mf mg mh gt mi gh gi paragraph-image"><div class="ab gu cl mj"><img src="../Images/c62fddfd22654ec0e608d41cb4232804.png" data-original-src="https://miro.medium.com/v2/format:webp/1*KdrUTDPaldtx3JWrbgW6ug.png"/></div><figcaption class="mm mn gj gh gi mo mp bd b be z dk translated"><a class="ae mc" href="https://medium.com/@connorshorten300/conditional-gans-639aa3785122" rel="noopener"> <strong class="bd kq"> cGANs架构</strong> </a></figcaption></figure><h1 id="840d" class="ko kp iq bd kq kr ks kt ku kv kw kx ky kf kz kg la ki lb kj lc kl ld km le lf bi translated">时代·卡根斯的建筑</h1><p id="364b" class="pw-post-body-paragraph lg lh iq li b lj lk ka ll lm ln kd lo lp lq lr ls lt lu lv lw lx ly lz ma mb ij bi translated"><strong class="li ja">脸老化-cGan </strong>有四个网络。</p><p id="dd51" class="pw-post-body-paragraph lg lh iq li b lj mq ka ll lm mr kd lo lp ms lr ls lt mt lv lw lx mu lz ma mb ij bi translated"><strong class="li ja">编码器:</strong>利用潜在向量z学习输入面部图像和年龄条件的逆映射</p><ul class=""><li id="eaeb" class="mv mw iq li b lj mq lm mr lp mx lt my lx mz mb na nb nc nd bi translated"><strong class="li ja">编码器</strong>网络生成输入图像的潜在向量。<strong class="li ja">编码器</strong>网络是一个CNN，它获取(64，64，3)维的图像，并将其转换为100维的向量。</li><li id="c284" class="mv mw iq li b lj ne lm nf lp ng lt nh lx ni mb na nb nc nd bi translated">有四个卷积块和两个密集层。</li><li id="f200" class="mv mw iq li b lj ne lm nf lp ng lt nh lx ni mb na nb nc nd bi translated">每个卷积块都有一个卷积层，后面是一个批量归一化层，除了第一个卷积层，还有一个激活函数。</li></ul><p id="2770" class="pw-post-body-paragraph lg lh iq li b lj mq ka ll lm mr kd lo lp ms lr ls lt mt lv lw lx mu lz ma mb ij bi translated"><strong class="li ja"> A FaceNet : </strong>它是一个面部识别网络，学习输入图像x和重建图像x’之间的差异。</p><ul class=""><li id="a62a" class="mv mw iq li b lj mq lm mr lp mx lt my lx mz mb na nb nc nd bi translated"><strong class="li ja"> FaceNet </strong>在给定的图像中识别一个人的身份。</li><li id="424f" class="mv mw iq li b lj ne lm nf lp ng lt nh lx ni mb na nb nc nd bi translated">可以使用没有完全连接的层的预训练的Inception、ResNet-50或Inception-ResNet-2模型。</li><li id="3e0b" class="mv mw iq li b lj ne lm nf lp ng lt nh lx ni mb na nb nc nd bi translated">可以通过计算嵌入的欧几里德距离来计算真实图像和重建图像的提取嵌入。</li></ul><p id="3d65" class="pw-post-body-paragraph lg lh iq li b lj mq ka ll lm mr kd lo lp ms lr ls lt mt lv lw lx mu lz ma mb ij bi translated"><strong class="li ja">生成器网络:</strong>它将人脸图像的隐藏表示和条件向量作为输入，生成图像。</p><ul class=""><li id="678b" class="mv mw iq li b lj mq lm mr lp mx lt my lx mz mb na nb nc nd bi translated"><strong class="li ja">生成器</strong>网络是CNN，它采用100维的潜在向量和条件向量y，并试图生成(64，64，3)维的真实图像</li><li id="ef99" class="mv mw iq li b lj ne lm nf lp ng lt nh lx ni mb na nb nc nd bi translated"><strong class="li ja">生成器</strong>网络具有密集层、上采样层和卷积层。</li><li id="0c29" class="mv mw iq li b lj ne lm nf lp ng lt nh lx ni mb na nb nc nd bi translated">它有两个输入，一个是噪声向量，第二个是条件向量。</li><li id="a078" class="mv mw iq li b lj ne lm nf lp ng lt nh lx ni mb na nb nc nd bi translated">条件向量是提供给网络的附加信息。对于年龄-cGAN，这将是年龄。</li></ul><p id="cc4d" class="pw-post-body-paragraph lg lh iq li b lj mq ka ll lm mr kd lo lp ms lr ls lt mt lv lw lx mu lz ma mb ij bi translated"><strong class="li ja">一个鉴别器网络:</strong>它<strong class="li ja"> </strong>试图区分真实图像和虚假图像。</p><ul class=""><li id="1795" class="mv mw iq li b lj mq lm mr lp mx lt my lx mz mb na nb nc nd bi translated"><strong class="li ja">鉴别器</strong>网络是一个CNN，它预测给定的图像是真是假。</li><li id="c910" class="mv mw iq li b lj ne lm nf lp ng lt nh lx ni mb na nb nc nd bi translated">有几个卷积块。每个卷积块包含一个卷积层，后跟一个批量归一化层和一个激活函数，但第一个卷积块除外，它没有批量归一化层。</li></ul><figure class="me mf mg mh gt mi gh gi paragraph-image"><div role="button" tabindex="0" class="nk nl di nm bf nn"><div class="gh gi nj"><img src="../Images/595511a18b1082e1227c34c615455cf1.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*UNphvZJyULZSMoi-5RTeRg.png"/></div></div><figcaption class="mm mn gj gh gi mo mp bd b be z dk translated"><a class="ae mc" href="https://arxiv.org/pdf/1702.01983.pdf" rel="noopener ugc nofollow" target="_blank"> <strong class="bd kq">在面对衰老的方法。(a)逼近潜在向量以重建输入图像；(b)在发生器G的输入端切换老化条件以执行面部老化。</strong>T11】</a></figcaption></figure><h1 id="3608" class="ko kp iq bd kq kr ks kt ku kv kw kx ky kf kz kg la ki lb kj lc kl ld km le lf bi translated">老龄化-cGANs的培训</h1><p id="4a13" class="pw-post-body-paragraph lg lh iq li b lj lk ka ll lm ln kd lo lp lq lr ls lt lu lv lw lx ly lz ma mb ij bi translated">Age-cGAN有四个网络，分三步训练。</p><p id="d14a" class="pw-post-body-paragraph lg lh iq li b lj mq ka ll lm mr kd lo lp ms lr ls lt mt lv lw lx mu lz ma mb ij bi translated"><strong class="li ja">条件GAN训练:生成器</strong>和<strong class="li ja">鉴别器</strong>网络训练。</p><ul class=""><li id="d08f" class="mv mw iq li b lj mq lm mr lp mx lt my lx mz mb na nb nc nd bi translated">cGAN训练可以表示为函数v(θG，θD)的优化，其中θG和θD分别是G和D的参数。</li></ul><figure class="me mf mg mh gt mi gh gi paragraph-image"><div class="gh gi no"><img src="../Images/e00f3d301b0b35be2b70c3f74a347cbd.png" data-original-src="https://miro.medium.com/v2/resize:fit:1152/format:webp/1*UguszUC7TVyeqC2J8ZD0KQ.png"/></div><figcaption class="mm mn gj gh gi mo mp bd b be z dk translated"><a class="ae mc" href="https://arxiv.org/pdf/1702.01983.pdf" rel="noopener ugc nofollow" target="_blank"> <strong class="bd kq">为cGANs的训练目标函数</strong> </a></figcaption></figure><p id="256e" class="pw-post-body-paragraph lg lh iq li b lj mq ka ll lm mr kd lo lp ms lr ls lt mt lv lw lx mu lz ma mb ij bi translated">在哪里</p><ul class=""><li id="3fb9" class="mv mw iq li b lj mq lm mr lp mx lt my lx mz mb na nb nc nd bi translated">log D(x，y)是<strong class="li ja">鉴别器</strong>模型的损耗。</li><li id="c72e" class="mv mw iq li b lj ne lm nf lp ng lt nh lx ni mb na nb nc nd bi translated">log(1-D(G(x，y′)，y′))是<strong class="li ja">发电机</strong>模型的损耗。</li><li id="eda6" class="mv mw iq li b lj ne lm nf lp ng lt nh lx ni mb na nb nc nd bi translated">p(数据)是所有可能图像的分布。</li></ul><p id="110b" class="pw-post-body-paragraph lg lh iq li b lj mq ka ll lm mr kd lo lp ms lr ls lt mt lv lw lx mu lz ma mb ij bi translated"><strong class="li ja">初始潜在向量逼近:编码器</strong>网络训练。</p><ul class=""><li id="c515" class="mv mw iq li b lj mq lm mr lp mx lt my lx mz mb na nb nc nd bi translated">初始潜在向量逼近法利用逼近一个潜在向量来优化人脸图像的重建。</li><li id="8549" class="mv mw iq li b lj ne lm nf lp ng lt nh lx ni mb na nb nc nd bi translated"><strong class="li ja">编码器</strong>是一个逼近潜在向量的神经网络。</li><li id="dfef" class="mv mw iq li b lj ne lm nf lp ng lt nh lx ni mb na nb nc nd bi translated">我们在生成的图像和真实图像上训练编码器网络。</li><li id="85fa" class="mv mw iq li b lj ne lm nf lp ng lt nh lx ni mb na nb nc nd bi translated">一旦被训练，编码器网络将开始从学习的分布产生潜在向量。</li><li id="81f8" class="mv mw iq li b lj ne lm nf lp ng lt nh lx ni mb na nb nc nd bi translated">用于训练编码器网络的训练目标函数是欧几里德距离损失</li></ul><p id="cd13" class="pw-post-body-paragraph lg lh iq li b lj mq ka ll lm mr kd lo lp ms lr ls lt mt lv lw lx mu lz ma mb ij bi translated"><strong class="li ja">潜在向量优化:</strong>同时优化<strong class="li ja">编码器</strong>和<strong class="li ja">发电机</strong>网络。</p><figure class="me mf mg mh gt mi gh gi paragraph-image"><div class="gh gi np"><img src="../Images/0cc3b1d9b93e3d6333a6b389b145f550.png" data-original-src="https://miro.medium.com/v2/resize:fit:930/format:webp/1*GVzb4eQRnlO2yKLAJ7ftBQ.png"/></div><figcaption class="mm mn gj gh gi mo mp bd b be z dk translated"><a class="ae mc" href="https://arxiv.org/pdf/1702.01983.pdf" rel="noopener ugc nofollow" target="_blank"> <strong class="bd kq">为潜在向量优化方程</strong> </a></figcaption></figure><p id="b587" class="pw-post-body-paragraph lg lh iq li b lj mq ka ll lm mr kd lo lp ms lr ls lt mt lv lw lx mu lz ma mb ij bi translated">在哪里</p><ul class=""><li id="38ac" class="mv mw iq li b lj mq lm mr lp mx lt my lx mz mb na nb nc nd bi translated">FR是面部识别网络，用于在输入面部图像x中识别人的身份</li><li id="016e" class="mv mw iq li b lj ne lm nf lp ng lt nh lx ni mb na nb nc nd bi translated">上面的等式是真实图像x和重建图像x '之间的欧几里德距离，并且它应该是最小的。</li><li id="5299" class="mv mw iq li b lj ne lm nf lp ng lt nh lx ni mb na nb nc nd bi translated">最小化这个欧几里德距离应该改善重建图像中的身份保持。</li></ul><figure class="me mf mg mh gt mi gh gi paragraph-image"><div class="gh gi nq"><img src="../Images/432f1c248a84ff54ab97814ab9a74f48.png" data-original-src="https://miro.medium.com/v2/resize:fit:516/format:webp/1*rd50KVxAlt5Ts7kx2mguFA.png"/></div><figcaption class="mm mn gj gh gi mo mp bd b be z dk translated"><a class="ae mc" href="https://arxiv.org/pdf/1702.01983.pdf" rel="noopener ugc nofollow" target="_blank"> <strong class="bd kq">一个</strong> </a></figcaption></figure><figure class="me mf mg mh gt mi gh gi paragraph-image"><div class="gh gi nr"><img src="../Images/3d0cb3563fe18ad6fedb995b1d0dfd09.png" data-original-src="https://miro.medium.com/v2/resize:fit:518/format:webp/1*BIGIjU0Q1sQDzC40N3KvUA.png"/></div><figcaption class="mm mn gj gh gi mo mp bd b be z dk translated"><a class="ae mc" href="https://arxiv.org/pdf/1702.01983.pdf" rel="noopener ugc nofollow" target="_blank">T5 bT7】</a></figcaption></figure><figure class="me mf mg mh gt mi gh gi paragraph-image"><div class="gh gi ns"><img src="../Images/7280f7b29c31c0d39eca05753b1d9577.png" data-original-src="https://miro.medium.com/v2/resize:fit:892/format:webp/1*nJ3TR8iHeX8BBiF4uGyJSg.png"/></div><figcaption class="mm mn gj gh gi mo mp bd b be z dk translated"><a class="ae mc" href="https://arxiv.org/pdf/1702.01983.pdf" rel="noopener ugc nofollow" target="_blank"> <strong class="bd kq"> c </strong> </a></figcaption></figure><figure class="me mf mg mh gt mi gh gi paragraph-image"><div role="button" tabindex="0" class="nk nl di nm bf nn"><div class="gh gi nt"><img src="../Images/e400378b2e5b1deb6d8d1c058904c0e7.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*DimJY4fsU1qgJsksSurwEw.png"/></div></div><figcaption class="mm mn gj gh gi mo mp bd b be z dk translated"><a class="ae mc" href="https://arxiv.org/pdf/1702.01983.pdf" rel="noopener ugc nofollow" target="_blank"> <strong class="bd kq"> d </strong> </a></figcaption></figure><ul class=""><li id="5018" class="mv mw iq li b lj mq lm mr lp mx lt my lx mz mb na nb nc nd bi translated">图像(a)是原始测试图像。</li><li id="7971" class="mv mw iq li b lj ne lm nf lp ng lt nh lx ni mb na nb nc nd bi translated">图像(b)是使用初始潜在近似值z0生成的重建图像。</li><li id="1ac6" class="mv mw iq li b lj ne lm nf lp ng lt nh lx ni mb na nb nc nd bi translated">图像(c)是使用“像素方式”和“身份保持”优化潜在近似生成的重建图像:z∫pixel和z∫IP。</li><li id="bb7a" class="mv mw iq li b lj ne lm nf lp ng lt nh lx ni mb na nb nc nd bi translated">图像(d)是使用身份保持z∫IP潜在近似生成的重建图像的老化，并以相应的年龄类别y(每列一个)为条件。</li></ul><p id="923c" class="pw-post-body-paragraph lg lh iq li b lj mq ka ll lm mr kd lo lp ms lr ls lt mt lv lw lx mu lz ma mb ij bi translated"><strong class="li ja">伴随jupyter本帖的笔记本可以在</strong><a class="ae mc" href="https://github.com/nitwmanish/Face-Aging-Using-Conditional-GAN" rel="noopener ugc nofollow" target="_blank"><strong class="li ja">Github</strong></a><strong class="li ja">上找到。</strong></p><h1 id="b2b3" class="ko kp iq bd kq kr ks kt ku kv kw kx ky kf kz kg la ki lb kj lc kl ld km le lf bi translated">结论</h1><p id="4d32" class="pw-post-body-paragraph lg lh iq li b lj lk ka ll lm ln kd lo lp lq lr ls lt lu lv lw lx ly lz ma mb ij bi translated"><strong class="li ja">年龄-cGANs </strong>也可以用来构建<em class="md">人脸老化</em>系统<em class="md">，</em>年龄合成和年龄进展有许多实际的工业和消费应用<em class="md"> </em>像跨年龄人脸识别、寻找走失的孩子、娱乐、电影中的视觉效果。</p><p id="28d5" class="pw-post-body-paragraph lg lh iq li b lj mq ka ll lm mr kd lo lp ms lr ls lt mt lv lw lx mu lz ma mb ij bi translated"><strong class="li ja"> <em class="md">我希望这篇文章能很好地解释和理解</em>年龄cgan，并<em class="md">帮助你开始构建自己的</em>年龄cgan<em class="md">。</em> </strong></p></div></div>    
</body>
</html>