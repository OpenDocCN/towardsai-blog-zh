<html>
<head>
<title>4 Graph Neural Networks you Need to Know (WLG, GCN, GAT, GIN)</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">你需要知道的4个图形神经网络(WLG、GCN、加特、金)</h1>
<blockquote>原文：<a href="https://pub.towardsai.net/4-graph-neural-networks-you-need-to-know-wlg-gcn-gat-gin-1bf10d29d836?source=collection_archive---------0-----------------------#2020-01-06">https://pub.towardsai.net/4-graph-neural-networks-you-need-to-know-wlg-gcn-gat-gin-1bf10d29d836?source=collection_archive---------0-----------------------#2020-01-06</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><figure class="is it gp gr iu iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi ir"><img src="../Images/614214083bbb71eefa950a84a558625c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*1TPIXtysZ90HKDC7"/></div></div><figcaption class="jc jd gj gh gi je jf bd b be z dk translated"><a class="ae jg" href="https://unsplash.com/@makcedward?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">马志威</a>在<a class="ae jg" href="https://unsplash.com/?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上拍照</figcaption></figure><div class=""/><p id="a8ac" class="pw-post-body-paragraph kg kh jj ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">在之前的图神经网络故事中，我们经历了<a class="ae jg" href="https://medium.com/towards-artificial-intelligence/a-gentle-introduction-to-graph-embeddings-c7b3d1db0fa8" rel="noopener">知识图嵌入</a>和<a class="ae jg" href="https://medium.com/towards-artificial-intelligence/random-walk-in-node-embeddings-deepwalk-node2vec-line-and-graphsage-ca23df60e493" rel="noopener">随机游走</a>。知识图嵌入为下游任务训练实体嵌入。另一方面，一些神经网络模型应用随机游走理论来训练实体嵌入。</p><p id="93d2" class="pw-post-body-paragraph kg kh jj ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">在这个故事中，我们将重点介绍4个图神经网络模型，它们是Weisfeiler-Lehman图核(Shervashidze等人，2011年)、图卷积网络(Kipf和Welling，2017年)、图注意网络(velikovi等人，2017年)和图同构网络(徐等人，2019年)</p><h1 id="bd66" class="le lf jj bd lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma mb bi translated">魏斯费勒-雷曼(WL)图核</h1><p id="3a96" class="pw-post-body-paragraph kg kh jj ki b kj mc kl km kn md kp kq kr me kt ku kv mf kx ky kz mg lb lc ld im bi translated">Shervashidze等人(2011)介绍了一种在图形神经网络上测量图形相似性的方法(WL测试)。通过WL检验意味着要么图是同构的，要么不能证明图不是同构的。</p><p id="44ab" class="pw-post-body-paragraph kg kh jj ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">在WL测试中，你可以定义图形的高度。高度意味着迭代次数。以下程序是h=1时的WL试验:</p><ol class=""><li id="a80c" class="mh mi jj ki b kj kk kn ko kr mj kv mk kz ml ld mm mn mo mp bi translated">每个节点的命名节点</li><li id="543d" class="mh mi jj ki b kj mq kn mr kr ms kv mt kz mu ld mm mn mo mp bi translated">添加连接的节点号。以图G为例，当节点4连接到节点1 (2次)、节点3和节点5时，节点4更新为节点4，1135。</li><li id="9f3a" class="mh mi jj ki b kj mq kn mr kr ms kv mt kz mu ld mm mn mo mp bi translated">简单的节点名。例如，将节点4，1135转换为11。(按顺序重新命名即可)</li><li id="6da7" class="mh mi jj ki b kj mq kn mr kr ms kv mt kz mu ld mm mn mo mp bi translated">重新标记新节点名</li><li id="bd73" class="mh mi jj ki b kj mq kn mr kr ms kv mt kz mu ld mm mn mo mp bi translated">检查原始节点标签和新生成标签的数量。如果两个节点的计数(特征向量)相同，则这两个图同构。</li></ol><figure class="mw mx my mz gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi mv"><img src="../Images/3d0e44d3c849a7feec9837cc61aac15a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Z5Q2uN_cQFp_Wk1lAKlwvg.png"/></div></div><figcaption class="jc jd gj gh gi je jf bd b be z dk translated">计算WL检验(h=1) (Shervashidze等人，2011年)</figcaption></figure><h1 id="5a58" class="le lf jj bd lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma mb bi translated">图形卷积网络(GCN)</h1><p id="5f74" class="pw-post-body-paragraph kg kh jj ki b kj mc kl km kn md kp kq kr me kt ku kv mf kx ky kz mg lb lc ld im bi translated">Kipf和Welling在2017年推出了图卷积网络(GCN)。GCN的基本思想是聚集自身特征和邻居特征。</p><p id="4dfa" class="pw-post-body-paragraph kg kh jj ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">下图显示了GCN的整体架构。以X2节点为例，它吸收X2特征(自身)、X1、X3和X4(邻居)特征，并馈入神经网络训练模型。</p><figure class="mw mx my mz gt iv gh gi paragraph-image"><div class="gh gi na"><img src="../Images/97d4fcad63be1e48a6f3092bace98fa7.png" data-original-src="https://miro.medium.com/v2/resize:fit:1210/format:webp/1*ZcX_82G0b0ZpzZUxAqQsiA.png"/></div><figcaption class="jc jd gj gh gi je jf bd b be z dk translated">图解图卷积网络(GCN) (Kipf和Welling，2016年)</figcaption></figure><p id="781f" class="pw-post-body-paragraph kg kh jj ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">关于节点的特征，可以是随机初始化或数字特征。以论文引用为例，文档是节点，边是引用。节点特征(例如文档)可以是一个热编码的字数、出版年份、作者。再比如社交网络。一个人是一个节点，而边是关系(如友谊)。特征包括一个城市的诞生，朋友的数量。</p><h1 id="925c" class="le lf jj bd lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma mb bi translated">图形注意网络</h1><p id="7f2c" class="pw-post-body-paragraph kg kh jj ki b kj mc kl km kn md kp kq kr me kt ku kv mf kx ky kz mg lb lc ld im bi translated">Velič ković等人受注意机制的启发，提出将其应用于图形神经网络。与GCN (Kipf和Welling，2017年)相同，图形注意力网络(GAT)(veli kovi等人，2017年)利用自身节点特征和邻居特征来训练模型。与自然语言处理(NLP)领域的<a class="ae jg" href="https://towardsdatascience.com/how-bert-leverage-attention-mechanism-and-transformer-to-learn-word-contextual-relations-5bbee1b6dbdb" rel="noopener" target="_blank"> BERT </a>相同，作者使用多头注意力来学习更多不同的注意力。</p><p id="fe03" class="pw-post-body-paragraph kg kh jj ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">使用注意力有几个好处:</p><ul class=""><li id="1aad" class="mh mi jj ki b kj kk kn ko kr mj kv mk kz ml ld nb mn mo mp bi translated">高计算效率，因为可以并行计算关注层</li><li id="c83c" class="mh mi jj ki b kj mq kn mr kr ms kv mt kz mu ld nb mn mo mp bi translated">对重要邻居给予更多关注</li><li id="3bdb" class="mh mi jj ki b kj mq kn mr kr ms kv mt kz mu ld nb mn mo mp bi translated">更强大，因为它可以支持直接图和无向图。</li><li id="6093" class="mh mi jj ki b kj mq kn mr kr ms kv mt kz mu ld nb mn mo mp bi translated">这是归纳学习，所以它可以处理看不见的节点。</li></ul><figure class="mw mx my mz gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi nc"><img src="../Images/d870541265c10c25e8482c848461d54d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*AGBM-8gCPPGmASLLpK2dxw.png"/></div></div><figcaption class="jc jd gj gh gi je jf bd b be z dk translated">左图:注意力网络图。右图:不同颜色代表多头关注。(Velič ković et la。, 2017)</figcaption></figure><h1 id="bbfd" class="le lf jj bd lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma mb bi translated">图形同构网络</h1><p id="2e1b" class="pw-post-body-paragraph kg kh jj ki b kj mc kl km kn md kp kq kr me kt ku kv mf kx ky kz mg lb lc ld im bi translated">拓扑相同可以是度量图的相似性的方法之一。传统上，我们可以让WL测试它。徐等人证明了杜松子酒的功效不亚于的试验:</p><ol class=""><li id="0acb" class="mh mi jj ki b kj kk kn ko kr mj kv mk kz ml ld mm mn mo mp bi translated">通过使用简单的架构(多层感知器)，图形神经网络(GNN)可以像WL测试一样强大。</li><li id="2c6e" class="mh mi jj ki b kj mq kn mr kr ms kv mt kz mu ld mm mn mo mp bi translated">GCN (Kipf和Welling，2017年)和GraphSAGE (Hamilton et al .，2017年)不能区分一些图结构。</li><li id="346c" class="mh mi jj ki b kj mq kn mr kr ms kv mt kz mu ld mm mn mo mp bi translated">在区分图结构方面，和聚集优于均值和最大聚集。</li></ol><figure class="mw mx my mz gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi nd"><img src="../Images/f29212840c8f21af21c2c5d071b23fdc.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*3RQxgpeAfXBb6lmgevAmYA.png"/></div></div><figcaption class="jc jd gj gh gi je jf bd b be z dk translated">平均值和最大值聚合无法区分两个图形。(徐等，2018)</figcaption></figure><h1 id="0d8e" class="le lf jj bd lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma mb bi translated">拿走</h1><ul class=""><li id="293d" class="mh mi jj ki b kj mc kn md kr ne kv nf kz ng ld nb mn mo mp bi translated">如果你需要处理看不见的节点，GCN可能不是你的选择，而GAT可以处理看不见的节点。</li><li id="22d3" class="mh mi jj ki b kj mq kn mr kr ms kv mt kz mu ld nb mn mo mp bi translated">GIN展示了一种更好地表示邻居聚合的方法。</li><li id="8e7d" class="mh mi jj ki b kj mq kn mr kr ms kv mt kz mu ld nb mn mo mp bi translated">您可以简单地使用<a class="ae jg" href="https://github.com/rusty1s/pytorch_geometric" rel="noopener ugc nofollow" target="_blank"> PyTorch几何</a>来应用GCN、GAT和GIN。</li></ul><h1 id="6757" class="le lf jj bd lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma mb bi translated">延伸阅读</h1><ul class=""><li id="4868" class="mh mi jj ki b kj mc kn md kr ne kv nf kz ng ld nb mn mo mp bi translated"><a class="ae jg" href="https://medium.com/towards-artificial-intelligence/a-gentle-introduction-to-graph-embeddings-c7b3d1db0fa8" rel="noopener">知识图嵌入</a></li><li id="893d" class="mh mi jj ki b kj mq kn mr kr ms kv mt kz mu ld nb mn mo mp bi translated"><a class="ae jg" href="https://medium.com/towards-artificial-intelligence/random-walk-in-node-embeddings-deepwalk-node2vec-line-and-graphsage-ca23df60e493" rel="noopener">图神经网络中的随机游走</a></li><li id="96e8" class="mh mi jj ki b kj mq kn mr kr ms kv mt kz mu ld nb mn mo mp bi translated"><a class="ae jg" href="https://towardsdatascience.com/how-to-do-deep-learning-on-graphs-with-graph-convolutional-networks-7d2250723780" rel="noopener" target="_blank"> GCN解释</a></li><li id="f6b7" class="mh mi jj ki b kj mq kn mr kr ms kv mt kz mu ld nb mn mo mp bi translated"><a class="ae jg" href="https://github.com/tkipf/pygcn" rel="noopener ugc nofollow" target="_blank"> GCN代码</a></li><li id="4d4c" class="mh mi jj ki b kj mq kn mr kr ms kv mt kz mu ld nb mn mo mp bi translated"><a class="ae jg" href="https://github.com/PetarV-/GAT" rel="noopener ugc nofollow" target="_blank"> GAT代码</a></li><li id="3ef6" class="mh mi jj ki b kj mq kn mr kr ms kv mt kz mu ld nb mn mo mp bi translated"><a class="ae jg" href="https://github.com/dmlc/dgl/tree/master/examples/pytorch/gin" rel="noopener ugc nofollow" target="_blank">轧花机代号</a></li></ul><h1 id="4cc8" class="le lf jj bd lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma mb bi translated">参考</h1><ul class=""><li id="8812" class="mh mi jj ki b kj mc kn md kr ne kv nf kz ng ld nb mn mo mp bi translated">名词（noun的缩写）Shervashidze、P. Schweitzer、E. J. Leeuwen、K.Mehlhorn和K. M. Borgwardt。<a class="ae jg" href="http://www.jmlr.org/papers/volume12/shervashidze11a/shervashidze11a.pdf" rel="noopener ugc nofollow" target="_blank">魏斯费勒-雷曼图形内核</a>。2011</li><li id="8aca" class="mh mi jj ki b kj mq kn mr kr ms kv mt kz mu ld nb mn mo mp bi translated">T.基普夫和m .韦林。<a class="ae jg" href="https://arxiv.org/pdf/1609.02907.pdf" rel="noopener ugc nofollow" target="_blank">基于图卷积网络的半监督分类</a>。2017</li><li id="45c2" class="mh mi jj ki b kj mq kn mr kr ms kv mt kz mu ld nb mn mo mp bi translated">页（page的缩写）Velič ković、G. Cucurull、A. Casanova、A. Romero、P. Liò和Y. Bengio。<a class="ae jg" href="https://arxiv.org/pdf/1710.10903.pdf" rel="noopener ugc nofollow" target="_blank">图形注意网络</a>。2017</li><li id="6558" class="mh mi jj ki b kj mq kn mr kr ms kv mt kz mu ld nb mn mo mp bi translated">K.徐、胡伟、j .莱斯科维奇和s .杰格尔卡。<a class="ae jg" href="https://arxiv.org/pdf/1810.00826.pdf" rel="noopener ugc nofollow" target="_blank">图形神经网络有多强大？</a>。2018.</li></ul></div></div>    
</body>
</html>