<html>
<head>
<title>Generative Adversarial Networks 102: DCGAN &amp; Mode Collapse</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">生成性对抗网络102: DCGAN和模式崩溃</h1>
<blockquote>原文：<a href="https://pub.towardsai.net/generative-adversarial-networks-102-dcgan-mode-collapse-ef119aa31a6f?source=collection_archive---------0-----------------------#2022-02-02">https://pub.towardsai.net/generative-adversarial-networks-102-dcgan-mode-collapse-ef119aa31a6f?source=collection_archive---------0-----------------------#2022-02-02</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><h2 id="a58e" class="ir is it bd b dl iu iv iw ix iy iz dk ja translated" aria-label="kicker paragraph"><a class="ae ep" href="https://towardsai.net/p/category/machine-learning/deep-learning" rel="noopener ugc nofollow" target="_blank">深度学习</a></h2><div class=""/><div class=""><h2 id="702b" class="pw-subtitle-paragraph jz jc it bd b ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq dk translated">革新简单的GAN以提高生成图像的质量。</h2></div><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi kr"><img src="../Images/7dcde276e78bba623d412aac4f381010.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Av7VIrXTUMCaCk1RJoEalw.png"/></div></div></figure><p id="3a18" class="pw-post-body-paragraph ld le it lf b lg lh kd li lj lk kg ll lm ln lo lp lq lr ls lt lu lv lw lx ly im bi translated">在我上一篇关于生成对抗网络的文章中，我们已经看到了这些巧妙简单而强大的模型是如何工作的，它们可以用来做什么，并且我们已经构建了一个非常简单的GAN来生成新的口袋妖怪物种。如果你还没有读过，请查看一下:</p><div class="lz ma gp gr mb mc"><a href="https://towardsdatascience.com/generative-adversarial-networks-101-c4b135a440d5" rel="noopener follow" target="_blank"><div class="md ab fo"><div class="me ab mf cl cj mg"><h2 class="bd jd gy z fp mh fr fs mi fu fw jc bi translated">生成性对抗网络101</h2><div class="mj l"><h3 class="bd b gy z fp mh fr fs mi fu fw dk translated">如何构建一个简单的GAN</h3></div><div class="mk l"><p class="bd b dl z fp mh fr fs mi fu fw dk translated">towardsdatascience.com</p></div></div><div class="ml l"><div class="mm l mn mo mp ml mq lb mc"/></div></div></a></div><p id="0b55" class="pw-post-body-paragraph ld le it lf b lg lh kd li lj lk kg ll lm ln lo lp lq lr ls lt lu lv lw lx ly im bi translated">在本文中，我们将把我们的模型更进一步，包括卷积层，更适合处理图像。我们将构建一个深度卷积GAN，或DCGAN，看看它是否能提高性能，以及它可能会带来什么问题。我们开始吧！</p><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div class="gh gi mr"><img src="../Images/ff08b5212dbc125df8651f08a5c82b0f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*4XiLZ-NLwWJ4FBZX.png"/></div></figure><h2 id="ccf1" class="ms mt it bd mu mv mw dn mx my mz dp na lm nb nc nd lq ne nf ng lu nh ni nj iz bi translated">深度卷积GAN</h2><p id="df38" class="pw-post-body-paragraph ld le it lf b lg nk kd li lj nl kg ll lm nm lo lp lq nn ls lt lu no lw lx ly im bi translated">有人可能会认为，从简单的前馈GAN网络过渡到卷积网络并不困难:只需用卷积网络取代密集层，就万事大吉了！然而，事实证明这比预期的要困难得多。</p><p id="f91a" class="pw-post-body-paragraph ld le it lf b lg lh kd li lj lk kg ll lm ln lo lp lq lr ls lt lu lv lw lx ly im bi translated">自从<a class="ae np" href="https://arxiv.org/abs/1406.2661" rel="noopener ugc nofollow" target="_blank"> Goodfellow等人在2014年提出最初的GAN </a>后，研究人员一直在试图使GAN更深，并使用卷积，以便它们可以生成更大更高质量的图像。这些任务被证明是困难的，因为训练是不稳定的，而CNN架构在监督问题上表现良好，但在应用于GANs时却变得无效。直到第一个成功的<a class="ae np" href="https://arxiv.org/pdf/1511.06434.pdf" rel="noopener ugc nofollow" target="_blank">深度卷积GAN被提出</a>，几乎花了两年时间。该模型被恰当地称为DCGAN，代表深度卷积GAN，是作者对不同模型架构进行大量实验的结果。最终，他们提出了以下一套指导方针:</p><ul class=""><li id="9e2c" class="nq nr it lf b lg lh lj lk lm ns lq nt lu nu ly nv nw nx ny bi translated">只使用大步卷积层，没有任何池或全连接层；</li><li id="dd9e" class="nq nr it lf b lg nz lj oa lm ob lq oc lu od ly nv nw nx ny bi translated">使用批处理规范化；</li><li id="789f" class="nq nr it lf b lg nz lj oa lm ob lq oc lu od ly nv nw nx ny bi translated">在生成器中对所有层使用ReLU激活，除了最后一层使用tanh</li><li id="487d" class="nq nr it lf b lg nz lj oa lm ob lq oc lu od ly nv nw nx ny bi translated">对所有层使用鉴别器中的LeakyReLU激活，除了最后一层，它不需要任何激活。</li></ul><p id="0590" class="pw-post-body-paragraph ld le it lf b lg lh kd li lj lk kg ll lm ln lo lp lq lr ls lt lu lv lw lx ly im bi translated">让我们看看为什么所有这些指导方针如此重要。</p><p id="f7f7" class="pw-post-body-paragraph ld le it lf b lg lh kd li lj lk kg ll lm ln lo lp lq lr ls lt lu lv lw lx ly im bi translated">首先，与使用确定性池化操作相反，使用步进卷积而不是池化层允许模型学习它自己的下采样(或上采样，在生成器的情况下)。这增加了网络的学习能力。接下来，不在卷积块上放置任何全连接层已经成为当时的一个增长趋势，人们使用全局平均池来代替。DCGAN的作者发现，全球平均池增加了模型的稳定性，但损害了收敛速度。作为折衷，他们建议将卷积层直接连接到输入端(在发生器中)或输出端(在鉴别器中),他们证明这样做效果很好。</p><p id="fe9b" class="pw-post-body-paragraph ld le it lf b lg lh kd li lj lk kg ll lm ln lo lp lq lr ls lt lu lv lw lx ly im bi translated">第二，DGGAN作者提倡使用批量标准化，它通过标准化网络单元的输入来稳定学习，使其均值为零，方差为一。这防止了由不幸的参数初始化引起的问题，并确保梯度在流经深层网络时不会消失。在GANs中，批处理规范化被证明有助于防止模式崩溃，这一点我们稍后会谈到。然而，关键的洞察力是<em class="oe">而不是</em>将其应用于发生器输出层和鉴别器输入层，因为那只会降低训练稳定性。</p><p id="a7ab" class="pw-post-body-paragraph ld le it lf b lg lh kd li lj lk kg ll lm ln lo lp lq lr ls lt lu lv lw lx ly im bi translated">最后，激活。作者建议在生成器中使用ReLU，因为它可以确保模型更快地饱和并覆盖数据的颜色空间。在鉴别器中，他们通过实验发现Leaky ReLU工作良好，尤其是在处理高分辨率图像时。</p><p id="211c" class="pw-post-body-paragraph ld le it lf b lg lh kd li lj lk kg ll lm ln lo lp lq lr ls lt lu lv lw lx ly im bi translated">让我们遵循这些准则来构建一个DCGAN，以生成新的口袋妖怪！</p><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div class="gh gi mr"><img src="../Images/ff08b5212dbc125df8651f08a5c82b0f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*4XiLZ-NLwWJ4FBZX.png"/></div></figure><h2 id="3c10" class="ms mt it bd mu mv mw dn mx my mz dp na lm nb nc nd lq ne nf ng lu nh ni nj iz bi translated">深度卷积生成器👨‍🎨</h2><p id="84eb" class="pw-post-body-paragraph ld le it lf b lg nk kd li lj nl kg ll lm nm lo lp lq nn ls lt lu no lw lx ly im bi translated">我们刚刚讨论过的生成器指南的PyTorch实现可能看起来像这样。我们在输出图像中使用4个通道，因为我们将使用的<a class="ae np" href="https://github.com/PokeAPI/sprites" rel="noopener ugc nofollow" target="_blank">口袋妖怪精灵</a>图像有4个颜色通道。</p><figure class="ks kt ku kv gt kw"><div class="bz fp l di"><div class="of og l"/></div></figure><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div class="gh gi mr"><img src="../Images/7864ae84d70b2d5294638a463d112ba8.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*SuoznQgsRDQITz4_.png"/></div></figure><h2 id="3d77" class="ms mt it bd mu mv mw dn mx my mz dp na lm nb nc nd lq ne nf ng lu nh ni nj iz bi translated">深度卷积鉴别器👮‍♀️</h2><p id="94db" class="pw-post-body-paragraph ld le it lf b lg nk kd li lj nl kg ll lm nm lo lp lq nn ls lt lu no lw lx ly im bi translated">鉴频器也将在其输入中使用4个通道。其他超参数，如每层中的块数或隐藏单元数，是任意选取的。让我们看看这将如何为我们的数据集工作。</p><figure class="ks kt ku kv gt kw"><div class="bz fp l di"><div class="of og l"/></div></figure><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div class="gh gi mr"><img src="../Images/7864ae84d70b2d5294638a463d112ba8.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*SuoznQgsRDQITz4_.png"/></div></figure><h2 id="601e" class="ms mt it bd mu mv mw dn mx my mz dp na lm nb nc nd lq ne nf ng lu nh ni nj iz bi translated">培养</h2><p id="5519" class="pw-post-body-paragraph ld le it lf b lg nk kd li lj nl kg ll lm nm lo lp lq nn ls lt lu no lw lx ly im bi translated">训练过程与我们用于简单的前馈GAN 的<a class="ae np" href="https://towardsdatascience.com/generative-adversarial-networks-101-c4b135a440d5" rel="noopener" target="_blank">非常相似。这个<code class="fe oh oi oj ok b">PokemonDataset</code>物品是我创作的，你可以在GitHub </a>上找到它<a class="ae np" href="https://github.com/MichalOleszak/gans/blob/main/gans/datasets.py" rel="noopener ugc nofollow" target="_blank">。</a></p><p id="4b73" class="pw-post-body-paragraph ld le it lf b lg lh kd li lj lk kg ll lm ln lo lp lq lr ls lt lu lv lw lx ly im bi translated">不同的是，我们手动初始化卷积层的参数，并为Adam优化器指定动量参数(betas)。我们还使用了一个很小的学习率，仅为0.0002。所有这些都是按照DCGAN作者的建议进行的。</p><figure class="ks kt ku kv gt kw"><div class="bz fp l di"><div class="of og l"/></div></figure><p id="919c" class="pw-post-body-paragraph ld le it lf b lg lh kd li lj lk kg ll lm ln lo lp lq lr ls lt lu lv lw lx ly im bi translated">发生器和鉴频器以及训练环路的损耗函数与前馈GAN完全相同。感兴趣的读者可以在之前的帖子中找到所有的<a class="ae np" href="https://towardsdatascience.com/generative-adversarial-networks-101-c4b135a440d5" rel="noopener" target="_blank">。你也可以在</a><a class="ae np" href="https://github.com/MichalOleszak/gans/blob/main/notebooks/dcgan.ipynb" rel="noopener ugc nofollow" target="_blank">这个笔记本</a>里自己运行代码。</p><p id="2791" class="pw-post-body-paragraph ld le it lf b lg lh kd li lj lk kg ll lm ln lo lp lq lr ls lt lu lv lw lx ly im bi translated">看看我们的GAN都出了什么！下面的图片显示了一些甘制作的口袋妖怪随着训练的进行。</p><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi ol"><img src="../Images/353c299abcf7835fec843dd545d43b7c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*6qS-Sfxm_2fzcHRGGvQfxA.png"/></div></div><figcaption class="om on gj gh gi oo op bd b be z dk translated">甘随着训练的进行生成了口袋妖怪。图片由作者提供。</figcaption></figure><p id="794b" class="pw-post-body-paragraph ld le it lf b lg lh kd li lj lk kg ll lm ln lo lp lq lr ls lt lu lv lw lx ly im bi translated">所有生成的图像都是一样的！这里发生了什么？</p><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div class="gh gi mr"><img src="../Images/4d7fba0e2b4fb7c24de736d880c8d15f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*et1IOYFiB841chwN.png"/></div></figure><h2 id="bdaa" class="ms mt it bd mu mv mw dn mx my mz dp na lm nb nc nd lq ne nf ng lu nh ni nj iz bi translated">模式崩溃</h2><p id="a7d5" class="pw-post-body-paragraph ld le it lf b lg nk kd li lj nl kg ll lm nm lo lp lq nn ls lt lu no lw lx ly im bi translated">我们现在看到的是所谓的<em class="oe">模式崩溃</em>的典型案例。为了理解这个术语，考虑一下发生器对其产生的图像进行采样的概率空间。这个概率空间通常是多模态的，也就是说，它有几个(或可能有许多)区域，从这些区域有可能生成图像，并且它有其他区域，从这些区域生成图像是不可能的。</p><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi oq"><img src="../Images/90020910a1b05f754f217662c5573ecf.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*Fb7cWW0J6Piv6BAD"/></div></div><figcaption class="om on gj gh gi oo op bd b be z dk translated">生成器的概率空间。Benjamin Grull 在<a class="ae np" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上的照片</figcaption></figure><p id="ba63" class="pw-post-body-paragraph ld le it lf b lg lh kd li lj lk kg ll lm ln lo lp lq lr ls lt lu lv lw lx ly im bi translated">想象一幅多山的风景。峰值是发生器概率分布的模式。发生器更有可能从一个峰而不是从一个谷的底部产生图像。理想地，从不同峰值生成的图像将类似于不同类型的训练数据图像。</p><p id="4896" class="pw-post-body-paragraph ld le it lf b lg lh kd li lj lk kg ll lm ln lo lp lq lr ls lt lu lv lw lx ly im bi translated">当发生器发现通过从一个特定的峰生成图像，它可以很好地欺骗鉴别器时，模式崩溃就发生了。这些图像甚至不需要看起来真实。如果出于某种原因，鉴别者无法正确地将它们归类为假货，这就足够了。生成器对此的反应将是生成更多这样的图像，导致它不断产生相同的输出。</p><p id="f62d" class="pw-post-body-paragraph ld le it lf b lg lh kd li lj lk kg ll lm ln lo lp lq lr ls lt lu lv lw lx ly im bi translated">随着训练的进行，鉴别者可能最终学会从真实的训练样本中辨别这些相同的假图像的任务。但是，发生器将简单地跳到鉴别器不擅长的另一个峰上，并从那里继续生成新的相同图像。</p><p id="8178" class="pw-post-body-paragraph ld le it lf b lg lh kd li lj lk kg ll lm ln lo lp lq lr ls lt lu lv lw lx ly im bi translated">这就是我们口袋妖怪的遭遇。对于纪元，生成器会生成看起来相似的形状，然后突然迁移到不同的形状。这是一个很好的例子，说明训练GANs是多么具有挑战性。</p><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div class="gh gi mr"><img src="../Images/86657e5f34ef77b54833cea091b712df.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*KDyFjGPbDd4n1Y1K.png"/></div></figure><h2 id="e4e6" class="ms mt it bd mu mv mw dn mx my mz dp na lm nb nc nd lq ne nf ng lu nh ni nj iz bi translated">防止模式崩溃</h2><p id="792f" class="pw-post-body-paragraph ld le it lf b lg nk kd li lj nl kg ll lm nm lo lp lq nn ls lt lu no lw lx ly im bi translated">发现了模式崩溃，我们能做些什么呢？一种方法是调整模型架构。改变层数，每层中的单元数，也许调整其他超参数，如学习率或优化器的动量设置。我们在这里使用的架构类似于作者在人脸和卧室数据集上测试的原始DCGAN架构。调整它，使之与我们的口袋妖怪一起工作可能是一个漫长而乏味的过程。</p><p id="a054" class="pw-post-body-paragraph ld le it lf b lg lh kd li lj lk kg ll lm ln lo lp lq lr ls lt lu lv lw lx ly im bi translated">幸运的是，还有另一种方法。训练gan的许多问题源于损失函数的选择。敬请关注下一篇文章，在这篇文章中，我们将使用一种称为Wasserstein distance的度量来取代我们迄今为止一直使用的二元交叉熵损失，以构建Wasserstein GAN或WGAN，并希望这将使我们的伪Pokomens更加真实！</p><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div class="gh gi mr"><img src="../Images/ed1fbd3ebc53e7943b5309a63f18950d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*Zz4chijZKt3Y6S1T.png"/></div></figure><h2 id="ecef" class="ms mt it bd mu mv mw dn mx my mz dp na lm nb nc nd lq ne nf ng lu nh ni nj iz bi translated">感谢</h2><p id="4861" class="pw-post-body-paragraph ld le it lf b lg nk kd li lj nl kg ll lm nm lo lp lq nn ls lt lu no lw lx ly im bi translated">这个DCGAN的训练循环代码以及损失计算函数是基于Coursera的<a class="ae np" href="https://www.coursera.org/specializations/generative-adversarial-networks-gans" rel="noopener ugc nofollow" target="_blank">由Sharon Zhou等人提出的生成对抗网络(GANs)专门化</a>。</p><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div class="gh gi mr"><img src="../Images/9b33492bbb90d8fcf79175f4ac653c66.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*Ubj30KUoi2ds77b3.png"/></div></figure><p id="e53c" class="pw-post-body-paragraph ld le it lf b lg lh kd li lj lk kg ll lm ln lo lp lq lr ls lt lu lv lw lx ly im bi translated">感谢阅读！</p><p id="6ac4" class="pw-post-body-paragraph ld le it lf b lg lh kd li lj lk kg ll lm ln lo lp lq lr ls lt lu lv lw lx ly im bi translated">如果你喜欢这篇文章，为什么不在我的新文章上<a class="ae np" href="https://michaloleszak.medium.com/subscribe" rel="noopener"> <strong class="lf jd">订阅电子邮件更新</strong> </a>？而通过<a class="ae np" href="https://michaloleszak.medium.com/membership" rel="noopener"> <strong class="lf jd">成为媒介会员</strong> </a>，就可以支持我的写作，获得其他作者和我自己的所有故事的无限访问权。</p><p id="d9e1" class="pw-post-body-paragraph ld le it lf b lg lh kd li lj lk kg ll lm ln lo lp lq lr ls lt lu lv lw lx ly im bi translated">需要咨询？你可以问我任何事情，也可以在这里 为我预约1:1 <a class="ae np" href="http://hiretheauthor.com/michal" rel="noopener ugc nofollow" target="_blank"> <strong class="lf jd">。</strong></a></p><p id="7368" class="pw-post-body-paragraph ld le it lf b lg lh kd li lj lk kg ll lm ln lo lp lq lr ls lt lu lv lw lx ly im bi translated">你也可以试试我的其他文章。不能选择？从这些中选择一个:</p><div class="lz ma gp gr mb mc"><a href="https://towardsdatascience.com/on-the-importance-of-bayesian-thinking-in-everyday-life-a74475fcceeb" rel="noopener follow" target="_blank"><div class="md ab fo"><div class="me ab mf cl cj mg"><h2 class="bd jd gy z fp mh fr fs mi fu fw jc bi translated">贝叶斯思维在日常生活中的重要性</h2><div class="mj l"><h3 class="bd b gy z fp mh fr fs mi fu fw dk translated">这个简单的思维转变将帮助你更好地理解你周围不确定的世界</h3></div><div class="mk l"><p class="bd b dl z fp mh fr fs mi fu fw dk translated">towardsdatascience.com</p></div></div><div class="ml l"><div class="or l mn mo mp ml mq lb mc"/></div></div></a></div><div class="lz ma gp gr mb mc"><a rel="noopener  ugc nofollow" target="_blank" href="/explainable-boosting-machines-c71b207231b5"><div class="md ab fo"><div class="me ab mf cl cj mg"><h2 class="bd jd gy z fp mh fr fs mi fu fw jc bi translated">可解释的助推机器</h2><div class="mj l"><h3 class="bd b gy z fp mh fr fs mi fu fw dk translated">保持高准确性，同时获得有启发性的解释，从而创造知识并帮助理解和调试数据。</h3></div><div class="mk l"><p class="bd b dl z fp mh fr fs mi fu fw dk translated">pub.towardsai.net</p></div></div><div class="ml l"><div class="os l mn mo mp ml mq lb mc"/></div></div></a></div><div class="lz ma gp gr mb mc"><a href="https://towardsdatascience.com/8-hazards-menacing-machine-learning-systems-in-production-5c470baa0163" rel="noopener follow" target="_blank"><div class="md ab fo"><div class="me ab mf cl cj mg"><h2 class="bd jd gy z fp mh fr fs mi fu fw jc bi translated">生产中威胁机器学习系统的8种危险</h2><div class="mj l"><h3 class="bd b gy z fp mh fr fs mi fu fw dk translated">维护ML系统时需要注意什么</h3></div><div class="mk l"><p class="bd b dl z fp mh fr fs mi fu fw dk translated">towardsdatascience.com</p></div></div><div class="ml l"><div class="ot l mn mo mp ml mq lb mc"/></div></div></a></div></div></div>    
</body>
</html>