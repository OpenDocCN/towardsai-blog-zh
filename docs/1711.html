<html>
<head>
<title>Clustering Custom Data Using the K-Means Algorithm — Python</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">使用K-Means算法对自定义数据进行聚类Python</h1>
<blockquote>原文：<a href="https://pub.towardsai.net/clustering-custom-data-using-the-k-means-algorithm-python-6a243308034a?source=collection_archive---------0-----------------------#2021-03-27">https://pub.towardsai.net/clustering-custom-data-using-the-k-means-algorithm-python-6a243308034a?source=collection_archive---------0-----------------------#2021-03-27</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><h2 id="5c6f" class="io ip iq bd b dl ir is it iu iv iw dk ix translated" aria-label="kicker paragraph"><a class="ae ep" href="https://towardsai.net/p/category/machine-learning" rel="noopener ugc nofollow" target="_blank">机器学习</a></h2><div class=""/><div class=""><h2 id="49f0" class="pw-subtitle-paragraph jw iz iq bd b jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn dk translated">使用Python理解和实现K-means算法的指南。</h2></div><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div class="gh gi ko"><img src="../Images/a97f3217b43b96f3a933e4706942deee.png" data-original-src="https://miro.medium.com/v2/resize:fit:810/format:webp/1*D05JEUMNSdcauMDcqaYKdA.png"/></div><figcaption class="kw kx gj gh gi ky kz bd b be z dk translated">来源:作者</figcaption></figure><h1 id="f551" class="la lb iq bd lc ld le lf lg lh li lj lk kf ll kg lm ki ln kj lo kl lp km lq lr bi translated">什么是K-Means聚类算法？</h1><p id="5a64" class="pw-post-body-paragraph ls lt iq lu b lv lw ka lx ly lz kd ma mb mc md me mf mg mh mi mj mk ml mm mn ij bi translated">K-Means聚类算法是一种无监督学习算法，这意味着它没有目标标签。该算法将相似的聚类分组在一起。</p><h1 id="8c84" class="la lb iq bd lc ld le lf lg lh li lj lk kf ll kg lm ki ln kj lo kl lp km lq lr bi translated">集群在现实世界中的应用是什么？</h1><p id="f6e3" class="pw-post-body-paragraph ls lt iq lu b lv lw ka lx ly lz kd ma mb mc md me mf mg mh mi mj mk ml mm mn ij bi translated">聚类算法的各种应用包括:</p><ol class=""><li id="fc9c" class="mo mp iq lu b lv mq ly mr mb ms mf mt mj mu mn mv mw mx my bi translated">市场分割</li><li id="6c53" class="mo mp iq lu b lv mz ly na mb nb mf nc mj nd mn mv mw mx my bi translated">基于特征的客户分组</li><li id="fa76" class="mo mp iq lu b lv mz ly na mb nb mf nc mj nd mn mv mw mx my bi translated">相似文档的聚类</li></ol><h1 id="71c7" class="la lb iq bd lc ld le lf lg lh li lj lk kf ll kg lm ki ln kj lo kl lp km lq lr bi translated">算法是如何工作的？</h1><p id="1f0c" class="pw-post-body-paragraph ls lt iq lu b lv lw ka lx ly lz kd ma mb mc md me mf mg mh mi mj mk ml mm mn ij bi translated">该算法遵循给定的步骤:</p><ol class=""><li id="a047" class="mo mp iq lu b lv mq ly mr mb ms mf mt mj mu mn mv mw mx my bi translated">选择若干个集群“K”。</li><li id="89da" class="mo mp iq lu b lv mz ly na mb nb mf nc mj nd mn mv mw mx my bi translated">然后将数据中的每个点随机分配给一个聚类。</li><li id="bdf9" class="mo mp iq lu b lv mz ly na mb nb mf nc mj nd mn mv mw mx my bi translated">重复以下步骤，直到集群停止变化:</li></ol><p id="e21f" class="pw-post-body-paragraph ls lt iq lu b lv mq ka lx ly mr kd ma mb ne md me mf nf mh mi mj ng ml mm mn ij bi translated">a)对于每个聚类，通过计算聚类中点的平均向量来计算聚类的质心。</p><p id="c251" class="pw-post-body-paragraph ls lt iq lu b lv mq ka lx ly mr kd ma mb ne md me mf nf mh mi mj ng ml mm mn ij bi translated">b)将每个数据点分配给质心最近的聚类。</p><h1 id="d797" class="la lb iq bd lc ld le lf lg lh li lj lk kf ll kg lm ki ln kj lo kl lp km lq lr bi translated">如何选择「K」的值？</h1><p id="5d4d" class="pw-post-body-paragraph ls lt iq lu b lv lw ka lx ly lz kd ma mb mc md me mf mg mh mi mj mk ml mm mn ij bi translated">选择最佳的“K”值是非常棘手的。但是有一种方法是肘法。根据该方法，对于“K”的一些值，计算误差平方和(SSE)。SSE是聚类的每个数据点与其质心之间的平方距离之和。当“K”对SSE作图时，误差随着“K”变大而减小。原因是当簇数量增加时，它们的大小减小，因此失真也更小。所以肘法规定“K”的值将是上证指数突然下降的值。它会产生“肘效应”。</p><h1 id="4e12" class="la lb iq bd lc ld le lf lg lh li lj lk kf ll kg lm ki ln kj lo kl lp km lq lr bi translated">如何用Python实现？</h1><p id="917f" class="pw-post-body-paragraph ls lt iq lu b lv lw ka lx ly lz kd ma mb mc md me mf mg mh mi mj mk ml mm mn ij bi translated">将创建用于聚类的数据集。使用sci-kt学习包将形成一个随机数据集，算法将在该数据集上运行。</p><p id="61bc" class="pw-post-body-paragraph ls lt iq lu b lv mq ka lx ly mr kd ma mb ne md me mf nf mh mi mj ng ml mm mn ij bi translated"><strong class="lu ja"> →进口包装</strong></p><p id="358f" class="pw-post-body-paragraph ls lt iq lu b lv mq ka lx ly mr kd ma mb ne md me mf nf mh mi mj ng ml mm mn ij bi translated">导入numpy库是为了与matplotlib一起处理数据，以帮助实现数据可视化。</p><pre class="kp kq kr ks gt nh ni nj nk aw nl bi"><span id="1d26" class="nm lb iq ni b gy nn no l np nq"><strong class="ni ja">&gt;&gt;&gt; import</strong> numpy <strong class="ni ja">as</strong> np<br/><strong class="ni ja">&gt;&gt;&gt; import</strong> matplotlib.pyplot <strong class="ni ja">as</strong> plt<br/><strong class="ni ja">&gt;&gt;&gt; %</strong>matplotlib inline</span></pre><p id="61c1" class="pw-post-body-paragraph ls lt iq lu b lv mq ka lx ly mr kd ma mb ne md me mf nf mh mi mj ng ml mm mn ij bi translated"><strong class="lu ja"> →创建数据</strong></p><p id="8a9b" class="pw-post-body-paragraph ls lt iq lu b lv mq ka lx ly mr kd ma mb ne md me mf nf mh mi mj ng ml mm mn ij bi translated">将使用sklearn包的“make_blobs”方法。样本数量、特征、中心和聚类标准偏差将被设置为参数。</p><pre class="kp kq kr ks gt nh ni nj nk aw nl bi"><span id="91d9" class="nm lb iq ni b gy nn no l np nq"><strong class="ni ja">&gt;&gt;&gt; from</strong> sklearn.datasets <strong class="ni ja">import</strong> make_blobs</span><span id="463c" class="nm lb iq ni b gy nr no l np nq">&gt;&gt;&gt; data <strong class="ni ja">=</strong> make_blobs(n_samples<strong class="ni ja">=</strong>400, n_features<strong class="ni ja">=</strong>2, centers<strong class="ni ja">=</strong>5, cluster_std<strong class="ni ja">=</strong>1.8)</span><span id="5de1" class="nm lb iq ni b gy nr no l np nq">&gt;&gt;&gt; data[0].shape<br/>(400, 2)</span></pre><p id="4d43" class="pw-post-body-paragraph ls lt iq lu b lv mq ka lx ly mr kd ma mb ne md me mf nf mh mi mj ng ml mm mn ij bi translated"><strong class="lu ja"> →绘制斑点</strong></p><p id="fcb5" class="pw-post-body-paragraph ls lt iq lu b lv mq ka lx ly mr kd ma mb ne md me mf nf mh mi mj ng ml mm mn ij bi translated">第一列的所有行的散点图是相对于第二列的所有行绘制的。然后提供分类编号标签以查看不同的分类。</p><pre class="kp kq kr ks gt nh ni nj nk aw nl bi"><span id="34a4" class="nm lb iq ni b gy nn no l np nq">&gt;&gt;&gt; plt.scatter(data[0][:,0],data[0][:,1],c<strong class="ni ja">=</strong>data[1],cmap<strong class="ni ja">=</strong>'rainbow')</span></pre><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div class="gh gi ns"><img src="../Images/c2bdcdab9569c1cbe97f7960d3629aea.png" data-original-src="https://miro.medium.com/v2/resize:fit:962/format:webp/1*ibmxRJKYcnJLJrqsSARR1A.png"/></div></figure><p id="1b3a" class="pw-post-body-paragraph ls lt iq lu b lv mq ka lx ly mr kd ma mb ne md me mf nf mh mi mj ng ml mm mn ij bi translated">因此，这里的集群是扭曲和重叠的。使用K-means算法，将执行聚类以正确地对数据进行分组。</p><p id="c3cc" class="pw-post-body-paragraph ls lt iq lu b lv mq ka lx ly mr kd ma mb ne md me mf nf mh mi mj ng ml mm mn ij bi translated"><strong class="lu ja"> →构建模型</strong></p><p id="0457" class="pw-post-body-paragraph ls lt iq lu b lv mq ka lx ly mr kd ma mb ne md me mf nf mh mi mj ng ml mm mn ij bi translated">从sklearn导入KMeans模块来构建模型。创建KMeans对象，并将参数“k”传递给该对象。这里有5个集群。那么它就符合数据。</p><pre class="kp kq kr ks gt nh ni nj nk aw nl bi"><span id="4530" class="nm lb iq ni b gy nn no l np nq"><strong class="ni ja">&gt;&gt;&gt; from</strong> sklearn.cluster <strong class="ni ja">import</strong> KMeans</span><span id="6d74" class="nm lb iq ni b gy nr no l np nq">&gt;&gt;&gt; model <strong class="ni ja">=</strong> KMeans(n_clusters<strong class="ni ja">=</strong>5)</span><span id="77f5" class="nm lb iq ni b gy nr no l np nq">&gt;&gt;&gt; model.fit(data[0])<br/>KMeans(n_clusters=5)</span></pre><p id="a3fa" class="pw-post-body-paragraph ls lt iq lu b lv mq ka lx ly mr kd ma mb ne md me mf nf mh mi mj ng ml mm mn ij bi translated">可以获得聚类中心和预测标签。</p><pre class="kp kq kr ks gt nh ni nj nk aw nl bi"><span id="60b7" class="nm lb iq ni b gy nn no l np nq">&gt;&gt;&gt; model.cluster_centers_<br/>array([[ 9.07898265,  5.31380282],<br/>       [ 0.09832752,  6.25299731],<br/>       [ 1.47946328, -1.483289  ],<br/>       [ 8.66272519,  0.43529401],<br/>       [ 6.1742668 ,  2.5718236 ]])</span><span id="9ed3" class="nm lb iq ni b gy nr no l np nq">&gt;&gt;&gt; model.labels_<br/>array([1, 3, 2, 1, 1, 2, 4, 4, 3, 1, 4, 2, 1, 2, 3, 0, 0, 0, 3, 0, 3, 0,<br/>       0, 3, 3, 4, 0, 0, 3, 0, 2, 4, 3, 2, 1, 1, 2, 4, 4, 0, 3, 4, 4, 2,<br/>       3, 1, 4, 3, 0, 0, 3, 0, 0, 3, 1, 0, 0, 0, 0, 0, 4, 3, 2, 1, 0, 3,<br/>       2, 1, 2, 1, 3, 1, 4, 1, 4, 0, 2, 4, 2, 2, 3, 3, 1, 3, 1, 2, 0, 3,<br/>       0, 3, 2, 0, 0, 1, 1, 0, 2, 2, 1, 4, 4, 1, 3, 1, 2, 2, 0, 1, 1, 1,<br/>       0, 4, 3, 1, 3, 3, 2, 4, 1, 0, 3, 0, 4, 2, 1, 0, 2, 1, 3, 3, 3, 2,<br/>       3, 3, 1, 1, 1, 3, 2, 0, 0, 2, 4, 1, 1, 0, 1, 0, 0, 0, 4, 1, 0, 0,<br/>       4, 2, 2, 0, 0, 2, 2, 3, 0, 4, 1, 1, 2, 4, 3, 0, 0, 0, 1, 0, 0, 1,<br/>       2, 1, 3, 2, 1, 0, 1, 3, 4, 4, 1, 1, 3, 3, 1, 3, 3, 4, 2, 3, 3, 2,<br/>       4, 0, 2, 2, 3, 3, 4, 2, 1, 1, 3, 0, 0, 3, 2, 3, 3, 2, 2, 0, 3, 2,<br/>       0, 3, 2, 4, 3, 0, 4, 4, 0, 3, 3, 1, 0, 0, 1, 0, 3, 1, 2, 2, 2, 2,<br/>       0, 3, 2, 4, 0, 4, 4, 4, 2, 0, 4, 1, 0, 3, 2, 3, 2, 2, 3, 1, 4, 0,<br/>       2, 3, 3, 4, 3, 1, 4, 2, 1, 0, 3, 2, 0, 4, 0, 3, 2, 2, 2, 4, 2, 2,<br/>       2, 1, 1, 0, 4, 1, 0, 2, 0, 4, 0, 1, 0, 1, 0, 3, 3, 1, 0, 2, 3, 0,<br/>       0, 4, 2, 3, 0, 1, 3, 4, 3, 3, 0, 1, 4, 2, 4, 4, 0, 0, 0, 1, 2, 1,<br/>       2, 4, 3, 0, 0, 4, 4, 1, 0, 3, 4, 2, 1, 3, 0, 0, 4, 1, 0, 4, 1, 4,<br/>       3, 0, 0, 2, 1, 3, 2, 2, 2, 3, 1, 1, 0, 1, 0, 4, 0, 0, 3, 3, 0, 3,<br/>       4, 1, 0, 3, 2, 3, 0, 0, 3, 1, 1, 2, 1, 4, 1, 3, 4, 4, 3, 3, 2, 2,<br/>       2, 0, 1, 3])</span></pre><p id="e4ad" class="pw-post-body-paragraph ls lt iq lu b lv mq ka lx ly mr kd ma mb ne md me mf nf mh mi mj ng ml mm mn ij bi translated">这里，模型已经预测了标签，并且由于是无监督的学习算法，如果采用真实世界的数据，将没有目标标签可以比较。由于数据是在这里创建的，因此可以将目标标签与预测标签进行比较，以了解K-Means算法的工作情况。</p><pre class="kp kq kr ks gt nh ni nj nk aw nl bi"><span id="9b78" class="nm lb iq ni b gy nn no l np nq">&gt;&gt;&gt; f, (ax1, ax2) <strong class="ni ja">=</strong> plt.subplots(1, 2, sharey<strong class="ni ja">=True</strong>,figsize<strong class="ni ja">=</strong>(10,6))</span><span id="d9a6" class="nm lb iq ni b gy nr no l np nq">&gt;&gt;&gt; ax1.set_title('K Means clusters')<br/>&gt;&gt;&gt; ax1.scatter(data[0][:,0],data[0[:,1],c<strong class="ni ja">=</strong>model.labels_,cmap<strong class="ni ja">=</strong>'rainbow')</span><span id="d04c" class="nm lb iq ni b gy nr no l np nq">&gt;&gt;&gt; ax2.set_title("Original clusters")<br/>&gt;&gt;&gt; ax2.scatter(data[0][:,0],data[0][:,1],c<strong class="ni ja">=</strong>data[1],cmap<strong class="ni ja">=</strong>'rainbow')</span></pre><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div role="button" tabindex="0" class="nu nv di nw bf nx"><div class="gh gi nt"><img src="../Images/b4b2e979ba77e3afea0fde9d04b4d332.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*4Y3qysonLY9FMvE1dB1opA.png"/></div></div></figure><p id="c203" class="pw-post-body-paragraph ls lt iq lu b lv mq ka lx ly mr kd ma mb ne md me mf nf mh mi mj ng ml mm mn ij bi translated">可以观察到，K-Means算法创建了更多定义的聚类。</p></div><div class="ab cl ny nz hu oa" role="separator"><span class="ob bw bk oc od oe"/><span class="ob bw bk oc od oe"/><span class="ob bw bk oc od"/></div><div class="ij ik il im in"><blockquote class="of"><p id="7e88" class="og oh iq bd oi oj ok ol om on oo mn dk translated"><em class="op">这里指笔记本</em><a class="ae oq" href="https://github.com/jayashree8/Machine_learning_unsupervised_models/blob/master/K-Means.ipynb" rel="noopener ugc nofollow" target="_blank"><em class="op"/></a><em class="op">。</em></p></blockquote><h2 id="b290" class="nm lb iq bd lc or os dn lg ot ou dp lk mb ov ow lm mf ox oy lo mj oz pa lq iw bi translated">初级机器学习书籍可以参考:</h2><div class="pb pc gp gr pd pe"><a href="https://amzn.to/3i3XU1A" rel="noopener  ugc nofollow" target="_blank"><div class="pf ab fo"><div class="pg ab ph cl cj pi"><h2 class="bd ja gy z fp pj fr fs pk fu fw iz bi translated">Python机器学习:机器学习和深度学习的Python编程初学者指南</h2></div><div class="pl l"><div class="pm l pn po pp pl pq ku pe"/></div></div></a></div><div class="pb pc gp gr pd pe"><a href="https://amzn.to/3fQc6IW" rel="noopener  ugc nofollow" target="_blank"><div class="pf ab fo"><div class="pg ab ph cl cj pi"><h2 class="bd ja gy z fp pj fr fs pk fu fw iz bi translated">一百页的机器学习书</h2></div><div class="pl l"><div class="pr l pn po pp pl pq ku pe"/></div></div></a></div><h2 id="ab42" class="nm lb iq bd lc or ps dn lg ot pt dp lk mb pu ow lm mf pv oy lo mj pw pa lq iw bi translated">可以参考的高级机器学习书籍:</h2><div class="pb pc gp gr pd pe"><a href="https://amzn.to/2SxwQNw" rel="noopener  ugc nofollow" target="_blank"><div class="pf ab fo"><div class="pg ab ph cl cj pi"><h2 class="bd ja gy z fp pj fr fs pk fu fw iz bi translated">用Scikit-Learn、Keras和张量流进行机器学习:概念、工具和技术…</h2></div><div class="pl l"><div class="px l pn po pp pl pq ku pe"/></div></div></a></div><div class="pb pc gp gr pd pe"><a href="https://amzn.to/3wz62eE" rel="noopener  ugc nofollow" target="_blank"><div class="pf ab fo"><div class="pg ab ph cl cj pi"><h2 class="bd ja gy z fp pj fr fs pk fu fw iz bi translated">模式识别和机器学习(信息科学和统计学)</h2></div><div class="pl l"><div class="py l pn po pp pl pq ku pe"/></div></div></a></div><blockquote class="pz qa qb"><p id="befe" class="ls lt qc lu b lv mq ka lx ly mr kd ma qd ne md me qe nf mh mi qf ng ml mm mn ij bi translated"><em class="iq">联系我:</em> <a class="ae oq" href="https://www.linkedin.com/in/jayashree-domala8/" rel="noopener ugc nofollow" target="_blank"> <em class="iq"> LinkedIn </em> </a></p><p id="7c57" class="ls lt qc lu b lv mq ka lx ly mr kd ma qd ne md me qe nf mh mi qf ng ml mm mn ij bi translated"><em class="iq">查看我的其他作品:</em> <a class="ae oq" href="https://github.com/jayashree8" rel="noopener ugc nofollow" target="_blank"> <em class="iq"> GitHub </em> </a></p></blockquote></div></div>    
</body>
</html>