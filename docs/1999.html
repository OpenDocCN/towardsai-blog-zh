<html>
<head>
<title>5 Useful Encoding Techniques in Machine Learning</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">机器学习中5种有用的编码技术</h1>
<blockquote>原文：<a href="https://pub.towardsai.net/5-useful-encoding-techniques-in-machine-learning-f735567399f4?source=collection_archive---------2-----------------------#2021-07-19">https://pub.towardsai.net/5-useful-encoding-techniques-in-machine-learning-f735567399f4?source=collection_archive---------2-----------------------#2021-07-19</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><h2 id="f6b7" class="ir is it bd b dl iu iv iw ix iy iz dk ja translated" aria-label="kicker paragraph"><a class="ae ep" href="https://towardsai.net/p/category/machine-learning" rel="noopener ugc nofollow" target="_blank">机器学习</a></h2><div class=""/><div class=""><h2 id="dca5" class="pw-subtitle-paragraph jz jc it bd b ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq dk translated">机器学习建模中的预处理步骤</h2></div><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi kr"><img src="../Images/2b6cea898dcf9e979d3eb8bfcac4fa08.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*KsTO0a4TINeMakyEH9XBGw.png"/></div></div></figure><blockquote class="ld le lf"><p id="ab0f" class="lg lh li lj b lk ll kd lm ln lo kg lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated"><strong class="lj jd">T3】简介T5】</strong></p></blockquote><p id="5411" class="pw-post-body-paragraph lg lh it lj b lk ll kd lm ln lo kg lp md lr ls lt me lv lw lx mf lz ma mb mc im bi translated">数据分析师花费大部分时间来准备和清理数据，因为原始数据是非结构化的，并且包含机器学习模型无法直接使用的噪声。因此，这些数据将被清理/过滤，这将提高模型的质量，也有助于特征工程。</p><p id="1c00" class="pw-post-body-paragraph lg lh it lj b lk ll kd lm ln lo kg lp md lr ls lt me lv lw lx mf lz ma mb mc im bi translated">数据清洗的主要目的是处理编码分类数据、处理缺失值、删除冗余特征，以及借助标准降维技术降低维度。这一步使我们的数据作为一个整体应用于任何机器学习算法。有两种类型的数据，分为结构化数据和非结构化数据两类。</p><p id="d74d" class="pw-post-body-paragraph lg lh it lj b lk ll kd lm ln lo kg lp md lr ls lt me lv lw lx mf lz ma mb mc im bi translated"><strong class="lj jd">数据编码</strong>是机器学习建模中的预处理步骤，将分类数据转换或编码为数字形式。</p><p id="9c25" class="pw-post-body-paragraph lg lh it lj b lk ll kd lm ln lo kg lp md lr ls lt me lv lw lx mf lz ma mb mc im bi translated"><strong class="lj jd">机器学习/数据科学中的变量</strong></p><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div class="gh gi mg"><img src="../Images/5e4af949864f93cf83a2850fa3c47d9b.png" data-original-src="https://miro.medium.com/v2/resize:fit:940/format:webp/1*X8xadLSM16JiH8CdtK5YQw.png"/></div></figure><p id="2a4e" class="pw-post-body-paragraph lg lh it lj b lk ll kd lm ln lo kg lp md lr ls lt me lv lw lx mf lz ma mb mc im bi translated">我们有各种各样的数据编码技术，我将在本文中借助Python来讨论这些技术。</p><p id="1ef9" class="pw-post-body-paragraph lg lh it lj b lk ll kd lm ln lo kg lp md lr ls lt me lv lw lx mf lz ma mb mc im bi translated">在机器学习中，我们的模型主要处理不同类型的<strong class="lj jd">变量，</strong>通常是数字变量，但当分类变量出现时会发生什么。在拟合和评估我们的模型之前，我们需要将这些分类变量转换为数字形式，以便我们的模型能够理解并从中提取洞察信息。为了解决这个问题，我们需要理解分类数据。</p><blockquote class="ld le lf"><p id="8a91" class="lg lh li lj b lk ll kd lm ln lo kg lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated"><strong class="lj jd"> <em class="it">分类数据</em> </strong></p></blockquote><p id="f314" class="pw-post-body-paragraph lg lh it lj b lk ll kd lm ln lo kg lp md lr ls lt me lv lw lx mf lz ma mb mc im bi translated">统计分类数据或分类变量用于表示属于特定类别的一定数量的可能值。</p><p id="395f" class="pw-post-body-paragraph lg lh it lj b lk ll kd lm ln lo kg lp md lr ls lt me lv lw lx mf lz ma mb mc im bi translated">例如:</p><ul class=""><li id="b4b8" class="mh mi it lj b lk ll ln lo md mj me mk mf ml mc mm mn mo mp bi translated">一个人居住的城市:诺伊达、德里、古尔冈、孟买、班加罗尔等。</li><li id="94d0" class="mh mi it lj b lk mq ln mr md ms me mt mf mu mc mm mn mo mp bi translated">一个人工作的部门:人力资源、财务、IT、生产等。</li><li id="2fb7" class="mh mi it lj b lk mq ln mr md ms me mt mf mu mc mm mn mo mp bi translated">一个人的最高学历:博士、硕士、学士、SSC、文凭、SC等。</li><li id="ab81" class="mh mi it lj b lk mq ln mr md ms me mt mf mu mc mm mn mo mp bi translated">学生的成绩:A、B、C、D等。</li></ul><p id="5ae3" class="pw-post-body-paragraph lg lh it lj b lk ll kd lm ln lo kg lp md lr ls lt me lv lw lx mf lz ma mb mc im bi translated">从上面给出的例子，我们得出结论，分类变量可能是两种类型序数和名义这是在上面的图像解释。</p><p id="2299" class="pw-post-body-paragraph lg lh it lj b lk ll kd lm ln lo kg lp md lr ls lt me lv lw lx mf lz ma mb mc im bi translated">将分类值转换为数值的技术如下所示:</p><ol class=""><li id="791a" class="mh mi it lj b lk ll ln lo md mj me mk mf ml mc mv mn mo mp bi translated">标签编码/顺序编码</li><li id="3e69" class="mh mi it lj b lk mq ln mr md ms me mt mf mu mc mv mn mo mp bi translated">一个热编码</li><li id="c1d1" class="mh mi it lj b lk mq ln mr md ms me mt mf mu mc mv mn mo mp bi translated">二进制编码</li><li id="e7c3" class="mh mi it lj b lk mq ln mr md ms me mt mf mu mc mv mn mo mp bi translated">哈希编码</li><li id="63ef" class="mh mi it lj b lk mq ln mr md ms me mt mf mu mc mv mn mo mp bi translated">平均编码或目标编码</li></ol><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div class="gh gi mw"><img src="../Images/40378386c72d0bcde24f28d9d1efab27.png" data-original-src="https://miro.medium.com/v2/resize:fit:1286/format:webp/1*7fmGaa4vu8WAEw-qnG-ShA.png"/></div><figcaption class="mx my gj gh gi mz na bd b be z dk translated">图像<a class="ae nb" href="http://towards data science" rel="noopener ugc nofollow" target="_blank">来源</a></figcaption></figure><blockquote class="ld le lf"><p id="b129" class="lg lh li lj b lk ll kd lm ln lo kg lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated"><strong class="lj jd"> <em class="it">序数编码或标签编码</em> </strong></p></blockquote><p id="3b8c" class="pw-post-body-paragraph lg lh it lj b lk ll kd lm ln lo kg lp md lr ls lt me lv lw lx mf lz ma mb mc im bi translated">当分类特征是序数时，使用分类数据编码技术。在标签编码中，每个标签都被转换成整数值。我们将创建一个变量，包含代表一个人<strong class="lj jd">资格的类别。</strong></p><p id="39ff" class="pw-post-body-paragraph lg lh it lj b lk ll kd lm ln lo kg lp md lr ls lt me lv lw lx mf lz ma mb mc im bi translated"><strong class="lj jd"> Python代码</strong></p><pre class="ks kt ku kv gt nc nd ne nf aw ng bi"><span id="6933" class="nh ni it nd b gy nj nk l nl nm">import category_encoders as ce<br/>import pandas as pd</span></pre><p id="5b8c" class="pw-post-body-paragraph lg lh it lj b lk ll kd lm ln lo kg lp md lr ls lt me lv lw lx mf lz ma mb mc im bi translated">在我们代码的第一行，我们导入category_encoders，这是一组scikit-learn风格的转换器，用于将分类变量编码为数字。</p><pre class="ks kt ku kv gt nc nd ne nf aw ng bi"><span id="488e" class="nh ni it nd b gy nj nk l nl nm">train_df=pd.DataFrame({'Degree'['Highschool','Masters','Diploma',<br/>                       'Bachelors','Bachelors','Masters','Phd','High<br/>                        school','High school']})</span><span id="d8f6" class="nh ni it nd b gy nn nk l nl nm"># create object of Ordinal encoding<br/>encoder= ce.OrdinalEncoder(cols=['Degree'],return_df = True,<br/>                           mapping=[{'col':'Degree',</span><span id="4f02" class="nh ni it nd b gy nn nk l nl nm">'mapping':{'None':0,'High school':1,'Diploma':2,'Bachelors':3,'Masters':4,'phd':5}}])</span><span id="deb6" class="nh ni it nd b gy nn nk l nl nm">#Original data<br/>train_df</span></pre><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div class="gh gi no"><img src="../Images/f3e9e4f77b8b4196473f20c239b09965.png" data-original-src="https://miro.medium.com/v2/resize:fit:310/format:webp/1*zZ75H3jnUsl7jI349EDGzg.png"/></div></figure><pre class="ks kt ku kv gt nc nd ne nf aw ng bi"><span id="2218" class="nh ni it nd b gy nj nk l nl nm">#fit and transform train data<br/>df_train_transformed = encoder.fit_transform(train_df)</span></pre><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div class="gh gi np"><img src="../Images/665be0ee782dfb44c3b3820b0e0e0fbc.png" data-original-src="https://miro.medium.com/v2/resize:fit:140/format:webp/1*R7oLIYoSVFJTKeXm8fQ4Ow.png"/></div></figure><p id="7bbc" class="pw-post-body-paragraph lg lh it lj b lk ll kd lm ln lo kg lp md lr ls lt me lv lw lx mf lz ma mb mc im bi translated"><strong class="lj jd">标签编码的缺点</strong></p><p id="c943" class="pw-post-body-paragraph lg lh it lj b lk ll kd lm ln lo kg lp md lr ls lt me lv lw lx mf lz ma mb mc im bi translated">标签编码考虑了列中的一些层次结构，这些层次结构会误导数据集中存在的名义特征。</p><blockquote class="ld le lf"><p id="aa2b" class="lg lh li lj b lk ll kd lm ln lo kg lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated"><strong class="lj jd"> <em class="it">一键热编码</em> </strong></p></blockquote><p id="1a63" class="pw-post-body-paragraph lg lh it lj b lk ll kd lm ln lo kg lp md lr ls lt me lv lw lx mf lz ma mb mc im bi translated">当特征是名义上的/没有顺序时使用的分类数据编码技术)。在一个热编码中，对于分类值的每一级，我们创建一个新变量。每个类别都用一个包含1或0的二进制变量表示，其中1表示该类别存在，0表示不存在。一种热编码克服了标签编码的问题，因为标签编码考虑了列中的一些层次，这可能误导数据集中存在的名义特征。</p><p id="3023" class="pw-post-body-paragraph lg lh it lj b lk ll kd lm ln lo kg lp md lr ls lt me lv lw lx mf lz ma mb mc im bi translated">这些创建的二进制特征被称为<strong class="lj jd">虚拟变量。</strong>有多少虚拟变量，取决于分类变量中存在的级别。例如，假设我们有一个动物类别的数据集，有不同的动物，如猫、狗、狮子、牛、羊、马。现在，我们正在对这些数据进行一次性编码。</p><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div class="gh gi nq"><img src="../Images/95a6f32051d1ead656093d411a31d425.png" data-original-src="https://miro.medium.com/v2/resize:fit:1314/format:webp/1*uxMQxzLsmhz2iGed05sgZw.png"/></div></figure><p id="4548" class="pw-post-body-paragraph lg lh it lj b lk ll kd lm ln lo kg lp md lr ls lt me lv lw lx mf lz ma mb mc im bi translated">当编码完成后，我们在第二个表中发现我们有虚拟变量，每个虚拟变量代表特征动物中的一个类别。对于表中的每个类别，我们在类别列中有0和1。现在，实现一个热点编码，如下所示。</p><p id="6867" class="pw-post-body-paragraph lg lh it lj b lk ll kd lm ln lo kg lp md lr ls lt me lv lw lx mf lz ma mb mc im bi translated"><strong class="lj jd"> Python代码</strong></p><pre class="ks kt ku kv gt nc nd ne nf aw ng bi"><span id="5de9" class="nh ni it nd b gy nj nk l nl nm">import category_encoders as ce<br/>import pandas as pd</span><span id="35f1" class="nh ni it nd b gy nn nk l nl nm">data=pd.DataFrame({‘City’:[‘Delhi’,’Mumbai’,’Hydrabad’,<br/>                        ’Chennai’,’Bangalore’,’Delhi’,’Hydrabad’,<br/>                        ’Bangalore’,’Delhi’]})</span><span id="5e5d" class="nh ni it nd b gy nn nk l nl nm">#Create object for one-hot encoding</span><span id="d332" class="nh ni it nd b gy nn nk l nl nm">encoder=ce.OneHotEncoder(cols=’City’,handle_unknown=’return_nan’,<br/>                         return_df=True,use_cat_names=True)</span><span id="4f08" class="nh ni it nd b gy nn nk l nl nm">#Original Data<br/>data</span></pre><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div class="gh gi nr"><img src="../Images/1c1c6a1232d542f3a2d45dad7170abec.png" data-original-src="https://miro.medium.com/v2/resize:fit:282/format:webp/1*itKCRO3PtKPNO2ZyWZuROQ.png"/></div></figure><pre class="ks kt ku kv gt nc nd ne nf aw ng bi"><span id="7518" class="nh ni it nd b gy nj nk l nl nm">#Fit and transform Data<br/>data_encoded = encoder.fit_transform(data)<br/>data_encoded</span></pre><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div class="gh gi ns"><img src="../Images/c9e55505e2928b7fa359569c8881d840.png" data-original-src="https://miro.medium.com/v2/resize:fit:1138/format:webp/1*7Ofeejm1icgrEGN36UC9Lw.png"/></div></figure><div class="nt nu gp gr nv nw"><a rel="noopener  ugc nofollow" target="_blank" href="/data-preprocessing-concepts-with-python-b93c63f14bb6"><div class="nx ab fo"><div class="ny ab nz cl cj oa"><h2 class="bd jd gy z fp ob fr fs oc fu fw jc bi translated">Python中的数据预处理概念</h2><div class="od l"><h3 class="bd b gy z fp ob fr fs oc fu fw dk translated">一种为机器学习估值器准备数据的稳健方法</h3></div><div class="oe l"><p class="bd b dl z fp ob fr fs oc fu fw dk translated">pub.towardsai.net</p></div></div><div class="of l"><div class="og l oh oi oj of ok lb nw"/></div></div></a></div><blockquote class="ld le lf"><p id="1e30" class="lg lh li lj b lk ll kd lm ln lo kg lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated"><strong class="lj jd"> <em class="it">二进制编码</em> </strong></p></blockquote><p id="0aa0" class="pw-post-body-paragraph lg lh it lj b lk ll kd lm ln lo kg lp md lr ls lt me lv lw lx mf lz ma mb mc im bi translated">二进制编码是一种热编码的特殊情况，其中二进制数字用于编码，即0或1。</p><p id="3a82" class="pw-post-body-paragraph lg lh it lj b lk ll kd lm ln lo kg lp md lr ls lt me lv lw lx mf lz ma mb mc im bi translated">例如对于7位二进制码是111。</p><p id="4488" class="pw-post-body-paragraph lg lh it lj b lk ll kd lm ln lo kg lp md lr ls lt me lv lw lx mf lz ma mb mc im bi translated">当有更多的数字类别时，这种技术更可取。假设您有100或更多不同的类别，那么一个热编码将创建100或更多不同的列，但是二进制编码只需要7列来表示它。</p><pre class="ks kt ku kv gt nc nd ne nf aw ng bi"><span id="e118" class="nh ni it nd b gy nj nk l nl nm"><strong class="nd jd">Binary coding</strong><br/>YES        1<br/>NO         0</span></pre><p id="937b" class="pw-post-body-paragraph lg lh it lj b lk ll kd lm ln lo kg lp md lr ls lt me lv lw lx mf lz ma mb mc im bi translated"><strong class="lj jd"> Python代码</strong></p><pre class="ks kt ku kv gt nc nd ne nf aw ng bi"><span id="5a0f" class="nh ni it nd b gy nj nk l nl nm">from category_encoders import BinaryEncoder<br/>encoder = BinaryEncoder(cols =['ord_2'])</span><span id="fcaf" class="nh ni it nd b gy nn nk l nl nm"># transforming the column after fitting<br/>newdata = encoder.fit_transform(df['ord_2'])</span><span id="dbfb" class="nh ni it nd b gy nn nk l nl nm"># concating dataframe<br/>df = pd.concat([df, newdata], axis = 1)</span><span id="bef7" class="nh ni it nd b gy nn nk l nl nm"># dropping old column<br/>df = df.drop(['ord_2'], axis = 1)<br/>df.head(10)</span></pre><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div class="gh gi ol"><img src="../Images/d9ee85adb0ee4e326753bab539828764.png" data-original-src="https://miro.medium.com/v2/resize:fit:1036/format:webp/1*oBVeq60v5HdeIZINAK0WJA.png"/></div></figure><blockquote class="ld le lf"><p id="db33" class="lg lh li lj b lk ll kd lm ln lo kg lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated"><strong class="lj jd"> <em class="it">哈希编码</em> </strong></p></blockquote><p id="1500" class="pw-post-body-paragraph lg lh it lj b lk ll kd lm ln lo kg lp md lr ls lt me lv lw lx mf lz ma mb mc im bi translated">哈希是通过应用哈希函数将字符串转换为唯一哈希代码或值的过程。它可以用较低的内存使用量处理更多的分类数据。</p><p id="06dc" class="pw-post-body-paragraph lg lh it lj b lk ll kd lm ln lo kg lp md lr ls lt me lv lw lx mf lz ma mb mc im bi translated"><strong class="lj jd"> Python代码</strong></p><pre class="ks kt ku kv gt nc nd ne nf aw ng bi"><span id="8af0" class="nh ni it nd b gy nj nk l nl nm">from sklearn.feature_extraction import FeatureHasher</span></pre><p id="0467" class="pw-post-body-paragraph lg lh it lj b lk ll kd lm ln lo kg lp md lr ls lt me lv lw lx mf lz ma mb mc im bi translated">在这里的代码中，我们导入了一个特性散列器，它实现了特性散列，并使用它们的散列值作为索引。</p><pre class="ks kt ku kv gt nc nd ne nf aw ng bi"><span id="5e39" class="nh ni it nd b gy nj nk l nl nm"># The number of bits you want in your hash value contained in n_features.</span><span id="bd85" class="nh ni it nd b gy nn nk l nl nm">h = FeatureHasher(n_features = 3, input_type =’string’)</span><span id="6426" class="nh ni it nd b gy nn nk l nl nm"># transforming the column after fitting</span><span id="86d3" class="nh ni it nd b gy nn nk l nl nm">hashed_Feature = h.fit_transform(df[‘nom_0’])<br/>hashed_Feature = hashed_Feature.toarray()</span><span id="6209" class="nh ni it nd b gy nn nk l nl nm">df = pd.concat([df, pd.DataFrame(hashed_Feature)], axis = 1)<br/>df.head(10)</span></pre><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div class="gh gi om"><img src="../Images/b079addc636be64651664b7cbba36f71.png" data-original-src="https://miro.medium.com/v2/resize:fit:1230/format:webp/1*byffC987DowZP_KLjlQRRw.png"/></div></figure><blockquote class="ld le lf"><p id="73e6" class="lg lh li lj b lk ll kd lm ln lo kg lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated"><strong class="lj jd"> <em class="it">表示编码或目标编码</em> </strong></p></blockquote><p id="5d46" class="pw-post-body-paragraph lg lh it lj b lk ll kd lm ln lo kg lp md lr ls lt me lv lw lx mf lz ma mb mc im bi translated">目标编码是一种非常好的编码技术，因为它选取可以解释目标的值。大多数竞争对手都使用它。这种技术的基本思想是用目标变量的平均值代替分类值。</p><p id="3905" class="pw-post-body-paragraph lg lh it lj b lk ll kd lm ln lo kg lp md lr ls lt me lv lw lx mf lz ma mb mc im bi translated"><strong class="lj jd">代号:</strong></p><pre class="ks kt ku kv gt nc nd ne nf aw ng bi"><span id="6bd1" class="nh ni it nd b gy nj nk l nl nm"># Target column inserting in the dataset as it needs a target<br/>df.insert (6, “Target”, [0, 1, 1, 0, 0, 1, 0, 0, 0, 1], True)</span><span id="5991" class="nh ni it nd b gy nn nk l nl nm"># importing TargetEncoder<br/>from category_encoders import TargetEncoder<br/>Target_enc = TargetEncoder()</span><span id="9804" class="nh ni it nd b gy nn nk l nl nm"># transforming the column after fitting<br/>points = Target_enc.fit_transform(X = df.nom_0, y = df.Target)</span><span id="0f75" class="nh ni it nd b gy nn nk l nl nm"># concating values with dataframe<br/>df = pd.concat([df, points], axis = 1)<br/>df.head(10)</span></pre><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div class="gh gi on"><img src="../Images/647b17381f674e8fe6c46bec0dbd41a5.png" data-original-src="https://miro.medium.com/v2/resize:fit:1046/format:webp/1*HCfZpgAAeJ82L4yqVLXAFQ.png"/></div></figure><blockquote class="ld le lf"><p id="498c" class="lg lh li lj b lk ll kd lm ln lo kg lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated"><strong class="lj jd"> <em class="it">结论</em> </strong></p></blockquote><p id="3630" class="pw-post-body-paragraph lg lh it lj b lk ll kd lm ln lo kg lp md lr ls lt me lv lw lx mf lz ma mb mc im bi translated">在本文中，我将重点放在数据编码技术上，这对于在拟合我们的模型和评估模型之前处理缺失值是非常重要的。</p></div><div class="ab cl oo op hx oq" role="separator"><span class="or bw bk os ot ou"/><span class="or bw bk os ot ou"/><span class="or bw bk os ot"/></div><div class="im in io ip iq"><p id="6376" class="pw-post-body-paragraph lg lh it lj b lk ll kd lm ln lo kg lp md lr ls lt me lv lw lx mf lz ma mb mc im bi translated">我希望你喜欢这篇文章。通过我的<a class="ae nb" href="https://www.linkedin.com/in/data-scientist-95040a1ab/" rel="noopener ugc nofollow" target="_blank"> LinkedIn </a>和<a class="ae nb" href="https://twitter.com/amitprius" rel="noopener ugc nofollow" target="_blank"> twitter </a>联系我。</p><h1 id="6d68" class="ov ni it bd ow ox oy oz pa pb pc pd pe ki pf kj pg kl ph km pi ko pj kp pk pl bi translated">推荐文章</h1><p id="bba5" class="pw-post-body-paragraph lg lh it lj b lk pm kd lm ln pn kg lp md po ls lt me pp lw lx mf pq ma mb mc im bi translated"><a class="ae nb" href="https://medium.com/towards-artificial-intelligence/nlp-zero-to-hero-with-python-2df6fcebff6e?sk=2231d868766e96b13d1e9d7db6064df1" rel="noopener"> 1。NLP —零到英雄与Python </a> <br/> 2。<a class="ae nb" href="https://medium.com/towards-artificial-intelligence/python-data-structures-data-types-and-objects-244d0a86c3cf?sk=42f4b462499f3fc3a160b21e2c94dba6" rel="noopener"> Python数据结构数据类型和对象</a>T5】3 .<a class="ae nb" rel="noopener ugc nofollow" target="_blank" href="/exception-handling-concepts-in-python-4d5116decac3?source=friends_link&amp;sk=a0ed49d9fdeaa67925eac34ecb55ea30">Python中的异常处理概念</a> <br/> 4。<a class="ae nb" rel="noopener ugc nofollow" target="_blank" href="/deep-learning-88e218b74a14?source=friends_link&amp;sk=540bf9088d31859d50dbddab7524ba35">为什么LSTM在深度学习方面比RNN更有用？</a> <br/> 5。<a class="ae nb" rel="noopener ugc nofollow" target="_blank" href="/neural-networks-the-rise-of-recurrent-neural-networks-df740252da88?source=friends_link&amp;sk=6844935e3de14e478ce00f0b22e419eb">神经网络:递归神经网络的兴起</a> <br/> 6。<a class="ae nb" href="https://medium.com/towards-artificial-intelligence/fully-explained-linear-regression-with-python-fe2b313f32f3?source=friends_link&amp;sk=53c91a2a51347ec2d93f8222c0e06402" rel="noopener">用Python </a> <br/> 7全面讲解了线性回归。<a class="ae nb" href="https://medium.com/towards-artificial-intelligence/fully-explained-logistic-regression-with-python-f4a16413ddcd?source=friends_link&amp;sk=528181f15a44e48ea38fdd9579241a78" rel="noopener">用Python </a> <br/>充分解释了Logistic回归8。<a class="ae nb" rel="noopener ugc nofollow" target="_blank" href="/differences-between-concat-merge-and-join-with-python-1a6541abc08d?source=friends_link&amp;sk=3b37b694fb90db16275059ea752fc16a">concat()、merge()和join()与Python </a> <br/>的区别9。<a class="ae nb" rel="noopener ugc nofollow" target="_blank" href="/data-wrangling-with-python-part-1-969e3cc81d69?source=friends_link&amp;sk=9c3649cf20f31a5c9ead51c50c89ba0b">与Python的数据角力—第一部分</a> <br/> 10。<a class="ae nb" href="https://medium.com/analytics-vidhya/confusion-matrix-in-machine-learning-91b6e2b3f9af?source=friends_link&amp;sk=11c6531da0bab7b504d518d02746d4cc" rel="noopener">机器学习中的混淆矩阵</a></p></div></div>    
</body>
</html>