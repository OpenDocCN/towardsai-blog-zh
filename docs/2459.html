<html>
<head>
<title>Create a Biometric Authenticator Using Deep Learning</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">使用深度学习创建生物认证器</h1>
<blockquote>原文：<a href="https://pub.towardsai.net/deep-learning-de50aeb8e6e0?source=collection_archive---------3-----------------------#2022-01-03">https://pub.towardsai.net/deep-learning-de50aeb8e6e0?source=collection_archive---------3-----------------------#2022-01-03</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><h2 id="0942" class="io ip iq bd b dl ir is it iu iv iw dk ix translated" aria-label="kicker paragraph"><a class="ae ep" href="https://towardsai.net/p/category/machine-learning/deep-learning" rel="noopener ugc nofollow" target="_blank">深度学习</a></h2><div class=""/><div class=""><h2 id="6f5d" class="pw-subtitle-paragraph jw iz iq bd b jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn dk translated">使用深度学习创建指纹认证器。</h2></div><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div role="button" tabindex="0" class="ku kv di kw bf kx"><div class="gh gi ko"><img src="../Images/c661a0ecec01e59189e2085f9a3b9fe1.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*NGNu70uSWdUz13ysJAP5Rg.jpeg"/></div></div><figcaption class="la lb gj gh gi lc ld bd b be z dk translated">图片由<a class="ae le" href="https://unsplash.com/@georgeprentzas" rel="noopener ugc nofollow" target="_blank">乔治·普伦萨斯</a>在Unsplash上拍摄</figcaption></figure><h1 id="37f0" class="lf lg iq bd lh li lj lk ll lm ln lo lp kf lq kg lr ki ls kj lt kl lu km lv lw bi translated"><strong class="ak">什么是生物认证？</strong></h1><p id="fe6e" class="pw-post-body-paragraph lx ly iq lz b ma mb ka mc md me kd mf mg mh mi mj mk ml mm mn mo mp mq mr ms ij bi translated">生物认证是基于用户身体特征的某一部分来验证用户的一种模式。身份验证不同于身份验证，身份验证采用指纹、面部、视网膜扫描等生物特征。用来识别一个人。在身份验证中，生物特征用于验证用户是否如其所声称的那样。</p><h1 id="c694" class="lf lg iq bd lh li lj lk ll lm ln lo lp kf lq kg lr ki ls kj lt kl lu km lv lw bi translated"><strong class="ak">生物认证器的重要性</strong></h1><p id="b431" class="pw-post-body-paragraph lx ly iq lz b ma mb ka mc md me kd mf mg mh mi mj mk ml mm mn mo mp mq mr ms ij bi translated">就数字身份而言，这是最受欢迎的安全形式之一。例如，许多数字设备(如手机、笔记本电脑)使用某种形式的认证器(如指纹、面部识别)来验证用户。这是通常的密码保护之外的又一层安全措施。</p></div><div class="ab cl mt mu hu mv" role="separator"><span class="mw bw bk mx my mz"/><span class="mw bw bk mx my mz"/><span class="mw bw bk mx my"/></div><div class="ij ik il im in"><h1 id="0358" class="lf lg iq bd lh li na lk ll lm nb lo lp kf nc kg lr ki nd kj lt kl ne km lv lw bi translated"><strong class="ak">如何使用一次性分类和连体网络创建指纹认证？</strong></h1><p id="2a38" class="pw-post-body-paragraph lx ly iq lz b ma mb ka mc md me kd mf mg mh mi mj mk ml mm mn mo mp mq mr ms ij bi translated">在本文中，我们将尝试使用深度学习进行指纹认证。这是受吴恩达在<a class="ae le" href="https://www.coursera.org/specializations/deep-learning" rel="noopener ugc nofollow" target="_blank"> Coursera </a>上的深度学习专业化课程的启发</p><h2 id="d5f4" class="nf lg iq bd lh ng nh dn ll ni nj dp lp mg nk nl lr mk nm nn lt mo no np lv iw bi translated">一次性分类</h2><p id="243d" class="pw-post-body-paragraph lx ly iq lz b ma mb ka mc md me kd mf mg mh mi mj mk ml mm mn mo mp mq mr ms ij bi translated">在标准识别方法的情况下，一组图像被输入到人工神经网络(ANN)中，以获得不同类别的输出概率。例如，如果我们想要识别猫和狗，我们想要收集大量的图像(每类可能超过500个图像)来提高模型的准确性。这种类型的网络在指纹识别方面的缺点是:</p><ol class=""><li id="ff78" class="nq nr iq lz b ma ns md nt mg nu mk nv mo nw ms nx ny nz oa bi translated">几乎不可能获得大量图像，</li><li id="d486" class="nq nr iq lz b ma ob md oc mg od mk oe mo of ms nx ny nz oa bi translated">如果我们想在数据库中包含一个新用户，我们需要重新训练模型来识别新用户。</li></ol><p id="a3e3" class="pw-post-body-paragraph lx ly iq lz b ma ns ka mc md nt kd mf mg og mi mj mk oh mm mn mo oi mq mr ms ij bi translated">正是由于这些原因，一次性分类被证明是有用的，因为我们可以使用一些预先训练的模型(如ImageNet)并将任务视为“<em class="oj">差异评估问题”</em>而不是分类问题。这就是暹罗网络出现的原因。</p><h2 id="c1f6" class="nf lg iq bd lh ng nh dn ll ni nj dp lp mg nk nl lr mk nm nn lt mo no np lv iw bi translated">暹罗网络</h2><p id="ff89" class="pw-post-body-paragraph lx ly iq lz b ma mb ka mc md me kd mf mg mh mi mj mk ml mm mn mo mp mq mr ms ij bi translated">连体网络(有时称为孪生神经网络)是一种人工神经网络，它学习区分两个输入，而不是分类。它采用两幅输入图像，同时通过相同的网络，并生成图像的两个矢量嵌入，这两个矢量嵌入通过逻辑损失来计算两幅图像之间的相似性得分。这非常有用，因为它不需要许多数据点来训练模型。其次，我们只需要存储用户的一个图像作为参考图像，并为呈现给网络的每个新实例计算相似性。</p><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div role="button" tabindex="0" class="ku kv di kw bf kx"><div class="gh gi ok"><img src="../Images/c04a8b394def3a461e5f804c374a850f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*ac_KmQtwj3x0BlAkThAeXg.jpeg"/></div></div><figcaption class="la lb gj gh gi lc ld bd b be z dk translated">图片由作者提供。<strong class="bd lh">具有连体网络的三重损失架构:</strong>三个图像(“锚”、“正”、“负”)同时通过同一个CNN，生成128维向量的最后一层。然后，所有三个向量都通过三元组损失函数，以最小化“锚”和“正”之间的距离，以及最大化“锚”和“负”之间的距离。</figcaption></figure><p id="f967" class="pw-post-body-paragraph lx ly iq lz b ma ns ka mc md nt kd mf mg og mi mj mk oh mm mn mo oi mq mr ms ij bi translated">我们的暹罗网络架构如上图所示。</p><h2 id="778f" class="nf lg iq bd lh ng nh dn ll ni nj dp lp mg nk nl lr mk nm nn lt mo no np lv iw bi translated">损失函数</h2><p id="328b" class="pw-post-body-paragraph lx ly iq lz b ma mb ka mc md me kd mf mg mh mi mj mk ml mm mn mo mp mq mr ms ij bi translated">尽管如此，物流损失在暹罗网络中运作良好。在这项工作中，我们使用了三重损失函数和连体网络。结合连体网络使用三联体损失函数(在下一小节中解释)的好处是双重的:<br/> 1 .它通过学习同时最大化两个相似图像之间的相似性(锚正)和两个不同图像之间的距离(锚负)来提取更多的特征。<br/> 2。它比逻辑损失产生更多的训练样本。如果我们有P个相似对和N个不相似对，那么对于逻辑损失，我们将有P + N个总训练样本。然而，我们将有PN三胞胎用于训练。这将提高模型精度。</p><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div class="gh gi ol"><img src="../Images/41eb8145fc436e43e11cf9f376388de6.png" data-original-src="https://miro.medium.com/v2/resize:fit:1340/format:webp/1*ZgghOMkoz3lO2LHJpxIlUA.jpeg"/></div><figcaption class="la lb gj gh gi lc ld bd b be z dk translated">图片由作者提供。<strong class="bd lh">三重损失架构:</strong>架构试图最小化“锚”与“正”的距离，最大化“锚”与“负”的距离</figcaption></figure><p id="9522" class="pw-post-body-paragraph lx ly iq lz b ma ns ka mc md nt kd mf mg og mi mj mk oh mm mn mo oi mq mr ms ij bi translated">三重态损耗架构如上图所示。</p><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div role="button" tabindex="0" class="ku kv di kw bf kx"><div class="gh gi ok"><img src="../Images/9a3e5c5ab15fc622280d589581cd617d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*_uwtpLFTXixiqBcf7XFlWw.jpeg"/></div></div><figcaption class="la lb gj gh gi lc ld bd b be z dk translated">作者图片</figcaption></figure><p id="690d" class="pw-post-body-paragraph lx ly iq lz b ma ns ka mc md nt kd mf mg og mi mj mk oh mm mn mo oi mq mr ms ij bi translated">最后，对于分类器，我们使用了一个改进的VGG16模型架构，并使用Keras在ImageNet上预先训练了权重。VGG16的模型架构如上所示。</p></div><div class="ab cl mt mu hu mv" role="separator"><span class="mw bw bk mx my mz"/><span class="mw bw bk mx my mz"/><span class="mw bw bk mx my"/></div><div class="ij ik il im in"><h1 id="cfaf" class="lf lg iq bd lh li na lk ll lm nb lo lp kf nc kg lr ki nd kj lt kl ne km lv lw bi translated">该设置</h1><p id="9b08" class="pw-post-body-paragraph lx ly iq lz b ma mb ka mc md me kd mf mg mh mi mj mk ml mm mn mo mp mq mr ms ij bi translated">我们首先创建三重损失层，并将其附加到我们的模型。</p><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div role="button" tabindex="0" class="ku kv di kw bf kx"><div class="gh gi om"><img src="../Images/1933d6e8fbff0ba860882e01b4a2ffce.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*ZDSuW58xDobkLufuZ01xJQ.png"/></div></div><figcaption class="la lb gj gh gi lc ld bd b be z dk translated">作者图片</figcaption></figure><p id="34d2" class="pw-post-body-paragraph lx ly iq lz b ma ns ka mc md nt kd mf mg og mi mj mk oh mm mn mo oi mq mr ms ij bi translated">根据上面的代码，<strong class="lz ja"> TripletLossLayer </strong>函数创建三重损失函数，而<strong class="lz ja"> build_model </strong>函数将损失函数附加到神经网络(在我们的例子中是VGG16)。</p><h2 id="cc63" class="nf lg iq bd lh ng nh dn ll ni nj dp lp mg nk nl lr mk nm nn lt mo no np lv iw bi translated">为培训准备批次</h2><p id="3154" class="pw-post-body-paragraph lx ly iq lz b ma mb ka mc md me kd mf mg mh mi mj mk ml mm mn mo mp mq mr ms ij bi translated">现在我们的模型已经构建好了，我们需要准备好三元组来馈入网络。我们决定生成50% <em class="oj">随机/容易</em>三元组和50% <em class="oj">困难</em>三元组，以防止网络过拟合。下面的代码显示了如何做到这一点。</p><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div role="button" tabindex="0" class="ku kv di kw bf kx"><div class="gh gi on"><img src="../Images/bee25faec62780d5818f4e31e7404211.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*8--EmEM4l7LxXFssw-70iA.png"/></div></div><figcaption class="la lb gj gh gi lc ld bd b be z dk translated">图片由作者提供。生成简单三元组的代码。</figcaption></figure><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div role="button" tabindex="0" class="ku kv di kw bf kx"><div class="gh gi oo"><img src="../Images/7f84337228da133cde03c1bc6b7fd39d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*aiW4CTlFB1rTimbpMFsfww.png"/></div></div><figcaption class="la lb gj gh gi lc ld bd b be z dk translated">图片由作者提供。生成硬三元组的代码。</figcaption></figure><p id="a84d" class="pw-post-body-paragraph lx ly iq lz b ma ns ka mc md nt kd mf mg og mi mj mk oh mm mn mo oi mq mr ms ij bi translated">下面是“简单”和“困难”批处理的样子。</p><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div role="button" tabindex="0" class="ku kv di kw bf kx"><div class="gh gi op"><img src="../Images/b569f815a094b01c9f7960d39e2ac6e9.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*1gJxC4cd_DdDQDPgU65q7g.png"/></div></div><figcaption class="la lb gj gh gi lc ld bd b be z dk translated">图片由作者提供。简易三联批</figcaption></figure><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div role="button" tabindex="0" class="ku kv di kw bf kx"><div class="gh gi oq"><img src="../Images/d1ad57748020bb37935ae93fb488ecdd.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*WsiBfzMNusIN5-GUcaigVQ.png"/></div></div><figcaption class="la lb gj gh gi lc ld bd b be z dk translated">图片由作者提供。硬三份批料</figcaption></figure><h1 id="7bd7" class="lf lg iq bd lh li lj lk ll lm ln lo lp kf lq kg lr ki ls kj lt kl lu km lv lw bi translated">估价</h1><p id="4134" class="pw-post-body-paragraph lx ly iq lz b ma mb ka mc md me kd mf mg mh mi mj mk ml mm mn mo mp mq mr ms ij bi translated"><strong class="lz ja">数据集</strong>:我们在这个项目中使用了<em class="oj"> </em> <a class="ae le" href="http://bias.csr.unibo.it/fvc2006/" rel="noopener ugc nofollow" target="_blank"> <em class="oj"> FVC2006 </em> </a>数据集。该数据库由4个不同的子集DB1、DB2、DB3和DB4组成。每个数据库由150个手指和每个手指12个印痕组成。每个子集进一步分为“集合A”和“集合B ”,其中“集合A”包含140×12个图像，“集合B”包含10×12个图像。我们只使用了DB1，它的图像大小为96x96，但我们预计其他数据库也会有类似的结果。</p><p id="d1de" class="pw-post-body-paragraph lx ly iq lz b ma ns ka mc md nt kd mf mg og mi mj mk oh mm mn mo oi mq mr ms ij bi translated"><em class="oj">训练数据:</em>为了训练，我们从DB1-A(总共140×10个图像)取得每个手指的10个印痕，并生成三联体对。我们使用了50%的“硬”和50%的“易”三联体对。</p><p id="6aeb" class="pw-post-body-paragraph lx ly iq lz b ma ns ka mc md nt kd mf mg og mi mj mk oh mm mn mo oi mq mr ms ij bi translated"><em class="oj">测试数据:</em>为了测试，我们使用了来自DB1-A的每个手指2个印痕(总共140x2个图像)。</p><p id="baeb" class="pw-post-body-paragraph lx ly iq lz b ma ns ka mc md nt kd mf mg og mi mj mk oh mm mn mo oi mq mr ms ij bi translated">一旦模型被训练，我们创建一个140张图片的数据库。为了验证，我们计算输入图像和来自数据库的图像之间的<strong class="lz ja">范数距离</strong>，如果该距离大于某个阈值距离，我们将它们计为“<em class="oj">不匹配</em>”，反之亦然。</p><p id="3905" class="pw-post-body-paragraph lx ly iq lz b ma ns ka mc md nt kd mf mg og mi mj mk oh mm mn mo oi mq mr ms ij bi translated"><strong class="lz ja">结果:</strong>我们在测试数据上获得了95.36%的准确度(280个指纹印记中有13个不匹配)，所有用户的解码区域半径为0.7。</p><h1 id="1cd8" class="lf lg iq bd lh li lj lk ll lm ln lo lp kf lq kg lr ki ls kj lt kl lu km lv lw bi translated">结束语</h1><p id="06cd" class="pw-post-body-paragraph lx ly iq lz b ma mb ka mc md me kd mf mg mh mi mj mk ml mm mn mo mp mq mr ms ij bi translated">仍然存在的一个问题是，我们是如何得出0.7的阈值距离的？</p><p id="616e" class="pw-post-body-paragraph lx ly iq lz b ma ns ka mc md nt kd mf mg og mi mj mk oh mm mn mo oi mq mr ms ij bi translated">有两种方法可以确定这一点，</p><ol class=""><li id="35ac" class="nq nr iq lz b ma ns md nt mg nu mk nv mo nw ms nx ny nz oa bi translated">一旦嵌入被存储在数据库中，我们选择任何阈值距离(在我们的例子中为0.7)并缩放特定范围的数据，以找出<a class="ae le" href="https://en.wikipedia.org/wiki/Biometrics" rel="noopener ugc nofollow" target="_blank"><strong class="lz ja">【EER】</strong></a><strong class="lz ja"/>，并据此选择我们的缩放因子。</li><li id="0ace" class="nq nr iq lz b ma ob md oc mg od mk oe mo of ms nx ny nz oa bi translated">或者，我们可以改变阈值距离并找到<strong class="lz ja"> EER。</strong></li></ol><p id="4745" class="pw-post-body-paragraph lx ly iq lz b ma ns ka mc md nt kd mf mg og mi mj mk oh mm mn mo oi mq mr ms ij bi translated">我们选择前一种方法，下面附上<a class="ae le" href="https://en.wikipedia.org/wiki/False_positive_rate" rel="noopener ugc nofollow" target="_blank"><strong class="lz ja">【FPR】</strong></a><strong class="lz ja">和</strong> <a class="ae le" href="https://en.wikipedia.org/wiki/False_positives_and_false_negatives" rel="noopener ugc nofollow" target="_blank"> <strong class="lz ja">假阴性率(FNR) </strong> </a> <strong class="lz ja"> vs比例因子</strong>的曲线图。</p><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div role="button" tabindex="0" class="ku kv di kw bf kx"><div class="gh gi or"><img src="../Images/761452b2718ad9e052e487b466a4e88c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*_7S09ZAjdtV6DMGG6vIJ1A.png"/></div></div><figcaption class="la lb gj gh gi lc ld bd b be z dk translated">图片由作者提供。在红点处，EER为0.0582，大约等于比例因子= 0.85</figcaption></figure><p id="1fa4" class="pw-post-body-paragraph lx ly iq lz b ma ns ka mc md nt kd mf mg og mi mj mk oh mm mn mo oi mq mr ms ij bi translated">为完整起见，我们展示了<a class="ae le" href="https://en.wikipedia.org/wiki/Receiver_operating_characteristic" rel="noopener ugc nofollow" target="_blank"><strong class="lz ja">【ROC】</strong></a><strong class="lz ja"/>的受试者工作特性来计算曲线下面积(AUC)。AUC接近1意味着分类器接近完美。</p><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div role="button" tabindex="0" class="ku kv di kw bf kx"><div class="gh gi or"><img src="../Images/9a0ff1d0cd2fc2a93be5b97b1d73bba2.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*5ncbR_tSvuC-eZlwZsgs9A.png"/></div></div><figcaption class="la lb gj gh gi lc ld bd b be z dk translated">图片由作者提供。ROC曲线显示AUC = 0.986</figcaption></figure><h1 id="b27f" class="lf lg iq bd lh li lj lk ll lm ln lo lp kf lq kg lr ki ls kj lt kl lu km lv lw bi translated">结论</h1><p id="86d6" class="pw-post-body-paragraph lx ly iq lz b ma mb ka mc md me kd mf mg mh mi mj mk ml mm mn mo mp mq mr ms ij bi translated">总之，连体网络的三联体丢失是创建指纹认证器的一个很好的方法。</p><p id="ce3a" class="pw-post-body-paragraph lx ly iq lz b ma ns ka mc md nt kd mf mg og mi mj mk oh mm mn mo oi mq mr ms ij bi translated">对于某个阈值距离，我们可以缩放嵌入并计算EER，以找到模型的最佳精度。</p><h1 id="a79e" class="lf lg iq bd lh li lj lk ll lm ln lo lp kf lq kg lr ki ls kj lt kl lu km lv lw bi translated">未来的工作</h1><p id="a0ce" class="pw-post-body-paragraph lx ly iq lz b ma mb ka mc md me kd mf mg mh mi mj mk ml mm mn mo mp mq mr ms ij bi translated">这项工作可以通过以下方式进一步扩展:</p><ol class=""><li id="b345" class="nq nr iq lz b ma ns md nt mg nu mk nv mo nw ms nx ny nz oa bi translated">对其他生物特征进行类似的测试，如视网膜扫描、面部图像等。</li><li id="0a79" class="nq nr iq lz b ma ob md oc mg od mk oe mo of ms nx ny nz oa bi translated">由于VGG16是一个相对“沉重”的网络，它会有时间上的性能损失。我们可以尝试一些轻量级网络来测试准确性。</li></ol><p id="1998" class="pw-post-body-paragraph lx ly iq lz b ma ns ka mc md nt kd mf mg og mi mj mk oh mm mn mo oi mq mr ms ij bi translated">该项目的详细描述可以在<a class="ae le" href="https://github.com/abhishek-jana/Fingerprint-Recognition/blob/master/Fingerprint%20Verification%20Using%20Triplet%20loss%20function.ipynb" rel="noopener ugc nofollow" target="_blank">这里</a>找到。与项目相关的文章可以在<a class="ae le" href="https://arxiv.org/pdf/2003.08433.pdf" rel="noopener ugc nofollow" target="_blank">这里</a>找到。</p><h1 id="2cd8" class="lf lg iq bd lh li lj lk ll lm ln lo lp kf lq kg lr ki ls kj lt kl lu km lv lw bi translated">参考资料:</h1><ul class=""><li id="5108" class="nq nr iq lz b ma mb md me mg os mk ot mo ou ms ov ny nz oa bi translated"><a class="ae le" href="https://www.coursera.org/specializations/deep-learning?utm_source=gg&amp;utm_medium=sem&amp;utm_campaign=17-DeepLearning-US&amp;utm_content=B2C&amp;campaignid=904733485&amp;adgroupid=46370300620&amp;device=c&amp;keyword=coursera%20deep%20learning%20ai&amp;matchtype=b&amp;network=g&amp;devicemodel=&amp;adpostion=&amp;creativeid=415429098219&amp;hide_mobile_promo&amp;gclid=Cj0KCQiA5aWOBhDMARIsAIXLlkeWUoeBGYRaILxiKlale8FN6Ic6dO1GUgcpquUrP4ObYwBWhNgsSlIaAvJpEALw_wcB" rel="noopener ugc nofollow" target="_blank">Coursera上的深度学习专业化。</a></li><li id="5cc4" class="nq nr iq lz b ma ob md oc mg od mk oe mo of ms ov ny nz oa bi translated"><a class="ae le" href="https://arxiv.org/pdf/2003.08433.pdf" rel="noopener ugc nofollow" target="_blank">https://arxiv.org/pdf/2003.08433.pdf</a></li><li id="c879" class="nq nr iq lz b ma ob md oc mg od mk oe mo of ms ov ny nz oa bi translated"><a class="ae le" href="https://github.com/abhishek-jana/Fingerprint-Recognition/blob/master/Fingerprint%20Verification%20Using%20Triplet%20loss%20function.ipynb" rel="noopener ugc nofollow" target="_blank">https://github . com/abhishek-Jana/Fingerprint-Recognition/blob/master/Fingerprint % 20 verification % 20 using % 20 triplet % 20 loss % 20 function . ipynb</a></li><li id="68e9" class="nq nr iq lz b ma ob md oc mg od mk oe mo of ms ov ny nz oa bi translated"><a class="ae le" href="http://bias.csr.unibo.it/fvc2006/" rel="noopener ugc nofollow" target="_blank">http://bias.csr.unibo.it/fvc2006/</a></li><li id="3c3d" class="nq nr iq lz b ma ob md oc mg od mk oe mo of ms ov ny nz oa bi translated"><a class="ae le" href="https://en.wikipedia.org/wiki/False_positives_and_false_negatives" rel="noopener ugc nofollow" target="_blank">https://en . Wikipedia . org/wiki/False _ positives _ and _ False _ negatives</a></li><li id="d344" class="nq nr iq lz b ma ob md oc mg od mk oe mo of ms ov ny nz oa bi translated"><a class="ae le" href="https://en.wikipedia.org/wiki/False_positive_rate" rel="noopener ugc nofollow" target="_blank">https://en.wikipedia.org/wiki/False_positive_rate</a></li><li id="545d" class="nq nr iq lz b ma ob md oc mg od mk oe mo of ms ov ny nz oa bi translated"><a class="ae le" href="https://en.wikipedia.org/wiki/Biometrics" rel="noopener ugc nofollow" target="_blank">https://en.wikipedia.org/wiki/Biometrics</a></li></ul></div></div>    
</body>
</html>