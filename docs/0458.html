<html>
<head>
<title>Classifying Credit-Loan Customers</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">信用贷款客户分类</h1>
<blockquote>原文：<a href="https://pub.towardsai.net/classifying-credit-loan-customers-35e4a18dd24?source=collection_archive---------1-----------------------#2020-05-04">https://pub.towardsai.net/classifying-credit-loan-customers-35e4a18dd24?source=collection_archive---------1-----------------------#2020-05-04</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="b1ed" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">应用特征工程和二元分类模型。</h2></div><h1 id="58eb" class="ki kj it bd kk kl km kn ko kp kq kr ks jz kt ka ku kc kv kd kw kf kx kg ky kz bi translated">目录:</h1><ul class=""><li id="70c4" class="la lb it lc b ld le lf lg lh li lj lk ll lm ln lo lp lq lr bi translated"><a class="ae ls" href="#c5b0" rel="noopener ugc nofollow">介绍</a>。</li><li id="40b5" class="la lb it lc b ld lt lf lu lh lv lj lw ll lx ln lo lp lq lr bi translated"><a class="ae ls" href="#bebe" rel="noopener ugc nofollow">探索性数据分析。</a></li><li id="b3e2" class="la lb it lc b ld lt lf lu lh lv lj lw ll lx ln lo lp lq lr bi translated"><a class="ae ls" href="#3e36" rel="noopener ugc nofollow">特色工程。</a></li><li id="10fb" class="la lb it lc b ld lt lf lu lh lv lj lw ll lx ln lo lp lq lr bi translated"><a class="ae ls" href="#97e9" rel="noopener ugc nofollow">建模和评估。</a></li><li id="f049" class="la lb it lc b ld lt lf lu lh lv lj lw ll lx ln lo lp lq lr bi translated"><a class="ae ls" href="#601c" rel="noopener ugc nofollow">结论。</a></li></ul><h1 id="c5b0" class="ki kj it bd kk kl km kn ko kp kq kr ks jz kt ka ku kc kv kd kw kf kx kg ky kz bi translated">第1部分:简介</h1><figure class="lz ma mb mc gt md gh gi paragraph-image"><div role="button" tabindex="0" class="me mf di mg bf mh"><div class="gh gi ly"><img src="../Images/865e7545019ae08d1a5d1237ecdcef36.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*cYycQ23I5gEijdfpoPs6uQ.jpeg"/></div></div><figcaption class="mk ml gj gh gi mm mn bd b be z dk translated"><strong class="bd kk">分类决策应该基于一些科学… </strong></figcaption></figure><p id="752c" class="pw-post-body-paragraph mo mp it lc b ld mq ju mr lf ms jx mt lh mu mv mw lj mx my mz ll na nb nc ln im bi translated">2018年8月，<a class="ae ls" href="https://nypost.com/2018/08/11/more-americans-are-defaulting-on-their-credit-cards-analyst/" rel="noopener ugc nofollow" target="_blank"> <em class="nd">纽约邮报</em> </a>的一篇文章显示，尽管“经济蓬勃发展”，但更多的美国人正在拖欠信用卡账单。另一位观察家LendingTree.com指出，同年5月，循环债务增加了162.5亿美元。</p><blockquote class="ne"><p id="f093" class="nf ng it bd nh ni nj nk nl nm nn ln dk translated">循环债务是按月结转的信用卡债务，通常利率很高，因为与房子不同，信用卡是一种无担保债务。</p></blockquote><p id="6a0d" class="pw-post-body-paragraph mo mp it lc b ld no ju mr lf np jx mt lh nq mv mw lj nr my mz ll ns nb nc ln im bi translated">文章进一步预测，到2018年底，循环和非循环债务都将超过4万亿美元大关。</p><p id="47e9" class="pw-post-body-paragraph mo mp it lc b ld mq ju mr lf ms jx mt lh mu mv mw lj mx my mz ll na nb nc ln im bi translated">今天(2020年5月)，我们都知道新冠肺炎对全球经济的毁灭性影响。据预测，情况在好转之前会变得更糟。</p><figure class="lz ma mb mc gt md gh gi paragraph-image"><div class="gh gi nt"><img src="../Images/394eb8789589ed772d22e4adc1452c76.png" data-original-src="https://miro.medium.com/v2/resize:fit:1320/format:webp/1*txuTYsIHVje-XnVNXdeyIA.jpeg"/></div><figcaption class="mk ml gj gh gi mm mn bd b be z dk translated">为所有因病毒而去世或生病的人祈祷…</figcaption></figure><p id="4c97" class="pw-post-body-paragraph mo mp it lc b ld mq ju mr lf ms jx mt lh mu mv mw lj mx my mz ll na nb nc ln im bi translated">作为数据科学专业人员，我们通过分析和编程手段(包括机器学习)从数据中推断见解，并交流这些见解以做出更好的决策。</p><p id="c9ae" class="pw-post-body-paragraph mo mp it lc b ld mq ju mr lf ms jx mt lh mu mv mw lj mx my mz ll na nb nc ln im bi translated">我先引用历史上最伟大的统计学家之一的一句名言:- <strong class="lc iu">乔治·爱德华·佩勒姆</strong> …</p><blockquote class="ne"><p id="5f9c" class="nf ng it bd nh ni nj nk nl nm nn ln dk translated">“所有模型都是错的，但有些是有用的”</p></blockquote><p id="95a6" class="pw-post-body-paragraph mo mp it lc b ld no ju mr lf np jx mt lh nq mv mw lj nr my mz ll ns nb nc ln im bi translated">也就是说，我们将探索一个来自<em class="nd"> CreditOne </em>银行的数据集，其中包含大约5000个客户的信用数据。基于这些数据，我们将建立机器学习模型，将客户分类为可能的<strong class="lc iu"><em class="nd"/></strong>或<strong class="lc iu"> <em class="nd">非违约</em> </strong>。</p><h1 id="bebe" class="ki kj it bd kk kl km kn ko kp kq kr ks jz kt ka ku kc kv kd kw kf kx kg ky kz bi translated">第2部分:EDA</h1><figure class="lz ma mb mc gt md gh gi paragraph-image"><div class="gh gi nu"><img src="../Images/e993e0d40ac1c49f30cc6e1446f6eb84.png" data-original-src="https://miro.medium.com/v2/resize:fit:1240/format:webp/1*iOTVrCLt_mq6n5pS7aMgMg.jpeg"/></div><figcaption class="mk ml gj gh gi mm mn bd b be z dk translated">Img| <a class="ae ls" href="https://www.google.com/url?sa=i&amp;url=https%3A%2F%2Fwww.educba.com%2Fexploratory-data-analysis%2F&amp;psig=AOvVaw1fdDK8L3_980C9n2oHjXcR&amp;ust=1586093559177000&amp;source=images&amp;cd=vfe&amp;ved=0CAIQjRxqFwoTCIDvjY7xzugCFQAAAAAdAAAAABAJ" rel="noopener ugc nofollow" target="_blank">信用</a></figcaption></figure><p id="35c8" class="pw-post-body-paragraph mo mp it lc b ld mq ju mr lf ms jx mt lh mu mv mw lj mx my mz ll na nb nc ln im bi translated">我们将使用的数据集来自<em class="nd"> CreditOne Bank </em>。它在<em class="nd"> Kaggle </em>中，通过这个<a class="ae ls" href="https://www.kaggle.com/dataforyou/bankloan" rel="noopener ugc nofollow" target="_blank"> <strong class="lc iu"> <em class="nd">链接</em> </strong> </a> <strong class="lc iu"> <em class="nd">可以在它的数据字典旁边看到。</em> </strong>下面是<strong class="lc iu"> <em class="nd"> </em> </strong> <a class="ae ls" href="https://www.kaggle.com/dataforyou/bankloan" rel="noopener ugc nofollow" target="_blank"> <em class="nd">数据字典</em> </a>。</p><p id="3dea" class="pw-post-body-paragraph mo mp it lc b ld mq ju mr lf ms jx mt lh mu mv mw lj mx my mz ll na nb nc ln im bi translated">除了数字数据之外，这个数据集还有包含一些编码变量基数的分类列，如果没有<a class="ae ls" href="https://www.kaggle.com/dataforyou/bankloan" rel="noopener ugc nofollow" target="_blank"> <em class="nd">数据字典，这些分类列是没有意义的。</em>T25】</a></p><p id="1a68" class="pw-post-body-paragraph mo mp it lc b ld mq ju mr lf ms jx mt lh mu mv mw lj mx my mz ll na nb nc ln im bi translated">excel文件可以从<a class="ae ls" href="https://github.com/Blackman9t/Machine_Learning/blob/master/Loan_Data%20for%20Classification.xlsx?raw=true%27" rel="noopener ugc nofollow" target="_blank"><strong class="lc iu"><em class="nd">GitHub</em></strong></a>下载。</p><p id="f499" class="pw-post-body-paragraph mo mp it lc b ld mq ju mr lf ms jx mt lh mu mv mw lj mx my mz ll na nb nc ln im bi translated">正在为EDA导入库…</p><pre class="lz ma mb mc gt nv nw nx ny aw nz bi"><span id="4577" class="oa kj it nw b gy ob oc l od oe"><strong class="nw iu">import</strong> <strong class="nw iu">itertools</strong><br/><strong class="nw iu">import</strong> <strong class="nw iu">numpy</strong> <strong class="nw iu">as</strong> <strong class="nw iu">np</strong><br/><strong class="nw iu">import</strong> <strong class="nw iu">matplotlib.pyplot</strong> <strong class="nw iu">as</strong> <strong class="nw iu">plt</strong><br/><strong class="nw iu">from</strong> <strong class="nw iu">matplotlib.ticker</strong> <strong class="nw iu">import</strong> <em class="nd">NullFormatter</em><br/><strong class="nw iu">import</strong> <strong class="nw iu">pandas</strong> <strong class="nw iu">as</strong> <strong class="nw iu">pd</strong><br/><strong class="nw iu">import</strong> <strong class="nw iu">numpy</strong> <strong class="nw iu">as</strong> <strong class="nw iu">np</strong><br/><strong class="nw iu">import</strong> <strong class="nw iu">matplotlib.ticker</strong> <strong class="nw iu">as</strong> <strong class="nw iu">ticker</strong><br/><strong class="nw iu">import</strong> <strong class="nw iu">seaborn</strong> <strong class="nw iu">as</strong> <strong class="nw iu">sns</strong><br/><strong class="nw iu">from</strong> <strong class="nw iu">sklearn</strong> <strong class="nw iu">import</strong> <em class="nd">preprocessing</em></span></pre><p id="fb7e" class="pw-post-body-paragraph mo mp it lc b ld mq ju mr lf ms jx mt lh mu mv mw lj mx my mz ll na nb nc ln im bi translated">让我们导入库来评估我们将要构建的模型。</p><pre class="lz ma mb mc gt nv nw nx ny aw nz bi"><span id="e90f" class="oa kj it nw b gy ob oc l od oe"><strong class="nw iu">from</strong> <strong class="nw iu">sklearn.metrics</strong> <strong class="nw iu">import</strong> <em class="nd">f1_score, confusion_matrix, log_loss, roc_auc_score, accuracy_score, classification_report</em></span></pre><p id="c4a9" class="pw-post-body-paragraph mo mp it lc b ld mq ju mr lf ms jx mt lh mu mv mw lj mx my mz ll na nb nc ln im bi translated">让我们为熊猫定义额外的NaN值，并读入我们的数据集。</p><pre class="lz ma mb mc gt nv nw nx ny aw nz bi"><span id="4815" class="oa kj it nw b gy ob oc l od oe"><strong class="nw iu">additional_nan_values = ['n/a', '--','?','None','Non','non','none']</strong></span><span id="88f6" class="oa kj it nw b gy of oc l od oe"><strong class="nw iu">data = '</strong><a class="ae ls" href="https://github.com/Blackman9t/Machine_Learning/blob/master/Loan_Data%20for%20Classification.xlsx?raw=true%27" rel="noopener ugc nofollow" target="_blank">https://medium.com/r/?url=https%3A%2F%2Fgithub.com%2FBlackman9t%2FMachine_Learning%2Fblob%2Fmaster%2FLoan_Data%2520for%2520Classification.xlsx%3Fraw%3Dtrue%2527</a>'</span><span id="7535" class="oa kj it nw b gy of oc l od oe"><strong class="nw iu">loan_df = pd.read_excel(data, header=2, na_values=additional_nan_values)</strong></span><span id="7b5f" class="oa kj it nw b gy of oc l od oe"><strong class="nw iu">loan_df.head()</strong></span></pre><figure class="lz ma mb mc gt md gh gi paragraph-image"><div role="button" tabindex="0" class="me mf di mg bf mh"><div class="gh gi og"><img src="../Images/e9744035c612d26d889f73ad99238ded.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Av9dCdROCHFACl32TmCoVw.jpeg"/></div></div></figure><p id="0c20" class="pw-post-body-paragraph mo mp it lc b ld mq ju mr lf ms jx mt lh mu mv mw lj mx my mz ll na nb nc ln im bi translated">查看标题，我们可以看到分类列，如<em class="nd"> Status_Checking_Acc </em>、<em class="nd"> Credit_History、</em>具有代表某些值的<em class="nd">、</em>代码。例如在<em class="nd">信用_历史</em>栏中，代码<strong class="lc iu"> A34 </strong>代表<em class="nd">关键账户/其他信用，</em>代码<strong class="lc iu"> A32 </strong>代表<em class="nd">到目前为止已到期归还的现有信用。</em></p><p id="a8e1" class="pw-post-body-paragraph mo mp it lc b ld mq ju mr lf ms jx mt lh mu mv mw lj mx my mz ll na nb nc ln im bi translated">所以，要理解数据，就必须理解<a class="ae ls" href="https://www.kaggle.com/dataforyou/bankloan" rel="noopener ugc nofollow" target="_blank"><strong class="lc iu"><em class="nd">——数据字典</em> </strong> </a>。</p><p id="729e" class="pw-post-body-paragraph mo mp it lc b ld mq ju mr lf ms jx mt lh mu mv mw lj mx my mz ll na nb nc ln im bi translated">让我们检查形状、信息和缺少的值。</p><pre class="lz ma mb mc gt nv nw nx ny aw nz bi"><span id="aa91" class="oa kj it nw b gy ob oc l od oe"><strong class="nw iu">loan_df.shape<br/></strong>&gt;&gt;<em class="nd">(5000,23)</em></span><span id="c9f9" class="oa kj it nw b gy of oc l od oe"><strong class="nw iu">loan_df.isna().any().all()<br/></strong>&gt;&gt; <em class="nd">False</em></span></pre><blockquote class="oh oi oj"><p id="ed7b" class="mo mp nd lc b ld mq ju mr lf ms jx mt ok mu mv mw ol mx my mz om na nb nc ln im bi translated">我们有5000个观察值，23个维度，没有缺失值。观察是信用贷款客户。尺寸是这些客户的特征。</p></blockquote><pre class="lz ma mb mc gt nv nw nx ny aw nz bi"><span id="78aa" class="oa kj it nw b gy ob oc l od oe"># Let's see the summary info for the numerical columns <br/><strong class="nw iu">loan_df.describe().T</strong></span></pre><figure class="lz ma mb mc gt md gh gi paragraph-image"><div role="button" tabindex="0" class="me mf di mg bf mh"><div class="gh gi on"><img src="../Images/75028e09439820fe4d5ed37912ef5161.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*gdTwNKmvSDODex9XmUgL0A.jpeg"/></div></div><figcaption class="mk ml gj gh gi mm mn bd b be z dk translated">数字列的描述性统计。</figcaption></figure><pre class="lz ma mb mc gt nv nw nx ny aw nz bi"><span id="4db4" class="oa kj it nw b gy ob oc l od oe"># Let's check summary for columns of object/categorical dtype.<br/><strong class="nw iu">loan_df.describe(include=['object','category']).T</strong></span></pre><figure class="lz ma mb mc gt md gh gi paragraph-image"><div class="gh gi oo"><img src="../Images/b62d858e0a1f85e43247e064e0e2851f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1348/format:webp/1*-WUaMACcp-aLfioB3StJuA.jpeg"/></div><figcaption class="mk ml gj gh gi mm mn bd b be z dk translated">分类列的汇总数据…</figcaption></figure><p id="666c" class="pw-post-body-paragraph mo mp it lc b ld mq ju mr lf ms jx mt lh mu mv mw lj mx my mz ll na nb nc ln im bi translated">从总结中，我们可以了解很多关于我们的数据。例如，最年轻的贷款客户是19岁，最老的是75岁。平均有29.9%的人拖欠付款。此外，每个分类列都有2到10个唯一编码的变量，代表数据字典中的一些定性值。</p><blockquote class="oh oi oj"><p id="8cd0" class="mo mp nd lc b ld mq ju mr lf ms jx mt ok mu mv mw ol mx my mz om na nb nc ln im bi translated">将<strong class="lc iu"> <em class="it">特征工程</em> </strong> <em class="it"> </em>应用于数据集时，理解<a class="ae ls" href="https://www.kaggle.com/dataforyou/bankloan" rel="noopener ugc nofollow" target="_blank">数据字典</a>中的这些分类变量至关重要。</p></blockquote><blockquote class="ne"><p id="a180" class="nf ng it bd nh ni op oq or os ot ln dk translated">因此，本练习的目的是建立统计模型，帮助金融机构识别可能拖欠付款的客户。这可能有助于进一步降低违约率，目前的平均违约率为29.9%。</p></blockquote><p id="3467" class="pw-post-body-paragraph mo mp it lc b ld no ju mr lf np jx mt lh nq mv mw lj nr my mz ll ns nb nc ln im bi translated"><strong class="lc iu"> <em class="nd">组织数据集:</em> </strong></p><p id="6c03" class="pw-post-body-paragraph mo mp it lc b ld mq ju mr lf ms jx mt lh mu mv mw lj mx my mz ll na nb nc ln im bi translated">让我们再来看一下数据，最好检查一下这些列，看看是否有任何可见的模式、关系或命名错误。</p><pre class="lz ma mb mc gt nv nw nx ny aw nz bi"><span id="3465" class="oa kj it nw b gy ob oc l od oe"># Let's see the total columns in the data set<br/><strong class="nw iu">loan_df.columns<br/></strong>&gt;&gt;<br/><em class="nd">Index(['Customer_ID', 'Status_Checking_Acc', 'Duration_in_Months',        'Credit_History', 'Purposre_Credit_Taken', 'Credit_Amount',        'Savings_Acc', 'Years_At_Present_Employment', 'Inst_Rt_Income',        'Marital_Status_Gender', 'Other_Debtors_Guarantors',        'Current_Address_Yrs', 'Property', 'Age', 'Other_Inst_Plans ',        'Housing', 'Num_CC', 'Job', 'Dependents', 'Telephone', 'Foreign_Worker',        'Default_On_Payment', 'Count'],       dtype='object')</em></span></pre><p id="850a" class="pw-post-body-paragraph mo mp it lc b ld mq ju mr lf ms jx mt lh mu mv mw lj mx my mz ll na nb nc ln im bi translated">我们需要清除一些带有空格或拼写错误的单词的列名。其他人可能只是需要一个更好的名字。让我们现在就这样做吧。</p><pre class="lz ma mb mc gt nv nw nx ny aw nz bi"><span id="d152" class="oa kj it nw b gy ob oc l od oe"><strong class="nw iu">loan_df.rename(columns={'Purposre_Credit_Taken':'Credit_Purpose',<br/>'Other_Inst_Plans ':'Other_Inst_Plans',<br/>'Years_At_Present_Employment': 'Present_Employment_Years',<br/>'Inst_Rt_Income':'Inst_Rate_Income',<br/>'Num_CC':'Num_Curr_Credits'}, inplace=True)</strong></span></pre><p id="d0b5" class="pw-post-body-paragraph mo mp it lc b ld mq ju mr lf ms jx mt lh mu mv mw lj mx my mz ll na nb nc ln im bi translated">接下来，让我们试着把他们分成小组。理想情况下，数据应该告诉我们一个故事…这意味着相似的列应该在一起。优选地，在数字列之前分类。</p><p id="dc05" class="pw-post-body-paragraph mo mp it lc b ld mq ju mr lf ms jx mt lh mu mv mw lj mx my mz ll na nb nc ln im bi translated">我可以从数据集中识别出三(3)大组列。让我们把它们分成python列列表…</p><pre class="lz ma mb mc gt nv nw nx ny aw nz bi"><span id="2a5f" class="oa kj it nw b gy ob oc l od oe"><strong class="nw iu">customer_data =</strong> <em class="nd">['Customer_ID', 'Marital_Status_Gender', 'Age', 'Dependents', 'Housing','Telephone', 'Property','Current_Address_Yrs']</em></span><span id="10a2" class="oa kj it nw b gy of oc l od oe"><strong class="nw iu">job_and_personal_finance =</strong> <em class="nd">['Job', 'Foreign_Worker', 'Present_Employment_Years', 'Savings_Acc','Status_Checking_Acc', 'Credit_History']</em></span><span id="c627" class="oa kj it nw b gy of oc l od oe"><strong class="nw iu">loan_credit_data =</strong> <em class="nd">['Credit_Amount', 'Credit_Purpose', 'Duration_in_Months','Inst_Rate_Income','Other_Debtors_Guarantors','Other_Inst_Plans','Num_Curr_Credits','Default_On_Payment', "Count"]</em></span></pre><p id="d2c0" class="pw-post-body-paragraph mo mp it lc b ld mq ju mr lf ms jx mt lh mu mv mw lj mx my mz ll na nb nc ln im bi translated">让我们将上面的3个列表连接起来，确保没有因为错误而留下空格，因为分组是手动完成的。</p><pre class="lz ma mb mc gt nv nw nx ny aw nz bi"><span id="7e67" class="oa kj it nw b gy ob oc l od oe"><strong class="nw iu">new_columns = customer_data + job_and_personal_finance + loan_credit_data</strong></span><span id="e984" class="oa kj it nw b gy of oc l od oe"># Lets strip off any whitespaces just incase...<br/><strong class="nw iu">stripped_columns = [str.strip(x, ' ') for x in new_columns if x[0] or x[-1] == ' ']</strong></span></pre><p id="f2c4" class="pw-post-body-paragraph mo mp it lc b ld mq ju mr lf ms jx mt lh mu mv mw lj mx my mz ll na nb nc ln im bi translated">现在让我们确认stripped_column中的所有列名都与loan_df列相同。</p><pre class="lz ma mb mc gt nv nw nx ny aw nz bi"><span id="60bc" class="oa kj it nw b gy ob oc l od oe"><strong class="nw iu">set(loan_df.columns).difference(set(stripped_columns))</strong><br/>&gt;&gt;<br/><strong class="nw iu"><em class="nd">set()</em></strong><em class="nd"><br/></em># The empty set returned, indicates we're all good.</span></pre><p id="3509" class="pw-post-body-paragraph mo mp it lc b ld mq ju mr lf ms jx mt lh mu mv mw lj mx my mz ll na nb nc ln im bi translated">现在，我们可以将新的有序和剥离的列分配给loan_df，作为我们的新列集。</p><pre class="lz ma mb mc gt nv nw nx ny aw nz bi"><span id="9ba3" class="oa kj it nw b gy ob oc l od oe"><strong class="nw iu">loan_df = loan_df[stripped_columns]</strong></span><span id="32df" class="oa kj it nw b gy of oc l od oe"># let's see the first few rows</span><span id="2a67" class="oa kj it nw b gy of oc l od oe"><strong class="nw iu">loan_df.head(3)<br/></strong>&gt;&gt;</span></pre><figure class="lz ma mb mc gt md gh gi paragraph-image"><div role="button" tabindex="0" class="me mf di mg bf mh"><div class="gh gi ou"><img src="../Images/e996c13d6a5c12344283f39bc9425b13.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*dko443CZRImROSfE1Cidow.jpeg"/></div></div><figcaption class="mk ml gj gh gi mm mn bd b be z dk translated">显示客户数据、工作数据、信用数据和每个客户的默认状态的有序列…</figcaption></figure><p id="a560" class="pw-post-body-paragraph mo mp it lc b ld mq ju mr lf ms jx mt lh mu mv mw lj mx my mz ll na nb nc ln im bi translated">现在，我们的数据集是用列组织起来的，这些列讲述了5000名信用客户中每一个人的精彩故事…太棒了！</p><figure class="lz ma mb mc gt md gh gi paragraph-image"><div class="gh gi nu"><img src="../Images/3d24e6fe2706231d1a7aedfba19a2d1d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1240/format:webp/1*RS1kuoIcXTJC5-7gE9QzbQ.jpeg"/></div><figcaption class="mk ml gj gh gi mm mn bd b be z dk translated">Img| <a class="ae ls" href="https://media.makeameme.org/created/cheers-to-you-c3b129e042.jpg" rel="noopener ugc nofollow" target="_blank">信用</a></figcaption></figure><h1 id="3e36" class="ki kj it bd kk kl km kn ko kp kq kr ks jz kt ka ku kc kv kd kw kf kx kg ky kz bi translated">第3部分:特征工程</h1><p id="4e0d" class="pw-post-body-paragraph mo mp it lc b ld le ju mr lf lg jx mt lh ov mv mw lj ow my mz ll ox nb nc ln im bi translated">好了，这是我们应用可视化库来获得更多关于变量的见解的部分。我们将目标变量<em class="nd"> (Default_On_Payment) </em>评估为独立变量的函数，然后我们应用<em class="nd">特征选择</em>、<em class="nd">二值化</em>、<em class="nd">归一化</em>，为建立模型做准备。</p><figure class="lz ma mb mc gt md gh gi paragraph-image"><div class="gh gi nu"><img src="../Images/7390ddb9516f51d04fa608d766732070.png" data-original-src="https://miro.medium.com/v2/resize:fit:1240/format:webp/1*JxKndrNrQQ1-XDOnMd9mFA.jpeg"/></div><figcaption class="mk ml gj gh gi mm mn bd b be z dk translated">Img| <a class="ae ls" href="https://thedigizones.com/blog/wp-content/uploads/2020/03/1_K6ctE0RZme0cqMtknrxq8A.png" rel="noopener ugc nofollow" target="_blank">信用</a></figcaption></figure><p id="8799" class="pw-post-body-paragraph mo mp it lc b ld mq ju mr lf ms jx mt lh mu mv mw lj mx my mz ll na nb nc ln im bi translated">让我们形象化分类变量和目标变量之间的关系。</p><pre class="lz ma mb mc gt nv nw nx ny aw nz bi"><span id="63d1" class="oa kj it nw b gy ob oc l od oe"># First we select the categorical columns<br/><strong class="nw iu">categorical_cols = loan_df.select_dtypes(['object']).columns<br/>print(categorical_cols)<br/></strong>&gt;&gt;<br/><em class="nd">Index(['Marital_Status_Gender', 'Housing', 'Telephone', 'Property', 'Job', 'Foreign_Worker', 'Present_Employment_Years', 'Savings_Acc',        'Status_Checking_Acc', 'Credit_History', 'Credit_Purpose',        'Other_Debtors_Guarantors', 'Other_Inst_Plans'],       dtype='object')</em></span></pre><p id="657d" class="pw-post-body-paragraph mo mp it lc b ld mq ju mr lf ms jx mt lh mu mv mw lj mx my mz ll na nb nc ln im bi translated">我们将使用<em class="nd"> violin </em>图来显示每个分类变量的违约百分比。这在<em class="nd">特征选择中会很方便。</em></p><figure class="lz ma mb mc gt md gh gi paragraph-image"><div role="button" tabindex="0" class="me mf di mg bf mh"><div class="gh gi oy"><img src="../Images/2a01f747a0e610bcb3d8d8746f99665d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*al5DywA008SLX6XzVZ-jDw.jpeg"/></div></div><figcaption class="mk ml gj gh gi mm mn bd b be z dk translated">violin图网格显示了每个分类变量中拖欠付款者的百分比。</figcaption></figure><p id="0c2c" class="pw-post-body-paragraph mo mp it lc b ld mq ju mr lf ms jx mt lh mu mv mw lj mx my mz ll na nb nc ln im bi translated">网格图是用<em class="nd"> seaborn </em>和<em class="nd"> matplotlib </em>库完成的。它只是显示了每个分类变量的违约百分比。回想一下，像<em class="nd"> Credit_History、</em>这样的每个分类变量都有一些子变量，用代码表示，如<em class="nd"> { </em> <strong class="lc iu"> A30 </strong>、<strong class="lc iu"> A31 </strong>、… <strong class="lc iu"> A34 </strong> <em class="nd"> }。</em></p><p id="34ff" class="pw-post-body-paragraph mo mp it lc b ld mq ju mr lf ms jx mt lh mu mv mw lj mx my mz ll na nb nc ln im bi translated">现在，这些代码代表<a class="ae ls" href="https://www.kaggle.com/dataforyou/bankloan" rel="noopener ugc nofollow" target="_blank"> <strong class="lc iu"> <em class="nd">数据字典</em> </strong> </a>中的某些定性值。我们只选择那些影响违约或非违约行为的变量来训练我们的模型。</p><p id="dc65" class="pw-post-body-paragraph mo mp it lc b ld mq ju mr lf ms jx mt lh mu mv mw lj mx my mz ll na nb nc ln im bi translated">为了更清楚，让我们检查一下<em class="nd">属性</em>分类变量…</p><figure class="lz ma mb mc gt md gh gi paragraph-image"><div role="button" tabindex="0" class="me mf di mg bf mh"><div class="gh gi oz"><img src="../Images/111149afd544879b06f2f3ee769f502f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1182/format:webp/1*gfRkJzrqZJliCwtBFfJ1Og.jpeg"/></div></div><figcaption class="mk ml gj gh gi mm mn bd b be z dk translated">Violin图显示属性变量的违约百分比。</figcaption></figure><p id="8fd4" class="pw-post-body-paragraph mo mp it lc b ld mq ju mr lf ms jx mt lh mu mv mw lj mx my mz ll na nb nc ln im bi translated"><em class="nd">属性</em>有四个子变量，分别编码为{ <strong class="lc iu"> A121 </strong>、<strong class="lc iu"> A122 </strong>、<strong class="lc iu"> A123 </strong>、<strong class="lc iu"> A124 </strong> }。很明显，我们可以看到对于<strong class="lc iu"> A121 </strong>，只有<em class="nd"> 21% </em>的客户违约，<strong class="lc iu"> A122 </strong>和<strong class="lc iu"> A123 </strong>分别有<em class="nd"> 31% </em>。而<strong class="lc iu"> A124 </strong>有<em class="nd"> 44% </em>的违约者。</p><p id="86d3" class="pw-post-body-paragraph mo mp it lc b ld mq ju mr lf ms jx mt lh mu mv mw lj mx my mz ll na nb nc ln im bi translated">所以<strong class="lc iu"> A124 </strong>不是训练我们模型的好的子变量。简单来说，几乎<em class="nd"> 50% </em>的客户都默认有这个功能。反之，约<em class="nd"> 50% </em>不违约。没有明确的区分阈值。相反，我们需要显示违约或非违约客户的不同百分比的分类变量。像<strong class="lc iu"> A121 </strong>，只有<em class="nd"> 21% </em>的违约者，相反，79%的非违约者。</p><p id="2c31" class="pw-post-body-paragraph mo mp it lc b ld mq ju mr lf ms jx mt lh mu mv mw lj mx my mz ll na nb nc ln im bi translated"><strong class="lc iu"> <em class="nd">阈值</em> : </strong></p><blockquote class="oh oi oj"><p id="0107" class="mo mp nd lc b ld mq ju mr lf ms jx mt ok mu mv mw ol mx my mz om na nb nc ln im bi translated">我的阈值是<strong class="lc iu"> ( <em class="it">默认&lt; =0.4 |默认&gt; =0.6)。</em> </strong>因此，我将只包括违约率小于或等于40%或大于或等于60%的类别。这将确保我的模型学习不同的属性。</p></blockquote><p id="91d8" class="pw-post-body-paragraph mo mp it lc b ld mq ju mr lf ms jx mt lh mu mv mw lj mx my mz ll na nb nc ln im bi translated"><strong class="lc iu"> <em class="nd">特征-二值化</em> </strong></p><p id="9306" class="pw-post-body-paragraph mo mp it lc b ld mq ju mr lf ms jx mt lh mu mv mw lj mx my mz ll na nb nc ln im bi translated">二进制化帮助我们将每个分类变量扩展成只包含零和一的新变量<em class="nd"> (0，1) </em> … <em class="nd">假</em> <em class="nd">或真</em>。它通常是<em class="nd">特征选择</em>的前身。</p><figure class="lz ma mb mc gt md gh gi paragraph-image"><div class="gh gi pa"><img src="../Images/cce9982be454b640d11ea91755a4bc68.png" data-original-src="https://miro.medium.com/v2/resize:fit:1112/format:webp/1*EfW8JGzoXQ-cXy7Qd-7dUQ.jpeg"/></div><figcaption class="mk ml gj gh gi mm mn bd b be z dk translated">将属性变量二进制化为4个新的0和1变量…</figcaption></figure><p id="cd14" class="pw-post-body-paragraph mo mp it lc b ld mq ju mr lf ms jx mt lh mu mv mw lj mx my mz ll na nb nc ln im bi translated">例如，<em class="nd">属性</em>变量有4个子变量或代码:- { <strong class="lc iu"> A121 </strong>，…，<strong class="lc iu"> A124 </strong> }。通过应用二进制化，<em class="nd">属性</em>被4个新变量取代{ <strong class="lc iu"> A121 </strong>、<strong class="lc iu"> A122 </strong>、<strong class="lc iu"> A123 </strong>、<strong class="lc iu"> A124 </strong> }，这些变量现在成为我们数据集中的不同变量，默认情况下包含0，并且仅在<em class="nd">属性</em>变量中各自之前占据的位置包含1……参见<a class="ae ls" href="https://deepai.org/machine-learning-glossary-and-terms/binarization" rel="noopener ugc nofollow" target="_blank"> <strong class="lc iu"> <em class="nd">链接</em> </strong> </a></p><pre class="lz ma mb mc gt nv nw nx ny aw nz bi"><span id="96b9" class="oa kj it nw b gy ob oc l od oe"># Let's binarize categorical variables and save in a new dataframe.<br/><strong class="nw iu">loan_df_dummies = pd.get_dummies(loan_df)</strong></span><span id="1b4c" class="oa kj it nw b gy of oc l od oe"># <em class="nd">we use the pd.get_dummies func to binarize variables.</em></span></pre><p id="5185" class="pw-post-body-paragraph mo mp it lc b ld mq ju mr lf ms jx mt lh mu mv mw lj mx my mz ll na nb nc ln im bi translated">好了，让我们从二值化数据框中选择理想的分类变量。记住我们想要满足这个条件的变量:- <strong class="lc iu"> ( <em class="nd">默认&lt; =0.4 |默认&gt; =0.6)。</em> </strong></p><pre class="lz ma mb mc gt nv nw nx ny aw nz bi"><span id="e02a" class="oa kj it nw b gy ob oc l od oe"># First we make a list of all categorical columns.<br/><strong class="nw iu">categorical_cols = loan_df.select_dtypes(['object']).columns</strong></span><span id="707c" class="oa kj it nw b gy of oc l od oe"># Next we define a simple method to sort out the features to delete<br/><strong class="nw iu">def delete_categorical_feature(categorical_cols):<br/>    """ This method takes a list of categorical columns,and returns a list of feature attributes to delete based on set threshold """<br/>    </strong><em class="nd">delete_list = []<br/>    for x in categorical_cols:<br/>    default_df = loan_df.groupby(x)<br/>    ['Default_On_Payment'].value_counts(normalize=True).<br/>     to_frame()[1::2]<br/>    delete_feature = default_df[(default_df.Default_On_Payment &gt;=          0.4) &amp; (default_df.Default_On_Payment &lt;= 0.6)]<br/>    delete = [delete_feature.index[i][0] for i in            range(len(delete_feature))]<br/>    for i in range(len(delete)):<br/>        delete[i] = x + '_' + delete[i]<br/>    delete_list += delete</em></span><span id="d265" class="oa kj it nw b gy of oc l od oe"><strong class="nw iu">return delete_list</strong></span><span id="240d" class="oa kj it nw b gy of oc l od oe"># Next, we call the method with the list of categorical columns<br/><strong class="nw iu">delete_list = delete_categorical_feature(categorical_cols)</strong></span><span id="1d5a" class="oa kj it nw b gy of oc l od oe"># Finally, let's see the columns to be deleted.<strong class="nw iu"><br/>print('Total cols to be deleted-', len(delete_list))<br/>print(delete_list)<br/></strong>&gt;&gt;<br/>Total cols to be deleted- 11</span><span id="435c" class="oa kj it nw b gy of oc l od oe"><em class="nd">['Marital_Status_Gender_A91',<br/> 'Housing_A153',<br/> 'Property_A124',<br/> 'Present_Employment_Years_A72',<br/> 'Status_Checking_Acc_A11',<br/> 'Credit_History_A31',<br/> 'Credit_Purpose_A410',<br/> 'Credit_Purpose_A46',<br/> 'Other_Debtors_Guarantors_A102',<br/> 'Other_Inst_Plans_A141',<br/> 'Other_Inst_Plans_A142']</em></span></pre><p id="2ff4" class="pw-post-body-paragraph mo mp it lc b ld mq ju mr lf ms jx mt lh mu mv mw lj mx my mz ll na nb nc ln im bi translated">既然我们已经确定了不合格的变量，让我们排除它们…</p><pre class="lz ma mb mc gt nv nw nx ny aw nz bi"><span id="a914" class="oa kj it nw b gy ob oc l od oe"><strong class="nw iu">loan_df_dummies = loan_df_dummies.drop(delete_list, axis=1)<br/>loan_df_dummies.shape</strong><br/>&gt;&gt;<br/><em class="nd">(5000, 53)</em></span></pre><blockquote class="oh oi oj"><p id="bef9" class="mo mp nd lc b ld mq ju mr lf ms jx mt ok mu mv mw ol mx my mz om na nb nc ln im bi translated">我们的二值化数据框现在有53列，包括目标变量，从23列增加到53列。这是由于来自二进制化的附加变量。</p></blockquote><p id="a6a1" class="pw-post-body-paragraph mo mp it lc b ld mq ju mr lf ms jx mt lh mu mv mw lj mx my mz ll na nb nc ln im bi translated"><strong class="lc iu"> <em class="nd">检查数值变量:</em> </strong></p><p id="39b2" class="pw-post-body-paragraph mo mp it lc b ld mq ju mr lf ms jx mt lh mu mv mw lj mx my mz ll na nb nc ln im bi translated">我们来看看原始数据集的数值特征，<em class="nd"> loan_df。</em></p><pre class="lz ma mb mc gt nv nw nx ny aw nz bi"><span id="c735" class="oa kj it nw b gy ob oc l od oe"># first let's make a list of numerical columns<br/><strong class="nw iu">numerical_columns = loan_df.select_dtypes(['number']).columns</strong></span><span id="05b8" class="oa kj it nw b gy of oc l od oe"># Next, let's see the list<br/><strong class="nw iu">print(numerical_columns)<br/></strong>&gt;&gt;<strong class="nw iu"><br/></strong><em class="nd">Index(['Customer_ID', 'Age', 'Dependents', 'Current_Address_Yrs',        'Credit_Amount', 'Duration_in_Months', 'Inst_Rate_Income',        'Num_Curr_Credits', 'Default_On_Payment', 'Count'],       dtype='object')</em></span></pre><p id="f406" class="pw-post-body-paragraph mo mp it lc b ld mq ju mr lf ms jx mt lh mu mv mw lj mx my mz ll na nb nc ln im bi translated">让我们看看数字特征的历史图</p><pre class="lz ma mb mc gt nv nw nx ny aw nz bi"><span id="db8d" class="oa kj it nw b gy ob oc l od oe"><strong class="nw iu">loan_df[numerical_columns].hist(figsize=(16,12))<br/>plt.suptitle('Histogram of Numerical Features', fontsize=18, y=0.95)<br/>plt.show()</strong></span></pre><figure class="lz ma mb mc gt md gh gi paragraph-image"><div role="button" tabindex="0" class="me mf di mg bf mh"><div class="gh gi pb"><img src="../Images/36a25cdf60cfcccb875138d730d2aa8e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*NBm6PBcDOp-iGdG4-6OYBw.jpeg"/></div></div><figcaption class="mk ml gj gh gi mm mn bd b be z dk translated">数字特征的直方图。</figcaption></figure><p id="cef1" class="pw-post-body-paragraph mo mp it lc b ld mq ju mr lf ms jx mt lh mu mv mw lj mx my mz ll na nb nc ln im bi translated"><em class="nd"> Customer_ID </em>和<em class="nd"> Count </em>变量不会给我们的模型添加任何值，它们只是帮助索引每个客户，应该被删除。</p><p id="5d2b" class="pw-post-body-paragraph mo mp it lc b ld mq ju mr lf ms jx mt lh mu mv mw lj mx my mz ll na nb nc ln im bi translated"><em class="nd">年龄</em>特征具有大量36岁以下的年轻人，较少的老年人导致直方图向右倾斜。而<em class="nd">信用_金额</em>列显示大多数信用低于2500美元，一些高达约5000美元</p><p id="dfa5" class="pw-post-body-paragraph mo mp it lc b ld mq ju mr lf ms jx mt lh mu mv mw lj mx my mz ll na nb nc ln im bi translated">其余的变量，如<em class="nd">【客户年龄】</em><em class="nd">【家属人数】</em><em class="nd">【信贷金额】</em>等，在训练我们的模型时都很重要。</p><p id="6a26" class="pw-post-body-paragraph mo mp it lc b ld mq ju mr lf ms jx mt lh mu mv mw lj mx my mz ll na nb nc ln im bi translated">但是让我们来看看数字特征的相关数据</p><pre class="lz ma mb mc gt nv nw nx ny aw nz bi"><span id="643d" class="oa kj it nw b gy ob oc l od oe"><strong class="nw iu">corr_data = loan_df[numerical_columns].corr()<br/>plt.figure(figsize=(12, 8))<br/>sns.set_style('ticks')<br/>sns.heatmap(corr_data, annot=True)<br/>plt.show()</strong></span></pre><figure class="lz ma mb mc gt md gh gi paragraph-image"><div role="button" tabindex="0" class="me mf di mg bf mh"><div class="gh gi pc"><img src="../Images/980caed1e743ba38ae3d93a10a5f0507.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*d_KK6NnKlYQgCDLkEfkZEA.jpeg"/></div></div><figcaption class="mk ml gj gh gi mm mn bd b be z dk translated">数字特征的相关矩阵</figcaption></figure><p id="de55" class="pw-post-body-paragraph mo mp it lc b ld mq ju mr lf ms jx mt lh mu mv mw lj mx my mz ll na nb nc ln im bi translated">目标变量(<em class="nd"> Default_On_Payment) </em>与任何特性都没有实质性的相关性。<em class="nd">信用_金额</em>和<em class="nd">持续_月数</em>是与<em class="nd"> </em> 0.62最相关的特征。</p><p id="6a04" class="pw-post-body-paragraph mo mp it lc b ld mq ju mr lf ms jx mt lh mu mv mw lj mx my mz ll na nb nc ln im bi translated">那么这些显著的低相关性数字告诉了我们什么呢？嗯……首先，我们的独立变量相对不同，我们的数据集被认为没有多重共线性问题。</p><p id="a0b4" class="pw-post-body-paragraph mo mp it lc b ld mq ju mr lf ms jx mt lh mu mv mw lj mx my mz ll na nb nc ln im bi translated">特征与目标不相关的事实对于<em class="nd">线性回归模型</em>来说是一个问题，对于<em class="nd">逻辑回归(LR) </em>来说也可能是一个问题，但是通过一些微调，<em class="nd">逻辑回归</em>模型可能会做得很好。</p><p id="e4f1" class="pw-post-body-paragraph mo mp it lc b ld mq ju mr lf ms jx mt lh mu mv mw lj mx my mz ll na nb nc ln im bi translated">很明显，这是一个<em class="nd">二元分类</em>问题，不是线性回归。</p><p id="6e69" class="pw-post-body-paragraph mo mp it lc b ld mq ju mr lf ms jx mt lh mu mv mw lj mx my mz ll na nb nc ln im bi translated">好的，让我们从二进制数据帧中去掉不需要的变量。</p><pre class="lz ma mb mc gt nv nw nx ny aw nz bi"><span id="cab1" class="oa kj it nw b gy ob oc l od oe"><strong class="nw iu">loan_df_dummies.drop(['Count', 'Customer_ID'], axis=1, inplace=True)</strong></span><span id="f504" class="oa kj it nw b gy of oc l od oe"># Next let's send the target variable to the extreme right position<br/><strong class="nw iu">temp = loan_df_dummies.Default_On_Payment<br/>loan_df_dummies = loan_df_dummies.drop('Default_On_Payment', axis=1)<br/>loan_df_dummies['Default_On_Payment'] = temp</strong></span><span id="fd25" class="oa kj it nw b gy of oc l od oe"># next let's inspect few rows of our binarized data frame<br/><strong class="nw iu">loan_df_dummies.head()</strong></span></pre><figure class="lz ma mb mc gt md gh gi paragraph-image"><div role="button" tabindex="0" class="me mf di mg bf mh"><div class="gh gi pd"><img src="../Images/19a29f681dcfbab8642a0d9d3e660a64.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*wt_4rSZTU-dodRzpxLk95Q.jpeg"/></div></div></figure><p id="1379" class="pw-post-body-paragraph mo mp it lc b ld mq ju mr lf ms jx mt lh mu mv mw lj mx my mz ll na nb nc ln im bi translated">一切都好……让我们进入下一个紧迫的问题。</p><p id="ac05" class="pw-post-body-paragraph mo mp it lc b ld mq ju mr lf ms jx mt lh mu mv mw lj mx my mz ll na nb nc ln im bi translated"><strong class="lc iu"> <em class="nd">我们的数据集有多均衡？</em> </strong></p><blockquote class="oh oi oj"><p id="6288" class="mo mp nd lc b ld mq ju mr lf ms jx mt ok mu mv mw ol mx my mz om na nb nc ln im bi translated">我们的课堂观察分布不均匀吗？如果数据有偏差…模型可能有偏差。</p></blockquote><p id="2759" class="pw-post-body-paragraph mo mp it lc b ld mq ju mr lf ms jx mt lh mu mv mw lj mx my mz ll na nb nc ln im bi translated">让我们检查数据集中违约者与非违约者的比率。</p><pre class="lz ma mb mc gt nv nw nx ny aw nz bi"><span id="2cf5" class="oa kj it nw b gy ob oc l od oe"><strong class="nw iu">loan_df.Default_On_Payment.value_counts(normalize=True)</strong><br/>&gt;&gt;<br/><em class="nd">0    0.701 <br/>1    0.299</em></span></pre><p id="fc20" class="pw-post-body-paragraph mo mp it lc b ld mq ju mr lf ms jx mt lh mu mv mw lj mx my mz ll na nb nc ln im bi translated">数据集中70%的信用客户没有违约，只有30%违约…</p><blockquote class="ne"><p id="b595" class="nf ng it bd nh ni nj nk nl nm nn ln dk translated">不平衡数据集是指类元素排列不均匀或不公平的数据集。</p></blockquote><pre class="pe pf pg ph pi nv nw nx ny aw nz bi"><span id="0aeb" class="oa kj it nw b gy ob oc l od oe"><strong class="nw iu">plt.figure(figsize=(8, 8))</strong></span><span id="3cc5" class="oa kj it nw b gy of oc l od oe"><strong class="nw iu">x = loan_df_dummies.Default_On_Payment.replace(to_replace=[0, 1], value=['Non-Defaulters','Defaulters'])</strong></span><span id="bdf1" class="oa kj it nw b gy of oc l od oe"><strong class="nw iu">sns.countplot(x)<br/>plt.title('Count of Defaulters and Non-Defaulters')<br/>plt.show()</strong></span></pre><figure class="lz ma mb mc gt md gh gi paragraph-image"><div class="gh gi nu"><img src="../Images/20b461077322c3e0e526b9defd724906.png" data-original-src="https://miro.medium.com/v2/resize:fit:1240/format:webp/1*J9MhkhXWP4e1BFYZT-KeAg.jpeg"/></div><figcaption class="mk ml gj gh gi mm mn bd b be z dk translated">显示不平衡等级分布的计数图</figcaption></figure><p id="4948" class="pw-post-body-paragraph mo mp it lc b ld mq ju mr lf ms jx mt lh mu mv mw lj mx my mz ll na nb nc ln im bi translated"><strong class="lc iu"> <em class="nd">平衡数据集:</em> </strong></p><p id="99ac" class="pw-post-body-paragraph mo mp it lc b ld mq ju mr lf ms jx mt lh mu mv mw lj mx my mz ll na nb nc ln im bi translated">不平衡的数据集使得模型对于优势类具有高识别率<strong class="lc iu"> ( <em class="nd">灵敏度</em> ) </strong>。在不平衡的数据集中，模型的<em class="nd"> F1 </em>分数可能不可靠。<a class="ae ls" href="https://sebastianraschka.com/faq/docs/computing-the-f1-score.html" rel="noopener ugc nofollow" target="_blank"> <strong class="lc iu"> <em class="nd">链接</em> </strong> </a></p><p id="90c4" class="pw-post-body-paragraph mo mp it lc b ld mq ju mr lf ms jx mt lh mu mv mw lj mx my mz ll na nb nc ln im bi translated">让我们继续使用SMOTE <strong class="lc iu"> <em class="nd">(合成少数过采样</em> </strong> <a class="ae ls" href="https://imbalanced-learn.readthedocs.io/en/stable/generated/imblearn.over_sampling.SMOTE.html" rel="noopener ugc nofollow" target="_blank"> <strong class="lc iu"> <em class="nd">技术</em> </strong> </a> <strong class="lc iu"> <em class="nd">)来平衡数据集。</em> </strong>注意其他技术也可用于处理不平衡数据。详见本<a class="ae ls" href="https://towardsdatascience.com/handling-imbalanced-datasets-in-machine-learning-7a0e84220f28" rel="noopener" target="_blank"> <strong class="lc iu"> <em class="nd">丰富文章</em> </strong> </a>。</p><p id="9ce0" class="pw-post-body-paragraph mo mp it lc b ld mq ju mr lf ms jx mt lh mu mv mw lj mx my mz ll na nb nc ln im bi translated"><strong class="lc iu"> <em class="nd"> SMOTE </em> </strong>将通过综合创建少数类的更多观察值来平衡数据集，以等同于优势类。在这种情况下，将创建额外的2，000个观察值并添加到defaulters类，这样每个类就有3，500个观察值，总共有7，000个观察值。</p><pre class="lz ma mb mc gt nv nw nx ny aw nz bi"><span id="b1d2" class="oa kj it nw b gy ob oc l od oe"><strong class="nw iu">from imblearn.over_sampling import SMOTE</strong></span><span id="7fe5" class="oa kj it nw b gy of oc l od oe"><strong class="nw iu">sm = SMOTE(sampling_strategy='minority', random_state=19, k_neighbors=5)</strong></span><span id="ccaf" class="oa kj it nw b gy of oc l od oe"><strong class="nw iu">over_sampled_features, over_sampled_target = sm.fit_resample(loan_df_dummies.drop('Default_On_Payment', axis=1), loan_df_dummies.Default_On_Payment)</strong></span></pre><p id="e4f2" class="pw-post-body-paragraph mo mp it lc b ld mq ju mr lf ms jx mt lh mu mv mw lj mx my mz ll na nb nc ln im bi translated">让我们看看新的重采样数据集</p><pre class="lz ma mb mc gt nv nw nx ny aw nz bi"><span id="8bb9" class="oa kj it nw b gy ob oc l od oe"><strong class="nw iu">plt.figure(figsize=(8, 8))<br/>yy = pd.Series(over_sampled_target).replace(to_replace=[0, 1], value=['Non-Defaulters','Defaulters'])</strong></span><span id="892b" class="oa kj it nw b gy of oc l od oe"><strong class="nw iu">sns.countplot(yy)<br/>plt.title('Count of Defaulters and Non-Defaulters')<br/>plt.show()</strong></span></pre><figure class="lz ma mb mc gt md gh gi paragraph-image"><div class="gh gi pj"><img src="../Images/c2c7cec6ccdd973ec74a8ba0faa80aad.png" data-original-src="https://miro.medium.com/v2/resize:fit:966/format:webp/1*fE7oGHLPv7AWsH6IG7BZog.jpeg"/></div><figcaption class="mk ml gj gh gi mm mn bd b be z dk translated">违约者和非违约者的平衡数据。</figcaption></figure><p id="4b8c" class="pw-post-body-paragraph mo mp it lc b ld mq ju mr lf ms jx mt lh mu mv mw lj mx my mz ll na nb nc ln im bi translated">在过采样练习之后，让我们适当地重新排列我们的数据集。</p><pre class="lz ma mb mc gt nv nw nx ny aw nz bi"><span id="220f" class="oa kj it nw b gy ob oc l od oe"># First we concat the features and target back into one data frame<br/><strong class="nw iu">over_sampled_features = pd.DataFrame(over_sampled_features)<br/>over_sampled_features['x'] = over_sampled_target<br/>resampled_data = over_sampled_features<br/>resampled_data.head(2)</strong></span><span id="5e5a" class="oa kj it nw b gy of oc l od oe"># Next, let's add the column headers<br/><strong class="nw iu">resampled_data.columns = loan_df_dummies.columns</strong></span></pre><p id="a42a" class="pw-post-body-paragraph mo mp it lc b ld mq ju mr lf ms jx mt lh mu mv mw lj mx my mz ll na nb nc ln im bi translated">好了，下一步是<em class="nd">规范化</em>我们的数据集。</p><p id="2b1c" class="pw-post-body-paragraph mo mp it lc b ld mq ju mr lf ms jx mt lh mu mv mw lj mx my mz ll na nb nc ln im bi translated"><strong class="lc iu"> <em class="nd">特征归一化:</em> </strong></p><p id="4aea" class="pw-post-body-paragraph mo mp it lc b ld mq ju mr lf ms jx mt lh mu mv mw lj mx my mz ll na nb nc ln im bi translated">这个过程确保我们的模型不会受到任何特定特性的过度影响，因为它将所有特性限制在特定的值范围内。</p><p id="5f33" class="pw-post-body-paragraph mo mp it lc b ld mq ju mr lf ms jx mt lh mu mv mw lj mx my mz ll na nb nc ln im bi translated">我们将使用<em class="nd">最小-最大</em>归一化器<em class="nd">。</em></p><blockquote class="oh oi oj"><p id="7b5b" class="mo mp nd lc b ld mq ju mr lf ms jx mt ok mu mv mw ol mx my mz om na nb nc ln im bi translated">也就是说，对于每个特征，我们从所有值中减去最小值，然后除以值的范围。最小-最大确保所有特征值都在0和1之间。</p></blockquote><p id="6132" class="pw-post-body-paragraph mo mp it lc b ld mq ju mr lf ms jx mt lh mu mv mw lj mx my mz ll na nb nc ln im bi translated">让我们在一行代码中使用python <em class="nd"> apply </em>和<em class="nd"> lambda </em>函数来应用<em class="nd"> min-max </em>规格化器。</p><pre class="lz ma mb mc gt nv nw nx ny aw nz bi"><span id="e30d" class="oa kj it nw b gy ob oc l od oe"># We apply min-max to all relevant features excluding the target feature.<strong class="nw iu"><br/>resampled_data.iloc[:,:-1] = resampled_data.iloc[:,:-1].apply(lambda x: (x - min(x)) / (max(x) - min(x)))</strong></span></pre><p id="7ac4" class="pw-post-body-paragraph mo mp it lc b ld mq ju mr lf ms jx mt lh mu mv mw lj mx my mz ll na nb nc ln im bi translated">让我们再看看我们的数据集，只是为了确保它都是好的…</p><pre class="lz ma mb mc gt nv nw nx ny aw nz bi"><span id="589b" class="oa kj it nw b gy ob oc l od oe"><strong class="nw iu">resampled_data.head()<br/>&gt;&gt;</strong></span></pre><figure class="lz ma mb mc gt md gh gi paragraph-image"><div role="button" tabindex="0" class="me mf di mg bf mh"><div class="gh gi pk"><img src="../Images/e5f403fd8391b68aabd81a1132546973.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*iPhb2dIwQqvkYaHpi15mVw.jpeg"/></div></div><figcaption class="mk ml gj gh gi mm mn bd b be z dk translated">好的，一切都检查过了…</figcaption></figure><p id="8872" class="pw-post-body-paragraph mo mp it lc b ld mq ju mr lf ms jx mt lh mu mv mw lj mx my mz ll na nb nc ln im bi translated"><strong class="lc iu"> <em class="nd">特征分割:</em> </strong></p><p id="7ee0" class="pw-post-body-paragraph mo mp it lc b ld mq ju mr lf ms jx mt lh mu mv mw lj mx my mz ll na nb nc ln im bi translated">作为构建模型之前的最后一步，让我们将数据分成训练集、验证集和测试集，并为每个子集添加标签。我们用训练集训练，用验证集验证每个模型的性能，只有当我们对模型满意时，我们才接近测试集。</p><p id="06dd" class="pw-post-body-paragraph mo mp it lc b ld mq ju mr lf ms jx mt lh mu mv mw lj mx my mz ll na nb nc ln im bi translated">我们把数据按照70%和30%的比例拆分成训练和测试。</p><pre class="lz ma mb mc gt nv nw nx ny aw nz bi"><span id="82a4" class="oa kj it nw b gy ob oc l od oe"><strong class="nw iu">from sklearn.model_selection import train_test_split</strong></span><span id="563e" class="oa kj it nw b gy of oc l od oe"><strong class="nw iu">X = resampled_data.iloc[:,:-1]</strong></span><span id="62d5" class="oa kj it nw b gy of oc l od oe"><strong class="nw iu">Y = resampled_data.Default_On_Payment</strong></span><span id="2667" class="oa kj it nw b gy of oc l od oe"><strong class="nw iu">x_train, x_test, y_train, y_test = train_test_split(X, Y, test_size = 0.3, stratify=Y)</strong></span></pre><p id="3cbc" class="pw-post-body-paragraph mo mp it lc b ld mq ju mr lf ms jx mt lh mu mv mw lj mx my mz ll na nb nc ln im bi translated">现在让我们通过将测试集分成两半来定义验证集…</p><pre class="lz ma mb mc gt nv nw nx ny aw nz bi"><span id="37ef" class="oa kj it nw b gy ob oc l od oe"><strong class="nw iu">X = x_test</strong></span><span id="d1b4" class="oa kj it nw b gy of oc l od oe"><strong class="nw iu">Y = y_test</strong></span><span id="7b36" class="oa kj it nw b gy of oc l od oe"><strong class="nw iu">x_val, x_test, y_val, y_test = train_test_split(X, Y, test_size = 0.5, stratify=Y)</strong></span></pre><p id="73a9" class="pw-post-body-paragraph mo mp it lc b ld mq ju mr lf ms jx mt lh mu mv mw lj mx my mz ll na nb nc ln im bi translated">因此，我们有一个包含70%<em class="nd">数据的训练集，以及各包含15%<em class="nd">数据的验证和测试集。总计= <em class="nd"> 100%。</em></em></em></p><p id="b5ae" class="pw-post-body-paragraph mo mp it lc b ld mq ju mr lf ms jx mt lh mu mv mw lj mx my mz ll na nb nc ln im bi translated">让我们看看我们分叉的形状…</p><pre class="lz ma mb mc gt nv nw nx ny aw nz bi"><span id="d6b9" class="oa kj it nw b gy ob oc l od oe"><strong class="nw iu">print('x_train shape is:', x_train.shape)<br/>print('y_train shape is:', y_train.shape)<br/>print('x_val shape is:', x_val.shape)<br/>print('y_val shape is:', y_val.shape)<br/>print('x_test shape is:', x_test.shape)<br/>print('y_test shape is:', y_test.shape)</strong></span><span id="4a58" class="oa kj it nw b gy of oc l od oe">&gt;&gt;</span><span id="485d" class="oa kj it nw b gy of oc l od oe"><em class="nd">x_train shape is: (4907, 50) <br/>y_train shape is: (4907,) <br/>x_val shape is: (1051, 50) <br/>y_val shape is: (1051,) <br/>x_test shape is: (1052, 50) <br/>y_test shape is: (1052,)</em></span></pre><p id="23b2" class="pw-post-body-paragraph mo mp it lc b ld mq ju mr lf ms jx mt lh mu mv mw lj mx my mz ll na nb nc ln im bi translated">所有统一的形状和正确的尺寸…让我们开始建模。</p><h1 id="97e9" class="ki kj it bd kk kl km kn ko kp kq kr ks jz kt ka ku kc kv kd kw kf kx kg ky kz bi translated">第4部分:建模和评估</h1><p id="aba5" class="pw-post-body-paragraph mo mp it lc b ld le ju mr lf lg jx mt lh ov mv mw lj ow my mz ll ox nb nc ln im bi translated">模型和超参数优化的选择与现有<strong class="lc iu"> <em class="nd">现金</em> </strong>工具<em class="nd">(组合算法选择和超参数优化)</em>的参数一样多种多样。</p><blockquote class="ne"><p id="9904" class="nf ng it bd nh ni nj nk nl nm nn ln dk translated">一些常见的现金工具包括GridSearchCV、RandomizedSearchCV、auto-sklearn(SMAC:基于序列模型的算法配置)、Hyperopt、TPOT和LALE</p></blockquote><figure class="pe pf pg ph pi md gh gi paragraph-image"><div role="button" tabindex="0" class="me mf di mg bf mh"><div class="gh gi pl"><img src="../Images/1f08ca2d7649c2dcc2c0f9416394a37a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*qLz70QQT1J74oqkLbBq2Gw.jpeg"/></div></div></figure><p id="d5d4" class="pw-post-body-paragraph mo mp it lc b ld mq ju mr lf ms jx mt lh mu mv mw lj mx my mz ll na nb nc ln im bi translated">这里，我们将使用四个分类模型的选择，并使用<em class="nd"> GridSearchCV </em>调整超参数。然后我们将选择最好的模型。</p><p id="8ea8" class="pw-post-body-paragraph mo mp it lc b ld mq ju mr lf ms jx mt lh mu mv mw lj mx my mz ll na nb nc ln im bi translated">首先，让我们为每个模型定义一个绘制混淆矩阵的方法。</p><figure class="lz ma mb mc gt md"><div class="bz fp l di"><div class="pm pn l"/></div></figure><blockquote class="oh oi oj"><p id="744d" class="mo mp nd lc b ld mq ju mr lf ms jx mt ok mu mv mw ol mx my mz om na nb nc ln im bi translated">混淆矩阵提供了一套用于评估分类模型的度量标准。看到一个<a class="ae ls" href="https://medium.com/towards-artificial-intelligence/the-confusion-matrix-for-classification-eb3bcf3064c7?source=---------7------------------" rel="noopener"> <strong class="lc iu">链接</strong> </a>到我的关于困惑矩阵的文章。</p></blockquote><h2 id="2f94" class="oa kj it bd kk po pp dn ko pq pr dp ks lh ps pt ku lj pu pv kw ll pw px ky py bi translated">4a。k最近邻分类器(KNN):</h2><p id="040d" class="pw-post-body-paragraph mo mp it lc b ld le ju mr lf lg jx mt lh ov mv mw lj ow my mz ll ox nb nc ln im bi translated">KNN相对来说比较容易理解…</p><figure class="lz ma mb mc gt md gh gi paragraph-image"><div class="gh gi nt"><img src="../Images/f780c63b86de0674e91cdb41ddf54256.png" data-original-src="https://miro.medium.com/v2/resize:fit:1320/format:webp/1*J68HrpOnCRS4UM4s7Sa1ag.jpeg"/></div><figcaption class="mk ml gj gh gi mm mn bd b be z dk translated"><strong class="bd kk">红星分类为k = 3的紫色，k = 6的黄色。</strong></figcaption></figure><p id="327a" class="pw-post-body-paragraph mo mp it lc b ld mq ju mr lf ms jx mt lh mu mv mw lj mx my mz ll na nb nc ln im bi translated">给定一个正整数<strong class="lc iu"> <em class="nd"> K </em> </strong>和一个测试观测值<strong class="lc iu"><em class="nd">x0</em></strong><strong class="lc iu">KNN</strong>分类器首先识别训练数据中最接近<strong class="lc iu"> <em class="nd"> x0 </em> </strong>的<em class="nd"> K </em> 点，用<strong class="lc iu"> <em class="nd"> N0 </em> </strong>表示。然后，它将类别<strong class="lc iu"> <em class="nd"> j </em> </strong>的条件概率估计为<strong class="lc iu"> <em class="nd"> N0 </em> </strong>中响应值等于<strong class="lc iu"> <em class="nd"> j </em> </strong>的点的分数:</p><p id="4306" class="pw-post-body-paragraph mo mp it lc b ld mq ju mr lf ms jx mt lh mu mv mw lj mx my mz ll na nb nc ln im bi translated"><strong class="lc iu"> <em class="nd"> Pr(Y = j|X = x0) </em> </strong></p><p id="c750" class="pw-post-body-paragraph mo mp it lc b ld mq ju mr lf ms jx mt lh mu mv mw lj mx my mz ll na nb nc ln im bi translated">最后，<strong class="lc iu"> KNN </strong>应用贝叶斯法则，将观测值<strong class="lc iu"> <em class="nd"> x0 </em> </strong>归入概率最大的类别。所以在<strong class="lc iu"> KNN </strong>中真正的挑战是为模型估计正确的<strong class="lc iu"> <em class="nd"> K </em> </strong>。</p><p id="5f23" class="pw-post-body-paragraph mo mp it lc b ld mq ju mr lf ms jx mt lh mu mv mw lj mx my mz ll na nb nc ln im bi translated">因此，让我们定义一个<strong class="lc iu"> KNN </strong>方法，它接受训练集和验证集并返回最佳模型。我们使用<em class="nd"> GridSearchCV </em>为我们的模型选择最佳的<strong class="lc iu"> <em class="nd"> K </em> </strong>和超参数。</p><figure class="lz ma mb mc gt md"><div class="bz fp l di"><div class="pm pn l"/></div></figure><p id="f5c5" class="pw-post-body-paragraph mo mp it lc b ld mq ju mr lf ms jx mt lh mu mv mw lj mx my mz ll na nb nc ln im bi translated">来看看它的性能和混淆矩阵。</p><pre class="lz ma mb mc gt nv nw nx ny aw nz bi"><span id="7e6e" class="oa kj it nw b gy ob oc l od oe"><strong class="nw iu">KNN_Model = knn_classifier(x_train, y_train, x_val, y_val)<br/>KNN_Model<br/></strong>&gt;&gt;<strong class="nw iu"><br/></strong><em class="nd">Best leaf_size: 1 <br/>Best p: 2 <br/>Best n_neighbors: 1 </em><br/><strong class="nw iu">{‘AUC’: 1.0, ‘F1_Score’: 1.0, ‘Log_loss’: 0.0}</strong></span></pre><figure class="lz ma mb mc gt md gh gi paragraph-image"><div class="gh gi nt"><img src="../Images/605464c62c68b6447b2f708a06882b0d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1320/format:webp/1*N2GDZL_KpjmI2qpsGTaJPg.jpeg"/></div><figcaption class="mk ml gj gh gi mm mn bd b be z dk translated"><strong class="bd kk"> {'AUC': 1.0，' F1_Score': 1.0，' Log_loss': 0.0} </strong></figcaption></figure><p id="fb65" class="pw-post-body-paragraph mo mp it lc b ld mq ju mr lf ms jx mt lh mu mv mw lj mx my mz ll na nb nc ln im bi translated"><strong class="lc iu"> KNN </strong>分类器在验证数据集上表现出色。在<em class="nd"> AUC </em>和<em class="nd"> F1 </em>分数为100%的情况下。</p><h2 id="3e48" class="oa kj it bd kk po pp dn ko pq pr dp ks lh ps pt ku lj pu pv kw ll pw px ky py bi translated">4b。逻辑回归分类器(LR):</h2><p id="e19c" class="pw-post-body-paragraph mo mp it lc b ld le ju mr lf lg jx mt lh ov mv mw lj ow my mz ll ox nb nc ln im bi translated">一个<strong class="lc iu"> LR </strong>模型只是<em class="nd">线性回归</em>模型的延伸。</p><figure class="lz ma mb mc gt md gh gi paragraph-image"><div class="gh gi nu"><img src="../Images/618c26b245ec64c4320c3e3779948107.png" data-original-src="https://miro.medium.com/v2/resize:fit:1240/format:webp/1*rGYzXEIvp_onO0_JnwNyuQ.jpeg"/></div></figure><p id="cd66" class="pw-post-body-paragraph mo mp it lc b ld mq ju mr lf ms jx mt lh mu mv mw lj mx my mz ll na nb nc ln im bi translated">事实上，一个<strong class="lc iu"> LR </strong>模型是一个<em class="nd">线性回归</em>模型，它配备了一个<em class="nd"> Sigmoid </em>激活函数。我这里有一篇关于非线性回归的文章<a class="ae ls" href="https://medium.com/towards-artificial-intelligence/understanding-non-linear-regression-fbef9a396b71" rel="noopener"><strong class="lc iu"><em class="nd"/></strong></a><em class="nd">。</em></p><pre class="lz ma mb mc gt nv nw nx ny aw nz bi"><span id="548f" class="oa kj it nw b gy ob oc l od oe"># Let's define a linear regression model<br/><strong class="nw iu"><em class="nd">y_hat = b0 + b1x1 + b2x2 + b3x3 + … bnxn</em></strong></span><span id="92c4" class="oa kj it nw b gy of oc l od oe"># let's extend y_hat to a logistic regression model<br/><strong class="nw iu"><em class="nd">log_reg = sigmoid(y_hat)<br/>log_reg = 1/1 + e^ -(y_hat)</em></strong></span></pre><p id="7165" class="pw-post-body-paragraph mo mp it lc b ld mq ju mr lf ms jx mt lh mu mv mw lj mx my mz ll na nb nc ln im bi translated">因此，我们再一次定义了一个<strong class="lc iu"> LR </strong>方法，它接受训练和验证数据集并返回最佳模型。我们创建超参数，如<em class="nd">惩罚</em>、<em class="nd">最大迭代</em>、<em class="nd">参数网格</em>。然后，我们将这些数据传递给<em class="nd"> GridSearchCV </em>，为我们的模型找到理想的参数。</p><figure class="lz ma mb mc gt md"><div class="bz fp l di"><div class="pm pn l"/></div></figure><p id="1b8d" class="pw-post-body-paragraph mo mp it lc b ld mq ju mr lf ms jx mt lh mu mv mw lj mx my mz ll na nb nc ln im bi translated">来看看它的性能和混淆矩阵。</p><pre class="lz ma mb mc gt nv nw nx ny aw nz bi"><span id="8910" class="oa kj it nw b gy ob oc l od oe"><strong class="nw iu">Log_Reg_Model = log_reg_classifier(x_train, y_train, x_val, y_val)<br/>Log_Reg_Model<br/></strong>&gt;&gt;<br/><strong class="nw iu">{'AUC': 0.7554861488321565, 'F1_Score': 0.7554, 'Log_loss': 8.4458}</strong></span></pre><figure class="lz ma mb mc gt md gh gi paragraph-image"><div class="gh gi nu"><img src="../Images/e01108c2b67368d7e8b7883b309109ac.png" data-original-src="https://miro.medium.com/v2/resize:fit:1240/format:webp/1*s2oN7u3HiHAg_ukpGlNLRA.jpeg"/></div><figcaption class="mk ml gj gh gi mm mn bd b be z dk translated"><strong class="bd kk"> {'AUC': 0.7554861488321565，' F1_Score': 0.7554，' Log_loss': 8.4458} </strong></figcaption></figure><p id="f0e4" class="pw-post-body-paragraph mo mp it lc b ld mq ju mr lf ms jx mt lh mu mv mw lj mx my mz ll na nb nc ln im bi translated"><strong class="lc iu"> Log_Reg </strong>模型不够灵活，无法学习数据属性，并且在<em class="nd"> AUC </em>和<em class="nd"> F1 </em>指标中均以76%的阈值执行。</p><h2 id="2820" class="oa kj it bd kk po pp dn ko pq pr dp ks lh ps pt ku lj pu pv kw ll pw px ky py bi translated">4c。支持向量机(SVM):</h2><p id="ef4d" class="pw-post-body-paragraph mo mp it lc b ld le ju mr lf lg jx mt lh ov mv mw lj ow my mz ll ox nb nc ln im bi translated">SVM的工作原理是将数据映射到一个高维特征空间，这样数据点就可以被分类。</p><figure class="lz ma mb mc gt md gh gi paragraph-image"><div class="gh gi nu"><img src="../Images/b5b0773690e858a65514d5b57672ac0b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1240/format:webp/1*atiChAKMztTEvJEY0wOkYA.jpeg"/></div></figure><p id="10f0" class="pw-post-body-paragraph mo mp it lc b ld mq ju mr lf ms jx mt lh mu mv mw lj mx my mz ll na nb nc ln im bi translated">即使数据不是线性可分的，也可以找到类别之间的分隔符。然后对数据进行转换，使得分隔符可以绘制为超平面。因此，新数据的特征可以用来预测新记录应该属于哪个组。</p><p id="cce8" class="pw-post-body-paragraph mo mp it lc b ld mq ju mr lf ms jx mt lh mu mv mw lj mx my mz ll na nb nc ln im bi translated">支持向量机支持大约四种核类型:- <em class="nd"> ['RBF '，' sigmoid '，' Linear '，' Poly'] </em>。因此，我们将定义一个<strong class="lc iu"> SVM </strong>方法，并将<em class="nd">内核列表</em>和<em class="nd"> param_grid </em>作为超参数传递给<em class="nd"> GridSearchCV </em>。我们会让它施展魔法，返回模型的最佳参数。</p><figure class="lz ma mb mc gt md"><div class="bz fp l di"><div class="pm pn l"/></div></figure><p id="f770" class="pw-post-body-paragraph mo mp it lc b ld mq ju mr lf ms jx mt lh mu mv mw lj mx my mz ll na nb nc ln im bi translated">让我们看看它的表现</p><pre class="lz ma mb mc gt nv nw nx ny aw nz bi"><span id="2138" class="oa kj it nw b gy ob oc l od oe"><strong class="nw iu">SVM_Model = svm_classifier(x_train, y_train, x_val, y_val)<br/>SVM_Model</strong><br/>&gt;&gt;<br/><strong class="nw iu">{'Kernel': 'poly', 'AUC': 1.0, 'F1_Score': 1.0, 'Log_Loss': 0.0}</strong></span></pre><figure class="lz ma mb mc gt md gh gi paragraph-image"><div class="gh gi nu"><img src="../Images/dd86dcba41a32f914966c70b7627bcbb.png" data-original-src="https://miro.medium.com/v2/resize:fit:1240/format:webp/1*lt23cI7CdxniP6axua5LVg.jpeg"/></div><figcaption class="mk ml gj gh gi mm mn bd b be z dk translated"><strong class="bd kk"> {'Kernel': 'poly '，' AUC': 1.0，' F1_Score': 1.0，' Log_Loss': 0.0} </strong></figcaption></figure><p id="5274" class="pw-post-body-paragraph mo mp it lc b ld mq ju mr lf ms jx mt lh mu mv mw lj mx my mz ll na nb nc ln im bi translated">所以我们在SVM 有了另一个完美的表现，100%。让我们试试决策树模型。</p><h2 id="447f" class="oa kj it bd kk po pp dn ko pq pr dp ks lh ps pt ku lj pu pv kw ll pw px ky py bi translated">4d。决策树分类器(DTree):</h2><p id="29ea" class="pw-post-body-paragraph mo mp it lc b ld le ju mr lf lg jx mt lh ov mv mw lj ow my mz ll ox nb nc ln im bi translated">一般来说，<strong class="lc iu"> DTrees </strong>由三个基本部分组成:-一个根节点、几个隐藏节点和许多终端节点(称为叶子)。</p><p id="3fca" class="pw-post-body-paragraph mo mp it lc b ld mq ju mr lf ms jx mt lh mu mv mw lj mx my mz ll na nb nc ln im bi translated">它们是非参数算法。也就是说，他们不会对特征和相应目标之间的关系<strong class="lc iu"><em class="nd">【f(x)】</em></strong>的形状做出假设。相反，他们寻求尽可能接近数据点而不会太粗糙或波动的估计值<strong class="lc iu"> <em class="nd"> f(x) </em> </strong>。</p><figure class="lz ma mb mc gt md gh gi paragraph-image"><div class="gh gi nt"><img src="../Images/efb049aa35a23ee6d48707038f958b87.png" data-original-src="https://miro.medium.com/v2/resize:fit:1320/format:webp/1*VsIdcD_DKevboyKW_qBt7Q.jpeg"/></div><figcaption class="mk ml gj gh gi mm mn bd b be z dk translated">决策树结构…</figcaption></figure><p id="a53e" class="pw-post-body-paragraph mo mp it lc b ld mq ju mr lf ms jx mt lh mu mv mw lj mx my mz ll na nb nc ln im bi translated">使用<strong class="lc iu">dtree</strong>，我们简单地估计叶子的最大深度，并在该范围内迭代以找到我们的理想参数。不需要<em class="nd"> GridSearchCV </em>。</p><figure class="lz ma mb mc gt md"><div class="bz fp l di"><div class="pm pn l"/></div></figure><p id="5044" class="pw-post-body-paragraph mo mp it lc b ld mq ju mr lf ms jx mt lh mu mv mw lj mx my mz ll na nb nc ln im bi translated">让我们看表演吧…</p><pre class="lz ma mb mc gt nv nw nx ny aw nz bi"><span id="7d6b" class="oa kj it nw b gy ob oc l od oe"><strong class="nw iu">Decision_Tree_Model = decision_tree_classifier(max_depth, x_train, y_train, x_val, y_val)</strong></span><span id="f2b0" class="oa kj it nw b gy of oc l od oe"><strong class="nw iu">Decision_Tree_Model</strong><br/>&gt;&gt;<strong class="nw iu"><br/>{'Max_Depth': 27, 'AUC': 0.997148288973384, 'F1_Score': 0.9971, 'Log_Loss': 0.0986}</strong></span></pre><figure class="lz ma mb mc gt md gh gi paragraph-image"><div class="gh gi nu"><img src="../Images/a3157be0b57ceb527928500bcc902804.png" data-original-src="https://miro.medium.com/v2/resize:fit:1240/format:webp/1*3l7HfpNqE4FuiVbGJZr8kA.jpeg"/></div><figcaption class="mk ml gj gh gi mm mn bd b be z dk translated"><strong class="bd kk"> {'Max_Depth': 27，' AUC': 0.997148288973384，' F1_Score': 0.9971，' Log_Loss': 0.0986} </strong></figcaption></figure><p id="b20c" class="pw-post-body-paragraph mo mp it lc b ld mq ju mr lf ms jx mt lh mu mv mw lj mx my mz ll na nb nc ln im bi translated">在我们关心的指标上，<strong class="lc iu">dtree</strong>获得了99%的分数，是一股不可忽视的力量。所以我们有四分之三的模型在验证集上表现很好。</p><p id="233c" class="pw-post-body-paragraph mo mp it lc b ld mq ju mr lf ms jx mt lh mu mv mw lj mx my mz ll na nb nc ln im bi translated">让我们在测试设备上试试我们的模型。这一次，我们定义了一种方法，它获取测试集并返回一个数据帧，显示各个分类模型各自的分数。</p><p id="7310" class="pw-post-body-paragraph mo mp it lc b ld mq ju mr lf ms jx mt lh mu mv mw lj mx my mz ll na nb nc ln im bi translated">让我们调用best_model方法。</p><pre class="lz ma mb mc gt nv nw nx ny aw nz bi"><span id="54fc" class="oa kj it nw b gy ob oc l od oe"><strong class="nw iu">test_evaluation_dict = best_model(x_test , y_test)<br/>test_evaluation_dict<br/>&gt;&gt;</strong></span></pre><figure class="lz ma mb mc gt md gh gi paragraph-image"><div class="gh gi pz"><img src="../Images/eed30005c35fd0138a7332e06cdb51b7.png" data-original-src="https://miro.medium.com/v2/resize:fit:1278/format:webp/1*fJ_niEBraYXTYVqdf4-aAQ.jpeg"/></div><figcaption class="mk ml gj gh gi mm mn bd b be z dk translated"><strong class="bd kk">很明显，KNN和SVM名列前茅，两者非常接近……</strong></figcaption></figure><p id="2270" class="pw-post-body-paragraph mo mp it lc b ld mq ju mr lf ms jx mt lh mu mv mw lj mx my mz ll na nb nc ln im bi translated">测试集上的性能也令人印象深刻。这可能意味着我们的模型在训练集和验证集上没有过度拟合。这也可能意味着我们需要更多的数据…但是我们仍然需要为这个练习选择一个。</p><blockquote class="ne"><p id="24e2" class="nf ng it bd nh ni nj nk nl nm nn ln dk translated">那么模型的选择应该考虑哪些因素呢？我们应该考虑哪些价值观？</p></blockquote><h1 id="601c" class="ki kj it bd kk kl km kn ko kp kq kr ks jz qa ka ku kc qb kd kw kf qc kg ky kz bi translated">第五部分:结论</h1><figure class="lz ma mb mc gt md gh gi paragraph-image"><div class="gh gi nu"><img src="../Images/d8cb6925ccd0b7ed064bd3b8cb347fb5.png" data-original-src="https://miro.medium.com/v2/resize:fit:1240/format:webp/1*uhiBkOL8_3APaLXjNBR3zw.jpeg"/></div><figcaption class="mk ml gj gh gi mm mn bd b be z dk translated">IMG| <a class="ae ls" href="https://pixabay.com/users/Peggy_Marco-1553824/?utm_source=link-attribution&amp;utm_medium=referral&amp;utm_campaign=image&amp;utm_content=1020145" rel="noopener ugc nofollow" target="_blank"> Crdt </a></figcaption></figure><p id="2873" class="pw-post-body-paragraph mo mp it lc b ld mq ju mr lf ms jx mt lh mu mv mw lj mx my mz ll na nb nc ln im bi translated">机器学习没有一刀切的解决方案，没有<em class="nd">一刀切的</em>算法。模型选择和优化是一个迭代过程，需要数据科学家的经验。</p><blockquote class="oh oi oj"><p id="def9" class="mo mp nd lc b ld mq ju mr lf ms jx mt ok mu mv mw ol mx my mz om na nb nc ln im bi translated">即使我们使用<em class="it">现金工具，某些决定还是取决于我们……</em></p></blockquote><p id="77aa" class="pw-post-body-paragraph mo mp it lc b ld mq ju mr lf ms jx mt lh mu mv mw lj mx my mz ll na nb nc ln im bi translated">也就是说，让我们比较一下我们的两个顶级算法。它们的属性是什么？</p><h2 id="9567" class="oa kj it bd kk po pp dn ko pq pr dp ks lh ps pt ku lj pu pv kw ll pw px ky py bi translated">5a。KNN对SVM:</h2><p id="add7" class="pw-post-body-paragraph mo mp it lc b ld le ju mr lf lg jx mt lh ov mv mw lj ow my mz ll ox nb nc ln im bi translated"><strong class="lc iu"> KNNs </strong>非常容易理解和实现，我们基本上只需要调整两个参数，即<strong class="lc iu"> <em class="nd"> k、</em> </strong>和<strong class="lc iu"> <em class="nd">距离</em> </strong>参数。此外，它们训练速度快，是推理的理想选择。</p><p id="f377" class="pw-post-body-paragraph mo mp it lc b ld mq ju mr lf ms jx mt lh mu mv mw lj mx my mz ll na nb nc ln im bi translated">另一方面，<strong class="lc iu"> KNNs </strong>不能很好地处理大型数据集。随着维度和观察值的增加，训练变得更加困难。它们不能抵抗异常值，并且对噪声和缺失值很敏感。</p><p id="a0bd" class="pw-post-body-paragraph mo mp it lc b ld mq ju mr lf ms jx mt lh mu mv mw lj mx my mz ll na nb nc ln im bi translated">支持向量机对离群值有抵抗力，这意味着即使数据集中有离群值，我们也能得到一个清晰的边界。SVM的优化目标是凸的。这很好，因为我们保证通过优化成本函数，我们将总是以全局最小值结束。支持向量机是稳定的，它们具有L2正则化，并且通过使用核，支持向量机可以有效地执行分类任务。</p><p id="d70b" class="pw-post-body-paragraph mo mp it lc b ld mq ju mr lf ms jx mt lh mu mv mw lj mx my mz ll na nb nc ln im bi translated">另一方面，<strong class="lc iu">支持向量机</strong>是默认的二元线性分类器，这意味着多类分类是不可能的，除非我们使用一对一的方法。它们在训练中需要大量的记忆，随着训练集的增加，情况会变得更糟。最后，它们是复杂、灵活的算法，很难解释为推理，但对预测来说很棒。</p><h2 id="30c4" class="oa kj it bd kk po pp dn ko pq pr dp ks lh ps pt ku lj pu pv kw ll pw px ky py bi translated">5b。排列重要性(PI):</h2><blockquote class="ne"><p id="410c" class="nf ng it bd nh ni nj nk nl nm nn ln dk translated">那么，每个模型的预测中最重要的特征是什么？</p></blockquote><p id="562e" class="pw-post-body-paragraph mo mp it lc b ld no ju mr lf np jx mt lh nq mv mw lj nr my mz ll ns nb nc ln im bi translated">让我们应用排列重要性指标来看看对每个模型的决策影响最大的特性。</p><figure class="lz ma mb mc gt md"><div class="bz fp l di"><div class="pm pn l"/></div></figure><p id="ef0e" class="pw-post-body-paragraph mo mp it lc b ld mq ju mr lf ms jx mt lh mu mv mw lj mx my mz ll na nb nc ln im bi translated">现在，我们可以看到每个型号的主要决定性特征…</p><figure class="lz ma mb mc gt md gh gi paragraph-image"><div class="gh gi qd"><img src="../Images/cc5cbab8984893ce35e0d126e038ed3d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1266/format:webp/1*1ibVIh_HEB7_MN7OGWfu3w.jpeg"/></div><figcaption class="mk ml gj gh gi mm mn bd b be z dk translated"><strong class="bd kk">以降序显示KNN模式决策的排列重要性。</strong></figcaption></figure><figure class="lz ma mb mc gt md gh gi paragraph-image"><div class="gh gi qe"><img src="../Images/5b78ac69121b6d9d1fabc5aa07712421.png" data-original-src="https://miro.medium.com/v2/resize:fit:1274/format:webp/1*RxL4kZ7iaSX1lyMCoXvyHg.jpeg"/></div><figcaption class="mk ml gj gh gi mm mn bd b be z dk translated"><strong class="bd kk">以降序显示SVM模型决策的排列重要性。</strong></figcaption></figure><h1 id="4cea" class="ki kj it bd kk kl km kn ko kp kq kr ks jz kt ka ku kc kv kd kw kf kx kg ky kz bi translated">最后…</h1><p id="8e1f" class="pw-post-body-paragraph mo mp it lc b ld le ju mr lf lg jx mt lh ov mv mw lj ow my mz ll ox nb nc ln im bi translated">我选择<strong class="lc iu"> SVM </strong>型号是基于它的'<strong class="lc iu"> PI </strong>分数和内在品质。最后一步是用整个训练、验证和测试集来重新训练所选择的模型。</p><p id="6060" class="pw-post-body-paragraph mo mp it lc b ld mq ju mr lf ms jx mt lh mu mv mw lj mx my mz ll na nb nc ln im bi translated">同样，我们可以通过应用可解释库，如<a class="ae ls" href="https://aix360.mybluemix.net/resources#overview" rel="noopener ugc nofollow" target="_blank"><strong class="lc iu"><em class="nd">AIX 360</em></strong><em class="nd"/>和<strong class="lc iu"> <em class="nd"> LIME </em> </strong> </a>来了解每个模型的预测</p><p id="d965" class="pw-post-body-paragraph mo mp it lc b ld mq ju mr lf ms jx mt lh mu mv mw lj mx my mz ll na nb nc ln im bi translated">这些练习简单地训练模型，根据信用历史将客户分类为<strong class="lc iu"> <em class="nd">违约者</em> </strong>或<strong class="lc iu"> <em class="nd">非违约者</em> </strong>。这些模型绝不是完美的，相关当局应该采取必要的激励措施来抑制信贷支付违约。</p><p id="40fb" class="pw-post-body-paragraph mo mp it lc b ld mq ju mr lf ms jx mt lh mu mv mw lj mx my mz ll na nb nc ln im bi translated"><strong class="lc iu">干杯，感谢！！</strong></p><h2 id="75a0" class="oa kj it bd kk po pp dn ko pq pr dp ks lh ps pt ku lj pu pv kw ll pw px ky py bi translated">关于我:</h2><p id="2a6d" class="pw-post-body-paragraph mo mp it lc b ld le ju mr lf lg jx mt lh ov mv mw lj ow my mz ll ox nb nc ln im bi translated">劳伦斯是技术层的数据专家，对公平和可解释的人工智能和数据科学充满热情。我持有IBM的 <strong class="lc iu"> <em class="nd">数据科学专业</em> </strong> <em class="nd">和</em> <strong class="lc iu"> <em class="nd">高级数据科学专业</em> </strong> <em class="nd">证书。我已经使用ML和DL库进行了几个项目，我喜欢尽可能多地编写函数代码，即使现有的库比比皆是。最后，我从未停止学习和实验，是的，我拥有几个数据科学和人工智能认证，并且我已经写了几篇强烈推荐的文章。</em></p><p id="2aed" class="pw-post-body-paragraph mo mp it lc b ld mq ju mr lf ms jx mt lh mu mv mw lj mx my mz ll na nb nc ln im bi translated">请随时在以下网址找到我</p><p id="31dd" class="pw-post-body-paragraph mo mp it lc b ld mq ju mr lf ms jx mt lh mu mv mw lj mx my mz ll na nb nc ln im bi translated"><a class="ae ls" href="https://github.com/Lawrence-Krukrubo" rel="noopener ugc nofollow" target="_blank">T37】GithubT39】</a></p><p id="f239" class="pw-post-body-paragraph mo mp it lc b ld mq ju mr lf ms jx mt lh mu mv mw lj mx my mz ll na nb nc ln im bi translated"><a class="ae ls" href="https://www.linkedin.com/in/lawrencekrukrubo/" rel="noopener ugc nofollow" target="_blank"> <strong class="lc iu">领英</strong> </a></p><p id="4257" class="pw-post-body-paragraph mo mp it lc b ld mq ju mr lf ms jx mt lh mu mv mw lj mx my mz ll na nb nc ln im bi translated"><a class="ae ls" href="https://twitter.com/LKrukrubo" rel="noopener ugc nofollow" target="_blank"> <strong class="lc iu">推特</strong> </a></p></div></div>    
</body>
</html>