<html>
<head>
<title>Image De-noising Using Deep Learning</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">基于深度学习的图像去噪</h1>
<blockquote>原文：<a href="https://pub.towardsai.net/image-de-noising-using-deep-learning-1a8334c81f06?source=collection_archive---------0-----------------------#2021-01-23">https://pub.towardsai.net/image-de-noising-using-deep-learning-1a8334c81f06?source=collection_archive---------0-----------------------#2021-01-23</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><h2 id="fd84" class="io ip iq bd b dl ir is it iu iv iw dk ix translated" aria-label="kicker paragraph"><a class="ae ep" href="https://towardsai.net/p/category/computer-vision" rel="noopener ugc nofollow" target="_blank">计算机视觉</a>，<a class="ae ep" href="https://towardsai.net/p/category/machine-learning/deep-learning" rel="noopener ugc nofollow" target="_blank">深度学习</a></h2><div class=""/><figure class="gl gn jx jy jz ka gh gi paragraph-image"><div role="button" tabindex="0" class="kb kc di kd bf ke"><div class="gh gi jw"><img src="../Images/e67e0c005cb1ce7bdf3f64498e872e65.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*XAwZScq8u92_r6Dj"/></div></div><figcaption class="kh ki gj gh gi kj kk bd b be z dk translated">照片由<a class="ae kl" href="https://unsplash.com/@impatrickt?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">帕特里克·托马索</a>在<a class="ae kl" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上拍摄</figcaption></figure><p id="c262" class="pw-post-body-paragraph km kn iq ko b kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj ij bi lk translated">去除图像噪声是一个经典问题，研究人员几十年来一直试图解决这个问题。在早期，研究人员使用<em class="lt">过滤器</em>来减少图像中的噪音。它们过去对于具有合理噪声水平的图像工作得相当好。但是，应用这些滤镜会使图像变得模糊。如果图像噪声太大，那么最终的图像会非常模糊，图像中的大部分关键细节都会丢失。</p><p id="10a9" class="pw-post-body-paragraph km kn iq ko b kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">一定有更好的方法来解决这个问题。因此，我实现了几个深度学习架构，远远超过了传统的去噪过滤器。在这篇博客中，我将把我的方法作为一个案例研究一步一步地解释，从问题公式化开始，到实现最先进的深度学习模型，然后最终看到结果。</p><h1 id="8119" class="lu lv iq bd lw lx ly lz ma mb mc md me mf mg mh mi mj mk ml mm mn mo mp mq mr bi translated">内容摘要</h1><ol class=""><li id="94f5" class="ms mt iq ko b kp mu kt mv kx mw lb mx lf my lj mz na nb nc bi translated">什么是图像中的噪声？</li><li id="823d" class="ms mt iq ko b kp nd kt ne kx nf lb ng lf nh lj mz na nb nc bi translated">问题定式化</li><li id="11b5" class="ms mt iq ko b kp nd kt ne kx nf lb ng lf nh lj mz na nb nc bi translated">机器学习问题公式</li><li id="409f" class="ms mt iq ko b kp nd kt ne kx nf lb ng lf nh lj mz na nb nc bi translated">数据来源</li><li id="ea5f" class="ms mt iq ko b kp nd kt ne kx nf lb ng lf nh lj mz na nb nc bi translated">探索性数据分析</li><li id="482a" class="ms mt iq ko b kp nd kt ne kx nf lb ng lf nh lj mz na nb nc bi translated">传统图像去噪滤波器综述</li><li id="019f" class="ms mt iq ko b kp nd kt ne kx nf lb ng lf nh lj mz na nb nc bi translated">图像去噪的深度学习模型</li><li id="5fa6" class="ms mt iq ko b kp nd kt ne kx nf lb ng lf nh lj mz na nb nc bi translated">结果比较</li><li id="f10a" class="ms mt iq ko b kp nd kt ne kx nf lb ng lf nh lj mz na nb nc bi translated">部署</li><li id="ac50" class="ms mt iq ko b kp nd kt ne kx nf lb ng lf nh lj mz na nb nc bi translated">未来工作和改进范围</li><li id="a121" class="ms mt iq ko b kp nd kt ne kx nf lb ng lf nh lj mz na nb nc bi translated">参考</li></ol><h1 id="829a" class="lu lv iq bd lw lx ly lz ma mb mc md me mf mg mh mi mj mk ml mm mn mo mp mq mr bi translated">1.什么是图像中的噪声？</h1><p id="1e08" class="pw-post-body-paragraph km kn iq ko b kp mu kr ks kt mv kv kw kx ni kz la lb nj ld le lf nk lh li lj ij bi translated">图像噪声是捕获的图像中亮度或颜色信息的随机变化。它是由外部源引起的图像信号的退化。数学上，图像中的噪声可以表示为:</p><blockquote class="nl nm nn"><p id="90a5" class="km kn lt ko b kp kq kr ks kt ku kv kw no ky kz la np lc ld le nq lg lh li lj ij bi translated"><strong class="ko ja"> <em class="iq"> A(x，y) = B(x，y) + H(x，y) </em> </strong></p></blockquote><p id="19b5" class="pw-post-body-paragraph km kn iq ko b kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">在哪里，</p><p id="c995" class="pw-post-body-paragraph km kn iq ko b kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">A(x，y)=噪声图像的函数；<br/> B(x，y)=原图像的函数；<br/> H(x，y)=噪声的函数；</p><p id="de4b" class="pw-post-body-paragraph km kn iq ko b kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">要了解更多关于噪音的知识，请查看这个博客。</p><h1 id="c30e" class="lu lv iq bd lw lx ly lz ma mb mc md me mf mg mh mi mj mk ml mm mn mo mp mq mr bi translated">2.问题定式化</h1><p id="05e0" class="pw-post-body-paragraph km kn iq ko b kp mu kr ks kt mv kv kw kx ni kz la lb nj ld le lf nk lh li lj ij bi translated">传统的图像去噪算法总是假设噪声是均匀高斯分布的。然而，实际上，真实图像上的噪声可能要复杂得多。这种真实图像上的噪声称为<strong class="ko ja"> <em class="lt">真实噪声</em> </strong>或<strong class="ko ja"> <em class="lt">盲噪声。传统的滤波器不能很好地处理有这种噪声的图像。</em></strong></p><p id="ac82" class="pw-post-body-paragraph km kn iq ko b kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">所以，问题的表述变成了，</p><blockquote class="nl nm nn"><p id="f1d7" class="km kn lt ko b kp kq kr ks kt ku kv kw no ky kz la np lc ld le nq lg lh li lj ij bi translated"><strong class="ko ja">如何对含有盲噪的图像去噪？</strong></p></blockquote><h2 id="ba36" class="nr lv iq bd lw ns nt dn ma nu nv dp me kx nw nx mi lb ny nz mm lf oa ob mq iw bi translated">目标和制约因素</h2><ul class=""><li id="53d7" class="ms mt iq ko b kp mu kt mv kx mw lb mx lf my lj oc na nb nc bi translated">目标是对含有盲噪声的彩色图像进行去噪</li><li id="eda9" class="ms mt iq ko b kp nd kt ne kx nf lb ng lf nh lj oc na nb nc bi translated">没有延迟限制，因为我想尽可能接近真实地去噪图像，即使这需要合理的时间</li></ul><p id="3126" class="pw-post-body-paragraph km kn iq ko b kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated"><em class="lt">盲去噪</em>这个术语指的是去噪时，去噪所用的基是从有噪样本本身学习来的。换句话说，无论我们构建什么样的深度学习架构，都应该固有地学习图像中的噪声分布，并对其进行降噪。所以和往常一样，这完全取决于我们提供给深度学习模型的数据类型。</p><h1 id="3760" class="lu lv iq bd lw lx ly lz ma mb mc md me mf mg mh mi mj mk ml mm mn mo mp mq mr bi translated">3.机器学习问题公式</h1><p id="8f6d" class="pw-post-body-paragraph km kn iq ko b kp mu kr ks kt mv kv kw kx ni kz la lb nj ld le lf nk lh li lj ij bi translated">首先，让我们考虑一下RGB图像的格式。</p><figure class="oe of og oh gt ka gh gi paragraph-image"><div class="gh gi od"><img src="../Images/61812dc7503145ab5d3670992698fac1.png" data-original-src="https://miro.medium.com/v2/resize:fit:1074/format:webp/1*Cki4uuEq5miF0ReP3LhOvg.png"/></div><figcaption class="kh ki gj gh gi kj kk bd b be z dk translated">图像的3个颜色通道</figcaption></figure><p id="a4b5" class="pw-post-body-paragraph km kn iq ko b kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">任何RGB图像的每个像素都有三个颜色通道——红色、绿色和蓝色。</p><p id="0982" class="pw-post-body-paragraph km kn iq ko b kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">现在，每种颜色都由一个8位数字表示，范围从0到255。因此，任何图像都可以用三维矩阵来表示。</p><figure class="oe of og oh gt ka gh gi paragraph-image"><div class="gh gi oi"><img src="../Images/c343f62f8b2de6804df8a5186aa9c81a.png" data-original-src="https://miro.medium.com/v2/resize:fit:994/format:webp/1*EBGo6zbp3A0_rtDWsyuc4g.png"/></div><figcaption class="kh ki gj gh gi kj kk bd b be z dk translated">用8位数字填充的图像的3个颜色通道</figcaption></figure><p id="18dc" class="pw-post-body-paragraph km kn iq ko b kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">现在考虑噪声图像的相同情况。</p><figure class="oe of og oh gt ka gh gi paragraph-image"><div class="gh gi oj"><img src="../Images/c9dbda93f63da4b1e103830730653782.png" data-original-src="https://miro.medium.com/v2/resize:fit:582/format:webp/1*4KpbWoXXz_nPCoxgEtJuxQ.png"/></div><figcaption class="kh ki gj gh gi kj kk bd b be z dk translated">带有3个颜色通道的噪声图像</figcaption></figure><p id="086d" class="pw-post-body-paragraph km kn iq ko b kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">我们在前面的章节中看到，噪声是像素的随机变化。换句话说，图像中3个通道的一些像素数值已损坏。为了将图像恢复到其原始形式，我们需要校正那些损坏的像素值。</p><h2 id="9b84" class="nr lv iq bd lw ns nt dn ma nu nv dp me kx nw nx mi lb ny nz mm lf oa ob mq iw bi translated">机器学习问题的类型</h2><ul class=""><li id="24fa" class="ms mt iq ko b kp mu kt mv kx mw lb mx lf my lj oc na nb nc bi translated">我们可以将此视为一个<strong class="ko ja">监督学习回归问题</strong>，在这里我们预测被破坏像素的真实值【数量在0-255的范围内】。</li></ul><h2 id="01ff" class="nr lv iq bd lw ns nt dn ma nu nv dp me kx nw nx mi lb ny nz mm lf oa ob mq iw bi translated">损失函数和性能度量</h2><ul class=""><li id="905e" class="ms mt iq ko b kp mu kt mv kx mw lb mx lf my lj oc na nb nc bi translated">我将使用的损失是<a class="ae kl" href="https://en.wikipedia.org/wiki/Mean_squared_error" rel="noopener ugc nofollow" target="_blank"> <strong class="ko ja"> MSE </strong> </a> <strong class="ko ja"> </strong>(均方误差)。分数越低越好。</li></ul><figure class="oe of og oh gt ka gh gi paragraph-image"><div class="gh gi ok"><img src="../Images/5a492bac180ddfdd3fb91c56280fb7b9.png" data-original-src="https://miro.medium.com/v2/resize:fit:634/format:webp/1*Q8KtoA-oIyjnQrvRXM3cIw.png"/></div><figcaption class="kh ki gj gh gi kj kk bd b be z dk translated">MSE公式</figcaption></figure><ul class=""><li id="b851" class="ms mt iq ko b kp kq kt ku kx ol lb om lf on lj oc na nb nc bi translated">对于性能评估，我将使用两个指标，<br/><a class="ae kl" href="https://en.wikipedia.org/wiki/Peak_signal-to-noise_ratio" rel="noopener ugc nofollow" target="_blank"><strong class="ko ja">【PSNR】</strong></a><strong class="ko ja">(</strong>【峰值信噪比】<strong class="ko ja"><br/></strong><a class="ae kl" href="https://en.wikipedia.org/wiki/Structural_similarity" rel="noopener ugc nofollow" target="_blank"><strong class="ko ja">【SSIM】</strong></a><strong class="ko ja"/>【结构相似性指数度量】<br/>对于两者，分数越高越好。</li></ul><h1 id="f28d" class="lu lv iq bd lw lx ly lz ma mb mc md me mf mg mh mi mj mk ml mm mn mo mp mq mr bi translated">4.数据来源</h1><p id="162c" class="pw-post-body-paragraph km kn iq ko b kp mu kr ks kt mv kv kw kx ni kz la lb nj ld le lf nk lh li lj ij bi translated">由于这是一个监督学习问题，我们需要一对噪声图像(<em class="lt"> x </em>)和地面真实图像(<em class="lt"> y </em>)。</p><p id="ef00" class="pw-post-body-paragraph km kn iq ko b kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">我从三个来源收集了数据。</p><ol class=""><li id="8f0b" class="ms mt iq ko b kp kq kt ku kx ol lb om lf on lj mz na nb nc bi translated"><a class="ae kl" href="https://www.eecs.yorku.ca/~kamel/sidd/dataset.php" rel="noopener ugc nofollow" target="_blank">SIDD</a>——包含来自智能手机摄像头的160对【嘈杂背景真相】图像</li><li id="fec9" class="ms mt iq ko b kp nd kt ne kx nf lb ng lf nh lj mz na nb nc bi translated">雷诺阿(RENOIR)——包含80对来自智能手机摄像头的[嘈杂——真实]图像</li><li id="2195" class="ms mt iq ko b kp nd kt ne kx nf lb ng lf nh lj mz na nb nc bi translated"><a class="ae kl" href="https://commons.wikimedia.org/wiki/Natural_Image_Noise_Dataset#Tools" rel="noopener ugc nofollow" target="_blank">NIND</a>——包含62对来自富士X-T1 DSLR相机的【嘈杂——地面真相】图像</li></ol><h1 id="c3bc" class="lu lv iq bd lw lx ly lz ma mb mc md me mf mg mh mi mj mk ml mm mn mo mp mq mr bi translated">5.探索性数据分析</h1><h2 id="edf7" class="nr lv iq bd lw ns nt dn ma nu nv dp me kx nw nx mi lb ny nz mm lf oa ob mq iw bi translated">元数据的分析</h2><figure class="oe of og oh gt ka gh gi paragraph-image"><div class="gh gi oo"><img src="../Images/7a2da60cc0e72ff57a23741ed2266cdc.png" data-original-src="https://miro.medium.com/v2/resize:fit:1266/format:webp/1*n9-c8rIS7oD6UekNJu7wCw.png"/></div><figcaption class="kh ki gj gh gi kj kk bd b be z dk translated">每部智能手机中的照片数量</figcaption></figure><p id="184e" class="pw-post-body-paragraph km kn iq ko b kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">我们可以看到大多数照片都是在iPhone 7上被点击的，其次是三星S6和谷歌Pixel。LG G4的照片数量最少。</p><figure class="oe of og oh gt ka gh gi paragraph-image"><div role="button" tabindex="0" class="kb kc di kd bf ke"><div class="gh gi op"><img src="../Images/1e99cd5536224cd587540ceb2b1fa348.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*y_baSoWnbz4-cA8cFivJEA.png"/></div></div><figcaption class="kh ki gj gh gi kj kk bd b be z dk translated">每部智能手机图像的ISO级别</figcaption></figure><p id="5330" class="pw-post-body-paragraph km kn iq ko b kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">数据集中总共使用了14种独特的ISO级别设置。大多数照片是在低ISO设置下点击的。最常用的ISO设置是100和800，其次是1600、400和3200。曝光越高，图像越亮，反之亦然。</p><figure class="oe of og oh gt ka gh gi paragraph-image"><div role="button" tabindex="0" class="kb kc di kd bf ke"><div class="gh gi oq"><img src="../Images/a2e035c04d6d15d30ba12002c404f766.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*kuKMXZs3-H4WmqptzyIyGg.png"/></div></div><figcaption class="kh ki gj gh gi kj kk bd b be z dk translated">每部智能手机图像的快门速度</figcaption></figure><p id="3d99" class="pw-post-body-paragraph km kn iq ko b kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">大部分照片是以100快门速度点击，其次是400和800。快门速度越高，图像越暗，反之亦然。</p><figure class="oe of og oh gt ka gh gi paragraph-image"><div class="gh gi or"><img src="../Images/4bc0b13b7b654955c6ce136fba3f71d9.png" data-original-src="https://miro.medium.com/v2/resize:fit:1012/format:webp/1*jL3FRGpLTBvn9-xSx4R0qg.png"/></div><figcaption class="kh ki gj gh gi kj kk bd b be z dk translated">每部智能手机图像的亮度级别</figcaption></figure><p id="990d" class="pw-post-body-paragraph km kn iq ko b kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">大多数照片是在正常亮度模式下点击的，其次是低亮度。三星S6上只有2张照片是高亮度点击的。</p><figure class="oe of og oh gt ka gh gi paragraph-image"><div role="button" tabindex="0" class="kb kc di kd bf ke"><div class="gh gi os"><img src="../Images/fbdad6f8a1f5abf69d697a3f7554dffa.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Xzhp77QOAtHEq50RkO2kjA.png"/></div></div><figcaption class="kh ki gj gh gi kj kk bd b be z dk translated">每部智能手机的分辨率</figcaption></figure><p id="d3ac" class="pw-post-body-paragraph km kn iq ko b kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">我们可以看到每部手机都有自己的图像分辨率。每部手机都以相同的分辨率拍摄照片。</p><h2 id="4f67" class="nr lv iq bd lw ns nt dn ma nu nv dp me kx nw nx mi lb ny nz mm lf oa ob mq iw bi translated">图像数据的分析</h2><figure class="oe of og oh gt ka gh gi paragraph-image"><div role="button" tabindex="0" class="kb kc di kd bf ke"><div class="gh gi ot"><img src="../Images/b6c745eaf4ff207490f1e7d79873a066.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*rtA4B3Nb6LzBn2Vx7iwP6w.png"/></div></div><figcaption class="kh ki gj gh gi kj kk bd b be z dk translated">三个通道所有图像的平均值和标准偏差</figcaption></figure><p id="ae14" class="pw-post-body-paragraph km kn iq ko b kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">可以看出，大多数平均像素值处于较低到中等的值(较暗到中等亮度的图像)。只有少数是很高价值的(亮图像)。你还可以看到，与地面真实图像相比，噪声图像中的一些均值有所不同。像素值越高，差异越明显。</p><figure class="oe of og oh gt ka gh gi paragraph-image"><div role="button" tabindex="0" class="kb kc di kd bf ke"><div class="gh gi ou"><img src="../Images/1d2ae19032357d9d762b1670371a550a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*tEwDgpdO1xDF5LLJW4byeQ.png"/></div></div></figure><p id="cbda" class="pw-post-body-paragraph km kn iq ko b kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">可以观察到，与原始图像相比，噪声图像具有平滑的像素强度分布。这样做的原因是，每当图像中有噪声时，相机就无法捕获这些像素的颜色信息(由于各种原因)，因此，为了填充这些像素中的“无颜色”，相机软件通常会用一些随机值进行填充。由于这些随机值(噪声),像素值变得平滑。</p><h1 id="2e6e" class="lu lv iq bd lw lx ly lz ma mb mc md me mf mg mh mi mj mk ml mm mn mo mp mq mr bi translated">6.传统图像去噪滤波器综述</h1><p id="3457" class="pw-post-body-paragraph km kn iq ko b kp mu kr ks kt mv kv kw kx ni kz la lb nj ld le lf nk lh li lj ij bi translated">传统上，研究人员想出了<em class="lt">滤波器</em>来对图像降噪。大多数过滤器是针对图像的噪声类型的。有几种类型的噪声，如高斯噪声、泊松噪声、斑点噪声、椒盐噪声等。每种类型的噪音都有特定的过滤器。因此，使用传统滤波器对图像去噪的第一步是识别图像中存在的噪声类型。识别之后，我们可以继续应用特定的过滤器。为了识别噪音的类型，有一些数学公式可以帮助我们猜测噪音的类型。或者领域专家可以通过查看图像来决定。还有一些过滤器可以处理任何类型的噪声。</p><p id="85b7" class="pw-post-body-paragraph km kn iq ko b kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">有大量的过滤器可用于图像去噪。各有利弊。在这里，我将讨论非局部均值(NLM)算法，它被认为是非常好的去噪图像。</p><h2 id="501f" class="nr lv iq bd lw ns nt dn ma nu nv dp me kx nw nx mi lb ny nz mm lf oa ob mq iw bi translated"><strong class="ak">非本地指</strong></h2><p id="7e1b" class="pw-post-body-paragraph km kn iq ko b kp mu kr ks kt mv kv kw kx ni kz la lb nj ld le lf nk lh li lj ij bi translated">首先，让我给你看一下NLM的公式，</p><figure class="oe of og oh gt ka gh gi paragraph-image"><div class="gh gi ov"><img src="../Images/cb0d65e331105054a83953d618a76c75.png" data-original-src="https://miro.medium.com/v2/resize:fit:614/format:webp/1*oiIYY_li1LiFJrVxR__oQQ.png"/></div><figcaption class="kh ki gj gh gi kj kk bd b be z dk translated">NLM公式</figcaption></figure><p id="3497" class="pw-post-body-paragraph km kn iq ko b kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">该算法将像素的估计值计算为图像中所有像素的加权平均值，但权重家族取决于像素<em class="lt"> i </em>和<em class="lt">j</em>之间的相似性。换句话说，它查看图像的一个斑块，然后识别整个图像中的其他相似斑块，并对它们进行加权平均。为了理解这一点，考虑下面的图像，</p><figure class="oe of og oh gt ka gh gi paragraph-image"><div role="button" tabindex="0" class="kb kc di kd bf ke"><div class="gh gi ow"><img src="../Images/94040cff4bbc4b15fc701e563878d7a8.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Rliek0hBkTRQdNmw1nBiBg.png"/></div></div></figure><p id="a7df" class="pw-post-body-paragraph km kn iq ko b kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">这里，相似的补丁用相同颜色的方框标记。所以现在，它会将相似块的像素加权平均作为目标像素的估计值。该算法将面片大小和面片距离作为输入。</p><p id="43cd" class="pw-post-body-paragraph km kn iq ko b kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">考虑下面的灰度图像，它已经使用NLM滤波器去噪。</p><figure class="oe of og oh gt ka gh gi paragraph-image"><div role="button" tabindex="0" class="kb kc di kd bf ke"><div class="gh gi ox"><img src="../Images/4ffca9dd7a3ea455a6345f5d40d25c42.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*q_dT4PN2lkWn7nbZefacfQ.png"/></div></div><figcaption class="kh ki gj gh gi kj kk bd b be z dk translated">左侧—噪声图像；右侧—使用NLM滤波器去除图像噪声</figcaption></figure><p id="af3d" class="pw-post-body-paragraph km kn iq ko b kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">你可以看到NLM在图像去噪方面做得相当不错。如果你仔细看，你会注意到去噪后的图像有点模糊。这是因为<em class="lt">的意思是</em>。应用于任何数据的平均值将使这些值变得平滑。</p><p id="61cc" class="pw-post-body-paragraph km kn iq ko b kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">然而，当噪声水平太高时，NLM不能提供好的结果。考虑下面这张使用NLM滤波器去噪的图像。</p><figure class="oe of og oh gt ka gh gi paragraph-image"><div role="button" tabindex="0" class="kb kc di kd bf ke"><div class="gh gi oy"><img src="../Images/ed0d3a5cd448f4a14c879e4ec3050f77.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*nwqqlp5z6BbCScBQp4zpvg.png"/></div></div><figcaption class="kh ki gj gh gi kj kk bd b be z dk translated">利用NLM对图像去噪</figcaption></figure><p id="b48f" class="pw-post-body-paragraph km kn iq ko b kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">你可以清楚地看到，去噪后，图像过于模糊，大部分关键细节都丢失在其中。例如，观察蓝色卡车上的橙色前灯。</p><h1 id="9308" class="lu lv iq bd lw lx ly lz ma mb mc md me mf mg mh mi mj mk ml mm mn mo mp mq mr bi translated">7.图像去噪的深度学习模型</h1><p id="7007" class="pw-post-body-paragraph km kn iq ko b kp mu kr ks kt mv kv kw kx ni kz la lb nj ld le lf nk lh li lj ij bi translated">随着深度学习技术的出现，现在可以从图像中去除盲噪声，使得结果非常接近地面真实图像，而细节损失最小。</p><p id="9d3a" class="pw-post-body-paragraph km kn iq ko b kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">我已经实现了三个深度学习架构，</p><ol class=""><li id="54d7" class="ms mt iq ko b kp kq kt ku kx ol lb om lf on lj mz na nb nc bi translated"><a class="ae kl" href="https://arxiv.org/pdf/1606.08921.pdf" rel="noopener ugc nofollow" target="_blank">红网</a></li><li id="cae8" class="ms mt iq ko b kp nd kt ne kx nf lb ng lf nh lj mz na nb nc bi translated"><a class="ae kl" href="https://arxiv.org/pdf/1805.07071.pdf" rel="noopener ugc nofollow" target="_blank">美国有线电视新闻网</a></li><li id="ab11" class="ms mt iq ko b kp nd kt ne kx nf lb ng lf nh lj mz na nb nc bi translated"><a class="ae kl" href="https://arxiv.org/pdf/1908.00273.pdf" rel="noopener ugc nofollow" target="_blank"> PRIDNet </a></li></ol><h2 id="7e31" class="nr lv iq bd lw ns nt dn ma nu nv dp me kx nw nx mi lb ny nz mm lf oa ob mq iw bi translated">REDNet —残差编码器-解码器网络</h2><p id="1abb" class="pw-post-body-paragraph km kn iq ko b kp mu kr ks kt mv kv kw kx ni kz la lb nj ld le lf nk lh li lj ij bi translated">这是一个基于CNN的<a class="ae kl" href="https://en.wikipedia.org/wiki/Autoencoder" rel="noopener ugc nofollow" target="_blank">自动编码器</a>架构，具有跳跃连接。该架构如下所示，</p><figure class="oe of og oh gt ka gh gi paragraph-image"><div role="button" tabindex="0" class="kb kc di kd bf ke"><div class="gh gi oz"><img src="../Images/b746d22cd17f9fa54c83b2cc3407477d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*fFUmJ4nThqm-CbPS7xs07A.png"/></div></div><figcaption class="kh ki gj gh gi kj kk bd b be z dk translated">REDNet架构</figcaption></figure><p id="1ad5" class="pw-post-body-paragraph km kn iq ko b kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">这里，我对编码器使用了5层卷积，对解码器使用了5层去卷积。这是一个非常简单的架构，我用它作为基线。</p><figure class="oe of og oh gt ka"><div class="bz fp l di"><div class="pa pb l"/></div><figcaption class="kh ki gj gh gi kj kk bd b be z dk translated">REDNet的代码</figcaption></figure><p id="704d" class="pw-post-body-paragraph km kn iq ko b kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">我已经在我的Github repo上分享了我的REDNet的完整代码。</p><p id="ed0c" class="pw-post-body-paragraph km kn iq ko b kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated"><strong class="ko ja">结果</strong></p><figure class="oe of og oh gt ka gh gi paragraph-image"><div role="button" tabindex="0" class="kb kc di kd bf ke"><div class="gh gi pc"><img src="../Images/07d00ed95d531e607a5414fa4195beac.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*1qBJ7mXfNEguwRKLiVLSoQ.png"/></div></div><figcaption class="kh ki gj gh gi kj kk bd b be z dk translated">REDNet结果</figcaption></figure><figure class="oe of og oh gt ka gh gi paragraph-image"><div role="button" tabindex="0" class="kb kc di kd bf ke"><div class="gh gi pd"><img src="../Images/e1f0906079a109675c63c7945fbfa109.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*GTD0Am5nG6-7JN5zd00GcA.png"/></div></div><figcaption class="kh ki gj gh gi kj kk bd b be z dk translated">REDNet结果</figcaption></figure><p id="0e60" class="pw-post-body-paragraph km kn iq ko b kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">可以看到，这种架构在图像去噪方面表现相当不错。你肯定可以看到噪声有所减少，图像正在努力适应图像中受损像素的原始颜色。</p><p id="2e02" class="pw-post-body-paragraph km kn iq ko b kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">这种架构的PSNR得分为30.5713，SSIM得分为0.7932。</p><h2 id="aa25" class="nr lv iq bd lw ns nt dn ma nu nv dp me kx nw nx mi lb ny nz mm lf oa ob mq iw bi translated">多级小波CNN</h2><p id="79d7" class="pw-post-body-paragraph km kn iq ko b kp mu kr ks kt mv kv kw kx ni kz la lb nj ld le lf nk lh li lj ij bi translated">这是一个基于小波的深度学习架构。它的架构与一个<a class="ae kl" href="https://arxiv.org/pdf/1505.04597.pdf" rel="noopener ugc nofollow" target="_blank"> U-Net </a>架构有着惊人的相似。MWCNN唯一的区别是，与U-Net中的下采样和上采样不同，这里我们使用DWT(离散小波变换)和IWT(小波逆变换)。DWT和IWT是如何工作的超出了本博客的范围。然而，我已经附上了一些参考资料，你可以从中学习。</p><figure class="oe of og oh gt ka gh gi paragraph-image"><div role="button" tabindex="0" class="kb kc di kd bf ke"><div class="gh gi pe"><img src="../Images/05d2241fb873c55a7a596703c2da05c8.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*694Kp_Er6KYmk1dQWhfV_w.png"/></div></div><figcaption class="kh ki gj gh gi kj kk bd b be z dk translated">MWCNN架构</figcaption></figure><p id="6a06" class="pw-post-body-paragraph km kn iq ko b kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">在这里，我将这个架构扩展到了4个层次。所以我的网络深度变成了32。代码有点长，我在Keras中使用了自定义层。你可以在我的Github repo上查看我的MWCNN 的<a class="ae kl" href="https://github.com/chintan1995/Image-Denoising-using-Deep-Learning/blob/main/Models/MWCNN_256x256.ipynb" rel="noopener ugc nofollow" target="_blank">完整代码。</a></p><p id="ee1c" class="pw-post-body-paragraph km kn iq ko b kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated"><strong class="ko ja">结果</strong></p><figure class="oe of og oh gt ka gh gi paragraph-image"><div role="button" tabindex="0" class="kb kc di kd bf ke"><div class="gh gi pf"><img src="../Images/d9dffb5508d532ba8644c3ba0d9c3a23.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*vaYWm-wIy9ZPJkLW3lNGnQ.png"/></div></div><figcaption class="kh ki gj gh gi kj kk bd b be z dk translated">MWCNN结果</figcaption></figure><figure class="oe of og oh gt ka gh gi paragraph-image"><div role="button" tabindex="0" class="kb kc di kd bf ke"><div class="gh gi pg"><img src="../Images/d8f6f4aefe070ed9eb5eb5dd77107293.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*KQcmgvMrQh0Z8YX7k0nV1w.png"/></div></div><figcaption class="kh ki gj gh gi kj kk bd b be z dk translated">MWCNN结果</figcaption></figure><figure class="oe of og oh gt ka gh gi paragraph-image"><div role="button" tabindex="0" class="kb kc di kd bf ke"><div class="gh gi pd"><img src="../Images/728299b817d09cb83e0ad3888153770f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*jgDLkyNY2Mv-xbYTpq-qPQ.png"/></div></div><figcaption class="kh ki gj gh gi kj kk bd b be z dk translated">MWCNN结果</figcaption></figure><p id="deae" class="pw-post-body-paragraph km kn iq ko b kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">我们可以看到，与REDNet相比，这种架构工作得更好，图像更清晰。</p><p id="539a" class="pw-post-body-paragraph km kn iq ko b kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">该架构的PSNR得分为32.5221，SSIM得分为0.8397。</p><h2 id="4da3" class="nr lv iq bd lw ns nt dn ma nu nv dp me kx nw nx mi lb ny nz mm lf oa ob mq iw bi translated">prid net——金字塔实像去噪网络</h2><p id="6677" class="pw-post-body-paragraph km kn iq ko b kp mu kr ks kt mv kv kw kx ni kz la lb nj ld le lf nk lh li lj ij bi translated">这是一个用于盲去噪的最先进的深度学习架构。这种架构不像我们在之前的两个网络中看到的那样简单。PRIDNet有几个模块，分为三个主要部分。</p><figure class="oe of og oh gt ka gh gi paragraph-image"><div role="button" tabindex="0" class="kb kc di kd bf ke"><div class="gh gi ph"><img src="../Images/b783be915b575e06bc22f7b3a3ee5fb7.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*d0b4HFG9uslzF9GcFJTpwQ.png"/></div></div><figcaption class="kh ki gj gh gi kj kk bd b be z dk translated">PRIDNet架构[完整]</figcaption></figure><p id="e597" class="pw-post-body-paragraph km kn iq ko b kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">乍一看，这似乎有点让人不知所措。但是让我把它分成几部分。相信我，这很容易理解。</p><p id="0219" class="pw-post-body-paragraph km kn iq ko b kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated"><strong class="ko ja">频道关注模块</strong></p><figure class="oe of og oh gt ka gh gi paragraph-image"><div class="gh gi pi"><img src="../Images/ea2882d5e404e4e2c95dc7b71820d570.png" data-original-src="https://miro.medium.com/v2/resize:fit:1242/format:webp/1*5QaG-SnfMO-w4lCiqX9vaA.png"/></div><figcaption class="kh ki gj gh gi kj kk bd b be z dk translated">频道注意模块</figcaption></figure><p id="dd32" class="pw-post-body-paragraph km kn iq ko b kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">频道关注模块负责<strong class="ko ja">关注机制。</strong>这里，注意力机制是这样实现的，它将注意力放在输入<em class="lt"> U </em>的每个通道上。现在，这个“<em class="lt">注意力”</em>可以被认为是权重。因此每个通道将有一个权重。结果，注意力权重将是大小为<em class="lt"> C </em>【频道数】的向量。这个向量将被乘以输入<em class="lt"> U </em>。因为我们想要"<em class="lt">学习</em>"注意力，我们需要这个向量是可训练的。PRIDNet实现的过程是，首先我们对输入进行全局平均汇集，然后从两个完全连接的层传递，结果应该是一个包含通道数的向量。这些是注意力权重μ。</p><p id="17cc" class="pw-post-body-paragraph km kn iq ko b kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated"><strong class="ko ja">多尺度特征提取模块/金字塔模块</strong></p><figure class="oe of og oh gt ka gh gi paragraph-image"><div class="gh gi ok"><img src="../Images/0b97857afdd62a6bdff70e335fc4655b.png" data-original-src="https://miro.medium.com/v2/resize:fit:634/format:webp/1*oAWsSumsYPbfhQr7sMmftQ.png"/></div><figcaption class="kh ki gj gh gi kj kk bd b be z dk translated">金字塔模块</figcaption></figure><p id="3433" class="pw-post-body-paragraph km kn iq ko b kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">这是整个架构的核心。这里，首先，我们将应用给定内核大小的平均池。这将对图像进行下采样。然后我们将对其应用U-Net架构。我选择了5级深U网。最后，我们将使用与平均池中相同的大小进行向上采样。因此，这将把图像恢复到与输入(该模块的输入)相同的大小。</p><p id="244f" class="pw-post-body-paragraph km kn iq ko b kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">我们将用不同的内核大小做5次，最后我们将连接结果。</p><p id="b8a1" class="pw-post-body-paragraph km kn iq ko b kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated"><strong class="ko ja">内核选择模块</strong></p><figure class="oe of og oh gt ka gh gi paragraph-image"><div class="gh gi pj"><img src="../Images/9ae76b00c5aaf1d3063765582a7ce639.png" data-original-src="https://miro.medium.com/v2/resize:fit:1282/format:webp/1*vY1nj6nIafuCx6ZIzWvrPw.png"/></div><figcaption class="kh ki gj gh gi kj kk bd b be z dk translated">内核选择模块</figcaption></figure><p id="a632" class="pw-post-body-paragraph km kn iq ko b kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">这个模块的灵感来自于一篇介绍了选择性内核网络的研究论文。该研究论文很好地阐述了这一网络背后的想法，如下所示:</p><blockquote class="nl nm nn"><p id="b8db" class="km kn lt ko b kp kq kr ks kt ku kv kw no ky kz la np lc ld le nq lg lh li lj ij bi translated">在标准卷积神经网络(CNN)中，每层人工神经元的感受野被设计为共享相同的大小。众所周知，视觉皮层神经元的感受野大小受到刺激的调制，这在构建细胞神经网络时很少被考虑。</p><p id="7aba" class="km kn lt ko b kp kq kr ks kt ku kv kw no ky kz la np lc ld le nq lg lh li lj ij bi translated">设计了一种称为选择性核(SK)单元的构建块，其中具有不同核大小的多个分支使用softmax注意力进行融合，该注意力由这些分支中的信息引导。对这些分支的不同关注产生了融合层中神经元的不同大小的有效感受野。</p></blockquote><p id="bacf" class="pw-post-body-paragraph km kn iq ko b kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">该模块与频道关注模块非常相似。根据PRIDNet论文，大小为<em class="lt"> C </em>的合成向量α、β、γ分别表示对U’、U”和U”’的软注意。</p><p id="70d7" class="pw-post-body-paragraph km kn iq ko b kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">下面是整个PRIDNet体系结构的鸟瞰图，</p><figure class="oe of og oh gt ka gh gi paragraph-image"><div role="button" tabindex="0" class="kb kc di kd bf ke"><div class="gh gi pk"><img src="../Images/158420c02f00ca35d97de1c595599cca.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*O_9__F0G7XsqqyMMRjklPg.png"/></div></div><figcaption class="kh ki gj gh gi kj kk bd b be z dk translated">PRIDNet架构；鸟瞰图</figcaption></figure><p id="26b0" class="pw-post-body-paragraph km kn iq ko b kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">我已经在我的Github repo上分享了PRIDNet 的全部代码。</p><p id="e7db" class="pw-post-body-paragraph km kn iq ko b kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated"><strong class="ko ja">结果</strong></p><figure class="oe of og oh gt ka gh gi paragraph-image"><div role="button" tabindex="0" class="kb kc di kd bf ke"><div class="gh gi pl"><img src="../Images/3dc53bfc434a03ab715e1450727d9073.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*IR_-uun7PTBX3uFck4kakQ.png"/></div></div><figcaption class="kh ki gj gh gi kj kk bd b be z dk translated">PRIDNet结果</figcaption></figure><figure class="oe of og oh gt ka gh gi paragraph-image"><div role="button" tabindex="0" class="kb kc di kd bf ke"><div class="gh gi pm"><img src="../Images/f7045d304752b3faa335f514fda5e676.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*_JugijJJk_izq17HCUnsvQ.png"/></div></div><figcaption class="kh ki gj gh gi kj kk bd b be z dk translated">PRIDNet结果</figcaption></figure><figure class="oe of og oh gt ka gh gi paragraph-image"><div role="button" tabindex="0" class="kb kc di kd bf ke"><div class="gh gi pn"><img src="../Images/d939ad4d18e5546d12b06b14ae94c9d8.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Twqenpzrn0HcBsQEpQf5-w.png"/></div></div><figcaption class="kh ki gj gh gi kj kk bd b be z dk translated">PRIDNet结果</figcaption></figure><p id="38d2" class="pw-post-body-paragraph km kn iq ko b kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">您可以看到，与之前讨论的架构相比，这种架构提供了最好的结果。在上面眼睛的特写图像中，<strong class="ko ja">注意去噪图像中眼球的细节层次</strong>！</p><p id="4263" class="pw-post-body-paragraph km kn iq ko b kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">另外，请查看上面的库图像。我在下面截取了一部分，</p><figure class="oe of og oh gt ka gh gi paragraph-image"><div class="gh gi po"><img src="../Images/2850b020a5cd6e153372389fcdd6ba68.png" data-original-src="https://miro.medium.com/v2/resize:fit:710/format:webp/1*IyJfwm5V6rJr08jWOEskGQ.png"/></div><figcaption class="kh ki gj gh gi kj kk bd b be z dk translated">裁剪过的图书馆书籍。左侧-噪声图像；右侧—去噪图像</figcaption></figure><figure class="oe of og oh gt ka gh gi paragraph-image"><div class="gh gi pp"><img src="../Images/a7bc57782bc4bc0f590f4d2581897fa4.png" data-original-src="https://miro.medium.com/v2/resize:fit:444/format:webp/1*IQ3XOdf44l33AV44W0TONA.png"/></div><figcaption class="kh ki gj gh gi kj kk bd b be z dk translated">裁剪过的图书馆家具。左侧-噪声图像；右侧—去噪图像</figcaption></figure><p id="1c2e" class="pw-post-body-paragraph km kn iq ko b kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">注意噪声图像中的黑色书籍[裁剪的图书馆书籍]。它们与周围的棕色家具几乎无法区分。好像都是黑的。然而，我们的模型能够以这样一种方式去噪，即它至少可以区分书籍和周围的家具。第二张图片[裁剪过的图书馆家具]也是如此。在其嘈杂的形象，你可以看到家具已经非常黑暗，它似乎几乎是黑色的顶部。然而，我们的模型能够理解棕色并相应地去噪。这有多神奇！</p><p id="e484" class="pw-post-body-paragraph km kn iq ko b kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">该架构的PSNR得分为33.3105，SSIM得分为0.8534。</p><h1 id="0867" class="lu lv iq bd lw lx ly lz ma mb mc md me mf mg mh mi mj mk ml mm mn mo mp mq mr bi translated">8.结果比较</h1><figure class="oe of og oh gt ka gh gi paragraph-image"><div role="button" tabindex="0" class="kb kc di kd bf ke"><div class="gh gi pq"><img src="../Images/61ef477a3c73ac0b2071a7761dbe0fe2.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*U6Aw7hL3OdLPTcaDkfd5OQ.png"/></div></div><figcaption class="kh ki gj gh gi kj kk bd b be z dk translated">比较所有架构的结果</figcaption></figure><p id="0cfc" class="pw-post-body-paragraph km kn iq ko b kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">我们可以清楚地看到，PRIDNet是性能最好的架构，对单幅图像进行降噪所需的时间最少。</p><p id="d785" class="pw-post-body-paragraph km kn iq ko b kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">现在让我们比较NLM滤波和PRIDNet的结果。</p><figure class="oe of og oh gt ka gh gi paragraph-image"><div role="button" tabindex="0" class="kb kc di kd bf ke"><div class="gh gi pr"><img src="../Images/3d1b41da3b166a3d529a04a526c206b5.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*2it6_L10ySkE1VYgM0gaxg.png"/></div></div><figcaption class="kh ki gj gh gi kj kk bd b be z dk translated">NLM滤波去噪</figcaption></figure><figure class="oe of og oh gt ka gh gi paragraph-image"><div role="button" tabindex="0" class="kb kc di kd bf ke"><div class="gh gi ps"><img src="../Images/082d95b084770133972d3c0c9921a573.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*J-gMmC8_4S8fb4QpXM-qDg.png"/></div></div><figcaption class="kh ki gj gh gi kj kk bd b be z dk translated">使用PRIDNet去噪</figcaption></figure><p id="b3ed" class="pw-post-body-paragraph km kn iq ko b kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">要比较的关键区域，</p><ul class=""><li id="f800" class="ms mt iq ko b kp kq kt ku kx ol lb om lf on lj oc na nb nc bi translated">黄色卡车的车顶区域</li><li id="ccd4" class="ms mt iq ko b kp nd kt ne kx nf lb ng lf nh lj oc na nb nc bi translated">橙色卡车的座位</li><li id="e370" class="ms mt iq ko b kp nd kt ne kx nf lb ng lf nh lj oc na nb nc bi translated">蓝色卡车上的橙色前灯</li><li id="9fe0" class="ms mt iq ko b kp nd kt ne kx nf lb ng lf nh lj oc na nb nc bi translated">蓝色卡车的车顶(观察阴影)</li><li id="cfc9" class="ms mt iq ko b kp nd kt ne kx nf lb ng lf nh lj oc na nb nc bi translated">地板中间的两条细条纹</li><li id="2ea9" class="ms mt iq ko b kp nd kt ne kx nf lb ng lf nh lj oc na nb nc bi translated">这个清单可以一直列下去！</li></ul><h1 id="c671" class="lu lv iq bd lw lx ly lz ma mb mc md me mf mg mh mi mj mk ml mm mn mo mp mq mr bi translated">9.部署</h1><p id="e9bd" class="pw-post-body-paragraph km kn iq ko b kp mu kr ks kt mv kv kw kx ni kz la lb nj ld le lf nk lh li lj ij bi translated">我已经使用Streamlit创建了一个Web应用程序并部署了它。到目前为止，我已经将它部署在localhost上，因为我的模型太大，无法上传到免费的云资源(如Heroku、GCP应用引擎、AWS EC2、Azure Web app等)的内存中。然而，我正在寻找解决办法。敬请关注这里的任何更新！</p><p id="038c" class="pw-post-body-paragraph km kn iq ko b kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">同时，看看我的网络应用的视频演示，</p><figure class="oe of og oh gt ka"><div class="bz fp l di"><div class="pt pb l"/></div></figure><h1 id="2428" class="lu lv iq bd lw lx ly lz ma mb mc md me mf mg mh mi mj mk ml mm mn mo mp mq mr bi translated">10.未来工作和改进范围</h1><p id="df78" class="pw-post-body-paragraph km kn iq ko b kp mu kr ks kt mv kv kw kx ni kz la lb nj ld le lf nk lh li lj ij bi translated">图像去噪是一个活跃的研究领域，并且不时有令人惊讶的架构被开发来对图像去噪。最近，研究人员正在使用<strong class="ko ja"> GANs </strong>对图像进行去噪，这已经被证明可以给出一些惊人的结果。一个好的GAN架构肯定会进一步改善去噪性能。</p><h1 id="ff78" class="lu lv iq bd lw lx ly lz ma mb mc md me mf mg mh mi mj mk ml mm mn mo mp mq mr bi translated">11.参考</h1><ul class=""><li id="5a35" class="ms mt iq ko b kp mu kt mv kx mw lb mx lf my lj oc na nb nc bi translated"><a class="ae kl" href="https://medium.com/image-vision/noise-in-digital-image-processing-55357c9fab71" rel="noopener">https://medium . com/image-vision/noise-in-digital-image-processing-55357 C9 fab 71</a>(什么是噪点？)</li><li id="f225" class="ms mt iq ko b kp nd kt ne kx nf lb ng lf nh lj oc na nb nc bi translated">https://www.youtube.com/watch?v=Va4Rwoy1v88&amp;ab _ channel = digitals reeni(非本地手段)</li><li id="5976" class="ms mt iq ko b kp nd kt ne kx nf lb ng lf nh lj oc na nb nc bi translated">【https://www.eecs.yorku.ca/~kamel/sidd/dataset.php T4】(SIDD数据集)</li><li id="18c5" class="ms mt iq ko b kp nd kt ne kx nf lb ng lf nh lj oc na nb nc bi translated"><a class="ae kl" href="http://adrianbarburesearch.blogspot.com/p/renoir-dataset.html" rel="noopener ugc nofollow" target="_blank">http://adrianbarburesearch . blogspot . com/p/RENOIR-dataset . html</a>(RENOIR数据集)</li><li id="be65" class="ms mt iq ko b kp nd kt ne kx nf lb ng lf nh lj oc na nb nc bi translated"><a class="ae kl" href="https://commons.wikimedia.org/wiki/Natural_Image_Noise_Dataset#Tools" rel="noopener ugc nofollow" target="_blank">https://commons . wikimedia . org/wiki/Natural _ Image _ Noise _ Dataset # Tools</a>(NIND数据集)</li><li id="f04a" class="ms mt iq ko b kp nd kt ne kx nf lb ng lf nh lj oc na nb nc bi translated"><a class="ae kl" href="https://arxiv.org/pdf/1606.08921.pdf" rel="noopener ugc nofollow" target="_blank">https://arxiv.org/pdf/1606.08921.pdf</a>(红网)</li><li id="a062" class="ms mt iq ko b kp nd kt ne kx nf lb ng lf nh lj oc na nb nc bi translated"><a class="ae kl" href="https://arxiv.org/pdf/1805.07071.pdf" rel="noopener ugc nofollow" target="_blank">https://arxiv.org/pdf/1805.07071.pdf</a></li><li id="4da5" class="ms mt iq ko b kp nd kt ne kx nf lb ng lf nh lj oc na nb nc bi translated">https://arxiv.org/pdf/1908.00273.pdf</li><li id="2421" class="ms mt iq ko b kp nd kt ne kx nf lb ng lf nh lj oc na nb nc bi translated"><a class="ae kl" href="https://arxiv.org/pdf/1505.04597.pdf" rel="noopener ugc nofollow" target="_blank">https://arxiv.org/pdf/1505.04597.pdf</a></li><li id="8b95" class="ms mt iq ko b kp nd kt ne kx nf lb ng lf nh lj oc na nb nc bi translated"><a class="ae kl" href="https://arxiv.org/pdf/1903.06586.pdf" rel="noopener ugc nofollow" target="_blank">https://arxiv.org/pdf/1903.06586.pdf</a>(选择性内核网络)</li><li id="9a19" class="ms mt iq ko b kp nd kt ne kx nf lb ng lf nh lj oc na nb nc bi translated"><a class="ae kl" href="https://www.eecis.udel.edu/~amer/CISC651/IEEEwavelet.pdf" rel="noopener ugc nofollow" target="_blank">https://www.eecis.udel.edu/~amer/CISC651/IEEEwavelet.pdf</a>(小波)</li><li id="db93" class="ms mt iq ko b kp nd kt ne kx nf lb ng lf nh lj oc na nb nc bi translated">https://towards data science . com/what-is wavelet-and-how-we-use-it for-data-science-d 19427699 cef(小波)</li><li id="7d4f" class="ms mt iq ko b kp nd kt ne kx nf lb ng lf nh lj oc na nb nc bi translated"><a class="ae kl" href="http://gwyddion.net/documentation/user-guide-en/wavelet-transform.html" rel="noopener ugc nofollow" target="_blank">http://gwyddion . net/documentation/user-guide-en/Wavelet-transform . html</a>(小波变换)</li></ul><div class="pu pv gp gr pw px"><a href="https://github.com/chintan1995/Image-Denoising-using-Deep-Learning" rel="noopener  ugc nofollow" target="_blank"><div class="py ab fo"><div class="pz ab qa cl cj qb"><h2 class="bd ja gy z fp qc fr fs qd fu fw iz bi translated">chintan 1995/使用深度学习的图像去噪</h2><div class="qe l"><h3 class="bd b gy z fp qc fr fs qd fu fw dk translated">在这篇报告中，我实现了三种不同的深度学习架构用于图像去噪…</h3></div><div class="qf l"><p class="bd b dl z fp qc fr fs qd fu fw dk translated">github.com</p></div></div><div class="qg l"><div class="qh l qi qj qk qg ql kf px"/></div></div></a></div><div class="pu pv gp gr pw px"><a href="https://www.linkedin.com/in/chintan-dave95/" rel="noopener  ugc nofollow" target="_blank"><div class="py ab fo"><div class="pz ab qa cl cj qb"><h2 class="bd ja gy z fp qc fr fs qd fu fw iz bi translated">钦坦戴夫-塔塔咨询服务| LinkedIn</h2><div class="qe l"><h3 class="bd b gy z fp qc fr fs qd fu fw dk translated">精通Python编程语言、自然语言处理、数据科学和机器学习。强…</h3></div><div class="qf l"><p class="bd b dl z fp qc fr fs qd fu fw dk translated">www.linkedin.com</p></div></div><div class="qg l"><div class="qm l qi qj qk qg ql kf px"/></div></div></a></div></div></div>    
</body>
</html>