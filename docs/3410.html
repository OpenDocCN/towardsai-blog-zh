<html>
<head>
<title>Blazing Fast Training with Small Dataset for Java Image Classification</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">Java图像分类的小数据集快速训练</h1>
<blockquote>原文：<a href="https://pub.towardsai.net/blazing-fast-training-with-small-dataset-for-java-applications-4acb9332cd0b?source=collection_archive---------2-----------------------#2022-12-16">https://pub.towardsai.net/blazing-fast-training-with-small-dataset-for-java-applications-4acb9332cd0b?source=collection_archive---------2-----------------------#2022-12-16</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><figure class="gl gn jo jp jq jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi jn"><img src="../Images/c73266884642f278703f037ae2041191.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*8gG7GdGWaWX1FKjhKKVwCw.png"/></div></div></figure><p id="22c0" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">深度学习在解决CV、NLP、强化学习等各种领域的问题中显示出强大的能力。，产生了许多成功应用的例子。然而，对于非常具体的定制任务，如杂货店中的腐烂水果检测，或公共场所中的戴口罩检测，仍有许多挑战要面对，包括以下两个:</p><p id="536f" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">1.适合该任务的训练数据集通常不会立即可用，而数据收集和注释可能会非常昂贵。</p><p id="085f" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">2.从头开始训练一个模型可能非常耗时，并且可能面临许多不确定性。</p><p id="551c" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">在这篇博文中，我们将用<strong class="ka ir">迁移学习</strong>解决上述两个问题，并在一个腐烂水果检测任务上演示。我们的结果表明，该模型可以在少于<strong class="ka ir"> 100 </strong>幅图像的情况下达到<strong class="ka ir"> 95% </strong>的图像分类准确率。我们还将展示在Java环境中实现这一点是多么容易。</p><p id="b67b" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">在接下来的10分钟内，您将了解如何实现这一点。</p><p id="5478" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">为了解决上面提到的问题，我们将使用DeepJavaLibrary <a class="ae kw" href="https://github.com/deepjavalibrary/djl" rel="noopener ugc nofollow" target="_blank"> DJL </a>中的迁移学习特性。DJL是一个为Java开发人员设计的深度学习库，与现有的深度学习引擎兼容，如PyTorch、MXNet和Tensorflow，并支持Java中的模型训练和推理。我们还将使用<a class="ae kw" href="https://github.com/awslabs/atlearn" rel="noopener ugc nofollow" target="_blank"> ATLearn </a>，一个自适应迁移学习工具包，来编辑和导入大型预训练模型。ATLearn是一个轻量级迁移学习工具包，为python用户提供了各种API、算法和模型动物园。</p><p id="060a" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">这篇博文的结构如下。</p><p id="d5fe" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">1.数据集和问题表述</p><p id="3ca4" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">2.迁移学习模式</p><p id="1e05" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">3.Java中迁移学习的演示</p><p id="1955" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">4.尝试减少训练数据的大小</p><p id="99f3" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">5.摘要</p><p id="7a72" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated"><strong class="ka ir">完整源代码</strong>可从<a class="ae kw" href="https://github.com/deepjavalibrary/djl/blob/master/examples/src/main/java/ai/djl/examples/training/transferlearning/TransferFreshFruit.java" rel="noopener ugc nofollow" target="_blank">这里</a>获得。</p><h1 id="4ec4" class="kx ky iq bd kz la lb lc ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu bi translated"><strong class="ak"> 1。数据集和问题公式化</strong></h1><p id="e1e5" class="pw-post-body-paragraph jy jz iq ka b kb lv kd ke kf lw kh ki kj lx kl km kn ly kp kq kr lz kt ku kv ij bi translated">在这篇博文中，我们用从Kaggle竞赛中公开获得的<a class="ae kw" href="https://www.kaggle.com/datasets/sriramr/fruits-fresh-and-rotten-for-classification" rel="noopener ugc nofollow" target="_blank">水果新鲜和腐烂数据集</a>进行了演示。这个数据集由图片组成，图片中有一个水果，新鲜的或腐烂的。因此，检测腐烂水果的任务可以表述为两类分类问题。这项任务在食品杂货店建立自动腐烂水果检测中具有潜在的应用。</p><p id="1000" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">以下是一些图像数据的示例。</p><p id="1091" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">新鲜/腐烂香蕉数据集:</p><figure class="mb mc md me gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi ma"><img src="../Images/9448c702170d20b595d92f667a8907ea.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*6s--Z3J1eN6-1rcuFOUeZQ.jpeg"/></div></div></figure><p id="70cd" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">新鲜/腐烂的苹果数据集:</p><figure class="mb mc md me gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi mf"><img src="../Images/900bb1131c665a98208665aa34a9804e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*cudVBPDCy2pUbM11ylm9AQ.jpeg"/></div></div></figure><p id="087f" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">很明显，水果图像确实具有足够的视觉变化，可用于分类器模型。</p><h1 id="b4b3" class="kx ky iq bd kz la lb lc ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu bi translated"><strong class="ak"> 2。迁移学习模式</strong></h1><p id="a352" class="pw-post-body-paragraph jy jz iq ka b kb lv kd ke kf lw kh ki kj lx kl km kn ly kp kq kr lz kt ku kv ij bi translated">基于迁移学习，该模型建立在一个大的预训练模型之上，该模型用于获得嵌入向量。然后，嵌入向量被馈送到随后的全连接层，随后是SoftMax激活函数。因此，通过迁移学习，用户可以从大量预先训练的模型中受益，并解决他们自己定制的问题。</p><p id="0bab" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">本次演示中使用的预训练模型是<a class="ae kw" href="https://pytorch.org/vision/main/models/generated/torchvision.models.resnet18.html" rel="noopener ugc nofollow" target="_blank"> ResNet18 </a>。你可以从ATLearn或者手动从PyTorch获得一个用它制作的嵌入模型。这里我们展示了使用ATLearn的方法，嵌入模型可以直接导出。</p><pre class="mb mc md me gt mg mh mi bn mj mk bi"><span id="60df" class="ml ky iq mh b be mm mn l mo mp">import ATLearn<br/>model = ATLearn.get_embedding(ATLearn.task.IMAGE_CLASSIFICATION,<br/>                              "EXPORT_PATH",<br/>                              network='resnet18',  # pre-trained model from torch<br/>                              user_network=None)   # users' own pre-trained model</span></pre><p id="5dd1" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">在这一步，ATLearn所做的是移除ResNet18的最后一层，以获得中间矢量，然后跟踪并导出模型为TorchScript文件<code class="fe mq mr ms mh b">resnet18_embedding.pt</code>，然后可以直接在DJL加载。这部分将在下一节介绍。</p><h1 id="f82a" class="kx ky iq bd kz la lb lc ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu bi translated">3.Java中迁移学习的演示</h1><p id="bb99" class="pw-post-body-paragraph jy jz iq ka b kb lv kd ke kf lw kh ki kj lx kl km kn ly kp kq kr lz kt ku kv ij bi translated">总的来说，这种迁移学习功能是一种培训功能，因此它的API与其他DJL培训示例有相似之处。它主要包含模型结构、数据加载、训练配置和指标。</p><p id="296c" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated"><strong class="ka ir"> 3。1设置</strong></p><p id="abf9" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">要开始使用DJL迁移学习功能，请将下面的代码片段添加到<code class="fe mq mr ms mh b">build.gradle</code>文件中，它定义了必要的依赖关系。</p><pre class="mb mc md me gt mg mh mi bn mj mk bi"><span id="7b9e" class="ml ky iq mh b be mm mn l mo mp">plugins {<br/>  id 'java'<br/>}<br/>repositories {<br/>  mavenCentral()<br/>}<br/>dependencies {<br/>  implementation "org.apache.logging.log4j:log4j-slf4j-impl:2.17.1"<br/>  implementation platform("ai.djl:bom:0.21.0")<br/>  implementation "ai.djl:api"<br/>  runtimeOnly "ai.djl.pytorch:pytorch-engine"<br/>  runtimeOnly "ai.djl.pytorch:pytorch-model-zoo"<br/>}</span></pre><p id="f6b7" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated"><strong class="ka ir"> 3.2模型构建</strong></p><p id="45e6" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated"><strong class="ka ir"> 3.2.1在DJL加载包埋，建立模型。</strong>如前所述，我们已经从ATLearn生成了一个嵌入层。现在我们可以把它装载到DJL。这个嵌入层在<code class="fe mq mr ms mh b">modelUrl = “djl://ai.djl.pytorch/resnet18_embedding”</code>也有。在DJL，模型加载是通过<code class="fe mq mr ms mh b">criteria</code> API实现的，它作为搜索模型的标准。它提供了几个选项来配置模型。其中<code class="fe mq mr ms mh b">trainParam</code>是专门针对迁移学习(或模型再培训)的选项。将其设置为“false”将会冻结加载的嵌入层(或模型)中的参数，而“true”则相反。</p><pre class="mb mc md me gt mg mh mi bn mj mk bi"><span id="edaf" class="ml ky iq mh b be mm mn l mo mp">String modelUrl = "/EXPORT_PATH/resnet18_embedding.pt";<br/>Criteria&lt;NDList, NDList&gt; criteria =<br/>        Criteria.builder()<br/>                .setTypes(NDList.class, NDList.class)<br/>                .optModelUrls(modelUrl)<br/>                .optEngine("PyTorch")<br/>                .optProgress(new ProgressBar())<br/>                .optOption("trainParam", "true")  // or "false" to freeze the embedding <br/>                .build();<br/>ZooModel&lt;NDList, NDList&gt; embedding = criteria.loadModel();<br/>Block baseBlock = embedding.getBlock();</span></pre><p id="5d11" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">在嵌入模型之上，我们进一步添加全连接(FC)层(也表示为MLP层)，其输出维度是类的数量，即，在该任务中为2。我们使用顺序块模型来包含嵌入和完全连接的层。最终输出是一个SoftMax函数，用于获取类概率，如下所示。</p><pre class="mb mc md me gt mg mh mi bn mj mk bi"><span id="f718" class="ml ky iq mh b be mm mn l mo mp"><br/>Block blocks =<br/>        new SequentialBlock()<br/>                .add(baseBlock)<br/>                .addSingleton(nd -&gt; nd.squeeze(new int[] {2, 3}))  // squeeze the size-1 dimensions from the baseBlock<br/>                .add(Linear.builder().setUnits(2).build()) // add fully connected layer<br/>                .addSingleton(nd -&gt; nd.softmax(1));<br/>Model model = Model.newInstance("TransferFreshFruit");<br/>model.setBlock(blocks);</span></pre><p id="860c" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated"><strong class="ka ir"> 3.2.2。教练配置。</strong>训练器的配置主要包括损失函数(本例中为<code class="fe mq mr ms mh b">SoftmaxCrossEntropy</code>)、评估指标(本例中为<code class="fe mq mr ms mh b">Accuracy</code>)、用于获取训练监控数据的训练监听器等的设置。在我们的任务中，它们被指定如下所示。</p><pre class="mb mc md me gt mg mh mi bn mj mk bi"><span id="60ce" class="ml ky iq mh b be mm mn l mo mp">private static DefaultTrainingConfig setupTrainingConfig(Block baseBlock) {<br/>    String outputDir = "build/fruits";<br/>    SaveModelTrainingListener listener = new SaveModelTrainingListener(outputDir);<br/>    listener.setSaveModelCallback(<br/>            trainer -&gt; {<br/>                TrainingResult result = trainer.getTrainingResult();<br/>                Model model = trainer.getModel();<br/>                float accuracy = result.getValidateEvaluation("Accuracy");<br/>                model.setProperty("Accuracy", String.format("%.5f", accuracy));<br/>                model.setProperty("Loss", String.format("%.5f", result.getValidateLoss()));<br/>            });<br/><br/>    DefaultTrainingConfig config = new DefaultTrainingConfig(new SoftmaxCrossEntropy("SoftmaxCrossEntropy"))<br/>            .addEvaluator(new Accuracy())<br/>            .optDevices(Engine.getInstance().getDevices(1))<br/>            .addTrainingListeners(TrainingListener.Defaults.logging(outputDir))<br/>            .addTrainingListeners(listener);<br/>     ...<br/>     return config;<br/>}</span></pre><p id="f0f8" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">在这一步，我们将在这两层上分配不同的学习速率:嵌入层的学习速率比FC层的学习速率小10倍。因此，嵌入层中的预训练参数不会改变太多。学习率的分配由<code class="fe mq mr ms mh b">learningRateTracker</code>指定，然后输入到<code class="fe mq mr ms mh b">Optimizer</code>中的<code class="fe mq mr ms mh b">learningRateTracker</code>选项，如下所示。</p><pre class="mb mc md me gt mg mh mi bn mj mk bi"><span id="6a25" class="ml ky iq mh b be mm mn l mo mp">// Customized learning rate<br/>float lr = 0.001f;<br/>FixedPerVarTracker.Builder learningRateTrackerBuilder =<br/>        FixedPerVarTracker.builder().setDefaultValue(lr);<br/>for (Pair&lt;String, Parameter&gt; paramPair : baseBlock.getParameters()) {<br/>        learningRateTrackerBuilder.put(paramPair.getValue().getId(), 0.1f * lr);<br/>}<br/>FixedPerVarTracker learningRateTracker = learningRateTrackerBuilder.build();<br/>Optimizer optimizer = Adam.builder().optLearningRateTracker(learningRateTracker).build();<br/>config.optOptimizer(optimizer);</span></pre><p id="438d" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">在此步骤之后，通过<code class="fe mq mr ms mh b">setupTrainingConfig</code>功能返回一个训练配置。然后用于设置训练器。</p><pre class="mb mc md me gt mg mh mi bn mj mk bi"><span id="6af2" class="ml ky iq mh b be mm mn l mo mp">Trainer trainer = model.newTrainer(config);</span></pre><p id="bd2e" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">接下来，训练器由下面的代码初始化，其中将指定每个块中参数的形状和初始值。必须事先知道<code class="fe mq mr ms mh b">inputShape</code>。</p><pre class="mb mc md me gt mg mh mi bn mj mk bi"><span id="8f33" class="ml ky iq mh b be mm mn l mo mp">int batchSize = 32;<br/>Shape inputShape = new Shape(batchSize, 3, 224, 224);<br/>trainer.initialize(inputShape);</span></pre><p id="3623" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">3.2.3数据加载。使用以下函数加载并预处理数据。</p><pre class="mb mc md me gt mg mh mi bn mj mk bi"><span id="ce54" class="ml ky iq mh b be mm mn l mo mp">private static RandomAccessDataset getData(String usage, int batchSize)<br/>        throws TranslateException, IOException {<br/>    float[] mean = {0.485f, 0.456f, 0.406f};<br/>    float[] std = {0.229f, 0.224f, 0.225f};<br/>    <br/>    // usage is either "train" or "test"<br/>    Repository repository = Repository.newInstance("banana", Paths.get("LOCAL_PATH/banana/" + usage)); <br/>    FruitsFreshAndRotten dataset =<br/>            FruitsFreshAndRotten.builder()<br/>                    .optRepository(repository)<br/>                    .addTransform(new RandomResizedCrop(256, 256)) // only in training<br/>                    .addTransform(new RandomFlipTopBottom()) // only in training<br/>                    .addTransform(new RandomFlipLeftRight()) // only in training<br/>                    .addTransform(new Resize(256, 256))<br/>                    .addTransform(new CenterCrop(224, 224))<br/>                    .addTransform(new ToTensor())<br/>                    .addTransform(new Normalize(mean, std))<br/>                    .addTargetTransform(new OneHot(2))<br/>                    .setSampling(batchSize, true)<br/>                    .build();<br/>    dataset.prepare();<br/>    return dataset;<br/>}</span></pre><p id="f57d" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">这里，数据用归一化和随机化函数进行预处理，这些函数通常用于图像分类(见本教程<a class="ae kw" href="https://pytorch.org/tutorials/beginner/transfer_learning_tutorial.html" rel="noopener ugc nofollow" target="_blank">)。随机化仅用于训练。</a></p><p id="9ed4" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated"><strong class="ka ir"> 3.2.4模型训练和导出。</strong>最后可以用<code class="fe mq mr ms mh b">Easytrain.fit</code>运行模型训练，保存模型进行预测。最后，<code class="fe mq mr ms mh b">model.close()</code>和<code class="fe mq mr ms mh b">embedding.close() </code>被调用。在DJL，在创建<code class="fe mq mr ms mh b">Model</code>和<code class="fe mq mr ms mh b">ZooModel&lt;NDList, NDList&gt;</code>的过程中，本地资源(例如PyTorch中分配的内存)被分配。这些资源由继承了<code class="fe mq mr ms mh b">AutoCloseable</code>类的<code class="fe mq mr ms mh b">NDManager </code>管理。</p><pre class="mb mc md me gt mg mh mi bn mj mk bi"><span id="f1c0" class="ml ky iq mh b be mm mn l mo mp">EasyTrain.fit(trainer, numEpoch, datasetTrain, datasetTest);<br/>model.save(Paths.get("SAVE_PATH"), "transferFreshFruit");<br/><br/>model.close();<br/>embedding.close();</span></pre><p id="9495" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">运行训练代码时，需要设置VM选项<code class="fe mq mr ms mh b">-Dai.djl.default_engine=PyTorch</code>来指定引擎。培训过程的一般输出如下:</p><pre class="mb mc md me gt mg mh mi bn mj mk bi"><span id="1dd8" class="ml ky iq mh b be mm mn l mo mp">Training:    100% |████████████████████████████████████████| speed: 28.26 items/sec<br/>Validating:  100% |████████████████████████████████████████|<br/>[INFO ] - Epoch 10 finished.<br/>[INFO ] - Train: Accuracy: 0.93, SoftmaxCrossEntropy: 0.22<br/>[INFO ] - Validate: Accuracy: 0.90, SoftmaxCrossEntropy: 0.34</span></pre><p id="575a" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">在这里，您可以监控训练和验证的准确性和损失下降。</p><h1 id="cb06" class="kx ky iq bd kz la lb lc ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu bi translated"><strong class="ak"> 4。尝试减少训练数据量</strong></h1><p id="a75d" class="pw-post-body-paragraph jy jz iq ka b kb lv kd ke kf lw kh ki kj lx kl km kn ly kp kq kr lz kt ku kv ij bi translated">迁移学习的主要优势在于它利用了预先训练的模型，因此可以在相对较小的数据集上进行训练。这将节省数据收集和注释的成本。在本节中，我们在<code class="fe mq mr ms mh b">FreshFruit </code>数据集上测量验证准确性与训练数据大小的关系。<strong class="ka ir">全实验代码</strong>可在<a class="ae kw" href="https://gist.github.com/KexinFeng/d9c0a244d0597e6c6e161c1c1c2db569" rel="noopener ugc nofollow" target="_blank">这里</a>获得。</p><p id="a087" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">在这个实验中，需要控制和随机选择训练数据集的大小。这部分实现如下，其中<code class="fe mq mr ms mh b">cut</code>是训练数据的大小。</p><pre class="mb mc md me gt mg mh mi bn mj mk bi"><span id="5934" class="ml ky iq mh b be mm mn l mo mp">List&lt;Long&gt; batchIndexList = new ArrayList&lt;&gt;();<br/>try (NDManager manager = NDManager.newBaseManager()) {<br/>    NDArray indices = manager.randomPermutation(dataset.size());<br/>    NDArray batchIndex = indices.get(":{}", cut);<br/>    for (long index : batchIndex.toLongArray()) {<br/>        batchIndexList.add(index);<br/>    }<br/>}<br/>return dataset.subDataset(batchIndexList);</span></pre><p id="3c6d" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">验证准确度与训练数据大小的结果如下。</p><p id="7059" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">新鲜/腐烂香蕉分类:</p><figure class="mb mc md me gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi mt"><img src="../Images/30f7af3fa0f27f7c712ed913425cee0b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*iQD6aaBjkIV_VrAXusjCRQ.jpeg"/></div></div></figure><p id="f300" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">新鲜/腐烂苹果分类:</p><figure class="mb mc md me gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi mt"><img src="../Images/a573945eb0075df7aa2d8fed363c4b80.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*mTBvUNDvsO3HB7cgCq7n3g.jpeg"/></div></div></figure><p id="f06a" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">在这里，我们测试了两个场景:冻结ResNet层和只更新MLP和更新所有层。正如所料，后者的稳定精度略好于前者，因为ResNet参数也是由数据微调的。我们还可以看到，香蕉数据的精度在30个样本时达到稳定的0.95，苹果数据的精度在大约70个样本时达到稳定的0.95。它们都相对小于Kaggle提供的超过1000的训练数据大小。这验证了所需的训练数据集确实很小。当人们需要收集和注释数据时，这提供了所需最小数据大小的参考。</p><h1 id="57f4" class="kx ky iq bd kz la lb lc ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu bi translated"><strong class="ak"> 5。总结</strong></h1><p id="14f7" class="pw-post-body-paragraph jy jz iq ka b kb lv kd ke kf lw kh ki kj lx kl km kn ly kp kq kr lz kt ku kv ij bi translated">在这篇博文中，我们展示了如何在DJL为一个图像分类任务建立一个迁移学习模型。这个过程也适用于模型再训练。最后，我们给出了关于训练数据集可以减少多少的实验。这种减少的直接好处是，它有助于节省昂贵的数据收集和注释成本。这使得利用大型预训练模型来解决小型数据集的其他各种任务变得更加容易。</p><p id="c879" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">该演示同样适用于其他任务和数据，如<a class="ae kw" href="https://www.kaggle.com/datasets/andrewmvd/face-mask-detection?select=images" rel="noopener ugc nofollow" target="_blank">戴面具检测</a>和<a class="ae kw" href="https://www.kaggle.com/datasets/dcsyanwq/fuit-freshness" rel="noopener ugc nofollow" target="_blank">水果新鲜度回归</a>。参见<a class="ae kw" href="https://github.com/awslabs/atlearn" rel="noopener ugc nofollow" target="_blank"> ATLearn </a>中的例子，了解它们在python中的实现，以及其他对象检测的例子。</p></div></div>    
</body>
</html>