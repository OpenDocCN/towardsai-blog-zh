<html>
<head>
<title>Gradient Boosting Technique</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">梯度推进技术</h1>
<blockquote>原文：<a href="https://pub.towardsai.net/gradient-boosting-technique-b3dbb7069b74?source=collection_archive---------2-----------------------#2020-12-20">https://pub.towardsai.net/gradient-boosting-technique-b3dbb7069b74?source=collection_archive---------2-----------------------#2020-12-20</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><h2 id="8027" class="io ip iq bd b dl ir is it iu iv iw dk ix translated" aria-label="kicker paragraph"><a class="ae ep" href="https://towardsai.net/p/category/machine-learning" rel="noopener ugc nofollow" target="_blank">机器学习</a></h2><div class=""/><div class=""><h2 id="1ba3" class="pw-subtitle-paragraph jw iz iq bd b jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn dk translated">数字解释和数学直觉</h2></div><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div class="gh gi ko"><img src="../Images/c0d240bb989c049fa54a43224ef1fe7b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1398/format:webp/1*FvSf1hwoQBYLk_qmo19Nhw.png"/></div><figcaption class="kw kx gj gh gi ky kz bd b be z dk translated"><a class="ae la" href="https://www.researchgate.net/profile/Ivanna_Baturynska/publication/340524896/figure/fig3/AS:878319096569859@1586418999392/Schematical-representation-of-gradient-boosting-regression-in-regards-to-algorithm.png" rel="noopener ugc nofollow" target="_blank">来源</a></figcaption></figure><h1 id="82e1" class="lb lc iq bd ld le lf lg lh li lj lk ll kf lm kg ln ki lo kj lp kl lq km lr ls bi translated">介绍</h1><p id="3d4f" class="pw-post-body-paragraph lt lu iq lv b lw lx ka ly lz ma kd mb mc md me mf mg mh mi mj mk ml mm mn mo ij bi translated">梯度推进技术是一种监督机器学习算法，属于集成推进技术家族。它通常应用于回归和分类问题，以生成基于弱预测学习器模型的组合输出结果来评估输出特征的模型。它应用最小化损失函数的概念来优化模型。使用决策树来构建顺序模型，直到达到最大准确度。</p><p id="5135" class="pw-post-body-paragraph lt lu iq lv b lw mp ka ly lz mq kd mb mc mr me mf mg ms mi mj mk mt mm mn mo ij bi translated">当梯度增强用于预测给定数据集的连续输出值时，我们将为回归执行梯度增强。同样，如果我们预测离散值输出，那么我们将执行梯度推进进行分类。</p><p id="564f" class="pw-post-body-paragraph lt lu iq lv b lw mp ka ly lz mq kd mb mc mr me mf mg ms mi mj mk mt mm mn mo ij bi translated">在本文中，我们将主要关注使用回归的梯度推进。</p><h1 id="6f5a" class="lb lc iq bd ld le lf lg lh li lj lk ll kf lm kg ln ki lo kj lp kl lq km lr ls bi translated">梯度推进的步骤</h1><p id="6e2e" class="pw-post-body-paragraph lt lu iq lv b lw lx ka ly lz ma kd mb mc md me mf mg mh mi mj mk ml mm mn mo ij bi translated">我们以下面的数据集为例，根据年龄、学位和工作年限等因素来预测候选人的薪资。</p><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div role="button" tabindex="0" class="mv mw di mx bf my"><div class="gh gi mu"><img src="../Images/510413787318b83817f446b9e857bf8f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*4utvcI7Lx8WvnxUfQQ8P0Q.png"/></div></div><figcaption class="kw kx gj gh gi ky kz bd b be z dk translated">作者图片</figcaption></figure><p id="4c34" class="pw-post-body-paragraph lt lu iq lv b lw mp ka ly lz mq kd mb mc mr me mf mg ms mi mj mk mt mm mn mo ij bi translated"><strong class="lv ja">第一步:取输出特征的平均值</strong></p><p id="5454" class="pw-post-body-paragraph lt lu iq lv b lw mp ka ly lz mq kd mb mc mr me mf mg ms mi mj mk mt mm mn mo ij bi translated">在这里，我们计算提供给候选人的工资的平均值，并假设它是我们的预测产值。所以我们在Salary(实际产值)列旁边添加一个新列。</p><p id="e589" class="pw-post-body-paragraph lt lu iq lv b lw mp ka ly lz mq kd mb mc mr me mf mg ms mi mj mk mt mm mn mo ij bi translated"><strong class="lv ja">=所有工资的总和</strong></p><p id="9e5e" class="pw-post-body-paragraph lt lu iq lv b lw mp ka ly lz mq kd mb mc mr me mf mg ms mi mj mk mt mm mn mo ij bi translated"><strong class="lv ja"> =60+50+65 = 58 </strong></p><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div role="button" tabindex="0" class="mv mw di mx bf my"><div class="gh gi mz"><img src="../Images/6d639aecae2439c24fb7ae0c1f7819f6.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*5dwvo_xNdwJuijZLXOquJA.png"/></div></div><figcaption class="kw kx gj gh gi ky kz bd b be z dk translated">作者图片</figcaption></figure><p id="79ae" class="pw-post-body-paragraph lt lu iq lv b lw mp ka ly lz mq kd mb mc mr me mf mg ms mi mj mk mt mm mn mo ij bi translated"><strong class="lv ja">第二步:计算残值</strong></p><p id="74ca" class="pw-post-body-paragraph lt lu iq lv b lw mp ka ly lz mq kd mb mc mr me mf mg ms mi mj mk mt mm mn mo ij bi translated">接下来是计算预测值和实际值之间的差异。这种差异被称为残值。</p><p id="14e2" class="pw-post-body-paragraph lt lu iq lv b lw mp ka ly lz mq kd mb mc mr me mf mg ms mi mj mk mt mm mn mo ij bi translated"><strong class="lv ja">残差=实际值—预测值</strong></p><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div role="button" tabindex="0" class="mv mw di mx bf my"><div class="gh gi gj"><img src="../Images/7aa1576043a11312baa5a6650475a02d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*baZJ40FSXqGWv5TVdQyDAg.png"/></div></div><figcaption class="kw kx gj gh gi ky kz bd b be z dk translated">作者图片</figcaption></figure><p id="6dd1" class="pw-post-body-paragraph lt lu iq lv b lw mp ka ly lz mq kd mb mc mr me mf mg ms mi mj mk mt mm mn mo ij bi translated">尽管从上表中可以看出，给预测工资加上一个残差就可以得到预期的实际工资，但是你认为这可行吗？嗯，这可能有助于我们在模型测试过程中自救，但我们可能无法在模型测试过程中得到很多变化。因此，基本上，在将模型应用于未知数据集时，我们可能会遇到低偏差和高方差的问题。文章的后半部分解释了这个问题的解决方案。</p><p id="ce02" class="pw-post-body-paragraph lt lu iq lv b lw mp ka ly lz mq kd mb mc mr me mf mg ms mi mj mk mt mm mn mo ij bi translated"><strong class="lv ja">步骤3:生成基础学习者决策树</strong></p><p id="0d1a" class="pw-post-body-paragraph lt lu iq lv b lw mp ka ly lz mq kd mb mc mr me mf mg ms mi mj mk mt mm mn mo ij bi translated">然后，我们基于作为输出值的残差和作为输入参数的给定独立特征来构建决策树。为了避免高方差问题，我们使用学习参数缩放剩余输出值，并将其添加到平均预测工资中。</p><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div class="gh gi na"><img src="../Images/08f613d2ca57d6ce14e9aa8ca68e1432.png" data-original-src="https://miro.medium.com/v2/resize:fit:1030/format:webp/1*oxs54ogqgdL-lcV9TQXJYw.png"/></div><figcaption class="kw kx gj gh gi ky kz bd b be z dk translated">作者图片</figcaption></figure><p id="0be8" class="pw-post-body-paragraph lt lu iq lv b lw mp ka ly lz mq kd mb mc mr me mf mg ms mi mj mk mt mm mn mo ij bi translated"><strong class="lv ja">步骤4:生成决策树1的预测输出</strong></p><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div role="button" tabindex="0" class="mv mw di mx bf my"><div class="gh gi mz"><img src="../Images/3a3f95a40ba1767fda8048cdb0551f27.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*y869uEHIEo39m-dmF6I0fg.png"/></div></div><figcaption class="kw kx gj gh gi ky kz bd b be z dk translated">作者图片</figcaption></figure><p id="7717" class="pw-post-body-paragraph lt lu iq lv b lw mp ka ly lz mq kd mb mc mr me mf mg ms mi mj mk mt mm mn mo ij bi translated">上图中我们计算的R1残差值显示了决策树模型的实际值。我们可以使用损失函数的公式来获得决策树输出的预测值。因为我们希望最小化实际输出和预测输出之间的损失，所以代表决策树的预测输出的剩余值R2将总是具有小于其输出的值。</p><p id="a4f4" class="pw-post-body-paragraph lt lu iq lv b lw mp ka ly lz mq kd mb mc mr me mf mg ms mi mj mk mt mm mn mo ij bi translated"><strong class="lv ja">步骤5:预测每个样本的新o/p值</strong></p><p id="9c90" class="pw-post-body-paragraph lt lu iq lv b lw mp ka ly lz mq kd mb mc mr me mf mg ms mi mj mk mt mm mn mo ij bi translated">因此，应用决策树后的新预测值如下所示:</p><p id="b19b" class="pw-post-body-paragraph lt lu iq lv b lw mp ka ly lz mq kd mb mc mr me mf mg ms mi mj mk mt mm mn mo ij bi translated">先前预测值+学习率*当前预测值</p><p id="015a" class="pw-post-body-paragraph lt lu iq lv b lw mp ka ly lz mq kd mb mc mr me mf mg ms mi mj mk mt mm mn mo ij bi translated"><strong class="lv ja"> α =学习率= 0.1 </strong></p><p id="893f" class="pw-post-body-paragraph lt lu iq lv b lw mp ka ly lz mq kd mb mc mr me mf mg ms mi mj mk mt mm mn mo ij bi translated">这里引入了学习率来解决上面在步骤2中引入的高方差问题。</p><p id="a248" class="pw-post-body-paragraph lt lu iq lv b lw mp ka ly lz mq kd mb mc mr me mf mg ms mi mj mk mt mm mn mo ij bi translated">现在我们考虑上面<a class="ae la" href="https://cdn-images-1.medium.com/max/720/1*y869uEHIEo39m-dmF6I0fg.png" rel="noopener">图像</a>中的记录-1，以便更好地理解事情。</p><p id="2c2b" class="pw-post-body-paragraph lt lu iq lv b lw mp ka ly lz mq kd mb mc mr me mf mg ms mi mj mk mt mm mn mo ij bi translated">这里，</p><p id="5e5d" class="pw-post-body-paragraph lt lu iq lv b lw mp ka ly lz mq kd mb mc mr me mf mg ms mi mj mk mt mm mn mo ij bi translated">实际产量最初由薪金= 60k给出</p><p id="e732" class="pw-post-body-paragraph lt lu iq lv b lw mp ka ly lz mq kd mb mc mr me mf mg ms mi mj mk mt mm mn mo ij bi translated">预测工资由= 58k给出</p><p id="8c17" class="pw-post-body-paragraph lt lu iq lv b lw mp ka ly lz mq kd mb mc mr me mf mg ms mi mj mk mt mm mn mo ij bi translated">树1的预测工资= 8k</p><p id="dfe5" class="pw-post-body-paragraph lt lu iq lv b lw mp ka ly lz mq kd mb mc mr me mf mg ms mi mj mk mt mm mn mo ij bi translated">因此，新的预测值由下式给出</p><p id="eb94" class="pw-post-body-paragraph lt lu iq lv b lw mp ka ly lz mq kd mb mc mr me mf mg ms mi mj mk mt mm mn mo ij bi">58+0.1*8 = 58.8</p><p id="59ba" class="pw-post-body-paragraph lt lu iq lv b lw mp ka ly lz mq kd mb mc mr me mf mg ms mi mj mk mt mm mn mo ij bi translated">因此，通过应用一个决策树，预测值从58到58.8更接近实际值60。</p><p id="4d3d" class="pw-post-body-paragraph lt lu iq lv b lw mp ka ly lz mq kd mb mc mr me mf mg ms mi mj mk mt mm mn mo ij bi translated"><strong class="lv ja">所以结论是，我们需要不断重复创建决策树的过程，直到达到预测值等于实际值的阶段。</strong></p><p id="b8b6" class="pw-post-body-paragraph lt lu iq lv b lw mp ka ly lz mq kd mb mc mr me mf mg ms mi mj mk mt mm mn mo ij bi translated">我们需要继续执行迭代以达到最大的准确性。</p><h1 id="ecb1" class="lb lc iq bd ld le lf lg lh li lj lk ll kf lm kg ln ki lo kj lp kl lq km lr ls bi translated">数学直觉</h1><p id="6d3e" class="pw-post-body-paragraph lt lu iq lv b lw lx ka ly lz ma kd mb mc md me mf mg mh mi mj mk ml mm mn mo ij bi translated">为了理解上述过程，我们进一步理解为其设计的算法。我们将对算法和数值做一步一步的比较，以便更好地把握事物。</p><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div class="gh gi nb"><img src="../Images/f0d1a1c5fc755b57c6e68f635dd8497a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1392/format:webp/1*qhxnDnmlTZJGKuq2GsMBAQ.png"/></div><figcaption class="kw kx gj gh gi ky kz bd b be z dk translated">作者图片</figcaption></figure><p id="8a5c" class="pw-post-body-paragraph lt lu iq lv b lw mp ka ly lz mq kd mb mc mr me mf mg ms mi mj mk mt mm mn mo ij bi translated"><strong class="lv ja">第一步:</strong></p><p id="b6b7" class="pw-post-body-paragraph lt lu iq lv b lw mp ka ly lz mq kd mb mc mr me mf mg ms mi mj mk mt mm mn mo ij bi translated">它是定义为常数值的平均值的计算。我们通过应用最小化实际和预测结果之间的差异的概念，即损失函数，来计算常数值或第一个预测工资值。数学上最小化任何东西意味着在那个点上的微分为零。因此，在下图中，我们</p><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div class="gh gi nc"><img src="../Images/2c0cdc94cee98610acca4bf86999652c.png" data-original-src="https://miro.medium.com/v2/resize:fit:998/format:webp/1*GLQI6cnlo7X-ZiW66CGvMA.png"/></div><figcaption class="kw kx gj gh gi ky kz bd b be z dk translated">作者图片</figcaption></figure><p id="f8b3" class="pw-post-body-paragraph lt lu iq lv b lw mp ka ly lz mq kd mb mc mr me mf mg ms mi mj mk mt mm mn mo ij bi translated">现在，放回每条记录的y值，我们可以计算整个数据集的预测值或平均值。</p><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div class="gh gi nd"><img src="../Images/f6876a97844a66c1056e02514e4efc6f.png" data-original-src="https://miro.medium.com/v2/resize:fit:842/format:webp/1*LPNIviQun73djmc3GiEtiA.png"/></div><figcaption class="kw kx gj gh gi ky kz bd b be z dk translated">作者图片</figcaption></figure><p id="a070" class="pw-post-body-paragraph lt lu iq lv b lw mp ka ly lz mq kd mb mc mr me mf mg ms mi mj mk mt mm mn mo ij bi translated"><strong class="lv ja">步骤2(a): </strong></p><p id="0018" class="pw-post-body-paragraph lt lu iq lv b lw mp ka ly lz mq kd mb mc mr me mf mg ms mi mj mk mt mm mn mo ij bi translated">对于ῡ= f₀( x)=预测值，我们现在需要计算预测值的残差或差值</p><p id="7624" class="pw-post-body-paragraph lt lu iq lv b lw mp ka ly lz mq kd mb mc mr me mf mg ms mi mj mk mt mm mn mo ij bi translated">为了计算残差，我们使用由m表示的决策树。</p><p id="b85f" class="pw-post-body-paragraph lt lu iq lv b lw mp ka ly lz mq kd mb mc mr me mf mg ms mi mj mk mt mm mn mo ij bi translated">rᵢₘ =决策树m的记录I的残差</p><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div class="gh gi ne"><img src="../Images/16d1bc76c13dfbe86cd97467dc459437.png" data-original-src="https://miro.medium.com/v2/resize:fit:1184/format:webp/1*lkWqjZgcBkxzE8-sYRcA0Q.png"/></div><figcaption class="kw kx gj gh gi ky kz bd b be z dk translated">作者图片</figcaption></figure><p id="a54b" class="pw-post-body-paragraph lt lu iq lv b lw mp ka ly lz mq kd mb mc mr me mf mg ms mi mj mk mt mm mn mo ij bi translated"><strong class="lv ja">步骤2(b): </strong></p><p id="7035" class="pw-post-body-paragraph lt lu iq lv b lw mp ka ly lz mq kd mb mc mr me mf mg ms mi mj mk mt mm mn mo ij bi translated">我们现在使用残差作为输出和特征x作为输入来构建决策树1。</p><p id="8ba0" class="pw-post-body-paragraph lt lu iq lv b lw mp ka ly lz mq kd mb mc mr me mf mg ms mi mj mk mt mm mn mo ij bi translated"><strong class="lv ja">步骤2(c): </strong></p><p id="3d98" class="pw-post-body-paragraph lt lu iq lv b lw mp ka ly lz mq kd mb mc mr me mf mg ms mi mj mk mt mm mn mo ij bi translated">对于在上述步骤中获得的每个实际剩余输出，我们现在将计算预测输出ῡ.</p><p id="8d4f" class="pw-post-body-paragraph lt lu iq lv b lw mp ka ly lz mq kd mb mc mr me mf mg ms mi mj mk mt mm mn mo ij bi translated">我们已经有了模型1的预测值，它被定义为步骤1中的平均值。</p><p id="0803" class="pw-post-body-paragraph lt lu iq lv b lw mp ka ly lz mq kd mb mc mr me mf mg ms mi mj mk mt mm mn mo ij bi translated">为了获得决策树中的剩余预测输出，我们使用步骤1的损失函数的概念。</p><p id="7f49" class="pw-post-body-paragraph lt lu iq lv b lw mp ka ly lz mq kd mb mc mr me mf mg ms mi mj mk mt mm mn mo ij bi translated">j =决策树中的叶节点</p><p id="8107" class="pw-post-body-paragraph lt lu iq lv b lw mp ka ly lz mq kd mb mc mr me mf mg ms mi mj mk mt mm mn mo ij bi translated">yᵢ =实际产量</p><p id="efa6" class="pw-post-body-paragraph lt lu iq lv b lw mp ka ly lz mq kd mb mc mr me mf mg ms mi mj mk mt mm mn mo ij bi translated">ῡ=预测产量</p><p id="6be2" class="pw-post-body-paragraph lt lu iq lv b lw mp ka ly lz mq kd mb mc mr me mf mg ms mi mj mk mt mm mn mo ij bi translated">Fₘ-₁( x ) =先前模型输出</p><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div class="gh gi nf"><img src="../Images/490ef544b5b4b6bf7b434efd2bfade5c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1188/format:webp/1*maQvBLXpfrOr3F4zZH8ZaQ.png"/></div><figcaption class="kw kx gj gh gi ky kz bd b be z dk translated">作者图片</figcaption></figure><p id="ca11" class="pw-post-body-paragraph lt lu iq lv b lw mp ka ly lz mq kd mb mc mr me mf mg ms mi mj mk mt mm mn mo ij bi translated"><strong class="lv ja">第二步(d) </strong></p><p id="809e" class="pw-post-body-paragraph lt lu iq lv b lw mp ka ly lz mq kd mb mc mr me mf mg ms mi mj mk mt mm mn mo ij bi translated">在获得决策树的预测值后，我们将其与先前的模型值相结合。循环将不断重复，直到预测值等于实际值。</p><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div class="gh gi ng"><img src="../Images/1254bc0a53219a4dc2597dfd65c729e6.png" data-original-src="https://miro.medium.com/v2/resize:fit:1132/format:webp/1*XfROymrS4caQaVI1M6strg.png"/></div><figcaption class="kw kx gj gh gi ky kz bd b be z dk translated">作者图片</figcaption></figure><p id="c169" class="pw-post-body-paragraph lt lu iq lv b lw mp ka ly lz mq kd mb mc mr me mf mg ms mi mj mk mt mm mn mo ij bi translated">感谢您朗读文章！！</p><p id="0e82" class="pw-post-body-paragraph lt lu iq lv b lw mp ka ly lz mq kd mb mc mr me mf mg ms mi mj mk mt mm mn mo ij bi translated">你可以在LinkedIn上找到我</p><div class="nh ni gp gr nj nk"><a href="https://www.linkedin.com/in/charanraj-shetty-a74831b2/" rel="noopener  ugc nofollow" target="_blank"><div class="nl ab fo"><div class="nm ab nn cl cj no"><h2 class="bd ja gy z fp np fr fs nq fu fw iz bi translated">Charanraj Shetty -技术作家-走向人工智能| LinkedIn</h2><div class="nr l"><h3 class="bd b gy z fp np fr fs nq fu fw dk translated">Pilani BITS软件系统(数据科学)在职硕士综合学习计划。正在寻找…</h3></div><div class="ns l"><p class="bd b dl z fp np fr fs nq fu fw dk translated">www.linkedin.com</p></div></div><div class="nt l"><div class="nu l nv nw nx nt ny ku nk"/></div></div></a></div></div></div>    
</body>
</html>