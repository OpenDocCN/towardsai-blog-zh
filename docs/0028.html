<html>
<head>
<title>Real-time Vehicle Detection with 50 HD Frames/sec on an AMD GPU</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">AMD GPU上50高清帧/秒的实时车辆检测</h1>
<blockquote>原文：<a href="https://pub.towardsai.net/real-time-hd-vehicle-detection-with-amd-rocm-e9c2eea73852?source=collection_archive---------2-----------------------#2019-04-01">https://pub.towardsai.net/real-time-hd-vehicle-detection-with-amd-rocm-e9c2eea73852?source=collection_archive---------2-----------------------#2019-04-01</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><h2 id="291c" class="io ip iq bd b dl ir is it iu iv iw dk ix translated" aria-label="kicker paragraph">实时车辆检测| <a class="ae ep" href="https://towardsai.net" rel="noopener ugc nofollow" target="_blank">走向人工智能</a></h2><div class=""/><figure class="gl gn jx jy jz ka gh gi paragraph-image"><div class="gh gi jw"><img src="../Images/812d932412971bdeeec910aab18b7aed.png" data-original-src="https://miro.medium.com/v2/resize:fit:1280/1*C9H_3I3v4voI0UzvQNuD0w.gif"/></div><figcaption class="kd ke gj gh gi kf kg bd b be z dk translated">高清分辨率为50帧/秒的实时车辆检测</figcaption></figure><h1 id="146c" class="kh ki iq bd kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le bi translated">什么是车辆检测？</h1><p id="f240" class="pw-post-body-paragraph lf lg iq lh b li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma mb mc ij bi translated">车辆检测是<a class="ae md" href="https://arxiv.org/ftp/arxiv/papers/1410/1410.5894.pdf" rel="noopener ugc nofollow" target="_blank">交通监控方法</a>的一部分，在实时交通反馈中，包括检测所有类型的车辆，包括轿车、货车、卡车、自行车等。有几种方法，从图像处理方法，如<a class="ae md" href="https://scikit-image.org/docs/dev/auto_examples/features_detection/plot_hog.html" rel="noopener ugc nofollow" target="_blank"> HOG(梯度方向直方图</a>)、<a class="ae md" href="https://en.wikipedia.org/wiki/Scale-invariant_feature_transform" rel="noopener ugc nofollow" target="_blank"> SIFT(尺度不变特征变换)</a>到深度学习对象检测，如<a class="ae md" href="https://arxiv.org/abs/1311.2524" rel="noopener ugc nofollow" target="_blank"> RCNN </a>、<a class="ae md" href="https://arxiv.org/abs/1512.02325" rel="noopener ugc nofollow" target="_blank"> SSD </a>、<a class="ae md" href="https://pjreddie.com/darknet/yolo/" rel="noopener ugc nofollow" target="_blank"> Yolo </a>等。</p><p id="3009" class="pw-post-body-paragraph lf lg iq lh b li me lk ll lm mf lo lp lq mg ls lt lu mh lw lx ly mi ma mb mc ij bi translated">在这里，我们重点关注深度学习对象检测模型，因为它们具有卓越的准确性。神经网络是运算符(如卷积、RelU等)及其参数(也称为权重和偏差矩阵)的图形。对象检测网络是一个特殊的子类，被训练来定位图像或视频帧中的对象。物体检测的输入是物体的清晰图像。该图像被传递给软件，该软件输出位置，或输入对象周围的边界框，如上图所示。</p><h1 id="b502" class="kh ki iq bd kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le bi translated">如何选择检测型号？</h1><p id="eb7a" class="pw-post-body-paragraph lf lg iq lh b li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma mb mc ij bi translated">性能和准确性是对象检测模型的两个基石。<a class="ae md" href="https://medium.com/@jonathan_hui/map-mean-average-precision-for-object-detection-45c121a31173" rel="noopener">图(平均精度)</a>是测量物体检测器精度的常用度量。</p><figure class="mk ml mm mn gt ka gh gi paragraph-image"><div role="button" tabindex="0" class="mo mp di mq bf mr"><div class="gh gi mj"><img src="../Images/3fef43117a081c5bb730f621e32d45e0.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*htWXBdI4h4nO29Byucoz8w.png"/></div></div><figcaption class="kd ke gj gh gi kf kg bd b be z dk translated">不同对象检测模型的mAP(平均精度)分数概述</figcaption></figure><p id="98f5" class="pw-post-body-paragraph lf lg iq lh b li me lk ll lm mf lo lp lq mg ls lt lu mh lw lx ly mi ma mb mc ij bi translated">虽然SSD和R-FCN等型号更准确，但Yolo是唯一一个在直播视频中每秒帧数最高的型号。</p><h1 id="eb82" class="kh ki iq bd kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le bi translated">为什么我们需要一个高端的GPU？</h1><p id="fc93" class="pw-post-body-paragraph lf lg iq lh b li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma mb mc ij bi translated">我们的主要目标是找到一种能够在高清分辨率的视频馈送上通过现代GPU提供每秒30帧以上的对象检测器。下面的图片来自<a class="ae md" href="https://arxiv.org/pdf/1611.10012.pdf" rel="noopener ugc nofollow" target="_blank">谷歌研究论文</a>在一台配备32GB RAM、英特尔至强E5–1650 v2处理器和Nvidia GeForce GTX Titan X GPU卡的台式机上，我们可以感受到精确度(mAP)与速度(ms)之间的权衡。</p><figure class="mk ml mm mn gt ka gh gi paragraph-image"><div role="button" tabindex="0" class="mo mp di mq bf mr"><div class="gh gi ms"><img src="../Images/843df4d398c59736281070800a88c956.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*r2b6TmQrBRhqbr6r_KTK3A.png"/></div></div><figcaption class="kd ke gj gh gi kf kg bd b be z dk translated">现代卷积物体探测器的速度/精度权衡(来源和参考:谷歌研究论文<a class="ae md" href="https://arxiv.org/pdf/1611.10012.pdf" rel="noopener ugc nofollow" target="_blank">https://arxiv.org/pdf/1611.10012.pdf</a></figcaption></figure><p id="bf48" class="pw-post-body-paragraph lf lg iq lh b li me lk ll lm mf lo lp lq mg ls lt lu mh lw lx ly mi ma mb mc ij bi translated">上图非常清楚地表明，很少有型号能够达到30 fps，相当于33毫秒。</p><p id="2a70" class="pw-post-body-paragraph lf lg iq lh b li me lk ll lm mf lo lp lq mg ls lt lu mh lw lx ly mi ma mb mc ij bi translated">由于我们的硬件仅限于16GB内存，采用AMD锐龙8核处理器和镭龙Instinct MI25 GPU，我们选择YoloV2作为起点。</p><h1 id="2a66" class="kh ki iq bd kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le bi translated">应用设计</h1><p id="dd89" class="pw-post-body-paragraph lf lg iq lh b li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma mb mc ij bi translated">下图是一个典型交通视觉应用的高层架构。</p><figure class="mk ml mm mn gt ka gh gi paragraph-image"><div role="button" tabindex="0" class="mo mp di mq bf mr"><div class="gh gi mt"><img src="../Images/97321517efd9b981d29d311636aab169.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*7KqDUE8PoRi_mJwb"/></div></div><figcaption class="kd ke gj gh gi kf kg bd b be z dk translated">交通视觉应用程序的高级设计</figcaption></figure><p id="c820" class="pw-post-body-paragraph lf lg iq lh b li me lk ll lm mf lo lp lq mg ls lt lu mh lw lx ly mi ma mb mc ij bi translated">下一张图片提供了我们应用软件的底层组件，其中底层3个组件由AMD MIVisionX工具集提供。</p><figure class="mk ml mm mn gt ka gh gi paragraph-image"><div role="button" tabindex="0" class="mo mp di mq bf mr"><div class="gh gi mu"><img src="../Images/eefb6bdb6560eb5149aa419afedf197c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*o3s5Td9klN_GXlnS"/></div></div><figcaption class="kd ke gj gh gi kf kg bd b be z dk translated">交通视觉应用的低层组件</figcaption></figure><h1 id="7605" class="kh ki iq bd kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le bi translated">如何翻译模型来使用GPU？</h1><p id="a4d7" class="pw-post-body-paragraph lf lg iq lh b li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma mb mc ij bi translated">如上所述，神经网络是操作符(如卷积、RelU等)及其参数(也称为权重和偏差矩阵)的图形。下载约罗·V2图表及其参数的链接如下:</p><ol class=""><li id="00bc" class="mv mw iq lh b li me lm mf lq mx lu my ly mz mc na nb nc nd bi translated"><a class="ae md" href="https://raw.githubusercontent.com/pjreddie/darknet/master/cfg/yolov2-tiny-voc.cfg" rel="noopener ugc nofollow" target="_blank"> Yolo V2网络</a></li><li id="c041" class="mv mw iq lh b li ne lm nf lq ng lu nh ly ni mc na nb nc nd bi translated"><a class="ae md" href="https://pjreddie.com/media/files/yolov2-tiny-voc.weights" rel="noopener ugc nofollow" target="_blank">约罗·V2举重</a></li></ol><p id="cbdb" class="pw-post-body-paragraph lf lg iq lh b li me lk ll lm mf lo lp lq mg ls lt lu mh lw lx ly mi ma mb mc ij bi translated">这是一个原始图形，必须翻译成一组可以在AMD桌面上使用CPU-cores和GPU的指令。<a class="ae md" href="https://gpuopen-professionalcompute-libraries.github.io/MIVisionX/" rel="noopener ugc nofollow" target="_blank"> AMD MIVisionX </a>包提供了一种使用<a class="ae md" href="https://gpuopen.com/compute-product/amd-openvx/" rel="noopener ugc nofollow" target="_blank"> AMD openVX </a>和<a class="ae md" href="https://en.wikipedia.org/wiki/OpenCL" rel="noopener ugc nofollow" target="_blank"> OpenCL </a>库转换到MI-xx GPU基础系统的简单方法。<a class="ae md" href="https://gpuopen.com/compute-product/amd-openvx/" rel="noopener ugc nofollow" target="_blank"> AMD openVX </a>是一个用于加速计算机视觉应用的底层库，而<a class="ae md" href="https://en.wikipedia.org/wiki/OpenCL" rel="noopener ugc nofollow" target="_blank"> OpenCL </a>是一个用于编写跨异构平台(如CPU &amp; GPU)执行的程序的框架。</p><p id="975a" class="pw-post-body-paragraph lf lg iq lh b li me lk ll lm mf lo lp lq mg ls lt lu mh lw lx ly mi ma mb mc ij bi translated">MIVisionX模型是使用下图所示的模型转换过程生成的。该过程将Yolo V2转换为MIVision模型，作为openVX库(带有。so extension)准备好在基于x86的CPU内核和MI-xx GPU上执行。</p><figure class="mk ml mm mn gt ka gh gi paragraph-image"><div role="button" tabindex="0" class="mo mp di mq bf mr"><div class="gh gi nj"><img src="../Images/e8e09489ad02fffaf28d277848cc0b19.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*BvLagEM5cSbifMl6"/></div></div><figcaption class="kd ke gj gh gi kf kg bd b be z dk translated">基于AMD系统的视觉应用Yolo模型转换流程</figcaption></figure><h1 id="ec96" class="kh ki iq bd kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le bi translated">应用前端</h1><p id="556d" class="pw-post-body-paragraph lf lg iq lh b li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma mb mc ij bi translated">一旦我们有了模型(一个动态库)，我们就把它包装成一个python包。MIVisionX模型是应用程序中计算最密集的部分，在GPU上执行。我们将其余组件实现为python模块，在主机CPU上执行，如下图所示。</p><figure class="mk ml mm mn gt ka gh gi paragraph-image"><div role="button" tabindex="0" class="mo mp di mq bf mr"><div class="gh gi nk"><img src="../Images/b522d418aaa3bf39d57f421aa2f453ef.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*bH80gkc0qYOV-DEt9KrSEw.png"/></div></div><figcaption class="kd ke gj gh gi kf kg bd b be z dk translated">交通视觉前端组件</figcaption></figure><h1 id="fa5e" class="kh ki iq bd kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le bi translated">如何部署</h1><p id="3b2f" class="pw-post-body-paragraph lf lg iq lh b li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma mb mc ij bi translated">虽然我们将它开发为一个桌面应用程序，带有作为IP网络摄像头的实时提要，但人们可以很容易地在云中或雾中将其扩展为HTTP服务。这种服务预计将使用nodeJS/javascript来支持其他类型的摄像头，包括手机、交通摄像头等。并在V8支持的浏览器中运行。</p><figure class="mk ml mm mn gt ka gh gi paragraph-image"><div role="button" tabindex="0" class="mo mp di mq bf mr"><div class="gh gi nl"><img src="../Images/85299fb29b0b406e71f0d8f1aba47d19.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*89-R-pHnw4eweTjOOjb38g.png"/></div></div><figcaption class="kd ke gj gh gi kf kg bd b be z dk translated">交通监控即云服务</figcaption></figure><h1 id="da24" class="kh ki iq bd kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le bi translated">结果</h1><p id="62da" class="pw-post-body-paragraph lf lg iq lh b li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma mb mc ij bi translated">这个应用程序在AMD锐龙公司的MI25 AI加速器桌面上以<strong class="lh ja"> 50高清(1920x1080)帧/秒</strong>的速度运行。</p><figure class="mk ml mm mn gt ka gh gi paragraph-image"><div class="ab gu cl nm"><img src="../Images/842fca35495e8559a1c640858315cd7f.png" data-original-src="https://miro.medium.com/v2/1*1VZUa3mn3569l3ePzq3piA.gif"/></div><figcaption class="kd ke gj gh gi kf kg bd b be z dk translated">克里斯·帕拉特对我们结果的反应令人震惊。😲</figcaption></figure><p id="f43b" class="pw-post-body-paragraph lf lg iq lh b li me lk ll lm mf lo lp lq mg ls lt lu mh lw lx ly mi ma mb mc ij bi translated">你可以在<a class="ae md" href="https://github.com/srohit0/trafficVision/" rel="noopener ugc nofollow" target="_blank"> GitHub </a>上下载源代码。更多信息请参考下面像我一样好奇的灵魂。</p><h1 id="83c8" class="kh ki iq bd kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le bi translated">参考</h1><ol class=""><li id="546e" class="mv mw iq lh b li lj lm ln lq nn lu no ly np mc na nb nc nd bi translated"><a class="ae md" href="https://github.com/srohit0/trafficVision/" rel="noopener ugc nofollow" target="_blank">交通视觉app </a></li><li id="fe64" class="mv mw iq lh b li ne lm nf lq ng lu nh ly ni mc na nb nc nd bi translated"><a class="ae md" href="https://arxiv.org/ftp/arxiv/papers/1410/1410.5894.pdf" rel="noopener ugc nofollow" target="_blank">车辆检测与跟踪技术</a></li><li id="7613" class="mv mw iq lh b li ne lm nf lq ng lu nh ly ni mc na nb nc nd bi translated"><a class="ae md" href="https://medium.com/datadriveninvestor/measuring-traffic-speed-with-deep-learning-object-detection-efc0bb9a3c57" rel="noopener">测量交通速度</a></li><li id="7706" class="mv mw iq lh b li ne lm nf lq ng lu nh ly ni mc na nb nc nd bi translated"><a class="ae md" href="https://arxiv.org/pdf/1612.08242.pdf" rel="noopener ugc nofollow" target="_blank"> yoloV2纸</a></li><li id="b527" class="mv mw iq lh b li ne lm nf lq ng lu nh ly ni mc na nb nc nd bi translated"><a class="ae md" href="https://pjreddie.com/darknet/imagenet/#reference" rel="noopener ugc nofollow" target="_blank"> Tiny Yolo又名暗网参考网</a></li><li id="7353" class="mv mw iq lh b li ne lm nf lq ng lu nh ly ni mc na nb nc nd bi translated"><a class="ae md" href="https://github.com/kiritigowda/MIVisionX-setup" rel="noopener ugc nofollow" target="_blank"> MiVisionX设置</a></li><li id="aea8" class="mv mw iq lh b li ne lm nf lq ng lu nh ly ni mc na nb nc nd bi translated"><a class="ae md" href="https://gpuopen.com/compute-product/amd-openvx/" rel="noopener ugc nofollow" target="_blank"> AMD OpenVX </a></li><li id="efd6" class="mv mw iq lh b li ne lm nf lq ng lu nh ly ni mc na nb nc nd bi translated"><a class="ae md" href="https://www.toptal.com/deep-learning" rel="noopener ugc nofollow" target="_blank">深度学习专家</a></li></ol></div></div>    
</body>
</html>