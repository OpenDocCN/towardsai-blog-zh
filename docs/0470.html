<html>
<head>
<title>Linear Regression Explained</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">线性回归解释</h1>
<blockquote>原文：<a href="https://pub.towardsai.net/linear-regression-explained-f5cc85ae2c5c?source=collection_archive---------3-----------------------#2020-05-07">https://pub.towardsai.net/linear-regression-explained-f5cc85ae2c5c?source=collection_archive---------3-----------------------#2020-05-07</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><div class=""><h2 id="56b9" class="pw-subtitle-paragraph jn ip iq bd b jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke dk translated">尽可能简单地解释线性回归。</h2></div><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi kf"><img src="../Images/61ec282fb97e164e7cfd84bf7bc0a0f1.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*PzyYpZZnnk57RI85bVCFvw.png"/></div></div><figcaption class="kr ks gj gh gi kt ku bd b be z dk translated">由达克什·特里汉在canva.com设计</figcaption></figure><p id="f397" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">由于其基本性质，它通常是第一个被教授的机器学习算法。这是监督学习的一部分，意味着所需的数据将被标记。回归是指预测连续值。顾名思义，是线性模型；也就是说，它只能拟合线性数据点。有两种类型的线性回归:-简单和多重。</p><h1 id="d80b" class="lr ls iq bd lt lu lv lw lx ly lz ma mb jw mc jx md jz me ka mf kc mg kd mh mi bi translated">简单线性回归</h1><p id="b630" class="pw-post-body-paragraph kv kw iq kx b ky mj jr la lb mk ju ld le ml lg lh li mm lk ll lm mn lo lp lq ij bi translated">简单线性回归对于寻找两个连续变量之间的关系很有用。一个变量是因变量或可预测变量，另一个是自变量。</p><p id="c1a7" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">提供给模型的输入将是一个或多个特征，并且预测输出将是实数。</p><p id="0c42" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">核心思想是获得最适合数据的线。最佳拟合线是总预测误差(所有数据点)尽可能小的线。误差是点到回归线之间的距离，或者简单地说，是预测值和理论值之间的差异。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi mo"><img src="../Images/c20ed2730ab3e104c5aa85d5cdd2c910.png" data-original-src="https://miro.medium.com/v2/resize:fit:800/format:webp/0*_RYGlkVN4U-zzMXH.png"/></div><figcaption class="kr ks gj gh gi kt ku bd b be z dk translated">由达克什·特里汉在canva.com设计</figcaption></figure><p id="fe1c" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">线性回归最基本的例子是预测房价，作为输入，我们提供了不同的特征，如房间数量、面积。房子的面积，地区类型，便利性，等等，我们预计将根据输入的特征预测房子的价格。线性模型首先提醒我们的是一条直线，直线的方程式是</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi mp"><img src="../Images/dd7782b496a5079ea176cb32d92ec8e1.png" data-original-src="https://miro.medium.com/v2/resize:fit:304/format:webp/0*fG-P9aJSBu_T-mg8.png"/></div></figure><blockquote class="mq"><p id="0b7a" class="mr ms iq bd mt mu mv mw mx my mz lq dk translated">在哪里</p><p id="5de1" class="mr ms iq bd mt mu na nb nc nd ne lq dk translated">c =常数，m =斜率</p><p id="f772" class="mr ms iq bd mt mu na nb nc nd ne lq dk translated">x =独立特征，y=从属特征</p></blockquote><p id="889d" class="pw-post-body-paragraph kv kw iq kx b ky nf jr la lb ng ju ld le nh lg lh li ni lk ll lm nj lo lp lq ij bi translated">线性回归的整个概念是基于直线的方程。线性回归中直线的方程被认为是:</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi nk"><img src="../Images/6a5486fb107164ece9271f0741df8ef3.png" data-original-src="https://miro.medium.com/v2/resize:fit:398/format:webp/0*_CR9v-E1TuRZaJcq.png"/></div></figure><p id="c38c" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">该算法的目标是学习θ0、θ1和h(x)。</p><p id="48fb" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">该算法的步骤如下</p><ol class=""><li id="01a9" class="nl nm iq kx b ky kz lb lc le nn li no lm np lq nq nr ns nt bi translated"><em class="nu">随机初始化θ0&amp;θ1。</em></li><li id="a2bb" class="nl nm iq kx b ky nv lb nw le nx li ny lm nz lq nq nr ns nt bi translated"><em class="nu">衡量theta有多好，因为它是监督学习，所以我们将获得标记数据；因此，我们可以容易地得到使用均方误差J(θ)的算法所呈现的误差。</em></li></ol><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi oa"><img src="../Images/9fc80752934e657d90e382dd3587dbf0.png" data-original-src="https://miro.medium.com/v2/resize:fit:920/format:webp/0*n1mM2rz1Kbiifv6z.png"/></div></figure><blockquote class="ob oc od"><p id="938b" class="kv kw nu kx b ky kz jr la lb lc ju ld oe lf lg lh of lj lk ll og ln lo lp lq ij bi translated">我们用的是均方差，而不是模误差，因为它是不可微的；为了方便起见，整个误差除以2。</p></blockquote><p id="6ce5" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">3.<em class="nu">更新theta，使J(theta)减小，我们得到最佳直线。</em> <br/>为了得到最好的直线，我们将使用梯度下降算法。<br/>一旦我们得到满意的结果，也就是说，我们注意到误差被最小化了。我们将用相同的超参数更新θ0和θ1。</p><h1 id="840a" class="lr ls iq bd lt lu lv lw lx ly lz ma mb jw mc jx md jz me ka mf kc mg kd mh mi bi translated">成本函数J(θ)</h1><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi oh"><img src="../Images/b145726a26dc9aead67ea945b7ac983a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*x3cf40i-gCzFtV89.jpg"/></div></div><figcaption class="kr ks gj gh gi kt ku bd b be z dk translated">由达克什·特里汉在canva.com设计</figcaption></figure><p id="5b54" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">线性回归的成本函数为:-</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi oi"><img src="../Images/8120a5e68f86ad2e13956c28b5eca2d9.png" data-original-src="https://miro.medium.com/v2/resize:fit:518/format:webp/0*88kal7qpYSMzZO5R.png"/></div></figure><p id="11e8" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">为了更清楚，可以写成:-</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi oa"><img src="../Images/9fc80752934e657d90e382dd3587dbf0.png" data-original-src="https://miro.medium.com/v2/resize:fit:920/format:webp/0*n1mM2rz1Kbiifv6z.png"/></div></figure><p id="1911" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">这里的<em class="nu"> m </em>表示数据集中的样本总数。在我们的示例中，<em class="nu"> m </em>将是我们数据集中房屋的总数。</p><p id="9a50" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">现在我们的目标是降低我们的成本函数。这是尽可能精确拟合的损失。为此，我们将使用<a class="ae oj" href="https://www.youtube.com/watch?v=IHZwWFHWa-w" rel="noopener ugc nofollow" target="_blank">梯度下降算法</a>。</p><h1 id="91ee" class="lr ls iq bd lt lu lv lw lx ly lz ma mb jw mc jx md jz me ka mf kc mg kd mh mi bi translated">梯度下降</h1><p id="0eb6" class="pw-post-body-paragraph kv kw iq kx b ky mj jr la lb mk ju ld le ml lg lh li mm lk ll lm mn lo lp lq ij bi translated">这是机器学习以及深度学习中迄今为止最关键的算法。它用于通过用我们的成本函数对重量的偏导数减去损失来减少损失。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi ok"><img src="../Images/f4fec5d3a5dd6c151a13bf8fdc54cea8.png" data-original-src="https://miro.medium.com/v2/resize:fit:836/format:webp/0*1LCi6lqvo-vmq-68.png"/></div></figure><p id="785d" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">让我们想象梯度下降如何帮助我们最小化损失函数。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi ol"><img src="../Images/838883c5be6d699a1ec7a4b8fcfd5af3.png" data-original-src="https://miro.medium.com/v2/resize:fit:510/0*p7zWYGgXZ1OuTla6"/></div><figcaption class="kr ks gj gh gi kt ku bd b be z dk translated">来源:https://tinyurl.com/ycnh9o47<a class="ae oj" href="https://tinyurl.com/ycnh9o47" rel="noopener ugc nofollow" target="_blank"/></figcaption></figure><p id="22ca" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">我们的目标是达到局部最小值以减少损失。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi om"><img src="../Images/229d2c23f6b084010fb3099f9676a5c3.png" data-original-src="https://miro.medium.com/v2/resize:fit:1240/0*Fy0PIuh3dGM14tzE"/></div></div><figcaption class="kr ks gj gh gi kt ku bd b be z dk translated">来源:https://tinyurl.com/y9wwrmpd<a class="ae oj" href="https://tinyurl.com/y9wwrmpd" rel="noopener ugc nofollow" target="_blank"/></figcaption></figure><p id="913d" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">目前，我们的位置是红点，我们的目标是达到局部最小值。为了实现这一点，我们必须采取一些措施，这些措施由用户决定，并被描述为学习率(alpha)。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi om"><img src="../Images/07e1c38bac689735040e85cf771d70e9.png" data-original-src="https://miro.medium.com/v2/resize:fit:1240/0*PdWCiPqSlywfk4qi"/></div></div><figcaption class="kr ks gj gh gi kt ku bd b be z dk translated">来源:<a class="ae oj" href="https://tinyurl.com/y9wwrmpd" rel="noopener ugc nofollow" target="_blank">https://tinyurl.com/y9wwrmpd</a></figcaption></figure><p id="029d" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">一旦我们开始训练，我们可以想象损失，以确认我们正在朝着正确的方向采取措施，并且我们正在获得想要的结果。一旦确认，我们将重复这些步骤，直到满意为止。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi on"><img src="../Images/696318167cd7c2cc2b428384ec82f682.png" data-original-src="https://miro.medium.com/v2/resize:fit:1054/0*-eyiy0HLExVRtfXZ"/></div><figcaption class="kr ks gj gh gi kt ku bd b be z dk translated">来源:<a class="ae oj" href="https://tinyurl.com/y9wwrmpd" rel="noopener ugc nofollow" target="_blank">https://tinyurl.com/y9wwrmpd</a></figcaption></figure><p id="3e85" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">一旦我们到达局部极小值，这意味着我们已经完成了我们的目标，损失现在是衰减的。我们可以期待我们的模型有更好的准确性。</p><h1 id="5280" class="lr ls iq bd lt lu lv lw lx ly lz ma mb jw mc jx md jz me ka mf kc mg kd mh mi bi translated">最终模型</h1><p id="06dc" class="pw-post-body-paragraph kv kw iq kx b ky mj jr la lb mk ju ld le ml lg lh li mm lk ll lm mn lo lp lq ij bi translated">一旦我们的成本函数被定义，我们执行梯度下降算法以最小化损失，并且我们继续重复直到我们到达局部最小值。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi oo"><img src="../Images/ca25845b58715c2ff9cb5ae93cbfb920.png" data-original-src="https://miro.medium.com/v2/resize:fit:830/format:webp/0*VdKe72191jlavB5H.jpg"/></div></div></figure><p id="ce4d" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">其中n(α)是学习速率，即在减少损失时要采取的步长。<br/>现在，我们算法的输出将是房屋的价格，这取决于θ0(常数)和θ1。现在把它和现实生活联系起来，所以简而言之</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi om"><img src="../Images/68bb37e22748993a90b03759e71003a9.png" data-original-src="https://miro.medium.com/v2/resize:fit:1240/format:webp/0*hUp_0pfvR1htUe44.png"/></div></figure><h2 id="7f92" class="op ls iq bd lt oq or dn lx os ot dp mb le ou ov md li ow ox mf lm oy oz mh pa bi translated">多元线性回归</h2><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi pb"><img src="../Images/751b8baa2c924f24be93757da0867b42.png" data-original-src="https://miro.medium.com/v2/resize:fit:1276/format:webp/0*KETfgqVrmA5ch_FZ.png"/></div><figcaption class="kr ks gj gh gi kt ku bd b be z dk translated">由达克什·特里汉在canva.com设计</figcaption></figure><p id="955c" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">当我们希望根据两个或更多变量来预测变量的值时，可以使用多元线性回归。</p><p id="344b" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">假设如果房子的价格也取决于房间的数量以及房子的大小，那么我们将实现多元线性回归，这与普通的线性回归没有太大的不同。</p><h2 id="bfad" class="op ls iq bd lt oq or dn lx os ot dp mb le ou ov md li ow ox mf lm oy oz mh pa bi translated">实现与我们的模型完美契合的方法</h2><p id="0f81" class="pw-post-body-paragraph kv kw iq kx b ky mj jr la lb mk ju ld le ml lg lh li mm lk ll lm mn lo lp lq ij bi translated">实施线性回归时要记住的另一件重要事情是仔细决定超参数，即n(学习率)。</p><blockquote class="mq"><p id="3f78" class="mr ms iq bd mt mu na nb nc nd ne lq dk translated">如果n很小，步数越多，训练越慢。</p><p id="bfc0" class="mr ms iq bd mt mu na nb nc nd ne lq dk translated">如果n大，步数少，训练快。</p><p id="d0b1" class="mr ms iq bd mt mu na nb nc nd ne lq dk translated">如果n非常大，它会振荡，不会有输出。</p></blockquote><figure class="pd pe pf pg ph kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi pc"><img src="../Images/25874427efa1043a25e2a746f52f18ed.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*hCfMrji7HnAFhIhc.png"/></div></div><figcaption class="kr ks gj gh gi kt ku bd b be z dk translated">来源:https://algorithmia.com/blog/introduction-to-optimizers</figcaption></figure><p id="5b43" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">我们可以通过使模型复杂化来避免过度拟合，也就是说，给我们的模型增加更多的特征。例如，如果我们的模型的方程是y =θ0+θ1(x)，使它成为y =θ0+θ1(x)+θ2(x)+θ3(x)…</p><p id="de26" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">关于选择超参数的更详细的解释如下:<a class="ae oj" href="https://medium.com/datadriveninvestor/determining-perfect-fit-for-your-ml-model-339459eef670" rel="noopener">确定最适合你的ML模型。</a></p><p id="96b1" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">线性回归的一些关键特征:-</p><ol class=""><li id="0f17" class="nl nm iq kx b ky kz lb lc le nn li no lm np lq nq nr ns nt bi translated">目标是一个区间变量。</li><li id="1950" class="nl nm iq kx b ky nv lb nw le nx li ny lm nz lq nq nr ns nt bi translated">预测值是目标变量的平均值。</li></ol><h2 id="1ff9" class="op ls iq bd lt oq or dn lx os ot dp mb le ou ov md li ow ox mf lm oy oz mh pa bi translated">使用Sci-kit学习线性回归的代码。</h2><p id="477c" class="pw-post-body-paragraph kv kw iq kx b ky mj jr la lb mk ju ld le ml lg lh li mm lk ll lm mn lo lp lq ij bi translated">当使用框架作为sci-kit learn时，我们不需要太关注要初始化的错误或其他值。框架已经选择了它们，但是了解算法背后的数学部分是很好的。</p><p id="7b43" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">对于从头开始线性回归代码，请遵循:-</p><div class="pi pj gp gr pk pl"><a href="https://github.com/dakshtrehan/machine-learning-online-2018/blob/master/3.%20Linear%20Regression/Linear%20Regression/02_Linear_Regression.ipynb" rel="noopener  ugc nofollow" target="_blank"><div class="pm ab fo"><div class="pn ab po cl cj pp"><h2 class="bd ir gy z fp pq fr fs pr fu fw ip bi translated">dakshtrehan/机器学习-在线-2018</h2><div class="ps l"><h3 class="bd b gy z fp pq fr fs pr fu fw dk translated">permalink dissolve GitHub是4000多万开发人员的家园，他们一起工作来托管和审查代码，管理…</h3></div><div class="pt l"><p class="bd b dl z fp pq fr fs pr fu fw dk translated">github.com</p></div></div><div class="pu l"><div class="pv l pw px py pu pz kp pl"/></div></div></a></div><h1 id="78a5" class="lr ls iq bd lt lu lv lw lx ly lz ma mb jw mc jx md jz me ka mf kc mg kd mh mi bi translated">结论</h1><p id="8c43" class="pw-post-body-paragraph kv kw iq kx b ky mj jr la lb mk ju ld le ml lg lh li mm lk ll lm mn lo lp lq ij bi translated">希望这篇文章不仅增加了你对线性回归的理解，还让你意识到机器学习并不难，并且已经在你的日常生活中发生了。</p><p id="f222" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">一如既往，非常感谢您的阅读，如果您觉得这篇文章有用，请分享！:)</p></div><div class="ab cl qa qb hu qc" role="separator"><span class="qd bw bk qe qf qg"/><span class="qd bw bk qe qf qg"/><span class="qd bw bk qe qf"/></div><div class="ij ik il im in"><p id="c618" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">查看我的其他文章:-</p><p id="f714" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated"><a class="ae oj" href="https://towardsdatascience.com/detecting-covid-19-using-deep-learning-262956b6f981" rel="noopener" target="_blank">利用深度学习检测新冠肺炎。</a></p><p id="5979" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated"><a class="ae oj" href="https://medium.com/datadriveninvestor/determining-perfect-fit-for-your-ml-model-339459eef670" rel="noopener">确定最适合您的ML模型。</a></p><p id="c2d9" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated"><a class="ae oj" href="https://medium.com/towards-artificial-intelligence/serving-data-science-to-a-rookie-b03af9ea99a2" rel="noopener">为菜鸟服务数据科学。</a></p><p id="b296" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated"><a class="ae oj" href="https://levelup.gitconnected.com/relating-machine-learning-techniques-to-real-life-4dafd626fdff" rel="noopener ugc nofollow" target="_blank">将机器学习技术与现实生活联系起来。</a></p><p id="562f" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">请随意连接:</p><blockquote class="ob oc od"><p id="f711" class="kv kw nu kx b ky kz jr la lb lc ju ld oe lf lg lh of lj lk ll og ln lo lp lq ij bi translated">作品集~<a class="ae oj" href="http://dakshtrehan.com" rel="noopener ugc nofollow" target="_blank">dakshtrehan.com</a></p><p id="8f22" class="kv kw nu kx b ky kz jr la lb lc ju ld oe lf lg lh of lj lk ll og ln lo lp lq ij bi translated"><em class="iq">LinkedIN ~</em><a class="ae oj" href="https://www.linkedin.com/in/dakshtrehan/" rel="noopener ugc nofollow" target="_blank"><em class="iq">https://www.linkedin.com/in/dakshtrehan/</em></a></p><p id="e470" class="kv kw nu kx b ky kz jr la lb lc ju ld oe lf lg lh of lj lk ll og ln lo lp lq ij bi translated"><em class="iq">insta gram ~</em><a class="ae oj" href="https://www.instagram.com/_daksh_trehan_/" rel="noopener ugc nofollow" target="_blank"><em class="iq">https://www.instagram.com/_daksh_trehan_/</em></a></p><p id="de7a" class="kv kw nu kx b ky kz jr la lb lc ju ld oe lf lg lh of lj lk ll og ln lo lp lq ij bi translated"><em class="iq">Github ~</em><a class="ae oj" href="https://github.com/dakshtrehan" rel="noopener ugc nofollow" target="_blank">T3】https://github.com/dakshtrehanT5】</a></p></blockquote><p id="a860" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">关注更多机器学习/深度学习博客。</p><blockquote class="ob oc od"><p id="9065" class="kv kw nu kx b ky kz jr la lb lc ju ld oe lf lg lh of lj lk ll og ln lo lp lq ij bi translated"><em class="iq">干杯。</em></p></blockquote></div></div>    
</body>
</html>