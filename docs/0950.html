<html>
<head>
<title>Deep Learning (CNN) — Discover the Breed of a Dog in an Image</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">深度学习(CNN)——在图像中发现狗的品种</h1>
<blockquote>原文：<a href="https://pub.towardsai.net/deep-learning-cnn-discover-the-breed-of-a-dog-in-an-image-f885dffaa4d0?source=collection_archive---------4-----------------------#2020-09-19">https://pub.towardsai.net/deep-learning-cnn-discover-the-breed-of-a-dog-in-an-image-f885dffaa4d0?source=collection_archive---------4-----------------------#2020-09-19</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><h2 id="76c3" class="io ip iq bd b dl ir is it iu iv iw dk ix translated" aria-label="kicker paragraph"><a class="ae ep" href="https://towardsai.net/p/category/machine-learning/deep-learning" rel="noopener ugc nofollow" target="_blank">深度学习</a></h2><div class=""/><h1 id="5cd1" class="jw jx iq bd jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt bi translated">介绍</h1><p id="e988" class="pw-post-body-paragraph ku kv iq kw b kx ky kz la lb lc ld le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">卷积神经网络(CNN)是深度学习网络，在图像的对象识别方面表现出色。它的设计灵感来自大脑中被称为视觉皮层的部分。视觉皮层的作用是处理视觉数据。它对高级人工智能产生了许多奇妙的影响，特别是在图像分类问题上取得了巨大的成功。</p><p id="79ba" class="pw-post-body-paragraph ku kv iq kw b kx ls kz la lb lt ld le lf lu lh li lj lv ll lm ln lw lp lq lr ij bi translated">在学习CNN之前，理解图像识别中的基本概念是非常重要的:</p><ul class=""><li id="ac43" class="lx ly iq kw b kx ls lb lt lf lz lj ma ln mb lr mc md me mf bi translated">特征检测</li><li id="15a0" class="lx ly iq kw b kx mg lb mh lf mi lj mj ln mk lr mc md me mf bi translated">盘旋</li></ul><h1 id="1f1c" class="jw jx iq bd jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt bi translated">特征检测</h1><p id="fbe3" class="pw-post-body-paragraph ku kv iq kw b kx ky kz la lb lc ld le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">图像由许多小方块组成的网格组成。这叫做像素。每个像素都与[0–225]范围内的一个值相关联，其中0表示黑色，255表示白色。最后，彩色图像由一组三个度量表示，每个度量对应一个颜色通道(红、绿、蓝)。这种表示如下所示:</p><figure class="mm mn mo mp gt mq gh gi paragraph-image"><div class="gh gi ml"><img src="../Images/064a9ed2ad2c791828f62ca397c211a1.png" data-original-src="https://miro.medium.com/v2/resize:fit:1372/0*lC1rQFDN0RgkL0Dh"/></div></figure><p id="f272" class="pw-post-body-paragraph ku kv iq kw b kx ls kz la lb lt ld le lf lu lh li lj lv ll lm ln lw lp lq lr ij bi translated">因此，它创建了一个称为核过滤器或特征检测器的矩阵。</p><h1 id="cffc" class="jw jx iq bd jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt bi translated">盘旋</h1><p id="1a7e" class="pw-post-body-paragraph ku kv iq kw b kx ky kz la lb lc ld le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">在数学中，尤其是在泛函分析中，卷积是对两个函数的数学运算，它产生第三个函数，并在其他函数用药的情况下告知其中一个函数的形状。因此，核滤波器沿着输入矩阵移动，并在核值和它所应用的矩阵部分的值之间执行标量积。这个结果是一个新的矩阵，称为卷积矩阵。</p><figure class="mm mn mo mp gt mq gh gi paragraph-image"><div class="gh gi mt"><img src="../Images/fa7bfd43a6569ebc9d28426039eb4e65.png" data-original-src="https://miro.medium.com/v2/resize:fit:950/0*L3Je9Xh-WAIQjHmy"/></div></figure><h1 id="b760" class="jw jx iq bd jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt bi translated">CNN架构</h1><p id="c363" class="pw-post-body-paragraph ku kv iq kw b kx ky kz la lb lc ld le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">我们取一张黑白图像(5*5矩阵)，输入矩阵为5*5。所以，这里CNN是由25个神经元组成的输入层(5*5 = 25)。其主要目的是获取对应于每个像素的输入值，并将其传递到下一个隐藏层。</p><p id="c728" class="pw-post-body-paragraph ku kv iq kw b kx ls kz la lb lt ld le lf lu lh li lj lv ll lm ln lw lp lq lr ij bi translated">在CNN中，每个神经元都连接到输入区的某个区域，该区域称为感受野。为了有效地识别图像，我们需要将不同的核滤波器应用于同一个感受野，因为每个滤波器应该识别不同特征的图像。识别相同特征的神经元集合定义了单个特征图。</p><figure class="mm mn mo mp gt mq gh gi paragraph-image"><div role="button" tabindex="0" class="mv mw di mx bf my"><div class="gh gi mu"><img src="../Images/8e0fb03e3b5208e980598f577323bf83.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*I1XEmHDKDZ6FKWcS"/></div></div><figcaption class="mz na gj gh gi nb nc bd b be z dk translated">CNN架构</figcaption></figure><p id="f34a" class="pw-post-body-paragraph ku kv iq kw b kx ls kz la lb lt ld le lf lu lh li lj lv ll lm ln lw lp lq lr ij bi translated">这张图片代表了CNN的架构。这里图像的输入尺寸是28*28，并且将由尺寸为28*28的32个特征图组成的卷积层来分析。</p><p id="f8e0" class="pw-post-body-paragraph ku kv iq kw b kx ls kz la lb lt ld le lf lu lh li lj lv ll lm ln lw lp lq lr ij bi translated">该体系结构还显示了感受野和3*3大小的内核过滤器。</p><p id="273b" class="pw-post-body-paragraph ku kv iq kw b kx ls kz la lb lt ld le lf lu lh li lj lv ll lm ln lw lp lq lr ij bi translated">CNN可以由级联的几个卷积层组成。每个卷积层的输出是一组特征图，所有这些矩阵定义了一个新的输入层，将被下一层使用。</p><p id="ccd9" class="pw-post-body-paragraph ku kv iq kw b kx ls kz la lb lt ld le lf lu lh li lj lv ll lm ln lw lp lq lr ij bi translated">在CNN中，每个神经元在激活阈值之后产生一个输出。CNN还使用位于卷积层之后的池层。</p><p id="1055" class="pw-post-body-paragraph ku kv iq kw b kx ls kz la lb lt ld le lf lu lh li lj lv ll lm ln lw lp lq lr ij bi translated">卷积网络的最后一个隐藏层通常是全连接网络，其输出层具有softmax激活功能。</p><h1 id="7846" class="jw jx iq bd jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt bi translated">利用CNN进行犬种识别</h1><p id="9c2a" class="pw-post-body-paragraph ku kv iq kw b kx ky kz la lb lc ld le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">美国有线电视新闻网可以很容易地识别好小狗的类型，品种等。</p><h1 id="3f72" class="jw jx iq bd jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt bi translated">构建数据集</h1><p id="d667" class="pw-post-body-paragraph ku kv iq kw b kx ky kz la lb lc ld le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">数据集:</p><ul class=""><li id="81cd" class="lx ly iq kw b kx ls lb lt lf lz lj ma ln mb lr mc md me mf bi translated">测试:-狗的图像</li><li id="309f" class="lx ly iq kw b kx mg lb mh lf mi lj mj ln mk lr mc md me mf bi translated">训练:-不同狗的图像</li><li id="0998" class="lx ly iq kw b kx mg lb mh lf mi lj mj ln mk lr mc md me mf bi translated">label.csv:-不同类型的品种</li></ul><pre class="mm mn mo mp gt nd ne nf ng aw nh bi"><span id="471d" class="ni jx iq ne b gy nj nk l nl nm">import os<br/>import seaborn as sns<br/>import matplotlib<br/>from shutil import copyfile<br/>import matplotlib.pyplot as plt</span></pre><p id="f79a" class="pw-post-body-paragraph ku kv iq kw b kx ls kz la lb lt ld le lf lu lh li lj lv ll lm ln lw lp lq lr ij bi translated">读取品种标签数据:</p><pre class="mm mn mo mp gt nd ne nf ng aw nh bi"><span id="4119" class="ni jx iq ne b gy nj nk l nl nm">labels = pd.read_csv('labels.csv')</span><span id="1f09" class="ni jx iq ne b gy nn nk l nl nm">labels.head()</span></pre><figure class="mm mn mo mp gt mq gh gi paragraph-image"><div class="gh gi no"><img src="../Images/d4af4b371ab7cb7622c8e64a4fc4625c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1074/0*8y9eWqnal23VD4to"/></div></figure><p id="204e" class="pw-post-body-paragraph ku kv iq kw b kx ls kz la lb lt ld le lf lu lh li lj lv ll lm ln lw lp lq lr ij bi translated">将品种分成不同的类别:</p><pre class="mm mn mo mp gt nd ne nf ng aw nh bi"><span id="c7c1" class="ni jx iq ne b gy nj nk l nl nm">labels_dict = {i:j for i,j in zip(labels['id'],labels['breed'])}</span><span id="744a" class="ni jx iq ne b gy nn nk l nl nm">classes = set(labels_dict.values())</span><span id="c592" class="ni jx iq ne b gy nn nk l nl nm">classes</span></pre><p id="150a" class="pw-post-body-paragraph ku kv iq kw b kx ls kz la lb lt ld le lf lu lh li lj lv ll lm ln lw lp lq lr ij bi translated">获取狗的所有训练图像:</p><pre class="mm mn mo mp gt nd ne nf ng aw nh bi"><span id="15c7" class="ni jx iq ne b gy nj nk l nl nm">images = [f for f in os.listdir('train/')]</span></pre><p id="1685" class="pw-post-body-paragraph ku kv iq kw b kx ls kz la lb lt ld le lf lu lh li lj lv ll lm ln lw lp lq lr ij bi translated">将训练图像拆分为训练图像和验证图像:</p><pre class="mm mn mo mp gt nd ne nf ng aw nh bi"><span id="ea45" class="ni jx iq ne b gy nj nk l nl nm">split = int(len(images) * 0.85)</span><span id="42fc" class="ni jx iq ne b gy nn nk l nl nm">training_images = images[:split]</span><span id="6787" class="ni jx iq ne b gy nn nk l nl nm">validation_images  = images[split:]</span></pre><p id="ed6b" class="pw-post-body-paragraph ku kv iq kw b kx ls kz la lb lt ld le lf lu lh li lj lv ll lm ln lw lp lq lr ij bi translated">将training_images和validation_images保存在两个单独的目录中:</p><pre class="mm mn mo mp gt nd ne nf ng aw nh bi"><span id="e17e" class="ni jx iq ne b gy nj nk l nl nm">if  not os.path.exists('training_images'):<br/>        os.makedirs('training_images')</span><span id="22b8" class="ni jx iq ne b gy nn nk l nl nm">if  not os.path.exists('validation_images'):<br/>         os.makedirs('validation_images')</span></pre><p id="0f73" class="pw-post-body-paragraph ku kv iq kw b kx ls kz la lb lt ld le lf lu lh li lj lv ll lm ln lw lp lq lr ij bi translated">为training_images创建类的子目录:</p><pre class="mm mn mo mp gt nd ne nf ng aw nh bi"><span id="43fd" class="ni jx iq ne b gy nj nk l nl nm">for curClass in classes:<br/>     if  not os.path.exists(os.path.join('training_images', curClass)):<br/>          os.makedirs(os.path.join('training_images', curClass))</span></pre><p id="1676" class="pw-post-body-paragraph ku kv iq kw b kx ls kz la lb lt ld le lf lu lh li lj lv ll lm ln lw lp lq lr ij bi translated">为validation_images创建类的子目录:</p><pre class="mm mn mo mp gt nd ne nf ng aw nh bi"><span id="31a1" class="ni jx iq ne b gy nj nk l nl nm">for curClass in classes:<br/>     if  not os.path.exists(os.path.join('validation_images', curClass)):<br/>          os.makedirs(os.path.join('validation_images', curClass))</span></pre><p id="855d" class="pw-post-body-paragraph ku kv iq kw b kx ls kz la lb lt ld le lf lu lh li lj lv ll lm ln lw lp lq lr ij bi translated">将分割的图像保存在两个不同的目录中:</p><pre class="mm mn mo mp gt nd ne nf ng aw nh bi"><span id="30c4" class="ni jx iq ne b gy nj nk l nl nm">count = 0</span><span id="0899" class="ni jx iq ne b gy nn nk l nl nm">destination_directory = 'training_images/'</span><span id="8876" class="ni jx iq ne b gy nn nk l nl nm">for item in images:<br/>   if count &gt;7999:<br/>        destination_directory = 'validation_images/'<br/>    filekey = os.path.splitext(item)[0]<br/>    des = destination_directory + labels_dict[filekey]+'/'+item<br/>    print(des)<br/>    if  not os.path.exists(des):<br/>        src = '/kaggle/input/dog-breed-identification/train/' + item<br/>        copyfile(src, des)<br/>    print(labels_dict[filekey])<br/>    count +=1</span></pre><figure class="mm mn mo mp gt mq gh gi paragraph-image"><div class="gh gi np"><img src="../Images/acc2bea1d8bae059c39b4f89c89d45b7.png" data-original-src="https://miro.medium.com/v2/resize:fit:1280/0*8DxxECqqOUeV4HVb"/></div></figure><h1 id="fd08" class="jw jx iq bd jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt bi translated">预处理</h1><p id="9cad" class="pw-post-body-paragraph ku kv iq kw b kx ky kz la lb lc ld le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">导入Keras的预处理库:</p><pre class="mm mn mo mp gt nd ne nf ng aw nh bi"><span id="5caa" class="ni jx iq ne b gy nj nk l nl nm">from keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img</span><span id="ad93" class="ni jx iq ne b gy nn nk l nl nm">datagen = ImageDataGenerator(<br/>        rotation_range=50,<br/>        width_shift_range=0.3,<br/>        height_shift_range=0.2,<br/>        shear_range=0.3,<br/>        zoom_range=0.3,<br/>        horizontal_flip=True,<br/>        fill_mode='nearest')</span></pre><p id="7b2f" class="pw-post-body-paragraph ku kv iq kw b kx ls kz la lb lt ld le lf lu lh li lj lv ll lm ln lw lp lq lr ij bi translated">转换为数组:</p><pre class="mm mn mo mp gt nd ne nf ng aw nh bi"><span id="83cb" class="ni jx iq ne b gy nj nk l nl nm">x = img_to_array(img)</span><span id="5190" class="ni jx iq ne b gy nn nk l nl nm">x = x.reshape((1,) + x.shape)</span></pre><p id="56dd" class="pw-post-body-paragraph ku kv iq kw b kx ls kz la lb lt ld le lf lu lh li lj lv ll lm ln lw lp lq lr ij bi translated">导入更多库:</p><pre class="mm mn mo mp gt nd ne nf ng aw nh bi"><span id="0f34" class="ni jx iq ne b gy nj nk l nl nm">from keras.preprocessing.image import ImageDataGenerator<br/>from keras.models import Sequential<br/>from keras.layers import Convolution2D<br/>from keras.layers import MaxPooling2D<br/>from keras.layers import Flatten<br/>from keras.layers import Dense</span><span id="6259" class="ni jx iq ne b gy nn nk l nl nm">from keras.layers import Conv2D,Dropout</span><span id="f976" class="ni jx iq ne b gy nn nk l nl nm">from keras.preprocessing.image import ImageDataGenerator</span><span id="c9f3" class="ni jx iq ne b gy nn nk l nl nm">train_datagen = ImageDataGenerator(<br/>        rescale=1./255,<br/>        shear_range=0.2,<br/>        zoom_range=0.2,<br/>        horizontal_flip=True)</span><span id="aaf7" class="ni jx iq ne b gy nn nk l nl nm">test_datagen = ImageDataGenerator(rescale=1./255)</span><span id="ba9c" class="ni jx iq ne b gy nn nk l nl nm">training_set = train_datagen.flow_from_directory(<br/>        'training_images',<br/>        target_size=(128, 128),<br/>        batch_size=20,<br/>        class_mode='categorical')</span><span id="6ffd" class="ni jx iq ne b gy nn nk l nl nm">test_datagen = ImageDataGenerator(rescale=1./255)</span><span id="8559" class="ni jx iq ne b gy nn nk l nl nm">training_set = train_datagen.flow_from_directory(<br/>        'training_images',<br/>        target_size=(128, 128),<br/>        batch_size=20,<br/>        class_mode='categorical')</span><span id="e627" class="ni jx iq ne b gy nn nk l nl nm">test_set = test_datagen.flow_from_directory(<br/>        'validation_images',<br/>        target_size=(128, 128),<br/>        batch_size=20,<br/>        class_mode='categorical')</span></pre><h1 id="23b0" class="jw jx iq bd jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt bi translated">构建层</h1><pre class="mm mn mo mp gt nd ne nf ng aw nh bi"><span id="77c8" class="ni jx iq ne b gy nj nk l nl nm">from keras.layers import Dropout<br/>clf = Sequential()<br/>#Convolution<br/>#32 is number of kernals of 3x3, we can use 64 128 256 etc in next layers<br/>#input shape can be 128, 256 later<br/>clf.add(Conv2D(32,(3,3),input_shape=(128,128,3),activation='relu'))<br/>#Max Pooling size reduces divided by 2<br/>clf.add(MaxPooling2D(pool_size=(2,2)))</span><span id="0990" class="ni jx iq ne b gy nn nk l nl nm">#clf.add(Dropout(0.5))</span><span id="deba" class="ni jx iq ne b gy nn nk l nl nm">clf.add(Conv2D(32,(3,3), activation='relu'))<br/>clf.add(MaxPooling2D(pool_size=(2,2)))<br/>#clf.add(Dropout(0.25))</span><span id="03d1" class="ni jx iq ne b gy nn nk l nl nm">clf.add(Conv2D(64, (3, 3), activation='relu'))<br/>clf.add(MaxPooling2D(pool_size=(2, 2)))<br/>#clf.add(Dropout(0.10))<br/>#Flattening<br/>clf.add(Flatten())<br/>        <br/>#Adding An ANN<br/>#lets take 128 hidden nodes in hidden layer<br/>#clf.add(Dense(units=128,activation='relu'))<br/>clf.add(Dense(units=64, activation='relu'))<br/>clf.add(Dropout(0.5))<br/>clf.add(Dense(units=120,activation='softmax'))<br/>#stochastic gradient descent -Adam -optimizer</span><span id="1379" class="ni jx iq ne b gy nn nk l nl nm">clf.compile(optimizer='adam',loss='categorical_crossentropy',metrics=['accuracy'])</span></pre><p id="27a6" class="pw-post-body-paragraph ku kv iq kw b kx ls kz la lb lt ld le lf lu lh li lj lv ll lm ln lw lp lq lr ij bi translated">添加提前停止:</p><pre class="mm mn mo mp gt nd ne nf ng aw nh bi"><span id="5515" class="ni jx iq ne b gy nj nk l nl nm">from keras.callbacks import EarlyStopping</span><span id="f56d" class="ni jx iq ne b gy nn nk l nl nm">early_stopping_monitor=EarlyStopping(patience=6)</span></pre><p id="63e9" class="pw-post-body-paragraph ku kv iq kw b kx ls kz la lb lt ld le lf lu lh li lj lv ll lm ln lw lp lq lr ij bi translated">安装发电机:</p><pre class="mm mn mo mp gt nd ne nf ng aw nh bi"><span id="9ab5" class="ni jx iq ne b gy nj nk l nl nm">hist=clf.fit_generator(<br/>        training_set,<br/>        steps_per_epoch=400,<br/>        epochs=50,<br/>        validation_data=test_set,<br/>        validation_steps=2222,<br/>callbacks=[early_stopping_monitor])</span></pre><figure class="mm mn mo mp gt mq gh gi paragraph-image"><div role="button" tabindex="0" class="mv mw di mx bf my"><div class="gh gi nq"><img src="../Images/00af81bb93c1244a6e6ce928e764f771.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*WoGtmVzUo6CkHR1V"/></div></div></figure><h1 id="1aec" class="jw jx iq bd jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt bi translated">预测</h1><p id="53fa" class="pw-post-body-paragraph ku kv iq kw b kx ky kz la lb lc ld le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">导入测试数据进行预测。</p><pre class="mm mn mo mp gt nd ne nf ng aw nh bi"><span id="d26f" class="ni jx iq ne b gy nj nk l nl nm">import cv2</span><span id="352b" class="ni jx iq ne b gy nn nk l nl nm">test_set = []</span><span id="14f5" class="ni jx iq ne b gy nn nk l nl nm">test_set_ids = []</span><span id="fd78" class="ni jx iq ne b gy nn nk l nl nm">for curImage in os.listdir('/kaggle/input/dog-breed-identification/test'):<br/>    test_set_ids.append(os.path.splitext(curImage)[0])<br/>    curImage = cv2.imread('/kaggle/input/dog-breed-identification/test/'+curImage)<br/>    <br/>    test_set.append(cv2.resize(curImage,(128, 128)))</span><span id="2a00" class="ni jx iq ne b gy nn nk l nl nm">test_set = np.array(test_set, np.float32)/255.0</span></pre><p id="64c6" class="pw-post-body-paragraph ku kv iq kw b kx ls kz la lb lt ld le lf lu lh li lj lv ll lm ln lw lp lq lr ij bi translated">预测:</p><pre class="mm mn mo mp gt nd ne nf ng aw nh bi"><span id="db86" class="ni jx iq ne b gy nj nk l nl nm">predictions= clf.predict(test_set)</span></pre><p id="e957" class="pw-post-body-paragraph ku kv iq kw b kx ls kz la lb lt ld le lf lu lh li lj lv ll lm ln lw lp lq lr ij bi translated">将预测数据与测试数据对应起来:</p><pre class="mm mn mo mp gt nd ne nf ng aw nh bi"><span id="560d" class="ni jx iq ne b gy nj nk l nl nm">predictions_df = pd.DataFrame(predictions)</span><span id="29c3" class="ni jx iq ne b gy nn nk l nl nm">predictions_df.columns = column_names</span><span id="65b6" class="ni jx iq ne b gy nn nk l nl nm">predictions_df.insert(0,'id', test_set_ids)</span><span id="be90" class="ni jx iq ne b gy nn nk l nl nm">predictions_df</span></pre><figure class="mm mn mo mp gt mq gh gi paragraph-image"><div role="button" tabindex="0" class="mv mw di mx bf my"><div class="gh gi nr"><img src="../Images/9912284094f341e760c1e8bbc2bbe8be.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*XHFq0yE4786v1hOv"/></div></div></figure><h1 id="888f" class="jw jx iq bd jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt bi translated">情节</h1><p id="bb29" class="pw-post-body-paragraph ku kv iq kw b kx ky kz la lb lc ld le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">验证损失与时代:</p><pre class="mm mn mo mp gt nd ne nf ng aw nh bi"><span id="4ac8" class="ni jx iq ne b gy nj nk l nl nm">plt.plot(hist.history['val_loss'])</span><span id="5680" class="ni jx iq ne b gy nn nk l nl nm">plt.xlabel('epochs')</span><span id="b955" class="ni jx iq ne b gy nn nk l nl nm">plt.ylabel('validation loss')</span><span id="d3e3" class="ni jx iq ne b gy nn nk l nl nm">plt.show()</span></pre><figure class="mm mn mo mp gt mq gh gi paragraph-image"><div class="gh gi ns"><img src="../Images/ddd06c91fff93f8775fd3397fa2632fa.png" data-original-src="https://miro.medium.com/v2/resize:fit:1004/0*OOODK3MJepUg9pSM"/></div></figure><p id="ebed" class="pw-post-body-paragraph ku kv iq kw b kx ls kz la lb lt ld le lf lu lh li lj lv ll lm ln lw lp lq lr ij bi translated">培训损失与验证损失:</p><pre class="mm mn mo mp gt nd ne nf ng aw nh bi"><span id="c97f" class="ni jx iq ne b gy nj nk l nl nm">plt.plot(hist.history['loss'],label="traing loss")</span><span id="4f2c" class="ni jx iq ne b gy nn nk l nl nm">plt.plot(hist.history['val_loss'], label="Validation loss")</span><span id="bdfd" class="ni jx iq ne b gy nn nk l nl nm">plt.legend()</span><span id="6549" class="ni jx iq ne b gy nn nk l nl nm">plt.xlabel('epochs')</span><span id="3c4c" class="ni jx iq ne b gy nn nk l nl nm">plt.show()</span></pre><figure class="mm mn mo mp gt mq gh gi paragraph-image"><div class="gh gi nt"><img src="../Images/df016e119878258dab776073eeaddf26.png" data-original-src="https://miro.medium.com/v2/resize:fit:982/0*q2bwdtT9Hs_UTmWW"/></div></figure><h1 id="6512" class="jw jx iq bd jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt bi translated">结论</h1><p id="03cf" class="pw-post-body-paragraph ku kv iq kw b kx ky kz la lb lc ld le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">卷积神经网络的设计灵感来自视觉皮层——大脑中处理视觉输入的区域。可以肯定地说，CNN正在支撑人工智能和机器学习领域许多最具影响力的最新进展。CNN的变体被应用于现存的一些最复杂的视觉、语言和解决问题的应用程序中。</p></div></div>    
</body>
</html>