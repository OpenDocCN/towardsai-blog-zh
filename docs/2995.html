<html>
<head>
<title>Monkey Pox Detection from Images</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">从图像中检测猴痘</h1>
<blockquote>原文：<a href="https://pub.towardsai.net/monkey-pox-detection-from-images-33d6fc39dbff?source=collection_archive---------1-----------------------#2022-07-28">https://pub.towardsai.net/monkey-pox-detection-from-images-33d6fc39dbff?source=collection_archive---------1-----------------------#2022-07-28</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="b93f" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">世界卫生组织宣布猴痘为全球卫生紧急事件</h2></div><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ki"><img src="../Images/d3d37b63f63e60075f5006ea7e6e8a47.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*POGdoG6G5T4FhIP3_AWoeg.jpeg"/></div></div></figure><p id="7fec" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">有不同种类的痘——水痘、天花、麻疹，现在还有猴痘。这将是有趣的，看看我们有多少数据可用于不同类型的痘和训练模型，使它们能够从图像中检测痘类型。</p><p id="1503" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated"><strong class="kw iu">使用的深度学习库:Pytorch </strong></p><p id="ec12" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated"><strong class="kw iu"> Github资源库:</strong> <a class="ae lq" href="https://github.com/ashhadulislam/train-pox-detector" rel="noopener ugc nofollow" target="_blank"> <strong class="kw iu">链接</strong> </a></p><h1 id="fdd3" class="lr ls it bd lt lu lv lw lx ly lz ma mb jz mc ka md kc me kd mf kf mg kg mh mi bi translated">第1部分:数据收集</h1><p id="5c01" class="pw-post-body-paragraph ku kv it kw b kx mj ju kz la mk jx lc ld ml lf lg lh mm lj lk ll mn ln lo lp im bi translated">谷歌搜索揭示了由<a class="ae lq" href="https://scholar.google.com/citations?hl=en&amp;user=fvWTiS8AAAAJ&amp;view_op=list_works&amp;sortby=pubdate%5C" rel="noopener ugc nofollow" target="_blank"> Md Manjurul Ahsan </a>在<a class="ae lq" href="https://github.com/mahsan2/Monkeypox-dataset-2022" rel="noopener ugc nofollow" target="_blank"> GitHub </a>维护的pox数据库。它包含水痘、麻疹、猴痘、麻疹和正常的彩色图像。同样的图片也有灰度版本。因此，对于所有不同的类别类型，它都有一组灰色的增强图像。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi mo"><img src="../Images/b3c3bc91bc372cc199b28fccb529df4f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*pU5qdnOBa7ZKrd4kVTWaow.png"/></div></div><figcaption class="mp mq gj gh gi mr ms bd b be z dk translated">不同痘型的图像</figcaption></figure><p id="e181" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">我们可以很容易地下载数据。但是，我们需要整理文件，以便PyTorch库可以使用它们。<br/>我们创建了一个名为project的文件夹和一个名为data的子文件夹。我们在数据文件夹中创建四个空文件夹来代表不同的数据类。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi mt"><img src="../Images/a8a1a215c22322997aac0e989c82454d.png" data-original-src="https://miro.medium.com/v2/resize:fit:896/format:webp/1*l-FTAJNircxkwDHyHEmJRQ.png"/></div><figcaption class="mp mq gj gh gi mr ms bd b be z dk translated">包含图像的文件夹</figcaption></figure><p id="2b96" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">现在我们把水痘_gray和水痘_gray_augmented的图片从资源库复制到project/data/水痘。</p><p id="a105" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">将麻疹_gray和麻疹_gray_augmented中的图像从资源库复制到project/data/麻疹中。</p><p id="d95c" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">将Monekypox_gray和Monekypox_gray_augmented中的图像从存储库中复制到project/data/Monekypox中。</p><p id="a4d5" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">最后，将Normal_image_gray和Normal_image_gray_augmented中的图像从存储库中复制到project/data/Normal中。</p><p id="4476" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">传输文件后，文件夹结构应如下所示:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi mu"><img src="../Images/6d42ae58a2987236857e244638e4c387.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*_MxMok86_uW7PZAyTu9N6w.png"/></div></div><figcaption class="mp mq gj gh gi mr ms bd b be z dk translated">每个文件夹都有其灰度图像和灰度增强图像的集合。有些文件名中间有空格</figcaption></figure><h1 id="de51" class="lr ls it bd lt lu lv lw lx ly lz ma mb jz mc ka md kc me kd mf kf mg kg mh mi bi translated">第2部分:数据转换</h1><p id="08bf" class="pw-post-body-paragraph ku kv it kw b kx mj ju kz la mk jx lc ld ml lf lg lh mm lj lk ll mn ln lo lp im bi translated">如果我们检查单个文件，我们会看到文件大小不同。然而，它们需要是统一的，以便将它们提供给网络。因此，我们将定义一些Pytorch转换来使图像一致。</p><p id="1433" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">我们在项目的根层打开一个jupyter笔记本。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi mv"><img src="../Images/ab352363c92a94ae5bbbc087c1bab5e0.png" data-original-src="https://miro.medium.com/v2/resize:fit:832/format:webp/1*a197KAn-Bnw9HDELbTT1bw.png"/></div><figcaption class="mp mq gj gh gi mr ms bd b be z dk translated">code.ipynb将包含模型等</figcaption></figure><p id="103b" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">首先需要导入这些库</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="mw mx l"/></div></figure><p id="e85f" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">接下来，我们将数据处理到训练加载器和测试加载器中。</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="mw mx l"/></div><figcaption class="mp mq gj gh gi mr ms bd b be z dk translated">从文件夹加载图像的代码片段。</figcaption></figure><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi my"><img src="../Images/cac1294fb1724355fd83b0b75f812ef5.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*DbYhmVuU_aShG7FsU3i5Sw.png"/></div></div><figcaption class="mp mq gj gh gi mr ms bd b be z dk translated">上述代码单元的输出。显示类别和标签值之间的映射。</figcaption></figure><p id="076e" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">请注意，图像的根文件夹是data/。数据/包含不同pox类型的所有图像。因此，我们在上面的代码片段中添加了额外的代码来将数据分成train和test。此外，在第23行和第24行，shuffle被设置为true，以便在将图像分成train和test之前对它们进行随机重新排序。</p><p id="1a3d" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">接下来，我们编写一段代码来检查图像是否被正确转换。</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="mw mx l"/></div><figcaption class="mp mq gj gh gi mr ms bd b be z dk translated">显示训练集中的图像。</figcaption></figure><p id="4f5f" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">上面的代码从第一批训练图像中取出第10幅图像并显示出来。由于数据在前一个代码块中被打乱，您的输出可能与我的不同。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi mz"><img src="../Images/86af698559fb1aa8902f8f80ca5d3d02.png" data-original-src="https://miro.medium.com/v2/resize:fit:502/format:webp/1*_zs5tbie8iyE4Eu_kygsZQ.png"/></div><figcaption class="mp mq gj gh gi mr ms bd b be z dk translated">正常的皮肤图像</figcaption></figure><p id="b6fe" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">有了数据，我们就可以开始重新训练预先训练好的模型了。</p><h1 id="59a1" class="lr ls it bd lt lu lv lw lx ly lz ma mb jz mc ka md kc me kd mf kf mg kg mh mi bi translated">第3部分:训练不同的模型。</h1><p id="d2c0" class="pw-post-body-paragraph ku kv it kw b kx mj ju kz la mk jx lc ld ml lf lg lh mm lj lk ll mn ln lo lp im bi translated">我们定义了一个通用的训练函数和一个通用的精度检验函数，可以用来计算模型的效率。</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="mw mx l"/></div><figcaption class="mp mq gj gh gi mr ms bd b be z dk translated">根据数据训练模型并测试其准确性的一般函数</figcaption></figure><p id="aaa1" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">第一行包含设备检查，以了解代码是在CPU上运行还是在GPU上运行。我们将历元的数量设置为30。随后，有两个函数可用于训练模型和测试模型。</p><p id="1afe" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">我们还可以用下面的代码检查数据中是否有重大的不平衡。</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="mw mx l"/></div></figure><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi na"><img src="../Images/83f664eee00f30e6577899165e942e90.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*YoAOWcIL6msKITpnbZUVgw.png"/></div></div><figcaption class="mp mq gj gh gi mr ms bd b be z dk translated">数据相当平衡。本来可以更好，但看起来还可以。</figcaption></figure><p id="3a43" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">我们现在准备执行模型训练。我们将训练的预训练模型是</p><ul class=""><li id="d0bf" class="nb nc it kw b kx ky la lb ld nd lh ne ll nf lp ng nh ni nj bi translated">squeezenet1_0</li><li id="5d96" class="nb nc it kw b kx nk la nl ld nm lh nn ll no lp ng nh ni nj bi translated">densenet161</li><li id="d33e" class="nb nc it kw b kx nk la nl ld nm lh nn ll no lp ng nh ni nj bi translated">densenet169</li><li id="5edd" class="nb nc it kw b kx nk la nl ld nm lh nn ll no lp ng nh ni nj bi translated">亚历克斯_网</li><li id="644d" class="nb nc it kw b kx nk la nl ld nm lh nn ll no lp ng nh ni nj bi translated">resnet18</li></ul><h2 id="cccd" class="np ls it bd lt nq nr dn lx ns nt dp mb ld nu nv md lh nw nx mf ll ny nz mh oa bi translated">Squeezenet1_0</h2><p id="3755" class="pw-post-body-paragraph ku kv it kw b kx mj ju kz la mk jx lc ld ml lf lg lh mm lj lk ll mn ln lo lp im bi translated">以下代码片段为squeezenet1_0模型定型。</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="mw mx l"/></div></figure><p id="d741" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">代码可以分为4个部分。第1行设置了保存训练模型的位置，以便将来使用。第4到9行初始化模型和其他条件。由于数据有4个类，因此有必要将模型的最后一层改为有4个输出(第5行)。第12到14行训练模型。最后，在第17到22行初始化一个新的模型，并在第25行测试它。</p><p id="a71e" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">精确度如下</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi ob"><img src="../Images/1b06994ec0c74b04066a622c4151071e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1256/format:webp/1*k5eGpeRa8eo0lw9EhHYltQ.png"/></div><figcaption class="mp mq gj gh gi mr ms bd b be z dk translated">75%的准确率，不够好</figcaption></figure><h2 id="4c28" class="np ls it bd lt nq nr dn lx ns nt dp mb ld nu nv md lh nw nx mf ll ny nz mh oa bi translated">DenseNet161</h2><p id="1db3" class="pw-post-body-paragraph ku kv it kw b kx mj ju kz la mk jx lc ld ml lf lg lh mm lj lk ll mn ln lo lp im bi translated">下面的代码片段为densenet161模型定型。</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="mw mx l"/></div></figure><p id="835e" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">输出如下所示</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi oc"><img src="../Images/38f3adcde596900ef45c75159c244d1c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1240/format:webp/1*waNBvhh-7dnGmqsoGaw1bw.png"/></div><figcaption class="mp mq gj gh gi mr ms bd b be z dk translated">DenseNet161的测试精度</figcaption></figure><h2 id="7e3c" class="np ls it bd lt nq nr dn lx ns nt dp mb ld nu nv md lh nw nx mf ll ny nz mh oa bi translated">DenseNet169</h2><p id="3da7" class="pw-post-body-paragraph ku kv it kw b kx mj ju kz la mk jx lc ld ml lf lg lh mm lj lk ll mn ln lo lp im bi translated">以下是用于训练DenseNet169的代码片段。它与前面的代码库非常相似，只是名称和预最终层(第6行和第20行)中的神经元数量有所变化</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="mw mx l"/></div></figure><p id="997d" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">输出如下所示:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi od"><img src="../Images/cd7a244fd835f11feea59461d066b54d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1268/format:webp/1*ryeMHpF4AUmMdkhdpPa5nw.png"/></div><figcaption class="mp mq gj gh gi mr ms bd b be z dk translated">准确率在82 %左右</figcaption></figure><h2 id="7ec5" class="np ls it bd lt nq nr dn lx ns nt dp mb ld nu nv md lh nw nx mf ll ny nz mh oa bi translated">AlexNet</h2><p id="1fea" class="pw-post-body-paragraph ku kv it kw b kx mj ju kz la mk jx lc ld ml lf lg lh mm lj lk ll mn ln lo lp im bi translated">接下来，我们尝试一个AlexNet。下面的代码帮助我们加载和重新训练模型。</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="mw mx l"/></div></figure><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi oe"><img src="../Images/266d2296b8271e83b814174873f990e6.png" data-original-src="https://miro.medium.com/v2/resize:fit:1220/format:webp/1*vKGFs2oVcXsZXXWlL9UwIg.png"/></div><figcaption class="mp mq gj gh gi mr ms bd b be z dk translated">准确率提高到90 %</figcaption></figure><h2 id="57f1" class="np ls it bd lt nq nr dn lx ns nt dp mb ld nu nv md lh nw nx mf ll ny nz mh oa bi translated">Resnet18</h2><p id="078f" class="pw-post-body-paragraph ku kv it kw b kx mj ju kz la mk jx lc ld ml lf lg lh mm lj lk ll mn ln lo lp im bi translated">下面的代码片段为resnet18模型定型。</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="mw mx l"/></div><figcaption class="mp mq gj gh gi mr ms bd b be z dk translated">培训和测试resnet18模型</figcaption></figure><p id="fb8c" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">上面的代码中发生了4件事。</p><p id="65c8" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">在第1行中，我们选择要保存的模型的名称和位置。第3到12行设置了resnet18模型的不同参数。我们将模型的输出数量改为4，这是我们数据集中的类的数量。第15到17行对模型进行训练，并将其保存在path中。在第19到25行，我们初始化了另一个resnet18模型，并将权重从path加载到其中。然后我们在第28行检查它的准确性。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi of"><img src="../Images/7dfa95ceb0a819e6fb929f440f31b1a1.png" data-original-src="https://miro.medium.com/v2/resize:fit:1232/format:webp/1*iJYO6J_rRq_Aby-CvbZ3Qw.png"/></div><figcaption class="mp mq gj gh gi mr ms bd b be z dk translated">准确率提高到94.23 %</figcaption></figure><p id="77c0" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">培训到此结束。为了使模型有用，我们需要编写代码将模型应用于单个图像，并预测图像中皮肤可能患有的痘的类型。</p><p id="b99a" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">由于resnet18提供了最好的精度，我们将在未来的步骤中使用相同的精度。</p><h1 id="dff7" class="lr ls it bd lt lu lv lw lx ly lz ma mb jz mc ka md kc me kd mf kf mg kg mh mi bi translated">第4部分:分类单个图像</h1><p id="5cff" class="pw-post-body-paragraph ku kv it kw b kx mj ju kz la mk jx lc ld ml lf lg lh mm lj lk ll mn ln lo lp im bi translated">我们假设输入图像是一个文件或一个HTTP链接，需要通过上面训练的resnet模型进行处理和传递，以确定流行的pox类型。让我们定义两个函数，一个用于加载模型，另一个用于预测给定模型和图像(可能是灰度或彩色)的类别。</p><p id="01e2" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">创建另一个名为<em class="og"> test.ipynb </em>的jupyter笔记本</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi oh"><img src="../Images/7707c68d14fa8b7b7589cac2816315be.png" data-original-src="https://miro.medium.com/v2/resize:fit:800/format:webp/1*RaT4uCV-wWND778yRn5IMg.png"/></div><figcaption class="mp mq gj gh gi mr ms bd b be z dk translated">分离测试</figcaption></figure><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="mw mx l"/></div></figure><p id="be24" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">上面的代码执行必要的导入，设置转换器，并初始化一些全局变量，如类、路径和设备。</p><p id="039d" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">接下来，我们定义加载模型的函数(resnet18)。这将类似于我们之前已经编写的代码。然而，为了方便使用，我们把它放在一个函数中。</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="mw mx l"/></div><figcaption class="mp mq gj gh gi mr ms bd b be z dk translated">加载resnet18模型</figcaption></figure><p id="cadc" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">需要另一个函数将模型应用于传递的图像。图像可以是文件或url。</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="mw mx l"/></div></figure><p id="01f4" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">上面的函数接收一个图像位置，并使用validator包检查它是一个URL还是一个绝对位置(第6到10行)。第12行到第15行执行一些转换，将单个图像存储在一个列表中(因为模型期望一批图像)，并将灰度通道复制为三个通道，因为模型可以用三个通道处理彩色图像。第16行是代码生成预测值的地方。我们从最高到最低对值进行排序，并返回与值的顺序相对应的所有标签。因此，这个函数的输出是pox类型的列表。</p><p id="28ab" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated"><strong class="kw iu">比如:</strong>【猴痘、水痘、麻疹、正常】暗示皮肤像几率最高的是得了猴痘，其次是水痘等等。</p><p id="b2fa" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">这就正式把我们带到了这篇文章的结尾。这里整个练习的代码可以在<a class="ae lq" href="https://github.com/ashhadulislam/train-pox-detector" rel="noopener ugc nofollow" target="_blank"> github </a>找到。</p><h1 id="cbbf" class="lr ls it bd lt lu lv lw lx ly lz ma mb jz mc ka md kc me kd mf kf mg kg mh mi bi translated">附加部分:前端应用</h1><p id="603c" class="pw-post-body-paragraph ku kv it kw b kx mj ju kz la mk jx lc ld ml lf lg lh mm lj lk ll mn ln lo lp im bi translated">如果我们能把这作为一个应用程序与全世界分享，那就太好了。我们上传皮肤的图像，它会按照严重程度的降序告诉我们痘的类型。我们可以使用Streamlit精确地做到这一点。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi oi"><img src="../Images/fa877fa02948a529ae086943058c8e48.png" data-original-src="https://miro.medium.com/v2/resize:fit:1200/1*3zAYeeYp0lKydb5anEALXw.gif"/></div><figcaption class="mp mq gj gh gi mr ms bd b be z dk translated">实时Streamlit应用程序执行痘型检测，视频可在<a class="ae lq" href="https://vimeo.com/734438419" rel="noopener ugc nofollow" target="_blank"> vimeo </a>获得。</figcaption></figure><p id="a610" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">关于Streamlit中编码的更详细的解释，看一看这篇<a class="ae lq" rel="noopener ugc nofollow" target="_blank" href="/deep-learning-a692669f6f42">文章</a>，并转到<em class="og">部分作为Streamlit应用程序托管(本地，然后在云中)</em>。这个应用程序的代码以类似的格式编写。Streamlit应用程序的GitHub repo可以在<a class="ae lq" href="https://github.com/ashhadulislam/medium-streamlit-pox-detection" rel="noopener ugc nofollow" target="_blank">这里</a>找到。你可以试试这里的app<a class="ae lq" href="https://ashhadulislam-medium-streamlit-pox-detection-main-h0zk0k.streamlitapp.com/" rel="noopener ugc nofollow" target="_blank"/>。</p><p id="bc63" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated"><strong class="kw iu">结论</strong></p><p id="0125" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">如果你坚持到最后，这里祝你和你的亲人身体健康。下次见。</p></div></div>    
</body>
</html>