<html>
<head>
<title>Linear Regression Basics for Absolute Beginners</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">绝对初学者的线性回归基础</h1>
<blockquote>原文：<a href="https://pub.towardsai.net/linear-regression-basics-for-absolute-beginners-68ed9ff980ae?source=collection_archive---------0-----------------------#2020-05-29">https://pub.towardsai.net/linear-regression-basics-for-absolute-beginners-68ed9ff980ae?source=collection_archive---------0-----------------------#2020-05-29</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><figure class="is it gp gr iu iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi ir"><img src="../Images/d10f03b90f4259910c2dc1c6b80821ee.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Nf2tTTkALYq6RTMQmhjo1A.png"/></div></div><figcaption class="jc jd gj gh gi je jf bd b be z dk translated">Benjamin O. Tayo的图片</figcaption></figure><h2 id="3169" class="jg jh ji bd b dl jj jk jl jm jn jo dk jp translated" aria-label="kicker paragraph">数据科学</h2><div class=""/><div class=""><h2 id="1519" class="pw-subtitle-paragraph ko jr ji bd b kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf dk translated">使用NumPy、Pylab和Scikit进行简单和多元回归分析的教程-学习</h2></div><h1 id="85d4" class="lg lh ji bd li lj lk ll lm ln lo lp lq kx lr ky ls la lt lb lu ld lv le lw lx bi translated">1.介绍</h1><p id="226a" class="pw-post-body-paragraph ly lz ji ma b mb mc ks md me mf kv mg mh mi mj mk ml mm mn mo mp mq mr ms mt im bi translated">回归模型是最流行的机器学习模型。回归模型用于连续预测目标变量。回归模型在几乎每个研究领域都有应用，因此，它是使用最广泛的机器学习模型之一。本文将讨论线性回归的基础知识，面向数据科学领域的初学者。</p><p id="2597" class="pw-post-body-paragraph ly lz ji ma b mb mu ks md me mv kv mg mh mw mj mk ml mx mn mo mp my mr ms mt im bi translated">使用游轮数据集<a class="ae mz" href="https://github.com/bot13956/ML_Model_for_Predicting_Ships_Crew_Size" rel="noopener ugc nofollow" target="_blank"><strong class="ma js">cruise _ ship _ info . CSV</strong></a>，我们将使用NumPy、Pylab和Scikit-learn演示简单和多重回归分析。因为这只是一个介绍性的教程，所以不需要区分内部值和外部值(外部值可以使用更健壮的方法来处理，比如RANSAC回归)。</p><h1 id="a3b7" class="lg lh ji bd li lj lk ll lm ln lo lp lq kx lr ky ls la lt lb lu ld lv le lw lx bi translated">2.数据分析</h1><h2 id="2633" class="na lh ji bd li nb nc dn lm nd ne dp lq mh nf ng ls ml nh ni lu mp nj nk lw jo bi translated">2.1导入必要的库</h2><pre class="nl nm nn no gt np nq nr ns aw nt bi"><span id="fb34" class="na lh ji nq b gy nu nv l nw nx">import numpy as np</span><span id="1e4c" class="na lh ji nq b gy ny nv l nw nx">import pandas as pd</span><span id="5e98" class="na lh ji nq b gy ny nv l nw nx">import pylab</span><span id="a66c" class="na lh ji nq b gy ny nv l nw nx">import matplotlib.pyplot as plt</span><span id="c362" class="na lh ji nq b gy ny nv l nw nx">import seaborn as sns</span><span id="9e68" class="na lh ji nq b gy ny nv l nw nx">import matplotlib.pyplot as plt</span><span id="bffd" class="na lh ji nq b gy ny nv l nw nx">from sklearn.metrics import r2_score</span><span id="e827" class="na lh ji nq b gy ny nv l nw nx">from sklearn.model_selection import train_test_split</span><span id="c270" class="na lh ji nq b gy ny nv l nw nx">from sklearn.preprocessing import StandardScaler</span><span id="d104" class="na lh ji nq b gy ny nv l nw nx">from sklearn.linear_model import LinearRegression</span><span id="b6ac" class="na lh ji nq b gy ny nv l nw nx">from sklearn.pipeline import Pipeline</span><span id="049a" class="na lh ji nq b gy ny nv l nw nx">pipe_lr = Pipeline([('scl', StandardScaler()),<br/>                    ('lr', LinearRegression())])</span></pre><h2 id="7ea4" class="na lh ji bd li nb nc dn lm nd ne dp lq mh nf ng ls ml nh ni lu mp nj nk lw jo bi translated">2.2读取数据集并显示列</h2><pre class="nl nm nn no gt np nq nr ns aw nt bi"><span id="7a13" class="na lh ji nq b gy nu nv l nw nx">df = pd.read_csv("cruise_ship_info.csv")</span><span id="18bd" class="na lh ji nq b gy ny nv l nw nx">df.head()</span></pre><figure class="nl nm nn no gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi nz"><img src="../Images/244f284fc69f41e98198a7e0f1ad0e6e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*lufPByGNax2vrJKu.png"/></div></div><figcaption class="jc jd gj gh gi je jf bd b be z dk translated"><strong class="bd li">表1 </strong>:显示数据集的前5行。</figcaption></figure><h2 id="22de" class="na lh ji bd li nb nc dn lm nd ne dp lq mh nf ng ls ml nh ni lu mp nj nk lw jo bi translated">2.3计算协方差矩阵</h2><pre class="nl nm nn no gt np nq nr ns aw nt bi"><span id="59ce" class="na lh ji nq b gy nu nv l nw nx">cols = ['Age', 'Tonnage', 'passengers', 'length', <br/>                      'cabins','passenger_density','crew']<br/><br/>stdsc = StandardScaler()</span><span id="e117" class="na lh ji nq b gy ny nv l nw nx">X_std = stdsc.fit_transform(df[cols].iloc[:,range(0,7)].values</span><span id="33a8" class="na lh ji nq b gy ny nv l nw nx">cov_mat = np.cov(X_std.T)</span></pre><h2 id="fe47" class="na lh ji bd li nb nc dn lm nd ne dp lq mh nf ng ls ml nh ni lu mp nj nk lw jo bi translated">2.4生成用于可视化协方差矩阵的热图</h2><pre class="nl nm nn no gt np nq nr ns aw nt bi"><span id="7fa4" class="na lh ji nq b gy nu nv l nw nx">plt.figure(figsize=(10,10))sns.set(font_scale=1.5)hm = sns.heatmap(cov_mat,<br/>                 cbar=<strong class="nq js">True</strong>,<br/>                 annot=<strong class="nq js">True</strong>,<br/>                 square=<strong class="nq js">True</strong>,<br/>                 fmt='.2f',<br/>                 annot_kws={'size': 12},<br/>                 yticklabels=cols,<br/>                 xticklabels=cols)<br/>plt.title('Covariance matrix showing correlation coefficients')<br/>plt.tight_layout()<br/>plt.show()</span></pre><figure class="nl nm nn no gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi oa"><img src="../Images/3c05444835a5dba73f18f58117fc4ca3.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*LF20WUg0pg3Xf0fp.png"/></div></div><figcaption class="jc jd gj gh gi je jf bd b be z dk translated"><strong class="bd li">图一</strong>。协方差矩阵图。</figcaption></figure><h1 id="448c" class="lg lh ji bd li lj lk ll lm ln lo lp lq kx lr ky ls la lt lb lu ld lv le lw lx bi translated">3.简单线性回归</h1><p id="b892" class="pw-post-body-paragraph ly lz ji ma b mb mc ks md me mf kv mg mh mi mj mk ml mm mn mo mp mq mr ms mt im bi translated">在简单线性回归中，只有一个预测变量。由于我们的目标是预测乘务人员变量，我们从图1<strong class="ma js">中看到</strong>客舱变量与乘务人员变量相关性最大。因此，我们的简单回归模型可以表示为以下形式:</p><figure class="nl nm nn no gt iv gh gi paragraph-image"><div class="gh gi ob"><img src="../Images/fdc33fb08eae156c8e4d5c47aac9cbb1.png" data-original-src="https://miro.medium.com/v2/resize:fit:722/format:webp/1*kKLyZPkEkkhLdE1GFVwwrg.png"/></div></figure><p id="65cc" class="pw-post-body-paragraph ly lz ji ma b mb mu ks md me mv kv mg mh mw mj mk ml mx mn mo mp my mr ms mt im bi translated">其中m是斜率或回归系数，c是截距。该模型将使用R2评分标准进行评估，其计算方法如下:</p><figure class="nl nm nn no gt iv gh gi paragraph-image"><div class="gh gi oc"><img src="../Images/e631ba213104372df6a4b3f448613ba8.png" data-original-src="https://miro.medium.com/v2/resize:fit:1128/format:webp/1*Ko1k7pqqOO544KFoXFxFJA.png"/></div></figure><p id="0a4e" class="pw-post-body-paragraph ly lz ji ma b mb mu ks md me mv kv mg mh mw mj mk ml mx mn mo mp my mr ms mt im bi translated">R2分数取0到1之间的值。当R2接近1时，意味着预测值与实际值非常接近。如果R2接近于零，则意味着模型的预测能力非常差。</p><p id="fef3" class="pw-post-body-paragraph ly lz ji ma b mb mu ks md me mv kv mg mh mw mj mk ml mx mn mo mp my mr ms mt im bi translated">现在让我们定义并绘制自变量和因变量:</p><pre class="nl nm nn no gt np nq nr ns aw nt bi"><span id="4e10" class="na lh ji nq b gy nu nv l nw nx">X = df['cabins']</span><span id="de33" class="na lh ji nq b gy ny nv l nw nx">y = df['crew']</span><span id="c364" class="na lh ji nq b gy ny nv l nw nx">plt.scatter(X,y,c='steelblue', edgecolor='white', s=70)</span><span id="7172" class="na lh ji nq b gy ny nv l nw nx">plt.xlabel('cabins')</span><span id="f5b3" class="na lh ji nq b gy ny nv l nw nx">plt.ylabel('crew')</span><span id="b036" class="na lh ji nq b gy ny nv l nw nx">plt.title('scatter plot of crew vs. cabins')</span><span id="48a0" class="na lh ji nq b gy ny nv l nw nx">plt.show()</span></pre><figure class="nl nm nn no gt iv gh gi paragraph-image"><div class="gh gi od"><img src="../Images/d38bc997681bbc4f5b62a3a5b66f7ff9.png" data-original-src="https://miro.medium.com/v2/resize:fit:792/format:webp/1*5me_bI2_8o7No0jXIQB8aw.png"/></div><figcaption class="jc jd gj gh gi je jf bd b be z dk translated"><strong class="bd li">图二</strong>。船员与客舱的散点图。</figcaption></figure><h2 id="c064" class="na lh ji bd li nb nc dn lm nd ne dp lq mh nf ng ls ml nh ni lu mp nj nk lw jo bi translated">3.1使用numpy的简单线性回归</h2><pre class="nl nm nn no gt np nq nr ns aw nt bi"><span id="b448" class="na lh ji nq b gy nu nv l nw nx">z = np.polyfit(X,y,1)</span><span id="3197" class="na lh ji nq b gy ny nv l nw nx">p = np.poly1d(z)</span><span id="a674" class="na lh ji nq b gy ny nv l nw nx">print(p)</span></pre><p id="6235" class="pw-post-body-paragraph ly lz ji ma b mb mu ks md me mv kv mg mh mw mj mk ml mx mn mo mp my mr ms mt im bi translated"><strong class="ma js">输出</strong> : 0.745 x + 1.216</p><p id="3e62" class="pw-post-body-paragraph ly lz ji ma b mb mu ks md me mv kv mg mh mw mj mk ml mx mn mo mp my mr ms mt im bi translated">这表明拟合的斜率是m = 0.745，截距是c = 1.216。</p><pre class="nl nm nn no gt np nq nr ns aw nt bi"><span id="73d3" class="na lh ji nq b gy nu nv l nw nx">y_pred_numpy = p(X)</span><span id="ada9" class="na lh ji nq b gy ny nv l nw nx">R2_numpy = 1 - ((y-y_pred_numpy)**2).sum()/((y-y.mean())**2).sum()</span><span id="be89" class="na lh ji nq b gy ny nv l nw nx">print(R2_numpy)</span></pre><p id="016e" class="pw-post-body-paragraph ly lz ji ma b mb mu ks md me mv kv mg mh mw mj mk ml mx mn mo mp my mr ms mt im bi translated"><strong class="ma js">输出</strong>:R2 _ numpy = 0.90068686686</p><pre class="nl nm nn no gt np nq nr ns aw nt bi"><span id="a5fa" class="na lh ji nq b gy nu nv l nw nx">print(r2_score(y, y_pred_numpy))</span></pre><p id="d93b" class="pw-post-body-paragraph ly lz ji ma b mb mu ks md me mv kv mg mh mw mj mk ml mx mn mo mp my mr ms mt im bi translated"><strong class="ma js">输出</strong>:0.9000000000001</p><p id="5748" class="pw-post-body-paragraph ly lz ji ma b mb mu ks md me mv kv mg mh mw mj mk ml mx mn mo mp my mr ms mt im bi translated">现在让我们绘制实际值和预测值:</p><pre class="nl nm nn no gt np nq nr ns aw nt bi"><span id="883c" class="na lh ji nq b gy nu nv l nw nx">plt.figure(figsize=(10,7))</span><span id="0c21" class="na lh ji nq b gy ny nv l nw nx">plt.scatter(X,y,c='steelblue', edgecolor='white', s=70, <br/>             label='actual')</span><span id="8dfd" class="na lh ji nq b gy ny nv l nw nx">plt.plot(X,y_pred_numpy, color='black', lw=2, label='predicted')</span><span id="91b1" class="na lh ji nq b gy ny nv l nw nx">plt.xlabel('cabins')</span><span id="0bc1" class="na lh ji nq b gy ny nv l nw nx">plt.ylabel('crew')</span><span id="1c1a" class="na lh ji nq b gy ny nv l nw nx">plt.title('actual and fitted plots')</span><span id="96d3" class="na lh ji nq b gy ny nv l nw nx">plt.legend()</span><span id="be70" class="na lh ji nq b gy ny nv l nw nx">plt.show()</span></pre><figure class="nl nm nn no gt iv gh gi paragraph-image"><div class="gh gi oe"><img src="../Images/0c2ddacc4a84dbed6804dd5ca07087e8.png" data-original-src="https://miro.medium.com/v2/resize:fit:772/format:webp/1*_-UmjNLUXGz203_lo3IM-w.png"/></div><figcaption class="jc jd gj gh gi je jf bd b be z dk translated"><strong class="bd li">图3 </strong>。船员与客舱的实际和拟合图。</figcaption></figure><h2 id="f64c" class="na lh ji bd li nb nc dn lm nd ne dp lq mh nf ng ls ml nh ni lu mp nj nk lw jo bi translated">3.2使用Pylab的简单线性回归</h2><pre class="nl nm nn no gt np nq nr ns aw nt bi"><span id="9722" class="na lh ji nq b gy nu nv l nw nx">degree = 1</span><span id="c810" class="na lh ji nq b gy ny nv l nw nx">model= pylab.polyfit(X,y,degree)</span><span id="62ba" class="na lh ji nq b gy ny nv l nw nx">print(model)</span></pre><p id="2de2" class="pw-post-body-paragraph ly lz ji ma b mb mu ks md me mv kv mg mh mw mj mk ml mx mn mo mp my mr ms mt im bi translated"><strong class="ma js">输出</strong>:数组([0.7449974，1.21585013])。我们再次看到斜率是m = 0.745，截距是c = 1.216。</p><pre class="nl nm nn no gt np nq nr ns aw nt bi"><span id="d533" class="na lh ji nq b gy nu nv l nw nx">y_pred_pylab = pylab.polyval(model,X)</span><span id="9f1c" class="na lh ji nq b gy ny nv l nw nx">R2_pylab = 1 - ((y-y_pred_pylab)**2).sum()/((y-y.mean())**2).sum()</span><span id="a9f0" class="na lh ji nq b gy ny nv l nw nx">print(R2_pylab)</span></pre><p id="cec1" class="pw-post-body-paragraph ly lz ji ma b mb mu ks md me mv kv mg mh mw mj mk ml mx mn mo mp my mr ms mt im bi translated">输出值:R2 _皮拉布= 0.904686868667</p><pre class="nl nm nn no gt np nq nr ns aw nt bi"><span id="2da0" class="na lh ji nq b gy nu nv l nw nx">print(r2_score(y, y_pred_pylab))</span></pre><p id="4522" class="pw-post-body-paragraph ly lz ji ma b mb mu ks md me mv kv mg mh mw mj mk ml mx mn mo mp my mr ms mt im bi translated"><strong class="ma js">输出</strong>:0.90363863863686</p><h2 id="c854" class="na lh ji bd li nb nc dn lm nd ne dp lq mh nf ng ls ml nh ni lu mp nj nk lw jo bi translated">3.3使用scikit-learn的简单线性回归</h2><pre class="nl nm nn no gt np nq nr ns aw nt bi"><span id="e692" class="na lh ji nq b gy nu nv l nw nx">lr = LinearRegression()</span><span id="735d" class="na lh ji nq b gy ny nv l nw nx">lr.fit(X.values.reshape(-1,1),y)</span><span id="c83e" class="na lh ji nq b gy ny nv l nw nx">print(lr.coef_)</span><span id="d513" class="na lh ji nq b gy ny nv l nw nx">print(lr.intercept_)</span></pre><p id="7e7f" class="pw-post-body-paragraph ly lz ji ma b mb mu ks md me mv kv mg mh mw mj mk ml mx mn mo mp my mr ms mt im bi translated"><strong class="ma js">输出</strong>:【0.7449974】，1.2158501299368671。我们再次看到斜率是m = 0.745，截距是c = 1.216。</p><pre class="nl nm nn no gt np nq nr ns aw nt bi"><span id="d21c" class="na lh ji nq b gy nu nv l nw nx">y_pred_sklearn = lr.predict(X.values.reshape(-1,1))</span><span id="fa2f" class="na lh ji nq b gy ny nv l nw nx">R2_sklearn = 1 - ((y-y_pred_sklearn)**2).sum()/((y-y.mean())**2).sum()</span><span id="ec6d" class="na lh ji nq b gy ny nv l nw nx">print(R2_sklearn)</span></pre><p id="8897" class="pw-post-body-paragraph ly lz ji ma b mb mu ks md me mv kv mg mh mw mj mk ml mx mn mo mp my mr ms mt im bi translated"><strong class="ma js">输出</strong>:R2 _ sklean = 0.90686866666</p><pre class="nl nm nn no gt np nq nr ns aw nt bi"><span id="0167" class="na lh ji nq b gy nu nv l nw nx">print(r2_score(y, y_pred_sklearn))</span></pre><p id="fdf6" class="pw-post-body-paragraph ly lz ji ma b mb mu ks md me mv kv mg mh mw mj mk ml mx mn mo mp my mr ms mt im bi translated"><strong class="ma js">输出</strong>:0.9036868686686</p><p id="4551" class="pw-post-body-paragraph ly lz ji ma b mb mu ks md me mv kv mg mh mw mj mk ml mx mn mo mp my mr ms mt im bi translated">我们观察到基本线性回归的所有3种方法(NumPy、Pylab和Scikit-learn)给出了一致的结果。</p><h1 id="b9e0" class="lg lh ji bd li lj lk ll lm ln lo lp lq kx lr ky ls la lt lb lu ld lv le lw lx bi translated">4.使用Scikit-Learn进行多元线性回归</h1><p id="3d77" class="pw-post-body-paragraph ly lz ji ma b mb mc ks md me mf kv mg mh mi mj mk ml mm mn mo mp mq mr ms mt im bi translated">从上面的协方差矩阵图(<strong class="ma js">图1 </strong>)中，我们看到“船员”变量与4个预测变量“吨位”、“乘客”、“长度”和“客舱”高度相关(相关系数≥ 0.6)。因此，我们可以建立以下形式的多元回归模型:</p><figure class="nl nm nn no gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi of"><img src="../Images/bfba6ca1cb8b96be7315ef594be4077e.png" data-original-src="https://miro.medium.com/v2/resize:fit:816/format:webp/1*fr7vcW_nnUxjqEPUYcYqMQ.png"/></div></div></figure><p id="24ad" class="pw-post-body-paragraph ly lz ji ma b mb mu ks md me mv kv mg mh mw mj mk ml mx mn mo mp my mr ms mt im bi translated">其中X是特征矩阵，w0是截距，w1、w2、w3和w4是回归系数。</p><h2 id="d08a" class="na lh ji bd li nb nc dn lm nd ne dp lq mh nf ng ls ml nh ni lu mp nj nk lw jo bi translated">4.1定义特征矩阵和目标变量</h2><pre class="nl nm nn no gt np nq nr ns aw nt bi"><span id="3edb" class="na lh ji nq b gy nu nv l nw nx">cols_selected = ['Tonnage', 'passengers', 'length', 'cabins','crew']</span><span id="101e" class="na lh ji nq b gy ny nv l nw nx">df[cols_selected].head()</span><span id="ce08" class="na lh ji nq b gy ny nv l nw nx">X = df[cols_selected].iloc[:,0:4].values    # features matrix </span><span id="43a4" class="na lh ji nq b gy ny nv l nw nx">y = df[cols_selected]['crew'].values        # target variable</span></pre><figure class="nl nm nn no gt iv gh gi paragraph-image"><div class="gh gi og"><img src="../Images/be4d3e8237c68ebfa4e5d872ec278abb.png" data-original-src="https://miro.medium.com/v2/resize:fit:732/format:webp/0*vkKrWoHxcwhC9soq.png"/></div><figcaption class="jc jd gj gh gi je jf bd b be z dk translated"><strong class="bd li">表2 </strong>。前5行重要特征和预测变量。</figcaption></figure><h2 id="7e31" class="na lh ji bd li nb nc dn lm nd ne dp lq mh nf ng ls ml nh ni lu mp nj nk lw jo bi translated">4.2模型建立和评估</h2><pre class="nl nm nn no gt np nq nr ns aw nt bi"><span id="2977" class="na lh ji nq b gy nu nv l nw nx">X_train, X_test, y_train, y_test = train_test_split( X, y, test_size=0.3, random_state=0)</span><span id="a691" class="na lh ji nq b gy ny nv l nw nx">sc_y = StandardScaler()</span><span id="50be" class="na lh ji nq b gy ny nv l nw nx">y_train_std = sc_y.fit_transform(y_train[:,np.newaxis]).flatten()</span><span id="7f3d" class="na lh ji nq b gy ny nv l nw nx">pipe_lr.fit(X_train, y_train_std)</span><span id="4438" class="na lh ji nq b gy ny nv l nw nx">y_train_pred = sc_y.inverse_transform(pipe_lr.predict(X_train))</span><span id="2959" class="na lh ji nq b gy ny nv l nw nx">y_test_pred = sc_y.inverse_transform(pipe_lr.predict(X_test))</span><span id="9702" class="na lh ji nq b gy ny nv l nw nx">r2_score_train = r2_score(y_train, y_train_pred)</span><span id="3a28" class="na lh ji nq b gy ny nv l nw nx">r2_score_test = r2_score(y_test, y_test_pred)</span><span id="a263" class="na lh ji nq b gy ny nv l nw nx">print('R2 train for lr: %.3f' % r2_score_train)</span><span id="6e9f" class="na lh ji nq b gy ny nv l nw nx">print('R2 test for lr:  %.3f ' % r2_score_test)</span></pre><p id="c691" class="pw-post-body-paragraph ly lz ji ma b mb mu ks md me mv kv mg mh mw mj mk ml mx mn mo mp my mr ms mt im bi translated"><strong class="ma js">输出:</strong></p><p id="8f6c" class="pw-post-body-paragraph ly lz ji ma b mb mu ks md me mv kv mg mh mw mj mk ml mx mn mo mp my mr ms mt im bi translated">R2列车为0.912 <br/> R2列车为0.958</p><h2 id="5bd9" class="na lh ji bd li nb nc dn lm nd ne dp lq mh nf ng ls ml nh ni lu mp nj nk lw jo bi translated">4.3绘制输出</h2><pre class="nl nm nn no gt np nq nr ns aw nt bi"><span id="b01c" class="na lh ji nq b gy nu nv l nw nx">plt.scatter(y_train, y_train_pred, c='steelblue', edgecolor='white', s=70, label='fitted')</span><span id="503b" class="na lh ji nq b gy ny nv l nw nx">plt.plot(y_train, y_train, c = 'red', lw = 2,label='ideal')</span><span id="28d5" class="na lh ji nq b gy ny nv l nw nx">plt.xlabel('actual crew')</span><span id="5fbc" class="na lh ji nq b gy ny nv l nw nx">plt.ylabel('predicted crew')</span><span id="cdad" class="na lh ji nq b gy ny nv l nw nx">plt.legend()</span><span id="7a38" class="na lh ji nq b gy ny nv l nw nx">plt.show()</span></pre><figure class="nl nm nn no gt iv gh gi paragraph-image"><div class="gh gi oh"><img src="../Images/9c20d18684fb17006e1fa10498c5318c.png" data-original-src="https://miro.medium.com/v2/resize:fit:804/format:webp/1*ibGGo643LZtGT5fUkl2-mg.png"/></div><figcaption class="jc jd gj gh gi je jf bd b be z dk translated"><strong class="bd li">图4 </strong>。使用多元回归分析的机组变量的理想图和拟合图。</figcaption></figure><h1 id="069d" class="lg lh ji bd li lj lk ll lm ln lo lp lq kx lr ky ls la lt lb lu ld lv le lw lx bi translated">5.摘要</h1><p id="d731" class="pw-post-body-paragraph ly lz ji ma b mb mc ks md me mf kv mg mh mi mj mk ml mm mn mo mp mq mr ms mt im bi translated">总之，我们介绍了一个使用不同库(如NumPy、Pylab和Scikit-learn)的简单和多元回归分析教程。线性回归是最流行的机器学习算法。对线性回归的透彻理解将为理解其他机器学习算法(如逻辑回归、K-最近邻和支持向量机)打下良好的基础。</p><h1 id="990d" class="lg lh ji bd li lj lk ll lm ln lo lp lq kx lr ky ls la lt lb lu ld lv le lw lx bi translated">其他数据科学/机器学习资源</h1><p id="64e8" class="pw-post-body-paragraph ly lz ji ma b mb mc ks md me mf kv mg mh mi mj mk ml mm mn mo mp mq mr ms mt im bi translated"><a class="ae mz" href="https://towardsdatascience.com/data-science-minimum-10-essential-skills-you-need-to-know-to-start-doing-data-science-e5a5a9be5991" rel="noopener" target="_blank">数据科学最低要求:开始从事数据科学工作需要知道的10项基本技能</a></p><p id="d1fd" class="pw-post-body-paragraph ly lz ji ma b mb mu ks md me mv kv mg mh mw mj mk ml mx mn mo mp my mr ms mt im bi translated"><a class="ae mz" href="https://medium.com/towards-artificial-intelligence/data-science-curriculum-bf3bb6805576" rel="noopener">数据科学课程</a></p><p id="6fb8" class="pw-post-body-paragraph ly lz ji ma b mb mu ks md me mv kv mg mh mw mj mk ml mx mn mo mp my mr ms mt im bi translated"><a class="ae mz" href="https://medium.com/towards-artificial-intelligence/4-math-skills-for-machine-learning-12bfbc959c92" rel="noopener">机器学习的基本数学技能</a></p><p id="2061" class="pw-post-body-paragraph ly lz ji ma b mb mu ks md me mv kv mg mh mw mj mk ml mx mn mo mp my mr ms mt im bi translated"><a class="ae mz" href="https://medium.com/towards-artificial-intelligence/3-best-data-science-mooc-specializations-d58da382f628" rel="noopener"> 3个最佳数据科学MOOC专业</a></p><p id="b116" class="pw-post-body-paragraph ly lz ji ma b mb mu ks md me mv kv mg mh mw mj mk ml mx mn mo mp my mr ms mt im bi translated"><a class="ae mz" href="https://towardsdatascience.com/5-best-degrees-for-getting-into-data-science-c3eb067883b1" rel="noopener" target="_blank">进入数据科学的5个最佳学位</a></p><p id="2cc4" class="pw-post-body-paragraph ly lz ji ma b mb mu ks md me mv kv mg mh mw mj mk ml mx mn mo mp my mr ms mt im bi translated"><a class="ae mz" href="https://towardsdatascience.com/5-reasons-why-you-should-begin-your-data-science-journey-in-2020-2b4a0a5e4239" rel="noopener" target="_blank">2020年开始数据科学之旅的5个理由</a></p><p id="9bee" class="pw-post-body-paragraph ly lz ji ma b mb mu ks md me mv kv mg mh mw mj mk ml mx mn mo mp my mr ms mt im bi translated"><a class="ae mz" href="https://towardsdatascience.com/theoretical-foundations-of-data-science-should-i-care-or-simply-focus-on-hands-on-skills-c53fb0caba66" rel="noopener" target="_blank">数据科学的理论基础——我应该关心还是仅仅关注实践技能？</a></p><p id="ac55" class="pw-post-body-paragraph ly lz ji ma b mb mu ks md me mv kv mg mh mw mj mk ml mx mn mo mp my mr ms mt im bi translated"><a class="ae mz" href="https://towardsdatascience.com/machine-learning-project-planning-71bdb3a44349" rel="noopener" target="_blank">机器学习项目规划</a></p><p id="979d" class="pw-post-body-paragraph ly lz ji ma b mb mu ks md me mv kv mg mh mw mj mk ml mx mn mo mp my mr ms mt im bi translated"><a class="ae mz" href="https://towardsdatascience.com/how-to-organize-your-data-science-project-dd6599cf000a" rel="noopener" target="_blank">如何组织你的数据科学项目</a></p><p id="aaa3" class="pw-post-body-paragraph ly lz ji ma b mb mu ks md me mv kv mg mh mw mj mk ml mx mn mo mp my mr ms mt im bi translated"><a class="ae mz" href="https://medium.com/towards-artificial-intelligence/productivity-tools-for-large-scale-data-science-projects-64810dfbb971" rel="noopener">大型数据科学项目的生产力工具</a></p><p id="01f4" class="pw-post-body-paragraph ly lz ji ma b mb mu ks md me mv kv mg mh mw mj mk ml mx mn mo mp my mr ms mt im bi translated"><a class="ae mz" href="https://towardsdatascience.com/a-data-science-portfolio-is-more-valuable-than-a-resume-2d031d6ce518" rel="noopener" target="_blank">数据科学作品集比简历更有价值</a></p><p id="ab22" class="pw-post-body-paragraph ly lz ji ma b mb mu ks md me mv kv mg mh mw mj mk ml mx mn mo mp my mr ms mt im bi translated"><a class="ae mz" href="https://medium.com/towards-artificial-intelligence/data-science-101-a-short-course-on-medium-platform-with-r-and-python-code-included-3cdc9d489c6d" rel="noopener">数据科学101 —包含R和Python代码的中型平台短期课程</a></p><p id="7fea" class="pw-post-body-paragraph ly lz ji ma b mb mu ks md me mv kv mg mh mw mj mk ml mx mn mo mp my mr ms mt im bi translated"><strong class="ma js"> <em class="oi">如有疑问，请发邮件给我</em></strong>:benjaminobi@gmail.com</p></div></div>    
</body>
</html>