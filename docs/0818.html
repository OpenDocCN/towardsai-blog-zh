<html>
<head>
<title>How to Quickly Preprocess and Visualize Text Data with TextHero</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">如何用TextHero快速预处理和可视化文本数据</h1>
<blockquote>原文：<a href="https://pub.towardsai.net/how-to-quickly-preprocess-and-visualize-text-data-with-texthero-c86957452824?source=collection_archive---------1-----------------------#2020-08-18">https://pub.towardsai.net/how-to-quickly-preprocess-and-visualize-text-data-with-texthero-c86957452824?source=collection_archive---------1-----------------------#2020-08-18</a></blockquote><div><div class="fc ii ij ik il im"/><div class="in io ip iq ir"><h2 id="1018" class="is it iu bd b dl iv iw ix iy iz ja dk jb translated" aria-label="kicker paragraph"><a class="ae ep" href="https://towardsai.net/p/category/nlp" rel="noopener ugc nofollow" target="_blank">自然语言处理</a></h2><div class=""/><div class=""><h2 id="cce9" class="pw-subtitle-paragraph ka jd iu bd b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr dk translated">TextHero库简介，用于快速预处理和可视化Python中的文本数据</h2></div><figure class="kt ku kv kw gu kx gi gj paragraph-image"><div role="button" tabindex="0" class="ky kz di la bf lb"><div class="gi gj ks"><img src="../Images/316321d540eaabe4468a758c0d4dbaaa.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*iTwENABdS7W5fA1e"/></div></div><figcaption class="le lf gk gi gj lg lh bd b be z dk translated">照片由<a class="ae li" href="https://unsplash.com/@chuttersnap" rel="noopener ugc nofollow" target="_blank">丘特尔斯纳普</a>在<a class="ae li" href="https://unsplash.com/photos/PVO_tj2APuM" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上拍摄</figcaption></figure><p id="6b88" class="pw-post-body-paragraph lj lk iu ll b lm ln ke lo lp lq kh lr ls lt lu lv lw lx ly lz ma mb mc md me in bi translated">当我们在任何NLP项目或比赛中工作时，我们会花大部分时间对文本进行预处理，如删除数字、标点符号、停用词、空格等，有时还会进行可视化。在对几个NLP数据集进行实验之后，我发现这个库对于预处理和可视化非常有用。这将为我们节省一些编写自定义函数的时间。你不兴奋吗！！？所以让我们开始吧。</p><p id="03d8" class="pw-post-body-paragraph lj lk iu ll b lm ln ke lo lp lq kh lr ls lt lu lv lw lx ly lz ma mb mc md me in bi translated">我们将把本文中将要学习的技术应用于Kaggle的<code class="fe mf mg mh mi b">Spooky Author Identification</code>数据集。你可以在这里找到数据集<a class="ae li" href="https://www.kaggle.com/c/spooky-author-identification/data" rel="noopener ugc nofollow" target="_blank">。文章末尾给出了完整的代码。</a></p><blockquote class="mj mk ml"><p id="a60f" class="lj lk mm ll b lm ln ke lo lp lq kh lr mn lt lu lv mo lx ly lz mp mb mc md me in bi translated">注意:TextHero仍处于测试阶段。该图书馆可能会发生重大变化。因此，下面的一些代码片段或功能可能会发生变化。</p></blockquote><h1 id="9c65" class="mq mr iu bd ms mt mu mv mw mx my mz na kj nb kk nc km nd kn ne kp nf kq ng nh bi translated">装置</h1><pre class="kt ku kv kw gu ni mi nj nk aw nl bi"><span id="74c7" class="nm mr iu mi b gz nn no l np nq">pip install texthero</span></pre><h1 id="0034" class="mq mr iu bd ms mt mu mv mw mx my mz na kj nb kk nc km nd kn ne kp nf kq ng nh bi translated">预处理</h1><p id="11b4" class="pw-post-body-paragraph lj lk iu ll b lm nr ke lo lp ns kh lr ls nt lu lv lw nu ly lz ma nv mc md me in bi translated">顾名思义<code class="fe mf mg mh mi b">clean</code>是用来清理文字的方法。默认情况下，<code class="fe mf mg mh mi b">clean</code>方法对文本应用7个<code class="fe mf mg mh mi b">default pipelines</code>。</p><pre class="kt ku kv kw gu ni mi nj nk aw nl bi"><span id="1c89" class="nm mr iu mi b gz nn no l np nq">from texthero import preprocessing<br/>df[‘clean_text’] = preprocessing.clean(df[‘text’])</span></pre><ol class=""><li id="1976" class="nw nx iu ll b lm ln lp lq ls ny lw nz ma oa me ob oc od oe bi translated">菲尔娜</li><li id="eefc" class="nw nx iu ll b lm of lp og ls oh lw oi ma oj me ob oc od oe bi translated">小写字母</li><li id="00d5" class="nw nx iu ll b lm of lp og ls oh lw oi ma oj me ob oc od oe bi translated">移除数字()</li><li id="bfc5" class="nw nx iu ll b lm of lp og ls oh lw oi ma oj me ob oc od oe bi translated">删除标点符号()</li><li id="d0e4" class="nw nx iu ll b lm of lp og ls oh lw oi ma oj me ob oc od oe bi translated">移除_音调符号()</li><li id="bb43" class="nw nx iu ll b lm of lp og ls oh lw oi ma oj me ob oc od oe bi translated">remove _停用字词()</li><li id="aa5e" class="nw nx iu ll b lm of lp og ls oh lw oi ma oj me ob oc od oe bi translated">remove _ white空格()</li></ol><p id="9166" class="pw-post-body-paragraph lj lk iu ll b lm ln ke lo lp lq kh lr ls lt lu lv lw lx ly lz ma mb mc md me in bi translated">我们可以通过下面的代码来确认使用的默认管道:</p><figure class="kt ku kv kw gu kx gi gj paragraph-image"><div class="gi gj ok"><img src="../Images/14d056ed5b7e97d46a876624e1308e57.png" data-original-src="https://miro.medium.com/v2/resize:fit:1168/format:webp/1*fwFZynadc3J7cJTUXqZGQw.png"/></div></figure><p id="6dc0" class="pw-post-body-paragraph lj lk iu ll b lm ln ke lo lp lq kh lr ls lt lu lv lw lx ly lz ma mb mc md me in bi translated">除了上面的7个默认管道，<code class="fe mf mg mh mi b">TextHero</code>还提供了更多我们可以使用的管道。参见完整列表<a class="ae li" href="https://texthero.org/docs/api-preprocessing" rel="noopener ugc nofollow" target="_blank">此处</a>的描述。这些是非常有用的，因为我们在文本预处理过程中处理所有这些。</p><p id="2f7a" class="pw-post-body-paragraph lj lk iu ll b lm ln ke lo lp lq kh lr ls lt lu lv lw lx ly lz ma mb mc md me in bi translated">根据我们的要求，我们还可以定制管道，如下所示。在这个例子中，我们使用了两条管道。但是，我们可以使用任意多的管道。</p><pre class="kt ku kv kw gu ni mi nj nk aw nl bi"><span id="d45a" class="nm mr iu mi b gz nn no l np nq">from texthero import preprocessing </span><span id="d08c" class="nm mr iu mi b gz ol no l np nq">custom_pipeline = [preprocessing.fillna, preprocessing.lowercase] </span><span id="02be" class="nm mr iu mi b gz ol no l np nq">df[‘clean_text’] = preprocessing.clean(df[‘text’], custom_pipeline)</span></pre><h1 id="b65b" class="mq mr iu bd ms mt mu mv mw mx my mz na kj nb kk nc km nd kn ne kp nf kq ng nh bi translated">自然语言处理</h1><p id="e4fd" class="pw-post-body-paragraph lj lk iu ll b lm nr ke lo lp ns kh lr ls nt lu lv lw nu ly lz ma nv mc md me in bi translated">到目前为止，这个NLP功能只提供了<code class="fe mf mg mh mi b">named_entity</code>和<code class="fe mf mg mh mi b">noun_phrases</code>方法。请参见下面的示例代码。由于<code class="fe mf mg mh mi b">TextHero</code>还在测试中，我相信，以后会有更多的功能加入。</p><p id="7470" class="pw-post-body-paragraph lj lk iu ll b lm ln ke lo lp lq kh lr ls lt lu lv lw lx ly lz ma mb mc md me in bi translated"><strong class="ll je">命名实体</strong></p><pre class="kt ku kv kw gu ni mi nj nk aw nl bi"><span id="960f" class="nm mr iu mi b gz nn no l np nq">s = pd.Series(“Narendra Damodardas Modi is an Indian politician serving as the 14th and current Prime Minister of India since 2014”)</span><span id="f3af" class="nm mr iu mi b gz ol no l np nq">print(nlp.named_entities(s)[0])</span><span id="854f" class="nm mr iu mi b gz ol no l np nq"><strong class="mi je">Output:</strong><br/>[('Narendra Damodardas Modi', 'PERSON', 0, 24),  <br/>('Indian', 'NORP', 31, 37),  <br/>('14th', 'ORDINAL', 64, 68),  <br/>('India', 'GPE', 99, 104),  <br/>('2014', 'DATE', 111, 115)]</span></pre><p id="4a94" class="pw-post-body-paragraph lj lk iu ll b lm ln ke lo lp lq kh lr ls lt lu lv lw lx ly lz ma mb mc md me in bi translated"><strong class="ll je">名词短语</strong></p><pre class="kt ku kv kw gu ni mi nj nk aw nl bi"><span id="b213" class="nm mr iu mi b gz nn no l np nq">s = pd.Series(“Narendra Damodardas Modi is an Indian politician serving as the 14th and current Prime Minister of India since 2014”)</span><span id="7282" class="nm mr iu mi b gz ol no l np nq">print(nlp.noun_chunks(s)[0])</span><span id="132b" class="nm mr iu mi b gz ol no l np nq"><strong class="mi je">Output:</strong><br/>[(‘Narendra Damodardas Modi’, ‘NP’, 0, 24), <br/>(‘an Indian politician’, ‘NP’, 28, 48), <br/>(‘the 14th and current Prime Minister’, ‘NP’, 60, 95), <br/>(‘India’, ‘NP’, 99, 104)]</span></pre><h1 id="de40" class="mq mr iu bd ms mt mu mv mw mx my mz na kj nb kk nc km nd kn ne kp nf kq ng nh bi translated">表现</h1><p id="1deb" class="pw-post-body-paragraph lj lk iu ll b lm nr ke lo lp ns kh lr ls nt lu lv lw nu ly lz ma nv mc md me in bi translated">此功能用于将文本数据映射到<code class="fe mf mg mh mi b">vectors </code>(词频，TF-IDF)，映射到<code class="fe mf mg mh mi b">clustering </code> (kmeans，dbscan，meanshift)，还映射到<code class="fe mf mg mh mi b">dimensionality reduction</code> (PCA，t-SNE，NMF)。</p><p id="5457" class="pw-post-body-paragraph lj lk iu ll b lm ln ke lo lp lq kh lr ls lt lu lv lw lx ly lz ma mb mc md me in bi translated">让我们看一个例子，在幽灵作者识别数据集上有<code class="fe mf mg mh mi b">TF-TDF</code>和<code class="fe mf mg mh mi b">PCA</code>。</p><pre class="kt ku kv kw gu ni mi nj nk aw nl bi"><span id="75c0" class="nm mr iu mi b gz nn no l np nq">train['pca'] = (<br/>    train['text']<br/>    .pipe(preprocessing.clean)<br/>    .pipe(representation.tfidf, max_features=1000)<br/>    .pipe(representation.pca)<br/>)</span><span id="4ca9" class="nm mr iu mi b gz ol no l np nq">visualization.scatterplot(train, 'pca', color='author', title="Spooky Author identification")</span></pre><figure class="kt ku kv kw gu kx gi gj paragraph-image"><div role="button" tabindex="0" class="ky kz di la bf lb"><div class="gi gj om"><img src="../Images/be60a2dd9fd1973c760a9c67d97cabfa.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*KdHzTjjAemhHAOE0A-Zf0Q.png"/></div></div></figure><h1 id="f199" class="mq mr iu bd ms mt mu mv mw mx my mz na kj nb kk nc km nd kn ne kp nf kq ng nh bi translated">形象化</h1><p id="3c75" class="pw-post-body-paragraph lj lk iu ll b lm nr ke lo lp ns kh lr ls nt lu lv lw nu ly lz ma nv mc md me in bi translated">该功能用于绘制<strong class="ll je">散点图</strong>、<strong class="ll je">单词云</strong>，也用于从文本中获取<strong class="ll je">前n个单词</strong>。参考下面的例子。</p><p id="9af9" class="pw-post-body-paragraph lj lk iu ll b lm ln ke lo lp lq kh lr ls lt lu lv lw lx ly lz ma mb mc md me in bi translated"><strong class="ll je">散点图示例</strong></p><pre class="kt ku kv kw gu ni mi nj nk aw nl bi"><span id="4d7c" class="nm mr iu mi b gz nn no l np nq">train['tfidf'] = (<br/>    train['text']<br/>    .pipe(preprocessing.clean)<br/>    .pipe(representation.tfidf, max_features=1000)<br/>)</span><span id="ea8f" class="nm mr iu mi b gz ol no l np nq">train['kmeans_labels'] = (<br/>    train['tfidf']<br/>    .pipe(representation.kmeans, n_clusters=3)<br/>    .astype(str)<br/>)</span><span id="c88e" class="nm mr iu mi b gz ol no l np nq">train['pca'] = train['tfidf'].pipe(representation.pca)</span><span id="288e" class="nm mr iu mi b gz ol no l np nq">visualization.scatterplot(train, 'pca', color='kmeans_labels', title="K-means Spooky author")</span></pre><figure class="kt ku kv kw gu kx gi gj paragraph-image"><div role="button" tabindex="0" class="ky kz di la bf lb"><div class="gi gj om"><img src="../Images/742c769ee86aeb19dc40f384ade836e5.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*fxo7t7amj6bdtPPLlOiWQQ.png"/></div></div></figure><h2 id="9e5a" class="nm mr iu bd ms on oo dn mw op oq dp na ls or os nc lw ot ou ne ma ov ow ng ja bi translated">Wordcloud示例</h2><pre class="kt ku kv kw gu ni mi nj nk aw nl bi"><span id="de08" class="nm mr iu mi b gz nn no l np nq">from texthero import visualization<br/>visualization.wordcloud(train[‘clean_text’])</span></pre><figure class="kt ku kv kw gu kx gi gj paragraph-image"><div role="button" tabindex="0" class="ky kz di la bf lb"><div class="gi gj ox"><img src="../Images/41338859f9d45f8db3a1d6579baf3bdd.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*KR5V1kKc70MDAM8YDZv8HA.png"/></div></div></figure><h2 id="f304" class="nm mr iu bd ms on oo dn mw op oq dp na ls or os nc lw ot ou ne ma ov ow ng ja bi translated">热门词汇示例</h2><figure class="kt ku kv kw gu kx gi gj paragraph-image"><div role="button" tabindex="0" class="ky kz di la bf lb"><div class="gi gj oy"><img src="../Images/447dfc184a27acdd02988422a99da7f6.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*ru87kP_MEG0R_HeBo1gb1A.png"/></div></div></figure><h1 id="75e4" class="mq mr iu bd ms mt mu mv mw mx my mz na kj nb kk nc km nd kn ne kp nf kq ng nh bi translated">完全码</h1><figure class="kt ku kv kw gu kx"><div class="bz fq l di"><div class="oz pa l"/></div></figure><h1 id="6c49" class="mq mr iu bd ms mt mu mv mw mx my mz na kj nb kk nc km nd kn ne kp nf kq ng nh bi translated">结论</h1><p id="68bc" class="pw-post-body-paragraph lj lk iu ll b lm nr ke lo lp ns kh lr ls nt lu lv lw nu ly lz ma nv mc md me in bi translated">我们已经完成了<code class="fe mf mg mh mi b">TextHero</code>提供的大部分功能。除了NLP功能，我发现其余的功能都非常有用，我们可以在下一个NLP项目中尝试使用它们。</p><p id="82b5" class="pw-post-body-paragraph lj lk iu ll b lm ln ke lo lp lq kh lr ls lt lu lv lw lx ly lz ma mb mc md me in bi translated"><em class="mm">阅读更多关于Python和数据科学的此类有趣文章，</em> <a class="ae li" href="https://pythonsimplified.com/home/" rel="noopener ugc nofollow" target="_blank"> <strong class="ll je"> <em class="mm">订阅</em> </strong> </a> <em class="mm">到我的博客</em><a class="ae li" href="http://www.pythonsimplified.com/" rel="noopener ugc nofollow" target="_blank"><strong class="ll je"><em class="mm">www.pythonsimplified.com</em></strong><strong class="ll je"><em class="mm">。</em> </strong>你也可以在</a><a class="ae li" href="https://www.linkedin.com/in/chetanambi/" rel="noopener ugc nofollow" target="_blank"><strong class="ll je">LinkedIn</strong></a><strong class="ll je">上联系我。</strong></p></div><div class="ab cl pb pc hy pd" role="separator"><span class="pe bw bk pf pg ph"/><span class="pe bw bk pf pg ph"/><span class="pe bw bk pf pg"/></div><div class="in io ip iq ir"><h1 id="f564" class="mq mr iu bd ms mt pi mv mw mx pj mz na kj pk kk nc km pl kn ne kp pm kq ng nh bi translated">参考</h1><div class="pn po gq gs pp pq"><a href="https://github.com/jbesomi/texthero" rel="noopener  ugc nofollow" target="_blank"><div class="pr ab fp"><div class="ps ab pt cl cj pu"><h2 class="bd je gz z fq pv fs ft pw fv fx jd bi translated">JB osmi/text hero</h2><div class="px l"><h3 class="bd b gz z fq pv fs ft pw fv fx dk translated">从零到英雄的文本预处理、表示和可视化。从零到英雄*安装*获取…</h3></div><div class="py l"><p class="bd b dl z fq pv fs ft pw fv fx dk translated">github.com</p></div></div><div class="pz l"><div class="qa l qb qc qd pz qe lc pq"/></div></div></a></div></div></div>    
</body>
</html>