<html>
<head>
<title>How to Train XGBoost Model With PySpark</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">如何用PySpark训练XGBoost模型</h1>
<blockquote>原文：<a href="https://pub.towardsai.net/how-to-train-xgboost-model-with-pyspark-2c4e219da5e1?source=collection_archive---------1-----------------------#2022-11-29">https://pub.towardsai.net/how-to-train-xgboost-model-with-pyspark-2c4e219da5e1?source=collection_archive---------1-----------------------#2022-11-29</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><figure class="gl gn jo jp jq jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi jn"><img src="../Images/a81416b859e0e63bad7b77a975662dff.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*zQnd0zE-kpG9AST7zo2CyA.png"/></div></div></figure><h1 id="328c" class="jy jz iq bd ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv bi translated">为什么选择XGBoost？</h1><p id="0c36" class="pw-post-body-paragraph kw kx iq ky b kz la lb lc ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt ij bi lu translated"><span class="l lv lw lx bm ly lz ma mb mc di"> X </span> GBoost ( <strong class="ky ir">极限梯度提升</strong>)是各行各业数据科学家最流行、最广泛使用的ML算法之一。此外，该算法在减少计算时间和提供内存资源的最佳使用方面非常有效，另一个重要特征是在训练过程的实现和并行化上处理缺失值。</p><p id="5815" class="pw-post-body-paragraph kw kx iq ky b kz md lb lc ld me lf lg lh mf lj lk ll mg ln lo lp mh lr ls lt ij bi translated">如今，由于数据集规模迅速增加，分布式训练真的很重要，所以在这篇博客中，我们将探讨有人如何集成<strong class="ky ir"> <em class="mi"> XGBoost + PySpark </em> </strong>并进行模型训练和评分。</p><p id="81c7" class="pw-post-body-paragraph kw kx iq ky b kz md lb lc ld me lf lg lh mf lj lk ll mg ln lo lp mh lr ls lt ij bi translated">人们可以很容易地在<strong class="ky ir"> pyspark.ml </strong>或<strong class="ky ir"> MLLib、</strong>中使用可用的ml算法，但要以同样的方式使用XGBoost，我们必须添加一些外部依赖项和python XGBoost包装器，另一种方法是直接使用带有pyspark的<strong class="ky ir"> XGBoost本机</strong>框架，最新版本的<a class="ae mj" href="https://pypi.org/project/xgboost/" rel="noopener ugc nofollow" target="_blank"> XGBoost </a>不支持该框架(这里唯一的限制是它仅在python版本≥3.8上受支持)，要知道(感谢dmlc社区..)</p><p id="303f" class="pw-post-body-paragraph kw kx iq ky b kz md lb lc ld me lf lg lh mf lj lk ll mg ln lo lp mh lr ls lt ij bi translated">但在这篇博客中，我们主要关注的是如何在python版本&lt; 3.8.</p><p id="3544" class="pw-post-body-paragraph kw kx iq ky b kz md lb lc ld me lf lg lh mf lj lk ll mg ln lo lp mh lr ls lt ij bi translated"><strong class="ky ir">上与PySpark集成，在开始集成部分之前，请从这个</strong> <a class="ae mj" href="https://github.com/divyhshah/xgboost-pyspark" rel="noopener ugc nofollow" target="_blank"> <strong class="ky ir">链接</strong> </a> <strong class="ky ir">下载必备文件。</strong></p><p id="6ffa" class="pw-post-body-paragraph kw kx iq ky b kz md lb lc ld me lf lg lh mf lj lk ll mg ln lo lp mh lr ls lt ij bi translated">一旦你下载了所有的3个文件，我们就可以把XGBoost和PySpark集成起来了。</p><ol class=""><li id="445f" class="mk ml iq ky b kz md ld me lh mm ll mn lp mo lt mp mq mr ms bi translated">如下面的示例代码所述，在<strong class="ky ir"> PYSPARK_SUBMIT_ARGS </strong>部分添加<strong class="ky ir"> JAR </strong>文件(确保添加文件位置的准确路径)</li><li id="4a0c" class="mk ml iq ky b kz mt ld mu lh mv ll mw lp mx lt mp mq mr ms bi translated">创建您的Spark会话。</li><li id="2d99" class="mk ml iq ky b kz mt ld mu lh mv ll mw lp mx lt mp mq mr ms bi translated">添加XGBoost python包装器代码文件<strong class="ky ir"> <em class="mi">(。zip文件)</em> </strong>在sparkContext中。(我们这样做是为了支持XGBoost导入，再次确保添加zip文件的正确路径)</li></ol><pre class="my mz na nb gt nc nd ne bn nf ng bi"><span id="f41c" class="nh jz iq nd b be ni nj l nk nl">import os<br/>import findspark<br/>import numpy as np<br/><br/>## Add the path of the downloaded jar files<br/>os.environ['PYSPARK_SUBMIT_ARGS'] = '--jars xgboost4j-spark.jar,xgboost4j.jar pyspark-shell'<br/><br/>findspark.init()<br/><br/>spark = SparkSession\<br/>        .builder\<br/>        .appName("XGBoost_PySpark")\<br/>        .master("local[*]")\<br/>        .getOrCreate()<br/><br/>spark.sparkContext.addPyFile("sparkxgb.zip")</span></pre><p id="0b0b" class="pw-post-body-paragraph kw kx iq ky b kz md lb lc ld me lf lg lh mf lj lk ll mg ln lo lp mh lr ls lt ij bi translated">完成上述步骤后，您可以通过导入XGBClassifier或Regressor进行交叉检查。</p><pre class="my mz na nb gt nc nd ne bn nf ng bi"><span id="3a24" class="nh jz iq nd b be ni nj l nk nl">from sparkxgb.xgboost import XGBoostClassificationModel, XGBoostClassifier</span></pre><p id="6e9a" class="pw-post-body-paragraph kw kx iq ky b kz md lb lc ld me lf lg lh mf lj lk ll mg ln lo lp mh lr ls lt ij bi translated">如果你得到一个JAR错误，那么可能是由于版本不匹配，在这种情况下，你可以从<a class="ae mj" href="https://mvnrepository.com/artifact/ml.dmlc/xgboost-jvm" rel="noopener ugc nofollow" target="_blank">这里</a>下载另一个版本的JAR文件来检查。</p><p id="a1ee" class="pw-post-body-paragraph kw kx iq ky b kz md lb lc ld me lf lg lh mf lj lk ll mg ln lo lp mh lr ls lt ij bi translated">现在，一旦所有的都完成了，让我们试着建立一个简单的模型，按照下面的步骤。</p><p id="1d15" class="pw-post-body-paragraph kw kx iq ky b kz md lb lc ld me lf lg lh mf lj lk ll mg ln lo lp mh lr ls lt ij bi translated">这里，我们采用了一个开源贷款预测数据集，并试图预测贷款是否会获得批准，这里的<strong class="ky ir"> Loan_Status </strong>是我们的目标变量(因为它是Y/N格式，所以我们在1/0中进行了转换)。</p><ol class=""><li id="bafa" class="mk ml iq ky b kz md ld me lh mm ll mn lp mo lt mp mq mr ms bi translated"><strong class="ky ir">添加所需的星火库</strong></li></ol><pre class="my mz na nb gt nc nd ne bn nf ng bi"><span id="87dc" class="nh jz iq nd b be ni nj l nk nl">from pyspark.ml.feature import StringIndexer, VectorAssembler<br/>from sparkxgb.xgboost import XGBoostClassificationModel, XGBoostClassifier<br/>from pyspark.ml import Pipeline<br/>from pyspark.mllib.evaluation import MulticlassMetrics<br/>from pyspark.sql import functions as F</span></pre><p id="bca2" class="pw-post-body-paragraph kw kx iq ky b kz md lb lc ld me lf lg lh mf lj lk ll mg ln lo lp mh lr ls lt ij bi translated"><strong class="ky ir"> 2。加载数据集并进行所需的预处理</strong></p><pre class="my mz na nb gt nc nd ne bn nf ng bi"><span id="c369" class="nh jz iq nd b be ni nj l nk nl">data = spark.read.parquet('train.parquet')<br/>data = data.withColumn('label', F.when(F.col('Loan_Status')=='Y', 1) \<br/>                                            .otherwise(0)<br/>                                  )<br/>data.show(5)</span></pre><pre class="nm nc nd ne bn nf ng bi"><span id="93fc" class="nh jz iq nd b be ni nj l nk nl">+--------+------+-------+----------+------------+-------------+---------------+-----------------+----------+----------------+--------------+-------------+-----------+-----+<br/>| Loan_ID|Gender|Married|Dependents|   Education|Self_Employed|ApplicantIncome|CoapplicantIncome|LoanAmount|Loan_Amount_Term|Credit_History|Property_Area|Loan_Status|label|<br/>+--------+------+-------+----------+------------+-------------+---------------+-----------------+----------+----------------+--------------+-------------+-----------+-----+<br/>|LP001002|  Male|     No|         0|    Graduate|           No|           5849|              0.0|      null|           360.0|           1.0|        Urban|          Y|    1|<br/>|LP001003|  Male|    Yes|         1|    Graduate|           No|           4583|           1508.0|     128.0|           360.0|           1.0|        Rural|          N|    0|<br/>|LP001005|  Male|    Yes|         0|    Graduate|          Yes|           3000|              0.0|      66.0|           360.0|           1.0|        Urban|          Y|    1|<br/>|LP001006|  Male|    Yes|         0|Not Graduate|           No|           2583|           2358.0|     120.0|           360.0|           1.0|        Urban|          Y|    1|<br/>|LP001008|  Male|     No|         0|    Graduate|           No|           6000|              0.0|     141.0|           360.0|           1.0|        Urban|          Y|    1|<br/>+--------+------+-------+----------+------------+-------------+---------------+-----------------+----------+----------------+--------------+-------------+-----------+-----+</span></pre><p id="5a9f" class="pw-post-body-paragraph kw kx iq ky b kz md lb lc ld me lf lg lh mf lj lk ll mg ln lo lp mh lr ls lt ij bi translated">在上面的示例数据中，我们可以看到一些列有分类/字符串值..因此，我们需要在将它们传递到模型之前将其转换为数值，PySpark提供了<strong class="ky ir">string indexer&amp;OneHotEncoder</strong>用于相同的目的，这里我们将<strong class="ky ir"> StringIndexer。</strong></p><pre class="my mz na nb gt nc nd ne bn nf ng bi"><span id="c043" class="nh jz iq nd b be ni nj l nk nl">index1 = StringIndexer().setInputCol("Gender").setOutputCol("GenderIndex").setHandleInvalid("keep")<br/>index2 = StringIndexer().setInputCol("Married").setOutputCol("MarriedIndex").setHandleInvalid("keep")<br/>index3 = StringIndexer().setInputCol("Education").setOutputCol("EducationIndex").setHandleInvalid("keep")<br/>index4 = StringIndexer().setInputCol("Self_Employed").setOutputCol("SelfEmployedIndex").setHandleInvalid("keep")<br/>index5 = StringIndexer().setInputCol("Property_Area").setOutputCol("PropertyAreaIndex").setHandleInvalid("keep")</span></pre><p id="8b0e" class="pw-post-body-paragraph kw kx iq ky b kz md lb lc ld me lf lg lh mf lj lk ll mg ln lo lp mh lr ls lt ij bi translated">现在，正如我们所看到的，我们有多个<strong class="ky ir"> StringIndexer </strong>对象，我们需要通过每个索引器进行转换，这是一个漫长的过程，因此为了整合所有的转换、特征矢量化和模型拟合<strong class="ky ir"> PySpark </strong> <strong class="ky ir"> ML </strong>提供了<strong class="ky ir"> ML管道</strong>的概念，在其中我们可以将几个步骤组合在一起并随时运行，</p><p id="3cd1" class="pw-post-body-paragraph kw kx iq ky b kz md lb lc ld me lf lg lh mf lj lk ll mg ln lo lp mh lr ls lt ij bi translated">在创建管道对象之前，我们先定义<strong class="ky ir"> VectorAssembler </strong>和<strong class="ky ir"> Model </strong>对象。</p><pre class="my mz na nb gt nc nd ne bn nf ng bi"><span id="e333" class="nh jz iq nd b be ni nj l nk nl">## define list of your final features<br/>features = ['GenderIndex', 'MarriedIndex', 'EducationIndex', 'SelfEmployedIndex', 'PropertyAreaIndex',<br/>           'ApplicantIncome', 'CoapplicantIncome', 'LoanAmount', 'Loan_Amount_Term', 'Credit_History']<br/><br/>vec_assembler = VectorAssembler(inputCols=features, outputCol='features', handleInvalid='keep')<br/><br/>xgb = XGBoostClassifier(objective="binary:logistic",seed=1712,<br/>                        featuresCol="features",<br/>                        labelCol="label",<br/>                        missing=0.0,<br/>                        )</span></pre><p id="6873" class="pw-post-body-paragraph kw kx iq ky b kz md lb lc ld me lf lg lh mf lj lk ll mg ln lo lp mh lr ls lt ij bi translated">现在让我们创建管道对象并构建最终模型。</p><p id="9796" class="pw-post-body-paragraph kw kx iq ky b kz md lb lc ld me lf lg lh mf lj lk ll mg ln lo lp mh lr ls lt ij bi translated"><strong class="ky ir"> 3。创建ML管道</strong></p><pre class="my mz na nb gt nc nd ne bn nf ng bi"><span id="2b7e" class="nh jz iq nd b be ni nj l nk nl"># here add all your steps inside setStages<br/><br/>pipeline = Pipeline().setStages([index1, index2, index3, index4, index5, vec_assembler, xgb])<br/><br/># split the data in train and test<br/>trainDF, testDF = train_data.randomSplit([0.7, 0.3], seed=1712)<br/><br/>model = pipeline.fit(trainDF)<br/><br/># Generate the prediction on test data<br/><br/>predictions = model.transform(testDF)[['Loan_ID', 'prediction', 'label']]<br/>predictions.show()</span></pre><pre class="nm nc nd ne bn nf ng bi"><span id="c912" class="nh jz iq nd b be ni nj l nk nl">+--------+----------+-----+<br/>| Loan_ID|prediction|label|<br/>+--------+----------+-----+<br/>|LP001005|       1.0|    1|<br/>|LP001013|       1.0|    1|<br/>|LP001018|       1.0|    1|<br/>|LP001027|       1.0|    1|<br/>|LP001032|       1.0|    1|<br/>+--------+----------+-----+</span></pre><p id="8a2e" class="pw-post-body-paragraph kw kx iq ky b kz md lb lc ld me lf lg lh mf lj lk ll mg ln lo lp mh lr ls lt ij bi translated">哇..最后建立XGBoost模型，并用PySpark进行测试</p><p id="3d61" class="pw-post-body-paragraph kw kx iq ky b kz md lb lc ld me lf lg lh mf lj lk ll mg ln lo lp mh lr ls lt ij bi translated"><strong class="ky ir"> 4。检查绩效指标</strong></p><pre class="my mz na nb gt nc nd ne bn nf ng bi"><span id="7e74" class="nh jz iq nd b be ni nj l nk nl">from pyspark.sql.types import DoubleType<br/><br/>predictionAndLabels = predictions.select(['prediction', 'label']\<br/>                                  ).withColumn('label',F.col('label').cast(DoubleType())).rdd<br/><br/>metrics = MulticlassMetrics(predictionAndLabels)<br/><br/>cm = metrics.confusionMatrix().toArray()<br/><br/>accuracy=(cm[0][0]+cm[1][1])/cm.sum()<br/>precision=(cm[1][1])/(cm[0][1]+cm[1][1])<br/>recall=(cm[1][1])/(cm[1][0]+cm[1][1])<br/><br/>print(accuracy, precision, recall)</span></pre><pre class="nm nc nd ne bn nf ng bi"><span id="7418" class="nh jz iq nd b be ni nj l nk nl">(0.7015706806282722, 0.7517241379310344, 0.8384615384615385)</span></pre><p id="e15e" class="pw-post-body-paragraph kw kx iq ky b kz md lb lc ld me lf lg lh mf lj lk ll mg ln lo lp mh lr ls lt ij bi translated"><strong class="ky ir"> 5。超参数调谐(可选步骤)</strong></p><p id="babe" class="pw-post-body-paragraph kw kx iq ky b kz md lb lc ld me lf lg lh mf lj lk ll mg ln lo lp mh lr ls lt ij bi translated">如果你想调整你的XGBoost参数，然后按照下面的代码，实际上，这不是可行的方法，因为在大量的数据上，它非常昂贵，因为它在每个参数的组合上建立一个模型，一个更好的方法是使用python中的<strong class="ky ir">randomsearccv</strong>并在这里使用该参数，或者你可以在PySpark中设计代码，每次使用随机值选择并分配给模型。</p><pre class="my mz na nb gt nc nd ne bn nf ng bi"><span id="2724" class="nh jz iq nd b be ni nj l nk nl">from pyspark.ml.tuning import ParamGridBuilder, CrossValidator, CrossValidatorModel<br/>from pyspark.ml.evaluation import BinaryClassificationEvaluator, MulticlassClassificationEvaluator<br/><br/>xgbEval = BinaryClassificationEvaluator()<br/><br/># Define your list of grid search parameters<br/><br/>paramGrid = (ParamGridBuilder()<br/>             .addGrid(xgb.alpha,[1e-5, 1e-2, 0.1])<br/>             .addGrid(xgb.eta, [0.001, 0.01])<br/>             .addGrid(xgb.numRound, [150,160])<br/>             .addGrid(xgb.maxDepth, range(3,7,3))<br/>             .addGrid(xgb.minChildWeight, [3.0, 4.0])<br/>             .addGrid(xgb.gamma, [i/10.0 for i in range(0,2)])<br/>             .addGrid(xgb.colsampleBytree, [i/10.0 for i in range(3,6)])<br/>             .addGrid(xgb.subsample, [0.4,0.6])<br/>             .build())<br/><br/>cv = CrossValidator(estimator=pipeline, estimatorParamMaps=paramGrid, evaluator=xgbEval, numFolds=3)<br/>cvModel = cv.fit(trainDF)<br/>cvPreds = cvModel.transform(testDF)<br/>xgbEval.evaluate(cvPreds)<br/><br/>## Print the tuned params<br/>cvModel.bestModel.extractParamMap()</span></pre><p id="7de1" class="pw-post-body-paragraph kw kx iq ky b kz md lb lc ld me lf lg lh mf lj lk ll mg ln lo lp mh lr ls lt ij bi translated">感谢您抽出时间阅读我的博客，希望对您有所帮助。总而言之，我们了解了一些XGBoost及其优点。我们还研究了使用外部依赖在PySpark中逐步实现XGBoost。我期待着来自我的读者的各种建议，让我知道你想让我写的下一部是什么。</p></div></div>    
</body>
</html>