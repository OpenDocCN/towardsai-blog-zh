<html>
<head>
<title>Complete List of Feature Engineering Methods: 40 Techniques, 10 Categories</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">特征工程方法的完整列表:40种技术，10个类别</h1>
<blockquote>原文：<a href="https://pub.towardsai.net/complete-list-of-feature-engineering-methods-40-techniques-10-categories-fda920883fad?source=collection_archive---------0-----------------------#2021-04-15">https://pub.towardsai.net/complete-list-of-feature-engineering-methods-40-techniques-10-categories-fda920883fad?source=collection_archive---------0-----------------------#2021-04-15</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><h2 id="47b9" class="ir is it bd b dl iu iv iw ix iy iz dk ja translated" aria-label="kicker paragraph"><a class="ae ep" href="https://towardsai.net/p/category/data-science" rel="noopener ugc nofollow" target="_blank">数据科学</a></h2><div class=""/><div class=""><h2 id="5e9e" class="pw-subtitle-paragraph jz jc it bd b ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq dk translated">一个完整的列表(截至目前)展示了用于数据探索的工程技术</h2></div><p id="7bab" class="pw-post-body-paragraph kr ks it kt b ku kv kd kw kx ky kg kz la lb lc ld le lf lg lh li lj lk ll lm im bi translated"><a class="ae ln" href="http://www.michelangiolo.best/" rel="noopener ugc nofollow" target="_blank"> <strong class="kt jd">点击这里了解我，我的项目，我的最新文章。</strong> </a></p><p id="6f16" class="pw-post-body-paragraph kr ks it kt b ku kv kd kw kx ky kg kz la lb lc ld le lf lg lh li lj lk ll lm im bi translated">在你从事数据科学的第一年，你不太可能理解特征工程的重要性。这是因为当你没有经验或经验很少时，尤其是你独自学习时，你无法获得大数据。事实上，您将只能处理非常小的数据样本，优先使用pandas和plotly来编辑和获取有关数据的信息。</p><figure class="lp lq lr ls gt lt gh gi paragraph-image"><div role="button" tabindex="0" class="lu lv di lw bf lx"><div class="gh gi lo"><img src="../Images/454a285f68d0db272caf2e8acd3caf04.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Jjy_1SbTDM31cE-q8Wpp3w.png"/></div></div><figcaption class="ma mb gj gh gi mc md bd b be z dk translated">检索自:<a class="ae ln" href="https://towardsdatascience.com/feature-engineering-what-powers-machine-learning-93ab191bcc2d" rel="noopener" target="_blank">https://towards data science . com/feature-engineering-what-powers-machine-learning-93ab 191 bcc2d</a></figcaption></figure><h2 id="3770" class="me mf it bd mg mh mi dn mj mk ml dp mm la mn mo mp le mq mr ms li mt mu mv iz bi translated">为什么选择特征工程？</h2><p id="5e07" class="pw-post-body-paragraph kr ks it kt b ku mw kd kw kx mx kg kz la my lc ld le mz lg lh li na lk ll lm im bi translated">事实上，当您开始过渡到大数据时，功能工程变得至关重要。大数据分析现在和将来都将保持高需求，因为到目前为止，你几乎没有办法学会如何独自处理庞大的数据集。着手处理大数据的唯一方法是在工作场所与一个专家团队合作。这是真正的数据科学的全方位体验。</p><p id="b3ae" class="pw-post-body-paragraph kr ks it kt b ku kv kd kw kx ky kg kz la lb lc ld le lf lg lh li lj lk ll lm im bi translated">处理小数据集的计算量不大。因为你基本上可以使用自己的GPU或谷歌或其他云服务提供商免费提供的GPU来训练你的模型，没有任何麻烦(例如，在谷歌Colab中，你可以通过点击一个按钮来访问它)，你可以训练模型的次数几乎没有限制。即使对于需要大量计算能力的CNN，在数据集很小的情况下，你也可以在几个小时内完成训练。</p><h2 id="e4f1" class="me mf it bd mg mh mi dn mj mk ml dp mm la mn mo mp le mq mr ms li mt mu mv iz bi translated">为什么大数据不同于小样本</h2><p id="3813" class="pw-post-body-paragraph kr ks it kt b ku mw kd kw kx mx kg kz la my lc ld le mz lg lh li na lk ll lm im bi translated">大数据则不同:每一个选择都必须非常谨慎，因为你没有多少机会尝试这些模型。每一次尝试都要花费大量的金钱和时间，简而言之:没有出错的余地。使用特征工程，您可以在尝试之前了解如何调整模型或编辑数据。</p><p id="dbd7" class="pw-post-body-paragraph kr ks it kt b ku kv kd kw kx ky kg kz la lb lc ld le lf lg lh li lj lk ll lm im bi translated">例如，如果您的数据有太多的异常值，您需要删除它们以获得一个能够很好地概括的模型。另一个例子是，如果有非常相似的特征(它们的相关性接近1)，您可以删除其中的一个，因为它只需要更多的GPU来训练，并且还可能使模型表现最差。</p><p id="068b" class="pw-post-body-paragraph kr ks it kt b ku kv kd kw kx ky kg kz la lb lc ld le lf lg lh li lj lk ll lm im bi translated">比如GPT-3花了400万去训练(这当然是夸张了，但是你明白我的意思)。想象一下它背后的团队在一次尝试中花费这么多之前所做的工作。总之，在开始训练您的模型之前，您必须确定使用哪种调优和模型。</p><p id="b874" class="pw-post-body-paragraph kr ks it kt b ku kv kd kw kx ky kg kz la lb lc ld le lf lg lh li lj lk ll lm im bi translated">这是我到目前为止能够收集到的最新特性列表。我不会解释单个的特性，因为列表是巨大的，我的目标是在一个功能层次中适当地组织每个特性:</p><h1 id="2ae6" class="nb mf it bd mg nc nd ne mj nf ng nh mm ki ni kj mp kl nj km ms ko nk kp mv nl bi translated"><strong class="ak">特征提取</strong></h1><p id="6636" class="pw-post-body-paragraph kr ks it kt b ku mw kd kw kx mx kg kz la my lc ld le mz lg lh li na lk ll lm im bi translated">请注意，我使用术语特征工程来包含特征提取和特征选择。特征提取意味着增加(或从无到有)特征的数量，而特征选择意味着减少其数量。</p><h2 id="423b" class="me mf it bd mg mh mi dn mj mk ml dp mm la mn mo mp le mq mr ms li mt mu mv iz bi translated"><strong class="ak"> 1。编码</strong></h2><p id="59d1" class="pw-post-body-paragraph kr ks it kt b ku mw kd kw kx mx kg kz la my lc ld le mz lg lh li na lk ll lm im bi translated">通过编码，我将数据从分类转换成数字。当我们有文本而不是数字时，这变得非常重要，基本上是非结构化数据的混乱。像嵌入神经网络这样的技术变得非常有用。这些是最常见的技术，其中连续矢量是最先进的:</p><ul class=""><li id="5bb6" class="nm nn it kt b ku kv kx ky la no le np li nq lm nr ns nt nu bi translated">One_Hot(已订购)</li><li id="2c0a" class="nm nn it kt b ku nv kx nw la nx le ny li nz lm nr ns nt nu bi translated">One_Hot(无序)</li><li id="89d5" class="nm nn it kt b ku nv kx nw la nx le ny li nz lm nr ns nt nu bi translated">基于索引的编码</li><li id="fcd2" class="nm nn it kt b ku nv kx nw la nx le ny li nz lm nr ns nt nu bi translated">连续向量</li></ul><h2 id="b4aa" class="me mf it bd mg mh mi dn mj mk ml dp mm la mn mo mp le mq mr ms li mt mu mv iz bi translated"><strong class="ak"> 2。特征分割</strong></h2><p id="0c76" class="pw-post-body-paragraph kr ks it kt b ku mw kd kw kx mx kg kz la my lc ld le mz lg lh li na lk ll lm im bi translated">通过特征分割，我将一个特征转换成两个或多个特征，增加了模型中特征的数量。执行拆分没有规则，它取决于数据。</p><h2 id="ff3c" class="me mf it bd mg mh mi dn mj mk ml dp mm la mn mo mp le mq mr ms li mt mu mv iz bi translated">3.插补方法</h2><p id="fe3b" class="pw-post-body-paragraph kr ks it kt b ku mw kd kw kx mx kg kz la my lc ld le mz lg lh li na lk ll lm im bi translated">插补是一种用于填补数据中缺失值的统计方法。因为在处理数据时这是很常见的，有几种方法可以填充缺失的数据，这取决于您正在处理的数据。时间序列可能需要插值，而截面数据意味着插补。</p><ul class=""><li id="33e8" class="nm nn it kt b ku kv kx ky la no le np li nq lm nr ns nt nu bi translated">数值插补</li><li id="0ba3" class="nm nn it kt b ku nv kx nw la nx le ny li nz lm nr ns nt nu bi translated">分类插补</li><li id="e38f" class="nm nn it kt b ku nv kx nw la nx le ny li nz lm nr ns nt nu bi translated">随机样本插补</li><li id="9deb" class="nm nn it kt b ku nv kx nw la nx le ny li nz lm nr ns nt nu bi translated">分布终点插补</li></ul><h1 id="6b1e" class="nb mf it bd mg nc nd ne mj nf ng nh mm ki ni kj mp kl nj km ms ko nk kp mv nl bi translated">特征选择</h1><h2 id="d596" class="me mf it bd mg mh mi dn mj mk ml dp mm la mn mo mp le mq mr ms li mt mu mv iz bi translated">4.过滤方法</h2><p id="d6ea" class="pw-post-body-paragraph kr ks it kt b ku mw kd kw kx mx kg kz la my lc ld le mz lg lh li na lk ll lm im bi translated">过滤方法允许根据一些指标的及格分数来选择或取消选择整个特性(本质上是列)。例如，如果一列的方差(意味着值过于分散)太高，我们有充分的理由避免将该列放入模型中，因为这可能会降低其准确性。这同样适用于不同的指标。</p><ul class=""><li id="e805" class="nm nn it kt b ku kv kx ky la no le np li nq lm nr ns nt nu bi translated">方差阈值</li><li id="7927" class="nm nn it kt b ku nv kx nw la nx le ny li nz lm nr ns nt nu bi translated">平均绝对差值</li><li id="f14c" class="nm nn it kt b ku nv kx nw la nx le ny li nz lm nr ns nt nu bi translated">费希尔评分</li><li id="d8f0" class="nm nn it kt b ku nv kx nw la nx le ny li nz lm nr ns nt nu bi translated">相关系数</li><li id="c2a7" class="nm nn it kt b ku nv kx nw la nx le ny li nz lm nr ns nt nu bi translated">AM-GM不等式</li><li id="7b51" class="nm nn it kt b ku nv kx nw la nx le ny li nz lm nr ns nt nu bi translated">基于标准差的异常值检测</li><li id="02a7" class="nm nn it kt b ku nv kx nw la nx le ny li nz lm nr ns nt nu bi translated">百分位异常值检测</li><li id="316c" class="nm nn it kt b ku nv kx nw la nx le ny li nz lm nr ns nt nu bi translated">卡方检验</li><li id="b75c" class="nm nn it kt b ku nv kx nw la nx le ny li nz lm nr ns nt nu bi translated">信息增益</li></ul><h2 id="b7dd" class="me mf it bd mg mh mi dn mj mk ml dp mm la mn mo mp le mq mr ms li mt mu mv iz bi translated">5.包装方法</h2><p id="5db3" class="pw-post-body-paragraph kr ks it kt b ku mw kd kw kx mx kg kz la my lc ld le mz lg lh li na lk ll lm im bi translated">包装方法将几种使用R平方值来衡量某个特征是否应该保留的技术组合在一起。这些技术通过在监视分数变化的同时迭代地使用特征来工作，因此它们递归地工作:</p><ul class=""><li id="5168" class="nm nn it kt b ku kv kx ky la no le np li nq lm nr ns nt nu bi translated">详尽的特征选择</li><li id="2322" class="nm nn it kt b ku nv kx nw la nx le ny li nz lm nr ns nt nu bi translated">向前回归</li><li id="9bc3" class="nm nn it kt b ku nv kx nw la nx le ny li nz lm nr ns nt nu bi translated">向后回归/RFE _递归特征消除</li><li id="b51c" class="nm nn it kt b ku nv kx nw la nx le ny li nz lm nr ns nt nu bi translated">逐步回归</li><li id="70de" class="nm nn it kt b ku nv kx nw la nx le ny li nz lm nr ns nt nu bi translated">双向消除</li></ul><h2 id="4935" class="me mf it bd mg mh mi dn mj mk ml dp mm la mn mo mp le mq mr ms li mt mu mv iz bi translated">:数值插补</h2><p id="ddaa" class="pw-post-body-paragraph kr ks it kt b ku mw kd kw kx mx kg kz la my lc ld le mz lg lh li na lk ll lm im bi translated">数字插补技术列表。</p><ul class=""><li id="4066" class="nm nn it kt b ku kv kx ky la no le np li nq lm nr ns nt nu bi translated">插入文字</li><li id="6868" class="nm nn it kt b ku nv kx nw la nx le ny li nz lm nr ns nt nu bi translated">推断</li><li id="a839" class="nm nn it kt b ku nv kx nw la nx le ny li nz lm nr ns nt nu bi translated">平均插补</li><li id="e496" class="nm nn it kt b ku nv kx nw la nx le ny li nz lm nr ns nt nu bi translated">代替</li><li id="58fc" class="nm nn it kt b ku nv kx nw la nx le ny li nz lm nr ns nt nu bi translated">热卡插补</li><li id="56e0" class="nm nn it kt b ku nv kx nw la nx le ny li nz lm nr ns nt nu bi translated">冷甲板归集</li><li id="a3fd" class="nm nn it kt b ku nv kx nw la nx le ny li nz lm nr ns nt nu bi translated">回归插补</li><li id="9021" class="nm nn it kt b ku nv kx nw la nx le ny li nz lm nr ns nt nu bi translated">随机回归插补</li></ul><h2 id="331d" class="me mf it bd mg mh mi dn mj mk ml dp mm la mn mo mp le mq mr ms li mt mu mv iz bi translated">6.宁滨方法</h2><p id="89e9" class="pw-post-body-paragraph kr ks it kt b ku mw kd kw kx mx kg kz la my lc ld le mz lg lh li na lk ll lm im bi translated">宁滨方法是降低数据复杂性的一种方式。我们可以将数据分组，并通过对其应用函数(例如平均值)来估算一组数据的值:</p><ul class=""><li id="17c5" class="nm nn it kt b ku kv kx ky la no le np li nq lm nr ns nt nu bi translated">数值宁滨</li><li id="9fd6" class="nm nn it kt b ku nv kx nw la nx le ny li nz lm nr ns nt nu bi translated">绝对宁滨</li></ul><h2 id="d426" class="me mf it bd mg mh mi dn mj mk ml dp mm la mn mo mp le mq mr ms li mt mu mv iz bi translated">7.分组操作方法</h2><p id="a86e" class="pw-post-body-paragraph kr ks it kt b ku mw kd kw kx mx kg kz la my lc ld le mz lg lh li na lk ll lm im bi translated">分组运算是一种将函数应用于特定值组的方法，使用的算法称为group by:</p><ul class=""><li id="c894" class="nm nn it kt b ku kv kx ky la no le np li nq lm nr ns nt nu bi translated">范畴分组</li><li id="223f" class="nm nn it kt b ku nv kx nw la nx le ny li nz lm nr ns nt nu bi translated">数字分组</li></ul><h2 id="e69b" class="me mf it bd mg mh mi dn mj mk ml dp mm la mn mo mp le mq mr ms li mt mu mv iz bi translated">8.嵌入式方法</h2><p id="5344" class="pw-post-body-paragraph kr ks it kt b ku mw kd kw kx mx kg kz la my lc ld le mz lg lh li na lk ll lm im bi translated">嵌入方法是在训练模型时执行特征选择的方法。这在神经网络中很常见，在神经网络中，使用标准化技术自动选择或取消选择特征:</p><ul class=""><li id="a1e7" class="nm nn it kt b ku kv kx ky la no le np li nq lm nr ns nt nu bi translated">L1归一化</li><li id="5df3" class="nm nn it kt b ku nv kx nw la nx le ny li nz lm nr ns nt nu bi translated">L2归一化</li><li id="b3df" class="nm nn it kt b ku nv kx nw la nx le ny li nz lm nr ns nt nu bi translated">随机森林重要性</li></ul><h2 id="0238" class="me mf it bd mg mh mi dn mj mk ml dp mm la mn mo mp le mq mr ms li mt mu mv iz bi translated">9.混合方法</h2><p id="bd54" class="pw-post-body-paragraph kr ks it kt b ku mw kd kw kx mx kg kz la my lc ld le mz lg lh li na lk ll lm im bi translated">混合方法是不同技术的组合(你可以从上面的列表中选择)来执行特征工程。</p><h1 id="bb0f" class="nb mf it bd mg nc nd ne mj nf ng nh mm ki ni kj mp kl nj km ms ko nk kp mv nl bi translated">特征编辑</h1><p id="4374" class="pw-post-body-paragraph kr ks it kt b ku mw kd kw kx mx kg kz la my lc ld le mz lg lh li na lk ll lm im bi translated">虽然这个名称并不存在，但我将所有允许编辑数据的方法，而不是增加或减少特征的数量，归入这一部分。</p><h2 id="4be5" class="me mf it bd mg mh mi dn mj mk ml dp mm la mn mo mp le mq mr ms li mt mu mv iz bi translated">10.特征缩放</h2><p id="f56e" class="pw-post-body-paragraph kr ks it kt b ku mw kd kw kx mx kg kz la my lc ld le mz lg lh li na lk ll lm im bi translated">构建回归模型时，要素缩放是一种常见的要素工程技术:数据需要放在同一个仪表中才能正常工作。</p><ul class=""><li id="f03c" class="nm nn it kt b ku kv kx ky la no le np li nq lm nr ns nt nu bi translated">标准化</li><li id="6bf7" class="nm nn it kt b ku nv kx nw la nx le ny li nz lm nr ns nt nu bi translated">正常化</li><li id="97d6" class="nm nn it kt b ku nv kx nw la nx le ny li nz lm nr ns nt nu bi translated">对数变换</li></ul></div></div>    
</body>
</html>