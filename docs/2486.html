<html>
<head>
<title>How to Set Up Your Environment for Spark</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">如何为Spark设置环境</h1>
<blockquote>原文：<a href="https://pub.towardsai.net/how-to-set-up-your-environment-for-spark-7820b84491ef?source=collection_archive---------0-----------------------#2022-01-15">https://pub.towardsai.net/how-to-set-up-your-environment-for-spark-7820b84491ef?source=collection_archive---------0-----------------------#2022-01-15</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><h2 id="5ee7" class="io ip iq bd b dl ir is it iu iv iw dk ix translated" aria-label="kicker paragraph"><a class="ae ep" href="https://towardsai.net/p/category/data-engineering" rel="noopener ugc nofollow" target="_blank">数据工程</a></h2><div class=""/><figure class="gl gn jx jy jz ka gh gi paragraph-image"><div role="button" tabindex="0" class="kb kc di kd bf ke"><div class="gh gi jw"><img src="../Images/7fd443edac05657d8b2ca7c5b9205c26.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*5ri8W3LSfnLHSFVd-ghUbw.jpeg"/></div></div><figcaption class="kh ki gj gh gi kj kk bd b be z dk translated">由<a class="ae kl" href="https://unsplash.com/@ilyapavlov" rel="noopener ugc nofollow" target="_blank">伊利亚·巴甫洛夫</a>在<a class="ae kl" href="https://unsplash.com/photos/OqtafYT5kTw" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上拍摄</figcaption></figure><p id="fa0a" class="pw-post-body-paragraph km kn iq ko b kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">Spark是一个非常受欢迎的开源大数据框架，业内许多公司都在使用它。这里我想向你展示如何在Linux机器上设置Spark环境(我用的是<strong class="ko ja"> Ubuntu 20.04.3 </strong>)。</p><h1 id="63d9" class="lk ll iq bd lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma mb mc md me mf mg mh bi translated">装置</h1><p id="4cdf" class="pw-post-body-paragraph km kn iq ko b kp mi kr ks kt mj kv kw kx mk kz la lb ml ld le lf mm lh li lj ij bi translated">这是我们需要安装的东西的列表:</p><ol class=""><li id="b4a1" class="mn mo iq ko b kp kq kt ku kx mp lb mq lf mr lj ms mt mu mv bi translated">JDK</li><li id="8022" class="mn mo iq ko b kp mw kt mx kx my lb mz lf na lj ms mt mu mv bi translated">想法</li><li id="d0dd" class="mn mo iq ko b kp mw kt mx kx my lb mz lf na lj ms mt mu mv bi translated">斯卡拉</li><li id="a856" class="mn mo iq ko b kp mw kt mx kx my lb mz lf na lj ms mt mu mv bi translated">火花</li><li id="2e64" class="mn mo iq ko b kp mw kt mx kx my lb mz lf na lj ms mt mu mv bi translated">PySpark(可选)</li><li id="b387" class="mn mo iq ko b kp mw kt mx kx my lb mz lf na lj ms mt mu mv bi translated">Hadoop</li></ol><h2 id="c24e" class="nb ll iq bd lm nc nd dn lq ne nf dp lu kx ng nh ly lb ni nj mc lf nk nl mg iw bi translated">1.JDK</h2><p id="2122" class="pw-post-body-paragraph km kn iq ko b kp mi kr ks kt mj kv kw kx mk kz la lb ml ld le lf mm lh li lj ij bi translated">JDK是Java开发工具包的缩写，是Java的开发环境。Spark是用Scala写的，Scala是一种和Java非常相似的语言，也运行在JVM (Java虚拟机)上，所以我们需要先安装JDK。在这里我安装了<strong class="ko ja"> JDK 11.0.13 </strong>。</p><p id="b53f" class="pw-post-body-paragraph km kn iq ko b kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">要安装JDK，请运行:</p><pre class="nm nn no np gt nq nr ns nt aw nu bi"><span id="1f74" class="nb ll iq nr b gy nv nw l nx ny">$ sudo apt install default-jre</span></pre><p id="44a4" class="pw-post-body-paragraph km kn iq ko b kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">接下来，检查安装是否完成:</p><pre class="nm nn no np gt nq nr ns nt aw nu bi"><span id="f25a" class="nb ll iq nr b gy nv nw l nx ny">$ java -version</span></pre><p id="8af8" class="pw-post-body-paragraph km kn iq ko b kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">它应该输出以下内容:</p><pre class="nm nn no np gt nq nr ns nt aw nu bi"><span id="3d41" class="nb ll iq nr b gy nv nw l nx ny">openjdk version "11.0.13" 2021-10-19<br/>OpenJDK Runtime Environment (build 11.0.13+8-Ubuntu-0ubuntu1.20.04)<br/>OpenJDK 64-Bit Server VM (build 11.0.13+8-Ubuntu-0ubuntu1.20.04, mixed mode, sharing)</span></pre><h2 id="bb0e" class="nb ll iq bd lm nc nd dn lq ne nf dp lu kx ng nh ly lb ni nj mc lf nk nl mg iw bi translated">2.想法</h2><p id="5ec9" class="pw-post-body-paragraph km kn iq ko b kp mi kr ks kt mj kv kw kx mk kz la lb ml ld le lf mm lh li lj ij bi translated">IntelliJ IDEA是最流行的Java/Scala IDE。我们需要它来编写和运行代码。</p><p id="e20e" class="pw-post-body-paragraph km kn iq ko b kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">在这里下载并安装IDEA的最新版本:<a class="ae kl" href="https://www.jetbrains.com/idea/download/#section=linux" rel="noopener ugc nofollow" target="_blank">https://www.jetbrains.com/idea/download/#section=linux</a>。我选择了免费社区版。</p><h2 id="1938" class="nb ll iq bd lm nc nd dn lq ne nf dp lu kx ng nh ly lb ni nj mc lf nk nl mg iw bi translated">3.斯卡拉</h2><p id="50f2" class="pw-post-body-paragraph km kn iq ko b kp mi kr ks kt mj kv kw kx mk kz la lb ml ld le lf mm lh li lj ij bi translated">Scala是常用于编写Spark程序的语言(还有Python！).如果你想学习如何用Scala编程，我强烈推荐这门课程:<a class="ae kl" href="https://www.coursera.org/specializations/scala" rel="noopener ugc nofollow" target="_blank">https://www.coursera.org/specializations/scala</a>。如果你不懂Scala，可以用Python，但是还是要安装Scala！</p><p id="52c7" class="pw-post-body-paragraph km kn iq ko b kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">在这里下载Scala:<a class="ae kl" href="https://www.scala-lang.org/download/scala2.html" rel="noopener ugc nofollow" target="_blank">https://www.scala-lang.org/download/scala2.html</a>。您可以选择“下载用于UNIX的Scala二进制文件”并在本地解压缩二进制文件，或者通过选择“<a class="ae kl" href="https://docs.scala-lang.org/getting-started/intellij-track/getting-started-with-scala-in-intellij.html" rel="noopener ugc nofollow" target="_blank">IntelliJ</a>中的Scala入门”使用IDEA安装Scala。我做了后者，在我的机器上安装了<strong class="ko ja"> Scala 2.12.11 </strong>。</p><figure class="nm nn no np gt ka gh gi paragraph-image"><div role="button" tabindex="0" class="kb kc di kd bf ke"><div class="gh gi nz"><img src="../Images/d4b402002bb9dc2c11a37cdae355a1fd.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*LvvcH1Gg4PyiBVYw.png"/></div></div></figure><h2 id="d9eb" class="nb ll iq bd lm nc nd dn lq ne nf dp lu kx ng nh ly lb ni nj mc lf nk nl mg iw bi translated">4.火花</h2><p id="597a" class="pw-post-body-paragraph km kn iq ko b kp mi kr ks kt mj kv kw kx mk kz la lb ml ld le lf mm lh li lj ij bi translated">在这里下载Spark:<a class="ae kl" href="https://spark.apache.org/downloads.html" rel="noopener ugc nofollow" target="_blank">https://spark.apache.org/downloads.html</a>。这里我选择了为<strong class="ko ja"> Apache Hadoop 3.3 </strong>预建的<strong class="ko ja">最新版本(3.2.0) </strong>。</p><p id="f2d1" class="pw-post-body-paragraph km kn iq ko b kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">然后打开包并将其移动到您的首选文件夹:</p><pre class="nm nn no np gt nq nr ns nt aw nu bi"><span id="8e96" class="nb ll iq nr b gy nv nw l nx ny">$ tar -zxvf spark-3.2.0-bin-hadoop3.2.tgz<br/>$ mv spark-3.2.0-bin-hadoop3.2 /opt/spark</span></pre><p id="6187" class="pw-post-body-paragraph km kn iq ko b kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">然后，您需要修改bash配置文件(<code class="fe oa ob oc nr b">~/.bashrc</code>或<code class="fe oa ob oc nr b">~/.bash_profile</code>或<code class="fe oa ob oc nr b">~/.zshrc</code>)，并在您的路径中添加Spark:</p><pre class="nm nn no np gt nq nr ns nt aw nu bi"><span id="d662" class="nb ll iq nr b gy nv nw l nx ny">export SPARK_HOME=/opt/spark<br/>export PATH=$PATH:$SPARK_HOME/bin:$SPARK_HOME/sbin</span></pre><p id="0ded" class="pw-post-body-paragraph km kn iq ko b kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">最后，您需要再次运行配置文件以使其工作:</p><pre class="nm nn no np gt nq nr ns nt aw nu bi"><span id="25af" class="nb ll iq nr b gy nv nw l nx ny">$ source ~/.bashrc</span></pre><p id="4d4f" class="pw-post-body-paragraph km kn iq ko b kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">现在你可以在你的机器上运行Spark了！转到<code class="fe oa ob oc nr b">/opt/spark/bin/</code>并运行:</p><pre class="nm nn no np gt nq nr ns nt aw nu bi"><span id="7f17" class="nb ll iq nr b gy nv nw l nx ny">$ ./spark-shell</span></pre><p id="de84" class="pw-post-body-paragraph km kn iq ko b kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">如果你看到下面的结果，这意味着你已经为Spark做好了准备！</p><figure class="nm nn no np gt ka gh gi paragraph-image"><div role="button" tabindex="0" class="kb kc di kd bf ke"><div class="gh gi od"><img src="../Images/7d823372997ddbda520bb964cf858aa4.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*kOIUyE_0SRtzZU51.png"/></div></div></figure><h2 id="201b" class="nb ll iq bd lm nc nd dn lq ne nf dp lu kx ng nh ly lb ni nj mc lf nk nl mg iw bi translated">5.PySpark(可选)</h2><p id="6ffe" class="pw-post-body-paragraph km kn iq ko b kp mi kr ks kt mj kv kw kx mk kz la lb ml ld le lf mm lh li lj ij bi translated">简单来说，PySpark就是Spark的Python版本。不用学Scala，用PySpark就能写出Python风格的Spark代码。要使用<a class="ae kl" href="https://pypi.org/project/pyspark/" rel="noopener ugc nofollow" target="_blank"> PyPI </a>安装PySpark，请运行:</p><pre class="nm nn no np gt nq nr ns nt aw nu bi"><span id="107c" class="nb ll iq nr b gy nv nw l nx ny">$ pip install pyspark</span></pre><h2 id="be0a" class="nb ll iq bd lm nc nd dn lq ne nf dp lu kx ng nh ly lb ni nj mc lf nk nl mg iw bi translated">6.Hadoop</h2><p id="e0be" class="pw-post-body-paragraph km kn iq ko b kp mi kr ks kt mj kv kw kx mk kz la lb ml ld le lf mm lh li lj ij bi translated">Hadoop是Spark之前的“上一代”大数据框架。尽管Spark很棒，但从某种意义上来说，它实际上是建立在Hadoop之上的，并且仍然依赖于Hadoop的组件。关于他们关系的更多细节可以在<a class="ae kl" href="https://www.geeksforgeeks.org/difference-between-hadoop-and-spark/" rel="noopener ugc nofollow" target="_blank">这篇文章</a>中找到。在这里，我想在Hadoop集群上运行Spark作业，并使用YARN (Hadoop的资源管理和调度工具)和HDFS (Hadoop的数据文件系统)，因为它们真的很容易使用，所以安装Hadoop是必须的。</p><p id="eb13" class="pw-post-body-paragraph km kn iq ko b kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">要安装Hadoop，请在这里下载:<a class="ae kl" href="https://hadoop.apache.org/releases.html" rel="noopener ugc nofollow" target="_blank">https://hadoop.apache.org/releases.html</a>。这里我选的是<strong class="ko ja"> 3.2.2版本</strong>。</p><p id="45f4" class="pw-post-body-paragraph km kn iq ko b kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">然后打开包并将其移动到您的首选文件夹:</p><pre class="nm nn no np gt nq nr ns nt aw nu bi"><span id="6e7f" class="nb ll iq nr b gy nv nw l nx ny">$ tar -zxvf hadoop-3.2.2.tar.gz<br/>$ mv hadoop-3.2.2.tar.gz /usr/local/hadoop/</span></pre><p id="f2f0" class="pw-post-body-paragraph km kn iq ko b kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">然后您需要修改您的bash配置文件(<code class="fe oa ob oc nr b">~/.bashrc</code>或<code class="fe oa ob oc nr b">~/.bash_profile</code>或<code class="fe oa ob oc nr b">~/.zshrc</code>)，并将Hadoop添加到您的路径中:</p><pre class="nm nn no np gt nq nr ns nt aw nu bi"><span id="b03d" class="nb ll iq nr b gy nv nw l nx ny">export HADOOP_HOME=/usr/local/hadoop/hadoop-3.2.2/<br/>export HADOOP_PREFIX=$HADOOP_HOME<br/>export PATH=$HADOOP_HOME/bin:$HADOOP_HOME/sbin:$PATH<br/>export HADOOP_CONF_DIR=$HADOOP_HOME/etc/hadoop</span></pre><p id="bec9" class="pw-post-body-paragraph km kn iq ko b kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">然后再次运行配置文件使其工作:</p><pre class="nm nn no np gt nq nr ns nt aw nu bi"><span id="629c" class="nb ll iq nr b gy nv nw l nx ny">$ source ~/.bashrc</span></pre><p id="5a3f" class="pw-post-body-paragraph km kn iq ko b kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">现在你可以在你的机器上运行Hadoop了！转到<code class="fe oa ob oc nr b">/usr/local/hadoop/hadoop-3.2.2/bin</code>并运行:</p><pre class="nm nn no np gt nq nr ns nt aw nu bi"><span id="f7e6" class="nb ll iq nr b gy nv nw l nx ny">$ hadoop version</span></pre><p id="5827" class="pw-post-body-paragraph km kn iq ko b kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">如果你看到下面的结果，这意味着Hadoop已经成功安装！</p><figure class="nm nn no np gt ka gh gi paragraph-image"><div role="button" tabindex="0" class="kb kc di kd bf ke"><div class="gh gi oe"><img src="../Images/1e519fee69d2799566f9ccbb961f4e72.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*JkOToYBwrFkIoIdN.png"/></div></div></figure><h1 id="0e3b" class="lk ll iq bd lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma mb mc md me mf mg mh bi translated">配置</h1><h2 id="992b" class="nb ll iq bd lm nc nd dn lq ne nf dp lu kx ng nh ly lb ni nj mc lf nk nl mg iw bi translated">1.配置Hadoop分布式模式(HDFS和纱线设置)</h2><h2 id="763b" class="nb ll iq bd lm nc nd dn lq ne nf dp lu kx ng nh ly lb ni nj mc lf nk nl mg iw bi translated">1.1 SSH验证设置</h2><p id="c581" class="pw-post-body-paragraph km kn iq ko b kp mi kr ks kt mj kv kw kx mk kz la lb ml ld le lf mm lh li lj ij bi translated">首先，您需要按照“安装”中的步骤确保您的机器中有Java。然后，我们需要设置分布式身份验证密钥对，以便主节点可以轻松地连接到工作节点。使用以下命令在您的计算机上安装SSH:</p><pre class="nm nn no np gt nq nr ns nt aw nu bi"><span id="5a1f" class="nb ll iq nr b gy nv nw l nx ny">$ sudo apt install openssh-client<br/>$ sudo apt install openssh-server</span></pre><p id="cc07" class="pw-post-body-paragraph km kn iq ko b kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">然后在每个节点上使用以下命令生成一个公共ssh-key:</p><pre class="nm nn no np gt nq nr ns nt aw nu bi"><span id="69c6" class="nb ll iq nr b gy nv nw l nx ny">$ ssh-keygen -t rsa -P ''</span></pre><p id="315b" class="pw-post-body-paragraph km kn iq ko b kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">然后将公钥发送到集群中的每台机器:</p><pre class="nm nn no np gt nq nr ns nt aw nu bi"><span id="a8a9" class="nb ll iq nr b gy nv nw l nx ny">$ cat ~/.ssh/id_dsa.pub &gt;&gt; ~/.ssh/autorized_keys</span></pre><p id="a05a" class="pw-post-body-paragraph km kn iq ko b kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">运行<code class="fe oa ob oc nr b">ssh localhost</code>检查是否仍然登录键。如果你看到下面，你的SSH设置就完成了！</p><figure class="nm nn no np gt ka gh gi paragraph-image"><div role="button" tabindex="0" class="kb kc di kd bf ke"><div class="gh gi of"><img src="../Images/c66a081542956a76ec47a9e7fc5efb36.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*exc-R6GoPf9O9dpY.png"/></div></div></figure><h2 id="13cc" class="nb ll iq bd lm nc nd dn lq ne nf dp lu kx ng nh ly lb ni nj mc lf nk nl mg iw bi translated">1.2 NameNode位置设置</h2><p id="6606" class="pw-post-body-paragraph km kn iq ko b kp mi kr ks kt mj kv kw kx mk kz la lb ml ld le lf mm lh li lj ij bi translated">更新您的<code class="fe oa ob oc nr b">/hadoop/etc/hadoop/core-site.xml</code>以设置NameNode位置:</p><pre class="nm nn no np gt nq nr ns nt aw nu bi"><span id="356e" class="nb ll iq nr b gy nv nw l nx ny">&lt;configuration&gt;<br/>    &lt;!-- specify communication address for namenode&gt;<br/>    &lt;property&gt;<br/>        &lt;name&gt;fs.defaultFS&lt;/name&gt;<br/>        &lt;value&gt;hdfs://localhost:9000&lt;/value&gt;<br/>        &lt;description&gt;The name of the default file system.&lt;/description&gt;<br/>    &lt;/property&gt;<br/>    &lt;!-- specify storage directory of temorary files generated during Hadoop run&gt;<br/>    &lt;property&gt;<br/>        &lt;name&gt;hadoop.tmp.dir&lt;/name&gt;<br/>        &lt;value&gt;file:/usr/local/hadoop/hadoop-3.2.2/tmp&lt;/value&gt;<br/>        &lt;description&gt;A base for other temporary directories.&lt;/description&gt;<br/>    &lt;/property&gt;<br/>&lt;/configuration&gt;</span></pre><h2 id="a70b" class="nb ll iq bd lm nc nd dn lq ne nf dp lu kx ng nh ly lb ni nj mc lf nk nl mg iw bi translated">1.3 HDFS路径设置</h2><p id="02f7" class="pw-post-body-paragraph km kn iq ko b kp mi kr ks kt mj kv kw kx mk kz la lb ml ld le lf mm lh li lj ij bi translated">更新您的<code class="fe oa ob oc nr b">hadoop/etc/hadoop/hdfs-site.xml</code>以设置HDFS路径:</p><pre class="nm nn no np gt nq nr ns nt aw nu bi"><span id="111d" class="nb ll iq nr b gy nv nw l nx ny">&lt;configuration&gt;<br/>    &lt;!-- specify how many times data is replicated in the cluster&gt;<br/>    &lt;property&gt;<br/>        &lt;name&gt;dfs.replication&lt;/name&gt;<br/>        &lt;value&gt;1&lt;/value&gt;<br/>    &lt;/property&gt;<br/>    &lt;property&gt;<br/>        &lt;name&gt;dfs.namenode.name.dir&lt;/name&gt;<br/>        &lt;value&gt;file:/usr/local/hadoop/hadoop-3.2.2/tmp/dfs/name&lt;/value&gt;<br/>    &lt;/property&gt;<br/>    &lt;property&gt;<br/>        &lt;name&gt;dfs.namenode.data.dir&lt;/name&gt;<br/>        &lt;value&gt;file:/usr/local/hadoop/hadoop-3.2.2/tmp/dfs/data&lt;/value&gt;<br/>    &lt;/property&gt;<br/>&lt;/configuration&gt;</span></pre><h2 id="6550" class="nb ll iq bd lm nc nd dn lq ne nf dp lu kx ng nh ly lb ni nj mc lf nk nl mg iw bi translated">1.4配置纱线</h2><p id="ca12" class="pw-post-body-paragraph km kn iq ko b kp mi kr ks kt mj kv kw kx mk kz la lb ml ld le lf mm lh li lj ij bi translated">首先，编辑<code class="fe oa ob oc nr b">hadoop/etc/hadoop/mapred-site.xml</code>将YARN设置为MapReduce操作的默认框架:</p><pre class="nm nn no np gt nq nr ns nt aw nu bi"><span id="57b8" class="nb ll iq nr b gy nv nw l nx ny">&lt;configuration&gt;<br/>    &lt;property&gt;<br/>        &lt;name&gt;mapreduce.framework.name&lt;/name&gt;<br/>        &lt;value&gt;yarn&lt;/value&gt;<br/>    &lt;/property&gt;<br/>    &lt;property&gt;<br/>        &lt;name&gt;yarn.app.mapreduce.am.env&lt;/name&gt;<br/>        &lt;value&gt;HADOOP_MAPRED_HOME=$HADOOP_HOME&lt;/value&gt;<br/>    &lt;/property&gt;<br/>    &lt;property&gt;<br/>        &lt;name&gt;mapreduce.map.env&lt;/name&gt;<br/>        &lt;value&gt;HADOOP_MAPRED_HOME=$HADOOP_HOME&lt;/value&gt;<br/>    &lt;/property&gt;<br/>    &lt;property&gt;<br/>        &lt;name&gt;mapreduce.reduce.env&lt;/name&gt;<br/>        &lt;value&gt;HADOOP_MAPRED_HOME=$HADOOP_HOME&lt;/value&gt;<br/>    &lt;/property&gt;<br/>&lt;/configuration&gt;</span></pre><p id="a12e" class="pw-post-body-paragraph km kn iq ko b kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">然后，编辑<code class="fe oa ob oc nr b">hadoop/etc/hadoop/yarn-site.xml</code>:</p><pre class="nm nn no np gt nq nr ns nt aw nu bi"><span id="4cce" class="nb ll iq nr b gy nv nw l nx ny">&lt;property&gt;<br/>        &lt;name&gt;yarn.nodemanager.aux-services&lt;/name&gt;<br/>        &lt;value&gt;mapreduce_shuffle&lt;/value&gt;<br/>    &lt;/property&gt;</span><span id="2d08" class="nb ll iq nr b gy og nw l nx ny">    &lt;property&gt;<br/>        &lt;name&gt;yarn.nodemanager.aux-services.mapreduce.shuffle.class&lt;/name&gt;<br/>        &lt;value&gt;org.apache.hadoop.mapred.ShuffleHandler&lt;/value&gt;<br/>&lt;/property&gt;</span></pre><h2 id="fe07" class="nb ll iq bd lm nc nd dn lq ne nf dp lu kx ng nh ly lb ni nj mc lf nk nl mg iw bi translated">1.5格式HDFS</h2><p id="0b86" class="pw-post-body-paragraph km kn iq ko b kp mi kr ks kt mj kv kw kx mk kz la lb ml ld le lf mm lh li lj ij bi translated">设置完成后，您需要通过运行以下命令来格式化HDFS:</p><pre class="nm nn no np gt nq nr ns nt aw nu bi"><span id="c976" class="nb ll iq nr b gy nv nw l nx ny">$ hadoop namenode -format</span></pre><p id="afe2" class="pw-post-body-paragraph km kn iq ko b kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">如果你看到下面，格式化完成了！</p><figure class="nm nn no np gt ka gh gi paragraph-image"><div role="button" tabindex="0" class="kb kc di kd bf ke"><div class="gh gi of"><img src="../Images/e69e8367c87caa41c773465466da7830.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*KSMM6J0x_vipGcRY.png"/></div></div></figure><h2 id="0c9d" class="nb ll iq bd lm nc nd dn lq ne nf dp lu kx ng nh ly lb ni nj mc lf nk nl mg iw bi translated">1.6运行HDFS和纱线</h2><p id="e1c7" class="pw-post-body-paragraph km kn iq ko b kp mi kr ks kt mj kv kw kx mk kz la lb ml ld le lf mm lh li lj ij bi translated">现在你可以经营HDFS和纱线服务！转到<code class="fe oa ob oc nr b">/usr/local/hadoop/hadoop-3.2.2/bin</code>并运行:</p><pre class="nm nn no np gt nq nr ns nt aw nu bi"><span id="b31c" class="nb ll iq nr b gy nv nw l nx ny">$ start-all.sh</span></pre><p id="5d77" class="pw-post-body-paragraph km kn iq ko b kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">使用<code class="fe oa ob oc nr b">jps</code>命令查看HDFS和纱线是否成功运行:</p><figure class="nm nn no np gt ka gh gi paragraph-image"><div role="button" tabindex="0" class="kb kc di kd bf ke"><div class="gh gi oh"><img src="../Images/825096751d1f7df39f8a215f9589abae.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*mT4Jky6y03b5iWWJ.png"/></div></div></figure><p id="2ce3" class="pw-post-body-paragraph km kn iq ko b kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">毕竟，您的作业已经完成，您可以通过转到<code class="fe oa ob oc nr b">/usr/local/hadoop/hadoop-3.2.2/bin</code>并运行以下命令来终止Hadoop服务:</p><pre class="nm nn no np gt nq nr ns nt aw nu bi"><span id="7987" class="nb ll iq nr b gy nv nw l nx ny">$ stop-all.sh</span></pre><h2 id="bda3" class="nb ll iq bd lm nc nd dn lq ne nf dp lu kx ng nh ly lb ni nj mc lf nk nl mg iw bi translated">2.在IDEA中创建和运行Scala代码</h2><h2 id="91c3" class="nb ll iq bd lm nc nd dn lq ne nf dp lu kx ng nh ly lb ni nj mc lf nk nl mg iw bi translated">2.1创建新的Scala项目</h2><p id="a20e" class="pw-post-body-paragraph km kn iq ko b kp mi kr ks kt mj kv kw kx mk kz la lb ml ld le lf mm lh li lj ij bi translated">正如我前面提到的，IDEA是一个非常流行的Scala IDE。原因之一是用IDEA为Scala项目建立开发环境非常容易。以下是方法:</p><p id="9f4b" class="pw-post-body-paragraph km kn iq ko b kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">首先，下载后打开IntelliJ IDEA。点击<strong class="ko ja">文件- &gt;新建- &gt;项目</strong>。选择<strong class="ko ja"> Scala - &gt; sbt </strong>，点击<strong class="ko ja">下一步</strong>:</p><figure class="nm nn no np gt ka gh gi paragraph-image"><div role="button" tabindex="0" class="kb kc di kd bf ke"><div class="gh gi nz"><img src="../Images/9fc359d00c6383e9e93b8ce86912f5fd.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*VnEO3SDjUYNE2KX7.png"/></div></div></figure><p id="9f0b" class="pw-post-body-paragraph km kn iq ko b kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">然后，命名您的项目并选择正确的JDK、SBT和Scala版本。确保版本与我们之前安装的一致！</p><figure class="nm nn no np gt ka gh gi paragraph-image"><div role="button" tabindex="0" class="kb kc di kd bf ke"><div class="gh gi nz"><img src="../Images/cb383f83e3569703bf753534b1327d5b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*Bn-Ci2I-EzytzA8U.png"/></div></div></figure><p id="c25e" class="pw-post-body-paragraph km kn iq ko b kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">然后点击<strong class="ko ja">完成</strong>，您将看到项目视图:</p><figure class="nm nn no np gt ka gh gi paragraph-image"><div role="button" tabindex="0" class="kb kc di kd bf ke"><div class="gh gi nz"><img src="../Images/abb933eb47a881e7850162b0c038bba6.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*vOMUyXRRv0sdaBy_.png"/></div></div></figure><p id="28a3" class="pw-post-body-paragraph km kn iq ko b kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">打开<strong class="ko ja"> build.sbt </strong>文件，修改如下:</p><pre class="nm nn no np gt nq nr ns nt aw nu bi"><span id="fc0d" class="nb ll iq nr b gy nv nw l nx ny">name := "demo_example"</span><span id="4922" class="nb ll iq nr b gy og nw l nx ny">scalaVersion := "2.12.11"</span><span id="489d" class="nb ll iq nr b gy og nw l nx ny">version := "1.0"</span><span id="e601" class="nb ll iq nr b gy og nw l nx ny">libraryDependencies += "org.scala-lang.modules" %% "scala-parser-combinators" % "1.1.2"<br/>libraryDependencies += "org.apache.spark" %% "spark-core" % "3.2.0"<br/>libraryDependencies += "org.apache.spark" %% "spark-mllib" % "3.2.0"<br/>libraryDependencies += "org.apache.spark" %% "spark-sql" % "3.2.0"<br/>libraryDependencies += "org.apache.spark" %% "spark-hive" % "3.2.0"</span></pre><p id="0bff" class="pw-post-body-paragraph km kn iq ko b kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">最后四行添加Spark包作为Scala依赖项。一旦你的编辑被保存，你会看到三个选项，<strong class="ko ja">刷新项目</strong>，<strong class="ko ja">启用自动导入，</strong>和<strong class="ko ja">忽略</strong>。点击<strong class="ko ja">启用自动导入</strong>，以便IDEA开始下载依赖项。它还会在每次对build.sbt进行更改时构建您的项目。一旦完成，您将在左侧窗格的外部库中看到所有spark依赖项。</p><figure class="nm nn no np gt ka gh gi paragraph-image"><div role="button" tabindex="0" class="kb kc di kd bf ke"><div class="gh gi oi"><img src="../Images/91b5c6d5911f4d044936527f95d485f7.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*9nv_TR9Hb0k3-spT.png"/></div></div></figure><h2 id="62ae" class="nb ll iq bd lm nc nd dn lq ne nf dp lu kx ng nh ly lb ni nj mc lf nk nl mg iw bi translated">2.2创建并运行示例Scala/Spark脚本</h2><p id="4f1b" class="pw-post-body-paragraph km kn iq ko b kp mi kr ks kt mj kv kw kx mk kz la lb ml ld le lf mm lh li lj ij bi translated">现在我们可以在这个项目中编写一些Scala代码。进入左侧窗格的<strong class="ko ja">src-&gt;main-&gt;Scala</strong>目录，右键选择<strong class="ko ja"> New - &gt; Scala Class </strong>，然后选择<strong class="ko ja"> Object </strong>并输入类名为<strong class="ko ja"> Demo </strong>，点击<strong class="ko ja"> OK </strong>。</p><figure class="nm nn no np gt ka gh gi paragraph-image"><div role="button" tabindex="0" class="kb kc di kd bf ke"><div class="gh gi oj"><img src="../Images/53a3e3e1a159f4b00b90b0d30ce0779a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*mVrVm2c9LcnvJNZ6.png"/></div></div></figure><p id="1591" class="pw-post-body-paragraph km kn iq ko b kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">将以下代码添加到<strong class="ko ja"> Demo.scala </strong>文件中:</p><pre class="nm nn no np gt nq nr ns nt aw nu bi"><span id="5060" class="nb ll iq nr b gy nv nw l nx ny">import org.apache.spark.rdd.RDD<br/>import org.apache.spark.{SparkConf, SparkContext}</span><span id="0d52" class="nb ll iq nr b gy og nw l nx ny">object Demo {<br/>  def main(args: Array[String]) = {<br/>      val sparkConf: SparkConf = new SparkConf().setMaster("local").setAppName("WordCount")<br/>      val sc = new SparkContext(sparkConf)</span><span id="bfc3" class="nb ll iq nr b gy og nw l nx ny">      // 1. read file, get data by line<br/>      val lines: RDD[String] = sc.parallelize(Array("Hello World Jack", "Hello World Luna", "Hello World Jack"))</span><span id="9608" class="nb ll iq nr b gy og nw l nx ny">    // 2. break each line to words<br/>      val words: RDD[String] = lines.flatMap(_.split(" "))</span><span id="8bad" class="nb ll iq nr b gy og nw l nx ny">      // 3. split data based on words<br/>      val wordGroup: RDD[(String, Iterable[String])] = words.groupBy(word =&gt; word)</span><span id="a85b" class="nb ll iq nr b gy og nw l nx ny">      // 4. convert data after splitting<br/>      val wordToCount = wordGroup.map {<br/>        case (word, list) =&gt; {<br/>          (word, list.size)<br/>        }<br/>      }</span><span id="ea9b" class="nb ll iq nr b gy og nw l nx ny">      // 5. collect the results and print<br/>      val array: Array[(String, Int)] = wordToCount.collect()<br/>      array.foreach(println)</span><span id="dacc" class="nb ll iq nr b gy og nw l nx ny">      // close connection<br/>      sc.stop()<br/>  }<br/>}</span></pre><p id="82aa" class="pw-post-body-paragraph km kn iq ko b kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">这段代码做的是对三个句子进行字数统计:“Hello World Jack”、“Hello World Luna”、“Hello World Jack”，并在控制台上打印出结果。右键点击<strong class="ko ja">运行‘演示’</strong>即可运行。在Spark的几个日志之后，您应该会看到输出。</p><figure class="nm nn no np gt ka gh gi paragraph-image"><div role="button" tabindex="0" class="kb kc di kd bf ke"><div class="gh gi ok"><img src="../Images/a98065d99518a8850d00eadb6ff22364.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*KIBxVirO5DsDpgGb.png"/></div></div></figure><p id="2fad" class="pw-post-body-paragraph km kn iq ko b kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">就是这样！现在，您已经运行了您的第一个Spark程序！</p><h2 id="e119" class="nb ll iq bd lm nc nd dn lq ne nf dp lu kx ng nh ly lb ni nj mc lf nk nl mg iw bi translated">2.3将Scala脚本打包到jar文件中</h2><p id="0c95" class="pw-post-body-paragraph km kn iq ko b kp mi kr ks kt mj kv kw kx mk kz la lb ml ld le lf mm lh li lj ij bi translated">为了提交用Scala编写的Spark作业，您必须将您的Scala代码打包成一个可执行的Jar文件。下面是我们的字数统计示例。</p><p id="7bc2" class="pw-post-body-paragraph km kn iq ko b kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">点击<strong class="ko ja">文件- &gt;项目结构- &gt;工件- &gt; + - &gt; JAR - &gt;从有依赖关系的模块</strong>。</p><figure class="nm nn no np gt ka gh gi paragraph-image"><div role="button" tabindex="0" class="kb kc di kd bf ke"><div class="gh gi nz"><img src="../Images/8920d898f197cf0b9f257b2f0acefaf8.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*HMHXiJgXutV55vIv.png"/></div></div></figure><p id="ee64" class="pw-post-body-paragraph km kn iq ko b kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">选择<strong class="ko ja">模块:demo_example </strong>和<strong class="ko ja">主类:Demo </strong>，点击<strong class="ko ja"> OK </strong>。</p><figure class="nm nn no np gt ka gh gi paragraph-image"><div role="button" tabindex="0" class="kb kc di kd bf ke"><div class="gh gi ol"><img src="../Images/c6d3bc8aaf32718d96299c3c9c74953e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*D89dp9g4VeMndsjA.png"/></div></div></figure><p id="57a8" class="pw-post-body-paragraph km kn iq ko b kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">然后，移除<strong class="ko ja">输出布局</strong>中的外部lib包支持，只保留<strong class="ko ja">‘demo _ example’编译输出</strong>。点击<strong class="ko ja">确定</strong>。</p><figure class="nm nn no np gt ka gh gi paragraph-image"><div role="button" tabindex="0" class="kb kc di kd bf ke"><div class="gh gi nz"><img src="../Images/b6204ccce8051eeee06d0761dfdc7656.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*mId8elGtzfT9_Dku.png"/></div></div></figure><figure class="nm nn no np gt ka gh gi paragraph-image"><div role="button" tabindex="0" class="kb kc di kd bf ke"><div class="gh gi nz"><img src="../Images/d6e80e9355084ff299e932b9bf9f48b5.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*3PGN7YPSN5ouuLyj.png"/></div></div></figure><p id="0a32" class="pw-post-body-paragraph km kn iq ko b kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">最后，通过点击<strong class="ko ja">Build-&gt;Build Artifacts-&gt;demo _ example:Jar-&gt;Build</strong>，编译生成Jar文件。您将在左侧面板的<code class="fe oa ob oc nr b">out/artifacts/demo_example_jar/</code>中看到一个<strong class="ko ja"> demo_example.jar </strong>文件。这是你的Jar文件！</p><p id="8813" class="pw-post-body-paragraph km kn iq ko b kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">现在您可以将这个jar文件提交给Spark并查看它的运行情况:</p><pre class="nm nn no np gt nq nr ns nt aw nu bi"><span id="c0ea" class="nb ll iq nr b gy nv nw l nx ny">spark-submit --class Demo --master local your/path/to/demo_example.jar</span></pre><p id="d991" class="pw-post-body-paragraph km kn iq ko b kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">如果您看到下面的内容，这意味着您刚刚成功打包并提交了您的Scala应用程序到Spark。</p><figure class="nm nn no np gt ka gh gi paragraph-image"><div role="button" tabindex="0" class="kb kc di kd bf ke"><div class="gh gi om"><img src="../Images/af53d5f72a583d91342a9ece32ddd7f6.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*79qwNAVeIM8-SY-W.png"/></div></div></figure><p id="5789" class="pw-post-body-paragraph km kn iq ko b kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">恭喜你！您只是为Spark设置了您的环境。现在，您可以编写任何Spark应用程序并在集群中运行它们。编码快乐！</p><p id="17b3" class="pw-post-body-paragraph km kn iq ko b kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">Github回购:<a class="ae kl" href="https://github.com/haocai1992/SparkDemo" rel="noopener ugc nofollow" target="_blank">https://github.com/haocai1992/SparkDemo</a></p><div class="on oo gp gr op oq"><a href="https://github.com/haocai1992/SparkDemo" rel="noopener  ugc nofollow" target="_blank"><div class="or ab fo"><div class="os ab ot cl cj ou"><h2 class="bd ja gy z fp ov fr fs ow fu fw iz bi translated">GitHub-haokai 1992/spark demo:使用IntelliJ创建的spark项目的演示示例</h2><div class="ox l"><h3 class="bd b gy z fp ov fr fs ow fu fw dk translated">此时您不能执行该操作。您已使用另一个标签页或窗口登录。您已在另一个选项卡中注销，或者…</h3></div><div class="oy l"><p class="bd b dl z fp ov fr fs ow fu fw dk translated">github.com</p></div></div><div class="oz l"><div class="pa l pb pc pd oz pe kf oq"/></div></div></a></div></div></div>    
</body>
</html>