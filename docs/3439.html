<html>
<head>
<title>Data Science Case Study: Predicting Salaries of Job Postings</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">数据科学案例研究:预测职位发布的工资</h1>
<blockquote>原文：<a href="https://pub.towardsai.net/data-science-case-study-predicting-salaries-of-job-postings-e1cbb4e83054?source=collection_archive---------4-----------------------#2022-12-23">https://pub.towardsai.net/data-science-case-study-predicting-salaries-of-job-postings-e1cbb4e83054?source=collection_archive---------4-----------------------#2022-12-23</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="5b39" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">使用Python实现的机器学习来预测工作搜索引擎的工作发布的工资的端到端案例研究</h2></div><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ki"><img src="../Images/5c9f77ce4f34bce36f31153caafdc5a5.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*QjTQxnJjrAYTBmtTV17E4g.jpeg"/></div></div><figcaption class="ku kv gj gh gi kw kx bd b be z dk translated">赞恩·格里芬在<a class="ae ky" href="https://unsplash.com/images/people?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上的照片</figcaption></figure><blockquote class="kz la lb"><p id="a3d4" class="lc ld le lf b lg lh ju li lj lk jx ll lm ln lo lp lq lr ls lt lu lv lw lx ly im bi translated">“教育不是减少群体数量。教育就是帮助每个学生成功”</p><p id="89b4" class="lc ld le lf b lg lh ju li lj lk jx ll lm ln lo lp lq lr ls lt lu lv lw lx ly im bi translated"><strong class="lf iu">吴恩达</strong></p></blockquote><p id="c32c" class="pw-post-body-paragraph lc ld it lf b lg lh ju li lj lk jx ll lz ln lo lp ma lr ls lt mb lv lw lx ly im bi translated">在这个端到端的数据科学案例研究中，我们将使用一系列机器学习模型来估计求职引擎<strong class="lf iu">实际上是</strong>的职位发布的工资。我们将使用K-Fold交叉验证及其估计的RMSE/MSE/MAE来训练和评估多个ML模型的性能。表现最佳的模型将在最后被选出，并保存测试职位发布的预测工资。</p><p id="6336" class="pw-post-body-paragraph lc ld it lf b lg lh ju li lj lk jx ll lz ln lo lp ma lr ls lt mb lv lw lx ly im bi translated"><strong class="lf iu"> <em class="le"> GitHub仓库中有数据和Python代码</em> </strong> <em class="le"> </em> <a class="ae ky" href="https://github.com/TatevKaren/Predicting-Jop-Postings-Salary" rel="noopener ugc nofollow" target="_blank"> <em class="le">这里有</em> </a></p><h2 id="064d" class="mc md it bd me mf mg dn mh mi mj dp mk lz ml mm mn ma mo mp mq mb mr ms mt mu bi translated">博客的内容</h2><p id="1e1b" class="pw-post-body-paragraph lc ld it lf b lg mv ju li lj mw jx ll lz mx lo lp ma my ls lt mb mz lw lx ly im bi translated"><a class="ae ky" href="#f18f" rel="noopener ugc nofollow"> <strong class="lf iu"> 1。定义业务和数据科学目标</strong> </a></p><p id="96e0" class="pw-post-body-paragraph lc ld it lf b lg lh ju li lj lk jx ll lz ln lo lp ma lr ls lt mb lv lw lx ly im bi translated"><a class="ae ky" href="#9c70" rel="noopener ugc nofollow">T23】2。数据预处理 </a></p><p id="3558" class="pw-post-body-paragraph lc ld it lf b lg lh ju li lj lk jx ll lz ln lo lp ma lr ls lt mb lv lw lx ly im bi translated"><a class="ae ky" href="#e07d" rel="noopener ugc nofollow"> <strong class="lf iu"> 3。数据可视化</strong> </a></p><p id="f09a" class="pw-post-body-paragraph lc ld it lf b lg lh ju li lj lk jx ll lz ln lo lp ma lr ls lt mb lv lw lx ly im bi translated"><a class="ae ky" href="#509d" rel="noopener ugc nofollow"> <strong class="lf iu"> 4。方法论(ML模型比较与描述)</strong> </a></p><p id="e1f5" class="pw-post-body-paragraph lc ld it lf b lg lh ju li lj lk jx ll lz ln lo lp ma lr ls lt mb lv lw lx ly im bi translated"><a class="ae ky" href="#0591" rel="noopener ugc nofollow"> <strong class="lf iu"> 5。机器学习模型的分步训练过程</strong> </a></p><p id="03aa" class="pw-post-body-paragraph lc ld it lf b lg lh ju li lj lk jx ll lz ln lo lp ma lr ls lt mb lv lw lx ly im bi translated"><a class="ae ky" href="#209d" rel="noopener ugc nofollow"> <strong class="lf iu"> 6。评估我们的机器学习模型</strong> </a></p><p id="64cb" class="pw-post-body-paragraph lc ld it lf b lg lh ju li lj lk jx ll lz ln lo lp ma lr ls lt mb lv lw lx ly im bi translated"><a class="ae ky" href="#8ba7" rel="noopener ugc nofollow"> <strong class="lf iu"> 7。特征重要性</strong> </a></p></div><div class="ab cl na nb hx nc" role="separator"><span class="nd bw bk ne nf ng"/><span class="nd bw bk ne nf ng"/><span class="nd bw bk ne nf"/></div><div class="im in io ip iq"><h1 id="f18f" class="nh md it bd me ni nj nk mh nl nm nn mk jz no ka mn kc np kd mq kf nq kg mt nr bi translated">1.定义业务和数据科学目标</h1><p id="5a2a" class="pw-post-body-paragraph lc ld it lf b lg mv ju li lj mw jx ll lz mx lo lp ma my ls lt mb mz lw lx ly im bi translated">如果你曾经尝试过使用现代的求职搜索引擎，比如“<a class="ae ky" href="https://www.glassdoor.ca/index.htm" rel="noopener ugc nofollow" target="_blank"><strong class="lf iu"/></a>”、“<a class="ae ky" href="https://ca.indeed.com/?r=us" rel="noopener ugc nofollow" target="_blank"> <strong class="lf iu">事实上</strong> </a>”来搜索“<a class="ae ky" href="https://www.google.com/url?sa=t&amp;rct=j&amp;q=&amp;esrc=s&amp;source=web&amp;cd=&amp;cad=rja&amp;uact=8&amp;ved=2ahUKEwiEu8yk3o78AhX2HjQIHY5IC_gQFnoECBcQAQ&amp;url=https%3A%2F%2Fca.linkedin.com%2F&amp;usg=AOvVaw3O3wU5fIskZ64tw9aWju8g" rel="noopener ugc nofollow" target="_blank"><strong class="lf iu">【LinkedIn】</strong></a>”，那么你可能会注意到，一些招聘信息中提到了薪水，但大多数都没有提供这一信息。每个职位发布的工资信息对候选人非常有帮助，因为它为他们节省了大量的前期时间。这将避免候选人经历这一过程，并在最后发现他们不会得到相应或预期的报酬。</p><p id="88d5" class="pw-post-body-paragraph lc ld it lf b lg lh ju li lj lk jx ll lz ln lo lp ma lr ls lt mb lv lw lx ly im bi translated">这对于任何工作搜索引擎来说都是一个主要问题，因为大多数工作发布都不包括工作薪水，增加这些功能可能会提高搜索引擎的用户满意度和参与度。</p><p id="ffc1" class="pw-post-body-paragraph lc ld it lf b lg lh ju li lj lk jx ll lz ln lo lp ma lr ls lt mb lv lw lx ly im bi translated">在任何案例研究中，我们需要做的第一件事就是定义和制定业务目标和技术(数据科学)目标，通过完成案例研究或项目来实现这些目标。</p><h2 id="aa2b" class="mc md it bd me mf mg dn mh mi mj dp mk lz ml mm mn ma mo mp mq mb mr ms mt mu bi translated">商业目标</h2><p id="8ce6" class="pw-post-body-paragraph lc ld it lf b lg mv ju li lj mw jx ll lz mx lo lp ma my ls lt mb mz lw lx ly im bi translated"><em class="le">在这个案例研究中，我们的目标是为工作搜索引擎创建一个工资估算功能。这些新职位发布的预计薪资可以为求职者提供薪资信息，从而改善他们的体验。</em></p><h2 id="d931" class="mc md it bd me mf mg dn mh mi mj dp mk lz ml mm mn ma mo mp mq mb mr ms mt mu bi translated">技术(数据科学)目标</h2><p id="4606" class="pw-post-body-paragraph lc ld it lf b lg mv ju li lj mw jx ll lz mx lo lp ma my ls lt mb mz lw lx ly im bi translated"><em class="le">本案例研究的技术目标是使用机器学习来预测给定职位描述的工作机会的薪资。</em></p><p id="2cbb" class="pw-post-body-paragraph lc ld it lf b lg lh ju li lj lk jx ll lz ln lo lp ma lr ls lt mb lv lw lx ly im bi translated">我们将回答以下问题:</p><ol class=""><li id="f201" class="ns nt it lf b lg lh lj lk lz nu ma nv mb nw ly nx ny nz oa bi translated">你用了什么软件语言和库来解决这个问题？你为什么选择这些语言/库？</li><li id="d048" class="ns nt it lf b lg ob lj oc lz od ma oe mb of ly nx ny nz oa bi translated">我们采取了什么步骤为项目准备数据？有必要清洁吗？</li><li id="b386" class="ns nt it lf b lg ob lj oc lz od ma oe mb of ly nx ny nz oa bi translated">应用了什么机器学习方法？</li><li id="0c75" class="ns nt it lf b lg ob lj oc lz od ma oe mb of ly nx ny nz oa bi translated">我们为什么选择这种方法？</li><li id="d8e6" class="ns nt it lf b lg ob lj oc lz od ma oe mb of ly nx ny nz oa bi translated">我们还考虑了其他什么方法？</li><li id="d771" class="ns nt it lf b lg ob lj oc lz od ma oe mb of ly nx ny nz oa bi translated">描述机器学习算法是如何工作的。</li><li id="63a4" class="ns nt it lf b lg ob lj oc lz od ma oe mb of ly nx ny nz oa bi translated">有必要对特性进行编码或转换吗？是哪一种？</li><li id="b3d2" class="ns nt it lf b lg ob lj oc lz od ma oe mb of ly nx ny nz oa bi translated">哪些特征对薪水影响最大？我们如何确定这些是最重要的？哪些特征对薪水的影响最小？我们是如何识别这些的？</li><li id="b2ae" class="ns nt it lf b lg ob lj oc lz od ma oe mb of ly nx ny nz oa bi translated">我们是如何训练机器学习模型的？在培训期间，有哪些问题值得关注？</li><li id="dab0" class="ns nt it lf b lg ob lj oc lz od ma oe mb of ly nx ny nz oa bi translated">你是如何评估RMSE绩效指标的？</li><li id="648f" class="ns nt it lf b lg ob lj oc lz od ma oe mb of ly nx ny nz oa bi translated">除了RMSE之外，还有哪些指标有助于评估薪资估算的准确性？为什么？</li></ol></div><div class="ab cl na nb hx nc" role="separator"><span class="nd bw bk ne nf ng"/><span class="nd bw bk ne nf ng"/><span class="nd bw bk ne nf"/></div><div class="im in io ip iq"><h1 id="9c70" class="nh md it bd me ni nj nk mh nl nm nn mk jz no ka mn kc np kd mq kf nq kg mt nr bi translated">2.数据预处理</h1><p id="bb26" class="pw-post-body-paragraph lc ld it lf b lg mv ju li lj mw jx ll lz mx lo lp ma my ls lt mb mz lw lx ly im bi translated">让我们快速浏览一下数据。</p><h2 id="6864" class="mc md it bd me mf mg dn mh mi mj dp mk lz ml mm mn ma mo mp mq mb mr ms mt mu bi translated">培训功能</h2><p id="199e" class="pw-post-body-paragraph lc ld it lf b lg mv ju li lj mw jx ll lz mx lo lp ma my ls lt mb mz lw lx ly im bi translated">train_features.csv:每一行代表一个职位发布的元数据</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi og"><img src="../Images/10566fe10b1088ed06abc0f6256db844.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*KTS-M9a3fD5AuGB0N93Dmw.png"/></div></div></figure><h2 id="461c" class="mc md it bd me mf mg dn mh mi mj dp mk lz ml mm mn ma mo mp mq mb mr ms mt mu bi translated">测试功能</h2><p id="5d29" class="pw-post-body-paragraph lc ld it lf b lg mv ju li lj mw jx ll lz mx lo lp ma my ls lt mb mz lw lx ly im bi translated">test_features.csv:类似于train_features.csv，其中每一行都代表一个职位发布的元数据</p><h2 id="7109" class="mc md it bd me mf mg dn mh mi mj dp mk lz ml mm mn ma mo mp mq mb mr ms mt mu bi translated">培训工资</h2><p id="27e1" class="pw-post-body-paragraph lc ld it lf b lg mv ju li lj mw jx ll lz mx lo lp ma my ls lt mb mz lw lx ly im bi translated">train_salaries.csv:每一行将一个“jobId”与一个“salary”相关联。这是监督机器学习模型的训练相关变量</p><pre class="kj kk kl km gt oh oi oj bn ok ol bi"><span id="7ee1" class="om md it oi b be on oo l op oq">train_features = 'train_features.csv'<br/>train_response = 'train_salaries.csv'<br/>test_features = 'test_features.csv'</span></pre><pre class="or oh oi os ot aw ou bi"><span id="4232" class="mc md it oi b gy ov ow l ox oq"># loading training features<br/>train_featuresDf = pd.read_csv(train_features, header=0)<br/># loading salaries: dependent variable<br/>train_responseDf = pd.read_csv(train_response, header=0)<br/># combining job features and salaries <br/>trainDf = train_featuresDf.merge(train_responseDf,on=None, how="inner")<br/># loading test features<br/>testDf = pd.read_csv(test_features, header=0)</span></pre><h2 id="9206" class="mc md it bd me mf mg dn mh mi mj dp mk lz ml mm mn ma mo mp mq mb mr ms mt mu bi translated">数据清理和准备</h2><p id="8b8b" class="pw-post-body-paragraph lc ld it lf b lg mv ju li lj mw jx ll lz mx lo lp ma my ls lt mb mz lw lx ly im bi translated">为了准备项目的数据，我经历了以下步骤</p><ul class=""><li id="7150" class="ns nt it lf b lg lh lj lk lz nu ma nv mb nw ly oy ny nz oa bi translated">加载数据集并浏览它们</li><li id="047f" class="ns nt it lf b lg ob lj oc lz od ma oe mb of ly oy ny nz oa bi translated">将培训功能与培训薪资合并</li><li id="bd72" class="ns nt it lf b lg ob lj oc lz od ma oe mb of ly oy ny nz oa bi translated">识别数字特征和分类特征</li><li id="3d83" class="ns nt it lf b lg ob lj oc lz od ma oe mb of ly oy ny nz oa bi translated">获取一些关于数据的简单描述性统计，看看是否有一些奇怪的值或差异</li><li id="da48" class="ns nt it lf b lg ob lj oc lz od ma oe mb of ly oy ny nz oa bi translated">已检查缺失的数据点(NULL和NA)</li><li id="e6fa" class="ns nt it lf b lg ob lj oc lz od ma oe mb of ly oy ny nz oa bi translated">已检查重复项</li><li id="c063" class="ns nt it lf b lg ob lj oc lz od ma oe mb of ly oy ny nz oa bi translated">检查无效值和异常值(检查非正值、分位数间范围规则、目视检查、浏览数据、可视化数值特征的数据分布以及与响应变量:薪金相关的箱线图)</li><li id="41f5" class="ns nt it lf b lg ob lj oc lz od ma oe mb of ly oy ny nz oa bi translated">标记异常值并将其从数据中删除</li><li id="19f1" class="ns nt it lf b lg ob lj oc lz od ma oe mb of ly oy ny nz oa bi translated">对分类变量进行编码</li><li id="90f5" class="ns nt it lf b lg ob lj oc lz od ma oe mb of ly oy ny nz oa bi translated">将JobId作为索引</li><li id="efc1" class="ns nt it lf b lg ob lj oc lz od ma oe mb of ly oy ny nz oa bi translated">为下一个过程保存数据</li></ul><p id="ed5d" class="pw-post-body-paragraph lc ld it lf b lg lh ju li lj lk jx ll lz ln lo lp ma lr ls lt mb lv lw lx ly im bi translated">在数据探索和可视化过程中，我发现存在一些无效值，例如看似全职的有薪工作的工资等于0的情况。然后我把它从训练集中删除了。我没有观察到数据中有任何缺失值。虽然数据非常干净，但是仍然需要清理过程来识别、标记和删除丢失的值。</p><pre class="kj kk kl km gt oh oi oj bn ok ol bi"><span id="1f46" class="om md it oi b be on oo l op oq"># for numeric features only <br/>        yearsExperience  milesFromMetropolis<br/>count   1000000.000000       1000000.000000<br/>mean         11.992386            49.529260<br/>std           7.212391            28.877733<br/>min           0.000000             0.000000<br/>25%           6.000000            25.000000<br/>50%          12.000000            50.000000<br/>75%          18.000000            75.000000<br/>max          24.000000            99.000000</span></pre><pre class="or oh oi oj bn ok ol bi"><span id="f6f4" class="om md it oi b be on oo l op oq">def process_validate_data(self):<br/>        '''data exploration and validation process'''<br/>        # load and store training data to dataFrame<br/>        self._create_training_df()<br/>        # load and store test data to dataFrame<br/>        self._create_test_df()<br/>        # get information about the features: categorical and numerical features<br/>        self._get_features_info()<br/>        # get training data statistics<br/>        self._get_trainDf_statistics()<br/>        # get test data statistics<br/>        self._get_testDf_statistics()<br/>        # checking for missing data points<br/>        self._check_missing_data(self.trainDf)<br/>        # checking the number of repeatitions/duplicates<br/>        self._check_duplicates()<br/>        # getting all columns containing negative or 0 values which is something we don't expect<br/>        self._get_invalid_data(self.trainDf, pred_response)</span></pre><pre class="or oh oi os ot aw ou bi"><span id="c6d2" class="mc md it oi b gy ov ow l ox oq">def _get_features_info(self):<br/>    '''getting categorical and numerical features'''<br/>    self.features_cat = self._get_cat_features(self.trainDf)<br/>    self.features_num = self._get_num_features(self.trainDf)</span><span id="1783" class="mc md it oi b gy oz ow l ox oq">def _get_cat_features(self, df):<br/>    '''finding  categorical columns in Dataframe'''<br/>    self.features_cat = df.select_dtypes(include=['O']).columns.tolist()<br/>    print('List of Categorical Features: {}'.format(self.features_cat))<br/>    return (self.features_cat)</span><span id="e9ed" class="mc md it oi b gy oz ow l ox oq">def _get_num_features(self, df):<br/>    '''finding numerical columns in Dataframe'''<br/>    self.features_num = df.select_dtypes(exclude=['O']).columns.tolist()<br/>    print('List of Numerical Features: {}'.format(self.features_num))<br/>    return (self.features_num)</span><span id="8d3c" class="mc md it oi b gy oz ow l ox oq">def _get_trainDf_statistics(self):<br/>    print('Training Data Statistics')<br/>    self._get_statistics(self.trainDf)</span><span id="7549" class="mc md it oi b gy oz ow l ox oq">def _get_testDf_statistics(self):<br/>    print('Test Data Statistics')<br/>    self._get_statistics(self.testDf)</span><span id="9c05" class="mc md it oi b gy oz ow l ox oq">def _get_statistics(self, df):<br/>    print('\n  Dataframe Information: \n')<br/>    print('n{}'.format(df.info()))<br/>    print('\n Dataframe Size [#rows, #cols]- {}'.format(df.shape))<br/>    print('\n Numerical Features Statistics: \n \n{}'.format(df.describe()))<br/>    print('\n Categorical Features Stats: \n \n{}'.format(df.describe(include='O')))</span><span id="f984" class="mc md it oi b gy oz ow l ox oq">def _check_missing_data(self, df):<br/>    '''Checking and finding  null or na values in Dataframe'''<br/>    num_missingval = np.sum(df.isna().sum()) + np.sum(df.isnull().sum())<br/>    if num_missingval == 0:<br/>        print('\n\n : There are no missing data points in the data')<br/>    else:<br/>        print('Features or columns that contain missing values\n\n{}'.format(df.isnull().sum()))</span><span id="2921" class="mc md it oi b gy oz ow l ox oq">def _check_duplicates(self):<br/>    '''Checking for duplicates'''<br/>    print('\n : There are {} duplicate values in Train Data'.format(self.trainDf.duplicated().sum()))<br/>    # though we found 5 repetitions in salary feature, this is not a duplicate since multiple jobs can have the same salary<br/>    print('\n : There are {} duplicate values in Test Data'.format(self.testDf.duplicated().sum()))</span><span id="8028" class="mc md it oi b gy oz ow l ox oq">def _get_invalid_data(self, df, cols):<br/>    '''Finding and flagging invalid values'''<br/>    for i in [cols]:<br/>        # we don't expect any of the values to be equal to 0 so we will identify anything &lt;= 0<br/>        inv_counts = np.sum(df[i] &lt;= 0)<br/>        if inv_counts &gt; 0:<br/>            self.invalid_data = True<br/>            print('\n :There are {} duplicates in {} column'.format(inv_counts, i))</span></pre><h2 id="5208" class="mc md it bd me mf mg dn mh mi mj dp mk lz ml mm mn ma mo mp mq mb mr ms mt mu bi translated">特征编码</h2><p id="786b" class="pw-post-body-paragraph lc ld it lf b lg mv ju li lj mw jx ll lz mx lo lp ma my ls lt mb mz lw lx ly im bi translated">因为数据中存在分类字符串特征，例如['companyId '，' jobType '，' degree '，' major '，' industry']。要在模型中使用它，必须对这些变量进行编码，以将字符串转换为数值。</p><p id="3ef8" class="pw-post-body-paragraph lc ld it lf b lg lh ju li lj lk jx ll lz ln lo lp ma lr ls lt mb lv lw lx ly im bi translated">我们使用LabelEncoder来执行编码。我在考虑使用一个热门的编码器，但是那会使我们很难判断特性的重要性。</p><pre class="kj kk kl km gt oh oi oj bn ok ol bi"><span id="e777" class="om md it oi b be on oo l op oq">def clean_encode_df(self):<br/>    '''Cleaning Data From Invalid Data points/Errors'''<br/>    '''Since salaries equal to 0 (lower limit we found) don't make sense, /n we assume they are outliers and we will fag and remove them'''<br/>    if self.invalid_data:<br/>        print('Number of data points before removing invalid rows:- {}'.format(data.trainDf.shape[0]))<br/>        data.trainDf = data.trainDf[data.trainDf['salary'] &gt; 0]<br/>        print('Number of data points after removing invalid rows with zero salary:- {}'.format(data.trainDf.shape[0]))</span></pre><pre class="or oh oi os ot aw ou bi"><span id="d356" class="mc md it oi b gy ov ow l ox oq">    ''' Encoding the categorical labels in training data'''<br/>    trainDf = self.encode_cat_features(data.trainDf, self.features_cat)<br/>    # since this is unique per observations it doesn't make sense to encode it<br/>    # but we still need the jobIds, therefore we will use it as the index<br/>    self.trainDf = trainDf.set_index("jobId").drop("index",1)<br/></span><span id="1d86" class="mc md it oi b gy oz ow l ox oq">    ''' Encoding the categorical labels in test data'''<br/>    testDf = self.encode_cat_features(data.testDf, self.features_cat, test_data=True)<br/>    self.testDf = testDf.set_index("jobId")<br/></span><span id="2f50" class="mc md it oi b gy oz ow l ox oq">def encode_cat_features(self, df, features, test_data=False):<br/>    '''encoding the labels in categorical features'''<br/>    if not test_data:<br/>        for feature in features:<br/>            l_encoder = LabelEncoder()<br/>            l_encoder.fit(df[feature])<br/>            self.labels[feature] = l_encoder<br/>            df[feature] = l_encoder.transform(df[feature])<br/>    else:<br/>        # encoding for test data<br/>        for feature, l_encoder in self.labels.items():<br/>            df[feature] = l_encoder.transform(df[feature])<br/>    return (df)</span></pre></div><div class="ab cl na nb hx nc" role="separator"><span class="nd bw bk ne nf ng"/><span class="nd bw bk ne nf ng"/><span class="nd bw bk ne nf"/></div><div class="im in io ip iq"><h1 id="e07d" class="nh md it bd me ni nj nk mh nl nm nn mk jz no ka mn kc np kd mq kf nq kg mt nr bi translated">3.数据可视化</h1><p id="4d23" class="pw-post-body-paragraph lc ld it lf b lg mv ju li lj mw jx ll lz mx lo lp ma my ls lt mb mz lw lx ly im bi translated">为了了解连续变量的基本分布，我画了它们的分布图。这些图表明变量不遵循正态分布，这是我们在选择需要正态特征的模型时需要记住的。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi pa"><img src="../Images/2aa7ebad760a18d716beb27400a7739c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Hx_jLeQFYkljLNeSeiPM4A.jpeg"/></div></div><figcaption class="ku kv gj gh gi kw kx bd b be z dk translated">图片来源:作者</figcaption></figure><pre class="kj kk kl km gt oh oi oj bn ok ol bi"><span id="4ef0" class="om md it oi b be on oo l op oq">def _distplot(self):<br/>    '''Creates Distribution Plots for Numeric Features'''<br/>    fig = plt.figure(figsize=(14, 10))<br/>    for index, col in enumerate(self.features_num):<br/>        fig.add_subplot(len(self.features_num), len(self.features_num), index + 1)<br/>        n, x, _ = plt.hist(self.trainDf[col], bins=20, color='yellow', edgecolor='black', linewidth=0.5)<br/>        bin_centers = 0.5 * (x[1:] + x[:-1])<br/>        plt.plot(bin_centers, n, color='darkgreen', linewidth=2)<br/>        plt.title('Distribution Plot for Numeric Features')<br/>        plt.xlabel(str(col))<br/>        plt.tight_layout()</span></pre><p id="a0ec" class="pw-post-body-paragraph lc ld it lf b lg lh ju li lj lk jx ll lz ln lo lp ma lr ls lt mb lv lw lx ly im bi translated">我还绘制了所有变量的箱线图，包括我们要预测的因变量，以及训练集中发布的职位工资。这些可以帮助我们识别不寻常的情况，以及我们可能想要检查并从数据中删除的异常值。我们可以看到，有一些情况，工资等于0，没有意义。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi pb"><img src="../Images/84ba4c1a934dab1f9f2a93081c539a22.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*2oldrC-B39FNX24QVUI6IQ.png"/></div></div><figcaption class="ku kv gj gh gi kw kx bd b be z dk translated">图片来源:作者</figcaption></figure><pre class="kj kk kl km gt oh oi oj bn ok ol bi"><span id="b6fa" class="om md it oi b be on oo l op oq">def _boxplot(self):<br/>    '''Creates BoxPlots for Categorical and Numeric Features'''<br/>    df = self.trainDf.copy()<br/>    fig = plt.figure(figsize=(14, 9))<br/>    for index, col in enumerate(self.features_cat):<br/>        if len(self.trainDf[col].unique()) &lt; 10:<br/>            df[col + '_mean'] = df.groupby(col)[self.pred_response].transform('mean')<br/>            fig.add_subplot(4, 2, index + 1)<br/>            sns.boxplot(x=col, y=self.pred_response, data=df.sort_values(col + '_mean'))<br/>            plt.title('Salaries vs {}'.format(col), fontsize=12)<br/>            plt.tight_layout()<br/>            plt.xticks(rotation=45)<br/>    for index, col in enumerate(self.features_num):<br/>        fig.add_subplot(len(self.features_num), len(self.features_num), index + 1)<br/>        sns.boxplot(self.trainDf[col], color='yellow')<br/>        plt.tight_layout()</span></pre></div><div class="ab cl na nb hx nc" role="separator"><span class="nd bw bk ne nf ng"/><span class="nd bw bk ne nf ng"/><span class="nd bw bk ne nf"/></div><div class="im in io ip iq"><h1 id="509d" class="nh md it bd me ni nj nk mh nl nm nn mk jz no ka mn kc np kd mq kf nq kg mt nr bi translated">4.方法学</h1><p id="d37d" class="pw-post-body-paragraph lc ld it lf b lg mv ju li lj mw jx ll lz mx lo lp ma my ls lt mb mz lw lx ly im bi translated">我们将使用以下机器学习模型，从非常简单的回归技术，如线性回归，到集成模型，如集成模型GBM和XGBoost。</p><ul class=""><li id="d185" class="ns nt it lf b lg lh lj lk lz nu ma nv mb nw ly oy ny nz oa bi translated"><strong class="lf iu">线性回归</strong></li><li id="31d6" class="ns nt it lf b lg ob lj oc lz od ma oe mb of ly oy ny nz oa bi translated"><strong class="lf iu">拉索回归(L1正则化)</strong></li><li id="e3de" class="ns nt it lf b lg ob lj oc lz od ma oe mb of ly oy ny nz oa bi translated"><strong class="lf iu">随机森林</strong></li><li id="10be" class="ns nt it lf b lg ob lj oc lz od ma oe mb of ly oy ny nz oa bi translated"><strong class="lf iu">梯度推进模型(GBM) </strong></li><li id="a6fe" class="ns nt it lf b lg ob lj oc lz od ma oe mb of ly oy ny nz oa bi translated"><strong class="lf iu"> XGBoost </strong></li></ul><h2 id="353b" class="mc md it bd me mf mg dn mh mi mj dp mk lz ml mm mn ma mo mp mq mb mr ms mt mu bi translated">比较ML模型</h2><p id="b7bc" class="pw-post-body-paragraph lc ld it lf b lg mv ju li lj mw jx ll lz mx lo lp ma my ls lt mb mz lw lx ly im bi translated">我们将在最后看到，我最终使用GBM算法作为最终选择的模型，因为它以对回归类型的问题提供更好的预测准确性而闻名，并且能够处理具有数百万行和分类/数字特征的复杂数据集，这是比决策树、Bagging甚至随机森林更大的优势。GBM像任何其他Boosting模型一样，学习缓慢但更准确，并且与AdaBoost不同，GBM对异常值不敏感，并且可以处理复杂的非线性模型。这也是我没有用AdaBoost的原因。</p><p id="b4b1" class="pw-post-body-paragraph lc ld it lf b lg lh ju li lj lk jx ll lz ln lo lp ma lr ls lt mb lv lw lx ly im bi translated">像Bagging(平均相关决策树)和Random Forest(平均不相关决策树)一样，Boosting旨在改善决策树产生的预测。Boosting是一种受监督的机器学习模型，可用于回归和分类问题。</p><p id="7cf8" class="pw-post-body-paragraph lc ld it lf b lg lh ju li lj lk jx ll lz ln lo lp ma lr ls lt mb lv lw lx ly im bi translated">与Bagging或Random Forest不同，在Bagging或Random Forest中，树是使用B引导样本(初始训练数据的副本)中的一个彼此独立地构建的，而在Boosting中，树是按顺序构建的，并且相互依赖:每棵树都是使用来自先前生长的树的信息来生长的。</p><p id="10df" class="pw-post-body-paragraph lc ld it lf b lg lh ju li lj lk jx ll lz ln lo lp ma lr ls lt mb lv lw lx ly im bi translated">众所周知，与前面提到的其他三种基于模型相比，Boosting具有更低的方差和更少的过拟合倾向。它优于其他聚合模型，如Bagging(创建相关的树)或Random Forest(由于其随机成分而创建不相关的树)。</p><h2 id="c592" class="mc md it bd me mf mg dn mh mi mj dp mk lz ml mm mn ma mo mp mq mb mr ms mt mu bi translated">梯度推进模型是如何工作的？</h2><p id="98f0" class="pw-post-body-paragraph lc ld it lf b lg mv ju li lj mw jx ll lz mx lo lp ma my ls lt mb mz lw lx ly im bi translated">Boosting旨在改进决策树产生的预测。Boosting是一种受监督的机器学习模型，可用于回归和分类问题。在Boosting中，树是按顺序建立的，并且相互依赖:每棵树都是使用来自先前生长的树的信息来生长的。</p><p id="a9b9" class="pw-post-body-paragraph lc ld it lf b lg lh ju li lj lk jx ll lz ln lo lp ma lr ls lt mb lv lw lx ly im bi translated">每棵树适合原始数据集的修改版本。这是一种将弱学习者转化为强学习者的方法。在boosting中，每个新树都适合原始数据集的修改版本。因此，与将单个大型决策树拟合到数据不同，这相当于将数据很难拟合，并且可能会过度拟合，相反，boosting方法学习起来很慢。</p><p id="d936" class="pw-post-body-paragraph lc ld it lf b lg lh ju li lj lk jx ll lz ln lo lp ma lr ls lt mb lv lw lx ly im bi translated">给定每个当前树，决策树适合来自模型的残差。也就是说，该算法使用当前残差而不是结果Y来拟合树，作为响应。然后，这个新的决策树被添加到拟合函数中，以便更新残差。这些树中的每一个都可以相当小，只有几个终端节点，这由算法中的参数d决定。</p><p id="94be" class="pw-post-body-paragraph lc ld it lf b lg lh ju li lj lk jx ll lz ln lo lp ma lr ls lt mb lv lw lx ly im bi translated">GBM通过选择单个树叶开始它的学习过程，并通过使用来自先前标记的弱学习器继续构建它。对应于所选叶子的结果是对结果变量的初步猜测。</p><p id="d473" class="pw-post-body-paragraph lc ld it lf b lg lh ju li lj lk jx ll lz ln lo lp ma lr ls lt mb lv lw lx ly im bi translated">为了确保树不会过度拟合，梯度提升使用学习率(eta)来缩放梯度贡献。梯度推进是基于这样的想法，即在正确的方向(梯度)上采取许多小步骤将导致更低的方差(对于测试数据)。GBM通过使用损失函数的梯度来识别先前模型的缺点。损失函数是一种衡量指标，它表明模型系数对基础数据的拟合程度。</p><p id="c0df" class="pw-post-body-paragraph lc ld it lf b lg lh ju li lj lk jx ll lz ln lo lp ma lr ls lt mb lv lw lx ly im bi translated">要构建GBM，可以使用以下分步流程:</p><ul class=""><li id="4cab" class="ns nt it lf b lg lh lj lk lz nu ma nv mb nw ly oy ny nz oa bi translated"><strong class="lf iu">步骤1: </strong>计算结果变量的平均值，并用它来计算<strong class="lf iu">伪残差</strong></li><li id="094d" class="ns nt it lf b lg ob lj oc lz od ma oe mb of ly oy ny nz oa bi translated"><strong class="lf iu">第二步:</strong>使用现有特征和伪残差作为输出变量来预测残差。</li><li id="65c7" class="ns nt it lf b lg ob lj oc lz od ma oe mb of ly oy ny nz oa bi translated"><strong class="lf iu">第3步:</strong>我们使用预测残差来更新上一步的预测，同时用学习率来调整对树的贡献。</li><li id="150a" class="ns nt it lf b lg ob lj oc lz od ma oe mb of ly oy ny nz oa bi translated"><strong class="lf iu">步骤4: </strong>这个过程继续更新伪残差和树，同时用学习率进行缩放，这有助于向正确的方向缓慢移动，直到不再有改进或我们的停止规则。</li></ul><pre class="kj kk kl km gt oh oi oj bn ok ol bi"><span id="fe12" class="om md it oi b be on oo l op oq">from sklearn import linear_model<br/>from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor<br/>from xgboost import XGBRegressor</span></pre><pre class="or oh oi os ot aw ou bi"><span id="125f" class="mc md it oi b gy ov ow l ox oq">LR = linear_model.LinearRegression()<br/>Lasso_LR = linear_model.Lasso()<br/>RForest = RandomForestRegressor(n_estimators=60, n_jobs=4, max_depth=15, min_samples_split=80, max_features=8,verbose=0)<br/>GBM = GradientBoostingRegressor(n_estimators=60, max_depth=7, loss='ls', verbose=0)<br/>xgboost = XGBRegressor(n_estimators=60, max_depth=7, eta=0.1, subsample=0.7, colsample_bytree=0.8)<br/>models = [LR, Lasso_LR, RForest, GBM, xgboost]</span></pre></div><div class="ab cl na nb hx nc" role="separator"><span class="nd bw bk ne nf ng"/><span class="nd bw bk ne nf ng"/><span class="nd bw bk ne nf"/></div><div class="im in io ip iq"><h1 id="0591" class="nh md it bd me ni nj nk mh nl nm nn mk jz no ka mn kc np kd mq kf nq kg mt nr bi translated">5.训练机器学习模型</h1><p id="8bf7" class="pw-post-body-paragraph lc ld it lf b lg mv ju li lj mw jx ll lz mx lo lp ma my ls lt mb mz lw lx ly im bi translated">以下是训练机器学习模型的逐步方法</p><h2 id="a124" class="mc md it bd me mf mg dn mh mi mj dp mk lz ml mm mn ma mo mp mq mb mr ms mt mu bi translated">步骤1:收集和准备数据</h2><p id="8113" class="pw-post-body-paragraph lc ld it lf b lg mv ju li lj mw jx ll lz mx lo lp ma my ls lt mb mz lw lx ly im bi translated">训练机器学习模型的第一步是收集和准备将用于训练模型的数据。这可能涉及清理数据、处理缺失值以及选择数据子集进行训练。</p><h2 id="8c90" class="mc md it bd me mf mg dn mh mi mj dp mk lz ml mm mn ma mo mp mq mb mr ms mt mu bi translated">步骤2:将数据分成训练集和验证集</h2><p id="902e" class="pw-post-body-paragraph lc ld it lf b lg mv ju li lj mw jx ll lz mx lo lp ma my ls lt mb mz lw lx ly im bi translated">通常将数据分成两组:训练集和验证集。该模型将在训练集上进行训练，并在验证集上进行评估。</p><h2 id="b22a" class="mc md it bd me mf mg dn mh mi mj dp mk lz ml mm mn ma mo mp mq mb mr ms mt mu bi translated">步骤3:选择模型并设置超参数</h2><p id="a9e7" class="pw-post-body-paragraph lc ld it lf b lg mv ju li lj mw jx ll lz mx lo lp ma my ls lt mb mz lw lx ly im bi translated">接下来，您需要选择一个机器学习模型并设置超参数。超参数是在训练期间不是从数据中学习的模型参数，例如学习率或正则化强度。</p><h2 id="c0d0" class="mc md it bd me mf mg dn mh mi mj dp mk lz ml mm mn ma mo mp mq mb mr ms mt mu bi translated">第四步:训练模型</h2><p id="95a2" class="pw-post-body-paragraph lc ld it lf b lg mv ju li lj mw jx ll lz mx lo lp ma my ls lt mb mz lw lx ly im bi translated">使用训练数据和选择的优化算法来训练该模型。优化算法更新模型参数以最小化损失函数，损失函数测量真实输出和预测输出之间的差异。</p><h2 id="5675" class="mc md it bd me mf mg dn mh mi mj dp mk lz ml mm mn ma mo mp mq mb mr ms mt mu bi translated">步骤5:评估模型</h2><p id="657f" class="pw-post-body-paragraph lc ld it lf b lg mv ju li lj mw jx ll lz mx lo lp ma my ls lt mb mz lw lx ly im bi translated">模型定型后，在验证集上对其进行评估，以评估其性能。评估度量将取决于特定的ML问题，例如分类任务或回归任务的准确性。</p><h2 id="7ffb" class="mc md it bd me mf mg dn mh mi mj dp mk lz ml mm mn ma mo mp mq mb mr ms mt mu bi translated">第六步:微调模型</h2><p id="a436" class="pw-post-body-paragraph lc ld it lf b lg mv ju li lj mw jx ll lz mx lo lp ma my ls lt mb mz lw lx ly im bi translated">如果模型在验证集中表现不佳，则可能需要调整超参数或尝试其他方法。这个过程称为模型微调。</p><h2 id="ae66" class="mc md it bd me mf mg dn mh mi mj dp mk lz ml mm mn ma mo mp mq mb mr ms mt mu bi translated">第7步:测试最终模型</h2><p id="ee10" class="pw-post-body-paragraph lc ld it lf b lg mv ju li lj mw jx ll lz mx lo lp ma my ls lt mb mz lw lx ly im bi translated">一旦对模型在验证集上的性能感到满意，就可以最终确定模型并在测试集上对其进行评估。这将为您提供模型在看不见的数据上的性能估计。</p><pre class="kj kk kl km gt oh oi oj bn ok ol bi"><span id="8e48" class="om md it oi b be on oo l op oq">class SalaryPredictingModel:<br/>    def __init__(self, data, models):<br/>        '''training multiple ML models for predicting salaries'''<br/>        self.data = data<br/>        self.models = models<br/>        self.mse = {}<br/>        self.rmse = {}<br/>        self.mae = {}<br/>        self.best_model = None<br/>        self.predictions = None<br/>        self.pred_response = data.pred_response<br/>        self.train_response = data.trainDf[data.pred_response]<br/>        self.train_features = data.trainDf.drop(data.pred_response, axis=1)<br/>        self.testDf = data.testDf<br/>        self.train_models()</span></pre><pre class="or oh oi os ot aw ou bi"><span id="5908" class="mc md it oi b gy ov ow l ox oq">    def train_models(self):<br/>        self.KFold_CV_model()<br/>        self.get_best_model()</span><span id="fb63" class="mc md it oi b gy oz ow l ox oq">    print('Training Process with K-Fold Cross Validation')<br/>    ''' we will use K-fold CV for estimating average test error rate'''</span><span id="d06a" class="mc md it oi b gy oz ow l ox oq">    # defaults is K=5 in K-fold<br/>    def KFold_CV_model(self):<br/>        for model_output in self.models:<br/>            print("Training model" + str(model_output) +" and calculating CV MSE, CV MAE, CV RMSE")<br/>            scores_mse = cross_val_score(model_output, self.train_features, self.train_response, cv=5,scoring='neg_mean_squared_error')<br/>            scores_mae = cross_val_score(model_output, self.train_features, self.train_response, cv=5,scoring='neg_mean_absolute_error')<br/>            scores_rmse = cross_val_score(model_output, self.train_features, self.train_response, cv=5,scoring='neg_root_mean_squared_error')<br/>            self.mse[model_output] = -1.0 * np.mean(scores_mse)<br/>            self.mae[model_output] = -1.0 * np.mean(scores_mae)<br/>            self.rmse[model_output] = -1.0 * np.mean(scores_rmse)</span><span id="f6fd" class="mc md it oi b gy oz ow l ox oq">    # picking the model with the least CV RMSE, then fitting and predicting that model<br/>    def get_best_model(self):<br/>        '''Selecting best model with RMSE, fitting the model train data'''<br/>        self.best_model = min(self.rmse, key=self.rmse.get)<br/>        self.get_model_performance()</span><span id="23db" class="mc md it oi b gy oz ow l ox oq">    def get_model_performance(self):<br/>        print("Model Performance")<br/>        for key, item in self.rmse.items():<br/>            print('\n Score of the model {} :-'.format(key))<br/>            print('\n RMSE - {}'.format(item))<br/>        print('\n Best model with smallest RMSE\n\n {} :-'.format(self.best_model))<br/>        print('\n RMSE - {}'.format(self.rmse[self.best_model]))<br/>        print('\nTraining the Best Model.....')<br/>        self.best_model.fit(self.train_features, self.train_response)<br/>        print('\n Getting Feature Importance')<br/>        self._plot_feature_importance()<br/>        print('\nPrediction for test data with Best Model')<br/>        self.testDf[self.pred_response] = self.best_model.predict(self.testDf)<br/>        <br/>        print('-------------------------- Best Model Performance ------------------------')<br/>        print(self.testDf[self.pred_response])</span><span id="cbe1" class="mc md it oi b gy oz ow l ox oq">    def _plot_feature_importance(self):<br/>        '''Printing the feature importance used to train the model'''<br/>        print('\n Feature Importance Calculation')<br/>        features = self.train_features.columns.to_list()<br/>        importances = self.best_model.feature_importances_<br/>        indices = np.argsort(importances)<br/>        plt.figure(figsize=(7, 6))<br/>        plt.title('Feature Importances')<br/>        plt.barh(range(len(indices)),<br/>                 importances[indices], color='r', align='center')<br/>        plt.yticks(range(len(indices)), [features[i] for i in indices])<br/>        plt.xlabel('Relative Importance')<br/>        plt.show()<br/>        </span><span id="bd36" class="mc md it oi b gy oz ow l ox oq">    @staticmethod<br/>    def saving_best_model(model_file, model):<br/>        ''' Saving the best model to a file'''<br/>        print('\n Saving Best Model to file')<br/>        pickle.dump(model, open(model_file, 'wb'))<br/>    print('Saving the Predictions to CSV file')<br/>    def saving_results(self, sub_file, df):<br/>        print('\n Saving job Salary predictions in testDf to a CSV file')<br/>        print('--------------------------------------------------------------------------------')<br/>        self.testDf[self.pred_response].to_csv(sub_file, index=True, header = 0)</span><span id="556b" class="mc md it oi b gy oz ow l ox oq">    @staticmethod<br/>    def hyperparameter_tuning(estimator, param_grid, n_iter=5, scoring='neg_root_mean_absolute_error', cv=5, n_jobs=-2,<br/>                              refit=False):<br/>        ''' Finding Optimal hyper-parameters used in models'''<br/>        rs_cv = RandomizedSearchCV(estimator=estimator, param_distribution=param_grid,<br/>                                   n_iter=n_iter,<br/>                                   cv=cv,<br/>                                   n_jobs=n_jobs,<br/>                                   refit=refit)<br/>        rs_cv.fit(train_features, train_response)<br/>        return (rs_cv.best_params_)</span></pre></div><div class="ab cl na nb hx nc" role="separator"><span class="nd bw bk ne nf ng"/><span class="nd bw bk ne nf ng"/><span class="nd bw bk ne nf"/></div><div class="im in io ip iq"><h1 id="209d" class="nh md it bd me ni nj nk mh nl nm nn mk jz no ka mn kc np kd mq kf nq kg mt nr bi translated">6.评估我们的机器学习模型</h1><p id="11de" class="pw-post-body-paragraph lc ld it lf b lg mv ju li lj mw jx ll lz mx lo lp ma my ls lt mb mz lw lx ly im bi translated">我使用K-Fold交叉验证重采样技术来估计我的模型将在测试数据集上实现的RMSE。这是我们在K次训练模型时获得的RMSEs的平均值，每次，Kth折叠数据都用作测试数据的代理。</p><p id="9296" class="pw-post-body-paragraph lc ld it lf b lg lh ju li lj lk jx ll lz ln lo lp ma lr ls lt mb lv lw lx ly im bi translated">为简单起见，模型使用<strong class="lf iu"> K倍交叉验证</strong>使用K=5进行训练。培训特征已被用作一组探索性变量(X_train)来学习和拟合模型，而薪金被用作因变量(Y_train)。以这种方式训练了多个模型。然后估计他们的CV RMSE以比较所有模型。</p><p id="14a7" class="pw-post-body-paragraph lc ld it lf b lg lh ju li lj lk jx ll lz ln lo lp ma lr ls lt mb lv lw lx ly im bi translated">每个模型的此CV RMSE已用于通过比较当前最佳模型与新模型RMSE并挑选具有最小CV RMSE的模型来更新最佳模型。然后，该最佳模型(即，拟合于训练特征的GBM)被用于使用测试数据特征(X测试)来预测薪金(Y测试)。</p><p id="f6b1" class="pw-post-body-paragraph lc ld it lf b lg lh ju li lj lk jx ll lz ln lo lp ma lr ls lt mb lv lw lx ly im bi translated">GBM最终具有最小的估计RMSE，因此这是所选的模型I，用于拟合模型和预测测试数据的薪资。</p><p id="78a1" class="pw-post-body-paragraph lc ld it lf b lg lh ju li lj lk jx ll lz ln lo lp ma lr ls lt mb lv lw lx ly im bi translated"><strong class="lf iu">培训期间的问题</strong></p><p id="7119" class="pw-post-body-paragraph lc ld it lf b lg lh ju li lj lk jx ll lz ln lo lp ma lr ls lt mb lv lw lx ly im bi translated">JobID不能用作特征，因为它是每个观察唯一的。有几种方法可以解决这个问题，但最简单的解决方法是将职务id转换为每个数据框的索引，以便可以将其与最终文件中所需的薪资一起保存。</p><p id="bb4c" class="pw-post-body-paragraph lc ld it lf b lg lh ju li lj lk jx ll lz ln lo lp ma lr ls lt mb lv lw lx ly im bi translated">2:模特们训练的时间。在这种情况下，PySpark可能是一个更好的选择，用于训练具有百万个观察值的模型，如果有更多的特征，该过程将更加耗时。</p><p id="cdce" class="pw-post-body-paragraph lc ld it lf b lg lh ju li lj lk jx ll lz ln lo lp ma lr ls lt mb lv lw lx ly im bi translated">3:我必须做出的假设:</p><ul class=""><li id="ea63" class="ns nt it lf b lg lh lj lk lz nu ma nv mb nw ly oy ny nz oa bi translated">我假设一份需要大量经验的工作的工资不能等于零，这在我看来不合逻辑。因此，我不得不删除它们</li><li id="bdb2" class="ns nt it lf b lg ob lj oc lz od ma oe mb of ly oy ny nz oa bi translated">我还假设，非常高的薪水确实有意义，而且必须留在数据中，因为它们与管理职位相对应</li><li id="445f" class="ns nt it lf b lg ob lj oc lz od ma oe mb of ly oy ny nz oa bi translated">K在K倍CV，我让它成为默认的K= 5，但理想情况下，我想使用肘的方法。</li><li id="9878" class="ns nt it lf b lg ob lj oc lz od ma oe mb of ly oy ny nz oa bi translated">我在训练模型的时候做了一些迭代次数的假设，我选了足够大的(60)来确保模型的准确性。</li><li id="d3d7" class="ns nt it lf b lg ob lj oc lz od ma oe mb of ly oy ny nz oa bi translated">我假设K倍CV RMSE是测试RMSE的适当估计，因为在每个第K次训练期间，K-1倍被用作训练集，第K倍被用作测试集的代理以获得RMSE，然后这些K个RMSE的平均值将是测试RMSE的良好估计。</li></ul><p id="3c0a" class="pw-post-body-paragraph lc ld it lf b lg lh ju li lj lk jx ll lz ln lo lp ma lr ls lt mb lv lw lx ly im bi translated">除了RMSE，我还估算了MSE和MAE，它们也是RMSE的替代指标。所有这些度量都是可以用来评估回归类型模型的性能的指标，就像我们的例子一样。</p><p id="7d37" class="pw-post-body-paragraph lc ld it lf b lg lh ju li lj lk jx ll lz ln lo lp ma lr ls lt mb lv lw lx ly im bi translated">如果选择线性回归模型，我们也可以使用R平方或调整后的R平方来评估模型的准确性以及模型对工资的解释程度。然后，我们还可以查看特征的标准误差和置信区间的宽度来做出结论。</p></div><div class="ab cl na nb hx nc" role="separator"><span class="nd bw bk ne nf ng"/><span class="nd bw bk ne nf ng"/><span class="nd bw bk ne nf"/></div><div class="im in io ip iq"><h1 id="8ba7" class="nh md it bd me ni nj nk mh nl nm nn mk jz no ka mn kc np kd mq kf nq kg mt nr bi translated">7.特征重要性</h1><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi pc"><img src="../Images/870e766acc9af2717432ac34af9785ca.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*uSnPjspWVpYW54Wbusomdg.png"/></div></div></figure><p id="f472" class="pw-post-body-paragraph lc ld it lf b lg lh ju li lj lk jx ll lz ln lo lp ma lr ls lt mb lv lw lx ly im bi translated">“工作类型”似乎对薪水影响最大。对薪水有显著影响的其他特征是经验和离大都市的距离。公司Id和学位似乎是最不重要的特征，对我们解释工资的变化没有多大帮助。</p><p id="9f4e" class="pw-post-body-paragraph lc ld it lf b lg lh ju li lj lk jx ll lz ln lo lp ma lr ls lt mb lv lw lx ly im bi translated">我已经通过绘制特征重要性图确定了最重要和最不重要的特征，其中特征重要性被计算为每棵树内RSS(残差平方和)减少的累积的平均值和标准偏差。最重要的特征在顶部，对应于最大的柱，而最不重要的特征在该图的底部，具有最短的柱。</p><p id="c393" class="pw-post-body-paragraph lc ld it lf b lg lh ju li lj lk jx ll lz ln lo lp ma lr ls lt mb lv lw lx ly im bi translated"><strong class="lf iu"> <em class="le"> GitHub知识库中有数据集和Python代码</em> </strong> <a class="ae ky" href="https://github.com/TatevKaren/Predicting-Jop-Postings-Salary" rel="noopener ugc nofollow" target="_blank">这里有</a></p></div><div class="ab cl na nb hx nc" role="separator"><span class="nd bw bk ne nf ng"/><span class="nd bw bk ne nf ng"/><span class="nd bw bk ne nf"/></div><div class="im in io ip iq"><h1 id="8941" class="nh md it bd me ni nj nk mh nl nm nn mk jz no ka mn kc np kd mq kf nq kg mt nr bi translated">如果你喜欢这篇文章，这里有一些你可能喜欢的其他文章:</h1><div class="pd pe gp gr pf pg"><a href="https://towardsdatascience.com/simple-and-complet-guide-to-a-b-testing-c34154d0ce5a" rel="noopener follow" target="_blank"><div class="ph ab fo"><div class="pi ab pj cl cj pk"><h2 class="bd iu gy z fp pl fr fs pm fu fw is bi translated">简单完整的A/B测试指南</h2><div class="pn l"><h3 class="bd b gy z fp pl fr fs pm fu fw dk translated">为您的数据科学实验进行端到端A/B测试，面向非技术和技术专家，提供示例和…</h3></div><div class="po l"><p class="bd b dl z fp pl fr fs pm fu fw dk translated">towardsdatascience.com</p></div></div><div class="pp l"><div class="pq l pr ps pt pp pu ks pg"/></div></div></a></div><div class="pd pe gp gr pf pg"><a href="https://towardsdatascience.com/spotify-data-science-case-study-what-makes-a-playlist-successful-28fec482c523" rel="noopener follow" target="_blank"><div class="ph ab fo"><div class="pi ab pj cl cj pk"><h2 class="bd iu gy z fp pl fr fs pm fu fw is bi translated">进行数据科学案例研究的完整指南</h2><div class="pn l"><h3 class="bd b gy z fp pl fr fs pm fu fw dk translated">端到端的数据科学案例研究，结合实际业务问题的技巧和Python实现:是什么让…</h3></div><div class="po l"><p class="bd b dl z fp pl fr fs pm fu fw dk translated">towardsdatascience.com</p></div></div><div class="pp l"><div class="pv l pr ps pt pp pu ks pg"/></div></div></a></div><div class="pd pe gp gr pf pg"><a href="https://towardsdatascience.com/bias-variance-trade-off-overfitting-regularization-in-machine-learning-d79c6d8f20b4" rel="noopener follow" target="_blank"><div class="ph ab fo"><div class="pi ab pj cl cj pk"><h2 class="bd iu gy z fp pl fr fs pm fu fw is bi translated">理解机器学习中的偏差-方差权衡、过拟合和正则化</h2><div class="pn l"><h3 class="bd b gy z fp pl fr fs pm fu fw dk translated">介绍偏差-方差权衡，过度拟合&amp;如何使用正则化解决过度拟合:脊和套索…</h3></div><div class="po l"><p class="bd b dl z fp pl fr fs pm fu fw dk translated">towardsdatascience.com</p></div></div><div class="pp l"><div class="pw l pr ps pt pp pu ks pg"/></div></div></a></div><div class="pd pe gp gr pf pg"><a href="https://tatev-aslanyan.medium.com/data-sampling-methods-in-python-a4400628ea1b" rel="noopener follow" target="_blank"><div class="ph ab fo"><div class="pi ab pj cl cj pk"><h2 class="bd iu gy z fp pl fr fs pm fu fw is bi translated">Python中的数据采样方法</h2><div class="pn l"><h3 class="bd b gy z fp pl fr fs pm fu fw dk translated">使用不同的数据采样技术创建Python中的随机样本的现成代码</h3></div><div class="po l"><p class="bd b dl z fp pl fr fs pm fu fw dk translated">tatev-aslanyan.medium.com</p></div></div><div class="pp l"><div class="px l pr ps pt pp pu ks pg"/></div></div></a></div><div class="pd pe gp gr pf pg"><a href="https://towardsdatascience.com/monte-carlo-simulation-and-variants-with-python-43e3e7c59e1f" rel="noopener follow" target="_blank"><div class="ph ab fo"><div class="pi ab pj cl cj pk"><h2 class="bd iu gy z fp pl fr fs pm fu fw is bi translated">蒙特卡罗模拟和Python变种</h2><div class="pn l"><h3 class="bd b gy z fp pl fr fs pm fu fw dk translated">蒙特卡洛模拟指南，必须了解Python实现的统计抽样技术</h3></div><div class="po l"><p class="bd b dl z fp pl fr fs pm fu fw dk translated">towardsdatascience.com</p></div></div><div class="pp l"><div class="py l pr ps pt pp pu ks pg"/></div></div></a></div></div><div class="ab cl na nb hx nc" role="separator"><span class="nd bw bk ne nf ng"/><span class="nd bw bk ne nf ng"/><span class="nd bw bk ne nf"/></div><div class="im in io ip iq"><p id="cfac" class="pw-post-body-paragraph lc ld it lf b lg lh ju li lj lk jx ll lz ln lo lp ma lr ls lt mb lv lw lx ly im bi translated"><strong class="lf iu"> <em class="le">感谢阅读</em> </strong></p><p id="2549" class="pw-post-body-paragraph lc ld it lf b lg lh ju li lj lk jx ll lz ln lo lp ma lr ls lt mb lv lw lx ly im bi translated"><em class="le">我鼓励你</em> <a class="ae ky" href="https://tatev-aslanyan.medium.com/membership" rel="noopener"> <strong class="lf iu"> <em class="le">加入Medium</em></strong></a><strong class="lf iu"><em class="le"/></strong><em class="le">来拥有</em> <strong class="lf iu"> <em class="le"> </em> </strong> <em class="le">完整访问我所有关于数据科学、机器学习、AI和其他主题的文章。</em></p><p id="7c21" class="pw-post-body-paragraph lc ld it lf b lg lh ju li lj lk jx ll lz ln lo lp ma lr ls lt mb lv lw lx ly im bi translated"><em class="le">关注我</em> <a class="ae ky" href="https://medium.com/@tatev-aslanyan" rel="noopener"> <strong class="lf iu"> <em class="le">中</em></strong></a><strong class="lf iu"><em class="le"/></strong><em class="le">阅读更多关于各种数据科学和数据分析主题的文章。更多机器学习、数学和统计概念的实际应用，请查看我的</em><a class="ae ky" href="https://github.com/TatevKaren" rel="noopener ugc nofollow" target="_blank"><strong class="lf iu"><em class="le">Github</em></strong></a><strong class="lf iu"><em class="le"/></strong><em class="le">账号。<br/>欢迎反馈，可在</em><a class="ae ky" href="https://www.linkedin.com/in/tatev-karen-aslanyan/" rel="noopener ugc nofollow" target="_blank"><strong class="lf iu"><em class="le">LinkedIn</em></strong></a><em class="le">上联系。</em></p><p id="21fd" class="pw-post-body-paragraph lc ld it lf b lg lh ju li lj lk jx ll lz ln lo lp ma lr ls lt mb lv lw lx ly im bi translated"><strong class="lf iu"> <em class="le">快乐学习！</em> </strong></p></div></div>    
</body>
</html>