<html>
<head>
<title>Trends in AI — November 2022</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">人工智能趋势—2022年11月</h1>
<blockquote>原文：<a href="https://pub.towardsai.net/10-research-papers-you-shouldnt-miss-82f36c104586?source=collection_archive---------0-----------------------#2022-11-04">https://pub.towardsai.net/10-research-papers-you-shouldnt-miss-82f36c104586?source=collection_archive---------0-----------------------#2022-11-04</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><div class=""><h2 id="f0b1" class="pw-subtitle-paragraph jn ip iq bd b jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke dk translated"><em class="kf">蓉城。人工智能关闭，贾斯帕。AI，还有稳定。AI获得大量资金，FLAN-T5 LLM，Meta的神经音频压缩，You-only-live-once，Dreamfusion，句子嵌入的新MTEB基准，城市驾驶的模仿学习，等等。</em></h2></div><figure class="kh ki kj kk gt kl gh gi paragraph-image"><div role="button" tabindex="0" class="km kn di ko bf kp"><div class="gh gi kg"><img src="../Images/51304364056d6bddf2a9e2ca37c733b1.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*WfwsDp8dBOTvMfW4bFt1Ag.png"/></div></div><figcaption class="ks kt gj gh gi ku kv bd b be z dk translated">图片由Zeta Alpha提供。</figcaption></figure><p id="a1ab" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">随着最大的人工智能研究会议(NeurIPS 2022)即将召开，我们进入了2022年的最后阶段。一个月后，我们将再次参加NeurIPS会议，对此我们感到非常兴奋，但首先，让我们回顾一下人工智能领域最近发生的事情。让我们开始强调一些新闻和代码发布！</p><h1 id="d03f" class="ls lt iq bd lu lv lw lx ly lz ma mb mc jw md jx me jz mf ka mg kc mh kd mi mj bi translated">🗞新闻</h1><ul class=""><li id="eed7" class="mk ml iq ky b kz mm lc mn lf mo lj mp ln mq lr mr ms mt mu bi translated"><a class="ae mv" href="https://www.jasper.ai/" rel="noopener ugc nofollow" target="_blank">jasper . AI</a>——人工智能内容生成平台——以15亿美元的估值融资1.25亿美元。特别是自两年前的GPT-3以来，用于内容创作(文本、图像……)的人工智能正在兴起，投资者不断在这方面下注。同样，<a class="ae mv" href="https://stability.ai/" rel="noopener ugc nofollow" target="_blank">Stability AI</a>——著名的文本到图像模型Stable Diffusion背后的初创公司——以1B的估值筹集了1.01亿美元。</li><li id="dd17" class="mk ml iq ky b kz mw lc mx lf my lj mz ln na lr mr ms mt mu bi translated">另一方面，许多自动驾驶计划未能在短短几年内实现完全自主的宏伟承诺，大型参与者正在放弃这场竞赛。<a class="ae mv" href="http://argo.ai/" rel="noopener ugc nofollow" target="_blank">蓉城。AI</a>——曾经估值70亿美元、由巨头福特和大众拥有的自动驾驶公司<a class="ae mv" href="https://techcrunch.com/2022/10/26/ford-vw-backed-argo-ai-is-shutting-down/" rel="noopener ugc nofollow" target="_blank">——正在关闭</a>。</li><li id="0a39" class="mk ml iq ky b kz mw lc mx lf my lj mz ln na lr mr ms mt mu bi translated">随着美国宣布更加严格地禁止出口高科技芯片设计和制造设备，围绕关键硅技术的美中贸易战升温。</li></ul><h1 id="4207" class="ls lt iq bd lu lv lw lx ly lz ma mb mc jw md jx me jz mf ka mg kc mh kd mi mj bi translated">👾密码</h1><ul class=""><li id="a367" class="mk ml iq ky b kz mm lc mn lf mo lj mp ln mq lr mr ms mt mu bi translated"><a class="ae mv" href="https://github.com/ELS-RD/kernl" rel="noopener ugc nofollow" target="_blank"> Kernl </a>是用<a class="ae mv" href="https://openai.com/blog/triton/" rel="noopener ugc nofollow" target="_blank"> OpenAI的Triton </a>编写的推理机，用于加速变形金刚的推理。</li><li id="3813" class="mk ml iq ky b kz mw lc mx lf my lj mz ln na lr mr ms mt mu bi translated"><a class="ae mv" href="https://github.com/gcorso/DiffDock" rel="noopener ugc nofollow" target="_blank">DiffDock</a>:DiffDock<a class="ae mv" href="https://arxiv.org/abs/2210.01776" rel="noopener ugc nofollow" target="_blank">的实现:扩散步骤，分子对接的曲折</a>。一种使用扩散的分子对接技术，很快获得了牵引力。</li><li id="3775" class="mk ml iq ky b kz mw lc mx lf my lj mz ln na lr mr ms mt mu bi translated">img-to-music :想象图像听起来是什么样子的模型！</li></ul><h1 id="b7cc" class="ls lt iq bd lu lv lw lx ly lz ma mb mc jw md jx me jz mf ka mg kc mh kd mi mj bi translated">🔬研究</h1><p id="5a9f" class="pw-post-body-paragraph kw kx iq ky b kz mm jr lb lc mn ju le lf nb lh li lj nc ll lm ln nd lp lq lr ij bi translated">每个月，我们都会分析最新的研究文献，并选择10篇你应该知道的论文。本月我们将讨论强化学习(RL)、扩散模型、自动驾驶、语言模型等主题。</p><h2 id="c823" class="ne lt iq bd lu nf ng dn ly nh ni dp mc lf nj nk me lj nl nm mg ln nn no mi np bi translated"><a class="ae mv" href="https://arxiv.org/abs/2210.11416" rel="noopener ugc nofollow" target="_blank"> 1。缩放指令-微调语言模型</a></h2><p id="f6d4" class="pw-post-body-paragraph kw kx iq ky b kz mm jr lb lc mn ju le lf nb lh li lj nc ll lm ln nd lp lq lr ij bi translated"><em class="nq">由Hyung Won Chung、Le Hou、Shayne Longpre、Barret Zoph、Yi Tay等人编写</em></p><p id="c079" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated"><strong class="ky ir"> ❓为什么→ </strong>一年前，<strong class="ky ir"> </strong>谷歌的FLAN展示了如何通过将带标签的NLP例子重新表述为自然语言指令，并将其包含在预训练语料库中，来提高语言模型(LMs)的泛化能力。现在我们知道扩大这项技术的规模是什么样的了。</p><p id="f0ec" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated"><strong class="ky ir">💡关键见解→</strong>open ai著名的GPT LMs系列的基本约束之一是对未标记数据的训练。但这并不意味着自回归LMs不能使用标记数据进行训练:可以在不改变任何架构的情况下将注释注入到模型的训练中。关键思想是——而不是让分类头输出输入的标签——将带标签的例子重新表述为用自然语言编写的指令。例如，情感分类的标记示例可以转换为具有以下模板的语句:</p><blockquote class="nr ns nt"><p id="c1b8" class="kw kx nq ky b kz la jr lb lc ld ju le nu lg lh li nv lk ll lm nw lo lp lq lr ij bi translated">这部电影有恐怖的情节和精彩的表演。【阳性】</p><p id="bc88" class="kw kx nq ky b kz la jr lb lc ld ju le nu lg lh li nv lk ll lm nw lo lp lq lr ij bi translated">这部电影很好，因为它有很棒的情节和精湛的演技。</p></blockquote><p id="6794" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">大警告:要比较零射击性能与完全自我监督的模型，如GPT-3，必须确保评估中使用的任务不包括在训练指令中！</p><p id="8ed4" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">最初的FLAN论文显示了这种技术在137B params模型上的强大功能，从几十个NLP任务中获得了最多30k的额外指令。在这篇论文中，他们通过缩放(1)任务数量到1836，(2)模型大小到540B参数，以及(3)添加思维链提示，进入下一个级别。</p><p id="4a21" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">结果表明，添加指令会提升性能，尤其是对于较小的模型，但原始模型规模仍然是最大的因素。</p><figure class="kh ki kj kk gt kl gh gi paragraph-image"><div role="button" tabindex="0" class="km kn di ko bf kp"><div class="gh gi nx"><img src="../Images/328e136ba2e59343488a4d0ea5d2af24.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*3UgXucTVbQlzkQbCjK_v_Q.png"/></div></div><figcaption class="ks kt gj gh gi ku kv bd b be z dk translated">来源:<a class="ae mv" href="https://arxiv.org/pdf/2210.11416.pdf" rel="noopener ugc nofollow" target="_blank">https://arxiv.org/pdf/2210.11416.pdf</a></figcaption></figure><p id="f311" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">完整的模型在谷歌的研究Github知识库上公开发布。</p><h2 id="ad23" class="ne lt iq bd lu nf ng dn ly nh ni dp mc lf nj nk me lj nl nm mg ln nn no mi np bi translated"><a class="ae mv" href="https://arxiv.org/abs/2210.01296" rel="noopener ugc nofollow" target="_blank"> 2。背诵-增强语言模型</a></h2><p id="240e" class="pw-post-body-paragraph kw kx iq ky b kz mm jr lb lc mn ju le lf nb lh li lj nc ll lm ln nd lp lq lr ij bi translated"><em class="nq">作者:孙志清、王学智、易泰、、周丹妮。</em></p><p id="fea7" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated"><strong class="ky ir"> ❓为什么→ </strong>聪明的提示技术继续扩展预先训练的语言模型的能力，而不需要新的复杂的建模技术。</p><p id="13a4" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated"><strong class="ky ir">💡关键见解→ </strong>检索增强语言模型通常从语料库中检索段落，并将它们作为文本附加到提示中，允许它们显式地访问内存。这使得它们更有效，事实上更正确，但代价是大大增加了它们的训练和实现的复杂性。</p><p id="b098" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">return是语言模型提示的一个新版本，其中提示模板推动模型在生成答案之前从记忆中背诵其训练语料库中的相关段落。通过在包含来自训练语料库的段落的提示中提供例子，模型将经常正确地背诵其中的精确段落。</p><p id="51e3" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">这种方法利用大型LMs惊人的良好记忆能力来提高问题回答的性能，而不需要从语料库中显式检索。与之前现成的高级提示技术类似，如思维链。</p><figure class="kh ki kj kk gt kl gh gi paragraph-image"><div role="button" tabindex="0" class="km kn di ko bf kp"><div class="gh gi ny"><img src="../Images/02955df5d621ab68aec6b8029145def4.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*sBUvjmYekJWphhmlMAs1mA.png"/></div></div><figcaption class="ks kt gj gh gi ku kv bd b be z dk translated">来源:https://arxiv.org/pdf/2210.01296.pdf<a class="ae mv" href="https://arxiv.org/pdf/2210.01296.pdf" rel="noopener ugc nofollow" target="_blank"/></figcaption></figure><p id="9318" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">一个重要的警告适用于虽然！这种方法不会像开箱即用那样创造奇迹。为了让它工作得更好，它通常需要多路径decoding⁴，这包括在给定提示(例如，20)的情况下对多个完成进行采样，然后基于多数投票选择答案，并且采样更多路径通常会导致更好的性能，但缺点是推理成本高得多。</p><figure class="kh ki kj kk gt kl gh gi paragraph-image"><div role="button" tabindex="0" class="km kn di ko bf kp"><div class="gh gi nz"><img src="../Images/f39b50d0d06470a589d929370bac724d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*tXee4w22kLfZ36VRdquqFw.png"/></div></div><figcaption class="ks kt gj gh gi ku kv bd b be z dk translated">来源:<a class="ae mv" href="https://arxiv.org/pdf/2210.01296.pdf" rel="noopener ugc nofollow" target="_blank">https://arxiv.org/pdf/2210.01296.pdf</a></figcaption></figure><p id="1c2b" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">如果你对语言模型感兴趣，你也会喜欢这个关于思维链提示的后续工作:<a class="ae mv" href="https://arxiv.org/abs/2210.11610" rel="noopener ugc nofollow" target="_blank">大型语言模型可以自我改进</a>。</p><h2 id="59e5" class="ne lt iq bd lu nf ng dn ly nh ni dp mc lf nj nk me lj nl nm mg ln nn no mi np bi translated"><a class="ae mv" href="https://arxiv.org/abs/2210.08340" rel="noopener ugc nofollow" target="_blank"> 3。迈向下一代人工智能:催化神经革命</a></h2><p id="8b2f" class="pw-post-body-paragraph kw kx iq ky b kz mm jr lb lc mn ju le lf nb lh li lj nc ll lm ln nd lp lq lr ij bi translated">安东尼·扎多尔和其他26名人工智能和神经科学领域的知名研究人员。</p><p id="7857" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated"><strong class="ky ir"> ❓为什么→ </strong>人工智能的创始人，如都灵或明斯基，都受到对大脑如何工作以及它们如何被机器复制的强烈好奇心的驱动。相比之下，现代人工智能从业者大多倾向于作为计算机科学家、逻辑学家和统计学家进行思考，与大脑如何工作的研究无关。该领域会从更紧密的合作中受益吗？很多AI和神经科学的高知名度人物都是这么认为的。</p><p id="da9c" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated"><strong class="ky ir">💡关键见解→ </strong>对大脑的更好理解将为如何建造智能机器提供见解，这一想法并不新鲜。人类大脑和人工智能从一开始就交织在一起。</p><p id="f8ba" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">立场文件强调了人工智能代理的现有挑战，特别是当它以一种明智的方式与世界互动时。虽然语言经常被描绘为人类智力的巅峰，但学习人类水平的感觉运动技能远非一项已解决的任务，而自然语言生成的进展令人震惊，以至于有些人认为原始的图灵测试已经解决。</p><p id="7d1e" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">该宣言的基本原则简明扼要地阐述如下:</p><blockquote class="nr ns nt"><p id="3b3f" class="kw kx nq ky b kz la jr lb lc ld ju le nu lg lh li nv lk ll lm nw lo lp lq lr ij bi translated"><em class="iq"> …对神经计算的更好理解将揭示智能的基本成分，并催化人工智能的下一场革命。</em></p></blockquote><p id="fd3b" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">作为对这一挑战的回应，作者提出了<strong class="ky ir">具体化的</strong>图灵<strong class="ky ir">测试</strong>作为原始图灵测试的继承者:一种更全面的测试，除了明确的推理能力之外，还包括评估感觉运动技能。</p><p id="8463" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">解决下一代图灵测试的路线图依赖于3个主要支柱。(1)对两个阵营给予同等重视的人工智能课程，以便新一代人工智能研究人员对计算机科学和神经科学一样感兴趣，(2)测试代理的共享平台，以及(3)增加对神经计算基础理论研究的资助。</p><h2 id="dfa1" class="ne lt iq bd lu nf ng dn ly nh ni dp mc lf nj nk me lj nl nm mg ln nn no mi np bi translated"><a class="ae mv" href="https://arxiv.org/abs/2210.08863" rel="noopener ugc nofollow" target="_blank"> 4。你只活一次:单生命强化学习</a></h2><p id="e905" class="pw-post-body-paragraph kw kx iq ky b kz mm jr lb lc mn ju le lf nb lh li lj nc ll lm ln nd lp lq lr ij bi translated">安妮·s·陈、阿奇特·夏尔马、谢尔盖·莱文和切尔西·费恩。</p><p id="a6a2" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated"><strong class="ky ir"> ❓为什么→ </strong>部署后，代理能够快速适应新环境吗？对于要求代理在看不见的环境中表现良好的问题，情景强化学习并不是一个合适的框架。</p><p id="218e" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated"><strong class="ky ir">💡关键见解→ </strong>在这项工作中，作者为单生命强化学习奠定了形式主义，这是一种在看不见的环境中测试代理的范式。目标是一次性解决任务而不陷入困境，而不是像在传统RL中那样学习该环境的策略。</p><p id="4811" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">作者还提出了一种新的算法，Q加权对抗学习(QWALE)，它使用“分布匹配”来利用以前的经验作为新情况下的指导。当然，他们的方法远远优于基线，但与大多数挑战范式的工作一样，不清楚评估的选择在多大程度上是根据提出的特定模型定制的。</p><p id="33ba" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">在任何情况下，这种RL范式都与零触发学习和泛化有着有趣的相似之处，这是ML中获得牵引力的领域，因为古老的监督学习技术的脆弱性已经被发现。单次RL会成为RL论文中一个新的必须包含的评估机制吗？我们希望如此！</p><figure class="kh ki kj kk gt kl gh gi paragraph-image"><div role="button" tabindex="0" class="km kn di ko bf kp"><div class="gh gi oa"><img src="../Images/73e3beb099532884eaa31dc88881ad57.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*lZ7WZZIPSkKSsODy7eD_7g.png"/></div></div><figcaption class="ks kt gj gh gi ku kv bd b be z dk translated">来源:https://arxiv.org/pdf/2210.08863.pdf</figcaption></figure><h2 id="b696" class="ne lt iq bd lu nf ng dn ly nh ni dp mc lf nj nk me lj nl nm mg ln nn no mi np bi translated"><a class="ae mv" href="https://arxiv.org/abs/2210.07729" rel="noopener ugc nofollow" target="_blank"> 5。基于模型的城市驾驶模仿学习</a> | <a class="ae mv" href="https://github.com/wayveai/mile" rel="noopener ugc nofollow" target="_blank">代码</a> | <a class="ae mv" href="https://wayve.ai/blog/learning-a-world-model-and-a-driving-policy/" rel="noopener ugc nofollow" target="_blank">博文</a></h2><p id="d791" class="pw-post-body-paragraph kw kx iq ky b kz mm jr lb lc mn ju le lf nb lh li lj nc ll lm ln nd lp lq lr ij bi translated"><em class="nq">作者:Anthony Hu、Gianluca Corrado、Nicolas Griffiths、Zak Murez、Corina Gurau、Hudson Yeo、Alex Kendall、Roberto Cipolla和Jamie Shotton。</em></p><p id="ecf9" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated"><strong class="ky ir"> ❓为什么→ </strong>自动驾驶性能的飞跃(嗯，在模拟环境下！)</p><p id="45ed" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated"><strong class="ky ir">💡关键见解→ </strong>从与世界的互动中在线学习与从演示中离线学习(模仿学习)是RL中最基本的划分之一。广义而言，前者稳健但低效，后者高效但脆弱。</p><p id="d884" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">本文介绍了在CARLA⁵模拟器上利用模仿学习实现自动驾驶的最新进展。模仿学习的进步特别有用，因为它们能更好地转化为现实世界的情况。在现实世界中学习驾驶政策在线学习往往太危险和昂贵。没人愿意每集重置都买新车！</p><p id="2c1c" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">这里提出的模型(MILE)通过尝试推断哪些潜在特征导致训练中提供的专家观察来学习潜在空间中的世界动态。您可以在下图中找到该模型如何工作的概述。</p><figure class="kh ki kj kk gt kl gh gi paragraph-image"><div role="button" tabindex="0" class="km kn di ko bf kp"><div class="gh gi ob"><img src="../Images/59044deb7f8df8ecabacb3d8eb4c04b8.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*4GUl_LixdJFhwKDHQB7_Mg.png"/></div></div><figcaption class="ks kt gj gh gi ku kv bd b be z dk translated">资料来源:https://arxiv.org/pdf/2210.07729.pdf</figcaption></figure><p id="2cd4" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">当谈到结果时，MILE闪耀<strong class="ky ir">特别是在域外评估</strong>:看不见的城镇和看不见的天气条件。</p><figure class="kh ki kj kk gt kl gh gi paragraph-image"><div role="button" tabindex="0" class="km kn di ko bf kp"><div class="gh gi oa"><img src="../Images/42cf841a4a3bbc34a57cba77b6a0c59f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*bVmBAKEOQt705vSBJjMIyQ.png"/></div></div><figcaption class="ks kt gj gh gi ku kv bd b be z dk translated">来源:<a class="ae mv" href="https://arxiv.org/pdf/2210.07729.pdf" rel="noopener ugc nofollow" target="_blank">https://arxiv.org/pdf/2210.07729.pdf</a></figcaption></figure><h2 id="eef8" class="ne lt iq bd lu nf ng dn ly nh ni dp mc lf nj nk me lj nl nm mg ln nn no mi np bi translated">6。DreamFusion:使用2D扩散将文本转换为3D|<a class="ae mv" href="https://dreamfusion3d.github.io" rel="noopener ugc nofollow" target="_blank">项目页面</a> | <a class="ae mv" href="https://github.com/ashawkey/stable-dreamfusion" rel="noopener ugc nofollow" target="_blank">非官方实现(稳定DreamFusion) </a></h2><p id="c6e9" class="pw-post-body-paragraph kw kx iq ky b kz mm jr lb lc mn ju le lf nb lh li lj nc ll lm ln nd lp lq lr ij bi translated">本·普尔、阿贾伊·贾恩、乔纳森·t·巴伦和本·米尔登霍尔。</p><p id="cfaf" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated"><strong class="ky ir"> ❓为什么→ </strong>扩散模型的迅速崛起超越了纯文本到图像的时代。</p><p id="f207" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated"><strong class="ky ir">💡关键见解→ </strong> 3D生成很难(还有其他挑战),因为不像2D图像，没有多少3D模型可以用来训练端到端的3D生成器。在这项工作中，他们通过利用现有2D图像生成器的功能来引导3D资产的生成，从而规避了这一限制。</p><p id="105a" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">关键成分是<strong class="ky ir">分数蒸馏取样(SDS)。</strong>该方法能够将2D文本到图像模型的输出转换到任何参数空间，例如3D模型，只要该转换是可微分的。为了从文本合成场景，该方法随机初始化一个NeRF模型，并从不同的相机位置和角度重复渲染该NeRF的视图，然后使用这些渲染作为扩散模型的输入+通过NeRF反向传播的得分蒸馏损失。最初，这些视图看起来像噪声，但是通过足够的扩散优化时间步长，它们最终正确地表示3D对象的视图。</p><p id="532e" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">需要一些技巧和规则来使设置工作，但结果是引人注目的，因为你可以在他们的项目页面上查看。你也可以玩一个<a class="ae mv" href="https://github.com/ashawkey/stable-dreamfusion" rel="noopener ugc nofollow" target="_blank">非官方的开源实现</a>,由同样开源的文本到图像稳定扩散支持。</p><figure class="kh ki kj kk gt kl gh gi paragraph-image"><div role="button" tabindex="0" class="km kn di ko bf kp"><div class="gh gi oc"><img src="../Images/b6815b3e416cc3dea77e8e7410222a09.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*1nOyckOwuqi9gvAa0_9KJw.png"/></div></div><figcaption class="ks kt gj gh gi ku kv bd b be z dk translated">来源:<a class="ae mv" href="https://arxiv.org/pdf/2209.14988.pdf" rel="noopener ugc nofollow" target="_blank">https://arxiv.org/pdf/2209.14988.pdf</a></figcaption></figure><h2 id="2cfb" class="ne lt iq bd lu nf ng dn ly nh ni dp mc lf nj nk me lj nl nm mg ln nn no mi np bi translated"><a class="ae mv" href="https://arxiv.org/abs/2210.09276" rel="noopener ugc nofollow" target="_blank"> 7。Imagic:使用扩散模型进行基于文本的真实图像编辑</a></h2><p id="b3ad" class="pw-post-body-paragraph kw kx iq ky b kz mm jr lb lc mn ju le lf nb lh li lj nc ll lm ln nd lp lq lr ij bi translated"><em class="nq">作者:Bahjat Kawar、Shiran Zada、Oran Lang、Omer Tov、Huiwen Chang、Dekel、Inbar Mosseri、Michal等。</em></p><p id="a5ac" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated"><strong class="ky ir"> ❓为什么→ </strong>用扩散模型编辑图像变得更好了！</p><p id="38be" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated"><strong class="ky ir">💡关键见解→ </strong>继续讨论扩散模型的话题，这种模型的一个强大应用是受限于特定编辑类型的图像编辑，例如条件修复或样式转移。这项工作展示了对图像应用无约束的、复杂的、语义相关的、文本引导的编辑的能力。</p><figure class="kh ki kj kk gt kl gh gi paragraph-image"><div role="button" tabindex="0" class="km kn di ko bf kp"><div class="gh gi od"><img src="../Images/150c1001252bea209405f90909bc313a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*6A243bglOpBSjeZnzt6WFg.png"/></div></div><figcaption class="ks kt gj gh gi ku kv bd b be z dk translated">来源:<a class="ae mv" href="https://arxiv.org/pdf/2210.09276.pdf" rel="noopener ugc nofollow" target="_blank">https://arxiv.org/pdf/2210.09276.pdf</a></figcaption></figure><p id="3d96" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">该技术依赖于在输入和目标图像之间的嵌入空间中进行插值。首先(A)，它们对齐文本和图像嵌入，使得在给定冻结的预训练扩散模型的情况下，相似的嵌入产生相似的图像代。然后(B)在对准嵌入上微调扩散模型，最后，内插目标和对准嵌入并用于生成编辑图像。</p><figure class="kh ki kj kk gt kl gh gi paragraph-image"><div role="button" tabindex="0" class="km kn di ko bf kp"><div class="gh gi od"><img src="../Images/aca4bb6bd6df48972a34e52cccefdb85.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Dm694gYYEi85pbCEbD_ZBw.png"/></div></div><figcaption class="ks kt gj gh gi ku kv bd b be z dk translated">来源:https://arxiv.org/pdf/2210.09276.pdf</figcaption></figure><h2 id="e861" class="ne lt iq bd lu nf ng dn ly nh ni dp mc lf nj nk me lj nl nm mg ln nn no mi np bi translated"><a class="ae mv" href="https://arxiv.org/abs/2210.03662" rel="noopener ugc nofollow" target="_blank"> 8。GoalsEye:在物理机器人上学习高速精密乒乓球</a> | <a class="ae mv" href="https://sites.google.com/view/goals-eye" rel="noopener ugc nofollow" target="_blank">项目页面</a></h2><p id="db64" class="pw-post-body-paragraph kw kx iq ky b kz mm jr lb lc mn ju le lf nb lh li lj nc ll lm ln nd lp lq lr ij bi translated"><em class="nq">作者:田丽·丁、劳拉·格雷塞、萨明达·阿贝鲁万、戴维·b·安布罗休、安尼施·尚卡尔、皮埃尔·塞尔马内、潘纳格·r·桑克蒂、科里·林奇。</em></p><p id="6708" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated"><strong class="ky ir"> ❓为什么→ </strong>这是模仿学习的又一个展示，展示了它将出色的表现传递给物理机器人的力量。</p><p id="dd5e" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated"><strong class="ky ir">💡关键见解→ </strong>仍然在2022年，RL系统最大的挑战之一是让它们在真实世界中工作，而不是在模拟环境中工作。这一点尤其重要——正如我们刚刚在自动驾驶汽车的背景下提到的那样——因为RL中的在线学习通常在物理世界中不可行:它仍然是低效的，并且太多的东西会坏太多次。</p><p id="a23d" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">本文展示了如何使用迭代监督模仿学习来教机器人打网球，即，将自我游戏与面向目标的行为克隆相结合。成功的关键是:( 1)从机器人刚刚击球的演示的非目标导向引导数据集开始，以克服低效的初始探索阶段。(2)后见之明重新标记目标条件行为克隆(例如，记录球是如何被击中的以及球落在哪里，然后将其用作目标)。(3)目标导向的迭代自我监督游戏以击中目标。</p><p id="3f25" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">查看他们的项目页面<a class="ae mv" href="https://sites.google.com/view/goals-eye" rel="noopener ugc nofollow" target="_blank">来观看他们的机器人如何工作的所有视频演示！</a></p><figure class="kh ki kj kk gt kl gh gi paragraph-image"><div role="button" tabindex="0" class="km kn di ko bf kp"><div class="gh gi oe"><img src="../Images/7e9225d83d2400d0cd17145a4b2e6d9e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*5b8fmmca7eG9KkBR50hLjw.png"/></div></div><figcaption class="ks kt gj gh gi ku kv bd b be z dk translated">资料来源:https://arxiv.org/pdf/2210.03662.pdf</figcaption></figure><h2 id="238f" class="ne lt iq bd lu nf ng dn ly nh ni dp mc lf nj nk me lj nl nm mg ln nn no mi np bi translated"><a class="ae mv" href="https://arxiv.org/abs/2210.07316" rel="noopener ugc nofollow" target="_blank"> 9。MTEB:海量文本嵌入基准</a> | <a class="ae mv" href="https://t.co/QseYZpIzuU" rel="noopener ugc nofollow" target="_blank">代码</a> | <a class="ae mv" href="https://huggingface.co/spaces/mteb/leaderboard" rel="noopener ugc nofollow" target="_blank">排行榜</a></h2><p id="a3b7" class="pw-post-body-paragraph kw kx iq ky b kz mm jr lb lc mn ju le lf nb lh li lj nc ll lm ln nd lp lq lr ij bi translated">Niklas Muennighoff、Nouamane Tazi、loc Magne和Nils Reimers。</p><p id="5656" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated"><strong class="ky ir"> ❓为什么→ </strong>如今有大量现成的自然语言处理嵌入模型，从中做出选择已经成为一个挑战。这项工作促进了这一进程。</p><p id="951e" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated"><strong class="ky ir">💡关键见解→ </strong>泛型语言嵌入非常流行的主要原因之一是它们的便利性:在将文本转换为向量后，执行NLP任务，如分类、语义相似性、检索或聚类等，变得很容易。但是用<em class="nq">一个嵌入来统治所有</em>的承诺还远未实现，这就是为什么对各种任务进行基准测试是找到通用用例最佳模型的关键。</p><p id="fc75" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">该基准测试包括8个嵌入任务，共涵盖56个数据集和112种语言，构建时考虑了4个基本原则:</p><ul class=""><li id="3ff9" class="mk ml iq ky b kz la lc ld lf of lj og ln oh lr mr ms mt mu bi translated">多样性(8项任务):分类、聚类、配对分类、重新排序、检索、语义文本相似性和摘要。</li><li id="bc23" class="mk ml iq ky b kz mw lc mx lf my lj mz ln na lr mr ms mt mu bi translated">简单性:可以通过即插即用的API访问该基准。</li><li id="071b" class="mk ml iq ky b kz mw lc mx lf my lj mz ln na lr mr ms mt mu bi translated">可扩展性:有一个指定的语法和过程，可以通过HuggingFace hub轻松地向现有基准添加新数据集。</li><li id="6301" class="mk ml iq ky b kz mw lc mx lf my lj mz ln na lr mr ms mt mu bi translated">可再现性:版本控制是该基准测试版的一个内置特性，使得在该基准测试的任何版本上重新运行任何评估成为可能。</li></ul><p id="addb" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">结果表明，现代基于变压器的模型如何优于GloVe等经典模型，但性能往往是以速度为代价的，这对于一些应用来说是不可接受的。您可以在<a class="ae mv" href="https://huggingface.co/spaces/mteb/leaderboard" rel="noopener ugc nofollow" target="_blank">hugging face排行榜</a>上查看最新结果。</p><figure class="kh ki kj kk gt kl gh gi paragraph-image"><div role="button" tabindex="0" class="km kn di ko bf kp"><div class="gh gi oi"><img src="../Images/2056360d0af161680a63f85233d54470.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*37ek0tXZ_koBOtES-J9RCA.jpeg"/></div></div><figcaption class="ks kt gj gh gi ku kv bd b be z dk translated">来源:<a class="ae mv" href="https://arxiv.org/pdf/2210.07316.pdf" rel="noopener ugc nofollow" target="_blank">https://arxiv.org/pdf/2210.07316.pdf</a></figcaption></figure><h2 id="fb64" class="ne lt iq bd lu nf ng dn ly nh ni dp mc lf nj nk me lj nl nm mg ln nn no mi np bi translated"><a class="ae mv" href="https://arxiv.org/abs/2210.13438" rel="noopener ugc nofollow" target="_blank"> 10。高保真神经音频压缩</a> | <a class="ae mv" href="https://ai.facebook.com/blog/ai-powered-audio-compression-technique/" rel="noopener ugc nofollow" target="_blank">博文</a> | <a class="ae mv" href="https://github.com/facebookresearch/encodec" rel="noopener ugc nofollow" target="_blank">代码+模型</a></h2><p id="3608" class="pw-post-body-paragraph kw kx iq ky b kz mm jr lb lc mn ju le lf nb lh li lj nc ll lm ln nd lp lq lr ij bi translated"><em class="nq">作者:Alexandre Défossez、Jade Copet、Gabriel Synnaeve和Yossi Adi。</em></p><p id="a398" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated"><strong class="ky ir"> ❓为什么→ </strong>压缩算法是互联网的支柱。经过多年对神经编解码器的研究，它们不仅在质量上，而且在方便性上都赶上了经典的健壮替代品。</p><p id="bdfd" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated"><strong class="ky ir">💡关键见解→</strong>Meta提出的压缩音频的方法由一个量化的自动编码器组成，该编码器根据重建和不利损失的组合进行训练。重构损失既在原始音频信号上也在mel谱图上，并且对抗性损失来自于需要对压缩表示和结果音频是否彼此对应进行分类的鉴别器。最后，量化表示上的额外正则化损失用于防止量化过度改变压缩表示。</p><figure class="kh ki kj kk gt kl gh gi paragraph-image"><div role="button" tabindex="0" class="km kn di ko bf kp"><div class="gh gi od"><img src="../Images/fd4e83f22e3101b653bd9047263abe56.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*l21aXTWbfwCffWLWKRuEzg.png"/></div></div><figcaption class="ks kt gj gh gi ku kv bd b be z dk translated">来源:https://arxiv.org/pdf/2210.13438.pdf<a class="ae mv" href="https://arxiv.org/pdf/2210.13438.pdf" rel="noopener ugc nofollow" target="_blank"/></figcaption></figure><p id="6c40" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">所描述的方法并不特别新颖，但高度的优化性和稳健性是。这种方法在合理的音频质量下实现的压缩增益令人印象深刻，以低至6kbps的速度编码音频，保持了与64kbps mp3编解码器相当的质量，同时以大约10倍的实时系数解码。<a class="ae mv" href="https://ai.facebook.com/blog/ai-powered-audio-compression-technique/" rel="noopener ugc nofollow" target="_blank">这个例子</a>你可以自己听。</p><p id="a6f8" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">但是性能并不是唯一重要的变量，尽管对于压缩编解码器来说，便利性是经典编解码器难以超越的。从Meta关于这项研究的博客帖子来看，他们认为这是一项关键的使能技术，用于他们涉及元宇宙的更广泛的公司使命，因此我们预计该公司将很快在生产中利用这些模型。</p></div><div class="ab cl oj ok hu ol" role="separator"><span class="om bw bk on oo op"/><span class="om bw bk on oo op"/><span class="om bw bk on oo"/></div><div class="ij ik il im in"><p id="ddf5" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated"><em class="nq">参考文献:</em></p><p id="b02d" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated"><em class="nq">【1】《微调过的语言模型是零射学习者》Jason Wei等人，2021。</em></p><p id="4c35" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated"><em class="nq">【2】《思维链提示引发大型语言模型中的推理》Jason Wei等，2022。</em></p><p id="e495" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated"><em class="nq">【3】《领域:检索-增强语言模型预训练》Kelvin Guu等人2020。</em></p><p id="6345" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated"><em class="nq">【4】《语言模型中自洽性提高思维推理链》王学智等2022。</em></p></div></div>    
</body>
</html>