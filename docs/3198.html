<html>
<head>
<title>F1 to F-beta</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">F1到F-beta</h1>
<blockquote>原文：<a href="https://pub.towardsai.net/f1-to-f-beta-2dc4b957ba11?source=collection_archive---------3-----------------------#2022-10-10">https://pub.towardsai.net/f1-to-f-beta-2dc4b957ba11?source=collection_archive---------3-----------------------#2022-10-10</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><h2 id="8e1c" class="io ip iq bd b dl ir is it iu iv iw dk ix translated" aria-label="kicker paragraph">模型评估</h2><div class=""/><figure class="gl gn jx jy jz ka gh gi paragraph-image"><div role="button" tabindex="0" class="kb kc di kd bf ke"><div class="gh gi jw"><img src="../Images/5712d363106e205b91fd60767666bb8f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*pqzLmhG02QIvllTT_F-2KA.png"/></div></div><figcaption class="kh ki gj gh gi kj kk bd b be z dk translated">作者图片</figcaption></figure><h1 id="c239" class="kl km iq bd kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li bi translated">F1分数</h1><p id="4bd2" class="pw-post-body-paragraph lj lk iq ll b lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma mb mc md me mf mg ij bi translated">F-1分数是一个流行的二进制分类指标，代表了<strong class="ll ja">精度</strong>和<strong class="ll ja">召回</strong>之间的平衡。这是精确和回忆的调和平均值。下面的等式可以表示F-1分数。</p><figure class="mi mj mk ml gt ka gh gi paragraph-image"><div class="gh gi mh"><img src="../Images/52deee285d0dce9c806f5a78d26a3ad7.png" data-original-src="https://miro.medium.com/v2/resize:fit:500/format:webp/1*96dLiRSU2VLqilr2KYc9xA.png"/></div></figure><p id="be68" class="pw-post-body-paragraph lj lk iq ll b lm mm lo lp lq mn ls lt lu mo lw lx ly mp ma mb mc mq me mf mg ij bi translated">其中<strong class="ll ja">精度</strong>可以定义为作为正类实际成员的正预测的概率。</p><figure class="mi mj mk ml gt ka gh gi paragraph-image"><div class="gh gi mr"><img src="../Images/5eae13d4c44bb4196ec5089637552646.png" data-original-src="https://miro.medium.com/v2/resize:fit:406/format:webp/1*X71ujliQAR6otoWybnNQqQ.png"/></div></figure><p id="cb63" class="pw-post-body-paragraph lj lk iq ll b lm mm lo lp lq mn ls lt lu mo lw lx ly mp ma mb mc mq me mf mg ij bi translated"><strong class="ll ja">召回</strong>是<strong class="ll ja"> </strong>定义为在实际肯定中肯定预测的概率。</p><figure class="mi mj mk ml gt ka gh gi paragraph-image"><div class="gh gi ms"><img src="../Images/40487487c1d55b73f1c74bfc1cc9ead8.png" data-original-src="https://miro.medium.com/v2/resize:fit:354/format:webp/1*QRfqIAC9LVTlQGVNlTtZgw.png"/></div></figure><p id="1b74" class="pw-post-body-paragraph lj lk iq ll b lm mm lo lp lq mn ls lt lu mo lw lx ly mp ma mb mc mq me mf mg ij bi translated">其中<strong class="ll ja"> TP </strong>为<strong class="ll ja">真阳性</strong>，<strong class="ll ja"> FP </strong>为<strong class="ll ja">假阳性，</strong>和<strong class="ll ja"> FN </strong>为<strong class="ll ja">假阴性</strong>。</p><p id="1f65" class="pw-post-body-paragraph lj lk iq ll b lm mm lo lp lq mn ls lt lu mo lw lx ly mp ma mb mc mq me mf mg ij bi translated"><em class="mt">让我们探索一下在sklearn中使用虚拟数据集的二元分类问题的F1分数。</em></p><pre class="mi mj mk ml gt mu mv mw mx aw my bi"><span id="91b8" class="mz km iq mv b gy na nb l nc nd">from sklearn.datasets import make_classification<br/>from sklearn.model_selection import train_test_split<br/>from sklearn.linear_model import LogisticRegression<br/>from sklearn.metrics import f1_score</span><span id="6e17" class="mz km iq mv b gy ne nb l nc nd">X, y = make_classification(n_samples=1000, n_classes=2,<br/>                           random_state=1)<br/>X_train, X_test, y_train, y_test = train_test_split(X, y,<br/>                                                    test_size=.2,<br/>                                                    random_state=2)<br/>lr = LogisticRegression()<br/>lr.fit(X_train, y_train)<br/>y_pred = lr.predict(X_test)<br/>y_pred_prob = lr.predict_proba(X_test)<br/>y_pred_prob = y_pred_prob[:,1]<br/>f1_score(y_test, y_pred)</span><span id="c406" class="mz km iq mv b gy ne nb l nc nd"><strong class="mv ja">Output:<br/></strong>0.8585858585858585</span></pre><p id="9c3c" class="pw-post-body-paragraph lj lk iq ll b lm mm lo lp lq mn ls lt lu mo lw lx ly mp ma mb mc mq me mf mg ij bi translated">虽然许多机器学习和深度学习实践者经常使用F1分数进行模型评估，但很少有人熟悉F-measure，这是F1分数的一般形式。</p><p id="8a3a" class="pw-post-body-paragraph lj lk iq ll b lm mm lo lp lq mn ls lt lu mo lw lx ly mp ma mb mc mq me mf mg ij bi translated"><strong class="ll ja"> F-beta评分</strong></p><p id="252d" class="pw-post-body-paragraph lj lk iq ll b lm mm lo lp lq mn ls lt lu mo lw lx ly mp ma mb mc mq me mf mg ij bi translated">F-beta分数的计算遵循与F1分数相同的形式。与F1分数中的调和平均值不同，它是精确度和召回率的<strong class="ll ja">加权</strong>调和平均值，在1处达到最佳值，在0处达到最差值。</p><figure class="mi mj mk ml gt ka gh gi paragraph-image"><div class="gh gi nf"><img src="../Images/15677c8431f692f241c3d1d697a391de.png" data-original-src="https://miro.medium.com/v2/resize:fit:626/format:webp/1*BEhU7qiJhiDa_SI3eNawQQ.png"/></div></figure><p id="af45" class="pw-post-body-paragraph lj lk iq ll b lm mm lo lp lq mn ls lt lu mo lw lx ly mp ma mb mc mq me mf mg ij bi translated"><code class="fe ng nh ni mv b">beta</code>参数决定了回忆在综合得分中的权重。<code class="fe ng nh ni mv b">beta &lt; 1</code>更重视精确度，而<code class="fe ng nh ni mv b">beta &gt; 1</code>更喜欢回忆。</p><p id="8930" class="pw-post-body-paragraph lj lk iq ll b lm mm lo lp lq mn ls lt lu mo lw lx ly mp ma mb mc mq me mf mg ij bi translated">我们来看看F-beta的分数，以及数值是如何随beta波动的。</p><pre class="mi mj mk ml gt mu mv mw mx aw my bi"><span id="f076" class="mz km iq mv b gy na nb l nc nd">from sklearn.metrics import fbeta_score</span><span id="6133" class="mz km iq mv b gy ne nb l nc nd">print(fbeta_score(y_test, y_pred, beta=0.5))<br/>print(fbeta_score(y_test, y_pred, beta=1))<br/>print(fbeta_score(y_test, y_pred, beta=2))</span><span id="5725" class="mz km iq mv b gy ne nb l nc nd"><strong class="mv ja">Output:<br/></strong>0.853413654618474<br/>0.8585858585858585<br/>0.8638211382113821</span></pre><p id="92ac" class="pw-post-body-paragraph lj lk iq ll b lm mm lo lp lq mn ls lt lu mo lw lx ly mp ma mb mc mq me mf mg ij bi translated">在这里，我们已经注意到F-beta随着beta移动而变化，现在让我们看看在不同阈值下相同的相对于精度和召回曲线。</p><pre class="mi mj mk ml gt mu mv mw mx aw my bi"><span id="9353" class="mz km iq mv b gy na nb l nc nd">import matplotlib.pyplot as plt<br/>from sklearn.metrics import recall_score<br/>from sklearn.metrics import precision_score<br/>from sklearn.metrics import precision_recall_curve</span><span id="641b" class="mz km iq mv b gy ne nb l nc nd">_, _, threshold = precision_recall_curve(y_test, y_pred_prob)</span><span id="c3d8" class="mz km iq mv b gy ne nb l nc nd">f1score = list()<br/>f05score = list()<br/>f2score = list()<br/>precision = list()<br/>recall = list()<br/>for th in threshold:                                                    <br/>    y_test_pred = list()<br/>    for prob in y_pred_prob:<br/>        if prob &gt; th:<br/>            y_test_pred.append(1)<br/>        else:<br/>            y_test_pred.append(0)<br/>    <br/>    f1score.append(f1_score(y_test, y_test_pred))<br/>    precision.append(precision_score(y_test, y_test_pred))<br/>    recall.append(recall_score(y_test, y_test_pred))<br/>    f05score.append(fbeta_score(y_test, y_test_pred, beta=0.5))<br/>    f2score.append(fbeta_score(y_test, y_test_pred, beta=2))</span><span id="047f" class="mz km iq mv b gy ne nb l nc nd">_, ax = plt.subplots(figsize=(8, 6))<br/>ax.set_xlabel('Threshold')<br/>plt.plot(threshold, precision, label='precision')<br/>plt.plot(threshold, recall, label='recall')<br/>plt.plot(threshold, f05score, label='F0.5')<br/>plt.plot(threshold, f1score, label='F1')<br/>plt.plot(threshold, f2score, label='F2')<br/>plt.legend(loc='lower left')</span></pre><figure class="mi mj mk ml gt ka gh gi paragraph-image"><div class="gh gi nj"><img src="../Images/933a107b37e4b1d50cf248b1145bb083.png" data-original-src="https://miro.medium.com/v2/resize:fit:974/format:webp/1*gMW2uRnyX74ePtAtasqEWg.png"/></div><figcaption class="kh ki gj gh gi kj kk bd b be z dk translated">精确度、召回率、F1与阈值|作者图片</figcaption></figure><p id="ac1f" class="pw-post-body-paragraph lj lk iq ll b lm mm lo lp lq mn ls lt lu mo lw lx ly mp ma mb mc mq me mf mg ij bi translated">从上图中可以明显看出，当我们从0开始增加beta值时，曲线开始向召回曲线移动，这意味着beta值的增加赋予召回更多的重要性，下面的代码绘制了不同beta值和阈值下的F-measure。</p><pre class="mi mj mk ml gt mu mv mw mx aw my bi"><span id="a615" class="mz km iq mv b gy na nb l nc nd">betas = [0.1, 0.3, 0.5, 0.7, 1, 2, 5]<br/>_, ax = plt.subplots(figsize=(8, 6))<br/>ax.set_xlabel('Threshold')<br/>ax.set_ylabel('Fbeta')<br/>for beta in betas:<br/>    fbetascore = list()<br/>    for i, th in enumerate(threshold):<br/>        y_test_pred = list()<br/>        for prob in y_pred_prob:<br/>            if prob &gt; th:<br/>                y_test_pred.append(1)<br/>            else:<br/>                y_test_pred.append(0)<br/>        fbetascore.append(fbeta_score(y_test, y_test_pred,<br/>                                      beta=beta))<br/>    plt.plot(threshold, fbetascore, label=f'F{beta}')<br/>plt.legend(loc='lower left')</span></pre><figure class="mi mj mk ml gt ka gh gi paragraph-image"><div class="gh gi nk"><img src="../Images/a74077629691aa82f3f09ed1408385f5.png" data-original-src="https://miro.medium.com/v2/resize:fit:1002/format:webp/1*LF0sX85Qk8oyoXUcM5qj2Q.png"/></div><figcaption class="kh ki gj gh gi kj kk bd b be z dk translated">Fbeta与阈值|作者图片</figcaption></figure><p id="6f00" class="pw-post-body-paragraph lj lk iq ll b lm mm lo lp lq mn ls lt lu mo lw lx ly mp ma mb mc mq me mf mg ij bi translated"><strong class="ll ja">参考文献:</strong></p><p id="eefe" class="pw-post-body-paragraph lj lk iq ll b lm mm lo lp lq mn ls lt lu mo lw lx ly mp ma mb mc mq me mf mg ij bi translated">[1] F1分数。<a class="ae nl" href="https://scikit-learn.org/stable/modules/generated/sklearn.metrics.f1_score.html#sklearn.metrics.f1_score" rel="noopener ugc nofollow" target="_blank">https://sci kit-learn . org/stable/modules/generated/sk learn . metrics . f1 _ score . html # sk learn . metrics . f1 _ score</a></p><p id="523b" class="pw-post-body-paragraph lj lk iq ll b lm mm lo lp lq mn ls lt lu mo lw lx ly mp ma mb mc mq me mf mg ij bi translated">[2] Fbeta分数。<a class="ae nl" href="https://scikit-learn.org/stable/modules/generated/sklearn.metrics.fbeta_score.html" rel="noopener ugc nofollow" target="_blank">https://sci kit-learn . org/stable/modules/generated/sk learn . metrics . fbeta _ score . html</a></p></div></div>    
</body>
</html>