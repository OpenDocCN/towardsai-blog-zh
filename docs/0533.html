<html>
<head>
<title>34 Words About Language, Every AI-Savvy Leader Must Know</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">关于语言的34个词，每个精通人工智能的领导者都必须知道</h1>
<blockquote>原文：<a href="https://pub.towardsai.net/ai-language-1d266caa72c6?source=collection_archive---------2-----------------------#2020-05-28">https://pub.towardsai.net/ai-language-1d266caa72c6?source=collection_archive---------2-----------------------#2020-05-28</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><h2 id="b9a9" class="io ip iq bd b dl ir is it iu iv iw dk ix translated" aria-label="kicker paragraph">人工智能</h2><div class=""/><div class=""><h2 id="74c8" class="pw-subtitle-paragraph jw iz iq bd b jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn dk translated">你能解释这些吗？检验你的知识！</h2></div><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div role="button" tabindex="0" class="ku kv di kw bf kx"><div class="gh gi ko"><img src="../Images/b74191884da4b996968f575c0e40aeba.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Ab_S-KPFo-h_hLlb8NX2zw.jpeg"/></div></div></figure><p id="f889" class="pw-post-body-paragraph la lb iq lc b ld le ka lf lg lh kd li lj lk ll lm ln lo lp lq lr ls lt lu lv ij bi translated"><em class="lw">【这是</em> <strong class="lc ja"> <em class="lw">系列</em> </strong> <em class="lw">的第7部。确保你阅读了关于</em> <a class="ae lx" href="https://medium.com/towards-artificial-intelligence/ai-search-e0cb610237f6" rel="noopener"> <em class="lw">搜索</em></a><a class="ae lx" href="https://medium.com/towards-artificial-intelligence/ai-knowledge-1020a00eb45d" rel="noopener"><em class="lw">知识</em></a><a class="ae lx" href="https://medium.com/towards-artificial-intelligence/ai-uncertainty-4ac6810899ac" rel="noopener"><em class="lw">不确定性</em></a><a class="ae lx" href="https://medium.com/towards-artificial-intelligence/ai-optimization-b8735dc09448" rel="noopener"><em class="lw">优化</em></a><em class="lw"/><a class="ae lx" href="https://medium.com/towards-artificial-intelligence/ai-learning-2eaea82ee6d" rel="noopener"><em class="lw">机器学习</em></a><em class="lw"/><a class="ae lx" href="https://medium.com/towards-artificial-intelligence/26-words-about-neural-networks-every-ai-neural-networks-1085bd972fd5" rel="noopener"><em class="lw">神经网络</em> </a> <em class="lw">和</em> <a class="ae lx" href="https://medium.com/towards-artificial-intelligence/ai-learning-2eaea82ee6d" rel="noopener">】</a></p><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div role="button" tabindex="0" class="ku kv di kw bf kx"><div class="gh gi ly"><img src="../Images/292b8dfe40e702f4f0437b48bc55594f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*7c4R1yVzjdKf4Kj-2KRKIg.png"/></div></div></figure><p id="6a64" class="pw-post-body-paragraph la lb iq lc b ld le ka lf lg lh kd li lj lk ll lm ln lo lp lq lr ls lt lu lv ij bi translated">为了真正改变人类与计算机的交互方式，我们需要让计算机能够阅读、理解并从书面和口头语言中获取意义。在AI中，这个领域被称为<strong class="lc ja">自然语言处理(NLP) </strong>。</p><p id="3453" class="pw-post-body-paragraph la lb iq lc b ld le ka lf lg lh kd li lj lk ll lm ln lo lp lq lr ls lt lu lv ij bi translated"><strong class="lc ja">潜在的</strong> <strong class="lc ja"> NLP应用包括:</strong></p><ul class=""><li id="cdac" class="lz ma iq lc b ld le lg lh lj mb ln mc lr md lv me mf mg mh bi translated">自动摘要</li><li id="fcc8" class="lz ma iq lc b ld mi lg mj lj mk ln ml lr mm lv me mf mg mh bi translated">信息提取</li><li id="c38a" class="lz ma iq lc b ld mi lg mj lj mk ln ml lr mm lv me mf mg mh bi translated">语言识别</li><li id="d184" class="lz ma iq lc b ld mi lg mj lj mk ln ml lr mm lv me mf mg mh bi translated">机器翻译</li><li id="0238" class="lz ma iq lc b ld mi lg mj lj mk ln ml lr mm lv me mf mg mh bi translated">命名实体识别</li><li id="51ef" class="lz ma iq lc b ld mi lg mj lj mk ln ml lr mm lv me mf mg mh bi translated">语音识别</li><li id="43ec" class="lz ma iq lc b ld mi lg mj lj mk ln ml lr mm lv me mf mg mh bi translated">文本分类</li><li id="65b7" class="lz ma iq lc b ld mi lg mj lj mk ln ml lr mm lv me mf mg mh bi translated">词义消歧</li></ul><p id="969f" class="pw-post-body-paragraph la lb iq lc b ld le ka lf lg lh kd li lj lk ll lm ln lo lp lq lr ls lt lu lv ij bi translated">诚然，这些术语都相当枯燥乏味...但是背后隐藏着很多令人兴奋的可能性！自己看:</p><figure class="kp kq kr ks gt kt"><div class="bz fp l di"><div class="mn mo l"/></div><figcaption class="mp mq gj gh gi mr ms bd b be z dk translated">谷歌双工:人工智能助理打电话给当地企业预约</figcaption></figure><blockquote class="mt"><p id="115f" class="mu mv iq bd mw mx my mz na nb nc lv dk translated">预约周二上午10点到12点之间的任何时间理发。</p></blockquote><p id="441b" class="pw-post-body-paragraph la lb iq lc b ld nd ka lf lg ne kd li lj nf ll lm ln ng lp lq lr nh lt lu lv ij bi translated">机器如何将这种声音翻译成它能理解并采取行动的东西？</p><p id="2751" class="pw-post-body-paragraph la lb iq lc b ld le ka lf lg lh kd li lj lk ll lm ln lo lp lq lr ls lt lu lv ij bi translated">还有，它如何解释上下文？</p><p id="063d" class="pw-post-body-paragraph la lb iq lc b ld le ka lf lg lh kd li lj lk ll lm ln lo lp lq lr ls lt lu lv ij bi translated">为了帮助你回答这些问题，本文简要定义了围绕<strong class="lc ja"> <em class="lw">语言</em> </strong>的核心概念和术语。</p></div><div class="ab cl ni nj hu nk" role="separator"><span class="nl bw bk nm nn no"/><span class="nl bw bk nm nn no"/><span class="nl bw bk nm nn"/></div><div class="ij ik il im in"><h1 id="0411" class="np nq iq bd nr ns nt nu nv nw nx ny nz kf oa kg ob ki oc kj od kl oe km of og bi translated">语言</h1><p id="ee2b" class="pw-post-body-paragraph la lb iq lc b ld oh ka lf lg oi kd li lj oj ll lm ln ok lp lq lr ol lt lu lv ij bi translated"><strong class="lc ja">自然语言处理:</strong>(或NLP)人工智能的一个主要领域，通过允许计算机阅读、理解和从语言中获取意义来处理人类和计算机之间的交互</p><p id="163d" class="pw-post-body-paragraph la lb iq lc b ld le ka lf lg lh kd li lj lk ll lm ln lo lp lq lr ls lt lu lv ij bi translated">语法:在一种语言中，为创造结构良好的句子而对单词和短语进行的排列</p><p id="f3f0" class="pw-post-body-paragraph la lb iq lc b ld le ka lf lg lh kd li lj lk ll lm ln lo lp lq lr ls lt lu lv ij bi translated">语义:单词、短语或文本的意思</p><p id="50c9" class="pw-post-body-paragraph la lb iq lc b ld le ka lf lg lh kd li lj lk ll lm ln lo lp lq lr ls lt lu lv ij bi translated"><strong class="lc ja">形式语法:</strong>一种语言中生成句子的规则系统</p><p id="4d98" class="pw-post-body-paragraph la lb iq lc b ld le ka lf lg lh kd li lj lk ll lm ln lo lp lq lr ls lt lu lv ij bi translated"><strong class="lc ja">上下文无关语法:</strong>一组有限的递归语法规则，例如:</p><pre class="kp kq kr ks gt om on oo op aw oq bi"><span id="f568" class="or nq iq on b gy os ot l ou ov">N → he | Anthony | computer | ... <br/>D → the | a | an | ...<br/>V → took | helped | searched | ...<br/>P → to | on | over | ...<br/>ADJ → blue | busy | old | ...</span><span id="5ad9" class="or nq iq on b gy ow ot l ou ov"><br/>N        V        D       N<br/>|        |        |       |<br/>he   searched    the   computer</span><span id="664e" class="or nq iq on b gy ow ot l ou ov"><br/>NP -&gt; N | DN</span><span id="6191" class="or nq iq on b gy ow ot l ou ov">          NP<br/>         /  \<br/>        D    N<br/>        |    |<br/>       the computer</span></pre><p id="7e22" class="pw-post-body-paragraph la lb iq lc b ld le ka lf lg lh kd li lj lk ll lm ln lo lp lq lr ls lt lu lv ij bi translated"><strong class="lc ja"> N-gram: </strong>来自文本样本的N个项目的连续序列</p><p id="b098" class="pw-post-body-paragraph la lb iq lc b ld le ka lf lg lh kd li lj lk ll lm ln lo lp lq lr ls lt lu lv ij bi translated"><strong class="lc ja">字符n元语法:</strong>来自文本样本的n个字符的连续序列</p><p id="8803" class="pw-post-body-paragraph la lb iq lc b ld le ka lf lg lh kd li lj lk ll lm ln lo lp lq lr ls lt lu lv ij bi translated"><strong class="lc ja">单词n元语法:</strong>来自文本样本的n个单词的连续序列</p><p id="6741" class="pw-post-body-paragraph la lb iq lc b ld le ka lf lg lh kd li lj lk ll lm ln lo lp lq lr ls lt lu lv ij bi translated"><strong class="lc ja"> Unigram: </strong>一个文本样本中的<em class="lw"> 1 </em>项的连续序列</p><p id="6c22" class="pw-post-body-paragraph la lb iq lc b ld le ka lf lg lh kd li lj lk ll lm ln lo lp lq lr ls lt lu lv ij bi translated"><strong class="lc ja">二元模型:</strong>来自文本样本的两个项目的连续序列</p><p id="fec1" class="pw-post-body-paragraph la lb iq lc b ld le ka lf lg lh kd li lj lk ll lm ln lo lp lq lr ls lt lu lv ij bi translated"><strong class="lc ja">三元模型:</strong>一个文本样本中3个项目的连续序列</p><pre class="kp kq kr ks gt om on oo op aw oq bi"><span id="d006" class="or nq iq on b gy os ot l ou ov"><strong class="on ja">The bolded words</strong> are one of the possible trigrams in this sentence.<br/>The <strong class="on ja">bolded words are</strong> one of the possible trigrams in this sentence.<br/>The bolded <strong class="on ja">words are one</strong> of the possible trigrams in this sentence.<br/>The bolded words <strong class="on ja">are one of</strong> the possible trigrams in this sentence.<br/>The bolded words are <strong class="on ja">one of the</strong> possible trigrams in this sentence.<br/>The bolded words are one <strong class="on ja">of the possible</strong> trigrams in this sentence.<br/>The bolded words are one of <strong class="on ja">the possible trigrams</strong> in this sentence.<br/>The bolded words are one of the possible <strong class="on ja">trigrams in this</strong> sentence.<br/>The bolded words are one of the possible trigrams <strong class="on ja">in this sentence.</strong></span></pre><p id="b3b4" class="pw-post-body-paragraph la lb iq lc b ld le ka lf lg lh kd li lj lk ll lm ln lo lp lq lr ls lt lu lv ij bi translated"><strong class="lc ja">记号化:</strong>将一个字符序列分割成多个片段(记号)的任务</p><pre class="kp kq kr ks gt om on oo op aw oq bi"><span id="1b87" class="or nq iq on b gy os ot l ou ov">"This is a sample sentence, for tokenization."</span><span id="64eb" class="or nq iq on b gy ow ot l ou ov">["This", "is", "a", "sample", "sentence,", "for", "tokenization."]</span></pre><p id="4d82" class="pw-post-body-paragraph la lb iq lc b ld le ka lf lg lh kd li lj lk ll lm ln lo lp lq lr ls lt lu lv ij bi translated"><strong class="lc ja">单词标记化:</strong>将一系列字符拆分成单词的任务</p><p id="540e" class="pw-post-body-paragraph la lb iq lc b ld le ka lf lg lh kd li lj lk ll lm ln lo lp lq lr ls lt lu lv ij bi translated"><strong class="lc ja">句子标记化:</strong>将一系列字符拆分成句子的任务</p><p id="a320" class="pw-post-body-paragraph la lb iq lc b ld le ka lf lg lh kd li lj lk ll lm ln lo lp lq lr ls lt lu lv ij bi translated"><strong class="lc ja">马尔可夫模型:</strong>用于模拟随机变化系统的随机模型</p><p id="1034" class="pw-post-body-paragraph la lb iq lc b ld le ka lf lg lh kd li lj lk ll lm ln lo lp lq lr ls lt lu lv ij bi translated"><strong class="lc ja">马尔可夫链</strong>:描述一系列可能事件的随机模型，其中每个事件的概率只取决于前一个事件达到的状态</p><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div role="button" tabindex="0" class="ku kv di kw bf kx"><div class="gh gi ox"><img src="../Images/4acc2046b2bc4d41e75a81124cfe83e1.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Rqq7dHvb79Evv6heSE-Fsg.png"/></div></div><figcaption class="mp mq gj gh gi mr ms bd b be z dk translated">马尔可夫链</figcaption></figure><p id="bbb6" class="pw-post-body-paragraph la lb iq lc b ld le ka lf lg lh kd li lj lk ll lm ln lo lp lq lr ls lt lu lv ij bi translated"><strong class="lc ja">文本分类:</strong>(或文本标记)将文本分类到有组织的组或类别中的任务</p><pre class="kp kq kr ks gt om on oo op aw oq bi"><span id="3d75" class="or nq iq on b gy os ot l ou ov">"I <strong class="on ja">love</strong> to eat ice cream. Gianlugigi makes the <strong class="on ja">best</strong> ice cream!"<br/>P(Positive | "<strong class="on ja">love</strong>", "<strong class="on ja">best</strong>")</span><span id="2427" class="or nq iq on b gy ow ot l ou ov">"This ice cream was <strong class="on ja">terrible</strong>. It was <strong class="on ja">not as good</strong> as I thought!"<br/>P(Negative | "<strong class="on ja">terrible</strong>", "<strong class="on ja">not as good</strong>")</span></pre><p id="f0b7" class="pw-post-body-paragraph la lb iq lc b ld le ka lf lg lh kd li lj lk ll lm ln lo lp lq lr ls lt lu lv ij bi translated"><strong class="lc ja">贝叶斯法则:</strong>(或称贝叶斯定理)<strong class="lc ja"> </strong>一个确定条件概率的实用数学公式:</p><pre class="kp kq kr ks gt om on oo op aw oq bi"><span id="b52c" class="or nq iq on b gy os ot l ou ov">P(b|a) = [ P(a|b) P(b) ] / P(a)</span><span id="d218" class="or nq iq on b gy ow ot l ou ov">P(Positive) = <br/>number of positive samples / number of total samples</span><span id="3c3d" class="or nq iq on b gy ow ot l ou ov">P("<strong class="on ja">love</strong>"| Positive) = <br/>number of positive samples with "<strong class="on ja">love</strong>" / number of positive samples</span></pre><p id="95f1" class="pw-post-body-paragraph la lb iq lc b ld le ka lf lg lh kd li lj lk ll lm ln lo lp lq lr ls lt lu lv ij bi translated"><strong class="lc ja">朴素贝叶斯:</strong>利用贝叶斯规则对对象进行分类的算法(例如垃圾邮件过滤器)</p><p id="14a1" class="pw-post-body-paragraph la lb iq lc b ld le ka lf lg lh kd li lj lk ll lm ln lo lp lq lr ls lt lu lv ij bi translated"><strong class="lc ja">加法平滑:(或拉普拉斯平滑)</strong>一种统计技术，通过将一个值<em class="lw"> α </em>(例如1)添加到分布中的每个值(假装你看到每个值的次数比实际多1次)来平滑分类数据</p><p id="3104" class="pw-post-body-paragraph la lb iq lc b ld le ka lf lg lh kd li lj lk ll lm ln lo lp lq lr ls lt lu lv ij bi translated"><strong class="lc ja">信息检索:</strong>响应用户查询找到相关文档的任务</p><p id="1d72" class="pw-post-body-paragraph la lb iq lc b ld le ka lf lg lh kd li lj lk ll lm ln lo lp lq lr ls lt lu lv ij bi translated"><strong class="lc ja">主题建模:</strong>为一组文档发现主题的模型</p><p id="0ebb" class="pw-post-body-paragraph la lb iq lc b ld le ka lf lg lh kd li lj lk ll lm ln lo lp lq lr ls lt lu lv ij bi translated"><strong class="lc ja">术语频率:</strong>术语在文档中出现的次数</p><p id="b09a" class="pw-post-body-paragraph la lb iq lc b ld le ka lf lg lh kd li lj lk ll lm ln lo lp lq lr ls lt lu lv ij bi translated"><strong class="lc ja">虚词:</strong>本身意义不大，但用来语法连接其他词的词，例如，</p><pre class="kp kq kr ks gt om on oo op aw oq bi"><span id="2c7c" class="or nq iq on b gy os ot l ou ov"><em class="lw">am, by, do, is, which, with, yet, …</em></span></pre><p id="2b92" class="pw-post-body-paragraph la lb iq lc b ld le ka lf lg lh kd li lj lk ll lm ln lo lp lq lr ls lt lu lv ij bi translated"><strong class="lc ja">实词:</strong>独立承载意义的词，例如:</p><pre class="kp kq kr ks gt om on oo op aw oq bi"><span id="fa71" class="or nq iq on b gy os ot l ou ov"><em class="lw">win, type, computer, …</em></span></pre><p id="d863" class="pw-post-body-paragraph la lb iq lc b ld le ka lf lg lh kd li lj lk ll lm ln lo lp lq lr ls lt lu lv ij bi translated"><strong class="lc ja">逆文档频率:</strong>衡量一个单词在文档中的常见或罕见程度</p><pre class="kp kq kr ks gt om on oo op aw oq bi"><span id="7294" class="or nq iq on b gy os ot l ou ov">log(total documents / number of Documents containing word x)</span></pre><p id="f779" class="pw-post-body-paragraph la lb iq lc b ld le ka lf lg lh kd li lj lk ll lm ln lo lp lq lr ls lt lu lv ij bi translated"><strong class="lc ja"> Tf-idf: </strong>通过将<em class="lw">词频</em> ( <em class="lw"> TF </em>)乘以<em class="lw">逆文档频率</em> ( <em class="lw"> IDF </em>)对文档中哪些词是重要的进行排序</p><pre class="kp kq kr ks gt om on oo op aw oq bi"><span id="a347" class="or nq iq on b gy os ot l ou ov">td-idf = term frequency * (inverse document frequency)</span></pre><p id="2ad7" class="pw-post-body-paragraph la lb iq lc b ld le ka lf lg lh kd li lj lk ll lm ln lo lp lq lr ls lt lu lv ij bi translated"><strong class="lc ja">信息提取:</strong>从文档中提取知识的任务</p><p id="1133" class="pw-post-body-paragraph la lb iq lc b ld le ka lf lg lh kd li lj lk ll lm ln lo lp lq lr ls lt lu lv ij bi translated">单词间语义关系的词汇数据库</p><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div role="button" tabindex="0" class="ku kv di kw bf kx"><div class="gh gi oy"><img src="../Images/c31defac541b2a481a2047f4431da21f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*6GEhh6mZdpY35QGacFa-4Q.png"/></div></div><figcaption class="mp mq gj gh gi mr ms bd b be z dk translated">Wordnet</figcaption></figure><p id="d86c" class="pw-post-body-paragraph la lb iq lc b ld le ka lf lg lh kd li lj lk ll lm ln lo lp lq lr ls lt lu lv ij bi translated"><strong class="lc ja">单词表示:</strong>将单词表示为特征因子的过程，其中向量条目代表单词含义的隐藏特征</p><p id="d901" class="pw-post-body-paragraph la lb iq lc b ld le ka lf lg lh kd li lj lk ll lm ln lo lp lq lr ls lt lu lv ij bi translated"><em class="lw">【务必查看</em> <a class="oz pa ep" href="https://medium.com/u/84da7a70e49d?source=post_page-----1d266caa72c6--------------------------------" rel="noopener" target="_blank"> <em class="lw">努尔扎特·拉赫曼别迪耶娃</em> </a> <em class="lw">的</em> <a class="ae lx" href="https://towardsdatascience.com/word-representation-in-natural-language-processing-part-i-e4cd54fed3d4" rel="noopener" target="_blank"> <em class="lw">关于文字表述的演练</em></a><em class="lw">…】</em></p><p id="ea6d" class="pw-post-body-paragraph la lb iq lc b ld le ka lf lg lh kd li lj lk ll lm ln lo lp lq lr ls lt lu lv ij bi translated"><strong class="lc ja">一键表示:</strong>用单个<em class="lw"> 1 </em>表示向量的含义，其他值为<em class="lw"> 0 </em></p><pre class="kp kq kr ks gt om on oo op aw oq bi"><span id="71d5" class="or nq iq on b gy os ot l ou ov">king  [1,0,0,...,0]<br/>man   [0,1,0,...,0]<br/>woman [0,1,1,...,0]<br/>queen ?</span></pre><p id="3fc6" class="pw-post-body-paragraph la lb iq lc b ld le ka lf lg lh kd li lj lk ll lm ln lo lp lq lr ls lt lu lv ij bi translated"><strong class="lc ja">分布表示:</strong>跨多个值分布的含义表示</p><pre class="kp kq kr ks gt om on oo op aw oq bi"><span id="8f3c" class="or nq iq on b gy os ot l ou ov">king  [-0.55, -0.65, 0.25, ..., 0.12]<br/>man   [-0.12, -0.44, 0.25, ..., 0.12]<br/>woman [-0.12, -0.44, 0.75, ..., 0.12]</span><span id="fe6c" class="or nq iq on b gy ow ot l ou ov">queen ?</span></pre><p id="1b8c" class="pw-post-body-paragraph la lb iq lc b ld le ka lf lg lh kd li lj lk ll lm ln lo lp lq lr ls lt lu lv ij bi translated"><strong class="lc ja"> Word2vec: </strong>生成单词向量的流行模型</p><p id="8022" class="pw-post-body-paragraph la lb iq lc b ld le ka lf lg lh kd li lj lk ll lm ln lo lp lq lr ls lt lu lv ij bi translated"><strong class="lc ja">跳过语法结构:</strong>神经网络结构，用于在给定目标单词的情况下预测上下文单词</p><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div role="button" tabindex="0" class="ku kv di kw bf kx"><div class="gh gi pb"><img src="../Images/582695a1e9acd65cf952fb2427f42d93.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*gTg40BItEJFfWsiePRBJhw.png"/></div></div><figcaption class="mp mq gj gh gi mr ms bd b be z dk translated">跳过程序体系结构</figcaption></figure></div><div class="ab cl ni nj hu nk" role="separator"><span class="nl bw bk nm nn no"/><span class="nl bw bk nm nn no"/><span class="nl bw bk nm nn"/></div><div class="ij ik il im in"><p id="fa2b" class="pw-post-body-paragraph la lb iq lc b ld le ka lf lg lh kd li lj lk ll lm ln lo lp lq lr ls lt lu lv ij bi translated">无论你看亚马逊、阿里巴巴、苹果、百度、谷歌、微软还是小米，大科技都在抓住个人数字助理的机会，相信它们将推动商业、分析和CRM的未来。</p><p id="8cca" class="pw-post-body-paragraph la lb iq lc b ld le ka lf lg lh kd li lj lk ll lm ln lo lp lq lr ls lt lu lv ij bi translated">没有一个数字助理是或声称是防弹的。相反，它们经常让我们感到沮丧，带着无法实现的期望离开。例如，<a class="ae lx" href="https://hbr.org/2019/05/voice-recognition-still-has-significant-race-and-gender-biases" rel="noopener ugc nofollow" target="_blank">语音识别中有偏见的数据集</a>只是众多障碍中的一个。</p><p id="dfd8" class="pw-post-body-paragraph la lb iq lc b ld le ka lf lg lh kd li lj lk ll lm ln lo lp lq lr ls lt lu lv ij bi translated">然而，语言领域正在飞速发展，这表明我们能够直观地与机器交流只是时间问题。</p><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div role="button" tabindex="0" class="ku kv di kw bf kx"><div class="gh gi ly"><img src="../Images/292b8dfe40e702f4f0437b48bc55594f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*7c4R1yVzjdKf4Kj-2KRKIg.png"/></div></div></figure><p id="a55e" class="pw-post-body-paragraph la lb iq lc b ld le ka lf lg lh kd li lj lk ll lm ln lo lp lq lr ls lt lu lv ij bi translated">探讨类似的AI相关话题，包括<a class="ae lx" href="https://medium.com/towards-artificial-intelligence/ai-search-e0cb610237f6" rel="noopener"> <em class="lw">搜索</em></a><a class="ae lx" href="https://medium.com/towards-artificial-intelligence/ai-knowledge-1020a00eb45d" rel="noopener"><em class="lw">知识</em></a><a class="ae lx" href="https://medium.com/towards-artificial-intelligence/ai-uncertainty-4ac6810899ac" rel="noopener"><em class="lw">不确定性</em></a><em class="lw"/><a class="ae lx" href="https://medium.com/towards-artificial-intelligence/ai-optimization-b8735dc09448" rel="noopener"><em class="lw">优化</em></a><a class="ae lx" href="https://medium.com/towards-artificial-intelligence/ai-learning-2eaea82ee6d" rel="noopener"><em class="lw">机器学习</em> </a> <em class="lw">，以及</em> <a class="ae lx" href="https://medium.com/towards-artificial-intelligence/26-words-about-neural-networks-every-ai-neural-networks-1085bd972fd5" rel="noopener"> <em class="lw">神经网络</em> </a>。</p><p id="ffde" class="pw-post-body-paragraph la lb iq lc b ld le ka lf lg lh kd li lj lk ll lm ln lo lp lq lr ls lt lu lv ij bi translated"><strong class="lc ja"> <em class="lw">喜欢读什么？</em> </strong> <em class="lw"> </em> <strong class="lc ja"> <em class="lw">渴望了解更多？</em> </strong> <em class="lw"> <br/>跟我上</em> <a class="ae lx" href="https://medium.com/@yannique" rel="noopener"> <em class="lw">中</em> </a> <em class="lw">或</em><a class="ae lx" href="https://www.linkedin.com/in/yannique/" rel="noopener ugc nofollow" target="_blank"><em class="lw">LinkedIn</em></a><em class="lw">。</em></p></div><div class="ab cl ni nj hu nk" role="separator"><span class="nl bw bk nm nn no"/><span class="nl bw bk nm nn no"/><span class="nl bw bk nm nn"/></div><div class="ij ik il im in"><p id="ce81" class="pw-post-body-paragraph la lb iq lc b ld le ka lf lg lh kd li lj lk ll lm ln lo lp lq lr ls lt lu lv ij bi translated"><strong class="lc ja"> <em class="lw">关于作者:<br/> </em> </strong> Yannique Hecht作品在结合策略、客户洞察、数据、创新等领域。虽然他的职业生涯一直在航空、旅游、金融和技术行业，但他对管理充满热情。Yannique专门开发AI &amp;机器学习产品商业化的策略。</p></div></div>    
</body>
</html>