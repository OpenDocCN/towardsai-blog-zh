<html>
<head>
<title>Support Vector Machine (SVM): A Simple Visual Explanation — Part 1</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">支持向量机(SVM):一个简单的直观解释——第一部分</h1>
<blockquote>原文：<a href="https://pub.towardsai.net/support-vector-machine-svm-a-visual-simple-explanation-part-1-a7efa96444f2?source=collection_archive---------1-----------------------#2019-05-08">https://pub.towardsai.net/support-vector-machine-svm-a-visual-simple-explanation-part-1-a7efa96444f2?source=collection_archive---------1-----------------------#2019-05-08</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><h2 id="62fa" class="ir is it bd b dl iu iv iw ix iy iz dk ja translated" aria-label="kicker paragraph"><a class="ae ep" href="https://towardsai.net/p/category/machine-learning" rel="noopener ugc nofollow" target="_blank">机器学习</a></h2><div class=""/><figure class="gl gn ka kb kc kd gh gi paragraph-image"><div role="button" tabindex="0" class="ke kf di kg bf kh"><div class="gh gi jz"><img src="../Images/1c94a24793acf0bdf85bec36031005c8.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*7XMDkXvCvSC-3Xsq.jpg"/></div></div></figure><h1 id="beb9" class="kk kl it bd km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh bi translated">什么是SVM？</h1><blockquote class="li lj lk"><p id="ab31" class="ll lm ln lo b lp lq lr ls lt lu lv lw lx ly lz ma mb mc md me mf mg mh mi mj im bi translated">SVM是一种使用超平面分离数据的监督分类方法。</p></blockquote><figure class="ml mm mn mo gt kd gh gi paragraph-image"><div class="gh gi mk"><img src="../Images/58b62564a57cb4a3508468858600fffc.png" data-original-src="https://miro.medium.com/v2/resize:fit:1204/format:webp/1*88ZAzSYiMAHevxwqE5STuw.png"/></div></figure><p id="5d3c" class="pw-post-body-paragraph ll lm it lo b lp lq lr ls lt lu lv lw mp ly lz ma mq mc md me mr mg mh mi mj im bi translated">SVM是一种受监督的机器学习算法，它将示例表示为空间中的点，通过映射，各个类别的示例被尽可能宽的清晰间隙分隔开。然后，新的例子被映射到相同的空间，并根据它们落在差距的哪一边来预测属于哪个类别。</p><blockquote class="li lj lk"><p id="2975" class="ll lm ln lo b lp lq lr ls lt lu lv lw lx ly lz ma mb mc md me mf mg mh mi mj im bi translated">除了执行线性分类，SVM还可以使用所谓的<strong class="lo jd">内核技巧</strong>有效地执行非线性分类，将输入隐式映射到高维特征空间。(非线性数据基本上不能用直线分开)</p></blockquote><h1 id="3f11" class="kk kl it bd km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh bi translated"><strong class="ak">SVM是如何工作的？</strong></h1><p id="accf" class="pw-post-body-paragraph ll lm it lo b lp ms lr ls lt mt lv lw mp mu lz ma mq mv md me mr mw mh mi mj im bi translated">为了理解它是如何工作的，让我们考虑一个兔子和老虎的例子(两个数据点仅用于直观解释)。现在让我们考虑一个小场景，假设你拥有一个农场。比方说，你有一个问题，想建立一个围栏来保护你的兔子免受老虎的攻击。</p><figure class="ml mm mn mo gt kd gh gi paragraph-image"><div class="gh gi mx"><img src="../Images/96171131465690da7a6a1313f4600b40.png" data-original-src="https://miro.medium.com/v2/resize:fit:852/format:webp/1*TJy9Zw9VtASpm3OkbcyPdg.png"/></div></figure><p id="49e3" class="pw-post-body-paragraph ll lm it lo b lp lq lr ls lt lu lv lw mp ly lz ma mq mc md me mr mg mh mi mj im bi translated">但是，你在哪里建造围栏呢？</p><p id="14dd" class="pw-post-body-paragraph ll lm it lo b lp lq lr ls lt lu lv lw mp ly lz ma mq mc md me mr mg mh mi mj im bi translated">解决这个问题的一个方法是根据兔子和老虎的位置建立一个分类器。你可以把兔子归为一类，把老虎归为另一类</p><p id="7446" class="pw-post-body-paragraph ll lm it lo b lp lq lr ls lt lu lv lw mp ly lz ma mq mc md me mr mg mh mi mj im bi translated">现在，如果我试图在兔子和老虎之间画一条分界线，它看起来像一条直线(请参考下图)，现在你可以清楚地沿着这条线建一个围栏。这正是SVM的工作方式，它在任何两个类之间画出一个决策边界，这是一个超平面，以便将它们分开或分类。</p><figure class="ml mm mn mo gt kd gh gi paragraph-image"><div class="gh gi my"><img src="../Images/84d2ad1715ef2323a46f7a320ed75d17.png" data-original-src="https://miro.medium.com/v2/resize:fit:772/format:webp/1*3jC3tDFZ-Z7JtrM6iBljWg.png"/></div></figure><p id="f76e" class="pw-post-body-paragraph ll lm it lo b lp lq lr ls lt lu lv lw mp ly lz ma mq mc md me mr mg mh mi mj im bi translated"><strong class="lo jd">但是，你怎么知道在哪里画超平面呢？</strong></p><p id="f6f5" class="pw-post-body-paragraph ll lm it lo b lp lq lr ls lt lu lv lw mp ly lz ma mq mc md me mr mg mh mi mj im bi translated">SVM背后的基本原理是绘制一个超平面，该超平面最好地分离这两个类，在我们的例子中，这两个类是兔子和老虎，所以你从绘制一个随机超平面开始，然后你检查超平面和每个类的最近数据点之间的距离。</p><figure class="ml mm mn mo gt kd gh gi paragraph-image"><div role="button" tabindex="0" class="ke kf di kg bf kh"><div class="gh gi mz"><img src="../Images/4174278c3858fd2baba63d8c2c86b90a.png" data-original-src="https://miro.medium.com/v2/resize:fit:868/format:webp/1*B9tREeJxZE29M-7TdMbXKA.png"/></div></div></figure><p id="3fb6" class="pw-post-body-paragraph ll lm it lo b lp lq lr ls lt lu lv lw mp ly lz ma mq mc md me mr mg mh mi mj im bi translated">这些最接近超平面的数据点被称为支持向量，这就是支持向量机名称的由来，所以基本上，超平面是基于这些支持向量绘制的。通常，与支持向量具有最大距离的超平面是最佳超平面，并且超平面和支持向量之间的距离被称为边缘。</p><figure class="ml mm mn mo gt kd gh gi paragraph-image"><div class="gh gi na"><img src="../Images/745acdddde979914de1072c1c7a2787b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1020/format:webp/1*QNhJyNy34bjGCl_M_MJNRQ.png"/></div></figure><p id="8dd2" class="pw-post-body-paragraph ll lm it lo b lp lq lr ls lt lu lv lw mp ly lz ma mq mc md me mr mg mh mi mj im bi translated">假设我们添加了一个新的数据点(又添加了一个tiger ),现在我想画一个超平面来以最佳方式分隔这两个类。因此，我首先绘制一个超平面，如上图所示，然后检查超平面和支持向量之间的距离，并尝试检查该超平面的边距是否最大。在这种情况下，利润较少。</p><p id="34a1" class="pw-post-body-paragraph ll lm it lo b lp lq lr ls lt lu lv lw mp ly lz ma mq mc md me mr mg mh mi mj im bi translated">在第二个场景中，我绘制了一个不同的超平面，如下图所示，然后检查超平面和支持向量之间的距离，并尝试检查该超平面的边距是否最大。这种情况下利润很高。</p><figure class="ml mm mn mo gt kd gh gi paragraph-image"><div class="gh gi nb"><img src="../Images/1aae0347614ac18e6f9a29b46d169059.png" data-original-src="https://miro.medium.com/v2/resize:fit:964/format:webp/1*NoPrPKdtkrdEFKUj99gQSg.png"/></div></figure><p id="d632" class="pw-post-body-paragraph ll lm it lo b lp lq lr ls lt lu lv lw mp ly lz ma mq mc md me mr mg mh mi mj im bi translated">与前一个超平面相比，这个超平面的余量很高。因此，我选择这个超平面，作为一个经验法则，支持向量和超平面之间的距离(边距)应该是最大的。这就是我们如何选择超平面。</p><p id="b5e1" class="pw-post-body-paragraph ll lm it lo b lp lq lr ls lt lu lv lw mp ly lz ma mq mc md me mr mg mh mi mj im bi translated">到目前为止，我们的数据是线性可分的，这意味着你可以画一条直线来区分这两个类。如果我们有如下数据点，我们能做什么？我们不能画一个超平面，因为它根本没有把两个类分开。</p><figure class="ml mm mn mo gt kd gh gi paragraph-image"><div class="gh gi nc"><img src="../Images/ca958947b702c47ecd6133eb446bf2e4.png" data-original-src="https://miro.medium.com/v2/resize:fit:1028/format:webp/1*vI-Se_jQGuUH0EvJxBo-Ug.png"/></div><figcaption class="nd ne gj gh gi nf ng bd b be z dk translated">非线性数据点</figcaption></figure><h1 id="22a1" class="kk kl it bd km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh bi translated">非线性SVM简介</h1><blockquote class="li lj lk"><p id="dd1c" class="ll lm ln lo b lp lq lr ls lt lu lv lw lx ly lz ma mb mc md me mf mg mh mi mj im bi translated">当数据不能用直线分离时，使用非线性SVM。</p></blockquote><p id="13fc" class="pw-post-body-paragraph ll lm it lo b lp lq lr ls lt lu lv lw mp ly lz ma mq mc md me mr mg mh mi mj im bi translated">在这种情况下，我们使用核函数来帮助将数据转换到另一个维度，在两个类之间有一个清晰的分界。核函数有助于将非线性空间转换成线性空间。</p><figure class="ml mm mn mo gt kd gh gi paragraph-image"><div class="gh gi nh"><img src="../Images/a245cee8aef62f490fcd09d75380caf7.png" data-original-src="https://miro.medium.com/v2/resize:fit:884/format:webp/1*VSjYaSemRh0acjAr262HaA.png"/></div></figure><p id="1866" class="pw-post-body-paragraph ll lm it lo b lp lq lr ls lt lu lv lw mp ly lz ma mq mc md me mr mg mh mi mj im bi translated">它将两个变量x和y转换到一个新的特征空间，其中包含一个名为z的新变量。到目前为止，我们正在二维空间上绘制数据。现在，我们基本上是在三维空间里做的。在3D空间中，我们可以清楚地看到这两个类之间的分界，我们可以通过绘制它们之间的最佳超平面来区分这两个类。</p><h1 id="15c5" class="kk kl it bd km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh bi translated">SVM的调谐参数</h1><p id="15af" class="pw-post-body-paragraph ll lm it lo b lp ms lr ls lt mt lv lw mp mu lz ma mq mv md me mr mw mh mi mj im bi translated">调整机器学习算法的参数值有效地提高了模型性能。让我们看看SVM可用的参数列表。让我们举一个小例子，</p><figure class="ml mm mn mo gt kd gh gi paragraph-image"><div class="gh gi mk"><img src="../Images/3ce67e259b1e6a4280338a4c82061a24.png" data-original-src="https://miro.medium.com/v2/resize:fit:1204/format:webp/1*de8tJjSW67PrJWl528Ij-Q.png"/></div></figure><p id="7eaa" class="pw-post-body-paragraph ll lm it lo b lp lq lr ls lt lu lv lw mp ly lz ma mq mc md me mr mg mh mi mj im bi translated">考虑到帖子的长度，我没有展示代码。详细的例子和编码将会包含在我的下一篇博客中。</p><figure class="ml mm mn mo gt kd gh gi paragraph-image"><div role="button" tabindex="0" class="ke kf di kg bf kh"><div class="gh gi ni"><img src="../Images/1edb139a0915ae58a5c7af429885c51f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*H5HM-DdFB6uy1kwXHLDhSg.png"/></div></div></figure><figure class="ml mm mn mo gt kd gh gi paragraph-image"><div role="button" tabindex="0" class="ke kf di kg bf kh"><div class="gh gi nj"><img src="../Images/e887d41ea0b0735de2af1f84f2ce3f61.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Nt909vWzudzglbxlTItZOA.png"/></div></div></figure><p id="4d54" class="pw-post-body-paragraph ll lm it lo b lp lq lr ls lt lu lv lw mp ly lz ma mq mc md me mr mg mh mi mj im bi translated">c-它是正则化参数。它允许你决定多少你想要惩罚错误分类的点。</p><p id="429d" class="pw-post-body-paragraph ll lm it lo b lp lq lr ls lt lu lv lw mp ly lz ma mq mc md me mr mg mh mi mj im bi translated">内核—它指定要使用的内核类型。有不同的核选项，如线性、径向基函数(RBF)、多项式和sigmoid。这里“rbf”和“poly”对于非线性超平面是有用的。</p><p id="67a9" class="pw-post-body-paragraph ll lm it lo b lp lq lr ls lt lu lv lw mp ly lz ma mq mc md me mr mg mh mi mj im bi translated">Gamma —它是“rbf”、“poly”和“sigmoid”的核心系数。较小的灰度系数复杂度较低，较大的灰度系数复杂度较高。</p><h1 id="ad29" class="kk kl it bd km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh bi translated">利弊——SVM</h1><p id="f3bb" class="pw-post-body-paragraph ll lm it lo b lp ms lr ls lt mt lv lw mp mu lz ma mq mv md me mr mw mh mi mj im bi translated"><strong class="lo jd">优点:</strong></p><ul class=""><li id="4ec0" class="nk nl it lo b lp lq lt lu mp nm mq nn mr no mj np nq nr ns bi translated">它对线性可分(硬边界)和非线性可分(软边界)数据都有用。</li><li id="ea6e" class="nk nl it lo b lp nt lt nu mp nv mq nw mr nx mj np nq nr ns bi translated">在高维空间是有效的。</li><li id="907c" class="nk nl it lo b lp nt lt nu mp nv mq nw mr nx mj np nq nr ns bi translated">这在维数大于样本数的情况下是有效的。</li><li id="e753" class="nk nl it lo b lp nt lt nu mp nv mq nw mr nx mj np nq nr ns bi translated">它在决策函数中使用训练点的子集(称为支持向量)，因此它也是内存高效的。</li></ul><p id="eb92" class="pw-post-body-paragraph ll lm it lo b lp lq lr ls lt lu lv lw mp ly lz ma mq mc md me mr mg mh mi mj im bi translated"><strong class="lo jd">缺点:</strong></p><ul class=""><li id="0738" class="nk nl it lo b lp lq lt lu mp nm mq nn mr no mj np nq nr ns bi translated">选择正确的内核和参数需要大量的计算。</li><li id="441e" class="nk nl it lo b lp nt lt nu mp nv mq nw mr nx mj np nq nr ns bi translated">当数据集有更多噪声时，即目标类重叠时，它的性能也不是很好</li><li id="51f0" class="nk nl it lo b lp nt lt nu mp nv mq nw mr nx mj np nq nr ns bi translated">SVM没有直接提供概率估计，这些是通过昂贵的五重交叉验证计算出来的。</li></ul><p id="8772" class="pw-post-body-paragraph ll lm it lo b lp lq lr ls lt lu lv lw mp ly lz ma mq mc md me mr mg mh mi mj im bi translated">这是一个简单的SVM视觉介绍。希望这将作为理解支持向量机的一个好的起点。在下一篇文章中，我将通过一个案例研究展示如何在SAS Enterprise Miner中实现SVM。</p><p id="1566" class="pw-post-body-paragraph ll lm it lo b lp lq lr ls lt lu lv lw mp ly lz ma mq mc md me mr mg mh mi mj im bi translated">请继续学习，并关注更多内容！</p></div></div>    
</body>
</html>