<html>
<head>
<title>State of the Art Models in Every Machine Learning Field 2021</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">2021年每个机器学习领域的最先进模型</h1>
<blockquote>原文：<a href="https://pub.towardsai.net/state-of-the-art-models-in-every-machine-learning-field-2021-c7cf074da8b2?source=collection_archive---------0-----------------------#2021-04-12">https://pub.towardsai.net/state-of-the-art-models-in-every-machine-learning-field-2021-c7cf074da8b2?source=collection_archive---------0-----------------------#2021-04-12</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><h2 id="c6f6" class="ir is it bd b dl iu iv iw ix iy iz dk ja translated" aria-label="kicker paragraph"><a class="ae ep" href="https://towardsai.net/p/category/machine-learning" rel="noopener ugc nofollow" target="_blank">机器学习</a></h2><div class=""/><div class=""><h2 id="7abf" class="pw-subtitle-paragraph jz jc it bd b ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq dk translated">你能想到的每一个ML领域的最好的SOTA模型的集合</h2></div><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi kr"><img src="../Images/d7a74cd34e4aba42b41e31071e609385.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*eiubBr7ioPVRh6wY"/></div></div><figcaption class="ld le gj gh gi lf lg bd b be z dk translated">照片由<a class="ae lh" href="https://unsplash.com/@jontyson?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">乔恩·泰森</a>在<a class="ae lh" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上拍摄</figcaption></figure><p id="dd44" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">最先进的模型一直在变化。作为一个已经参加Kaggle竞赛将近一年的人，我发现自己遇到了很多这样的竞赛，对它们进行比较、评估和测试。我认为列出每个ML任务的最佳模型是个好主意，这样你就知道从哪里开始了。</p><p id="3deb" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">在我们开始之前，如果您正在寻找一个系统来处理您的机器学习工作负载，请看看SabrePC。他们目前提供一个预建的人工智能工作站，起价3700美元，由多达4个支持NVIDIA CUDA的GPU驱动，预装了最新的深度学习软件堆栈，并包括3年保修。(注:虽然我推广这个产品是有经济补偿的，但是你买一个我就不收任何佣金了！)</p><p id="83dc" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">没有别的事了，我们开始吧！</p><h2 id="e2f0" class="me mf it bd mg mh mi dn mj mk ml dp mm lr mn mo mp lv mq mr ms lz mt mu mv iz bi translated"><strong class="ak"> 1。图像分类</strong></h2><ul class=""><li id="6113" class="mw mx it lk b ll my lo mz lr na lv nb lz nc md nd ne nf ng bi translated"><a class="ae lh" href="https://towardsdatascience.com/google-releases-efficientnetv2-a-smaller-faster-and-better-efficientnet-673a77bdd43c" rel="noopener" target="_blank"><strong class="lk jd">efficient net v2</strong></a></li></ul><p id="cfb9" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">EfficientNetsV2比最先进的图像分类网络高出2%,同时训练速度提高了5-11倍，这是一个巨大的进步。模型训练速度一直是机器学习的一个巨大瓶颈，因为它只是让调试网络问题变得非常漫长。尽管它们在最近发布后还没有经过全面测试，但我想我们都同意EfficientNet是一个SOTA图像分类模型。</p><ul class=""><li id="e8e7" class="mw mx it lk b ll lm lo lp lr nh lv ni lz nj md nd ne nf ng bi translated"><a class="ae lh" href="https://towardsdatascience.com/deepmind-releases-a-new-state-of-the-art-image-classification-model-nfnets-75c0b3f37312" rel="noopener" target="_blank"> <strong class="lk jd">无规格化器网络(NF-Nets) </strong> </a></li></ul><p id="7e1d" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">今年对模型的一个主要关注点不是在基准数据集(如ImageNet21k)上实现性能的大幅提升，而是在训练速度上实现大幅提升。NF-Nets消除了批量标准化，并引入了自适应梯度裁剪，训练速度提高了9倍，同时在ImageNet上具有相同的SOTA性能。</p><h2 id="fa2d" class="me mf it bd mg mh mi dn mj mk ml dp mm lr mn mo mp lv mq mr ms lz mt mu mv iz bi translated"><strong class="ak"> 2。图像分割</strong></h2><ul class=""><li id="a883" class="mw mx it lk b ll my lo mz lr na lv nb lz nc md nd ne nf ng bi translated"><a class="ae lh" href="https://openaccess.thecvf.com/content_CVPRW_2020/papers/w22/Baheti_Eff-UNet_A_Novel_Architecture_for_Semantic_Segmentation_in_Unstructured_Environment_CVPRW_2020_paper.pdf" rel="noopener ugc nofollow" target="_blank"> <strong class="lk jd">高效U网</strong> </a></li></ul><p id="0cc9" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">u-网在图像分割方面非常强大。优化U-Net的最近趋势是将SOTA CNN作为U-Net编码器/主干。由于EfficientNet是主要的SOTA图像分类模型之一，最近发布了一篇论文，用efficient Net替换U-Net的编码器，并显示了令人印象深刻的结果。我也可以看到Eff-Unets在图像分割比赛中广泛使用，从而提高了它的价值。</p><h2 id="8bd6" class="me mf it bd mg mh mi dn mj mk ml dp mm lr mn mo mp lv mq mr ms lz mt mu mv iz bi translated">3.<strong class="ak">物体检测</strong></h2><ul class=""><li id="0eec" class="mw mx it lk b ll my lo mz lr na lv nb lz nc md nd ne nf ng bi translated"><a class="ae lh" href="https://towardsdatascience.com/advanced-yolov5-tutorial-enhancing-yolov5-with-weighted-boxes-fusion-3bead5b71688" rel="noopener" target="_blank"> <strong class="lk jd"> YoloV5 </strong> </a></li></ul><p id="6d8b" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">当然，Yolo在物体检测领域已经相当受欢迎。所以我不认为这部分需要更多的解释，因为有很多关于YoloV5的文章。</p><ul class=""><li id="0608" class="mw mx it lk b ll lm lo lp lr nh lv ni lz nj md nd ne nf ng bi translated"><a class="ae lh" href="https://arxiv.org/abs/2008.13367" rel="noopener ugc nofollow" target="_blank"><strong class="lk jd">【VF-Net】</strong></a></li></ul><p id="988e" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">我在做一个物体探测比赛的时候偶然发现了VF-Net，我对它的表现感到惊讶。它似乎总是匹配Yolo的表现，有时甚至超过它。VF-Net的作者引入了一种新的“Iou感知分类分数”,它在过滤预测框以获得更准确的平均精度方面做了大量工作。他们还设计了一种新的损失函数，称为<strong class="lk jd">变焦距损失</strong>，并提出了一种新的“星形包围盒”。这听起来对我来说非常有趣，我肯定会很快就此写一篇单独的文章。如果你有兴趣尝试使用MMDetection，可以查看我的教程<a class="ae lh" href="https://towardsdatascience.com/mmdetection-tutorial-an-end2end-state-of-the-art-object-detection-library-59064deeada3" rel="noopener" target="_blank">这里</a>。</p><h2 id="52a8" class="me mf it bd mg mh mi dn mj mk ml dp mm lr mn mo mp lv mq mr ms lz mt mu mv iz bi translated">4.表格数据和时间序列</h2><p id="cc03" class="pw-post-body-paragraph li lj it lk b ll my kd ln lo mz kg lq lr nk lt lu lv nl lx ly lz nm mb mc md im bi translated">表格数据非常受欢迎，因为许多机器学习项目都是建立在表格数据之上的。这是经典机器学习算法似乎优于深度学习网络(或至少表现相同)的少数地方之一。</p><ul class=""><li id="86f7" class="mw mx it lk b ll lm lo lp lr nh lv ni lz nj md nd ne nf ng bi translated"><strong class="lk jd">梯度增压机(LGBM，XGBoost &amp; Catboost) </strong></li></ul><p id="1274" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">我很惊讶地看到一个简单的算法(与其他DL网络相比)，如Light-GBM在Kaggle比赛中胜过神经网络。性能上的差异并不大，但在90年代达到1-2%并不容易。</p><p id="6d1d" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">梯度推进机器已经出现了很多，它们是建立在决策树之上的。它们最吸引人的特点是它们的可解释性和易用性。如果你是机器学习的初学者，我绝对建议从梯度推进机器开始，更具体地说是基础决策树。</p><ul class=""><li id="6f59" class="mw mx it lk b ll lm lo lp lr nh lv ni lz nj md nd ne nf ng bi translated"><strong class="lk jd">图形神经网络</strong></li></ul><p id="4ccf" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">图形神经网络已经成为机器学习领域的一个热门话题。我记得在今年流行的ML会议上看到了大量的GNN论文。</p><p id="1ea1" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">gnn提供的最好的东西之一是它们的灵活性。许多基于文本的机器学习问题可以转化为基于图的问题，这使得GNNs的使用成为可能。此外，GNNs可以通过图形卷积网络用于图像。此外，我已经看到大量的ML解决方案通过使用注意力来促进GNNs。因此，我将它添加到列表中的主要原因是它提供的灵活性和SOTA性能。如果你感兴趣，可以看看我这篇关于GNNs参加挑战性Kaggle比赛的文章:</p><div class="nn no gp gr np nq"><a href="https://towardsdatascience.com/what-i-learned-from-stanfords-covid-mrna-vaccine-kaggle-competition-98d3f454eef" rel="noopener follow" target="_blank"><div class="nr ab fo"><div class="ns ab nt cl cj nu"><h2 class="bd jd gy z fp nv fr fs nw fu fw jc bi translated">从斯坦福的Covid mRNA疫苗Kaggle竞赛中我学到了什么</h2><div class="nx l"><h3 class="bd b gy z fp nv fr fs nw fu fw dk translated">如果你真的对机器学习感兴趣，你一定听说过令人惊叹的数据科学竞赛…</h3></div><div class="ny l"><p class="bd b dl z fp nv fr fs nw fu fw dk translated">towardsdatascience.com</p></div></div><div class="nz l"><div class="oa l ob oc od nz oe lb nq"/></div></div></a></div><h2 id="4798" class="me mf it bd mg mh mi dn mj mk ml dp mm lr mn mo mp lv mq mr ms lz mt mu mv iz bi translated"><strong class="ak"> 5。自然语言处理</strong></h2><p id="f169" class="pw-post-body-paragraph li lj it lk b ll my kd ln lo mz kg lq lr nk lt lu lv nl lx ly lz nm mb mc md im bi translated">你可能已经猜到变形金刚是当前NLP的SOTA，而不是谈论你可能已经读过无数遍的变形金刚的基础知识，我想谈谈最近的基于变形金刚的模型。</p><ul class=""><li id="64b4" class="mw mx it lk b ll lm lo lp lr nh lv ni lz nj md nd ne nf ng bi translated"><strong class="lk jd"> OpenAI GPT-3 </strong></li></ul><p id="f37a" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">可能会围绕这个列表中的一些模型进行一些讨论，但我认为我们都同意GPT-3是最强大的NLP模型之一。有大量的文章展示了它在编写代码、编写内容、回答问题等方面的用途。尽管说实话，我仍然不认为它真的会取代编码员/编写者，等等…仅仅因为它是在网上内容上训练的，因此它将产生的所有东西都是已经存在的东西的混合物。我知道你在想什么，有些混合物可能仍然很好，但就我个人而言，我不认为GPT-3生产那些，也许GPT-4！但是，平心而论，我仍然对它的功能印象深刻。</p><ul class=""><li id="bd8c" class="mw mx it lk b ll lm lo lp lr nh lv ni lz nj md nd ne nf ng bi translated"><strong class="lk jd">伯特(当然)</strong></li><li id="88bb" class="mw mx it lk b ll of lo og lr oh lv oi lz oj md nd ne nf ng bi translated"><strong class="lk jd">尊贵提:</strong> <a class="ae lh" href="https://towardsdatascience.com/google-switch-transformers-scaling-to-trillion-parameter-models-with-constant-computational-costs-806fd145923d" rel="noopener" target="_blank"> <strong class="lk jd">谷歌开关变形金刚</strong> </a></li></ul><p id="77bf" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">我不确定我是否会把谷歌开关称为变形金刚SOTA，但他们肯定会在最佳NLP模型的列表中。尤其是，当这些模型“扩展到万亿个参数”时</p><p id="62f5" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">接下来的两个部分是关于无监督学习和强化学习。对于这两者，很难命名SOTA模型，因为没有很多评论和比较(相对于上述子领域)。</p><h2 id="fc26" class="me mf it bd mg mh mi dn mj mk ml dp mm lr mn mo mp lv mq mr ms lz mt mu mv iz bi translated">-无监督表示学习</h2><p id="c142" class="pw-post-body-paragraph li lj it lk b ll my kd ln lo mz kg lq lr nk lt lu lv nl lx ly lz nm mb mc md im bi translated">无监督学习得到的关注比它应该得到的少得多。我坚信无标签训练机器学习模型的力量。老实说，我做过的最愉快的项目之一是无人监管的机器学习项目。虽然有强大的无监督经典机器学习算法，但我打算和这篇文章的基调保持一致，坚持深度学习。也很难找到关于无监督算法性能的评论，因为评估它们是一件痛苦的事情。</p><p id="186a" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">众所周知，自动编码器和生成对抗网络一直处于深度无监督学习的前沿。然而，我将更多地关注自动编码器，因为它们更符合“表示学习”的标准。</p><ul class=""><li id="d3a3" class="mw mx it lk b ll lm lo lp lr nh lv ni lz nj md nd ne nf ng bi translated"><a class="ae lh" href="https://blog.usejournal.com/understanding-vector-quantized-variational-autoencoders-vq-vae-323d710a888a?gi=2dfb384ac7eb" rel="noopener ugc nofollow" target="_blank"> <strong class="lk jd">(矢量量化)</strong> </a> <strong class="lk jd"> </strong> <a class="ae lh" href="https://towardsdatascience.com/intuitively-understanding-variational-autoencoders-1bfe67eb5daf" rel="noopener" target="_blank"> <strong class="lk jd">变分自动编码器</strong> </a></li></ul><p id="0ce1" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">可变自动编码器提供了对经典编码器/解码器架构的升级。他们的瓶颈分为两层，“均值”和“标准差”。这两层然后进入采样层，这就是事情变得有趣的地方。该采样层试图表示数据集的分布。此外，您可以从该采样层“生成”数据点，因为它应该对数据集的分布进行建模。</p><h2 id="f78f" class="me mf it bd mg mh mi dn mj mk ml dp mm lr mn mo mp lv mq mr ms lz mt mu mv iz bi translated"><strong class="ak"> -强化学习</strong></h2><p id="9e85" class="pw-post-body-paragraph li lj it lk b ll my kd ln lo mz kg lq lr nk lt lu lv nl lx ly lz nm mb mc md im bi translated">我不是强化学习的专家，所以我不想解释这些模型，但如果你想了解更多，我会提供有用的资源。</p><ul class=""><li id="3cb4" class="mw mx it lk b ll lm lo lp lr nh lv ni lz nj md nd ne nf ng bi translated"><strong class="lk jd">深度Q网络</strong></li></ul><div class="nn no gp gr np nq"><a href="https://towardsdatascience.com/dqn-part-1-vanilla-deep-q-networks-6eb4a00febfb" rel="noopener follow" target="_blank"><div class="nr ab fo"><div class="ns ab nt cl cj nu"><h2 class="bd jd gy z fp nv fr fs nw fu fw jc bi translated">普通深度Q网络</h2><div class="nx l"><h3 class="bd b gy z fp nv fr fs nw fu fw dk translated">深度Q学习解释</h3></div><div class="ny l"><p class="bd b dl z fp nv fr fs nw fu fw dk translated">towardsdatascience.com</p></div></div><div class="nz l"><div class="ok l ob oc od nz oe lb nq"/></div></div></a></div><ul class=""><li id="5489" class="mw mx it lk b ll lm lo lp lr nh lv ni lz nj md nd ne nf ng bi translated"><strong class="lk jd">优势影评人</strong></li></ul><div class="nn no gp gr np nq"><a href="https://towardsdatascience.com/understanding-actor-critic-methods-931b97b6df3f" rel="noopener follow" target="_blank"><div class="nr ab fo"><div class="ns ab nt cl cj nu"><h2 class="bd jd gy z fp nv fr fs nw fu fw jc bi translated">理解演员-评论家方法</h2><div class="nx l"><h3 class="bd b gy z fp nv fr fs nw fu fw dk translated">预赛</h3></div><div class="ny l"><p class="bd b dl z fp nv fr fs nw fu fw dk translated">towardsdatascience.com</p></div></div><div class="nz l"><div class="ol l ob oc od nz oe lb nq"/></div></div></a></div><h2 id="e9c4" class="me mf it bd mg mh mi dn mj mk ml dp mm lr mn mo mp lv mq mr ms lz mt mu mv iz bi translated"><strong class="ak">最终想法</strong></h2><p id="80c6" class="pw-post-body-paragraph li lj it lk b ll my kd ln lo mz kg lq lr nk lt lu lv nl lx ly lz nm mb mc md im bi translated">希望你喜欢这篇文章，如果你开始一个新的项目，希望你知道从哪里开始寻找。如果你对我的选择有任何想法，请发表评论！</p><p id="c4d0" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">如果你想定期收到关于人工智能和机器学习的最新论文的评论，请在这里添加你的电子邮件并订阅！</p><p id="d004" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated"><a class="ae lh" href="https://artisanal-motivator-8249.ck.page/5524b8f934" rel="noopener ugc nofollow" target="_blank">https://artisanal-motivator-8249.ck.page/5524b8f934</a></p></div></div>    
</body>
</html>