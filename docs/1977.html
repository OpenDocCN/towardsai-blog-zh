<html>
<head>
<title>NumPy: Linear Algebra on Images</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">NumPy:图像上的线性代数</h1>
<blockquote>原文：<a href="https://pub.towardsai.net/numpy-linear-algebra-on-images-ed3180978cdb?source=collection_archive---------1-----------------------#2021-07-11">https://pub.towardsai.net/numpy-linear-algebra-on-images-ed3180978cdb?source=collection_archive---------1-----------------------#2021-07-11</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><h2 id="df39" class="ir is it bd b dl iu iv iw ix iy iz dk ja translated" aria-label="kicker paragraph"><a class="ae ep" href="https://towardsai.net/p/category/mathematics" rel="noopener ugc nofollow" target="_blank">数学</a></h2><div class=""/><div class=""><h2 id="0f15" class="pw-subtitle-paragraph jz jc it bd b ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq dk translated">SVD来生成图像的压缩近似</h2></div><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi kr"><img src="../Images/bf2c110a452418117be49bc218a0775b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*2xQdJdniygvqNF8el2vrzg.png"/></div></div><figcaption class="ld le gj gh gi lf lg bd b be z dk translated">图片<a class="ae lh" href="https://www.google.com/imgres?imgurl=https%3A%2F%2Fblog.tonkabi.com%2Fstorage%2Fapp%2Fmedia%2Fpixel%2520pic.png&amp;imgrefurl=https%3A%2F%2Fblog.tonkabi.com%2Fblog%2Fpost%2Fcomputer-vision-vs-human-vision&amp;tbnid=WHBb4jktnumlVM&amp;vet=10CAUQxiAoBGoXChMIiM_v-8fR8QIVAAAAAB0AAAAAEAg..i&amp;docid=l7r2USvptJr_mM&amp;w=1130&amp;h=715&amp;itg=1&amp;q=image%20pixels&amp;client=firefox-b-d&amp;ved=0CAUQxiAoBGoXChMIiM_v-8fR8QIVAAAAAB0AAAAAEAg" rel="noopener ugc nofollow" target="_blank">来源</a></figcaption></figure><p id="3778" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">在本教学练习中，我们将使用线性代数中的矩阵分解，奇异值分解，来生成图像的压缩近似值。我们将使用scipy.misc模块中的ascent图像:</p><p id="6d8c" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated"><strong class="lk jd">让我们从什么是奇异值分解开始吧？</strong></p><p id="e4f4" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">奇异值分解(SVD)有着广泛的应用。这些包括降维、压缩图像和数据去噪。基本上，SVD认为一个矩阵可以表示为其他三个矩阵的乘积。用数学术语来说，SVD可以写成:</p><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div class="gh gi me"><img src="../Images/9db3d0c20fb97c2e6ad37716b96e806e.png" data-original-src="https://miro.medium.com/v2/resize:fit:536/format:webp/0*q98jtlLvnV7evADz.png"/></div></figure><p id="c92b" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">其中<strong class="lk jd"> <em class="mf"> n </em> </strong>和<strong class="lk jd"> <em class="mf"> p </em> </strong>为行数和维度数。</p><p id="e164" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">我们将使用来自scipy.misc模块的面部图像。该图像是一个NumPy数组，正如我们在使用type函数时所看到的。</p><p id="83a4" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">让我们使用<a class="ae lh" href="http://matplotlib.pyplot.im" rel="noopener ugc nofollow" target="_blank">matplotlib . py plot . im</a>show函数绘制图像:</p><pre class="ks kt ku kv gt mg mh mi mj aw mk bi"><span id="6010" class="ml mm it mh b gy mn mo l mp mq">from scipy import misc<br/>image=misc.face()</span><span id="c836" class="ml mm it mh b gy mr mo l mp mq">type(image)</span></pre><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi ms"><img src="../Images/e8ffcbc37ec12bea38752d9f254293e2.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*dMc3hFt-lEmo3oJ7YMDDMg.png"/></div></div><figcaption class="ld le gj gh gi lf lg bd b be z dk translated">作者的照片</figcaption></figure><p id="1083" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">检查形状、轴和数组属性，结果如下</p><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div class="gh gi mt"><img src="../Images/2e83c5273b46b9221ca381f67c7a84b7.png" data-original-src="https://miro.medium.com/v2/resize:fit:1102/format:webp/1*CZACPkc730nRoOVZGek0eA.png"/></div></figure><p id="7980" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">它表示我们有一个由3个矩阵组成的数组，每个矩阵的形状都是768x1024。由于这是一幅彩色图像，并且我们使用了imread函数来读取它，因此数据被组织在三个2D数组中，代表颜色通道(在本例中为红色、绿色和蓝色— RGB)。因为我们将对这些数据执行线性代数运算，所以在矩阵的每个条目中使用一个介于0和1之间的实数来显示RGB值可能更有意思。我们可以通过设置。</p><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div class="gh gi mu"><img src="../Images/d9726ac72c68fd08a6dbdfb9d3c0472a.png" data-original-src="https://miro.medium.com/v2/resize:fit:772/format:webp/1*yxFvq1Q86vAFz8sMr4H3Wg.png"/></div></figure><div class="mv mw gp gr mx my"><a rel="noopener  ugc nofollow" target="_blank" href="/understand-list-with-python-example-5e02a5566ca0"><div class="mz ab fo"><div class="na ab nb cl cj nc"><h2 class="bd jd gy z fp nd fr fs ne fu fw jc bi translated">通过Python示例了解List[]</h2><div class="nf l"><h3 class="bd b gy z fp nd fr fs ne fu fw dk translated">python中数据结构的便捷概念</h3></div><div class="ng l"><p class="bd b dl z fp nd fr fs ne fu fw dk translated">pub.towardsai.net</p></div></div><div class="nh l"><div class="ni l nj nk nl nh nm lb my"/></div></div></a></div><div class="mv mw gp gr mx my"><a rel="noopener  ugc nofollow" target="_blank" href="/understand-dictionary-with-python-example-c315e5af44ab"><div class="mz ab fo"><div class="na ab nb cl cj nc"><h2 class="bd jd gy z fp nd fr fs ne fu fw jc bi translated">用Python例子理解字典{}</h2><div class="nf l"><h3 class="bd b gy z fp nd fr fs ne fu fw dk translated">python中数据结构的便捷概念</h3></div><div class="ng l"><p class="bd b dl z fp nd fr fs ne fu fw dk translated">pub.towardsai.net</p></div></div><div class="nh l"><div class="nn l nj nk nl nh nm lb my"/></div></div></a></div><p id="1d66" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">这个操作，将一个数组除以一个标量，由于NumPy的广播规则，你可以通过做一些测试来检查上面的工作；例如，查询该数组的最大值和最小值或检查数组中的数据类型:</p><pre class="ks kt ku kv gt mg mh mi mj aw mk bi"><span id="354d" class="ml mm it mh b gy mn mo l mp mq">image_array.max(), image_array.min()<br/>(1.0, 0.0)</span><span id="1888" class="ml mm it mh b gy mr mo l mp mq"> image_array.dtype<br/>dtype('float64')</span></pre><p id="e3d5" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">这里，我们将使用SVD(奇异值分解)来尝试修改比原始图像使用更少奇异值信息的图像，同时仍然保留其一些特征。</p><p id="6a0c" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">接下来，让我们从NumPy导入线性代数子模块:</p><pre class="ks kt ku kv gt mg mh mi mj aw mk bi"><span id="01db" class="ml mm it mh b gy mn mo l mp mq">from numpy import linalg</span></pre><p id="9be1" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">为了从给定的矩阵中提取信息，我们将使用SVD来获得3个数组，这些数组可以相乘以获得原始矩阵。根据线性代数理论，给定矩阵A，可以计算出以下乘积:</p><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div class="gh gi no"><img src="../Images/8719ecc601d72c6087f4ee1b887ec7aa.png" data-original-src="https://miro.medium.com/v2/resize:fit:1290/format:webp/1*BgVVTU4IT576HDl04CmXpQ.png"/></div></figure><ul class=""><li id="f45e" class="np nq it lk b ll lm lo lp lr nr lv ns lz nt md nu nv nw nx bi translated">正交矩阵是U是an (m × m)。</li><li id="5242" class="np nq it lk b ll ny lo nz lr oa lv ob lz oc md nu nv nw nx bi translated">矩形对角矩阵是一个m × n的σ，σ1，…，σmin(m，n)是所有非负且按非递增顺序排列的对角元素。</li></ul><p id="4105" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">它包含A的奇异值，从最大到最小组织。要注意的是，这些值在矩阵a中被标记为重要性和非负值。</p><ul class=""><li id="9304" class="np nq it lk b ll lm lo lp lr nr lv ns lz nt md nu nv nw nx bi translated">正交矩阵是V是an (n × n)。</li></ul><p id="6972" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">让我们先用一个矩阵的例子来看看这在实践中是如何工作的。请注意，根据色度学，如果我们应用以下公式，就有可能获得相当合理的彩色图像灰度版本</p><blockquote class="od"><p id="dd0b" class="oe of it bd og oh oi oj ok ol om md dk translated">Y = 0.2126R + 0.7152G + 0.0722B</p></blockquote><p id="9852" class="pw-post-body-paragraph li lj it lk b ll on kd ln lo oo kg lq lr op lt lu lv oq lx ly lz or mb mc md im bi translated">其中Y是输出灰度图像阵列，R、G和B是具有一些初始值的红色、绿色和蓝色通道阵列。</p><pre class="ks kt ku kv gt mg mh mi mj aw mk bi"><span id="7a32" class="ml mm it mh b gy mn mo l mp mq">image_gray = image_array @ [0.2126, 0.7152, 0.0722]<br/>image_gray.shape<br/>  <br/>(768, 1024)</span></pre><p id="e757" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">我们在这里近似图像的灰度部分，所以我们将使用颜色图灰色</p><pre class="ks kt ku kv gt mg mh mi mj aw mk bi"><span id="75ed" class="ml mm it mh b gy mn mo l mp mq">plt.imshow(image_gray, cmap="gray")</span></pre><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div class="gh gi os"><img src="../Images/599e64a526511260a63c1c4e3d8efab2.png" data-original-src="https://miro.medium.com/v2/resize:fit:1068/format:webp/1*wbsMbDcYFHQeV2jP3skAbA.png"/></div></figure><p id="cdcf" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">现在，将linalg.svd函数应用于该矩阵，我们得到以下结果:</p><pre class="ks kt ku kv gt mg mh mi mj aw mk bi"><span id="dd2d" class="ml mm it mh b gy mn mo l mp mq">U, s, Vt = linalg.svd(image_gray)</span></pre><p id="8fc0" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">现在让我们再次检查形状</p><pre class="ks kt ku kv gt mg mh mi mj aw mk bi"><span id="72b5" class="ml mm it mh b gy mn mo l mp mq">U.shape, s.shape, Vt.shape</span></pre><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div class="gh gi ot"><img src="../Images/8330755991b6cb874316313cc44ceccb.png" data-original-src="https://miro.medium.com/v2/resize:fit:1018/format:webp/1*yL7fOVnUuREiH0rYdcGxSg.png"/></div></figure><p id="4f9d" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">注意:s有一个特殊的形状:它只有一维。这意味着其他一些需要2d数组的线性代数函数可能无法工作。</p><p id="76c9" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">例如，从理论上讲，人们可能期望s和Vt对于乘法是不冲突的。然而，这是不正确的，因为s在这里没有第二个轴。执行会导致值错误。这是因为在这种情况下，s的一维数组实际上比用相同的数据构建对角矩阵更合理。为了重建原始矩阵，我们可以重建对角矩阵σ，其对角线上有s的分量，并且具有适当的乘法维数:在我们的例子中，σ应该是768×1024，因为U是768×768，Vt是1024×1024。</p><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi ou"><img src="../Images/356dee5ea99cd3d5bef53efd0566feb2.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Pl5KV4TAL6doEm6-ImYXYQ.png"/></div></div></figure><pre class="ks kt ku kv gt mg mh mi mj aw mk bi"><span id="c0e7" class="ml mm it mh b gy mn mo l mp mq">import numpy as np<br/>Sigma = np.zeros((768, 1024))<br/>for i in range(768):<br/>   Sigma[i, i] = s[i]</span></pre><p id="0f3f" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">现在，让我们检查一下重建的U @适马@ Vt是否接近原始的img_gray矩阵。</p><pre class="ks kt ku kv gt mg mh mi mj aw mk bi"><span id="9bd2" class="ml mm it mh b gy mn mo l mp mq">linalg.norm(image_gray - U @ Sigma @ Vt</span></pre><h1 id="436f" class="ov mm it bd ow ox oy oz pa pb pc pd pe ki pf kj pg kl ph km pi ko pj kp pk pl bi translated">接近</h1><p id="87ba" class="pw-post-body-paragraph li lj it lk b ll pm kd ln lo pn kg lq lr po lt lu lv pp lx ly lz pq mb mc md im bi translated">linalg模块包括一个范数函数，它计算以NumPy数组表示的向量或矩阵的范数。例如，根据上面的SVD解释，我们期望img_gray和重构的SVD乘积之间的差的范数很小，如下面的代码所示。</p><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div class="gh gi pr"><img src="../Images/618af99e03161eb849e9189df0718ab7.png" data-original-src="https://miro.medium.com/v2/resize:fit:1270/format:webp/1*vOibM07r6Dr4iqwwUXq2yw.png"/></div></figure><p id="a2d3" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">为了查看近似是否公平，我们可以检查s中的值:</p><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div class="gh gi ps"><img src="../Images/8312dade2973d0cd85f27e0dc1deceaa.png" data-original-src="https://miro.medium.com/v2/resize:fit:1164/format:webp/1*kiQeZAnPfwc6j3O5QmQVTQ.png"/></div></figure><p id="4fa2" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">在图中，我们可以看到，尽管s中有768个奇异值，但大多数(在第150个条目之后)都非常小。为了建立更经济的近似值，我们需要将第一个“50”的奇异值与信息联系起来。</p><h1 id="27a3" class="ov mm it bd ow ox oy oz pa pb pc pd pe ki pf kj pg kl ph km pi ko pj kp pk pl bi translated">最后的想法</h1><p id="aef0" class="pw-post-body-paragraph li lj it lk b ll pm kd ln lo pn kg lq lr po lt lu lv pp lx ly lz pq mb mc md im bi translated">无论是对于PCA(主成分分析)还是推荐算法，SVD都是一种强大的技术，目前广泛应用于许多模型中。奇异值分解是图像处理应用中代数变换的一种重要方法。</p></div><div class="ab cl pt pu hx pv" role="separator"><span class="pw bw bk px py pz"/><span class="pw bw bk px py pz"/><span class="pw bw bk px py"/></div><div class="im in io ip iq"><p id="540d" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">我希望你喜欢这篇文章。通过我的<a class="ae lh" href="https://www.linkedin.com/in/data-scientist-95040a1ab/" rel="noopener ugc nofollow" target="_blank"> LinkedIn </a>和<a class="ae lh" href="https://twitter.com/amitprius" rel="noopener ugc nofollow" target="_blank"> twitter </a>联系我。</p><h1 id="c0d4" class="ov mm it bd ow ox oy oz pa pb pc pd pe ki pf kj pg kl ph km pi ko pj kp pk pl bi translated">推荐文章</h1><p id="f3a5" class="pw-post-body-paragraph li lj it lk b ll pm kd ln lo pn kg lq lr po lt lu lv pp lx ly lz pq mb mc md im bi translated"><a class="ae lh" href="https://medium.com/towards-artificial-intelligence/nlp-zero-to-hero-with-python-2df6fcebff6e?sk=2231d868766e96b13d1e9d7db6064df1" rel="noopener"> 1。NLP —零到英雄用Python </a> <br/> 2。<a class="ae lh" href="https://medium.com/towards-artificial-intelligence/python-data-structures-data-types-and-objects-244d0a86c3cf?sk=42f4b462499f3fc3a160b21e2c94dba6" rel="noopener"> Python数据结构数据类型和对象</a> <br/> 3。<a class="ae lh" rel="noopener ugc nofollow" target="_blank" href="/exception-handling-concepts-in-python-4d5116decac3?source=friends_link&amp;sk=a0ed49d9fdeaa67925eac34ecb55ea30">Python中的异常处理概念</a> <br/> 4。<a class="ae lh" rel="noopener ugc nofollow" target="_blank" href="/deep-learning-88e218b74a14?source=friends_link&amp;sk=540bf9088d31859d50dbddab7524ba35">为什么LSTM在深度学习方面比RNN更有用？</a> <br/> 5。<a class="ae lh" rel="noopener ugc nofollow" target="_blank" href="/neural-networks-the-rise-of-recurrent-neural-networks-df740252da88?source=friends_link&amp;sk=6844935e3de14e478ce00f0b22e419eb">神经网络:递归神经网络的兴起</a> <br/> 6。<a class="ae lh" href="https://medium.com/towards-artificial-intelligence/fully-explained-linear-regression-with-python-fe2b313f32f3?source=friends_link&amp;sk=53c91a2a51347ec2d93f8222c0e06402" rel="noopener">用Python充分解释了线性回归</a> <br/> 7。<a class="ae lh" href="https://medium.com/towards-artificial-intelligence/fully-explained-logistic-regression-with-python-f4a16413ddcd?source=friends_link&amp;sk=528181f15a44e48ea38fdd9579241a78" rel="noopener">用Python </a> <br/>充分解释了Logistic回归8。<a class="ae lh" rel="noopener ugc nofollow" target="_blank" href="/differences-between-concat-merge-and-join-with-python-1a6541abc08d?source=friends_link&amp;sk=3b37b694fb90db16275059ea752fc16a">concat()、merge()和join()与Python </a> <br/> 9的区别。<a class="ae lh" rel="noopener ugc nofollow" target="_blank" href="/data-wrangling-with-python-part-1-969e3cc81d69?source=friends_link&amp;sk=9c3649cf20f31a5c9ead51c50c89ba0b">与Python的数据角力—第一部分</a>T30】10。<a class="ae lh" href="https://medium.com/analytics-vidhya/confusion-matrix-in-machine-learning-91b6e2b3f9af?source=friends_link&amp;sk=11c6531da0bab7b504d518d02746d4cc" rel="noopener">机器学习中的混淆矩阵</a></p></div></div>    
</body>
</html>