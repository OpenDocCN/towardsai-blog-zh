<html>
<head>
<title>Machine Learning A-Z Briefly Explained</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">机器学习A-Z简要说明</h1>
<blockquote>原文：<a href="https://pub.towardsai.net/machine-learning-a-z-briefly-explained-4ff86bd81e3a?source=collection_archive---------0-----------------------#2022-04-14">https://pub.towardsai.net/machine-learning-a-z-briefly-explained-4ff86bd81e3a?source=collection_archive---------0-----------------------#2022-04-14</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><figure class="gl gn jr js jt ju gh gi paragraph-image"><div class="gh gi jq"><img src="../Images/df272af29c3d9777896e9c2daf01e2ec.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*DKzB1sRr5WcZ-z56Zu1d0Q.png"/></div><figcaption class="jx jy gj gh gi jz ka bd b be z dk translated">作者图片</figcaption></figure><p id="1e77" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi kz translated">在这篇文章中，我试图简要地向你指出机器学习A-Z <strong class="kd iu">。你可以在面试前读一下这篇文章，让你的记忆焕然一新。这个术语很重要'<em class="li">简单来说'</em>,让你在面试时快速回忆起这个解释。</strong></p></div><div class="ab cl lj lk hx ll" role="separator"><span class="lm bw bk ln lo lp"/><span class="lm bw bk ln lo lp"/><span class="lm bw bk ln lo"/></div><div class="im in io ip iq"><pre class="lq lr ls lt gt lu lv lw lx aw ly bi"><span id="2d60" class="lz ma it lv b gy mb mc l md me">· <a class="ae mf" href="#32d9" rel="noopener ugc nofollow">Machine Learning Types</a><br/>· <a class="ae mf" href="#6c07" rel="noopener ugc nofollow">Machine Learning Model Types</a><br/> ∘ <a class="ae mf" href="#abc0" rel="noopener ugc nofollow">Linear Regression</a><br/> ∘ <a class="ae mf" href="#90fb" rel="noopener ugc nofollow">Multiple Linear Regression</a><br/> ∘ <a class="ae mf" href="#51b0" rel="noopener ugc nofollow">Polynomial Linear Regression</a><br/>· <a class="ae mf" href="#7fd5" rel="noopener ugc nofollow">Classification</a><br/> ∘ <a class="ae mf" href="#7bda" rel="noopener ugc nofollow">Real-Life Examples</a><br/> ∘ <a class="ae mf" href="#b77e" rel="noopener ugc nofollow">Logistic Regression</a><br/> ∘ <a class="ae mf" href="#827b" rel="noopener ugc nofollow">Naive Bayes</a><br/> ∘ <a class="ae mf" href="#f12f" rel="noopener ugc nofollow">K-Nearest Neighbors</a><br/> ∘ <a class="ae mf" href="#4748" rel="noopener ugc nofollow">Decision Tree</a><br/> ∘ <a class="ae mf" href="#434f" rel="noopener ugc nofollow">Support Vector Machines</a><br/>· <a class="ae mf" href="#183c" rel="noopener ugc nofollow">Clustering</a><br/> ∘ <a class="ae mf" href="#a9a4" rel="noopener ugc nofollow">Real-life Examples</a><br/> ∘ <a class="ae mf" href="#a34c" rel="noopener ugc nofollow">K-means clustering</a><br/> ∘ <a class="ae mf" href="#2d83" rel="noopener ugc nofollow">DBSCAN clustering algorithm</a><br/> ∘ <a class="ae mf" href="#6e00" rel="noopener ugc nofollow">An agglomerative Hierarchy clustering algorithm</a><br/>· <a class="ae mf" href="#89d0" rel="noopener ugc nofollow">Mostly Faced Problems in Machine Learning and Solutions</a><br/> ∘ <a class="ae mf" href="#17b9" rel="noopener ugc nofollow">Overfitting</a><br/> ∘ <a class="ae mf" href="#ee40" rel="noopener ugc nofollow">Underfitting</a><br/> ∘ <a class="ae mf" href="#733d" rel="noopener ugc nofollow">Missing Data</a><br/>· <a class="ae mf" href="#cee7" rel="noopener ugc nofollow">Common Terms in Machine Learning</a><br/> ∘ <a class="ae mf" href="#5347" rel="noopener ugc nofollow">Pipeline</a><br/> ∘ <a class="ae mf" href="#8cad" rel="noopener ugc nofollow">A/B Testing</a><br/> ∘ <a class="ae mf" href="#5e8e" rel="noopener ugc nofollow">One-Hot Encoding</a><br/> ∘ <a class="ae mf" href="#8df2" rel="noopener ugc nofollow">Training / Test Split</a><br/> ∘ <a class="ae mf" href="#9e6d" rel="noopener ugc nofollow">Gradient Descent</a><br/> ∘ <a class="ae mf" href="#54f6" rel="noopener ugc nofollow">Learning Rate</a><br/> ∘ <a class="ae mf" href="#b209" rel="noopener ugc nofollow">Mean Absolute Error</a><br/> ∘ <a class="ae mf" href="#04ce" rel="noopener ugc nofollow">Normalization</a><br/> ∘ <a class="ae mf" href="#5bbd" rel="noopener ugc nofollow">Confusion Matrix</a><br/> ∘ <a class="ae mf" href="#517d" rel="noopener ugc nofollow">False Positive / False Negative</a><br/> ∘ <a class="ae mf" href="#cab4" rel="noopener ugc nofollow">Deep Learning</a><br/> ∘ <a class="ae mf" href="#37a0" rel="noopener ugc nofollow">Bias &amp; Variance</a><br/> ∘ <a class="ae mf" href="#8185" rel="noopener ugc nofollow">Recommendation System</a><br/> ∘ <a class="ae mf" href="#f784" rel="noopener ugc nofollow">Reducing Dimensionality</a><br/> ∘ <a class="ae mf" href="#4ad9" rel="noopener ugc nofollow">PCA</a><br/> ∘ <a class="ae mf" href="#068a" rel="noopener ugc nofollow">F1 Score</a><br/> ∘ <a class="ae mf" href="#3904" rel="noopener ugc nofollow">Correlation</a><br/> ∘ <a class="ae mf" href="#23ea" rel="noopener ugc nofollow">Ensemble learning</a><br/> ∘ <a class="ae mf" href="#22ba" rel="noopener ugc nofollow">Cross-Validation</a><br/>· <a class="ae mf" href="#eaae" rel="noopener ugc nofollow">Conclusion</a></span></pre></div><div class="ab cl lj lk hx ll" role="separator"><span class="lm bw bk ln lo lp"/><span class="lm bw bk ln lo lp"/><span class="lm bw bk ln lo"/></div><div class="im in io ip iq"><p id="e3b7" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">此外，我添加了图表，因为如果招聘经理希望你进一步解释，你可以用一个简单的手势来解释。</p><figure class="lq lr ls lt gt ju"><div class="bz fp l di"><div class="mg mh l"/></div><figcaption class="jx jy gj gh gi jz ka bd b be z dk translated"><a class="ae mf" href="https://giphy.com/gifs/xUOrvTqtFduR07rNXq" rel="noopener ugc nofollow" target="_blank">参考</a></figcaption></figure></div><div class="ab cl lj lk hx ll" role="separator"><span class="lm bw bk ln lo lp"/><span class="lm bw bk ln lo lp"/><span class="lm bw bk ln lo"/></div><div class="im in io ip iq"><h1 id="32d9" class="mi ma it bd mj mk ml mm mn mo mp mq mr ms mt mu mv mw mx my mz na nb nc nd ne bi translated">机器学习类型</h1><p id="ea6e" class="pw-post-body-paragraph kb kc it kd b ke nf kg kh ki ng kk kl km nh ko kp kq ni ks kt ku nj kw kx ky im bi translated"><strong class="kd iu">监督学习</strong></p><p id="b6f5" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">您要预测的标签在数据集中。</p><p id="730d" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">(预测房价时，数据集包含房价。)</p><p id="032f" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated"><strong class="kd iu">无监督学习</strong></p><p id="8665" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">您要预测的标签不在数据集中。</p><p id="e3f7" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated"><strong class="kd iu">强化学习</strong></p><p id="70bd" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">当你教一台有奖惩系统的电脑。</p><h1 id="6c07" class="mi ma it bd mj mk nk mm mn mo nl mq mr ms nm mu mv mw nn my mz na no nc nd ne bi translated"><strong class="ak">机器学习模型类型</strong></h1><h2 id="abc0" class="lz ma it bd mj np nq dn mn nr ns dp mr km nt nu mv kq nv nw mz ku nx ny nd nz bi translated"><strong class="ak">线性回归</strong></h2><p id="b941" class="pw-post-body-paragraph kb kc it kd b ke nf kg kh ki ng kk kl km nh ko kp kq ni ks kt ku nj kw kx ky im bi translated">当你想用一个变量预测一个数值变量时。</p><p id="18ae" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated"><strong class="kd iu">多元线性回归</strong></p><p id="39c2" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">用多个变量预测一个数字变量。</p><h2 id="51b0" class="lz ma it bd mj np nq dn mn nr ns dp mr km nt nu mv kq nv nw mz ku nx ny nd nz bi translated"><strong class="ak">多项式线性回归</strong></h2><p id="3c89" class="pw-post-body-paragraph kb kc it kd b ke nf kg kh ki ng kk kl km nh ko kp kq ni ks kt ku nj kw kx ky im bi translated">当变量之间的线比一条直线更复杂时。</p><figure class="lq lr ls lt gt ju gh gi paragraph-image"><div role="button" tabindex="0" class="ob oc di od bf oe"><div class="gh gi oa"><img src="../Images/a995bea3c0ad0abd4f5d8800978068c2.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*dxO2IhrFYSA7Xs4tgYr6kQ.png"/></div></div><figcaption class="jx jy gj gh gi jz ka bd b be z dk translated">参考:动手机器学习O Reilly</figcaption></figure><div class="of og gp gr oh oi"><a href="https://medium.com/@geencay/machine-learning-model-in-weight-prediction-b22a4cb77e2c" rel="noopener follow" target="_blank"><div class="oj ab fo"><div class="ok ab ol cl cj om"><h2 class="bd iu gy z fp on fr fs oo fu fw is bi translated">体重预测中的回归模型</h2><div class="op l"><p class="bd b dl z fp on fr fs oo fu fw dk translated">medium.com</p></div></div><div class="oq l"><div class="or l os ot ou oq ov jv oi"/></div></div></a></div><div class="of og gp gr oh oi"><a href="https://medium.com/@geencay/linear-regression-in-fuel-consumption-2fefb66418a0" rel="noopener follow" target="_blank"><div class="oj ab fo"><div class="ok ab ol cl cj om"><h2 class="bd iu gy z fp on fr fs oo fu fw is bi translated">燃料消耗的线性回归</h2><div class="op l"><p class="bd b dl z fp on fr fs oo fu fw dk translated">medium.com</p></div></div><div class="oq l"><div class="ow l os ot ou oq ov jv oi"/></div></div></a></div><h1 id="7fd5" class="mi ma it bd mj mk nk mm mn mo nl mq mr ms nm mu mv mw nn my mz na no nc nd ne bi translated"><strong class="ak">分类</strong></h1><h2 id="7bda" class="lz ma it bd mj np nq dn mn nr ns dp mr km nt nu mv kq nv nw mz ku nx ny nd nz bi translated"><strong class="ak">现实生活中的例子</strong></h2><ul class=""><li id="5d59" class="ox oy it kd b ke nf ki ng km oz kq pa ku pb ky pc pd pe pf bi translated">手写数字识别</li><li id="c454" class="ox oy it kd b ke pg ki ph km pi kq pj ku pk ky pc pd pe pf bi translated">垃圾电子邮件</li><li id="500d" class="ox oy it kd b ke pg ki ph km pi kq pj ku pk ky pc pd pe pf bi translated">客户流失预测</li><li id="ef58" class="ox oy it kd b ke pg ki ph km pi kq pj ku pk ky pc pd pe pf bi translated">信用卡欺诈检测</li></ul><h2 id="b77e" class="lz ma it bd mj np nq dn mn nr ns dp mr km nt nu mv kq nv nw mz ku nx ny nd nz bi translated"><strong class="ak">逻辑回归</strong></h2><p id="abce" class="pw-post-body-paragraph kb kc it kd b ke nf kg kh ki ng kk kl km nh ko kp kq ni ks kt ku nj kw kx ky im bi translated"><em class="li">监督学习算法。</em></p><p id="97ac" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">一般用于二元分类问题。</p><p id="65c2" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated"><em class="li">举例:选举预测——奥巴马还是特朗普？</em></p><figure class="lq lr ls lt gt ju gh gi paragraph-image"><div class="gh gi jq"><img src="../Images/cc8e128bfac6700676cf0ac9629e80c1.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*gue0cahhyw5cyOMaWeSyAw.png"/></div><figcaption class="jx jy gj gh gi jz ka bd b be z dk translated"><a class="ae mf" href="https://www.javatpoint.com/linear-regression-vs-logistic-regression-in-machine-learning" rel="noopener ugc nofollow" target="_blank">参考</a></figcaption></figure><h2 id="827b" class="lz ma it bd mj np nq dn mn nr ns dp mr km nt nu mv kq nv nw mz ku nx ny nd nz bi translated"><strong class="ak">朴素贝叶斯</strong></h2><p id="2e9a" class="pw-post-body-paragraph kb kc it kd b ke nf kg kh ki ng kk kl km nh ko kp kq ni ks kt ku nj kw kx ky im bi translated">监督学习算法。</p><p id="2370" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">朴素贝叶斯假设特征是相互独立的，特征之间没有相关性，这就是它幼稚的原因。</p><p id="4493" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">该计算依赖于贝叶斯定理计算。</p><p id="9e30" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">高斯，多项式，伯努利，补数。</p><p id="aa2f" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated"><strong class="kd iu"> <em class="li">举例:</em> </strong>对一篇关于<strong class="kd iu">科技</strong>、<strong class="kd iu">政治</strong>或者<strong class="kd iu">体育</strong>的新闻文章进行分类</p><h2 id="f12f" class="lz ma it bd mj np nq dn mn nr ns dp mr km nt nu mv kq nv nw mz ku nx ny nd nz bi translated"><strong class="ak">K-最近邻</strong></h2><p id="f84b" class="pw-post-body-paragraph kb kc it kd b ke nf kg kh ki ng kk kl km nh ko kp kq ni ks kt ku nj kw kx ky im bi translated">监督学习算法。</p><p id="d4a4" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">选择k，根据聚类的复数做预测。</p><p id="e903" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">在图中，我们看到1个黄色的2个紫色的球，所以当k = 3时，它将是紫色的。</p><p id="b2fd" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated"><em class="li">示例:推荐系统</em></p><figure class="lq lr ls lt gt ju gh gi paragraph-image"><div role="button" tabindex="0" class="ob oc di od bf oe"><div class="gh gi pl"><img src="../Images/55927ab661fdb3819599d9b54ae20cb8.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*AT_0Phqh9MntmYHG5kyQzg.png"/></div></div><figcaption class="jx jy gj gh gi jz ka bd b be z dk translated"><a class="ae mf" href="https://helloacm.com/a-short-introduction-to-k-nearest-neighbors-algorithm/" rel="noopener ugc nofollow" target="_blank">参考</a></figcaption></figure><h2 id="4748" class="lz ma it bd mj np nq dn mn nr ns dp mr km nt nu mv kq nv nw mz ku nx ny nd nz bi translated"><strong class="ak">决策树</strong></h2><p id="9c7d" class="pw-post-body-paragraph kb kc it kd b ke nf kg kh ki ng kk kl km nh ko kp kq ni ks kt ku nj kw kx ky im bi translated">监督学习算法</p><p id="5d4e" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">决策树是由重复的问题及其答案构建而成的。</p><p id="742f" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated"><em class="li">举例:房价预测</em></p><figure class="lq lr ls lt gt ju gh gi paragraph-image"><div role="button" tabindex="0" class="ob oc di od bf oe"><div class="gh gi pm"><img src="../Images/5b91deb0e291a5c5525cd4377c236bff.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*sjqm_sapuaR92EvX1VP2RA.png"/></div></div><figcaption class="jx jy gj gh gi jz ka bd b be z dk translated">来自Kaggle机器学习教程</figcaption></figure><p id="5e52" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">随机森林是许多决策树的集合。</p><h2 id="434f" class="lz ma it bd mj np nq dn mn nr ns dp mr km nt nu mv kq nv nw mz ku nx ny nd nz bi translated"><strong class="ak">支持向量机</strong></h2><p id="bd11" class="pw-post-body-paragraph kb kc it kd b ke nf kg kh ki ng kk kl km nh ko kp kq ni ks kt ku nj kw kx ky im bi translated">监督学习算法</p><p id="a955" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">二分分类法，用一个边距画一个决策边界。</p><figure class="lq lr ls lt gt ju gh gi paragraph-image"><div class="gh gi pn"><img src="../Images/a9bb9382612832f346c004d4dc4f520f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1000/format:webp/1*MyGRpHINcLX2IIbMNkZ8-A.jpeg"/></div><figcaption class="jx jy gj gh gi jz ka bd b be z dk translated"><em class="po">人工智能趋势内幕人士兰斯·艾略特博士</em></figcaption></figure><p id="234d" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated"><em class="li">举例</em> <strong class="kd iu"> <em class="li"> : </em> </strong> <em class="li">语音识别，人脸识别</em></p><div class="of og gp gr oh oi"><a href="https://medium.com/@geencay/past-loan-data-75710e4552ed" rel="noopener follow" target="_blank"><div class="oj ab fo"><div class="ok ab ol cl cj om"><h2 class="bd iu gy z fp on fr fs oo fu fw is bi translated">将分类算法应用于过去的贷款数据</h2><div class="op l"><p class="bd b dl z fp on fr fs oo fu fw dk translated">medium.com</p></div></div><div class="oq l"><div class="pp l os ot ou oq ov jv oi"/></div></div></a></div><div class="of og gp gr oh oi"><a href="https://medium.com/@geencay/face-recognition-algorithms-with-2-different-methods-361276a2ebc0" rel="noopener follow" target="_blank"><div class="oj ab fo"><div class="ok ab ol cl cj om"><h2 class="bd iu gy z fp on fr fs oo fu fw is bi translated">两种不同方法的人脸识别算法</h2><div class="pq l"><h3 class="bd b gy z fp on fr fs oo fu fw dk translated">用两种不同的方法应用人脸识别算法。</h3></div><div class="op l"><p class="bd b dl z fp on fr fs oo fu fw dk translated">medium.com</p></div></div><div class="oq l"><div class="pr l os ot ou oq ov jv oi"/></div></div></a></div><h1 id="4985" class="mi ma it bd mj mk nk mm mn mo nl mq mr ms nm mu mv mw nn my mz na no nc nd ne bi translated"><strong class="ak">聚类</strong></h1><h2 id="a9a4" class="lz ma it bd mj np nq dn mn nr ns dp mr km nt nu mv kq nv nw mz ku nx ny nd nz bi translated"><strong class="ak">现实生活中的例子</strong></h2><ul class=""><li id="5114" class="ox oy it kd b ke nf ki ng km oz kq pa ku pb ky pc pd pe pf bi translated">垃圾邮件过滤器。</li><li id="314a" class="ox oy it kd b ke pg ki ph km pi kq pj ku pk ky pc pd pe pf bi translated">识别假新闻</li><li id="0427" class="ox oy it kd b ke pg ki ph km pi kq pj ku pk ky pc pd pe pf bi translated">识别欺诈或犯罪活动</li></ul><h2 id="a34c" class="lz ma it bd mj np nq dn mn nr ns dp mr km nt nu mv kq nv nw mz ku nx ny nd nz bi translated"><strong class="ak">K-均值聚类</strong></h2><p id="25cf" class="pw-post-body-paragraph kb kc it kd b ke nf kg kh ki ng kk kl km nh ko kp kq ni ks kt ku nj kw kx ky im bi translated">监督学习</p><p id="8b12" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">通过测量距离和计算每个聚类的均值进行聚类，并根据新的均值重新聚类，完成后聚类不会发生变化。</p><figure class="lq lr ls lt gt ju gh gi paragraph-image"><div class="gh gi ps"><img src="../Images/db89c21fe42f1b8566adc442830866c6.png" data-original-src="https://miro.medium.com/v2/resize:fit:868/1*E9R_N48ftoul7kp1y9-OIg.gif"/></div><figcaption class="jx jy gj gh gi jz ka bd b be z dk translated"><a class="ae mf" href="https://aws.amazon.com/blogs/machine-learning/k-means-clustering-with-amazon-sagemaker/" rel="noopener ugc nofollow" target="_blank">参考</a></figcaption></figure><p id="9f5e" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated"><strong class="kd iu"> <em class="li">举例:推荐系统</em> </strong></p><h2 id="2d83" class="lz ma it bd mj np nq dn mn nr ns dp mr km nt nu mv kq nv nw mz ku nx ny nd nz bi translated"><strong class="ak"> DBSCAN聚类算法</strong></h2><p id="1e07" class="pw-post-body-paragraph kb kc it kd b ke nf kg kh ki ng kk kl km nh ko kp kq ni ks kt ku nj kw kx ky im bi translated">无监督学习</p><p id="7013" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">基于密度的技术对于任意形状的簇更有效，如嵌套的圆形。</p><p id="9d14" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated"><strong class="kd iu"> <em class="li">例如:</em> </strong></p><figure class="lq lr ls lt gt ju gh gi paragraph-image"><div role="button" tabindex="0" class="ob oc di od bf oe"><div class="gh gi pt"><img src="../Images/f89118dde58de4bb2db0551187c67443.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*z3nfzF-_KHQFZYoV0zk9Vg.png"/></div></div><figcaption class="jx jy gj gh gi jz ka bd b be z dk translated"><a class="ae mf" href="https://www.analyticsvidhya.com/blog/2020/09/how-dbscan-clustering-works/" rel="noopener ugc nofollow" target="_blank">参考</a></figcaption></figure><h2 id="6e00" class="lz ma it bd mj np nq dn mn nr ns dp mr km nt nu mv kq nv nw mz ku nx ny nd nz bi translated"><strong class="ak">凝聚层次聚类算法</strong></h2><p id="9a58" class="pw-post-body-paragraph kb kc it kd b ke nf kg kh ki ng kk kl km nh ko kp kq ni ks kt ku nj kw kx ky im bi translated">创建一个包含聚类的树，然后递归地分组或分离数据点。</p><p id="3d66" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">无监督学习</p><figure class="lq lr ls lt gt ju gh gi paragraph-image"><div role="button" tabindex="0" class="ob oc di od bf oe"><div class="gh gi pu"><img src="../Images/314a0e45e138ec8ac471fce19ee736eb.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*WF5xCL4nmMsmkS3yvuGLZQ.png"/></div></div><figcaption class="jx jy gj gh gi jz ka bd b be z dk translated"><a class="ae mf" href="https://www.datanovia.com/en/lessons/agglomerative-hierarchical-clustering/" rel="noopener ugc nofollow" target="_blank">参考</a></figcaption></figure><div class="of og gp gr oh oi"><a href="https://medium.com/@geencay/cafe-restaurant-management-in-istanbul-economical-background-f49e544415db" rel="noopener follow" target="_blank"><div class="oj ab fo"><div class="ok ab ol cl cj om"><h2 class="bd iu gy z fp on fr fs oo fu fw is bi translated">伊斯坦布尔的咖啡馆餐厅管理&amp;经济背景</h2><div class="op l"><p class="bd b dl z fp on fr fs oo fu fw dk translated">medium.com</p></div></div><div class="oq l"><div class="pv l os ot ou oq ov jv oi"/></div></div></a></div><h1 id="89d0" class="mi ma it bd mj mk nk mm mn mo nl mq mr ms nm mu mv mw nn my mz na no nc nd ne bi translated"><strong class="ak">机器学习中面临的主要问题及解决方案</strong></h1><h2 id="17b9" class="lz ma it bd mj np nq dn mn nr ns dp mr km nt nu mv kq nv nw mz ku nx ny nd nz bi translated"><strong class="ak">过度拟合</strong></h2><p id="a2d1" class="pw-post-body-paragraph kb kc it kd b ke nf kg kh ki ng kk kl km nh ko kp kq ni ks kt ku nj kw kx ky im bi translated">该模型在训练集上表现良好，但在测试集上表现不佳。</p><p id="8a8e" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">避免过度拟合</p><ul class=""><li id="b620" class="ox oy it kd b ke kf ki kj km pw kq px ku py ky pc pd pe pf bi translated">正规化。</li><li id="8582" class="ox oy it kd b ke pg ki ph km pi kq pj ku pk ky pc pd pe pf bi translated">制作一个简单的模型。使用较少的变量和参数</li><li id="e8d4" class="ox oy it kd b ke pg ki ph km pi kq pj ku pk ky pc pd pe pf bi translated">应用交叉验证方法</li><li id="385c" class="ox oy it kd b ke pg ki ph km pi kq pj ku pk ky pc pd pe pf bi translated">收集更多数据</li><li id="1523" class="ox oy it kd b ke pg ki ph km pi kq pj ku pk ky pc pd pe pf bi translated">移除异常值</li><li id="d50c" class="ox oy it kd b ke pg ki ph km pi kq pj ku pk ky pc pd pe pf bi translated">如果你的一个参数是原因，应用正则化方法。(山脊，套索)</li></ul><h2 id="ee40" class="lz ma it bd mj np nq dn mn nr ns dp mr km nt nu mv kq nv nw mz ku nx ny nd nz bi translated"><strong class="ak">欠配合</strong></h2><p id="74f0" class="pw-post-body-paragraph kb kc it kd b ke nf kg kh ki ng kk kl km nh ko kp kq ni ks kt ku nj kw kx ky im bi translated">模型表现不好，它发生在你的模型太简单的时候。</p><ul class=""><li id="2d1a" class="ox oy it kd b ke kf ki kj km pw kq px ku py ky pc pd pe pf bi translated">选择一个简单的模型(变量较少)</li><li id="abed" class="ox oy it kd b ke pg ki ph km pi kq pj ku pk ky pc pd pe pf bi translated">特征工程</li><li id="27f3" class="ox oy it kd b ke pg ki ph km pi kq pj ku pk ky pc pd pe pf bi translated">降维。</li></ul><h2 id="733d" class="lz ma it bd mj np nq dn mn nr ns dp mr km nt nu mv kq nv nw mz ku nx ny nd nz bi translated"><strong class="ak">缺失数据</strong></h2><p id="10e6" class="pw-post-body-paragraph kb kc it kd b ke nf kg kh ki ng kk kl km nh ko kp kq ni ks kt ku nj kw kx ky im bi translated">当你得到足够的数据时，你可以删除丢失的行。然而，否则，你应该用该列的平均值来填充数据。</p><h1 id="cee7" class="mi ma it bd mj mk nk mm mn mo nl mq mr ms nm mu mv mw nn my mz na no nc nd ne bi translated"><strong class="ak">机器学习中的常用术语</strong></h1><h2 id="5347" class="lz ma it bd mj np nq dn mn nr ns dp mr km nt nu mv kq nv nw mz ku nx ny nd nz bi translated">管道</h2><p id="e618" class="pw-post-body-paragraph kb kc it kd b ke nf kg kh ki ng kk kl km nh ko kp kq ni ks kt ku nj kw kx ky im bi translated">将数据从原始格式转换为有用的格式</p><h2 id="8cad" class="lz ma it bd mj np nq dn mn nr ns dp mr km nt nu mv kq nv nw mz ku nx ny nd nz bi translated">A/B测试</h2><p id="e686" class="pw-post-body-paragraph kb kc it kd b ke nf kg kh ki ng kk kl km nh ko kp kq ni ks kt ku nj kw kx ky im bi translated">评估和比较不同模型的准确性。</p><h2 id="5e8e" class="lz ma it bd mj np nq dn mn nr ns dp mr km nt nu mv kq nv nw mz ku nx ny nd nz bi translated"><strong class="ak">一键编码</strong></h2><p id="46e6" class="pw-post-body-paragraph kb kc it kd b ke nf kg kh ki ng kk kl km nh ko kp kq ni ks kt ku nj kw kx ky im bi translated">将分类变量转换为数值变量，以执行机器学习算法。</p><h2 id="8df2" class="lz ma it bd mj np nq dn mn nr ns dp mr km nt nu mv kq nv nw mz ku nx ny nd nz bi translated"><strong class="ak">训练/测试分割</strong></h2><p id="d874" class="pw-post-body-paragraph kb kc it kd b ke nf kg kh ki ng kk kl km nh ko kp kq ni ks kt ku nj kw kx ky im bi translated">训练测试分割是一种用于评估机器学习算法性能的技术。(80/20)</p><h2 id="9e6d" class="lz ma it bd mj np nq dn mn nr ns dp mr km nt nu mv kq nv nw mz ku nx ny nd nz bi translated"><strong class="ak">梯度下降</strong></h2><p id="d0b8" class="pw-post-body-paragraph kb kc it kd b ke nf kg kh ki ng kk kl km nh ko kp kq ni ks kt ku nj kw kx ky im bi translated">这样做是为了通过操纵参数来减少功能损失。</p><h2 id="54f6" class="lz ma it bd mj np nq dn mn nr ns dp mr km nt nu mv kq nv nw mz ku nx ny nd nz bi translated"><strong class="ak">学习率</strong></h2><p id="e0f3" class="pw-post-body-paragraph kb kc it kd b ke nf kg kh ki ng kk kl km nh ko kp kq ni ks kt ku nj kw kx ky im bi translated">向局部最小值梯度下降的步长。</p><h2 id="b209" class="lz ma it bd mj np nq dn mn nr ns dp mr km nt nu mv kq nv nw mz ku nx ny nd nz bi translated"><strong class="ak">平均绝对误差</strong></h2><p id="760a" class="pw-post-body-paragraph kb kc it kd b ke nf kg kh ki ng kk kl km nh ko kp kq ni ks kt ku nj kw kx ky im bi translated">它用于模型评估，即预测真实误差的平均值。</p><h2 id="04ce" class="lz ma it bd mj np nq dn mn nr ns dp mr km nt nu mv kq nv nw mz ku nx ny nd nz bi translated"><strong class="ak">正常化</strong></h2><p id="0a12" class="pw-post-body-paragraph kb kc it kd b ke nf kg kh ki ng kk kl km nh ko kp kq ni ks kt ku nj kw kx ky im bi translated">将实际值范围转换为标准值范围的过程，通常为-1到+1或0到1。</p><h2 id="5bbd" class="lz ma it bd mj np nq dn mn nr ns dp mr km nt nu mv kq nv nw mz ku nx ny nd nz bi translated"><strong class="ak">混淆矩阵</strong></h2><p id="d5c2" class="pw-post-body-paragraph kb kc it kd b ke nf kg kh ki ng kk kl km nh ko kp kq ni ks kt ku nj kw kx ky im bi translated">分类模型评估表。</p><h2 id="517d" class="lz ma it bd mj np nq dn mn nr ns dp mr km nt nu mv kq nv nw mz ku nx ny nd nz bi translated"><strong class="ak">假阳性/假阴性</strong></h2><p id="3dfd" class="pw-post-body-paragraph kb kc it kd b ke nf kg kh ki ng kk kl km nh ko kp kq ni ks kt ku nj kw kx ky im bi translated">模型错误地预测了负类。</p><p id="456e" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">模型错误地预测了正类</p><h2 id="cab4" class="lz ma it bd mj np nq dn mn nr ns dp mr km nt nu mv kq nv nw mz ku nx ny nd nz bi translated"><strong class="ak">深度学习</strong></h2><p id="5f27" class="pw-post-body-paragraph kb kc it kd b ke nf kg kh ki ng kk kl km nh ko kp kq ni ks kt ku nj kw kx ky im bi translated">它是机器学习的子集，意味着复制人类的思维过程，并包含具有几层的神经网络。该层标记的名称为“深度”。</p><p id="7836" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">ml和dl之间有许多不同之处，但这是区分它们的一种方法，可以通过查找过程来实现。深度学习本身确实具有工程特征，但在机器学习中，你必须自己完成。</p><p id="bed1" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated"><strong class="kd iu">分类或回归</strong></p><p id="5e57" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">分类-分类变量</p><p id="43e0" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">回归-数字变量</p><h2 id="37a0" class="lz ma it bd mj np nq dn mn nr ns dp mr km nt nu mv kq nv nw mz ku nx ny nd nz bi translated"><strong class="ak">偏差&amp;方差</strong></h2><p id="df50" class="pw-post-body-paragraph kb kc it kd b ke nf kg kh ki ng kk kl km nh ko kp kq ni ks kt ku nj kw kx ky im bi translated">当(预测值-实际值)过高时，就会发生这种情况。</p><p id="6d66" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">方差-当你使用不同的训练数据时，你的模型会发生变化。这个变化就是你的方差。</p><p id="658b" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">在一个好的模型中，方差应该很低。</p><p id="6cdf" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated"><strong class="kd iu">精确&amp;召回</strong></p><p id="37f3" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">精度-正预测值</p><p id="4717" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">精度= TP / TP+ FP</p><p id="02f9" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">回忆敏感性。</p><p id="d692" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">召回= TP / TP +FN)</p><p id="a80f" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">TP:真阳性</p><p id="e4e3" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">FP:假阳性</p><p id="770a" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">FN:假阴性</p><h2 id="8185" class="lz ma it bd mj np nq dn mn nr ns dp mr km nt nu mv kq nv nw mz ku nx ny nd nz bi translated"><strong class="ak">推荐系统</strong></h2><p id="dbee" class="pw-post-body-paragraph kb kc it kd b ke nf kg kh ki ng kk kl km nh ko kp kq ni ks kt ku nj kw kx ky im bi translated">很简单，一旦你看了一部关于网飞的电影，你可能也会喜欢这部电影</p><p id="d3dd" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">Spotify和亚马逊也使用这种算法。</p><h2 id="f784" class="lz ma it bd mj np nq dn mn nr ns dp mr km nt nu mv kq nv nw mz ku nx ny nd nz bi translated"><strong class="ak">降维</strong></h2><p id="aec0" class="pw-post-body-paragraph kb kc it kd b ke nf kg kh ki ng kk kl km nh ko kp kq ni ks kt ku nj kw kx ky im bi translated">它减少了你做预测的变量的数量。</p><p id="36d7" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">通过应用特征工程、移除共线特征或使用算法降维。(PCA)</p><h2 id="4ad9" class="lz ma it bd mj np nq dn mn nr ns dp mr km nt nu mv kq nv nw mz ku nx ny nd nz bi translated"><strong class="ak"> PCA </strong></h2><p id="1ee2" class="pw-post-body-paragraph kb kc it kd b ke nf kg kh ki ng kk kl km nh ko kp kq ni ks kt ku nj kw kx ky im bi translated">无监督算法。</p><p id="79ae" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">有时也在监督算法应用于监督算法之前使用。</p><h2 id="068a" class="lz ma it bd mj np nq dn mn nr ns dp mr km nt nu mv kq nv nw mz ku nx ny nd nz bi translated"><strong class="ak"> F1得分</strong></h2><p id="d500" class="pw-post-body-paragraph kb kc it kd b ke nf kg kh ki ng kk kl km nh ko kp kq ni ks kt ku nj kw kx ky im bi translated">它是通过使用精度和召回率来计算的。也称为加权平均。</p><p id="c08e" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">它的计算方法是乘以精度，再除以总精度和召回率乘以2。</p><p id="e161" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">2 *(P * R / P + R)</p><p id="5c0d" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">P =精度</p><p id="6d64" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">R =回忆</p><p id="2607" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated"><strong class="kd iu">第一类错误&amp;第二类错误</strong></p><p id="0d84" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">类型I-零假设是真的，但我们拒绝它。</p><p id="9b10" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">第二类——不管我们接受与否，零假设都是错误的。</p><h2 id="3904" class="lz ma it bd mj np nq dn mn nr ns dp mr km nt nu mv kq nv nw mz ku nx ny nd nz bi translated"><strong class="ak">关联</strong></h2><p id="d296" class="pw-post-body-paragraph kb kc it kd b ke nf kg kh ki ng kk kl km nh ko kp kq ni ks kt ku nj kw kx ky im bi translated">相关性:两个随机变量的相关性有多强</p><h2 id="23ea" class="lz ma it bd mj np nq dn mn nr ns dp mr km nt nu mv kq nv nw mz ku nx ny nd nz bi translated"><strong class="ak">集成学习</strong></h2><p id="1871" class="pw-post-body-paragraph kb kc it kd b ke nf kg kh ki ng kk kl km nh ko kp kq ni ks kt ku nj kw kx ky im bi translated">组合从多个ML模型收集的结果以提高模型效率。</p><h2 id="22ba" class="lz ma it bd mj np nq dn mn nr ns dp mr km nt nu mv kq nv nw mz ku nx ny nd nz bi translated"><strong class="ak">交叉验证</strong></h2><p id="b083" class="pw-post-body-paragraph kb kc it kd b ke nf kg kh ki ng kk kl km nh ko kp kq ni ks kt ku nj kw kx ky im bi translated">通过测试定型集的其他部分来评估模型归纳新数据的能力。</p><h1 id="eaae" class="mi ma it bd mj mk nk mm mn mo nl mq mr ms nm mu mv mw nn my mz na no nc nd ne bi translated">结论</h1><p id="a7ce" class="pw-post-body-paragraph kb kc it kd b ke nf kg kh ki ng kk kl km nh ko kp kq ni ks kt ku nj kw kx ky im bi translated">我在准备面试时为自己制定了这个指南，它对我帮助很大。</p><p id="33bd" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">我希望它也能帮助你，你会找到你梦想的工作。</p><figure class="lq lr ls lt gt ju"><div class="bz fp l di"><div class="pz mh l"/></div><figcaption class="jx jy gj gh gi jz ka bd b be z dk translated"><a class="ae mf" href="https://media.giphy.com/media/nz94Hdu9eWFFK8ClHS/giphy.gif" rel="noopener ugc nofollow" target="_blank">参考</a></figcaption></figure><p id="abfa" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">感谢阅读我的文章，如果你想阅读更多类似的文章，请竖起大拇指关注我。</p><p id="7fa9" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">下面是这篇文章。</p><div class="of og gp gr oh oi"><a rel="noopener  ugc nofollow" target="_blank" href="/machine-learning-a-z-briefly-explained-part-2-61191a01c235"><div class="oj ab fo"><div class="ok ab ol cl cj om"><h2 class="bd iu gy z fp on fr fs oo fu fw is bi translated">机器学习A-Z简要解释了第2部分</h2><div class="pq l"><h3 class="bd b gy z fp on fr fs oo fu fw dk translated">提神和快速回忆</h3></div><div class="op l"><p class="bd b dl z fp on fr fs oo fu fw dk translated">pub.towardsai.net</p></div></div><div class="oq l"><div class="qa l os ot ou oq ov jv oi"/></div></div></a></div></div></div>    
</body>
</html>