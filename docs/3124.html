<html>
<head>
<title>Latent Diffusion Explained Simply (with Pokémon)</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">简单解释了潜在扩散(用神奇宝贝)</h1>
<blockquote>原文：<a href="https://pub.towardsai.net/latent-diffusion-explained-simply-with-pok%C3%A9mon-3ebe15a3a019?source=collection_archive---------0-----------------------#2022-09-16">https://pub.towardsai.net/latent-diffusion-explained-simply-with-pok%C3%A9mon-3ebe15a3a019?source=collection_archive---------0-----------------------#2022-09-16</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="ca4c" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">从文本到图像，图像到图像和修复-潜在的扩散革命。</h2></div><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ki"><img src="../Images/9f398e711f816b155785255c4d24d492.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*9AWk73MasXF2Yj5u7t-82A.png"/></div></div></figure><p id="6126" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">在过去的几个月里，潜在扩散一直是人们关注的焦点，人们根据文本提示生成各种各样的图像。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi lq"><img src="../Images/e43df41920da6ac229673396310df95c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*QptEhWLdwzuxp0SNcxRlYA.png"/></div></div><figcaption class="lr ls gj gh gi lt lu bd b be z dk translated">使用稳定扩散生成的图像，提示“一张宇航员骑马的照片”</figcaption></figure><p id="1c29" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">看到如此高的质量，你会想这项技术将来会有什么用途。我说的不仅仅是图像。想象一个程序性构建的3D世界，玩家在游戏中探索一个区域，设计新的酶，比如说，纯粹基于描述来消化塑料，甚至根据科学论文产生假设/问题/修正(每个博士生的梦想)。</p><p id="e590" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">通过这篇文章，我想深入挖掘这些模型，并(试图)解释它们是如何工作的(与神奇宝贝)。最后，您应该对输入文本提示后发生的事情有了直观的理解。我的结构有点不同于平时:首先，介绍主题，然后是一些视觉效果和直觉，最后是更深入的解释。正如那句名言所说:</p><blockquote class="lv"><p id="bc86" class="lw lx it bd ly lz ma mb mc md me lp dk translated">“如果你不能简单地解释它，你就不够了解它”</p></blockquote><p id="9aa1" class="pw-post-body-paragraph ku kv it kw b kx mf ju kz la mg jx lc ld mh lf lg lh mi lj lk ll mj ln lo lp im bi translated">为什么是神奇宝贝？因为你可能很熟悉这些游戏，而且有可能你喜欢玩这些游戏。此外，它相对来说是小众的，因此它应该将模型推出其“舒适区”(即潜在空间中人口较少的部分)。</p><p id="9ec8" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">如果你想玩玩这个模型，试试这里的演示:</p><div class="mk ml gp gr mm mn"><a href="https://huggingface.co/spaces/stabilityai/stable-diffusion" rel="noopener  ugc nofollow" target="_blank"><div class="mo ab fo"><div class="mp ab mq cl cj mr"><h2 class="bd iu gy z fp ms fr fs mt fu fw is bi translated">稳定扩散——稳定的拥抱面空间</h2><div class="mu l"><h3 class="bd b gy z fp ms fr fs mt fu fw dk translated">发现由社区制作的令人惊叹的ML应用程序</h3></div><div class="mv l"><p class="bd b dl z fp ms fr fs mt fu fw dk translated">huggingface.co</p></div></div><div class="mw l"><div class="mx l my mz na mw nb ks mn"/></div></div></a></div><p id="9d76" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">或者，您可以使用搜索引擎Lexica(<a class="ae nc" href="https://lexica.art" rel="noopener ugc nofollow" target="_blank">https://Lexica . art</a>)浏览生成的图像集合</p><p id="8484" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">让我们深入了解一些使用案例！</p></div><div class="ab cl nd ne hx nf" role="separator"><span class="ng bw bk nh ni nj"/><span class="ng bw bk nh ni nj"/><span class="ng bw bk nh ni"/></div><div class="im in io ip iq"><h1 id="9709" class="nk nl it bd nm nn no np nq nr ns nt nu jz nv ka nw kc nx kd ny kf nz kg oa ob bi translated">文本到图像</h1><p id="d254" class="pw-post-body-paragraph ku kv it kw b kx oc ju kz la od jx lc ld oe lf lg lh of lj lk ll og ln lo lp im bi translated"><strong class="kw iu">文本到图像</strong>可能是潜在扩散模型最著名的应用(至少根据我的Twitter消息)。很像条件VAE，我们使用文本提示(y)根据分布p(z|y)有条件地生成，从而作为潜在空间区域的向导。</p><p id="43bb" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">我用“皮卡丘”做了实验，我想模型应该看过它的照片。此外，我还插入了文森特·梵高的《星夜》和加那利群岛的位置提示。前者应该推动模型绘制一个符合艺术风格的2D皮卡丘，而后者作为一个真实世界的位置，可能会产生一个3D皮卡丘。</p><h2 id="3c51" class="oh nl it bd nm oi oj dn nq ok ol dp nu ld om on nw lh oo op ny ll oq or oa os bi translated">结果</h2><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ot"><img src="../Images/7f1bb1c701556091f22b33ff3dd01f8b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*_NAR7VjjGwGe52SMJI0BNQ.png"/></div></div><figcaption class="lr ls gj gh gi lt lu bd b be z dk translated">提示:“星夜画中的一只皮卡丘冲浪”</figcaption></figure><p id="80ad" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">这相当漂亮——即使考虑到皮卡丘偶尔的畸形。第一张照片可能是我最喜欢的，因为它甚至拿起了教堂般的建筑，并添加了一个领域。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ot"><img src="../Images/9db9c51d4a487d79dfef5e329578cfd8.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*RgF-iJPvEsj-rAG1o_nBSA.png"/></div></div><figcaption class="lr ls gj gh gi lt lu bd b be z dk translated">提示:“加那利群岛的皮卡丘冲浪”</figcaption></figure><p id="6487" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">在得到冲浪板和水方面肯定更成功。一个有趣的细节是在加那利群岛的一些图片中的沙丘:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ot"><img src="../Images/1abea2cbba88b0d00e8135a72f13004e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Aih19vmmXlftz7Xx_mCQPQ.png"/></div></div><figcaption class="lr ls gj gh gi lt lu bd b be z dk translated">大加那利岛的沙丘——布莱恩·李摄影<a class="ae nc" href="https://bryanli.io" rel="noopener ugc nofollow" target="_blank"> https://bryanli.io </a></figcaption></figure><h2 id="8ef9" class="oh nl it bd nm oi oj dn nq ok ol dp nu ld om on nw lh oo op ny ll oq or oa os bi translated">它是如何工作的</h2><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ot"><img src="../Images/236c5b3d0414f7d95e238f4f3685390b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*UJtTvjYpg2D9YquvyX2ung.png"/></div></div></figure><p id="5ce1" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">输入y由特定域编码器(tau_theta)预处理，以产生表示tau_theta(y)。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi ou"><img src="../Images/70ac6eef73a107af733f482d697386dd.png" data-original-src="https://miro.medium.com/v2/resize:fit:448/format:webp/1*M9wHTT2fsBYbdgqUsbkTiw.png"/></div><figcaption class="lr ls gj gh gi lt lu bd b be z dk translated">由tau_theta编码的调节步骤，用于调节生成过程。图片来自https://arxiv.org/abs/2112.10752<a class="ae nc" href="https://arxiv.org/abs/2112.10752" rel="noopener ugc nofollow" target="_blank"/></figcaption></figure><p id="bd2e" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">基本的UNet架构是通过交叉注意力层实现的，这意味着在UNet的每个单元，注意力被计算，然后传递到后面的层。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ot"><img src="../Images/b72f69acdf93eda22da885359f62fa3a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*GFpAk8To1MYmWL8Y8DT2ew.png"/></div></div></figure><p id="6df8" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">注意力通常用查询、键、值术语来表达。这里，这些值将通过考虑域特定编码器tau_theta(y)的输出来修改，如此:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ov"><img src="../Images/614ce9ca46bda71de5bafff0c8193987.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*UTqSpSMPUTDaT5azDOc_yA.png"/></div></div></figure><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ow"><img src="../Images/cd7cf34ef831047ee5d66ea00add1ad9.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*tlS9VQW6fO1Gkqutjh64JA.png"/></div></div></figure><p id="e9fd" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">这意味着我们正在对提示进行编码，以调节去噪步骤，从而输出符合描述的图像。</p></div><div class="ab cl nd ne hx nf" role="separator"><span class="ng bw bk nh ni nj"/><span class="ng bw bk nh ni nj"/><span class="ng bw bk nh ni"/></div><div class="im in io ip iq"><h1 id="d9eb" class="nk nl it bd nm nn no np nq nr ns nt nu jz nv ka nw kc nx kd ny kf nz kg oa ob bi translated">图像到图像</h1><p id="0d20" class="pw-post-body-paragraph ku kv it kw b kx oc ju kz la od jx lc ld oe lf lg lh of lj lk ll og ln lo lp im bi translated">这个任务非常类似于<strong class="kw iu">文本到图像</strong>。然而，输入是作为提示的图像。然后使用特定于域的编码器tau_theta(y)对图像进行编码，并将其像文本一样输入到模型中。除了图像之外，您还可以输入文本提示来进一步指导生成过程。</p><h2 id="841b" class="oh nl it bd nm oi oj dn nq ok ol dp nu ld om on nw lh oo op ny ll oq or oa os bi translated">结果</h2><p id="d736" class="pw-post-body-paragraph ku kv it kw b kx oc ju kz la od jx lc ld oe lf lg lh of lj lk ll og ln lo lp im bi translated">我对模型的输入是:</p><ol class=""><li id="d277" class="ox oy it kw b kx ky la lb ld oz lh pa ll pb lp pc pd pe pf bi translated">"火型神奇宝贝吐出蓝色火焰."</li><li id="462c" class="ox oy it kw b kx pg la ph ld pi lh pj ll pk lp pc pd pe pf bi translated">这个涂鸦(我知道，看起来很可怕):</li></ol><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ot"><img src="../Images/bc46ea02cfb7180849f328c242b02527.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*5VyW9f__M9mDY1VlKBdf7Q.png"/></div></div><figcaption class="lr ls gj gh gi lt lu bd b be z dk translated">涂鸦输入。</figcaption></figure><p id="155e" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">结果让我大吃一惊:</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="pl pm l"/></div><figcaption class="lr ls gj gh gi lt lu bd b be z dk translated">生成的图像设置–强度0.8–n _ ITER 30，并提示“一个火型口袋妖怪吐蓝火”</figcaption></figure><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi pn"><img src="../Images/399f2c95debd3a87cd9afc228d970f57.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Mj954LvthhULf2b7eWixrQ.png"/></div></div><figcaption class="lr ls gj gh gi lt lu bd b be z dk translated">来自上面GIF的静态样本。</figcaption></figure><p id="d9b7" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">这些大多数看起来像神奇宝贝，其中几个集成了蓝色的火焰。</p><p id="9d59" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">可惜他们都没有把拓法特当拓法特用(这个可以怪我的画图技术)，但是大部分都用了头上的黑色。</p></div><div class="ab cl nd ne hx nf" role="separator"><span class="ng bw bk nh ni nj"/><span class="ng bw bk nh ni nj"/><span class="ng bw bk nh ni"/></div><div class="im in io ip iq"><h1 id="9544" class="nk nl it bd nm nn no np nq nr ns nt nu jz nv ka nw kc nx kd ny kf nz kg oa ob bi translated">修补</h1><p id="ccd5" class="pw-post-body-paragraph ku kv it kw b kx oc ju kz la od jx lc ld oe lf lg lh of lj lk ll og ln lo lp im bi translated"><strong class="kw iu">修补</strong>是根据蒙版移除或替换图像中的对象。我记得早在2010年(或者可能更早)，当Photoshop将它作为“愈合画笔”的一部分发布时，我感到非常惊讶。</p><p id="d7b0" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">你猜对了，潜在扩散模型也可以用于此。HuggingFace有一个非常直观的用户界面，您可以在图像本身上绘制遮罩:</p><div class="mk ml gp gr mm mn"><a href="https://huggingface.co/spaces/fffiloni/stable-diffusion-inpainting" rel="noopener  ugc nofollow" target="_blank"><div class="mo ab fo"><div class="mp ab mq cl cj mr"><h2 class="bd iu gy z fp ms fr fs mt fu fw is bi translated">用fffiloni修复稳定扩散CPU - a拥抱人脸空间</h2><div class="mu l"><h3 class="bd b gy z fp ms fr fs mt fu fw dk translated">发现由社区制作的令人惊叹的ML应用程序</h3></div><div class="mv l"><p class="bd b dl z fp ms fr fs mt fu fw dk translated">huggingface.co</p></div></div><div class="mw l"><div class="po l my mz na mw nb ks mn"/></div></div></a></div><h2 id="465c" class="oh nl it bd nm oi oj dn nq ok ol dp nu ld om on nw lh oo op ny ll oq or oa os bi translated">结果</h2><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ot"><img src="../Images/30fe672bc57e9ee4c7666fcf842db0f3.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*QQiWDem2hYvFvS6YATZWcw.png"/></div></div><figcaption class="lr ls gj gh gi lt lu bd b be z dk translated">输入左边的图像和蒙版。右边生成的图像。</figcaption></figure><p id="5a10" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">这顶帽子看起来有点像哈利波特分院帽的压扁版本——在人工智能的防御中，我们确实给了它一个相当小的面具。我还喜欢它适应了视频游戏的风格。</p><p id="01b0" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">还有一些其他因素需要注意:</p><ol class=""><li id="c922" class="ox oy it kw b kx ky la lb ld oz lh pa ll pb lp pc pd pe pf bi translated">有人试图固定帽子周围的地板。这并不惊人，但这是一个开始。</li><li id="0c4a" class="ox oy it kw b kx pg la ph ld pi lh pj ll pk lp pc pd pe pf bi translated">在生成的图像中，黎明的眼睛显得更暗，几乎是空洞的。她的嘴也微微变了形。我认为这是由于在编码和解码步骤中丢失了信息</li></ol><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ot"><img src="../Images/f3c1a4311424d3a7abe13cec014d63e7.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*389kGThSlR5mhobrlxoFkA.png"/></div></div><figcaption class="lr ls gj gh gi lt lu bd b be z dk translated">从上一张图片放大</figcaption></figure><p id="4286" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">最后，我还试图创造一个新角色:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ot"><img src="../Images/bd1f68fdbb8e23eaad7a4140329039b2.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*yf8WzG0xFCBIFVq3hUDxhQ.png"/></div></div><figcaption class="lr ls gj gh gi lt lu bd b be z dk translated">输入左边的图像和蒙版。右边生成的图像。</figcaption></figure><p id="b0e7" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">它有一个背包，一顶形状怪异的帽子和腿。“蓝色”提示被部分用于裤子和帽子。</p><h2 id="2d79" class="oh nl it bd nm oi oj dn nq ok ol dp nu ld om on nw lh oo op ny ll oq or oa os bi translated">它是如何工作的</h2><p id="bf19" class="pw-post-body-paragraph ku kv it kw b kx oc ju kz la od jx lc ld oe lf lg lh of lj lk ll og ln lo lp im bi translated">与<strong class="kw iu">图像到图像</strong>非常相似，在<strong class="kw iu">修复</strong>过程中，我们修改了蒙版区域(<strong class="kw iu">未知区域</strong>)，同时保持图像的其余部分(<strong class="kw iu">已知区域</strong>))固定不变。与其他模型一样，我们可以输入一个文本提示，它将被编码并与图像的已知区域一起传递。然后，模型将使用符合区域形状和文本提示的图像来填充未知区域。</p><p id="d559" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">前面，我提到了潜在表示在计算和速度上的优势。对于<strong class="kw iu">修复</strong>，潜在扩散模型至少比<strong class="kw iu">快2.7倍</strong>，弗雷歇初始距离(FID) 增加了<strong class="kw iu">1.6倍。该度量量化了真实图像和生成图像之间的分布差异(平均值和标准偏差),而不是逐像素度量。这个想法是，它试图模仿图像之间相似性的“感知”。</strong></p></div><div class="ab cl nd ne hx nf" role="separator"><span class="ng bw bk nh ni nj"/><span class="ng bw bk nh ni nj"/><span class="ng bw bk nh ni"/></div><div class="im in io ip iq"><h1 id="400f" class="nk nl it bd nm nn no np nq nr ns nt nu jz nv ka nw kc nx kd ny kf nz kg oa ob bi translated">其他用途</h1><p id="8b47" class="pw-post-body-paragraph ku kv it kw b kx oc ju kz la od jx lc ld oe lf lg lh of lj lk ll og ln lo lp im bi translated">该论文介绍了潜在扩散模型可以使用的其他方式:图像<strong class="kw iu">超分辨率</strong>和<strong class="kw iu">布局到图像合成</strong>。</p><p id="54f0" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated"><strong class="kw iu">图像超分辨率</strong>是从低分辨率图像生成高分辨率图像的过程。它在生物医学应用中特别有用，如MRI扫描。我怀疑，如果不进行任何再培训，这种模式能否有效地用于此类任务。然而，对于普通图像，结果在视觉上是令人愉快的:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ot"><img src="../Images/de61dac25bbcf00583b314ef19ca0eef.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*6nCpebP2Q7A3yQLzA8ltCg.png"/></div></div><figcaption class="lr ls gj gh gi lt lu bd b be z dk translated">图片来自原论文<a class="ae nc" href="https://arxiv.org/abs/2112.10752" rel="noopener ugc nofollow" target="_blank">https://arxiv.org/abs/2112.10752</a></figcaption></figure><p id="fe84" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated"><strong class="kw iu">布局到图像合成</strong>旨在生成符合边界框的图像，该边界框指导图像特定位置元素的生成。这是一个例子:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ot"><img src="../Images/9b88a30a6159fc75cdfe1e109a5226b0.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*gekbNsiNf3U-OaBn_I0cEw.png"/></div></div><figcaption class="lr ls gj gh gi lt lu bd b be z dk translated">图片来自原论文<a class="ae nc" href="https://arxiv.org/abs/2112.10752" rel="noopener ugc nofollow" target="_blank">https://arxiv.org/abs/2112.10752</a></figcaption></figure></div><div class="ab cl nd ne hx nf" role="separator"><span class="ng bw bk nh ni nj"/><span class="ng bw bk nh ni nj"/><span class="ng bw bk nh ni"/></div><div class="im in io ip iq"><h1 id="d5a8" class="nk nl it bd nm nn no np nq nr ns nt nu jz nv ka nw kc nx kd ny kf nz kg oa ob bi translated">局限性和道德考量</h1><ol class=""><li id="c85d" class="ox oy it kw b kx oc la od ld pp lh pq ll pr lp pc pd pe pf bi translated">一个非常直观的限制是，在没有任何关于主题的先验知识的情况下，该模型无法生成图像。例如，如果不知道星空是什么样子，就不可能生成与之相关的图像。有趣的是，是否可以纯粹基于文本描述而不用梵高的任何画作来生成相似的图像。</li><li id="8f7c" class="ox oy it kw b kx pg la ph ld pi lh pj ll pk lp pc pd pe pf bi translated">人工智能模型的潜在滥用可能会产生重大的社会影响，例如，创建与垃圾邮件/新闻或攻击性图像相关的虚假图像。原始存储库有几个NSFW过滤器，用于隐藏攻击性图像，并在图像上放置不可见的水印，尽管鉴于该模型的开源性质，绕过它并非不可能。</li><li id="94b6" class="ox oy it kw b kx pg la ph ld pi lh pj ll pk lp pc pd pe pf bi translated">这些模型特别容易受到语言偏见的影响，并可能在生成图像时显示出来。因此，人工智能有可能误解提示并生成潜在的无关图像。</li><li id="7fbd" class="ox oy it kw b kx pg la ph ld pi lh pj ll pk lp pc pd pe pf bi translated">这种模型已经被用于生成艺术，甚至赢得了艺术比赛(而评委不知道这是人工智能生成的)。这应该被允许吗？还有，你会对(只)使用潜在扩散模型的艺术比赛感兴趣吗？</li></ol><div class="mk ml gp gr mm mn"><a href="https://slate.com/technology/2022/09/ai-artists-colorado-art-competition-midjourney.html" rel="noopener  ugc nofollow" target="_blank"><div class="mo ab fo"><div class="mp ab mq cl cj mr"><h2 class="bd iu gy z fp ms fr fs mt fu fw is bi translated">一个人工智能在比赛中打败了人类艺术家。接下来会是他们的工作吗？</h2><div class="mu l"><h3 class="bd b gy z fp ms fr fs mt fu fw dk translated">听听接下来的内容:TBD:上个月，一件名为“空间剧院”的艺术品(法语是“空间歌剧”的意思)</h3></div><div class="mv l"><p class="bd b dl z fp ms fr fs mt fu fw dk translated">slate.com</p></div></div><div class="mw l"><div class="ps l my mz na mw nb ks mn"/></div></div></a></div><h1 id="f85c" class="nk nl it bd nm nn pt np nq nr pu nt nu jz pv ka nw kc pw kd ny kf px kg oa ob bi translated">结论</h1><p id="76c4" class="pw-post-body-paragraph ku kv it kw b kx oc ju kz la od jx lc ld oe lf lg lh of lj lk ll og ln lo lp im bi translated">在这篇文章中，我介绍了潜在扩散模型的三种用途:<strong class="kw iu">文本到图像</strong>、<strong class="kw iu">图像到图像</strong>和<strong class="kw iu">修复</strong>。我探索了(在神奇宝贝的上下文中)如何使用这些技术来生成图像以及每个生成的图像的特殊细节。</p><p id="81d4" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">还有其他方式可以使用这些模型，例如用于图像超分辨率和布局到图像的合成。如果你想对这篇博文的某些部分进行更精确的解释，我强烈推荐原文:</p><div class="mk ml gp gr mm mn"><a href="https://arxiv.org/abs/2112.10752" rel="noopener  ugc nofollow" target="_blank"><div class="mo ab fo"><div class="mp ab mq cl cj mr"><h2 class="bd iu gy z fp ms fr fs mt fu fw is bi translated">利用潜在扩散模型的高分辨率图像合成</h2><div class="mu l"><h3 class="bd b gy z fp ms fr fs mt fu fw dk translated">通过将图像形成过程分解为去噪自动编码器、扩散模型…</h3></div><div class="mv l"><p class="bd b dl z fp ms fr fs mt fu fw dk translated">arxiv.org</p></div></div><div class="mw l"><div class="py l my mz na mw nb ks mn"/></div></div></a></div><p id="3934" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">或者这篇博文:</p><div class="mk ml gp gr mm mn"><a href="https://lilianweng.github.io/posts/2021-07-11-diffusion-models/#what-are-diffusion-models" rel="noopener  ugc nofollow" target="_blank"><div class="mo ab fo"><div class="mp ab mq cl cj mr"><h2 class="bd iu gy z fp ms fr fs mt fu fw is bi translated">什么是扩散模型？</h2><div class="mu l"><h3 class="bd b gy z fp ms fr fs mt fu fw dk translated">更新于2021-09-19:强烈推荐这篇由宋洋(作者…</h3></div><div class="mv l"><p class="bd b dl z fp ms fr fs mt fu fw dk translated">lilianweng.github.io</p></div></div></div></a></div><p id="6559" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated"><em class="pz">免责声明:</em>本帖所有生成的图片均由stable diffusion(和我)使用官方GitHub代码创建:</p><div class="mk ml gp gr mm mn"><a href="https://github.com/CompVis/stable-diffusion" rel="noopener  ugc nofollow" target="_blank"><div class="mo ab fo"><div class="mp ab mq cl cj mr"><h2 class="bd iu gy z fp ms fr fs mt fu fw is bi translated">GitHub-CompVis/stable-diffusion:一个潜在的文本到图像的扩散模型</h2><div class="mu l"><h3 class="bd b gy z fp ms fr fs mt fu fw dk translated">由于与Stability AI和Runway的合作，稳定的扩散成为可能，并建立在我们以前的…</h3></div><div class="mv l"><p class="bd b dl z fp ms fr fs mt fu fw dk translated">github.com</p></div></div><div class="mw l"><div class="qa l my mz na mw nb ks mn"/></div></div></a></div><p id="4901" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">如果你发现任何错误或不准确，请随时评论/联系我，我会更新文章(并在特别感谢部分包括你)。</p></div></div>    
</body>
</html>