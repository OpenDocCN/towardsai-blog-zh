<html>
<head>
<title>How to Handle Imbalanced Data in ML Classification using Python</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">如何使用Python处理ML分类中的不平衡数据</h1>
<blockquote>原文：<a href="https://pub.towardsai.net/important-techniques-to-handle-imbalanced-data-in-machine-learning-python-3b0cb44a12bf?source=collection_archive---------1-----------------------#2022-09-18">https://pub.towardsai.net/important-techniques-to-handle-imbalanced-data-in-machine-learning-python-3b0cb44a12bf?source=collection_archive---------1-----------------------#2022-09-18</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><p id="8e19" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">在本文中，我们将讨论什么是不平衡数据，我们应该使用哪些指标来评估具有不平衡数据的模型，以及用于处理不平衡数据的技术。</p><p id="620d" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">在进行二元分类时，几乎每个数据科学家都可能遇到过处理不平衡数据的问题。通常，当数据集分布不均时，即当一个类中的数据点频率或行数比其他类中的数据点频率或行数多得多时，就会出现不平衡数据。</p><p id="6f1c" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">例如，假设我们有一个covid数据集，我们的目标类是一个人是否有covid，如果我们类中的正比率是10%，负比率是90%，那么我们可以说我们的数据是不平衡的。</p><figure class="km kn ko kp gt kq gh gi paragraph-image"><div class="gh gi kl"><img src="../Images/27e4c5f36e0847f0a8e74a73bf284e5f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1050/format:webp/1*L8Qpb4sXNP92KCoAz94Ybw.png"/></div><figcaption class="kt ku gj gh gi kv kw bd b be z dk translated">作者图片</figcaption></figure><h2 id="812a" class="kx ky iq bd kz la lb dn lc ld le dp lf jy lg lh li kc lj lk ll kg lm ln lo lp bi translated">不平衡数据的问题</h2><p id="e9f8" class="pw-post-body-paragraph jn jo iq jp b jq lq js jt ju lr jw jx jy ls ka kb kc lt ke kf kg lu ki kj kk ij bi translated">大多数机器学习算法的设计都是为了提高准确性和减少错误。在这个过程中，他们不考虑阶级的分布。此外，决策树和逻辑回归等标准机器学习算法偏向多数类，往往会忽略少数类。因此，在这些情况下，即使模型具有95%的准确性，也不能说它是完美的模型，因为测试数据中类别数量的频率可能是95%，并且5%的错误预测数据必须来自少数类别。</p><h2 id="f0a3" class="kx ky iq bd kz la lb dn lc ld le dp lf jy lg lh li kc lj lk ll kg lm ln lo lp bi translated">准确性陷阱</h2><p id="621e" class="pw-post-body-paragraph jn jo iq jp b jq lq js jt ju lr jw jx jy ls ka kb kc lt ke kf kg lu ki kj kk ij bi translated">在深入处理不平衡数据集之前，让我们了解一下在评估模型时应该使用的度量标准。通常，accuracy_score的计算方法是正确预测数与预测总数的比率。</p><p id="81d2" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">准确度=正确预测数/预测总数。</p><p id="9345" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">所以我们可以看到，accuracy_score是不会考虑班级分布的。它只关注正确预测的数量。因此，即使我们获得了95+的准确性，如上面的示例所示，我们也不能保证模型的性能及其对少数类的预测。</p><p id="410d" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">因此，对于分类技术，建议使用混淆矩阵、精确度分数、召回分数和ROC曲线下面积(AUC)代替精确度分数作为评估指标。</p><h2 id="e02c" class="kx ky iq bd kz la lb dn lc ld le dp lf jy lg lh li kc lj lk ll kg lm ln lo lp bi translated"><strong class="ak">处理不平衡数据</strong></h2><p id="b189" class="pw-post-body-paragraph jn jo iq jp b jq lq js jt ju lr jw jx jy ls ka kb kc lt ke kf kg lu ki kj kk ij bi translated">处理不平衡数据时广泛使用的一种技术是采样。有两种类型的取样—</p><ul class=""><li id="c436" class="lv lw iq jp b jq jr ju jv jy lx kc ly kg lz kk ma mb mc md bi translated">欠采样</li><li id="7c70" class="lv lw iq jp b jq me ju mf jy mg kc mh kg mi kk ma mb mc md bi translated">过采样</li></ul><p id="531b" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">在欠采样中，样本从多数类中移除，而在过采样中，样本被添加到少数类中。</p><p id="7a5c" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">为了演示上述技术的使用，首先，我们将考虑一个不处理不平衡数据的例子。使用的数据集可以在<a class="ae mj" href="https://www.kaggle.com/datasets/mlg-ulb/creditcardfraud" rel="noopener ugc nofollow" target="_blank"> <strong class="jp ir">这里找到</strong> </a>。</p><h2 id="5a44" class="kx ky iq bd kz la lb dn lc ld le dp lf jy lg lh li kc lj lk ll kg lm ln lo lp bi translated">导入库</h2><pre class="km kn ko kp gt mk ml mm mn aw mo bi"><span id="0d13" class="kx ky iq ml b gy mp mq l mr ms"># import necessary modules</span><span id="956e" class="kx ky iq ml b gy mt mq l mr ms">import pandas  as pd<br/>import matplotlib.pyplot as plt<br/>import numpy as np<br/>from sklearn.linear_model import LogisticRegression<br/>from sklearn.preprocessing import StandardScaler<br/>from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score, f1_score</span></pre><h2 id="db08" class="kx ky iq bd kz la lb dn lc ld le dp lf jy lg lh li kc lj lk ll kg lm ln lo lp bi translated">加载数据</h2><pre class="km kn ko kp gt mk ml mm mn aw mo bi"><span id="6e11" class="kx ky iq ml b gy mp mq l mr ms">df  = pd.read_csv("/content/drive/MyDrive/creditcard.csv")</span></pre><h2 id="cdce" class="kx ky iq bd kz la lb dn lc ld le dp lf jy lg lh li kc lj lk ll kg lm ln lo lp bi translated">准备数据</h2><pre class="km kn ko kp gt mk ml mm mn aw mo bi"><span id="3aea" class="kx ky iq ml b gy mp mq l mr ms"># normalise the amount column</span><span id="052d" class="kx ky iq ml b gy mt mq l mr ms">df['normAmount'] = StandardScaler().fit_transform(np.array( df['Amount']).reshape(-1, 1))</span><span id="ca8d" class="kx ky iq ml b gy mt mq l mr ms"># drop Time and Amount columns as they are not relevant for prediction purpose<br/>data = df.drop(['Time', 'Amount'], axis = 1)</span><span id="4e92" class="kx ky iq ml b gy mt mq l mr ms"># as you can see there are 492 fraud transactions.<br/>data['Class'].value_counts()</span></pre><figure class="km kn ko kp gt kq gh gi paragraph-image"><div class="gh gi mu"><img src="../Images/8bc54f1d55e061c31c654e5ada46f926.png" data-original-src="https://miro.medium.com/v2/resize:fit:684/format:webp/1*0o05RCehdsu-IMi8shrEIg.png"/></div><figcaption class="kt ku gj gh gi kv kw bd b be z dk translated">输出</figcaption></figure><pre class="km kn ko kp gt mk ml mm mn aw mo bi"><span id="df1f" class="kx ky iq ml b gy mp mq l mr ms">X = data.drop(['Class'], axis = 1)<br/>y = data["Class"]</span></pre><h2 id="a067" class="kx ky iq bd kz la lb dn lc ld le dp lf jy lg lh li kc lj lk ll kg lm ln lo lp bi translated">分割列车测试数据</h2><pre class="km kn ko kp gt mk ml mm mn aw mo bi"><span id="b770" class="kx ky iq ml b gy mp mq l mr ms">from sklearn.model_selection import train_test_split</span><span id="2ff8" class="kx ky iq ml b gy mt mq l mr ms"># split into 70:30 ratio<br/>X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3, random_state = 0)</span><span id="16ec" class="kx ky iq ml b gy mt mq l mr ms"># describes info about train and test set</span><span id="2630" class="kx ky iq ml b gy mt mq l mr ms">print("Number transactions X_train dataset: ", X_train.shape)<br/>print("Number transactions y_train dataset: ", y_train.shape)<br/>print("Number transactions X_test dataset: ", X_test.shape)<br/>print("Number transactions y_test dataset: ", y_test.shape)</span></pre><figure class="km kn ko kp gt kq gh gi paragraph-image"><div class="gh gi mv"><img src="../Images/b231e8d5e41540aeeb2478f68b98d920.png" data-original-src="https://miro.medium.com/v2/resize:fit:1142/format:webp/1*0AF7eu8a2pGSLqlU40_62g.png"/></div><figcaption class="kt ku gj gh gi kv kw bd b be z dk translated">输出</figcaption></figure><h2 id="21a7" class="kx ky iq bd kz la lb dn lc ld le dp lf jy lg lh li kc lj lk ll kg lm ln lo lp bi translated">分类</h2><pre class="km kn ko kp gt mk ml mm mn aw mo bi"><span id="f72a" class="kx ky iq ml b gy mp mq l mr ms"># logistic regression object<br/>lr = LogisticRegression()</span><span id="90fb" class="kx ky iq ml b gy mt mq l mr ms"># train the model on train set<br/>lr.fit(X_train, y_train.ravel())<br/>predictions = lr.predict(X_test)</span><span id="146c" class="kx ky iq ml b gy mt mq l mr ms"># print classification report<br/>print("Accuracy score is: ",accuracy_score(y_test, predictions))<br/>print("Recall score is: ",recall_score(y_test, predictions))<br/>print("Precision score is: ",precision_score(y_test, predictions))<br/>print("Confusion Matrix: \n",confusion_matrix(y_test, predictions))</span></pre><figure class="km kn ko kp gt kq gh gi paragraph-image"><div class="gh gi mw"><img src="../Images/874bcf9ff52ee4d838f29ccdddc87f95.png" data-original-src="https://miro.medium.com/v2/resize:fit:972/format:webp/1*FbWDQEY0Otr8lb6eyLx44A.png"/></div><figcaption class="kt ku gj gh gi kv kw bd b be z dk translated">输出</figcaption></figure><p id="bd20" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">我们可以看到，即使准确率分数是99.9%，我们可以看到召回分数是61.9%，这是相对较低的，精确度分数是88.3%。</p><p id="919b" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">这是因为数据集是不平衡的，现在我们将尝试使用上述技术来提高这些分数。</p><h2 id="988c" class="kx ky iq bd kz la lb dn lc ld le dp lf jy lg lh li kc lj lk ll kg lm ln lo lp bi translated">利用欠采样处理不平衡数据</h2><p id="fc20" class="pw-post-body-paragraph jn jo iq jp b jq lq js jt ju lr jw jx jy ls ka kb kc lt ke kf kg lu ki kj kk ij bi translated">欠采样包括从多数类中删除记录，以平衡少数类。</p><figure class="km kn ko kp gt kq gh gi paragraph-image"><div class="gh gi mx"><img src="../Images/fe37a67c202c0e398075354e87010e54.png" data-original-src="https://miro.medium.com/v2/resize:fit:872/format:webp/1*-xq4D-UI6ksqFkSBiaZjdA.png"/></div></figure><p id="e534" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">欠采样涉及的最简单技术是随机欠采样。这种技术包括从多数类中移除随机记录。但是，如果我们随机删除这些行，将会丢失重要的信息。因此实现了各种技术来对数据进行欠采样。一种这样的导入技术是接近缺失欠采样。</p><h2 id="9d71" class="kx ky iq bd kz la lb dn lc ld le dp lf jy lg lh li kc lj lk ll kg lm ln lo lp bi translated">接近欠采样</h2><p id="4135" class="pw-post-body-paragraph jn jo iq jp b jq lq js jt ju lr jw jx jy ls ka kb kc lt ke kf kg lu ki kj kk ij bi translated">在这种技术中，数据点是根据多数类和少数类之间的距离来选择的。它有3个不同的版本，每个版本都考虑了来自多数类的不同数据点。</p><ul class=""><li id="5439" class="lv lw iq jp b jq jr ju jv jy lx kc ly kg lz kk ma mb mc md bi translated">版本1-它选择与少数类的K个最近实例的平均距离最小的多数类的数据点</li><li id="6dae" class="lv lw iq jp b jq me ju mf jy mg kc mh kg mi kk ma mb mc md bi translated">版本2-选择与少数类的K个最远实例的平均距离最小的多数类的数据点</li><li id="5ac0" class="lv lw iq jp b jq me ju mf jy mg kc mh kg mi kk ma mb mc md bi translated">版本3 —它分两步工作。首先，对于每个少数类实例，它们的<strong class="jp ir"> M个最近邻居</strong>将被存储。最后，选择到N个最近邻居的平均距离最大的多数类实例。</li></ul><p id="9101" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">简而言之，版本3是更准确的版本，因为它将删除tomek链接，并使分类过程更容易，因为它形成了决策边界。</p><figure class="km kn ko kp gt kq gh gi paragraph-image"><div role="button" tabindex="0" class="mz na di nb bf nc"><div class="gh gi my"><img src="../Images/f95e0fac4fd089d8a7f12ffef86df082.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*AQUQRV52VZIQnLsLcFA3UQ.png"/></div></div><figcaption class="kt ku gj gh gi kv kw bd b be z dk translated">接近欠采样</figcaption></figure><pre class="km kn ko kp gt mk ml mm mn aw mo bi"><span id="43a2" class="kx ky iq ml b gy mp mq l mr ms"># apply near miss<br/>from imblearn.under_sampling import NearMiss</span><span id="32de" class="kx ky iq ml b gy mt mq l mr ms">nr = NearMiss()</span><span id="1495" class="kx ky iq ml b gy mt mq l mr ms">X_train_miss, y_train_miss = nr.fit_resample(X_train, y_train.ravel())</span><span id="ecf6" class="kx ky iq ml b gy mt mq l mr ms">print('After Undersampling, the shape of train_X: {}'.format(X_train_miss.shape))</span><span id="662c" class="kx ky iq ml b gy mt mq l mr ms">print('After Undersampling, the shape of train_y: {} \n'.format(y_train_miss.shape))</span><span id="38b3" class="kx ky iq ml b gy mt mq l mr ms">print("After Undersampling, counts of label '1': {}".format(sum(y_train_miss == 1)))</span><span id="6332" class="kx ky iq ml b gy mt mq l mr ms">print("After Undersampling, counts of label '0': {}".format(sum(y_train_miss == 0)))</span></pre><figure class="km kn ko kp gt kq gh gi paragraph-image"><div class="gh gi nd"><img src="../Images/0130b6d958027463fe98c86e6379cd1b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1074/format:webp/1*nZrvN75xTC2LvySBwuzgWQ.png"/></div><figcaption class="kt ku gj gh gi kv kw bd b be z dk translated">输出</figcaption></figure><p id="a12f" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">我们对多数类-0进行了欠采样，并与少数类-1进行了平衡。现在让我们训练和评估数据。</p><pre class="km kn ko kp gt mk ml mm mn aw mo bi"><span id="46e6" class="kx ky iq ml b gy mp mq l mr ms">lr2 = LogisticRegression()</span><span id="e0ae" class="kx ky iq ml b gy mt mq l mr ms">lr2.fit(X_train_miss, y_train_miss)</span><span id="5019" class="kx ky iq ml b gy mt mq l mr ms">predictions = lr2.predict(X_test)</span><span id="29b3" class="kx ky iq ml b gy mt mq l mr ms"># print evaluation metrics<br/>print("Accuracy score is: ",accuracy_score(y_test, predictions))<br/>print("Recall score is: ",recall_score(y_test, predictions))<br/>print("Precision score is: ",precision_score(y_test, predictions))<br/>print("Confusion Matrix: \n",confusion_matrix(y_test, predictions))</span></pre><figure class="km kn ko kp gt kq gh gi paragraph-image"><div class="gh gi ne"><img src="../Images/0d2ff4d26734f95b6b26f65b7e8796fc.png" data-original-src="https://miro.medium.com/v2/resize:fit:994/format:webp/1*ZXhKJwj90-BGnlYhHUH5fw.png"/></div><figcaption class="kt ku gj gh gi kv kw bd b be z dk translated">输出</figcaption></figure><p id="e7de" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">所以即使回忆分数更多，我们可以看到准确性更少。但是通过我们的观察，当少数类的预测是优先的时候，我们可以使用这种技术。</p><h2 id="b998" class="kx ky iq bd kz la lb dn lc ld le dp lf jy lg lh li kc lj lk ll kg lm ln lo lp bi translated">使用过采样处理不平衡数据</h2><p id="279b" class="pw-post-body-paragraph jn jo iq jp b jq lq js jt ju lr jw jx jy ls ka kb kc lt ke kf kg lu ki kj kk ij bi translated">与欠采样不同，在欠采样中，我们从多数类中删除记录，在过采样中，我们将添加少数类中的记录。当我们拥有大量数据时，可以使用欠采样，而当我们拥有较少数据时，可以使用过采样。</p><figure class="km kn ko kp gt kq gh gi paragraph-image"><div class="gh gi nf"><img src="../Images/0bc7a08106c80fc8f1bdcf3093a64620.png" data-original-src="https://miro.medium.com/v2/resize:fit:936/format:webp/1*tH8alDfWYEB7i0BSL6wZHw.png"/></div><figcaption class="kt ku gj gh gi kv kw bd b be z dk translated">过采样</figcaption></figure><p id="85b4" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">过采样中涉及的最简单的技术是随机过采样，其中我们向少数类随机添加更多的副本，以与多数类平衡，但过采样的缺点是它会导致数据的过拟合和泛化，从而降低准确性。为此，我们使用SMOTE技术。</p><h2 id="14ca" class="kx ky iq bd kz la lb dn lc ld le dp lf jy lg lh li kc lj lk ll kg lm ln lo lp bi translated">合成少数过采样技术</h2><p id="2047" class="pw-post-body-paragraph jn jo iq jp b jq lq js jt ju lr jw jx jy ls ka kb kc lt ke kf kg lu ki kj kk ij bi translated">SMOTE技术的工作原理是从少数类中随机选取一个数据点，并计算该点的K-最近邻，然后在这个选定的点和它的邻居之间添加随机点。</p><figure class="km kn ko kp gt kq gh gi paragraph-image"><div role="button" tabindex="0" class="mz na di nb bf nc"><div class="gh gi ng"><img src="../Images/227bf22926c868b9a57c720d5176e349.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*7c5J2WfJi8W8LZXP4EMGPg.png"/></div></div><figcaption class="kt ku gj gh gi kv kw bd b be z dk translated">重击</figcaption></figure><p id="0d87" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">SMOTE算法分4步工作—</p><ul class=""><li id="dee1" class="lv lw iq jp b jq jr ju jv jy lx kc ly kg lz kk ma mb mc md bi translated">选择少数民族类作为输入向量。</li><li id="a8cc" class="lv lw iq jp b jq me ju mf jy mg kc mh kg mi kk ma mb mc md bi translated">使用欧几里德距离找到它的K个最近邻。</li><li id="58cb" class="lv lw iq jp b jq me ju mf jy mg kc mh kg mi kk ma mb mc md bi translated">选择这些相邻点中的一个，并在所选点及其相邻点之间添加一个合成点。</li><li id="0577" class="lv lw iq jp b jq me ju mf jy mg kc mh kg mi kk ma mb mc md bi translated">重复上述步骤，直到达到平衡。</li></ul><pre class="km kn ko kp gt mk ml mm mn aw mo bi"><span id="33f5" class="kx ky iq ml b gy mp mq l mr ms">from<!-- --> <!-- -->imblearn.over_sampling import<!-- --> <!-- -->SMOTE</span><span id="77f3" class="kx ky iq ml b gy mt mq l mr ms">sm <strong class="ml ir">=</strong> <!-- -->SMOTE(random_state <strong class="ml ir">=</strong> <!-- -->2)</span><span id="a664" class="kx ky iq ml b gy mt mq l mr ms">X_train_res, y_train_res <strong class="ml ir">=</strong> <!-- -->sm.fit_resample(X_train, y_train.ravel())</span><span id="a600" class="kx ky iq ml b gy mt mq l mr ms">print('After OverSampling, the shape of train_X: {}'.format(X_train_res.shape))<br/>print('After OverSampling, the shape of train_y: {} \n'.format(y_train_res.shape))<br/>print("After OverSampling, counts of label '1': {}".format(sum(y_train_res ==<!-- --> <!-- -->1)))<br/>print("After OverSampling, counts of label '0': {}".format(sum(y_train_res ==<!-- --> <!-- -->0)))</span></pre><figure class="km kn ko kp gt kq gh gi paragraph-image"><div class="gh gi nh"><img src="../Images/7a3239bba49523ffee374ccd316a4853.png" data-original-src="https://miro.medium.com/v2/resize:fit:1206/format:webp/1*U9CRGy0EibkijMewD5Q_oQ.png"/></div><figcaption class="kt ku gj gh gi kv kw bd b be z dk translated">输出</figcaption></figure><p id="2bd7" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">我们对少数类1进行了过采样，并用多数类0对其进行了平衡。让我们对数据进行训练和评估。</p><pre class="km kn ko kp gt mk ml mm mn aw mo bi"><span id="7dda" class="kx ky iq ml b gy mp mq l mr ms">lr1 = LogisticRegression()<br/>lr1.fit(X_train_res, y_train_res.ravel())</span><span id="c295" class="kx ky iq ml b gy mt mq l mr ms">predictions = lr1.predict(X_test)</span><span id="99fb" class="kx ky iq ml b gy mt mq l mr ms"># print Evaluation Metrics</span><span id="1ec4" class="kx ky iq ml b gy mt mq l mr ms">print("Accuracy score is: ",accuracy_score(y_test, predictions))<br/>print("Recall score is: ",recall_score(y_test, predictions))<br/>print("Precision score is: ",precision_score(y_test, predictions))<br/>print("Confusion Matrix: \n",confusion_matrix(y_test, predictions))</span></pre><figure class="km kn ko kp gt kq gh gi paragraph-image"><div class="gh gi ni"><img src="../Images/3abc98b9bd12b3672b0fdd5197b15c50.png" data-original-src="https://miro.medium.com/v2/resize:fit:944/format:webp/1*L-fCRkWT6Fw4D0xyRibFRA.png"/></div><figcaption class="kt ku gj gh gi kv kw bd b be z dk translated">输出</figcaption></figure><p id="0133" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">正如我们可以看到的，与原始统计数据相比，recall_score在精确度上有极小的下降，但却显著增加了。</p><h2 id="7823" class="kx ky iq bd kz la lb dn lc ld le dp lf jy lg lh li kc lj lk ll kg lm ln lo lp bi translated">比较模型性能</h2><p id="02d6" class="pw-post-body-paragraph jn jo iq jp b jq lq js jt ju lr jw jx jy ls ka kb kc lt ke kf kg lu ki kj kk ij bi translated">下面是模型在不处理不平衡数据、欠采样和过采样的情况下的比较</p><figure class="km kn ko kp gt kq gh gi paragraph-image"><div class="gh gi nj"><img src="../Images/ea187f7d588bc9f7aad723d026fb75a5.png" data-original-src="https://miro.medium.com/v2/resize:fit:1322/format:webp/1*fCJt8kYfPUZVgoC5K3WgFQ.png"/></div><figcaption class="kt ku gj gh gi kv kw bd b be z dk translated">作者图片</figcaption></figure><p id="3ad2" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">通过以上度量，可以理解SMOTE技术具有良好的效果。</p><h2 id="d3ed" class="kx ky iq bd kz la lb dn lc ld le dp lf jy lg lh li kc lj lk ll kg lm ln lo lp bi translated">结论</h2><p id="bc6e" class="pw-post-body-paragraph jn jo iq jp b jq lq js jt ju lr jw jx jy ls ka kb kc lt ke kf kg lu ki kj kk ij bi translated">在本文中，我们讨论了如何使用不同的技术处理不平衡数据。我们在上面的例子中使用了逻辑回归，我们可以尝试各种算法，提高模型性能。</p><p id="de62" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">希望这有帮助…快乐编码…..</p></div></div>    
</body>
</html>