<html>
<head>
<title>Databricks: Upsert to Azure SQL using PySpark</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">Databricks:使用PySpark升级到Azure SQL</h1>
<blockquote>原文：<a href="https://pub.towardsai.net/databricks-upsert-to-azure-sql-using-pyspark-5937e8303fbf?source=collection_archive---------1-----------------------#2021-02-19">https://pub.towardsai.net/databricks-upsert-to-azure-sql-using-pyspark-5937e8303fbf?source=collection_archive---------1-----------------------#2021-02-19</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><h2 id="a9c5" class="io ip iq bd b dl ir is it iu iv iw dk ix translated" aria-label="kicker paragraph"><a class="ae ep" href="https://towardsai.net/p/category/cloud-computing" rel="noopener ugc nofollow" target="_blank">云计算</a></h2><div class=""/><p id="f17b" class="pw-post-body-paragraph jw jx iq jy b jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ij bi translated">Upsert是一种RDBMS特性，它允许DML语句的作者自动插入一行，或者如果该行已经存在，则更新该现有行。</p><p id="bedd" class="pw-post-body-paragraph jw jx iq jy b jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ij bi translated">根据我构建多个Azure数据平台的经验，我已经能够开发可重用的ELT函数，可以在项目之间使用，其中一个是Azure SQL upsert函数。</p><p id="4850" class="pw-post-body-paragraph jw jx iq jy b jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ij bi translated">今天我将和你分享如何使用PySpark创建一个Azure SQL Upsert函数。它可以在Databricks工作流中重用，只需最少的工作量和灵活性。</p><figure class="kv kw kx ky gt kz gh gi paragraph-image"><div role="button" tabindex="0" class="la lb di lc bf ld"><div class="gh gi ku"><img src="../Images/01721caedd9a19919e548c44d19d4b26.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*uOXz9kMMOVhas6MMX-8T1Q.png"/></div></div></figure><p id="f4db" class="pw-post-body-paragraph jw jx iq jy b jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ij bi translated">基本上插逻辑</p><ol class=""><li id="3b25" class="lg lh iq jy b jz ka kd ke kh li kl lj kp lk kt ll lm ln lo bi translated">创建了两个表，一个临时表和一个目标表</li><li id="3e35" class="lg lh iq jy b jz lp kd lq kh lr kl ls kp lt kt ll lm ln lo bi translated">数据被加载到分段表中</li><li id="5e3f" class="lg lh iq jy b jz lp kd lq kh lr kl ls kp lt kt ll lm ln lo bi translated">这些表在查找列和/或增量列上联接，以标识匹配项</li><li id="b6f0" class="lg lh iq jy b jz lp kd lq kh lr kl ls kp lt kt ll lm ln lo bi translated">如果临时表中的记录存在于目标表中，则在目标表中更新该记录</li><li id="091b" class="lg lh iq jy b jz lp kd lq kh lr kl ls kp lt kt ll lm ln lo bi translated">如果临时表中的记录在目标表中不存在，则将它插入到目标表中</li></ol><h1 id="187d" class="lu lv iq bd lw lx ly lz ma mb mc md me mf mg mh mi mj mk ml mm mn mo mp mq mr bi translated">Azure SQL Upsert PySpark函数</h1><p id="ad3d" class="pw-post-body-paragraph jw jx iq jy b jz ms kb kc kd mt kf kg kh mu kj kk kl mv kn ko kp mw kr ks kt ij bi translated">功能</p><ul class=""><li id="0d51" class="lg lh iq jy b jz ka kd ke kh li kl lj kp lk kt mx lm ln lo bi translated">输入数据帧被写入Azure SQL上的临时表</li><li id="b90d" class="lg lh iq jy b jz lp kd lq kh lr kl ls kp lt kt mx lm ln lo bi translated">该函数接受多个查找列和/或可选增量列的参数，以连接临时表和目标表</li><li id="0631" class="lg lh iq jy b jz lp kd lq kh lr kl ls kp lt kt mx lm ln lo bi translated">如果将增量列传递给函数，则只有当临时表记录比目标表记录新时，它才会更新目标表中的记录</li><li id="9daf" class="lg lh iq jy b jz lp kd lq kh lr kl ls kp lt kt mx lm ln lo bi translated">该函数将动态读取数据帧列，以形成SQL Merge upsert和insert语句的一部分</li></ul><p id="81b5" class="pw-post-body-paragraph jw jx iq jy b jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ij bi translated">在编写代码之前，理解Spark Azure SQL数据库连接器至关重要。连接器不支持写入表后的preUpdate或postUpdate语句。因此，我们需要将数据帧写入staging表，然后将有效的SQL merge语句传递给PyODBC连接器以执行upsert。</p><p id="bf35" class="pw-post-body-paragraph jw jx iq jy b jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ij bi translated"><strong class="jy ja">先决条件</strong></p><ul class=""><li id="61dd" class="lg lh iq jy b jz ka kd ke kh li kl lj kp lk kt mx lm ln lo bi translated">使用正确的数据类型和索引创建Azure SQL目标和临时表，以提高连接性能</li><li id="1e68" class="lg lh iq jy b jz lp kd lq kh lr kl ls kp lt kt mx lm ln lo bi translated">在您的集群上安装Apache Spark connector for SQL Server和Azure SQL:【https://github.com/microsoft/sql-spark-connector】T4</li><li id="3e2f" class="lg lh iq jy b jz lp kd lq kh lr kl ls kp lt kt mx lm ln lo bi translated">在集群上运行以下代码来安装PyODBC</li></ul><pre class="kv kw kx ky gt mz na nb nc aw nd bi"><span id="37a5" class="ne lv iq na b gy nf ng l nh ni">%sh<br/>curl <a class="ae my" href="https://packages.microsoft.com/keys/microsoft.asc" rel="noopener ugc nofollow" target="_blank">https://packages.microsoft.com/keys/microsoft.asc</a> | apt-key add -<br/>curl <a class="ae my" href="https://packages.microsoft.com/config/ubuntu/" rel="noopener ugc nofollow" target="_blank">https://packages.microsoft.com/config/ubuntu/</a><strong class="na ja">16.04</strong>/prod.list &gt; /etc/apt/sources.list.d/mssql-release.list <br/>apt-get update<br/>ACCEPT_EULA=Y apt-get install msodbcsql17<br/>apt-get -y install unixodbc-dev<br/>sudo apt-get install python3-pip -y<br/>pip3 install --upgrade pyodbc</span></pre><p id="3612" class="pw-post-body-paragraph jw jx iq jy b jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ij bi translated">注意:当您重新启动集群或创建新的集群时，这些设置将会丢失，您需要再次运行。省去麻烦，把它放到一个<a class="ae my" href="https://docs.databricks.com/user-guide/clusters/init-scripts.html" rel="noopener ugc nofollow" target="_blank">初始化脚本</a>中。这样你就不用重复这种痛苦了。</p><p id="1b7e" class="pw-post-body-paragraph jw jx iq jy b jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ij bi translated"><strong class="jy ja">输入参数</strong></p><ul class=""><li id="c829" class="lg lh iq jy b jz ka kd ke kh li kl lj kp lk kt mx lm ln lo bi translated">df:输入数据帧</li><li id="d6f6" class="lg lh iq jy b jz lp kd lq kh lr kl ls kp lt kt mx lm ln lo bi translated">Azure SQL stagingtable:Azure SQL目标表的名称</li><li id="b480" class="lg lh iq jy b jz lp kd lq kh lr kl ls kp lt kt mx lm ln lo bi translated">azureSqlDWTable:Azure SQL目标DW表的名称</li><li id="eda6" class="lg lh iq jy b jz lp kd lq kh lr kl ls kp lt kt mx lm ln lo bi translated">lookupColumns:在输入数据帧中唯一定义记录的管道分隔列，例如CustomerId或CustomerId|FirstName</li><li id="ce5c" class="lg lh iq jy b jz lp kd lq kh lr kl ls kp lt kt mx lm ln lo bi translated">deltaColumn:输入数据帧中水印列的名称</li></ul><p id="847e" class="pw-post-body-paragraph jw jx iq jy b jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ij bi translated"><strong class="jy ja">代码</strong></p><p id="3136" class="pw-post-body-paragraph jw jx iq jy b jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ij bi translated">请查看每个代码块的注释以获得解释。</p><figure class="kv kw kx ky gt kz gh gi paragraph-image"><div role="button" tabindex="0" class="la lb di lc bf ld"><div class="gh gi nj"><img src="../Images/3747039faf5ddc03530f40391bdf9fd4.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*9yAnFUluCaF0yyABWmPwEg.png"/></div></div></figure><h1 id="c8d9" class="lu lv iq bd lw lx ly lz ma mb mc md me mf mg mh mi mj mk ml mm mn mo mp mq mr bi translated">结论</h1><p id="06c0" class="pw-post-body-paragraph jw jx iq jy b jz ms kb kc kd mt kf kg kh mu kj kk kl mv kn ko kp mw kr ks kt ij bi translated">如果你想要一本，请在<a class="ae my" href="https://www.linkedin.com/in/rorymcmanus/" rel="noopener ugc nofollow" target="_blank"> LinkedIn </a>上给我留言。</p><p id="1cc2" class="pw-post-body-paragraph jw jx iq jy b jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ij bi translated">我希望这对您有所帮助，并在编写upsert函数时节省您的时间。任何想法，问题，更正和建议都非常欢迎:)</p><p id="5e66" class="pw-post-body-paragraph jw jx iq jy b jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ij bi translated">如果你觉得这个有用，请在LinkedIn上分享#数据工程#分享#社区#数据砖#PySpark #AzureSQL #SQL #ELT</p><div class="nk nl gp gr nm nn"><a href="https://www.linkedin.com/in/rorymcmanus/" rel="noopener  ugc nofollow" target="_blank"><div class="no ab fo"><div class="np ab nq cl cj nr"><h2 class="bd ja gy z fp ns fr fs nt fu fw iz bi translated">Rory McManus —数据架构师—数据掌握| LinkedIn</h2><div class="nu l"><h3 class="bd b gy z fp ns fr fs nt fu fw dk translated">Azure数据工厂、Spark Databricks和AI领域的Azure数据架构师专家。构建平台的丰富经验…</h3></div><div class="nv l"><p class="bd b dl z fp ns fr fs nt fu fw dk translated">www.linkedin.com</p></div></div></div></a></div><h1 id="0f2e" class="lu lv iq bd lw lx ly lz ma mb mc md me mf mg mh mi mj mk ml mm mn mo mp mq mr bi translated">如果你喜欢这篇文章，这里有一些你可能喜欢的其他文章:</h1><div class="nk nl gp gr nm nn"><a rel="noopener  ugc nofollow" target="_blank" href="/databricks-pyspark-type-2-scd-function-for-azure-synapse-analytics-8c0ff8862a11"><div class="no ab fo"><div class="np ab nq cl cj nr"><h2 class="bd ja gy z fp ns fr fs nt fu fw iz bi translated">用于Azure Synapse分析的Databricks PySpark Type 2 SCD函数</h2><div class="nu l"><h3 class="bd b gy z fp ns fr fs nt fu fw dk translated">渐变维度(SCD)是数据仓库中一种常用的维度建模技术，用于捕获…</h3></div><div class="nv l"><p class="bd b dl z fp ns fr fs nt fu fw dk translated">pub.towardsai.net</p></div></div><div class="nw l"><div class="nx l ny nz oa nw ob le nn"/></div></div></a></div><div class="nk nl gp gr nm nn"><a rel="noopener  ugc nofollow" target="_blank" href="/azure-cognitive-services-sentiment-analysis-v3-using-pyspark-b38bfcfd20fb"><div class="no ab fo"><div class="np ab nq cl cj nr"><h2 class="bd ja gy z fp ns fr fs nt fu fw iz bi translated">Azure认知服务情感分析V3—使用PySpark</h2><div class="nu l"><h3 class="bd b gy z fp ns fr fs nt fu fw dk translated">什么是Azure认知服务-文本分析？</h3></div><div class="nv l"><p class="bd b dl z fp ns fr fs nt fu fw dk translated">pub.towardsai.net</p></div></div><div class="nw l"><div class="oc l ny nz oa nw ob le nn"/></div></div></a></div></div></div>    
</body>
</html>