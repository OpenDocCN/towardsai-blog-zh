<html>
<head>
<title>Image Classification using Deep Learning &amp; PyTorch: A Case Study with Flower Image Data</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">基于深度学习和PyTorch的图像分类——以花卉图像数据为例</h1>
<blockquote>原文：<a href="https://pub.towardsai.net/image-classification-using-deep-learning-pytorch-a-case-study-with-flower-image-data-80a18554df63?source=collection_archive---------0-----------------------#2019-08-05">https://pub.towardsai.net/image-classification-using-deep-learning-pytorch-a-case-study-with-flower-image-data-80a18554df63?source=collection_archive---------0-----------------------#2019-08-05</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><h2 id="2b82" class="ir is it bd b dl iu iv iw ix iy iz dk ja translated" aria-label="kicker paragraph"><a class="ae ep" href="https://towardsai.net/p/category/machine-learning/deep-learning" rel="noopener ugc nofollow" target="_blank">深度学习</a>、<a class="ae ep" href="https://towardsai.net/p/category/machine-learning" rel="noopener ugc nofollow" target="_blank">机器学习</a>、<a class="ae ep" href="https://towardsai.net/p/category/programming/python" rel="noopener ugc nofollow" target="_blank"> Python </a></h2><div class=""/><div class=""><h2 id="65fa" class="pw-subtitle-paragraph jz jc it bd b ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq dk translated">基于PyTorch库的卷积深度神经网络花卉图像分类</h2></div><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi kr"><img src="../Images/da3b2a520913d627f5d6eac753dd2416.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*INYvq1x7Slq3mina"/></div></div><figcaption class="ld le gj gh gi lf lg bd b be z dk translated">照片由<a class="ae lh" href="https://unsplash.com/@krystina_elise?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Krystina rogers </a>在<a class="ae lh" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上拍摄</figcaption></figure><p id="7969" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi me translated"><span class="l mf mg mh bm mi mj mk ml mm di"> C </span>对图像数据进行分类是深度学习技术非常流行的用法之一。在本文中，我们将讨论使用深度卷积神经网络识别花卉图像。</p><p id="1b7f" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">为此，我们将使用Python的PyTorch、TorchVision和PIL库</p><h1 id="c1d3" class="mn mo it bd mp mq mr ms mt mu mv mw mx ki my kj mz kl na km nb ko nc kp nd ne bi translated">数据探索</h1><p id="979c" class="pw-post-body-paragraph li lj it lk b ll nf kd ln lo ng kg lq lr nh lt lu lv ni lx ly lz nj mb mc md im bi translated">这个问题所需的数据集可以在<a class="ae lh" href="https://www.kaggle.com/alxmamaev/flowers-recognition/" rel="noopener ugc nofollow" target="_blank"> Kaggle </a>找到。它包含一个文件夹结构&amp;里面有花的图片。有5种不同类型的花。文件夹结构如下所示</p><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi gj"><img src="../Images/9b1f5f571728867bc208598e1ec35620.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*sBJXTNWsoUlJLnABJbPWnQ.png"/></div></div><figcaption class="ld le gj gh gi lf lg bd b be z dk translated">图一</figcaption></figure><p id="0ff8" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">现在，我们将从文件夹“玫瑰”中看到一个花图像的样本</p><figure class="ks kt ku kv gt kw"><div class="bz fp l di"><div class="nk nl l"/></div></figure><pre class="ks kt ku kv gt nm nn no np aw nq bi"><span id="e218" class="nr mo it nn b gy ns nt l nu nv">show_image("../data/flowers/rose/537207677_f96a0507bb.jpg")</span></pre><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div class="gh gi nw"><img src="../Images/0a1aa119294034e57805dd12cb315932.png" data-original-src="https://miro.medium.com/v2/resize:fit:638/format:webp/1*5am-jVgXySEEr9s2PY2mgA.png"/></div></figure><h1 id="a84c" class="mn mo it bd mp mq mr ms mt mu mv mw mx ki my kj mz kl na km nb ko nc kp nd ne bi translated">数据预处理</h1><p id="3d19" class="pw-post-body-paragraph li lj it lk b ll nf kd ln lo ng kg lq lr nh lt lu lv ni lx ly lz nj mb mc md im bi translated">PyTorch总是期望数据以“张量”的形式出现。这些“张量”在神经网络的节点之间运行，包含原始和预处理或后处理的数据。简而言之，基本上“张量”类似于“numpy”数组。</p><p id="b573" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">同样对于图像数据，我们必须将图像作为张量读取，并在进行任何分类之前应用几个预处理阶段。</p><p id="b406" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">我们可以把图像看作一个三维张量。每幅图像的像素可以有3种颜色值，分别是红色、绿色和蓝色。我们称之为RGB颜色编码。另外两个维度是长度和宽度方向的像素值。</p><p id="cba1" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">通常，图像数据需要两个非常常见的预处理阶段，如下所示:</p><ol class=""><li id="2492" class="nx ny it lk b ll lm lo lp lr nz lv oa lz ob md oc od oe of bi translated"><strong class="lk jd">根据模板调整大小:</strong>将图像调整为方形。在我们的例子中，我们将把每个图像的大小调整为64x64。</li><li id="b919" class="nx ny it lk b ll og lo oh lr oi lv oj lz ok md oc od oe of bi translated"><strong class="lk jd">归一化:</strong>使用每个像素值的(x — mean)/sd机制的统计归一化。它有助于改善可视化，增强特征和拉伸图像中的对比度。</li></ol><p id="224a" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">使用PyTorch，我们将做这一套预处理</p><figure class="ks kt ku kv gt kw"><div class="bz fp l di"><div class="nk nl l"/></div></figure><p id="0558" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">我们还可以定义一个函数来显示一组转换后的图像</p><figure class="ks kt ku kv gt kw"><div class="bz fp l di"><div class="nk nl l"/></div></figure><p id="b21e" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">现在，我们可以看到第一批的变形图像</p><pre class="ks kt ku kv gt nm nn no np aw nq bi"><span id="83f7" class="nr mo it nn b gy ns nt l nu nv">show_transformed_image(make_grid(image))</span></pre><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi ol"><img src="../Images/4a552c87abeb901b59bdfc9e055c5071.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*_n_-oBfUdvOgUuvOiYN_Cw.png"/></div></div></figure><p id="0218" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">我们也可以用这个类来索引数据字典</p><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi om"><img src="../Images/2349d6825b5f438a74f8cf3027c73d4f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*eQ6XFgrSrmeHrNRHZpRzhA.png"/></div></div></figure><p id="88a0" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">这将有助于识别类别。</p><h1 id="355d" class="mn mo it bd mp mq mr ms mt mu mv mw mx ki my kj mz kl na km nb ko nc kp nd ne bi translated">构建模型</h1><p id="da8f" class="pw-post-body-paragraph li lj it lk b ll nf kd ln lo ng kg lq lr nh lt lu lv ni lx ly lz nj mb mc md im bi translated">为了建立图像数据的机器学习模型，仅仅提供像素值是不够的。图像中有许多隐藏的特征仍未被发现。为此，我们应该使用卷积和最大池层的组合来提取重要的特征。</p><h2 id="5d9f" class="nr mo it bd mp on oo dn mt op oq dp mx lr or os mz lv ot ou nb lz ov ow nd iz bi translated">卷积层</h2><p id="2435" class="pw-post-body-paragraph li lj it lk b ll nf kd ln lo ng kg lq lr nh lt lu lv ni lx ly lz nj mb mc md im bi translated">数学上，两个函数f &amp; g之间的卷积运算定义为</p><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div class="gh gi ox"><img src="../Images/5fb42d61fed0b3894e3e753a29d7cc76.png" data-original-src="https://miro.medium.com/v2/resize:fit:322/1*hVoZEEfIQ5LqkDRgOjyumg.gif"/></div></figure><p id="c828" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">实际上，如果我们认为f是图像张量，那么g应该是另一个可以作为“卷积核”的张量。</p><blockquote class="oy oz pa"><p id="4974" class="li lj pb lk b ll lm kd ln lo lp kg lq pc ls lt lu pd lw lx ly pe ma mb mc md im bi translated">它是两个张量相乘值的逐像素求和。</p></blockquote><p id="26bc" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">下图显示了卷积运算对样本图像张量的影响</p><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi pf"><img src="../Images/a305db26915f5bd62f3664bc466f88f9.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Hx5orXisSsqpXZzSEG9jmQ.png"/></div></div></figure><p id="1021" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">大小为3×3的卷积核作为从(0，0)位置开始的窗口在图像张量周围移动，并且输出张量的(0，0)处的样本结果如下计算</p><blockquote class="oy oz pa"><p id="318e" class="li lj pb lk b ll lm kd ln lo lp kg lq pc ls lt lu pd lw lx ly pe ma mb mc md im bi translated">输出(0，0) =图像张量(0，0) x内核(0，0) +图像张量(0，1) x内核(0，1) +图像张量(0，2) x内核(0，2) +图像张量(1，0) x内核(1，0) +图像张量(1，1)+图像张量(1，2) x内核(1，2) +图像张量(2，0) x内核(2，0) +图像张量(2，1) x内核(2，1)</p></blockquote><p id="eb8a" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">核将位置移动1位，以计算输出张量的其他位置的值。这种“转变”被称为“跨越”。</p><blockquote class="oy oz pa"><p id="408c" class="li lj pb lk b ll lm kd ln lo lp kg lq pc ls lt lu pd lw lx ly pe ma mb mc md im bi translated">需要卷积层来增强和提取图像的重要和隐藏特征。在我们的例子中，可能会发生“花”位于图像的中心位置，所以应用卷积有助于检索花的核心特征，而忽略其他背景对象&amp;颜色。</p></blockquote><p id="4b5f" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">由于每个图像遵循RGB颜色编码，我们将对每个颜色应用卷积运算，因此我们将获得三个输出张量。最终输出将是所有三者的张量和。在PyTorch API术语中，这些“颜色代码”中的每一个都被称为“通道”。</p><blockquote class="oy oz pa"><p id="0b76" class="li lj pb lk b ll lm kd ln lo lp kg lq pc ls lt lu pd lw lx ly pe ma mb mc md im bi translated">在数学上，如果大小为kxk的滤波器应用于大小为WxH的图像，那么它产生大小为(W-k+1)×(H-k+1)的输出图像/张量</p></blockquote><p id="7db1" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">在我们的例子中，卷积是这样创建的</p><pre class="ks kt ku kv gt nm nn no np aw nq bi"><span id="5b49" class="nr mo it nn b gy ns nt l nu nv">self.conv1 = nn.Conv2d(in_channels=3, out_channels=12, kernel_size=3,stride=1, padding=1)</span></pre><blockquote class="oy oz pa"><p id="e27c" class="li lj pb lk b ll lm kd ln lo lp kg lq pc ls lt lu pd lw lx ly pe ma mb mc md im bi translated">“out_channels”指定要应用多少个过滤器。这里我们应用了12个过滤器，它们将产生12个大小为62x62的中间图像张量。这些图像中的每一个都包含原始图像的一个独特特征。</p></blockquote><p id="37bc" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">关于“卷积滤波器”的更多细节，读者可以点击下面的链接</p><div class="pg ph gp gr pi pj"><a href="https://www.superdatascience.com/blogs/convolutional-neural-networks-cnn-step-1-convolution-operation" rel="noopener  ugc nofollow" target="_blank"><div class="pk ab fo"><div class="pl ab pm cl cj pn"><h2 class="bd jd gy z fp po fr fs pp fu fw jc bi translated">卷积神经网络(CNN):第一步-卷积运算-博客超级数据科学-大…</h2><div class="pq l"><h3 class="bd b gy z fp po fr fs pp fu fw dk translated">步骤1-卷积运算在本教程中，我们将学习卷积，这是第一步…</h3></div><div class="pr l"><p class="bd b dl z fp po fr fs pp fu fw dk translated">www.superdatascience.com</p></div></div><div class="ps l"><div class="pt l pu pv pw ps px lb pj"/></div></div></a></div><h2 id="f379" class="nr mo it bd mp on oo dn mt op oq dp mx lr or os mz lv ot ou nb lz ov ow nd iz bi translated">ReLU层</h2><p id="82a9" class="pw-post-body-paragraph li lj it lk b ll nf kd ln lo ng kg lq lr nh lt lu lv ni lx ly lz nj mb mc md im bi translated">“ReLU”是一个激活函数，它捕捉另一个函数输出中的非线性。数学上，它被定义为</p><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div class="gh gi py"><img src="../Images/dcdd42a192b42ab735e18c3d9309d73b.png" data-original-src="https://miro.medium.com/v2/resize:fit:268/1*6NPRKqezcqqPbs8bk6G4Eg.gif"/></div></figure><p id="22ee" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">所以，它总是返回正值。我们可以说，它是一个“积极的过滤器”。我们将应用卷积后的“ReLU”层。</p><p id="244b" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">在我们的例子中，“ReLU”是这样创建的</p><pre class="ks kt ku kv gt nm nn no np aw nq bi"><span id="f6a3" class="nr mo it nn b gy ns nt l nu nv">self.relu1 = nn.ReLU()</span></pre><h2 id="8bf6" class="nr mo it bd mp on oo dn mt op oq dp mx lr or os mz lv ot ou nb lz ov ow nd iz bi translated">最大池层</h2><p id="1d1c" class="pw-post-body-paragraph li lj it lk b ll nf kd ln lo ng kg lq lr nh lt lu lv ni lx ly lz nj mb mc md im bi translated">“最大池层”通常在“ReLU”之后。大小为2的“最大池”是一个2×2窗口，它遍历“ReLU”操作的输出张量，并在窗口内选择最大像素值。这个操作可以通过下图来解释</p><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div class="gh gi pz"><img src="../Images/5af60b9d9f65ca58f810ecd51801d913.png" data-original-src="https://miro.medium.com/v2/resize:fit:1364/format:webp/1*EoHr9QWEBF3PPXbzS53OPg.png"/></div></figure><p id="a302" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">“最大池”层的目标是只选择那些影响大、价值高的功能。这有助于减少特征的尺寸。</p><p id="f636" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">在我们的例子中，“最大池”创建如下</p><pre class="ks kt ku kv gt nm nn no np aw nq bi"><span id="3be6" class="nr mo it nn b gy ns nt l nu nv">self.maxpool1 = nn.MaxPool2d(kernel_size=2)</span></pre><p id="a46b" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">它会将图像的尺寸减少50% (32 = 64/2)。</p><h2 id="ad6d" class="nr mo it bd mp on oo dn mt op oq dp mx lr or os mz lv ot ou nb lz ov ow nd iz bi translated">线性功能层</h2><p id="6185" class="pw-post-body-paragraph li lj it lk b ll nf kd ln lo ng kg lq lr nh lt lu lv ni lx ly lz nj mb mc md im bi translated">顾名思义，它是一个线性函数，将“Max Pool”的输出作为展平数组，并产生作为类索引的输出。预测类别指数的“线性函数”的输出值将最大。</p><p id="d273" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">在我们的例子中，“线性函数”创建如下</p><pre class="ks kt ku kv gt nm nn no np aw nq bi"><span id="5d31" class="nr mo it nn b gy ns nt l nu nv">self.lf = nn.Linear(in_features=32 * 32 * 24, out_features=num_classes)</span></pre><h2 id="bf49" class="nr mo it bd mp on oo dn mt op oq dp mx lr or os mz lv ot ou nb lz ov ow nd iz bi translated">模型的整体架构</h2><p id="2315" class="pw-post-body-paragraph li lj it lk b ll nf kd ln lo ng kg lq lr nh lt lu lv ni lx ly lz nj mb mc md im bi translated">我们将应用不同的层，如下图所示</p><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi qa"><img src="../Images/c8e33c30c54d29b35653d69766e46278.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*p8Zac3yJxD2UENmf6kyvgQ.png"/></div></div></figure><p id="5307" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">我们有两组“卷积”和“ReLU”层。“视图”对最后一个“ReLU”层的输出张量进行展平。我们有大小为64x64的图像张量作为输入，由于应用了内核大小为2x2 (32 = 64/2)的“MaxPool2D ”,它将减少到32x32。</p><p id="0f76" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">首先，我们将数据集按80:20的比例分为训练和测试</p><figure class="ks kt ku kv gt kw"><div class="bz fp l di"><div class="nk nl l"/></div></figure><p id="ff26" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">然后，我们将编写一个自定义类，通过扩展PyTorch库提供的“模块”来堆叠这些层</p><figure class="ks kt ku kv gt kw"><div class="bz fp l di"><div class="nk nl l"/></div></figure><p id="f8a0" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">__init__ '定义每个层及其参数，而' forward '函数执行实际调用和层堆叠。最后一层的输出从“forward”函数返回。</p><h2 id="3175" class="nr mo it bd mp on oo dn mt op oq dp mx lr or os mz lv ot ou nb lz ov ow nd iz bi translated">模特培训</h2><p id="f8e7" class="pw-post-body-paragraph li lj it lk b ll nf kd ln lo ng kg lq lr nh lt lu lv ni lx ly lz nj mb mc md im bi translated">我们需要一个优化器和损失函数来进行模型训练。为此，我们将使用'<a class="ae lh" href="https://engmrk.com/adam-optimization-algorithm/" rel="noopener ugc nofollow" target="_blank"> Adam优化器</a> ' &amp; ' <a class="ae lh" href="https://ml-cheatsheet.readthedocs.io/en/latest/loss_functions.html" rel="noopener ugc nofollow" target="_blank">交叉熵损失</a>。</p><pre class="ks kt ku kv gt nm nn no np aw nq bi"><span id="c6dd" class="nr mo it nn b gy ns nt l nu nv">from torch.optim import Adam</span><span id="e1d7" class="nr mo it nn b gy qb nt l nu nv">cnn_model = FlowerClassifierCNNModel()<br/>optimizer = Adam(cnn_model.parameters())<br/>loss_fn = nn.CrossEntropyLoss()</span></pre><p id="86e1" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">使用PyTorch，我们需要将模型设置为训练模式，然后通过迭代训练数据集、计算优化器的损失和增量步骤来运行训练。</p><p id="78e8" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">我们可以为此写一个函数</p><figure class="ks kt ku kv gt kw"><div class="bz fp l di"><div class="nk nl l"/></div></figure><p id="736d" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">函数调用“loss.backward”返回到各层，并计算过程中发生的损失。</p><p id="06ef" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">我们将使用200的“epoche”来训练模型</p><pre class="ks kt ku kv gt nm nn no np aw nq bi"><span id="37ce" class="nr mo it nn b gy ns nt l nu nv">train_and_build(200)</span></pre><h2 id="43a2" class="nr mo it bd mp on oo dn mt op oq dp mx lr or os mz lv ot ou nb lz ov ow nd iz bi translated">模型测试和准确性</h2><p id="2d10" class="pw-post-body-paragraph li lj it lk b ll nf kd ln lo ng kg lq lr nh lt lu lv ni lx ly lz nj mb mc md im bi translated">我们应该将模型设置为“评估”模式，以便在测试数据集上测试其准确性</p><figure class="ks kt ku kv gt kw"><div class="bz fp l di"><div class="nk nl l"/></div></figure><blockquote class="oy oz pa"><p id="5177" class="li lj pb lk b ll lm kd ln lo lp kg lq pc ls lt lu pd lw lx ly pe ma mb mc md im bi translated">' torch.max '函数返回'线性函数'输出张量的最大值。最大值推断预测的类别标签。</p><p id="cb20" class="li lj pb lk b ll lm kd ln lo lp kg lq pc ls lt lu pd lw lx ly pe ma mb mc md im bi translated">“torch.sum”函数对“预测”和“实际测试输出”张量之间的“与”运算输出的张量中的“1”进行求和。所以这个总和给出了正确预测的图像数量。</p></blockquote><p id="4819" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">这里我们得到了精确度</p><pre class="ks kt ku kv gt nm nn no np aw nq bi"><span id="8975" class="nr mo it nn b gy ns nt l nu nv">test_accuracy</span></pre><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div class="gh gi qc"><img src="../Images/6d9b692ff15adb835f314fa0bed3edfa.png" data-original-src="https://miro.medium.com/v2/resize:fit:688/format:webp/1*yfmggL_ZE3HwuWsRJUJrpg.png"/></div></figure><p id="8d43" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">差不多是70.52%。我们用一个简单的模型得到了很好的精确度。这个模型可以进一步调整。</p><h1 id="8bb6" class="mn mo it bd mp mq mr ms mt mu mv mw mx ki my kj mz kl na km nb ko nc kp nd ne bi translated">使用模型对样本图像进行预测</h1><p id="6817" class="pw-post-body-paragraph li lj it lk b ll nf kd ln lo ng kg lq lr nh lt lu lv ni lx ly lz nj mb mc md im bi translated">现在，我们将看看如何使用来自数据集的样本图像来使用该模型。</p><pre class="ks kt ku kv gt nm nn no np aw nq bi"><span id="f20a" class="nr mo it nn b gy ns nt l nu nv">show_image("../data/flowers/dandelion/13920113_f03e867ea7_m.jpg")</span></pre><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div class="gh gi qd"><img src="../Images/443349bda515a58edeb9ce0afa837581.png" data-original-src="https://miro.medium.com/v2/resize:fit:624/format:webp/1*ix4i6eWJI90G0XqQDGA-fw.png"/></div></figure><p id="15da" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">这是一个“蒲公英”的图像。</p><p id="2373" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">现在，我们将使用PIL图像API读取图像，并将其输入到我们的转换管道中进行必要的预处理，然后使用模型进行预测</p><figure class="ks kt ku kv gt kw"><div class="bz fp l di"><div class="nk nl l"/></div></figure><pre class="ks kt ku kv gt nm nn no np aw nq bi"><span id="0cdd" class="nr mo it nn b gy ns nt l nu nv">class_index</span></pre><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div class="gh gi qe"><img src="../Images/9f138a338117cd65aa5826fd2f91383e.png" data-original-src="https://miro.medium.com/v2/resize:fit:104/format:webp/1*nCrLsC8_h1U-M1hMZtaIUQ.png"/></div></figure><p id="55df" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">所以，从上面提到的类到索引字典，我们可以确认它是一个‘蒲公英’。因此，我们的图像分类器模型运行良好！！</p><h1 id="0f36" class="mn mo it bd mp mq mr ms mt mu mv mw mx ki my kj mz kl na km nb ko nc kp nd ne bi translated">结论</h1><p id="a9f0" class="pw-post-body-paragraph li lj it lk b ll nf kd ln lo ng kg lq lr nh lt lu lv ni lx ly lz nj mb mc md im bi translated">我们学习了如何使用PyTorch库进行图像分类。在此过程中，我们介绍了图像的预处理、卷积层的构建以及输入图像模型的测试。</p><blockquote class="oy oz pa"><p id="a80a" class="li lj pb lk b ll lm kd ln lo lp kg lq pc ls lt lu pd lw lx ly pe ma mb mc md im bi translated">通过“超参数”调整，如试验“Adam optimizer”参数、添加额外的卷积层、调整内核大小和最大池窗口大小等，可以进一步提高模型的准确性。本文的读者可以自己尝试这些技术。</p></blockquote><p id="600e" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">Jupyter笔记本可以从下面的链接中找到</p><div class="pg ph gp gr pi pj"><a href="https://github.com/avisheknag17/public_ml_models/blob/master/image_classification_cnn_pytorch/notebook/cnn_image_classification_pytorch.ipynb" rel="noopener  ugc nofollow" target="_blank"><div class="pk ab fo"><div class="pl ab pm cl cj pn"><h2 class="bd jd gy z fp po fr fs pp fu fw jc bi translated">avisheknag17/public_ml_models</h2><div class="pq l"><h3 class="bd b gy z fp po fr fs pp fu fw dk translated">此时您不能执行该操作。您已使用另一个标签页或窗口登录。您已在另一个选项卡中注销，或者…</h3></div><div class="pr l"><p class="bd b dl z fp po fr fs pp fu fw dk translated">github.com</p></div></div><div class="ps l"><div class="qf l pu pv pw ps px lb pj"/></div></div></a></div><p id="993b" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">最近，我写了一本关于ML(<a class="ae lh" href="https://twitter.com/bpbonline/status/1256146448346988546" rel="noopener ugc nofollow" target="_blank">https://twitter.com/bpbonline/status/1256146448346988546</a>)的书</p></div></div>    
</body>
</html>