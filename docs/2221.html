<html>
<head>
<title>The AI Monthly Top 3 — September 2021</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">人工智能月度前三名—2021年9月</h1>
<blockquote>原文：<a href="https://pub.towardsai.net/the-ai-monthly-top-3-semptember-2021-e730e304771c?source=collection_archive---------4-----------------------#2021-10-04">https://pub.towardsai.net/the-ai-monthly-top-3-semptember-2021-e730e304771c?source=collection_archive---------4-----------------------#2021-10-04</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><h2 id="3bcb" class="ir is it bd b dl iu iv iw ix iy iz dk ja translated" aria-label="kicker paragraph"><a class="ae ep" href="https://towardsai.net/p/category/newsletter" rel="noopener ugc nofollow" target="_blank">简讯</a></h2><div class=""/><div class=""><h2 id="b5c3" class="pw-subtitle-paragraph jz jc it bd b ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq dk translated">最有趣的9月人工智能突破，包括视频演示、短文、代码和论文参考。</h2></div><blockquote class="kr ks kt"><p id="99f5" class="ku kv kw kx b ky kz kd la lb lc kg ld le lf lg lh li lj lk ll lm ln lo lp lq im bi translated">原载于<a class="ae lr" href="https://www.louisbouchard.ai/ai-monthly-top-3-september-2021/" rel="noopener ugc nofollow" target="_blank"> louisbouchard.ai </a>，前两天在<a class="ae lr" href="https://www.louisbouchard.ai/ai-monthly-top-3-september-2021/" rel="noopener ugc nofollow" target="_blank">我的博客</a>上看到的！</p></blockquote><figure class="lt lu lv lw gt lx gh gi paragraph-image"><div role="button" tabindex="0" class="ly lz di ma bf mb"><div class="gh gi ls"><img src="../Images/0a24b83dd31ac69e8e4392f0502a2339.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*kfRZppNrKhvX8EM3yFfe6A.png"/></div></div></figure><p id="b5b6" class="pw-post-body-paragraph ku kv it kx b ky kz kd la lb lc kg ld me lf lg lh mf lj lk ll mg ln lo lp lq im bi translated">如果你错过了其中的任何一篇，这里有3篇本月最有趣的研究论文。它是按发布日期排列的人工智能和数据科学的<strong class="kx jd">最新突破的精选列表，带有<strong class="kx jd">清晰的视频解释</strong>、<strong class="kx jd">指向更深入文章的链接</strong>和<strong class="kx jd">代码</strong>(如果适用)。享受阅读，如果我错过了任何重要的论文，请在评论中告诉我，或者直接在<a class="ae lr" href="https://www.linkedin.com/in/whats-ai/" rel="noopener ugc nofollow" target="_blank"> LinkedIn </a>上联系我！</strong></p><p id="bd2e" class="pw-post-body-paragraph ku kv it kx b ky kz kd la lb lc kg ld me lf lg lh mf lj lk ll mg ln lo lp lq im bi translated">如果你也想阅读更多的研究论文，我推荐你阅读我的文章<a class="ae lr" rel="noopener ugc nofollow" target="_blank" href="/how-to-read-more-research-papers-7737e3770d7f"><strong class="kx jd"/></a>，在那里我分享了寻找和阅读更多研究论文的最佳技巧。</p><blockquote class="mh"><p id="021b" class="mi mj it bd mk ml mm mn mo mp mq lq dk translated">跟着我上<a class="ae lr" href="https://whats-ai.medium.com/membership" rel="noopener">媒</a>看这个AI top 3月度！</p></blockquote></div><div class="ab cl mr ms hx mt" role="separator"><span class="mu bw bk mv mw mx"/><span class="mu bw bk mv mw mx"/><span class="mu bw bk mv mw"/></div><div class="im in io ip iq"><h1 id="8c7d" class="my mz it bd na nb nc nd ne nf ng nh ni ki nj kj nk kl nl km nm ko nn kp no np bi translated">论文#1:</h1><h2 id="a91e" class="nq mz it bd na nr ns dn ne nt nu dp ni me nv nw nk mf nx ny nm mg nz oa no iz bi translated"><a class="ae lr" href="https://arxiv.org/abs/2103.17249" rel="noopener ugc nofollow" target="_blank"> Styleclip:文本驱动的StyleGAN图像操作[1] </a></h2><p id="dbb2" class="pw-post-body-paragraph ku kv it kx b ky ob kd la lb oc kg ld me od lg lh mf oe lk ll mg of lo lp lq im bi translated">人工智能可以生成图像，然后，使用大量的脑力和反复试验，研究人员可以按照特定的风格控制结果。现在，有了这个新模型，你可以只用文本就能做到！</p><h2 id="334f" class="nq mz it bd na nr ns dn ne nt nu dp ni me nv nw nk mf nx ny nm mg nz oa no iz bi translated">观看视频</h2><figure class="lt lu lv lw gt lx"><div class="bz fp l di"><div class="og oh l"/></div></figure><h2 id="fc2a" class="nq mz it bd na nr ns dn ne nt nu dp ni me nv nw nk mf nx ny nm mg nz oa no iz bi translated">简短阅读版本</h2><div class="oi oj gp gr ok ol"><a rel="noopener  ugc nofollow" target="_blank" href="/manipulate-real-images-with-text-25b9f583e292"><div class="om ab fo"><div class="on ab oo cl cj op"><h2 class="bd jd gy z fp oq fr fs or fu fw jc bi translated">用文本处理真实图像</h2><div class="os l"><h3 class="bd b gy z fp oq fr fs or fu fw dk translated">创意艺术家的人工智能！StyleCLIP解释</h3></div><div class="ot l"><p class="bd b dl z fp oq fr fs or fu fw dk translated">pub.towardsai.net</p></div></div><div class="ou l"><div class="ov l ow ox oy ou oz mc ol"/></div></div></a></div><p id="b6b7" class="pw-post-body-paragraph ku kv it kx b ky kz kd la lb lc kg ld me lf lg lh mf lj lk ll mg ln lo lp lq im bi translated">代码(与本地GUI或colab笔记本一起使用):<a class="ae lr" href="https://github.com/orpatashnik/StyleCLIP" rel="noopener ugc nofollow" target="_blank">https://github.com/orpatashnik/StyleCLIP</a></p><p id="4258" class="pw-post-body-paragraph ku kv it kx b ky kz kd la lb lc kg ld me lf lg lh mf lj lk ll mg ln lo lp lq im bi translated">演示:<a class="ae lr" href="https://colab.research.google.com/github/orpatashnik/StyleCLIP/blob/main/notebooks/StyleCLIP_global.ipynb" rel="noopener ugc nofollow" target="_blank">https://colab . research . Google . com/github/orpatashnik/style clip/blob/main/notebooks/style clip _ global . ipynb</a></p><figure class="lt lu lv lw gt lx gh gi paragraph-image"><a href="http://eepurl.com/huGLT5"><div class="gh gi pa"><img src="../Images/44c5c65ec9df7b7d9a6472ab941ad3d1.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*135hkaDvwAIsdxZUx9a-rg.png"/></div></a></figure></div><div class="ab cl mr ms hx mt" role="separator"><span class="mu bw bk mv mw mx"/><span class="mu bw bk mv mw mx"/><span class="mu bw bk mv mw"/></div><div class="im in io ip iq"><h1 id="e690" class="my mz it bd na nb nc nd ne nf ng nh ni ki nj kj nk kl nl km nm ko nn kp no np bi translated">论文#2:</h1><h2 id="d997" class="nq mz it bd na nr ns dn ne nt nu dp ni me nv nw nk mf nx ny nm mg nz oa no iz bi translated"><a class="ae lr" href="http://rpg.ifi.uzh.ch/docs/CVPR21_Gehrig.pdf" rel="noopener ugc nofollow" target="_blank"> TimeLens:基于事件的视频帧插值[2] </a></h2><p id="7e23" class="pw-post-body-paragraph ku kv it kx b ky ob kd la lb oc kg ld me od lg lh mf oe lk ll mg of lo lp lq im bi translated">TimeLens可以理解视频帧之间的粒子运动，以我们肉眼无法看到的速度重建真实发生的事情。事实上，它实现了我们的智能手机和其他型号之前无法达到的效果！</p><h2 id="de80" class="nq mz it bd na nr ns dn ne nt nu dp ni me nv nw nk mf nx ny nm mg nz oa no iz bi translated">观看视频</h2><div class="oi oj gp gr ok ol"><a href="https://www.louisbouchard.ai/timelens/" rel="noopener  ugc nofollow" target="_blank"><div class="om ab fo"><div class="on ab oo cl cj op"><h2 class="bd jd gy z fp oq fr fs or fu fw jc bi translated">如何用AI制作慢动作视频！</h2><div class="os l"><h3 class="bd b gy z fp oq fr fs or fu fw dk translated">TimeLens可以理解视频帧之间的粒子运动，以重建真正的…</h3></div><div class="ot l"><p class="bd b dl z fp oq fr fs or fu fw dk translated">www.louisbouchard.ai</p></div></div><div class="ou l"><div class="pb l ow ox oy ou oz mc ol"/></div></div></a></div><h2 id="0510" class="nq mz it bd na nr ns dn ne nt nu dp ni me nv nw nk mf nx ny nm mg nz oa no iz bi translated">简短阅读版本</h2><div class="oi oj gp gr ok ol"><a rel="noopener  ugc nofollow" target="_blank" href="/change-video-into-slow-motion-with-ai-timelens-explained-4281d97c9b9d"><div class="om ab fo"><div class="on ab oo cl cj op"><h2 class="bd jd gy z fp oq fr fs or fu fw jc bi translated">用AI把视频换成慢动作！TimeLens解释道</h2><div class="os l"><h3 class="bd b gy z fp oq fr fs or fu fw dk translated">时间镜头可以理解视频帧之间的粒子运动，以重建真正的…</h3></div><div class="ot l"><p class="bd b dl z fp oq fr fs or fu fw dk translated">pub.towardsai.net</p></div></div><div class="ou l"><div class="pc l ow ox oy ou oz mc ol"/></div></div></a></div><p id="a1be" class="pw-post-body-paragraph ku kv it kx b ky kz kd la lb lc kg ld me lf lg lh mf lj lk ll mg ln lo lp lq im bi translated">官方代号:<a class="ae lr" href="https://github.com/uzh-rpg/rpg_timelens" rel="noopener ugc nofollow" target="_blank">https://github.com/uzh-rpg/rpg_timelens</a></p><figure class="lt lu lv lw gt lx gh gi paragraph-image"><a href="https://www.louisbouchard.ai/learnai/"><div class="gh gi pd"><img src="../Images/5343680522879ba9f9f07a9b1444e6de.png" data-original-src="https://miro.medium.com/v2/resize:fit:924/format:webp/0*Cxof5qlGRP3Fty_h.png"/></div></a></figure></div><div class="ab cl mr ms hx mt" role="separator"><span class="mu bw bk mv mw mx"/><span class="mu bw bk mv mw mx"/><span class="mu bw bk mv mw"/></div><div class="im in io ip iq"><h1 id="8ad7" class="my mz it bd na nb nc nd ne nf ng nh ni ki nj kj nk kl nl km nm ko nn kp no np bi translated">论文#3:</h1><h2 id="d10b" class="nq mz it bd na nr ns dn ne nt nu dp ni me nv nw nk mf nx ny nm mg nz oa no iz bi translated"><a class="ae lr" href="https://arxiv.org/abs/2109.08591" rel="noopener ugc nofollow" target="_blank">从一个视频中产生不同的一代人成为可能【3】</a></h2><p id="7ac4" class="pw-post-body-paragraph ku kv it kx b ky ob kd la lb oc kg ld me od lg lh mf oe lk ll mg of lo lp lq im bi translated">你有没有想过剪辑一个视频？</p><p id="a578" class="pw-post-body-paragraph ku kv it kx b ky kz kd la lb lc kg ld me lf lg lh mf lj lk ll mg ln lo lp lq im bi translated">删除或添加某人，更改背景，使其持续更长时间，或者更改分辨率以适应特定的纵横比，而不压缩或拉伸它。对于那些已经开展过广告活动的人来说，你肯定希望有不同的视频来进行AB测试，看看什么效果最好。Niv Haim等人的这项新研究可以帮助你在一个高清视频中完成所有这些事情！</p><p id="2e82" class="pw-post-body-paragraph ku kv it kx b ky kz kd la lb lc kg ld me lf lg lh mf lj lk ll mg ln lo lp lq im bi translated">的确，使用一个简单的视频，你可以在几秒钟或几分钟内完成我刚才提到的任何高质量视频的任务。你基本上可以把它用于任何你想到的视频操作或视频生成应用。它甚至在所有方面都优于GANs，并且不使用任何深度学习的花哨研究，也不需要庞大而不切实际的数据集！最棒的是，这项技术可以扩展到高分辨率视频。</p><h2 id="e681" class="nq mz it bd na nr ns dn ne nt nu dp ni me nv nw nk mf nx ny nm mg nz oa no iz bi translated">观看视频</h2><figure class="lt lu lv lw gt lx"><div class="bz fp l di"><div class="og oh l"/></div></figure><h2 id="aa39" class="nq mz it bd na nr ns dn ne nt nu dp ni me nv nw nk mf nx ny nm mg nz oa no iz bi translated">简短阅读版本</h2><div class="oi oj gp gr ok ol"><a rel="noopener  ugc nofollow" target="_blank" href="/diverse-generation-from-a-single-video-made-possible-no-dataset-or-deep-learning-required-f4377c0c56bf"><div class="om ab fo"><div class="on ab oo cl cj op"><h2 class="bd jd gy z fp oq fr fs or fu fw jc bi translated">从单个视频生成不同的内容成为可能—不需要数据集或深度学习！</h2><div class="os l"><h3 class="bd b gy z fp oq fr fs or fu fw dk translated">这种模式可以做任何视频操作或视频生成应用程序，你记住了！</h3></div><div class="ot l"><p class="bd b dl z fp oq fr fs or fu fw dk translated">pub.towardsai.net</p></div></div><div class="ou l"><div class="pe l ow ox oy ou oz mc ol"/></div></div></a></div><p id="cb83" class="pw-post-body-paragraph ku kv it kx b ky kz kd la lb lc kg ld me lf lg lh mf lj lk ll mg ln lo lp lq im bi translated">代码(即将推出):【https://nivha.github.io/vgpnn/ T4】</p></div><div class="ab cl mr ms hx mt" role="separator"><span class="mu bw bk mv mw mx"/><span class="mu bw bk mv mw mx"/><span class="mu bw bk mv mw"/></div><div class="im in io ip iq"><h1 id="77e3" class="my mz it bd na nb nc nd ne nf ng nh ni ki nj kj nk kl nl km nm ko nn kp no np bi translated">人工智能专业人员的奖金</h1><h2 id="607f" class="nq mz it bd na nr ns dn ne nt nu dp ni me nv nw nk mf nx ny nm mg nz oa no iz bi translated">人工智能中任何人都应该知道的8个工具</h2><figure class="lt lu lv lw gt lx"><div class="bz fp l di"><div class="og oh l"/></div></figure><p id="072f" class="pw-post-body-paragraph ku kv it kx b ky kz kd la lb lc kg ld me lf lg lh mf lj lk ll mg ln lo lp lq im bi translated">两年前，我看到了我的第一篇研究论文。我记得它看起来有多旧，里面的数学是多么令人沮丧。这看起来确实像研究人员在电影中所做的工作。公平地说，这张纸是上世纪50年代的，但从那以后就没怎么变过。时至今日，在去年为我的youtube频道读了几百篇论文后，我获得了很多阅读它们的经验，在那里我试图简单地解释它们。尽管如此，我知道第一次阅读是多么令人难以接受，尤其是第一次阅读你的第一篇研究论文。这就是为什么我想分享我的最佳技巧和实用工具 <strong class="kx jd">的原因，我每天使用</strong>来<strong class="kx jd">简化我的生活，在寻找和阅读有趣的研究论文时更有效率</strong>。</p><p id="43e8" class="pw-post-body-paragraph ku kv it kx b ky kz kd la lb lc kg ld me lf lg lh mf lj lk ll mg ln lo lp lq im bi translated">这里是我作为一名研究科学家每天用来寻找和阅读人工智能研究论文的最有用的工具… <a class="ae lr" href="https://www.louisbouchard.ai/research-papers/" rel="noopener ugc nofollow" target="_blank">在这里阅读更多。</a></p></div><div class="ab cl mr ms hx mt" role="separator"><span class="mu bw bk mv mw mx"/><span class="mu bw bk mv mw mx"/><span class="mu bw bk mv mw"/></div><div class="im in io ip iq"><p id="e400" class="pw-post-body-paragraph ku kv it kx b ky kz kd la lb lc kg ld me lf lg lh mf lj lk ll mg ln lo lp lq im bi translated">如果你喜欢我的工作，并想与人工智能保持同步，你绝对应该关注我的其他社交媒体账户(<a class="ae lr" href="https://www.linkedin.com/in/whats-ai/" rel="noopener ugc nofollow" target="_blank"> LinkedIn </a>，<a class="ae lr" href="https://twitter.com/Whats_AI" rel="noopener ugc nofollow" target="_blank"> Twitter </a>)，并订阅我的每周人工智能<a class="ae lr" href="http://eepurl.com/huGLT5" rel="noopener ugc nofollow" target="_blank"> <strong class="kx jd">简讯</strong> </a>！</p><h2 id="cda9" class="nq mz it bd na nr ns dn ne nt nu dp ni me nv nw nk mf nx ny nm mg nz oa no iz bi translated">支持我:</h2><ul class=""><li id="4d01" class="pf pg it kx b ky ob lb oc me ph mf pi mg pj lq pk pl pm pn bi translated">支持我的最好方式是在<a class="ae lr" href="https://whats-ai.medium.com/membership" rel="noopener"><strong class="kx jd">Medium</strong></a><strong class="kx jd"/>上关注我，或者如果你喜欢视频格式，在<a class="ae lr" href="https://www.youtube.com/channel/UCUzGQrN-lyyc0BWTYoJM_Sg" rel="noopener ugc nofollow" target="_blank"><strong class="kx jd">YouTube</strong></a><strong class="kx jd"/>上订阅我的频道<strong class="kx jd"> </strong>。</li><li id="f325" class="pf pg it kx b ky po lb pp me pq mf pr mg ps lq pk pl pm pn bi translated">支持我在<a class="ae lr" href="https://www.patreon.com/whatsai" rel="noopener ugc nofollow" target="_blank"> <strong class="kx jd"> Patreon </strong> </a> <strong class="kx jd">上的工作。</strong></li><li id="f7f8" class="pf pg it kx b ky po lb pp me pq mf pr mg ps lq pk pl pm pn bi translated">加入我们的<a class="ae lr" href="https://discord.gg/learnaitogether" rel="noopener ugc nofollow" target="_blank"> <strong class="kx jd"> Discord社区:</strong> <strong class="kx jd">一起学AI</strong></a>和<em class="kw">分享你的项目、论文、最佳课程、寻找Kaggle队友等等！</em></li></ul><h1 id="b098" class="my mz it bd na nb pt nd ne nf pu nh ni ki pv kj nk kl pw km nm ko px kp no np bi translated">参考</h1><p id="6404" class="pw-post-body-paragraph ku kv it kx b ky ob kd la lb oc kg ld me od lg lh mf oe lk ll mg of lo lp lq im bi translated">[1] Patashnik，Or，et al .(2021)，“风格剪辑:风格图像的文本驱动操作。”，<a class="ae lr" href="https://arxiv.org/abs/2103.17249" rel="noopener ugc nofollow" target="_blank">https://arxiv.org/abs/2103.17249</a></p><p id="5cce" class="pw-post-body-paragraph ku kv it kx b ky kz kd la lb lc kg ld me lf lg lh mf lj lk ll mg ln lo lp lq im bi translated">[2]斯捷潘·图利亚科夫*、丹尼尔·格赫里希*、斯塔马蒂亚斯·乔戈里斯、朱利叶斯·埃尔巴希、马蒂亚斯·格赫里希、李、大卫·斯卡拉穆扎，TimeLens:基于事件的视频帧内插，IEEE计算机视觉和模式识别会议(CVPR)，纳什维尔，2021，<a class="ae lr" href="http://rpg.ifi.uzh.ch/docs/CVPR21_Gehrig.pdf" rel="noopener ugc nofollow" target="_blank"/></p><p id="5e76" class="pw-post-body-paragraph ku kv it kx b ky kz kd la lb lc kg ld me lf lg lh mf lj lk ll mg ln lo lp lq im bi translated">[3]哈伊姆、范因斯坦、格拉诺特、肖彻、巴贡、戴克尔和伊拉尼(2021年)。多样化的一代从一个单一的视频成为可能，【https://arxiv.org/abs/2109.08591】T2。</p><figure class="lt lu lv lw gt lx gh gi paragraph-image"><div role="button" tabindex="0" class="ly lz di ma bf mb"><div class="gh gi py"><img src="../Images/c3e5b8ae0fe3bbaef874fa79cc850851.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*O82uEcQdSfRly266"/></div></div><figcaption class="pz qa gj gh gi qb qc bd b be z dk translated">照片由<a class="ae lr" href="https://unsplash.com/@cyrus_c?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Cyrus Chew </a>在<a class="ae lr" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上拍摄</figcaption></figure></div></div>    
</body>
</html>