<html>
<head>
<title>Get the Optimal K in K-Means Clustering</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">求K-均值聚类中的最优K</h1>
<blockquote>原文：<a href="https://pub.towardsai.net/get-the-optimal-k-in-k-means-clustering-d45b5b8a4315?source=collection_archive---------0-----------------------#2019-10-14">https://pub.towardsai.net/get-the-optimal-k-in-k-means-clustering-d45b5b8a4315?source=collection_archive---------0-----------------------#2019-10-14</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><figure class="is it gp gr iu iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi ir"><img src="../Images/a94d6c62d8b6819b4e62188221c4f1b3.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*iZCqQnP2fbpcwVo01G9qAw.jpeg"/></div></div><figcaption class="jc jd gj gh gi je jf bd b be z dk translated">照片由<a class="ae jg" href="https://unsplash.com/@ffstop?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText" rel="noopener ugc nofollow" target="_blank"> Fotis Fotopoulos </a>在<a class="ae jg" href="https://unsplash.com/s/photos/coding-cluster?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上拍摄</figcaption></figure><h2 id="3bd4" class="jh ji jj bd b dl jk jl jm jn jo jp dk jq translated" aria-label="kicker paragraph"><a class="ae ep" href="https://towardsai.net/p/category/machine-learning" rel="noopener ugc nofollow" target="_blank">机器学习</a>、<a class="ae ep" href="https://towardsai.net/p/category/tutorial" rel="noopener ugc nofollow" target="_blank">教程</a></h2><div class=""/><div class=""><h2 id="1aa7" class="pw-subtitle-paragraph kp js jj bd b kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg dk translated">提供快速入门指南，以便在K-means聚类中找到最佳的聚类数</h2></div><h2 id="d29c" class="lh li jj bd lj lk ll dn lm ln lo dp lp lq lr ls lt lu lv lw lx ly lz ma mb jp bi translated">介绍</h2><p id="1b61" class="pw-post-body-paragraph mc md jj me b mf mg kt mh mi mj kw mk lq ml mm mn lu mo mp mq ly mr ms mt mu im bi translated">聚类(或聚类分析)有助于识别和分组数据点，这些数据点使用某种距离度量与数据块或数据段密切相关。聚类被归类为机器学习空间内的无监督学习，这意味着没有标记。</p><p id="e84e" class="pw-post-body-paragraph mc md jj me b mf mv kt mh mi mw kw mk lq mx mm mn lu my mp mq ly mz ms mt mu im bi translated">对于利用数据科学的商业或公司来说，它是机器学习中的重要技术之一。几个使用案例是:</p><ul class=""><li id="51ab" class="na nb jj me b mf mv mi mw lq nc lu nd ly ne mu nf ng nh ni bi translated">在金融行业，可以使用异常检测来识别可疑活动和个人</li><li id="899f" class="na nb jj me b mf nj mi nk lq nl lu nm ly nn mu nf ng nh ni bi translated">在生物学中，聚类用于寻找具有相似特性或表达模式的基因组</li><li id="5514" class="na nb jj me b mf nj mi nk lq nl lu nm ly nn mu nf ng nh ni bi translated">在营销科学中，聚类用于通过各种特征来识别相似客户的细分。有了这些细分市场，企业可以制定个性化的营销策略和计划，以相应地应对每个细分市场</li></ul><p id="61b1" class="pw-post-body-paragraph mc md jj me b mf mv kt mh mi mw kw mk lq mx mm mn lu my mp mq ly mz ms mt mu im bi translated"><strong class="me jt"><em class="no">k</em>-means clustering</strong>(不要与机器学习技术混淆:k-nearest neighborhood classifier)是数据挖掘中聚类分析的常用方法。该方法旨在将给定的观察值划分为<strong class="me jt"> <em class="no"> k </em> </strong>个簇，其中每个观察值都在具有<strong class="me jt">最近均值</strong>的簇中。</p><p id="7041" class="pw-post-body-paragraph mc md jj me b mf mv kt mh mi mw kw mk lq mx mm mn lu my mp mq ly mz ms mt mu im bi translated">K-means聚类被归类为<strong class="me jt"> <em class="no">基于原型的聚类</em> </strong>，因为每个聚类由一个原型表示，该原型可以是具有连续特征的相似点的<strong class="me jt">形心</strong> ( <em class="no">平均值</em>)，或者是分类特征情况下的<strong class="me jt"> medoid </strong>(最具<em class="no">代表性的</em>或最频繁出现的点)。</p><p id="bce2" class="pw-post-body-paragraph mc md jj me b mf mv kt mh mi mw kw mk lq mx mm mn lu my mp mq ly mz ms mt mu im bi translated">选择正确数量的<strong class="me jt"> <em class="no"> k </em> </strong>类可能有点棘手，本文将展示k-means聚类的基本原理以及如何选择正确数量的类，这将帮助您启动您的聚类项目。</p><figure class="nq nr ns nt gt iv gh gi paragraph-image"><div class="gh gi np"><img src="../Images/9153191930fa5b63c68ddf8ffa9f1961.png" data-original-src="https://miro.medium.com/v2/resize:fit:926/format:webp/1*CkgRZLFkiPxNqOLNm1gWig.jpeg"/></div><figcaption class="jc jd gj gh gi je jf bd b be z dk translated">聚类样本</figcaption></figure><h2 id="e962" class="lh li jj bd lj lk ll dn lm ln lo dp lp lq lr ls lt lu lv lw lx ly lz ma mb jp bi translated">基本原则</h2><p id="7f5f" class="pw-post-body-paragraph mc md jj me b mf mg kt mh mi mj kw mk lq ml mm mn lu mo mp mq ly mr ms mt mu im bi translated">有多种聚类算法，这些算法基于备选策略来解决问题。有两种主要的聚类技术；</p><ol class=""><li id="a7bc" class="na nb jj me b mf mv mi mw lq nc lu nd ly ne mu nu ng nh ni bi translated"><strong class="me jt">硬聚类</strong>技术，其中每个观察值必须只属于一个单独的聚类</li><li id="c194" class="na nb jj me b mf nj mi nk lq nl lu nm ly nn mu nu ng nh ni bi translated"><strong class="me jt">软</strong>(或<strong class="me jt">模糊</strong> ) <strong class="me jt">聚类</strong>，这是一种替代方法，它基于一个成员分数，该分数定义了元素与每个聚类兼容的程度。</li></ol><p id="2bf1" class="pw-post-body-paragraph mc md jj me b mf mv kt mh mi mw kw mk lq mx mm mn lu my mp mq ly mz ms mt mu im bi translated"><strong class="me jt"><em class="no"/></strong>-表示聚类算法将</p><ol class=""><li id="b3e7" class="na nb jj me b mf mv mi mw lq nc lu nd ly ne mu nu ng nh ni bi translated">随机分配简单点作为起始聚类中心(或<strong class="me jt">质心</strong>)。</li><li id="9452" class="na nb jj me b mf nj mi nk lq nl lu nm ly nn mu nu ng nh ni bi translated">然后，该算法将迭代地将质心移动到样本的中心。这种迭代方法使组内误差平方和最小化，有时称为组惯性。</li><li id="7660" class="na nb jj me b mf nj mi nk lq nl lu nm ly nn mu nu ng nh ni bi translated">继续步骤(2 ),直到达到定义的公差或达到最大迭代次数。</li></ol><p id="241e" class="pw-post-body-paragraph mc md jj me b mf mv kt mh mi mw kw mk lq mx mm mn lu my mp mq ly mz ms mt mu im bi translated">当质心移动时，它会计算<strong class="me jt"> <em class="no">平方欧氏距离</em> </strong>来衡量样本和质心之间的相似性。因此，k-means非常擅长识别具有球形形状的聚类(因为它使用平方欧几里得距离)。这也是一个缺点，因为在现实中，数据点不会是这样的形状，k-means不考虑方差，并且在高维时具有维数灾难的影响。</p><p id="04fd" class="pw-post-body-paragraph mc md jj me b mf mv kt mh mi mw kw mk lq mx mm mn lu my mp mq ly mz ms mt mu im bi translated">k-means的另一个缺点是用户需要指定聚类数，<strong class="me jt"><em class="no"/></strong>。这可能会导致分析和聚类性能下降。在本文中，我将展示几种有效选择k-means聚类数的方法。</p></div><div class="ab cl nv nw hx nx" role="separator"><span class="ny bw bk nz oa ob"/><span class="ny bw bk nz oa ob"/><span class="ny bw bk nz oa"/></div><div class="im in io ip iq"><h2 id="9fde" class="lh li jj bd lj lk ll dn lm ln lo dp lp lq lr ls lt lu lv lw lx ly lz ma mb jp bi translated">我的“k”是什么？</h2><p id="4199" class="pw-post-body-paragraph mc md jj me b mf mg kt mh mi mj kw mk lq ml mm mn lu mo mp mq ly mr ms mt mu im bi translated">这个问题没有明确的解决方法；什么是'<strong class="me jt">'最佳</strong>'集群数。聚类的最佳数量在某种程度上是主观的(尤其是在商业领域),并且取决于用于测量相似性的方法和聚类期间使用的参数。</p><p id="1c8c" class="pw-post-body-paragraph mc md jj me b mf mv kt mh mi mw kw mk lq mx mm mn lu my mp mq ly mz ms mt mu im bi translated">有两种方法可以使用:</p><ol class=""><li id="60ea" class="na nb jj me b mf mv mi mw lq nc lu nd ly ne mu nu ng nh ni bi translated"><strong class="me jt">直接方法</strong>包括优化标准(即在聚类平方和内)。<em class="no">弯头</em>和<em class="no">剪影</em>的方法都在此方法中。</li><li id="8ab9" class="na nb jj me b mf nj mi nk lq nl lu nm ly nn mu nu ng nh ni bi translated"><strong class="me jt">统计检验法</strong>这种方法将证据与原假设进行比较。<em class="no">缺口统计</em>就是其中一个例子。</li></ol><p id="4433" class="pw-post-body-paragraph mc md jj me b mf mv kt mh mi mw kw mk lq mx mm mn lu my mp mq ly mz ms mt mu im bi translated">这是要演示的数据点的示例，让我们来看看每一种方法。</p><figure class="nq nr ns nt gt iv gh gi paragraph-image"><div class="gh gi oc"><img src="../Images/06fea581973ce0d3d6f8b3b3a40befb9.png" data-original-src="https://miro.medium.com/v2/resize:fit:972/format:webp/1*eTEA8VP9AqPg-5Dd1EUOsQ.png"/></div><figcaption class="jc jd gj gh gi je jf bd b be z dk translated">它们有多少个集群？</figcaption></figure><h1 id="71c2" class="od li jj bd lj oe of og lm oh oi oj lp ky ok kz lt lb ol lc lx le om lf mb on bi translated">1.肘法</h1><p id="969e" class="pw-post-body-paragraph mc md jj me b mf mg kt mh mi mj kw mk lq ml mm mn lu mo mp mq ly mr ms mt mu im bi translated">众所周知的<strong class="me jt">肘法</strong>是基于最优簇数必须产生<strong class="me jt">小惯性、</strong>或总簇内变异<strong class="me jt">的假设来确定簇数。</strong>因此，惯性和集群数量之间会有一个权衡。</p><p id="28a2" class="pw-post-body-paragraph mc md jj me b mf mv kt mh mi mw kw mk lq mx mm mn lu my mp mq ly mz ms mt mu im bi translated">有了这个概念，我们应该选择一些集群，这样添加另一个集群不会有太大的改善。</p><figure class="nq nr ns nt gt iv gh gi paragraph-image"><div class="gh gi oo"><img src="../Images/eed4bec31aec3af5697d5bdea98e18cd.png" data-original-src="https://miro.medium.com/v2/resize:fit:1288/format:webp/1*-hmOKGfaUScq73e30R1q0g.png"/></div><figcaption class="jc jd gj gh gi je jf bd b be z dk translated">弯头位于<strong class="bd lj"> <em class="op"> k </em> = 3 </strong></figcaption></figure><p id="df90" class="pw-post-body-paragraph mc md jj me b mf mv kt mh mi mw kw mk lq mx mm mn lu my mp mq ly mz ms mt mu im bi translated">我们可以看到3个集群的惯性显著下降，我们通常称之为<strong class="me jt"> <em class="no">肘</em> </strong>。</p><p id="4989" class="pw-post-body-paragraph mc md jj me b mf mv kt mh mi mw kw mk lq mx mm mn lu my mp mq ly mz ms mt mu im bi translated">然后，我们可以使用它作为一些集群，如下所示。集群和你的直觉相似吗？</p><figure class="nq nr ns nt gt iv gh gi paragraph-image"><div class="gh gi oc"><img src="../Images/2e25fe8a961866585287b424e4f77e07.png" data-original-src="https://miro.medium.com/v2/resize:fit:972/format:webp/1*EvfRA_Yg28EA3AbNJqauAQ.png"/></div><figcaption class="jc jd gj gh gi je jf bd b be z dk translated">使用肘方法可视化3个集群</figcaption></figure><h1 id="71e4" class="od li jj bd lj oe of og lm oh oi oj lp ky ok kz lt lb ol lc lx le om lf mb on bi translated">2.剪影法</h1><p id="e394" class="pw-post-body-paragraph mc md jj me b mf mg kt mh mi mj kw mk lq ml mm mn lu mo mp mq ly mr ms mt mu im bi translated">侧影分数衡量观察结果的聚类程度，并估计聚类之间的平均距离。它希望找到最佳数量的聚类，这些聚类将数据集细分为彼此分离的密集块。有关更多信息，我将参考此处的<a class="ae jg" href="https://scikit-learn.org/stable/modules/generated/sklearn.metrics.silhouette_score.html" rel="noopener ugc nofollow" target="_blank">以获取实施指南和定义。</a></p><p id="0c01" class="pw-post-body-paragraph mc md jj me b mf mv kt mh mi mw kw mk lq mx mm mn lu my mp mq ly mz ms mt mu im bi translated">该值将介于-1和1之间，而接近0的值表示重叠的簇。负值通常表示观测值被分配到了错误的聚类。</p><figure class="nq nr ns nt gt iv gh gi paragraph-image"><div class="gh gi oq"><img src="../Images/9ebe8449a34abc510bb697b93f5ce231.png" data-original-src="https://miro.medium.com/v2/resize:fit:1090/format:webp/1*SnfUlyro6zSfPF8iG-tsJQ.png"/></div><figcaption class="jc jd gj gh gi je jf bd b be z dk translated">每组数的轮廓系数</figcaption></figure><p id="ca43" class="pw-post-body-paragraph mc md jj me b mf mv kt mh mi mw kw mk lq mx mm mn lu my mp mq ly mz ms mt mu im bi translated">我们可以清楚地看到<code class="fe or os ot ou b">silhouette score</code>如何在k=3时达到峰值，这表明有<strong class="me jt"> 3个致密团聚体</strong>。</p><p id="60cc" class="pw-post-body-paragraph mc md jj me b mf mv kt mh mi mw kw mk lq mx mm mn lu my mp mq ly mz ms mt mu im bi translated">而且，我们还可以对剪影情节做更多的处理。它显示一个聚类中的每个点与相邻聚类中的点的接近程度。</p><p id="08ca" class="pw-post-body-paragraph mc md jj me b mf mv kt mh mi mw kw mk lq mx mm mn lu my mp mq ly mz ms mt mu im bi translated">样本可视化如下所示。</p><figure class="nq nr ns nt gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi ov"><img src="../Images/503924d6d2df1da37c5ef1af457919e3.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*fwHvSGa6COyHT8LCJwz6qg.png"/></div></div><figcaption class="jc jd gj gh gi je jf bd b be z dk translated">2至5个集群的轮廓图</figcaption></figure><p id="1d28" class="pw-post-body-paragraph mc md jj me b mf mv kt mh mi mw kw mk lq mx mm mn lu my mp mq ly mz ms mt mu im bi translated">即使剪影得分在k=3时显示最高分，但在聚类数据上，我更喜欢使用k=4(甚至5个聚类)。你怎么想呢?</p><h1 id="3e2f" class="od li jj bd lj oe of og lm oh oi oj lp ky ok kz lt lb ol lc lx le om lf mb on bi translated">3.差距统计法</h1><p id="95dc" class="pw-post-body-paragraph mc md jj me b mf mg kt mh mi mj kw mk lq ml mm mn lu mo mp mq ly mr ms mt mu im bi translated">差距统计是由<a class="ae jg" href="https://web.stanford.edu/~hastie/Papers/gap.pdf" rel="noopener ugc nofollow" target="_blank">蒂布希拉尼、瓦尔特和哈斯蒂在他们2001年的论文</a>中提出的。它将不同的<em class="no"> k </em>值的总体组内变异与数据的零参考分布下的预期值进行比较。因此，<em class="no"> k </em>的最佳选择是使间隙最大化的值(意味着聚类结构远离点的随机均匀分布)。</p><figure class="nq nr ns nt gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi ow"><img src="../Images/f6c2b04b9e0c5597e80f77a0f7aaf034.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*9R4MGNEwXIr3ZX0Ey44bWw.png"/></div></div><figcaption class="jc jd gj gh gi je jf bd b be z dk translated">k=5产生最高的间隙值</figcaption></figure><figure class="nq nr ns nt gt iv gh gi paragraph-image"><div class="gh gi ox"><img src="../Images/b1ce4c122cc93c38811f94a32dfeb724.png" data-original-src="https://miro.medium.com/v2/resize:fit:976/format:webp/1*ISbDIIB1StUJlhPhvIL7HA.png"/></div><figcaption class="jc jd gj gh gi je jf bd b be z dk translated">5个集群的可视化</figcaption></figure><p id="7638" class="pw-post-body-paragraph mc md jj me b mf mv kt mh mi mw kw mk lq mx mm mn lu my mp mq ly mz ms mt mu im bi translated">然后，我们可以使用差距统计法中的k=5在<code class="fe or os ot ou b">KMeans</code>中使用，并可视化聚类结果。</p><p id="fa4d" class="pw-post-body-paragraph mc md jj me b mf mv kt mh mi mw kw mk lq mx mm mn lu my mp mq ly mz ms mt mu im bi translated">这实际上是唯一的方法，它正确地将数据聚集成5个簇。</p><figure class="nq nr ns nt gt iv"><div class="bz fp l di"><div class="oy oz l"/></div><figcaption class="jc jd gj gh gi je jf bd b be z dk translated">生成起始数据块的源代码</figcaption></figure><p id="4ee6" class="pw-post-body-paragraph mc md jj me b mf mv kt mh mi mw kw mk lq mx mm mn lu my mp mq ly mz ms mt mu im bi translated">这些并不是找到最佳的聚类数的唯一技术。还有一些其他的技术，如Calinski-Harabasz指数，集群不稳定性等，每种技术都有自己的优点和缺点。</p></div><div class="ab cl nv nw hx nx" role="separator"><span class="ny bw bk nz oa ob"/><span class="ny bw bk nz oa ob"/><span class="ny bw bk nz oa"/></div><div class="im in io ip iq"><p id="8a9a" class="pw-post-body-paragraph mc md jj me b mf mv kt mh mi mw kw mk lq mx mm mn lu my mp mq ly mz ms mt mu im bi translated">希望这能给你关于<strong class="me jt"><em class="no">K-均值聚类</em> </strong>的直觉，以及我们如何为聚类找到最优的<em class="no"> k </em>。</p><p id="1d8f" class="pw-post-body-paragraph mc md jj me b mf mv kt mh mi mw kw mk lq mx mm mn lu my mp mq ly mz ms mt mu im bi translated">关于本教程的完整代码，请访问我下面的GitHub库:</p><div class="is it gp gr iu pa"><a href="https://github.com/netsatsawat/tutorial_KmeansClustering" rel="noopener  ugc nofollow" target="_blank"><div class="pb ab fo"><div class="pc ab pd cl cj pe"><h2 class="bd jt gy z fp pf fr fs pg fu fw js bi translated">netsatsawat/tutorial _ kmeans集群</h2><div class="ph l"><h3 class="bd b gy z fp pf fr fs pg fu fw dk translated">此时您不能执行该操作。您已使用另一个标签页或窗口登录。您已在另一个选项卡中注销，或者…</h3></div><div class="pi l"><p class="bd b dl z fp pf fr fs pg fu fw dk translated">github.com</p></div></div><div class="pj l"><div class="pk l pl pm pn pj po ja pa"/></div></div></a></div></div></div>    
</body>
</html>