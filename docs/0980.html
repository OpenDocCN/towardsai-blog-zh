<html>
<head>
<title>Everyone Can Understand Machine Learning — Regression Tree Model</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">每个人都能理解机器学习——回归树模型</h1>
<blockquote>原文：<a href="https://pub.towardsai.net/everyone-can-understand-machine-learning-regression-tree-model-28e3541b3e79?source=collection_archive---------1-----------------------#2020-09-27">https://pub.towardsai.net/everyone-can-understand-machine-learning-regression-tree-model-28e3541b3e79?source=collection_archive---------1-----------------------#2020-09-27</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><figure class="is it gp gr iu iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi ir"><img src="../Images/b2b9b7fda270a4c47651af0addbf472e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*CUIurKvG6Mj1cHrg8AMZ9A.jpeg"/></div></div><figcaption class="jc jd gj gh gi je jf bd b be z dk translated">照片由<a class="ae jg" href="https://pixabay.com/users/GregMontani-1014946/" rel="noopener ugc nofollow" target="_blank"> GregMontani </a>在<a class="ae jg" href="https://pixabay.com/photos/castle-avenue-trees-nature-sky-5511046/" rel="noopener ugc nofollow" target="_blank"> Pixabay </a>上拍摄</figcaption></figure><h2 id="45bd" class="jh ji jj bd b dl jk jl jm jn jo jp dk jq translated" aria-label="kicker paragraph"><a class="ae ep" href="https://towardsai.net/p/category/machine-learning" rel="noopener ugc nofollow" target="_blank">机器学习</a></h2><div class=""/><div class=""><h2 id="8305" class="pw-subtitle-paragraph kp js jj bd b kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg dk translated">没有公式、方程式和科学陈述的回归树模型介绍</h2></div><p id="041e" class="pw-post-body-paragraph lh li jj lj b lk ll kt lm ln lo kw lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated"><em class="md">本文旨在解释回归树机器学习模型，没有任何流行词汇和科学表达，因此您不需要任何先决知识或计算机科学/数学学位来理解它。</em></p><p id="5521" class="pw-post-body-paragraph lh li jj lj b lk ll kt lm ln lo kw lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">作为最常用的机器学习模型之一，决策树通常用于分类目的。但是，它也可用于预测连续数值。在这篇文章中，我将介绍一种特殊类型的决策树——回归树。如果你不是数据科学家或数据分析师，请不要担心，我会尽力帮助你了解回归树是如何在没有任何公式和方程的情况下构建的。</p><p id="f128" class="pw-post-body-paragraph lh li jj lj b lk ll kt lm ln lo kw lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">你不需要数学学位就能理解这一点:)</p><h1 id="0bb5" class="me mf jj bd mg mh mi mj mk ml mm mn mo ky mp kz mq lb mr lc ms le mt lf mu mv bi translated">抽样资料</h1><figure class="mw mx my mz gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi ir"><img src="../Images/291708055f8eb874b6892c36363f9a04.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*ZdRTkYJGuQL9fbk-y9rgFA.jpeg"/></div></div><figcaption class="jc jd gj gh gi je jf bd b be z dk translated">照片由<a class="ae jg" href="https://pixabay.com/users/congerdesign-509903/" rel="noopener ugc nofollow" target="_blank">设计师</a>在<a class="ae jg" href="https://pixabay.com/photos/apples-fruit-jam-fruit-preserve-5543778/" rel="noopener ugc nofollow" target="_blank"> Pixabay </a>上拍摄</figcaption></figure><p id="855f" class="pw-post-body-paragraph lh li jj lj b lk ll kt lm ln lo kw lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">让我们想象一个场景。我们普遍认为，学生在学习上花费越多，期末考试的分数就应该越高。假设我们有一群小学生被调查，问他们每周一般花多少小时学习，然后和他们的考试成绩关联起来就有了下面这个数据集。</p><figure class="mw mx my mz gt iv gh gi paragraph-image"><div class="gh gi na"><img src="../Images/1453831f0b8372907c35472ef72cb17f.png" data-original-src="https://miro.medium.com/v2/resize:fit:414/format:webp/1*TYCcPy_L0abTX7qe6EYR4A.png"/></div></figure><p id="4168" class="pw-post-body-paragraph lh li jj lj b lk ll kt lm ln lo kw lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">嗯，这看起来有点理想，因为我们知道考试结果不应该只受学习时间的影响，但这没关系。我们只是用它来演示回归树模型。还有一点很重要，就是数据绝对不是下图所示的线性。</p><figure class="mw mx my mz gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi nb"><img src="../Images/569f8c933ab42966284d510fe8426280.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*xUBot6KNyTuN9n_JYHQB6g.png"/></div></div></figure><h1 id="f38f" class="me mf jj bd mg mh mi mj mk ml mm mn mo ky mp kz mq lb mr lc ms le mt lf mu mv bi translated">分割节点(制作分支)</h1><figure class="mw mx my mz gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi ir"><img src="../Images/426c444f1352911564e9fdd17c86a32d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*N1vn0qiIeDtrfc6i3Vc2cw.jpeg"/></div></div><figcaption class="jc jd gj gh gi je jf bd b be z dk translated"><a class="ae jg" href="https://pixabay.com/users/Deeezy-15467098/" rel="noopener ugc nofollow" target="_blank"> Deeezy </a>在<a class="ae jg" href="https://pixabay.com/photos/canyon-gorge-perspective-nature-5552326/" rel="noopener ugc nofollow" target="_blank"> Pixabay </a>上拍摄的照片</figcaption></figure><p id="0013" class="pw-post-body-paragraph lh li jj lj b lk ll kt lm ln lo kw lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">毫不奇怪，构建回归树的过程基本上就是决定如何分割节点。或者，我们可以简单地说“做一个分支”。</p><h2 id="523b" class="nc mf jj bd mg nd ne dn mk nf ng dp mo lq nh ni mq lu nj nk ms ly nl nm mu jp bi translated">分支是什么意思？</h2><p id="3594" class="pw-post-body-paragraph lh li jj lj b lk nn kt lm ln no kw lp lq np ls lt lu nq lw lx ly nr ma mb mc im bi translated">假设我们想通过拆分条件为“学习时间&lt; 3.1”. This number “3.1” is the number between the 7th and the 8th data point, which is shown below (it shows 6th and 7th because we started from 0)</p><figure class="mw mx my mz gt iv gh gi paragraph-image"><div class="gh gi ns"><img src="../Images/4aeffb7f0517525e23e87494747ddca2.png" data-original-src="https://miro.medium.com/v2/resize:fit:600/format:webp/1*6hzlykBJVFn_Z3h-BD4YIA.png"/></div></figure><p id="75a2" class="pw-post-body-paragraph lh li jj lj b lk ll kt lm ln lo kw lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">As shown in the figure below, the red vertical line (Study Hour = 3.1) splits the data into the left region and the right region.</p><p id="d7dd" class="pw-post-body-paragraph lh li jj lj b lk ll kt lm ln lo kw lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">For each of the left and the right, we can calculate the average of all the data points with their “Marks”. The average for the left 7 points is <strong class="lj jt"> 15.96 </strong>的数据得到树的第一个分支，而右边16个点的平均值是<strong class="lj jt"> 87.65 </strong>。</p><figure class="mw mx my mz gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi nt"><img src="../Images/d0f7c1fd941f6825e9acdf46d02a8fad.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*zozRE0WGq_PNlwcs0ONMKQ.png"/></div></div></figure><p id="edb9" class="pw-post-body-paragraph lh li jj lj b lk ll kt lm ln lo kw lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">假设我们要做一个这样的分支，那么</p><ul class=""><li id="811a" class="nu nv jj lj b lk ll ln lo lq nw lu nx ly ny mc nz oa ob oc bi translated">每个学习时间少于3.1小时的学生将被预测为15.96分</li><li id="051d" class="nu nv jj lj b lk od ln oe lq of lu og ly oh mc nz oa ob oc bi translated">每个学习时间大于或等于3.1小时的学生将被预测为87.65分</li></ul><figure class="mw mx my mz gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi oi"><img src="../Images/4d170d7b9fadc472a94cc19ceacf0cb8.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*ofUT37iXc4tZBTUJo8RiBw.png"/></div></div></figure><p id="43e6" class="pw-post-body-paragraph lh li jj lj b lk ll kt lm ln lo kw lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">因此，我们最终得到如上所示的树。</p><p id="7692" class="pw-post-body-paragraph lh li jj lj b lk ll kt lm ln lo kw lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">但是，如何才能决定拆分条件呢？换句话说，为什么我们使用第7个和第8个之间的值进行分割，而不使用第8个和第9个或其他值？总共有24个值，所以我们有23个不同的分裂条件候选。</p><p id="5725" class="pw-post-body-paragraph lh li jj lj b lk ll kt lm ln lo kw lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">基本标准如下:</p><blockquote class="oj"><p id="6d68" class="ok ol jj bd om on oo op oq or os mc dk translated"><strong class="ak">每次拆分误差最小</strong></p></blockquote><h2 id="f009" class="nc mf jj bd mg nd ot dn mk nf ou dp mo lq ov ni mq lu ow nk ms ly ox nm mu jp bi translated">误差的测量</h2><p id="4fec" class="pw-post-body-paragraph lh li jj lj b lk nn kt lm ln no kw lp lq np ls lt lu nq lw lx ly nr ma mb mc im bi translated">如果我们想将误差降至最低，我们首先需要知道如何测量误差。</p><p id="3608" class="pw-post-body-paragraph lh li jj lj b lk ll kt lm ln lo kw lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">显然，当我们使用上面的树预测标记时，肯定会出现“错误”。例如，根据数据集，一个每周学习0.5小时的学生只有1.4分(如下所示)。然而，我们当前的回归树将预测它是15.96分。</p><figure class="mw mx my mz gt iv gh gi paragraph-image"><div class="gh gi oy"><img src="../Images/2ce28d1fba31a3e499f5be179fc466a2.png" data-original-src="https://miro.medium.com/v2/resize:fit:800/format:webp/1*4f_bf3RZOu41-BT6XhrVog.png"/></div></figure><p id="40c0" class="pw-post-body-paragraph lh li jj lj b lk ll kt lm ln lo kw lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">那么，误差就是两个值之差。也就是15.96–1.4 = 14.56。在下图中，所有的灰色虚线都是“错误”。</p><figure class="mw mx my mz gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi nt"><img src="../Images/55912a2cbbe2796dc243fa58b25cae37.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*-lrRcjyeJuwSaAxQwEtDmw.png"/></div></div></figure><p id="b9b0" class="pw-post-body-paragraph lh li jj lj b lk ll kt lm ln lo kw lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">好的。那么，如何决定最佳的拆分条件呢？基本上，我们会尝试每一种可能的方法来分割数据集，如下所示，然后选择误差最小的一个。</p><figure class="mw mx my mz gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi oz"><img src="../Images/a08b817579578b392ca76202c7d17865.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/1*T2xsqbrzwJ0nSl0M5nGIMA.gif"/></div></div></figure><p id="ebf1" class="pw-post-body-paragraph lh li jj lj b lk ll kt lm ln lo kw lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">如果你注意上面的GIF，你会发现，当我们在第7点和第8点之间拆分时，“总误差”会最小。总误差是实际标记和预测(平均)标记之间的差值的平方值，因此它是一个非常大的数字。</p><h2 id="e289" class="nc mf jj bd mg nd ne dn mk nf ng dp mo lq nh ni mq lu nj nk ms ly nl nm mu jp bi translated">继续分裂</h2><p id="ace0" class="pw-post-body-paragraph lh li jj lj b lk nn kt lm ln no kw lp lq np ls lt lu nq lw lx ly nr ma mb mc im bi translated">当然，虽然条件“学习时间&lt; 3.1”是第一次分割的最佳条件，但它没有得到充分优化，因为总误差仍然很大。所以，我们需要继续分裂这棵树，使它成为一个更好的模型。</p><p id="7364" class="pw-post-body-paragraph lh li jj lj b lk ll kt lm ln lo kw lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">在之前使用条件“学习时间&lt; 3.1”进行拆分后，我们得到了两个分支。左边的有7个样本，右边的有17个样本。</p><figure class="mw mx my mz gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi oi"><img src="../Images/648cd029228652f653f713f5f29d9e72.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Qunrr9i_38wc8AdGpJUlig.png"/></div></div></figure><p id="a423" class="pw-post-body-paragraph lh li jj lj b lk ll kt lm ln lo kw lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">上面示出的相同逻辑将被分别应用于左样本和右样本，以便我们可以如下对左样本和右样本进行最佳分割。</p><figure class="mw mx my mz gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi pa"><img src="../Images/27c042a3da850ae62e56f46161911af9.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*ELjO9Qbd7jn4RaJQUL-1Kw.png"/></div></div></figure><p id="d3ed" class="pw-post-body-paragraph lh li jj lj b lk ll kt lm ln lo kw lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">那就好多了！现在，当我们有一个过去只学习0.5小时的学生时，我们会预测分数是4.82，而实际分数是1.4。我们通过不断分割回归树模型，成功地改进了它。</p><h1 id="70dd" class="me mf jj bd mg mh mi mj mk ml mm mn mo ky mp kz mq lb mr lc ms le mt lf mu mv bi translated">过度拟合问题</h1><figure class="mw mx my mz gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi ir"><img src="../Images/cf16257c803e3bd3a45851b3a73400d9.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*FRAbntoNZtDXdiD5IZd_SQ.jpeg"/></div></div><figcaption class="jc jd gj gh gi je jf bd b be z dk translated">由<a class="ae jg" href="https://pixabay.com/users/raffaeledl-17131402/" rel="noopener ugc nofollow" target="_blank"> raffaeledl </a>在<a class="ae jg" href="https://pixabay.com/photos/village-rural-field-mountain-5521554/" rel="noopener ugc nofollow" target="_blank"> Pixabay </a>上拍摄的照片</figcaption></figure><p id="d4c0" class="pw-post-body-paragraph lh li jj lj b lk ll kt lm ln lo kw lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">现在我们知道了回归树模型是如何构建的。按照上面演示的逻辑，我们可以不断改进我们的模型，以获得越来越好的预测结果。</p><p id="3c52" class="pw-post-body-paragraph lh li jj lj b lk ll kt lm ln lo kw lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">但是，你有没有发现有一个问题？</p><figure class="mw mx my mz gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi pb"><img src="../Images/40f103da03f4d02f09e2e4a8b9e55cb0.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*gCpFGbc_CY35tQoEPuXWew.png"/></div></div></figure><p id="e557" class="pw-post-body-paragraph lh li jj lj b lk ll kt lm ln lo kw lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">我们来看看上图。我们可以继续分割第二个分支，它有两个样本，平均分数为43.8。所以，我们有另外两个分支。</p><ul class=""><li id="3752" class="nu nv jj lj b lk ll ln lo lq nw lu nx ly ny mc nz oa ob oc bi translated">当学习时间在2.3和2.7之间时，学生的分数预计为61.7</li><li id="17e8" class="nu nv jj lj b lk od ln oe lq of lu og ly oh mc nz oa ob oc bi translated">当学习时间在2.7小时和3.1小时之间时，学生的分数预计为25.9分</li></ul><p id="a706" class="pw-post-body-paragraph lh li jj lj b lk ll kt lm ln lo kw lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">如果我们使用我们的数据集(如下)验证该树，我们将发现这两个样本的误差为零！</p><figure class="mw mx my mz gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi pc"><img src="../Images/f5d8f573027c89eb416484dba5196a1d.png" data-original-src="https://miro.medium.com/v2/resize:fit:782/format:webp/1*CJUuLdJUNCZOd3Bzv3uyUg.png"/></div></div></figure><p id="428b" class="pw-post-body-paragraph lh li jj lj b lk ll kt lm ln lo kw lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">但是等等，有些不对劲。看起来我们的回归树模型认为学习时间多一点的学生分数会低一些。这说不通啊！</p><p id="ad8e" class="pw-post-body-paragraph lh li jj lj b lk ll kt lm ln lo kw lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">这是因为我们的原始数据集并不完美。实践中也有发生。毕竟不能说学生的考试成绩只看学习时间。例如，一些学生可能非常聪明，不需要像其他人一样花很多时间来获得相同的分数。</p><p id="57aa" class="pw-post-body-paragraph lh li jj lj b lk ll kt lm ln lo kw lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">在这种情况下，我们的模型完全符合我们的训练数据集，但在实践中会失败。也就是所谓的“<strong class="lj jt">过拟合</strong>”。</p><p id="8d6a" class="pw-post-body-paragraph lh li jj lj b lk ll kt lm ln lo kw lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">理论上，无论是分类还是回归，决策树机器学习模型都可以在训练数据上达到100%的准确率。只要让树有大量的分支，每个分支只有1个样本，这将达到100%的准确率。然而，这样的树在实践中毫无用处。我们需要避免过度拟合的问题。</p><h1 id="a337" class="me mf jj bd mg mh mi mj mk ml mm mn mo ky mp kz mq lb mr lc ms le mt lf mu mv bi translated">避免过度拟合问题</h1><figure class="mw mx my mz gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi ir"><img src="../Images/73af5dcd902ce3bc750b5220ea058e1c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Hya6FJ-zqNxmwSHQ8gwatA.jpeg"/></div></div><figcaption class="jc jd gj gh gi je jf bd b be z dk translated">由<a class="ae jg" href="https://pixabay.com/users/almatel-18074652/" rel="noopener ugc nofollow" target="_blank"> almatel </a>在<a class="ae jg" href="https://pixabay.com/photos/rice-field-rice-terraces-landscape-5530707/" rel="noopener ugc nofollow" target="_blank"> Pixabay </a>上拍摄的照片</figcaption></figure><p id="15c9" class="pw-post-body-paragraph lh li jj lj b lk ll kt lm ln lo kw lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">不幸的是，过拟合问题无法完全避免。但是有很多方法可以降低它的程度。有两种常用的方法。</p><h2 id="eec9" class="nc mf jj bd mg nd ne dn mk nf ng dp mo lq nh ni mq lu nj nk ms ly nl nm mu jp bi translated">限制树的深度</h2><figure class="mw mx my mz gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi pd"><img src="../Images/514c2cc36b6a70f758fdd511261fe5ee.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*CFqLWF_QRJ0dEM9mmWneBQ.png"/></div></div></figure><p id="0522" class="pw-post-body-paragraph lh li jj lj b lk ll kt lm ln lo kw lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">如果我们看一下上面生成的树，我们可以很容易地定义树的“深度”。基本上树的根会是深度= 0，拆分后的下一级是深度= 1，以此类推。</p><p id="7716" class="pw-post-body-paragraph lh li jj lj b lk ll kt lm ln lo kw lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">因此，我们可以限制树的深度，比如说<strong class="lj jt">最大深度是2 </strong>，以减少过拟合问题。然后，树的构建将在这里停止，因为我们已经达到了最大深度。</p><h2 id="611d" class="nc mf jj bd mg nd ne dn mk nf ng dp mo lq nh ni mq lu nj nk ms ly nl nm mu jp bi translated">限制叶子上的样本数</h2><p id="448d" class="pw-post-body-paragraph lh li jj lj b lk nn kt lm ln no kw lp lq np ls lt lu nq lw lx ly nr ma mb mc im bi translated">减少过拟合问题的另一种方法是限制叶子上的样本数量。如果你注意到我在树中使用了不同的颜色，绿框是“叶节点”,因为它们是树的末端，也用于预测。</p><p id="9eb1" class="pw-post-body-paragraph lh li jj lj b lk ll kt lm ln lo kw lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">假设我们限制样本的数量必须大于<strong class="lj jt"> 5 </strong>，那么我们应该得到如下的树。</p><figure class="mw mx my mz gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi pe"><img src="../Images/9d79b3ef7ebf7c626b6beb6529e6d2b2.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*aghtGTp6f8eJJSlwfQPkHw.png"/></div></div></figure><p id="0850" class="pw-post-body-paragraph lh li jj lj b lk ll kt lm ln lo kw lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">在上面的回归树中，我们没有少于5个样本的叶节点。另外，请注意，具有7个样本和平均分数= 15.96的第一个叶节点将不会被分割，因为我们从前面的例子中知道，在分割后，其中一个分支将只有2个样本。</p><p id="6620" class="pw-post-body-paragraph lh li jj lj b lk ll kt lm ln lo kw lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">在实践中，减少过拟合问题的两种方法可以一起使用。</p><h1 id="7d7a" class="me mf jj bd mg mh mi mj mk ml mm mn mo ky mp kz mq lb mr lc ms le mt lf mu mv bi translated">摘要</h1><figure class="mw mx my mz gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi ir"><img src="../Images/5afee4b74ee916349564773db2185a16.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*8yowFXYtJWmzl0mlqC-KHw.jpeg"/></div></div><figcaption class="jc jd gj gh gi je jf bd b be z dk translated">由<a class="ae jg" href="https://pixabay.com/users/EvgeniT-4930349/" rel="noopener ugc nofollow" target="_blank"> EvgeniT </a>在<a class="ae jg" href="https://pixabay.com/photos/autumn-lake-plane-trees-nature-4667080/" rel="noopener ugc nofollow" target="_blank"> Pixabay </a>拍摄的照片</figcaption></figure><p id="84d9" class="pw-post-body-paragraph lh li jj lj b lk ll kt lm ln lo kw lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">在这篇文章中，我挑战了自己，在没有任何公式、方程或科学表达式的情况下解释回归树机器学习算法。我相信一个没有任何计算机科学和数学学位的人应该能够理解这个ML模型的机制和直觉。</p><p id="9529" class="pw-post-body-paragraph lh li jj lj b lk ll kt lm ln lo kw lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">本文重点讨论了如何构造回归树以及如何确定分裂条件。然后，我还介绍了过拟合问题和用于减少过拟合问题程度的常用方法。</p><div class="is it gp gr iu pf"><a href="https://medium.com/@qiuyujx/membership" rel="noopener follow" target="_blank"><div class="pg ab fo"><div class="ph ab pi cl cj pj"><h2 class="bd jt gy z fp pk fr fs pl fu fw js bi translated">通过我的推荐链接加入Medium克里斯托弗·陶</h2><div class="pm l"><h3 class="bd b gy z fp pk fr fs pl fu fw dk translated">作为一个媒体会员，你的会员费的一部分会给你阅读的作家，你可以完全接触到每一个故事…</h3></div><div class="pn l"><p class="bd b dl z fp pk fr fs pl fu fw dk translated">medium.com</p></div></div><div class="po l"><div class="pp l pq pr ps po pt ja pf"/></div></div></a></div><p id="e3c8" class="pw-post-body-paragraph lh li jj lj b lk ll kt lm ln lo kw lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">如果你觉得我的文章有帮助，请考虑加入Medium会员来支持我和成千上万的其他作者！(点击上面的链接)</p></div></div>    
</body>
</html>