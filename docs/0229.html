<html>
<head>
<title>DNC: Differential Neural Network</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">差分神经网络</h1>
<blockquote>原文：<a href="https://pub.towardsai.net/dnc-differential-neural-network-3cfd82d0d99e?source=collection_archive---------0-----------------------#2019-12-08">https://pub.towardsai.net/dnc-differential-neural-network-3cfd82d0d99e?source=collection_archive---------0-----------------------#2019-12-08</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><h2 id="6532" class="ir is it bd b dl iu iv iw ix iy iz dk ja translated" aria-label="kicker paragraph"><a class="ae ep" href="https://towardsai.net/p/category/machine-learning" rel="noopener ugc nofollow" target="_blank">机器学习</a></h2><div class=""/><div class=""><h2 id="1004" class="pw-subtitle-paragraph jz jc it bd b ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq dk translated">DNC的详细演练</h2></div><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi kr"><img src="../Images/9de4f049717d0bf7b7434e03bcb8e98c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*-6JV_t-Zbgk4xHyUFyYsTg.jpeg"/></div></div><figcaption class="ld le gj gh gi lf lg bd b be z dk translated">由<a class="ae lh" href="https://unsplash.com/@fantasyflip?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText" rel="noopener ugc nofollow" target="_blank">菲利普·卡森伯格</a>在<a class="ae lh" href="https://unsplash.com/s/photos/computer?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上拍摄的照片</figcaption></figure><h1 id="f66e" class="li lj it bd lk ll lm ln lo lp lq lr ls ki lt kj lu kl lv km lw ko lx kp ly lz bi translated">介绍</h1><p id="ac42" class="pw-post-body-paragraph ma mb it mc b md me kd mf mg mh kg mi mj mk ml mm mn mo mp mq mr ms mt mu mv im bi translated">在<a class="ae lh" href="https://medium.com/towards-artificial-intelligence/neural-turing-machines-eaada7e7a6cc?source=friends_link&amp;sk=4e4ef671ea6220b57e3b279430678539" rel="noopener">之前的文章</a>中，我们讨论了神经图灵机(NTMs)，它引入了一个外部存储器来维护信息以供以后检索。在这篇文章中，我们进一步讨论一种更复杂的方法，即差分神经计算机(DNC)。DNC建立在与NTMs相同的理念上——两者都旨在通过向神经网络提供对外部存储器的读写访问，来结合神经和计算处理的优势。另一方面，它以更复杂和灵活的交互机制改进了NTMs，这使得它可能比NTMs更强大。</p><h1 id="be5e" class="li lj it bd lk ll lm ln lo lp lq lr ls ki lt kj lu kl lv km lw ko lx kp ly lz bi translated">差分神经计算机综述</h1><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi mw"><img src="../Images/cd61ab32e8bddae00e2be93852f5bdb7.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*N9ABN6IDCQh7GvL1u79L5w.png"/></div></div><figcaption class="ld le gj gh gi lf lg bd b be z dk translated">来源:Graves等人，使用具有动态外部存储器的神经网络的混合计算</figcaption></figure><p id="04af" class="pw-post-body-paragraph ma mb it mc b md mx kd mf mg my kg mi mj mz ml mm mn na mp mq mr nb mt mu mv im bi translated">原始论文中的上图展示了DNC的整体架构。下图进一步详细描述了其内部结构。</p><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi nc"><img src="../Images/39b359da7ff52c168c1604237f274c65.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*3FL7JcDqKRWdcQuyd-OlPg.png"/></div></div><figcaption class="ld le gj gh gi lf lg bd b be z dk translated">DNC的内部结构。紫色方块中的符号来自界面向量；橙色方块中的代表DNC以前的状态；红色方块表示当前状态。蓝色矩形中定义了操作</figcaption></figure><p id="b80e" class="pw-post-body-paragraph ma mb it mc b md mx kd mf mg my kg mi mj mz ml mm mn na mp mq mr nb mt mu mv im bi translated">我们首先简要介绍DNC单元中的各个部分，稍后将进行详细讨论。</p><ul class=""><li id="30a8" class="nd ne it mc b md mx mg my mj nf mn ng mr nh mv ni nj nk nl bi translated"><em class="nm">控制器</em>(通常为LSTM单元)接收来自环境的输入以及先前的读取向量，并发出输出向量和接口向量，后者负责与写入和读取模块的交互。</li><li id="0d51" class="nd ne it mc b md nn mg no mj np mn nq mr nr mv ni nj nk nl bi translated">写模块通过集成基于内容的查找和分配机制来操纵存储器矩阵。前者通过测量输入写密钥和存储器条目之间的相似性来生成权重，而后者基于每个存储器位置的使用来生成权重。</li><li id="54ae" class="nd ne it mc b md nn mg no mj np mn nq mr nr mv ni nj nk nl bi translated">read模块对三种类型的内存进行加权:由read键指示的基于内容的内存，以及按向前和向后写入顺序的临时内存。我们使用基于内容的查找来处理第一种类型的存储器，其余的使用时间链接机制，该机制利用一种可学习的相邻矩阵来跟踪顺序。</li></ul><h1 id="4195" class="li lj it bd lk ll lm ln lo lp lq lr ls ki lt kj lu kl lv km lw ko lx kp ly lz bi translated">控制器网络</h1><p id="bbd1" class="pw-post-body-paragraph ma mb it mc b md me kd mf mg mh kg mi mj mk ml mm mn mo mp mq mr ms mt mu mv im bi translated">我们将控制器总结为三个步骤</p><p id="7dbd" class="pw-post-body-paragraph ma mb it mc b md mx kd mf mg my kg mi mj mz ml mm mn na mp mq mr nb mt mu mv im bi translated">1.在每个时间步长<em class="nm"> t </em>，控制器网络接收来自环境(或数据集)的输入向量<strong class="mc jd"> <em class="nm"> x </em> </strong> <em class="nm"> _t∈R^X </em>以及来自存储器矩阵<strong class="mc jd"> <em class="nm"> M </em>的一组<em class="nm"> R </em>读取向量<strong class="mc jd"><em class="nm">r</em></strong><em class="nm">_ { t-1 }、…、</em><strong class="mc jd"><em class="nm">r</em></strong><em class="nm">_{t-1}^r</em></strong></p><p id="c3bc" class="pw-post-body-paragraph ma mb it mc b md mx kd mf mg my kg mi mj mz ml mm mn na mp mq mr nb mt mu mv im bi translated">2.然后它连接读取和输入向量以获得单个控制器输入向量<strong class="mc jd"><em class="nm">X</em></strong><em class="nm">_ t =[</em><strong class="mc jd"><em class="nm">X</em></strong><em class="nm">_ t；</em><strong class="mc jd"><em class="nm"/></strong><em class="nm">_ { t-1 }；…，</em><strong class="mc jd"><em class="nm">r</em></strong><em class="nm">【_{t-1}^r】</em>并通过它深入LSTM架构:</p><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div class="gh gi ns"><img src="../Images/4003fb1a24f065aca68c085d0e947452.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*XbdB-mJmWxyWhrlN_YOpKw.png"/></div><figcaption class="ld le gj gh gi lf lg bd b be z dk translated"><em class="nt"> l </em>是层指数，<em class="nt"> 𝜎(x) </em>是logistic sigmoid函数，<strong class="bd lk"> <em class="nt"> h </em> </strong> <em class="nt"> _t^l，</em><strong class="bd lk"><em class="nt">I</em></strong><em class="nt"/><strong class="bd lk"><em class="nt">f</em></strong><em class="nt">_t^l，</em><strong class="bd lk"><em class="nt">s<em class="nt"/> <em class="nt"> h⁰_t=0 </em>为全<em class="nt">师</em>；<strong class="bd lk"><em class="nt">h</em></strong><em class="nt">_0^l=</em><strong class="bd lk"><em class="nt">s</em></strong><em class="nt">_0^l=0</em>为全<em class="nt"> l </em>。这些只是常规LSTM堆栈的组件；这里没有什么新东西。</em></strong></figcaption></figure><p id="931b" class="pw-post-body-paragraph ma mb it mc b md mx kd mf mg my kg mi mj mz ml mm mn na mp mq mr nb mt mu mv im bi translated">3.控制器发出一个输出向量<strong class="mc jd"><em class="nm">v</em></strong><em class="nm">_ t</em>，定义为</p><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div class="gh gi nu"><img src="../Images/7d6c4cbd52f5db722906baa7d9a7a257.png" data-original-src="https://miro.medium.com/v2/resize:fit:628/format:webp/1*gKMfbGZ9v4H6K9yeHiktfQ.png"/></div></figure><p id="97e7" class="pw-post-body-paragraph ma mb it mc b md mx kd mf mg my kg mi mj mz ml mm mn na mp mq mr nb mt mu mv im bi translated">输出向量<strong class="mc jd"><em class="nm">v</em></strong><em class="nm">_ t</em>然后与当前读取向量结合，以产生最终输出——用于强化学习的动作分布，或用于监督学习的预测分布</p><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div class="gh gi nv"><img src="../Images/1b6e48048af4a9c40897cd83b372cabe.png" data-original-src="https://miro.medium.com/v2/resize:fit:952/format:webp/1*CBKdbjY5SdrdIz9bm4s7tQ.png"/></div><figcaption class="ld le gj gh gi lf lg bd b be z dk translated">第二步，我们将<em class="nt"> W_y </em>和<em class="nt"> W_r </em>组合成一个单层<em class="nt"> W </em></figcaption></figure><p id="f84d" class="pw-post-body-paragraph ma mb it mc b md mx kd mf mg my kg mi mj mz ml mm mn na mp mq mr nb mt mu mv im bi translated">这种安排允许DNC在刚刚被读取的存储器上调节其输出尺寸。</p><p id="3b8f" class="pw-post-body-paragraph ma mb it mc b md mx kd mf mg my kg mi mj mz ml mm mn na mp mq mr nb mt mu mv im bi translated">控制器还产生一个接口向量<em class="nm">𝜉_t∈r^{(w\times r)+3w+5r+3 }</em>，定义为</p><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div class="gh gi nw"><img src="../Images/f42681cb5ee5d17b173ddf5010911d83.png" data-original-src="https://miro.medium.com/v2/resize:fit:648/format:webp/1*9lLmRhJefuEpj7CaVtcJgQ.png"/></div></figure><p id="071d" class="pw-post-body-paragraph ma mb it mc b md mx kd mf mg my kg mi mj mz ml mm mn na mp mq mr nb mt mu mv im bi translated">接口向量在当前时间步长对其与内存的交互进行编码，类似于上一篇文章中讨论的NTMs，但使用不同的机制来构建读写权重。</p><h1 id="25f8" class="li lj it bd lk ll lm ln lo lp lq lr ls ki lt kj lu kl lv km lw ko lx kp ly lz bi translated">演说</h1><h2 id="7f64" class="nx lj it bd lk ny nz dn lo oa ob dp ls mj oc od lu mn oe of lw mr og oh ly iz bi translated">界面参数</h2><p id="266e" class="pw-post-body-paragraph ma mb it mc b md me kd mf mg mh kg mi mj mk ml mm mn mo mp mq mr ms mt mu mv im bi translated">在我们描述接口向量<em class="nm"> 𝜉_t </em>如何与形状<em class="nm"> N⨉W </em>的外部存储器交互之前，我们将其细分如下:</p><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi oi"><img src="../Images/c08694b6ad75bbfd2b6c4d3334af57fa.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*ytFvlps7tc8U_nbb2-5vag.png"/></div></div></figure><p id="5b53" class="pw-post-body-paragraph ma mb it mc b md mx kd mf mg my kg mi mj mz ml mm mn na mp mq mr nb mt mu mv im bi translated">然后用各种函数处理具有^的组件，以确保它们位于正确的域中。之后，我们有下面的标量和向量集:</p><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi oj"><img src="../Images/25a75c7d83a73a3fc2ba01947cff1d71.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*OjFEZ6N4UzYWESkq-3n9fA.png"/></div></div></figure><p id="7874" class="pw-post-body-paragraph ma mb it mc b md mx kd mf mg my kg mi mj mz ml mm mn na mp mq mr nb mt mu mv im bi translated">其中oneplus函数和单位单纯形<em class="nm"> S_N </em>定义如下:</p><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div class="gh gi ok"><img src="../Images/764ed9677fbc41c98eca6e36e04057e6.png" data-original-src="https://miro.medium.com/v2/resize:fit:1276/format:webp/1*wtgDflHPVb6lLwhRkIsdGQ.png"/></div></figure><p id="3aac" class="pw-post-body-paragraph ma mb it mc b md mx kd mf mg my kg mi mj mz ml mm mn na mp mq mr nb mt mu mv im bi translated">我们进一步引入了在<em class="nm"> N </em>个位置上的加权空间，它与单位单纯形<em class="nm"> S_N </em>的唯一不同之处在于𝛼不一定总和为1。</p><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi ol"><img src="../Images/5cdc63d56d63ce11ad553c3f38c17ec1.png" data-original-src="https://miro.medium.com/v2/resize:fit:1272/format:webp/1*LSIITeKKKSNlElZY75DtiA.png"/></div></div></figure><h2 id="4c97" class="nx lj it bd lk ny nz dn lo oa ob dp ls mj oc od lu mn oe of lw mr og oh ly iz bi translated">阅读和写作的快速浏览</h2><p id="591f" class="pw-post-body-paragraph ma mb it mc b md me kd mf mg mh kg mi mj mk ml mm mn mo mp mq mr ms mt mu mv im bi translated">我们把读写权重的计算<strong class="mc jd"><em class="nm">w</em></strong><em class="nm">_t^{r,1},…、</em><strong class="mc jd"><em class="nm">w</em></strong><em class="nm">_t^{r,r}、</em><strong class="mc jd"><em class="nm">w</em></strong><em class="nm">_t^w</em>推迟到下一小节。现在，我们假设这些权重已经计算过了。读取和写入向量的计算方式与在NTMs中相同</p><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div class="gh gi om"><img src="../Images/96e86fa9db3d6398dc2a9e5edcc23b77.png" data-original-src="https://miro.medium.com/v2/resize:fit:1084/format:webp/1*Bakj4p9u6IcA2drKyp0fDA.png"/></div><figcaption class="ld le gj gh gi lf lg bd b be z dk translated">∘表示逐元素乘法，而<strong class="bd lk"> <em class="nt"> E </em> </strong>是一个一的<em class="nt"> N⨉W </em>矩阵。</figcaption></figure><p id="9446" class="pw-post-body-paragraph ma mb it mc b md mx kd mf mg my kg mi mj mz ml mm mn na mp mq mr nb mt mu mv im bi translated">值得注意的是，上面使用的权重不一定总和为1。</p><h2 id="ec86" class="nx lj it bd lk ny nz dn lo oa ob dp ls mj oc od lu mn oe of lw mr og oh ly iz bi translated">存储器编址</h2><p id="c809" class="pw-post-body-paragraph ma mb it mc b md me kd mf mg mh kg mi mj mk ml mm mn mo mp mq mr ms mt mu mv im bi translated">如前所述，系统使用基于<em class="nm">内容的寻址</em>和<em class="nm">动态内存分配</em>的组合来确定<em class="nm">将</em>写入内存的何处，并使用基于<em class="nm">内容的寻址</em>和<em class="nm">临时内存链接</em>的组合来确定<em class="nm">将</em>读取至何处。这些机制都由“接口参数”一节中定义的接口向量进行参数化，描述如下。</p><h2 id="70e3" class="nx lj it bd lk ny nz dn lo oa ob dp ls mj oc od lu mn oe of lw mr og oh ly iz bi translated">基于内容的寻址</h2><p id="60fe" class="pw-post-body-paragraph ma mb it mc b md me kd mf mg mh kg mi mj mk ml mm mn mo mp mq mr ms mt mu mv im bi translated">作为ntm，读写头分别使用基于内容的寻址来进行关联调用和修改内存中的现有向量。重要的是，这使得仅部分匹配存储器位置的内容的密钥仍然能够被用于强烈关注该位置。因此，它允许一种形式的模式完成，由此通过读取存储位置恢复的值包括密钥中不存在的附加信息。</p><p id="1e14" class="pw-post-body-paragraph ma mb it mc b md mx kd mf mg my kg mi mj mz ml mm mn na mp mq mr nb mt mu mv im bi translated">我们通过具有放大余弦相似性的softmax函数来计算内容权重</p><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div class="gh gi on"><img src="../Images/116fb3f7e92a8f6054893aab82a0f86e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1216/format:webp/1*mpHh_jX8wqDqqL-t0QvQDQ.png"/></div></figure><p id="ab60" class="pw-post-body-paragraph ma mb it mc b md mx kd mf mg my kg mi mj mz ml mm mn na mp mq mr nb mt mu mv im bi translated">其中<strong class="mc jd"> <em class="nm"> k </em> </strong>和<em class="nm"> 𝛽 </em>分别是读/写键和读/写强度。我们可以将这种计算矢量化为</p><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div class="gh gi oo"><img src="../Images/ea69ce45e036af0df11192065540f4b2.png" data-original-src="https://miro.medium.com/v2/resize:fit:888/format:webp/1*Ili9TtvSWM5tMg-ZkXMWHw.png"/></div><figcaption class="ld le gj gh gi lf lg bd b be z dk translated"><em class="nt">\帽子</em> <strong class="bd lk"> <em class="nt"> M </em> </strong>是<strong class="bd lk"> <em class="nt"> M </em> </strong>带<em class="nt">L2</em>-规格化行和<em class="nt">\帽子</em> <strong class="bd lk"> <em class="nt"> k </em> </strong>是<em class="nt">L2</em>-规格化<strong class="bd lk"><em class="nt"/></strong></figcaption></figure><h2 id="f586" class="nx lj it bd lk ny nz dn lo oa ob dp ls mj oc od lu mn oe of lw mr og oh ly iz bi translated">动态存储分配</h2><p id="41c6" class="pw-post-body-paragraph ma mb it mc b md me kd mf mg mh kg mi mj mk ml mm mn mo mp mq mr ms mt mu mv im bi translated">为了允许控制器根据需要释放和分配内存，Graves&amp;Wayne等人开发了一种“自由列表”内存分配方案的可区分模拟方案，通过在链表中添加和删除地址来维护可用内存位置的列表。</p><p id="a04a" class="pw-post-body-paragraph ma mb it mc b md mx kd mf mg my kg mi mj mz ml mm mn na mp mq mr nb mt mu mv im bi translated">1.控制器发出一组自由门<em class="nm"> f_t^i </em>，每个读取头一个，决定最近读取的位置是否可以被释放。</p><p id="f9f5" class="pw-post-body-paragraph ma mb it mc b md mx kd mf mg my kg mi mj mz ml mm mn na mp mq mr nb mt mu mv im bi translated">2.我们从自由门计算内存保持向量<em class="nm"> 𝜓_t ∈[0,1]^N </em>，它表示每个位置有多少不会被自由门释放:</p><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div class="gh gi op"><img src="../Images/ad844c9bf2677458decdaa12e23c4cb3.png" data-original-src="https://miro.medium.com/v2/resize:fit:672/format:webp/1*4Cu6Oz-f6uglN7gSkXusmg.png"/></div><figcaption class="ld le gj gh gi lf lg bd b be z dk translated">乘法表示保留概率的交集。</figcaption></figure><p id="66c4" class="pw-post-body-paragraph ma mb it mc b md mx kd mf mg my kg mi mj mz ml mm mn na mp mq mr nb mt mu mv im bi translated">3.内存使用向量可以定义为</p><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div class="gh gi oq"><img src="../Images/d9d55589604632cb860e964a2f637671.png" data-original-src="https://miro.medium.com/v2/resize:fit:1172/format:webp/1*TwElavNgs6pgu0mxu5p8lw.png"/></div></figure><p id="7541" class="pw-post-body-paragraph ma mb it mc b md mx kd mf mg my kg mi mj mz ml mm mn na mp mq mr nb mt mu mv im bi translated">用<strong class="mc jd"><em class="nm">u</em></strong><em class="nm">_ 0 = 0</em>和<strong class="mc jd"><em class="nm">u</em></strong><em class="nm">_ t</em>∈<em class="nm">【0,1]^n</em>。直观地说，如果位置已经被自由门(𝜓_t[i]≈1)保留，并且已经在使用(<strong class="mc jd"><em class="nm"/></strong><em class="nm">_ { t-1 }</em>≈<strong class="mc jd"><em class="nm">1</em></strong>)或者刚刚被写入(<strong class="mc jd"><em class="nm">【w</em></strong><em class="nm">【_{t-1}^w】</em>≈<strong class="mc jd"><em class="nm">1</em></strong>)。使用自由门只能随后减少使用量(因为括号中的内容总是大于或等于<strong class="mc jd"><em class="nm"/></strong><em class="nm">_ { t-1 }</em>假定<strong class="mc jd"><em class="nm">w</em></strong><em class="nm">_{t-1}^w≥</em><strong class="mc jd"><em class="nm">0</em></strong>—它等于<em class="nm">u _ { t-1 }</em>也可以将括号内的部分作为集合联合运算，其中<strong class="mc jd"><em class="nm"/></strong><em class="nm">_ { t-1 }</em>和<strong class="mc jd"><em class="nm">w</em></strong><em class="nm">_{t-1}^w</em>是两个集合，而<strong class="mc jd"><em class="nm"/></strong><em class="nm">_ { t-1 }</em>∘<strong class="mc jd"><em class="nm">w</em></strong></p><p id="38e6" class="pw-post-body-paragraph ma mb it mc b md mx kd mf mg my kg mi mj mz ml mm mn na mp mq mr nb mt mu mv im bi translated">4.一旦<strong class="mc jd"><em class="nm"/></strong><em class="nm">_ t</em>被确定，空闲列表<em class="nm"> 𝜙_t∈Z^N </em>通过以使用的升序排序存储器位置的索引来定义。</p><p id="8e05" class="pw-post-body-paragraph ma mb it mc b md mx kd mf mg my kg mi mj mz ml mm mn na mp mq mr nb mt mu mv im bi translated">5.用于提供新的写入位置的分配权重<strong class="mc jd"> <em class="nm"> a </em> </strong> <em class="nm"> _t∈ 𝛥_N </em>定义为</p><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div class="gh gi or"><img src="../Images/dd6ebfbe8d786e56a6cb3b3045c3add8.png" data-original-src="https://miro.medium.com/v2/resize:fit:1132/format:webp/1*Fb5PL8GgjNpJwpwPuZ_r4w.png"/></div></figure><p id="efe5" class="pw-post-body-paragraph ma mb it mc b md mx kd mf mg my kg mi mj mz ml mm mn na mp mq mr nb mt mu mv im bi translated">直观地说，分配权重<strong class="mc jd"><em class="nm"/></strong><em class="nm">_ t[</em><em class="nm">_ t[j]]</em>与比𝜙 <em class="nm"> _t[j] </em>有更多可用空间的位置的使用率成正比——这些位置的使用率越高，<em class="nm">【𝜙_t[j】</em>分配的内存越多——与<em class="nm">【𝜙_t[j】</em>本身的使用率成反比。前者保证总是用更多的可用空间填充位置。</p><p id="f6ef" class="pw-post-body-paragraph ma mb it mc b md mx kd mf mg my kg mi mj mz ml mm mn na mp mq mr nb mt mu mv im bi translated">正如作者所指出的，步骤4中的排序操作会在排序顺序发生变化的地方导致不连续。当计算梯度时，我们忽略这些不连续性，因为它们似乎与学习无关。</p><p id="16ed" class="pw-post-body-paragraph ma mb it mc b md mx kd mf mg my kg mi mj mz ml mm mn na mp mq mr nb mt mu mv im bi translated">值得注意的是，分配机制独立于内存大小(事实上，接口向量中的所有元素都是独立的)，这意味着DNC可以被训练为使用一种大小的内存来解决一个任务，并在以后升级到更大的内存，而无需重新训练。</p><h2 id="77d0" class="nx lj it bd lk ny nz dn lo oa ob dp ls mj oc od lu mn oe of lw mr og oh ly iz bi translated">写入权重</h2><p id="08e3" class="pw-post-body-paragraph ma mb it mc b md me kd mf mg mh kg mi mj mk ml mm mn mo mp mq mr ms mt mu mv im bi translated">现在，我们将基于内容的寻址和动态内存分配结合起来，形成写入权重。我们使用前一时间步的内存来计算内容权重</p><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div class="gh gi os"><img src="../Images/02c2911b3fd16212fc3dd58fbe88d848.png" data-original-src="https://miro.medium.com/v2/resize:fit:664/format:webp/1*zEqY3fUbTrwNICbfkU4jDA.png"/></div></figure><p id="33e9" class="pw-post-body-paragraph ma mb it mc b md mx kd mf mg my kg mi mj mz ml mm mn na mp mq mr nb mt mu mv im bi translated">写权重可以写为</p><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div class="gh gi ot"><img src="../Images/2197cd3b46f150e81fce4bbc38b2d461.png" data-original-src="https://miro.medium.com/v2/resize:fit:872/format:webp/1*dz3ZefURb_aPIAJfsDNz-A.png"/></div><figcaption class="ld le gj gh gi lf lg bd b be z dk translated">分配门<em class="nt">g_t^a∈[0,1】</em>控制插值，写门<em class="nt">g_t^w∈[0,1】</em>决定将多少数据写入内存。</figcaption></figure><h2 id="a9c4" class="nx lj it bd lk ny nz dn lo oa ob dp ls mj oc od lu mn oe of lw mr og oh ly iz bi translated">时间记忆链接</h2><p id="368c" class="pw-post-body-paragraph ma mb it mc b md me kd mf mg mh kg mi mj mk ml mm mn mo mp mq mr ms mt mu mv im bi translated">到目前为止，我们讨论的机制没有存储关于存储位置被写入的顺序的信息。然而，在许多情况下，保留这些信息是有用的:例如，当必须按顺序记录和检索一系列指令时。Graves&amp;Wayne等人提出跟踪连续修改的存储位置，从而使DNC能够按照书写顺序恢复序列。这是按如下方式完成的</p><p id="3bc2" class="pw-post-body-paragraph ma mb it mc b md mx kd mf mg my kg mi mj mz ml mm mn na mp mq mr nb mt mu mv im bi translated">1.我们首先引入一个优先权重<strong class="mc jd"><em class="nm">p</em></strong><em class="nm">_ t ∈𝛥_n</em>，其中元素<strong class="mc jd"><em class="nm">p</em></strong><em class="nm">_ t【I】</em>表示位置<em class="nm"> i </em>最后被写入的程度。我们通过递推关系定义<strong class="mc jd"><em class="nm">p</em></strong><em class="nm">_ t</em>:</p><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div class="gh gi ou"><img src="../Images/c52dc1f5a13702d651dbe246f733c103.png" data-original-src="https://miro.medium.com/v2/resize:fit:1016/format:webp/1*6i31LS8gdYa4aPxmvu79ZQ.png"/></div><figcaption class="ld le gj gh gi lf lg bd b be z dk translated"><strong class="bd lk"><em class="nt">w</em></strong><em class="nt"/>是写权重</figcaption></figure><p id="d759" class="pw-post-body-paragraph ma mb it mc b md mx kd mf mg my kg mi mj mz ml mm mn na mp mq mr nb mt mu mv im bi translated">注意，<strong class="mc jd"> <em class="nm"> p </em> </strong> <em class="nm"> _t </em>是基于当前时间步的写权重<strong class="mc jd"> <em class="nm"> w </em> </strong> <em class="nm"> _t^w </em>更新的:如果<em class="nm">𝛴_i</em><strong class="mc jd"><em class="nm">w</em></strong><em class="nm">_t^w[i]≈0</em>，这意味着在当前时间步几乎没有任何写操作发生，那么<strong class="mc jd"><em class="nm">p</em></strong><em class="nm">_ t</em>反之，如果<em class="nm">𝛴_i</em><strong class="mc jd"><em class="nm">w</em></strong><em class="nm">_t^w[i]≈1</em>，前面的先后顺序几乎被取代，那么<strong class="mc jd"><em class="nm">p</em><em class="nm">_ t</em>≈<strong class="mc jd"><em class="nm">w</em></strong><em class="nm">_t^w</em>。</strong></p><p id="e060" class="pw-post-body-paragraph ma mb it mc b md mx kd mf mg my kg mi mj mz ml mm mn na mp mq mr nb mt mu mv im bi translated">2.现在我们定义时态链接矩阵<strong class="mc jd"><em class="nm">L</em></strong><em class="nm">_ t</em>，其中<strong class="mc jd"><em class="nm">L</em></strong><em class="nm">_ t【I，j】</em>表示在位置<em class="nm"> j </em>被写入之后位置<em class="nm"> i </em>被写入的程度(可以将其视为相邻矩阵的变体)。每次修改一个位置时，我们都希望更新链接矩阵，以删除该位置的旧链接，并从上次写入的位置添加新链接。这是通过以下递归关系实现的</p><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi ov"><img src="../Images/9536f65321e6690d0f077cee31956a61.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*3IZlM11J1D5My30ECCNVYA.png"/></div></div></figure><p id="c789" class="pw-post-body-paragraph ma mb it mc b md mx kd mf mg my kg mi mj mz ml mm mn na mp mq mr nb mt mu mv im bi translated">我们排除了自链接，因为不清楚如何跟踪从一个位置到其自身的转换。值得注意的是，我们在上面的更新中使用了前一时间步的优先权重，这是合理的，因为定义了链接矩阵<strong class="mc jd"><em class="nm">L</em></strong><em class="nm">_ t</em>。我们可以将上述过程矢量化如下</p><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi ow"><img src="../Images/3d066becdad394fe3870627ec93b6964.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*9zxQZu8OvTZ5WpUKyZIaHw.png"/></div></div><figcaption class="ld le gj gh gi lf lg bd b be z dk translated"><strong class="bd lk"> <em class="nt"> E </em> </strong>是个1的矩阵，<strong class="bd lk"> <em class="nt"> I </em> </strong>是个单位矩阵。</figcaption></figure><p id="df72" class="pw-post-body-paragraph ma mb it mc b md mx kd mf mg my kg mi mj mz ml mm mn na mp mq mr nb mt mu mv im bi translated">在继续之前，我们先花点时间理顺一下<em class="nm">(1-</em><strong class="mc jd"><em class="nm">w</em></strong><em class="nm">_t^w[i]-</em><strong class="mc jd"><em class="nm">w</em></strong><em class="nm">【_t^w[j】</em>。<em class="nm">-</em><strong class="mc jd"><em class="nm">w</em></strong><em class="nm">【_t^w[i】</em>说我们对内存槽<em class="nm"> i </em>写的越多，我们保留相应的链接条目就越少。特别是，当<strong class="mc jd"><em class="nm"/></strong><em class="nm">【_t^w[i]=1】</em>时，我们不再保留关于<strong class="mc jd"><em class="nm">l</em></strong><em class="nm">_ { t-1 }【I，j】</em>和我们的新<strong class="mc jd"><em class="nm">l</em></strong><em class="nm">_ t【I，j】</em>完全依赖于<strong class="mc jd"><em class="nm">w</em></strong><em class="nm">【_t^w[i】</em><strong class="mc jd"><strong class="mc jd"><em class="nm">w</em></strong><em class="nm">【_t^w[j】</em>的合理性以类似的方式工作:写入的内存槽<em class="nm"> j </em>越多，位置<em class="nm"> j </em>处的内存越新，相应的链接条目应该保留得越少。当<strong class="mc jd"><em class="nm">w</em></strong><em class="nm">_t^w[j]=1</em>时，即位置<em class="nm"> j </em>的内存被新的写向量完全刷新时，所有的<strong class="mc jd"> <em class="nm"> L </em> </strong> <em class="nm"> _t[，j】</em>被复位。</strong></p><p id="f687" class="pw-post-body-paragraph ma mb it mc b md mx kd mf mg my kg mi mj mz ml mm mn na mp mq mr nb mt mu mv im bi translated">3.我们现在基于时间链接矩阵为读取头<em class="nm"> i </em>指定前向加权<strong class="mc jd"><em class="nm">f</em></strong><em class="nm">_t^i∈𝛥_n</em>和后向加权<strong class="mc jd"><em class="nm">b</em></strong><em class="nm">_t^i∈𝛥_n</em></p><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div class="gh gi ox"><img src="../Images/604dc18f0b86b586ef2e8e1dcff30ffe.png" data-original-src="https://miro.medium.com/v2/resize:fit:428/format:webp/1*_V5ZeHzsaCXYa7odhjJv_g.png"/></div><figcaption class="ld le gj gh gi lf lg bd b be z dk translated"><strong class="bd lk"><em class="nt">w</em></strong><em class="nt">_{t-1}^{r,i}</em>是从上一时间步读取的第<em class="nt"> i </em>个权重</figcaption></figure><p id="5ba1" class="pw-post-body-paragraph ma mb it mc b md mx kd mf mg my kg mi mj mz ml mm mn na mp mq mr nb mt mu mv im bi translated">直观地说，前向加权指定了磁头在前一次读取之后以顺序写入顺序将要读取的内容，后向加权指定了以相反的写入顺序读取的内容。</p><p id="9a88" class="pw-post-body-paragraph ma mb it mc b md mx kd mf mg my kg mi mj mz ml mm mn na mp mq mr nb mt mu mv im bi translated">另外，Graves&amp;Wayne等人提出了一种减少链路矩阵开销的技巧。我省略了它，因为我不太确定它是否值得我们去矢量化更新。</p><h2 id="1b59" class="nx lj it bd lk ny nz dn lo oa ob dp ls mj oc od lu mn oe of lw mr og oh ly iz bi translated"><strong class="ak">读取权重</strong></h2><p id="6378" class="pw-post-body-paragraph ma mb it mc b md me kd mf mg mh kg mi mj mk ml mm mn mo mp mq mr ms mt mu mv im bi translated">每个读取头利用一个读取模式向量<em class="nm"> 𝜋_t^i∈S_3 </em>对后向权重<strong class="mc jd">t105】bt107】t108】_t^i前向权重<strong class="mc jd">t111】f</strong>t114】_t^i和内容读取权重<strong class="mc jd"><em class="nm">c</em></strong><em class="nm">_t^{r,i}=c(</em><strong class="mc jd"><em class="nm">m</em></strong></strong></p><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div class="gh gi oy"><img src="../Images/7e8b76da2c1347cce2970b66d8e2f11b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1048/format:webp/1*GHjgBJNPcu4jbVWXlDADjw.png"/></div></figure><h1 id="1f3d" class="li lj it bd lk ll lm ln lo lp lq lr ls ki lt kj lu kl lv km lw ko lx kp ly lz bi translated">结束</h1><p id="258a" class="pw-post-body-paragraph ma mb it mc b md me kd mf mg mh kg mi mj mk ml mm mn mo mp mq mr ms mt mu mv im bi translated">就是这样。这是一次长途旅行；希望你喜欢。如果你碰到一些错误或者有一些顾虑，欢迎留言/评论。</p><h1 id="49ea" class="li lj it bd lk ll lm ln lo lp lq lr ls ki lt kj lu kl lv km lw ko lx kp ly lz bi translated"><strong class="ak">参考文献</strong></h1><p id="527e" class="pw-post-body-paragraph ma mb it mc b md me kd mf mg mh kg mi mj mk ml mm mn mo mp mq mr ms mt mu mv im bi translated">亚历克斯·格雷夫斯、格雷格·韦恩、马尔科姆·雷诺兹、蒂姆·哈雷、伊沃·达尼埃尔卡、阿格尼耶斯卡·格拉布斯卡-巴尔维什卡、塞尔吉奥·戈麦斯·科尔梅纳雷霍、爱德华·格雷芬斯特特、蒂亚戈·拉马尔霍、约翰·阿加皮乌、阿德里亚·普伊格多姆内奇·巴迪亚、卡尔·莫里茨·赫尔曼、尤里·兹沃斯、格奥尔格·奥斯特罗夫斯基、亚当·该隐、海伦·金、克里斯托弗·萨默菲尔德、菲尔·布伦松、科拉雷·卡武克库奥卢和戴密斯·哈萨比斯。2016."使用具有动态外部存储器的神经网络的混合计算."<em class="nm">*自然*</em>538(7626):471–76。【https://doi.org/10.1038/nature20101. T4】</p><p id="72fd" class="pw-post-body-paragraph ma mb it mc b md mx kd mf mg my kg mi mj mz ml mm mn na mp mq mr nb mt mu mv im bi translated">欣，卡罗尔。2016."可微分神经计算机的实现和优化."<a class="ae lh" href="https://web.stanford.edu/class/cs224n/reports/2753780.pdf." rel="noopener ugc nofollow" target="_blank">https://web.stanford.edu/class/cs224n/reports/2753780.pdf.</a></p><p id="0552" class="pw-post-body-paragraph ma mb it mc b md mx kd mf mg my kg mi mj mz ml mm mn na mp mq mr nb mt mu mv im bi translated">代号:<a class="ae lh" href="https://github.com/deepmind/dnc" rel="noopener ugc nofollow" target="_blank">https://github.com/deepmind/dnc</a></p></div></div>    
</body>
</html>