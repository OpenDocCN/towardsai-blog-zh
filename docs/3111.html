<html>
<head>
<title>Keras Callbacks Tutorial for Training Your Neural Networks Efficiently</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">Keras回调教程有效训练你的神经网络</h1>
<blockquote>原文：<a href="https://pub.towardsai.net/keras-callbacks-tutorial-for-training-your-neural-networks-efficiently-fa51dc0d792f?source=collection_archive---------4-----------------------#2022-09-10">https://pub.towardsai.net/keras-callbacks-tutorial-for-training-your-neural-networks-efficiently-fa51dc0d792f?source=collection_archive---------4-----------------------#2022-09-10</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><blockquote class="jn jo jp"><p id="0ca8" class="jq jr js jt b ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko ij bi translated">神经网络的训练可能需要几个小时甚至几天才能完成。所以我们需要一些功能来监视和控制我们的模型。因为在数小时或数天的训练后，如果一个模型崩溃了，那么所有的训练时间都浪费了。一旦我们选择了一些纪元并且开始训练，我们可能需要停止训练以避免过度拟合，或者如果我们已经实现了一些最小损失，并且如果它在之后增加，我们需要停止训练等等。,.因此，一旦培训开始，我们必须需要一些功能来监视和控制我们的模型，这就是本文所要讨论的内容— <strong class="jt ir">回调</strong></p></blockquote><p id="2f8a" class="pw-post-body-paragraph jq jr iq jt b ju jv jw jx jy jz ka kb kp kd ke kf kq kh ki kj kr kl km kn ko ij bi translated">在一般定义中，回调是Keras中的一个对象，它可以在训练的各个阶段执行操作。</p><figure class="kt ku kv kw gt kx gh gi paragraph-image"><div class="gh gi ks"><img src="../Images/cc54e19fe10953e6bbe7d9b08d22b5b5.png" data-original-src="https://miro.medium.com/v2/resize:fit:1194/format:webp/1*EI7xpPdCXnOFqO6UlHLYyQ.png"/></div><figcaption class="la lb gj gh gi lc ld bd b be z dk translated">图片由Muttineni Sai Rohith提供</figcaption></figure><p id="2244" class="pw-post-body-paragraph jq jr iq jt b ju jv jw jx jy jz ka kb kp kd ke kf kq kh ki kj kr kl km kn ko ij bi translated">可以在一个时期开始或结束之前、在一个批处理之前或之后调用回调，等等。我们可以使用回调来提前停止，定期将我们的模型保存到磁盘，在训练期间查看内部状态并获得模型的统计数据，在每批训练后写日志，等等。,</p><p id="8f9f" class="pw-post-body-paragraph jq jr iq jt b ju jv jw jx jy jz ka kb kp kd ke kf kq kh ki kj kr kl km kn ko ij bi translated"><strong class="jt ir">回调用法:</strong></p><ol class=""><li id="72c0" class="le lf iq jt b ju jv jy jz kp lg kq lh kr li ko lj lk ll lm bi translated">定义回调</li></ol><pre class="kt ku kv kw gt ln lo lp lq aw lr bi"><span id="d339" class="ls lt iq lo b gy lu lv l lw lx">#EarlyStopping<br/>early_stop = tf.keras.callbacks.EarlyStopping(<br/>    monitor='val_loss', min_delta=0.001, patience=3, verbose=1,<br/>    mode='min'<br/>)</span><span id="c58d" class="ls lt iq lo b gy ly lv l lw lx">#ModelCheckpoint<br/>checkpoint = ModelCheckpoint(filepath ,monitor='val_loss',       <br/>                  mode='min',save_best_only=True,verbose=1<br/>                 )</span></pre><p id="1345" class="pw-post-body-paragraph jq jr iq jt b ju jv jw jx jy jz ka kb kp kd ke kf kq kh ki kj kr kl km kn ko ij bi translated">如果您现在没有得到它们，请不要担心，我们将在下面详细介绍它们。</p><p id="befd" class="pw-post-body-paragraph jq jr iq jt b ju jv jw jx jy jz ka kb kp kd ke kf kq kh ki kj kr kl km kn ko ij bi translated">2.将回调传递给model.fit()</p><pre class="kt ku kv kw gt ln lo lp lq aw lr bi"><span id="87f0" class="ls lt iq lo b gy lu lv l lw lx">model.fit(X_train,y_train,epochs=10,validation_data=(X_test,y_test),<br/>callbacks = [early_stop, <!-- -->checkpoint<!-- -->])<br/></span></pre><p id="7eb4" class="pw-post-body-paragraph jq jr iq jt b ju jv jw jx jy jz ka kb kp kd ke kf kq kh ki kj kr kl km kn ko ij bi translated">让我们来看看一些最常用的回调。</p><h2 id="4bea" class="ls lt iq bd lz ma mb dn mc md me dp mf kp mg mh mi kq mj mk ml kr mm mn mo mp bi translated"><strong class="ak"> <em class="mq">模型检查点:</em> </strong></h2><p id="ec9b" class="pw-post-body-paragraph jq jr iq jt b ju mr jw jx jy ms ka kb kp mt ke kf kq mu ki kj kr mv km kn ko ij bi translated">我们使用这个回调来定期保存我们的模型，这样如果我们的训练意外崩溃，我们就不会浪费我们的训练时间。此外，我们可以利用中间的最佳存储权重，并在以后加载它们，以从保存的状态继续训练。</p><p id="ed0b" class="pw-post-body-paragraph jq jr iq jt b ju jv jw jx jy jz ka kb kp kd ke kf kq kh ki kj kr kl km kn ko ij bi translated">语法:</p><pre class="kt ku kv kw gt ln lo lp lq aw lr bi"><span id="71ec" class="ls lt iq lo b gy lu lv l lw lx">tf.keras.callbacks.ModelCheckpoint(<br/>    filepath,<br/>    monitor = "val_loss",<br/>    verbose = 0,<br/>    save_best_only = False,<br/>    save_weights_only = True,<br/>    mode = "auto",<br/>    save_freq="epoch",<br/>    options=None,<br/>    initial_value_threshold=None,<br/>    **kwargs<br/>)</span></pre><p id="5380" class="pw-post-body-paragraph jq jr iq jt b ju jv jw jx jy jz ka kb kp kd ke kf kq kh ki kj kr kl km kn ko ij bi translated"><strong class="jt ir"> <em class="js"> filepath </em> </strong> —保存模型的位置<br/><strong class="jt ir"><em class="js">monitor</em></strong>—需要监视的指标例如:(" val_loss "、" val_accuracy "、" loss "、" accuracy ")<br/><strong class="jt ir"><em class="js">verbose</em></strong>—如果为1，则在采取回调操作时显示一条消息，反之亦然；如果为0<br/><strong class="jt ir"><em class="js">save _ best _ only</em></strong>—如果为真，则保存<br/><strong class="jt ir"><em class="js">save _ weights _ only</em></strong>—如果为True，则只保存权重。<br/> <strong class="jt ir"> <em class="js">模式</em></strong>——(“自动”、“最小”、“最大”)对于精度，应该是“最大”，对于损耗，应该是“最小”。如果是“auto ”,它可以通过使用度量的名称来推断模式。<br/><strong class="jt ir"><em class="js">save _ freq</em></strong>—如果“epoch”为每一个epoch保存，否则为整数n，每第n批后保存。</p><h2 id="42f9" class="ls lt iq bd lz ma mb dn mc md me dp mf kp mg mh mi kq mj mk ml kr mm mn mo mp bi translated"><strong class="ak">T43【终结】安南T45】</strong></h2><p id="ec4e" class="pw-post-body-paragraph jq jr iq jt b ju mr jw jx jy ms ka kb kp mt ke kf kq mu ki kj kr mv km kn ko ij bi translated">当出现NaN丢失时，此回调将终止训练。</p><pre class="kt ku kv kw gt ln lo lp lq aw lr bi"><span id="7d4c" class="ls lt iq lo b gy lu lv l lw lx">tf.keras.callbacks.TerminateOnNaN()</span></pre><h2 id="55bb" class="ls lt iq bd lz ma mb dn mc md me dp mf kp mg mh mi kq mj mk ml kr mm mn mo mp bi translated"><a class="ae mw" href="https://muttinenisairohith.medium.com/keras-earlystopping-callback-to-train-the-neural-networks-perfectly-2a3f865148f7" rel="noopener">提前停止</a>:</h2><p id="bfef" class="pw-post-body-paragraph jq jr iq jt b ju mr jw jx jy ms ka kb kp mt ke kf kq mu ki kj kr mv km kn ko ij bi translated">EarlyStopping是在训练神经网络时使用的回调，它为我们提供了使用大量训练时期的优势，并且一旦模型的性能在验证数据集上停止改善，就停止训练。</p><pre class="kt ku kv kw gt ln lo lp lq aw lr bi"><span id="89d5" class="ls lt iq lo b gy lu lv l lw lx">tf.keras.callbacks.EarlyStopping(<br/>    monitor="val_loss",<br/>    min_delta=0,<br/>    patience=0,<br/>    verbose=0,<br/>    mode="auto",<br/>    baseline=None,<br/>    restore_best_weights=False,<br/>)</span></pre><p id="a2f8" class="pw-post-body-paragraph jq jr iq jt b ju jv jw jx jy jz ka kb kp kd ke kf kq kh ki kj kr kl km kn ko ij bi translated">关于提前停止的详细解释，请参考我下面的文章—</p><div class="mx my gp gr mz na"><a href="https://muttinenisairohith.medium.com/keras-earlystopping-callback-to-train-the-neural-networks-perfectly-2a3f865148f7" rel="noopener follow" target="_blank"><div class="nb ab fo"><div class="nc ab nd cl cj ne"><h2 class="bd ir gy z fp nf fr fs ng fu fw ip bi translated">Keras早期停止回调以完美训练神经网络</h2><div class="nh l"><h3 class="bd b gy z fp nf fr fs ng fu fw dk translated">早期停止是一种帮助您在训练神经网络时避免过拟合和欠拟合的方法。</h3></div><div class="ni l"><p class="bd b dl z fp nf fr fs ng fu fw dk translated">muttinenisairohith.medium.com</p></div></div><div class="nj l"><div class="nk l nl nm nn nj no ky na"/></div></div></a></div><h2 id="9416" class="ls lt iq bd lz ma mb dn mc md me dp mf kp mg mh mi kq mj mk ml kr mm mn mo mp bi translated">ReduceLROnPlateau</h2><p id="096d" class="pw-post-body-paragraph jq jr iq jt b ju mr jw jx jy ms ka kb kp mt ke kf kq mu ki kj kr mv km kn ko ij bi translated">如果没有改善，这种回调会降低学习率(lr)。模型通常受益于降低学习率。使用这个回调将监控指定的度量，如果“耐心”的历元数没有改善，学习率将会降低。</p><p id="7815" class="pw-post-body-paragraph jq jr iq jt b ju jv jw jx jy jz ka kb kp kd ke kf kq kh ki kj kr kl km kn ko ij bi translated">语法:</p><pre class="kt ku kv kw gt ln lo lp lq aw lr bi"><span id="91f6" class="ls lt iq lo b gy lu lv l lw lx">tf.keras.callbacks.ReduceLROnPlateau(<br/>    monitor="val_loss",<br/>    factor=0.1,<br/>    patience=10,<br/>    verbose=0,<br/>    mode="auto",<br/>    min_delta=0.0001,<br/>    cooldown=0,<br/>    min_lr=0,<br/>    **kwargs<br/>)</span></pre><p id="a032" class="pw-post-body-paragraph jq jr iq jt b ju jv jw jx jy jz ka kb kp kd ke kf kq kh ki kj kr kl km kn ko ij bi translated"><strong class="jt ir"> <em class="js">监控</em> </strong> —必须监控的指标，例如:(" val_loss "、" val_accuracy "、" loss "、" accuracy") <br/> <strong class="jt ir"> <em class="js">因子— </em> </strong>学习率将降低的因子。<code class="fe np nq nr lo b">new_lr = lr * factor</code>。<br/> <strong class="jt ir"> <em class="js">耐心—</em></strong>lr降低后无改善的时期数<strong class="jt ir"> <em class="js"> <br/>冗长</em> </strong> —如果为1，则在采取回调动作时显示一条消息，反之如果为0 <br/> <strong class="jt ir"> <em class="js">模式</em> </strong> —(“自动”、“最小”、“最大”)对于精确度，应该为“最大”，对于损耗，应该为“最小”。如果是“auto ”,它可以通过使用度量的名称来推断模式。<br/><strong class="jt ir"><em class="js">min _ delta</em></strong>—用于只关注一个显著的变化。<br/> <strong class="jt ir"> <em class="js">冷却</em></strong>——lr降低后恢复正常运行前等待的周期数。<br/> <strong class="jt ir"> <em class="js"> min_lr — </em> </strong>学习率上下限。</p><h1 id="4882" class="ns lt iq bd lz nt nu nv mc nw nx ny mf nz oa ob mi oc od oe ml of og oh mo oi bi translated">学习率计划程序</h1><p id="3dad" class="pw-post-body-paragraph jq jr iq jt b ju mr jw jx jy ms ka kb kp mt ke kf kq mu ki kj kr mv km kn ko ij bi translated">一个简单的回调函数用于调整一段时间后的学习速率。我们可以编写一个函数来根据时期或某些条件改变学习速率，并可以将它作为参数传递给这个回调函数。</p><p id="67c2" class="pw-post-body-paragraph jq jr iq jt b ju jv jw jx jy jz ka kb kp kd ke kf kq kh ki kj kr kl km kn ko ij bi translated">带有示例的语法:</p><pre class="kt ku kv kw gt ln lo lp lq aw lr bi"><span id="9420" class="ls lt iq lo b gy lu lv l lw lx">def scheduler(epoch, lr):<br/>     if epoch % 10 == 0:<br/>        return lr * tf.math.exp(-0.1)</span><span id="ec0b" class="ls lt iq lo b gy ly lv l lw lx">callback = tf.keras.callbacks.LearningRateScheduler(scheduler)</span></pre><p id="0902" class="pw-post-body-paragraph jq jr iq jt b ju jv jw jx jy jz ka kb kp kd ke kf kq kh ki kj kr kl km kn ko ij bi translated">这将改变每10个时期的学习率。</p><h1 id="45e8" class="ns lt iq bd lz nt nu nv mc nw nx ny mf nz oa ob mi oc od oe ml of og oh mo oi bi translated">张量板</h1><p id="6a4c" class="pw-post-body-paragraph jq jr iq jt b ju mr jw jx jy ms ka kb kp mt ke kf kq mu ki kj kr mv km kn ko ij bi translated">它是Tensorflow提供的可视化工具。这个回调允许我们可视化关于训练过程的信息，如度量、训练图、激活函数直方图和其他梯度分布。要使用tensorboard，我们首先需要设置一个log_dir来保存tensorboard文件。</p><pre class="kt ku kv kw gt ln lo lp lq aw lr bi"><span id="1255" class="ls lt iq lo b gy lu lv l lw lx">log_dir="logs"<br/>tensorboard_callback = tf.keras.callbacks.TensorBoard(<br/>log_dir=log_dir, histogram_freq=1, write_graph=True)</span></pre><p id="4507" class="pw-post-body-paragraph jq jr iq jt b ju jv jw jx jy jz ka kb kp kd ke kf kq kh ki kj kr kl km kn ko ij bi translated"><strong class="jt ir"> <em class="js"> log_dir — </em> </strong>保存文件的目录<br/><strong class="jt ir"><em class="js">histogram _ freq—</em></strong>计算直方图和渐变图的历元频率<br/><strong class="jt ir"><em class="js">write _ graph—</em></strong>是否需要在张量板上显示和可视化图形</p><p id="ed78" class="pw-post-body-paragraph jq jr iq jt b ju jv jw jx jy jz ka kb kp kd ke kf kq kh ki kj kr kl km kn ko ij bi translated">我们已经讨论了几次回访。还有其他的回调，比如</p><ul class=""><li id="a7f2" class="le lf iq jt b ju jv jy jz kp lg kq lh kr li ko oj lk ll lm bi translated"><strong class="jt ir"> <em class="js">备份和恢复— </em> </strong>备份和恢复特定的训练状态</li><li id="df67" class="le lf iq jt b ju ok jy ol kp om kq on kr oo ko oj lk ll lm bi translated"><strong class="jt ir"><em class="js">remote monitor—</em></strong>回调用于将事件流式传输到服务器</li><li id="c8a1" class="le lf iq jt b ju ok jy ol kp om kq on kr oo ko oj lk ll lm bi translated"><strong class="jt ir"> <em class="js"> CSVLogger — </em> </strong>将epoch结果流式传输到CSV文件的回调。</li><li id="24f4" class="le lf iq jt b ju ok jy ol kp om kq on kr oo ko oj lk ll lm bi translated"><strong class="jt ir"><em class="js">lambda Callback—</em></strong>回调用于动态创建简单的自定义回调。</li><li id="9577" class="le lf iq jt b ju ok jy ol kp om kq on kr oo ko oj lk ll lm bi translated"><strong class="jt ir"><em class="js">progbar logger—</em></strong>将指标打印到标准输出的回调。</li></ul><p id="9951" class="pw-post-body-paragraph jq jr iq jt b ju jv jw jx jy jz ka kb kp kd ke kf kq kh ki kj kr kl km kn ko ij bi translated">这就是Keras试镜的意义。确保下次在训练神经网络时使用它们。</p><p id="dcab" class="pw-post-body-paragraph jq jr iq jt b ju jv jw jx jy jz ka kb kp kd ke kf kq kh ki kj kr kl km kn ko ij bi translated">如果你喜欢这篇文章，去我的feed看看我的其他文章。它们可能会有帮助。</p><p id="bd4d" class="pw-post-body-paragraph jq jr iq jt b ju jv jw jx jy jz ka kb kp kd ke kf kq kh ki kj kr kl km kn ko ij bi translated">参考资料:</p><ul class=""><li id="6d52" class="le lf iq jt b ju jv jy jz kp lg kq lh kr li ko oj lk ll lm bi translated"><a class="ae mw" href="https://keras.io/api/callbacks/" rel="noopener ugc nofollow" target="_blank">https://keras.io/api/callbacks/</a></li></ul><p id="61ad" class="pw-post-body-paragraph jq jr iq jt b ju jv jw jx jy jz ka kb kp kd ke kf kq kh ki kj kr kl km kn ko ij bi translated">快乐编码…</p></div></div>    
</body>
</html>