<html>
<head>
<title>A Gentle Introduction to Representation Learning</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">表象学习的温和介绍</h1>
<blockquote>原文：<a href="https://pub.towardsai.net/a-gentle-introduction-to-representation-learning-e79e5ed6964?source=collection_archive---------0-----------------------#2022-07-25">https://pub.towardsai.net/a-gentle-introduction-to-representation-learning-e79e5ed6964?source=collection_archive---------0-----------------------#2022-07-25</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="d0f1" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">机器学习的核心基础之一。</h2></div><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ki"><img src="../Images/8ed414e6e75e3723dbda2802d3dc7064.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*4B1ewn2HRn8AgTdA.png"/></div></div><figcaption class="ku kv gj gh gi kw kx bd b be z dk translated">图片来源:<a class="ae ky" href="https://medium.com/syncedreview/uc-berkeley-uses-a-causal-perspective-to-formalise-the-desiderata-for-representation-learning-f2a7cf9c96a3" rel="noopener">https://medium . com/synced review/UC-Berkeley-uses-a-causal-perspective-to-formulate-the-desiderata-for-representation-learning-F2 a 7 cf 9 c 96 a 3</a></figcaption></figure><blockquote class="kz la lb"><p id="75cc" class="lc ld le lf b lg lh ju li lj lk jx ll lm ln lo lp lq lr ls lt lu lv lw lx ly im bi translated">我最近创办了一份专注于人工智能的教育时事通讯，已经有超过125，000名订户。《序列》是一份无废话(意思是没有炒作，没有新闻等)的ML导向时事通讯，需要5分钟阅读。目标是让你与机器学习项目、研究论文和概念保持同步。请通过订阅以下内容来尝试一下:</p></blockquote><div class="lz ma gp gr mb mc"><a href="https://thesequence.substack.com/" rel="noopener  ugc nofollow" target="_blank"><div class="md ab fo"><div class="me ab mf cl cj mg"><h2 class="bd iu gy z fp mh fr fs mi fu fw is bi translated">序列</h2><div class="mj l"><h3 class="bd b gy z fp mh fr fs mi fu fw dk translated">与机器学习、人工智能和数据发展保持同步的最佳资源…</h3></div><div class="mk l"><p class="bd b dl z fp mh fr fs mi fu fw dk translated">thesequence.substack.com</p></div></div><div class="ml l"><div class="mm l mn mo mp ml mq ks mc"/></div></div></a></div><p id="9c63" class="pw-post-body-paragraph lc ld it lf b lg lh ju li lj lk jx ll mr ln lo lp ms lr ls lt mt lv lw lx ly im bi translated">理解输入数据集的特征是机器学习算法的一项基本能力。给定特定的输入，机器学习模型需要推断关于数据的特定特征，以便执行一些目标动作。表示学习或特征学习是机器学习空间的子学科，处理提取特征或理解数据集的表示。</p><p id="4dcd" class="pw-post-body-paragraph lc ld it lf b lg lh ju li lj lk jx ll mr ln lo lp ms lr ls lt mt lv lw lx ly im bi translated">表征学习可以用一个非常简单的例子来说明。以深度学习算法为例，该算法试图识别下图中的几何形状:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi mu"><img src="../Images/1596c79d8e89b4bb38b0e6ab05ff1eac.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*7VYZ3jxWRJBfF0MT.png"/></div></figure><p id="07ca" class="pw-post-body-paragraph lc ld it lf b lg lh ju li lj lk jx ll mr ln lo lp ms lr ls lt mt lv lw lx ly im bi translated">为了将像素匹配到几何形状，算法首先需要理解数据的一些基本特征/表示，例如角的数量。这就是表征学习的作用。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi mu"><img src="../Images/9ca72d5f66fae31daf557bb5ed51f448.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*HkmM33hSgCDWgIsN.png"/></div></figure><p id="b31f" class="pw-post-body-paragraph lc ld it lf b lg lh ju li lj lk jx ll mr ln lo lp ms lr ls lt mt lv lw lx ly im bi translated">几十年来，表示学习已经成为机器学习领域的一个既定学科，但随着深度学习的出现，它的相关性最近已经大大增加。虽然分类等传统机器学习技术通常处理数学上结构良好的数据集，但深度学习模型处理的是图像或声音等没有明确特征的数据。从这个意义上说，表征学习是大多数深度学习架构的关键要素。</p><p id="1185" class="pw-post-body-paragraph lc ld it lf b lg lh ju li lj lk jx ll mr ln lo lp ms lr ls lt mt lv lw lx ly im bi translated">表征学习的核心问题是确定输入数据的最佳表征。在深度学习的背景下，表征的质量主要取决于它在多大程度上促进了学习过程。在现实世界中，学习算法和模型的底层表示是直接相关的。</p><h1 id="6b89" class="mv mw it bd mx my mz na nb nc nd ne nf jz ng ka nh kc ni kd nj kf nk kg nl nm bi translated">没有免费的午餐定理</h1><p id="d0c5" class="pw-post-body-paragraph lc ld it lf b lg nn ju li lj no jx ll mr np lo lp ms nq ls lt mt nr lw lx ly im bi translated">如果模型的知识表示依赖于它的学习算法，那么选择正确的表示应该是微不足道的，对吗？我们只是选择与学习任务相关的知识表示，这应该保证最佳的性能。我希望事情能这么简单。在寻找最优表示的过程中，我们很快找到了一个老朋友:没有免费的午餐定理(NFLT)。</p><p id="89d8" class="pw-post-body-paragraph lc ld it lf b lg lh ju li lj lk jx ll mr ln lo lp ms lr ls lt mt lv lw lx ly im bi translated">NFLT是困扰最务实的数据科学家和技术专家的数学悖论之一。简而言之，NFLT指出，对所有可能的数据生成分布进行平均，每个机器学习算法在处理以前未观察到的点时都具有大致相同的错误率(阅读我以前关于NFLT的文章)。换句话说，在给定足够宽的数据集的情况下，没有任何机器学习算法比任何其他算法更好。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi ns"><img src="../Images/95457825d66271d2b500aeb8223ea48b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1246/format:webp/0*9EbQkrDl86T7EHWT.png"/></div><figcaption class="ku kv gj gh gi kw kx bd b be z dk translated">图片来源:<a class="ae ky" href="https://medium.com/@LeonFedden/the-no-free-lunch-theorem-62ae2c3ed10c" rel="noopener">https://medium . com/@ LeonFedden/the-no-free-lunch-theory-62 AE 2c 3 ed 10 c</a></figcaption></figure><p id="ff09" class="pw-post-body-paragraph lc ld it lf b lg lh ju li lj lk jx ll mr ln lo lp ms lr ls lt mt lv lw lx ly im bi translated">在表征学习的背景下，NFLT证明了多种知识表征可以适用于学习任务。如果是这样的话，我们怎么能凭经验决定一种知识表示和另一种知识表示呢？答案是机器学习和深度学习模型中最核心且经常被忽略的技术之一:正则化。</p><h1 id="36b2" class="mv mw it bd mx my mz na nb nc nd ne nf jz ng ka nh kc ni kd nj kf nk kg nl nm bi translated">正规化</h1><p id="0f49" class="pw-post-body-paragraph lc ld it lf b lg nn ju li lj no jx ll mr np lo lp ms nq ls lt mt nr lw lx ly im bi translated">机器学习算法的核心任务是在训练数据集之外的新输入下表现良好。优化这项任务就是正则化的作用。从概念上讲，正则化导致对机器学习算法的修改，这种修改减少了测试或泛化误差，而不影响训练误差。</p><p id="00ae" class="pw-post-body-paragraph lc ld it lf b lg lh ju li lj lk jx ll mr ln lo lp ms lr ls lt mt lv lw lx ly im bi translated">现在让我们回到原点，看看正则化是如何与表征学习相关联的。这种关系非常清楚:知识表示的质量从根本上与其有效概括知识的能力有关。换句话说，知识表示必须能够适应训练数据集之外的新输入。为了更好地处理新输入并减少泛化误差，任何知识表示都应该在正则化技术中有用。因此，表征学习模型的质量直接受到它们使用不同正则化策略的能力的影响。下一步是找出哪些正则化策略与表征学习特别相关。这将是未来文章的主题。</p><p id="f94d" class="pw-post-body-paragraph lc ld it lf b lg lh ju li lj lk jx ll mr ln lo lp ms lr ls lt mt lv lw lx ly im bi translated">既然我们知道正则化是一种改进知识表示的机制，下一步就是评估给定表示的质量。本质上，我们试图回答一个简单的问题:是什么使知识表示优于其他表示？</p><h1 id="b493" class="mv mw it bd mx my mz na nb nc nd ne nf jz ng ka nh kc ni kd nj kf nk kg nl nm bi translated">通过规范化提高知识</h1><p id="06ab" class="pw-post-body-paragraph lc ld it lf b lg nn ju li lj no jx ll mr np lo lp ms nq ls lt mt nr lw lx ly im bi translated">为了让术语更直截了当，通过正则化，我们指的是模型在不影响其训练误差的情况下减少其测试误差(生成误差)的能力。每一种知识表示都有某些特征，这些特征使得它更适合特定的正则化技术。人工智能杰出人物伊恩·古德费勒(Ian Goodfellow)和约舒阿·本吉奥(Yoshua Bengio)在正则化领域做了一些出色的工作。根据Goodfellow和Bengio的论文，当涉及到正则化时，有几个特征使知识表示更有效。我总结了以下五种我最喜欢的监管模式:</p><h2 id="d962" class="nt mw it bd mx nu nv dn nb nw nx dp nf mr ny nz nh ms oa ob nj mt oc od nl oe bi translated">1 —解开因果因素</h2><p id="6663" class="pw-post-body-paragraph lc ld it lf b lg nn ju li lj no jx ll mr np lo lp ms nq ls lt mt nr lw lx ly im bi translated">健壮知识表示的关键指标之一是其特征对应于训练数据的潜在原因的事实。此特征有助于区分制图表达中的哪些要素对应于输入数据集中的特定原因，从而有助于更好地将一些要素与其他要素区分开来。</p><h2 id="e408" class="nt mw it bd mx nu nv dn nb nw nx dp nf mr ny nz nh ms oa ob nj mt oc od nl oe bi translated">2 —平滑度</h2><p id="722f" class="pw-post-body-paragraph lc ld it lf b lg nn ju li lj no jx ll mr np lo lp ms nq ls lt mt nr lw lx ly im bi translated">制图表达平滑度是假设输入数据集中相邻点之间的假设值不会发生剧烈变化。从数学上来说，平滑度意味着对于非常小的e，<em class="le"> f(x+ed)≈ f(x) </em>。这一特性允许知识表示在输入数据集中的封闭区域内更好地进行概括。</p><h2 id="0261" class="nt mw it bd mx nu nv dn nb nw nx dp nf mr ny nz nh ms oa ob nj mt oc od nl oe bi translated">3线性度</h2><p id="ecd9" class="pw-post-body-paragraph lc ld it lf b lg nn ju li lj no jx ll mr np lo lp ms nq ls lt mt nr lw lx ly im bi translated">线性是一种正则化模式，是对平滑假设的补充。从概念上讲，这种特性假设一些输入变量之间的关系是线性的<em class="le"> (f(x) = ax + b)，</em>，这使得即使当输入存在相对较大的变化时也能做出准确的预测。</p><h2 id="935a" class="nt mw it bd mx nu nv dn nb nw nx dp nf mr ny nz nh ms oa ob nj mt oc od nl oe bi translated">4 —分层结构</h2><p id="1bc9" class="pw-post-body-paragraph lc ld it lf b lg nn ju li lj no jx ll mr np lo lp ms nq ls lt mt nr lw lx ly im bi translated">基于层次的知识表示是许多正则化技术的理想选择。层次结构假设网络中的每一步都可以用前面的步骤来解释，这极大地有助于通过知识表示进行更好的推理。</p><h2 id="aaad" class="nt mw it bd mx nu nv dn nb nw nx dp nf mr ny nz nh ms oa ob nj mt oc od nl oe bi translated">5-流形表示</h2><p id="92a7" class="pw-post-body-paragraph lc ld it lf b lg nn ju li lj no jx ll mr np lo lp ms nq ls lt mt nr lw lx ly im bi translated">流形学习是机器学习最迷人、数学上最深厚的基础之一。从概念上讲，流形是完全连接点的高维区域。流形假设表明概率质量倾向于集中在输入数据的流形上。流形的伟大之处在于，它们相对容易从高维结构简化为低维表示，这更容易操作，也更便宜。许多正则化算法在检测和操纵流形方面特别有效。</p><p id="59ef" class="pw-post-body-paragraph lc ld it lf b lg lh ju li lj lk jx ll mr ln lo lp ms lr ls lt mt lv lw lx ly im bi translated">尽管它很重要，但在深度学习领域，表征学习仍然是一个不太为人所知的学科。为了为任何给定的任务选择最佳的神经网络架构，理解基础数据集的特征和表示是至关重要的。本文中解释的一些特征为在深度学习解决方案的背景下考虑表征学习提供了一个简单的框架。</p></div></div>    
</body>
</html>