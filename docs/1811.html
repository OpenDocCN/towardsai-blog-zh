<html>
<head>
<title>A Gentle Introduction to Audio Classification With Tensorflow</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">Tensorflow音频分类简介</h1>
<blockquote>原文：<a href="https://pub.towardsai.net/a-gentle-introduction-to-audio-classification-with-tensorflow-c469cb0be6f5?source=collection_archive---------1-----------------------#2021-05-03">https://pub.towardsai.net/a-gentle-introduction-to-audio-classification-with-tensorflow-c469cb0be6f5?source=collection_archive---------1-----------------------#2021-05-03</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><h2 id="43b1" class="io ip iq bd b dl ir is it iu iv iw dk ix translated" aria-label="kicker paragraph"><a class="ae ep" href="https://towardsai.net/p/category/machine-learning/deep-learning" rel="noopener ugc nofollow" target="_blank">深度学习</a></h2><div class=""/><div class=""><h2 id="2b4c" class="pw-subtitle-paragraph jw iz iq bd b jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn dk translated">深度学习在Tensorflow音频分类中的应用</h2></div><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div role="button" tabindex="0" class="ku kv di kw bf kx"><div class="gh gi ko"><img src="../Images/c1a8d58d026bc49d4ff60e8fccc7ca36.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*lp8s9bSTDF3lv4ILQHCt9A.png"/></div></div><figcaption class="la lb gj gh gi lc ld bd b be z dk translated">来源:https://www.tensorflow.org/tutorials/audio/simple_audio<a class="ae le" href="https://www.tensorflow.org/tutorials/audio/simple_audio" rel="noopener ugc nofollow" target="_blank"/></figcaption></figure><p id="c3d8" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi mb translated"><span class="l mc md me bm mf mg mh mi mj di">我们</span>已经看到了许多与<strong class="lh ja">视觉</strong>和<strong class="lh ja">语言</strong>领域相关的深度学习的最新进展，很直观地理解为什么CNN在图像上表现非常好，具有像素的<strong class="lh ja">局部相关性</strong>，以及像RNNs或transformers这样的序列模型如何也在语言上表现非常好，具有其<strong class="lh ja">序列</strong>性质，但音频呢？当我们处理音频数据时，使用什么类型的模型和过程？</p><blockquote class="mk"><p id="9ad6" class="ml mm iq bd mn mo mp mq mr ms mt ma dk translated">在这篇文章中，你将学习如何处理一个简单的音频分类问题，你将学习一些常用和有效的方法，以及Tensorflow代码。</p></blockquote><blockquote class="mu mv mw"><p id="ec15" class="lf lg mx lh b li my ka lk ll mz kd ln na nb lq lr nc nd lu lv ne nf ly lz ma ij bi translated">声明:此处提供的代码基于为“<a class="ae le" href="https://www.kaggle.com/c/rfcx-species-audio-detection" rel="noopener ugc nofollow" target="_blank">雨林连接物种音频检测</a>”ka ggle竞赛开发的<a class="ae le" href="https://www.kaggle.com/dimitreoliveira/rainforest-audio-classification-tensorflow-starter/notebook" rel="noopener ugc nofollow" target="_blank">我的作品</a>，但出于演示目的，我将使用“<a class="ae le" href="https://arxiv.org/abs/1804.03209" rel="noopener ugc nofollow" target="_blank">语音命令</a>数据集。</p></blockquote><h2 id="0922" class="ng nh iq bd ni nj nk dn nl nm nn dp no lo np nq nr ls ns nt nu lw nv nw nx iw bi translated">波形</h2><p id="9e50" class="pw-post-body-paragraph lf lg iq lh b li ny ka lk ll nz kd ln lo oa lq lr ls ob lu lv lw oc ly lz ma ij bi translated">我们通常在“<strong class="lh ja">中有音频文件。wav </strong>格式，它们通常被称为<strong class="lh ja">波形</strong>，一个波形是一个<strong class="lh ja">时间序列</strong>，具有在每个特定时间的信号幅度，如果我们可视化这些波形样本中的一个，我们将得到类似这样的结果:</p><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div role="button" tabindex="0" class="ku kv di kw bf kx"><div class="gh gi od"><img src="../Images/86959c290247f814402b5038084329f2.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*eNM-nfw8p2zi7vmtBett7w.png"/></div></div><figcaption class="la lb gj gh gi lc ld bd b be z dk translated">x轴是时间，y轴是归一化的信号幅度</figcaption></figure><p id="72c3" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">直觉上，人们可能会考虑使用某种类型的<strong class="lh ja"> RNN </strong>模型将这些数据建模为常规的<strong class="lh ja">时间序列</strong>(例如股票价格预测)，事实上，这是可以做到的，但由于我们使用的是音频信号，更合适的选择是将<strong class="lh ja">波形</strong>样本转换为<strong class="lh ja">频谱图</strong>。</p><h2 id="57f5" class="ng nh iq bd ni nj nk dn nl nm nn dp no lo np nq nr ls ns nt nu lw nv nw nx iw bi translated">光谱图</h2><p id="cb08" class="pw-post-body-paragraph lf lg iq lh b li ny ka lk ll nz kd ln lo oa lq lr ls ob lu lv lw oc ly lz ma ij bi translated">频谱图是波形信号的<strong class="lh ja">图像表示</strong>，它显示了其<strong class="lh ja">随时间变化的频率强度范围</strong>，当我们想要评估信号随时间变化的频率分布时，它会非常有用。下面是我们上面看到的波形图的声谱图表示。</p><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div role="button" tabindex="0" class="ku kv di kw bf kx"><div class="gh gi od"><img src="../Images/2b3e8bcb6845b9f891615ba3828a266f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*yJme_mHM3OJ5lBp8hjq3aA.png"/></div></div><figcaption class="la lb gj gh gi lc ld bd b be z dk translated">x轴是采样时间，y轴是频率</figcaption></figure><h2 id="fa07" class="ng nh iq bd ni nj nk dn nl nm nn dp no lo np nq nr ls ns nt nu lw nv nw nx iw bi translated">语音命令用例</h2><p id="578f" class="pw-post-body-paragraph lf lg iq lh b li ny ka lk ll nz kd ln lo oa lq lr ls ob lu lv lw oc ly lz ma ij bi translated">为了使本教程更简单，我们将使用"<a class="ae le" href="https://arxiv.org/abs/1804.03209" rel="noopener ugc nofollow" target="_blank">语音命令</a>"数据集，这个数据集有一个一秒钟的音频剪辑，带有语音单词，如:"向下"、"向前"、"向左"、"不"、"向右"、"停止"、"向上"和"是"。</p><h2 id="46aa" class="ng nh iq bd ni nj nk dn nl nm nn dp no lo np nq nr ls ns nt nu lw nv nw nx iw bi translated">使用Tensorflow进行音频处理</h2><p id="83d0" class="pw-post-body-paragraph lf lg iq lh b li ny ka lk ll nz kd ln lo oa lq lr ls ob lu lv lw oc ly lz ma ij bi translated">现在，我们已经了解了如何处理音频数据以用于深度学习模型，我们可以继续查看代码实现来做到这一点，我们的管道将遵循下图描述的简单工作流程:</p><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div role="button" tabindex="0" class="ku kv di kw bf kx"><div class="gh gi oe"><img src="../Images/9f91ba3bcbf190c555c711a94e591a1d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*PyudpjESKeGkWVzOhlqmgg.jpeg"/></div></div><figcaption class="la lb gj gh gi lc ld bd b be z dk translated">简单音频处理图</figcaption></figure><blockquote class="mu mv mw"><p id="dc76" class="lf lg mx lh b li lj ka lk ll lm kd ln na lp lq lr nc lt lu lv ne lx ly lz ma ij bi translated">请注意，在我们的用例中，在<strong class="lh ja">第一步中，</strong>数据是直接从。wav”文件，而第三步<strong class="lh ja">是可选的</strong>，因为每个音频文件只有一秒钟，在某些情况下，对于较长的文件以及在所有样本中保持固定长度，裁剪音频可能是个好主意。</p></blockquote><p id="2f12" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated"><strong class="lh ja">加载数据</strong></p><pre class="kp kq kr ks gt of og oh oi aw oj bi"><span id="34a9" class="ng nh iq og b gy ok ol l om on">def load_dataset(filenames):<br/>  dataset = <!-- -->tf.data.Dataset.from_tensor_slices(<!-- -->filenames<!-- -->)<br/>  return dataset</span></pre><p id="7ae3" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated"><code class="fe oo op oq og b">load_dataset</code>函数将负责加载<code class="fe oo op oq og b">.wav</code>文件并将它们转换成Tensorflow数据集。</p><p id="81c1" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated"><strong class="lh ja">提取波形并标记</strong></p><pre class="kp kq kr ks gt of og oh oi aw oj bi"><span id="4e3a" class="ng nh iq og b gy ok ol l om on">commands = np.array(tf.io.gfile.listdir(str(data_dir)))<br/>commands = commands[commands != 'README.md']</span><span id="8b95" class="ng nh iq og b gy or ol l om on">def decode_audio(audio_binary):<br/>  audio, _ = tf.audio.decode_wav(audio_binary)<br/>  return tf.squeeze(audio, axis=-1)</span><span id="8e38" class="ng nh iq og b gy or ol l om on">def get_label(<!-- -->filename<!-- -->):<br/>  label = tf.strings.split(<!-- -->filename<!-- -->, os.path.sep)[-2]<br/>  label = tf.argmax(label == commands)<br/>  return label</span><span id="eed9" class="ng nh iq og b gy or ol l om on">def get_waveform_and_label(<!-- -->filename<!-- -->):<br/>  label = get_label(<!-- -->filename<!-- -->)<br/>  audio_binary = tf.io.read_file(<!-- -->filename<!-- -->)<br/>  waveform = decode_audio(audio_binary)<br/>  return waveform, label</span></pre><p id="f308" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">加载完<code class="fe oo op oq og b">.wav</code>文件后，我们需要解码它们，这可以使用<code class="fe oo op oq og b">tf.audio.decode_wav</code>函数来完成，它会将<code class="fe oo op oq og b">.wav</code>文件转换成浮点张量。接下来，我们需要从文件中提取标签，在这个特定的用例中，我们可以从每个样本的文件路径中获取标签，之后我们只需要对它们进行一次性编码。</p><p id="947e" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">下面是一个例子:<br/>首先，我们得到这样一个文件路径:</p><pre class="kp kq kr ks gt of og oh oi aw oj bi"><span id="ae4f" class="ng nh iq og b gy ok ol l om on">"data/mini_speech_commands/up/50f55535_nohash_0.wav"</span></pre><p id="4d2f" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">然后我们提取第二个“<strong class="lh ja"> / </strong>”之后的文本，在这种情况下，标签是<strong class="lh ja"> UP，</strong>最后，我们使用<code class="fe oo op oq og b">commands</code>列表对标签进行一键编码。</p><pre class="kp kq kr ks gt of og oh oi aw oj bi"><span id="4427" class="ng nh iq og b gy ok ol l om on">Commands: ['up' 'down' 'go' 'stop' 'left' 'no' 'yes' 'right']</span><span id="0a4b" class="ng nh iq og b gy or ol l om on">Label = 'up'</span><span id="62b2" class="ng nh iq og b gy or ol l om on">After one-hot encoding:</span><span id="2062" class="ng nh iq og b gy or ol l om on">Label = [1, 0, 0, 0, 0, 0, 0, 0]</span></pre><p id="5530" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated"><strong class="lh ja">将波形转换成频谱图</strong></p><p id="5a05" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">下一步是将<strong class="lh ja">波形</strong>文件转换为<strong class="lh ja">频谱图</strong>，幸运的是Tensorflow有一个功能可以做到这一点，<code class="fe oo op oq og b">tf.signal.stft</code>应用短时傅立叶变换(<strong class="lh ja"> STFT </strong>)将音频转换到时频域，然后我们应用<code class="fe oo op oq og b">tf.abs</code>算子去除信号相位，只保留<strong class="lh ja">幅度</strong>。请注意，<code class="fe oo op oq og b">tf.signal.stft</code>功能有一些参数，如<code class="fe oo op oq og b">frame_length</code>和<code class="fe oo op oq og b">frame_step</code>，它们会影响生成的声谱图，我不会详细介绍如何调整它们，但您可以参考<a class="ae le" href="https://www.coursera.org/lecture/audio-signal-processing/stft-2-tjEQe" rel="noopener ugc nofollow" target="_blank">此视频</a>了解更多信息。</p><pre class="kp kq kr ks gt of og oh oi aw oj bi"><span id="1ac2" class="ng nh iq og b gy ok ol l om on">def get_spectrogram(waveform, padding=False, min_padding=48000):<br/>  waveform = tf.cast(waveform, tf.float32)<br/>  spectrogram = tf.signal.stft(waveform, frame_length=2048, frame_step=512, fft_length=2048)<br/>  spectrogram = tf.abs(spectrogram)<br/>  return spectrogram</span><span id="e223" class="ng nh iq og b gy or ol l om on">def get_spectrogram_tf(waveform, label):<br/>  spectrogram = get_spectrogram(waveform)<br/>  spectrogram = tf.expand_dims(spectrogram, <!-- -->axis=-<!-- -->1)<br/>  return spectrogram, label</span></pre><p id="8274" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated"><strong class="lh ja">将光谱图转换成RGB图像</strong></p><p id="b2fb" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">最后一步是将光谱图转换为RGB图像，这一步是可选的，但这里我们将使用在ImageNet数据集上预先训练的模型，该模型需要具有3个通道的输入图像，否则，您可以只保留一个通道的光谱图。</p><pre class="kp kq kr ks gt of og oh oi aw oj bi"><span id="c057" class="ng nh iq og b gy ok ol l om on">def prepare_sample(spectrogram, label):<br/>  spectrogram = tf.image.resize(spectrogram, [HEIGHT, WIDTH])<br/>  spectrogram = tf.image.grayscale_to_rgb(spectrogram)<br/>  return spectrogram, label</span></pre><p id="3674" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated"><strong class="lh ja">结合在一起</strong></p><pre class="kp kq kr ks gt of og oh oi aw oj bi"><span id="f369" class="ng nh iq og b gy ok ol l om on">HEIGHT, WIDTH = 128, 128<br/>AUTO = tf.data.AUTOTUNE</span><span id="755f" class="ng nh iq og b gy or ol l om on">def get_dataset(filenames, batch_size=32):<br/>  dataset = load_dataset(filenames)<br/>    <br/>  <!-- -->dataset<!-- --> = files_ds.map(get_waveform_and_label, num_parallel_calls=AUTO)<br/>  dataset = dataset.map(get_spectrogram_tf, num_parallel_calls=AUTO)<br/>  dataset = dataset.map(prepare_sample, num_parallel_calls=AUTO)</span><span id="647d" class="ng nh iq og b gy or ol l om on">  dataset = dataset.shuffle(256)<br/>  dataset = dataset.repeat()<br/>  dataset = dataset.batch(batch_size)<br/>  dataset = dataset.prefetch(<!-- -->AUTO<!-- -->)<br/>  return dataset</span></pre><p id="199a" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">综上所述，我们使用了<code class="fe oo op oq og b">get_dataset</code>函数，它将文件名作为输入，在完成上述所有步骤后，返回一个包含RGB光谱图图像及其标签的Tensorflow数据集。</p><h2 id="4e63" class="ng nh iq bd ni nj nk dn nl nm nn dp no lo np nq nr ls ns nt nu lw nv nw nx iw bi translated">模型</h2><pre class="kp kq kr ks gt of og oh oi aw oj bi"><span id="8608" class="ng nh iq og b gy ok ol l om on">def model_fn(input_shape, N_CLASSES):<br/>  inputs = L.Input(shape=input_shape, name='input_audio')<br/>  base_model = efn.EfficientNetB0(input_tensor=inputs, <br/>                                  include_top=False, <br/>                                  weights='imagenet')<br/><br/>  x = L.GlobalAveragePooling2D()(base_model.output)<br/>  x = L.Dropout(.5)(x)<br/>  output = L.Dense(N_CLASSES, activation='softmax',name='output')(x)<br/>    <br/>  model = Model(inputs=inputs, outputs=output)<br/><br/>  return model</span></pre><p id="4d42" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">我们的模型将有一个<strong class="lh ja"> EfficientNetB0 </strong>主干，在它的顶部，我们添加了一个<strong class="lh ja">globalaveragepool2d</strong>，后面是一个<strong class="lh ja"> Dropout，</strong>，最后是一个<strong class="lh ja"> Dense </strong>层，它将进行实际的多类分类。</p><blockquote class="mu mv mw"><p id="4794" class="lf lg mx lh b li lj ka lk ll lm kd ln na lp lq lr nc lt lu lv ne lx ly lz ma ij bi translated">对于小数据集来说，EfficientNetB0可能是一个很好的基准，即使它是一个快速而轻便的模型，它也有相当好的准确性。</p></blockquote><h2 id="173a" class="ng nh iq bd ni nj nk dn nl nm nn dp no lo np nq nr ls ns nt nu lw nv nw nx iw bi translated">培养</h2><pre class="kp kq kr ks gt of og oh oi aw oj bi"><span id="13e4" class="ng nh iq og b gy ok ol l om on">model = model_fn((None, None, CHANNELS), N_CLASSES)</span><span id="9e1a" class="ng nh iq og b gy or ol l om on">model.compile(optimizer=tf.optimizers.Adam(), <br/>              loss=losses.CategoricalCrossentropy(), <br/>              metrics=[metrics.CategoricalAccuracy()])<br/><br/>model.fit(x=get_dataset(FILENAMES), <br/>          steps_per_epoch=100, <br/>          epochs=10)</span></pre><p id="c793" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">对于Keras模型来说，训练代码是非常标准的，所以您可能不会在这里发现任何新东西。</p><h2 id="9a22" class="ng nh iq bd ni nj nk dn nl nm nn dp no lo np nq nr ls ns nt nu lw nv nw nx iw bi translated">结论</h2><p id="cb80" class="pw-post-body-paragraph lf lg iq lh b li ny ka lk ll nz kd ln lo oa lq lr ls ob lu lv lw oc ly lz ma ij bi translated">现在，您应该对将深度学习应用于音频文件的工作流有了更清晰的理解，尽管这不是唯一的方法，但这是关于易用性/性能权衡的最佳选择之一。如果你要制作音频模型，你也可以考虑其他有前途的方法，比如变压器。</p><p id="f33e" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">作为额外的预处理步骤，您可以截断或填充波形，这可能是一个好主意，如果您的样本具有不同的长度，或者如果样本太长，您只需要其中的一小部分，您可以在下面的参考资料部分找到如何做到这一点的代码。</p><p id="f19c" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated"><strong class="lh ja">参考文献</strong> <br/> - <a class="ae le" href="https://www.tensorflow.org/tutorials/audio/simple_audio" rel="noopener ugc nofollow" target="_blank">简单音频识别:识别关键词</a>-<a class="ae le" href="https://www.kaggle.com/dimitreoliveira/rainforest-audio-classification-tensorflow-starter" rel="noopener ugc nofollow" target="_blank">雨林-音频分类tensor flow starter</a>-<a class="ae le" href="https://www.kaggle.com/dimitreoliveira/rainforest-audio-classification-tf-improved/notebook" rel="noopener ugc nofollow" target="_blank">雨林-音频分类TF改良</a></p><div class="os ot gp gr ou ov"><a href="https://www.kaggle.com/dimitreoliveira/rainforest-audio-classification-tensorflow-starter?scriptVersionId=60260050&amp;cellId=1" rel="noopener  ugc nofollow" target="_blank"><div class="ow ab fo"><div class="ox ab oy cl cj oz"><h2 class="bd ja gy z fp pa fr fs pb fu fw iz bi translated">雨林-音频分类Tensorflow启动器</h2><div class="pc l"><h3 class="bd b gy z fp pa fr fs pb fu fw dk translated">使用Kaggle笔记本探索和运行机器学习代码|使用来自雨林连接物种音频的数据…</h3></div><div class="pd l"><p class="bd b dl z fp pa fr fs pb fu fw dk translated">www.kaggle.com</p></div></div><div class="pe l"><div class="pf l pg ph pi pe pj ky ov"/></div></div></a></div><div class="os ot gp gr ou ov"><a href="https://www.kaggle.com/dimitreoliveira/rainforest-audio-classification-tf-improved/notebook?scriptVersionId=53686233&amp;cellId=1" rel="noopener  ugc nofollow" target="_blank"><div class="ow ab fo"><div class="ox ab oy cl cj oz"><h2 class="bd ja gy z fp pa fr fs pb fu fw iz bi translated">雨林-音频分类TF改进</h2><div class="pc l"><h3 class="bd b gy z fp pa fr fs pb fu fw dk translated">使用Kaggle笔记本探索和运行机器学习代码|使用来自雨林连接物种音频的数据…</h3></div><div class="pd l"><p class="bd b dl z fp pa fr fs pb fu fw dk translated">www.kaggle.com</p></div></div><div class="pe l"><div class="pk l pg ph pi pe pj ky ov"/></div></div></a></div></div></div>    
</body>
</html>