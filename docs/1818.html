<html>
<head>
<title>Infinite Nature: Fly Into an Image and Explore It Like Controlling a Drone!</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">无限自然:飞入一个影像，像控制无人机一样探索它！</h1>
<blockquote>原文：<a href="https://pub.towardsai.net/infinite-nature-fly-into-an-image-and-explore-it-like-controlling-a-drone-541cab44b8f5?source=collection_archive---------3-----------------------#2021-05-04">https://pub.towardsai.net/infinite-nature-fly-into-an-image-and-explore-it-like-controlling-a-drone-541cab44b8f5?source=collection_archive---------3-----------------------#2021-05-04</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><h2 id="a186" class="ir is it bd b dl iu iv iw ix iy iz dk ja translated" aria-label="kicker paragraph"><a class="ae ep" href="https://towardsai.net/p/category/artificial-intelligence" rel="noopener ugc nofollow" target="_blank">人工智能</a></h2><div class=""/><div class=""><h2 id="764b" class="pw-subtitle-paragraph jz jc it bd b ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq dk translated">视图合成的下一步:永久视图生成，目标是拍摄一幅图像，然后飞进去探索风景！</h2></div><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi kr"><img src="../Images/b1644e8057c6ffd24e247ebe244e3634.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*oYyXXjNqlL8CKtT_FpPdAQ.png"/></div></div></figure><blockquote class="ld le lf"><p id="f1d3" class="lg lh li lj b lk ll kd lm ln lo kg lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">原载于<a class="ae md" href="https://www.louisbouchard.ai/infinite-nature/" rel="noopener ugc nofollow" target="_blank"> louisbouchard.ai </a>，前两天在<a class="ae md" href="https://www.louisbouchard.ai/tag/artificial-intelligence/" rel="noopener ugc nofollow" target="_blank">我的博客</a>上看到的！</p></blockquote><figure class="ks kt ku kv gt kw"><div class="bz fp l di"><div class="me mf l"/></div><figcaption class="mg mh gj gh gi mi mj bd b be z dk translated">听听这个故事</figcaption></figure><p id="71c7" class="pw-post-body-paragraph lg lh it lj b lk ll kd lm ln lo kg lp mk lr ls lt ml lv lw lx mm lz ma mb mc im bi translated">本周的<a class="ae md" href="https://arxiv.org/pdf/2012.09855.pdf" rel="noopener ugc nofollow" target="_blank">论文</a>是关于一项名为“永久视图生成”的新任务，目标是拍摄一张图像飞入其中并探索风景。这是这个问题的第一个解决方案，但考虑到我们只将一幅图像输入网络，它可以生成像鸟一样飞入网络的图像，这是非常令人印象深刻的。当然，这项任务极其复杂，并将随着时间的推移而改进。正如两分钟论文所说，想象一下，在接下来的几篇论文中，这项技术对于视频游戏或飞行模拟器是多么有用！</p><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div class="gh gi mn"><img src="../Images/92dfe8e65453849369278eb9063f7a76.png" data-original-src="https://miro.medium.com/v2/resize:fit:1184/1*4vlnsgYBBvm4_M3qY7CsZw.gif"/></div><figcaption class="mg mh gj gh gi mi mj bd b be z dk translated">莉雅等著<a class="ae md" href="https://arxiv.org/pdf/2012.09855.pdf" rel="noopener ugc nofollow" target="_blank">无限自然</a></figcaption></figure><p id="b988" class="pw-post-body-paragraph lg lh it lj b lk ll kd lm ln lo kg lp mk lr ls lt ml lv lw lx mm lz ma mb mc im bi translated">我惊讶地看到它已经运行得如此之好，即使这是介绍这项新任务的论文。尤其是考虑到这个任务有多复杂。不仅因为它必须像GANverse3D一样生成新的视点，我在以前的<a class="ae md" href="https://www.louisbouchard.me/ganverse3d/" rel="noopener ugc nofollow" target="_blank">文章</a>中提到过，而且它还必须在每一帧生成一个新的图像，一旦你通过了几十帧，你就几乎没有原始图像可以使用了。是的，这可以在数百帧上完成，同时仍然比当前的视图合成方法看起来好得多。</p><p id="df1e" class="pw-post-body-paragraph lg lh it lj b lk ll kd lm ln lo kg lp mk lr ls lt ml lv lw lx mm lz ma mb mc im bi translated">让我们看看他们如何从一张图片生成一个完整的鸟瞰视频，以及您如何在无需设置任何东西的情况下立即尝试！</p><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div class="gh gi mo"><img src="../Images/da3a28a437e6b91173f9ef1e5cacf2e5.png" data-original-src="https://miro.medium.com/v2/resize:fit:1108/0*CkbHUGZbZHMtDv8l.gif"/></div><figcaption class="mg mh gj gh gi mi mj bd b be z dk translated"><a class="ae md" href="https://arxiv.org/pdf/2012.09855.pdf" rel="noopener ugc nofollow" target="_blank">莉雅等著《无限的自然》</a></figcaption></figure><p id="15e5" class="pw-post-body-paragraph lg lh it lj b lk ll kd lm ln lo kg lp mk lr ls lt ml lv lw lx mm lz ma mb mc im bi translated">要做到这一点，他们必须使用图像的几何形状，所以他们首先需要产生图像的视差图。这是通过一个叫做<a class="ae md" href="https://github.com/intel-isl/MiDaS" rel="noopener ugc nofollow" target="_blank"> MiDaS </a>的最先进的网络来完成的，我就不赘述了，但这是它给出的输出。这个视差图基本上是一个反向深度图，通知网络场景内部的深度。</p><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi mp"><img src="../Images/f90c9fd03daf30f4d7a527706dd0673e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*ZVG2C-5g1wiMh-7d.PNG"/></div></div><figcaption class="mg mh gj gh gi mi mj bd b be z dk translated"><a class="ae md" href="https://arxiv.org/pdf/2012.09855.pdf" rel="noopener ugc nofollow" target="_blank">莉雅，A等人，无限自然</a></figcaption></figure><p id="d736" class="pw-post-body-paragraph lg lh it lj b lk ll kd lm ln lo kg lp mk lr ls lt ml lv lw lx mm lz ma mb mc im bi translated">然后，我们进入他们的技术的真正的第一步，这是渲染器。这个渲染器的目标是基于旧视图生成一个新视图。这个新视图将是下一帧，正如你所理解的，旧视图是输入图像。这是使用可区分渲染器完成的。可微分只是因为我们可以使用反向传播来训练它，就像我们传统上使用传统的深度网络一样，你知道。该渲染器利用图像和视差图生成一个三维网格，表示您可以在下面的图3(左)中看到的场景。然后，我们简单地使用这个3D网格从一个新的视点生成一个图像，在这个例子中是P1。这给了我们这张惊人的新照片，看起来有点放大，但它不是简单的放大。渲染图像上有一些粉红色的标记，视差图上有一些黑色的标记，如上面的图2所示。它们对应于用作渲染器输入的先前图像中的遮挡区域和视野之外的区域，因为该渲染器仅生成新的视图，而不能创造看不见的细节。这就给我们带来了一个相当大的问题，如果我们不知道那里发生了什么，我们怎么能有一个完整而真实的图像呢？好吧，我们可以使用另一个网络，它也将这个新的视差图和图像作为输入来“细化”它(图3，右)。</p><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi mq"><img src="../Images/77fbcc38b745dc8b0d2c1618bd6d2e2c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*7BOQ8u3NEiZ4gKkg.PNG"/></div></div><figcaption class="mg mh gj gh gi mi mj bd b be z dk translated">莉雅著，<a class="ae md" href="https://arxiv.org/pdf/2012.09855.pdf" rel="noopener ugc nofollow" target="_blank">A等人，</a>无限自然</figcaption></figure><p id="ed79" class="pw-post-body-paragraph lg lh it lj b lk ll kd lm ln lo kg lp mk lr ls lt ml lv lw lx mm lz ma mb mc im bi translated">另一个名为SPADE的网络(显示在右边)也是一个网络状态，但用于条件图像合成。这里，它是一个条件图像合成网络，因为我们需要告诉我们的网络一些条件，在这种情况下，这些条件是粉红色和黑色缺失的部分。我们基本上是将这个有缺陷的图像发送到第二个网络，以填补漏洞并添加必要的细节。你可以将这种铲形网络视为GAN架构，图像首先被编码成潜在代码，这将为我们提供图像的风格。然后，该代码被解码以生成初始图像的新版本，简单地用遵循编码信息中存在的相同风格的新信息来填充丢失的部分。</p><p id="0045" class="pw-post-body-paragraph lg lh it lj b lk ll kd lm ln lo kg lp mk lr ls lt ml lv lw lx mm lz ma mb mc im bi translated">瞧！你有了新的框架和它的反向深度图。你现在可以简单地一遍又一遍地重复这个过程来得到所有未来的帧，就像这样。使用这个输出作为下一次迭代的输入，您可以产生无限的迭代，总是遵循想要的视点和前面的帧上下文！</p><p id="9e02" class="pw-post-body-paragraph lg lh it lj b lk ll kd lm ln lo kg lp mk lr ls lt ml lv lw lx mm lz ma mb mc im bi translated">如你所知，如此强大的算法经常需要数据和注释来训练，这个也不例外。为了做到这一点，他们需要从无人机上拍摄的自然航拍镜头，这些镜头是他们从youtube上拍摄的，经过人工策划和预处理，以创建他们自己的数据集。幸运的是，对于其他想要应对这一挑战的研究人员来说，你不必做同样的事情，因为他们发布了这套自然海岸场景的空中镜头数据集，用于训练他们的算法。它可以在他们的项目页面上下载，该页面链接在下面的参考资料中。</p><p id="3b48" class="pw-post-body-paragraph lg lh it lj b lk ll kd lm ln lo kg lp mk lr ls lt ml lv lw lx mm lz ma mb mc im bi translated">正如我提到的，你甚至可以自己尝试，因为他们公开了代码，但他们也创建了一个<a class="ae md" href="https://colab.research.google.com/github/google-research/google-research/blob/master/infinite_nature/infinite_nature_demo.ipynb#scrollTo=sCuRX1liUEVM" rel="noopener ugc nofollow" target="_blank">演示</a>你现在就可以在google colab上尝试。链接在下面的参考资料中。您只需像这样运行前几个单元，它们将安装代码和依赖项，加载它们的模型，然后就可以了。你现在可以在他们的图片周围自由飞翔，甚至上传你自己的图片！当然，我刚才提到的所有步骤都已经存在了。</p><p id="4827" class="pw-post-body-paragraph lg lh it lj b lk ll kd lm ln lo kg lp mk lr ls lt ml lv lw lx mm lz ma mb mc im bi translated">只需运行代码并享受！</p><h2 id="3a24" class="mr ms it bd mt mu mv dn mw mx my dp mz mk na nb nc ml nd ne nf mm ng nh ni iz bi translated">观看视频中的更多示例:</h2><figure class="ks kt ku kv gt kw"><div class="bz fp l di"><div class="nj mf l"/></div></figure><p id="15a4" class="pw-post-body-paragraph lg lh it lj b lk ll kd lm ln lo kg lp mk lr ls lt ml lv lw lx mm lz ma mb mc im bi translated">如果你喜欢我的工作，并想与人工智能保持同步，你绝对应该关注我的其他社交媒体账户(<a class="ae md" href="https://www.linkedin.com/in/whats-ai/" rel="noopener ugc nofollow" target="_blank"> LinkedIn </a>，<a class="ae md" href="https://twitter.com/Whats_AI" rel="noopener ugc nofollow" target="_blank"> Twitter </a>)，并订阅我的每周人工智能<a class="ae md" href="http://eepurl.com/huGLT5" rel="noopener ugc nofollow" target="_blank"> <strong class="lj jd">简讯</strong> </a>！</p><h2 id="38a4" class="mr ms it bd mt mu mv dn mw mx my dp mz mk na nb nc ml nd ne nf mm ng nh ni iz bi translated">支持我:</h2><ul class=""><li id="b3f3" class="nk nl it lj b lk nm ln nn mk no ml np mm nq mc nr ns nt nu bi translated">支持我的最好方式是在<a class="ae md" href="https://medium.com/@whats-ai" rel="noopener"> <strong class="lj jd">媒体</strong> </a> <strong class="lj jd"> </strong>上关注我，或者如果你喜欢视频格式，在<a class="ae md" href="https://www.youtube.com/channel/UCUzGQrN-lyyc0BWTYoJM_Sg" rel="noopener ugc nofollow" target="_blank"><strong class="lj jd">YouTube</strong></a><strong class="lj jd"/>上订阅我的频道<strong class="lj jd"> </strong>。</li><li id="9253" class="nk nl it lj b lk nv ln nw mk nx ml ny mm nz mc nr ns nt nu bi translated">支持我在<a class="ae md" href="https://www.patreon.com/whatsai" rel="noopener ugc nofollow" target="_blank"> <strong class="lj jd">上的工作</strong></a></li><li id="99f2" class="nk nl it lj b lk nv ln nw mk nx ml ny mm nz mc nr ns nt nu bi translated">加入我们的<a class="ae md" href="https://discord.gg/learnaitogether" rel="noopener ugc nofollow" target="_blank"> <strong class="lj jd"> Discord社区:</strong> <strong class="lj jd">一起学AI</strong></a>和<em class="li">分享你的项目、论文、最佳课程、寻找Kaggle队友等等！</em></li></ul></div><div class="ab cl oa ob hx oc" role="separator"><span class="od bw bk oe of og"/><span class="od bw bk oe of og"/><span class="od bw bk oe of"/></div><div class="im in io ip iq"><h2 id="9a10" class="mr ms it bd mt mu mv dn mw mx my dp mz mk na nb nc ml nd ne nf mm ng nh ni iz bi translated">参考</h2><p id="7599" class="pw-post-body-paragraph lg lh it lj b lk nm kd lm ln nn kg lp mk oh ls lt ml oi lw lx mm oj ma mb mc im bi translated">论文:刘，a .，塔克，r .，贾帕尼，v .，马卡迪亚，a .，斯内夫利，n .，金泽，a .，2020。无限自然:从一幅图像中生成自然场景的永久视图，<a class="ae md" href="https://arxiv.org/pdf/2012.09855.pdf" rel="noopener ugc nofollow" target="_blank">https://arxiv.org/pdf/2012.09855.pdf</a></p><p id="abc6" class="pw-post-body-paragraph lg lh it lj b lk ll kd lm ln lo kg lp mk lr ls lt ml lv lw lx mm lz ma mb mc im bi translated">项目链接:【https://infinite-nature.github.io/ T2】</p><p id="fbe4" class="pw-post-body-paragraph lg lh it lj b lk ll kd lm ln lo kg lp mk lr ls lt ml lv lw lx mm lz ma mb mc im bi translated">代码:<a class="ae md" href="https://github.com/google-research/google-research/tree/master/infinite_nature" rel="noopener ugc nofollow" target="_blank">https://github . com/Google-research/Google-research/tree/master/infinite _ nature</a></p><p id="bd0f" class="pw-post-body-paragraph lg lh it lj b lk ll kd lm ln lo kg lp mk lr ls lt ml lv lw lx mm lz ma mb mc im bi translated">colab demo:<a class="ae md" href="https://colab.research.google.com/github/google-research/google-research/blob/master/infinite_nature/infinite_nature_demo.ipynb#scrollTo=sCuRX1liUEVM" rel="noopener ugc nofollow" target="_blank">https://colab . research . Google . com/github/Google-research/Google-research/blob/master/infinite _ nature/infinite _ nature _ demo . ipynb # scroll to = scurx 1 Liu EVM</a></p><p id="a469" class="pw-post-body-paragraph lg lh it lj b lk ll kd lm ln lo kg lp mk lr ls lt ml lv lw lx mm lz ma mb mc im bi translated">midalsl:Ranftl等人，2020年，走向稳健的单目深度估计:零炮跨数据集传输的混合数据集，<a class="ae md" href="https://github.com/intel-isl/MiDaS" rel="noopener ugc nofollow" target="_blank">https://github.com/intel-isl/MiDaS</a></p><p id="ae2e" class="pw-post-body-paragraph lg lh it lj b lk ll kd lm ln lo kg lp mk lr ls lt ml lv lw lx mm lz ma mb mc im bi translated">SPADE: Park等人，2019，空间自适应归一化的语义图像合成，<a class="ae md" href="https://github.com/NVlabs/SPADE" rel="noopener ugc nofollow" target="_blank">https://github.com/NVlabs/SPADE</a></p></div></div>    
</body>
</html>