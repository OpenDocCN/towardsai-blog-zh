<html>
<head>
<title>What is a GPU? Are GPUs Needed for Deep Learning?</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">什么是GPU？深度学习需要GPU吗？</h1>
<blockquote>原文：<a href="https://pub.towardsai.net/what-is-a-gpu-are-gpus-needed-for-deep-learning-7b315ed80f16?source=collection_archive---------0-----------------------#2021-03-13">https://pub.towardsai.net/what-is-a-gpu-are-gpus-needed-for-deep-learning-7b315ed80f16?source=collection_archive---------0-----------------------#2021-03-13</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><figure class="is it gp gr iu iv gh gi paragraph-image"><a href="https://news.towardsai.net/laptops"><div class="gh gi ir"><img src="../Images/e7193d7a94f6afd0143a79971cc622b1.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*skBJZVf2v_6sAbljn1-bRw.jpeg"/></div></a><figcaption class="iy iz gj gh gi ja jb bd b be z dk translated">来源:卡斯帕·卡米尔·鲁宾在Unsplash 上的照片</figcaption></figure><h2 id="72a8" class="jd je jf bd b dl jg jh ji jj jk jl dk jm translated" aria-label="kicker paragraph"><a class="ae ep" href="https://towardsai.net/p/category/machine-learning/deep-learning" rel="noopener ugc nofollow" target="_blank">深度学习</a>、<a class="ae ep" href="https://towardsai.net/p/category/editorial" rel="noopener ugc nofollow" target="_blank">社论</a>、<a class="ae ep" href="https://towardsai.net/p/category/technology" rel="noopener ugc nofollow" target="_blank">技术</a></h2><div class=""/><div class=""><h2 id="552b" class="pw-subtitle-paragraph kl jo jf bd b km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc dk translated">深入了解什么是GPU的技术解释</h2></div><p id="06b7" class="pw-post-body-paragraph ld le jf lf b lg lh kp li lj lk ks ll lm ln lo lp lq lr ls lt lu lv lw lx ly im bi translated"><strong class="lf jp">作者:</strong>布塞·任亚·泰京，<a class="ae jc" href="https://mktg.best/vguzs" rel="noopener ugc nofollow" target="_blank">罗伯托·伊里翁多</a></p><div class="is it gp gr iu lz"><a href="https://members.towardsai.net/" rel="noopener  ugc nofollow" target="_blank"><div class="ma ab fo"><div class="mb ab mc cl cj md"><h2 class="bd jp gy z fp me fr fs mf fu fw jo bi translated">加入我们吧↓ |面向人工智能成员|数据驱动的社区</h2><div class="mg l"><h3 class="bd b gy z fp me fr fs mf fu fw dk translated">向着AI加入。通过成为会员，你不仅将支持人工智能，但你将有机会…</h3></div><div class="mh l"><p class="bd b dl z fp me fr fs mf fu fw dk translated">members.towardsai.net</p></div></div><div class="mi l"><div class="mj l mk ml mm mi mn iw lz"/></div></div></a></div><p id="783a" class="pw-post-body-paragraph ld le jf lf b lg lh kp li lj lk ks ll lm ln lo lp lq lr ls lt lu lv lw lx ly im bi mo translated"><span class="l mp mq mr bm ms mt mu mv mw di">在</span>智能时代，越来越多的创新概念每天都在涌现。其中一个无疑是<strong class="lf jp"/><a class="ae jc" href="https://news.towardsai.net/aiml" rel="noopener ugc nofollow" target="_blank"><strong class="lf jp">人工智能</strong> </a> <strong class="lf jp">的领域。”</strong>在<strong class="lf jp"> </strong>这个案例中，具体来说，AI的一个子分支——<a class="ae jc" href="https://news.towardsai.net/dl" rel="noopener ugc nofollow" target="_blank"><strong class="lf jp"/></a>深度学习，会在我们需要深入复杂问题的时候遇到我们，如今在很多领域都有使用。我们开发深度学习模型来完成特定的任务，在某些情况下，超越人类的重复能力。在本文中，我们将通过代码示例来探索GPU如何用于深度学习。</p><p id="e47e" class="pw-post-body-paragraph ld le jf lf b lg lh kp li lj lk ks ll lm ln lo lp lq lr ls lt lu lv lw lx ly im bi translated">本教程的代码可以在Github上找到，也可以在Google Colab上找到。</p><blockquote class="mx my mz"><p id="ee89" class="ld le na lf b lg lh kp li lj lk ks ll nb ln lo lp nc lr ls lt nd lv lw lx ly im bi translated">“在人工智能和算法在我们的生活和组织中做出更多决策的时代，是时候让人们利用他们的直觉作为今天技术能力的辅助手段了。我们内在的智慧可以将经验数据嵌入人性。”</p><p id="6b46" class="ld le na lf b lg lh kp li lj lk ks ll nb ln lo lp nc lr ls lt nd lv lw lx ly im bi translated"><em class="jf">——阿布舍克·拉特纳</em><a class="ae jc" href="https://www.goodreads.com/quotes/tag/algorithms" rel="noopener ugc nofollow" target="_blank"><em class="jf">12</em></a><em class="jf"/></p></blockquote><h1 id="362a" class="ne nf jf bd ng nh ni nj nk nl nm nn no ku np kv nq kx nr ky ns la nt lb nu nv bi translated">什么是GPU？</h1><p id="db93" class="pw-post-body-paragraph ld le jf lf b lg nw kp li lj nx ks ll lm ny lo lp lq nz ls lt lu oa lw lx ly im bi translated">图形处理单元(GPU)是一种专门的电子电路，设计用于快速操作和更改内存，以加速在帧缓冲区中创建图像，并输出到显示设备[ <a class="ae jc" href="https://en.wikipedia.org/wiki/Graphics_processing_unit" rel="noopener ugc nofollow" target="_blank"> 1 </a> ]。</p><p id="25a8" class="pw-post-body-paragraph ld le jf lf b lg lh kp li lj lk ks ll lm ln lo lp lq lr ls lt lu lv lw lx ly im bi translated">图形处理单元是一个计算机芯片，执行快速数学方程来渲染图像。专用或集成可能是图形卡的一部分。</p><p id="be86" class="pw-post-body-paragraph ld le jf lf b lg lh kp li lj lk ks ll lm ln lo lp lq lr ls lt lu lv lw lx ly im bi translated">在嵌入式系统中，在很多领域都很有可能看到GPU，比如个人电脑或者工作站。这取决于并行处理结构。与图像和视频处理中包含的图形处理器相比，GPU具有优势。如今，GPU越来越受欢迎，也越来越被人工智能(AI)所需要。</p><figure class="oc od oe of gt iv gh gi paragraph-image"><a href="https://news.towardsai.net/laptops"><div class="gh gi ob"><img src="../Images/4bdb9588ecf241cc3170f7d4b5c56ed7.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*wj4tENfWs0lpFEiq.png"/></div></a><figcaption class="iy iz gj gh gi ja jb bd b be z dk translated">来源:照片由<a class="ae jc" href="https://unsplash.com/@christianw" rel="noopener ugc nofollow" target="_blank">克里斯蒂安·威迪格</a>在<a class="ae jc" href="https://unsplash.com/photos/3GUW88tRmv8" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上拍摄</figcaption></figure><h1 id="0ad4" class="ne nf jf bd ng nh ni nj nk nl nm nn no ku np kv nq kx nr ky ns la nt lb nu nv bi translated">深度学习需要GPU吗？</h1><p id="3419" class="pw-post-body-paragraph ld le jf lf b lg nw kp li lj nx ks ll lm ny lo lp lq nz ls lt lu oa lw lx ly im bi translated">在使用深度学习方法的同时，经常被提及的GPU也在不断尝试后台存在的可能性。因此，这种情况不是很抽象。虽然我们在上面讨论了GPU的更多主题领域，但我们将讨论使用GPU以及它对深度学习的意义。</p><p id="c681" class="pw-post-body-paragraph ld le jf lf b lg lh kp li lj lk ks ll lm ln lo lp lq lr ls lt lu lv lw lx ly im bi translated">在深度学习领域，当涉及到训练模型时，需要更多的速度和性能。更具体地说，想想<a class="ae jc" href="https://news.towardsai.net/ivn" rel="noopener ugc nofollow" target="_blank"> <strong class="lf jp">人工神经网络</strong> </a>的复杂结构。虽然这些神经网络主要处理大型数据集，但在训练训练集时会观察到正常运行时间的增加。此外，随着数据集的增长，训练时间有时甚至会占用很长时间。</p><p id="2eb7" class="pw-post-body-paragraph ld le jf lf b lg lh kp li lj lk ks ll lm ln lo lp lq lr ls lt lu lv lw lx ly im bi translated">假设我们有一个包含图像内容的样本数据集。从算法上来说，对该数据集中关于神经网络前馈和反向传播的每个数据采取行动。如果我们没有GPU，机器将承担更多的处理负载，因此需要很长时间才能给我们处理结果。</p><p id="2267" class="pw-post-body-paragraph ld le jf lf b lg lh kp li lj lk ks ll lm ln lo lp lq lr ls lt lu lv lw lx ly im bi translated"><strong class="lf jp">因此，在开发深度学习模型时，我们将需要的最重要的硬件之一是GPU。</strong></p><h1 id="e7c4" class="ne nf jf bd ng nh ni nj nk nl nm nn no ku np kv nq kx nr ky ns la nt lb nu nv bi translated">GPU和CPU有什么区别？</h1><figure class="oc od oe of gt iv gh gi paragraph-image"><div class="gh gi og"><img src="../Images/95dfab5889d7f9466e234a7203e00f69.png" data-original-src="https://miro.medium.com/v2/resize:fit:1162/format:webp/0*_gfi6sQ2N4pBZJkS.png"/></div><figcaption class="iy iz gj gh gi ja jb bd b be z dk translated">CPU与GPU架构</figcaption></figure><p id="f5bc" class="pw-post-body-paragraph ld le jf lf b lg lh kp li lj lk ks ll lm ln lo lp lq lr ls lt lu lv lw lx ly im bi translated">中央处理单元(CPU)，也称为中央处理器、微处理器、主处理器或简称为处理器，执行包括计算机程序的指令。</p><p id="930d" class="pw-post-body-paragraph ld le jf lf b lg lh kp li lj lk ks ll lm ln lo lp lq lr ls lt lu lv lw lx ly im bi translated">传统的CPU(中央处理器)基于一些方法，由于它们的成本和可扩展性问题，这些方法不能带来执行并行计算任务的最佳解决方案。如上图所示，CPU执行程序指令[ <a class="ae jc" href="https://blogs.nvidia.com/blog/2009/12/16/whats-the-difference-between-a-cpu-and-a-gpu/" rel="noopener ugc nofollow" target="_blank"> 6 </a> ]指定的基本算术、逻辑、控制和输入/输出(I / O)操作。</p><figure class="oc od oe of gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="oi oj di ok bf ol"><div class="gh gi oh"><img src="../Images/2dd7826cf9c8d6e31b32c27a3cc9267e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*WMYjUPG4h3hnG9mW"/></div></div><figcaption class="iy iz gj gh gi ja jb bd b be z dk translated">由<a class="ae jc" href="https://unsplash.com/@aleshcka?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">奥列格·戈斯波达雷斯</a>在<a class="ae jc" href="https://unsplash.com/?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上拍摄的照片</figcaption></figure><p id="deed" class="pw-post-body-paragraph ld le jf lf b lg lh kp li lj lk ks ll lm ln lo lp lq lr ls lt lu lv lw lx ly im bi translated">相比之下，GPU(图形处理单元)是一种特殊类型的微处理器，主要用于快速图像渲染。GPU似乎对图形密集型应用程序做出了响应，这些应用程序加重了CPU的负担，降低了计算机性能。</p><p id="1243" class="pw-post-body-paragraph ld le jf lf b lg lh kp li lj lk ks ll lm ln lo lp lq lr ls lt lu lv lw lx ly im bi translated">CPU和GPU完全可以互换(取决于手头的任务)，它们都以不同的方式完成工作。大脑和力量通常被作为这一对的例子。因为CPU是中央处理器，所以被称为<strong class="lf jp">计算机的大脑</strong>。当然，如果没有CPU，GPU就没有任何意义。由于CPU被认为是大脑，它处理不同类型的计算，而GPU必须专注于特定的任务。</p><p id="7722" class="pw-post-body-paragraph ld le jf lf b lg lh kp li lj lk ks ll lm ln lo lp lq lr ls lt lu lv lw lx ly im bi translated">而CPU可以解决进程，它会一个接一个地做，GPU可以高效地同时同步解决多个任务。在某种程度上，这两者是相辅相成的。</p><p id="c920" class="pw-post-body-paragraph ld le jf lf b lg lh kp li lj lk ks ll lm ln lo lp lq lr ls lt lu lv lw lx ly im bi translated">除了切换设备，还可以同步使用多个GPU来提高深度学习模型的性能。这种硬件变体被称为<strong class="lf jp">多GPU </strong>。我们可以并行运行多个GPU，也可以不并行继续。当GPU在没有并行的情况下加电时，每个GPU都会单独工作。因此，建议使用并行多GPU来提高性能。</p><p id="7eba" class="pw-post-body-paragraph ld le jf lf b lg lh kp li lj lk ks ll lm ln lo lp lq lr ls lt lu lv lw lx ly im bi translated">多GPU的使用在<strong class="lf jp"> PyTorch </strong>和<strong class="lf jp"> TensorFlow </strong>框架中非常灵活，这两个框架都是流行的深度学习模型。</p><blockquote class="mx my mz"><p id="2ab2" class="ld le na lf b lg lh kp li lj lk ks ll nb ln lo lp nc lr ls lt nd lv lw lx ly im bi translated"><em class="jf"> PyTorch是一个基于Torch库的开源机器学习库，用于计算机视觉和自然语言处理等应用，主要由脸书的AI研究实验室[</em><a class="ae jc" href="https://en.wikipedia.org/wiki/PyTorch" rel="noopener ugc nofollow" target="_blank"><em class="jf">8</em></a><em class="jf">]开发。</em></p></blockquote><p id="6394" class="pw-post-body-paragraph ld le jf lf b lg lh kp li lj lk ks ll lm ln lo lp lq lr ls lt lu lv lw lx ly im bi translated">TensorFlow是一个开源框架，它灵活地支持模型<strong class="lf jp">并行</strong>。</p><blockquote class="mx my mz"><p id="5daf" class="ld le na lf b lg lh kp li lj lk ks ll nb ln lo lp nc lr ls lt nd lv lw lx ly im bi translated"><em class="jf"> TensorFlow是一款</em> <a class="ae jc" href="https://en.wikipedia.org/wiki/Free_software" rel="noopener ugc nofollow" target="_blank"> <em class="jf">免费</em></a><em class="jf"/><a class="ae jc" href="https://en.wikipedia.org/wiki/Open-source_software" rel="noopener ugc nofollow" target="_blank"><strong class="lf jp"><em class="jf">开源</em></strong></a><strong class="lf jp"><em class="jf"/></strong><a class="ae jc" href="https://en.wikipedia.org/wiki/Library_(computing)" rel="noopener ugc nofollow" target="_blank"><strong class="lf jp"><em class="jf">软件库</em> </strong> </a> <em class="jf">为</em> <a class="ae jc" href="https://mld.ai/mldcmu" rel="noopener ugc nofollow" target="_blank"> <strong class="lf jp"> <em class="jf">机器学习</em> </strong> </a> <em class="jf">。它可以跨一系列任务使用但重点是</em> <a class="ae jc" href="https://en.wikipedia.org/wiki/Types_of_artificial_neural_networks#Training" rel="noopener ugc nofollow" target="_blank"> <strong class="lf jp"> <em class="jf">训练</em> </strong> </a> <em class="jf">和</em> <a class="ae jc" href="https://en.wikipedia.org/wiki/Statistical_inference" rel="noopener ugc nofollow" target="_blank"> <strong class="lf jp"> <em class="jf">推理</em></strong></a><strong class="lf jp"><em class="jf"/></strong><em class="jf">深度神经网络</em> <a class="ae jc" href="https://en.wikipedia.org/wiki/TensorFlow" rel="noopener ugc nofollow" target="_blank"> <em class="jf"> 10 </em> </a> <em class="jf">】。</em></p></blockquote><p id="0c05" class="pw-post-body-paragraph ld le jf lf b lg lh kp li lj lk ks ll lm ln lo lp lq lr ls lt lu lv lw lx ly im bi translated">🎥让我们来看看Adobe Illustrator如何处理图像，以了解GPU的工作机制和CPU之间的差异。🎥</p><figure class="oc od oe of gt iv"><div class="bz fp l di"><div class="om on l"/></div><figcaption class="iy iz gj gh gi ja jb bd b be z dk translated">adobe Illustrator CC:NVIDIA GPU与CPU</figcaption></figure><p id="7fdb" class="pw-post-body-paragraph ld le jf lf b lg lh kp li lj lk ks ll lm ln lo lp lq lr ls lt lu lv lw lx ly im bi translated">NVIDIA首席执行官黄仁勋在<a class="ae jc" href="https://www.youtube.com/watch?v=pzbhU4ttSvM" rel="noopener ugc nofollow" target="_blank"> <strong class="lf jp"> GPU技术大会(GTC)的主题演讲中描述了一个将加速和人工智能计算引入Arm CPU平台的三管齐下的尝试:“人工智能时代的计算</strong> </a>”它还总结了英伟达正在做什么来推进人工智能时代。在一次<a class="ae jc" href="https://www.youtube.com/watch?v=-P28LKWTzrI" rel="noopener ugc nofollow" target="_blank"> <strong class="lf jp">流言终结者演示</strong> </a>中，亚当·沙维奇和杰米·韩门展示了GPU计算的强大功能。</p><figure class="oc od oe of gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="oi oj di ok bf ol"><div class="gh gi oh"><img src="../Images/4aa18f0abdc04d5327ca3928a4295767.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*NVMH5oDHe-0wNKhR"/></div></div><figcaption class="iy iz gj gh gi ja jb bd b be z dk translated">Lars Kienle 在<a class="ae jc" href="https://unsplash.com/?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上拍摄的照片</figcaption></figure><p id="712b" class="pw-post-body-paragraph ld le jf lf b lg lh kp li lj lk ks ll lm ln lo lp lq lr ls lt lu lv lw lx ly im bi translated">作为一个附加信息，除了CPU和GPU之外，还有一个<strong class="lf jp">数据处理单元</strong>叫做<strong class="lf jp"> DPU </strong>。诚然，也许多年来计算机上唯一的元素就是CPU。图形处理单元，我们称之为GPU，现在已经承担了这一角色，最近，通过在数据中心[ <a class="ae jc" href="https://blogs.nvidia.com/blog/2020/05/20/whats-a-dpu-data-processing-unit/" rel="noopener ugc nofollow" target="_blank"> 5 </a> ]构建软件可编程的多核CPU，已经创建了dpu。</p><h1 id="7aa8" class="ne nf jf bd ng nh ni nj nk nl nm nn no ku np kv nq kx nr ky ns la nt lb nu nv bi translated">如何用GPU开发深度学习模型？</h1><p id="1340" class="pw-post-body-paragraph ld le jf lf b lg nw kp li lj nx ks ll lm ny lo lp lq nz ls lt lu oa lw lx ly im bi translated">在开发深度学习模型的时候，我们首先要确定我们的计算机有GPU并且可用。</p><p id="e5bb" class="pw-post-body-paragraph ld le jf lf b lg lh kp li lj lk ks ll lm ln lo lp lq lr ls lt lu lv lw lx ly im bi translated">⚙️<strong class="lf jp">OS:</strong>windows 10 pro<br/>⚙️<strong class="lf jp">cuda工具包:</strong>10<br/>⚙️<strong class="lf jp">cud nn:</strong>7.4<br/>⚙️<strong class="lf jp">tensor flow GPU:</strong>1 . 14 . 0<br/>⚙️<strong class="lf jp">keras:</strong>2 . 2 . 5</p><p id="c1e0" class="pw-post-body-paragraph ld le jf lf b lg lh kp li lj lk ks ll lm ln lo lp lq lr ls lt lu lv lw lx ly im bi translated">软件技术有很多选择。我们使用一个我们最喜欢的叫做<strong class="lf jp"> TensorFlow </strong>的机器学习框架，它有很多文档。</p><p id="4abf" class="pw-post-body-paragraph ld le jf lf b lg lh kp li lj lk ks ll lm ln lo lp lq lr ls lt lu lv lw lx ly im bi translated">通过访问<a class="ae jc" href="https://developer.nvidia.com/cuda-gpus#collapse4" rel="noopener ugc nofollow" target="_blank"><strong class="lf jp">CUDA GPU</strong></a>确定适合机器的处理器。例如，在下图中，我们通过主动检查我使用的机器了解了处理能力。</p><figure class="oc od oe of gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="oi oj di ok bf ol"><div class="gh gi oo"><img src="../Images/abedadf2fd13d50ab4b4b81d72bb78ff.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*AMm_DCHbd2SyFw7g.png"/></div></div><figcaption class="iy iz gj gh gi ja jb bd b be z dk translated">控制夸德罗RTX 5000处理器</figcaption></figure><p id="15c1" class="pw-post-body-paragraph ld le jf lf b lg lh kp li lj lk ks ll lm ln lo lp lq lr ls lt lu lv lw lx ly im bi translated">为了使用GPU执行深度学习任务，我们需要为我们的机器安装合适的cuDNN工具和CUDA工具包。否则，我们将无法使用GPU。要在TensorFlow中使用GPU，如果使用Conda加载，则需要安装TensorFlow-GPU库。在此过程中，还将显示适当的CUDA和cuDNN版本。</p><h1 id="d37b" class="ne nf jf bd ng nh ni nj nk nl nm nn no ku np kv nq kx nr ky ns la nt lb nu nv bi translated">安装CUDA工具包和cuDNN工具</h1><p id="2283" class="pw-post-body-paragraph ld le jf lf b lg nw kp li lj nx ks ll lm ny lo lp lq nz ls lt lu oa lw lx ly im bi translated">我们需要安装与我们将使用的TensorFlow版本相匹配的CUDA和cuDNN工具。作为警告，如果我们下载不同的版本，我们会遇到许多错误。在TensorFlow 2.x版本中，可以接收日志或形状错误。我们注意到，多次安装后，TensorFlow-GPU与1.14.0或1.15.0配合使用效果良好。</p><figure class="oc od oe of gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="oi oj di ok bf ol"><div class="gh gi op"><img src="../Images/7be7696ffafb5400f64b2d621e808f0a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*ln4oy1Zf0NpTJjDi.png"/></div></div><figcaption class="iy iz gj gh gi ja jb bd b be z dk translated">适用于CUDA的TensorFlow版本[ <a class="ae jc" href="https://www.tensorflow.org/install/source_windows" rel="noopener ugc nofollow" target="_blank"> Res </a> ] [4]</figcaption></figure><p id="85ac" class="pw-post-body-paragraph ld le jf lf b lg lh kp li lj lk ks ll lm ln lo lp lq lr ls lt lu lv lw lx ly im bi translated"><strong class="lf jp"> TensorFlow-gpu==1.14.0 </strong>所需的编译显示<strong class="lf jp"> cuDNN </strong>的<strong class="lf jp"> 7.4 </strong>和<strong class="lf jp"> CUDA工具包</strong>的<strong class="lf jp"> 10 </strong>版本。</p><p id="6258" class="pw-post-body-paragraph ld le jf lf b lg lh kp li lj lk ks ll lm ln lo lp lq lr ls lt lu lv lw lx ly im bi translated">当与Conda一起安装时，我们将收到安装批准。我们也可以看到CUDA和cuDNN版本安装的同时给予这种认可。这样，我们就会看到我们是在正确的轨道上。</p><figure class="oc od oe of gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="oi oj di ok bf ol"><div class="gh gi oq"><img src="../Images/82918cf30a584e81780eab08f7c4aa9e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1270/format:webp/0*MH5Nx0MMbqZ-fMaT.png"/></div></div><figcaption class="iy iz gj gh gi ja jb bd b be z dk translated">作者图片</figcaption></figure><p id="048c" class="pw-post-body-paragraph ld le jf lf b lg lh kp li lj lk ks ll lm ln lo lp lq lr ls lt lu lv lw lx ly im bi translated">但是，除了TensorFlow之外，还必须安装Keras库。Keras是一个开源软件库，为神经网络提供了Python接口。Keras充当TensorFlow库[ <a class="ae jc" href="https://en.wikipedia.org/wiki/Keras" rel="noopener ugc nofollow" target="_blank"> 11 </a> ]的接口。</p><p id="b949" class="pw-post-body-paragraph ld le jf lf b lg lh kp li lj lk ks ll lm ln lo lp lq lr ls lt lu lv lw lx ly im bi translated">📚《T4》<strong class="lf jp"><em class="na">用Python进行深度学习</em> </strong> ，由Keras的创造者弗朗索瓦·乔莱(Franç ois Chollet)所著，对于想从事这方面工作的人来说是非常成功的。要使用深度学习创建GPU设置环境，请访问文章<a class="ae jc" rel="noopener ugc nofollow" target="_blank" href="/creating-a-deep-learning-environment-with-tensorflow-gpu-c16980ed1f67"> <strong class="lf jp">使用TensorFlow GPU创建深度学习环境</strong> </a>。</p><p id="660e" class="pw-post-body-paragraph ld le jf lf b lg lh kp li lj lk ks ll lm ln lo lp lq lr ls lt lu lv lw lx ly im bi translated">虚拟环境通常用于避免机器基础环境中的错误安装。在这个步骤中，建立了一个特定Python版本的虚拟环境。</p><pre class="oc od oe of gt or os ot ou aw ov bi"><span id="88f5" class="ow nf jf os b gy ox oy l oz pa">conda create -n virtualenv python=3.6conda activate virtualenv</span></pre><p id="d54f" class="pw-post-body-paragraph ld le jf lf b lg lh kp li lj lk ks ll lm ln lo lp lq lr ls lt lu lv lw lx ly im bi translated">Conda或pip命令用于加载TensorFlow GP。这一步将安装TensorFlow GPU。</p><pre class="oc od oe of gt or os ot ou aw ov bi"><span id="ba00" class="ow nf jf os b gy ox oy l oz pa">pip install tensorflow-gpu</span></pre><p id="2c7c" class="pw-post-body-paragraph ld le jf lf b lg lh kp li lj lk ks ll lm ln lo lp lq lr ls lt lu lv lw lx ly im bi translated">如果安装TensorFlow GPU时未指定版本，将安装最新版本。如果要安装特定的版本，可以通过编写版本来完成。</p><pre class="oc od oe of gt or os ot ou aw ov bi"><span id="d9bf" class="ow nf jf os b gy ox oy l oz pa">pip install tensorflow-gpu==1.15.0</span></pre><p id="2fd2" class="pw-post-body-paragraph ld le jf lf b lg lh kp li lj lk ks ll lm ln lo lp lq lr ls lt lu lv lw lx ly im bi translated">安装TensorFlow GPU后，我们应该运行以下代码行进行控制。</p><pre class="oc od oe of gt or os ot ou aw ov bi"><span id="e25e" class="ow nf jf os b gy ox oy l oz pa">import tensorflow as tf<br/>tf.test.gpu_device_name()</span></pre><p id="9d54" class="pw-post-body-paragraph ld le jf lf b lg lh kp li lj lk ks ll lm ln lo lp lq lr ls lt lu lv lw lx ly im bi translated">要检查我们已安装的TensorFlow GPU版本，请运行<strong class="lf jp"> pip show命令。</strong></p><pre class="oc od oe of gt or os ot ou aw ov bi"><span id="f61b" class="ow nf jf os b gy ox oy l oz pa">pip show tensorflow-gpu</span></pre><p id="90d3" class="pw-post-body-paragraph ld le jf lf b lg lh kp li lj lk ks ll lm ln lo lp lq lr ls lt lu lv lw lx ly im bi translated">为了检查GPU的可用性，运行以下代码片段。</p><pre class="oc od oe of gt or os ot ou aw ov bi"><span id="5446" class="ow nf jf os b gy ox oy l oz pa">%tensorflow_version 2.x</span><span id="e1fd" class="ow nf jf os b gy pb oy l oz pa">import tensorflow as tf</span><span id="2f4c" class="ow nf jf os b gy pb oy l oz pa">device_name = tf.test.gpu_device_name()</span><span id="d991" class="ow nf jf os b gy pb oy l oz pa">if device_name != ‘/device:GPU:0’:</span><span id="c783" class="ow nf jf os b gy pb oy l oz pa">raise SystemError(‘GPU device not found’)</span><span id="7816" class="ow nf jf os b gy pb oy l oz pa">print(‘Found GPU at: {}’.format(device_name))</span></pre><p id="65b1" class="pw-post-body-paragraph ld le jf lf b lg lh kp li lj lk ks ll lm ln lo lp lq lr ls lt lu lv lw lx ly im bi translated">使用TensorFlow 2.4.1版本时，显示TensorFlow 2.x版本。此案例用于1.x版本，如下所示。</p><pre class="oc od oe of gt or os ot ou aw ov bi"><span id="fd7f" class="ow nf jf os b gy ox oy l oz pa">%tensorflow_version 1.x</span><span id="8158" class="ow nf jf os b gy pb oy l oz pa">import tensorflow as tf</span><span id="12d0" class="ow nf jf os b gy pb oy l oz pa">device_name = tf.test.gpu_device_name()</span><span id="b3cb" class="ow nf jf os b gy pb oy l oz pa">if device_name != ‘/device:GPU:0’:</span><span id="80d5" class="ow nf jf os b gy pb oy l oz pa">raise SystemError(‘GPU device not found’)</span><span id="8222" class="ow nf jf os b gy pb oy l oz pa">print(‘Found GPU at: {}’.format(device_name))</span></pre><p id="1ac5" class="pw-post-body-paragraph ld le jf lf b lg lh kp li lj lk ks ll lm ln lo lp lq lr ls lt lu lv lw lx ly im bi translated">计算机很可能有不止一个GPU。默认情况下，我们的机器或媒体使用GPU，这要感谢Google Colab。可以用另一个设备代替这个GPU来代替。在下面的代码片段中，它适用于device / GPU: 1。</p><pre class="oc od oe of gt or os ot ou aw ov bi"><span id="4d3c" class="ow nf jf os b gy ox oy l oz pa">import tensorflow as tf</span><span id="878c" class="ow nf jf os b gy pb oy l oz pa">tf.device('/device:GPU:1')</span></pre><p id="a7a2" class="pw-post-body-paragraph ld le jf lf b lg lh kp li lj lk ks ll lm ln lo lp lq lr ls lt lu lv lw lx ly im bi translated">已达到并行GPU使用。此外，我们必须提到，在进入笔记本电脑之前，甚至可以在我们的终端上设置GPU。</p><pre class="oc od oe of gt or os ot ou aw ov bi"><span id="4542" class="ow nf jf os b gy ox oy l oz pa">from tensorflow.python.client import </span><span id="1ffb" class="ow nf jf os b gy pb oy l oz pa">device_libdevice_lib.list_local_devices()</span></pre><p id="be3b" class="pw-post-body-paragraph ld le jf lf b lg lh kp li lj lk ks ll lm ln lo lp lq lr ls lt lu lv lw lx ly im bi translated">考虑Colab笔记本电脑时，将提供四种设备。这些是CPU，GPU，XLA_CPU和XLA_GPU。这里的列表中显示了四个设备。其中两个是排除CPU和GPU的一个概念。</p><p id="928e" class="pw-post-body-paragraph ld le jf lf b lg lh kp li lj lk ks ll lm ln lo lp lq lr ls lt lu lv lw lx ly im bi translated">正如TensorFlow的文档中提到的，XLA代表“加速线性代数”Tensorflow相对较新的优化编译器可以通过将过去的多个CUDA内核合并为一个[ <a class="ae jc" href="https://stackoverflow.com/questions/52943489/what-is-xla-gpu-and-xla-cpu-for-tensorflow" rel="noopener ugc nofollow" target="_blank"> 13 </a> ]来进一步加快我们的ML模型的GPU操作。</p><pre class="oc od oe of gt or os ot ou aw ov bi"><span id="4324" class="ow nf jf os b gy ox oy l oz pa">import tensorflow as tf</span><span id="d6c0" class="ow nf jf os b gy pb oy l oz pa">try:</span><span id="bfc3" class="ow nf jf os b gy pb oy l oz pa">  tf.device('/job:localhost/replica:0/task:0/device:GPU:1')except RuntimeError as e:</span><span id="c15e" class="ow nf jf os b gy pb oy l oz pa">  print(e)</span></pre><p id="7fa3" class="pw-post-body-paragraph ld le jf lf b lg lh kp li lj lk ks ll lm ln lo lp lq lr ls lt lu lv lw lx ly im bi translated">如果设备1的物理GPU不存在，我们建议尝试下面的代码。为了学习所用设备的名称，测试GPU将在它是GPU时运行。</p><pre class="oc od oe of gt or os ot ou aw ov bi"><span id="a371" class="ow nf jf os b gy ox oy l oz pa">import tensorflow as tftf.test.gpu_device_name()</span></pre><p id="a990" class="pw-post-body-paragraph ld le jf lf b lg lh kp li lj lk ks ll lm ln lo lp lq lr ls lt lu lv lw lx ly im bi translated">有时会测试模型训练来检查GPU的运行速度。通过加载MNIST数据集中的数据，卷积网络在特定图层上运行。</p><pre class="oc od oe of gt or os ot ou aw ov bi"><span id="558b" class="ow nf jf os b gy ox oy l oz pa">import tensorflow as tf</span><span id="82d5" class="ow nf jf os b gy pb oy l oz pa">mnist = tf.keras.datasets.fashion_mnist</span><span id="1079" class="ow nf jf os b gy pb oy l oz pa">(training_images, training_labels), (test_images, test_labels) = mnist.load_data()</span><span id="7288" class="ow nf jf os b gy pb oy l oz pa">training_images=training_images / 255.0</span><span id="b638" class="ow nf jf os b gy pb oy l oz pa">test_images=test_images / 255.0</span><span id="4f1c" class="ow nf jf os b gy pb oy l oz pa">model = tf.keras.models.Sequential([</span><span id="74da" class="ow nf jf os b gy pb oy l oz pa">tf.keras.layers.Flatten(),</span><span id="384c" class="ow nf jf os b gy pb oy l oz pa">tf.keras.layers.Dense(128, activation=tf.nn.relu),</span><span id="a5b8" class="ow nf jf os b gy pb oy l oz pa">tf.keras.layers.Dense(10, activation=tf.nn.softmax)</span><span id="040f" class="ow nf jf os b gy pb oy l oz pa">])</span><span id="24a2" class="ow nf jf os b gy pb oy l oz pa">model.compile(optimizer=’adam’, loss=’sparse_categorical_crossentropy’, metrics=[‘accuracy’])</span><span id="b78b" class="ow nf jf os b gy pb oy l oz pa">model.fit(training_images, training_labels, epochs=5)</span><span id="55b1" class="ow nf jf os b gy pb oy l oz pa">test_loss = model.evaluate(test_images, test_labels)</span></pre><p id="381f" class="pw-post-body-paragraph ld le jf lf b lg lh kp li lj lk ks ll lm ln lo lp lq lr ls lt lu lv lw lx ly im bi translated">在这里，随着数据数量的增加，问题变得更加复杂，训练之间的差异会变得更大。因为在这个示例代码行中没有非常大的数据集，所以在处理数据时，CPU和GPU之间没有太大的区别。但是在处理大数据的时候会有明显的区别。</p><pre class="oc od oe of gt or os ot ou aw ov bi"><span id="f88d" class="ow nf jf os b gy ox oy l oz pa">import tensorflow as tf</span><span id="b5f8" class="ow nf jf os b gy pb oy l oz pa">sess=tf.Session(config=tf.ConfigProto(log_device_placement=True))</span></pre><p id="79fa" class="pw-post-body-paragraph ld le jf lf b lg lh kp li lj lk ks ll lm ln lo lp lq lr ls lt lu lv lw lx ly im bi translated">与最近被频繁提及的Keras框架TensorFlow一起，TensorFlow现在被用作<code class="fe pc pd pe os b">tf.keras</code>。这是应该在深度学习环境中使用的框架。</p><pre class="oc od oe of gt or os ot ou aw ov bi"><span id="bfef" class="ow nf jf os b gy ox oy l oz pa">pip install keras==2.2.5</span></pre><h1 id="f39a" class="ne nf jf bd ng nh ni nj nk nl nm nn no ku np kv nq kx nr ky ns la nt lb nu nv bi translated">一段时间内CPU和GPU带宽的比较</h1><blockquote class="mx my mz"><p id="56b3" class="ld le na lf b lg lh kp li lj lk ks ll nb ln lo lp nc lr ls lt nd lv lw lx ly im bi translated"><em class="jf">带宽是指GPU与其关联系统之间的外部带宽。它是对连接两者的总线上的数据传输速度的度量(例如，PCIe或Thunderbolt)。带宽不是指GPU内部的带宽，是衡量GPU内部组件之间数据传输速度的指标[</em><a class="ae jc" href="https://developer.apple.com/documentation/metal/gpu_selection_in_macos/understanding_gpu_bandwidth" rel="noopener ugc nofollow" target="_blank"><em class="jf">7</em></a><em class="jf">][</em><a class="ae jc" href="https://en.wikipedia.org/wiki/Memory_bandwidth" rel="noopener ugc nofollow" target="_blank"><em class="jf">9</em></a><em class="jf">]。</em></p></blockquote><p id="0909" class="pw-post-body-paragraph ld le jf lf b lg lh kp li lj lk ks ll lm ln lo lp lq lr ls lt lu lv lw lx ly im bi translated">在深度学习过程中训练模型时，CPU使用了太多内存。原则上，在处理大型数据集时会遇到这种情况。但是在看GPU的时候，在训练模型的时候，在用名为<strong class="lf jp"> VRAM </strong>的内存处理的同时，CPU剩余的内存会分配给其他任务。因此，即使在复杂的问题中，该过程也可以用很少的循环来完成。</p><figure class="oc od oe of gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="oi oj di ok bf ol"><div class="gh gi pf"><img src="../Images/ab5bcf1288e1338f45bdac9e4b45063a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*WDvPwW-fW2Rq8CKO.png"/></div></div><figcaption class="iy iz gj gh gi ja jb bd b be z dk translated">GPU与CPU性能[ <a class="ae jc" href="https://www.researchgate.net/publication/270222593_To_Use_or_Not_to_Use_Graphics_Processing_Units_for_Pattern_Matching_Algorithms" rel="noopener ugc nofollow" target="_blank"> Res </a> ] [2]</figcaption></figure><p id="6ee5" class="pw-post-body-paragraph ld le jf lf b lg lh kp li lj lk ks ll lm ln lo lp lq lr ls lt lu lv lw lx ly im bi translated">高端NVIDIA GPUs拥有比任何CPU都宽得多的总线和更高的内存时钟频率。最大内存带宽是从处理器的半导体内存中读取数据或向其中存储数据的最大速率(GB/s)。</p><p id="5420" class="pw-post-body-paragraph ld le jf lf b lg lh kp li lj lk ks ll lm ln lo lp lq lr ls lt lu lv lw lx ly im bi translated">英特尔酷睿X系列处理器的理论最大内存带宽可通过以下方法计算得出:将内存频率(两倍数据速率后的一半x 2)、宽度字节数和处理器支持的通道数相乘[ <a class="ae jc" href="https://www.intel.com/content/www/us/en/products/docs/processors/what-is-a-gpu.html" rel="noopener ugc nofollow" target="_blank"> 2 </a> ]。</p><blockquote class="mx my mz"><p id="4090" class="ld le na lf b lg lh kp li lj lk ks ll nb ln lo lp nc lr ls lt nd lv lw lx ly im bi translated"><em class="jf">例如:<br/>对于DDR4 2933，某些core-x系列支持的内存为(1466.67 X 2) X 8(字节数宽度)X 4(通道数)= 93866.88 MB/s带宽，或94gb/s[</em><a class="ae jc" href="https://forums.developer.nvidia.com/t/why-gpu-has-large-memory-bandwidth-than-cpu/10294" rel="noopener ugc nofollow" target="_blank"><em class="jf">Res</em></a><em class="jf">][</em><a class="ae jc" href="https://www.intel.com/content/www/us/en/products/docs/processors/what-is-a-gpu.html" rel="noopener ugc nofollow" target="_blank"><em class="jf">2</em></a><em class="jf">][3]。</em></p></blockquote><p id="bf66" class="pw-post-body-paragraph ld le jf lf b lg lh kp li lj lk ks ll lm ln lo lp lq lr ls lt lu lv lw lx ly im bi translated">由于许多系统变量，如软件工作负载和系统电源状态，内存带宽可能低于预期。</p><blockquote class="mx my mz"><p id="5636" class="ld le na lf b lg lh kp li lj lk ks ll nb ln lo lp nc lr ls lt nd lv lw lx ly im bi translated"><em class="jf">高端NVIDIA GPUs比任何CPU都有更宽的总线和更高的内存时钟速度。考虑到具有最高内存带宽的英特尔酷睿i7处理器，它似乎具有192位宽的内存总线和高达800 MHz的内存速度(有效地)。最快的NVIDIA GPU是GTX 285[</em><a class="ae jc" href="https://forums.developer.nvidia.com/t/why-gpu-has-large-memory-bandwidth-than-cpu/10294" rel="noopener ugc nofollow" target="_blank"><em class="jf">Res</em></a><em class="jf">【3】。</em></p></blockquote></div><div class="ab cl pg ph hx pi" role="separator"><span class="pj bw bk pk pl pm"/><span class="pj bw bk pk pl pm"/><span class="pj bw bk pk pl"/></div><div class="im in io ip iq"><p id="5377" class="pw-post-body-paragraph ld le jf lf b lg lh kp li lj lk ks ll lm ln lo lp lq lr ls lt lu lv lw lx ly im bi translated"><strong class="lf jp"> <em class="na">披露:</em> </strong> <em class="na">作为亚马逊的合作伙伴，朝向AI可能会从本帖中链接的合格购买中获得一小笔佣金(买家无需额外付费)。如有反馈、问题或疑虑，请发送电子邮件至pub@towardsai.net</em><a class="ae jc" href="mailto:pub@towardsai.net" rel="noopener ugc nofollow" target="_blank"><em class="na"/></a><em class="na">。</em></p><p id="05a1" class="pw-post-body-paragraph ld le jf lf b lg lh kp li lj lk ks ll lm ln lo lp lq lr ls lt lu lv lw lx ly im bi translated"><strong class="lf jp">免责声明:</strong>本文所表达的观点均为作者个人观点，不代表与作者(直接或间接)相关的任何公司的观点。这项工作并不打算成为最终产品，而是当前思想的反映，同时也是讨论和改进的催化剂。</p><p id="0ecf" class="pw-post-body-paragraph ld le jf lf b lg lh kp li lj lk ks ll lm ln lo lp lq lr ls lt lu lv lw lx ly im bi translated"><strong class="lf jp">除非另有说明，所有图片均来自作者。</strong></p><p id="913d" class="pw-post-body-paragraph ld le jf lf b lg lh kp li lj lk ks ll lm ln lo lp lq lr ls lt lu lv lw lx ly im bi translated">经由<a class="ae jc" href="https://towardsai.net/" rel="noopener ugc nofollow" target="_blank">发布<strong class="lf jp">走向艾</strong> </a></p><h1 id="9311" class="ne nf jf bd ng nh ni nj nk nl nm nn no ku np kv nq kx nr ky ns la nt lb nu nv bi translated">资源</h1><div class="is it gp gr iu lz"><a href="https://colab.research.google.com/drive/1FU2P9XDqdX5jB3PR7P6CYLKcUzSK_yl-?usp=sharing" rel="noopener  ugc nofollow" target="_blank"><div class="ma ab fo"><div class="mb ab mc cl cj md"><h2 class="bd jp gy z fp me fr fs mf fu fw jo bi translated">什么是GPU？—谷歌联合实验室</h2><div class="mh l"><p class="bd b dl z fp me fr fs mf fu fw dk translated">colab.research.google.com</p></div></div><div class="mi l"><div class="pn l mk ml mm mi mn iw lz"/></div></div></a></div><div class="is it gp gr iu lz"><a href="https://github.com/towardsai/tutorials/tree/master/what-is-a-gpu" rel="noopener  ugc nofollow" target="_blank"><div class="ma ab fo"><div class="mb ab mc cl cj md"><h2 class="bd jp gy z fp me fr fs mf fu fw jo bi translated">什么是GPU？|走向人工智能教程</h2><div class="mg l"><h3 class="bd b gy z fp me fr fs mf fu fw dk translated">AI相关教程。免费访问其中任何一个→https://towardsai.net/editorial-toward sai/教程</h3></div><div class="mh l"><p class="bd b dl z fp me fr fs mf fu fw dk translated">github.com</p></div></div><div class="mi l"><div class="po l mk ml mm mi mn iw lz"/></div></div></a></div><div class="is it gp gr iu lz"><a rel="noopener  ugc nofollow" target="_blank" href="/best-laptops-for-machine-learning-deep-learning-data-science-ml-f55602197593"><div class="ma ab fo"><div class="mb ab mc cl cj md"><h2 class="bd jp gy z fp me fr fs mf fu fw jo bi translated">用于深度学习、机器学习和数据科学的最佳笔记本电脑</h2><div class="mg l"><h3 class="bd b gy z fp me fr fs mf fu fw dk translated">适合各种预算的机器学习、数据科学和深度学习的最佳笔记本电脑—编辑推荐</h3></div><div class="mh l"><p class="bd b dl z fp me fr fs mf fu fw dk translated">pub.towardsai.net</p></div></div><div class="mi l"><div class="pp l mk ml mm mi mn iw lz"/></div></div></a></div><div class="is it gp gr iu lz"><a href="https://amzn.to/2PMJLda" rel="noopener  ugc nofollow" target="_blank"><div class="ma ab fo"><div class="mb ab mc cl cj md"><h2 class="bd jp gy z fp me fr fs mf fu fw jo bi translated">使用Python进行深度学习</h2><div class="mg l"><h3 class="bd b gy z fp me fr fs mf fu fw dk translated">用Python [Chollet，Fran ois]对Amazon.com进行深度学习。*符合条件的优惠可享受免费*运输。深度学习与…</h3></div><div class="mh l"><p class="bd b dl z fp me fr fs mf fu fw dk translated">Amazon.com</p></div></div><div class="mi l"><div class="pq l mk ml mm mi mn iw lz"/></div></div></a></div><div class="is it gp gr iu lz"><a href="https://amzn.to/3etZlVk" rel="noopener  ugc nofollow" target="_blank"><div class="ma ab fo"><div class="mb ab mc cl cj md"><h2 class="bd jp gy z fp me fr fs mf fu fw jo bi translated">深度神经网络的有效处理(计算机体系结构综合讲座)</h2><div class="mg l"><h3 class="bd b gy z fp me fr fs mf fu fw dk translated">深度神经网络的高效处理(计算机体系结构综合讲座)</h3></div><div class="mh l"><p class="bd b dl z fp me fr fs mf fu fw dk translated">amzon.com</p></div></div><div class="mi l"><div class="pr l mk ml mm mi mn iw lz"/></div></div></a></div><div class="is it gp gr iu lz"><a href="https://lambdalabs.com/blog/choosing-a-gpu-for-deep-learning/" rel="noopener  ugc nofollow" target="_blank"><div class="ma ab fo"><div class="mb ab mc cl cj md"><h2 class="bd jp gy z fp me fr fs mf fu fw jo bi translated">2020年选择深度学习的最佳GPU</h2><div class="mg l"><h3 class="bd b gy z fp me fr fs mf fu fw dk translated">最先进的(SOTA)深度学习模型有大量的内存足迹。许多GPU没有足够的VRAM来训练…</h3></div><div class="mh l"><p class="bd b dl z fp me fr fs mf fu fw dk translated">lambdalabs.com</p></div></div><div class="mi l"><div class="ps l mk ml mm mi mn iw lz"/></div></div></a></div><p id="8d37" class="pw-post-body-paragraph ld le jf lf b lg lh kp li lj lk ks ll lm ln lo lp lq lr ls lt lu lv lw lx ly im bi translated">坦巴维塔、Vajira &amp; Ragel、罗山&amp; Elkaduwe、达卡。(2014).使用或不使用:用于模式匹配算法的图形处理单元，<a class="ae jc" href="https://www.researchgate.net/publication/270222593_To_Use_or_Not_to_Use_Graphics_Processing_Units_for_Pattern_Matching_Algorithms" rel="noopener ugc nofollow" target="_blank">https://www . research gate . net/publication/270222593 _ To _ Use _ or _ Not _ To _ Use _ Graphics _ Processing _ Units _ for _ Pattern _ Matching _ Algorithms</a></p><div class="is it gp gr iu lz"><a href="https://forums.developer.nvidia.com/t/why-gpu-has-large-memory-bandwidth-than-cpu/10294" rel="noopener  ugc nofollow" target="_blank"><div class="ma ab fo"><div class="mb ab mc cl cj md"><h2 class="bd jp gy z fp me fr fs mf fu fw jo bi translated">为什么GPU比CPU内存带宽大？</h2><div class="mg l"><h3 class="bd b gy z fp me fr fs mf fu fw dk translated">1、为什么GPU比CPU内存带宽大？高端NVIDIA GPUs拥有更宽的总线和更高的内存…</h3></div><div class="mh l"><p class="bd b dl z fp me fr fs mf fu fw dk translated">forums.developer.nvidia.com</p></div></div><div class="mi l"><div class="pt l mk ml mm mi mn iw lz"/></div></div></a></div><div class="is it gp gr iu lz"><a href="https://www.tensorflow.org/install/source_windows" rel="noopener  ugc nofollow" target="_blank"><div class="ma ab fo"><div class="mb ab mc cl cj md"><h2 class="bd jp gy z fp me fr fs mf fu fw jo bi translated">在Windows | TensorFlow上从源代码构建</h2><div class="mg l"><h3 class="bd b gy z fp me fr fs mf fu fw dk translated">从源代码构建一个TensorFlow pip包，并将其安装在Windows上。我们已经提供了经过充分测试、预先构建的注释…</h3></div><div class="mh l"><p class="bd b dl z fp me fr fs mf fu fw dk translated">www.tensorflow.org</p></div></div><div class="mi l"><div class="pu l mk ml mm mi mn iw lz"/></div></div></a></div></div><div class="ab cl pg ph hx pi" role="separator"><span class="pj bw bk pk pl pm"/><span class="pj bw bk pk pl pm"/><span class="pj bw bk pk pl"/></div><div class="im in io ip iq"><h1 id="0efa" class="ne nf jf bd ng nh pv nj nk nl pw nn no ku px kv nq kx py ky ns la pz lb nu nv bi translated">参考</h1><p id="6eb3" class="pw-post-body-paragraph ld le jf lf b lg nw kp li lj nx ks ll lm ny lo lp lq nz ls lt lu oa lw lx ly im bi translated">[1]“图形处理单元”。2021.En.Wikipedia.Org。https://en.wikipedia.org/wiki/Graphics_processing_unit.<a class="ae jc" href="https://en.wikipedia.org/wiki/Graphics_processing_unit." rel="noopener ugc nofollow" target="_blank"/></p><p id="0a4b" class="pw-post-body-paragraph ld le jf lf b lg lh kp li lj lk ks ll lm ln lo lp lq lr ls lt lu lv lw lx ly im bi translated">[2]“什么是GPU？图形处理单元定义”。2021.英特尔。<a class="ae jc" href="https://www.intel.com/content/www/us/en/products/docs/processors/what-is-a-gpu.html." rel="noopener ugc nofollow" target="_blank">https://www . Intel . com/content/www/us/en/products/docs/processors/what-is-a-GPU . html</a></p><p id="4276" class="pw-post-body-paragraph ld le jf lf b lg lh kp li lj lk ks ll lm ln lo lp lq lr ls lt lu lv lw lx ly im bi translated">[3]“神经网络从零开始，详细介绍Python代码和数学— I”。2021.走向AI。https://pub . toward sai . net/building-neural-networks-from-scratch-with-python-code-and-math-in-detail-I-536 FAE 5d 7 bbf。</p><p id="4696" class="pw-post-body-paragraph ld le jf lf b lg lh kp li lj lk ks ll lm ln lo lp lq lr ls lt lu lv lw lx ly im bi translated">[4]来自维基百科，自由百科，<a class="ae jc" href="https://en.wikipedia.org/wiki/Central_processing_unit" rel="noopener ugc nofollow" target="_blank">https://en.wikipedia.org/wiki/Central_processing_unit</a>。</p><p id="2dc7" class="pw-post-body-paragraph ld le jf lf b lg lh kp li lj lk ks ll lm ln lo lp lq lr ls lt lu lv lw lx ly im bi translated">[5]“什么是DPU？|英伟达博客”。2020.NVIDIA官方博客。<a class="ae jc" href="https://blogs.nvidia.com/blog/2020/05/20/whats-a-dpu-data-processing-unit/." rel="noopener ugc nofollow" target="_blank">https://blogs . NVIDIA . com/blog/2020/05/20/whats-a-dpu-data-processing-unit/。</a></p><p id="ed79" class="pw-post-body-paragraph ld le jf lf b lg lh kp li lj lk ks ll lm ln lo lp lq lr ls lt lu lv lw lx ly im bi translated">[6]“CPU Vs GPU:有什么区别？”。2009.NVIDIA官方博客。<a class="ae jc" href="https://blogs.nvidia.com/blog/2009/12/16/whats-the-difference-between-a-cpu-and-a-gpu/." rel="noopener ugc nofollow" target="_blank">https://blogs . NVIDIA . com/blog/2009/12/16/a-CPU和-a-gpu之间有什么区别/</a></p><p id="56cd" class="pw-post-body-paragraph ld le jf lf b lg lh kp li lj lk ks ll lm ln lo lp lq lr ls lt lu lv lw lx ly im bi translated">[7]《苹果开发者文档》。2021.Developer.Apple.Com。<a class="ae jc" href="https://developer.apple.com/documentation/metal/gpu_selection_in_macos/understanding_gpu_bandwidth." rel="noopener ugc nofollow" target="_blank">https://developer . apple . com/documentation/metal/GPU _ selection _ in _ MAC OS/understanding _ GPU _ bandwidth。</a></p><p id="b2f5" class="pw-post-body-paragraph ld le jf lf b lg lh kp li lj lk ks ll lm ln lo lp lq lr ls lt lu lv lw lx ly im bi translated">[8]《py torch》。2021.En.Wikipedia.Org。https://en.wikipedia.org/wiki/PyTorch.<a class="ae jc" href="https://en.wikipedia.org/wiki/PyTorch." rel="noopener ugc nofollow" target="_blank"/></p><p id="40ad" class="pw-post-body-paragraph ld le jf lf b lg lh kp li lj lk ks ll lm ln lo lp lq lr ls lt lu lv lw lx ly im bi translated">[9]来自维基百科，自由百科，【https://en.wikipedia.org/wiki/Memory_bandwidth】T4。</p><p id="d6e3" class="pw-post-body-paragraph ld le jf lf b lg lh kp li lj lk ks ll lm ln lo lp lq lr ls lt lu lv lw lx ly im bi translated">[10]来自维基百科，免费的百科全书，<a class="ae jc" href="https://en.wikipedia.org/wiki/TensorFlow" rel="noopener ugc nofollow" target="_blank">https://en.wikipedia.org/wiki/TensorFlow</a></p><p id="9944" class="pw-post-body-paragraph ld le jf lf b lg lh kp li lj lk ks ll lm ln lo lp lq lr ls lt lu lv lw lx ly im bi translated">[11]来自维基百科，免费的百科全书，<a class="ae jc" href="https://en.wikipedia.org/wiki/Keras" rel="noopener ugc nofollow" target="_blank">https://en.wikipedia.org/wiki/Keras</a></p><p id="8e4c" class="pw-post-body-paragraph ld le jf lf b lg lh kp li lj lk ks ll lm ln lo lp lq lr ls lt lu lv lw lx ly im bi translated">[12]《算法语录(46条语录)》。2021.Goodreads.Com。<a class="ae jc" href="https://www.goodreads.com/quotes/tag/algorithms." rel="noopener ugc nofollow" target="_blank">https://www.goodreads.com/quotes/tag/algorithms.</a></p><p id="3084" class="pw-post-body-paragraph ld le jf lf b lg lh kp li lj lk ks ll lm ln lo lp lq lr ls lt lu lv lw lx ly im bi translated">[13]张量流，什么。2018.“什么是Tensorflow的XLA_GPU和XLA_CPU”。堆栈溢出。<a class="ae jc" href="https://stackoverflow.com/questions/52943489/what-is-xla-gpu-and-xla-cpu-for-tensorflow." rel="noopener ugc nofollow" target="_blank">https://stack overflow . com/questions/52943489/what-is-xla-GPU-and-xla-CPU-for-tensor flow。</a></p></div><div class="ab cl pg ph hx pi" role="separator"><span class="pj bw bk pk pl pm"/><span class="pj bw bk pk pl pm"/><span class="pj bw bk pk pl"/></div><div class="im in io ip iq"><p id="df3b" class="pw-post-body-paragraph ld le jf lf b lg lh kp li lj lk ks ll lm ln lo lp lq lr ls lt lu lv lw lx ly im bi translated"><strong class="lf jp">元数据:</strong>{什么是GPU } {什么是GPU } {深度学习需要GPU吗？} {GPU和深度学习} { GPU与CPU } {并行} {并行计算} {图形处理单元} {图形处理单元讲解}</p></div></div>    
</body>
</html>