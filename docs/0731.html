<html>
<head>
<title>Google Stock prediction using Multivariate LSTM Neural Network</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">基于多元LSTM神经网络的谷歌股票预测</h1>
<blockquote>原文：<a href="https://pub.towardsai.net/google-stock-prediction-using-multivariate-lstm-11278d22a78b?source=collection_archive---------3-----------------------#2020-07-27">https://pub.towardsai.net/google-stock-prediction-using-multivariate-lstm-11278d22a78b?source=collection_archive---------3-----------------------#2020-07-27</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><h2 id="3762" class="ir is it bd b dl iu iv iw ix iy iz dk ja translated" aria-label="kicker paragraph"><a class="ae ep" href="https://towardsai.net/p/category/machine-learning/deep-learning" rel="noopener ugc nofollow" target="_blank">深度学习</a></h2><div class=""/><div class=""><h2 id="8f26" class="pw-subtitle-paragraph jz jc it bd b ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq dk translated">使用堆叠LSTM预测谷歌股票价格。完整的代码<a class="ae kr" href="https://github.com/arditoibryan/Projects/tree/master/20200727_GOOG_Stock_Forecasts_2" rel="noopener ugc nofollow" target="_blank">可在我的Github回购。</a></h2></div><p id="9985" class="pw-post-body-paragraph ks kt it ku b kv kw kd kx ky kz kg la lb lc ld le lf lg lh li lj lk ll lm ln im bi translated">不久前<a class="ae kr" href="https://medium.com/towards-artificial-intelligence/google-stock-predictions-using-an-lstm-neural-network-dbe785949a96" rel="noopener">我发表了一篇类似的文章</a>，讲述如何使用LSTMs通过一个普通的神经网络进行股票预测。因为我想最小化问题的复杂性，所以我使用了单一品种模型。今天我将利用一个多元模型来训练我的人工智能。它会更复杂，但会开始变得更现实。我将使用的结构几乎与上一篇文章中的结构相同，唯一的区别是这一个将能够包含多个变量(GOOG价格和GDP)。</p><p id="d3f8" class="pw-post-body-paragraph ks kt it ku b kv kw kd kx ky kz kg la lb lc ld le lf lg lh li lj lk ll lm ln im bi translated"><strong class="ku jd">* * *免责声明</strong>:尽管看起来令人兴奋，但这是一个财务分析模型的低分辨率模拟。现实世界的模型要复杂得多，需要多变量数据，并且不限于单个人工智能，而是一组人工智能一起工作。因此，只使用这个模型来训练建立神经网络:不要试图在真实交易中使用它，因为它不复杂，所以缺乏可靠性。</p><figure class="lp lq lr ls gt lt gh gi paragraph-image"><div role="button" tabindex="0" class="lu lv di lw bf lx"><div class="gh gi lo"><img src="../Images/8d4df0eda8b85e576a3d6b7a56b0db31.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*iwUYQF04-Ewf6B0uB1dOkA.png"/></div></div><figcaption class="ma mb gj gh gi mc md bd b be z dk translated">决赛成绩</figcaption></figure><h1 id="f2b9" class="me mf it bd mg mh mi mj mk ml mm mn mo ki mp kj mq kl mr km ms ko mt kp mu mv bi translated">整个过程</h1><p id="2189" class="pw-post-body-paragraph ks kt it ku b kv mw kd kx ky mx kg la lb my ld le lf mz lh li lj na ll lm ln im bi translated">像往常一样，我将使用我的个人图形笔记作为指南，指导您如何进行。上面的方案很好地总结了创建用于时间序列预测的堆叠多元LSTM神经网络的整个过程。</p><figure class="lp lq lr ls gt lt gh gi paragraph-image"><div role="button" tabindex="0" class="lu lv di lw bf lx"><div class="gh gi nb"><img src="../Images/c6ee1a44d77d1c7bbe72f6a4095b50be.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*WFY6Wp6GED1zpEbF.png"/></div></div><figcaption class="ma mb gj gh gi mc md bd b be z dk translated">建立LSTM</figcaption></figure><h1 id="2d57" class="me mf it bd mg mh mi mj mk ml mm mn mo ki mp kj mq kl mr km ms ko mt kp mu mv bi translated">流程中的步骤:</h1><ol class=""><li id="83e2" class="nc nd it ku b kv mw ky mx lb ne lf nf lj ng ln nh ni nj nk bi translated">导入模块</li><li id="6966" class="nc nd it ku b kv nl ky nm lb nn lf no lj np ln nh ni nj nk bi translated">每天产生国内生产总值时间序列</li><li id="47ab" class="nc nd it ku b kv nl ky nm lb nn lf no lj np ln nh ni nj nk bi translated">导入数据帧</li><li id="83c8" class="nc nd it ku b kv nl ky nm lb nn lf no lj np ln nh ni nj nk bi translated">数据帧预处理</li><li id="2473" class="nc nd it ku b kv nl ky nm lb nn lf no lj np ln nh ni nj nk bi translated">数据帧转换成监督问题</li><li id="e551" class="nc nd it ku b kv nl ky nm lb nn lf no lj np ln nh ni nj nk bi translated">数据帧分为X_train、y_train、X_test、y_test</li><li id="41e9" class="nc nd it ku b kv nl ky nm lb nn lf no lj np ln nh ni nj nk bi translated">将输入整形为[样本，n _输入_时间步长，n _特征]</li><li id="4df2" class="nc nd it ku b kv nl ky nm lb nn lf no lj np ln nh ni nj nk bi translated">创建LSTM模式</li><li id="719d" class="nc nd it ku b kv nl ky nm lb nn lf no lj np ln nh ni nj nk bi translated">使用X_train，y_train拟合模型</li><li id="c737" class="nc nd it ku b kv nl ky nm lb nn lf no lj np ln nh ni nj nk bi translated">对前进的每一步进行评估</li><li id="5648" class="nc nd it ku b kv nl ky nm lb nn lf no lj np ln nh ni nj nk bi translated">对输出进行反向预处理</li><li id="d630" class="nc nd it ku b kv nl ky nm lb nn lf no lj np ln nh ni nj nk bi translated">比较预测和估计</li></ol><h1 id="ead3" class="me mf it bd mg mh mi mj mk ml mm mn mo ki mp kj mq kl mr km ms ko mt kp mu mv bi translated">进口GOOG股票</h1><pre class="lp lq lr ls gt nq nr ns nt aw nu bi"><span id="5994" class="nv mf it nr b gy nw nx l ny nz"># load dataset<br/>import pandas as pd<br/>X = pd.read_csv('/content/drive/My Drive/Colab Notebooks/Projects/20200525_GOOG_Multivariate_LSTM/GOOG.csv')</span><span id="b025" class="nv mf it nr b gy oa nx l ny nz">#original copy without preprocessing<br/>X = X.drop(['High', 'Low', 'Close', 'Adj Close', 'Volume'], axis=1)<br/>index = X.pop('Date')<br/>X</span></pre><p id="e4c8" class="pw-post-body-paragraph ks kt it ku b kv kw kd kx ky kz kg la lb lc ld le lf lg lh li lj lk ll lm ln im bi translated">为了您的方便，我已经将谷歌股票(GOOG)1年的股票表现保存在一个. csv文件中，您可以在这里下载。因为我用的是Google Colab，所以会从我的个人硬盘加载。您可以下载。csv并从自己的路径导入。</p><h1 id="65f0" class="me mf it bd mg mh mi mj mk ml mm mn mo ki mp kj mq kl mr km ms ko mt kp mu mv bi translated">每天产生GDP</h1><p id="3e2c" class="pw-post-body-paragraph ks kt it ku b kv mw kd kx ky mx kg la lb my ld le lf mz lh li lj na ll lm ln im bi translated">GDP每年发布4次，每季度一次。因为我不想立即从一个值跳到另一个值，所以我想计算一年中每一天的GDP变化，这样我就可以使它适应Google股票数据。这两个时间序列需要标准化，在这种情况下，它们需要不间断地显示一年中每天的数据。</p><pre class="lp lq lr ls gt nq nr ns nt aw nu bi"><span id="db17" class="nv mf it nr b gy nw nx l ny nz">#GDP interpolation<br/>import matplotlib.pyplot as plt</span><span id="8ab6" class="nv mf it nr b gy oa nx l ny nz">y = [20897804, 21098827, 21340267, 21542540, 21729124, 21537940, 21537940]<br/>x = [int((365/4)*0), int((365/4)*1), int((365/4)*2), int((365/4)*3), int((365/4)*4), int((365/4)*5), int((365/4)*6)]</span><span id="aa89" class="nv mf it nr b gy oa nx l ny nz">plt.plot(x, y, ‘o’)<br/>x</span></pre><p id="0152" class="pw-post-body-paragraph ks kt it ku b kv kw kd kx ky kz kg la lb lc ld le lf lg lh li lj lk ll lm ln im bi translated">因为我只有GDP的值，但是我不能使用日期，因为与Google股票不兼容，所以我选择使用从0开始的天数。实际上，在第0天，GDP是20，897，804，在第91天，GDP是21，098，827…</p><figure class="lp lq lr ls gt lt gh gi paragraph-image"><div class="gh gi ob"><img src="../Images/2bb13a137aeacc7574fabc9e14a9754b.png" data-original-src="https://miro.medium.com/v2/resize:fit:950/format:webp/1*cLiIlymU_oWwQqO3f4VxEA.png"/></div></figure><h2 id="2070" class="nv mf it bd mg oc od dn mk oe of dp mo lb og oh mq lf oi oj ms lj ok ol mu iz bi translated">插入文字</h2><p id="07ab" class="pw-post-body-paragraph ks kt it ku b kv mw kd kx ky mx kg la lb my ld le lf mz lh li lj na ll lm ln im bi translated">我创建了一个表格，包含了从政府网站上获得的所有GDP值。我将利用这7个季度来创建一个时间序列。</p><pre class="lp lq lr ls gt nq nr ns nt aw nu bi"><span id="3894" class="nv mf it nr b gy nw nx l ny nz">from scipy.interpolate import interp1d<br/>import numpy as np</span><span id="3428" class="nv mf it nr b gy oa nx l ny nz">f = interp1d(x, y, kind='cubic')<br/>plt.plot(f(x))</span></pre><figure class="lp lq lr ls gt lt gh gi paragraph-image"><div class="gh gi om"><img src="../Images/0d6dabb77408e8a39a7156a5d85c3077.png" data-original-src="https://miro.medium.com/v2/resize:fit:936/format:webp/1*-dZZLXlacEjHWfGR4QZrGg.png"/></div></figure><h2 id="4a16" class="nv mf it bd mg oc od dn mk oe of dp mo lb og oh mq lf oi oj ms lj ok ol mu iz bi translated">使GDP函数适应一年中的每一天</h2><p id="3f05" class="pw-post-body-paragraph ks kt it ku b kv mw kd kx ky mx kg la lb my ld le lf mz lh li lj na ll lm ln im bi translated">正如您已经注意到的，x轴没有显示正确的日期，而是显示了每个新的GDP输入的计数。我必须使它适应谷歌股票数据集的起始日，这样我就可以同步这两个数据集。</p><pre class="lp lq lr ls gt nq nr ns nt aw nu bi"><span id="d24f" class="nv mf it nr b gy nw nx l ny nz">list_day = list()<br/>list_GDP = list()<br/>for _ in range(len(index)):<br/>  year = int(index[_][0]+index[_][1]+index[_][2]+index[_][3])<br/>  month = int(index[_][5]+index[_][6])<br/>  day = int(index[_][8]+index[_][9])<br/>  date = datetime.datetime(year, month, day)<br/>  date_add = int(date.strftime('%j'))<br/>  history_day = date_add+((year-2019)*365)<br/>  list_day.append(history_day)<br/>  list_GDP.append(f(history_day))</span><span id="1ba3" class="nv mf it nr b gy oa nx l ny nz">plt.plot(list_day, list_GDP, 'o', linewidth=1, markersize=2)</span></pre><figure class="lp lq lr ls gt lt gh gi paragraph-image"><div class="gh gi on"><img src="../Images/af5976a687fa8f6151eca0231e6418ed.png" data-original-src="https://miro.medium.com/v2/resize:fit:932/format:webp/1*CMx9ExwRXLHPub3LJkA2-Q.png"/></div><figcaption class="ma mb gj gh gi mc md bd b be z dk translated">国内生产总值的完全内插法:得出每天的国内生产总值</figcaption></figure><h2 id="300e" class="nv mf it bd mg oc od dn mk oe of dp mo lb og oh mq lf oi oj ms lj ok ol mu iz bi translated">合并数据集</h2><pre class="lp lq lr ls gt nq nr ns nt aw nu bi"><span id="cec2" class="nv mf it nr b gy nw nx l ny nz">list_GDP = pd.DataFrame(list_GDP)<br/>list_GDP.columns = ['GDP']<br/>list_GDP</span></pre><figure class="lp lq lr ls gt lt gh gi paragraph-image"><div class="gh gi oo"><img src="../Images/eb20f5b08616b5bd0d5e7c216072837c.png" data-original-src="https://miro.medium.com/v2/resize:fit:382/format:webp/1*zB7HU6zLff1Xl6JUdBuqZQ.png"/></div><figcaption class="ma mb gj gh gi mc md bd b be z dk translated">我刚刚创建的数据框架的概述</figcaption></figure><pre class="lp lq lr ls gt nq nr ns nt aw nu bi"><span id="7be9" class="nv mf it nr b gy nw nx l ny nz">#merge Google Stock with GDP<br/>X = pd.concat([X, list_GDP], axis=1)<br/>X</span></pre><figure class="lp lq lr ls gt lt gh gi paragraph-image"><div class="gh gi op"><img src="../Images/3e919e507bef1f00a306071aff59d036.png" data-original-src="https://miro.medium.com/v2/resize:fit:626/format:webp/1*RUYhVSB3PDfKgw7nN7R5Yw.png"/></div><figcaption class="ma mb gj gh gi mc md bd b be z dk translated">股票价格和国内生产总值</figcaption></figure><p id="2ad7" class="pw-post-body-paragraph ks kt it ku b kv kw kd kx ky kz kg la lb lc ld le lf lg lh li lj lk ll lm ln im bi translated">现在数据集有了相应的日期，我终于可以把它们一个接一个地放在一起了。我将使用GDP值作为谷歌股票数据的预测值。与前一篇文章相比，该时间序列不会试图仅根据以前的数据来预测自己，但它也会使用GDP值。</p><h1 id="2c51" class="me mf it bd mg mh mi mj mk ml mm mn mo ki mp kj mq kl mr km ms ko mt kp mu mv bi translated">设置功能</h1><p id="2113" class="pw-post-body-paragraph ks kt it ku b kv mw kd kx ky mx kg la lb my ld le lf mz lh li lj na ll lm ln im bi translated">为了继续设置我的模型，我必须创建自定义函数来处理时间序列。不幸的是，我还没有找到任何属于任何ML库的预制函数。这是处理时间序列会变得激烈的原因之一。</p><pre class="lp lq lr ls gt nq nr ns nt aw nu bi"><span id="cfa0" class="nv mf it nr b gy nw nx l ny nz">from sklearn import preprocessing<br/>import numpy as np</span></pre><h2 id="6583" class="nv mf it bd mg oc od dn mk oe of dp mo lb og oh mq lf oi oj ms lj ok ol mu iz bi translated"><strong class="ak">滞后</strong></h2><p id="dbf6" class="pw-post-body-paragraph ks kt it ku b kv mw kd kx ky mx kg la lb my ld le lf mz lh li lj na ll lm ln im bi translated">这大概是这个预处理的核心功能。它将创建许多列，给原始值增加一个滞后。神经网络将考虑预测日期之前的短期值，以估计未来的一个或多个步骤。</p><pre class="lp lq lr ls gt nq nr ns nt aw nu bi"><span id="e1bf" class="nv mf it nr b gy nw nx l ny nz">#convert series to supervised learning<br/>def series_to_supervised(data, n_in=1, n_out=1, dropnan=True, drop_col=False, y_var=1):<br/>  n_features = int(len(data.columns))<br/>  n_vars = 1 if type(data) is list else data.shape[1]<br/>  df = pd.DataFrame(data)<br/>  cols, names = list(), list()<br/>  # input sequence (t-n, ... t-1)<br/>  for i in range(n_in, 0, -1):<br/>    cols.append(df.shift(i))<br/>    names += [('var%d(t-%d)' % (j+1, i)) for j in range(n_vars)]<br/>  # forecast sequence (t, t+1, ... t+n)<br/>  for i in range(0, n_out):<br/>    cols.append(df.shift(-i))<br/>    if i == 0:<br/>      names += [('var%d(t)' % (j+1)) for j in range(n_vars)]<br/>    else:<br/>      names += [('var%d(t+%d)' % (j+1, i)) for j in range(n_vars)]<br/>  #put it all together<br/>  agg = pd.concat(cols, axis=1)<br/>  agg.columns = names<br/>  # drop rows with NaN values<br/>  if dropnan:<br/>    agg.dropna(inplace=True)<br/>    data = agg.copy()<br/>    <br/>  if drop_col == True:<br/>    tot = n_features*n_in+n_features #24+8 = 32</span><span id="f5c3" class="nv mf it nr b gy oa nx l ny nz">y_name = list(data.columns)[n_features*n_in-1 + y_var]<br/>    y = data[y_name]<br/>    for i in range(n_features*n_in, tot):<br/>      data.drop(data.columns[[tot-n_features]], axis=1, inplace=True)<br/>    data = pd.concat([data, y], axis=1)<br/>  return data</span></pre><h2 id="04f4" class="nv mf it bd mg oc od dn mk oe of dp mo lb og oh mq lf oi oj ms lj ok ol mu iz bi translated">剧烈的</h2><pre class="lp lq lr ls gt nq nr ns nt aw nu bi"><span id="e3ec" class="nv mf it nr b gy nw nx l ny nz">def split(df, test_size):<br/>  df = df.values<br/>  len_df = df.shape[0]<br/>  test_size = int(len_df*test_size)<br/>  train, test = df[0:-test_size], df[-test_size:]<br/>  return train, test</span></pre><h2 id="04cb" class="nv mf it bd mg oc od dn mk oe of dp mo lb og oh mq lf oi oj ms lj ok ol mu iz bi translated">静止的</h2><p id="0e39" class="pw-post-body-paragraph ks kt it ku b kv mw kd kx ky mx kg la lb my ld le lf mz lh li lj na ll lm ln im bi translated">原始数据不是静态的。我将使用这个函数将数据转换成平稳的时间序列，然后我将不得不用一个相反的函数来逆转这个效果。</p><pre class="lp lq lr ls gt nq nr ns nt aw nu bi"><span id="13d5" class="nv mf it nr b gy nw nx l ny nz">def transform_to_stationary(df):<br/>  #create a differenced series<br/>  def difference(dataset, interval=1):<br/>    diff = list()<br/>    for i in range(interval, len(dataset)):<br/>      value = dataset[i] - dataset[i - interval]<br/>      diff.append(value)<br/>    return pd.DataFrame(diff)<br/>  <br/>  df = df.values #al di fuori delle funzioni voglio operare solo su un DataFrame<br/>  df = difference(df, 1) #X ritorna ad essere un df<br/>  return df</span></pre><h1 id="94b1" class="me mf it bd mg mh mi mj mk ml mm mn mo ki mp kj mq kl mr km ms ko mt kp mu mv bi translated">预处理</h1><p id="983a" class="pw-post-body-paragraph ks kt it ku b kv mw kd kx ky mx kg la lb my ld le lf mz lh li lj na ll lm ln im bi translated">我需要我将要创建的分区的两个副本。将只对原始副本进行规范化，而第二个副本将先进行规范化，然后进行标准化。保留两个副本的原因是，我需要将输出重新转换为初始比例。到时候我会解释详细的程序。</p><h2 id="4168" class="nv mf it bd mg oc od dn mk oe of dp mo lb og oh mq lf oi oj ms lj ok ol mu iz bi translated">仅标准化</h2><pre class="lp lq lr ls gt nq nr ns nt aw nu bi"><span id="dbb0" class="nv mf it nr b gy nw nx l ny nz">#original copy<br/>X = K.copy()</span><span id="7c25" class="nv mf it nr b gy oa nx l ny nz">input = 3<br/>X = series_to_supervised(X, input, 1, drop_col=False)<br/>X</span><span id="0109" class="nv mf it nr b gy oa nx l ny nz">#X, y<br/>y = X.pop('var1(t)')<br/>X = X.drop(['var2(t)'], axis=1)</span><span id="e687" class="nv mf it nr b gy oa nx l ny nz">#scaling<br/>scaler_1 = preprocessing.MinMaxScaler(feature_range=(0, 1))<br/>X = pd.DataFrame(scaler_1.fit_transform(X))<br/>X<br/>scaler_1 = preprocessing.MinMaxScaler(feature_range=(0, 1))<br/>y = pd.DataFrame(scaler_1.fit_transform(pd.DataFrame(y)))<br/>y</span><span id="4bc3" class="nv mf it nr b gy oa nx l ny nz">#train, test<br/>X_train_, X_test_ = split(X, 0.1)<br/>y_train_, y_test_ = split(y, 0.1)<br/>X_ = X.copy()<br/>y_ = y.copy()<br/>print(X_train_.shape, X_test_.shape, y_train_.shape, y_test_.shape)</span></pre><p id="ca53" class="pw-post-body-paragraph ks kt it ku b kv kw kd kx ky kz kg la lb lc ld le lf lg lh li lj lk ll lm ln im bi translated">如您所见，我存储的所有变量都有一个_作为后缀，以区别于其他变量。</p><pre class="lp lq lr ls gt nq nr ns nt aw nu bi"><span id="8694" class="nv mf it nr b gy nw nx l ny nz">import matplotlib.pyplot as plt</span><span id="0b4a" class="nv mf it nr b gy oa nx l ny nz">fig=plt.figure(figsize=(20, 10), dpi= 80)<br/>fig=plt.plot(y_)</span></pre><figure class="lp lq lr ls gt lt gh gi paragraph-image"><div role="button" tabindex="0" class="lu lv di lw bf lx"><div class="gh gi oq"><img src="../Images/c8e72034f6c59b35682309e695eda7d3.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*rKr_s2DQKNyvH79QcDtWEw.png"/></div></div><figcaption class="ma mb gj gh gi mc md bd b be z dk translated">每次谷歌价格</figcaption></figure><h2 id="2e72" class="nv mf it bd mg oc od dn mk oe of dp mo lb og oh mq lf oi oj ms lj ok ol mu iz bi translated">规范化+标准化</h2><pre class="lp lq lr ls gt nq nr ns nt aw nu bi"><span id="6bd1" class="nv mf it nr b gy nw nx l ny nz">#only scaling<br/>X = K.copy()</span><span id="dae2" class="nv mf it nr b gy oa nx l ny nz">#preprocessing<br/>X = transform_to_stationary(X)</span><span id="28c9" class="nv mf it nr b gy oa nx l ny nz">X = series_to_supervised(X, input, 1, drop_col=False)<br/>X</span><span id="9e14" class="nv mf it nr b gy oa nx l ny nz">#X, y<br/>y = X.pop('var1(t)')<br/>X = X.drop(['var2(t)'], axis=1)</span></pre><h2 id="20c4" class="nv mf it bd mg oc od dn mk oe of dp mo lb og oh mq lf oi oj ms lj ok ol mu iz bi translated">数据帧转换成监督问题</h2><p id="a877" class="pw-post-body-paragraph ks kt it ku b kv mw kd kx ky mx kg la lb my ld le lf mz lh li lj na ll lm ln im bi translated">在预处理过程中，我隔离了数据集e.y和e.X。如果您在分割之前查看这两个数据集，我们最终得到的结果基本上是这样的:</p><ul class=""><li id="0d72" class="nc nd it ku b kv kw ky kz lb or lf os lj ot ln ou ni nj nk bi translated">投入</li></ul><pre class="lp lq lr ls gt nq nr ns nt aw nu bi"><span id="5ae1" class="nv mf it nr b gy nw nx l ny nz">X</span></pre><figure class="lp lq lr ls gt lt gh gi paragraph-image"><div class="gh gi ov"><img src="../Images/c8d78e0a496dae49cdf17d1a09748ee8.png" data-original-src="https://miro.medium.com/v2/resize:fit:1216/format:webp/1*TR9FGVopKjw09ZQYQwgeHw.png"/></div></figure><p id="f2bd" class="pw-post-body-paragraph ks kt it ku b kv kw kd kx ky kz kg la lb lc ld le lf lg lh li lj lk ll lm ln im bi translated">我只取了时间为0的股票数据集，并将其移动了三次，将每次移动存储在GDP和GOOG价格的不同列中，从而得到了上图。这叫做<strong class="ku jd">滞后</strong>。LSTM将向后看三步，做出一步的未来预测。</p><ul class=""><li id="5b38" class="nc nd it ku b kv kw ky kz lb or lf os lj ot ln ou ni nj nk bi translated">输出</li></ul><pre class="lp lq lr ls gt nq nr ns nt aw nu bi"><span id="ef10" class="nv mf it nr b gy nw nx l ny nz">y</span></pre><figure class="lp lq lr ls gt lt gh gi paragraph-image"><div class="gh gi ow"><img src="../Images/4d3be150060fb696aea6b74ff71c467b.png" data-original-src="https://miro.medium.com/v2/resize:fit:310/format:webp/1*kIXOv_1j6Z2ozYyexysytg.png"/></div></figure><p id="3abc" class="pw-post-body-paragraph ks kt it ku b kv kw kd kx ky kz kg la lb lc ld le lf lg lh li lj lk ll lm ln im bi translated">我将用这些标签来训练LSTM。在这种情况下，我希望LSTM只着眼于未来的一步，因此只有一列。</p><h2 id="4169" class="nv mf it bd mg oc od dn mk oe of dp mo lb og oh mq lf oi oj ms lj ok ol mu iz bi translated">缩放和拆分</h2><pre class="lp lq lr ls gt nq nr ns nt aw nu bi"><span id="df43" class="nv mf it nr b gy nw nx l ny nz">#scaling<br/>scaler_2 = preprocessing.MinMaxScaler(feature_range=(0, 1))<br/>X = pd.DataFrame(scaler_2.fit_transform(X))<br/>X<br/>scaler_2 = preprocessing.MinMaxScaler(feature_range=(0, 1))<br/>y = pd.DataFrame(scaler_2.fit_transform(pd.DataFrame(y)))<br/>y</span><span id="777c" class="nv mf it nr b gy oa nx l ny nz">#train, test<br/>X_train, X_test = split(X, 0.1)<br/>y_train, y_test = split(y, 0.1)<br/>X = X.copy()<br/>y = y.copy()<br/>print(X_train.shape, X_test.shape, y_train.shape, y_test.shape)</span></pre><p id="1d3c" class="pw-post-body-paragraph ks kt it ku b kv kw kd kx ky kz kg la lb lc ld le lf lg lh li lj lk ll lm ln im bi translated">与前面的代码块不同，上面的所有变量都以no _作为后缀。我实际上不需要保存所有这些副本。实际上，这些代码中的大部分并不是真正必要的，但是对我来说解释起来会更容易。我将保留一个规范化的副本(在每个变量的末尾用_定义)和整个df的一个规范化+标准化的副本。</p><pre class="lp lq lr ls gt nq nr ns nt aw nu bi"><span id="e173" class="nv mf it nr b gy nw nx l ny nz">import matplotlib.pyplot as plt</span><span id="1272" class="nv mf it nr b gy oa nx l ny nz">fig=plt.figure(figsize=(20, 10), dpi= 80)<br/>fig=plt.plot(y)</span></pre><figure class="lp lq lr ls gt lt gh gi paragraph-image"><div role="button" tabindex="0" class="lu lv di lw bf lx"><div class="gh gi ox"><img src="../Images/4e017bacaef8fb9f2e069dc9884ac715.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*4stYIIg0VCcUpAUFrupYwA.png"/></div></div><figcaption class="ma mb gj gh gi mc md bd b be z dk translated">静态数据集的可视化</figcaption></figure><pre class="lp lq lr ls gt nq nr ns nt aw nu bi"><span id="9fbc" class="nv mf it nr b gy nw nx l ny nz">import matplotlib.pyplot as plt</span><span id="8b4d" class="nv mf it nr b gy oa nx l ny nz">fig=plt.figure(figsize=(20, 10), dpi= 80)<br/>fig=plt.plot(X)</span></pre><figure class="lp lq lr ls gt lt gh gi paragraph-image"><div role="button" tabindex="0" class="lu lv di lw bf lx"><div class="gh gi oy"><img src="../Images/bdf70a9dbd533cb10036fffee78b8c2d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*YSc8kqw0MIA5O1zuTUnn8Q.png"/></div></div><figcaption class="ma mb gj gh gi mc md bd b be z dk translated">GDP和GOOG价格滞后数据集的可视化</figcaption></figure><p id="bf60" class="pw-post-body-paragraph ks kt it ku b kv kw kd kx ky kz kg la lb lc ld le lf lg lh li lj lk ll lm ln im bi translated">正如你在上面的代码中看到的，我将把数据集分成X_train，y_train，X_test，y_test。我将使用训练集来训练我们的AI，X_test来进行预测，y_test(在其预处理被反转后)来进行估计和真实数据之间的比较。</p><h1 id="bac2" class="me mf it bd mg mh mi mj mk ml mm mn mo ki mp kj mq kl mr km ms ko mt kp mu mv bi translated">为LSTM准备投入</h1><p id="66c5" class="pw-post-body-paragraph ks kt it ku b kv mw kd kx ky mx kg la lb my ld le lf mz lh li lj na ll lm ln im bi translated">作为输入，我将使用我们的列var1(t)。因为它的原始形状是(225，6)，所以我需要把它改造成LSTM能理解的形式。</p><pre class="lp lq lr ls gt nq nr ns nt aw nu bi"><span id="7ece" class="nv mf it nr b gy nw nx l ny nz">#reshape [samples, n_input_timesteps, n_features]<br/>X_train = X_train.reshape((225, 6, 1))<br/>y_train = y_train.reshape((225, 1, 1))<br/>print(X_train.shape, y_train.shape)</span><span id="4227" class="nv mf it nr b gy oa nx l ny nz">Output:<br/>(225, 6, 1) (225, 1, 1)</span></pre><p id="0b55" class="pw-post-body-paragraph ks kt it ku b kv kw kd kx ky kz kg la lb lc ld le lf lg lh li lj lk ll lm ln im bi translated">每一个单独的样本，例如，第一行:</p><pre class="lp lq lr ls gt nq nr ns nt aw nu bi"><span id="0a1f" class="nv mf it nr b gy nw nx l ny nz">X_train[0]<br/>...</span></pre><p id="b6bb" class="pw-post-body-paragraph ks kt it ku b kv kw kd kx ky kz kg la lb lc ld le lf lg lh li lj lk ll lm ln im bi translated">将有维度(1，6，1)。</p><h1 id="3add" class="me mf it bd mg mh mi mj mk ml mm mn mo ki mp kj mq kl mr km ms ko mt kp mu mv bi translated">堆叠LSTM</h1><p id="788c" class="pw-post-body-paragraph ks kt it ku b kv mw kd kx ky mx kg la lb my ld le lf mz lh li lj na ll lm ln im bi translated">我终于可以为我们的神经网络创建模型了。我将使用的LSTM被称为堆叠LSTM，两层神经元，是一种适应多变量时间序列预测的神经网络形式:</p><pre class="lp lq lr ls gt nq nr ns nt aw nu bi"><span id="ddbc" class="nv mf it nr b gy nw nx l ny nz">#LSTM<br/>%tensorflow_version 2.x<br/>import tensorflow as tf<br/>from tensorflow.keras import Sequential<br/>from tensorflow.keras.layers import RepeatVector<br/>from tensorflow.keras.layers import TimeDistributed<br/>from tensorflow.keras import layers<br/>from tensorflow.keras.layers import Dense<br/>from tensorflow.keras.layers import LSTM</span><span id="66ac" class="nv mf it nr b gy oa nx l ny nz">model = Sequential()<br/>model.add(LSTM(100, activation='relu', batch_input_shape=(1, 6, 1)))<br/>model.add(RepeatVector(1)) #numero di output<br/>model.add(LSTM(100, activation='relu', return_sequences=True))<br/>model.add(TimeDistributed(Dense(1)))<br/>model.compile(loss='mse', optimizer='adam')<br/>#model.compile(optimizer='adam', loss='mse')</span><span id="3790" class="nv mf it nr b gy oa nx l ny nz">model.fit(X_train, y_train, epochs=3000, batch_size=1, verbose=2, shuffle=False)<br/>model.reset_states()</span><span id="c28f" class="nv mf it nr b gy oa nx l ny nz">X_test = X_test.reshape(24, 6, 1)<br/>y_test = y_test.reshape(24, 1, 1)<br/>print(X_test.shape, y_test.shape)</span><span id="b907" class="nv mf it nr b gy oa nx l ny nz">Output:<br/>...<br/>Epoch 2996/3000<br/>225/225–1s — loss: 0.0004<br/>Epoch 2997/3000<br/>225/225–1s — loss: 0.0005<br/>Epoch 2998/3000<br/>225/225–1s — loss: 0.0001<br/>Epoch 2999/3000<br/>225/225–1s — loss: 0.0002<br/>Epoch 3000/3000<br/>(24, 6, 1) (24, 1, 1)</span></pre><h1 id="8779" class="me mf it bd mg mh mi mj mk ml mm mn mo ki mp kj mq kl mr km ms ko mt kp mu mv bi translated">逆预处理预测</h1><p id="5ab2" class="pw-post-body-paragraph ks kt it ku b kv mw kd kx ky mx kg la lb my ld le lf mz lh li lj na ll lm ln im bi translated">我可以将我们的预测存储在一个名为<strong class="ku jd"> <em class="oz"> yhat </em> </strong>的列表中:</p><pre class="lp lq lr ls gt nq nr ns nt aw nu bi"><span id="b67c" class="nv mf it nr b gy nw nx l ny nz">#make a one-step forecast<br/>yhat = model.predict(X_test, verbose=2, batch_size=1) #SENZA LA BATCH_SIZE, prende un input alla volta, con la batch_size tutto il dataset<br/>print(yhat)</span></pre><p id="7063" class="pw-post-body-paragraph ks kt it ku b kv kw kd kx ky kz kg la lb lc ld le lf lg lh li lj lk ll lm ln im bi translated">不幸的是，如前所述，这种预测将得出相同的输入比例，这已经被标准化，然后缩放。我将不得不颠倒这些过程，以得到一个我实际上可以用来进行比较的数据尺度。</p><figure class="lp lq lr ls gt lt gh gi paragraph-image"><div role="button" tabindex="0" class="lu lv di lw bf lx"><div class="gh gi pa"><img src="../Images/0d18df14554ab9a2c5acfdecb9a250f1.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*ogE_0oUV_CvE0qo2.png"/></div></div></figure><p id="d4b7" class="pw-post-body-paragraph ks kt it ku b kv kw kd kx ky kz kg la lb lc ld le lf lg lh li lj lk ll lm ln im bi translated">为了反演数据，我需要y_test_和我的预测的原始副本。y_test_ it是数据的真实版本，因此我想要获得的比例(例如。1300，现在它的对等数字是. 0009)。因为预测<em class="oz"> yhat </em>已经被标准化，然后被固定化，它们只不过是一个缺口的集合。我会将这些缺口添加到y_test_的规范化版本中。</p><h2 id="a70b" class="nv mf it bd mg oc od dn mk oe of dp mo lb og oh mq lf oi oj ms lj ok ol mu iz bi translated">调节定标器</h2><p id="af1c" class="pw-post-body-paragraph ks kt it ku b kv mw kd kx ky mx kg la lb my ld le lf mz lh li lj na ll lm ln im bi translated">当把我的缩放器应用到yhat时，我需要确保它的大小合适。y_hat只有一列，我无法使用以前应用于多列的缩放器:</p><pre class="lp lq lr ls gt nq nr ns nt aw nu bi"><span id="b300" class="nv mf it nr b gy nw nx l ny nz">#adjust scaler to 1 column<br/>X = K.drop(['GDP'], axis=1)<br/>scaler_3, X = v.partition.scale('all_df', scaler='MinMaxScaler', df=X, to_float=True, return_df=True)</span></pre><h2 id="3928" class="nv mf it bd mg oc od dn mk oe of dp mo lb og oh mq lf oi oj ms lj ok ol mu iz bi translated">逆预处理</h2><pre class="lp lq lr ls gt nq nr ns nt aw nu bi"><span id="4d28" class="nv mf it nr b gy nw nx l ny nz">#2   inverse scaling of the prediction<br/>raw = scaler_3.inverse_transform(yhat[:, :, -1])<br/>raw</span><span id="3290" class="nv mf it nr b gy oa nx l ny nz">#2   inverse scaling of the gaps<br/>#non so perchè prima ho fatto un reshaping, sembra senza ragione<br/>#comunque, ora correggo<br/>y_test = y_test.reshape(X_test.shape[0], 1)<br/>gap = scaler_2.inverse_transform(y_test)<br/>gap #err</span><span id="8bd2" class="nv mf it nr b gy oa nx l ny nz">#2   invert preprocessing on predicted data<br/>#remove stationary<br/>y_test = y_test.reshape(X_test.shape[0], 1)<br/>var1 = raw    #original values<br/>var2 = gap     #gaps<br/>var3 = list()     #</span><span id="a5bd" class="nv mf it nr b gy oa nx l ny nz">#var1 = var1.values<br/>#var2 = var2.values</span><span id="1882" class="nv mf it nr b gy oa nx l ny nz">var3.append(var1[0])<br/>for i in range(0, len(var2)-1):<br/>  values = var1[i] + var2[i+1]<br/>  print('values: ', var1[i], var2[i+1])<br/>  var3.append(values)<br/>var3</span></pre><p id="099c" class="pw-post-body-paragraph ks kt it ku b kv kw kd kx ky kz kg la lb lc ld le lf lg lh li lj lk ll lm ln im bi translated">我将把输出保存为变量<strong class="ku jd">预测的</strong>。</p><pre class="lp lq lr ls gt nq nr ns nt aw nu bi"><span id="26a5" class="nv mf it nr b gy nw nx l ny nz">predicted = var3</span></pre><h1 id="972e" class="me mf it bd mg mh mi mj mk ml mm mn mo ki mp kj mq kl mr km ms ko mt kp mu mv bi translated">预期</h1><p id="42ed" class="pw-post-body-paragraph ks kt it ku b kv mw kd kx ky mx kg la lb my ld le lf mz lh li lj na ll lm ln im bi translated">显示实际发生了什么的标记数据只是被规范化了(这就是为什么它有_作为后缀)。我只需要用我从一开始就保存的<strong class="ku jd">缩放器</strong>将它恢复到正常比例。</p><pre class="lp lq lr ls gt nq nr ns nt aw nu bi"><span id="d70c" class="nv mf it nr b gy nw nx l ny nz">#invert preprocessing on expected data<br/>#inverse scaling<br/>expected = scaler_.inverse_transform(y_test_)<br/>expected</span></pre><h1 id="b6f2" class="me mf it bd mg mh mi mj mk ml mm mn mo ki mp kj mq kl mr km ms ko mt kp mu mv bi translated">比较:预测与预期</h1><p id="ff48" class="pw-post-body-paragraph ks kt it ku b kv mw kd kx ky mx kg la lb my ld le lf mz lh li lj na ll lm ln im bi translated">我准备比较<strong class="ku jd">预测的</strong>和<strong class="ku jd">预期的</strong>值，看看它们有多接近:</p><pre class="lp lq lr ls gt nq nr ns nt aw nu bi"><span id="e13c" class="nv mf it nr b gy nw nx l ny nz">for i in range(len(y_test_)-1):<br/>  print('iteration=%d, Predicted=%f, Expected=%f' % (i+1, predicted[i], expected[i]))<br/>iteration=1, Predicted=1327.208740, Expected=1350.199951<br/>iteration=2, Predicted=1255.448730, Expected=1277.060059<br/>iteration=3, Predicted=1482.946533, Expected=1205.300049<br/>iteration=4, Predicted=1337.115722, Expected=1260.000000<br/>iteration=5, Predicted=1123.502320, Expected=1249.699951<br/>iteration=6, Predicted=1312.548218, Expected=1126.000000<br/>iteration=7, Predicted=1234.089355, Expected=1179.000000<br/>iteration=8, Predicted=1256.272949, Expected=1096.000000<br/>iteration=9, Predicted=1338.860352, Expected=1093.109985<br/>iteration=10, Predicted=1344.502563, Expected=1056.510010<br/>iteration=11, Predicted=1292.143799, Expected=1093.050049<br/>iteration=12, Predicted=1309.008422, Expected=1135.719971<br/>iteration=13, Predicted=1355.812745, Expected=1061.319946<br/>iteration=14, Predicted=1346.901367, Expected=1103.770020<br/>iteration=15, Predicted=1305.695068, Expected=1126.469971<br/>iteration=16, Predicted=1279.220459, Expected=1111.800049<br/>iteration=17, Predicted=1332.081665, Expected=1125.670044<br/>iteration=18, Predicted=1343.338867, Expected=1125.040039<br/>iteration=19, Predicted=1393.632202, Expected=1147.300049<br/>iteration=20, Predicted=1311.974854, Expected=1122.000000<br/>iteration=21, Predicted=1323.434204, Expected=1098.260010<br/>iteration=22, Predicted=1190.604858, Expected=1119.015015<br/>iteration=23, Predicted=1472.490967, Expected=1138.000000<br/>iteration=24, Predicted=1398.332275, Expected=1221.000000</span></pre><h1 id="c074" class="me mf it bd mg mh mi mj mk ml mm mn mo ki mp kj mq kl mr km ms ko mt kp mu mv bi translated">最终图形</h1><pre class="lp lq lr ls gt nq nr ns nt aw nu bi"><span id="ab91" class="nv mf it nr b gy nw nx l ny nz">import matplotlib.pyplot as plt</span><span id="881c" class="nv mf it nr b gy oa nx l ny nz">fig=plt.figure(figsize=(20, 10), dpi= 80)<br/>fig=plt.plot(expected)<br/>fig=plt.plot(predicted)<br/>#predicted = orange<br/>#expected = blue</span></pre><figure class="lp lq lr ls gt lt gh gi paragraph-image"><div role="button" tabindex="0" class="lu lv di lw bf lx"><div class="gh gi pb"><img src="../Images/2561bed785d5cec928afee998822759b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*VqViV-9KPgvFEt33VW8_Wg.png"/></div></div><figcaption class="ma mb gj gh gi mc md bd b be z dk translated">橙色=预测，蓝色=预期</figcaption></figure><h1 id="9b14" class="me mf it bd mg mh mi mj mk ml mm mn mo ki mp kj mq kl mr km ms ko mt kp mu mv bi translated">评估绩效</h1><pre class="lp lq lr ls gt nq nr ns nt aw nu bi"><span id="bbe5" class="nv mf it nr b gy nw nx l ny nz"># report performance<br/>from math import *<br/>from sklearn.metrics import mean_squared_error<br/>rmse = sqrt(mean_squared_error(expected[:-1], predicted))<br/>print('Test RMSE: %.3f' % rmse)</span><span id="430c" class="nv mf it nr b gy oa nx l ny nz">Output:<br/>Test RMSE: 200.900</span></pre></div></div>    
</body>
</html>