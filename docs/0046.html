<html>
<head>
<title>Understanding The simple Mathematics Behind Simple Linear Regression</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">理解简单线性回归背后的简单数学</h1>
<blockquote>原文：<a href="https://pub.towardsai.net/understanding-the-simple-maths-behind-simple-linear-regression-3ce4a30e7602?source=collection_archive---------1-----------------------#2019-05-16">https://pub.towardsai.net/understanding-the-simple-maths-behind-simple-linear-regression-3ce4a30e7602?source=collection_archive---------1-----------------------#2019-05-16</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><h2 id="59ba" class="ir is it bd b dl iu iv iw ix iy iz dk ja translated" aria-label="kicker paragraph"><a class="ae ep" href="https://towardsai.net/p/category/mathematics" rel="noopener ugc nofollow" target="_blank">数学</a></h2><div class=""/><p id="b3c8" class="pw-post-body-paragraph jz ka it kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw im bi kx translated">T2:很多人喜欢数学，而且有充分的理由。我不太喜欢它，但我试图保持基础知识的更新:-代数、线图、三角函数、微积分先修课程等。感谢像<a class="ae lg" href="http://www.khanacademy.org" rel="noopener ugc nofollow" target="_blank">汗学院</a>这样的平台……学习数学会很有趣。</p><p id="1423" class="pw-post-body-paragraph jz ka it kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw im bi translated">他的文章是写给任何对机器学习感兴趣的人的，尤其是初学者，监督学习技术的新手。</p><p id="0f90" class="pw-post-body-paragraph jz ka it kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw im bi translated">有些人可能会说，数据科学和ML可以不用数学来完成，我在这里不是要反驳这个前提，但是我要说的是，人们需要花时间来看看我们日常使用的一些工具和抽象的引擎盖下面，对启发式有更好的直觉。</p><p id="011a" class="pw-post-body-paragraph jz ka it kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw im bi translated"><strong class="kb jd"> L </strong>线性回归我们已经知道，是指用一个或多个自变量来预测一个因变量。因变量必须是连续的，如预测二氧化碳排放量、工人的年龄或工资、明天的温度等，而自变量可以是连续的或分类的。</p><p id="3253" class="pw-post-body-paragraph jz ka it kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw im bi translated">在本文中，我们将集中讨论简单线性回归。SLR可以说是最直观、最普遍的机器学习算法。</p><p id="841e" class="pw-post-body-paragraph jz ka it kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw im bi translated">在机器学习中，模型可以被认为是在给定一个或多个其他值的情况下，用来预测一个值的数学方程。</p><blockquote class="li lj lk"><p id="803e" class="jz ka lh kb b kc kd ke kf kg kh ki kj ll kl km kn lm kp kq kr ln kt ku kv kw im bi translated">通常你拥有的相关数据越多，你的模型就越精确。</p></blockquote><figure class="lp lq lr ls gt lt gh gi paragraph-image"><div class="gh gi lo"><img src="../Images/e0821402362a328277df1ff3b50e44c2.png" data-original-src="https://miro.medium.com/v2/resize:fit:1382/format:webp/1*CbTy3TT-uxSRBL0FbUuM9A.png"/></div><figcaption class="lw lx gj gh gi ly lz bd b be z dk translated">简单的线性回归模型，在给定车辆发动机尺寸的情况下预测二氧化碳排放量</figcaption></figure><p id="0613" class="pw-post-body-paragraph jz ka it kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw im bi kx translated">上图描绘了一个简单的线性回归模型。它被称为简单线性回归，因为只有一个特征或独立变量用于预测给定的标签或目标。在这种情况下，只有发动机尺寸用于预测二氧化碳排放量。如果我们有一个以上的预测因子，那么我们称之为<em class="lh">多元线性回归</em> <em class="lh"> (MLR) </em>。</p><p id="1215" class="pw-post-body-paragraph jz ka it kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw im bi translated">上图中的<strong class="kb jd"> T </strong> he <strong class="kb jd">红线</strong>代表车型。这是一条最符合数据的直线。因此，该模型是一个数学方程，在给定发动机尺寸(自变量)的情况下，试图预测Co2排放量(因变量)。</p><figure class="lp lq lr ls gt lt gh gi paragraph-image"><div class="gh gi ma"><img src="../Images/dcfad49ec7adce599bd8eb2a396ad42e.png" data-original-src="https://miro.medium.com/v2/resize:fit:738/format:webp/1*P9AtsLFrjLewHWNAndwqOQ.png"/></div><figcaption class="lw lx gj gh gi ly lz bd b be z dk translated">线性方程的斜率截距形式</figcaption></figure><p id="d469" class="pw-post-body-paragraph jz ka it kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw im bi translated">这篇文章旨在创造一个更好的单反直觉，让我们更舒服的概念和其内部工作。这只是简单的数学。谁都能想出来。一个有效的开始方式是从已知到未知…所以让我们回到高中。</p><figure class="lp lq lr ls gt lt gh gi paragraph-image"><div role="button" tabindex="0" class="mc md di me bf mf"><div class="gh gi mb"><img src="../Images/b7ab206980baf5ce300d7aee2555f8fd.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*4rC11rSp6UNcUyhFb2Izhg.png"/></div></div><figcaption class="lw lx gj gh gi ly lz bd b be z dk translated">图片提供:-<a class="ae lg" href="http://www.toondoo.com//public/h/n/b/hnbar/toons/cool-cartoon-1114635.png" rel="noopener ugc nofollow" target="_blank">http://www.toondoo.com</a></figcaption></figure><p id="de65" class="pw-post-body-paragraph jz ka it kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw im bi translated"><strong class="kb jd">T3】y = MX+bT5】</strong></p><p id="58bb" class="pw-post-body-paragraph jz ka it kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw im bi translated"><strong class="kb jd"> T </strong>斜率截距形式<em class="lh"> (y=mx+b) </em>是直接应用于简单线性回归的线性方程</p><p id="1be0" class="pw-post-body-paragraph jz ka it kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw im bi translated"><strong class="kb jd"><em class="lh">y = y轴上的数值</em> </strong></p><p id="dd43" class="pw-post-body-paragraph jz ka it kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw im bi translated"><strong class="kb jd"> <em class="lh"> m =直线的斜率或坡度(y方向的变化</em></strong><em class="lh">/</em><strong class="kb jd"><em class="lh">x方向的变化)</em> </strong></p><p id="3576" class="pw-post-body-paragraph jz ka it kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw im bi translated"><strong class="kb jd"><em class="lh">x = x轴上的值</em> </strong></p><p id="6ad5" class="pw-post-body-paragraph jz ka it kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw im bi translated"><strong class="kb jd"><em class="lh">b = y轴截距或x为0时y的值</em> </strong></p><p id="ed35" class="pw-post-body-paragraph jz ka it kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw im bi translated"><strong class="kb jd">一个</strong>线性方程是这样一个方程，其中如果我们绘制x和y的所有值，那么该图在坐标平面上将是一条完美的直线。</p><figure class="lp lq lr ls gt lt gh gi paragraph-image"><div class="gh gi mg"><img src="../Images/37b736a91ab8222b75b6a057dabeeb20.png" data-original-src="https://miro.medium.com/v2/resize:fit:870/format:webp/1*eTZhrvNlWr9dYJn2Gs_VwA.png"/></div><figcaption class="lw lx gj gh gi ly lz bd b be z dk translated">2x + y = 2的线性方程解，显示一条完美的直线</figcaption></figure><p id="94d1" class="pw-post-body-paragraph jz ka it kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw im bi translated"><strong class="kb jd"> T </strong>因此，斜率截距表表明，对于坐标平面上的任意直线，<strong class="kb jd"><em class="lh"/></strong>的值是直线<strong class="kb jd"> <em class="lh"> m </em> </strong>的斜率与<strong class="kb jd"><em class="lh">×直线</em> </strong>的值加上直线<strong class="kb jd"> <em class="lh"> b </em> </strong>的y截距的乘积。参见<a class="ae lg" href="https://www.khanacademy.org/math/algebra-basics/alg-basics-graphing-lines-and-slope/alg-basics-slope-intercept-form/a/introduction-to-slope-intercept-form" rel="noopener ugc nofollow" target="_blank">链接</a></p><p id="3efc" class="pw-post-body-paragraph jz ka it kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw im bi translated"><strong class="kb jd"> <em class="lh"> y = mx + b </em> </strong></p><p id="251c" class="pw-post-body-paragraph jz ka it kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw im bi translated"><strong class="kb jd"> O </strong>好，回到简单的线性回归…SLR<strong class="kb jd">模型与我们上面看到的斜率-截距形式方程相同，唯一的区别是我们将我们想要预测的标签或因变量表示为<strong class="kb jd"> <em class="lh"> y </em> </strong>并且我们将我们的权重或模型参数表示为<strong class="kb jd"> <em class="lh"> m </em> </strong>和<strong class="kb jd"> <em class="lh"> b </em></strong></strong></p><figure class="lp lq lr ls gt lt gh gi paragraph-image"><div class="gh gi mh"><img src="../Images/86961c03877c620c0c6457dfccff88bc.png" data-original-src="https://miro.medium.com/v2/resize:fit:1198/format:webp/1*Vev02hPbPqzuMsstNtxZQQ.png"/></div><figcaption class="lw lx gj gh gi ly lz bd b be z dk translated">y_hat = b0 + b1x1…表示预测值(yhat) =偏差单位+(斜率*特征)</figcaption></figure><p id="bd0b" class="pw-post-body-paragraph jz ka it kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw im bi translated"><em class="lh">在简单线性回归中:</em></p><p id="95f4" class="pw-post-body-paragraph jz ka it kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw im bi translated"><strong class="kb jd">T81】y = wx+bT83】</strong></p><p id="5369" class="pw-post-body-paragraph jz ka it kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw im bi translated"><em class="lh">同:</em></p><p id="774d" class="pw-post-body-paragraph jz ka it kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw im bi translated"><strong class="kb jd"> <em class="lh"> y = b + wx </em> </strong></p><p id="e906" class="pw-post-body-paragraph jz ka it kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw im bi translated">这与以下内容相同:</p><p id="be86" class="pw-post-body-paragraph jz ka it kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw im bi translated"><strong class="kb jd"><em class="lh">y = B0+b1x 1</em>T3】</strong></p><p id="b887" class="pw-post-body-paragraph jz ka it kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw im bi translated"><em class="lh">哪里:- </em></p><p id="a531" class="pw-post-body-paragraph jz ka it kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw im bi translated"><strong class="kb jd"> <em class="lh"> y =因变量或目标变量。</em> </strong> <em class="lh">(又名，预测或y_hat) </em></p><p id="71c9" class="pw-post-body-paragraph jz ka it kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw im bi translated"><strong class="kb jd"> <em class="lh"> x =自变量或预测变量。</em> </strong> <em class="lh">(又名，x1) </em> <strong class="kb jd"> <em class="lh">。</em> </strong></p><p id="730e" class="pw-post-body-paragraph jz ka it kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw im bi translated"><strong class="kb jd"><em class="lh">B0 = y轴截距。</em> </strong> <em class="lh">(又名偏置单位)</em> <strong class="kb jd"> <em class="lh">。</em> </strong></p><p id="39ea" class="pw-post-body-paragraph jz ka it kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw im bi translated"><strong class="kb jd"> <em class="lh"> b1 =回归线的斜率或梯度</em> </strong></p><p id="fb50" class="pw-post-body-paragraph jz ka it kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw im bi translated"><strong class="kb jd"> A </strong> nd就像斜率截距形式(<strong class="kb jd"> <em class="lh"> y = mx + b) </em> </strong>，只要自变量<em class="lh">(</em><strong class="kb jd"><em class="lh">【x】</em></strong><em class="lh">)</em>)和因变量<em class="lh">(</em><strong class="kb jd"><em class="lh">【y</em></strong><em class="lh">)</em>有线性关系，无论这种关系是正还是负，我们都可以</p><figure class="lp lq lr ls gt lt gh gi paragraph-image"><div class="gh gi mi"><img src="../Images/7933de90d4bebe7f487a000c6eaf5c32.png" data-original-src="https://miro.medium.com/v2/resize:fit:862/format:webp/1*xkBDTQYmB3qvjemv0XCqFw.jpeg"/></div><figcaption class="lw lx gj gh gi ly lz bd b be z dk translated">负关系向下倾斜，正关系向上倾斜，零或弱关系很少或没有倾斜。</figcaption></figure><h1 id="cab8" class="mj mk it bd ml mm mn mo mp mq mr ms mt mu mv mw mx my mz na nb nc nd ne nf ng bi translated">最基本的问题是:-</h1><blockquote class="li lj lk"><p id="12be" class="jz ka lh kb b kc kd ke kf kg kh ki kj ll kl km kn lm kp kq kr ln kt ku kv kw im bi translated"><strong class="kb jd"> <em class="it"> 1。我们如何判断一个自变量与我们想要预测的因变量之间是否存在线性关系？</em> </strong></p></blockquote><p id="9dd2" class="pw-post-body-paragraph jz ka it kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw im bi translated"><strong class="kb jd"> B </strong>因为在线性回归<em class="lh">(无论是简单的还是多重的)</em>中，有<strong class="kb jd">必须</strong>在自变量或预测变量和因变量或目标变量之间存在线性关系。</p><p id="a56c" class="pw-post-body-paragraph jz ka it kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw im bi translated">更多详情请参见来自IBM @Coursera的这个<a class="ae lg" href="https://www.coursera.org/learn/machine-learning-with-python/lecture/0y8Cq/multiple-linear-regression" rel="noopener ugc nofollow" target="_blank"> <strong class="kb jd"> <em class="lh">链接</em> </strong> </a></p><figure class="lp lq lr ls gt lt gh gi paragraph-image"><div role="button" tabindex="0" class="mc md di me bf mf"><div class="gh gi nh"><img src="../Images/de7f709f27f8faa862b15a9068ace59b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Add9SO79Rsx155SEIXQb9w.png"/></div></div><figcaption class="lw lx gj gh gi ly lz bd b be z dk translated">SLR模型，仅使用发动机尺寸作为预测因素或独立变量来预测二氧化碳排放量。</figcaption></figure><blockquote class="li lj lk"><p id="381f" class="jz ka lh kb b kc kd ke kf kg kh ki kj ll kl km kn lm kp kq kr ln kt ku kv kw im bi translated"><strong class="kb jd">2<em class="it">2。如何才能为自己的单反机型选择最好的线路？换句话说，在给定自变量和因变量的情况下，我们如何找到</em> b0 <em class="it">和</em> b1 <em class="it">的理想值，使它们产生最佳预测线？</em>T89】</strong></p></blockquote><h2 id="8c78" class="ni mk it bd ml nj nk dn mp nl nm dp mt kk nn no mx ko np nq nb ks nr ns nf iz bi translated">如何验证两个变量之间是否存在线性关系？</h2><p id="3b85" class="pw-post-body-paragraph jz ka it kb b kc nt ke kf kg nu ki kj kk nv km kn ko nw kq kr ks nx ku kv kw im bi translated">听说过术语<strong class="kb jd"> ' <em class="lh">相关性</em>'吗？？</strong></p><figure class="lp lq lr ls gt lt gh gi paragraph-image"><div role="button" tabindex="0" class="mc md di me bf mf"><div class="gh gi ny"><img src="../Images/bbc3f6cb97e01e68595b60bee93a6496.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Yz_b7ZiFky34N4FvWJI5NQ.png"/></div></div></figure><p id="e796" class="pw-post-body-paragraph jz ka it kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw im bi kx translated">换句话说，相关性试图告诉我们一个变量的变化是否会影响另一个变量，或者可能会导致另一个变量的变化，以及影响的程度。</p><p id="23de" class="pw-post-body-paragraph jz ka it kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw im bi translated">例如，如果汽车发动机尺寸的增加可能导致二氧化碳排放量的增加，那么它们是正相关的。但是如果COMB(mpg)的增加可能导致CO2排放的减少，那么COMB(mpg)和CO2排放是负相关的。如果不存在可能的关系，那么统计学家说它们之间的相关性很弱。</p><figure class="lp lq lr ls gt lt gh gi paragraph-image"><div class="gh gi mi"><img src="../Images/7933de90d4bebe7f487a000c6eaf5c32.png" data-original-src="https://miro.medium.com/v2/resize:fit:862/format:webp/1*xkBDTQYmB3qvjemv0XCqFw.jpeg"/></div><figcaption class="lw lx gj gh gi ly lz bd b be z dk translated">负相关向下倾斜，正相关向上倾斜，弱相关很少或没有倾斜</figcaption></figure><p id="ab72" class="pw-post-body-paragraph jz ka it kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw im bi translated"><strong class="kb jd"> C </strong> orrelation产生一个介于-1和1之间的数。如果数字接近-1，表示强负相关，如果接近1，表示强正相关，如果接近0，表示变量间弱相关。</p><p id="efbd" class="pw-post-body-paragraph jz ka it kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw im bi translated">详见<a class="ae lg" href="https://www.coursera.org/learn/data-analysis-with-python/lecture/lb1Hl/correlation" rel="noopener ugc nofollow" target="_blank"> <strong class="kb jd"> <em class="lh">链接</em> </strong> </a></p><blockquote class="li lj lk"><p id="eea7" class="jz ka lh kb b kc kd ke kf kg kh ki kj ll kl km kn lm kp kq kr ln kt ku kv kw im bi translated"><strong class="kb jd">如果相关性的绝对值大于0.6，<em class="it">表明变量之间存在良好的线性关系</em>。</strong></p></blockquote><p id="8fc0" class="pw-post-body-paragraph jz ka it kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw im bi translated">线性关系可以是负的(如果相关性是负的)或正的。</p><p id="d9d9" class="pw-post-body-paragraph jz ka it kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw im bi translated">相关性或皮尔逊相关性由符号<strong class="kb jd"> <em class="lh"> r </em> </strong>表示</p><figure class="lp lq lr ls gt lt gh gi paragraph-image"><div class="gh gi nz"><img src="../Images/849871ba395a1ef0158e15a6bdec55f8.png" data-original-src="https://miro.medium.com/v2/resize:fit:992/format:webp/1*uhxEOmHtuJcVLbR9fcJXoA.png"/></div><figcaption class="lw lx gj gh gi ly lz bd b be z dk translated">计算两个变量x和y之间相关性的公式</figcaption></figure><blockquote class="li lj lk"><p id="1984" class="jz ka lh kb b kc kd ke kf kg kh ki kj ll kl km kn lm kp kq kr ln kt ku kv kw im bi translated"><strong class="kb jd"> <em class="it">记住相关性并不意味着因果关系……’</em></strong></p></blockquote><h1 id="5484" class="mj mk it bd ml mm mn mo mp mq mr ms mt mu mv mw mx my mz na nb nc nd ne nf ng bi translated">让我们玩一些真实的数据…</h1><figure class="lp lq lr ls gt lt gh gi paragraph-image"><div class="gh gi oa"><img src="../Images/05988516e151499f926ddbaac770125a.png" data-original-src="https://miro.medium.com/v2/resize:fit:390/format:webp/1*gGHZDLF-KuwSeYLdNJVN-g.png"/></div><figcaption class="lw lx gj gh gi ly lz bd b be z dk translated">微笑，让我们一起玩</figcaption></figure><p id="cf9e" class="pw-post-body-paragraph jz ka it kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw im bi translated">W  e将使用<em class="lh">油耗率</em>数据集在加拿大销售汽车。<a class="ae lg" href="https://open.canada.ca/data/en/dataset/98f1a129-f628-4ce4-b24d-6f16bf24dd64" rel="noopener ugc nofollow" target="_blank"> <strong class="kb jd">(原车油耗等级2000–2014)</strong></a>。但是坦率地说，任何流行的回归分析数据集都足够了。</p><p id="5be6" class="pw-post-body-paragraph jz ka it kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw im bi translated"><strong class="kb jd"> T </strong> he <strong class="kb jd"> </strong>数据集已经下载到Google drive，让我们将其导入Google Colab。</p><p id="380c" class="pw-post-body-paragraph jz ka it kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw im bi translated">让我们看一下数据集的摘要图像，数据集包含14343行和13列数据。</p><pre class="lp lq lr ls gt ob oc od oe aw of bi"><span id="80d4" class="ni mk it oc b gy og oh l oi oj"><strong class="oc jd">Understanding the Data</strong></span><span id="ced1" class="ni mk it oc b gy ok oh l oi oj">FuelConsumption.csv:<br/>We have downloaded a fuel consumption dataset, <br/>FuelConsumption.csv, which contains model-specific fuel consumption ratings and estimated carbon dioxide emissions for new light-duty vehicles for retail sale in Canada.</span><span id="02bb" class="ni mk it oc b gy ok oh l oi oj">- <strong class="oc jd">MODELYEAR</strong> e.g. 2014<br/>- <strong class="oc jd">MAKE</strong> e.g. Acura<br/>- <strong class="oc jd">MODEL</strong> e.g. ILX<br/>- <strong class="oc jd">VEHICLE CLASS</strong> e.g. SUV<br/>- <strong class="oc jd">ENGINE SIZE</strong> e.g. 4.7<br/>- <strong class="oc jd">CYLINDERS</strong> e.g 6<br/>- <strong class="oc jd">TRANSMISSION</strong> e.g. A6<br/>- <strong class="oc jd">FUEL CONSUMPTION in CITY(L/100 km)</strong> e.g. 9.9<br/>- <strong class="oc jd">FUEL CONSUMPTION in HWY (L/100 km)</strong> e.g. 8.9<br/>- <strong class="oc jd">FUEL CONSUMPTION COMB (L/100 km)</strong> e.g. 9.2<br/>- <strong class="oc jd">CO2 EMISSIONS (g/km)</strong> e.g. 182   --&gt; low --&gt; 0</span></pre><p id="744f" class="pw-post-body-paragraph jz ka it kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw im bi translated">首先，让我们导入需要的包</p><pre class="lp lq lr ls gt ob oc od oe aw of bi"><span id="7586" class="ni mk it oc b gy og oh l oi oj">import matplotlib.pyplot as plt<br/>import pandas as pd<br/>import pylab as pl<br/>import numpy as np<br/>import seaborn as sns<br/>%matplotlib inline<br/>print('imports all done')</span></pre><p id="681e" class="pw-post-body-paragraph jz ka it kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw im bi translated"><strong class="kb jd"> L </strong> et的导入Gdrive，轻松将文件从Gdrive上传到Google Colab。</p><pre class="lp lq lr ls gt ob oc od oe aw of bi"><span id="64f0" class="ni mk it oc b gy og oh l oi oj">from google.colab import drive<br/>drive.mount('/content/gdrive')</span></pre><p id="4286" class="pw-post-body-paragraph jz ka it kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw im bi translated">让我们从Gdrive读取文件到Pandas数据帧</p><pre class="lp lq lr ls gt ob oc od oe aw of bi"><span id="eb75" class="ni mk it oc b gy og oh l oi oj">file = ''<br/>with open('/content/gdrive/My Drive/Colab_Notebooks/IBM_cognitive_class_learning/Original_2000-2014_Fuel_Consumption_Ratings.csv') as f:<br/>    file = f.read()<br/>    <br/>import sys<br/>if sys.version_info[0] &lt; 3: <br/>    from StringIO import StringIO<br/>else:<br/>    from io import StringIO</span><span id="01fb" class="ni mk it oc b gy ok oh l oi oj">Data = StringIO(file)</span><span id="30e5" class="ni mk it oc b gy ok oh l oi oj">fuel_consumption_df = pd.read_csv(Data, sep=",")</span><span id="05d1" class="ni mk it oc b gy ok oh l oi oj">fuel_consumption_df.head()</span></pre><figure class="lp lq lr ls gt lt gh gi paragraph-image"><div role="button" tabindex="0" class="mc md di me bf mf"><div class="gh gi ol"><img src="../Images/80aa2de8b94ce6ac9f41c38a45328833.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*zklNb3yFdbRXgHC5THVX7w.png"/></div></div><figcaption class="lw lx gj gh gi ly lz bd b be z dk translated">数据集的前五行的输出</figcaption></figure><p id="1f4b" class="pw-post-body-paragraph jz ka it kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw im bi translated">为了简洁起见，让我们重新命名一些列标题</p><pre class="lp lq lr ls gt ob oc od oe aw of bi"><span id="c6d9" class="ni mk it oc b gy og oh l oi oj">fuel_consumption_df.rename(columns={'FUEL_CONSUMPTION_CITY(L/100km)': 'FUEL_CONS_CITY(L/100km)', 'CO2_EMISSIONS(g/km)':'CO2_EMISSIONS'}, inplace=True)</span></pre><h2 id="494c" class="ni mk it bd ml nj nk dn mp nl nm dp mt kk nn no mx ko np nq nb ks nr ns nf iz bi translated">一点EDA来感受一下数据集…</h2><p id="09c4" class="pw-post-body-paragraph jz ka it kb b kc nt ke kf kg nu ki kj kk nv km kn ko nw kq kr ks nx ku kv kw im bi translated">我们来确认一下形状，</p><pre class="lp lq lr ls gt ob oc od oe aw of bi"><span id="4a58" class="ni mk it oc b gy og oh l oi oj">fuel_consumption_df.shape</span><span id="3b77" class="ni mk it oc b gy ok oh l oi oj"># which prints out:</span><span id="3954" class="ni mk it oc b gy ok oh l oi oj">(14343, 13)</span></pre><p id="70ec" class="pw-post-body-paragraph jz ka it kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw im bi translated"><strong class="kb jd">C</strong>column数据类型、</p><pre class="lp lq lr ls gt ob oc od oe aw of bi"><span id="5784" class="ni mk it oc b gy og oh l oi oj">fuel_consumption_df.dtypes</span><span id="f750" class="ni mk it oc b gy ok oh l oi oj"># which prints out:</span></pre><figure class="lp lq lr ls gt lt gh gi paragraph-image"><div role="button" tabindex="0" class="mc md di me bf mf"><div class="gh gi om"><img src="../Images/b0476f6231363ab43ca4135877358c5b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*BpCZrfqSW6HtV5figPLjNA.png"/></div></div><figcaption class="lw lx gj gh gi ly lz bd b be z dk translated">显示每列数据类型的代码单元格的输出。</figcaption></figure><p id="934d" class="pw-post-body-paragraph jz ka it kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw im bi translated"><strong class="kb jd"> C </strong>检查NaN值。</p><pre class="lp lq lr ls gt ob oc od oe aw of bi"><span id="af6b" class="ni mk it oc b gy og oh l oi oj">fuel_consumption_df.isna().sum()</span></pre><figure class="lp lq lr ls gt lt gh gi paragraph-image"><div role="button" tabindex="0" class="mc md di me bf mf"><div class="gh gi om"><img src="../Images/ad9e79f2b391e2584deaa045f5fc5fa2.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*JG1xtsdc82qkB-6Uuv190w.png"/></div></div><figcaption class="lw lx gj gh gi ly lz bd b be z dk translated">代码单元检查NaN值的输出…令人惊讶的是一个也没有！</figcaption></figure><h1 id="55d1" class="mj mk it bd ml mm mn mo mp mq mr ms mt mu mv mw mx my mz na nb nc nd ne nf ng bi translated">相互关系</h1><p id="4a8b" class="pw-post-body-paragraph jz ka it kb b kc nt ke kf kg nu ki kj kk nv km kn ko nw kq kr ks nx ku kv kw im bi kx translated"><span class="l ky kz la bm lb lc ld le lf di"> F </span>或<strong class="kb jd"> SLR </strong>，我们希望仅使用数据集中的一个特征或变量来预测Co2 _排放量<em class="lh">(因变量)</em>。让我们查看数据集中变量的相关性，这样我们就可以选择一个强独立变量。</p><pre class="lp lq lr ls gt ob oc od oe aw of bi"><span id="939f" class="ni mk it oc b gy og oh l oi oj">corr_data = fuel_consumption_df.corr()</span><span id="a133" class="ni mk it oc b gy ok oh l oi oj">plt.figure(figsize=(10,4))<br/>sns.set_style('ticks')<br/>sns.heatmap(corr_data, annot=True)<br/>plt.title('Correlation of variables in fuel_consumption_df Data set')</span><span id="b54f" class="ni mk it oc b gy ok oh l oi oj">plt.show()</span></pre><figure class="lp lq lr ls gt lt gh gi paragraph-image"><div role="button" tabindex="0" class="mc md di me bf mf"><div class="gh gi on"><img src="../Images/60a487afb79eb59b02180bdf5aded3fb.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*SOj4ryIQ4Ps9xHyXhlYbIQ.png"/></div></div><figcaption class="lw lx gj gh gi ly lz bd b be z dk translated">使用Seaborn库的热图显示数据集中变量的相关性。较浅的颜色表示较高的相关数字</figcaption></figure><p id="24ba" class="pw-post-body-paragraph jz ka it kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw im bi translated"><strong class="kb jd"> C </strong>显然，与Co2 _排放量相关数字最好的变量是:-<em class="lh">Fuel _ Cons _ City(</em><strong class="kb jd">0.92</strong><em class="lh">)</em>、<em class="lh">COMB _(mpg)(</em><strong class="kb jd">0.92</strong><em class="lh">)</em>和<em class="lh">Engine _ Size(</em><strong class="kb jd">0.83</strong><em class="lh">)。让我们想象一下每种关系。</em></p><p id="42ce" class="pw-post-body-paragraph jz ka it kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw im bi translated">绘制3个散点图以显示最高相关变量。</p><pre class="lp lq lr ls gt ob oc od oe aw of bi"><span id="d623" class="ni mk it oc b gy og oh l oi oj">fig = plt.figure(figsize=(20, 5))<br/>plt.suptitle('Scatter plots showing correlation between Top-Correlated-Variables and CO2_EMISSIONS', y=1.05, fontsize=16)</span><span id="fc6c" class="ni mk it oc b gy ok oh l oi oj">ax = fig.add_subplot(131)<br/>ax1 = fig.add_subplot(132)<br/>ax2 = fig.add_subplot(133)</span><span id="568d" class="ni mk it oc b gy ok oh l oi oj"># Subplot 1 scatter plot of ENGINE_SIZE and Co2_EMISSIONS<br/>fuel_consumption_df.plot(kind='scatter', x='ENGINE_SIZE(L)', y='CO2_EMISSIONS', color='red', ax=ax)<br/>ax.set_title('ENGINE_SIZE(L) and CO2_EMISSIONS')<br/>ax.set_xlabel('ENGINE_SIZE(L)')<br/>ax.set_ylabel('CO2_EMISSIONS')</span><span id="7ca2" class="ni mk it oc b gy ok oh l oi oj"># Subplot 2 scatter plot of FUEL_CONS_CITY(L/100km) and Co2_EMISSIONS<br/>fuel_consumption_df.plot(kind='scatter', x='FUEL_CONS_CITY(L/100km)', y='CO2_EMISSIONS', color='navy', ax=ax1)<br/>ax1.set_title('FUEL_CONS_CITY(L/100km) and CO2_EMISSIONS')<br/>ax1.set_xlabel('FUEL_CONS_CITY(L/100km)')<br/>ax1.set_ylabel('CO2_EMISSIONS')</span><span id="1a5a" class="ni mk it oc b gy ok oh l oi oj"># Subplot 3 scatter plot of COMB_(L/100km) and Co2_EMISSIONS<br/>fuel_consumption_df.plot(kind='scatter', x='COMB_(L/100km)', y='CO2_EMISSIONS', color='green', ax=ax2)<br/>ax2.set_title('COMB_(L/100km) and CO2_EMISSIONS')<br/>ax2.set_xlabel('COMB_(L/100km)')<br/>ax2.set_ylabel('CO2_EMISSIONS')</span><span id="9716" class="ni mk it oc b gy ok oh l oi oj">plt.show()</span></pre><figure class="lp lq lr ls gt lt gh gi paragraph-image"><div role="button" tabindex="0" class="mc md di me bf mf"><div class="gh gi om"><img src="../Images/548c7cecf2d9d40eeae945234a4571b4.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*LTzHp01f41FnWW2DQoVL1Q.png"/></div></div><figcaption class="lw lx gj gh gi ly lz bd b be z dk translated">输出显示每个顶部相关变量和因变量(CO2 _排放量)之间清晰的正线性关系。</figcaption></figure><p id="cfa0" class="pw-post-body-paragraph jz ka it kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw im bi kx translated">ll三个变量与CO2排放有很强的正线性关系。我选择ENGINE_SIZE(L)作为这个练习的自变量。你可以自由选择其中任何一个。</p><p id="ba69" class="pw-post-body-paragraph jz ka it kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw im bi translated">现在是时候回答第二个基本问题了。</p><figure class="lp lq lr ls gt lt gh gi paragraph-image"><div class="gh gi oo"><img src="../Images/8554425e7ceda1beb1c20886c5f74349.png" data-original-src="https://miro.medium.com/v2/resize:fit:1162/format:webp/1*SRKwqe7YM2-cV3PMMN7VTg.png"/></div><figcaption class="lw lx gj gh gi ly lz bd b be z dk translated">计算均方误差的公式</figcaption></figure><blockquote class="li lj lk"><p id="8232" class="jz ka lh kb b kc kd ke kf kg kh ki kj ll kl km kn lm kp kq kr ln kt ku kv kw im bi translated">参数b0和b1的最佳值将是最小化均方误差(MSE)的值。</p></blockquote><h2 id="fca9" class="ni mk it bd ml nj nk dn mp nl nm dp mt kk nn no mx ko np nq nb ks nr ns nf iz bi translated">什么是MSE？</h2><p id="9c97" class="pw-post-body-paragraph jz ka it kb b kc nt ke kf kg nu ki kj kk nv km kn ko nw kq kr ks nx ku kv kw im bi translated">均方误差就是每个预测值和每个实际值之间的平方差之和，除以观察总数。</p><p id="efea" class="pw-post-body-paragraph jz ka it kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw im bi translated">在这里，一个<strong class="kb jd"> <em class="lh">观察值</em> </strong>是一行特定的数据<strong class="kb jd"> <em class="lh">。</em></strong><strong class="kb jd"><em class="lh">示例</em> </strong>简单来说就是一对给定的发动机尺寸值及其对应的二氧化碳排放量值。记住，数据集包含14343个例子/观察值。</p><blockquote class="op"><p id="819d" class="oq or it bd os ot ou ov ow ox oy kw dk translated">那么，我们如何找到b0和b1的理想值，使我们的单反模型产生最小的MSE呢？</p></blockquote><p id="947d" class="pw-post-body-paragraph jz ka it kb b kc oz ke kf kg pa ki kj kk pb km kn ko pc kq kr ks pd ku kv kw im bi translated"><strong class="kb jd"> C </strong> heesy…首先，我们用一个简单的数学公式求出<strong class="kb jd"> <em class="lh"> b1 </em> </strong> <em class="lh">(斜率)</em> <strong class="kb jd"> <em class="lh"> </em> </strong>的值。然后我们把<strong class="kb jd"> <em class="lh"> b1 </em> </strong>代入<strong class="kb jd">单反</strong>方程<strong class="kb jd"> <em class="lh"> (y = b0 + b1x1) </em> </strong>，求<strong class="kb jd"> <em class="lh"> b0 </em> </strong> <em class="lh">(拦截器偏置单元)</em> …就这样<strong class="kb jd"> <em class="lh">。</em>T73】</strong></p><p id="58f3" class="pw-post-body-paragraph jz ka it kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw im bi translated"><strong class="kb jd"> <em class="lh">斜率公式</em> </strong>为<strong class="kb jd"> <em class="lh"> </em> </strong>计算<strong class="kb jd"> <em class="lh"> b1 </em> </strong> <em class="lh">(斜率)</em> <strong class="kb jd"> <em class="lh"> </em> </strong>在简单线性回归中为:-</p><figure class="lp lq lr ls gt lt gh gi paragraph-image"><div class="gh gi pe"><img src="../Images/8f7144b4673f0045538dbc0153650dd6.png" data-original-src="https://miro.medium.com/v2/resize:fit:860/format:webp/1*AQyNX2A0Ks8s8o9ut4Aziw.png"/></div><figcaption class="lw lx gj gh gi ly lz bd b be z dk translated">一元线性回归斜率的计算公式</figcaption></figure><p id="88b1" class="pw-post-body-paragraph jz ka it kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw im bi translated">其中:</p><p id="bec4" class="pw-post-body-paragraph jz ka it kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw im bi translated"><strong class="kb jd"><em class="lh"/></strong>(是观测值的总数)</p><p id="b733" class="pw-post-body-paragraph jz ka it kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw im bi translated"><strong class="kb jd"> <em class="lh"> x </em> </strong>(自变量，引擎大小，即一个<strong class="kb jd"> <em class="lh"> n * 1 </em> </strong>列向量)</p><p id="0e78" class="pw-post-body-paragraph jz ka it kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw im bi translated"><strong class="kb jd"> <em class="lh"> y </em> </strong>(因变量，Co2 _排放量，这是一个<strong class="kb jd"> <em class="lh"> n * 1 </em> </strong>列向量)</p><p id="3249" class="pw-post-body-paragraph jz ka it kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw im bi translated"><strong class="kb jd"> <em class="lh"> i = 1 </em> </strong>(指数据集中的第一次观察。<strong class="kb jd">注</strong> : <strong class="kb jd"> <em class="lh"> i </em> </strong>从1上升到<strong class="kb jd"> <em class="lh"> n </em> </strong>)</p><p id="88b5" class="pw-post-body-paragraph jz ka it kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw im bi translated"><strong class="kb jd"> <em class="lh"> xi </em> </strong>(第<strong class="kb jd"> <em class="lh"> i </em> </strong>第<strong class="kb jd"> <em class="lh"> x </em> </strong>的观察)</p><p id="7742" class="pw-post-body-paragraph jz ka it kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw im bi translated"><strong class="kb jd"><em class="lh">x _ bar</em></strong>(<strong class="kb jd"><em class="lh">x</em></strong>的平均值)</p><p id="60e4" class="pw-post-body-paragraph jz ka it kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw im bi translated"><strong class="kb jd"><em class="lh"/></strong>(第<strong class="kb jd"> <em class="lh"> i </em> </strong>第<strong class="kb jd"> <em class="lh"> y </em> </strong>观察)</p><p id="7e51" class="pw-post-body-paragraph jz ka it kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw im bi translated"><strong class="kb jd"><em class="lh">y _ bar</em></strong>(y<strong class="kb jd"><em class="lh"/></strong>的平均值)</p><h2 id="7457" class="ni mk it bd ml nj nk dn mp nl nm dp mt kk nn no mx ko np nq nb ks nr ns nf iz bi translated">概括起来</h2><blockquote class="li lj lk"><p id="6d3c" class="jz ka lh kb b kc kd ke kf kg kh ki kj ll kl km kn lm kp kq kr ln kt ku kv kw im bi translated">为了找到<strong class="kb jd"> b1 </strong>，我们将斜率公式的<strong class="kb jd">分子</strong>除以<strong class="kb jd">分母</strong>。</p><p id="7f65" class="jz ka lh kb b kc kd ke kf kg kh ki kj ll kl km kn lm kp kq kr ln kt ku kv kw im bi translated"><strong class="kb jd">分子</strong>简单来说就是<em class="it"/><strong class="kb jd"><em class="it">I</em></strong><em class="it"/>等于1到<strong class="kb jd"> n </strong>对于<strong class="kb jd">的每个值，</strong>减去<strong class="kb jd"> x_bar </strong>，再乘以<strong class="kb jd"> yi、</strong>减去<strong class="kb jd"> y_bar </strong>的对应值。</p><p id="1565" class="jz ka lh kb b kc kd ke kf kg kh ki kj ll kl km kn lm kp kq kr ln kt ku kv kw im bi translated"><strong class="kb jd">分母</strong>就是从<strong class="kb jd"> <em class="it"> i </em> </strong>等于1到<strong class="kb jd"> n </strong>的<strong class="kb jd"> xi </strong>和<strong class="kb jd"> x_bar </strong>的每个值的平方差之和。</p></blockquote><h1 id="f462" class="mj mk it bd ml mm mn mo mp mq mr ms mt mu mv mw mx my mz na nb nc nd ne nf ng bi translated">让我们用斜率公式求解b1或斜率。</h1><p id="4aaa" class="pw-post-body-paragraph jz ka it kb b kc nt ke kf kg nu ki kj kk nv km kn ko nw kq kr ks nx ku kv kw im bi translated">首先让我们定义一下我们的变量:- <strong class="kb jd"> <em class="lh"> x </em> </strong>和<strong class="kb jd"> <em class="lh"> x_bar </em> </strong>，以及<strong class="kb jd"> <em class="lh"> y </em> </strong>和<strong class="kb jd"> <em class="lh"> y_bar。</em>T145】</strong></p><pre class="lp lq lr ls gt ob oc od oe aw of bi"><span id="935c" class="ni mk it oc b gy og oh l oi oj"># The predictor or independent variable x is Engine_Size<br/>x = fuel_consumption_df['ENGINE_SIZE(L)']</span><span id="d57a" class="ni mk it oc b gy ok oh l oi oj"># The mean or average of x is x_bar<br/>x_bar = x.mean()</span><span id="5a71" class="ni mk it oc b gy ok oh l oi oj"># The target or dependent variable y is Co2_Emissions<br/>y = fuel_consumption_df['CO2_EMISSIONS']</span><span id="3b3a" class="ni mk it oc b gy ok oh l oi oj"># The mean or average of y is y_bar<br/>y_bar = y.mean()</span></pre><figure class="lp lq lr ls gt lt gh gi paragraph-image"><div role="button" tabindex="0" class="mc md di me bf mf"><div class="gh gi om"><img src="../Images/cf1cdfcebe99fde4bf7b224b729265b8.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*NsG2aRTpEOUQqMiOy_prNQ.png"/></div></div><figcaption class="lw lx gj gh gi ly lz bd b be z dk translated">定义变量:- x(发动机尺寸)，y(二氧化碳排放量)，x _ bar(x的平均值)和y _ bar(y的平均值)。</figcaption></figure><p id="7837" class="pw-post-body-paragraph jz ka it kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw im bi translated">接下来，让我们定义一个简单的函数，它接受变量并返回<strong class="kb jd"><em class="lh">【B1】</em></strong></p><pre class="lp lq lr ls gt ob oc od oe aw of bi"><span id="a268" class="ni mk it oc b gy og oh l oi oj"><strong class="oc jd">def</strong> <strong class="oc jd">calc_slope(feature, target, x_bar, y_bar):</strong><br/>    """ takes two series objects- feature and target and their averages x_bar and y_bar<br/>    performs the slope equation on each combine variables of feature and target,<br/>    then finally returns a floating point number as theta one or b_one,<br/>    Which is also known as the gradient or slope of the linear regression"""</span><span id="9e77" class="ni mk it oc b gy ok oh l oi oj">    numerator = 0<br/>    denominator = 0<br/>    for i, j in zip(feature, target):<br/>        numerator+= (i - x_bar) * (j - y_bar)<br/>        denominator+= (i - x_bar)**2<br/>    return round((numerator / denominator),8)</span></pre><p id="9566" class="pw-post-body-paragraph jz ka it kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw im bi translated">让我们通过调用函数并向其传递变量来定义<strong class="kb jd"> <em class="lh"> b1 </em> </strong></p><pre class="lp lq lr ls gt ob oc od oe aw of bi"><span id="699d" class="ni mk it oc b gy og oh l oi oj">b1 = <strong class="oc jd">calc_slope(x, y, x_bar, y_bar)</strong></span><span id="ae5e" class="ni mk it oc b gy ok oh l oi oj">b1</span></pre><p id="be3a" class="pw-post-body-paragraph jz ka it kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw im bi translated">这会打印出值为37.28016592的<strong class="kb jd"> <em class="lh"> b1或</em> </strong></p><figure class="lp lq lr ls gt lt gh gi paragraph-image"><div role="button" tabindex="0" class="mc md di me bf mf"><div class="gh gi ol"><img src="../Images/a6f3b4a1da724edead9150a4dc8ba70d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*C0SzT4ZWGQWmAN8RfRvR9A.png"/></div></div><figcaption class="lw lx gj gh gi ly lz bd b be z dk translated">使用一个简单的函数，我们可以看到单反模型的b1或斜率约为37.28。</figcaption></figure><h1 id="7267" class="mj mk it bd ml mm mn mo mp mq mr ms mt mu mv mw mx my mz na nb nc nd ne nf ng bi translated">接下来让我们替换单反方程式中b1的值</h1><p id="e428" class="pw-post-body-paragraph jz ka it kb b kc nt ke kf kg nu ki kj kk nv km kn ko nw kq kr ks nx ku kv kw im bi translated"><strong class="kb jd"> R </strong>记住SLR方程<strong class="kb jd">(<em class="lh">y = B0+bixi</em></strong><em class="lh">)</em>与斜率截距方程<strong class="kb jd"> <em class="lh"> (y = b + mx) </em> </strong>相同。</p><p id="32b4" class="pw-post-body-paragraph jz ka it kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw im bi translated"><strong class="kb jd"> T </strong>因此我们可以使用我们已知的<strong class="kb jd"> <em class="lh"> y </em> </strong>和<strong class="kb jd"> <em class="lh"> x </em> </strong>的任意对应值，将斜率<strong class="kb jd"><em class="lh">【B1】</em></strong>代入SLR方程，得到<strong class="kb jd"> <em class="lh"> y_intercept </em> </strong>或<strong class="kb jd"> <em class="lh"> b0。</em>T45】</strong></p><p id="dbe4" class="pw-post-body-paragraph jz ka it kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw im bi translated">我们先用平均值<strong class="kb jd"> <em class="lh"> x_bar </em> </strong>和<strong class="kb jd"> <em class="lh"> y_bar </em> </strong>。</p><p id="8fde" class="pw-post-body-paragraph jz ka it kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw im bi translated"><strong class="kb jd"> <em class="lh"> y = b0 + b1x1 </em> </strong></p><p id="a216" class="pw-post-body-paragraph jz ka it kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw im bi translated"><em class="lh">因此</em>:<br/><strong class="kb jd"><em class="lh">y _ bar = B0+B1(x _ bar)</em></strong></p><p id="a19c" class="pw-post-body-paragraph jz ka it kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw im bi translated"><strong class="kb jd">让我们求解为<em class="lh">B0</em>T68】</strong></p><p id="710a" class="pw-post-body-paragraph jz ka it kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw im bi translated"><em class="lh">因此</em><strong class="kb jd">:</strong><br/><strong class="kb jd"><em class="lh">B0+B1(x _ bar)= y _ bar</em></strong></p><p id="5984" class="pw-post-body-paragraph jz ka it kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw im bi translated"><em class="lh">最后求解为</em> <strong class="kb jd"> <em class="lh"> b0 </em> </strong> <em class="lh">，可以写成:</em><br/><strong class="kb jd"><em class="lh">B0 = y _ bar—B1(x _ bar)</em></strong></p><p id="7965" class="pw-post-body-paragraph jz ka it kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw im bi translated">我们先输入<strong class="kb jd"> <em class="lh"> y_bar </em> </strong>，<strong class="kb jd"> <em class="lh"> b1 </em> </strong>和<strong class="kb jd"> <em class="lh"> x_bar </em> </strong>的值，得到<strong class="kb jd"> <em class="lh"> b0 </em> </strong>的值。</p><pre class="lp lq lr ls gt ob oc od oe aw of bi"><span id="ef12" class="ni mk it oc b gy og oh l oi oj">b0 = y_bar - (b1 * x_bar)</span><span id="17d4" class="ni mk it oc b gy ok oh l oi oj"># Lets round b0 to 8 D.P as is the norm<br/>b0 = round(b0, 8)</span><span id="7ce4" class="ni mk it oc b gy ok oh l oi oj">b0</span></pre><p id="497b" class="pw-post-body-paragraph jz ka it kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw im bi translated">这会打印出<strong class="kb jd"> <em class="lh"> b0或截距或偏置单位，</em> </strong>的值为119.00800194</p><figure class="lp lq lr ls gt lt gh gi paragraph-image"><div role="button" tabindex="0" class="mc md di me bf mf"><div class="gh gi om"><img src="../Images/c039a132e2f7521136a95d8ec4b43909.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*_FKuphlfTF0A3DR-PGNWeQ.png"/></div></div><figcaption class="lw lx gj gh gi ly lz bd b be z dk translated">使用SLR方程对b0进行数学求解，得出截距或偏差单位为119.00</figcaption></figure><h2 id="981d" class="ni mk it bd ml nj nk dn mp nl nm dp mt kk nn no mx ko np nq nb ks nr ns nf iz bi translated">概括起来</h2><blockquote class="li lj lk"><p id="f695" class="jz ka lh kb b kc kd ke kf kg kh ki kj ll kl km kn lm kp kq kr ln kt ku kv kw im bi translated">从数学上，我们可以看到模型参数<strong class="kb jd"> b0 </strong>和<strong class="kb jd"> b1 </strong>的理想值为:<strong class="kb jd"> <em class="it"> 119 </em> (b0) </strong>和<strong class="kb jd"><em class="it">37.28</em>(B1)</strong>。</p></blockquote><p id="c45e" class="pw-post-body-paragraph jz ka it kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw im bi translated">这样我们的数学单反模型就是<strong class="kb jd"><em class="lh">y _ hat =</em>119<em class="lh">+</em>37.28<em class="lh">(x1)</em></strong></p><p id="61be" class="pw-post-body-paragraph jz ka it kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw im bi translated">这意味着如果我们想预测一辆引擎大小为13.5升的汽车的二氧化碳排放量。我们未知的预测是<strong class="kb jd"> <em class="lh"> y_hat </em> </strong>。我们的预测器是<strong class="kb jd"> <em class="lh"> x1 </em> </strong>，是13.5。所以我们所需要做的就是将13.5代入方程，找到<strong class="kb jd"> <em class="lh"> y_hat </em> </strong>。</p><p id="dc0e" class="pw-post-body-paragraph jz ka it kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw im bi translated"><strong class="kb jd"><em class="lh">y _ hat =</em>119<em class="lh">+</em>37.28<em class="lh">*</em>13.5</strong></p><p id="7670" class="pw-post-body-paragraph jz ka it kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw im bi translated"><strong class="kb jd"> <em class="lh"> y_hat = </em> 622 </strong>(四舍五入为整数)</p><h1 id="577b" class="mj mk it bd ml mm mn mo mp mq mr ms mt mu mv mw mx my mz na nb nc nd ne nf ng bi translated">让我们比较一下我们的数学模型和Sklearn模型</h1><p id="b083" class="pw-post-body-paragraph jz ka it kb b kc nt ke kf kg nu ki kj kk nv km kn ko nw kq kr ks nx ku kv kw im bi translated">首先，从Sklearn导入线性回归并创建一个模型</p><pre class="lp lq lr ls gt ob oc od oe aw of bi"><span id="2df4" class="ni mk it oc b gy og oh l oi oj"># first we import Linear regression model from sklearn</span><span id="5ca8" class="ni mk it oc b gy ok oh l oi oj">from sklearn.linear_model import LinearRegression<br/>from sklearn.metrics import mean_squared_error</span></pre><p id="9696" class="pw-post-body-paragraph jz ka it kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw im bi translated">接下来，我们实例化一个线性回归模型</p><pre class="lp lq lr ls gt ob oc od oe aw of bi"><span id="d4b3" class="ni mk it oc b gy og oh l oi oj">model = LinearRegression()</span></pre><p id="76a1" class="pw-post-body-paragraph jz ka it kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw im bi translated"><strong class="kb jd"> N </strong> ext，我们定义特征<strong class="kb jd"><em class="lh">【X】</em></strong>和目标<strong class="kb jd"><em class="lh">【Y】</em></strong>变量到2D数组中</p><pre class="lp lq lr ls gt ob oc od oe aw of bi"><span id="8680" class="ni mk it oc b gy og oh l oi oj"># The feature or independent variable <br/>X = fuel_consumption_df[['ENGINE_SIZE(L)']].values</span><span id="30b4" class="ni mk it oc b gy ok oh l oi oj"># The target or dependent variable<br/>Y = fuel_consumption_df[['CO2_EMISSIONS']].values</span></pre><p id="8160" class="pw-post-body-paragraph jz ka it kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw im bi translated"><strong class="kb jd"> T </strong>当我们使用fit函数训练模型并向其传递<strong class="kb jd"> <em class="lh"> X </em> </strong>和<strong class="kb jd"> <em class="lh"> Y </em> </strong>时。</p><pre class="lp lq lr ls gt ob oc od oe aw of bi"><span id="ca4b" class="ni mk it oc b gy og oh l oi oj">model.fit(X,Y)</span></pre><p id="a835" class="pw-post-body-paragraph jz ka it kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw im bi translated">最后，我们打印出Sklearn模型的理想值<strong class="kb jd"> <em class="lh"> b0 </em> </strong>和<strong class="kb jd"> <em class="lh"> b1 </em> </strong></p><pre class="lp lq lr ls gt ob oc od oe aw of bi"><span id="7052" class="ni mk it oc b gy og oh l oi oj"># Defining the model slope or b1<br/>slope = model.coef_</span><span id="1ec4" class="ni mk it oc b gy ok oh l oi oj"># Defining the model intercept or b0<br/>intercept = model.intercept_</span><span id="f248" class="ni mk it oc b gy ok oh l oi oj">print(slope,intercept)</span></pre><p id="183c" class="pw-post-body-paragraph jz ka it kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw im bi translated">他打印出的斜率为37.28046592，截距为119.00800194，与我们的数学模型完全相同。</p><figure class="lp lq lr ls gt lt gh gi paragraph-image"><div role="button" tabindex="0" class="mc md di me bf mf"><div class="gh gi pf"><img src="../Images/0b0e37a5d543f324840727f087aa8e34.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*IJAcG8oqQtIxlmr030ZZJA.png"/></div></div><figcaption class="lw lx gj gh gi ly lz bd b be z dk translated">显示Sklearn模型斜率(b1)的代码单元的输出，该值与数学模型的值相同。</figcaption></figure><figure class="lp lq lr ls gt lt gh gi paragraph-image"><div role="button" tabindex="0" class="mc md di me bf mf"><div class="gh gi om"><img src="../Images/99ee28a04f480219e000fcc7c01fadca.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*0mLU0Du4v7z5kxrCi2qWYw.png"/></div></div><figcaption class="lw lx gj gh gi ly lz bd b be z dk translated">显示Sklearn模型截距(b0)的代码单元的输出，与数学模型具有相同的值。</figcaption></figure><p id="6410" class="pw-post-body-paragraph jz ka it kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw im bi translated">Maths和Sklearn模型都有完全相同的参数<strong class="kb jd"> <em class="lh"> b0 </em> </strong>和<strong class="kb jd"> <em class="lh"> b1 </em> </strong>，这证明了一个事实，即不需要库就可以直观地解决SLR，特别是如果它是一个中小型数据集。</p><figure class="lp lq lr ls gt lt gh gi paragraph-image"><div role="button" tabindex="0" class="mc md di me bf mf"><div class="gh gi om"><img src="../Images/ae58d815fc268cd222f40bd6fc1f8cdd.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*B57KW0iE5zAd6Gn-ZdA5Zw.png"/></div></div><figcaption class="lw lx gj gh gi ly lz bd b be z dk translated">Maths和Sklearn模型具有相同的斜率(梯度)和截距(偏差单位)值</figcaption></figure><h1 id="73c7" class="mj mk it bd ml mm mn mo mp mq mr ms mt mu mv mw mx my mz na nb nc nd ne nf ng bi translated">最后，</h1><h2 id="761c" class="ni mk it bd ml nj nk dn mp nl nm dp mt kk nn no mx ko np nq nb ks nr ns nf iz bi translated">评估…</h2><blockquote class="li lj lk"><p id="b140" class="jz ka lh kb b kc kd ke kf kg kh ki kj ll kl km kn lm kp kq kr ln kt ku kv kw im bi translated">模特们表现如何？。</p></blockquote><figure class="lp lq lr ls gt lt gh gi paragraph-image"><div role="button" tabindex="0" class="mc md di me bf mf"><div class="gh gi pg"><img src="../Images/a9418a2ff023a09f2b5f06b474c078f4.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*G4toi8TRuTpSARdLhL1o6w.png"/></div></div><figcaption class="lw lx gj gh gi ly lz bd b be z dk translated">图片提供:<a class="ae lg" href="https://cdn.lynda.com/course/645049/645049-636628390565991366-16x9.jpg" rel="noopener ugc nofollow" target="_blank">https://cdn . Lynda . com/course/645049/645049-636628390565991366-16x 9 . jpg</a></figcaption></figure><p id="ee30" class="pw-post-body-paragraph jz ka it kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw im bi translated">让我们比较一下数学模型和Sklearn模型的<strong class="kb jd"> <em class="lh"> RMSE </em> </strong>。</p><p id="c3de" class="pw-post-body-paragraph jz ka it kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw im bi translated">均方根误差是<strong class="kb jd"> <em class="lh"> MSE </em> </strong>的平方根，是衡量线性回归模型性能的理想指标。</p><blockquote class="li lj lk"><p id="66df" class="jz ka lh kb b kc kd ke kf kg kh ki kj ll kl km kn lm kp kq kr ln kt ku kv kw im bi translated"><code class="fe ph pi pj oc b"><strong class="kb jd"><em class="it">RMSE can be interpreted right on the same scale as the dependent or target variable and gives a good indicator of how well our model performs. Simply find the range of the target variable and compare the RMSE to it. The lower the RMSE as a percentage of the range, the better the model performance.</em></strong></code></p></blockquote><p id="64f7" class="pw-post-body-paragraph jz ka it kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw im bi translated">让我们计算两个模型的MSE和RMSE</p><pre class="lp lq lr ls gt ob oc od oe aw of bi"><span id="6980" class="ni mk it oc b gy og oh l oi oj"># First import mean_squared_error metric from sklearn<br/>from sklearn.metrics import mean_squared_error</span><span id="a958" class="ni mk it oc b gy ok oh l oi oj"># for maths model<br/>y_hat = round(x * b1 + b0)<br/>MSE = mean_squared_error(y_hat, y)<br/>RMSE = MSE**0.5</span><span id="06ca" class="ni mk it oc b gy ok oh l oi oj"># for Sklearn model<br/>prediction = model.predict(X)<br/>model_MSE = mean_squared_error(prediction, Y)<br/>model_RMSE = model_MSE**0.5</span></pre><p id="9663" class="pw-post-body-paragraph jz ka it kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw im bi translated">接下来，我们打印出数学和Sklearn模型的MSE和RMSE</p><pre class="lp lq lr ls gt ob oc od oe aw of bi"><span id="6b20" class="ni mk it oc b gy og oh l oi oj">print('The Mathematical MSE is:', round(MSE))<br/>print('The Scikit Learn MSE is:', np.round(model_MSE))<br/>print('The Mathematical RMSE is:', round(RMSE))<br/>print('The Scikit Learn RMSE is:', np.round(model_RMSE))</span></pre><p id="58fd" class="pw-post-body-paragraph jz ka it kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw im bi translated">上面的代码打印出以下内容</p><pre class="lp lq lr ls gt ob oc od oe aw of bi"><span id="fae9" class="ni mk it oc b gy og oh l oi oj">The Mathematical MSE is: 1110.0 <br/>The Scikit Learn MSE is: 1110.0 <br/>The Mathematical RMSE is: 33.0 <br/>The Scikit Learn RMSE is: 33.0</span></pre><figure class="lp lq lr ls gt lt gh gi paragraph-image"><div role="button" tabindex="0" class="mc md di me bf mf"><div class="gh gi om"><img src="../Images/ecb9e22800ec1448788b2b55ad010fc9.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*7K_3RnvaF_fX1bs62rUJdQ.png"/></div></div><figcaption class="lw lx gj gh gi ly lz bd b be z dk translated">两个模型都有完全相同的MSE和RMSE，但是33的RMSE到底意味着什么呢？</figcaption></figure><p id="1c7e" class="pw-post-body-paragraph jz ka it kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw im bi translated">两款车型都有相同的<strong class="kb jd">1110</strong>的MSE和33 的<strong class="kb jd"> RMSE。</strong></p><blockquote class="li lj lk"><p id="935d" class="jz ka lh kb b kc kd ke kf kg kh ki kj ll kl km kn lm kp kq kr ln kt ku kv kw im bi translated">但是，一个33 的<strong class="kb jd"> RMSE到底意味着什么……它能告诉我们什么？</strong></p></blockquote><p id="1991" class="pw-post-body-paragraph jz ka it kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw im bi translated"><strong class="kb jd"> T </strong> o得到<strong class="kb jd"> <em class="lh"> RMSE </em> </strong>的含义，让我们把它做成因变量范围的百分比。百分比越低，模型越好。</p><p id="5015" class="pw-post-body-paragraph jz ka it kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw im bi translated">首先，我们找到因变量(二氧化碳排放量)的范围</p><pre class="lp lq lr ls gt ob oc od oe aw of bi"><span id="53a4" class="ni mk it oc b gy og oh l oi oj">y_range = fuel_consumption_df['CO2_EMISSIONS'].max() - fuel_consumption_df['CO2_EMISSIONS'].min()</span><span id="5e54" class="ni mk it oc b gy ok oh l oi oj">y_range</span></pre><p id="6786" class="pw-post-body-paragraph jz ka it kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw im bi translated">这给出了一个范围<strong class="kb jd"> 487 </strong></p><p id="4ec8" class="pw-post-body-paragraph jz ka it kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw im bi translated">最后，我们将RMSE设为量程的一个百分比</p><pre class="lp lq lr ls gt ob oc od oe aw of bi"><span id="a521" class="ni mk it oc b gy og oh l oi oj">error_margin = (RMSE / y_range) * 100</span><span id="4736" class="ni mk it oc b gy ok oh l oi oj">error_margin</span></pre><p id="3465" class="pw-post-body-paragraph jz ka it kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw im bi translated">这会打印出一个值<strong class="kb jd"> 6.84% </strong></p><figure class="lp lq lr ls gt lt gh gi paragraph-image"><div role="button" tabindex="0" class="mc md di me bf mf"><div class="gh gi om"><img src="../Images/ccd720b75151f55a4192b12d02c9b04d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*GuLG41YAjEe2oI8NykosMA.png"/></div></div><figcaption class="lw lx gj gh gi ly lz bd b be z dk translated">显示两个模型的误差范围的输出</figcaption></figure><p id="1fa8" class="pw-post-body-paragraph jz ka it kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw im bi translated">因此，利用 33 的<strong class="kb jd"> <em class="lh"> RMSE，我们的模型误差在因变量(CO2 _排放)的<strong class="kb jd"> <em class="lh">范围</em>【487】</strong>的<strong class="kb jd"> 6.84% </strong>的误差范围内……这意味着我们的SLR模型虽然简单，但做得相当好。</em></strong></p><h2 id="247a" class="ni mk it bd ml nj nk dn mp nl nm dp mt kk nn no mx ko np nq nb ks nr ns nf iz bi translated">让我们来看看数学模型和Sklearn模型的曲线图。</h2><figure class="lp lq lr ls gt lt gh gi paragraph-image"><div role="button" tabindex="0" class="mc md di me bf mf"><div class="gh gi om"><img src="../Images/c147184c1007f8a05602a35aa718cbea.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*czBpam8Zthmo14QwjmipHw.png"/></div></div><figcaption class="lw lx gj gh gi ly lz bd b be z dk translated">数学和Sklearn模型的Regplots。两者惊人的相同。</figcaption></figure><h1 id="1ad0" class="mj mk it bd ml mm mn mo mp mq mr ms mt mu mv mw mx my mz na nb nc nd ne nf ng bi translated">结论</h1><p id="5680" class="pw-post-body-paragraph jz ka it kb b kc nt ke kf kg nu ki kj kk nv km kn ko nw kq kr ks nx ku kv kw im bi translated">我希望我已经向你展示了简单的线性回归是如何工作的。运用统计学和简单数学。希望你喜欢阅读，欢迎在下面发表任何问题或意见</p><p id="dad2" class="pw-post-body-paragraph jz ka it kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw im bi translated">坚持练习。</p><p id="528b" class="pw-post-body-paragraph jz ka it kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw im bi translated">如需进一步学习，请查看这些来自<a class="ae lg" href="https://courses.cognitiveclass.ai/login?next=/courses/course-v1%3ACognitiveClass%2BML0101ENv3%2B2018/progress" rel="noopener ugc nofollow" target="_blank"> cognitiveclass.ai </a>的免费课程</p><ol class=""><li id="2828" class="pk pl it kb b kc kd kg kh kk pm ko pn ks po kw pp pq pr ps bi translated"><a class="ae lg" href="https://cognitiveclass.ai/courses/data-analysis-python/" rel="noopener ugc nofollow" target="_blank">用python进行数据分析</a></li><li id="2faa" class="pk pl it kb b kc pt kg pu kk pv ko pw ks px kw pp pq pr ps bi translated"><a class="ae lg" href="https://cognitiveclass.ai/courses/machine-learning-with-python/" rel="noopener ugc nofollow" target="_blank">用python进行机器学习</a></li></ol><p id="803d" class="pw-post-body-paragraph jz ka it kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw im bi translated">您可以在<a class="ae lg" href="https://github.com/Blackman9t/Machine_Learning/blob/master/understanding_the_maths_of_simple_linear_regression.ipynb" rel="noopener ugc nofollow" target="_blank"> Github </a>上找到本文的代码库</p><p id="a9ab" class="pw-post-body-paragraph jz ka it kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw im bi translated"><strong class="kb jd">干杯！！</strong></p><h2 id="ef30" class="ni mk it bd ml nj nk dn mp nl nm dp mt kk nn no mx ko np nq nb ks nr ns nf iz bi translated">关于我:</h2><p id="2a6d" class="pw-post-body-paragraph jz ka it kb b kc nt ke kf kg nu ki kj kk nv km kn ko nw kq kr ks nx ku kv kw im bi translated"><em class="lh"> Lawrence是技术层的数据专家，对公平可解释的人工智能和数据科学充满热情。我持有IBM的</em> <strong class="kb jd"> <em class="lh">数据科学专业</em> </strong> <em class="lh">和</em> <strong class="kb jd"> <em class="lh">高级数据科学专业</em> </strong> <em class="lh">证书。我已经使用ML和DL库进行了几个项目，我喜欢尽可能多地编写函数代码，即使现有的库比比皆是。最后，我从未停止学习和实验，是的，我拥有几个数据科学和人工智能认证，并且我已经写了几篇强烈推荐的文章。</em></p><p id="2aed" class="pw-post-body-paragraph jz ka it kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw im bi translated">请随时在以下网址找到我</p><p id="31dd" class="pw-post-body-paragraph jz ka it kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw im bi translated"><a class="ae lg" href="https://github.com/Lawrence-Krukrubo" rel="noopener ugc nofollow" target="_blank"> <strong class="kb jd"> Github </strong> </a></p><p id="f239" class="pw-post-body-paragraph jz ka it kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw im bi translated"><a class="ae lg" href="https://www.linkedin.com/in/lawrencekrukrubo/" rel="noopener ugc nofollow" target="_blank"> <strong class="kb jd">领英</strong> </a></p><p id="4257" class="pw-post-body-paragraph jz ka it kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw im bi translated"><a class="ae lg" href="https://twitter.com/LKrukrubo" rel="noopener ugc nofollow" target="_blank"> <strong class="kb jd">推特</strong> </a></p></div></div>    
</body>
</html>