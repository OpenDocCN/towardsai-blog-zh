<html>
<head>
<title>A Useful New Image Classification Method That Uses neither CNNs nor Attention</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">一种既不用CNN也不用注意力的有用的新图像分类方法</h1>
<blockquote>原文：<a href="https://pub.towardsai.net/a-useful-new-image-classification-method-that-uses-neither-cnns-nor-attention-b0f2952334bf?source=collection_archive---------2-----------------------#2021-05-19">https://pub.towardsai.net/a-useful-new-image-classification-method-that-uses-neither-cnns-nor-attention-b0f2952334bf?source=collection_archive---------2-----------------------#2021-05-19</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><h2 id="9b9a" class="io ip iq bd b dl ir is it iu iv iw dk ix translated" aria-label="kicker paragraph"><a class="ae ep" href="https://towardsai.net/p/category/computer-vision" rel="noopener ugc nofollow" target="_blank">计算机视觉</a></h2><div class=""/><div class=""><h2 id="d5ae" class="pw-subtitle-paragraph jw iz iq bd b jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn dk translated">[论文摘要] MLP密炼机</h2></div><p id="2907" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">在这篇文章中，我想介绍一下MLP混合器，它是由谷歌研究大脑团队(与视觉变形金刚(ViT)是同一团队)在2021年5月提出的。有趣的是，与最先进的模型(ViT和BiT)相比，基于ViT的MLP混合器可以在大数据集上训练快近三倍，并获得类似的结果。</p><p id="bea5" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">MLP混合器是基于多层感知器(MLP)，它迭代地应用于空间位置和特征通道，并作为一种既不使用CNN也不使用变压器的图像分类算法而受到关注。</p><p id="0bca" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">仅使用MLP的优点是架构简单和计算速度。此外，MLP混合器的计算复杂度与输入补片的数量成线性关系，不像视觉变换器(ViT)是输入补片数量的平方。</p><blockquote class="lk ll lm"><p id="f681" class="ko kp ln kq b kr ks ka kt ku kv kd kw lo ky kz la lp lc ld le lq lg lh li lj ij bi translated"><em class="iq">视觉变形金刚(ViT)延续了从模型中去除手工制作的视觉特征和归纳偏见的长期趋势，并进一步依赖于从原始数据中学习。</em></p><p id="5493" class="ko kp ln kq b kr ks ka kt ku kv kd kw lo ky kz la lp lc ld le lq lg lh li lj ij bi translated"><em class="iq">我们提出了MLP混合器，一种完全基于多层感知器(MLPs)的架构。MLP混合器包含两种类型的层:一种是MLPs独立应用于图像面片(即“混合”每个位置的特征)，另一种是MLPs跨面片应用(即“混合”空间信息)。</em></p><p id="0314" class="ko kp ln kq b kr ks ka kt ku kv kd kw lo ky kz la lp lc ld le lq lg lh li lj ij bi translated"><a class="ae lr" href="https://arxiv.org/abs/2105.01601" rel="noopener ugc nofollow" target="_blank"><em class="iq">https://arxiv.org/abs/2105.01601</em></a></p></blockquote><figure class="lt lu lv lw gt lx gh gi paragraph-image"><div role="button" tabindex="0" class="ly lz di ma bf mb"><div class="gh gi ls"><img src="../Images/ab69591b1537a92d96a6838bd21c00b6.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*WaqKjli0ls8720M573uQFA.jpeg"/></div></div><figcaption class="me mf gj gh gi mg mh bd b be z dk translated">图1: MLP混频器架构。</figcaption></figure><h1 id="7580" class="mi mj iq bd mk ml mm mn mo mp mq mr ms kf mt kg mu ki mv kj mw kl mx km my mz bi translated">点</h1><p id="3efb" class="pw-post-body-paragraph ko kp iq kq b kr na ka kt ku nb kd kw kx nc kz la lb nd ld le lf ne lh li lj ij bi translated">基于简单多层感知器(MLP)的模型与CNN和注意力模型竞争，在大型数据集(1亿个图像数据集)上速度快3倍。</p><p id="70e9" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">MLP混频器架构基于多层感知器(MLP)，仅依赖基本矩阵乘法例程、数据布局修改(整形和转置)和标量非线性。</p><p id="a5c7" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">当在大型数据集(约1亿张图像)上进行预训练时，它达到了与CNN和transformers相当的性能，并在准确性和成本之间进行了权衡。</p><h1 id="e6f5" class="mi mj iq bd mk ml mm mn mo mp mq mr ms kf mt kg mu ki mv kj mw kl mx km my mz bi translated">MLP混频器架构</h1><p id="edcd" class="pw-post-body-paragraph ko kp iq kq b kr na ka kt ku nb kd kw kx nc kz la lb nd ld le lf ne lh li lj ij bi translated">如图2所示，MLP混合器在体系结构上类似于视觉变压器(ViT ),不使用自我注意。类似于ViT，MLP混合器首先将输入图像分成小的迷你小块，然后将所有小块馈送到全连接层，以获得潜在的嵌入表示。换句话说，图像中的每个小块对应一个向量。</p><div class="lt lu lv lw gt ab cb"><figure class="nf lx ng nh ni nj nk paragraph-image"><div role="button" tabindex="0" class="ly lz di ma bf mb"><img src="../Images/5201765484a2059a549e9eeeffcd5f6c.png" data-original-src="https://miro.medium.com/v2/resize:fit:848/format:webp/1*ZTAZBgw4NEEfgZVGOpi4gg.png"/></div></figure><figure class="nf lx nl nh ni nj nk paragraph-image"><div role="button" tabindex="0" class="ly lz di ma bf mb"><img src="../Images/75f4b8dac5b33a05ef2af622a0f7c7a6.png" data-original-src="https://miro.medium.com/v2/resize:fit:1154/format:webp/1*vq0qBTUFO27cJMPQo0h6xg.png"/></div><figcaption class="me mf gj gh gi mg mh bd b be z dk nm di nn no translated">图2:(从左至右)视觉变压器(ViT)架构，MLP混频器架构。</figcaption></figure></div><p id="0039" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">如图3所示，MLP混合器由每个面片的线性嵌入、MLP混合器块和图像类别分类器组成。与视觉转换器(ViT)相比，MLP混合器模块不使用位置嵌入。这是由于下面描述的令牌混合MLP的特性。</p><figure class="lt lu lv lw gt lx gh gi paragraph-image"><div role="button" tabindex="0" class="ly lz di ma bf mb"><div class="gh gi np"><img src="../Images/41d601508db9035be5dcef04ee90b06c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*vq0qBTUFO27cJMPQo0h6xg.png"/></div></div><figcaption class="me mf gj gh gi mg mh bd b be z dk translated">图3:MLP混频器的结构。</figcaption></figure><p id="00db" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">该模型以线性投影的图像斑块作为输入，并保持“斑块×通道”的维数；如图4所示，MLP混频器由两层MLP组成，即信道混合MLP和令牌混合MLP，并且该块被表示为混频器层。混合器层仅依赖于基本的矩阵乘法、数据布局修改(形状改变和换位)和标量非线性。</p><figure class="lt lu lv lw gt lx gh gi paragraph-image"><div role="button" tabindex="0" class="ly lz di ma bf mb"><div class="gh gi ls"><img src="../Images/17aa6550c23aa9f8c89773a6d9e6a2a9.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*P5mbq378HtC4gEbCamE4Rw.png"/></div></div><figcaption class="me mf gj gh gi mg mh bd b be z dk translated">图4:混合器层的细节:令牌混合MLP(绿色部分)，通道混合MLP(橙色部分)。</figcaption></figure><p id="176f" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">令牌混合MLP和通道混合MLP允许补丁和通道输入维度的交互。</p><h2 id="45f1" class="nq mj iq bd mk nr ns dn mo nt nu dp ms kx nv nw mu lb nx ny mw lf nz oa my iw bi translated">令牌混合MLP；混合具有不同空间位置的面片的特征</h2><p id="1879" class="pw-post-body-paragraph ko kp iq kq b kr na ka kt ku nb kd kw kx nc kz la lb nd ld le lf ne lh li lj ij bi translated">令牌混合MLP(绿色)对输入数据的每一列进行转置，并在所有行之间共享相同的MLP权重。因此，图像中所有面片的通道都是1，并且完全连接层中的所有权重都是共享的。因此，不同的面片共享相同的通道权重。要混合面片，请使用单通道深度卷积。</p><h2 id="0db2" class="nq mj iq bd mk nr ns dn mo nt nu dp ms kx nv nw mu lb nx ny mw lf nz oa my iw bi translated">通道混合MLP；混合不同频道的功能</h2><p id="2732" class="pw-post-body-paragraph ko kp iq kq b kr na ka kt ku nb kd kw kx nc kz la lb nd ld le lf ne lh li lj ij bi translated">通道混合MLP(橙色部分)再次转置每一行输入数据，并再次将其转换为面片。然后，所有面片共享MLP权重。因此，不同的信道共享相同的信道权重。要混合通道，请使用1x1卷积。</p><h1 id="9d3f" class="mi mj iq bd mk ml mm mn mo mp mq mr ms kf mt kg mu ki mv kj mw kl mx km my mz bi translated">实验结果</h1><p id="6380" class="pw-post-body-paragraph ko kp iq kq b kr na ka kt ku nb kd kw kx nc kz la lb nd ld le lf ne lh li lj ij bi translated">如下表所示，与ViT和BiT等最先进的图像分类方法相比，所提出的方法以更低的计算成本实现了相同水平的精度。</p><figure class="lt lu lv lw gt lx gh gi paragraph-image"><div role="button" tabindex="0" class="ly lz di ma bf mb"><div class="gh gi ob"><img src="../Images/fc4eb62875b2cedf448b4cfe081f3b8b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*JMPH2ysnq_xQwMT71UZ3fw.png"/></div></div></figure><p id="e190" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">此外，从图中可以看出，MLP混合器在数据集大小和图像分类精度方面都有显著提高。随着数据集大小的增加，分类精度变得与ViT相当。</p><figure class="lt lu lv lw gt lx gh gi paragraph-image"><div class="gh gi oc"><img src="../Images/c41bf462bd83f1d02eb5bca30c87875a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1172/format:webp/1*GJUN6EDNuwESefe5QkfPjw.png"/></div></figure><h1 id="9388" class="mi mj iq bd mk ml mm mn mo mp mq mr ms kf mt kg mu ki mv kj mw kl mx km my mz bi translated">结论</h1><p id="6bea" class="pw-post-body-paragraph ko kp iq kq b kr na ka kt ku nb kd kw kx nc kz la lb nd ld le lf ne lh li lj ij bi translated">MLP混合器是一种基于称为多层感知器(MLP)的非常简单的模型的网络，但它提出了一些非常有趣的结果，例如训练的低计算成本和随着数据大小的增加而提高的分类精度。</p><p id="e99e" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">谷歌研究，大脑团队还陈述了以下内容。</p><blockquote class="lk ll lm"><p id="a027" class="ko kp ln kq b kr ks ka kt ku kv kd kw lo ky kz la lp lc ld le lq lg lh li lj ij bi translated"><em class="iq">有希望的是，这些结果引发了进一步的研究，超越了基于卷积和自我关注转换器的成熟模型的领域</em></p></blockquote><h1 id="5298" class="mi mj iq bd mk ml mm mn mo mp mq mr ms kf mt kg mu ki mv kj mw kl mx km my mz bi translated">参考</h1><p id="6fb5" class="pw-post-body-paragraph ko kp iq kq b kr na ka kt ku nb kd kw kx nc kz la lb nd ld le lf ne lh li lj ij bi translated">https://arxiv.org/abs/2105.01601MLP<a class="ae lr" href="https://arxiv.org/abs/2105.01601" rel="noopener ugc nofollow" target="_blank"/></p><p id="0dea" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">https://arxiv.org/abs/2010.11929的<a class="ae lr" href="https://arxiv.org/abs/2010.11929" rel="noopener ugc nofollow" target="_blank"/></p><p id="7f5a" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated"><a class="ae lr" href="https://github.com/rwightman/pytorch-image-models/blob/master/timm/models/mlp_mixer.py" rel="noopener ugc nofollow" target="_blank">https://github . com/rwightman/py torch-image-models/blob/master/timm/models/MLP _ mixer . py</a></p></div></div>    
</body>
</html>