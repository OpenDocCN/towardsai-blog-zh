<html>
<head>
<title>An End-to-End Comprehensive Summary of Machine Learning</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">机器学习的端到端综合总结</h1>
<blockquote>原文：<a href="https://pub.towardsai.net/an-end-to-end-comprehensive-summary-of-machine-learning-df30fa149c94?source=collection_archive---------0-----------------------#2020-05-26">https://pub.towardsai.net/an-end-to-end-comprehensive-summary-of-machine-learning-df30fa149c94?source=collection_archive---------0-----------------------#2020-05-26</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><figure class="ip iq gp gr ir is gh gi paragraph-image"><div role="button" tabindex="0" class="it iu di iv bf iw"><div class="gh gi io"><img src="../Images/284d8f8812f19e95a6df0d03c25c243b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*ZTSPd7GOziRlmceUxjIk9w.jpeg"/></div></div><figcaption class="iz ja gj gh gi jb jc bd b be z dk translated">照片由<a class="ae jd" href="https://unsplash.com/s/photos/machine-learning?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上的<a class="ae jd" href="https://unsplash.com/@heyerlein?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText" rel="noopener ugc nofollow" target="_blank"> h heyerlein </a>拍摄</figcaption></figure><h2 id="7cf3" class="je jf jg bd b dl jh ji jj jk jl jm dk jn translated" aria-label="kicker paragraph">机器学习</h2><div class=""/><div class=""><h2 id="bd3d" class="pw-subtitle-paragraph km jp jg bd b kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld dk translated">机器学习概念和实际实现技巧的备忘单</h2></div><h1 id="728b" class="le lf jg bd lg lh li lj lk ll lm ln lo kv lp kw lq ky lr kz ls lb lt lc lu lv bi translated">介绍</h1><p id="0596" class="pw-post-body-paragraph lw lx jg ly b lz ma kq mb mc md kt me mf mg mh mi mj mk ml mm mn mo mp mq mr ij bi translated">如果你是机器学习领域的新手，并且希望快速熟悉机器学习的所有概念，而不会被背景中复杂的数学知识所淹没，那么请阅读这篇文章。</p><p id="a81e" class="pw-post-body-paragraph lw lx jg ly b lz ms kq mb mc mt kt me mf mu mh mi mj mv ml mm mn mw mp mq mr ij bi translated">这篇文章包含了机器学习的关键概念，这些概念是基于我从多种来源获得的知识，特别是从<a class="ae jd" href="https://en.wikipedia.org/wiki/Andrew_Ng" rel="noopener ugc nofollow" target="_blank">吴恩达教授的</a>机器学习在线课程和课堂讲座中获得的知识，这些课程和讲座带有链接，可供感兴趣的人进一步阅读。</p><p id="b1ef" class="pw-post-body-paragraph lw lx jg ly b lz ms kq mb mc mt kt me mf mu mh mi mj mv ml mm mn mw mp mq mr ij bi translated">我希望这可以作为新机器学习爱好者的一个去处，也可以作为那些想用一些关键的实现技巧刷新他们对什么是机器学习的想法的人的一个去处。</p><p id="9816" class="pw-post-body-paragraph lw lx jg ly b lz ms kq mb mc mt kt me mf mu mh mi mj mv ml mm mn mw mp mq mr ij bi translated">请原谅我这篇文章有点长，但它是可以理解的，值得你花时间，因为它几乎触及了机器学习的每个主要概念。</p><p id="d078" class="pw-post-body-paragraph lw lx jg ly b lz ms kq mb mc mt kt me mf mu mh mi mj mv ml mm mn mw mp mq mr ij bi translated">这篇文章被分成几天，只是为了那些喜欢慢慢来的人。你可以阅读一天的重点，然后尝试进一步研究，并根据这些概念实施一个项目。这给了它结构。</p><p id="3827" class="pw-post-body-paragraph lw lx jg ly b lz ms kq mb mc mt kt me mf mu mh mi mj mv ml mm mn mw mp mq mr ij bi translated">所以不用浪费你太多时间，让我们开始吧。</p><h1 id="7d1e" class="le lf jg bd lg lh li lj lk ll lm ln lo kv lp kw lq ky lr kz ls lb lt lc lu lv bi translated">第一天亮点</h1><figure class="my mz na nb gt is gh gi paragraph-image"><div role="button" tabindex="0" class="it iu di iv bf iw"><div class="gh gi mx"><img src="../Images/2044742c241fb4cd07a5b84a14a77147.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*o61WcjIPFCHyOSAZa9Yqgg.png"/></div></div><figcaption class="iz ja gj gh gi jb jc bd b be z dk translated">图片来自Coursera</figcaption></figure><h1 id="46ff" class="le lf jg bd lg lh li lj lk ll lm ln lo kv lp kw lq ky lr kz ls lb lt lc lu lv bi translated">什么是机器学习？</h1><p id="d2e9" class="pw-post-body-paragraph lw lx jg ly b lz ma kq mb mc md kt me mf mg mh mi mj mk ml mm mn mo mp mq mr ij bi translated">机器学习是人工智能的一个分支，它为计算机系统提供了自动学习和根据经验改进的能力，而无需显式编程。</p><p id="0709" class="pw-post-body-paragraph lw lx jg ly b lz ms kq mb mc mt kt me mf mu mh mi mj mv ml mm mn mw mp mq mr ij bi translated">它大致分为两大类:<strong class="ly jq">有监督的和无监督的。</strong>此外，我们还遇到了<strong class="ly jq">异常检测</strong>问题，这些问题结合了监督和非监督技术。</p><h1 id="6853" class="le lf jg bd lg lh li lj lk ll lm ln lo kv lp kw lq ky lr kz ls lb lt lc lu lv bi translated">监督学习。</h1><p id="dbf4" class="pw-post-body-paragraph lw lx jg ly b lz ma kq mb mc md kt me mf mg mh mi mj mk ml mm mn mo mp mq mr ij bi translated">在监督学习中，学习算法(模型)是用标记数据训练的。机器学习算法(模型)通过迭代过程从这些标记的数据中学习，然后使其能够对新的未知数据进行预测。</p><p id="07e9" class="pw-post-body-paragraph lw lx jg ly b lz ms kq mb mc mt kt me mf mu mh mi mj mv ml mm mn mw mp mq mr ij bi translated">监督学习进一步分为<strong class="ly jq">回归和分类问题。</strong></p><h2 id="0a9f" class="nc lf jg bd lg nd ne dn lk nf ng dp lo mf nh ni lq mj nj nk ls mn nl nm lu jm bi translated">线性回归分析。</h2><p id="5997" class="pw-post-body-paragraph lw lx jg ly b lz ma kq mb mc md kt me mf mg mh mi mj mk ml mm mn mo mp mq mr ij bi translated">在回归问题中，模型预测的输出变量是一个数值。例如，预测纽约市的房价，或者预测某个州的能源消耗量。</p><h2 id="7d72" class="nc lf jg bd lg nd ne dn lk nf ng dp lo mf nh ni lq mj nj nk ls mn nl nm lu jm bi translated">线性回归的目的。</h2><p id="ec92" class="pw-post-body-paragraph lw lx jg ly b lz ma kq mb mc md kt me mf mg mh mi mj mk ml mm mn mo mp mq mr ij bi translated">在线性回归中，目标非常简单。</p><p id="cf0a" class="pw-post-body-paragraph lw lx jg ly b lz ms kq mb mc mt kt me mf mu mh mi mj mv ml mm mn mw mp mq mr ij bi translated">给定一个标有训练集的m-training例子，目的是<em class="nn"> </em> <strong class="ly jq"> <em class="nn">找到使代价函数</em> </strong> <em class="nn">最小的模型参数。这将很快变得非常清楚。</em></p><p id="f543" class="pw-post-body-paragraph lw lx jg ly b lz ms kq mb mc mt kt me mf mu mh mi mj mv ml mm mn mw mp mq mr ij bi translated">回归可以是<strong class="ly jq">单变量或多变量。</strong></p><h2 id="347d" class="nc lf jg bd lg nd ne dn lk nf ng dp lo mf nh ni lq mj nj nk ls mn nl nm lu jm bi translated">一元线性回归。</h2><p id="094a" class="pw-post-body-paragraph lw lx jg ly b lz ma kq mb mc md kt me mf mg mh mi mj mk ml mm mn mo mp mq mr ij bi translated">单变量简单地说就是单个变量(特征)。用于训练线性回归模型的输入示例X(i)是单值或一维向量的回归问题是单变量线性回归问题。</p><p id="138e" class="pw-post-body-paragraph lw lx jg ly b lz ms kq mb mc mt kt me mf mu mh mi mj mv ml mm mn mw mp mq mr ij bi translated">这是一个带有单个变量(年龄)和相应输出(体重)的带标签训练数据集的示例。仅给出个体的年龄，该模型旨在预测个体的体重。</p><figure class="my mz na nb gt is gh gi paragraph-image"><div class="gh gi no"><img src="../Images/b92803ef236f709d249af956ce51e394.png" data-original-src="https://miro.medium.com/v2/resize:fit:374/format:webp/1*FVkO22CzPi_KgD-_qnVZYQ.png"/></div><figcaption class="iz ja gj gh gi jb jc bd b be z dk translated">图像单变量数据集</figcaption></figure><p id="16d1" class="pw-post-body-paragraph lw lx jg ly b lz ms kq mb mc mt kt me mf mu mh mi mj mv ml mm mn mw mp mq mr ij bi translated">从技术上讲，下图总结了一个线性回归模型。在这种情况下，它是一个单变量模型，因为X是一个值，而不是一个向量。</p><figure class="my mz na nb gt is gh gi paragraph-image"><div class="gh gi np"><img src="../Images/345021d2f409eef1b68a1a15e9621878.png" data-original-src="https://miro.medium.com/v2/resize:fit:1342/format:webp/1*cjbBETGjnEur1OQ4wWqMzA.png"/></div><figcaption class="iz ja gj gh gi jb jc bd b be z dk translated">来源:程序员搜索</figcaption></figure><p id="003b" class="pw-post-body-paragraph lw lx jg ly b lz ms kq mb mc mt kt me mf mu mh mi mj mv ml mm mn mw mp mq mr ij bi translated">出现的问题是，</p><blockquote class="nq"><p id="4773" class="nr ns jg bd nt nu nv nw nx ny nz mr dk translated">我们如何找到产生成本函数最小值的模型参数(θ)的值？</p></blockquote><p id="e7a6" class="pw-post-body-paragraph lw lx jg ly b lz oa kq mb mc ob kt me mf oc mh mi mj od ml mm mn oe mp mq mr ij bi translated">幸运的是，梯度下降的出现让我们不再头疼。</p><h2 id="6849" class="nc lf jg bd lg nd ne dn lk nf ng dp lo mf nh ni lq mj nj nk ls mn nl nm lu jm bi translated">梯度下降</h2><p id="75f1" class="pw-post-body-paragraph lw lx jg ly b lz ma kq mb mc md kt me mf mg mh mi mj mk ml mm mn mo mp mq mr ij bi translated">梯度下降是一种通用算法，用于最小化不同类型的函数。在线性回归中，我们使用梯度下降算法来自动地和同时地更新模型参数。T13】</p><p id="c85a" class="pw-post-body-paragraph lw lx jg ly b lz ms kq mb mc mt kt me mf mu mh mi mj mv ml mm mn mw mp mq mr ij bi translated">这是一种迭代算法。对于每次迭代，评估成本函数的导数并更新模型参数。这样做，直到达到成本函数的有希望的收敛，即找到全局最优。</p><figure class="my mz na nb gt is gh gi paragraph-image"><div class="gh gi of"><img src="../Images/10381d70d811d16d878eedfe6e626d4a.png" data-original-src="https://miro.medium.com/v2/resize:fit:940/format:webp/1*yspUVJRu0zVzFbYBv3M56Q.png"/></div><figcaption class="iz ja gj gh gi jb jc bd b be z dk translated">梯度下降算法</figcaption></figure><p id="2bd7" class="pw-post-body-paragraph lw lx jg ly b lz ms kq mb mc mt kt me mf mu mh mi mj mv ml mm mn mw mp mq mr ij bi translated">构成梯度下降算法的两个基本要素是<strong class="ly jq"> <em class="nn">学习速率</em> </strong>和<strong class="ly jq"> <em class="nn">成本函数的偏导数。</em> </strong></p><figure class="my mz na nb gt is gh gi paragraph-image"><div role="button" tabindex="0" class="it iu di iv bf iw"><div class="gh gi og"><img src="../Images/830ad0931743e0d1e57cff262b6d998a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*rSbJqpqqeJ6NMPsRc4iIZQ.png"/></div></div><figcaption class="iz ja gj gh gi jb jc bd b be z dk translated">梯度下降图解:来源:Coursera</figcaption></figure><p id="bf39" class="pw-post-body-paragraph lw lx jg ly b lz ms kq mb mc mt kt me mf mu mh mi mj mv ml mm mn mw mp mq mr ij bi translated">学习率(alpha)也决定了在更新模型参数<em class="nn">时，我们采用<strong class="ly jq">的多少步长</strong>。</em>上面<strong class="ly jq"> <em class="nn">求和项表示的偏导数项给出了最陡斜率的方向。</em>T29】</strong></p><p id="cec2" class="pw-post-body-paragraph lw lx jg ly b lz ms kq mb mc mt kt me mf mu mh mi mj mv ml mm mn mw mp mq mr ij bi translated">注意:记住，函数在某一点的导数是与通过该点的函数相切的直线的斜率。</p><p id="f507" class="pw-post-body-paragraph lw lx jg ly b lz ms kq mb mc mt kt me mf mu mh mi mj mv ml mm mn mw mp mq mr ij bi translated"><strong class="ly jq">梯度下降的关键注释</strong></p><p id="1cce" class="pw-post-body-paragraph lw lx jg ly b lz ms kq mb mc mt kt me mf mu mh mi mj mv ml mm mn mw mp mq mr ij bi translated">如果alpha超参数太小，梯度下降会变得太慢，因为收敛到局部最小值需要很多时间。这是因为更新的θ参数是通过下山的小步增加的。</p><p id="8c4c" class="pw-post-body-paragraph lw lx jg ly b lz ms kq mb mc mt kt me mf mu mh mi mj mv ml mm mn mw mp mq mr ij bi translated">如果阿尔法太大，我们可能会超调，甚至发散。也就是说，我们可能会跳过最小值，永远不会收敛。</p><p id="8f97" class="pw-post-body-paragraph lw lx jg ly b lz ms kq mb mc mt kt me mf mu mh mi mj mv ml mm mn mw mp mq mr ij bi translated">这里解释的这种梯度下降算法又称为<strong class="ly jq"> <em class="nn">【批量梯度下降】，</em> </strong>为算法在每次模型参数的更新迭代过程中使用所有的训练样本。</p><p id="5434" class="pw-post-body-paragraph lw lx jg ly b lz ms kq mb mc mt kt me mf mu mh mi mj mv ml mm mn mw mp mq mr ij bi translated">这里有一些文章的链接，包括我的文章，可以拓宽你对基本概念的理解</p><blockquote class="oh oi oj"><p id="4dec" class="lw lx nn ly b lz ms kq mb mc mt kt me ok mu mh mi ol mv ml mm om mw mp mq mr ij bi translated"><a class="ae jd" href="https://towardsdatascience.com/linear-regression-detailed-view-ea73175f6e86" rel="noopener" target="_blank"> <em class="jg">线性回归</em> </a>详细查看文章中由<a class="ae jd" href="https://towardsdatascience.com/@saishruthi.tn?source=post_page-----ea73175f6e86----------------------" rel="noopener" target="_blank"> Saishruthi </a></p><p id="ab05" class="lw lx nn ly b lz ms kq mb mc mt kt me ok mu mh mi ol mv ml mm om mw mp mq mr ij bi translated"><a class="ae jd" href="https://towardsdatascience.com/supervised-and-unsupervised-learning-for-everyone-526f9b746dd5?source=your_stories_page---------------------------" rel="noopener" target="_blank">针对每个人的监督和非监督学习</a></p></blockquote><blockquote class="nq"><p id="394e" class="nr ns jg bd nt nu on oo op oq or mr dk translated">第一天结束了！！</p></blockquote><h1 id="bd18" class="le lf jg bd lg lh li lj lk ll lm ln lo kv os kw lq ky ot kz ls lb ou lc lu lv bi translated">**第二天亮点**</h1><h2 id="f483" class="nc lf jg bd lg nd ne dn lk nf ng dp lo mf nh ni lq mj nj nk ls mn nl nm lu jm bi translated">多特征线性回归</h2><p id="e14a" class="pw-post-body-paragraph lw lx jg ly b lz ma kq mb mc md kt me mf mg mh mi mj mk ml mm mn mo mp mq mr ij bi translated">当我们在每个训练示例的训练数据中有多个特征用于预测时，每个训练示例现在都变成一个向量，而不是单个值。具体而言，在这种情况下，每个训练示例变成n维特征向量，其中n =训练集中的特征数量。</p><p id="a070" class="pw-post-body-paragraph lw lx jg ly b lz ms kq mb mc mt kt me mf mu mh mi mj mv ml mm mn mw mp mq mr ij bi translated">这就是所谓的<strong class="ly jq">多元线性回归。</strong>多元简单来说就是多个变量或特征。下面显示了一个数据集示例，其中每个训练示例的特征数n为四(4)，带标签的输出为工资增长。</p><figure class="my mz na nb gt is gh gi paragraph-image"><div class="gh gi ov"><img src="../Images/7353f1ab2e9aafca1962968597a85cda.png" data-original-src="https://miro.medium.com/v2/resize:fit:1080/format:webp/1*13f6Q38yjozbDVZYZaS2Nw.png"/></div><figcaption class="iz ja gj gh gi jb jc bd b be z dk translated">具有多个特征的训练数据集的图像</figcaption></figure><p id="b94a" class="pw-post-body-paragraph lw lx jg ly b lz ms kq mb mc mt kt me mf mu mh mi mj mv ml mm mn mw mp mq mr ij bi translated">多元线性回归的假设是一元线性回归的扩展，如下所示，其中n =要素数。</p><figure class="my mz na nb gt is gh gi paragraph-image"><div role="button" tabindex="0" class="it iu di iv bf iw"><div class="gh gi ow"><img src="../Images/361d1943c91dc3f4f99e6557cef085ba.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*vdMyKanmMBJWJ3JFt-Lb8Q.png"/></div></div><figcaption class="iz ja gj gh gi jb jc bd b be z dk translated">多元线性回归假设和成本函数</figcaption></figure><p id="66f4" class="pw-post-body-paragraph lw lx jg ly b lz ms kq mb mc mt kt me mf mu mh mi mj mv ml mm mn mw mp mq mr ij bi translated">这意味着特征<strong class="ly jq"> i </strong>的单位变化对应于假设中的变化bi。例如房价。</p><p id="5a66" class="pw-post-body-paragraph lw lx jg ly b lz ms kq mb mc mt kt me mf mu mh mi mj mv ml mm mn mw mp mq mr ij bi translated">在多元线性回归的梯度下降中，成本函数J简单地随着模型参数(θ)的数量而变化，如上图所示。</p><p id="90af" class="pw-post-body-paragraph lw lx jg ly b lz ms kq mb mc mt kt me mf mu mh mi mj mv ml mm mn mw mp mq mr ij bi translated">在回归中，我们经常在成本函数中添加一个正则项，这有助于我们避免过度拟合我们的模型，如下所示。关于这一点的更多信息可以在我将在最后分享的附加链接中找到。</p><figure class="my mz na nb gt is gh gi paragraph-image"><div class="gh gi ox"><img src="../Images/cd1c63258b6174a3750030602362089b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1058/format:webp/1*pcIH5dnYihxD21WlPUxZtA.png"/></div><figcaption class="iz ja gj gh gi jb jc bd b be z dk translated">带有正则项的代价函数。</figcaption></figure><h2 id="0cf1" class="nc lf jg bd lg nd ne dn lk nf ng dp lo mf nh ni lq mj nj nk ls mn nl nm lu jm bi translated">特征缩放</h2><p id="4069" class="pw-post-body-paragraph lw lx jg ly b lz ma kq mb mc md kt me mf mg mh mi mj mk ml mm mn mo mp mq mr ij bi translated">这是两种常见技术之一，旨在将所有特征的范围调整为相同或彼此接近。</p><p id="94a6" class="pw-post-body-paragraph lw lx jg ly b lz ms kq mb mc mt kt me mf mu mh mi mj mv ml mm mn mw mp mq mr ij bi translated">特征缩放有助于梯度下降算法<strong class="ly jq"> <em class="nn">收敛得更快，迭代次数更少，也更正确。</em> </strong>如果数值范围太小，则放大或缩小。</p><h2 id="bb0b" class="nc lf jg bd lg nd ne dn lk nf ng dp lo mf nh ni lq mj nj nk ls mn nl nm lu jm bi translated">均值归一化</h2><p id="71e4" class="pw-post-body-paragraph lw lx jg ly b lz ma kq mb mc md kt me mf mg mh mi mj mk ml mm mn mo mp mq mr ij bi translated">这是另一种主要用于特征缩放的技术。</p><figure class="my mz na nb gt is gh gi paragraph-image"><div role="button" tabindex="0" class="it iu di iv bf iw"><div class="gh gi oy"><img src="../Images/b659bfbbaac23bf2033dc1584d160c07.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*CyUjHiFFRjk3M_yJ_VeDsw.jpeg"/></div></div><figcaption class="iz ja gj gh gi jb jc bd b be z dk translated">图片由wallstreetmojo.com拍摄</figcaption></figure><h2 id="6241" class="nc lf jg bd lg nd ne dn lk nf ng dp lo mf nh ni lq mj nj nk ls mn nl nm lu jm bi translated">确定梯度何时收敛。</h2><p id="2086" class="pw-post-body-paragraph lw lx jg ly b lz ma kq mb mc md kt me mf mg mh mi mj mk ml mm mn mo mp mq mr ij bi translated">绘制成本函数J(θ)与梯度下降算法执行的迭代次数的关系图是确定梯度下降是否收敛的一种很好的实用方法。</p><p id="6065" class="pw-post-body-paragraph lw lx jg ly b lz ms kq mb mc mt kt me mf mu mh mi mj mv ml mm mn mw mp mq mr ij bi translated">学习率 的<strong class="ly jq"> <em class="nn">小值导致<strong class="ly jq"> <em class="nn">非常缓慢的收敛</em> </strong>，即，达到成本函数的全局最优需要很长时间。<br/>另一方面，如果<strong class="ly jq"> <em class="nn">学习率过大，</em> </strong>代价函数<strong class="ly jq"> <em class="nn">可能不会在每次迭代中减少</em> </strong>，甚至会<strong class="ly jq"><em class="nn"/></strong></em></strong></p><h2 id="dd99" class="nc lf jg bd lg nd ne dn lk nf ng dp lo mf nh ni lq mj nj nk ls mn nl nm lu jm bi translated">正规方程技术</h2><p id="eae7" class="pw-post-body-paragraph lw lx jg ly b lz ma kq mb mc md kt me mf mg mh mi mj mk ml mm mn mo mp mq mr ij bi translated">这是一种用于求解模型参数值的技术，其在分析上最小化成本函数。它不像梯度下降那样执行迭代过程，我们不选择任何学习速率。</p><figure class="my mz na nb gt is gh gi paragraph-image"><div class="gh gi oz"><img src="../Images/e558d824ef2268f39bc9a38bf279bc13.png" data-original-src="https://miro.medium.com/v2/resize:fit:506/format:webp/1*w6M0avkhKBzm15aH65ZL-w.png"/></div><figcaption class="iz ja gj gh gi jb jc bd b be z dk translated">正规方程公式</figcaption></figure><p id="1e5b" class="pw-post-body-paragraph lw lx jg ly b lz ms kq mb mc mt kt me mf mu mh mi mj mv ml mm mn mw mp mq mr ij bi translated">对于非常大量的特征，即n = 10000+而言，正规方程在计算上变得昂贵，因为我们需要<strong class="ly jq"> <em class="nn">计算矩阵逆</em> </strong>，这对于大型矩阵来说是相当昂贵的过程。在这种情况下，梯度下降是最好的选择。</p><h2 id="778b" class="nc lf jg bd lg nd ne dn lk nf ng dp lo mf nh ni lq mj nj nk ls mn nl nm lu jm bi translated">关键音符</h2><blockquote class="oh oi oj"><p id="db2a" class="lw lx nn ly b lz ms kq mb mc mt kt me ok mu mh mi ol mv ml mm om mw mp mq mr ij bi translated">如果正规方程的X . TX矩阵是不可逆的，即它是奇异的或退化的，那么这意味着两件主要的事情</p><p id="4300" class="lw lx nn ly b lz ms kq mb mc mt kt me ok mu mh mi ol mv ml mm om mw mp mq mr ij bi translated">*冗余特征—线性相关特征<br/> *特征过多</p></blockquote><p id="cae3" class="pw-post-body-paragraph lw lx jg ly b lz ms kq mb mc mt kt me mf mu mh mi mj mv ml mm mn mw mp mq mr ij bi translated"><a class="ae jd" href="https://towardsdatascience.com/all-about-feature-scaling-bcc0ad75cb35" rel="noopener" target="_blank">这里</a>是一篇关于特征缩放的好文章。</p><blockquote class="nq"><p id="a09c" class="nr ns jg bd nt nu nv nw nx ny nz mr dk translated">第二天结束了！！</p></blockquote><h1 id="579e" class="le lf jg bd lg lh li lj lk ll lm ln lo kv os kw lq ky ot kz ls lb ou lc lu lv bi translated">**第三天亮点**</h1><h1 id="e8bf" class="le lf jg bd lg lh li lj lk ll lm ln lo kv lp kw lq ky lr kz ls lb lt lc lu lv bi translated">分类</h1><figure class="my mz na nb gt is gh gi paragraph-image"><div role="button" tabindex="0" class="it iu di iv bf iw"><div class="gh gi pa"><img src="../Images/ace78c88ff4e960e84528355dc0f0a0d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*jX-Q3ntEiiZz5cAekx3jOg.jpeg"/></div></div><figcaption class="iz ja gj gh gi jb jc bd b be z dk translated">来源:<a class="ae jd" href="https://www.wkrg.com/northwest-florida/new-penalties-for-animal-abusers-take-effect-monday-in-florida/" rel="noopener ugc nofollow" target="_blank">https://www . wkrg . com/northwestern-Florida/new-penalty-for-animal-breakers-take-effect-Monday-in-Florida/</a></figcaption></figure><p id="38fe" class="pw-post-body-paragraph lw lx jg ly b lz ms kq mb mc mt kt me mf mu mh mi mj mv ml mm mn mw mp mq mr ij bi translated">在分类中，目标是识别一个对象(输入)属于哪个类别。例如，我们可能有兴趣确定图像是否包含<strong class="ly jq">狗或猫</strong>，颜色<strong class="ly jq">红色或黑色</strong>，电子邮件<strong class="ly jq">垃圾邮件，或真正的</strong>，患者是否携带<strong class="ly jq">艾滋病毒</strong>。</p><p id="9448" class="pw-post-body-paragraph lw lx jg ly b lz ms kq mb mc mt kt me mf mu mh mi mj mv ml mm mn mw mp mq mr ij bi translated">用于解决机器学习中的分类问题的一个非常常见的模型是逻辑回归。</p><h2 id="3b93" class="nc lf jg bd lg nd ne dn lk nf ng dp lo mf nh ni lq mj nj nk ls mn nl nm lu jm bi translated">逻辑回归</h2><p id="ed59" class="pw-post-body-paragraph lw lx jg ly b lz ma kq mb mc md kt me mf mg mh mi mj mk ml mm mn mo mp mq mr ij bi translated">这是一种基于sigmoid或逻辑函数的分类算法，其值压缩在0和1之间。</p><div class="my mz na nb gt ab cb"><figure class="pb is pc pd pe pf pg paragraph-image"><img src="../Images/53fabb6a8f5e8d17cd92f664acd6905e.png" data-original-src="https://miro.medium.com/v2/resize:fit:584/format:webp/1*2SXHmTmrjwWTdaRV4A3Nyg.png"/></figure><figure class="pb is ph pd pe pf pg paragraph-image"><div role="button" tabindex="0" class="it iu di iv bf iw"><img src="../Images/ad9a8f2ea667760d99b44e6dcc035ed9.png" data-original-src="https://miro.medium.com/v2/resize:fit:1234/format:webp/1*YuabQiGBA-W-5PWsojwN5A.png"/></div><figcaption class="iz ja gj gh gi jb jc bd b be z dk pi di pj pk translated">资料来源:Researchgate.net</figcaption></figure></div><p id="ec67" class="pw-post-body-paragraph lw lx jg ly b lz ms kq mb mc mt kt me mf mu mh mi mj mv ml mm mn mw mp mq mr ij bi translated">如上图所示，h(x) = g(z)是用于计算0到1范围内的输出值或概率的假设函数或sigmoid函数。</p><p id="faa8" class="pw-post-body-paragraph lw lx jg ly b lz ms kq mb mc mt kt me mf mu mh mi mj mv ml mm mn mw mp mq mr ij bi translated">我们的逻辑函数的行为方式是，当其输入z大于或等于零时，其输出g(z)大于或等于0.5:</p><h2 id="94b5" class="nc lf jg bd lg nd ne dn lk nf ng dp lo mf nh ni lq mj nj nk ls mn nl nm lu jm bi translated">二元分类</h2><p id="d827" class="pw-post-body-paragraph lw lx jg ly b lz ma kq mb mc md kt me mf mg mh mi mj mk ml mm mn mo mp mq mr ij bi translated">在二元分类中，输出为0或1，因此与线性回归的情况相反，假设也必须在0和1的范围内。这就是我们使用逻辑函数或sigmoid函数进行假设的原因。</p><p id="5a94" class="pw-post-body-paragraph lw lx jg ly b lz ms kq mb mc mt kt me mf mu mh mi mj mv ml mm mn mw mp mq mr ij bi translated">它通常被解释为一种概率。</p><p id="016a" class="pw-post-body-paragraph lw lx jg ly b lz ms kq mb mc mt kt me mf mu mh mi mj mv ml mm mn mw mp mq mr ij bi translated">例如，假设假设的输出值h(x)为垃圾邮件分类问题的h(x) = 0.7，其中0代表垃圾邮件，1代表垃圾邮件。这仅仅意味着该电子邮件是垃圾邮件的概率为0.7。</p><h2 id="78f0" class="nc lf jg bd lg nd ne dn lk nf ng dp lo mf nh ni lq mj nj nk ls mn nl nm lu jm bi translated">决策界限</h2><p id="02c3" class="pw-post-body-paragraph lw lx jg ly b lz ma kq mb mc md kt me mf mg mh mi mj mk ml mm mn mo mp mq mr ij bi translated">它是将数据集分成不同类的界限。在二元分类问题中，决策边界是将数据集中的正例与反例分开的线。</p><figure class="my mz na nb gt is gh gi paragraph-image"><div class="gh gi pl"><img src="../Images/17818af27b0be8dd5293e8f2436b1a60.png" data-original-src="https://miro.medium.com/v2/resize:fit:972/format:webp/1*8L9JVgu8CLKJJRKoxDxm4w.png"/></div><figcaption class="iz ja gj gh gi jb jc bd b be z dk translated">媒体图像</figcaption></figure><p id="a70f" class="pw-post-body-paragraph lw lx jg ly b lz ms kq mb mc mt kt me mf mu mh mi mj mv ml mm mn mw mp mq mr ij bi translated"><strong class="ly jq">非线性决策边界</strong>也可用于分类任务，以获得更好的模型。</p><h2 id="5440" class="nc lf jg bd lg nd ne dn lk nf ng dp lo mf nh ni lq mj nj nk ls mn nl nm lu jm bi translated">逻辑回归的成本函数</h2><p id="759c" class="pw-post-body-paragraph lw lx jg ly b lz ma kq mb mc md kt me mf mg mh mi mj mk ml mm mn mo mp mq mr ij bi translated">逻辑回归的成本函数与我们在线性回归中看到的不同。这是因为如果我们使用线性回归的代价函数来评估逻辑回归模型，它将导致具有许多局部最优值的波动和不规则形式，即它不是凸函数。</p><figure class="my mz na nb gt is gh gi paragraph-image"><div role="button" tabindex="0" class="it iu di iv bf iw"><div class="gh gi pm"><img src="../Images/dcc517bbb49b712dc288ea9127ac1610.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*JWvYunYNRvkTz7ROGR43_w.png"/></div></div><figcaption class="iz ja gj gh gi jb jc bd b be z dk translated">逻辑回归的成本函数</figcaption></figure><h2 id="d00c" class="nc lf jg bd lg nd ne dn lk nf ng dp lo mf nh ni lq mj nj nk ls mn nl nm lu jm bi translated">多类分类</h2><p id="ffcf" class="pw-post-body-paragraph lw lx jg ly b lz ma kq mb mc md kt me mf mg mh mi mj mk ml mm mn mo mp mq mr ij bi translated">我们使用<a class="ae jd" href="https://utkuufuk.com/2018/06/03/one-vs-all-classification/" rel="noopener ugc nofollow" target="_blank"> <strong class="ly jq">一对一</strong> </a> <strong class="ly jq">(或一对其余)</strong>分类技术，由此我们为数据集中的n个不同类训练n个二元逻辑分类器。</p><p id="a431" class="pw-post-body-paragraph lw lx jg ly b lz ms kq mb mc mt kt me mf mu mh mi mj mv ml mm mn mw mp mq mr ij bi translated">这是通过在训练期间将单个类的类标签设置为正，然后将属于其余类的其他训练样本的标签设置为负来实现的。这依次进行，直到我们为数据集中的n个类训练了n个二元分类器。</p><p id="dc3f" class="pw-post-body-paragraph lw lx jg ly b lz ms kq mb mc mt kt me mf mu mh mi mj mv ml mm mn mw mp mq mr ij bi translated">在预测期间，输入在所有n分类器中运行。输入属于其模型输出概率最高的类。</p><h2 id="cdb1" class="nc lf jg bd lg nd ne dn lk nf ng dp lo mf nh ni lq mj nj nk ls mn nl nm lu jm bi translated">解决过拟合问题。</h2><p id="751e" class="pw-post-body-paragraph lw lx jg ly b lz ma kq mb mc md kt me mf mg mh mi mj mk ml mm mn mo mp mq mr ij bi translated"><strong class="ly jq">欠拟合</strong>也称为<strong class="ly jq">高偏差</strong>发生在我们只有非常少的训练数据的时候。<br/> <strong class="ly jq">过拟合</strong>，也称为<strong class="ly jq">高方差</strong>经常发生在我们的数据集中有太多特征的时候。</p><p id="2dae" class="pw-post-body-paragraph lw lx jg ly b lz ms kq mb mc mt kt me mf mu mh mi mj mv ml mm mn mw mp mq mr ij bi translated">有两个主要选项可以解决过度拟合问题:</p><ol class=""><li id="d38d" class="pn po jg ly b lz ms mc mt mf pp mj pq mn pr mr ps pt pu pv bi translated"><strong class="ly jq">减少特征的数量:</strong> <br/>我们可以用两种方法减少特征的数量</li></ol><blockquote class="oh oi oj"><p id="1f64" class="lw lx nn ly b lz ms kq mb mc mt kt me ok mu mh mi ol mv ml mm om mw mp mq mr ij bi translated">*通过手动选择要保留的功能。<br/> *通过使用模型选择算法。</p></blockquote><p id="795a" class="pw-post-body-paragraph lw lx jg ly b lz ms kq mb mc mt kt me mf mu mh mi mj mv ml mm mn mw mp mq mr ij bi translated"><a class="ae jd" href="https://towardsdatascience.com/regularization-an-important-concept-in-machine-learning-5891628907ea" rel="noopener" target="_blank"> <strong class="ly jq"> 2。正规化</strong> </a></p><p id="80a8" class="pw-post-body-paragraph lw lx jg ly b lz ms kq mb mc mt kt me mf mu mh mi mj mv ml mm mn mw mp mq mr ij bi translated">当我们有很多稍微有用的特性时，正则化工作得很好。</p><h1 id="a402" class="le lf jg bd lg lh li lj lk ll lm ln lo kv lp kw lq ky lr kz ls lb lt lc lu lv bi translated">**第4天亮点**</h1><h1 id="0c4c" class="le lf jg bd lg lh li lj lk ll lm ln lo kv lp kw lq ky lr kz ls lb lt lc lu lv bi translated">神经网络和表示。</h1><p id="9785" class="pw-post-body-paragraph lw lx jg ly b lz ma kq mb mc md kt me mf mg mh mi mj mk ml mm mn mo mp mq mr ij bi translated">神经网络是作为大脑中的模拟神经元或神经元网络而开发的。下图显示了人工神经网络的基本结构。</p><figure class="my mz na nb gt is gh gi paragraph-image"><div role="button" tabindex="0" class="it iu di iv bf iw"><div class="gh gi pw"><img src="../Images/d3af5f7b559382e6099e69b787d177ac.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*rptqFUQTMiruWZWKm-WMqQ.png"/></div></div><figcaption class="iz ja gj gh gi jb jc bd b be z dk translated">单个人工神经元的图像</figcaption></figure><p id="394a" class="pw-post-body-paragraph lw lx jg ly b lz ms kq mb mc mt kt me mf mu mh mi mj mv ml mm mn mw mp mq mr ij bi translated">每个圆称为一个节点。黄色节点被称为输入节点(特征)。绿色的<strong class="ly jq">节点</strong>被称为隐藏节点，最后红色的<strong class="ly jq">输出节点</strong>。这些隐藏节点(单元)通常被称为激活单元，因为它们计算的函数被称为激活函数。最常见的激活函数是sigmoid和Relu(整流线性单元)</p><p id="18d6" class="pw-post-body-paragraph lw lx jg ly b lz ms kq mb mc mt kt me mf mu mh mi mj mv ml mm mn mw mp mq mr ij bi translated">通过以结构化的方式堆叠这些节点，我们可以创建非常强大的模型，能够以高精度执行复杂的任务。下图是一个<strong class="ly jq">三(3)层神经网络</strong>(输入层不算)。</p><figure class="my mz na nb gt is gh gi paragraph-image"><div class="ab gu cl px"><img src="../Images/aa6f38c9ea186f50b057d93bc52c7b5e.png" data-original-src="https://miro.medium.com/v2/format:webp/1*WVNrkhHSE7bN2tiPnafNgA.jpeg"/></div><figcaption class="iz ja gj gh gi jb jc bd b be z dk translated">从走向数据科学的两层神经网络图像</figcaption></figure><h1 id="bc08" class="le lf jg bd lg lh li lj lk ll lm ln lo kv lp kw lq ky lr kz ls lb lt lc lu lv bi translated">神经网络的应用</h1><p id="6ea2" class="pw-post-body-paragraph lw lx jg ly b lz ma kq mb mc md kt me mf mg mh mi mj mk ml mm mn mo mp mq mr ij bi translated">神经网络是多用途的，因此可以用于许多不同的应用。它们用于二元分类以及多类分类任务。神经网络也用于解决回归问题。</p><p id="fd04" class="pw-post-body-paragraph lw lx jg ly b lz ms kq mb mc mt kt me mf mu mh mi mj mv ml mm mn mw mp mq mr ij bi translated">这里有一些实际的使用案例:字符识别、图像压缩、股票市场价格等预测问题、签名识别等等。</p><p id="d44b" class="pw-post-body-paragraph lw lx jg ly b lz ms kq mb mc mt kt me mf mu mh mi mj mv ml mm mn mw mp mq mr ij bi translated"><em class="nn">第5天结束时提供了有关神经网络的更多信息的链接。继续走。</em></p><blockquote class="nq"><p id="15f5" class="nr ns jg bd nt nu nv nw nx ny nz mr dk translated">第四天结束了！！</p></blockquote><h1 id="cc3a" class="le lf jg bd lg lh li lj lk ll lm ln lo kv os kw lq ky ot kz ls lb ou lc lu lv bi translated">**第5天亮点**</h1><h1 id="89ae" class="le lf jg bd lg lh li lj lk ll lm ln lo kv lp kw lq ky lr kz ls lb lt lc lu lv bi translated">神经网络:学习</h1><figure class="my mz na nb gt is gh gi paragraph-image"><div role="button" tabindex="0" class="it iu di iv bf iw"><div class="gh gi py"><img src="../Images/87f483acbd11b0761567ab2b32a97cd8.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*u1ififkhEPQuzSSiblcKKw.png"/></div></div><figcaption class="iz ja gj gh gi jb jc bd b be z dk translated">图片来自3blueOneBrown youtube</figcaption></figure><p id="f199" class="pw-post-body-paragraph lw lx jg ly b lz ms kq mb mc mt kt me mf mu mh mi mj mv ml mm mn mw mp mq mr ij bi translated">神经网络是最强大的监督学习算法之一。在机器学习问题中，当线性分类器不起作用时，训练神经网络分类器通常是一种好的做法。</p><h2 id="56d9" class="nc lf jg bd lg nd ne dn lk nf ng dp lo mf nh ni lq mj nj nk ls mn nl nm lu jm bi translated">训练神经网络</h2><p id="c1c5" class="pw-post-body-paragraph lw lx jg ly b lz ma kq mb mc md kt me mf mg mh mi mj mk ml mm mn mo mp mq mr ij bi translated">训练神经网络是一个迭代且计算量大的过程，包括寻找最佳模型参数——使误差最小化的权重和偏差。</p><p id="7d98" class="pw-post-body-paragraph lw lx jg ly b lz ms kq mb mc mt kt me mf mu mh mi mj mv ml mm mn mw mp mq mr ij bi translated">寻找最佳模型参数的驱动机制基于一种称为反向传播的算法。</p><blockquote class="oh oi oj"><p id="dcf3" class="lw lx nn ly b lz ms kq mb mc mt kt me ok mu mh mi ol mv ml mm om mw mp mq mr ij bi translated">旁注:神经网络实际上非常复杂，非常数学化，所以我不会在这里深入探讨。</p></blockquote><h2 id="8bd6" class="nc lf jg bd lg nd ne dn lk nf ng dp lo mf nh ni lq mj nj nk ls mn nl nm lu jm bi translated">反向传播算法。</h2><p id="38b2" class="pw-post-body-paragraph lw lx jg ly b lz ma kq mb mc md kt me mf mg mh mi mj mk ml mm mn mo mp mq mr ij bi translated">反向传播是一种算法，用于根据训练数据以迭代方式找到最佳模型参数，即神经网络的权重和偏差。</p><p id="b862" class="pw-post-body-paragraph lw lx jg ly b lz ms kq mb mc mt kt me mf mu mh mi mj mv ml mm mn mw mp mq mr ij bi translated">这是通过计算成本函数J相对于权重和偏差值的偏导数来实现的。</p><p id="f903" class="pw-post-body-paragraph lw lx jg ly b lz ms kq mb mc mt kt me mf mu mh mi mj mv ml mm mn mw mp mq mr ij bi translated"><strong class="ly jq">梯度下降算法</strong>使用反向传播和成本函数来评估最佳模型参数。这是神经网络的训练阶段，它产生最佳的模型参数。</p><p id="652d" class="pw-post-body-paragraph lw lx jg ly b lz ms kq mb mc mt kt me mf mu mh mi mj mv ml mm mn mw mp mq mr ij bi translated"><a class="ae jd" href="https://towardsdatascience.com/how-to-debug-a-neural-network-with-gradient-checking-41deec0357a9" rel="noopener" target="_blank"> <strong class="ly jq">梯度检查</strong> </a>是一种用于验证反向传播的实现是否正常工作的方法。</p><h2 id="8352" class="nc lf jg bd lg nd ne dn lk nf ng dp lo mf nh ni lq mj nj nk ls mn nl nm lu jm bi translated">偏差与方差</h2><p id="73d2" class="pw-post-body-paragraph lw lx jg ly b lz ma kq mb mc md kt me mf mg mh mi mj mk ml mm mn mo mp mq mr ij bi translated">在训练神经网络时，我们需要首先决定<strong class="ly jq">网络架构</strong>。网络结构简单来说就是神经元之间的连接模式，也就是选择要使用的隐藏层数。</p><p id="e0d8" class="pw-post-body-paragraph lw lx jg ly b lz ms kq mb mc mt kt me mf mu mh mi mj mv ml mm mn mw mp mq mr ij bi translated">注意，神经网络的输入单元的数量等于训练样本的特征的维数。如果你正在处理一个分类问题，输出单元的数量由类的数量决定。</p><p id="69ea" class="pw-post-body-paragraph lw lx jg ly b lz ms kq mb mc mt kt me mf mu mh mi mj mv ml mm mn mw mp mq mr ij bi translated">在神经网络的每个隐藏层中使用相同数量的单元也是很好的实践。隐藏单元越大，模型的性能越好，但是计算复杂度增加，</p><h2 id="8dfc" class="nc lf jg bd lg nd ne dn lk nf ng dp lo mf nh ni lq mj nj nk ls mn nl nm lu jm bi translated">训练神经网络的步骤</h2><p id="3d79" class="pw-post-body-paragraph lw lx jg ly b lz ma kq mb mc md kt me mf mg mh mi mj mk ml mm mn mo mp mq mr ij bi translated">1.随机初始化权重<br/> 2。实现正向传播以获取每个定型示例的输出值。<br/> 3。计算成本函数<br/> 4。实施反向传播以计算偏导数<br/> 5。使用梯度检查来确认您的反向传播工作。然后禁用梯度检查。<br/> 6。使用梯度下降或任何内置优化函数，通过迭代更新权重和偏差来最小化成本函数。</p><blockquote class="oh oi oj"><p id="cd2c" class="lw lx nn ly b lz ms kq mb mc mt kt me ok mu mh mi ol mv ml mm om mw mp mq mr ij bi translated">注意:当实现神经网络时，我们不用零初始化模型参数，因为模型在训练后不会学习任何有趣的特征。这被称为<strong class="ly jq">对称重量问题。</strong>执行模型参数的随机初始化以避免这一缺点。这被称为<strong class="ly jq">对称性破缺。</strong></p></blockquote><p id="0417" class="pw-post-body-paragraph lw lx jg ly b lz ms kq mb mc mt kt me mf mu mh mi mj mv ml mm mn mw mp mq mr ij bi translated">关于神经网络的更多信息，这里有一些重要的链接。</p><ul class=""><li id="4e09" class="pn po jg ly b lz ms mc mt mf pp mj pq mn pr mr pz pt pu pv bi translated">饶彤彤的文章对神经网络背后的过程给出了直观的解释(见<a class="ae jd" href="https://towardsdatascience.com/understanding-neural-networks-19020b758230" rel="noopener" target="_blank">此处</a>)。</li><li id="7931" class="pn po jg ly b lz qa mc qb mf qc mj qd mn qe mr pz pt pu pv bi translated">如果你想更进一步，理解神经网络背后的数学，请点击这里查看这本免费的在线书籍。</li><li id="1419" class="pn po jg ly b lz qa mc qb mf qc mj qd mn qe mr pz pt pu pv bi translated">如果你是一名视觉/音频学习者，3Blue1Brown在YouTube上有一个关于神经网络和深度学习的惊人系列<a class="ae jd" href="https://www.youtube.com/watch?v=aircAruvnKk" rel="noopener ugc nofollow" target="_blank">这里</a>。</li></ul><blockquote class="nq"><p id="e0bd" class="nr ns jg bd nt nu on oo op oq or mr dk translated">第五天结束了！！</p></blockquote><h1 id="91f0" class="le lf jg bd lg lh li lj lk ll lm ln lo kv os kw lq ky ot kz ls lb ou lc lu lv bi translated">**第6天亮点**</h1><h2 id="5d62" class="nc lf jg bd lg nd ne dn lk nf ng dp lo mf nh ni lq mj nj nk ls mn nl nm lu jm bi translated">调试学习算法</h2><p id="8ee7" class="pw-post-body-paragraph lw lx jg ly b lz ma kq mb mc md kt me mf mg mh mi mj mk ml mm mn mo mp mq mr ij bi translated">如果你训练的机器学习模型在测试数据上表现不佳，这里有一些通用步骤，你可以尝试提高模型的性能。</p><blockquote class="oh oi oj"><p id="450b" class="lw lx nn ly b lz ms kq mb mc mt kt me ok mu mh mi ol mv ml mm om mw mp mq mr ij bi translated">*获取更多训练示例<br/> *尝试更小的特征集<br/> *尝试获取更多附加特征<br/> *尝试多项式特征<br/> *减少或增加正则项的λ</p></blockquote><h2 id="9e16" class="nc lf jg bd lg nd ne dn lk nf ng dp lo mf nh ni lq mj nj nk ls mn nl nm lu jm bi translated">评估假设</h2><p id="038f" class="pw-post-body-paragraph lw lx jg ly b lz ma kq mb mc md kt me mf mg mh mi mj mk ml mm mn mo mp mq mr ij bi translated">传统上，为了评估模型的性能，我们将数据分为训练和测试两部分。然后，我们使用训练分割来训练模型，以获得优化的模型参数(θ)。</p><p id="20fb" class="pw-post-body-paragraph lw lx jg ly b lz ms kq mb mc mt kt me mf mu mh mi mj mv ml mm mn mw mp mq mr ij bi translated">使用训练的模型参数，我们仅使用测试分割示例来评估测试集误差。这让我们对你的模型在看不见的数据上的表现有所了解。这种技术经常应用于回归问题</p><p id="4baf" class="pw-post-body-paragraph lw lx jg ly b lz ms kq mb mc mt kt me mf mu mh mi mj mv ml mm mn mw mp mq mr ij bi translated"><strong class="ly jq">误分类误差</strong>是另一个常用于评估假设在分类情况下表现如何的指标。</p><p id="9340" class="pw-post-body-paragraph lw lx jg ly b lz ms kq mb mc mt kt me mf mu mh mi mj mv ml mm mn mw mp mq mr ij bi translated">一般来说，将数据分成<strong class="ly jq">训练、交叉验证和测试集是一个很好的实践。</strong>这有助于在调整模型超参数时，对训练数据集上的模型拟合提供无偏评估。</p><p id="4b07" class="pw-post-body-paragraph lw lx jg ly b lz ms kq mb mc mt kt me mf mu mh mi mj mv ml mm mn mw mp mq mr ij bi translated">使用训练集计算模型参数，然后使用交叉验证集评估模型性能，即模型是否可能欠拟合或过拟合。然后可以进行超参数调整或其他更改，并使用验证集重新训练和测试模型。</p><h2 id="75d8" class="nc lf jg bd lg nd ne dn lk nf ng dp lo mf nh ni lq mj nj nk ls mn nl nm lu jm bi translated">重击规则。</h2><p id="d571" class="pw-post-body-paragraph lw lx jg ly b lz ma kq mb mc md kt me mf mg mh mi mj mk ml mm mn mo mp mq mr ij bi translated">选择具有最小交叉验证误差的模型，然后使用测试集，计算测试误差(J_test)以选择具有最小测试误差的模型。</p><h2 id="82d9" class="nc lf jg bd lg nd ne dn lk nf ng dp lo mf nh ni lq mj nj nk ls mn nl nm lu jm bi translated">偏差与方差</h2><p id="2a5a" class="pw-post-body-paragraph lw lx jg ly b lz ma kq mb mc md kt me mf mg mh mi mj mk ml mm mn mo mp mq mr ij bi translated">如果你训练过的模型性能很低，可能是由于<strong class="ly jq"> <em class="nn">【欠拟合】</em> </strong> <em class="nn">或者</em> <strong class="ly jq"> <em class="nn">高方差(过拟合)</em> </strong> <em class="nn">。</em></p><p id="8c42" class="pw-post-body-paragraph lw lx jg ly b lz ms kq mb mc mt kt me mf mu mh mi mj mv ml mm mn mw mp mq mr ij bi translated">要识别您的模型遇到的问题，请检查训练和交叉验证集的<em class="nn">错误。</em></p><p id="8198" class="pw-post-body-paragraph lw lx jg ly b lz ms kq mb mc mt kt me mf mu mh mi mj mv ml mm mn mw mp mq mr ij bi translated">如果训练误差和验证误差都是<strong class="ly jq"><em class="nn"/></strong>高，则暗示模型是<strong class="ly jq"> <em class="nn">欠拟合(高偏差)</em> </strong>。如果训练误差为<strong class="ly jq"> <em class="nn">低</em> </strong>而验证误差为<strong class="ly jq"> <em class="nn">高，</em> </strong>则表示模型为<strong class="ly jq"> <em class="nn">过拟合(高方差)。</em>T41】</strong></p><h2 id="0de5" class="nc lf jg bd lg nd ne dn lk nf ng dp lo mf nh ni lq mj nj nk ls mn nl nm lu jm bi translated">学习曲线</h2><p id="ae42" class="pw-post-body-paragraph lw lx jg ly b lz ma kq mb mc md kt me mf mg mh mi mj mk ml mm mn mo mp mq mr ij bi translated">使用学习曲线来诊断您的学习算法是否存在偏差或方差问题，</p><figure class="my mz na nb gt is gh gi paragraph-image"><div class="gh gi qf"><img src="../Images/28176e8838e5046a2e78bad36744c7f7.png" data-original-src="https://miro.medium.com/v2/resize:fit:970/format:webp/1*Uzjz7fIFjPMQp0nCXp8QiQ.png"/></div><figcaption class="iz ja gj gh gi jb jc bd b be z dk translated">图像if高偏差(低方差)、高方差(低偏差)和良好的偏差-方差权衡</figcaption></figure><p id="eb37" class="pw-post-body-paragraph lw lx jg ly b lz ms kq mb mc mt kt me mf mu mh mi mj mv ml mm mn mw mp mq mr ij bi translated">如果你的算法正遭受<strong class="ly jq">高偏差</strong>，增加训练样本无助于减少训练和交叉验证误差值。</p><p id="c9cf" class="pw-post-body-paragraph lw lx jg ly b lz ms kq mb mc mt kt me mf mu mh mi mj mv ml mm mn mw mp mq mr ij bi translated">相反，如果你的学习算法正遭受<strong class="ly jq">高方差</strong>，获得更多的训练样本可能有助于提高其性能，因为交叉验证成本误差将随着更多的训练样本而不断降低。</p><h2 id="9f33" class="nc lf jg bd lg nd ne dn lk nf ng dp lo mf nh ni lq mj nj nk ls mn nl nm lu jm bi translated">机器学习模型的最终决策过程</h2><p id="0b61" class="pw-post-body-paragraph lw lx jg ly b lz ma kq mb mc md kt me mf mg mh mi mj mk ml mm mn mo mp mq mr ij bi translated">我们的决策过程可以细分如下:</p><blockquote class="nq"><p id="f11c" class="nr ns jg bd nt nu nv nw nx ny nz mr dk translated">1.获得更多的训练例子:修正高方差<br/> 2。尝试更小的功能集:修复高方差<br/> 3。增加功能:修正高偏差<br/> 4。增加多项式特性:修复高偏差<br/> 5。减小λ(正则化超参数):修复高偏差<br/> 6。增加λ:修复高方差。</p></blockquote><h1 id="2320" class="le lf jg bd lg lh li lj lk ll lm ln lo kv os kw lq ky ot kz ls lb ou lc lu lv bi translated">分类模型的评价标准。</h1><p id="17d4" class="pw-post-body-paragraph lw lx jg ly b lz ma kq mb mc md kt me mf mg mh mi mj mk ml mm mn mo mp mq mr ij bi translated"><strong class="ly jq">精度</strong>和<strong class="ly jq">召回</strong>是分类模型的良好评估指标，因为它可以帮助查明<strong class="ly jq">倾斜数据集</strong>的影响。</p><figure class="my mz na nb gt is gh gi paragraph-image"><div role="button" tabindex="0" class="it iu di iv bf iw"><div class="gh gi qg"><img src="../Images/8ce1c0146d554a6d44e2d16a83fa6120.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Nu29gRsSO-45gR-J9cDyiw.png"/></div></div><figcaption class="iz ja gj gh gi jb jc bd b be z dk translated">图片来自走向数据科学</figcaption></figure><h2 id="35a5" class="nc lf jg bd lg nd ne dn lk nf ng dp lo mf nh ni lq mj nj nk ls mn nl nm lu jm bi translated">精确</h2><p id="20ee" class="pw-post-body-paragraph lw lx jg ly b lz ma kq mb mc md kt me mf mg mh mi mj mk ml mm mn mo mp mq mr ij bi translated">这是一个分类指标，用于评估相对于我们的模型做出的正面预测总数(TP + FP)而言，真实正面预测(TP)的比例。</p><figure class="my mz na nb gt is gh gi paragraph-image"><div role="button" tabindex="0" class="it iu di iv bf iw"><div class="gh gi qh"><img src="../Images/097b948ce5251a00f8f39a98990ddee0.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*6duSoCrnZHGL_Ab88FO8dw.png"/></div></div></figure><h2 id="1d7e" class="nc lf jg bd lg nd ne dn lk nf ng dp lo mf nh ni lq mj nj nk ls mn nl nm lu jm bi translated">回忆</h2><p id="eafb" class="pw-post-body-paragraph lw lx jg ly b lz ma kq mb mc md kt me mf mg mh mi mj mk ml mm mn mo mp mq mr ij bi translated">它评估了由我们的模型做出的真实正面预测(TP)相对于最初在我们的训练数据集中的正面示例的实际数量(TP + FN)的比例。</p><figure class="my mz na nb gt is gh gi paragraph-image"><div class="gh gi qi"><img src="../Images/5b1b7338c7051504a85cacc5fcd59bbe.png" data-original-src="https://miro.medium.com/v2/resize:fit:944/format:webp/1*CcpBx61jpTdU0kQtmQS8gg.png"/></div></figure><p id="8abd" class="pw-post-body-paragraph lw lx jg ly b lz ms kq mb mc mt kt me mf mu mh mi mj mv ml mm mn mw mp mq mr ij bi translated">很明显，具有更多负面例子的数据集可能导致非常低的召回率。</p><p id="fd28" class="pw-post-body-paragraph lw lx jg ly b lz ms kq mb mc mt kt me mf mu mh mi mj mv ml mm mn mw mp mq mr ij bi translated">通过改变逻辑分类器的假设函数的阈值。即<strong class="ly jq"> <em class="nn">假设&gt;阈值</em> </strong>，我们可以在交叉验证集上获得不同的查准率和查全率值。</p><p id="c906" class="pw-post-body-paragraph lw lx jg ly b lz ms kq mb mc mt kt me mf mu mh mi mj mv ml mm mn mw mp mq mr ij bi translated"><em class="nn">精度和召回率高</em>意味着学习算法性能好</p><h2 id="c727" class="nc lf jg bd lg nd ne dn lk nf ng dp lo mf nh ni lq mj nj nk ls mn nl nm lu jm bi translated">哪个分类器比较好？</h2><p id="360c" class="pw-post-body-paragraph lw lx jg ly b lz ma kq mb mc md kt me mf mg mh mi mj mk ml mm mn mo mp mq mr ij bi translated">为了选择最好的分类器，基于精度和召回值，我们通常评估精度和召回的平均值，即(P + R) / 2。然而，这并不是决定哪个模型最好的好方法，因为特定模型的<strong class="ly jq"> <em class="nn">高精度和低召回率或者低精度和高召回率</em> </strong>会导致<strong class="ly jq">高平均值，</strong>而该模型不好。</p><h2 id="a640" class="nc lf jg bd lg nd ne dn lk nf ng dp lo mf nh ni lq mj nj nk ls mn nl nm lu jm bi translated">f1-分数</h2><p id="b3c1" class="pw-post-body-paragraph lw lx jg ly b lz ma kq mb mc md kt me mf mg mh mi mj mk ml mm mn mo mp mq mr ij bi translated">为了解决平均评估的这一缺点，我们使用了<strong class="ly jq"><em class="nn">F1-得分评估指标</em> </strong>，其计算如下:</p><figure class="my mz na nb gt is gh gi paragraph-image"><div class="gh gi qj"><img src="../Images/0703567d6a08432fe9a400bc5b917490.png" data-original-src="https://miro.medium.com/v2/resize:fit:990/format:webp/1*Q8JeJ4mCPo6IdsnluTjmVg.jpeg"/></div></figure><p id="33f5" class="pw-post-body-paragraph lw lx jg ly b lz ms kq mb mc mt kt me mf mu mh mi mj mv ml mm mn mw mp mq mr ij bi translated">因此，如果精度或召回率非常低，F1值将会很低。只有通过相对较高的精确度和召回率才能获得较高的F1分数。最佳车型的F1得分最高。</p><blockquote class="nq"><p id="bed4" class="nr ns jg bd nt nu nv nw nx ny nz mr dk translated">第六天结束了！！</p></blockquote><h1 id="90da" class="le lf jg bd lg lh li lj lk ll lm ln lo kv os kw lq ky ot kz ls lb ou lc lu lv bi translated">**第7天亮点**</h1><h1 id="b861" class="le lf jg bd lg lh li lj lk ll lm ln lo kv lp kw lq ky lr kz ls lb lt lc lu lv bi translated">支持向量机。</h1><p id="89d3" class="pw-post-body-paragraph lw lx jg ly b lz ma kq mb mc md kt me mf mg mh mi mj mk ml mm mn mo mp mq mr ij bi translated">SVM是另一种有趣的分类器，就其成本函数而言，类似于逻辑回归。SVM的不遭受局部极小问题，因为它的成本函数是纯凸的。</p><p id="2358" class="pw-post-body-paragraph lw lx jg ly b lz ms kq mb mc mt kt me mf mu mh mi mj mv ml mm mn mw mp mq mr ij bi translated">SVM假设和成本函数如下所示:</p><figure class="my mz na nb gt is gh gi paragraph-image"><div role="button" tabindex="0" class="it iu di iv bf iw"><div class="gh gi qk"><img src="../Images/21049090bef8a85dcd63bf7cae2a7a3a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*b93HS-5pnqTyKFxzAQ_okQ.png"/></div></div></figure><p id="8b34" class="pw-post-body-paragraph lw lx jg ly b lz ms kq mb mc mt kt me mf mu mh mi mj mv ml mm mn mw mp mq mr ij bi translated">SVM的目标是计算使成本函数J(θ)最小的模型参数(θ)的最佳值。</p><p id="e95b" class="pw-post-body-paragraph lw lx jg ly b lz ms kq mb mc mt kt me mf mu mh mi mj mv ml mm mn mw mp mq mr ij bi translated">成本函数中的<strong class="ly jq">超参数，C </strong>，在线性回归正则化成本函数的情况下起到<strong class="ly jq">C = 1/λ</strong>的作用。</p><p id="8c6b" class="pw-post-body-paragraph lw lx jg ly b lz ms kq mb mc mt kt me mf mu mh mi mj mv ml mm mn mw mp mq mr ij bi translated">这意味着，<strong class="ly jq">如果C很大</strong>，则λ很小，因此，模型参数受到的惩罚较少，导致<strong class="ly jq">高复杂度</strong>，因此<strong class="ly jq">过拟合</strong>。如果<strong class="ly jq"> C小，则</strong>λ变大，导致<strong class="ly jq">模型参数</strong>的高惩罚，这降低了模型复杂性<strong class="ly jq">，导致欠拟合。</strong></p><p id="4a46" class="pw-post-body-paragraph lw lx jg ly b lz ms kq mb mc mt kt me mf mu mh mi mj mv ml mm mn mw mp mq mr ij bi translated">SVM的假设直接为正类输出1，为负类输出0。这与输出概率(0到1)的逻辑回归相反。</p><h2 id="1ee4" class="nc lf jg bd lg nd ne dn lk nf ng dp lo mf nh ni lq mj nj nk ls mn nl nm lu jm bi translated">开发复杂的非线性SVM模型</h2><p id="7aab" class="pw-post-body-paragraph lw lx jg ly b lz ma kq mb mc md kt me mf mg mh mi mj mk ml mm mn mo mp mq mr ij bi translated"><strong class="ly jq">相似性函数</strong>也称为<strong class="ly jq">内核</strong>可以与支持向量机一起使用，以开发复杂的非线性SVM模型。</p><p id="ed8d" class="pw-post-body-paragraph lw lx jg ly b lz ms kq mb mc mt kt me mf mu mh mi mj mv ml mm mn mw mp mq mr ij bi translated">例如，<strong class="ly jq">高斯核</strong>是一种非常常见的核，它基于在我们的训练数据集上选择称为界标的随机点，然后基于高斯分布方程生成新的特征k。</p><figure class="my mz na nb gt is gh gi paragraph-image"><div role="button" tabindex="0" class="it iu di iv bf iw"><div class="gh gi ql"><img src="../Images/b60d563f3a70130070c40ee9d2bbbdf9.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*OOHoiuEN7cltEAK7PzY4lw.jpeg"/></div></div><figcaption class="iz ja gj gh gi jb jc bd b be z dk translated">高斯核函数</figcaption></figure><p id="8916" class="pw-post-body-paragraph lw lx jg ly b lz ms kq mb mc mt kt me mf mu mh mi mj mv ml mm mn mw mp mq mr ij bi translated"><strong class="ly jq"> y = </strong>随机地标向量，<strong class="ly jq"> x </strong> =训练样本。基于地标的数量，对于每个训练示例，我们评估k，然后在我们的假设中使用它来训练和预测我们的模型。</p><p id="48f7" class="pw-post-body-paragraph lw lx jg ly b lz ms kq mb mc mt kt me mf mu mh mi mj mv ml mm mn mw mp mq mr ij bi translated">使用内核的想法只是使用我们的原始训练样本来创建新的特征，然后使用这些新的特征而不是原始训练数据集特征来训练SVM分类器。</p><p id="23f7" class="pw-post-body-paragraph lw lx jg ly b lz ms kq mb mc mt kt me mf mu mh mi mj mv ml mm mn mw mp mq mr ij bi translated">通常在与训练样本相同的位置选择标志。因此，如果您的训练集有m个示例，那么您就有m个地标。</p><p id="7a85" class="pw-post-body-paragraph lw lx jg ly b lz ms kq mb mc mt kt me mf mu mh mi mj mv ml mm mn mw mp mq mr ij bi translated">这导致长度为m + 1的新特征向量k，因此，您的模型将具有与k相同大小的模型参数(θ),即m + 1。这包括截距项(θ-零)。</p><p id="0f56" class="pw-post-body-paragraph lw lx jg ly b lz ms kq mb mc mt kt me mf mu mh mi mj mv ml mm mn mw mp mq mr ij bi translated">新的假设变成了:</p><p id="514d" class="pw-post-body-paragraph lw lx jg ly b lz ms kq mb mc mt kt me mf mu mh mi mj mv ml mm mn mw mp mq mr ij bi translated"><strong class="ly jq">预测，y = 1，如果(Theta * K &gt; 0) </strong>而非形式(Theta * X &gt; 0)</p><p id="7be9" class="pw-post-body-paragraph lw lx jg ly b lz ms kq mb mc mt kt me mf mu mh mi mj mv ml mm mn mw mp mq mr ij bi translated">核可以和线性回归一起使用，但是这在计算上很昂贵，除非绝对需要，否则不应该使用。</p><figure class="my mz na nb gt is gh gi paragraph-image"><div class="gh gi qm"><img src="../Images/d1bcb20361dd71e3b17cef03cf1cc4f0.png" data-original-src="https://miro.medium.com/v2/resize:fit:960/format:webp/1*Y8w5za0Wh-G8Ej4N51XNcg.png"/></div><figcaption class="iz ja gj gh gi jb jc bd b be z dk translated">图片由VRC学院提供</figcaption></figure><p id="28a6" class="pw-post-body-paragraph lw lx jg ly b lz ms kq mb mc mt kt me mf mu mh mi mj mv ml mm mn mw mp mq mr ij bi translated">SVMs的另一个<strong class="ly jq">超参数是高斯核函数中的sigma </strong>。随着特征<strong class="ly jq"> k </strong>平滑变化，<strong class="ly jq">大sigma </strong>导致对应于<strong class="ly jq">低方差</strong>和<strong class="ly jq">高偏差</strong>的平缓倾斜高斯曲线。<strong class="ly jq">小sigma </strong>，导致更陡的高斯函数，导致<strong class="ly jq">高方差，</strong>因此，<strong class="ly jq">低偏差</strong>随着特征k急剧变化。</p><p id="c6b7" class="pw-post-body-paragraph lw lx jg ly b lz ms kq mb mc mt kt me mf mu mh mi mj mv ml mm mn mw mp mq mr ij bi translated">对非常大的数据集使用支持向量机<strong class="ly jq">计算开销很大</strong>，因为使用内核创建的新特征的数量等于数据集样本的大小。</p><p id="58a0" class="pw-post-body-paragraph lw lx jg ly b lz ms kq mb mc mt kt me mf mu mh mi mj mv ml mm mn mw mp mq mr ij bi translated">对于使用SVM 的<strong class="ly jq">多分类，我们使用<strong class="ly jq">一对一</strong>方法来区分不同的类别。如果我们有K个类，我们简单地通过将相应的类设置为y = 1，将所有其他类设置为y = 0来为每个类训练K个SVM分类器。</strong></p><p id="a77f" class="pw-post-body-paragraph lw lx jg ly b lz ms kq mb mc mt kt me mf mu mh mi mj mv ml mm mn mw mp mq mr ij bi translated">通过选择具有最高假设值的SVM来完成对示例的预测。</p><h2 id="b3d9" class="nc lf jg bd lg nd ne dn lk nf ng dp lo mf nh ni lq mj nj nk ls mn nl nm lu jm bi translated">重点说明。</h2><p id="3059" class="pw-post-body-paragraph lw lx jg ly b lz ma kq mb mc md kt me mf mg mh mi mj mk ml mm mn mo mp mq mr ij bi translated"><strong class="ly jq">何时使用SVM或逻辑回归分类器。</strong> <br/>如果特征的数量，n相对大于训练样本的数量，比如m，n = 10000，m = 10–1000，使用无核的logistic回归或SVM。</p><p id="d7b9" class="pw-post-body-paragraph lw lx jg ly b lz ms kq mb mc mt kt me mf mu mh mi mj mv ml mm mn mw mp mq mr ij bi translated">如果特征数量n很小，m是中间值，例如(n = 1–1000，m = 10–10000)，使用<strong class="ly jq">高斯核SVM。</strong></p><p id="7436" class="pw-post-body-paragraph lw lx jg ly b lz ms kq mb mc mt kt me mf mu mh mi mj mv ml mm mn mw mp mq mr ij bi translated">如果n很小而m很大，例如(n = 1 -1000，m = 50000+)，使用<strong class="ly jq">逻辑回归或线性核的SVM</strong>是明智的。</p><p id="261a" class="pw-post-body-paragraph lw lx jg ly b lz ms kq mb mc mt kt me mf mu mh mi mj mv ml mm mn mw mp mq mr ij bi translated">对于上述所有情况，神经网络往往工作良好。只是稍微慢一点。</p><p id="b8f3" class="pw-post-body-paragraph lw lx jg ly b lz ms kq mb mc mt kt me mf mu mh mi mj mv ml mm mn mw mp mq mr ij bi translated"><em class="nn">如果你想了解更多细节，Savan写了一篇关于支持向量机的文章</em> <a class="ae jd" href="https://medium.com/machine-learning-101/chapter-2-svm-support-vector-machine-theory-f0812effc72" rel="noopener"> <em class="nn">这里</em> </a> <em class="nn">。</em></p><blockquote class="nq"><p id="a375" class="nr ns jg bd nt nu nv nw nx ny nz mr dk translated">第七天结束了！！</p></blockquote><h1 id="f7a7" class="le lf jg bd lg lh li lj lk ll lm ln lo kv os kw lq ky ot kz ls lb ou lc lu lv bi translated">**第8天亮点**</h1><h1 id="7e48" class="le lf jg bd lg lh li lj lk ll lm ln lo kv lp kw lq ky lr kz ls lb lt lc lu lv bi translated">无监督学习。</h1><p id="ec24" class="pw-post-body-paragraph lw lx jg ly b lz ma kq mb mc md kt me mf mg mh mi mj mk ml mm mn mo mp mq mr ij bi translated">在<a class="ae jd" href="https://beltus.github.io/vision/ml/2020-03-05-supervised-unsupervised-learning/" rel="noopener ugc nofollow" target="_blank">无监督机器学习</a>中，模型被输入<strong class="ly jq"> <em class="nn">未标记数据</em>。</strong>在数据中寻找隐藏的结构、模式或关系是由算法决定的。</p><p id="a911" class="pw-post-body-paragraph lw lx jg ly b lz ms kq mb mc mt kt me mf mu mh mi mj mv ml mm mn mw mp mq mr ij bi translated">聚类算法通常用于无监督的机器学习任务。</p><p id="0b40" class="pw-post-body-paragraph lw lx jg ly b lz ms kq mb mc mt kt me mf mu mh mi mj mv ml mm mn mw mp mq mr ij bi translated"><a class="ae jd" href="https://towardsdatascience.com/k-means-clustering-algorithm-applications-evaluation-methods-and-drawbacks-aa03e644b48a" rel="noopener" target="_blank"> <strong class="ly jq"> K-means聚类</strong> </a> <strong class="ly jq">算法</strong>是使用最多的聚类算法。它用于获得关于数据结构的直觉。</p><p id="1ce7" class="pw-post-body-paragraph lw lx jg ly b lz ms kq mb mc mt kt me mf mu mh mi mj mv ml mm mn mw mp mq mr ij bi translated">该算法是迭代的，基于两个主要步骤。</p><ol class=""><li id="641a" class="pn po jg ly b lz ms mc mt mf pp mj pq mn pr mr ps pt pu pv bi translated"><strong class="ly jq">聚类分配步骤</strong>，其基于训练样本与聚类质心的接近度将训练样本分配给每个聚类。</li></ol><p id="288f" class="pw-post-body-paragraph lw lx jg ly b lz ms kq mb mc mt kt me mf mu mh mi mj mv ml mm mn mw mp mq mr ij bi translated">2.<strong class="ly jq">移动聚类质心步骤</strong>，将每个质心重新定位到其聚类子集的平均值。</p><h2 id="3e0b" class="nc lf jg bd lg nd ne dn lk nf ng dp lo mf nh ni lq mj nj nk ls mn nl nm lu jm bi translated">K均值算法的步骤</h2><p id="a6f3" class="pw-post-body-paragraph lw lx jg ly b lz ma kq mb mc md kt me mf mg mh mi mj mk ml mm mn mo mp mq mr ij bi translated">K-means算法的工作方式如下:</p><blockquote class="oh oi oj"><p id="809f" class="lw lx nn ly b lz ms kq mb mc mt kt me ok mu mh mi ol mv ml mm om mw mp mq mr ij bi translated">1.指定集群数量<em class="jg"> K </em>。</p><p id="8e94" class="lw lx nn ly b lz ms kq mb mc mt kt me ok mu mh mi ol mv ml mm om mw mp mq mr ij bi translated">2.通过首先混洗数据集，然后为质心随机选择<em class="jg"> K </em>个数据点来初始化质心，而无需替换。</p><p id="3867" class="lw lx nn ly b lz ms kq mb mc mt kt me ok mu mh mi ol mv ml mm om mw mp mq mr ij bi translated">3.继续迭代，直到质心没有变化。也就是说，数据点到聚类的分配没有改变。</p><p id="3a25" class="lw lx nn ly b lz ms kq mb mc mt kt me ok mu mh mi ol mv ml mm om mw mp mq mr ij bi translated">4.计算数据点和所有质心之间距离的平方和。</p><p id="e528" class="lw lx nn ly b lz ms kq mb mc mt kt me ok mu mh mi ol mv ml mm om mw mp mq mr ij bi translated">5.将每个数据点分配给最近的聚类(质心)。</p><p id="6005" class="lw lx nn ly b lz ms kq mb mc mt kt me ok mu mh mi ol mv ml mm om mw mp mq mr ij bi translated">6.通过取属于每个聚类的所有数据点的平均值来计算聚类的质心。</p></blockquote><p id="c6e7" class="pw-post-body-paragraph lw lx jg ly b lz ms kq mb mc mt kt me mf mu mh mi mj mv ml mm mn mw mp mq mr ij bi translated">通过将k个聚类质心分配给随机选择的k个训练样本来完成聚类质心的初始化。</p><h2 id="3951" class="nc lf jg bd lg nd ne dn lk nf ng dp lo mf nh ni lq mj nj nk ls mn nl nm lu jm bi translated">降维</h2><p id="c12a" class="pw-post-body-paragraph lw lx jg ly b lz ma kq mb mc md kt me mf mg mh mi mj mk ml mm mn mo mp mq mr ij bi translated">这是另一种无监督学习算法。最常见的降维算法是<a class="ae jd" href="https://en.wikipedia.org/wiki/Principal_component_analysis" rel="noopener ugc nofollow" target="_blank"> <strong class="ly jq">【主成分分析】</strong> </a></p><p id="2fde" class="pw-post-body-paragraph lw lx jg ly b lz ms kq mb mc mt kt me mf mu mh mi mj mv ml mm mn mw mp mq mr ij bi translated">PCA旨在找到一个较低的k维特征超平面(表面),以最小化平方投影误差(从每个训练样本到投影表面的距离)的方式将较高维的训练样本投影到该超平面上</p><p id="48a5" class="pw-post-body-paragraph lw lx jg ly b lz ms kq mb mc mt kt me mf mu mh mi mj mv ml mm mn mw mp mq mr ij bi translated">在为PCA选择主成分k的数量时，选择k的最小值是一个好的实践，对于该最小值，保留了99%的方差。 </p><p id="1ba9" class="pw-post-body-paragraph lw lx jg ly b lz ms kq mb mc mt kt me mf mu mh mi mj mv ml mm mn mw mp mq mr ij bi translated">我们还将PCA应用于具有大量特征的监督学习问题。这仅适用于数据集的输入定型集，而不适用于数据集的交叉验证或测试集。</p><p id="9cb8" class="pw-post-body-paragraph lw lx jg ly b lz ms kq mb mc mt kt me mf mu mh mi mj mv ml mm mn mw mp mq mr ij bi translated">PCA找到从训练示例x(i)到z(i)的映射，其中z(i)是在运行PCA之后获得的新特征向量。因此，PCA可以被认为是监督学习算法的预处理步骤。</p><h2 id="1951" class="nc lf jg bd lg nd ne dn lk nf ng dp lo mf nh ni lq mj nj nk ls mn nl nm lu jm bi translated">主成分分析的主要应用</h2><p id="755c" class="pw-post-body-paragraph lw lx jg ly b lz ma kq mb mc md kt me mf mg mh mi mj mk ml mm mn mo mp mq mr ij bi translated"><strong class="ly jq"> 1。压缩:</strong>减少用于存储数据的内存/磁盘空间，加快学习算法。</p><p id="09ca" class="pw-post-body-paragraph lw lx jg ly b lz ms kq mb mc mt kt me mf mu mh mi mj mv ml mm mn mw mp mq mr ij bi translated">2.<strong class="ly jq">可视化应用</strong>其中主成分k的数量可以是1、2或3，以便于可视化。</p><p id="62fb" class="pw-post-body-paragraph lw lx jg ly b lz ms kq mb mc mt kt me mf mu mh mi mj mv ml mm mn mw mp mq mr ij bi translated"><em class="nn">这里有关于</em><a class="ae jd" href="https://www.geeksforgeeks.org/dimensionality-reduction/" rel="noopener ugc nofollow" target="_blank"><em class="nn">geekforgeks</em></a>更深入的降维信息</p><blockquote class="nq"><p id="c45a" class="nr ns jg bd nt nu nv nw nx ny nz mr dk translated">第八天结束了！！</p></blockquote><h1 id="0bc0" class="le lf jg bd lg lh li lj lk ll lm ln lo kv os kw lq ky ot kz ls lb ou lc lu lv bi translated">**第9天亮点**</h1><figure class="my mz na nb gt is gh gi paragraph-image"><div role="button" tabindex="0" class="it iu di iv bf iw"><div class="gh gi qn"><img src="../Images/1ddb22965ce37ffb2415d873c777901b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*GooGIjyGyIMmnokZqOe7Dg.png"/></div></div><figcaption class="iz ja gj gh gi jb jc bd b be z dk translated">图片来自Coursera</figcaption></figure><h2 id="0c15" class="nc lf jg bd lg nd ne dn lk nf ng dp lo mf nh ni lq mj nj nk ls mn nl nm lu jm bi translated">构建异常检测系统</h2><p id="3b43" class="pw-post-body-paragraph lw lx jg ly b lz ma kq mb mc md kt me mf mg mh mi mj mk ml mm mn mo mp mq mr ij bi translated"><a class="ae jd" href="https://www.wikiwand.com/en/Anomaly_detection" rel="noopener ugc nofollow" target="_blank">机器学习中的异常检测</a>用于预测我们数据集中与大多数数据显著不同的罕见事件。</p><p id="85af" class="pw-post-body-paragraph lw lx jg ly b lz ms kq mb mc mt kt me mf mu mh mi mj mv ml mm mn mw mp mq mr ij bi translated">它的主要应用是在<strong class="ly jq">欺诈检测</strong>中，我们使用未标记的数据集来建立一个概率模型。然后使用它来检测任何异常或欺诈活动。</p><p id="27ee" class="pw-post-body-paragraph lw lx jg ly b lz ms kq mb mc mt kt me mf mu mh mi mj mv ml mm mn mw mp mq mr ij bi translated"><strong class="ly jq">制造</strong>也使用异常检测来确定他们的产品是否有缺陷。<strong class="ly jq">监控数据中心的计算机</strong>或服务器也是我们看到异常检测应用的另一个领域。</p><p id="7df1" class="pw-post-body-paragraph lw lx jg ly b lz ms kq mb mc mt kt me mf mu mh mi mj mv ml mm mn mw mp mq mr ij bi translated"><a class="ae jd" href="https://www.wikiwand.com/en/Normal_distribution" rel="noopener ugc nofollow" target="_blank"> <strong class="ly jq">高斯分布</strong> </a>用于异常检测，我们使用训练集数据估计<br/>分布的均值和方差。</p><figure class="my mz na nb gt is gh gi paragraph-image"><div class="gh gi qo"><img src="../Images/f80071f2e724bac9f669f5ea3da701e1.png" data-original-src="https://miro.medium.com/v2/resize:fit:1024/format:webp/1*43F3r3WSMYJrrlp_HwF4vg.png"/></div><figcaption class="iz ja gj gh gi jb jc bd b be z dk translated">由SpLabs生成的图像</figcaption></figure><p id="3b00" class="pw-post-body-paragraph lw lx jg ly b lz ms kq mb mc mt kt me mf mu mh mi mj mv ml mm mn mw mp mq mr ij bi translated">通常，在异常检测算法中，我们估计训练数据集中各个特征的平均值(均值)和方差，这成为模型参数。</p><p id="be1e" class="pw-post-body-paragraph lw lx jg ly b lz ms kq mb mc mt kt me mf mu mh mi mj mv ml mm mn mw mp mq mr ij bi translated">给定一个新的例子x，我们简单地使用在训练期间获得的高斯分布参数的估计均值和方差来计算概率p(x)。</p><p id="fed1" class="pw-post-body-paragraph lw lx jg ly b lz ms kq mb mc mt kt me mf mu mh mi mj mv ml mm mn mw mp mq mr ij bi translated">如果p(x)&lt; epsilon, then the example, x, is anomalous, otherwise, it is a normal condition.</p><p id="7c41" class="pw-post-body-paragraph lw lx jg ly b lz ms kq mb mc mt kt me mf mu mh mi mj mv ml mm mn mw mp mq mr ij bi translated">The probability, p(x) is calculated based on the assumption of the independence of features. i.e p(x) is the product of the probability of each feature in the feature vector.</p><p id="e63f" class="pw-post-body-paragraph lw lx jg ly b lz ms kq mb mc mt kt me mf mu mh mi mj mv ml mm mn mw mp mq mr ij bi translated">P(x) = P(x1)*P(x2)*P(x3)……..P(xn)</p><p id="fb75" class="pw-post-body-paragraph lw lx jg ly b lz ms kq mb mc mt kt me mf mu mh mi mj mv ml mm mn mw mp mq mr ij bi translated">In building Anomaly detection systems, the dataset is often skewed as we usually have far more negative examples than positive. So, we recline from using classification accuracy as a performance metric which can be very high and misleading. It's preferable to use<strong class="ly jq">F1-得分度量。</strong></p><h2 id="9e1e" class="nc lf jg bd lg nd ne dn lk nf ng dp lo mf nh ni lq mj nj nk ls mn nl nm lu jm bi translated">何时使用异常检测技术。</h2><p id="a6fa" class="pw-post-body-paragraph lw lx jg ly b lz ma kq mb mc md kt me mf mg mh mi mj mk ml mm mn mo mp mq mr ij bi translated">当我们有非常少的正例(异常)和大量的负例(正常)时，我们使用异常检测而不是监督学习算法。这是因为监督学习将使学习算法从如此小的样本子集学习变得更具挑战性。</p><p id="6b36" class="pw-post-body-paragraph lw lx jg ly b lz ms kq mb mc mt kt me mf mu mh mi mj mv ml mm mn mw mp mq mr ij bi translated">当对捕捉特征之间的一些相关性感兴趣时，我们<br/>可以使用<strong class="ly jq">多元高斯模型</strong>来估计参数(均值向量和协方差矩阵)。</p><h2 id="7938" class="nc lf jg bd lg nd ne dn lk nf ng dp lo mf nh ni lq mj nj nk ls mn nl nm lu jm bi translated">推荐系统</h2><figure class="my mz na nb gt is gh gi paragraph-image"><div role="button" tabindex="0" class="it iu di iv bf iw"><div class="gh gi qp"><img src="../Images/cdc3748b69beb49affe4fb5248df14f5.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*dCEBhlDpuHkwEErkprmG_g.jpeg"/></div></div><figcaption class="iz ja gj gh gi jb jc bd b be z dk translated">图片来自走向数据科学</figcaption></figure><p id="36bd" class="pw-post-body-paragraph lw lx jg ly b lz ms kq mb mc mt kt me mf mu mh mi mj mv ml mm mn mw mp mq mr ij bi translated">推荐系统的目的是向用户推荐相关的项目。</p><p id="0450" class="pw-post-body-paragraph lw lx jg ly b lz ms kq mb mc mt kt me mf mu mh mi mj mv ml mm mn mw mp mq mr ij bi translated">推荐系统主要有两大类:<strong class="ly jq"> <em class="nn">基于内容和协同过滤的推荐系统。</em> </strong></p><h2 id="a801" class="nc lf jg bd lg nd ne dn lk nf ng dp lo mf nh ni lq mj nj nk ls mn nl nm lu jm bi translated">基于内容的推荐系统</h2><p id="21db" class="pw-post-body-paragraph lw lx jg ly b lz ma kq mb mc md kt me mf mg mh mi mj mk ml mm mn mo mp mq mr ij bi translated">比方说，我们收集了用户在网站上观看某些电影后给出的评级信息。推荐系统获取这些信息，并试图预测用户可能对他尚未观看的电影给出的评级值。</p><p id="5263" class="pw-post-body-paragraph lw lx jg ly b lz ms kq mb mc mt kt me mf mu mh mi mj mv ml mm mn mw mp mq mr ij bi translated">基于估计的分级值，系统决定向您推荐这部电影。所以在基于内容的推荐系统中，我们使用<strong class="ly jq"> <em class="nn">关于我们的用户和/或项目的附加信息。</em> </strong></p><h2 id="99d3" class="nc lf jg bd lg nd ne dn lk nf ng dp lo mf nh ni lq mj nj nk ls mn nl nm lu jm bi translated">协同过滤推荐系统</h2><p id="015d" class="pw-post-body-paragraph lw lx jg ly b lz ma kq mb mc md kt me mf mg mh mi mj mk ml mm mn mo mp mq mr ij bi translated">该方法用于自动学习推荐系统的相关特征。</p><p id="f9b6" class="pw-post-body-paragraph lw lx jg ly b lz ms kq mb mc mt kt me mf mu mh mi mj mv ml mm mn mw mp mq mr ij bi translated">协同过滤算法的目标是使用每个客户(用户)的评级，并学习一组特征X，然后使用这些特征来学习每个用户的模型参数。有了这些参数。基于这些学习到的特征X和参数θ，推荐器可以预测产品的评级，例如没有任何评级的电影。</p><p id="82cc" class="pw-post-body-paragraph lw lx jg ly b lz ms kq mb mc mt kt me mf mu mh mi mj mv ml mm mn mw mp mq mr ij bi translated">此外，学习到的参数可用于比较不同电影的特征，并基于差异向其用户推荐新电影。</p><p id="5125" class="pw-post-body-paragraph lw lx jg ly b lz ms kq mb mc mt kt me mf mu mh mi mj mv ml mm mn mw mp mq mr ij bi translated">这里有一篇<a class="ae jd" href="https://sandipanweb.wordpress.com/2016/07/02/using-low-rank-matrix-factorization-for-collaborative-filtering-recommender-system/" rel="noopener ugc nofollow" target="_blank">文章</a>关于协同过滤算法的更多信息。</p><p id="7f8f" class="pw-post-body-paragraph lw lx jg ly b lz ms kq mb mc mt kt me mf mu mh mi mj mv ml mm mn mw mp mq mr ij bi translated"><strong class="ly jq">关键注释</strong></p><p id="19ae" class="pw-post-body-paragraph lw lx jg ly b lz ms kq mb mc mt kt me mf mu mh mi mj mv ml mm mn mw mp mq mr ij bi translated">在推荐系统中，每个用户都有自己独特的模型参数集。所以用户的数量等于需要训练的线性回归模型的数量。</p><p id="4130" class="pw-post-body-paragraph lw lx jg ly b lz ms kq mb mc mt kt me mf mu mh mi mj mv ml mm mn mw mp mq mr ij bi translated"><strong class="ly jq">均值归一化</strong>有时用于增强模型的性能，尤其是当存在对产品没有评级的用户时。</p><p id="1785" class="pw-post-body-paragraph lw lx jg ly b lz ms kq mb mc mt kt me mf mu mh mi mj mv ml mm mn mw mp mq mr ij bi translated"><em class="nn">更多信息，h</em><a class="ae jd" href="https://towardsdatascience.com/introduction-to-recommender-systems-6c66cf15ada" rel="noopener" target="_blank"><em class="nn">ere</em></a><em class="nn">是Baptiste Rocca写的一篇关于推荐系统的文章</em></p><blockquote class="nq"><p id="d88f" class="nr ns jg bd nt nu nv nw nx ny nz mr dk translated">第九天结束了！！</p></blockquote><h1 id="7e16" class="le lf jg bd lg lh li lj lk ll lm ln lo kv os kw lq ky ot kz ls lb ou lc lu lv bi translated">**第10天重点**</h1><h2 id="dae5" class="nc lf jg bd lg nd ne dn lk nf ng dp lo mf nh ni lq mj nj nk ls mn nl nm lu jm bi translated">大规模机器学习</h2><p id="46d3" class="pw-post-body-paragraph lw lx jg ly b lz ma kq mb mc md kt me mf mg mh mi mj mk ml mm mn mo mp mq mr ij bi translated">随着训练数据集的大小增加到数百万个示例，用于寻找最佳模型参数的梯度下降(即批量梯度下降)算法由于所涉及的高计算时间而变得非常低效。</p><p id="f5c0" class="pw-post-body-paragraph lw lx jg ly b lz ms kq mb mc mt kt me mf mu mh mi mj mv ml mm mn mw mp mq mr ij bi translated"><strong class="ly jq">随机梯度下降(SGD) </strong>算法在这种情况下是首选，因为它快得多。在SGD算法中，我们首先混洗训练数据，然后对于每个训练样本，我们更新模型参数。</p><p id="ca6e" class="pw-post-body-paragraph lw lx jg ly b lz ms kq mb mc mt kt me mf mu mh mi mj mv ml mm mn mw mp mq mr ij bi translated">这与批量梯度下降相反，在批量梯度下降中，模型参数的单次更新涉及使用所有训练样本。</p><p id="55c4" class="pw-post-body-paragraph lw lx jg ly b lz ms kq mb mc mt kt me mf mu mh mi mj mv ml mm mn mw mp mq mr ij bi translated"><strong class="ly jq">小批量梯度下降</strong>在每次迭代中使用我们的小批量训练数据集来更新模型参数。与在每次更新迭代中使用单个示例的SGD相反。</p><h2 id="a6c6" class="nc lf jg bd lg nd ne dn lk nf ng dp lo mf nh ni lq mj nj nk ls mn nl nm lu jm bi translated">Map Reduce —数据并行方法</h2><figure class="my mz na nb gt is gh gi paragraph-image"><div role="button" tabindex="0" class="it iu di iv bf iw"><div class="gh gi qq"><img src="../Images/5400b2b6849ac7543c22e7bd056a91cb.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*TAaw-5mR3QpjgMg0fYxGRw.png"/></div></div></figure><p id="c758" class="pw-post-body-paragraph lw lx jg ly b lz ms kq mb mc mt kt me mf mu mh mi mj mv ml mm mn mw mp mq mr ij bi translated">在map-reduce方法中，包含数亿个示例的非常大的训练数据集被分成大小相等的子集，然后这些子集可以被提供给不同的机器。</p><p id="dcde" class="pw-post-body-paragraph lw lx jg ly b lz ms kq mb mc mt kt me mf mu mh mi mj mv ml mm mn mw mp mq mr ij bi translated">这允许在子集上同时计算部分和。然后，集中的机器组合来自这些多台计算机的结果，然后执行模型参数更新。</p><p id="35e6" class="pw-post-body-paragraph lw lx jg ly b lz ms kq mb mc mt kt me mf mu mh mi mj mv ml mm mn mw mp mq mr ij bi translated">这减少了学习模型参数所花费的时间。Map-reduce对于多核机器也是可行的，其中数据并行是在不同的核上完成的。</p><p id="62b2" class="pw-post-body-paragraph lw lx jg ly b lz ms kq mb mc mt kt me mf mu mh mi mj mv ml mm mn mw mp mq mr ij bi translated"><em class="nn">关于MapReduce </em> <a class="ae jd" href="https://www.wikiwand.com/en/MapReduce" rel="noopener ugc nofollow" target="_blank"> <em class="nn">的更多信息，请看这里</em> </a></p><blockquote class="nq"><p id="a9aa" class="nr ns jg bd nt nu nv nw nx ny nz mr dk translated">第10天结束了！！</p></blockquote><h1 id="1cc1" class="le lf jg bd lg lh li lj lk ll lm ln lo kv os kw lq ky ot kz ls lb ou lc lu lv bi translated">**第11天亮点**</h1><h2 id="5dfb" class="nc lf jg bd lg nd ne dn lk nf ng dp lo mf nh ni lq mj nj nk ls mn nl nm lu jm bi translated">机器学习管道</h2><figure class="my mz na nb gt is gh gi paragraph-image"><div role="button" tabindex="0" class="it iu di iv bf iw"><div class="gh gi qr"><img src="../Images/e67ee8ccb067cce7690f7e4c4446c8ba.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*peaOTNQS2ptfttD8l8CNLQ.png"/></div></div><figcaption class="iz ja gj gh gi jb jc bd b be z dk translated">典型的机器学习管道</figcaption></figure><p id="e775" class="pw-post-body-paragraph lw lx jg ly b lz ms kq mb mc mt kt me mf mu mh mi mj mv ml mm mn mw mp mq mr ij bi translated">机器学习问题的应用通常遵循流水线，例如上面所示的照片OCR(光学字符识别)的例子。每个模块的输出成为下一个模块的输入。</p><p id="0efb" class="pw-post-body-paragraph lw lx jg ly b lz ms kq mb mc mt kt me mf mu mh mi mj mv ml mm mn mw mp mq mr ij bi translated">通过<strong class="ly jq">人工合成方法获得大量数据是一种</strong>技术，只有当模型具有<strong class="ly jq">低偏差</strong>时<strong class="ly jq"> </strong>才能帮助提高你的模型的性能。通过<strong class="ly jq">绘制学习曲线</strong>可以看到低偏差。</p><h2 id="37bb" class="nc lf jg bd lg nd ne dn lk nf ng dp lo mf nh ni lq mj nj nk ls mn nl nm lu jm bi translated">关键音符</h2><p id="0314" class="pw-post-body-paragraph lw lx jg ly b lz ma kq mb mc md kt me mf mg mh mi mj mk ml mm mn mo mp mq mr ij bi translated">对于机器学习问题，重要的是首先使用学习<br/>曲线检查您的模型是否存在<strong class="ly jq">低偏差。</strong>其次，问这样一个问题，<em class="nn">要获得比你现有数据多10倍的数据，需要什么？然后你就可以生成新的数据集了。</em></p><h2 id="00dd" class="nc lf jg bd lg nd ne dn lk nf ng dp lo mf nh ni lq mj nj nk ls mn nl nm lu jm bi translated">上限分析</h2><p id="e7e3" class="pw-post-body-paragraph lw lx jg ly b lz ma kq mb mc md kt me mf mg mh mi mj mk ml mm mn mo mp mq mr ij bi translated">它是手动覆盖系统中每个组件的过程，以提供该组件100%准确的预测。此后，您可以逐个组件地观察您的机器学习系统的整体改进。这有助于确定您需要花时间改进管道的哪个组件。</p><p id="3169" class="pw-post-body-paragraph lw lx jg ly b lz ms kq mb mc mt kt me mf mu mh mi mj mv ml mm mn mw mp mq mr ij bi translated"><em class="nn">更多关于天花板分析的信息可以在</em> <a class="ae jd" href="https://medium.com/@rossbulat/ceiling-analysis-in-deep-learning-and-software-development-8bc41e59364a" rel="noopener"> <em class="nn">这里</em> </a>找到</p><blockquote class="nq"><p id="aac1" class="nr ns jg bd nt nu nv nw nx ny nz mr dk translated">第11天终于结束了！！</p></blockquote><h1 id="af57" class="le lf jg bd lg lh li lj lk ll lm ln lo kv os kw lq ky ot kz ls lb ou lc lu lv bi translated">结论</h1><p id="f68f" class="pw-post-body-paragraph lw lx jg ly b lz ma kq mb mc md kt me mf mg mh mi mj mk ml mm mn mo mp mq mr ij bi translated">在这篇文章中，我以结构化和时间顺序的方式介绍了机器学习的主要思想、概念和最佳实践。</p><p id="b673" class="pw-post-body-paragraph lw lx jg ly b lz ms kq mb mc mt kt me mf mu mh mi mj mv ml mm mn mw mp mq mr ij bi translated">它强调了所有11天中每天最重要的概念，同时最小化了机器学习中涉及的线性和多元微积分的技术细节。</p><p id="0b58" class="pw-post-body-paragraph lw lx jg ly b lz ms kq mb mc mt kt me mf mu mh mi mj mv ml mm mn mw mp mq mr ij bi translated">我知道这篇文章并不详尽，不可能深入涵盖这些概念中的大部分，所以我在文章中提供了一些链接，供有兴趣的读者进一步阅读。</p><p id="54c8" class="pw-post-body-paragraph lw lx jg ly b lz ms kq mb mc mt kt me mf mu mh mi mj mv ml mm mn mw mp mq mr ij bi translated">如果你有兴趣学习更多关于机器学习的知识，我鼓励你注册安德鲁的机器学习课程。这值得你花费时间和精力。这里是<a class="ae jd" href="https://www.coursera.org/learn/machine-learning" rel="noopener ugc nofollow" target="_blank"> <strong class="ly jq"> Coursera </strong> </a> <strong class="ly jq">上的课程链接。</strong>该课程帮助我构建了这篇文章。</p><h1 id="d768" class="le lf jg bd lg lh li lj lk ll lm ln lo kv lp kw lq ky lr kz ls lb lt lc lu lv bi translated">感谢阅读！</h1><p id="2f29" class="pw-post-body-paragraph lw lx jg ly b lz ma kq mb mc md kt me mf mg mh mi mj mk ml mm mn mo mp mq mr ij bi translated">如果你觉得这篇文章有帮助，请随时联系我。</p><ol class=""><li id="1a05" class="pn po jg ly b lz ms mc mt mf pp mj pq mn pr mr ps pt pu pv bi translated">可以在<strong class="ly jq">中</strong>T8】这里关注我。</li><li id="0c97" class="pn po jg ly b lz qa mc qb mf qc mj qd mn qe mr ps pt pu pv bi translated">在<strong class="ly jq"> LinkedIn </strong>上关注我<a class="ae jd" href="https://www.linkedin.com/in/beltus/" rel="noopener ugc nofollow" target="_blank">这里</a>。</li><li id="fe93" class="pn po jg ly b lz qa mc qb mf qc mj qd mn qe mr ps pt pu pv bi translated">访问我的网站；<a class="ae jd" href="https://beltus.github.io/vision/blog/" rel="noopener ugc nofollow" target="_blank"><strong class="ly jq">beltus . github . io</strong></a>查看更多有趣的帖子。</li><li id="d5a5" class="pn po jg ly b lz qa mc qb mf qc mj qd mn qe mr ps pt pu pv bi translated">关注我<strong class="ly jq"> </strong> <a class="ae jd" href="https://twitter.com/beltusnkwawir" rel="noopener ugc nofollow" target="_blank"> <strong class="ly jq">推特</strong> </a></li></ol></div></div>    
</body>
</html>