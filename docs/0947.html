<html>
<head>
<title>Deep-fake Detection Using OpenCV and MTCNN</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">基于OpenCV和MTCNN的深度防伪检测</h1>
<blockquote>原文：<a href="https://pub.towardsai.net/deep-fake-detection-using-opencv-and-mtcnn-833625abdd03?source=collection_archive---------1-----------------------#2020-09-19">https://pub.towardsai.net/deep-fake-detection-using-opencv-and-mtcnn-833625abdd03?source=collection_archive---------1-----------------------#2020-09-19</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><h2 id="6767" class="io ip iq bd b dl ir is it iu iv iw dk ix translated" aria-label="kicker paragraph"><a class="ae ep" href="https://towardsai.net/p/category/machine-learning/deep-learning" rel="noopener ugc nofollow" target="_blank">深度学习</a></h2><div class=""/><figure class="gl gn jx jy jz ka gh gi paragraph-image"><div role="button" tabindex="0" class="kb kc di kd bf ke"><div class="gh gi jw"><img src="../Images/41e875754faa6c849281b85d10376d63.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*QPdGdO7T2MRzsllA98HCwg.jpeg"/></div></div><figcaption class="kh ki gj gh gi kj kk bd b be z dk translated">来源:https://stockup.sitebuilderreport.com<a class="ae kl" href="https://stockup.sitebuilderreport.com" rel="noopener ugc nofollow" target="_blank"/></figcaption></figure><p id="fea7" class="pw-post-body-paragraph km kn iq ko b kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">这个周末，我碰到了一个有趣的话题。话题很深——假货。有许多关于流行名人或政治家的假视频的报道。这些被操纵的视频是通过操纵原始视频而创建的。这些假视频很难用肉眼发现，它们正在成为社会的一个重要问题。</p><p id="42a9" class="pw-post-body-paragraph km kn iq ko b kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">脸书、推特、Youtube等社交媒体平台。是这些被篡改的视频的主要发布渠道。当这些平台正在努力解决这个问题时，脸书正在投入巨资(1000万美元)来解决这个问题，Twitter和Google等其他平台也在努力解决这个问题。这是谷歌打击深度假货的一些<a class="ae kl" href="https://ai.googleblog.com/2019/09/contributing-data-to-deepfake-detection.html" rel="noopener ugc nofollow" target="_blank">细节</a>。</p><p id="a929" class="pw-post-body-paragraph km kn iq ko b kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">在这篇文章中，我们将讨论如何识别真假。它包括将视频分解成一帧，从真实和虚假的视频中检测人脸，裁剪人脸，并对其进行分析。我们将使用:</p><ol class=""><li id="e89d" class="lk ll iq ko b kp kq kt ku kx lm lb ln lf lo lj lp lq lr ls bi translated">OpenCV: OpenCV支持大量与计算机视觉和机器学习相关的算法。OpenCV有一个叫做“OpenCV-python”的Python库。</li><li id="237d" class="lk ll iq ko b kp lt kt lu kx lv lb lw lf lx lj lp lq lr ls bi translated">Numpy:它用于python中数组的一般表示和操作。</li><li id="cc4c" class="lk ll iq ko b kp lt kt lu kx lv lb lw lf lx lj lp lq lr ls bi translated">scikit-image:我们将使用这个工具对面部图像进行操作。</li><li id="d44a" class="lk ll iq ko b kp lt kt lu kx lv lb lw lf lx lj lp lq lr ls bi translated">Matplotlib:用于绘制检测结果(直方图和ROC <br/>曲线等)。).</li></ol><p id="80b4" class="pw-post-body-paragraph km kn iq ko b kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">数据集</p><p id="64f8" class="pw-post-body-paragraph km kn iq ko b kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">我们使用的是DeepfakeTIMIT数据库(T8)，这是一个视频数据库，使用开源的基于GAN的方法交换人脸。</p><p id="f0a9" class="pw-post-body-paragraph km kn iq ko b kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">这个数据集是从最初的<a class="ae kl" href="https://github.com/deepfakes/faceswap" rel="noopener ugc nofollow" target="_blank">基于自动编码器的Deepfake算法</a>中创建的。</p><p id="b869" class="pw-post-body-paragraph km kn iq ko b kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">我们将使用两种不同的GAN模型进行训练/测试:低质量(LQ)的64 x 64输入/输出尺寸模型，高质量(HQ)的128 x 128尺寸模型。</p><p id="9733" class="pw-post-body-paragraph km kn iq ko b kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">让我们进入正题。</p><p id="c88f" class="pw-post-body-paragraph km kn iq ko b kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">我们将使用两种不同的GAN模型进行训练/测试:低质量(LQ)的64 x 64输入/输出尺寸模型，高质量(HQ)的128 x 128尺寸模型。</p><p id="ac18" class="pw-post-body-paragraph km kn iq ko b kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">让我们进入正题。</p><h1 id="cc07" class="ly lz iq bd ma mb mc md me mf mg mh mi mj mk ml mm mn mo mp mq mr ms mt mu mv bi translated">OpenCV</h1><p id="6b74" class="pw-post-body-paragraph km kn iq ko b kp mw kr ks kt mx kv kw kx my kz la lb mz ld le lf na lh li lj ij bi translated"><strong class="ko ja">使用pip安装OpenCV</strong></p><pre class="nb nc nd ne gt nf ng nh ni aw nj bi"><span id="22e0" class="nk lz iq ng b gy nl nm l nn no">pip install opencv</span></pre><p id="da6a" class="pw-post-body-paragraph km kn iq ko b kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated"><strong class="ko ja">窗户安装</strong></p><p id="1b86" class="pw-post-body-paragraph km kn iq ko b kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">请关注这篇文章:</p><p id="fe79" class="pw-post-body-paragraph km kn iq ko b kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated"><a class="ae kl" href="https://opencv-python-tutroals.readthedocs.io/en/latest/py_tutorials/py_setup/py_setup_in_windows/py_setup_in_windows.html" rel="noopener ugc nofollow" target="_blank">https://opencv-python-tutro als . readthedocs . io/en/latest/py _ tutorials/py _ setup/py _ setup _ in _ windows/py _ setup _ in _ windows . html</a></p><p id="720b" class="pw-post-body-paragraph km kn iq ko b kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">OpenCV将用于四个主要任务。</p><ol class=""><li id="edaa" class="lk ll iq ko b kp kq kt ku kx lm lb ln lf lo lj lp lq lr ls bi translated">图像处理</li><li id="318a" class="lk ll iq ko b kp lt kt lu kx lv lb lw lf lx lj lp lq lr ls bi translated">视频处理</li><li id="5fb0" class="lk ll iq ko b kp lt kt lu kx lv lb lw lf lx lj lp lq lr ls bi translated">特征检测</li><li id="a7c5" class="lk ll iq ko b kp lt kt lu kx lv lb lw lf lx lj lp lq lr ls bi translated">目标检测</li></ol><p id="6496" class="pw-post-body-paragraph km kn iq ko b kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">让我们讨论一下OpenCV的一些基础知识</p><p id="53ba" class="pw-post-body-paragraph km kn iq ko b kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">要使用OpenCV，您需要做的就是</p><pre class="nb nc nd ne gt nf ng nh ni aw nj bi"><span id="b4c3" class="nk lz iq ng b gy nl nm l nn no">Import cv2</span></pre><p id="db81" class="pw-post-body-paragraph km kn iq ko b kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated"><strong class="ko ja">读一个图像</strong></p><pre class="nb nc nd ne gt nf ng nh ni aw nj bi"><span id="d4c5" class="nk lz iq ng b gy nl nm l nn no">import numpy as np<br/>import cv2</span><span id="6369" class="nk lz iq ng b gy np nm l nn no"># Load an color image in grayscale<br/>img = cv2.imread('imagename.jpg',0)</span></pre><p id="77ab" class="pw-post-body-paragraph km kn iq ko b kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">cv2.imread()函数有两个参数。第一个是图像源，第二个是标志，它指定了读取图像的方式。他们是</p><ul class=""><li id="633d" class="lk ll iq ko b kp kq kt ku kx lm lb ln lf lo lj nq lq lr ls bi translated">cv2。加载一幅彩色图像。图像的任何透明度都将被忽略。这是默认标志。</li><li id="d13d" class="lk ll iq ko b kp lt kt lu kx lv lb lw lf lx lj nq lq lr ls bi translated">cv2。im read _ gray:以灰度模式加载图像</li><li id="7a52" class="lk ll iq ko b kp lt kt lu kx lv lb lw lf lx lj nq lq lr ls bi translated">cv2。IMREAD_UNCHANGED:加载图像本身，包括alpha通道</li></ul><p id="4355" class="pw-post-body-paragraph km kn iq ko b kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">在您的函数中，我们将“0”作为第二个参数传递。可以传递全名，也可以分别传递1、0和-1。</p><p id="a0b6" class="pw-post-body-paragraph km kn iq ko b kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated"><strong class="ko ja">显示一幅图像</strong></p><pre class="nb nc nd ne gt nf ng nh ni aw nj bi"><span id="ba26" class="nk lz iq ng b gy nl nm l nn no">cv2.imshow('image',img)<br/>cv2.waitKey(0)<br/>cv2.destroyAllWindows()</span></pre><p id="0117" class="pw-post-body-paragraph km kn iq ko b kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">cv2.imshow()有两个参数。第一个是图像的名称，第二个是图像来源。cv2.waitKey()为任何键盘事件等待指定的毫秒数。cv2.destroyAllWindows()简单地销毁我们创建的所有窗口。</p><p id="4f10" class="pw-post-body-paragraph km kn iq ko b kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated"><strong class="ko ja">写一个图像</strong></p><pre class="nb nc nd ne gt nf ng nh ni aw nj bi"><span id="ec3d" class="nk lz iq ng b gy nl nm l nn no">cv2.imwrite('imagename.png',img)</span></pre><p id="daa0" class="pw-post-body-paragraph km kn iq ko b kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">这将在当前目录中创建一个图像。第一个参数是您设置的图像文件的名称，第二个参数是实际的图像。</p><p id="be8e" class="pw-post-body-paragraph km kn iq ko b kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated"><strong class="ko ja">从摄像机捕捉视频</strong></p><pre class="nb nc nd ne gt nf ng nh ni aw nj bi"><span id="7aa6" class="nk lz iq ng b gy nl nm l nn no">import numpy as np<br/>import cv2</span><span id="a9a0" class="nk lz iq ng b gy np nm l nn no">cap = cv2.VideoCapture(0)</span><span id="e60d" class="nk lz iq ng b gy np nm l nn no">while(True):<br/>    # Capture frame-by-frame<br/>    ret, frame = cap.read()</span><span id="3109" class="nk lz iq ng b gy np nm l nn no">    # Our operations on the frame come here<br/>    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)</span><span id="8f26" class="nk lz iq ng b gy np nm l nn no">    # Display the resulting frame<br/>    cv2.imshow('frame',gray)<br/>    if cv2.waitKey(1) &amp; 0xFF == ord('q'):<br/>        break</span><span id="b465" class="nk lz iq ng b gy np nm l nn no"># When everything done, release the capture<br/>cap.release()<br/>cv2.destroyAllWindows()</span></pre><p id="dcc4" class="pw-post-body-paragraph km kn iq ko b kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">代码参考:<a class="ae kl" href="https://opencv-python-tutroals.readthedocs.io/en/latest/py_tutorials/py_gui/py_video_display/py_video_display.html" rel="noopener ugc nofollow" target="_blank">官方OpenCV库网站</a></p><p id="117c" class="pw-post-body-paragraph km kn iq ko b kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">这将打开摄像机中的视频。</p><p id="9d82" class="pw-post-body-paragraph km kn iq ko b kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated"><strong class="ko ja">播放文件中的视频。</strong></p><pre class="nb nc nd ne gt nf ng nh ni aw nj bi"><span id="e871" class="nk lz iq ng b gy nl nm l nn no">import numpy as np<br/>import cv2</span><span id="cbb2" class="nk lz iq ng b gy np nm l nn no">cap = cv2.VideoCapture('yourvoideofilename.avi')</span><span id="d55b" class="nk lz iq ng b gy np nm l nn no">while(cap.isOpened()):<br/>    ret, frame = cap.read()</span><span id="4da0" class="nk lz iq ng b gy np nm l nn no">    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)</span><span id="0333" class="nk lz iq ng b gy np nm l nn no">    cv2.imshow('frame',gray)<br/>    if cv2.waitKey(1) &amp; 0xFF == ord('q'):<br/>        break</span><span id="293e" class="nk lz iq ng b gy np nm l nn no">cap.release()<br/>cv2.destroyAllWindows()</span></pre><p id="0cc3" class="pw-post-body-paragraph km kn iq ko b kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">代码参考:<a class="ae kl" href="https://opencv-python-tutroals.readthedocs.io/en/latest/py_tutorials/py_gui/py_video_display/py_video_display.html" rel="noopener ugc nofollow" target="_blank">官方OpenCV库网站</a>。</p><p id="5890" class="pw-post-body-paragraph km kn iq ko b kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">它将从您提供的路径打开一个视频文件。这些是OpenCV中执行的一般任务，但是你可以在这里找到更多的<a class="ae kl" href="https://opencv-python-tutroals.readthedocs.io/en/latest/py_tutorials/py_gui/py_drawing_functions/py_drawing_functions.html" rel="noopener ugc nofollow" target="_blank"/>。</p><h2 id="f1a7" class="nk lz iq bd ma nr ns dn me nt nu dp mi kx nv nw mm lb nx ny mq lf nz oa mu iw bi translated">Matplotlib</h2><p id="fe3c" class="pw-post-body-paragraph km kn iq ko b kp mw kr ks kt mx kv kw kx my kz la lb mz ld le lf na lh li lj ij bi translated">Matplotlib会给你各种各样的绘图方法。我们将在本文后面讨论更多内容。下面是一个如何使用matplotlib显示图像的示例。</p><pre class="nb nc nd ne gt nf ng nh ni aw nj bi"><span id="37b2" class="nk lz iq ng b gy nl nm l nn no">import numpy as np<br/>import cv2<br/>from matplotlib import pyplot as plt</span><span id="4f36" class="nk lz iq ng b gy np nm l nn no">img = cv2.imread('yourimagename.jpg',0)<br/>plt.imshow(img, cmap = 'gray', interpolation = 'bicubic')</span><span id="0c46" class="nk lz iq ng b gy np nm l nn no"># to hide tick values on X and Y axis<br/>plt.xticks([]), plt.yticks([])  <br/>plt.show()</span></pre><p id="ca7a" class="pw-post-body-paragraph km kn iq ko b kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">它将显示您提供的路径中的图像。</p><p id="fc08" class="pw-post-body-paragraph km kn iq ko b kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">现在，我们的主要目标是从path中读取视频文件，并从我们选择的真实视频和虚假视频中提取帧。然后执行面部检测以提取面部。之后，我们用各种方法分析了这两张人脸图像的差异。我把代码分成多个部分。我希望它能更容易阅读。</p><pre class="nb nc nd ne gt nf ng nh ni aw nj bi"><span id="1485" class="nk lz iq ng b gy nl nm l nn no">#required Libraries</span><span id="14cb" class="nk lz iq ng b gy np nm l nn no">import numpy as np<br/>import matplotlib.pyplot as plt<br/>import cv2<br/>import pandas as pd<br/>import glob2<br/>import os, fnmatch<br/>from pathlib import Path<br/># import mtcnn<br/>from mtcnn.mtcnn import MTCNN</span></pre><p id="cc75" class="pw-post-body-paragraph km kn iq ko b kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">处理视频</p><pre class="nb nc nd ne gt nf ng nh ni aw nj bi"><span id="13fe" class="nk lz iq ng b gy nl nm l nn no"># reading video fame<br/># Create a VideoCapture object and read from input file</span><span id="fdd3" class="nk lz iq ng b gy np nm l nn no">def extract_multiple_videos(intput_filenames, image_path_infile):<br/>    """Extract video files into sequence of images."""</span><span id="1345" class="nk lz iq ng b gy np nm l nn no">i = 1  # Counter of first video</span><span id="4e25" class="nk lz iq ng b gy np nm l nn no"># Iterate file names:<br/>    cap = cv2.VideoCapture('your_video_file_path.avi' or intput_filenames)</span><span id="9672" class="nk lz iq ng b gy np nm l nn no">if (cap.isOpened()== False):<br/>        print("Error opening file")</span><span id="1d63" class="nk lz iq ng b gy np nm l nn no"># Keep iterating break<br/>    while True:<br/>        ret, frame = cap.read()  # Read frame from first video<br/>            <br/>        if ret:<br/>            cv2.imwrite(os.path.join(image_path_infile , str(i) + '.jpg'), frame)  # Write frame to JPEG file (1.jpg, 2.jpg, ...)</span><span id="833b" class="nk lz iq ng b gy np nm l nn no"># you can uncomment this line if you want to view them.<br/>#           cv2.imshow('frame', frame)  # Display frame for testing<br/>            i += 1 # Advance file counter<br/>        else:<br/>            # Break the interal loop when res status is False.<br/>            break</span><span id="2ccc" class="nk lz iq ng b gy np nm l nn no">cv2.waitKey(50) #Wait 50msec</span><span id="e34c" class="nk lz iq ng b gy np nm l nn no">cap.release()</span></pre><p id="f08f" class="pw-post-body-paragraph km kn iq ko b kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">调用这个函数</p><pre class="nb nc nd ne gt nf ng nh ni aw nj bi"><span id="e685" class="nk lz iq ng b gy nl nm l nn no"># extract_multiple_videos(real_video_name,real_image_path_for_frame)</span><span id="48ea" class="nk lz iq ng b gy np nm l nn no">extract_multiple_videos(fake_video_name, fake_image_path_for_frame)<br/>extract_multiple_videos(real_video_name, real_image_path_for_frame)</span></pre><p id="5a21" class="pw-post-body-paragraph km kn iq ko b kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated"><strong class="ko ja">extract _ multiple _ videos()</strong>函数有两个参数。第一个参数是视频文件路径。第二个参数是保存提取的帧的路径。</p><p id="d4ba" class="pw-post-body-paragraph km kn iq ko b kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">我们只是加载了视频，读取了帧，并把它们写到一个文件中。</p><p id="7f9a" class="pw-post-body-paragraph km kn iq ko b kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">现在，让我们找出两个框架之间的差异，并可视化的差异。</p><pre class="nb nc nd ne gt nf ng nh ni aw nj bi"><span id="e7f3" class="nk lz iq ng b gy nl nm l nn no"># from skimage.measure import structural_similarity as ssim<br/>from skimage import measure</span><span id="1f01" class="nk lz iq ng b gy np nm l nn no">def mse(imageA, imageB):<br/>    # the 'Mean Squared Error' between the two images is the<br/>    # sum of the squared difference between the two images;<br/>    # NOTE: the two images must have the same dimension<br/>    err = np.sum((imageA.astype("float") - imageB.astype("float")) ** 2)<br/>    err /= float(imageA.shape[0] * imageA.shape[1])</span><span id="51ad" class="nk lz iq ng b gy np nm l nn no"># return the MSE, the lower the error, the more "similar"<br/>    # the two images are<br/>    return err<br/>def compare_images(imageA, imageB, title):<br/>    # compute the mean squared error and structural similarity<br/>    # index for the images<br/>    m = mse(imageA, imageB)<br/>    s = measure.compare_ssim(imageA, imageB)<br/>    # setup the figure<br/>    fig = plt.figure(title)<br/>    plt.suptitle("MSE: %.2f, SSIM: %.2f" % (m, s))<br/>    # show first image<br/>    ax = fig.add_subplot(1, 2, 1)<br/>    plt.imshow(imageA, cmap = plt.cm.gray)<br/>    plt.axis("off")<br/>    # show the second image<br/>    ax = fig.add_subplot(1, 2, 2)<br/>    plt.imshow(imageB, cmap = plt.cm.gray)<br/>    plt.axis("off")<br/>    # show the images<br/>    plt.show()</span></pre><p id="ce12" class="pw-post-body-paragraph km kn iq ko b kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">代码参考:【https://www.pyimagesearch.com T2】</p><pre class="nb nc nd ne gt nf ng nh ni aw nj bi"><span id="ee71" class="nk lz iq ng b gy nl nm l nn no">original = cv2.imread("image_path_from_real_video")<br/>shopped = cv2.imread("image_path_from_fake_video")<br/># convert the images to grayscale<br/>original = cv2.cvtColor(original, cv2.COLOR_BGR2GRAY)<br/>shopped = cv2.cvtColor(shopped, cv2.COLOR_BGR2GRAY)</span></pre><p id="c1c6" class="pw-post-body-paragraph km kn iq ko b kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">调用函数</p><pre class="nb nc nd ne gt nf ng nh ni aw nj bi"><span id="7ea9" class="nk lz iq ng b gy nl nm l nn no"># initialize the figure<br/>fig = plt.figure("Images")<br/>images = ("Original", original), ("modified", shopped)<br/># loop over the images<br/>for (i, (name, image)) in enumerate(images):<br/> # show the image<br/> ax = fig.add_subplot(1, 3, i + 1)<br/> ax.set_title(name)<br/> plt.imshow(image, cmap = plt.cm.gray)<br/> plt.axis("off")<br/># show the figure<br/>plt.show()</span><span id="f0c5" class="nk lz iq ng b gy np nm l nn no"># compare the images<br/>compare_images(original, original, "Original vs. Original")<br/>compare_images(original, shopped, "Original vs. Modified")<br/># cv2.subtract(original)<br/># img3 = original-shopped<br/>image3 = cv2.absdiff(original, shopped)<br/>image3</span><span id="23cc" class="nk lz iq ng b gy np nm l nn no">is_all_zero = not np.any(image3)</span><span id="3ebd" class="nk lz iq ng b gy np nm l nn no">if is_all_zero:<br/>    print('Array contains only 0')<br/>else:<br/>    print('Array has non-zero items too')</span></pre><p id="75b7" class="pw-post-body-paragraph km kn iq ko b kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">在上面的代码中，我们比较了从原始视频中提取的图像和从假视频中提取的相应图像。在代码的最后一部分，我检查两个图像是否有差异。</p><p id="d691" class="pw-post-body-paragraph km kn iq ko b kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">输出:</p><figure class="nb nc nd ne gt ka gh gi paragraph-image"><div role="button" tabindex="0" class="kb kc di kd bf ke"><div class="gh gi ob"><img src="../Images/8cd8fc93a6ff63114e890b570a7d7137.png" data-original-src="https://miro.medium.com/v2/resize:fit:1258/format:webp/1*IPuFmuAlVh7az4iZXMycNA.png"/></div></div></figure><figure class="nb nc nd ne gt ka gh gi paragraph-image"><div role="button" tabindex="0" class="kb kc di kd bf ke"><div class="gh gi ob"><img src="../Images/8cd8fc93a6ff63114e890b570a7d7137.png" data-original-src="https://miro.medium.com/v2/resize:fit:1258/format:webp/1*IPuFmuAlVh7az4iZXMycNA.png"/></div></div></figure><figure class="nb nc nd ne gt ka gh gi paragraph-image"><div class="gh gi oc"><img src="../Images/aeac81ef23c14471b44780465354bf8f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1082/format:webp/1*-saiyEQX-17eHv_rzVACuQ.png"/></div></figure><p id="812a" class="pw-post-body-paragraph km kn iq ko b kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">现在我们很难过，这两个图像是不同的。我们可以计算<strong class="ko ja"> SSIM。</strong></p><p id="93f1" class="pw-post-body-paragraph km kn iq ko b kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated"><strong class="ko ja">计算结构相似指数(SSIM) </strong></p><pre class="nb nc nd ne gt nf ng nh ni aw nj bi"><span id="c0b1" class="nk lz iq ng b gy nl nm l nn no">from skimage.measure import compare_ssim<br/>import argparse<br/>import imutils</span><span id="2495" class="nk lz iq ng b gy np nm l nn no">(score, diff) = compare_ssim(original, shopped, full=True)<br/>diff = (diff * 255).astype(“uint8”)<br/>print(“SSIM: {}”.format(score))</span></pre><p id="acdb" class="pw-post-body-paragraph km kn iq ko b kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">该分数表示两幅图像之间的结构相似性。所以我们的图像91.50 %相似。diff变量包含两个图像之间的实际位差。如果打印出来，可以在Diff中看到这个数组。</p><p id="a643" class="pw-post-body-paragraph km kn iq ko b kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated"><strong class="ko ja">寻找图像差异</strong></p><pre class="nb nc nd ne gt nf ng nh ni aw nj bi"><span id="7a3c" class="nk lz iq ng b gy nl nm l nn no">thresh = cv2.threshold(diff, 0, 255,cv2.THRESH_BINARY_INV | cv2.THRESH_OTSU)[1]<br/>cnts = cv2.findContours(thresh.copy(), cv2.RETR_EXTERNAL,cv2.CHAIN_APPROX_SIMPLE)<br/>cnts = imutils.grab_contours(cnts)</span></pre><p id="2a00" class="pw-post-body-paragraph km kn iq ko b kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">显示图像</p><pre class="nb nc nd ne gt nf ng nh ni aw nj bi"><span id="4711" class="nk lz iq ng b gy nl nm l nn no">%matplotlib inline# loop over the contours<br/>for c in cnts:<br/> # compute the bounding box of the contour and then draw the<br/> # bounding box on both input images to represent where the two<br/> # images differ<br/> (x, y, w, h) = cv2.boundingRect(c)<br/> cv2.rectangle(original, (x, y), (x + w, y + h), (0, 0, 255), 2)<br/> cv2.rectangle(shopped, (x, y), (x + w, y + h), (0, 0, 255), 2)<br/> <br/># show the output images<br/># plt.imshow(“Original”, original)<br/>plt.imshow(original)<br/># cv2.waitKey(0)</span></pre><p id="4487" class="pw-post-body-paragraph km kn iq ko b kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">原象</p><figure class="nb nc nd ne gt ka gh gi paragraph-image"><div class="gh gi od"><img src="../Images/1a880387632933323d1f1edec3960ee2.png" data-original-src="https://miro.medium.com/v2/resize:fit:936/format:webp/1*PfEz88ewDNT0p8-5Ve8dyw.png"/></div><figcaption class="kh ki gj gh gi kj kk bd b be z dk translated">原象</figcaption></figure><p id="c813" class="pw-post-body-paragraph km kn iq ko b kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">修改的图像</p><figure class="nb nc nd ne gt ka gh gi paragraph-image"><div class="gh gi od"><img src="../Images/34fba234f3cbdfe655ed38938b418a4b.png" data-original-src="https://miro.medium.com/v2/resize:fit:936/format:webp/1*69JqpMfqhJOcj59UO0vfzA.png"/></div><figcaption class="kh ki gj gh gi kj kk bd b be z dk translated">修改的图像</figcaption></figure><p id="99e8" class="pw-post-body-paragraph km kn iq ko b kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">两幅图像的差异</p><figure class="nb nc nd ne gt ka gh gi paragraph-image"><div class="gh gi od"><img src="../Images/b8d08c35e5ca2f56a9832ad9244353d0.png" data-original-src="https://miro.medium.com/v2/resize:fit:936/format:webp/1*ladK5M0wA3WoholPf0-opg.png"/></div><figcaption class="kh ki gj gh gi kj kk bd b be z dk translated">两者之间的差异</figcaption></figure><p id="e20c" class="pw-post-body-paragraph km kn iq ko b kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">正如我们从图像中看到的，我们可以查看两幅图像之间的差异，并计算修改的部分。</p><p id="4f9f" class="pw-post-body-paragraph km kn iq ko b kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated"><strong class="ko ja">执行面部检测</strong></p><pre class="nb nc nd ne gt nf ng nh ni aw nj bi"><span id="5939" class="nk lz iq ng b gy nl nm l nn no">from matplotlib.patches import Rectangle<br/>from matplotlib.patches import Circle<br/>from matplotlib import pyplot<br/>from mtcnn.mtcnn import MTCNN</span><span id="9aab" class="nk lz iq ng b gy np nm l nn no"># draw an image with detected objects<br/>def draw_image_with_boxes(filename, result_list, face_filename):<br/> # load the image<br/> data = pyplot.imread(filename)<br/> for i in range(len(result_list)):<br/> # get coordinates<br/> x1, y1, width, height = result_list[i][‘box’]<br/> x2, y2 = x1 + width, y1 + height<br/> # define subplot<br/> pyplot.subplot(1, len(result_list), i+1)<br/> pyplot.axis(‘off’)<br/> # plot face<br/> pyplot.imshow(data[y1:y2, x1:x2])<br/> pyplot.savefig(‘Dataset/only_face/’+ face_filename)<br/># show the plot<br/>pyplot.show()</span></pre><p id="4f12" class="pw-post-body-paragraph km kn iq ko b kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">提取视频帧并用MTCNN检测人脸</p><pre class="nb nc nd ne gt nf ng nh ni aw nj bi"><span id="8555" class="nk lz iq ng b gy nl nm l nn no"># reading video fame<br/># Create a VideoCapture object and read from input file<br/>def extract_multiple_videos_faces(intput_video_file_names, image_path_infile):<br/>    """Extract video files into sequence of images.<br/>       Intput_filenames is a list for video file names"""</span><span id="4b42" class="nk lz iq ng b gy np nm l nn no">i = 1  # Counter of first video</span><span id="4b26" class="nk lz iq ng b gy np nm l nn no"># Iterate file names:<br/>    cap = cv2.VideoCapture('/Users/praladneupane/Documents/Third_Semester/695/projects/Deepfake/Dataset/VidTIMIT/mstk0/sa1.avi')<br/>        <br/>    if (cap.isOpened()== False):<br/>        print("Error opening video stream or file")</span><span id="aadb" class="nk lz iq ng b gy np nm l nn no"># Keep iterating break<br/>    while True:<br/>        ret, frame = cap.read()  # Read frame from first video<br/>            <br/>        if ret:<br/>            <br/>#           cv2.imwrite(str(i) + '.jpg', frame)  # Write frame to JPEG file (1.jpg, 2.jpg, ...)<br/>#             this code can be use to do 1.2.3 and 1.3, but i am only doing 1.3 now<br/>#             cv2.imwrite(os.path.join(image_path_infile , str(i) + '.jpg'), frame)  # Write frame to JPEG file (1.jpg, 2.jpg, ...)<br/>                <br/>#           cv2.imshow('frame', frame)  # Display frame for testing<br/>    <br/>            filename = os.path.join(image_path_infile , str(i) + '.jpg') <br/>        <br/>        # this line feels little odd. Cause it looks <br/>        # like i am reading it mannually but if i uncomment above line it will be dynamic everytime, cause those line <br/>        # creates the frame in the folder first.<br/>        <br/>            # load image from file<br/>            pixels = pyplot.imread(filename)<br/>            # create the detector, using default weights<br/>            detector = MTCNN()<br/>            # detect faces in the image<br/>            faces = detector.detect_faces(pixels)<br/>            # display faces on the original image<br/>            face_filename_crp = str(i) + '.jpg'<br/>            draw_image_with_boxes(filename, faces, face_filename_crp)<br/>        <br/>    <br/>            i += 1 # Advance file counter<br/>        <br/>            face_filename = str(i) + '.jpg'<br/>            # display faces on the original image<br/>#             draw_image_with_boxes(filename, faces,face_filename)<br/>        else:<br/>            # Break the interal loop when res status is False.<br/>            break</span><span id="b182" class="nk lz iq ng b gy np nm l nn no">cv2.waitKey(100) #Wait 100msec (for debugging)</span><span id="665b" class="nk lz iq ng b gy np nm l nn no">cap.release() #Release must be inside the outer loop</span></pre><p id="b59f" class="pw-post-body-paragraph km kn iq ko b kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">打电话吧</p><pre class="nb nc nd ne gt nf ng nh ni aw nj bi"><span id="6532" class="nk lz iq ng b gy nl nm l nn no">extract_multiple_videos_faces(video_file_path,real_image_path_for_frame)</span></pre><p id="58fa" class="pw-post-body-paragraph km kn iq ko b kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">这里，extract_multiple_videos_faces()函数需要两个参数。第一个参数是视频文件路径，第二个参数是保存这些视频的帧的位置。只需更改文件路径即可检测不同的视频，并传递一个路径保存在不同的目录中。</p><p id="71ab" class="pw-post-body-paragraph km kn iq ko b kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">现在你只有真实和虚假的面部图像。你可以试着实现上面叫做<strong class="ko ja">寻找轮廓</strong>的部分。这是故意的，所以试一试。</p><p id="b675" class="pw-post-body-paragraph km kn iq ko b kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">总之，我们能够从真实和虚假的视频中提取帧，比较和对比来自两者的相同图像，并检测差异。</p><p id="847b" class="pw-post-body-paragraph km kn iq ko b kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">[1]:P. Korshunov和S. Marcel，<br/> DeepFakes:人脸识别的新威胁？评估和检测。<br/> arXiv和Idiap研究报告</p><p id="8979" class="pw-post-body-paragraph km kn iq ko b kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">[2]:C. Sanderson和B.C. Lovell，<br/>用于稳健和可扩展身份推断的多区域概率直方图。<br/>计算机科学讲义(LNCS)，第5558卷，第199–208页，2009年。</p></div></div>    
</body>
</html>