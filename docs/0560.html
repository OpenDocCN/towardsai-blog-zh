<html>
<head>
<title>Sentiment Analysis on Tweets with NLP Achieving 96% Accuracy</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">使用NLP对推文进行情感分析，准确率达到96%</h1>
<blockquote>原文：<a href="https://pub.towardsai.net/sentiment-analysis-on-tweets-with-nlp-achieving-96-accuracy-8b63f0bcee99?source=collection_archive---------1-----------------------#2020-06-06">https://pub.towardsai.net/sentiment-analysis-on-tweets-with-nlp-achieving-96-accuracy-8b63f0bcee99?source=collection_archive---------1-----------------------#2020-06-06</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><h2 id="a5f3" class="ir is it bd b dl iu iv iw ix iy iz dk ja translated" aria-label="kicker paragraph">自然语言处理</h2><div class=""/><div class=""><h2 id="3b9a" class="pw-subtitle-paragraph jz jc it bd b ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq dk translated">在我的Github库中可以找到完整的代码。一手资料可在<a class="ae kr" href="https://opendatascience.com/intro-to-natural-language-processing/" rel="noopener ugc nofollow" target="_blank"> ODSC </a>获得</h2></div><figure class="kt ku kv kw gt kx gh gi paragraph-image"><div role="button" tabindex="0" class="ky kz di la bf lb"><div class="gh gi ks"><img src="../Images/c276955205313b67d4423bc875535643.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*qR5gWiDFuwOGTil8"/></div></div><figcaption class="le lf gj gh gi lg lh bd b be z dk translated">照片由<a class="ae kr" href="https://unsplash.com/@stereophototyp?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">莎拉·库菲</a>在<a class="ae kr" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>拍摄</figcaption></figure><p id="1ef0" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">人工智能最复杂的用途之一是NLP(自然语言处理)。原因是语言不同于所有其他类型的数据。例如，虽然数字和图像数据具有客观的优势，但书面文本是相对的。它的解释因文化而异:同一个句子对两个不同的人来说可能意味着完全不同的事情。</p><p id="8528" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">当然，数据分析师已经找到了让机器对文本内容有“基本理解”的有效解决方案。</p><h1 id="1a5b" class="me mf it bd mg mh mi mj mk ml mm mn mo ki mp kj mq kl mr km ms ko mt kp mu mv bi translated">情感分析</h1><p id="2d13" class="pw-post-body-paragraph li lj it lk b ll mw kd ln lo mx kg lq lr my lt lu lv mz lx ly lz na mb mc md im bi translated">学习NLP模型的第一步是创建情感分析。给定一些文本，人工智能应该被训练识别它的意思是积极的还是消极的。实际上，您可以使用该工具来了解客户对产品或新闻的总体看法，尤其是在没有数字度量(如评分)而只有文本的情况下。</p><h2 id="248a" class="nb mf it bd mg nc nd dn mk ne nf dp mo lr ng nh mq lv ni nj ms lz nk nl mu iz bi translated">机器学习与深度学习</h2><p id="42c8" class="pw-post-body-paragraph li lj it lk b ll mw kd ln lo mx kg lq lr my lt lu lv mz lx ly lz na mb mc md im bi translated">根据我的经验，我们必须根据问题的复杂程度使用不同的工具。在电影评论中，鉴于每个元素的复杂性，我们需要使用神经网络，但对于推文，我们可以使用机器学习，并取得非常有希望的结果。</p><h2 id="9a43" class="nb mf it bd mg nc nd dn mk ne nf dp mo lr ng nh mq lv ni nj ms lz nk nl mu iz bi translated">nltk</h2><p id="9aa3" class="pw-post-body-paragraph li lj it lk b ll mw kd ln lo mx kg lq lr my lt lu lv mz lx ly lz na mb mc md im bi translated">我将使用专门用于NLP的机器学习库，称为nltk。我更喜欢使用scikit-learn来创建机器学习模型，但它是一个专门用于表格数据而不是自然语言处理的库。</p><h1 id="2ed1" class="me mf it bd mg mh mi mj mk ml mm mn mo ki mp kj mq kl mr km ms ko mt kp mu mv bi translated">步伐</h1><p id="e5fc" class="pw-post-body-paragraph li lj it lk b ll mw kd ln lo mx kg lq lr my lt lu lv mz lx ly lz na mb mc md im bi translated">在本文中，我将遵循以下步骤:</p><ol class=""><li id="f8d1" class="nm nn it lk b ll lm lo lp lr no lv np lz nq md nr ns nt nu bi translated">导入模块</li><li id="e5c2" class="nm nn it lk b ll nv lo nw lr nx lv ny lz nz md nr ns nt nu bi translated">创建要素和标签(编码)</li><li id="bab7" class="nm nn it lk b ll nv lo nw lr nx lv ny lz nz md nr ns nt nu bi translated">创建训练和测试(分割)</li><li id="a600" class="nm nn it lk b ll nv lo nw lr nx lv ny lz nz md nr ns nt nu bi translated">使用模型:朴素贝叶斯分类器</li><li id="5e08" class="nm nn it lk b ll nv lo nw lr nx lv ny lz nz md nr ns nt nu bi translated">性能评估</li></ol><p id="ca2a" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">像往常一样，AI并不规范。有几种方法可以达到同样的效果。在常规的NLP中，我们需要以这种方式预处理数据:</p><ul class=""><li id="dc29" class="nm nn it lk b ll lm lo lp lr no lv np lz nq md oa ns nt nu bi translated">标记化:将句子分割成单个单词</li><li id="4686" class="nm nn it lk b ll nv lo nw lr nx lv ny lz nz md oa ns nt nu bi translated">编码:将这些单词转换成数字</li><li id="db63" class="nm nn it lk b ll nv lo nw lr nx lv ny lz nz md oa ns nt nu bi translated">创建NLP模型</li></ul><p id="c57b" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">我将使用字典，因此我不会将文本编码成数字，而是编码成布尔值。</p><h1 id="cf4c" class="me mf it bd mg mh mi mj mk ml mm mn mo ki mp kj mq kl mr km ms ko mt kp mu mv bi translated">1.导入模块</h1><pre class="kt ku kv kw gt ob oc od oe aw of bi"><span id="7391" class="nb mf it oc b gy og oh l oi oj">!pip install nltk<br/>import nltk<br/>#per risolvere un bug, altrimenti da errore<br/>nltk.download('punkt')</span><span id="1533" class="nb mf it oc b gy ok oh l oi oj">#tokenizer<br/>def format_sentence(sent):<br/>  return({word: True for word in nltk.word_tokenize(sent)})</span></pre><h1 id="c0b8" class="me mf it bd mg mh mi mj mk ml mm mn mo ki mp kj mq kl mr km ms ko mt kp mu mv bi translated">2.创建要素和标签</h1><p id="b645" class="pw-post-body-paragraph li lj it lk b ll mw kd ln lo mx kg lq lr my lt lu lv mz lx ly lz na mb mc md im bi translated">在这一节中，我将分别导入包含正面和负面推文的数据集，分别对它们进行预处理。</p><p id="2cd5" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">正在讨论的数据集包含617条正面推文和1387条负面推文的样本，总共2000条推文。</p><pre class="kt ku kv kw gt ob oc od oe aw of bi"><span id="7592" class="nb mf it oc b gy og oh l oi oj">#   X + y<br/>total = open('/content/drive/My Drive/Colab Notebooks/Projects/20200602_Twitter_Sentiment_Analysis/pos_tweets.txt')<br/>Xy_pos = list()<br/>#word tokenization<br/>for sentence in total:<br/>  #print(sentence)<br/>  Xy_pos.append([format_sentence(sentence), 'pos'])<br/>  #saves the sentence in format: [{tokenized sentence}, 'pos]<br/>#Xy_pos</span><span id="d0bc" class="nb mf it oc b gy ok oh l oi oj">#   X + y<br/>total = open('/content/drive/My Drive/Colab Notebooks/Projects/20200602_Twitter_Sentiment_Analysis/neg_tweets.txt')<br/>Xy_neg = list()<br/>#word tokenization<br/>for sentence in total:<br/>  #print(sentence)<br/>  Xy_neg.append([format_sentence(sentence), 'neg'])<br/>  #saves the sentence in format: [{tokenized sentence}, 'pos]<br/>#Xy_neg</span></pre><p id="4703" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">因此，我将有一个嵌套在列表中的字典:</p><pre class="kt ku kv kw gt ob oc od oe aw of bi"><span id="295c" class="nb mf it oc b gy og oh l oi oj">[dictionary, sentiment]</span></pre><p id="8a73" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">如果我们看一下positive_tweets的第一个元素，我们可以看到我们的数据是如何被编码的:</p><pre class="kt ku kv kw gt ob oc od oe aw of bi"><span id="5eec" class="nb mf it oc b gy og oh l oi oj">Xy_pos[0]<br/>[{"''": True,<br/>  "'m": True,<br/>  ',': True,<br/>  '.': True,<br/>  ':': True,<br/>  'Ballads': True,<br/>  'Cellos': True,<br/>  'Genius': True,<br/>  'I': True,<br/>  '``': True,<br/>  'and': True,<br/>  'by': True,<br/>  'called': True,<br/>  'cheer': True,<br/>  'down': True,<br/>  'iPod': True,<br/>  'listening': True,<br/>  'love': True,<br/>  'music': True,<br/>  'my': True,<br/>  'myself': True,<br/>  'of': True,<br/>  'playlist': True,<br/>  'taste': True,<br/>  'to': True,<br/>  'up': True,<br/>  'when': True},<br/> 'pos']</span></pre><h1 id="67a3" class="me mf it bd mg mh mi mj mk ml mm mn mo ki mp kj mq kl mr km ms ko mt kp mu mv bi translated">3.创建训练和测试</h1><p id="5f2e" class="pw-post-body-paragraph li lj it lk b ll mw kd ln lo mx kg lq lr my lt lu lv mz lx ly lz na mb mc md im bi translated">我们在监督学习领域工作。不幸的是，与表格数据的分析相比，至少对于nltk工具来说，预处理的行为有点不同。</p><p id="adc2" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">如果我必须分析表格数据，我会将我的部分分成:</p><pre class="kt ku kv kw gt ob oc od oe aw of bi"><span id="f09f" class="nb mf it oc b gy og oh l oi oj">X_train, y_train, X_test, y_test</span></pre><p id="120c" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">在这种特殊情况下，我需要合并标注和要素，保留:</p><pre class="kt ku kv kw gt ob oc od oe aw of bi"><span id="a199" class="nb mf it oc b gy og oh l oi oj">Xy_train, Xy_test</span></pre><p id="b511" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">这种变化的原因是nltk模型只接受一个参数，X_train和y_train合并:在我们的例子中是Xy_train</p><h2 id="c70b" class="nb mf it bd mg nc nd dn mk ne nf dp mo lr ng nh mq lv ni nj ms lz nk nl mu iz bi translated">剧烈的</h2><p id="01f2" class="pw-post-body-paragraph li lj it lk b ll mw kd ln lo mx kg lq lr my lt lu lv mz lx ly lz na mb mc md im bi translated">为了创建我的训练和测试部分，我必须合并pos和neg，因为它们包含训练和测试部分。然后，我将拆分合并的数据集。</p><pre class="kt ku kv kw gt ob oc od oe aw of bi"><span id="1031" class="nb mf it oc b gy og oh l oi oj">def split(pos, neg, ratio):<br/>  train = pos[:int((1-ratio)*len(pos))] + neg[:int((1-ratio)*len(neg))]<br/>  test = pos[int((ratio)*len(pos)):] + neg[int((ratio)*len(neg)):]<br/>  return train, test</span><span id="024c" class="nb mf it oc b gy ok oh l oi oj">Xy_train, Xy_test = split(Xy_pos, Xy_neg, 0.1)</span></pre><h1 id="18b2" class="me mf it bd mg mh mi mj mk ml mm mn mo ki mp kj mq kl mr km ms ko mt kp mu mv bi translated">4.使用模型:朴素贝叶斯分类器</h1><p id="c2d5" class="pw-post-body-paragraph li lj it lk b ll mw kd ln lo mx kg lq lr my lt lu lv mz lx ly lz na mb mc md im bi translated">现在是时候创建机器学习模型了。</p><pre class="kt ku kv kw gt ob oc od oe aw of bi"><span id="1e6b" class="nb mf it oc b gy og oh l oi oj">from nltk.classify import NaiveBayesClassifier</span><span id="aafe" class="nb mf it oc b gy ok oh l oi oj">#encoded thrugh dictionaries<br/>classifier = NaiveBayesClassifier.train(Xy_train)<br/>classifier.show_most_informative_features()<br/>Most Informative Features                       no = True              neg : pos    =     20.6 : 1.0                  awesome = True              pos : neg    =     18.7 : 1.0                 headache = True              neg : pos    =     18.0 : 1.0                beautiful = True              pos : neg    =     14.2 : 1.0                     love = True              pos : neg    =     14.2 : 1.0                       Hi = True              pos : neg    =     12.7 : 1.0                      fan = True              pos : neg    =      9.7 : 1.0                    Thank = True              pos : neg    =      9.7 : 1.0                     glad = True              pos : neg    =      9.7 : 1.0                     lost = True              neg : pos    =      9.3 : 1.0</span></pre><p id="057a" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">该模型将一个值与数据集中的每个单词相关联。它将对每条推文中包含的所有单词进行计算，然后做出评估:正面或负面。</p><h1 id="cb67" class="me mf it bd mg mh mi mj mk ml mm mn mo ki mp kj mq kl mr km ms ko mt kp mu mv bi translated">5.性能评估</h1><p id="699e" class="pw-post-body-paragraph li lj it lk b ll mw kd ln lo mx kg lq lr my lt lu lv mz lx ly lz na mb mc md im bi translated">正如我们所看到的，我们在所有推文中获得了96%的准确率(通过过度近似)!惊人的结果。</p><pre class="kt ku kv kw gt ob oc od oe aw of bi"><span id="6f25" class="nb mf it oc b gy og oh l oi oj">from nltk.classify.util import accuracy<br/>print(accuracy(classifier, Xy_test))<br/>0.9562326869806094</span></pre></div></div>    
</body>
</html>