<html>
<head>
<title>Text Classification with Simple Transformers</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">使用简单转换器的文本分类</h1>
<blockquote>原文：<a href="https://pub.towardsai.net/text-classification-with-simple-transformers-a29d13358135?source=collection_archive---------0-----------------------#2020-08-10">https://pub.towardsai.net/text-classification-with-simple-transformers-a29d13358135?source=collection_archive---------0-----------------------#2020-08-10</a></blockquote><div><div class="fc ii ij ik il im"/><div class="in io ip iq ir"><h2 id="84b9" class="is it iu bd b dl iv iw ix iy iz ja dk jb translated" aria-label="kicker paragraph"><a class="ae ep" href="https://towardsai.net/p/category/nlp" rel="noopener ugc nofollow" target="_blank">自然语言处理</a></h2><div class=""/><div class=""><h2 id="b61c" class="pw-subtitle-paragraph ka jd iu bd b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr dk translated">用简单的转换器解决二值文本分类问题</h2></div><figure class="kt ku kv kw gu kx gi gj paragraph-image"><div role="button" tabindex="0" class="ky kz di la bf lb"><div class="gi gj ks"><img src="../Images/f30b93f927ff3951e577a0d8561c9e97.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*B7OSS5lNz9EqROpx"/></div></div><figcaption class="le lf gk gi gj lg lh bd b be z dk translated"><a class="ae li" href="https://unsplash.com/@tetrakiss" rel="noopener ugc nofollow" target="_blank">阿瑟尼·托古列夫</a>在<a class="ae li" href="https://unsplash.com/photos/uPuh-VwJRM0" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上拍摄的照片</figcaption></figure><p id="ba54" class="pw-post-body-paragraph lj lk iu ll b lm ln ke lo lp lq kh lr ls lt lu lv lw lx ly lz ma mb mc md me in bi translated"><strong class="ll je">使用变压器模型从未如此简单过<em class="mf">！是的，这是作者Thilina Rajapakse说的，我同意他的观点，你也应该同意。您可能已经见过包含数百行代码的冗长代码来实现BERT、RoBERTa等变压器模型。一旦你理解了如何使用<code class="fe mg mh mi mj b">Simple Transformers</code>，你就会知道使用transformer模型是多么容易和简单。</em></strong></p><p id="7881" class="pw-post-body-paragraph lj lk iu ll b lm ln ke lo lp lq kh lr ls lt lu lv lw lx ly lz ma mb mc md me in bi translated"><code class="fe mg mh mi mj b">Simple Transformers</code>图书馆建立在拥抱脸<code class="fe mg mh mi mj b">Transformers</code>图书馆之上。<code class="fe mg mh mi mj b">transformers</code>库提供了许多预先训练好的模型，如BERT、RoBERTa、XLNET等。这可用于解决许多NLP任务。</p><p id="1185" class="pw-post-body-paragraph lj lk iu ll b lm ln ke lo lp lq kh lr ls lt lu lv lw lx ly lz ma mb mc md me in bi translated">简单的转换器可以用于文本分类、命名实体识别、问题回答、语言建模等。在本文中，我们将使用来自Kaggle的灾难推特数据集在<a class="ae li" href="https://www.kaggle.com/c/nlp-getting-started/overview" rel="noopener ugc nofollow" target="_blank"> NLP上用简单的转换器解决二进制分类问题。让我们开始吧。</a></p></div><div class="ab cl mk ml hy mm" role="separator"><span class="mn bw bk mo mp mq"/><span class="mn bw bk mo mp mq"/><span class="mn bw bk mo mp"/></div><div class="in io ip iq ir"><h1 id="ec0e" class="mr ms iu bd mt mu mv mw mx my mz na nb kj nc kk nd km ne kn nf kp ng kq nh ni bi translated"><strong class="ak">导入库&amp;数据集</strong></h1><p id="9dbd" class="pw-post-body-paragraph lj lk iu ll b lm nj ke lo lp nk kh lr ls nl lu lv lw nm ly lz ma nn mc md me in bi translated">将数据集从Kaggle下载到Colab。从您的Kaggle个人资料导航至<code class="fe mg mh mi mj b"><strong class="ll je">My Account &gt; API</strong></code>，然后点击<code class="fe mg mh mi mj b"><strong class="ll je">Create New API Token.</strong></code> <strong class="ll je"> </strong>这将下载<code class="fe mg mh mi mj b"><strong class="ll je">kaggle.json</strong></code>文件。一旦你有了这个文件，运行下面的代码。在执行过程中，它会提示您上传一个JSON文件，以便您可以上传<code class="fe mg mh mi mj b"><strong class="ll je">kaggle.json</strong></code>文件。</p><pre class="kt ku kv kw gu no mj np nq aw nr bi"><span id="2abb" class="ns ms iu mj b gz nt nu l nv nw">from google.colab import files<br/>files.upload()<br/>!pip install -q kaggle<br/>!mkdir ~/.kaggle<br/>!cp kaggle.json ~/.kaggle/<br/>!chmod 600 ~/.kaggle/kaggle.json<br/>!kaggle competitions download -c nlp-getting-started</span></pre><p id="b29a" class="pw-post-body-paragraph lj lk iu ll b lm ln ke lo lp lq kh lr ls lt lu lv lw lx ly lz ma mb mc md me in bi translated">谷歌Colab预装了变形金刚。在这里，我们正在升级变形金刚库，这样我们将拥有它的最新版本，然后安装简单的变形金刚:</p><pre class="kt ku kv kw gu no mj np nq aw nr bi"><span id="e99f" class="ns ms iu mj b gz nt nu l nv nw">!pip install --upgrade transformers<br/>!pip install simpletransformers</span></pre><p id="fc3b" class="pw-post-body-paragraph lj lk iu ll b lm ln ke lo lp lq kh lr ls lt lu lv lw lx ly lz ma mb mc md me in bi translated">现在，导入所有必需的库:</p><pre class="kt ku kv kw gu no mj np nq aw nr bi"><span id="b7df" class="ns ms iu mj b gz nt nu l nv nw">import numpy as np<br/>import pandas as pd<br/>from sklearn.metrics import f1_score<br/>from sklearn.model_selection import train_test_split<br/>from simpletransformers.classification import ClassificationModel, ClassificationArgs</span></pre><h1 id="3497" class="mr ms iu bd mt mu nx mw mx my ny na nb kj nz kk nd km oa kn nf kp ob kq nh ni bi translated">预处理</h1><p id="14ef" class="pw-post-body-paragraph lj lk iu ll b lm nj ke lo lp nk kh lr ls nl lu lv lw nm ly lz ma nn mc md me in bi translated">我们现在将把训练和测试数据集加载到pandas数据框架中，即训练和测试。训练集中有7613条记录，测试集中有3263条记录。</p><pre class="kt ku kv kw gu no mj np nq aw nr bi"><span id="35cc" class="ns ms iu mj b gz nt nu l nv nw">train = pd.read_csv(‘/content/train.csv’)<br/>test = pd.read_csv(‘/content/test.csv’)</span><span id="8c5f" class="ns ms iu mj b gz oc nu l nv nw">print(‘Shape of train set {}’.format(train.shape))<br/>print(‘Shape of test set {}’.format(test.shape))<br/>&gt;&gt;&gt; Shape of train set (7613, 5) <br/>&gt;&gt;&gt; Shape of test set (3263, 4)</span></pre><figure class="kt ku kv kw gu kx gi gj paragraph-image"><div role="button" tabindex="0" class="ky kz di la bf lb"><div class="gi gj od"><img src="../Images/bc8226e912c8ab8dd87196c4fc0c107e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*6Em97IgyOrt4shbHj3idxw.png"/></div></div></figure><p id="0f2e" class="pw-post-body-paragraph lj lk iu ll b lm ln ke lo lp lq kh lr ls lt lu lv lw lx ly lz ma mb mc md me in bi translated">由于我们不需要<code class="fe mg mh mi mj b">‘id’</code>、<code class="fe mg mh mi mj b">‘keyword’</code>、&amp;、<code class="fe mg mh mi mj b">‘location’</code>列，我们将从两个列车&amp;测试数据中移除这些列。</p><pre class="kt ku kv kw gu no mj np nq aw nr bi"><span id="7f96" class="ns ms iu mj b gz nt nu l nv nw">train.drop([‘id’, ‘keyword’, ‘location’], axis=1, inplace=True)<br/>test.drop([‘id’, ‘keyword’, ‘location’], axis=1, inplace=True)</span></pre><p id="e964" class="pw-post-body-paragraph lj lk iu ll b lm ln ke lo lp lq kh lr ls lt lu lv lw lx ly lz ma mb mc md me in bi translated">两个数据集中没有空值。所以我们不必担心处理丢失的值。</p><pre class="kt ku kv kw gu no mj np nq aw nr bi"><span id="4812" class="ns ms iu mj b gz nt nu l nv nw">train.isnull().sum().sum()<br/>&gt;&gt; 0</span><span id="0948" class="ns ms iu mj b gz oc nu l nv nw">test.isnull().sum().sum()<br/>&gt;&gt; 0</span></pre><p id="5167" class="pw-post-body-paragraph lj lk iu ll b lm ln ke lo lp lq kh lr ls lt lu lv lw lx ly lz ma mb mc md me in bi translated">我们来看看目标分布。</p><figure class="kt ku kv kw gu kx gi gj paragraph-image"><div role="button" tabindex="0" class="ky kz di la bf lb"><div class="gi gj oe"><img src="../Images/2ae8c3484ccf60bf5752de36308387cd.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*x6jRACV0vMSa8KbnuYRhVg.png"/></div></div><figcaption class="le lf gk gi gj lg lh bd b be z dk translated">作者图片</figcaption></figure><p id="7f52" class="pw-post-body-paragraph lj lk iu ll b lm ln ke lo lp lq kh lr ls lt lu lv lw lx ly lz ma mb mc md me in bi translated">我们将使用训练测试分割，并使用80%的数据来构建分类模型。</p><pre class="kt ku kv kw gu no mj np nq aw nr bi"><span id="0fde" class="ns ms iu mj b gz nt nu l nv nw">train.columns = ['text', 'labels']</span><span id="5c15" class="ns ms iu mj b gz oc nu l nv nw">train_df, valid_df = train_test_split(train, test_size=0.2, stratify=train[‘labels’], random_state=42)</span></pre><h1 id="d058" class="mr ms iu bd mt mu nx mw mx my ny na nb kj nz kk nd km oa kn nf kp ob kq nh ni bi translated"><strong class="ak">初始化一个</strong>T3】</h1><p id="a767" class="pw-post-body-paragraph lj lk iu ll b lm nj ke lo lp nk kh lr ls nl lu lv lw nm ly lz ma nn mc md me in bi translated">由于我们试图解决二进制文本分类，我们将不得不按照<a class="ae li" href="https://simpletransformers.ai/docs/classification-specifics/#sub-tasks-falling-under-text-classification" rel="noopener ugc nofollow" target="_blank">这个</a>表使用<code class="fe mg mh mi mj b">ClassificationModel</code>。</p><p id="746f" class="pw-post-body-paragraph lj lk iu ll b lm ln ke lo lp lq kh lr ls lt lu lv lw lx ly lz ma mb mc md me in bi translated">对于<code class="fe mg mh mi mj b">ClassificationModel</code>，我们需要通过<code class="fe mg mh mi mj b">model_type</code>和<code class="fe mg mh mi mj b">model_name</code>。我们将使用<code class="fe mg mh mi mj b">roberta</code>和<code class="fe mg mh mi mj b">roberta_base</code>。但是，您可以从列表中自由选择任何型号并进行试验。</p><p id="b378" class="pw-post-body-paragraph lj lk iu ll b lm ln ke lo lp lq kh lr ls lt lu lv lw lx ly lz ma mb mc md me in bi translated">变压器等深度学习模型运行在支持CUDA的GPU上。默认情况下，CUDA是启用的。在使用简单的变压器之前，请确保您的系统中的GPU是打开的。既然我们处理的是二进制分类<code class="fe mg mh mi mj b">num_labels</code>应该设为2。</p><p id="54c2" class="pw-post-body-paragraph lj lk iu ll b lm ln ke lo lp lq kh lr ls lt lu lv lw lx ly lz ma mb mc md me in bi translated">我们可以为分类模型配置几个参数，可以在<a class="ae li" href="https://simpletransformers.ai/docs/usage/#configuring-a-simple-transformers-model" rel="noopener ugc nofollow" target="_blank">这里</a>找到。这里我们只使用三个参数:<code class="fe mg mh mi mj b">num_train_epochs</code>、<code class="fe mg mh mi mj b">overwrite_output_dir</code>、&amp;、<code class="fe mg mh mi mj b">manual_seed</code>。其他一些重要且最常用的参数有— <code class="fe mg mh mi mj b">learning_rate</code>、<code class="fe mg mh mi mj b">train_batch_size</code>等。</p><pre class="kt ku kv kw gu no mj np nq aw nr bi"><span id="2ae5" class="ns ms iu mj b gz nt nu l nv nw">model_args = ClassificationArgs(num_train_epochs=1, overwrite_output_dir=True, manual_seed=42)</span><span id="fb60" class="ns ms iu mj b gz oc nu l nv nw">model = ClassificationModel(model_type='roberta', model_name='roberta-base', use_cuda=True, num_labels=2, args=model_args)</span></pre><h1 id="038f" class="mr ms iu bd mt mu nx mw mx my ny na nb kj nz kk nd km oa kn nf kp ob kq nh ni bi translated"><strong class="ak">训练模型</strong></h1><p id="79b7" class="pw-post-body-paragraph lj lk iu ll b lm nj ke lo lp nk kh lr ls nl lu lv lw nm ly lz ma nn mc md me in bi translated"><code class="fe mg mh mi mj b">train_model()</code>方法使用<code class="fe mg mh mi mj b">train_df</code>数据帧训练模型。这将运行一个时期，因为我们已经将<code class="fe mg mh mi mj b">num_train_epoch</code>设置为1。</p><pre class="kt ku kv kw gu no mj np nq aw nr bi"><span id="dfb1" class="ns ms iu mj b gz nt nu l nv nw">model.train_model(train_df)</span></pre><h1 id="552a" class="mr ms iu bd mt mu nx mw mx my ny na nb kj nz kk nd km oa kn nf kp ob kq nh ni bi translated"><strong class="ak">评估模型</strong></h1><p id="b619" class="pw-post-body-paragraph lj lk iu ll b lm nj ke lo lp nk kh lr ls nl lu lv lw nm ly lz ma nn mc md me in bi translated"><code class="fe mg mh mi mj b">eval_model()</code>方法将使用<code class="fe mg mh mi mj b">valid_df</code>数据帧评估模型，并返回3个输出。</p><pre class="kt ku kv kw gu no mj np nq aw nr bi"><span id="2e84" class="ns ms iu mj b gz nt nu l nv nw">result, model_outputs, wrong_preds = model.eval_model(valid_df)</span></pre><p id="7aa1" class="pw-post-body-paragraph lj lk iu ll b lm ln ke lo lp lq kh lr ls lt lu lv lw lx ly lz ma mb mc md me in bi translated">由于本次比赛的评价指标是<code class="fe mg mh mi mj b">f1_score</code>，所以让我们用sklearn计算一下<code class="fe mg mh mi mj b">f1_score</code>。</p><pre class="kt ku kv kw gu no mj np nq aw nr bi"><span id="6679" class="ns ms iu mj b gz nt nu l nv nw">predictions = []<br/>for x in model_outputs:<br/>    predictions.append(np.argmax(x))<br/>print(‘f1 score:’, f1_score(valid_df[‘labels’], predictions))</span><span id="c190" class="ns ms iu mj b gz oc nu l nv nw">&gt;&gt;&gt; f1 score: 0.8134044173648134</span></pre><h1 id="ffaf" class="mr ms iu bd mt mu nx mw mx my ny na nb kj nz kk nd km oa kn nf kp ob kq nh ni bi translated">对测试集的预测</h1><p id="0b99" class="pw-post-body-paragraph lj lk iu ll b lm nj ke lo lp nk kh lr ls nl lu lv lw nm ly lz ma nn mc md me in bi translated"><code class="fe mg mh mi mj b">predict()</code>方法将用于对未知数据进行预测。在对测试做出预测并提交给Kaggle后，在排行榜上给出了<code class="fe mg mh mi mj b">0.81949</code>的<code class="fe mg mh mi mj b">f1_score</code>。</p><pre class="kt ku kv kw gu no mj np nq aw nr bi"><span id="deef" class="ns ms iu mj b gz nt nu l nv nw">test_predictions, raw_outputs = model.predict(test[‘text’])<br/>sample_sub[‘target’] = test_predictions<br/>sample_sub.to_csv(‘submission.csv’,index=False)<br/>files.download(‘submission.csv’)</span></pre><p id="fb39" class="pw-post-body-paragraph lj lk iu ll b lm ln ke lo lp lq kh lr ls lt lu lv lw lx ly lz ma mb mc md me in bi translated">考虑到我们仅在80%的训练数据上试验了一个变压器模型，并且我们还没有探索超参数优化、早期停止和k倍交叉验证，这是一个非常好的分数。如果我们能尝试所有这些，我们可以进一步提高分数。</p><p id="6bb3" class="pw-post-body-paragraph lj lk iu ll b lm ln ke lo lp lq kh lr ls lt lu lv lw lx ly lz ma mb mc md me in bi translated">完整的代码可以在Colab上的<a class="ae li" href="https://colab.research.google.com/drive/1-24bwB3in7zVHxmENOhI6RWa-MqmrQt8?usp=sharing" rel="noopener ugc nofollow" target="_blank">这里</a>找到。您也可以查看下面的相同代码:</p><figure class="kt ku kv kw gu kx"><div class="bz fq l di"><div class="of og l"/></div></figure><p id="453c" class="pw-post-body-paragraph lj lk iu ll b lm ln ke lo lp lq kh lr ls lt lu lv lw lx ly lz ma mb mc md me in bi translated">这里还有一篇你可能会感兴趣的文章:</p><div class="oh oi gq gs oj ok"><a href="https://medium.com/towards-artificial-intelligence/summarization-with-simple-transformers-14d158686faa" rel="noopener follow" target="_blank"><div class="ol ab fp"><div class="om ab on cl cj oo"><h2 class="bd je gz z fq op fs ft oq fv fx jd bi translated">简单变压器总结</h2><div class="or l"><h3 class="bd b gz z fq op fs ft oq fv fx dk translated">使用simpletransformers生成摘要的实践指南</h3></div><div class="os l"><p class="bd b dl z fq op fs ft oq fv fx dk translated">medium.com</p></div></div><div class="ot l"><div class="ou l ov ow ox ot oy lc ok"/></div></div></a></div><h1 id="8f53" class="mr ms iu bd mt mu nx mw mx my ny na nb kj nz kk nd km oa kn nf kp ob kq nh ni bi translated">结论</h1><p id="b518" class="pw-post-body-paragraph lj lk iu ll b lm nj ke lo lp nk kh lr ls nl lu lv lw nm ly lz ma nn mc md me in bi translated">希望你喜欢阅读本教程，并理解如何使用简单的变压器分类任务。</p></div><div class="ab cl mk ml hy mm" role="separator"><span class="mn bw bk mo mp mq"/><span class="mn bw bk mo mp mq"/><span class="mn bw bk mo mp"/></div><div class="in io ip iq ir"><h1 id="793a" class="mr ms iu bd mt mu mv mw mx my mz na nb kj nc kk nd km ne kn nf kp ng kq nh ni bi translated"><strong class="ak">参考文献</strong></h1><div class="oh oi gq gs oj ok"><a href="https://simpletransformers.ai/" rel="noopener  ugc nofollow" target="_blank"><div class="ol ab fp"><div class="om ab on cl cj oo"><h2 class="bd je gz z fq op fs ft oq fv fx jd bi translated">简单变压器</h2><div class="or l"><h3 class="bd b gz z fq op fs ft oq fv fx dk translated">使用变压器模型从未如此简单！内置支持:文本分类令牌分类…</h3></div><div class="os l"><p class="bd b dl z fq op fs ft oq fv fx dk translated">simpletransformers.ai</p></div></div><div class="ot l"><div class="oz l ov ow ox ot oy lc ok"/></div></div></a></div></div><div class="ab cl mk ml hy mm" role="separator"><span class="mn bw bk mo mp mq"/><span class="mn bw bk mo mp mq"/><span class="mn bw bk mo mp"/></div><div class="in io ip iq ir"><p id="29c2" class="pw-post-body-paragraph lj lk iu ll b lm ln ke lo lp lq kh lr ls lt lu lv lw lx ly lz ma mb mc md me in bi translated"><em class="mf">阅读更多关于Python和数据科学的此类有趣文章，</em> <a class="ae li" href="https://pythonsimplified.com/home/" rel="noopener ugc nofollow" target="_blank"> <strong class="ll je"> <em class="mf">订阅</em> </strong> </a> <em class="mf">到我的博客</em><a class="ae li" href="http://www.pythonsimplified.com/" rel="noopener ugc nofollow" target="_blank"><strong class="ll je">【www.pythonsimplified.com】</strong></a><strong class="ll je"><em class="mf">。</em> </strong>你也可以在<a class="ae li" href="https://www.linkedin.com/in/chetanambi/" rel="noopener ugc nofollow" target="_blank"><strong class="ll je">LinkedIn</strong></a><strong class="ll je">上联系我。</strong></p></div></div>    
</body>
</html>