<html>
<head>
<title>Centroid Neural Network and Vector Quantization for Image Compression</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">质心神经网络和矢量量化用于图像压缩</h1>
<blockquote>原文：<a href="https://pub.towardsai.net/centroid-neural-network-and-vector-quantization-for-image-compression-a7d30aa63167?source=collection_archive---------4-----------------------#2021-08-19">https://pub.towardsai.net/centroid-neural-network-and-vector-quantization-for-image-compression-a7d30aa63167?source=collection_archive---------4-----------------------#2021-08-19</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><h2 id="d7cc" class="io ip iq bd b dl ir is it iu iv iw dk ix translated" aria-label="kicker paragraph"><a class="ae ep" href="https://towardsai.net/p/category/machine-learning/deep-learning" rel="noopener ugc nofollow" target="_blank">深度学习</a></h2><div class=""/><div class=""><h2 id="76da" class="pw-subtitle-paragraph jw iz iq bd b jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn dk translated">让我们提升那些没有被重视的潜力</h2></div><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div role="button" tabindex="0" class="ku kv di kw bf kx"><div class="gh gi ko"><img src="../Images/85d4dc3298c848ba62af037084100506.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*eqTTdGlXeumg6x0O"/></div></div><figcaption class="la lb gj gh gi lc ld bd b be z dk translated">照片由<a class="ae le" href="https://unsplash.com/@verneho?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">凡尔纳何</a>在<a class="ae le" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上拍摄</figcaption></figure><p id="124e" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">质心神经网络已被证明是一种高效稳定的聚类算法，并已成功应用于各种问题。与K-Means和自组织映射(SOM)相比，CentNN在大多数情况下产生更准确的聚类结果。CentNN的主要限制是它需要更多的时间来收敛，因为CentNN从2个聚类开始，并逐渐增长，直到达到所需的聚类数。回到人工神经网络(ANNs)理论在1943年被引入的那一天，但它只是在60年代早期<strong class="lh ja">反向传播</strong>被导出并在1970年左右被实现在计算机上运行时才变得流行，或者辛顿的胶囊网络(CapsNet)的想法已经被琢磨了将近<strong class="lh ja"> 40年</strong>，直到2017年<strong class="lh ja">动态路由</strong>被发布。从我的角度来看，CentNN面临着同样的问题，当它只需要一个更快的方式来更好地运作时，因为其理论的鲁棒性已经形成。你可以在这里找到我对CentNN <a class="ae le" rel="noopener ugc nofollow" target="_blank" href="/centroid-neural-network-an-efficient-and-stable-clustering-algorithm-b2fa8cbb2a27">的解释，在这里</a>找到我实现这个算法的教程<a class="ae le" rel="noopener ugc nofollow" target="_blank" href="/centroid-neural-network-for-clustering-with-numpy-fb5812149fed">。</a></p><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div class="gh gi mb"><img src="../Images/05629483dd83161ca60e365c10432d3e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1152/1*L-VCpM3FfJ7hqlbEfwFJ9g.gif"/></div><figcaption class="la lb gj gh gi lc ld bd b be z dk translated">使用质心神经网络进行聚类(GIF由作者提供)</figcaption></figure><p id="e6b1" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">在这篇文章中，我将实现CentNN算法来解决图像压缩问题，并展示它与K-Means相比有多好。</p><h1 id="18de" class="mc md iq bd me mf mg mh mi mj mk ml mm kf mn kg mo ki mp kj mq kl mr km ms mt bi translated">图像压缩</h1><p id="2c43" class="pw-post-body-paragraph lf lg iq lh b li mu ka lk ll mv kd ln lo mw lq lr ls mx lu lv lw my ly lz ma ij bi translated">图像压缩是数据压缩的一种类型，其中数据的类型是数字图像，目的是最小化传输和存储的成本。为此，聚类和矢量量化是广泛使用的两种方法。</p><p id="650b" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">矢量量化是一种用于数据压缩的有损压缩技术。它指的是将一大组数据点划分成预定数量的聚类，其中每个聚类的质心与其聚类的数据点相比具有最近的距离。在这个意义上，聚类方法被部署来执行量化。你可以在Mahnoor Javed的文章<a class="ae le" href="https://medium.com/analytics-vidhya/vector-quantization-using-k-means-algorithm-6382f3888326#:~:text=Vector%20Quantization%20is%20a%20lossy%20data%20compression%20technique.&amp;text=Vector%20Quantization%20works%20by%20dividing,and%20some%20other%20clustering%20algorithms." rel="noopener">这里</a>中找到使用K-Means算法进行图像压缩的矢量量化的更直接的解释。</p><p id="58e7" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">至此，我想你已经理解了CentNN和K-Means算法，以及使用聚类和矢量量化的图像压缩。同样，你可以在这里找到我对CentNN <a class="ae le" rel="noopener ugc nofollow" target="_blank" href="/centroid-neural-network-an-efficient-and-stable-clustering-algorithm-b2fa8cbb2a27">的解释，在这里</a>找到我实现这个算法的教程<a class="ae le" rel="noopener ugc nofollow" target="_blank" href="/centroid-neural-network-for-clustering-with-numpy-fb5812149fed">。现在，让我们来看看今天的主要新闻。</a></p><h1 id="7d5e" class="mc md iq bd me mf mg mh mi mj mk ml mm kf mn kg mo ki mp kj mq kl mr km ms mt bi translated">图像压缩的质心神经网络</h1><p id="f412" class="pw-post-body-paragraph lf lg iq lh b li mu ka lk ll mv kd ln lo mw lq lr ls mx lu lv lw my ly lz ma ij bi translated">在这篇文章中，我想以经典的Lena图像为样本，使用CentNN进行图像压缩的实验，并使用K-Means进行比较。我想比较一下CentNN和K-Means的两种量化方式:<em class="mz">标量量化</em>和<em class="mz">块(矢量)量化</em>。现在让我们加载我们的图像样本，并做几个预处理步骤:</p><pre class="kp kq kr ks gt na nb nc nd aw ne bi"><span id="94ee" class="nf md iq nb b gy ng nh l ni nj">image = cv2.imread(“images/lena.jpg”, 0)<br/>image = cv2.resize(image, (128,128))<br/>plt.imshow(image, cmap = “gray”)<br/>plt.show()</span></pre><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div class="gh gi nk"><img src="../Images/42c528d126cf40754988a9fc5d884d38.png" data-original-src="https://miro.medium.com/v2/resize:fit:962/format:webp/1*cfxKwtnNhN3LZjoXo2LzvA.png"/></div><figcaption class="la lb gj gh gi lc ld bd b be z dk translated">莉娜图像(128x128)</figcaption></figure><h2 id="a2e5" class="nf md iq bd me nl nm dn mi nn no dp mm lo np nq mo ls nr ns mq lw nt nu ms iw bi translated">1.CentNN +标量量化</h2><p id="784f" class="pw-post-body-paragraph lf lg iq lh b li mu ka lk ll mv kd ln lo mw lq lr ls mx lu lv lw my ly lz ma ij bi translated">在这个实验中，簇的数量被设置为48。首先，从<em class="mz"> sklearn </em>调用K-Means函数，并实现一个用于量化的子程序:</p><figure class="kp kq kr ks gt kt"><div class="bz fp l di"><div class="nv nw l"/></div></figure><p id="02db" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">这个结果留待以后比较。</p><p id="4184" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">现在让我们实现CentNN算法来量化我们的样本图像，下面是我的完整实现和解释注释，你可以在我的GitHub repo <a class="ae le" href="https://github.com/tranleanh/centroid-neural-networks" rel="noopener ugc nofollow" target="_blank">这里</a>找到一个带有调用函数的易用版本。如果对这一堆代码行不感兴趣，就直接忽略它，直接跳过去看结果，没有硬邦邦的感觉。</p><figure class="kp kq kr ks gt kt"><div class="bz fp l di"><div class="nv nw l"/></div></figure><p id="3408" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">现在我们可以解码量化数据，计算PSNR值并显示结果:</p><figure class="kp kq kr ks gt kt"><div class="bz fp l di"><div class="nv nw l"/></div></figure><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div role="button" tabindex="0" class="ku kv di kw bf kx"><div class="gh gi nx"><img src="../Images/5411d562da5e4bccf7dc8228782cf434.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*a7Ub8IIuurL9lyq-2xBNtQ.png"/></div></div><figcaption class="la lb gj gh gi lc ld bd b be z dk translated">使用K-Means(中间)和CentNN(右侧)标量量化的重建图像。(图片由作者提供)</figcaption></figure><p id="3d08" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">具有所述设置的这个实验表明，CentNN算法(PSNR 47.53)的重建图像具有比K均值(PSNR 46.35)更好的质量。</p><h2 id="5a2f" class="nf md iq bd me nl nm dn mi nn no dp mm lo np nq mo ls nr ns mq lw nt nu ms iw bi translated">2.CentNN +块量化</h2><p id="4594" class="pw-post-body-paragraph lf lg iq lh b li mu ka lk ll mv kd ln lo mw lq lr ls mx lu lv lw my ly lz ma ij bi translated">在第二个实验中，块(矢量)量化、聚类数和块大小分别设置为512和4x4。与之前的实验类似，首先，从<em class="mz"> sklearn </em>库中调用K-Means函数，并实现一个用于块量化的子程序:</p><figure class="kp kq kr ks gt kt"><div class="bz fp l di"><div class="nv nw l"/></div></figure><p id="34c3" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">同样，K-Means的结果很快用于与CentNN进行比较。</p><p id="279f" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">现在做块量化的CentNN算法的代码。还有，如果你对编码不感兴趣，可以忽略下面的部分，跳转看结果。</p><figure class="kp kq kr ks gt kt"><div class="bz fp l di"><div class="nv nw l"/></div></figure><p id="1f92" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">解码并显示结果:</p><figure class="kp kq kr ks gt kt"><div class="bz fp l di"><div class="nv nw l"/></div></figure><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div class="ab gu cl ny"><img src="../Images/101f7e43bfe0f9ba8dd45a884d8e5f2e.png" data-original-src="https://miro.medium.com/v2/format:webp/1*bcf9_Po12Hqbn6FZsFf_ag.png"/></div><figcaption class="la lb gj gh gi lc ld bd b be z dk translated">使用K-Means(中)和CentNN(右)的块量化重建图像。(图片由作者提供)</figcaption></figure><p id="b355" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">正如我们在这个结果中看到的，CentNN以显著的差距优于K-Means，PSNR分别为36.78和32.57。</p><h1 id="f401" class="mc md iq bd me mf mg mh mi mj mk ml mm kf mn kg mo ki mp kj mq kl mr km ms mt bi translated">结论</h1><p id="b2b2" class="pw-post-body-paragraph lf lg iq lh b li mu ka lk ll mv kd ln lo mw lq lr ls mx lu lv lw my ly lz ma ij bi translated">在这篇文章中，我向大家介绍了用于图像压缩的质心神经网络(CentNN)的实现，以及CentNN和K-Means在图像压缩任务中的比较。通过对标量量化和块(矢量)量化的两个实验，得出了CentNN在给定任务中优于K-Means的结论。对我来说，CentNN是一个很酷的算法，但不知何故，它并没有得到太多的关注。通过分享我的写作，我希望把这些奇妙的东西带给所有爱上机器学习的人。</p><p id="6802" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">欢迎你访问我的脸书粉丝页，这是一个分享关于机器学习的东西的页面:<a class="ae le" href="https://www.facebook.com/diveintomachinelearning" rel="noopener ugc nofollow" target="_blank">投入机器学习</a>。</p><p id="bb4f" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">今天够了。感谢您抽出时间！</p><h2 id="5829" class="nf md iq bd me nl nm dn mi nn no dp mm lo np nq mo ls nr ns mq lw nt nu ms iw bi translated">参考</h2><p id="12ef" class="pw-post-body-paragraph lf lg iq lh b li mu ka lk ll mv kd ln lo mw lq lr ls mx lu lv lw my ly lz ma ij bi translated">[1] <a class="ae le" rel="noopener ugc nofollow" target="_blank" href="/centroid-neural-network-an-efficient-and-stable-clustering-algorithm-b2fa8cbb2a27">质心神经网络:一种高效稳定的聚类算法</a></p><p id="7c5e" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">[2] <a class="ae le" rel="noopener ugc nofollow" target="_blank" href="/centroid-neural-network-for-clustering-with-numpy-fb5812149fed">用Numpy进行聚类的质心神经网络</a></p></div></div>    
</body>
</html>