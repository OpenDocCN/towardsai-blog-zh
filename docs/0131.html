<html>
<head>
<title>Balancing Act in Datasets of a Machine Learning Algorithm</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">机器学习算法的数据集中的平衡行为</h1>
<blockquote>原文：<a href="https://pub.towardsai.net/balancing-act-eb75dd05ffa3?source=collection_archive---------0-----------------------#2019-08-07">https://pub.towardsai.net/balancing-act-eb75dd05ffa3?source=collection_archive---------0-----------------------#2019-08-07</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><h2 id="1928" class="ir is it bd b dl iu iv iw ix iy iz dk ja translated" aria-label="kicker paragraph">处理ML | <a class="ae ep" href="https://towardsai.net/" rel="noopener ugc nofollow" target="_blank">中的不平衡数据集到AI </a></h2><div class=""/><div class=""><h2 id="deec" class="pw-subtitle-paragraph jz jc it bd b ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq dk translated">Python中减轻不平衡数据集训练分类器影响的技术</h2></div><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi kr"><img src="../Images/f9f29c8f0fa96365e791662407223d16.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*DJoo_O-eNQAnYrc4blWzAg.jpeg"/></div></div></figure><h1 id="ba32" class="ld le it bd lf lg lh li lj lk ll lm ln ki lo kj lp kl lq km lr ko ls kp lt lu bi translated">用不平衡数据训练分类器会怎么样？</h1><p id="b20a" class="pw-post-body-paragraph lv lw it lx b ly lz kd ma mb mc kg md me mf mg mh mi mj mk ml mm mn mo mp mq im bi translated">当处理不平衡的类时，我们可能需要做一些额外的工作和计划，以确保我们的算法给我们有用的结果。</p><p id="8614" class="pw-post-body-paragraph lv lw it lx b ly mr kd ma mb ms kg md me mt mg mh mi mu mk ml mm mv mo mp mq im bi translated">在这篇博客中，我只研究了两种分类技术来说明这个问题，但是你应该知道这个问题是普遍性的。出于一个很好的理由，监督分类算法(使用标记数据)将类别分布考虑在内。然而，当我们试图检测重要的、但与备选方案相比很少的类时，很难开发一个模型来捕捉它们。</p><p id="f663" class="pw-post-body-paragraph lv lw it lx b ly mr kd ma mb ms kg md me mt mg mh mi mu mk ml mm mv mo mp mq im bi translated">在这里，在通过一些例子深入研究了这个问题之后，我概述了一些解决这个问题的可靠的技术。</p><h1 id="9851" class="ld le it bd lf lg lh li lj lk ll lm ln ki lo kj lp kl lq km lr ko ls kp lt lu bi translated">低优先级，高优先级</h1><h2 id="9668" class="mw le it bd lf mx my dn lj mz na dp ln me nb nc lp mi nd ne lr mm nf ng lt iz bi translated">朴素贝叶斯</h2><p id="1610" class="pw-post-body-paragraph lv lw it lx b ly lz kd ma mb mc kg md me mf mg mh mi mj mk ml mm mn mo mp mq im bi translated">假设您正在构建一个预测模型来检测欺诈。您有一个包含10，000行和一些要素列的数据集，每行标记1表示欺诈性交易，标记0表示有效交易。为简单起见，我将重点介绍一个特性x，细分如下:</p><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi nh"><img src="../Images/83c889cbf4fbb90cc9a815a41d9320ca.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*POCnK_YgNFKeVixX5D9big.png"/></div></div></figure><p id="08e7" class="pw-post-body-paragraph lv lw it lx b ly mr kd ma mb ms kg md me mt mg mh mi mu mk ml mm mv mo mp mq im bi translated"><a class="ae ni" href="https://towardsdatascience.com/naive-bayes-document-classification-in-python-e33ff50f937e" rel="noopener" target="_blank">朴素贝叶斯</a>分类模型使用贝叶斯定理的比率公式来预测类成员的概率。</p><pre class="ks kt ku kv gt nj nk nl nm aw nn bi"><span id="6590" class="mw le it nk b gy no np l nq nr">Formula: Pr(C1|E)/Pr(C2|E)/ = Pr(E|C1)*Pr(C1) / Pr(E|C2)*P(C2)</span></pre><p id="2a9e" class="pw-post-body-paragraph lv lw it lx b ly mr kd ma mb ms kg md me mt mg mh mi mu mk ml mm mv mo mp mq im bi translated">该模型预测比率的哪一侧更高。</p><p id="1b0c" class="pw-post-body-paragraph lv lw it lx b ly mr kd ma mb ms kg md me mt mg mh mi mu mk ml mm mv mo mp mq im bi translated">如果类别1的先验概率非常低，而类别2的先验概率非常高，则朴素贝叶斯模型将经常无法预测类别1，即使类别1(给定证据)的可能性非常高而类别2的可能性非常低。</p><p id="1d15" class="pw-post-body-paragraph lv lw it lx b ly mr kd ma mb ms kg md me mt mg mh mi mu mk ml mm mv mo mp mq im bi translated">将欺诈视为第1类，将非欺诈视为第2类，对于不存在特征X的行，计算如下:</p><pre class="ks kt ku kv gt nj nk nl nm aw nn bi"><span id="ffa9" class="mw le it nk b gy no np l nq nr">Pr(E|C1) = 90/100 = .9<br/>Pr(C1) = 100/10,000 = .01<br/>Pr(E|C2) = 10/100 = .1<br/>Pr(C2) = 9,900/10,000 = .99</span><span id="da0e" class="mw le it nk b gy ns np l nq nr">.9 * .01 / .1 * .99 = .009/.099</span></pre><p id="ef2c" class="pw-post-body-paragraph lv lw it lx b ly mr kd ma mb ms kg md me mt mg mh mi mu mk ml mm mv mo mp mq im bi translated">由于分母较高，因此模型将预测类别2。尽管事实上证据倾向于欺诈。100个欺诈案例中有90个没有特征X，因此该交易符合大多数已知欺诈的特征。</p><p id="dbfc" class="pw-post-body-paragraph lv lw it lx b ly mr kd ma mb ms kg md me mt mg mh mi mu mk ml mm mv mo mp mq im bi translated">由于类别1的先验概率如此之低，不管证据如何，算法的输出几乎总是偏向类别2。在这种情况下，可能性必须大于0.99才能扭转局面。</p><p id="26e3" class="pw-post-body-paragraph lv lw it lx b ly mr kd ma mb ms kg md me mt mg mh mi mu mk ml mm mv mo mp mq im bi translated">如果你想要一个能区分1类和2类的模型，这是个坏消息。遗漏欺诈对银行和持卡人来说都有很高的成本。无论何时发生，抓住它并防止它，符合所有人的利益，即使它在银行交易的大计划中概率很低。</p><h2 id="5b15" class="mw le it bd lf mx my dn lj mz na dp ln me nb nc lp mi nd ne lr mm nf ng lt iz bi translated">逻辑回归</h2><p id="7332" class="pw-post-body-paragraph lv lw it lx b ly lz kd ma mb mc kg md me mf mg mh mi mj mk ml mm mn mo mp mq im bi translated">逻辑回归是另一种输出概率的分类算法。一条最佳拟合线被绘制到对数优势标度的数据上，然后y轴被转换成概率，将该线变成s曲线。随着x减小，曲线在底部变平，概率趋近于零；随着x的增加，曲线在顶部变平，概率接近1。</p><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div class="gh gi nt"><img src="../Images/04f735d163aca96e827a33ec8e958fe6.png" data-original-src="https://miro.medium.com/v2/resize:fit:1152/format:webp/1*8vhPj0GNdB60v91DlfO66g.png"/></div></figure><p id="5c95" class="pw-post-body-paragraph lv lw it lx b ly mr kd ma mb ms kg md me mt mg mh mi mu mk ml mm mv mo mp mq im bi translated">类别1的低先验将使类别1的预测难以实现，因为逻辑回归通过找到具有最高最大可能性的线来确定最佳拟合的线。最大似然是给定线上数据点的对数似然的总和。对数似然性通过将数据点从x轴投影到直线上并在y轴上找到相应概率的对数来确定。如果类别1的情况非常少，则最佳拟合线可能是很少(如果有的话)将高概率分配给类别1的线。在这些情况下，该模型可以通过正确地分类尽可能多的多数类而忽略少数类来获得更好的最大似然得分。</p><p id="d67f" class="pw-post-body-paragraph lv lw it lx b ly mr kd ma mb ms kg md me mt mg mh mi mu mk ml mm mv mo mp mq im bi translated"><strong class="lx jd">概括一下:</strong>如果你想用机器学习对某样东西进行分类，而它的先验概率很低，你会遇到麻烦。幸运的是，您可以使用一些策略来推动您的分类器预测低先验类别。我在这里概述了其中的三个。</p><h1 id="d3e0" class="ld le it bd lf lg lh li lj lk ll lm ln ki lo kj lp kl lq km lr ko ls kp lt lu bi translated">策略1:用自举改变先验</h1><p id="e30b" class="pw-post-body-paragraph lv lw it lx b ly lz kd ma mb mc kg md me mf mg mh mi mj mk ml mm mn mo mp mq im bi translated">您可以通过对数据进行重采样来更改类先验。</p><p id="67b7" class="pw-post-body-paragraph lv lw it lx b ly mr kd ma mb ms kg md me mt mg mh mi mu mk ml mm mv mo mp mq im bi translated">如果不平衡很小，你可以对你的多数类进行随机<a class="ae ni" href="https://imbalanced-learn.readthedocs.io/en/stable/generated/imblearn.under_sampling.RandomUnderSampler.html#imblearn.under_sampling.RandomUnderSampler" rel="noopener ugc nofollow" target="_blank">欠采样</a>。如果你的类高度不平衡，我不推荐这个选项，因为你会丢失很多数据。</p><p id="c0fb" class="pw-post-body-paragraph lv lw it lx b ly mr kd ma mb ms kg md me mt mg mh mi mu mk ml mm mv mo mp mq im bi translated">另一个选择是对你的少数类使用随机<a class="ae ni" href="https://imbalanced-learn.readthedocs.io/en/stable/generated/imblearn.over_sampling.RandomOverSampler.html#imblearn.over_sampling.RandomOverSampler" rel="noopener ugc nofollow" target="_blank">过采样</a>或者合成过采样。Imblearn的<a class="ae ni" href="https://imbalanced-learn.readthedocs.io/en/stable/generated/imblearn.over_sampling.SMOTE.html#imblearn.over_sampling.SMOTE" rel="noopener ugc nofollow" target="_blank"> SMOTE </a>通过查找每个数据点的最近邻居(默认值为5)并在它们之间的向量上绘制点来创建合成样本。每个向量上的点数取决于平衡类别所需的样本数。</p><p id="85a8" class="pw-post-body-paragraph lv lw it lx b ly mr kd ma mb ms kg md me mt mg mh mi mu mk ml mm mv mo mp mq im bi translated">下图显示了SMOTE前后的数据:</p><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi nu"><img src="../Images/d772b7056a0488a92f0dfb8ef2727ee4.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*GtDa81o401d00mlnqzYPRw.png"/></div></div></figure><p id="aca1" class="pw-post-body-paragraph lv lw it lx b ly mr kd ma mb ms kg md me mt mg mh mi mu mk ml mm mv mo mp mq im bi translated">您可以看到，现在在现有数据点之间聚集了少数民族类的附加数据点。</p><p id="bbdd" class="pw-post-body-paragraph lv lw it lx b ly mr kd ma mb ms kg md me mt mg mh mi mu mk ml mm mv mo mp mq im bi translated">您可以在带有分类器的“imblearn”管道中使用SMOTE，然后使管道符合您的数据，如下所示:</p><pre class="ks kt ku kv gt nj nk nl nm aw nn bi"><span id="91fc" class="mw le it nk b gy no np l nq nr">from imblearn.pipeline import Pipeline<br/>from imblearn.over_sampling import SMOTE</span><span id="70ea" class="mw le it nk b gy ns np l nq nr">smote = SMOTE()<br/>cls = LogisticRegression()</span><span id="a953" class="mw le it nk b gy ns np l nq nr">pipe = Pipeline([(‘smt’, smote), (‘cls’, cls)])<br/>pipe.fit(X_train, y_train)</span></pre><p id="91e5" class="pw-post-body-paragraph lv lw it lx b ly mr kd ma mb ms kg md me mt mg mh mi mu mk ml mm mv mo mp mq im bi translated">SMOTE有许多您可能希望考虑的变体，例如<a class="ae ni" href="https://imbalanced-learn.readthedocs.io/en/stable/generated/imblearn.over_sampling.SMOTENC.html" rel="noopener ugc nofollow" target="_blank"> SMOTENC </a>，它被设计用来处理分类特征。在<a class="ae ni" href="https://imbalanced-learn.readthedocs.io/en/stable/over_sampling.html" rel="noopener ugc nofollow" target="_blank">用户指南</a>中有详细的描述。</p><h1 id="a05e" class="ld le it bd lf lg lh li lj lk ll lm ln ki lo kj lp kl lq km lr ko ls kp lt lu bi translated">策略2:调整损失函数</h1><p id="ebeb" class="pw-post-body-paragraph lv lw it lx b ly lz kd ma mb mc kg md me mf mg mh mi mj mk ml mm mn mo mp mq im bi translated">一些分类器有一个可选的“类权重”参数。您可以使用类权重来调整损失函数，这样您的模型就不会因仅获得多数类的正确预测而优化。您可以使用字典以所需的比率分配类权重:</p><p id="39e6" class="pw-post-body-paragraph lv lw it lx b ly mr kd ma mb ms kg md me mt mg mh mi mu mk ml mm mv mo mp mq im bi translated">class_weight={0:1，1:10}</p><p id="6881" class="pw-post-body-paragraph lv lw it lx b ly mr kd ma mb ms kg md me mt mg mh mi mu mk ml mm mv mo mp mq im bi translated">当正确分类为1时，对数损失的各种重量组合(<strong class="lx jd">(ylog(p)+(1y)log(1p)</strong>)如下所示。</p><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div class="gh gi nv"><img src="../Images/5650eb1059277782db1cd8d6d7d8c238.png" data-original-src="https://miro.medium.com/v2/resize:fit:864/format:webp/1*JlIwrrZrEeDhBkbvd-CGGw.png"/></div></figure><p id="d9dc" class="pw-post-body-paragraph lv lw it lx b ly mr kd ma mb ms kg md me mt mg mh mi mu mk ml mm mv mo mp mq im bi translated">x轴上. 5或更大的值是1的预测值，概率从低到高。x轴上低于0.5的值是0的预测值(不是类1)，概率从高到低。分配给1(正确类别)的概率越高，对数损失越低。模型分配给0(不正确的类别)的概率越高，对数损失就越大。我们分配的类别权重越高，对错误预测的惩罚就越严厉。</p><h1 id="08c7" class="ld le it bd lf lg lh li lj lk ll lm ln ki lo kj lp kl lq km lr ko ls kp lt lu bi translated">策略3:改变预测的阈值</h1><p id="5b94" class="pw-post-body-paragraph lv lw it lx b ly lz kd ma mb mc kg md me mf mg mh mi mj mk ml mm mn mo mp mq im bi translated">如果您的模型正在预测您的少数类的概率，因此可能的情况始终在30%或40%的“雷达下飞行”,您可能希望降低正面预测的阈值。</p><p id="e218" class="pw-post-body-paragraph lv lw it lx b ly mr kd ma mb ms kg md me mt mg mh mi mu mk ml mm mv mo mp mq im bi translated">要了解这种情况是否会发生，请使用分类器的predict_proba()方法。然后，您可以创建一个带有阈值的自定义预测列表，以捕捉目标类的更多情况。代码应该如下所示:</p><pre class="ks kt ku kv gt nj nk nl nm aw nn bi"><span id="ef49" class="mw le it nk b gy no np l nq nr">probabilities = cls.predict_proba(x_test)[:,1]<br/>y_hat = [1 if i&gt;.35 else 0 for i in probabilities]</span></pre><p id="7611" class="pw-post-body-paragraph lv lw it lx b ly mr kd ma mb ms kg md me mt mg mh mi mu mk ml mm mv mo mp mq im bi translated">当心:如果你把门槛移得太远，你可能会在交易中得到比你预想的更多的误报。确保绘制了一个<a class="ae ni" href="https://scikit-learn.org/stable/modules/generated/sklearn.metrics.confusion_matrix.html" rel="noopener ugc nofollow" target="_blank">混淆矩阵</a>，并比较了移动阈值前后的<a class="ae ni" href="https://scikit-learn.org/stable/modules/generated/sklearn.metrics.f1_score.html" rel="noopener ugc nofollow" target="_blank"> F1分数</a>，以便根据需要进行调整。</p><h1 id="0665" class="ld le it bd lf lg lh li lj lk ll lm ln ki lo kj lp kl lq km lr ko ls kp lt lu bi translated">总结</h1><p id="d17f" class="pw-post-body-paragraph lv lw it lx b ly lz kd ma mb mc kg md me mf mg mh mi mj mk ml mm mn mo mp mq im bi translated">您可以通过以下方式处理不平衡的类:</p><ul class=""><li id="53d1" class="nw nx it lx b ly mr mb ms me ny mi nz mm oa mq ob oc od oe bi translated">通过重采样改变先验</li><li id="d8d9" class="nw nx it lx b ly of mb og me oh mi oi mm oj mq ob oc od oe bi translated">调整损失函数</li><li id="700f" class="nw nx it lx b ly of mb og me oh mi oi mm oj mq ob oc od oe bi translated">更改预测的概率阈值</li></ul><p id="88d2" class="pw-post-body-paragraph lv lw it lx b ly mr kd ma mb ms kg md me mt mg mh mi mu mk ml mm mv mo mp mq im bi translated">在某些情况下，您可能需要使用这三者来创建一个能够持续预测罕见类的模型。</p><h1 id="7d74" class="ld le it bd lf lg lh li lj lk ll lm ln ki lo kj lp kl lq km lr ko ls kp lt lu bi translated"><strong class="ak">资源</strong></h1><p id="4792" class="pw-post-body-paragraph lv lw it lx b ly lz kd ma mb mc kg md me mf mg mh mi mj mk ml mm mn mo mp mq im bi translated">这是我和海伦·利维·迈尔斯和亚当·布隆菲尔德一起做的一个项目，它使用了上述一些技术:</p><div class="ok ol gp gr om on"><a href="https://github.com/AdamBlomfield/mod_5_project" rel="noopener  ugc nofollow" target="_blank"><div class="oo ab fo"><div class="op ab oq cl cj or"><h2 class="bd jd gy z fp os fr fs ot fu fw jc bi translated">AdamBlomfield/mod_5_project</h2><div class="ou l"><h3 class="bd b gy z fp os fr fs ot fu fw dk translated">作者:Kelly Epley，Adam Blomfield和Helen Levy-Myers在这个项目中，我们训练了一个模型，将交易标记为…</h3></div><div class="ov l"><p class="bd b dl z fp os fr fs ot fu fw dk translated">github.com</p></div></div><div class="ow l"><div class="ox l oy oz pa ow pb lb on"/></div></div></a></div><p id="0e5e" class="pw-post-body-paragraph lv lw it lx b ly mr kd ma mb ms kg md me mt mg mh mi mu mk ml mm mv mo mp mq im bi translated">以下是一些有用的链接:</p><div class="ok ol gp gr om on"><a href="https://imbalanced-learn.readthedocs.io/en/stable/" rel="noopener  ugc nofollow" target="_blank"><div class="oo ab fo"><div class="op ab oq cl cj or"><h2 class="bd jd gy z fp os fr fs ot fu fw jc bi translated">欢迎来到不平衡学习文档！—不平衡—了解0.5.0文档</h2><div class="ou l"><h3 class="bd b gy z fp os fr fs ot fu fw dk translated">安装、测试和贡献包的信息。主要文档。这包含了深入的…</h3></div><div class="ov l"><p class="bd b dl z fp os fr fs ot fu fw dk translated">不平衡-learn.readthedocs.io</p></div></div></div></a></div><div class="ok ol gp gr om on"><a href="http://wiki.fast.ai/index.php/Log_Loss" rel="noopener  ugc nofollow" target="_blank"><div class="oo ab fo"><div class="op ab oq cl cj or"><h2 class="bd jd gy z fp os fr fs ot fu fw jc bi translated">原木损失</h2><div class="ou l"><h3 class="bd b gy z fp os fr fs ot fu fw dk translated">对数损失(与交叉熵相关)衡量分类模型的性能，其中预测…</h3></div><div class="ov l"><p class="bd b dl z fp os fr fs ot fu fw dk translated">wiki.fast.ai</p></div></div></div></a></div><div class="ok ol gp gr om on"><a href="https://developers.google.com/machine-learning/crash-course/classification/precision-and-recall" rel="noopener  ugc nofollow" target="_blank"><div class="oo ab fo"><div class="op ab oq cl cj or"><h2 class="bd jd gy z fp os fr fs ot fu fw jc bi translated">分类:精确度和召回率|机器学习速成班|谷歌开发者</h2><div class="ou l"><h3 class="bd b gy z fp os fr fs ot fu fw dk translated">预计时间:9分钟精度试图回答以下问题:什么比例的积极…</h3></div><div class="ov l"><p class="bd b dl z fp os fr fs ot fu fw dk translated">developers.google.com</p></div></div><div class="ow l"><div class="pc l oy oz pa ow pb lb on"/></div></div></a></div></div></div>    
</body>
</html>