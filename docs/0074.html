<html>
<head>
<title>How To Use Active Learning To Iteratively Improve Your Machine Learning Models</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">如何使用主动学习来迭代改进您的机器学习模型</h1>
<blockquote>原文：<a href="https://pub.towardsai.net/how-to-use-active-learning-to-iteratively-improve-your-machine-learning-models-1c6164bdab99?source=collection_archive---------0-----------------------#2019-06-17">https://pub.towardsai.net/how-to-use-active-learning-to-iteratively-improve-your-machine-learning-models-1c6164bdab99?source=collection_archive---------0-----------------------#2019-06-17</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><h2 id="203e" class="ir is it bd b dl iu iv iw ix iy iz dk ja translated" aria-label="kicker paragraph"><a class="ae ep" href="https://towardsai.net/p/category/machine-learning" rel="noopener ugc nofollow" target="_blank">机器学习</a></h2><div class=""/><h1 id="31f9" class="jz ka it bd kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw bi translated"><strong class="ak">简介</strong></h1><p id="58f9" class="pw-post-body-paragraph kx ky it kz b la lb lc ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">在本文中，我将解释如何使用主动学习来迭代地提高机器学习模型的性能。这种技术适用于任何模型，但是出于本文的目的，我将说明如何改进二进制文本分类器。本文涵盖的所有材料都基于微软题为“使用R和Python进行可扩展数据科学、机器学习和AI”的2018 Strata数据大会教程。</p><p id="fab5" class="pw-post-body-paragraph kx ky it kz b la lv lc ld le lw lg lh li lx lk ll lm ly lo lp lq lz ls lt lu im bi translated">我假设读者熟悉机器学习环境中的主动学习概念。如果没有，那么<a class="ae ma" href="https://en.wikipedia.org/wiki/Active_learning_(machine_learning)" rel="noopener ugc nofollow" target="_blank">这篇</a>维基百科文章的导语部分就是一个很好的介绍。</p><p id="481c" class="pw-post-body-paragraph kx ky it kz b la lv lc ld le lw lg lh li lx lk ll lm ly lo lp lq lz ls lt lu im bi translated">重现本文给出的结果的代码是<a class="ae ma" href="https://github.com/hsm207/Strata2018/tree/blog" rel="noopener ugc nofollow" target="_blank">这里是</a>。</p><h1 id="7b27" class="jz ka it bd kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw bi translated">方法学</h1><h2 id="f10c" class="mb ka it bd kb mc md dn kf me mf dp kj li mg mh kn lm mi mj kr lq mk ml kv iz bi translated">资料组</h2><p id="71fd" class="pw-post-body-paragraph kx ky it kz b la lb lc ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">我们将通过构建一个在<a class="ae ma" href="https://meta.m.wikimedia.org/wiki/Research:Detox/Data_Release" rel="noopener ugc nofollow" target="_blank"> Wikipedia Detox </a>数据集上训练的二进制文本分类器来验证主动学习的概念，以检测评论是否构成人身攻击。这里有几个例子来说明这个问题:</p><figure class="mn mo mp mq gt mr gh gi paragraph-image"><div role="button" tabindex="0" class="ms mt di mu bf mv"><div class="gh gi mm"><img src="../Images/27485e7345b8cfb9ad7a74e47f23db8f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*d_UXHO3hFkmP7TgjYNXJbg.png"/></div></div></figure><p id="2c19" class="pw-post-body-paragraph kx ky it kz b la lv lc ld le lw lg lh li lx lk ll lm ly lo lp lq lz ls lt lu im bi translated">训练集有115，374个标记示例。我们将这个训练集分成三个集合，即初始训练集、未标记训练集和测试集，如下所示:</p><figure class="mn mo mp mq gt mr gh gi paragraph-image"><div class="gh gi my"><img src="../Images/a499ad8c30075bf430a7bb3329065eeb.png" data-original-src="https://miro.medium.com/v2/resize:fit:450/format:webp/1*GiyTPuqstqv0UpJeChenrg.png"/></div></figure><p id="0c8a" class="pw-post-body-paragraph kx ky it kz b la lv lc ld le lw lg lh li lx lk ll lm ly lo lp lq lz ls lt lu im bi translated">此外，标签在初始训练集中均匀分布，但在测试集上，只有13%的标签为1。</p><p id="bb5e" class="pw-post-body-paragraph kx ky it kz b la lv lc ld le lw lg lh li lx lk ll lm ly lo lp lq lz ls lt lu im bi translated">我们以这种方式分割训练集，以模拟真实世界的条件。这种分裂对应于这样的情况:我们有10，285个高质量的已标记示例，并且需要决定我们需要标记105，089个“未标记”示例中的哪一个，以获得更多的训练数据来训练我们的分类器。因为标记数据是昂贵的，所以挑战在于识别将对我们的模型的性能有最大贡献的例子。</p><p id="f935" class="pw-post-body-paragraph kx ky it kz b la lv lc ld le lw lg lh li lx lk ll lm ly lo lp lq lz ls lt lu im bi translated">我们将看到，相对于在无标签训练集上的随机采样，主动学习是一种更好的采样策略。</p><p id="056b" class="pw-post-body-paragraph kx ky it kz b la lv lc ld le lw lg lh li lx lk ll lm ly lo lp lq lz ls lt lu im bi translated">最后，使用手套词嵌入将评论转换成50维嵌入。</p><h2 id="ed10" class="mb ka it bd kb mc md dn kf me mf dp kj li mg mh kn lm mi mj kr lq mk ml kv iz bi translated">抽样策略</h2><p id="d73a" class="pw-post-body-paragraph kx ky it kz b la lb lc ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">我们将使用的抽样策略是不确定性抽样和基于池的抽样的组合。它是这样工作的:</p><ol class=""><li id="f3ef" class="mz na it kz b la lv le lw li nb lm nc lq nd lu ne nf ng nh bi translated">从未标记的训练集中随机选择1，000个样本</li><li id="eee2" class="mz na it kz b la ni le nj li nk lm nl lq nm lu ne nf ng nh bi translated">使用欧几里德距离作为距离度量，在这1，000个样本上构建一个分层聚类(这是汇集部分)</li><li id="e620" class="mz na it kz b la ni le nj li nk lm nl lq nm lu ne nf ng nh bi translated">将分级分类的输出分成20组</li><li id="657b" class="mz na it kz b la ni le nj li nk lm nl lq nm lu ne nf ng nh bi translated">对于每组，选择具有最高<a class="ae ma" href="http://www.di.fc.ul.pt/~jpn/r/maxent/maxent.html" rel="noopener ugc nofollow" target="_blank">熵</a>的样本，即挑选模型最不确定的观察值</li></ol><p id="e5d6" class="pw-post-body-paragraph kx ky it kz b la lv lc ld le lw lg lh li lx lk ll lm ly lo lp lq lz ls lt lu im bi translated">选择上面的数字是为了模拟我们一次只能获得20个高质量标签的情况，例如放射科医师一天只能处理20个医学图像。我们不会对整个未标记的训练集进行聚类，因为计算熵需要进行模型推断，而这在大型数据集上可能需要很长时间。</p><p id="5cab" class="pw-post-body-paragraph kx ky it kz b la lv lc ld le lw lg lh li lx lk ll lm ly lo lp lq lz ls lt lu im bi translated">对样本进行聚类的原因是为了最大化将要发送进行标记的样本的多样性。例如，如果我们简单地从这1000个样本中挑选出具有最高熵的前20个例子，那么如果这些例子形成一个紧密的组，我们就有挑选非常相似的例子的风险。在这种情况下，最好只从这组中挑选一个例子，其余的从另一组中挑选，因为不同的例子有助于模型更好地学习。</p><h2 id="21af" class="mb ka it bd kb mc md dn kf me mf dp kj li mg mh kn lm mi mj kr lq mk ml kv iz bi translated">模型</h2><p id="80a0" class="pw-post-body-paragraph kx ky it kz b la lb lc ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">我们将使用快速树来构建分类器，将评论的矢量嵌入作为输入。FastTrees是FastRank的实现，fast rank是梯度推进算法的变体。这个<a class="ae ma" href="https://docs.microsoft.com/en-us/machine-learning-server/r-reference/microsoftml/rxfasttrees" rel="noopener ugc nofollow" target="_blank">链接</a>有更多的细节。</p><h2 id="bc51" class="mb ka it bd kb mc md dn kf me mf dp kj li mg mh kn lm mi mj kr lq mk ml kv iz bi translated">评估指标</h2><p id="af98" class="pw-post-body-paragraph kx ky it kz b la lb lc ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">由于测试集不平衡，我们将使用AUC作为主要评估指标。</p><h2 id="1d9f" class="mb ka it bd kb mc md dn kf me mf dp kj li mg mh kn lm mi mj kr lq mk ml kv iz bi translated">实施细节</h2><p id="11c9" class="pw-post-body-paragraph kx ky it kz b la lb lc ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">下面的图表说明了主动学习在这个实验中的作用:</p><figure class="mn mo mp mq gt mr gh gi paragraph-image"><div class="gh gi nn"><img src="../Images/05f077d45a62262e5cacf40b9d8adbd1.png" data-original-src="https://miro.medium.com/v2/resize:fit:1168/format:webp/1*INwqM6zn0-KCsDtwOWifdQ.png"/></div></figure><p id="9170" class="pw-post-body-paragraph kx ky it kz b la lv lc ld le lw lg lh li lx lk ll lm ly lo lp lq lz ls lt lu im bi translated">首先，我们将在初始训练集上训练我们的模型。然后，我们将使用该模型和之前描述的采样策略来识别未标记训练集中的20个评论，其分类是最不确定的，即不确定的。这些评论将被“发送”给人类进行标记。现在，我们可以扩展我们的初始训练集，以包括这些来自人类的新标记样本，并重新训练我们的模型(从头开始)。这是实验的主动学习部分。我们将重复扩展初始训练集的步骤20次迭代，并在每次迭代结束时在测试集上评估模型的性能。</p><h1 id="dcfb" class="jz ka it bd kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw bi translated">结果</h1><p id="65ed" class="pw-post-body-paragraph kx ky it kz b la lb lc ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">作为比较，我们可以通过从我们的未标记训练集中随机选取任意20个例子来迭代扩展我们的初始训练集。下图根据训练集(tss)的大小，使用不同的指标，将我们的方法(主动)与3次随机采样(随机)进行了比较。</p><figure class="mn mo mp mq gt mr gh gi paragraph-image"><div role="button" tabindex="0" class="ms mt di mu bf mv"><div class="gh gi no"><img src="../Images/7085714d25ce657b4dd011df2a6b603c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*UYRwyWu4CQYg0eH5ZqNZ2Q.png"/></div></div></figure><p id="1a09" class="pw-post-body-paragraph kx ky it kz b la lv lc ld le lw lg lh li lx lk ll lm ly lo lp lq lz ls lt lu im bi translated">我们看到随机抽样最初优于我们的主动学习方法。然而，在300的训练集规模左右，主动学习方法在AUC方面开始远远超过随机采样。</p><p id="5b4a" class="pw-post-body-paragraph kx ky it kz b la lv lc ld le lw lg lh li lx lk ll lm ly lo lp lq lz ls lt lu im bi translated">在实践中，您可能希望继续扩展初始训练集，直到模型改进(如AUC增加)相对于标记成本的比率低于预定阈值。</p><h1 id="36a0" class="jz ka it bd kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw bi translated">验证结果</h1><p id="1ec8" class="pw-post-body-paragraph kx ky it kz b la lb lc ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">为了确保我们的结果不是侥幸，我们可以模拟20次迭代的随机采样策略100次，并计算它产生比我们的主动学习方法更大的AUC的次数。我的模拟结果只产生了一个随机抽样比主动学习给出更高AUC的例子。这表明主动学习的结果在5%的水平上具有统计学意义。最后，随机抽样和主动学习之间的AUC的平均差异是-0.03。</p><h1 id="eb81" class="jz ka it bd kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw bi translated">结论</h1><p id="41be" class="pw-post-body-paragraph kx ky it kz b la lb lc ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">如果您有大量未标记的数据，但对这些数据进行标记的预算有限，那么采用主动学习方法来识别这些未标记数据中的哪些数据需要发送进行人工标记，可以在给定的预算约束下最大化模型性能。</p><p id="3405" class="pw-post-body-paragraph kx ky it kz b la lv lc ld le lw lg lh li lx lk ll lm ly lo lp lq lz ls lt lu im bi translated">如果你有任何问题，请在评论中告诉我。</p><h1 id="c480" class="jz ka it bd kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw bi translated">参考</h1><ul class=""><li id="4455" class="mz na it kz b la lb le lf li np lm nq lq nr lu ns nf ng nh bi translated"><a class="ae ma" href="https://conferences.oreilly.com/strata/strata-ca-2018/public/schedule/speaker/221674" rel="noopener ugc nofollow" target="_blank">使用R和Python进行可扩展的数据科学、机器学习和AI</a>；Inchiosa等人。艾尔。2018</li><li id="48ef" class="mz na it kz b la ni le nj li nk lm nl lq nm lu ns nf ng nh bi translated"><a class="ae ma" href="https://en.wikipedia.org/wiki/Active_learning_(machine_learning)" rel="noopener ugc nofollow" target="_blank">主动学习(机器学习)</a>；维基百科。2019年6月17日访问。</li></ul></div></div>    
</body>
</html>