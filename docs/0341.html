<html>
<head>
<title>NLP News Cypher | 03.01.20</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">NLP新闻密码| 03.01.20</h1>
<blockquote>原文：<a href="https://pub.towardsai.net/nlp-news-cypher-03-01-20-ccfa7a6cf8?source=collection_archive---------1-----------------------#2020-03-02">https://pub.towardsai.net/nlp-news-cypher-03-01-20-ccfa7a6cf8?source=collection_archive---------1-----------------------#2020-03-02</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><figure class="ip iq gp gr ir is gh gi paragraph-image"><div role="button" tabindex="0" class="it iu di iv bf iw"><div class="gh gi io"><img src="../Images/80474971c725faa9caa11bf00bccc0ac.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*3Z7OiXfZzki4sYBo"/></div></div><figcaption class="iz ja gj gh gi jb jc bd b be z dk translated">照片由<a class="ae jd" href="https://unsplash.com/@solotravelgoals?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> SoloTravelGoals </a>在<a class="ae jd" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上拍摄</figcaption></figure><h2 id="5eba" class="je jf jg bd b dl jh ji jj jk jl jm dk jn translated" aria-label="kicker paragraph">自然语言处理每周时事通讯</h2><div class=""/><div class=""><h2 id="90f5" class="pw-subtitle-paragraph km jp jg bd b kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld dk translated">除此之外什么都没有…</h2></div></div><div class="ab cl le lf hu lg" role="separator"><span class="lh bw bk li lj lk"/><span class="lh bw bk li lj lk"/><span class="lh bw bk li lj"/></div><div class="ij ik il im in"><p id="b7c2" class="pw-post-body-paragraph ll lm jg ln b lo lp kq lq lr ls kt lt lu lv lw lx ly lz ma mb mc md me mf mg ij bi mh translated"><span class="l mi mj mk bm ml mm mn mo mp di">正如</span>你可能已经猜到的，当前管理简单系统的定律(即牛顿物理学)允许观察独立变量。也就是说，如果你在这个所谓的简单系统中观察一个变量，信息不会从观察系统中的其他变量中丢失。</p><blockquote class="mq mr ms"><p id="cc80" class="ll lm mt ln b lo lp kq lq lr ls kt lt mu lv lw lx mv lz ma mb mw md me mf mg ij bi translated">观察金星的轨迹不会影响地球的轨迹。</p></blockquote><p id="ef3f" class="pw-post-body-paragraph ll lm jg ln b lo lp kq lq lr ls kt lt lu lv lw lx ly lz ma mb mc md me mf mg ij bi translated">然而，当我们增加变量的数量时，这种独立性变得难以精确观察，并且我们发现变量之间存在关系。这些变量通常以集群或系统的形式出现，它们相互依赖，是构成复杂系统的单元。</p><p id="2849" class="pw-post-body-paragraph ll lm jg ln b lo lp kq lq lr ls kt lt lu lv lw lx ly lz ma mb mc md me mf mg ij bi translated">当前现实中存在各种复杂系统，或者Neo会称之为矩阵，例如:进化过程、气候、大脑、语言(NLP？)，甚至股市…</p><p id="3577" class="pw-post-body-paragraph ll lm jg ln b lo lp kq lq lr ls kt lt lu lv lw lx ly lz ma mb mc md me mf mg ij bi translated">就拿一个可变的“情绪”和一个复杂的系统“股市”来说吧。如果我们从新闻标题的角度观察股票市场的状态，并试图将标题分为看涨、看跌或中性；我们很快就会意识到我们正处于复杂的阵痛之中。</p><p id="d06c" class="pw-post-body-paragraph ll lm jg ln b lo lp kq lq lr ls kt lt lu lv lw lx ly lz ma mb mc md me mf mg ij bi translated">这里有一个例子，假设我们有这样一个标题:</p><blockquote class="mq mr ms"><p id="af81" class="ll lm mt ln b lo lp kq lq lr ls kt lt mu lv lw lx mv lz ma mb mw md me mf mg ij bi translated">由于冠状病毒爆发的下行压力给股票带来压力，黄金在盘前上涨了6%。</p></blockquote><p id="08d8" class="pw-post-body-paragraph ll lm jg ln b lo lp kq lq lr ls kt lt lu lv lw lx ly lz ma mb mc md me mf mg ij bi translated">你认为这个标题的基本观点是什么？黄金上涨了，这很好(看涨，对吗？)，但是等等，它说股票下跌(然后看跌？)，对但是它在标题里说了两个pos/neg语句(所以是中性的对吧？！🤷‍♂️).看起来好像标题中的信息包并不是独立的，我们在将情感归结为一个分句时丢失了信息。你猜对了，自然语言是很难的！</p><figure class="mx my mz na gt is"><div class="bz fp l di"><div class="nb nc l"/></div><figcaption class="iz ja gj gh gi jb jc bd b be z dk translated">WOAH！</figcaption></figure><p id="229b" class="pw-post-body-paragraph ll lm jg ln b lo lp kq lq lr ls kt lt lu lv lw lx ly lz ma mb mc md me mf mg ij bi translated">让我们思考这个问题，直到下周(扣人心弦)，与此同时，这就是我们即将推出的实时平台的演示，该平台根据主题/情绪对金融新闻进行分类👇。我还没有完成部署，如果你想提前访问，请在<a class="ae jd" href="https://twitter.com/Quantum_Stat" rel="noopener ugc nofollow" target="_blank"> El Twitter </a>上与我联系。</p><figure class="mx my mz na gt is gh gi paragraph-image"><div role="button" tabindex="0" class="it iu di iv bf iw"><div class="gh gi nd"><img src="../Images/6eb8c2de9ea9916a09e2efbb4e5d4e0a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*6UQIL9m47R1XqWCFFMmWiw.png"/></div></div><figcaption class="iz ja gj gh gi jb jc bd b be z dk translated">解密的</figcaption></figure><p id="08df" class="pw-post-body-paragraph ll lm jg ln b lo lp kq lq lr ls kt lt lu lv lw lx ly lz ma mb mc md me mf mg ij bi translated">你这周过得怎么样？</p><h1 id="81c6" class="ne nf jg bd ng nh ni nj nk nl nm nn no kv np kw nq ky nr kz ns lb nt lc nu nv bi translated">本周:</h1><blockquote class="mq mr ms"><p id="c5e9" class="ll lm mt ln b lo lp kq lq lr ls kt lt mu lv lw lx mv lz ma mb mw md me mf mg ij bi translated">机器学习东京</p><p id="9ae7" class="ll lm mt ln b lo lp kq lq lr ls kt lt mu lv lw lx mv lz ma mb mw md me mf mg ij bi translated">分解，这是一个问题</p><p id="a226" class="ll lm mt ln b lo lp kq lq lr ls kt lt mu lv lw lx mv lz ma mb mw md me mf mg ij bi translated">NLP获得多种语言</p><p id="511b" class="ll lm mt ln b lo lp kq lq lr ls kt lt mu lv lw lx mv lz ma mb mw md me mf mg ij bi translated">给我看看100美元的TensorFlow for</p><p id="3914" class="ll lm mt ln b lo lp kq lq lr ls kt lt mu lv lw lx mv lz ma mb mw md me mf mg ij bi translated">NER任务的Colab演示</p><p id="95e4" class="ll lm mt ln b lo lp kq lq lr ls kt lt mu lv lw lx mv lz ma mb mw md me mf mg ij bi translated">嘿，伯特…欢迎来到黑客帝国</p><p id="1dc3" class="ll lm mt ln b lo lp kq lq lr ls kt lt mu lv lw lx mv lz ma mb mw md me mf mg ij bi translated">本周数据集:HotpotQA</p></blockquote></div><div class="ab cl le lf hu lg" role="separator"><span class="lh bw bk li lj lk"/><span class="lh bw bk li lj lk"/><span class="lh bw bk li lj"/></div><div class="ij ik il im in"><h1 id="a499" class="ne nf jg bd ng nh nw nj nk nl nx nn no kv ny kw nq ky nz kz ns lb oa lc nu nv bi translated">机器学习东京</h1><p id="0164" class="pw-post-body-paragraph ll lm jg ln b lo ob kq lq lr oc kt lt lu od lw lx ly oe ma mb mc of me mf mg ij bi translated">有时，回购页面会出现并挽救局面。这个坏男孩拥有麻省理工学院系列讲座的链接，涉及CV、NLP和RL的各种主题！</p><div class="ip iq gp gr ir og"><a href="https://github.com/Machine-Learning-Tokyo/AI_Curriculum" rel="noopener  ugc nofollow" target="_blank"><div class="oh ab fo"><div class="oi ab oj cl cj ok"><h2 class="bd jq gy z fp ol fr fs om fu fw jp bi translated">机器学习-东京/人工智能_课程</h2><div class="on l"><h3 class="bd b gy z fp ol fr fs om fu fw dk translated">开放深度学习和强化学习讲座，来自顶尖大学，如斯坦福大学，麻省理工学院，加州大学…</h3></div><div class="oo l"><p class="bd b dl z fp ol fr fs om fu fw dk translated">github.com</p></div></div><div class="op l"><div class="oq l or os ot op ou ix og"/></div></div></a></div><h1 id="609e" class="ne nf jg bd ng nh ni nj nk nl nm nn no kv np kw nq ky nr kz ns lb nt lc nu nv bi translated">分解，这是一个问题</h1><p id="9f20" class="pw-post-body-paragraph ll lm jg ln b lo ob kq lq lr oc kt lt lu od lw lx ly oe ma mb mc of me mf mg ij bi translated">一篇新论文展示了如何将一个复杂的问题分解成小的子问题，有助于提高问答任务的性能。他们使用无监督的分解模型来分解从普通爬行中提取的问题，然后使用标准QA模型来回答这些问题，然后用于HotpotQA数据集上的多跳问题的下游。</p><p id="b35e" class="pw-post-body-paragraph ll lm jg ln b lo lp kq lq lr ls kt lt lu lv lw lx ly lz ma mb mc md me mf mg ij bi translated"><strong class="ln jq">线程</strong>:</p><div class="ip iq gp gr ir og"><a href="https://threader.app/thread/1232127027961942018" rel="noopener  ugc nofollow" target="_blank"><div class="oh ab fo"><div class="oi ab oj cl cj ok"><h2 class="bd jq gy z fp ol fr fs om fu fw jp bi translated">@EthanJPerez写的一个线程</h2><div class="on l"><h3 class="bd b gy z fp ol fr fs om fu fw dk translated">新的！“用于问答的无监督问题分解”:我们将一个困难的问题分解成几个更简单的问题，用…</h3></div><div class="oo l"><p class="bd b dl z fp ol fr fs om fu fw dk translated">线程应用程序</p></div></div><div class="op l"><div class="ov l or os ot op ou ix og"/></div></div></a></div><p id="c7bc" class="pw-post-body-paragraph ll lm jg ln b lo lp kq lq lr ls kt lt lu lv lw lx ly lz ma mb mc md me mf mg ij bi translated"><strong class="ln jq">论文:</strong></p><figure class="mx my mz na gt is"><div class="bz fp l di"><div class="ow nc l"/></div><figcaption class="iz ja gj gh gi jb jc bd b be z dk translated"><a class="ae jd" href="https://arxiv.org/pdf/2002.09758.pdf" rel="noopener ugc nofollow" target="_blank">链接</a></figcaption></figure><h1 id="6c2e" class="ne nf jg bd ng nh ni nj nk nl nm nn no kv np kw nq ky nr kz ns lb nt lc nu nv bi translated">NLP获得多种语言</h1><p id="48e9" class="pw-post-body-paragraph ll lm jg ln b lo ob kq lq lr oc kt lt lu od lw lx ly oe ma mb mc of me mf mg ij bi translated">Abed先生使用MULTIFIT模型为阿拉伯语构建了一个情感分析工具，并部署在Heroku上！</p><p id="06d2" class="pw-post-body-paragraph ll lm jg ln b lo lp kq lq lr ls kt lt lu lv lw lx ly lz ma mb mc md me mf mg ij bi translated"><strong class="ln jq">演示</strong>:</p><div class="ip iq gp gr ir og"><a href="http://arabic-nlp.herokuapp.com/" rel="noopener  ugc nofollow" target="_blank"><div class="oh ab fo"><div class="oi ab oj cl cj ok"><h2 class="bd jq gy z fp ol fr fs om fu fw jp bi translated">阿拉伯文本分类</h2><div class="on l"><h3 class="bd b gy z fp ol fr fs om fu fw dk translated">使用这种神经网络模型(MULTIFiT ),你可以将阿拉伯语评论或类似文本分为正面或负面…</h3></div><div class="oo l"><p class="bd b dl z fp ol fr fs om fu fw dk translated">arabic-nlp.herokuapp.com</p></div></div></div></a></div><figure class="mx my mz na gt is"><div class="bz fp l di"><div class="ox nc l"/></div></figure><h1 id="40c9" class="ne nf jg bd ng nh ni nj nk nl nm nn no kv np kw nq ky nr kz ns lb nt lc nu nv bi translated">给我看看100美元的TensorFlow for</h1><p id="b129" class="pw-post-body-paragraph ll lm jg ln b lo ob kq lq lr oc kt lt lu od lw lx ly oe ma mb mc of me mf mg ij bi translated">TensorFlow上周宣布，他们将转发你在他们的ML跟踪平台<a class="ae jd" href="https://tensorflow.org/tensorboard" rel="noopener ugc nofollow" target="_blank"> TensorBoard </a>上分享的模型。如果你想让你的应用程序在社交媒体上或者可能在他们的开发峰会上得到报道，下面是详细信息:</p><figure class="mx my mz na gt is"><div class="bz fp l di"><div class="ox nc l"/></div></figure><p id="a73f" class="pw-post-body-paragraph ll lm jg ln b lo lp kq lq lr ls kt lt lu lv lw lx ly lz ma mb mc md me mf mg ij bi translated"><strong class="ln jq">地点</strong>:</p><div class="ip iq gp gr ir og"><a href="https://tensorboard.dev/" rel="noopener  ugc nofollow" target="_blank"><div class="oh ab fo"><div class="oi ab oj cl cj ok"><h2 class="bd jq gy z fp ol fr fs om fu fw jp bi translated">TensorBoard.dev</h2><div class="on l"><h3 class="bd b gy z fp ol fr fs om fu fw dk translated">托管TensorBoard体验，让您上传并与任何人分享您的ML实验结果。</h3></div><div class="oo l"><p class="bd b dl z fp ol fr fs om fu fw dk translated">tensorboard.dev</p></div></div></div></a></div><h1 id="a241" class="ne nf jg bd ng nh ni nj nk nl nm nn no kv np kw nq ky nr kz ns lb nt lc nu nv bi translated">NER任务的Colab演示</h1><p id="b5a5" class="pw-post-body-paragraph ll lm jg ln b lo ob kq lq lr oc kt lt lu od lw lx ly oe ma mb mc of me mf mg ij bi translated">厌倦了在你的colab笔记本上使用GPU😢？Rush先生发布了一款colab笔记本，它使用TPUs来训练PyTorch上用于命名实体识别的转换器！(它使用<a class="ae jd" href="https://towardsdatascience.com/from-pytorch-to-pytorch-lightning-a-gentle-introduction-b371b7caaf09" rel="noopener" target="_blank"> PyTorch闪电</a>)</p><p id="1dc5" class="pw-post-body-paragraph ll lm jg ln b lo lp kq lq lr ls kt lt lu lv lw lx ly lz ma mb mc md me mf mg ij bi translated"><strong class="ln jq"> Colab </strong>:</p><div class="ip iq gp gr ir og"><a href="https://colab.research.google.com/drive/1dBN-wwYUngLYVt985wGs_OKPlK_ANB9D" rel="noopener  ugc nofollow" target="_blank"><div class="oh ab fo"><div class="oi ab oj cl cj ok"><h2 class="bd jq gy z fp ol fr fs om fu fw jp bi translated">谷歌联合实验室</h2><div class="on l"><h3 class="bd b gy z fp ol fr fs om fu fw dk translated">编辑描述</h3></div><div class="oo l"><p class="bd b dl z fp ol fr fs om fu fw dk translated">colab.research.google.com</p></div></div><div class="op l"><div class="oy l or os ot op ou ix og"/></div></div></a></div><p id="6103" class="pw-post-body-paragraph ll lm jg ln b lo lp kq lq lr ls kt lt lu lv lw lx ly lz ma mb mc md me mf mg ij bi translated"><strong class="ln jq">代码</strong>:</p><div class="ip iq gp gr ir og"><a href="https://github.com/huggingface/transformers/blob/master/examples/ner/run_pl_ner.py" rel="noopener  ugc nofollow" target="_blank"><div class="oh ab fo"><div class="oi ab oj cl cj ok"><h2 class="bd jq gy z fp ol fr fs om fu fw jp bi translated">拥抱脸/变形金刚</h2><div class="on l"><h3 class="bd b gy z fp ol fr fs om fu fw dk translated">🤗变形金刚:用于TensorFlow 2.0和PyTorch的最新自然语言处理。…</h3></div><div class="oo l"><p class="bd b dl z fp ol fr fs om fu fw dk translated">github.com</p></div></div><div class="op l"><div class="oz l or os ot op ou ix og"/></div></div></a></div><h1 id="04b2" class="ne nf jg bd ng nh ni nj nk nl nm nn no kv np kw nq ky nr kz ns lb nt lc nu nv bi translated">嘿，伯特…欢迎来到黑客帝国</h1><p id="ac77" class="pw-post-body-paragraph ll lm jg ln b lo ob kq lq lr oc kt lt lu od lw lx ly oe ma mb mc of me mf mg ij bi translated">GitHub上有一个隐藏的宝藏。有人发现了一个仓库，里面有一大堆文件，关于伯特的一切！我是说一切！</p><ul class=""><li id="e477" class="pa pb jg ln b lo lp lr ls lu pc ly pd mc pe mg pf pg ph pi bi translated"><a class="ae jd" href="https://github.com/tomohideshibata/BERT-related-papers#downstream-task" rel="noopener ugc nofollow" target="_blank">下游任务</a></li><li id="ad28" class="pa pb jg ln b lo pj lr pk lu pl ly pm mc pn mg pf pg ph pi bi translated"><a class="ae jd" href="https://github.com/tomohideshibata/BERT-related-papers#generation" rel="noopener ugc nofollow" target="_blank">代</a></li><li id="94f0" class="pa pb jg ln b lo pj lr pk lu pl ly pm mc pn mg pf pg ph pi bi translated"><a class="ae jd" href="https://github.com/tomohideshibata/BERT-related-papers#modification-multi-task-masking-strategy-etc" rel="noopener ugc nofollow" target="_blank">修改(多任务、掩蔽策略等。)</a></li><li id="14f2" class="pa pb jg ln b lo pj lr pk lu pl ly pm mc pn mg pf pg ph pi bi translated"><a class="ae jd" href="https://github.com/tomohideshibata/BERT-related-papers#transformer-variants" rel="noopener ugc nofollow" target="_blank">变压器变体</a></li><li id="516f" class="pa pb jg ln b lo pj lr pk lu pl ly pm mc pn mg pf pg ph pi bi translated"><a class="ae jd" href="https://github.com/tomohideshibata/BERT-related-papers#probe" rel="noopener ugc nofollow" target="_blank">探针</a></li><li id="2907" class="pa pb jg ln b lo pj lr pk lu pl ly pm mc pn mg pf pg ph pi bi translated"><a class="ae jd" href="https://github.com/tomohideshibata/BERT-related-papers#inside-bert" rel="noopener ugc nofollow" target="_blank">伯特内部</a></li><li id="c36e" class="pa pb jg ln b lo pj lr pk lu pl ly pm mc pn mg pf pg ph pi bi translated"><a class="ae jd" href="https://github.com/tomohideshibata/BERT-related-papers#multi-lingual" rel="noopener ugc nofollow" target="_blank">多语言</a></li><li id="8eda" class="pa pb jg ln b lo pj lr pk lu pl ly pm mc pn mg pf pg ph pi bi translated"><a class="ae jd" href="https://github.com/tomohideshibata/BERT-related-papers#other-than-english-models" rel="noopener ugc nofollow" target="_blank">除英制车型外</a></li><li id="ff2f" class="pa pb jg ln b lo pj lr pk lu pl ly pm mc pn mg pf pg ph pi bi translated"><a class="ae jd" href="https://github.com/tomohideshibata/BERT-related-papers#domain-specific" rel="noopener ugc nofollow" target="_blank">特定领域</a></li><li id="475b" class="pa pb jg ln b lo pj lr pk lu pl ly pm mc pn mg pf pg ph pi bi translated"><a class="ae jd" href="https://github.com/tomohideshibata/BERT-related-papers#multi-modal" rel="noopener ugc nofollow" target="_blank">多模态</a></li><li id="78d7" class="pa pb jg ln b lo pj lr pk lu pl ly pm mc pn mg pf pg ph pi bi translated"><a class="ae jd" href="https://github.com/tomohideshibata/BERT-related-papers#model-compression" rel="noopener ugc nofollow" target="_blank">模型压缩</a></li><li id="ee12" class="pa pb jg ln b lo pj lr pk lu pl ly pm mc pn mg pf pg ph pi bi translated"><a class="ae jd" href="https://github.com/tomohideshibata/BERT-related-papers#misc" rel="noopener ugc nofollow" target="_blank">杂项</a></li></ul><div class="ip iq gp gr ir og"><a href="https://github.com/tomohideshibata/BERT-related-papers" rel="noopener  ugc nofollow" target="_blank"><div class="oh ab fo"><div class="oi ab oj cl cj ok"><h2 class="bd jq gy z fp ol fr fs om fu fw jp bi translated">tomohideshibata/BERT相关论文</h2><div class="on l"><h3 class="bd b gy z fp ol fr fs om fu fw dk translated">伯特相关论文。通过在GitHub上创建一个帐户，为tomohideshibata/BERT相关论文的开发做出贡献。</h3></div><div class="oo l"><p class="bd b dl z fp ol fr fs om fu fw dk translated">github.com</p></div></div><div class="op l"><div class="po l or os ot op ou ix og"/></div></div></a></div><h1 id="329d" class="ne nf jg bd ng nh ni nj nk nl nm nn no kv np kw nq ky nr kz ns lb nt lc nu nv bi translated">本周数据集:HotpotQA</h1><p id="98f2" class="pw-post-body-paragraph ll lm jg ln b lo ob kq lq lr oc kt lt lu od lw lx ly oe ma mb mc of me mf mg ij bi translated"><strong class="ln jq">什么事？</strong></p><p id="1d91" class="pw-post-body-paragraph ll lm jg ln b lo lp kq lq lr ls kt lt lu lv lw lx ly lz ma mb mc md me mf mg ij bi translated">“这是一个问答数据集，以自然、多跳问题为特色，并对支持事实进行强有力的监督，以实现更具解释力的问答系统。”</p><p id="ba25" class="pw-post-body-paragraph ll lm jg ln b lo lp kq lq lr ls kt lt lu lv lw lx ly lz ma mb mc md me mf mg ij bi translated"><strong class="ln jq">样本:</strong></p><div class="ip iq gp gr ir og"><a href="https://hotpotqa.github.io/explorer.html" rel="noopener  ugc nofollow" target="_blank"><div class="oh ab fo"><div class="oi ab oj cl cj ok"><h2 class="bd jq gy z fp ol fr fs om fu fw jp bi translated">HotpotQA:一个多样化、可解释的多跳问答数据集</h2><div class="on l"><h3 class="bd b gy z fp ol fr fs om fu fw dk translated">探索HotpotQA</h3></div><div class="oo l"><p class="bd b dl z fp ol fr fs om fu fw dk translated">hotpotqa.github.io</p></div></div><div class="op l"><div class="pp l or os ot op ou ix og"/></div></div></a></div><p id="ba1b" class="pw-post-body-paragraph ll lm jg ln b lo lp kq lq lr ls kt lt lu lv lw lx ly lz ma mb mc md me mf mg ij bi translated"><strong class="ln jq">在哪里？</strong></p><div class="ip iq gp gr ir og"><a href="https://hotpotqa.github.io/" rel="noopener  ugc nofollow" target="_blank"><div class="oh ab fo"><div class="oi ab oj cl cj ok"><h2 class="bd jq gy z fp ol fr fs om fu fw jp bi translated">HotpotQA</h2><div class="on l"><h3 class="bd b gy z fp ol fr fs om fu fw dk translated">HotpotQA是一个问答数据集，具有自然，多跳的问题，具有强大的监督支持…</h3></div><div class="oo l"><p class="bd b dl z fp ol fr fs om fu fw dk translated">hotpotqa.github.io</p></div></div><div class="op l"><div class="pq l or os ot op ou ix og"/></div></div></a></div></div><div class="ab cl le lf hu lg" role="separator"><span class="lh bw bk li lj lk"/><span class="lh bw bk li lj lk"/><span class="lh bw bk li lj"/></div><div class="ij ik il im in"><blockquote class="pr"><p id="3b9d" class="ps pt jg bd pu pv pw px py pz qa mg dk translated">每周日，我们都会对来自世界各地的研究人员的NLP新闻和代码进行每周综述。</p><p id="a029" class="ps pt jg bd pu pv pw px py pz qa mg dk translated">如果您喜欢这篇文章，请帮助我们，并与朋友或社交媒体分享！</p><p id="de14" class="ps pt jg bd pu pv pw px py pz qa mg dk translated">如需完整报道，请关注我们的twitter: @Quantum_Stat </p></blockquote><figure class="qd qe qf qg qh is gh gi paragraph-image"><div class="gh gi qc"><img src="../Images/3ad5e7babd5f4ea7185bb4639fda9a93.png" data-original-src="https://miro.medium.com/v2/resize:fit:108/0*4pCPnc4uALef0Ojr"/></div><figcaption class="iz ja gj gh gi jb jc bd b be z dk translated"><a class="ae jd" href="http://www.quantumstat.com/" rel="noopener ugc nofollow" target="_blank">www.quantumstat.com</a></figcaption></figure></div></div>    
</body>
</html>